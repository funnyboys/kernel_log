commit 9398554fb3979852512ff4f1405e759889b45c16
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 13 14:36:00 2020 +0200

    block: remove the error_sector argument to blkdev_issue_flush
    
    The argument isn't used by any caller, and drivers don't fill out
    bi_sector for flush requests either.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 84cf8bdbec9c..0b641ae694f1 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -159,7 +159,7 @@ static int reiserfs_sync_file(struct file *filp, loff_t start, loff_t end,
 	barrier_done = reiserfs_commit_for_inode(inode);
 	reiserfs_write_unlock(inode->i_sb);
 	if (barrier_done != 1 && reiserfs_barrier_flush(inode->i_sb))
-		blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);
+		blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL);
 	inode_unlock(inode);
 	if (barrier_done < 0)
 		return barrier_done;

commit a9913d7eafa74eb2e34e26aa31fe80449b999f8e
Author: Nikitas Angelinas <nikitas.angelinas@gmail.com>
Date:   Sun Nov 3 01:44:54 2019 -0800

    reiserfs: replace open-coded atomic_dec_and_mutex_lock()
    
    Replace the open-coded logic of atomic_dec_and_mutex_lock() in
    reiserfs_file_release().
    
    Link: https://lore.kernel.org/r/20191103094431.GA18576-nikitas.angelinas@gmail.com
    Signed-off-by: Nikitas Angelinas <nikitas.angelinas@gmail.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 843aadcc123c..84cf8bdbec9c 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -38,16 +38,10 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 
 	BUG_ON(!S_ISREG(inode->i_mode));
 
-        if (atomic_add_unless(&REISERFS_I(inode)->openers, -1, 1))
+	if (!atomic_dec_and_mutex_lock(&REISERFS_I(inode)->openers,
+				       &REISERFS_I(inode)->tailpack))
 		return 0;
 
-	mutex_lock(&REISERFS_I(inode)->tailpack);
-
-        if (!atomic_dec_and_test(&REISERFS_I(inode)->openers)) {
-		mutex_unlock(&REISERFS_I(inode)->tailpack);
-		return 0;
-	}
-
 	/* fast out for when nothing needs to be done */
 	if ((!(REISERFS_I(inode)->i_flags & i_pack_on_close_mask) ||
 	     !tail_has_to_be_packed(inode)) &&

commit 3b49c9a1e984b524142afc7536041d8c66877113
Author: Jeff Layton <jlayton@redhat.com>
Date:   Fri Jul 7 15:20:52 2017 -0400

    fs: convert a pile of fsync routines to errseq_t based reporting
    
    This patch converts most of the in-kernel filesystems that do writeback
    out of the pagecache to report errors using the errseq_t-based
    infrastructure that was recently added. This allows them to report
    errors once for each open file description.
    
    Most filesystems have a fairly straightforward fsync operation. They
    call filemap_write_and_wait_range to write back all of the data and
    wait on it, and then (sometimes) sync out the metadata.
    
    For those filesystems this is a straightforward conversion from calling
    filemap_write_and_wait_range in their fsync operation to calling
    file_write_and_wait_range.
    
    Acked-by: Jan Kara <jack@suse.cz>
    Acked-by: Dave Kleikamp <dave.kleikamp@oracle.com>
    Signed-off-by: Jeff Layton <jlayton@redhat.com>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index b396eb09f288..843aadcc123c 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -154,7 +154,7 @@ static int reiserfs_sync_file(struct file *filp, loff_t start, loff_t end,
 	int err;
 	int barrier_done;
 
-	err = filemap_write_and_wait_range(inode->i_mapping, start, end);
+	err = file_write_and_wait_range(filp, start, end);
 	if (err)
 		return err;
 

commit 93407472a21b82f39c955ea7787e5bc7da100642
Author: Fabian Frederick <fabf@skynet.be>
Date:   Mon Feb 27 14:28:32 2017 -0800

    fs: add i_blocksize()
    
    Replace all 1 << inode->i_blkbits and (1 << inode->i_blkbits) in fs
    branch.
    
    This patch also fixes multiple checkpatch warnings: WARNING: Prefer
    'unsigned int' to bare use of 'unsigned'
    
    Thanks to Andrew Morton for suggesting more appropriate function instead
    of macro.
    
    [geliangtang@gmail.com: truncate: use i_blocksize()]
      Link: http://lkml.kernel.org/r/9c8b2cd83c8f5653805d43debde9fa8817e02fc4.1484895804.git.geliangtang@gmail.com
    Link: http://lkml.kernel.org/r/1481319905-10126-1-git-send-email-fabf@skynet.be
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Signed-off-by: Geliang Tang <geliangtang@gmail.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 2f8c5c9bdaf6..b396eb09f288 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -189,7 +189,7 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 	int ret = 0;
 
 	th.t_trans_id = 0;
-	blocksize = 1 << inode->i_blkbits;
+	blocksize = i_blocksize(inode);
 
 	if (logit) {
 		reiserfs_write_lock(s);

commit fd50ecaddf8372a1d96e0daeaac0f93cf04e4d42
Author: Andreas Gruenbacher <agruenba@redhat.com>
Date:   Thu Sep 29 17:48:45 2016 +0200

    vfs: Remove {get,set,remove}xattr inode operations
    
    These inode operations are no longer used; remove them.
    
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 90f815bdfa8a..2f8c5c9bdaf6 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -260,10 +260,7 @@ const struct file_operations reiserfs_file_operations = {
 
 const struct inode_operations reiserfs_file_inode_operations = {
 	.setattr = reiserfs_setattr,
-	.setxattr = generic_setxattr,
-	.getxattr = generic_getxattr,
 	.listxattr = reiserfs_listxattr,
-	.removexattr = generic_removexattr,
 	.permission = reiserfs_permission,
 	.get_acl = reiserfs_get_acl,
 	.set_acl = reiserfs_set_acl,

commit 84695ffee7987ee1e581be4c4696e47e1a29403b
Merge: bf1620068911 ce23e6401334
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon May 2 19:45:47 2016 -0400

    Merge getxattr prototype change into work.lookups
    
    The rest of work.xattr stuff isn't needed for this branch

commit 79a628d14ec7ee9adfdc3ce04343d5ff7ec20c18
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Apr 10 18:50:48 2016 -0400

    reiserfs: switch to generic_{get,set,remove}xattr()
    
    reiserfs_xattr_[sg]et() will fail with -EOPNOTSUPP for V1 inodes anyway,
    and all reiserfs instances of ->[sg]et() call it and so does ->set_acl().
    
    Checks for name length in the instances had been bogus; they should've
    been "bugger off if it's _exactly_ the prefix" (as generic would
    do on its own) and not "bugger off if it's shorter than the prefix" -
    that can't happen.
    
    xattr_full_name() is needed to adjust for the fact that generic instances
    will skip the prefix in the name passed to ->[gs]et(); reiserfs homegrown
    analogues didn't.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 9424a4ba93a9..9ffaf7145644 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -260,10 +260,10 @@ const struct file_operations reiserfs_file_operations = {
 
 const struct inode_operations reiserfs_file_inode_operations = {
 	.setattr = reiserfs_setattr,
-	.setxattr = reiserfs_setxattr,
-	.getxattr = reiserfs_getxattr,
+	.setxattr = generic_setxattr,
+	.getxattr = generic_getxattr,
 	.listxattr = reiserfs_listxattr,
-	.removexattr = reiserfs_removexattr,
+	.removexattr = generic_removexattr,
 	.permission = reiserfs_permission,
 	.get_acl = reiserfs_get_acl,
 	.set_acl = reiserfs_set_acl,

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 9424a4ba93a9..389773711de4 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -180,11 +180,11 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 	int partial = 0;
 	unsigned blocksize;
 	struct buffer_head *bh, *head;
-	unsigned long i_size_index = inode->i_size >> PAGE_CACHE_SHIFT;
+	unsigned long i_size_index = inode->i_size >> PAGE_SHIFT;
 	int new;
 	int logit = reiserfs_file_data_log(inode);
 	struct super_block *s = inode->i_sb;
-	int bh_per_page = PAGE_CACHE_SIZE / s->s_blocksize;
+	int bh_per_page = PAGE_SIZE / s->s_blocksize;
 	struct reiserfs_transaction_handle th;
 	int ret = 0;
 

commit 5955102c9984fa081b2d570cfac75c97eecf8f3b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Jan 22 15:40:57 2016 -0500

    wrappers for ->i_mutex access
    
    parallel to mutex_{lock,unlock,trylock,is_locked,lock_nested},
    inode_foo(inode) being mutex_foo(&inode->i_mutex).
    
    Please, use those for access to ->i_mutex; over the coming cycle
    ->i_mutex will become rwsem, with ->lookup() done with it held
    only shared.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 96a1bcf33db4..9424a4ba93a9 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -158,7 +158,7 @@ static int reiserfs_sync_file(struct file *filp, loff_t start, loff_t end,
 	if (err)
 		return err;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	BUG_ON(!S_ISREG(inode->i_mode));
 	err = sync_mapping_buffers(inode->i_mapping);
 	reiserfs_write_lock(inode->i_sb);
@@ -166,7 +166,7 @@ static int reiserfs_sync_file(struct file *filp, loff_t start, loff_t end,
 	reiserfs_write_unlock(inode->i_sb);
 	if (barrier_done != 1 && reiserfs_barrier_flush(inode->i_sb))
 		blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	if (barrier_done < 0)
 		return barrier_done;
 	return (err < 0) ? -EIO : 0;

commit 5d5d568975307877e9195f5305f4240e506a2807
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Apr 3 15:41:18 2015 -0400

    make new_sync_{read,write}() static
    
    All places outside of core VFS that checked ->read and ->write for being NULL or
    called the methods directly are gone now, so NULL {read,write} with non-NULL
    {read,write}_iter will do the right thing in all cases.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 751dd3f4346b..96a1bcf33db4 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -243,8 +243,6 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 }
 
 const struct file_operations reiserfs_file_operations = {
-	.read = new_sync_read,
-	.write = new_sync_write,
 	.unlocked_ioctl = reiserfs_ioctl,
 #ifdef CONFIG_COMPAT
 	.compat_ioctl = reiserfs_compat_ioctl,

commit 17093991af4995c4b93f6d8ac63aab68fcd9e1be
Author: Fabian Frederick <fabf@skynet.be>
Date:   Fri Aug 8 14:21:12 2014 -0700

    fs/reiserfs: use linux/uaccess.h
    
    Fix checkpatch warning
    
      WARNING: Use #include <linux/uaccess.h> instead of <asm/uaccess.h>
    
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index db9e80ba53a0..751dd3f4346b 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -6,7 +6,7 @@
 #include "reiserfs.h"
 #include "acl.h"
 #include "xattr.h"
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include <linux/pagemap.h>
 #include <linux/swap.h>
 #include <linux/writeback.h>

commit 16b9057804c02e2d351e9c8f606e909b43cbd9e7
Merge: 5c02c392cd23 c2338f2dc7c1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 12 10:30:18 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs updates from Al Viro:
     "This the bunch that sat in -next + lock_parent() fix.  This is the
      minimal set; there's more pending stuff.
    
      In particular, I really hope to get acct.c fixes merged this cycle -
      we need that to deal sanely with delayed-mntput stuff.  In the next
      pile, hopefully - that series is fairly short and localized
      (kernel/acct.c, fs/super.c and fs/namespace.c).  In this pile: more
      iov_iter work.  Most of prereqs for ->splice_write with sane locking
      order are there and Kent's dio rewrite would also fit nicely on top of
      this pile"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (70 commits)
      lock_parent: don't step on stale ->d_parent of all-but-freed one
      kill generic_file_splice_write()
      ceph: switch to iter_file_splice_write()
      shmem: switch to iter_file_splice_write()
      nfs: switch to iter_splice_write_file()
      fs/splice.c: remove unneeded exports
      ocfs2: switch to iter_file_splice_write()
      ->splice_write() via ->write_iter()
      bio_vec-backed iov_iter
      optimize copy_page_{to,from}_iter()
      bury generic_file_aio_{read,write}
      lustre: get rid of messing with iovecs
      ceph: switch to ->write_iter()
      ceph_sync_direct_write: stop poking into iov_iter guts
      ceph_sync_read: stop poking into iov_iter guts
      new helper: copy_page_from_iter()
      fuse: switch to ->write_iter()
      btrfs: switch to ->write_iter()
      ocfs2: switch to ->write_iter()
      xfs: switch to ->write_iter()
      ...

commit 8d0207652cbe27d1f962050737848e5ad4671958
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Apr 5 04:27:08 2014 -0400

    ->splice_write() via ->write_iter()
    
    iter_file_splice_write() - a ->splice_write() instance that gathers the
    pipe buffers, builds a bio_vec-based iov_iter covering those and feeds
    it to ->write_iter().  A bunch of simple cases coverted to that...
    
    [AV: fixed the braino spotted by Cyrill]
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 7c8ecd6468db..f070cc827456 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -248,7 +248,7 @@ const struct file_operations reiserfs_file_operations = {
 	.read_iter = generic_file_read_iter,
 	.write_iter = generic_file_write_iter,
 	.splice_read = generic_file_splice_read,
-	.splice_write = generic_file_splice_write,
+	.splice_write = iter_file_splice_write,
 	.llseek = generic_file_llseek,
 };
 

commit 8174202b34c30e0c07231bf63f18ab29af634f0b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Apr 3 03:17:43 2014 -0400

    write_iter variants of {__,}generic_file_aio_write()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 7592d681fd8c..7c8ecd6468db 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -236,7 +236,7 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 
 const struct file_operations reiserfs_file_operations = {
 	.read = new_sync_read,
-	.write = do_sync_write,
+	.write = new_sync_write,
 	.unlocked_ioctl = reiserfs_ioctl,
 #ifdef CONFIG_COMPAT
 	.compat_ioctl = reiserfs_compat_ioctl,
@@ -246,7 +246,7 @@ const struct file_operations reiserfs_file_operations = {
 	.release = reiserfs_file_release,
 	.fsync = reiserfs_sync_file,
 	.read_iter = generic_file_read_iter,
-	.aio_write = generic_file_aio_write,
+	.write_iter = generic_file_write_iter,
 	.splice_read = generic_file_splice_read,
 	.splice_write = generic_file_splice_write,
 	.llseek = generic_file_llseek,

commit aad4f8bb42af06371aa0e85bf0cd9d52c0494985
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Apr 2 14:33:16 2014 -0400

    switch simple generic_file_aio_read() users to ->read_iter()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index ed58d843d578..7592d681fd8c 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -235,7 +235,7 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 }
 
 const struct file_operations reiserfs_file_operations = {
-	.read = do_sync_read,
+	.read = new_sync_read,
 	.write = do_sync_write,
 	.unlocked_ioctl = reiserfs_ioctl,
 #ifdef CONFIG_COMPAT
@@ -245,7 +245,7 @@ const struct file_operations reiserfs_file_operations = {
 	.open = reiserfs_file_open,
 	.release = reiserfs_file_release,
 	.fsync = reiserfs_sync_file,
-	.aio_read = generic_file_aio_read,
+	.read_iter = generic_file_read_iter,
 	.aio_write = generic_file_aio_write,
 	.splice_read = generic_file_splice_read,
 	.splice_write = generic_file_splice_write,

commit a228bf8f0a3e5f1406edbd61f7400e87e23af5f7
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:42 2014 -0400

    reiserfs: cleanup, remove unnecessary parens
    
    The reiserfs code is littered with extra parens in places where the authors
    may not have been certain about precedence of & vs ->. This patch cleans them
    out.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 8496b09f00be..5f6c32c668b6 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -41,10 +41,10 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
         if (atomic_add_unless(&REISERFS_I(inode)->openers, -1, 1))
 		return 0;
 
-	mutex_lock(&(REISERFS_I(inode)->tailpack));
+	mutex_lock(&REISERFS_I(inode)->tailpack);
 
         if (!atomic_dec_and_test(&REISERFS_I(inode)->openers)) {
-		mutex_unlock(&(REISERFS_I(inode)->tailpack));
+		mutex_unlock(&REISERFS_I(inode)->tailpack);
 		return 0;
 	}
 
@@ -52,7 +52,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 	if ((!(REISERFS_I(inode)->i_flags & i_pack_on_close_mask) ||
 	     !tail_has_to_be_packed(inode)) &&
 	    REISERFS_I(inode)->i_prealloc_count <= 0) {
-		mutex_unlock(&(REISERFS_I(inode)->tailpack));
+		mutex_unlock(&REISERFS_I(inode)->tailpack);
 		return 0;
 	}
 
@@ -116,7 +116,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 	}
 out:
 	reiserfs_write_unlock(inode->i_sb);
-	mutex_unlock(&(REISERFS_I(inode)->tailpack));
+	mutex_unlock(&REISERFS_I(inode)->tailpack);
 	return err;
 }
 
@@ -126,18 +126,18 @@ static int reiserfs_file_open(struct inode *inode, struct file *file)
 
 	/* somebody might be tailpacking on final close; wait for it */
         if (!atomic_inc_not_zero(&REISERFS_I(inode)->openers)) {
-		mutex_lock(&(REISERFS_I(inode)->tailpack));
+		mutex_lock(&REISERFS_I(inode)->tailpack);
 		atomic_inc(&REISERFS_I(inode)->openers);
-		mutex_unlock(&(REISERFS_I(inode)->tailpack));
+		mutex_unlock(&REISERFS_I(inode)->tailpack);
 	}
 	return err;
 }
 
 void reiserfs_vfs_truncate_file(struct inode *inode)
 {
-	mutex_lock(&(REISERFS_I(inode)->tailpack));
+	mutex_lock(&REISERFS_I(inode)->tailpack);
 	reiserfs_truncate_file(inode, 1);
-	mutex_unlock(&(REISERFS_I(inode)->tailpack));
+	mutex_unlock(&REISERFS_I(inode)->tailpack);
 }
 
 /* Sync a reiserfs file. */

commit cf776a7a4dafa330dd371a6a301ddf9e38747d93
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:41 2014 -0400

    reiserfs: cleanup, remove leading whitespace from labels
    
    This patch moves reiserfs closer to adhering to the style rules by
    removing leading whitespace from labels.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 1010c452c450..8496b09f00be 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -114,7 +114,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 		 */
 		err = reiserfs_truncate_file(inode, 0);
 	}
-      out:
+out:
 	reiserfs_write_unlock(inode->i_sb);
 	mutex_unlock(&(REISERFS_I(inode)->tailpack));
 	return err;
@@ -228,7 +228,7 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 	}
 	if (logit) {
 		ret = journal_end(&th);
-	      drop_write_lock:
+drop_write_lock:
 		reiserfs_write_unlock(s);
 	}
 	/*

commit b491dd1769f11c2cd07278c1e285a63ccb1918ae
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:40 2014 -0400

    reiserfs: cleanup, remove blocks arg from journal_join
    
    journal_join is always called with a block count of 1. Let's just get
    rid of the argument.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index db8e3aeff9ff..1010c452c450 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -71,7 +71,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 		 * aborted transaction
 		 */
 		jbegin_failure = err;
-		err = journal_join_abort(&th, inode->i_sb, 1);
+		err = journal_join_abort(&th, inode->i_sb);
 
 		if (err) {
 			/*

commit 09f1b80ba8c967b6e17c0516e95578d5da18115f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:39 2014 -0400

    reiserfs: cleanup, remove sb argument from journal_mark_dirty
    
    journal_mark_dirty doesn't need a separate sb argument; It's provided
    by the transaction handle.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index a059320d7b44..db8e3aeff9ff 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -212,7 +212,7 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 			set_buffer_uptodate(bh);
 			if (logit) {
 				reiserfs_prepare_for_journal(s, bh, 1);
-				journal_mark_dirty(&th, s, bh);
+				journal_mark_dirty(&th, bh);
 			} else if (!buffer_dirty(bh)) {
 				mark_buffer_dirty(bh);
 				/*

commit 58d854265c4c7d9792ecb5aa5ef67ba79b1a4c12
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:38 2014 -0400

    reiserfs: cleanup, remove sb argument from journal_end
    
    journal_end doesn't need a separate sb argument; it's provided by the
    transaction handle.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 653074a2a48c..a059320d7b44 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -96,7 +96,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 #ifdef REISERFS_PREALLOCATE
 	reiserfs_discard_prealloc(&th, inode);
 #endif
-	err = journal_end(&th, inode->i_sb);
+	err = journal_end(&th);
 
 	/* copy back the error code from journal_begin */
 	if (!err)
@@ -227,7 +227,7 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 		}
 	}
 	if (logit) {
-		ret = journal_end(&th, s);
+		ret = journal_end(&th);
 	      drop_write_lock:
 		reiserfs_write_unlock(s);
 	}

commit 706a5323384d9ae973a72005b73987d39e009019
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:37 2014 -0400

    reiserfs: cleanup, remove nblocks argument from journal_end
    
    journal_end takes a block count argument but doesn't actually use it
    for anything. We can remove it.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 27399430664e..653074a2a48c 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -96,7 +96,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 #ifdef REISERFS_PREALLOCATE
 	reiserfs_discard_prealloc(&th, inode);
 #endif
-	err = journal_end(&th, inode->i_sb, 1);
+	err = journal_end(&th, inode->i_sb);
 
 	/* copy back the error code from journal_begin */
 	if (!err)
@@ -227,7 +227,7 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 		}
 	}
 	if (logit) {
-		ret = journal_end(&th, s, bh_per_page + 1);
+		ret = journal_end(&th, s);
 	      drop_write_lock:
 		reiserfs_write_unlock(s);
 	}

commit 098297b27d23ad9d0fc302e3417474d9342c6c14
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:36 2014 -0400

    reiserfs: cleanup, reformat comments to normal kernel style
    
    This patch reformats comments in the reiserfs code to fit in 80 columns and
    to follow the style rules.
    
    There is no functional change but it helps make my eyes bleed less.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index ed58d843d578..27399430664e 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -15,20 +15,20 @@
 #include <linux/quotaops.h>
 
 /*
-** We pack the tails of files on file close, not at the time they are written.
-** This implies an unnecessary copy of the tail and an unnecessary indirect item
-** insertion/balancing, for files that are written in one write.
-** It avoids unnecessary tail packings (balances) for files that are written in
-** multiple writes and are small enough to have tails.
-**
-** file_release is called by the VFS layer when the file is closed.  If
-** this is the last open file descriptor, and the file
-** small enough to have a tail, and the tail is currently in an
-** unformatted node, the tail is converted back into a direct item.
-**
-** We use reiserfs_truncate_file to pack the tail, since it already has
-** all the conditions coded.
-*/
+ * We pack the tails of files on file close, not at the time they are written.
+ * This implies an unnecessary copy of the tail and an unnecessary indirect item
+ * insertion/balancing, for files that are written in one write.
+ * It avoids unnecessary tail packings (balances) for files that are written in
+ * multiple writes and are small enough to have tails.
+ *
+ * file_release is called by the VFS layer when the file is closed.  If
+ * this is the last open file descriptor, and the file
+ * small enough to have a tail, and the tail is currently in an
+ * unformatted node, the tail is converted back into a direct item.
+ *
+ * We use reiserfs_truncate_file to pack the tail, since it already has
+ * all the conditions coded.
+ */
 static int reiserfs_file_release(struct inode *inode, struct file *filp)
 {
 
@@ -57,14 +57,16 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 	}
 
 	reiserfs_write_lock(inode->i_sb);
-	/* freeing preallocation only involves relogging blocks that
+	/*
+	 * freeing preallocation only involves relogging blocks that
 	 * are already in the current transaction.  preallocation gets
 	 * freed at the end of each transaction, so it is impossible for
 	 * us to log any additional blocks (including quota blocks)
 	 */
 	err = journal_begin(&th, inode->i_sb, 1);
 	if (err) {
-		/* uh oh, we can't allow the inode to go away while there
+		/*
+		 * uh oh, we can't allow the inode to go away while there
 		 * is still preallocation blocks pending.  Try to join the
 		 * aborted transaction
 		 */
@@ -72,11 +74,13 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 		err = journal_join_abort(&th, inode->i_sb, 1);
 
 		if (err) {
-			/* hmpf, our choices here aren't good.  We can pin the inode
-			 * which will disallow unmount from every happening, we can
-			 * do nothing, which will corrupt random memory on unmount,
-			 * or we can forcibly remove the file from the preallocation
-			 * list, which will leak blocks on disk.  Lets pin the inode
+			/*
+			 * hmpf, our choices here aren't good.  We can pin
+			 * the inode which will disallow unmount from ever
+			 * happening, we can do nothing, which will corrupt
+			 * random memory on unmount, or we can forcibly
+			 * remove the file from the preallocation list, which
+			 * will leak blocks on disk.  Lets pin the inode
 			 * and let the admin know what is going on.
 			 */
 			igrab(inode);
@@ -102,10 +106,12 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 	    (REISERFS_I(inode)->i_flags & i_pack_on_close_mask) &&
 	    tail_has_to_be_packed(inode)) {
 
-		/* if regular file is released by last holder and it has been
-		   appended (we append by unformatted node only) or its direct
-		   item(s) had to be converted, then it may have to be
-		   indirect2direct converted */
+		/*
+		 * if regular file is released by last holder and it has been
+		 * appended (we append by unformatted node only) or its direct
+		 * item(s) had to be converted, then it may have to be
+		 * indirect2direct converted
+		 */
 		err = reiserfs_truncate_file(inode, 0);
 	}
       out:
@@ -117,8 +123,9 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 static int reiserfs_file_open(struct inode *inode, struct file *file)
 {
 	int err = dquot_file_open(inode, file);
+
+	/* somebody might be tailpacking on final close; wait for it */
         if (!atomic_inc_not_zero(&REISERFS_I(inode)->openers)) {
-		/* somebody might be tailpacking on final close; wait for it */
 		mutex_lock(&(REISERFS_I(inode)->tailpack));
 		atomic_inc(&REISERFS_I(inode)->openers);
 		mutex_unlock(&(REISERFS_I(inode)->tailpack));
@@ -208,7 +215,8 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 				journal_mark_dirty(&th, s, bh);
 			} else if (!buffer_dirty(bh)) {
 				mark_buffer_dirty(bh);
-				/* do data=ordered on any page past the end
+				/*
+				 * do data=ordered on any page past the end
 				 * of file and any buffer marked BH_New.
 				 */
 				if (reiserfs_data_ordered(inode->i_sb) &&

commit 47f70d08facf288a9faad6e6c36ac2e670be8195
Author: Christoph Hellwig <hch@infradead.org>
Date:   Fri Dec 20 05:16:49 2013 -0800

    reiserfs: use generic posix ACL infrastructure
    
    Also don't bother to set up a .get_acl method for symlinks as we do not
    support access control (ACLs or even mode bits) for symlinks in Linux.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index dcaafcfc23b0..ed58d843d578 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -260,4 +260,5 @@ const struct inode_operations reiserfs_file_inode_operations = {
 	.removexattr = reiserfs_removexattr,
 	.permission = reiserfs_permission,
 	.get_acl = reiserfs_get_acl,
+	.set_acl = reiserfs_set_acl,
 };

commit d5daaaff24026d59130e97a406f2999118bafdc3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Mar 19 19:46:45 2013 -0400

    reiserfs: don't wank with EFBIG before calling do_sync_write()
    
    look for file_capable() in there...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 6165bd4784f6..dcaafcfc23b0 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -234,68 +234,9 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 	return ret;
 }
 
-/* Write @count bytes at position @ppos in a file indicated by @file
-   from the buffer @buf.
-
-   generic_file_write() is only appropriate for filesystems that are not seeking to optimize performance and want
-   something simple that works.  It is not for serious use by general purpose filesystems, excepting the one that it was
-   written for (ext2/3).  This is for several reasons:
-
-   * It has no understanding of any filesystem specific optimizations.
-
-   * It enters the filesystem repeatedly for each page that is written.
-
-   * It depends on reiserfs_get_block() function which if implemented by reiserfs performs costly search_by_key
-   * operation for each page it is supplied with. By contrast reiserfs_file_write() feeds as much as possible at a time
-   * to reiserfs which allows for fewer tree traversals.
-
-   * Each indirect pointer insertion takes a lot of cpu, because it involves memory moves inside of blocks.
-
-   * Asking the block allocation code for blocks one at a time is slightly less efficient.
-
-   All of these reasons for not using only generic file write were understood back when reiserfs was first miscoded to
-   use it, but we were in a hurry to make code freeze, and so it couldn't be revised then.  This new code should make
-   things right finally.
-
-   Future Features: providing search_by_key with hints.
-
-*/
-static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going to write into */
-				   const char __user * buf,	/*  pointer to user supplied data
-								   (in userspace) */
-				   size_t count,	/* amount of bytes to write */
-				   loff_t * ppos	/* pointer to position in file that we start writing at. Should be updated to
-							 * new current position before returning. */
-				   )
-{
-	struct inode *inode = file_inode(file);	// Inode of the file that we are writing to.
-	/* To simplify coding at this time, we store
-	   locked pages in array for now */
-	struct reiserfs_transaction_handle th;
-	th.t_trans_id = 0;
-
-	/* If a filesystem is converted from 3.5 to 3.6, we'll have v3.5 items
-	* lying around (most of the disk, in fact). Despite the filesystem
-	* now being a v3.6 format, the old items still can't support large
-	* file sizes. Catch this case here, as the rest of the VFS layer is
-	* oblivious to the different limitations between old and new items.
-	* reiserfs_setattr catches this for truncates. This chunk is lifted
-	* from generic_write_checks. */
-	if (get_inode_item_key_version (inode) == KEY_FORMAT_3_5 &&
-	    *ppos + count > MAX_NON_LFS) {
-		if (*ppos >= MAX_NON_LFS) {
-			return -EFBIG;
-		}
-		if (count > MAX_NON_LFS - (unsigned long)*ppos)
-			count = MAX_NON_LFS - (unsigned long)*ppos;
-	}
-
-	return do_sync_write(file, buf, count, ppos);
-}
-
 const struct file_operations reiserfs_file_operations = {
 	.read = do_sync_read,
-	.write = reiserfs_file_write,
+	.write = do_sync_write,
 	.unlocked_ioctl = reiserfs_ioctl,
 #ifdef CONFIG_COMPAT
 	.compat_ioctl = reiserfs_compat_ioctl,

commit 496ad9aa8ef448058e36ca7a787c61f2e63f0f54
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jan 23 17:07:38 2013 -0500

    new helper: file_inode(file)
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 50302d6f8895..6165bd4784f6 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -268,7 +268,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 							 * new current position before returning. */
 				   )
 {
-	struct inode *inode = file->f_path.dentry->d_inode;	// Inode of the file that we are writing to.
+	struct inode *inode = file_inode(file);	// Inode of the file that we are writing to.
 	/* To simplify coding at this time, we store
 	   locked pages in array for now */
 	struct reiserfs_transaction_handle th;

commit cfac4b47c664e207740880d6492938761c53d74b
Author: Marco Stornelli <marco.stornelli@gmail.com>
Date:   Sat Dec 15 11:47:31 2012 +0100

    reiserfs: drop vmtruncate
    
    Removed vmtruncate
    
    Signed-off-by: Marco Stornelli <marco.stornelli@gmail.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 8375c922c0d5..50302d6f8895 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -126,7 +126,7 @@ static int reiserfs_file_open(struct inode *inode, struct file *file)
 	return err;
 }
 
-static void reiserfs_vfs_truncate_file(struct inode *inode)
+void reiserfs_vfs_truncate_file(struct inode *inode)
 {
 	mutex_lock(&(REISERFS_I(inode)->tailpack));
 	reiserfs_truncate_file(inode, 1);
@@ -312,7 +312,6 @@ const struct file_operations reiserfs_file_operations = {
 };
 
 const struct inode_operations reiserfs_file_inode_operations = {
-	.truncate = reiserfs_vfs_truncate_file,
 	.setattr = reiserfs_setattr,
 	.setxattr = reiserfs_setxattr,
 	.getxattr = reiserfs_getxattr,

commit f466c6fdb3b1f043ff1977a8d2a1d0cd4dc164fa
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 17 01:16:43 2012 -0400

    move private bits of reiserfs_fs.h to fs/reiserfs/reiserfs.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 3fa5915dea6e..8375c922c0d5 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -3,7 +3,7 @@
  */
 
 #include <linux/time.h>
-#include <linux/reiserfs_fs.h>
+#include "reiserfs.h"
 #include "acl.h"
 #include "xattr.h"
 #include <asm/uaccess.h>

commit a3063ab88fcbe5249f841cb95dfd626b8bf2674f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 17 01:03:10 2012 -0400

    move reiserfs_acl.h to fs/reiserfs/acl.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index e26ee4988e78..3fa5915dea6e 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -4,7 +4,7 @@
 
 #include <linux/time.h>
 #include <linux/reiserfs_fs.h>
-#include <linux/reiserfs_acl.h>
+#include "acl.h"
 #include "xattr.h"
 #include <asm/uaccess.h>
 #include <linux/pagemap.h>

commit c45ac8887e778c4fa2b572c51a94a681a0955d4d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 17 00:59:06 2012 -0400

    take private bits of reiserfs_xattr.h to fs/reiserfs/xattr.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index ace635053a36..e26ee4988e78 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -5,7 +5,7 @@
 #include <linux/time.h>
 #include <linux/reiserfs_fs.h>
 #include <linux/reiserfs_acl.h>
-#include <linux/reiserfs_xattr.h>
+#include "xattr.h"
 #include <asm/uaccess.h>
 #include <linux/pagemap.h>
 #include <linux/swap.h>

commit 4e34e719e457f2e031297175410fc0bd4016a085
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jul 23 17:37:31 2011 +0200

    fs: take the ACL checks to common code
    
    Replace the ->check_acl method with a ->get_acl method that simply reads an
    ACL from disk after having a cache miss.  This means we can replace the ACL
    checking boilerplate code with a single implementation in namei.c.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index c7156dc39ce7..ace635053a36 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -319,5 +319,5 @@ const struct inode_operations reiserfs_file_inode_operations = {
 	.listxattr = reiserfs_listxattr,
 	.removexattr = reiserfs_removexattr,
 	.permission = reiserfs_permission,
-	.check_acl = reiserfs_check_acl,
+	.get_acl = reiserfs_get_acl,
 };

commit 02c24a82187d5a628c68edfe71ae60dc135cd178
Author: Josef Bacik <josef@redhat.com>
Date:   Sat Jul 16 20:44:56 2011 -0400

    fs: push i_mutex and filemap_write_and_wait down into ->fsync() handlers
    
    Btrfs needs to be able to control how filemap_write_and_wait_range() is called
    in fsync to make it less of a painful operation, so push down taking i_mutex and
    the calling of filemap_write_and_wait() down into the ->fsync() handlers.  Some
    file systems can drop taking the i_mutex altogether it seems, like ext3 and
    ocfs2.  For correctness sake I just pushed everything down in all cases to make
    sure that we keep the current behavior the same for everybody, and then each
    individual fs maintainer can make up their mind about what to do from there.
    Thanks,
    
    Acked-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index bbf31003d308..c7156dc39ce7 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -140,12 +140,18 @@ static void reiserfs_vfs_truncate_file(struct inode *inode)
  * be removed...
  */
 
-static int reiserfs_sync_file(struct file *filp, int datasync)
+static int reiserfs_sync_file(struct file *filp, loff_t start, loff_t end,
+			      int datasync)
 {
 	struct inode *inode = filp->f_mapping->host;
 	int err;
 	int barrier_done;
 
+	err = filemap_write_and_wait_range(inode->i_mapping, start, end);
+	if (err)
+		return err;
+
+	mutex_lock(&inode->i_mutex);
 	BUG_ON(!S_ISREG(inode->i_mode));
 	err = sync_mapping_buffers(inode->i_mapping);
 	reiserfs_write_lock(inode->i_sb);
@@ -153,6 +159,7 @@ static int reiserfs_sync_file(struct file *filp, int datasync)
 	reiserfs_write_unlock(inode->i_sb);
 	if (barrier_done != 1 && reiserfs_barrier_flush(inode->i_sb))
 		blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);
+	mutex_unlock(&inode->i_mutex);
 	if (barrier_done < 0)
 		return barrier_done;
 	return (err < 0) ? -EIO : 0;

commit 178ea73521d64ba41d7aa5488fb9f549c6d4507d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jun 20 11:31:30 2011 -0400

    kill check_acl callback of generic_permission()
    
    its value depends only on inode and does not change; we might as
    well store it in ->i_op->check_acl and be done with that.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 91f080cc76c8..bbf31003d308 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -312,4 +312,5 @@ const struct inode_operations reiserfs_file_inode_operations = {
 	.listxattr = reiserfs_listxattr,
 	.removexattr = reiserfs_removexattr,
 	.permission = reiserfs_permission,
+	.check_acl = reiserfs_check_acl,
 };

commit dd3932eddf428571762596e17b65f5dc92ca361b
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Sep 16 20:51:46 2010 +0200

    block: remove BLKDEV_IFL_WAIT
    
    All the blkdev_issue_* helpers can only sanely be used for synchronous
    caller.  To issue cache flushes or barriers asynchronously the caller needs
    to set up a bio by itself with a completion callback to move the asynchronous
    state machine ahead.  So drop the BLKDEV_IFL_WAIT flag that is always
    specified when calling blkdev_issue_* and also remove the now unused flags
    argument to blkdev_issue_flush and blkdev_issue_zeroout.  For
    blkdev_issue_discard we need to keep it for the secure discard flag, which
    gains a more descriptive name and loses the bitops vs flag confusion.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 6846371498b6..91f080cc76c8 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -152,8 +152,7 @@ static int reiserfs_sync_file(struct file *filp, int datasync)
 	barrier_done = reiserfs_commit_for_inode(inode);
 	reiserfs_write_unlock(inode->i_sb);
 	if (barrier_done != 1 && reiserfs_barrier_flush(inode->i_sb))
-		blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL, 
-			BLKDEV_IFL_WAIT);
+		blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);
 	if (barrier_done < 0)
 		return barrier_done;
 	return (err < 0) ? -EIO : 0;

commit 0e4f6a791b1e8cfde75a74e2f885642ecb3fe9d8
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jul 4 12:18:57 2010 +0400

    Fix reiserfs_file_release()
    
    a) count file openers correctly; i_count use was completely wrong
    b) use new mutex for exclusion between final close/open/truncate,
    to protect tailpacking logics.  i_mutex use was wrong and resulted
    in deadlocks.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index b82cdd8a45dd..6846371498b6 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -38,20 +38,24 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 
 	BUG_ON(!S_ISREG(inode->i_mode));
 
+        if (atomic_add_unless(&REISERFS_I(inode)->openers, -1, 1))
+		return 0;
+
+	mutex_lock(&(REISERFS_I(inode)->tailpack));
+
+        if (!atomic_dec_and_test(&REISERFS_I(inode)->openers)) {
+		mutex_unlock(&(REISERFS_I(inode)->tailpack));
+		return 0;
+	}
+
 	/* fast out for when nothing needs to be done */
-	if ((atomic_read(&inode->i_count) > 1 ||
-	     !(REISERFS_I(inode)->i_flags & i_pack_on_close_mask) ||
+	if ((!(REISERFS_I(inode)->i_flags & i_pack_on_close_mask) ||
 	     !tail_has_to_be_packed(inode)) &&
 	    REISERFS_I(inode)->i_prealloc_count <= 0) {
+		mutex_unlock(&(REISERFS_I(inode)->tailpack));
 		return 0;
 	}
 
-	mutex_lock(&inode->i_mutex);
-
-	mutex_lock(&(REISERFS_I(inode)->i_mmap));
-	if (REISERFS_I(inode)->i_flags & i_ever_mapped)
-		REISERFS_I(inode)->i_flags &= ~i_pack_on_close_mask;
-
 	reiserfs_write_lock(inode->i_sb);
 	/* freeing preallocation only involves relogging blocks that
 	 * are already in the current transaction.  preallocation gets
@@ -94,9 +98,10 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 	if (!err)
 		err = jbegin_failure;
 
-	if (!err && atomic_read(&inode->i_count) <= 1 &&
+	if (!err &&
 	    (REISERFS_I(inode)->i_flags & i_pack_on_close_mask) &&
 	    tail_has_to_be_packed(inode)) {
+
 		/* if regular file is released by last holder and it has been
 		   appended (we append by unformatted node only) or its direct
 		   item(s) had to be converted, then it may have to be
@@ -104,27 +109,28 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 		err = reiserfs_truncate_file(inode, 0);
 	}
       out:
-	mutex_unlock(&(REISERFS_I(inode)->i_mmap));
-	mutex_unlock(&inode->i_mutex);
 	reiserfs_write_unlock(inode->i_sb);
+	mutex_unlock(&(REISERFS_I(inode)->tailpack));
 	return err;
 }
 
-static int reiserfs_file_mmap(struct file *file, struct vm_area_struct *vma)
+static int reiserfs_file_open(struct inode *inode, struct file *file)
 {
-	struct inode *inode;
-
-	inode = file->f_path.dentry->d_inode;
-	mutex_lock(&(REISERFS_I(inode)->i_mmap));
-	REISERFS_I(inode)->i_flags |= i_ever_mapped;
-	mutex_unlock(&(REISERFS_I(inode)->i_mmap));
-
-	return generic_file_mmap(file, vma);
+	int err = dquot_file_open(inode, file);
+        if (!atomic_inc_not_zero(&REISERFS_I(inode)->openers)) {
+		/* somebody might be tailpacking on final close; wait for it */
+		mutex_lock(&(REISERFS_I(inode)->tailpack));
+		atomic_inc(&REISERFS_I(inode)->openers);
+		mutex_unlock(&(REISERFS_I(inode)->tailpack));
+	}
+	return err;
 }
 
 static void reiserfs_vfs_truncate_file(struct inode *inode)
 {
+	mutex_lock(&(REISERFS_I(inode)->tailpack));
 	reiserfs_truncate_file(inode, 1);
+	mutex_unlock(&(REISERFS_I(inode)->tailpack));
 }
 
 /* Sync a reiserfs file. */
@@ -288,8 +294,8 @@ const struct file_operations reiserfs_file_operations = {
 #ifdef CONFIG_COMPAT
 	.compat_ioctl = reiserfs_compat_ioctl,
 #endif
-	.mmap = reiserfs_file_mmap,
-	.open = dquot_file_open,
+	.mmap = generic_file_mmap,
+	.open = reiserfs_file_open,
 	.release = reiserfs_file_release,
 	.fsync = reiserfs_sync_file,
 	.aio_read = generic_file_aio_read,

commit 7ea8085910ef3dd4f3cad6845aaa2b580d39b115
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 26 17:53:25 2010 +0200

    drop unused dentry argument to ->fsync
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 9977df9f3a54..b82cdd8a45dd 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -134,10 +134,9 @@ static void reiserfs_vfs_truncate_file(struct inode *inode)
  * be removed...
  */
 
-static int reiserfs_sync_file(struct file *filp,
-			      struct dentry *dentry, int datasync)
+static int reiserfs_sync_file(struct file *filp, int datasync)
 {
-	struct inode *inode = dentry->d_inode;
+	struct inode *inode = filp->f_mapping->host;
 	int err;
 	int barrier_done;
 

commit fbd9b09a177a481eda256447c881f014f29034fe
Author: Dmitry Monakhov <dmonakhov@openvz.org>
Date:   Wed Apr 28 17:55:06 2010 +0400

    blkdev: generalize flags for blkdev_issue_fn functions
    
    The patch just convert all blkdev_issue_xxx function to common
    set of flags. Wait/allocation semantics preserved.
    
    Signed-off-by: Dmitry Monakhov <dmonakhov@openvz.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 1d9c12714c5c..9977df9f3a54 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -147,7 +147,8 @@ static int reiserfs_sync_file(struct file *filp,
 	barrier_done = reiserfs_commit_for_inode(inode);
 	reiserfs_write_unlock(inode->i_sb);
 	if (barrier_done != 1 && reiserfs_barrier_flush(inode->i_sb))
-		blkdev_issue_flush(inode->i_sb->s_bdev, NULL);
+		blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL, 
+			BLKDEV_IFL_WAIT);
 	if (barrier_done < 0)
 		return barrier_done;
 	return (err < 0) ? -EIO : 0;

commit 907f4554e2521cb28b0009d17167760650a9561c
Author: Christoph Hellwig <hch@infradead.org>
Date:   Wed Mar 3 09:05:06 2010 -0500

    dquot: move dquot initialization responsibility into the filesystem
    
    Currently various places in the VFS call vfs_dq_init directly.  This means
    we tie the quota code into the VFS.  Get rid of that and make the
    filesystem responsible for the initialization.   For most metadata operations
    this is a straight forward move into the methods, but for truncate and
    open it's a bit more complicated.
    
    For truncate we currently only call vfs_dq_init for the sys_truncate case
    because open already takes care of it for ftruncate and open(O_TRUNC) - the
    new code causes an additional vfs_dq_init for those which is harmless.
    
    For open the initialization is moved from do_filp_open into the open method,
    which means it happens slightly earlier now, and only for regular files.
    The latter is fine because we don't need to initialize it for operations
    on special files, and we already do it as part of the namespace operations
    for directories.
    
    Add a dquot_file_open helper that filesystems that support generic quotas
    can use to fill in ->open.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index da2dba082e2d..1d9c12714c5c 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -289,7 +289,7 @@ const struct file_operations reiserfs_file_operations = {
 	.compat_ioctl = reiserfs_compat_ioctl,
 #endif
 	.mmap = reiserfs_file_mmap,
-	.open = generic_file_open,
+	.open = dquot_file_open,
 	.release = reiserfs_file_release,
 	.fsync = reiserfs_sync_file,
 	.aio_read = generic_file_aio_read,

commit 205cb37b89ab37db553907e5ac17962eec561804
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Oct 14 23:22:17 2009 +0200

    kill-the-bkl/reiserfs: definitely drop the bkl from reiserfs_ioctl()
    
    The reiserfs ioctl path doesn't need the big kernel lock anymore , now
    that the filesystem synchronizes through its own lock.
    
    We can then turn reiserfs_ioctl() into an unlocked_ioctl callback.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Alexander Beregalov <a.beregalov@gmail.com>
    Cc: Laurent Riffard <laurent.riffard@free.fr>
    Cc: Thomas Gleixner <tglx@linutronix.de>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 9f436668b7f8..da2dba082e2d 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -284,7 +284,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 const struct file_operations reiserfs_file_operations = {
 	.read = do_sync_read,
 	.write = reiserfs_file_write,
-	.ioctl = reiserfs_ioctl,
+	.unlocked_ioctl = reiserfs_ioctl,
 #ifdef CONFIG_COMPAT
 	.compat_ioctl = reiserfs_compat_ioctl,
 #endif

commit ee93961be1faddf9e9a638bc519145c20f0cfeba
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:50 2009 -0400

    reiserfs: rename [cn]_* variables
    
    This patch renames n_, c_, etc variables to something more sane.  This
    is the sixth in a series of patches to rip out some of the awful
    variable naming in reiserfs.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index cde16429ff00..9f436668b7f8 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -138,11 +138,11 @@ static int reiserfs_sync_file(struct file *filp,
 			      struct dentry *dentry, int datasync)
 {
 	struct inode *inode = dentry->d_inode;
-	int n_err;
+	int err;
 	int barrier_done;
 
 	BUG_ON(!S_ISREG(inode->i_mode));
-	n_err = sync_mapping_buffers(inode->i_mapping);
+	err = sync_mapping_buffers(inode->i_mapping);
 	reiserfs_write_lock(inode->i_sb);
 	barrier_done = reiserfs_commit_for_inode(inode);
 	reiserfs_write_unlock(inode->i_sb);
@@ -150,7 +150,7 @@ static int reiserfs_sync_file(struct file *filp,
 		blkdev_issue_flush(inode->i_sb->s_bdev, NULL);
 	if (barrier_done < 0)
 		return barrier_done;
-	return (n_err < 0) ? -EIO : 0;
+	return (err < 0) ? -EIO : 0;
 }
 
 /* taken fs/buffer.c:__block_commit_write */

commit d68caa9530a8ba54f97002e02bf6a0ad2462b8c0
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:49 2009 -0400

    reiserfs: rename p_._ variables
    
    This patch is a simple s/p_._//g to the reiserfs code.  This is the
    fifth in a series of patches to rip out some of the awful variable
    naming in reiserfs.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index a73579f66214..cde16429ff00 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -134,10 +134,10 @@ static void reiserfs_vfs_truncate_file(struct inode *inode)
  * be removed...
  */
 
-static int reiserfs_sync_file(struct file *p_s_filp,
-			      struct dentry *p_s_dentry, int datasync)
+static int reiserfs_sync_file(struct file *filp,
+			      struct dentry *dentry, int datasync)
 {
-	struct inode *inode = p_s_dentry->d_inode;
+	struct inode *inode = dentry->d_inode;
 	int n_err;
 	int barrier_done;
 

commit 995c762ea486b48c9777522071fbf132dea96807
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:47 2009 -0400

    reiserfs: rename p_s_inode to inode
    
    This patch is a simple s/p_s_inode/inode/g to the reiserfs code.  This
    is the third in a series of patches to rip out some of the awful
    variable naming in reiserfs.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index f0160ee03e17..a73579f66214 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -137,17 +137,17 @@ static void reiserfs_vfs_truncate_file(struct inode *inode)
 static int reiserfs_sync_file(struct file *p_s_filp,
 			      struct dentry *p_s_dentry, int datasync)
 {
-	struct inode *p_s_inode = p_s_dentry->d_inode;
+	struct inode *inode = p_s_dentry->d_inode;
 	int n_err;
 	int barrier_done;
 
-	BUG_ON(!S_ISREG(p_s_inode->i_mode));
-	n_err = sync_mapping_buffers(p_s_inode->i_mapping);
-	reiserfs_write_lock(p_s_inode->i_sb);
-	barrier_done = reiserfs_commit_for_inode(p_s_inode);
-	reiserfs_write_unlock(p_s_inode->i_sb);
-	if (barrier_done != 1 && reiserfs_barrier_flush(p_s_inode->i_sb))
-		blkdev_issue_flush(p_s_inode->i_sb->s_bdev, NULL);
+	BUG_ON(!S_ISREG(inode->i_mode));
+	n_err = sync_mapping_buffers(inode->i_mapping);
+	reiserfs_write_lock(inode->i_sb);
+	barrier_done = reiserfs_commit_for_inode(inode);
+	reiserfs_write_unlock(inode->i_sb);
+	if (barrier_done != 1 && reiserfs_barrier_flush(inode->i_sb))
+		blkdev_issue_flush(inode->i_sb->s_bdev, NULL);
 	if (barrier_done < 0)
 		return barrier_done;
 	return (n_err < 0) ? -EIO : 0;

commit 0222e6571c332563a48d4cf5487b67feabe60b5e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:44 2009 -0400

    reiserfs: strip trailing whitespace
    
    This patch strips trailing whitespace from the reiserfs code.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 47bab8978be1..f0160ee03e17 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -20,14 +20,14 @@
 ** insertion/balancing, for files that are written in one write.
 ** It avoids unnecessary tail packings (balances) for files that are written in
 ** multiple writes and are small enough to have tails.
-** 
+**
 ** file_release is called by the VFS layer when the file is closed.  If
 ** this is the last open file descriptor, and the file
 ** small enough to have a tail, and the tail is currently in an
 ** unformatted node, the tail is converted back into a direct item.
-** 
+**
 ** We use reiserfs_truncate_file to pack the tail, since it already has
-** all the conditions coded.  
+** all the conditions coded.
 */
 static int reiserfs_file_release(struct inode *inode, struct file *filp)
 {
@@ -223,7 +223,7 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 }
 
 /* Write @count bytes at position @ppos in a file indicated by @file
-   from the buffer @buf.  
+   from the buffer @buf.
 
    generic_file_write() is only appropriate for filesystems that are not seeking to optimize performance and want
    something simple that works.  It is not for serious use by general purpose filesystems, excepting the one that it was

commit 45b03d5e8e674eb6555b767e1c8eb40b671ff892
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:21 2009 -0400

    reiserfs: rework reiserfs_warning
    
    ReiserFS warnings can be somewhat inconsistent.
    In some cases:
     * a unique identifier may be associated with it
     * the function name may be included
     * the device may be printed separately
    
    This patch aims to make warnings more consistent. reiserfs_warning() prints
    the device name, so printing it a second time is not required. The function
    name for a warning is always helpful in debugging, so it is now automatically
    inserted into the output. Hans has stated that every warning should have
    a unique identifier. Some cases lack them, others really shouldn't have them.
    reiserfs_warning() now expects an id associated with each message. In the
    rare case where one isn't needed, "" will suffice.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 33408417038c..47bab8978be1 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -76,7 +76,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 			 * and let the admin know what is going on.
 			 */
 			igrab(inode);
-			reiserfs_warning(inode->i_sb,
+			reiserfs_warning(inode->i_sb, "clm-9001",
 					 "pinning inode %lu because the "
 					 "preallocation can't be freed",
 					 inode->i_ino);

commit 91efc167d02509ea78abeff6d668065964c67c0b
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Sep 8 19:42:50 2008 +0200

    [PATCH] reiserfs: add missing llseek method
    
    Reiserfs currently doesn't set a llseek method for regular files, which
    means it will fall back to default_llseek.  This means no one can seek
    beyond 2 Gigabytes on reiserfs, and that there's not protection vs
    the i_size updates from writers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index a804903d31d1..33408417038c 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -296,6 +296,7 @@ const struct file_operations reiserfs_file_operations = {
 	.aio_write = generic_file_aio_write,
 	.splice_read = generic_file_splice_read,
 	.splice_write = generic_file_splice_write,
+	.llseek = generic_file_llseek,
 };
 
 const struct inode_operations reiserfs_file_inode_operations = {

commit 797b4cffdf79b9ed66759b8d2d5252eba965fb18
Author: Vladimir Saveliev <vs@namesys.com>
Date:   Tue Oct 16 01:25:12 2007 -0700

    reiserfs: use generic write
    
    Make reiserfs to write via generic routines.
    Original reiserfs write optimized for big writes is deadlock rone
    
    Signed-off-by: Vladimir Saveliev <vs@namesys.com>
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 2070aeee2a52..a804903d31d1 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -153,608 +153,6 @@ static int reiserfs_sync_file(struct file *p_s_filp,
 	return (n_err < 0) ? -EIO : 0;
 }
 
-/* I really do not want to play with memory shortage right now, so
-   to simplify the code, we are not going to write more than this much pages at
-   a time. This still should considerably improve performance compared to 4k
-   at a time case. This is 32 pages of 4k size. */
-#define REISERFS_WRITE_PAGES_AT_A_TIME (128 * 1024) / PAGE_CACHE_SIZE
-
-/* Allocates blocks for a file to fulfil write request.
-   Maps all unmapped but prepared pages from the list.
-   Updates metadata with newly allocated blocknumbers as needed */
-static int reiserfs_allocate_blocks_for_region(struct reiserfs_transaction_handle *th, struct inode *inode,	/* Inode we work with */
-					       loff_t pos,	/* Writing position */
-					       int num_pages,	/* number of pages write going
-								   to touch */
-					       int write_bytes,	/* amount of bytes to write */
-					       struct page **prepared_pages,	/* array of
-										   prepared pages
-										 */
-					       int blocks_to_allocate	/* Amount of blocks we
-									   need to allocate to
-									   fit the data into file
-									 */
-    )
-{
-	struct cpu_key key;	// cpu key of item that we are going to deal with
-	struct item_head *ih;	// pointer to item head that we are going to deal with
-	struct buffer_head *bh;	// Buffer head that contains items that we are going to deal with
-	__le32 *item;		// pointer to item we are going to deal with
-	INITIALIZE_PATH(path);	// path to item, that we are going to deal with.
-	b_blocknr_t *allocated_blocks;	// Pointer to a place where allocated blocknumbers would be stored.
-	reiserfs_blocknr_hint_t hint;	// hint structure for block allocator.
-	size_t res;		// return value of various functions that we call.
-	int curr_block;		// current block used to keep track of unmapped blocks.
-	int i;			// loop counter
-	int itempos;		// position in item
-	unsigned int from = (pos & (PAGE_CACHE_SIZE - 1));	// writing position in
-	// first page
-	unsigned int to = ((pos + write_bytes - 1) & (PAGE_CACHE_SIZE - 1)) + 1;	/* last modified byte offset in last page */
-	__u64 hole_size;	// amount of blocks for a file hole, if it needed to be created.
-	int modifying_this_item = 0;	// Flag for items traversal code to keep track
-	// of the fact that we already prepared
-	// current block for journal
-	int will_prealloc = 0;
-	RFALSE(!blocks_to_allocate,
-	       "green-9004: tried to allocate zero blocks?");
-
-	/* only preallocate if this is a small write */
-	if (REISERFS_I(inode)->i_prealloc_count ||
-	    (!(write_bytes & (inode->i_sb->s_blocksize - 1)) &&
-	     blocks_to_allocate <
-	     REISERFS_SB(inode->i_sb)->s_alloc_options.preallocsize))
-		will_prealloc =
-		    REISERFS_SB(inode->i_sb)->s_alloc_options.preallocsize;
-
-	allocated_blocks = kmalloc((blocks_to_allocate + will_prealloc) *
-				   sizeof(b_blocknr_t), GFP_NOFS);
-	if (!allocated_blocks)
-		return -ENOMEM;
-
-	/* First we compose a key to point at the writing position, we want to do
-	   that outside of any locking region. */
-	make_cpu_key(&key, inode, pos + 1, TYPE_ANY, 3 /*key length */ );
-
-	/* If we came here, it means we absolutely need to open a transaction,
-	   since we need to allocate some blocks */
-	reiserfs_write_lock(inode->i_sb);	// Journaling stuff and we need that.
-	res = journal_begin(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS(inode->i_sb));	// Wish I know if this number enough
-	if (res)
-		goto error_exit;
-	reiserfs_update_inode_transaction(inode);
-
-	/* Look for the in-tree position of our write, need path for block allocator */
-	res = search_for_position_by_key(inode->i_sb, &key, &path);
-	if (res == IO_ERROR) {
-		res = -EIO;
-		goto error_exit;
-	}
-
-	/* Allocate blocks */
-	/* First fill in "hint" structure for block allocator */
-	hint.th = th;		// transaction handle.
-	hint.path = &path;	// Path, so that block allocator can determine packing locality or whatever it needs to determine.
-	hint.inode = inode;	// Inode is needed by block allocator too.
-	hint.search_start = 0;	// We have no hint on where to search free blocks for block allocator.
-	hint.key = key.on_disk_key;	// on disk key of file.
-	hint.block = inode->i_blocks >> (inode->i_sb->s_blocksize_bits - 9);	// Number of disk blocks this file occupies already.
-	hint.formatted_node = 0;	// We are allocating blocks for unformatted node.
-	hint.preallocate = will_prealloc;
-
-	/* Call block allocator to allocate blocks */
-	res =
-	    reiserfs_allocate_blocknrs(&hint, allocated_blocks,
-				       blocks_to_allocate, blocks_to_allocate);
-	if (res != CARRY_ON) {
-		if (res == NO_DISK_SPACE) {
-			/* We flush the transaction in case of no space. This way some
-			   blocks might become free */
-			SB_JOURNAL(inode->i_sb)->j_must_wait = 1;
-			res = restart_transaction(th, inode, &path);
-			if (res)
-				goto error_exit;
-
-			/* We might have scheduled, so search again */
-			res =
-			    search_for_position_by_key(inode->i_sb, &key,
-						       &path);
-			if (res == IO_ERROR) {
-				res = -EIO;
-				goto error_exit;
-			}
-
-			/* update changed info for hint structure. */
-			res =
-			    reiserfs_allocate_blocknrs(&hint, allocated_blocks,
-						       blocks_to_allocate,
-						       blocks_to_allocate);
-			if (res != CARRY_ON) {
-				res = res == QUOTA_EXCEEDED ? -EDQUOT : -ENOSPC;
-				pathrelse(&path);
-				goto error_exit;
-			}
-		} else {
-			res = res == QUOTA_EXCEEDED ? -EDQUOT : -ENOSPC;
-			pathrelse(&path);
-			goto error_exit;
-		}
-	}
-#ifdef __BIG_ENDIAN
-	// Too bad, I have not found any way to convert a given region from
-	// cpu format to little endian format
-	{
-		int i;
-		for (i = 0; i < blocks_to_allocate; i++)
-			allocated_blocks[i] = cpu_to_le32(allocated_blocks[i]);
-	}
-#endif
-
-	/* Blocks allocating well might have scheduled and tree might have changed,
-	   let's search the tree again */
-	/* find where in the tree our write should go */
-	res = search_for_position_by_key(inode->i_sb, &key, &path);
-	if (res == IO_ERROR) {
-		res = -EIO;
-		goto error_exit_free_blocks;
-	}
-
-	bh = get_last_bh(&path);	// Get a bufferhead for last element in path.
-	ih = get_ih(&path);	// Get a pointer to last item head in path.
-	item = get_item(&path);	// Get a pointer to last item in path
-
-	/* Let's see what we have found */
-	if (res != POSITION_FOUND) {	/* position not found, this means that we
-					   might need to append file with holes
-					   first */
-		// Since we are writing past the file's end, we need to find out if
-		// there is a hole that needs to be inserted before our writing
-		// position, and how many blocks it is going to cover (we need to
-		//  populate pointers to file blocks representing the hole with zeros)
-
-		{
-			int item_offset = 1;
-			/*
-			 * if ih is stat data, its offset is 0 and we don't want to
-			 * add 1 to pos in the hole_size calculation
-			 */
-			if (is_statdata_le_ih(ih))
-				item_offset = 0;
-			hole_size = (pos + item_offset -
-				     (le_key_k_offset
-				      (get_inode_item_key_version(inode),
-				       &(ih->ih_key)) + op_bytes_number(ih,
-									inode->
-									i_sb->
-									s_blocksize)))
-			    >> inode->i_sb->s_blocksize_bits;
-		}
-
-		if (hole_size > 0) {
-			int to_paste = min_t(__u64, hole_size, MAX_ITEM_LEN(inode->i_sb->s_blocksize) / UNFM_P_SIZE);	// How much data to insert first time.
-			/* area filled with zeroes, to supply as list of zero blocknumbers
-			   We allocate it outside of loop just in case loop would spin for
-			   several iterations. */
-			char *zeros = kzalloc(to_paste * UNFM_P_SIZE, GFP_ATOMIC);	// We cannot insert more than MAX_ITEM_LEN bytes anyway.
-			if (!zeros) {
-				res = -ENOMEM;
-				goto error_exit_free_blocks;
-			}
-			do {
-				to_paste =
-				    min_t(__u64, hole_size,
-					  MAX_ITEM_LEN(inode->i_sb->
-						       s_blocksize) /
-					  UNFM_P_SIZE);
-				if (is_indirect_le_ih(ih)) {
-					/* Ok, there is existing indirect item already. Need to append it */
-					/* Calculate position past inserted item */
-					make_cpu_key(&key, inode,
-						     le_key_k_offset
-						     (get_inode_item_key_version
-						      (inode),
-						      &(ih->ih_key)) +
-						     op_bytes_number(ih,
-								     inode->
-								     i_sb->
-								     s_blocksize),
-						     TYPE_INDIRECT, 3);
-					res =
-					    reiserfs_paste_into_item(th, &path,
-								     &key,
-								     inode,
-								     (char *)
-								     zeros,
-								     UNFM_P_SIZE
-								     *
-								     to_paste);
-					if (res) {
-						kfree(zeros);
-						goto error_exit_free_blocks;
-					}
-				} else if (is_statdata_le_ih(ih)) {
-					/* No existing item, create it */
-					/* item head for new item */
-					struct item_head ins_ih;
-
-					/* create a key for our new item */
-					make_cpu_key(&key, inode, 1,
-						     TYPE_INDIRECT, 3);
-
-					/* Create new item head for our new item */
-					make_le_item_head(&ins_ih, &key,
-							  key.version, 1,
-							  TYPE_INDIRECT,
-							  to_paste *
-							  UNFM_P_SIZE,
-							  0 /* free space */ );
-
-					/* Find where such item should live in the tree */
-					res =
-					    search_item(inode->i_sb, &key,
-							&path);
-					if (res != ITEM_NOT_FOUND) {
-						/* item should not exist, otherwise we have error */
-						if (res != -ENOSPC) {
-							reiserfs_warning(inode->
-									 i_sb,
-									 "green-9008: search_by_key (%K) returned %d",
-									 &key,
-									 res);
-						}
-						res = -EIO;
-						kfree(zeros);
-						goto error_exit_free_blocks;
-					}
-					res =
-					    reiserfs_insert_item(th, &path,
-								 &key, &ins_ih,
-								 inode,
-								 (char *)zeros);
-				} else {
-					reiserfs_panic(inode->i_sb,
-						       "green-9011: Unexpected key type %K\n",
-						       &key);
-				}
-				if (res) {
-					kfree(zeros);
-					goto error_exit_free_blocks;
-				}
-				/* Now we want to check if transaction is too full, and if it is
-				   we restart it. This will also free the path. */
-				if (journal_transaction_should_end
-				    (th, th->t_blocks_allocated)) {
-					inode->i_size = cpu_key_k_offset(&key) +
-						(to_paste << inode->i_blkbits);
-					res =
-					    restart_transaction(th, inode,
-								&path);
-					if (res) {
-						pathrelse(&path);
-						kfree(zeros);
-						goto error_exit;
-					}
-				}
-
-				/* Well, need to recalculate path and stuff */
-				set_cpu_key_k_offset(&key,
-						     cpu_key_k_offset(&key) +
-						     (to_paste << inode->
-						      i_blkbits));
-				res =
-				    search_for_position_by_key(inode->i_sb,
-							       &key, &path);
-				if (res == IO_ERROR) {
-					res = -EIO;
-					kfree(zeros);
-					goto error_exit_free_blocks;
-				}
-				bh = get_last_bh(&path);
-				ih = get_ih(&path);
-				item = get_item(&path);
-				hole_size -= to_paste;
-			} while (hole_size);
-			kfree(zeros);
-		}
-	}
-	// Go through existing indirect items first
-	// replace all zeroes with blocknumbers from list
-	// Note that if no corresponding item was found, by previous search,
-	// it means there are no existing in-tree representation for file area
-	// we are going to overwrite, so there is nothing to scan through for holes.
-	for (curr_block = 0, itempos = path.pos_in_item;
-	     curr_block < blocks_to_allocate && res == POSITION_FOUND;) {
-	      retry:
-
-		if (itempos >= ih_item_len(ih) / UNFM_P_SIZE) {
-			/* We run out of data in this indirect item, let's look for another
-			   one. */
-			/* First if we are already modifying current item, log it */
-			if (modifying_this_item) {
-				journal_mark_dirty(th, inode->i_sb, bh);
-				modifying_this_item = 0;
-			}
-			/* Then set the key to look for a new indirect item (offset of old
-			   item is added to old item length */
-			set_cpu_key_k_offset(&key,
-					     le_key_k_offset
-					     (get_inode_item_key_version(inode),
-					      &(ih->ih_key)) +
-					     op_bytes_number(ih,
-							     inode->i_sb->
-							     s_blocksize));
-			/* Search ofor position of new key in the tree. */
-			res =
-			    search_for_position_by_key(inode->i_sb, &key,
-						       &path);
-			if (res == IO_ERROR) {
-				res = -EIO;
-				goto error_exit_free_blocks;
-			}
-			bh = get_last_bh(&path);
-			ih = get_ih(&path);
-			item = get_item(&path);
-			itempos = path.pos_in_item;
-			continue;	// loop to check all kinds of conditions and so on.
-		}
-		/* Ok, we have correct position in item now, so let's see if it is
-		   representing file hole (blocknumber is zero) and fill it if needed */
-		if (!item[itempos]) {
-			/* Ok, a hole. Now we need to check if we already prepared this
-			   block to be journaled */
-			while (!modifying_this_item) {	// loop until succeed
-				/* Well, this item is not journaled yet, so we must prepare
-				   it for journal first, before we can change it */
-				struct item_head tmp_ih;	// We copy item head of found item,
-				// here to detect if fs changed under
-				// us while we were preparing for
-				// journal.
-				int fs_gen;	// We store fs generation here to find if someone
-				// changes fs under our feet
-
-				copy_item_head(&tmp_ih, ih);	// Remember itemhead
-				fs_gen = get_generation(inode->i_sb);	// remember fs generation
-				reiserfs_prepare_for_journal(inode->i_sb, bh, 1);	// Prepare a buffer within which indirect item is stored for changing.
-				if (fs_changed(fs_gen, inode->i_sb)
-				    && item_moved(&tmp_ih, &path)) {
-					// Sigh, fs was changed under us, we need to look for new
-					// location of item we are working with
-
-					/* unmark prepaerd area as journaled and search for it's
-					   new position */
-					reiserfs_restore_prepared_buffer(inode->
-									 i_sb,
-									 bh);
-					res =
-					    search_for_position_by_key(inode->
-								       i_sb,
-								       &key,
-								       &path);
-					if (res == IO_ERROR) {
-						res = -EIO;
-						goto error_exit_free_blocks;
-					}
-					bh = get_last_bh(&path);
-					ih = get_ih(&path);
-					item = get_item(&path);
-					itempos = path.pos_in_item;
-					goto retry;
-				}
-				modifying_this_item = 1;
-			}
-			item[itempos] = allocated_blocks[curr_block];	// Assign new block
-			curr_block++;
-		}
-		itempos++;
-	}
-
-	if (modifying_this_item) {	// We need to log last-accessed block, if it
-		// was modified, but not logged yet.
-		journal_mark_dirty(th, inode->i_sb, bh);
-	}
-
-	if (curr_block < blocks_to_allocate) {
-		// Oh, well need to append to indirect item, or to create indirect item
-		// if there weren't any
-		if (is_indirect_le_ih(ih)) {
-			// Existing indirect item - append. First calculate key for append
-			// position. We do not need to recalculate path as it should
-			// already point to correct place.
-			make_cpu_key(&key, inode,
-				     le_key_k_offset(get_inode_item_key_version
-						     (inode),
-						     &(ih->ih_key)) +
-				     op_bytes_number(ih,
-						     inode->i_sb->s_blocksize),
-				     TYPE_INDIRECT, 3);
-			res =
-			    reiserfs_paste_into_item(th, &path, &key, inode,
-						     (char *)(allocated_blocks +
-							      curr_block),
-						     UNFM_P_SIZE *
-						     (blocks_to_allocate -
-						      curr_block));
-			if (res) {
-				goto error_exit_free_blocks;
-			}
-		} else if (is_statdata_le_ih(ih)) {
-			// Last found item was statdata. That means we need to create indirect item.
-			struct item_head ins_ih;	/* itemhead for new item */
-
-			/* create a key for our new item */
-			make_cpu_key(&key, inode, 1, TYPE_INDIRECT, 3);	// Position one,
-			// because that's
-			// where first
-			// indirect item
-			// begins
-			/* Create new item head for our new item */
-			make_le_item_head(&ins_ih, &key, key.version, 1,
-					  TYPE_INDIRECT,
-					  (blocks_to_allocate -
-					   curr_block) * UNFM_P_SIZE,
-					  0 /* free space */ );
-			/* Find where such item should live in the tree */
-			res = search_item(inode->i_sb, &key, &path);
-			if (res != ITEM_NOT_FOUND) {
-				/* Well, if we have found such item already, or some error
-				   occured, we need to warn user and return error */
-				if (res != -ENOSPC) {
-					reiserfs_warning(inode->i_sb,
-							 "green-9009: search_by_key (%K) "
-							 "returned %d", &key,
-							 res);
-				}
-				res = -EIO;
-				goto error_exit_free_blocks;
-			}
-			/* Insert item into the tree with the data as its body */
-			res =
-			    reiserfs_insert_item(th, &path, &key, &ins_ih,
-						 inode,
-						 (char *)(allocated_blocks +
-							  curr_block));
-		} else {
-			reiserfs_panic(inode->i_sb,
-				       "green-9010: unexpected item type for key %K\n",
-				       &key);
-		}
-	}
-	// the caller is responsible for closing the transaction
-	// unless we return an error, they are also responsible for logging
-	// the inode.
-	//
-	pathrelse(&path);
-	/*
-	 * cleanup prellocation from previous writes
-	 * if this is a partial block write
-	 */
-	if (write_bytes & (inode->i_sb->s_blocksize - 1))
-		reiserfs_discard_prealloc(th, inode);
-	reiserfs_write_unlock(inode->i_sb);
-
-	// go through all the pages/buffers and map the buffers to newly allocated
-	// blocks (so that system knows where to write these pages later).
-	curr_block = 0;
-	for (i = 0; i < num_pages; i++) {
-		struct page *page = prepared_pages[i];	//current page
-		struct buffer_head *head = page_buffers(page);	// first buffer for a page
-		int block_start, block_end;	// in-page offsets for buffers.
-
-		if (!page_buffers(page))
-			reiserfs_panic(inode->i_sb,
-				       "green-9005: No buffers for prepared page???");
-
-		/* For each buffer in page */
-		for (bh = head, block_start = 0; bh != head || !block_start;
-		     block_start = block_end, bh = bh->b_this_page) {
-			if (!bh)
-				reiserfs_panic(inode->i_sb,
-					       "green-9006: Allocated but absent buffer for a page?");
-			block_end = block_start + inode->i_sb->s_blocksize;
-			if (i == 0 && block_end <= from)
-				/* if this buffer is before requested data to map, skip it */
-				continue;
-			if (i == num_pages - 1 && block_start >= to)
-				/* If this buffer is after requested data to map, abort
-				   processing of current page */
-				break;
-
-			if (!buffer_mapped(bh)) {	// Ok, unmapped buffer, need to map it
-				map_bh(bh, inode->i_sb,
-				       le32_to_cpu(allocated_blocks
-						   [curr_block]));
-				curr_block++;
-				set_buffer_new(bh);
-			}
-		}
-	}
-
-	RFALSE(curr_block > blocks_to_allocate,
-	       "green-9007: Used too many blocks? weird");
-
-	kfree(allocated_blocks);
-	return 0;
-
-// Need to deal with transaction here.
-      error_exit_free_blocks:
-	pathrelse(&path);
-	// free blocks
-	for (i = 0; i < blocks_to_allocate; i++)
-		reiserfs_free_block(th, inode, le32_to_cpu(allocated_blocks[i]),
-				    1);
-
-      error_exit:
-	if (th->t_trans_id) {
-		int err;
-		// update any changes we made to blk count
-		mark_inode_dirty(inode);
-		err =
-		    journal_end(th, inode->i_sb,
-				JOURNAL_PER_BALANCE_CNT * 3 + 1 +
-				2 * REISERFS_QUOTA_TRANS_BLOCKS(inode->i_sb));
-		if (err)
-			res = err;
-	}
-	reiserfs_write_unlock(inode->i_sb);
-	kfree(allocated_blocks);
-
-	return res;
-}
-
-/* Unlock pages prepared by reiserfs_prepare_file_region_for_write */
-static void reiserfs_unprepare_pages(struct page **prepared_pages,	/* list of locked pages */
-				     size_t num_pages /* amount of pages */ )
-{
-	int i;			// loop counter
-
-	for (i = 0; i < num_pages; i++) {
-		struct page *page = prepared_pages[i];
-
-		try_to_free_buffers(page);
-		unlock_page(page);
-		page_cache_release(page);
-	}
-}
-
-/* This function will copy data from userspace to specified pages within
-   supplied byte range */
-static int reiserfs_copy_from_user_to_file_region(loff_t pos,	/* In-file position */
-						  int num_pages,	/* Number of pages affected */
-						  int write_bytes,	/* Amount of bytes to write */
-						  struct page **prepared_pages,	/* pointer to 
-										   array to
-										   prepared pages
-										 */
-						  const char __user * buf	/* Pointer to user-supplied
-										   data */
-    )
-{
-	long page_fault = 0;	// status of copy_from_user.
-	int i;			// loop counter.
-	int offset;		// offset in page
-
-	for (i = 0, offset = (pos & (PAGE_CACHE_SIZE - 1)); i < num_pages;
-	     i++, offset = 0) {
-		size_t count = min_t(size_t, PAGE_CACHE_SIZE - offset, write_bytes);	// How much of bytes to write to this page
-		struct page *page = prepared_pages[i];	// Current page we process.
-
-		fault_in_pages_readable(buf, count);
-
-		/* Copy data from userspace to the current page */
-		kmap(page);
-		page_fault = __copy_from_user(page_address(page) + offset, buf, count);	// Copy the data.
-		/* Flush processor's dcache for this page */
-		flush_dcache_page(page);
-		kunmap(page);
-		buf += count;
-		write_bytes -= count;
-
-		if (page_fault)
-			break;	// Was there a fault? abort.
-	}
-
-	return page_fault ? -EFAULT : 0;
-}
-
 /* taken fs/buffer.c:__block_commit_write */
 int reiserfs_commit_page(struct inode *inode, struct page *page,
 			 unsigned from, unsigned to)
@@ -824,432 +222,6 @@ int reiserfs_commit_page(struct inode *inode, struct page *page,
 	return ret;
 }
 
-/* Submit pages for write. This was separated from actual file copying
-   because we might want to allocate block numbers in-between.
-   This function assumes that caller will adjust file size to correct value. */
-static int reiserfs_submit_file_region_for_write(struct reiserfs_transaction_handle *th, struct inode *inode, loff_t pos,	/* Writing position offset */
-						 size_t num_pages,	/* Number of pages to write */
-						 size_t write_bytes,	/* number of bytes to write */
-						 struct page **prepared_pages	/* list of pages */
-    )
-{
-	int status;		// return status of block_commit_write.
-	int retval = 0;		// Return value we are going to return.
-	int i;			// loop counter
-	int offset;		// Writing offset in page.
-	int orig_write_bytes = write_bytes;
-	int sd_update = 0;
-
-	for (i = 0, offset = (pos & (PAGE_CACHE_SIZE - 1)); i < num_pages;
-	     i++, offset = 0) {
-		int count = min_t(int, PAGE_CACHE_SIZE - offset, write_bytes);	// How much of bytes to write to this page
-		struct page *page = prepared_pages[i];	// Current page we process.
-
-		status =
-		    reiserfs_commit_page(inode, page, offset, offset + count);
-		if (status)
-			retval = status;	// To not overcomplicate matters We are going to
-		// submit all the pages even if there was error.
-		// we only remember error status to report it on
-		// exit.
-		write_bytes -= count;
-	}
-	/* now that we've gotten all the ordered buffers marked dirty,
-	 * we can safely update i_size and close any running transaction
-	 */
-	if (pos + orig_write_bytes > inode->i_size) {
-		inode->i_size = pos + orig_write_bytes;	// Set new size
-		/* If the file have grown so much that tail packing is no
-		 * longer possible, reset "need to pack" flag */
-		if ((have_large_tails(inode->i_sb) &&
-		     inode->i_size > i_block_size(inode) * 4) ||
-		    (have_small_tails(inode->i_sb) &&
-		     inode->i_size > i_block_size(inode)))
-			REISERFS_I(inode)->i_flags &= ~i_pack_on_close_mask;
-		else if ((have_large_tails(inode->i_sb) &&
-			  inode->i_size < i_block_size(inode) * 4) ||
-			 (have_small_tails(inode->i_sb) &&
-			  inode->i_size < i_block_size(inode)))
-			REISERFS_I(inode)->i_flags |= i_pack_on_close_mask;
-
-		if (th->t_trans_id) {
-			reiserfs_write_lock(inode->i_sb);
-			// this sets the proper flags for O_SYNC to trigger a commit
-			mark_inode_dirty(inode);
-			reiserfs_write_unlock(inode->i_sb);
-		} else {
-			reiserfs_write_lock(inode->i_sb);
-			reiserfs_update_inode_transaction(inode);
-			mark_inode_dirty(inode);
-			reiserfs_write_unlock(inode->i_sb);
-		}
-
-		sd_update = 1;
-	}
-	if (th->t_trans_id) {
-		reiserfs_write_lock(inode->i_sb);
-		if (!sd_update)
-			mark_inode_dirty(inode);
-		status = journal_end(th, th->t_super, th->t_blocks_allocated);
-		if (status)
-			retval = status;
-		reiserfs_write_unlock(inode->i_sb);
-	}
-	th->t_trans_id = 0;
-
-	/* 
-	 * we have to unlock the pages after updating i_size, otherwise
-	 * we race with writepage
-	 */
-	for (i = 0; i < num_pages; i++) {
-		struct page *page = prepared_pages[i];
-		unlock_page(page);
-		mark_page_accessed(page);
-		page_cache_release(page);
-	}
-	return retval;
-}
-
-/* Look if passed writing region is going to touch file's tail
-   (if it is present). And if it is, convert the tail to unformatted node */
-static int reiserfs_check_for_tail_and_convert(struct inode *inode,	/* inode to deal with */
-					       loff_t pos,	/* Writing position */
-					       int write_bytes	/* amount of bytes to write */
-    )
-{
-	INITIALIZE_PATH(path);	// needed for search_for_position
-	struct cpu_key key;	// Key that would represent last touched writing byte.
-	struct item_head *ih;	// item header of found block;
-	int res;		// Return value of various functions we call.
-	int cont_expand_offset;	// We will put offset for generic_cont_expand here
-	// This can be int just because tails are created
-	// only for small files.
-
-/* this embodies a dependency on a particular tail policy */
-	if (inode->i_size >= inode->i_sb->s_blocksize * 4) {
-		/* such a big files do not have tails, so we won't bother ourselves
-		   to look for tails, simply return */
-		return 0;
-	}
-
-	reiserfs_write_lock(inode->i_sb);
-	/* find the item containing the last byte to be written, or if
-	 * writing past the end of the file then the last item of the
-	 * file (and then we check its type). */
-	make_cpu_key(&key, inode, pos + write_bytes + 1, TYPE_ANY,
-		     3 /*key length */ );
-	res = search_for_position_by_key(inode->i_sb, &key, &path);
-	if (res == IO_ERROR) {
-		reiserfs_write_unlock(inode->i_sb);
-		return -EIO;
-	}
-	ih = get_ih(&path);
-	res = 0;
-	if (is_direct_le_ih(ih)) {
-		/* Ok, closest item is file tail (tails are stored in "direct"
-		 * items), so we need to unpack it. */
-		/* To not overcomplicate matters, we just call generic_cont_expand
-		   which will in turn call other stuff and finally will boil down to
-		   reiserfs_get_block() that would do necessary conversion. */
-		cont_expand_offset =
-		    le_key_k_offset(get_inode_item_key_version(inode),
-				    &(ih->ih_key));
-		pathrelse(&path);
-		res = generic_cont_expand(inode, cont_expand_offset);
-	} else
-		pathrelse(&path);
-
-	reiserfs_write_unlock(inode->i_sb);
-	return res;
-}
-
-/* This function locks pages starting from @pos for @inode.
-   @num_pages pages are locked and stored in
-   @prepared_pages array. Also buffers are allocated for these pages.
-   First and last page of the region is read if it is overwritten only
-   partially. If last page did not exist before write (file hole or file
-   append), it is zeroed, then. 
-   Returns number of unallocated blocks that should be allocated to cover
-   new file data.*/
-static int reiserfs_prepare_file_region_for_write(struct inode *inode
-						  /* Inode of the file */ ,
-						  loff_t pos,	/* position in the file */
-						  size_t num_pages,	/* number of pages to
-									   prepare */
-						  size_t write_bytes,	/* Amount of bytes to be
-									   overwritten from
-									   @pos */
-						  struct page **prepared_pages	/* pointer to array
-										   where to store
-										   prepared pages */
-    )
-{
-	int res = 0;		// Return values of different functions we call.
-	unsigned long index = pos >> PAGE_CACHE_SHIFT;	// Offset in file in pages.
-	int from = (pos & (PAGE_CACHE_SIZE - 1));	// Writing offset in first page
-	int to = ((pos + write_bytes - 1) & (PAGE_CACHE_SIZE - 1)) + 1;
-	/* offset of last modified byte in last
-	   page */
-	struct address_space *mapping = inode->i_mapping;	// Pages are mapped here.
-	int i;			// Simple counter
-	int blocks = 0;		/* Return value (blocks that should be allocated) */
-	struct buffer_head *bh, *head;	// Current bufferhead and first bufferhead
-	// of a page.
-	unsigned block_start, block_end;	// Starting and ending offsets of current
-	// buffer in the page.
-	struct buffer_head *wait[2], **wait_bh = wait;	// Buffers for page, if
-	// Page appeared to be not up
-	// to date. Note how we have
-	// at most 2 buffers, this is
-	// because we at most may
-	// partially overwrite two
-	// buffers for one page. One at                                                 // the beginning of write area
-	// and one at the end.
-	// Everything inthe middle gets                                                 // overwritten totally.
-
-	struct cpu_key key;	// cpu key of item that we are going to deal with
-	struct item_head *ih = NULL;	// pointer to item head that we are going to deal with
-	struct buffer_head *itembuf = NULL;	// Buffer head that contains items that we are going to deal with
-	INITIALIZE_PATH(path);	// path to item, that we are going to deal with.
-	__le32 *item = NULL;	// pointer to item we are going to deal with
-	int item_pos = -1;	/* Position in indirect item */
-
-	if (num_pages < 1) {
-		reiserfs_warning(inode->i_sb,
-				 "green-9001: reiserfs_prepare_file_region_for_write "
-				 "called with zero number of pages to process");
-		return -EFAULT;
-	}
-
-	/* We have 2 loops for pages. In first loop we grab and lock the pages, so
-	   that nobody would touch these until we release the pages. Then
-	   we'd start to deal with mapping buffers to blocks. */
-	for (i = 0; i < num_pages; i++) {
-		prepared_pages[i] = grab_cache_page(mapping, index + i);	// locks the page
-		if (!prepared_pages[i]) {
-			res = -ENOMEM;
-			goto failed_page_grabbing;
-		}
-		if (!page_has_buffers(prepared_pages[i]))
-			create_empty_buffers(prepared_pages[i],
-					     inode->i_sb->s_blocksize, 0);
-	}
-
-	/* Let's count amount of blocks for a case where all the blocks
-	   overwritten are new (we will substract already allocated blocks later) */
-	if (num_pages > 2)
-		/* These are full-overwritten pages so we count all the blocks in
-		   these pages are counted as needed to be allocated */
-		blocks =
-		    (num_pages - 2) << (PAGE_CACHE_SHIFT - inode->i_blkbits);
-
-	/* count blocks needed for first page (possibly partially written) */
-	blocks += ((PAGE_CACHE_SIZE - from) >> inode->i_blkbits) + !!(from & (inode->i_sb->s_blocksize - 1));	/* roundup */
-
-	/* Now we account for last page. If last page == first page (we
-	   overwrite only one page), we substract all the blocks past the
-	   last writing position in a page out of already calculated number
-	   of blocks */
-	blocks += ((num_pages > 1) << (PAGE_CACHE_SHIFT - inode->i_blkbits)) -
-	    ((PAGE_CACHE_SIZE - to) >> inode->i_blkbits);
-	/* Note how we do not roundup here since partial blocks still
-	   should be allocated */
-
-	/* Now if all the write area lies past the file end, no point in
-	   maping blocks, since there is none, so we just zero out remaining
-	   parts of first and last pages in write area (if needed) */
-	if ((pos & ~((loff_t) PAGE_CACHE_SIZE - 1)) > inode->i_size) {
-		if (from != 0)		/* First page needs to be partially zeroed */
-			zero_user_page(prepared_pages[0], 0, from, KM_USER0);
-
-		if (to != PAGE_CACHE_SIZE)	/* Last page needs to be partially zeroed */
-			zero_user_page(prepared_pages[num_pages-1], to,
-					PAGE_CACHE_SIZE - to, KM_USER0);
-
-		/* Since all blocks are new - use already calculated value */
-		return blocks;
-	}
-
-	/* Well, since we write somewhere into the middle of a file, there is
-	   possibility we are writing over some already allocated blocks, so
-	   let's map these blocks and substract number of such blocks out of blocks
-	   we need to allocate (calculated above) */
-	/* Mask write position to start on blocksize, we do it out of the
-	   loop for performance reasons */
-	pos &= ~((loff_t) inode->i_sb->s_blocksize - 1);
-	/* Set cpu key to the starting position in a file (on left block boundary) */
-	make_cpu_key(&key, inode,
-		     1 + ((pos) & ~((loff_t) inode->i_sb->s_blocksize - 1)),
-		     TYPE_ANY, 3 /*key length */ );
-
-	reiserfs_write_lock(inode->i_sb);	// We need that for at least search_by_key()
-	for (i = 0; i < num_pages; i++) {
-
-		head = page_buffers(prepared_pages[i]);
-		/* For each buffer in the page */
-		for (bh = head, block_start = 0; bh != head || !block_start;
-		     block_start = block_end, bh = bh->b_this_page) {
-			if (!bh)
-				reiserfs_panic(inode->i_sb,
-					       "green-9002: Allocated but absent buffer for a page?");
-			/* Find where this buffer ends */
-			block_end = block_start + inode->i_sb->s_blocksize;
-			if (i == 0 && block_end <= from)
-				/* if this buffer is before requested data to map, skip it */
-				continue;
-
-			if (i == num_pages - 1 && block_start >= to) {
-				/* If this buffer is after requested data to map, abort
-				   processing of current page */
-				break;
-			}
-
-			if (buffer_mapped(bh) && bh->b_blocknr != 0) {
-				/* This is optimisation for a case where buffer is mapped
-				   and have blocknumber assigned. In case significant amount
-				   of such buffers are present, we may avoid some amount
-				   of search_by_key calls.
-				   Probably it would be possible to move parts of this code
-				   out of BKL, but I afraid that would overcomplicate code
-				   without any noticeable benefit.
-				 */
-				item_pos++;
-				/* Update the key */
-				set_cpu_key_k_offset(&key,
-						     cpu_key_k_offset(&key) +
-						     inode->i_sb->s_blocksize);
-				blocks--;	// Decrease the amount of blocks that need to be
-				// allocated
-				continue;	// Go to the next buffer
-			}
-
-			if (!itembuf ||	/* if first iteration */
-			    item_pos >= ih_item_len(ih) / UNFM_P_SIZE) {	/* or if we progressed past the
-										   current unformatted_item */
-				/* Try to find next item */
-				res =
-				    search_for_position_by_key(inode->i_sb,
-							       &key, &path);
-				/* Abort if no more items */
-				if (res != POSITION_FOUND) {
-					/* make sure later loops don't use this item */
-					itembuf = NULL;
-					item = NULL;
-					break;
-				}
-
-				/* Update information about current indirect item */
-				itembuf = get_last_bh(&path);
-				ih = get_ih(&path);
-				item = get_item(&path);
-				item_pos = path.pos_in_item;
-
-				RFALSE(!is_indirect_le_ih(ih),
-				       "green-9003: indirect item expected");
-			}
-
-			/* See if there is some block associated with the file
-			   at that position, map the buffer to this block */
-			if (get_block_num(item, item_pos)) {
-				map_bh(bh, inode->i_sb,
-				       get_block_num(item, item_pos));
-				blocks--;	// Decrease the amount of blocks that need to be
-				// allocated
-			}
-			item_pos++;
-			/* Update the key */
-			set_cpu_key_k_offset(&key,
-					     cpu_key_k_offset(&key) +
-					     inode->i_sb->s_blocksize);
-		}
-	}
-	pathrelse(&path);	// Free the path
-	reiserfs_write_unlock(inode->i_sb);
-
-	/* Now zero out unmappend buffers for the first and last pages of
-	   write area or issue read requests if page is mapped. */
-	/* First page, see if it is not uptodate */
-	if (!PageUptodate(prepared_pages[0])) {
-		head = page_buffers(prepared_pages[0]);
-
-		/* For each buffer in page */
-		for (bh = head, block_start = 0; bh != head || !block_start;
-		     block_start = block_end, bh = bh->b_this_page) {
-
-			if (!bh)
-				reiserfs_panic(inode->i_sb,
-					       "green-9002: Allocated but absent buffer for a page?");
-			/* Find where this buffer ends */
-			block_end = block_start + inode->i_sb->s_blocksize;
-			if (block_end <= from)
-				/* if this buffer is before requested data to map, skip it */
-				continue;
-			if (block_start < from) {	/* Aha, our partial buffer */
-				if (buffer_mapped(bh)) {	/* If it is mapped, we need to
-								   issue READ request for it to
-								   not loose data */
-					ll_rw_block(READ, 1, &bh);
-					*wait_bh++ = bh;
-				} else {	/* Not mapped, zero it */
-					zero_user_page(prepared_pages[0],
-						       block_start,
-						       from - block_start, KM_USER0);
-					set_buffer_uptodate(bh);
-				}
-			}
-		}
-	}
-
-	/* Last page, see if it is not uptodate, or if the last page is past the end of the file. */
-	if (!PageUptodate(prepared_pages[num_pages - 1]) ||
-	    ((pos + write_bytes) >> PAGE_CACHE_SHIFT) >
-	    (inode->i_size >> PAGE_CACHE_SHIFT)) {
-		head = page_buffers(prepared_pages[num_pages - 1]);
-
-		/* for each buffer in page */
-		for (bh = head, block_start = 0; bh != head || !block_start;
-		     block_start = block_end, bh = bh->b_this_page) {
-
-			if (!bh)
-				reiserfs_panic(inode->i_sb,
-					       "green-9002: Allocated but absent buffer for a page?");
-			/* Find where this buffer ends */
-			block_end = block_start + inode->i_sb->s_blocksize;
-			if (block_start >= to)
-				/* if this buffer is after requested data to map, skip it */
-				break;
-			if (block_end > to) {	/* Aha, our partial buffer */
-				if (buffer_mapped(bh)) {	/* If it is mapped, we need to
-								   issue READ request for it to
-								   not loose data */
-					ll_rw_block(READ, 1, &bh);
-					*wait_bh++ = bh;
-				} else {	/* Not mapped, zero it */
-					zero_user_page(prepared_pages[num_pages-1],
-							to, block_end - to, KM_USER0);
-					set_buffer_uptodate(bh);
-				}
-			}
-		}
-	}
-
-	/* Wait for read requests we made to happen, if necessary */
-	while (wait_bh > wait) {
-		wait_on_buffer(*--wait_bh);
-		if (!buffer_uptodate(*wait_bh)) {
-			res = -EIO;
-			goto failed_read;
-		}
-	}
-
-	return blocks;
-      failed_page_grabbing:
-	num_pages = i;
-      failed_read:
-	reiserfs_unprepare_pages(prepared_pages, num_pages);
-	return res;
-}
-
 /* Write @count bytes at position @ppos in a file indicated by @file
    from the buffer @buf.  
 
@@ -1284,14 +256,9 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 							 * new current position before returning. */
 				   )
 {
-	size_t already_written = 0;	// Number of bytes already written to the file.
-	loff_t pos;		// Current position in the file.
-	ssize_t res;		// return value of various functions that we call.
-	int err = 0;
 	struct inode *inode = file->f_path.dentry->d_inode;	// Inode of the file that we are writing to.
 	/* To simplify coding at this time, we store
 	   locked pages in array for now */
-	struct page *prepared_pages[REISERFS_WRITE_PAGES_AT_A_TIME];
 	struct reiserfs_transaction_handle th;
 	th.t_trans_id = 0;
 
@@ -1311,212 +278,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 			count = MAX_NON_LFS - (unsigned long)*ppos;
 	}
 
-	if (file->f_flags & O_DIRECT)
-		return do_sync_write(file, buf, count, ppos);
-
-	if (unlikely((ssize_t) count < 0))
-		return -EINVAL;
-
-	if (unlikely(!access_ok(VERIFY_READ, buf, count)))
-		return -EFAULT;
-
-	mutex_lock(&inode->i_mutex);	// locks the entire file for just us
-
-	pos = *ppos;
-
-	/* Check if we can write to specified region of file, file
-	   is not overly big and this kind of stuff. Adjust pos and
-	   count, if needed */
-	res = generic_write_checks(file, &pos, &count, 0);
-	if (res)
-		goto out;
-
-	if (count == 0)
-		goto out;
-
-	res = remove_suid(file->f_path.dentry);
-	if (res)
-		goto out;
-
-	file_update_time(file);
-
-	// Ok, we are done with all the checks.
-
-	// Now we should start real work
-
-	/* If we are going to write past the file's packed tail or if we are going
-	   to overwrite part of the tail, we need that tail to be converted into
-	   unformatted node */
-	res = reiserfs_check_for_tail_and_convert(inode, pos, count);
-	if (res)
-		goto out;
-
-	while (count > 0) {
-		/* This is the main loop in which we running until some error occures
-		   or until we write all of the data. */
-		size_t num_pages;	/* amount of pages we are going to write this iteration */
-		size_t write_bytes;	/* amount of bytes to write during this iteration */
-		size_t blocks_to_allocate;	/* how much blocks we need to allocate for this iteration */
-
-		/*  (pos & (PAGE_CACHE_SIZE-1)) is an idiom for offset into a page of pos */
-		num_pages = !!((pos + count) & (PAGE_CACHE_SIZE - 1)) +	/* round up partial
-									   pages */
-		    ((count +
-		      (pos & (PAGE_CACHE_SIZE - 1))) >> PAGE_CACHE_SHIFT);
-		/* convert size to amount of
-		   pages */
-		reiserfs_write_lock(inode->i_sb);
-		if (num_pages > REISERFS_WRITE_PAGES_AT_A_TIME
-		    || num_pages > reiserfs_can_fit_pages(inode->i_sb)) {
-			/* If we were asked to write more data than we want to or if there
-			   is not that much space, then we shorten amount of data to write
-			   for this iteration. */
-			num_pages =
-			    min_t(size_t, REISERFS_WRITE_PAGES_AT_A_TIME,
-				  reiserfs_can_fit_pages(inode->i_sb));
-			/* Also we should not forget to set size in bytes accordingly */
-			write_bytes = (num_pages << PAGE_CACHE_SHIFT) -
-			    (pos & (PAGE_CACHE_SIZE - 1));
-			/* If position is not on the
-			   start of the page, we need
-			   to substract the offset
-			   within page */
-		} else
-			write_bytes = count;
-
-		/* reserve the blocks to be allocated later, so that later on
-		   we still have the space to write the blocks to */
-		reiserfs_claim_blocks_to_be_allocated(inode->i_sb,
-						      num_pages <<
-						      (PAGE_CACHE_SHIFT -
-						       inode->i_blkbits));
-		reiserfs_write_unlock(inode->i_sb);
-
-		if (!num_pages) {	/* If we do not have enough space even for a single page... */
-			if (pos >
-			    inode->i_size + inode->i_sb->s_blocksize -
-			    (pos & (inode->i_sb->s_blocksize - 1))) {
-				res = -ENOSPC;
-				break;	// In case we are writing past the end of the last file block, break.
-			}
-			// Otherwise we are possibly overwriting the file, so
-			// let's set write size to be equal or less than blocksize.
-			// This way we get it correctly for file holes.
-			// But overwriting files on absolutelly full volumes would not
-			// be very efficient. Well, people are not supposed to fill
-			// 100% of disk space anyway.
-			write_bytes =
-			    min_t(size_t, count,
-				  inode->i_sb->s_blocksize -
-				  (pos & (inode->i_sb->s_blocksize - 1)));
-			num_pages = 1;
-			// No blocks were claimed before, so do it now.
-			reiserfs_claim_blocks_to_be_allocated(inode->i_sb,
-							      1 <<
-							      (PAGE_CACHE_SHIFT
-							       -
-							       inode->
-							       i_blkbits));
-		}
-
-		/* Prepare for writing into the region, read in all the
-		   partially overwritten pages, if needed. And lock the pages,
-		   so that nobody else can access these until we are done.
-		   We get number of actual blocks needed as a result. */
-		res = reiserfs_prepare_file_region_for_write(inode, pos,
-							     num_pages,
-							     write_bytes,
-							     prepared_pages);
-		if (res < 0) {
-			reiserfs_release_claimed_blocks(inode->i_sb,
-							num_pages <<
-							(PAGE_CACHE_SHIFT -
-							 inode->i_blkbits));
-			break;
-		}
-
-		blocks_to_allocate = res;
-
-		/* First we correct our estimate of how many blocks we need */
-		reiserfs_release_claimed_blocks(inode->i_sb,
-						(num_pages <<
-						 (PAGE_CACHE_SHIFT -
-						  inode->i_sb->
-						  s_blocksize_bits)) -
-						blocks_to_allocate);
-
-		if (blocks_to_allocate > 0) {	/*We only allocate blocks if we need to */
-			/* Fill in all the possible holes and append the file if needed */
-			res =
-			    reiserfs_allocate_blocks_for_region(&th, inode, pos,
-								num_pages,
-								write_bytes,
-								prepared_pages,
-								blocks_to_allocate);
-		}
-
-		/* well, we have allocated the blocks, so it is time to free
-		   the reservation we made earlier. */
-		reiserfs_release_claimed_blocks(inode->i_sb,
-						blocks_to_allocate);
-		if (res) {
-			reiserfs_unprepare_pages(prepared_pages, num_pages);
-			break;
-		}
-
-/* NOTE that allocating blocks and filling blocks can be done in reverse order
-   and probably we would do that just to get rid of garbage in files after a
-   crash */
-
-		/* Copy data from user-supplied buffer to file's pages */
-		res =
-		    reiserfs_copy_from_user_to_file_region(pos, num_pages,
-							   write_bytes,
-							   prepared_pages, buf);
-		if (res) {
-			reiserfs_unprepare_pages(prepared_pages, num_pages);
-			break;
-		}
-
-		/* Send the pages to disk and unlock them. */
-		res =
-		    reiserfs_submit_file_region_for_write(&th, inode, pos,
-							  num_pages,
-							  write_bytes,
-							  prepared_pages);
-		if (res)
-			break;
-
-		already_written += write_bytes;
-		buf += write_bytes;
-		*ppos = pos += write_bytes;
-		count -= write_bytes;
-		balance_dirty_pages_ratelimited_nr(inode->i_mapping, num_pages);
-	}
-
-	/* this is only true on error */
-	if (th.t_trans_id) {
-		reiserfs_write_lock(inode->i_sb);
-		err = journal_end(&th, th.t_super, th.t_blocks_allocated);
-		reiserfs_write_unlock(inode->i_sb);
-		if (err) {
-			res = err;
-			goto out;
-		}
-	}
-
-	if (likely(res >= 0) &&
-	    (unlikely((file->f_flags & O_SYNC) || IS_SYNC(inode))))
-		res = generic_osync_inode(inode, file->f_mapping,
-		                          OSYNC_METADATA | OSYNC_DATA);
-
-	mutex_unlock(&inode->i_mutex);
-	reiserfs_async_progress_wait(inode->i_sb);
-	return (already_written != 0) ? already_written : res;
-
-      out:
-	mutex_unlock(&inode->i_mutex);	// unlock the file on exit.
-	return res;
+	return do_sync_write(file, buf, count, ppos);
 }
 
 const struct file_operations reiserfs_file_operations = {

commit 17973f5af741f1758ed57c5115ca394c22bee159
Author: Micah Cowan <micah@cowan.name>
Date:   Sun Jul 15 23:40:08 2007 -0700

    Only send SIGXFSZ when exceeding rlimits.
    
    Some users have been having problems with utilities like cp or dd dumping
    core when they try to copy a file that's too large for the destination
    filesystem (typically, > 4gb).  Apparently, some defunct standards required
    SIGXFSZ to be sent in such circumstances, but SUS only requires/allows it
    for when a written file exceeds the process's resource limits.  I'd like to
    limit SIGXFSZs to the bare minimum required by SUS.
    
    Patch sent per http://lkml.org/lkml/2007/4/10/302
    
    Signed-off-by: Micah Cowan <micahcowan@ubuntu.com>
    Acked-by: Alan Cox <alan@redhat.com>
    Cc: <reiserfs-dev@namesys.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 30eebfb1b2d8..2070aeee2a52 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1305,7 +1305,6 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 	if (get_inode_item_key_version (inode) == KEY_FORMAT_3_5 &&
 	    *ppos + count > MAX_NON_LFS) {
 		if (*ppos >= MAX_NON_LFS) {
-			send_sig(SIGXFSZ, current, 0);
 			return -EFBIG;
 		}
 		if (count > MAX_NON_LFS - (unsigned long)*ppos)

commit 5ffc4ef45b3b0a57872f631b4e4ceb8ace0d7496
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri Jun 1 11:49:19 2007 +0200

    sendfile: remove .sendfile from filesystems that use generic_file_sendfile()
    
    They can use generic_file_splice_read() instead. Since sys_sendfile() now
    prefers that, there should be no change in behaviour.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 9e451a68580f..30eebfb1b2d8 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1531,7 +1531,6 @@ const struct file_operations reiserfs_file_operations = {
 	.open = generic_file_open,
 	.release = reiserfs_file_release,
 	.fsync = reiserfs_sync_file,
-	.sendfile = generic_file_sendfile,
 	.aio_read = generic_file_aio_read,
 	.aio_write = generic_file_aio_write,
 	.splice_read = generic_file_splice_read,

commit f2fff596955867d407cc7e8e426097bd9ad2be9b
Author: Nate Diller <nate.diller@gmail.com>
Date:   Wed May 9 02:35:09 2007 -0700

    reiserfs: use zero_user_page
    
    Use zero_user_page() instead of open-coding it.
    
    Signed-off-by: Nate Diller <nate.diller@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index ab45db529c80..9e451a68580f 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1059,20 +1059,12 @@ static int reiserfs_prepare_file_region_for_write(struct inode *inode
 	   maping blocks, since there is none, so we just zero out remaining
 	   parts of first and last pages in write area (if needed) */
 	if ((pos & ~((loff_t) PAGE_CACHE_SIZE - 1)) > inode->i_size) {
-		if (from != 0) {	/* First page needs to be partially zeroed */
-			char *kaddr = kmap_atomic(prepared_pages[0], KM_USER0);
-			memset(kaddr, 0, from);
-			kunmap_atomic(kaddr, KM_USER0);
-			flush_dcache_page(prepared_pages[0]);
-		}
-		if (to != PAGE_CACHE_SIZE) {	/* Last page needs to be partially zeroed */
-			char *kaddr =
-			    kmap_atomic(prepared_pages[num_pages - 1],
-					KM_USER0);
-			memset(kaddr + to, 0, PAGE_CACHE_SIZE - to);
-			kunmap_atomic(kaddr, KM_USER0);
-			flush_dcache_page(prepared_pages[num_pages - 1]);
-		}
+		if (from != 0)		/* First page needs to be partially zeroed */
+			zero_user_page(prepared_pages[0], 0, from, KM_USER0);
+
+		if (to != PAGE_CACHE_SIZE)	/* Last page needs to be partially zeroed */
+			zero_user_page(prepared_pages[num_pages-1], to,
+					PAGE_CACHE_SIZE - to, KM_USER0);
 
 		/* Since all blocks are new - use already calculated value */
 		return blocks;
@@ -1199,13 +1191,9 @@ static int reiserfs_prepare_file_region_for_write(struct inode *inode
 					ll_rw_block(READ, 1, &bh);
 					*wait_bh++ = bh;
 				} else {	/* Not mapped, zero it */
-					char *kaddr =
-					    kmap_atomic(prepared_pages[0],
-							KM_USER0);
-					memset(kaddr + block_start, 0,
-					       from - block_start);
-					kunmap_atomic(kaddr, KM_USER0);
-					flush_dcache_page(prepared_pages[0]);
+					zero_user_page(prepared_pages[0],
+						       block_start,
+						       from - block_start, KM_USER0);
 					set_buffer_uptodate(bh);
 				}
 			}
@@ -1237,13 +1225,8 @@ static int reiserfs_prepare_file_region_for_write(struct inode *inode
 					ll_rw_block(READ, 1, &bh);
 					*wait_bh++ = bh;
 				} else {	/* Not mapped, zero it */
-					char *kaddr =
-					    kmap_atomic(prepared_pages
-							[num_pages - 1],
-							KM_USER0);
-					memset(kaddr + to, 0, block_end - to);
-					kunmap_atomic(kaddr, KM_USER0);
-					flush_dcache_page(prepared_pages[num_pages - 1]);
+					zero_user_page(prepared_pages[num_pages-1],
+							to, block_end - to, KM_USER0);
 					set_buffer_uptodate(bh);
 				}
 			}

commit e63340ae6b6205fef26b40a75673d1c9c0c8bb90
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Tue May 8 00:28:08 2007 -0700

    header cleaning: don't include smp_lock.h when not used
    
    Remove includes of <linux/smp_lock.h> where it is not used/needed.
    Suggested by Al Viro.
    
    Builds cleanly on x86_64, i386, alpha, ia64, powerpc, sparc,
    sparc64, and arm (all 59 defconfigs).
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index abfada2f52db..ab45db529c80 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -6,7 +6,6 @@
 #include <linux/reiserfs_fs.h>
 #include <linux/reiserfs_acl.h>
 #include <linux/reiserfs_xattr.h>
-#include <linux/smp_lock.h>
 #include <asm/uaccess.h>
 #include <linux/pagemap.h>
 #include <linux/swap.h>

commit c5ef1c42c51b1b5b4a401a6517bdda30933ddbaf
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Mon Feb 12 00:55:40 2007 -0800

    [PATCH] mark struct inode_operations const 3
    
    Many struct inode_operations in the kernel can be "const".  Marking them const
    moves these to the .rodata section, which avoids false sharing with potential
    dirty data.  In addition it'll catch accidental writes at compile time to
    these shared resources.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 5109f1d5e7ff..abfada2f52db 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1556,7 +1556,7 @@ const struct file_operations reiserfs_file_operations = {
 	.splice_write = generic_file_splice_write,
 };
 
-struct inode_operations reiserfs_file_inode_operations = {
+const struct inode_operations reiserfs_file_inode_operations = {
 	.truncate = reiserfs_vfs_truncate_file,
 	.setattr = reiserfs_setattr,
 	.setxattr = reiserfs_setxattr,

commit de14569f94513279e3d44d9571a421e9da1759ae
Author: Vladimir Saveliev <vs@namesys.com>
Date:   Mon Jan 22 20:40:46 2007 -0800

    [PATCH] resierfs: avoid tail packing if an inode was ever mmapped
    
    This patch fixes a confusion reiserfs has for a long time.
    
    On release file operation reiserfs used to try to pack file data stored in
    last incomplete page of some files into metadata blocks.  After packing the
    page got cleared with clear_page_dirty.  It did not take into account that
    the page may be mmaped into other process's address space.  Recent
    replacement for clear_page_dirty cancel_dirty_page found the confusion with
    sanity check that page has to be not mapped.
    
    The patch fixes the confusion by making reiserfs avoid tail packing if an
    inode was ever mmapped.  reiserfs_mmap and reiserfs_file_release are
    serialized with mutex in reiserfs specific inode.  reiserfs_mmap locks the
    mutex and sets a bit in reiserfs specific inode flags.
    reiserfs_file_release checks the bit having the mutex locked.  If bit is
    set - tail packing is avoided.  This eliminates a possibility that mmapped
    page gets cancel_page_dirty-ed.
    
    Signed-off-by: Vladimir Saveliev <vs@namesys.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 99b6f329ba23..5109f1d5e7ff 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -48,6 +48,11 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 	}
 
 	mutex_lock(&inode->i_mutex);
+
+	mutex_lock(&(REISERFS_I(inode)->i_mmap));
+	if (REISERFS_I(inode)->i_flags & i_ever_mapped)
+		REISERFS_I(inode)->i_flags &= ~i_pack_on_close_mask;
+
 	reiserfs_write_lock(inode->i_sb);
 	/* freeing preallocation only involves relogging blocks that
 	 * are already in the current transaction.  preallocation gets
@@ -100,11 +105,24 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 		err = reiserfs_truncate_file(inode, 0);
 	}
       out:
+	mutex_unlock(&(REISERFS_I(inode)->i_mmap));
 	mutex_unlock(&inode->i_mutex);
 	reiserfs_write_unlock(inode->i_sb);
 	return err;
 }
 
+static int reiserfs_file_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	struct inode *inode;
+
+	inode = file->f_path.dentry->d_inode;
+	mutex_lock(&(REISERFS_I(inode)->i_mmap));
+	REISERFS_I(inode)->i_flags |= i_ever_mapped;
+	mutex_unlock(&(REISERFS_I(inode)->i_mmap));
+
+	return generic_file_mmap(file, vma);
+}
+
 static void reiserfs_vfs_truncate_file(struct inode *inode)
 {
 	reiserfs_truncate_file(inode, 1);
@@ -1527,7 +1545,7 @@ const struct file_operations reiserfs_file_operations = {
 #ifdef CONFIG_COMPAT
 	.compat_ioctl = reiserfs_compat_ioctl,
 #endif
-	.mmap = generic_file_mmap,
+	.mmap = reiserfs_file_mmap,
 	.open = generic_file_open,
 	.release = reiserfs_file_release,
 	.fsync = reiserfs_sync_file,

commit 1fc5adbd1916793c19d25347f484806c124d9be7
Author: Josef Sipek <jsipek@fsl.cs.sunysb.edu>
Date:   Fri Dec 8 02:37:33 2006 -0800

    [PATCH] struct path: convert reiserfs
    
    Signed-off-by: Josef Sipek <jsipek@fsl.cs.sunysb.edu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 373d862c3f87..99b6f329ba23 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1288,7 +1288,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 	loff_t pos;		// Current position in the file.
 	ssize_t res;		// return value of various functions that we call.
 	int err = 0;
-	struct inode *inode = file->f_dentry->d_inode;	// Inode of the file that we are writing to.
+	struct inode *inode = file->f_path.dentry->d_inode;	// Inode of the file that we are writing to.
 	/* To simplify coding at this time, we store
 	   locked pages in array for now */
 	struct page *prepared_pages[REISERFS_WRITE_PAGES_AT_A_TIME];
@@ -1335,7 +1335,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 	if (count == 0)
 		goto out;
 
-	res = remove_suid(file->f_dentry);
+	res = remove_suid(file->f_path.dentry);
 	if (res)
 		goto out;
 

commit c55747682e938c57a9a859d3b26f2c4c83cea011
Author: Vladimir V. Saveliev <vs@namesys.com>
Date:   Wed Dec 6 20:39:12 2006 -0800

    [PATCH] reiserfs: do not add save links for O_DIRECT writes
    
    We add a save link for O_DIRECT writes to protect the i_size against the
    crashes before we actually finish the I/O.  If we hit an -ENOSPC in
    aops->prepare_write(), we would do a truncate() to release the blocks which
    might have got initialized.  Now the truncate would add another save link
    for the same inode causing a reiserfs panic for having multiple save links
    for the same inode.
    
    Signed-off-by: Vladimir V. Saveliev <vs@namesys.com>
    Signed-off-by: Amit Arora <amitarora@in.ibm.com>
    Signed-off-by: Suzuki K P <suzuki@in.ibm.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 970ecd9dbe69..373d862c3f87 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -406,6 +406,8 @@ static int reiserfs_allocate_blocks_for_region(struct reiserfs_transaction_handl
 				   we restart it. This will also free the path. */
 				if (journal_transaction_should_end
 				    (th, th->t_blocks_allocated)) {
+					inode->i_size = cpu_key_k_offset(&key) +
+						(to_paste << inode->i_blkbits);
 					res =
 					    restart_transaction(th, inode,
 								&path);
@@ -1310,56 +1312,8 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 			count = MAX_NON_LFS - (unsigned long)*ppos;
 	}
 
-	if (file->f_flags & O_DIRECT) {	// Direct IO needs treatment
-		ssize_t result, after_file_end = 0;
-		if ((*ppos + count >= inode->i_size)
-		    || (file->f_flags & O_APPEND)) {
-			/* If we are appending a file, we need to put this savelink in here.
-			   If we will crash while doing direct io, finish_unfinished will
-			   cut the garbage from the file end. */
-			reiserfs_write_lock(inode->i_sb);
-			err =
-			    journal_begin(&th, inode->i_sb,
-					  JOURNAL_PER_BALANCE_CNT);
-			if (err) {
-				reiserfs_write_unlock(inode->i_sb);
-				return err;
-			}
-			reiserfs_update_inode_transaction(inode);
-			add_save_link(&th, inode, 1 /* Truncate */ );
-			after_file_end = 1;
-			err =
-			    journal_end(&th, inode->i_sb,
-					JOURNAL_PER_BALANCE_CNT);
-			reiserfs_write_unlock(inode->i_sb);
-			if (err)
-				return err;
-		}
-		result = do_sync_write(file, buf, count, ppos);
-
-		if (after_file_end) {	/* Now update i_size and remove the savelink */
-			struct reiserfs_transaction_handle th;
-			reiserfs_write_lock(inode->i_sb);
-			err = journal_begin(&th, inode->i_sb, 1);
-			if (err) {
-				reiserfs_write_unlock(inode->i_sb);
-				return err;
-			}
-			reiserfs_update_inode_transaction(inode);
-			mark_inode_dirty(inode);
-			err = journal_end(&th, inode->i_sb, 1);
-			if (err) {
-				reiserfs_write_unlock(inode->i_sb);
-				return err;
-			}
-			err = remove_save_link(inode, 1 /* truncate */ );
-			reiserfs_write_unlock(inode->i_sb);
-			if (err)
-				return err;
-		}
-
-		return result;
-	}
+	if (file->f_flags & O_DIRECT)
+		return do_sync_write(file, buf, count, ppos);
 
 	if (unlikely((ssize_t) count < 0))
 		return -EINVAL;

commit 01afb2134ed079fa4551b4d26f62423df6790c09
Author: Yan Burman <burman.yan@gmail.com>
Date:   Wed Dec 6 20:39:01 2006 -0800

    [PATCH] reiser: replace kmalloc+memset with kzalloc
    
    Replace kmalloc+memset with kzalloc
    
    Signed-off-by: Yan Burman <burman.yan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 6526498949d8..970ecd9dbe69 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -317,12 +317,11 @@ static int reiserfs_allocate_blocks_for_region(struct reiserfs_transaction_handl
 			/* area filled with zeroes, to supply as list of zero blocknumbers
 			   We allocate it outside of loop just in case loop would spin for
 			   several iterations. */
-			char *zeros = kmalloc(to_paste * UNFM_P_SIZE, GFP_ATOMIC);	// We cannot insert more than MAX_ITEM_LEN bytes anyway.
+			char *zeros = kzalloc(to_paste * UNFM_P_SIZE, GFP_ATOMIC);	// We cannot insert more than MAX_ITEM_LEN bytes anyway.
 			if (!zeros) {
 				res = -ENOMEM;
 				goto error_exit_free_blocks;
 			}
-			memset(zeros, 0, to_paste * UNFM_P_SIZE);
 			do {
 				to_paste =
 				    min_t(__u64, hole_size,

commit de21c57b90b3716f6f951e88e039d00ab6729ce9
Author: Alexey Dobriyan <adobriyan@openvz.org>
Date:   Wed Dec 6 20:38:02 2006 -0800

    [PATCH] reiserfs: add missing D-cache flushing
    
    Looks like, reiserfs_prepare_file_region_for_write() doesn't contain
    several flush_dcache_page() calls.
    
    Found with help from Dmitriy Monakhov <dmonakhov@openvz.org>
    
    [akpm@osdl.org: small speedup]
    Signed-off-by: Alexey Dobriyan <adobriyan@openvz.org>
    Cc: Dmitriy Monakhov <dmonakhov@openvz.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index ac14318c81ba..6526498949d8 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1045,6 +1045,7 @@ static int reiserfs_prepare_file_region_for_write(struct inode *inode
 			char *kaddr = kmap_atomic(prepared_pages[0], KM_USER0);
 			memset(kaddr, 0, from);
 			kunmap_atomic(kaddr, KM_USER0);
+			flush_dcache_page(prepared_pages[0]);
 		}
 		if (to != PAGE_CACHE_SIZE) {	/* Last page needs to be partially zeroed */
 			char *kaddr =
@@ -1052,6 +1053,7 @@ static int reiserfs_prepare_file_region_for_write(struct inode *inode
 					KM_USER0);
 			memset(kaddr + to, 0, PAGE_CACHE_SIZE - to);
 			kunmap_atomic(kaddr, KM_USER0);
+			flush_dcache_page(prepared_pages[num_pages - 1]);
 		}
 
 		/* Since all blocks are new - use already calculated value */
@@ -1185,6 +1187,7 @@ static int reiserfs_prepare_file_region_for_write(struct inode *inode
 					memset(kaddr + block_start, 0,
 					       from - block_start);
 					kunmap_atomic(kaddr, KM_USER0);
+					flush_dcache_page(prepared_pages[0]);
 					set_buffer_uptodate(bh);
 				}
 			}
@@ -1222,6 +1225,7 @@ static int reiserfs_prepare_file_region_for_write(struct inode *inode
 							KM_USER0);
 					memset(kaddr + to, 0, block_end - to);
 					kunmap_atomic(kaddr, KM_USER0);
+					flush_dcache_page(prepared_pages[num_pages - 1]);
 					set_buffer_uptodate(bh);
 				}
 			}

commit 533221fbaf001692d5db646f84f7d033fac78cc7
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Sat Nov 25 11:09:30 2006 -0800

    [PATCH] reiserfs: fmt bugfix
    
    One reiserfs_warning() call uses %lu, but doesn't supply what to print.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index b67ce9354048..ac14318c81ba 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -74,7 +74,8 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 			igrab(inode);
 			reiserfs_warning(inode->i_sb,
 					 "pinning inode %lu because the "
-					 "preallocation can't be freed");
+					 "preallocation can't be freed",
+					 inode->i_ino);
 			goto out;
 		}
 	}

commit 038b0a6d8d32db934bba6a24e74e76e4e327a94f
Author: Dave Jones <davej@redhat.com>
Date:   Wed Oct 4 03:38:54 2006 -0400

    Remove all inclusions of <linux/config.h>
    kbuild explicitly includes this at build time.
    
    Signed-off-by: Dave Jones <davej@redhat.com>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index c093642fb983..b67ce9354048 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -2,7 +2,6 @@
  * Copyright 2000 by Hans Reiser, licensing governed by reiserfs/README
  */
 
-#include <linux/config.h>
 #include <linux/time.h>
 #include <linux/reiserfs_fs.h>
 #include <linux/reiserfs_acl.h>

commit 14a61442c2203d2a49f2f954bfa9259c0ddac1aa
Author: Eric Sesterhenn <snakebyte@gmx.de>
Date:   Tue Oct 3 23:36:38 2006 +0200

    BUG_ON conversion for fs/reiserfs
    
    This patch converts several if () BUG(); construct to BUG_ON();
    which occupies less space, uses unlikely and is safer when
    BUG() is disabled. S_ISREG() has no side effects, so the
    conversion is safe.
    
    Signed-off-by: Eric Sesterhenn <snakebyte@gmx.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 41f24369e47a..c093642fb983 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -38,8 +38,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 	int err;
 	int jbegin_failure = 0;
 
-	if (!S_ISREG(inode->i_mode))
-		BUG();
+	BUG_ON(!S_ISREG(inode->i_mode));
 
 	/* fast out for when nothing needs to be done */
 	if ((atomic_read(&inode->i_count) > 1 ||
@@ -125,8 +124,7 @@ static int reiserfs_sync_file(struct file *p_s_filp,
 	int n_err;
 	int barrier_done;
 
-	if (!S_ISREG(p_s_inode->i_mode))
-		BUG();
+	BUG_ON(!S_ISREG(p_s_inode->i_mode));
 	n_err = sync_mapping_buffers(p_s_inode->i_mapping);
 	reiserfs_write_lock(p_s_inode->i_sb);
 	barrier_done = reiserfs_commit_for_inode(p_s_inode);

commit 027445c37282bc1ed26add45e573ad2d3e4860a5
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Sat Sep 30 23:28:46 2006 -0700

    [PATCH] Vectorize aio_read/aio_write fileop methods
    
    This patch vectorizes aio_read() and aio_write() methods to prepare for
    collapsing all aio & vectored operations into one interface - which is
    aio_read()/aio_write().
    
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Michael Holzheu <HOLZHEU@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index c11f6118c9ca..41f24369e47a 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1334,7 +1334,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 			if (err)
 				return err;
 		}
-		result = generic_file_write(file, buf, count, ppos);
+		result = do_sync_write(file, buf, count, ppos);
 
 		if (after_file_end) {	/* Now update i_size and remove the savelink */
 			struct reiserfs_transaction_handle th;
@@ -1566,7 +1566,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 }
 
 const struct file_operations reiserfs_file_operations = {
-	.read = generic_file_read,
+	.read = do_sync_read,
 	.write = reiserfs_file_write,
 	.ioctl = reiserfs_ioctl,
 #ifdef CONFIG_COMPAT

commit 5a2618e6a972f305496daa257a56a09dd3acca29
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Sat Sep 30 23:28:44 2006 -0700

    [PATCH] reiserfs: use generic_file_open for open() checks
    
    The other common disk-based file systems (I checked ext[23], xfs, jfs)
    check to ensure that opens of files > 2 GB fail unless O_LARGEFILE is
    specified.  They check via generic_file_open or their own open routine.
    
    ReiserFS doesn't have an f_op->open defined, and as such, it's possible to
    open files > 2 GB without O_LARGEFILE.
    
    This patch adds the f_op->open member to conform with the expected
    behavior.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Cc: <reiserfs-dev@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 3e08f7161a3d..c11f6118c9ca 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1573,6 +1573,7 @@ const struct file_operations reiserfs_file_operations = {
 	.compat_ioctl = reiserfs_compat_ioctl,
 #endif
 	.mmap = generic_file_mmap,
+	.open = generic_file_open,
 	.release = reiserfs_file_release,
 	.fsync = reiserfs_sync_file,
 	.sendfile = generic_file_sendfile,

commit 52b499c438ff60991eb3855ca090782569b3e8cf
Author: David Howells <dhowells@redhat.com>
Date:   Tue Aug 29 19:06:18 2006 +0100

    [PATCH] BLOCK: Move the ReiserFS device ioctl compat stuff to the ReiserFS driver [try #6]
    
    Move the ReiserFS device ioctl compat stuff from fs/compat_ioctl.c to the
    ReiserFS driver so that the ReiserFS header file doesn't need to be included.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 1cfbe857ba27..3e08f7161a3d 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -2,6 +2,7 @@
  * Copyright 2000 by Hans Reiser, licensing governed by reiserfs/README
  */
 
+#include <linux/config.h>
 #include <linux/time.h>
 #include <linux/reiserfs_fs.h>
 #include <linux/reiserfs_acl.h>
@@ -1568,6 +1569,9 @@ const struct file_operations reiserfs_file_operations = {
 	.read = generic_file_read,
 	.write = reiserfs_file_write,
 	.ioctl = reiserfs_ioctl,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl = reiserfs_compat_ioctl,
+#endif
 	.mmap = generic_file_mmap,
 	.release = reiserfs_file_release,
 	.fsync = reiserfs_sync_file,

commit 25736b1c692d436508585d1d710912e6f76be2d8
Author: Chris Mason <mason@suse.com>
Date:   Fri Sep 29 01:59:54 2006 -0700

    [PATCH] reiserfs_fsync should only use barriers when they are enabled
    
    make sure that reiserfs_fsync only triggers barriers when mounted with -o
    barrier=flush
    
    Signed-off-by: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 1627edd50810..1cfbe857ba27 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -130,7 +130,7 @@ static int reiserfs_sync_file(struct file *p_s_filp,
 	reiserfs_write_lock(p_s_inode->i_sb);
 	barrier_done = reiserfs_commit_for_inode(p_s_inode);
 	reiserfs_write_unlock(p_s_inode->i_sb);
-	if (barrier_done != 1)
+	if (barrier_done != 1 && reiserfs_barrier_flush(p_s_inode->i_sb))
 		blkdev_issue_flush(p_s_inode->i_sb->s_bdev, NULL);
 	if (barrier_done < 0)
 		return barrier_done;

commit b5f3953c10b27fcd1c83e199e573b41d8327e22e
Author: Chris Mason <mason@suse.com>
Date:   Sat Aug 5 12:15:08 2006 -0700

    [PATCH] fix reiserfs lock inversion of bkl vs inode semaphore
    
    The correct lock ordering is inode lock -> BKL
    
    Signed-off-by: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index f318b58510fd..1627edd50810 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -48,8 +48,8 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 		return 0;
 	}
 
-	reiserfs_write_lock(inode->i_sb);
 	mutex_lock(&inode->i_mutex);
+	reiserfs_write_lock(inode->i_sb);
 	/* freeing preallocation only involves relogging blocks that
 	 * are already in the current transaction.  preallocation gets
 	 * freed at the end of each transaction, so it is impossible for

commit 73ce5934e2d855db436566297f12966eb507a435
Author: Hisashi Hifumi <hifumi.hisashi@oss.ntt.co.jp>
Date:   Mon Jul 10 04:43:56 2006 -0700

    [PATCH] reiserfs: fix journaling issue regarding fsync()
    
    When write() extends a file(i_size is increased) and fsync() is called,
    change of inode must be written to journaling area through fsync().
    But,currently the i_trans_id is not correctly updated when i_size is
    increased.  So fsync() does not kick the journal writer.
    
    Reiserfs_file_write() already updates the transaction when blocks are
    allocated, but the case when i_size increases and new blocks are not added
    is not correctly treated.
    
    Following patch fix this bug.
    
    Signed-off-by: Hisashi Hifumi <hifumi.hisashi@oss.ntt.co.jp>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <mason@suse.com>
    Cc: Hans Reiser <reiser@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 752cea12e30f..f318b58510fd 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -860,8 +860,12 @@ static int reiserfs_submit_file_region_for_write(struct reiserfs_transaction_han
 			// this sets the proper flags for O_SYNC to trigger a commit
 			mark_inode_dirty(inode);
 			reiserfs_write_unlock(inode->i_sb);
-		} else
+		} else {
+			reiserfs_write_lock(inode->i_sb);
+			reiserfs_update_inode_transaction(inode);
 			mark_inode_dirty(inode);
+			reiserfs_write_unlock(inode->i_sb);
+		}
 
 		sd_update = 1;
 	}

commit 9637f28f8b9facff53b00bea6b5d27c9b150b422
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Mon Jun 26 00:24:57 2006 -0700

    [PATCH] reiserfs: remove reiserfs_aio_write()
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: <reiserfs-dev@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index cf6e1cf40351..752cea12e30f 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1560,12 +1560,6 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 	return res;
 }
 
-static ssize_t reiserfs_aio_write(struct kiocb *iocb, const char __user * buf,
-				  size_t count, loff_t pos)
-{
-	return generic_file_aio_write(iocb, buf, count, pos);
-}
-
 const struct file_operations reiserfs_file_operations = {
 	.read = generic_file_read,
 	.write = reiserfs_file_write,
@@ -1575,7 +1569,7 @@ const struct file_operations reiserfs_file_operations = {
 	.fsync = reiserfs_sync_file,
 	.sendfile = generic_file_sendfile,
 	.aio_read = generic_file_aio_read,
-	.aio_write = reiserfs_aio_write,
+	.aio_write = generic_file_aio_write,
 	.splice_read = generic_file_splice_read,
 	.splice_write = generic_file_splice_write,
 };

commit 5274f052e7b3dbd81935772eb551dfd0325dfa9d
Author: Jens Axboe <axboe@suse.de>
Date:   Thu Mar 30 15:15:30 2006 +0200

    [PATCH] Introduce sys_splice() system call
    
    This adds support for the sys_splice system call. Using a pipe as a
    transport, it can connect to files or sockets (latter as output only).
    
    From the splice.c comments:
    
       "splice": joining two ropes together by interweaving their strands.
    
       This is the "extended pipe" functionality, where a pipe is used as
       an arbitrary in-memory buffer. Think of a pipe as a small kernel
       buffer that you can use to transfer data from one end to the other.
    
       The traditional unix read/write is extended with a "splice()" operation
       that transfers data buffers to or from a pipe buffer.
    
       Named by Larry McVoy, original implementation from Linus, extended by
       Jens to support splicing to files and fixing the initial implementation
       bugs.
    
    Signed-off-by: Jens Axboe <axboe@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 010094d14da6..cf6e1cf40351 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1576,6 +1576,8 @@ const struct file_operations reiserfs_file_operations = {
 	.sendfile = generic_file_sendfile,
 	.aio_read = generic_file_aio_read,
 	.aio_write = reiserfs_aio_write,
+	.splice_read = generic_file_splice_read,
+	.splice_write = generic_file_splice_write,
 };
 
 struct inode_operations reiserfs_file_inode_operations = {

commit 4b6f5d20b04dcbc3d888555522b90ba6d36c4106
Author: Arjan van de Ven <arjan@infradead.org>
Date:   Tue Mar 28 01:56:42 2006 -0800

    [PATCH] Make most file operations structs in fs/ const
    
    This is a conversion to make the various file_operations structs in fs/
    const.  Basically a regexp job, with a few manual fixups
    
    The goal is both to increase correctness (harder to accidentally write to
    shared datastructures) and reducing the false sharing of cachelines with
    things that get dirty in .data (while .rodata is nicely read only and thus
    cache clean)
    
    Signed-off-by: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index d0c1e865963e..010094d14da6 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1566,7 +1566,7 @@ static ssize_t reiserfs_aio_write(struct kiocb *iocb, const char __user * buf,
 	return generic_file_aio_write(iocb, buf, count, pos);
 }
 
-struct file_operations reiserfs_file_operations = {
+const struct file_operations reiserfs_file_operations = {
 	.read = generic_file_read,
 	.write = reiserfs_file_write,
 	.ioctl = reiserfs_ioctl,

commit 5930860296ca438071d3824bf7306ad0dfd33fc1
Author: Alexander Zarochentsev <zam@namesys.com>
Date:   Sat Mar 25 03:07:16 2006 -0800

    [PATCH] reiserfs: use balance_dirty_pages_ratelimited_nr in reiserfs_file_write()
    
    Use the new balance_dirty_pages_ratelimited_nr in reiserfs "largeio" file
    write.
    
    Signed-off-by: Hans Reiser <reiser@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 044de8be39a7..d0c1e865963e 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1532,7 +1532,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 		buf += write_bytes;
 		*ppos = pos += write_bytes;
 		count -= write_bytes;
-		balance_dirty_pages_ratelimited(inode->i_mapping);
+		balance_dirty_pages_ratelimited_nr(inode->i_mapping, num_pages);
 	}
 
 	/* this is only true on error */

commit 619d5d8a2b3f800ea3a0301a58ede570684956b0
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Sat Mar 25 03:07:00 2006 -0800

    [PATCH] reiserfs: reiserfs_file_write() will lose error code when a 0-length write occurs w/ O_SYNC
    
    When an error occurs in reiserfs_file_write before any data is written, and
    O_SYNC is set, the return code of generic_osync_write will overwrite the
    error code, losing it.
    
    This patch ensures that generic_osync_inode() doesn't run under an error
    condition, losing the error.  This duplicates the logic from
    generic_file_buffered_write().
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <mason@suse.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Alexander Zarochentsev <zam@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index be12879bb179..044de8be39a7 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1546,10 +1546,10 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 		}
 	}
 
-	if ((file->f_flags & O_SYNC) || IS_SYNC(inode))
-		res =
-		    generic_osync_inode(inode, file->f_mapping,
-					OSYNC_METADATA | OSYNC_DATA);
+	if (likely(res >= 0) &&
+	    (unlikely((file->f_flags & O_SYNC) || IS_SYNC(inode))))
+		res = generic_osync_inode(inode, file->f_mapping,
+		                          OSYNC_METADATA | OSYNC_DATA);
 
 	mutex_unlock(&inode->i_mutex);
 	reiserfs_async_progress_wait(inode->i_sb);

commit c499ec24c31edf270e777a868ffd0daddcfe7ebd
Author: Vladimir V. Saveliev <vs@namesys.com>
Date:   Thu Mar 2 02:54:39 2006 -0800

    [PATCH] reiserfs: do not check if unsigned < 0
    
    This patch fixes bugs in reiserfs where unsigned integers were checked
    whether they are less then 0.
    
    Signed-off-by: Vladimir V. Saveliev <vs@namesys.com>
    Cc: Neil Brown <neilb@cse.unsw.edu.au>
    Signed-off-by: Hans Reiser <reiser@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index f3473176c83a..be12879bb179 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1464,13 +1464,11 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 		   partially overwritten pages, if needed. And lock the pages,
 		   so that nobody else can access these until we are done.
 		   We get number of actual blocks needed as a result. */
-		blocks_to_allocate =
-		    reiserfs_prepare_file_region_for_write(inode, pos,
-							   num_pages,
-							   write_bytes,
-							   prepared_pages);
-		if (blocks_to_allocate < 0) {
-			res = blocks_to_allocate;
+		res = reiserfs_prepare_file_region_for_write(inode, pos,
+							     num_pages,
+							     write_bytes,
+							     prepared_pages);
+		if (res < 0) {
 			reiserfs_release_claimed_blocks(inode->i_sb,
 							num_pages <<
 							(PAGE_CACHE_SHIFT -
@@ -1478,6 +1476,8 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 			break;
 		}
 
+		blocks_to_allocate = res;
+
 		/* First we correct our estimate of how many blocks we need */
 		reiserfs_release_claimed_blocks(inode->i_sb,
 						(num_pages <<

commit fa385bef256077f3b820b241e8f3755ef3905b74
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Feb 1 03:06:51 2006 -0800

    [PATCH] reiserfs: reiserfs: check for files > 2GB on 3.5.x disks
    
    When a filesystem has been converted from 3.5.x to 3.6.x, we need an extra
    check during file write to make sure we are not trying to make a 3.5.x file
    > 2GB.
    
    Signed-off-by: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 1cad5d066a5c..f3473176c83a 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1287,6 +1287,23 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 	struct reiserfs_transaction_handle th;
 	th.t_trans_id = 0;
 
+	/* If a filesystem is converted from 3.5 to 3.6, we'll have v3.5 items
+	* lying around (most of the disk, in fact). Despite the filesystem
+	* now being a v3.6 format, the old items still can't support large
+	* file sizes. Catch this case here, as the rest of the VFS layer is
+	* oblivious to the different limitations between old and new items.
+	* reiserfs_setattr catches this for truncates. This chunk is lifted
+	* from generic_write_checks. */
+	if (get_inode_item_key_version (inode) == KEY_FORMAT_3_5 &&
+	    *ppos + count > MAX_NON_LFS) {
+		if (*ppos >= MAX_NON_LFS) {
+			send_sig(SIGXFSZ, current, 0);
+			return -EFBIG;
+		}
+		if (count > MAX_NON_LFS - (unsigned long)*ppos)
+			count = MAX_NON_LFS - (unsigned long)*ppos;
+	}
+
 	if (file->f_flags & O_DIRECT) {	// Direct IO needs treatment
 		ssize_t result, after_file_end = 0;
 		if ((*ppos + count >= inode->i_size)

commit e5dd259f78ba0fd0c7bfc5c52179dbbff3eb48aa
Author: Diego Calleja <diegocg@gmail.com>
Date:   Wed Feb 1 03:06:44 2006 -0800

    [PATCH] reiserfs: missing kmalloc failure check
    
    According to http://bugzilla.kernel.org/show_bug.cgi?id=5778
    fs/reiserfs/file.c is missing this check.
    
    Signed-off-by: Diego Calleja <diegocg@gmail.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index ad6fa964b0e7..1cad5d066a5c 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -192,6 +192,8 @@ static int reiserfs_allocate_blocks_for_region(struct reiserfs_transaction_handl
 
 	allocated_blocks = kmalloc((blocks_to_allocate + will_prealloc) *
 				   sizeof(b_blocknr_t), GFP_NOFS);
+	if (!allocated_blocks)
+		return -ENOMEM;
 
 	/* First we compose a key to point at the writing position, we want to do
 	   that outside of any locking region. */

commit 870f481793b585323fbda3e87c54efc116f46351
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jan 9 20:52:01 2006 -0800

    [PATCH] replace inode_update_time with file_update_time
    
    To allow various options to work per-mount instead of per-sb we need a
    struct vfsmount when updating ctime and mtime.  This preparation patch
    replaces the inode_update_time routine with a file_update_atime routine so
    we can easily get at the vfsmount.  (and the file makes more sense in this
    context anyway).  Also get rid of the unused second argument - we always
    want to update the ctime when calling this routine.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@ftp.linux.org.uk>
    Cc: Anton Altaparmakov <aia21@cantab.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 127e7d2cabdd..ad6fa964b0e7 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1360,7 +1360,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 	if (res)
 		goto out;
 
-	inode_update_time(inode, 1);	/* Both mtime and ctime */
+	file_update_time(file);
 
 	// Ok, we are done with all the checks.
 

commit 1b1dcc1b57a49136f118a0f16367256ff9994a69
Author: Jes Sorensen <jes@sgi.com>
Date:   Mon Jan 9 15:59:24 2006 -0800

    [PATCH] mutex subsystem, semaphore to mutex: VFS, ->i_sem
    
    This patch converts the inode semaphore to a mutex. I have tested it on
    XFS and compiled as much as one can consider on an ia64. Anyway your
    luck with it might be different.
    
    Modified-by: Ingo Molnar <mingo@elte.hu>
    
    (finished the conversion)
    
    Signed-off-by: Jes Sorensen <jes@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 7892a865b58a..127e7d2cabdd 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -49,7 +49,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 	}
 
 	reiserfs_write_lock(inode->i_sb);
-	down(&inode->i_sem);
+	mutex_lock(&inode->i_mutex);
 	/* freeing preallocation only involves relogging blocks that
 	 * are already in the current transaction.  preallocation gets
 	 * freed at the end of each transaction, so it is impossible for
@@ -100,7 +100,7 @@ static int reiserfs_file_release(struct inode *inode, struct file *filp)
 		err = reiserfs_truncate_file(inode, 0);
 	}
       out:
-	up(&inode->i_sem);
+	mutex_unlock(&inode->i_mutex);
 	reiserfs_write_unlock(inode->i_sb);
 	return err;
 }
@@ -1342,7 +1342,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 	if (unlikely(!access_ok(VERIFY_READ, buf, count)))
 		return -EFAULT;
 
-	down(&inode->i_sem);	// locks the entire file for just us
+	mutex_lock(&inode->i_mutex);	// locks the entire file for just us
 
 	pos = *ppos;
 
@@ -1532,12 +1532,12 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 		    generic_osync_inode(inode, file->f_mapping,
 					OSYNC_METADATA | OSYNC_DATA);
 
-	up(&inode->i_sem);
+	mutex_unlock(&inode->i_mutex);
 	reiserfs_async_progress_wait(inode->i_sb);
 	return (already_written != 0) ? already_written : res;
 
       out:
-	up(&inode->i_sem);	// unlock the file on exit.
+	mutex_unlock(&inode->i_mutex);	// unlock the file on exit.
 	return res;
 }
 

commit 0ad74ffa90fb20b4132ae6e67e473f24621c6af2
Author: Jan Kara <jack@suse.cz>
Date:   Tue Nov 8 21:34:58 2005 -0800

    [PATCH] Fix return value in reiserfs allocator
    
    Make reiserfs correctly return EDQUOT when the allocation failed due to
    quotas (so far we just returned ENOSPC).
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index c20babd6216d..7892a865b58a 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -251,12 +251,12 @@ static int reiserfs_allocate_blocks_for_region(struct reiserfs_transaction_handl
 						       blocks_to_allocate,
 						       blocks_to_allocate);
 			if (res != CARRY_ON) {
-				res = -ENOSPC;
+				res = res == QUOTA_EXCEEDED ? -EDQUOT : -ENOSPC;
 				pathrelse(&path);
 				goto error_exit;
 			}
 		} else {
-			res = -ENOSPC;
+			res = res == QUOTA_EXCEEDED ? -EDQUOT : -ENOSPC;
 			pathrelse(&path);
 			goto error_exit;
 		}

commit 9f03783ce5d851e4b98dfaf3e9eb177870f6c75d
Author: Chris Mason <mason@suse.com>
Date:   Tue Sep 13 01:25:17 2005 -0700

    [PATCH] reiserfs: use mark_inode_dirty instead of reiserfs_update_sd
    
    reiserfs should use mark_inode_dirty during reiserfs_file_write and
    reiserfs_commit_write.  This makes sure the inode is properly flagged as
    dirty, which is used during O_SYNC to decide when to trigger log commits.
    
    This patch also removes the O_SYNC check from reiserfs_commit_write, since
    that gets dealt with properly at higher layers once we start using
    mark_inode_dirty.
    
    Thanks to Hifumi Hisashi <hifumi.hisashi@lab.ntt.co.jp> for catching this.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index c9f178fb494f..c20babd6216d 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -667,7 +667,7 @@ static int reiserfs_allocate_blocks_for_region(struct reiserfs_transaction_handl
 	if (th->t_trans_id) {
 		int err;
 		// update any changes we made to blk count
-		reiserfs_update_sd(th, inode);
+		mark_inode_dirty(inode);
 		err =
 		    journal_end(th, inode->i_sb,
 				JOURNAL_PER_BALANCE_CNT * 3 + 1 +
@@ -855,17 +855,18 @@ static int reiserfs_submit_file_region_for_write(struct reiserfs_transaction_han
 
 		if (th->t_trans_id) {
 			reiserfs_write_lock(inode->i_sb);
-			reiserfs_update_sd(th, inode);	// And update on-disk metadata
+			// this sets the proper flags for O_SYNC to trigger a commit
+			mark_inode_dirty(inode);
 			reiserfs_write_unlock(inode->i_sb);
 		} else
-			inode->i_sb->s_op->dirty_inode(inode);
+			mark_inode_dirty(inode);
 
 		sd_update = 1;
 	}
 	if (th->t_trans_id) {
 		reiserfs_write_lock(inode->i_sb);
 		if (!sd_update)
-			reiserfs_update_sd(th, inode);
+			mark_inode_dirty(inode);
 		status = journal_end(th, th->t_super, th->t_blocks_allocated);
 		if (status)
 			retval = status;
@@ -1320,7 +1321,7 @@ static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going t
 				return err;
 			}
 			reiserfs_update_inode_transaction(inode);
-			reiserfs_update_sd(&th, inode);
+			mark_inode_dirty(inode);
 			err = journal_end(&th, inode->i_sb, 1);
 			if (err) {
 				reiserfs_write_unlock(inode->i_sb);

commit bd4c625c061c2a38568d0add3478f59172455159
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Tue Jul 12 20:21:28 2005 -0700

    reiserfs: run scripts/Lindent on reiserfs code
    
    This was a pure indentation change, using:
    
            scripts/Lindent fs/reiserfs/*.c include/linux/reiserfs_*.h
    
    to make reiserfs match the regular Linux indentation style.  As Jeff
    Mahoney <jeffm@suse.com> writes:
    
     The ReiserFS code is a mix of a number of different coding styles, sometimes
     different even from line-to-line. Since the code has been relatively stable
     for quite some time and there are few outstanding patches to be applied, it
     is time to reformat the code to conform to the Linux style standard outlined
     in Documentation/CodingStyle.
    
     This patch contains the result of running scripts/Lindent against
     fs/reiserfs/*.c and include/linux/reiserfs_*.h. There are places where the
     code can be made to look better, but I'd rather keep those patches separate
     so that there isn't a subtle by-hand hand accident in the middle of a huge
     patch. To be clear: This patch is reformatting *only*.
    
     A number of patches may follow that continue to make the code more consistent
     with the Linux coding style.
    
     Hans wasn't particularly enthusiastic about these patches, but said he
     wouldn't really oppose them either.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 12e91209544e..c9f178fb494f 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -2,7 +2,6 @@
  * Copyright 2000 by Hans Reiser, licensing governed by reiserfs/README
  */
 
-
 #include <linux/time.h>
 #include <linux/reiserfs_fs.h>
 #include <linux/reiserfs_acl.h>
@@ -31,82 +30,84 @@
 ** We use reiserfs_truncate_file to pack the tail, since it already has
 ** all the conditions coded.  
 */
-static int reiserfs_file_release (struct inode * inode, struct file * filp)
+static int reiserfs_file_release(struct inode *inode, struct file *filp)
 {
 
-    struct reiserfs_transaction_handle th ;
-    int err;
-    int jbegin_failure = 0;
+	struct reiserfs_transaction_handle th;
+	int err;
+	int jbegin_failure = 0;
 
-    if (!S_ISREG (inode->i_mode))
-	BUG ();
+	if (!S_ISREG(inode->i_mode))
+		BUG();
 
-    /* fast out for when nothing needs to be done */
-    if ((atomic_read(&inode->i_count) > 1 ||
-	!(REISERFS_I(inode)->i_flags & i_pack_on_close_mask) || 
-         !tail_has_to_be_packed(inode))       && 
-	REISERFS_I(inode)->i_prealloc_count <= 0) {
-	return 0;
-    }    
-    
-    reiserfs_write_lock(inode->i_sb);
-    down (&inode->i_sem); 
-    /* freeing preallocation only involves relogging blocks that
-     * are already in the current transaction.  preallocation gets
-     * freed at the end of each transaction, so it is impossible for
-     * us to log any additional blocks (including quota blocks)
-     */
-    err = journal_begin(&th, inode->i_sb, 1);
-    if (err) {
-	/* uh oh, we can't allow the inode to go away while there
-	 * is still preallocation blocks pending.  Try to join the
-	 * aborted transaction
-	 */
-	jbegin_failure = err;
-	err = journal_join_abort(&th, inode->i_sb, 1);
+	/* fast out for when nothing needs to be done */
+	if ((atomic_read(&inode->i_count) > 1 ||
+	     !(REISERFS_I(inode)->i_flags & i_pack_on_close_mask) ||
+	     !tail_has_to_be_packed(inode)) &&
+	    REISERFS_I(inode)->i_prealloc_count <= 0) {
+		return 0;
+	}
 
+	reiserfs_write_lock(inode->i_sb);
+	down(&inode->i_sem);
+	/* freeing preallocation only involves relogging blocks that
+	 * are already in the current transaction.  preallocation gets
+	 * freed at the end of each transaction, so it is impossible for
+	 * us to log any additional blocks (including quota blocks)
+	 */
+	err = journal_begin(&th, inode->i_sb, 1);
 	if (err) {
-	    /* hmpf, our choices here aren't good.  We can pin the inode
-	     * which will disallow unmount from every happening, we can
-	     * do nothing, which will corrupt random memory on unmount,
-	     * or we can forcibly remove the file from the preallocation
-	     * list, which will leak blocks on disk.  Lets pin the inode
-	     * and let the admin know what is going on.
-	     */
-	    igrab(inode);
-	    reiserfs_warning(inode->i_sb, "pinning inode %lu because the "
-	                     "preallocation can't be freed");
-	    goto out;
+		/* uh oh, we can't allow the inode to go away while there
+		 * is still preallocation blocks pending.  Try to join the
+		 * aborted transaction
+		 */
+		jbegin_failure = err;
+		err = journal_join_abort(&th, inode->i_sb, 1);
+
+		if (err) {
+			/* hmpf, our choices here aren't good.  We can pin the inode
+			 * which will disallow unmount from every happening, we can
+			 * do nothing, which will corrupt random memory on unmount,
+			 * or we can forcibly remove the file from the preallocation
+			 * list, which will leak blocks on disk.  Lets pin the inode
+			 * and let the admin know what is going on.
+			 */
+			igrab(inode);
+			reiserfs_warning(inode->i_sb,
+					 "pinning inode %lu because the "
+					 "preallocation can't be freed");
+			goto out;
+		}
 	}
-    }
-    reiserfs_update_inode_transaction(inode) ;
+	reiserfs_update_inode_transaction(inode);
 
 #ifdef REISERFS_PREALLOCATE
-    reiserfs_discard_prealloc (&th, inode);
+	reiserfs_discard_prealloc(&th, inode);
 #endif
-    err = journal_end(&th, inode->i_sb, 1);
-
-    /* copy back the error code from journal_begin */
-    if (!err)
-        err = jbegin_failure;
-
-    if (!err && atomic_read(&inode->i_count) <= 1 &&
-	(REISERFS_I(inode)->i_flags & i_pack_on_close_mask) &&
-        tail_has_to_be_packed (inode)) {
-	/* if regular file is released by last holder and it has been
-	   appended (we append by unformatted node only) or its direct
-	   item(s) had to be converted, then it may have to be
-	   indirect2direct converted */
-	err = reiserfs_truncate_file(inode, 0) ;
-    }
-out:
-    up (&inode->i_sem); 
-    reiserfs_write_unlock(inode->i_sb);
-    return err;
+	err = journal_end(&th, inode->i_sb, 1);
+
+	/* copy back the error code from journal_begin */
+	if (!err)
+		err = jbegin_failure;
+
+	if (!err && atomic_read(&inode->i_count) <= 1 &&
+	    (REISERFS_I(inode)->i_flags & i_pack_on_close_mask) &&
+	    tail_has_to_be_packed(inode)) {
+		/* if regular file is released by last holder and it has been
+		   appended (we append by unformatted node only) or its direct
+		   item(s) had to be converted, then it may have to be
+		   indirect2direct converted */
+		err = reiserfs_truncate_file(inode, 0);
+	}
+      out:
+	up(&inode->i_sem);
+	reiserfs_write_unlock(inode->i_sb);
+	return err;
 }
 
-static void reiserfs_vfs_truncate_file(struct inode *inode) {
-    reiserfs_truncate_file(inode, 1) ;
+static void reiserfs_vfs_truncate_file(struct inode *inode)
+{
+	reiserfs_truncate_file(inode, 1);
 }
 
 /* Sync a reiserfs file. */
@@ -116,26 +117,24 @@ static void reiserfs_vfs_truncate_file(struct inode *inode) {
  * be removed...
  */
 
-static int reiserfs_sync_file(
-			      struct file   * p_s_filp,
-			      struct dentry * p_s_dentry,
-			      int datasync
-			      ) {
-  struct inode * p_s_inode = p_s_dentry->d_inode;
-  int n_err;
-  int barrier_done;
-
-  if (!S_ISREG(p_s_inode->i_mode))
-      BUG ();
-  n_err = sync_mapping_buffers(p_s_inode->i_mapping) ;
-  reiserfs_write_lock(p_s_inode->i_sb);
-  barrier_done = reiserfs_commit_for_inode(p_s_inode);
-  reiserfs_write_unlock(p_s_inode->i_sb);
-  if (barrier_done != 1)
-      blkdev_issue_flush(p_s_inode->i_sb->s_bdev, NULL);
-  if (barrier_done < 0)
-    return barrier_done;
-  return ( n_err < 0 ) ? -EIO : 0;
+static int reiserfs_sync_file(struct file *p_s_filp,
+			      struct dentry *p_s_dentry, int datasync)
+{
+	struct inode *p_s_inode = p_s_dentry->d_inode;
+	int n_err;
+	int barrier_done;
+
+	if (!S_ISREG(p_s_inode->i_mode))
+		BUG();
+	n_err = sync_mapping_buffers(p_s_inode->i_mapping);
+	reiserfs_write_lock(p_s_inode->i_sb);
+	barrier_done = reiserfs_commit_for_inode(p_s_inode);
+	reiserfs_write_unlock(p_s_inode->i_sb);
+	if (barrier_done != 1)
+		blkdev_issue_flush(p_s_inode->i_sb->s_bdev, NULL);
+	if (barrier_done < 0)
+		return barrier_done;
+	return (n_err < 0) ? -EIO : 0;
 }
 
 /* I really do not want to play with memory shortage right now, so
@@ -147,700 +146,797 @@ static int reiserfs_sync_file(
 /* Allocates blocks for a file to fulfil write request.
    Maps all unmapped but prepared pages from the list.
    Updates metadata with newly allocated blocknumbers as needed */
-static int reiserfs_allocate_blocks_for_region(
-				struct reiserfs_transaction_handle *th,
-				struct inode *inode, /* Inode we work with */
-				loff_t pos, /* Writing position */
-				int num_pages, /* number of pages write going
-						  to touch */
-				int write_bytes, /* amount of bytes to write */
-				struct page **prepared_pages, /* array of
-							         prepared pages
-							       */
-				int blocks_to_allocate /* Amount of blocks we
-							  need to allocate to
-							  fit the data into file
-							 */
-				)
+static int reiserfs_allocate_blocks_for_region(struct reiserfs_transaction_handle *th, struct inode *inode,	/* Inode we work with */
+					       loff_t pos,	/* Writing position */
+					       int num_pages,	/* number of pages write going
+								   to touch */
+					       int write_bytes,	/* amount of bytes to write */
+					       struct page **prepared_pages,	/* array of
+										   prepared pages
+										 */
+					       int blocks_to_allocate	/* Amount of blocks we
+									   need to allocate to
+									   fit the data into file
+									 */
+    )
 {
-    struct cpu_key key; // cpu key of item that we are going to deal with
-    struct item_head *ih; // pointer to item head that we are going to deal with
-    struct buffer_head *bh; // Buffer head that contains items that we are going to deal with
-    __le32 * item; // pointer to item we are going to deal with
-    INITIALIZE_PATH(path); // path to item, that we are going to deal with.
-    b_blocknr_t *allocated_blocks; // Pointer to a place where allocated blocknumbers would be stored.
-    reiserfs_blocknr_hint_t hint; // hint structure for block allocator.
-    size_t res; // return value of various functions that we call.
-    int curr_block; // current block used to keep track of unmapped blocks.
-    int i; // loop counter
-    int itempos; // position in item
-    unsigned int from = (pos & (PAGE_CACHE_SIZE - 1)); // writing position in
-						       // first page
-    unsigned int to = ((pos + write_bytes - 1) & (PAGE_CACHE_SIZE - 1)) + 1; /* last modified byte offset in last page */
-    __u64 hole_size ; // amount of blocks for a file hole, if it needed to be created.
-    int modifying_this_item = 0; // Flag for items traversal code to keep track
-				 // of the fact that we already prepared
-				 // current block for journal
-    int will_prealloc = 0;
-    RFALSE(!blocks_to_allocate, "green-9004: tried to allocate zero blocks?");
-
-    /* only preallocate if this is a small write */
-    if (REISERFS_I(inode)->i_prealloc_count ||
-       (!(write_bytes & (inode->i_sb->s_blocksize -1)) &&
-        blocks_to_allocate <
-        REISERFS_SB(inode->i_sb)->s_alloc_options.preallocsize))
-        will_prealloc = REISERFS_SB(inode->i_sb)->s_alloc_options.preallocsize;
-
-    allocated_blocks = kmalloc((blocks_to_allocate + will_prealloc) *
-    					sizeof(b_blocknr_t), GFP_NOFS);
-
-    /* First we compose a key to point at the writing position, we want to do
-       that outside of any locking region. */
-    make_cpu_key (&key, inode, pos+1, TYPE_ANY, 3/*key length*/);
-
-    /* If we came here, it means we absolutely need to open a transaction,
-       since we need to allocate some blocks */
-    reiserfs_write_lock(inode->i_sb); // Journaling stuff and we need that.
-    res = journal_begin(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS(inode->i_sb)); // Wish I know if this number enough
-    if (res)
-        goto error_exit;
-    reiserfs_update_inode_transaction(inode) ;
-
-    /* Look for the in-tree position of our write, need path for block allocator */
-    res = search_for_position_by_key(inode->i_sb, &key, &path);
-    if ( res == IO_ERROR ) {
-	res = -EIO;
-	goto error_exit;
-    }
-   
-    /* Allocate blocks */
-    /* First fill in "hint" structure for block allocator */
-    hint.th = th; // transaction handle.
-    hint.path = &path; // Path, so that block allocator can determine packing locality or whatever it needs to determine.
-    hint.inode = inode; // Inode is needed by block allocator too.
-    hint.search_start = 0; // We have no hint on where to search free blocks for block allocator.
-    hint.key = key.on_disk_key; // on disk key of file.
-    hint.block = inode->i_blocks>>(inode->i_sb->s_blocksize_bits-9); // Number of disk blocks this file occupies already.
-    hint.formatted_node = 0; // We are allocating blocks for unformatted node.
-    hint.preallocate = will_prealloc;
-
-    /* Call block allocator to allocate blocks */
-    res = reiserfs_allocate_blocknrs(&hint, allocated_blocks, blocks_to_allocate, blocks_to_allocate);
-    if ( res != CARRY_ON ) {
-	if ( res == NO_DISK_SPACE ) {
-	    /* We flush the transaction in case of no space. This way some
-	       blocks might become free */
-	    SB_JOURNAL(inode->i_sb)->j_must_wait = 1;
-	    res = restart_transaction(th, inode, &path);
-            if (res)
-                goto error_exit;
-
-	    /* We might have scheduled, so search again */
-	    res = search_for_position_by_key(inode->i_sb, &key, &path);
-	    if ( res == IO_ERROR ) {
-		res = -EIO;
+	struct cpu_key key;	// cpu key of item that we are going to deal with
+	struct item_head *ih;	// pointer to item head that we are going to deal with
+	struct buffer_head *bh;	// Buffer head that contains items that we are going to deal with
+	__le32 *item;		// pointer to item we are going to deal with
+	INITIALIZE_PATH(path);	// path to item, that we are going to deal with.
+	b_blocknr_t *allocated_blocks;	// Pointer to a place where allocated blocknumbers would be stored.
+	reiserfs_blocknr_hint_t hint;	// hint structure for block allocator.
+	size_t res;		// return value of various functions that we call.
+	int curr_block;		// current block used to keep track of unmapped blocks.
+	int i;			// loop counter
+	int itempos;		// position in item
+	unsigned int from = (pos & (PAGE_CACHE_SIZE - 1));	// writing position in
+	// first page
+	unsigned int to = ((pos + write_bytes - 1) & (PAGE_CACHE_SIZE - 1)) + 1;	/* last modified byte offset in last page */
+	__u64 hole_size;	// amount of blocks for a file hole, if it needed to be created.
+	int modifying_this_item = 0;	// Flag for items traversal code to keep track
+	// of the fact that we already prepared
+	// current block for journal
+	int will_prealloc = 0;
+	RFALSE(!blocks_to_allocate,
+	       "green-9004: tried to allocate zero blocks?");
+
+	/* only preallocate if this is a small write */
+	if (REISERFS_I(inode)->i_prealloc_count ||
+	    (!(write_bytes & (inode->i_sb->s_blocksize - 1)) &&
+	     blocks_to_allocate <
+	     REISERFS_SB(inode->i_sb)->s_alloc_options.preallocsize))
+		will_prealloc =
+		    REISERFS_SB(inode->i_sb)->s_alloc_options.preallocsize;
+
+	allocated_blocks = kmalloc((blocks_to_allocate + will_prealloc) *
+				   sizeof(b_blocknr_t), GFP_NOFS);
+
+	/* First we compose a key to point at the writing position, we want to do
+	   that outside of any locking region. */
+	make_cpu_key(&key, inode, pos + 1, TYPE_ANY, 3 /*key length */ );
+
+	/* If we came here, it means we absolutely need to open a transaction,
+	   since we need to allocate some blocks */
+	reiserfs_write_lock(inode->i_sb);	// Journaling stuff and we need that.
+	res = journal_begin(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS(inode->i_sb));	// Wish I know if this number enough
+	if (res)
 		goto error_exit;
-	    }
+	reiserfs_update_inode_transaction(inode);
 
-	    /* update changed info for hint structure. */
-	    res = reiserfs_allocate_blocknrs(&hint, allocated_blocks, blocks_to_allocate, blocks_to_allocate);
-	    if ( res != CARRY_ON ) {
-		res = -ENOSPC; 
-		pathrelse(&path);
+	/* Look for the in-tree position of our write, need path for block allocator */
+	res = search_for_position_by_key(inode->i_sb, &key, &path);
+	if (res == IO_ERROR) {
+		res = -EIO;
 		goto error_exit;
-	    }
-	} else {
-	    res = -ENOSPC;
-	    pathrelse(&path);
-	    goto error_exit;
 	}
-    }
 
-#ifdef __BIG_ENDIAN
-        // Too bad, I have not found any way to convert a given region from
-        // cpu format to little endian format
-    {
-        int i;
-        for ( i = 0; i < blocks_to_allocate ; i++)
-            allocated_blocks[i]=cpu_to_le32(allocated_blocks[i]);
-    }
-#endif
-
-    /* Blocks allocating well might have scheduled and tree might have changed,
-       let's search the tree again */
-    /* find where in the tree our write should go */
-    res = search_for_position_by_key(inode->i_sb, &key, &path);
-    if ( res == IO_ERROR ) {
-	res = -EIO;
-	goto error_exit_free_blocks;
-    }
-
-    bh = get_last_bh( &path ); // Get a bufferhead for last element in path.
-    ih = get_ih( &path );      // Get a pointer to last item head in path.
-    item = get_item( &path );  // Get a pointer to last item in path
-
-    /* Let's see what we have found */
-    if ( res != POSITION_FOUND ) { /* position not found, this means that we
-				      might need to append file with holes
-				      first */
-	// Since we are writing past the file's end, we need to find out if
-	// there is a hole that needs to be inserted before our writing
-	// position, and how many blocks it is going to cover (we need to
-	//  populate pointers to file blocks representing the hole with zeros)
+	/* Allocate blocks */
+	/* First fill in "hint" structure for block allocator */
+	hint.th = th;		// transaction handle.
+	hint.path = &path;	// Path, so that block allocator can determine packing locality or whatever it needs to determine.
+	hint.inode = inode;	// Inode is needed by block allocator too.
+	hint.search_start = 0;	// We have no hint on where to search free blocks for block allocator.
+	hint.key = key.on_disk_key;	// on disk key of file.
+	hint.block = inode->i_blocks >> (inode->i_sb->s_blocksize_bits - 9);	// Number of disk blocks this file occupies already.
+	hint.formatted_node = 0;	// We are allocating blocks for unformatted node.
+	hint.preallocate = will_prealloc;
+
+	/* Call block allocator to allocate blocks */
+	res =
+	    reiserfs_allocate_blocknrs(&hint, allocated_blocks,
+				       blocks_to_allocate, blocks_to_allocate);
+	if (res != CARRY_ON) {
+		if (res == NO_DISK_SPACE) {
+			/* We flush the transaction in case of no space. This way some
+			   blocks might become free */
+			SB_JOURNAL(inode->i_sb)->j_must_wait = 1;
+			res = restart_transaction(th, inode, &path);
+			if (res)
+				goto error_exit;
+
+			/* We might have scheduled, so search again */
+			res =
+			    search_for_position_by_key(inode->i_sb, &key,
+						       &path);
+			if (res == IO_ERROR) {
+				res = -EIO;
+				goto error_exit;
+			}
 
+			/* update changed info for hint structure. */
+			res =
+			    reiserfs_allocate_blocknrs(&hint, allocated_blocks,
+						       blocks_to_allocate,
+						       blocks_to_allocate);
+			if (res != CARRY_ON) {
+				res = -ENOSPC;
+				pathrelse(&path);
+				goto error_exit;
+			}
+		} else {
+			res = -ENOSPC;
+			pathrelse(&path);
+			goto error_exit;
+		}
+	}
+#ifdef __BIG_ENDIAN
+	// Too bad, I have not found any way to convert a given region from
+	// cpu format to little endian format
 	{
-	    int item_offset = 1;
-	    /*
-	     * if ih is stat data, its offset is 0 and we don't want to
-	     * add 1 to pos in the hole_size calculation
-	     */
-	    if (is_statdata_le_ih(ih))
-	        item_offset = 0;
-	    hole_size = (pos + item_offset -
-	            (le_key_k_offset( get_inode_item_key_version(inode),
-		    &(ih->ih_key)) +
-		    op_bytes_number(ih, inode->i_sb->s_blocksize))) >>
-		    inode->i_sb->s_blocksize_bits;
+		int i;
+		for (i = 0; i < blocks_to_allocate; i++)
+			allocated_blocks[i] = cpu_to_le32(allocated_blocks[i]);
 	}
+#endif
 
-	if ( hole_size > 0 ) {
-	    int to_paste = min_t(__u64, hole_size, MAX_ITEM_LEN(inode->i_sb->s_blocksize)/UNFM_P_SIZE ); // How much data to insert first time.
-	    /* area filled with zeroes, to supply as list of zero blocknumbers
-	       We allocate it outside of loop just in case loop would spin for
-	       several iterations. */
-	    char *zeros = kmalloc(to_paste*UNFM_P_SIZE, GFP_ATOMIC); // We cannot insert more than MAX_ITEM_LEN bytes anyway.
-	    if ( !zeros ) {
-		res = -ENOMEM;
+	/* Blocks allocating well might have scheduled and tree might have changed,
+	   let's search the tree again */
+	/* find where in the tree our write should go */
+	res = search_for_position_by_key(inode->i_sb, &key, &path);
+	if (res == IO_ERROR) {
+		res = -EIO;
 		goto error_exit_free_blocks;
-	    }
-	    memset ( zeros, 0, to_paste*UNFM_P_SIZE);
-	    do {
-		to_paste = min_t(__u64, hole_size, MAX_ITEM_LEN(inode->i_sb->s_blocksize)/UNFM_P_SIZE );
-		if ( is_indirect_le_ih(ih) ) {
-		    /* Ok, there is existing indirect item already. Need to append it */
-		    /* Calculate position past inserted item */
-		    make_cpu_key( &key, inode, le_key_k_offset( get_inode_item_key_version(inode), &(ih->ih_key)) + op_bytes_number(ih, inode->i_sb->s_blocksize), TYPE_INDIRECT, 3);
-		    res = reiserfs_paste_into_item( th, &path, &key, inode, (char *)zeros, UNFM_P_SIZE*to_paste);
-		    if ( res ) {
-			kfree(zeros);
-			goto error_exit_free_blocks;
-		    }
-		} else if ( is_statdata_le_ih(ih) ) {
-		    /* No existing item, create it */
-		    /* item head for new item */
-		    struct item_head ins_ih;
-
-		    /* create a key for our new item */
-		    make_cpu_key( &key, inode, 1, TYPE_INDIRECT, 3);
-
-		    /* Create new item head for our new item */
-		    make_le_item_head (&ins_ih, &key, key.version, 1,
-				       TYPE_INDIRECT, to_paste*UNFM_P_SIZE,
-				       0 /* free space */);
-
-		    /* Find where such item should live in the tree */
-		    res = search_item (inode->i_sb, &key, &path);
-		    if ( res != ITEM_NOT_FOUND ) {
-			/* item should not exist, otherwise we have error */
-			if ( res != -ENOSPC ) {
-			    reiserfs_warning (inode->i_sb,
-				"green-9008: search_by_key (%K) returned %d",
-					      &key, res);
+	}
+
+	bh = get_last_bh(&path);	// Get a bufferhead for last element in path.
+	ih = get_ih(&path);	// Get a pointer to last item head in path.
+	item = get_item(&path);	// Get a pointer to last item in path
+
+	/* Let's see what we have found */
+	if (res != POSITION_FOUND) {	/* position not found, this means that we
+					   might need to append file with holes
+					   first */
+		// Since we are writing past the file's end, we need to find out if
+		// there is a hole that needs to be inserted before our writing
+		// position, and how many blocks it is going to cover (we need to
+		//  populate pointers to file blocks representing the hole with zeros)
+
+		{
+			int item_offset = 1;
+			/*
+			 * if ih is stat data, its offset is 0 and we don't want to
+			 * add 1 to pos in the hole_size calculation
+			 */
+			if (is_statdata_le_ih(ih))
+				item_offset = 0;
+			hole_size = (pos + item_offset -
+				     (le_key_k_offset
+				      (get_inode_item_key_version(inode),
+				       &(ih->ih_key)) + op_bytes_number(ih,
+									inode->
+									i_sb->
+									s_blocksize)))
+			    >> inode->i_sb->s_blocksize_bits;
+		}
+
+		if (hole_size > 0) {
+			int to_paste = min_t(__u64, hole_size, MAX_ITEM_LEN(inode->i_sb->s_blocksize) / UNFM_P_SIZE);	// How much data to insert first time.
+			/* area filled with zeroes, to supply as list of zero blocknumbers
+			   We allocate it outside of loop just in case loop would spin for
+			   several iterations. */
+			char *zeros = kmalloc(to_paste * UNFM_P_SIZE, GFP_ATOMIC);	// We cannot insert more than MAX_ITEM_LEN bytes anyway.
+			if (!zeros) {
+				res = -ENOMEM;
+				goto error_exit_free_blocks;
 			}
-			res = -EIO;
-		        kfree(zeros);
-			goto error_exit_free_blocks;
-		    }
-		    res = reiserfs_insert_item( th, &path, &key, &ins_ih, inode, (char *)zeros);
-		} else {
-		    reiserfs_panic(inode->i_sb, "green-9011: Unexpected key type %K\n", &key);
+			memset(zeros, 0, to_paste * UNFM_P_SIZE);
+			do {
+				to_paste =
+				    min_t(__u64, hole_size,
+					  MAX_ITEM_LEN(inode->i_sb->
+						       s_blocksize) /
+					  UNFM_P_SIZE);
+				if (is_indirect_le_ih(ih)) {
+					/* Ok, there is existing indirect item already. Need to append it */
+					/* Calculate position past inserted item */
+					make_cpu_key(&key, inode,
+						     le_key_k_offset
+						     (get_inode_item_key_version
+						      (inode),
+						      &(ih->ih_key)) +
+						     op_bytes_number(ih,
+								     inode->
+								     i_sb->
+								     s_blocksize),
+						     TYPE_INDIRECT, 3);
+					res =
+					    reiserfs_paste_into_item(th, &path,
+								     &key,
+								     inode,
+								     (char *)
+								     zeros,
+								     UNFM_P_SIZE
+								     *
+								     to_paste);
+					if (res) {
+						kfree(zeros);
+						goto error_exit_free_blocks;
+					}
+				} else if (is_statdata_le_ih(ih)) {
+					/* No existing item, create it */
+					/* item head for new item */
+					struct item_head ins_ih;
+
+					/* create a key for our new item */
+					make_cpu_key(&key, inode, 1,
+						     TYPE_INDIRECT, 3);
+
+					/* Create new item head for our new item */
+					make_le_item_head(&ins_ih, &key,
+							  key.version, 1,
+							  TYPE_INDIRECT,
+							  to_paste *
+							  UNFM_P_SIZE,
+							  0 /* free space */ );
+
+					/* Find where such item should live in the tree */
+					res =
+					    search_item(inode->i_sb, &key,
+							&path);
+					if (res != ITEM_NOT_FOUND) {
+						/* item should not exist, otherwise we have error */
+						if (res != -ENOSPC) {
+							reiserfs_warning(inode->
+									 i_sb,
+									 "green-9008: search_by_key (%K) returned %d",
+									 &key,
+									 res);
+						}
+						res = -EIO;
+						kfree(zeros);
+						goto error_exit_free_blocks;
+					}
+					res =
+					    reiserfs_insert_item(th, &path,
+								 &key, &ins_ih,
+								 inode,
+								 (char *)zeros);
+				} else {
+					reiserfs_panic(inode->i_sb,
+						       "green-9011: Unexpected key type %K\n",
+						       &key);
+				}
+				if (res) {
+					kfree(zeros);
+					goto error_exit_free_blocks;
+				}
+				/* Now we want to check if transaction is too full, and if it is
+				   we restart it. This will also free the path. */
+				if (journal_transaction_should_end
+				    (th, th->t_blocks_allocated)) {
+					res =
+					    restart_transaction(th, inode,
+								&path);
+					if (res) {
+						pathrelse(&path);
+						kfree(zeros);
+						goto error_exit;
+					}
+				}
+
+				/* Well, need to recalculate path and stuff */
+				set_cpu_key_k_offset(&key,
+						     cpu_key_k_offset(&key) +
+						     (to_paste << inode->
+						      i_blkbits));
+				res =
+				    search_for_position_by_key(inode->i_sb,
+							       &key, &path);
+				if (res == IO_ERROR) {
+					res = -EIO;
+					kfree(zeros);
+					goto error_exit_free_blocks;
+				}
+				bh = get_last_bh(&path);
+				ih = get_ih(&path);
+				item = get_item(&path);
+				hole_size -= to_paste;
+			} while (hole_size);
+			kfree(zeros);
 		}
-		if ( res ) {
-		    kfree(zeros);
-		    goto error_exit_free_blocks;
+	}
+	// Go through existing indirect items first
+	// replace all zeroes with blocknumbers from list
+	// Note that if no corresponding item was found, by previous search,
+	// it means there are no existing in-tree representation for file area
+	// we are going to overwrite, so there is nothing to scan through for holes.
+	for (curr_block = 0, itempos = path.pos_in_item;
+	     curr_block < blocks_to_allocate && res == POSITION_FOUND;) {
+	      retry:
+
+		if (itempos >= ih_item_len(ih) / UNFM_P_SIZE) {
+			/* We run out of data in this indirect item, let's look for another
+			   one. */
+			/* First if we are already modifying current item, log it */
+			if (modifying_this_item) {
+				journal_mark_dirty(th, inode->i_sb, bh);
+				modifying_this_item = 0;
+			}
+			/* Then set the key to look for a new indirect item (offset of old
+			   item is added to old item length */
+			set_cpu_key_k_offset(&key,
+					     le_key_k_offset
+					     (get_inode_item_key_version(inode),
+					      &(ih->ih_key)) +
+					     op_bytes_number(ih,
+							     inode->i_sb->
+							     s_blocksize));
+			/* Search ofor position of new key in the tree. */
+			res =
+			    search_for_position_by_key(inode->i_sb, &key,
+						       &path);
+			if (res == IO_ERROR) {
+				res = -EIO;
+				goto error_exit_free_blocks;
+			}
+			bh = get_last_bh(&path);
+			ih = get_ih(&path);
+			item = get_item(&path);
+			itempos = path.pos_in_item;
+			continue;	// loop to check all kinds of conditions and so on.
 		}
-		/* Now we want to check if transaction is too full, and if it is
-		   we restart it. This will also free the path. */
-		if (journal_transaction_should_end(th, th->t_blocks_allocated)) {
-		    res = restart_transaction(th, inode, &path);
-                    if (res) {
-                        pathrelse (&path);
-                        kfree(zeros);
-                        goto error_exit;
-                    }
-                }
-
-		/* Well, need to recalculate path and stuff */
-		set_cpu_key_k_offset( &key, cpu_key_k_offset(&key) + (to_paste << inode->i_blkbits));
-		res = search_for_position_by_key(inode->i_sb, &key, &path);
-		if ( res == IO_ERROR ) {
-		    res = -EIO;
-		    kfree(zeros);
-		    goto error_exit_free_blocks;
+		/* Ok, we have correct position in item now, so let's see if it is
+		   representing file hole (blocknumber is zero) and fill it if needed */
+		if (!item[itempos]) {
+			/* Ok, a hole. Now we need to check if we already prepared this
+			   block to be journaled */
+			while (!modifying_this_item) {	// loop until succeed
+				/* Well, this item is not journaled yet, so we must prepare
+				   it for journal first, before we can change it */
+				struct item_head tmp_ih;	// We copy item head of found item,
+				// here to detect if fs changed under
+				// us while we were preparing for
+				// journal.
+				int fs_gen;	// We store fs generation here to find if someone
+				// changes fs under our feet
+
+				copy_item_head(&tmp_ih, ih);	// Remember itemhead
+				fs_gen = get_generation(inode->i_sb);	// remember fs generation
+				reiserfs_prepare_for_journal(inode->i_sb, bh, 1);	// Prepare a buffer within which indirect item is stored for changing.
+				if (fs_changed(fs_gen, inode->i_sb)
+				    && item_moved(&tmp_ih, &path)) {
+					// Sigh, fs was changed under us, we need to look for new
+					// location of item we are working with
+
+					/* unmark prepaerd area as journaled and search for it's
+					   new position */
+					reiserfs_restore_prepared_buffer(inode->
+									 i_sb,
+									 bh);
+					res =
+					    search_for_position_by_key(inode->
+								       i_sb,
+								       &key,
+								       &path);
+					if (res == IO_ERROR) {
+						res = -EIO;
+						goto error_exit_free_blocks;
+					}
+					bh = get_last_bh(&path);
+					ih = get_ih(&path);
+					item = get_item(&path);
+					itempos = path.pos_in_item;
+					goto retry;
+				}
+				modifying_this_item = 1;
+			}
+			item[itempos] = allocated_blocks[curr_block];	// Assign new block
+			curr_block++;
 		}
-		bh=get_last_bh(&path);
-		ih=get_ih(&path);
-		item = get_item(&path);
-		hole_size -= to_paste;
-	    } while ( hole_size );
-	    kfree(zeros);
+		itempos++;
 	}
-    }
-
-    // Go through existing indirect items first
-    // replace all zeroes with blocknumbers from list
-    // Note that if no corresponding item was found, by previous search,
-    // it means there are no existing in-tree representation for file area
-    // we are going to overwrite, so there is nothing to scan through for holes.
-    for ( curr_block = 0, itempos = path.pos_in_item ; curr_block < blocks_to_allocate && res == POSITION_FOUND ; ) {
-retry:
-
-	if ( itempos >= ih_item_len(ih)/UNFM_P_SIZE ) {
-	    /* We run out of data in this indirect item, let's look for another
-	       one. */
-	    /* First if we are already modifying current item, log it */
-	    if ( modifying_this_item ) {
-		journal_mark_dirty (th, inode->i_sb, bh);
-		modifying_this_item = 0;
-	    }
-	    /* Then set the key to look for a new indirect item (offset of old
-	       item is added to old item length */
-	    set_cpu_key_k_offset( &key, le_key_k_offset( get_inode_item_key_version(inode), &(ih->ih_key)) + op_bytes_number(ih, inode->i_sb->s_blocksize));
-	    /* Search ofor position of new key in the tree. */
-	    res = search_for_position_by_key(inode->i_sb, &key, &path);
-	    if ( res == IO_ERROR) {
-		res = -EIO;
-		goto error_exit_free_blocks;
-	    }
-	    bh=get_last_bh(&path);
-	    ih=get_ih(&path);
-	    item = get_item(&path);
-	    itempos = path.pos_in_item;
-	    continue; // loop to check all kinds of conditions and so on.
+
+	if (modifying_this_item) {	// We need to log last-accessed block, if it
+		// was modified, but not logged yet.
+		journal_mark_dirty(th, inode->i_sb, bh);
 	}
-	/* Ok, we have correct position in item now, so let's see if it is
-	   representing file hole (blocknumber is zero) and fill it if needed */
-	if ( !item[itempos] ) {
-	    /* Ok, a hole. Now we need to check if we already prepared this
-	       block to be journaled */
-	    while ( !modifying_this_item ) { // loop until succeed
-		/* Well, this item is not journaled yet, so we must prepare
-		   it for journal first, before we can change it */
-		struct item_head tmp_ih; // We copy item head of found item,
-					 // here to detect if fs changed under
-					 // us while we were preparing for
-					 // journal.
-		int fs_gen; // We store fs generation here to find if someone
-			    // changes fs under our feet
-
-		copy_item_head (&tmp_ih, ih); // Remember itemhead
-		fs_gen = get_generation (inode->i_sb); // remember fs generation
-		reiserfs_prepare_for_journal(inode->i_sb, bh, 1); // Prepare a buffer within which indirect item is stored for changing.
-		if (fs_changed (fs_gen, inode->i_sb) && item_moved (&tmp_ih, &path)) {
-		    // Sigh, fs was changed under us, we need to look for new
-		    // location of item we are working with
-
-		    /* unmark prepaerd area as journaled and search for it's
-		       new position */
-		    reiserfs_restore_prepared_buffer(inode->i_sb, bh);
-		    res = search_for_position_by_key(inode->i_sb, &key, &path);
-		    if ( res == IO_ERROR) {
-			res = -EIO;
-			goto error_exit_free_blocks;
-		    }
-		    bh=get_last_bh(&path);
-		    ih=get_ih(&path);
-		    item = get_item(&path);
-		    itempos = path.pos_in_item;
-		    goto retry;
+
+	if (curr_block < blocks_to_allocate) {
+		// Oh, well need to append to indirect item, or to create indirect item
+		// if there weren't any
+		if (is_indirect_le_ih(ih)) {
+			// Existing indirect item - append. First calculate key for append
+			// position. We do not need to recalculate path as it should
+			// already point to correct place.
+			make_cpu_key(&key, inode,
+				     le_key_k_offset(get_inode_item_key_version
+						     (inode),
+						     &(ih->ih_key)) +
+				     op_bytes_number(ih,
+						     inode->i_sb->s_blocksize),
+				     TYPE_INDIRECT, 3);
+			res =
+			    reiserfs_paste_into_item(th, &path, &key, inode,
+						     (char *)(allocated_blocks +
+							      curr_block),
+						     UNFM_P_SIZE *
+						     (blocks_to_allocate -
+						      curr_block));
+			if (res) {
+				goto error_exit_free_blocks;
+			}
+		} else if (is_statdata_le_ih(ih)) {
+			// Last found item was statdata. That means we need to create indirect item.
+			struct item_head ins_ih;	/* itemhead for new item */
+
+			/* create a key for our new item */
+			make_cpu_key(&key, inode, 1, TYPE_INDIRECT, 3);	// Position one,
+			// because that's
+			// where first
+			// indirect item
+			// begins
+			/* Create new item head for our new item */
+			make_le_item_head(&ins_ih, &key, key.version, 1,
+					  TYPE_INDIRECT,
+					  (blocks_to_allocate -
+					   curr_block) * UNFM_P_SIZE,
+					  0 /* free space */ );
+			/* Find where such item should live in the tree */
+			res = search_item(inode->i_sb, &key, &path);
+			if (res != ITEM_NOT_FOUND) {
+				/* Well, if we have found such item already, or some error
+				   occured, we need to warn user and return error */
+				if (res != -ENOSPC) {
+					reiserfs_warning(inode->i_sb,
+							 "green-9009: search_by_key (%K) "
+							 "returned %d", &key,
+							 res);
+				}
+				res = -EIO;
+				goto error_exit_free_blocks;
+			}
+			/* Insert item into the tree with the data as its body */
+			res =
+			    reiserfs_insert_item(th, &path, &key, &ins_ih,
+						 inode,
+						 (char *)(allocated_blocks +
+							  curr_block));
+		} else {
+			reiserfs_panic(inode->i_sb,
+				       "green-9010: unexpected item type for key %K\n",
+				       &key);
 		}
-		modifying_this_item = 1;
-	    }
-	    item[itempos] = allocated_blocks[curr_block]; // Assign new block
-	    curr_block++;
 	}
-	itempos++;
-    }
-
-    if ( modifying_this_item ) { // We need to log last-accessed block, if it
-				 // was modified, but not logged yet.
-	journal_mark_dirty (th, inode->i_sb, bh);
-    }
-
-    if ( curr_block < blocks_to_allocate ) {
-	// Oh, well need to append to indirect item, or to create indirect item
-	// if there weren't any
-	if ( is_indirect_le_ih(ih) ) {
-	    // Existing indirect item - append. First calculate key for append
-	    // position. We do not need to recalculate path as it should
-	    // already point to correct place.
-	    make_cpu_key( &key, inode, le_key_k_offset( get_inode_item_key_version(inode), &(ih->ih_key)) + op_bytes_number(ih, inode->i_sb->s_blocksize), TYPE_INDIRECT, 3);
-	    res = reiserfs_paste_into_item( th, &path, &key, inode, (char *)(allocated_blocks+curr_block), UNFM_P_SIZE*(blocks_to_allocate-curr_block));
-	    if ( res ) {
-		goto error_exit_free_blocks;
-	    }
-	} else if (is_statdata_le_ih(ih) ) {
-	    // Last found item was statdata. That means we need to create indirect item.
-	    struct item_head ins_ih; /* itemhead for new item */
-
-	    /* create a key for our new item */
-	    make_cpu_key( &key, inode, 1, TYPE_INDIRECT, 3); // Position one,
-							    // because that's
-							    // where first
-							    // indirect item
-							    // begins
-	    /* Create new item head for our new item */
-	    make_le_item_head (&ins_ih, &key, key.version, 1, TYPE_INDIRECT,
-			       (blocks_to_allocate-curr_block)*UNFM_P_SIZE,
-			       0 /* free space */);
-	    /* Find where such item should live in the tree */
-	    res = search_item (inode->i_sb, &key, &path);
-	    if ( res != ITEM_NOT_FOUND ) {
-		/* Well, if we have found such item already, or some error
-		   occured, we need to warn user and return error */
-		if ( res != -ENOSPC ) {
-		    reiserfs_warning (inode->i_sb,
-				      "green-9009: search_by_key (%K) "
-				      "returned %d", &key, res);
+	// the caller is responsible for closing the transaction
+	// unless we return an error, they are also responsible for logging
+	// the inode.
+	//
+	pathrelse(&path);
+	/*
+	 * cleanup prellocation from previous writes
+	 * if this is a partial block write
+	 */
+	if (write_bytes & (inode->i_sb->s_blocksize - 1))
+		reiserfs_discard_prealloc(th, inode);
+	reiserfs_write_unlock(inode->i_sb);
+
+	// go through all the pages/buffers and map the buffers to newly allocated
+	// blocks (so that system knows where to write these pages later).
+	curr_block = 0;
+	for (i = 0; i < num_pages; i++) {
+		struct page *page = prepared_pages[i];	//current page
+		struct buffer_head *head = page_buffers(page);	// first buffer for a page
+		int block_start, block_end;	// in-page offsets for buffers.
+
+		if (!page_buffers(page))
+			reiserfs_panic(inode->i_sb,
+				       "green-9005: No buffers for prepared page???");
+
+		/* For each buffer in page */
+		for (bh = head, block_start = 0; bh != head || !block_start;
+		     block_start = block_end, bh = bh->b_this_page) {
+			if (!bh)
+				reiserfs_panic(inode->i_sb,
+					       "green-9006: Allocated but absent buffer for a page?");
+			block_end = block_start + inode->i_sb->s_blocksize;
+			if (i == 0 && block_end <= from)
+				/* if this buffer is before requested data to map, skip it */
+				continue;
+			if (i == num_pages - 1 && block_start >= to)
+				/* If this buffer is after requested data to map, abort
+				   processing of current page */
+				break;
+
+			if (!buffer_mapped(bh)) {	// Ok, unmapped buffer, need to map it
+				map_bh(bh, inode->i_sb,
+				       le32_to_cpu(allocated_blocks
+						   [curr_block]));
+				curr_block++;
+				set_buffer_new(bh);
+			}
 		}
-		res = -EIO;
-		goto error_exit_free_blocks;
-	    }
-	    /* Insert item into the tree with the data as its body */
-	    res = reiserfs_insert_item( th, &path, &key, &ins_ih, inode, (char *)(allocated_blocks+curr_block));
-	} else {
-	    reiserfs_panic(inode->i_sb, "green-9010: unexpected item type for key %K\n",&key);
-	}
-    }
-
-    // the caller is responsible for closing the transaction
-    // unless we return an error, they are also responsible for logging
-    // the inode.
-    //
-    pathrelse(&path);
-    /*
-     * cleanup prellocation from previous writes
-     * if this is a partial block write
-     */
-    if (write_bytes & (inode->i_sb->s_blocksize -1))
-        reiserfs_discard_prealloc(th, inode);
-    reiserfs_write_unlock(inode->i_sb);
-
-    // go through all the pages/buffers and map the buffers to newly allocated
-    // blocks (so that system knows where to write these pages later).
-    curr_block = 0;
-    for ( i = 0; i < num_pages ; i++ ) {
-	struct page *page=prepared_pages[i]; //current page
-	struct buffer_head *head = page_buffers(page);// first buffer for a page
-	int block_start, block_end; // in-page offsets for buffers.
-
-	if (!page_buffers(page))
-	    reiserfs_panic(inode->i_sb, "green-9005: No buffers for prepared page???");
-
-	/* For each buffer in page */
-	for(bh = head, block_start = 0; bh != head || !block_start;
-	    block_start=block_end, bh = bh->b_this_page) {
-	    if (!bh)
-		reiserfs_panic(inode->i_sb, "green-9006: Allocated but absent buffer for a page?");
-	    block_end = block_start+inode->i_sb->s_blocksize;
-	    if (i == 0 && block_end <= from )
-		/* if this buffer is before requested data to map, skip it */
-		continue;
-	    if (i == num_pages - 1 && block_start >= to)
-		/* If this buffer is after requested data to map, abort
-		   processing of current page */
-		break;
-
-	    if ( !buffer_mapped(bh) ) { // Ok, unmapped buffer, need to map it
-		map_bh( bh, inode->i_sb, le32_to_cpu(allocated_blocks[curr_block]));
-		curr_block++;
-		set_buffer_new(bh);
-	    }
 	}
-    }
 
-    RFALSE( curr_block > blocks_to_allocate, "green-9007: Used too many blocks? weird");
+	RFALSE(curr_block > blocks_to_allocate,
+	       "green-9007: Used too many blocks? weird");
 
-    kfree(allocated_blocks);
-    return 0;
+	kfree(allocated_blocks);
+	return 0;
 
 // Need to deal with transaction here.
-error_exit_free_blocks:
-    pathrelse(&path);
-    // free blocks
-    for( i = 0; i < blocks_to_allocate; i++ )
-	reiserfs_free_block(th, inode, le32_to_cpu(allocated_blocks[i]), 1);
-
-error_exit:
-    if (th->t_trans_id) {
-        int err;
-        // update any changes we made to blk count
-        reiserfs_update_sd(th, inode);
-        err = journal_end(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS(inode->i_sb));
-        if (err)
-            res = err;
-    }
-    reiserfs_write_unlock(inode->i_sb);
-    kfree(allocated_blocks);
-
-    return res;
+      error_exit_free_blocks:
+	pathrelse(&path);
+	// free blocks
+	for (i = 0; i < blocks_to_allocate; i++)
+		reiserfs_free_block(th, inode, le32_to_cpu(allocated_blocks[i]),
+				    1);
+
+      error_exit:
+	if (th->t_trans_id) {
+		int err;
+		// update any changes we made to blk count
+		reiserfs_update_sd(th, inode);
+		err =
+		    journal_end(th, inode->i_sb,
+				JOURNAL_PER_BALANCE_CNT * 3 + 1 +
+				2 * REISERFS_QUOTA_TRANS_BLOCKS(inode->i_sb));
+		if (err)
+			res = err;
+	}
+	reiserfs_write_unlock(inode->i_sb);
+	kfree(allocated_blocks);
+
+	return res;
 }
 
 /* Unlock pages prepared by reiserfs_prepare_file_region_for_write */
-static void reiserfs_unprepare_pages(struct page **prepared_pages, /* list of locked pages */
-			      size_t num_pages /* amount of pages */) {
-    int i; // loop counter
+static void reiserfs_unprepare_pages(struct page **prepared_pages,	/* list of locked pages */
+				     size_t num_pages /* amount of pages */ )
+{
+	int i;			// loop counter
 
-    for (i=0; i < num_pages ; i++) {
-	struct page *page = prepared_pages[i];
+	for (i = 0; i < num_pages; i++) {
+		struct page *page = prepared_pages[i];
 
-	try_to_free_buffers(page);
-	unlock_page(page);
-	page_cache_release(page);
-    }
+		try_to_free_buffers(page);
+		unlock_page(page);
+		page_cache_release(page);
+	}
 }
 
 /* This function will copy data from userspace to specified pages within
    supplied byte range */
-static int reiserfs_copy_from_user_to_file_region(
-				loff_t pos, /* In-file position */
-				int num_pages, /* Number of pages affected */
-				int write_bytes, /* Amount of bytes to write */
-				struct page **prepared_pages, /* pointer to 
-								 array to
-								 prepared pages
-								*/
-				const char __user *buf /* Pointer to user-supplied
-						   data*/
-				)
+static int reiserfs_copy_from_user_to_file_region(loff_t pos,	/* In-file position */
+						  int num_pages,	/* Number of pages affected */
+						  int write_bytes,	/* Amount of bytes to write */
+						  struct page **prepared_pages,	/* pointer to 
+										   array to
+										   prepared pages
+										 */
+						  const char __user * buf	/* Pointer to user-supplied
+										   data */
+    )
 {
-    long page_fault=0; // status of copy_from_user.
-    int i; // loop counter.
-    int offset; // offset in page
-
-    for ( i = 0, offset = (pos & (PAGE_CACHE_SIZE-1)); i < num_pages ; i++,offset=0) {
-	size_t count = min_t(size_t,PAGE_CACHE_SIZE-offset,write_bytes); // How much of bytes to write to this page
-	struct page *page=prepared_pages[i]; // Current page we process.
-
-	fault_in_pages_readable( buf, count);
-
-	/* Copy data from userspace to the current page */
-	kmap(page);
-	page_fault = __copy_from_user(page_address(page)+offset, buf, count); // Copy the data.
-	/* Flush processor's dcache for this page */
-	flush_dcache_page(page);
-	kunmap(page);
-	buf+=count;
-	write_bytes-=count;
-
-	if (page_fault)
-	    break; // Was there a fault? abort.
-    }
-
-    return page_fault?-EFAULT:0;
+	long page_fault = 0;	// status of copy_from_user.
+	int i;			// loop counter.
+	int offset;		// offset in page
+
+	for (i = 0, offset = (pos & (PAGE_CACHE_SIZE - 1)); i < num_pages;
+	     i++, offset = 0) {
+		size_t count = min_t(size_t, PAGE_CACHE_SIZE - offset, write_bytes);	// How much of bytes to write to this page
+		struct page *page = prepared_pages[i];	// Current page we process.
+
+		fault_in_pages_readable(buf, count);
+
+		/* Copy data from userspace to the current page */
+		kmap(page);
+		page_fault = __copy_from_user(page_address(page) + offset, buf, count);	// Copy the data.
+		/* Flush processor's dcache for this page */
+		flush_dcache_page(page);
+		kunmap(page);
+		buf += count;
+		write_bytes -= count;
+
+		if (page_fault)
+			break;	// Was there a fault? abort.
+	}
+
+	return page_fault ? -EFAULT : 0;
 }
 
 /* taken fs/buffer.c:__block_commit_write */
 int reiserfs_commit_page(struct inode *inode, struct page *page,
-		unsigned from, unsigned to)
+			 unsigned from, unsigned to)
 {
-    unsigned block_start, block_end;
-    int partial = 0;
-    unsigned blocksize;
-    struct buffer_head *bh, *head;
-    unsigned long i_size_index = inode->i_size >> PAGE_CACHE_SHIFT;
-    int new;
-    int logit = reiserfs_file_data_log(inode);
-    struct super_block *s = inode->i_sb;
-    int bh_per_page = PAGE_CACHE_SIZE / s->s_blocksize;
-    struct reiserfs_transaction_handle th;
-    int ret = 0;
-
-    th.t_trans_id = 0;
-    blocksize = 1 << inode->i_blkbits;
-
-    if (logit) {
-	reiserfs_write_lock(s);
-	ret = journal_begin(&th, s, bh_per_page + 1);
-	if (ret)
-	    goto drop_write_lock;
-	reiserfs_update_inode_transaction(inode);
-    }
-    for(bh = head = page_buffers(page), block_start = 0;
-        bh != head || !block_start;
-	block_start=block_end, bh = bh->b_this_page)
-    {
-
-	new = buffer_new(bh);
-	clear_buffer_new(bh);
-	block_end = block_start + blocksize;
-	if (block_end <= from || block_start >= to) {
-	    if (!buffer_uptodate(bh))
-		    partial = 1;
-	} else {
-	    set_buffer_uptodate(bh);
-	    if (logit) {
-		reiserfs_prepare_for_journal(s, bh, 1);
-		journal_mark_dirty(&th, s, bh);
-	    } else if (!buffer_dirty(bh)) {
-		mark_buffer_dirty(bh);
-		/* do data=ordered on any page past the end
-		 * of file and any buffer marked BH_New.
-		 */
-		if (reiserfs_data_ordered(inode->i_sb) &&
-		    (new || page->index >= i_size_index)) {
-		    reiserfs_add_ordered_list(inode, bh);
-	        }
-	    }
+	unsigned block_start, block_end;
+	int partial = 0;
+	unsigned blocksize;
+	struct buffer_head *bh, *head;
+	unsigned long i_size_index = inode->i_size >> PAGE_CACHE_SHIFT;
+	int new;
+	int logit = reiserfs_file_data_log(inode);
+	struct super_block *s = inode->i_sb;
+	int bh_per_page = PAGE_CACHE_SIZE / s->s_blocksize;
+	struct reiserfs_transaction_handle th;
+	int ret = 0;
+
+	th.t_trans_id = 0;
+	blocksize = 1 << inode->i_blkbits;
+
+	if (logit) {
+		reiserfs_write_lock(s);
+		ret = journal_begin(&th, s, bh_per_page + 1);
+		if (ret)
+			goto drop_write_lock;
+		reiserfs_update_inode_transaction(inode);
+	}
+	for (bh = head = page_buffers(page), block_start = 0;
+	     bh != head || !block_start;
+	     block_start = block_end, bh = bh->b_this_page) {
+
+		new = buffer_new(bh);
+		clear_buffer_new(bh);
+		block_end = block_start + blocksize;
+		if (block_end <= from || block_start >= to) {
+			if (!buffer_uptodate(bh))
+				partial = 1;
+		} else {
+			set_buffer_uptodate(bh);
+			if (logit) {
+				reiserfs_prepare_for_journal(s, bh, 1);
+				journal_mark_dirty(&th, s, bh);
+			} else if (!buffer_dirty(bh)) {
+				mark_buffer_dirty(bh);
+				/* do data=ordered on any page past the end
+				 * of file and any buffer marked BH_New.
+				 */
+				if (reiserfs_data_ordered(inode->i_sb) &&
+				    (new || page->index >= i_size_index)) {
+					reiserfs_add_ordered_list(inode, bh);
+				}
+			}
+		}
 	}
-    }
-    if (logit) {
-	ret = journal_end(&th, s, bh_per_page + 1);
-drop_write_lock:
-	reiserfs_write_unlock(s);
-    }
-    /*
-     * If this is a partial write which happened to make all buffers
-     * uptodate then we can optimize away a bogus readpage() for
-     * the next read(). Here we 'discover' whether the page went
-     * uptodate as a result of this (potentially partial) write.
-     */
-    if (!partial)
-	SetPageUptodate(page);
-    return ret;
+	if (logit) {
+		ret = journal_end(&th, s, bh_per_page + 1);
+	      drop_write_lock:
+		reiserfs_write_unlock(s);
+	}
+	/*
+	 * If this is a partial write which happened to make all buffers
+	 * uptodate then we can optimize away a bogus readpage() for
+	 * the next read(). Here we 'discover' whether the page went
+	 * uptodate as a result of this (potentially partial) write.
+	 */
+	if (!partial)
+		SetPageUptodate(page);
+	return ret;
 }
 
-
 /* Submit pages for write. This was separated from actual file copying
    because we might want to allocate block numbers in-between.
    This function assumes that caller will adjust file size to correct value. */
-static int reiserfs_submit_file_region_for_write(
-				struct reiserfs_transaction_handle *th,
-				struct inode *inode,
-				loff_t pos, /* Writing position offset */
-				size_t num_pages, /* Number of pages to write */
-				size_t write_bytes, /* number of bytes to write */
-				struct page **prepared_pages /* list of pages */
-				)
+static int reiserfs_submit_file_region_for_write(struct reiserfs_transaction_handle *th, struct inode *inode, loff_t pos,	/* Writing position offset */
+						 size_t num_pages,	/* Number of pages to write */
+						 size_t write_bytes,	/* number of bytes to write */
+						 struct page **prepared_pages	/* list of pages */
+    )
 {
-    int status; // return status of block_commit_write.
-    int retval = 0; // Return value we are going to return.
-    int i; // loop counter
-    int offset; // Writing offset in page.
-    int orig_write_bytes = write_bytes;
-    int sd_update = 0;
-
-    for ( i = 0, offset = (pos & (PAGE_CACHE_SIZE-1)); i < num_pages ; i++,offset=0) {
-	int count = min_t(int,PAGE_CACHE_SIZE-offset,write_bytes); // How much of bytes to write to this page
-	struct page *page=prepared_pages[i]; // Current page we process.
-
-	status = reiserfs_commit_page(inode, page, offset, offset+count);
-	if ( status )
-	    retval = status; // To not overcomplicate matters We are going to
-			     // submit all the pages even if there was error.
-			     // we only remember error status to report it on
-			     // exit.
-	write_bytes-=count;
-    }
-    /* now that we've gotten all the ordered buffers marked dirty,
-     * we can safely update i_size and close any running transaction
-     */
-    if ( pos + orig_write_bytes > inode->i_size) {
-	inode->i_size = pos + orig_write_bytes; // Set new size
-	/* If the file have grown so much that tail packing is no
-	 * longer possible, reset "need to pack" flag */
-	if ( (have_large_tails (inode->i_sb) &&
-	      inode->i_size > i_block_size (inode)*4) ||
-	     (have_small_tails (inode->i_sb) &&
-	     inode->i_size > i_block_size(inode)) )
-	    REISERFS_I(inode)->i_flags &= ~i_pack_on_close_mask ;
-        else if ( (have_large_tails (inode->i_sb) &&
-	          inode->i_size < i_block_size (inode)*4) ||
-	          (have_small_tails (inode->i_sb) &&
-		  inode->i_size < i_block_size(inode)) )
-	    REISERFS_I(inode)->i_flags |= i_pack_on_close_mask ;
-
+	int status;		// return status of block_commit_write.
+	int retval = 0;		// Return value we are going to return.
+	int i;			// loop counter
+	int offset;		// Writing offset in page.
+	int orig_write_bytes = write_bytes;
+	int sd_update = 0;
+
+	for (i = 0, offset = (pos & (PAGE_CACHE_SIZE - 1)); i < num_pages;
+	     i++, offset = 0) {
+		int count = min_t(int, PAGE_CACHE_SIZE - offset, write_bytes);	// How much of bytes to write to this page
+		struct page *page = prepared_pages[i];	// Current page we process.
+
+		status =
+		    reiserfs_commit_page(inode, page, offset, offset + count);
+		if (status)
+			retval = status;	// To not overcomplicate matters We are going to
+		// submit all the pages even if there was error.
+		// we only remember error status to report it on
+		// exit.
+		write_bytes -= count;
+	}
+	/* now that we've gotten all the ordered buffers marked dirty,
+	 * we can safely update i_size and close any running transaction
+	 */
+	if (pos + orig_write_bytes > inode->i_size) {
+		inode->i_size = pos + orig_write_bytes;	// Set new size
+		/* If the file have grown so much that tail packing is no
+		 * longer possible, reset "need to pack" flag */
+		if ((have_large_tails(inode->i_sb) &&
+		     inode->i_size > i_block_size(inode) * 4) ||
+		    (have_small_tails(inode->i_sb) &&
+		     inode->i_size > i_block_size(inode)))
+			REISERFS_I(inode)->i_flags &= ~i_pack_on_close_mask;
+		else if ((have_large_tails(inode->i_sb) &&
+			  inode->i_size < i_block_size(inode) * 4) ||
+			 (have_small_tails(inode->i_sb) &&
+			  inode->i_size < i_block_size(inode)))
+			REISERFS_I(inode)->i_flags |= i_pack_on_close_mask;
+
+		if (th->t_trans_id) {
+			reiserfs_write_lock(inode->i_sb);
+			reiserfs_update_sd(th, inode);	// And update on-disk metadata
+			reiserfs_write_unlock(inode->i_sb);
+		} else
+			inode->i_sb->s_op->dirty_inode(inode);
+
+		sd_update = 1;
+	}
 	if (th->t_trans_id) {
-	    reiserfs_write_lock(inode->i_sb);
-	    reiserfs_update_sd(th, inode); // And update on-disk metadata
-	    reiserfs_write_unlock(inode->i_sb);
-	} else
-	    inode->i_sb->s_op->dirty_inode(inode);
+		reiserfs_write_lock(inode->i_sb);
+		if (!sd_update)
+			reiserfs_update_sd(th, inode);
+		status = journal_end(th, th->t_super, th->t_blocks_allocated);
+		if (status)
+			retval = status;
+		reiserfs_write_unlock(inode->i_sb);
+	}
+	th->t_trans_id = 0;
 
-        sd_update = 1;
-    }
-    if (th->t_trans_id) {
-	reiserfs_write_lock(inode->i_sb);
-	if (!sd_update)
-	    reiserfs_update_sd(th, inode);
-	status = journal_end(th, th->t_super, th->t_blocks_allocated);
-        if (status)
-            retval = status;
-	reiserfs_write_unlock(inode->i_sb);
-    }
-    th->t_trans_id = 0;
-
-    /* 
-     * we have to unlock the pages after updating i_size, otherwise
-     * we race with writepage
-     */
-    for ( i = 0; i < num_pages ; i++) {
-	struct page *page=prepared_pages[i];
-	unlock_page(page); 
-	mark_page_accessed(page);
-	page_cache_release(page);
-    }
-    return retval;
+	/* 
+	 * we have to unlock the pages after updating i_size, otherwise
+	 * we race with writepage
+	 */
+	for (i = 0; i < num_pages; i++) {
+		struct page *page = prepared_pages[i];
+		unlock_page(page);
+		mark_page_accessed(page);
+		page_cache_release(page);
+	}
+	return retval;
 }
 
 /* Look if passed writing region is going to touch file's tail
    (if it is present). And if it is, convert the tail to unformatted node */
-static int reiserfs_check_for_tail_and_convert( struct inode *inode, /* inode to deal with */
-					 loff_t pos, /* Writing position */
-					 int write_bytes /* amount of bytes to write */
-				        )
+static int reiserfs_check_for_tail_and_convert(struct inode *inode,	/* inode to deal with */
+					       loff_t pos,	/* Writing position */
+					       int write_bytes	/* amount of bytes to write */
+    )
 {
-    INITIALIZE_PATH(path); // needed for search_for_position
-    struct cpu_key key; // Key that would represent last touched writing byte.
-    struct item_head *ih; // item header of found block;
-    int res; // Return value of various functions we call.
-    int cont_expand_offset; // We will put offset for generic_cont_expand here
-			    // This can be int just because tails are created
-			    // only for small files.
- 
+	INITIALIZE_PATH(path);	// needed for search_for_position
+	struct cpu_key key;	// Key that would represent last touched writing byte.
+	struct item_head *ih;	// item header of found block;
+	int res;		// Return value of various functions we call.
+	int cont_expand_offset;	// We will put offset for generic_cont_expand here
+	// This can be int just because tails are created
+	// only for small files.
+
 /* this embodies a dependency on a particular tail policy */
-    if ( inode->i_size >= inode->i_sb->s_blocksize*4 ) {
-	/* such a big files do not have tails, so we won't bother ourselves
-	   to look for tails, simply return */
-	return 0;
-    }
-
-    reiserfs_write_lock(inode->i_sb);
-    /* find the item containing the last byte to be written, or if
-     * writing past the end of the file then the last item of the
-     * file (and then we check its type). */
-    make_cpu_key (&key, inode, pos+write_bytes+1, TYPE_ANY, 3/*key length*/);
-    res = search_for_position_by_key(inode->i_sb, &key, &path);
-    if ( res == IO_ERROR ) {
-        reiserfs_write_unlock(inode->i_sb);
-	return -EIO;
-    }
-    ih = get_ih(&path);
-    res = 0;
-    if ( is_direct_le_ih(ih) ) {
-	/* Ok, closest item is file tail (tails are stored in "direct"
-	 * items), so we need to unpack it. */
-	/* To not overcomplicate matters, we just call generic_cont_expand
-	   which will in turn call other stuff and finally will boil down to
-	    reiserfs_get_block() that would do necessary conversion. */
-	cont_expand_offset = le_key_k_offset(get_inode_item_key_version(inode), &(ih->ih_key));
-	pathrelse(&path);
-	res = generic_cont_expand( inode, cont_expand_offset);
-    } else
-	pathrelse(&path);
+	if (inode->i_size >= inode->i_sb->s_blocksize * 4) {
+		/* such a big files do not have tails, so we won't bother ourselves
+		   to look for tails, simply return */
+		return 0;
+	}
 
-    reiserfs_write_unlock(inode->i_sb);
-    return res;
+	reiserfs_write_lock(inode->i_sb);
+	/* find the item containing the last byte to be written, or if
+	 * writing past the end of the file then the last item of the
+	 * file (and then we check its type). */
+	make_cpu_key(&key, inode, pos + write_bytes + 1, TYPE_ANY,
+		     3 /*key length */ );
+	res = search_for_position_by_key(inode->i_sb, &key, &path);
+	if (res == IO_ERROR) {
+		reiserfs_write_unlock(inode->i_sb);
+		return -EIO;
+	}
+	ih = get_ih(&path);
+	res = 0;
+	if (is_direct_le_ih(ih)) {
+		/* Ok, closest item is file tail (tails are stored in "direct"
+		 * items), so we need to unpack it. */
+		/* To not overcomplicate matters, we just call generic_cont_expand
+		   which will in turn call other stuff and finally will boil down to
+		   reiserfs_get_block() that would do necessary conversion. */
+		cont_expand_offset =
+		    le_key_k_offset(get_inode_item_key_version(inode),
+				    &(ih->ih_key));
+		pathrelse(&path);
+		res = generic_cont_expand(inode, cont_expand_offset);
+	} else
+		pathrelse(&path);
+
+	reiserfs_write_unlock(inode->i_sb);
+	return res;
 }
 
 /* This function locks pages starting from @pos for @inode.
@@ -851,275 +947,296 @@ static int reiserfs_check_for_tail_and_convert( struct inode *inode, /* inode to
    append), it is zeroed, then. 
    Returns number of unallocated blocks that should be allocated to cover
    new file data.*/
-static int reiserfs_prepare_file_region_for_write(
-				struct inode *inode /* Inode of the file */,
-				loff_t pos, /* position in the file */
-				size_t num_pages, /* number of pages to
-					          prepare */
-				size_t write_bytes, /* Amount of bytes to be
-						    overwritten from
-						    @pos */
-				struct page **prepared_pages /* pointer to array
-							       where to store
-							       prepared pages */
-					   )
+static int reiserfs_prepare_file_region_for_write(struct inode *inode
+						  /* Inode of the file */ ,
+						  loff_t pos,	/* position in the file */
+						  size_t num_pages,	/* number of pages to
+									   prepare */
+						  size_t write_bytes,	/* Amount of bytes to be
+									   overwritten from
+									   @pos */
+						  struct page **prepared_pages	/* pointer to array
+										   where to store
+										   prepared pages */
+    )
 {
-    int res=0; // Return values of different functions we call.
-    unsigned long index = pos >> PAGE_CACHE_SHIFT; // Offset in file in pages.
-    int from = (pos & (PAGE_CACHE_SIZE - 1)); // Writing offset in first page
-    int to = ((pos + write_bytes - 1) & (PAGE_CACHE_SIZE - 1)) + 1;
-					 /* offset of last modified byte in last
-				            page */
-    struct address_space *mapping = inode->i_mapping; // Pages are mapped here.
-    int i; // Simple counter
-    int blocks = 0; /* Return value (blocks that should be allocated) */
-    struct buffer_head *bh, *head; // Current bufferhead and first bufferhead
-				   // of a page.
-    unsigned block_start, block_end; // Starting and ending offsets of current
-				     // buffer in the page.
-    struct buffer_head *wait[2], **wait_bh=wait; // Buffers for page, if
-						 // Page appeared to be not up
-						 // to date. Note how we have
-						 // at most 2 buffers, this is
-						 // because we at most may
-						 // partially overwrite two
-						 // buffers for one page. One at                                                 // the beginning of write area
-						 // and one at the end.
-						 // Everything inthe middle gets                                                 // overwritten totally.
-
-    struct cpu_key key; // cpu key of item that we are going to deal with
-    struct item_head *ih = NULL; // pointer to item head that we are going to deal with
-    struct buffer_head *itembuf=NULL; // Buffer head that contains items that we are going to deal with
-    INITIALIZE_PATH(path); // path to item, that we are going to deal with.
-    __le32 * item=NULL; // pointer to item we are going to deal with
-    int item_pos=-1; /* Position in indirect item */
-
-
-    if ( num_pages < 1 ) {
-	reiserfs_warning (inode->i_sb,
-			  "green-9001: reiserfs_prepare_file_region_for_write "
-			  "called with zero number of pages to process");
-	return -EFAULT;
-    }
-
-    /* We have 2 loops for pages. In first loop we grab and lock the pages, so
-       that nobody would touch these until we release the pages. Then
-       we'd start to deal with mapping buffers to blocks. */
-    for ( i = 0; i < num_pages; i++) {
-	prepared_pages[i] = grab_cache_page(mapping, index + i); // locks the page
-	if ( !prepared_pages[i]) {
-	    res = -ENOMEM;
-	    goto failed_page_grabbing;
-	}
-	if (!page_has_buffers(prepared_pages[i]))
-	    create_empty_buffers(prepared_pages[i], inode->i_sb->s_blocksize, 0);
-    }
-
-    /* Let's count amount of blocks for a case where all the blocks
-       overwritten are new (we will substract already allocated blocks later)*/
-    if ( num_pages > 2 )
-	/* These are full-overwritten pages so we count all the blocks in
-	   these pages are counted as needed to be allocated */
-	blocks = (num_pages - 2) << (PAGE_CACHE_SHIFT - inode->i_blkbits);
-
-    /* count blocks needed for first page (possibly partially written) */
-    blocks += ((PAGE_CACHE_SIZE - from) >> inode->i_blkbits) +
-	   !!(from & (inode->i_sb->s_blocksize-1)); /* roundup */
-
-    /* Now we account for last page. If last page == first page (we
-       overwrite only one page), we substract all the blocks past the
-       last writing position in a page out of already calculated number
-       of blocks */
-    blocks += ((num_pages > 1) << (PAGE_CACHE_SHIFT-inode->i_blkbits)) -
-	   ((PAGE_CACHE_SIZE - to) >> inode->i_blkbits);
-	   /* Note how we do not roundup here since partial blocks still
-		   should be allocated */
-
-    /* Now if all the write area lies past the file end, no point in
-       maping blocks, since there is none, so we just zero out remaining
-       parts of first and last pages in write area (if needed) */
-    if ( (pos & ~((loff_t)PAGE_CACHE_SIZE - 1)) > inode->i_size ) {
-	if ( from != 0 ) {/* First page needs to be partially zeroed */
-	    char *kaddr = kmap_atomic(prepared_pages[0], KM_USER0);
-	    memset(kaddr, 0, from);
-	    kunmap_atomic( kaddr, KM_USER0);
-	}
-	if ( to != PAGE_CACHE_SIZE ) { /* Last page needs to be partially zeroed */
-	    char *kaddr = kmap_atomic(prepared_pages[num_pages-1], KM_USER0);
-	    memset(kaddr+to, 0, PAGE_CACHE_SIZE - to);
-	    kunmap_atomic( kaddr, KM_USER0);
+	int res = 0;		// Return values of different functions we call.
+	unsigned long index = pos >> PAGE_CACHE_SHIFT;	// Offset in file in pages.
+	int from = (pos & (PAGE_CACHE_SIZE - 1));	// Writing offset in first page
+	int to = ((pos + write_bytes - 1) & (PAGE_CACHE_SIZE - 1)) + 1;
+	/* offset of last modified byte in last
+	   page */
+	struct address_space *mapping = inode->i_mapping;	// Pages are mapped here.
+	int i;			// Simple counter
+	int blocks = 0;		/* Return value (blocks that should be allocated) */
+	struct buffer_head *bh, *head;	// Current bufferhead and first bufferhead
+	// of a page.
+	unsigned block_start, block_end;	// Starting and ending offsets of current
+	// buffer in the page.
+	struct buffer_head *wait[2], **wait_bh = wait;	// Buffers for page, if
+	// Page appeared to be not up
+	// to date. Note how we have
+	// at most 2 buffers, this is
+	// because we at most may
+	// partially overwrite two
+	// buffers for one page. One at                                                 // the beginning of write area
+	// and one at the end.
+	// Everything inthe middle gets                                                 // overwritten totally.
+
+	struct cpu_key key;	// cpu key of item that we are going to deal with
+	struct item_head *ih = NULL;	// pointer to item head that we are going to deal with
+	struct buffer_head *itembuf = NULL;	// Buffer head that contains items that we are going to deal with
+	INITIALIZE_PATH(path);	// path to item, that we are going to deal with.
+	__le32 *item = NULL;	// pointer to item we are going to deal with
+	int item_pos = -1;	/* Position in indirect item */
+
+	if (num_pages < 1) {
+		reiserfs_warning(inode->i_sb,
+				 "green-9001: reiserfs_prepare_file_region_for_write "
+				 "called with zero number of pages to process");
+		return -EFAULT;
 	}
 
-	/* Since all blocks are new - use already calculated value */
-	return blocks;
-    }
-
-    /* Well, since we write somewhere into the middle of a file, there is
-       possibility we are writing over some already allocated blocks, so
-       let's map these blocks and substract number of such blocks out of blocks
-       we need to allocate (calculated above) */
-    /* Mask write position to start on blocksize, we do it out of the
-       loop for performance reasons */
-    pos &= ~((loff_t) inode->i_sb->s_blocksize - 1);
-    /* Set cpu key to the starting position in a file (on left block boundary)*/
-    make_cpu_key (&key, inode, 1 + ((pos) & ~((loff_t) inode->i_sb->s_blocksize - 1)), TYPE_ANY, 3/*key length*/);
-
-    reiserfs_write_lock(inode->i_sb); // We need that for at least search_by_key()
-    for ( i = 0; i < num_pages ; i++ ) { 
-
-	head = page_buffers(prepared_pages[i]);
-	/* For each buffer in the page */
-	for(bh = head, block_start = 0; bh != head || !block_start;
-	    block_start=block_end, bh = bh->b_this_page) {
-		if (!bh)
-		    reiserfs_panic(inode->i_sb, "green-9002: Allocated but absent buffer for a page?");
-		/* Find where this buffer ends */
-		block_end = block_start+inode->i_sb->s_blocksize;
-		if (i == 0 && block_end <= from )
-		    /* if this buffer is before requested data to map, skip it*/
-		    continue;
-
-		if (i == num_pages - 1 && block_start >= to) {
-		    /* If this buffer is after requested data to map, abort
-		       processing of current page */
-		    break;
+	/* We have 2 loops for pages. In first loop we grab and lock the pages, so
+	   that nobody would touch these until we release the pages. Then
+	   we'd start to deal with mapping buffers to blocks. */
+	for (i = 0; i < num_pages; i++) {
+		prepared_pages[i] = grab_cache_page(mapping, index + i);	// locks the page
+		if (!prepared_pages[i]) {
+			res = -ENOMEM;
+			goto failed_page_grabbing;
 		}
+		if (!page_has_buffers(prepared_pages[i]))
+			create_empty_buffers(prepared_pages[i],
+					     inode->i_sb->s_blocksize, 0);
+	}
 
-		if ( buffer_mapped(bh) && bh->b_blocknr !=0 ) {
-		    /* This is optimisation for a case where buffer is mapped
-		       and have blocknumber assigned. In case significant amount
-		       of such buffers are present, we may avoid some amount
-		       of search_by_key calls.
-		       Probably it would be possible to move parts of this code
-		       out of BKL, but I afraid that would overcomplicate code
-		       without any noticeable benefit.
-		    */
-		    item_pos++;
-		    /* Update the key */
-		    set_cpu_key_k_offset( &key, cpu_key_k_offset(&key) + inode->i_sb->s_blocksize);
-		    blocks--; // Decrease the amount of blocks that need to be
-			      // allocated
-		    continue; // Go to the next buffer
+	/* Let's count amount of blocks for a case where all the blocks
+	   overwritten are new (we will substract already allocated blocks later) */
+	if (num_pages > 2)
+		/* These are full-overwritten pages so we count all the blocks in
+		   these pages are counted as needed to be allocated */
+		blocks =
+		    (num_pages - 2) << (PAGE_CACHE_SHIFT - inode->i_blkbits);
+
+	/* count blocks needed for first page (possibly partially written) */
+	blocks += ((PAGE_CACHE_SIZE - from) >> inode->i_blkbits) + !!(from & (inode->i_sb->s_blocksize - 1));	/* roundup */
+
+	/* Now we account for last page. If last page == first page (we
+	   overwrite only one page), we substract all the blocks past the
+	   last writing position in a page out of already calculated number
+	   of blocks */
+	blocks += ((num_pages > 1) << (PAGE_CACHE_SHIFT - inode->i_blkbits)) -
+	    ((PAGE_CACHE_SIZE - to) >> inode->i_blkbits);
+	/* Note how we do not roundup here since partial blocks still
+	   should be allocated */
+
+	/* Now if all the write area lies past the file end, no point in
+	   maping blocks, since there is none, so we just zero out remaining
+	   parts of first and last pages in write area (if needed) */
+	if ((pos & ~((loff_t) PAGE_CACHE_SIZE - 1)) > inode->i_size) {
+		if (from != 0) {	/* First page needs to be partially zeroed */
+			char *kaddr = kmap_atomic(prepared_pages[0], KM_USER0);
+			memset(kaddr, 0, from);
+			kunmap_atomic(kaddr, KM_USER0);
+		}
+		if (to != PAGE_CACHE_SIZE) {	/* Last page needs to be partially zeroed */
+			char *kaddr =
+			    kmap_atomic(prepared_pages[num_pages - 1],
+					KM_USER0);
+			memset(kaddr + to, 0, PAGE_CACHE_SIZE - to);
+			kunmap_atomic(kaddr, KM_USER0);
 		}
 
-		if ( !itembuf || /* if first iteration */
-		     item_pos >= ih_item_len(ih)/UNFM_P_SIZE)
-					     { /* or if we progressed past the
-						  current unformatted_item */
-			/* Try to find next item */
-			res = search_for_position_by_key(inode->i_sb, &key, &path);
-			/* Abort if no more items */
-			if ( res != POSITION_FOUND ) {
-			    /* make sure later loops don't use this item */
-			    itembuf = NULL;
-			    item = NULL;
-			    break;
+		/* Since all blocks are new - use already calculated value */
+		return blocks;
+	}
+
+	/* Well, since we write somewhere into the middle of a file, there is
+	   possibility we are writing over some already allocated blocks, so
+	   let's map these blocks and substract number of such blocks out of blocks
+	   we need to allocate (calculated above) */
+	/* Mask write position to start on blocksize, we do it out of the
+	   loop for performance reasons */
+	pos &= ~((loff_t) inode->i_sb->s_blocksize - 1);
+	/* Set cpu key to the starting position in a file (on left block boundary) */
+	make_cpu_key(&key, inode,
+		     1 + ((pos) & ~((loff_t) inode->i_sb->s_blocksize - 1)),
+		     TYPE_ANY, 3 /*key length */ );
+
+	reiserfs_write_lock(inode->i_sb);	// We need that for at least search_by_key()
+	for (i = 0; i < num_pages; i++) {
+
+		head = page_buffers(prepared_pages[i]);
+		/* For each buffer in the page */
+		for (bh = head, block_start = 0; bh != head || !block_start;
+		     block_start = block_end, bh = bh->b_this_page) {
+			if (!bh)
+				reiserfs_panic(inode->i_sb,
+					       "green-9002: Allocated but absent buffer for a page?");
+			/* Find where this buffer ends */
+			block_end = block_start + inode->i_sb->s_blocksize;
+			if (i == 0 && block_end <= from)
+				/* if this buffer is before requested data to map, skip it */
+				continue;
+
+			if (i == num_pages - 1 && block_start >= to) {
+				/* If this buffer is after requested data to map, abort
+				   processing of current page */
+				break;
 			}
 
-			/* Update information about current indirect item */
-			itembuf = get_last_bh( &path );
-			ih = get_ih( &path );
-			item = get_item( &path );
-			item_pos = path.pos_in_item;
+			if (buffer_mapped(bh) && bh->b_blocknr != 0) {
+				/* This is optimisation for a case where buffer is mapped
+				   and have blocknumber assigned. In case significant amount
+				   of such buffers are present, we may avoid some amount
+				   of search_by_key calls.
+				   Probably it would be possible to move parts of this code
+				   out of BKL, but I afraid that would overcomplicate code
+				   without any noticeable benefit.
+				 */
+				item_pos++;
+				/* Update the key */
+				set_cpu_key_k_offset(&key,
+						     cpu_key_k_offset(&key) +
+						     inode->i_sb->s_blocksize);
+				blocks--;	// Decrease the amount of blocks that need to be
+				// allocated
+				continue;	// Go to the next buffer
+			}
 
-			RFALSE( !is_indirect_le_ih (ih), "green-9003: indirect item expected");
-		}
+			if (!itembuf ||	/* if first iteration */
+			    item_pos >= ih_item_len(ih) / UNFM_P_SIZE) {	/* or if we progressed past the
+										   current unformatted_item */
+				/* Try to find next item */
+				res =
+				    search_for_position_by_key(inode->i_sb,
+							       &key, &path);
+				/* Abort if no more items */
+				if (res != POSITION_FOUND) {
+					/* make sure later loops don't use this item */
+					itembuf = NULL;
+					item = NULL;
+					break;
+				}
+
+				/* Update information about current indirect item */
+				itembuf = get_last_bh(&path);
+				ih = get_ih(&path);
+				item = get_item(&path);
+				item_pos = path.pos_in_item;
+
+				RFALSE(!is_indirect_le_ih(ih),
+				       "green-9003: indirect item expected");
+			}
 
-		/* See if there is some block associated with the file
-		   at that position, map the buffer to this block */
-		if ( get_block_num(item,item_pos) ) {
-		    map_bh(bh, inode->i_sb, get_block_num(item,item_pos));
-		    blocks--; // Decrease the amount of blocks that need to be
-			      // allocated
+			/* See if there is some block associated with the file
+			   at that position, map the buffer to this block */
+			if (get_block_num(item, item_pos)) {
+				map_bh(bh, inode->i_sb,
+				       get_block_num(item, item_pos));
+				blocks--;	// Decrease the amount of blocks that need to be
+				// allocated
+			}
+			item_pos++;
+			/* Update the key */
+			set_cpu_key_k_offset(&key,
+					     cpu_key_k_offset(&key) +
+					     inode->i_sb->s_blocksize);
 		}
-		item_pos++;
-		/* Update the key */
-		set_cpu_key_k_offset( &key, cpu_key_k_offset(&key) + inode->i_sb->s_blocksize);
 	}
-    }
-    pathrelse(&path); // Free the path
-    reiserfs_write_unlock(inode->i_sb);
+	pathrelse(&path);	// Free the path
+	reiserfs_write_unlock(inode->i_sb);
 
 	/* Now zero out unmappend buffers for the first and last pages of
 	   write area or issue read requests if page is mapped. */
 	/* First page, see if it is not uptodate */
-	if ( !PageUptodate(prepared_pages[0]) ) {
-	    head = page_buffers(prepared_pages[0]);
-
-	    /* For each buffer in page */
-	    for(bh = head, block_start = 0; bh != head || !block_start;
-		block_start=block_end, bh = bh->b_this_page) {
-
-		if (!bh)
-		    reiserfs_panic(inode->i_sb, "green-9002: Allocated but absent buffer for a page?");
-		/* Find where this buffer ends */
-		block_end = block_start+inode->i_sb->s_blocksize;
-		if ( block_end <= from )
-		    /* if this buffer is before requested data to map, skip it*/
-		    continue;
-		if ( block_start < from ) { /* Aha, our partial buffer */
-		    if ( buffer_mapped(bh) ) { /* If it is mapped, we need to
-						  issue READ request for it to
-						  not loose data */
-			ll_rw_block(READ, 1, &bh);
-			*wait_bh++=bh;
-		    } else { /* Not mapped, zero it */
-			char *kaddr = kmap_atomic(prepared_pages[0], KM_USER0);
-			memset(kaddr+block_start, 0, from-block_start);
-			kunmap_atomic( kaddr, KM_USER0);
-			set_buffer_uptodate(bh);
-		    }
+	if (!PageUptodate(prepared_pages[0])) {
+		head = page_buffers(prepared_pages[0]);
+
+		/* For each buffer in page */
+		for (bh = head, block_start = 0; bh != head || !block_start;
+		     block_start = block_end, bh = bh->b_this_page) {
+
+			if (!bh)
+				reiserfs_panic(inode->i_sb,
+					       "green-9002: Allocated but absent buffer for a page?");
+			/* Find where this buffer ends */
+			block_end = block_start + inode->i_sb->s_blocksize;
+			if (block_end <= from)
+				/* if this buffer is before requested data to map, skip it */
+				continue;
+			if (block_start < from) {	/* Aha, our partial buffer */
+				if (buffer_mapped(bh)) {	/* If it is mapped, we need to
+								   issue READ request for it to
+								   not loose data */
+					ll_rw_block(READ, 1, &bh);
+					*wait_bh++ = bh;
+				} else {	/* Not mapped, zero it */
+					char *kaddr =
+					    kmap_atomic(prepared_pages[0],
+							KM_USER0);
+					memset(kaddr + block_start, 0,
+					       from - block_start);
+					kunmap_atomic(kaddr, KM_USER0);
+					set_buffer_uptodate(bh);
+				}
+			}
 		}
-	    }
 	}
 
 	/* Last page, see if it is not uptodate, or if the last page is past the end of the file. */
-	if ( !PageUptodate(prepared_pages[num_pages-1]) || 
-	    ((pos+write_bytes)>>PAGE_CACHE_SHIFT) > (inode->i_size>>PAGE_CACHE_SHIFT) ) {
-	    head = page_buffers(prepared_pages[num_pages-1]);
-
-	    /* for each buffer in page */
-	    for(bh = head, block_start = 0; bh != head || !block_start;
-		block_start=block_end, bh = bh->b_this_page) {
-
-		if (!bh)
-		    reiserfs_panic(inode->i_sb, "green-9002: Allocated but absent buffer for a page?");
-		/* Find where this buffer ends */
-		block_end = block_start+inode->i_sb->s_blocksize;
-		if ( block_start >= to )
-		    /* if this buffer is after requested data to map, skip it*/
-		    break;
-		if ( block_end > to ) { /* Aha, our partial buffer */
-		    if ( buffer_mapped(bh) ) { /* If it is mapped, we need to
-						  issue READ request for it to
-						  not loose data */
-			ll_rw_block(READ, 1, &bh);
-			*wait_bh++=bh;
-		    } else { /* Not mapped, zero it */
-			char *kaddr = kmap_atomic(prepared_pages[num_pages-1], KM_USER0);
-			memset(kaddr+to, 0, block_end-to);
-			kunmap_atomic( kaddr, KM_USER0);
-			set_buffer_uptodate(bh);
-		    }
+	if (!PageUptodate(prepared_pages[num_pages - 1]) ||
+	    ((pos + write_bytes) >> PAGE_CACHE_SHIFT) >
+	    (inode->i_size >> PAGE_CACHE_SHIFT)) {
+		head = page_buffers(prepared_pages[num_pages - 1]);
+
+		/* for each buffer in page */
+		for (bh = head, block_start = 0; bh != head || !block_start;
+		     block_start = block_end, bh = bh->b_this_page) {
+
+			if (!bh)
+				reiserfs_panic(inode->i_sb,
+					       "green-9002: Allocated but absent buffer for a page?");
+			/* Find where this buffer ends */
+			block_end = block_start + inode->i_sb->s_blocksize;
+			if (block_start >= to)
+				/* if this buffer is after requested data to map, skip it */
+				break;
+			if (block_end > to) {	/* Aha, our partial buffer */
+				if (buffer_mapped(bh)) {	/* If it is mapped, we need to
+								   issue READ request for it to
+								   not loose data */
+					ll_rw_block(READ, 1, &bh);
+					*wait_bh++ = bh;
+				} else {	/* Not mapped, zero it */
+					char *kaddr =
+					    kmap_atomic(prepared_pages
+							[num_pages - 1],
+							KM_USER0);
+					memset(kaddr + to, 0, block_end - to);
+					kunmap_atomic(kaddr, KM_USER0);
+					set_buffer_uptodate(bh);
+				}
+			}
 		}
-	    }
 	}
 
-    /* Wait for read requests we made to happen, if necessary */
-    while(wait_bh > wait) {
-	wait_on_buffer(*--wait_bh);
-	if (!buffer_uptodate(*wait_bh)) {
-	    res = -EIO;
-	    goto failed_read;
+	/* Wait for read requests we made to happen, if necessary */
+	while (wait_bh > wait) {
+		wait_on_buffer(*--wait_bh);
+		if (!buffer_uptodate(*wait_bh)) {
+			res = -EIO;
+			goto failed_read;
+		}
 	}
-    }
-
-    return blocks;
-failed_page_grabbing:
-    num_pages = i;
-failed_read:
-    reiserfs_unprepare_pages(prepared_pages, num_pages);
-    return res;
+
+	return blocks;
+      failed_page_grabbing:
+	num_pages = i;
+      failed_read:
+	reiserfs_unprepare_pages(prepared_pages, num_pages);
+	return res;
 }
 
 /* Write @count bytes at position @ppos in a file indicated by @file
@@ -1148,262 +1265,305 @@ static int reiserfs_prepare_file_region_for_write(
    Future Features: providing search_by_key with hints.
 
 */
-static ssize_t reiserfs_file_write( struct file *file, /* the file we are going to write into */
-                             const char __user *buf, /*  pointer to user supplied data
-(in userspace) */
-                             size_t count, /* amount of bytes to write */
-                             loff_t *ppos /* pointer to position in file that we start writing at. Should be updated to
-                                           * new current position before returning. */ )
+static ssize_t reiserfs_file_write(struct file *file,	/* the file we are going to write into */
+				   const char __user * buf,	/*  pointer to user supplied data
+								   (in userspace) */
+				   size_t count,	/* amount of bytes to write */
+				   loff_t * ppos	/* pointer to position in file that we start writing at. Should be updated to
+							 * new current position before returning. */
+				   )
 {
-    size_t already_written = 0; // Number of bytes already written to the file.
-    loff_t pos; // Current position in the file.
-    ssize_t res; // return value of various functions that we call.
-    int err = 0;
-    struct inode *inode = file->f_dentry->d_inode; // Inode of the file that we are writing to.
-				/* To simplify coding at this time, we store
-				   locked pages in array for now */
-    struct page * prepared_pages[REISERFS_WRITE_PAGES_AT_A_TIME];
-    struct reiserfs_transaction_handle th;
-    th.t_trans_id = 0;
-
-    if ( file->f_flags & O_DIRECT) { // Direct IO needs treatment
-	ssize_t result, after_file_end = 0;
-	if ( (*ppos + count >= inode->i_size) || (file->f_flags & O_APPEND) ) {
-	    /* If we are appending a file, we need to put this savelink in here.
-	       If we will crash while doing direct io, finish_unfinished will
-	       cut the garbage from the file end. */
-	    reiserfs_write_lock(inode->i_sb);
-	    err = journal_begin(&th, inode->i_sb,  JOURNAL_PER_BALANCE_CNT );
-            if (err) {
-		reiserfs_write_unlock (inode->i_sb);
-		return err;
-	    }
-	    reiserfs_update_inode_transaction(inode);
-	    add_save_link (&th, inode, 1 /* Truncate */);
-	    after_file_end = 1;
-	    err = journal_end(&th, inode->i_sb, JOURNAL_PER_BALANCE_CNT );
-            reiserfs_write_unlock(inode->i_sb);
-	    if (err)
-		return err;
-	}
-	result = generic_file_write(file, buf, count, ppos);
-
-	if ( after_file_end ) { /* Now update i_size and remove the savelink */
-	    struct reiserfs_transaction_handle th;
-	    reiserfs_write_lock(inode->i_sb);
-	    err = journal_begin(&th, inode->i_sb, 1);
-            if (err) {
-                reiserfs_write_unlock (inode->i_sb);
-                return err;
-            }
-	    reiserfs_update_inode_transaction(inode);
-	    reiserfs_update_sd(&th, inode);
-	    err = journal_end(&th, inode->i_sb, 1);
-            if (err) {
-                reiserfs_write_unlock (inode->i_sb);
-                return err;
-            }
-	    err = remove_save_link (inode, 1/* truncate */);
-	    reiserfs_write_unlock(inode->i_sb);
-            if (err)
-                return err;
-	}
-
-	return result;
-    }
-
-    if ( unlikely((ssize_t) count < 0 ))
-        return -EINVAL;
-
-    if (unlikely(!access_ok(VERIFY_READ, buf, count)))
-        return -EFAULT;
-
-    down(&inode->i_sem); // locks the entire file for just us
-
-    pos = *ppos;
-
-    /* Check if we can write to specified region of file, file
-       is not overly big and this kind of stuff. Adjust pos and
-       count, if needed */
-    res = generic_write_checks(file, &pos, &count, 0);
-    if (res)
-	goto out;
-
-    if ( count == 0 )
-	goto out;
-
-    res = remove_suid(file->f_dentry);
-    if (res)
-	goto out;
-
-    inode_update_time(inode, 1); /* Both mtime and ctime */
-
-    // Ok, we are done with all the checks.
+	size_t already_written = 0;	// Number of bytes already written to the file.
+	loff_t pos;		// Current position in the file.
+	ssize_t res;		// return value of various functions that we call.
+	int err = 0;
+	struct inode *inode = file->f_dentry->d_inode;	// Inode of the file that we are writing to.
+	/* To simplify coding at this time, we store
+	   locked pages in array for now */
+	struct page *prepared_pages[REISERFS_WRITE_PAGES_AT_A_TIME];
+	struct reiserfs_transaction_handle th;
+	th.t_trans_id = 0;
+
+	if (file->f_flags & O_DIRECT) {	// Direct IO needs treatment
+		ssize_t result, after_file_end = 0;
+		if ((*ppos + count >= inode->i_size)
+		    || (file->f_flags & O_APPEND)) {
+			/* If we are appending a file, we need to put this savelink in here.
+			   If we will crash while doing direct io, finish_unfinished will
+			   cut the garbage from the file end. */
+			reiserfs_write_lock(inode->i_sb);
+			err =
+			    journal_begin(&th, inode->i_sb,
+					  JOURNAL_PER_BALANCE_CNT);
+			if (err) {
+				reiserfs_write_unlock(inode->i_sb);
+				return err;
+			}
+			reiserfs_update_inode_transaction(inode);
+			add_save_link(&th, inode, 1 /* Truncate */ );
+			after_file_end = 1;
+			err =
+			    journal_end(&th, inode->i_sb,
+					JOURNAL_PER_BALANCE_CNT);
+			reiserfs_write_unlock(inode->i_sb);
+			if (err)
+				return err;
+		}
+		result = generic_file_write(file, buf, count, ppos);
+
+		if (after_file_end) {	/* Now update i_size and remove the savelink */
+			struct reiserfs_transaction_handle th;
+			reiserfs_write_lock(inode->i_sb);
+			err = journal_begin(&th, inode->i_sb, 1);
+			if (err) {
+				reiserfs_write_unlock(inode->i_sb);
+				return err;
+			}
+			reiserfs_update_inode_transaction(inode);
+			reiserfs_update_sd(&th, inode);
+			err = journal_end(&th, inode->i_sb, 1);
+			if (err) {
+				reiserfs_write_unlock(inode->i_sb);
+				return err;
+			}
+			err = remove_save_link(inode, 1 /* truncate */ );
+			reiserfs_write_unlock(inode->i_sb);
+			if (err)
+				return err;
+		}
 
-    // Now we should start real work
+		return result;
+	}
 
-    /* If we are going to write past the file's packed tail or if we are going
-       to overwrite part of the tail, we need that tail to be converted into
-       unformatted node */
-    res = reiserfs_check_for_tail_and_convert( inode, pos, count);
-    if (res)
-	goto out;
+	if (unlikely((ssize_t) count < 0))
+		return -EINVAL;
+
+	if (unlikely(!access_ok(VERIFY_READ, buf, count)))
+		return -EFAULT;
+
+	down(&inode->i_sem);	// locks the entire file for just us
+
+	pos = *ppos;
+
+	/* Check if we can write to specified region of file, file
+	   is not overly big and this kind of stuff. Adjust pos and
+	   count, if needed */
+	res = generic_write_checks(file, &pos, &count, 0);
+	if (res)
+		goto out;
+
+	if (count == 0)
+		goto out;
+
+	res = remove_suid(file->f_dentry);
+	if (res)
+		goto out;
+
+	inode_update_time(inode, 1);	/* Both mtime and ctime */
+
+	// Ok, we are done with all the checks.
+
+	// Now we should start real work
+
+	/* If we are going to write past the file's packed tail or if we are going
+	   to overwrite part of the tail, we need that tail to be converted into
+	   unformatted node */
+	res = reiserfs_check_for_tail_and_convert(inode, pos, count);
+	if (res)
+		goto out;
+
+	while (count > 0) {
+		/* This is the main loop in which we running until some error occures
+		   or until we write all of the data. */
+		size_t num_pages;	/* amount of pages we are going to write this iteration */
+		size_t write_bytes;	/* amount of bytes to write during this iteration */
+		size_t blocks_to_allocate;	/* how much blocks we need to allocate for this iteration */
+
+		/*  (pos & (PAGE_CACHE_SIZE-1)) is an idiom for offset into a page of pos */
+		num_pages = !!((pos + count) & (PAGE_CACHE_SIZE - 1)) +	/* round up partial
+									   pages */
+		    ((count +
+		      (pos & (PAGE_CACHE_SIZE - 1))) >> PAGE_CACHE_SHIFT);
+		/* convert size to amount of
+		   pages */
+		reiserfs_write_lock(inode->i_sb);
+		if (num_pages > REISERFS_WRITE_PAGES_AT_A_TIME
+		    || num_pages > reiserfs_can_fit_pages(inode->i_sb)) {
+			/* If we were asked to write more data than we want to or if there
+			   is not that much space, then we shorten amount of data to write
+			   for this iteration. */
+			num_pages =
+			    min_t(size_t, REISERFS_WRITE_PAGES_AT_A_TIME,
+				  reiserfs_can_fit_pages(inode->i_sb));
+			/* Also we should not forget to set size in bytes accordingly */
+			write_bytes = (num_pages << PAGE_CACHE_SHIFT) -
+			    (pos & (PAGE_CACHE_SIZE - 1));
+			/* If position is not on the
+			   start of the page, we need
+			   to substract the offset
+			   within page */
+		} else
+			write_bytes = count;
+
+		/* reserve the blocks to be allocated later, so that later on
+		   we still have the space to write the blocks to */
+		reiserfs_claim_blocks_to_be_allocated(inode->i_sb,
+						      num_pages <<
+						      (PAGE_CACHE_SHIFT -
+						       inode->i_blkbits));
+		reiserfs_write_unlock(inode->i_sb);
+
+		if (!num_pages) {	/* If we do not have enough space even for a single page... */
+			if (pos >
+			    inode->i_size + inode->i_sb->s_blocksize -
+			    (pos & (inode->i_sb->s_blocksize - 1))) {
+				res = -ENOSPC;
+				break;	// In case we are writing past the end of the last file block, break.
+			}
+			// Otherwise we are possibly overwriting the file, so
+			// let's set write size to be equal or less than blocksize.
+			// This way we get it correctly for file holes.
+			// But overwriting files on absolutelly full volumes would not
+			// be very efficient. Well, people are not supposed to fill
+			// 100% of disk space anyway.
+			write_bytes =
+			    min_t(size_t, count,
+				  inode->i_sb->s_blocksize -
+				  (pos & (inode->i_sb->s_blocksize - 1)));
+			num_pages = 1;
+			// No blocks were claimed before, so do it now.
+			reiserfs_claim_blocks_to_be_allocated(inode->i_sb,
+							      1 <<
+							      (PAGE_CACHE_SHIFT
+							       -
+							       inode->
+							       i_blkbits));
+		}
 
-    while ( count > 0) {
-	/* This is the main loop in which we running until some error occures
-	   or until we write all of the data. */
-	size_t num_pages;/* amount of pages we are going to write this iteration */
-	size_t write_bytes; /* amount of bytes to write during this iteration */
-	size_t blocks_to_allocate; /* how much blocks we need to allocate for this iteration */
-        
-        /*  (pos & (PAGE_CACHE_SIZE-1)) is an idiom for offset into a page of pos*/
-	num_pages = !!((pos+count) & (PAGE_CACHE_SIZE - 1)) + /* round up partial
-							  pages */
-		    ((count + (pos & (PAGE_CACHE_SIZE-1))) >> PAGE_CACHE_SHIFT); 
-						/* convert size to amount of
-						   pages */
-	reiserfs_write_lock(inode->i_sb);
-	if ( num_pages > REISERFS_WRITE_PAGES_AT_A_TIME 
-		|| num_pages > reiserfs_can_fit_pages(inode->i_sb) ) {
-	    /* If we were asked to write more data than we want to or if there
-	       is not that much space, then we shorten amount of data to write
-	       for this iteration. */
-	    num_pages = min_t(size_t, REISERFS_WRITE_PAGES_AT_A_TIME, reiserfs_can_fit_pages(inode->i_sb));
-	    /* Also we should not forget to set size in bytes accordingly */
-	    write_bytes = (num_pages << PAGE_CACHE_SHIFT) - 
-			    (pos & (PAGE_CACHE_SIZE-1));
-					 /* If position is not on the
-					    start of the page, we need
-					    to substract the offset
-					    within page */
-	} else
-	    write_bytes = count;
+		/* Prepare for writing into the region, read in all the
+		   partially overwritten pages, if needed. And lock the pages,
+		   so that nobody else can access these until we are done.
+		   We get number of actual blocks needed as a result. */
+		blocks_to_allocate =
+		    reiserfs_prepare_file_region_for_write(inode, pos,
+							   num_pages,
+							   write_bytes,
+							   prepared_pages);
+		if (blocks_to_allocate < 0) {
+			res = blocks_to_allocate;
+			reiserfs_release_claimed_blocks(inode->i_sb,
+							num_pages <<
+							(PAGE_CACHE_SHIFT -
+							 inode->i_blkbits));
+			break;
+		}
 
-	/* reserve the blocks to be allocated later, so that later on
-	   we still have the space to write the blocks to */
-	reiserfs_claim_blocks_to_be_allocated(inode->i_sb, num_pages << (PAGE_CACHE_SHIFT - inode->i_blkbits));
-	reiserfs_write_unlock(inode->i_sb);
+		/* First we correct our estimate of how many blocks we need */
+		reiserfs_release_claimed_blocks(inode->i_sb,
+						(num_pages <<
+						 (PAGE_CACHE_SHIFT -
+						  inode->i_sb->
+						  s_blocksize_bits)) -
+						blocks_to_allocate);
+
+		if (blocks_to_allocate > 0) {	/*We only allocate blocks if we need to */
+			/* Fill in all the possible holes and append the file if needed */
+			res =
+			    reiserfs_allocate_blocks_for_region(&th, inode, pos,
+								num_pages,
+								write_bytes,
+								prepared_pages,
+								blocks_to_allocate);
+		}
 
-	if ( !num_pages ) { /* If we do not have enough space even for a single page... */
-	    if ( pos > inode->i_size+inode->i_sb->s_blocksize-(pos & (inode->i_sb->s_blocksize-1))) {
-		res = -ENOSPC;
-		break; // In case we are writing past the end of the last file block, break.
-	    }
-	    // Otherwise we are possibly overwriting the file, so
-	    // let's set write size to be equal or less than blocksize.
-	    // This way we get it correctly for file holes.
-	    // But overwriting files on absolutelly full volumes would not
-	    // be very efficient. Well, people are not supposed to fill
-	    // 100% of disk space anyway.
-	    write_bytes = min_t(size_t, count, inode->i_sb->s_blocksize - (pos & (inode->i_sb->s_blocksize - 1)));
-	    num_pages = 1;
-	    // No blocks were claimed before, so do it now.
-	    reiserfs_claim_blocks_to_be_allocated(inode->i_sb, 1 << (PAGE_CACHE_SHIFT - inode->i_blkbits));
-	}
+		/* well, we have allocated the blocks, so it is time to free
+		   the reservation we made earlier. */
+		reiserfs_release_claimed_blocks(inode->i_sb,
+						blocks_to_allocate);
+		if (res) {
+			reiserfs_unprepare_pages(prepared_pages, num_pages);
+			break;
+		}
 
-	/* Prepare for writing into the region, read in all the
-	   partially overwritten pages, if needed. And lock the pages,
-	   so that nobody else can access these until we are done.
-	   We get number of actual blocks needed as a result.*/
-	blocks_to_allocate = reiserfs_prepare_file_region_for_write(inode, pos, num_pages, write_bytes, prepared_pages);
-	if ( blocks_to_allocate < 0 ) {
-	    res = blocks_to_allocate;
-	    reiserfs_release_claimed_blocks(inode->i_sb, num_pages << (PAGE_CACHE_SHIFT - inode->i_blkbits));
-	    break;
-	}
+/* NOTE that allocating blocks and filling blocks can be done in reverse order
+   and probably we would do that just to get rid of garbage in files after a
+   crash */
 
-	/* First we correct our estimate of how many blocks we need */
-	reiserfs_release_claimed_blocks(inode->i_sb, (num_pages << (PAGE_CACHE_SHIFT - inode->i_sb->s_blocksize_bits)) - blocks_to_allocate );
+		/* Copy data from user-supplied buffer to file's pages */
+		res =
+		    reiserfs_copy_from_user_to_file_region(pos, num_pages,
+							   write_bytes,
+							   prepared_pages, buf);
+		if (res) {
+			reiserfs_unprepare_pages(prepared_pages, num_pages);
+			break;
+		}
 
-	if ( blocks_to_allocate > 0) {/*We only allocate blocks if we need to*/
-	    /* Fill in all the possible holes and append the file if needed */
-	    res = reiserfs_allocate_blocks_for_region(&th, inode, pos, num_pages, write_bytes, prepared_pages, blocks_to_allocate);
+		/* Send the pages to disk and unlock them. */
+		res =
+		    reiserfs_submit_file_region_for_write(&th, inode, pos,
+							  num_pages,
+							  write_bytes,
+							  prepared_pages);
+		if (res)
+			break;
+
+		already_written += write_bytes;
+		buf += write_bytes;
+		*ppos = pos += write_bytes;
+		count -= write_bytes;
+		balance_dirty_pages_ratelimited(inode->i_mapping);
 	}
 
-	/* well, we have allocated the blocks, so it is time to free
-	   the reservation we made earlier. */
-	reiserfs_release_claimed_blocks(inode->i_sb, blocks_to_allocate);
-	if ( res ) {
-	    reiserfs_unprepare_pages(prepared_pages, num_pages);
-	    break;
+	/* this is only true on error */
+	if (th.t_trans_id) {
+		reiserfs_write_lock(inode->i_sb);
+		err = journal_end(&th, th.t_super, th.t_blocks_allocated);
+		reiserfs_write_unlock(inode->i_sb);
+		if (err) {
+			res = err;
+			goto out;
+		}
 	}
 
-/* NOTE that allocating blocks and filling blocks can be done in reverse order
-   and probably we would do that just to get rid of garbage in files after a
-   crash */
+	if ((file->f_flags & O_SYNC) || IS_SYNC(inode))
+		res =
+		    generic_osync_inode(inode, file->f_mapping,
+					OSYNC_METADATA | OSYNC_DATA);
 
-	/* Copy data from user-supplied buffer to file's pages */
-	res = reiserfs_copy_from_user_to_file_region(pos, num_pages, write_bytes, prepared_pages, buf);
-	if ( res ) {
-	    reiserfs_unprepare_pages(prepared_pages, num_pages);
-	    break;
-	}
+	up(&inode->i_sem);
+	reiserfs_async_progress_wait(inode->i_sb);
+	return (already_written != 0) ? already_written : res;
 
-	/* Send the pages to disk and unlock them. */
-	res = reiserfs_submit_file_region_for_write(&th, inode, pos, num_pages,
-	                                            write_bytes,prepared_pages);
-	if ( res )
-	    break;
-
-	already_written += write_bytes;
-	buf += write_bytes;
-	*ppos = pos += write_bytes;
-	count -= write_bytes;
-	balance_dirty_pages_ratelimited(inode->i_mapping);
-    }
-
-    /* this is only true on error */
-    if (th.t_trans_id) {
-        reiserfs_write_lock(inode->i_sb);
-        err = journal_end(&th, th.t_super, th.t_blocks_allocated);
-        reiserfs_write_unlock(inode->i_sb);
-        if (err) {
-            res = err;
-            goto out;
-        }
-    }
-
-    if ((file->f_flags & O_SYNC) || IS_SYNC(inode))
-	res = generic_osync_inode(inode, file->f_mapping, OSYNC_METADATA|OSYNC_DATA);
-
-    up(&inode->i_sem);
-    reiserfs_async_progress_wait(inode->i_sb);
-    return (already_written != 0)?already_written:res;
-
-out:
-    up(&inode->i_sem); // unlock the file on exit.
-    return res;
+      out:
+	up(&inode->i_sem);	// unlock the file on exit.
+	return res;
 }
 
-static ssize_t reiserfs_aio_write(struct kiocb *iocb, const char __user *buf,
-			       size_t count, loff_t pos)
+static ssize_t reiserfs_aio_write(struct kiocb *iocb, const char __user * buf,
+				  size_t count, loff_t pos)
 {
-    return generic_file_aio_write(iocb, buf, count, pos);
+	return generic_file_aio_write(iocb, buf, count, pos);
 }
 
-
-
 struct file_operations reiserfs_file_operations = {
-    .read	= generic_file_read,
-    .write	= reiserfs_file_write,
-    .ioctl	= reiserfs_ioctl,
-    .mmap	= generic_file_mmap,
-    .release	= reiserfs_file_release,
-    .fsync	= reiserfs_sync_file,
-    .sendfile	= generic_file_sendfile,
-    .aio_read   = generic_file_aio_read,
-    .aio_write  = reiserfs_aio_write,
+	.read = generic_file_read,
+	.write = reiserfs_file_write,
+	.ioctl = reiserfs_ioctl,
+	.mmap = generic_file_mmap,
+	.release = reiserfs_file_release,
+	.fsync = reiserfs_sync_file,
+	.sendfile = generic_file_sendfile,
+	.aio_read = generic_file_aio_read,
+	.aio_write = reiserfs_aio_write,
 };
 
-
-struct  inode_operations reiserfs_file_inode_operations = {
-    .truncate	= reiserfs_vfs_truncate_file,
-    .setattr    = reiserfs_setattr,
-    .setxattr   = reiserfs_setxattr,
-    .getxattr   = reiserfs_getxattr,
-    .listxattr  = reiserfs_listxattr,
-    .removexattr = reiserfs_removexattr,
-    .permission = reiserfs_permission,
+struct inode_operations reiserfs_file_inode_operations = {
+	.truncate = reiserfs_vfs_truncate_file,
+	.setattr = reiserfs_setattr,
+	.setxattr = reiserfs_setxattr,
+	.getxattr = reiserfs_getxattr,
+	.listxattr = reiserfs_listxattr,
+	.removexattr = reiserfs_removexattr,
+	.permission = reiserfs_permission,
 };
-
-

commit 556a2a45bce1740f035befaa7201e4ad836c7257
Author: Jan Kara <jack@suse.cz>
Date:   Thu Jun 23 22:01:06 2005 -0700

    [PATCH] quota: reiserfs: improve quota credit estimates
    
    Use improved credits estimates for quota operations.  Also reserve space
    for a quota operation in a transaction only if filesystem was mounted with
    some quota option.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 2230afff1870..12e91209544e 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -201,7 +201,7 @@ static int reiserfs_allocate_blocks_for_region(
     /* If we came here, it means we absolutely need to open a transaction,
        since we need to allocate some blocks */
     reiserfs_write_lock(inode->i_sb); // Journaling stuff and we need that.
-    res = journal_begin(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS); // Wish I know if this number enough
+    res = journal_begin(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS(inode->i_sb)); // Wish I know if this number enough
     if (res)
         goto error_exit;
     reiserfs_update_inode_transaction(inode) ;
@@ -576,7 +576,7 @@ static int reiserfs_allocate_blocks_for_region(
         int err;
         // update any changes we made to blk count
         reiserfs_update_sd(th, inode);
-        err = journal_end(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS);
+        err = journal_end(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS(inode->i_sb));
         if (err)
             res = err;
     }

commit 3e8962be915bacc1d70e4849a075041838d60a3f
Author: Al Viro <viro@www.linux.org.uk>
Date:   Sun May 1 08:59:18 2005 -0700

    [PATCH] reiserfs endianness: annotate little-endian objects
    
    little-endian objects annotated as such; again, obviously no changes of
    resulting code, we only replace __u16 with __le16, etc.  in relevant places.
    
    Signed-off-by: Al Viro <viro@parcelfarce.linux.theplanet.co.uk>
    Cc: <reiserfs-dev@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index f6860e83521d..2230afff1870 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -166,7 +166,7 @@ static int reiserfs_allocate_blocks_for_region(
     struct cpu_key key; // cpu key of item that we are going to deal with
     struct item_head *ih; // pointer to item head that we are going to deal with
     struct buffer_head *bh; // Buffer head that contains items that we are going to deal with
-    __u32 * item; // pointer to item we are going to deal with
+    __le32 * item; // pointer to item we are going to deal with
     INITIALIZE_PATH(path); // path to item, that we are going to deal with.
     b_blocknr_t *allocated_blocks; // Pointer to a place where allocated blocknumbers would be stored.
     reiserfs_blocknr_hint_t hint; // hint structure for block allocator.
@@ -891,7 +891,7 @@ static int reiserfs_prepare_file_region_for_write(
     struct item_head *ih = NULL; // pointer to item head that we are going to deal with
     struct buffer_head *itembuf=NULL; // Buffer head that contains items that we are going to deal with
     INITIALIZE_PATH(path); // path to item, that we are going to deal with.
-    __u32 * item=NULL; // pointer to item we are going to deal with
+    __le32 * item=NULL; // pointer to item we are going to deal with
     int item_pos=-1; /* Position in indirect item */
 
 

commit 127144df4ce817ad648af15a3983c8d52aacf670
Author: Jan Kara <jack@suse.cz>
Date:   Sun May 1 08:59:07 2005 -0700

    [PATCH] Fix rewriting on a full reiserfs filesystem
    
    Allow rewriting of a file and extending a file upto the end of the
    allocated block on a full filesystem.
    
    From: Chris Mason <mason@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index 26950113af8c..f6860e83521d 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -1284,10 +1284,11 @@ static ssize_t reiserfs_file_write( struct file *file, /* the file we are going
 	reiserfs_claim_blocks_to_be_allocated(inode->i_sb, num_pages << (PAGE_CACHE_SHIFT - inode->i_blkbits));
 	reiserfs_write_unlock(inode->i_sb);
 
-	if ( !num_pages ) { /* If we do not have enough space even for */
-	    res = -ENOSPC;  /* single page, return -ENOSPC */
-	    if ( pos > (inode->i_size & (inode->i_sb->s_blocksize-1)))
-		break; // In case we are writing past the file end, break.
+	if ( !num_pages ) { /* If we do not have enough space even for a single page... */
+	    if ( pos > inode->i_size+inode->i_sb->s_blocksize-(pos & (inode->i_sb->s_blocksize-1))) {
+		res = -ENOSPC;
+		break; // In case we are writing past the end of the last file block, break.
+	    }
 	    // Otherwise we are possibly overwriting the file, so
 	    // let's set write size to be equal or less than blocksize.
 	    // This way we get it correctly for file holes.

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
new file mode 100644
index 000000000000..26950113af8c
--- /dev/null
+++ b/fs/reiserfs/file.c
@@ -0,0 +1,1408 @@
+/*
+ * Copyright 2000 by Hans Reiser, licensing governed by reiserfs/README
+ */
+
+
+#include <linux/time.h>
+#include <linux/reiserfs_fs.h>
+#include <linux/reiserfs_acl.h>
+#include <linux/reiserfs_xattr.h>
+#include <linux/smp_lock.h>
+#include <asm/uaccess.h>
+#include <linux/pagemap.h>
+#include <linux/swap.h>
+#include <linux/writeback.h>
+#include <linux/blkdev.h>
+#include <linux/buffer_head.h>
+#include <linux/quotaops.h>
+
+/*
+** We pack the tails of files on file close, not at the time they are written.
+** This implies an unnecessary copy of the tail and an unnecessary indirect item
+** insertion/balancing, for files that are written in one write.
+** It avoids unnecessary tail packings (balances) for files that are written in
+** multiple writes and are small enough to have tails.
+** 
+** file_release is called by the VFS layer when the file is closed.  If
+** this is the last open file descriptor, and the file
+** small enough to have a tail, and the tail is currently in an
+** unformatted node, the tail is converted back into a direct item.
+** 
+** We use reiserfs_truncate_file to pack the tail, since it already has
+** all the conditions coded.  
+*/
+static int reiserfs_file_release (struct inode * inode, struct file * filp)
+{
+
+    struct reiserfs_transaction_handle th ;
+    int err;
+    int jbegin_failure = 0;
+
+    if (!S_ISREG (inode->i_mode))
+	BUG ();
+
+    /* fast out for when nothing needs to be done */
+    if ((atomic_read(&inode->i_count) > 1 ||
+	!(REISERFS_I(inode)->i_flags & i_pack_on_close_mask) || 
+         !tail_has_to_be_packed(inode))       && 
+	REISERFS_I(inode)->i_prealloc_count <= 0) {
+	return 0;
+    }    
+    
+    reiserfs_write_lock(inode->i_sb);
+    down (&inode->i_sem); 
+    /* freeing preallocation only involves relogging blocks that
+     * are already in the current transaction.  preallocation gets
+     * freed at the end of each transaction, so it is impossible for
+     * us to log any additional blocks (including quota blocks)
+     */
+    err = journal_begin(&th, inode->i_sb, 1);
+    if (err) {
+	/* uh oh, we can't allow the inode to go away while there
+	 * is still preallocation blocks pending.  Try to join the
+	 * aborted transaction
+	 */
+	jbegin_failure = err;
+	err = journal_join_abort(&th, inode->i_sb, 1);
+
+	if (err) {
+	    /* hmpf, our choices here aren't good.  We can pin the inode
+	     * which will disallow unmount from every happening, we can
+	     * do nothing, which will corrupt random memory on unmount,
+	     * or we can forcibly remove the file from the preallocation
+	     * list, which will leak blocks on disk.  Lets pin the inode
+	     * and let the admin know what is going on.
+	     */
+	    igrab(inode);
+	    reiserfs_warning(inode->i_sb, "pinning inode %lu because the "
+	                     "preallocation can't be freed");
+	    goto out;
+	}
+    }
+    reiserfs_update_inode_transaction(inode) ;
+
+#ifdef REISERFS_PREALLOCATE
+    reiserfs_discard_prealloc (&th, inode);
+#endif
+    err = journal_end(&th, inode->i_sb, 1);
+
+    /* copy back the error code from journal_begin */
+    if (!err)
+        err = jbegin_failure;
+
+    if (!err && atomic_read(&inode->i_count) <= 1 &&
+	(REISERFS_I(inode)->i_flags & i_pack_on_close_mask) &&
+        tail_has_to_be_packed (inode)) {
+	/* if regular file is released by last holder and it has been
+	   appended (we append by unformatted node only) or its direct
+	   item(s) had to be converted, then it may have to be
+	   indirect2direct converted */
+	err = reiserfs_truncate_file(inode, 0) ;
+    }
+out:
+    up (&inode->i_sem); 
+    reiserfs_write_unlock(inode->i_sb);
+    return err;
+}
+
+static void reiserfs_vfs_truncate_file(struct inode *inode) {
+    reiserfs_truncate_file(inode, 1) ;
+}
+
+/* Sync a reiserfs file. */
+
+/*
+ * FIXME: sync_mapping_buffers() never has anything to sync.  Can
+ * be removed...
+ */
+
+static int reiserfs_sync_file(
+			      struct file   * p_s_filp,
+			      struct dentry * p_s_dentry,
+			      int datasync
+			      ) {
+  struct inode * p_s_inode = p_s_dentry->d_inode;
+  int n_err;
+  int barrier_done;
+
+  if (!S_ISREG(p_s_inode->i_mode))
+      BUG ();
+  n_err = sync_mapping_buffers(p_s_inode->i_mapping) ;
+  reiserfs_write_lock(p_s_inode->i_sb);
+  barrier_done = reiserfs_commit_for_inode(p_s_inode);
+  reiserfs_write_unlock(p_s_inode->i_sb);
+  if (barrier_done != 1)
+      blkdev_issue_flush(p_s_inode->i_sb->s_bdev, NULL);
+  if (barrier_done < 0)
+    return barrier_done;
+  return ( n_err < 0 ) ? -EIO : 0;
+}
+
+/* I really do not want to play with memory shortage right now, so
+   to simplify the code, we are not going to write more than this much pages at
+   a time. This still should considerably improve performance compared to 4k
+   at a time case. This is 32 pages of 4k size. */
+#define REISERFS_WRITE_PAGES_AT_A_TIME (128 * 1024) / PAGE_CACHE_SIZE
+
+/* Allocates blocks for a file to fulfil write request.
+   Maps all unmapped but prepared pages from the list.
+   Updates metadata with newly allocated blocknumbers as needed */
+static int reiserfs_allocate_blocks_for_region(
+				struct reiserfs_transaction_handle *th,
+				struct inode *inode, /* Inode we work with */
+				loff_t pos, /* Writing position */
+				int num_pages, /* number of pages write going
+						  to touch */
+				int write_bytes, /* amount of bytes to write */
+				struct page **prepared_pages, /* array of
+							         prepared pages
+							       */
+				int blocks_to_allocate /* Amount of blocks we
+							  need to allocate to
+							  fit the data into file
+							 */
+				)
+{
+    struct cpu_key key; // cpu key of item that we are going to deal with
+    struct item_head *ih; // pointer to item head that we are going to deal with
+    struct buffer_head *bh; // Buffer head that contains items that we are going to deal with
+    __u32 * item; // pointer to item we are going to deal with
+    INITIALIZE_PATH(path); // path to item, that we are going to deal with.
+    b_blocknr_t *allocated_blocks; // Pointer to a place where allocated blocknumbers would be stored.
+    reiserfs_blocknr_hint_t hint; // hint structure for block allocator.
+    size_t res; // return value of various functions that we call.
+    int curr_block; // current block used to keep track of unmapped blocks.
+    int i; // loop counter
+    int itempos; // position in item
+    unsigned int from = (pos & (PAGE_CACHE_SIZE - 1)); // writing position in
+						       // first page
+    unsigned int to = ((pos + write_bytes - 1) & (PAGE_CACHE_SIZE - 1)) + 1; /* last modified byte offset in last page */
+    __u64 hole_size ; // amount of blocks for a file hole, if it needed to be created.
+    int modifying_this_item = 0; // Flag for items traversal code to keep track
+				 // of the fact that we already prepared
+				 // current block for journal
+    int will_prealloc = 0;
+    RFALSE(!blocks_to_allocate, "green-9004: tried to allocate zero blocks?");
+
+    /* only preallocate if this is a small write */
+    if (REISERFS_I(inode)->i_prealloc_count ||
+       (!(write_bytes & (inode->i_sb->s_blocksize -1)) &&
+        blocks_to_allocate <
+        REISERFS_SB(inode->i_sb)->s_alloc_options.preallocsize))
+        will_prealloc = REISERFS_SB(inode->i_sb)->s_alloc_options.preallocsize;
+
+    allocated_blocks = kmalloc((blocks_to_allocate + will_prealloc) *
+    					sizeof(b_blocknr_t), GFP_NOFS);
+
+    /* First we compose a key to point at the writing position, we want to do
+       that outside of any locking region. */
+    make_cpu_key (&key, inode, pos+1, TYPE_ANY, 3/*key length*/);
+
+    /* If we came here, it means we absolutely need to open a transaction,
+       since we need to allocate some blocks */
+    reiserfs_write_lock(inode->i_sb); // Journaling stuff and we need that.
+    res = journal_begin(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS); // Wish I know if this number enough
+    if (res)
+        goto error_exit;
+    reiserfs_update_inode_transaction(inode) ;
+
+    /* Look for the in-tree position of our write, need path for block allocator */
+    res = search_for_position_by_key(inode->i_sb, &key, &path);
+    if ( res == IO_ERROR ) {
+	res = -EIO;
+	goto error_exit;
+    }
+   
+    /* Allocate blocks */
+    /* First fill in "hint" structure for block allocator */
+    hint.th = th; // transaction handle.
+    hint.path = &path; // Path, so that block allocator can determine packing locality or whatever it needs to determine.
+    hint.inode = inode; // Inode is needed by block allocator too.
+    hint.search_start = 0; // We have no hint on where to search free blocks for block allocator.
+    hint.key = key.on_disk_key; // on disk key of file.
+    hint.block = inode->i_blocks>>(inode->i_sb->s_blocksize_bits-9); // Number of disk blocks this file occupies already.
+    hint.formatted_node = 0; // We are allocating blocks for unformatted node.
+    hint.preallocate = will_prealloc;
+
+    /* Call block allocator to allocate blocks */
+    res = reiserfs_allocate_blocknrs(&hint, allocated_blocks, blocks_to_allocate, blocks_to_allocate);
+    if ( res != CARRY_ON ) {
+	if ( res == NO_DISK_SPACE ) {
+	    /* We flush the transaction in case of no space. This way some
+	       blocks might become free */
+	    SB_JOURNAL(inode->i_sb)->j_must_wait = 1;
+	    res = restart_transaction(th, inode, &path);
+            if (res)
+                goto error_exit;
+
+	    /* We might have scheduled, so search again */
+	    res = search_for_position_by_key(inode->i_sb, &key, &path);
+	    if ( res == IO_ERROR ) {
+		res = -EIO;
+		goto error_exit;
+	    }
+
+	    /* update changed info for hint structure. */
+	    res = reiserfs_allocate_blocknrs(&hint, allocated_blocks, blocks_to_allocate, blocks_to_allocate);
+	    if ( res != CARRY_ON ) {
+		res = -ENOSPC; 
+		pathrelse(&path);
+		goto error_exit;
+	    }
+	} else {
+	    res = -ENOSPC;
+	    pathrelse(&path);
+	    goto error_exit;
+	}
+    }
+
+#ifdef __BIG_ENDIAN
+        // Too bad, I have not found any way to convert a given region from
+        // cpu format to little endian format
+    {
+        int i;
+        for ( i = 0; i < blocks_to_allocate ; i++)
+            allocated_blocks[i]=cpu_to_le32(allocated_blocks[i]);
+    }
+#endif
+
+    /* Blocks allocating well might have scheduled and tree might have changed,
+       let's search the tree again */
+    /* find where in the tree our write should go */
+    res = search_for_position_by_key(inode->i_sb, &key, &path);
+    if ( res == IO_ERROR ) {
+	res = -EIO;
+	goto error_exit_free_blocks;
+    }
+
+    bh = get_last_bh( &path ); // Get a bufferhead for last element in path.
+    ih = get_ih( &path );      // Get a pointer to last item head in path.
+    item = get_item( &path );  // Get a pointer to last item in path
+
+    /* Let's see what we have found */
+    if ( res != POSITION_FOUND ) { /* position not found, this means that we
+				      might need to append file with holes
+				      first */
+	// Since we are writing past the file's end, we need to find out if
+	// there is a hole that needs to be inserted before our writing
+	// position, and how many blocks it is going to cover (we need to
+	//  populate pointers to file blocks representing the hole with zeros)
+
+	{
+	    int item_offset = 1;
+	    /*
+	     * if ih is stat data, its offset is 0 and we don't want to
+	     * add 1 to pos in the hole_size calculation
+	     */
+	    if (is_statdata_le_ih(ih))
+	        item_offset = 0;
+	    hole_size = (pos + item_offset -
+	            (le_key_k_offset( get_inode_item_key_version(inode),
+		    &(ih->ih_key)) +
+		    op_bytes_number(ih, inode->i_sb->s_blocksize))) >>
+		    inode->i_sb->s_blocksize_bits;
+	}
+
+	if ( hole_size > 0 ) {
+	    int to_paste = min_t(__u64, hole_size, MAX_ITEM_LEN(inode->i_sb->s_blocksize)/UNFM_P_SIZE ); // How much data to insert first time.
+	    /* area filled with zeroes, to supply as list of zero blocknumbers
+	       We allocate it outside of loop just in case loop would spin for
+	       several iterations. */
+	    char *zeros = kmalloc(to_paste*UNFM_P_SIZE, GFP_ATOMIC); // We cannot insert more than MAX_ITEM_LEN bytes anyway.
+	    if ( !zeros ) {
+		res = -ENOMEM;
+		goto error_exit_free_blocks;
+	    }
+	    memset ( zeros, 0, to_paste*UNFM_P_SIZE);
+	    do {
+		to_paste = min_t(__u64, hole_size, MAX_ITEM_LEN(inode->i_sb->s_blocksize)/UNFM_P_SIZE );
+		if ( is_indirect_le_ih(ih) ) {
+		    /* Ok, there is existing indirect item already. Need to append it */
+		    /* Calculate position past inserted item */
+		    make_cpu_key( &key, inode, le_key_k_offset( get_inode_item_key_version(inode), &(ih->ih_key)) + op_bytes_number(ih, inode->i_sb->s_blocksize), TYPE_INDIRECT, 3);
+		    res = reiserfs_paste_into_item( th, &path, &key, inode, (char *)zeros, UNFM_P_SIZE*to_paste);
+		    if ( res ) {
+			kfree(zeros);
+			goto error_exit_free_blocks;
+		    }
+		} else if ( is_statdata_le_ih(ih) ) {
+		    /* No existing item, create it */
+		    /* item head for new item */
+		    struct item_head ins_ih;
+
+		    /* create a key for our new item */
+		    make_cpu_key( &key, inode, 1, TYPE_INDIRECT, 3);
+
+		    /* Create new item head for our new item */
+		    make_le_item_head (&ins_ih, &key, key.version, 1,
+				       TYPE_INDIRECT, to_paste*UNFM_P_SIZE,
+				       0 /* free space */);
+
+		    /* Find where such item should live in the tree */
+		    res = search_item (inode->i_sb, &key, &path);
+		    if ( res != ITEM_NOT_FOUND ) {
+			/* item should not exist, otherwise we have error */
+			if ( res != -ENOSPC ) {
+			    reiserfs_warning (inode->i_sb,
+				"green-9008: search_by_key (%K) returned %d",
+					      &key, res);
+			}
+			res = -EIO;
+		        kfree(zeros);
+			goto error_exit_free_blocks;
+		    }
+		    res = reiserfs_insert_item( th, &path, &key, &ins_ih, inode, (char *)zeros);
+		} else {
+		    reiserfs_panic(inode->i_sb, "green-9011: Unexpected key type %K\n", &key);
+		}
+		if ( res ) {
+		    kfree(zeros);
+		    goto error_exit_free_blocks;
+		}
+		/* Now we want to check if transaction is too full, and if it is
+		   we restart it. This will also free the path. */
+		if (journal_transaction_should_end(th, th->t_blocks_allocated)) {
+		    res = restart_transaction(th, inode, &path);
+                    if (res) {
+                        pathrelse (&path);
+                        kfree(zeros);
+                        goto error_exit;
+                    }
+                }
+
+		/* Well, need to recalculate path and stuff */
+		set_cpu_key_k_offset( &key, cpu_key_k_offset(&key) + (to_paste << inode->i_blkbits));
+		res = search_for_position_by_key(inode->i_sb, &key, &path);
+		if ( res == IO_ERROR ) {
+		    res = -EIO;
+		    kfree(zeros);
+		    goto error_exit_free_blocks;
+		}
+		bh=get_last_bh(&path);
+		ih=get_ih(&path);
+		item = get_item(&path);
+		hole_size -= to_paste;
+	    } while ( hole_size );
+	    kfree(zeros);
+	}
+    }
+
+    // Go through existing indirect items first
+    // replace all zeroes with blocknumbers from list
+    // Note that if no corresponding item was found, by previous search,
+    // it means there are no existing in-tree representation for file area
+    // we are going to overwrite, so there is nothing to scan through for holes.
+    for ( curr_block = 0, itempos = path.pos_in_item ; curr_block < blocks_to_allocate && res == POSITION_FOUND ; ) {
+retry:
+
+	if ( itempos >= ih_item_len(ih)/UNFM_P_SIZE ) {
+	    /* We run out of data in this indirect item, let's look for another
+	       one. */
+	    /* First if we are already modifying current item, log it */
+	    if ( modifying_this_item ) {
+		journal_mark_dirty (th, inode->i_sb, bh);
+		modifying_this_item = 0;
+	    }
+	    /* Then set the key to look for a new indirect item (offset of old
+	       item is added to old item length */
+	    set_cpu_key_k_offset( &key, le_key_k_offset( get_inode_item_key_version(inode), &(ih->ih_key)) + op_bytes_number(ih, inode->i_sb->s_blocksize));
+	    /* Search ofor position of new key in the tree. */
+	    res = search_for_position_by_key(inode->i_sb, &key, &path);
+	    if ( res == IO_ERROR) {
+		res = -EIO;
+		goto error_exit_free_blocks;
+	    }
+	    bh=get_last_bh(&path);
+	    ih=get_ih(&path);
+	    item = get_item(&path);
+	    itempos = path.pos_in_item;
+	    continue; // loop to check all kinds of conditions and so on.
+	}
+	/* Ok, we have correct position in item now, so let's see if it is
+	   representing file hole (blocknumber is zero) and fill it if needed */
+	if ( !item[itempos] ) {
+	    /* Ok, a hole. Now we need to check if we already prepared this
+	       block to be journaled */
+	    while ( !modifying_this_item ) { // loop until succeed
+		/* Well, this item is not journaled yet, so we must prepare
+		   it for journal first, before we can change it */
+		struct item_head tmp_ih; // We copy item head of found item,
+					 // here to detect if fs changed under
+					 // us while we were preparing for
+					 // journal.
+		int fs_gen; // We store fs generation here to find if someone
+			    // changes fs under our feet
+
+		copy_item_head (&tmp_ih, ih); // Remember itemhead
+		fs_gen = get_generation (inode->i_sb); // remember fs generation
+		reiserfs_prepare_for_journal(inode->i_sb, bh, 1); // Prepare a buffer within which indirect item is stored for changing.
+		if (fs_changed (fs_gen, inode->i_sb) && item_moved (&tmp_ih, &path)) {
+		    // Sigh, fs was changed under us, we need to look for new
+		    // location of item we are working with
+
+		    /* unmark prepaerd area as journaled and search for it's
+		       new position */
+		    reiserfs_restore_prepared_buffer(inode->i_sb, bh);
+		    res = search_for_position_by_key(inode->i_sb, &key, &path);
+		    if ( res == IO_ERROR) {
+			res = -EIO;
+			goto error_exit_free_blocks;
+		    }
+		    bh=get_last_bh(&path);
+		    ih=get_ih(&path);
+		    item = get_item(&path);
+		    itempos = path.pos_in_item;
+		    goto retry;
+		}
+		modifying_this_item = 1;
+	    }
+	    item[itempos] = allocated_blocks[curr_block]; // Assign new block
+	    curr_block++;
+	}
+	itempos++;
+    }
+
+    if ( modifying_this_item ) { // We need to log last-accessed block, if it
+				 // was modified, but not logged yet.
+	journal_mark_dirty (th, inode->i_sb, bh);
+    }
+
+    if ( curr_block < blocks_to_allocate ) {
+	// Oh, well need to append to indirect item, or to create indirect item
+	// if there weren't any
+	if ( is_indirect_le_ih(ih) ) {
+	    // Existing indirect item - append. First calculate key for append
+	    // position. We do not need to recalculate path as it should
+	    // already point to correct place.
+	    make_cpu_key( &key, inode, le_key_k_offset( get_inode_item_key_version(inode), &(ih->ih_key)) + op_bytes_number(ih, inode->i_sb->s_blocksize), TYPE_INDIRECT, 3);
+	    res = reiserfs_paste_into_item( th, &path, &key, inode, (char *)(allocated_blocks+curr_block), UNFM_P_SIZE*(blocks_to_allocate-curr_block));
+	    if ( res ) {
+		goto error_exit_free_blocks;
+	    }
+	} else if (is_statdata_le_ih(ih) ) {
+	    // Last found item was statdata. That means we need to create indirect item.
+	    struct item_head ins_ih; /* itemhead for new item */
+
+	    /* create a key for our new item */
+	    make_cpu_key( &key, inode, 1, TYPE_INDIRECT, 3); // Position one,
+							    // because that's
+							    // where first
+							    // indirect item
+							    // begins
+	    /* Create new item head for our new item */
+	    make_le_item_head (&ins_ih, &key, key.version, 1, TYPE_INDIRECT,
+			       (blocks_to_allocate-curr_block)*UNFM_P_SIZE,
+			       0 /* free space */);
+	    /* Find where such item should live in the tree */
+	    res = search_item (inode->i_sb, &key, &path);
+	    if ( res != ITEM_NOT_FOUND ) {
+		/* Well, if we have found such item already, or some error
+		   occured, we need to warn user and return error */
+		if ( res != -ENOSPC ) {
+		    reiserfs_warning (inode->i_sb,
+				      "green-9009: search_by_key (%K) "
+				      "returned %d", &key, res);
+		}
+		res = -EIO;
+		goto error_exit_free_blocks;
+	    }
+	    /* Insert item into the tree with the data as its body */
+	    res = reiserfs_insert_item( th, &path, &key, &ins_ih, inode, (char *)(allocated_blocks+curr_block));
+	} else {
+	    reiserfs_panic(inode->i_sb, "green-9010: unexpected item type for key %K\n",&key);
+	}
+    }
+
+    // the caller is responsible for closing the transaction
+    // unless we return an error, they are also responsible for logging
+    // the inode.
+    //
+    pathrelse(&path);
+    /*
+     * cleanup prellocation from previous writes
+     * if this is a partial block write
+     */
+    if (write_bytes & (inode->i_sb->s_blocksize -1))
+        reiserfs_discard_prealloc(th, inode);
+    reiserfs_write_unlock(inode->i_sb);
+
+    // go through all the pages/buffers and map the buffers to newly allocated
+    // blocks (so that system knows where to write these pages later).
+    curr_block = 0;
+    for ( i = 0; i < num_pages ; i++ ) {
+	struct page *page=prepared_pages[i]; //current page
+	struct buffer_head *head = page_buffers(page);// first buffer for a page
+	int block_start, block_end; // in-page offsets for buffers.
+
+	if (!page_buffers(page))
+	    reiserfs_panic(inode->i_sb, "green-9005: No buffers for prepared page???");
+
+	/* For each buffer in page */
+	for(bh = head, block_start = 0; bh != head || !block_start;
+	    block_start=block_end, bh = bh->b_this_page) {
+	    if (!bh)
+		reiserfs_panic(inode->i_sb, "green-9006: Allocated but absent buffer for a page?");
+	    block_end = block_start+inode->i_sb->s_blocksize;
+	    if (i == 0 && block_end <= from )
+		/* if this buffer is before requested data to map, skip it */
+		continue;
+	    if (i == num_pages - 1 && block_start >= to)
+		/* If this buffer is after requested data to map, abort
+		   processing of current page */
+		break;
+
+	    if ( !buffer_mapped(bh) ) { // Ok, unmapped buffer, need to map it
+		map_bh( bh, inode->i_sb, le32_to_cpu(allocated_blocks[curr_block]));
+		curr_block++;
+		set_buffer_new(bh);
+	    }
+	}
+    }
+
+    RFALSE( curr_block > blocks_to_allocate, "green-9007: Used too many blocks? weird");
+
+    kfree(allocated_blocks);
+    return 0;
+
+// Need to deal with transaction here.
+error_exit_free_blocks:
+    pathrelse(&path);
+    // free blocks
+    for( i = 0; i < blocks_to_allocate; i++ )
+	reiserfs_free_block(th, inode, le32_to_cpu(allocated_blocks[i]), 1);
+
+error_exit:
+    if (th->t_trans_id) {
+        int err;
+        // update any changes we made to blk count
+        reiserfs_update_sd(th, inode);
+        err = journal_end(th, inode->i_sb, JOURNAL_PER_BALANCE_CNT * 3 + 1 + 2 * REISERFS_QUOTA_TRANS_BLOCKS);
+        if (err)
+            res = err;
+    }
+    reiserfs_write_unlock(inode->i_sb);
+    kfree(allocated_blocks);
+
+    return res;
+}
+
+/* Unlock pages prepared by reiserfs_prepare_file_region_for_write */
+static void reiserfs_unprepare_pages(struct page **prepared_pages, /* list of locked pages */
+			      size_t num_pages /* amount of pages */) {
+    int i; // loop counter
+
+    for (i=0; i < num_pages ; i++) {
+	struct page *page = prepared_pages[i];
+
+	try_to_free_buffers(page);
+	unlock_page(page);
+	page_cache_release(page);
+    }
+}
+
+/* This function will copy data from userspace to specified pages within
+   supplied byte range */
+static int reiserfs_copy_from_user_to_file_region(
+				loff_t pos, /* In-file position */
+				int num_pages, /* Number of pages affected */
+				int write_bytes, /* Amount of bytes to write */
+				struct page **prepared_pages, /* pointer to 
+								 array to
+								 prepared pages
+								*/
+				const char __user *buf /* Pointer to user-supplied
+						   data*/
+				)
+{
+    long page_fault=0; // status of copy_from_user.
+    int i; // loop counter.
+    int offset; // offset in page
+
+    for ( i = 0, offset = (pos & (PAGE_CACHE_SIZE-1)); i < num_pages ; i++,offset=0) {
+	size_t count = min_t(size_t,PAGE_CACHE_SIZE-offset,write_bytes); // How much of bytes to write to this page
+	struct page *page=prepared_pages[i]; // Current page we process.
+
+	fault_in_pages_readable( buf, count);
+
+	/* Copy data from userspace to the current page */
+	kmap(page);
+	page_fault = __copy_from_user(page_address(page)+offset, buf, count); // Copy the data.
+	/* Flush processor's dcache for this page */
+	flush_dcache_page(page);
+	kunmap(page);
+	buf+=count;
+	write_bytes-=count;
+
+	if (page_fault)
+	    break; // Was there a fault? abort.
+    }
+
+    return page_fault?-EFAULT:0;
+}
+
+/* taken fs/buffer.c:__block_commit_write */
+int reiserfs_commit_page(struct inode *inode, struct page *page,
+		unsigned from, unsigned to)
+{
+    unsigned block_start, block_end;
+    int partial = 0;
+    unsigned blocksize;
+    struct buffer_head *bh, *head;
+    unsigned long i_size_index = inode->i_size >> PAGE_CACHE_SHIFT;
+    int new;
+    int logit = reiserfs_file_data_log(inode);
+    struct super_block *s = inode->i_sb;
+    int bh_per_page = PAGE_CACHE_SIZE / s->s_blocksize;
+    struct reiserfs_transaction_handle th;
+    int ret = 0;
+
+    th.t_trans_id = 0;
+    blocksize = 1 << inode->i_blkbits;
+
+    if (logit) {
+	reiserfs_write_lock(s);
+	ret = journal_begin(&th, s, bh_per_page + 1);
+	if (ret)
+	    goto drop_write_lock;
+	reiserfs_update_inode_transaction(inode);
+    }
+    for(bh = head = page_buffers(page), block_start = 0;
+        bh != head || !block_start;
+	block_start=block_end, bh = bh->b_this_page)
+    {
+
+	new = buffer_new(bh);
+	clear_buffer_new(bh);
+	block_end = block_start + blocksize;
+	if (block_end <= from || block_start >= to) {
+	    if (!buffer_uptodate(bh))
+		    partial = 1;
+	} else {
+	    set_buffer_uptodate(bh);
+	    if (logit) {
+		reiserfs_prepare_for_journal(s, bh, 1);
+		journal_mark_dirty(&th, s, bh);
+	    } else if (!buffer_dirty(bh)) {
+		mark_buffer_dirty(bh);
+		/* do data=ordered on any page past the end
+		 * of file and any buffer marked BH_New.
+		 */
+		if (reiserfs_data_ordered(inode->i_sb) &&
+		    (new || page->index >= i_size_index)) {
+		    reiserfs_add_ordered_list(inode, bh);
+	        }
+	    }
+	}
+    }
+    if (logit) {
+	ret = journal_end(&th, s, bh_per_page + 1);
+drop_write_lock:
+	reiserfs_write_unlock(s);
+    }
+    /*
+     * If this is a partial write which happened to make all buffers
+     * uptodate then we can optimize away a bogus readpage() for
+     * the next read(). Here we 'discover' whether the page went
+     * uptodate as a result of this (potentially partial) write.
+     */
+    if (!partial)
+	SetPageUptodate(page);
+    return ret;
+}
+
+
+/* Submit pages for write. This was separated from actual file copying
+   because we might want to allocate block numbers in-between.
+   This function assumes that caller will adjust file size to correct value. */
+static int reiserfs_submit_file_region_for_write(
+				struct reiserfs_transaction_handle *th,
+				struct inode *inode,
+				loff_t pos, /* Writing position offset */
+				size_t num_pages, /* Number of pages to write */
+				size_t write_bytes, /* number of bytes to write */
+				struct page **prepared_pages /* list of pages */
+				)
+{
+    int status; // return status of block_commit_write.
+    int retval = 0; // Return value we are going to return.
+    int i; // loop counter
+    int offset; // Writing offset in page.
+    int orig_write_bytes = write_bytes;
+    int sd_update = 0;
+
+    for ( i = 0, offset = (pos & (PAGE_CACHE_SIZE-1)); i < num_pages ; i++,offset=0) {
+	int count = min_t(int,PAGE_CACHE_SIZE-offset,write_bytes); // How much of bytes to write to this page
+	struct page *page=prepared_pages[i]; // Current page we process.
+
+	status = reiserfs_commit_page(inode, page, offset, offset+count);
+	if ( status )
+	    retval = status; // To not overcomplicate matters We are going to
+			     // submit all the pages even if there was error.
+			     // we only remember error status to report it on
+			     // exit.
+	write_bytes-=count;
+    }
+    /* now that we've gotten all the ordered buffers marked dirty,
+     * we can safely update i_size and close any running transaction
+     */
+    if ( pos + orig_write_bytes > inode->i_size) {
+	inode->i_size = pos + orig_write_bytes; // Set new size
+	/* If the file have grown so much that tail packing is no
+	 * longer possible, reset "need to pack" flag */
+	if ( (have_large_tails (inode->i_sb) &&
+	      inode->i_size > i_block_size (inode)*4) ||
+	     (have_small_tails (inode->i_sb) &&
+	     inode->i_size > i_block_size(inode)) )
+	    REISERFS_I(inode)->i_flags &= ~i_pack_on_close_mask ;
+        else if ( (have_large_tails (inode->i_sb) &&
+	          inode->i_size < i_block_size (inode)*4) ||
+	          (have_small_tails (inode->i_sb) &&
+		  inode->i_size < i_block_size(inode)) )
+	    REISERFS_I(inode)->i_flags |= i_pack_on_close_mask ;
+
+	if (th->t_trans_id) {
+	    reiserfs_write_lock(inode->i_sb);
+	    reiserfs_update_sd(th, inode); // And update on-disk metadata
+	    reiserfs_write_unlock(inode->i_sb);
+	} else
+	    inode->i_sb->s_op->dirty_inode(inode);
+
+        sd_update = 1;
+    }
+    if (th->t_trans_id) {
+	reiserfs_write_lock(inode->i_sb);
+	if (!sd_update)
+	    reiserfs_update_sd(th, inode);
+	status = journal_end(th, th->t_super, th->t_blocks_allocated);
+        if (status)
+            retval = status;
+	reiserfs_write_unlock(inode->i_sb);
+    }
+    th->t_trans_id = 0;
+
+    /* 
+     * we have to unlock the pages after updating i_size, otherwise
+     * we race with writepage
+     */
+    for ( i = 0; i < num_pages ; i++) {
+	struct page *page=prepared_pages[i];
+	unlock_page(page); 
+	mark_page_accessed(page);
+	page_cache_release(page);
+    }
+    return retval;
+}
+
+/* Look if passed writing region is going to touch file's tail
+   (if it is present). And if it is, convert the tail to unformatted node */
+static int reiserfs_check_for_tail_and_convert( struct inode *inode, /* inode to deal with */
+					 loff_t pos, /* Writing position */
+					 int write_bytes /* amount of bytes to write */
+				        )
+{
+    INITIALIZE_PATH(path); // needed for search_for_position
+    struct cpu_key key; // Key that would represent last touched writing byte.
+    struct item_head *ih; // item header of found block;
+    int res; // Return value of various functions we call.
+    int cont_expand_offset; // We will put offset for generic_cont_expand here
+			    // This can be int just because tails are created
+			    // only for small files.
+ 
+/* this embodies a dependency on a particular tail policy */
+    if ( inode->i_size >= inode->i_sb->s_blocksize*4 ) {
+	/* such a big files do not have tails, so we won't bother ourselves
+	   to look for tails, simply return */
+	return 0;
+    }
+
+    reiserfs_write_lock(inode->i_sb);
+    /* find the item containing the last byte to be written, or if
+     * writing past the end of the file then the last item of the
+     * file (and then we check its type). */
+    make_cpu_key (&key, inode, pos+write_bytes+1, TYPE_ANY, 3/*key length*/);
+    res = search_for_position_by_key(inode->i_sb, &key, &path);
+    if ( res == IO_ERROR ) {
+        reiserfs_write_unlock(inode->i_sb);
+	return -EIO;
+    }
+    ih = get_ih(&path);
+    res = 0;
+    if ( is_direct_le_ih(ih) ) {
+	/* Ok, closest item is file tail (tails are stored in "direct"
+	 * items), so we need to unpack it. */
+	/* To not overcomplicate matters, we just call generic_cont_expand
+	   which will in turn call other stuff and finally will boil down to
+	    reiserfs_get_block() that would do necessary conversion. */
+	cont_expand_offset = le_key_k_offset(get_inode_item_key_version(inode), &(ih->ih_key));
+	pathrelse(&path);
+	res = generic_cont_expand( inode, cont_expand_offset);
+    } else
+	pathrelse(&path);
+
+    reiserfs_write_unlock(inode->i_sb);
+    return res;
+}
+
+/* This function locks pages starting from @pos for @inode.
+   @num_pages pages are locked and stored in
+   @prepared_pages array. Also buffers are allocated for these pages.
+   First and last page of the region is read if it is overwritten only
+   partially. If last page did not exist before write (file hole or file
+   append), it is zeroed, then. 
+   Returns number of unallocated blocks that should be allocated to cover
+   new file data.*/
+static int reiserfs_prepare_file_region_for_write(
+				struct inode *inode /* Inode of the file */,
+				loff_t pos, /* position in the file */
+				size_t num_pages, /* number of pages to
+					          prepare */
+				size_t write_bytes, /* Amount of bytes to be
+						    overwritten from
+						    @pos */
+				struct page **prepared_pages /* pointer to array
+							       where to store
+							       prepared pages */
+					   )
+{
+    int res=0; // Return values of different functions we call.
+    unsigned long index = pos >> PAGE_CACHE_SHIFT; // Offset in file in pages.
+    int from = (pos & (PAGE_CACHE_SIZE - 1)); // Writing offset in first page
+    int to = ((pos + write_bytes - 1) & (PAGE_CACHE_SIZE - 1)) + 1;
+					 /* offset of last modified byte in last
+				            page */
+    struct address_space *mapping = inode->i_mapping; // Pages are mapped here.
+    int i; // Simple counter
+    int blocks = 0; /* Return value (blocks that should be allocated) */
+    struct buffer_head *bh, *head; // Current bufferhead and first bufferhead
+				   // of a page.
+    unsigned block_start, block_end; // Starting and ending offsets of current
+				     // buffer in the page.
+    struct buffer_head *wait[2], **wait_bh=wait; // Buffers for page, if
+						 // Page appeared to be not up
+						 // to date. Note how we have
+						 // at most 2 buffers, this is
+						 // because we at most may
+						 // partially overwrite two
+						 // buffers for one page. One at                                                 // the beginning of write area
+						 // and one at the end.
+						 // Everything inthe middle gets                                                 // overwritten totally.
+
+    struct cpu_key key; // cpu key of item that we are going to deal with
+    struct item_head *ih = NULL; // pointer to item head that we are going to deal with
+    struct buffer_head *itembuf=NULL; // Buffer head that contains items that we are going to deal with
+    INITIALIZE_PATH(path); // path to item, that we are going to deal with.
+    __u32 * item=NULL; // pointer to item we are going to deal with
+    int item_pos=-1; /* Position in indirect item */
+
+
+    if ( num_pages < 1 ) {
+	reiserfs_warning (inode->i_sb,
+			  "green-9001: reiserfs_prepare_file_region_for_write "
+			  "called with zero number of pages to process");
+	return -EFAULT;
+    }
+
+    /* We have 2 loops for pages. In first loop we grab and lock the pages, so
+       that nobody would touch these until we release the pages. Then
+       we'd start to deal with mapping buffers to blocks. */
+    for ( i = 0; i < num_pages; i++) {
+	prepared_pages[i] = grab_cache_page(mapping, index + i); // locks the page
+	if ( !prepared_pages[i]) {
+	    res = -ENOMEM;
+	    goto failed_page_grabbing;
+	}
+	if (!page_has_buffers(prepared_pages[i]))
+	    create_empty_buffers(prepared_pages[i], inode->i_sb->s_blocksize, 0);
+    }
+
+    /* Let's count amount of blocks for a case where all the blocks
+       overwritten are new (we will substract already allocated blocks later)*/
+    if ( num_pages > 2 )
+	/* These are full-overwritten pages so we count all the blocks in
+	   these pages are counted as needed to be allocated */
+	blocks = (num_pages - 2) << (PAGE_CACHE_SHIFT - inode->i_blkbits);
+
+    /* count blocks needed for first page (possibly partially written) */
+    blocks += ((PAGE_CACHE_SIZE - from) >> inode->i_blkbits) +
+	   !!(from & (inode->i_sb->s_blocksize-1)); /* roundup */
+
+    /* Now we account for last page. If last page == first page (we
+       overwrite only one page), we substract all the blocks past the
+       last writing position in a page out of already calculated number
+       of blocks */
+    blocks += ((num_pages > 1) << (PAGE_CACHE_SHIFT-inode->i_blkbits)) -
+	   ((PAGE_CACHE_SIZE - to) >> inode->i_blkbits);
+	   /* Note how we do not roundup here since partial blocks still
+		   should be allocated */
+
+    /* Now if all the write area lies past the file end, no point in
+       maping blocks, since there is none, so we just zero out remaining
+       parts of first and last pages in write area (if needed) */
+    if ( (pos & ~((loff_t)PAGE_CACHE_SIZE - 1)) > inode->i_size ) {
+	if ( from != 0 ) {/* First page needs to be partially zeroed */
+	    char *kaddr = kmap_atomic(prepared_pages[0], KM_USER0);
+	    memset(kaddr, 0, from);
+	    kunmap_atomic( kaddr, KM_USER0);
+	}
+	if ( to != PAGE_CACHE_SIZE ) { /* Last page needs to be partially zeroed */
+	    char *kaddr = kmap_atomic(prepared_pages[num_pages-1], KM_USER0);
+	    memset(kaddr+to, 0, PAGE_CACHE_SIZE - to);
+	    kunmap_atomic( kaddr, KM_USER0);
+	}
+
+	/* Since all blocks are new - use already calculated value */
+	return blocks;
+    }
+
+    /* Well, since we write somewhere into the middle of a file, there is
+       possibility we are writing over some already allocated blocks, so
+       let's map these blocks and substract number of such blocks out of blocks
+       we need to allocate (calculated above) */
+    /* Mask write position to start on blocksize, we do it out of the
+       loop for performance reasons */
+    pos &= ~((loff_t) inode->i_sb->s_blocksize - 1);
+    /* Set cpu key to the starting position in a file (on left block boundary)*/
+    make_cpu_key (&key, inode, 1 + ((pos) & ~((loff_t) inode->i_sb->s_blocksize - 1)), TYPE_ANY, 3/*key length*/);
+
+    reiserfs_write_lock(inode->i_sb); // We need that for at least search_by_key()
+    for ( i = 0; i < num_pages ; i++ ) { 
+
+	head = page_buffers(prepared_pages[i]);
+	/* For each buffer in the page */
+	for(bh = head, block_start = 0; bh != head || !block_start;
+	    block_start=block_end, bh = bh->b_this_page) {
+		if (!bh)
+		    reiserfs_panic(inode->i_sb, "green-9002: Allocated but absent buffer for a page?");
+		/* Find where this buffer ends */
+		block_end = block_start+inode->i_sb->s_blocksize;
+		if (i == 0 && block_end <= from )
+		    /* if this buffer is before requested data to map, skip it*/
+		    continue;
+
+		if (i == num_pages - 1 && block_start >= to) {
+		    /* If this buffer is after requested data to map, abort
+		       processing of current page */
+		    break;
+		}
+
+		if ( buffer_mapped(bh) && bh->b_blocknr !=0 ) {
+		    /* This is optimisation for a case where buffer is mapped
+		       and have blocknumber assigned. In case significant amount
+		       of such buffers are present, we may avoid some amount
+		       of search_by_key calls.
+		       Probably it would be possible to move parts of this code
+		       out of BKL, but I afraid that would overcomplicate code
+		       without any noticeable benefit.
+		    */
+		    item_pos++;
+		    /* Update the key */
+		    set_cpu_key_k_offset( &key, cpu_key_k_offset(&key) + inode->i_sb->s_blocksize);
+		    blocks--; // Decrease the amount of blocks that need to be
+			      // allocated
+		    continue; // Go to the next buffer
+		}
+
+		if ( !itembuf || /* if first iteration */
+		     item_pos >= ih_item_len(ih)/UNFM_P_SIZE)
+					     { /* or if we progressed past the
+						  current unformatted_item */
+			/* Try to find next item */
+			res = search_for_position_by_key(inode->i_sb, &key, &path);
+			/* Abort if no more items */
+			if ( res != POSITION_FOUND ) {
+			    /* make sure later loops don't use this item */
+			    itembuf = NULL;
+			    item = NULL;
+			    break;
+			}
+
+			/* Update information about current indirect item */
+			itembuf = get_last_bh( &path );
+			ih = get_ih( &path );
+			item = get_item( &path );
+			item_pos = path.pos_in_item;
+
+			RFALSE( !is_indirect_le_ih (ih), "green-9003: indirect item expected");
+		}
+
+		/* See if there is some block associated with the file
+		   at that position, map the buffer to this block */
+		if ( get_block_num(item,item_pos) ) {
+		    map_bh(bh, inode->i_sb, get_block_num(item,item_pos));
+		    blocks--; // Decrease the amount of blocks that need to be
+			      // allocated
+		}
+		item_pos++;
+		/* Update the key */
+		set_cpu_key_k_offset( &key, cpu_key_k_offset(&key) + inode->i_sb->s_blocksize);
+	}
+    }
+    pathrelse(&path); // Free the path
+    reiserfs_write_unlock(inode->i_sb);
+
+	/* Now zero out unmappend buffers for the first and last pages of
+	   write area or issue read requests if page is mapped. */
+	/* First page, see if it is not uptodate */
+	if ( !PageUptodate(prepared_pages[0]) ) {
+	    head = page_buffers(prepared_pages[0]);
+
+	    /* For each buffer in page */
+	    for(bh = head, block_start = 0; bh != head || !block_start;
+		block_start=block_end, bh = bh->b_this_page) {
+
+		if (!bh)
+		    reiserfs_panic(inode->i_sb, "green-9002: Allocated but absent buffer for a page?");
+		/* Find where this buffer ends */
+		block_end = block_start+inode->i_sb->s_blocksize;
+		if ( block_end <= from )
+		    /* if this buffer is before requested data to map, skip it*/
+		    continue;
+		if ( block_start < from ) { /* Aha, our partial buffer */
+		    if ( buffer_mapped(bh) ) { /* If it is mapped, we need to
+						  issue READ request for it to
+						  not loose data */
+			ll_rw_block(READ, 1, &bh);
+			*wait_bh++=bh;
+		    } else { /* Not mapped, zero it */
+			char *kaddr = kmap_atomic(prepared_pages[0], KM_USER0);
+			memset(kaddr+block_start, 0, from-block_start);
+			kunmap_atomic( kaddr, KM_USER0);
+			set_buffer_uptodate(bh);
+		    }
+		}
+	    }
+	}
+
+	/* Last page, see if it is not uptodate, or if the last page is past the end of the file. */
+	if ( !PageUptodate(prepared_pages[num_pages-1]) || 
+	    ((pos+write_bytes)>>PAGE_CACHE_SHIFT) > (inode->i_size>>PAGE_CACHE_SHIFT) ) {
+	    head = page_buffers(prepared_pages[num_pages-1]);
+
+	    /* for each buffer in page */
+	    for(bh = head, block_start = 0; bh != head || !block_start;
+		block_start=block_end, bh = bh->b_this_page) {
+
+		if (!bh)
+		    reiserfs_panic(inode->i_sb, "green-9002: Allocated but absent buffer for a page?");
+		/* Find where this buffer ends */
+		block_end = block_start+inode->i_sb->s_blocksize;
+		if ( block_start >= to )
+		    /* if this buffer is after requested data to map, skip it*/
+		    break;
+		if ( block_end > to ) { /* Aha, our partial buffer */
+		    if ( buffer_mapped(bh) ) { /* If it is mapped, we need to
+						  issue READ request for it to
+						  not loose data */
+			ll_rw_block(READ, 1, &bh);
+			*wait_bh++=bh;
+		    } else { /* Not mapped, zero it */
+			char *kaddr = kmap_atomic(prepared_pages[num_pages-1], KM_USER0);
+			memset(kaddr+to, 0, block_end-to);
+			kunmap_atomic( kaddr, KM_USER0);
+			set_buffer_uptodate(bh);
+		    }
+		}
+	    }
+	}
+
+    /* Wait for read requests we made to happen, if necessary */
+    while(wait_bh > wait) {
+	wait_on_buffer(*--wait_bh);
+	if (!buffer_uptodate(*wait_bh)) {
+	    res = -EIO;
+	    goto failed_read;
+	}
+    }
+
+    return blocks;
+failed_page_grabbing:
+    num_pages = i;
+failed_read:
+    reiserfs_unprepare_pages(prepared_pages, num_pages);
+    return res;
+}
+
+/* Write @count bytes at position @ppos in a file indicated by @file
+   from the buffer @buf.  
+
+   generic_file_write() is only appropriate for filesystems that are not seeking to optimize performance and want
+   something simple that works.  It is not for serious use by general purpose filesystems, excepting the one that it was
+   written for (ext2/3).  This is for several reasons:
+
+   * It has no understanding of any filesystem specific optimizations.
+
+   * It enters the filesystem repeatedly for each page that is written.
+
+   * It depends on reiserfs_get_block() function which if implemented by reiserfs performs costly search_by_key
+   * operation for each page it is supplied with. By contrast reiserfs_file_write() feeds as much as possible at a time
+   * to reiserfs which allows for fewer tree traversals.
+
+   * Each indirect pointer insertion takes a lot of cpu, because it involves memory moves inside of blocks.
+
+   * Asking the block allocation code for blocks one at a time is slightly less efficient.
+
+   All of these reasons for not using only generic file write were understood back when reiserfs was first miscoded to
+   use it, but we were in a hurry to make code freeze, and so it couldn't be revised then.  This new code should make
+   things right finally.
+
+   Future Features: providing search_by_key with hints.
+
+*/
+static ssize_t reiserfs_file_write( struct file *file, /* the file we are going to write into */
+                             const char __user *buf, /*  pointer to user supplied data
+(in userspace) */
+                             size_t count, /* amount of bytes to write */
+                             loff_t *ppos /* pointer to position in file that we start writing at. Should be updated to
+                                           * new current position before returning. */ )
+{
+    size_t already_written = 0; // Number of bytes already written to the file.
+    loff_t pos; // Current position in the file.
+    ssize_t res; // return value of various functions that we call.
+    int err = 0;
+    struct inode *inode = file->f_dentry->d_inode; // Inode of the file that we are writing to.
+				/* To simplify coding at this time, we store
+				   locked pages in array for now */
+    struct page * prepared_pages[REISERFS_WRITE_PAGES_AT_A_TIME];
+    struct reiserfs_transaction_handle th;
+    th.t_trans_id = 0;
+
+    if ( file->f_flags & O_DIRECT) { // Direct IO needs treatment
+	ssize_t result, after_file_end = 0;
+	if ( (*ppos + count >= inode->i_size) || (file->f_flags & O_APPEND) ) {
+	    /* If we are appending a file, we need to put this savelink in here.
+	       If we will crash while doing direct io, finish_unfinished will
+	       cut the garbage from the file end. */
+	    reiserfs_write_lock(inode->i_sb);
+	    err = journal_begin(&th, inode->i_sb,  JOURNAL_PER_BALANCE_CNT );
+            if (err) {
+		reiserfs_write_unlock (inode->i_sb);
+		return err;
+	    }
+	    reiserfs_update_inode_transaction(inode);
+	    add_save_link (&th, inode, 1 /* Truncate */);
+	    after_file_end = 1;
+	    err = journal_end(&th, inode->i_sb, JOURNAL_PER_BALANCE_CNT );
+            reiserfs_write_unlock(inode->i_sb);
+	    if (err)
+		return err;
+	}
+	result = generic_file_write(file, buf, count, ppos);
+
+	if ( after_file_end ) { /* Now update i_size and remove the savelink */
+	    struct reiserfs_transaction_handle th;
+	    reiserfs_write_lock(inode->i_sb);
+	    err = journal_begin(&th, inode->i_sb, 1);
+            if (err) {
+                reiserfs_write_unlock (inode->i_sb);
+                return err;
+            }
+	    reiserfs_update_inode_transaction(inode);
+	    reiserfs_update_sd(&th, inode);
+	    err = journal_end(&th, inode->i_sb, 1);
+            if (err) {
+                reiserfs_write_unlock (inode->i_sb);
+                return err;
+            }
+	    err = remove_save_link (inode, 1/* truncate */);
+	    reiserfs_write_unlock(inode->i_sb);
+            if (err)
+                return err;
+	}
+
+	return result;
+    }
+
+    if ( unlikely((ssize_t) count < 0 ))
+        return -EINVAL;
+
+    if (unlikely(!access_ok(VERIFY_READ, buf, count)))
+        return -EFAULT;
+
+    down(&inode->i_sem); // locks the entire file for just us
+
+    pos = *ppos;
+
+    /* Check if we can write to specified region of file, file
+       is not overly big and this kind of stuff. Adjust pos and
+       count, if needed */
+    res = generic_write_checks(file, &pos, &count, 0);
+    if (res)
+	goto out;
+
+    if ( count == 0 )
+	goto out;
+
+    res = remove_suid(file->f_dentry);
+    if (res)
+	goto out;
+
+    inode_update_time(inode, 1); /* Both mtime and ctime */
+
+    // Ok, we are done with all the checks.
+
+    // Now we should start real work
+
+    /* If we are going to write past the file's packed tail or if we are going
+       to overwrite part of the tail, we need that tail to be converted into
+       unformatted node */
+    res = reiserfs_check_for_tail_and_convert( inode, pos, count);
+    if (res)
+	goto out;
+
+    while ( count > 0) {
+	/* This is the main loop in which we running until some error occures
+	   or until we write all of the data. */
+	size_t num_pages;/* amount of pages we are going to write this iteration */
+	size_t write_bytes; /* amount of bytes to write during this iteration */
+	size_t blocks_to_allocate; /* how much blocks we need to allocate for this iteration */
+        
+        /*  (pos & (PAGE_CACHE_SIZE-1)) is an idiom for offset into a page of pos*/
+	num_pages = !!((pos+count) & (PAGE_CACHE_SIZE - 1)) + /* round up partial
+							  pages */
+		    ((count + (pos & (PAGE_CACHE_SIZE-1))) >> PAGE_CACHE_SHIFT); 
+						/* convert size to amount of
+						   pages */
+	reiserfs_write_lock(inode->i_sb);
+	if ( num_pages > REISERFS_WRITE_PAGES_AT_A_TIME 
+		|| num_pages > reiserfs_can_fit_pages(inode->i_sb) ) {
+	    /* If we were asked to write more data than we want to or if there
+	       is not that much space, then we shorten amount of data to write
+	       for this iteration. */
+	    num_pages = min_t(size_t, REISERFS_WRITE_PAGES_AT_A_TIME, reiserfs_can_fit_pages(inode->i_sb));
+	    /* Also we should not forget to set size in bytes accordingly */
+	    write_bytes = (num_pages << PAGE_CACHE_SHIFT) - 
+			    (pos & (PAGE_CACHE_SIZE-1));
+					 /* If position is not on the
+					    start of the page, we need
+					    to substract the offset
+					    within page */
+	} else
+	    write_bytes = count;
+
+	/* reserve the blocks to be allocated later, so that later on
+	   we still have the space to write the blocks to */
+	reiserfs_claim_blocks_to_be_allocated(inode->i_sb, num_pages << (PAGE_CACHE_SHIFT - inode->i_blkbits));
+	reiserfs_write_unlock(inode->i_sb);
+
+	if ( !num_pages ) { /* If we do not have enough space even for */
+	    res = -ENOSPC;  /* single page, return -ENOSPC */
+	    if ( pos > (inode->i_size & (inode->i_sb->s_blocksize-1)))
+		break; // In case we are writing past the file end, break.
+	    // Otherwise we are possibly overwriting the file, so
+	    // let's set write size to be equal or less than blocksize.
+	    // This way we get it correctly for file holes.
+	    // But overwriting files on absolutelly full volumes would not
+	    // be very efficient. Well, people are not supposed to fill
+	    // 100% of disk space anyway.
+	    write_bytes = min_t(size_t, count, inode->i_sb->s_blocksize - (pos & (inode->i_sb->s_blocksize - 1)));
+	    num_pages = 1;
+	    // No blocks were claimed before, so do it now.
+	    reiserfs_claim_blocks_to_be_allocated(inode->i_sb, 1 << (PAGE_CACHE_SHIFT - inode->i_blkbits));
+	}
+
+	/* Prepare for writing into the region, read in all the
+	   partially overwritten pages, if needed. And lock the pages,
+	   so that nobody else can access these until we are done.
+	   We get number of actual blocks needed as a result.*/
+	blocks_to_allocate = reiserfs_prepare_file_region_for_write(inode, pos, num_pages, write_bytes, prepared_pages);
+	if ( blocks_to_allocate < 0 ) {
+	    res = blocks_to_allocate;
+	    reiserfs_release_claimed_blocks(inode->i_sb, num_pages << (PAGE_CACHE_SHIFT - inode->i_blkbits));
+	    break;
+	}
+
+	/* First we correct our estimate of how many blocks we need */
+	reiserfs_release_claimed_blocks(inode->i_sb, (num_pages << (PAGE_CACHE_SHIFT - inode->i_sb->s_blocksize_bits)) - blocks_to_allocate );
+
+	if ( blocks_to_allocate > 0) {/*We only allocate blocks if we need to*/
+	    /* Fill in all the possible holes and append the file if needed */
+	    res = reiserfs_allocate_blocks_for_region(&th, inode, pos, num_pages, write_bytes, prepared_pages, blocks_to_allocate);
+	}
+
+	/* well, we have allocated the blocks, so it is time to free
+	   the reservation we made earlier. */
+	reiserfs_release_claimed_blocks(inode->i_sb, blocks_to_allocate);
+	if ( res ) {
+	    reiserfs_unprepare_pages(prepared_pages, num_pages);
+	    break;
+	}
+
+/* NOTE that allocating blocks and filling blocks can be done in reverse order
+   and probably we would do that just to get rid of garbage in files after a
+   crash */
+
+	/* Copy data from user-supplied buffer to file's pages */
+	res = reiserfs_copy_from_user_to_file_region(pos, num_pages, write_bytes, prepared_pages, buf);
+	if ( res ) {
+	    reiserfs_unprepare_pages(prepared_pages, num_pages);
+	    break;
+	}
+
+	/* Send the pages to disk and unlock them. */
+	res = reiserfs_submit_file_region_for_write(&th, inode, pos, num_pages,
+	                                            write_bytes,prepared_pages);
+	if ( res )
+	    break;
+
+	already_written += write_bytes;
+	buf += write_bytes;
+	*ppos = pos += write_bytes;
+	count -= write_bytes;
+	balance_dirty_pages_ratelimited(inode->i_mapping);
+    }
+
+    /* this is only true on error */
+    if (th.t_trans_id) {
+        reiserfs_write_lock(inode->i_sb);
+        err = journal_end(&th, th.t_super, th.t_blocks_allocated);
+        reiserfs_write_unlock(inode->i_sb);
+        if (err) {
+            res = err;
+            goto out;
+        }
+    }
+
+    if ((file->f_flags & O_SYNC) || IS_SYNC(inode))
+	res = generic_osync_inode(inode, file->f_mapping, OSYNC_METADATA|OSYNC_DATA);
+
+    up(&inode->i_sem);
+    reiserfs_async_progress_wait(inode->i_sb);
+    return (already_written != 0)?already_written:res;
+
+out:
+    up(&inode->i_sem); // unlock the file on exit.
+    return res;
+}
+
+static ssize_t reiserfs_aio_write(struct kiocb *iocb, const char __user *buf,
+			       size_t count, loff_t pos)
+{
+    return generic_file_aio_write(iocb, buf, count, pos);
+}
+
+
+
+struct file_operations reiserfs_file_operations = {
+    .read	= generic_file_read,
+    .write	= reiserfs_file_write,
+    .ioctl	= reiserfs_ioctl,
+    .mmap	= generic_file_mmap,
+    .release	= reiserfs_file_release,
+    .fsync	= reiserfs_sync_file,
+    .sendfile	= generic_file_sendfile,
+    .aio_read   = generic_file_aio_read,
+    .aio_write  = reiserfs_aio_write,
+};
+
+
+struct  inode_operations reiserfs_file_inode_operations = {
+    .truncate	= reiserfs_vfs_truncate_file,
+    .setattr    = reiserfs_setattr,
+    .setxattr   = reiserfs_setxattr,
+    .getxattr   = reiserfs_getxattr,
+    .listxattr  = reiserfs_listxattr,
+    .removexattr = reiserfs_removexattr,
+    .permission = reiserfs_permission,
+};
+
+
