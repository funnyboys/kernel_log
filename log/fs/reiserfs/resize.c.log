commit fad953ce0b22cfd352a9a90b070c34b8791e6868
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jun 12 14:27:37 2018 -0700

    treewide: Use array_size() in vzalloc()
    
    The vzalloc() function has no 2-factor argument form, so multiplication
    factors need to be wrapped in array_size(). This patch replaces cases of:
    
            vzalloc(a * b)
    
    with:
            vzalloc(array_size(a, b))
    
    as well as handling cases of:
    
            vzalloc(a * b * c)
    
    with:
    
            vzalloc(array3_size(a, b, c))
    
    This does, however, attempt to ignore constant size factors like:
    
            vzalloc(4 * 1024)
    
    though any constants defined via macros get caught up in the conversion.
    
    Any factors with a sizeof() of "unsigned char", "char", and "u8" were
    dropped, since they're redundant.
    
    The Coccinelle script used for this was:
    
    // Fix redundant parens around sizeof().
    @@
    type TYPE;
    expression THING, E;
    @@
    
    (
      vzalloc(
    -       (sizeof(TYPE)) * E
    +       sizeof(TYPE) * E
      , ...)
    |
      vzalloc(
    -       (sizeof(THING)) * E
    +       sizeof(THING) * E
      , ...)
    )
    
    // Drop single-byte sizes and redundant parens.
    @@
    expression COUNT;
    typedef u8;
    typedef __u8;
    @@
    
    (
      vzalloc(
    -       sizeof(u8) * (COUNT)
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(__u8) * (COUNT)
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(char) * (COUNT)
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(unsigned char) * (COUNT)
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(u8) * COUNT
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(__u8) * COUNT
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(char) * COUNT
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(unsigned char) * COUNT
    +       COUNT
      , ...)
    )
    
    // 2-factor product with sizeof(type/expression) and identifier or constant.
    @@
    type TYPE;
    expression THING;
    identifier COUNT_ID;
    constant COUNT_CONST;
    @@
    
    (
      vzalloc(
    -       sizeof(TYPE) * (COUNT_ID)
    +       array_size(COUNT_ID, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * COUNT_ID
    +       array_size(COUNT_ID, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * (COUNT_CONST)
    +       array_size(COUNT_CONST, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * COUNT_CONST
    +       array_size(COUNT_CONST, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * (COUNT_ID)
    +       array_size(COUNT_ID, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * COUNT_ID
    +       array_size(COUNT_ID, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * (COUNT_CONST)
    +       array_size(COUNT_CONST, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * COUNT_CONST
    +       array_size(COUNT_CONST, sizeof(THING))
      , ...)
    )
    
    // 2-factor product, only identifiers.
    @@
    identifier SIZE, COUNT;
    @@
    
      vzalloc(
    -       SIZE * COUNT
    +       array_size(COUNT, SIZE)
      , ...)
    
    // 3-factor product with 1 sizeof(type) or sizeof(expression), with
    // redundant parens removed.
    @@
    expression THING;
    identifier STRIDE, COUNT;
    type TYPE;
    @@
    
    (
      vzalloc(
    -       sizeof(TYPE) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    )
    
    // 3-factor product with 2 sizeof(variable), with redundant parens removed.
    @@
    expression THING1, THING2;
    identifier COUNT;
    type TYPE1, TYPE2;
    @@
    
    (
      vzalloc(
    -       sizeof(TYPE1) * sizeof(TYPE2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      vzalloc(
    -       sizeof(THING1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      vzalloc(
    -       sizeof(THING1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    )
    
    // 3-factor product, only identifiers, with redundant parens removed.
    @@
    identifier STRIDE, SIZE, COUNT;
    @@
    
    (
      vzalloc(
    -       (COUNT) * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       COUNT * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       COUNT * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       (COUNT) * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       COUNT * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       (COUNT) * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       (COUNT) * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       COUNT * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    )
    
    // Any remaining multi-factor products, first at least 3-factor products
    // when they're not all constants...
    @@
    expression E1, E2, E3;
    constant C1, C2, C3;
    @@
    
    (
      vzalloc(C1 * C2 * C3, ...)
    |
      vzalloc(
    -       E1 * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    )
    
    // And then all remaining 2 factors products when they're not all constants.
    @@
    expression E1, E2;
    constant C1, C2;
    @@
    
    (
      vzalloc(C1 * C2, ...)
    |
      vzalloc(
    -       E1 * E2
    +       array_size(E1, E2)
      , ...)
    )
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 6052d323bc9a..8096c74c38ac 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -120,7 +120,8 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 		 * array of bitmap block pointers
 		 */
 		bitmap =
-		    vzalloc(sizeof(struct reiserfs_bitmap_info) * bmap_nr_new);
+		    vzalloc(array_size(bmap_nr_new,
+				       sizeof(struct reiserfs_bitmap_info)));
 		if (!bitmap) {
 			/*
 			 * Journal bitmaps are still supersized, but the

commit 09f1b80ba8c967b6e17c0516e95578d5da18115f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:39 2014 -0400

    reiserfs: cleanup, remove sb argument from journal_mark_dirty
    
    journal_mark_dirty doesn't need a separate sb argument; It's provided
    by the transaction handle.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 99eb32596c6e..6052d323bc9a 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -193,7 +193,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 		reiserfs_clear_le_bit(i, bh->b_data);
 	info->free_count += s->s_blocksize * 8 - block_r;
 
-	journal_mark_dirty(&th, s, bh);
+	journal_mark_dirty(&th, bh);
 	brelse(bh);
 
 	/* Correct new last bitmap block - It may not be full */
@@ -209,7 +209,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	reiserfs_prepare_for_journal(s, bh, 1);
 	for (i = block_r_new; i < s->s_blocksize * 8; i++)
 		reiserfs_set_le_bit(i, bh->b_data);
-	journal_mark_dirty(&th, s, bh);
+	journal_mark_dirty(&th, bh);
 	brelse(bh);
 
 	info->free_count -= s->s_blocksize * 8 - block_r_new;
@@ -222,7 +222,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	PUT_SB_BLOCK_COUNT(s, block_count_new);
 	PUT_SB_BMAP_NR(s, bmap_would_wrap(bmap_nr_new) ? : bmap_nr_new);
 
-	journal_mark_dirty(&th, s, SB_BUFFER_WITH_SB(s));
+	journal_mark_dirty(&th, SB_BUFFER_WITH_SB(s));
 
 	SB_JOURNAL(s)->j_must_wait = 1;
 	return journal_end(&th);

commit 58d854265c4c7d9792ecb5aa5ef67ba79b1a4c12
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:38 2014 -0400

    reiserfs: cleanup, remove sb argument from journal_end
    
    journal_end doesn't need a separate sb argument; it's provided by the
    transaction handle.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 2e3f003027aa..99eb32596c6e 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -182,7 +182,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	info = SB_AP_BITMAP(s) + bmap_nr - 1;
 	bh = reiserfs_read_bitmap_block(s, bmap_nr - 1);
 	if (!bh) {
-		int jerr = journal_end(&th, s);
+		int jerr = journal_end(&th);
 		if (jerr)
 			return jerr;
 		return -EIO;
@@ -200,7 +200,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	info = SB_AP_BITMAP(s) + bmap_nr_new - 1;
 	bh = reiserfs_read_bitmap_block(s, bmap_nr_new - 1);
 	if (!bh) {
-		int jerr = journal_end(&th, s);
+		int jerr = journal_end(&th);
 		if (jerr)
 			return jerr;
 		return -EIO;
@@ -225,5 +225,5 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	journal_mark_dirty(&th, s, SB_BUFFER_WITH_SB(s));
 
 	SB_JOURNAL(s)->j_must_wait = 1;
-	return journal_end(&th, s);
+	return journal_end(&th);
 }

commit 706a5323384d9ae973a72005b73987d39e009019
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:37 2014 -0400

    reiserfs: cleanup, remove nblocks argument from journal_end
    
    journal_end takes a block count argument but doesn't actually use it
    for anything. We can remove it.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 037b00c40f1f..2e3f003027aa 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -182,7 +182,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	info = SB_AP_BITMAP(s) + bmap_nr - 1;
 	bh = reiserfs_read_bitmap_block(s, bmap_nr - 1);
 	if (!bh) {
-		int jerr = journal_end(&th, s, 10);
+		int jerr = journal_end(&th, s);
 		if (jerr)
 			return jerr;
 		return -EIO;
@@ -200,7 +200,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	info = SB_AP_BITMAP(s) + bmap_nr_new - 1;
 	bh = reiserfs_read_bitmap_block(s, bmap_nr_new - 1);
 	if (!bh) {
-		int jerr = journal_end(&th, s, 10);
+		int jerr = journal_end(&th, s);
 		if (jerr)
 			return jerr;
 		return -EIO;
@@ -225,5 +225,5 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	journal_mark_dirty(&th, s, SB_BUFFER_WITH_SB(s));
 
 	SB_JOURNAL(s)->j_must_wait = 1;
-	return journal_end(&th, s, 10);
+	return journal_end(&th, s);
 }

commit 098297b27d23ad9d0fc302e3417474d9342c6c14
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:36 2014 -0400

    reiserfs: cleanup, reformat comments to normal kernel style
    
    This patch reformats comments in the reiserfs code to fit in 80 columns and
    to follow the style rules.
    
    There is no functional change but it helps make my eyes bleed less.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index a4ef5cd606eb..037b00c40f1f 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -53,8 +53,10 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	}
 	bforget(bh);
 
-	/* old disk layout detection; those partitions can be mounted, but
-	 * cannot be resized */
+	/*
+	 * old disk layout detection; those partitions can be mounted, but
+	 * cannot be resized
+	 */
 	if (SB_BUFFER_WITH_SB(s)->b_blocknr * SB_BUFFER_WITH_SB(s)->b_size
 	    != REISERFS_DISK_OFFSET_IN_BYTES) {
 		printk
@@ -86,12 +88,14 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			    ("reiserfs_resize: unable to allocate memory for journal bitmaps\n");
 			return -ENOMEM;
 		}
-		/* the new journal bitmaps are zero filled, now we copy in the bitmap
-		 ** node pointers from the old journal bitmap structs, and then
-		 ** transfer the new data structures into the journal struct.
-		 **
-		 ** using the copy_size var below allows this code to work for
-		 ** both shrinking and expanding the FS.
+		/*
+		 * the new journal bitmaps are zero filled, now we copy i
+		 * the bitmap node pointers from the old journal bitmap
+		 * structs, and then transfer the new data structures
+		 * into the journal struct.
+		 *
+		 * using the copy_size var below allows this code to work for
+		 * both shrinking and expanding the FS.
 		 */
 		copy_size = bmap_nr_new < bmap_nr ? bmap_nr_new : bmap_nr;
 		copy_size =
@@ -101,36 +105,45 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			jb = SB_JOURNAL(s)->j_list_bitmap + i;
 			memcpy(jbitmap[i].bitmaps, jb->bitmaps, copy_size);
 
-			/* just in case vfree schedules on us, copy the new
-			 ** pointer into the journal struct before freeing the
-			 ** old one
+			/*
+			 * just in case vfree schedules on us, copy the new
+			 * pointer into the journal struct before freeing the
+			 * old one
 			 */
 			node_tmp = jb->bitmaps;
 			jb->bitmaps = jbitmap[i].bitmaps;
 			vfree(node_tmp);
 		}
 
-		/* allocate additional bitmap blocks, reallocate array of bitmap
-		 * block pointers */
+		/*
+		 * allocate additional bitmap blocks, reallocate
+		 * array of bitmap block pointers
+		 */
 		bitmap =
 		    vzalloc(sizeof(struct reiserfs_bitmap_info) * bmap_nr_new);
 		if (!bitmap) {
-			/* Journal bitmaps are still supersized, but the memory isn't
-			 * leaked, so I guess it's ok */
+			/*
+			 * Journal bitmaps are still supersized, but the
+			 * memory isn't leaked, so I guess it's ok
+			 */
 			printk("reiserfs_resize: unable to allocate memory.\n");
 			return -ENOMEM;
 		}
 		for (i = 0; i < bmap_nr; i++)
 			bitmap[i] = old_bitmap[i];
 
-		/* This doesn't go through the journal, but it doesn't have to.
-		 * The changes are still atomic: We're synced up when the journal
-		 * transaction begins, and the new bitmaps don't matter if the
-		 * transaction fails. */
+		/*
+		 * This doesn't go through the journal, but it doesn't have to.
+		 * The changes are still atomic: We're synced up when the
+		 * journal transaction begins, and the new bitmaps don't
+		 * matter if the transaction fails.
+		 */
 		for (i = bmap_nr; i < bmap_nr_new; i++) {
 			int depth;
-			/* don't use read_bitmap_block since it will cache
-			 * the uninitialized bitmap */
+			/*
+			 * don't use read_bitmap_block since it will cache
+			 * the uninitialized bitmap
+			 */
 			depth = reiserfs_write_unlock_nested(s);
 			bh = sb_bread(s, i * s->s_blocksize * 8);
 			reiserfs_write_lock_nested(s, depth);
@@ -147,7 +160,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			depth = reiserfs_write_unlock_nested(s);
 			sync_dirty_buffer(bh);
 			reiserfs_write_lock_nested(s, depth);
-			// update bitmap_info stuff
+			/* update bitmap_info stuff */
 			bitmap[i].free_count = sb_blocksize(sb) * 8 - 1;
 			brelse(bh);
 		}
@@ -156,9 +169,11 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 		vfree(old_bitmap);
 	}
 
-	/* begin transaction, if there was an error, it's fine. Yes, we have
+	/*
+	 * begin transaction, if there was an error, it's fine. Yes, we have
 	 * incorrect bitmaps now, but none of it is ever going to touch the
-	 * disk anyway. */
+	 * disk anyway.
+	 */
 	err = journal_begin(&th, s, 10);
 	if (err)
 		return err;

commit 278f6679f454bf185a07d9a4ca355b153482d17a
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Aug 8 17:34:46 2013 -0400

    reiserfs: locking, handle nested locks properly
    
    The reiserfs write lock replaced the BKL and uses similar semantics.
    
    Frederic's locking code makes a distinction between when the lock is nested
    and when it's being acquired/released, but I don't think that's the right
    distinction to make.
    
    The right distinction is between the lock being released at end-of-use and
    the lock being released for a schedule. The unlock should return the depth
    and the lock should restore it, rather than the other way around as it is now.
    
    This patch implements that and adds a number of places where the lock
    should be dropped.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 3ce02cff5e90..a4ef5cd606eb 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -34,6 +34,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	unsigned long int block_count, free_blocks;
 	int i;
 	int copy_size;
+	int depth;
 
 	sb = SB_DISK_SUPER_BLOCK(s);
 
@@ -43,7 +44,9 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	}
 
 	/* check the device size */
+	depth = reiserfs_write_unlock_nested(s);
 	bh = sb_bread(s, block_count_new - 1);
+	reiserfs_write_lock_nested(s, depth);
 	if (!bh) {
 		printk("reiserfs_resize: can\'t read last block\n");
 		return -EINVAL;
@@ -125,9 +128,12 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 		 * transaction begins, and the new bitmaps don't matter if the
 		 * transaction fails. */
 		for (i = bmap_nr; i < bmap_nr_new; i++) {
+			int depth;
 			/* don't use read_bitmap_block since it will cache
 			 * the uninitialized bitmap */
+			depth = reiserfs_write_unlock_nested(s);
 			bh = sb_bread(s, i * s->s_blocksize * 8);
+			reiserfs_write_lock_nested(s, depth);
 			if (!bh) {
 				vfree(bitmap);
 				return -EIO;
@@ -138,9 +144,9 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 
 			set_buffer_uptodate(bh);
 			mark_buffer_dirty(bh);
-			reiserfs_write_unlock(s);
+			depth = reiserfs_write_unlock_nested(s);
 			sync_dirty_buffer(bh);
-			reiserfs_write_lock(s);
+			reiserfs_write_lock_nested(s, depth);
 			// update bitmap_info stuff
 			bitmap[i].free_count = sb_blocksize(sb) * 8 - 1;
 			brelse(bh);

commit 717f03c4d71677d2afb68d54628def3aae5d46ab
Author: Artem Bityutskiy <artem.bityutskiy@linux.intel.com>
Date:   Fri Jun 1 17:18:06 2012 +0300

    reiserfs: remove useless superblock dirtying
    
    The 'reiserfs_resize()' function marks the superblock as dirty by assigning 1
    to 's_dirt' and then calls 'journal_mark_dirty()' which does the same. Thus,
    we can remove the assignment from 'reiserfs_resize()'.
    
    Signed-off-by: Artem Bityutskiy <artem.bityutskiy@linux.intel.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 9a17f63c3fd7..3ce02cff5e90 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -200,7 +200,6 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 					  (bmap_nr_new - bmap_nr)));
 	PUT_SB_BLOCK_COUNT(s, block_count_new);
 	PUT_SB_BMAP_NR(s, bmap_would_wrap(bmap_nr_new) ? : bmap_nr_new);
-	s->s_dirt = 1;
 
 	journal_mark_dirty(&th, s, SB_BUFFER_WITH_SB(s));
 

commit f466c6fdb3b1f043ff1977a8d2a1d0cd4dc164fa
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 17 01:16:43 2012 -0400

    move private bits of reiserfs_fs.h to fs/reiserfs/reiserfs.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index e1415ad93251..9a17f63c3fd7 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -13,7 +13,7 @@
 #include <linux/vmalloc.h>
 #include <linux/string.h>
 #include <linux/errno.h>
-#include <linux/reiserfs_fs.h>
+#include "reiserfs.h"
 #include <linux/buffer_head.h>
 
 int reiserfs_resize(struct super_block *s, unsigned long block_count_new)

commit a8a4b79b53fc7cbb023afedf58b04dd4e9bbb114
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 17 01:06:11 2012 -0400

    kill pointless includes of reiserfs_fs_{i,sb}.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 7483279b482d..e1415ad93251 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -14,7 +14,6 @@
 #include <linux/string.h>
 #include <linux/errno.h>
 #include <linux/reiserfs_fs.h>
-#include <linux/reiserfs_fs_sb.h>
 #include <linux/buffer_head.h>
 
 int reiserfs_resize(struct super_block *s, unsigned long block_count_new)

commit 558feb0818374d657fbc1ea03776ee20f204b3a6
Author: Joe Perches <joe@perches.com>
Date:   Sat May 28 10:36:33 2011 -0700

    fs: Convert vmalloc/memset to vzalloc
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Acked-by: Alex Elder <aelder@sgi.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index b6b9b1fe33b0..7483279b482d 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -111,15 +111,13 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 		/* allocate additional bitmap blocks, reallocate array of bitmap
 		 * block pointers */
 		bitmap =
-		    vmalloc(sizeof(struct reiserfs_bitmap_info) * bmap_nr_new);
+		    vzalloc(sizeof(struct reiserfs_bitmap_info) * bmap_nr_new);
 		if (!bitmap) {
 			/* Journal bitmaps are still supersized, but the memory isn't
 			 * leaked, so I guess it's ok */
 			printk("reiserfs_resize: unable to allocate memory.\n");
 			return -ENOMEM;
 		}
-		memset(bitmap, 0,
-		       sizeof(struct reiserfs_bitmap_info) * bmap_nr_new);
 		for (i = 0; i < bmap_nr; i++)
 			bitmap[i] = old_bitmap[i];
 

commit 0c2fd1bfb155947a821fdaeb3c46aa1cfa20ad64
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Mon Jul 25 17:13:37 2011 -0700

    reiserfs: use proper little-endian bitops
    
    Using __test_and_{set,clear}_bit_le() with ignoring its return value can
    be replaced with __{set,clear}_bit_le().
    
    This introduces reiserfs_{set,clear}_le_bit for __{set,clear}_bit_le and
    does the above change with them.
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index b3a94d20f0fc..b6b9b1fe33b0 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -136,7 +136,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 				return -EIO;
 			}
 			memset(bh->b_data, 0, sb_blocksize(sb));
-			reiserfs_test_and_set_le_bit(0, bh->b_data);
+			reiserfs_set_le_bit(0, bh->b_data);
 			reiserfs_cache_bitmap_metadata(s, bh, bitmap + i);
 
 			set_buffer_uptodate(bh);
@@ -172,7 +172,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 
 	reiserfs_prepare_for_journal(s, bh, 1);
 	for (i = block_r; i < s->s_blocksize * 8; i++)
-		reiserfs_test_and_clear_le_bit(i, bh->b_data);
+		reiserfs_clear_le_bit(i, bh->b_data);
 	info->free_count += s->s_blocksize * 8 - block_r;
 
 	journal_mark_dirty(&th, s, bh);
@@ -190,7 +190,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 
 	reiserfs_prepare_for_journal(s, bh, 1);
 	for (i = block_r_new; i < s->s_blocksize * 8; i++)
-		reiserfs_test_and_set_le_bit(i, bh->b_data);
+		reiserfs_set_le_bit(i, bh->b_data);
 	journal_mark_dirty(&th, s, bh);
 	brelse(bh);
 

commit 8ebc423238341b52912c7295b045a32477b33f09
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Apr 7 04:19:49 2009 +0200

    reiserfs: kill-the-BKL
    
    This patch is an attempt to remove the Bkl based locking scheme from
    reiserfs and is intended.
    
    It is a bit inspired from an old attempt by Peter Zijlstra:
    
       http://lkml.indiana.edu/hypermail/linux/kernel/0704.2/2174.html
    
    The bkl is heavily used in this filesystem to prevent from
    concurrent write accesses on the filesystem.
    
    Reiserfs makes a deep use of the specific properties of the Bkl:
    
    - It can be acqquired recursively by a same task
    - It is released on the schedule() calls and reacquired when schedule() returns
    
    The two properties above are a roadmap for the reiserfs write locking so it's
    very hard to simply replace it with a common mutex.
    
    - We need a recursive-able locking unless we want to restructure several blocks
      of the code.
    - We need to identify the sites where the bkl was implictly relaxed
      (schedule, wait, sync, etc...) so that we can in turn release and
      reacquire our new lock explicitly.
      Such implicit releases of the lock are often required to let other
      resources producer/consumer do their job or we can suffer unexpected
      starvations or deadlocks.
    
    So the new lock that replaces the bkl here is a per superblock mutex with a
    specific property: it can be acquired recursively by a same task, like the
    bkl.
    
    For such purpose, we integrate a lock owner and a lock depth field on the
    superblock information structure.
    
    The first axis on this patch is to turn reiserfs_write_(un)lock() function
    into a wrapper to manage this mutex. Also some explicit calls to
    lock_kernel() have been converted to reiserfs_write_lock() helpers.
    
    The second axis is to find the important blocking sites (schedule...(),
    wait_on_buffer(), sync_dirty_buffer(), etc...) and then apply an explicit
    release of the write lock on these locations before blocking. Then we can
    safely wait for those who can give us resources or those who need some.
    Typically this is a fight between the current writer, the reiserfs workqueue
    (aka the async commiter) and the pdflush threads.
    
    The third axis is a consequence of the second. The write lock is usually
    on top of a lock dependency chain which can include the journal lock, the
    flush lock or the commit lock. So it's dangerous to release and trying to
    reacquire the write lock while we still hold other locks.
    
    This is fine with the bkl:
    
          T1                       T2
    
    lock_kernel()
        mutex_lock(A)
        unlock_kernel()
        // do something
                                lock_kernel()
                                    mutex_lock(A) -> already locked by T1
                                    schedule() (and then unlock_kernel())
        lock_kernel()
        mutex_unlock(A)
        ....
    
    This is not fine with a mutex:
    
          T1                       T2
    
    mutex_lock(write)
        mutex_lock(A)
        mutex_unlock(write)
        // do something
                               mutex_lock(write)
                                  mutex_lock(A) -> already locked by T1
                                  schedule()
    
        mutex_lock(write) -> already locked by T2
        deadlock
    
    The solution in this patch is to provide a helper which releases the write
    lock and sleep a bit if we can't lock a mutex that depend on it. It's another
    simulation of the bkl behaviour.
    
    The last axis is to locate the fs callbacks that are called with the bkl held,
    according to Documentation/filesystem/Locking.
    
    Those are:
    
    - reiserfs_remount
    - reiserfs_fill_super
    - reiserfs_put_super
    
    Reiserfs didn't need to explicitly lock because of the context of these callbacks.
    But now we must take care of that with the new locking.
    
    After this patch, reiserfs suffers from a slight performance regression (for now).
    On UP, a high volume write with dd reports an average of 27 MB/s instead
    of 30 MB/s without the patch applied.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Bron Gondwana <brong@fastmail.fm>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    LKML-Reference: <1239070789-13354-1-git-send-email-fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 18b315d3d104..b3a94d20f0fc 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -141,7 +141,9 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 
 			set_buffer_uptodate(bh);
 			mark_buffer_dirty(bh);
+			reiserfs_write_unlock(s);
 			sync_dirty_buffer(bh);
+			reiserfs_write_lock(s);
 			// update bitmap_info stuff
 			bitmap[i].free_count = sb_blocksize(sb) * 8 - 1;
 			brelse(bh);

commit b5450d9c84bdd38b261922057cd167da51dfae93
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 19 10:30:07 2009 +0200

    reiserfs: remove stray unlock_super in reiserfs_resize
    
    Reiserfs doesn't use lock_super anywhere internally, and ->remount_fs
    which calls reiserfs_resize does have it currently but also expects it
    to be held on return, so there's no business for the unlock_super here.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked by Edward Shishkin <edward.shishkin@gmail.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 238e9d9b31e0..18b315d3d104 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -82,7 +82,6 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 		if (reiserfs_allocate_list_bitmaps(s, jbitmap, bmap_nr_new) < 0) {
 			printk
 			    ("reiserfs_resize: unable to allocate memory for journal bitmaps\n");
-			unlock_super(s);
 			return -ENOMEM;
 		}
 		/* the new journal bitmaps are zero filled, now we copy in the bitmap

commit 0222e6571c332563a48d4cf5487b67feabe60b5e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:44 2009 -0400

    reiserfs: strip trailing whitespace
    
    This patch strips trailing whitespace from the reiserfs code.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index f71c3948edef..238e9d9b31e0 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -1,8 +1,8 @@
-/* 
+/*
  * Copyright 2000 by Hans Reiser, licensing governed by reiserfs/README
  */
 
-/* 
+/*
  * Written by Alexander Zarochentcev.
  *
  * The kernel part of the (on-line) reiserfs resizer.
@@ -101,7 +101,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			memcpy(jbitmap[i].bitmaps, jb->bitmaps, copy_size);
 
 			/* just in case vfree schedules on us, copy the new
-			 ** pointer into the journal struct before freeing the 
+			 ** pointer into the journal struct before freeing the
 			 ** old one
 			 */
 			node_tmp = jb->bitmaps;

commit cb680c1be62e9898fc2ca2a89d9fdba7c84a5c81
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Oct 18 23:39:27 2007 -0700

    reiserfs: ignore on disk s_bmap_nr value
    
    Implement support for file systems larger than 8 TiB.
    
    The reiserfs superblock contains a 16 bit value for counting the number of
    bitmap blocks.  The rest of the disk format supports file systems up to 2^32
    blocks, but the bitmap block limitation artificially limits this to 8 TiB with
    a 4KiB block size.
    
    Rather than trust the superblock's 16-bit bitmap block count, we calculate it
    dynamically based on the number of blocks in the file system.  When an
    incorrect value is observed in the superblock, it is zeroed out, ensuring that
    older kernels will not be able to mount the file system.
    
    Userspace support has already been implemented and shipped in reiserfsprogs
    3.6.20.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 66f1cda83a81..f71c3948edef 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -61,7 +61,8 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	}
 
 	/* count used bits in last bitmap block */
-	block_r = SB_BLOCK_COUNT(s) - (SB_BMAP_NR(s) - 1) * s->s_blocksize * 8;
+	block_r = SB_BLOCK_COUNT(s) -
+			(reiserfs_bmap_count(s) - 1) * s->s_blocksize * 8;
 
 	/* count bitmap blocks in new fs */
 	bmap_nr_new = block_count_new / (s->s_blocksize * 8);
@@ -73,7 +74,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 
 	/* save old values */
 	block_count = SB_BLOCK_COUNT(s);
-	bmap_nr = SB_BMAP_NR(s);
+	bmap_nr = reiserfs_bmap_count(s);
 
 	/* resizing of reiserfs bitmaps (journal and real), if needed */
 	if (bmap_nr_new > bmap_nr) {
@@ -200,7 +201,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			   free_blocks + (block_count_new - block_count -
 					  (bmap_nr_new - bmap_nr)));
 	PUT_SB_BLOCK_COUNT(s, block_count_new);
-	PUT_SB_BMAP_NR(s, bmap_nr_new);
+	PUT_SB_BMAP_NR(s, bmap_would_wrap(bmap_nr_new) ? : bmap_nr_new);
 	s->s_dirt = 1;
 
 	journal_mark_dirty(&th, s, SB_BUFFER_WITH_SB(s));

commit 4d20851d3757ba5bece263a4c8c5a2bd4983cb5d
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Oct 18 23:39:26 2007 -0700

    reiserfs: remove first_zero_hint
    
    The first_zero_hint metadata caching was never actually used, and it's of
    dubious optimization quality.  This patch removes it.
    
    It doesn't actually shrink the size of the reiserfs_bitmap_info struct, since
    that doesn't work with block sizes larger than 8K.  There was a big fixme in
    there, and with all the work lately in allowing block size > page size, I
    might as well kill the fixme as well.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 3bec2f96242a..66f1cda83a81 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -143,7 +143,6 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			mark_buffer_dirty(bh);
 			sync_dirty_buffer(bh);
 			// update bitmap_info stuff
-			bitmap[i].first_zero_hint = 1;
 			bitmap[i].free_count = sb_blocksize(sb) * 8 - 1;
 			brelse(bh);
 		}
@@ -173,8 +172,6 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	for (i = block_r; i < s->s_blocksize * 8; i++)
 		reiserfs_test_and_clear_le_bit(i, bh->b_data);
 	info->free_count += s->s_blocksize * 8 - block_r;
-	if (!info->first_zero_hint)
-		info->first_zero_hint = block_r;
 
 	journal_mark_dirty(&th, s, bh);
 	brelse(bh);
@@ -196,9 +193,6 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	brelse(bh);
 
 	info->free_count -= s->s_blocksize * 8 - block_r_new;
-	/* Extreme case where last bitmap is the only valid block in itself. */
-	if (!info->free_count)
-		info->first_zero_hint = 0;
 	/* update super */
 	reiserfs_prepare_for_journal(s, SB_BUFFER_WITH_SB(s), 1);
 	free_blocks = SB_FREE_BLOCKS(s);

commit 6c57c2c8d3862c8d5b908669654f6565da74ec19
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Oct 18 23:39:25 2007 -0700

    reiserfs: fix memset byte count during resize
    
    Correct the memset in reiserfs_resize to clear the memory allocated for the
    new bitmap info structs.  Previously, it would clear the memory used by the
    old size.  Depending on the contents of memory, this could cause incorrect
    caching behavior for bitmap blocks in the newly allocated area.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 976cc7887a0d..3bec2f96242a 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -119,7 +119,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			return -ENOMEM;
 		}
 		memset(bitmap, 0,
-		       sizeof(struct reiserfs_bitmap_info) * SB_BMAP_NR(s));
+		       sizeof(struct reiserfs_bitmap_info) * bmap_nr_new);
 		for (i = 0; i < bmap_nr; i++)
 			bitmap[i] = old_bitmap[i];
 

commit 2d3466a348a61c4d7f958ce80020eba17c09d7f7
Author: Dmitriy Monakhov <dmonakhov@sw.ru>
Date:   Tue May 8 00:24:37 2007 -0700

    reiserfs: possible null pointer dereference during resize
    
    sb_read may return NULL, let's explicitly check it.  If so free new bitmap
    blocks array, after this we may safely exit as it done above during bitmap
    allocation.
    
    Signed-off-by: Dmitriy Monakhov <dmonakhov@openvz.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 315684793d1d..976cc7887a0d 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -131,6 +131,10 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			/* don't use read_bitmap_block since it will cache
 			 * the uninitialized bitmap */
 			bh = sb_bread(s, i * s->s_blocksize * 8);
+			if (!bh) {
+				vfree(bitmap);
+				return -EIO;
+			}
 			memset(bh->b_data, 0, sb_blocksize(sb));
 			reiserfs_test_and_set_le_bit(0, bh->b_data);
 			reiserfs_cache_bitmap_metadata(s, bh, bitmap + i);

commit 5065227b46235ec0131b383cc2f537069b55c6b6
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Sat Sep 30 23:28:44 2006 -0700

    [PATCH] reiserfs: on-demand bitmap loading
    
    This is the patch the three previous ones have been leading up to.
    
    It changes the behavior of ReiserFS from loading and caching all the bitmaps
    as special, to treating the bitmaps like any other bit of metadata and just
    letting the system-wide caches figure out what to hang on to.
    
    Buffer heads are allocated on the fly, so there is no need to retain pointers
    to all of them.  The caching of the metadata occurs when the data is read and
    updated, and is considered invalid and uncached until then.
    
    I needed to remove the vs-4040 check for performing a duplicate operation on a
    particular bit.  The reason is that while the other sites for working with
    bitmaps are allowed to schedule, is_reusable() is called from do_balance(),
    which will panic if a schedule occurs in certain places.
    
    The benefit of on-demand bitmaps clearly outweighs a sanity check that depends
    on a compile-time option that is discouraged.
    
    [akpm@osdl.org: warning fix]
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Cc: <reiserfs-dev@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 90d39fd3096f..315684793d1d 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -128,8 +128,9 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 		 * transaction begins, and the new bitmaps don't matter if the
 		 * transaction fails. */
 		for (i = bmap_nr; i < bmap_nr_new; i++) {
-			bh = sb_getblk(s, i * s->s_blocksize * 8);
-			get_bh(bh);
+			/* don't use read_bitmap_block since it will cache
+			 * the uninitialized bitmap */
+			bh = sb_bread(s, i * s->s_blocksize * 8);
 			memset(bh->b_data, 0, sb_blocksize(sb));
 			reiserfs_test_and_set_le_bit(0, bh->b_data);
 			reiserfs_cache_bitmap_metadata(s, bh, bitmap + i);
@@ -140,7 +141,6 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			// update bitmap_info stuff
 			bitmap[i].first_zero_hint = 1;
 			bitmap[i].free_count = sb_blocksize(sb) * 8 - 1;
-			bitmap[i].bh = bh;
 			brelse(bh);
 		}
 		/* free old bitmap blocks array */
@@ -157,8 +157,13 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 
 	/* Extend old last bitmap block - new blocks have been made available */
 	info = SB_AP_BITMAP(s) + bmap_nr - 1;
-	bh = info->bh;
-	get_bh(bh);
+	bh = reiserfs_read_bitmap_block(s, bmap_nr - 1);
+	if (!bh) {
+		int jerr = journal_end(&th, s, 10);
+		if (jerr)
+			return jerr;
+		return -EIO;
+	}
 
 	reiserfs_prepare_for_journal(s, bh, 1);
 	for (i = block_r; i < s->s_blocksize * 8; i++)
@@ -172,8 +177,13 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 
 	/* Correct new last bitmap block - It may not be full */
 	info = SB_AP_BITMAP(s) + bmap_nr_new - 1;
-	bh = info->bh;
-	get_bh(bh);
+	bh = reiserfs_read_bitmap_block(s, bmap_nr_new - 1);
+	if (!bh) {
+		int jerr = journal_end(&th, s, 10);
+		if (jerr)
+			return jerr;
+		return -EIO;
+	}
 
 	reiserfs_prepare_for_journal(s, bh, 1);
 	for (i = block_r_new; i < s->s_blocksize * 8; i++)

commit 6f01046b35d940079822827498a7dd6d3eec8c6b
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Sat Sep 30 23:28:43 2006 -0700

    [PATCH] reiserfs: reorganize bitmap loading functions
    
    This patch moves the bitmap loading code from super.c to bitmap.c
    
    The code is also restructured somewhat.  The only difference between new
    format bitmaps and old format bitmaps is where they are.  That's a two liner
    before loading the block to use the correct one.  There's no need for an
    entirely separate code path.
    
    The load path is generally the same, with the pattern being to throw out a
    bunch of requests and then wait for them, then cache the metadata from the
    contents.
    
    Again, like the previous patches, the purpose is to set up for later ones.
    
    Update: There was a bug in the previously posted version of this that resulted
    in corruption.  The problem was that bitmap 0 on new format file systems must
    be treated specially, and wasn't.  A stupid bug with an easy fix.
    
    This is hopefully the last fix for the disaster that is the reiserfs bitmap
    patch set.
    
    If a bitmap block was full, first_zero_hint would end up at zero since it
    would never be changed from it's zeroed out value.  This just sets it
    beyond the end of the bitmap block.  If any bits are freed, it will be
    reset to a valid bit.  When info->free_count = 0, then we already know it's
    full.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Cc: <reiserfs-dev@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 958b75978994..90d39fd3096f 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -132,6 +132,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 			get_bh(bh);
 			memset(bh->b_data, 0, sb_blocksize(sb));
 			reiserfs_test_and_set_le_bit(0, bh->b_data);
+			reiserfs_cache_bitmap_metadata(s, bh, bitmap + i);
 
 			set_buffer_uptodate(bh);
 			mark_buffer_dirty(bh);

commit 0b3dc17bc0c0997bde9f5d7691ec0cae24258cf7
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Sat Sep 30 23:28:42 2006 -0700

    [PATCH] reiserfs: clean up bitmap block buffer head references
    
    Similar to the SB_JOURNAL cleanup that was accepted a while ago, this patch
    uses a temporary variable for buffer head references from the bitmap info
    array.
    
    This makes the code much more readable in some areas.
    
    It also uses proper reference counting, doing a get_bh() after using the
    pointer from the array and brelse()'ing it later.  This may seem silly, but a
    later patch will replace the simple temporary variables with an actual read,
    so the reference freeing will be used then.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Cc: <reiserfs-dev@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 39cc7f47f5dc..958b75978994 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -22,6 +22,7 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	int err = 0;
 	struct reiserfs_super_block *sb;
 	struct reiserfs_bitmap_info *bitmap;
+	struct reiserfs_bitmap_info *info;
 	struct reiserfs_bitmap_info *old_bitmap = SB_AP_BITMAP(s);
 	struct buffer_head *bh;
 	struct reiserfs_transaction_handle th;
@@ -127,16 +128,19 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 		 * transaction begins, and the new bitmaps don't matter if the
 		 * transaction fails. */
 		for (i = bmap_nr; i < bmap_nr_new; i++) {
-			bitmap[i].bh = sb_getblk(s, i * s->s_blocksize * 8);
-			memset(bitmap[i].bh->b_data, 0, sb_blocksize(sb));
-			reiserfs_test_and_set_le_bit(0, bitmap[i].bh->b_data);
-
-			set_buffer_uptodate(bitmap[i].bh);
-			mark_buffer_dirty(bitmap[i].bh);
-			sync_dirty_buffer(bitmap[i].bh);
+			bh = sb_getblk(s, i * s->s_blocksize * 8);
+			get_bh(bh);
+			memset(bh->b_data, 0, sb_blocksize(sb));
+			reiserfs_test_and_set_le_bit(0, bh->b_data);
+
+			set_buffer_uptodate(bh);
+			mark_buffer_dirty(bh);
+			sync_dirty_buffer(bh);
 			// update bitmap_info stuff
 			bitmap[i].first_zero_hint = 1;
 			bitmap[i].free_count = sb_blocksize(sb) * 8 - 1;
+			bitmap[i].bh = bh;
+			brelse(bh);
 		}
 		/* free old bitmap blocks array */
 		SB_AP_BITMAP(s) = bitmap;
@@ -150,30 +154,36 @@ int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 	if (err)
 		return err;
 
-	/* correct last bitmap blocks in old and new disk layout */
-	reiserfs_prepare_for_journal(s, SB_AP_BITMAP(s)[bmap_nr - 1].bh, 1);
+	/* Extend old last bitmap block - new blocks have been made available */
+	info = SB_AP_BITMAP(s) + bmap_nr - 1;
+	bh = info->bh;
+	get_bh(bh);
+
+	reiserfs_prepare_for_journal(s, bh, 1);
 	for (i = block_r; i < s->s_blocksize * 8; i++)
-		reiserfs_test_and_clear_le_bit(i,
-					       SB_AP_BITMAP(s)[bmap_nr -
-							       1].bh->b_data);
-	SB_AP_BITMAP(s)[bmap_nr - 1].free_count += s->s_blocksize * 8 - block_r;
-	if (!SB_AP_BITMAP(s)[bmap_nr - 1].first_zero_hint)
-		SB_AP_BITMAP(s)[bmap_nr - 1].first_zero_hint = block_r;
+		reiserfs_test_and_clear_le_bit(i, bh->b_data);
+	info->free_count += s->s_blocksize * 8 - block_r;
+	if (!info->first_zero_hint)
+		info->first_zero_hint = block_r;
+
+	journal_mark_dirty(&th, s, bh);
+	brelse(bh);
 
-	journal_mark_dirty(&th, s, SB_AP_BITMAP(s)[bmap_nr - 1].bh);
+	/* Correct new last bitmap block - It may not be full */
+	info = SB_AP_BITMAP(s) + bmap_nr_new - 1;
+	bh = info->bh;
+	get_bh(bh);
 
-	reiserfs_prepare_for_journal(s, SB_AP_BITMAP(s)[bmap_nr_new - 1].bh, 1);
+	reiserfs_prepare_for_journal(s, bh, 1);
 	for (i = block_r_new; i < s->s_blocksize * 8; i++)
-		reiserfs_test_and_set_le_bit(i,
-					     SB_AP_BITMAP(s)[bmap_nr_new -
-							     1].bh->b_data);
-	journal_mark_dirty(&th, s, SB_AP_BITMAP(s)[bmap_nr_new - 1].bh);
+		reiserfs_test_and_set_le_bit(i, bh->b_data);
+	journal_mark_dirty(&th, s, bh);
+	brelse(bh);
 
-	SB_AP_BITMAP(s)[bmap_nr_new - 1].free_count -=
-	    s->s_blocksize * 8 - block_r_new;
+	info->free_count -= s->s_blocksize * 8 - block_r_new;
 	/* Extreme case where last bitmap is the only valid block in itself. */
-	if (!SB_AP_BITMAP(s)[bmap_nr_new - 1].free_count)
-		SB_AP_BITMAP(s)[bmap_nr_new - 1].first_zero_hint = 0;
+	if (!info->free_count)
+		info->first_zero_hint = 0;
 	/* update super */
 	reiserfs_prepare_for_journal(s, SB_BUFFER_WITH_SB(s), 1);
 	free_blocks = SB_FREE_BLOCKS(s);

commit bd4c625c061c2a38568d0add3478f59172455159
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Tue Jul 12 20:21:28 2005 -0700

    reiserfs: run scripts/Lindent on reiserfs code
    
    This was a pure indentation change, using:
    
            scripts/Lindent fs/reiserfs/*.c include/linux/reiserfs_*.h
    
    to make reiserfs match the regular Linux indentation style.  As Jeff
    Mahoney <jeffm@suse.com> writes:
    
     The ReiserFS code is a mix of a number of different coding styles, sometimes
     different even from line-to-line. Since the code has been relatively stable
     for quite some time and there are few outstanding patches to be applied, it
     is time to reformat the code to conform to the Linux style standard outlined
     in Documentation/CodingStyle.
    
     This patch contains the result of running scripts/Lindent against
     fs/reiserfs/*.c and include/linux/reiserfs_*.h. There are places where the
     code can be made to look better, but I'd rather keep those patches separate
     so that there isn't a subtle by-hand hand accident in the middle of a huge
     patch. To be clear: This patch is reformatting *only*.
    
     A number of patches may follow that continue to make the code more consistent
     with the Linux coding style.
    
     Hans wasn't particularly enthusiastic about these patches, but said he
     wouldn't really oppose them either.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
index 170012078b76..39cc7f47f5dc 100644
--- a/fs/reiserfs/resize.c
+++ b/fs/reiserfs/resize.c
@@ -1,7 +1,7 @@
 /* 
  * Copyright 2000 by Hans Reiser, licensing governed by reiserfs/README
  */
- 
+
 /* 
  * Written by Alexander Zarochentcev.
  *
@@ -17,23 +17,23 @@
 #include <linux/reiserfs_fs_sb.h>
 #include <linux/buffer_head.h>
 
-int reiserfs_resize (struct super_block * s, unsigned long block_count_new)
+int reiserfs_resize(struct super_block *s, unsigned long block_count_new)
 {
-        int err = 0;
-	struct reiserfs_super_block * sb;
-        struct reiserfs_bitmap_info *bitmap;
+	int err = 0;
+	struct reiserfs_super_block *sb;
+	struct reiserfs_bitmap_info *bitmap;
 	struct reiserfs_bitmap_info *old_bitmap = SB_AP_BITMAP(s);
-	struct buffer_head * bh;
+	struct buffer_head *bh;
 	struct reiserfs_transaction_handle th;
 	unsigned int bmap_nr_new, bmap_nr;
 	unsigned int block_r_new, block_r;
-	
-	struct reiserfs_list_bitmap * jb;
+
+	struct reiserfs_list_bitmap *jb;
 	struct reiserfs_list_bitmap jbitmap[JOURNAL_NUM_BITMAPS];
-	
+
 	unsigned long int block_count, free_blocks;
 	int i;
-	int copy_size ;
+	int copy_size;
 
 	sb = SB_DISK_SUPER_BLOCK(s);
 
@@ -47,136 +47,145 @@ int reiserfs_resize (struct super_block * s, unsigned long block_count_new)
 	if (!bh) {
 		printk("reiserfs_resize: can\'t read last block\n");
 		return -EINVAL;
-	}	
+	}
 	bforget(bh);
 
 	/* old disk layout detection; those partitions can be mounted, but
 	 * cannot be resized */
-	if (SB_BUFFER_WITH_SB(s)->b_blocknr *	SB_BUFFER_WITH_SB(s)->b_size 
-		!= REISERFS_DISK_OFFSET_IN_BYTES ) {
-		printk("reiserfs_resize: unable to resize a reiserfs without distributed bitmap (fs version < 3.5.12)\n");
+	if (SB_BUFFER_WITH_SB(s)->b_blocknr * SB_BUFFER_WITH_SB(s)->b_size
+	    != REISERFS_DISK_OFFSET_IN_BYTES) {
+		printk
+		    ("reiserfs_resize: unable to resize a reiserfs without distributed bitmap (fs version < 3.5.12)\n");
 		return -ENOTSUPP;
 	}
-       
+
 	/* count used bits in last bitmap block */
-	block_r = SB_BLOCK_COUNT(s) -
-	        (SB_BMAP_NR(s) - 1) * s->s_blocksize * 8;
-	
+	block_r = SB_BLOCK_COUNT(s) - (SB_BMAP_NR(s) - 1) * s->s_blocksize * 8;
+
 	/* count bitmap blocks in new fs */
-	bmap_nr_new = block_count_new / ( s->s_blocksize * 8 );
+	bmap_nr_new = block_count_new / (s->s_blocksize * 8);
 	block_r_new = block_count_new - bmap_nr_new * s->s_blocksize * 8;
-	if (block_r_new) 
+	if (block_r_new)
 		bmap_nr_new++;
 	else
 		block_r_new = s->s_blocksize * 8;
 
 	/* save old values */
 	block_count = SB_BLOCK_COUNT(s);
-	bmap_nr     = SB_BMAP_NR(s);
+	bmap_nr = SB_BMAP_NR(s);
 
 	/* resizing of reiserfs bitmaps (journal and real), if needed */
-	if (bmap_nr_new > bmap_nr) {	    
-	    /* reallocate journal bitmaps */
-	    if (reiserfs_allocate_list_bitmaps(s, jbitmap, bmap_nr_new) < 0) {
-		printk("reiserfs_resize: unable to allocate memory for journal bitmaps\n");
-		unlock_super(s) ;
-		return -ENOMEM ;
-	    }
-	    /* the new journal bitmaps are zero filled, now we copy in the bitmap
-	    ** node pointers from the old journal bitmap structs, and then
-	    ** transfer the new data structures into the journal struct.
-	    **
-	    ** using the copy_size var below allows this code to work for
-	    ** both shrinking and expanding the FS.
-	    */
-	    copy_size = bmap_nr_new < bmap_nr ? bmap_nr_new : bmap_nr ;
-	    copy_size = copy_size * sizeof(struct reiserfs_list_bitmap_node *) ;
-	    for (i = 0 ; i < JOURNAL_NUM_BITMAPS ; i++) {
-		struct reiserfs_bitmap_node **node_tmp ;
-		jb = SB_JOURNAL(s)->j_list_bitmap + i ;
-		memcpy(jbitmap[i].bitmaps, jb->bitmaps, copy_size) ;
-
-		/* just in case vfree schedules on us, copy the new
-		** pointer into the journal struct before freeing the 
-		** old one
-		*/
-		node_tmp = jb->bitmaps ;
-		jb->bitmaps = jbitmap[i].bitmaps ;
-		vfree(node_tmp) ;
-	    }	
-	
-	    /* allocate additional bitmap blocks, reallocate array of bitmap
-	     * block pointers */
-	    bitmap = vmalloc(sizeof(struct reiserfs_bitmap_info) * bmap_nr_new);
-	    if (!bitmap) {
-		/* Journal bitmaps are still supersized, but the memory isn't
-		 * leaked, so I guess it's ok */
-		printk("reiserfs_resize: unable to allocate memory.\n");
-		return -ENOMEM;
-	    }
-	    memset (bitmap, 0, sizeof (struct reiserfs_bitmap_info) * SB_BMAP_NR(s));
-	    for (i = 0; i < bmap_nr; i++)
-		bitmap[i] = old_bitmap[i];
-
-	    /* This doesn't go through the journal, but it doesn't have to.
-	     * The changes are still atomic: We're synced up when the journal
-	     * transaction begins, and the new bitmaps don't matter if the
-	     * transaction fails. */
-	    for (i = bmap_nr; i < bmap_nr_new; i++) {
-		bitmap[i].bh = sb_getblk(s, i * s->s_blocksize * 8);
-		memset(bitmap[i].bh->b_data, 0, sb_blocksize(sb));
-		reiserfs_test_and_set_le_bit(0, bitmap[i].bh->b_data);
-
-		set_buffer_uptodate(bitmap[i].bh);
-		mark_buffer_dirty(bitmap[i].bh) ;
-		sync_dirty_buffer(bitmap[i].bh);
-		// update bitmap_info stuff
-		bitmap[i].first_zero_hint=1;
-		bitmap[i].free_count = sb_blocksize(sb) * 8 - 1;
-	    }	
-	    /* free old bitmap blocks array */
-	    SB_AP_BITMAP(s) = bitmap;
-	    vfree (old_bitmap);
+	if (bmap_nr_new > bmap_nr) {
+		/* reallocate journal bitmaps */
+		if (reiserfs_allocate_list_bitmaps(s, jbitmap, bmap_nr_new) < 0) {
+			printk
+			    ("reiserfs_resize: unable to allocate memory for journal bitmaps\n");
+			unlock_super(s);
+			return -ENOMEM;
+		}
+		/* the new journal bitmaps are zero filled, now we copy in the bitmap
+		 ** node pointers from the old journal bitmap structs, and then
+		 ** transfer the new data structures into the journal struct.
+		 **
+		 ** using the copy_size var below allows this code to work for
+		 ** both shrinking and expanding the FS.
+		 */
+		copy_size = bmap_nr_new < bmap_nr ? bmap_nr_new : bmap_nr;
+		copy_size =
+		    copy_size * sizeof(struct reiserfs_list_bitmap_node *);
+		for (i = 0; i < JOURNAL_NUM_BITMAPS; i++) {
+			struct reiserfs_bitmap_node **node_tmp;
+			jb = SB_JOURNAL(s)->j_list_bitmap + i;
+			memcpy(jbitmap[i].bitmaps, jb->bitmaps, copy_size);
+
+			/* just in case vfree schedules on us, copy the new
+			 ** pointer into the journal struct before freeing the 
+			 ** old one
+			 */
+			node_tmp = jb->bitmaps;
+			jb->bitmaps = jbitmap[i].bitmaps;
+			vfree(node_tmp);
+		}
+
+		/* allocate additional bitmap blocks, reallocate array of bitmap
+		 * block pointers */
+		bitmap =
+		    vmalloc(sizeof(struct reiserfs_bitmap_info) * bmap_nr_new);
+		if (!bitmap) {
+			/* Journal bitmaps are still supersized, but the memory isn't
+			 * leaked, so I guess it's ok */
+			printk("reiserfs_resize: unable to allocate memory.\n");
+			return -ENOMEM;
+		}
+		memset(bitmap, 0,
+		       sizeof(struct reiserfs_bitmap_info) * SB_BMAP_NR(s));
+		for (i = 0; i < bmap_nr; i++)
+			bitmap[i] = old_bitmap[i];
+
+		/* This doesn't go through the journal, but it doesn't have to.
+		 * The changes are still atomic: We're synced up when the journal
+		 * transaction begins, and the new bitmaps don't matter if the
+		 * transaction fails. */
+		for (i = bmap_nr; i < bmap_nr_new; i++) {
+			bitmap[i].bh = sb_getblk(s, i * s->s_blocksize * 8);
+			memset(bitmap[i].bh->b_data, 0, sb_blocksize(sb));
+			reiserfs_test_and_set_le_bit(0, bitmap[i].bh->b_data);
+
+			set_buffer_uptodate(bitmap[i].bh);
+			mark_buffer_dirty(bitmap[i].bh);
+			sync_dirty_buffer(bitmap[i].bh);
+			// update bitmap_info stuff
+			bitmap[i].first_zero_hint = 1;
+			bitmap[i].free_count = sb_blocksize(sb) * 8 - 1;
+		}
+		/* free old bitmap blocks array */
+		SB_AP_BITMAP(s) = bitmap;
+		vfree(old_bitmap);
 	}
-	
+
 	/* begin transaction, if there was an error, it's fine. Yes, we have
 	 * incorrect bitmaps now, but none of it is ever going to touch the
 	 * disk anyway. */
 	err = journal_begin(&th, s, 10);
 	if (err)
-	    return err;
+		return err;
 
 	/* correct last bitmap blocks in old and new disk layout */
 	reiserfs_prepare_for_journal(s, SB_AP_BITMAP(s)[bmap_nr - 1].bh, 1);
 	for (i = block_r; i < s->s_blocksize * 8; i++)
-	    reiserfs_test_and_clear_le_bit(i, 
-					   SB_AP_BITMAP(s)[bmap_nr - 1].bh->b_data);
+		reiserfs_test_and_clear_le_bit(i,
+					       SB_AP_BITMAP(s)[bmap_nr -
+							       1].bh->b_data);
 	SB_AP_BITMAP(s)[bmap_nr - 1].free_count += s->s_blocksize * 8 - block_r;
-	if ( !SB_AP_BITMAP(s)[bmap_nr - 1].first_zero_hint)
-	    SB_AP_BITMAP(s)[bmap_nr - 1].first_zero_hint = block_r;
+	if (!SB_AP_BITMAP(s)[bmap_nr - 1].first_zero_hint)
+		SB_AP_BITMAP(s)[bmap_nr - 1].first_zero_hint = block_r;
 
 	journal_mark_dirty(&th, s, SB_AP_BITMAP(s)[bmap_nr - 1].bh);
 
 	reiserfs_prepare_for_journal(s, SB_AP_BITMAP(s)[bmap_nr_new - 1].bh, 1);
 	for (i = block_r_new; i < s->s_blocksize * 8; i++)
-	    reiserfs_test_and_set_le_bit(i,
-					 SB_AP_BITMAP(s)[bmap_nr_new - 1].bh->b_data);
+		reiserfs_test_and_set_le_bit(i,
+					     SB_AP_BITMAP(s)[bmap_nr_new -
+							     1].bh->b_data);
 	journal_mark_dirty(&th, s, SB_AP_BITMAP(s)[bmap_nr_new - 1].bh);
- 
-	SB_AP_BITMAP(s)[bmap_nr_new - 1].free_count -= s->s_blocksize * 8 - block_r_new;
+
+	SB_AP_BITMAP(s)[bmap_nr_new - 1].free_count -=
+	    s->s_blocksize * 8 - block_r_new;
 	/* Extreme case where last bitmap is the only valid block in itself. */
-	if ( !SB_AP_BITMAP(s)[bmap_nr_new - 1].free_count )
-	    SB_AP_BITMAP(s)[bmap_nr_new - 1].first_zero_hint = 0;
- 	/* update super */
-	reiserfs_prepare_for_journal(s, SB_BUFFER_WITH_SB(s), 1) ;
+	if (!SB_AP_BITMAP(s)[bmap_nr_new - 1].free_count)
+		SB_AP_BITMAP(s)[bmap_nr_new - 1].first_zero_hint = 0;
+	/* update super */
+	reiserfs_prepare_for_journal(s, SB_BUFFER_WITH_SB(s), 1);
 	free_blocks = SB_FREE_BLOCKS(s);
-	PUT_SB_FREE_BLOCKS(s, free_blocks + (block_count_new - block_count - (bmap_nr_new - bmap_nr)));
+	PUT_SB_FREE_BLOCKS(s,
+			   free_blocks + (block_count_new - block_count -
+					  (bmap_nr_new - bmap_nr)));
 	PUT_SB_BLOCK_COUNT(s, block_count_new);
 	PUT_SB_BMAP_NR(s, bmap_nr_new);
 	s->s_dirt = 1;
 
 	journal_mark_dirty(&th, s, SB_BUFFER_WITH_SB(s));
-	
+
 	SB_JOURNAL(s)->j_must_wait = 1;
 	return journal_end(&th, s, 10);
 }

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/fs/reiserfs/resize.c b/fs/reiserfs/resize.c
new file mode 100644
index 000000000000..170012078b76
--- /dev/null
+++ b/fs/reiserfs/resize.c
@@ -0,0 +1,182 @@
+/* 
+ * Copyright 2000 by Hans Reiser, licensing governed by reiserfs/README
+ */
+ 
+/* 
+ * Written by Alexander Zarochentcev.
+ *
+ * The kernel part of the (on-line) reiserfs resizer.
+ */
+
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/string.h>
+#include <linux/errno.h>
+#include <linux/reiserfs_fs.h>
+#include <linux/reiserfs_fs_sb.h>
+#include <linux/buffer_head.h>
+
+int reiserfs_resize (struct super_block * s, unsigned long block_count_new)
+{
+        int err = 0;
+	struct reiserfs_super_block * sb;
+        struct reiserfs_bitmap_info *bitmap;
+	struct reiserfs_bitmap_info *old_bitmap = SB_AP_BITMAP(s);
+	struct buffer_head * bh;
+	struct reiserfs_transaction_handle th;
+	unsigned int bmap_nr_new, bmap_nr;
+	unsigned int block_r_new, block_r;
+	
+	struct reiserfs_list_bitmap * jb;
+	struct reiserfs_list_bitmap jbitmap[JOURNAL_NUM_BITMAPS];
+	
+	unsigned long int block_count, free_blocks;
+	int i;
+	int copy_size ;
+
+	sb = SB_DISK_SUPER_BLOCK(s);
+
+	if (SB_BLOCK_COUNT(s) >= block_count_new) {
+		printk("can\'t shrink filesystem on-line\n");
+		return -EINVAL;
+	}
+
+	/* check the device size */
+	bh = sb_bread(s, block_count_new - 1);
+	if (!bh) {
+		printk("reiserfs_resize: can\'t read last block\n");
+		return -EINVAL;
+	}	
+	bforget(bh);
+
+	/* old disk layout detection; those partitions can be mounted, but
+	 * cannot be resized */
+	if (SB_BUFFER_WITH_SB(s)->b_blocknr *	SB_BUFFER_WITH_SB(s)->b_size 
+		!= REISERFS_DISK_OFFSET_IN_BYTES ) {
+		printk("reiserfs_resize: unable to resize a reiserfs without distributed bitmap (fs version < 3.5.12)\n");
+		return -ENOTSUPP;
+	}
+       
+	/* count used bits in last bitmap block */
+	block_r = SB_BLOCK_COUNT(s) -
+	        (SB_BMAP_NR(s) - 1) * s->s_blocksize * 8;
+	
+	/* count bitmap blocks in new fs */
+	bmap_nr_new = block_count_new / ( s->s_blocksize * 8 );
+	block_r_new = block_count_new - bmap_nr_new * s->s_blocksize * 8;
+	if (block_r_new) 
+		bmap_nr_new++;
+	else
+		block_r_new = s->s_blocksize * 8;
+
+	/* save old values */
+	block_count = SB_BLOCK_COUNT(s);
+	bmap_nr     = SB_BMAP_NR(s);
+
+	/* resizing of reiserfs bitmaps (journal and real), if needed */
+	if (bmap_nr_new > bmap_nr) {	    
+	    /* reallocate journal bitmaps */
+	    if (reiserfs_allocate_list_bitmaps(s, jbitmap, bmap_nr_new) < 0) {
+		printk("reiserfs_resize: unable to allocate memory for journal bitmaps\n");
+		unlock_super(s) ;
+		return -ENOMEM ;
+	    }
+	    /* the new journal bitmaps are zero filled, now we copy in the bitmap
+	    ** node pointers from the old journal bitmap structs, and then
+	    ** transfer the new data structures into the journal struct.
+	    **
+	    ** using the copy_size var below allows this code to work for
+	    ** both shrinking and expanding the FS.
+	    */
+	    copy_size = bmap_nr_new < bmap_nr ? bmap_nr_new : bmap_nr ;
+	    copy_size = copy_size * sizeof(struct reiserfs_list_bitmap_node *) ;
+	    for (i = 0 ; i < JOURNAL_NUM_BITMAPS ; i++) {
+		struct reiserfs_bitmap_node **node_tmp ;
+		jb = SB_JOURNAL(s)->j_list_bitmap + i ;
+		memcpy(jbitmap[i].bitmaps, jb->bitmaps, copy_size) ;
+
+		/* just in case vfree schedules on us, copy the new
+		** pointer into the journal struct before freeing the 
+		** old one
+		*/
+		node_tmp = jb->bitmaps ;
+		jb->bitmaps = jbitmap[i].bitmaps ;
+		vfree(node_tmp) ;
+	    }	
+	
+	    /* allocate additional bitmap blocks, reallocate array of bitmap
+	     * block pointers */
+	    bitmap = vmalloc(sizeof(struct reiserfs_bitmap_info) * bmap_nr_new);
+	    if (!bitmap) {
+		/* Journal bitmaps are still supersized, but the memory isn't
+		 * leaked, so I guess it's ok */
+		printk("reiserfs_resize: unable to allocate memory.\n");
+		return -ENOMEM;
+	    }
+	    memset (bitmap, 0, sizeof (struct reiserfs_bitmap_info) * SB_BMAP_NR(s));
+	    for (i = 0; i < bmap_nr; i++)
+		bitmap[i] = old_bitmap[i];
+
+	    /* This doesn't go through the journal, but it doesn't have to.
+	     * The changes are still atomic: We're synced up when the journal
+	     * transaction begins, and the new bitmaps don't matter if the
+	     * transaction fails. */
+	    for (i = bmap_nr; i < bmap_nr_new; i++) {
+		bitmap[i].bh = sb_getblk(s, i * s->s_blocksize * 8);
+		memset(bitmap[i].bh->b_data, 0, sb_blocksize(sb));
+		reiserfs_test_and_set_le_bit(0, bitmap[i].bh->b_data);
+
+		set_buffer_uptodate(bitmap[i].bh);
+		mark_buffer_dirty(bitmap[i].bh) ;
+		sync_dirty_buffer(bitmap[i].bh);
+		// update bitmap_info stuff
+		bitmap[i].first_zero_hint=1;
+		bitmap[i].free_count = sb_blocksize(sb) * 8 - 1;
+	    }	
+	    /* free old bitmap blocks array */
+	    SB_AP_BITMAP(s) = bitmap;
+	    vfree (old_bitmap);
+	}
+	
+	/* begin transaction, if there was an error, it's fine. Yes, we have
+	 * incorrect bitmaps now, but none of it is ever going to touch the
+	 * disk anyway. */
+	err = journal_begin(&th, s, 10);
+	if (err)
+	    return err;
+
+	/* correct last bitmap blocks in old and new disk layout */
+	reiserfs_prepare_for_journal(s, SB_AP_BITMAP(s)[bmap_nr - 1].bh, 1);
+	for (i = block_r; i < s->s_blocksize * 8; i++)
+	    reiserfs_test_and_clear_le_bit(i, 
+					   SB_AP_BITMAP(s)[bmap_nr - 1].bh->b_data);
+	SB_AP_BITMAP(s)[bmap_nr - 1].free_count += s->s_blocksize * 8 - block_r;
+	if ( !SB_AP_BITMAP(s)[bmap_nr - 1].first_zero_hint)
+	    SB_AP_BITMAP(s)[bmap_nr - 1].first_zero_hint = block_r;
+
+	journal_mark_dirty(&th, s, SB_AP_BITMAP(s)[bmap_nr - 1].bh);
+
+	reiserfs_prepare_for_journal(s, SB_AP_BITMAP(s)[bmap_nr_new - 1].bh, 1);
+	for (i = block_r_new; i < s->s_blocksize * 8; i++)
+	    reiserfs_test_and_set_le_bit(i,
+					 SB_AP_BITMAP(s)[bmap_nr_new - 1].bh->b_data);
+	journal_mark_dirty(&th, s, SB_AP_BITMAP(s)[bmap_nr_new - 1].bh);
+ 
+	SB_AP_BITMAP(s)[bmap_nr_new - 1].free_count -= s->s_blocksize * 8 - block_r_new;
+	/* Extreme case where last bitmap is the only valid block in itself. */
+	if ( !SB_AP_BITMAP(s)[bmap_nr_new - 1].free_count )
+	    SB_AP_BITMAP(s)[bmap_nr_new - 1].first_zero_hint = 0;
+ 	/* update super */
+	reiserfs_prepare_for_journal(s, SB_BUFFER_WITH_SB(s), 1) ;
+	free_blocks = SB_FREE_BLOCKS(s);
+	PUT_SB_FREE_BLOCKS(s, free_blocks + (block_count_new - block_count - (bmap_nr_new - bmap_nr)));
+	PUT_SB_BLOCK_COUNT(s, block_count_new);
+	PUT_SB_BMAP_NR(s, bmap_nr_new);
+	s->s_dirt = 1;
+
+	journal_mark_dirty(&th, s, SB_BUFFER_WITH_SB(s));
+	
+	SB_JOURNAL(s)->j_must_wait = 1;
+	return journal_end(&th, s, 10);
+}
