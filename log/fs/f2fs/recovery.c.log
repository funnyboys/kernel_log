commit 43c780ba26244e4caf3f9986beb6c4ae5eb54f50
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu May 7 00:59:04 2020 -0700

    f2fs: rework filename handling
    
    Rework f2fs's handling of filenames to use a new 'struct f2fs_filename'.
    Similar to 'struct ext4_filename', this stores the usr_fname, disk_name,
    dirhash, crypto_buf, and casefolded name.  Some of these names can be
    NULL in some cases.  'struct f2fs_filename' differs from
    'struct fscrypt_name' mainly in that the casefolded name is included.
    
    For user-initiated directory operations like lookup() and create(),
    initialize the f2fs_filename by translating the corresponding
    fscrypt_name, then computing the dirhash and casefolded name if needed.
    
    This makes the dirhash and casefolded name be cached for each syscall,
    so we don't have to recompute them repeatedly.  (Previously, f2fs
    computed the dirhash once per directory level, and the casefolded name
    once per directory block.)  This improves performance.
    
    This rework also makes it much easier to correctly handle all
    combinations of normal, encrypted, casefolded, and encrypted+casefolded
    directories.  (The fourth isn't supported yet but is being worked on.)
    
    The only other cases where an f2fs_filename gets initialized are for two
    filesystem-internal operations: (1) when converting an inline directory
    to a regular one, we grab the needed disk_name and hash from an existing
    f2fs_dir_entry; and (2) when roll-forward recovering a new dentry, we
    grab the needed disk_name from f2fs_inode::i_name and compute the hash.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index dd804c07eeb0..ae5310f02e7f 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -107,13 +107,51 @@ static void del_fsync_inode(struct fsync_inode_entry *entry, int drop)
 	kmem_cache_free(fsync_entry_slab, entry);
 }
 
+static int init_recovered_filename(const struct inode *dir,
+				   struct f2fs_inode *raw_inode,
+				   struct f2fs_filename *fname,
+				   struct qstr *usr_fname)
+{
+	int err;
+
+	memset(fname, 0, sizeof(*fname));
+	fname->disk_name.len = le32_to_cpu(raw_inode->i_namelen);
+	fname->disk_name.name = raw_inode->i_name;
+
+	if (WARN_ON(fname->disk_name.len > F2FS_NAME_LEN))
+		return -ENAMETOOLONG;
+
+	if (!IS_ENCRYPTED(dir)) {
+		usr_fname->name = fname->disk_name.name;
+		usr_fname->len = fname->disk_name.len;
+		fname->usr_fname = usr_fname;
+	}
+
+	/* Compute the hash of the filename */
+	if (IS_CASEFOLDED(dir)) {
+		err = f2fs_init_casefolded_name(dir, fname);
+		if (err)
+			return err;
+		f2fs_hash_filename(dir, fname);
+#ifdef CONFIG_UNICODE
+		/* Case-sensitive match is fine for recovery */
+		kfree(fname->cf_name.name);
+		fname->cf_name.name = NULL;
+#endif
+	} else {
+		f2fs_hash_filename(dir, fname);
+	}
+	return 0;
+}
+
 static int recover_dentry(struct inode *inode, struct page *ipage,
 						struct list_head *dir_list)
 {
 	struct f2fs_inode *raw_inode = F2FS_INODE(ipage);
 	nid_t pino = le32_to_cpu(raw_inode->i_pino);
 	struct f2fs_dir_entry *de;
-	struct fscrypt_name fname;
+	struct f2fs_filename fname;
+	struct qstr usr_fname;
 	struct page *page;
 	struct inode *dir, *einode;
 	struct fsync_inode_entry *entry;
@@ -132,16 +170,9 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 	}
 
 	dir = entry->inode;
-
-	memset(&fname, 0, sizeof(struct fscrypt_name));
-	fname.disk_name.len = le32_to_cpu(raw_inode->i_namelen);
-	fname.disk_name.name = raw_inode->i_name;
-
-	if (unlikely(fname.disk_name.len > F2FS_NAME_LEN)) {
-		WARN_ON(1);
-		err = -ENAMETOOLONG;
+	err = init_recovered_filename(dir, raw_inode, &fname, &usr_fname);
+	if (err)
 		goto out;
-	}
 retry:
 	de = __f2fs_find_entry(dir, &fname, &page);
 	if (de && inode->i_ino == le32_to_cpu(de->ino))

commit 5df7731f60c2a933695a68d732f8b39fca788de6
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Feb 17 17:45:44 2020 +0800

    f2fs: introduce DEFAULT_IO_TIMEOUT
    
    As Geert Uytterhoeven reported:
    
    for parameter HZ/50 in congestion_wait(BLK_RW_ASYNC, HZ/50);
    
    On some platforms, HZ can be less than 50, then unexpected 0 timeout
    jiffies will be set in congestion_wait().
    
    This patch introduces a macro DEFAULT_IO_TIMEOUT to wrap a determinate
    value with msecs_to_jiffies(20) to instead HZ/50 to avoid such issue.
    
    Quoted from Geert Uytterhoeven:
    
    "A timeout of HZ means 1 second.
    HZ/50 means 20 ms, but has the risk of being zero, if HZ < 50.
    
    If you want to use a timeout of 20 ms, you best use msecs_to_jiffies(20),
    as that takes care of the special cases, and never returns 0."
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 348e8d463b3e..dd804c07eeb0 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -534,7 +534,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	err = f2fs_get_dnode_of_data(&dn, start, ALLOC_NODE);
 	if (err) {
 		if (err == -ENOMEM) {
-			congestion_wait(BLK_RW_ASYNC, HZ/50);
+			congestion_wait(BLK_RW_ASYNC, DEFAULT_IO_TIMEOUT);
 			goto retry_dn;
 		}
 		goto out;
@@ -617,7 +617,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			err = check_index_in_prev_nodes(sbi, dest, &dn);
 			if (err) {
 				if (err == -ENOMEM) {
-					congestion_wait(BLK_RW_ASYNC, HZ/50);
+					congestion_wait(BLK_RW_ASYNC,
+							DEFAULT_IO_TIMEOUT);
 					goto retry_prev;
 				}
 				goto err;

commit a2ced1ce1087a19361b7845c85a2d910fc591344
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Feb 14 17:44:10 2020 +0800

    f2fs: clean up codes with {f2fs_,}data_blkaddr()
    
    - rename datablock_addr() to data_blkaddr().
    - wrap data_blkaddr() with f2fs_data_blkaddr() to clean up
    parameters.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 763d5c0951d1..348e8d463b3e 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -496,8 +496,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	return 0;
 
 truncate_out:
-	if (datablock_addr(tdn.inode, tdn.node_page,
-					tdn.ofs_in_node) == blkaddr)
+	if (f2fs_data_blkaddr(&tdn) == blkaddr)
 		f2fs_truncate_data_blocks_range(&tdn, 1);
 	if (dn->inode->i_ino == nid && !dn->inode_page_locked)
 		unlock_page(dn->inode_page);
@@ -560,8 +559,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	for (; start < end; start++, dn.ofs_in_node++) {
 		block_t src, dest;
 
-		src = datablock_addr(dn.inode, dn.node_page, dn.ofs_in_node);
-		dest = datablock_addr(dn.inode, page, dn.ofs_in_node);
+		src = f2fs_data_blkaddr(&dn);
+		dest = data_blkaddr(dn.inode, page, dn.ofs_in_node);
 
 		if (__is_valid_data_blkaddr(src) &&
 			!f2fs_is_valid_blkaddr(sbi, src, META_POR)) {

commit c426d99127b1ab797f4cc355b18d77288978b2f2
Author: Shin'ichiro Kawasaki <shinichiro.kawasaki@wdc.com>
Date:   Mon Dec 9 19:44:44 2019 +0900

    f2fs: Check write pointer consistency of open zones
    
    On sudden f2fs shutdown, write pointers of zoned block devices can go
    further but f2fs meta data keeps current segments at positions before the
    write operations. After remounting the f2fs, this inconsistency causes
    write operations not at write pointers and "Unaligned write command"
    error is reported.
    
    To avoid the error, compare current segments with write pointers of open
    zones the current segments point to, during mount operation. If the write
    pointer position is not aligned with the current segment position, assign
    a new zone to the current segment. Also check the newly assigned zone has
    write pointer at zone start. If not, reset write pointer of the zone.
    
    Perform the consistency check during fsync recovery. Not to lose the
    fsync data, do the check after fsync data gets restored and before
    checkpoint commit which flushes data at current segment positions. Not to
    cause conflict with kworker's dirfy data/node flush, do the fix within
    SBI_POR_DOING protection.
    
    Signed-off-by: Shin'ichiro Kawasaki <shinichiro.kawasaki@wdc.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 76477f71d4ee..763d5c0951d1 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -723,6 +723,7 @@ int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	int ret = 0;
 	unsigned long s_flags = sbi->sb->s_flags;
 	bool need_writecp = false;
+	bool fix_curseg_write_pointer = false;
 #ifdef CONFIG_QUOTA
 	int quota_enabled;
 #endif
@@ -774,6 +775,8 @@ int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 		sbi->sb->s_flags = s_flags;
 	}
 skip:
+	fix_curseg_write_pointer = !check_only || list_empty(&inode_list);
+
 	destroy_fsync_dnodes(&inode_list, err);
 	destroy_fsync_dnodes(&tmp_inode_list, err);
 
@@ -784,9 +787,22 @@ int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	if (err) {
 		truncate_inode_pages_final(NODE_MAPPING(sbi));
 		truncate_inode_pages_final(META_MAPPING(sbi));
-	} else {
-		clear_sbi_flag(sbi, SBI_POR_DOING);
 	}
+
+	/*
+	 * If fsync data succeeds or there is no fsync data to recover,
+	 * and the f2fs is not read only, check and fix zoned block devices'
+	 * write pointer consistency.
+	 */
+	if (!err && fix_curseg_write_pointer && !f2fs_readonly(sbi->sb) &&
+			f2fs_sb_has_blkzoned(sbi)) {
+		err = f2fs_fix_curseg_write_pointer(sbi);
+		ret = err;
+	}
+
+	if (!err)
+		clear_sbi_flag(sbi, SBI_POR_DOING);
+
 	mutex_unlock(&sbi->cp_mutex);
 
 	/* let's drop all the directory inodes for clean checkpoint */

commit f5a53edcf01eae21dc3ef1845515229e8459e5cc
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Oct 18 10:06:40 2019 -0700

    f2fs: support aligned pinned file
    
    This patch supports 2MB-aligned pinned file, which can guarantee no GC at all
    by allocating fully valid 2MB segment.
    
    Check free segments by has_not_enough_free_secs() with large budget.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 783773e4560d..76477f71d4ee 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -711,7 +711,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 		f2fs_put_page(page, 1);
 	}
 	if (!err)
-		f2fs_allocate_new_segments(sbi);
+		f2fs_allocate_new_segments(sbi, NO_CHECK_TYPE);
 	return err;
 }
 

commit 10f966bbf521bb9b2e497bbca496a5141f4071d0
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Jun 20 11:36:14 2019 +0800

    f2fs: use generic EFSBADCRC/EFSCORRUPTED
    
    f2fs uses EFAULT as error number to indicate filesystem is corrupted
    all the time, but generic filesystems use EUCLEAN for such condition,
    we need to change to follow others.
    
    This patch adds two new macros as below to wrap more generic error
    code macros, and spread them in code.
    
    EFSBADCRC       EBADMSG         /* Bad CRC detected */
    EFSCORRUPTED    EUCLEAN         /* Filesystem is corrupted */
    
    Reported-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Acked-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 72c2c4ba795f..783773e4560d 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -553,7 +553,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		f2fs_warn(sbi, "Inconsistent ofs_of_node, ino:%lu, ofs:%u, %u",
 			  inode->i_ino, ofs_of_node(dn.node_page),
 			  ofs_of_node(page));
-		err = -EFAULT;
+		err = -EFSCORRUPTED;
 		goto err;
 	}
 
@@ -565,13 +565,13 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 		if (__is_valid_data_blkaddr(src) &&
 			!f2fs_is_valid_blkaddr(sbi, src, META_POR)) {
-			err = -EFAULT;
+			err = -EFSCORRUPTED;
 			goto err;
 		}
 
 		if (__is_valid_data_blkaddr(dest) &&
 			!f2fs_is_valid_blkaddr(sbi, dest, META_POR)) {
-			err = -EFAULT;
+			err = -EFSCORRUPTED;
 			goto err;
 		}
 

commit dcbb4c10e6d9693cc9d6fa493b4d130b66a60c7d
Author: Joe Perches <joe@perches.com>
Date:   Tue Jun 18 17:48:42 2019 +0800

    f2fs: introduce f2fs_<level> macros to wrap f2fs_printk()
    
    - Add and use f2fs_<level> macros
    - Convert f2fs_msg to f2fs_printk
    - Remove level from f2fs_printk and embed the level in the format
    - Coalesce formats and align multi-line arguments
    - Remove unnecessary duplicate extern f2fs_msg f2fs.h
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index e04f82b3f4fc..72c2c4ba795f 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -188,10 +188,9 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 		name = "<encrypted>";
 	else
 		name = raw_inode->i_name;
-	f2fs_msg(inode->i_sb, KERN_NOTICE,
-			"%s: ino = %x, name = %s, dir = %lx, err = %d",
-			__func__, ino_of_node(ipage), name,
-			IS_ERR(dir) ? 0 : dir->i_ino, err);
+	f2fs_notice(F2FS_I_SB(inode), "%s: ino = %x, name = %s, dir = %lx, err = %d",
+		    __func__, ino_of_node(ipage), name,
+		    IS_ERR(dir) ? 0 : dir->i_ino, err);
 	return err;
 }
 
@@ -292,9 +291,8 @@ static int recover_inode(struct inode *inode, struct page *page)
 	else
 		name = F2FS_INODE(page)->i_name;
 
-	f2fs_msg(inode->i_sb, KERN_NOTICE,
-		"recover_inode: ino = %x, name = %s, inline = %x",
-			ino_of_node(page), name, raw->i_inline);
+	f2fs_notice(F2FS_I_SB(inode), "recover_inode: ino = %x, name = %s, inline = %x",
+		    ino_of_node(page), name, raw->i_inline);
 	return 0;
 }
 
@@ -371,10 +369,9 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 		/* sanity check in order to detect looped node chain */
 		if (++loop_cnt >= free_blocks ||
 			blkaddr == next_blkaddr_of_node(page)) {
-			f2fs_msg(sbi->sb, KERN_NOTICE,
-				"%s: detect looped node chain, "
-				"blkaddr:%u, next:%u",
-				__func__, blkaddr, next_blkaddr_of_node(page));
+			f2fs_notice(sbi, "%s: detect looped node chain, blkaddr:%u, next:%u",
+				    __func__, blkaddr,
+				    next_blkaddr_of_node(page));
 			f2fs_put_page(page, 1);
 			err = -EINVAL;
 			break;
@@ -553,10 +550,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	f2fs_bug_on(sbi, ni.ino != ino_of_node(page));
 
 	if (ofs_of_node(dn.node_page) != ofs_of_node(page)) {
-		f2fs_msg(sbi->sb, KERN_WARNING,
-			"Inconsistent ofs_of_node, ino:%lu, ofs:%u, %u",
-			inode->i_ino, ofs_of_node(dn.node_page),
-			ofs_of_node(page));
+		f2fs_warn(sbi, "Inconsistent ofs_of_node, ino:%lu, ofs:%u, %u",
+			  inode->i_ino, ofs_of_node(dn.node_page),
+			  ofs_of_node(page));
 		err = -EFAULT;
 		goto err;
 	}
@@ -642,11 +638,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 err:
 	f2fs_put_dnode(&dn);
 out:
-	f2fs_msg(sbi->sb, KERN_NOTICE,
-		"recover_data: ino = %lx (i_size: %s) recovered = %d, err = %d",
-		inode->i_ino,
-		file_keep_isize(inode) ? "keep" : "recover",
-		recovered, err);
+	f2fs_notice(sbi, "recover_data: ino = %lx (i_size: %s) recovered = %d, err = %d",
+		    inode->i_ino, file_keep_isize(inode) ? "keep" : "recover",
+		    recovered, err);
 	return err;
 }
 
@@ -734,8 +728,7 @@ int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 #endif
 
 	if (s_flags & SB_RDONLY) {
-		f2fs_msg(sbi->sb, KERN_INFO,
-				"recover fsync data on readonly fs");
+		f2fs_info(sbi, "recover fsync data on readonly fs");
 		sbi->sb->s_flags &= ~SB_RDONLY;
 	}
 

commit 93770ab7a6e963147a5dbca25278b69ba6c8f8c5
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Apr 15 15:26:32 2019 +0800

    f2fs: introduce DATA_GENERIC_ENHANCE
    
    Previously, f2fs_is_valid_blkaddr(, blkaddr, DATA_GENERIC) will check
    whether @blkaddr locates in main area or not.
    
    That check is weak, since the block address in range of main area can
    point to the address which is not valid in segment info table, and we
    can not detect such condition, we may suffer worse corruption as system
    continues running.
    
    So this patch introduce DATA_GENERIC_ENHANCE to enhance the sanity check
    which trigger SIT bitmap check rather than only range check.
    
    This patch did below changes as wel:
    - set SBI_NEED_FSCK in f2fs_is_valid_blkaddr().
    - get rid of is_valid_data_blkaddr() to avoid panic if blkaddr is invalid.
    - introduce verify_fio_blkaddr() to wrap fio {new,old}_blkaddr validation check.
    - spread blkaddr check in:
     * f2fs_get_node_info()
     * __read_out_blkaddrs()
     * f2fs_submit_page_read()
     * ra_data_block()
     * do_recover_data()
    
    This patch can fix bug reported from bugzilla below:
    
    https://bugzilla.kernel.org/show_bug.cgi?id=203215
    https://bugzilla.kernel.org/show_bug.cgi?id=203223
    https://bugzilla.kernel.org/show_bug.cgi?id=203231
    https://bugzilla.kernel.org/show_bug.cgi?id=203235
    https://bugzilla.kernel.org/show_bug.cgi?id=203241
    
    = Update by Jaegeuk Kim =
    
    DATA_GENERIC_ENHANCE enhanced to validate block addresses on read/write paths.
    But, xfstest/generic/446 compalins some generated kernel messages saying invalid
    bitmap was detected when reading a block. The reaons is, when we get the
    block addresses from extent_cache, there is no lock to synchronize it from
    truncating the blocks in parallel.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b14c718139a9..e04f82b3f4fc 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -567,6 +567,18 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		src = datablock_addr(dn.inode, dn.node_page, dn.ofs_in_node);
 		dest = datablock_addr(dn.inode, page, dn.ofs_in_node);
 
+		if (__is_valid_data_blkaddr(src) &&
+			!f2fs_is_valid_blkaddr(sbi, src, META_POR)) {
+			err = -EFAULT;
+			goto err;
+		}
+
+		if (__is_valid_data_blkaddr(dest) &&
+			!f2fs_is_valid_blkaddr(sbi, dest, META_POR)) {
+			err = -EFAULT;
+			goto err;
+		}
+
 		/* skip recovering if dest is the same as src */
 		if (src == dest)
 			continue;

commit 22d61e286e2d9097dae36f75ed48801056b77cac
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Apr 15 15:28:37 2019 +0800

    f2fs: fix to avoid panic in do_recover_data()
    
    As Jungyeon reported in bugzilla:
    
    https://bugzilla.kernel.org/show_bug.cgi?id=203227
    
    - Overview
    When mounting the attached crafted image, following errors are reported.
    Additionally, it hangs on sync after trying to mount it.
    
    The image is intentionally fuzzed from a normal f2fs image for testing.
    Compile options for F2FS are as follows.
    CONFIG_F2FS_FS=y
    CONFIG_F2FS_STAT_FS=y
    CONFIG_F2FS_FS_XATTR=y
    CONFIG_F2FS_FS_POSIX_ACL=y
    CONFIG_F2FS_CHECK_FS=y
    
    - Reproduces
    mkdir test
    mount -t f2fs tmp.img test
    sync
    
    - Messages
     kernel BUG at fs/f2fs/recovery.c:549!
     RIP: 0010:recover_data+0x167a/0x1780
     Call Trace:
      f2fs_recover_fsync_data+0x613/0x710
      f2fs_fill_super+0x1043/0x1aa0
      mount_bdev+0x16d/0x1a0
      mount_fs+0x4a/0x170
      vfs_kern_mount+0x5d/0x100
      do_mount+0x200/0xcf0
      ksys_mount+0x79/0xc0
      __x64_sys_mount+0x1c/0x20
      do_syscall_64+0x43/0xf0
      entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    During recovery, if ofs_of_node is inconsistent in between recovered
    node page and original checkpointed node page, let's just fail recovery
    instead of making kernel panic.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d4f9d5408103..b14c718139a9 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -551,7 +551,15 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		goto err;
 
 	f2fs_bug_on(sbi, ni.ino != ino_of_node(page));
-	f2fs_bug_on(sbi, ofs_of_node(dn.node_page) != ofs_of_node(page));
+
+	if (ofs_of_node(dn.node_page) != ofs_of_node(page)) {
+		f2fs_msg(sbi->sb, KERN_WARNING,
+			"Inconsistent ofs_of_node, ino:%lu, ofs:%u, %u",
+			inode->i_ino, ofs_of_node(dn.node_page),
+			ofs_of_node(page));
+		err = -EFAULT;
+		goto err;
+	}
 
 	for (; start < end; start++, dn.ofs_in_node++) {
 		block_t src, dest;

commit 988385795c7f46b231982d54750587f204bd558b
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Apr 10 18:45:26 2019 +0800

    f2fs: fix error path of recovery
    
    There are some places in where we missed to unlock page or unlock page
    incorrectly, fix them.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index e3883db868d8..d4f9d5408103 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -325,8 +325,10 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 			break;
 		}
 
-		if (!is_recoverable_dnode(page))
+		if (!is_recoverable_dnode(page)) {
+			f2fs_put_page(page, 1);
 			break;
+		}
 
 		if (!is_fsync_dnode(page))
 			goto next;
@@ -338,8 +340,10 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 			if (!check_only &&
 					IS_INODE(page) && is_dent_dnode(page)) {
 				err = f2fs_recover_inode_page(sbi, page);
-				if (err)
+				if (err) {
+					f2fs_put_page(page, 1);
 					break;
+				}
 				quota_inode = true;
 			}
 
@@ -355,6 +359,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 					err = 0;
 					goto next;
 				}
+				f2fs_put_page(page, 1);
 				break;
 			}
 		}
@@ -370,6 +375,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 				"%s: detect looped node chain, "
 				"blkaddr:%u, next:%u",
 				__func__, blkaddr, next_blkaddr_of_node(page));
+			f2fs_put_page(page, 1);
 			err = -EINVAL;
 			break;
 		}
@@ -380,7 +386,6 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 
 		f2fs_ra_meta_pages_cond(sbi, blkaddr);
 	}
-	f2fs_put_page(page, 1);
 	return err;
 }
 
@@ -666,8 +671,10 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 		 */
 		if (IS_INODE(page)) {
 			err = recover_inode(entry->inode, page);
-			if (err)
+			if (err) {
+				f2fs_put_page(page, 1);
 				break;
+			}
 		}
 		if (entry->last_dentry == blkaddr) {
 			err = recover_dentry(entry->inode, page, dir_list);

commit bae0ee7a767ceeea6d8e170da3f228fbc7480331
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Dec 25 17:43:42 2018 +0800

    f2fs: check PageWriteback flag for ordered case
    
    For all ordered cases in f2fs_wait_on_page_writeback(), we need to
    check PageWriteback status, so let's clean up to relocate the check
    into f2fs_wait_on_page_writeback().
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index c22f9d0011ba..e3883db868d8 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -539,7 +539,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		goto out;
 	}
 
-	f2fs_wait_on_page_writeback(dn.node_page, NODE, true);
+	f2fs_wait_on_page_writeback(dn.node_page, NODE, true, true);
 
 	err = f2fs_get_node_info(sbi, dn.nid, &ni);
 	if (err)

commit 7beb01f74415c56f5992922b5b902b45d365e694
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Oct 24 18:34:26 2018 +0800

    f2fs: clean up f2fs_sb_has_##feature_name
    
    In F2FS_HAS_FEATURE(), we will use F2FS_SB(sb) to get sbi pointer to
    access .raw_super field, to avoid unneeded pointer conversion, this
    patch changes to F2FS_HAS_FEATURE() accept sbi parameter directly.
    
    Just do cleanup, no logic change.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 1dfb17f9f9ff..c22f9d0011ba 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -250,7 +250,7 @@ static int recover_inode(struct inode *inode, struct page *page)
 	i_gid_write(inode, le32_to_cpu(raw->i_gid));
 
 	if (raw->i_inline & F2FS_EXTRA_ATTR) {
-		if (f2fs_sb_has_project_quota(F2FS_I_SB(inode)->sb) &&
+		if (f2fs_sb_has_project_quota(F2FS_I_SB(inode)) &&
 			F2FS_FITS_IN_INODE(raw, le16_to_cpu(raw->i_extra_isize),
 								i_projid)) {
 			projid_t i_projid;

commit 78130819695f17f5c042d8ba097802639478faf5
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Sep 25 15:36:02 2018 +0800

    f2fs: fix to keep project quota consistent
    
    This patch does below changes to keep consistence of project quota data
    in sudden power-cut case:
    - update inode.i_projid and project quota atomically under lock_op() in
    f2fs_ioc_setproject()
    - recover inode.i_projid and project quota in recover_inode()
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index df2123759ac7..1dfb17f9f9ff 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -254,10 +254,18 @@ static int recover_inode(struct inode *inode, struct page *page)
 			F2FS_FITS_IN_INODE(raw, le16_to_cpu(raw->i_extra_isize),
 								i_projid)) {
 			projid_t i_projid;
+			kprojid_t kprojid;
 
 			i_projid = (projid_t)le32_to_cpu(raw->i_projid);
-			F2FS_I(inode)->i_projid =
-				make_kprojid(&init_user_ns, i_projid);
+			kprojid = make_kprojid(&init_user_ns, i_projid);
+
+			if (!projid_eq(kprojid, F2FS_I(inode)->i_projid)) {
+				err = f2fs_transfer_project_quota(inode,
+								kprojid);
+				if (err)
+					return err;
+				F2FS_I(inode)->i_projid = kprojid;
+			}
 		}
 	}
 

commit af033b2aa8a874fd5737fafe90d159136527b5b4
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Sep 20 20:05:00 2018 +0800

    f2fs: guarantee journalled quota data by checkpoint
    
    For journalled quota mode, let checkpoint to flush dquot dirty data
    and quota file data to guarntee persistence of all quota sysfile in
    last checkpoint, by this way, we can avoid corrupting quota sysfile
    when encountering SPO.
    
    The implementation is as below:
    
    1. add a global state SBI_QUOTA_NEED_FLUSH to indicate that there is
    cached dquot metadata changes in quota subsystem, and later checkpoint
    should:
     a) flush dquot metadata into quota file.
     b) flush quota file to storage to keep file usage be consistent.
    
    2. add a global state SBI_QUOTA_NEED_REPAIR to indicate that quota
    operation failed due to -EIO or -ENOSPC, so later,
     a) checkpoint will skip syncing dquot metadata.
     b) CP_QUOTA_NEED_FSCK_FLAG will be set in last cp pack to give a
        hint for fsck repairing.
    
    3. add a global state SBI_QUOTA_SKIP_FLUSH, in checkpoint, if quota
    data updating is very heavy, it may cause hungtask in block_operation().
    To avoid this, if our retry time exceed threshold, let's just skip
    flushing and retry in next checkpoint().
    
    Signed-off-by: Weichao Guo <guoweichao@huawei.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: avoid warnings and set fsck flag]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 875d2e205791..df2123759ac7 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -195,6 +195,33 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 	return err;
 }
 
+static int recover_quota_data(struct inode *inode, struct page *page)
+{
+	struct f2fs_inode *raw = F2FS_INODE(page);
+	struct iattr attr;
+	uid_t i_uid = le32_to_cpu(raw->i_uid);
+	gid_t i_gid = le32_to_cpu(raw->i_gid);
+	int err;
+
+	memset(&attr, 0, sizeof(attr));
+
+	attr.ia_uid = make_kuid(inode->i_sb->s_user_ns, i_uid);
+	attr.ia_gid = make_kgid(inode->i_sb->s_user_ns, i_gid);
+
+	if (!uid_eq(attr.ia_uid, inode->i_uid))
+		attr.ia_valid |= ATTR_UID;
+	if (!gid_eq(attr.ia_gid, inode->i_gid))
+		attr.ia_valid |= ATTR_GID;
+
+	if (!attr.ia_valid)
+		return 0;
+
+	err = dquot_transfer(inode, &attr);
+	if (err)
+		set_sbi_flag(F2FS_I_SB(inode), SBI_QUOTA_NEED_REPAIR);
+	return err;
+}
+
 static void recover_inline_flags(struct inode *inode, struct f2fs_inode *ri)
 {
 	if (ri->i_inline & F2FS_PIN_FILE)
@@ -207,12 +234,18 @@ static void recover_inline_flags(struct inode *inode, struct f2fs_inode *ri)
 		clear_inode_flag(inode, FI_DATA_EXIST);
 }
 
-static void recover_inode(struct inode *inode, struct page *page)
+static int recover_inode(struct inode *inode, struct page *page)
 {
 	struct f2fs_inode *raw = F2FS_INODE(page);
 	char *name;
+	int err;
 
 	inode->i_mode = le16_to_cpu(raw->i_mode);
+
+	err = recover_quota_data(inode, page);
+	if (err)
+		return err;
+
 	i_uid_write(inode, le32_to_cpu(raw->i_uid));
 	i_gid_write(inode, le32_to_cpu(raw->i_gid));
 
@@ -254,6 +287,7 @@ static void recover_inode(struct inode *inode, struct page *page)
 	f2fs_msg(inode->i_sb, KERN_NOTICE,
 		"recover_inode: ino = %x, name = %s, inline = %x",
 			ino_of_node(page), name, raw->i_inline);
+	return 0;
 }
 
 static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
@@ -622,8 +656,11 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 		 * In this case, we can lose the latest inode(x).
 		 * So, call recover_inode for the inode update.
 		 */
-		if (IS_INODE(page))
-			recover_inode(entry->inode, page);
+		if (IS_INODE(page)) {
+			err = recover_inode(entry->inode, page);
+			if (err)
+				break;
+		}
 		if (entry->last_dentry == blkaddr) {
 			err = recover_dentry(entry->inode, page, dir_list);
 			if (err) {

commit 26b5a079197c8cb6725565968b7fd3299bd1877b
Author: Sheng Yong <shengyong1@huawei.com>
Date:   Fri Oct 12 18:49:26 2018 +0800

    f2fs: cleanup dirty pages if recover failed
    
    During recover, we will try to create new dentries for inodes with
    dentry_mark. But if the parent is missing (e.g. killed by fsck),
    recover will break. But those recovered dirty pages are not cleanup.
    This will hit f2fs_bug_on:
    
    [   53.519566] F2FS-fs (loop0): Found nat_bits in checkpoint
    [   53.539354] F2FS-fs (loop0): recover_inode: ino = 5, name = file, inline = 3
    [   53.539402] F2FS-fs (loop0): recover_dentry: ino = 5, name = file, dir = 0, err = -2
    [   53.545760] F2FS-fs (loop0): Cannot recover all fsync data errno=-2
    [   53.546105] F2FS-fs (loop0): access invalid blkaddr:4294967295
    [   53.546171] WARNING: CPU: 1 PID: 1798 at fs/f2fs/checkpoint.c:163 f2fs_is_valid_blkaddr+0x26c/0x320
    [   53.546174] Modules linked in:
    [   53.546183] CPU: 1 PID: 1798 Comm: mount Not tainted 4.19.0-rc2+ #1
    [   53.546186] Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
    [   53.546191] RIP: 0010:f2fs_is_valid_blkaddr+0x26c/0x320
    [   53.546195] Code: 85 bb 00 00 00 48 89 df 88 44 24 07 e8 ad a8 db ff 48 8b 3b 44 89 e1 48 c7 c2 40 03 72 a9 48 c7 c6 e0 01 72 a9 e8 84 3c ff ff <0f> 0b 0f b6 44 24 07 e9 8a 00 00 00 48 8d bf 38 01 00 00 e8 7c a8
    [   53.546201] RSP: 0018:ffff88006c067768 EFLAGS: 00010282
    [   53.546208] RAX: 0000000000000000 RBX: ffff880068844200 RCX: ffffffffa83e1a33
    [   53.546211] RDX: 0000000000000000 RSI: 0000000000000008 RDI: ffff88006d51e590
    [   53.546215] RBP: 0000000000000005 R08: ffffed000daa3cb3 R09: ffffed000daa3cb3
    [   53.546218] R10: 0000000000000001 R11: ffffed000daa3cb2 R12: 00000000ffffffff
    [   53.546221] R13: ffff88006a1f8000 R14: 0000000000000200 R15: 0000000000000009
    [   53.546226] FS:  00007fb2f3646840(0000) GS:ffff88006d500000(0000) knlGS:0000000000000000
    [   53.546229] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   53.546234] CR2: 00007f0fd77f0008 CR3: 00000000687e6002 CR4: 00000000000206e0
    [   53.546237] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [   53.546240] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [   53.546242] Call Trace:
    [   53.546248]  f2fs_submit_page_bio+0x95/0x740
    [   53.546253]  read_node_page+0x161/0x1e0
    [   53.546271]  ? truncate_node+0x650/0x650
    [   53.546283]  ? add_to_page_cache_lru+0x12c/0x170
    [   53.546288]  ? pagecache_get_page+0x262/0x2d0
    [   53.546292]  __get_node_page+0x200/0x660
    [   53.546302]  f2fs_update_inode_page+0x4a/0x160
    [   53.546306]  f2fs_write_inode+0x86/0xb0
    [   53.546317]  __writeback_single_inode+0x49c/0x620
    [   53.546322]  writeback_single_inode+0xe4/0x1e0
    [   53.546326]  sync_inode_metadata+0x93/0xd0
    [   53.546330]  ? sync_inode+0x10/0x10
    [   53.546342]  ? do_raw_spin_unlock+0xed/0x100
    [   53.546347]  f2fs_sync_inode_meta+0xe0/0x130
    [   53.546351]  f2fs_fill_super+0x287d/0x2d10
    [   53.546367]  ? vsnprintf+0x742/0x7a0
    [   53.546372]  ? f2fs_commit_super+0x180/0x180
    [   53.546379]  ? up_write+0x20/0x40
    [   53.546385]  ? set_blocksize+0x5f/0x140
    [   53.546391]  ? f2fs_commit_super+0x180/0x180
    [   53.546402]  mount_bdev+0x181/0x200
    [   53.546406]  mount_fs+0x94/0x180
    [   53.546411]  vfs_kern_mount+0x6c/0x1e0
    [   53.546415]  do_mount+0xe5e/0x1510
    [   53.546420]  ? fs_reclaim_release+0x9/0x30
    [   53.546424]  ? copy_mount_string+0x20/0x20
    [   53.546428]  ? fs_reclaim_acquire+0xd/0x30
    [   53.546435]  ? __might_sleep+0x2c/0xc0
    [   53.546440]  ? ___might_sleep+0x53/0x170
    [   53.546453]  ? __might_fault+0x4c/0x60
    [   53.546468]  ? _copy_from_user+0x95/0xa0
    [   53.546474]  ? memdup_user+0x39/0x60
    [   53.546478]  ksys_mount+0x88/0xb0
    [   53.546482]  __x64_sys_mount+0x5d/0x70
    [   53.546495]  do_syscall_64+0x65/0x130
    [   53.546503]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   53.547639] ---[ end trace b804d1ea2fec893e ]---
    
    So if recover fails, we need to drop all recovered data.
    
    Signed-off-by: Sheng Yong <shengyong1@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 382779f7b2ed..875d2e205791 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -96,8 +96,12 @@ static struct fsync_inode_entry *add_fsync_inode(struct f2fs_sb_info *sbi,
 	return ERR_PTR(err);
 }
 
-static void del_fsync_inode(struct fsync_inode_entry *entry)
+static void del_fsync_inode(struct fsync_inode_entry *entry, int drop)
 {
+	if (drop) {
+		/* inode should not be recovered, drop it */
+		f2fs_inode_synced(entry->inode);
+	}
 	iput(entry->inode);
 	list_del(&entry->list);
 	kmem_cache_free(fsync_entry_slab, entry);
@@ -338,12 +342,12 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 	return err;
 }
 
-static void destroy_fsync_dnodes(struct list_head *head)
+static void destroy_fsync_dnodes(struct list_head *head, int drop)
 {
 	struct fsync_inode_entry *entry, *tmp;
 
 	list_for_each_entry_safe(entry, tmp, head, list)
-		del_fsync_inode(entry);
+		del_fsync_inode(entry, drop);
 }
 
 static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
@@ -580,7 +584,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 }
 
 static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
-						struct list_head *dir_list)
+		struct list_head *tmp_inode_list, struct list_head *dir_list)
 {
 	struct curseg_info *curseg;
 	struct page *page = NULL;
@@ -634,7 +638,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 		}
 
 		if (entry->blkaddr == blkaddr)
-			del_fsync_inode(entry);
+			list_move_tail(&entry->list, tmp_inode_list);
 next:
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
@@ -647,7 +651,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 
 int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 {
-	struct list_head inode_list;
+	struct list_head inode_list, tmp_inode_list;
 	struct list_head dir_list;
 	int err;
 	int ret = 0;
@@ -678,6 +682,7 @@ int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	}
 
 	INIT_LIST_HEAD(&inode_list);
+	INIT_LIST_HEAD(&tmp_inode_list);
 	INIT_LIST_HEAD(&dir_list);
 
 	/* prevent checkpoint */
@@ -696,11 +701,16 @@ int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	need_writecp = true;
 
 	/* step #2: recover data */
-	err = recover_data(sbi, &inode_list, &dir_list);
+	err = recover_data(sbi, &inode_list, &tmp_inode_list, &dir_list);
 	if (!err)
 		f2fs_bug_on(sbi, !list_empty(&inode_list));
+	else {
+		/* restore s_flags to let iput() trash data */
+		sbi->sb->s_flags = s_flags;
+	}
 skip:
-	destroy_fsync_dnodes(&inode_list);
+	destroy_fsync_dnodes(&inode_list, err);
+	destroy_fsync_dnodes(&tmp_inode_list, err);
 
 	/* truncate meta pages to be used by the recovery */
 	truncate_inode_pages_range(META_MAPPING(sbi),
@@ -709,13 +719,13 @@ int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	if (err) {
 		truncate_inode_pages_final(NODE_MAPPING(sbi));
 		truncate_inode_pages_final(META_MAPPING(sbi));
+	} else {
+		clear_sbi_flag(sbi, SBI_POR_DOING);
 	}
-
-	clear_sbi_flag(sbi, SBI_POR_DOING);
 	mutex_unlock(&sbi->cp_mutex);
 
 	/* let's drop all the directory inodes for clean checkpoint */
-	destroy_fsync_dnodes(&dir_list);
+	destroy_fsync_dnodes(&dir_list, err);
 
 	if (need_writecp) {
 		set_sbi_flag(sbi, SBI_IS_RECOVERED);

commit 0c093b590efb5c1ccdc835868dc2ae94bd2e14dc
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sun Oct 7 03:03:38 2018 +0800

    f2fs: fix to recover inode->i_flags of inode block during POR
    
    Testcase to reproduce this bug:
    1. mkfs.f2fs /dev/sdd
    2. mount -t f2fs /dev/sdd /mnt/f2fs
    3. touch /mnt/f2fs/file
    4. sync
    5. chattr +a /mnt/f2fs/file
    6. xfs_io -a /mnt/f2fs/file -c "fsync"
    7. godown /mnt/f2fs
    8. umount /mnt/f2fs
    9. mount -t f2fs /dev/sdd /mnt/f2fs
    10. xfs_io /mnt/f2fs/file
    
    There is no error when opening this file w/o O_APPEND, but actually,
    we expect the correct result should be:
    
    /mnt/f2fs/file: Operation not permitted
    
    The root cause is, in recover_inode(), we recover inode->i_flags more
    than F2FS_I(inode)->i_flags, so fix it.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 93e3b6c46aae..382779f7b2ed 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -234,6 +234,7 @@ static void recover_inode(struct inode *inode, struct page *page)
 
 	F2FS_I(inode)->i_advise = raw->i_advise;
 	F2FS_I(inode)->i_flags = le32_to_cpu(raw->i_flags);
+	f2fs_set_inode_flags(inode);
 	F2FS_I(inode)->i_gc_failures[GC_FAILURE_PIN] =
 				le16_to_cpu(raw->i_gc_failures);
 

commit edc55aaf0d1712b54a3704dd58423c7e495534fe
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 17 17:36:06 2018 -0700

    f2fs: avoid f2fs_bug_on if f2fs_get_meta_page_nofail got EIO
    
    This patch avoids BUG_ON when f2fs_get_meta_page_nofail got EIO during
    xfstests/generic/475.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index fb24a6d734e9..93e3b6c46aae 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -375,6 +375,8 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	}
 
 	sum_page = f2fs_get_sum_page(sbi, segno);
+	if (IS_ERR(sum_page))
+		return PTR_ERR(sum_page);
 	sum_node = (struct f2fs_summary_block *)page_address(sum_page);
 	sum = sum_node->entries[blkoff];
 	f2fs_put_page(sum_page, 1);

commit 4a1728cad6340bfbe17bd17fd158b2165cd99508
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Sep 25 15:36:03 2018 +0800

    f2fs: mark inode dirty explicitly in recover_inode()
    
    Mark inode dirty explicitly in the end of recover_inode() to make sure
    that all recoverable fields can be persisted later.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index f11eefc24818..fb24a6d734e9 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -239,6 +239,8 @@ static void recover_inode(struct inode *inode, struct page *page)
 
 	recover_inline_flags(inode, raw);
 
+	f2fs_mark_inode_dirty_sync(inode, true);
+
 	if (file_enc_name(inode))
 		name = "<encrypted>";
 	else

commit 7de36cf3e4087207f42a88992f8cb615a1bd902e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Sep 25 15:36:00 2018 +0800

    f2fs: fix to recover inode's i_gc_failures during POR
    
    inode.i_gc_failures is used to indicate that skip count of migrating
    on blocks of inode, we should guarantee it can be recovered in sudden
    power-off case.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d8c169c38417..f11eefc24818 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -234,6 +234,8 @@ static void recover_inode(struct inode *inode, struct page *page)
 
 	F2FS_I(inode)->i_advise = raw->i_advise;
 	F2FS_I(inode)->i_flags = le32_to_cpu(raw->i_flags);
+	F2FS_I(inode)->i_gc_failures[GC_FAILURE_PIN] =
+				le16_to_cpu(raw->i_gc_failures);
 
 	recover_inline_flags(inode, raw);
 

commit 19c73a691ccf6fb2f12d4e9cf9830023966cec88
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Sep 25 15:35:59 2018 +0800

    f2fs: fix to recover inode's i_flags during POR
    
    Testcase to reproduce this bug:
    1. mkfs.f2fs /dev/sdd
    2. mount -t f2fs /dev/sdd /mnt/f2fs
    3. touch /mnt/f2fs/file
    4. sync
    5. chattr +A /mnt/f2fs/file
    6. xfs_io -f /mnt/f2fs/file -c "fsync"
    7. godown /mnt/f2fs
    8. umount /mnt/f2fs
    9. mount -t f2fs /dev/sdd /mnt/f2fs
    10. lsattr /mnt/f2fs/file
    
    -----------------N- /mnt/f2fs/file
    
    But actually, we expect the corrct result is:
    
    -------A---------N- /mnt/f2fs/file
    
    The reason is we didn't recover inode.i_flags field during mount,
    fix it.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 2b59e37d9093..d8c169c38417 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -233,6 +233,7 @@ static void recover_inode(struct inode *inode, struct page *page)
 	inode->i_mtime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);
 
 	F2FS_I(inode)->i_advise = raw->i_advise;
+	F2FS_I(inode)->i_flags = le32_to_cpu(raw->i_flags);
 
 	recover_inline_flags(inode, raw);
 

commit f4474aa6e5e901ee4af21f39f1b9115aaaaec503
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Sep 25 15:35:58 2018 +0800

    f2fs: fix to recover inode's project id during POR
    
    Testcase to reproduce this bug:
    1. mkfs.f2fs -O extra_attr -O project_quota /dev/sdd
    2. mount -t f2fs /dev/sdd /mnt/f2fs
    3. touch /mnt/f2fs/file
    4. sync
    5. chattr -p 1 /mnt/f2fs/file
    6. xfs_io -f /mnt/f2fs/file -c "fsync"
    7. godown /mnt/f2fs
    8. umount /mnt/f2fs
    9. mount -t f2fs /dev/sdd /mnt/f2fs
    10. lsattr -p /mnt/f2fs/file
    
        0 -----------------N- /mnt/f2fs/file
    
    But actually, we expect the correct result is:
    
        1 -----------------N- /mnt/f2fs/file
    
    The reason is we didn't recover inode.i_projid field during mount,
    fix it.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 41f2c0fe6d8e..2b59e37d9093 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -211,6 +211,19 @@ static void recover_inode(struct inode *inode, struct page *page)
 	inode->i_mode = le16_to_cpu(raw->i_mode);
 	i_uid_write(inode, le32_to_cpu(raw->i_uid));
 	i_gid_write(inode, le32_to_cpu(raw->i_gid));
+
+	if (raw->i_inline & F2FS_EXTRA_ATTR) {
+		if (f2fs_sb_has_project_quota(F2FS_I_SB(inode)->sb) &&
+			F2FS_FITS_IN_INODE(raw, le16_to_cpu(raw->i_extra_isize),
+								i_projid)) {
+			projid_t i_projid;
+
+			i_projid = (projid_t)le32_to_cpu(raw->i_projid);
+			F2FS_I(inode)->i_projid =
+				make_kprojid(&init_user_ns, i_projid);
+		}
+	}
+
 	f2fs_i_size_write(inode, le64_to_cpu(raw->i_size));
 	inode->i_atime.tv_sec = le64_to_cpu(raw->i_atime);
 	inode->i_ctime.tv_sec = le64_to_cpu(raw->i_ctime);

commit dc4cd1257c86451cec3e8e352cc376348e4f4af4
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Sep 20 17:41:30 2018 +0800

    f2fs: fix to recover inode's uid/gid during POR
    
    Step to reproduce this bug:
    1. logon as root
    2. mount -t f2fs /dev/sdd /mnt;
    3. touch /mnt/file;
    4. chown system /mnt/file; chgrp system /mnt/file;
    5. xfs_io -f /mnt/file -c "fsync";
    6. godown /mnt;
    7. umount /mnt;
    8. mount -t f2fs /dev/sdd /mnt;
    
    After step 8) we will expect file's uid/gid are all system, but during
    recovery, these two fields were not been recovered, fix it.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 56d34193a74b..41f2c0fe6d8e 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -209,6 +209,8 @@ static void recover_inode(struct inode *inode, struct page *page)
 	char *name;
 
 	inode->i_mode = le16_to_cpu(raw->i_mode);
+	i_uid_write(inode, le32_to_cpu(raw->i_uid));
+	i_gid_write(inode, le32_to_cpu(raw->i_gid));
 	f2fs_i_size_write(inode, le64_to_cpu(raw->i_size));
 	inode->i_atime.tv_sec = le64_to_cpu(raw->i_atime);
 	inode->i_ctime.tv_sec = le64_to_cpu(raw->i_ctime);

commit 7c1a000d466235c875a989971cfda344e6bb1166
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Sep 12 09:16:07 2018 +0800

    f2fs: add SPDX license identifiers
    
    Remove the verbose license text from f2fs files and replace them with
    SPDX tags.  This does not change the license of any of the code.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index e3aa6eee7a8b..56d34193a74b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -1,12 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * fs/f2fs/recovery.c
  *
  * Copyright (c) 2012 Samsung Electronics Co., Ltd.
  *             http://www.samsung.com/
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 #include <linux/fs.h>
 #include <linux/f2fs_fs.h>

commit 1378752b9921e60749eaf18ec6c47b33f9001abb
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Aug 22 17:11:05 2018 +0800

    f2fs: fix to flush all dirty inodes recovered in readonly fs
    
    generic/417 reported as blow:
    
    ------------[ cut here ]------------
    kernel BUG at /home/yuchao/git/devf2fs/inode.c:695!
    invalid opcode: 0000 [#1] PREEMPT SMP
    CPU: 1 PID: 21697 Comm: umount Tainted: G        W  O      4.18.0-rc2+ #39
    Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
    EIP: f2fs_evict_inode+0x556/0x580 [f2fs]
    Call Trace:
     ? _raw_spin_unlock+0x2c/0x50
     evict+0xa8/0x170
     dispose_list+0x34/0x40
     evict_inodes+0x118/0x120
     generic_shutdown_super+0x41/0x100
     ? rcu_read_lock_sched_held+0x97/0xa0
     kill_block_super+0x22/0x50
     kill_f2fs_super+0x6f/0x80 [f2fs]
     deactivate_locked_super+0x3d/0x70
     deactivate_super+0x40/0x60
     cleanup_mnt+0x39/0x70
     __cleanup_mnt+0x10/0x20
     task_work_run+0x81/0xa0
     exit_to_usermode_loop+0x59/0xa7
     do_fast_syscall_32+0x1f5/0x22c
     entry_SYSENTER_32+0x53/0x86
    EIP: f2fs_evict_inode+0x556/0x580 [f2fs]
    
    It can simply reproduced with scripts:
    
    Enable quota feature during mkfs.
    
    Testcase1:
    1. mkfs.f2fs /dev/zram0
    2. mount -t f2fs /dev/zram0 /mnt/f2fs
    3. xfs_io -f /mnt/f2fs/file -c "pwrite 0 4k" -c "fsync"
    4. godown /mnt/f2fs
    5. umount /mnt/f2fs
    6. mount -t f2fs -o ro /dev/zram0 /mnt/f2fs
    7. umount /mnt/f2fs
    
    Testcase2:
    1. mkfs.f2fs /dev/zram0
    2. mount -t f2fs /dev/zram0 /mnt/f2fs
    3. touch /mnt/f2fs/file
    4. create process[pid = x] do:
            a) open /mnt/f2fs/file;
            b) unlink /mnt/f2fs/file
    5. godown -f /mnt/f2fs
    6. kill process[pid = x]
    7. umount /mnt/f2fs
    8. mount -t f2fs -o ro /dev/zram0 /mnt/f2fs
    9. umount /mnt/f2fs
    
    The reason is: during recovery, i_{c,m}time of inode will be updated, then
    the inode can be set dirty w/o being tracked in sbi->inode_list[DIRTY_META]
    global list, so later write_checkpoint will not flush such dirty inode into
    node page.
    
    Once umount is called, sync_filesystem() in generic_shutdown_super() will
    skip syncng dirty inodes due to sb_rdonly check, leaving dirty inodes
    there.
    
    To solve this issue, during umount, add remove SB_RDONLY flag in
    sb->s_flags, to make sure sync_filesystem() will not be skipped.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 95511ed11a22..e3aa6eee7a8b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -697,11 +697,15 @@ int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	/* let's drop all the directory inodes for clean checkpoint */
 	destroy_fsync_dnodes(&dir_list);
 
-	if (!err && need_writecp) {
-		struct cp_control cpc = {
-			.reason = CP_RECOVERY,
-		};
-		err = f2fs_write_checkpoint(sbi, &cpc);
+	if (need_writecp) {
+		set_sbi_flag(sbi, SBI_IS_RECOVERED);
+
+		if (!err) {
+			struct cp_control cpc = {
+				.reason = CP_RECOVERY,
+			};
+			err = f2fs_write_checkpoint(sbi, &cpc);
+		}
 	}
 
 	kmem_cache_destroy(fsync_entry_slab);

commit 7fa750a163089cf96866de402314d853a96cb342
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Aug 13 23:38:06 2018 +0200

    f2fs: rework fault injection handling to avoid a warning
    
    When CONFIG_F2FS_FAULT_INJECTION is disabled, we get a warning about an
    unused label:
    
    fs/f2fs/segment.c: In function '__submit_discard_cmd':
    fs/f2fs/segment.c:1059:1: error: label 'submit' defined but not used [-Werror=unused-label]
    
    This could be fixed by adding another #ifdef around it, but the more
    reliable way of doing this seems to be to remove the other #ifdefs
    where that is easily possible.
    
    By defining time_to_inject() as a trivial stub, most of the checks for
    CONFIG_F2FS_FAULT_INJECTION can go away. This also leads to nicer
    formatting of the code.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 64e5a59a270a..95511ed11a22 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -518,10 +518,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 			if (src == NULL_ADDR) {
 				err = f2fs_reserve_new_block(&dn);
-#ifdef CONFIG_F2FS_FAULT_INJECTION
-				while (err)
+				while (err &&
+				       IS_ENABLED(CONFIG_F2FS_FAULT_INJECTION))
 					err = f2fs_reserve_new_block(&dn);
-#endif
 				/* We should not get -ENOSPC */
 				f2fs_bug_on(sbi, err);
 				if (err)

commit e6b0b159cf2f62de69561f585fe8515d3d9189d4
Author: Yunlei He <heyunlei@huawei.com>
Date:   Thu Jul 19 14:57:14 2018 +0800

    f2fs: fix wrong kernel message when recover fsync data on ro fs
    
    This patch fix wrong message info for recover fsync data
    on readonly fs.
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 956f34c87082..64e5a59a270a 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -639,7 +639,8 @@ int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 #endif
 
 	if (s_flags & SB_RDONLY) {
-		f2fs_msg(sbi->sb, KERN_INFO, "orphan cleanup on readonly fs");
+		f2fs_msg(sbi->sb, KERN_INFO,
+				"recover fsync data on readonly fs");
 		sbi->sb->s_flags &= ~SB_RDONLY;
 	}
 

commit 7735730d39d75e70476c1b01435b9b1f41637f0e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Jul 17 00:02:17 2018 +0800

    f2fs: fix to propagate error from __get_meta_page()
    
    If caller of __get_meta_page() can handle error, let's propagate error
    from __get_meta_page().
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 0d927ae26c48..956f34c87082 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -256,6 +256,10 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 			return 0;
 
 		page = f2fs_get_tmp_page(sbi, blkaddr);
+		if (IS_ERR(page)) {
+			err = PTR_ERR(page);
+			break;
+		}
 
 		if (!is_recoverable_dnode(page))
 			break;
@@ -471,7 +475,10 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 	f2fs_wait_on_page_writeback(dn.node_page, NODE, true);
 
-	f2fs_get_node_info(sbi, dn.nid, &ni);
+	err = f2fs_get_node_info(sbi, dn.nid, &ni);
+	if (err)
+		goto err;
+
 	f2fs_bug_on(sbi, ni.ino != ino_of_node(page));
 	f2fs_bug_on(sbi, ofs_of_node(dn.node_page) != ofs_of_node(page));
 
@@ -574,6 +581,10 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 		f2fs_ra_meta_pages_cond(sbi, blkaddr);
 
 		page = f2fs_get_tmp_page(sbi, blkaddr);
+		if (IS_ERR(page)) {
+			err = PTR_ERR(page);
+			break;
+		}
 
 		if (!is_recoverable_dnode(page)) {
 			f2fs_put_page(page, 1);

commit 82902c06bd17dbf6e8184299842ca5c68880970f
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Jul 5 19:37:00 2018 +0800

    f2fs: fix to detect looped node chain correctly
    
    Below dmesg was printed when testing generic/388 of fstest:
    
    F2FS-fs (zram1): find_fsync_dnodes: detect looped node chain, blkaddr:526615, next:526616
    F2FS-fs (zram1): Cannot recover all fsync data errno=-22
    F2FS-fs (zram1): Mounted with checkpoint version = 22300d0e
    F2FS-fs (zram1): find_fsync_dnodes: detect looped node chain, blkaddr:526615, next:526616
    F2FS-fs (zram1): Cannot recover all fsync data errno=-22
    
    The reason is that we initialize free_blocks with free blocks of
    filesystem, so if filesystem is full, free_blocks can be zero,
    below condition will be true, so that, it will fail recovery.
    
    if (++loop_cnt >= free_blocks ||
            blkaddr == next_blkaddr_of_node(page))
    
    To fix this issue, initialize free_blocks with correct value which
    includes over-privision blocks.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 3051a5e5dfc7..0d927ae26c48 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -241,8 +241,8 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 	struct page *page = NULL;
 	block_t blkaddr;
 	unsigned int loop_cnt = 0;
-	unsigned int free_blocks = sbi->user_block_count -
-					valid_user_blocks(sbi);
+	unsigned int free_blocks = MAIN_SEGS(sbi) * sbi->blocks_per_seg -
+						valid_user_blocks(sbi);
 	int err = 0;
 
 	/* get node pages in the current segment */

commit e1da7872f6eda977bd812346bf588c35e4495a1e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Jun 5 17:44:11 2018 +0800

    f2fs: introduce and spread verify_blkaddr
    
    This patch introduces verify_blkaddr to check meta/data block address
    with valid range to detect bug earlier.
    
    In addition, once we encounter an invalid blkaddr, notice user to run
    fsck to fix, and let the kernel panic.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 38f25f0b193a..3051a5e5dfc7 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -252,7 +252,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (!f2fs_is_valid_meta_blkaddr(sbi, blkaddr, META_POR))
+		if (!f2fs_is_valid_blkaddr(sbi, blkaddr, META_POR))
 			return 0;
 
 		page = f2fs_get_tmp_page(sbi, blkaddr);
@@ -507,7 +507,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		}
 
 		/* dest is valid block, try to recover from src to dest */
-		if (f2fs_is_valid_meta_blkaddr(sbi, dest, META_POR)) {
+		if (f2fs_is_valid_blkaddr(sbi, dest, META_POR)) {
 
 			if (src == NULL_ADDR) {
 				err = f2fs_reserve_new_block(&dn);
@@ -568,7 +568,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (!f2fs_is_valid_meta_blkaddr(sbi, blkaddr, META_POR))
+		if (!f2fs_is_valid_blkaddr(sbi, blkaddr, META_POR))
 			break;
 
 		f2fs_ra_meta_pages_cond(sbi, blkaddr);

commit 4d57b86dd86404fd8bb4f87d277d5a86a7fe537e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed May 30 00:20:41 2018 +0800

    f2fs: clean up symbol namespace
    
    As Ted reported:
    
    "Hi, I was looking at f2fs's sources recently, and I noticed that there
    is a very large number of non-static symbols which don't have a f2fs
    prefix.  There's well over a hundred (see attached below).
    
    As one example, in fs/f2fs/dir.c there is:
    
    unsigned char get_de_type(struct f2fs_dir_entry *de)
    
    This function is clearly only useful for f2fs, but it has a generic
    name.  This means that if any other file system tries to have the same
    symbol name, there will be a symbol conflict and the kernel would not
    successfully build.  It also means that when someone is looking f2fs
    sources, it's not at all obvious whether a function such as
    read_data_page(), invalidate_blocks(), is a generic kernel function
    found in the fs, mm, or block layers, or a f2fs specific function.
    
    You might want to fix this at some point.  Hopefully Kent's bcachefs
    isn't similarly using genericly named functions, since that might
    cause conflicts with f2fs's functions --- but just as this would be a
    problem that we would rightly insist that Kent fix, this is something
    that we should have rightly insisted that f2fs should have fixed
    before it was integrated into the mainline kernel.
    
    acquire_orphan_inode
    add_ino_entry
    add_orphan_inode
    allocate_data_block
    allocate_new_segments
    alloc_nid
    alloc_nid_done
    alloc_nid_failed
    available_free_memory
    ...."
    
    This patch adds "f2fs_" prefix for all non-static symbols in order to:
    a) avoid conflict with other kernel generic symbols;
    b) to indicate the function is f2fs specific one instead of generic
    one;
    
    Reported-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index bb519ba2558e..38f25f0b193a 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -47,7 +47,7 @@
 
 static struct kmem_cache *fsync_entry_slab;
 
-bool space_for_roll_forward(struct f2fs_sb_info *sbi)
+bool f2fs_space_for_roll_forward(struct f2fs_sb_info *sbi)
 {
 	s64 nalloc = percpu_counter_sum_positive(&sbi->alloc_valid_block_count);
 
@@ -162,7 +162,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 			goto out_put;
 		}
 
-		err = acquire_orphan_inode(F2FS_I_SB(inode));
+		err = f2fs_acquire_orphan_inode(F2FS_I_SB(inode));
 		if (err) {
 			iput(einode);
 			goto out_put;
@@ -173,7 +173,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 	} else if (IS_ERR(page)) {
 		err = PTR_ERR(page);
 	} else {
-		err = __f2fs_do_add_link(dir, &fname, inode,
+		err = f2fs_add_dentry(dir, &fname, inode,
 					inode->i_ino, inode->i_mode);
 	}
 	if (err == -ENOMEM)
@@ -252,10 +252,10 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (!is_valid_meta_blkaddr(sbi, blkaddr, META_POR))
+		if (!f2fs_is_valid_meta_blkaddr(sbi, blkaddr, META_POR))
 			return 0;
 
-		page = get_tmp_page(sbi, blkaddr);
+		page = f2fs_get_tmp_page(sbi, blkaddr);
 
 		if (!is_recoverable_dnode(page))
 			break;
@@ -269,7 +269,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 
 			if (!check_only &&
 					IS_INODE(page) && is_dent_dnode(page)) {
-				err = recover_inode_page(sbi, page);
+				err = f2fs_recover_inode_page(sbi, page);
 				if (err)
 					break;
 				quota_inode = true;
@@ -310,7 +310,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 		blkaddr = next_blkaddr_of_node(page);
 		f2fs_put_page(page, 1);
 
-		ra_meta_pages_cond(sbi, blkaddr);
+		f2fs_ra_meta_pages_cond(sbi, blkaddr);
 	}
 	f2fs_put_page(page, 1);
 	return err;
@@ -353,7 +353,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 		}
 	}
 
-	sum_page = get_sum_page(sbi, segno);
+	sum_page = f2fs_get_sum_page(sbi, segno);
 	sum_node = (struct f2fs_summary_block *)page_address(sum_page);
 	sum = sum_node->entries[blkoff];
 	f2fs_put_page(sum_page, 1);
@@ -373,7 +373,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	}
 
 	/* Get the node page */
-	node_page = get_node_page(sbi, nid);
+	node_page = f2fs_get_node_page(sbi, nid);
 	if (IS_ERR(node_page))
 		return PTR_ERR(node_page);
 
@@ -398,7 +398,8 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 		inode = dn->inode;
 	}
 
-	bidx = start_bidx_of_node(offset, inode) + le16_to_cpu(sum.ofs_in_node);
+	bidx = f2fs_start_bidx_of_node(offset, inode) +
+				le16_to_cpu(sum.ofs_in_node);
 
 	/*
 	 * if inode page is locked, unlock temporarily, but its reference
@@ -408,11 +409,11 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 		unlock_page(dn->inode_page);
 
 	set_new_dnode(&tdn, inode, NULL, NULL, 0);
-	if (get_dnode_of_data(&tdn, bidx, LOOKUP_NODE))
+	if (f2fs_get_dnode_of_data(&tdn, bidx, LOOKUP_NODE))
 		goto out;
 
 	if (tdn.data_blkaddr == blkaddr)
-		truncate_data_blocks_range(&tdn, 1);
+		f2fs_truncate_data_blocks_range(&tdn, 1);
 
 	f2fs_put_dnode(&tdn);
 out:
@@ -425,7 +426,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 truncate_out:
 	if (datablock_addr(tdn.inode, tdn.node_page,
 					tdn.ofs_in_node) == blkaddr)
-		truncate_data_blocks_range(&tdn, 1);
+		f2fs_truncate_data_blocks_range(&tdn, 1);
 	if (dn->inode->i_ino == nid && !dn->inode_page_locked)
 		unlock_page(dn->inode_page);
 	return 0;
@@ -441,25 +442,25 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 	/* step 1: recover xattr */
 	if (IS_INODE(page)) {
-		recover_inline_xattr(inode, page);
+		f2fs_recover_inline_xattr(inode, page);
 	} else if (f2fs_has_xattr_block(ofs_of_node(page))) {
-		err = recover_xattr_data(inode, page);
+		err = f2fs_recover_xattr_data(inode, page);
 		if (!err)
 			recovered++;
 		goto out;
 	}
 
 	/* step 2: recover inline data */
-	if (recover_inline_data(inode, page))
+	if (f2fs_recover_inline_data(inode, page))
 		goto out;
 
 	/* step 3: recover data indices */
-	start = start_bidx_of_node(ofs_of_node(page), inode);
+	start = f2fs_start_bidx_of_node(ofs_of_node(page), inode);
 	end = start + ADDRS_PER_PAGE(page, inode);
 
 	set_new_dnode(&dn, inode, NULL, NULL, 0);
 retry_dn:
-	err = get_dnode_of_data(&dn, start, ALLOC_NODE);
+	err = f2fs_get_dnode_of_data(&dn, start, ALLOC_NODE);
 	if (err) {
 		if (err == -ENOMEM) {
 			congestion_wait(BLK_RW_ASYNC, HZ/50);
@@ -470,7 +471,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 	f2fs_wait_on_page_writeback(dn.node_page, NODE, true);
 
-	get_node_info(sbi, dn.nid, &ni);
+	f2fs_get_node_info(sbi, dn.nid, &ni);
 	f2fs_bug_on(sbi, ni.ino != ino_of_node(page));
 	f2fs_bug_on(sbi, ofs_of_node(dn.node_page) != ofs_of_node(page));
 
@@ -486,7 +487,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 		/* dest is invalid, just invalidate src block */
 		if (dest == NULL_ADDR) {
-			truncate_data_blocks_range(&dn, 1);
+			f2fs_truncate_data_blocks_range(&dn, 1);
 			continue;
 		}
 
@@ -500,19 +501,19 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		 * and then reserve one new block in dnode page.
 		 */
 		if (dest == NEW_ADDR) {
-			truncate_data_blocks_range(&dn, 1);
-			reserve_new_block(&dn);
+			f2fs_truncate_data_blocks_range(&dn, 1);
+			f2fs_reserve_new_block(&dn);
 			continue;
 		}
 
 		/* dest is valid block, try to recover from src to dest */
-		if (is_valid_meta_blkaddr(sbi, dest, META_POR)) {
+		if (f2fs_is_valid_meta_blkaddr(sbi, dest, META_POR)) {
 
 			if (src == NULL_ADDR) {
-				err = reserve_new_block(&dn);
+				err = f2fs_reserve_new_block(&dn);
 #ifdef CONFIG_F2FS_FAULT_INJECTION
 				while (err)
-					err = reserve_new_block(&dn);
+					err = f2fs_reserve_new_block(&dn);
 #endif
 				/* We should not get -ENOSPC */
 				f2fs_bug_on(sbi, err);
@@ -567,12 +568,12 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (!is_valid_meta_blkaddr(sbi, blkaddr, META_POR))
+		if (!f2fs_is_valid_meta_blkaddr(sbi, blkaddr, META_POR))
 			break;
 
-		ra_meta_pages_cond(sbi, blkaddr);
+		f2fs_ra_meta_pages_cond(sbi, blkaddr);
 
-		page = get_tmp_page(sbi, blkaddr);
+		page = f2fs_get_tmp_page(sbi, blkaddr);
 
 		if (!is_recoverable_dnode(page)) {
 			f2fs_put_page(page, 1);
@@ -610,11 +611,11 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 		f2fs_put_page(page, 1);
 	}
 	if (!err)
-		allocate_new_segments(sbi);
+		f2fs_allocate_new_segments(sbi);
 	return err;
 }
 
-int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
+int f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 {
 	struct list_head inode_list;
 	struct list_head dir_list;
@@ -689,7 +690,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 		struct cp_control cpc = {
 			.reason = CP_RECOVERY,
 		};
-		err = write_checkpoint(sbi, &cpc);
+		err = f2fs_write_checkpoint(sbi, &cpc);
 	}
 
 	kmem_cache_destroy(fsync_entry_slab);

commit 7b525dd01365c6764018e374d391c92466be1b7a
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed May 23 22:25:08 2018 +0800

    f2fs: clean up with is_valid_blkaddr()
    
    - rename is_valid_blkaddr() to is_valid_meta_blkaddr() for readability.
    - introduce is_valid_blkaddr() for cleanup.
    
    No logic change in this patch.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 709dd4daaf29..bb519ba2558e 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -252,7 +252,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (!is_valid_blkaddr(sbi, blkaddr, META_POR))
+		if (!is_valid_meta_blkaddr(sbi, blkaddr, META_POR))
 			return 0;
 
 		page = get_tmp_page(sbi, blkaddr);
@@ -506,7 +506,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		}
 
 		/* dest is valid block, try to recover from src to dest */
-		if (is_valid_blkaddr(sbi, dest, META_POR)) {
+		if (is_valid_meta_blkaddr(sbi, dest, META_POR)) {
 
 			if (src == NULL_ADDR) {
 				err = reserve_new_block(&dn);
@@ -567,7 +567,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (!is_valid_blkaddr(sbi, blkaddr, META_POR))
+		if (!is_valid_meta_blkaddr(sbi, blkaddr, META_POR))
 			break;
 
 		ra_meta_pages_cond(sbi, blkaddr);

commit eff15c2aec6c93681dffb183779db2b08df09bc3
Author: Sheng Yong <shengyong1@huawei.com>
Date:   Mon Apr 23 10:29:13 2018 +0800

    f2fs: do not check F2FS_INLINE_DOTS in recover
    
    Only dir may have F2FS_INLINE_DOTS flag, so there is no need to check
    the flag in recover flow.
    
    Signed-off-by: Sheng Yong <shengyong1@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 1b23d3febe4c..709dd4daaf29 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -204,8 +204,6 @@ static void recover_inline_flags(struct inode *inode, struct f2fs_inode *ri)
 		set_inode_flag(inode, FI_DATA_EXIST);
 	else
 		clear_inode_flag(inode, FI_DATA_EXIST);
-	if (!(ri->i_inline & F2FS_INLINE_DOTS))
-		clear_inode_flag(inode, FI_INLINE_DOTS);
 }
 
 static void recover_inode(struct inode *inode, struct page *page)

commit fb0e72c8b94903be3a7e742ab0a4b53b89e7ee35
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sat Feb 3 17:44:39 2018 +0800

    f2fs: fix to handle looped node chain during recovery
    
    There is no checksum in node block now, so bit-transition from hardware
    can make node_footer.next_blkaddr being corrupted w/o any detection,
    result in node chain becoming looped one.
    
    For this condition, during recovery, in order to avoid running into dead
    loop, let's detect it and just skip out.
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index c5e5c45130b5..1b23d3febe4c 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -242,6 +242,9 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 	struct curseg_info *curseg;
 	struct page *page = NULL;
 	block_t blkaddr;
+	unsigned int loop_cnt = 0;
+	unsigned int free_blocks = sbi->user_block_count -
+					valid_user_blocks(sbi);
 	int err = 0;
 
 	/* get node pages in the current segment */
@@ -294,6 +297,17 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 		if (IS_INODE(page) && is_dent_dnode(page))
 			entry->last_dentry = blkaddr;
 next:
+		/* sanity check in order to detect looped node chain */
+		if (++loop_cnt >= free_blocks ||
+			blkaddr == next_blkaddr_of_node(page)) {
+			f2fs_msg(sbi->sb, KERN_NOTICE,
+				"%s: detect looped node chain, "
+				"blkaddr:%u, next:%u",
+				__func__, blkaddr, next_blkaddr_of_node(page));
+			err = -EINVAL;
+			break;
+		}
+
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
 		f2fs_put_page(page, 1);

commit bdbc90fa55af632f8a883a3d93c54a08708ed80a
Author: Yunlong Song <yunlong.song@huawei.com>
Date:   Wed Feb 28 20:31:52 2018 +0800

    f2fs: don't put dentry page in pagecache into highmem
    
    Previous dentry page uses highmem, which will cause panic in platforms
    using highmem (such as arm), since the address space of dentry pages
    from highmem directly goes into the decryption path via the function
    fscrypt_fname_disk_to_usr. But sg_init_one assumes the address is not
    from highmem, and then cause panic since it doesn't call kmap_high but
    kunmap_high is triggered at the end. To fix this problem in a simple
    way, this patch avoids to put dentry page in pagecache into highmem.
    
    Signed-off-by: Yunlong Song <yunlong.song@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: fix coding style]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 337f3363f48f..c5e5c45130b5 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -144,7 +144,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 retry:
 	de = __f2fs_find_entry(dir, &fname, &page);
 	if (de && inode->i_ino == le32_to_cpu(de->ino))
-		goto out_unmap_put;
+		goto out_put;
 
 	if (de) {
 		einode = f2fs_iget_retry(inode->i_sb, le32_to_cpu(de->ino));
@@ -153,19 +153,19 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 			err = PTR_ERR(einode);
 			if (err == -ENOENT)
 				err = -EEXIST;
-			goto out_unmap_put;
+			goto out_put;
 		}
 
 		err = dquot_initialize(einode);
 		if (err) {
 			iput(einode);
-			goto out_unmap_put;
+			goto out_put;
 		}
 
 		err = acquire_orphan_inode(F2FS_I_SB(inode));
 		if (err) {
 			iput(einode);
-			goto out_unmap_put;
+			goto out_put;
 		}
 		f2fs_delete_entry(de, page, dir, einode);
 		iput(einode);
@@ -180,8 +180,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 		goto retry;
 	goto out;
 
-out_unmap_put:
-	f2fs_dentry_kunmap(dir, page);
+out_put:
 	f2fs_put_page(page, 0);
 out:
 	if (file_enc_name(inode))

commit 37a086f015245a7d81e9e577389872b98aa0719a
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jan 19 20:01:40 2018 -0800

    f2fs: recover some i_inline flags
    
    This fixes lost i_inline flags during roll-forward.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index cbeef73bc4dd..337f3363f48f 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -195,6 +195,20 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 	return err;
 }
 
+static void recover_inline_flags(struct inode *inode, struct f2fs_inode *ri)
+{
+	if (ri->i_inline & F2FS_PIN_FILE)
+		set_inode_flag(inode, FI_PIN_FILE);
+	else
+		clear_inode_flag(inode, FI_PIN_FILE);
+	if (ri->i_inline & F2FS_DATA_EXIST)
+		set_inode_flag(inode, FI_DATA_EXIST);
+	else
+		clear_inode_flag(inode, FI_DATA_EXIST);
+	if (!(ri->i_inline & F2FS_INLINE_DOTS))
+		clear_inode_flag(inode, FI_INLINE_DOTS);
+}
+
 static void recover_inode(struct inode *inode, struct page *page)
 {
 	struct f2fs_inode *raw = F2FS_INODE(page);
@@ -211,13 +225,16 @@ static void recover_inode(struct inode *inode, struct page *page)
 
 	F2FS_I(inode)->i_advise = raw->i_advise;
 
+	recover_inline_flags(inode, raw);
+
 	if (file_enc_name(inode))
 		name = "<encrypted>";
 	else
 		name = F2FS_INODE(page)->i_name;
 
-	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode: ino = %x, name = %s",
-			ino_of_node(page), name);
+	f2fs_msg(inode->i_sb, KERN_NOTICE,
+		"recover_inode: ino = %x, name = %s, inline = %x",
+			ino_of_node(page), name, raw->i_inline);
 }
 
 static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,

commit e17d488bce9ef4fe3b18d1548ea79b65f836b497
Author: Sheng Yong <shengyong1@huawei.com>
Date:   Wed Nov 22 18:23:40 2017 +0800

    f2fs: remove unused parameter
    
    Commit d260081ccf37 ("f2fs: change recovery policy of xattr node block")
    removes the use of blkaddr, which is no longer used. So remove the
    parameter.
    
    Signed-off-by: Sheng Yong <shengyong1@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b3a14b0429f2..cbeef73bc4dd 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -404,7 +404,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 }
 
 static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
-					struct page *page, block_t blkaddr)
+					struct page *page)
 {
 	struct dnode_of_data dn;
 	struct node_info ni;
@@ -415,7 +415,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	if (IS_INODE(page)) {
 		recover_inline_xattr(inode, page);
 	} else if (f2fs_has_xattr_block(ofs_of_node(page))) {
-		err = recover_xattr_data(inode, page, blkaddr);
+		err = recover_xattr_data(inode, page);
 		if (!err)
 			recovered++;
 		goto out;
@@ -568,7 +568,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 				break;
 			}
 		}
-		err = do_recover_data(sbi, entry->inode, page, blkaddr);
+		err = do_recover_data(sbi, entry->inode, page);
 		if (err) {
 			f2fs_put_page(page, 1);
 			break;

commit 1751e8a6cb935e555fcdbcb9ab4f0446e322ca3e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 27 13:05:09 2017 -0800

    Rename superblock flags (MS_xyz -> SB_xyz)
    
    This is a pure automated search-and-replace of the internal kernel
    superblock flags.
    
    The s_flags are now called SB_*, with the names and the values for the
    moment mirroring the MS_* flags that they're equivalent to.
    
    Note how the MS_xyz flags are the ones passed to the mount system call,
    while the SB_xyz flags are what we then use in sb->s_flags.
    
    The script to do this was:
    
        # places to look in; re security/*: it generally should *not* be
        # touched (that stuff parses mount(2) arguments directly), but
        # there are two places where we really deal with superblock flags.
        FILES="drivers/mtd drivers/staging/lustre fs ipc mm \
                include/linux/fs.h include/uapi/linux/bfs_fs.h \
                security/apparmor/apparmorfs.c security/apparmor/include/lib.h"
        # the list of MS_... constants
        SYMS="RDONLY NOSUID NODEV NOEXEC SYNCHRONOUS REMOUNT MANDLOCK \
              DIRSYNC NOATIME NODIRATIME BIND MOVE REC VERBOSE SILENT \
              POSIXACL UNBINDABLE PRIVATE SLAVE SHARED RELATIME KERNMOUNT \
              I_VERSION STRICTATIME LAZYTIME SUBMOUNT NOREMOTELOCK NOSEC BORN \
              ACTIVE NOUSER"
    
        SED_PROG=
        for i in $SYMS; do SED_PROG="$SED_PROG -e s/MS_$i/SB_$i/g"; done
    
        # we want files that contain at least one of MS_...,
        # with fs/namespace.c and fs/pnode.c excluded.
        L=$(for i in $SYMS; do git grep -w -l MS_$i $FILES; done| sort|uniq|grep -v '^fs/namespace.c'|grep -v '^fs/pnode.c')
    
        for f in $L; do sed -i $f $SED_PROG; done
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 92c57ace1939..b3a14b0429f2 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -598,16 +598,16 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	int quota_enabled;
 #endif
 
-	if (s_flags & MS_RDONLY) {
+	if (s_flags & SB_RDONLY) {
 		f2fs_msg(sbi->sb, KERN_INFO, "orphan cleanup on readonly fs");
-		sbi->sb->s_flags &= ~MS_RDONLY;
+		sbi->sb->s_flags &= ~SB_RDONLY;
 	}
 
 #ifdef CONFIG_QUOTA
 	/* Needed for iput() to work correctly and not trash data */
-	sbi->sb->s_flags |= MS_ACTIVE;
+	sbi->sb->s_flags |= SB_ACTIVE;
 	/* Turn on quotas so that they are updated correctly */
-	quota_enabled = f2fs_enable_quota_files(sbi, s_flags & MS_RDONLY);
+	quota_enabled = f2fs_enable_quota_files(sbi, s_flags & SB_RDONLY);
 #endif
 
 	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
@@ -671,7 +671,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	if (quota_enabled)
 		f2fs_quota_off_umount(sbi->sb);
 #endif
-	sbi->sb->s_flags = s_flags; /* Restore MS_RDONLY status */
+	sbi->sb->s_flags = s_flags; /* Restore SB_RDONLY status */
 
 	return ret ? ret: err;
 }

commit ea6767337f86312ebe473585899a159bf50ef1b7
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Oct 6 09:14:28 2017 -0700

    f2fs: support quota sys files
    
    This patch supports hidden quota files in the system, which will be used for
    Android. It requires up-to-date f2fs-tools later than v1.9.0.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 9626758bc762..92c57ace1939 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -594,6 +594,9 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	int ret = 0;
 	unsigned long s_flags = sbi->sb->s_flags;
 	bool need_writecp = false;
+#ifdef CONFIG_QUOTA
+	int quota_enabled;
+#endif
 
 	if (s_flags & MS_RDONLY) {
 		f2fs_msg(sbi->sb, KERN_INFO, "orphan cleanup on readonly fs");
@@ -604,7 +607,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	/* Needed for iput() to work correctly and not trash data */
 	sbi->sb->s_flags |= MS_ACTIVE;
 	/* Turn on quotas so that they are updated correctly */
-	f2fs_enable_quota_files(sbi);
+	quota_enabled = f2fs_enable_quota_files(sbi, s_flags & MS_RDONLY);
 #endif
 
 	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
@@ -665,7 +668,8 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 out:
 #ifdef CONFIG_QUOTA
 	/* Turn quotas off */
-	f2fs_quota_off_umount(sbi->sb);
+	if (quota_enabled)
+		f2fs_quota_off_umount(sbi->sb);
 #endif
 	sbi->sb->s_flags = s_flags; /* Restore MS_RDONLY status */
 

commit 125c9fb1ccb53eb2ea9380df40f3c743f3fb2fed
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Sat Aug 12 21:33:23 2017 -0700

    f2fs: check hot_data for roll-forward recovery
    
    We need to check HOT_DATA to truncate any previous data block when doing
    roll-forward recovery.
    
    Cc: <stable@vger.kernel.org>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index f707d810c87d..9626758bc762 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -317,7 +317,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 		return 0;
 
 	/* Get the previous summary */
-	for (i = CURSEG_WARM_DATA; i <= CURSEG_COLD_DATA; i++) {
+	for (i = CURSEG_HOT_DATA; i <= CURSEG_COLD_DATA; i++) {
 		struct curseg_info *curseg = CURSEG_I(sbi, i);
 		if (curseg->segno == segno) {
 			sum = curseg->sum_blk->entries[blkoff];

commit afd2b4da40b3b567ef8d8e6881479345a2312a03
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Aug 10 17:35:04 2017 -0700

    f2fs: let fill_super handle roll-forward errors
    
    If we set CP_ERROR_FLAG in roll-forward error, f2fs is no longer to proceed
    any IOs due to f2fs_cp_error(). But, for example, if some stale data is involved
    on roll-forward process, we're able to get -ENOENT, getting fs stuck.
    If we get any error, let fill_super set SBI_NEED_FSCK and try to recover back
    to stable point.
    
    Cc: <stable@vger.kernel.org>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index a3d02613934a..f707d810c87d 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -649,8 +649,6 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	}
 
 	clear_sbi_flag(sbi, SBI_POR_DOING);
-	if (err)
-		set_ckpt_flags(sbi, CP_ERROR_FLAG);
 	mutex_unlock(&sbi->cp_mutex);
 
 	/* let's drop all the directory inodes for clean checkpoint */

commit 4b2414d04e99120ce852ba15a1926c9c3a77d9ce
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Aug 8 10:54:31 2017 +0800

    f2fs: support journalled quota
    
    This patch supports to enable f2fs to accept quota information through
    mount option:
    - {usr,grp,prj}jquota=<quota file path>
    - jqfmt=<quota type>
    
    Then, in ->mount flow, we can recover quota file during log replaying,
    by this, journelled quota can be supported.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: Fix wrong return values.]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 2d9b8182691f..a3d02613934a 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -69,20 +69,34 @@ static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
 }
 
 static struct fsync_inode_entry *add_fsync_inode(struct f2fs_sb_info *sbi,
-					struct list_head *head, nid_t ino)
+			struct list_head *head, nid_t ino, bool quota_inode)
 {
 	struct inode *inode;
 	struct fsync_inode_entry *entry;
+	int err;
 
 	inode = f2fs_iget_retry(sbi->sb, ino);
 	if (IS_ERR(inode))
 		return ERR_CAST(inode);
 
+	err = dquot_initialize(inode);
+	if (err)
+		goto err_out;
+
+	if (quota_inode) {
+		err = dquot_alloc_inode(inode);
+		if (err)
+			goto err_out;
+	}
+
 	entry = f2fs_kmem_cache_alloc(fsync_entry_slab, GFP_F2FS_ZERO);
 	entry->inode = inode;
 	list_add_tail(&entry->list, head);
 
 	return entry;
+err_out:
+	iput(inode);
+	return ERR_PTR(err);
 }
 
 static void del_fsync_inode(struct fsync_inode_entry *entry)
@@ -107,7 +121,8 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 
 	entry = get_fsync_inode(dir_list, pino);
 	if (!entry) {
-		entry = add_fsync_inode(F2FS_I_SB(inode), dir_list, pino);
+		entry = add_fsync_inode(F2FS_I_SB(inode), dir_list,
+							pino, false);
 		if (IS_ERR(entry)) {
 			dir = ERR_CAST(entry);
 			err = PTR_ERR(entry);
@@ -140,6 +155,13 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 				err = -EEXIST;
 			goto out_unmap_put;
 		}
+
+		err = dquot_initialize(einode);
+		if (err) {
+			iput(einode);
+			goto out_unmap_put;
+		}
+
 		err = acquire_orphan_inode(F2FS_I_SB(inode));
 		if (err) {
 			iput(einode);
@@ -226,18 +248,22 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
 
 		entry = get_fsync_inode(head, ino_of_node(page));
 		if (!entry) {
+			bool quota_inode = false;
+
 			if (!check_only &&
 					IS_INODE(page) && is_dent_dnode(page)) {
 				err = recover_inode_page(sbi, page);
 				if (err)
 					break;
+				quota_inode = true;
 			}
 
 			/*
 			 * CP | dnode(F) | inode(DF)
 			 * For this case, we should not give up now.
 			 */
-			entry = add_fsync_inode(sbi, head, ino_of_node(page));
+			entry = add_fsync_inode(sbi, head, ino_of_node(page),
+								quota_inode);
 			if (IS_ERR(entry)) {
 				err = PTR_ERR(entry);
 				if (err == -ENOENT) {
@@ -328,10 +354,18 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	f2fs_put_page(node_page, 1);
 
 	if (ino != dn->inode->i_ino) {
+		int ret;
+
 		/* Deallocate previous index in the node page */
 		inode = f2fs_iget_retry(sbi->sb, ino);
 		if (IS_ERR(inode))
 			return PTR_ERR(inode);
+
+		ret = dquot_initialize(inode);
+		if (ret) {
+			iput(inode);
+			return ret;
+		}
 	} else {
 		inode = dn->inode;
 	}
@@ -558,12 +592,27 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	struct list_head dir_list;
 	int err;
 	int ret = 0;
+	unsigned long s_flags = sbi->sb->s_flags;
 	bool need_writecp = false;
 
+	if (s_flags & MS_RDONLY) {
+		f2fs_msg(sbi->sb, KERN_INFO, "orphan cleanup on readonly fs");
+		sbi->sb->s_flags &= ~MS_RDONLY;
+	}
+
+#ifdef CONFIG_QUOTA
+	/* Needed for iput() to work correctly and not trash data */
+	sbi->sb->s_flags |= MS_ACTIVE;
+	/* Turn on quotas so that they are updated correctly */
+	f2fs_enable_quota_files(sbi);
+#endif
+
 	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
 			sizeof(struct fsync_inode_entry));
-	if (!fsync_entry_slab)
-		return -ENOMEM;
+	if (!fsync_entry_slab) {
+		err = -ENOMEM;
+		goto out;
+	}
 
 	INIT_LIST_HEAD(&inode_list);
 	INIT_LIST_HEAD(&dir_list);
@@ -574,11 +623,11 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	/* step #1: find fsynced inode numbers */
 	err = find_fsync_dnodes(sbi, &inode_list, check_only);
 	if (err || list_empty(&inode_list))
-		goto out;
+		goto skip;
 
 	if (check_only) {
 		ret = 1;
-		goto out;
+		goto skip;
 	}
 
 	need_writecp = true;
@@ -587,7 +636,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	err = recover_data(sbi, &inode_list, &dir_list);
 	if (!err)
 		f2fs_bug_on(sbi, !list_empty(&inode_list));
-out:
+skip:
 	destroy_fsync_dnodes(&inode_list);
 
 	/* truncate meta pages to be used by the recovery */
@@ -615,5 +664,12 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	}
 
 	kmem_cache_destroy(fsync_entry_slab);
+out:
+#ifdef CONFIG_QUOTA
+	/* Turn quotas off */
+	f2fs_quota_off_umount(sbi->sb);
+#endif
+	sbi->sb->s_flags = s_flags; /* Restore MS_RDONLY status */
+
 	return ret ? ret: err;
 }

commit 7a2af766af15887754f7f7a0869b4603b390876a
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Jul 19 00:19:06 2017 +0800

    f2fs: enhance on-disk inode structure scalability
    
    This patch add new flag F2FS_EXTRA_ATTR storing in inode.i_inline
    to indicate that on-disk structure of current inode is extended.
    
    In order to extend, we changed the inode structure a bit:
    
    Original one:
    
    struct f2fs_inode {
            ...
            struct f2fs_extent i_ext;
            __le32 i_addr[DEF_ADDRS_PER_INODE];
            __le32 i_nid[DEF_NIDS_PER_INODE];
    }
    
    Extended one:
    
    struct f2fs_inode {
            ...
            struct f2fs_extent i_ext;
            union {
                    struct {
                            __le16 i_extra_isize;
                            __le16 i_padding;
                            __le32 i_extra_end[0];
                    };
                    __le32 i_addr[DEF_ADDRS_PER_INODE];
            };
            __le32 i_nid[DEF_NIDS_PER_INODE];
    }
    
    Once F2FS_EXTRA_ATTR is set, we will steal four bytes in the head of
    i_addr field for storing i_extra_isize and i_padding. with i_extra_isize,
    we can calculate actual size of reserved space in i_addr, available
    attribute fields included in total extra attribute fields for current
    inode can be described as below:
    
      +--------------------+
      | .i_mode            |
      | ...                |
      | .i_ext             |
      +--------------------+
      | .i_extra_isize     |-----+
      | .i_padding         |     |
      | .i_prjid           |     |
      | .i_atime_extra     |     |
      | .i_ctime_extra     |     |
      | .i_mtime_extra     |<----+
      | .i_inode_cs        |<----- store blkaddr/inline from here
      | .i_xattr_cs        |
      | ...                |
      +--------------------+
      |                    |
      |    block address   |
      |                    |
      +--------------------+
      | .i_nid             |
      +--------------------+
      |   node_footer      |
      | (nid, ino, offset) |
      +--------------------+
    
    Hence, with this patch, we would enhance scalability of f2fs inode for
    storing more newly added attribute.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 907d6b7dde6a..2d9b8182691f 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -361,7 +361,8 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	return 0;
 
 truncate_out:
-	if (datablock_addr(tdn.node_page, tdn.ofs_in_node) == blkaddr)
+	if (datablock_addr(tdn.inode, tdn.node_page,
+					tdn.ofs_in_node) == blkaddr)
 		truncate_data_blocks_range(&tdn, 1);
 	if (dn->inode->i_ino == nid && !dn->inode_page_locked)
 		unlock_page(dn->inode_page);
@@ -414,8 +415,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	for (; start < end; start++, dn.ofs_in_node++) {
 		block_t src, dest;
 
-		src = datablock_addr(dn.node_page, dn.ofs_in_node);
-		dest = datablock_addr(page, dn.ofs_in_node);
+		src = datablock_addr(dn.inode, dn.node_page, dn.ofs_in_node);
+		dest = datablock_addr(dn.inode, page, dn.ofs_in_node);
 
 		/* skip recovering if dest is the same as src */
 		if (src == dest)

commit d40d30c5aa5227546030d3d7b0a6a38c6c85933a
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Apr 14 15:46:23 2017 -0700

    f2fs: avoid dirty node pages in check_only recovery
    
    In the check_only mode, we should not make any dirty node pages. Otherwise,
    we can get this panic:
    
    F2FS-fs (nvme0n1p1): Need to recover fsync data
    ------------[ cut here ]------------
    kernel BUG at fs/f2fs/node.c:2204!
    CPU: 7 PID: 19923 Comm: mount Tainted: G           OE   4.9.8 #2
    RIP: 0010:[<ffffffffc0979c0b>]  [<ffffffffc0979c0b>] flush_nat_entries+0x43b/0x7d0 [f2fs]
    Call Trace:
     [<ffffffffc096ddaa>] ? __f2fs_submit_merged_bio+0x5a/0xd0 [f2fs]
     [<ffffffffc096ddaa>] ? __f2fs_submit_merged_bio+0x5a/0xd0 [f2fs]
     [<ffffffffc096dddb>] ? __f2fs_submit_merged_bio+0x8b/0xd0 [f2fs]
     [<ffffffff860e450f>] ? up_write+0x1f/0x40
     [<ffffffffc096dddb>] ? __f2fs_submit_merged_bio+0x8b/0xd0 [f2fs]
     [<ffffffffc0969f04>] write_checkpoint+0x2f4/0xf20 [f2fs]
     [<ffffffff860e938d>] ? trace_hardirqs_on+0xd/0x10
     [<ffffffffc0960bc9>] ? f2fs_sync_fs+0x79/0x190 [f2fs]
     [<ffffffffc0960bc9>] ? f2fs_sync_fs+0x79/0x190 [f2fs]
     [<ffffffffc0960bd5>] f2fs_sync_fs+0x85/0x190 [f2fs]
     [<ffffffffc097b6de>] f2fs_balance_fs_bg+0x7e/0x1c0 [f2fs]
     [<ffffffffc0977b64>] f2fs_write_node_pages+0x34/0x350 [f2fs]
     [<ffffffff860e5f42>] ? __lock_is_held+0x52/0x70
     [<ffffffff861d9b31>] do_writepages+0x21/0x30
     [<ffffffff86298ce1>] __writeback_single_inode+0x61/0x760
     [<ffffffff86909127>] ? _raw_spin_unlock+0x27/0x40
     [<ffffffff8629a735>] writeback_single_inode+0xd5/0x190
     [<ffffffff8629a889>] write_inode_now+0x99/0xc0
     [<ffffffff86283876>] iput+0x1f6/0x2c0
     [<ffffffffc0964b52>] f2fs_fill_super+0xc32/0x10c0 [f2fs]
     [<ffffffff86266462>] mount_bdev+0x182/0x1b0
     [<ffffffffc0963f20>] ? f2fs_commit_super+0x100/0x100 [f2fs]
     [<ffffffffc0960da5>] f2fs_mount+0x15/0x20 [f2fs]
     [<ffffffff86266e08>] mount_fs+0x38/0x170
     [<ffffffff86288bab>] vfs_kern_mount+0x6b/0x160
     [<ffffffff8628bcfe>] do_mount+0x1be/0xd60
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d025aa83fb5b..907d6b7dde6a 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -198,7 +198,8 @@ static void recover_inode(struct inode *inode, struct page *page)
 			ino_of_node(page), name);
 }
 
-static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
+static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,
+				bool check_only)
 {
 	struct curseg_info *curseg;
 	struct page *page = NULL;
@@ -225,7 +226,8 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 
 		entry = get_fsync_inode(head, ino_of_node(page));
 		if (!entry) {
-			if (IS_INODE(page) && is_dent_dnode(page)) {
+			if (!check_only &&
+					IS_INODE(page) && is_dent_dnode(page)) {
 				err = recover_inode_page(sbi, page);
 				if (err)
 					break;
@@ -569,7 +571,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	mutex_lock(&sbi->cp_mutex);
 
 	/* step #1: find fsynced inode numbers */
-	err = find_fsync_dnodes(sbi, &inode_list);
+	err = find_fsync_dnodes(sbi, &inode_list, check_only);
 	if (err || list_empty(&inode_list))
 		goto out;
 

commit d260081ccf37f57b74396ec48f415f27d1b01b13
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Feb 8 17:39:45 2017 +0800

    f2fs: change recovery policy of xattr node block
    
    Currently, if we call fsync after updating the xattr date belongs to the
    file, f2fs needs to trigger checkpoint to keep xattr data consistent. But,
    this policy cause low performance as checkpoint will block most foreground
    operations and cause unneeded and unrelated IOs around checkpoint.
    
    This patch will reuse regular file recovery policy for xattr node block,
    so, we change to write xattr node block tagged with fsync flag to warm
    area instead of cold area, and during recovery, we search warm node chain
    for fsynced xattr block, and do the recovery.
    
    So, for below application IO pattern, performance can be improved
    obviously:
    - touch file
    - create/update/delete xattr entry in file
    - fsync file
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index e93316ea8d1b..d025aa83fb5b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -378,11 +378,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	if (IS_INODE(page)) {
 		recover_inline_xattr(inode, page);
 	} else if (f2fs_has_xattr_block(ofs_of_node(page))) {
-		/*
-		 * Deprecated; xattr blocks should be found from cold log.
-		 * But, we should remain this for backward compatibility.
-		 */
-		recover_xattr_data(inode, page, blkaddr);
+		err = recover_xattr_data(inode, page, blkaddr);
+		if (!err)
+			recovered++;
 		goto out;
 	}
 

commit dba79f38bc60d98b605bdbbf5613aa3fb8f8ff7c
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Jan 25 10:52:39 2017 +0800

    f2fs: fix to avoid overflow when left shifting page offset
    
    We use following method to calculate size with current page index:
    size = index << PAGE_SHIFT
    If type of index has only 32-bits size, left shifting will incur overflow,
    which makes result incorrect.
    
    So let's cast index with 64-bits type to avoid such issue.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 4fb4471a3206..e93316ea8d1b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -428,8 +428,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		}
 
 		if (!file_keep_isize(inode) &&
-				(i_size_read(inode) <= (start << PAGE_SHIFT)))
-			f2fs_i_size_write(inode, (start + 1) << PAGE_SHIFT);
+			(i_size_read(inode) <= ((loff_t)start << PAGE_SHIFT)))
+			f2fs_i_size_write(inode,
+				(loff_t)(start + 1) << PAGE_SHIFT);
 
 		/*
 		 * dest is reserved block, invalidate src block

commit fed24668482e07421b8e746a4886e7725434050a
Author: Yunlei He <heyunlei@huawei.com>
Date:   Tue Dec 13 17:23:37 2016 +0800

    f2fs: remove unused values in recover_fsync_data
    
    This patch remove unused values in function recover_fsync_data
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 981a9584b62f..4fb4471a3206 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -552,10 +552,8 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 
 int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 {
-	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	struct list_head inode_list;
 	struct list_head dir_list;
-	block_t blkaddr;
 	int err;
 	int ret = 0;
 	bool need_writecp = false;
@@ -571,8 +569,6 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	/* prevent checkpoint */
 	mutex_lock(&sbi->cp_mutex);
 
-	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
-
 	/* step #1: find fsynced inode numbers */
 	err = find_fsync_dnodes(sbi, &inode_list);
 	if (err || list_empty(&inode_list))

commit 26787236b36660baf4d136281d40b5bb33a570ec
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Nov 28 15:33:38 2016 -0800

    f2fs: do not activate auto_recovery for fallocated i_size
    
    If a file needs to keep its i_size by fallocate, we need to turn off auto
    recovery during roll-forward recovery.
    
    This will resolve the below scenario.
    
    1. xfs_io -f /mnt/f2fs/file -c "pwrite 0 4096" -c "fsync"
    2. xfs_io -f /mnt/f2fs/file -c "falloc -k 4096 4096" -c "fsync"
    3. md5sum /mnt/f2fs/file;
    4. godown /mnt/f2fs/
    5. umount /mnt/f2fs/
    6. mount -t f2fs /dev/sdx /mnt/f2fs
    7. md5sum /mnt/f2fs/file
    
    Reported-by: Chao Yu <chao@kernel.org>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 687c176f0b56..981a9584b62f 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -187,6 +187,8 @@ static void recover_inode(struct inode *inode, struct page *page)
 	inode->i_ctime.tv_nsec = le32_to_cpu(raw->i_ctime_nsec);
 	inode->i_mtime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);
 
+	F2FS_I(inode)->i_advise = raw->i_advise;
+
 	if (file_enc_name(inode))
 		name = "<encrypted>";
 	else
@@ -425,7 +427,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			continue;
 		}
 
-		if (i_size_read(inode) <= (start << PAGE_SHIFT))
+		if (!file_keep_isize(inode) &&
+				(i_size_read(inode) <= (start << PAGE_SHIFT)))
 			f2fs_i_size_write(inode, (start + 1) << PAGE_SHIFT);
 
 		/*
@@ -478,8 +481,10 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	f2fs_put_dnode(&dn);
 out:
 	f2fs_msg(sbi->sb, KERN_NOTICE,
-		"recover_data: ino = %lx, recovered = %d blocks, err = %d",
-		inode->i_ino, recovered, err);
+		"recover_data: ino = %lx (i_size: %s) recovered = %d, err = %d",
+		inode->i_ino,
+		file_keep_isize(inode) ? "keep" : "recover",
+		recovered, err);
 	return err;
 }
 

commit 3a3a5ead7b6d2c9a29f493791ba23f264052db34
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Nov 16 15:09:48 2016 -0800

    f2fs: do not recover i_size if it's valid
    
    If i_size is already valid during roll_forward recovery, we should not update
    it according to the block alignment.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 62523b217571..687c176f0b56 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -425,7 +425,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			continue;
 		}
 
-		if ((start + 1) << PAGE_SHIFT > i_size_read(inode))
+		if (i_size_read(inode) <= (start << PAGE_SHIFT))
 			f2fs_i_size_write(inode, (start + 1) << PAGE_SHIFT);
 
 		/*

commit d47b8715953ad0cf82bb0a9d30d7b11d83bc9c11
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sat Nov 5 11:12:40 2016 +0800

    Revert "f2fs: do not recover from previous remained wrong dnodes"
    
    i_times of inode will be set with current system time which can be
    configured through 'date', so it's not safe to judge dnode block as
    garbage data or unchanged inode depend on i_times.
    
    Now, we have used enhanced 'cp_ver + cp' crc method to verify valid
    dnode block, so I expect recoverying invalid dnode is almost not
    possible.
    
    This reverts commit 807b1e1c8e08452948495b1a9985ab46d329e5c2.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d2ba4da08ec3..62523b217571 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -196,32 +196,6 @@ static void recover_inode(struct inode *inode, struct page *page)
 			ino_of_node(page), name);
 }
 
-static bool is_same_inode(struct inode *inode, struct page *ipage)
-{
-	struct f2fs_inode *ri = F2FS_INODE(ipage);
-	struct timespec disk;
-
-	if (!IS_INODE(ipage))
-		return true;
-
-	disk.tv_sec = le64_to_cpu(ri->i_ctime);
-	disk.tv_nsec = le32_to_cpu(ri->i_ctime_nsec);
-	if (timespec_compare(&inode->i_ctime, &disk) > 0)
-		return false;
-
-	disk.tv_sec = le64_to_cpu(ri->i_atime);
-	disk.tv_nsec = le32_to_cpu(ri->i_atime_nsec);
-	if (timespec_compare(&inode->i_atime, &disk) > 0)
-		return false;
-
-	disk.tv_sec = le64_to_cpu(ri->i_mtime);
-	disk.tv_nsec = le32_to_cpu(ri->i_mtime_nsec);
-	if (timespec_compare(&inode->i_mtime, &disk) > 0)
-		return false;
-
-	return true;
-}
-
 static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 {
 	struct curseg_info *curseg;
@@ -248,10 +222,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 			goto next;
 
 		entry = get_fsync_inode(head, ino_of_node(page));
-		if (entry) {
-			if (!is_same_inode(entry->inode, page))
-				goto next;
-		} else {
+		if (!entry) {
 			if (IS_INODE(page) && is_dent_dnode(page)) {
 				err = recover_inode_page(sbi, page);
 				if (err)

commit 9f0552e078b8a25fcf9c3950a05ea1398616d2b9
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Nov 4 00:26:55 2016 +0800

    f2fs: fix wrong i_atime recovery
    
    Shouldn't update in-memory i_atime with on-disk i_mtime of inode when
    recovering inode.
    
    Shuoran found this bug which is hidden for a long time, honour is belong
    to him.
    
    Signed-off-by: Shuoran Liu <liushuoran@huawei.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 2fc84a991325..d2ba4da08ec3 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -180,10 +180,10 @@ static void recover_inode(struct inode *inode, struct page *page)
 
 	inode->i_mode = le16_to_cpu(raw->i_mode);
 	f2fs_i_size_write(inode, le64_to_cpu(raw->i_size));
-	inode->i_atime.tv_sec = le64_to_cpu(raw->i_mtime);
+	inode->i_atime.tv_sec = le64_to_cpu(raw->i_atime);
 	inode->i_ctime.tv_sec = le64_to_cpu(raw->i_ctime);
 	inode->i_mtime.tv_sec = le64_to_cpu(raw->i_mtime);
-	inode->i_atime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);
+	inode->i_atime.tv_nsec = le32_to_cpu(raw->i_atime_nsec);
 	inode->i_ctime.tv_nsec = le32_to_cpu(raw->i_ctime_nsec);
 	inode->i_mtime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);
 

commit aaec2b1d18792a5f27b69ff37f34f43f89f5aa3b
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Sep 20 11:04:18 2016 +0800

    f2fs: introduce cp_lock to protect updating of ckpt_flags
    
    This patch introduces spinlock to protect updating process of ckpt_flags
    field in struct f2fs_checkpoint, it avoids incorrectly updating in race
    condition.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: add __is_set_ckpt_flags likewise __set_ckpt_flags]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 509273a65157..2fc84a991325 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -627,7 +627,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 
 	clear_sbi_flag(sbi, SBI_POR_DOING);
 	if (err)
-		set_ckpt_flags(sbi->ckpt, CP_ERROR_FLAG);
+		set_ckpt_flags(sbi, CP_ERROR_FLAG);
 	mutex_unlock(&sbi->cp_mutex);
 
 	/* let's drop all the directory inodes for clean checkpoint */

commit 9e1e6df412a28cdbbd2909de5c6189eda4a3383d
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 19 18:13:54 2016 -0700

    f2fs: put directory inodes before checkpoint in roll-forward recovery
    
    Before checkpoint, we'd be better drop any inodes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 2b8a56deb2d2..509273a65157 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -630,6 +630,9 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 		set_ckpt_flags(sbi->ckpt, CP_ERROR_FLAG);
 	mutex_unlock(&sbi->cp_mutex);
 
+	/* let's drop all the directory inodes for clean checkpoint */
+	destroy_fsync_dnodes(&dir_list);
+
 	if (!err && need_writecp) {
 		struct cp_control cpc = {
 			.reason = CP_RECOVERY,
@@ -637,7 +640,6 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 		err = write_checkpoint(sbi, &cpc);
 	}
 
-	destroy_fsync_dnodes(&dir_list);
 	kmem_cache_destroy(fsync_entry_slab);
 	return ret ? ret: err;
 }

commit a468f0ef516fda9c7d91bb550d458e853d76955e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 19 17:55:10 2016 -0700

    f2fs: use crc and cp version to determine roll-forward recovery
    
    Previously, we used cp_version only to detect recoverable dnodes.
    In order to avoid same garbage cp_version, we needed to truncate the next
    dnode during checkpoint, resulting in additional discard or data write.
    If we can distinguish this by using crc in addition to cp_version, we can
    remove this overhead.
    
    There is backward compatibility concern where it changes node_footer layout.
    So, this patch introduces a new checkpoint flag, CP_CRC_RECOVERY_FLAG, to
    detect new layout. New layout will be activated only when this flag is set.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index ad748e52956a..2b8a56deb2d2 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -224,7 +224,6 @@ static bool is_same_inode(struct inode *inode, struct page *ipage)
 
 static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 {
-	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
 	struct page *page = NULL;
 	block_t blkaddr;
@@ -242,7 +241,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 
 		page = get_tmp_page(sbi, blkaddr);
 
-		if (cp_ver != cpver_of_node(page))
+		if (!is_recoverable_dnode(page))
 			break;
 
 		if (!is_fsync_dnode(page))
@@ -516,7 +515,6 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 						struct list_head *dir_list)
 {
-	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
 	struct page *page = NULL;
 	int err = 0;
@@ -536,7 +534,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
 
 		page = get_tmp_page(sbi, blkaddr);
 
-		if (cp_ver != cpver_of_node(page)) {
+		if (!is_recoverable_dnode(page)) {
 			f2fs_put_page(page, 1);
 			break;
 		}
@@ -628,37 +626,15 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	}
 
 	clear_sbi_flag(sbi, SBI_POR_DOING);
-	if (err) {
-		bool invalidate = false;
-
-		if (test_opt(sbi, LFS)) {
-			update_meta_page(sbi, NULL, blkaddr);
-			invalidate = true;
-		} else if (discard_next_dnode(sbi, blkaddr)) {
-			invalidate = true;
-		}
-
-		f2fs_wait_all_discard_bio(sbi);
-
-		/* Flush all the NAT/SIT pages */
-		while (get_pages(sbi, F2FS_DIRTY_META))
-			sync_meta_pages(sbi, META, LONG_MAX);
-
-		/* invalidate temporary meta page */
-		if (invalidate)
-			invalidate_mapping_pages(META_MAPPING(sbi),
-							blkaddr, blkaddr);
-
+	if (err)
 		set_ckpt_flags(sbi->ckpt, CP_ERROR_FLAG);
-		mutex_unlock(&sbi->cp_mutex);
-	} else if (need_writecp) {
+	mutex_unlock(&sbi->cp_mutex);
+
+	if (!err && need_writecp) {
 		struct cp_control cpc = {
 			.reason = CP_RECOVERY,
 		};
-		mutex_unlock(&sbi->cp_mutex);
 		err = write_checkpoint(sbi, &cpc);
-	} else {
-		mutex_unlock(&sbi->cp_mutex);
 	}
 
 	destroy_fsync_dnodes(&dir_list);

commit e8ea9b3d7e278d2ef4b60e703f780ceee70cb331
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Sep 9 16:59:39 2016 -0700

    f2fs: avoid ENOMEM during roll-forward recovery
    
    This patch gives another chances during roll-forward recovery regarding to
    -ENOMEM.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 1269277773f5..ad748e52956a 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -71,18 +71,14 @@ static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
 static struct fsync_inode_entry *add_fsync_inode(struct f2fs_sb_info *sbi,
 					struct list_head *head, nid_t ino)
 {
-	struct inode *inode = f2fs_iget(sbi->sb, ino);
+	struct inode *inode;
 	struct fsync_inode_entry *entry;
 
+	inode = f2fs_iget_retry(sbi->sb, ino);
 	if (IS_ERR(inode))
 		return ERR_CAST(inode);
 
-	entry = kmem_cache_alloc(fsync_entry_slab, GFP_F2FS_ZERO);
-	if (!entry) {
-		iput(inode);
-		return ERR_PTR(-ENOMEM);
-	}
-
+	entry = f2fs_kmem_cache_alloc(fsync_entry_slab, GFP_F2FS_ZERO);
 	entry->inode = inode;
 	list_add_tail(&entry->list, head);
 
@@ -136,7 +132,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 		goto out_unmap_put;
 
 	if (de) {
-		einode = f2fs_iget(inode->i_sb, le32_to_cpu(de->ino));
+		einode = f2fs_iget_retry(inode->i_sb, le32_to_cpu(de->ino));
 		if (IS_ERR(einode)) {
 			WARN_ON(1);
 			err = PTR_ERR(einode);
@@ -158,6 +154,8 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 		err = __f2fs_do_add_link(dir, &fname, inode,
 					inode->i_ino, inode->i_mode);
 	}
+	if (err == -ENOMEM)
+		goto retry;
 	goto out;
 
 out_unmap_put:
@@ -357,7 +355,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 
 	if (ino != dn->inode->i_ino) {
 		/* Deallocate previous index in the node page */
-		inode = f2fs_iget(sbi->sb, ino);
+		inode = f2fs_iget_retry(sbi->sb, ino);
 		if (IS_ERR(inode))
 			return PTR_ERR(inode);
 	} else {
@@ -425,10 +423,15 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	end = start + ADDRS_PER_PAGE(page, inode);
 
 	set_new_dnode(&dn, inode, NULL, NULL, 0);
-
+retry_dn:
 	err = get_dnode_of_data(&dn, start, ALLOC_NODE);
-	if (err)
+	if (err) {
+		if (err == -ENOMEM) {
+			congestion_wait(BLK_RW_ASYNC, HZ/50);
+			goto retry_dn;
+		}
 		goto out;
+	}
 
 	f2fs_wait_on_page_writeback(dn.node_page, NODE, true);
 
@@ -479,11 +482,16 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 				if (err)
 					goto err;
 			}
-
+retry_prev:
 			/* Check the previous node page having this index */
 			err = check_index_in_prev_nodes(sbi, dest, &dn);
-			if (err)
+			if (err) {
+				if (err == -ENOMEM) {
+					congestion_wait(BLK_RW_ASYNC, HZ/50);
+					goto retry_prev;
+				}
 				goto err;
+			}
 
 			/* write dummy data page */
 			f2fs_replace_block(sbi, &dn, src, dest,

commit f4702d61eb53466251eeb677f9784e047e1caf0c
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Sep 9 16:48:15 2016 -0700

    f2fs: add common iget in add_fsync_inode
    
    There is no functional change.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index ba0fc2ec7caf..1269277773f5 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -68,14 +68,20 @@ static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
 	return NULL;
 }
 
-static struct fsync_inode_entry *add_fsync_inode(struct list_head *head,
-							struct inode *inode)
+static struct fsync_inode_entry *add_fsync_inode(struct f2fs_sb_info *sbi,
+					struct list_head *head, nid_t ino)
 {
+	struct inode *inode = f2fs_iget(sbi->sb, ino);
 	struct fsync_inode_entry *entry;
 
+	if (IS_ERR(inode))
+		return ERR_CAST(inode);
+
 	entry = kmem_cache_alloc(fsync_entry_slab, GFP_F2FS_ZERO);
-	if (!entry)
-		return NULL;
+	if (!entry) {
+		iput(inode);
+		return ERR_PTR(-ENOMEM);
+	}
 
 	entry->inode = inode;
 	list_add_tail(&entry->list, head);
@@ -105,16 +111,10 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 
 	entry = get_fsync_inode(dir_list, pino);
 	if (!entry) {
-		dir = f2fs_iget(inode->i_sb, pino);
-		if (IS_ERR(dir)) {
-			err = PTR_ERR(dir);
-			goto out;
-		}
-
-		entry = add_fsync_inode(dir_list, dir);
-		if (!entry) {
-			err = -ENOMEM;
-			iput(dir);
+		entry = add_fsync_inode(F2FS_I_SB(inode), dir_list, pino);
+		if (IS_ERR(entry)) {
+			dir = ERR_CAST(entry);
+			err = PTR_ERR(entry);
 			goto out;
 		}
 	}
@@ -228,7 +228,6 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 {
 	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
-	struct inode *inode;
 	struct page *page = NULL;
 	block_t blkaddr;
 	int err = 0;
@@ -266,23 +265,15 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 			 * CP | dnode(F) | inode(DF)
 			 * For this case, we should not give up now.
 			 */
-			inode = f2fs_iget(sbi->sb, ino_of_node(page));
-			if (IS_ERR(inode)) {
-				err = PTR_ERR(inode);
+			entry = add_fsync_inode(sbi, head, ino_of_node(page));
+			if (IS_ERR(entry)) {
+				err = PTR_ERR(entry);
 				if (err == -ENOENT) {
 					err = 0;
 					goto next;
 				}
 				break;
 			}
-
-			/* add this fsync inode to the list */
-			entry = add_fsync_inode(head, inode);
-			if (!entry) {
-				err = -ENOMEM;
-				iput(inode);
-				break;
-			}
 		}
 		entry->blkaddr = blkaddr;
 

commit e7ba108a06216dae89a64c0243560502276b92d8
Author: Shuoran Liu <liushuoran@huawei.com>
Date:   Mon Aug 29 11:27:56 2016 +0800

    f2fs: add roll-forward recovery process for encrypted dentry
    
    Add roll-forward recovery process for encrypted dentry, so the first fsync
    issued to an encrypted file does not need writing checkpoint.
    
    This improves the performance of the following test at thousands of small
    files: open -> write -> fsync -> close
    
    Signed-off-by: Shuoran Liu <liushuoran@huawei.com>
    Acked-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: modify kernel message to show encrypted names]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 2f38bbbeec2c..ba0fc2ec7caf 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -96,11 +96,12 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 	struct f2fs_inode *raw_inode = F2FS_INODE(ipage);
 	nid_t pino = le32_to_cpu(raw_inode->i_pino);
 	struct f2fs_dir_entry *de;
-	struct qstr name;
+	struct fscrypt_name fname;
 	struct page *page;
 	struct inode *dir, *einode;
 	struct fsync_inode_entry *entry;
 	int err = 0;
+	char *name;
 
 	entry = get_fsync_inode(dir_list, pino);
 	if (!entry) {
@@ -120,19 +121,17 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 
 	dir = entry->inode;
 
-	if (file_enc_name(inode))
-		return 0;
-
-	name.len = le32_to_cpu(raw_inode->i_namelen);
-	name.name = raw_inode->i_name;
+	memset(&fname, 0, sizeof(struct fscrypt_name));
+	fname.disk_name.len = le32_to_cpu(raw_inode->i_namelen);
+	fname.disk_name.name = raw_inode->i_name;
 
-	if (unlikely(name.len > F2FS_NAME_LEN)) {
+	if (unlikely(fname.disk_name.len > F2FS_NAME_LEN)) {
 		WARN_ON(1);
 		err = -ENAMETOOLONG;
 		goto out;
 	}
 retry:
-	de = f2fs_find_entry(dir, &name, &page);
+	de = __f2fs_find_entry(dir, &fname, &page);
 	if (de && inode->i_ino == le32_to_cpu(de->ino))
 		goto out_unmap_put;
 
@@ -156,7 +155,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 	} else if (IS_ERR(page)) {
 		err = PTR_ERR(page);
 	} else {
-		err = __f2fs_add_link(dir, &name, inode,
+		err = __f2fs_do_add_link(dir, &fname, inode,
 					inode->i_ino, inode->i_mode);
 	}
 	goto out;
@@ -165,9 +164,13 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 	f2fs_dentry_kunmap(dir, page);
 	f2fs_put_page(page, 0);
 out:
+	if (file_enc_name(inode))
+		name = "<encrypted>";
+	else
+		name = raw_inode->i_name;
 	f2fs_msg(inode->i_sb, KERN_NOTICE,
 			"%s: ino = %x, name = %s, dir = %lx, err = %d",
-			__func__, ino_of_node(ipage), raw_inode->i_name,
+			__func__, ino_of_node(ipage), name,
 			IS_ERR(dir) ? 0 : dir->i_ino, err);
 	return err;
 }

commit 275b66b09e85cf0520dc610dd89706952751a473
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Aug 29 23:58:34 2016 +0800

    f2fs: support async discard
    
    Like most filesystems, f2fs will issue discard command synchronously, so
    when user trigger fstrim through ioctl, multiple discard commands will be
    issued serially with sync mode, which makes poor performance.
    
    In this patch we try to support async discard, so that all discard
    commands can be issued and be waited for endio in batch to improve
    performance.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 9e652d5a659b..2f38bbbeec2c 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -636,6 +636,8 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 			invalidate = true;
 		}
 
+		f2fs_wait_all_discard_bio(sbi);
+
 		/* Flush all the NAT/SIT pages */
 		while (get_pages(sbi, F2FS_DIRTY_META))
 			sync_meta_pages(sbi, META, LONG_MAX);

commit 6f3ec9952c13f0adf632e89456df43946cec6525
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Jul 19 19:30:06 2016 -0700

    f2fs: handle error case with f2fs_bug_on
    
    It's enough to show BUG or WARN by f2fs_bug_on for error case.
    Then, we don't need to remain corrupted filesystem.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 5d4461f2c266..9e652d5a659b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -482,6 +482,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 #endif
 				/* We should not get -ENOSPC */
 				f2fs_bug_on(sbi, err);
+				if (err)
+					goto err;
 			}
 
 			/* Check the previous node page having this index */

commit 91246c21b85985c48b1e1f5603e0d81161eb76a4
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Jul 19 08:27:47 2016 +0800

    f2fs: fix to report error number of f2fs_find_entry
    
    This patch fixes to report the right error number of f2fs_find_entry to
    its caller.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index a39d84ab66b2..5d4461f2c266 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -153,9 +153,12 @@ static int recover_dentry(struct inode *inode, struct page *ipage,
 		f2fs_delete_entry(de, page, dir, einode);
 		iput(einode);
 		goto retry;
+	} else if (IS_ERR(page)) {
+		err = PTR_ERR(page);
+	} else {
+		err = __f2fs_add_link(dir, &name, inode,
+					inode->i_ino, inode->i_mode);
 	}
-	err = __f2fs_add_link(dir, &name, inode, inode->i_ino, inode->i_mode);
-
 	goto out;
 
 out_unmap_put:

commit 36abef4e796d382e81a0c2d21ea5327481dd7154
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jun 3 19:29:38 2016 -0700

    f2fs: introduce mode=lfs mount option
    
    This mount option is to enable original log-structured filesystem forcefully.
    So, there should be no random writes for main area.
    
    Especially, this supports host-managed SMR device.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b568b28c74f2..a39d84ab66b2 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -624,8 +624,12 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	if (err) {
 		bool invalidate = false;
 
-		if (discard_next_dnode(sbi, blkaddr))
+		if (test_opt(sbi, LFS)) {
+			update_meta_page(sbi, NULL, blkaddr);
 			invalidate = true;
+		} else if (discard_next_dnode(sbi, blkaddr)) {
+			invalidate = true;
+		}
 
 		/* Flush all the NAT/SIT pages */
 		while (get_pages(sbi, F2FS_DIRTY_META))

commit 26de9b11713057a16a9220423a2f137774763b0e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri May 20 20:42:37 2016 -0700

    f2fs: avoid unnecessary updating inode during fsync
    
    If roll-forward recovery can recover i_size, we don't need to update inode's
    metadata during fsync.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 68c433f17ab5..b568b28c74f2 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -455,6 +455,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			continue;
 		}
 
+		if ((start + 1) << PAGE_SHIFT > i_size_read(inode))
+			f2fs_i_size_write(inode, (start + 1) << PAGE_SHIFT);
+
 		/*
 		 * dest is reserved block, invalidate src block
 		 * and then reserve one new block in dnode page.

commit ee6d182f2a19d5d44607b5ae4bec523726d76a99
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri May 20 16:32:49 2016 -0700

    f2fs: remove syncing inode page in all the cases
    
    This patch reduces to call them across the whole tree.
    - sync_inode_page()
    - update_inode_page()
    - update_inode()
    - f2fs_write_inode()
    
    Instead, checkpoint will flush all the dirty inode metadata before syncing
    node pages.
    Note that, this is doable, since we call mark_inode_dirty_sync() for all
    inode's field change which needs to update on-disk inode as well.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 2500b6a5daf0..68c433f17ab5 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -490,9 +490,6 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		}
 	}
 
-	if (IS_INODE(dn.node_page))
-		sync_inode_page(&dn);
-
 	copy_node_footer(dn.node_page, page);
 	fill_node_footer(dn.node_page, dn.nid, ni.ino,
 					ofs_of_node(page), false);

commit fc9581c809722960c46a02445f2434120e5e483b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri May 20 09:22:03 2016 -0700

    f2fs: introduce f2fs_i_size_write with mark_inode_dirty_sync
    
    This patch introduces f2fs_i_size_write() to call mark_inode_dirty_sync() with
    i_size_write().
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 3d7216d7a288..2500b6a5daf0 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -175,7 +175,7 @@ static void recover_inode(struct inode *inode, struct page *page)
 	char *name;
 
 	inode->i_mode = le16_to_cpu(raw->i_mode);
-	i_size_write(inode, le64_to_cpu(raw->i_size));
+	f2fs_i_size_write(inode, le64_to_cpu(raw->i_size));
 	inode->i_atime.tv_sec = le64_to_cpu(raw->i_mtime);
 	inode->i_ctime.tv_sec = le64_to_cpu(raw->i_ctime);
 	inode->i_mtime.tv_sec = le64_to_cpu(raw->i_mtime);

commit 975756c41332bc5e523e9f843271ed5ab6aaaaaa
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu May 19 11:57:21 2016 -0700

    f2fs: avoid ENOSPC fault in the recovery process
    
    This patch avoids impossible error injection, ENOSPC, during recovery process.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index f89b70e72004..3d7216d7a288 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -470,6 +470,10 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 			if (src == NULL_ADDR) {
 				err = reserve_new_block(&dn);
+#ifdef CONFIG_F2FS_FAULT_INJECTION
+				while (err)
+					err = reserve_new_block(&dn);
+#endif
 				/* We should not get -ENOSPC */
 				f2fs_bug_on(sbi, err);
 			}

commit 41382ec43255b502321c3c27f1347efeb3279290
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon May 16 11:06:50 2016 -0700

    f2fs: use percpu_counter for alloc_valid_block_count
    
    This patch uses percpu_count for sbi->alloc_valid_block_count.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 6303b2a38c34..f89b70e72004 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -49,8 +49,9 @@ static struct kmem_cache *fsync_entry_slab;
 
 bool space_for_roll_forward(struct f2fs_sb_info *sbi)
 {
-	if (sbi->last_valid_block_count + sbi->alloc_valid_block_count
-			> sbi->user_block_count)
+	s64 nalloc = percpu_counter_sum_positive(&sbi->alloc_valid_block_count);
+
+	if (sbi->last_valid_block_count + nalloc > sbi->user_block_count)
 		return false;
 	return true;
 }

commit 3b9b10f9ce61b574c63d71ff3eeec9cf5dbe763f
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed May 11 09:13:13 2016 -0700

    f2fs: avoid f2fs_bug_on during recovery
    
    We don't need to use f2fs_bug_on() to treat with any error case when allocating
    a block during recovery.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 2b2532903b43..6303b2a38c34 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -460,8 +460,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		 */
 		if (dest == NEW_ADDR) {
 			truncate_data_blocks_range(&dn, 1);
-			err = reserve_new_block(&dn);
-			f2fs_bug_on(sbi, err);
+			reserve_new_block(&dn);
 			continue;
 		}
 

commit f61cce5b81f91ba336184008b24baec84afbb3dd
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sat May 7 16:15:05 2016 +0800

    f2fs: fix inode cache leak
    
    When testing f2fs with inline_dentry option, generic/342 reports:
    VFS: Busy inodes after unmount of dm-0. Self-destruct in 5 seconds.  Have a nice day...
    
    After rmmod f2fs module, kenrel shows following dmesg:
     =============================================================================
     BUG f2fs_inode_cache (Tainted: G           O   ): Objects remaining in f2fs_inode_cache on __kmem_cache_shutdown()
     -----------------------------------------------------------------------------
    
     Disabling lock debugging due to kernel taint
     INFO: Slab 0xf51ca0e0 objects=22 used=1 fp=0xd1e6fc60 flags=0x40004080
     CPU: 3 PID: 7455 Comm: rmmod Tainted: G    B      O    4.6.0-rc4+ #16
     Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
      00000086 00000086 d062fe18 c13a83a0 f51ca0e0 d062fe38 d062fea4 c11c7276
      c1981040 f51ca0e0 00000016 00000001 d1e6fc60 40004080 656a624f 20737463
      616d6572 6e696e69 6e692067 66326620 6e695f73 5f65646f 68636163 6e6f2065
     Call Trace:
      [<c13a83a0>] dump_stack+0x5f/0x8f
      [<c11c7276>] slab_err+0x76/0x80
      [<c11cbfc0>] ? __kmem_cache_shutdown+0x100/0x2f0
      [<c11cbfc0>] ? __kmem_cache_shutdown+0x100/0x2f0
      [<c11cbfe5>] __kmem_cache_shutdown+0x125/0x2f0
      [<c1198a38>] kmem_cache_destroy+0x158/0x1f0
      [<c176b43d>] ? mutex_unlock+0xd/0x10
      [<f8f15aa3>] exit_f2fs_fs+0x4b/0x5a8 [f2fs]
      [<c10f596c>] SyS_delete_module+0x16c/0x1d0
      [<c1001b10>] ? do_fast_syscall_32+0x30/0x1c0
      [<c13c59bf>] ? __this_cpu_preempt_check+0xf/0x20
      [<c10afa7d>] ? trace_hardirqs_on_caller+0xdd/0x210
      [<c10ad50b>] ? trace_hardirqs_off+0xb/0x10
      [<c1001b81>] do_fast_syscall_32+0xa1/0x1c0
      [<c176d888>] sysenter_past_esp+0x45/0x74
     INFO: Object 0xd1e6d9e0 @offset=6624
     kmem_cache_destroy f2fs_inode_cache: Slab cache still has objects
     CPU: 3 PID: 7455 Comm: rmmod Tainted: G    B      O    4.6.0-rc4+ #16
     Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
      00000286 00000286 d062fef4 c13a83a0 f174b000 d062ff14 d062ff28 c1198ac7
      c197fe18 f3c5b980 d062ff20 000d04f2 d062ff0c d062ff0c d062ff14 d062ff14
      f8f20dc0 fffffff5 d062e000 d062ff30 f8f15aa3 d062ff7c c10f596c 73663266
     Call Trace:
      [<c13a83a0>] dump_stack+0x5f/0x8f
      [<c1198ac7>] kmem_cache_destroy+0x1e7/0x1f0
      [<f8f15aa3>] exit_f2fs_fs+0x4b/0x5a8 [f2fs]
      [<c10f596c>] SyS_delete_module+0x16c/0x1d0
      [<c1001b10>] ? do_fast_syscall_32+0x30/0x1c0
      [<c13c59bf>] ? __this_cpu_preempt_check+0xf/0x20
      [<c10afa7d>] ? trace_hardirqs_on_caller+0xdd/0x210
      [<c10ad50b>] ? trace_hardirqs_off+0xb/0x10
      [<c1001b81>] do_fast_syscall_32+0xa1/0x1c0
      [<c176d888>] sysenter_past_esp+0x45/0x74
    
    The reason is: in recovery flow, we use delayed iput mechanism for directory
    which has recovered dentry block. It means the reference of inode will be
    held until last dirty dentry page being writebacked.
    
    But when we mount f2fs with inline_dentry option, during recovery, dirent
    may only be recovered into dir inode page rather than dentry page, so there
    are no chance for us to release inode reference in ->writepage when
    writebacking last dentry page.
    
    We can call paired iget/iput explicityly for inline_dentry case, but for
    non-inline_dentry case, iput will call writeback_single_inode to write all
    data pages synchronously, but during recovery, ->writepages of f2fs skips
    writing all pages, result in losing dirent.
    
    This patch fixes this issue by obsoleting old mechanism, and introduce a
    new dir_list to hold all directory inodes which has recovered datas until
    finishing recovery.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 29a37aae95d4..2b2532903b43 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -89,7 +89,8 @@ static void del_fsync_inode(struct fsync_inode_entry *entry)
 	kmem_cache_free(fsync_entry_slab, entry);
 }
 
-static int recover_dentry(struct inode *inode, struct page *ipage)
+static int recover_dentry(struct inode *inode, struct page *ipage,
+						struct list_head *dir_list)
 {
 	struct f2fs_inode *raw_inode = F2FS_INODE(ipage);
 	nid_t pino = le32_to_cpu(raw_inode->i_pino);
@@ -97,18 +98,29 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 	struct qstr name;
 	struct page *page;
 	struct inode *dir, *einode;
+	struct fsync_inode_entry *entry;
 	int err = 0;
 
-	dir = f2fs_iget(inode->i_sb, pino);
-	if (IS_ERR(dir)) {
-		err = PTR_ERR(dir);
-		goto out;
+	entry = get_fsync_inode(dir_list, pino);
+	if (!entry) {
+		dir = f2fs_iget(inode->i_sb, pino);
+		if (IS_ERR(dir)) {
+			err = PTR_ERR(dir);
+			goto out;
+		}
+
+		entry = add_fsync_inode(dir_list, dir);
+		if (!entry) {
+			err = -ENOMEM;
+			iput(dir);
+			goto out;
+		}
 	}
 
-	if (file_enc_name(inode)) {
-		iput(dir);
+	dir = entry->inode;
+
+	if (file_enc_name(inode))
 		return 0;
-	}
 
 	name.len = le32_to_cpu(raw_inode->i_namelen);
 	name.name = raw_inode->i_name;
@@ -116,7 +128,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 	if (unlikely(name.len > F2FS_NAME_LEN)) {
 		WARN_ON(1);
 		err = -ENAMETOOLONG;
-		goto out_err;
+		goto out;
 	}
 retry:
 	de = f2fs_find_entry(dir, &name, &page);
@@ -142,23 +154,12 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 		goto retry;
 	}
 	err = __f2fs_add_link(dir, &name, inode, inode->i_ino, inode->i_mode);
-	if (err)
-		goto out_err;
-
-	if (is_inode_flag_set(F2FS_I(dir), FI_DELAY_IPUT)) {
-		iput(dir);
-	} else {
-		add_dirty_dir_inode(dir);
-		set_inode_flag(F2FS_I(dir), FI_DELAY_IPUT);
-	}
 
 	goto out;
 
 out_unmap_put:
 	f2fs_dentry_kunmap(dir, page);
 	f2fs_put_page(page, 0);
-out_err:
-	iput(dir);
 out:
 	f2fs_msg(inode->i_sb, KERN_NOTICE,
 			"%s: ino = %x, name = %s, dir = %lx, err = %d",
@@ -501,7 +502,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	return err;
 }
 
-static int recover_data(struct f2fs_sb_info *sbi, struct list_head *head)
+static int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,
+						struct list_head *dir_list)
 {
 	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
@@ -528,7 +530,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *head)
 			break;
 		}
 
-		entry = get_fsync_inode(head, ino_of_node(page));
+		entry = get_fsync_inode(inode_list, ino_of_node(page));
 		if (!entry)
 			goto next;
 		/*
@@ -539,7 +541,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *head)
 		if (IS_INODE(page))
 			recover_inode(entry->inode, page);
 		if (entry->last_dentry == blkaddr) {
-			err = recover_dentry(entry->inode, page);
+			err = recover_dentry(entry->inode, page, dir_list);
 			if (err) {
 				f2fs_put_page(page, 1);
 				break;
@@ -567,6 +569,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 {
 	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	struct list_head inode_list;
+	struct list_head dir_list;
 	block_t blkaddr;
 	int err;
 	int ret = 0;
@@ -578,6 +581,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 		return -ENOMEM;
 
 	INIT_LIST_HEAD(&inode_list);
+	INIT_LIST_HEAD(&dir_list);
 
 	/* prevent checkpoint */
 	mutex_lock(&sbi->cp_mutex);
@@ -597,12 +601,11 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	need_writecp = true;
 
 	/* step #2: recover data */
-	err = recover_data(sbi, &inode_list);
+	err = recover_data(sbi, &inode_list, &dir_list);
 	if (!err)
 		f2fs_bug_on(sbi, !list_empty(&inode_list));
 out:
 	destroy_fsync_dnodes(&inode_list);
-	kmem_cache_destroy(fsync_entry_slab);
 
 	/* truncate meta pages to be used by the recovery */
 	truncate_inode_pages_range(META_MAPPING(sbi),
@@ -640,5 +643,8 @@ int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 	} else {
 		mutex_unlock(&sbi->cp_mutex);
 	}
+
+	destroy_fsync_dnodes(&dir_list);
+	kmem_cache_destroy(fsync_entry_slab);
 	return ret ? ret: err;
 }

commit ae8d1db34ff57b11feceeaaa26940015b14e30fb
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed May 4 23:17:00 2016 +0800

    f2fs: remove unneeded readahead in find_fsync_dnodes
    
    In find_fsync_dnodes, get_tmp_page will read dnode page synchronously,
    previously, ra_meta_page did the same work, which is redundant, remove
    it.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 58275a29e87d..29a37aae95d4 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -229,8 +229,6 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 	curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
-	ra_meta_pages(sbi, blkaddr, 1, META_POR, true);
-
 	while (1) {
 		struct fsync_inode_entry *entry;
 

commit 3f8ab270855b0b461995da5dc48dce9461c85d94
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Apr 29 20:13:37 2016 +0800

    f2fs: factor out fsync inode entry operations
    
    Factor out fsync inode entry operations into {add,del}_fsync_inode.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index a646d3ba3b25..58275a29e87d 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -67,6 +67,28 @@ static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
 	return NULL;
 }
 
+static struct fsync_inode_entry *add_fsync_inode(struct list_head *head,
+							struct inode *inode)
+{
+	struct fsync_inode_entry *entry;
+
+	entry = kmem_cache_alloc(fsync_entry_slab, GFP_F2FS_ZERO);
+	if (!entry)
+		return NULL;
+
+	entry->inode = inode;
+	list_add_tail(&entry->list, head);
+
+	return entry;
+}
+
+static void del_fsync_inode(struct fsync_inode_entry *entry)
+{
+	iput(entry->inode);
+	list_del(&entry->list);
+	kmem_cache_free(fsync_entry_slab, entry);
+}
+
 static int recover_dentry(struct inode *inode, struct page *ipage)
 {
 	struct f2fs_inode *raw_inode = F2FS_INODE(ipage);
@@ -198,6 +220,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 {
 	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
+	struct inode *inode;
 	struct page *page = NULL;
 	block_t blkaddr;
 	int err = 0;
@@ -233,27 +256,27 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 					break;
 			}
 
-			/* add this fsync inode to the list */
-			entry = kmem_cache_alloc(fsync_entry_slab, GFP_F2FS_ZERO);
-			if (!entry) {
-				err = -ENOMEM;
-				break;
-			}
 			/*
 			 * CP | dnode(F) | inode(DF)
 			 * For this case, we should not give up now.
 			 */
-			entry->inode = f2fs_iget(sbi->sb, ino_of_node(page));
-			if (IS_ERR(entry->inode)) {
-				err = PTR_ERR(entry->inode);
-				kmem_cache_free(fsync_entry_slab, entry);
+			inode = f2fs_iget(sbi->sb, ino_of_node(page));
+			if (IS_ERR(inode)) {
+				err = PTR_ERR(inode);
 				if (err == -ENOENT) {
 					err = 0;
 					goto next;
 				}
 				break;
 			}
-			list_add_tail(&entry->list, head);
+
+			/* add this fsync inode to the list */
+			entry = add_fsync_inode(head, inode);
+			if (!entry) {
+				err = -ENOMEM;
+				iput(inode);
+				break;
+			}
 		}
 		entry->blkaddr = blkaddr;
 
@@ -274,11 +297,8 @@ static void destroy_fsync_dnodes(struct list_head *head)
 {
 	struct fsync_inode_entry *entry, *tmp;
 
-	list_for_each_entry_safe(entry, tmp, head, list) {
-		iput(entry->inode);
-		list_del(&entry->list);
-		kmem_cache_free(fsync_entry_slab, entry);
-	}
+	list_for_each_entry_safe(entry, tmp, head, list)
+		del_fsync_inode(entry);
 }
 
 static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
@@ -533,11 +553,8 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *head)
 			break;
 		}
 
-		if (entry->blkaddr == blkaddr) {
-			iput(entry->inode);
-			list_del(&entry->list);
-			kmem_cache_free(fsync_entry_slab, entry);
-		}
+		if (entry->blkaddr == blkaddr)
+			del_fsync_inode(entry);
 next:
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);

commit 608514deba38c8611ad330d6a3c8e2b9a1f68e4b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Apr 15 09:43:17 2016 -0700

    f2fs: set fsync mark only for the last dnode
    
    In order to give atomic writes, we should consider power failure during
    sync_node_pages in fsync.
    So, this patch marks fsync flag only in the last dnode block.
    
    Acked-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 2c87c12b6f1c..a646d3ba3b25 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -257,11 +257,8 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 		}
 		entry->blkaddr = blkaddr;
 
-		if (IS_INODE(page)) {
-			entry->last_inode = blkaddr;
-			if (is_dent_dnode(page))
-				entry->last_dentry = blkaddr;
-		}
+		if (IS_INODE(page) && is_dent_dnode(page))
+			entry->last_dentry = blkaddr;
 next:
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
@@ -521,7 +518,7 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *head)
 		 * In this case, we can lose the latest inode(x).
 		 * So, call recover_inode for the inode update.
 		 */
-		if (entry->last_inode == blkaddr)
+		if (IS_INODE(page))
 			recover_inode(entry->inode, page);
 		if (entry->last_dentry == blkaddr) {
 			err = recover_dentry(entry->inode, page);

commit 6781eabba1bdb133eb9125c4acf6704ccbe4df02
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Mar 23 16:12:58 2016 -0700

    f2fs: give -EINVAL for norecovery and rw mount
    
    Once detecting something to recover, f2fs should stop mounting, given norecovery
    and rw mount options.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 011942f94d64..2c87c12b6f1c 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -551,12 +551,13 @@ static int recover_data(struct f2fs_sb_info *sbi, struct list_head *head)
 	return err;
 }
 
-int recover_fsync_data(struct f2fs_sb_info *sbi)
+int recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)
 {
 	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	struct list_head inode_list;
 	block_t blkaddr;
 	int err;
+	int ret = 0;
 	bool need_writecp = false;
 
 	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
@@ -573,11 +574,13 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	/* step #1: find fsynced inode numbers */
 	err = find_fsync_dnodes(sbi, &inode_list);
-	if (err)
+	if (err || list_empty(&inode_list))
 		goto out;
 
-	if (list_empty(&inode_list))
+	if (check_only) {
+		ret = 1;
 		goto out;
+	}
 
 	need_writecp = true;
 
@@ -625,5 +628,5 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	} else {
 		mutex_unlock(&sbi->cp_mutex);
 	}
-	return err;
+	return ret ? ret: err;
 }

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 0b30cd2aeebd..011942f94d64 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -591,7 +591,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	/* truncate meta pages to be used by the recovery */
 	truncate_inode_pages_range(META_MAPPING(sbi),
-			(loff_t)MAIN_BLKADDR(sbi) << PAGE_CACHE_SHIFT, -1);
+			(loff_t)MAIN_BLKADDR(sbi) << PAGE_SHIFT, -1);
 
 	if (err) {
 		truncate_inode_pages_final(NODE_MAPPING(sbi));

commit 28bc106b2346a7348706bf86d9efbe31920c69f3
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sat Feb 6 14:40:34 2016 +0800

    f2fs: support revoking atomic written pages
    
    f2fs support atomic write with following semantics:
    1. open db file
    2. ioctl start atomic write
    3. (write db file) * n
    4. ioctl commit atomic write
    5. close db file
    
    With this flow we can avoid file becoming corrupted when abnormal power
    cut, because we hold data of transaction in referenced pages linked in
    inmem_pages list of inode, but without setting them dirty, so these data
    won't be persisted unless we commit them in step 4.
    
    But we should still hold journal db file in memory by using volatile
    write, because our semantics of 'atomic write support' is incomplete, in
    step 4, we could fail to submit all dirty data of transaction, once
    partial dirty data was committed in storage, then after a checkpoint &
    abnormal power-cut, db file will be corrupted forever.
    
    So this patch tries to improve atomic write flow by adding a revoking flow,
    once inner error occurs in committing, this gives another chance to try to
    revoke these partial submitted data of current transaction, it makes
    committing operation more like aotmical one.
    
    If we're not lucky, once revoking operation was failed, EAGAIN will be
    reported to user for suggesting doing the recovery with held journal file,
    or retrying current transaction again.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 5045dd6a27e9..0b30cd2aeebd 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -465,7 +465,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 			/* write dummy data page */
 			f2fs_replace_block(sbi, &dn, src, dest,
-							ni.version, false);
+						ni.version, false, false);
 			recovered++;
 		}
 	}

commit 81ca7350ce5ed438547ea769b0c33cb0abbd74ba
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Jan 26 15:39:35 2016 +0800

    f2fs: remove unneeded pointer conversion
    
    There are redundant pointer conversion in following call stack:
     - at position a, inode was been converted to f2fs_file_info.
     - at position b, f2fs_file_info was been converted to inode again.
    
     - truncate_blocks(inode,..)
      - fi = F2FS_I(inode)          ---a
      - ADDRS_PER_PAGE(node_page, fi)
       - addrs_per_inode(fi)
        - inode = &fi->vfs_inode    ---b
        - f2fs_has_inline_xattr(inode)
         - fi = F2FS_I(inode)
         - is_inode_flag_set(fi,..)
    
    In order to avoid unneeded conversion, alter ADDRS_PER_PAGE and
    addrs_per_inode to acept parameter with type of inode pointer.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 5a8fd4a99b11..5045dd6a27e9 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -350,8 +350,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 		inode = dn->inode;
 	}
 
-	bidx = start_bidx_of_node(offset, F2FS_I(inode)) +
-			le16_to_cpu(sum.ofs_in_node);
+	bidx = start_bidx_of_node(offset, inode) + le16_to_cpu(sum.ofs_in_node);
 
 	/*
 	 * if inode page is locked, unlock temporarily, but its reference
@@ -386,10 +385,9 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 					struct page *page, block_t blkaddr)
 {
-	struct f2fs_inode_info *fi = F2FS_I(inode);
-	unsigned int start, end;
 	struct dnode_of_data dn;
 	struct node_info ni;
+	unsigned int start, end;
 	int err = 0, recovered = 0;
 
 	/* step 1: recover xattr */
@@ -409,8 +407,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		goto out;
 
 	/* step 3: recover data indices */
-	start = start_bidx_of_node(ofs_of_node(page), fi);
-	end = start + ADDRS_PER_PAGE(page, fi);
+	start = start_bidx_of_node(ofs_of_node(page), inode);
+	end = start + ADDRS_PER_PAGE(page, inode);
 
 	set_new_dnode(&dn, inode, NULL, NULL, 0);
 

commit fec1d6576cdf2ce13f84fcdf7b20d02a05f76fc6
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Jan 20 23:43:51 2016 +0800

    f2fs: use wait_for_stable_page to avoid contention
    
    In write_begin, if storage supports stable_page, we don't need to wait for
    writeback to update its contents.
    This patch introduces to use wait_for_stable_page instead of
    wait_on_page_writeback.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 589b20b8677b..5a8fd4a99b11 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -418,7 +418,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	if (err)
 		goto out;
 
-	f2fs_wait_on_page_writeback(dn.node_page, NODE);
+	f2fs_wait_on_page_writeback(dn.node_page, NODE, true);
 
 	get_node_info(sbi, dn.nid, &ni);
 	f2fs_bug_on(sbi, ni.ino != ino_of_node(page));

commit c34f42e2cb2d27650549306de5ff36839e9177d6
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Dec 23 17:50:30 2015 +0800

    f2fs: report error of do_checkpoint
    
    do_checkpoint and write_checkpoint can fail due to reasons like triggering
    in a readonly fs or encountering IO error of storage device.
    
    So it's better to report such error info to user, let user be aware of
    failure of doing checkpoint.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 7fcb6e49deff..589b20b8677b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -623,7 +623,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 			.reason = CP_RECOVERY,
 		};
 		mutex_unlock(&sbi->cp_mutex);
-		write_checkpoint(sbi, &cpc);
+		err = write_checkpoint(sbi, &cpc);
 	} else {
 		mutex_unlock(&sbi->cp_mutex);
 	}

commit b7973f2378c619d0e17a075f13350bd58a9ebe3d
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Dec 1 11:43:59 2015 +0800

    f2fs: clean up argument of recover_data
    
    In recover_data, value of argument 'type' will be CURSEG_WARM_NODE all
    the time, remove it for cleanup.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index fad010faa859..7fcb6e49deff 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -488,8 +488,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	return err;
 }
 
-static int recover_data(struct f2fs_sb_info *sbi,
-				struct list_head *head, int type)
+static int recover_data(struct f2fs_sb_info *sbi, struct list_head *head)
 {
 	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
@@ -498,7 +497,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 	block_t blkaddr;
 
 	/* get node pages in the current segment */
-	curseg = CURSEG_I(sbi, type);
+	curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
 	while (1) {
@@ -585,7 +584,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	need_writecp = true;
 
 	/* step #2: recover data */
-	err = recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
+	err = recover_data(sbi, &inode_list);
 	if (!err)
 		f2fs_bug_on(sbi, !list_empty(&inode_list));
 out:

commit 807b1e1c8e08452948495b1a9985ab46d329e5c2
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Dec 3 14:14:40 2015 -0800

    f2fs: do not recover from previous remained wrong dnodes
    
    If device does not support discard, some obsolete dnodes can be recovered
    by roll-forward. This patch enhances the recovery flow.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index cbf74f47cce8..fad010faa859 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -168,6 +168,32 @@ static void recover_inode(struct inode *inode, struct page *page)
 			ino_of_node(page), name);
 }
 
+static bool is_same_inode(struct inode *inode, struct page *ipage)
+{
+	struct f2fs_inode *ri = F2FS_INODE(ipage);
+	struct timespec disk;
+
+	if (!IS_INODE(ipage))
+		return true;
+
+	disk.tv_sec = le64_to_cpu(ri->i_ctime);
+	disk.tv_nsec = le32_to_cpu(ri->i_ctime_nsec);
+	if (timespec_compare(&inode->i_ctime, &disk) > 0)
+		return false;
+
+	disk.tv_sec = le64_to_cpu(ri->i_atime);
+	disk.tv_nsec = le32_to_cpu(ri->i_atime_nsec);
+	if (timespec_compare(&inode->i_atime, &disk) > 0)
+		return false;
+
+	disk.tv_sec = le64_to_cpu(ri->i_mtime);
+	disk.tv_nsec = le32_to_cpu(ri->i_mtime_nsec);
+	if (timespec_compare(&inode->i_mtime, &disk) > 0)
+		return false;
+
+	return true;
+}
+
 static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 {
 	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
@@ -197,7 +223,10 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 			goto next;
 
 		entry = get_fsync_inode(head, ino_of_node(page));
-		if (!entry) {
+		if (entry) {
+			if (!is_same_inode(entry->inode, page))
+				goto next;
+		} else {
 			if (IS_INODE(page) && is_dent_dnode(page)) {
 				err = recover_inode_page(sbi, page);
 				if (err)

commit 26879fb101f28c554294eaf25ac7817a2825b180
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Oct 12 17:05:59 2015 +0800

    f2fs: support lower priority asynchronous readahead in ra_meta_pages
    
    Now, we use ra_meta_pages to reads continuous physical blocks as much as
    possible to improve performance of following reads. However, ra_meta_pages
    uses a synchronous readahead approach by submitting bio with READ, as READ
    is with high priority, it can not be used in the case of preloading blocks,
    and it's not sure when these RAed pages will be used.
    
    This patch supports asynchronous readahead in ra_meta_pages by tagging bio
    with READA flag in order to allow preloading.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 75dbc0708c7b..cbf74f47cce8 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -180,7 +180,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 	curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
-	ra_meta_pages(sbi, blkaddr, 1, META_POR);
+	ra_meta_pages(sbi, blkaddr, 1, META_POR, true);
 
 	while (1) {
 		struct fsync_inode_entry *entry;

commit 2b947003fa98d5a39f3b21214380d0b1daf750b5
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Oct 12 17:04:21 2015 +0800

    f2fs: don't tag REQ_META for temporary non-meta pages
    
    In recovery or checkpoint flow, we grab pages temperarily in meta inode's
    mapping for caching temperary data, actually, datas in these pages were
    not meta data of f2fs, but still we tag them with REQ_META flag. However,
    lower device like eMMC may do some optimization for data of such type.
    So in order to avoid wrong optimization, we'd better remove such flag
    for temperary non-meta pages.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index c5daec503e7f..75dbc0708c7b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -188,7 +188,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 		if (!is_valid_blkaddr(sbi, blkaddr, META_POR))
 			return 0;
 
-		page = get_meta_page(sbi, blkaddr);
+		page = get_tmp_page(sbi, blkaddr);
 
 		if (cp_ver != cpver_of_node(page))
 			break;
@@ -480,7 +480,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 
 		ra_meta_pages_cond(sbi, blkaddr);
 
-		page = get_meta_page(sbi, blkaddr);
+		page = get_tmp_page(sbi, blkaddr);
 
 		if (cp_ver != cpver_of_node(page)) {
 			f2fs_put_page(page, 1);

commit 7223554133c3f72809ea6ddbf0d8464e7c70c1b1
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Fri Sep 25 17:54:56 2015 +0800

    f2fs: remove unneeded f2fs_{,un}lock_op in do_recover_data()
    
    Protecting recovery flow by using cp_rwsem is not needed, since we have
    prevent triggering any checkpoint by locking cp_mutex previously.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index acc21f20637b..c5daec503e7f 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -383,15 +383,11 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	start = start_bidx_of_node(ofs_of_node(page), fi);
 	end = start + ADDRS_PER_PAGE(page, fi);
 
-	f2fs_lock_op(sbi);
-
 	set_new_dnode(&dn, inode, NULL, NULL, 0);
 
 	err = get_dnode_of_data(&dn, start, ALLOC_NODE);
-	if (err) {
-		f2fs_unlock_op(sbi);
+	if (err)
 		goto out;
-	}
 
 	f2fs_wait_on_page_writeback(dn.node_page, NODE);
 
@@ -456,7 +452,6 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	set_page_dirty(dn.node_page);
 err:
 	f2fs_put_dnode(&dn);
-	f2fs_unlock_op(sbi);
 out:
 	f2fs_msg(sbi->sb, KERN_NOTICE,
 		"recover_data: ino = %lx, recovered = %d blocks, err = %d",

commit 9edcdabf36422d15d01db73b0fa5487e418beff6
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Fri Sep 11 14:43:52 2015 +0800

    f2fs: fix overflow of size calculation
    
    We have potential overflow issue when calculating size of object, when
    we left shift index with PAGE_CACHE_SHIFT bits, if type of index has only
    32-bits space in 32-bit architecture, left shifting will incur overflow,
    i.e:
    
    pgoff_t index =  0xFFFFFFFF;
    loff_t size = index << PAGE_CACHE_SHIFT;
    size: 0xFFFFF000
    
    So we should cast index with 64-bits type to avoid this issue.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index faec2ca004b9..acc21f20637b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -570,7 +570,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	/* truncate meta pages to be used by the recovery */
 	truncate_inode_pages_range(META_MAPPING(sbi),
-			MAIN_BLKADDR(sbi) << PAGE_CACHE_SHIFT, -1);
+			(loff_t)MAIN_BLKADDR(sbi) << PAGE_CACHE_SHIFT, -1);
 
 	if (err) {
 		truncate_inode_pages_final(NODE_MAPPING(sbi));

commit 315df8398e36360c0be62e6fdd3f2708fc3a2567
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Aug 11 12:45:39 2015 -0700

    f2fs: do not write any node pages related to orphan inodes
    
    We should not write node pages when deleting orphan inodes.
    In order to do that, we can eaisly set POR_DOING flag earlier before entering
    orphan inode routine.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d2ef0c9f53e7..faec2ca004b9 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -545,14 +545,12 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	INIT_LIST_HEAD(&inode_list);
 
-	/* step #1: find fsynced inode numbers */
-	set_sbi_flag(sbi, SBI_POR_DOING);
-
 	/* prevent checkpoint */
 	mutex_lock(&sbi->cp_mutex);
 
 	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
+	/* step #1: find fsynced inode numbers */
 	err = find_fsync_dnodes(sbi, &inode_list);
 	if (err)
 		goto out;

commit 12a8343e99a8af50b2a1cd8da72d34b6e860da0f
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Aug 5 17:23:54 2015 +0800

    f2fs: recover invalid/reserved block address for fsynced file
    
    When testing with generic/101 in xfstests, error message outputed as below:
    
        --- tests/generic/101.out
        +++ results//generic/101.out.bad
        @@ -10,10 +10,14 @@
         File foo content after log replay:
         0000000 aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa
         *
        -0200000 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
        +0200000 bb bb bb bb bb bb bb bb bb bb bb bb bb bb bb bb
         *
         0372000
        ...
        (Run 'diff -u tests/generic/101.out results/generic/101.out.bad'  to see the entire diff)
    
    The test flow is like below:
    1. pwrite foo -S 0xaa 0 64K
    2. pwrite foo -S 0xbb 64K 61K
    3. sync
    4. truncate foo 64K
    5. truncate foo 125K
    6. fsync foo
    7. flakey drop writes
    8. umount
    
    After this test, we expect the data of recovered file will have the first
    64k of data filling with value 0xaa and the next 61k of data filling with
    value 0x00 because we have fsynced it before dropping writes in dm.
    
    In f2fs, during recovering, we will only recover the valid block address
    in direct node page if it is marked as a fsynced dnode, but block address
    which means invalid/reserved (with value NULL_ADDR/NEW_ADDR) will not be
    recovered. So, the file recovered shows its incorrect data 0xbb in range of
    [61k, 125k].
    
    In this patch, we fix to recover invalid/reserved block during recover flow.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 07a36e413ace..d2ef0c9f53e7 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -399,14 +399,35 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	f2fs_bug_on(sbi, ni.ino != ino_of_node(page));
 	f2fs_bug_on(sbi, ofs_of_node(dn.node_page) != ofs_of_node(page));
 
-	for (; start < end; start++) {
+	for (; start < end; start++, dn.ofs_in_node++) {
 		block_t src, dest;
 
 		src = datablock_addr(dn.node_page, dn.ofs_in_node);
 		dest = datablock_addr(page, dn.ofs_in_node);
 
-		if (src != dest && dest != NEW_ADDR && dest != NULL_ADDR &&
-			is_valid_blkaddr(sbi, dest, META_POR)) {
+		/* skip recovering if dest is the same as src */
+		if (src == dest)
+			continue;
+
+		/* dest is invalid, just invalidate src block */
+		if (dest == NULL_ADDR) {
+			truncate_data_blocks_range(&dn, 1);
+			continue;
+		}
+
+		/*
+		 * dest is reserved block, invalidate src block
+		 * and then reserve one new block in dnode page.
+		 */
+		if (dest == NEW_ADDR) {
+			truncate_data_blocks_range(&dn, 1);
+			err = reserve_new_block(&dn);
+			f2fs_bug_on(sbi, err);
+			continue;
+		}
+
+		/* dest is valid block, try to recover from src to dest */
+		if (is_valid_blkaddr(sbi, dest, META_POR)) {
 
 			if (src == NULL_ADDR) {
 				err = reserve_new_block(&dn);
@@ -424,7 +445,6 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 							ni.version, false);
 			recovered++;
 		}
-		dn.ofs_in_node++;
 	}
 
 	if (IS_INODE(dn.node_page))

commit e90c2d2850d9d034e814a328725a4b15878f0357
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Jul 28 18:36:47 2015 +0800

    f2fs: invalidate temporary meta page
    
    To avoid meeting garbage data in next free node block at the end of warm
    node chain when doing recovery, we will try to zero out that invalid block.
    
    If the device is not support discard, our way for zeroing out block is:
    grabbing a temporary zeroed page in meta inode, then, issue write request
    with this page.
    
    But, we forget to release that temporary page, so our memory usage will
    increase without gaining any hit ratio benefit, so it's better to free it
    for saving memory.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 24a8c1d4f45f..07a36e413ace 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -561,11 +561,20 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	clear_sbi_flag(sbi, SBI_POR_DOING);
 	if (err) {
-		discard_next_dnode(sbi, blkaddr);
+		bool invalidate = false;
+
+		if (discard_next_dnode(sbi, blkaddr))
+			invalidate = true;
 
 		/* Flush all the NAT/SIT pages */
 		while (get_pages(sbi, F2FS_DIRTY_META))
 			sync_meta_pages(sbi, META, LONG_MAX);
+
+		/* invalidate temporary meta page */
+		if (invalidate)
+			invalidate_mapping_pages(META_MAPPING(sbi),
+							blkaddr, blkaddr);
+
 		set_ckpt_flags(sbi->ckpt, CP_ERROR_FLAG);
 		mutex_unlock(&sbi->cp_mutex);
 	} else if (need_writecp) {

commit 528e34593d6eff11a289ef23452c66175a340f0b
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu May 28 19:15:35 2015 +0800

    f2fs: hide common code in f2fs_replace_block
    
    This patch clean up codes through:
    1.rename f2fs_replace_block to __f2fs_replace_block().
    2.introduce new f2fs_replace_block() to include __f2fs_replace_block()
    and some common related codes around __f2fs_replace_block().
    
    Then, newly introduced function f2fs_replace_block can be used by
    following patch.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 9de25878db2b..24a8c1d4f45f 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -360,7 +360,6 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	struct f2fs_inode_info *fi = F2FS_I(inode);
 	unsigned int start, end;
 	struct dnode_of_data dn;
-	struct f2fs_summary sum;
 	struct node_info ni;
 	int err = 0, recovered = 0;
 
@@ -420,13 +419,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			if (err)
 				goto err;
 
-			set_summary(&sum, dn.nid, dn.ofs_in_node, ni.version);
-
 			/* write dummy data page */
-			f2fs_replace_block(sbi, &sum, src, dest, false);
-			dn.data_blkaddr = dest;
-			set_data_blkaddr(&dn);
-			f2fs_update_extent_cache(&dn);
+			f2fs_replace_block(sbi, &dn, src, dest,
+							ni.version, false);
 			recovered++;
 		}
 		dn.ofs_in_node++;

commit e7d5545285ededcf73dc7cbb9b7c65d0259f2b44
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Apr 29 17:02:18 2015 -0700

    f2fs crypto: add filename encryption for roll-forward recovery
    
    This patch adds a bit flag to indicate whether or not i_name in the inode
    is encrypted.
    
    If this name is encrypted, we can't do recover_dentry during roll-forward.
    So, f2fs_sync_file() needs to do checkpoint, if this will be needed in future.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index f77a1beac783..9de25878db2b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -83,6 +83,11 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 		goto out;
 	}
 
+	if (file_enc_name(inode)) {
+		iput(dir);
+		return 0;
+	}
+
 	name.len = le32_to_cpu(raw_inode->i_namelen);
 	name.name = raw_inode->i_name;
 
@@ -143,6 +148,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 static void recover_inode(struct inode *inode, struct page *page)
 {
 	struct f2fs_inode *raw = F2FS_INODE(page);
+	char *name;
 
 	inode->i_mode = le16_to_cpu(raw->i_mode);
 	i_size_write(inode, le64_to_cpu(raw->i_size));
@@ -153,8 +159,13 @@ static void recover_inode(struct inode *inode, struct page *page)
 	inode->i_ctime.tv_nsec = le32_to_cpu(raw->i_ctime_nsec);
 	inode->i_mtime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);
 
+	if (file_enc_name(inode))
+		name = "<encrypted>";
+	else
+		name = F2FS_INODE(page)->i_name;
+
 	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode: ino = %x, name = %s",
-			ino_of_node(page), F2FS_INODE(page)->i_name);
+			ino_of_node(page), name);
 }
 
 static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)

commit 19f106bc03e62739961249a29916ee3602ac3de9
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed May 6 13:08:06 2015 +0800

    f2fs: introduce f2fs_replace_block() for reuse
    
    Introduce a generic function replace_block base on recover_data_page,
    and export it. So with it we can operate file's meta data which is in
    CP/SSA area when we invoke fallocate with FALLOC_FL_COLLAPSE_RANGE
    flag.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b80d9d48f125..f77a1beac783 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -412,7 +412,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			set_summary(&sum, dn.nid, dn.ofs_in_node, ni.version);
 
 			/* write dummy data page */
-			recover_data_page(sbi, NULL, &sum, src, dest);
+			f2fs_replace_block(sbi, &sum, src, dest, false);
 			dn.data_blkaddr = dest;
 			set_data_blkaddr(&dn);
 			f2fs_update_extent_cache(&dn);

commit f0c9cadae6706b6ce00ef724121fbf0f34187e22
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sat Apr 18 18:05:36 2015 +0800

    f2fs: use is_valid_blkaddr to verify blkaddr for readability
    
    Export is_valid_blkaddr() and use it to replace some codes for readability.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 8d8ea99f2156..b80d9d48f125 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -174,7 +174,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (blkaddr < MAIN_BLKADDR(sbi) || blkaddr >= MAX_BLKADDR(sbi))
+		if (!is_valid_blkaddr(sbi, blkaddr, META_POR))
 			return 0;
 
 		page = get_meta_page(sbi, blkaddr);
@@ -396,7 +396,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		dest = datablock_addr(page, dn.ofs_in_node);
 
 		if (src != dest && dest != NEW_ADDR && dest != NULL_ADDR &&
-			dest >= MAIN_BLKADDR(sbi) && dest < MAX_BLKADDR(sbi)) {
+			is_valid_blkaddr(sbi, dest, META_POR)) {
 
 			if (src == NULL_ADDR) {
 				err = reserve_new_block(&dn);
@@ -454,7 +454,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (blkaddr < MAIN_BLKADDR(sbi) || blkaddr >= MAX_BLKADDR(sbi))
+		if (!is_valid_blkaddr(sbi, blkaddr, META_POR))
 			break;
 
 		ra_meta_pages_cond(sbi, blkaddr);

commit 10027551ccf5459cc771c31ac8bc8e5cc8db45f8
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Apr 9 17:03:53 2015 -0700

    f2fs: pass checkpoint reason on roll-forward recovery
    
    This patch adds CP_RECOVERY to remain recovery information for checkpoint.
    And, it makes sure writing checkpoint in this case.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 4b742c96c223..8d8ea99f2156 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -564,7 +564,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 		mutex_unlock(&sbi->cp_mutex);
 	} else if (need_writecp) {
 		struct cp_control cpc = {
-			.reason = CP_SYNC,
+			.reason = CP_RECOVERY,
 		};
 		mutex_unlock(&sbi->cp_mutex);
 		write_checkpoint(sbi, &cpc);

commit e03b07d9084d03e896b7f1a598a7f6aa18f6eeda
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Apr 1 19:38:20 2015 -0700

    f2fs: do not recover wrong data index
    
    During the roll-forward recovery, if we found a new data index written fsync
    lastly, we need to recover new block address.
    But, if that address was corrupted, we should not recover that.
    Otherwise, f2fs gets kernel panic from:
    
     In check_index_in_prev_nodes(),
    
        sentry = get_seg_entry(sbi, segno);
                 --------------------------> out-of-range segno.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 63b720bd7e75..4b742c96c223 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -395,7 +395,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		src = datablock_addr(dn.node_page, dn.ofs_in_node);
 		dest = datablock_addr(page, dn.ofs_in_node);
 
-		if (src != dest && dest != NEW_ADDR && dest != NULL_ADDR) {
+		if (src != dest && dest != NEW_ADDR && dest != NULL_ADDR &&
+			dest >= MAIN_BLKADDR(sbi) && dest < MAX_BLKADDR(sbi)) {
+
 			if (src == NULL_ADDR) {
 				err = reserve_new_block(&dn);
 				/* We should not get -ENOSPC */

commit 418f6c277011d89c394309e72df9ad058e0a3f7d
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Mar 31 18:03:29 2015 -0700

    f2fs: do not increase link count during recovery
    
    If there are multiple fsynced dnodes having a dent flag, roll-forward routine
    sets FI_INC_LINK for their inode, and recovery_dentry increases its link count
    accordingly.
    That results in normal file having a link count as 2, so we can't unlink those
    files.
    
    This was added to handle several inode blocks having same inode number with
    different directory paths.
    But, current f2fs doesn't replay all of path changes and only recover its dentry
    for the last fsynced inode block.
    So, there is no reason to do this.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 679c465e9def..63b720bd7e75 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -93,10 +93,9 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 	}
 retry:
 	de = f2fs_find_entry(dir, &name, &page);
-	if (de && inode->i_ino == le32_to_cpu(de->ino)) {
-		clear_inode_flag(F2FS_I(inode), FI_INC_LINK);
+	if (de && inode->i_ino == le32_to_cpu(de->ino))
 		goto out_unmap_put;
-	}
+
 	if (de) {
 		einode = f2fs_iget(inode->i_sb, le32_to_cpu(de->ino));
 		if (IS_ERR(einode)) {
@@ -187,11 +186,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 			goto next;
 
 		entry = get_fsync_inode(head, ino_of_node(page));
-		if (entry) {
-			if (IS_INODE(page) && is_dent_dnode(page))
-				set_inode_flag(F2FS_I(entry->inode),
-							FI_INC_LINK);
-		} else {
+		if (!entry) {
 			if (IS_INODE(page) && is_dent_dnode(page)) {
 				err = recover_inode_page(sbi, page);
 				if (err)

commit 510022a85839a8409d1e6a519bb86ce71a84f30a
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Mar 30 15:07:16 2015 -0700

    f2fs: add F2FS_INLINE_DOTS to recover missing dot dentries
    
    If f2fs was corrupted with missing dot dentries, it needs to recover them after
    fsck.f2fs detection.
    
    The underlying precedure is:
    
    1. The fsck.f2fs remains F2FS_INLINE_DOTS flag in directory inode, if it detects
    missing dot dentries.
    
    2. When f2fs looks up the corrupted directory, it triggers f2fs_add_link with
    proper inode numbers and their dot and dotdot names.
    
    3. Once f2fs recovers the directory without errors, it removes F2FS_INLINE_DOTS
    finally.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index c69de88a6453..679c465e9def 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -115,7 +115,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 		iput(einode);
 		goto retry;
 	}
-	err = __f2fs_add_link(dir, &name, inode);
+	err = __f2fs_add_link(dir, &name, inode, inode->i_ino, inode->i_mode);
 	if (err)
 		goto out_err;
 

commit c9ef481097d17fb8ff8ea7930ce715b5a676f10f
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Mar 26 18:46:38 2015 -0700

    f2fs: fix mismatching lock and unlock pages for roll-forward recovery
    
    Previously, inode page is not correctly locked and unlocked in pair during
    the roll-forward recovery.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index e60ffaa380f1..c69de88a6453 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -258,6 +258,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	struct f2fs_summary_block *sum_node;
 	struct f2fs_summary sum;
 	struct page *sum_page, *node_page;
+	struct dnode_of_data tdn = *dn;
 	nid_t ino, nid;
 	struct inode *inode;
 	unsigned int offset;
@@ -285,17 +286,15 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	/* Use the locked dnode page and inode */
 	nid = le32_to_cpu(sum.nid);
 	if (dn->inode->i_ino == nid) {
-		struct dnode_of_data tdn = *dn;
 		tdn.nid = nid;
+		if (!dn->inode_page_locked)
+			lock_page(dn->inode_page);
 		tdn.node_page = dn->inode_page;
 		tdn.ofs_in_node = le16_to_cpu(sum.ofs_in_node);
-		truncate_data_blocks_range(&tdn, 1);
-		return 0;
+		goto truncate_out;
 	} else if (dn->nid == nid) {
-		struct dnode_of_data tdn = *dn;
 		tdn.ofs_in_node = le16_to_cpu(sum.ofs_in_node);
-		truncate_data_blocks_range(&tdn, 1);
-		return 0;
+		goto truncate_out;
 	}
 
 	/* Get the node page */
@@ -319,18 +318,33 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	bidx = start_bidx_of_node(offset, F2FS_I(inode)) +
 			le16_to_cpu(sum.ofs_in_node);
 
-	if (ino != dn->inode->i_ino) {
-		truncate_hole(inode, bidx, bidx + 1);
+	/*
+	 * if inode page is locked, unlock temporarily, but its reference
+	 * count keeps alive.
+	 */
+	if (ino == dn->inode->i_ino && dn->inode_page_locked)
+		unlock_page(dn->inode_page);
+
+	set_new_dnode(&tdn, inode, NULL, NULL, 0);
+	if (get_dnode_of_data(&tdn, bidx, LOOKUP_NODE))
+		goto out;
+
+	if (tdn.data_blkaddr == blkaddr)
+		truncate_data_blocks_range(&tdn, 1);
+
+	f2fs_put_dnode(&tdn);
+out:
+	if (ino != dn->inode->i_ino)
 		iput(inode);
-	} else {
-		struct dnode_of_data tdn;
-		set_new_dnode(&tdn, inode, dn->inode_page, NULL, 0);
-		if (get_dnode_of_data(&tdn, bidx, LOOKUP_NODE))
-			return 0;
-		if (tdn.data_blkaddr != NULL_ADDR)
-			truncate_data_blocks_range(&tdn, 1);
-		f2fs_put_page(tdn.node_page, 1);
-	}
+	else if (dn->inode_page_locked)
+		lock_page(dn->inode_page);
+	return 0;
+
+truncate_out:
+	if (datablock_addr(tdn.node_page, tdn.ofs_in_node) == blkaddr)
+		truncate_data_blocks_range(&tdn, 1);
+	if (dn->inode->i_ino == nid && !dn->inode_page_locked)
+		unlock_page(dn->inode_page);
 	return 0;
 }
 

commit 216a620a7c3d35ae604ba519c99c5cd1ce4dad6e
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Mar 19 19:23:32 2015 +0800

    f2fs: split set_data_blkaddr from f2fs_update_extent_cache
    
    Split __set_data_blkaddr from f2fs_update_extent_cache for readability.
    
    Additionally rename __set_data_blkaddr to set_data_blkaddr for exporting.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 6e40874dfbb9..e60ffaa380f1 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -403,6 +403,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			/* write dummy data page */
 			recover_data_page(sbi, NULL, &sum, src, dest);
 			dn.data_blkaddr = dest;
+			set_data_blkaddr(&dn);
 			f2fs_update_extent_cache(&dn);
 			recovered++;
 		}

commit 8fbc418f99caf65a53f3921ac2a32a0a0af7aba2
Author: Jaegeuk Kim <jaegeuk@motorola.com>
Date:   Tue Feb 24 18:01:46 2015 -0800

    f2fs: avoid wrong error during recovery
    
    During the roll-forward recovery, -ENOENT for f2fs_iget can be skipped.
    So, this error value should not be propagated.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b2a92d47c5d7..6e40874dfbb9 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -212,8 +212,10 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 			if (IS_ERR(entry->inode)) {
 				err = PTR_ERR(entry->inode);
 				kmem_cache_free(fsync_entry_slab, entry);
-				if (err == -ENOENT)
+				if (err == -ENOENT) {
+					err = 0;
 					goto next;
+				}
 				break;
 			}
 			list_add_tail(&entry->list, head);

commit 1614091dc1551d1ddeda7420df8ab5ad89b04987
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Feb 23 19:59:52 2015 -0800

    f2fs: remove obsolete code
    
    This patch removes obsolete code in which summary variable is not needed.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 188a03449c5c..b2a92d47c5d7 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -407,8 +407,6 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		dn.ofs_in_node++;
 	}
 
-	/* write node page in place */
-	set_summary(&sum, dn.nid, 0, 0);
 	if (IS_INODE(dn.node_page))
 		sync_inode_page(&dn);
 

commit 7e4dde79df7cdf8b40282857e030c7572ff04886
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Feb 5 17:51:34 2015 +0800

    f2fs: introduce universal lookup/update interface for extent cache
    
    In this patch, we do these jobs:
    1. rename {check,update}_extent_cache to {lookup,update}_extent_info;
    2. introduce universal lookup/update interface of extent cache:
    f2fs_{lookup,update}_extent_cache including above two real functions, then
    export them to function callers.
    
    So after above cleanup, we can add new rb-tree based extent cache into exported
    interfaces.
    
    v2:
     o remove "f2fs_" for inner function {lookup,update}_extent_info suggested by
       Jaegeuk Kim.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 41afb9534bbd..188a03449c5c 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -401,7 +401,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			/* write dummy data page */
 			recover_data_page(sbi, NULL, &sum, src, dest);
 			dn.data_blkaddr = dest;
-			update_extent_cache(&dn);
+			f2fs_update_extent_cache(&dn);
 			recovered++;
 		}
 		dn.ofs_in_node++;

commit caf0047e7e1e60a7ad1d655d3b81b32e2dfb6095
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Jan 28 17:48:42 2015 +0800

    f2fs: merge flags in struct f2fs_sb_info
    
    Currently, there are several variables with Boolean type as below:
    
    struct f2fs_sb_info {
    ...
            int s_dirty;
            bool need_fsck;
            bool s_closing;
    ...
            bool por_doing;
    ...
    }
    
    For this there are some issues:
    1. there are some space of f2fs_sb_info is wasted due to aligning after Boolean
       type variables by compiler.
    2. if we continuously add new flag into f2fs_sb_info, structure will be messed
       up.
    
    So in this patch, we try to:
    1. switch s_dirty to Boolean type variable since it has two status 0/1.
    2. merge s_dirty/need_fsck/s_closing/por_doing variables into s_flag.
    3. introduce an enum type which can indicate different states of sbi.
    4. use new introduced universal interfaces is_sbi_flag_set/{set,clear}_sbi_flag
       to operate flags for sbi.
    
    After that, above issues will be fixed.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 57603a7127f7..41afb9534bbd 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -508,7 +508,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	INIT_LIST_HEAD(&inode_list);
 
 	/* step #1: find fsynced inode numbers */
-	sbi->por_doing = true;
+	set_sbi_flag(sbi, SBI_POR_DOING);
 
 	/* prevent checkpoint */
 	mutex_lock(&sbi->cp_mutex);
@@ -541,7 +541,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 		truncate_inode_pages_final(META_MAPPING(sbi));
 	}
 
-	sbi->por_doing = false;
+	clear_sbi_flag(sbi, SBI_POR_DOING);
 	if (err) {
 		discard_next_dnode(sbi, blkaddr);
 

commit bc4a1f873b9db010f5b0971ee5f2987d9be32c36
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jan 22 14:48:28 2015 -0800

    f2fs: leave comment for code readability
    
    During the recovery, any xattr blocks should not be found, since they are
    written into cold log, not the warm node chain.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index c4211a5862df..57603a7127f7 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -346,6 +346,10 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	if (IS_INODE(page)) {
 		recover_inline_xattr(inode, page);
 	} else if (f2fs_has_xattr_block(ofs_of_node(page))) {
+		/*
+		 * Deprecated; xattr blocks should be found from cold log.
+		 * But, we should remain this for backward compatibility.
+		 */
 		recover_xattr_data(inode, page, blkaddr);
 		goto out;
 	}

commit e1509cf294cc670cda1fedd430f0ff175c42b591
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Dec 30 22:57:55 2014 -0800

    f2fs: clean up to remove parameter
    
    This patch uses dn->data_blkaddr as a parameter for the destination block
    address.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 9160a37e1c7a..c4211a5862df 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -396,7 +396,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 			/* write dummy data page */
 			recover_data_page(sbi, NULL, &sum, src, dest);
-			update_extent_cache(dest, &dn);
+			dn.data_blkaddr = dest;
+			update_extent_cache(&dn);
 			recovered++;
 		}
 		dn.ofs_in_node++;

commit 635aee1fefef921ae4124b127fced62ea6008839
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Dec 8 15:02:52 2014 +0800

    f2fs: avoid to ra unneeded blocks in recover flow
    
    To improve recovery speed, f2fs try to readahead many contiguous blocks in warm
    node segment, but for most time, abnormal power-off do not occur frequently, so
    when mount a normal power-off f2fs image, by contrary ra so many blocks and then
    invalid them will hurt the performance of mount.
    It's better to just ra the first next-block for normal condition.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 9a93a6e29b05..9160a37e1c7a 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -170,13 +170,15 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 	curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
+	ra_meta_pages(sbi, blkaddr, 1, META_POR);
+
 	while (1) {
 		struct fsync_inode_entry *entry;
 
 		if (blkaddr < MAIN_BLKADDR(sbi) || blkaddr >= MAX_BLKADDR(sbi))
 			return 0;
 
-		page = get_meta_page_ra(sbi, blkaddr);
+		page = get_meta_page(sbi, blkaddr);
 
 		if (cp_ver != cpver_of_node(page))
 			break;
@@ -227,6 +229,8 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
 		f2fs_put_page(page, 1);
+
+		ra_meta_pages_cond(sbi, blkaddr);
 	}
 	f2fs_put_page(page, 1);
 	return err;
@@ -436,7 +440,9 @@ static int recover_data(struct f2fs_sb_info *sbi,
 		if (blkaddr < MAIN_BLKADDR(sbi) || blkaddr >= MAX_BLKADDR(sbi))
 			break;
 
-		page = get_meta_page_ra(sbi, blkaddr);
+		ra_meta_pages_cond(sbi, blkaddr);
+
+		page = get_meta_page(sbi, blkaddr);
 
 		if (cp_ver != cpver_of_node(page)) {
 			f2fs_put_page(page, 1);

commit 9486ba442b00a6b227bfe0d66b0f4dbcd1a2ee91
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Nov 21 16:36:28 2014 -0800

    f2fs: introduce f2fs_dentry_kunmap to clean up
    
    This patch introduces f2fs_dentry_kunmap to clean up dirty codes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 4b180bbc3a21..9a93a6e29b05 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -129,8 +129,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 	goto out;
 
 out_unmap_put:
-	if (!f2fs_has_inline_dentry(dir))
-		kunmap(page);
+	f2fs_dentry_kunmap(dir, page);
 	f2fs_put_page(page, 0);
 out_err:
 	iput(dir);

commit 622f28ae9ba4fa89b4ff0f4a6cf75d153ea838ce
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Sep 24 18:19:10 2014 +0800

    f2fs: enable inline dir handling
    
    Add inline dir functions into normal dir ops' function to handle inline ops.
    Besides, we enable inline dir mode when a new dir inode is created if
    inline_data option is on.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 843da53ed7d5..4b180bbc3a21 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -129,7 +129,8 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 	goto out;
 
 out_unmap_put:
-	kunmap(page);
+	if (!f2fs_has_inline_dentry(dir))
+		kunmap(page);
 	f2fs_put_page(page, 0);
 out_err:
 	iput(dir);

commit dbeacf02ebfed8161ac0b9379892262593c9a734
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Sep 24 18:17:04 2014 +0800

    f2fs: export dir operations for inline dir
    
    This patch exports some dir operations for inline dir, additionally introduces
    f2fs_drop_nlink from f2fs_delete_entry for reusing by inline dir function.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index ebd013225788..843da53ed7d5 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -111,7 +111,7 @@ static int recover_dentry(struct inode *inode, struct page *ipage)
 			iput(einode);
 			goto out_unmap_put;
 		}
-		f2fs_delete_entry(de, page, einode);
+		f2fs_delete_entry(de, page, dir, einode);
 		iput(einode);
 		goto retry;
 	}

commit 7cd8558baa4e4588a80ecb31cb30784195763cdd
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Sep 23 11:23:01 2014 -0700

    f2fs: check the use of macros on block counts and addresses
    
    This patch cleans up the existing and new macros for readability.
    
    Rule is like this.
    
             ,-----------------------------------------> MAX_BLKADDR -,
             |  ,------------- TOTAL_BLKS ----------------------------,
             |  |                                                     |
             |  ,- seg0_blkaddr   ,----- sit/nat/ssa/main blkaddress  |
    block    |  | (SEG0_BLKADDR)  | | | |   (e.g., MAIN_BLKADDR)      |
    address  0..x................ a b c d .............................
                |                                                     |
    global seg# 0...................... m .............................
                |                       |                             |
                |                       `------- MAIN_SEGS -----------'
                `-------------- TOTAL_SEGS ---------------------------'
                                        |                             |
     seg#                               0..........xx..................
    
    = Note =
     o GET_SEGNO_FROM_SEG0 : blk address -> global segno
     o GET_SEGNO           : blk address -> segno
     o START_BLOCK         : segno -> starting block address
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 947b92273d08..ebd013225788 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -173,8 +173,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (blkaddr < SM_I(sbi)->main_blkaddr ||
-			blkaddr >= (SM_I(sbi)->seg0_blkaddr + TOTAL_BLKS(sbi)))
+		if (blkaddr < MAIN_BLKADDR(sbi) || blkaddr >= MAX_BLKADDR(sbi))
 			return 0;
 
 		page = get_meta_page_ra(sbi, blkaddr);
@@ -434,8 +433,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (blkaddr < SM_I(sbi)->main_blkaddr ||
-			blkaddr >= (SM_I(sbi)->seg0_blkaddr + TOTAL_BLKS(sbi)))
+		if (blkaddr < MAIN_BLKADDR(sbi) || blkaddr >= MAX_BLKADDR(sbi))
 			break;
 
 		page = get_meta_page_ra(sbi, blkaddr);
@@ -525,7 +523,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	/* truncate meta pages to be used by the recovery */
 	truncate_inode_pages_range(META_MAPPING(sbi),
-		SM_I(sbi)->main_blkaddr << PAGE_CACHE_SHIFT, -1);
+			MAIN_BLKADDR(sbi) << PAGE_CACHE_SHIFT, -1);
 
 	if (err) {
 		truncate_inode_pages_final(NODE_MAPPING(sbi));

commit 75ab4cb8301adb3a02a96c5c03c837ed941f1bc5
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Sat Sep 20 21:57:51 2014 -0700

    f2fs: introduce cp_control structure
    
    This patch add a new data structure to control checkpoint parameters.
    Currently, it presents the reason of checkpoint such as is_umount and normal
    sync.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 39c4ff69990e..947b92273d08 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -542,8 +542,11 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 		set_ckpt_flags(sbi->ckpt, CP_ERROR_FLAG);
 		mutex_unlock(&sbi->cp_mutex);
 	} else if (need_writecp) {
+		struct cp_control cpc = {
+			.reason = CP_SYNC,
+		};
 		mutex_unlock(&sbi->cp_mutex);
-		write_checkpoint(sbi, false);
+		write_checkpoint(sbi, &cpc);
 	} else {
 		mutex_unlock(&sbi->cp_mutex);
 	}

commit c52e1b10b175bef84f1681946b4a438cc4c84147
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Sep 11 14:29:06 2014 -0700

    f2fs: remove redundant operation during roll-forward recovery
    
    If same data is updated multiple times, we don't need to redo whole the
    operations.
    Let's just update the lastest one.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 39832833c02f..39c4ff69990e 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -67,7 +67,7 @@ static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
 	return NULL;
 }
 
-static int recover_dentry(struct page *ipage, struct inode *inode)
+static int recover_dentry(struct inode *inode, struct page *ipage)
 {
 	struct f2fs_inode *raw_inode = F2FS_INODE(ipage);
 	nid_t pino = le32_to_cpu(raw_inode->i_pino);
@@ -141,7 +141,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	return err;
 }
 
-static void __recover_inode(struct inode *inode, struct page *page)
+static void recover_inode(struct inode *inode, struct page *page)
 {
 	struct f2fs_inode *raw = F2FS_INODE(page);
 
@@ -153,21 +153,9 @@ static void __recover_inode(struct inode *inode, struct page *page)
 	inode->i_atime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);
 	inode->i_ctime.tv_nsec = le32_to_cpu(raw->i_ctime_nsec);
 	inode->i_mtime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);
-}
-
-static int recover_inode(struct inode *inode, struct page *node_page)
-{
-	if (!IS_INODE(node_page))
-		return 0;
-
-	__recover_inode(inode, node_page);
-
-	if (is_dent_dnode(node_page))
-		return recover_dentry(node_page, inode);
 
 	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode: ino = %x, name = %s",
-			ino_of_node(node_page), F2FS_INODE(node_page)->i_name);
-	return 0;
+			ino_of_node(page), F2FS_INODE(page)->i_name);
 }
 
 static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
@@ -210,12 +198,11 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 			}
 
 			/* add this fsync inode to the list */
-			entry = kmem_cache_alloc(fsync_entry_slab, GFP_NOFS);
+			entry = kmem_cache_alloc(fsync_entry_slab, GFP_F2FS_ZERO);
 			if (!entry) {
 				err = -ENOMEM;
 				break;
 			}
-
 			/*
 			 * CP | dnode(F) | inode(DF)
 			 * For this case, we should not give up now.
@@ -232,9 +219,11 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 		}
 		entry->blkaddr = blkaddr;
 
-		err = recover_inode(entry->inode, page);
-		if (err && err != -ENOENT)
-			break;
+		if (IS_INODE(page)) {
+			entry->last_inode = blkaddr;
+			if (is_dent_dnode(page))
+				entry->last_dentry = blkaddr;
+		}
 next:
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
@@ -462,11 +451,17 @@ static int recover_data(struct f2fs_sb_info *sbi,
 		/*
 		 * inode(x) | CP | inode(x) | dnode(F)
 		 * In this case, we can lose the latest inode(x).
-		 * So, call __recover_inode for the inode update.
+		 * So, call recover_inode for the inode update.
 		 */
-		if (IS_INODE(page))
-			__recover_inode(entry->inode, page);
-
+		if (entry->last_inode == blkaddr)
+			recover_inode(entry->inode, page);
+		if (entry->last_dentry == blkaddr) {
+			err = recover_dentry(entry->inode, page);
+			if (err) {
+				f2fs_put_page(page, 1);
+				break;
+			}
+		}
 		err = do_recover_data(sbi, entry->inode, page, blkaddr);
 		if (err) {
 			f2fs_put_page(page, 1);

commit 441ac5cb323a47b0a665f77f7cd6f76aacbdf21c
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 15 16:46:08 2014 -0700

    f2fs: fix roll-forward missing scenarios
    
    We can summarize the roll forward recovery scenarios as follows.
    
    [Term] F: fsync_mark, D: dentry_mark
    
    1. inode(x) | CP | inode(x) | dnode(F)
    -> Update the latest inode(x).
    
    2. inode(x) | CP | inode(F) | dnode(F)
    -> No problem.
    
    3. inode(x) | CP | dnode(F) | inode(x)
    -> Recover to the latest dnode(F), and drop the last inode(x)
    
    4. inode(x) | CP | dnode(F) | inode(F)
    -> No problem.
    
    5. CP | inode(x) | dnode(F)
    -> The inode(DF) was missing. Should drop this dnode(F).
    
    6. CP | inode(DF) | dnode(F)
    -> No problem.
    
    7. CP | dnode(F) | inode(DF)
    -> If f2fs_iget fails, then goto next to find inode(DF).
    
    8. CP | dnode(F) | inode(x)
    -> If f2fs_iget fails, then goto next to find inode(DF).
       But it will fail due to no inode(DF).
    
    So, this patch adds some missing points such as #1, #5, #7, and #8.
    
    Signed-off-by: Huang Ying <ying.huang@intel.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 7049a3adc409..39832833c02f 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -14,6 +14,37 @@
 #include "node.h"
 #include "segment.h"
 
+/*
+ * Roll forward recovery scenarios.
+ *
+ * [Term] F: fsync_mark, D: dentry_mark
+ *
+ * 1. inode(x) | CP | inode(x) | dnode(F)
+ * -> Update the latest inode(x).
+ *
+ * 2. inode(x) | CP | inode(F) | dnode(F)
+ * -> No problem.
+ *
+ * 3. inode(x) | CP | dnode(F) | inode(x)
+ * -> Recover to the latest dnode(F), and drop the last inode(x)
+ *
+ * 4. inode(x) | CP | dnode(F) | inode(F)
+ * -> No problem.
+ *
+ * 5. CP | inode(x) | dnode(F)
+ * -> The inode(DF) was missing. Should drop this dnode(F).
+ *
+ * 6. CP | inode(DF) | dnode(F)
+ * -> No problem.
+ *
+ * 7. CP | dnode(F) | inode(DF)
+ * -> If f2fs_iget fails, then goto next to find inode(DF).
+ *
+ * 8. CP | dnode(F) | inode(x)
+ * -> If f2fs_iget fails, then goto next to find inode(DF).
+ *    But it will fail due to no inode(DF).
+ */
+
 static struct kmem_cache *fsync_entry_slab;
 
 bool space_for_roll_forward(struct f2fs_sb_info *sbi)
@@ -110,27 +141,32 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	return err;
 }
 
-static int recover_inode(struct inode *inode, struct page *node_page)
+static void __recover_inode(struct inode *inode, struct page *page)
 {
-	struct f2fs_inode *raw_inode = F2FS_INODE(node_page);
+	struct f2fs_inode *raw = F2FS_INODE(page);
+
+	inode->i_mode = le16_to_cpu(raw->i_mode);
+	i_size_write(inode, le64_to_cpu(raw->i_size));
+	inode->i_atime.tv_sec = le64_to_cpu(raw->i_mtime);
+	inode->i_ctime.tv_sec = le64_to_cpu(raw->i_ctime);
+	inode->i_mtime.tv_sec = le64_to_cpu(raw->i_mtime);
+	inode->i_atime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);
+	inode->i_ctime.tv_nsec = le32_to_cpu(raw->i_ctime_nsec);
+	inode->i_mtime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);
+}
 
+static int recover_inode(struct inode *inode, struct page *node_page)
+{
 	if (!IS_INODE(node_page))
 		return 0;
 
-	inode->i_mode = le16_to_cpu(raw_inode->i_mode);
-	i_size_write(inode, le64_to_cpu(raw_inode->i_size));
-	inode->i_atime.tv_sec = le64_to_cpu(raw_inode->i_mtime);
-	inode->i_ctime.tv_sec = le64_to_cpu(raw_inode->i_ctime);
-	inode->i_mtime.tv_sec = le64_to_cpu(raw_inode->i_mtime);
-	inode->i_atime.tv_nsec = le32_to_cpu(raw_inode->i_mtime_nsec);
-	inode->i_ctime.tv_nsec = le32_to_cpu(raw_inode->i_ctime_nsec);
-	inode->i_mtime.tv_nsec = le32_to_cpu(raw_inode->i_mtime_nsec);
+	__recover_inode(inode, node_page);
 
 	if (is_dent_dnode(node_page))
 		return recover_dentry(node_page, inode);
 
 	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode: ino = %x, name = %s",
-			ino_of_node(node_page), raw_inode->i_name);
+			ino_of_node(node_page), F2FS_INODE(node_page)->i_name);
 	return 0;
 }
 
@@ -180,10 +216,16 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 				break;
 			}
 
+			/*
+			 * CP | dnode(F) | inode(DF)
+			 * For this case, we should not give up now.
+			 */
 			entry->inode = f2fs_iget(sbi->sb, ino_of_node(page));
 			if (IS_ERR(entry->inode)) {
 				err = PTR_ERR(entry->inode);
 				kmem_cache_free(fsync_entry_slab, entry);
+				if (err == -ENOENT)
+					goto next;
 				break;
 			}
 			list_add_tail(&entry->list, head);
@@ -417,6 +459,13 @@ static int recover_data(struct f2fs_sb_info *sbi,
 		entry = get_fsync_inode(head, ino_of_node(page));
 		if (!entry)
 			goto next;
+		/*
+		 * inode(x) | CP | inode(x) | dnode(F)
+		 * In this case, we can lose the latest inode(x).
+		 * So, call __recover_inode for the inode update.
+		 */
+		if (IS_INODE(page))
+			__recover_inode(entry->inode, page);
 
 		err = do_recover_data(sbi, entry->inode, page, blkaddr);
 		if (err) {

commit 4c521f493b625c7982cf2eae246e86c893f62dfa
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Sep 11 13:49:55 2014 -0700

    f2fs: use meta_inode cache to improve roll-forward speed
    
    Previously, all the dnode pages should be read during the roll-forward recovery.
    Even worsely, whole the chain was traversed twice.
    This patch removes that redundant and costly read operations by using page cache
    of meta_inode and readahead function as well.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index e587ee128e17..7049a3adc409 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -138,7 +138,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 {
 	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
-	struct page *page;
+	struct page *page = NULL;
 	block_t blkaddr;
 	int err = 0;
 
@@ -146,20 +146,14 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 	curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
-	/* read node page */
-	page = alloc_page(GFP_F2FS_ZERO);
-	if (!page)
-		return -ENOMEM;
-	lock_page(page);
-
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		err = f2fs_submit_page_bio(sbi, page, blkaddr, READ_SYNC);
-		if (err)
-			return err;
+		if (blkaddr < SM_I(sbi)->main_blkaddr ||
+			blkaddr >= (SM_I(sbi)->seg0_blkaddr + TOTAL_BLKS(sbi)))
+			return 0;
 
-		lock_page(page);
+		page = get_meta_page_ra(sbi, blkaddr);
 
 		if (cp_ver != cpver_of_node(page))
 			break;
@@ -202,11 +196,9 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 next:
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
+		f2fs_put_page(page, 1);
 	}
-
-	unlock_page(page);
-	__free_pages(page, 0);
-
+	f2fs_put_page(page, 1);
 	return err;
 }
 
@@ -400,7 +392,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 {
 	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
-	struct page *page;
+	struct page *page = NULL;
 	int err = 0;
 	block_t blkaddr;
 
@@ -408,32 +400,29 @@ static int recover_data(struct f2fs_sb_info *sbi,
 	curseg = CURSEG_I(sbi, type);
 	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
-	/* read node page */
-	page = alloc_page(GFP_F2FS_ZERO);
-	if (!page)
-		return -ENOMEM;
-
-	lock_page(page);
-
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		err = f2fs_submit_page_bio(sbi, page, blkaddr, READ_SYNC);
-		if (err)
-			return err;
+		if (blkaddr < SM_I(sbi)->main_blkaddr ||
+			blkaddr >= (SM_I(sbi)->seg0_blkaddr + TOTAL_BLKS(sbi)))
+			break;
 
-		lock_page(page);
+		page = get_meta_page_ra(sbi, blkaddr);
 
-		if (cp_ver != cpver_of_node(page))
+		if (cp_ver != cpver_of_node(page)) {
+			f2fs_put_page(page, 1);
 			break;
+		}
 
 		entry = get_fsync_inode(head, ino_of_node(page));
 		if (!entry)
 			goto next;
 
 		err = do_recover_data(sbi, entry->inode, page, blkaddr);
-		if (err)
+		if (err) {
+			f2fs_put_page(page, 1);
 			break;
+		}
 
 		if (entry->blkaddr == blkaddr) {
 			iput(entry->inode);
@@ -443,11 +432,8 @@ static int recover_data(struct f2fs_sb_info *sbi,
 next:
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
+		f2fs_put_page(page, 1);
 	}
-
-	unlock_page(page);
-	__free_pages(page, 0);
-
 	if (!err)
 		allocate_new_segments(sbi);
 	return err;
@@ -493,6 +479,10 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	destroy_fsync_dnodes(&inode_list);
 	kmem_cache_destroy(fsync_entry_slab);
 
+	/* truncate meta pages to be used by the recovery */
+	truncate_inode_pages_range(META_MAPPING(sbi),
+		SM_I(sbi)->main_blkaddr << PAGE_CACHE_SHIFT, -1);
+
 	if (err) {
 		truncate_inode_pages_final(NODE_MAPPING(sbi));
 		truncate_inode_pages_final(META_MAPPING(sbi));

commit 60979115a69e0e7916a1c1796f902264f1350977
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Sat Sep 13 00:35:58 2014 +0900

    f2fs: fix double lock for inode page during roll-foward recovery
    
    If the inode is same and its data index are needed to truncate, we can fall into
    double lock for its inode page via get_dnode_of_data.
    
    Error case is like this.
    
    1. write data 1, 2, 3, 4, 5 in inode #4.
    2. write data 100, 102, 103, 104, 105 in dnode #6 of inode #4.
    3. sync
    4. update data 100->106 in dnode #6.
    5. fsync inode #4.
    6. power-cut
    
    -> Then,
    1. go back to #3's checkpoint
    2. in do_recover_data, get_dnode_of_data() gets inode #4.
    3. detect 100->106 in dnode #6.
    4. check_index_in_prev_nodes tries to truncate 100 in dnode #6.
    5. to trigger truncate_hole, get_dnode_of_data should grab inode #4.
    6. detect *kernel hang*
    
    This patch should resolve that bug.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 6c5a74a45f33..e587ee128e17 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -279,16 +279,30 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	ino = ino_of_node(node_page);
 	f2fs_put_page(node_page, 1);
 
-	/* Deallocate previous index in the node page */
-	inode = f2fs_iget(sbi->sb, ino);
-	if (IS_ERR(inode))
-		return PTR_ERR(inode);
+	if (ino != dn->inode->i_ino) {
+		/* Deallocate previous index in the node page */
+		inode = f2fs_iget(sbi->sb, ino);
+		if (IS_ERR(inode))
+			return PTR_ERR(inode);
+	} else {
+		inode = dn->inode;
+	}
 
 	bidx = start_bidx_of_node(offset, F2FS_I(inode)) +
-					le16_to_cpu(sum.ofs_in_node);
+			le16_to_cpu(sum.ofs_in_node);
 
-	truncate_hole(inode, bidx, bidx + 1);
-	iput(inode);
+	if (ino != dn->inode->i_ino) {
+		truncate_hole(inode, bidx, bidx + 1);
+		iput(inode);
+	} else {
+		struct dnode_of_data tdn;
+		set_new_dnode(&tdn, inode, dn->inode_page, NULL, 0);
+		if (get_dnode_of_data(&tdn, bidx, LOOKUP_NODE))
+			return 0;
+		if (tdn.data_blkaddr != NULL_ADDR)
+			truncate_data_blocks_range(&tdn, 1);
+		f2fs_put_page(tdn.node_page, 1);
+	}
 	return 0;
 }
 

commit 9850cf4a8908886370b1f15aacf83d291f098c72
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Sep 2 15:52:58 2014 -0700

    f2fs: need fsck.f2fs when f2fs_bug_on is triggered
    
    If any f2fs_bug_on is triggered, fsck.f2fs is needed.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 5c095f7ac21c..6c5a74a45f33 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -331,8 +331,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	f2fs_wait_on_page_writeback(dn.node_page, NODE);
 
 	get_node_info(sbi, dn.nid, &ni);
-	f2fs_bug_on(ni.ino != ino_of_node(page));
-	f2fs_bug_on(ofs_of_node(dn.node_page) != ofs_of_node(page));
+	f2fs_bug_on(sbi, ni.ino != ino_of_node(page));
+	f2fs_bug_on(sbi, ofs_of_node(dn.node_page) != ofs_of_node(page));
 
 	for (; start < end; start++) {
 		block_t src, dest;
@@ -344,7 +344,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			if (src == NULL_ADDR) {
 				err = reserve_new_block(&dn);
 				/* We should not get -ENOSPC */
-				f2fs_bug_on(err);
+				f2fs_bug_on(sbi, err);
 			}
 
 			/* Check the previous node page having this index */
@@ -474,7 +474,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	/* step #2: recover data */
 	err = recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
 	if (!err)
-		f2fs_bug_on(!list_empty(&inode_list));
+		f2fs_bug_on(sbi, !list_empty(&inode_list));
 out:
 	destroy_fsync_dnodes(&inode_list);
 	kmem_cache_destroy(fsync_entry_slab);

commit 4081363fbe84a7ebac6d3339dd2775df45d856d0
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Sep 2 15:31:18 2014 -0700

    f2fs: introduce F2FS_I_SB, F2FS_M_SB, and F2FS_P_SB
    
    This patch adds three inline functions to clean up dirty casting codes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 756c41cd2582..5c095f7ac21c 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -75,7 +75,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 				err = -EEXIST;
 			goto out_unmap_put;
 		}
-		err = acquire_orphan_inode(F2FS_SB(inode->i_sb));
+		err = acquire_orphan_inode(F2FS_I_SB(inode));
 		if (err) {
 			iput(einode);
 			goto out_unmap_put;

commit 202095a7a0ec075b924cb15dde330bf76e485f61
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Aug 15 09:56:46 2014 -0700

    f2fs: remove rewrite_node_page
    
    I think we need to let the dirty node pages remain in the page cache instead
    of rewriting them in their places.
    So, after done with successful recovery, write_checkpoint will flush all of them
    through the normal write path.
    Through this, we can avoid potential error cases in terms of block allocation.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d36ef35353b2..756c41cd2582 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -371,8 +371,6 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	fill_node_footer(dn.node_page, dn.nid, ni.ino,
 					ofs_of_node(page), false);
 	set_page_dirty(dn.node_page);
-
-	recover_node_page(sbi, dn.node_page, &sum, &ni, blkaddr);
 err:
 	f2fs_put_dnode(&dn);
 	f2fs_unlock_op(sbi);

commit 14f4e690857715d5e0cbe403b4cb8e8c904a6c15
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Aug 13 16:30:46 2014 -0700

    f2fs: prevent checkpoint during roll-forward
    
    Any checkpoint should not be done during the core roll-forward procedure.
    Especially, it includes error cases too.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 7ca7aadaa607..d36ef35353b2 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -459,6 +459,9 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	/* step #1: find fsynced inode numbers */
 	sbi->por_doing = true;
 
+	/* prevent checkpoint */
+	mutex_lock(&sbi->cp_mutex);
+
 	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
 	err = find_fsync_dnodes(sbi, &inode_list);
@@ -490,8 +493,13 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 		/* Flush all the NAT/SIT pages */
 		while (get_pages(sbi, F2FS_DIRTY_META))
 			sync_meta_pages(sbi, META, LONG_MAX);
+		set_ckpt_flags(sbi->ckpt, CP_ERROR_FLAG);
+		mutex_unlock(&sbi->cp_mutex);
 	} else if (need_writecp) {
+		mutex_unlock(&sbi->cp_mutex);
 		write_checkpoint(sbi, false);
+	} else {
+		mutex_unlock(&sbi->cp_mutex);
 	}
 	return err;
 }

commit b307384e4f4670c490b4d142d27fed497df51fae
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Aug 8 10:18:43 2014 -0700

    f2fs: avoid bug_on when error is occurred
    
    During the recovery, if an error like EIO or ENOMEM, f2fs_bug_on should skip.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d7b67b86f607..7ca7aadaa607 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -472,7 +472,8 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	/* step #2: recover data */
 	err = recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
-	f2fs_bug_on(!list_empty(&inode_list));
+	if (!err)
+		f2fs_bug_on(!list_empty(&inode_list));
 out:
 	destroy_fsync_dnodes(&inode_list);
 	kmem_cache_destroy(fsync_entry_slab);

commit 1c35a90e8ab57cd34b8e806b9c75ba05b3b5c7a3
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Aug 7 23:49:17 2014 -0700

    f2fs: fix to recover inline_xattr/data and blocks
    
    This patch fixes not to skip xattr recovery and inline xattr/data recovery
    order.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index cfb2aa9bfc20..d7b67b86f607 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -302,14 +302,19 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	struct node_info ni;
 	int err = 0, recovered = 0;
 
-	recover_inline_xattr(inode, page);
-
-	if (recover_inline_data(inode, page))
+	/* step 1: recover xattr */
+	if (IS_INODE(page)) {
+		recover_inline_xattr(inode, page);
+	} else if (f2fs_has_xattr_block(ofs_of_node(page))) {
+		recover_xattr_data(inode, page, blkaddr);
 		goto out;
+	}
 
-	if (recover_xattr_data(inode, page, blkaddr))
+	/* step 2: recover inline data */
+	if (recover_inline_data(inode, page))
 		goto out;
 
+	/* step 3: recover data indices */
 	start = start_bidx_of_node(ofs_of_node(page), fi);
 	end = start + ADDRS_PER_PAGE(page, fi);
 

commit 695facc05a3eaaf434911dc5dbbc3e6c6a4e1862
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Aug 7 17:06:18 2014 -0700

    f2fs: clear FI_INC_LINK during the recovery
    
    If an inode are fsynced multiple times with fsync & dent marks, this inode will
    set FI_INC_LINK at find_fsync_dnodes during the recovery.
    But, in recover_inode, recover_dentry doesn't clear that flag when multiple hits
    were occurred.
    
    So this patch removes the flag for the further consistency.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index fe1c6d921ba2..cfb2aa9bfc20 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -62,8 +62,10 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	}
 retry:
 	de = f2fs_find_entry(dir, &name, &page);
-	if (de && inode->i_ino == le32_to_cpu(de->ino))
+	if (de && inode->i_ino == le32_to_cpu(de->ino)) {
+		clear_inode_flag(F2FS_I(inode), FI_INC_LINK);
 		goto out_unmap_put;
+	}
 	if (de) {
 		einode = f2fs_iget(inode->i_sb, le32_to_cpu(de->ino));
 		if (IS_ERR(einode)) {

commit 70cfed88efa760fd165fc413cfd1801b5cc8acd2
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sat Aug 2 15:26:04 2014 +0800

    f2fs: avoid skipping recover_inline_xattr after recover_inline_data
    
    When we recover data of inode in roll-forward procedure, and the inode has both
    inline data and inline xattr. We may skip recovering inline xattr if we recover
    inline data form node page first.
    This patch will fix the problem that we lost inline xattr data in above
    scenario.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b2aa53b99f64..fe1c6d921ba2 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -300,6 +300,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	struct node_info ni;
 	int err = 0, recovered = 0;
 
+	recover_inline_xattr(inode, page);
+
 	if (recover_inline_data(inode, page))
 		goto out;
 

commit cf2271e781cb16e1ca22be920010c2b64d90c338
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jul 25 15:47:25 2014 -0700

    f2fs: avoid retrying wrong recovery routine when error was occurred
    
    This patch eliminates the propagation of recovery errors to the next mount.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index a112368a4a86..b2aa53b99f64 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -434,7 +434,9 @@ static int recover_data(struct f2fs_sb_info *sbi,
 
 int recover_fsync_data(struct f2fs_sb_info *sbi)
 {
+	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	struct list_head inode_list;
+	block_t blkaddr;
 	int err;
 	bool need_writecp = false;
 
@@ -447,6 +449,9 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	/* step #1: find fsynced inode numbers */
 	sbi->por_doing = true;
+
+	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
+
 	err = find_fsync_dnodes(sbi, &inode_list);
 	if (err)
 		goto out;
@@ -462,8 +467,21 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 out:
 	destroy_fsync_dnodes(&inode_list);
 	kmem_cache_destroy(fsync_entry_slab);
+
+	if (err) {
+		truncate_inode_pages_final(NODE_MAPPING(sbi));
+		truncate_inode_pages_final(META_MAPPING(sbi));
+	}
+
 	sbi->por_doing = false;
-	if (!err && need_writecp)
+	if (err) {
+		discard_next_dnode(sbi, blkaddr);
+
+		/* Flush all the NAT/SIT pages */
+		while (get_pages(sbi, F2FS_DIRTY_META))
+			sync_meta_pages(sbi, META, LONG_MAX);
+	} else if (need_writecp) {
 		write_checkpoint(sbi, false);
+	}
 	return err;
 }

commit 86928f984e8b166fcd0c7c241501bc00f53eb623
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Sat Jun 7 03:05:03 2014 +0900

    f2fs: avoid not to call remove_dirty_inode
    
    There is an errorneous case during the recovery like below.
    
    In recovery_dentry,
     1) dir = f2fs_iget();
     2) mark the dir with FI_DELAY_IPUT
     3) goto unmap_out
    
    After the end of recovery routine, there is no dirty dentries so the dir cannot
    be released by iput in remove_dirty_dir_inode.
    
    This patch fixes such the bug case by handling the iget and iput in the
    recovery_dentry procedure.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index e950a2f50ac1..a112368a4a86 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -52,20 +52,13 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 		goto out;
 	}
 
-	if (is_inode_flag_set(F2FS_I(dir), FI_DIRTY_DIR)) {
-		iput(dir);
-	} else {
-		add_dirty_dir_inode(dir);
-		set_inode_flag(F2FS_I(dir), FI_DELAY_IPUT);
-	}
-
 	name.len = le32_to_cpu(raw_inode->i_namelen);
 	name.name = raw_inode->i_name;
 
 	if (unlikely(name.len > F2FS_NAME_LEN)) {
 		WARN_ON(1);
 		err = -ENAMETOOLONG;
-		goto out;
+		goto out_err;
 	}
 retry:
 	de = f2fs_find_entry(dir, &name, &page);
@@ -90,11 +83,23 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 		goto retry;
 	}
 	err = __f2fs_add_link(dir, &name, inode);
+	if (err)
+		goto out_err;
+
+	if (is_inode_flag_set(F2FS_I(dir), FI_DELAY_IPUT)) {
+		iput(dir);
+	} else {
+		add_dirty_dir_inode(dir);
+		set_inode_flag(F2FS_I(dir), FI_DELAY_IPUT);
+	}
+
 	goto out;
 
 out_unmap_put:
 	kunmap(page);
 	f2fs_put_page(page, 0);
+out_err:
+	iput(dir);
 out:
 	f2fs_msg(inode->i_sb, KERN_NOTICE,
 			"%s: ino = %x, name = %s, dir = %lx, err = %d",

commit 5c1f9927ec1a4753e845193bde99ac3b03b08818
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Apr 28 17:58:34 2014 +0800

    f2fs: set errno when f2fs_iget failed in recover_dentry
    
    We should set the error number correctly when we fail in recover_dentry(), so
    the recover flow could stop for the reason as error number shows instead of
    continuing.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index be1e3e881725..e950a2f50ac1 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -75,7 +75,8 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 		einode = f2fs_iget(inode->i_sb, le32_to_cpu(de->ino));
 		if (IS_ERR(einode)) {
 			WARN_ON(1);
-			if (PTR_ERR(einode) == -ENOENT)
+			err = PTR_ERR(einode);
+			if (err == -ENOENT)
 				err = -EEXIST;
 			goto out_unmap_put;
 		}

commit 6403eb1f646a49cc92f25c08f8716f8870a4a865
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sat Apr 26 19:59:52 2014 +0800

    f2fs: introduce help macro ADDRS_PER_PAGE()
    
    Introduce help macro ADDRS_PER_PAGE() to get the number of address pointers in
    direct node or inode.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 9eb6487f383d..be1e3e881725 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -301,10 +301,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		goto out;
 
 	start = start_bidx_of_node(ofs_of_node(page), fi);
-	if (IS_INODE(page))
-		end = start + ADDRS_PER_INODE(fi);
-	else
-		end = start + ADDRS_PER_BLOCK;
+	end = start + ADDRS_PER_PAGE(page, fi);
 
 	f2fs_lock_op(sbi);
 

commit ed57c27f736f6d8a51e442610c800ee0c3d83977
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Apr 15 11:19:28 2014 +0900

    f2fs: remove costly dirty_dir_inode operations
    
    This patch removes list opeations in handling dirty dir inodes.
    Previously, F2FS traverses whole the list of dirty dir inodes to check whether
    there is an existing inode or not, resulting in heavy CPU overheads.
    
    So this patch removes such the traverse operations by adding FI_DIRTY_DIR to
    indicate the inode lies on the list or not.
    Through this simple flag, we can remove redundant operations gracefully.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b1ae89f0f44e..9eb6487f383d 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -46,15 +46,17 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	struct inode *dir, *einode;
 	int err = 0;
 
-	dir = check_dirty_dir_inode(F2FS_SB(inode->i_sb), pino);
-	if (!dir) {
-		dir = f2fs_iget(inode->i_sb, pino);
-		if (IS_ERR(dir)) {
-			err = PTR_ERR(dir);
-			goto out;
-		}
-		set_inode_flag(F2FS_I(dir), FI_DELAY_IPUT);
+	dir = f2fs_iget(inode->i_sb, pino);
+	if (IS_ERR(dir)) {
+		err = PTR_ERR(dir);
+		goto out;
+	}
+
+	if (is_inode_flag_set(F2FS_I(dir), FI_DIRTY_DIR)) {
+		iput(dir);
+	} else {
 		add_dirty_dir_inode(dir);
+		set_inode_flag(F2FS_I(dir), FI_DELAY_IPUT);
 	}
 
 	name.len = le32_to_cpu(raw_inode->i_namelen);

commit 2d7b822ad9daf0ea903accacaa89340ddd3f201f
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sat Mar 29 11:33:17 2014 +0800

    f2fs: use list_for_each_entry{_safe} for simplyfying code
    
    This patch use list_for_each_entry{_safe} instead of list_for_each{_safe} for
    simplfying code.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index bbef4ed157a7..b1ae89f0f44e 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -27,14 +27,12 @@ bool space_for_roll_forward(struct f2fs_sb_info *sbi)
 static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
 								nid_t ino)
 {
-	struct list_head *this;
 	struct fsync_inode_entry *entry;
 
-	list_for_each(this, head) {
-		entry = list_entry(this, struct fsync_inode_entry, list);
+	list_for_each_entry(entry, head, list)
 		if (entry->inode->i_ino == ino)
 			return entry;
-	}
+
 	return NULL;
 }
 

commit 3cb5ad152b54430f3e5f338c15f8cd434e7160c8
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Mar 18 13:29:07 2014 +0900

    f2fs: call f2fs_wait_on_page_writeback instead of native function
    
    If a page is on writeback, f2fs can face with deadlock due to under writepages.
    This is caused by merging IOs inside f2fs, so if it comes to detect, let's throw
    merged IOs, which is implemented by f2fs_wait_on_page_writeback.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 03b28ec4c2dc..bbef4ed157a7 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -316,7 +316,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		goto out;
 	}
 
-	wait_on_page_writeback(dn.node_page);
+	f2fs_wait_on_page_writeback(dn.node_page, NODE);
 
 	get_node_info(sbi, dn.nid, &ni);
 	f2fs_bug_on(ni.ino != ino_of_node(page));

commit e8512d2e0c4eb38cd78b1499bb08d7d8eea6c723
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Fri Mar 7 18:43:28 2014 +0800

    f2fs: remove the unused ctor argument of f2fs_kmem_cache_create()
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index aef77681e10b..03b28ec4c2dc 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -436,7 +436,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	bool need_writecp = false;
 
 	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
-			sizeof(struct fsync_inode_entry), NULL);
+			sizeof(struct fsync_inode_entry));
 	if (!fsync_entry_slab)
 		return -ENOMEM;
 

commit 695fd1ed3bcaae9fc032cbe47f0fe9a934bf1717
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Feb 27 19:52:21 2014 +0800

    f2fs: use existing macro to clean up some codes
    
    This patch use existing macro F2FS_INODE/NEXT_FREE_BLKADDR to clean up some
    codes.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 72adbbfdb3e5..aef77681e10b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -136,7 +136,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 
 	/* get node pages in the current segment */
 	curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
-	blkaddr = START_BLOCK(sbi, curseg->segno) + curseg->next_blkoff;
+	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
 	/* read node page */
 	page = alloc_page(GFP_F2FS_ZERO);

commit f6517cfc84246b2606fd631730846c648ee0d455
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Jan 28 14:54:07 2014 +0900

    f2fs: fix a build warning
    
    This patch modifies flow a little bit to avoid the following build warnings.
    
    src/fs/f2fs/recovery.c: In function check_index_in_prev_nodes:
    src/fs/f2fs/recovery.c:288:51: warning: sum.<U5390>.<U52f8>.ofs_in_node may
            be used uninitialized in this function [-Wmaybe-uninitialized]
    src/fs/f2fs/recovery.c:260:23: warning: sum.nid may be used uninitialized
            in this function [-Wmaybe-uninitialized]
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index bda04a012909..72adbbfdb3e5 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -219,11 +219,11 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	struct seg_entry *sentry;
 	unsigned int segno = GET_SEGNO(sbi, blkaddr);
 	unsigned short blkoff = GET_BLKOFF_FROM_SEG0(sbi, blkaddr);
+	struct f2fs_summary_block *sum_node;
 	struct f2fs_summary sum;
+	struct page *sum_page, *node_page;
 	nid_t ino, nid;
-	void *kaddr;
 	struct inode *inode;
-	struct page *node_page;
 	unsigned int offset;
 	block_t bidx;
 	int i;
@@ -237,18 +237,15 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 		struct curseg_info *curseg = CURSEG_I(sbi, i);
 		if (curseg->segno == segno) {
 			sum = curseg->sum_blk->entries[blkoff];
-			break;
+			goto got_it;
 		}
 	}
-	if (i > CURSEG_COLD_DATA) {
-		struct page *sum_page = get_sum_page(sbi, segno);
-		struct f2fs_summary_block *sum_node;
-		kaddr = page_address(sum_page);
-		sum_node = (struct f2fs_summary_block *)kaddr;
-		sum = sum_node->entries[blkoff];
-		f2fs_put_page(sum_page, 1);
-	}
 
+	sum_page = get_sum_page(sbi, segno);
+	sum_node = (struct f2fs_summary_block *)page_address(sum_page);
+	sum = sum_node->entries[blkoff];
+	f2fs_put_page(sum_page, 1);
+got_it:
 	/* Use the locked dnode page and inode */
 	nid = le32_to_cpu(sum.nid);
 	if (dn->inode->i_ino == nid) {

commit 491c0854b41380f48e422c00ae7e25ae4d02cecc
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Feb 4 13:01:10 2014 +0900

    f2fs: clean up with a macro
    
    This patch adds GET_BLKOFF_FROM_SEG0 to clean up some codes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index f1b0b8917436..bda04a012909 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -218,8 +218,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 {
 	struct seg_entry *sentry;
 	unsigned int segno = GET_SEGNO(sbi, blkaddr);
-	unsigned short blkoff = GET_SEGOFF_FROM_SEG0(sbi, blkaddr) &
-					(sbi->blocks_per_seg - 1);
+	unsigned short blkoff = GET_BLKOFF_FROM_SEG0(sbi, blkaddr);
 	struct f2fs_summary sum;
 	nid_t ino, nid;
 	void *kaddr;

commit abb2366c82c3d2dac3d7e9a74332137da8fc9399
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Jan 28 12:25:06 2014 +0900

    f2fs: fix to recover xattr node block
    
    If a new xattr node page was allocated and its inode is fsynced, we should
    recover the xattr node page during the roll-forward process after power-cut.
    But, previously, f2fs didn't handle that case, resulting in kernel panic as
    follows reported by Tom Li.
    
    BUG: unable to handle kernel paging request at ffffc9001c861a98
    IP: [<ffffffffa0295236>] check_index_in_prev_nodes+0x86/0x2d0 [f2fs]
    Call Trace:
     [<ffffffff815ece9b>] ? printk+0x48/0x4a
     [<ffffffffa029626a>] recover_fsync_data+0xdca/0xf50 [f2fs]
     [<ffffffffa02873ae>] f2fs_fill_super+0x92e/0x970 [f2fs]
     [<ffffffff8112c9f8>] mount_bdev+0x1b8/0x200
     [<ffffffffa0286a80>] ? f2fs_remount+0x130/0x130 [f2fs]
     [<ffffffffa0285e40>] f2fs_mount+0x10/0x20 [f2fs]
     [<ffffffff8112d4de>] mount_fs+0x3e/0x1b0
     [<ffffffff810ef4eb>] ? __alloc_percpu+0xb/0x10
     [<ffffffff8114761f>] vfs_kern_mount+0x6f/0x120
     [<ffffffff811497b9>] do_mount+0x259/0xa90
     [<ffffffff810ead1d>] ? memdup_user+0x3d/0x80
     [<ffffffff810eadb3>] ? strndup_user+0x53/0x70
     [<ffffffff8114a2c9>] SyS_mount+0x89/0xd0
     [<ffffffff815feae2>] system_call_fastpath+0x16/0x1b
    
    This patch adds a recovery function of xattr node pages.
    
    Reported-by: Tom Li <biergaizi@members.fsf.org>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 976a7a934db5..f1b0b8917436 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -301,6 +301,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	if (recover_inline_data(inode, page))
 		goto out;
 
+	if (recover_xattr_data(inode, page, blkaddr))
+		goto out;
+
 	start = start_bidx_of_node(ofs_of_node(page), fi);
 	if (IS_INODE(page))
 		end = start + ADDRS_PER_INODE(fi);

commit 6c311ec6c2d9e015d454b4e3fda8008b5bebf316
Author: Chris Fries <cfries@motorola.com>
Date:   Fri Jan 17 14:44:39 2014 -0600

    f2fs: clean checkpatch warnings
    
    Fixed a variety of trivial checkpatch warnings.  The only delta should
    be some minor formatting on log strings that were split / too long.
    
    Signed-off-by: Chris Fries <cfries@motorola.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 655791e518cf..976a7a934db5 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -95,9 +95,9 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	kunmap(page);
 	f2fs_put_page(page, 0);
 out:
-	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode and its dentry: "
-			"ino = %x, name = %s, dir = %lx, err = %d",
-			ino_of_node(ipage), raw_inode->i_name,
+	f2fs_msg(inode->i_sb, KERN_NOTICE,
+			"%s: ino = %x, name = %s, dir = %lx, err = %d",
+			__func__, ino_of_node(ipage), raw_inode->i_name,
 			IS_ERR(dir) ? 0 : dir->i_ino, err);
 	return err;
 }
@@ -366,9 +366,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	f2fs_put_dnode(&dn);
 	f2fs_unlock_op(sbi);
 out:
-	f2fs_msg(sbi->sb, KERN_NOTICE, "recover_data: ino = %lx, "
-			"recovered_data = %d blocks, err = %d",
-			inode->i_ino, recovered, err);
+	f2fs_msg(sbi->sb, KERN_NOTICE,
+		"recover_data: ino = %lx, recovered = %d blocks, err = %d",
+		inode->i_ino, recovered, err);
 	return err;
 }
 

commit 1e1bb4baf10be371f72150e2801d97a04d40b3b9
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Dec 26 12:49:48 2013 +0900

    f2fs: add inline_data recovery routine
    
    This patch adds a inline_data recovery routine with the following policy.
    
    [prev.] [next] of inline_data flag
       o       o  -> recover inline_data
       o       x  -> remove inline_data, and then recover data blocks
       x       o  -> remove inline_data, and then recover inline_data
       x       x  -> recover data blocks
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 96e690b6f0fa..655791e518cf 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -298,6 +298,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	struct node_info ni;
 	int err = 0, recovered = 0;
 
+	if (recover_inline_data(inode, page))
+		goto out;
+
 	start = start_bidx_of_node(ofs_of_node(page), fi);
 	if (IS_INODE(page))
 		end = start + ADDRS_PER_INODE(fi);
@@ -305,12 +308,13 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		end = start + ADDRS_PER_BLOCK;
 
 	f2fs_lock_op(sbi);
+
 	set_new_dnode(&dn, inode, NULL, NULL, 0);
 
 	err = get_dnode_of_data(&dn, start, ALLOC_NODE);
 	if (err) {
 		f2fs_unlock_op(sbi);
-		return err;
+		goto out;
 	}
 
 	wait_on_page_writeback(dn.node_page);
@@ -361,7 +365,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 err:
 	f2fs_put_dnode(&dn);
 	f2fs_unlock_op(sbi);
-
+out:
 	f2fs_msg(sbi->sb, KERN_NOTICE, "recover_data: ino = %lx, "
 			"recovered_data = %d blocks, err = %d",
 			inode->i_ino, recovered, err);

commit 58bfaf44df58082c72882b235cae611c975537d4
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Dec 26 16:30:41 2013 +0900

    f2fs: introduce F2FS_INODE macro to get f2fs_inode
    
    This patch introduces F2FS_INODE that returns struct f2fs_inode * from the inode
    page.
    By using this macro, we can remove unnecessary casting codes like below.
    
       struct f2fs_inode *ri = &F2FS_NODE(inode_page)->i;
    -> struct f2fs_inode *ri = F2FS_INODE(inode_page);
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 4d411a26b85d..96e690b6f0fa 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -40,8 +40,7 @@ static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
 
 static int recover_dentry(struct page *ipage, struct inode *inode)
 {
-	struct f2fs_node *raw_node = F2FS_NODE(ipage);
-	struct f2fs_inode *raw_inode = &(raw_node->i);
+	struct f2fs_inode *raw_inode = F2FS_INODE(ipage);
 	nid_t pino = le32_to_cpu(raw_inode->i_pino);
 	struct f2fs_dir_entry *de;
 	struct qstr name;
@@ -105,8 +104,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 
 static int recover_inode(struct inode *inode, struct page *node_page)
 {
-	struct f2fs_node *raw_node = F2FS_NODE(node_page);
-	struct f2fs_inode *raw_inode = &(raw_node->i);
+	struct f2fs_inode *raw_inode = F2FS_INODE(node_page);
 
 	if (!IS_INODE(node_page))
 		return 0;

commit d96b143151a11820ee3eee552554209f2453799e
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Dec 23 11:12:21 2013 +0800

    f2fs: check filename length in recover_dentry
    
    In current flow, we will get Null return value of f2fs_find_entry in
    recover_dentry when name.len is bigger than F2FS_NAME_LEN, and then we
    still add this inode into its dir entry.
    To avoid this situation, we must check filename length before we use it.
    
    Another point is that we could remove the code of checking filename length
    In f2fs_find_entry, because f2fs_lookup will be called previously to ensure of
    validity of filename length.
    
    V2:
     o add WARN_ON() as Jaegeuk Kim suggested.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index a3f4542160cf..4d411a26b85d 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -62,6 +62,12 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 
 	name.len = le32_to_cpu(raw_inode->i_namelen);
 	name.name = raw_inode->i_name;
+
+	if (unlikely(name.len > F2FS_NAME_LEN)) {
+		WARN_ON(1);
+		err = -ENAMETOOLONG;
+		goto out;
+	}
 retry:
 	de = f2fs_find_entry(dir, &name, &page);
 	if (de && inode->i_ino == le32_to_cpu(de->ino))

commit 6bacf52fb58aeb3e89d9a62970b85a5570aa8ace
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Dec 6 15:00:58 2013 +0900

    f2fs: add unlikely() macro for compiler more aggressively
    
    This patch adds unlikely() macro into the most of codes.
    The basic rule is to add that when:
    - checking unusual errors,
    - checking page mappings,
    - and the other unlikely conditions.
    
    Change log from v1:
     - Don't add unlikely for the NULL test and error test: advised by Andi Kleen.
    
    Cc: Chao Yu <chao2.yu@samsung.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d07546575879..a3f4542160cf 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -430,7 +430,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
 			sizeof(struct fsync_inode_entry), NULL);
-	if (unlikely(!fsync_entry_slab))
+	if (!fsync_entry_slab)
 		return -ENOMEM;
 
 	INIT_LIST_HEAD(&inode_list);

commit b9987a277f1ec9dba203d04c3a20d967c01a1fba
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Dec 5 09:54:56 2013 +0800

    f2fs: avoid unneeded page release for correct _count of page
    
    In find_fsync_dnodes() and recover_data(), our flow is like this:
    
    ->f2fs_submit_page_bio()
            -> f2fs_put_page()
                    -> page_cache_release() ---- page->_count declined to zero.
    ->__free_pages()
            -> put_page_testzero() ---- page->_count will be declined again.
    
    We will get a segment fault in put_page_testzero when CONFIG_DEBUG_VM
    is on, or return MM with a bad page with wrong _count num.
    
    So let's just release this page.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 7dda1f28f6cb..d07546575879 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -145,7 +145,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 
 		err = f2fs_submit_page_bio(sbi, page, blkaddr, READ_SYNC);
 		if (err)
-			goto out;
+			return err;
 
 		lock_page(page);
 
@@ -191,9 +191,10 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
 	}
+
 	unlock_page(page);
-out:
 	__free_pages(page, 0);
+
 	return err;
 }
 
@@ -388,7 +389,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 
 		err = f2fs_submit_page_bio(sbi, page, blkaddr, READ_SYNC);
 		if (err)
-			goto out;
+			return err;
 
 		lock_page(page);
 
@@ -412,8 +413,8 @@ static int recover_data(struct f2fs_sb_info *sbi,
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
 	}
+
 	unlock_page(page);
-out:
 	__free_pages(page, 0);
 
 	if (!err)

commit a0acdfe05a954363861a65eb537573ab417cb7ed
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Dec 5 09:54:00 2013 +0800

    f2fs: use inner macro GFP_F2FS_ZERO for simplification
    
    Use inner macro GFP_F2FS_ZERO to instead of GFP_NOFS | __GFP_ZERO for
    simplification of code.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index c209b8652927..7dda1f28f6cb 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -377,7 +377,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
 
 	/* read node page */
-	page = alloc_page(GFP_NOFS | __GFP_ZERO);
+	page = alloc_page(GFP_F2FS_ZERO);
 	if (!page)
 		return -ENOMEM;
 

commit 93dfe2ac516250755f7d5edd438b0ce67c0e3aa6
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Sat Nov 30 12:51:14 2013 +0900

    f2fs: refactor bio-related operations
    
    This patch integrates redundant bio operations on read and write IOs.
    
    1. Move bio-related codes to the top of data.c.
    2. Replace f2fs_submit_bio with f2fs_submit_merged_bio, which handles read
       bios additionally.
    3. Introduce __submit_merged_bio to submit the merged bio.
    4. Change f2fs_readpage to f2fs_submit_page_bio.
    5. Introduce f2fs_submit_page_mbio to integrate previous submit_read_page and
       submit_write_page.
    
    Reviewed-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Reviewed-by: Chao Yu <chao2.yu@samsung.com >
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index fdc81161f254..c209b8652927 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -143,7 +143,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		err = f2fs_readpage(sbi, page, blkaddr, READ_SYNC);
+		err = f2fs_submit_page_bio(sbi, page, blkaddr, READ_SYNC);
 		if (err)
 			goto out;
 
@@ -386,7 +386,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		err = f2fs_readpage(sbi, page, blkaddr, READ_SYNC);
+		err = f2fs_submit_page_bio(sbi, page, blkaddr, READ_SYNC);
 		if (err)
 			goto out;
 

commit 5d56b6718a0f4e5c58cdd3cb6b7a472d7c5671b9
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Oct 29 15:14:54 2013 +0900

    f2fs: add an option to avoid unnecessary BUG_ONs
    
    If you want to remove unnecessary BUG_ONs, you can just turn off F2FS_CHECK_FS
    in your kernel config.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b278c68b3e08..fdc81161f254 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -311,8 +311,8 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	wait_on_page_writeback(dn.node_page);
 
 	get_node_info(sbi, dn.nid, &ni);
-	BUG_ON(ni.ino != ino_of_node(page));
-	BUG_ON(ofs_of_node(dn.node_page) != ofs_of_node(page));
+	f2fs_bug_on(ni.ino != ino_of_node(page));
+	f2fs_bug_on(ofs_of_node(dn.node_page) != ofs_of_node(page));
 
 	for (; start < end; start++) {
 		block_t src, dest;
@@ -322,9 +322,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 		if (src != dest && dest != NEW_ADDR && dest != NULL_ADDR) {
 			if (src == NULL_ADDR) {
-				int err = reserve_new_block(&dn);
+				err = reserve_new_block(&dn);
 				/* We should not get -ENOSPC */
-				BUG_ON(err);
+				f2fs_bug_on(err);
 			}
 
 			/* Check the previous node page having this index */
@@ -447,7 +447,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	/* step #2: recover data */
 	err = recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
-	BUG_ON(!list_empty(&inode_list));
+	f2fs_bug_on(!list_empty(&inode_list));
 out:
 	destroy_fsync_dnodes(&inode_list);
 	kmem_cache_destroy(fsync_entry_slab);

commit aabe51364f44681cbd83fb1c27ef7d3dbe567c45
Author: Haicheng Li <haicheng.li@linux.intel.com>
Date:   Wed Oct 23 12:39:32 2013 +0800

    f2fs: use bool for booleans
    
    Signed-off-by: Haicheng Li <haicheng.li@linux.intel.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 353cf4f66c7b..b278c68b3e08 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -425,7 +425,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 {
 	struct list_head inode_list;
 	int err;
-	int need_writecp = 0;
+	bool need_writecp = false;
 
 	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
 			sizeof(struct fsync_inode_entry), NULL);
@@ -435,7 +435,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	INIT_LIST_HEAD(&inode_list);
 
 	/* step #1: find fsynced inode numbers */
-	sbi->por_doing = 1;
+	sbi->por_doing = true;
 	err = find_fsync_dnodes(sbi, &inode_list);
 	if (err)
 		goto out;
@@ -443,7 +443,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	if (list_empty(&inode_list))
 		goto out;
 
-	need_writecp = 1;
+	need_writecp = true;
 
 	/* step #2: recover data */
 	err = recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
@@ -451,7 +451,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 out:
 	destroy_fsync_dnodes(&inode_list);
 	kmem_cache_destroy(fsync_entry_slab);
-	sbi->por_doing = 0;
+	sbi->por_doing = false;
 	if (!err && need_writecp)
 		write_checkpoint(sbi, false);
 	return err;

commit e479556bfdd136669854292eb57ed0139d7253d5
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Fri Sep 27 18:08:30 2013 +0800

    f2fs: use rw_sem instead of fs_lock(locks mutex)
    
    The fs_locks is used to block other ops(ex, recovery) when doing checkpoint.
    And each other operate routine(besides checkpoint) needs to acquire a fs_lock,
    there is a terrible problem here, if these are too many concurrency threads acquiring
    fs_lock, so that they will block each other and may lead to some performance problem,
    but this is not the phenomenon we want to see.
    Though there are some optimization patches introduced to enhance the usage of fs_lock,
    but the thorough solution is using a *rw_sem* to replace the fs_lock.
    Checkpoint routine takes write_sem, and other ops take read_sem, so that we can block
    other ops(ex, recovery) when doing checkpoint, and other ops will not disturb each other,
    this can avoid the problem described above completely.
    Because of the weakness of rw_sem, the above change may introduce a potential problem
    that the checkpoint thread might get starved if other threads are intensively locking
    the read semaphore for I/O.(Pointed out by Xu Jin)
    In order to avoid this, a wait_list is introduced, the appending read semaphore ops
    will be dropped into the wait_list if checkpoint thread is waiting for write semaphore,
    and will be waked up when checkpoint thread gives up write semaphore.
    Thanks to Kim's previous review and test, and will be very glad to see other guys'
    performance tests about this patch.
    
    V2:
      -fix the potential starvation problem.
      -use more suitable func name suggested by Xu Jin.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    [Jaegeuk Kim: adjust minor coding standard]
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index a15d122fdc50..353cf4f66c7b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -292,7 +292,6 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	struct f2fs_summary sum;
 	struct node_info ni;
 	int err = 0, recovered = 0;
-	int ilock;
 
 	start = start_bidx_of_node(ofs_of_node(page), fi);
 	if (IS_INODE(page))
@@ -300,12 +299,12 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	else
 		end = start + ADDRS_PER_BLOCK;
 
-	ilock = mutex_lock_op(sbi);
+	f2fs_lock_op(sbi);
 	set_new_dnode(&dn, inode, NULL, NULL, 0);
 
 	err = get_dnode_of_data(&dn, start, ALLOC_NODE);
 	if (err) {
-		mutex_unlock_op(sbi, ilock);
+		f2fs_unlock_op(sbi);
 		return err;
 	}
 
@@ -356,7 +355,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	recover_node_page(sbi, dn.node_page, &sum, &ni, blkaddr);
 err:
 	f2fs_put_dnode(&dn);
-	mutex_unlock_op(sbi, ilock);
+	f2fs_unlock_op(sbi);
 
 	f2fs_msg(sbi->sb, KERN_NOTICE, "recover_data: ino = %lx, "
 			"recovered_data = %d blocks, err = %d",

commit 2e5558f4a5cf16a7394fd5770087303db8912c66
Author: Russ W. Knize <rknize@gmail.com>
Date:   Tue Sep 24 09:40:57 2013 -0500

    f2fs: account for orphan inodes during recovery
    
    During recovery, orphan inodes are deleted via truncate_hole().
    These orphans are added by recover_dentry() via f2fs_delete_entry().
    However, f2fs_delete_entry() adds them via add_orphan_inode()
    without calling acquire_orphan_inode() first.  This prevents the
    counters from being incremented properly, which causes them to
    underflow when remove_orphan_inode() is called later on.
    
    Signed-off-by: Russ Knize <rknize@motorola.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d43e4cd1f815..a15d122fdc50 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -64,24 +64,31 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	name.name = raw_inode->i_name;
 retry:
 	de = f2fs_find_entry(dir, &name, &page);
-	if (de && inode->i_ino == le32_to_cpu(de->ino)) {
-		kunmap(page);
-		f2fs_put_page(page, 0);
-		goto out;
-	}
+	if (de && inode->i_ino == le32_to_cpu(de->ino))
+		goto out_unmap_put;
 	if (de) {
 		einode = f2fs_iget(inode->i_sb, le32_to_cpu(de->ino));
 		if (IS_ERR(einode)) {
 			WARN_ON(1);
 			if (PTR_ERR(einode) == -ENOENT)
 				err = -EEXIST;
-			goto out;
+			goto out_unmap_put;
+		}
+		err = acquire_orphan_inode(F2FS_SB(inode->i_sb));
+		if (err) {
+			iput(einode);
+			goto out_unmap_put;
 		}
 		f2fs_delete_entry(de, page, einode);
 		iput(einode);
 		goto retry;
 	}
 	err = __f2fs_add_link(dir, &name, inode);
+	goto out;
+
+out_unmap_put:
+	kunmap(page);
+	f2fs_put_page(page, 0);
 out:
 	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode and its dentry: "
 			"ino = %x, name = %s, dir = %lx, err = %d",

commit 691c6fd2a2d6b6db08b17beec5e42ab0687058c7
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Sep 24 09:26:24 2013 +0800

    f2fs: remove unneeded write checkpoint in recover_fsync_data
    
    Previously, recover_fsync_data still to write checkpoint when there is
    nothing to recover with normal umount image.
    It may reduce mount performance and flash memory lifetime, so let's remove
    it.
    
    Signed-off-by: Tan Shu <shu.tan@samsung.com>
    Signed-off-by: Yu Chao <chao2.yu@samsung.com>
    Reviewed-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 51ef5eec33d7..d43e4cd1f815 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -419,6 +419,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 {
 	struct list_head inode_list;
 	int err;
+	int need_writecp = 0;
 
 	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
 			sizeof(struct fsync_inode_entry), NULL);
@@ -436,6 +437,8 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	if (list_empty(&inode_list))
 		goto out;
 
+	need_writecp = 1;
+
 	/* step #2: recover data */
 	err = recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
 	BUG_ON(!list_empty(&inode_list));
@@ -443,7 +446,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	destroy_fsync_dnodes(&inode_list);
 	kmem_cache_destroy(fsync_entry_slab);
 	sbi->por_doing = 0;
-	if (!err)
+	if (!err && need_writecp)
 		write_checkpoint(sbi, false);
 	return err;
 }

commit de93653fe31fc9439971296842dcd0280f8ab5f4
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Mon Aug 12 21:08:03 2013 +0900

    f2fs: reserve the xattr space dynamically
    
    This patch enables the number of direct pointers inside on-disk inode block to
    be changed dynamically according to the size of inline xattr space.
    
    The number of direct pointers, ADDRS_PER_INODE, can be changed only if the file
    has inline xattr flag.
    
    The number of direct pointers that will be used by inline xattrs is defined as
    F2FS_INLINE_XATTR_ADDRS.
    Current patch assigns F2FS_INLINE_XATTR_ADDRS to 0 temporarily.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index fa493bb64167..51ef5eec33d7 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -213,6 +213,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	void *kaddr;
 	struct inode *inode;
 	struct page *node_page;
+	unsigned int offset;
 	block_t bidx;
 	int i;
 
@@ -257,8 +258,8 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	node_page = get_node_page(sbi, nid);
 	if (IS_ERR(node_page))
 		return PTR_ERR(node_page);
-	bidx = start_bidx_of_node(ofs_of_node(node_page)) +
-					le16_to_cpu(sum.ofs_in_node);
+
+	offset = ofs_of_node(node_page);
 	ino = ino_of_node(node_page);
 	f2fs_put_page(node_page, 1);
 
@@ -267,6 +268,9 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	if (IS_ERR(inode))
 		return PTR_ERR(inode);
 
+	bidx = start_bidx_of_node(offset, F2FS_I(inode)) +
+					le16_to_cpu(sum.ofs_in_node);
+
 	truncate_hole(inode, bidx, bidx + 1);
 	iput(inode);
 	return 0;
@@ -275,6 +279,7 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 					struct page *page, block_t blkaddr)
 {
+	struct f2fs_inode_info *fi = F2FS_I(inode);
 	unsigned int start, end;
 	struct dnode_of_data dn;
 	struct f2fs_summary sum;
@@ -282,9 +287,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	int err = 0, recovered = 0;
 	int ilock;
 
-	start = start_bidx_of_node(ofs_of_node(page));
+	start = start_bidx_of_node(ofs_of_node(page), fi);
 	if (IS_INODE(page))
-		end = start + ADDRS_PER_INODE;
+		end = start + ADDRS_PER_INODE(fi);
 	else
 		end = start + ADDRS_PER_BLOCK;
 

commit e27dae4d663762da2020e93885be2219f0608ec6
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Thu Aug 15 08:54:56 2013 +0300

    f2fs: alloc_page() doesn't return an ERR_PTR
    
    alloc_page() returns a NULL on failure, it never returns an ERR_PTR.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index c6908b5d9d84..fa493bb64167 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -129,8 +129,8 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 
 	/* read node page */
 	page = alloc_page(GFP_F2FS_ZERO);
-	if (IS_ERR(page))
-		return PTR_ERR(page);
+	if (!page)
+		return -ENOMEM;
 	lock_page(page);
 
 	while (1) {
@@ -367,7 +367,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 
 	/* read node page */
 	page = alloc_page(GFP_NOFS | __GFP_ZERO);
-	if (IS_ERR(page))
+	if (!page)
 		return -ENOMEM;
 
 	lock_page(page);

commit d71b5564c0da4f652af2e4ca9d3c22b9c960ec1f
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Aug 9 15:03:21 2013 +0900

    f2fs: introduce cur_cp_version function to reduce code size
    
    This patch introduces a new inline function, cur_cp_version, to reduce redundant
    codes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 639eb3465286..c6908b5d9d84 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -117,7 +117,7 @@ static int recover_inode(struct inode *inode, struct page *node_page)
 
 static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 {
-	unsigned long long cp_ver = le64_to_cpu(sbi->ckpt->checkpoint_ver);
+	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
 	struct page *page;
 	block_t blkaddr;
@@ -355,7 +355,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 static int recover_data(struct f2fs_sb_info *sbi,
 				struct list_head *head, int type)
 {
-	unsigned long long cp_ver = le64_to_cpu(sbi->ckpt->checkpoint_ver);
+	unsigned long long cp_ver = cur_cp_version(F2FS_CKPT(sbi));
 	struct curseg_info *curseg;
 	struct page *page;
 	int err = 0;

commit 4559071063270999d016c92a0b9241692cbbb522
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Mon Jul 15 17:57:38 2013 +0800

    f2fs: introduce help function F2FS_NODE()
    
    Introduce help function F2FS_NODE() to simplify the conversion of node_page to
    f2fs_node.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index d56d951c2253..639eb3465286 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -40,8 +40,7 @@ static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
 
 static int recover_dentry(struct page *ipage, struct inode *inode)
 {
-	void *kaddr = page_address(ipage);
-	struct f2fs_node *raw_node = (struct f2fs_node *)kaddr;
+	struct f2fs_node *raw_node = F2FS_NODE(ipage);
 	struct f2fs_inode *raw_inode = &(raw_node->i);
 	nid_t pino = le32_to_cpu(raw_inode->i_pino);
 	struct f2fs_dir_entry *de;
@@ -93,8 +92,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 
 static int recover_inode(struct inode *inode, struct page *node_page)
 {
-	void *kaddr = page_address(node_page);
-	struct f2fs_node *raw_node = (struct f2fs_node *)kaddr;
+	struct f2fs_node *raw_node = F2FS_NODE(node_page);
 	struct f2fs_inode *raw_inode = &(raw_node->i);
 
 	if (!IS_INODE(node_page))

commit 5ebefc5b409a194a09da7ad1962b4bfce10a6859
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Thu Jun 27 09:28:54 2013 +0800

    f2fs: remove the unused argument "sbi" of func destroy_fsync_dnodes()
    
    As destroy_fsync_dnodes() is a simple list-cleanup func, so delete the unused
    and unrelated f2fs_sb_info argument of it.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 9db8239642f4..d56d951c2253 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -192,8 +192,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 	return err;
 }
 
-static void destroy_fsync_dnodes(struct f2fs_sb_info *sbi,
-					struct list_head *head)
+static void destroy_fsync_dnodes(struct list_head *head)
 {
 	struct fsync_inode_entry *entry, *tmp;
 
@@ -438,7 +437,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	err = recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
 	BUG_ON(!list_empty(&inode_list));
 out:
-	destroy_fsync_dnodes(sbi, &inode_list);
+	destroy_fsync_dnodes(&inode_list);
 	kmem_cache_destroy(fsync_entry_slab);
 	sbi->por_doing = 0;
 	if (!err)

commit 060dd67b3c0d451ea2c41e6a87811b4736a984e4
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Mon Jun 24 07:47:23 2013 +0900

    f2fs: fix an endian conversion bug detected by sparse
    
    This patch should fix the following bug reported by kbuild test robot.
    
    fs/f2fs/recovery.c:233:33: sparse: incorrect type in assignment
    (different base types)
    
    parse warnings: (new ones prefixed by >>)
    
    >> recovery.c:233: sparse: incorrect type in assignment (different base types)
       recovery.c:233:    expected unsigned int [unsigned] [assigned] ofs_in_node
       recovery.c:233:    got restricted __le16 [assigned] [usertype] ofs_in_node
    >> recovery.c:238: sparse: incorrect type in assignment (different base types)
       recovery.c:238:    expected unsigned int [unsigned] ofs_in_node
       recovery.c:238:    got restricted __le16 [assigned] [usertype] ofs_in_node
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index ddde14f0eacb..9db8239642f4 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -246,12 +246,12 @@ static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 		struct dnode_of_data tdn = *dn;
 		tdn.nid = nid;
 		tdn.node_page = dn->inode_page;
-		tdn.ofs_in_node = sum.ofs_in_node;
+		tdn.ofs_in_node = le16_to_cpu(sum.ofs_in_node);
 		truncate_data_blocks_range(&tdn, 1);
 		return 0;
 	} else if (dn->nid == nid) {
 		struct dnode_of_data tdn = *dn;
-		tdn.ofs_in_node = sum.ofs_in_node;
+		tdn.ofs_in_node = le16_to_cpu(sum.ofs_in_node);
 		truncate_data_blocks_range(&tdn, 1);
 		return 0;
 	}

commit 5deb82671ae344b28b4e744020afcbc76df1779b
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Jun 5 17:42:45 2013 +0900

    f2fs: fix iget/iput of dir during recovery
    
    It is possible that iput is skipped after iget during the recovery.
    
    In recover_dentry(),
     dir = f2fs_iget();
     ...
     if (de && inode->i_ino == le32_to_cpu(de->ino))
            goto out;
    
    In this case, this dir is not able to be added in dirty_dir_inode_list.
    The actual linking is done only when set_page_dirty() is called.
    
    So let's add this newly got inode into the list explicitly, and put it at the
    end of the recovery routine.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 539ca32f4483..ddde14f0eacb 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -58,6 +58,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 			goto out;
 		}
 		set_inode_flag(F2FS_I(dir), FI_DELAY_IPUT);
+		add_dirty_dir_inode(dir);
 	}
 
 	name.len = le32_to_cpu(raw_inode->i_namelen);

commit 6b8213d9a4ca0d7a02a38757068ba79cd96206f0
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue May 28 09:19:22 2013 +0900

    f2fs: fix dentry recovery routine
    
    The error scenario is:
    1. create /a
    (1.a link /a /b)
    2. sync
    3. unlinke /a
    4. create /a
    5. fsync /a
    6. Sudden power-off
    
    When the f2fs recovers the fsynced dentry, /a, we discover an exsiting dentry at
    f2fs_find_entry() in recover_dentry().
    
    In such the case, we should unlink the existing dentry and its inode
    and then recover newly created dentry.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 0dd2ce1b492f..539ca32f4483 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -44,9 +44,10 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	struct f2fs_node *raw_node = (struct f2fs_node *)kaddr;
 	struct f2fs_inode *raw_inode = &(raw_node->i);
 	nid_t pino = le32_to_cpu(raw_inode->i_pino);
+	struct f2fs_dir_entry *de;
 	struct qstr name;
 	struct page *page;
-	struct inode *dir;
+	struct inode *dir, *einode;
 	int err = 0;
 
 	dir = check_dirty_dir_inode(F2FS_SB(inode->i_sb), pino);
@@ -61,13 +62,26 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 
 	name.len = le32_to_cpu(raw_inode->i_namelen);
 	name.name = raw_inode->i_name;
-
-	if (f2fs_find_entry(dir, &name, &page)) {
+retry:
+	de = f2fs_find_entry(dir, &name, &page);
+	if (de && inode->i_ino == le32_to_cpu(de->ino)) {
 		kunmap(page);
 		f2fs_put_page(page, 0);
-	} else {
-		err = __f2fs_add_link(dir, &name, inode);
+		goto out;
+	}
+	if (de) {
+		einode = f2fs_iget(inode->i_sb, le32_to_cpu(de->ino));
+		if (IS_ERR(einode)) {
+			WARN_ON(1);
+			if (PTR_ERR(einode) == -ENOENT)
+				err = -EEXIST;
+			goto out;
+		}
+		f2fs_delete_entry(de, page, einode);
+		iput(einode);
+		goto retry;
 	}
+	err = __f2fs_add_link(dir, &name, inode);
 out:
 	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode and its dentry: "
 			"ino = %x, name = %s, dir = %lx, err = %d",

commit f28c06fa6f3d3215a1ba5e62ebc5ce7229d7a895
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Thu May 23 13:02:13 2013 +0300

    f2fs: dereferencing an ERR_PTR
    
    There is an error path where "dir" is an ERR_PTR.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index dcd8e860aad3..0dd2ce1b492f 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -71,7 +71,8 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 out:
 	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode and its dentry: "
 			"ino = %x, name = %s, dir = %lx, err = %d",
-			ino_of_node(ipage), raw_inode->i_name, dir->i_ino, err);
+			ino_of_node(ipage), raw_inode->i_name,
+			IS_ERR(dir) ? 0 : dir->i_ino, err);
 	return err;
 }
 

commit 39cf72cf09c8f36a383919e7675bdb15bd4db53b
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed May 22 08:20:01 2013 +0900

    f2fs: fix to handle do_recover_data errors
    
    This patch adds error handling codes of check_index_in_prev_nodes and its
    caller, do_recover_data.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index eceb6652532d..dcd8e860aad3 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -188,7 +188,7 @@ static void destroy_fsync_dnodes(struct f2fs_sb_info *sbi,
 	}
 }
 
-static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
+static int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 			block_t blkaddr, struct dnode_of_data *dn)
 {
 	struct seg_entry *sentry;
@@ -205,7 +205,7 @@ static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 
 	sentry = get_seg_entry(sbi, segno);
 	if (!f2fs_test_bit(blkoff, sentry->cur_valid_map))
-		return;
+		return 0;
 
 	/* Get the previous summary */
 	for (i = CURSEG_WARM_DATA; i <= CURSEG_COLD_DATA; i++) {
@@ -232,16 +232,18 @@ static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 		tdn.node_page = dn->inode_page;
 		tdn.ofs_in_node = sum.ofs_in_node;
 		truncate_data_blocks_range(&tdn, 1);
-		return;
+		return 0;
 	} else if (dn->nid == nid) {
 		struct dnode_of_data tdn = *dn;
 		tdn.ofs_in_node = sum.ofs_in_node;
 		truncate_data_blocks_range(&tdn, 1);
-		return;
+		return 0;
 	}
 
 	/* Get the node page */
 	node_page = get_node_page(sbi, nid);
+	if (IS_ERR(node_page))
+		return PTR_ERR(node_page);
 	bidx = start_bidx_of_node(ofs_of_node(node_page)) +
 					le16_to_cpu(sum.ofs_in_node);
 	ino = ino_of_node(node_page);
@@ -250,10 +252,11 @@ static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	/* Deallocate previous index in the node page */
 	inode = f2fs_iget(sbi->sb, ino);
 	if (IS_ERR(inode))
-		return;
+		return PTR_ERR(inode);
 
 	truncate_hole(inode, bidx, bidx + 1);
 	iput(inode);
+	return 0;
 }
 
 static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
@@ -301,7 +304,9 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			}
 
 			/* Check the previous node page having this index */
-			check_index_in_prev_nodes(sbi, dest, &dn);
+			err = check_index_in_prev_nodes(sbi, dest, &dn);
+			if (err)
+				goto err;
 
 			set_summary(&sum, dn.nid, dn.ofs_in_node, ni.version);
 
@@ -324,13 +329,14 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	set_page_dirty(dn.node_page);
 
 	recover_node_page(sbi, dn.node_page, &sum, &ni, blkaddr);
+err:
 	f2fs_put_dnode(&dn);
 	mutex_unlock_op(sbi, ilock);
 
 	f2fs_msg(sbi->sb, KERN_NOTICE, "recover_data: ino = %lx, "
-			"recovered_data = %d blocks",
-			inode->i_ino, recovered);
-	return 0;
+			"recovered_data = %d blocks, err = %d",
+			inode->i_ino, recovered, err);
+	return err;
 }
 
 static int recover_data(struct f2fs_sb_info *sbi,

commit b292dcab068e141d8a820b77cbcc88d98c610eb4
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed May 22 08:02:02 2013 +0900

    f2fs: reuse the locked dnode page and its inode
    
    This patch fixes the following deadlock bug during the recovery.
    
    INFO: task mount:1322 blocked for more than 120 seconds.
    "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    mount           D ffffffff81125870     0  1322   1266 0x00000000
     ffff8801207e39d8 0000000000000046 ffff88012ab1dee0 0000000000000046
     ffff8801207e3a08 ffff880115903f40 ffff8801207e3fd8 ffff8801207e3fd8
     ffff8801207e3fd8 ffff880115903f40 ffff8801207e39d8 ffff88012fc94520
    Call Trace:
    [<ffffffff81125870>] ? __lock_page+0x70/0x70
    [<ffffffff816a92d9>] schedule+0x29/0x70
    [<ffffffff816a93af>] io_schedule+0x8f/0xd0
    [<ffffffff8112587e>] sleep_on_page+0xe/0x20
    [<ffffffff816a649a>] __wait_on_bit_lock+0x5a/0xc0
    [<ffffffff81125867>] __lock_page+0x67/0x70
    [<ffffffff8106c7b0>] ? autoremove_wake_function+0x40/0x40
    [<ffffffff81126857>] find_lock_page+0x67/0x80
    [<ffffffff8112698f>] find_or_create_page+0x3f/0xb0
    [<ffffffffa03901a8>] ? sync_inode_page+0xa8/0xd0 [f2fs]
    [<ffffffffa038fdf7>] get_node_page+0x67/0x180 [f2fs]
    [<ffffffffa039818b>] recover_fsync_data+0xacb/0xff0 [f2fs]
    [<ffffffff816aaa1e>] ? _raw_spin_unlock+0x3e/0x40
    [<ffffffffa0389634>] f2fs_fill_super+0x7d4/0x850 [f2fs]
    [<ffffffff81184cf9>] mount_bdev+0x1c9/0x210
    [<ffffffffa0388e60>] ? validate_superblock+0x180/0x180 [f2fs]
    [<ffffffffa0387635>] f2fs_mount+0x15/0x20 [f2fs]
    [<ffffffff81185a13>] mount_fs+0x43/0x1b0
    [<ffffffff81145ba0>] ? __alloc_percpu+0x10/0x20
    [<ffffffff811a0796>] vfs_kern_mount+0x76/0x120
    [<ffffffff811a2cb7>] do_mount+0x237/0xa10
    [<ffffffff81140b9b>] ? strndup_user+0x5b/0x80
    [<ffffffff811a3520>] SyS_mount+0x90/0xe0
    [<ffffffff816b3502>] system_call_fastpath+0x16/0x1b
    
    The bug is triggered when check_index_in_prev_nodes tries to get the direct
    node page by calling get_node_page.
    At this point, if the direct node page is already locked by get_dnode_of_data,
    its caller, we got a deadlock condition.
    
    This patch adds additional condition check for the reuse of locked direct node
    pages prior to the get_node_page call.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 5148d90049b0..eceb6652532d 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -189,14 +189,14 @@ static void destroy_fsync_dnodes(struct f2fs_sb_info *sbi,
 }
 
 static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
-						block_t blkaddr)
+			block_t blkaddr, struct dnode_of_data *dn)
 {
 	struct seg_entry *sentry;
 	unsigned int segno = GET_SEGNO(sbi, blkaddr);
 	unsigned short blkoff = GET_SEGOFF_FROM_SEG0(sbi, blkaddr) &
 					(sbi->blocks_per_seg - 1);
 	struct f2fs_summary sum;
-	nid_t ino;
+	nid_t ino, nid;
 	void *kaddr;
 	struct inode *inode;
 	struct page *node_page;
@@ -224,10 +224,26 @@ static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 		f2fs_put_page(sum_page, 1);
 	}
 
+	/* Use the locked dnode page and inode */
+	nid = le32_to_cpu(sum.nid);
+	if (dn->inode->i_ino == nid) {
+		struct dnode_of_data tdn = *dn;
+		tdn.nid = nid;
+		tdn.node_page = dn->inode_page;
+		tdn.ofs_in_node = sum.ofs_in_node;
+		truncate_data_blocks_range(&tdn, 1);
+		return;
+	} else if (dn->nid == nid) {
+		struct dnode_of_data tdn = *dn;
+		tdn.ofs_in_node = sum.ofs_in_node;
+		truncate_data_blocks_range(&tdn, 1);
+		return;
+	}
+
 	/* Get the node page */
-	node_page = get_node_page(sbi, le32_to_cpu(sum.nid));
+	node_page = get_node_page(sbi, nid);
 	bidx = start_bidx_of_node(ofs_of_node(node_page)) +
-				le16_to_cpu(sum.ofs_in_node);
+					le16_to_cpu(sum.ofs_in_node);
 	ino = ino_of_node(node_page);
 	f2fs_put_page(node_page, 1);
 
@@ -285,7 +301,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			}
 
 			/* Check the previous node page having this index */
-			check_index_in_prev_nodes(sbi, dest);
+			check_index_in_prev_nodes(sbi, dest, &dn);
 
 			set_summary(&sum, dn.nid, dn.ofs_in_node, ni.version);
 

commit 2c2c149f7dabd5a4d41cae5d2c2ce1d130acf72c
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Mon May 20 14:48:49 2013 +0900

    f2fs: don't do checkpoint if error is occurred
    
    If we met an error during the dentry recovery, we should not conduct checkpoint.
    Otherwise, some errorneous dentry blocks overwrites the existing blocks that
    contain the remaining recovery information.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 3a4b51c03321..5148d90049b0 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -403,6 +403,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	destroy_fsync_dnodes(sbi, &inode_list);
 	kmem_cache_destroy(fsync_entry_slab);
 	sbi->por_doing = 0;
-	write_checkpoint(sbi, false);
+	if (!err)
+		write_checkpoint(sbi, false);
 	return err;
 }

commit 45856aff0d9091f4836e333951c66eca382a8573
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Mon May 20 10:26:09 2013 +0900

    f2fs: fix to unlock page before exit
    
    If we got an error after lock_page, we should unlock it before exit.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index f91ff0f0044d..3a4b51c03321 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -347,7 +347,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 		lock_page(page);
 
 		if (cp_ver != cpver_of_node(page))
-			goto unlock_out;
+			break;
 
 		entry = get_fsync_inode(head, ino_of_node(page));
 		if (!entry)
@@ -355,7 +355,7 @@ static int recover_data(struct f2fs_sb_info *sbi,
 
 		err = do_recover_data(sbi, entry->inode, page, blkaddr);
 		if (err)
-			goto out;
+			break;
 
 		if (entry->blkaddr == blkaddr) {
 			iput(entry->inode);
@@ -366,7 +366,6 @@ static int recover_data(struct f2fs_sb_info *sbi,
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
 	}
-unlock_out:
 	unlock_page(page);
 out:
 	__free_pages(page, 0);

commit 9a55ed656c9afbe41316ab2373bc063359b7683f
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Mon May 20 10:23:40 2013 +0900

    f2fs: remove unnecessary kmap/kunmap operations
    
    The allocated page used by the recovery is not on HIGHMEM, so that we don't
    need to use kmap/kunmap.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 6ad4e539c60a..f91ff0f0044d 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -40,11 +40,11 @@ static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
 
 static int recover_dentry(struct page *ipage, struct inode *inode)
 {
-	struct f2fs_node *raw_node = (struct f2fs_node *)kmap(ipage);
+	void *kaddr = page_address(ipage);
+	struct f2fs_node *raw_node = (struct f2fs_node *)kaddr;
 	struct f2fs_inode *raw_inode = &(raw_node->i);
 	nid_t pino = le32_to_cpu(raw_inode->i_pino);
 	struct qstr name;
-	struct f2fs_dir_entry *de;
 	struct page *page;
 	struct inode *dir;
 	int err = 0;
@@ -62,8 +62,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	name.len = le32_to_cpu(raw_inode->i_namelen);
 	name.name = raw_inode->i_name;
 
-	de = f2fs_find_entry(dir, &name, &page);
-	if (de) {
+	if (f2fs_find_entry(dir, &name, &page)) {
 		kunmap(page);
 		f2fs_put_page(page, 0);
 	} else {
@@ -73,7 +72,6 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode and its dentry: "
 			"ino = %x, name = %s, dir = %lx, err = %d",
 			ino_of_node(ipage), raw_inode->i_name, dir->i_ino, err);
-	kunmap(ipage);
 	return err;
 }
 

commit f356fe0cba0e3523e538987916bd2acedd4e6f41
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu May 16 15:04:49 2013 +0900

    f2fs: add debug msgs in the recovery routine
    
    This patch adds some trivial debugging messages in the recovery process.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 23f580397e6c..6ad4e539c60a 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -49,9 +49,6 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	struct inode *dir;
 	int err = 0;
 
-	if (!is_dent_dnode(ipage))
-		goto out;
-
 	dir = check_dirty_dir_inode(F2FS_SB(inode->i_sb), pino);
 	if (!dir) {
 		dir = f2fs_iget(inode->i_sb, pino);
@@ -73,6 +70,9 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 		err = __f2fs_add_link(dir, &name, inode);
 	}
 out:
+	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode and its dentry: "
+			"ino = %x, name = %s, dir = %lx, err = %d",
+			ino_of_node(ipage), raw_inode->i_name, dir->i_ino, err);
 	kunmap(ipage);
 	return err;
 }
@@ -83,6 +83,9 @@ static int recover_inode(struct inode *inode, struct page *node_page)
 	struct f2fs_node *raw_node = (struct f2fs_node *)kaddr;
 	struct f2fs_inode *raw_inode = &(raw_node->i);
 
+	if (!IS_INODE(node_page))
+		return 0;
+
 	inode->i_mode = le16_to_cpu(raw_inode->i_mode);
 	i_size_write(inode, le64_to_cpu(raw_inode->i_size));
 	inode->i_atime.tv_sec = le64_to_cpu(raw_inode->i_mtime);
@@ -92,7 +95,12 @@ static int recover_inode(struct inode *inode, struct page *node_page)
 	inode->i_ctime.tv_nsec = le32_to_cpu(raw_inode->i_ctime_nsec);
 	inode->i_mtime.tv_nsec = le32_to_cpu(raw_inode->i_mtime_nsec);
 
-	return recover_dentry(node_page, inode);
+	if (is_dent_dnode(node_page))
+		return recover_dentry(node_page, inode);
+
+	f2fs_msg(inode->i_sb, KERN_NOTICE, "recover_inode: ino = %x, name = %s",
+			ino_of_node(node_page), raw_inode->i_name);
+	return 0;
 }
 
 static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
@@ -123,7 +131,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 		lock_page(page);
 
 		if (cp_ver != cpver_of_node(page))
-			goto unlock_out;
+			break;
 
 		if (!is_fsync_dnode(page))
 			goto next;
@@ -137,40 +145,33 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 			if (IS_INODE(page) && is_dent_dnode(page)) {
 				err = recover_inode_page(sbi, page);
 				if (err)
-					goto unlock_out;
+					break;
 			}
 
 			/* add this fsync inode to the list */
 			entry = kmem_cache_alloc(fsync_entry_slab, GFP_NOFS);
 			if (!entry) {
 				err = -ENOMEM;
-				goto unlock_out;
+				break;
 			}
 
 			entry->inode = f2fs_iget(sbi->sb, ino_of_node(page));
 			if (IS_ERR(entry->inode)) {
 				err = PTR_ERR(entry->inode);
 				kmem_cache_free(fsync_entry_slab, entry);
-				goto unlock_out;
+				break;
 			}
 			list_add_tail(&entry->list, head);
 		}
 		entry->blkaddr = blkaddr;
 
-		if (IS_INODE(page)) {
-			err = recover_inode(entry->inode, page);
-			if (err == -ENOENT) {
-				goto next;
-			} else if (err) {
-				err = -EINVAL;
-				goto unlock_out;
-			}
-		}
+		err = recover_inode(entry->inode, page);
+		if (err && err != -ENOENT)
+			break;
 next:
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
 	}
-unlock_out:
 	unlock_page(page);
 out:
 	__free_pages(page, 0);
@@ -248,7 +249,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	struct dnode_of_data dn;
 	struct f2fs_summary sum;
 	struct node_info ni;
-	int err = 0;
+	int err = 0, recovered = 0;
 	int ilock;
 
 	start = start_bidx_of_node(ofs_of_node(page));
@@ -293,6 +294,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 			/* write dummy data page */
 			recover_data_page(sbi, NULL, &sum, src, dest);
 			update_extent_cache(dest, &dn);
+			recovered++;
 		}
 		dn.ofs_in_node++;
 	}
@@ -310,6 +312,10 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	recover_node_page(sbi, dn.node_page, &sum, &ni, blkaddr);
 	f2fs_put_dnode(&dn);
 	mutex_unlock_op(sbi, ilock);
+
+	f2fs_msg(sbi->sb, KERN_NOTICE, "recover_data: ino = %lx, "
+			"recovered_data = %d blocks",
+			inode->i_ino, recovered);
 	return 0;
 }
 

commit 74d0b917ef7789097e12d60fc054efa427ce9171
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed May 15 16:40:02 2013 +0900

    f2fs: fix BUG_ON during f2fs_evict_inode(dir)
    
    During the dentry recovery routine, recover_inode() triggers __f2fs_add_link
    with its directory inode.
    
    In the following scenario, a bug is captured.
     1. dir = f2fs_iget(pino)
     2. __f2fs_add_link(dir, name)
     3. iput(dir)
      -> f2fs_evict_inode() faces with BUG_ON(atomic_read(fi->dirty_dents))
    
    Kernel BUG at ffffffffa01c0676 [verbose debug info unavailable]
    [<ffffffffa01c0676>] f2fs_evict_inode+0x276/0x300 [f2fs]
    Call Trace:
     [<ffffffff8118ea00>] evict+0xb0/0x1b0
     [<ffffffff8118f1c5>] iput+0x105/0x190
     [<ffffffffa01d2dac>] recover_fsync_data+0x3bc/0x1070 [f2fs]
     [<ffffffff81692e8a>] ? io_schedule+0xaa/0xd0
     [<ffffffff81690acb>] ? __wait_on_bit_lock+0x7b/0xc0
     [<ffffffff8111a0e7>] ? __lock_page+0x67/0x70
     [<ffffffff81165e21>] ? kmem_cache_alloc+0x31/0x140
     [<ffffffff8118a502>] ? __d_instantiate+0x92/0xf0
     [<ffffffff812a949b>] ? security_d_instantiate+0x1b/0x30
     [<ffffffff8118a5b4>] ? d_instantiate+0x54/0x70
    
    This means that we should flush all the dentry pages between iget and iput().
    But, during the recovery routine, it is unallowed due to consistency, so we
    have to wait the whole recovery process.
    And then, write_checkpoint flushes all the dirty dentry blocks, and nicely we
    can put the stale dir inodes from the dirty_dir_inode_list.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 4d895149a6f0..23f580397e6c 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -42,6 +42,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 {
 	struct f2fs_node *raw_node = (struct f2fs_node *)kmap(ipage);
 	struct f2fs_inode *raw_inode = &(raw_node->i);
+	nid_t pino = le32_to_cpu(raw_inode->i_pino);
 	struct qstr name;
 	struct f2fs_dir_entry *de;
 	struct page *page;
@@ -51,10 +52,14 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	if (!is_dent_dnode(ipage))
 		goto out;
 
-	dir = f2fs_iget(inode->i_sb, le32_to_cpu(raw_inode->i_pino));
-	if (IS_ERR(dir)) {
-		err = PTR_ERR(dir);
-		goto out;
+	dir = check_dirty_dir_inode(F2FS_SB(inode->i_sb), pino);
+	if (!dir) {
+		dir = f2fs_iget(inode->i_sb, pino);
+		if (IS_ERR(dir)) {
+			err = PTR_ERR(dir);
+			goto out;
+		}
+		set_inode_flag(F2FS_I(dir), FI_DELAY_IPUT);
 	}
 
 	name.len = le32_to_cpu(raw_inode->i_namelen);
@@ -67,7 +72,6 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 	} else {
 		err = __f2fs_add_link(dir, &name, inode);
 	}
-	iput(dir);
 out:
 	kunmap(ipage);
 	return err;

commit 8c26d7d5717adf7f06d98c4416852d09566edd7c
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed May 15 16:12:18 2013 +0900

    f2fs: fix por_doing variable coverage
    
    The reason of using sbi->por_doing is to alleviate data writes during the
    recovery.
    The find_fsync_dnodes() produces some dirty dentry pages, so we should
    cover it too with sbi->por_doing.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 294198775f8b..4d895149a6f0 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -381,6 +381,7 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 	INIT_LIST_HEAD(&inode_list);
 
 	/* step #1: find fsynced inode numbers */
+	sbi->por_doing = 1;
 	err = find_fsync_dnodes(sbi, &inode_list);
 	if (err)
 		goto out;
@@ -389,13 +390,12 @@ int recover_fsync_data(struct f2fs_sb_info *sbi)
 		goto out;
 
 	/* step #2: recover data */
-	sbi->por_doing = 1;
 	err = recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
-	sbi->por_doing = 0;
 	BUG_ON(!list_empty(&inode_list));
 out:
 	destroy_fsync_dnodes(sbi, &inode_list);
 	kmem_cache_destroy(fsync_entry_slab);
+	sbi->por_doing = 0;
 	write_checkpoint(sbi, false);
 	return err;
 }

commit addbe45b005d73f876d55bcfc16f4a6ce52a55e3
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed May 15 10:49:13 2013 +0900

    f2fs: remove redundant assignment
    
    We don't need to assign a value redundantly.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 60c8a5097058..294198775f8b 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -126,7 +126,6 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 
 		entry = get_fsync_inode(head, ino_of_node(page));
 		if (entry) {
-			entry->blkaddr = blkaddr;
 			if (IS_INODE(page) && is_dent_dnode(page))
 				set_inode_flag(F2FS_I(entry->inode),
 							FI_INC_LINK);
@@ -150,10 +149,10 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 				kmem_cache_free(fsync_entry_slab, entry);
 				goto unlock_out;
 			}
-
 			list_add_tail(&entry->list, head);
-			entry->blkaddr = blkaddr;
 		}
+		entry->blkaddr = blkaddr;
+
 		if (IS_INODE(page)) {
 			err = recover_inode(entry->inode, page);
 			if (err == -ENOENT) {

commit 047184b42b52376f4066f9ab357c0a61a12f116e
Author: Chris Fries <C.Fries@motorola.com>
Date:   Thu May 2 16:09:05 2013 -0500

    f2fs: recover when journal contains deleted files
    
    When recovering a journal file with fsync data for files that have
    been deleted, don't bail out on recovery.
    
    Signed-off-by: Chris Fries <C.Fries@motorola.com>
    Reviewed-by: Russell Knize <rknize2@motorola.com>
    Reviewed-by: Jason Hrycay <jason.hrycay@motorola.com>
    [Jaegeuk Kim: fit the coding style]
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index f16d12df8e99..60c8a5097058 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -53,7 +53,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 
 	dir = f2fs_iget(inode->i_sb, le32_to_cpu(raw_inode->i_pino));
 	if (IS_ERR(dir)) {
-		err = -EINVAL;
+		err = PTR_ERR(dir);
 		goto out;
 	}
 
@@ -156,8 +156,12 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 		}
 		if (IS_INODE(page)) {
 			err = recover_inode(entry->inode, page);
-			if (err)
+			if (err == -ENOENT) {
+				goto next;
+			} else if (err) {
+				err = -EINVAL;
 				goto unlock_out;
+			}
 		}
 next:
 		/* check next segment */

commit 399368372ed9f3c396eadb5c2bbc98be8c774a39
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Nov 22 16:21:29 2012 +0900

    f2fs: introduce a new global lock scheme
    
    In the previous version, f2fs uses global locks according to the usage types,
    such as directory operations, block allocation, block write, and so on.
    
    Reference the following lock types in f2fs.h.
    enum lock_type {
            RENAME,         /* for renaming operations */
            DENTRY_OPS,     /* for directory operations */
            DATA_WRITE,     /* for data write */
            DATA_NEW,       /* for data allocation */
            DATA_TRUNC,     /* for data truncate */
            NODE_NEW,       /* for node allocation */
            NODE_TRUNC,     /* for node truncate */
            NODE_WRITE,     /* for node write */
            NR_LOCK_TYPE,
    };
    
    In that case, we lose the performance under the multi-threading environment,
    since every types of operations must be conducted one at a time.
    
    In order to address the problem, let's share the locks globally with a mutex
    array regardless of any types.
    So, let users grab a mutex and perform their jobs in parallel as much as
    possbile.
    
    For this, I propose a new global lock scheme as follows.
    
    0. Data structure
     - f2fs_sb_info -> mutex_lock[NR_GLOBAL_LOCKS]
     - f2fs_sb_info -> node_write
    
    1. mutex_lock_op(sbi)
     - try to get an avaiable lock from the array.
     - returns the index of the gottern lock variable.
    
    2. mutex_unlock_op(sbi, index of the lock)
     - unlock the given index of the lock.
    
    3. mutex_lock_all(sbi)
     - grab all the locks in the array before the checkpoint.
    
    4. mutex_unlock_all(sbi)
     - release all the locks in the array after checkpoint.
    
    5. block_operations()
     - call mutex_lock_all()
     - sync_dirty_dir_inodes()
     - grab node_write
     - sync_node_pages()
    
    Note that,
     the pairs of mutex_lock_op()/mutex_unlock_op() and
     mutex_lock_all()/mutex_unlock_all() should be used together.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 61bdaa755906..f16d12df8e99 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -242,6 +242,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	struct f2fs_summary sum;
 	struct node_info ni;
 	int err = 0;
+	int ilock;
 
 	start = start_bidx_of_node(ofs_of_node(page));
 	if (IS_INODE(page))
@@ -249,10 +250,14 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 	else
 		end = start + ADDRS_PER_BLOCK;
 
+	ilock = mutex_lock_op(sbi);
 	set_new_dnode(&dn, inode, NULL, NULL, 0);
+
 	err = get_dnode_of_data(&dn, start, ALLOC_NODE);
-	if (err)
+	if (err) {
+		mutex_unlock_op(sbi, ilock);
 		return err;
+	}
 
 	wait_on_page_writeback(dn.node_page);
 
@@ -297,6 +302,7 @@ static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 	recover_node_page(sbi, dn.node_page, &sum, &ni, blkaddr);
 	f2fs_put_dnode(&dn);
+	mutex_unlock_op(sbi, ilock);
 	return 0;
 }
 

commit 6ead114232f786e3ef7a034c8617f2a4df8e5226
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Mar 20 19:01:06 2013 +0900

    f2fs: fix the recovery flow to handle errors correctly
    
    We should handle errors during the recovery flow correctly.
    For example, if we get -ENOMEM, we should report a mount failure instead of
    conducting the remained mount procedure.
    
    Reviewed-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 2d86eb26c493..61bdaa755906 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -118,10 +118,8 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 
 		lock_page(page);
 
-		if (cp_ver != cpver_of_node(page)) {
-			err = -EINVAL;
+		if (cp_ver != cpver_of_node(page))
 			goto unlock_out;
-		}
 
 		if (!is_fsync_dnode(page))
 			goto next;
@@ -134,10 +132,9 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 							FI_INC_LINK);
 		} else {
 			if (IS_INODE(page) && is_dent_dnode(page)) {
-				if (recover_inode_page(sbi, page)) {
-					err = -ENOMEM;
+				err = recover_inode_page(sbi, page);
+				if (err)
 					goto unlock_out;
-				}
 			}
 
 			/* add this fsync inode to the list */
@@ -237,13 +234,14 @@ static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	iput(inode);
 }
 
-static void do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
+static int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 					struct page *page, block_t blkaddr)
 {
 	unsigned int start, end;
 	struct dnode_of_data dn;
 	struct f2fs_summary sum;
 	struct node_info ni;
+	int err = 0;
 
 	start = start_bidx_of_node(ofs_of_node(page));
 	if (IS_INODE(page))
@@ -252,8 +250,9 @@ static void do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		end = start + ADDRS_PER_BLOCK;
 
 	set_new_dnode(&dn, inode, NULL, NULL, 0);
-	if (get_dnode_of_data(&dn, start, ALLOC_NODE))
-		return;
+	err = get_dnode_of_data(&dn, start, ALLOC_NODE);
+	if (err)
+		return err;
 
 	wait_on_page_writeback(dn.node_page);
 
@@ -298,14 +297,16 @@ static void do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 
 	recover_node_page(sbi, dn.node_page, &sum, &ni, blkaddr);
 	f2fs_put_dnode(&dn);
+	return 0;
 }
 
-static void recover_data(struct f2fs_sb_info *sbi,
+static int recover_data(struct f2fs_sb_info *sbi,
 				struct list_head *head, int type)
 {
 	unsigned long long cp_ver = le64_to_cpu(sbi->ckpt->checkpoint_ver);
 	struct curseg_info *curseg;
 	struct page *page;
+	int err = 0;
 	block_t blkaddr;
 
 	/* get node pages in the current segment */
@@ -315,13 +316,15 @@ static void recover_data(struct f2fs_sb_info *sbi,
 	/* read node page */
 	page = alloc_page(GFP_NOFS | __GFP_ZERO);
 	if (IS_ERR(page))
-		return;
+		return -ENOMEM;
+
 	lock_page(page);
 
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (f2fs_readpage(sbi, page, blkaddr, READ_SYNC))
+		err = f2fs_readpage(sbi, page, blkaddr, READ_SYNC);
+		if (err)
 			goto out;
 
 		lock_page(page);
@@ -333,7 +336,9 @@ static void recover_data(struct f2fs_sb_info *sbi,
 		if (!entry)
 			goto next;
 
-		do_recover_data(sbi, entry->inode, page, blkaddr);
+		err = do_recover_data(sbi, entry->inode, page, blkaddr);
+		if (err)
+			goto out;
 
 		if (entry->blkaddr == blkaddr) {
 			iput(entry->inode);
@@ -349,22 +354,26 @@ static void recover_data(struct f2fs_sb_info *sbi,
 out:
 	__free_pages(page, 0);
 
-	allocate_new_segments(sbi);
+	if (!err)
+		allocate_new_segments(sbi);
+	return err;
 }
 
-void recover_fsync_data(struct f2fs_sb_info *sbi)
+int recover_fsync_data(struct f2fs_sb_info *sbi)
 {
 	struct list_head inode_list;
+	int err;
 
 	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
 			sizeof(struct fsync_inode_entry), NULL);
 	if (unlikely(!fsync_entry_slab))
-		return;
+		return -ENOMEM;
 
 	INIT_LIST_HEAD(&inode_list);
 
 	/* step #1: find fsynced inode numbers */
-	if (find_fsync_dnodes(sbi, &inode_list))
+	err = find_fsync_dnodes(sbi, &inode_list);
+	if (err)
 		goto out;
 
 	if (list_empty(&inode_list))
@@ -372,11 +381,12 @@ void recover_fsync_data(struct f2fs_sb_info *sbi)
 
 	/* step #2: recover data */
 	sbi->por_doing = 1;
-	recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
+	err = recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
 	sbi->por_doing = 0;
 	BUG_ON(!list_empty(&inode_list));
 out:
 	destroy_fsync_dnodes(sbi, &inode_list);
 	kmem_cache_destroy(fsync_entry_slab);
 	write_checkpoint(sbi, false);
+	return err;
 }

commit 393ff91f57c87d48ffed30878be6e3e486d3a00a
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Mar 8 21:29:23 2013 +0900

    f2fs: reduce unncessary locking pages during read
    
    This patch reduces redundant locking and unlocking pages during read operations.
    In f2fs_readpage, let's use wait_on_page_locked() instead of lock_page.
    And then, when we need to modify any data finally, let's lock the page so that
    we can avoid lock contention.
    
    [readpage rule]
    - The f2fs_readpage returns unlocked page, or released page too in error cases.
    - Its caller should handle read error, -EIO, after locking the page, which
      indicates read completion.
    - Its caller should check PageUptodate after grab_cache_page.
    
    Signed-off-by: Changman Lee <cm224.lee@samsung.com>
    Reviewed-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 6b82e2034cfd..2d86eb26c493 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -112,11 +112,16 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 	while (1) {
 		struct fsync_inode_entry *entry;
 
-		if (f2fs_readpage(sbi, page, blkaddr, READ_SYNC))
+		err = f2fs_readpage(sbi, page, blkaddr, READ_SYNC);
+		if (err)
 			goto out;
 
-		if (cp_ver != cpver_of_node(page))
-			goto out;
+		lock_page(page);
+
+		if (cp_ver != cpver_of_node(page)) {
+			err = -EINVAL;
+			goto unlock_out;
+		}
 
 		if (!is_fsync_dnode(page))
 			goto next;
@@ -131,7 +136,7 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 			if (IS_INODE(page) && is_dent_dnode(page)) {
 				if (recover_inode_page(sbi, page)) {
 					err = -ENOMEM;
-					goto out;
+					goto unlock_out;
 				}
 			}
 
@@ -139,14 +144,14 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 			entry = kmem_cache_alloc(fsync_entry_slab, GFP_NOFS);
 			if (!entry) {
 				err = -ENOMEM;
-				goto out;
+				goto unlock_out;
 			}
 
 			entry->inode = f2fs_iget(sbi->sb, ino_of_node(page));
 			if (IS_ERR(entry->inode)) {
 				err = PTR_ERR(entry->inode);
 				kmem_cache_free(fsync_entry_slab, entry);
-				goto out;
+				goto unlock_out;
 			}
 
 			list_add_tail(&entry->list, head);
@@ -155,15 +160,15 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 		if (IS_INODE(page)) {
 			err = recover_inode(entry->inode, page);
 			if (err)
-				goto out;
+				goto unlock_out;
 		}
 next:
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
-		ClearPageUptodate(page);
 	}
-out:
+unlock_out:
 	unlock_page(page);
+out:
 	__free_pages(page, 0);
 	return err;
 }
@@ -319,8 +324,10 @@ static void recover_data(struct f2fs_sb_info *sbi,
 		if (f2fs_readpage(sbi, page, blkaddr, READ_SYNC))
 			goto out;
 
+		lock_page(page);
+
 		if (cp_ver != cpver_of_node(page))
-			goto out;
+			goto unlock_out;
 
 		entry = get_fsync_inode(head, ino_of_node(page));
 		if (!entry)
@@ -336,10 +343,10 @@ static void recover_data(struct f2fs_sb_info *sbi,
 next:
 		/* check next segment */
 		blkaddr = next_blkaddr_of_node(page);
-		ClearPageUptodate(page);
 	}
-out:
+unlock_out:
 	unlock_page(page);
+out:
 	__free_pages(page, 0);
 
 	allocate_new_segments(sbi);

commit 266e97a81cf73d1a0dac5f68391da382630a80b7
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Feb 26 13:10:46 2013 +0900

    f2fs: introduce readahead mode of node pages
    
    Previously, f2fs reads several node pages ahead when get_dnode_of_data is called
    with RDONLY_NODE flag.
    And, this flag is set by the following functions.
    - get_data_block_ro
    - get_lock_data_page
    - do_write_data_page
    - truncate_blocks
    - truncate_hole
    
    However, this readahead mechanism is initially introduced for the use of
    get_data_block_ro to enhance the sequential read performance.
    
    So, let's clarify all the cases with the additional modes as follows.
    
    enum {
            ALLOC_NODE,     /* allocate a new node page if needed */
            LOOKUP_NODE,    /* look up a node without readahead */
            LOOKUP_NODE_RA, /*
                             * look up a node with readahead called
                             * by get_datablock_ro.
                             */
    }
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>
    Reviewed-by: Namjae Jeon <namjae.jeon@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b235215ac138..6b82e2034cfd 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -247,7 +247,7 @@ static void do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
 		end = start + ADDRS_PER_BLOCK;
 
 	set_new_dnode(&dn, inode, NULL, NULL, 0);
-	if (get_dnode_of_data(&dn, start, 0))
+	if (get_dnode_of_data(&dn, start, ALLOC_NODE))
 		return;
 
 	wait_on_page_writeback(dn.node_page);

commit 90b2fc64f0a6d6a6706eae0a90038ed576d5d4b6
Merge: e9750824114f b7f7a5e0be94
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Feb 12 07:17:20 2013 +0900

    Merge branch 'f2fs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs into dev
    
    Pull f2fs cleanup patches from Al Viro:
    
    f2fs: get rid of fake on-stack dentries
    f2fs: switch init_inode_metadata() to passing parent and name separately
    f2fs: switch new_inode_page() from dentry to qstr
    f2fs: init_dent_inode() should take qstr
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>
    
    Conflicts:
            fs/f2fs/recovery.c

commit 437275272f9e635673f065300e5d95226a25cb06
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Mon Feb 4 15:11:17 2013 +0900

    f2fs: clarify and enhance the f2fs_gc flow
    
    This patch makes clearer the ambiguous f2fs_gc flow as follows.
    
    1. Remove intermediate checkpoint condition during f2fs_gc
     (i.e., should_do_checkpoint() and GC_BLOCKED)
    
    2. Remove unnecessary return values of f2fs_gc because of #1.
     (i.e., GC_NODE, GC_OK, etc)
    
    3. Simplify write_checkpoint() because of #2.
    
    4. Clarify the main f2fs_gc flow.
     o monitor how many freed sections during one iteration of do_garbage_collect().
     o do GC more without checkpoints if we can't get enough free sections.
     o do checkpoint once we've got enough free sections through forground GCs.
    
    5. Adopt thread-logging (Slack-Space-Recycle) scheme more aggressively on data
      log types. See. get_ssr_segement()
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index e2a3e1a8eae9..01e1a03b54c8 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -373,5 +373,5 @@ void recover_fsync_data(struct f2fs_sb_info *sbi)
 out:
 	destroy_fsync_dnodes(sbi, &inode_list);
 	kmem_cache_destroy(fsync_entry_slab);
-	write_checkpoint(sbi, false, false);
+	write_checkpoint(sbi, false);
 }

commit d4686d56ec912d55fd8a9d6d509de50de24e90ab
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Jan 31 15:36:04 2013 +0900

    f2fs: avoid balanc_fs during evict_inode
    
    1. Background
    
    Previously, if f2fs tries to move data blocks of an *evicting* inode during the
    cleaning process, it stops the process incompletely and then restarts the whole
    process, since it needs a locked inode to grab victim data pages in its address
    space. In order to get a locked inode, iget_locked() by f2fs_iget() is normally
    used, but, it waits if the inode is on freeing.
    
    So, here is a deadlock scenario.
    1. f2fs_evict_inode()       <- inode "A"
      2. f2fs_balance_fs()
        3. f2fs_gc()
          4. gc_data_segment()
            5. f2fs_iget()      <- inode "A" too!
    
    If step #1 and #5 treat a same inode "A", step #5 would fall into deadlock since
    the inode "A" is on freeing. In order to resolve this, f2fs_iget_nowait() which
    skips __wait_on_freeing_inode() was introduced in step #5, and stops f2fs_gc()
    to complete f2fs_evict_inode().
    
    1. f2fs_evict_inode()           <- inode "A"
      2. f2fs_balance_fs()
        3. f2fs_gc()
          4. gc_data_segment()
            5. f2fs_iget_nowait()   <- inode "A", then stop f2fs_gc() w/ -ENOENT
    
    2. Problem and Solution
    
    In the above scenario, however, f2fs cannot finish f2fs_evict_inode() only if:
     o there are not enough free sections, and
     o f2fs_gc() tries to move data blocks of the *evicting* inode repeatedly.
    
    So, the final solution is to use f2fs_iget() and remove f2fs_balance_fs() in
    f2fs_evict_inode().
    The f2fs_evict_inode() actually truncates all the data and node blocks, which
    means that it doesn't produce any dirty node pages accordingly.
    So, we don't need to do f2fs_balance_fs() in practical.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index f42e4060b399..e2a3e1a8eae9 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -226,7 +226,7 @@ static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 	f2fs_put_page(node_page, 1);
 
 	/* Deallocate previous index in the node page */
-	inode = f2fs_iget_nowait(sbi->sb, ino);
+	inode = f2fs_iget(sbi->sb, ino);
 	if (IS_ERR(inode))
 		return;
 

commit b7f7a5e0be94d13875a1c6c9aa65eeb11a46fc1b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Jan 25 16:15:43 2013 -0500

    f2fs: get rid of fake on-stack dentries
    
    those should never be used for a lot of reasons...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b571fee677d5..62000422879a 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -42,7 +42,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 {
 	struct f2fs_node *raw_node = (struct f2fs_node *)kmap(ipage);
 	struct f2fs_inode *raw_inode = &(raw_node->i);
-	struct dentry dent, parent;
+	struct qstr name;
 	struct f2fs_dir_entry *de;
 	struct page *page;
 	struct inode *dir;
@@ -57,17 +57,15 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 		goto out;
 	}
 
-	parent.d_inode = dir;
-	dent.d_parent = &parent;
-	dent.d_name.len = le32_to_cpu(raw_inode->i_namelen);
-	dent.d_name.name = raw_inode->i_name;
+	name.len = le32_to_cpu(raw_inode->i_namelen);
+	name.name = raw_inode->i_name;
 
-	de = f2fs_find_entry(dir, &dent.d_name, &page);
+	de = f2fs_find_entry(dir, &name, &page);
 	if (de) {
 		kunmap(page);
 		f2fs_put_page(page, 0);
 	} else {
-		f2fs_add_link(&dent, inode);
+		__f2fs_add_link(dir, &name, inode);
 	}
 	iput(dir);
 out:

commit d8b79b2f94600262fcfbffbe3df7fd3c83c6c51b
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Sun Jan 20 18:02:58 2013 +0300

    f2fs: use _safe() version of list_for_each
    
    This is calling list_del() inside a loop which is a problem when we try
    move to the next item on the list.  I've converted it to use the _safe
    version.  And also, as a cleanup, I've converted it to use
    list_for_each_entry instead of list_for_each.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 6cc046d36815..f42e4060b399 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -173,10 +173,9 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 static void destroy_fsync_dnodes(struct f2fs_sb_info *sbi,
 					struct list_head *head)
 {
-	struct list_head *this;
-	struct fsync_inode_entry *entry;
-	list_for_each(this, head) {
-		entry = list_entry(this, struct fsync_inode_entry, list);
+	struct fsync_inode_entry *entry, *tmp;
+
+	list_for_each_entry_safe(entry, tmp, head, list) {
 		iput(entry->inode);
 		list_del(&entry->list);
 		kmem_cache_free(fsync_entry_slab, entry);

commit c335a86930b4841c11df12e1fdfd8345e0ebce84
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Jan 3 09:33:20 2013 +0900

    f2fs: check return value during recovery
    
    This patch resolves Coverity #753102:
    
    >>> No check of the return value of "f2fs_add_link(&dent, inode)".
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 502c63d8f096..6cc046d36815 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -67,7 +67,7 @@ static int recover_dentry(struct page *ipage, struct inode *inode)
 		kunmap(page);
 		f2fs_put_page(page, 0);
 	} else {
-		f2fs_add_link(&dent, inode);
+		err = f2fs_add_link(&dent, inode);
 	}
 	iput(dir);
 out:

commit 24c366a9ea256b86426b42e75f764495a2558861
Author: Namjae Jeon <namjae.jeon@samsung.com>
Date:   Sun Dec 30 14:53:08 2012 +0900

    f2fs: remove unneeded INIT_LIST_HEAD at few places
    
    While creating a new entry for addition to the list(orphan inode list
    and fsync inode entry list), there is no need to call HEAD initialization
    for these entries. So, remove that init part.
    
    Signed-off-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Amit Sahrawat <a.sahrawat@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b571fee677d5..502c63d8f096 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -151,7 +151,6 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 				goto out;
 			}
 
-			INIT_LIST_HEAD(&entry->list);
 			list_add_tail(&entry->list, head);
 			entry->blkaddr = blkaddr;
 		}

commit fd8bb65f796f041ee6ba400255ca9021bc45a992
Author: Namjae Jeon <namjae.jeon@samsung.com>
Date:   Sat Dec 22 12:10:12 2012 +0900

    f2fs: fix fsync_inode list addition logic and avoid invalid access to memory
    
    In function find_fsync_dnodes() - the fsync inodes gets added to the list, but
    in one path suppose f2fs_iget results in error, in such case - error gets added
    to the fsync inode list.
    In next call to recover_data()->get_fsync_inode()
    entry = list_entry(this, struct fsync_inode_entry, list);
                    if (entry->inode->i_ino == ino)
    This can result in "invalid access to memory" when it encounters 'error' as
    entry in the fsync inode list.
    So, add the fsync inode entry to the list only in case of no errors.
    And, free the object at that point itself in case of issue.
    
    Signed-off-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Amit Sahrawat <a.sahrawat@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 207e2c865c7e..b571fee677d5 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -144,14 +144,15 @@ static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
 				goto out;
 			}
 
-			INIT_LIST_HEAD(&entry->list);
-			list_add_tail(&entry->list, head);
-
 			entry->inode = f2fs_iget(sbi->sb, ino_of_node(page));
 			if (IS_ERR(entry->inode)) {
 				err = PTR_ERR(entry->inode);
+				kmem_cache_free(fsync_entry_slab, entry);
 				goto out;
 			}
+
+			INIT_LIST_HEAD(&entry->list);
+			list_add_tail(&entry->list, head);
 			entry->blkaddr = blkaddr;
 		}
 		if (IS_INODE(page)) {

commit 06025f4df88e9e41f4ebcf6b4c3df30661332bc9
Author: Namjae Jeon <namjae.jeon@samsung.com>
Date:   Sat Dec 22 12:09:43 2012 +0900

    f2fs: handle error from f2fs_iget_nowait
    
    In case f2fs_iget_nowait returns error, it results in truncate_hole being
    called with 'error' value as inode pointer. There is no check in truncate_hole
    for valid inode, so it could result in crash due "invalid access to memory".
    Avoid this by handling error condition properly.
    
    Signed-off-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Amit Sahrawat <a.sahrawat@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index b07e9b6ef376..207e2c865c7e 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -228,6 +228,9 @@ static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
 
 	/* Deallocate previous index in the node page */
 	inode = f2fs_iget_nowait(sbi->sb, ino);
+	if (IS_ERR(inode))
+		return;
+
 	truncate_hole(inode, bidx, bidx + 1);
 	iput(inode);
 }

commit 0a8165d7c2cf1395059db20ab07665baf3758fcd
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Nov 29 13:28:09 2012 +0900

    f2fs: adjust kernel coding style
    
    As pointed out by Randy Dunlap, this patch removes all usage of "/**" for comment
    blocks. Instead, just use "/*".
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 222a7bb92214..b07e9b6ef376 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -1,4 +1,4 @@
-/**
+/*
  * fs/f2fs/recovery.c
  *
  * Copyright (c) 2012 Samsung Electronics Co., Ltd.

commit 25ca923b2a766b9c93b63777ead351137533a623
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Nov 28 16:12:41 2012 +0900

    f2fs: fix endian conversion bugs reported by sparse
    
    This patch should resolve the bugs reported by the sparse tool.
    Initial reports were written by "kbuild test robot" managed by fengguang.wu.
    
    In my local machines, I've tested also by running:
    > make C=2 CF="-D__CHECK_ENDIAN__"
    
    Accordingly, I've found lots of warnings and bugs related to the endian
    conversion. And I've fixed all at this moment.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
index 7a43df0b72c1..222a7bb92214 100644
--- a/fs/f2fs/recovery.c
+++ b/fs/f2fs/recovery.c
@@ -81,7 +81,7 @@ static int recover_inode(struct inode *inode, struct page *node_page)
 	struct f2fs_node *raw_node = (struct f2fs_node *)kaddr;
 	struct f2fs_inode *raw_inode = &(raw_node->i);
 
-	inode->i_mode = le32_to_cpu(raw_inode->i_mode);
+	inode->i_mode = le16_to_cpu(raw_inode->i_mode);
 	i_size_write(inode, le64_to_cpu(raw_inode->i_size));
 	inode->i_atime.tv_sec = le64_to_cpu(raw_inode->i_mtime);
 	inode->i_ctime.tv_sec = le64_to_cpu(raw_inode->i_ctime);

commit d624c96fb3249e5d3dcf4e60a805e5e6b0dd7d91
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Nov 2 17:13:32 2012 +0900

    f2fs: add recovery routines for roll-forward
    
    This adds roll-forward routines to recover fsynced data.
    
    - F2FS uses basically roll-back model with checkpointing.
    
    - In order to implement fsync(), there are two approaches as follows.
    
    1. A roll-back model with checkpointing at every fsync()
     : This is a naive method, but suffers from very low performance.
    
    2. A roll-forward model
     : F2FS adopts this model where all the fsynced data should be recovered, which
       were written after checkpointing was done. In order to figure out the data,
       F2FS keeps a "fsync" mark in direct node blocks. In addition, F2FS remains
       the location of next node block in each direct node block for reconstructing
       the chain of node blocks during the recovery.
    
    - In order to enhance the performance, F2FS keeps a "dentry" mark also in direct
      node blocks. If this is set during the recovery, F2FS replays adding a dentry.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/recovery.c b/fs/f2fs/recovery.c
new file mode 100644
index 000000000000..7a43df0b72c1
--- /dev/null
+++ b/fs/f2fs/recovery.c
@@ -0,0 +1,375 @@
+/**
+ * fs/f2fs/recovery.c
+ *
+ * Copyright (c) 2012 Samsung Electronics Co., Ltd.
+ *             http://www.samsung.com/
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/fs.h>
+#include <linux/f2fs_fs.h>
+#include "f2fs.h"
+#include "node.h"
+#include "segment.h"
+
+static struct kmem_cache *fsync_entry_slab;
+
+bool space_for_roll_forward(struct f2fs_sb_info *sbi)
+{
+	if (sbi->last_valid_block_count + sbi->alloc_valid_block_count
+			> sbi->user_block_count)
+		return false;
+	return true;
+}
+
+static struct fsync_inode_entry *get_fsync_inode(struct list_head *head,
+								nid_t ino)
+{
+	struct list_head *this;
+	struct fsync_inode_entry *entry;
+
+	list_for_each(this, head) {
+		entry = list_entry(this, struct fsync_inode_entry, list);
+		if (entry->inode->i_ino == ino)
+			return entry;
+	}
+	return NULL;
+}
+
+static int recover_dentry(struct page *ipage, struct inode *inode)
+{
+	struct f2fs_node *raw_node = (struct f2fs_node *)kmap(ipage);
+	struct f2fs_inode *raw_inode = &(raw_node->i);
+	struct dentry dent, parent;
+	struct f2fs_dir_entry *de;
+	struct page *page;
+	struct inode *dir;
+	int err = 0;
+
+	if (!is_dent_dnode(ipage))
+		goto out;
+
+	dir = f2fs_iget(inode->i_sb, le32_to_cpu(raw_inode->i_pino));
+	if (IS_ERR(dir)) {
+		err = -EINVAL;
+		goto out;
+	}
+
+	parent.d_inode = dir;
+	dent.d_parent = &parent;
+	dent.d_name.len = le32_to_cpu(raw_inode->i_namelen);
+	dent.d_name.name = raw_inode->i_name;
+
+	de = f2fs_find_entry(dir, &dent.d_name, &page);
+	if (de) {
+		kunmap(page);
+		f2fs_put_page(page, 0);
+	} else {
+		f2fs_add_link(&dent, inode);
+	}
+	iput(dir);
+out:
+	kunmap(ipage);
+	return err;
+}
+
+static int recover_inode(struct inode *inode, struct page *node_page)
+{
+	void *kaddr = page_address(node_page);
+	struct f2fs_node *raw_node = (struct f2fs_node *)kaddr;
+	struct f2fs_inode *raw_inode = &(raw_node->i);
+
+	inode->i_mode = le32_to_cpu(raw_inode->i_mode);
+	i_size_write(inode, le64_to_cpu(raw_inode->i_size));
+	inode->i_atime.tv_sec = le64_to_cpu(raw_inode->i_mtime);
+	inode->i_ctime.tv_sec = le64_to_cpu(raw_inode->i_ctime);
+	inode->i_mtime.tv_sec = le64_to_cpu(raw_inode->i_mtime);
+	inode->i_atime.tv_nsec = le32_to_cpu(raw_inode->i_mtime_nsec);
+	inode->i_ctime.tv_nsec = le32_to_cpu(raw_inode->i_ctime_nsec);
+	inode->i_mtime.tv_nsec = le32_to_cpu(raw_inode->i_mtime_nsec);
+
+	return recover_dentry(node_page, inode);
+}
+
+static int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head)
+{
+	unsigned long long cp_ver = le64_to_cpu(sbi->ckpt->checkpoint_ver);
+	struct curseg_info *curseg;
+	struct page *page;
+	block_t blkaddr;
+	int err = 0;
+
+	/* get node pages in the current segment */
+	curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
+	blkaddr = START_BLOCK(sbi, curseg->segno) + curseg->next_blkoff;
+
+	/* read node page */
+	page = alloc_page(GFP_F2FS_ZERO);
+	if (IS_ERR(page))
+		return PTR_ERR(page);
+	lock_page(page);
+
+	while (1) {
+		struct fsync_inode_entry *entry;
+
+		if (f2fs_readpage(sbi, page, blkaddr, READ_SYNC))
+			goto out;
+
+		if (cp_ver != cpver_of_node(page))
+			goto out;
+
+		if (!is_fsync_dnode(page))
+			goto next;
+
+		entry = get_fsync_inode(head, ino_of_node(page));
+		if (entry) {
+			entry->blkaddr = blkaddr;
+			if (IS_INODE(page) && is_dent_dnode(page))
+				set_inode_flag(F2FS_I(entry->inode),
+							FI_INC_LINK);
+		} else {
+			if (IS_INODE(page) && is_dent_dnode(page)) {
+				if (recover_inode_page(sbi, page)) {
+					err = -ENOMEM;
+					goto out;
+				}
+			}
+
+			/* add this fsync inode to the list */
+			entry = kmem_cache_alloc(fsync_entry_slab, GFP_NOFS);
+			if (!entry) {
+				err = -ENOMEM;
+				goto out;
+			}
+
+			INIT_LIST_HEAD(&entry->list);
+			list_add_tail(&entry->list, head);
+
+			entry->inode = f2fs_iget(sbi->sb, ino_of_node(page));
+			if (IS_ERR(entry->inode)) {
+				err = PTR_ERR(entry->inode);
+				goto out;
+			}
+			entry->blkaddr = blkaddr;
+		}
+		if (IS_INODE(page)) {
+			err = recover_inode(entry->inode, page);
+			if (err)
+				goto out;
+		}
+next:
+		/* check next segment */
+		blkaddr = next_blkaddr_of_node(page);
+		ClearPageUptodate(page);
+	}
+out:
+	unlock_page(page);
+	__free_pages(page, 0);
+	return err;
+}
+
+static void destroy_fsync_dnodes(struct f2fs_sb_info *sbi,
+					struct list_head *head)
+{
+	struct list_head *this;
+	struct fsync_inode_entry *entry;
+	list_for_each(this, head) {
+		entry = list_entry(this, struct fsync_inode_entry, list);
+		iput(entry->inode);
+		list_del(&entry->list);
+		kmem_cache_free(fsync_entry_slab, entry);
+	}
+}
+
+static void check_index_in_prev_nodes(struct f2fs_sb_info *sbi,
+						block_t blkaddr)
+{
+	struct seg_entry *sentry;
+	unsigned int segno = GET_SEGNO(sbi, blkaddr);
+	unsigned short blkoff = GET_SEGOFF_FROM_SEG0(sbi, blkaddr) &
+					(sbi->blocks_per_seg - 1);
+	struct f2fs_summary sum;
+	nid_t ino;
+	void *kaddr;
+	struct inode *inode;
+	struct page *node_page;
+	block_t bidx;
+	int i;
+
+	sentry = get_seg_entry(sbi, segno);
+	if (!f2fs_test_bit(blkoff, sentry->cur_valid_map))
+		return;
+
+	/* Get the previous summary */
+	for (i = CURSEG_WARM_DATA; i <= CURSEG_COLD_DATA; i++) {
+		struct curseg_info *curseg = CURSEG_I(sbi, i);
+		if (curseg->segno == segno) {
+			sum = curseg->sum_blk->entries[blkoff];
+			break;
+		}
+	}
+	if (i > CURSEG_COLD_DATA) {
+		struct page *sum_page = get_sum_page(sbi, segno);
+		struct f2fs_summary_block *sum_node;
+		kaddr = page_address(sum_page);
+		sum_node = (struct f2fs_summary_block *)kaddr;
+		sum = sum_node->entries[blkoff];
+		f2fs_put_page(sum_page, 1);
+	}
+
+	/* Get the node page */
+	node_page = get_node_page(sbi, le32_to_cpu(sum.nid));
+	bidx = start_bidx_of_node(ofs_of_node(node_page)) +
+				le16_to_cpu(sum.ofs_in_node);
+	ino = ino_of_node(node_page);
+	f2fs_put_page(node_page, 1);
+
+	/* Deallocate previous index in the node page */
+	inode = f2fs_iget_nowait(sbi->sb, ino);
+	truncate_hole(inode, bidx, bidx + 1);
+	iput(inode);
+}
+
+static void do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,
+					struct page *page, block_t blkaddr)
+{
+	unsigned int start, end;
+	struct dnode_of_data dn;
+	struct f2fs_summary sum;
+	struct node_info ni;
+
+	start = start_bidx_of_node(ofs_of_node(page));
+	if (IS_INODE(page))
+		end = start + ADDRS_PER_INODE;
+	else
+		end = start + ADDRS_PER_BLOCK;
+
+	set_new_dnode(&dn, inode, NULL, NULL, 0);
+	if (get_dnode_of_data(&dn, start, 0))
+		return;
+
+	wait_on_page_writeback(dn.node_page);
+
+	get_node_info(sbi, dn.nid, &ni);
+	BUG_ON(ni.ino != ino_of_node(page));
+	BUG_ON(ofs_of_node(dn.node_page) != ofs_of_node(page));
+
+	for (; start < end; start++) {
+		block_t src, dest;
+
+		src = datablock_addr(dn.node_page, dn.ofs_in_node);
+		dest = datablock_addr(page, dn.ofs_in_node);
+
+		if (src != dest && dest != NEW_ADDR && dest != NULL_ADDR) {
+			if (src == NULL_ADDR) {
+				int err = reserve_new_block(&dn);
+				/* We should not get -ENOSPC */
+				BUG_ON(err);
+			}
+
+			/* Check the previous node page having this index */
+			check_index_in_prev_nodes(sbi, dest);
+
+			set_summary(&sum, dn.nid, dn.ofs_in_node, ni.version);
+
+			/* write dummy data page */
+			recover_data_page(sbi, NULL, &sum, src, dest);
+			update_extent_cache(dest, &dn);
+		}
+		dn.ofs_in_node++;
+	}
+
+	/* write node page in place */
+	set_summary(&sum, dn.nid, 0, 0);
+	if (IS_INODE(dn.node_page))
+		sync_inode_page(&dn);
+
+	copy_node_footer(dn.node_page, page);
+	fill_node_footer(dn.node_page, dn.nid, ni.ino,
+					ofs_of_node(page), false);
+	set_page_dirty(dn.node_page);
+
+	recover_node_page(sbi, dn.node_page, &sum, &ni, blkaddr);
+	f2fs_put_dnode(&dn);
+}
+
+static void recover_data(struct f2fs_sb_info *sbi,
+				struct list_head *head, int type)
+{
+	unsigned long long cp_ver = le64_to_cpu(sbi->ckpt->checkpoint_ver);
+	struct curseg_info *curseg;
+	struct page *page;
+	block_t blkaddr;
+
+	/* get node pages in the current segment */
+	curseg = CURSEG_I(sbi, type);
+	blkaddr = NEXT_FREE_BLKADDR(sbi, curseg);
+
+	/* read node page */
+	page = alloc_page(GFP_NOFS | __GFP_ZERO);
+	if (IS_ERR(page))
+		return;
+	lock_page(page);
+
+	while (1) {
+		struct fsync_inode_entry *entry;
+
+		if (f2fs_readpage(sbi, page, blkaddr, READ_SYNC))
+			goto out;
+
+		if (cp_ver != cpver_of_node(page))
+			goto out;
+
+		entry = get_fsync_inode(head, ino_of_node(page));
+		if (!entry)
+			goto next;
+
+		do_recover_data(sbi, entry->inode, page, blkaddr);
+
+		if (entry->blkaddr == blkaddr) {
+			iput(entry->inode);
+			list_del(&entry->list);
+			kmem_cache_free(fsync_entry_slab, entry);
+		}
+next:
+		/* check next segment */
+		blkaddr = next_blkaddr_of_node(page);
+		ClearPageUptodate(page);
+	}
+out:
+	unlock_page(page);
+	__free_pages(page, 0);
+
+	allocate_new_segments(sbi);
+}
+
+void recover_fsync_data(struct f2fs_sb_info *sbi)
+{
+	struct list_head inode_list;
+
+	fsync_entry_slab = f2fs_kmem_cache_create("f2fs_fsync_inode_entry",
+			sizeof(struct fsync_inode_entry), NULL);
+	if (unlikely(!fsync_entry_slab))
+		return;
+
+	INIT_LIST_HEAD(&inode_list);
+
+	/* step #1: find fsynced inode numbers */
+	if (find_fsync_dnodes(sbi, &inode_list))
+		goto out;
+
+	if (list_empty(&inode_list))
+		goto out;
+
+	/* step #2: recover data */
+	sbi->por_doing = 1;
+	recover_data(sbi, &inode_list, CURSEG_WARM_NODE);
+	sbi->por_doing = 0;
+	BUG_ON(!list_empty(&inode_list));
+out:
+	destroy_fsync_dnodes(sbi, &inode_list);
+	kmem_cache_destroy(fsync_entry_slab);
+	write_checkpoint(sbi, false, false);
+}
