commit 042be373adf719ab64c4a44ae809d110826becbf
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri May 8 17:50:20 2020 +0800

    f2fs: shrink spinlock coverage
    
    In f2fs_try_to_free_nids(), .nid_list_lock spinlock critical region will
    increase as expected shrink number increase, to avoid spining other CPUs
    for long time, we change to release nid caches with small batch each time
    under .nid_list_lock coverage.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 6a2011deea23..69e5859e993c 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -15,6 +15,9 @@
 #define FREE_NID_PAGES	8
 #define MAX_FREE_NIDS	(NAT_ENTRY_PER_BLOCK * FREE_NID_PAGES)
 
+/* size of free nid batch when shrinking */
+#define SHRINK_NID_BATCH_SIZE	8
+
 #define DEF_RA_NID_PAGES	0	/* # of nid pages to be readaheaded */
 
 /* maximum readahead size for node during getting data blocks */

commit d29fbcdb051fbe8e6aee87dd5a7df723f299494d
Author: Nishad Kamdar <nishadkamdar@gmail.com>
Date:   Sat Apr 25 18:49:08 2020 +0530

    f2fs: Use the correct style for SPDX License Identifier
    
    This patch corrects the SPDX License Identifier style in
    header files related to F2FS File System support.
    For C header files Documentation/process/license-rules.rst
    mandates C-like comments (opposed to C source files where
    C++ style should be used).
    
    Changes made by using a script provided by Joe Perches here:
    https://lkml.org/lkml/2019/2/7/46.
    
    Suggested-by: Joe Perches <joe@perches.com>
    Signed-off-by: Nishad Kamdar <nishadkamdar@gmail.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index e05af5df5648..6a2011deea23 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -1,4 +1,4 @@
-// SPDX-License-Identifier: GPL-2.0
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * fs/f2fs/node.h
  *

commit bae0ee7a767ceeea6d8e170da3f228fbc7480331
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Dec 25 17:43:42 2018 +0800

    f2fs: check PageWriteback flag for ordered case
    
    For all ordered cases in f2fs_wait_on_page_writeback(), we need to
    check PageWriteback status, so let's clean up to relocate the check
    into f2fs_wait_on_page_writeback().
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 1c73d879a9bc..e05af5df5648 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -361,7 +361,7 @@ static inline int set_nid(struct page *p, int off, nid_t nid, bool i)
 {
 	struct f2fs_node *rn = F2FS_NODE(p);
 
-	f2fs_wait_on_page_writeback(p, NODE, true);
+	f2fs_wait_on_page_writeback(p, NODE, true, true);
 
 	if (i)
 		rn->i.i_nid[off - NODE_DIR1_BLOCK] = cpu_to_le32(nid);

commit 7c1a000d466235c875a989971cfda344e6bb1166
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Sep 12 09:16:07 2018 +0800

    f2fs: add SPDX license identifiers
    
    Remove the verbose license text from f2fs files and replace them with
    SPDX tags.  This does not change the license of any of the code.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 0f4db7a61254..1c73d879a9bc 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -1,12 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * fs/f2fs/node.h
  *
  * Copyright (c) 2012 Samsung Electronics Co., Ltd.
  *             http://www.samsung.com/
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 /* start node id of a node block dedicated to the given node id */
 #define	START_NID(nid) (((nid) / NAT_ENTRY_PER_BLOCK) * NAT_ENTRY_PER_BLOCK)

commit fd8c8caf7e7c8261a92ce0f7f2cd0adb8afd9e0d
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Jul 25 19:16:21 2018 +0800

    f2fs: let checkpoint flush dnode page of regular
    
    Fsyncer will wait on all dnode pages of regular writeback before flushing,
    if there are async dnode pages blocked by IO scheduler, it may decrease
    fsync's performance.
    
    In this patch, we choose to let f2fs_balance_fs_bg() to trigger checkpoint
    to flush these dnode pages of regular, so async IO of dnode page can be
    elimitnated, making fsyncer only need to wait for sync IO.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 8f34bdffde93..0f4db7a61254 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -135,6 +135,11 @@ static inline bool excess_cached_nats(struct f2fs_sb_info *sbi)
 	return NM_I(sbi)->nat_cnt >= DEF_NAT_CACHE_THRESHOLD;
 }
 
+static inline bool excess_dirty_nodes(struct f2fs_sb_info *sbi)
+{
+	return get_pages(sbi, F2FS_DIRTY_NODES) >= sbi->blocks_per_seg * 8;
+}
+
 enum mem_type {
 	FREE_NIDS,	/* indicates the free nid list */
 	NAT_ENTRIES,	/* indicates the cached nat entry */

commit 54c55c4e4fc7ec35f96a3b6a626314b0b7256137
Author: Weichao Guo <guoweichao@huawei.com>
Date:   Fri Mar 9 23:10:21 2018 +0800

    f2fs: support in-memory inode checksum when checking consistency
    
    Enable in-memory inode checksum to protect metadata blocks from
    in-memory scribbles when checking consistency, which has no
    performance requirements.
    
    Signed-off-by: Weichao Guo <guoweichao@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index b95e49e4a928..8f34bdffde93 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -444,6 +444,10 @@ static inline void set_mark(struct page *page, int mark, int type)
 	else
 		flag &= ~(0x1 << type);
 	rn->footer.flag = cpu_to_le32(flag);
+
+#ifdef CONFIG_F2FS_CHECK_FS
+	f2fs_inode_chksum_set(F2FS_P_SB(page), page);
+#endif
 }
 #define set_dentry_mark(page, mark)	set_mark(page, mark, DENT_BIT_SHIFT)
 #define set_fsync_mark(page, mark)	set_mark(page, mark, FSYNC_BIT_SHIFT)

commit 780de47cf6cb5f524cd98ec8ffbffc3da5696e17
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Mar 20 23:08:30 2018 +0800

    f2fs: don't track new nat entry in nat set
    
    Nat entry set is used only in checkpoint(), and during checkpoint() we
    won't flush new nat entry with unallocated address, so we don't need to
    add new nat entry into nat set, then nat_entry_set::entry_cnt can
    indicate actual entry count we need to flush in checkpoint().
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index e593b4d78be2..b95e49e4a928 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -44,6 +44,7 @@ enum {
 	HAS_FSYNCED_INODE,	/* is the inode fsynced before? */
 	HAS_LAST_FSYNC,		/* has the latest node fsync mark? */
 	IS_DIRTY,		/* this nat entry is dirty? */
+	IS_PREALLOC,		/* nat entry is preallocated */
 };
 
 /*

commit c56675750d7c45ce6cc21a67770629aaf41d1491
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Mar 9 14:24:22 2018 +0800

    f2fs: remove unneeded set_cold_node()
    
    When setting COLD_BIT_SHIFT flag in node block, we only need to call
    set_cold_node() in new_node_page() and recover_inode_page() during
    node page initialization. So remove unneeded set_cold_node() in other
    places.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 081ef0d672bf..e593b4d78be2 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -422,12 +422,12 @@ static inline void clear_inline_node(struct page *page)
 	ClearPageChecked(page);
 }
 
-static inline void set_cold_node(struct inode *inode, struct page *page)
+static inline void set_cold_node(struct page *page, bool is_dir)
 {
 	struct f2fs_node *rn = F2FS_NODE(page);
 	unsigned int flag = le32_to_cpu(rn->footer.flag);
 
-	if (S_ISDIR(inode->i_mode))
+	if (is_dir)
 		flag &= ~(0x1 << COLD_BIT_SHIFT);
 	else
 		flag |= (0x1 << COLD_BIT_SHIFT);

commit f236792311f4575a1ca47240d3a74034096ef9e8
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jan 19 13:42:33 2018 -0800

    f2fs: allow to recover node blocks given updated checkpoint
    
    If fsck.f2fs changes crc, we have no way to recover some inode blocks by roll-
    forward recovery. Let's relax the condition to recover them.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 0ee3e5ff49a3..081ef0d672bf 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -305,6 +305,10 @@ static inline bool is_recoverable_dnode(struct page *page)
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(F2FS_P_SB(page));
 	__u64 cp_ver = cur_cp_version(ckpt);
 
+	/* Don't care crc part, if fsck.f2fs sets it. */
+	if (__is_set_ckpt_flags(ckpt, CP_NOCRC_RECOVERY_FLAG))
+		return (cp_ver << 32) == (cpver_of_node(page) << 32);
+
 	if (__is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG))
 		cp_ver |= (cur_cp_crc(ckpt) << 32);
 

commit 57864ae5ce3ab5c6e3137dd03edefdb2e5531ba1
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Oct 18 19:05:57 2017 -0700

    f2fs: limit # of inmemory pages
    
    If some abnormal users try lots of atomic write operations, f2fs is able to
    produce pinned pages in the main memory which affects system performance.
    This patch limits that as 20% over total memory size, and if f2fs reaches
    to the limit, it will drop all the inmemory pages.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index e91b08b4a51a..0ee3e5ff49a3 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -140,6 +140,7 @@ enum mem_type {
 	DIRTY_DENTS,	/* indicates dirty dentry pages */
 	INO_ENTRIES,	/* indicates inode entries */
 	EXTENT_CACHE,	/* indicates extent cache */
+	INMEM_PAGES,	/* indicates inmemory pages */
 	BASE_CHECK,	/* check kernel status */
 };
 

commit 9a4ffdf55811ff3382cdf44459ec17521bd47e5e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Sep 29 13:59:35 2017 +0800

    f2fs: obsolete ALLOC_NID_LIST list
    
    As Fan Li reported, there is no user traversing nid_list[ALLOC_NID_LIST]
    which is used for tracking preallocated nids. Let's drop it, and only
    track preallocated nids in free_nid_root radix-tree.
    
    Reported-by: Fan Li <fanofcode.li@samsung.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index bb53e9955ff2..e91b08b4a51a 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -150,18 +150,10 @@ struct nat_entry_set {
 	unsigned int entry_cnt;		/* the # of nat entries in set */
 };
 
-/*
- * For free nid mangement
- */
-enum nid_state {
-	NID_NEW,	/* newly added to free nid list */
-	NID_ALLOC	/* it is allocated */
-};
-
 struct free_nid {
 	struct list_head list;	/* for free node id list */
 	nid_t nid;		/* node id */
-	int state;		/* in use or not: NID_NEW or NID_ALLOC */
+	int state;		/* in use or not: FREE_NID or PREALLOC_NID */
 };
 
 static inline void next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
@@ -170,12 +162,11 @@ static inline void next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
 	struct free_nid *fnid;
 
 	spin_lock(&nm_i->nid_list_lock);
-	if (nm_i->nid_cnt[FREE_NID_LIST] <= 0) {
+	if (nm_i->nid_cnt[FREE_NID] <= 0) {
 		spin_unlock(&nm_i->nid_list_lock);
 		return;
 	}
-	fnid = list_first_entry(&nm_i->nid_list[FREE_NID_LIST],
-						struct free_nid, list);
+	fnid = list_first_entry(&nm_i->free_nid_list, struct free_nid, list);
 	*nid = fnid->nid;
 	spin_unlock(&nm_i->nid_list_lock);
 }

commit 72fdbe2efe3e42a54e268d2ee2a8c0828d3996e7
Author: Fan Li <fanofcode.li@samsung.com>
Date:   Fri Jun 2 15:45:42 2017 +0800

    f2fs: simplify the way of calulating next nat address
    
    The index of segment which the next nat block is in has only one different
    bit than the current one, so to get the next nat address, we can simply
    alter that one bit.
    
    Signed-off-by: Fan Li <fanofcode.li@samsung.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 558048e33cf9..bb53e9955ff2 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -224,11 +224,7 @@ static inline pgoff_t next_nat_addr(struct f2fs_sb_info *sbi,
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
 
 	block_addr -= nm_i->nat_blkaddr;
-	if ((block_addr >> sbi->log_blocks_per_seg) % 2)
-		block_addr -= sbi->blocks_per_seg;
-	else
-		block_addr += sbi->blocks_per_seg;
-
+	block_addr ^= 1 << sbi->log_blocks_per_seg;
 	return block_addr + nm_i->nat_blkaddr;
 }
 

commit 68afcf2d38cd7544817558757e57e7b9d5c4e72c
Author: Tomohiro Kusumi <tkusumi@tuxera.com>
Date:   Sun Apr 9 02:11:36 2017 +0300

    f2fs: guard macro variables with braces
    
    Add braces around variables used within macros for those make sense
    to do it. Many of the macros in f2fs already do this. What this commit
    doesn't do is anything that changes line# as a result of adding braces,
    which usually affects the binary via __LINE__.
    
    Confirmed no diff in fs/f2fs/f2fs.ko before/after this commit on x86_64,
    to make sure this has no functional change as well as there's been no
    unexpected side effect due to callers' arithmetics within the existing
    code.
    
    Signed-off-by: Tomohiro Kusumi <tkusumi@tuxera.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index ebed0240aa53..558048e33cf9 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -9,10 +9,10 @@
  * published by the Free Software Foundation.
  */
 /* start node id of a node block dedicated to the given node id */
-#define	START_NID(nid) ((nid / NAT_ENTRY_PER_BLOCK) * NAT_ENTRY_PER_BLOCK)
+#define	START_NID(nid) (((nid) / NAT_ENTRY_PER_BLOCK) * NAT_ENTRY_PER_BLOCK)
 
 /* node block offset on the NAT area dedicated to the given start node id */
-#define	NAT_BLOCK_OFFSET(start_nid) (start_nid / NAT_ENTRY_PER_BLOCK)
+#define	NAT_BLOCK_OFFSET(start_nid) ((start_nid) / NAT_ENTRY_PER_BLOCK)
 
 /* # of pages to perform synchronous readahead before building free nids */
 #define FREE_NID_PAGES	8
@@ -62,16 +62,16 @@ struct nat_entry {
 	struct node_info ni;	/* in-memory node information */
 };
 
-#define nat_get_nid(nat)		(nat->ni.nid)
-#define nat_set_nid(nat, n)		(nat->ni.nid = n)
-#define nat_get_blkaddr(nat)		(nat->ni.blk_addr)
-#define nat_set_blkaddr(nat, b)		(nat->ni.blk_addr = b)
-#define nat_get_ino(nat)		(nat->ni.ino)
-#define nat_set_ino(nat, i)		(nat->ni.ino = i)
-#define nat_get_version(nat)		(nat->ni.version)
-#define nat_set_version(nat, v)		(nat->ni.version = v)
+#define nat_get_nid(nat)		((nat)->ni.nid)
+#define nat_set_nid(nat, n)		((nat)->ni.nid = (n))
+#define nat_get_blkaddr(nat)		((nat)->ni.blk_addr)
+#define nat_set_blkaddr(nat, b)		((nat)->ni.blk_addr = (b))
+#define nat_get_ino(nat)		((nat)->ni.ino)
+#define nat_set_ino(nat, i)		((nat)->ni.ino = (i))
+#define nat_get_version(nat)		((nat)->ni.version)
+#define nat_set_version(nat, v)		((nat)->ni.version = (v))
 
-#define inc_node_version(version)	(++version)
+#define inc_node_version(version)	(++(version))
 
 static inline void copy_node_info(struct node_info *dst,
 						struct node_info *src)

commit 8a6aa32502549b1f15f0a28e3d2fcc5edabc3f19
Author: Fan Li <fanofcode.li@samsung.com>
Date:   Wed Mar 8 13:39:16 2017 +0800

    f2fs: adjust the way of calculating nat block
    
    use a slightly simpler expression to calculate nat block with nid.
    
    Signed-off-by: Fan Li <fanofcode.li@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 2f9603fa85a5..ebed0240aa53 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -200,13 +200,16 @@ static inline pgoff_t current_nat_addr(struct f2fs_sb_info *sbi, nid_t start)
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
 	pgoff_t block_off;
 	pgoff_t block_addr;
-	int seg_off;
 
+	/*
+	 * block_off = segment_off * 512 + off_in_segment
+	 * OLD = (segment_off * 512) * 2 + off_in_segment
+	 * NEW = 2 * (segment_off * 512 + off_in_segment) - off_in_segment
+	 */
 	block_off = NAT_BLOCK_OFFSET(start);
-	seg_off = block_off >> sbi->log_blocks_per_seg;
 
 	block_addr = (pgoff_t)(nm_i->nat_blkaddr +
-		(seg_off << sbi->log_blocks_per_seg << 1) +
+		(block_off << 1) -
 		(block_off & (sbi->blocks_per_seg - 1)));
 
 	if (f2fs_test_bit(block_off, nm_i->nat_bitmap))

commit ced2c7ea8e99b46755a270872cd5ba61c27cffad
Author: Kinglong Mee <kinglongmee@gmail.com>
Date:   Sat Feb 25 19:53:39 2017 +0800

    f2fs: new helper cur_cp_crc() getting crc in f2fs_checkpoint
    
    There are four places that getting the crc value in f2fs_checkpoint,
    just add a new helper cur_cp_crc for them.
    
    Signed-off-by: Kinglong Mee <kinglongmee@gmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 3fc9c4b1dce9..2f9603fa85a5 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -300,14 +300,11 @@ static inline void fill_node_footer_blkaddr(struct page *page, block_t blkaddr)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(F2FS_P_SB(page));
 	struct f2fs_node *rn = F2FS_NODE(page);
-	size_t crc_offset = le32_to_cpu(ckpt->checksum_offset);
-	__u64 cp_ver = le64_to_cpu(ckpt->checkpoint_ver);
+	__u64 cp_ver = cur_cp_version(ckpt);
+
+	if (__is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG))
+		cp_ver |= (cur_cp_crc(ckpt) << 32);
 
-	if (__is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG)) {
-		__u64 crc = le32_to_cpu(*((__le32 *)
-				((unsigned char *)ckpt + crc_offset)));
-		cp_ver |= (crc << 32);
-	}
 	rn->footer.cp_ver = cpu_to_le64(cp_ver);
 	rn->footer.next_blkaddr = cpu_to_le32(blkaddr);
 }
@@ -315,14 +312,11 @@ static inline void fill_node_footer_blkaddr(struct page *page, block_t blkaddr)
 static inline bool is_recoverable_dnode(struct page *page)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(F2FS_P_SB(page));
-	size_t crc_offset = le32_to_cpu(ckpt->checksum_offset);
 	__u64 cp_ver = cur_cp_version(ckpt);
 
-	if (__is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG)) {
-		__u64 crc = le32_to_cpu(*((__le32 *)
-				((unsigned char *)ckpt + crc_offset)));
-		cp_ver |= (crc << 32);
-	}
+	if (__is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG))
+		cp_ver |= (cur_cp_crc(ckpt) << 32);
+
 	return cp_ver == cpver_of_node(page);
 }
 

commit 6bfaf7b150f7dba04024b7b6420773c09606538c
Author: Hou Pengyang <houpengyang@huawei.com>
Date:   Thu Feb 23 09:18:06 2017 +0000

    f2fs: remove unsafe bitmap checking
    
    proc A:                      proc B:
    - writeback_sb_inodes
    - __writeback_single_inode
    - do_writepages
    - f2fs_write_node_pages
    - f2fs_balance_fs_bg         - write_checkpoint
    - build_free_nids            - flush_nat_entries
    - __build_free_nids          - __flush_nat_entry_set
    - ra_meta_pages              - get_next_nat_page
    - current_nat_addr           - set_to_next_nat
    [do nat_bitmap checking]     - f2fs_change_bit
    
    For proc A, nat_bitmap and nat_bitmap_mir would be compared without lock_op and
    nm_i->nat_tree_lock, while proc B is changing nat_bitmap/nat_bitmap_ver in cp.
    
    So it is normal for nat_bitmap/nat_bitmap diffrence under such scenario.
    
    This patch fix this by removing the monitoring point.
    
    [Fix: 599a09b f2fs: check in-memory nat version bitmap]
    Signed-off-by: Hou Pengyang <houpengyang@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index d3d289306469..3fc9c4b1dce9 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -209,12 +209,6 @@ static inline pgoff_t current_nat_addr(struct f2fs_sb_info *sbi, nid_t start)
 		(seg_off << sbi->log_blocks_per_seg << 1) +
 		(block_off & (sbi->blocks_per_seg - 1)));
 
-#ifdef CONFIG_F2FS_CHECK_FS
-	if (f2fs_test_bit(block_off, nm_i->nat_bitmap) !=
-			f2fs_test_bit(block_off, nm_i->nat_bitmap_mir))
-		f2fs_bug_on(sbi, 1);
-#endif
-
 	if (f2fs_test_bit(block_off, nm_i->nat_bitmap))
 		block_addr += sbi->blocks_per_seg;
 

commit d260081ccf37f57b74396ec48f415f27d1b01b13
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Feb 8 17:39:45 2017 +0800

    f2fs: change recovery policy of xattr node block
    
    Currently, if we call fsync after updating the xattr date belongs to the
    file, f2fs needs to trigger checkpoint to keep xattr data consistent. But,
    this policy cause low performance as checkpoint will block most foreground
    operations and cause unneeded and unrelated IOs around checkpoint.
    
    This patch will reuse regular file recovery policy for xattr node block,
    so, we change to write xattr node block tagged with fsync flag to warm
    area instead of cold area, and during recovery, we search warm node chain
    for fsynced xattr block, and do the recovery.
    
    So, for below application IO pattern, performance can be improved
    obviously:
    - touch file
    - create/update/delete xattr entry in file
    - fsync file
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 29ff783eb9c3..d3d289306469 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -358,7 +358,7 @@ static inline bool IS_DNODE(struct page *node_page)
 	unsigned int ofs = ofs_of_node(node_page);
 
 	if (f2fs_has_xattr_block(ofs))
-		return false;
+		return true;
 
 	if (ofs == 3 || ofs == 4 + NIDS_PER_BLOCK ||
 			ofs == 5 + 2 * NIDS_PER_BLOCK)

commit 599a09b2c1ac222e6aad0c22515d1ccde7c3b702
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sat Jan 7 18:52:01 2017 +0800

    f2fs: check in-memory nat version bitmap
    
    This patch adds a mirror for nat version bitmap, and use it to detect
    in-memory bitmap corruption which may be caused by bit-transition of
    cache or memory overflow.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 9278b21ee073..29ff783eb9c3 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -186,6 +186,12 @@ static inline void next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
 static inline void get_nat_bitmap(struct f2fs_sb_info *sbi, void *addr)
 {
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
+
+#ifdef CONFIG_F2FS_CHECK_FS
+	if (memcmp(nm_i->nat_bitmap, nm_i->nat_bitmap_mir,
+						nm_i->bitmap_size))
+		f2fs_bug_on(sbi, 1);
+#endif
 	memcpy(addr, nm_i->nat_bitmap, nm_i->bitmap_size);
 }
 
@@ -203,6 +209,12 @@ static inline pgoff_t current_nat_addr(struct f2fs_sb_info *sbi, nid_t start)
 		(seg_off << sbi->log_blocks_per_seg << 1) +
 		(block_off & (sbi->blocks_per_seg - 1)));
 
+#ifdef CONFIG_F2FS_CHECK_FS
+	if (f2fs_test_bit(block_off, nm_i->nat_bitmap) !=
+			f2fs_test_bit(block_off, nm_i->nat_bitmap_mir))
+		f2fs_bug_on(sbi, 1);
+#endif
+
 	if (f2fs_test_bit(block_off, nm_i->nat_bitmap))
 		block_addr += sbi->blocks_per_seg;
 
@@ -228,6 +240,9 @@ static inline void set_to_next_nat(struct f2fs_nm_info *nm_i, nid_t start_nid)
 	unsigned int block_off = NAT_BLOCK_OFFSET(start_nid);
 
 	f2fs_change_bit(block_off, nm_i->nat_bitmap);
+#ifdef CONFIG_F2FS_CHECK_FS
+	f2fs_change_bit(block_off, nm_i->nat_bitmap_mir);
+#endif
 }
 
 static inline nid_t ino_of_node(struct page *node_page)

commit 939afa943c5290a3b92f01612a792af17bc98115
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sat Jan 7 18:49:42 2017 +0800

    f2fs: clean up with list_{first, last}_entry
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index e7997e240366..9278b21ee073 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -174,7 +174,7 @@ static inline void next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
 		spin_unlock(&nm_i->nid_list_lock);
 		return;
 	}
-	fnid = list_entry(nm_i->nid_list[FREE_NID_LIST].next,
+	fnid = list_first_entry(&nm_i->nid_list[FREE_NID_LIST],
 						struct free_nid, list);
 	*nid = fnid->nid;
 	spin_unlock(&nm_i->nid_list_lock);

commit b8559dc242d1d47dcf99660a4d6afded727e0cc0
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Oct 12 19:28:29 2016 +0800

    f2fs: split free nid list
    
    During free nid allocation, in order to do preallocation, we will tag free
    nid entry as allocated one and still leave it in free nid list, for other
    allocators who want to grab free nids, it needs to traverse the free nid
    list for lookup. It becomes overhead in scenario of allocating free nid
    intensively by multithreads.
    
    This patch splits free nid list to two list: {free,alloc}_nid_list, to
    keep free nids and preallocated free nids separately, after that, traverse
    latency will be gone, besides split nid_cnt for separate statistic.
    
    Additionally, introduce __insert_nid_to_list and __remove_nid_from_list for
    cleanup.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: modify f2fs_bug_on to avoid needless branches]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index cfdcf98516a1..e7997e240366 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -169,14 +169,15 @@ static inline void next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
 	struct free_nid *fnid;
 
-	spin_lock(&nm_i->free_nid_list_lock);
-	if (nm_i->fcnt <= 0) {
-		spin_unlock(&nm_i->free_nid_list_lock);
+	spin_lock(&nm_i->nid_list_lock);
+	if (nm_i->nid_cnt[FREE_NID_LIST] <= 0) {
+		spin_unlock(&nm_i->nid_list_lock);
 		return;
 	}
-	fnid = list_entry(nm_i->free_nid_list.next, struct free_nid, list);
+	fnid = list_entry(nm_i->nid_list[FREE_NID_LIST].next,
+						struct free_nid, list);
 	*nid = fnid->nid;
-	spin_unlock(&nm_i->free_nid_list_lock);
+	spin_unlock(&nm_i->nid_list_lock);
 }
 
 /*

commit 0c0b471e43e7acf0747c6eb410863bf78c14750d
Author: Eric Biggers <ebiggers@google.com>
Date:   Tue Oct 11 10:36:12 2016 -0700

    f2fs: fix sparse warnings
    
    f2fs contained a number of endianness conversion bugs.
    
    Also, one function should have been 'static'.
    
    Found with sparse by running 'make C=2 CF=-D__CHECK_ENDIAN__ fs/f2fs/'
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 868bec65e51c..cfdcf98516a1 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -313,7 +313,7 @@ static inline bool is_recoverable_dnode(struct page *page)
 				((unsigned char *)ckpt + crc_offset)));
 		cp_ver |= (crc << 32);
 	}
-	return cpu_to_le64(cp_ver) == cpver_of_node(page);
+	return cp_ver == cpver_of_node(page);
 }
 
 /*

commit aaec2b1d18792a5f27b69ff37f34f43f89f5aa3b
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Sep 20 11:04:18 2016 +0800

    f2fs: introduce cp_lock to protect updating of ckpt_flags
    
    This patch introduces spinlock to protect updating process of ckpt_flags
    field in struct f2fs_checkpoint, it avoids incorrectly updating in race
    condition.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: add __is_set_ckpt_flags likewise __set_ckpt_flags]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index e8ca64a70de0..868bec65e51c 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -293,7 +293,7 @@ static inline void fill_node_footer_blkaddr(struct page *page, block_t blkaddr)
 	size_t crc_offset = le32_to_cpu(ckpt->checksum_offset);
 	__u64 cp_ver = le64_to_cpu(ckpt->checkpoint_ver);
 
-	if (is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG)) {
+	if (__is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG)) {
 		__u64 crc = le32_to_cpu(*((__le32 *)
 				((unsigned char *)ckpt + crc_offset)));
 		cp_ver |= (crc << 32);
@@ -308,7 +308,7 @@ static inline bool is_recoverable_dnode(struct page *page)
 	size_t crc_offset = le32_to_cpu(ckpt->checksum_offset);
 	__u64 cp_ver = cur_cp_version(ckpt);
 
-	if (is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG)) {
+	if (__is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG)) {
 		__u64 crc = le32_to_cpu(*((__le32 *)
 				((unsigned char *)ckpt + crc_offset)));
 		cp_ver |= (crc << 32);

commit a468f0ef516fda9c7d91bb550d458e853d76955e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 19 17:55:10 2016 -0700

    f2fs: use crc and cp version to determine roll-forward recovery
    
    Previously, we used cp_version only to detect recoverable dnodes.
    In order to avoid same garbage cp_version, we needed to truncate the next
    dnode during checkpoint, resulting in additional discard or data write.
    If we can distinguish this by using crc in addition to cp_version, we can
    remove this overhead.
    
    There is backward compatibility concern where it changes node_footer layout.
    So, this patch introduces a new checkpoint flag, CP_CRC_RECOVERY_FLAG, to
    detect new layout. New layout will be activated only when this flag is set.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index fc7684554b1a..e8ca64a70de0 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -229,6 +229,37 @@ static inline void set_to_next_nat(struct f2fs_nm_info *nm_i, nid_t start_nid)
 	f2fs_change_bit(block_off, nm_i->nat_bitmap);
 }
 
+static inline nid_t ino_of_node(struct page *node_page)
+{
+	struct f2fs_node *rn = F2FS_NODE(node_page);
+	return le32_to_cpu(rn->footer.ino);
+}
+
+static inline nid_t nid_of_node(struct page *node_page)
+{
+	struct f2fs_node *rn = F2FS_NODE(node_page);
+	return le32_to_cpu(rn->footer.nid);
+}
+
+static inline unsigned int ofs_of_node(struct page *node_page)
+{
+	struct f2fs_node *rn = F2FS_NODE(node_page);
+	unsigned flag = le32_to_cpu(rn->footer.flag);
+	return flag >> OFFSET_BIT_SHIFT;
+}
+
+static inline __u64 cpver_of_node(struct page *node_page)
+{
+	struct f2fs_node *rn = F2FS_NODE(node_page);
+	return le64_to_cpu(rn->footer.cp_ver);
+}
+
+static inline block_t next_blkaddr_of_node(struct page *node_page)
+{
+	struct f2fs_node *rn = F2FS_NODE(node_page);
+	return le32_to_cpu(rn->footer.next_blkaddr);
+}
+
 static inline void fill_node_footer(struct page *page, nid_t nid,
 				nid_t ino, unsigned int ofs, bool reset)
 {
@@ -259,40 +290,30 @@ static inline void fill_node_footer_blkaddr(struct page *page, block_t blkaddr)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(F2FS_P_SB(page));
 	struct f2fs_node *rn = F2FS_NODE(page);
+	size_t crc_offset = le32_to_cpu(ckpt->checksum_offset);
+	__u64 cp_ver = le64_to_cpu(ckpt->checkpoint_ver);
 
-	rn->footer.cp_ver = ckpt->checkpoint_ver;
+	if (is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG)) {
+		__u64 crc = le32_to_cpu(*((__le32 *)
+				((unsigned char *)ckpt + crc_offset)));
+		cp_ver |= (crc << 32);
+	}
+	rn->footer.cp_ver = cpu_to_le64(cp_ver);
 	rn->footer.next_blkaddr = cpu_to_le32(blkaddr);
 }
 
-static inline nid_t ino_of_node(struct page *node_page)
-{
-	struct f2fs_node *rn = F2FS_NODE(node_page);
-	return le32_to_cpu(rn->footer.ino);
-}
-
-static inline nid_t nid_of_node(struct page *node_page)
+static inline bool is_recoverable_dnode(struct page *page)
 {
-	struct f2fs_node *rn = F2FS_NODE(node_page);
-	return le32_to_cpu(rn->footer.nid);
-}
-
-static inline unsigned int ofs_of_node(struct page *node_page)
-{
-	struct f2fs_node *rn = F2FS_NODE(node_page);
-	unsigned flag = le32_to_cpu(rn->footer.flag);
-	return flag >> OFFSET_BIT_SHIFT;
-}
-
-static inline unsigned long long cpver_of_node(struct page *node_page)
-{
-	struct f2fs_node *rn = F2FS_NODE(node_page);
-	return le64_to_cpu(rn->footer.cp_ver);
-}
+	struct f2fs_checkpoint *ckpt = F2FS_CKPT(F2FS_P_SB(page));
+	size_t crc_offset = le32_to_cpu(ckpt->checksum_offset);
+	__u64 cp_ver = cur_cp_version(ckpt);
 
-static inline block_t next_blkaddr_of_node(struct page *node_page)
-{
-	struct f2fs_node *rn = F2FS_NODE(node_page);
-	return le32_to_cpu(rn->footer.next_blkaddr);
+	if (is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG)) {
+		__u64 crc = le32_to_cpu(*((__le32 *)
+				((unsigned char *)ckpt + crc_offset)));
+		cp_ver |= (crc << 32);
+	}
+	return cpu_to_le64(cp_ver) == cpver_of_node(page);
 }
 
 /*

commit ad4edb83143fdeef9e6fdd9daaa735b59476565b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jun 16 16:41:49 2016 -0700

    f2fs: produce more nids and reduce readahead nats
    
    The readahead nat pages are more likely to be reclaimed quickly, so it'd better
    to gather more free nids in advance.
    
    And, let's keep some free nids as much as possible.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 673ce926cf09..fc7684554b1a 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -15,9 +15,10 @@
 #define	NAT_BLOCK_OFFSET(start_nid) (start_nid / NAT_ENTRY_PER_BLOCK)
 
 /* # of pages to perform synchronous readahead before building free nids */
-#define FREE_NID_PAGES 4
+#define FREE_NID_PAGES	8
+#define MAX_FREE_NIDS	(NAT_ENTRY_PER_BLOCK * FREE_NID_PAGES)
 
-#define DEF_RA_NID_PAGES	4	/* # of nid pages to be readaheaded */
+#define DEF_RA_NID_PAGES	0	/* # of nid pages to be readaheaded */
 
 /* maximum readahead size for node during getting data blocks */
 #define MAX_RA_NODE		128

commit e589c2c477b44e06754508a4e8b883e5ae7294aa
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jun 2 15:24:24 2016 -0700

    f2fs: control not to exceed # of cached nat entries
    
    This is to avoid cache entry management overhead including radix tree.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 2c2a797e18a8..673ce926cf09 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -27,6 +27,8 @@
 
 /* control dirty nats ratio threshold (default: 10% over max nid count) */
 #define DEF_DIRTY_NAT_RATIO_THRESHOLD		10
+/* control total # of nats */
+#define DEF_NAT_CACHE_THRESHOLD			100000
 
 /* vector size for gang look-up from nat cache that consists of radix tree */
 #define NATVEC_SIZE	64
@@ -126,6 +128,11 @@ static inline bool excess_dirty_nats(struct f2fs_sb_info *sbi)
 					NM_I(sbi)->dirty_nats_ratio / 100;
 }
 
+static inline bool excess_cached_nats(struct f2fs_sb_info *sbi)
+{
+	return NM_I(sbi)->nat_cnt >= DEF_NAT_CACHE_THRESHOLD;
+}
+
 enum mem_type {
 	FREE_NIDS,	/* indicates the free nid list */
 	NAT_ENTRIES,	/* indicates the cached nat entry */

commit 29710bcf9426c84bb6a9b1d94316895ed6143813
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jun 2 15:26:27 2016 -0700

    f2fs: fix wrong percentage
    
    This should be 1%, 10MB / 1GB.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 1f4f9d4569d9..2c2a797e18a8 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -23,7 +23,7 @@
 #define MAX_RA_NODE		128
 
 /* control the memory footprint threshold (10MB per 1GB ram) */
-#define DEF_RAM_THRESHOLD	10
+#define DEF_RAM_THRESHOLD	1
 
 /* control dirty nats ratio threshold (default: 10% over max nid count) */
 #define DEF_DIRTY_NAT_RATIO_THRESHOLD		10

commit fec1d6576cdf2ce13f84fcdf7b20d02a05f76fc6
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Jan 20 23:43:51 2016 +0800

    f2fs: use wait_for_stable_page to avoid contention
    
    In write_begin, if storage supports stable_page, we don't need to wait for
    writeback to update its contents.
    This patch introduces to use wait_for_stable_page instead of
    wait_on_page_writeback.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 8f405d243e49..1f4f9d4569d9 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -330,7 +330,7 @@ static inline int set_nid(struct page *p, int off, nid_t nid, bool i)
 {
 	struct f2fs_node *rn = F2FS_NODE(p);
 
-	f2fs_wait_on_page_writeback(p, NODE);
+	f2fs_wait_on_page_writeback(p, NODE, true);
 
 	if (i)
 		rn->i.i_nid[off - NODE_DIR1_BLOCK] = cpu_to_le32(nid);

commit 2049d4fcb057c263929bec480f2db079d25fd601
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Jan 25 05:57:05 2016 -0800

    f2fs: avoid multiple node page writes due to inline_data
    
    The sceanrio is:
    1. create fully node blocks
    2. flush node blocks
    3. write inline_data for all the node blocks again
    4. flush node blocks redundantly
    
    So, this patch tries to flush inline_data when flushing node blocks.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 56c451921522..8f405d243e49 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -379,6 +379,21 @@ static inline int is_node(struct page *page, int type)
 #define is_fsync_dnode(page)	is_node(page, FSYNC_BIT_SHIFT)
 #define is_dent_dnode(page)	is_node(page, DENT_BIT_SHIFT)
 
+static inline int is_inline_node(struct page *page)
+{
+	return PageChecked(page);
+}
+
+static inline void set_inline_node(struct page *page)
+{
+	SetPageChecked(page);
+}
+
+static inline void clear_inline_node(struct page *page)
+{
+	ClearPageChecked(page);
+}
+
 static inline void set_cold_node(struct inode *inode, struct page *page)
 {
 	struct f2fs_node *rn = F2FS_NODE(page);

commit 2304cb0c4438829c88bed69f57374b80ae31f0ba
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Jan 18 18:32:58 2016 +0800

    f2fs: export dirty_nats_ratio in sysfs
    
    This patch exports a new sysfs entry 'dirty_nat_ratio' to control threshold
    of dirty nat entries, if current ratio exceeds configured threshold,
    checkpoint will be triggered in f2fs_balance_fs_bg for flushing dirty nats.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index bd119c0edf93..56c451921522 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -123,7 +123,7 @@ static inline void raw_nat_from_node_info(struct f2fs_nat_entry *raw_ne,
 static inline bool excess_dirty_nats(struct f2fs_sb_info *sbi)
 {
 	return NM_I(sbi)->dirty_nat_cnt >= NM_I(sbi)->max_nid *
-					DEF_DIRTY_NAT_RATIO_THRESHOLD / 100;
+					NM_I(sbi)->dirty_nats_ratio / 100;
 }
 
 enum mem_type {

commit 7d768d2c264eec44941a13cb92200565e8c754d0
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Jan 18 18:31:18 2016 +0800

    f2fs: flush dirty nat entries when exceeding threshold
    
    When testing f2fs with xfstest, generic/251 is stuck for long time,
    the case uses below serials to obtain fresh released space in device,
    in order to prepare for following fstrim test.
    
    1. rm -rf /mnt/dir
    2. mkdir /mnt/dir/
    3. cp -axT `pwd`/ /mnt/dir/
    4. goto 1
    
    During preparing step, all nat entries will be cached in nat cache,
    most of them are dirty entries with invalid blkaddr, which means
    nodes related to these entries have been truncated, and they could
    be reused after the dirty entries been checkpointed.
    
    However, there was no checkpoint been triggered, so nid allocators
    (e.g. mkdir, creat) will run into long journey of iterating all NAT
    pages, looking for free nids in alloc_nid->build_free_nids.
    
    Here, in f2fs_balance_fs_bg we give another chance to do checkpoint
    to flush nat entries for reusing them in free nid cache when dirty
    entry count exceeds 10% of max count.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index d4d1f636fe1c..bd119c0edf93 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -25,6 +25,9 @@
 /* control the memory footprint threshold (10MB per 1GB ram) */
 #define DEF_RAM_THRESHOLD	10
 
+/* control dirty nats ratio threshold (default: 10% over max nid count) */
+#define DEF_DIRTY_NAT_RATIO_THRESHOLD		10
+
 /* vector size for gang look-up from nat cache that consists of radix tree */
 #define NATVEC_SIZE	64
 #define SETVEC_SIZE	32
@@ -117,6 +120,12 @@ static inline void raw_nat_from_node_info(struct f2fs_nat_entry *raw_ne,
 	raw_ne->version = ni->version;
 }
 
+static inline bool excess_dirty_nats(struct f2fs_sb_info *sbi)
+{
+	return NM_I(sbi)->dirty_nat_cnt >= NM_I(sbi)->max_nid *
+					DEF_DIRTY_NAT_RATIO_THRESHOLD / 100;
+}
+
 enum mem_type {
 	FREE_NIDS,	/* indicates the free nid list */
 	NAT_ENTRIES,	/* indicates the cached nat entry */

commit 12719ae14e57980ebf0a7baa63bc80494c76b192
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jan 7 13:23:12 2016 -0800

    f2fs: avoid unnecessary f2fs_balance_fs calls
    
    Only when node page is newly dirtied, it needs to check whether we need to do
    f2fs_gc.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 2de759a7746f..d4d1f636fe1c 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -317,7 +317,7 @@ static inline bool IS_DNODE(struct page *node_page)
 	return true;
 }
 
-static inline void set_nid(struct page *p, int off, nid_t nid, bool i)
+static inline int set_nid(struct page *p, int off, nid_t nid, bool i)
 {
 	struct f2fs_node *rn = F2FS_NODE(p);
 
@@ -327,7 +327,7 @@ static inline void set_nid(struct page *p, int off, nid_t nid, bool i)
 		rn->i.i_nid[off - NODE_DIR1_BLOCK] = cpu_to_le32(nid);
 	else
 		rn->in.nid[off] = cpu_to_le32(nid);
-	set_page_dirty(p);
+	return set_page_dirty(p);
 }
 
 static inline nid_t get_nid(struct page *p, int off, bool i)

commit 3519e3f992995d46c200134cfbf84c61b7a01f4c
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Dec 1 11:56:52 2015 +0800

    f2fs: use sbi->blocks_per_seg to avoid unnecessary calculation
    
    Use sbi->blocks_per_seg directly to avoid unnecessary calculation when using
    1 << sbi->log_blocks_per_seg.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index e4fffd2d98c4..2de759a7746f 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -183,7 +183,7 @@ static inline pgoff_t current_nat_addr(struct f2fs_sb_info *sbi, nid_t start)
 
 	block_addr = (pgoff_t)(nm_i->nat_blkaddr +
 		(seg_off << sbi->log_blocks_per_seg << 1) +
-		(block_off & ((1 << sbi->log_blocks_per_seg) - 1)));
+		(block_off & (sbi->blocks_per_seg - 1)));
 
 	if (f2fs_test_bit(block_off, nm_i->nat_bitmap))
 		block_addr += sbi->blocks_per_seg;

commit ea1a29a0bdfffd56ca98335c0655308e8d7d0e22
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Oct 12 17:08:48 2015 +0800

    f2fs: export ra_nid_pages to sysfs
    
    After finishing building free nid cache, we will try to readahead
    asynchronously 4 more pages for the next reloading, the count of
    readahead nid pages is fixed.
    
    In some case, like SMR drive, read less sectors with fixed count
    each time we trigger RA may be low efficient, since we will face
    high seeking overhead, so we'd better let user to configure this
    parameter from sysfs in specific workload.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 7427e956ad81..e4fffd2d98c4 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -14,9 +14,11 @@
 /* node block offset on the NAT area dedicated to the given start node id */
 #define	NAT_BLOCK_OFFSET(start_nid) (start_nid / NAT_ENTRY_PER_BLOCK)
 
-/* # of pages to perform readahead before building free nids */
+/* # of pages to perform synchronous readahead before building free nids */
 #define FREE_NID_PAGES 4
 
+#define DEF_RA_NID_PAGES	4	/* # of nid pages to be readaheaded */
+
 /* maximum readahead size for node during getting data blocks */
 #define MAX_RA_NODE		128
 

commit a125702326d9c3b753fe9c9b9727d3b3dd1cba4a
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Oct 8 10:40:07 2015 -0700

    Revert "f2fs: do not skip dentry block writes"
    
    The periodic checkpoint can resolve the previous issue.
    So, now we can use this again to improve the reported performance regression:
    
    https://lkml.org/lkml/2015/10/8/20
    
    This reverts commit 15bec0ff5a9ba6d203178fa8772259df6207942a.

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 51c62edf2e89..7427e956ad81 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -118,6 +118,7 @@ static inline void raw_nat_from_node_info(struct f2fs_nat_entry *raw_ne,
 enum mem_type {
 	FREE_NIDS,	/* indicates the free nid list */
 	NAT_ENTRIES,	/* indicates the cached nat entry */
+	DIRTY_DENTS,	/* indicates dirty dentry pages */
 	INO_ENTRIES,	/* indicates inode entries */
 	EXTENT_CACHE,	/* indicates extent cache */
 	BASE_CHECK,	/* check kernel status */

commit 90b803e6fb6243922bff9ddd8a6205c17cb93b31
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Sep 25 19:34:50 2015 -0700

    f2fs: do not skip dentry block writes
    
    Previously, we skip dentry block writes when wbc is SYNC_NONE with no memory
    pressure and the number of dirty pages is pretty small.
    
    But, we didn't skip for normal data writes, which gives us not much big impact
    on overall performance.
    Moreover, by skipping some data writes, kworker falls into infinite loop to try
    to write blocks, when many dir inodes have only one dentry block.
    
    So, this patch removes skipping data writes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 7427e956ad81..51c62edf2e89 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -118,7 +118,6 @@ static inline void raw_nat_from_node_info(struct f2fs_nat_entry *raw_ne,
 enum mem_type {
 	FREE_NIDS,	/* indicates the free nid list */
 	NAT_ENTRIES,	/* indicates the cached nat entry */
-	DIRTY_DENTS,	/* indicates dirty dentry pages */
 	INO_ENTRIES,	/* indicates inode entries */
 	EXTENT_CACHE,	/* indicates extent cache */
 	BASE_CHECK,	/* check kernel status */

commit b5492af78c89b52a8e7273445b2248b397a15333
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Apr 20 13:44:41 2015 -0700

    f2fs: move existing definitions into f2fs.h
    
    This patch moves some inode-related definitions from node.h to f2fs.h to
    add new features.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index c56026f1725c..7427e956ad81 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -343,28 +343,6 @@ static inline nid_t get_nid(struct page *p, int off, bool i)
  *  - Mark cold node blocks in their node footer
  *  - Mark cold data pages in page cache
  */
-static inline int is_file(struct inode *inode, int type)
-{
-	return F2FS_I(inode)->i_advise & type;
-}
-
-static inline void set_file(struct inode *inode, int type)
-{
-	F2FS_I(inode)->i_advise |= type;
-}
-
-static inline void clear_file(struct inode *inode, int type)
-{
-	F2FS_I(inode)->i_advise &= ~type;
-}
-
-#define file_is_cold(inode)	is_file(inode, FADVISE_COLD_BIT)
-#define file_wrong_pino(inode)	is_file(inode, FADVISE_LOST_PINO_BIT)
-#define file_set_cold(inode)	set_file(inode, FADVISE_COLD_BIT)
-#define file_lost_pino(inode)	set_file(inode, FADVISE_LOST_PINO_BIT)
-#define file_clear_cold(inode)	clear_file(inode, FADVISE_COLD_BIT)
-#define file_got_pino(inode)	clear_file(inode, FADVISE_LOST_PINO_BIT)
-
 static inline int is_cold_data(struct page *page)
 {
 	return PageChecked(page);

commit 13054c548a1c9e78f8f8ba5f134909cb56152285
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Feb 5 17:52:58 2015 +0800

    f2fs: introduce infra macro and data structure of rb-tree extent cache
    
    Introduce infra macro and data structure for rb-tree based extent cache:
    
    Macros:
     * EXT_TREE_VEC_SIZE: indicate vector size for gang lookup in extent tree.
     * F2FS_MIN_EXTENT_LEN: indicate minimum length of extent managed in cache.
     * EXTENT_CACHE_SHRINK_NUMBER: indicate number of extent in cache will be shrunk.
    
    Basic data structures for extent cache:
     * struct extent_tree: extent tree entry per inode.
     * struct extent_node: extent info node linked in extent tree.
    
    Besides, adding new extent cache related fields in f2fs_sb_info.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Changman Lee <cm224.lee@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index f405bbf2435a..c56026f1725c 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -120,6 +120,7 @@ enum mem_type {
 	NAT_ENTRIES,	/* indicates the cached nat entry */
 	DIRTY_DENTS,	/* indicates dirty dentry pages */
 	INO_ENTRIES,	/* indicates inode entries */
+	EXTENT_CACHE,	/* indicates extent cache */
 	BASE_CHECK,	/* check kernel status */
 };
 

commit 7aed0d45376e531330cf20af581a76edc0347d06
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Jan 7 10:47:57 2015 -0800

    f2fs: free radix_tree_nodes used by nat_set entries
    
    In the normal case, the radix_tree_nodes are freed successfully.
    But, when cp_error was detected, we should destroy them forcefully.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index cac8a3d9acbd..f405bbf2435a 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -25,6 +25,7 @@
 
 /* vector size for gang look-up from nat cache that consists of radix tree */
 #define NATVEC_SIZE	64
+#define SETVEC_SIZE	32
 
 /* return value for read_node_page */
 #define LOCKED_PAGE	1

commit 09eb483e895f36fd002e88c878e9578c359aa468
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Dec 23 16:26:31 2014 -0800

    f2fs: fix missing cold bit during recovery
    
    In do_recover_data, we find and update previous node pages after updating
    its new block addresses.
    After then, we call fill_node_footer without reset field, we erase its
    cold bit so that this new cold node block is written to wrong log area.
    This patch fixes not to miss its old flag.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index fa6f95968b42..cac8a3d9acbd 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -212,11 +212,19 @@ static inline void fill_node_footer(struct page *page, nid_t nid,
 				nid_t ino, unsigned int ofs, bool reset)
 {
 	struct f2fs_node *rn = F2FS_NODE(page);
+	unsigned int old_flag = 0;
+
 	if (reset)
 		memset(rn, 0, sizeof(*rn));
+	else
+		old_flag = le32_to_cpu(rn->footer.flag);
+
 	rn->footer.nid = cpu_to_le32(nid);
 	rn->footer.ino = cpu_to_le32(ino);
-	rn->footer.flag = cpu_to_le32(ofs << OFFSET_BIT_SHIFT);
+
+	/* should remain old flag bits such as COLD_BIT_SHIFT */
+	rn->footer.flag = cpu_to_le32((ofs << OFFSET_BIT_SHIFT) |
+					(old_flag & OFFSET_BIT_MASK));
 }
 
 static inline void copy_node_footer(struct page *dst, struct page *src)

commit 5c27f4ee447b4ef1cd88d5313eeb838c56265571
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Dec 18 17:37:21 2014 +0800

    f2fs: merge two uchar variable in struct node_info to reduce memory cost
    
    This patch moves one member of struct nat_entry: _flag_ to struct node_info,
    so _version_ in struct node_info and _flag_ which are unsigned char type will
    merge to one 32-bit space in register/memory. So the size of nat_entry will be
    reduced from 28 bytes to 24 bytes (for 64-bit machine, reduce its size from 40
    bytes to 32 bytes) and then slab memory using by f2fs will be reduced.
    
    changes from v2:
     o update description of memory usage gain for 64-bit machine suggested by
       Changman Lee.
    changes from v1:
     o introduce inline copy_node_info() to copy valid data from node info suggested
       by Jaegeuk Kim, it can avoid bug.
    
    Reviewed-by: Changman Lee <cm224.lee@samsung.com>
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 036b887176ff..fa6f95968b42 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -29,6 +29,14 @@
 /* return value for read_node_page */
 #define LOCKED_PAGE	1
 
+/* For flag in struct node_info */
+enum {
+	IS_CHECKPOINTED,	/* is it checkpointed before? */
+	HAS_FSYNCED_INODE,	/* is the inode fsynced before? */
+	HAS_LAST_FSYNC,		/* has the latest node fsync mark? */
+	IS_DIRTY,		/* this nat entry is dirty? */
+};
+
 /*
  * For node information
  */
@@ -37,18 +45,11 @@ struct node_info {
 	nid_t ino;		/* inode number of the node's owner */
 	block_t	blk_addr;	/* block address of the node */
 	unsigned char version;	/* version of the node */
-};
-
-enum {
-	IS_CHECKPOINTED,	/* is it checkpointed before? */
-	HAS_FSYNCED_INODE,	/* is the inode fsynced before? */
-	HAS_LAST_FSYNC,		/* has the latest node fsync mark? */
-	IS_DIRTY,		/* this nat entry is dirty? */
+	unsigned char flag;	/* for node information bits */
 };
 
 struct nat_entry {
 	struct list_head list;	/* for clean or dirty nat list */
-	unsigned char flag;	/* for node information bits */
 	struct node_info ni;	/* in-memory node information */
 };
 
@@ -63,20 +64,30 @@ struct nat_entry {
 
 #define inc_node_version(version)	(++version)
 
+static inline void copy_node_info(struct node_info *dst,
+						struct node_info *src)
+{
+	dst->nid = src->nid;
+	dst->ino = src->ino;
+	dst->blk_addr = src->blk_addr;
+	dst->version = src->version;
+	/* should not copy flag here */
+}
+
 static inline void set_nat_flag(struct nat_entry *ne,
 				unsigned int type, bool set)
 {
 	unsigned char mask = 0x01 << type;
 	if (set)
-		ne->flag |= mask;
+		ne->ni.flag |= mask;
 	else
-		ne->flag &= ~mask;
+		ne->ni.flag &= ~mask;
 }
 
 static inline bool get_nat_flag(struct nat_entry *ne, unsigned int type)
 {
 	unsigned char mask = 0x01 << type;
-	return ne->flag & mask;
+	return ne->ni.flag & mask;
 }
 
 static inline void nat_reset_flag(struct nat_entry *ne)

commit 1e84371ffeef451e8532e0cd04c2fe59ff10c514
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Dec 9 06:08:59 2014 -0800

    f2fs: change atomic and volatile write policies
    
    This patch adds two new ioctls to release inmemory pages grabbed by atomic
    writes.
     o f2fs_ioc_abort_volatile_write
      - If transaction was failed, all the grabbed pages and data should be written.
     o f2fs_ioc_release_volatile_write
      - This is to enhance the performance of PERSIST mode in sqlite.
    
    In order to avoid huge memory consumption which causes OOM, this patch changes
    volatile writes to use normal dirty pages, instead blocked flushing to the disk
    as long as system does not suffer from memory pressure.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index d10b6448a671..036b887176ff 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -108,6 +108,7 @@ enum mem_type {
 	NAT_ENTRIES,	/* indicates the cached nat entry */
 	DIRTY_DENTS,	/* indicates dirty dentry pages */
 	INO_ENTRIES,	/* indicates inode entries */
+	BASE_CHECK,	/* check kernel status */
 };
 
 struct nat_entry_set {

commit e5e7ea3c86e56b725e4076e8dc583378abad7697
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Nov 6 15:24:46 2014 -0800

    f2fs: control the memory footprint used by ino entries
    
    This patch adds to control the memory footprint used by ino entries.
    This will conduct best effort, not strictly.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index acb71e507a7a..d10b6448a671 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -106,7 +106,8 @@ static inline void raw_nat_from_node_info(struct f2fs_nat_entry *raw_ne,
 enum mem_type {
 	FREE_NIDS,	/* indicates the free nid list */
 	NAT_ENTRIES,	/* indicates the cached nat entry */
-	DIRTY_DENTS	/* indicates dirty dentry pages */
+	DIRTY_DENTS,	/* indicates dirty dentry pages */
+	INO_ENTRIES,	/* indicates inode entries */
 };
 
 struct nat_entry_set {

commit c6ac4c0ec416e77cab09cac6cee2d100fbd7fc82
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Mon Oct 20 17:45:50 2014 +0800

    f2fs: introduce f2fs_change_bit to simplify the change bit logic
    
    Introduce f2fs_change_bit to simplify the change bit logic in
    function set_to_next_nat{sit}.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 8d5e6e0dd840..acb71e507a7a 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -192,10 +192,7 @@ static inline void set_to_next_nat(struct f2fs_nm_info *nm_i, nid_t start_nid)
 {
 	unsigned int block_off = NAT_BLOCK_OFFSET(start_nid);
 
-	if (f2fs_test_bit(block_off, nm_i->nat_bitmap))
-		f2fs_clear_bit(block_off, nm_i->nat_bitmap);
-	else
-		f2fs_set_bit(block_off, nm_i->nat_bitmap);
+	f2fs_change_bit(block_off, nm_i->nat_bitmap);
 }
 
 static inline void fill_node_footer(struct page *page, nid_t nid,

commit 120c2cba1d76494a68e36a11eb630cb335ed1494
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Oct 3 15:12:42 2014 -0700

    f2fs: remove unused return value
    
    Don't return any value without any usage.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index bd826d953c7c..8d5e6e0dd840 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -130,7 +130,7 @@ struct free_nid {
 	int state;		/* in use or not: NID_NEW or NID_ALLOC */
 };
 
-static inline int next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
+static inline void next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
 {
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
 	struct free_nid *fnid;
@@ -138,12 +138,11 @@ static inline int next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
 	spin_lock(&nm_i->free_nid_list_lock);
 	if (nm_i->fcnt <= 0) {
 		spin_unlock(&nm_i->free_nid_list_lock);
-		return -1;
+		return;
 	}
 	fnid = list_entry(nm_i->free_nid_list.next, struct free_nid, list);
 	*nid = fnid->nid;
 	spin_unlock(&nm_i->free_nid_list_lock);
-	return 0;
 }
 
 /*

commit 309cc2b6e7ae6672ff9744fe07735ed234a8994e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 22 11:40:48 2014 -0700

    f2fs: refactor flush_nat_entries to remove costly reorganizing ops
    
    Previously, f2fs tries to reorganize the dirty nat entries into multiple sets
    according to its nid ranges. This can improve the flushing nat pages, however,
    if there are a lot of cached nat entries, it becomes a bottleneck.
    
    This patch introduces a new set management flow by removing dirty nat list and
    adding a series of set operations when the nat entry becomes dirty.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index b8ba63c43b99..bd826d953c7c 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -43,6 +43,7 @@ enum {
 	IS_CHECKPOINTED,	/* is it checkpointed before? */
 	HAS_FSYNCED_INODE,	/* is the inode fsynced before? */
 	HAS_LAST_FSYNC,		/* has the latest node fsync mark? */
+	IS_DIRTY,		/* this nat entry is dirty? */
 };
 
 struct nat_entry {
@@ -60,10 +61,6 @@ struct nat_entry {
 #define nat_get_version(nat)		(nat->ni.version)
 #define nat_set_version(nat, v)		(nat->ni.version = v)
 
-#define __set_nat_cache_dirty(nm_i, ne)					\
-		list_move_tail(&ne->list, &nm_i->dirty_nat_entries);
-#define __clear_nat_cache_dirty(nm_i, ne)				\
-		list_move_tail(&ne->list, &nm_i->nat_entries);
 #define inc_node_version(version)	(++version)
 
 static inline void set_nat_flag(struct nat_entry *ne,
@@ -113,9 +110,9 @@ enum mem_type {
 };
 
 struct nat_entry_set {
-	struct list_head set_list;	/* link with all nat sets */
+	struct list_head set_list;	/* link with other nat sets */
 	struct list_head entry_list;	/* link with dirty nat entries */
-	nid_t start_nid;		/* start nid of nats in set */
+	nid_t set;			/* set number*/
 	unsigned int entry_cnt;		/* the # of nat entries in set */
 };
 

commit 88bd02c9472a166b706284a34a84f1243322d782
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 15 14:50:48 2014 -0700

    f2fs: fix conditions to remain recovery information in f2fs_sync_file
    
    This patch revisited whole the recovery information during the f2fs_sync_file.
    
    In this patch, there are three information to make a decision.
    
    a) IS_CHECKPOINTED,     /* is it checkpointed before? */
    b) HAS_FSYNCED_INODE,   /* is the inode fsynced before? */
    c) HAS_LAST_FSYNC,      /* has the latest node fsync mark? */
    
    And, the scenarios for our rule are based on:
    
    [Term] F: fsync_mark, D: dentry_mark
    
    1. inode(x) | CP | inode(x) | dnode(F)
    2. inode(x) | CP | inode(F) | dnode(F)
    3. inode(x) | CP | dnode(F) | inode(x) | inode(F)
    4. inode(x) | CP | dnode(F) | inode(F)
    5. CP | inode(x) | dnode(F) | inode(DF)
    6. CP | inode(DF) | dnode(F)
    7. CP | dnode(F) | inode(DF)
    8. CP | dnode(F) | inode(x) | inode(DF)
    
    For example, #3, the three conditions should be changed as follows.
    
       inode(x) | CP | dnode(F) | inode(x) | inode(F)
    a)    x       o      o          o          o
    b)    x       x      x          x          o
    c)    x       o      o          x          o
    
    If f2fs_sync_file stops   ------^,
     it should write inode(F)    --------------^
    
    So, the need_inode_block_update should return true, since
     c) get_nat_flag(e, HAS_LAST_FSYNC), is false.
    
    For example, #8,
          CP | alloc | dnode(F) | inode(x) | inode(DF)
    a)    o      x        x          x          x
    b)    x               x          x          o
    c)    o               o          x          o
    
    If f2fs_sync_file stops   -------^,
     it should write inode(DF)    --------------^
    
    Note that, the roll-forward policy should follow this rule, which means,
    if there are any missing blocks, we doesn't need to recover that inode.
    
    Signed-off-by: Huang Ying <ying.huang@intel.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 3043778d805b..b8ba63c43b99 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -41,7 +41,8 @@ struct node_info {
 
 enum {
 	IS_CHECKPOINTED,	/* is it checkpointed before? */
-	HAS_FSYNC_MARK,		/* has the latest node fsync mark? */
+	HAS_FSYNCED_INODE,	/* is the inode fsynced before? */
+	HAS_LAST_FSYNC,		/* has the latest node fsync mark? */
 };
 
 struct nat_entry {
@@ -60,15 +61,9 @@ struct nat_entry {
 #define nat_set_version(nat, v)		(nat->ni.version = v)
 
 #define __set_nat_cache_dirty(nm_i, ne)					\
-	do {								\
-		set_nat_flag(ne, IS_CHECKPOINTED, false);		\
-		list_move_tail(&ne->list, &nm_i->dirty_nat_entries);	\
-	} while (0)
+		list_move_tail(&ne->list, &nm_i->dirty_nat_entries);
 #define __clear_nat_cache_dirty(nm_i, ne)				\
-	do {								\
-		set_nat_flag(ne, IS_CHECKPOINTED, true);		\
-		list_move_tail(&ne->list, &nm_i->nat_entries);		\
-	} while (0)
+		list_move_tail(&ne->list, &nm_i->nat_entries);
 #define inc_node_version(version)	(++version)
 
 static inline void set_nat_flag(struct nat_entry *ne,
@@ -87,6 +82,14 @@ static inline bool get_nat_flag(struct nat_entry *ne, unsigned int type)
 	return ne->flag & mask;
 }
 
+static inline void nat_reset_flag(struct nat_entry *ne)
+{
+	/* these states can be set only after checkpoint was done */
+	set_nat_flag(ne, IS_CHECKPOINTED, true);
+	set_nat_flag(ne, HAS_FSYNCED_INODE, false);
+	set_nat_flag(ne, HAS_LAST_FSYNC, true);
+}
+
 static inline void node_info_from_raw_nat(struct node_info *ni,
 						struct f2fs_nat_entry *raw_ne)
 {

commit 7ef35e3b9e7a99db4930b58b33a94455dbf53276
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 15 12:07:13 2014 -0700

    f2fs: introduce a flag to represent each nat entry information
    
    This patch introduces a flag in the nat entry structure to merge various
    information such as checkpointed and fsync_done marks.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 324917d757f7..3043778d805b 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -39,10 +39,14 @@ struct node_info {
 	unsigned char version;	/* version of the node */
 };
 
+enum {
+	IS_CHECKPOINTED,	/* is it checkpointed before? */
+	HAS_FSYNC_MARK,		/* has the latest node fsync mark? */
+};
+
 struct nat_entry {
 	struct list_head list;	/* for clean or dirty nat list */
-	bool checkpointed;	/* whether it is checkpointed or not */
-	bool fsync_done;	/* whether the latest node has fsync mark */
+	unsigned char flag;	/* for node information bits */
 	struct node_info ni;	/* in-memory node information */
 };
 
@@ -57,16 +61,32 @@ struct nat_entry {
 
 #define __set_nat_cache_dirty(nm_i, ne)					\
 	do {								\
-		ne->checkpointed = false;				\
+		set_nat_flag(ne, IS_CHECKPOINTED, false);		\
 		list_move_tail(&ne->list, &nm_i->dirty_nat_entries);	\
 	} while (0)
 #define __clear_nat_cache_dirty(nm_i, ne)				\
 	do {								\
-		ne->checkpointed = true;				\
+		set_nat_flag(ne, IS_CHECKPOINTED, true);		\
 		list_move_tail(&ne->list, &nm_i->nat_entries);		\
 	} while (0)
 #define inc_node_version(version)	(++version)
 
+static inline void set_nat_flag(struct nat_entry *ne,
+				unsigned int type, bool set)
+{
+	unsigned char mask = 0x01 << type;
+	if (set)
+		ne->flag |= mask;
+	else
+		ne->flag &= ~mask;
+}
+
+static inline bool get_nat_flag(struct nat_entry *ne, unsigned int type)
+{
+	unsigned char mask = 0x01 << type;
+	return ne->flag & mask;
+}
+
 static inline void node_info_from_raw_nat(struct node_info *ni,
 						struct f2fs_nat_entry *raw_ne)
 {

commit c6e489305eb5ed029002b037e36800032a994bb4
Author: Huang Ying <ying.huang@intel.com>
Date:   Fri Sep 12 19:21:11 2014 +0800

    f2fs: fix a race condition in next_free_nid
    
    The nm_i->fcnt checking is executed before spin_lock, so if another
    thread delete the last free_nid from the list, the wrong nid may be
    gotten.  So fix the race condition by moving the nm_i->fnct checking
    into spin_lock.
    
    Signed-off-by: Huang, Ying <ying.huang@intel.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index b24f588a0fe4..324917d757f7 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -115,9 +115,11 @@ static inline int next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
 	struct free_nid *fnid;
 
-	if (nm_i->fcnt <= 0)
-		return -1;
 	spin_lock(&nm_i->free_nid_list_lock);
+	if (nm_i->fcnt <= 0) {
+		spin_unlock(&nm_i->free_nid_list_lock);
+		return -1;
+	}
 	fnid = list_entry(nm_i->free_nid_list.next, struct free_nid, list);
 	*nid = fnid->nid;
 	spin_unlock(&nm_i->free_nid_list_lock);

commit 4081363fbe84a7ebac6d3339dd2775df45d856d0
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Sep 2 15:31:18 2014 -0700

    f2fs: introduce F2FS_I_SB, F2FS_M_SB, and F2FS_P_SB
    
    This patch adds three inline functions to clean up dirty casting codes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 8a116a407599..b24f588a0fe4 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -197,8 +197,7 @@ static inline void copy_node_footer(struct page *dst, struct page *src)
 
 static inline void fill_node_footer_blkaddr(struct page *page, block_t blkaddr)
 {
-	struct f2fs_sb_info *sbi = F2FS_SB(page->mapping->host->i_sb);
-	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
+	struct f2fs_checkpoint *ckpt = F2FS_CKPT(F2FS_P_SB(page));
 	struct f2fs_node *rn = F2FS_NODE(page);
 
 	rn->footer.cp_ver = ckpt->checkpoint_ver;

commit aec71382c68135261ef6efc3d8a96b7149939446
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Jun 24 09:18:20 2014 +0800

    f2fs: refactor flush_nat_entries codes for reducing NAT writes
    
    Although building NAT journal in cursum reduce the read/write work for NAT
    block, but previous design leave us lower performance when write checkpoint
    frequently for these cases:
    1. if journal in cursum has already full, it's a bit of waste that we flush all
       nat entries to page for persistence, but not to cache any entries.
    2. if journal in cursum is not full, we fill nat entries to journal util
       journal is full, then flush the left dirty entries to disk without merge
       journaled entries, so these journaled entries may be flushed to disk at next
       checkpoint but lost chance to flushed last time.
    
    In this patch we merge dirty entries located in same NAT block to nat entry set,
    and linked all set to list, sorted ascending order by entries' count of set.
    Later we flush entries in sparse set into journal as many as we can, and then
    flush merged entries to disk. In this way we can not only gain in performance,
    but also save lifetime of flash device.
    
    In my testing environment, it shows this patch can help to reduce NAT block
    writes obviously. In hard disk test case: cost time of fsstress is stablely
    reduced by about 5%.
    
    1. virtual machine + hard disk:
    fsstress -p 20 -n 200 -l 5
                    node num        cp count        nodes/cp
    based           4599.6          1803.0          2.551
    patched         2714.6          1829.6          1.483
    
    2. virtual machine + 32g micro SD card:
    fsstress -p 20 -n 200 -l 1 -w -f chown=0 -f creat=4 -f dwrite=0
    -f fdatasync=4 -f fsync=4 -f link=0 -f mkdir=4 -f mknod=4 -f rename=5
    -f rmdir=5 -f symlink=0 -f truncate=4 -f unlink=5 -f write=0 -S
    
                    node num        cp count        nodes/cp
    based           84.5            43.7            1.933
    patched         49.2            40.0            1.23
    
    Our latency of merging op shows not bad when handling extreme case like:
    merging a great number of dirty nats:
    latency(ns)     dirty nat count
    3089219         24922
    5129423         27422
    4000250         24523
    
    change log from v1:
     o fix wrong logic in add_nat_entry when grab a new nat entry set.
     o swith to create slab cache in create_node_manager_caches.
     o use GFP_ATOMIC instead of GFP_NOFS to avoid potential long latency.
    
    change log from v2:
     o make comment position more appropriate suggested by Jaegeuk Kim.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 7281112cd1c8..8a116a407599 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -89,6 +89,13 @@ enum mem_type {
 	DIRTY_DENTS	/* indicates dirty dentry pages */
 };
 
+struct nat_entry_set {
+	struct list_head set_list;	/* link with all nat sets */
+	struct list_head entry_list;	/* link with dirty nat entries */
+	nid_t start_nid;		/* start nid of nats in set */
+	unsigned int entry_cnt;		/* the # of nat entries in set */
+};
+
 /*
  * For free nid mangement
  */

commit 8b376249e7e659c41896e0d3e9b25d1230a4e7f6
Author: Zhang Zhen <zhenzhang.zhang@huawei.com>
Date:   Sun May 4 16:37:06 2014 +0800

    f2fs: fix checkpatch warning
    
    fix the following checkpatch warning:
    WARNING: do {} while (0) macros should not be semicolon terminated
    
    Signed-off-by: Zhang Zhen <zhenzhang.zhang@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 4ee29d506f8c..7281112cd1c8 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -59,12 +59,12 @@ struct nat_entry {
 	do {								\
 		ne->checkpointed = false;				\
 		list_move_tail(&ne->list, &nm_i->dirty_nat_entries);	\
-	} while (0);
+	} while (0)
 #define __clear_nat_cache_dirty(nm_i, ne)				\
 	do {								\
 		ne->checkpointed = true;				\
 		list_move_tail(&ne->list, &nm_i->nat_entries);		\
-	} while (0);
+	} while (0)
 #define inc_node_version(version)	(++version)
 
 static inline void node_info_from_raw_nat(struct node_info *ni,

commit 54b591dfda1f5ab0bc2a9ce1bee5364110168777
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Apr 29 17:28:32 2014 +0900

    f2fs: split grab_cache_page and wait_on_page_writeback for node pages
    
    This patch splits grab_cache_page_write_begin into grab_cache_page and
    wait_on_page_writeback for node pages.
    
    This patch intends to enhance the latency to get node pages by alleviating
    unnecessary wait_on_page_writeback.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index a076c88bdca5..4ee29d506f8c 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -272,7 +272,7 @@ static inline void set_nid(struct page *p, int off, nid_t nid, bool i)
 {
 	struct f2fs_node *rn = F2FS_NODE(p);
 
-	wait_on_page_writeback(p);
+	f2fs_wait_on_page_writeback(p, NODE);
 
 	if (i)
 		rn->i.i_nid[off - NODE_DIR1_BLOCK] = cpu_to_le32(nid);

commit 6fb03f3a40805a412c9b285010ffdc2e7563f81b
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Apr 16 10:47:06 2014 +0900

    f2fs: adjust free mem size to flush dentry blocks
    
    If so many dirty dentry blocks are cached, not reached to the flush condition,
    we should fall into livelock in balance_dirty_pages.
    So, let's consider the mem size for the condition.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 41bb65b1c97d..a076c88bdca5 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -83,9 +83,10 @@ static inline void raw_nat_from_node_info(struct f2fs_nat_entry *raw_ne,
 	raw_ne->version = ni->version;
 }
 
-enum nid_type {
+enum mem_type {
 	FREE_NIDS,	/* indicates the free nid list */
-	NAT_ENTRIES	/* indicates the cached nat entry */
+	NAT_ENTRIES,	/* indicates the cached nat entry */
+	DIRTY_DENTS	/* indicates dirty dentry pages */
 };
 
 /*

commit 94dac22e72e891b16e8e8abbdb6df10f322d20e0
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Apr 17 10:51:05 2014 +0800

    f2fs: introduce raw_nat_from_node_info() to simplfy codes
    
    This patch introduce raw_nat_from_node_info() to simplfy some codes, and also
    use exist function node_info_from_raw_nat() to do the same job.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 5decc1a375f0..41bb65b1c97d 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -75,6 +75,14 @@ static inline void node_info_from_raw_nat(struct node_info *ni,
 	ni->version = raw_ne->version;
 }
 
+static inline void raw_nat_from_node_info(struct f2fs_nat_entry *raw_ne,
+						struct node_info *ni)
+{
+	raw_ne->ino = cpu_to_le32(ni->ino);
+	raw_ne->block_addr = cpu_to_le32(ni->blk_addr);
+	raw_ne->version = ni->version;
+}
+
 enum nid_type {
 	FREE_NIDS,	/* indicates the free nid list */
 	NAT_ENTRIES	/* indicates the cached nat entry */

commit 479f40c44ae30e02642ce0391be707a53852d545
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Mar 20 21:52:53 2014 +0900

    f2fs: skip unnecessary node writes during fsync
    
    If multiple redundant fsync calls are triggered, we don't need to write its
    node pages with fsync mark continuously.
    
    So, this patch adds FI_NEED_FSYNC to track whether the latest node block is
    written with the fsync mark or not.
    If the mark was set, a new fsync doesn't need to write a node block.
    Otherwise, we should do a new node block with the mark for roll-forward
    recovery.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index c2015b71ff87..5decc1a375f0 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -42,6 +42,7 @@ struct node_info {
 struct nat_entry {
 	struct list_head list;	/* for clean or dirty nat list */
 	bool checkpointed;	/* whether it is checkpointed or not */
+	bool fsync_done;	/* whether the latest node has fsync mark */
 	struct node_info ni;	/* in-memory node information */
 };
 

commit a5f420101db326e27ef5c2ab737c8c1b0e3559e3
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Mar 19 13:45:52 2014 +0900

    f2fs: remove unnecessary threshold
    
    The NM_WOUT_THRESHOLD is now obsolete since f2fs starts to control on a basis
    of the memory footprint.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index c97215432100..c2015b71ff87 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -20,9 +20,6 @@
 /* maximum readahead size for node during getting data blocks */
 #define MAX_RA_NODE		128
 
-/* maximum cached nat entries to manage memory footprint */
-#define NM_WOUT_THRESHOLD	(64 * NAT_ENTRY_PER_BLOCK)
-
 /* control the memory footprint threshold (10MB per 1GB ram) */
 #define DEF_RAM_THRESHOLD	10
 

commit cdfc41c134d48c1923066bcfa6630b94588ad6bc
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Mar 19 13:31:37 2014 +0900

    f2fs: throttle the memory footprint with a sysfs entry
    
    This patch introduces ram_thresh, a sysfs entry, which controls the memory
    footprint used by the free nid list and the nat cache.
    
    Previously, the free nid list was controlled by MAX_FREE_NIDS, while the nat
    cache was managed by NM_WOUT_THRESHOLD.
    However, this approach cannot be applied dynamically according to the system.
    
    So, this patch adds ram_thresh that users can specify the threshold, which is
    in order of 1 / 1024.
    For example, if the total ram size is 4GB and the value is set to 10 by default,
    f2fs tries to control the number of free nids and nat caches not to consume over
    10 * (4GB / 1024) = 10MB.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index ee6d28684ee8..c97215432100 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -17,15 +17,15 @@
 /* # of pages to perform readahead before building free nids */
 #define FREE_NID_PAGES 4
 
-/* maximum # of free node ids to produce during build_free_nids */
-#define MAX_FREE_NIDS (NAT_ENTRY_PER_BLOCK * FREE_NID_PAGES)
-
 /* maximum readahead size for node during getting data blocks */
 #define MAX_RA_NODE		128
 
 /* maximum cached nat entries to manage memory footprint */
 #define NM_WOUT_THRESHOLD	(64 * NAT_ENTRY_PER_BLOCK)
 
+/* control the memory footprint threshold (10MB per 1GB ram) */
+#define DEF_RAM_THRESHOLD	10
+
 /* vector size for gang look-up from nat cache that consists of radix tree */
 #define NATVEC_SIZE	64
 
@@ -77,6 +77,11 @@ static inline void node_info_from_raw_nat(struct node_info *ni,
 	ni->version = raw_ne->version;
 }
 
+enum nid_type {
+	FREE_NIDS,	/* indicates the free nid list */
+	NAT_ENTRIES	/* indicates the cached nat entry */
+};
+
 /*
  * For free nid mangement
  */

commit 4bc8e9bcf50103216a7a316ab66b9bb8e81baa27
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Mar 17 16:35:06 2014 +0800

    f2fs: introduce f2fs_has_xattr_block for better readability
    
    This patch introduces a help function f2fs_has_xattr_block for better
    readability.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 4dea719766ef..ee6d28684ee8 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -242,7 +242,7 @@ static inline bool IS_DNODE(struct page *node_page)
 {
 	unsigned int ofs = ofs_of_node(node_page);
 
-	if (ofs == XATTR_NODE_OFFSET)
+	if (f2fs_has_xattr_block(ofs))
 		return false;
 
 	if (ofs == 3 || ofs == 4 + NIDS_PER_BLOCK ||

commit fffc2a00fc01b781c1e3b9541e3e0f270c50ce90
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Feb 21 13:17:22 2014 +0900

    f2fs: fix to mark the checkpointed nat entry correctly
    
    The nat cache entry maintains a status whether it is checkpointed or not.
    So, if a new cache entry is loaded from the last checkpoint,
    nat_entry->checkpointed should be true.
    If the cache entry is modified as being dirty, nat_entry->checkpoint should
    be false.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index c4c79885c993..4dea719766ef 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -58,9 +58,15 @@ struct nat_entry {
 #define nat_set_version(nat, v)		(nat->ni.version = v)
 
 #define __set_nat_cache_dirty(nm_i, ne)					\
-	list_move_tail(&ne->list, &nm_i->dirty_nat_entries);
+	do {								\
+		ne->checkpointed = false;				\
+		list_move_tail(&ne->list, &nm_i->dirty_nat_entries);	\
+	} while (0);
 #define __clear_nat_cache_dirty(nm_i, ne)				\
-	list_move_tail(&ne->list, &nm_i->nat_entries);
+	do {								\
+		ne->checkpointed = true;				\
+		list_move_tail(&ne->list, &nm_i->nat_entries);		\
+	} while (0);
 #define inc_node_version(version)	(++version)
 
 static inline void node_info_from_raw_nat(struct node_info *ni,

commit 4f4124d0b99682efa7307191a28ec050872d2079
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sat Dec 21 18:02:14 2013 +0800

    f2fs: update several comments
    
    Update several comments:
    1. use f2fs_{un}lock_op install of mutex_{un}lock_op.
    2. update comment of get_data_block().
    3. update description of node offset.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 3496bb3e15dc..c4c79885c993 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -224,7 +224,13 @@ static inline block_t next_blkaddr_of_node(struct page *node_page)
  *    |            `- direct node (5 + N => 5 + 2N - 1)
  *    `- double indirect node (5 + 2N)
  *                 `- indirect node (6 + 2N)
- *                       `- direct node (x(N + 1))
+ *                       `- direct node
+ *                 ......
+ *                 `- indirect node ((6 + 2N) + x(N + 1))
+ *                       `- direct node
+ *                 ......
+ *                 `- indirect node ((6 + 2N) + (N - 1)(N + 1))
+ *                       `- direct node
  */
 static inline bool IS_DNODE(struct page *node_page)
 {

commit dbe6a5ff4fa78bdfa983458c338831d91b35f315
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Aug 9 08:14:06 2013 +0900

    f2fs: fix the use of XATTR_NODE_OFFSET
    
    This patch fixes the use of XATTR_NODE_OFFSET.
    
    o The offset should not use several MSB bits which are used by marking node
    blocks.
    
    o IS_DNODE should handle XATTR_NODE_OFFSET to avoid potential abnormality
    during the fsync call.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 87349c4ea0ef..3496bb3e15dc 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -229,6 +229,10 @@ static inline block_t next_blkaddr_of_node(struct page *node_page)
 static inline bool IS_DNODE(struct page *node_page)
 {
 	unsigned int ofs = ofs_of_node(node_page);
+
+	if (ofs == XATTR_NODE_OFFSET)
+		return false;
+
 	if (ofs == 3 || ofs == 4 + NIDS_PER_BLOCK ||
 			ofs == 5 + 2 * NIDS_PER_BLOCK)
 		return false;

commit 4559071063270999d016c92a0b9241692cbbb522
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Mon Jul 15 17:57:38 2013 +0800

    f2fs: introduce help function F2FS_NODE()
    
    Introduce help function F2FS_NODE() to simplify the conversion of node_page to
    f2fs_node.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index c65fb4f4230f..87349c4ea0ef 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -155,8 +155,7 @@ static inline void set_to_next_nat(struct f2fs_nm_info *nm_i, nid_t start_nid)
 static inline void fill_node_footer(struct page *page, nid_t nid,
 				nid_t ino, unsigned int ofs, bool reset)
 {
-	void *kaddr = page_address(page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	struct f2fs_node *rn = F2FS_NODE(page);
 	if (reset)
 		memset(rn, 0, sizeof(*rn));
 	rn->footer.nid = cpu_to_le32(nid);
@@ -166,10 +165,8 @@ static inline void fill_node_footer(struct page *page, nid_t nid,
 
 static inline void copy_node_footer(struct page *dst, struct page *src)
 {
-	void *src_addr = page_address(src);
-	void *dst_addr = page_address(dst);
-	struct f2fs_node *src_rn = (struct f2fs_node *)src_addr;
-	struct f2fs_node *dst_rn = (struct f2fs_node *)dst_addr;
+	struct f2fs_node *src_rn = F2FS_NODE(src);
+	struct f2fs_node *dst_rn = F2FS_NODE(dst);
 	memcpy(&dst_rn->footer, &src_rn->footer, sizeof(struct node_footer));
 }
 
@@ -177,45 +174,40 @@ static inline void fill_node_footer_blkaddr(struct page *page, block_t blkaddr)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(page->mapping->host->i_sb);
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
-	void *kaddr = page_address(page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	struct f2fs_node *rn = F2FS_NODE(page);
+
 	rn->footer.cp_ver = ckpt->checkpoint_ver;
 	rn->footer.next_blkaddr = cpu_to_le32(blkaddr);
 }
 
 static inline nid_t ino_of_node(struct page *node_page)
 {
-	void *kaddr = page_address(node_page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	struct f2fs_node *rn = F2FS_NODE(node_page);
 	return le32_to_cpu(rn->footer.ino);
 }
 
 static inline nid_t nid_of_node(struct page *node_page)
 {
-	void *kaddr = page_address(node_page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	struct f2fs_node *rn = F2FS_NODE(node_page);
 	return le32_to_cpu(rn->footer.nid);
 }
 
 static inline unsigned int ofs_of_node(struct page *node_page)
 {
-	void *kaddr = page_address(node_page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	struct f2fs_node *rn = F2FS_NODE(node_page);
 	unsigned flag = le32_to_cpu(rn->footer.flag);
 	return flag >> OFFSET_BIT_SHIFT;
 }
 
 static inline unsigned long long cpver_of_node(struct page *node_page)
 {
-	void *kaddr = page_address(node_page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	struct f2fs_node *rn = F2FS_NODE(node_page);
 	return le64_to_cpu(rn->footer.cp_ver);
 }
 
 static inline block_t next_blkaddr_of_node(struct page *node_page)
 {
-	void *kaddr = page_address(node_page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	struct f2fs_node *rn = F2FS_NODE(node_page);
 	return le32_to_cpu(rn->footer.next_blkaddr);
 }
 
@@ -250,7 +242,7 @@ static inline bool IS_DNODE(struct page *node_page)
 
 static inline void set_nid(struct page *p, int off, nid_t nid, bool i)
 {
-	struct f2fs_node *rn = (struct f2fs_node *)page_address(p);
+	struct f2fs_node *rn = F2FS_NODE(p);
 
 	wait_on_page_writeback(p);
 
@@ -263,7 +255,8 @@ static inline void set_nid(struct page *p, int off, nid_t nid, bool i)
 
 static inline nid_t get_nid(struct page *p, int off, bool i)
 {
-	struct f2fs_node *rn = (struct f2fs_node *)page_address(p);
+	struct f2fs_node *rn = F2FS_NODE(p);
+
 	if (i)
 		return le32_to_cpu(rn->i.i_nid[off - NODE_DIR1_BLOCK]);
 	return le32_to_cpu(rn->in.nid[off]);
@@ -314,8 +307,7 @@ static inline void clear_cold_data(struct page *page)
 
 static inline int is_node(struct page *page, int type)
 {
-	void *kaddr = page_address(page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	struct f2fs_node *rn = F2FS_NODE(page);
 	return le32_to_cpu(rn->footer.flag) & (1 << type);
 }
 
@@ -325,7 +317,7 @@ static inline int is_node(struct page *page, int type)
 
 static inline void set_cold_node(struct inode *inode, struct page *page)
 {
-	struct f2fs_node *rn = (struct f2fs_node *)page_address(page);
+	struct f2fs_node *rn = F2FS_NODE(page);
 	unsigned int flag = le32_to_cpu(rn->footer.flag);
 
 	if (S_ISDIR(inode->i_mode))
@@ -337,7 +329,7 @@ static inline void set_cold_node(struct inode *inode, struct page *page)
 
 static inline void set_mark(struct page *page, int mark, int type)
 {
-	struct f2fs_node *rn = (struct f2fs_node *)page_address(page);
+	struct f2fs_node *rn = F2FS_NODE(page);
 	unsigned int flag = le32_to_cpu(rn->footer.flag);
 	if (mark)
 		flag |= (0x1 << type);

commit 354a3399dc6f7e556d04e1c731cd50e08eeb44bd
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Jun 14 08:52:35 2013 +0900

    f2fs: recover wrong pino after checkpoint during fsync
    
    If a file is linked, f2fs loose its parent inode number so that fsync calls
    for the linked file should do checkpoint all the time.
    But, if we can recover its parent inode number after the checkpoint, we can
    adjust roll-forward mechanism for the further fsync calls, which is able to
    improve the fsync performance significatly.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index a503661307db..c65fb4f4230f 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -285,10 +285,17 @@ static inline void set_file(struct inode *inode, int type)
 	F2FS_I(inode)->i_advise |= type;
 }
 
-#define is_cold_file(inode)	is_file(inode, FADVISE_COLD_BIT)
-#define is_cp_file(inode)	is_file(inode, FADVISE_CP_BIT)
-#define set_cold_file(inode)	set_file(inode, FADVISE_COLD_BIT)
-#define set_cp_file(inode)	set_file(inode, FADVISE_CP_BIT)
+static inline void clear_file(struct inode *inode, int type)
+{
+	F2FS_I(inode)->i_advise &= ~type;
+}
+
+#define file_is_cold(inode)	is_file(inode, FADVISE_COLD_BIT)
+#define file_wrong_pino(inode)	is_file(inode, FADVISE_LOST_PINO_BIT)
+#define file_set_cold(inode)	set_file(inode, FADVISE_COLD_BIT)
+#define file_lost_pino(inode)	set_file(inode, FADVISE_LOST_PINO_BIT)
+#define file_clear_cold(inode)	clear_file(inode, FADVISE_COLD_BIT)
+#define file_got_pino(inode)	clear_file(inode, FADVISE_LOST_PINO_BIT)
 
 static inline int is_cold_data(struct page *page)
 {

commit a06a2416038d317a6430e453f5bc5fd81834554d
Author: Namjae Jeon <namjae.jeon@samsung.com>
Date:   Thu May 23 22:58:40 2013 +0900

    f2fs: optimize several routines in node.h
    
    There are various functions with common code which could be separated
    out to make common routines. So, made new routines and in order to
    retain the same call path and no major changes, written some macros
    to access those routines.
    
    Signed-off-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Amit Sahrawat <a.sahrawat@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 0a2d72f0024d..a503661307db 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -275,25 +275,20 @@ static inline nid_t get_nid(struct page *p, int off, bool i)
  *  - Mark cold node blocks in their node footer
  *  - Mark cold data pages in page cache
  */
-static inline int is_cold_file(struct inode *inode)
+static inline int is_file(struct inode *inode, int type)
 {
-	return F2FS_I(inode)->i_advise & FADVISE_COLD_BIT;
+	return F2FS_I(inode)->i_advise & type;
 }
 
-static inline void set_cold_file(struct inode *inode)
+static inline void set_file(struct inode *inode, int type)
 {
-	F2FS_I(inode)->i_advise |= FADVISE_COLD_BIT;
+	F2FS_I(inode)->i_advise |= type;
 }
 
-static inline int is_cp_file(struct inode *inode)
-{
-	return F2FS_I(inode)->i_advise & FADVISE_CP_BIT;
-}
-
-static inline void set_cp_file(struct inode *inode)
-{
-	F2FS_I(inode)->i_advise |= FADVISE_CP_BIT;
-}
+#define is_cold_file(inode)	is_file(inode, FADVISE_COLD_BIT)
+#define is_cp_file(inode)	is_file(inode, FADVISE_CP_BIT)
+#define set_cold_file(inode)	set_file(inode, FADVISE_COLD_BIT)
+#define set_cp_file(inode)	set_file(inode, FADVISE_CP_BIT)
 
 static inline int is_cold_data(struct page *page)
 {
@@ -310,29 +305,16 @@ static inline void clear_cold_data(struct page *page)
 	ClearPageChecked(page);
 }
 
-static inline int is_cold_node(struct page *page)
+static inline int is_node(struct page *page, int type)
 {
 	void *kaddr = page_address(page);
 	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
-	unsigned int flag = le32_to_cpu(rn->footer.flag);
-	return flag & (0x1 << COLD_BIT_SHIFT);
+	return le32_to_cpu(rn->footer.flag) & (1 << type);
 }
 
-static inline unsigned char is_fsync_dnode(struct page *page)
-{
-	void *kaddr = page_address(page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
-	unsigned int flag = le32_to_cpu(rn->footer.flag);
-	return flag & (0x1 << FSYNC_BIT_SHIFT);
-}
-
-static inline unsigned char is_dent_dnode(struct page *page)
-{
-	void *kaddr = page_address(page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
-	unsigned int flag = le32_to_cpu(rn->footer.flag);
-	return flag & (0x1 << DENT_BIT_SHIFT);
-}
+#define is_cold_node(page)	is_node(page, COLD_BIT_SHIFT)
+#define is_fsync_dnode(page)	is_node(page, FSYNC_BIT_SHIFT)
+#define is_dent_dnode(page)	is_node(page, DENT_BIT_SHIFT)
 
 static inline void set_cold_node(struct inode *inode, struct page *page)
 {
@@ -346,26 +328,15 @@ static inline void set_cold_node(struct inode *inode, struct page *page)
 	rn->footer.flag = cpu_to_le32(flag);
 }
 
-static inline void set_fsync_mark(struct page *page, int mark)
-{
-	void *kaddr = page_address(page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
-	unsigned int flag = le32_to_cpu(rn->footer.flag);
-	if (mark)
-		flag |= (0x1 << FSYNC_BIT_SHIFT);
-	else
-		flag &= ~(0x1 << FSYNC_BIT_SHIFT);
-	rn->footer.flag = cpu_to_le32(flag);
-}
-
-static inline void set_dentry_mark(struct page *page, int mark)
+static inline void set_mark(struct page *page, int mark, int type)
 {
-	void *kaddr = page_address(page);
-	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	struct f2fs_node *rn = (struct f2fs_node *)page_address(page);
 	unsigned int flag = le32_to_cpu(rn->footer.flag);
 	if (mark)
-		flag |= (0x1 << DENT_BIT_SHIFT);
+		flag |= (0x1 << type);
 	else
-		flag &= ~(0x1 << DENT_BIT_SHIFT);
+		flag &= ~(0x1 << type);
 	rn->footer.flag = cpu_to_le32(flag);
 }
+#define set_dentry_mark(page, mark)	set_mark(page, mark, DENT_BIT_SHIFT)
+#define set_fsync_mark(page, mark)	set_mark(page, mark, FSYNC_BIT_SHIFT)

commit 3315101f7070013d01bb5396c6bde07b3a8bcbd8
Author: Zhihui Zhang <zzhsuny@gmail.com>
Date:   Sun Apr 7 12:57:04 2013 -0400

    f2fs: fix the logic of IS_DNODE()
    
    If (ofs % (NIDS_PER_BLOCK + 1) == 0), the node is an indirect node block.
    
    Signed-off-by: Zhihui Zhang <zzhsuny@gmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 271a61c25601..0a2d72f0024d 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -242,7 +242,7 @@ static inline bool IS_DNODE(struct page *node_page)
 		return false;
 	if (ofs >= 6 + 2 * NIDS_PER_BLOCK) {
 		ofs -= 6 + 2 * NIDS_PER_BLOCK;
-		if ((long int)ofs % (NIDS_PER_BLOCK + 1))
+		if (!((long int)ofs % (NIDS_PER_BLOCK + 1)))
 			return false;
 	}
 	return true;

commit 56ae674cc27230ea86ab25db7fcf1f32dfe17ec1
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Sun Mar 31 12:47:20 2013 +0900

    f2fs: remove redundant lock_page calls
    
    In get_node_page, we do not need to call lock_page all the time.
    
    If the node page is cached as uptodate,
    
    1. grab_cache_page locks the page,
    2. read_node_page unlocks the page, and
    3. lock_page is called for further process.
    
    Let's avoid this.
    
    Reviewed-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index d009cdfd2679..271a61c25601 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -29,6 +29,9 @@
 /* vector size for gang look-up from nat cache that consists of radix tree */
 #define NATVEC_SIZE	64
 
+/* return value for read_node_page */
+#define LOCKED_PAGE	1
+
 /*
  * For node information
  */

commit 953a3e27e10fc6acb480801ea47197d0270d735e
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Mar 21 15:21:57 2013 +0900

    f2fs: fix to give correct parent inode number for roll forward
    
    When we recover fsync'ed data after power-off-recovery, we should guarantee
    that any parent inode number should be correct for each direct inode blocks.
    
    So, let's make the following rules.
    
    - The fsync should do checkpoint to all the inodes that were experienced hard
    links.
    
    - So, the only normal files can be recovered by roll-forward.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index afdb130f782e..d009cdfd2679 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -277,6 +277,21 @@ static inline int is_cold_file(struct inode *inode)
 	return F2FS_I(inode)->i_advise & FADVISE_COLD_BIT;
 }
 
+static inline void set_cold_file(struct inode *inode)
+{
+	F2FS_I(inode)->i_advise |= FADVISE_COLD_BIT;
+}
+
+static inline int is_cp_file(struct inode *inode)
+{
+	return F2FS_I(inode)->i_advise & FADVISE_CP_BIT;
+}
+
+static inline void set_cp_file(struct inode *inode)
+{
+	F2FS_I(inode)->i_advise |= FADVISE_CP_BIT;
+}
+
 static inline int is_cold_data(struct page *page)
 {
 	return PageChecked(page);

commit 0a8165d7c2cf1395059db20ab07665baf3758fcd
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Nov 29 13:28:09 2012 +0900

    f2fs: adjust kernel coding style
    
    As pointed out by Randy Dunlap, this patch removes all usage of "/**" for comment
    blocks. Instead, just use "/*".
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 0ab92d643052..afdb130f782e 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -1,4 +1,4 @@
-/**
+/*
  * fs/f2fs/node.h
  *
  * Copyright (c) 2012 Samsung Electronics Co., Ltd.

commit 25ca923b2a766b9c93b63777ead351137533a623
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Nov 28 16:12:41 2012 +0900

    f2fs: fix endian conversion bugs reported by sparse
    
    This patch should resolve the bugs reported by the sparse tool.
    Initial reports were written by "kbuild test robot" managed by fengguang.wu.
    
    In my local machines, I've tested also by running:
    > make C=2 CF="-D__CHECK_ENDIAN__"
    
    Accordingly, I've found lots of warnings and bugs related to the endian
    conversion. And I've fixed all at this moment.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
index 5d525ed312ba..0ab92d643052 100644
--- a/fs/f2fs/node.h
+++ b/fs/f2fs/node.h
@@ -177,7 +177,7 @@ static inline void fill_node_footer_blkaddr(struct page *page, block_t blkaddr)
 	void *kaddr = page_address(page);
 	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
 	rn->footer.cp_ver = ckpt->checkpoint_ver;
-	rn->footer.next_blkaddr = blkaddr;
+	rn->footer.next_blkaddr = cpu_to_le32(blkaddr);
 }
 
 static inline nid_t ino_of_node(struct page *node_page)

commit 39a53e0ce0df01b3cf4bb898c7ae2fd2189647d5
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Nov 28 13:37:31 2012 +0900

    f2fs: add superblock and major in-memory structure
    
    This adds the following major in-memory structures in f2fs.
    
    - f2fs_sb_info:
      contains f2fs-specific information, two special inode pointers for node and
      meta address spaces, and orphan inode management.
    
    - f2fs_inode_info:
      contains vfs_inode and other fs-specific information.
    
    - f2fs_nm_info:
      contains node manager information such as NAT entry cache, free nid list,
      and NAT page management.
    
    - f2fs_node_info:
      represents a node as node id, inode number, block address, and its version.
    
    - f2fs_sm_info:
      contains segment manager information such as SIT entry cache, free segment
      map, current active logs, dirty segment management, and segment utilization.
      The specific structures are sit_info, free_segmap_info, dirty_seglist_info,
      curseg_info.
    
    In addition, add F2FS_SUPER_MAGIC in magic.h.
    
    Signed-off-by: Chul Lee <chur.lee@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/node.h b/fs/f2fs/node.h
new file mode 100644
index 000000000000..5d525ed312ba
--- /dev/null
+++ b/fs/f2fs/node.h
@@ -0,0 +1,353 @@
+/**
+ * fs/f2fs/node.h
+ *
+ * Copyright (c) 2012 Samsung Electronics Co., Ltd.
+ *             http://www.samsung.com/
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+/* start node id of a node block dedicated to the given node id */
+#define	START_NID(nid) ((nid / NAT_ENTRY_PER_BLOCK) * NAT_ENTRY_PER_BLOCK)
+
+/* node block offset on the NAT area dedicated to the given start node id */
+#define	NAT_BLOCK_OFFSET(start_nid) (start_nid / NAT_ENTRY_PER_BLOCK)
+
+/* # of pages to perform readahead before building free nids */
+#define FREE_NID_PAGES 4
+
+/* maximum # of free node ids to produce during build_free_nids */
+#define MAX_FREE_NIDS (NAT_ENTRY_PER_BLOCK * FREE_NID_PAGES)
+
+/* maximum readahead size for node during getting data blocks */
+#define MAX_RA_NODE		128
+
+/* maximum cached nat entries to manage memory footprint */
+#define NM_WOUT_THRESHOLD	(64 * NAT_ENTRY_PER_BLOCK)
+
+/* vector size for gang look-up from nat cache that consists of radix tree */
+#define NATVEC_SIZE	64
+
+/*
+ * For node information
+ */
+struct node_info {
+	nid_t nid;		/* node id */
+	nid_t ino;		/* inode number of the node's owner */
+	block_t	blk_addr;	/* block address of the node */
+	unsigned char version;	/* version of the node */
+};
+
+struct nat_entry {
+	struct list_head list;	/* for clean or dirty nat list */
+	bool checkpointed;	/* whether it is checkpointed or not */
+	struct node_info ni;	/* in-memory node information */
+};
+
+#define nat_get_nid(nat)		(nat->ni.nid)
+#define nat_set_nid(nat, n)		(nat->ni.nid = n)
+#define nat_get_blkaddr(nat)		(nat->ni.blk_addr)
+#define nat_set_blkaddr(nat, b)		(nat->ni.blk_addr = b)
+#define nat_get_ino(nat)		(nat->ni.ino)
+#define nat_set_ino(nat, i)		(nat->ni.ino = i)
+#define nat_get_version(nat)		(nat->ni.version)
+#define nat_set_version(nat, v)		(nat->ni.version = v)
+
+#define __set_nat_cache_dirty(nm_i, ne)					\
+	list_move_tail(&ne->list, &nm_i->dirty_nat_entries);
+#define __clear_nat_cache_dirty(nm_i, ne)				\
+	list_move_tail(&ne->list, &nm_i->nat_entries);
+#define inc_node_version(version)	(++version)
+
+static inline void node_info_from_raw_nat(struct node_info *ni,
+						struct f2fs_nat_entry *raw_ne)
+{
+	ni->ino = le32_to_cpu(raw_ne->ino);
+	ni->blk_addr = le32_to_cpu(raw_ne->block_addr);
+	ni->version = raw_ne->version;
+}
+
+/*
+ * For free nid mangement
+ */
+enum nid_state {
+	NID_NEW,	/* newly added to free nid list */
+	NID_ALLOC	/* it is allocated */
+};
+
+struct free_nid {
+	struct list_head list;	/* for free node id list */
+	nid_t nid;		/* node id */
+	int state;		/* in use or not: NID_NEW or NID_ALLOC */
+};
+
+static inline int next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)
+{
+	struct f2fs_nm_info *nm_i = NM_I(sbi);
+	struct free_nid *fnid;
+
+	if (nm_i->fcnt <= 0)
+		return -1;
+	spin_lock(&nm_i->free_nid_list_lock);
+	fnid = list_entry(nm_i->free_nid_list.next, struct free_nid, list);
+	*nid = fnid->nid;
+	spin_unlock(&nm_i->free_nid_list_lock);
+	return 0;
+}
+
+/*
+ * inline functions
+ */
+static inline void get_nat_bitmap(struct f2fs_sb_info *sbi, void *addr)
+{
+	struct f2fs_nm_info *nm_i = NM_I(sbi);
+	memcpy(addr, nm_i->nat_bitmap, nm_i->bitmap_size);
+}
+
+static inline pgoff_t current_nat_addr(struct f2fs_sb_info *sbi, nid_t start)
+{
+	struct f2fs_nm_info *nm_i = NM_I(sbi);
+	pgoff_t block_off;
+	pgoff_t block_addr;
+	int seg_off;
+
+	block_off = NAT_BLOCK_OFFSET(start);
+	seg_off = block_off >> sbi->log_blocks_per_seg;
+
+	block_addr = (pgoff_t)(nm_i->nat_blkaddr +
+		(seg_off << sbi->log_blocks_per_seg << 1) +
+		(block_off & ((1 << sbi->log_blocks_per_seg) - 1)));
+
+	if (f2fs_test_bit(block_off, nm_i->nat_bitmap))
+		block_addr += sbi->blocks_per_seg;
+
+	return block_addr;
+}
+
+static inline pgoff_t next_nat_addr(struct f2fs_sb_info *sbi,
+						pgoff_t block_addr)
+{
+	struct f2fs_nm_info *nm_i = NM_I(sbi);
+
+	block_addr -= nm_i->nat_blkaddr;
+	if ((block_addr >> sbi->log_blocks_per_seg) % 2)
+		block_addr -= sbi->blocks_per_seg;
+	else
+		block_addr += sbi->blocks_per_seg;
+
+	return block_addr + nm_i->nat_blkaddr;
+}
+
+static inline void set_to_next_nat(struct f2fs_nm_info *nm_i, nid_t start_nid)
+{
+	unsigned int block_off = NAT_BLOCK_OFFSET(start_nid);
+
+	if (f2fs_test_bit(block_off, nm_i->nat_bitmap))
+		f2fs_clear_bit(block_off, nm_i->nat_bitmap);
+	else
+		f2fs_set_bit(block_off, nm_i->nat_bitmap);
+}
+
+static inline void fill_node_footer(struct page *page, nid_t nid,
+				nid_t ino, unsigned int ofs, bool reset)
+{
+	void *kaddr = page_address(page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	if (reset)
+		memset(rn, 0, sizeof(*rn));
+	rn->footer.nid = cpu_to_le32(nid);
+	rn->footer.ino = cpu_to_le32(ino);
+	rn->footer.flag = cpu_to_le32(ofs << OFFSET_BIT_SHIFT);
+}
+
+static inline void copy_node_footer(struct page *dst, struct page *src)
+{
+	void *src_addr = page_address(src);
+	void *dst_addr = page_address(dst);
+	struct f2fs_node *src_rn = (struct f2fs_node *)src_addr;
+	struct f2fs_node *dst_rn = (struct f2fs_node *)dst_addr;
+	memcpy(&dst_rn->footer, &src_rn->footer, sizeof(struct node_footer));
+}
+
+static inline void fill_node_footer_blkaddr(struct page *page, block_t blkaddr)
+{
+	struct f2fs_sb_info *sbi = F2FS_SB(page->mapping->host->i_sb);
+	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
+	void *kaddr = page_address(page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	rn->footer.cp_ver = ckpt->checkpoint_ver;
+	rn->footer.next_blkaddr = blkaddr;
+}
+
+static inline nid_t ino_of_node(struct page *node_page)
+{
+	void *kaddr = page_address(node_page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	return le32_to_cpu(rn->footer.ino);
+}
+
+static inline nid_t nid_of_node(struct page *node_page)
+{
+	void *kaddr = page_address(node_page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	return le32_to_cpu(rn->footer.nid);
+}
+
+static inline unsigned int ofs_of_node(struct page *node_page)
+{
+	void *kaddr = page_address(node_page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	unsigned flag = le32_to_cpu(rn->footer.flag);
+	return flag >> OFFSET_BIT_SHIFT;
+}
+
+static inline unsigned long long cpver_of_node(struct page *node_page)
+{
+	void *kaddr = page_address(node_page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	return le64_to_cpu(rn->footer.cp_ver);
+}
+
+static inline block_t next_blkaddr_of_node(struct page *node_page)
+{
+	void *kaddr = page_address(node_page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	return le32_to_cpu(rn->footer.next_blkaddr);
+}
+
+/*
+ * f2fs assigns the following node offsets described as (num).
+ * N = NIDS_PER_BLOCK
+ *
+ *  Inode block (0)
+ *    |- direct node (1)
+ *    |- direct node (2)
+ *    |- indirect node (3)
+ *    |            `- direct node (4 => 4 + N - 1)
+ *    |- indirect node (4 + N)
+ *    |            `- direct node (5 + N => 5 + 2N - 1)
+ *    `- double indirect node (5 + 2N)
+ *                 `- indirect node (6 + 2N)
+ *                       `- direct node (x(N + 1))
+ */
+static inline bool IS_DNODE(struct page *node_page)
+{
+	unsigned int ofs = ofs_of_node(node_page);
+	if (ofs == 3 || ofs == 4 + NIDS_PER_BLOCK ||
+			ofs == 5 + 2 * NIDS_PER_BLOCK)
+		return false;
+	if (ofs >= 6 + 2 * NIDS_PER_BLOCK) {
+		ofs -= 6 + 2 * NIDS_PER_BLOCK;
+		if ((long int)ofs % (NIDS_PER_BLOCK + 1))
+			return false;
+	}
+	return true;
+}
+
+static inline void set_nid(struct page *p, int off, nid_t nid, bool i)
+{
+	struct f2fs_node *rn = (struct f2fs_node *)page_address(p);
+
+	wait_on_page_writeback(p);
+
+	if (i)
+		rn->i.i_nid[off - NODE_DIR1_BLOCK] = cpu_to_le32(nid);
+	else
+		rn->in.nid[off] = cpu_to_le32(nid);
+	set_page_dirty(p);
+}
+
+static inline nid_t get_nid(struct page *p, int off, bool i)
+{
+	struct f2fs_node *rn = (struct f2fs_node *)page_address(p);
+	if (i)
+		return le32_to_cpu(rn->i.i_nid[off - NODE_DIR1_BLOCK]);
+	return le32_to_cpu(rn->in.nid[off]);
+}
+
+/*
+ * Coldness identification:
+ *  - Mark cold files in f2fs_inode_info
+ *  - Mark cold node blocks in their node footer
+ *  - Mark cold data pages in page cache
+ */
+static inline int is_cold_file(struct inode *inode)
+{
+	return F2FS_I(inode)->i_advise & FADVISE_COLD_BIT;
+}
+
+static inline int is_cold_data(struct page *page)
+{
+	return PageChecked(page);
+}
+
+static inline void set_cold_data(struct page *page)
+{
+	SetPageChecked(page);
+}
+
+static inline void clear_cold_data(struct page *page)
+{
+	ClearPageChecked(page);
+}
+
+static inline int is_cold_node(struct page *page)
+{
+	void *kaddr = page_address(page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	unsigned int flag = le32_to_cpu(rn->footer.flag);
+	return flag & (0x1 << COLD_BIT_SHIFT);
+}
+
+static inline unsigned char is_fsync_dnode(struct page *page)
+{
+	void *kaddr = page_address(page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	unsigned int flag = le32_to_cpu(rn->footer.flag);
+	return flag & (0x1 << FSYNC_BIT_SHIFT);
+}
+
+static inline unsigned char is_dent_dnode(struct page *page)
+{
+	void *kaddr = page_address(page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	unsigned int flag = le32_to_cpu(rn->footer.flag);
+	return flag & (0x1 << DENT_BIT_SHIFT);
+}
+
+static inline void set_cold_node(struct inode *inode, struct page *page)
+{
+	struct f2fs_node *rn = (struct f2fs_node *)page_address(page);
+	unsigned int flag = le32_to_cpu(rn->footer.flag);
+
+	if (S_ISDIR(inode->i_mode))
+		flag &= ~(0x1 << COLD_BIT_SHIFT);
+	else
+		flag |= (0x1 << COLD_BIT_SHIFT);
+	rn->footer.flag = cpu_to_le32(flag);
+}
+
+static inline void set_fsync_mark(struct page *page, int mark)
+{
+	void *kaddr = page_address(page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	unsigned int flag = le32_to_cpu(rn->footer.flag);
+	if (mark)
+		flag |= (0x1 << FSYNC_BIT_SHIFT);
+	else
+		flag &= ~(0x1 << FSYNC_BIT_SHIFT);
+	rn->footer.flag = cpu_to_le32(flag);
+}
+
+static inline void set_dentry_mark(struct page *page, int mark)
+{
+	void *kaddr = page_address(page);
+	struct f2fs_node *rn = (struct f2fs_node *)kaddr;
+	unsigned int flag = le32_to_cpu(rn->footer.flag);
+	if (mark)
+		flag |= (0x1 << DENT_BIT_SHIFT);
+	else
+		flag &= ~(0x1 << DENT_BIT_SHIFT);
+	rn->footer.flag = cpu_to_le32(flag);
+}
