commit 7a88ddb56077d07257a5d0393a4be13e424ca755
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Feb 27 19:30:05 2020 +0800

    f2fs: fix inconsistent comments
    
    Lack of maintenance on comments may mislead developers, fix them.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index a467aca29cfe..d66de5999a26 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -58,7 +58,7 @@ unsigned long f2fs_shrink_count(struct shrinker *shrink,
 		/* count extent cache entries */
 		count += __count_extent_cache(sbi);
 
-		/* shrink clean nat cache entries */
+		/* count clean nat cache entries */
 		count += __count_nat_entries(sbi);
 
 		/* count free nids cache entries */

commit e4589fa545e0020dbbc3c9bde35f35f949901392
Author: Sahitya Tummala <stummala@codeaurora.org>
Date:   Tue Dec 18 16:39:24 2018 +0530

    f2fs: fix sbi->extent_list corruption issue
    
    When there is a failure in f2fs_fill_super() after/during
    the recovery of fsync'd nodes, it frees the current sbi and
    retries again. This time the mount is successful, but the files
    that got recovered before retry, still holds the extent tree,
    whose extent nodes list is corrupted since sbi and sbi->extent_list
    is freed up. The list_del corruption issue is observed when the
    file system is getting unmounted and when those recoverd files extent
    node is being freed up in the below context.
    
    list_del corruption. prev->next should be fffffff1e1ef5480, but was (null)
    <...>
    kernel BUG at kernel/msm-4.14/lib/list_debug.c:53!
    lr : __list_del_entry_valid+0x94/0xb4
    pc : __list_del_entry_valid+0x94/0xb4
    <...>
    Call trace:
    __list_del_entry_valid+0x94/0xb4
    __release_extent_node+0xb0/0x114
    __free_extent_tree+0x58/0x7c
    f2fs_shrink_extent_tree+0xdc/0x3b0
    f2fs_leave_shrinker+0x28/0x7c
    f2fs_put_super+0xfc/0x1e0
    generic_shutdown_super+0x70/0xf4
    kill_block_super+0x2c/0x5c
    kill_f2fs_super+0x44/0x50
    deactivate_locked_super+0x60/0x8c
    deactivate_super+0x68/0x74
    cleanup_mnt+0x40/0x78
    __cleanup_mnt+0x1c/0x28
    task_work_run+0x48/0xd0
    do_notify_resume+0x678/0xe98
    work_pending+0x8/0x14
    
    Fix this by not creating extents for those recovered files if shrinker is
    not registered yet. Once mount is successful and shrinker is registered,
    those files can have extents again.
    
    Signed-off-by: Sahitya Tummala <stummala@codeaurora.org>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index 9e13db994fdf..a467aca29cfe 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -135,6 +135,6 @@ void f2fs_leave_shrinker(struct f2fs_sb_info *sbi)
 	f2fs_shrink_extent_tree(sbi, __count_extent_cache(sbi));
 
 	spin_lock(&f2fs_list_lock);
-	list_del(&sbi->s_list);
+	list_del_init(&sbi->s_list);
 	spin_unlock(&f2fs_list_lock);
 }

commit 7c1a000d466235c875a989971cfda344e6bb1166
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Sep 12 09:16:07 2018 +0800

    f2fs: add SPDX license identifiers
    
    Remove the verbose license text from f2fs files and replace them with
    SPDX tags.  This does not change the license of any of the code.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index 36cfd816c160..9e13db994fdf 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -1,13 +1,10 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * f2fs shrinker support
  *   the basic infra was copied from fs/ubifs/shrinker.c
  *
  * Copyright (c) 2015 Motorola Mobility
  * Copyright (c) 2015 Jaegeuk Kim <jaegeuk@kernel.org>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 #include <linux/fs.h>
 #include <linux/f2fs_fs.h>

commit 4d57b86dd86404fd8bb4f87d277d5a86a7fe537e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed May 30 00:20:41 2018 +0800

    f2fs: clean up symbol namespace
    
    As Ted reported:
    
    "Hi, I was looking at f2fs's sources recently, and I noticed that there
    is a very large number of non-static symbols which don't have a f2fs
    prefix.  There's well over a hundred (see attached below).
    
    As one example, in fs/f2fs/dir.c there is:
    
    unsigned char get_de_type(struct f2fs_dir_entry *de)
    
    This function is clearly only useful for f2fs, but it has a generic
    name.  This means that if any other file system tries to have the same
    symbol name, there will be a symbol conflict and the kernel would not
    successfully build.  It also means that when someone is looking f2fs
    sources, it's not at all obvious whether a function such as
    read_data_page(), invalidate_blocks(), is a generic kernel function
    found in the fs, mm, or block layers, or a f2fs specific function.
    
    You might want to fix this at some point.  Hopefully Kent's bcachefs
    isn't similarly using genericly named functions, since that might
    cause conflicts with f2fs's functions --- but just as this would be a
    problem that we would rightly insist that Kent fix, this is something
    that we should have rightly insisted that f2fs should have fixed
    before it was integrated into the mainline kernel.
    
    acquire_orphan_inode
    add_ino_entry
    add_orphan_inode
    allocate_data_block
    allocate_new_segments
    alloc_nid
    alloc_nid_done
    alloc_nid_failed
    available_free_memory
    ...."
    
    This patch adds "f2fs_" prefix for all non-static symbols in order to:
    a) avoid conflict with other kernel generic symbols;
    b) to indicate the function is f2fs specific one instead of generic
    one;
    
    Reported-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index 0b5664a1a6cc..36cfd816c160 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -109,11 +109,11 @@ unsigned long f2fs_shrink_scan(struct shrinker *shrink,
 
 		/* shrink clean nat cache entries */
 		if (freed < nr)
-			freed += try_to_free_nats(sbi, nr - freed);
+			freed += f2fs_try_to_free_nats(sbi, nr - freed);
 
 		/* shrink free nids cache entries */
 		if (freed < nr)
-			freed += try_to_free_nids(sbi, nr - freed);
+			freed += f2fs_try_to_free_nids(sbi, nr - freed);
 
 		spin_lock(&f2fs_list_lock);
 		p = p->next;

commit 9a4ffdf55811ff3382cdf44459ec17521bd47e5e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Sep 29 13:59:35 2017 +0800

    f2fs: obsolete ALLOC_NID_LIST list
    
    As Fan Li reported, there is no user traversing nid_list[ALLOC_NID_LIST]
    which is used for tracking preallocated nids. Let's drop it, and only
    track preallocated nids in free_nid_root radix-tree.
    
    Reported-by: Fan Li <fanofcode.li@samsung.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index 5c60fc28ec75..0b5664a1a6cc 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -28,7 +28,7 @@ static unsigned long __count_nat_entries(struct f2fs_sb_info *sbi)
 
 static unsigned long __count_free_nids(struct f2fs_sb_info *sbi)
 {
-	long count = NM_I(sbi)->nid_cnt[FREE_NID_LIST] - MAX_FREE_NIDS;
+	long count = NM_I(sbi)->nid_cnt[FREE_NID] - MAX_FREE_NIDS;
 
 	return count > 0 ? count : 0;
 }

commit 02110a4fd53164db7cce3bb2780dce4d6c4e058f
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Oct 11 22:31:36 2016 +0800

    f2fs: avoid casted negative value as shrink count
    
    This patch makes sure it returns a positive value instead of a probable
    casted negative value as shrink count.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index ec539f407cc4..5c60fc28ec75 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -21,14 +21,16 @@ static unsigned int shrinker_run_no;
 
 static unsigned long __count_nat_entries(struct f2fs_sb_info *sbi)
 {
-	return NM_I(sbi)->nat_cnt - NM_I(sbi)->dirty_nat_cnt;
+	long count = NM_I(sbi)->nat_cnt - NM_I(sbi)->dirty_nat_cnt;
+
+	return count > 0 ? count : 0;
 }
 
 static unsigned long __count_free_nids(struct f2fs_sb_info *sbi)
 {
-	if (NM_I(sbi)->nid_cnt[FREE_NID_LIST] > MAX_FREE_NIDS)
-		return NM_I(sbi)->nid_cnt[FREE_NID_LIST] - MAX_FREE_NIDS;
-	return 0;
+	long count = NM_I(sbi)->nid_cnt[FREE_NID_LIST] - MAX_FREE_NIDS;
+
+	return count > 0 ? count : 0;
 }
 
 static unsigned long __count_extent_cache(struct f2fs_sb_info *sbi)

commit b8559dc242d1d47dcf99660a4d6afded727e0cc0
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Oct 12 19:28:29 2016 +0800

    f2fs: split free nid list
    
    During free nid allocation, in order to do preallocation, we will tag free
    nid entry as allocated one and still leave it in free nid list, for other
    allocators who want to grab free nids, it needs to traverse the free nid
    list for lookup. It becomes overhead in scenario of allocating free nid
    intensively by multithreads.
    
    This patch splits free nid list to two list: {free,alloc}_nid_list, to
    keep free nids and preallocated free nids separately, after that, traverse
    latency will be gone, besides split nid_cnt for separate statistic.
    
    Additionally, introduce __insert_nid_to_list and __remove_nid_from_list for
    cleanup.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: modify f2fs_bug_on to avoid needless branches]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index 46c915425923..ec539f407cc4 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -26,8 +26,8 @@ static unsigned long __count_nat_entries(struct f2fs_sb_info *sbi)
 
 static unsigned long __count_free_nids(struct f2fs_sb_info *sbi)
 {
-	if (NM_I(sbi)->fcnt > MAX_FREE_NIDS)
-		return NM_I(sbi)->fcnt - MAX_FREE_NIDS;
+	if (NM_I(sbi)->nid_cnt[FREE_NID_LIST] > MAX_FREE_NIDS)
+		return NM_I(sbi)->nid_cnt[FREE_NID_LIST] - MAX_FREE_NIDS;
 	return 0;
 }
 

commit ad4edb83143fdeef9e6fdd9daaa735b59476565b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jun 16 16:41:49 2016 -0700

    f2fs: produce more nids and reduce readahead nats
    
    The readahead nat pages are more likely to be reclaimed quickly, so it'd better
    to gather more free nids in advance.
    
    And, let's keep some free nids as much as possible.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index 93606f281bf9..46c915425923 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -13,6 +13,7 @@
 #include <linux/f2fs_fs.h>
 
 #include "f2fs.h"
+#include "node.h"
 
 static LIST_HEAD(f2fs_list);
 static DEFINE_SPINLOCK(f2fs_list_lock);
@@ -25,8 +26,8 @@ static unsigned long __count_nat_entries(struct f2fs_sb_info *sbi)
 
 static unsigned long __count_free_nids(struct f2fs_sb_info *sbi)
 {
-	if (NM_I(sbi)->fcnt > NAT_ENTRY_PER_BLOCK)
-		return NM_I(sbi)->fcnt - NAT_ENTRY_PER_BLOCK;
+	if (NM_I(sbi)->fcnt > MAX_FREE_NIDS)
+		return NM_I(sbi)->fcnt - MAX_FREE_NIDS;
 	return 0;
 }
 

commit 74fd8d9927ef08db30a85f131a124152aeba66c7
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Dec 21 19:25:50 2015 -0800

    f2fs: speed up shrinking extent tree entries
    
    If there is no candidates for shrinking slab entries, we don't need to traverse
    any trees at all.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    [Jaegeuk Kim: fix missing initialization reported by Yunlei He]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index a11e099cbddc..93606f281bf9 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -32,7 +32,7 @@ static unsigned long __count_free_nids(struct f2fs_sb_info *sbi)
 
 static unsigned long __count_extent_cache(struct f2fs_sb_info *sbi)
 {
-	return atomic_read(&sbi->total_ext_tree) +
+	return atomic_read(&sbi->total_zombie_tree) +
 				atomic_read(&sbi->total_ext_node);
 }
 

commit 7441ccef339f87abc27afc4ccfc24c014d7360c9
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Dec 21 19:20:15 2015 -0800

    f2fs: use atomic variable for total_extent_tree
    
    It would be better to use atomic variable for total_extent_tree.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index da0d8e0b55a5..a11e099cbddc 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -32,7 +32,8 @@ static unsigned long __count_free_nids(struct f2fs_sb_info *sbi)
 
 static unsigned long __count_extent_cache(struct f2fs_sb_info *sbi)
 {
-	return sbi->total_ext_tree + atomic_read(&sbi->total_ext_node);
+	return atomic_read(&sbi->total_ext_tree) +
+				atomic_read(&sbi->total_ext_node);
 }
 
 unsigned long f2fs_shrink_count(struct shrinker *shrink,

commit 31696580bf4c042a0f7b06d855e04441488d18b1
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Jul 28 18:33:46 2015 +0800

    f2fs: shrink free_nids entries
    
    This patch introduces __count_free_nids/try_to_free_nids and registers
    them in slab shrinker for shrinking under memory pressure.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index 9aa4235cd304..da0d8e0b55a5 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -23,6 +23,13 @@ static unsigned long __count_nat_entries(struct f2fs_sb_info *sbi)
 	return NM_I(sbi)->nat_cnt - NM_I(sbi)->dirty_nat_cnt;
 }
 
+static unsigned long __count_free_nids(struct f2fs_sb_info *sbi)
+{
+	if (NM_I(sbi)->fcnt > NAT_ENTRY_PER_BLOCK)
+		return NM_I(sbi)->fcnt - NAT_ENTRY_PER_BLOCK;
+	return 0;
+}
+
 static unsigned long __count_extent_cache(struct f2fs_sb_info *sbi)
 {
 	return sbi->total_ext_tree + atomic_read(&sbi->total_ext_node);
@@ -53,6 +60,9 @@ unsigned long f2fs_shrink_count(struct shrinker *shrink,
 		/* shrink clean nat cache entries */
 		count += __count_nat_entries(sbi);
 
+		/* count free nids cache entries */
+		count += __count_free_nids(sbi);
+
 		spin_lock(&f2fs_list_lock);
 		p = p->next;
 		mutex_unlock(&sbi->umount_mutex);
@@ -97,6 +107,10 @@ unsigned long f2fs_shrink_scan(struct shrinker *shrink,
 		if (freed < nr)
 			freed += try_to_free_nats(sbi, nr - freed);
 
+		/* shrink free nids cache entries */
+		if (freed < nr)
+			freed += try_to_free_nids(sbi, nr - freed);
+
 		spin_lock(&f2fs_list_lock);
 		p = p->next;
 		list_move_tail(&sbi->s_list, &f2fs_list);

commit 3e72f721390dc14e7b33fda812843c0725810106
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jun 19 17:53:26 2015 -0700

    f2fs: use extent_cache by default
    
    We don't need to handle the duplicate extent information.
    
    The integrated rule is:
     - update on-disk extent with largest one tracked by in-memory extent_cache
     - destroy extent_tree for the truncation case
     - drop per-inode extent_cache by shrinker
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index 1f0a131be3d2..9aa4235cd304 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -117,6 +117,8 @@ void f2fs_join_shrinker(struct f2fs_sb_info *sbi)
 
 void f2fs_leave_shrinker(struct f2fs_sb_info *sbi)
 {
+	f2fs_shrink_extent_tree(sbi, __count_extent_cache(sbi));
+
 	spin_lock(&f2fs_list_lock);
 	list_del(&sbi->s_list);
 	spin_unlock(&f2fs_list_lock);

commit 554df79e523d14dab475eb6650cb96617256ceea
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jun 19 13:41:23 2015 -0700

    f2fs: shrink extent_cache entries
    
    This patch registers shrinking extent_caches.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index c4bd6ee5936c..1f0a131be3d2 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -23,6 +23,11 @@ static unsigned long __count_nat_entries(struct f2fs_sb_info *sbi)
 	return NM_I(sbi)->nat_cnt - NM_I(sbi)->dirty_nat_cnt;
 }
 
+static unsigned long __count_extent_cache(struct f2fs_sb_info *sbi)
+{
+	return sbi->total_ext_tree + atomic_read(&sbi->total_ext_node);
+}
+
 unsigned long f2fs_shrink_count(struct shrinker *shrink,
 				struct shrink_control *sc)
 {
@@ -42,6 +47,9 @@ unsigned long f2fs_shrink_count(struct shrinker *shrink,
 		}
 		spin_unlock(&f2fs_list_lock);
 
+		/* count extent cache entries */
+		count += __count_extent_cache(sbi);
+
 		/* shrink clean nat cache entries */
 		count += __count_nat_entries(sbi);
 
@@ -82,8 +90,12 @@ unsigned long f2fs_shrink_scan(struct shrinker *shrink,
 
 		sbi->shrinker_run_no = run_no;
 
+		/* shrink extent cache entries */
+		freed += f2fs_shrink_extent_tree(sbi, nr >> 1);
+
 		/* shrink clean nat cache entries */
-		freed += try_to_free_nats(sbi, nr);
+		if (freed < nr)
+			freed += try_to_free_nats(sbi, nr - freed);
 
 		spin_lock(&f2fs_list_lock);
 		p = p->next;

commit 1b38dc8e74a366b92986755c304591e330f3c3e0
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jun 19 15:36:07 2015 -0700

    f2fs: shrink nat_cache entries
    
    This patch registers shrinking nat_cache entries.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
index 16e9b43635c2..c4bd6ee5936c 100644
--- a/fs/f2fs/shrinker.c
+++ b/fs/f2fs/shrinker.c
@@ -18,6 +18,11 @@ static LIST_HEAD(f2fs_list);
 static DEFINE_SPINLOCK(f2fs_list_lock);
 static unsigned int shrinker_run_no;
 
+static unsigned long __count_nat_entries(struct f2fs_sb_info *sbi)
+{
+	return NM_I(sbi)->nat_cnt - NM_I(sbi)->dirty_nat_cnt;
+}
+
 unsigned long f2fs_shrink_count(struct shrinker *shrink,
 				struct shrink_control *sc)
 {
@@ -37,7 +42,8 @@ unsigned long f2fs_shrink_count(struct shrinker *shrink,
 		}
 		spin_unlock(&f2fs_list_lock);
 
-		/* TODO: count # of objects */
+		/* shrink clean nat cache entries */
+		count += __count_nat_entries(sbi);
 
 		spin_lock(&f2fs_list_lock);
 		p = p->next;
@@ -76,7 +82,8 @@ unsigned long f2fs_shrink_scan(struct shrinker *shrink,
 
 		sbi->shrinker_run_no = run_no;
 
-		/* TODO: shrink caches */
+		/* shrink clean nat cache entries */
+		freed += try_to_free_nats(sbi, nr);
 
 		spin_lock(&f2fs_list_lock);
 		p = p->next;

commit 2658e50de61429f57d9496bfe371f232e2d039a1
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jun 19 12:01:21 2015 -0700

    f2fs: introduce a shrinker for mounted fs
    
    This patch introduces a shrinker targeting to reduce memory footprint consumed
    by a number of in-memory f2fs data structures.
    
    In addition, it newly adds:
     - sbi->umount_mutex to avoid data races on shrinker and put_super
     - sbi->shruinker_run_no to not revisit objects
    
    Note that the basic implementation was copied from fs/ubifs/shrinker.c
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/shrinker.c b/fs/f2fs/shrinker.c
new file mode 100644
index 000000000000..16e9b43635c2
--- /dev/null
+++ b/fs/f2fs/shrinker.c
@@ -0,0 +1,104 @@
+/*
+ * f2fs shrinker support
+ *   the basic infra was copied from fs/ubifs/shrinker.c
+ *
+ * Copyright (c) 2015 Motorola Mobility
+ * Copyright (c) 2015 Jaegeuk Kim <jaegeuk@kernel.org>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/fs.h>
+#include <linux/f2fs_fs.h>
+
+#include "f2fs.h"
+
+static LIST_HEAD(f2fs_list);
+static DEFINE_SPINLOCK(f2fs_list_lock);
+static unsigned int shrinker_run_no;
+
+unsigned long f2fs_shrink_count(struct shrinker *shrink,
+				struct shrink_control *sc)
+{
+	struct f2fs_sb_info *sbi;
+	struct list_head *p;
+	unsigned long count = 0;
+
+	spin_lock(&f2fs_list_lock);
+	p = f2fs_list.next;
+	while (p != &f2fs_list) {
+		sbi = list_entry(p, struct f2fs_sb_info, s_list);
+
+		/* stop f2fs_put_super */
+		if (!mutex_trylock(&sbi->umount_mutex)) {
+			p = p->next;
+			continue;
+		}
+		spin_unlock(&f2fs_list_lock);
+
+		/* TODO: count # of objects */
+
+		spin_lock(&f2fs_list_lock);
+		p = p->next;
+		mutex_unlock(&sbi->umount_mutex);
+	}
+	spin_unlock(&f2fs_list_lock);
+	return count;
+}
+
+unsigned long f2fs_shrink_scan(struct shrinker *shrink,
+				struct shrink_control *sc)
+{
+	unsigned long nr = sc->nr_to_scan;
+	struct f2fs_sb_info *sbi;
+	struct list_head *p;
+	unsigned int run_no;
+	unsigned long freed = 0;
+
+	spin_lock(&f2fs_list_lock);
+	do {
+		run_no = ++shrinker_run_no;
+	} while (run_no == 0);
+	p = f2fs_list.next;
+	while (p != &f2fs_list) {
+		sbi = list_entry(p, struct f2fs_sb_info, s_list);
+
+		if (sbi->shrinker_run_no == run_no)
+			break;
+
+		/* stop f2fs_put_super */
+		if (!mutex_trylock(&sbi->umount_mutex)) {
+			p = p->next;
+			continue;
+		}
+		spin_unlock(&f2fs_list_lock);
+
+		sbi->shrinker_run_no = run_no;
+
+		/* TODO: shrink caches */
+
+		spin_lock(&f2fs_list_lock);
+		p = p->next;
+		list_move_tail(&sbi->s_list, &f2fs_list);
+		mutex_unlock(&sbi->umount_mutex);
+		if (freed >= nr)
+			break;
+	}
+	spin_unlock(&f2fs_list_lock);
+	return freed;
+}
+
+void f2fs_join_shrinker(struct f2fs_sb_info *sbi)
+{
+	spin_lock(&f2fs_list_lock);
+	list_add_tail(&sbi->s_list, &f2fs_list);
+	spin_unlock(&f2fs_list_lock);
+}
+
+void f2fs_leave_shrinker(struct f2fs_sb_info *sbi)
+{
+	spin_lock(&f2fs_list_lock);
+	list_del(&sbi->s_list);
+	spin_unlock(&f2fs_list_lock);
+}
