commit 0b6d4ca04a86b9dababbb76e58d33c437e127b77
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Jun 4 21:57:48 2020 -0700

    f2fs: don't return vmalloc() memory from f2fs_kmalloc()
    
    kmalloc() returns kmalloc'ed memory, and kvmalloc() returns either
    kmalloc'ed or vmalloc'ed memory.  But the f2fs wrappers, f2fs_kmalloc()
    and f2fs_kvmalloc(), both return both kinds of memory.
    
    It's redundant to have two functions that do the same thing, and also
    breaking the standard naming convention is causing bugs since people
    assume it's safe to kfree() memory allocated by f2fs_kmalloc().  See
    e.g. the various allocations in fs/f2fs/compress.c.
    
    Fix this by making f2fs_kmalloc() just use kmalloc().  And to avoid
    re-introducing the allocation failures that the vmalloc fallback was
    intended to fix, convert the largest allocations to use f2fs_kvmalloc().
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3dc3ac6fe143..236064930251 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -895,8 +895,8 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	int i;
 	int err;
 
-	sbi->ckpt = f2fs_kzalloc(sbi, array_size(blk_size, cp_blks),
-				 GFP_KERNEL);
+	sbi->ckpt = f2fs_kvzalloc(sbi, array_size(blk_size, cp_blks),
+				  GFP_KERNEL);
 	if (!sbi->ckpt)
 		return -ENOMEM;
 	/*

commit 9c30df7c5a304e383592587cb2a41bb2ab0ac80d
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed May 13 21:12:53 2020 -0700

    f2fs: flush dirty meta pages when flushing them
    
    Let's guarantee flusing dirty meta pages to avoid infinite loop.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 620a386d82c1..3dc3ac6fe143 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1266,6 +1266,9 @@ void f2fs_wait_on_all_pages(struct f2fs_sb_info *sbi, int type)
 		if (unlikely(f2fs_cp_error(sbi)))
 			break;
 
+		if (type == F2FS_DIRTY_META)
+			f2fs_sync_meta_pages(sbi, META, LONG_MAX,
+							FS_CP_META_IO);
 		io_schedule_timeout(DEFAULT_IO_TIMEOUT);
 	}
 	finish_wait(&sbi->cp_wait, &wait);

commit b4b10061ef98c583bcf82a4200703fbaa98c18dc
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Mar 31 11:43:07 2020 -0700

    f2fs: refactor resize_fs to avoid meta updates in progress
    
    Sahitya raised an issue:
    - prevent meta updates while checkpoint is in progress
    
    allocate_segment_for_resize() can cause metapage updates if
    it requires to change the current node/data segments for resizing.
    Stop these meta updates when there is a checkpoint already
    in progress to prevent inconsistent CP data.
    
    Signed-off-by: Sahitya Tummala <stummala@codeaurora.org>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 79e605f38f4f..620a386d82c1 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1559,7 +1559,8 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 			return 0;
 		f2fs_warn(sbi, "Start checkpoint disabled!");
 	}
-	mutex_lock(&sbi->cp_mutex);
+	if (cpc->reason != CP_RESIZE)
+		mutex_lock(&sbi->cp_mutex);
 
 	if (!is_sbi_flag_set(sbi, SBI_IS_DIRTY) &&
 		((cpc->reason & CP_FASTBOOT) || (cpc->reason & CP_SYNC) ||
@@ -1628,7 +1629,8 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	f2fs_update_time(sbi, CP_TIME);
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish checkpoint");
 out:
-	mutex_unlock(&sbi->cp_mutex);
+	if (cpc->reason != CP_RESIZE)
+		mutex_unlock(&sbi->cp_mutex);
 	return err;
 }
 

commit 34c061ad85a2f5d5e9e3b045d72f3b211db6e282
Author: Sayali Lokhande <sayalil@codeaurora.org>
Date:   Thu Apr 30 16:28:29 2020 +0530

    f2fs: Avoid double lock for cp_rwsem during checkpoint
    
    There could be a scenario where f2fs_sync_node_pages gets
    called during checkpoint, which in turn tries to flush
    inline data and calls iput(). This results in deadlock as
    iput() tries to hold cp_rwsem, which is already held at the
    beginning by checkpoint->block_operations().
    
    Call stack :
    
    Thread A                Thread B
    f2fs_write_checkpoint()
    - block_operations(sbi)
     - f2fs_lock_all(sbi);
      - down_write(&sbi->cp_rwsem);
    
                            - open()
                             - igrab()
                            - write() write inline data
                            - unlink()
    - f2fs_sync_node_pages()
     - if (is_inline_node(page))
      - flush_inline_data()
       - ilookup()
         page = f2fs_pagecache_get_page()
         if (!page)
          goto iput_out;
         iput_out:
                            -close()
                            -iput()
           iput(inode);
           - f2fs_evict_inode()
            - f2fs_truncate_blocks()
             - f2fs_lock_op()
               - down_read(&sbi->cp_rwsem);
    
    Fixes: 2049d4fcb057 ("f2fs: avoid multiple node page writes due to inline_data")
    Signed-off-by: Sayali Lokhande <sayalil@codeaurora.org>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d49f7a01d8a2..79e605f38f4f 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1168,6 +1168,11 @@ static int block_operations(struct f2fs_sb_info *sbi)
 	};
 	int err = 0, cnt = 0;
 
+	/*
+	 * Let's flush inline_data in dirty node pages.
+	 */
+	f2fs_flush_inline_data(sbi);
+
 retry_flush_quotas:
 	f2fs_lock_all(sbi);
 	if (__need_flush_quota(sbi)) {

commit 1f5f11a3c41e2b23288b2769435a00f74e02496b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri May 8 12:25:45 2020 -0700

    f2fs: remove blk_plugging in block_operations
    
    blk_plugging doesn't seem to give any benefit.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5ba649e17c72..d49f7a01d8a2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1166,11 +1166,8 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		.nr_to_write = LONG_MAX,
 		.for_reclaim = 0,
 	};
-	struct blk_plug plug;
 	int err = 0, cnt = 0;
 
-	blk_start_plug(&plug);
-
 retry_flush_quotas:
 	f2fs_lock_all(sbi);
 	if (__need_flush_quota(sbi)) {
@@ -1198,7 +1195,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		f2fs_unlock_all(sbi);
 		err = f2fs_sync_dirty_inodes(sbi, DIR_INODE);
 		if (err)
-			goto out;
+			return err;
 		cond_resched();
 		goto retry_flush_quotas;
 	}
@@ -1214,7 +1211,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		f2fs_unlock_all(sbi);
 		err = f2fs_sync_inode_meta(sbi);
 		if (err)
-			goto out;
+			return err;
 		cond_resched();
 		goto retry_flush_quotas;
 	}
@@ -1230,7 +1227,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		if (err) {
 			up_write(&sbi->node_change);
 			f2fs_unlock_all(sbi);
-			goto out;
+			return err;
 		}
 		cond_resched();
 		goto retry_flush_nodes;
@@ -1242,8 +1239,6 @@ static int block_operations(struct f2fs_sb_info *sbi)
 	 */
 	__prepare_cp_block(sbi);
 	up_write(&sbi->node_change);
-out:
-	blk_finish_plug(&plug);
 	return err;
 }
 

commit 8b83ac81f4283ae3bd05c9a7e15dca721014dd03
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Apr 16 18:16:56 2020 +0800

    f2fs: support read iostat
    
    Adds to support accounting read IOs from userspace/kernel.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6be357c8e002..5ba649e17c72 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -86,6 +86,8 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 		return ERR_PTR(err);
 	}
 
+	f2fs_update_iostat(sbi, FS_META_READ_IO, F2FS_BLKSIZE);
+
 	lock_page(page);
 	if (unlikely(page->mapping != mapping)) {
 		f2fs_put_page(page, 1);
@@ -266,6 +268,9 @@ int f2fs_ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		fio.page = page;
 		err = f2fs_submit_page_bio(&fio);
 		f2fs_put_page(page, err ? 1 : 0);
+
+		if (!err)
+			f2fs_update_iostat(sbi, FS_META_READ_IO, F2FS_BLKSIZE);
 	}
 out:
 	blk_finish_plug(&plug);

commit ce4c638cdd52b302247434daed4c127f258d9860
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Apr 10 18:07:20 2020 +0800

    f2fs: fix to handle error path of f2fs_ra_meta_pages()
    
    In f2fs_ra_meta_pages(), if f2fs_submit_page_bio() failed, we need to
    unlock page, fix it.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 852890b72d6a..6be357c8e002 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -220,6 +220,7 @@ int f2fs_ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		.is_por = (type == META_POR),
 	};
 	struct blk_plug plug;
+	int err;
 
 	if (unlikely(type == META_POR))
 		fio.op_flags &= ~REQ_META;
@@ -263,8 +264,8 @@ int f2fs_ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		}
 
 		fio.page = page;
-		f2fs_submit_page_bio(&fio);
-		f2fs_put_page(page, 0);
+		err = f2fs_submit_page_bio(&fio);
+		f2fs_put_page(page, err ? 1 : 0);
 	}
 out:
 	blk_finish_plug(&plug);

commit c84ef3c5e65ccf99a7a91a4d731ebb5d6331a178
Author: Sahitya Tummala <stummala@codeaurora.org>
Date:   Tue Mar 3 19:59:26 2020 +0530

    f2fs: Add a new CP flag to help fsck fix resize SPO issues
    
    Add and set a new CP flag CP_RESIZEFS_FLAG during
    online resize FS to help fsck fix the metadata mismatch
    that may happen due to SPO during resize, where SB
    got updated but CP data couldn't be written yet.
    
    fsck errors -
    Info: CKPT version = 6ed7bccb
            Wrong user_block_count(2233856)
    [f2fs_do_mount:3365] Checkpoint is polluted
    
    Signed-off-by: Sahitya Tummala <stummala@codeaurora.org>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 46fc9c1542fe..852890b72d6a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1298,10 +1298,14 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	else
 		__clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 
-	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK) ||
-		is_sbi_flag_set(sbi, SBI_IS_RESIZEFS))
+	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK))
 		__set_ckpt_flags(ckpt, CP_FSCK_FLAG);
 
+	if (is_sbi_flag_set(sbi, SBI_IS_RESIZEFS))
+		__set_ckpt_flags(ckpt, CP_RESIZEFS_FLAG);
+	else
+		__clear_ckpt_flags(ckpt, CP_RESIZEFS_FLAG);
+
 	if (is_sbi_flag_set(sbi, SBI_CP_DISABLED))
 		__set_ckpt_flags(ckpt, CP_DISABLED_FLAG);
 	else

commit 5df7731f60c2a933695a68d732f8b39fca788de6
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Feb 17 17:45:44 2020 +0800

    f2fs: introduce DEFAULT_IO_TIMEOUT
    
    As Geert Uytterhoeven reported:
    
    for parameter HZ/50 in congestion_wait(BLK_RW_ASYNC, HZ/50);
    
    On some platforms, HZ can be less than 50, then unexpected 0 timeout
    jiffies will be set in congestion_wait().
    
    This patch introduces a macro DEFAULT_IO_TIMEOUT to wrap a determinate
    value with msecs_to_jiffies(20) to instead HZ/50 to avoid such issue.
    
    Quoted from Geert Uytterhoeven:
    
    "A timeout of HZ means 1 second.
    HZ/50 means 20 ms, but has the risk of being zero, if HZ < 50.
    
    If you want to use a timeout of 20 ms, you best use msecs_to_jiffies(20),
    as that takes care of the special cases, and never returns 0."
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0dea31f1ddad..46fc9c1542fe 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1260,7 +1260,7 @@ void f2fs_wait_on_all_pages(struct f2fs_sb_info *sbi, int type)
 		if (unlikely(f2fs_cp_error(sbi)))
 			break;
 
-		io_schedule_timeout(HZ/50);
+		io_schedule_timeout(DEFAULT_IO_TIMEOUT);
 	}
 	finish_wait(&sbi->cp_wait, &wait);
 }

commit 7a88ddb56077d07257a5d0393a4be13e424ca755
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Feb 27 19:30:05 2020 +0800

    f2fs: fix inconsistent comments
    
    Lack of maintenance on comments may mislead developers, fix them.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9c88fb3d255a..0dea31f1ddad 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -50,9 +50,6 @@ struct page *f2fs_grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return page;
 }
 
-/*
- * We guarantee no failure on the returned page.
- */
 static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 							bool is_meta)
 {
@@ -206,7 +203,7 @@ bool f2fs_is_valid_blkaddr(struct f2fs_sb_info *sbi,
 }
 
 /*
- * Readahead CP/NAT/SIT/SSA pages
+ * Readahead CP/NAT/SIT/SSA/POR pages
  */
 int f2fs_ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 							int type, bool sync)
@@ -898,7 +895,7 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 		return -ENOMEM;
 	/*
 	 * Finding out valid cp block involves read both
-	 * sets( cp pack1 and cp pack 2)
+	 * sets( cp pack 1 and cp pack 2)
 	 */
 	cp_start_blk_no = le32_to_cpu(fsb->cp_blkaddr);
 	cp1 = validate_checkpoint(sbi, cp_start_blk_no, &cp1_version);
@@ -1385,10 +1382,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* Flush all the NAT/SIT pages */
 	f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
 
-	/*
-	 * modify checkpoint
-	 * version number is already updated
-	 */
+	/* start to update checkpoint, cp ver is already updated previously */
 	ckpt->elapsed_time = cpu_to_le64(get_mtime(sbi, true));
 	ckpt->free_segment_count = cpu_to_le32(free_segments(sbi));
 	for (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {
@@ -1541,9 +1535,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	return unlikely(f2fs_cp_error(sbi)) ? -EIO : 0;
 }
 
-/*
- * We guarantee that this checkpoint procedure will not fail.
- */
 int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
@@ -1611,7 +1602,6 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	f2fs_flush_sit_entries(sbi, cpc);
 
-	/* unlock all the fs_lock[] in do_checkpoint() */
 	err = do_checkpoint(sbi, cpc);
 	if (err)
 		f2fs_release_discard_addrs(sbi);
@@ -1624,7 +1614,7 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (cpc->reason & CP_RECOVERY)
 		f2fs_notice(sbi, "checkpoint: version = %llx", ckpt_ver);
 
-	/* do checkpoint periodically */
+	/* update CP_TIME to trigger checkpoint periodically */
 	f2fs_update_time(sbi, CP_TIME);
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish checkpoint");
 out:

commit bf22c3cc8ce71454dddd772284773306a68031d8
Author: Sahitya Tummala <stummala@codeaurora.org>
Date:   Tue Feb 18 09:19:07 2020 +0530

    f2fs: fix the panic in do_checkpoint()
    
    There could be a scenario where f2fs_sync_meta_pages() will not
    ensure that all F2FS_DIRTY_META pages are submitted for IO. Thus,
    resulting in the below panic in do_checkpoint() -
    
    f2fs_bug_on(sbi, get_pages(sbi, F2FS_DIRTY_META) &&
                                    !f2fs_cp_error(sbi));
    
    This can happen in a low-memory condition, where shrinker could
    also be doing the writepage operation (stack shown below)
    at the same time when checkpoint is running on another core.
    
    schedule
    down_write
    f2fs_submit_page_write -> by this time, this page in page cache is tagged
                            as PAGECACHE_TAG_WRITEBACK and PAGECACHE_TAG_DIRTY
                            is cleared, due to which f2fs_sync_meta_pages()
                            cannot sync this page in do_checkpoint() path.
    f2fs_do_write_meta_page
    __f2fs_write_meta_page
    f2fs_write_meta_page
    shrink_page_list
    shrink_inactive_list
    shrink_node_memcg
    shrink_node
    kswapd
    
    Signed-off-by: Sahitya Tummala <stummala@codeaurora.org>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 44e84ac5c941..9c88fb3d255a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1250,20 +1250,20 @@ static void unblock_operations(struct f2fs_sb_info *sbi)
 	f2fs_unlock_all(sbi);
 }
 
-void f2fs_wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
+void f2fs_wait_on_all_pages(struct f2fs_sb_info *sbi, int type)
 {
 	DEFINE_WAIT(wait);
 
 	for (;;) {
 		prepare_to_wait(&sbi->cp_wait, &wait, TASK_UNINTERRUPTIBLE);
 
-		if (!get_pages(sbi, F2FS_WB_CP_DATA))
+		if (!get_pages(sbi, type))
 			break;
 
 		if (unlikely(f2fs_cp_error(sbi)))
 			break;
 
-		io_schedule_timeout(5*HZ);
+		io_schedule_timeout(HZ/50);
 	}
 	finish_wait(&sbi->cp_wait, &wait);
 }
@@ -1384,8 +1384,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* Flush all the NAT/SIT pages */
 	f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
-	f2fs_bug_on(sbi, get_pages(sbi, F2FS_DIRTY_META) &&
-					!f2fs_cp_error(sbi));
 
 	/*
 	 * modify checkpoint
@@ -1493,11 +1491,11 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* Here, we have one bio having CP pack except cp pack 2 page */
 	f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
-	f2fs_bug_on(sbi, get_pages(sbi, F2FS_DIRTY_META) &&
-					!f2fs_cp_error(sbi));
+	/* Wait for all dirty meta pages to be submitted for IO */
+	f2fs_wait_on_all_pages(sbi, F2FS_DIRTY_META);
 
 	/* wait for previous submitted meta pages writeback */
-	f2fs_wait_on_all_pages_writeback(sbi);
+	f2fs_wait_on_all_pages(sbi, F2FS_WB_CP_DATA);
 
 	/* flush all device cache */
 	err = f2fs_flush_device_cache(sbi);
@@ -1506,7 +1504,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* barrier and flush checkpoint cp pack 2 page if it can */
 	commit_checkpoint(sbi, ckpt, start_blk);
-	f2fs_wait_on_all_pages_writeback(sbi);
+	f2fs_wait_on_all_pages(sbi, F2FS_WB_CP_DATA);
 
 	/*
 	 * invalidate intermediate page cache borrowed from meta inode which are

commit 542989b6749b69e9de59a9d41a9ee9af7dbb1986
Author: Eric Biggers <ebiggers@google.com>
Date:   Mon Dec 9 12:00:55 2019 -0800

    f2fs: don't keep META_MAPPING pages used for moving verity file blocks
    
    META_MAPPING is used to move blocks for both encrypted and verity files.
    So the META_MAPPING invalidation condition in do_checkpoint() should
    consider verity too, not just encrypt.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ffdaba0c55d2..44e84ac5c941 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1509,10 +1509,10 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	f2fs_wait_on_all_pages_writeback(sbi);
 
 	/*
-	 * invalidate intermediate page cache borrowed from meta inode
-	 * which are used for migration of encrypted inode's blocks.
+	 * invalidate intermediate page cache borrowed from meta inode which are
+	 * used for migration of encrypted or verity inode's blocks.
 	 */
-	if (f2fs_sb_has_encrypt(sbi))
+	if (f2fs_sb_has_encrypt(sbi) || f2fs_sb_has_verity(sbi))
 		invalidate_mapping_pages(META_MAPPING(sbi),
 				MAIN_BLKADDR(sbi), MAX_BLKADDR(sbi) - 1);
 

commit c45d6002ff7a322022560e9b19ad867b01fec77f
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Nov 1 17:53:23 2019 +0800

    f2fs: show f2fs instance in printk_ratelimited
    
    As Eric mentioned, bare printk{,_ratelimited} won't show which
    filesystem instance these message is coming from, this patch tries
    to show fs instance with sb->s_id field in all places we missed
    before.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index a0eef95b9e0e..ffdaba0c55d2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -581,7 +581,7 @@ int f2fs_acquire_orphan_inode(struct f2fs_sb_info *sbi)
 
 	if (time_to_inject(sbi, FAULT_ORPHAN)) {
 		spin_unlock(&im->ino_lock);
-		f2fs_show_injection_info(FAULT_ORPHAN);
+		f2fs_show_injection_info(sbi, FAULT_ORPHAN);
 		return -ENOSPC;
 	}
 

commit db6ec53b7e0320c8fad27e9a816e50080154bd51
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed May 29 10:58:45 2019 -0700

    f2fs: add a rw_sem to cover quota flag changes
    
    Two paths to update quota and f2fs_lock_op:
    
    1.
     - lock_op
     |  - quota_update
     `- unlock_op
    
    2.
     - quota_update
     - lock_op
     `- unlock_op
    
    But, we need to make a transaction on quota_update + lock_op in #2 case.
    So, this patch introduces:
    1. lock_op
    2. down_write
    3. check __need_flush
    4. up_write
    5. if there is dirty quota entries, flush them
    6. otherwise, good to go
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2d23671d2034..a0eef95b9e0e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1133,17 +1133,24 @@ static void __prepare_cp_block(struct f2fs_sb_info *sbi)
 
 static bool __need_flush_quota(struct f2fs_sb_info *sbi)
 {
+	bool ret = false;
+
 	if (!is_journalled_quota(sbi))
 		return false;
-	if (is_sbi_flag_set(sbi, SBI_QUOTA_SKIP_FLUSH))
-		return false;
-	if (is_sbi_flag_set(sbi, SBI_QUOTA_NEED_REPAIR))
-		return false;
-	if (is_sbi_flag_set(sbi, SBI_QUOTA_NEED_FLUSH))
-		return true;
-	if (get_pages(sbi, F2FS_DIRTY_QDATA))
-		return true;
-	return false;
+
+	down_write(&sbi->quota_sem);
+	if (is_sbi_flag_set(sbi, SBI_QUOTA_SKIP_FLUSH)) {
+		ret = false;
+	} else if (is_sbi_flag_set(sbi, SBI_QUOTA_NEED_REPAIR)) {
+		ret = false;
+	} else if (is_sbi_flag_set(sbi, SBI_QUOTA_NEED_FLUSH)) {
+		clear_sbi_flag(sbi, SBI_QUOTA_NEED_FLUSH);
+		ret = true;
+	} else if (get_pages(sbi, F2FS_DIRTY_QDATA)) {
+		ret = true;
+	}
+	up_write(&sbi->quota_sem);
+	return ret;
 }
 
 /*
@@ -1162,26 +1169,22 @@ static int block_operations(struct f2fs_sb_info *sbi)
 	blk_start_plug(&plug);
 
 retry_flush_quotas:
+	f2fs_lock_all(sbi);
 	if (__need_flush_quota(sbi)) {
 		int locked;
 
 		if (++cnt > DEFAULT_RETRY_QUOTA_FLUSH_COUNT) {
 			set_sbi_flag(sbi, SBI_QUOTA_SKIP_FLUSH);
-			f2fs_lock_all(sbi);
+			set_sbi_flag(sbi, SBI_QUOTA_NEED_FLUSH);
 			goto retry_flush_dents;
 		}
-		clear_sbi_flag(sbi, SBI_QUOTA_NEED_FLUSH);
+		f2fs_unlock_all(sbi);
 
 		/* only failed during mount/umount/freeze/quotactl */
 		locked = down_read_trylock(&sbi->sb->s_umount);
 		f2fs_quota_sync(sbi->sb, -1);
 		if (locked)
 			up_read(&sbi->sb->s_umount);
-	}
-
-	f2fs_lock_all(sbi);
-	if (__need_flush_quota(sbi)) {
-		f2fs_unlock_all(sbi);
 		cond_resched();
 		goto retry_flush_quotas;
 	}
@@ -1203,12 +1206,6 @@ static int block_operations(struct f2fs_sb_info *sbi)
 	 */
 	down_write(&sbi->node_change);
 
-	if (__need_flush_quota(sbi)) {
-		up_write(&sbi->node_change);
-		f2fs_unlock_all(sbi);
-		goto retry_flush_quotas;
-	}
-
 	if (get_pages(sbi, F2FS_DIRTY_IMETA)) {
 		up_write(&sbi->node_change);
 		f2fs_unlock_all(sbi);

commit 10f966bbf521bb9b2e497bbca496a5141f4071d0
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Jun 20 11:36:14 2019 +0800

    f2fs: use generic EFSBADCRC/EFSCORRUPTED
    
    f2fs uses EFAULT as error number to indicate filesystem is corrupted
    all the time, but generic filesystems use EUCLEAN for such condition,
    we need to change to follow others.
    
    This patch adds two new macros as below to wrap more generic error
    code macros, and spread them in code.
    
    EFSBADCRC       EBADMSG         /* Bad CRC detected */
    EFSCORRUPTED    EUCLEAN         /* Filesystem is corrupted */
    
    Reported-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Acked-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index a5ae1ef1a6d0..2d23671d2034 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -890,6 +890,7 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	unsigned int cp_blks = 1 + __cp_payload(sbi);
 	block_t cp_blk_no;
 	int i;
+	int err;
 
 	sbi->ckpt = f2fs_kzalloc(sbi, array_size(blk_size, cp_blks),
 				 GFP_KERNEL);
@@ -917,6 +918,7 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	} else if (cp2) {
 		cur_page = cp2;
 	} else {
+		err = -EFSCORRUPTED;
 		goto fail_no_cp;
 	}
 
@@ -929,8 +931,10 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 		sbi->cur_cp_pack = 2;
 
 	/* Sanity checking of checkpoint */
-	if (f2fs_sanity_check_ckpt(sbi))
+	if (f2fs_sanity_check_ckpt(sbi)) {
+		err = -EFSCORRUPTED;
 		goto free_fail_no_cp;
+	}
 
 	if (cp_blks <= 1)
 		goto done;
@@ -944,8 +948,10 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 		unsigned char *ckpt = (unsigned char *)sbi->ckpt;
 
 		cur_page = f2fs_get_meta_page(sbi, cp_blk_no + i);
-		if (IS_ERR(cur_page))
+		if (IS_ERR(cur_page)) {
+			err = PTR_ERR(cur_page);
 			goto free_fail_no_cp;
+		}
 		sit_bitmap_ptr = page_address(cur_page);
 		memcpy(ckpt + i * blk_size, sit_bitmap_ptr, blk_size);
 		f2fs_put_page(cur_page, 1);
@@ -960,7 +966,7 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	f2fs_put_page(cp2, 1);
 fail_no_cp:
 	kvfree(sbi->ckpt);
-	return -EINVAL;
+	return err;
 }
 
 static void __add_dirty_inode(struct inode *inode, enum inode_type type)

commit dcbb4c10e6d9693cc9d6fa493b4d130b66a60c7d
Author: Joe Perches <joe@perches.com>
Date:   Tue Jun 18 17:48:42 2019 +0800

    f2fs: introduce f2fs_<level> macros to wrap f2fs_printk()
    
    - Add and use f2fs_<level> macros
    - Convert f2fs_msg to f2fs_printk
    - Remove level from f2fs_printk and embed the level in the format
    - Coalesce formats and align multi-line arguments
    - Remove unnecessary duplicate extern f2fs_msg f2fs.h
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7b4a0fd59512..a5ae1ef1a6d0 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -146,8 +146,8 @@ static bool __is_bitmap_valid(struct f2fs_sb_info *sbi, block_t blkaddr,
 
 	exist = f2fs_test_bit(offset, se->cur_valid_map);
 	if (!exist && type == DATA_GENERIC_ENHANCE) {
-		f2fs_msg(sbi->sb, KERN_ERR, "Inconsistent error "
-			"blkaddr:%u, sit bitmap:%d", blkaddr, exist);
+		f2fs_err(sbi, "Inconsistent error blkaddr:%u, sit bitmap:%d",
+			 blkaddr, exist);
 		set_sbi_flag(sbi, SBI_NEED_FSCK);
 		WARN_ON(1);
 	}
@@ -184,8 +184,8 @@ bool f2fs_is_valid_blkaddr(struct f2fs_sb_info *sbi,
 	case DATA_GENERIC_ENHANCE_READ:
 		if (unlikely(blkaddr >= MAX_BLKADDR(sbi) ||
 				blkaddr < MAIN_BLKADDR(sbi))) {
-			f2fs_msg(sbi->sb, KERN_WARNING,
-				"access invalid blkaddr:%u", blkaddr);
+			f2fs_warn(sbi, "access invalid blkaddr:%u",
+				  blkaddr);
 			set_sbi_flag(sbi, SBI_NEED_FSCK);
 			WARN_ON(1);
 			return false;
@@ -657,9 +657,8 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 
 err_out:
 	set_sbi_flag(sbi, SBI_NEED_FSCK);
-	f2fs_msg(sbi->sb, KERN_WARNING,
-			"%s: orphan failed (ino=%x), run fsck to fix.",
-			__func__, ino);
+	f2fs_warn(sbi, "%s: orphan failed (ino=%x), run fsck to fix.",
+		  __func__, ino);
 	return err;
 }
 
@@ -676,13 +675,12 @@ int f2fs_recover_orphan_inodes(struct f2fs_sb_info *sbi)
 		return 0;
 
 	if (bdev_read_only(sbi->sb->s_bdev)) {
-		f2fs_msg(sbi->sb, KERN_INFO, "write access "
-			"unavailable, skipping orphan cleanup");
+		f2fs_info(sbi, "write access unavailable, skipping orphan cleanup");
 		return 0;
 	}
 
 	if (s_flags & SB_RDONLY) {
-		f2fs_msg(sbi->sb, KERN_INFO, "orphan cleanup on readonly fs");
+		f2fs_info(sbi, "orphan cleanup on readonly fs");
 		sbi->sb->s_flags &= ~SB_RDONLY;
 	}
 
@@ -827,15 +825,14 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 	if (crc_offset < CP_MIN_CHKSUM_OFFSET ||
 			crc_offset > CP_CHKSUM_OFFSET) {
 		f2fs_put_page(*cp_page, 1);
-		f2fs_msg(sbi->sb, KERN_WARNING,
-			"invalid crc_offset: %zu", crc_offset);
+		f2fs_warn(sbi, "invalid crc_offset: %zu", crc_offset);
 		return -EINVAL;
 	}
 
 	crc = f2fs_checkpoint_chksum(sbi, *cp_block);
 	if (crc != cur_cp_crc(*cp_block)) {
 		f2fs_put_page(*cp_page, 1);
-		f2fs_msg(sbi->sb, KERN_WARNING, "invalid crc value");
+		f2fs_warn(sbi, "invalid crc value");
 		return -EINVAL;
 	}
 
@@ -858,9 +855,8 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 
 	if (le32_to_cpu(cp_block->cp_pack_total_block_count) >
 					sbi->blocks_per_seg) {
-		f2fs_msg(sbi->sb, KERN_WARNING,
-			"invalid cp_pack_total_block_count:%u",
-			le32_to_cpu(cp_block->cp_pack_total_block_count));
+		f2fs_warn(sbi, "invalid cp_pack_total_block_count:%u",
+			  le32_to_cpu(cp_block->cp_pack_total_block_count));
 		goto invalid_cp;
 	}
 	pre_version = *version;
@@ -1559,8 +1555,7 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (unlikely(is_sbi_flag_set(sbi, SBI_CP_DISABLED))) {
 		if (cpc->reason != CP_PAUSE)
 			return 0;
-		f2fs_msg(sbi->sb, KERN_WARNING,
-				"Start checkpoint disabled!");
+		f2fs_warn(sbi, "Start checkpoint disabled!");
 	}
 	mutex_lock(&sbi->cp_mutex);
 
@@ -1626,8 +1621,7 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	stat_inc_cp_count(sbi->stat_info);
 
 	if (cpc->reason & CP_RECOVERY)
-		f2fs_msg(sbi->sb, KERN_NOTICE,
-			"checkpoint: version = %llx", ckpt_ver);
+		f2fs_notice(sbi, "checkpoint: version = %llx", ckpt_ver);
 
 	/* do checkpoint periodically */
 	f2fs_update_time(sbi, CP_TIME);

commit 04f0b2eaa3b3ee243df6040617b4bfbbc0404854
Author: Qiuyang Sun <sunqiuyang@huawei.com>
Date:   Wed Jun 5 11:33:25 2019 +0800

    f2fs: ioctl for removing a range from F2FS
    
    This ioctl shrinks a given length (aligned to sections) from end of the
    main area. Any cursegs and valid blocks will be moved out before
    invalidating the range.
    
    This feature can be used for adjusting partition sizes online.
    
    History of the patch:
    
    Sahitya Tummala:
     - Add this ioctl for f2fs_compat_ioctl() as well.
     - Fix debugfs status to reflect the online resize changes.
     - Fix potential race between online resize path and allocate new data
       block path or gc path.
    
    Others:
     - Rename some identifiers.
     - Add some error handling branches.
     - Clear sbi->next_victim_seg[BG_GC/FG_GC] in shrinking range.
     - Implement this interface as ext4's, and change the parameter from shrunk
    bytes to new block count of F2FS.
     - During resizing, force to empty sit_journal and forbid adding new
       entries to it, in order to avoid invalid segno in journal after resize.
     - Reduce sbi->user_block_count before resize starts.
     - Commit the updated superblock first, and then update in-memory metadata
       only when the former succeeds.
     - Target block count must align to sections.
     - Write checkpoint before and after committing the new superblock, w/o
    CP_FSCK_FLAG respectively, so that the FS can be fixed by fsck even if
    resize fails after the new superblock is committed.
     - In free_segment_range(), reduce granularity of gc_mutex.
     - Add protection on curseg migration.
     - Add freeze_bdev() and thaw_bdev() for resize fs.
     - Remove CUR_MAIN_SECS and use MAIN_SECS directly for allocation.
     - Recover super_block and FS metadata when resize fails.
     - No need to clear CP_FSCK_FLAG in update_ckpt_flags().
     - Clean up the sb and fs metadata update functions for resize_fs.
    
    Geert Uytterhoeven:
     - Use div_u64*() for 64-bit divisions
    
    Arnd Bergmann:
     - Not all architectures support get_user() with a 64-bit argument:
        ERROR: "__get_user_bad" [fs/f2fs/f2fs.ko] undefined!
        Use copy_from_user() here, this will always work.
    
    Signed-off-by: Qiuyang Sun <sunqiuyang@huawei.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Sahitya Tummala <stummala@codeaurora.org>
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 89825261d474..7b4a0fd59512 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1302,7 +1302,8 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	else
 		__clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 
-	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK))
+	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK) ||
+		is_sbi_flag_set(sbi, SBI_IS_RESIZEFS))
 		__set_ckpt_flags(ckpt, CP_FSCK_FLAG);
 
 	if (is_sbi_flag_set(sbi, SBI_CP_DISABLED))

commit 5dae2d39074dde941cc3150dcbb7840d88179743
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon May 20 10:09:22 2019 +0800

    f2fs: fix to check layout on last valid checkpoint park
    
    As Ju Hyung reported:
    
    "
    I was semi-forced today to use the new kernel and test f2fs.
    
    My Ubuntu initramfs got a bit wonky and I had to boot into live CD and
    fix some stuffs. The live CD was using 4.15 kernel, and just mounting
    the f2fs partition there corrupted f2fs and my 4.19(with 5.1-rc1-4.19
    f2fs-stable merged) refused to mount with "SIT is corrupted node"
    message.
    
    I used the latest f2fs-tools sent by Chao including "fsck.f2fs: fix to
    repair cp_loads blocks at correct position"
    
    It spit out 140M worth of output, but at least I didn't have to run it
    twice. Everything returned "Ok" in the 2nd run.
    The new log is at
    http://arter97.com/f2fs/final
    
    After fixing the image, I used my 4.19 kernel with 5.2-rc1-4.19
    f2fs-stable merged and it mounted.
    
    But, I got this:
    [    1.047791] F2FS-fs (nvme0n1p3): layout of large_nat_bitmap is
    deprecated, run fsck to repair, chksum_offset: 4092
    [    1.081307] F2FS-fs (nvme0n1p3): Found nat_bits in checkpoint
    [    1.161520] F2FS-fs (nvme0n1p3): recover fsync data on readonly fs
    [    1.162418] F2FS-fs (nvme0n1p3): Mounted with checkpoint version = 761c7e00
    
    But after doing a reboot, the message is gone:
    [    1.098423] F2FS-fs (nvme0n1p3): Found nat_bits in checkpoint
    [    1.177771] F2FS-fs (nvme0n1p3): recover fsync data on readonly fs
    [    1.178365] F2FS-fs (nvme0n1p3): Mounted with checkpoint version = 761c7eda
    
    I'm not exactly sure why the kernel detected that I'm still using the
    old layout on the first boot. Maybe fsck didn't fix it properly, or
    the check from the kernel is improper.
    "
    
    Although we have rebuild the old deprecated checkpoint with new layout
    during repair, we only repair last checkpoint park, the other old one is
    remained.
    
    Once the image was mounted, we will 1) sanity check layout and 2) decide
    which checkpoint park to use according to cp_ver. So that we will print
    reported message unnecessarily at step 1), to avoid it, we simply move
    layout check into f2fs_sanity_check_ckpt() after step 2).
    
    Reported-by: Park Ju Hyung <qkrwngud825@gmail.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9c07b71037ee..89825261d474 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -832,17 +832,6 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 		return -EINVAL;
 	}
 
-	if (__is_set_ckpt_flags(*cp_block, CP_LARGE_NAT_BITMAP_FLAG)) {
-		if (crc_offset != CP_MIN_CHKSUM_OFFSET) {
-			f2fs_put_page(*cp_page, 1);
-			f2fs_msg(sbi->sb, KERN_WARNING,
-				"layout of large_nat_bitmap is deprecated, "
-				"run fsck to repair, chksum_offset: %zu",
-				crc_offset);
-			return -EINVAL;
-		}
-	}
-
 	crc = f2fs_checkpoint_chksum(sbi, *cp_block);
 	if (crc != cur_cp_crc(*cp_block)) {
 		f2fs_put_page(*cp_page, 1);

commit bc88ac96a9acff450f612b7a21dc934005683187
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon May 20 16:17:56 2019 -0700

    f2fs: link f2fs quota ops for sysfile
    
    This patch reverts:
    commit fb40d618b039 ("f2fs: don't clear CP_QUOTA_NEED_FSCK_FLAG").
    
    We were missing error handlers used in f2fs quota ops.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ed70b68b2b38..9c07b71037ee 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1328,10 +1328,8 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	if (is_sbi_flag_set(sbi, SBI_QUOTA_SKIP_FLUSH))
 		__set_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);
-	/*
-	 * TODO: we count on fsck.f2fs to clear this flag until we figure out
-	 * missing cases which clear it incorrectly.
-	 */
+	else
+		__clear_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);
 
 	if (is_sbi_flag_set(sbi, SBI_QUOTA_NEED_REPAIR))
 		__set_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);

commit c9c8ed50d94c613fc3f4917c51e9c75d493a312e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sun May 5 11:40:46 2019 +0800

    f2fs: fix to avoid potential race on sbi->unusable_block_count access/update
    
    Use sbi.stat_lock to protect sbi->unusable_block_count accesss/udpate, in
    order to avoid potential race on it.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 805a33088e82..ed70b68b2b38 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1536,7 +1536,11 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 	clear_sbi_flag(sbi, SBI_NEED_CP);
 	clear_sbi_flag(sbi, SBI_QUOTA_SKIP_FLUSH);
+
+	spin_lock(&sbi->stat_lock);
 	sbi->unusable_block_count = 0;
+	spin_unlock(&sbi->stat_lock);
+
 	__set_cp_next_pack(sbi);
 
 	/*

commit 93770ab7a6e963147a5dbca25278b69ba6c8f8c5
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Apr 15 15:26:32 2019 +0800

    f2fs: introduce DATA_GENERIC_ENHANCE
    
    Previously, f2fs_is_valid_blkaddr(, blkaddr, DATA_GENERIC) will check
    whether @blkaddr locates in main area or not.
    
    That check is weak, since the block address in range of main area can
    point to the address which is not valid in segment info table, and we
    can not detect such condition, we may suffer worse corruption as system
    continues running.
    
    So this patch introduce DATA_GENERIC_ENHANCE to enhance the sanity check
    which trigger SIT bitmap check rather than only range check.
    
    This patch did below changes as wel:
    - set SBI_NEED_FSCK in f2fs_is_valid_blkaddr().
    - get rid of is_valid_data_blkaddr() to avoid panic if blkaddr is invalid.
    - introduce verify_fio_blkaddr() to wrap fio {new,old}_blkaddr validation check.
    - spread blkaddr check in:
     * f2fs_get_node_info()
     * __read_out_blkaddrs()
     * f2fs_submit_page_read()
     * ra_data_block()
     * do_recover_data()
    
    This patch can fix bug reported from bugzilla below:
    
    https://bugzilla.kernel.org/show_bug.cgi?id=203215
    https://bugzilla.kernel.org/show_bug.cgi?id=203223
    https://bugzilla.kernel.org/show_bug.cgi?id=203231
    https://bugzilla.kernel.org/show_bug.cgi?id=203235
    https://bugzilla.kernel.org/show_bug.cgi?id=203241
    
    = Update by Jaegeuk Kim =
    
    DATA_GENERIC_ENHANCE enhanced to validate block addresses on read/write paths.
    But, xfstest/generic/446 compalins some generated kernel messages saying invalid
    bitmap was detected when reading a block. The reaons is, when we get the
    block addresses from extent_cache, there is no lock to synchronize it from
    truncating the blocks in parallel.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b8614cf77cdd..805a33088e82 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -130,6 +130,30 @@ struct page *f2fs_get_tmp_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return __get_meta_page(sbi, index, false);
 }
 
+static bool __is_bitmap_valid(struct f2fs_sb_info *sbi, block_t blkaddr,
+							int type)
+{
+	struct seg_entry *se;
+	unsigned int segno, offset;
+	bool exist;
+
+	if (type != DATA_GENERIC_ENHANCE && type != DATA_GENERIC_ENHANCE_READ)
+		return true;
+
+	segno = GET_SEGNO(sbi, blkaddr);
+	offset = GET_BLKOFF_FROM_SEG0(sbi, blkaddr);
+	se = get_seg_entry(sbi, segno);
+
+	exist = f2fs_test_bit(offset, se->cur_valid_map);
+	if (!exist && type == DATA_GENERIC_ENHANCE) {
+		f2fs_msg(sbi->sb, KERN_ERR, "Inconsistent error "
+			"blkaddr:%u, sit bitmap:%d", blkaddr, exist);
+		set_sbi_flag(sbi, SBI_NEED_FSCK);
+		WARN_ON(1);
+	}
+	return exist;
+}
+
 bool f2fs_is_valid_blkaddr(struct f2fs_sb_info *sbi,
 					block_t blkaddr, int type)
 {
@@ -151,15 +175,22 @@ bool f2fs_is_valid_blkaddr(struct f2fs_sb_info *sbi,
 			return false;
 		break;
 	case META_POR:
+		if (unlikely(blkaddr >= MAX_BLKADDR(sbi) ||
+			blkaddr < MAIN_BLKADDR(sbi)))
+			return false;
+		break;
 	case DATA_GENERIC:
+	case DATA_GENERIC_ENHANCE:
+	case DATA_GENERIC_ENHANCE_READ:
 		if (unlikely(blkaddr >= MAX_BLKADDR(sbi) ||
-			blkaddr < MAIN_BLKADDR(sbi))) {
-			if (type == DATA_GENERIC) {
-				f2fs_msg(sbi->sb, KERN_WARNING,
-					"access invalid blkaddr:%u", blkaddr);
-				WARN_ON(1);
-			}
+				blkaddr < MAIN_BLKADDR(sbi))) {
+			f2fs_msg(sbi->sb, KERN_WARNING,
+				"access invalid blkaddr:%u", blkaddr);
+			set_sbi_flag(sbi, SBI_NEED_FSCK);
+			WARN_ON(1);
 			return false;
+		} else {
+			return __is_bitmap_valid(sbi, blkaddr, type);
 		}
 		break;
 	case META_GENERIC:

commit f5a131bb236d0283436842f0b07d23d401b2811d
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Apr 22 20:22:38 2019 +0800

    f2fs: fix to be aware of readonly device in write_checkpoint()
    
    As Park Ju Hyung reported:
    
    Probably unrelated but a similar issue:
    Warning appears upon unmounting a corrupted R/O f2fs loop image.
    
    Should be a trivial issue to fix as well :)
    
    [ 2373.758424] ------------[ cut here ]------------
    [ 2373.758428] generic_make_request: Trying to write to read-only
    block-device loop1 (partno 0)
    [ 2373.758455] WARNING: CPU: 1 PID: 13950 at block/blk-core.c:2174
    generic_make_request_checks+0x590/0x630
    [ 2373.758556] CPU: 1 PID: 13950 Comm: umount Tainted: G           O
       4.19.35-zen+ #1
    [ 2373.758558] Hardware name: System manufacturer System Product
    Name/ROG MAXIMUS X HERO (WI-FI AC), BIOS 1704 09/14/2018
    [ 2373.758564] RIP: 0010:generic_make_request_checks+0x590/0x630
    [ 2373.758567] Code: 5c 03 00 00 48 8d 74 24 08 48 89 df c6 05 b5 cd
    36 01 01 e8 c2 90 01 00 48 89 c6 44 89 ea 48 c7 c7 98 64 59 82 e8 d5
    9b a7 ff <0f> 0b 48 8b 7b 08 e9 f2 fa ff ff 41 8b 86 98 02 00 00 49 8b
    16 89
    [ 2373.758570] RSP: 0018:ffff8882bdb43950 EFLAGS: 00010282
    [ 2373.758573] RAX: 0000000000000050 RBX: ffff8887244c6700 RCX: 0000000000000006
    [ 2373.758575] RDX: 0000000000000007 RSI: 0000000000000086 RDI: ffff88884ec56340
    [ 2373.758577] RBP: ffff888849c426c0 R08: 0000000000000004 R09: 00000000000003ba
    [ 2373.758579] R10: 0000000000000001 R11: 0000000000000029 R12: 0000000000001000
    [ 2373.758581] R13: 0000000000000000 R14: ffff888844a2e800 R15: ffff8882bdb43ac0
    [ 2373.758584] FS:  00007fc0d114f8c0(0000) GS:ffff88884ec40000(0000)
    knlGS:0000000000000000
    [ 2373.758586] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 2373.758588] CR2: 00007fc0d1ad12c0 CR3: 00000002bdb82003 CR4: 00000000003606e0
    [ 2373.758590] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 2373.758592] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 2373.758593] Call Trace:
    [ 2373.758602]  ? generic_make_request+0x46/0x3d0
    [ 2373.758608]  ? wait_woken+0x80/0x80
    [ 2373.758612]  ? mempool_alloc+0xb7/0x1a0
    [ 2373.758618]  ? submit_bio+0x30/0x110
    [ 2373.758622]  ? bvec_alloc+0x7c/0xd0
    [ 2373.758628]  ? __submit_merged_bio+0x68/0x390
    [ 2373.758633]  ? f2fs_submit_page_write+0x1bb/0x7f0
    [ 2373.758638]  ? f2fs_do_write_meta_page+0x7f/0x160
    [ 2373.758642]  ? __f2fs_write_meta_page+0x70/0x140
    [ 2373.758647]  ? f2fs_sync_meta_pages+0x140/0x250
    [ 2373.758653]  ? f2fs_write_checkpoint+0x5c5/0x17b0
    [ 2373.758657]  ? f2fs_sync_fs+0x9c/0x110
    [ 2373.758664]  ? sync_filesystem+0x66/0x80
    [ 2373.758667]  ? generic_shutdown_super+0x1d/0x100
    [ 2373.758670]  ? kill_block_super+0x1c/0x40
    [ 2373.758674]  ? kill_f2fs_super+0x64/0xb0
    [ 2373.758678]  ? deactivate_locked_super+0x2d/0xb0
    [ 2373.758682]  ? cleanup_mnt+0x65/0xa0
    [ 2373.758688]  ? task_work_run+0x7f/0xa0
    [ 2373.758693]  ? exit_to_usermode_loop+0x9c/0xa0
    [ 2373.758698]  ? do_syscall_64+0xc7/0xf0
    [ 2373.758703]  ? entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [ 2373.758706] ---[ end trace 5d3639907c56271b ]---
    [ 2373.758780] print_req_error: I/O error, dev loop1, sector 143048
    [ 2373.758800] print_req_error: I/O error, dev loop1, sector 152200
    [ 2373.758808] print_req_error: I/O error, dev loop1, sector 8192
    [ 2373.758819] print_req_error: I/O error, dev loop1, sector 12272
    
    This patch adds to detect readonly device in write_checkpoint() to avoid
    trigger write IOs on it.
    
    Reported-by: Park Ju Hyung <qkrwngud825@gmail.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 1982fc7c1eea..b8614cf77cdd 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1530,6 +1530,9 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	unsigned long long ckpt_ver;
 	int err = 0;
 
+	if (f2fs_readonly(sbi->sb) || f2fs_hw_is_readonly(sbi))
+		return -EROFS;
+
 	if (unlikely(is_sbi_flag_set(sbi, SBI_CP_DISABLED))) {
 		if (cpc->reason != CP_PAUSE)
 			return 0;
@@ -1546,10 +1549,6 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		err = -EIO;
 		goto out;
 	}
-	if (f2fs_readonly(sbi->sb)) {
-		err = -EROFS;
-		goto out;
-	}
 
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "start block_ops");
 

commit b61af314c9b8c81016db373fa3bfc1d901feebfd
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Apr 22 20:22:37 2019 +0800

    f2fs: fix to skip recovery on readonly device
    
    As Park Ju Hyung reported in mailing list:
    
    https://sourceforge.net/p/linux-f2fs/mailman/message/36639787/
    
    generic_make_request: Trying to write to read-only block-device loop0 (partno 0)
    WARNING: CPU: 0 PID: 23437 at block/blk-core.c:2174 generic_make_request_checks+0x594/0x630
    
     generic_make_request+0x46/0x3d0
     submit_bio+0x30/0x110
     __submit_merged_bio+0x68/0x390
     f2fs_submit_page_write+0x1bb/0x7f0
     f2fs_do_write_meta_page+0x7f/0x160
     __f2fs_write_meta_page+0x70/0x140
     f2fs_sync_meta_pages+0x140/0x250
     f2fs_write_checkpoint+0x5c5/0x17b0
     f2fs_sync_fs+0x9c/0x110
     sync_filesystem+0x66/0x80
     f2fs_recover_fsync_data+0x790/0xa30
     f2fs_fill_super+0xe4e/0x1980
     mount_bdev+0x518/0x610
     mount_fs+0x34/0x13f
     vfs_kern_mount.part.11+0x4f/0x120
     do_mount+0x2d1/0xe40
     __x64_sys_mount+0xbf/0xe0
     do_syscall_64+0x4a/0xf0
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    print_req_error: I/O error, dev loop0, sector 4096
    
    If block device is readonly, we should never trigger write IO from
    filesystem layer, but previously, orphan and journal recovery didn't
    consider such condition, result in triggering above warning, fix it.
    
    Reported-by: Park Ju Hyung <qkrwngud825@gmail.com>
    Tested-by: Park Ju Hyung <qkrwngud825@gmail.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d52a15799488..1982fc7c1eea 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -644,6 +644,12 @@ int f2fs_recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	if (!is_set_ckpt_flags(sbi, CP_ORPHAN_PRESENT_FLAG))
 		return 0;
 
+	if (bdev_read_only(sbi->sb->s_bdev)) {
+		f2fs_msg(sbi->sb, KERN_INFO, "write access "
+			"unavailable, skipping orphan cleanup");
+		return 0;
+	}
+
 	if (s_flags & SB_RDONLY) {
 		f2fs_msg(sbi->sb, KERN_INFO, "orphan cleanup on readonly fs");
 		sbi->sb->s_flags &= ~SB_RDONLY;

commit b471eb99e64495a1f0e430da3f96b88f600d3bb5
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Apr 22 17:33:53 2019 +0800

    f2fs: relocate chksum_offset for large_nat_bitmap feature
    
    For large_nat_bitmap feature, there is a design flaw:
    
    Previous:
    
    struct f2fs_checkpoint layout:
    +--------------------------+  0x0000
    | checkpoint_ver           |
    | ......                   |
    | checksum_offset          |------+
    | ......                   |      |
    | sit_nat_version_bitmap[] |<-----|-------+
    | ......                   |      |       |
    | checksum_value           |<-----+       |
    +--------------------------+  0x1000      |
    |                          |      nat_bitmap + sit_bitmap
    | payload blocks           |              |
    |                          |              |
    +--------------------------|<-------------+
    
    Obviously, if nat_bitmap size + sit_bitmap size is larger than
    MAX_BITMAP_SIZE_IN_CKPT, nat_bitmap or sit_bitmap may overlap
    checkpoint checksum's position, once checkpoint() is triggered
    from kernel, nat or sit bitmap will be damaged by checksum field.
    
    In order to fix this, let's relocate checksum_value's position
    to the head of sit_nat_version_bitmap as below, then nat/sit
    bitmap and chksum value update will become safe.
    
    After:
    
    struct f2fs_checkpoint layout:
    +--------------------------+  0x0000
    | checkpoint_ver           |
    | ......                   |
    | checksum_offset          |------+
    | ......                   |      |
    | sit_nat_version_bitmap[] |<-----+
    | ......                   |<-------------+
    |                          |              |
    +--------------------------+  0x1000      |
    |                          |      nat_bitmap + sit_bitmap
    | payload blocks           |              |
    |                          |              |
    +--------------------------|<-------------+
    
    Related report and discussion:
    
    https://sourceforge.net/p/linux-f2fs/mailman/message/36642346/
    
    Reported-by: Park Ju Hyung <qkrwngud825@gmail.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index af77655e65b2..d52a15799488 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -795,6 +795,17 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 		return -EINVAL;
 	}
 
+	if (__is_set_ckpt_flags(*cp_block, CP_LARGE_NAT_BITMAP_FLAG)) {
+		if (crc_offset != CP_MIN_CHKSUM_OFFSET) {
+			f2fs_put_page(*cp_page, 1);
+			f2fs_msg(sbi->sb, KERN_WARNING,
+				"layout of large_nat_bitmap is deprecated, "
+				"run fsck to repair, chksum_offset: %zu",
+				crc_offset);
+			return -EINVAL;
+		}
+	}
+
 	crc = f2fs_checkpoint_chksum(sbi, *cp_block);
 	if (crc != cur_cp_crc(*cp_block)) {
 		f2fs_put_page(*cp_page, 1);

commit d7eb8f1cdfaefcd41b716ef0ed1745b43c6c4fc9
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Apr 22 17:33:52 2019 +0800

    f2fs: allow unfixed f2fs_checkpoint.checksum_offset
    
    Previously, f2fs_checkpoint.checksum_offset points fixed position of
    f2fs_checkpoint structure:
    
    "#define CP_CHKSUM_OFFSET       4092"
    
    It is unnecessary, and it breaks the consecutiveness of nat and sit
    bitmap stored across checkpoint park block and payload blocks.
    
    This patch allows f2fs to handle unfixed .checksum_offset.
    
    In addition, for the case checksum value is stored in the middle of
    checkpoint park, calculating checksum value with superposition method
    like we did for inode_checksum.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f42b0015724b..af77655e65b2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -758,13 +758,27 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	}
 }
 
+static __u32 f2fs_checkpoint_chksum(struct f2fs_sb_info *sbi,
+						struct f2fs_checkpoint *ckpt)
+{
+	unsigned int chksum_ofs = le32_to_cpu(ckpt->checksum_offset);
+	__u32 chksum;
+
+	chksum = f2fs_crc32(sbi, ckpt, chksum_ofs);
+	if (chksum_ofs < CP_CHKSUM_OFFSET) {
+		chksum_ofs += sizeof(chksum);
+		chksum = f2fs_chksum(sbi, chksum, (__u8 *)ckpt + chksum_ofs,
+						F2FS_BLKSIZE - chksum_ofs);
+	}
+	return chksum;
+}
+
 static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 		struct f2fs_checkpoint **cp_block, struct page **cp_page,
 		unsigned long long *version)
 {
-	unsigned long blk_size = sbi->blocksize;
 	size_t crc_offset = 0;
-	__u32 crc = 0;
+	__u32 crc;
 
 	*cp_page = f2fs_get_meta_page(sbi, cp_addr);
 	if (IS_ERR(*cp_page))
@@ -773,15 +787,16 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 	*cp_block = (struct f2fs_checkpoint *)page_address(*cp_page);
 
 	crc_offset = le32_to_cpu((*cp_block)->checksum_offset);
-	if (crc_offset > (blk_size - sizeof(__le32))) {
+	if (crc_offset < CP_MIN_CHKSUM_OFFSET ||
+			crc_offset > CP_CHKSUM_OFFSET) {
 		f2fs_put_page(*cp_page, 1);
 		f2fs_msg(sbi->sb, KERN_WARNING,
 			"invalid crc_offset: %zu", crc_offset);
 		return -EINVAL;
 	}
 
-	crc = cur_cp_crc(*cp_block);
-	if (!f2fs_crc_valid(sbi, crc, *cp_block, crc_offset)) {
+	crc = f2fs_checkpoint_chksum(sbi, *cp_block);
+	if (crc != cur_cp_crc(*cp_block)) {
 		f2fs_put_page(*cp_page, 1);
 		f2fs_msg(sbi->sb, KERN_WARNING, "invalid crc value");
 		return -EINVAL;
@@ -1389,7 +1404,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	get_sit_bitmap(sbi, __bitmap_ptr(sbi, SIT_BITMAP));
 	get_nat_bitmap(sbi, __bitmap_ptr(sbi, NAT_BITMAP));
 
-	crc32 = f2fs_crc32(sbi, ckpt, le32_to_cpu(ckpt->checksum_offset));
+	crc32 = f2fs_checkpoint_chksum(sbi, ckpt);
 	*((__le32 *)((unsigned char *)ckpt +
 				le32_to_cpu(ckpt->checksum_offset)))
 				= cpu_to_le32(crc32);

commit 6dc3a12663c8a99ef033287f48bbdd61b6b1979b
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Apr 15 15:26:31 2019 +0800

    f2fs: fix wrong __is_meta_io() macro
    
    This patch changes codes as below:
    - don't use is_read_io() as a condition to judge the meta IO.
    - use .is_por to replace .is_meta to indicate IO is from recovery explicitly.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 935ebdb9cf47..f42b0015724b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -66,7 +66,7 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 		.old_blkaddr = index,
 		.new_blkaddr = index,
 		.encrypted_page = NULL,
-		.is_meta = is_meta,
+		.is_por = !is_meta,
 	};
 	int err;
 
@@ -189,7 +189,7 @@ int f2fs_ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		.op_flags = sync ? (REQ_META | REQ_PRIO) : REQ_RAHEAD,
 		.encrypted_page = NULL,
 		.in_list = false,
-		.is_meta = (type != META_POR),
+		.is_por = (type == META_POR),
 	};
 	struct blk_plug plug;
 

commit 186857c5a14aee85cace2ae7a36c6e43b9d3c7a5
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Apr 2 18:52:19 2019 +0800

    f2fs: fix potential recursive call when enabling data_flush
    
    As Hagbard Celine reported:
    
    Hi, this is a long standing bug that I've hit before on older kernels,
    but I was not able to get the syslog saved because of the nature of
    the bug. This time I had booted form a pen-drive, and was able to save
    the log to it's efi-partition.
    What i did to trigger it was to create a partition and format it f2fs,
    then mount it with options:
    "rw,relatime,lazytime,background_gc=on,disable_ext_identify,discard,heap,user_xattr,inline_xattr,acl,inline_data,inline_dentry,flush_merge,data_flush,extent_cache,mode=adaptive,active_logs=6,whint_mode=fs-based,alloc_mode=default,fsync_mode=strict".
    Then I unpacked a big .tar.xz to the partition (I used a
    gentoo-stage3-tarball as I was in process of installing Gentoo).
    
    Same options just without data_flush gives no problems.
    
    Mar 20 20:54:01 usbgentoo kernel: FAT-fs (nvme0n1p4): Volume was not
    properly unmounted. Some data may be corrupt. Please run fsck.
    Mar 20 21:05:23 usbgentoo kernel: kworker/dying (1588) used greatest
    stack depth: 12064 bytes left
    Mar 20 21:06:40 usbgentoo kernel: BUG: stack guard page was hit at
    00000000a4b0733c (stack is 0000000056016422..0000000096e7463f)
    Mar 20 21:06:40 usbgentoo kernel: kernel stack overflow
    
    ......
    
    Mar 20 21:06:40 usbgentoo kernel: Call Trace:
    Mar 20 21:06:40 usbgentoo kernel:  read_node_page+0x71/0xf0
    Mar 20 21:06:40 usbgentoo kernel:  ? xas_load+0x8/0x50
    Mar 20 21:06:40 usbgentoo kernel:  __get_node_page+0x73/0x2a0
    Mar 20 21:06:40 usbgentoo kernel:  f2fs_get_dnode_of_data+0x34e/0x580
    Mar 20 21:06:40 usbgentoo kernel:  f2fs_write_inline_data+0x5e/0x2a0
    Mar 20 21:06:40 usbgentoo kernel:  __write_data_page+0x421/0x690
    Mar 20 21:06:40 usbgentoo kernel:  f2fs_write_cache_pages+0x1cf/0x460
    Mar 20 21:06:40 usbgentoo kernel:  f2fs_write_data_pages+0x2b3/0x2e0
    Mar 20 21:06:40 usbgentoo kernel:  ? f2fs_inode_chksum_verify+0x1d/0xc0
    Mar 20 21:06:40 usbgentoo kernel:  ? read_node_page+0x71/0xf0
    Mar 20 21:06:40 usbgentoo kernel:  do_writepages+0x3c/0xd0
    Mar 20 21:06:40 usbgentoo kernel:  __filemap_fdatawrite_range+0x7c/0xb0
    Mar 20 21:06:40 usbgentoo kernel:  f2fs_sync_dirty_inodes+0xf2/0x200
    Mar 20 21:06:40 usbgentoo kernel:  f2fs_balance_fs_bg+0x2a3/0x2c0
    Mar 20 21:06:40 usbgentoo kernel:  ? f2fs_inode_dirtied+0x21/0xc0
    Mar 20 21:06:40 usbgentoo kernel:  f2fs_balance_fs+0xd6/0x2b0
    Mar 20 21:06:40 usbgentoo kernel:  __write_data_page+0x4fb/0x690
    
    ......
    
    Mar 20 21:06:40 usbgentoo kernel:  __writeback_single_inode+0x2a1/0x340
    Mar 20 21:06:40 usbgentoo kernel:  ? soft_cursor+0x1b4/0x220
    Mar 20 21:06:40 usbgentoo kernel:  writeback_sb_inodes+0x1d5/0x3e0
    Mar 20 21:06:40 usbgentoo kernel:  __writeback_inodes_wb+0x58/0xa0
    Mar 20 21:06:40 usbgentoo kernel:  wb_writeback+0x250/0x2e0
    Mar 20 21:06:40 usbgentoo kernel:  ? 0xffffffff8c000000
    Mar 20 21:06:40 usbgentoo kernel:  ? cpumask_next+0x16/0x20
    Mar 20 21:06:40 usbgentoo kernel:  wb_workfn+0x2f6/0x3b0
    Mar 20 21:06:40 usbgentoo kernel:  ? __switch_to_asm+0x40/0x70
    Mar 20 21:06:40 usbgentoo kernel:  process_one_work+0x1f5/0x3f0
    Mar 20 21:06:40 usbgentoo kernel:  worker_thread+0x28/0x3c0
    Mar 20 21:06:40 usbgentoo kernel:  ? rescuer_thread+0x330/0x330
    Mar 20 21:06:40 usbgentoo kernel:  kthread+0x10e/0x130
    Mar 20 21:06:40 usbgentoo kernel:  ? kthread_create_on_node+0x60/0x60
    Mar 20 21:06:40 usbgentoo kernel:  ret_from_fork+0x35/0x40
    
    The root cause is that we run into an infinite recursive calling in
    between f2fs_balance_fs_bg and writepage() as described below:
    
    - f2fs_write_data_pages         --- A
     - __write_data_page
      - f2fs_balance_fs
       - f2fs_balance_fs_bg         --- B
        - f2fs_sync_dirty_inodes
         - filemap_fdatawrite
          - f2fs_write_data_pages   --- A
    ...
              - f2fs_balance_fs_bg  --- B
    ...
    
    In order to fix this issue, let's detect such condition in __write_data_page()
    and just skip calling f2fs_balance_fs() recursively.
    
    Reported-by: Hagbard Celine <hagbardcelin@gmail.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index a98e1b02279e..935ebdb9cf47 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1009,13 +1009,11 @@ int f2fs_sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 	if (inode) {
 		unsigned long cur_ino = inode->i_ino;
 
-		if (is_dir)
-			F2FS_I(inode)->cp_task = current;
+		F2FS_I(inode)->cp_task = current;
 
 		filemap_fdatawrite(inode->i_mapping);
 
-		if (is_dir)
-			F2FS_I(inode)->cp_task = NULL;
+		F2FS_I(inode)->cp_task = NULL;
 
 		iput(inode);
 		/* We need to give cpu to another writers. */

commit 240a59156d9bcfabceddb66be449e7b32fb5dc4a
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Mar 6 17:30:59 2019 +0800

    f2fs: fix to add refcount once page is tagged PG_private
    
    As Gao Xiang reported in bugzilla:
    
    https://bugzilla.kernel.org/show_bug.cgi?id=202749
    
    f2fs may skip pageout() due to incorrect page reference count.
    
    The problem here is that MM defined the rule [1] very clearly that
    once page was set with PG_private flag, we should increment the
    refcount in that page, also main flows like pageout(), migrate_page()
    will assume there is one additional page reference count if
    page_has_private() returns true.
    
    But currently, f2fs won't add/del refcount when changing PG_private
    flag. Anyway, f2fs should follow MM's rule to make MM's related flows
    running as expected.
    
    [1] https://lore.kernel.org/lkml/2b19b3c4-2bc4-15fa-15cc-27a13e5c7af1@aol.com/
    
    Reported-by: Gao Xiang <gaoxiang25@huawei.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c65a1e8e1e95..a98e1b02279e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -406,7 +406,7 @@ static int f2fs_set_meta_page_dirty(struct page *page)
 	if (!PageDirty(page)) {
 		__set_page_dirty_nobuffers(page);
 		inc_page_count(F2FS_P_SB(page), F2FS_DIRTY_META);
-		SetPagePrivate(page);
+		f2fs_set_page_private(page, 0);
 		f2fs_trace_pid(page);
 		return 1;
 	}
@@ -957,7 +957,7 @@ void f2fs_update_dirty_page(struct inode *inode, struct page *page)
 	inode_inc_dirty_pages(inode);
 	spin_unlock(&sbi->inode_lock[type]);
 
-	SetPagePrivate(page);
+	f2fs_set_page_private(page, 0);
 	f2fs_trace_pid(page);
 }
 

commit fb40d618b03978b7cc5820697894461f4a2af98b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Feb 5 07:59:57 2019 -0800

    f2fs: don't clear CP_QUOTA_NEED_FSCK_FLAG
    
    If we met this once, let fsck.f2fs clear this only.
    Note that, this addresses all the subtle fault injection test.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 03fea4efd64b..c65a1e8e1e95 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1267,8 +1267,10 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	if (is_sbi_flag_set(sbi, SBI_QUOTA_SKIP_FLUSH))
 		__set_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);
-	else
-		__clear_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);
+	/*
+	 * TODO: we count on fsck.f2fs to clear this flag until we figure out
+	 * missing cases which clear it incorrectly.
+	 */
 
 	if (is_sbi_flag_set(sbi, SBI_QUOTA_NEED_REPAIR))
 		__set_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);

commit 812a95977fd2f0d1f220c716a98a7f22e22f488d
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Jan 22 14:04:33 2019 -0800

    f2fs: sync filesystem after roll-forward recovery
    
    Some works after roll-forward recovery can get an error which will release
    all the data structures. Let's flush them in order to make it clean.
    
    One possible corruption came from:
    
    [   90.400500] list_del corruption. prev->next should be ffffffed1f566208, but was (null)
    [   90.675349] Call trace:
    [   90.677869]  __list_del_entry_valid+0x94/0xb4
    [   90.682351]  remove_dirty_inode+0xac/0x114
    [   90.686563]  __f2fs_write_data_pages+0x6a8/0x6c8
    [   90.691302]  f2fs_write_data_pages+0x40/0x4c
    [   90.695695]  do_writepages+0x80/0xf0
    [   90.699372]  __writeback_single_inode+0xdc/0x4ac
    [   90.704113]  writeback_sb_inodes+0x280/0x440
    [   90.708501]  wb_writeback+0x1b8/0x3d0
    [   90.712267]  wb_workfn+0x1a8/0x4d4
    [   90.715765]  process_one_work+0x1c0/0x3d4
    [   90.719883]  worker_thread+0x224/0x344
    [   90.723739]  kthread+0x120/0x130
    [   90.727055]  ret_from_fork+0x10/0x18
    
    Reported-by: Sahitya Tummala <stummala@codeaurora.org>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 622dca707752..03fea4efd64b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -306,8 +306,9 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 		goto skip_write;
 
 	/* collect a number of dirty meta pages and write together */
-	if (wbc->for_kupdate ||
-		get_pages(sbi, F2FS_DIRTY_META) < nr_pages_to_skip(sbi, META))
+	if (wbc->sync_mode != WB_SYNC_ALL &&
+			get_pages(sbi, F2FS_DIRTY_META) <
+					nr_pages_to_skip(sbi, META))
 		goto skip_write;
 
 	/* if locked failed, cp will flush dirty pages instead */

commit db610a640eeeb268c36a4558414f28e1c269433e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jan 24 17:48:38 2019 -0800

    f2fs: add quick mode of checkpoint=disable for QA
    
    This mode returns mount() quickly with EAGAIN. We can trigger this by
    shutdown(F2FS_GOING_DOWN_NEED_FSCK).
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f955cd3e0677..622dca707752 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1259,6 +1259,11 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	else
 		__clear_ckpt_flags(ckpt, CP_DISABLED_FLAG);
 
+	if (is_sbi_flag_set(sbi, SBI_CP_DISABLED_QUICK))
+		__set_ckpt_flags(ckpt, CP_DISABLED_QUICK_FLAG);
+	else
+		__clear_ckpt_flags(ckpt, CP_DISABLED_QUICK_FLAG);
+
 	if (is_sbi_flag_set(sbi, SBI_QUOTA_SKIP_FLUSH))
 		__set_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);
 	else

commit bae0ee7a767ceeea6d8e170da3f228fbc7480331
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Dec 25 17:43:42 2018 +0800

    f2fs: check PageWriteback flag for ordered case
    
    For all ordered cases in f2fs_wait_on_page_writeback(), we need to
    check PageWriteback status, so let's clean up to relocate the check
    into f2fs_wait_on_page_writeback().
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5401ea5e491d..f955cd3e0677 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -44,7 +44,7 @@ struct page *f2fs_grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		cond_resched();
 		goto repeat;
 	}
-	f2fs_wait_on_page_writeback(page, META, true);
+	f2fs_wait_on_page_writeback(page, META, true, true);
 	if (!PageUptodate(page))
 		SetPageUptodate(page);
 	return page;
@@ -370,9 +370,8 @@ long f2fs_sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 				goto continue_unlock;
 			}
 
-			f2fs_wait_on_page_writeback(page, META, true);
+			f2fs_wait_on_page_writeback(page, META, true, true);
 
-			BUG_ON(PageWriteback(page));
 			if (!clear_page_dirty_for_io(page))
 				goto continue_unlock;
 
@@ -1290,8 +1289,7 @@ static void commit_checkpoint(struct f2fs_sb_info *sbi,
 	struct page *page = f2fs_grab_meta_page(sbi, blk_addr);
 	int err;
 
-	f2fs_wait_on_page_writeback(page, META, true);
-	f2fs_bug_on(sbi, PageWriteback(page));
+	f2fs_wait_on_page_writeback(page, META, true, true);
 
 	memcpy(page_address(page), src, PAGE_SIZE);
 

commit 8ec18bff7b90b56eba5986555c174721ebd5670b
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Dec 12 18:12:32 2018 +0800

    f2fs: clean up checkpoint flow
    
    This patch cleans up checkpoint flow a bit:
    - remove unneeded circulation of flushing meta pages.
    - don't flush nat_bits pages in prior to other checkpoint pages.
    - add bug_on to check remained meta pages after flushing.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 1d8283370861..5401ea5e491d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1329,11 +1329,9 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	int err;
 
 	/* Flush all the NAT/SIT pages */
-	while (get_pages(sbi, F2FS_DIRTY_META)) {
-		f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
-		if (unlikely(f2fs_cp_error(sbi)))
-			break;
-	}
+	f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
+	f2fs_bug_on(sbi, get_pages(sbi, F2FS_DIRTY_META) &&
+					!f2fs_cp_error(sbi));
 
 	/*
 	 * modify checkpoint
@@ -1406,14 +1404,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		for (i = 0; i < nm_i->nat_bits_blocks; i++)
 			f2fs_update_meta_page(sbi, nm_i->nat_bits +
 					(i << F2FS_BLKSIZE_BITS), blk + i);
-
-		/* Flush all the NAT BITS pages */
-		while (get_pages(sbi, F2FS_DIRTY_META)) {
-			f2fs_sync_meta_pages(sbi, META, LONG_MAX,
-							FS_CP_META_IO);
-			if (unlikely(f2fs_cp_error(sbi)))
-				break;
-		}
 	}
 
 	/* write out checkpoint buffer at block 0 */
@@ -1449,6 +1439,8 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* Here, we have one bio having CP pack except cp pack 2 page */
 	f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
+	f2fs_bug_on(sbi, get_pages(sbi, F2FS_DIRTY_META) &&
+					!f2fs_cp_error(sbi));
 
 	/* wait for previous submitted meta pages writeback */
 	f2fs_wait_on_all_pages_writeback(sbi);

commit 5222595d093ebe80329d38d255d14316257afb3e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Dec 13 18:38:33 2018 -0800

    f2fs: use kvmalloc, if kmalloc is failed
    
    One report says memalloc failure during mount.
    
     (unwind_backtrace) from [<c010cd4c>] (show_stack+0x10/0x14)
     (show_stack) from [<c049c6b8>] (dump_stack+0x8c/0xa0)
     (dump_stack) from [<c024fcf0>] (warn_alloc+0xc4/0x160)
     (warn_alloc) from [<c0250218>] (__alloc_pages_nodemask+0x3f4/0x10d0)
     (__alloc_pages_nodemask) from [<c0270450>] (kmalloc_order_trace+0x2c/0x120)
     (kmalloc_order_trace) from [<c03fa748>] (build_node_manager+0x35c/0x688)
     (build_node_manager) from [<c03de494>] (f2fs_fill_super+0xf0c/0x16cc)
     (f2fs_fill_super) from [<c02a5864>] (mount_bdev+0x15c/0x188)
     (mount_bdev) from [<c03da624>] (f2fs_mount+0x18/0x20)
     (f2fs_mount) from [<c02a68b8>] (mount_fs+0x158/0x19c)
     (mount_fs) from [<c02c3c9c>] (vfs_kern_mount+0x78/0x134)
     (vfs_kern_mount) from [<c02c76ac>] (do_mount+0x474/0xca4)
     (do_mount) from [<c02c8264>] (SyS_mount+0x94/0xbc)
     (SyS_mount) from [<c0108180>] (ret_fast_syscall+0x0/0x48)
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4f02461f348c..1d8283370861 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -911,7 +911,7 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	f2fs_put_page(cp1, 1);
 	f2fs_put_page(cp2, 1);
 fail_no_cp:
-	kfree(sbi->ckpt);
+	kvfree(sbi->ckpt);
 	return -EINVAL;
 }
 

commit 8d64d365aed355b2e2465d19ba61df02462fff4d
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Dec 12 18:12:30 2018 +0800

    f2fs: fix to reorder set_page_dirty and wait_on_page_writeback
    
    This patch reorders flow from
    
    - update page
    - set_page_dirty
    - wait_on_page_writeback
    
    to
    
    - wait_on_page_writeback
    - update page
    - set_page_dirty
    
    The reason is:
    - set_page_dirty will increase reference of dirty page, the reference
    should be cleared before wait_on_page_writeback to keep its consistency.
    - some devices need stable page during page writebacking, so we
    should not change page's data.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3a25cf22d732..4f02461f348c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1290,11 +1290,12 @@ static void commit_checkpoint(struct f2fs_sb_info *sbi,
 	struct page *page = f2fs_grab_meta_page(sbi, blk_addr);
 	int err;
 
-	memcpy(page_address(page), src, PAGE_SIZE);
-	set_page_dirty(page);
-
 	f2fs_wait_on_page_writeback(page, META, true);
 	f2fs_bug_on(sbi, PageWriteback(page));
+
+	memcpy(page_address(page), src, PAGE_SIZE);
+
+	set_page_dirty(page);
 	if (unlikely(!clear_page_dirty_for_io(page)))
 		f2fs_bug_on(sbi, 1);
 

commit 7beb01f74415c56f5992922b5b902b45d365e694
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Oct 24 18:34:26 2018 +0800

    f2fs: clean up f2fs_sb_has_##feature_name
    
    In F2FS_HAS_FEATURE(), we will use F2FS_SB(sb) to get sbi pointer to
    access .raw_super field, to avoid unneeded pointer conversion, this
    patch changes to F2FS_HAS_FEATURE() accept sbi parameter directly.
    
    Just do cleanup, no logic change.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9c28ea439e0b..3a25cf22d732 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1465,7 +1465,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	 * invalidate intermediate page cache borrowed from meta inode
 	 * which are used for migration of encrypted inode's blocks.
 	 */
-	if (f2fs_sb_has_encrypt(sbi->sb))
+	if (f2fs_sb_has_encrypt(sbi))
 		invalidate_mapping_pages(META_MAPPING(sbi),
 				MAIN_BLKADDR(sbi), MAX_BLKADDR(sbi) - 1);
 

commit af033b2aa8a874fd5737fafe90d159136527b5b4
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Sep 20 20:05:00 2018 +0800

    f2fs: guarantee journalled quota data by checkpoint
    
    For journalled quota mode, let checkpoint to flush dquot dirty data
    and quota file data to guarntee persistence of all quota sysfile in
    last checkpoint, by this way, we can avoid corrupting quota sysfile
    when encountering SPO.
    
    The implementation is as below:
    
    1. add a global state SBI_QUOTA_NEED_FLUSH to indicate that there is
    cached dquot metadata changes in quota subsystem, and later checkpoint
    should:
     a) flush dquot metadata into quota file.
     b) flush quota file to storage to keep file usage be consistent.
    
    2. add a global state SBI_QUOTA_NEED_REPAIR to indicate that quota
    operation failed due to -EIO or -ENOSPC, so later,
     a) checkpoint will skip syncing dquot metadata.
     b) CP_QUOTA_NEED_FSCK_FLAG will be set in last cp pack to give a
        hint for fsck repairing.
    
    3. add a global state SBI_QUOTA_SKIP_FLUSH, in checkpoint, if quota
    data updating is very heavy, it may cause hungtask in block_operation().
    To avoid this, if our retry time exceed threshold, let's just skip
    flushing and retry in next checkpoint().
    
    Signed-off-by: Weichao Guo <guoweichao@huawei.com>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: avoid warnings and set fsck flag]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index eb6ac79640f8..9c28ea439e0b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1079,6 +1079,21 @@ static void __prepare_cp_block(struct f2fs_sb_info *sbi)
 	ckpt->next_free_nid = cpu_to_le32(last_nid);
 }
 
+static bool __need_flush_quota(struct f2fs_sb_info *sbi)
+{
+	if (!is_journalled_quota(sbi))
+		return false;
+	if (is_sbi_flag_set(sbi, SBI_QUOTA_SKIP_FLUSH))
+		return false;
+	if (is_sbi_flag_set(sbi, SBI_QUOTA_NEED_REPAIR))
+		return false;
+	if (is_sbi_flag_set(sbi, SBI_QUOTA_NEED_FLUSH))
+		return true;
+	if (get_pages(sbi, F2FS_DIRTY_QDATA))
+		return true;
+	return false;
+}
+
 /*
  * Freeze all the FS-operations for checkpoint.
  */
@@ -1090,12 +1105,36 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		.for_reclaim = 0,
 	};
 	struct blk_plug plug;
-	int err = 0;
+	int err = 0, cnt = 0;
 
 	blk_start_plug(&plug);
 
-retry_flush_dents:
+retry_flush_quotas:
+	if (__need_flush_quota(sbi)) {
+		int locked;
+
+		if (++cnt > DEFAULT_RETRY_QUOTA_FLUSH_COUNT) {
+			set_sbi_flag(sbi, SBI_QUOTA_SKIP_FLUSH);
+			f2fs_lock_all(sbi);
+			goto retry_flush_dents;
+		}
+		clear_sbi_flag(sbi, SBI_QUOTA_NEED_FLUSH);
+
+		/* only failed during mount/umount/freeze/quotactl */
+		locked = down_read_trylock(&sbi->sb->s_umount);
+		f2fs_quota_sync(sbi->sb, -1);
+		if (locked)
+			up_read(&sbi->sb->s_umount);
+	}
+
 	f2fs_lock_all(sbi);
+	if (__need_flush_quota(sbi)) {
+		f2fs_unlock_all(sbi);
+		cond_resched();
+		goto retry_flush_quotas;
+	}
+
+retry_flush_dents:
 	/* write all the dirty dentry pages */
 	if (get_pages(sbi, F2FS_DIRTY_DENTS)) {
 		f2fs_unlock_all(sbi);
@@ -1103,7 +1142,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		if (err)
 			goto out;
 		cond_resched();
-		goto retry_flush_dents;
+		goto retry_flush_quotas;
 	}
 
 	/*
@@ -1112,6 +1151,12 @@ static int block_operations(struct f2fs_sb_info *sbi)
 	 */
 	down_write(&sbi->node_change);
 
+	if (__need_flush_quota(sbi)) {
+		up_write(&sbi->node_change);
+		f2fs_unlock_all(sbi);
+		goto retry_flush_quotas;
+	}
+
 	if (get_pages(sbi, F2FS_DIRTY_IMETA)) {
 		up_write(&sbi->node_change);
 		f2fs_unlock_all(sbi);
@@ -1119,7 +1164,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		if (err)
 			goto out;
 		cond_resched();
-		goto retry_flush_dents;
+		goto retry_flush_quotas;
 	}
 
 retry_flush_nodes:
@@ -1215,6 +1260,14 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	else
 		__clear_ckpt_flags(ckpt, CP_DISABLED_FLAG);
 
+	if (is_sbi_flag_set(sbi, SBI_QUOTA_SKIP_FLUSH))
+		__set_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);
+	else
+		__clear_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);
+
+	if (is_sbi_flag_set(sbi, SBI_QUOTA_NEED_REPAIR))
+		__set_ckpt_flags(ckpt, CP_QUOTA_NEED_FSCK_FLAG);
+
 	/* set this flag to activate crc|cp_ver for recovery */
 	__set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG);
 	__clear_ckpt_flags(ckpt, CP_NOCRC_RECOVERY_FLAG);
@@ -1422,6 +1475,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 	clear_sbi_flag(sbi, SBI_NEED_CP);
+	clear_sbi_flag(sbi, SBI_QUOTA_SKIP_FLUSH);
 	sbi->unusable_block_count = 0;
 	__set_cp_next_pack(sbi);
 

commit 4354994f097d068a894aa1a0860da54571df3582
Author: Daniel Rosenberg <drosen@google.com>
Date:   Mon Aug 20 19:21:43 2018 -0700

    f2fs: checkpoint disabling
    
    Note that, it requires "f2fs: return correct errno in f2fs_gc".
    
    This adds a lightweight non-persistent snapshotting scheme to f2fs.
    
    To use, mount with the option checkpoint=disable, and to return to
    normal operation, remount with checkpoint=enable. If the filesystem
    is shut down before remounting with checkpoint=enable, it will revert
    back to its apparent state when it was first mounted with
    checkpoint=disable. This is useful for situations where you wish to be
    able to roll back the state of the disk in case of some critical
    failure.
    
    Signed-off-by: Daniel Rosenberg <drosen@google.com>
    [Jaegeuk Kim: use SB_RDONLY instead of MS_RDONLY]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 97b429ba2911..eb6ac79640f8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1210,6 +1210,11 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK))
 		__set_ckpt_flags(ckpt, CP_FSCK_FLAG);
 
+	if (is_sbi_flag_set(sbi, SBI_CP_DISABLED))
+		__set_ckpt_flags(ckpt, CP_DISABLED_FLAG);
+	else
+		__clear_ckpt_flags(ckpt, CP_DISABLED_FLAG);
+
 	/* set this flag to activate crc|cp_ver for recovery */
 	__set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG);
 	__clear_ckpt_flags(ckpt, CP_NOCRC_RECOVERY_FLAG);
@@ -1417,6 +1422,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 	clear_sbi_flag(sbi, SBI_NEED_CP);
+	sbi->unusable_block_count = 0;
 	__set_cp_next_pack(sbi);
 
 	/*
@@ -1441,6 +1447,12 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	unsigned long long ckpt_ver;
 	int err = 0;
 
+	if (unlikely(is_sbi_flag_set(sbi, SBI_CP_DISABLED))) {
+		if (cpc->reason != CP_PAUSE)
+			return 0;
+		f2fs_msg(sbi->sb, KERN_WARNING,
+				"Start checkpoint disabled!");
+	}
 	mutex_lock(&sbi->cp_mutex);
 
 	if (!is_sbi_flag_set(sbi, SBI_IS_DIRTY) &&

commit bab475c5414e8d1fa182fd17ae966864e9c85741
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Sep 27 23:41:16 2018 +0800

    Revert: "f2fs: check last page index in cached bio to decide submission"
    
    There is one case that we can leave bio in f2fs, result in hanging
    page writeback waiter.
    
    Thread A                                Thread B
    - f2fs_write_cache_pages
     - f2fs_submit_page_write
     page #0 cached in bio #0 of cold log
     - f2fs_submit_page_write
     page #1 cached in bio #1 of warm log
                                            - f2fs_write_cache_pages
                                             - f2fs_submit_page_write
                                             bio is full, submit bio #1 contain page #1
     - f2fs_submit_merged_write_cond(, page #1)
     fail to submit bio #0 due to page #1 is not in any cached bios.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f4b9b81e3ed6..97b429ba2911 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -276,8 +276,7 @@ static int __f2fs_write_meta_page(struct page *page,
 	dec_page_count(sbi, F2FS_DIRTY_META);
 
 	if (wbc->for_reclaim)
-		f2fs_submit_merged_write_cond(sbi, page->mapping->host,
-						0, page->index, META);
+		f2fs_submit_merged_write_cond(sbi, NULL, page, 0, META);
 
 	unlock_page(page);
 

commit edc55aaf0d1712b54a3704dd58423c7e495534fe
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 17 17:36:06 2018 -0700

    f2fs: avoid f2fs_bug_on if f2fs_get_meta_page_nofail got EIO
    
    This patch avoids BUG_ON when f2fs_get_meta_page_nofail got EIO during
    xfstests/generic/475.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d312d2829d5a..f4b9b81e3ed6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -119,11 +119,8 @@ struct page *f2fs_get_meta_page_nofail(struct f2fs_sb_info *sbi, pgoff_t index)
 		if (PTR_ERR(page) == -EIO &&
 				++count <= DEFAULT_RETRY_IO_COUNT)
 			goto retry;
-
 		f2fs_stop_checkpoint(sbi, false);
-		f2fs_bug_on(sbi, 1);
 	}
-
 	return page;
 }
 
@@ -1496,7 +1493,10 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	ckpt->checkpoint_ver = cpu_to_le64(++ckpt_ver);
 
 	/* write cached NAT/SIT entries to NAT/SIT area */
-	f2fs_flush_nat_entries(sbi, cpc);
+	err = f2fs_flush_nat_entries(sbi, cpc);
+	if (err)
+		goto stop;
+
 	f2fs_flush_sit_entries(sbi, cpc);
 
 	/* unlock all the fs_lock[] in do_checkpoint() */
@@ -1505,7 +1505,7 @@ int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		f2fs_release_discard_addrs(sbi);
 	else
 		f2fs_clear_prefree_segments(sbi, cpc);
-
+stop:
 	unblock_operations(sbi);
 	stat_inc_cp_count(sbi->stat_info);
 

commit 7c1a000d466235c875a989971cfda344e6bb1166
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Sep 12 09:16:07 2018 +0800

    f2fs: add SPDX license identifiers
    
    Remove the verbose license text from f2fs files and replace them with
    SPDX tags.  This does not change the license of any of the code.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 59d0472013f4..d312d2829d5a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1,12 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * fs/f2fs/checkpoint.c
  *
  * Copyright (c) 2012 Samsung Electronics Co., Ltd.
  *             http://www.samsung.com/
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 #include <linux/fs.h>
 #include <linux/bio.h>

commit 1378752b9921e60749eaf18ec6c47b33f9001abb
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Aug 22 17:11:05 2018 +0800

    f2fs: fix to flush all dirty inodes recovered in readonly fs
    
    generic/417 reported as blow:
    
    ------------[ cut here ]------------
    kernel BUG at /home/yuchao/git/devf2fs/inode.c:695!
    invalid opcode: 0000 [#1] PREEMPT SMP
    CPU: 1 PID: 21697 Comm: umount Tainted: G        W  O      4.18.0-rc2+ #39
    Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
    EIP: f2fs_evict_inode+0x556/0x580 [f2fs]
    Call Trace:
     ? _raw_spin_unlock+0x2c/0x50
     evict+0xa8/0x170
     dispose_list+0x34/0x40
     evict_inodes+0x118/0x120
     generic_shutdown_super+0x41/0x100
     ? rcu_read_lock_sched_held+0x97/0xa0
     kill_block_super+0x22/0x50
     kill_f2fs_super+0x6f/0x80 [f2fs]
     deactivate_locked_super+0x3d/0x70
     deactivate_super+0x40/0x60
     cleanup_mnt+0x39/0x70
     __cleanup_mnt+0x10/0x20
     task_work_run+0x81/0xa0
     exit_to_usermode_loop+0x59/0xa7
     do_fast_syscall_32+0x1f5/0x22c
     entry_SYSENTER_32+0x53/0x86
    EIP: f2fs_evict_inode+0x556/0x580 [f2fs]
    
    It can simply reproduced with scripts:
    
    Enable quota feature during mkfs.
    
    Testcase1:
    1. mkfs.f2fs /dev/zram0
    2. mount -t f2fs /dev/zram0 /mnt/f2fs
    3. xfs_io -f /mnt/f2fs/file -c "pwrite 0 4k" -c "fsync"
    4. godown /mnt/f2fs
    5. umount /mnt/f2fs
    6. mount -t f2fs -o ro /dev/zram0 /mnt/f2fs
    7. umount /mnt/f2fs
    
    Testcase2:
    1. mkfs.f2fs /dev/zram0
    2. mount -t f2fs /dev/zram0 /mnt/f2fs
    3. touch /mnt/f2fs/file
    4. create process[pid = x] do:
            a) open /mnt/f2fs/file;
            b) unlink /mnt/f2fs/file
    5. godown -f /mnt/f2fs
    6. kill process[pid = x]
    7. umount /mnt/f2fs
    8. mount -t f2fs -o ro /dev/zram0 /mnt/f2fs
    9. umount /mnt/f2fs
    
    The reason is: during recovery, i_{c,m}time of inode will be updated, then
    the inode can be set dirty w/o being tracked in sbi->inode_list[DIRTY_META]
    global list, so later write_checkpoint will not flush such dirty inode into
    node page.
    
    Once umount is called, sync_filesystem() in generic_shutdown_super() will
    skip syncng dirty inodes due to sb_rdonly check, leaving dirty inodes
    there.
    
    To solve this issue, during umount, add remove SB_RDONLY flag in
    sb->s_flags, to make sure sync_filesystem() will not be skipped.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index e8b6b89bddb8..59d0472013f4 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -696,6 +696,8 @@ int f2fs_recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	/* clear Orphan Flag */
 	clear_ckpt_flags(sbi, CP_ORPHAN_PRESENT_FLAG);
 out:
+	set_sbi_flag(sbi, SBI_IS_RECOVERED);
+
 #ifdef CONFIG_QUOTA
 	/* Turn quotas off */
 	if (quota_enabled)

commit 7fa750a163089cf96866de402314d853a96cb342
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Aug 13 23:38:06 2018 +0200

    f2fs: rework fault injection handling to avoid a warning
    
    When CONFIG_F2FS_FAULT_INJECTION is disabled, we get a warning about an
    unused label:
    
    fs/f2fs/segment.c: In function '__submit_discard_cmd':
    fs/f2fs/segment.c:1059:1: error: label 'submit' defined but not used [-Werror=unused-label]
    
    This could be fixed by adding another #ifdef around it, but the more
    reliable way of doing this seems to be to remove the other #ifdefs
    where that is easily possible.
    
    By defining time_to_inject() as a trivial stub, most of the checks for
    CONFIG_F2FS_FAULT_INJECTION can go away. This also leads to nicer
    formatting of the code.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3ab7a00c0641..e8b6b89bddb8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -555,13 +555,12 @@ int f2fs_acquire_orphan_inode(struct f2fs_sb_info *sbi)
 
 	spin_lock(&im->ino_lock);
 
-#ifdef CONFIG_F2FS_FAULT_INJECTION
 	if (time_to_inject(sbi, FAULT_ORPHAN)) {
 		spin_unlock(&im->ino_lock);
 		f2fs_show_injection_info(FAULT_ORPHAN);
 		return -ENOSPC;
 	}
-#endif
+
 	if (unlikely(im->ino_num >= sbi->max_orphans))
 		err = -ENOSPC;
 	else

commit d494500a70434223bc35f862fab0679b13bea23d
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Aug 8 17:36:41 2018 +0800

    f2fs: support fault_type mount option
    
    Previously, once fault injection is on, by default, all kind of faults
    will be injected to f2fs, if we want to trigger single or specified
    combined type during the test, we need to configure sysfs entry, it will
    be a little inconvenient to integrate sysfs configuring into testsuit,
    such as xfstest.
    
    So this patch introduces a new mount option 'fault_type' to assist old
    option 'fault_injection', with these two mount options, we can specify
    any fault rate/type at mount-time.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 31561026ac9a..3ab7a00c0641 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -28,7 +28,7 @@ struct kmem_cache *f2fs_inode_entry_slab;
 
 void f2fs_stop_checkpoint(struct f2fs_sb_info *sbi, bool end_io)
 {
-	f2fs_build_fault_attr(sbi, 0);
+	f2fs_build_fault_attr(sbi, 0, 0);
 	set_ckpt_flags(sbi, CP_ERROR_FLAG);
 	if (!end_io)
 		f2fs_flush_merged_writes(sbi);

commit d3f07c049dab1a3f1740f476afd3d5e5b738c21c
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Aug 2 22:59:12 2018 +0800

    f2fs: fix invalid memory access
    
    syzbot found the following crash on:
    
    HEAD commit:    d9bd94c0bcaa Add linux-next specific files for 20180801
    git tree:       linux-next
    console output: https://syzkaller.appspot.com/x/log.txt?x=1001189c400000
    kernel config:  https://syzkaller.appspot.com/x/.config?x=cc8964ea4d04518c
    dashboard link: https://syzkaller.appspot.com/bug?extid=c966a82db0b14aa37e81
    compiler:       gcc (GCC) 8.0.1 20180413 (experimental)
    
    Unfortunately, I don't have any reproducer for this crash yet.
    
    IMPORTANT: if you fix the bug, please add the following tag to the commit:
    Reported-by: syzbot+c966a82db0b14aa37e81@syzkaller.appspotmail.com
    
    loop7: rw=12288, want=8200, limit=20
    netlink: 65342 bytes leftover after parsing attributes in process `syz-executor4'.
    openvswitch: netlink: Message has 8 unknown bytes.
    kasan: CONFIG_KASAN_INLINE enabled
    kasan: GPF could be caused by NULL-ptr deref or user memory access
    general protection fault: 0000 [#1] SMP KASAN
    CPU: 1 PID: 7615 Comm: syz-executor7 Not tainted 4.18.0-rc7-next-20180801+ #29
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    RIP: 0010:__read_once_size include/linux/compiler.h:188 [inline]
    RIP: 0010:compound_head include/linux/page-flags.h:142 [inline]
    RIP: 0010:PageLocked include/linux/page-flags.h:272 [inline]
    RIP: 0010:f2fs_put_page fs/f2fs/f2fs.h:2011 [inline]
    RIP: 0010:validate_checkpoint+0x66d/0xec0 fs/f2fs/checkpoint.c:835
    Code: e8 58 05 7f fe 4c 8d 6b 80 4d 8d 74 24 08 48 b8 00 00 00 00 00 fc ff df 4c 89 ea 48 c1 ea 03 c6 04 02 00 4c 89 f2 48 c1 ea 03 <80> 3c 02 00 0f 85 f4 06 00 00 4c 89 ea 4d 8b 7c 24 08 48 b8 00 00
    RSP: 0018:ffff8801937cebe8 EFLAGS: 00010246
    RAX: dffffc0000000000 RBX: ffff8801937cef30 RCX: ffffc90006035000
    RDX: 0000000000000000 RSI: ffffffff82fd9658 RDI: 0000000000000005
    RBP: ffff8801937cef58 R08: ffff8801ab254700 R09: fffff94000d9e026
    R10: fffff94000d9e026 R11: ffffea0006cf0137 R12: fffffffffffffffb
    R13: ffff8801937ceeb0 R14: 0000000000000003 R15: ffff880193419b40
    FS:  00007f36a61d5700(0000) GS:ffff8801db100000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007fc04ff93000 CR3: 00000001d0562000 CR4: 00000000001426e0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    Call Trace:
     f2fs_get_valid_checkpoint+0x436/0x1ec0 fs/f2fs/checkpoint.c:860
     f2fs_fill_super+0x2d42/0x8110 fs/f2fs/super.c:2883
     mount_bdev+0x314/0x3e0 fs/super.c:1344
     f2fs_mount+0x3c/0x50 fs/f2fs/super.c:3133
     legacy_get_tree+0x131/0x460 fs/fs_context.c:729
     vfs_get_tree+0x1cb/0x5c0 fs/super.c:1743
     do_new_mount fs/namespace.c:2603 [inline]
     do_mount+0x6f2/0x1e20 fs/namespace.c:2927
     ksys_mount+0x12d/0x140 fs/namespace.c:3143
     __do_sys_mount fs/namespace.c:3157 [inline]
     __se_sys_mount fs/namespace.c:3154 [inline]
     __x64_sys_mount+0xbe/0x150 fs/namespace.c:3154
     do_syscall_64+0x1b9/0x820 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    RIP: 0033:0x45943a
    Code: b8 a6 00 00 00 0f 05 48 3d 01 f0 ff ff 0f 83 bd 8a fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 49 89 ca b8 a5 00 00 00 0f 05 <48> 3d 01 f0 ff ff 0f 83 9a 8a fb ff c3 66 0f 1f 84 00 00 00 00 00
    RSP: 002b:00007f36a61d4a88 EFLAGS: 00000206 ORIG_RAX: 00000000000000a5
    RAX: ffffffffffffffda RBX: 00007f36a61d4b30 RCX: 000000000045943a
    RDX: 00007f36a61d4ad0 RSI: 0000000020000100 RDI: 00007f36a61d4af0
    RBP: 0000000020000100 R08: 00007f36a61d4b30 R09: 00007f36a61d4ad0
    R10: 0000000000000000 R11: 0000000000000206 R12: 0000000000000013
    R13: 0000000000000000 R14: 00000000004c8ea0 R15: 0000000000000000
    Modules linked in:
    Dumping ftrace buffer:
       (ftrace buffer empty)
    ---[ end trace bd8550c129352286 ]---
    RIP: 0010:__read_once_size include/linux/compiler.h:188 [inline]
    RIP: 0010:compound_head include/linux/page-flags.h:142 [inline]
    RIP: 0010:PageLocked include/linux/page-flags.h:272 [inline]
    RIP: 0010:f2fs_put_page fs/f2fs/f2fs.h:2011 [inline]
    RIP: 0010:validate_checkpoint+0x66d/0xec0 fs/f2fs/checkpoint.c:835
    Code: e8 58 05 7f fe 4c 8d 6b 80 4d 8d 74 24 08 48 b8 00 00 00 00 00 fc ff df 4c 89 ea 48 c1 ea 03 c6 04 02 00 4c 89 f2 48 c1 ea 03 <80> 3c 02 00 0f 85 f4 06 00 00 4c 89 ea 4d 8b 7c 24 08 48 b8 00 00
    RSP: 0018:ffff8801937cebe8 EFLAGS: 00010246
    RAX: dffffc0000000000 RBX: ffff8801937cef30 RCX: ffffc90006035000
    RDX: 0000000000000000 RSI: ffffffff82fd9658 RDI: 0000000000000005
    netlink: 65342 bytes leftover after parsing attributes in process `syz-executor4'.
    RBP: ffff8801937cef58 R08: ffff8801ab254700 R09: fffff94000d9e026
    openvswitch: netlink: Message has 8 unknown bytes.
    R10: fffff94000d9e026 R11: ffffea0006cf0137 R12: fffffffffffffffb
    R13: ffff8801937ceeb0 R14: 0000000000000003 R15: ffff880193419b40
    FS:  00007f36a61d5700(0000) GS:ffff8801db100000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007fc04ff93000 CR3: 00000001d0562000 CR4: 00000000001426e0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    
    In validate_checkpoint(), if we failed to call get_checkpoint_version(), we
    will pass returned invalid page pointer into f2fs_put_page, cause accessing
    invalid memory, this patch tries to handle error path correctly to fix this
    issue.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 551c1d1984ec..31561026ac9a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -780,6 +780,7 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 
 	crc_offset = le32_to_cpu((*cp_block)->checksum_offset);
 	if (crc_offset > (blk_size - sizeof(__le32))) {
+		f2fs_put_page(*cp_page, 1);
 		f2fs_msg(sbi->sb, KERN_WARNING,
 			"invalid crc_offset: %zu", crc_offset);
 		return -EINVAL;
@@ -787,6 +788,7 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 
 	crc = cur_cp_crc(*cp_block);
 	if (!f2fs_crc_valid(sbi, crc, *cp_block, crc_offset)) {
+		f2fs_put_page(*cp_page, 1);
 		f2fs_msg(sbi->sb, KERN_WARNING, "invalid crc value");
 		return -EINVAL;
 	}
@@ -806,14 +808,14 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	err = get_checkpoint_version(sbi, cp_addr, &cp_block,
 					&cp_page_1, version);
 	if (err)
-		goto invalid_cp1;
+		return NULL;
 
 	if (le32_to_cpu(cp_block->cp_pack_total_block_count) >
 					sbi->blocks_per_seg) {
 		f2fs_msg(sbi->sb, KERN_WARNING,
 			"invalid cp_pack_total_block_count:%u",
 			le32_to_cpu(cp_block->cp_pack_total_block_count));
-		goto invalid_cp1;
+		goto invalid_cp;
 	}
 	pre_version = *version;
 
@@ -821,7 +823,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	err = get_checkpoint_version(sbi, cp_addr, &cp_block,
 					&cp_page_2, version);
 	if (err)
-		goto invalid_cp2;
+		goto invalid_cp;
 	cur_version = *version;
 
 	if (cur_version == pre_version) {
@@ -829,9 +831,8 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 		f2fs_put_page(cp_page_2, 1);
 		return cp_page_1;
 	}
-invalid_cp2:
 	f2fs_put_page(cp_page_2, 1);
-invalid_cp1:
+invalid_cp:
 	f2fs_put_page(cp_page_1, 1);
 	return NULL;
 }

commit 50fa53eccf9f911a5b435248a2b0bd484fd82e5e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Aug 2 23:03:19 2018 +0800

    f2fs: fix to avoid broken of dnode block list
    
    f2fs recovery flow is relying on dnode block link list, it means fsynced
    file recovery depends on previous dnode's persistence in the list, so
    during fsync() we should wait on all regular inode's dnode writebacked
    before issuing flush.
    
    By this way, we can avoid dnode block list being broken by out-of-order
    IO submission due to IO scheduler or driver.
    
    Sheng Yong helps to do the test with this patch:
    
    Target:/data (f2fs, -)
    64MB / 32768KB / 4KB / 8
    
    1 / PERSIST / Index
    
    Base:
            SEQ-RD(MB/s)    SEQ-WR(MB/s)    RND-RD(IOPS)    RND-WR(IOPS)    Insert(TPS)     Update(TPS)     Delete(TPS)
    1       867.82          204.15          41440.03        41370.54        680.8           1025.94         1031.08
    2       871.87          205.87          41370.3         40275.2         791.14          1065.84         1101.7
    3       866.52          205.69          41795.67        40596.16        694.69          1037.16         1031.48
    Avg     868.7366667     205.2366667     41535.33333     40747.3         722.21          1042.98         1054.753333
    
    After:
            SEQ-RD(MB/s)    SEQ-WR(MB/s)    RND-RD(IOPS)    RND-WR(IOPS)    Insert(TPS)     Update(TPS)     Delete(TPS)
    1       798.81          202.5           41143           40613.87        602.71          838.08          913.83
    2       805.79          206.47          40297.2         41291.46        604.44          840.75          924.27
    3       814.83          206.17          41209.57        40453.62        602.85          834.66          927.91
    Avg     806.4766667     205.0466667     40883.25667     40786.31667     603.3333333     837.83          922.0033333
    
    Patched/Original:
            0.928332713     0.999074239     0.984300676     1.000957528     0.835398753     0.803303994     0.874141189
    
    It looks like atomic write will suffer performance regression.
    
    I suspect that the criminal is that we forcing to wait all dnode being in
    storage cache before we issue PREFLUSH+FUA.
    
    BTW, will commit ("f2fs: don't need to wait for node writes for atomic write")
    cause the problem: we will lose data of last transaction after SPO, even if
    atomic write return no error:
    
    - atomic_open();
    - write() P1, P2, P3;
    - atomic_commit();
     - writeback data: P1, P2, P3;
     - writeback node: N1, N2, N3;  <--- If N1, N2 is not writebacked, N3 with fsync_mark is
    writebacked, In SPOR, we won't find N3 since node chain is broken, turns out that losing
    last transaction.
     - preflush + fua;
    - power-cut
    
    If we don't wait dnode writeback for atomic_write:
    
            SEQ-RD(MB/s)    SEQ-WR(MB/s)    RND-RD(IOPS)    RND-WR(IOPS)    Insert(TPS)     Update(TPS)     Delete(TPS)
    1       779.91          206.03          41621.5         40333.16        716.9           1038.21         1034.85
    2       848.51          204.35          40082.44        39486.17        791.83          1119.96         1083.77
    3       772.12          206.27          41335.25        41599.65        723.29          1055.07         971.92
    Avg     800.18          205.55          41013.06333     40472.99333     744.0066667     1071.08         1030.18
    
    Patched/Original:
            0.92108464      1.001526693     0.987425886     0.993268102     1.030180511     1.026942031     0.976702294
    
    SQLite's performance recovers.
    
    Jaegeuk:
    "Practically, I don't see db corruption becase of this. We can excuse to lose
    the last transaction."
    
    Finally, we decide to keep original implementation of atomic write interface
    sematics that we don't wait all dnode writeback before preflush+fua submission.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 334c6f90eaf1..551c1d1984ec 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1161,7 +1161,7 @@ static void unblock_operations(struct f2fs_sb_info *sbi)
 	f2fs_unlock_all(sbi);
 }
 
-static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
+void f2fs_wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 {
 	DEFINE_WAIT(wait);
 
@@ -1397,7 +1397,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
 
 	/* wait for previous submitted meta pages writeback */
-	wait_on_all_pages_writeback(sbi);
+	f2fs_wait_on_all_pages_writeback(sbi);
 
 	/* flush all device cache */
 	err = f2fs_flush_device_cache(sbi);
@@ -1406,7 +1406,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* barrier and flush checkpoint cp pack 2 page if it can */
 	commit_checkpoint(sbi, ckpt, start_blk);
-	wait_on_all_pages_writeback(sbi);
+	f2fs_wait_on_all_pages_writeback(sbi);
 
 	/*
 	 * invalidate intermediate page cache borrowed from meta inode
@@ -1418,6 +1418,8 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	f2fs_release_ino_entry(sbi, false);
 
+	f2fs_reset_fsync_node_info(sbi);
+
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 	clear_sbi_flag(sbi, SBI_NEED_CP);
 	__set_cp_next_pack(sbi);

commit e494c2f995d6181d6e29c4927d68e0f295ecf75b
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Aug 1 19:16:11 2018 +0800

    f2fs: fix to do sanity check with cp_pack_start_sum
    
    After fuzzing, cp_pack_start_sum could be corrupted, so current log's
    summary info should be wrong due to loading incorrect summary block.
    Then, if segment's type in current log is exceeded NR_CURSEG_TYPE, it
    can lead accessing invalid dirty_i->dirty_segmap bitmap finally.
    
    Add sanity check for cp_pack_start_sum to fix this issue.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200419
    
    - Reproduce
    
    - Kernel message (f2fs-dev w/ KASAN)
    [ 3117.578432] F2FS-fs (loop0): Invalid log blocks per segment (8)
    
    [ 3117.578445] F2FS-fs (loop0): Can't find valid F2FS filesystem in 2th superblock
    [ 3117.581364] F2FS-fs (loop0): invalid crc_offset: 30716
    [ 3117.583564] WARNING: CPU: 1 PID: 1225 at fs/f2fs/checkpoint.c:90 __get_meta_page+0x448/0x4b0
    [ 3117.583570] Modules linked in: snd_hda_codec_generic snd_hda_intel snd_hda_codec snd_hda_core snd_hwdep snd_pcm snd_timer joydev input_leds serio_raw snd soundcore mac_hid i2c_piix4 ib_iser rdma_cm iw_cm ib_cm ib_core configfs iscsi_tcp libiscsi_tcp libiscsi scsi_transport_iscsi btrfs zstd_decompress zstd_compress xxhash raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c raid1 raid0 multipath linear 8139too qxl ttm drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops drm crct10dif_pclmul crc32_pclmul ghash_clmulni_intel pcbc aesni_intel psmouse aes_x86_64 8139cp crypto_simd cryptd mii glue_helper pata_acpi floppy
    [ 3117.584014] CPU: 1 PID: 1225 Comm: mount Not tainted 4.17.0+ #1
    [ 3117.584017] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
    [ 3117.584022] RIP: 0010:__get_meta_page+0x448/0x4b0
    [ 3117.584023] Code: 00 49 8d bc 24 84 00 00 00 e8 74 54 da ff 41 83 8c 24 84 00 00 00 08 4c 89 f6 4c 89 ef e8 c0 d9 95 00 48 89 ef e8 18 e3 00 00 <0f> 0b f0 80 4d 48 04 e9 0f fe ff ff 0f 0b 48 89 c7 48 89 04 24 e8
    [ 3117.584072] RSP: 0018:ffff88018eb678c0 EFLAGS: 00010286
    [ 3117.584082] RAX: ffff88018f0a6a78 RBX: ffffea0007a46600 RCX: ffffffff9314d1b2
    [ 3117.584085] RDX: ffffffff00000001 RSI: 0000000000000000 RDI: ffff88018f0a6a98
    [ 3117.584087] RBP: ffff88018ebe9980 R08: 0000000000000002 R09: 0000000000000001
    [ 3117.584090] R10: 0000000000000001 R11: ffffed00326e4450 R12: ffff880193722200
    [ 3117.584092] R13: ffff88018ebe9afc R14: 0000000000000206 R15: ffff88018eb67900
    [ 3117.584096] FS:  00007f5694636840(0000) GS:ffff8801f3b00000(0000) knlGS:0000000000000000
    [ 3117.584098] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 3117.584101] CR2: 00000000016f21b8 CR3: 0000000191c22000 CR4: 00000000000006e0
    [ 3117.584112] Call Trace:
    [ 3117.584121]  ? f2fs_set_meta_page_dirty+0x150/0x150
    [ 3117.584127]  ? f2fs_build_segment_manager+0xbf9/0x3190
    [ 3117.584133]  ? f2fs_npages_for_summary_flush+0x75/0x120
    [ 3117.584145]  f2fs_build_segment_manager+0xda8/0x3190
    [ 3117.584151]  ? f2fs_get_valid_checkpoint+0x298/0xa00
    [ 3117.584156]  ? f2fs_flush_sit_entries+0x10e0/0x10e0
    [ 3117.584184]  ? map_id_range_down+0x17c/0x1b0
    [ 3117.584188]  ? __put_user_ns+0x30/0x30
    [ 3117.584206]  ? find_next_bit+0x53/0x90
    [ 3117.584237]  ? cpumask_next+0x16/0x20
    [ 3117.584249]  f2fs_fill_super+0x1948/0x2b40
    [ 3117.584258]  ? f2fs_commit_super+0x1a0/0x1a0
    [ 3117.584279]  ? sget_userns+0x65e/0x690
    [ 3117.584296]  ? set_blocksize+0x88/0x130
    [ 3117.584302]  ? f2fs_commit_super+0x1a0/0x1a0
    [ 3117.584305]  mount_bdev+0x1c0/0x200
    [ 3117.584310]  mount_fs+0x5c/0x190
    [ 3117.584320]  vfs_kern_mount+0x64/0x190
    [ 3117.584330]  do_mount+0x2e4/0x1450
    [ 3117.584343]  ? lockref_put_return+0x130/0x130
    [ 3117.584347]  ? copy_mount_string+0x20/0x20
    [ 3117.584357]  ? kasan_unpoison_shadow+0x31/0x40
    [ 3117.584362]  ? kasan_kmalloc+0xa6/0xd0
    [ 3117.584373]  ? memcg_kmem_put_cache+0x16/0x90
    [ 3117.584377]  ? __kmalloc_track_caller+0x196/0x210
    [ 3117.584383]  ? _copy_from_user+0x61/0x90
    [ 3117.584396]  ? memdup_user+0x3e/0x60
    [ 3117.584401]  ksys_mount+0x7e/0xd0
    [ 3117.584405]  __x64_sys_mount+0x62/0x70
    [ 3117.584427]  do_syscall_64+0x73/0x160
    [ 3117.584440]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [ 3117.584455] RIP: 0033:0x7f5693f14b9a
    [ 3117.584456] Code: 48 8b 0d 01 c3 2b 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 49 89 ca b8 a5 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d ce c2 2b 00 f7 d8 64 89 01 48
    [ 3117.584505] RSP: 002b:00007fff27346488 EFLAGS: 00000206 ORIG_RAX: 00000000000000a5
    [ 3117.584510] RAX: ffffffffffffffda RBX: 00000000016e2030 RCX: 00007f5693f14b9a
    [ 3117.584512] RDX: 00000000016e2210 RSI: 00000000016e3f30 RDI: 00000000016ee040
    [ 3117.584514] RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000013
    [ 3117.584516] R10: 00000000c0ed0000 R11: 0000000000000206 R12: 00000000016ee040
    [ 3117.584519] R13: 00000000016e2210 R14: 0000000000000000 R15: 0000000000000003
    [ 3117.584523] ---[ end trace a8e0d899985faf31 ]---
    [ 3117.685663] F2FS-fs (loop0): f2fs_check_nid_range: out-of-range nid=2, run fsck to fix.
    [ 3117.685673] F2FS-fs (loop0): recover_data: ino = 2 (i_size: recover) recovered = 1, err = 0
    [ 3117.685707] ==================================================================
    [ 3117.685955] BUG: KASAN: slab-out-of-bounds in __remove_dirty_segment+0xdd/0x1e0
    [ 3117.686175] Read of size 8 at addr ffff88018f0a63d0 by task mount/1225
    
    [ 3117.686477] CPU: 0 PID: 1225 Comm: mount Tainted: G        W         4.17.0+ #1
    [ 3117.686481] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
    [ 3117.686483] Call Trace:
    [ 3117.686494]  dump_stack+0x71/0xab
    [ 3117.686512]  print_address_description+0x6b/0x290
    [ 3117.686517]  kasan_report+0x28e/0x390
    [ 3117.686522]  ? __remove_dirty_segment+0xdd/0x1e0
    [ 3117.686527]  __remove_dirty_segment+0xdd/0x1e0
    [ 3117.686532]  locate_dirty_segment+0x189/0x190
    [ 3117.686538]  f2fs_allocate_new_segments+0xa9/0xe0
    [ 3117.686543]  recover_data+0x703/0x2c20
    [ 3117.686547]  ? f2fs_recover_fsync_data+0x48f/0xd50
    [ 3117.686553]  ? ksys_mount+0x7e/0xd0
    [ 3117.686564]  ? policy_nodemask+0x1a/0x90
    [ 3117.686567]  ? policy_node+0x56/0x70
    [ 3117.686571]  ? add_fsync_inode+0xf0/0xf0
    [ 3117.686592]  ? blk_finish_plug+0x44/0x60
    [ 3117.686597]  ? f2fs_ra_meta_pages+0x38b/0x5e0
    [ 3117.686602]  ? find_inode_fast+0xac/0xc0
    [ 3117.686606]  ? f2fs_is_valid_blkaddr+0x320/0x320
    [ 3117.686618]  ? __radix_tree_lookup+0x150/0x150
    [ 3117.686633]  ? dqget+0x670/0x670
    [ 3117.686648]  ? pagecache_get_page+0x29/0x410
    [ 3117.686656]  ? kmem_cache_alloc+0x176/0x1e0
    [ 3117.686660]  ? f2fs_is_valid_blkaddr+0x11d/0x320
    [ 3117.686664]  f2fs_recover_fsync_data+0xc23/0xd50
    [ 3117.686670]  ? f2fs_space_for_roll_forward+0x60/0x60
    [ 3117.686674]  ? rb_insert_color+0x323/0x3d0
    [ 3117.686678]  ? f2fs_recover_orphan_inodes+0xa5/0x700
    [ 3117.686683]  ? proc_register+0x153/0x1d0
    [ 3117.686686]  ? f2fs_remove_orphan_inode+0x10/0x10
    [ 3117.686695]  ? f2fs_attr_store+0x50/0x50
    [ 3117.686700]  ? proc_create_single_data+0x52/0x60
    [ 3117.686707]  f2fs_fill_super+0x1d06/0x2b40
    [ 3117.686728]  ? f2fs_commit_super+0x1a0/0x1a0
    [ 3117.686735]  ? sget_userns+0x65e/0x690
    [ 3117.686740]  ? set_blocksize+0x88/0x130
    [ 3117.686745]  ? f2fs_commit_super+0x1a0/0x1a0
    [ 3117.686748]  mount_bdev+0x1c0/0x200
    [ 3117.686753]  mount_fs+0x5c/0x190
    [ 3117.686758]  vfs_kern_mount+0x64/0x190
    [ 3117.686762]  do_mount+0x2e4/0x1450
    [ 3117.686769]  ? lockref_put_return+0x130/0x130
    [ 3117.686773]  ? copy_mount_string+0x20/0x20
    [ 3117.686777]  ? kasan_unpoison_shadow+0x31/0x40
    [ 3117.686780]  ? kasan_kmalloc+0xa6/0xd0
    [ 3117.686786]  ? memcg_kmem_put_cache+0x16/0x90
    [ 3117.686790]  ? __kmalloc_track_caller+0x196/0x210
    [ 3117.686795]  ? _copy_from_user+0x61/0x90
    [ 3117.686801]  ? memdup_user+0x3e/0x60
    [ 3117.686804]  ksys_mount+0x7e/0xd0
    [ 3117.686809]  __x64_sys_mount+0x62/0x70
    [ 3117.686816]  do_syscall_64+0x73/0x160
    [ 3117.686824]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [ 3117.686829] RIP: 0033:0x7f5693f14b9a
    [ 3117.686830] Code: 48 8b 0d 01 c3 2b 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 49 89 ca b8 a5 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d ce c2 2b 00 f7 d8 64 89 01 48
    [ 3117.686887] RSP: 002b:00007fff27346488 EFLAGS: 00000206 ORIG_RAX: 00000000000000a5
    [ 3117.686892] RAX: ffffffffffffffda RBX: 00000000016e2030 RCX: 00007f5693f14b9a
    [ 3117.686894] RDX: 00000000016e2210 RSI: 00000000016e3f30 RDI: 00000000016ee040
    [ 3117.686896] RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000013
    [ 3117.686899] R10: 00000000c0ed0000 R11: 0000000000000206 R12: 00000000016ee040
    [ 3117.686901] R13: 00000000016e2210 R14: 0000000000000000 R15: 0000000000000003
    
    [ 3117.687005] Allocated by task 1225:
    [ 3117.687152]  kasan_kmalloc+0xa6/0xd0
    [ 3117.687157]  kmem_cache_alloc_trace+0xfd/0x200
    [ 3117.687161]  f2fs_build_segment_manager+0x2d09/0x3190
    [ 3117.687165]  f2fs_fill_super+0x1948/0x2b40
    [ 3117.687168]  mount_bdev+0x1c0/0x200
    [ 3117.687171]  mount_fs+0x5c/0x190
    [ 3117.687174]  vfs_kern_mount+0x64/0x190
    [ 3117.687177]  do_mount+0x2e4/0x1450
    [ 3117.687180]  ksys_mount+0x7e/0xd0
    [ 3117.687182]  __x64_sys_mount+0x62/0x70
    [ 3117.687186]  do_syscall_64+0x73/0x160
    [ 3117.687190]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    [ 3117.687285] Freed by task 19:
    [ 3117.687412]  __kasan_slab_free+0x137/0x190
    [ 3117.687416]  kfree+0x8b/0x1b0
    [ 3117.687460]  ttm_bo_man_put_node+0x61/0x80 [ttm]
    [ 3117.687476]  ttm_bo_cleanup_refs+0x15f/0x250 [ttm]
    [ 3117.687492]  ttm_bo_delayed_delete+0x2f0/0x300 [ttm]
    [ 3117.687507]  ttm_bo_delayed_workqueue+0x17/0x50 [ttm]
    [ 3117.687528]  process_one_work+0x2f9/0x740
    [ 3117.687531]  worker_thread+0x78/0x6b0
    [ 3117.687541]  kthread+0x177/0x1c0
    [ 3117.687545]  ret_from_fork+0x35/0x40
    
    [ 3117.687638] The buggy address belongs to the object at ffff88018f0a6300
                    which belongs to the cache kmalloc-192 of size 192
    [ 3117.688014] The buggy address is located 16 bytes to the right of
                    192-byte region [ffff88018f0a6300, ffff88018f0a63c0)
    [ 3117.688382] The buggy address belongs to the page:
    [ 3117.688554] page:ffffea00063c2980 count:1 mapcount:0 mapping:ffff8801f3403180 index:0x0
    [ 3117.688788] flags: 0x17fff8000000100(slab)
    [ 3117.688944] raw: 017fff8000000100 ffffea00063c2840 0000000e0000000e ffff8801f3403180
    [ 3117.689166] raw: 0000000000000000 0000000080100010 00000001ffffffff 0000000000000000
    [ 3117.689386] page dumped because: kasan: bad access detected
    
    [ 3117.689653] Memory state around the buggy address:
    [ 3117.689816]  ffff88018f0a6280: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3117.690027]  ffff88018f0a6300: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [ 3117.690239] >ffff88018f0a6380: 00 00 fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [ 3117.690448]                                                  ^
    [ 3117.690644]  ffff88018f0a6400: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [ 3117.690868]  ffff88018f0a6480: 00 00 fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [ 3117.691077] ==================================================================
    [ 3117.691290] Disabling lock debugging due to kernel taint
    [ 3117.693893] BUG: unable to handle kernel NULL pointer dereference at 0000000000000000
    [ 3117.694120] PGD 80000001f01bc067 P4D 80000001f01bc067 PUD 1d9638067 PMD 0
    [ 3117.694338] Oops: 0002 [#1] SMP KASAN PTI
    [ 3117.694490] CPU: 1 PID: 1225 Comm: mount Tainted: G    B   W         4.17.0+ #1
    [ 3117.694703] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
    [ 3117.695073] RIP: 0010:__remove_dirty_segment+0xe2/0x1e0
    [ 3117.695246] Code: c4 48 89 c7 e8 cf bb d7 ff 45 0f b6 24 24 41 83 e4 3f 44 88 64 24 07 41 83 e4 3f 4a 8d 7c e3 08 e8 b3 bc d7 ff 4a 8b 4c e3 08 <f0> 4c 0f b3 29 0f 82 94 00 00 00 48 8d bd 20 04 00 00 e8 97 bb d7
    [ 3117.695793] RSP: 0018:ffff88018eb67638 EFLAGS: 00010292
    [ 3117.695969] RAX: 0000000000000000 RBX: ffff88018f0a6300 RCX: 0000000000000000
    [ 3117.696182] RDX: 0000000000000000 RSI: 0000000000000297 RDI: 0000000000000297
    [ 3117.696391] RBP: ffff88018ebe9980 R08: ffffed003e743ebb R09: ffffed003e743ebb
    [ 3117.696604] R10: 0000000000000001 R11: ffffed003e743eba R12: 0000000000000019
    [ 3117.696813] R13: 0000000000000014 R14: 0000000000000320 R15: ffff88018ebe99e0
    [ 3117.697032] FS:  00007f5694636840(0000) GS:ffff8801f3b00000(0000) knlGS:0000000000000000
    [ 3117.697280] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 3117.702357] CR2: 00007fe89bb1a000 CR3: 0000000191c22000 CR4: 00000000000006e0
    [ 3117.707235] Call Trace:
    [ 3117.712077]  locate_dirty_segment+0x189/0x190
    [ 3117.716891]  f2fs_allocate_new_segments+0xa9/0xe0
    [ 3117.721617]  recover_data+0x703/0x2c20
    [ 3117.726316]  ? f2fs_recover_fsync_data+0x48f/0xd50
    [ 3117.730957]  ? ksys_mount+0x7e/0xd0
    [ 3117.735573]  ? policy_nodemask+0x1a/0x90
    [ 3117.740198]  ? policy_node+0x56/0x70
    [ 3117.744829]  ? add_fsync_inode+0xf0/0xf0
    [ 3117.749487]  ? blk_finish_plug+0x44/0x60
    [ 3117.754152]  ? f2fs_ra_meta_pages+0x38b/0x5e0
    [ 3117.758831]  ? find_inode_fast+0xac/0xc0
    [ 3117.763448]  ? f2fs_is_valid_blkaddr+0x320/0x320
    [ 3117.768046]  ? __radix_tree_lookup+0x150/0x150
    [ 3117.772603]  ? dqget+0x670/0x670
    [ 3117.777159]  ? pagecache_get_page+0x29/0x410
    [ 3117.781648]  ? kmem_cache_alloc+0x176/0x1e0
    [ 3117.786067]  ? f2fs_is_valid_blkaddr+0x11d/0x320
    [ 3117.790476]  f2fs_recover_fsync_data+0xc23/0xd50
    [ 3117.794790]  ? f2fs_space_for_roll_forward+0x60/0x60
    [ 3117.799086]  ? rb_insert_color+0x323/0x3d0
    [ 3117.803304]  ? f2fs_recover_orphan_inodes+0xa5/0x700
    [ 3117.807563]  ? proc_register+0x153/0x1d0
    [ 3117.811766]  ? f2fs_remove_orphan_inode+0x10/0x10
    [ 3117.815947]  ? f2fs_attr_store+0x50/0x50
    [ 3117.820087]  ? proc_create_single_data+0x52/0x60
    [ 3117.824262]  f2fs_fill_super+0x1d06/0x2b40
    [ 3117.828367]  ? f2fs_commit_super+0x1a0/0x1a0
    [ 3117.832432]  ? sget_userns+0x65e/0x690
    [ 3117.836500]  ? set_blocksize+0x88/0x130
    [ 3117.840501]  ? f2fs_commit_super+0x1a0/0x1a0
    [ 3117.844420]  mount_bdev+0x1c0/0x200
    [ 3117.848275]  mount_fs+0x5c/0x190
    [ 3117.852053]  vfs_kern_mount+0x64/0x190
    [ 3117.855810]  do_mount+0x2e4/0x1450
    [ 3117.859441]  ? lockref_put_return+0x130/0x130
    [ 3117.862996]  ? copy_mount_string+0x20/0x20
    [ 3117.866417]  ? kasan_unpoison_shadow+0x31/0x40
    [ 3117.869719]  ? kasan_kmalloc+0xa6/0xd0
    [ 3117.872948]  ? memcg_kmem_put_cache+0x16/0x90
    [ 3117.876121]  ? __kmalloc_track_caller+0x196/0x210
    [ 3117.879333]  ? _copy_from_user+0x61/0x90
    [ 3117.882467]  ? memdup_user+0x3e/0x60
    [ 3117.885604]  ksys_mount+0x7e/0xd0
    [ 3117.888700]  __x64_sys_mount+0x62/0x70
    [ 3117.891742]  do_syscall_64+0x73/0x160
    [ 3117.894692]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [ 3117.897669] RIP: 0033:0x7f5693f14b9a
    [ 3117.900563] Code: 48 8b 0d 01 c3 2b 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 49 89 ca b8 a5 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d ce c2 2b 00 f7 d8 64 89 01 48
    [ 3117.906922] RSP: 002b:00007fff27346488 EFLAGS: 00000206 ORIG_RAX: 00000000000000a5
    [ 3117.910159] RAX: ffffffffffffffda RBX: 00000000016e2030 RCX: 00007f5693f14b9a
    [ 3117.913469] RDX: 00000000016e2210 RSI: 00000000016e3f30 RDI: 00000000016ee040
    [ 3117.916764] RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000013
    [ 3117.920071] R10: 00000000c0ed0000 R11: 0000000000000206 R12: 00000000016ee040
    [ 3117.923393] R13: 00000000016e2210 R14: 0000000000000000 R15: 0000000000000003
    [ 3117.926680] Modules linked in: snd_hda_codec_generic snd_hda_intel snd_hda_codec snd_hda_core snd_hwdep snd_pcm snd_timer joydev input_leds serio_raw snd soundcore mac_hid i2c_piix4 ib_iser rdma_cm iw_cm ib_cm ib_core configfs iscsi_tcp libiscsi_tcp libiscsi scsi_transport_iscsi btrfs zstd_decompress zstd_compress xxhash raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c raid1 raid0 multipath linear 8139too qxl ttm drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops drm crct10dif_pclmul crc32_pclmul ghash_clmulni_intel pcbc aesni_intel psmouse aes_x86_64 8139cp crypto_simd cryptd mii glue_helper pata_acpi floppy
    [ 3117.949979] CR2: 0000000000000000
    [ 3117.954283] ---[ end trace a8e0d899985faf32 ]---
    [ 3117.958575] RIP: 0010:__remove_dirty_segment+0xe2/0x1e0
    [ 3117.962810] Code: c4 48 89 c7 e8 cf bb d7 ff 45 0f b6 24 24 41 83 e4 3f 44 88 64 24 07 41 83 e4 3f 4a 8d 7c e3 08 e8 b3 bc d7 ff 4a 8b 4c e3 08 <f0> 4c 0f b3 29 0f 82 94 00 00 00 48 8d bd 20 04 00 00 e8 97 bb d7
    [ 3117.971789] RSP: 0018:ffff88018eb67638 EFLAGS: 00010292
    [ 3117.976333] RAX: 0000000000000000 RBX: ffff88018f0a6300 RCX: 0000000000000000
    [ 3117.980926] RDX: 0000000000000000 RSI: 0000000000000297 RDI: 0000000000000297
    [ 3117.985497] RBP: ffff88018ebe9980 R08: ffffed003e743ebb R09: ffffed003e743ebb
    [ 3117.990098] R10: 0000000000000001 R11: ffffed003e743eba R12: 0000000000000019
    [ 3117.994761] R13: 0000000000000014 R14: 0000000000000320 R15: ffff88018ebe99e0
    [ 3117.999392] FS:  00007f5694636840(0000) GS:ffff8801f3b00000(0000) knlGS:0000000000000000
    [ 3118.004096] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 3118.008816] CR2: 00007fe89bb1a000 CR3: 0000000191c22000 CR4: 00000000000006e0
    
    - Location
    https://elixir.bootlin.com/linux/v4.18-rc3/source/fs/f2fs/segment.c#L775
                    if (test_and_clear_bit(segno, dirty_i->dirty_segmap[t]))
                            dirty_i->nr_dirty[t]--;
    Here dirty_i->dirty_segmap[t] can be NULL which leads to crash in test_and_clear_bit()
    
    Reported-by Wen Xu <wen.xu@gatech.edu>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 1425aced91ec..334c6f90eaf1 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -880,15 +880,15 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	cp_block = (struct f2fs_checkpoint *)page_address(cur_page);
 	memcpy(sbi->ckpt, cp_block, blk_size);
 
-	/* Sanity checking of checkpoint */
-	if (f2fs_sanity_check_ckpt(sbi))
-		goto free_fail_no_cp;
-
 	if (cur_page == cp1)
 		sbi->cur_cp_pack = 1;
 	else
 		sbi->cur_cp_pack = 2;
 
+	/* Sanity checking of checkpoint */
+	if (f2fs_sanity_check_ckpt(sbi))
+		goto free_fail_no_cp;
+
 	if (cp_blks <= 1)
 		goto done;
 

commit 18767e62639622554c3642a6e3f3b0ca19bc1d9d
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Jul 27 18:15:13 2018 +0800

    f2fs: don't keep meta pages used for block migration
    
    For migration of encrypted inode's block, we load data of encrypted block
    into meta inode's page cache, after checkpoint, those all intermediate
    pages should be clean, and no one will read them again, so let's just
    release them for more memory.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3f11b3abd766..1425aced91ec 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1408,6 +1408,14 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	commit_checkpoint(sbi, ckpt, start_blk);
 	wait_on_all_pages_writeback(sbi);
 
+	/*
+	 * invalidate intermediate page cache borrowed from meta inode
+	 * which are used for migration of encrypted inode's blocks.
+	 */
+	if (f2fs_sb_has_encrypt(sbi->sb))
+		invalidate_mapping_pages(META_MAPPING(sbi),
+				MAIN_BLKADDR(sbi), MAX_BLKADDR(sbi) - 1);
+
 	f2fs_release_ino_entry(sbi, false);
 
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);

commit 76cf05d79c9ef02d5afa77abaf9b109afde794c4
Author: Sheng Yong <shengyong1@huawei.com>
Date:   Thu Jul 26 19:24:25 2018 +0800

    f2fs: quota: fix incorrect comments
    
    Signed-off-by: Sheng Yong <shengyong1@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c5fd318c06d2..3f11b3abd766 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -661,7 +661,10 @@ int f2fs_recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	/* Needed for iput() to work correctly and not trash data */
 	sbi->sb->s_flags |= SB_ACTIVE;
 
-	/* Turn on quotas so that they are updated correctly */
+	/*
+	 * Turn on quotas which were not enabled for read-only mounts if
+	 * filesystem has quota feature, so that they are updated correctly.
+	 */
 	quota_enabled = f2fs_enable_quota_files(sbi, s_flags & SB_RDONLY);
 #endif
 

commit 7735730d39d75e70476c1b01435b9b1f41637f0e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Jul 17 00:02:17 2018 +0800

    f2fs: fix to propagate error from __get_meta_page()
    
    If caller of __get_meta_page() can handle error, let's propagate error
    from __get_meta_page().
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b766f78b05f9..c5fd318c06d2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -71,6 +71,7 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 		.encrypted_page = NULL,
 		.is_meta = is_meta,
 	};
+	int err;
 
 	if (unlikely(!is_meta))
 		fio.op_flags &= ~REQ_META;
@@ -85,11 +86,10 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 
 	fio.page = page;
 
-	if (f2fs_submit_page_bio(&fio)) {
-		memset(page_address(page), 0, PAGE_SIZE);
-		f2fs_stop_checkpoint(sbi, false);
-		f2fs_bug_on(sbi, 1);
-		return page;
+	err = f2fs_submit_page_bio(&fio);
+	if (err) {
+		f2fs_put_page(page, 1);
+		return ERR_PTR(err);
 	}
 
 	lock_page(page);
@@ -98,14 +98,9 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 		goto repeat;
 	}
 
-	/*
-	 * if there is any IO error when accessing device, make our filesystem
-	 * readonly and make sure do not write checkpoint with non-uptodate
-	 * meta page.
-	 */
 	if (unlikely(!PageUptodate(page))) {
-		memset(page_address(page), 0, PAGE_SIZE);
-		f2fs_stop_checkpoint(sbi, false);
+		f2fs_put_page(page, 1);
+		return ERR_PTR(-EIO);
 	}
 out:
 	return page;
@@ -116,6 +111,25 @@ struct page *f2fs_get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return __get_meta_page(sbi, index, true);
 }
 
+struct page *f2fs_get_meta_page_nofail(struct f2fs_sb_info *sbi, pgoff_t index)
+{
+	struct page *page;
+	int count = 0;
+
+retry:
+	page = __get_meta_page(sbi, index, true);
+	if (IS_ERR(page)) {
+		if (PTR_ERR(page) == -EIO &&
+				++count <= DEFAULT_RETRY_IO_COUNT)
+			goto retry;
+
+		f2fs_stop_checkpoint(sbi, false);
+		f2fs_bug_on(sbi, 1);
+	}
+
+	return page;
+}
+
 /* for POR only */
 struct page *f2fs_get_tmp_page(struct f2fs_sb_info *sbi, pgoff_t index)
 {
@@ -607,7 +621,9 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	/* truncate all the data during iput */
 	iput(inode);
 
-	f2fs_get_node_info(sbi, ino, &ni);
+	err = f2fs_get_node_info(sbi, ino, &ni);
+	if (err)
+		goto err_out;
 
 	/* ENOMEM was fully retried in f2fs_evict_inode. */
 	if (ni.blk_addr != NULL_ADDR) {
@@ -655,9 +671,15 @@ int f2fs_recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	f2fs_ra_meta_pages(sbi, start_blk, orphan_blocks, META_CP, true);
 
 	for (i = 0; i < orphan_blocks; i++) {
-		struct page *page = f2fs_get_meta_page(sbi, start_blk + i);
+		struct page *page;
 		struct f2fs_orphan_block *orphan_blk;
 
+		page = f2fs_get_meta_page(sbi, start_blk + i);
+		if (IS_ERR(page)) {
+			err = PTR_ERR(page);
+			goto out;
+		}
+
 		orphan_blk = (struct f2fs_orphan_block *)page_address(page);
 		for (j = 0; j < le32_to_cpu(orphan_blk->entry_count); j++) {
 			nid_t ino = le32_to_cpu(orphan_blk->ino[j]);
@@ -748,6 +770,9 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 	__u32 crc = 0;
 
 	*cp_page = f2fs_get_meta_page(sbi, cp_addr);
+	if (IS_ERR(*cp_page))
+		return PTR_ERR(*cp_page);
+
 	*cp_block = (struct f2fs_checkpoint *)page_address(*cp_page);
 
 	crc_offset = le32_to_cpu((*cp_block)->checksum_offset);
@@ -873,6 +898,8 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 		unsigned char *ckpt = (unsigned char *)sbi->ckpt;
 
 		cur_page = f2fs_get_meta_page(sbi, cp_blk_no + i);
+		if (IS_ERR(cur_page))
+			goto free_fail_no_cp;
 		sit_bitmap_ptr = page_address(cur_page);
 		memcpy(ckpt + i * blk_size, sit_bitmap_ptr, blk_size);
 		f2fs_put_page(cur_page, 1);

commit c9b60788fc760d136211853f10ce73dc152d1f4a
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Aug 1 19:13:44 2018 +0800

    f2fs: fix to do sanity check with block address in main area
    
    This patch add to do sanity check with below field:
    - cp_pack_total_block_count
    - blkaddr of data/node
    - extent info
    
    - Overview
    BUG() in verify_block_addr() when writing to a corrupted f2fs image
    
    - Reproduce (4.18 upstream kernel)
    
    - POC (poc.c)
    
    static void activity(char *mpoint) {
    
      char *foo_bar_baz;
      int err;
    
      static int buf[8192];
      memset(buf, 0, sizeof(buf));
    
      err = asprintf(&foo_bar_baz, "%s/foo/bar/baz", mpoint);
    
      int fd = open(foo_bar_baz, O_RDWR | O_TRUNC, 0777);
      if (fd >= 0) {
        write(fd, (char *)buf, sizeof(buf));
        fdatasync(fd);
        close(fd);
      }
    }
    
    int main(int argc, char *argv[]) {
      activity(argv[1]);
      return 0;
    }
    
    - Kernel message
    [  689.349473] F2FS-fs (loop0): Mounted with checkpoint version = 3
    [  699.728662] WARNING: CPU: 0 PID: 1309 at fs/f2fs/segment.c:2860 f2fs_inplace_write_data+0x232/0x240
    [  699.728670] Modules linked in: snd_hda_codec_generic snd_hda_intel snd_hda_codec snd_hwdep snd_hda_core snd_pcm snd_timer snd mac_hid i2c_piix4 soundcore ib_iser rdma_cm iw_cm ib_cm ib_core iscsi_tcp libiscsi_tcp libiscsi scsi_transport_iscsi raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx raid1 raid0 multipath linear 8139too crct10dif_pclmul crc32_pclmul qxl drm_kms_helper syscopyarea aesni_intel sysfillrect sysimgblt fb_sys_fops ttm drm aes_x86_64 crypto_simd cryptd 8139cp glue_helper mii pata_acpi floppy
    [  699.729056] CPU: 0 PID: 1309 Comm: a.out Not tainted 4.18.0-rc1+ #4
    [  699.729064] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
    [  699.729074] RIP: 0010:f2fs_inplace_write_data+0x232/0x240
    [  699.729076] Code: ff e9 cf fe ff ff 49 8d 7d 10 e8 39 45 ad ff 4d 8b 7d 10 be 04 00 00 00 49 8d 7f 48 e8 07 49 ad ff 45 8b 7f 48 e9 fb fe ff ff <0f> 0b f0 41 80 4d 48 04 e9 65 fe ff ff 90 66 66 66 66 90 55 48 8d
    [  699.729130] RSP: 0018:ffff8801f43af568 EFLAGS: 00010202
    [  699.729139] RAX: 000000000000003f RBX: ffff8801f43af7b8 RCX: ffffffffb88c9113
    [  699.729142] RDX: 0000000000000003 RSI: dffffc0000000000 RDI: ffff8802024e5540
    [  699.729144] RBP: ffff8801f43af590 R08: 0000000000000009 R09: ffffffffffffffe8
    [  699.729147] R10: 0000000000000001 R11: ffffed0039b0596a R12: ffff8802024e5540
    [  699.729149] R13: ffff8801f0335500 R14: ffff8801e3e7a700 R15: ffff8801e1ee4450
    [  699.729154] FS:  00007f9bf97f5700(0000) GS:ffff8801f6e00000(0000) knlGS:0000000000000000
    [  699.729156] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  699.729159] CR2: 00007f9bf925d170 CR3: 00000001f0c34000 CR4: 00000000000006f0
    [  699.729171] Call Trace:
    [  699.729192]  f2fs_do_write_data_page+0x2e2/0xe00
    [  699.729203]  ? f2fs_should_update_outplace+0xd0/0xd0
    [  699.729238]  ? memcg_drain_all_list_lrus+0x280/0x280
    [  699.729269]  ? __radix_tree_replace+0xa3/0x120
    [  699.729276]  __write_data_page+0x5c7/0xe30
    [  699.729291]  ? kasan_check_read+0x11/0x20
    [  699.729310]  ? page_mapped+0x8a/0x110
    [  699.729321]  ? page_mkclean+0xe9/0x160
    [  699.729327]  ? f2fs_do_write_data_page+0xe00/0xe00
    [  699.729331]  ? invalid_page_referenced_vma+0x130/0x130
    [  699.729345]  ? clear_page_dirty_for_io+0x332/0x450
    [  699.729351]  f2fs_write_cache_pages+0x4ca/0x860
    [  699.729358]  ? __write_data_page+0xe30/0xe30
    [  699.729374]  ? percpu_counter_add_batch+0x22/0xa0
    [  699.729380]  ? kasan_check_write+0x14/0x20
    [  699.729391]  ? _raw_spin_lock+0x17/0x40
    [  699.729403]  ? f2fs_mark_inode_dirty_sync.part.18+0x16/0x30
    [  699.729413]  ? iov_iter_advance+0x113/0x640
    [  699.729418]  ? f2fs_write_end+0x133/0x2e0
    [  699.729423]  ? balance_dirty_pages_ratelimited+0x239/0x640
    [  699.729428]  f2fs_write_data_pages+0x329/0x520
    [  699.729433]  ? generic_perform_write+0x250/0x320
    [  699.729438]  ? f2fs_write_cache_pages+0x860/0x860
    [  699.729454]  ? current_time+0x110/0x110
    [  699.729459]  ? f2fs_preallocate_blocks+0x1ef/0x370
    [  699.729464]  do_writepages+0x37/0xb0
    [  699.729468]  ? f2fs_write_cache_pages+0x860/0x860
    [  699.729472]  ? do_writepages+0x37/0xb0
    [  699.729478]  __filemap_fdatawrite_range+0x19a/0x1f0
    [  699.729483]  ? delete_from_page_cache_batch+0x4e0/0x4e0
    [  699.729496]  ? __vfs_write+0x2b2/0x410
    [  699.729501]  file_write_and_wait_range+0x66/0xb0
    [  699.729506]  f2fs_do_sync_file+0x1f9/0xd90
    [  699.729511]  ? truncate_partial_data_page+0x290/0x290
    [  699.729521]  ? __sb_end_write+0x30/0x50
    [  699.729526]  ? vfs_write+0x20f/0x260
    [  699.729530]  f2fs_sync_file+0x9a/0xb0
    [  699.729534]  ? f2fs_do_sync_file+0xd90/0xd90
    [  699.729548]  vfs_fsync_range+0x68/0x100
    [  699.729554]  ? __fget_light+0xc9/0xe0
    [  699.729558]  do_fsync+0x3d/0x70
    [  699.729562]  __x64_sys_fdatasync+0x24/0x30
    [  699.729585]  do_syscall_64+0x78/0x170
    [  699.729595]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [  699.729613] RIP: 0033:0x7f9bf930d800
    [  699.729615] Code: 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 83 3d 49 bf 2c 00 00 75 10 b8 4b 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 31 c3 48 83 ec 08 e8 be 78 01 00 48 89 04 24
    [  699.729668] RSP: 002b:00007ffee3606c68 EFLAGS: 00000246 ORIG_RAX: 000000000000004b
    [  699.729673] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f9bf930d800
    [  699.729675] RDX: 0000000000008000 RSI: 00000000006010a0 RDI: 0000000000000003
    [  699.729678] RBP: 00007ffee3606ca0 R08: 0000000001503010 R09: 0000000000000000
    [  699.729680] R10: 00000000000002e8 R11: 0000000000000246 R12: 0000000000400610
    [  699.729683] R13: 00007ffee3606da0 R14: 0000000000000000 R15: 0000000000000000
    [  699.729687] ---[ end trace 4ce02f25ff7d3df5 ]---
    [  699.729782] ------------[ cut here ]------------
    [  699.729785] kernel BUG at fs/f2fs/segment.h:654!
    [  699.731055] invalid opcode: 0000 [#1] SMP KASAN PTI
    [  699.732104] CPU: 0 PID: 1309 Comm: a.out Tainted: G        W         4.18.0-rc1+ #4
    [  699.733684] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
    [  699.735611] RIP: 0010:f2fs_submit_page_bio+0x29b/0x730
    [  699.736649] Code: 54 49 8d bd 18 04 00 00 e8 b2 59 af ff 41 8b 8d 18 04 00 00 8b 45 b8 41 d3 e6 44 01 f0 4c 8d 73 14 41 39 c7 0f 82 37 fe ff ff <0f> 0b 65 8b 05 2c 04 77 47 89 c0 48 0f a3 05 52 c1 d5 01 0f 92 c0
    [  699.740524] RSP: 0018:ffff8801f43af508 EFLAGS: 00010283
    [  699.741573] RAX: 0000000000000000 RBX: ffff8801f43af7b8 RCX: ffffffffb88a7cef
    [  699.743006] RDX: 0000000000000007 RSI: dffffc0000000000 RDI: ffff8801e3e7a64c
    [  699.744426] RBP: ffff8801f43af558 R08: ffffed003e066b55 R09: ffffed003e066b55
    [  699.745833] R10: 0000000000000001 R11: ffffed003e066b54 R12: ffffea0007876940
    [  699.747256] R13: ffff8801f0335500 R14: ffff8801e3e7a600 R15: 0000000000000001
    [  699.748683] FS:  00007f9bf97f5700(0000) GS:ffff8801f6e00000(0000) knlGS:0000000000000000
    [  699.750293] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  699.751462] CR2: 00007f9bf925d170 CR3: 00000001f0c34000 CR4: 00000000000006f0
    [  699.752874] Call Trace:
    [  699.753386]  ? f2fs_inplace_write_data+0x93/0x240
    [  699.754341]  f2fs_inplace_write_data+0xd2/0x240
    [  699.755271]  f2fs_do_write_data_page+0x2e2/0xe00
    [  699.756214]  ? f2fs_should_update_outplace+0xd0/0xd0
    [  699.757215]  ? memcg_drain_all_list_lrus+0x280/0x280
    [  699.758209]  ? __radix_tree_replace+0xa3/0x120
    [  699.759164]  __write_data_page+0x5c7/0xe30
    [  699.760002]  ? kasan_check_read+0x11/0x20
    [  699.760823]  ? page_mapped+0x8a/0x110
    [  699.761573]  ? page_mkclean+0xe9/0x160
    [  699.762345]  ? f2fs_do_write_data_page+0xe00/0xe00
    [  699.763332]  ? invalid_page_referenced_vma+0x130/0x130
    [  699.764374]  ? clear_page_dirty_for_io+0x332/0x450
    [  699.765347]  f2fs_write_cache_pages+0x4ca/0x860
    [  699.766276]  ? __write_data_page+0xe30/0xe30
    [  699.767161]  ? percpu_counter_add_batch+0x22/0xa0
    [  699.768112]  ? kasan_check_write+0x14/0x20
    [  699.768951]  ? _raw_spin_lock+0x17/0x40
    [  699.769739]  ? f2fs_mark_inode_dirty_sync.part.18+0x16/0x30
    [  699.770885]  ? iov_iter_advance+0x113/0x640
    [  699.771743]  ? f2fs_write_end+0x133/0x2e0
    [  699.772569]  ? balance_dirty_pages_ratelimited+0x239/0x640
    [  699.773680]  f2fs_write_data_pages+0x329/0x520
    [  699.774603]  ? generic_perform_write+0x250/0x320
    [  699.775544]  ? f2fs_write_cache_pages+0x860/0x860
    [  699.776510]  ? current_time+0x110/0x110
    [  699.777299]  ? f2fs_preallocate_blocks+0x1ef/0x370
    [  699.778279]  do_writepages+0x37/0xb0
    [  699.779026]  ? f2fs_write_cache_pages+0x860/0x860
    [  699.779978]  ? do_writepages+0x37/0xb0
    [  699.780755]  __filemap_fdatawrite_range+0x19a/0x1f0
    [  699.781746]  ? delete_from_page_cache_batch+0x4e0/0x4e0
    [  699.782820]  ? __vfs_write+0x2b2/0x410
    [  699.783597]  file_write_and_wait_range+0x66/0xb0
    [  699.784540]  f2fs_do_sync_file+0x1f9/0xd90
    [  699.785381]  ? truncate_partial_data_page+0x290/0x290
    [  699.786415]  ? __sb_end_write+0x30/0x50
    [  699.787204]  ? vfs_write+0x20f/0x260
    [  699.787941]  f2fs_sync_file+0x9a/0xb0
    [  699.788694]  ? f2fs_do_sync_file+0xd90/0xd90
    [  699.789572]  vfs_fsync_range+0x68/0x100
    [  699.790360]  ? __fget_light+0xc9/0xe0
    [  699.791128]  do_fsync+0x3d/0x70
    [  699.791779]  __x64_sys_fdatasync+0x24/0x30
    [  699.792614]  do_syscall_64+0x78/0x170
    [  699.793371]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [  699.794406] RIP: 0033:0x7f9bf930d800
    [  699.795134] Code: 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 83 3d 49 bf 2c 00 00 75 10 b8 4b 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 31 c3 48 83 ec 08 e8 be 78 01 00 48 89 04 24
    [  699.798960] RSP: 002b:00007ffee3606c68 EFLAGS: 00000246 ORIG_RAX: 000000000000004b
    [  699.800483] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f9bf930d800
    [  699.801923] RDX: 0000000000008000 RSI: 00000000006010a0 RDI: 0000000000000003
    [  699.803373] RBP: 00007ffee3606ca0 R08: 0000000001503010 R09: 0000000000000000
    [  699.804798] R10: 00000000000002e8 R11: 0000000000000246 R12: 0000000000400610
    [  699.806233] R13: 00007ffee3606da0 R14: 0000000000000000 R15: 0000000000000000
    [  699.807667] Modules linked in: snd_hda_codec_generic snd_hda_intel snd_hda_codec snd_hwdep snd_hda_core snd_pcm snd_timer snd mac_hid i2c_piix4 soundcore ib_iser rdma_cm iw_cm ib_cm ib_core iscsi_tcp libiscsi_tcp libiscsi scsi_transport_iscsi raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx raid1 raid0 multipath linear 8139too crct10dif_pclmul crc32_pclmul qxl drm_kms_helper syscopyarea aesni_intel sysfillrect sysimgblt fb_sys_fops ttm drm aes_x86_64 crypto_simd cryptd 8139cp glue_helper mii pata_acpi floppy
    [  699.817079] ---[ end trace 4ce02f25ff7d3df6 ]---
    [  699.818068] RIP: 0010:f2fs_submit_page_bio+0x29b/0x730
    [  699.819114] Code: 54 49 8d bd 18 04 00 00 e8 b2 59 af ff 41 8b 8d 18 04 00 00 8b 45 b8 41 d3 e6 44 01 f0 4c 8d 73 14 41 39 c7 0f 82 37 fe ff ff <0f> 0b 65 8b 05 2c 04 77 47 89 c0 48 0f a3 05 52 c1 d5 01 0f 92 c0
    [  699.822919] RSP: 0018:ffff8801f43af508 EFLAGS: 00010283
    [  699.823977] RAX: 0000000000000000 RBX: ffff8801f43af7b8 RCX: ffffffffb88a7cef
    [  699.825436] RDX: 0000000000000007 RSI: dffffc0000000000 RDI: ffff8801e3e7a64c
    [  699.826881] RBP: ffff8801f43af558 R08: ffffed003e066b55 R09: ffffed003e066b55
    [  699.828292] R10: 0000000000000001 R11: ffffed003e066b54 R12: ffffea0007876940
    [  699.829750] R13: ffff8801f0335500 R14: ffff8801e3e7a600 R15: 0000000000000001
    [  699.831192] FS:  00007f9bf97f5700(0000) GS:ffff8801f6e00000(0000) knlGS:0000000000000000
    [  699.832793] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  699.833981] CR2: 00007f9bf925d170 CR3: 00000001f0c34000 CR4: 00000000000006f0
    [  699.835556] ==================================================================
    [  699.837029] BUG: KASAN: stack-out-of-bounds in update_stack_state+0x38c/0x3e0
    [  699.838462] Read of size 8 at addr ffff8801f43af970 by task a.out/1309
    
    [  699.840086] CPU: 0 PID: 1309 Comm: a.out Tainted: G      D W         4.18.0-rc1+ #4
    [  699.841603] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
    [  699.843475] Call Trace:
    [  699.843982]  dump_stack+0x7b/0xb5
    [  699.844661]  print_address_description+0x70/0x290
    [  699.845607]  kasan_report+0x291/0x390
    [  699.846351]  ? update_stack_state+0x38c/0x3e0
    [  699.853831]  __asan_load8+0x54/0x90
    [  699.854569]  update_stack_state+0x38c/0x3e0
    [  699.855428]  ? __read_once_size_nocheck.constprop.7+0x20/0x20
    [  699.856601]  ? __save_stack_trace+0x5e/0x100
    [  699.857476]  unwind_next_frame.part.5+0x18e/0x490
    [  699.858448]  ? unwind_dump+0x290/0x290
    [  699.859217]  ? clear_page_dirty_for_io+0x332/0x450
    [  699.860185]  __unwind_start+0x106/0x190
    [  699.860974]  __save_stack_trace+0x5e/0x100
    [  699.861808]  ? __save_stack_trace+0x5e/0x100
    [  699.862691]  ? unlink_anon_vmas+0xba/0x2c0
    [  699.863525]  save_stack_trace+0x1f/0x30
    [  699.864312]  save_stack+0x46/0xd0
    [  699.864993]  ? __alloc_pages_slowpath+0x1420/0x1420
    [  699.865990]  ? flush_tlb_mm_range+0x15e/0x220
    [  699.866889]  ? kasan_check_write+0x14/0x20
    [  699.867724]  ? __dec_node_state+0x92/0xb0
    [  699.868543]  ? lock_page_memcg+0x85/0xf0
    [  699.869350]  ? unlock_page_memcg+0x16/0x80
    [  699.870185]  ? page_remove_rmap+0x198/0x520
    [  699.871048]  ? mark_page_accessed+0x133/0x200
    [  699.871930]  ? _cond_resched+0x1a/0x50
    [  699.872700]  ? unmap_page_range+0xcd4/0xe50
    [  699.873551]  ? rb_next+0x58/0x80
    [  699.874217]  ? rb_next+0x58/0x80
    [  699.874895]  __kasan_slab_free+0x13c/0x1a0
    [  699.875734]  ? unlink_anon_vmas+0xba/0x2c0
    [  699.876563]  kasan_slab_free+0xe/0x10
    [  699.877315]  kmem_cache_free+0x89/0x1e0
    [  699.878095]  unlink_anon_vmas+0xba/0x2c0
    [  699.878913]  free_pgtables+0x101/0x1b0
    [  699.879677]  exit_mmap+0x146/0x2a0
    [  699.880378]  ? __ia32_sys_munmap+0x50/0x50
    [  699.881214]  ? kasan_check_read+0x11/0x20
    [  699.882052]  ? mm_update_next_owner+0x322/0x380
    [  699.882985]  mmput+0x8b/0x1d0
    [  699.883602]  do_exit+0x43a/0x1390
    [  699.884288]  ? mm_update_next_owner+0x380/0x380
    [  699.885212]  ? f2fs_sync_file+0x9a/0xb0
    [  699.885995]  ? f2fs_do_sync_file+0xd90/0xd90
    [  699.886877]  ? vfs_fsync_range+0x68/0x100
    [  699.887694]  ? __fget_light+0xc9/0xe0
    [  699.888442]  ? do_fsync+0x3d/0x70
    [  699.889118]  ? __x64_sys_fdatasync+0x24/0x30
    [  699.889996]  rewind_stack_do_exit+0x17/0x20
    [  699.890860] RIP: 0033:0x7f9bf930d800
    [  699.891585] Code: Bad RIP value.
    [  699.892268] RSP: 002b:00007ffee3606c68 EFLAGS: 00000246 ORIG_RAX: 000000000000004b
    [  699.893781] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f9bf930d800
    [  699.895220] RDX: 0000000000008000 RSI: 00000000006010a0 RDI: 0000000000000003
    [  699.896643] RBP: 00007ffee3606ca0 R08: 0000000001503010 R09: 0000000000000000
    [  699.898069] R10: 00000000000002e8 R11: 0000000000000246 R12: 0000000000400610
    [  699.899505] R13: 00007ffee3606da0 R14: 0000000000000000 R15: 0000000000000000
    
    [  699.901241] The buggy address belongs to the page:
    [  699.902215] page:ffffea0007d0ebc0 count:0 mapcount:0 mapping:0000000000000000 index:0x0
    [  699.903811] flags: 0x2ffff0000000000()
    [  699.904585] raw: 02ffff0000000000 0000000000000000 ffffffff07d00101 0000000000000000
    [  699.906125] raw: 0000000000000000 0000000000240000 00000000ffffffff 0000000000000000
    [  699.907673] page dumped because: kasan: bad access detected
    
    [  699.909108] Memory state around the buggy address:
    [  699.910077]  ffff8801f43af800: 00 f1 f1 f1 f1 00 f4 f4 f4 f3 f3 f3 f3 00 00 00
    [  699.911528]  ffff8801f43af880: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  699.912953] >ffff8801f43af900: 00 00 00 00 00 00 00 00 f1 01 f4 f4 f4 f2 f2 f2
    [  699.914392]                                                              ^
    [  699.915758]  ffff8801f43af980: f2 00 f4 f4 00 00 00 00 f2 00 00 00 00 00 00 00
    [  699.917193]  ffff8801f43afa00: 00 00 00 00 00 00 00 00 00 f3 f3 f3 00 00 00 00
    [  699.918634] ==================================================================
    
    - Location
    https://elixir.bootlin.com/linux/v4.18-rc1/source/fs/f2fs/segment.h#L644
    
    Reported-by Wen Xu <wen.xu@gatech.edu>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 94552286ac12..b766f78b05f9 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -86,8 +86,10 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 	fio.page = page;
 
 	if (f2fs_submit_page_bio(&fio)) {
-		f2fs_put_page(page, 1);
-		goto repeat;
+		memset(page_address(page), 0, PAGE_SIZE);
+		f2fs_stop_checkpoint(sbi, false);
+		f2fs_bug_on(sbi, 1);
+		return page;
 	}
 
 	lock_page(page);
@@ -143,8 +145,14 @@ bool f2fs_is_valid_blkaddr(struct f2fs_sb_info *sbi,
 	case META_POR:
 	case DATA_GENERIC:
 		if (unlikely(blkaddr >= MAX_BLKADDR(sbi) ||
-			blkaddr < MAIN_BLKADDR(sbi)))
+			blkaddr < MAIN_BLKADDR(sbi))) {
+			if (type == DATA_GENERIC) {
+				f2fs_msg(sbi->sb, KERN_WARNING,
+					"access invalid blkaddr:%u", blkaddr);
+				WARN_ON(1);
+			}
 			return false;
+		}
 		break;
 	case META_GENERIC:
 		if (unlikely(blkaddr < SEG0_BLKADDR(sbi) ||
@@ -771,6 +779,14 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 					&cp_page_1, version);
 	if (err)
 		goto invalid_cp1;
+
+	if (le32_to_cpu(cp_block->cp_pack_total_block_count) >
+					sbi->blocks_per_seg) {
+		f2fs_msg(sbi->sb, KERN_WARNING,
+			"invalid cp_pack_total_block_count:%u",
+			le32_to_cpu(cp_block->cp_pack_total_block_count));
+		goto invalid_cp1;
+	}
 	pre_version = *version;
 
 	cp_addr += le32_to_cpu(cp_block->cp_pack_total_block_count) - 1;

commit e1da7872f6eda977bd812346bf588c35e4495a1e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Jun 5 17:44:11 2018 +0800

    f2fs: introduce and spread verify_blkaddr
    
    This patch introduces verify_blkaddr to check meta/data block address
    with valid range to detect bug earlier.
    
    In addition, once we encounter an invalid blkaddr, notice user to run
    fsck to fix, and let the kernel panic.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index e5cf2ff5b39d..94552286ac12 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -120,7 +120,7 @@ struct page *f2fs_get_tmp_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return __get_meta_page(sbi, index, false);
 }
 
-bool f2fs_is_valid_meta_blkaddr(struct f2fs_sb_info *sbi,
+bool f2fs_is_valid_blkaddr(struct f2fs_sb_info *sbi,
 					block_t blkaddr, int type)
 {
 	switch (type) {
@@ -141,10 +141,16 @@ bool f2fs_is_valid_meta_blkaddr(struct f2fs_sb_info *sbi,
 			return false;
 		break;
 	case META_POR:
+	case DATA_GENERIC:
 		if (unlikely(blkaddr >= MAX_BLKADDR(sbi) ||
 			blkaddr < MAIN_BLKADDR(sbi)))
 			return false;
 		break;
+	case META_GENERIC:
+		if (unlikely(blkaddr < SEG0_BLKADDR(sbi) ||
+			blkaddr >= MAIN_BLKADDR(sbi)))
+			return false;
+		break;
 	default:
 		BUG();
 	}
@@ -177,7 +183,7 @@ int f2fs_ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 	blk_start_plug(&plug);
 	for (; nrpages-- > 0; blkno++) {
 
-		if (!f2fs_is_valid_meta_blkaddr(sbi, blkno, type))
+		if (!f2fs_is_valid_blkaddr(sbi, blkno, type))
 			goto out;
 
 		switch (type) {

commit 2a63531a612f776ea754fee6272fc8f16a06b9d6
Author: Yunlei He <heyunlei@huawei.com>
Date:   Thu Jun 21 14:49:06 2018 +0800

    f2fs: fix a hungtask problem caused by congestion_wait
    
    This patch fix hungtask problem which can be reproduced as follow:
    
    Thread 0~3:
    while true
    do
            touch /xxx/test/file_xxx
    done
    
    Thread 4 write a new checkpoint every three seconds.
    
    In the meantime, fio start 16 threads for randwrite.
    
    With my debug info, cycles num will exceed 1000 in function
    f2fs_sync_dirty_inodes, and most of cycle will be dropped
    into congestion_wait() and sleep more than 20ms. Cycles num
    reduced to 3 with this patch.
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 502d7afd71a2..e5cf2ff5b39d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -972,12 +972,10 @@ int f2fs_sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 
 		iput(inode);
 		/* We need to give cpu to another writers. */
-		if (ino == cur_ino) {
-			congestion_wait(BLK_RW_ASYNC, HZ/50);
+		if (ino == cur_ino)
 			cond_resched();
-		} else {
+		else
 			ino = cur_ino;
-		}
 	} else {
 		/*
 		 * We should submit bio, since it exists several

commit 76a45e3c45002836b2ea0711a130403dcd7d8f52
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Jun 6 23:55:01 2018 +0800

    f2fs: don't acquire orphan ino during recovery
    
    During orphan inode recovery, checkpoint should never succeed due to
    SBI_POR_DOING flag, so we don't need acquire orphan ino which only be
    used by checkpoint.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 1a3ec978f1a6..502d7afd71a2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -570,12 +570,7 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	struct inode *inode;
 	struct node_info ni;
-	int err = f2fs_acquire_orphan_inode(sbi);
-
-	if (err)
-		goto err_out;
-
-	__add_ino_entry(sbi, ino, 0, ORPHAN_INO);
+	int err;
 
 	inode = f2fs_iget_retry(sbi->sb, ino);
 	if (IS_ERR(inode)) {
@@ -605,7 +600,6 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 		err = -EIO;
 		goto err_out;
 	}
-	__remove_ino_entry(sbi, ino, ORPHAN_INO);
 	return 0;
 
 err_out:

commit 83a3bfdb5a8a086290dff2c13409c7380b683a96
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jun 21 13:46:23 2018 -0700

    f2fs: indicate shutdown f2fs to allow unmount successfully
    
    Once we shutdown f2fs, we have to flush stale pages in order to unmount
    the system. In order to make stable, we need to stop fault injection as well.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index fe92d2372f4a..1a3ec978f1a6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -28,6 +28,7 @@ struct kmem_cache *f2fs_inode_entry_slab;
 
 void f2fs_stop_checkpoint(struct f2fs_sb_info *sbi, bool end_io)
 {
+	f2fs_build_fault_attr(sbi, 0);
 	set_ckpt_flags(sbi, CP_ERROR_FLAG);
 	if (!end_io)
 		f2fs_flush_merged_writes(sbi);

commit af697c0f5c5b8798832e651baf23460d588393de
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Jul 11 18:30:42 2018 -0700

    f2fs: keep meta pages in cp_error state
    
    It turns out losing meta pages in shutdown period makes f2fs very unstable
    so that I could see many unexpected error conditions.
    
    Let's keep meta pages for fault injection and sudden power-off tests.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9f1c96caebda..fe92d2372f4a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -242,11 +242,8 @@ static int __f2fs_write_meta_page(struct page *page,
 
 	trace_f2fs_writepage(page, META);
 
-	if (unlikely(f2fs_cp_error(sbi))) {
-		dec_page_count(sbi, F2FS_DIRTY_META);
-		unlock_page(page);
-		return 0;
-	}
+	if (unlikely(f2fs_cp_error(sbi)))
+		goto redirty_out;
 	if (unlikely(is_sbi_flag_set(sbi, SBI_POR_DOING)))
 		goto redirty_out;
 	if (wbc->for_reclaim && page->index < GET_SUM_BLOCK(sbi, 0))
@@ -1129,6 +1126,9 @@ static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 		if (!get_pages(sbi, F2FS_WB_CP_DATA))
 			break;
 
+		if (unlikely(f2fs_cp_error(sbi)))
+			break;
+
 		io_schedule_timeout(5*HZ);
 	}
 	finish_wait(&sbi->cp_wait, &wait);
@@ -1202,8 +1202,12 @@ static void commit_checkpoint(struct f2fs_sb_info *sbi,
 
 	/* writeout cp pack 2 page */
 	err = __f2fs_write_meta_page(page, &wbc, FS_CP_META_IO);
-	f2fs_bug_on(sbi, err);
+	if (unlikely(err && f2fs_cp_error(sbi))) {
+		f2fs_put_page(page, 1);
+		return;
+	}
 
+	f2fs_bug_on(sbi, err);
 	f2fs_put_page(page, 0);
 
 	/* submit checkpoint (with barrier if NOBARRIER is not set) */
@@ -1229,7 +1233,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	while (get_pages(sbi, F2FS_DIRTY_META)) {
 		f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
 		if (unlikely(f2fs_cp_error(sbi)))
-			return -EIO;
+			break;
 	}
 
 	/*
@@ -1309,7 +1313,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 			f2fs_sync_meta_pages(sbi, META, LONG_MAX,
 							FS_CP_META_IO);
 			if (unlikely(f2fs_cp_error(sbi)))
-				return -EIO;
+				break;
 		}
 	}
 
@@ -1350,9 +1354,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* wait for previous submitted meta pages writeback */
 	wait_on_all_pages_writeback(sbi);
 
-	if (unlikely(f2fs_cp_error(sbi)))
-		return -EIO;
-
 	/* flush all device cache */
 	err = f2fs_flush_device_cache(sbi);
 	if (err)
@@ -1364,9 +1365,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	f2fs_release_ino_entry(sbi, false);
 
-	if (unlikely(f2fs_cp_error(sbi)))
-		return -EIO;
-
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 	clear_sbi_flag(sbi, SBI_NEED_CP);
 	__set_cp_next_pack(sbi);
@@ -1381,7 +1379,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	f2fs_bug_on(sbi, get_pages(sbi, F2FS_DIRTY_DENTS));
 
-	return 0;
+	return unlikely(f2fs_cp_error(sbi)) ? -EIO : 0;
 }
 
 /*

commit 026f05079b00a56250e6e5864b6949eae50ae4b8
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jun 12 14:28:23 2018 -0700

    treewide: Use array_size() in f2fs_kzalloc()
    
    The f2fs_kzalloc() function has no 2-factor argument form, so
    multiplication factors need to be wrapped in array_size(). This patch
    replaces cases of:
    
            f2fs_kzalloc(handle, a * b, gfp)
    
    with:
            f2fs_kzalloc(handle, array_size(a, b), gfp)
    
    as well as handling cases of:
    
            f2fs_kzalloc(handle, a * b * c, gfp)
    
    with:
    
            f2fs_kzalloc(handle, array3_size(a, b, c), gfp)
    
    This does, however, attempt to ignore constant size factors like:
    
            f2fs_kzalloc(handle, 4 * 1024, gfp)
    
    though any constants defined via macros get caught up in the conversion.
    
    Any factors with a sizeof() of "unsigned char", "char", and "u8" were
    dropped, since they're redundant.
    
    The Coccinelle script used for this was:
    
    // Fix redundant parens around sizeof().
    @@
    expression HANDLE;
    type TYPE;
    expression THING, E;
    @@
    
    (
      f2fs_kzalloc(HANDLE,
    -       (sizeof(TYPE)) * E
    +       sizeof(TYPE) * E
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       (sizeof(THING)) * E
    +       sizeof(THING) * E
      , ...)
    )
    
    // Drop single-byte sizes and redundant parens.
    @@
    expression HANDLE;
    expression COUNT;
    typedef u8;
    typedef __u8;
    @@
    
    (
      f2fs_kzalloc(HANDLE,
    -       sizeof(u8) * (COUNT)
    +       COUNT
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(__u8) * (COUNT)
    +       COUNT
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(char) * (COUNT)
    +       COUNT
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(unsigned char) * (COUNT)
    +       COUNT
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(u8) * COUNT
    +       COUNT
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(__u8) * COUNT
    +       COUNT
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(char) * COUNT
    +       COUNT
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(unsigned char) * COUNT
    +       COUNT
      , ...)
    )
    
    // 2-factor product with sizeof(type/expression) and identifier or constant.
    @@
    expression HANDLE;
    type TYPE;
    expression THING;
    identifier COUNT_ID;
    constant COUNT_CONST;
    @@
    
    (
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE) * (COUNT_ID)
    +       array_size(COUNT_ID, sizeof(TYPE))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE) * COUNT_ID
    +       array_size(COUNT_ID, sizeof(TYPE))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE) * (COUNT_CONST)
    +       array_size(COUNT_CONST, sizeof(TYPE))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE) * COUNT_CONST
    +       array_size(COUNT_CONST, sizeof(TYPE))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING) * (COUNT_ID)
    +       array_size(COUNT_ID, sizeof(THING))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING) * COUNT_ID
    +       array_size(COUNT_ID, sizeof(THING))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING) * (COUNT_CONST)
    +       array_size(COUNT_CONST, sizeof(THING))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING) * COUNT_CONST
    +       array_size(COUNT_CONST, sizeof(THING))
      , ...)
    )
    
    // 2-factor product, only identifiers.
    @@
    expression HANDLE;
    identifier SIZE, COUNT;
    @@
    
      f2fs_kzalloc(HANDLE,
    -       SIZE * COUNT
    +       array_size(COUNT, SIZE)
      , ...)
    
    // 3-factor product with 1 sizeof(type) or sizeof(expression), with
    // redundant parens removed.
    @@
    expression HANDLE;
    expression THING;
    identifier STRIDE, COUNT;
    type TYPE;
    @@
    
    (
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    )
    
    // 3-factor product with 2 sizeof(variable), with redundant parens removed.
    @@
    expression HANDLE;
    expression THING1, THING2;
    identifier COUNT;
    type TYPE1, TYPE2;
    @@
    
    (
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE1) * sizeof(TYPE2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(THING1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    )
    
    // 3-factor product, only identifiers, with redundant parens removed.
    @@
    expression HANDLE;
    identifier STRIDE, SIZE, COUNT;
    @@
    
    (
      f2fs_kzalloc(HANDLE,
    -       (COUNT) * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       COUNT * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       COUNT * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       (COUNT) * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       COUNT * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       (COUNT) * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       (COUNT) * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      f2fs_kzalloc(HANDLE,
    -       COUNT * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    )
    
    // Any remaining multi-factor products, first at least 3-factor products
    // when they're not all constants...
    @@
    expression HANDLE;
    expression E1, E2, E3;
    constant C1, C2, C3;
    @@
    
    (
      f2fs_kzalloc(HANDLE, C1 * C2 * C3, ...)
    |
      f2fs_kzalloc(HANDLE,
    -       E1 * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    )
    
    // And then all remaining 2 factors products when they're not all constants.
    @@
    expression HANDLE;
    expression E1, E2;
    constant C1, C2;
    @@
    
    (
      f2fs_kzalloc(HANDLE, C1 * C2, ...)
    |
      f2fs_kzalloc(HANDLE,
    -       E1 * E2
    +       array_size(E1, E2)
      , ...)
    )
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9624a8f7254b..9f1c96caebda 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -806,7 +806,8 @@ int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	block_t cp_blk_no;
 	int i;
 
-	sbi->ckpt = f2fs_kzalloc(sbi, cp_blks * blk_size, GFP_KERNEL);
+	sbi->ckpt = f2fs_kzalloc(sbi, array_size(blk_size, cp_blks),
+				 GFP_KERNEL);
 	if (!sbi->ckpt)
 		return -ENOMEM;
 	/*

commit c29fd0c0e26dacb7a33ad166587059818a94b4e0
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Jun 4 23:20:36 2018 +0800

    f2fs: let sync node IO interrupt async one
    
    Although mixed sync/async IOs can have continuous LBA, as they have
    different IO priority, block IO scheduler will add them into different
    queues and commit them separately, result in splited IOs which causes
    wrose performance.
    
    This patch gives high priority to synchronous IO of nodes, means that
    once synchronous flow starts, it can interrupt asynchronous writeback
    flow of system flusher, so more big IOs can be expected.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 40b39db317ea..9624a8f7254b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1089,7 +1089,9 @@ static int block_operations(struct f2fs_sb_info *sbi)
 
 	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
 		up_write(&sbi->node_write);
+		atomic_inc(&sbi->wb_sync_req[NODE]);
 		err = f2fs_sync_node_pages(sbi, &wbc, false, FS_CP_NODE_IO);
+		atomic_dec(&sbi->wb_sync_req[NODE]);
 		if (err) {
 			up_write(&sbi->node_change);
 			f2fs_unlock_all(sbi);

commit a1f72ac2c0a8d8a3488b31867c9255264331a4db
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Jun 4 23:20:17 2018 +0800

    f2fs: fix to update mtime correctly
    
    If we change system time to the past, get_mtime() will return a
    overflowed time, and SIT_I(sbi)->max_mtime will be udpated
    incorrectly, this patch fixes the two issues.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 8eb184c3de84..40b39db317ea 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1233,7 +1233,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	 * modify checkpoint
 	 * version number is already updated
 	 */
-	ckpt->elapsed_time = cpu_to_le64(get_mtime(sbi));
+	ckpt->elapsed_time = cpu_to_le64(get_mtime(sbi, true));
 	ckpt->free_segment_count = cpu_to_le32(free_segments(sbi));
 	for (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {
 		ckpt->cur_node_segno[i] =

commit 4d57b86dd86404fd8bb4f87d277d5a86a7fe537e
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed May 30 00:20:41 2018 +0800

    f2fs: clean up symbol namespace
    
    As Ted reported:
    
    "Hi, I was looking at f2fs's sources recently, and I noticed that there
    is a very large number of non-static symbols which don't have a f2fs
    prefix.  There's well over a hundred (see attached below).
    
    As one example, in fs/f2fs/dir.c there is:
    
    unsigned char get_de_type(struct f2fs_dir_entry *de)
    
    This function is clearly only useful for f2fs, but it has a generic
    name.  This means that if any other file system tries to have the same
    symbol name, there will be a symbol conflict and the kernel would not
    successfully build.  It also means that when someone is looking f2fs
    sources, it's not at all obvious whether a function such as
    read_data_page(), invalidate_blocks(), is a generic kernel function
    found in the fs, mm, or block layers, or a f2fs specific function.
    
    You might want to fix this at some point.  Hopefully Kent's bcachefs
    isn't similarly using genericly named functions, since that might
    cause conflicts with f2fs's functions --- but just as this would be a
    problem that we would rightly insist that Kent fix, this is something
    that we should have rightly insisted that f2fs should have fixed
    before it was integrated into the mainline kernel.
    
    acquire_orphan_inode
    add_ino_entry
    add_orphan_inode
    allocate_data_block
    allocate_new_segments
    alloc_nid
    alloc_nid_done
    alloc_nid_failed
    available_free_memory
    ...."
    
    This patch adds "f2fs_" prefix for all non-static symbols in order to:
    a) avoid conflict with other kernel generic symbols;
    b) to indicate the function is f2fs specific one instead of generic
    one;
    
    Reported-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index e38221d96564..8eb184c3de84 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -24,7 +24,7 @@
 #include <trace/events/f2fs.h>
 
 static struct kmem_cache *ino_entry_slab;
-struct kmem_cache *inode_entry_slab;
+struct kmem_cache *f2fs_inode_entry_slab;
 
 void f2fs_stop_checkpoint(struct f2fs_sb_info *sbi, bool end_io)
 {
@@ -36,7 +36,7 @@ void f2fs_stop_checkpoint(struct f2fs_sb_info *sbi, bool end_io)
 /*
  * We guarantee no failure on the returned page.
  */
-struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
+struct page *f2fs_grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 {
 	struct address_space *mapping = META_MAPPING(sbi);
 	struct page *page = NULL;
@@ -108,18 +108,19 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 	return page;
 }
 
-struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
+struct page *f2fs_get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 {
 	return __get_meta_page(sbi, index, true);
 }
 
 /* for POR only */
-struct page *get_tmp_page(struct f2fs_sb_info *sbi, pgoff_t index)
+struct page *f2fs_get_tmp_page(struct f2fs_sb_info *sbi, pgoff_t index)
 {
 	return __get_meta_page(sbi, index, false);
 }
 
-bool is_valid_meta_blkaddr(struct f2fs_sb_info *sbi, block_t blkaddr, int type)
+bool f2fs_is_valid_meta_blkaddr(struct f2fs_sb_info *sbi,
+					block_t blkaddr, int type)
 {
 	switch (type) {
 	case META_NAT:
@@ -153,7 +154,7 @@ bool is_valid_meta_blkaddr(struct f2fs_sb_info *sbi, block_t blkaddr, int type)
 /*
  * Readahead CP/NAT/SIT/SSA pages
  */
-int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
+int f2fs_ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 							int type, bool sync)
 {
 	struct page *page;
@@ -175,7 +176,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 	blk_start_plug(&plug);
 	for (; nrpages-- > 0; blkno++) {
 
-		if (!is_valid_meta_blkaddr(sbi, blkno, type))
+		if (!f2fs_is_valid_meta_blkaddr(sbi, blkno, type))
 			goto out;
 
 		switch (type) {
@@ -219,7 +220,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 	return blkno - start;
 }
 
-void ra_meta_pages_cond(struct f2fs_sb_info *sbi, pgoff_t index)
+void f2fs_ra_meta_pages_cond(struct f2fs_sb_info *sbi, pgoff_t index)
 {
 	struct page *page;
 	bool readahead = false;
@@ -230,7 +231,7 @@ void ra_meta_pages_cond(struct f2fs_sb_info *sbi, pgoff_t index)
 	f2fs_put_page(page, 0);
 
 	if (readahead)
-		ra_meta_pages(sbi, index, BIO_MAX_PAGES, META_POR, true);
+		f2fs_ra_meta_pages(sbi, index, BIO_MAX_PAGES, META_POR, true);
 }
 
 static int __f2fs_write_meta_page(struct page *page,
@@ -251,7 +252,7 @@ static int __f2fs_write_meta_page(struct page *page,
 	if (wbc->for_reclaim && page->index < GET_SUM_BLOCK(sbi, 0))
 		goto redirty_out;
 
-	write_meta_page(sbi, page, io_type);
+	f2fs_do_write_meta_page(sbi, page, io_type);
 	dec_page_count(sbi, F2FS_DIRTY_META);
 
 	if (wbc->for_reclaim)
@@ -296,7 +297,7 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 
 	trace_f2fs_writepages(mapping->host, wbc, META);
 	diff = nr_pages_to_write(sbi, META, wbc);
-	written = sync_meta_pages(sbi, META, wbc->nr_to_write, FS_META_IO);
+	written = f2fs_sync_meta_pages(sbi, META, wbc->nr_to_write, FS_META_IO);
 	mutex_unlock(&sbi->cp_mutex);
 	wbc->nr_to_write = max((long)0, wbc->nr_to_write - written - diff);
 	return 0;
@@ -307,7 +308,7 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 	return 0;
 }
 
-long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
+long f2fs_sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 				long nr_to_write, enum iostat_type io_type)
 {
 	struct address_space *mapping = META_MAPPING(sbi);
@@ -457,20 +458,20 @@ static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 	spin_unlock(&im->ino_lock);
 }
 
-void add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
+void f2fs_add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
 	/* add new dirty ino entry into list */
 	__add_ino_entry(sbi, ino, 0, type);
 }
 
-void remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
+void f2fs_remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
 	/* remove dirty ino entry from list */
 	__remove_ino_entry(sbi, ino, type);
 }
 
 /* mode should be APPEND_INO or UPDATE_INO */
-bool exist_written_data(struct f2fs_sb_info *sbi, nid_t ino, int mode)
+bool f2fs_exist_written_data(struct f2fs_sb_info *sbi, nid_t ino, int mode)
 {
 	struct inode_management *im = &sbi->im[mode];
 	struct ino_entry *e;
@@ -481,7 +482,7 @@ bool exist_written_data(struct f2fs_sb_info *sbi, nid_t ino, int mode)
 	return e ? true : false;
 }
 
-void release_ino_entry(struct f2fs_sb_info *sbi, bool all)
+void f2fs_release_ino_entry(struct f2fs_sb_info *sbi, bool all)
 {
 	struct ino_entry *e, *tmp;
 	int i;
@@ -500,13 +501,13 @@ void release_ino_entry(struct f2fs_sb_info *sbi, bool all)
 	}
 }
 
-void set_dirty_device(struct f2fs_sb_info *sbi, nid_t ino,
+void f2fs_set_dirty_device(struct f2fs_sb_info *sbi, nid_t ino,
 					unsigned int devidx, int type)
 {
 	__add_ino_entry(sbi, ino, devidx, type);
 }
 
-bool is_dirty_device(struct f2fs_sb_info *sbi, nid_t ino,
+bool f2fs_is_dirty_device(struct f2fs_sb_info *sbi, nid_t ino,
 					unsigned int devidx, int type)
 {
 	struct inode_management *im = &sbi->im[type];
@@ -521,7 +522,7 @@ bool is_dirty_device(struct f2fs_sb_info *sbi, nid_t ino,
 	return is_dirty;
 }
 
-int acquire_orphan_inode(struct f2fs_sb_info *sbi)
+int f2fs_acquire_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	struct inode_management *im = &sbi->im[ORPHAN_INO];
 	int err = 0;
@@ -544,7 +545,7 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 	return err;
 }
 
-void release_orphan_inode(struct f2fs_sb_info *sbi)
+void f2fs_release_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	struct inode_management *im = &sbi->im[ORPHAN_INO];
 
@@ -554,14 +555,14 @@ void release_orphan_inode(struct f2fs_sb_info *sbi)
 	spin_unlock(&im->ino_lock);
 }
 
-void add_orphan_inode(struct inode *inode)
+void f2fs_add_orphan_inode(struct inode *inode)
 {
 	/* add new orphan ino entry into list */
 	__add_ino_entry(F2FS_I_SB(inode), inode->i_ino, 0, ORPHAN_INO);
-	update_inode_page(inode);
+	f2fs_update_inode_page(inode);
 }
 
-void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
+void f2fs_remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	/* remove orphan entry from orphan list */
 	__remove_ino_entry(sbi, ino, ORPHAN_INO);
@@ -571,7 +572,7 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	struct inode *inode;
 	struct node_info ni;
-	int err = acquire_orphan_inode(sbi);
+	int err = f2fs_acquire_orphan_inode(sbi);
 
 	if (err)
 		goto err_out;
@@ -599,7 +600,7 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	/* truncate all the data during iput */
 	iput(inode);
 
-	get_node_info(sbi, ino, &ni);
+	f2fs_get_node_info(sbi, ino, &ni);
 
 	/* ENOMEM was fully retried in f2fs_evict_inode. */
 	if (ni.blk_addr != NULL_ADDR) {
@@ -617,7 +618,7 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	return err;
 }
 
-int recover_orphan_inodes(struct f2fs_sb_info *sbi)
+int f2fs_recover_orphan_inodes(struct f2fs_sb_info *sbi)
 {
 	block_t start_blk, orphan_blocks, i, j;
 	unsigned int s_flags = sbi->sb->s_flags;
@@ -645,10 +646,10 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	start_blk = __start_cp_addr(sbi) + 1 + __cp_payload(sbi);
 	orphan_blocks = __start_sum_addr(sbi) - 1 - __cp_payload(sbi);
 
-	ra_meta_pages(sbi, start_blk, orphan_blocks, META_CP, true);
+	f2fs_ra_meta_pages(sbi, start_blk, orphan_blocks, META_CP, true);
 
 	for (i = 0; i < orphan_blocks; i++) {
-		struct page *page = get_meta_page(sbi, start_blk + i);
+		struct page *page = f2fs_get_meta_page(sbi, start_blk + i);
 		struct f2fs_orphan_block *orphan_blk;
 
 		orphan_blk = (struct f2fs_orphan_block *)page_address(page);
@@ -698,7 +699,7 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	/* loop for each orphan inode entry and write them in Jornal block */
 	list_for_each_entry(orphan, head, list) {
 		if (!page) {
-			page = grab_meta_page(sbi, start_blk++);
+			page = f2fs_grab_meta_page(sbi, start_blk++);
 			orphan_blk =
 				(struct f2fs_orphan_block *)page_address(page);
 			memset(orphan_blk, 0, sizeof(*orphan_blk));
@@ -740,7 +741,7 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 	size_t crc_offset = 0;
 	__u32 crc = 0;
 
-	*cp_page = get_meta_page(sbi, cp_addr);
+	*cp_page = f2fs_get_meta_page(sbi, cp_addr);
 	*cp_block = (struct f2fs_checkpoint *)page_address(*cp_page);
 
 	crc_offset = le32_to_cpu((*cp_block)->checksum_offset);
@@ -793,7 +794,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	return NULL;
 }
 
-int get_valid_checkpoint(struct f2fs_sb_info *sbi)
+int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)
 {
 	struct f2fs_checkpoint *cp_block;
 	struct f2fs_super_block *fsb = sbi->raw_super;
@@ -837,7 +838,7 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	memcpy(sbi->ckpt, cp_block, blk_size);
 
 	/* Sanity checking of checkpoint */
-	if (sanity_check_ckpt(sbi))
+	if (f2fs_sanity_check_ckpt(sbi))
 		goto free_fail_no_cp;
 
 	if (cur_page == cp1)
@@ -856,7 +857,7 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 		void *sit_bitmap_ptr;
 		unsigned char *ckpt = (unsigned char *)sbi->ckpt;
 
-		cur_page = get_meta_page(sbi, cp_blk_no + i);
+		cur_page = f2fs_get_meta_page(sbi, cp_blk_no + i);
 		sit_bitmap_ptr = page_address(cur_page);
 		memcpy(ckpt + i * blk_size, sit_bitmap_ptr, blk_size);
 		f2fs_put_page(cur_page, 1);
@@ -901,7 +902,7 @@ static void __remove_dirty_inode(struct inode *inode, enum inode_type type)
 	stat_dec_dirty_inode(F2FS_I_SB(inode), type);
 }
 
-void update_dirty_page(struct inode *inode, struct page *page)
+void f2fs_update_dirty_page(struct inode *inode, struct page *page)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	enum inode_type type = S_ISDIR(inode->i_mode) ? DIR_INODE : FILE_INODE;
@@ -920,7 +921,7 @@ void update_dirty_page(struct inode *inode, struct page *page)
 	f2fs_trace_pid(page);
 }
 
-void remove_dirty_inode(struct inode *inode)
+void f2fs_remove_dirty_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	enum inode_type type = S_ISDIR(inode->i_mode) ? DIR_INODE : FILE_INODE;
@@ -937,7 +938,7 @@ void remove_dirty_inode(struct inode *inode)
 	spin_unlock(&sbi->inode_lock[type]);
 }
 
-int sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
+int f2fs_sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 {
 	struct list_head *head;
 	struct inode *inode;
@@ -1020,7 +1021,7 @@ int f2fs_sync_inode_meta(struct f2fs_sb_info *sbi)
 
 			/* it's on eviction */
 			if (is_inode_flag_set(inode, FI_DIRTY_INODE))
-				update_inode_page(inode);
+				f2fs_update_inode_page(inode);
 			iput(inode);
 		}
 	}
@@ -1060,7 +1061,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 	/* write all the dirty dentry pages */
 	if (get_pages(sbi, F2FS_DIRTY_DENTS)) {
 		f2fs_unlock_all(sbi);
-		err = sync_dirty_inodes(sbi, DIR_INODE);
+		err = f2fs_sync_dirty_inodes(sbi, DIR_INODE);
 		if (err)
 			goto out;
 		cond_resched();
@@ -1088,7 +1089,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 
 	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
 		up_write(&sbi->node_write);
-		err = sync_node_pages(sbi, &wbc, false, FS_CP_NODE_IO);
+		err = f2fs_sync_node_pages(sbi, &wbc, false, FS_CP_NODE_IO);
 		if (err) {
 			up_write(&sbi->node_change);
 			f2fs_unlock_all(sbi);
@@ -1182,10 +1183,10 @@ static void commit_checkpoint(struct f2fs_sb_info *sbi,
 
 	/*
 	 * pagevec_lookup_tag and lock_page again will take
-	 * some extra time. Therefore, update_meta_pages and
-	 * sync_meta_pages are combined in this function.
+	 * some extra time. Therefore, f2fs_update_meta_pages and
+	 * f2fs_sync_meta_pages are combined in this function.
 	 */
-	struct page *page = grab_meta_page(sbi, blk_addr);
+	struct page *page = f2fs_grab_meta_page(sbi, blk_addr);
 	int err;
 
 	memcpy(page_address(page), src, PAGE_SIZE);
@@ -1223,7 +1224,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* Flush all the NAT/SIT pages */
 	while (get_pages(sbi, F2FS_DIRTY_META)) {
-		sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
+		f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
 		if (unlikely(f2fs_cp_error(sbi)))
 			return -EIO;
 	}
@@ -1252,7 +1253,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	}
 
 	/* 2 cp  + n data seg summary + orphan inode blocks */
-	data_sum_blocks = npages_for_summary_flush(sbi, false);
+	data_sum_blocks = f2fs_npages_for_summary_flush(sbi, false);
 	spin_lock_irqsave(&sbi->cp_lock, flags);
 	if (data_sum_blocks < NR_CURSEG_DATA_TYPE)
 		__set_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
@@ -1297,22 +1298,23 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 		blk = start_blk + sbi->blocks_per_seg - nm_i->nat_bits_blocks;
 		for (i = 0; i < nm_i->nat_bits_blocks; i++)
-			update_meta_page(sbi, nm_i->nat_bits +
+			f2fs_update_meta_page(sbi, nm_i->nat_bits +
 					(i << F2FS_BLKSIZE_BITS), blk + i);
 
 		/* Flush all the NAT BITS pages */
 		while (get_pages(sbi, F2FS_DIRTY_META)) {
-			sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
+			f2fs_sync_meta_pages(sbi, META, LONG_MAX,
+							FS_CP_META_IO);
 			if (unlikely(f2fs_cp_error(sbi)))
 				return -EIO;
 		}
 	}
 
 	/* write out checkpoint buffer at block 0 */
-	update_meta_page(sbi, ckpt, start_blk++);
+	f2fs_update_meta_page(sbi, ckpt, start_blk++);
 
 	for (i = 1; i < 1 + cp_payload_blks; i++)
-		update_meta_page(sbi, (char *)ckpt + i * F2FS_BLKSIZE,
+		f2fs_update_meta_page(sbi, (char *)ckpt + i * F2FS_BLKSIZE,
 							start_blk++);
 
 	if (orphan_num) {
@@ -1320,7 +1322,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		start_blk += orphan_blocks;
 	}
 
-	write_data_summaries(sbi, start_blk);
+	f2fs_write_data_summaries(sbi, start_blk);
 	start_blk += data_sum_blocks;
 
 	/* Record write statistics in the hot node summary */
@@ -1331,7 +1333,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	seg_i->journal->info.kbytes_written = cpu_to_le64(kbytes_written);
 
 	if (__remain_node_summaries(cpc->reason)) {
-		write_node_summaries(sbi, start_blk);
+		f2fs_write_node_summaries(sbi, start_blk);
 		start_blk += NR_CURSEG_NODE_TYPE;
 	}
 
@@ -1340,7 +1342,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	percpu_counter_set(&sbi->alloc_valid_block_count, 0);
 
 	/* Here, we have one bio having CP pack except cp pack 2 page */
-	sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
+	f2fs_sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
 
 	/* wait for previous submitted meta pages writeback */
 	wait_on_all_pages_writeback(sbi);
@@ -1357,7 +1359,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	commit_checkpoint(sbi, ckpt, start_blk);
 	wait_on_all_pages_writeback(sbi);
 
-	release_ino_entry(sbi, false);
+	f2fs_release_ino_entry(sbi, false);
 
 	if (unlikely(f2fs_cp_error(sbi)))
 		return -EIO;
@@ -1382,7 +1384,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 /*
  * We guarantee that this checkpoint procedure will not fail.
  */
-int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
+int f2fs_write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	unsigned long long ckpt_ver;
@@ -1415,7 +1417,7 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* this is the case of multiple fstrims without any changes */
 	if (cpc->reason & CP_DISCARD) {
-		if (!exist_trim_candidates(sbi, cpc)) {
+		if (!f2fs_exist_trim_candidates(sbi, cpc)) {
 			unblock_operations(sbi);
 			goto out;
 		}
@@ -1423,8 +1425,8 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		if (NM_I(sbi)->dirty_nat_cnt == 0 &&
 				SIT_I(sbi)->dirty_sentries == 0 &&
 				prefree_segments(sbi) == 0) {
-			flush_sit_entries(sbi, cpc);
-			clear_prefree_segments(sbi, cpc);
+			f2fs_flush_sit_entries(sbi, cpc);
+			f2fs_clear_prefree_segments(sbi, cpc);
 			unblock_operations(sbi);
 			goto out;
 		}
@@ -1439,15 +1441,15 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	ckpt->checkpoint_ver = cpu_to_le64(++ckpt_ver);
 
 	/* write cached NAT/SIT entries to NAT/SIT area */
-	flush_nat_entries(sbi, cpc);
-	flush_sit_entries(sbi, cpc);
+	f2fs_flush_nat_entries(sbi, cpc);
+	f2fs_flush_sit_entries(sbi, cpc);
 
 	/* unlock all the fs_lock[] in do_checkpoint() */
 	err = do_checkpoint(sbi, cpc);
 	if (err)
-		release_discard_addrs(sbi);
+		f2fs_release_discard_addrs(sbi);
 	else
-		clear_prefree_segments(sbi, cpc);
+		f2fs_clear_prefree_segments(sbi, cpc);
 
 	unblock_operations(sbi);
 	stat_inc_cp_count(sbi->stat_info);
@@ -1464,7 +1466,7 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	return err;
 }
 
-void init_ino_entry_info(struct f2fs_sb_info *sbi)
+void f2fs_init_ino_entry_info(struct f2fs_sb_info *sbi)
 {
 	int i;
 
@@ -1482,23 +1484,23 @@ void init_ino_entry_info(struct f2fs_sb_info *sbi)
 				F2FS_ORPHANS_PER_BLOCK;
 }
 
-int __init create_checkpoint_caches(void)
+int __init f2fs_create_checkpoint_caches(void)
 {
 	ino_entry_slab = f2fs_kmem_cache_create("f2fs_ino_entry",
 			sizeof(struct ino_entry));
 	if (!ino_entry_slab)
 		return -ENOMEM;
-	inode_entry_slab = f2fs_kmem_cache_create("f2fs_inode_entry",
+	f2fs_inode_entry_slab = f2fs_kmem_cache_create("f2fs_inode_entry",
 			sizeof(struct inode_entry));
-	if (!inode_entry_slab) {
+	if (!f2fs_inode_entry_slab) {
 		kmem_cache_destroy(ino_entry_slab);
 		return -ENOMEM;
 	}
 	return 0;
 }
 
-void destroy_checkpoint_caches(void)
+void f2fs_destroy_checkpoint_caches(void)
 {
 	kmem_cache_destroy(ino_entry_slab);
-	kmem_cache_destroy(inode_entry_slab);
+	kmem_cache_destroy(f2fs_inode_entry_slab);
 }

commit 7b525dd01365c6764018e374d391c92466be1b7a
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed May 23 22:25:08 2018 +0800

    f2fs: clean up with is_valid_blkaddr()
    
    - rename is_valid_blkaddr() to is_valid_meta_blkaddr() for readability.
    - introduce is_valid_blkaddr() for cleanup.
    
    No logic change in this patch.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 33d2da006789..e38221d96564 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -119,7 +119,7 @@ struct page *get_tmp_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return __get_meta_page(sbi, index, false);
 }
 
-bool is_valid_blkaddr(struct f2fs_sb_info *sbi, block_t blkaddr, int type)
+bool is_valid_meta_blkaddr(struct f2fs_sb_info *sbi, block_t blkaddr, int type)
 {
 	switch (type) {
 	case META_NAT:
@@ -175,7 +175,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 	blk_start_plug(&plug);
 	for (; nrpages-- > 0; blkno++) {
 
-		if (!is_valid_blkaddr(sbi, blkno, type))
+		if (!is_valid_meta_blkaddr(sbi, blkno, type))
 			goto out;
 
 		switch (type) {

commit a515d12f1b180ce88273ff20b065baa1c4da3284
Author: Sheng Yong <shengyong1@huawei.com>
Date:   Sat Apr 21 14:12:50 2018 +0800

    f2fs: remove duplicated dquot_initialize and fix error handling
    
    This patch removes duplicated dquot_initialize in recover_orphan_inode(),
    and fix the error handling if dquot_initialize fails.
    
    Signed-off-by: Sheng Yong <shengyong1@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 8fc55d42ba25..33d2da006789 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -589,10 +589,11 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	}
 
 	err = dquot_initialize(inode);
-	if (err)
+	if (err) {
+		iput(inode);
 		goto err_out;
+	}
 
-	dquot_initialize(inode);
 	clear_nlink(inode);
 
 	/* truncate all the data during iput */

commit 81114baa835b59ed02d14aa1d67f91ea874077cd
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Apr 9 20:25:06 2018 +0800

    f2fs: don't use GFP_ZERO for page caches
    
    Related to https://lkml.org/lkml/2018/4/8/661
    
    Sometimes, we need to write meta data to new allocated block address,
    then we will allocate a zeroed page in inner inode's address space, and
    fill partial data in it, and leave other place with zero value which means
    some fields are initial status.
    
    There are two inner inodes (meta inode and node inode) setting __GFP_ZERO,
    I have just checked them, for both of them, we can avoid using __GFP_ZERO,
    and do initialization by ourselves to avoid unneeded/redundant zeroing
    from mm.
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3d3a1f6b21a1..8fc55d42ba25 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -100,8 +100,10 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 	 * readonly and make sure do not write checkpoint with non-uptodate
 	 * meta page.
 	 */
-	if (unlikely(!PageUptodate(page)))
+	if (unlikely(!PageUptodate(page))) {
+		memset(page_address(page), 0, PAGE_SIZE);
 		f2fs_stop_checkpoint(sbi, false);
+	}
 out:
 	return page;
 }

commit b87078ad3aec0d116e8bdc91ecbe18b5c0e49896
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Apr 20 19:29:52 2018 -0700

    Revert "f2fs: introduce f2fs_set_page_dirty_nobuffer"
    
    This patch reverts copied f2fs_set_page_dirty_nobuffer to use generic function
    for stability.
    
    This reverts commit fe76b796fc5194cc3d57265002e3a748566d073f.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index bf779461df13..3d3a1f6b21a1 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -382,7 +382,7 @@ static int f2fs_set_meta_page_dirty(struct page *page)
 	if (!PageUptodate(page))
 		SetPageUptodate(page);
 	if (!PageDirty(page)) {
-		f2fs_set_page_dirty_nobuffers(page);
+		__set_page_dirty_nobuffers(page);
 		inc_page_count(F2FS_P_SB(page), F2FS_DIRTY_META);
 		SetPagePrivate(page);
 		f2fs_trace_pid(page);

commit 0833721ec3658a4e9d5e58b6fa82cf9edc431e59
Author: Yunlei He <heyunlei@huawei.com>
Date:   Thu Mar 8 16:29:13 2018 +0800

    f2fs: check blkaddr more accuratly before issue a bio
    
    This patch check blkaddr more accuratly before issue a
    write or read bio.
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5b2db75ecd54..bf779461df13 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -68,6 +68,7 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 		.old_blkaddr = index,
 		.new_blkaddr = index,
 		.encrypted_page = NULL,
+		.is_meta = is_meta,
 	};
 
 	if (unlikely(!is_meta))
@@ -162,6 +163,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		.op_flags = sync ? (REQ_META | REQ_PRIO) : REQ_RAHEAD,
 		.encrypted_page = NULL,
 		.in_list = false,
+		.is_meta = (type != META_POR),
 	};
 	struct blk_plug plug;
 

commit 46706d5917f4457a6befe7a39a15c89dbb1ce9ca
Author: Gao Xiang <hsiangkao@aol.com>
Date:   Sat Feb 10 12:12:51 2018 +0800

    f2fs: flush cp pack except cp pack 2 page at first
    
    Previously, we attempt to flush the whole cp pack in a single bio,
    however, when suddenly powering off at this time, we could get into
    an extreme scenario that cp pack 1 page and cp pack 2 page are updated
    and latest, but payload or current summaries are still partially
    outdated. (see reliable write in the UFS specification)
    
    This patch submits the whole cp pack except cp pack 2 page at first,
    and then writes the cp pack 2 page with an extra independent
    bio with pre-io barrier.
    
    Signed-off-by: Gao Xiang <gaoxiang25@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index e3bf753a47be..5b2db75ecd54 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1168,6 +1168,39 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	spin_unlock_irqrestore(&sbi->cp_lock, flags);
 }
 
+static void commit_checkpoint(struct f2fs_sb_info *sbi,
+	void *src, block_t blk_addr)
+{
+	struct writeback_control wbc = {
+		.for_reclaim = 0,
+	};
+
+	/*
+	 * pagevec_lookup_tag and lock_page again will take
+	 * some extra time. Therefore, update_meta_pages and
+	 * sync_meta_pages are combined in this function.
+	 */
+	struct page *page = grab_meta_page(sbi, blk_addr);
+	int err;
+
+	memcpy(page_address(page), src, PAGE_SIZE);
+	set_page_dirty(page);
+
+	f2fs_wait_on_page_writeback(page, META, true);
+	f2fs_bug_on(sbi, PageWriteback(page));
+	if (unlikely(!clear_page_dirty_for_io(page)))
+		f2fs_bug_on(sbi, 1);
+
+	/* writeout cp pack 2 page */
+	err = __f2fs_write_meta_page(page, &wbc, FS_CP_META_IO);
+	f2fs_bug_on(sbi, err);
+
+	f2fs_put_page(page, 0);
+
+	/* submit checkpoint (with barrier if NOBARRIER is not set) */
+	f2fs_submit_merged_write(sbi, META_FLUSH);
+}
+
 static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
@@ -1270,16 +1303,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		}
 	}
 
-	/* need to wait for end_io results */
-	wait_on_all_pages_writeback(sbi);
-	if (unlikely(f2fs_cp_error(sbi)))
-		return -EIO;
-
-	/* flush all device cache */
-	err = f2fs_flush_device_cache(sbi);
-	if (err)
-		return err;
-
 	/* write out checkpoint buffer at block 0 */
 	update_meta_page(sbi, ckpt, start_blk++);
 
@@ -1307,26 +1330,26 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		start_blk += NR_CURSEG_NODE_TYPE;
 	}
 
-	/* writeout checkpoint block */
-	update_meta_page(sbi, ckpt, start_blk);
+	/* update user_block_counts */
+	sbi->last_valid_block_count = sbi->total_valid_block_count;
+	percpu_counter_set(&sbi->alloc_valid_block_count, 0);
 
-	/* wait for previous submitted node/meta pages writeback */
+	/* Here, we have one bio having CP pack except cp pack 2 page */
+	sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
+
+	/* wait for previous submitted meta pages writeback */
 	wait_on_all_pages_writeback(sbi);
 
 	if (unlikely(f2fs_cp_error(sbi)))
 		return -EIO;
 
-	filemap_fdatawait_range(NODE_MAPPING(sbi), 0, LLONG_MAX);
-	filemap_fdatawait_range(META_MAPPING(sbi), 0, LLONG_MAX);
-
-	/* update user_block_counts */
-	sbi->last_valid_block_count = sbi->total_valid_block_count;
-	percpu_counter_set(&sbi->alloc_valid_block_count, 0);
-
-	/* Here, we only have one bio having CP pack */
-	sync_meta_pages(sbi, META_FLUSH, LONG_MAX, FS_CP_META_IO);
+	/* flush all device cache */
+	err = f2fs_flush_device_cache(sbi);
+	if (err)
+		return err;
 
-	/* wait for previous submitted meta pages writeback */
+	/* barrier and flush checkpoint cp pack 2 page if it can */
+	commit_checkpoint(sbi, ckpt, start_blk);
 	wait_on_all_pages_writeback(sbi);
 
 	release_ino_entry(sbi, false);

commit 0f9ec2a8f65d72a454e99fb4f7351d7e01070385
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Feb 7 17:01:48 2018 -0800

    f2fs: handle quota for orphan inodes
    
    This is to detect dquot_initialize errors early from evict_inode
    for orphan inodes.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 8b0945ba284d..e3bf753a47be 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -569,13 +569,8 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	struct node_info ni;
 	int err = acquire_orphan_inode(sbi);
 
-	if (err) {
-		set_sbi_flag(sbi, SBI_NEED_FSCK);
-		f2fs_msg(sbi->sb, KERN_WARNING,
-				"%s: orphan failed (ino=%x), run fsck to fix.",
-				__func__, ino);
-		return err;
-	}
+	if (err)
+		goto err_out;
 
 	__add_ino_entry(sbi, ino, 0, ORPHAN_INO);
 
@@ -589,6 +584,11 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 		return PTR_ERR(inode);
 	}
 
+	err = dquot_initialize(inode);
+	if (err)
+		goto err_out;
+
+	dquot_initialize(inode);
 	clear_nlink(inode);
 
 	/* truncate all the data during iput */
@@ -598,14 +598,18 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 
 	/* ENOMEM was fully retried in f2fs_evict_inode. */
 	if (ni.blk_addr != NULL_ADDR) {
-		set_sbi_flag(sbi, SBI_NEED_FSCK);
-		f2fs_msg(sbi->sb, KERN_WARNING,
-			"%s: orphan failed (ino=%x) by kernel, retry mount.",
-				__func__, ino);
-		return -EIO;
+		err = -EIO;
+		goto err_out;
 	}
 	__remove_ino_entry(sbi, ino, ORPHAN_INO);
 	return 0;
+
+err_out:
+	set_sbi_flag(sbi, SBI_NEED_FSCK);
+	f2fs_msg(sbi->sb, KERN_WARNING,
+			"%s: orphan failed (ino=%x), run fsck to fix.",
+			__func__, ino);
+	return err;
 }
 
 int recover_orphan_inodes(struct f2fs_sb_info *sbi)

commit cd36d7a17f9da68be9aa67185ba3ad7969934a19
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Jan 31 09:30:34 2018 +0800

    f2fs: fix to clear CP_TRIMMED_FLAG
    
    Once CP_TRIMMED_FLAG is set, after a reboot, we will never issue discard
    before LBA becomes invalid again, fix it by clearing the flag in
    checkpoint without CP_TRIMMED reason.
    
    Fixes: 1f43e2ad7bff ("f2fs: introduce CP_TRIMMED_FLAG to avoid unneeded discard")
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 512dca8abc7d..8b0945ba284d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1136,6 +1136,8 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	if (cpc->reason & CP_TRIMMED)
 		__set_ckpt_flags(ckpt, CP_TRIMMED_FLAG);
+	else
+		__clear_ckpt_flags(ckpt, CP_TRIMMED_FLAG);
 
 	if (cpc->reason & CP_UMOUNT)
 		__set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);

commit f236792311f4575a1ca47240d3a74034096ef9e8
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jan 19 13:42:33 2018 -0800

    f2fs: allow to recover node blocks given updated checkpoint
    
    If fsck.f2fs changes crc, we have no way to recover some inode blocks by roll-
    forward recovery. Let's relax the condition to recover them.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9c7596f7daae..512dca8abc7d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1157,6 +1157,7 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* set this flag to activate crc|cp_ver for recovery */
 	__set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG);
+	__clear_ckpt_flags(ckpt, CP_NOCRC_RECOVERY_FLAG);
 
 	spin_unlock_irqrestore(&sbi->cp_lock, flags);
 }

commit db198ae0f823e13e3698b24049e741978a0f14e3
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Jan 18 17:29:10 2018 +0800

    f2fs: drop page cache after fs shutdown
    
    Don't remain dirtied page cache in f2fs after shutdown, it can mitigate
    memory pressure of whole system, in order to keep other modules working
    properly.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 097eadc82432..9c7596f7daae 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -237,12 +237,15 @@ static int __f2fs_write_meta_page(struct page *page,
 
 	trace_f2fs_writepage(page, META);
 
+	if (unlikely(f2fs_cp_error(sbi))) {
+		dec_page_count(sbi, F2FS_DIRTY_META);
+		unlock_page(page);
+		return 0;
+	}
 	if (unlikely(is_sbi_flag_set(sbi, SBI_POR_DOING)))
 		goto redirty_out;
 	if (wbc->for_reclaim && page->index < GET_SUM_BLOCK(sbi, 0))
 		goto redirty_out;
-	if (unlikely(f2fs_cp_error(sbi)))
-		goto redirty_out;
 
 	write_meta_page(sbi, page, io_type);
 	dec_page_count(sbi, F2FS_DIRTY_META);

commit acbf054d537d7efddc232e6c11a15d4be0507fd6
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Nov 30 19:28:17 2017 +0800

    f2fs: inject fault to kzalloc
    
    This patch introduces f2fs_kzalloc based on f2fs_kmalloc in order to
    support error injection for kzalloc().
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4aa69bc1c70a..097eadc82432 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -793,7 +793,7 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	block_t cp_blk_no;
 	int i;
 
-	sbi->ckpt = kzalloc(cp_blks * blk_size, GFP_KERNEL);
+	sbi->ckpt = f2fs_kzalloc(sbi, cp_blks * blk_size, GFP_KERNEL);
 	if (!sbi->ckpt)
 		return -ENOMEM;
 	/*

commit 1751e8a6cb935e555fcdbcb9ab4f0446e322ca3e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 27 13:05:09 2017 -0800

    Rename superblock flags (MS_xyz -> SB_xyz)
    
    This is a pure automated search-and-replace of the internal kernel
    superblock flags.
    
    The s_flags are now called SB_*, with the names and the values for the
    moment mirroring the MS_* flags that they're equivalent to.
    
    Note how the MS_xyz flags are the ones passed to the mount system call,
    while the SB_xyz flags are what we then use in sb->s_flags.
    
    The script to do this was:
    
        # places to look in; re security/*: it generally should *not* be
        # touched (that stuff parses mount(2) arguments directly), but
        # there are two places where we really deal with superblock flags.
        FILES="drivers/mtd drivers/staging/lustre fs ipc mm \
                include/linux/fs.h include/uapi/linux/bfs_fs.h \
                security/apparmor/apparmorfs.c security/apparmor/include/lib.h"
        # the list of MS_... constants
        SYMS="RDONLY NOSUID NODEV NOEXEC SYNCHRONOUS REMOUNT MANDLOCK \
              DIRSYNC NOATIME NODIRATIME BIND MOVE REC VERBOSE SILENT \
              POSIXACL UNBINDABLE PRIVATE SLAVE SHARED RELATIME KERNMOUNT \
              I_VERSION STRICTATIME LAZYTIME SUBMOUNT NOREMOTELOCK NOSEC BORN \
              ACTIVE NOUSER"
    
        SED_PROG=
        for i in $SYMS; do SED_PROG="$SED_PROG -e s/MS_$i/SB_$i/g"; done
    
        # we want files that contain at least one of MS_...,
        # with fs/namespace.c and fs/pnode.c excluded.
        L=$(for i in $SYMS; do git grep -w -l MS_$i $FILES; done| sort|uniq|grep -v '^fs/namespace.c'|grep -v '^fs/pnode.c')
    
        for f in $L; do sed -i $f $SED_PROG; done
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index dd2e73e10857..4aa69bc1c70a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -617,17 +617,17 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	if (!is_set_ckpt_flags(sbi, CP_ORPHAN_PRESENT_FLAG))
 		return 0;
 
-	if (s_flags & MS_RDONLY) {
+	if (s_flags & SB_RDONLY) {
 		f2fs_msg(sbi->sb, KERN_INFO, "orphan cleanup on readonly fs");
-		sbi->sb->s_flags &= ~MS_RDONLY;
+		sbi->sb->s_flags &= ~SB_RDONLY;
 	}
 
 #ifdef CONFIG_QUOTA
 	/* Needed for iput() to work correctly and not trash data */
-	sbi->sb->s_flags |= MS_ACTIVE;
+	sbi->sb->s_flags |= SB_ACTIVE;
 
 	/* Turn on quotas so that they are updated correctly */
-	quota_enabled = f2fs_enable_quota_files(sbi, s_flags & MS_RDONLY);
+	quota_enabled = f2fs_enable_quota_files(sbi, s_flags & SB_RDONLY);
 #endif
 
 	start_blk = __start_cp_addr(sbi) + 1 + __cp_payload(sbi);
@@ -658,7 +658,7 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	if (quota_enabled)
 		f2fs_quota_off_umount(sbi->sb);
 #endif
-	sbi->sb->s_flags = s_flags; /* Restore MS_RDONLY status */
+	sbi->sb->s_flags = s_flags; /* Restore SB_RDONLY status */
 
 	return err;
 }

commit a02cd4229e298aadbe8f5cf286edee8058d87116
Merge: 487e2c9f44c4 ead710b7d82d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 16 12:10:21 2017 -0800

    Merge tag 'f2fs-for-4.15-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/jaegeuk/f2fs
    
    Pull f2fs updates from Jaegeuk Kim:
     "In this round, we introduce sysfile-based quota support which is
      required for Android by default. In addition, we allow that users are
      able to reserve some blocks in runtime to mitigate performance drops
      in low free space.
    
      Enhancements:
       - assign proper data segments according to write_hints given by user
       - issue cache_flush on dirty devices only among multiple devices
       - exploit cp_error flag and add more faults to enhance fault
         injection test
       - conduct more readaheads during f2fs_readdir
       - add a range for discard commands
    
      Bug fixes:
       - fix zero stat->st_blocks when inline_data is set
       - drop crypto key and free stale memory pointer while evict_inode is
         failing
       - fix some corner cases in free space and segment management
       - fix wrong last_disk_size
    
      This series includes lots of clean-ups and code enhancement in terms
      of xattr operations, discard/flush command control. In addition, it
      adds versatile debugfs entries to monitor f2fs status"
    
    * tag 'f2fs-for-4.15-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/jaegeuk/f2fs: (75 commits)
      f2fs: deny accessing encryption policy if encryption is off
      f2fs: inject fault in inc_valid_node_count
      f2fs: fix to clear FI_NO_PREALLOC
      f2fs: expose quota information in debugfs
      f2fs: separate nat entry mem alloc from nat_tree_lock
      f2fs: validate before set/clear free nat bitmap
      f2fs: avoid opened loop codes in __add_ino_entry
      f2fs: apply write hints to select the type of segments for buffered write
      f2fs: introduce scan_curseg_cache for cleanup
      f2fs: optimize the way of traversing free_nid_bitmap
      f2fs: keep scanning until enough free nids are acquired
      f2fs: trace checkpoint reason in fsync()
      f2fs: keep isize once block is reserved cross EOF
      f2fs: avoid race in between GC and block exchange
      f2fs: save a multiplication for last_nid calculation
      f2fs: fix summary info corruption
      f2fs: remove dead code in update_meta_page
      f2fs: remove unneeded semicolon
      f2fs: don't bother with inode->i_version
      f2fs: check curseg space before foreground GC
      ...

commit 8667982014d6048e0b5e286b6247ff24f48d4cc6
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Wed Nov 15 17:37:52 2017 -0800

    mm, pagevec: remove cold parameter for pagevecs
    
    Every pagevec_init user claims the pages being released are hot even in
    cases where it is unlikely the pages are hot.  As no one cares about the
    hotness of pages being released to the allocator, just ditch the
    parameter.
    
    No performance impact is expected as the overhead is marginal.  The
    parameter is removed simply because it is a bit stupid to have a useless
    parameter copied everywhere.
    
    Link: http://lkml.kernel.org/r/20171018075952.10627-6-mgorman@techsingularity.net
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6124f8710dc3..0bb8e2c022d3 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -314,7 +314,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 	};
 	struct blk_plug plug;
 
-	pagevec_init(&pvec, 0);
+	pagevec_init(&pvec);
 
 	blk_start_plug(&plug);
 

commit 67fd707f468142d0f689a6240044bb45c1913003
Author: Jan Kara <jack@suse.cz>
Date:   Wed Nov 15 17:35:19 2017 -0800

    mm: remove nr_pages argument from pagevec_lookup_{,range}_tag()
    
    All users of pagevec_lookup() and pagevec_lookup_range() now pass
    PAGEVEC_SIZE as a desired number of pages.  Just drop the argument.
    
    Link: http://lkml.kernel.org/r/20171009151359.31984-15-jack@suse.cz
    Signed-off-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index fb74ec4ed9d2..6124f8710dc3 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -319,7 +319,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 	blk_start_plug(&plug);
 
 	while ((nr_pages = pagevec_lookup_tag(&pvec, mapping, &index,
-				PAGECACHE_TAG_DIRTY, PAGEVEC_SIZE))) {
+				PAGECACHE_TAG_DIRTY))) {
 		int i;
 
 		for (i = 0; i < nr_pages; i++) {

commit 028a63a6e381d7d109e19db4740085d1b655c539
Author: Jan Kara <jack@suse.cz>
Date:   Wed Nov 15 17:34:51 2017 -0800

    f2fs: simplify page iteration loops
    
    In several places we want to iterate over all tagged pages in a mapping.
    However the code was apparently copied from places that iterate only
    over a limited range and thus it checks for index <= end, optimizes the
    case where we are coming close to range end which is all pointless when
    end == ULONG_MAX.  So just remove this dead code.
    
    [akpm@linux-foundation.org: fix warnings]
    Link: http://lkml.kernel.org/r/20171009151359.31984-7-jack@suse.cz
    Signed-off-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Cc: Jaegeuk Kim <jaegeuk@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 04fe1df052b2..fb74ec4ed9d2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -305,9 +305,10 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 				long nr_to_write, enum iostat_type io_type)
 {
 	struct address_space *mapping = META_MAPPING(sbi);
-	pgoff_t index = 0, end = ULONG_MAX, prev = ULONG_MAX;
+	pgoff_t index = 0, prev = ULONG_MAX;
 	struct pagevec pvec;
 	long nwritten = 0;
+	int nr_pages;
 	struct writeback_control wbc = {
 		.for_reclaim = 0,
 	};
@@ -317,13 +318,9 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 
 	blk_start_plug(&plug);
 
-	while (index <= end) {
-		int i, nr_pages;
-		nr_pages = pagevec_lookup_tag(&pvec, mapping, &index,
-				PAGECACHE_TAG_DIRTY,
-				min(end - index, (pgoff_t)PAGEVEC_SIZE-1) + 1);
-		if (unlikely(nr_pages == 0))
-			break;
+	while ((nr_pages = pagevec_lookup_tag(&pvec, mapping, &index,
+				PAGECACHE_TAG_DIRTY, PAGEVEC_SIZE))) {
+		int i;
 
 		for (i = 0; i < nr_pages; i++) {
 			struct page *page = pvec.pages[i];

commit 19526d74cfbe31b04fb81b64c2884687a321f4a0
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Nov 10 09:30:42 2017 +0800

    f2fs: avoid opened loop codes in __add_ino_entry
    
    We will keep __add_ino_entry success all the time, for ENOMEM failure
    case, we have already handled it by using  __GFP_NOFAIL flag, so we
    don't have to use additional opened loop codes here, remove them.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 98777c1ae70c..a30024f2a567 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -407,18 +407,16 @@ static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino,
 	struct ino_entry *e, *tmp;
 
 	tmp = f2fs_kmem_cache_alloc(ino_entry_slab, GFP_NOFS);
-retry:
+
 	radix_tree_preload(GFP_NOFS | __GFP_NOFAIL);
 
 	spin_lock(&im->ino_lock);
 	e = radix_tree_lookup(&im->ino_root, ino);
 	if (!e) {
 		e = tmp;
-		if (radix_tree_insert(&im->ino_root, ino, e)) {
-			spin_unlock(&im->ino_lock);
-			radix_tree_preload_end();
-			goto retry;
-		}
+		if (unlikely(radix_tree_insert(&im->ino_root, ino, e)))
+			f2fs_bug_on(sbi, 1);
+
 		memset(e, 0, sizeof(struct ino_entry));
 		e->ino = ino;
 

commit dee668c14313bdc3a6a532980200908c046dda11
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Nov 2 20:41:01 2017 +0800

    f2fs: remove unneeded semicolon
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 78e1b2998bbd..98777c1ae70c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1016,7 +1016,7 @@ int f2fs_sync_inode_meta(struct f2fs_sb_info *sbi)
 				update_inode_page(inode);
 			iput(inode);
 		}
-	};
+	}
 	return 0;
 }
 

commit ea6767337f86312ebe473585899a159bf50ef1b7
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Oct 6 09:14:28 2017 -0700

    f2fs: support quota sys files
    
    This patch supports hidden quota files in the system, which will be used for
    Android. It requires up-to-date f2fs-tools later than v1.9.0.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6b52d4b66c7b..78e1b2998bbd 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -615,6 +615,9 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	block_t start_blk, orphan_blocks, i, j;
 	unsigned int s_flags = sbi->sb->s_flags;
 	int err = 0;
+#ifdef CONFIG_QUOTA
+	int quota_enabled;
+#endif
 
 	if (!is_set_ckpt_flags(sbi, CP_ORPHAN_PRESENT_FLAG))
 		return 0;
@@ -627,8 +630,9 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 #ifdef CONFIG_QUOTA
 	/* Needed for iput() to work correctly and not trash data */
 	sbi->sb->s_flags |= MS_ACTIVE;
+
 	/* Turn on quotas so that they are updated correctly */
-	f2fs_enable_quota_files(sbi);
+	quota_enabled = f2fs_enable_quota_files(sbi, s_flags & MS_RDONLY);
 #endif
 
 	start_blk = __start_cp_addr(sbi) + 1 + __cp_payload(sbi);
@@ -656,7 +660,8 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 out:
 #ifdef CONFIG_QUOTA
 	/* Turn quotas off */
-	f2fs_quota_off_umount(sbi->sb);
+	if (quota_enabled)
+		f2fs_quota_off_umount(sbi->sb);
 #endif
 	sbi->sb->s_flags = s_flags; /* Restore MS_RDONLY status */
 

commit 1f227a3e215d3613ea6cbc2fbe29caafbcaa8f71
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Oct 23 23:48:49 2017 +0200

    f2fs: stop all the operations by cp_error flag
    
    This patch replaces to use cp_error flag instead of RDONLY for quota off.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 201608281681..6b52d4b66c7b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -29,7 +29,6 @@ struct kmem_cache *inode_entry_slab;
 void f2fs_stop_checkpoint(struct f2fs_sb_info *sbi, bool end_io)
 {
 	set_ckpt_flags(sbi, CP_ERROR_FLAG);
-	sbi->sb->s_flags |= MS_RDONLY;
 	if (!end_io)
 		f2fs_flush_merged_writes(sbi);
 }

commit 1228b482c4ee26f3334dd83eb13bcf7e462f9c93
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Sep 29 13:59:39 2017 +0800

    f2fs: fix to flush multiple device in checkpoint
    
    If f2fs manages multiple devices, in checkpoint, we need to issue flush
    in those devices which contain dirty data/node in their cache before
    we write checkpoint region, otherwise, filesystem metadata could be
    corrupted if hitting SPO after checkpoint.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 571980793542..201608281681 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1172,6 +1172,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	struct super_block *sb = sbi->sb;
 	struct curseg_info *seg_i = CURSEG_I(sbi, CURSEG_HOT_NODE);
 	u64 kbytes_written;
+	int err;
 
 	/* Flush all the NAT/SIT pages */
 	while (get_pages(sbi, F2FS_DIRTY_META)) {
@@ -1265,6 +1266,11 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (unlikely(f2fs_cp_error(sbi)))
 		return -EIO;
 
+	/* flush all device cache */
+	err = f2fs_flush_device_cache(sbi);
+	if (err)
+		return err;
+
 	/* write out checkpoint buffer at block 0 */
 	update_meta_page(sbi, ckpt, start_blk++);
 

commit 39d787bec4f792e69e24b11aa3d61ae1c0e4830b
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Sep 29 13:59:38 2017 +0800

    f2fs: enhance multiple device flush
    
    When multiple device feature is enabled, during ->fsync we will issue
    flush in all devices to make sure node/data of the file being persisted
    into storage. But some flushes of device could be unneeded as file's
    data may be not writebacked into those devices. So this patch adds and
    manage bitmap per inode in global cache to indicate which device is
    dirty and it needs to issue flush during ->fsync, hence, we could improve
    performance of fsync in scenario of multiple device.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 04fe1df052b2..571980793542 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -401,7 +401,8 @@ const struct address_space_operations f2fs_meta_aops = {
 #endif
 };
 
-static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
+static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino,
+						unsigned int devidx, int type)
 {
 	struct inode_management *im = &sbi->im[type];
 	struct ino_entry *e, *tmp;
@@ -426,6 +427,10 @@ static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 		if (type != ORPHAN_INO)
 			im->ino_num++;
 	}
+
+	if (type == FLUSH_INO)
+		f2fs_set_bit(devidx, (char *)&e->dirty_device);
+
 	spin_unlock(&im->ino_lock);
 	radix_tree_preload_end();
 
@@ -454,7 +459,7 @@ static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 void add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
 	/* add new dirty ino entry into list */
-	__add_ino_entry(sbi, ino, type);
+	__add_ino_entry(sbi, ino, 0, type);
 }
 
 void remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
@@ -480,7 +485,7 @@ void release_ino_entry(struct f2fs_sb_info *sbi, bool all)
 	struct ino_entry *e, *tmp;
 	int i;
 
-	for (i = all ? ORPHAN_INO: APPEND_INO; i <= UPDATE_INO; i++) {
+	for (i = all ? ORPHAN_INO : APPEND_INO; i < MAX_INO_ENTRY; i++) {
 		struct inode_management *im = &sbi->im[i];
 
 		spin_lock(&im->ino_lock);
@@ -494,6 +499,27 @@ void release_ino_entry(struct f2fs_sb_info *sbi, bool all)
 	}
 }
 
+void set_dirty_device(struct f2fs_sb_info *sbi, nid_t ino,
+					unsigned int devidx, int type)
+{
+	__add_ino_entry(sbi, ino, devidx, type);
+}
+
+bool is_dirty_device(struct f2fs_sb_info *sbi, nid_t ino,
+					unsigned int devidx, int type)
+{
+	struct inode_management *im = &sbi->im[type];
+	struct ino_entry *e;
+	bool is_dirty = false;
+
+	spin_lock(&im->ino_lock);
+	e = radix_tree_lookup(&im->ino_root, ino);
+	if (e && f2fs_test_bit(devidx, (char *)&e->dirty_device))
+		is_dirty = true;
+	spin_unlock(&im->ino_lock);
+	return is_dirty;
+}
+
 int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	struct inode_management *im = &sbi->im[ORPHAN_INO];
@@ -530,7 +556,7 @@ void release_orphan_inode(struct f2fs_sb_info *sbi)
 void add_orphan_inode(struct inode *inode)
 {
 	/* add new orphan ino entry into list */
-	__add_ino_entry(F2FS_I_SB(inode), inode->i_ino, ORPHAN_INO);
+	__add_ino_entry(F2FS_I_SB(inode), inode->i_ino, 0, ORPHAN_INO);
 	update_inode_page(inode);
 }
 
@@ -554,7 +580,7 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 		return err;
 	}
 
-	__add_ino_entry(sbi, ino, ORPHAN_INO);
+	__add_ino_entry(sbi, ino, 0, ORPHAN_INO);
 
 	inode = f2fs_iget_retry(sbi->sb, ino);
 	if (IS_ERR(inode)) {

commit 4b2414d04e99120ce852ba15a1926c9c3a77d9ce
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Aug 8 10:54:31 2017 +0800

    f2fs: support journalled quota
    
    This patch supports to enable f2fs to accept quota information through
    mount option:
    - {usr,grp,prj}jquota=<quota file path>
    - jqfmt=<quota type>
    
    Then, in ->mount flow, we can recover quota file during log replaying,
    by this, journelled quota can be supported.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: Fix wrong return values.]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index da5b49183e09..04fe1df052b2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -588,11 +588,24 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 {
 	block_t start_blk, orphan_blocks, i, j;
-	int err;
+	unsigned int s_flags = sbi->sb->s_flags;
+	int err = 0;
 
 	if (!is_set_ckpt_flags(sbi, CP_ORPHAN_PRESENT_FLAG))
 		return 0;
 
+	if (s_flags & MS_RDONLY) {
+		f2fs_msg(sbi->sb, KERN_INFO, "orphan cleanup on readonly fs");
+		sbi->sb->s_flags &= ~MS_RDONLY;
+	}
+
+#ifdef CONFIG_QUOTA
+	/* Needed for iput() to work correctly and not trash data */
+	sbi->sb->s_flags |= MS_ACTIVE;
+	/* Turn on quotas so that they are updated correctly */
+	f2fs_enable_quota_files(sbi);
+#endif
+
 	start_blk = __start_cp_addr(sbi) + 1 + __cp_payload(sbi);
 	orphan_blocks = __start_sum_addr(sbi) - 1 - __cp_payload(sbi);
 
@@ -608,14 +621,21 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 			err = recover_orphan_inode(sbi, ino);
 			if (err) {
 				f2fs_put_page(page, 1);
-				return err;
+				goto out;
 			}
 		}
 		f2fs_put_page(page, 1);
 	}
 	/* clear Orphan Flag */
 	clear_ckpt_flags(sbi, CP_ORPHAN_PRESENT_FLAG);
-	return 0;
+out:
+#ifdef CONFIG_QUOTA
+	/* Turn quotas off */
+	f2fs_quota_off_umount(sbi->sb);
+#endif
+	sbi->sb->s_flags = s_flags; /* Restore MS_RDONLY status */
+
+	return err;
 }
 
 static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)

commit b0af6d491a6b5f5622fa91ac75f34f3640f862c4
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Aug 2 23:21:48 2017 +0800

    f2fs: add app/fs io stat
    
    This patch enables inner app/fs io stats and introduces below virtual fs
    nodes for exposing stats info:
    /sys/fs/f2fs/<dev>/iostat_enable
    /proc/fs/f2fs/<dev>/iostat_info
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: fix wrong stat assignment]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3c84a2520796..da5b49183e09 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -230,8 +230,9 @@ void ra_meta_pages_cond(struct f2fs_sb_info *sbi, pgoff_t index)
 		ra_meta_pages(sbi, index, BIO_MAX_PAGES, META_POR, true);
 }
 
-static int f2fs_write_meta_page(struct page *page,
-				struct writeback_control *wbc)
+static int __f2fs_write_meta_page(struct page *page,
+				struct writeback_control *wbc,
+				enum iostat_type io_type)
 {
 	struct f2fs_sb_info *sbi = F2FS_P_SB(page);
 
@@ -244,7 +245,7 @@ static int f2fs_write_meta_page(struct page *page,
 	if (unlikely(f2fs_cp_error(sbi)))
 		goto redirty_out;
 
-	write_meta_page(sbi, page);
+	write_meta_page(sbi, page, io_type);
 	dec_page_count(sbi, F2FS_DIRTY_META);
 
 	if (wbc->for_reclaim)
@@ -263,6 +264,12 @@ static int f2fs_write_meta_page(struct page *page,
 	return AOP_WRITEPAGE_ACTIVATE;
 }
 
+static int f2fs_write_meta_page(struct page *page,
+				struct writeback_control *wbc)
+{
+	return __f2fs_write_meta_page(page, wbc, FS_META_IO);
+}
+
 static int f2fs_write_meta_pages(struct address_space *mapping,
 				struct writeback_control *wbc)
 {
@@ -283,7 +290,7 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 
 	trace_f2fs_writepages(mapping->host, wbc, META);
 	diff = nr_pages_to_write(sbi, META, wbc);
-	written = sync_meta_pages(sbi, META, wbc->nr_to_write);
+	written = sync_meta_pages(sbi, META, wbc->nr_to_write, FS_META_IO);
 	mutex_unlock(&sbi->cp_mutex);
 	wbc->nr_to_write = max((long)0, wbc->nr_to_write - written - diff);
 	return 0;
@@ -295,7 +302,7 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 }
 
 long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
-						long nr_to_write)
+				long nr_to_write, enum iostat_type io_type)
 {
 	struct address_space *mapping = META_MAPPING(sbi);
 	pgoff_t index = 0, end = ULONG_MAX, prev = ULONG_MAX;
@@ -346,7 +353,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 			if (!clear_page_dirty_for_io(page))
 				goto continue_unlock;
 
-			if (mapping->a_ops->writepage(page, &wbc)) {
+			if (__f2fs_write_meta_page(page, &wbc, io_type)) {
 				unlock_page(page);
 				break;
 			}
@@ -904,7 +911,14 @@ int sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 	if (inode) {
 		unsigned long cur_ino = inode->i_ino;
 
+		if (is_dir)
+			F2FS_I(inode)->cp_task = current;
+
 		filemap_fdatawrite(inode->i_mapping);
+
+		if (is_dir)
+			F2FS_I(inode)->cp_task = NULL;
+
 		iput(inode);
 		/* We need to give cpu to another writers. */
 		if (ino == cur_ino) {
@@ -1017,7 +1031,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 
 	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
 		up_write(&sbi->node_write);
-		err = sync_node_pages(sbi, &wbc, false);
+		err = sync_node_pages(sbi, &wbc, false, FS_CP_NODE_IO);
 		if (err) {
 			up_write(&sbi->node_change);
 			f2fs_unlock_all(sbi);
@@ -1115,7 +1129,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* Flush all the NAT/SIT pages */
 	while (get_pages(sbi, F2FS_DIRTY_META)) {
-		sync_meta_pages(sbi, META, LONG_MAX);
+		sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
 		if (unlikely(f2fs_cp_error(sbi)))
 			return -EIO;
 	}
@@ -1194,7 +1208,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 		/* Flush all the NAT BITS pages */
 		while (get_pages(sbi, F2FS_DIRTY_META)) {
-			sync_meta_pages(sbi, META, LONG_MAX);
+			sync_meta_pages(sbi, META, LONG_MAX, FS_CP_META_IO);
 			if (unlikely(f2fs_cp_error(sbi)))
 				return -EIO;
 		}
@@ -1249,7 +1263,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	percpu_counter_set(&sbi->alloc_valid_block_count, 0);
 
 	/* Here, we only have one bio having CP pack */
-	sync_meta_pages(sbi, META_FLUSH, LONG_MAX);
+	sync_meta_pages(sbi, META_FLUSH, LONG_MAX, FS_CP_META_IO);
 
 	/* wait for previous submitted meta pages writeback */
 	wait_on_all_pages_writeback(sbi);

commit 401db79f61e0810e7c9fa3c7425c0aef84e5c30a
Author: Yunlong Song <yunlong.song@huawei.com>
Date:   Thu Jul 27 20:11:00 2017 +0800

    f2fs: provide f2fs_balance_fs to __write_node_page
    
    Let node writeback also do f2fs_balance_fs to ensure there are always enough free
    segments.
    
    Signed-off-by: Yunlong Song <yunlong.song@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5b876f6d3f6b..3c84a2520796 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1017,7 +1017,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 
 	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
 		up_write(&sbi->node_write);
-		err = sync_node_pages(sbi, &wbc);
+		err = sync_node_pages(sbi, &wbc, false);
 		if (err) {
 			up_write(&sbi->node_change);
 			f2fs_unlock_all(sbi);

commit 4db08d016ccedb5b97869724a096990acad59685
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jul 14 11:45:21 2017 -0700

    f2fs: avoid cpu lockup
    
    Before retrying to flush data or dentry pages, we need to release cpu in order
    to prevent watchdog.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 56bbf592e487..5b876f6d3f6b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -879,6 +879,7 @@ int sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 	struct inode *inode;
 	struct f2fs_inode_info *fi;
 	bool is_dir = (type == DIR_INODE);
+	unsigned long ino = 0;
 
 	trace_f2fs_sync_dirty_inodes_enter(sbi->sb, is_dir,
 				get_pages(sbi, is_dir ?
@@ -901,8 +902,17 @@ int sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 	inode = igrab(&fi->vfs_inode);
 	spin_unlock(&sbi->inode_lock[type]);
 	if (inode) {
+		unsigned long cur_ino = inode->i_ino;
+
 		filemap_fdatawrite(inode->i_mapping);
 		iput(inode);
+		/* We need to give cpu to another writers. */
+		if (ino == cur_ino) {
+			congestion_wait(BLK_RW_ASYNC, HZ/50);
+			cond_resched();
+		} else {
+			ino = cur_ino;
+		}
 	} else {
 		/*
 		 * We should submit bio, since it exists several

commit d1aa245354ae4605d1183f542ed8d45811c439f6
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Jul 7 14:10:15 2017 +0800

    f2fs: use spin_{,un}lock_irq{save,restore}
    
    generic/361 reports below warning, this is because: once, there is
    someone entering into critical region of sbi.cp_lock, if write_end_io.
    f2fs_stop_checkpoint is invoked from an triggered IRQ, we will encounter
    deadlock.
    
    So this patch changes to use spin_{,un}lock_irq{save,restore} to create
    critical region without IRQ enabled to avoid potential deadlock.
    
     irq event stamp: 83391573
     loop: Write error at byte offset 438729728, length 1024.
     hardirqs last  enabled at (83391573): [<c1809752>] restore_all+0xf/0x65
     hardirqs last disabled at (83391572): [<c1809eac>] reschedule_interrupt+0x30/0x3c
     loop: Write error at byte offset 438860288, length 1536.
     softirqs last  enabled at (83389244): [<c180cc4e>] __do_softirq+0x1ae/0x476
     softirqs last disabled at (83389237): [<c101ca7c>] do_softirq_own_stack+0x2c/0x40
     loop: Write error at byte offset 438990848, length 2048.
     ================================
     WARNING: inconsistent lock state
     4.12.0-rc2+ #30 Tainted: G           O
     --------------------------------
     inconsistent {HARDIRQ-ON-W} -> {IN-HARDIRQ-W} usage.
     xfs_io/7959 [HC1[1]:SC0[0]:HE0:SE1] takes:
      (&(&sbi->cp_lock)->rlock){?.+...}, at: [<f96f96cc>] f2fs_stop_checkpoint+0x1c/0x50 [f2fs]
     {HARDIRQ-ON-W} state was registered at:
       __lock_acquire+0x527/0x7b0
       lock_acquire+0xae/0x220
       _raw_spin_lock+0x42/0x50
       do_checkpoint+0x165/0x9e0 [f2fs]
       write_checkpoint+0x33f/0x740 [f2fs]
       __f2fs_sync_fs+0x92/0x1f0 [f2fs]
       f2fs_sync_fs+0x12/0x20 [f2fs]
       sync_filesystem+0x67/0x80
       generic_shutdown_super+0x27/0x100
       kill_block_super+0x22/0x50
       kill_f2fs_super+0x3a/0x40 [f2fs]
       deactivate_locked_super+0x3d/0x70
       deactivate_super+0x40/0x60
       cleanup_mnt+0x39/0x70
       __cleanup_mnt+0x10/0x20
       task_work_run+0x69/0x80
       exit_to_usermode_loop+0x57/0x85
       do_fast_syscall_32+0x18c/0x1b0
       entry_SYSENTER_32+0x4c/0x7b
     irq event stamp: 1957420
     hardirqs last  enabled at (1957419): [<c1808f37>] _raw_spin_unlock_irq+0x27/0x50
     hardirqs last disabled at (1957420): [<c1809f9c>] call_function_single_interrupt+0x30/0x3c
     softirqs last  enabled at (1953784): [<c180cc4e>] __do_softirq+0x1ae/0x476
     softirqs last disabled at (1953773): [<c101ca7c>] do_softirq_own_stack+0x2c/0x40
    
     other info that might help us debug this:
      Possible unsafe locking scenario:
    
            CPU0
            ----
       lock(&(&sbi->cp_lock)->rlock);
       <Interrupt>
         lock(&(&sbi->cp_lock)->rlock);
    
      *** DEADLOCK ***
    
     2 locks held by xfs_io/7959:
      #0:  (sb_writers#13){.+.+.+}, at: [<c11fd7ca>] vfs_write+0x16a/0x190
      #1:  (&sb->s_type->i_mutex_key#16){+.+.+.}, at: [<f96e33f5>] f2fs_file_write_iter+0x25/0x140 [f2fs]
    
     stack backtrace:
     CPU: 2 PID: 7959 Comm: xfs_io Tainted: G           O    4.12.0-rc2+ #30
     Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
     Call Trace:
      dump_stack+0x5f/0x92
      print_usage_bug+0x1d3/0x1dd
      ? check_usage_backwards+0xe0/0xe0
      mark_lock+0x23d/0x280
      __lock_acquire+0x699/0x7b0
      ? __this_cpu_preempt_check+0xf/0x20
      ? trace_hardirqs_off_caller+0x91/0xe0
      lock_acquire+0xae/0x220
      ? f2fs_stop_checkpoint+0x1c/0x50 [f2fs]
      _raw_spin_lock+0x42/0x50
      ? f2fs_stop_checkpoint+0x1c/0x50 [f2fs]
      f2fs_stop_checkpoint+0x1c/0x50 [f2fs]
      f2fs_write_end_io+0x147/0x150 [f2fs]
      bio_endio+0x7a/0x1e0
      blk_update_request+0xad/0x410
      blk_mq_end_request+0x16/0x60
      lo_complete_rq+0x3c/0x70
      __blk_mq_complete_request_remote+0x11/0x20
      flush_smp_call_function_queue+0x6d/0x120
      ? debug_smp_processor_id+0x12/0x20
      generic_smp_call_function_single_interrupt+0x12/0x30
      smp_call_function_single_interrupt+0x25/0x40
      call_function_single_interrupt+0x37/0x3c
     EIP: _raw_spin_unlock_irq+0x2d/0x50
     EFLAGS: 00000296 CPU: 2
     EAX: 00000001 EBX: d2ccc51c ECX: 00000001 EDX: c1aacebd
     ESI: 00000000 EDI: 00000000 EBP: c96c9d1c ESP: c96c9d18
      DS: 007b ES: 007b FS: 00d8 GS: 0033 SS: 0068
      ? inherit_task_group.isra.98.part.99+0x6b/0xb0
      __add_to_page_cache_locked+0x1d4/0x290
      add_to_page_cache_lru+0x38/0xb0
      pagecache_get_page+0x8e/0x200
      f2fs_write_begin+0x96/0xf00 [f2fs]
      ? trace_hardirqs_on_caller+0xdd/0x1c0
      ? current_time+0x17/0x50
      ? trace_hardirqs_on+0xb/0x10
      generic_perform_write+0xa9/0x170
      __generic_file_write_iter+0x1a2/0x1f0
      ? f2fs_preallocate_blocks+0x137/0x160 [f2fs]
      f2fs_file_write_iter+0x6e/0x140 [f2fs]
      ? __lock_acquire+0x429/0x7b0
      __vfs_write+0xc1/0x140
      vfs_write+0x9b/0x190
      SyS_pwrite64+0x63/0xa0
      do_fast_syscall_32+0xa1/0x1b0
      entry_SYSENTER_32+0x4c/0x7b
     EIP: 0xb7786c61
     EFLAGS: 00000293 CPU: 2
     EAX: ffffffda EBX: 00000003 ECX: 08416000 EDX: 00001000
     ESI: 18b24000 EDI: 00000000 EBP: 00000003 ESP: bf9b36b0
      DS: 007b ES: 007b FS: 0000 GS: 0033 SS: 007b
    
    Fixes: aaec2b1d1879 ("f2fs: introduce cp_lock to protect updating of ckpt_flags")
    Cc: stable@vger.kernel.org
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 954917d582f8..56bbf592e487 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1053,8 +1053,9 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	unsigned long orphan_num = sbi->im[ORPHAN_INO].ino_num;
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
+	unsigned long flags;
 
-	spin_lock(&sbi->cp_lock);
+	spin_lock_irqsave(&sbi->cp_lock, flags);
 
 	if ((cpc->reason & CP_UMOUNT) &&
 			le32_to_cpu(ckpt->cp_pack_total_block_count) >
@@ -1085,14 +1086,14 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* set this flag to activate crc|cp_ver for recovery */
 	__set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG);
 
-	spin_unlock(&sbi->cp_lock);
+	spin_unlock_irqrestore(&sbi->cp_lock, flags);
 }
 
 static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
-	unsigned long orphan_num = sbi->im[ORPHAN_INO].ino_num;
+	unsigned long orphan_num = sbi->im[ORPHAN_INO].ino_num, flags;
 	block_t start_blk;
 	unsigned int data_sum_blocks, orphan_blocks;
 	__u32 crc32 = 0;
@@ -1134,12 +1135,12 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* 2 cp  + n data seg summary + orphan inode blocks */
 	data_sum_blocks = npages_for_summary_flush(sbi, false);
-	spin_lock(&sbi->cp_lock);
+	spin_lock_irqsave(&sbi->cp_lock, flags);
 	if (data_sum_blocks < NR_CURSEG_DATA_TYPE)
 		__set_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
 	else
 		__clear_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
-	spin_unlock(&sbi->cp_lock);
+	spin_unlock_irqrestore(&sbi->cp_lock, flags);
 
 	orphan_blocks = GET_ORPHAN_BLOCKS(orphan_num);
 	ckpt->cp_pack_start_sum = cpu_to_le32(1 + cp_payload_blks +

commit 0771fcc71c0c28bf31ac5c2c863b9f0de0fdf00d
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Jun 29 23:20:45 2017 +0800

    f2fs: skip ->writepages for {mete,node}_inode during recovery
    
    Skip ->writepages in prior to ->writepage for {meta,node}_inode during
    recovery, hence unneeded loop in ->writepages can be avoided.
    
    Moreover, check SBI_POR_DOING earlier while writebacking pages.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 12559a4b6c24..954917d582f8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -269,6 +269,9 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 	struct f2fs_sb_info *sbi = F2FS_M_SB(mapping);
 	long diff, written;
 
+	if (unlikely(is_sbi_flag_set(sbi, SBI_POR_DOING)))
+		goto skip_write;
+
 	/* collect a number of dirty meta pages and write together */
 	if (wbc->for_kupdate ||
 		get_pages(sbi, F2FS_DIRTY_META) < nr_pages_to_skip(sbi, META))

commit fb830fc5cfc90ba8236921aacb72c6d70bf78af7
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri May 19 23:37:01 2017 +0800

    f2fs: introduce io_list for serialize data/node IOs
    
    Serialize data/node IOs by using fifo list instead of mutex lock,
    it will help to enhance concurrency of f2fs, meanwhile keeping LFS
    IO semantics.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 13828f63a871..12559a4b6c24 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -162,6 +162,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		.op = REQ_OP_READ,
 		.op_flags = sync ? (REQ_META | REQ_PRIO) : REQ_RAHEAD,
 		.encrypted_page = NULL,
+		.in_list = false,
 	};
 	struct blk_plug plug;
 

commit b9109b0e49b93b0ae663330acb36561b8f4f6905
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed May 10 11:28:38 2017 -0700

    f2fs: remove unnecessary read cases in merged IO flow
    
    Merged IO flow doesn't need to care about read IOs.
    
    f2fs_submit_merged_bio -> f2fs_submit_merged_write
    f2fs_submit_merged_bios -> f2fs_submit_merged_writes
    f2fs_submit_merged_bio_cond -> f2fs_submit_merged_write_cond
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 8d92f8249000..13828f63a871 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -31,7 +31,7 @@ void f2fs_stop_checkpoint(struct f2fs_sb_info *sbi, bool end_io)
 	set_ckpt_flags(sbi, CP_ERROR_FLAG);
 	sbi->sb->s_flags |= MS_RDONLY;
 	if (!end_io)
-		f2fs_flush_merged_bios(sbi);
+		f2fs_flush_merged_writes(sbi);
 }
 
 /*
@@ -247,13 +247,13 @@ static int f2fs_write_meta_page(struct page *page,
 	dec_page_count(sbi, F2FS_DIRTY_META);
 
 	if (wbc->for_reclaim)
-		f2fs_submit_merged_bio_cond(sbi, page->mapping->host,
-						0, page->index, META, WRITE);
+		f2fs_submit_merged_write_cond(sbi, page->mapping->host,
+						0, page->index, META);
 
 	unlock_page(page);
 
 	if (unlikely(f2fs_cp_error(sbi)))
-		f2fs_submit_merged_bio(sbi, META, WRITE);
+		f2fs_submit_merged_write(sbi, META);
 
 	return 0;
 
@@ -356,7 +356,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 	}
 stop:
 	if (nwritten)
-		f2fs_submit_merged_bio(sbi, type, WRITE);
+		f2fs_submit_merged_write(sbi, type);
 
 	blk_finish_plug(&plug);
 
@@ -904,7 +904,7 @@ int sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 		 * We should submit bio, since it exists several
 		 * wribacking dentry pages in the freeing inode.
 		 */
-		f2fs_submit_merged_bio(sbi, DATA, WRITE);
+		f2fs_submit_merged_write(sbi, DATA);
 		cond_resched();
 	}
 	goto retry;
@@ -1293,7 +1293,7 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish block_ops");
 
-	f2fs_flush_merged_bios(sbi);
+	f2fs_flush_merged_writes(sbi);
 
 	/* this is the case of multiple fstrims without any changes */
 	if (cpc->reason & CP_DISCARD) {

commit 1919ffc0d7a300d4d8002e92ab3c6dea1974defc
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed May 10 11:23:36 2017 -0700

    f2fs: use f2fs_submit_page_bio for ra_meta_pages
    
    This patch avoids to use f2fs_submit_merged_bio for read, which was the only
    read case.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ea9c317b5916..8d92f8249000 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -207,12 +207,10 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		}
 
 		fio.page = page;
-		fio.old_blkaddr = fio.new_blkaddr;
-		f2fs_submit_page_mbio(&fio);
+		f2fs_submit_page_bio(&fio);
 		f2fs_put_page(page, 0);
 	}
 out:
-	f2fs_submit_merged_bio(sbi, META, READ);
 	blk_finish_plug(&plug);
 	return blkno - start;
 }

commit 1f43e2ad7bff54f7c82a084a57e5c90da0d3f4d9
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Apr 28 13:56:08 2017 +0800

    f2fs: introduce CP_TRIMMED_FLAG to avoid unneeded discard
    
    Introduce CP_TRIMMED_FLAG to indicate all invalid block were trimmed
    before umount, so once we do mount with image which contain the flag,
    we don't record invalid blocks as undiscard one, when fstrim is being
    triggered, we can avoid issuing redundant discard commands.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 27578903eeb6..ea9c317b5916 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1059,6 +1059,9 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 			sbi->blocks_per_seg - NM_I(sbi)->nat_bits_blocks)
 		disable_nat_bits(sbi, false);
 
+	if (cpc->reason & CP_TRIMMED)
+		__set_ckpt_flags(ckpt, CP_TRIMMED_FLAG);
+
 	if (cpc->reason & CP_UMOUNT)
 		__set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
 	else

commit c473f1a9658b6c23d576136d5a49b1c731ef1767
Author: Chao Yu <yuchao0@huawei.com>
Date:   Thu Apr 27 20:40:39 2017 +0800

    f2fs: allow cpc->reason to indicate more than one reason
    
    Change to use different bits of cpc->reason to indicate different status,
    so cpc->reason can indicate more than one reason.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 800be94f8cb3..27578903eeb6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1054,17 +1054,17 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	spin_lock(&sbi->cp_lock);
 
-	if (cpc->reason == CP_UMOUNT &&
+	if ((cpc->reason & CP_UMOUNT) &&
 			le32_to_cpu(ckpt->cp_pack_total_block_count) >
 			sbi->blocks_per_seg - NM_I(sbi)->nat_bits_blocks)
 		disable_nat_bits(sbi, false);
 
-	if (cpc->reason == CP_UMOUNT)
+	if (cpc->reason & CP_UMOUNT)
 		__set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
 	else
 		__clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
 
-	if (cpc->reason == CP_FASTBOOT)
+	if (cpc->reason & CP_FASTBOOT)
 		__set_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
 	else
 		__clear_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
@@ -1272,8 +1272,8 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	mutex_lock(&sbi->cp_mutex);
 
 	if (!is_sbi_flag_set(sbi, SBI_IS_DIRTY) &&
-		(cpc->reason == CP_FASTBOOT || cpc->reason == CP_SYNC ||
-		(cpc->reason == CP_DISCARD && !sbi->discard_blks)))
+		((cpc->reason & CP_FASTBOOT) || (cpc->reason & CP_SYNC) ||
+		((cpc->reason & CP_DISCARD) && !sbi->discard_blks)))
 		goto out;
 	if (unlikely(f2fs_cp_error(sbi))) {
 		err = -EIO;
@@ -1295,7 +1295,7 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	f2fs_flush_merged_bios(sbi);
 
 	/* this is the case of multiple fstrims without any changes */
-	if (cpc->reason == CP_DISCARD) {
+	if (cpc->reason & CP_DISCARD) {
 		if (!exist_trim_candidates(sbi, cpc)) {
 			unblock_operations(sbi);
 			goto out;
@@ -1333,7 +1333,7 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	unblock_operations(sbi);
 	stat_inc_cp_count(sbi->stat_info);
 
-	if (cpc->reason == CP_RECOVERY)
+	if (cpc->reason & CP_RECOVERY)
 		f2fs_msg(sbi->sb, KERN_NOTICE,
 			"checkpoint: version = %llx", ckpt_ver);
 

commit 309738835451739dc019dc3d5bb4c93d487ff36b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Apr 11 19:15:33 2017 -0700

    f2fs: give time to flush dirty pages for checkpoint
    
    If all the threads are waiting for checkpoint, we have no chance to flush
    required dirty pages.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9db92990f193..800be94f8cb3 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -980,6 +980,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		err = sync_dirty_inodes(sbi, DIR_INODE);
 		if (err)
 			goto out;
+		cond_resched();
 		goto retry_flush_dents;
 	}
 
@@ -995,6 +996,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		err = f2fs_sync_inode_meta(sbi);
 		if (err)
 			goto out;
+		cond_resched();
 		goto retry_flush_dents;
 	}
 
@@ -1009,6 +1011,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 			f2fs_unlock_all(sbi);
 			goto out;
 		}
+		cond_resched();
 		goto retry_flush_nodes;
 	}
 

commit fc2e2875d54c3571fe7c9dbed83814bd26e8a33a
Author: Kaixu Xia <xiakaixu@huawei.com>
Date:   Sun Apr 2 02:39:48 2017 +0800

    f2fs: remove the redundant variable definition
    
    The variable 'i' has been defined before, so here we can
    use it directly.
    
    Signed-off-by: Kaixu Xia <xiakaixu@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9aba0bb340a0..9db92990f193 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1163,7 +1163,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* write nat bits */
 	if (enabled_nat_bits(sbi, cpc)) {
 		__u64 cp_ver = cur_cp_version(ckpt);
-		unsigned int i;
 		block_t blk;
 
 		cp_ver |= ((__u64)crc32 << 32);

commit 59c9081bc86ef0b273a41abf2c1f413301429a6d
Author: Yunlei He <heyunlei@huawei.com>
Date:   Mon Mar 13 20:22:18 2017 +0800

    f2fs: allow write page cache when writting cp
    
    This patch allow write data to normal file when writting
    new checkpoint.
    
    We relax three limitations for write_begin path:
    1. data allocation
    2. node allocation
    3. variables in checkpoint
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index adcc2c370df9..9aba0bb340a0 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -944,6 +944,19 @@ int f2fs_sync_inode_meta(struct f2fs_sb_info *sbi)
 	return 0;
 }
 
+static void __prepare_cp_block(struct f2fs_sb_info *sbi)
+{
+	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
+	struct f2fs_nm_info *nm_i = NM_I(sbi);
+	nid_t last_nid = nm_i->next_scan_nid;
+
+	next_free_nid(sbi, &last_nid);
+	ckpt->valid_block_count = cpu_to_le64(valid_user_blocks(sbi));
+	ckpt->valid_node_count = cpu_to_le32(valid_node_count(sbi));
+	ckpt->valid_inode_count = cpu_to_le32(valid_inode_count(sbi));
+	ckpt->next_free_nid = cpu_to_le32(last_nid);
+}
+
 /*
  * Freeze all the FS-operations for checkpoint.
  */
@@ -970,7 +983,14 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		goto retry_flush_dents;
 	}
 
+	/*
+	 * POR: we should ensure that there are no dirty node pages
+	 * until finishing nat/sit flush. inode->i_blocks can be updated.
+	 */
+	down_write(&sbi->node_change);
+
 	if (get_pages(sbi, F2FS_DIRTY_IMETA)) {
+		up_write(&sbi->node_change);
 		f2fs_unlock_all(sbi);
 		err = f2fs_sync_inode_meta(sbi);
 		if (err)
@@ -978,10 +998,6 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		goto retry_flush_dents;
 	}
 
-	/*
-	 * POR: we should ensure that there are no dirty node pages
-	 * until finishing nat/sit flush.
-	 */
 retry_flush_nodes:
 	down_write(&sbi->node_write);
 
@@ -989,11 +1005,19 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		up_write(&sbi->node_write);
 		err = sync_node_pages(sbi, &wbc);
 		if (err) {
+			up_write(&sbi->node_change);
 			f2fs_unlock_all(sbi);
 			goto out;
 		}
 		goto retry_flush_nodes;
 	}
+
+	/*
+	 * sbi->node_change is used only for AIO write_begin path which produces
+	 * dirty node blocks and some checkpoint values by block allocation.
+	 */
+	__prepare_cp_block(sbi);
+	up_write(&sbi->node_change);
 out:
 	blk_finish_plug(&plug);
 	return err;
@@ -1061,7 +1085,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
 	unsigned long orphan_num = sbi->im[ORPHAN_INO].ino_num;
-	nid_t last_nid = nm_i->next_scan_nid;
 	block_t start_blk;
 	unsigned int data_sum_blocks, orphan_blocks;
 	__u32 crc32 = 0;
@@ -1078,14 +1101,11 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 			return -EIO;
 	}
 
-	next_free_nid(sbi, &last_nid);
-
 	/*
 	 * modify checkpoint
 	 * version number is already updated
 	 */
 	ckpt->elapsed_time = cpu_to_le64(get_mtime(sbi));
-	ckpt->valid_block_count = cpu_to_le64(valid_user_blocks(sbi));
 	ckpt->free_segment_count = cpu_to_le32(free_segments(sbi));
 	for (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {
 		ckpt->cur_node_segno[i] =
@@ -1104,10 +1124,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 				curseg_alloc_type(sbi, i + CURSEG_HOT_DATA);
 	}
 
-	ckpt->valid_node_count = cpu_to_le32(valid_node_count(sbi));
-	ckpt->valid_inode_count = cpu_to_le32(valid_inode_count(sbi));
-	ckpt->next_free_nid = cpu_to_le32(last_nid);
-
 	/* 2 cp  + n data seg summary + orphan inode blocks */
 	data_sum_blocks = npages_for_summary_flush(sbi, false);
 	spin_lock(&sbi->cp_lock);

commit 99f4b917b0411f660b06ffd30f3dc36cf7b05710
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Mar 22 17:23:46 2017 +0800

    f2fs: don't track volatile file in dirty inode list
    
    Don't track volatile file in dirty inode list, otherwise with data_flush
    option, background thread will entry into endless loop for flushing
    journal file's pages.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7dd7dd5914c5..adcc2c370df9 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -817,7 +817,9 @@ static void __add_dirty_inode(struct inode *inode, enum inode_type type)
 		return;
 
 	set_inode_flag(inode, flag);
-	list_add_tail(&F2FS_I(inode)->dirty_list, &sbi->inode_list[type]);
+	if (!f2fs_is_volatile_file(inode))
+		list_add_tail(&F2FS_I(inode)->dirty_list,
+						&sbi->inode_list[type]);
 	stat_inc_dirty_inode(sbi, type);
 }
 

commit c6f89dfd528041de2e71788495579a18c0363869
Author: Kinglong Mee <kinglongmee@gmail.com>
Date:   Wed Mar 15 21:12:50 2017 +0800

    f2fs: sanity check of crc_offset from raw checkpoint
    
    The crc_offset towards or beyond the end of block is wrong,
    sanity check it.
    
    Signed-off-by: Kinglong Mee <kinglongmee@gmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 22348c7df67d..7dd7dd5914c5 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -678,7 +678,7 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 	*cp_block = (struct f2fs_checkpoint *)page_address(*cp_page);
 
 	crc_offset = le32_to_cpu((*cp_block)->checksum_offset);
-	if (crc_offset >= blk_size) {
+	if (crc_offset > (blk_size - sizeof(__le32))) {
 		f2fs_msg(sbi->sb, KERN_WARNING,
 			"invalid crc_offset: %zu", crc_offset);
 		return -EINVAL;

commit a29d0e0bc0eeefad2a50a8aa7e3f4b98f72c7feb
Author: Yunlei He <heyunlei@huawei.com>
Date:   Wed Mar 1 18:07:10 2017 +0800

    f2fs: skip writeback meta pages if cp_mutex acquire failed
    
    Skip writeback meta pages if cp_mutex lock acquire failed, cp will
    flush dirty pages instead.
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3c3d2d01448d..22348c7df67d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -275,10 +275,11 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 		get_pages(sbi, F2FS_DIRTY_META) < nr_pages_to_skip(sbi, META))
 		goto skip_write;
 
-	trace_f2fs_writepages(mapping->host, wbc, META);
+	/* if locked failed, cp will flush dirty pages instead */
+	if (!mutex_trylock(&sbi->cp_mutex))
+		goto skip_write;
 
-	/* if mounting is failed, skip writing node pages */
-	mutex_lock(&sbi->cp_mutex);
+	trace_f2fs_writepages(mapping->host, wbc, META);
 	diff = nr_pages_to_write(sbi, META, wbc);
 	written = sync_meta_pages(sbi, META, wbc->nr_to_write);
 	mutex_unlock(&sbi->cp_mutex);

commit 5ce4738a0250ba9b6fbc89900ee0fc92a5eb60db
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Mar 7 13:54:56 2017 -0800

    f2fs: show more precise message on orphan recovery failure
    
    This case is not caused by fsck.f2fs. User needs to retry mount.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b72a9aad296c..3c3d2d01448d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -567,7 +567,7 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	if (ni.blk_addr != NULL_ADDR) {
 		set_sbi_flag(sbi, SBI_NEED_FSCK);
 		f2fs_msg(sbi->sb, KERN_WARNING,
-			"%s: orphan failed (ino=%x), run fsck to fix.",
+			"%s: orphan failed (ino=%x) by kernel, retry mount.",
 				__func__, ino);
 		return -EIO;
 	}

commit 10047f537c8fb33599bae599ed0e1d9551639d80
Author: Kinglong Mee <kinglongmee@gmail.com>
Date:   Sat Mar 11 21:18:01 2017 +0800

    f2fs: le32_to_cpu for ckpt->cp_pack_total_block_count
    
    Fixes: 22ad0b6ab4 ("f2fs: add bitmaps for empty or full NAT blocks")
    Signed-off-by: Kinglong Mee <kinglongmee@gmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0339daf4ca02..b72a9aad296c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1024,7 +1024,8 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	spin_lock(&sbi->cp_lock);
 
-	if (cpc->reason == CP_UMOUNT && ckpt->cp_pack_total_block_count >
+	if (cpc->reason == CP_UMOUNT &&
+			le32_to_cpu(ckpt->cp_pack_total_block_count) >
 			sbi->blocks_per_seg - NM_I(sbi)->nat_bits_blocks)
 		disable_nat_bits(sbi, false);
 

commit ced2c7ea8e99b46755a270872cd5ba61c27cffad
Author: Kinglong Mee <kinglongmee@gmail.com>
Date:   Sat Feb 25 19:53:39 2017 +0800

    f2fs: new helper cur_cp_crc() getting crc in f2fs_checkpoint
    
    There are four places that getting the crc value in f2fs_checkpoint,
    just add a new helper cur_cp_crc for them.
    
    Signed-off-by: Kinglong Mee <kinglongmee@gmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 04d7c244c0f0..0339daf4ca02 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -683,8 +683,7 @@ static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
 		return -EINVAL;
 	}
 
-	crc = le32_to_cpu(*((__le32 *)((unsigned char *)*cp_block
-							+ crc_offset)));
+	crc = cur_cp_crc(*cp_block);
 	if (!f2fs_crc_valid(sbi, crc, *cp_block, crc_offset)) {
 		f2fs_msg(sbi->sb, KERN_WARNING, "invalid crc value");
 		return -EINVAL;

commit 55523519bc7227e651fd4febeb3aafdd22b8af1c
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sat Feb 25 11:08:28 2017 +0800

    f2fs: show simple call stack in fault injection message
    
    Previously kernel message can show that in which function we do the
    injection, but unfortunately, most of the caller are the same, for
    tracking more information of injection path, it needs to show upper
    caller's name. This patch supports that ability.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index cd7132121573..04d7c244c0f0 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -494,6 +494,7 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 #ifdef CONFIG_F2FS_FAULT_INJECTION
 	if (time_to_inject(sbi, FAULT_ORPHAN)) {
 		spin_unlock(&im->ino_lock);
+		f2fs_show_injection_info(FAULT_ORPHAN);
 		return -ENOSPC;
 	}
 #endif

commit 22ad0b6ab46683975c6da032f1c2593066c7b3bd
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Feb 9 10:38:09 2017 -0800

    f2fs: add bitmaps for empty or full NAT blocks
    
    This patches adds bitmaps to represent empty or full NAT blocks containing
    free nid entries.
    
    If we can find valid crc|cp_ver in the last block of checkpoint pack, we'll
    use these bitmaps when building free nids. In order to avoid checkpointing
    burden, up-to-date bitmaps will be flushed only during umount time. So,
    normally we can get this gain, but when power-cut happens, we rely on fsck.f2fs
    which recovers this bitmap again.
    
    After this patch, we build free nids from nid #0 at mount time to make more
    full NAT blocks, but in runtime, we check empty NAT blocks to load free nids
    without loading any NAT pages from disk.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 042f8d9afe44..cd7132121573 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1024,6 +1024,10 @@ static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	spin_lock(&sbi->cp_lock);
 
+	if (cpc->reason == CP_UMOUNT && ckpt->cp_pack_total_block_count >
+			sbi->blocks_per_seg - NM_I(sbi)->nat_bits_blocks)
+		disable_nat_bits(sbi, false);
+
 	if (cpc->reason == CP_UMOUNT)
 		__set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
 	else
@@ -1136,6 +1140,28 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	start_blk = __start_cp_next_addr(sbi);
 
+	/* write nat bits */
+	if (enabled_nat_bits(sbi, cpc)) {
+		__u64 cp_ver = cur_cp_version(ckpt);
+		unsigned int i;
+		block_t blk;
+
+		cp_ver |= ((__u64)crc32 << 32);
+		*(__le64 *)nm_i->nat_bits = cpu_to_le64(cp_ver);
+
+		blk = start_blk + sbi->blocks_per_seg - nm_i->nat_bits_blocks;
+		for (i = 0; i < nm_i->nat_bits_blocks; i++)
+			update_meta_page(sbi, nm_i->nat_bits +
+					(i << F2FS_BLKSIZE_BITS), blk + i);
+
+		/* Flush all the NAT BITS pages */
+		while (get_pages(sbi, F2FS_DIRTY_META)) {
+			sync_meta_pages(sbi, META, LONG_MAX);
+			if (unlikely(f2fs_cp_error(sbi)))
+				return -EIO;
+		}
+	}
+
 	/* need to wait for end_io results */
 	wait_on_all_pages_writeback(sbi);
 	if (unlikely(f2fs_cp_error(sbi)))
@@ -1272,7 +1298,7 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	ckpt->checkpoint_ver = cpu_to_le64(++ckpt_ver);
 
 	/* write cached NAT/SIT entries to NAT/SIT area */
-	flush_nat_entries(sbi);
+	flush_nat_entries(sbi, cpc);
 	flush_sit_entries(sbi, cpc);
 
 	/* unlock all the fs_lock[] in do_checkpoint() */

commit 9b064f7d0c9ab179b9cb18e144ab65d7ea953443
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Sat Feb 11 10:46:44 2017 -0800

    f2fs: remove build_free_nids() during checkpoint
    
    Let's avoid build_free_nids() in checkpoint path.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index e6e42a4b1344..042f8d9afe44 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -999,8 +999,6 @@ static int block_operations(struct f2fs_sb_info *sbi)
 static void unblock_operations(struct f2fs_sb_info *sbi)
 {
 	up_write(&sbi->node_write);
-
-	build_free_nids(sbi, false);
 	f2fs_unlock_all(sbi);
 }
 

commit 942fd3192f83cef54bc0d485937fd5382ac5acd0
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Feb 1 16:51:22 2017 -0800

    f2fs: check last page index in cached bio to decide submission
    
    If the cached bio has the last page's index, then we need to submit it.
    Otherwise, we don't need to submit it and can wait for further IO merges.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index fb8cdfcaece6..e6e42a4b1344 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -249,7 +249,8 @@ static int f2fs_write_meta_page(struct page *page,
 	dec_page_count(sbi, F2FS_DIRTY_META);
 
 	if (wbc->for_reclaim)
-		f2fs_submit_merged_bio_cond(sbi, NULL, page, 0, META, WRITE);
+		f2fs_submit_merged_bio_cond(sbi, page->mapping->host,
+						0, page->index, META, WRITE);
 
 	unlock_page(page);
 

commit 939afa943c5290a3b92f01612a792af17bc98115
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sat Jan 7 18:49:42 2017 +0800

    f2fs: clean up with list_{first, last}_entry
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ccea40763d9d..fb8cdfcaece6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -891,7 +891,7 @@ int sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 				F2FS_DIRTY_DENTS : F2FS_DIRTY_DATA));
 		return 0;
 	}
-	fi = list_entry(head->next, struct f2fs_inode_info, dirty_list);
+	fi = list_first_entry(head, struct f2fs_inode_info, dirty_list);
 	inode = igrab(&fi->vfs_inode);
 	spin_unlock(&sbi->inode_lock[type]);
 	if (inode) {
@@ -924,7 +924,7 @@ int f2fs_sync_inode_meta(struct f2fs_sb_info *sbi)
 			spin_unlock(&sbi->inode_lock[DIRTY_META]);
 			return 0;
 		}
-		fi = list_entry(head->next, struct f2fs_inode_info,
+		fi = list_first_entry(head, struct f2fs_inode_info,
 							gdirty_list);
 		inode = igrab(&fi->vfs_inode);
 		spin_unlock(&sbi->inode_lock[DIRTY_META]);

commit 25290fa5591d81767713db304e0d567bf991786f
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Dec 29 22:06:15 2016 -0800

    f2fs: return fs_trim if there is no candidate
    
    If there is no candidate to submit discard command during f2fs_trim_fs, let's
    return without checkpoint.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 917b5c5053ae..ccea40763d9d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1249,6 +1249,11 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* this is the case of multiple fstrims without any changes */
 	if (cpc->reason == CP_DISCARD) {
+		if (!exist_trim_candidates(sbi, cpc)) {
+			unblock_operations(sbi);
+			goto out;
+		}
+
 		if (NM_I(sbi)->dirty_nat_cnt == 0 &&
 				SIT_I(sbi)->dirty_sentries == 0 &&
 				prefree_segments(sbi) == 0) {

commit 0333ad4e4f49e14217256e1db1134a70cf60b2de
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Dec 29 16:58:54 2016 -0800

    f2fs: avoid needless checkpoint in f2fs_trim_fs
    
    The f2fs_trim_fs() doesn't need to do checkpoint if there are newly allocated
    data blocks only which didn't change the critical checkpoint data such as nat
    and sit entries.
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 1a9ba69a22ba..917b5c5053ae 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1248,14 +1248,15 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	f2fs_flush_merged_bios(sbi);
 
 	/* this is the case of multiple fstrims without any changes */
-	if (cpc->reason == CP_DISCARD && !is_sbi_flag_set(sbi, SBI_IS_DIRTY)) {
-		f2fs_bug_on(sbi, NM_I(sbi)->dirty_nat_cnt);
-		f2fs_bug_on(sbi, SIT_I(sbi)->dirty_sentries);
-		f2fs_bug_on(sbi, prefree_segments(sbi));
-		flush_sit_entries(sbi, cpc);
-		clear_prefree_segments(sbi, cpc);
-		unblock_operations(sbi);
-		goto out;
+	if (cpc->reason == CP_DISCARD) {
+		if (NM_I(sbi)->dirty_nat_cnt == 0 &&
+				SIT_I(sbi)->dirty_sentries == 0 &&
+				prefree_segments(sbi) == 0) {
+			flush_sit_entries(sbi, cpc);
+			clear_prefree_segments(sbi, cpc);
+			unblock_operations(sbi);
+			goto out;
+		}
 	}
 
 	/*

commit 4e6a8d9b224f886362ea6e8f6046b541437c944f
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Dec 29 14:07:53 2016 -0800

    f2fs: relax async discard commands more
    
    This patch relaxes async discard commands to avoid waiting its end_io during
    checkpoint.
    Instead of waiting them during checkpoint, it will be done when actually reusing
    them.
    
    Test on initial partition of nvme drive.
    
     # time fstrim /mnt/test
    
    Before : 6.158s
    After : 4.822s
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f73ee9534d83..1a9ba69a22ba 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1254,7 +1254,6 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		f2fs_bug_on(sbi, prefree_segments(sbi));
 		flush_sit_entries(sbi, cpc);
 		clear_prefree_segments(sbi, cpc);
-		f2fs_wait_all_discard_bio(sbi);
 		unblock_operations(sbi);
 		goto out;
 	}
@@ -1273,12 +1272,10 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* unlock all the fs_lock[] in do_checkpoint() */
 	err = do_checkpoint(sbi, cpc);
-	if (err) {
+	if (err)
 		release_discard_addrs(sbi);
-	} else {
+	else
 		clear_prefree_segments(sbi, cpc);
-		f2fs_wait_all_discard_bio(sbi);
-	}
 
 	unblock_operations(sbi);
 	stat_inc_cp_count(sbi->stat_info);

commit 09cb6464fe5e7fcd5177911429badd139c4481b7
Merge: 19d37ce2a715 c0ed4405a99e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 14 09:07:36 2016 -0800

    Merge tag 'for-f2fs-4.10' of git://git.kernel.org/pub/scm/linux/kernel/git/jaegeuk/f2fs
    
    Pull f2fs updates from Jaegeuk Kim:
     "This patch series contains several performance tuning patches
      regarding to the IO submission flow, in addition to supporting new
      features such as a ZBC-base drive and multiple devices.
    
      It also includes some major bug fixes such as:
       - checkpoint version control
       - fdatasync-related roll-forward recovery routine
       - memory boundary or null-pointer access in corner cases
       - missing error cases
    
      It has various minor clean-up patches as well"
    
    * tag 'for-f2fs-4.10' of git://git.kernel.org/pub/scm/linux/kernel/git/jaegeuk/f2fs: (66 commits)
      f2fs: fix a missing size change in f2fs_setattr
      f2fs: fix to access nullified flush_cmd_control pointer
      f2fs: free meta pages if sanity check for ckpt is failed
      f2fs: detect wrong layout
      f2fs: call sync_fs when f2fs is idle
      Revert "f2fs: use percpu_counter for # of dirty pages in inode"
      f2fs: return AOP_WRITEPAGE_ACTIVATE for writepage
      f2fs: do not activate auto_recovery for fallocated i_size
      f2fs: fix to determine start_cp_addr by sbi->cur_cp_pack
      f2fs: fix 32-bit build
      f2fs: set ->owner for debugfs status file's file_operations
      f2fs: fix incorrect free inode count in ->statfs
      f2fs: drop duplicate header timer.h
      f2fs: fix wrong AUTO_RECOVER condition
      f2fs: do not recover i_size if it's valid
      f2fs: fix fdatasync
      f2fs: fix to account total free nid correctly
      f2fs: fix an infinite loop when flush nodes in cp
      f2fs: don't wait writeback for datas during checkpoint
      f2fs: fix wrong written_valid_blocks counting
      ...

commit a2125ff7dd1ed3a2a53cdc1f8f9c9cec9cfaa7ab
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Dec 5 17:25:32 2016 -0800

    f2fs: free meta pages if sanity check for ckpt is failed
    
    This fixes missing freeing meta pages in the error case.
    
    Tested-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 35601b0d077f..698b13ae261c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -770,7 +770,7 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 
 	/* Sanity checking of checkpoint */
 	if (sanity_check_ckpt(sbi))
-		goto fail_no_cp;
+		goto free_fail_no_cp;
 
 	if (cur_page == cp1)
 		sbi->cur_cp_pack = 1;
@@ -798,6 +798,9 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	f2fs_put_page(cp2, 1);
 	return 0;
 
+free_fail_no_cp:
+	f2fs_put_page(cp1, 1);
+	f2fs_put_page(cp2, 1);
 fail_no_cp:
 	kfree(sbi->ckpt);
 	return -EINVAL;

commit 8508e44ae98622f841f5ef29d0bf3d5db4e0c1cc
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Nov 24 12:45:15 2016 -0800

    f2fs: fix to determine start_cp_addr by sbi->cur_cp_pack
    
    We don't guarantee cp_addr is fixed by cp_version.
    This is to sync with f2fs-tools.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 54cc6a9a0d30..35601b0d077f 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -772,6 +772,11 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	if (sanity_check_ckpt(sbi))
 		goto fail_no_cp;
 
+	if (cur_page == cp1)
+		sbi->cur_cp_pack = 1;
+	else
+		sbi->cur_cp_pack = 2;
+
 	if (cp_blks <= 1)
 		goto done;
 
@@ -1127,7 +1132,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 				le32_to_cpu(ckpt->checksum_offset)))
 				= cpu_to_le32(crc32);
 
-	start_blk = __start_cp_addr(sbi);
+	start_blk = __start_cp_next_addr(sbi);
 
 	/* need to wait for end_io results */
 	wait_on_all_pages_writeback(sbi);
@@ -1190,6 +1195,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 	clear_sbi_flag(sbi, SBI_NEED_CP);
+	__set_cp_next_pack(sbi);
 
 	/*
 	 * redirty superblock if metadata like node page or inode cache is

commit 36951b38d13ac7cce9fcf89e0e01c22ed0d05688
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Nov 16 10:41:20 2016 +0800

    f2fs: don't wait writeback for datas during checkpoint
    
    Normally, while committing checkpoint, we will wait on all pages to be
    writebacked no matter the page is data or metadata, so in scenario where
    there are lots of data IO being submitted with metadata, we may suffer
    long latency for waiting writeback during checkpoint.
    
    Indeed, we only care about persistence for pages with metadata, but not
    pages with data, as file system consistent are only related to metadate,
    so in order to avoid encountering long latency in above scenario, let's
    recognize and reference metadata in submitted IOs, wait writeback only
    for metadatas.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index e5677e4a69d6..54cc6a9a0d30 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1002,7 +1002,7 @@ static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 	for (;;) {
 		prepare_to_wait(&sbi->cp_wait, &wait, TASK_UNINTERRUPTIBLE);
 
-		if (!atomic_read(&sbi->nr_wb_bios))
+		if (!get_pages(sbi, F2FS_WB_CP_DATA))
 			break;
 
 		io_schedule_timeout(5*HZ);

commit 18340edc8da20b0d399eb25ba4bb631b27652f46
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Oct 19 18:27:56 2016 -0700

    f2fs: make clean inodes when flushing inode page
    
    This patch tries to make more clean inodes when flushing dirty inodes in
    checkpoint.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 157b7fdc2c67..e5677e4a69d6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -921,7 +921,11 @@ int f2fs_sync_inode_meta(struct f2fs_sb_info *sbi)
 		inode = igrab(&fi->vfs_inode);
 		spin_unlock(&sbi->inode_lock[DIRTY_META]);
 		if (inode) {
-			update_inode_page(inode);
+			sync_inode_metadata(inode, 0);
+
+			/* it's on eviction */
+			if (is_inode_flag_set(inode, FI_DIRTY_INODE))
+				update_inode_page(inode);
 			iput(inode);
 		}
 	};

commit 664ba972df9b96942191db3068274cc1db899774
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Oct 18 11:07:45 2016 -0700

    f2fs: use BIO_MAX_PAGES for bio allocation
    
    We don't need to allocate bio partially in order to maximize sequential writes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 654f5d7f9288..157b7fdc2c67 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -228,7 +228,7 @@ void ra_meta_pages_cond(struct f2fs_sb_info *sbi, pgoff_t index)
 	f2fs_put_page(page, 0);
 
 	if (readahead)
-		ra_meta_pages(sbi, index, MAX_BIO_BLOCKS(sbi), META_POR, true);
+		ra_meta_pages(sbi, index, BIO_MAX_PAGES, META_POR, true);
 }
 
 static int f2fs_write_meta_page(struct page *page,

commit 3a2ad5672bb36ee9c07bab97dadc8b0f70d391f4
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Oct 11 22:31:35 2016 +0800

    f2fs: don't interrupt free nids building during nid allocation
    
    Let build_free_nids support sync/async methods, in allocation flow of nids,
    we use synchronuous method, so that we can avoid looping in alloc_nid when
    free memory is low; in unblock_operations and f2fs_balance_fs_bg we use
    asynchronuous method in where low memory condition can interrupt us.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7db2aa2280ad..654f5d7f9288 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -987,7 +987,7 @@ static void unblock_operations(struct f2fs_sb_info *sbi)
 {
 	up_write(&sbi->node_write);
 
-	build_free_nids(sbi);
+	build_free_nids(sbi, false);
 	f2fs_unlock_all(sbi);
 }
 

commit 2dd15654ac0abe587a245a09a7823bbbd588bfb7
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Oct 11 22:57:00 2016 +0800

    f2fs: fix to release discard entries during checkpoint
    
    In f2fs_fill_super, if there is any IO error occurs during recovery,
    cached discard entries will be leaked, in order to avoid this, make
    write_checkpoint() handle memory release by itself, besides, move
    clear_prefree_segments to write_checkpoint for readability.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7e9b504bd8b2..7db2aa2280ad 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1184,7 +1184,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (unlikely(f2fs_cp_error(sbi)))
 		return -EIO;
 
-	clear_prefree_segments(sbi, cpc);
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 	clear_sbi_flag(sbi, SBI_NEED_CP);
 
@@ -1261,8 +1260,12 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* unlock all the fs_lock[] in do_checkpoint() */
 	err = do_checkpoint(sbi, cpc);
-
-	f2fs_wait_all_discard_bio(sbi);
+	if (err) {
+		release_discard_addrs(sbi);
+	} else {
+		clear_prefree_segments(sbi, cpc);
+		f2fs_wait_all_discard_bio(sbi);
+	}
 
 	unblock_operations(sbi);
 	stat_inc_cp_count(sbi->stat_info);

commit 70fd76140a6cb63262bd47b68d57b42e889c10ee
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 1 07:40:10 2016 -0600

    block,fs: use REQ_* flags directly
    
    Remove the WRITE_* and READ_SYNC wrappers, and just use the flags
    directly.  Where applicable this also drops usage of the
    bio_set_op_attrs wrapper.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7e9b504bd8b2..d935c06a84f0 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -65,7 +65,7 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 		.sbi = sbi,
 		.type = META,
 		.op = REQ_OP_READ,
-		.op_flags = READ_SYNC | REQ_META | REQ_PRIO,
+		.op_flags = REQ_META | REQ_PRIO,
 		.old_blkaddr = index,
 		.new_blkaddr = index,
 		.encrypted_page = NULL,
@@ -160,7 +160,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		.sbi = sbi,
 		.type = META,
 		.op = REQ_OP_READ,
-		.op_flags = sync ? (READ_SYNC | REQ_META | REQ_PRIO) : REQ_RAHEAD,
+		.op_flags = sync ? (REQ_META | REQ_PRIO) : REQ_RAHEAD,
 		.encrypted_page = NULL,
 	};
 	struct blk_plug plug;

commit e4c5d8489a41209534699220021dab409e4d4f55
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Sep 30 17:37:43 2016 -0700

    f2fs: introduce update_ckpt_flags to clean up
    
    This patch add update_ckpt_flags() to clean up the flow.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7e2632835031..7e9b504bd8b2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1006,6 +1006,37 @@ static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 	finish_wait(&sbi->cp_wait, &wait);
 }
 
+static void update_ckpt_flags(struct f2fs_sb_info *sbi, struct cp_control *cpc)
+{
+	unsigned long orphan_num = sbi->im[ORPHAN_INO].ino_num;
+	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
+
+	spin_lock(&sbi->cp_lock);
+
+	if (cpc->reason == CP_UMOUNT)
+		__set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+	else
+		__clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+
+	if (cpc->reason == CP_FASTBOOT)
+		__set_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
+	else
+		__clear_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
+
+	if (orphan_num)
+		__set_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
+	else
+		__clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
+
+	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK))
+		__set_ckpt_flags(ckpt, CP_FSCK_FLAG);
+
+	/* set this flag to activate crc|cp_ver for recovery */
+	__set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG);
+
+	spin_unlock(&sbi->cp_lock);
+}
+
 static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
@@ -1080,29 +1111,8 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 				cp_payload_blks + data_sum_blocks +
 				orphan_blocks);
 
-	spin_lock(&sbi->cp_lock);
-	if (cpc->reason == CP_UMOUNT)
-		__set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
-	else
-		__clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
-
-	if (cpc->reason == CP_FASTBOOT)
-		__set_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
-	else
-		__clear_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
-
-	if (orphan_num)
-		__set_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
-	else
-		__clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
-
-	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK))
-		__set_ckpt_flags(ckpt, CP_FSCK_FLAG);
-
-	/* set this flag to activate crc|cp_ver for recovery */
-	__set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG);
-
-	spin_unlock(&sbi->cp_lock);
+	/* update ckpt flag for checkpoint */
+	update_ckpt_flags(sbi, cpc);
 
 	/* update SIT/NAT bitmap */
 	get_sit_bitmap(sbi, __bitmap_ptr(sbi, SIT_BITMAP));

commit fc0065adb202518e25fb929cda7d5887a456f774
Author: Tiezhu Yang <kernelpatch@126.com>
Date:   Fri Sep 30 08:24:53 2016 +0800

    f2fs: introduce get_checkpoint_version for cleanup
    
    There exists almost same codes when get the value of pre_version
    and cur_version in function validate_checkpoint, this patch adds
    get_checkpoint_version to clean up redundant codes.
    
    Signed-off-by: Tiezhu Yang <kernelpatch@126.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2a7b9f511c76..7e2632835031 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -663,45 +663,55 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	}
 }
 
-static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
-				block_t cp_addr, unsigned long long *version)
+static int get_checkpoint_version(struct f2fs_sb_info *sbi, block_t cp_addr,
+		struct f2fs_checkpoint **cp_block, struct page **cp_page,
+		unsigned long long *version)
 {
-	struct page *cp_page_1, *cp_page_2 = NULL;
 	unsigned long blk_size = sbi->blocksize;
-	struct f2fs_checkpoint *cp_block;
-	unsigned long long cur_version = 0, pre_version = 0;
-	size_t crc_offset;
+	size_t crc_offset = 0;
 	__u32 crc = 0;
 
-	/* Read the 1st cp block in this CP pack */
-	cp_page_1 = get_meta_page(sbi, cp_addr);
+	*cp_page = get_meta_page(sbi, cp_addr);
+	*cp_block = (struct f2fs_checkpoint *)page_address(*cp_page);
 
-	/* get the version number */
-	cp_block = (struct f2fs_checkpoint *)page_address(cp_page_1);
-	crc_offset = le32_to_cpu(cp_block->checksum_offset);
-	if (crc_offset >= blk_size)
-		goto invalid_cp1;
+	crc_offset = le32_to_cpu((*cp_block)->checksum_offset);
+	if (crc_offset >= blk_size) {
+		f2fs_msg(sbi->sb, KERN_WARNING,
+			"invalid crc_offset: %zu", crc_offset);
+		return -EINVAL;
+	}
 
-	crc = le32_to_cpu(*((__le32 *)((unsigned char *)cp_block + crc_offset)));
-	if (!f2fs_crc_valid(sbi, crc, cp_block, crc_offset))
-		goto invalid_cp1;
+	crc = le32_to_cpu(*((__le32 *)((unsigned char *)*cp_block
+							+ crc_offset)));
+	if (!f2fs_crc_valid(sbi, crc, *cp_block, crc_offset)) {
+		f2fs_msg(sbi->sb, KERN_WARNING, "invalid crc value");
+		return -EINVAL;
+	}
 
-	pre_version = cur_cp_version(cp_block);
+	*version = cur_cp_version(*cp_block);
+	return 0;
+}
 
-	/* Read the 2nd cp block in this CP pack */
-	cp_addr += le32_to_cpu(cp_block->cp_pack_total_block_count) - 1;
-	cp_page_2 = get_meta_page(sbi, cp_addr);
+static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
+				block_t cp_addr, unsigned long long *version)
+{
+	struct page *cp_page_1 = NULL, *cp_page_2 = NULL;
+	struct f2fs_checkpoint *cp_block = NULL;
+	unsigned long long cur_version = 0, pre_version = 0;
+	int err;
 
-	cp_block = (struct f2fs_checkpoint *)page_address(cp_page_2);
-	crc_offset = le32_to_cpu(cp_block->checksum_offset);
-	if (crc_offset >= blk_size)
-		goto invalid_cp2;
+	err = get_checkpoint_version(sbi, cp_addr, &cp_block,
+					&cp_page_1, version);
+	if (err)
+		goto invalid_cp1;
+	pre_version = *version;
 
-	crc = le32_to_cpu(*((__le32 *)((unsigned char *)cp_block + crc_offset)));
-	if (!f2fs_crc_valid(sbi, crc, cp_block, crc_offset))
+	cp_addr += le32_to_cpu(cp_block->cp_pack_total_block_count) - 1;
+	err = get_checkpoint_version(sbi, cp_addr, &cp_block,
+					&cp_page_2, version);
+	if (err)
 		goto invalid_cp2;
-
-	cur_version = cur_cp_version(cp_block);
+	cur_version = *version;
 
 	if (cur_version == pre_version) {
 		*version = cur_version;

commit 7fd748df451d57cc40b66f6cd8091c0707497443
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Sep 27 00:09:53 2016 +0800

    f2fs: remove redundant io plug
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5891093200cf..2a7b9f511c76 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -267,7 +267,6 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 				struct writeback_control *wbc)
 {
 	struct f2fs_sb_info *sbi = F2FS_M_SB(mapping);
-	struct blk_plug plug;
 	long diff, written;
 
 	/* collect a number of dirty meta pages and write together */
@@ -280,9 +279,7 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 	/* if mounting is failed, skip writing node pages */
 	mutex_lock(&sbi->cp_mutex);
 	diff = nr_pages_to_write(sbi, META, wbc);
-	blk_start_plug(&plug);
 	written = sync_meta_pages(sbi, META, wbc->nr_to_write);
-	blk_finish_plug(&plug);
 	mutex_unlock(&sbi->cp_mutex);
 	wbc->nr_to_write = max((long)0, wbc->nr_to_write - written - diff);
 	return 0;

commit 1ecc0c5c50ce8834f7e35b63be7480bf1aaa4155
Author: Chao Yu <yuchao0@huawei.com>
Date:   Fri Sep 23 21:30:09 2016 +0800

    f2fs: support configuring fault injection per superblock
    
    Previously, we only support global fault injection configuration, so that
    when we configure type/rate of fault injection through sysfs, mount
    option, it will influence all f2fs partition which is being used.
    
    It is not make sence, since it will be not convenient if developer want
    to test separated partitions with different fault injection rate/type
    simultaneously, also it's not possible to enable fault injection in one
    partition and disable fault injection in other one.
    
    >From now on, we move global configuration of fault injection in module
    into per-superblock, hence injection testing can be more flexible.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 15c0006b12f1..5891093200cf 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -494,7 +494,7 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 	spin_lock(&im->ino_lock);
 
 #ifdef CONFIG_F2FS_FAULT_INJECTION
-	if (time_to_inject(FAULT_ORPHAN)) {
+	if (time_to_inject(sbi, FAULT_ORPHAN)) {
 		spin_unlock(&im->ino_lock);
 		return -ENOSPC;
 	}

commit d41065e20484c53d8976742367bb78ac248fb0d5
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Sep 21 11:39:42 2016 -0700

    f2fs: handle errors during recover_orphan_inodes
    
    This patch fixes to handle EIO during recover_orphan_inode() given the below
    panic.
    
    F2FS-fs : inject IO error in f2fs_read_end_io+0xe6/0x100 [f2fs]
    ------------[ cut here ]------------
    RIP: 0010:[<ffffffffc0b244e3>]  [<ffffffffc0b244e3>] f2fs_evict_inode+0x433/0x470 [f2fs]
    RSP: 0018:ffff92f8b7fb7c30  EFLAGS: 00010246
    RAX: ffff92fb88a13500 RBX: ffff92f890566ea0 RCX: 00000000fd3c255c
    RDX: 0000000000000001 RSI: ffff92fb88a13d90 RDI: ffff92fb8ee127e8
    RBP: ffff92f8b7fb7c58 R08: 0000000000000001 R09: ffff92fb88a13d58
    R10: 000000005a6a9373 R11: 0000000000000001 R12: 00000000fffffffb
    R13: ffff92fb8ee12000 R14: 00000000000034ca R15: ffff92fb8ee12620
    FS:  00007f1fefd8e880(0000) GS:ffff92fb95600000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007fc211d34cdb CR3: 000000012d43a000 CR4: 00000000001406e0
    Stack:
     ffff92f890566ea0 ffff92f890567078 ffffffffc0b5a0c0 ffff92f890566f28
     ffff92fb888b2000 ffff92f8b7fb7c80 ffffffffbc27ff55 ffff92f890566ea0
     ffff92fb8bf10000 ffffffffc0b5a0c0 ffff92f8b7fb7cb0 ffffffffbc28090d
    Call Trace:
     [<ffffffffbc27ff55>] evict+0xc5/0x1a0
     [<ffffffffbc28090d>] iput+0x1ad/0x2c0
     [<ffffffffc0b3304c>] recover_orphan_inodes+0x10c/0x2e0 [f2fs]
     [<ffffffffc0b2e0f4>] f2fs_fill_super+0x884/0x1150 [f2fs]
     [<ffffffffbc2644ac>] mount_bdev+0x18c/0x1c0
     [<ffffffffc0b2d870>] ? f2fs_commit_super+0x100/0x100 [f2fs]
     [<ffffffffc0b2a755>] f2fs_mount+0x15/0x20 [f2fs]
     [<ffffffffbc264e49>] mount_fs+0x39/0x170
     [<ffffffffbc28555b>] vfs_kern_mount+0x6b/0x160
     [<ffffffffbc2881df>] do_mount+0x1cf/0xd00
     [<ffffffffbc287f2c>] ? copy_mount_options+0xac/0x170
     [<ffffffffbc289003>] SyS_mount+0x83/0xd0
     [<ffffffffbc8ee880>] entry_SYSCALL_64_fastpath+0x23/0xc1
    
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 64e389285f54..15c0006b12f1 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -535,6 +535,17 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	struct inode *inode;
 	struct node_info ni;
+	int err = acquire_orphan_inode(sbi);
+
+	if (err) {
+		set_sbi_flag(sbi, SBI_NEED_FSCK);
+		f2fs_msg(sbi->sb, KERN_WARNING,
+				"%s: orphan failed (ino=%x), run fsck to fix.",
+				__func__, ino);
+		return err;
+	}
+
+	__add_ino_entry(sbi, ino, ORPHAN_INO);
 
 	inode = f2fs_iget_retry(sbi->sb, ino);
 	if (IS_ERR(inode)) {
@@ -555,17 +566,13 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 
 	/* ENOMEM was fully retried in f2fs_evict_inode. */
 	if (ni.blk_addr != NULL_ADDR) {
-		int err = acquire_orphan_inode(sbi);
-
-		if (err) {
-			set_sbi_flag(sbi, SBI_NEED_FSCK);
-			f2fs_msg(sbi->sb, KERN_WARNING,
-				"%s: orphan failed (ino=%x), run fsck to fix.",
-					__func__, ino);
-			return err;
-		}
-		__add_ino_entry(sbi, ino, ORPHAN_INO);
+		set_sbi_flag(sbi, SBI_NEED_FSCK);
+		f2fs_msg(sbi->sb, KERN_WARNING,
+			"%s: orphan failed (ino=%x), run fsck to fix.",
+				__func__, ino);
+		return -EIO;
 	}
+	__remove_ino_entry(sbi, ino, ORPHAN_INO);
 	return 0;
 }
 

commit 5b7a487cf32d3a266fea83d590d3226b5ad817a7
Author: Weichao Guo <guoweichao@huawei.com>
Date:   Tue Sep 20 05:03:27 2016 +0800

    f2fs: add customized migrate_page callback
    
    This patch improves the migration of dirty pages and allows migrating atomic
    written pages that F2FS uses in Page Cache. Instead of the fallback releasing
    page path, it provides better performance for memory compaction, CMA and other
    users of memory page migrating. For dirty pages, there is no need to write back
    first when migrating. For an atomic written page before committing, we can
    migrate the page and update the related 'inmem_pages' list at the same time.
    
    Signed-off-by: Weichao Guo <guoweichao@huawei.com>
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: fix some coding style]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 591db95222d1..64e389285f54 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -388,6 +388,9 @@ const struct address_space_operations f2fs_meta_aops = {
 	.set_page_dirty	= f2fs_set_meta_page_dirty,
 	.invalidatepage = f2fs_invalidate_page,
 	.releasepage	= f2fs_release_page,
+#ifdef CONFIG_MIGRATION
+	.migratepage    = f2fs_migrate_page,
+#endif
 };
 
 static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)

commit aaec2b1d18792a5f27b69ff37f34f43f89f5aa3b
Author: Chao Yu <yuchao0@huawei.com>
Date:   Tue Sep 20 11:04:18 2016 +0800

    f2fs: introduce cp_lock to protect updating of ckpt_flags
    
    This patch introduces spinlock to protect updating process of ckpt_flags
    field in struct f2fs_checkpoint, it avoids incorrectly updating in race
    condition.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    [Jaegeuk Kim: add __is_set_ckpt_flags likewise __set_ckpt_flags]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9c6439b0e8d2..591db95222d1 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -28,7 +28,7 @@ struct kmem_cache *inode_entry_slab;
 
 void f2fs_stop_checkpoint(struct f2fs_sb_info *sbi, bool end_io)
 {
-	set_ckpt_flags(sbi->ckpt, CP_ERROR_FLAG);
+	set_ckpt_flags(sbi, CP_ERROR_FLAG);
 	sbi->sb->s_flags |= MS_RDONLY;
 	if (!end_io)
 		f2fs_flush_merged_bios(sbi);
@@ -571,7 +571,7 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	block_t start_blk, orphan_blocks, i, j;
 	int err;
 
-	if (!is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG))
+	if (!is_set_ckpt_flags(sbi, CP_ORPHAN_PRESENT_FLAG))
 		return 0;
 
 	start_blk = __start_cp_addr(sbi) + 1 + __cp_payload(sbi);
@@ -595,7 +595,7 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 		f2fs_put_page(page, 1);
 	}
 	/* clear Orphan Flag */
-	clear_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG);
+	clear_ckpt_flags(sbi, CP_ORPHAN_PRESENT_FLAG);
 	return 0;
 }
 
@@ -1043,10 +1043,12 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* 2 cp  + n data seg summary + orphan inode blocks */
 	data_sum_blocks = npages_for_summary_flush(sbi, false);
+	spin_lock(&sbi->cp_lock);
 	if (data_sum_blocks < NR_CURSEG_DATA_TYPE)
-		set_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
+		__set_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
 	else
-		clear_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
+		__clear_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
+	spin_unlock(&sbi->cp_lock);
 
 	orphan_blocks = GET_ORPHAN_BLOCKS(orphan_num);
 	ckpt->cp_pack_start_sum = cpu_to_le32(1 + cp_payload_blks +
@@ -1061,26 +1063,29 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 				cp_payload_blks + data_sum_blocks +
 				orphan_blocks);
 
+	spin_lock(&sbi->cp_lock);
 	if (cpc->reason == CP_UMOUNT)
-		set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+		__set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
 	else
-		clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+		__clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
 
 	if (cpc->reason == CP_FASTBOOT)
-		set_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
+		__set_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
 	else
-		clear_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
+		__clear_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
 
 	if (orphan_num)
-		set_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
+		__set_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 	else
-		clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
+		__clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 
 	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK))
-		set_ckpt_flags(ckpt, CP_FSCK_FLAG);
+		__set_ckpt_flags(ckpt, CP_FSCK_FLAG);
 
 	/* set this flag to activate crc|cp_ver for recovery */
-	set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG);
+	__set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG);
+
+	spin_unlock(&sbi->cp_lock);
 
 	/* update SIT/NAT bitmap */
 	get_sit_bitmap(sbi, __bitmap_ptr(sbi, SIT_BITMAP));

commit a468f0ef516fda9c7d91bb550d458e853d76955e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 19 17:55:10 2016 -0700

    f2fs: use crc and cp version to determine roll-forward recovery
    
    Previously, we used cp_version only to detect recoverable dnodes.
    In order to avoid same garbage cp_version, we needed to truncate the next
    dnode during checkpoint, resulting in additional discard or data write.
    If we can distinguish this by using crc in addition to cp_version, we can
    remove this overhead.
    
    There is backward compatibility concern where it changes node_footer layout.
    So, this patch introduces a new checkpoint flag, CP_CRC_RECOVERY_FLAG, to
    detect new layout. New layout will be activated only when this flag is set.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index df56a43f982e..9c6439b0e8d2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -992,7 +992,6 @@ static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
-	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
 	unsigned long orphan_num = sbi->im[ORPHAN_INO].ino_num;
 	nid_t last_nid = nm_i->next_scan_nid;
@@ -1001,19 +1000,10 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	__u32 crc32 = 0;
 	int i;
 	int cp_payload_blks = __cp_payload(sbi);
-	block_t discard_blk = NEXT_FREE_BLKADDR(sbi, curseg);
-	bool invalidate = false;
 	struct super_block *sb = sbi->sb;
 	struct curseg_info *seg_i = CURSEG_I(sbi, CURSEG_HOT_NODE);
 	u64 kbytes_written;
 
-	/*
-	 * This avoids to conduct wrong roll-forward operations and uses
-	 * metapages, so should be called prior to sync_meta_pages below.
-	 */
-	if (!test_opt(sbi, LFS) && discard_next_dnode(sbi, discard_blk))
-		invalidate = true;
-
 	/* Flush all the NAT/SIT pages */
 	while (get_pages(sbi, F2FS_DIRTY_META)) {
 		sync_meta_pages(sbi, META, LONG_MAX);
@@ -1089,6 +1079,9 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK))
 		set_ckpt_flags(ckpt, CP_FSCK_FLAG);
 
+	/* set this flag to activate crc|cp_ver for recovery */
+	set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG);
+
 	/* update SIT/NAT bitmap */
 	get_sit_bitmap(sbi, __bitmap_ptr(sbi, SIT_BITMAP));
 	get_nat_bitmap(sbi, __bitmap_ptr(sbi, NAT_BITMAP));
@@ -1154,14 +1147,6 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* wait for previous submitted meta pages writeback */
 	wait_on_all_pages_writeback(sbi);
 
-	/*
-	 * invalidate meta page which is used temporarily for zeroing out
-	 * block at the end of warm node chain.
-	 */
-	if (invalidate)
-		invalidate_mapping_pages(META_MAPPING(sbi), discard_blk,
-								discard_blk);
-
 	release_ino_entry(sbi, false);
 
 	if (unlikely(f2fs_cp_error(sbi)))

commit 5905f9afa27234f74423f7276d0833fed6a9a415
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 12 15:08:37 2016 -0700

    f2fs: handle error in recover_orphan_inode
    
    This patch enhances the error path in recover_orphan_inode.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b80dd379b3be..df56a43f982e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -531,8 +531,9 @@ void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	struct inode *inode;
+	struct node_info ni;
 
-	inode = f2fs_iget(sbi->sb, ino);
+	inode = f2fs_iget_retry(sbi->sb, ino);
 	if (IS_ERR(inode)) {
 		/*
 		 * there should be a bug that we can't find the entry
@@ -546,6 +547,22 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 
 	/* truncate all the data during iput */
 	iput(inode);
+
+	get_node_info(sbi, ino, &ni);
+
+	/* ENOMEM was fully retried in f2fs_evict_inode. */
+	if (ni.blk_addr != NULL_ADDR) {
+		int err = acquire_orphan_inode(sbi);
+
+		if (err) {
+			set_sbi_flag(sbi, SBI_NEED_FSCK);
+			f2fs_msg(sbi->sb, KERN_WARNING,
+				"%s: orphan failed (ino=%x), run fsck to fix.",
+					__func__, ino);
+			return err;
+		}
+		__add_ino_entry(sbi, ino, ORPHAN_INO);
+	}
 	return 0;
 }
 

commit c2a080aefa94c4b3dad35fbd9fa6cd0c8039b128
Author: Chao Yu <yuchao0@huawei.com>
Date:   Wed Aug 31 10:43:19 2016 +0800

    f2fs: fix to set superblock dirty correctly
    
    tests/generic/251 of fstest suit complains us with below message:
    
    ------------[ cut here ]------------
    invalid opcode: 0000 [#1] PREEMPT SMP
    CPU: 2 PID: 7698 Comm: fstrim Tainted: G           O    4.7.0+ #21
    task: e9f4e000 task.stack: e7262000
    EIP: 0060:[<f89fcefe>] EFLAGS: 00010202 CPU: 2
    EIP is at write_checkpoint+0xfde/0x1020 [f2fs]
    EAX: f33eb300 EBX: eecac310 ECX: 00000001 EDX: ffff0001
    ESI: eecac000 EDI: eecac5f0 EBP: e7263dec ESP: e7263d18
     DS: 007b ES: 007b FS: 00d8 GS: 0033 SS: 0068
    CR0: 80050033 CR2: b76ab01c CR3: 2eb89de0 CR4: 000406f0
    Stack:
     00000001 a220fb7b e9f4e000 00000002 419ff2d3 b3a05151 00000002 e9f4e5d8
     e9f4e000 419ff2d3 b3a05151 eecac310 c10b8154 b3a05151 419ff2d3 c10b78bd
     e9f4e000 e9f4e000 e9f4e5d8 00000001 e9f4e000 ec409000 eecac2cc eecac288
    Call Trace:
     [<c10b8154>] ? __lock_acquire+0x3c4/0x760
     [<c10b78bd>] ? mark_held_locks+0x5d/0x80
     [<f8a10632>] f2fs_trim_fs+0x1c2/0x2e0 [f2fs]
     [<f89e9f56>] f2fs_ioctl+0x6b6/0x10b0 [f2fs]
     [<c13d51df>] ? __this_cpu_preempt_check+0xf/0x20
     [<c10b4281>] ? trace_hardirqs_off_caller+0x91/0x120
     [<f89e98a0>] ? __exchange_data_block+0xd30/0xd30 [f2fs]
     [<c120b2e1>] do_vfs_ioctl+0x81/0x7f0
     [<c11d57c5>] ? kmem_cache_free+0x245/0x2e0
     [<c1217840>] ? get_unused_fd_flags+0x40/0x40
     [<c1206eec>] ? putname+0x4c/0x50
     [<c11f631e>] ? do_sys_open+0x16e/0x1d0
     [<c1001990>] ? do_fast_syscall_32+0x30/0x1c0
     [<c13d51df>] ? __this_cpu_preempt_check+0xf/0x20
     [<c120baa8>] SyS_ioctl+0x58/0x80
     [<c1001a01>] do_fast_syscall_32+0xa1/0x1c0
     [<c178cc54>] sysenter_past_esp+0x45/0x74
    EIP: [<f89fcefe>] write_checkpoint+0xfde/0x1020 [f2fs] SS:ESP 0068:e7263d18
    ---[ end trace 4de95d7e6b3aa7c6 ]---
    
    The reason is: with below call stack, we will encounter BUG_ON during
    doing fstrim.
    
    Thread A                                Thread B
    - write_checkpoint
     - do_checkpoint
                                            - f2fs_write_inode
                                             - update_inode_page
                                              - update_inode
                                               - set_page_dirty
                                                - f2fs_set_node_page_dirty
                                                 - inc_page_count
                                                  - percpu_counter_inc
                                                  - set_sbi_flag(SBI_IS_DIRTY)
      - clear_sbi_flag(SBI_IS_DIRTY)
    
    Thread C                                Thread D
    - f2fs_write_node_page
     - set_node_addr
      - __set_nat_cache_dirty
       - nm_i->dirty_nat_cnt++
                                            - do_vfs_ioctl
                                             - f2fs_ioctl
                                              - f2fs_trim_fs
                                               - write_checkpoint
                                                - f2fs_bug_on(nm_i->dirty_nat_cnt)
    
    Fix it by setting superblock dirty correctly in do_checkpoint and
    f2fs_write_node_page.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 727e97edf758..b80dd379b3be 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1154,6 +1154,16 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 	clear_sbi_flag(sbi, SBI_NEED_CP);
 
+	/*
+	 * redirty superblock if metadata like node page or inode cache is
+	 * updated during writing checkpoint.
+	 */
+	if (get_pages(sbi, F2FS_DIRTY_NODES) ||
+			get_pages(sbi, F2FS_DIRTY_IMETA))
+		set_sbi_flag(sbi, SBI_IS_DIRTY);
+
+	f2fs_bug_on(sbi, get_pages(sbi, F2FS_DIRTY_DENTS));
+
 	return 0;
 }
 

commit bbf156f7afa7f3cc07177f1119878f6f60855fd1
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Aug 29 18:23:45 2016 -0700

    f2fs: fix lost xattrs of directories
    
    This patch enhances the xattr consistency of dirs from suddern power-cuts.
    
    Possible scenario would be:
    1. dir->setxattr used by per-file encryption
    2. file->setxattr goes into inline_xattr
    3. file->fsync
    
    In that case, we should do checkpoint for #1.
    Otherwise we'd lose dir's key information for the file given #2.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 64a685d5c11b..727e97edf758 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1152,6 +1152,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	clear_prefree_segments(sbi, cpc);
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
+	clear_sbi_flag(sbi, SBI_NEED_CP);
 
 	return 0;
 }

commit 275b66b09e85cf0520dc610dd89706952751a473
Author: Chao Yu <yuchao0@huawei.com>
Date:   Mon Aug 29 23:58:34 2016 +0800

    f2fs: support async discard
    
    Like most filesystems, f2fs will issue discard command synchronously, so
    when user trigger fstrim through ioctl, multiple discard commands will be
    issued serially with sync mode, which makes poor performance.
    
    In this patch we try to support async discard, so that all discard
    commands can be issued and be waited for endio in batch to improve
    performance.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index cd0443d25063..64a685d5c11b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1197,6 +1197,7 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		f2fs_bug_on(sbi, prefree_segments(sbi));
 		flush_sit_entries(sbi, cpc);
 		clear_prefree_segments(sbi, cpc);
+		f2fs_wait_all_discard_bio(sbi);
 		unblock_operations(sbi);
 		goto out;
 	}
@@ -1216,6 +1217,8 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* unlock all the fs_lock[] in do_checkpoint() */
 	err = do_checkpoint(sbi, cpc);
 
+	f2fs_wait_all_discard_bio(sbi);
+
 	unblock_operations(sbi);
 	stat_inc_cp_count(sbi->stat_info);
 

commit 58cce381fa4e8cfbe7ce005a6a858267a3b481f2
Author: Yunlei He <heyunlei@huawei.com>
Date:   Thu Aug 18 21:01:19 2016 +0800

    f2fs: skip new checkpoint when doing fstrim without fs change
    
    This patch enables to do fstrim without checkpoint, if there is no fs
    change.
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f94d01e7d001..cd0443d25063 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1190,6 +1190,17 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	f2fs_flush_merged_bios(sbi);
 
+	/* this is the case of multiple fstrims without any changes */
+	if (cpc->reason == CP_DISCARD && !is_sbi_flag_set(sbi, SBI_IS_DIRTY)) {
+		f2fs_bug_on(sbi, NM_I(sbi)->dirty_nat_cnt);
+		f2fs_bug_on(sbi, SIT_I(sbi)->dirty_sentries);
+		f2fs_bug_on(sbi, prefree_segments(sbi));
+		flush_sit_entries(sbi, cpc);
+		clear_prefree_segments(sbi, cpc);
+		unblock_operations(sbi);
+		goto out;
+	}
+
 	/*
 	 * update checkpoint pack index
 	 * Increase the version number so that

commit 4fc29c1aa375353ffe7c8fa171bf941b71ce29ef
Merge: 0e6acf0204da 5302fb000def
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 27 10:36:31 2016 -0700

    Merge tag 'for-f2fs-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/jaegeuk/f2fs
    
    Pull f2fs updates from Jaegeuk Kim:
     "The major change in this version is mitigating cpu overheads on write
      paths by replacing redundant inode page updates with mark_inode_dirty
      calls.  And we tried to reduce lock contentions as well to improve
      filesystem scalability.  Other feature is setting F2FS automatically
      when detecting host-managed SMR.
    
      Enhancements:
       - ioctl to move a range of data between files
       - inject orphan inode errors
       - avoid flush commands congestion
       - support lazytime
    
      Bug fixes:
       - return proper results for some dentry operations
       - fix deadlock in add_link failure
       - disable extent_cache for fcollapse/finsert"
    
    * tag 'for-f2fs-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/jaegeuk/f2fs: (68 commits)
      f2fs: clean up coding style and redundancy
      f2fs: get victim segment again after new cp
      f2fs: handle error case with f2fs_bug_on
      f2fs: avoid data race when deciding checkpoin in f2fs_sync_file
      f2fs: support an ioctl to move a range of data blocks
      f2fs: fix to report error number of f2fs_find_entry
      f2fs: avoid memory allocation failure due to a long length
      f2fs: reset default idle interval value
      f2fs: use blk_plug in all the possible paths
      f2fs: fix to avoid data update racing between GC and DIO
      f2fs: add maximum prefree segments
      f2fs: disable extent_cache for fcollapse/finsert inodes
      f2fs: refactor __exchange_data_block for speed up
      f2fs: fix ERR_PTR returned by bio
      f2fs: avoid mark_inode_dirty
      f2fs: move i_size_write in f2fs_write_end
      f2fs: fix to avoid redundant discard during fstrim
      f2fs: avoid mismatching block range for discard
      f2fs: fix incorrect f_bfree calculation in ->statfs
      f2fs: use percpu_rw_semaphore
      ...

commit 70246286e94c335b5bea0cbc68a17a96dd620281
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jul 19 11:28:41 2016 +0200

    block: get rid of bio_rw and READA
    
    These two are confusing leftover of the old world order, combining
    values of the REQ_OP_ and REQ_ namespaces.  For callers that don't
    special case we mostly just replace bi_rw with bio_data_dir or
    op_is_write, except for the few cases where a switch over the REQ_OP_
    values makes more sense.  Any check for READA is replaced with an
    explicit check for REQ_RAHEAD.  Also remove the READA alias for
    REQ_RAHEAD.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Mike Christie <mchristi@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b6d600e91f39..124b4a3017b5 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -159,7 +159,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		.sbi = sbi,
 		.type = META,
 		.op = REQ_OP_READ,
-		.op_flags = sync ? (READ_SYNC | REQ_META | REQ_PRIO) : READA,
+		.op_flags = sync ? (READ_SYNC | REQ_META | REQ_PRIO) : REQ_RAHEAD,
 		.encrypted_page = NULL,
 	};
 	struct blk_plug plug;

commit 9dfa1baff76d08843aaf5e3c78f6da6950957702
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Jul 13 19:33:19 2016 -0700

    f2fs: use blk_plug in all the possible paths
    
    This patch reverts 19a5f5e2ef37 (f2fs: drop any block plugging),
    and adds blk_plug in write paths additionally.
    
    The main reason is that blk_start_plug can be used to wake up from low-power
    mode before submitting further bios.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 8ea895389ae4..be1c54b62388 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -265,6 +265,7 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 				struct writeback_control *wbc)
 {
 	struct f2fs_sb_info *sbi = F2FS_M_SB(mapping);
+	struct blk_plug plug;
 	long diff, written;
 
 	/* collect a number of dirty meta pages and write together */
@@ -277,7 +278,9 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 	/* if mounting is failed, skip writing node pages */
 	mutex_lock(&sbi->cp_mutex);
 	diff = nr_pages_to_write(sbi, META, wbc);
+	blk_start_plug(&plug);
 	written = sync_meta_pages(sbi, META, wbc->nr_to_write);
+	blk_finish_plug(&plug);
 	mutex_unlock(&sbi->cp_mutex);
 	wbc->nr_to_write = max((long)0, wbc->nr_to_write - written - diff);
 	return 0;
@@ -899,8 +902,11 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		.nr_to_write = LONG_MAX,
 		.for_reclaim = 0,
 	};
+	struct blk_plug plug;
 	int err = 0;
 
+	blk_start_plug(&plug);
+
 retry_flush_dents:
 	f2fs_lock_all(sbi);
 	/* write all the dirty dentry pages */
@@ -937,6 +943,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		goto retry_flush_nodes;
 	}
 out:
+	blk_finish_plug(&plug);
 	return err;
 }
 

commit 237c0790e54020d522b8fd23097e8dcafb4e331d
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jun 30 18:49:15 2016 -0700

    f2fs: call SetPageUptodate if needed
    
    SetPageUptodate() issues memory barrier, resulting in performance degrdation.
    Let's avoid that.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2755ef730a41..8ea895389ae4 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -48,7 +48,8 @@ struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		goto repeat;
 	}
 	f2fs_wait_on_page_writeback(page, META, true);
-	SetPageUptodate(page);
+	if (!PageUptodate(page))
+		SetPageUptodate(page);
 	return page;
 }
 
@@ -364,7 +365,8 @@ static int f2fs_set_meta_page_dirty(struct page *page)
 {
 	trace_f2fs_set_page_dirty(page, META);
 
-	SetPageUptodate(page);
+	if (!PageUptodate(page))
+		SetPageUptodate(page);
 	if (!PageDirty(page)) {
 		f2fs_set_page_dirty_nobuffers(page);
 		inc_page_count(F2FS_P_SB(page), F2FS_DIRTY_META);

commit fe76b796fc5194cc3d57265002e3a748566d073f
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jun 30 18:40:10 2016 -0700

    f2fs: introduce f2fs_set_page_dirty_nobuffer
    
    This patch adds f2fs_set_page_dirty_nobuffer() copied from __set_page_dirty_buffer.
    When appending 4KB blocks in f2fs on pmem with multiple cores, this improves the
    overall performance.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2b43d4013e92..2755ef730a41 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -366,7 +366,7 @@ static int f2fs_set_meta_page_dirty(struct page *page)
 
 	SetPageUptodate(page);
 	if (!PageDirty(page)) {
-		__set_page_dirty_nobuffers(page);
+		f2fs_set_page_dirty_nobuffers(page);
 		inc_page_count(F2FS_P_SB(page), F2FS_DIRTY_META);
 		SetPagePrivate(page);
 		f2fs_trace_pid(page);

commit ad4edb83143fdeef9e6fdd9daaa735b59476565b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jun 16 16:41:49 2016 -0700

    f2fs: produce more nids and reduce readahead nats
    
    The readahead nat pages are more likely to be reclaimed quickly, so it'd better
    to gather more free nids in advance.
    
    And, let's keep some free nids as much as possible.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 8534b98c0712..2b43d4013e92 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -941,6 +941,8 @@ static int block_operations(struct f2fs_sb_info *sbi)
 static void unblock_operations(struct f2fs_sb_info *sbi)
 {
 	up_write(&sbi->node_write);
+
+	build_free_nids(sbi);
 	f2fs_unlock_all(sbi);
 }
 

commit 67c3758d2267de589ee9a8856fe637cce85993d9
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Jun 13 18:27:02 2016 -0700

    f2fs: call update_inode_page for orphan inodes
    
    Let's store orphan inode pages right away.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 837e6bcad5ce..8534b98c0712 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -508,10 +508,11 @@ void release_orphan_inode(struct f2fs_sb_info *sbi)
 	spin_unlock(&im->ino_lock);
 }
 
-void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
+void add_orphan_inode(struct inode *inode)
 {
 	/* add new orphan ino entry into list */
-	__add_ino_entry(sbi, ino, ORPHAN_INO);
+	__add_ino_entry(F2FS_I_SB(inode), inode->i_ino, ORPHAN_INO);
+	update_inode_page(inode);
 }
 
 void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
@@ -535,7 +536,6 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	}
 
 	clear_nlink(inode);
-	mark_inode_dirty_sync(inode);
 
 	/* truncate all the data during iput */
 	iput(inode);

commit 36abef4e796d382e81a0c2d21ea5327481dd7154
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jun 3 19:29:38 2016 -0700

    f2fs: introduce mode=lfs mount option
    
    This mount option is to enable original log-structured filesystem forcefully.
    So, there should be no random writes for main area.
    
    Especially, this supports host-managed SMR device.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4179c7b971fc..837e6bcad5ce 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -981,7 +981,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	 * This avoids to conduct wrong roll-forward operations and uses
 	 * metapages, so should be called prior to sync_meta_pages below.
 	 */
-	if (discard_next_dnode(sbi, discard_blk))
+	if (!test_opt(sbi, LFS) && discard_next_dnode(sbi, discard_blk))
 		invalidate = true;
 
 	/* Flush all the NAT/SIT pages */

commit 19a5f5e2ef37f032efd840ada257bce2e91c8066
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Sat Jun 4 14:25:24 2016 -0700

    f2fs: drop any block plugging
    
    In f2fs, we don't need to keep block plugging for NODE and DATA writes, since
    we already merged bios as much as possible.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5ddd15cd6c6c..4179c7b971fc 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -897,11 +897,8 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		.nr_to_write = LONG_MAX,
 		.for_reclaim = 0,
 	};
-	struct blk_plug plug;
 	int err = 0;
 
-	blk_start_plug(&plug);
-
 retry_flush_dents:
 	f2fs_lock_all(sbi);
 	/* write all the dirty dentry pages */
@@ -938,7 +935,6 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		goto retry_flush_nodes;
 	}
 out:
-	blk_finish_plug(&plug);
 	return err;
 }
 

commit 04d328defd06257bf386d58f359013e0ef329226
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:55 2016 -0500

    f2fs: use bio op accessors
    
    Separate the op from the rq_flag_bits and have f2fs
    set/get the bio using bio_set_op_attrs/bio_op.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 389160049993..b6d600e91f39 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -63,14 +63,15 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 	struct f2fs_io_info fio = {
 		.sbi = sbi,
 		.type = META,
-		.rw = READ_SYNC | REQ_META | REQ_PRIO,
+		.op = REQ_OP_READ,
+		.op_flags = READ_SYNC | REQ_META | REQ_PRIO,
 		.old_blkaddr = index,
 		.new_blkaddr = index,
 		.encrypted_page = NULL,
 	};
 
 	if (unlikely(!is_meta))
-		fio.rw &= ~REQ_META;
+		fio.op_flags &= ~REQ_META;
 repeat:
 	page = f2fs_grab_cache_page(mapping, index, false);
 	if (!page) {
@@ -157,13 +158,14 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 	struct f2fs_io_info fio = {
 		.sbi = sbi,
 		.type = META,
-		.rw = sync ? (READ_SYNC | REQ_META | REQ_PRIO) : READA,
+		.op = REQ_OP_READ,
+		.op_flags = sync ? (READ_SYNC | REQ_META | REQ_PRIO) : READA,
 		.encrypted_page = NULL,
 	};
 	struct blk_plug plug;
 
 	if (unlikely(type == META_POR))
-		fio.rw &= ~REQ_META;
+		fio.op_flags &= ~REQ_META;
 
 	blk_start_plug(&plug);
 	for (; nrpages-- > 0; blkno++) {

commit 0f18b462b2e5aff64b8638e8a47284b907351ef3
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri May 20 11:10:10 2016 -0700

    f2fs: flush inode metadata when checkpoint is doing
    
    This patch registers all the inodes which have dirty metadata to sync when
    checkpoint is doing.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 02e0522beccf..5ddd15cd6c6c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -859,6 +859,34 @@ int sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 	goto retry;
 }
 
+int f2fs_sync_inode_meta(struct f2fs_sb_info *sbi)
+{
+	struct list_head *head = &sbi->inode_list[DIRTY_META];
+	struct inode *inode;
+	struct f2fs_inode_info *fi;
+	s64 total = get_pages(sbi, F2FS_DIRTY_IMETA);
+
+	while (total--) {
+		if (unlikely(f2fs_cp_error(sbi)))
+			return -EIO;
+
+		spin_lock(&sbi->inode_lock[DIRTY_META]);
+		if (list_empty(head)) {
+			spin_unlock(&sbi->inode_lock[DIRTY_META]);
+			return 0;
+		}
+		fi = list_entry(head->next, struct f2fs_inode_info,
+							gdirty_list);
+		inode = igrab(&fi->vfs_inode);
+		spin_unlock(&sbi->inode_lock[DIRTY_META]);
+		if (inode) {
+			update_inode_page(inode);
+			iput(inode);
+		}
+	};
+	return 0;
+}
+
 /*
  * Freeze all the FS-operations for checkpoint.
  */
@@ -885,6 +913,14 @@ static int block_operations(struct f2fs_sb_info *sbi)
 		goto retry_flush_dents;
 	}
 
+	if (get_pages(sbi, F2FS_DIRTY_IMETA)) {
+		f2fs_unlock_all(sbi);
+		err = f2fs_sync_inode_meta(sbi);
+		if (err)
+			goto out;
+		goto retry_flush_dents;
+	}
+
 	/*
 	 * POR: we should ensure that there are no dirty node pages
 	 * until finishing nat/sit flush.

commit a1961246c392dbf7dabdc81b4e074c32053fbf61
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri May 20 09:43:20 2016 -0700

    f2fs: introduce f2fs_i_links_write with mark_inode_dirty_sync
    
    This patch introduces f2fs_i_links_write() to call mark_inode_dirty_sync() when
    changing inode->i_links.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index aa8cb4559ff8..02e0522beccf 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -535,6 +535,7 @@ static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	}
 
 	clear_nlink(inode);
+	mark_inode_dirty_sync(inode);
 
 	/* truncate all the data during iput */
 	iput(inode);

commit 91942321e4c9f8460f260cdfcf0a7a48a73a84a4
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri May 20 10:13:22 2016 -0700

    f2fs: use inode pointer for {set, clear}_inode_flag
    
    This patch refactors to use inode pointer for set_inode_flag and
    clear_inode_flag.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5cf7238f4f89..aa8cb4559ff8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -759,28 +759,25 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 static void __add_dirty_inode(struct inode *inode, enum inode_type type)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
-	struct f2fs_inode_info *fi = F2FS_I(inode);
 	int flag = (type == DIR_INODE) ? FI_DIRTY_DIR : FI_DIRTY_FILE;
 
-	if (is_inode_flag_set(fi, flag))
+	if (is_inode_flag_set(inode, flag))
 		return;
 
-	set_inode_flag(fi, flag);
-	list_add_tail(&fi->dirty_list, &sbi->inode_list[type]);
+	set_inode_flag(inode, flag);
+	list_add_tail(&F2FS_I(inode)->dirty_list, &sbi->inode_list[type]);
 	stat_inc_dirty_inode(sbi, type);
 }
 
 static void __remove_dirty_inode(struct inode *inode, enum inode_type type)
 {
-	struct f2fs_inode_info *fi = F2FS_I(inode);
 	int flag = (type == DIR_INODE) ? FI_DIRTY_DIR : FI_DIRTY_FILE;
 
-	if (get_dirty_pages(inode) ||
-			!is_inode_flag_set(F2FS_I(inode), flag))
+	if (get_dirty_pages(inode) || !is_inode_flag_set(inode, flag))
 		return;
 
-	list_del_init(&fi->dirty_list);
-	clear_inode_flag(fi, flag);
+	list_del_init(&F2FS_I(inode)->dirty_list);
+	clear_inode_flag(inode, flag);
 	stat_dec_dirty_inode(F2FS_I_SB(inode), type);
 }
 

commit 1c4bf763039ccdc6dab9e1c3cf84a1cb14c6ff13
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Jun 1 20:55:51 2016 -0700

    Revert "f2fs: no need inc dirty pages under inode lock"
    
    This reverts commit b951a4ec165af4973b2bd9c80fb5845fbd840435.
    
     Conflicts:
            fs/f2fs/checkpoint.c

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 389160049993..5cf7238f4f89 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -793,13 +793,12 @@ void update_dirty_page(struct inode *inode, struct page *page)
 			!S_ISLNK(inode->i_mode))
 		return;
 
-	if (type != FILE_INODE || test_opt(sbi, DATA_FLUSH)) {
-		spin_lock(&sbi->inode_lock[type]);
+	spin_lock(&sbi->inode_lock[type]);
+	if (type != FILE_INODE || test_opt(sbi, DATA_FLUSH))
 		__add_dirty_inode(inode, type);
-		spin_unlock(&sbi->inode_lock[type]);
-	}
-
 	inode_inc_dirty_pages(inode);
+	spin_unlock(&sbi->inode_lock[type]);
+
 	SetPagePrivate(page);
 	f2fs_trace_pid(page);
 }

commit 38f91ca8c0ea69f707c26f592dcc70f937088bcc
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed May 18 14:07:56 2016 -0700

    f2fs: flush pending bios right away when error occurs
    
    Given errors, this patch flushes pending bios as soon as possible.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index cf79598aec0e..389160049993 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -26,6 +26,14 @@
 static struct kmem_cache *ino_entry_slab;
 struct kmem_cache *inode_entry_slab;
 
+void f2fs_stop_checkpoint(struct f2fs_sb_info *sbi, bool end_io)
+{
+	set_ckpt_flags(sbi->ckpt, CP_ERROR_FLAG);
+	sbi->sb->s_flags |= MS_RDONLY;
+	if (!end_io)
+		f2fs_flush_merged_bios(sbi);
+}
+
 /*
  * We guarantee no failure on the returned page.
  */
@@ -91,7 +99,7 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 	 * meta page.
 	 */
 	if (unlikely(!PageUptodate(page)))
-		f2fs_stop_checkpoint(sbi);
+		f2fs_stop_checkpoint(sbi, false);
 out:
 	return page;
 }

commit 41382ec43255b502321c3c27f1347efeb3279290
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon May 16 11:06:50 2016 -0700

    f2fs: use percpu_counter for alloc_valid_block_count
    
    This patch uses percpu_count for sbi->alloc_valid_block_count.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 447e2a986560..cf79598aec0e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1079,7 +1079,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* update user_block_counts */
 	sbi->last_valid_block_count = sbi->total_valid_block_count;
-	sbi->alloc_valid_block_count = 0;
+	percpu_counter_set(&sbi->alloc_valid_block_count, 0);
 
 	/* Here, we only have one bio having CP pack */
 	sync_meta_pages(sbi, META_FLUSH, LONG_MAX);

commit f573018491fd823e909d587cfe16758f3dd9e6d6
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue May 17 16:23:36 2016 -0700

    f2fs: use bio count instead of F2FS_WRITEBACK page count
    
    This can reduce page counting overhead.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d04113b9ac18..447e2a986560 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -914,7 +914,7 @@ static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 	for (;;) {
 		prepare_to_wait(&sbi->cp_wait, &wait, TASK_UNINTERRUPTIBLE);
 
-		if (!get_pages(sbi, F2FS_WRITEBACK))
+		if (!atomic_read(&sbi->nr_wb_bios))
 			break;
 
 		io_schedule_timeout(5*HZ);

commit 10aa97c379cdd1e9f537a00ef2d787989759269d
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon May 16 10:33:40 2016 -0700

    f2fs: manipulate dirty file inodes when DATA_FLUSH is set
    
    It needs to maintain dirty file inodes only if DATA_FLUSH is set.
    Otherwise, let's avoid its overhead.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3da6499a9e82..d04113b9ac18 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -785,9 +785,11 @@ void update_dirty_page(struct inode *inode, struct page *page)
 			!S_ISLNK(inode->i_mode))
 		return;
 
-	spin_lock(&sbi->inode_lock[type]);
-	__add_dirty_inode(inode, type);
-	spin_unlock(&sbi->inode_lock[type]);
+	if (type != FILE_INODE || test_opt(sbi, DATA_FLUSH)) {
+		spin_lock(&sbi->inode_lock[type]);
+		__add_dirty_inode(inode, type);
+		spin_unlock(&sbi->inode_lock[type]);
+	}
 
 	inode_inc_dirty_pages(inode);
 	SetPagePrivate(page);
@@ -803,6 +805,9 @@ void remove_dirty_inode(struct inode *inode)
 			!S_ISLNK(inode->i_mode))
 		return;
 
+	if (type == FILE_INODE && !test_opt(sbi, DATA_FLUSH))
+		return;
+
 	spin_lock(&sbi->inode_lock[type]);
 	__remove_dirty_inode(inode, type);
 	spin_unlock(&sbi->inode_lock[type]);

commit b951a4ec165af4973b2bd9c80fb5845fbd840435
Author: Yunlei He <heyunlei@huawei.com>
Date:   Fri May 13 14:57:43 2016 +0800

    f2fs: no need inc dirty pages under inode lock
    
    No need inc dirty pages under inode lock
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6402e9372f6c..3da6499a9e82 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -787,9 +787,9 @@ void update_dirty_page(struct inode *inode, struct page *page)
 
 	spin_lock(&sbi->inode_lock[type]);
 	__add_dirty_inode(inode, type);
-	inode_inc_dirty_pages(inode);
 	spin_unlock(&sbi->inode_lock[type]);
 
+	inode_inc_dirty_pages(inode);
 	SetPagePrivate(page);
 	f2fs_trace_pid(page);
 }

commit f61cce5b81f91ba336184008b24baec84afbb3dd
Author: Chao Yu <yuchao0@huawei.com>
Date:   Sat May 7 16:15:05 2016 +0800

    f2fs: fix inode cache leak
    
    When testing f2fs with inline_dentry option, generic/342 reports:
    VFS: Busy inodes after unmount of dm-0. Self-destruct in 5 seconds.  Have a nice day...
    
    After rmmod f2fs module, kenrel shows following dmesg:
     =============================================================================
     BUG f2fs_inode_cache (Tainted: G           O   ): Objects remaining in f2fs_inode_cache on __kmem_cache_shutdown()
     -----------------------------------------------------------------------------
    
     Disabling lock debugging due to kernel taint
     INFO: Slab 0xf51ca0e0 objects=22 used=1 fp=0xd1e6fc60 flags=0x40004080
     CPU: 3 PID: 7455 Comm: rmmod Tainted: G    B      O    4.6.0-rc4+ #16
     Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
      00000086 00000086 d062fe18 c13a83a0 f51ca0e0 d062fe38 d062fea4 c11c7276
      c1981040 f51ca0e0 00000016 00000001 d1e6fc60 40004080 656a624f 20737463
      616d6572 6e696e69 6e692067 66326620 6e695f73 5f65646f 68636163 6e6f2065
     Call Trace:
      [<c13a83a0>] dump_stack+0x5f/0x8f
      [<c11c7276>] slab_err+0x76/0x80
      [<c11cbfc0>] ? __kmem_cache_shutdown+0x100/0x2f0
      [<c11cbfc0>] ? __kmem_cache_shutdown+0x100/0x2f0
      [<c11cbfe5>] __kmem_cache_shutdown+0x125/0x2f0
      [<c1198a38>] kmem_cache_destroy+0x158/0x1f0
      [<c176b43d>] ? mutex_unlock+0xd/0x10
      [<f8f15aa3>] exit_f2fs_fs+0x4b/0x5a8 [f2fs]
      [<c10f596c>] SyS_delete_module+0x16c/0x1d0
      [<c1001b10>] ? do_fast_syscall_32+0x30/0x1c0
      [<c13c59bf>] ? __this_cpu_preempt_check+0xf/0x20
      [<c10afa7d>] ? trace_hardirqs_on_caller+0xdd/0x210
      [<c10ad50b>] ? trace_hardirqs_off+0xb/0x10
      [<c1001b81>] do_fast_syscall_32+0xa1/0x1c0
      [<c176d888>] sysenter_past_esp+0x45/0x74
     INFO: Object 0xd1e6d9e0 @offset=6624
     kmem_cache_destroy f2fs_inode_cache: Slab cache still has objects
     CPU: 3 PID: 7455 Comm: rmmod Tainted: G    B      O    4.6.0-rc4+ #16
     Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
      00000286 00000286 d062fef4 c13a83a0 f174b000 d062ff14 d062ff28 c1198ac7
      c197fe18 f3c5b980 d062ff20 000d04f2 d062ff0c d062ff0c d062ff14 d062ff14
      f8f20dc0 fffffff5 d062e000 d062ff30 f8f15aa3 d062ff7c c10f596c 73663266
     Call Trace:
      [<c13a83a0>] dump_stack+0x5f/0x8f
      [<c1198ac7>] kmem_cache_destroy+0x1e7/0x1f0
      [<f8f15aa3>] exit_f2fs_fs+0x4b/0x5a8 [f2fs]
      [<c10f596c>] SyS_delete_module+0x16c/0x1d0
      [<c1001b10>] ? do_fast_syscall_32+0x30/0x1c0
      [<c13c59bf>] ? __this_cpu_preempt_check+0xf/0x20
      [<c10afa7d>] ? trace_hardirqs_on_caller+0xdd/0x210
      [<c10ad50b>] ? trace_hardirqs_off+0xb/0x10
      [<c1001b81>] do_fast_syscall_32+0xa1/0x1c0
      [<c176d888>] sysenter_past_esp+0x45/0x74
    
    The reason is: in recovery flow, we use delayed iput mechanism for directory
    which has recovered dentry block. It means the reference of inode will be
    held until last dirty dentry page being writebacked.
    
    But when we mount f2fs with inline_dentry option, during recovery, dirent
    may only be recovered into dir inode page rather than dentry page, so there
    are no chance for us to release inode reference in ->writepage when
    writebacking last dentry page.
    
    We can call paired iget/iput explicityly for inline_dentry case, but for
    non-inline_dentry case, iput will call writeback_single_inode to write all
    data pages synchronously, but during recovery, ->writepages of f2fs skips
    writing all pages, result in losing dirent.
    
    This patch fixes this issue by obsoleting old mechanism, and introduce a
    new dir_list to hold all directory inodes which has recovered datas until
    finishing recovery.
    
    Signed-off-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 432a6baa61d1..6402e9372f6c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -794,19 +794,9 @@ void update_dirty_page(struct inode *inode, struct page *page)
 	f2fs_trace_pid(page);
 }
 
-void add_dirty_dir_inode(struct inode *inode)
-{
-	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
-
-	spin_lock(&sbi->inode_lock[DIR_INODE]);
-	__add_dirty_inode(inode, DIR_INODE);
-	spin_unlock(&sbi->inode_lock[DIR_INODE]);
-}
-
 void remove_dirty_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
-	struct f2fs_inode_info *fi = F2FS_I(inode);
 	enum inode_type type = S_ISDIR(inode->i_mode) ? DIR_INODE : FILE_INODE;
 
 	if (!S_ISDIR(inode->i_mode) && !S_ISREG(inode->i_mode) &&
@@ -816,12 +806,6 @@ void remove_dirty_inode(struct inode *inode)
 	spin_lock(&sbi->inode_lock[type]);
 	__remove_dirty_inode(inode, type);
 	spin_unlock(&sbi->inode_lock[type]);
-
-	/* Only from the recovery routine */
-	if (is_inode_flag_set(fi, FI_DELAY_IPUT)) {
-		clear_inode_flag(fi, FI_DELAY_IPUT);
-		iput(inode);
-	}
 }
 
 int sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)

commit 74ef924167ad9d2897ffc0ef83c7ebf322fcc535
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon May 2 22:09:56 2016 -0700

    f2fs: fix leak of orphan inode objects
    
    When unmounting filesystem, we should release all the ino entries.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 79da86d6cf5c..432a6baa61d1 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -449,12 +449,12 @@ bool exist_written_data(struct f2fs_sb_info *sbi, nid_t ino, int mode)
 	return e ? true : false;
 }
 
-void release_ino_entry(struct f2fs_sb_info *sbi)
+void release_ino_entry(struct f2fs_sb_info *sbi, bool all)
 {
 	struct ino_entry *e, *tmp;
 	int i;
 
-	for (i = APPEND_INO; i <= UPDATE_INO; i++) {
+	for (i = all ? ORPHAN_INO: APPEND_INO; i <= UPDATE_INO; i++) {
 		struct inode_management *im = &sbi->im[i];
 
 		spin_lock(&im->ino_lock);
@@ -1106,7 +1106,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		invalidate_mapping_pages(META_MAPPING(sbi), discard_blk,
 								discard_blk);
 
-	release_ino_entry(sbi);
+	release_ino_entry(sbi, false);
 
 	if (unlikely(f2fs_cp_error(sbi)))
 		return -EIO;

commit cb78942b821380913e6810375c9ce72858e64c4f
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Apr 29 16:29:22 2016 -0700

    f2fs: inject ENOSPC failures
    
    This patch injects ENOSPC failures.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9596d61ca6a8..79da86d6cf5c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -474,6 +474,13 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 	int err = 0;
 
 	spin_lock(&im->ino_lock);
+
+#ifdef CONFIG_F2FS_FAULT_INJECTION
+	if (time_to_inject(FAULT_ORPHAN)) {
+		spin_unlock(&im->ino_lock);
+		return -ENOSPC;
+	}
+#endif
 	if (unlikely(im->ino_num >= sbi->max_orphans))
 		err = -ENOSPC;
 	else

commit 300e129c15f0ed2f94482900a4cb65b28eb09d94
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Apr 29 16:11:53 2016 -0700

    f2fs: use f2fs_grab_cache_page instead of grab_cache_page
    
    This patch converts grab_cache_page to f2fs_grab_cache_page.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index bf040b51989d..9596d61ca6a8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -34,7 +34,7 @@ struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	struct address_space *mapping = META_MAPPING(sbi);
 	struct page *page = NULL;
 repeat:
-	page = grab_cache_page(mapping, index);
+	page = f2fs_grab_cache_page(mapping, index, false);
 	if (!page) {
 		cond_resched();
 		goto repeat;
@@ -64,7 +64,7 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 	if (unlikely(!is_meta))
 		fio.rw &= ~REQ_META;
 repeat:
-	page = grab_cache_page(mapping, index);
+	page = f2fs_grab_cache_page(mapping, index, false);
 	if (!page) {
 		cond_resched();
 		goto repeat;
@@ -186,7 +186,8 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 			BUG();
 		}
 
-		page = grab_cache_page(META_MAPPING(sbi), fio.new_blkaddr);
+		page = f2fs_grab_cache_page(META_MAPPING(sbi),
+						fio.new_blkaddr, false);
 		if (!page)
 			continue;
 		if (PageUptodate(page)) {

commit 5268137564920843e581304d9bfb06fb9502cf24
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Apr 13 16:24:44 2016 -0700

    f2fs: split sync_node_pages with fsync_node_pages
    
    This patch splits the existing sync_node_pages into (f)sync_node_pages.
    The fsync_node_pages is used for f2fs_sync_file only.
    
    Acked-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b92782f40643..bf040b51989d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -892,7 +892,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 
 	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
 		up_write(&sbi->node_write);
-		err = sync_node_pages(sbi, 0, &wbc);
+		err = sync_node_pages(sbi, &wbc);
 		if (err) {
 			f2fs_unlock_all(sbi);
 			goto out;

commit 4da7bf5a4345f3ce9699476a8022f66cfb4a8ce9
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Apr 6 11:27:03 2016 -0700

    f2fs: remove redundant condition check
    
    This patch resolves the redundant condition check reported by David.
    
    Reported-by: David Binderman <dcb314@hotmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0955312e5ca0..b92782f40643 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -211,7 +211,7 @@ void ra_meta_pages_cond(struct f2fs_sb_info *sbi, pgoff_t index)
 	bool readahead = false;
 
 	page = find_get_page(META_MAPPING(sbi), index);
-	if (!page || (page && !PageUptodate(page)))
+	if (!page || !PageUptodate(page))
 		readahead = true;
 	f2fs_put_page(page, 0);
 

commit 43b6573bac95d7cc8a7fb51efe8468c994f5cf56
Author: Keith Mok <ek9852@gmail.com>
Date:   Wed Mar 2 12:04:24 2016 -0800

    f2fs: use cryptoapi crc32 functions
    
    The crc function is done bit by bit.
    Optimize this by use cryptoapi
    crc32 function which is backed by h/w acceleration.
    
    Signed-off-by: Keith Mok <ek9852@gmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4933b82feedd..0955312e5ca0 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -635,7 +635,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 		goto invalid_cp1;
 
 	crc = le32_to_cpu(*((__le32 *)((unsigned char *)cp_block + crc_offset)));
-	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
+	if (!f2fs_crc_valid(sbi, crc, cp_block, crc_offset))
 		goto invalid_cp1;
 
 	pre_version = cur_cp_version(cp_block);
@@ -650,7 +650,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 		goto invalid_cp2;
 
 	crc = le32_to_cpu(*((__le32 *)((unsigned char *)cp_block + crc_offset)));
-	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
+	if (!f2fs_crc_valid(sbi, crc, cp_block, crc_offset))
 		goto invalid_cp2;
 
 	cur_version = cur_cp_version(cp_block);
@@ -1029,7 +1029,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	get_sit_bitmap(sbi, __bitmap_ptr(sbi, SIT_BITMAP));
 	get_nat_bitmap(sbi, __bitmap_ptr(sbi, NAT_BITMAP));
 
-	crc32 = f2fs_crc32(ckpt, le32_to_cpu(ckpt->checksum_offset));
+	crc32 = f2fs_crc32(sbi, ckpt, le32_to_cpu(ckpt->checksum_offset));
 	*((__le32 *)((unsigned char *)ckpt +
 				le32_to_cpu(ckpt->checksum_offset)))
 				= cpu_to_le32(crc32);

commit 406657dd1868a4d7b12be04ed769d9215ec9a7d1
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Feb 24 17:17:55 2016 +0800

    f2fs: introduce f2fs_flush_merged_bios for cleanup
    
    Add a new helper f2fs_flush_merged_bios to clean up redundant codes.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b32ecc954229..4933b82feedd 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1141,9 +1141,7 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish block_ops");
 
-	f2fs_submit_merged_bio(sbi, DATA, WRITE);
-	f2fs_submit_merged_bio(sbi, NODE, WRITE);
-	f2fs_submit_merged_bio(sbi, META, WRITE);
+	f2fs_flush_merged_bios(sbi);
 
 	/*
 	 * update checkpoint pack index

commit 80dd9c0e9db220697301e76b7b61f580ad9e8ecd
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Feb 24 17:20:44 2016 +0800

    f2fs: fix incorrect upper bound when iterating inode mapping tree
    
    1. Inode mapping tree can index page in range of [0, ULONG_MAX], however,
    in some places, f2fs only search or iterate page in ragne of [0, LONG_MAX],
    result in miss hitting in page cache.
    
    2. filemap_fdatawait_range accepts range parameters in unit of bytes, so
    the max range it covers should be [0, LLONG_MAX], if we use [0, LONG_MAX]
    as range for waiting on writeback, big number of pages will not be covered.
    
    This patch corrects above two issues.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f55355d7d6b1..b32ecc954229 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -282,7 +282,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 						long nr_to_write)
 {
 	struct address_space *mapping = META_MAPPING(sbi);
-	pgoff_t index = 0, end = LONG_MAX, prev = LONG_MAX;
+	pgoff_t index = 0, end = ULONG_MAX, prev = ULONG_MAX;
 	struct pagevec pvec;
 	long nwritten = 0;
 	struct writeback_control wbc = {
@@ -305,7 +305,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 		for (i = 0; i < nr_pages; i++) {
 			struct page *page = pvec.pages[i];
 
-			if (prev == LONG_MAX)
+			if (prev == ULONG_MAX)
 				prev = page->index - 1;
 			if (nr_to_write != LONG_MAX && page->index != prev + 1) {
 				pagevec_release(&pvec);
@@ -1077,8 +1077,8 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (unlikely(f2fs_cp_error(sbi)))
 		return -EIO;
 
-	filemap_fdatawait_range(NODE_MAPPING(sbi), 0, LONG_MAX);
-	filemap_fdatawait_range(META_MAPPING(sbi), 0, LONG_MAX);
+	filemap_fdatawait_range(NODE_MAPPING(sbi), 0, LLONG_MAX);
+	filemap_fdatawait_range(META_MAPPING(sbi), 0, LLONG_MAX);
 
 	/* update user_block_counts */
 	sbi->last_valid_block_count = sbi->total_valid_block_count;

commit 0ff21646f2a5c6ff77acc51eb3df4235af39be46
Author: Yunlei He <heyunlei@huawei.com>
Date:   Tue Feb 23 12:07:56 2016 +0800

    f2fs: avoid hungtask problem caused by losing wake_up
    
    The D state of wait_on_all_pages_writeback should be waken by
    function f2fs_write_end_io when all writeback pages have been
    succesfully written to device. It's possible that wake_up comes
    between get_pages and io_schedule. Maybe in this case it will
    lost wake_up and still in D state even if all pages have been
    write back to device, and finally, the whole system will be into
    the hungtask state.
    
                    if (!get_pages(sbi, F2FS_WRITEBACK))
                             break;
                                            <---------  wake_up
                    io_schedule();
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Signed-off-by: Biao He <hebiao6@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2bac8a165488..f55355d7d6b1 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -920,7 +920,7 @@ static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 		if (!get_pages(sbi, F2FS_WRITEBACK))
 			break;
 
-		io_schedule();
+		io_schedule_timeout(5*HZ);
 	}
 	finish_wait(&sbi->cp_wait, &wait);
 }

commit 7a9d75481b85d59204d76097d41a28db663a7a43
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Feb 22 18:36:38 2016 +0800

    f2fs: trace old block address for CoWed page
    
    This patch enables to trace old block address of CoWed page for better
    debugging.
    
    f2fs_submit_page_mbio: dev = (1,0), ino = 1, page_index = 0x1d4f0, oldaddr = 0xfe8ab, newaddr = 0xfee90 rw = WRITE_SYNC, type = NODE
    f2fs_submit_page_mbio: dev = (1,0), ino = 1, page_index = 0x1d4f8, oldaddr = 0xfe8b0, newaddr = 0xfee91 rw = WRITE_SYNC, type = NODE
    f2fs_submit_page_mbio: dev = (1,0), ino = 1, page_index = 0x1d4fa, oldaddr = 0xfe8ae, newaddr = 0xfee92 rw = WRITE_SYNC, type = NODE
    
    f2fs_submit_page_mbio: dev = (1,0), ino = 134824, page_index = 0x96, oldaddr = 0xf049b, newaddr = 0x2bbe rw = WRITE, type = DATA
    f2fs_submit_page_mbio: dev = (1,0), ino = 134824, page_index = 0x97, oldaddr = 0xf049c, newaddr = 0x2bbf rw = WRITE, type = DATA
    f2fs_submit_page_mbio: dev = (1,0), ino = 134824, page_index = 0x98, oldaddr = 0xf049d, newaddr = 0x2bc0 rw = WRITE, type = DATA
    
    f2fs_submit_page_mbio: dev = (1,0), ino = 135260, page_index = 0x47, oldaddr = 0xffffffff, newaddr = 0xf2631 rw = WRITE, type = DATA
    f2fs_submit_page_mbio: dev = (1,0), ino = 135260, page_index = 0x48, oldaddr = 0xffffffff, newaddr = 0xf2632 rw = WRITE, type = DATA
    f2fs_submit_page_mbio: dev = (1,0), ino = 135260, page_index = 0x49, oldaddr = 0xffffffff, newaddr = 0xf2633 rw = WRITE, type = DATA
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 8d88a964dd04..2bac8a165488 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -56,7 +56,8 @@ static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
 		.sbi = sbi,
 		.type = META,
 		.rw = READ_SYNC | REQ_META | REQ_PRIO,
-		.blk_addr = index,
+		.old_blkaddr = index,
+		.new_blkaddr = index,
 		.encrypted_page = NULL,
 	};
 
@@ -168,24 +169,24 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 					NAT_BLOCK_OFFSET(NM_I(sbi)->max_nid)))
 				blkno = 0;
 			/* get nat block addr */
-			fio.blk_addr = current_nat_addr(sbi,
+			fio.new_blkaddr = current_nat_addr(sbi,
 					blkno * NAT_ENTRY_PER_BLOCK);
 			break;
 		case META_SIT:
 			/* get sit block addr */
-			fio.blk_addr = current_sit_addr(sbi,
+			fio.new_blkaddr = current_sit_addr(sbi,
 					blkno * SIT_ENTRY_PER_BLOCK);
 			break;
 		case META_SSA:
 		case META_CP:
 		case META_POR:
-			fio.blk_addr = blkno;
+			fio.new_blkaddr = blkno;
 			break;
 		default:
 			BUG();
 		}
 
-		page = grab_cache_page(META_MAPPING(sbi), fio.blk_addr);
+		page = grab_cache_page(META_MAPPING(sbi), fio.new_blkaddr);
 		if (!page)
 			continue;
 		if (PageUptodate(page)) {
@@ -194,6 +195,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		}
 
 		fio.page = page;
+		fio.old_blkaddr = fio.new_blkaddr;
 		f2fs_submit_page_mbio(&fio);
 		f2fs_put_page(page, 0);
 	}

commit 984ec63c5a82a07ad4490ecc69bebacd23f6fa64
Author: Shawn Lin <shawn.lin@rock-chips.com>
Date:   Wed Feb 17 11:26:32 2016 +0800

    f2fs: move sanity checking of cp into get_valid_checkpoint
    
    >From the function name of get_valid_checkpoint, it seems to return
    the valid cp or NULL for caller to check. If no valid one is found,
    f2fs_fill_super will print the err log. But if get_valid_checkpoint
    get one valid(the return value indicate that it's valid, however actually
    it is invalid after sanity checking), then print another similar err
    log. That seems strange. Let's keep sanity checking inside the procedure
    of geting valid cp. Another improvement we gained from this move is
    that even the large volume is supported, we check the cp in advanced
    to skip the following procedure if failing the sanity checking.
    
    Signed-off-by: Shawn Lin <shawn.lin@rock-chips.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 359a805397e3..8d88a964dd04 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -708,6 +708,10 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	cp_block = (struct f2fs_checkpoint *)page_address(cur_page);
 	memcpy(sbi->ckpt, cp_block, blk_size);
 
+	/* Sanity checking of checkpoint */
+	if (sanity_check_ckpt(sbi))
+		goto fail_no_cp;
+
 	if (cp_blks <= 1)
 		goto done;
 

commit b7ad7512b84b26f1c0ec823647a387627c138d32
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Fri Feb 19 18:08:46 2016 +0800

    f2fs: split journal cache from curseg cache
    
    In curseg cache, f2fs caches two different parts:
     - datas of current summay block, i.e. summary entries, footer info.
     - journal info, i.e. sparse nat/sit entries or io stat info.
    
    With this approach, 1) it may cause higher lock contention when we access
    or update both of the parts of cache since we use the same mutex lock
    curseg_mutex to protect the cache. 2) current summary block with last
    journal info will be writebacked into device as a normal summary block
    when flushing, however, we treat journal info as valid one only in current
    summary, so most normal summary blocks contain junk journal data, it wastes
    remaining space of summary block.
    
    So, in order to fix above issues, we split curseg cache into two parts:
    a) current summary block, protected by original mutex lock curseg_mutex
    b) journal cache, protected by newly introduced r/w semaphore journal_rwsem
    
    When loading curseg cache during ->mount, we store summary info and
    journal info into different caches; When doing checkpoint, we combine
    datas of two cache into current summary block for persisting.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 677680368708..359a805397e3 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1055,7 +1055,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (sb->s_bdev->bd_part)
 		kbytes_written += BD_PART_WRITTEN(sbi);
 
-	seg_i->sum_blk->journal.info.kbytes_written = cpu_to_le64(kbytes_written);
+	seg_i->journal->info.kbytes_written = cpu_to_le64(kbytes_written);
 
 	if (__remain_node_summaries(cpc->reason)) {
 		write_node_summaries(sbi, start_blk);

commit e9f5b8b8d6e279ab61d5902fcbebf3799597c900
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sun Feb 14 18:54:33 2016 +0800

    f2fs: enhance IO path with block plug
    
    Try to use block plug in more place as below to let process cache bios
    as much as possbile, in order to reduce lock overhead of queue in IO
    scheduler.
    1) sync_meta_pages
    2) ra_meta_pages
    3) f2fs_balance_fs_bg
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3cdcdaf1d0fe..677680368708 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -143,7 +143,6 @@ bool is_valid_blkaddr(struct f2fs_sb_info *sbi, block_t blkaddr, int type)
 int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 							int type, bool sync)
 {
-	block_t prev_blk_addr = 0;
 	struct page *page;
 	block_t blkno = start;
 	struct f2fs_io_info fio = {
@@ -152,10 +151,12 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 		.rw = sync ? (READ_SYNC | REQ_META | REQ_PRIO) : READA,
 		.encrypted_page = NULL,
 	};
+	struct blk_plug plug;
 
 	if (unlikely(type == META_POR))
 		fio.rw &= ~REQ_META;
 
+	blk_start_plug(&plug);
 	for (; nrpages-- > 0; blkno++) {
 
 		if (!is_valid_blkaddr(sbi, blkno, type))
@@ -174,9 +175,6 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 			/* get sit block addr */
 			fio.blk_addr = current_sit_addr(sbi,
 					blkno * SIT_ENTRY_PER_BLOCK);
-			if (blkno != start && prev_blk_addr + 1 != fio.blk_addr)
-				goto out;
-			prev_blk_addr = fio.blk_addr;
 			break;
 		case META_SSA:
 		case META_CP:
@@ -201,6 +199,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
 	}
 out:
 	f2fs_submit_merged_bio(sbi, META, READ);
+	blk_finish_plug(&plug);
 	return blkno - start;
 }
 
@@ -287,9 +286,12 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 	struct writeback_control wbc = {
 		.for_reclaim = 0,
 	};
+	struct blk_plug plug;
 
 	pagevec_init(&pvec, 0);
 
+	blk_start_plug(&plug);
+
 	while (index <= end) {
 		int i, nr_pages;
 		nr_pages = pagevec_lookup_tag(&pvec, mapping, &index,
@@ -342,6 +344,8 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 	if (nwritten)
 		f2fs_submit_merged_bio(sbi, type, WRITE);
 
+	blk_finish_plug(&plug);
+
 	return nwritten;
 }
 

commit dfc08a12e49a64f97d8b474da1d7745230cec5eb
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sun Feb 14 18:50:40 2016 +0800

    f2fs: introduce f2fs_journal struct to wrap journal info
    
    Introduce a new structure f2fs_journal to wrap journal info in struct
    f2fs_summary_block for readability.
    
    struct f2fs_journal {
            union {
                    __le16 n_nats;
                    __le16 n_sits;
            };
            union {
                    struct nat_journal nat_j;
                    struct sit_journal sit_j;
                    struct f2fs_extra_info info;
            };
    } __packed;
    
    struct f2fs_summary_block {
            struct f2fs_summary entries[ENTRIES_IN_SUM];
            struct f2fs_journal journal;
            struct summary_footer footer;
    } __packed;
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 536bec99bd64..3cdcdaf1d0fe 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1051,7 +1051,7 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (sb->s_bdev->bd_part)
 		kbytes_written += BD_PART_WRITTEN(sbi);
 
-	seg_i->sum_blk->info.kbytes_written = cpu_to_le64(kbytes_written);
+	seg_i->sum_blk->journal.info.kbytes_written = cpu_to_le64(kbytes_written);
 
 	if (__remain_node_summaries(cpc->reason)) {
 		write_node_summaries(sbi, start_blk);

commit d31c7c3f0b003358a68c5c9a660ea2be13a3ca67
Author: Yunlei He <heyunlei@huawei.com>
Date:   Thu Feb 4 16:14:00 2016 +0800

    f2fs: fix missing skip pages info
    
    fix missing skip pages info in f2fs_writepages trace event.
    
    Signed-off-by: Yunlei He <heyunlei@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9c0d721598e5..536bec99bd64 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -256,13 +256,13 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 	struct f2fs_sb_info *sbi = F2FS_M_SB(mapping);
 	long diff, written;
 
-	trace_f2fs_writepages(mapping->host, wbc, META);
-
 	/* collect a number of dirty meta pages and write together */
 	if (wbc->for_kupdate ||
 		get_pages(sbi, F2FS_DIRTY_META) < nr_pages_to_skip(sbi, META))
 		goto skip_write;
 
+	trace_f2fs_writepages(mapping->host, wbc, META);
+
 	/* if mounting is failed, skip writing node pages */
 	mutex_lock(&sbi->cp_mutex);
 	diff = nr_pages_to_write(sbi, META, wbc);
@@ -273,6 +273,7 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 
 skip_write:
 	wbc->pages_skipped += get_pages(sbi, F2FS_DIRTY_META);
+	trace_f2fs_writepages(mapping->host, wbc, META);
 	return 0;
 }
 

commit 0c3a579758362d5c713bb8ecc85ef82eccd56db0
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Jan 18 18:28:11 2016 +0800

    f2fs: introduce f2fs_submit_merged_bio_cond
    
    f2fs use single bio buffer per type data (META/NODE/DATA) for caching
    writes locating in continuous block address as many as possible, after
    submitting, these writes may be still cached in bio buffer, so we have
    to flush cached writes in bio buffer by calling f2fs_submit_merged_bio.
    
    Unfortunately, in the scenario of high concurrency, bio buffer could be
    flushed by someone else before we submit it as below reasons:
    a) there is no space in bio buffer.
    b) add a request of different type (SYNC, ASYNC).
    c) add a discontinuous block address.
    
    For this condition, f2fs_submit_merged_bio will be devastating, because
    it could break the following merging of writes in bio buffer, split one
    big bio into two smaller one.
    
    This patch introduces f2fs_submit_merged_bio_cond which can do a
    conditional submitting with bio buffer, before submitting it will judge
    whether:
     - page in DATA type bio buffer is matching with specified page;
     - page in DATA type bio buffer is belong to specified inode;
     - page in NODE type bio buffer is belong to specified inode;
    If there is no eligible page in bio buffer, we will skip submitting step,
    result in gaining more chance to merge consecutive block IOs in bio cache.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 96d606d93f2f..9c0d721598e5 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -234,10 +234,15 @@ static int f2fs_write_meta_page(struct page *page,
 
 	write_meta_page(sbi, page);
 	dec_page_count(sbi, F2FS_DIRTY_META);
+
+	if (wbc->for_reclaim)
+		f2fs_submit_merged_bio_cond(sbi, NULL, page, 0, META, WRITE);
+
 	unlock_page(page);
 
-	if (wbc->for_reclaim || unlikely(f2fs_cp_error(sbi)))
+	if (unlikely(f2fs_cp_error(sbi)))
 		f2fs_submit_merged_bio(sbi, META, WRITE);
+
 	return 0;
 
 redirty_out:

commit fa3d2bdf94879c3645b3688e88ca03deb3bb495a
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jan 28 11:48:52 2016 -0800

    f2fs: wait on page's writeback in writepages path
    
    Likewise f2fs_write_cache_pages, let's do for node and meta pages too.
    Especially, for node blocks, we should do this before marking its fsync
    and dentry flags.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 112e19fdbe08..96d606d93f2f 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -232,7 +232,6 @@ static int f2fs_write_meta_page(struct page *page,
 	if (unlikely(f2fs_cp_error(sbi)))
 		goto redirty_out;
 
-	f2fs_wait_on_page_writeback(page, META, true);
 	write_meta_page(sbi, page);
 	dec_page_count(sbi, F2FS_DIRTY_META);
 	unlock_page(page);
@@ -315,6 +314,9 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 				goto continue_unlock;
 			}
 
+			f2fs_wait_on_page_writeback(page, META, true);
+
+			BUG_ON(PageWriteback(page));
 			if (!clear_page_dirty_for_io(page))
 				goto continue_unlock;
 

commit 8f1dbbbbdfe9bada7e2f8041e07c6373f787c043
Author: Shuoran Liu <liushuoran@huawei.com>
Date:   Wed Jan 27 09:57:30 2016 +0800

    f2fs: introduce lifetime write IO statistics
    
    This patch introduces lifetime IO write statistics exposed to the sysfs interface.
    The write IO amount is obtained from block layer, accumulated in the file system and
    stored in the hot node summary of checkpoint.
    
    Signed-off-by: Shuoran Liu <liushuoran@huawei.com>
    Signed-off-by: Pengyang Hou <houpengyang@huawei.com>
    [Jaegeuk Kim: add sysfs documentation]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4b6f9c08f6fa..112e19fdbe08 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -921,6 +921,9 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	int cp_payload_blks = __cp_payload(sbi);
 	block_t discard_blk = NEXT_FREE_BLKADDR(sbi, curseg);
 	bool invalidate = false;
+	struct super_block *sb = sbi->sb;
+	struct curseg_info *seg_i = CURSEG_I(sbi, CURSEG_HOT_NODE);
+	u64 kbytes_written;
 
 	/*
 	 * This avoids to conduct wrong roll-forward operations and uses
@@ -1034,6 +1037,14 @@ static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	write_data_summaries(sbi, start_blk);
 	start_blk += data_sum_blocks;
+
+	/* Record write statistics in the hot node summary */
+	kbytes_written = sbi->kbytes_written;
+	if (sb->s_bdev->bd_part)
+		kbytes_written += BD_PART_WRITTEN(sbi);
+
+	seg_i->sum_blk->info.kbytes_written = cpu_to_le64(kbytes_written);
+
 	if (__remain_node_summaries(cpc->reason)) {
 		write_node_summaries(sbi, start_blk);
 		start_blk += NR_CURSEG_NODE_TYPE;

commit fec1d6576cdf2ce13f84fcdf7b20d02a05f76fc6
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Jan 20 23:43:51 2016 +0800

    f2fs: use wait_for_stable_page to avoid contention
    
    In write_begin, if storage supports stable_page, we don't need to wait for
    writeback to update its contents.
    This patch introduces to use wait_for_stable_page instead of
    wait_on_page_writeback.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3842af954cd5..4b6f9c08f6fa 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -39,7 +39,7 @@ struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		cond_resched();
 		goto repeat;
 	}
-	f2fs_wait_on_page_writeback(page, META);
+	f2fs_wait_on_page_writeback(page, META, true);
 	SetPageUptodate(page);
 	return page;
 }
@@ -232,7 +232,7 @@ static int f2fs_write_meta_page(struct page *page,
 	if (unlikely(f2fs_cp_error(sbi)))
 		goto redirty_out;
 
-	f2fs_wait_on_page_writeback(page, META);
+	f2fs_wait_on_page_writeback(page, META, true);
 	write_meta_page(sbi, page);
 	dec_page_count(sbi, F2FS_DIRTY_META);
 	unlock_page(page);

commit 6beceb5427aa8731f958d2484e0fd8ff21d604dc
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jan 8 15:51:50 2016 -0800

    f2fs: introduce time and interval facility
    
    This patch adds time and interval arrays to store some timing variables.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5dbafd5e83d9..3842af954cd5 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1139,7 +1139,7 @@ int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 			"checkpoint: version = %llx", ckpt_ver);
 
 	/* do checkpoint periodically */
-	sbi->cp_expires = round_jiffies_up(jiffies + HZ * sbi->cp_interval);
+	f2fs_update_time(sbi, CP_TIME);
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish checkpoint");
 out:
 	mutex_unlock(&sbi->cp_mutex);

commit 8d4ea29b6426470456ee9daee64bac55a3b13289
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Dec 31 13:08:02 2015 -0800

    f2fs: write pending bios when cp_error is set
    
    When testing ioc_shutdown, put_super is able to be hanged by waiting for
    writebacking pages as follows.
    
    INFO: task umount:2723 blocked for more than 120 seconds.
          Tainted: G           O    4.4.0-rc3+ #8
    "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    umount          D ffff88000859f9d8     0  2723   2110 0x00000000
     ffff88000859f9d8 0000000000000000 0000000000000000 ffffffff81e11540
     ffff880078c225c0 ffff8800085a0000 ffff88007fc17440 7fffffffffffffff
     ffffffff818239f0 ffff88000859fb48 ffff88000859f9f0 ffffffff8182310c
    Call Trace:
     [<ffffffff818239f0>] ? bit_wait+0x50/0x50
     [<ffffffff8182310c>] schedule+0x3c/0x90
     [<ffffffff81827fb9>] schedule_timeout+0x2d9/0x430
     [<ffffffff810e0f8f>] ? mark_held_locks+0x6f/0xa0
     [<ffffffff8111614d>] ? ktime_get+0x7d/0x140
     [<ffffffff818239f0>] ? bit_wait+0x50/0x50
     [<ffffffff8106a655>] ? kvm_clock_get_cycles+0x25/0x30
     [<ffffffff8111617c>] ? ktime_get+0xac/0x140
     [<ffffffff818239f0>] ? bit_wait+0x50/0x50
     [<ffffffff81822564>] io_schedule_timeout+0xa4/0x110
     [<ffffffff81823a25>] bit_wait_io+0x35/0x50
     [<ffffffff818235bd>] __wait_on_bit+0x5d/0x90
     [<ffffffff811b9e8b>] wait_on_page_bit+0xcb/0xf0
     [<ffffffff810d5f90>] ? autoremove_wake_function+0x40/0x40
     [<ffffffff811cf84c>] truncate_inode_pages_range+0x4bc/0x840
     [<ffffffff811cfc3d>] truncate_inode_pages_final+0x4d/0x60
     [<ffffffffc023ced5>] f2fs_evict_inode+0x75/0x400 [f2fs]
     [<ffffffff812639bc>] evict+0xbc/0x190
     [<ffffffff81263d19>] iput+0x229/0x2c0
     [<ffffffffc0241885>] f2fs_put_super+0x105/0x1a0 [f2fs]
     [<ffffffff8124756a>] generic_shutdown_super+0x6a/0xf0
     [<ffffffff812478f7>] kill_block_super+0x27/0x70
     [<ffffffffc0241290>] kill_f2fs_super+0x20/0x30 [f2fs]
     [<ffffffff81247b03>] deactivate_locked_super+0x43/0x70
     [<ffffffff81247f4c>] deactivate_super+0x5c/0x60
     [<ffffffff81268d2f>] cleanup_mnt+0x3f/0x90
     [<ffffffff81268dc2>] __cleanup_mnt+0x12/0x20
     [<ffffffff810ac463>] task_work_run+0x73/0xa0
     [<ffffffff810032ac>] exit_to_usermode_loop+0xcc/0xd0
     [<ffffffff81003e7c>] syscall_return_slowpath+0xcc/0xe0
     [<ffffffff81829ea2>] int_ret_from_sys_call+0x25/0x9f
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6b89ac69b7e4..5dbafd5e83d9 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -237,7 +237,7 @@ static int f2fs_write_meta_page(struct page *page,
 	dec_page_count(sbi, F2FS_DIRTY_META);
 	unlock_page(page);
 
-	if (wbc->for_reclaim)
+	if (wbc->for_reclaim || unlikely(f2fs_cp_error(sbi)))
 		f2fs_submit_merged_bio(sbi, META, WRITE);
 	return 0;
 

commit 6d5a1495eebd441216dc96913a4270100b26e104
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Dec 24 18:04:56 2015 +0800

    f2fs: let user being aware of IO error
    
    Sometimes we keep dumb when IO error occur in lower layer device, so user
    will not receive any error return value for some operation, but actually,
    the operation did not succeed.
    
    This sould be avoided, so this patch reports such kind of error to user.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9cdb16197351..6b89ac69b7e4 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -798,7 +798,7 @@ void remove_dirty_inode(struct inode *inode)
 	}
 }
 
-void sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
+int sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 {
 	struct list_head *head;
 	struct inode *inode;
@@ -810,7 +810,7 @@ void sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 				F2FS_DIRTY_DENTS : F2FS_DIRTY_DATA));
 retry:
 	if (unlikely(f2fs_cp_error(sbi)))
-		return;
+		return -EIO;
 
 	spin_lock(&sbi->inode_lock[type]);
 
@@ -820,7 +820,7 @@ void sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 		trace_f2fs_sync_dirty_inodes_exit(sbi->sb, is_dir,
 				get_pages(sbi, is_dir ?
 				F2FS_DIRTY_DENTS : F2FS_DIRTY_DATA));
-		return;
+		return 0;
 	}
 	fi = list_entry(head->next, struct f2fs_inode_info, dirty_list);
 	inode = igrab(&fi->vfs_inode);
@@ -859,11 +859,9 @@ static int block_operations(struct f2fs_sb_info *sbi)
 	/* write all the dirty dentry pages */
 	if (get_pages(sbi, F2FS_DIRTY_DENTS)) {
 		f2fs_unlock_all(sbi);
-		sync_dirty_inodes(sbi, DIR_INODE);
-		if (unlikely(f2fs_cp_error(sbi))) {
-			err = -EIO;
+		err = sync_dirty_inodes(sbi, DIR_INODE);
+		if (err)
 			goto out;
-		}
 		goto retry_flush_dents;
 	}
 
@@ -876,10 +874,9 @@ static int block_operations(struct f2fs_sb_info *sbi)
 
 	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
 		up_write(&sbi->node_write);
-		sync_node_pages(sbi, 0, &wbc);
-		if (unlikely(f2fs_cp_error(sbi))) {
+		err = sync_node_pages(sbi, 0, &wbc);
+		if (err) {
 			f2fs_unlock_all(sbi);
-			err = -EIO;
 			goto out;
 		}
 		goto retry_flush_nodes;

commit c34f42e2cb2d27650549306de5ff36839e9177d6
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Dec 23 17:50:30 2015 +0800

    f2fs: report error of do_checkpoint
    
    do_checkpoint and write_checkpoint can fail due to reasons like triggering
    in a readonly fs or encountering IO error of storage device.
    
    So it's better to report such error info to user, let user be aware of
    failure of doing checkpoint.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index fdd43f71d2c6..9cdb16197351 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -910,7 +910,7 @@ static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 	finish_wait(&sbi->cp_wait, &wait);
 }
 
-static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
+static int do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
@@ -936,7 +936,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	while (get_pages(sbi, F2FS_DIRTY_META)) {
 		sync_meta_pages(sbi, META, LONG_MAX);
 		if (unlikely(f2fs_cp_error(sbi)))
-			return;
+			return -EIO;
 	}
 
 	next_free_nid(sbi, &last_nid);
@@ -1021,7 +1021,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* need to wait for end_io results */
 	wait_on_all_pages_writeback(sbi);
 	if (unlikely(f2fs_cp_error(sbi)))
-		return;
+		return -EIO;
 
 	/* write out checkpoint buffer at block 0 */
 	update_meta_page(sbi, ckpt, start_blk++);
@@ -1049,7 +1049,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	wait_on_all_pages_writeback(sbi);
 
 	if (unlikely(f2fs_cp_error(sbi)))
-		return;
+		return -EIO;
 
 	filemap_fdatawait_range(NODE_MAPPING(sbi), 0, LONG_MAX);
 	filemap_fdatawait_range(META_MAPPING(sbi), 0, LONG_MAX);
@@ -1075,19 +1075,22 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	release_ino_entry(sbi);
 
 	if (unlikely(f2fs_cp_error(sbi)))
-		return;
+		return -EIO;
 
 	clear_prefree_segments(sbi, cpc);
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
+
+	return 0;
 }
 
 /*
  * We guarantee that this checkpoint procedure will not fail.
  */
-void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
+int write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	unsigned long long ckpt_ver;
+	int err = 0;
 
 	mutex_lock(&sbi->cp_mutex);
 
@@ -1095,14 +1098,19 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		(cpc->reason == CP_FASTBOOT || cpc->reason == CP_SYNC ||
 		(cpc->reason == CP_DISCARD && !sbi->discard_blks)))
 		goto out;
-	if (unlikely(f2fs_cp_error(sbi)))
+	if (unlikely(f2fs_cp_error(sbi))) {
+		err = -EIO;
 		goto out;
-	if (f2fs_readonly(sbi->sb))
+	}
+	if (f2fs_readonly(sbi->sb)) {
+		err = -EROFS;
 		goto out;
+	}
 
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "start block_ops");
 
-	if (block_operations(sbi))
+	err = block_operations(sbi);
+	if (err)
 		goto out;
 
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish block_ops");
@@ -1124,7 +1132,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	flush_sit_entries(sbi, cpc);
 
 	/* unlock all the fs_lock[] in do_checkpoint() */
-	do_checkpoint(sbi, cpc);
+	err = do_checkpoint(sbi, cpc);
 
 	unblock_operations(sbi);
 	stat_inc_cp_count(sbi->stat_info);
@@ -1138,6 +1146,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish checkpoint");
 out:
 	mutex_unlock(&sbi->cp_mutex);
+	return err;
 }
 
 void init_ino_entry_info(struct f2fs_sb_info *sbi)

commit 4cf185379b7504d640c9dd72f959f081b25f6ea2
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Dec 17 17:17:16 2015 +0800

    f2fs: add a tracepoint for sync_dirty_inodes
    
    This patch adds a tracepoint for sync_dirty_inodes.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 53044ea8bb5d..fdd43f71d2c6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -803,6 +803,11 @@ void sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 	struct list_head *head;
 	struct inode *inode;
 	struct f2fs_inode_info *fi;
+	bool is_dir = (type == DIR_INODE);
+
+	trace_f2fs_sync_dirty_inodes_enter(sbi->sb, is_dir,
+				get_pages(sbi, is_dir ?
+				F2FS_DIRTY_DENTS : F2FS_DIRTY_DATA));
 retry:
 	if (unlikely(f2fs_cp_error(sbi)))
 		return;
@@ -812,6 +817,9 @@ void sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 	head = &sbi->inode_list[type];
 	if (list_empty(head)) {
 		spin_unlock(&sbi->inode_lock[type]);
+		trace_f2fs_sync_dirty_inodes_exit(sbi->sb, is_dir,
+				get_pages(sbi, is_dir ?
+				F2FS_DIRTY_DENTS : F2FS_DIRTY_DATA));
 		return;
 	}
 	fi = list_entry(head->next, struct f2fs_inode_info, dirty_list);

commit 33fbd5100de6d0a87f354ecf5ec0486ba01a6da7
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Dec 17 17:14:44 2015 +0800

    f2fs: stat dirty regular/symlink inodes
    
    Add to stat dirty regular and symlink inode for showing in debugfs.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index a037bbd89dc6..53044ea8bb5d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -733,13 +733,11 @@ static void __add_dirty_inode(struct inode *inode, enum inode_type type)
 
 	set_inode_flag(fi, flag);
 	list_add_tail(&fi->dirty_list, &sbi->inode_list[type]);
-	if (type == DIR_INODE)
-		stat_inc_dirty_dir(sbi);
+	stat_inc_dirty_inode(sbi, type);
 }
 
 static void __remove_dirty_inode(struct inode *inode, enum inode_type type)
 {
-	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	struct f2fs_inode_info *fi = F2FS_I(inode);
 	int flag = (type == DIR_INODE) ? FI_DIRTY_DIR : FI_DIRTY_FILE;
 
@@ -749,8 +747,7 @@ static void __remove_dirty_inode(struct inode *inode, enum inode_type type)
 
 	list_del_init(&fi->dirty_list);
 	clear_inode_flag(fi, flag);
-	if (type == DIR_INODE)
-		stat_dec_dirty_dir(sbi);
+	stat_dec_dirty_inode(F2FS_I_SB(inode), type);
 }
 
 void update_dirty_page(struct inode *inode, struct page *page)

commit c227f912732f204c0ec4a577ba812401ac4672af
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Dec 16 13:09:20 2015 +0800

    f2fs: record dirty status of regular/symlink inode
    
    Maintain regular/symlink inode which has dirty pages in global dirty list
    and record their total dirty pages count like the way of handling directory
    inode.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5008b872f316..a037bbd89dc6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -722,53 +722,51 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	return -EINVAL;
 }
 
-static void __add_dirty_inode(struct inode *inode)
+static void __add_dirty_inode(struct inode *inode, enum inode_type type)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	struct f2fs_inode_info *fi = F2FS_I(inode);
+	int flag = (type == DIR_INODE) ? FI_DIRTY_DIR : FI_DIRTY_FILE;
 
-	if (is_inode_flag_set(fi, FI_DIRTY_DIR))
+	if (is_inode_flag_set(fi, flag))
 		return;
 
-	set_inode_flag(fi, FI_DIRTY_DIR);
-	list_add_tail(&fi->dirty_list, &sbi->dir_inode_list);
-	stat_inc_dirty_dir(sbi);
-	return;
+	set_inode_flag(fi, flag);
+	list_add_tail(&fi->dirty_list, &sbi->inode_list[type]);
+	if (type == DIR_INODE)
+		stat_inc_dirty_dir(sbi);
 }
 
-static void __remove_dirty_inode(struct inode *inode)
+static void __remove_dirty_inode(struct inode *inode, enum inode_type type)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	struct f2fs_inode_info *fi = F2FS_I(inode);
+	int flag = (type == DIR_INODE) ? FI_DIRTY_DIR : FI_DIRTY_FILE;
 
 	if (get_dirty_pages(inode) ||
-			!is_inode_flag_set(F2FS_I(inode), FI_DIRTY_DIR))
+			!is_inode_flag_set(F2FS_I(inode), flag))
 		return;
 
 	list_del_init(&fi->dirty_list);
-	clear_inode_flag(fi, FI_DIRTY_DIR);
-	stat_dec_dirty_dir(sbi);
+	clear_inode_flag(fi, flag);
+	if (type == DIR_INODE)
+		stat_dec_dirty_dir(sbi);
 }
 
 void update_dirty_page(struct inode *inode, struct page *page)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
+	enum inode_type type = S_ISDIR(inode->i_mode) ? DIR_INODE : FILE_INODE;
 
 	if (!S_ISDIR(inode->i_mode) && !S_ISREG(inode->i_mode) &&
 			!S_ISLNK(inode->i_mode))
 		return;
 
-	if (!S_ISDIR(inode->i_mode)) {
-		inode_inc_dirty_pages(inode);
-		goto out;
-	}
-
-	spin_lock(&sbi->dir_inode_lock);
-	__add_dirty_inode(inode);
+	spin_lock(&sbi->inode_lock[type]);
+	__add_dirty_inode(inode, type);
 	inode_inc_dirty_pages(inode);
-	spin_unlock(&sbi->dir_inode_lock);
+	spin_unlock(&sbi->inode_lock[type]);
 
-out:
 	SetPagePrivate(page);
 	f2fs_trace_pid(page);
 }
@@ -777,22 +775,24 @@ void add_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 
-	spin_lock(&sbi->dir_inode_lock);
-	__add_dirty_inode(inode);
-	spin_unlock(&sbi->dir_inode_lock);
+	spin_lock(&sbi->inode_lock[DIR_INODE]);
+	__add_dirty_inode(inode, DIR_INODE);
+	spin_unlock(&sbi->inode_lock[DIR_INODE]);
 }
 
-void remove_dirty_dir_inode(struct inode *inode)
+void remove_dirty_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	struct f2fs_inode_info *fi = F2FS_I(inode);
+	enum inode_type type = S_ISDIR(inode->i_mode) ? DIR_INODE : FILE_INODE;
 
-	if (!S_ISDIR(inode->i_mode))
+	if (!S_ISDIR(inode->i_mode) && !S_ISREG(inode->i_mode) &&
+			!S_ISLNK(inode->i_mode))
 		return;
 
-	spin_lock(&sbi->dir_inode_lock);
-	__remove_dirty_inode(inode);
-	spin_unlock(&sbi->dir_inode_lock);
+	spin_lock(&sbi->inode_lock[type]);
+	__remove_dirty_inode(inode, type);
+	spin_unlock(&sbi->inode_lock[type]);
 
 	/* Only from the recovery routine */
 	if (is_inode_flag_set(fi, FI_DELAY_IPUT)) {
@@ -801,7 +801,7 @@ void remove_dirty_dir_inode(struct inode *inode)
 	}
 }
 
-void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
+void sync_dirty_inodes(struct f2fs_sb_info *sbi, enum inode_type type)
 {
 	struct list_head *head;
 	struct inode *inode;
@@ -810,16 +810,16 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 	if (unlikely(f2fs_cp_error(sbi)))
 		return;
 
-	spin_lock(&sbi->dir_inode_lock);
+	spin_lock(&sbi->inode_lock[type]);
 
-	head = &sbi->dir_inode_list;
+	head = &sbi->inode_list[type];
 	if (list_empty(head)) {
-		spin_unlock(&sbi->dir_inode_lock);
+		spin_unlock(&sbi->inode_lock[type]);
 		return;
 	}
 	fi = list_entry(head->next, struct f2fs_inode_info, dirty_list);
 	inode = igrab(&fi->vfs_inode);
-	spin_unlock(&sbi->dir_inode_lock);
+	spin_unlock(&sbi->inode_lock[type]);
 	if (inode) {
 		filemap_fdatawrite(inode->i_mapping);
 		iput(inode);
@@ -854,7 +854,7 @@ static int block_operations(struct f2fs_sb_info *sbi)
 	/* write all the dirty dentry pages */
 	if (get_pages(sbi, F2FS_DIRTY_DENTS)) {
 		f2fs_unlock_all(sbi);
-		sync_dirty_dir_inodes(sbi);
+		sync_dirty_inodes(sbi, DIR_INODE);
 		if (unlikely(f2fs_cp_error(sbi))) {
 			err = -EIO;
 			goto out;

commit 55d1cdb25a815ba92a917ae579c27cc3ffb9a57d
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Dec 15 16:07:14 2015 -0800

    f2fs: relocate tracepoint of write_checkpoint
    
    It needs to relocate its location to see exact trace logs.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index a4392f06f733..5008b872f316 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1130,9 +1130,9 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* do checkpoint periodically */
 	sbi->cp_expires = round_jiffies_up(jiffies + HZ * sbi->cp_interval);
+	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish checkpoint");
 out:
 	mutex_unlock(&sbi->cp_mutex);
-	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish checkpoint");
 }
 
 void init_ino_entry_info(struct f2fs_sb_info *sbi)

commit 6ad7609a183a250f1a346c7edfcbeaa30a29cfcc
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Dec 15 13:31:40 2015 +0800

    f2fs: introduce __remove_dirty_inode
    
    Introduce __remove_dirty_inode to clean up codes in remove_dirty_dir_inode.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 1aca402cab9c..a4392f06f733 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -736,6 +736,20 @@ static void __add_dirty_inode(struct inode *inode)
 	return;
 }
 
+static void __remove_dirty_inode(struct inode *inode)
+{
+	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
+	struct f2fs_inode_info *fi = F2FS_I(inode);
+
+	if (get_dirty_pages(inode) ||
+			!is_inode_flag_set(F2FS_I(inode), FI_DIRTY_DIR))
+		return;
+
+	list_del_init(&fi->dirty_list);
+	clear_inode_flag(fi, FI_DIRTY_DIR);
+	stat_dec_dirty_dir(sbi);
+}
+
 void update_dirty_page(struct inode *inode, struct page *page)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
@@ -777,15 +791,7 @@ void remove_dirty_dir_inode(struct inode *inode)
 		return;
 
 	spin_lock(&sbi->dir_inode_lock);
-	if (get_dirty_pages(inode) ||
-			!is_inode_flag_set(F2FS_I(inode), FI_DIRTY_DIR)) {
-		spin_unlock(&sbi->dir_inode_lock);
-		return;
-	}
-
-	list_del_init(&fi->dirty_list);
-	clear_inode_flag(fi, FI_DIRTY_DIR);
-	stat_dec_dirty_dir(sbi);
+	__remove_dirty_inode(inode);
 	spin_unlock(&sbi->dir_inode_lock);
 
 	/* Only from the recovery routine */

commit 2710fd7e00b4f77dbe807efaf546bed00b62e65e
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Dec 15 13:30:45 2015 +0800

    f2fs: introduce dirty list node in inode info
    
    Add a new dirt list node member in inode info for linking the inode to
    global dirty list in superblock, instead of old implementation which
    allocate slab cache memory as an entry to inode.
    
    It avoids memory pressure due to slab cache allocation, and also makes
    codes more clean.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b839f5f3385c..1aca402cab9c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -722,25 +722,23 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	return -EINVAL;
 }
 
-static int __add_dirty_inode(struct inode *inode, struct inode_entry *new)
+static void __add_dirty_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
+	struct f2fs_inode_info *fi = F2FS_I(inode);
 
-	if (is_inode_flag_set(F2FS_I(inode), FI_DIRTY_DIR))
-		return -EEXIST;
+	if (is_inode_flag_set(fi, FI_DIRTY_DIR))
+		return;
 
-	set_inode_flag(F2FS_I(inode), FI_DIRTY_DIR);
-	F2FS_I(inode)->dirty_dir = new;
-	list_add_tail(&new->list, &sbi->dir_inode_list);
+	set_inode_flag(fi, FI_DIRTY_DIR);
+	list_add_tail(&fi->dirty_list, &sbi->dir_inode_list);
 	stat_inc_dirty_dir(sbi);
-	return 0;
+	return;
 }
 
 void update_dirty_page(struct inode *inode, struct page *page)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
-	struct inode_entry *new;
-	int ret = 0;
 
 	if (!S_ISDIR(inode->i_mode) && !S_ISREG(inode->i_mode) &&
 			!S_ISLNK(inode->i_mode))
@@ -751,17 +749,11 @@ void update_dirty_page(struct inode *inode, struct page *page)
 		goto out;
 	}
 
-	new = f2fs_kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
-	new->inode = inode;
-	INIT_LIST_HEAD(&new->list);
-
 	spin_lock(&sbi->dir_inode_lock);
-	ret = __add_dirty_inode(inode, new);
+	__add_dirty_inode(inode);
 	inode_inc_dirty_pages(inode);
 	spin_unlock(&sbi->dir_inode_lock);
 
-	if (ret)
-		kmem_cache_free(inode_entry_slab, new);
 out:
 	SetPagePrivate(page);
 	f2fs_trace_pid(page);
@@ -770,25 +762,16 @@ void update_dirty_page(struct inode *inode, struct page *page)
 void add_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
-	struct inode_entry *new =
-			f2fs_kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
-	int ret = 0;
-
-	new->inode = inode;
-	INIT_LIST_HEAD(&new->list);
 
 	spin_lock(&sbi->dir_inode_lock);
-	ret = __add_dirty_inode(inode, new);
+	__add_dirty_inode(inode);
 	spin_unlock(&sbi->dir_inode_lock);
-
-	if (ret)
-		kmem_cache_free(inode_entry_slab, new);
 }
 
 void remove_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
-	struct inode_entry *entry;
+	struct f2fs_inode_info *fi = F2FS_I(inode);
 
 	if (!S_ISDIR(inode->i_mode))
 		return;
@@ -800,17 +783,14 @@ void remove_dirty_dir_inode(struct inode *inode)
 		return;
 	}
 
-	entry = F2FS_I(inode)->dirty_dir;
-	list_del(&entry->list);
-	F2FS_I(inode)->dirty_dir = NULL;
-	clear_inode_flag(F2FS_I(inode), FI_DIRTY_DIR);
+	list_del_init(&fi->dirty_list);
+	clear_inode_flag(fi, FI_DIRTY_DIR);
 	stat_dec_dirty_dir(sbi);
 	spin_unlock(&sbi->dir_inode_lock);
-	kmem_cache_free(inode_entry_slab, entry);
 
 	/* Only from the recovery routine */
-	if (is_inode_flag_set(F2FS_I(inode), FI_DELAY_IPUT)) {
-		clear_inode_flag(F2FS_I(inode), FI_DELAY_IPUT);
+	if (is_inode_flag_set(fi, FI_DELAY_IPUT)) {
+		clear_inode_flag(fi, FI_DELAY_IPUT);
 		iput(inode);
 	}
 }
@@ -818,8 +798,8 @@ void remove_dirty_dir_inode(struct inode *inode)
 void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 {
 	struct list_head *head;
-	struct inode_entry *entry;
 	struct inode *inode;
+	struct f2fs_inode_info *fi;
 retry:
 	if (unlikely(f2fs_cp_error(sbi)))
 		return;
@@ -831,8 +811,8 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 		spin_unlock(&sbi->dir_inode_lock);
 		return;
 	}
-	entry = list_entry(head->next, struct inode_entry, list);
-	inode = igrab(entry->inode);
+	fi = list_entry(head->next, struct f2fs_inode_info, dirty_list);
+	inode = igrab(&fi->vfs_inode);
 	spin_unlock(&sbi->dir_inode_lock);
 	if (inode) {
 		filemap_fdatawrite(inode->i_mapping);

commit a49324f127dec918f5a3b3f145d0bf2fb81f4588
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Dec 15 13:29:47 2015 +0800

    f2fs: rename {add,remove,release}_dirty_inode to {add,remove,release}_ino_entry
    
    remove_dirty_dir_inode will be renamed to remove_dirty_inode as a generic
    function in following patch for removing directory/regular/symlink inode
    in global dirty list.
    
    Here rename ino management related functions for readability, also in
    order to avoid name conflict.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f661d80474be..b839f5f3385c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -410,13 +410,13 @@ static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 	spin_unlock(&im->ino_lock);
 }
 
-void add_dirty_inode(struct f2fs_sb_info *sbi, nid_t ino, int type)
+void add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
 	/* add new dirty ino entry into list */
 	__add_ino_entry(sbi, ino, type);
 }
 
-void remove_dirty_inode(struct f2fs_sb_info *sbi, nid_t ino, int type)
+void remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
 	/* remove dirty ino entry from list */
 	__remove_ino_entry(sbi, ino, type);
@@ -434,7 +434,7 @@ bool exist_written_data(struct f2fs_sb_info *sbi, nid_t ino, int mode)
 	return e ? true : false;
 }
 
-void release_dirty_inode(struct f2fs_sb_info *sbi)
+void release_ino_entry(struct f2fs_sb_info *sbi)
 {
 	struct ino_entry *e, *tmp;
 	int i;
@@ -1081,7 +1081,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		invalidate_mapping_pages(META_MAPPING(sbi), discard_blk,
 								discard_blk);
 
-	release_dirty_inode(sbi);
+	release_ino_entry(sbi);
 
 	if (unlikely(f2fs_cp_error(sbi)))
 		return;

commit 26879fb101f28c554294eaf25ac7817a2825b180
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Oct 12 17:05:59 2015 +0800

    f2fs: support lower priority asynchronous readahead in ra_meta_pages
    
    Now, we use ra_meta_pages to reads continuous physical blocks as much as
    possible to improve performance of following reads. However, ra_meta_pages
    uses a synchronous readahead approach by submitting bio with READ, as READ
    is with high priority, it can not be used in the case of preloading blocks,
    and it's not sure when these RAed pages will be used.
    
    This patch supports asynchronous readahead in ra_meta_pages by tagging bio
    with READA flag in order to allow preloading.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 60a95992384f..f661d80474be 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -140,7 +140,8 @@ bool is_valid_blkaddr(struct f2fs_sb_info *sbi, block_t blkaddr, int type)
 /*
  * Readahead CP/NAT/SIT/SSA pages
  */
-int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type)
+int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages,
+							int type, bool sync)
 {
 	block_t prev_blk_addr = 0;
 	struct page *page;
@@ -148,7 +149,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 	struct f2fs_io_info fio = {
 		.sbi = sbi,
 		.type = META,
-		.rw = READ_SYNC | REQ_META | REQ_PRIO,
+		.rw = sync ? (READ_SYNC | REQ_META | REQ_PRIO) : READA,
 		.encrypted_page = NULL,
 	};
 
@@ -214,7 +215,7 @@ void ra_meta_pages_cond(struct f2fs_sb_info *sbi, pgoff_t index)
 	f2fs_put_page(page, 0);
 
 	if (readahead)
-		ra_meta_pages(sbi, index, MAX_BIO_BLOCKS(sbi), META_POR);
+		ra_meta_pages(sbi, index, MAX_BIO_BLOCKS(sbi), META_POR, true);
 }
 
 static int f2fs_write_meta_page(struct page *page,
@@ -521,7 +522,7 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	start_blk = __start_cp_addr(sbi) + 1 + __cp_payload(sbi);
 	orphan_blocks = __start_sum_addr(sbi) - 1 - __cp_payload(sbi);
 
-	ra_meta_pages(sbi, start_blk, orphan_blocks, META_CP);
+	ra_meta_pages(sbi, start_blk, orphan_blocks, META_CP, true);
 
 	for (i = 0; i < orphan_blocks; i++) {
 		struct page *page = get_meta_page(sbi, start_blk + i);

commit 2b947003fa98d5a39f3b21214380d0b1daf750b5
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Oct 12 17:04:21 2015 +0800

    f2fs: don't tag REQ_META for temporary non-meta pages
    
    In recovery or checkpoint flow, we grab pages temperarily in meta inode's
    mapping for caching temperary data, actually, datas in these pages were
    not meta data of f2fs, but still we tag them with REQ_META flag. However,
    lower device like eMMC may do some optimization for data of such type.
    So in order to avoid wrong optimization, we'd better remove such flag
    for temperary non-meta pages.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0a9ec4228342..60a95992384f 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -47,7 +47,8 @@ struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 /*
  * We guarantee no failure on the returned page.
  */
-struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
+static struct page *__get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index,
+							bool is_meta)
 {
 	struct address_space *mapping = META_MAPPING(sbi);
 	struct page *page;
@@ -58,6 +59,9 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		.blk_addr = index,
 		.encrypted_page = NULL,
 	};
+
+	if (unlikely(!is_meta))
+		fio.rw &= ~REQ_META;
 repeat:
 	page = grab_cache_page(mapping, index);
 	if (!page) {
@@ -91,6 +95,17 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return page;
 }
 
+struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
+{
+	return __get_meta_page(sbi, index, true);
+}
+
+/* for POR only */
+struct page *get_tmp_page(struct f2fs_sb_info *sbi, pgoff_t index)
+{
+	return __get_meta_page(sbi, index, false);
+}
+
 bool is_valid_blkaddr(struct f2fs_sb_info *sbi, block_t blkaddr, int type)
 {
 	switch (type) {
@@ -137,6 +152,9 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 		.encrypted_page = NULL,
 	};
 
+	if (unlikely(type == META_POR))
+		fio.rw &= ~REQ_META;
+
 	for (; nrpages-- > 0; blkno++) {
 
 		if (!is_valid_blkaddr(sbi, blkno, type))

commit 6066d8cdb6dd0fd51ccd96027f6ae8e6b3b5adff
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Oct 1 16:42:55 2015 -0700

    f2fs: merge meta writes as many possible
    
    This patch tries to merge IOs as many as possible when background flusher
    conducts flushing the dirty meta pages.
    
    [Before]
    
    ...
    2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 124320, size = 4096
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 124560, size = 32768
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 95720, size = 987136
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 123928, size = 4096
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 123944, size = 8192
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 123968, size = 45056
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 124064, size = 4096
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 97648, size = 1007616
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 123776, size = 8192
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 123800, size = 32768
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 124624, size = 4096
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 99616, size = 921600
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 123608, size = 4096
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 123624, size = 77824
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 123792, size = 4096
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 123864, size = 32768
    ...
    
    [After]
    
    ...
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 92168, size = 892928
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 93912, size = 753664
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 95384, size = 716800
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 96784, size = 712704
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 104160, size = 364544
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 104872, size = 356352
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 105568, size = 278528
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 106112, size = 319488
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 106736, size = 258048
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 107240, size = 270336
    f2fs_submit_write_bio: dev = (8,18), WRITE_SYNC(MP), META, sector = 107768, size = 180224
    ...
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0569097dbd7a..0a9ec4228342 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -257,7 +257,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 						long nr_to_write)
 {
 	struct address_space *mapping = META_MAPPING(sbi);
-	pgoff_t index = 0, end = LONG_MAX;
+	pgoff_t index = 0, end = LONG_MAX, prev = LONG_MAX;
 	struct pagevec pvec;
 	long nwritten = 0;
 	struct writeback_control wbc = {
@@ -277,6 +277,13 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 		for (i = 0; i < nr_pages; i++) {
 			struct page *page = pvec.pages[i];
 
+			if (prev == LONG_MAX)
+				prev = page->index - 1;
+			if (nr_to_write != LONG_MAX && page->index != prev + 1) {
+				pagevec_release(&pvec);
+				goto stop;
+			}
+
 			lock_page(page);
 
 			if (unlikely(page->mapping != mapping)) {
@@ -297,13 +304,14 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 				break;
 			}
 			nwritten++;
+			prev = page->index;
 			if (unlikely(nwritten >= nr_to_write))
 				break;
 		}
 		pagevec_release(&pvec);
 		cond_resched();
 	}
-
+stop:
 	if (nwritten)
 		f2fs_submit_merged_bio(sbi, type, WRITE);
 

commit 60b99b486b568c13cbb7caa83cf8a12af7665f1e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Oct 5 14:49:57 2015 -0700

    f2fs: introduce a periodic checkpoint flow
    
    This patch introduces a periodic checkpoint feature.
    Note that, this is not enforcing to conduct checkpoints very strictly in terms
    of trigger timing, instead just hope to help user experiences.
    The default value is 60 seconds.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ff53405aee39..0569097dbd7a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1114,6 +1114,9 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (cpc->reason == CP_RECOVERY)
 		f2fs_msg(sbi->sb, KERN_NOTICE,
 			"checkpoint: version = %llx", ckpt_ver);
+
+	/* do checkpoint periodically */
+	sbi->cp_expires = round_jiffies_up(jiffies + HZ * sbi->cp_interval);
 out:
 	mutex_unlock(&sbi->cp_mutex);
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish checkpoint");

commit a7230d16d5f8635dbc029af057969e46e3eb2246
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Sep 16 14:06:54 2015 -0700

    f2fs: check end_io for metapages before making next checkpoint blocks
    
    This patch avoids to produce new checkpoint blocks before the previous meta
    pages were written completely.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c5a38e352a80..ff53405aee39 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1000,6 +1000,11 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	start_blk = __start_cp_addr(sbi);
 
+	/* need to wait for end_io results */
+	wait_on_all_pages_writeback(sbi);
+	if (unlikely(f2fs_cp_error(sbi)))
+		return;
+
 	/* write out checkpoint buffer at block 0 */
 	update_meta_page(sbi, ckpt, start_blk++);
 

commit 80c545055dc7c1f7f487176fe0aac17896a4b7af
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Aug 20 08:51:56 2015 -0700

    f2fs: use __GFP_NOFAIL to avoid infinite loop
    
    __GFP_NOFAIL can avoid retrying the whole path of kmem_cache_alloc and
    bio_alloc.
    And, it also fixes the use cases of GFP_ATOMIC correctly.
    
    Suggested-by: Chao Yu <chao2.yu@samsung.com>
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 890e4d4c39d7..c5a38e352a80 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -336,26 +336,18 @@ const struct address_space_operations f2fs_meta_aops = {
 static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
 	struct inode_management *im = &sbi->im[type];
-	struct ino_entry *e;
+	struct ino_entry *e, *tmp;
+
+	tmp = f2fs_kmem_cache_alloc(ino_entry_slab, GFP_NOFS);
 retry:
-	if (radix_tree_preload(GFP_NOFS)) {
-		cond_resched();
-		goto retry;
-	}
+	radix_tree_preload(GFP_NOFS | __GFP_NOFAIL);
 
 	spin_lock(&im->ino_lock);
-
 	e = radix_tree_lookup(&im->ino_root, ino);
 	if (!e) {
-		e = kmem_cache_alloc(ino_entry_slab, GFP_ATOMIC);
-		if (!e) {
-			spin_unlock(&im->ino_lock);
-			radix_tree_preload_end();
-			goto retry;
-		}
+		e = tmp;
 		if (radix_tree_insert(&im->ino_root, ino, e)) {
 			spin_unlock(&im->ino_lock);
-			kmem_cache_free(ino_entry_slab, e);
 			radix_tree_preload_end();
 			goto retry;
 		}
@@ -368,6 +360,9 @@ static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 	}
 	spin_unlock(&im->ino_lock);
 	radix_tree_preload_end();
+
+	if (e != tmp)
+		kmem_cache_free(ino_entry_slab, tmp);
 }
 
 static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)

commit 315df8398e36360c0be62e6fdd3f2708fc3a2567
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Aug 11 12:45:39 2015 -0700

    f2fs: do not write any node pages related to orphan inodes
    
    We should not write node pages when deleting orphan inodes.
    In order to do that, we can eaisly set POR_DOING flag earlier before entering
    orphan inode routine.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0958c8399d8e..890e4d4c39d7 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -497,8 +497,6 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	if (!is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG))
 		return 0;
 
-	set_sbi_flag(sbi, SBI_POR_DOING);
-
 	start_blk = __start_cp_addr(sbi) + 1 + __cp_payload(sbi);
 	orphan_blocks = __start_sum_addr(sbi) - 1 - __cp_payload(sbi);
 
@@ -514,7 +512,6 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 			err = recover_orphan_inode(sbi, ino);
 			if (err) {
 				f2fs_put_page(page, 1);
-				clear_sbi_flag(sbi, SBI_POR_DOING);
 				return err;
 			}
 		}
@@ -522,7 +519,6 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	}
 	/* clear Orphan Flag */
 	clear_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG);
-	clear_sbi_flag(sbi, SBI_POR_DOING);
 	return 0;
 }
 

commit 8c14bfadeac2a01b305ef4434907295b81b58db2
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Fri Aug 7 17:58:43 2015 +0800

    f2fs: handle error of f2fs_iget correctly
    
    In recover_orphan_inode, whenever f2fs_iget fail, we will make kernel panic,
    but it's not reasonable, because f2fs_iget can fail due to a lot of reasons
    including out of memory.
    
    So we change error handling method as below:
    a) when finding no entry for the orphan inode, bug_on for catching bugs;
    b) for other reasons, report it to caller.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c3111769d382..0958c8399d8e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -468,22 +468,34 @@ void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	__remove_ino_entry(sbi, ino, ORPHAN_INO);
 }
 
-static void recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
+static int recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
-	struct inode *inode = f2fs_iget(sbi->sb, ino);
-	f2fs_bug_on(sbi, IS_ERR(inode));
+	struct inode *inode;
+
+	inode = f2fs_iget(sbi->sb, ino);
+	if (IS_ERR(inode)) {
+		/*
+		 * there should be a bug that we can't find the entry
+		 * to orphan inode.
+		 */
+		f2fs_bug_on(sbi, PTR_ERR(inode) == -ENOENT);
+		return PTR_ERR(inode);
+	}
+
 	clear_nlink(inode);
 
 	/* truncate all the data during iput */
 	iput(inode);
+	return 0;
 }
 
-void recover_orphan_inodes(struct f2fs_sb_info *sbi)
+int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 {
 	block_t start_blk, orphan_blocks, i, j;
+	int err;
 
 	if (!is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG))
-		return;
+		return 0;
 
 	set_sbi_flag(sbi, SBI_POR_DOING);
 
@@ -499,14 +511,19 @@ void recover_orphan_inodes(struct f2fs_sb_info *sbi)
 		orphan_blk = (struct f2fs_orphan_block *)page_address(page);
 		for (j = 0; j < le32_to_cpu(orphan_blk->entry_count); j++) {
 			nid_t ino = le32_to_cpu(orphan_blk->ino[j]);
-			recover_orphan_inode(sbi, ino);
+			err = recover_orphan_inode(sbi, ino);
+			if (err) {
+				f2fs_put_page(page, 1);
+				clear_sbi_flag(sbi, SBI_POR_DOING);
+				return err;
+			}
 		}
 		f2fs_put_page(page, 1);
 	}
 	/* clear Orphan Flag */
 	clear_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG);
 	clear_sbi_flag(sbi, SBI_POR_DOING);
-	return;
+	return 0;
 }
 
 static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)

commit e90c2d2850d9d034e814a328725a4b15878f0357
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Jul 28 18:36:47 2015 +0800

    f2fs: invalidate temporary meta page
    
    To avoid meeting garbage data in next free node block at the end of warm
    node chain when doing recovery, we will try to zero out that invalid block.
    
    If the device is not support discard, our way for zeroing out block is:
    grabbing a temporary zeroed page in meta inode, then, issue write request
    with this page.
    
    But, we forget to release that temporary page, so our memory usage will
    increase without gaining any hit ratio benefit, so it's better to free it
    for saving memory.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9c1acf69bfbb..c3111769d382 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -896,12 +896,15 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	__u32 crc32 = 0;
 	int i;
 	int cp_payload_blks = __cp_payload(sbi);
+	block_t discard_blk = NEXT_FREE_BLKADDR(sbi, curseg);
+	bool invalidate = false;
 
 	/*
 	 * This avoids to conduct wrong roll-forward operations and uses
 	 * metapages, so should be called prior to sync_meta_pages below.
 	 */
-	discard_next_dnode(sbi, NEXT_FREE_BLKADDR(sbi, curseg));
+	if (discard_next_dnode(sbi, discard_blk))
+		invalidate = true;
 
 	/* Flush all the NAT/SIT pages */
 	while (get_pages(sbi, F2FS_DIRTY_META)) {
@@ -1030,6 +1033,14 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* wait for previous submitted meta pages writeback */
 	wait_on_all_pages_writeback(sbi);
 
+	/*
+	 * invalidate meta page which is used temporarily for zeroing out
+	 * block at the end of warm node chain.
+	 */
+	if (invalidate)
+		invalidate_mapping_pages(META_MAPPING(sbi), discard_blk,
+								discard_blk);
+
 	release_dirty_inode(sbi);
 
 	if (unlikely(f2fs_cp_error(sbi)))

commit f3f338caad3428fbc4bb563828efc6ecce4d956b
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Jul 29 17:33:13 2015 +0800

    f2fs: freeze filesystem when fail to update meta page due to IO error
    
    In get_meta_page, we guarantee no failure for the returned page,
    but sometimes, IO error from device will incur returning an
    non-updated page.
    
    Then, we still use this page as updated one, exception could happen
    when using this kind of page.
    
    So in this condition, we'd better freeze fs by making fs readonly and
    and stop doing checkpoint.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6fb696da42e8..9c1acf69bfbb 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -79,6 +79,14 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		f2fs_put_page(page, 1);
 		goto repeat;
 	}
+
+	/*
+	 * if there is any IO error when accessing device, make our filesystem
+	 * readonly and make sure do not write checkpoint with non-uptodate
+	 * meta page.
+	 */
+	if (unlikely(!PageUptodate(page)))
+		f2fs_stop_checkpoint(sbi);
 out:
 	return page;
 }

commit 86531d6b84bc096d5d9dbc23333df0ab8d347763
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Jul 15 13:08:21 2015 -0700

    f2fs: callers take care of the page from bio error
    
    This patch changes for a caller to handle the page after its bio gets an error.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 60327027137f..6fb696da42e8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -69,8 +69,10 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 
 	fio.page = page;
 
-	if (f2fs_submit_page_bio(&fio))
+	if (f2fs_submit_page_bio(&fio)) {
+		f2fs_put_page(page, 1);
 		goto repeat;
+	}
 
 	lock_page(page);
 	if (unlikely(page->mapping != mapping)) {

commit bd936f840779366b61300c0f4f752dd1b52b1ca3
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Jul 13 17:44:25 2015 +0800

    f2fs: cleanup write_orphan_inodes
    
    Previously, since 'commit 4531929e3922 ("f2fs: move grabing orphan
    pages out of protection region")' was committed, in write_orphan_inodes(),
    we will grab all meta page in a batch before we use them under spinlock,
    so that we can avoid large time delay of grabbing meta pages under
    spinlock.
    
    Now, 'commit d6c67a4fee86 ("f2fs: revmove spin_lock for
    write_orphan_inodes")' remove the spinlock in write_orphan_inodes,
    so there is no issue we describe above, we'd better recover to move
    the grab operation to original place for readability.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index de7a0d6a371a..60327027137f 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -504,7 +504,7 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	struct list_head *head;
 	struct f2fs_orphan_block *orphan_blk = NULL;
 	unsigned int nentries = 0;
-	unsigned short index;
+	unsigned short index = 1;
 	unsigned short orphan_blocks;
 	struct page *page = NULL;
 	struct ino_entry *orphan = NULL;
@@ -512,11 +512,6 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 
 	orphan_blocks = GET_ORPHAN_BLOCKS(im->ino_num);
 
-	for (index = 0; index < orphan_blocks; index++)
-		grab_meta_page(sbi, start_blk + index);
-
-	index = 1;
-
 	/*
 	 * we don't need to do spin_lock(&im->ino_lock) here, since all the
 	 * orphan inode operations are covered under f2fs_lock_op().
@@ -527,12 +522,10 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	/* loop for each orphan inode entry and write them in Jornal block */
 	list_for_each_entry(orphan, head, list) {
 		if (!page) {
-			page = find_get_page(META_MAPPING(sbi), start_blk++);
-			f2fs_bug_on(sbi, !page);
+			page = grab_meta_page(sbi, start_blk++);
 			orphan_blk =
 				(struct f2fs_orphan_block *)page_address(page);
 			memset(orphan_blk, 0, sizeof(*orphan_blk));
-			f2fs_put_page(page, 0);
 		}
 
 		orphan_blk->ino[nentries++] = cpu_to_le32(orphan->ino);

commit 5ac9f36fcacd532b218db1e0fd0f9e8a18321f22
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Jun 29 18:14:10 2015 +0800

    f2fs: fix to record dirty page count for symlink
    
    Dirty page can be exist in mapping of newly created symlink, but previously
    we did not maintain the counting of dirty page for symlink like we maintained
    for regular/directory, so the counting we lookuped should be wrong.
    
    This patch adds missed dirty page counting for symlink to fix this issue.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b70bbe1a6a8c..de7a0d6a371a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -704,7 +704,8 @@ void update_dirty_page(struct inode *inode, struct page *page)
 	struct inode_entry *new;
 	int ret = 0;
 
-	if (!S_ISDIR(inode->i_mode) && !S_ISREG(inode->i_mode))
+	if (!S_ISDIR(inode->i_mode) && !S_ISREG(inode->i_mode) &&
+			!S_ISLNK(inode->i_mode))
 		return;
 
 	if (!S_ISDIR(inode->i_mode)) {

commit 381722d2ac0314f65fd98db9a0eb8bdd1d984925
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue May 19 17:40:04 2015 +0800

    f2fs: introduce update_meta_page
    
    Add a help function update_meta_page() to update meta page with specified
    buffer.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7b7a9d8bd6ca..b70bbe1a6a8c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -888,10 +888,8 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	unsigned long orphan_num = sbi->im[ORPHAN_INO].ino_num;
 	nid_t last_nid = nm_i->next_scan_nid;
 	block_t start_blk;
-	struct page *cp_page;
 	unsigned int data_sum_blocks, orphan_blocks;
 	__u32 crc32 = 0;
-	void *kaddr;
 	int i;
 	int cp_payload_blks = __cp_payload(sbi);
 
@@ -988,19 +986,11 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	start_blk = __start_cp_addr(sbi);
 
 	/* write out checkpoint buffer at block 0 */
-	cp_page = grab_meta_page(sbi, start_blk++);
-	kaddr = page_address(cp_page);
-	memcpy(kaddr, ckpt, F2FS_BLKSIZE);
-	set_page_dirty(cp_page);
-	f2fs_put_page(cp_page, 1);
-
-	for (i = 1; i < 1 + cp_payload_blks; i++) {
-		cp_page = grab_meta_page(sbi, start_blk++);
-		kaddr = page_address(cp_page);
-		memcpy(kaddr, (char *)ckpt + i * F2FS_BLKSIZE, F2FS_BLKSIZE);
-		set_page_dirty(cp_page);
-		f2fs_put_page(cp_page, 1);
-	}
+	update_meta_page(sbi, ckpt, start_blk++);
+
+	for (i = 1; i < 1 + cp_payload_blks; i++)
+		update_meta_page(sbi, (char *)ckpt + i * F2FS_BLKSIZE,
+							start_blk++);
 
 	if (orphan_num) {
 		write_orphan_inodes(sbi, start_blk);
@@ -1015,11 +1005,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	}
 
 	/* writeout checkpoint block */
-	cp_page = grab_meta_page(sbi, start_blk);
-	kaddr = page_address(cp_page);
-	memcpy(kaddr, ckpt, F2FS_BLKSIZE);
-	set_page_dirty(cp_page);
-	f2fs_put_page(cp_page, 1);
+	update_meta_page(sbi, ckpt, start_blk);
 
 	/* wait for previous submitted node/meta pages writeback */
 	wait_on_all_pages_writeback(sbi);

commit 4375a33664de17af9032b5f491a49bd256670927
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Apr 23 12:04:33 2015 -0700

    f2fs crypto: add encryption support in read/write paths
    
    This patch adds encryption support in read and write paths.
    
    Note that, in f2fs, we need to consider cleaning operation.
    In cleaning procedure, we must avoid encrypting and decrypting written blocks.
    So, this patch implements move_encrypted_block().
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index a61d4b06e05a..7b7a9d8bd6ca 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -56,6 +56,7 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		.type = META,
 		.rw = READ_SYNC | REQ_META | REQ_PRIO,
 		.blk_addr = index,
+		.encrypted_page = NULL,
 	};
 repeat:
 	page = grab_cache_page(mapping, index);
@@ -122,7 +123,8 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 	struct f2fs_io_info fio = {
 		.sbi = sbi,
 		.type = META,
-		.rw = READ_SYNC | REQ_META | REQ_PRIO
+		.rw = READ_SYNC | REQ_META | REQ_PRIO,
+		.encrypted_page = NULL,
 	};
 
 	for (; nrpages-- > 0; blkno++) {

commit 836b5a6356ac49a4631c06bc87b0ea02f41623ca
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Apr 30 22:50:06 2015 -0700

    f2fs: issue discard with finally produced len and minlen
    
    This patch determines to issue discard commands by comparing given minlen and
    the length of produced final candidates.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 55b65e52aaea..a61d4b06e05a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1043,7 +1043,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	if (unlikely(f2fs_cp_error(sbi)))
 		return;
 
-	clear_prefree_segments(sbi);
+	clear_prefree_segments(sbi, cpc);
 	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 }
 

commit a66cdd985532e69999b79249cd3b4a6bccd0f84b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Apr 30 22:37:50 2015 -0700

    f2fs: introduce discard_map for f2fs_trim_fs
    
    This patch adds a bitmap for discard issues from f2fs_trim_fs.
    There-in rule is to issue discard commands only for invalidated blocks
    after mount.
    Once mount is done, f2fs_trim_fs trims out whole invalid area.
    After ehn, it will not issue and discrads redundantly.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d076e7efb25d..55b65e52aaea 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1058,7 +1058,8 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	mutex_lock(&sbi->cp_mutex);
 
 	if (!is_sbi_flag_set(sbi, SBI_IS_DIRTY) &&
-		(cpc->reason == CP_FASTBOOT || cpc->reason == CP_SYNC))
+		(cpc->reason == CP_FASTBOOT || cpc->reason == CP_SYNC ||
+		(cpc->reason == CP_DISCARD && !sbi->discard_blks)))
 		goto out;
 	if (unlikely(f2fs_cp_error(sbi)))
 		goto out;

commit d6c67a4fee866ad95fe1d727f80a56f956737706
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri May 1 11:08:59 2015 -0700

    f2fs: revmove spin_lock for write_orphan_inodes
    
    This patch removes spin_lock, since this is covered by f2fs_lock_op already.
    And, we should avoid to use page operations inside spin_lock.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6dbff2b0bcd8..d076e7efb25d 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -514,7 +514,12 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 		grab_meta_page(sbi, start_blk + index);
 
 	index = 1;
-	spin_lock(&im->ino_lock);
+
+	/*
+	 * we don't need to do spin_lock(&im->ino_lock) here, since all the
+	 * orphan inode operations are covered under f2fs_lock_op().
+	 * And, spin_lock should be avoided due to page operations below.
+	 */
 	head = &im->ino_list;
 
 	/* loop for each orphan inode entry and write them in Jornal block */
@@ -554,8 +559,6 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 		set_page_dirty(page);
 		f2fs_put_page(page, 1);
 	}
-
-	spin_unlock(&im->ino_lock);
 }
 
 static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,

commit 05ca3632e5a73b493b27ec3e2a337885563abff0
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Apr 23 14:38:15 2015 -0700

    f2fs: add sbi and page pointer in f2fs_io_info
    
    This patch adds f2fs_sb_info and page pointers in f2fs_io_info structure.
    With this change, we can reduce a lot of parameters for IO functions.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 72f64b314d2e..6dbff2b0bcd8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -52,6 +52,7 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	struct address_space *mapping = META_MAPPING(sbi);
 	struct page *page;
 	struct f2fs_io_info fio = {
+		.sbi = sbi,
 		.type = META,
 		.rw = READ_SYNC | REQ_META | REQ_PRIO,
 		.blk_addr = index,
@@ -65,7 +66,9 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	if (PageUptodate(page))
 		goto out;
 
-	if (f2fs_submit_page_bio(sbi, page, &fio))
+	fio.page = page;
+
+	if (f2fs_submit_page_bio(&fio))
 		goto repeat;
 
 	lock_page(page);
@@ -117,6 +120,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 	struct page *page;
 	block_t blkno = start;
 	struct f2fs_io_info fio = {
+		.sbi = sbi,
 		.type = META,
 		.rw = READ_SYNC | REQ_META | REQ_PRIO
 	};
@@ -160,7 +164,8 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 			continue;
 		}
 
-		f2fs_submit_page_mbio(sbi, page, &fio);
+		fio.page = page;
+		f2fs_submit_page_mbio(&fio);
 		f2fs_put_page(page, 0);
 	}
 out:

commit f0c9cadae6706b6ce00ef724121fbf0f34187e22
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sat Apr 18 18:05:36 2015 +0800

    f2fs: use is_valid_blkaddr to verify blkaddr for readability
    
    Export is_valid_blkaddr() and use it to replace some codes for readability.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index a5e17a2a0781..72f64b314d2e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -77,8 +77,7 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return page;
 }
 
-static inline bool is_valid_blkaddr(struct f2fs_sb_info *sbi,
-						block_t blkaddr, int type)
+bool is_valid_blkaddr(struct f2fs_sb_info *sbi, block_t blkaddr, int type)
 {
 	switch (type) {
 	case META_NAT:

commit 10027551ccf5459cc771c31ac8bc8e5cc8db45f8
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Apr 9 17:03:53 2015 -0700

    f2fs: pass checkpoint reason on roll-forward recovery
    
    This patch adds CP_RECOVERY to remain recovery information for checkpoint.
    And, it makes sure writing checkpoint in this case.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 384bfc4c36c3..a5e17a2a0781 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1051,7 +1051,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	mutex_lock(&sbi->cp_mutex);
 
 	if (!is_sbi_flag_set(sbi, SBI_IS_DIRTY) &&
-			cpc->reason != CP_DISCARD && cpc->reason != CP_UMOUNT)
+		(cpc->reason == CP_FASTBOOT || cpc->reason == CP_SYNC))
 		goto out;
 	if (unlikely(f2fs_cp_error(sbi)))
 		goto out;
@@ -1086,6 +1086,10 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	unblock_operations(sbi);
 	stat_inc_cp_count(sbi->stat_info);
+
+	if (cpc->reason == CP_RECOVERY)
+		f2fs_msg(sbi->sb, KERN_NOTICE,
+			"checkpoint: version = %llx", ckpt_ver);
 out:
 	mutex_unlock(&sbi->cp_mutex);
 	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish checkpoint");

commit e0150392ddfaaf5ccf338893f6db177a2c64a7ee
Author: Changman Lee <cm224.lee@samsung.com>
Date:   Mon Mar 9 08:07:04 2015 +0900

    f2fs: cleanup statement about max orphan inodes calc
    
    Through each macro, we can read the meaning easily.
    
    Signed-off-by: Changman Lee <cm224.lee@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 53bc32804841..384bfc4c36c3 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1104,13 +1104,6 @@ void init_ino_entry_info(struct f2fs_sb_info *sbi)
 		im->ino_num = 0;
 	}
 
-	/*
-	 * considering 512 blocks in a segment 8+cp_payload blocks are
-	 * needed for cp and log segment summaries. Remaining blocks are
-	 * used to keep orphan entries with the limitation one reserved
-	 * segment for cp pack we can have max 1020*(504-cp_payload)
-	 * orphan entries
-	 */
 	sbi->max_orphans = (sbi->blocks_per_seg - F2FS_CP_PACKS -
 			NR_CURSEG_TYPE - __cp_payload(sbi)) *
 				F2FS_ORPHANS_PER_BLOCK;

commit 7ecebe5e07958a0b7e54a560dbc24144287c6b41
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Fri Feb 27 13:13:14 2015 +0100

    f2fs: add cond_resched() to sync_dirty_dir_inodes()
    
    In a preempt-off enviroment a alot of FS activity (write/delete) I run
    into a CPU stall:
    
    | NMI watchdog: BUG: soft lockup - CPU#0 stuck for 22s! [kworker/u2:2:59]
    | Modules linked in:
    | CPU: 0 PID: 59 Comm: kworker/u2:2 Tainted: G        W      3.19.0-00010-g10c11c51ffed #153
    | Workqueue: writeback bdi_writeback_workfn (flush-179:0)
    | task: df230000 ti: df23e000 task.ti: df23e000
    | PC is at __submit_merged_bio+0x6c/0x110
    | LR is at f2fs_submit_merged_bio+0x74/0x80
    …
    | [<c00085c4>] (gic_handle_irq) from [<c0012e84>] (__irq_svc+0x44/0x5c)
    | Exception stack(0xdf23fb48 to 0xdf23fb90)
    | fb40:                   deef3484 ffff0001 ffff0001 00000027 deef3484 00000000
    | fb60: deef3440 00000000 de426000 deef34ec deefc440 df23fbb4 df23fbb8 df23fb90
    | fb80: c02191f0 c0218fa0 60000013 ffffffff
    | [<c0012e84>] (__irq_svc) from [<c0218fa0>] (__submit_merged_bio+0x6c/0x110)
    | [<c0218fa0>] (__submit_merged_bio) from [<c02191f0>] (f2fs_submit_merged_bio+0x74/0x80)
    | [<c02191f0>] (f2fs_submit_merged_bio) from [<c021624c>] (sync_dirty_dir_inodes+0x70/0x78)
    | [<c021624c>] (sync_dirty_dir_inodes) from [<c0216358>] (write_checkpoint+0x104/0xc10)
    | [<c0216358>] (write_checkpoint) from [<c021231c>] (f2fs_sync_fs+0x80/0xbc)
    | [<c021231c>] (f2fs_sync_fs) from [<c0221eb8>] (f2fs_balance_fs_bg+0x4c/0x68)
    | [<c0221eb8>] (f2fs_balance_fs_bg) from [<c021e9b8>] (f2fs_write_node_pages+0x40/0x110)
    | [<c021e9b8>] (f2fs_write_node_pages) from [<c00de620>] (do_writepages+0x34/0x48)
    | [<c00de620>] (do_writepages) from [<c0145714>] (__writeback_single_inode+0x50/0x228)
    | [<c0145714>] (__writeback_single_inode) from [<c0146184>] (writeback_sb_inodes+0x1a8/0x378)
    | [<c0146184>] (writeback_sb_inodes) from [<c01463e4>] (__writeback_inodes_wb+0x90/0xc8)
    | [<c01463e4>] (__writeback_inodes_wb) from [<c01465f8>] (wb_writeback+0x1dc/0x28c)
    | [<c01465f8>] (wb_writeback) from [<c0146dd8>] (bdi_writeback_workfn+0x2ac/0x460)
    | [<c0146dd8>] (bdi_writeback_workfn) from [<c003c3fc>] (process_one_work+0x11c/0x3a4)
    | [<c003c3fc>] (process_one_work) from [<c003c844>] (worker_thread+0x17c/0x490)
    | [<c003c844>] (worker_thread) from [<c0041398>] (kthread+0xec/0x100)
    | [<c0041398>] (kthread) from [<c000ed10>] (ret_from_fork+0x14/0x24)
    
    As it turns out, the code loops in sync_dirty_dir_inodes() and waits for
    others to make progress but since it never leaves the CPU there is no
    progress made. At the time of this stall, there is also a rm process
    blocked:
    | rm              R running      0  1989   1774 0x00000000
    | [<c047c55c>] (__schedule) from [<c00486dc>] (__cond_resched+0x30/0x4c)
    | [<c00486dc>] (__cond_resched) from [<c047c8c8>] (_cond_resched+0x4c/0x54)
    | [<c047c8c8>] (_cond_resched) from [<c00e1aec>] (truncate_inode_pages_range+0x1f0/0x5e8)
    | [<c00e1aec>] (truncate_inode_pages_range) from [<c00e1fd8>] (truncate_inode_pages+0x28/0x30)
    | [<c00e1fd8>] (truncate_inode_pages) from [<c00e2148>] (truncate_inode_pages_final+0x60/0x64)
    | [<c00e2148>] (truncate_inode_pages_final) from [<c020c92c>] (f2fs_evict_inode+0x4c/0x268)
    | [<c020c92c>] (f2fs_evict_inode) from [<c0137214>] (evict+0x94/0x140)
    | [<c0137214>] (evict) from [<c01377e8>] (iput+0xc8/0x134)
    | [<c01377e8>] (iput) from [<c01333e4>] (d_delete+0x154/0x180)
    | [<c01333e4>] (d_delete) from [<c0129870>] (vfs_rmdir+0x114/0x12c)
    | [<c0129870>] (vfs_rmdir) from [<c012d644>] (do_rmdir+0x158/0x168)
    | [<c012d644>] (do_rmdir) from [<c012dd90>] (SyS_unlinkat+0x30/0x3c)
    | [<c012dd90>] (SyS_unlinkat) from [<c000ec40>] (ret_fast_syscall+0x0/0x4c)
    
    As explained by Jaegeuk Kim:
    |This inode is the directory (c.f., do_rmdir) causing a infinite loop on
    |sync_dirty_dir_inodes.
    |The sync_dirty_dir_inodes tries to flush dirty dentry pages, but if the
    |inode is under eviction, it submits bios and do it again until eviction
    |is finished.
    
    This patch adds a cond_resched() (as suggested by Jaegeuk) after a BIO
    is submitted so other thread can make progress.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    [Jaegeuk Kim: change fs/f2fs to f2fs in subject as naming convention]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 81d6d2f0e8ed..53bc32804841 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -795,6 +795,7 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 		 * wribacking dentry pages in the freeing inode.
 		 */
 		f2fs_submit_merged_bio(sbi, DATA, WRITE);
+		cond_resched();
 	}
 	goto retry;
 }

commit 14b42817763903070fa8cbf087369461400cc021
Author: Wanpeng Li <wanpeng.li@linux.intel.com>
Date:   Fri Feb 27 17:38:13 2015 +0800

    f2fs: fix max orphan inodes calculation
    
    cp_payload is introduced for sit bitmap to support large volume, and it is
    just after the block of f2fs_checkpoint + nat bitmap, so the first segment
    should include F2FS_CP_PACKS + NR_CURSEG_TYPE + cp_payload + orphan blocks.
    However, current max orphan inodes calculation don't consider cp_payload,
    this patch fix it by reducing the number of cp_payload from total blocks of
    the first segment when calculate max orphan inodes.
    
    Signed-off-by: Wanpeng Li <wanpeng.li@linux.intel.com>
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index e9f30abbb6fe..81d6d2f0e8ed 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1104,13 +1104,15 @@ void init_ino_entry_info(struct f2fs_sb_info *sbi)
 	}
 
 	/*
-	 * considering 512 blocks in a segment 8 blocks are needed for cp
-	 * and log segment summaries. Remaining blocks are used to keep
-	 * orphan entries with the limitation one reserved segment
-	 * for cp pack we can have max 1020*504 orphan entries
+	 * considering 512 blocks in a segment 8+cp_payload blocks are
+	 * needed for cp and log segment summaries. Remaining blocks are
+	 * used to keep orphan entries with the limitation one reserved
+	 * segment for cp pack we can have max 1020*(504-cp_payload)
+	 * orphan entries
 	 */
 	sbi->max_orphans = (sbi->blocks_per_seg - F2FS_CP_PACKS -
-			NR_CURSEG_TYPE) * F2FS_ORPHANS_PER_BLOCK;
+			NR_CURSEG_TYPE - __cp_payload(sbi)) *
+				F2FS_ORPHANS_PER_BLOCK;
 }
 
 int __init create_checkpoint_caches(void)

commit 2bda542d59f970b61095bd8205c6c76062f286e3
Author: Wanpeng Li <wanpeng.li@linux.intel.com>
Date:   Fri Feb 27 15:56:16 2015 +0800

    f2fs: fix block_ops trace point
    
    block operations is used to flush all dirty node and dentry blocks in
    the page cache and suspend ordinary writing activities, however, there
    are some facts such like cp error or mount read-only etc which lead to
    block operations can't be invoked. Current trace point print block_ops
    start premature even if block_ops doesn't have opportunity to execute.
    This patch fix it by move block_ops trace point just before block_ops.
    
    Signed-off-by: Wanpeng Li <wanpeng.li@linux.intel.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4d5e697d82f6..e9f30abbb6fe 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1047,8 +1047,6 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	unsigned long long ckpt_ver;
 
-	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "start block_ops");
-
 	mutex_lock(&sbi->cp_mutex);
 
 	if (!is_sbi_flag_set(sbi, SBI_IS_DIRTY) &&
@@ -1058,6 +1056,9 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		goto out;
 	if (f2fs_readonly(sbi->sb))
 		goto out;
+
+	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "start block_ops");
+
 	if (block_operations(sbi))
 		goto out;
 

commit 3c64298579a1343cbdf3d2f17adf774a58546aae
Author: Wanpeng Li <wanpeng.li@linux.intel.com>
Date:   Thu Feb 26 07:57:21 2015 +0800

    f2fs: fix the number of orphan inode blocks
    
    cp_pack_start_sum is calculated in do_checkpoint and is equal to
    cpu_to_le32(1 + cp_payload_blks + orphan_blocks). The number of
    orphan inode blocks is take advantage of by recover_orphan_inodes
    to readahead meta pages and recovery inodes. However, current codes
    forget to reduce the number of cp payload blocks when calculate
    the number of orphan inode blocks. This patch fix it.
    
    Signed-off-by: Wanpeng Li <wanpeng.li@linux.intel.com>
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c7cafd8d522c..4d5e697d82f6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -464,7 +464,7 @@ static void recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 
 void recover_orphan_inodes(struct f2fs_sb_info *sbi)
 {
-	block_t start_blk, orphan_blkaddr, i, j;
+	block_t start_blk, orphan_blocks, i, j;
 
 	if (!is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG))
 		return;
@@ -472,11 +472,11 @@ void recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	set_sbi_flag(sbi, SBI_POR_DOING);
 
 	start_blk = __start_cp_addr(sbi) + 1 + __cp_payload(sbi);
-	orphan_blkaddr = __start_sum_addr(sbi) - 1;
+	orphan_blocks = __start_sum_addr(sbi) - 1 - __cp_payload(sbi);
 
-	ra_meta_pages(sbi, start_blk, orphan_blkaddr, META_CP);
+	ra_meta_pages(sbi, start_blk, orphan_blocks, META_CP);
 
-	for (i = 0; i < orphan_blkaddr; i++) {
+	for (i = 0; i < orphan_blocks; i++) {
 		struct page *page = get_meta_page(sbi, start_blk + i);
 		struct f2fs_orphan_block *orphan_blk;
 

commit 551414861fbd494d58d50f4750d1d1b7f42b6df1
Author: Wanpeng Li <wanpeng.li@linux.intel.com>
Date:   Thu Feb 26 07:57:20 2015 +0800

    f2fs: introduce macro __cp_payload
    
    This patch introduce macro __cp_payload.
    
    Signed-off-by: Wanpeng Li <wanpeng.li@linux.intel.com>
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6faffce01869..c7cafd8d522c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -471,8 +471,7 @@ void recover_orphan_inodes(struct f2fs_sb_info *sbi)
 
 	set_sbi_flag(sbi, SBI_POR_DOING);
 
-	start_blk = __start_cp_addr(sbi) + 1 +
-		le32_to_cpu(F2FS_RAW_SUPER(sbi)->cp_payload);
+	start_blk = __start_cp_addr(sbi) + 1 + __cp_payload(sbi);
 	orphan_blkaddr = __start_sum_addr(sbi) - 1;
 
 	ra_meta_pages(sbi, start_blk, orphan_blkaddr, META_CP);
@@ -615,7 +614,7 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	unsigned long blk_size = sbi->blocksize;
 	unsigned long long cp1_version = 0, cp2_version = 0;
 	unsigned long long cp_start_blk_no;
-	unsigned int cp_blks = 1 + le32_to_cpu(F2FS_RAW_SUPER(sbi)->cp_payload);
+	unsigned int cp_blks = 1 + __cp_payload(sbi);
 	block_t cp_blk_no;
 	int i;
 
@@ -884,7 +883,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	__u32 crc32 = 0;
 	void *kaddr;
 	int i;
-	int cp_payload_blks = le32_to_cpu(F2FS_RAW_SUPER(sbi)->cp_payload);
+	int cp_payload_blks = __cp_payload(sbi);
 
 	/*
 	 * This avoids to conduct wrong roll-forward operations and uses

commit 97dc3fd2cbbf6dac239333083a8a005bf50c96e8
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Feb 16 16:19:22 2015 +0800

    f2fs: use ->writepage in sync_meta_pages
    
    This patch uses ->writepage of meta mapping in sync_meta_pages instead of
    f2fs_write_meta_page, by this way, in its caller we can ignore any changes
    (e.g. changing name) of this registered function.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7f794b72b3b7..6faffce01869 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -276,7 +276,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 			if (!clear_page_dirty_for_io(page))
 				goto continue_unlock;
 
-			if (f2fs_write_meta_page(page, &wbc)) {
+			if (mapping->a_ops->writepage(page, &wbc)) {
 				unlock_page(page);
 				break;
 			}

commit 29e7043f405c4c4c3a82f61222790f3ea8c0bf13
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Feb 10 16:23:12 2015 -0800

    f2fs: fix sparse warnings
    
    This patch resolves the following warnings.
    
    include/trace/events/f2fs.h:150:1: warning: expression using sizeof bool
    include/trace/events/f2fs.h:180:1: warning: expression using sizeof bool
    include/trace/events/f2fs.h:990:1: warning: expression using sizeof bool
    include/trace/events/f2fs.h:990:1: warning: expression using sizeof bool
    include/trace/events/f2fs.h:150:1: warning: odd constant _Bool cast (ffffffffffffffff becomes 1)
    include/trace/events/f2fs.h:180:1: warning: odd constant _Bool cast (ffffffffffffffff becomes 1)
    include/trace/events/f2fs.h:990:1: warning: odd constant _Bool cast (ffffffffffffffff becomes 1)
    include/trace/events/f2fs.h:990:1: warning: odd constant _Bool cast (ffffffffffffffff becomes 1)
    
    fs/f2fs/checkpoint.c:27:19: warning: symbol 'inode_entry_slab' was not declared. Should it be static?
    fs/f2fs/checkpoint.c:577:15: warning: cast to restricted __le32
    fs/f2fs/checkpoint.c:592:15: warning: cast to restricted __le32
    
    fs/f2fs/trace.c:19:1: warning: symbol 'pids' was not declared. Should it be static?
    fs/f2fs/trace.c:21:21: warning: symbol 'last_io' was not declared. Should it be static?
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 58d88df0d632..7f794b72b3b7 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -574,7 +574,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	if (crc_offset >= blk_size)
 		goto invalid_cp1;
 
-	crc = le32_to_cpu(*((__u32 *)((unsigned char *)cp_block + crc_offset)));
+	crc = le32_to_cpu(*((__le32 *)((unsigned char *)cp_block + crc_offset)));
 	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
 		goto invalid_cp1;
 
@@ -589,7 +589,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	if (crc_offset >= blk_size)
 		goto invalid_cp2;
 
-	crc = le32_to_cpu(*((__u32 *)((unsigned char *)cp_block + crc_offset)));
+	crc = le32_to_cpu(*((__le32 *)((unsigned char *)cp_block + crc_offset)));
 	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
 		goto invalid_cp2;
 

commit f7ef9b83b583640111039b30e13263b71c3a6ed5
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Feb 9 12:02:44 2015 -0800

    f2fs: introduce macros to convert bytes and blocks in f2fs
    
    This patch adds two macros for transition between byte and block offsets.
    Currently, f2fs only supports 4KB blocks, so use the default size for now.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 31a715b5fd5c..58d88df0d632 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -981,15 +981,14 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* write out checkpoint buffer at block 0 */
 	cp_page = grab_meta_page(sbi, start_blk++);
 	kaddr = page_address(cp_page);
-	memcpy(kaddr, ckpt, (1 << sbi->log_blocksize));
+	memcpy(kaddr, ckpt, F2FS_BLKSIZE);
 	set_page_dirty(cp_page);
 	f2fs_put_page(cp_page, 1);
 
 	for (i = 1; i < 1 + cp_payload_blks; i++) {
 		cp_page = grab_meta_page(sbi, start_blk++);
 		kaddr = page_address(cp_page);
-		memcpy(kaddr, (char *)ckpt + i * F2FS_BLKSIZE,
-				(1 << sbi->log_blocksize));
+		memcpy(kaddr, (char *)ckpt + i * F2FS_BLKSIZE, F2FS_BLKSIZE);
 		set_page_dirty(cp_page);
 		f2fs_put_page(cp_page, 1);
 	}
@@ -1009,7 +1008,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* writeout checkpoint block */
 	cp_page = grab_meta_page(sbi, start_blk);
 	kaddr = page_address(cp_page);
-	memcpy(kaddr, ckpt, (1 << sbi->log_blocksize));
+	memcpy(kaddr, ckpt, F2FS_BLKSIZE);
 	set_page_dirty(cp_page);
 	f2fs_put_page(cp_page, 1);
 

commit 487261f39bcd8983f55c611e299f70f34659674b
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Feb 5 17:44:29 2015 +0800

    f2fs: merge {invalidate,release}page for meta/node/data pages
    
    This patch merges ->{invalidate,release}page function for meta/node/data pages.
    
    After this, duplication of codes could be removed.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 470fa58606b2..31a715b5fd5c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -309,32 +309,12 @@ static int f2fs_set_meta_page_dirty(struct page *page)
 	return 0;
 }
 
-static void f2fs_invalidate_meta_page(struct page *page, unsigned int offset,
-				      unsigned int length)
-{
-	struct inode *inode = page->mapping->host;
-
-	if (PageDirty(page))
-		dec_page_count(F2FS_I_SB(inode), F2FS_DIRTY_META);
-	ClearPagePrivate(page);
-}
-
-static int f2fs_release_meta_page(struct page *page, gfp_t wait)
-{
-	/* If this is dirty page, keep PagePrivate */
-	if (PageDirty(page))
-		return 0;
-
-	ClearPagePrivate(page);
-	return 1;
-}
-
 const struct address_space_operations f2fs_meta_aops = {
 	.writepage	= f2fs_write_meta_page,
 	.writepages	= f2fs_write_meta_pages,
 	.set_page_dirty	= f2fs_set_meta_page_dirty,
-	.invalidatepage = f2fs_invalidate_meta_page,
-	.releasepage	= f2fs_release_meta_page,
+	.invalidatepage = f2fs_invalidate_page,
+	.releasepage	= f2fs_release_page,
 };
 
 static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)

commit f68daeebba5a697f31f64c07b8693fa678981819
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jan 30 11:39:08 2015 -0800

    f2fs: keep PagePrivate during releasepage
    
    If PagePrivate is removed by releasepage, f2fs loses counting dirty pages.
    
    e.g., try_to_release_page will not release page when the page is dirty,
    but our releasepage removes PagePrivate.
    
        [<ffffffff81188d75>] try_to_release_page+0x35/0x50
        [<ffffffff811996f9>] invalidate_inode_pages2_range+0x2f9/0x3b0
        [<ffffffffa02a7f54>] ? truncate_blocks+0x384/0x4d0 [f2fs]
        [<ffffffffa02b7583>] ? f2fs_direct_IO+0x283/0x290 [f2fs]
        [<ffffffffa02b7fb0>] ? get_data_block_fiemap+0x20/0x20 [f2fs]
        [<ffffffff8118aa53>] generic_file_direct_write+0x163/0x170
        [<ffffffff8118ad06>] __generic_file_write_iter+0x2a6/0x350
        [<ffffffff8118adef>] generic_file_write_iter+0x3f/0xb0
        [<ffffffff81203081>] new_sync_write+0x81/0xb0
        [<ffffffff81203837>] vfs_write+0xb7/0x1f0
        [<ffffffff81204459>] SyS_write+0x49/0xb0
        [<ffffffff817c286d>] system_call_fastpath+0x16/0x1b
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f7cdcad31943..470fa58606b2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -321,6 +321,10 @@ static void f2fs_invalidate_meta_page(struct page *page, unsigned int offset,
 
 static int f2fs_release_meta_page(struct page *page, gfp_t wait)
 {
+	/* If this is dirty page, keep PagePrivate */
+	if (PageDirty(page))
+		return 0;
+
 	ClearPagePrivate(page);
 	return 1;
 }

commit 119ee9144534141822462e3e8a5ccc8dc537f712
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jan 29 11:45:33 2015 -0800

    f2fs: split UMOUNT and FASTBOOT flags
    
    This patch adds FASTBOOT flag into checkpoint as follows.
    
     - CP_UMOUNT_FLAG is set when system is umounted.
     - CP_FASTBOOT_FLAG is set when intermediate checkpoint having node summaries
       was done.
    
    So, if you get CP_UMOUNT_FLAG from checkpoint, the system was umounted cleanly.
    Instead, if there was sudden-power-off, you can get CP_FASTBOOT_FLAG or nothing.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 22165fb1d0d1..f7cdcad31943 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -956,17 +956,24 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	ckpt->cp_pack_start_sum = cpu_to_le32(1 + cp_payload_blks +
 			orphan_blocks);
 
-	if (cpc->reason == CP_UMOUNT) {
-		set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+	if (__remain_node_summaries(cpc->reason))
 		ckpt->cp_pack_total_block_count = cpu_to_le32(F2FS_CP_PACKS+
 				cp_payload_blks + data_sum_blocks +
 				orphan_blocks + NR_CURSEG_NODE_TYPE);
-	} else {
-		clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+	else
 		ckpt->cp_pack_total_block_count = cpu_to_le32(F2FS_CP_PACKS +
 				cp_payload_blks + data_sum_blocks +
 				orphan_blocks);
-	}
+
+	if (cpc->reason == CP_UMOUNT)
+		set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+	else
+		clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+
+	if (cpc->reason == CP_FASTBOOT)
+		set_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
+	else
+		clear_ckpt_flags(ckpt, CP_FASTBOOT_FLAG);
 
 	if (orphan_num)
 		set_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
@@ -1010,7 +1017,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	write_data_summaries(sbi, start_blk);
 	start_blk += data_sum_blocks;
-	if (cpc->reason == CP_UMOUNT) {
+	if (__remain_node_summaries(cpc->reason)) {
 		write_node_summaries(sbi, start_blk);
 		start_blk += NR_CURSEG_NODE_TYPE;
 	}

commit 11504a8e7e20e2ff2e68176850e9b83b8bae760e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jan 23 18:43:45 2015 -0800

    f2fs: avoid write_checkpoint if f2fs is mounted readonly
    
    Do not change any partition when f2fs is changed to readonly mode.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 19021414d195..22165fb1d0d1 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1067,6 +1067,8 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		goto out;
 	if (unlikely(f2fs_cp_error(sbi)))
 		goto out;
+	if (f2fs_readonly(sbi->sb))
+		goto out;
 	if (block_operations(sbi))
 		goto out;
 

commit caf0047e7e1e60a7ad1d655d3b81b32e2dfb6095
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Jan 28 17:48:42 2015 +0800

    f2fs: merge flags in struct f2fs_sb_info
    
    Currently, there are several variables with Boolean type as below:
    
    struct f2fs_sb_info {
    ...
            int s_dirty;
            bool need_fsck;
            bool s_closing;
    ...
            bool por_doing;
    ...
    }
    
    For this there are some issues:
    1. there are some space of f2fs_sb_info is wasted due to aligning after Boolean
       type variables by compiler.
    2. if we continuously add new flag into f2fs_sb_info, structure will be messed
       up.
    
    So in this patch, we try to:
    1. switch s_dirty to Boolean type variable since it has two status 0/1.
    2. merge s_dirty/need_fsck/s_closing/por_doing variables into s_flag.
    3. introduce an enum type which can indicate different states of sbi.
    4. use new introduced universal interfaces is_sbi_flag_set/{set,clear}_sbi_flag
       to operate flags for sbi.
    
    After that, above issues will be fixed.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 79f82819086f..19021414d195 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -190,7 +190,7 @@ static int f2fs_write_meta_page(struct page *page,
 
 	trace_f2fs_writepage(page, META);
 
-	if (unlikely(sbi->por_doing))
+	if (unlikely(is_sbi_flag_set(sbi, SBI_POR_DOING)))
 		goto redirty_out;
 	if (wbc->for_reclaim && page->index < GET_SUM_BLOCK(sbi, 0))
 		goto redirty_out;
@@ -485,7 +485,7 @@ void recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	if (!is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG))
 		return;
 
-	sbi->por_doing = true;
+	set_sbi_flag(sbi, SBI_POR_DOING);
 
 	start_blk = __start_cp_addr(sbi) + 1 +
 		le32_to_cpu(F2FS_RAW_SUPER(sbi)->cp_payload);
@@ -506,7 +506,7 @@ void recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	}
 	/* clear Orphan Flag */
 	clear_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG);
-	sbi->por_doing = false;
+	clear_sbi_flag(sbi, SBI_POR_DOING);
 	return;
 }
 
@@ -973,7 +973,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	else
 		clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 
-	if (sbi->need_fsck)
+	if (is_sbi_flag_set(sbi, SBI_NEED_FSCK))
 		set_ckpt_flags(ckpt, CP_FSCK_FLAG);
 
 	/* update SIT/NAT bitmap */
@@ -1047,7 +1047,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		return;
 
 	clear_prefree_segments(sbi);
-	F2FS_RESET_SB_DIRT(sbi);
+	clear_sbi_flag(sbi, SBI_IS_DIRTY);
 }
 
 /*
@@ -1062,7 +1062,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	mutex_lock(&sbi->cp_mutex);
 
-	if (!sbi->s_dirty &&
+	if (!is_sbi_flag_set(sbi, SBI_IS_DIRTY) &&
 			cpc->reason != CP_DISCARD && cpc->reason != CP_UMOUNT)
 		goto out;
 	if (unlikely(f2fs_cp_error(sbi)))

commit 1601839e9e5bd5726d744c9c5919f87dc808bbcc
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Jan 19 20:24:37 2015 +0800

    f2fs: fix to release count of meta page in ->invalidatepage
    
    We will encounter deadloop in below scenario:
    
    1. increase page count for F2FS_DIRTY_META type in following path:
    ->recover_fsync_data
      ->recover_data
        ->do_recover_data
          ->recover_data_page
            ->change_curseg
              ->write_sum_page
                ->set_page_dirty
    2. fail in recover_data()
    3. invalidate meta pages in truncate_inode_pages_final without decreasing page
       count.
    4. deadloop when sync_meta_pages as page count will always be non-zero.
    
    message:
    NMI watchdog: BUG: soft lockup - CPU#0 stuck for 22s!
    
     [<c1129a37>] pagevec_lookup_tag+0x27/0x30
     [<f0e774c7>] sync_meta_pages+0x87/0x160 [f2fs]
     [<f0e86dd9>] recover_fsync_data+0xeb9/0xf10 [f2fs]
     [<f0e75398>] f2fs_fill_super+0x888/0x980 [f2fs]
     [<c11733ca>] mount_bdev+0x16a/0x1a0
     [<f0e7180f>] f2fs_mount+0x1f/0x30 [f2fs]
     [<c1173da6>] mount_fs+0x36/0x170
     [<c118b6f5>] vfs_kern_mount+0x55/0xe0
     [<c118d63f>] do_mount+0x1df/0x9f0
     [<c118e110>] SyS_mount+0x70/0xb0
     [<c15a0c48>] sysenter_do_call+0x12/0x12
    
    To avoid page count leak, let's add ->invalidatepage and ->releasepage in
    f2fs_meta_aops as f2fs_node_aops to release meta page count correctly.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 231d8c9fea0a..79f82819086f 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -302,16 +302,35 @@ static int f2fs_set_meta_page_dirty(struct page *page)
 	if (!PageDirty(page)) {
 		__set_page_dirty_nobuffers(page);
 		inc_page_count(F2FS_P_SB(page), F2FS_DIRTY_META);
+		SetPagePrivate(page);
 		f2fs_trace_pid(page);
 		return 1;
 	}
 	return 0;
 }
 
+static void f2fs_invalidate_meta_page(struct page *page, unsigned int offset,
+				      unsigned int length)
+{
+	struct inode *inode = page->mapping->host;
+
+	if (PageDirty(page))
+		dec_page_count(F2FS_I_SB(inode), F2FS_DIRTY_META);
+	ClearPagePrivate(page);
+}
+
+static int f2fs_release_meta_page(struct page *page, gfp_t wait)
+{
+	ClearPagePrivate(page);
+	return 1;
+}
+
 const struct address_space_operations f2fs_meta_aops = {
 	.writepage	= f2fs_write_meta_page,
 	.writepages	= f2fs_write_meta_pages,
 	.set_page_dirty	= f2fs_set_meta_page_dirty,
+	.invalidatepage = f2fs_invalidate_meta_page,
+	.releasepage	= f2fs_release_meta_page,
 };
 
 static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)

commit 85dc2f2c6c84e99e9864ef660f79683aaad85f42
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Jan 14 17:41:41 2015 -0800

    f2fs: do checkpoint when umount flag is not set
    
    If the previous checkpoint was done without CP_UMOUNT flag, it needs to do
    checkpoint with CP_UMOUNT for the next fast boot.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9f5317c9ad72..231d8c9fea0a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1043,7 +1043,8 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	mutex_lock(&sbi->cp_mutex);
 
-	if (!sbi->s_dirty && cpc->reason != CP_DISCARD)
+	if (!sbi->s_dirty &&
+			cpc->reason != CP_DISCARD && cpc->reason != CP_UMOUNT)
 		goto out;
 	if (unlikely(f2fs_cp_error(sbi)))
 		goto out;

commit 062920734c0de9dd4f0a9bdc36fdcabc2751eb34
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Dec 29 15:56:18 2014 +0800

    f2fs: reuse inode_entry_slab in gc procedure for using slab more effectively
    
    There are two slab cache inode_entry_slab and winode_slab using the same
    structure as below:
    
    struct dir_inode_entry {
            struct list_head list;  /* list head */
            struct inode *inode;    /* vfs inode pointer */
    };
    
    struct inode_entry {
            struct list_head list;
            struct inode *inode;
    };
    
    It's a little waste that the two cache can not share their memory space for each
    other.
    So in this patch we remove one redundant winode_slab slab cache, then use more
    universal name struct inode_entry as remaining data structure name of slab,
    finally we reuse the inode_entry_slab to store dirty dir item and gc item for
    more effective.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3999933f7a74..9f5317c9ad72 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -24,7 +24,7 @@
 #include <trace/events/f2fs.h>
 
 static struct kmem_cache *ino_entry_slab;
-static struct kmem_cache *inode_entry_slab;
+struct kmem_cache *inode_entry_slab;
 
 /*
  * We guarantee no failure on the returned page.
@@ -673,7 +673,7 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	return -EINVAL;
 }
 
-static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
+static int __add_dirty_inode(struct inode *inode, struct inode_entry *new)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 
@@ -690,7 +690,7 @@ static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
 void update_dirty_page(struct inode *inode, struct page *page)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
-	struct dir_inode_entry *new;
+	struct inode_entry *new;
 	int ret = 0;
 
 	if (!S_ISDIR(inode->i_mode) && !S_ISREG(inode->i_mode))
@@ -720,7 +720,7 @@ void update_dirty_page(struct inode *inode, struct page *page)
 void add_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
-	struct dir_inode_entry *new =
+	struct inode_entry *new =
 			f2fs_kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
 	int ret = 0;
 
@@ -738,7 +738,7 @@ void add_dirty_dir_inode(struct inode *inode)
 void remove_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
-	struct dir_inode_entry *entry;
+	struct inode_entry *entry;
 
 	if (!S_ISDIR(inode->i_mode))
 		return;
@@ -768,7 +768,7 @@ void remove_dirty_dir_inode(struct inode *inode)
 void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 {
 	struct list_head *head;
-	struct dir_inode_entry *entry;
+	struct inode_entry *entry;
 	struct inode *inode;
 retry:
 	if (unlikely(f2fs_cp_error(sbi)))
@@ -781,7 +781,7 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 		spin_unlock(&sbi->dir_inode_lock);
 		return;
 	}
-	entry = list_entry(head->next, struct dir_inode_entry, list);
+	entry = list_entry(head->next, struct inode_entry, list);
 	inode = igrab(entry->inode);
 	spin_unlock(&sbi->dir_inode_lock);
 	if (inode) {
@@ -1107,8 +1107,8 @@ int __init create_checkpoint_caches(void)
 			sizeof(struct ino_entry));
 	if (!ino_entry_slab)
 		return -ENOMEM;
-	inode_entry_slab = f2fs_kmem_cache_create("f2fs_dirty_dir_entry",
-			sizeof(struct dir_inode_entry));
+	inode_entry_slab = f2fs_kmem_cache_create("f2fs_inode_entry",
+			sizeof(struct inode_entry));
 	if (!inode_entry_slab) {
 		kmem_cache_destroy(ino_entry_slab);
 		return -ENOMEM;

commit 9e4ded3f309eb5b5a9be0ca2acd26e5ea7f00914
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Dec 17 19:58:58 2014 -0800

    f2fs: activate f2fs_trace_pid
    
    This patch activates f2fs_trace_pid.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0ac7c39605ed..3999933f7a74 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -20,6 +20,7 @@
 #include "f2fs.h"
 #include "node.h"
 #include "segment.h"
+#include "trace.h"
 #include <trace/events/f2fs.h>
 
 static struct kmem_cache *ino_entry_slab;
@@ -301,6 +302,7 @@ static int f2fs_set_meta_page_dirty(struct page *page)
 	if (!PageDirty(page)) {
 		__set_page_dirty_nobuffers(page);
 		inc_page_count(F2FS_P_SB(page), F2FS_DIRTY_META);
+		f2fs_trace_pid(page);
 		return 1;
 	}
 	return 0;
@@ -712,6 +714,7 @@ void update_dirty_page(struct inode *inode, struct page *page)
 		kmem_cache_free(inode_entry_slab, new);
 out:
 	SetPagePrivate(page);
+	f2fs_trace_pid(page);
 }
 
 void add_dirty_dir_inode(struct inode *inode)

commit cf04e8eb55290c7b836c36f0b4e1a8d0fe8ee275
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Dec 17 19:33:13 2014 -0800

    f2fs: use f2fs_io_info to clean up messy parameters during IO path
    
    This patch cleans up parameters on IO paths.
    The key idea is to use f2fs_io_info adding a parameter, block address, and then
    use this structure as parameters.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 825158e4855a..0ac7c39605ed 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -50,6 +50,11 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 {
 	struct address_space *mapping = META_MAPPING(sbi);
 	struct page *page;
+	struct f2fs_io_info fio = {
+		.type = META,
+		.rw = READ_SYNC | REQ_META | REQ_PRIO,
+		.blk_addr = index,
+	};
 repeat:
 	page = grab_cache_page(mapping, index);
 	if (!page) {
@@ -59,8 +64,7 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	if (PageUptodate(page))
 		goto out;
 
-	if (f2fs_submit_page_bio(sbi, page, index,
-				READ_SYNC | REQ_META | REQ_PRIO))
+	if (f2fs_submit_page_bio(sbi, page, &fio))
 		goto repeat;
 
 	lock_page(page);
@@ -112,14 +116,12 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 	block_t prev_blk_addr = 0;
 	struct page *page;
 	block_t blkno = start;
-
 	struct f2fs_io_info fio = {
 		.type = META,
 		.rw = READ_SYNC | REQ_META | REQ_PRIO
 	};
 
 	for (; nrpages-- > 0; blkno++) {
-		block_t blk_addr;
 
 		if (!is_valid_blkaddr(sbi, blkno, type))
 			goto out;
@@ -130,27 +132,27 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 					NAT_BLOCK_OFFSET(NM_I(sbi)->max_nid)))
 				blkno = 0;
 			/* get nat block addr */
-			blk_addr = current_nat_addr(sbi,
+			fio.blk_addr = current_nat_addr(sbi,
 					blkno * NAT_ENTRY_PER_BLOCK);
 			break;
 		case META_SIT:
 			/* get sit block addr */
-			blk_addr = current_sit_addr(sbi,
+			fio.blk_addr = current_sit_addr(sbi,
 					blkno * SIT_ENTRY_PER_BLOCK);
-			if (blkno != start && prev_blk_addr + 1 != blk_addr)
+			if (blkno != start && prev_blk_addr + 1 != fio.blk_addr)
 				goto out;
-			prev_blk_addr = blk_addr;
+			prev_blk_addr = fio.blk_addr;
 			break;
 		case META_SSA:
 		case META_CP:
 		case META_POR:
-			blk_addr = blkno;
+			fio.blk_addr = blkno;
 			break;
 		default:
 			BUG();
 		}
 
-		page = grab_cache_page(META_MAPPING(sbi), blk_addr);
+		page = grab_cache_page(META_MAPPING(sbi), fio.blk_addr);
 		if (!page)
 			continue;
 		if (PageUptodate(page)) {
@@ -158,7 +160,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 			continue;
 		}
 
-		f2fs_submit_page_mbio(sbi, page, blk_addr, &fio);
+		f2fs_submit_page_mbio(sbi, page, &fio);
 		f2fs_put_page(page, 0);
 	}
 out:

commit 3fa06d7bc9f579bd180e879fd1c9bdb6b1b0d9b7
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Dec 9 14:21:46 2014 +0800

    f2fs: readahead contiguous current summary blocks in checkpoint
    
    Let's add readahead code for reading contiguous compact/normal summary blocks
    in checkpoint, then we will gain better performance in mount procedure.
    
    Changes from v1
      o remove inappropriate 'unlikely' in npages_for_summary_flush.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index e6c271fefaca..825158e4855a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -922,7 +922,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	ckpt->next_free_nid = cpu_to_le32(last_nid);
 
 	/* 2 cp  + n data seg summary + orphan inode blocks */
-	data_sum_blocks = npages_for_summary_flush(sbi);
+	data_sum_blocks = npages_for_summary_flush(sbi, false);
 	if (data_sum_blocks < NR_CURSEG_DATA_TYPE)
 		set_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
 	else

commit 635aee1fefef921ae4124b127fced62ea6008839
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Dec 8 15:02:52 2014 +0800

    f2fs: avoid to ra unneeded blocks in recover flow
    
    To improve recovery speed, f2fs try to readahead many contiguous blocks in warm
    node segment, but for most time, abnormal power-off do not occur frequently, so
    when mount a normal power-off f2fs image, by contrary ra so many blocks and then
    invalid them will hurt the performance of mount.
    It's better to just ra the first next-block for normal condition.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b2d5431d6850..e6c271fefaca 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -72,21 +72,6 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return page;
 }
 
-struct page *get_meta_page_ra(struct f2fs_sb_info *sbi, pgoff_t index)
-{
-	bool readahead = false;
-	struct page *page;
-
-	page = find_get_page(META_MAPPING(sbi), index);
-	if (!page || (page && !PageUptodate(page)))
-		readahead = true;
-	f2fs_put_page(page, 0);
-
-	if (readahead)
-		ra_meta_pages(sbi, index, MAX_BIO_BLOCKS(sbi), META_POR);
-	return get_meta_page(sbi, index);
-}
-
 static inline bool is_valid_blkaddr(struct f2fs_sb_info *sbi,
 						block_t blkaddr, int type)
 {
@@ -181,6 +166,20 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 	return blkno - start;
 }
 
+void ra_meta_pages_cond(struct f2fs_sb_info *sbi, pgoff_t index)
+{
+	struct page *page;
+	bool readahead = false;
+
+	page = find_get_page(META_MAPPING(sbi), index);
+	if (!page || (page && !PageUptodate(page)))
+		readahead = true;
+	f2fs_put_page(page, 0);
+
+	if (readahead)
+		ra_meta_pages(sbi, index, MAX_BIO_BLOCKS(sbi), META_POR);
+}
+
 static int f2fs_write_meta_page(struct page *page,
 				struct writeback_control *wbc)
 {

commit 66b00c186764e29765e8962a03556c329dee48e5
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Dec 8 14:59:17 2014 +0800

    f2fs: introduce is_valid_blkaddr to cleanup codes in ra_meta_pages
    
    This patch does cleanup work, it introduces is_valid_blkaddr() to include
    verification code for blkaddr with upper and down boundary value which were in
    ra_meta_pages previous.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f3ebfb5a8431..b2d5431d6850 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -87,22 +87,36 @@ struct page *get_meta_page_ra(struct f2fs_sb_info *sbi, pgoff_t index)
 	return get_meta_page(sbi, index);
 }
 
-static inline block_t get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
+static inline bool is_valid_blkaddr(struct f2fs_sb_info *sbi,
+						block_t blkaddr, int type)
 {
 	switch (type) {
 	case META_NAT:
-		return NM_I(sbi)->max_nid / NAT_ENTRY_PER_BLOCK;
+		break;
 	case META_SIT:
-		return SIT_BLK_CNT(sbi);
+		if (unlikely(blkaddr >= SIT_BLK_CNT(sbi)))
+			return false;
+		break;
 	case META_SSA:
-		return MAIN_BLKADDR(sbi);
+		if (unlikely(blkaddr >= MAIN_BLKADDR(sbi) ||
+			blkaddr < SM_I(sbi)->ssa_blkaddr))
+			return false;
+		break;
 	case META_CP:
-		return SM_I(sbi)->sit_info->sit_base_addr;
+		if (unlikely(blkaddr >= SIT_I(sbi)->sit_base_addr ||
+			blkaddr < __start_cp_addr(sbi)))
+			return false;
+		break;
 	case META_POR:
-		return MAX_BLKADDR(sbi);
+		if (unlikely(blkaddr >= MAX_BLKADDR(sbi) ||
+			blkaddr < MAIN_BLKADDR(sbi)))
+			return false;
+		break;
 	default:
 		BUG();
 	}
+
+	return true;
 }
 
 /*
@@ -113,7 +127,6 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 	block_t prev_blk_addr = 0;
 	struct page *page;
 	block_t blkno = start;
-	block_t max_blks = get_max_meta_blks(sbi, type);
 
 	struct f2fs_io_info fio = {
 		.type = META,
@@ -123,18 +136,20 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 	for (; nrpages-- > 0; blkno++) {
 		block_t blk_addr;
 
+		if (!is_valid_blkaddr(sbi, blkno, type))
+			goto out;
+
 		switch (type) {
 		case META_NAT:
-			/* get nat block addr */
-			if (unlikely(blkno >= max_blks))
+			if (unlikely(blkno >=
+					NAT_BLOCK_OFFSET(NM_I(sbi)->max_nid)))
 				blkno = 0;
+			/* get nat block addr */
 			blk_addr = current_nat_addr(sbi,
 					blkno * NAT_ENTRY_PER_BLOCK);
 			break;
 		case META_SIT:
 			/* get sit block addr */
-			if (unlikely(blkno >= max_blks))
-				goto out;
 			blk_addr = current_sit_addr(sbi,
 					blkno * SIT_ENTRY_PER_BLOCK);
 			if (blkno != start && prev_blk_addr + 1 != blk_addr)
@@ -142,24 +157,8 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 			prev_blk_addr = blk_addr;
 			break;
 		case META_SSA:
-			if (unlikely(blkno >= max_blks))
-				goto out;
-			if (unlikely(blkno < SM_I(sbi)->ssa_blkaddr))
-				goto out;
-			blk_addr = blkno;
-			break;
 		case META_CP:
-			if (unlikely(blkno >= max_blks))
-				goto out;
-			if (unlikely(blkno < __start_cp_addr(sbi)))
-				goto out;
-			blk_addr = blkno;
-			break;
 		case META_POR:
-			if (unlikely(blkno >= max_blks))
-				goto out;
-			if (unlikely(blkno < MAIN_BLKADDR(sbi)))
-				goto out;
 			blk_addr = blkno;
 			break;
 		default:

commit 13da549460d549aec78a943e589f4ffc3fdc716c
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Mon Dec 8 14:56:19 2014 +0800

    f2fs: fix to enable readahead for SSA/CP blocks
    
    1.We use zero as upper boundary value for ra SSA/CP blocks, we will skip
    readahead as verification failure with max number, it causes low performance.
    2.Low boundary value is not accurate for SSA/CP/POR region verification, so
    these values need to be redefined.
    
    This patch fixes above issues.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6a81b73add06..f3ebfb5a8431 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -95,8 +95,9 @@ static inline block_t get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
 	case META_SIT:
 		return SIT_BLK_CNT(sbi);
 	case META_SSA:
+		return MAIN_BLKADDR(sbi);
 	case META_CP:
-		return 0;
+		return SM_I(sbi)->sit_info->sit_base_addr;
 	case META_POR:
 		return MAX_BLKADDR(sbi);
 	default:
@@ -141,11 +142,23 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 			prev_blk_addr = blk_addr;
 			break;
 		case META_SSA:
+			if (unlikely(blkno >= max_blks))
+				goto out;
+			if (unlikely(blkno < SM_I(sbi)->ssa_blkaddr))
+				goto out;
+			blk_addr = blkno;
+			break;
 		case META_CP:
+			if (unlikely(blkno >= max_blks))
+				goto out;
+			if (unlikely(blkno < __start_cp_addr(sbi)))
+				goto out;
+			blk_addr = blkno;
+			break;
 		case META_POR:
 			if (unlikely(blkno >= max_blks))
 				goto out;
-			if (unlikely(blkno < SEG0_BLKADDR(sbi)))
+			if (unlikely(blkno < MAIN_BLKADDR(sbi)))
 				goto out;
 			blk_addr = blkno;
 			break;

commit 769ec6e5b7d4a8115447736871be8bffaaba3a7d
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Dec 3 20:47:26 2014 -0800

    f2fs: call radix_tree_preload before radix_tree_insert
    
    This patch tries to fix:
    
     BUG: using smp_processor_id() in preemptible [00000000] code: f2fs_gc-254:0/384
      (radix_tree_node_alloc+0x14/0x74) from [<c033d8a0>] (radix_tree_insert+0x110/0x200)
      (radix_tree_insert+0x110/0x200) from [<c02e8264>] (gc_data_segment+0x340/0x52c)
      (gc_data_segment+0x340/0x52c) from [<c02e8658>] (f2fs_gc+0x208/0x400)
      (f2fs_gc+0x208/0x400) from [<c02e8a98>] (gc_thread_func+0x248/0x28c)
      (gc_thread_func+0x248/0x28c) from [<c0139944>] (kthread+0xa0/0xac)
      (kthread+0xa0/0xac) from [<c0105ef8>] (ret_from_fork+0x14/0x3c)
    
    The reason is that f2fs calls radix_tree_insert under enabled preemption.
    So, before calling it, we need to call radix_tree_preload.
    
    Otherwise, we should use _GFP_WAIT for the radix tree, and use mutex or
    semaphore to cover the radix tree operations.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 20a917b05b99..6a81b73add06 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -304,6 +304,11 @@ static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 	struct inode_management *im = &sbi->im[type];
 	struct ino_entry *e;
 retry:
+	if (radix_tree_preload(GFP_NOFS)) {
+		cond_resched();
+		goto retry;
+	}
+
 	spin_lock(&im->ino_lock);
 
 	e = radix_tree_lookup(&im->ino_root, ino);
@@ -311,11 +316,13 @@ static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 		e = kmem_cache_alloc(ino_entry_slab, GFP_ATOMIC);
 		if (!e) {
 			spin_unlock(&im->ino_lock);
+			radix_tree_preload_end();
 			goto retry;
 		}
 		if (radix_tree_insert(&im->ino_root, ino, e)) {
 			spin_unlock(&im->ino_lock);
 			kmem_cache_free(ino_entry_slab, e);
+			radix_tree_preload_end();
 			goto retry;
 		}
 		memset(e, 0, sizeof(struct ino_entry));
@@ -326,6 +333,7 @@ static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 			im->ino_num++;
 	}
 	spin_unlock(&im->ino_lock);
+	radix_tree_preload_end();
 }
 
 static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)

commit 857dc4e0598e2a95b1cbb8d17c8538b34cc9a2f3
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Nov 19 11:03:34 2014 -0800

    f2fs: write SSA pages under memory pressure
    
    Under memory pressure, we don't need to skip SSA page writes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 838e8ed3d13a..20a917b05b99 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -178,7 +178,7 @@ static int f2fs_write_meta_page(struct page *page,
 
 	if (unlikely(sbi->por_doing))
 		goto redirty_out;
-	if (wbc->for_reclaim)
+	if (wbc->for_reclaim && page->index < GET_SUM_BLOCK(sbi, 0))
 		goto redirty_out;
 	if (unlikely(f2fs_cp_error(sbi)))
 		goto redirty_out;
@@ -187,6 +187,9 @@ static int f2fs_write_meta_page(struct page *page,
 	write_meta_page(sbi, page);
 	dec_page_count(sbi, F2FS_DIRTY_META);
 	unlock_page(page);
+
+	if (wbc->for_reclaim)
+		f2fs_submit_merged_bio(sbi, META, WRITE);
 	return 0;
 
 redirty_out:

commit 67298804f34452a53a9ec9e609d95aa35084132b
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue Nov 18 11:18:36 2014 +0800

    f2fs: introduce struct inode_management to wrap inner fields
    
    Now in f2fs, we have three inode cache: ORPHAN_INO, APPEND_INO, UPDATE_INO,
    and we manage fields related to inode cache separately in struct f2fs_sb_info
    for each inode cache type.
    This makes codes a bit messy, so that this patch intorduce a new struct
    inode_management to wrap inner fields as following which make codes more neat.
    
    /* for inner inode cache management */
    struct inode_management {
            struct radix_tree_root ino_root;        /* ino entry array */
            spinlock_t ino_lock;                    /* for ino entry lock */
            struct list_head ino_list;              /* inode list head */
            unsigned long ino_num;                  /* number of entries */
    };
    
    struct f2fs_sb_info {
            ...
            struct inode_management im[MAX_INO_ENTRY];      /* manage inode cache */
            ...
    }
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index bcd686e0dded..838e8ed3d13a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -298,47 +298,49 @@ const struct address_space_operations f2fs_meta_aops = {
 
 static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
+	struct inode_management *im = &sbi->im[type];
 	struct ino_entry *e;
 retry:
-	spin_lock(&sbi->ino_lock[type]);
+	spin_lock(&im->ino_lock);
 
-	e = radix_tree_lookup(&sbi->ino_root[type], ino);
+	e = radix_tree_lookup(&im->ino_root, ino);
 	if (!e) {
 		e = kmem_cache_alloc(ino_entry_slab, GFP_ATOMIC);
 		if (!e) {
-			spin_unlock(&sbi->ino_lock[type]);
+			spin_unlock(&im->ino_lock);
 			goto retry;
 		}
-		if (radix_tree_insert(&sbi->ino_root[type], ino, e)) {
-			spin_unlock(&sbi->ino_lock[type]);
+		if (radix_tree_insert(&im->ino_root, ino, e)) {
+			spin_unlock(&im->ino_lock);
 			kmem_cache_free(ino_entry_slab, e);
 			goto retry;
 		}
 		memset(e, 0, sizeof(struct ino_entry));
 		e->ino = ino;
 
-		list_add_tail(&e->list, &sbi->ino_list[type]);
+		list_add_tail(&e->list, &im->ino_list);
 		if (type != ORPHAN_INO)
-			sbi->ino_num[type]++;
+			im->ino_num++;
 	}
-	spin_unlock(&sbi->ino_lock[type]);
+	spin_unlock(&im->ino_lock);
 }
 
 static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
+	struct inode_management *im = &sbi->im[type];
 	struct ino_entry *e;
 
-	spin_lock(&sbi->ino_lock[type]);
-	e = radix_tree_lookup(&sbi->ino_root[type], ino);
+	spin_lock(&im->ino_lock);
+	e = radix_tree_lookup(&im->ino_root, ino);
 	if (e) {
 		list_del(&e->list);
-		radix_tree_delete(&sbi->ino_root[type], ino);
-		sbi->ino_num[type]--;
-		spin_unlock(&sbi->ino_lock[type]);
+		radix_tree_delete(&im->ino_root, ino);
+		im->ino_num--;
+		spin_unlock(&im->ino_lock);
 		kmem_cache_free(ino_entry_slab, e);
 		return;
 	}
-	spin_unlock(&sbi->ino_lock[type]);
+	spin_unlock(&im->ino_lock);
 }
 
 void add_dirty_inode(struct f2fs_sb_info *sbi, nid_t ino, int type)
@@ -356,10 +358,12 @@ void remove_dirty_inode(struct f2fs_sb_info *sbi, nid_t ino, int type)
 /* mode should be APPEND_INO or UPDATE_INO */
 bool exist_written_data(struct f2fs_sb_info *sbi, nid_t ino, int mode)
 {
+	struct inode_management *im = &sbi->im[mode];
 	struct ino_entry *e;
-	spin_lock(&sbi->ino_lock[mode]);
-	e = radix_tree_lookup(&sbi->ino_root[mode], ino);
-	spin_unlock(&sbi->ino_lock[mode]);
+
+	spin_lock(&im->ino_lock);
+	e = radix_tree_lookup(&im->ino_root, ino);
+	spin_unlock(&im->ino_lock);
 	return e ? true : false;
 }
 
@@ -369,37 +373,42 @@ void release_dirty_inode(struct f2fs_sb_info *sbi)
 	int i;
 
 	for (i = APPEND_INO; i <= UPDATE_INO; i++) {
-		spin_lock(&sbi->ino_lock[i]);
-		list_for_each_entry_safe(e, tmp, &sbi->ino_list[i], list) {
+		struct inode_management *im = &sbi->im[i];
+
+		spin_lock(&im->ino_lock);
+		list_for_each_entry_safe(e, tmp, &im->ino_list, list) {
 			list_del(&e->list);
-			radix_tree_delete(&sbi->ino_root[i], e->ino);
+			radix_tree_delete(&im->ino_root, e->ino);
 			kmem_cache_free(ino_entry_slab, e);
-			sbi->ino_num[i]--;
+			im->ino_num--;
 		}
-		spin_unlock(&sbi->ino_lock[i]);
+		spin_unlock(&im->ino_lock);
 	}
 }
 
 int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 {
+	struct inode_management *im = &sbi->im[ORPHAN_INO];
 	int err = 0;
 
-	spin_lock(&sbi->ino_lock[ORPHAN_INO]);
-	if (unlikely(sbi->ino_num[ORPHAN_INO] >= sbi->max_orphans))
+	spin_lock(&im->ino_lock);
+	if (unlikely(im->ino_num >= sbi->max_orphans))
 		err = -ENOSPC;
 	else
-		sbi->ino_num[ORPHAN_INO]++;
-	spin_unlock(&sbi->ino_lock[ORPHAN_INO]);
+		im->ino_num++;
+	spin_unlock(&im->ino_lock);
 
 	return err;
 }
 
 void release_orphan_inode(struct f2fs_sb_info *sbi)
 {
-	spin_lock(&sbi->ino_lock[ORPHAN_INO]);
-	f2fs_bug_on(sbi, sbi->ino_num[ORPHAN_INO] == 0);
-	sbi->ino_num[ORPHAN_INO]--;
-	spin_unlock(&sbi->ino_lock[ORPHAN_INO]);
+	struct inode_management *im = &sbi->im[ORPHAN_INO];
+
+	spin_lock(&im->ino_lock);
+	f2fs_bug_on(sbi, im->ino_num == 0);
+	im->ino_num--;
+	spin_unlock(&im->ino_lock);
 }
 
 void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
@@ -465,15 +474,16 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	unsigned short orphan_blocks;
 	struct page *page = NULL;
 	struct ino_entry *orphan = NULL;
+	struct inode_management *im = &sbi->im[ORPHAN_INO];
 
-	orphan_blocks = GET_ORPHAN_BLOCKS(sbi->ino_num[ORPHAN_INO]);
+	orphan_blocks = GET_ORPHAN_BLOCKS(im->ino_num);
 
 	for (index = 0; index < orphan_blocks; index++)
 		grab_meta_page(sbi, start_blk + index);
 
 	index = 1;
-	spin_lock(&sbi->ino_lock[ORPHAN_INO]);
-	head = &sbi->ino_list[ORPHAN_INO];
+	spin_lock(&im->ino_lock);
+	head = &im->ino_list;
 
 	/* loop for each orphan inode entry and write them in Jornal block */
 	list_for_each_entry(orphan, head, list) {
@@ -513,7 +523,7 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 		f2fs_put_page(page, 1);
 	}
 
-	spin_unlock(&sbi->ino_lock[ORPHAN_INO]);
+	spin_unlock(&im->ino_lock);
 }
 
 static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
@@ -836,6 +846,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	struct f2fs_nm_info *nm_i = NM_I(sbi);
+	unsigned long orphan_num = sbi->im[ORPHAN_INO].ino_num;
 	nid_t last_nid = nm_i->next_scan_nid;
 	block_t start_blk;
 	struct page *cp_page;
@@ -895,7 +906,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	else
 		clear_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
 
-	orphan_blocks = GET_ORPHAN_BLOCKS(sbi->ino_num[ORPHAN_INO]);
+	orphan_blocks = GET_ORPHAN_BLOCKS(orphan_num);
 	ckpt->cp_pack_start_sum = cpu_to_le32(1 + cp_payload_blks +
 			orphan_blocks);
 
@@ -911,7 +922,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 				orphan_blocks);
 	}
 
-	if (sbi->ino_num[ORPHAN_INO])
+	if (orphan_num)
 		set_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 	else
 		clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
@@ -946,7 +957,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		f2fs_put_page(cp_page, 1);
 	}
 
-	if (sbi->ino_num[ORPHAN_INO]) {
+	if (orphan_num) {
 		write_orphan_inodes(sbi, start_blk);
 		start_blk += orphan_blocks;
 	}
@@ -1045,10 +1056,12 @@ void init_ino_entry_info(struct f2fs_sb_info *sbi)
 	int i;
 
 	for (i = 0; i < MAX_INO_ENTRY; i++) {
-		INIT_RADIX_TREE(&sbi->ino_root[i], GFP_ATOMIC);
-		spin_lock_init(&sbi->ino_lock[i]);
-		INIT_LIST_HEAD(&sbi->ino_list[i]);
-		sbi->ino_num[i] = 0;
+		struct inode_management *im = &sbi->im[i];
+
+		INIT_RADIX_TREE(&im->ino_root, GFP_ATOMIC);
+		spin_lock_init(&im->ino_lock);
+		INIT_LIST_HEAD(&im->ino_list);
+		im->ino_num = 0;
 	}
 
 	/*

commit 8c402946f0743af91d22eca31d98b058b3371054
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Nov 6 15:16:04 2014 -0800

    f2fs: introduce the number of inode entries
    
    This patch adds to monitor the number of ino entries.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index dd6a357a59de..bcd686e0dded 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -318,6 +318,8 @@ static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 		e->ino = ino;
 
 		list_add_tail(&e->list, &sbi->ino_list[type]);
+		if (type != ORPHAN_INO)
+			sbi->ino_num[type]++;
 	}
 	spin_unlock(&sbi->ino_lock[type]);
 }
@@ -331,8 +333,7 @@ static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 	if (e) {
 		list_del(&e->list);
 		radix_tree_delete(&sbi->ino_root[type], ino);
-		if (type == ORPHAN_INO)
-			sbi->n_orphans--;
+		sbi->ino_num[type]--;
 		spin_unlock(&sbi->ino_lock[type]);
 		kmem_cache_free(ino_entry_slab, e);
 		return;
@@ -373,6 +374,7 @@ void release_dirty_inode(struct f2fs_sb_info *sbi)
 			list_del(&e->list);
 			radix_tree_delete(&sbi->ino_root[i], e->ino);
 			kmem_cache_free(ino_entry_slab, e);
+			sbi->ino_num[i]--;
 		}
 		spin_unlock(&sbi->ino_lock[i]);
 	}
@@ -383,10 +385,10 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 	int err = 0;
 
 	spin_lock(&sbi->ino_lock[ORPHAN_INO]);
-	if (unlikely(sbi->n_orphans >= sbi->max_orphans))
+	if (unlikely(sbi->ino_num[ORPHAN_INO] >= sbi->max_orphans))
 		err = -ENOSPC;
 	else
-		sbi->n_orphans++;
+		sbi->ino_num[ORPHAN_INO]++;
 	spin_unlock(&sbi->ino_lock[ORPHAN_INO]);
 
 	return err;
@@ -395,8 +397,8 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 void release_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	spin_lock(&sbi->ino_lock[ORPHAN_INO]);
-	f2fs_bug_on(sbi, sbi->n_orphans == 0);
-	sbi->n_orphans--;
+	f2fs_bug_on(sbi, sbi->ino_num[ORPHAN_INO] == 0);
+	sbi->ino_num[ORPHAN_INO]--;
 	spin_unlock(&sbi->ino_lock[ORPHAN_INO]);
 }
 
@@ -460,11 +462,12 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	struct f2fs_orphan_block *orphan_blk = NULL;
 	unsigned int nentries = 0;
 	unsigned short index;
-	unsigned short orphan_blocks =
-			(unsigned short)GET_ORPHAN_BLOCKS(sbi->n_orphans);
+	unsigned short orphan_blocks;
 	struct page *page = NULL;
 	struct ino_entry *orphan = NULL;
 
+	orphan_blocks = GET_ORPHAN_BLOCKS(sbi->ino_num[ORPHAN_INO]);
+
 	for (index = 0; index < orphan_blocks; index++)
 		grab_meta_page(sbi, start_blk + index);
 
@@ -892,7 +895,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	else
 		clear_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
 
-	orphan_blocks = GET_ORPHAN_BLOCKS(sbi->n_orphans);
+	orphan_blocks = GET_ORPHAN_BLOCKS(sbi->ino_num[ORPHAN_INO]);
 	ckpt->cp_pack_start_sum = cpu_to_le32(1 + cp_payload_blks +
 			orphan_blocks);
 
@@ -908,7 +911,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 				orphan_blocks);
 	}
 
-	if (sbi->n_orphans)
+	if (sbi->ino_num[ORPHAN_INO])
 		set_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 	else
 		clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
@@ -943,7 +946,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 		f2fs_put_page(cp_page, 1);
 	}
 
-	if (sbi->n_orphans) {
+	if (sbi->ino_num[ORPHAN_INO]) {
 		write_orphan_inodes(sbi, start_blk);
 		start_blk += orphan_blocks;
 	}
@@ -1045,6 +1048,7 @@ void init_ino_entry_info(struct f2fs_sb_info *sbi)
 		INIT_RADIX_TREE(&sbi->ino_root[i], GFP_ATOMIC);
 		spin_lock_init(&sbi->ino_lock[i]);
 		INIT_LIST_HEAD(&sbi->ino_list[i]);
+		sbi->ino_num[i] = 0;
 	}
 
 	/*
@@ -1053,7 +1057,6 @@ void init_ino_entry_info(struct f2fs_sb_info *sbi)
 	 * orphan entries with the limitation one reserved segment
 	 * for cp pack we can have max 1020*504 orphan entries
 	 */
-	sbi->n_orphans = 0;
 	sbi->max_orphans = (sbi->blocks_per_seg - F2FS_CP_PACKS -
 			NR_CURSEG_TYPE) * F2FS_ORPHANS_PER_BLOCK;
 }

commit 6a8f8ca582a1bafe6b620e000316206c8719f1d0
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Wed Oct 29 14:37:22 2014 -0700

    f2fs: avoid race condition in handling wait_io
    
    __submit_merged_bio    f2fs_write_end_io        f2fs_write_end_io
                           wait_io = X              wait_io = x
                           complete(X)              complete(X)
                           wait_io = NULL
    wait_for_completion()
    free(X)
                                                     spin_lock(X)
                                                     kernel panic
    
    In order to avoid this, this patch removes the wait_io facility.
    Instead, we can use wait_on_all_pages_writeback(sbi) to wait for end_ios.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ca514d599b79..dd6a357a59de 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -978,6 +978,9 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 	/* Here, we only have one bio having CP pack */
 	sync_meta_pages(sbi, META_FLUSH, LONG_MAX);
 
+	/* wait for previous submitted meta pages writeback */
+	wait_on_all_pages_writeback(sbi);
+
 	release_dirty_inode(sbi);
 
 	if (unlikely(f2fs_cp_error(sbi)))

commit af41d3ee00bf97bfc3bd64bce6d7a92e85955e98
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Oct 17 14:14:16 2014 -0700

    f2fs: avoid infinite loop at cp_error
    
    This patch avoids an infinite loop in sync_dirty_inode_page when -EIO was
    detected.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index dd10a031c052..ca514d599b79 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -731,6 +731,9 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 	struct dir_inode_entry *entry;
 	struct inode *inode;
 retry:
+	if (unlikely(f2fs_cp_error(sbi)))
+		return;
+
 	spin_lock(&sbi->dir_inode_lock);
 
 	head = &sbi->dir_inode_list;

commit 7cd8558baa4e4588a80ecb31cb30784195763cdd
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Sep 23 11:23:01 2014 -0700

    f2fs: check the use of macros on block counts and addresses
    
    This patch cleans up the existing and new macros for readability.
    
    Rule is like this.
    
             ,-----------------------------------------> MAX_BLKADDR -,
             |  ,------------- TOTAL_BLKS ----------------------------,
             |  |                                                     |
             |  ,- seg0_blkaddr   ,----- sit/nat/ssa/main blkaddress  |
    block    |  | (SEG0_BLKADDR)  | | | |   (e.g., MAIN_BLKADDR)      |
    address  0..x................ a b c d .............................
                |                                                     |
    global seg# 0...................... m .............................
                |                       |                             |
                |                       `------- MAIN_SEGS -----------'
                `-------------- TOTAL_SEGS ---------------------------'
                                        |                             |
     seg#                               0..........xx..................
    
    = Note =
     o GET_SEGNO_FROM_SEG0 : blk address -> global segno
     o GET_SEGNO           : blk address -> segno
     o START_BLOCK         : segno -> starting block address
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4abf0ba01525..dd10a031c052 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -98,7 +98,7 @@ static inline block_t get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
 	case META_CP:
 		return 0;
 	case META_POR:
-		return SM_I(sbi)->seg0_blkaddr + TOTAL_BLKS(sbi);
+		return MAX_BLKADDR(sbi);
 	default:
 		BUG();
 	}
@@ -113,7 +113,6 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 	struct page *page;
 	block_t blkno = start;
 	block_t max_blks = get_max_meta_blks(sbi, type);
-	block_t min_blks = SM_I(sbi)->seg0_blkaddr;
 
 	struct f2fs_io_info fio = {
 		.type = META,
@@ -146,7 +145,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type
 		case META_POR:
 			if (unlikely(blkno >= max_blks))
 				goto out;
-			if (unlikely(blkno < min_blks))
+			if (unlikely(blkno < SEG0_BLKADDR(sbi)))
 				goto out;
 			blk_addr = blkno;
 			break;

commit 4b2fecc84655055a6a1fe9151786992ac04b56ce
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Sat Sep 20 22:06:39 2014 -0700

    f2fs: introduce FITRIM in f2fs_ioctl
    
    This patch introduces FITRIM in f2fs_ioctl.
    In this case, f2fs will issue small discards and prefree discards as many as
    possible for the given area.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index efc530cb74a9..4abf0ba01525 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -997,7 +997,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	mutex_lock(&sbi->cp_mutex);
 
-	if (!sbi->s_dirty)
+	if (!sbi->s_dirty && cpc->reason != CP_DISCARD)
 		goto out;
 	if (unlikely(f2fs_cp_error(sbi)))
 		goto out;
@@ -1020,7 +1020,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 
 	/* write cached NAT/SIT entries to NAT/SIT area */
 	flush_nat_entries(sbi);
-	flush_sit_entries(sbi);
+	flush_sit_entries(sbi, cpc);
 
 	/* unlock all the fs_lock[] in do_checkpoint() */
 	do_checkpoint(sbi, cpc);

commit 75ab4cb8301adb3a02a96c5c03c837ed941f1bc5
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Sat Sep 20 21:57:51 2014 -0700

    f2fs: introduce cp_control structure
    
    This patch add a new data structure to control checkpoint parameters.
    Currently, it presents the reason of checkpoint such as is_umount and normal
    sync.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b4a813345de2..efc530cb74a9 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -826,7 +826,7 @@ static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 	finish_wait(&sbi->cp_wait, &wait);
 }
 
-static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
+static void do_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
@@ -894,7 +894,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	ckpt->cp_pack_start_sum = cpu_to_le32(1 + cp_payload_blks +
 			orphan_blocks);
 
-	if (is_umount) {
+	if (cpc->reason == CP_UMOUNT) {
 		set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
 		ckpt->cp_pack_total_block_count = cpu_to_le32(F2FS_CP_PACKS+
 				cp_payload_blks + data_sum_blocks +
@@ -948,7 +948,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 
 	write_data_summaries(sbi, start_blk);
 	start_blk += data_sum_blocks;
-	if (is_umount) {
+	if (cpc->reason == CP_UMOUNT) {
 		write_node_summaries(sbi, start_blk);
 		start_blk += NR_CURSEG_NODE_TYPE;
 	}
@@ -988,12 +988,12 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 /*
  * We guarantee that this checkpoint procedure will not fail.
  */
-void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
+void write_checkpoint(struct f2fs_sb_info *sbi, struct cp_control *cpc)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	unsigned long long ckpt_ver;
 
-	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "start block_ops");
+	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "start block_ops");
 
 	mutex_lock(&sbi->cp_mutex);
 
@@ -1004,7 +1004,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	if (block_operations(sbi))
 		goto out;
 
-	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish block_ops");
+	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish block_ops");
 
 	f2fs_submit_merged_bio(sbi, DATA, WRITE);
 	f2fs_submit_merged_bio(sbi, NODE, WRITE);
@@ -1023,13 +1023,13 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	flush_sit_entries(sbi);
 
 	/* unlock all the fs_lock[] in do_checkpoint() */
-	do_checkpoint(sbi, is_umount);
+	do_checkpoint(sbi, cpc);
 
 	unblock_operations(sbi);
 	stat_inc_cp_count(sbi->stat_info);
 out:
 	mutex_unlock(&sbi->cp_mutex);
-	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish checkpoint");
+	trace_f2fs_write_checkpoint(sbi->sb, cpc->reason, "finish checkpoint");
 }
 
 void init_ino_entry_info(struct f2fs_sb_info *sbi)

commit 90a893c749f4582f21e97639f4e85e7f2362c2f0
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Sep 22 16:21:07 2014 -0700

    f2fs: use MAX_BIO_BLOCKS(sbi)
    
    This patch cleans up a simple macro.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index a1786d680906..b4a813345de2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -83,8 +83,7 @@ struct page *get_meta_page_ra(struct f2fs_sb_info *sbi, pgoff_t index)
 	f2fs_put_page(page, 0);
 
 	if (readahead)
-		ra_meta_pages(sbi, index,
-				MAX_BIO_BLOCKS(max_hw_blocks(sbi)), META_POR);
+		ra_meta_pages(sbi, index, MAX_BIO_BLOCKS(sbi), META_POR);
 	return get_meta_page(sbi, index);
 }
 

commit 4c521f493b625c7982cf2eae246e86c893f62dfa
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Sep 11 13:49:55 2014 -0700

    f2fs: use meta_inode cache to improve roll-forward speed
    
    Previously, all the dnode pages should be read during the roll-forward recovery.
    Even worsely, whole the chain was traversed twice.
    This patch removes that redundant and costly read operations by using page cache
    of meta_inode and readahead function as well.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d44d287cdae9..a1786d680906 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -72,7 +72,23 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return page;
 }
 
-static inline int get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
+struct page *get_meta_page_ra(struct f2fs_sb_info *sbi, pgoff_t index)
+{
+	bool readahead = false;
+	struct page *page;
+
+	page = find_get_page(META_MAPPING(sbi), index);
+	if (!page || (page && !PageUptodate(page)))
+		readahead = true;
+	f2fs_put_page(page, 0);
+
+	if (readahead)
+		ra_meta_pages(sbi, index,
+				MAX_BIO_BLOCKS(max_hw_blocks(sbi)), META_POR);
+	return get_meta_page(sbi, index);
+}
+
+static inline block_t get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
 {
 	switch (type) {
 	case META_NAT:
@@ -82,6 +98,8 @@ static inline int get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
 	case META_SSA:
 	case META_CP:
 		return 0;
+	case META_POR:
+		return SM_I(sbi)->seg0_blkaddr + TOTAL_BLKS(sbi);
 	default:
 		BUG();
 	}
@@ -90,12 +108,13 @@ static inline int get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
 /*
  * Readahead CP/NAT/SIT/SSA pages
  */
-int ra_meta_pages(struct f2fs_sb_info *sbi, int start, int nrpages, int type)
+int ra_meta_pages(struct f2fs_sb_info *sbi, block_t start, int nrpages, int type)
 {
 	block_t prev_blk_addr = 0;
 	struct page *page;
-	int blkno = start;
-	int max_blks = get_max_meta_blks(sbi, type);
+	block_t blkno = start;
+	block_t max_blks = get_max_meta_blks(sbi, type);
+	block_t min_blks = SM_I(sbi)->seg0_blkaddr;
 
 	struct f2fs_io_info fio = {
 		.type = META,
@@ -125,7 +144,11 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, int start, int nrpages, int type)
 			break;
 		case META_SSA:
 		case META_CP:
-			/* get ssa/cp block addr */
+		case META_POR:
+			if (unlikely(blkno >= max_blks))
+				goto out;
+			if (unlikely(blkno < min_blks))
+				goto out;
 			blk_addr = blkno;
 			break;
 		default:

commit 7704182387f7eab6217a587420f8a3b3aa2d17d5
Author: Huang Ying <ying.huang@intel.com>
Date:   Fri Sep 12 20:19:48 2014 +0800

    f2fs: use nm_i->next_scan_nid as default for next_free_nid
    
    Now, if there is no free nid in nm_i->free_nid_list, 0 may be saved
    into next_free_nid of checkpoint, this may cause useless scanning for
    next mount.  nm_i->next_scan_nid should be a better default value than
    0.
    
    Signed-off-by: Huang, Ying <ying.huang@intel.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5af7e3d1bb6e..d44d287cdae9 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -808,7 +808,8 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
-	nid_t last_nid = 0;
+	struct f2fs_nm_info *nm_i = NM_I(sbi);
+	nid_t last_nid = nm_i->next_scan_nid;
 	block_t start_blk;
 	struct page *cp_page;
 	unsigned int data_sum_blocks, orphan_blocks;

commit a7ffdbe22cecaed59b5d76a5f003d68907d64240
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Sep 12 15:53:45 2014 -0700

    f2fs: expand counting dirty pages in the inode page cache
    
    Previously f2fs only counts dirty dentry pages, but there is no reason not to
    expand the scope.
    
    This patch changes the names on the management of dirty pages and to count
    dirty pages in each inode info as well.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 935a56e03bf6..5af7e3d1bb6e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -627,27 +627,33 @@ static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
 	return 0;
 }
 
-void set_dirty_dir_page(struct inode *inode, struct page *page)
+void update_dirty_page(struct inode *inode, struct page *page)
 {
 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	struct dir_inode_entry *new;
 	int ret = 0;
 
-	if (!S_ISDIR(inode->i_mode))
+	if (!S_ISDIR(inode->i_mode) && !S_ISREG(inode->i_mode))
 		return;
 
+	if (!S_ISDIR(inode->i_mode)) {
+		inode_inc_dirty_pages(inode);
+		goto out;
+	}
+
 	new = f2fs_kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
 	new->inode = inode;
 	INIT_LIST_HEAD(&new->list);
 
 	spin_lock(&sbi->dir_inode_lock);
 	ret = __add_dirty_inode(inode, new);
-	inode_inc_dirty_dents(inode);
-	SetPagePrivate(page);
+	inode_inc_dirty_pages(inode);
 	spin_unlock(&sbi->dir_inode_lock);
 
 	if (ret)
 		kmem_cache_free(inode_entry_slab, new);
+out:
+	SetPagePrivate(page);
 }
 
 void add_dirty_dir_inode(struct inode *inode)
@@ -677,7 +683,7 @@ void remove_dirty_dir_inode(struct inode *inode)
 		return;
 
 	spin_lock(&sbi->dir_inode_lock);
-	if (get_dirty_dents(inode) ||
+	if (get_dirty_pages(inode) ||
 			!is_inode_flag_set(F2FS_I(inode), FI_DIRTY_DIR)) {
 		spin_unlock(&sbi->dir_inode_lock);
 		return;

commit 9850cf4a8908886370b1f15aacf83d291f098c72
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Sep 2 15:52:58 2014 -0700

    f2fs: need fsck.f2fs when f2fs_bug_on is triggered
    
    If any f2fs_bug_on is triggered, fsck.f2fs is needed.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5af97d99106e..935a56e03bf6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -374,7 +374,7 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 void release_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	spin_lock(&sbi->ino_lock[ORPHAN_INO]);
-	f2fs_bug_on(sbi->n_orphans == 0);
+	f2fs_bug_on(sbi, sbi->n_orphans == 0);
 	sbi->n_orphans--;
 	spin_unlock(&sbi->ino_lock[ORPHAN_INO]);
 }
@@ -394,7 +394,7 @@ void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 static void recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	struct inode *inode = f2fs_iget(sbi->sb, ino);
-	f2fs_bug_on(IS_ERR(inode));
+	f2fs_bug_on(sbi, IS_ERR(inode));
 	clear_nlink(inode);
 
 	/* truncate all the data during iput */
@@ -455,7 +455,7 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	list_for_each_entry(orphan, head, list) {
 		if (!page) {
 			page = find_get_page(META_MAPPING(sbi), start_blk++);
-			f2fs_bug_on(!page);
+			f2fs_bug_on(sbi, !page);
 			orphan_blk =
 				(struct f2fs_orphan_block *)page_address(page);
 			memset(orphan_blk, 0, sizeof(*orphan_blk));

commit 2ae4c673e3cbd69bc2decf6d7f5961f3c7b9b38b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Sep 2 15:43:52 2014 -0700

    f2fs: retain inconsistency information to initiate fsck.f2fs
    
    This patch adds sbi->need_fsck to conduct fsck.f2fs later.
    This flag can only be removed by fsck.f2fs.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index cb5cb4ca1814..5af97d99106e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -882,6 +882,9 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	else
 		clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 
+	if (sbi->need_fsck)
+		set_ckpt_flags(ckpt, CP_FSCK_FLAG);
+
 	/* update SIT/NAT bitmap */
 	get_sit_bitmap(sbi, __bitmap_ptr(sbi, SIT_BITMAP));
 	get_nat_bitmap(sbi, __bitmap_ptr(sbi, NAT_BITMAP));

commit 4081363fbe84a7ebac6d3339dd2775df45d856d0
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Sep 2 15:31:18 2014 -0700

    f2fs: introduce F2FS_I_SB, F2FS_M_SB, and F2FS_P_SB
    
    This patch adds three inline functions to clean up dirty casting codes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ec3b7a5381fa..cb5cb4ca1814 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -151,8 +151,7 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, int start, int nrpages, int type)
 static int f2fs_write_meta_page(struct page *page,
 				struct writeback_control *wbc)
 {
-	struct inode *inode = page->mapping->host;
-	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	struct f2fs_sb_info *sbi = F2FS_P_SB(page);
 
 	trace_f2fs_writepage(page, META);
 
@@ -177,7 +176,7 @@ static int f2fs_write_meta_page(struct page *page,
 static int f2fs_write_meta_pages(struct address_space *mapping,
 				struct writeback_control *wbc)
 {
-	struct f2fs_sb_info *sbi = F2FS_SB(mapping->host->i_sb);
+	struct f2fs_sb_info *sbi = F2FS_M_SB(mapping);
 	long diff, written;
 
 	trace_f2fs_writepages(mapping->host, wbc, META);
@@ -259,15 +258,12 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 
 static int f2fs_set_meta_page_dirty(struct page *page)
 {
-	struct address_space *mapping = page->mapping;
-	struct f2fs_sb_info *sbi = F2FS_SB(mapping->host->i_sb);
-
 	trace_f2fs_set_page_dirty(page, META);
 
 	SetPageUptodate(page);
 	if (!PageDirty(page)) {
 		__set_page_dirty_nobuffers(page);
-		inc_page_count(sbi, F2FS_DIRTY_META);
+		inc_page_count(F2FS_P_SB(page), F2FS_DIRTY_META);
 		return 1;
 	}
 	return 0;
@@ -619,7 +615,7 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 
 static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
 {
-	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 
 	if (is_inode_flag_set(F2FS_I(inode), FI_DIRTY_DIR))
 		return -EEXIST;
@@ -633,7 +629,7 @@ static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
 
 void set_dirty_dir_page(struct inode *inode, struct page *page)
 {
-	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	struct dir_inode_entry *new;
 	int ret = 0;
 
@@ -656,7 +652,7 @@ void set_dirty_dir_page(struct inode *inode, struct page *page)
 
 void add_dirty_dir_inode(struct inode *inode)
 {
-	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	struct dir_inode_entry *new =
 			f2fs_kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
 	int ret = 0;
@@ -674,7 +670,7 @@ void add_dirty_dir_inode(struct inode *inode)
 
 void remove_dirty_dir_inode(struct inode *inode)
 {
-	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
 	struct dir_inode_entry *entry;
 
 	if (!S_ISDIR(inode->i_mode))

commit b5b822050ca3c4fc1f475100cc197cc00ba2d492
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Fri Aug 22 16:17:38 2014 +0800

    f2fs: use macro for code readability
    
    This patch introduces DEF_NIDS_PER_INODE/GET_ORPHAN_BLOCKS/F2FS_CP_PACKS macro
    instead of numbers in code for readability.
    
    change log from v1:
     o fix typo pointed out by Jaegeuk Kim.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c9c08d52ecfd..ec3b7a5381fa 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -443,8 +443,8 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	struct f2fs_orphan_block *orphan_blk = NULL;
 	unsigned int nentries = 0;
 	unsigned short index;
-	unsigned short orphan_blocks = (unsigned short)((sbi->n_orphans +
-		(F2FS_ORPHANS_PER_BLOCK - 1)) / F2FS_ORPHANS_PER_BLOCK);
+	unsigned short orphan_blocks =
+			(unsigned short)GET_ORPHAN_BLOCKS(sbi->n_orphans);
 	struct page *page = NULL;
 	struct ino_entry *orphan = NULL;
 
@@ -837,7 +837,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	ckpt->elapsed_time = cpu_to_le64(get_mtime(sbi));
 	ckpt->valid_block_count = cpu_to_le64(valid_user_blocks(sbi));
 	ckpt->free_segment_count = cpu_to_le32(free_segments(sbi));
-	for (i = 0; i < 3; i++) {
+	for (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {
 		ckpt->cur_node_segno[i] =
 			cpu_to_le32(curseg_segno(sbi, i + CURSEG_HOT_NODE));
 		ckpt->cur_node_blkoff[i] =
@@ -845,7 +845,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 		ckpt->alloc_type[i + CURSEG_HOT_NODE] =
 				curseg_alloc_type(sbi, i + CURSEG_HOT_NODE);
 	}
-	for (i = 0; i < 3; i++) {
+	for (i = 0; i < NR_CURSEG_DATA_TYPE; i++) {
 		ckpt->cur_data_segno[i] =
 			cpu_to_le32(curseg_segno(sbi, i + CURSEG_HOT_DATA));
 		ckpt->cur_data_blkoff[i] =
@@ -860,24 +860,23 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 
 	/* 2 cp  + n data seg summary + orphan inode blocks */
 	data_sum_blocks = npages_for_summary_flush(sbi);
-	if (data_sum_blocks < 3)
+	if (data_sum_blocks < NR_CURSEG_DATA_TYPE)
 		set_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
 	else
 		clear_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
 
-	orphan_blocks = (sbi->n_orphans + F2FS_ORPHANS_PER_BLOCK - 1)
-					/ F2FS_ORPHANS_PER_BLOCK;
+	orphan_blocks = GET_ORPHAN_BLOCKS(sbi->n_orphans);
 	ckpt->cp_pack_start_sum = cpu_to_le32(1 + cp_payload_blks +
 			orphan_blocks);
 
 	if (is_umount) {
 		set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
-		ckpt->cp_pack_total_block_count = cpu_to_le32(2 +
+		ckpt->cp_pack_total_block_count = cpu_to_le32(F2FS_CP_PACKS+
 				cp_payload_blks + data_sum_blocks +
 				orphan_blocks + NR_CURSEG_NODE_TYPE);
 	} else {
 		clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
-		ckpt->cp_pack_total_block_count = cpu_to_le32(2 +
+		ckpt->cp_pack_total_block_count = cpu_to_le32(F2FS_CP_PACKS +
 				cp_payload_blks + data_sum_blocks +
 				orphan_blocks);
 	}
@@ -1022,8 +1021,8 @@ void init_ino_entry_info(struct f2fs_sb_info *sbi)
 	 * for cp pack we can have max 1020*504 orphan entries
 	 */
 	sbi->n_orphans = 0;
-	sbi->max_orphans = (sbi->blocks_per_seg - 2 - NR_CURSEG_TYPE)
-				* F2FS_ORPHANS_PER_BLOCK;
+	sbi->max_orphans = (sbi->blocks_per_seg - F2FS_CP_PACKS -
+			NR_CURSEG_TYPE) * F2FS_ORPHANS_PER_BLOCK;
 }
 
 int __init create_checkpoint_caches(void)

commit cf779cab14d50a84b61399f758da269654b863db
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Aug 11 18:37:46 2014 -0700

    f2fs: handle EIO not to break fs consistency
    
    There are two rules when EIO is occurred.
    1. don't write any checkpoint data to preserve the previous checkpoint
    2. don't lose the cached dentry/node/meta pages
    
    So, at first, this patch adds set_page_dirty in f2fs_write_end_io's failure.
    Then, writing checkpoint/dentry/node blocks is not allowed.
    
    Note that, for the data pages, we can't just throw away by redirtying them.
    Otherwise, kworker can fall into infinite loop to flush them.
    (Ref. xfstests/019)
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index dc29b7837687..c9c08d52ecfd 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -160,14 +160,11 @@ static int f2fs_write_meta_page(struct page *page,
 		goto redirty_out;
 	if (wbc->for_reclaim)
 		goto redirty_out;
-
-	/* Should not write any meta pages, if any IO error was occurred */
 	if (unlikely(f2fs_cp_error(sbi)))
-		goto no_write;
+		goto redirty_out;
 
 	f2fs_wait_on_page_writeback(page, META);
 	write_meta_page(sbi, page);
-no_write:
 	dec_page_count(sbi, F2FS_DIRTY_META);
 	unlock_page(page);
 	return 0;
@@ -737,7 +734,7 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 /*
  * Freeze all the FS-operations for checkpoint.
  */
-static void block_operations(struct f2fs_sb_info *sbi)
+static int block_operations(struct f2fs_sb_info *sbi)
 {
 	struct writeback_control wbc = {
 		.sync_mode = WB_SYNC_ALL,
@@ -745,6 +742,7 @@ static void block_operations(struct f2fs_sb_info *sbi)
 		.for_reclaim = 0,
 	};
 	struct blk_plug plug;
+	int err = 0;
 
 	blk_start_plug(&plug);
 
@@ -754,6 +752,10 @@ static void block_operations(struct f2fs_sb_info *sbi)
 	if (get_pages(sbi, F2FS_DIRTY_DENTS)) {
 		f2fs_unlock_all(sbi);
 		sync_dirty_dir_inodes(sbi);
+		if (unlikely(f2fs_cp_error(sbi))) {
+			err = -EIO;
+			goto out;
+		}
 		goto retry_flush_dents;
 	}
 
@@ -767,9 +769,16 @@ static void block_operations(struct f2fs_sb_info *sbi)
 	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
 		up_write(&sbi->node_write);
 		sync_node_pages(sbi, 0, &wbc);
+		if (unlikely(f2fs_cp_error(sbi))) {
+			f2fs_unlock_all(sbi);
+			err = -EIO;
+			goto out;
+		}
 		goto retry_flush_nodes;
 	}
+out:
 	blk_finish_plug(&plug);
+	return err;
 }
 
 static void unblock_operations(struct f2fs_sb_info *sbi)
@@ -813,8 +822,11 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	discard_next_dnode(sbi, NEXT_FREE_BLKADDR(sbi, curseg));
 
 	/* Flush all the NAT/SIT pages */
-	while (get_pages(sbi, F2FS_DIRTY_META))
+	while (get_pages(sbi, F2FS_DIRTY_META)) {
 		sync_meta_pages(sbi, META, LONG_MAX);
+		if (unlikely(f2fs_cp_error(sbi)))
+			return;
+	}
 
 	next_free_nid(sbi, &last_nid);
 
@@ -924,6 +936,9 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	/* wait for previous submitted node/meta pages writeback */
 	wait_on_all_pages_writeback(sbi);
 
+	if (unlikely(f2fs_cp_error(sbi)))
+		return;
+
 	filemap_fdatawait_range(NODE_MAPPING(sbi), 0, LONG_MAX);
 	filemap_fdatawait_range(META_MAPPING(sbi), 0, LONG_MAX);
 
@@ -934,11 +949,13 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	/* Here, we only have one bio having CP pack */
 	sync_meta_pages(sbi, META_FLUSH, LONG_MAX);
 
-	if (!f2fs_cp_error(sbi)) {
-		clear_prefree_segments(sbi);
-		release_dirty_inode(sbi);
-		F2FS_RESET_SB_DIRT(sbi);
-	}
+	release_dirty_inode(sbi);
+
+	if (unlikely(f2fs_cp_error(sbi)))
+		return;
+
+	clear_prefree_segments(sbi);
+	F2FS_RESET_SB_DIRT(sbi);
 }
 
 /*
@@ -955,8 +972,10 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 
 	if (!sbi->s_dirty)
 		goto out;
-
-	block_operations(sbi);
+	if (unlikely(f2fs_cp_error(sbi)))
+		goto out;
+	if (block_operations(sbi))
+		goto out;
 
 	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish block_ops");
 

commit 8501017e50fb7586ba522a2913ce664d6c2024f6
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Aug 11 18:37:46 2014 -0700

    f2fs: check s_dirty under cp_mutex
    
    It needs to check s_dirty under cp_mutex, since s_dirty is reset under that
    mutex.
    And previous condition was not correct, since we can omit doing checkpoint
    when checkpoint was done followed by all the node pages were written back.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6f38aad8e654..dc29b7837687 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -952,6 +952,10 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "start block_ops");
 
 	mutex_lock(&sbi->cp_mutex);
+
+	if (!sbi->s_dirty)
+		goto out;
+
 	block_operations(sbi);
 
 	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish block_ops");
@@ -976,9 +980,9 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	do_checkpoint(sbi, is_umount);
 
 	unblock_operations(sbi);
-	mutex_unlock(&sbi->cp_mutex);
-
 	stat_inc_cp_count(sbi->stat_info);
+out:
+	mutex_unlock(&sbi->cp_mutex);
 	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish checkpoint");
 }
 

commit 1e968fdfe69e4060f05fa04059ecad93a0284e32
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Mon Aug 11 16:49:25 2014 -0700

    f2fs: introduce f2fs_cp_error for readability
    
    This patch adds f2fs_cp_error for readability.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f14af912a146..6f38aad8e654 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -162,7 +162,7 @@ static int f2fs_write_meta_page(struct page *page,
 		goto redirty_out;
 
 	/* Should not write any meta pages, if any IO error was occurred */
-	if (unlikely(is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ERROR_FLAG)))
+	if (unlikely(f2fs_cp_error(sbi)))
 		goto no_write;
 
 	f2fs_wait_on_page_writeback(page, META);
@@ -934,7 +934,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	/* Here, we only have one bio having CP pack */
 	sync_meta_pages(sbi, META_FLUSH, LONG_MAX);
 
-	if (!is_set_ckpt_flags(ckpt, CP_ERROR_FLAG)) {
+	if (!f2fs_cp_error(sbi)) {
 		clear_prefree_segments(sbi);
 		release_dirty_inode(sbi);
 		F2FS_RESET_SB_DIRT(sbi);

commit 6f12ac25f0167adb5d9ad5547fd6838380261e5c
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Tue Aug 19 09:48:22 2014 -0700

    f2fs: trigger release_dirty_inode in f2fs_put_super
    
    The generic_shutdown_super calls sync_filesystem, evict_inode, and then
    f2fs_put_super. In f2fs_evict_inode, we remain some dirty inode information
    so we should release them at f2fs_put_super.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7e1c13bfb99f..f14af912a146 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -348,7 +348,7 @@ bool exist_written_data(struct f2fs_sb_info *sbi, nid_t ino, int mode)
 	return e ? true : false;
 }
 
-static void release_dirty_inode(struct f2fs_sb_info *sbi)
+void release_dirty_inode(struct f2fs_sb_info *sbi)
 {
 	struct ino_entry *e, *tmp;
 	int i;

commit e1c42045203071c4634b89e696037357810d3083
Author: arter97 <qkrwngud825@gmail.com>
Date:   Wed Aug 6 23:22:50 2014 +0900

    f2fs: fix typo
    
    Fix typo and some grammatical errors.
    
    The words "filesystem" and "readahead" are being used without the space treewide.
    
    Signed-off-by: Park Ju Hyung <qkrwngud825@gmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6aeed5bada52..7e1c13bfb99f 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -758,7 +758,7 @@ static void block_operations(struct f2fs_sb_info *sbi)
 	}
 
 	/*
-	 * POR: we should ensure that there is no dirty node pages
+	 * POR: we should ensure that there are no dirty node pages
 	 * until finishing nat/sit flush.
 	 */
 retry_flush_nodes:
@@ -942,7 +942,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 }
 
 /*
- * We guarantee that this checkpoint procedure should not fail.
+ * We guarantee that this checkpoint procedure will not fail.
  */
 void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 {

commit b3582c68920105e29d219714d8a6fbde25a43379
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Jul 3 18:58:39 2014 +0800

    f2fs: reduce competition among node page writes
    
    We do not need to block on ->node_write among different node page writers e.g.
    fsync/flush, unless we have a node page writer from write_checkpoint.
    So it's better use rw_semaphore instead of mutex type for ->node_write to
    promote performance.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index cea20b810f44..6aeed5bada52 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -762,10 +762,10 @@ static void block_operations(struct f2fs_sb_info *sbi)
 	 * until finishing nat/sit flush.
 	 */
 retry_flush_nodes:
-	mutex_lock(&sbi->node_write);
+	down_write(&sbi->node_write);
 
 	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
-		mutex_unlock(&sbi->node_write);
+		up_write(&sbi->node_write);
 		sync_node_pages(sbi, 0, &wbc);
 		goto retry_flush_nodes;
 	}
@@ -774,7 +774,7 @@ static void block_operations(struct f2fs_sb_info *sbi)
 
 static void unblock_operations(struct f2fs_sb_info *sbi)
 {
-	mutex_unlock(&sbi->node_write);
+	up_write(&sbi->node_write);
 	f2fs_unlock_all(sbi);
 }
 

commit cf2271e781cb16e1ca22be920010c2b64d90c338
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jul 25 15:47:25 2014 -0700

    f2fs: avoid retrying wrong recovery routine when error was occurred
    
    This patch eliminates the propagation of recovery errors to the next mount.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 26b94bbc826c..cea20b810f44 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -796,6 +796,7 @@ static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
 static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
+	struct curseg_info *curseg = CURSEG_I(sbi, CURSEG_WARM_NODE);
 	nid_t last_nid = 0;
 	block_t start_blk;
 	struct page *cp_page;
@@ -809,7 +810,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	 * This avoids to conduct wrong roll-forward operations and uses
 	 * metapages, so should be called prior to sync_meta_pages below.
 	 */
-	discard_next_dnode(sbi);
+	discard_next_dnode(sbi, NEXT_FREE_BLKADDR(sbi, curseg));
 
 	/* Flush all the NAT/SIT pages */
 	while (get_pages(sbi, F2FS_DIRTY_META))

commit 01229f5e1b21b378863c91f8c653bbd8e593858c
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jul 25 07:41:43 2014 -0700

    f2fs: fix wrong condition for unlikely
    
    This patch fixes the wrongly used unlikely condition.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 430163d8c806..26b94bbc826c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -933,7 +933,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	/* Here, we only have one bio having CP pack */
 	sync_meta_pages(sbi, META_FLUSH, LONG_MAX);
 
-	if (unlikely(!is_set_ckpt_flags(ckpt, CP_ERROR_FLAG))) {
+	if (!is_set_ckpt_flags(ckpt, CP_ERROR_FLAG)) {
 		clear_prefree_segments(sbi);
 		release_dirty_inode(sbi);
 		F2FS_RESET_SB_DIRT(sbi);

commit fff04f90c1b9f91b9c513a89702a4b9ffe5dc1c5
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jul 25 07:40:59 2014 -0700

    f2fs: add info of appended or updated data writes
    
    This patch introduces a inode number list in which represents inodes having
    appended data writes or updated data writes after last checkpoint.
    This will be used at fsync to determine whether the recovery information
    should be written or not.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4bf203756cf8..430163d8c806 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -326,6 +326,44 @@ static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 	spin_unlock(&sbi->ino_lock[type]);
 }
 
+void add_dirty_inode(struct f2fs_sb_info *sbi, nid_t ino, int type)
+{
+	/* add new dirty ino entry into list */
+	__add_ino_entry(sbi, ino, type);
+}
+
+void remove_dirty_inode(struct f2fs_sb_info *sbi, nid_t ino, int type)
+{
+	/* remove dirty ino entry from list */
+	__remove_ino_entry(sbi, ino, type);
+}
+
+/* mode should be APPEND_INO or UPDATE_INO */
+bool exist_written_data(struct f2fs_sb_info *sbi, nid_t ino, int mode)
+{
+	struct ino_entry *e;
+	spin_lock(&sbi->ino_lock[mode]);
+	e = radix_tree_lookup(&sbi->ino_root[mode], ino);
+	spin_unlock(&sbi->ino_lock[mode]);
+	return e ? true : false;
+}
+
+static void release_dirty_inode(struct f2fs_sb_info *sbi)
+{
+	struct ino_entry *e, *tmp;
+	int i;
+
+	for (i = APPEND_INO; i <= UPDATE_INO; i++) {
+		spin_lock(&sbi->ino_lock[i]);
+		list_for_each_entry_safe(e, tmp, &sbi->ino_list[i], list) {
+			list_del(&e->list);
+			radix_tree_delete(&sbi->ino_root[i], e->ino);
+			kmem_cache_free(ino_entry_slab, e);
+		}
+		spin_unlock(&sbi->ino_lock[i]);
+	}
+}
+
 int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	int err = 0;
@@ -897,6 +935,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 
 	if (unlikely(!is_set_ckpt_flags(ckpt, CP_ERROR_FLAG))) {
 		clear_prefree_segments(sbi);
+		release_dirty_inode(sbi);
 		F2FS_RESET_SB_DIRT(sbi);
 	}
 }

commit 39efac41fbe44343cac29472320a1d502fcff66b
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Thu Jul 24 18:15:17 2014 -0700

    f2fs: use radix_tree for ino management
    
    For better ino management, this patch replaces the data structure from list
    to radix tree.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f93d154e2770..4bf203756cf8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -284,24 +284,27 @@ const struct address_space_operations f2fs_meta_aops = {
 
 static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
-	struct ino_entry *new, *e;
-
-	new = f2fs_kmem_cache_alloc(ino_entry_slab, GFP_ATOMIC);
-	new->ino = ino;
-
+	struct ino_entry *e;
+retry:
 	spin_lock(&sbi->ino_lock[type]);
-	list_for_each_entry(e, &sbi->ino_list[type], list) {
-		if (e->ino == ino) {
+
+	e = radix_tree_lookup(&sbi->ino_root[type], ino);
+	if (!e) {
+		e = kmem_cache_alloc(ino_entry_slab, GFP_ATOMIC);
+		if (!e) {
 			spin_unlock(&sbi->ino_lock[type]);
-			kmem_cache_free(ino_entry_slab, new);
-			return;
+			goto retry;
 		}
-		if (e->ino > ino)
-			break;
-	}
+		if (radix_tree_insert(&sbi->ino_root[type], ino, e)) {
+			spin_unlock(&sbi->ino_lock[type]);
+			kmem_cache_free(ino_entry_slab, e);
+			goto retry;
+		}
+		memset(e, 0, sizeof(struct ino_entry));
+		e->ino = ino;
 
-	/* add new entry into list which is sorted by inode number */
-	list_add_tail(&new->list, &e->list);
+		list_add_tail(&e->list, &sbi->ino_list[type]);
+	}
 	spin_unlock(&sbi->ino_lock[type]);
 }
 
@@ -310,14 +313,15 @@ static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 	struct ino_entry *e;
 
 	spin_lock(&sbi->ino_lock[type]);
-	list_for_each_entry(e, &sbi->ino_list[type], list) {
-		if (e->ino == ino) {
-			list_del(&e->list);
+	e = radix_tree_lookup(&sbi->ino_root[type], ino);
+	if (e) {
+		list_del(&e->list);
+		radix_tree_delete(&sbi->ino_root[type], ino);
+		if (type == ORPHAN_INO)
 			sbi->n_orphans--;
-			spin_unlock(&sbi->ino_lock[type]);
-			kmem_cache_free(ino_entry_slab, e);
-			return;
-		}
+		spin_unlock(&sbi->ino_lock[type]);
+		kmem_cache_free(ino_entry_slab, e);
+		return;
 	}
 	spin_unlock(&sbi->ino_lock[type]);
 }
@@ -346,7 +350,7 @@ void release_orphan_inode(struct f2fs_sb_info *sbi)
 
 void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
-	/* add new orphan entry into list which is sorted by inode number */
+	/* add new orphan ino entry into list */
 	__add_ino_entry(sbi, ino, ORPHAN_INO);
 }
 
@@ -943,6 +947,7 @@ void init_ino_entry_info(struct f2fs_sb_info *sbi)
 	int i;
 
 	for (i = 0; i < MAX_INO_ENTRY; i++) {
+		INIT_RADIX_TREE(&sbi->ino_root[i], GFP_ATOMIC);
 		spin_lock_init(&sbi->ino_lock[i]);
 		INIT_LIST_HEAD(&sbi->ino_list[i]);
 	}

commit 6451e041c8d39daf39c71eefe839641c2093713e
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jul 25 15:47:17 2014 -0700

    f2fs: add infra for ino management
    
    This patch changes the naming of orphan-related data structures to use as
    inode numbers managed globally.
    Later, we can use this facility for managing any inode number lists.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 1c6eb6bcfd99..f93d154e2770 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -22,7 +22,7 @@
 #include "segment.h"
 #include <trace/events/f2fs.h>
 
-static struct kmem_cache *orphan_entry_slab;
+static struct kmem_cache *ino_entry_slab;
 static struct kmem_cache *inode_entry_slab;
 
 /*
@@ -282,19 +282,18 @@ const struct address_space_operations f2fs_meta_aops = {
 	.set_page_dirty	= f2fs_set_meta_page_dirty,
 };
 
-static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino)
+static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
-	struct list_head *head;
-	struct orphan_inode_entry *new, *e;
+	struct ino_entry *new, *e;
 
-	new = f2fs_kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
+	new = f2fs_kmem_cache_alloc(ino_entry_slab, GFP_ATOMIC);
 	new->ino = ino;
 
-	spin_lock(&sbi->orphan_inode_lock);
-	list_for_each_entry(e, &sbi->orphan_inode_list, list) {
+	spin_lock(&sbi->ino_lock[type]);
+	list_for_each_entry(e, &sbi->ino_list[type], list) {
 		if (e->ino == ino) {
-			spin_unlock(&sbi->orphan_inode_lock);
-			kmem_cache_free(orphan_entry_slab, new);
+			spin_unlock(&sbi->ino_lock[type]);
+			kmem_cache_free(ino_entry_slab, new);
 			return;
 		}
 		if (e->ino > ino)
@@ -303,58 +302,58 @@ static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino)
 
 	/* add new entry into list which is sorted by inode number */
 	list_add_tail(&new->list, &e->list);
-	spin_unlock(&sbi->orphan_inode_lock);
+	spin_unlock(&sbi->ino_lock[type]);
 }
 
-static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino)
+static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino, int type)
 {
-	struct orphan_inode_entry *e;
+	struct ino_entry *e;
 
-	spin_lock(&sbi->orphan_inode_lock);
-	list_for_each_entry(e, &sbi->orphan_inode_list, list) {
+	spin_lock(&sbi->ino_lock[type]);
+	list_for_each_entry(e, &sbi->ino_list[type], list) {
 		if (e->ino == ino) {
 			list_del(&e->list);
 			sbi->n_orphans--;
-			spin_unlock(&sbi->orphan_inode_lock);
-			kmem_cache_free(orphan_entry_slab, e);
+			spin_unlock(&sbi->ino_lock[type]);
+			kmem_cache_free(ino_entry_slab, e);
 			return;
 		}
 	}
-	spin_unlock(&sbi->orphan_inode_lock);
+	spin_unlock(&sbi->ino_lock[type]);
 }
 
 int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	int err = 0;
 
-	spin_lock(&sbi->orphan_inode_lock);
+	spin_lock(&sbi->ino_lock[ORPHAN_INO]);
 	if (unlikely(sbi->n_orphans >= sbi->max_orphans))
 		err = -ENOSPC;
 	else
 		sbi->n_orphans++;
-	spin_unlock(&sbi->orphan_inode_lock);
+	spin_unlock(&sbi->ino_lock[ORPHAN_INO]);
 
 	return err;
 }
 
 void release_orphan_inode(struct f2fs_sb_info *sbi)
 {
-	spin_lock(&sbi->orphan_inode_lock);
+	spin_lock(&sbi->ino_lock[ORPHAN_INO]);
 	f2fs_bug_on(sbi->n_orphans == 0);
 	sbi->n_orphans--;
-	spin_unlock(&sbi->orphan_inode_lock);
+	spin_unlock(&sbi->ino_lock[ORPHAN_INO]);
 }
 
 void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	/* add new orphan entry into list which is sorted by inode number */
-	__add_ino_entry(sbi, ino);
+	__add_ino_entry(sbi, ino, ORPHAN_INO);
 }
 
 void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	/* remove orphan entry from orphan list */
-	__remove_ino_entry(sbi, ino);
+	__remove_ino_entry(sbi, ino, ORPHAN_INO);
 }
 
 static void recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
@@ -408,14 +407,14 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	unsigned short orphan_blocks = (unsigned short)((sbi->n_orphans +
 		(F2FS_ORPHANS_PER_BLOCK - 1)) / F2FS_ORPHANS_PER_BLOCK);
 	struct page *page = NULL;
-	struct orphan_inode_entry *orphan = NULL;
+	struct ino_entry *orphan = NULL;
 
 	for (index = 0; index < orphan_blocks; index++)
 		grab_meta_page(sbi, start_blk + index);
 
 	index = 1;
-	spin_lock(&sbi->orphan_inode_lock);
-	head = &sbi->orphan_inode_list;
+	spin_lock(&sbi->ino_lock[ORPHAN_INO]);
+	head = &sbi->ino_list[ORPHAN_INO];
 
 	/* loop for each orphan inode entry and write them in Jornal block */
 	list_for_each_entry(orphan, head, list) {
@@ -455,7 +454,7 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 		f2fs_put_page(page, 1);
 	}
 
-	spin_unlock(&sbi->orphan_inode_lock);
+	spin_unlock(&sbi->ino_lock[ORPHAN_INO]);
 }
 
 static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
@@ -939,31 +938,36 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish checkpoint");
 }
 
-void init_orphan_info(struct f2fs_sb_info *sbi)
+void init_ino_entry_info(struct f2fs_sb_info *sbi)
 {
-	spin_lock_init(&sbi->orphan_inode_lock);
-	INIT_LIST_HEAD(&sbi->orphan_inode_list);
-	sbi->n_orphans = 0;
+	int i;
+
+	for (i = 0; i < MAX_INO_ENTRY; i++) {
+		spin_lock_init(&sbi->ino_lock[i]);
+		INIT_LIST_HEAD(&sbi->ino_list[i]);
+	}
+
 	/*
 	 * considering 512 blocks in a segment 8 blocks are needed for cp
 	 * and log segment summaries. Remaining blocks are used to keep
 	 * orphan entries with the limitation one reserved segment
 	 * for cp pack we can have max 1020*504 orphan entries
 	 */
+	sbi->n_orphans = 0;
 	sbi->max_orphans = (sbi->blocks_per_seg - 2 - NR_CURSEG_TYPE)
 				* F2FS_ORPHANS_PER_BLOCK;
 }
 
 int __init create_checkpoint_caches(void)
 {
-	orphan_entry_slab = f2fs_kmem_cache_create("f2fs_orphan_entry",
-			sizeof(struct orphan_inode_entry));
-	if (!orphan_entry_slab)
+	ino_entry_slab = f2fs_kmem_cache_create("f2fs_ino_entry",
+			sizeof(struct ino_entry));
+	if (!ino_entry_slab)
 		return -ENOMEM;
 	inode_entry_slab = f2fs_kmem_cache_create("f2fs_dirty_dir_entry",
 			sizeof(struct dir_inode_entry));
 	if (!inode_entry_slab) {
-		kmem_cache_destroy(orphan_entry_slab);
+		kmem_cache_destroy(ino_entry_slab);
 		return -ENOMEM;
 	}
 	return 0;
@@ -971,6 +975,6 @@ int __init create_checkpoint_caches(void)
 
 void destroy_checkpoint_caches(void)
 {
-	kmem_cache_destroy(orphan_entry_slab);
+	kmem_cache_destroy(ino_entry_slab);
 	kmem_cache_destroy(inode_entry_slab);
 }

commit 953e6cc6bcb615dfa373320ffa62b574c6be608a
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Jul 25 15:47:16 2014 -0700

    f2fs: punch the core function for inode management
    
    This patch punches out the core functions to manage the inode numbers.
    
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0b4710c1d370..1c6eb6bcfd99 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -282,6 +282,47 @@ const struct address_space_operations f2fs_meta_aops = {
 	.set_page_dirty	= f2fs_set_meta_page_dirty,
 };
 
+static void __add_ino_entry(struct f2fs_sb_info *sbi, nid_t ino)
+{
+	struct list_head *head;
+	struct orphan_inode_entry *new, *e;
+
+	new = f2fs_kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
+	new->ino = ino;
+
+	spin_lock(&sbi->orphan_inode_lock);
+	list_for_each_entry(e, &sbi->orphan_inode_list, list) {
+		if (e->ino == ino) {
+			spin_unlock(&sbi->orphan_inode_lock);
+			kmem_cache_free(orphan_entry_slab, new);
+			return;
+		}
+		if (e->ino > ino)
+			break;
+	}
+
+	/* add new entry into list which is sorted by inode number */
+	list_add_tail(&new->list, &e->list);
+	spin_unlock(&sbi->orphan_inode_lock);
+}
+
+static void __remove_ino_entry(struct f2fs_sb_info *sbi, nid_t ino)
+{
+	struct orphan_inode_entry *e;
+
+	spin_lock(&sbi->orphan_inode_lock);
+	list_for_each_entry(e, &sbi->orphan_inode_list, list) {
+		if (e->ino == ino) {
+			list_del(&e->list);
+			sbi->n_orphans--;
+			spin_unlock(&sbi->orphan_inode_lock);
+			kmem_cache_free(orphan_entry_slab, e);
+			return;
+		}
+	}
+	spin_unlock(&sbi->orphan_inode_lock);
+}
+
 int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	int err = 0;
@@ -306,48 +347,14 @@ void release_orphan_inode(struct f2fs_sb_info *sbi)
 
 void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
-	struct list_head *head;
-	struct orphan_inode_entry *new, *orphan;
-
-	new = f2fs_kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
-	new->ino = ino;
-
-	spin_lock(&sbi->orphan_inode_lock);
-	head = &sbi->orphan_inode_list;
-	list_for_each_entry(orphan, head, list) {
-		if (orphan->ino == ino) {
-			spin_unlock(&sbi->orphan_inode_lock);
-			kmem_cache_free(orphan_entry_slab, new);
-			return;
-		}
-
-		if (orphan->ino > ino)
-			break;
-	}
-
 	/* add new orphan entry into list which is sorted by inode number */
-	list_add_tail(&new->list, &orphan->list);
-	spin_unlock(&sbi->orphan_inode_lock);
+	__add_ino_entry(sbi, ino);
 }
 
 void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
-	struct list_head *head;
-	struct orphan_inode_entry *orphan;
-
-	spin_lock(&sbi->orphan_inode_lock);
-	head = &sbi->orphan_inode_list;
-	list_for_each_entry(orphan, head, list) {
-		if (orphan->ino == ino) {
-			list_del(&orphan->list);
-			f2fs_bug_on(sbi->n_orphans == 0);
-			sbi->n_orphans--;
-			spin_unlock(&sbi->orphan_inode_lock);
-			kmem_cache_free(orphan_entry_slab, orphan);
-			return;
-		}
-	}
-	spin_unlock(&sbi->orphan_inode_lock);
+	/* remove orphan entry from orphan list */
+	__remove_ino_entry(sbi, ino);
 }
 
 static void recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)

commit 64b2d1fbbfda07765dae3f601862796a61b2c451
Merge: b1cce8032f6a 9ab701349247
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 9 19:11:44 2014 -0700

    Merge tag 'for-f2fs-3.16' of git://git.kernel.org/pub/scm/linux/kernel/git/jaegeuk/f2fs
    
    Pull f2fs updates from Jaegeuk Kim:
     "In this round, there is no special interesting feature, but we've
      investigated a couple of tuning points with respect to the I/O flow.
      Several major bug fixes and a bunch of clean-ups also have been made.
    
      This patch-set includes the following major enhancement patches:
       - enhance wait_on_page_writeback
       - support SEEK_DATA and SEEK_HOLE
       - enhance readahead flows
       - enhance IO flushes
       - support fiemap
       - add some tracepoints
    
      The other bug fixes are as follows:
       - fix to support a large volume > 2TB correctly
       - recovery bug fix wrt fallocated space
       - fix recursive lock on xattr operations
       - fix some cases on the remount flow
    
      And, there are a bunch of cleanups"
    
    * tag 'for-f2fs-3.16' of git://git.kernel.org/pub/scm/linux/kernel/git/jaegeuk/f2fs: (52 commits)
      f2fs: support f2fs_fiemap
      f2fs: avoid not to call remove_dirty_inode
      f2fs: recover fallocated space
      f2fs: fix to recover data written by dio
      f2fs: large volume support
      f2fs: avoid crash when trace f2fs_submit_page_mbio event in ra_sum_pages
      f2fs: avoid overflow when large directory feathure is enabled
      f2fs: fix recursive lock by f2fs_setxattr
      MAINTAINERS: add a co-maintainer from samsung for F2FS
      MAINTAINERS: change the email address for f2fs
      f2fs: use inode_init_owner() to simplify codes
      f2fs: avoid to use slab memory in f2fs_issue_flush for efficiency
      f2fs: add a tracepoint for f2fs_read_data_page
      f2fs: add a tracepoint for f2fs_write_{meta,node,data}_pages
      f2fs: add a tracepoint for f2fs_write_{meta,node,data}_page
      f2fs: add a tracepoint for f2fs_write_end
      f2fs: add a tracepoint for f2fs_write_begin
      f2fs: fix checkpatch warning
      f2fs: deactivate inode page if the inode is evicted
      f2fs: decrease the lock granularity during write_begin
      ...

commit 2457aec63745e235bcafb7ef312b182d8682f0fc
Author: Mel Gorman <mgorman@suse.de>
Date:   Wed Jun 4 16:10:31 2014 -0700

    mm: non-atomically mark page accessed during page cache allocation where possible
    
    aops->write_begin may allocate a new page and make it visible only to have
    mark_page_accessed called almost immediately after.  Once the page is
    visible the atomic operations are necessary which is noticable overhead
    when writing to an in-memory filesystem like tmpfs but should also be
    noticable with fast storage.  The objective of the patch is to initialse
    the accessed information with non-atomic operations before the page is
    visible.
    
    The bulk of filesystems directly or indirectly use
    grab_cache_page_write_begin or find_or_create_page for the initial
    allocation of a page cache page.  This patch adds an init_page_accessed()
    helper which behaves like the first call to mark_page_accessed() but may
    called before the page is visible and can be done non-atomically.
    
    The primary APIs of concern in this care are the following and are used
    by most filesystems.
    
            find_get_page
            find_lock_page
            find_or_create_page
            grab_cache_page_nowait
            grab_cache_page_write_begin
    
    All of them are very similar in detail to the patch creates a core helper
    pagecache_get_page() which takes a flags parameter that affects its
    behavior such as whether the page should be marked accessed or not.  Then
    old API is preserved but is basically a thin wrapper around this core
    function.
    
    Each of the filesystems are then updated to avoid calling
    mark_page_accessed when it is known that the VM interfaces have already
    done the job.  There is a slight snag in that the timing of the
    mark_page_accessed() has now changed so in rare cases it's possible a page
    gets to the end of the LRU as PageReferenced where as previously it might
    have been repromoted.  This is expected to be rare but it's worth the
    filesystem people thinking about it in case they see a problem with the
    timing change.  It is also the case that some filesystems may be marking
    pages accessed that previously did not but it makes sense that filesystems
    have consistent behaviour in this regard.
    
    The test case used to evaulate this is a simple dd of a large file done
    multiple times with the file deleted on each iterations.  The size of the
    file is 1/10th physical memory to avoid dirty page balancing.  In the
    async case it will be possible that the workload completes without even
    hitting the disk and will have variable results but highlight the impact
    of mark_page_accessed for async IO.  The sync results are expected to be
    more stable.  The exception is tmpfs where the normal case is for the "IO"
    to not hit the disk.
    
    The test machine was single socket and UMA to avoid any scheduling or NUMA
    artifacts.  Throughput and wall times are presented for sync IO, only wall
    times are shown for async as the granularity reported by dd and the
    variability is unsuitable for comparison.  As async results were variable
    do to writback timings, I'm only reporting the maximum figures.  The sync
    results were stable enough to make the mean and stddev uninteresting.
    
    The performance results are reported based on a run with no profiling.
    Profile data is based on a separate run with oprofile running.
    
    async dd
                                        3.15.0-rc3            3.15.0-rc3
                                           vanilla           accessed-v2
    ext3    Max      elapsed     13.9900 (  0.00%)     11.5900 ( 17.16%)
    tmpfs   Max      elapsed      0.5100 (  0.00%)      0.4900 (  3.92%)
    btrfs   Max      elapsed     12.8100 (  0.00%)     12.7800 (  0.23%)
    ext4    Max      elapsed     18.6000 (  0.00%)     13.3400 ( 28.28%)
    xfs     Max      elapsed     12.5600 (  0.00%)      2.0900 ( 83.36%)
    
    The XFS figure is a bit strange as it managed to avoid a worst case by
    sheer luck but the average figures looked reasonable.
    
            samples percentage
    ext3       86107    0.9783  vmlinux-3.15.0-rc4-vanilla        mark_page_accessed
    ext3       23833    0.2710  vmlinux-3.15.0-rc4-accessed-v3r25 mark_page_accessed
    ext3        5036    0.0573  vmlinux-3.15.0-rc4-accessed-v3r25 init_page_accessed
    ext4       64566    0.8961  vmlinux-3.15.0-rc4-vanilla        mark_page_accessed
    ext4        5322    0.0713  vmlinux-3.15.0-rc4-accessed-v3r25 mark_page_accessed
    ext4        2869    0.0384  vmlinux-3.15.0-rc4-accessed-v3r25 init_page_accessed
    xfs        62126    1.7675  vmlinux-3.15.0-rc4-vanilla        mark_page_accessed
    xfs         1904    0.0554  vmlinux-3.15.0-rc4-accessed-v3r25 init_page_accessed
    xfs          103    0.0030  vmlinux-3.15.0-rc4-accessed-v3r25 mark_page_accessed
    btrfs      10655    0.1338  vmlinux-3.15.0-rc4-vanilla        mark_page_accessed
    btrfs       2020    0.0273  vmlinux-3.15.0-rc4-accessed-v3r25 init_page_accessed
    btrfs        587    0.0079  vmlinux-3.15.0-rc4-accessed-v3r25 mark_page_accessed
    tmpfs      59562    3.2628  vmlinux-3.15.0-rc4-vanilla        mark_page_accessed
    tmpfs       1210    0.0696  vmlinux-3.15.0-rc4-accessed-v3r25 init_page_accessed
    tmpfs         94    0.0054  vmlinux-3.15.0-rc4-accessed-v3r25 mark_page_accessed
    
    [akpm@linux-foundation.org: don't run init_page_accessed() against an uninitialised pointer]
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Tested-by: Prabhakar Lad <prabhakar.csengg@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4aa521aa9bc3..c405b8f17054 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -69,7 +69,6 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		goto repeat;
 	}
 out:
-	mark_page_accessed(page);
 	return page;
 }
 
@@ -137,13 +136,11 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, int start, int nrpages, int type)
 		if (!page)
 			continue;
 		if (PageUptodate(page)) {
-			mark_page_accessed(page);
 			f2fs_put_page(page, 1);
 			continue;
 		}
 
 		f2fs_submit_page_mbio(sbi, page, blk_addr, &fio);
-		mark_page_accessed(page);
 		f2fs_put_page(page, 0);
 	}
 out:

commit 1dbe4152168d44fa164edbdc9f1243de70b98f7a
Author: Changman Lee <cm224.lee@samsung.com>
Date:   Mon May 12 12:27:43 2014 +0900

    f2fs: large volume support
    
    f2fs's cp has one page which consists of struct f2fs_checkpoint and
    version bitmap of sit and nat. To support lots of segments, we need more
    blocks for sit bitmap. So let's arrange sit bitmap as following:
    +-----------------+------------+
    | f2fs_checkpoint | sit bitmap |
    | + nat bitmap    |            |
    +-----------------+------------+
    0                 4k        N blocks
    
    Signed-off-by: Changman Lee <cm224.lee@samsung.com>
    [Jaegeuk Kim: simple code change for readability]
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index fe968c7bfc90..ecba8da3308b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -371,7 +371,9 @@ void recover_orphan_inodes(struct f2fs_sb_info *sbi)
 		return;
 
 	sbi->por_doing = true;
-	start_blk = __start_cp_addr(sbi) + 1;
+
+	start_blk = __start_cp_addr(sbi) + 1 +
+		le32_to_cpu(F2FS_RAW_SUPER(sbi)->cp_payload);
 	orphan_blkaddr = __start_sum_addr(sbi) - 1;
 
 	ra_meta_pages(sbi, start_blk, orphan_blkaddr, META_CP);
@@ -512,8 +514,11 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	unsigned long blk_size = sbi->blocksize;
 	unsigned long long cp1_version = 0, cp2_version = 0;
 	unsigned long long cp_start_blk_no;
+	unsigned int cp_blks = 1 + le32_to_cpu(F2FS_RAW_SUPER(sbi)->cp_payload);
+	block_t cp_blk_no;
+	int i;
 
-	sbi->ckpt = kzalloc(blk_size, GFP_KERNEL);
+	sbi->ckpt = kzalloc(cp_blks * blk_size, GFP_KERNEL);
 	if (!sbi->ckpt)
 		return -ENOMEM;
 	/*
@@ -544,6 +549,23 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	cp_block = (struct f2fs_checkpoint *)page_address(cur_page);
 	memcpy(sbi->ckpt, cp_block, blk_size);
 
+	if (cp_blks <= 1)
+		goto done;
+
+	cp_blk_no = le32_to_cpu(fsb->cp_blkaddr);
+	if (cur_page == cp2)
+		cp_blk_no += 1 << le32_to_cpu(fsb->log_blocks_per_seg);
+
+	for (i = 1; i < cp_blks; i++) {
+		void *sit_bitmap_ptr;
+		unsigned char *ckpt = (unsigned char *)sbi->ckpt;
+
+		cur_page = get_meta_page(sbi, cp_blk_no + i);
+		sit_bitmap_ptr = page_address(cur_page);
+		memcpy(ckpt + i * blk_size, sit_bitmap_ptr, blk_size);
+		f2fs_put_page(cur_page, 1);
+	}
+done:
 	f2fs_put_page(cp1, 1);
 	f2fs_put_page(cp2, 1);
 	return 0;
@@ -736,6 +758,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	__u32 crc32 = 0;
 	void *kaddr;
 	int i;
+	int cp_payload_blks = le32_to_cpu(F2FS_RAW_SUPER(sbi)->cp_payload);
 
 	/*
 	 * This avoids to conduct wrong roll-forward operations and uses
@@ -786,16 +809,19 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 
 	orphan_blocks = (sbi->n_orphans + F2FS_ORPHANS_PER_BLOCK - 1)
 					/ F2FS_ORPHANS_PER_BLOCK;
-	ckpt->cp_pack_start_sum = cpu_to_le32(1 + orphan_blocks);
+	ckpt->cp_pack_start_sum = cpu_to_le32(1 + cp_payload_blks +
+			orphan_blocks);
 
 	if (is_umount) {
 		set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
 		ckpt->cp_pack_total_block_count = cpu_to_le32(2 +
-			data_sum_blocks + orphan_blocks + NR_CURSEG_NODE_TYPE);
+				cp_payload_blks + data_sum_blocks +
+				orphan_blocks + NR_CURSEG_NODE_TYPE);
 	} else {
 		clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
 		ckpt->cp_pack_total_block_count = cpu_to_le32(2 +
-			data_sum_blocks + orphan_blocks);
+				cp_payload_blks + data_sum_blocks +
+				orphan_blocks);
 	}
 
 	if (sbi->n_orphans)
@@ -821,6 +847,15 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	set_page_dirty(cp_page);
 	f2fs_put_page(cp_page, 1);
 
+	for (i = 1; i < 1 + cp_payload_blks; i++) {
+		cp_page = grab_meta_page(sbi, start_blk++);
+		kaddr = page_address(cp_page);
+		memcpy(kaddr, (char *)ckpt + i * F2FS_BLKSIZE,
+				(1 << sbi->log_blocksize));
+		set_page_dirty(cp_page);
+		f2fs_put_page(cp_page, 1);
+	}
+
 	if (sbi->n_orphans) {
 		write_orphan_inodes(sbi, start_blk);
 		start_blk += orphan_blocks;

commit e57484343898094bb8f72a2aa1a50929d27aa027
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue May 6 16:51:24 2014 +0800

    f2fs: add a tracepoint for f2fs_write_{meta,node,data}_pages
    
    This patch adds a tracepoint for f2fs_write_{meta,node,data}_pages to trace when
    pages are fsyncing/flushing.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c95d62281d7e..fe968c7bfc90 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -186,6 +186,8 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 	struct f2fs_sb_info *sbi = F2FS_SB(mapping->host->i_sb);
 	long diff, written;
 
+	trace_f2fs_writepages(mapping->host, wbc, META);
+
 	/* collect a number of dirty meta pages and write together */
 	if (wbc->for_kupdate ||
 		get_pages(sbi, F2FS_DIRTY_META) < nr_pages_to_skip(sbi, META))

commit ecda0de3430455378f1c02523bf3ad71d91d613a
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Tue May 6 16:48:26 2014 +0800

    f2fs: add a tracepoint for f2fs_write_{meta,node,data}_page
    
    This patch adds a tracepoint for f2fs_write_{meta,node,data}_page to trace when
    page is writting out.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4206f1664be5..c95d62281d7e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -157,6 +157,8 @@ static int f2fs_write_meta_page(struct page *page,
 	struct inode *inode = page->mapping->host;
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
 
+	trace_f2fs_writepage(page, META);
+
 	if (unlikely(sbi->por_doing))
 		goto redirty_out;
 	if (wbc->for_reclaim)

commit bde446866c9200fcfa27ccde213d83db9a6827db
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Apr 30 09:18:53 2014 +0900

    f2fs: no need to wait on page writebck to meta pages
    
    This patch removes grab_cache_page_write_begin for meta pages.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 1346ce916b84..4206f1664be5 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -33,12 +33,12 @@ struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	struct address_space *mapping = META_MAPPING(sbi);
 	struct page *page = NULL;
 repeat:
-	page = grab_cache_page_write_begin(mapping, index, AOP_FLAG_NOFS);
+	page = grab_cache_page(mapping, index);
 	if (!page) {
 		cond_resched();
 		goto repeat;
 	}
-
+	f2fs_wait_on_page_writeback(page, META);
 	SetPageUptodate(page);
 	return page;
 }

commit b49ad51e6d4fa665a0ab587798d36bebfdfa54a9
Author: Fabian Frederick <fabf@skynet.be>
Date:   Thu Apr 17 17:51:06 2014 +0200

    f2fs: add static to get_max_meta_blks
    
    inline get_max_meta_blks is only used in checkpoint.c
    Use standard static inline format.
    
    Cc: Jaegeuk Kim <jaegeuk.kim@samsung.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 744c68be2e15..1346ce916b84 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -73,7 +73,7 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return page;
 }
 
-inline int get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
+static inline int get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
 {
 	switch (type) {
 	case META_NAT:

commit ed57c27f736f6d8a51e442610c800ee0c3d83977
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Apr 15 11:19:28 2014 +0900

    f2fs: remove costly dirty_dir_inode operations
    
    This patch removes list opeations in handling dirty dir inodes.
    Previously, F2FS traverses whole the list of dirty dir inodes to check whether
    there is an existing inode or not, resulting in heavy CPU overheads.
    
    So this patch removes such the traverse operations by adding FI_DIRTY_DIR to
    indicate the inode lies on the list or not.
    Through this simple flag, we can remove redundant operations gracefully.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2902f7d50770..744c68be2e15 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -552,14 +552,13 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
-	struct list_head *head = &sbi->dir_inode_list;
-	struct dir_inode_entry *entry;
 
-	list_for_each_entry(entry, head, list)
-		if (unlikely(entry->inode == inode))
-			return -EEXIST;
+	if (is_inode_flag_set(F2FS_I(inode), FI_DIRTY_DIR))
+		return -EEXIST;
 
-	list_add_tail(&new->list, head);
+	set_inode_flag(F2FS_I(inode), FI_DIRTY_DIR);
+	F2FS_I(inode)->dirty_dir = new;
+	list_add_tail(&new->list, &sbi->dir_inode_list);
 	stat_inc_dirty_dir(sbi);
 	return 0;
 }
@@ -608,31 +607,26 @@ void add_dirty_dir_inode(struct inode *inode)
 void remove_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
-	struct list_head *head;
 	struct dir_inode_entry *entry;
 
 	if (!S_ISDIR(inode->i_mode))
 		return;
 
 	spin_lock(&sbi->dir_inode_lock);
-	if (get_dirty_dents(inode)) {
+	if (get_dirty_dents(inode) ||
+			!is_inode_flag_set(F2FS_I(inode), FI_DIRTY_DIR)) {
 		spin_unlock(&sbi->dir_inode_lock);
 		return;
 	}
 
-	head = &sbi->dir_inode_list;
-	list_for_each_entry(entry, head, list) {
-		if (entry->inode == inode) {
-			list_del(&entry->list);
-			stat_dec_dirty_dir(sbi);
-			spin_unlock(&sbi->dir_inode_lock);
-			kmem_cache_free(inode_entry_slab, entry);
-			goto done;
-		}
-	}
+	entry = F2FS_I(inode)->dirty_dir;
+	list_del(&entry->list);
+	F2FS_I(inode)->dirty_dir = NULL;
+	clear_inode_flag(F2FS_I(inode), FI_DIRTY_DIR);
+	stat_dec_dirty_dir(sbi);
 	spin_unlock(&sbi->dir_inode_lock);
+	kmem_cache_free(inode_entry_slab, entry);
 
-done:
 	/* Only from the recovery routine */
 	if (is_inode_flag_set(F2FS_I(inode), FI_DELAY_IPUT)) {
 		clear_inode_flag(F2FS_I(inode), FI_DELAY_IPUT);
@@ -640,26 +634,6 @@ void remove_dirty_dir_inode(struct inode *inode)
 	}
 }
 
-struct inode *check_dirty_dir_inode(struct f2fs_sb_info *sbi, nid_t ino)
-{
-
-	struct list_head *head;
-	struct inode *inode = NULL;
-	struct dir_inode_entry *entry;
-
-	spin_lock(&sbi->dir_inode_lock);
-
-	head = &sbi->dir_inode_list;
-	list_for_each_entry(entry, head, list) {
-		if (entry->inode->i_ino == ino) {
-			inode = entry->inode;
-			break;
-		}
-	}
-	spin_unlock(&sbi->dir_inode_lock);
-	return inode;
-}
-
 void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 {
 	struct list_head *head;

commit 76f60268e70a700c04c85e1b0d520c94062a40a2
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Apr 15 16:04:15 2014 +0900

    f2fs: call redirty_page_for_writepage
    
    This patch replace some general codes with redirty_page_for_writepage, which
    can be enabled after consideration on additional procedure like counting dirty
    pages appropriately.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 890e23d208a8..2902f7d50770 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -174,10 +174,7 @@ static int f2fs_write_meta_page(struct page *page,
 	return 0;
 
 redirty_out:
-	dec_page_count(sbi, F2FS_DIRTY_META);
-	wbc->pages_skipped++;
-	account_page_redirty(page);
-	set_page_dirty(page);
+	redirty_page_for_writepage(wbc, page);
 	return AOP_WRITEPAGE_ACTIVATE;
 }
 

commit 1e87a78d95ecea7a989349860feb42db3e4b7db5
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Apr 15 13:57:55 2014 +0900

    f2fs: avoid to conduct roll-forward due to the remained garbage blocks
    
    The f2fs always scans the next chain of direct node blocks.
    But some garbage blocks are able to be remained due to no discard support or
    SSR triggers.
    This occasionally wreaks recovering wrong inodes that were used or BUG_ONs
    due to reallocating node ids as follows.
    
    When mount this f2fs image:
    http://linuxtesting.org/downloads/f2fs_fault_image.zip
    BUG_ON is triggered in f2fs driver (messages below are generated on
    kernel 3.13.2; for other kernels output is similar):
    
    kernel BUG at fs/f2fs/node.c:215!
     Call Trace:
     [<ffffffffa032ebad>] recover_inode_page+0x1fd/0x3e0 [f2fs]
     [<ffffffff811446e7>] ? __lock_page+0x67/0x70
     [<ffffffff81089990>] ? autoremove_wake_function+0x50/0x50
     [<ffffffffa0337788>] recover_fsync_data+0x1398/0x15d0 [f2fs]
     [<ffffffff812b9e5c>] ? selinux_d_instantiate+0x1c/0x20
     [<ffffffff811cb20b>] ? d_instantiate+0x5b/0x80
     [<ffffffffa0321044>] f2fs_fill_super+0xb04/0xbf0 [f2fs]
     [<ffffffff811b861e>] ? mount_bdev+0x7e/0x210
     [<ffffffff811b8769>] mount_bdev+0x1c9/0x210
     [<ffffffffa0320540>] ? validate_superblock+0x210/0x210 [f2fs]
     [<ffffffffa031cf8d>] f2fs_mount+0x1d/0x30 [f2fs]
     [<ffffffff811b9497>] mount_fs+0x47/0x1c0
     [<ffffffff81166e00>] ? __alloc_percpu+0x10/0x20
     [<ffffffff811d4032>] vfs_kern_mount+0x72/0x110
     [<ffffffff811d6763>] do_mount+0x493/0x910
     [<ffffffff811615cb>] ? strndup_user+0x5b/0x80
     [<ffffffff811d6c70>] SyS_mount+0x90/0xe0
     [<ffffffff8166f8d9>] system_call_fastpath+0x16/0x1b
    
    Found by Linux File System Verification project (linuxtesting.org).
    
    Reported-by: Andrey Tsyvarev <tsyvarev@ispras.ru>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4aa521aa9bc3..890e23d208a8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -762,6 +762,12 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	void *kaddr;
 	int i;
 
+	/*
+	 * This avoids to conduct wrong roll-forward operations and uses
+	 * metapages, so should be called prior to sync_meta_pages below.
+	 */
+	discard_next_dnode(sbi);
+
 	/* Flush all the NAT/SIT pages */
 	while (get_pages(sbi, F2FS_DIRTY_META))
 		sync_meta_pages(sbi, META, LONG_MAX);

commit 2d7b822ad9daf0ea903accacaa89340ddd3f201f
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Sat Mar 29 11:33:17 2014 +0800

    f2fs: use list_for_each_entry{_safe} for simplyfying code
    
    This patch use list_for_each_entry{_safe} instead of list_for_each{_safe} for
    simplfying code.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d877f46c75ed..4aa521aa9bc3 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -308,16 +308,15 @@ void release_orphan_inode(struct f2fs_sb_info *sbi)
 
 void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
-	struct list_head *head, *this;
-	struct orphan_inode_entry *new = NULL, *orphan = NULL;
+	struct list_head *head;
+	struct orphan_inode_entry *new, *orphan;
 
 	new = f2fs_kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
 	new->ino = ino;
 
 	spin_lock(&sbi->orphan_inode_lock);
 	head = &sbi->orphan_inode_list;
-	list_for_each(this, head) {
-		orphan = list_entry(this, struct orphan_inode_entry, list);
+	list_for_each_entry(orphan, head, list) {
 		if (orphan->ino == ino) {
 			spin_unlock(&sbi->orphan_inode_lock);
 			kmem_cache_free(orphan_entry_slab, new);
@@ -326,14 +325,10 @@ void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 
 		if (orphan->ino > ino)
 			break;
-		orphan = NULL;
 	}
 
-	/* add new_oentry into list which is sorted by inode number */
-	if (orphan)
-		list_add(&new->list, this->prev);
-	else
-		list_add_tail(&new->list, head);
+	/* add new orphan entry into list which is sorted by inode number */
+	list_add_tail(&new->list, &orphan->list);
 	spin_unlock(&sbi->orphan_inode_lock);
 }
 
@@ -561,14 +556,12 @@ static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
 	struct list_head *head = &sbi->dir_inode_list;
-	struct list_head *this;
+	struct dir_inode_entry *entry;
 
-	list_for_each(this, head) {
-		struct dir_inode_entry *entry;
-		entry = list_entry(this, struct dir_inode_entry, list);
+	list_for_each_entry(entry, head, list)
 		if (unlikely(entry->inode == inode))
 			return -EEXIST;
-	}
+
 	list_add_tail(&new->list, head);
 	stat_inc_dirty_dir(sbi);
 	return 0;
@@ -618,7 +611,8 @@ void add_dirty_dir_inode(struct inode *inode)
 void remove_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
-	struct list_head *this, *head;
+	struct list_head *head;
+	struct dir_inode_entry *entry;
 
 	if (!S_ISDIR(inode->i_mode))
 		return;
@@ -630,9 +624,7 @@ void remove_dirty_dir_inode(struct inode *inode)
 	}
 
 	head = &sbi->dir_inode_list;
-	list_for_each(this, head) {
-		struct dir_inode_entry *entry;
-		entry = list_entry(this, struct dir_inode_entry, list);
+	list_for_each_entry(entry, head, list) {
 		if (entry->inode == inode) {
 			list_del(&entry->list);
 			stat_dec_dirty_dir(sbi);
@@ -654,15 +646,14 @@ void remove_dirty_dir_inode(struct inode *inode)
 struct inode *check_dirty_dir_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 
-	struct list_head *this, *head;
+	struct list_head *head;
 	struct inode *inode = NULL;
+	struct dir_inode_entry *entry;
 
 	spin_lock(&sbi->dir_inode_lock);
 
 	head = &sbi->dir_inode_list;
-	list_for_each(this, head) {
-		struct dir_inode_entry *entry;
-		entry = list_entry(this, struct dir_inode_entry, list);
+	list_for_each_entry(entry, head, list) {
 		if (entry->inode->i_ino == ino) {
 			inode = entry->inode;
 			break;

commit cf0ee0f09bc09f54b9852dda1088b9cdcd4f8683
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Apr 2 08:55:00 2014 +0800

    f2fs: avoid free slab cache under spinlock
    
    Move kmem_cache_free out of spinlock protection region for better performance.
    
    Change log from v1:
     o remove spinlock protection for kmem_cache_free in destroy_node_manager
    suggested by Jaegeuk Kim.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index a80be5121e8a..d877f46c75ed 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -347,10 +347,11 @@ void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	list_for_each_entry(orphan, head, list) {
 		if (orphan->ino == ino) {
 			list_del(&orphan->list);
-			kmem_cache_free(orphan_entry_slab, orphan);
 			f2fs_bug_on(sbi->n_orphans == 0);
 			sbi->n_orphans--;
-			break;
+			spin_unlock(&sbi->orphan_inode_lock);
+			kmem_cache_free(orphan_entry_slab, orphan);
+			return;
 		}
 	}
 	spin_unlock(&sbi->orphan_inode_lock);
@@ -577,6 +578,7 @@ void set_dirty_dir_page(struct inode *inode, struct page *page)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
 	struct dir_inode_entry *new;
+	int ret = 0;
 
 	if (!S_ISDIR(inode->i_mode))
 		return;
@@ -586,12 +588,13 @@ void set_dirty_dir_page(struct inode *inode, struct page *page)
 	INIT_LIST_HEAD(&new->list);
 
 	spin_lock(&sbi->dir_inode_lock);
-	if (__add_dirty_inode(inode, new))
-		kmem_cache_free(inode_entry_slab, new);
-
+	ret = __add_dirty_inode(inode, new);
 	inode_inc_dirty_dents(inode);
 	SetPagePrivate(page);
 	spin_unlock(&sbi->dir_inode_lock);
+
+	if (ret)
+		kmem_cache_free(inode_entry_slab, new);
 }
 
 void add_dirty_dir_inode(struct inode *inode)
@@ -599,20 +602,22 @@ void add_dirty_dir_inode(struct inode *inode)
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
 	struct dir_inode_entry *new =
 			f2fs_kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
+	int ret = 0;
 
 	new->inode = inode;
 	INIT_LIST_HEAD(&new->list);
 
 	spin_lock(&sbi->dir_inode_lock);
-	if (__add_dirty_inode(inode, new))
-		kmem_cache_free(inode_entry_slab, new);
+	ret = __add_dirty_inode(inode, new);
 	spin_unlock(&sbi->dir_inode_lock);
+
+	if (ret)
+		kmem_cache_free(inode_entry_slab, new);
 }
 
 void remove_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
-
 	struct list_head *this, *head;
 
 	if (!S_ISDIR(inode->i_mode))
@@ -630,13 +635,15 @@ void remove_dirty_dir_inode(struct inode *inode)
 		entry = list_entry(this, struct dir_inode_entry, list);
 		if (entry->inode == inode) {
 			list_del(&entry->list);
-			kmem_cache_free(inode_entry_slab, entry);
 			stat_dec_dirty_dir(sbi);
-			break;
+			spin_unlock(&sbi->dir_inode_lock);
+			kmem_cache_free(inode_entry_slab, entry);
+			goto done;
 		}
 	}
 	spin_unlock(&sbi->dir_inode_lock);
 
+done:
 	/* Only from the recovery routine */
 	if (is_inode_flag_set(F2FS_I(inode), FI_DELAY_IPUT)) {
 		clear_inode_flag(F2FS_I(inode), FI_DELAY_IPUT);

commit 3cb5ad152b54430f3e5f338c15f8cd434e7160c8
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Mar 18 13:29:07 2014 +0900

    f2fs: call f2fs_wait_on_page_writeback instead of native function
    
    If a page is on writeback, f2fs can face with deadlock due to under writepages.
    This is caused by merging IOs inside f2fs, so if it comes to detect, let's throw
    merged IOs, which is implemented by f2fs_wait_on_page_writeback.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2a00c94726fb..a80be5121e8a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -33,14 +33,12 @@ struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	struct address_space *mapping = META_MAPPING(sbi);
 	struct page *page = NULL;
 repeat:
-	page = grab_cache_page(mapping, index);
+	page = grab_cache_page_write_begin(mapping, index, AOP_FLAG_NOFS);
 	if (!page) {
 		cond_resched();
 		goto repeat;
 	}
 
-	/* We wait writeback only inside grab_meta_page() */
-	wait_on_page_writeback(page);
 	SetPageUptodate(page);
 	return page;
 }
@@ -168,7 +166,7 @@ static int f2fs_write_meta_page(struct page *page,
 	if (unlikely(is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ERROR_FLAG)))
 		goto no_write;
 
-	wait_on_page_writeback(page);
+	f2fs_wait_on_page_writeback(page, META);
 	write_meta_page(sbi, page);
 no_write:
 	dec_page_count(sbi, F2FS_DIRTY_META);

commit 50c8cdb35ad8016c52fb2326ef9d65542e3a3e1b
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Mar 18 13:47:11 2014 +0900

    f2fs: introduce nr_pages_to_write for segment alignment
    
    This patch introduces nr_pages_to_write to align page writes to the segment
    or other operational unit size, which can be tuned according to the system
    environment.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index aef32f36e2f3..2a00c94726fb 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -187,18 +187,19 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 				struct writeback_control *wbc)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(mapping->host->i_sb);
-	int nrpages = nr_pages_to_skip(sbi, META);
-	long written;
+	long diff, written;
 
 	/* collect a number of dirty meta pages and write together */
-	if (wbc->for_kupdate || get_pages(sbi, F2FS_DIRTY_META) < nrpages)
+	if (wbc->for_kupdate ||
+		get_pages(sbi, F2FS_DIRTY_META) < nr_pages_to_skip(sbi, META))
 		goto skip_write;
 
 	/* if mounting is failed, skip writing node pages */
 	mutex_lock(&sbi->cp_mutex);
-	written = sync_meta_pages(sbi, META, nrpages);
+	diff = nr_pages_to_write(sbi, META, wbc);
+	written = sync_meta_pages(sbi, META, wbc->nr_to_write);
 	mutex_unlock(&sbi->cp_mutex);
-	wbc->nr_to_write -= written;
+	wbc->nr_to_write = max((long)0, wbc->nr_to_write - written - diff);
 	return 0;
 
 skip_write:

commit d3baf95da5b0bce9fe980eeff6140817d63fabdf
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Mar 18 13:43:05 2014 +0900

    f2fs: increase pages_skipped when skipping writepages
    
    This patch increases pages_skipped when skipping writepages.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 1f52b70ff9d1..aef32f36e2f3 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -190,12 +190,9 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 	int nrpages = nr_pages_to_skip(sbi, META);
 	long written;
 
-	if (wbc->for_kupdate)
-		return 0;
-
 	/* collect a number of dirty meta pages and write together */
-	if (get_pages(sbi, F2FS_DIRTY_META) < nrpages)
-		return 0;
+	if (wbc->for_kupdate || get_pages(sbi, F2FS_DIRTY_META) < nrpages)
+		goto skip_write;
 
 	/* if mounting is failed, skip writing node pages */
 	mutex_lock(&sbi->cp_mutex);
@@ -203,6 +200,10 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 	mutex_unlock(&sbi->cp_mutex);
 	wbc->nr_to_write -= written;
 	return 0;
+
+skip_write:
+	wbc->pages_skipped += get_pages(sbi, F2FS_DIRTY_META);
+	return 0;
 }
 
 long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,

commit 87d6f890944d092c4ef5b84053f0d0d5d8137b0b
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Mar 18 12:40:49 2014 +0900

    f2fs: avoid small data writes by skipping writepages
    
    This patch introduces nr_pages_to_skip(sbi, type) to determine writepages can
    be skipped.
    The dentry, node, and meta pages can be conrolled by F2FS without breaking the
    FS consistency.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4c0e98ddf3db..1f52b70ff9d1 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -187,7 +187,7 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 				struct writeback_control *wbc)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(mapping->host->i_sb);
-	int nrpages = MAX_BIO_BLOCKS(max_hw_blocks(sbi));
+	int nrpages = nr_pages_to_skip(sbi, META);
 	long written;
 
 	if (wbc->for_kupdate)
@@ -682,7 +682,7 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 	inode = igrab(entry->inode);
 	spin_unlock(&sbi->dir_inode_lock);
 	if (inode) {
-		filemap_flush(inode->i_mapping);
+		filemap_fdatawrite(inode->i_mapping);
 		iput(inode);
 	} else {
 		/*

commit f8b2c1f940dca2843fe13b55ba5868bac8040551
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Mar 18 12:33:06 2014 +0900

    f2fs: introduce get_dirty_dents for readability
    
    The get_dirty_dents gives us the number of dirty dentry pages.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 911b6f9e9f7b..4c0e98ddf3db 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -619,7 +619,7 @@ void remove_dirty_dir_inode(struct inode *inode)
 		return;
 
 	spin_lock(&sbi->dir_inode_lock);
-	if (atomic_read(&F2FS_I(inode)->dirty_dents)) {
+	if (get_dirty_dents(inode)) {
 		spin_unlock(&sbi->dir_inode_lock);
 		return;
 	}

commit e8512d2e0c4eb38cd78b1499bb08d7d8eea6c723
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Fri Mar 7 18:43:28 2014 +0800

    f2fs: remove the unused ctor argument of f2fs_kmem_cache_create()
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f069249011b2..911b6f9e9f7b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -939,11 +939,11 @@ void init_orphan_info(struct f2fs_sb_info *sbi)
 int __init create_checkpoint_caches(void)
 {
 	orphan_entry_slab = f2fs_kmem_cache_create("f2fs_orphan_entry",
-			sizeof(struct orphan_inode_entry), NULL);
+			sizeof(struct orphan_inode_entry));
 	if (!orphan_entry_slab)
 		return -ENOMEM;
 	inode_entry_slab = f2fs_kmem_cache_create("f2fs_dirty_dir_entry",
-			sizeof(struct dir_inode_entry), NULL);
+			sizeof(struct dir_inode_entry));
 	if (!inode_entry_slab) {
 		kmem_cache_destroy(orphan_entry_slab);
 		return -ENOMEM;

commit 9cf3c3898a274ca637b88ad01b0830550ee2d318
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Fri Feb 28 10:12:05 2014 +0800

    f2fs: fix dirty page accounting when redirty
    
    We should de-account dirty counters for page when redirty in ->writepage().
    
    Wu Fengguang described in 'commit 971767caf632190f77a40b4011c19948232eed75':
    "writeback: fix dirtied pages accounting on redirty
    De-account the accumulative dirty counters on page redirty.
    
    Page redirties (very common in ext4) will introduce mismatch between
    counters (a) and (b)
    
    a) NR_DIRTIED, BDI_DIRTIED, tsk->nr_dirtied
    b) NR_WRITTEN, BDI_WRITTEN
    
    This will introduce systematic errors in balanced_rate and result in
    dirty page position errors (ie. the dirty pages are no longer balanced
    around the global/bdi setpoints)."
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c8516ee24126..f069249011b2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -178,6 +178,7 @@ static int f2fs_write_meta_page(struct page *page,
 redirty_out:
 	dec_page_count(sbi, F2FS_DIRTY_META);
 	wbc->pages_skipped++;
+	account_page_redirty(page);
 	set_page_dirty(page);
 	return AOP_WRITEPAGE_ACTIVATE;
 }

commit 81c1a0f13e6306a76fc3743b8504085d96659a5f
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Feb 27 19:12:24 2014 +0800

    f2fs: readahead contiguous SSA blocks for f2fs_gc
    
    If there are multi segments in one section, we will read those SSA blocks which
    have contiguous address one by one in f2fs_gc. It may lost performance, let's
    read ahead SSA blocks by merge multi read request.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 757b77b7118e..c8516ee24126 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -82,6 +82,7 @@ inline int get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
 		return NM_I(sbi)->max_nid / NAT_ENTRY_PER_BLOCK;
 	case META_SIT:
 		return SIT_BLK_CNT(sbi);
+	case META_SSA:
 	case META_CP:
 		return 0;
 	default:
@@ -90,7 +91,7 @@ inline int get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
 }
 
 /*
- * Readahead CP/NAT/SIT pages
+ * Readahead CP/NAT/SIT/SSA pages
  */
 int ra_meta_pages(struct f2fs_sb_info *sbi, int start, int nrpages, int type)
 {
@@ -125,8 +126,9 @@ int ra_meta_pages(struct f2fs_sb_info *sbi, int start, int nrpages, int type)
 				goto out;
 			prev_blk_addr = blk_addr;
 			break;
+		case META_SSA:
 		case META_CP:
-			/* get cp block addr */
+			/* get ssa/cp block addr */
 			blk_addr = blkno;
 			break;
 		default:

commit 942e0be6219cc80384eb961feb963cab275bcbbf
Author: Changman Lee <cm224.lee@samsung.com>
Date:   Thu Feb 13 15:12:29 2014 +0900

    f2fs: show counts of checkpoint in status
    
    This patch shows the counts of checkpoint in f2fs' status.
    
    Signed-off-by: Changman Lee <cm224.lee@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index deb60356f7cf..757b77b7118e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -914,6 +914,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	unblock_operations(sbi);
 	mutex_unlock(&sbi->cp_mutex);
 
+	stat_inc_cp_count(sbi->stat_info);
 	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish checkpoint");
 }
 

commit 662befda25fb16d7164633c39e9e20aeac5107d9
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Fri Feb 7 16:11:53 2014 +0800

    f2fs: introduce ra_meta_pages to readahead CP/NAT/SIT pages
    
    This patch help us to cleanup the readahead code by merging ra_{sit,nat}_pages
    function into ra_meta_pages.
    Additionally the new function is used to readahead cp block in
    recover_orphan_inodes.
    
    Change log from v1:
     o fix a deadloop bug pointed by Jaegeuk Kim.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 427dd55cfd5a..deb60356f7cf 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -75,6 +75,82 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return page;
 }
 
+inline int get_max_meta_blks(struct f2fs_sb_info *sbi, int type)
+{
+	switch (type) {
+	case META_NAT:
+		return NM_I(sbi)->max_nid / NAT_ENTRY_PER_BLOCK;
+	case META_SIT:
+		return SIT_BLK_CNT(sbi);
+	case META_CP:
+		return 0;
+	default:
+		BUG();
+	}
+}
+
+/*
+ * Readahead CP/NAT/SIT pages
+ */
+int ra_meta_pages(struct f2fs_sb_info *sbi, int start, int nrpages, int type)
+{
+	block_t prev_blk_addr = 0;
+	struct page *page;
+	int blkno = start;
+	int max_blks = get_max_meta_blks(sbi, type);
+
+	struct f2fs_io_info fio = {
+		.type = META,
+		.rw = READ_SYNC | REQ_META | REQ_PRIO
+	};
+
+	for (; nrpages-- > 0; blkno++) {
+		block_t blk_addr;
+
+		switch (type) {
+		case META_NAT:
+			/* get nat block addr */
+			if (unlikely(blkno >= max_blks))
+				blkno = 0;
+			blk_addr = current_nat_addr(sbi,
+					blkno * NAT_ENTRY_PER_BLOCK);
+			break;
+		case META_SIT:
+			/* get sit block addr */
+			if (unlikely(blkno >= max_blks))
+				goto out;
+			blk_addr = current_sit_addr(sbi,
+					blkno * SIT_ENTRY_PER_BLOCK);
+			if (blkno != start && prev_blk_addr + 1 != blk_addr)
+				goto out;
+			prev_blk_addr = blk_addr;
+			break;
+		case META_CP:
+			/* get cp block addr */
+			blk_addr = blkno;
+			break;
+		default:
+			BUG();
+		}
+
+		page = grab_cache_page(META_MAPPING(sbi), blk_addr);
+		if (!page)
+			continue;
+		if (PageUptodate(page)) {
+			mark_page_accessed(page);
+			f2fs_put_page(page, 1);
+			continue;
+		}
+
+		f2fs_submit_page_mbio(sbi, page, blk_addr, &fio);
+		mark_page_accessed(page);
+		f2fs_put_page(page, 0);
+	}
+out:
+	f2fs_submit_merged_bio(sbi, META, READ);
+	return blkno - start;
+}
+
 static int f2fs_write_meta_page(struct page *page,
 				struct writeback_control *wbc)
 {
@@ -298,6 +374,8 @@ void recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	start_blk = __start_cp_addr(sbi) + 1;
 	orphan_blkaddr = __start_sum_addr(sbi) - 1;
 
+	ra_meta_pages(sbi, start_blk, orphan_blkaddr, META_CP);
+
 	for (i = 0; i < orphan_blkaddr; i++) {
 		struct page *page = get_meta_page(sbi, start_blk + i);
 		struct f2fs_orphan_block *orphan_blk;

commit 1fe54f9dd3acfaa3ed4e1d1e3278fd0f1d1e98cd
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Feb 7 10:00:06 2014 +0900

    f2fs: clean up redundant function call
    
    This patch integrates inode_[inc|dec]_dirty_dents with inc_page_count to remove
    redundant calls.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 8f5dff1989a8..427dd55cfd5a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -508,7 +508,6 @@ void set_dirty_dir_page(struct inode *inode, struct page *page)
 	if (__add_dirty_inode(inode, new))
 		kmem_cache_free(inode_entry_slab, new);
 
-	inc_page_count(sbi, F2FS_DIRTY_DENTS);
 	inode_inc_dirty_dents(inode);
 	SetPagePrivate(page);
 	spin_unlock(&sbi->dir_inode_lock);

commit 203681f65b07055259bd475a6281136615b4e9a4
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Feb 5 13:03:57 2014 +0900

    f2fs: fix f2fs_write_meta_page at no checkpoint status
    
    If f2fs entered errorneous checkpoint status, it should skip writing meta
    pages instead of redirtying the pages out.
    Otherwise, it cannot unmount the partition even though f2fs is under read-only
    status.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 293d0486a40f..8f5dff1989a8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -81,17 +81,18 @@ static int f2fs_write_meta_page(struct page *page,
 	struct inode *inode = page->mapping->host;
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
 
-	/* Should not write any meta pages, if any IO error was occurred */
-	if (unlikely(sbi->por_doing ||
-			is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ERROR_FLAG)))
+	if (unlikely(sbi->por_doing))
 		goto redirty_out;
-
 	if (wbc->for_reclaim)
 		goto redirty_out;
 
-	wait_on_page_writeback(page);
+	/* Should not write any meta pages, if any IO error was occurred */
+	if (unlikely(is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ERROR_FLAG)))
+		goto no_write;
 
+	wait_on_page_writeback(page);
 	write_meta_page(sbi, page);
+no_write:
 	dec_page_count(sbi, F2FS_DIRTY_META);
 	unlock_page(page);
 	return 0;
@@ -148,10 +149,22 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 
 		for (i = 0; i < nr_pages; i++) {
 			struct page *page = pvec.pages[i];
+
 			lock_page(page);
-			f2fs_bug_on(page->mapping != mapping);
-			f2fs_bug_on(!PageDirty(page));
-			clear_page_dirty_for_io(page);
+
+			if (unlikely(page->mapping != mapping)) {
+continue_unlock:
+				unlock_page(page);
+				continue;
+			}
+			if (!PageDirty(page)) {
+				/* someone wrote it for us */
+				goto continue_unlock;
+			}
+
+			if (!clear_page_dirty_for_io(page))
+				goto continue_unlock;
+
 			if (f2fs_write_meta_page(page, &wbc)) {
 				unlock_page(page);
 				break;

commit 4ef51a8fcc7c54ca3ad948a8b4310b3bd5490c72
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Jan 21 18:51:16 2014 +0900

    f2fs: introduce NODE_MAPPING for code consistency
    
    This patch adds NODE_MAPPING which is similar as META_MAPPING introduced by
    Gu Zheng.
    
    Cc: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ed82de6bfb47..293d0486a40f 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -771,7 +771,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	/* wait for previous submitted node/meta pages writeback */
 	wait_on_all_pages_writeback(sbi);
 
-	filemap_fdatawait_range(sbi->node_inode->i_mapping, 0, LONG_MAX);
+	filemap_fdatawait_range(NODE_MAPPING(sbi), 0, LONG_MAX);
 	filemap_fdatawait_range(META_MAPPING(sbi), 0, LONG_MAX);
 
 	/* update user_block_counts */

commit 63f5384c9a7df95a0e0eb6745f3038c703bdf4c3
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Mon Jan 20 18:37:30 2014 +0800

    f2fs: remove the orphan block page array
    
    As the orphan_blocks may be max to 504, so it is not security
    and rigorous to store such a large array in the kernel stack
    as Dan Carpenter said.
    In fact, grab_meta_page has locked the page in the page cache,
    and we can use find_get_page() to fetch the page safely in the
    downstream, so we can remove the page array directly.
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f9d4f7de75ad..ed82de6bfb47 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -311,11 +311,10 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	unsigned short orphan_blocks = (unsigned short)((sbi->n_orphans +
 		(F2FS_ORPHANS_PER_BLOCK - 1)) / F2FS_ORPHANS_PER_BLOCK);
 	struct page *page = NULL;
-	struct page *pages[orphan_blocks];
 	struct orphan_inode_entry *orphan = NULL;
 
 	for (index = 0; index < orphan_blocks; index++)
-		pages[index] = grab_meta_page(sbi, start_blk + index);
+		grab_meta_page(sbi, start_blk + index);
 
 	index = 1;
 	spin_lock(&sbi->orphan_inode_lock);
@@ -324,10 +323,12 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	/* loop for each orphan inode entry and write them in Jornal block */
 	list_for_each_entry(orphan, head, list) {
 		if (!page) {
-			page = pages[index - 1];
+			page = find_get_page(META_MAPPING(sbi), start_blk++);
+			f2fs_bug_on(!page);
 			orphan_blk =
 				(struct f2fs_orphan_block *)page_address(page);
 			memset(orphan_blk, 0, sizeof(*orphan_blk));
+			f2fs_put_page(page, 0);
 		}
 
 		orphan_blk->ino[nentries++] = cpu_to_le32(orphan->ino);

commit 9df27d982d58b9372bc476fb6b9bab861d617029
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Mon Jan 20 18:37:04 2014 +0800

    f2fs: add help function META_MAPPING
    
    Introduce help function META_MAPPING() to get the cache meta blocks'
    address space.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 4de0345f73f3..f9d4f7de75ad 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -30,7 +30,7 @@ static struct kmem_cache *inode_entry_slab;
  */
 struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 {
-	struct address_space *mapping = sbi->meta_inode->i_mapping;
+	struct address_space *mapping = META_MAPPING(sbi);
 	struct page *page = NULL;
 repeat:
 	page = grab_cache_page(mapping, index);
@@ -50,7 +50,7 @@ struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
  */
 struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 {
-	struct address_space *mapping = sbi->meta_inode->i_mapping;
+	struct address_space *mapping = META_MAPPING(sbi);
 	struct page *page;
 repeat:
 	page = grab_cache_page(mapping, index);
@@ -128,7 +128,7 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 						long nr_to_write)
 {
-	struct address_space *mapping = sbi->meta_inode->i_mapping;
+	struct address_space *mapping = META_MAPPING(sbi);
 	pgoff_t index = 0, end = LONG_MAX;
 	struct pagevec pvec;
 	long nwritten = 0;
@@ -771,7 +771,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	wait_on_all_pages_writeback(sbi);
 
 	filemap_fdatawait_range(sbi->node_inode->i_mapping, 0, LONG_MAX);
-	filemap_fdatawait_range(sbi->meta_inode->i_mapping, 0, LONG_MAX);
+	filemap_fdatawait_range(META_MAPPING(sbi), 0, LONG_MAX);
 
 	/* update user_block_counts */
 	sbi->last_valid_block_count = sbi->total_valid_block_count;

commit 17b692f60e93f5d417fcdbfd681b0f20f9f31ec8
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Fri Jan 10 18:09:14 2014 +0800

    f2fs: use spinlock rather than mutex for better speed
    
    With the 2 previous changes, all the long time operations are moved out
    of the protection region, so here we can use spinlock rather than mutex
    (orphan_inode_mutex) for lower overhead.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 681782c715fb..4de0345f73f3 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -196,22 +196,22 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	int err = 0;
 
-	mutex_lock(&sbi->orphan_inode_mutex);
+	spin_lock(&sbi->orphan_inode_lock);
 	if (unlikely(sbi->n_orphans >= sbi->max_orphans))
 		err = -ENOSPC;
 	else
 		sbi->n_orphans++;
-	mutex_unlock(&sbi->orphan_inode_mutex);
+	spin_unlock(&sbi->orphan_inode_lock);
 
 	return err;
 }
 
 void release_orphan_inode(struct f2fs_sb_info *sbi)
 {
-	mutex_lock(&sbi->orphan_inode_mutex);
+	spin_lock(&sbi->orphan_inode_lock);
 	f2fs_bug_on(sbi->n_orphans == 0);
 	sbi->n_orphans--;
-	mutex_unlock(&sbi->orphan_inode_mutex);
+	spin_unlock(&sbi->orphan_inode_lock);
 }
 
 void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
@@ -222,12 +222,12 @@ void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	new = f2fs_kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
 	new->ino = ino;
 
-	mutex_lock(&sbi->orphan_inode_mutex);
+	spin_lock(&sbi->orphan_inode_lock);
 	head = &sbi->orphan_inode_list;
 	list_for_each(this, head) {
 		orphan = list_entry(this, struct orphan_inode_entry, list);
 		if (orphan->ino == ino) {
-			mutex_unlock(&sbi->orphan_inode_mutex);
+			spin_unlock(&sbi->orphan_inode_lock);
 			kmem_cache_free(orphan_entry_slab, new);
 			return;
 		}
@@ -242,7 +242,7 @@ void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 		list_add(&new->list, this->prev);
 	else
 		list_add_tail(&new->list, head);
-	mutex_unlock(&sbi->orphan_inode_mutex);
+	spin_unlock(&sbi->orphan_inode_lock);
 }
 
 void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
@@ -250,7 +250,7 @@ void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	struct list_head *head;
 	struct orphan_inode_entry *orphan;
 
-	mutex_lock(&sbi->orphan_inode_mutex);
+	spin_lock(&sbi->orphan_inode_lock);
 	head = &sbi->orphan_inode_list;
 	list_for_each_entry(orphan, head, list) {
 		if (orphan->ino == ino) {
@@ -261,7 +261,7 @@ void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 			break;
 		}
 	}
-	mutex_unlock(&sbi->orphan_inode_mutex);
+	spin_unlock(&sbi->orphan_inode_lock);
 }
 
 static void recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
@@ -318,7 +318,7 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 		pages[index] = grab_meta_page(sbi, start_blk + index);
 
 	index = 1;
-	mutex_lock(&sbi->orphan_inode_mutex);
+	spin_lock(&sbi->orphan_inode_lock);
 	head = &sbi->orphan_inode_list;
 
 	/* loop for each orphan inode entry and write them in Jornal block */
@@ -357,7 +357,7 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 		f2fs_put_page(page, 1);
 	}
 
-	mutex_unlock(&sbi->orphan_inode_mutex);
+	spin_unlock(&sbi->orphan_inode_lock);
 }
 
 static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
@@ -828,7 +828,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 
 void init_orphan_info(struct f2fs_sb_info *sbi)
 {
-	mutex_init(&sbi->orphan_inode_mutex);
+	spin_lock_init(&sbi->orphan_inode_lock);
 	INIT_LIST_HEAD(&sbi->orphan_inode_list);
 	sbi->n_orphans = 0;
 	/*

commit c1ef37257229dc8903615eaf1d1abaa5da3f0686
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Fri Jan 10 18:09:08 2014 +0800

    f2fs: move alloc new orphan node out of lock protection region
    
    Move alloc new orphan node out of lock protection region.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index fdc5a12c0edd..681782c715fb 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -219,26 +219,29 @@ void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	struct list_head *head, *this;
 	struct orphan_inode_entry *new = NULL, *orphan = NULL;
 
+	new = f2fs_kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
+	new->ino = ino;
+
 	mutex_lock(&sbi->orphan_inode_mutex);
 	head = &sbi->orphan_inode_list;
 	list_for_each(this, head) {
 		orphan = list_entry(this, struct orphan_inode_entry, list);
-		if (orphan->ino == ino)
-			goto out;
+		if (orphan->ino == ino) {
+			mutex_unlock(&sbi->orphan_inode_mutex);
+			kmem_cache_free(orphan_entry_slab, new);
+			return;
+		}
+
 		if (orphan->ino > ino)
 			break;
 		orphan = NULL;
 	}
 
-	new = f2fs_kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
-	new->ino = ino;
-
 	/* add new_oentry into list which is sorted by inode number */
 	if (orphan)
 		list_add(&new->list, this->prev);
 	else
 		list_add_tail(&new->list, head);
-out:
 	mutex_unlock(&sbi->orphan_inode_mutex);
 }
 

commit 4531929e3922f2cdd34208d7dc1404ac06e6ced5
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Fri Jan 10 18:09:02 2014 +0800

    f2fs: move grabing orphan pages out of protection region
    
    Move grabing orphan block page out of protection region, and grab all
    the orphan block pages ahead.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    [Jaegeuk Kim: remove unnecessary code pointed by Chao Yu]
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0d78bbe79f98..fdc5a12c0edd 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -303,22 +303,25 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 {
 	struct list_head *head;
 	struct f2fs_orphan_block *orphan_blk = NULL;
-	struct page *page = NULL;
 	unsigned int nentries = 0;
-	unsigned short index = 1;
-	unsigned short orphan_blocks;
+	unsigned short index;
+	unsigned short orphan_blocks = (unsigned short)((sbi->n_orphans +
+		(F2FS_ORPHANS_PER_BLOCK - 1)) / F2FS_ORPHANS_PER_BLOCK);
+	struct page *page = NULL;
+	struct page *pages[orphan_blocks];
 	struct orphan_inode_entry *orphan = NULL;
 
-	orphan_blocks = (unsigned short)((sbi->n_orphans +
-		(F2FS_ORPHANS_PER_BLOCK - 1)) / F2FS_ORPHANS_PER_BLOCK);
+	for (index = 0; index < orphan_blocks; index++)
+		pages[index] = grab_meta_page(sbi, start_blk + index);
 
+	index = 1;
 	mutex_lock(&sbi->orphan_inode_mutex);
 	head = &sbi->orphan_inode_list;
 
 	/* loop for each orphan inode entry and write them in Jornal block */
 	list_for_each_entry(orphan, head, list) {
 		if (!page) {
-			page = grab_meta_page(sbi, start_blk);
+			page = pages[index - 1];
 			orphan_blk =
 				(struct f2fs_orphan_block *)page_address(page);
 			memset(orphan_blk, 0, sizeof(*orphan_blk));
@@ -338,7 +341,6 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 			set_page_dirty(page);
 			f2fs_put_page(page, 1);
 			index++;
-			start_blk++;
 			nentries = 0;
 			page = NULL;
 		}

commit 0d47c1adc2a1f1e4f4673f122a8328c90c58e232
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Thu Dec 26 18:24:19 2013 +0800

    f2fs: convert max_orphans to a field of f2fs_sb_info
    
    Previously, we need to calculate the max orphan num when we try to acquire an
    orphan inode, but it's a stable value since the super block was inited. So
    converting it to a field of f2fs_sb_info and use it directly when needed seems
    a better choose.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2fc3b6beaeb8..0d78bbe79f98 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -194,23 +194,15 @@ const struct address_space_operations f2fs_meta_aops = {
 
 int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 {
-	unsigned int max_orphans;
 	int err = 0;
 
-	/*
-	 * considering 512 blocks in a segment 8 blocks are needed for cp
-	 * and log segment summaries. Remaining blocks are used to keep
-	 * orphan entries with the limitation one reserved segment
-	 * for cp pack we can have max 1020*504 orphan entries
-	 */
-	max_orphans = (sbi->blocks_per_seg - 2 - NR_CURSEG_TYPE)
-				* F2FS_ORPHANS_PER_BLOCK;
 	mutex_lock(&sbi->orphan_inode_mutex);
-	if (unlikely(sbi->n_orphans >= max_orphans))
+	if (unlikely(sbi->n_orphans >= sbi->max_orphans))
 		err = -ENOSPC;
 	else
 		sbi->n_orphans++;
 	mutex_unlock(&sbi->orphan_inode_mutex);
+
 	return err;
 }
 
@@ -834,6 +826,14 @@ void init_orphan_info(struct f2fs_sb_info *sbi)
 	mutex_init(&sbi->orphan_inode_mutex);
 	INIT_LIST_HEAD(&sbi->orphan_inode_list);
 	sbi->n_orphans = 0;
+	/*
+	 * considering 512 blocks in a segment 8 blocks are needed for cp
+	 * and log segment summaries. Remaining blocks are used to keep
+	 * orphan entries with the limitation one reserved segment
+	 * for cp pack we can have max 1020*504 orphan entries
+	 */
+	sbi->max_orphans = (sbi->blocks_per_seg - 2 - NR_CURSEG_TYPE)
+				* F2FS_ORPHANS_PER_BLOCK;
 }
 
 int __init create_checkpoint_caches(void)

commit 5459aa9770fe2e8c6a660a0985ea454c42cfd8c1
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Dec 17 17:28:41 2013 +0900

    f2fs: write dirty meta pages collectively
    
    This patch enhances writing dirty meta pages collectively in background.
    During the file data writes, it'd better avoid to write small dirty meta pages
    frequently.
    So let's give a chance to collect a number of dirty meta pages for a while.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f8c074961e0a..2fc3b6beaeb8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -107,18 +107,19 @@ static int f2fs_write_meta_pages(struct address_space *mapping,
 				struct writeback_control *wbc)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(mapping->host->i_sb);
-	struct block_device *bdev = sbi->sb->s_bdev;
+	int nrpages = MAX_BIO_BLOCKS(max_hw_blocks(sbi));
 	long written;
 
 	if (wbc->for_kupdate)
 		return 0;
 
-	if (get_pages(sbi, F2FS_DIRTY_META) == 0)
+	/* collect a number of dirty meta pages and write together */
+	if (get_pages(sbi, F2FS_DIRTY_META) < nrpages)
 		return 0;
 
 	/* if mounting is failed, skip writing node pages */
 	mutex_lock(&sbi->cp_mutex);
-	written = sync_meta_pages(sbi, META, bio_get_nr_vecs(bdev));
+	written = sync_meta_pages(sbi, META, nrpages);
 	mutex_unlock(&sbi->cp_mutex);
 	wbc->nr_to_write -= written;
 	return 0;

commit 458e6197c37de53f7be0a837644daabb900c3036
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Dec 11 13:54:01 2013 +0900

    f2fs: refactor bio->rw handling
    
    This patch introduces f2fs_io_info to mitigate the complex parameter list.
    
    struct f2fs_io_info {
            enum page_type type;            /* contains DATA/NODE/META/META_FLUSH */
            int rw;                         /* contains R/RS/W/WS */
            int rw_flag;                    /* contains REQ_META/REQ_PRIO */
    }
    
    1. f2fs_write_data_pages
     - DATA
     - WRITE_SYNC is set when wbc->WB_SYNC_ALL.
    
    2. sync_node_pages
     - NODE
     - WRITE_SYNC all the time
    
    3. sync_meta_pages
     - META
     - WRITE_SYNC all the time
     - REQ_META | REQ_PRIO all the time
    
     ** f2fs_submit_merged_bio() handles META_FLUSH.
    
    4. ra_nat_pages, ra_sit_pages, ra_sum_pages
     - META
     - READ_SYNC
    
    Cc: Fan Li <fanofcode.li@samsung.com>
    Cc: Changman Lee <cm224.lee@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index cf505eb843e8..f8c074961e0a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -164,8 +164,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 	}
 
 	if (nwritten)
-		f2fs_submit_merged_bio(sbi, type, nr_to_write == LONG_MAX,
-								WRITE);
+		f2fs_submit_merged_bio(sbi, type, WRITE);
 
 	return nwritten;
 }
@@ -598,7 +597,7 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 		 * We should submit bio, since it exists several
 		 * wribacking dentry pages in the freeing inode.
 		 */
-		f2fs_submit_merged_bio(sbi, DATA, true, WRITE);
+		f2fs_submit_merged_bio(sbi, DATA, WRITE);
 	}
 	goto retry;
 }
@@ -804,9 +803,9 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 
 	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish block_ops");
 
-	f2fs_submit_merged_bio(sbi, DATA, true, WRITE);
-	f2fs_submit_merged_bio(sbi, NODE, true, WRITE);
-	f2fs_submit_merged_bio(sbi, META, true, WRITE);
+	f2fs_submit_merged_bio(sbi, DATA, WRITE);
+	f2fs_submit_merged_bio(sbi, NODE, WRITE);
+	f2fs_submit_merged_bio(sbi, META, WRITE);
 
 	/*
 	 * update checkpoint pack index

commit 6bacf52fb58aeb3e89d9a62970b85a5570aa8ace
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Dec 6 15:00:58 2013 +0900

    f2fs: add unlikely() macro for compiler more aggressively
    
    This patch adds unlikely() macro into the most of codes.
    The basic rule is to add that when:
    - checking unusual errors,
    - checking page mappings,
    - and the other unlikely conditions.
    
    Change log from v1:
     - Don't add unlikely for the NULL test and error test: advised by Andi Kleen.
    
    Cc: Chao Yu <chao2.yu@samsung.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Reviewed-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6b2106685b7a..cf505eb843e8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -66,7 +66,7 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		goto repeat;
 
 	lock_page(page);
-	if (page->mapping != mapping) {
+	if (unlikely(page->mapping != mapping)) {
 		f2fs_put_page(page, 1);
 		goto repeat;
 	}
@@ -473,7 +473,7 @@ static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
 	list_for_each(this, head) {
 		struct dir_inode_entry *entry;
 		entry = list_entry(this, struct dir_inode_entry, list);
-		if (entry->inode == inode)
+		if (unlikely(entry->inode == inode))
 			return -EEXIST;
 	}
 	list_add_tail(&new->list, head);
@@ -783,7 +783,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	/* Here, we only have one bio having CP pack */
 	sync_meta_pages(sbi, META_FLUSH, LONG_MAX);
 
-	if (!is_set_ckpt_flags(ckpt, CP_ERROR_FLAG)) {
+	if (unlikely(!is_set_ckpt_flags(ckpt, CP_ERROR_FLAG))) {
 		clear_prefree_segments(sbi);
 		F2FS_RESET_SB_DIRT(sbi);
 	}
@@ -840,11 +840,11 @@ int __init create_checkpoint_caches(void)
 {
 	orphan_entry_slab = f2fs_kmem_cache_create("f2fs_orphan_entry",
 			sizeof(struct orphan_inode_entry), NULL);
-	if (unlikely(!orphan_entry_slab))
+	if (!orphan_entry_slab)
 		return -ENOMEM;
 	inode_entry_slab = f2fs_kmem_cache_create("f2fs_dirty_dir_entry",
 			sizeof(struct dir_inode_entry), NULL);
-	if (unlikely(!inode_entry_slab)) {
+	if (!inode_entry_slab) {
 		kmem_cache_destroy(orphan_entry_slab);
 		return -ENOMEM;
 	}

commit cfb271d485d0ec31eb92b51f4fbe54bf6542e8e6
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Dec 5 17:15:22 2013 +0800

    f2fs: add unlikely() macro for compiler optimization
    
    As we know, some of our branch condition will rarely be true. So we could add
    'unlikely' to let compiler optimize these code, by this way we could drop
    unneeded 'jump' assemble code to improve performance.
    
    change log:
     o add *unlikely* as many as possible across the whole source files at once
       suggested by Jaegeuk Kim.
    
    Suggested-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 38f4a2245085..6b2106685b7a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -82,13 +82,12 @@ static int f2fs_write_meta_page(struct page *page,
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
 
 	/* Should not write any meta pages, if any IO error was occurred */
-	if (wbc->for_reclaim || sbi->por_doing ||
-			is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ERROR_FLAG)) {
-		dec_page_count(sbi, F2FS_DIRTY_META);
-		wbc->pages_skipped++;
-		set_page_dirty(page);
-		return AOP_WRITEPAGE_ACTIVATE;
-	}
+	if (unlikely(sbi->por_doing ||
+			is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ERROR_FLAG)))
+		goto redirty_out;
+
+	if (wbc->for_reclaim)
+		goto redirty_out;
 
 	wait_on_page_writeback(page);
 
@@ -96,6 +95,12 @@ static int f2fs_write_meta_page(struct page *page,
 	dec_page_count(sbi, F2FS_DIRTY_META);
 	unlock_page(page);
 	return 0;
+
+redirty_out:
+	dec_page_count(sbi, F2FS_DIRTY_META);
+	wbc->pages_skipped++;
+	set_page_dirty(page);
+	return AOP_WRITEPAGE_ACTIVATE;
 }
 
 static int f2fs_write_meta_pages(struct address_space *mapping,
@@ -137,7 +142,7 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 		nr_pages = pagevec_lookup_tag(&pvec, mapping, &index,
 				PAGECACHE_TAG_DIRTY,
 				min(end - index, (pgoff_t)PAGEVEC_SIZE-1) + 1);
-		if (nr_pages == 0)
+		if (unlikely(nr_pages == 0))
 			break;
 
 		for (i = 0; i < nr_pages; i++) {
@@ -150,7 +155,8 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 				unlock_page(page);
 				break;
 			}
-			if (nwritten++ >= nr_to_write)
+			nwritten++;
+			if (unlikely(nwritten >= nr_to_write))
 				break;
 		}
 		pagevec_release(&pvec);
@@ -200,7 +206,7 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 	max_orphans = (sbi->blocks_per_seg - 2 - NR_CURSEG_TYPE)
 				* F2FS_ORPHANS_PER_BLOCK;
 	mutex_lock(&sbi->orphan_inode_mutex);
-	if (sbi->n_orphans >= max_orphans)
+	if (unlikely(sbi->n_orphans >= max_orphans))
 		err = -ENOSPC;
 	else
 		sbi->n_orphans++;

commit 93dfe2ac516250755f7d5edd438b0ce67c0e3aa6
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Sat Nov 30 12:51:14 2013 +0900

    f2fs: refactor bio-related operations
    
    This patch integrates redundant bio operations on read and write IOs.
    
    1. Move bio-related codes to the top of data.c.
    2. Replace f2fs_submit_bio with f2fs_submit_merged_bio, which handles read
       bios additionally.
    3. Introduce __submit_merged_bio to submit the merged bio.
    4. Change f2fs_readpage to f2fs_submit_page_bio.
    5. Introduce f2fs_submit_page_mbio to integrate previous submit_read_page and
       submit_write_page.
    
    Reviewed-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Reviewed-by: Chao Yu <chao2.yu@samsung.com >
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 40eea42f85ff..38f4a2245085 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -61,7 +61,8 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	if (PageUptodate(page))
 		goto out;
 
-	if (f2fs_readpage(sbi, page, index, READ_SYNC | REQ_META | REQ_PRIO))
+	if (f2fs_submit_page_bio(sbi, page, index,
+				READ_SYNC | REQ_META | REQ_PRIO))
 		goto repeat;
 
 	lock_page(page);
@@ -157,7 +158,8 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 	}
 
 	if (nwritten)
-		f2fs_submit_bio(sbi, type, nr_to_write == LONG_MAX);
+		f2fs_submit_merged_bio(sbi, type, nr_to_write == LONG_MAX,
+								WRITE);
 
 	return nwritten;
 }
@@ -590,7 +592,7 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 		 * We should submit bio, since it exists several
 		 * wribacking dentry pages in the freeing inode.
 		 */
-		f2fs_submit_bio(sbi, DATA, true);
+		f2fs_submit_merged_bio(sbi, DATA, true, WRITE);
 	}
 	goto retry;
 }
@@ -796,9 +798,9 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 
 	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish block_ops");
 
-	f2fs_submit_bio(sbi, DATA, true);
-	f2fs_submit_bio(sbi, NODE, true);
-	f2fs_submit_bio(sbi, META, true);
+	f2fs_submit_merged_bio(sbi, DATA, true, WRITE);
+	f2fs_submit_merged_bio(sbi, NODE, true, WRITE);
+	f2fs_submit_merged_bio(sbi, META, true, WRITE);
 
 	/*
 	 * update checkpoint pack index

commit 8f99a946f360c4083d6e323e10a5928e1ce385a4
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Thu Nov 28 15:43:43 2013 +0800

    f2fs: convert recover_orphan_inodes to void
    
    The recover_orphan_inodes() returns no error all the time, so we don't need to
    check its errors.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    [Jaegeuk Kim: add description]
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c7e0572fdede..40eea42f85ff 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -271,12 +271,12 @@ static void recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	iput(inode);
 }
 
-int recover_orphan_inodes(struct f2fs_sb_info *sbi)
+void recover_orphan_inodes(struct f2fs_sb_info *sbi)
 {
 	block_t start_blk, orphan_blkaddr, i, j;
 
 	if (!is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG))
-		return 0;
+		return;
 
 	sbi->por_doing = true;
 	start_blk = __start_cp_addr(sbi) + 1;
@@ -296,7 +296,7 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	/* clear Orphan Flag */
 	clear_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG);
 	sbi->por_doing = false;
-	return 0;
+	return;
 }
 
 static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)

commit 6947eea957e4c4c873f92a4ee5da7a6ef0012718
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Fri Nov 29 16:37:00 2013 +0800

    f2fs: avoid to calculate incorrect max orphan number
    
    Because we will write node summaries when do_checkpoint with umount flag,
    our number of max orphan blocks should minus NR_CURSEG_NODE_TYPE additional.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Shu Tan <shu.tan@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 21e721534965..c7e0572fdede 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -190,12 +190,13 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 	int err = 0;
 
 	/*
-	 * considering 512 blocks in a segment 5 blocks are needed for cp
+	 * considering 512 blocks in a segment 8 blocks are needed for cp
 	 * and log segment summaries. Remaining blocks are used to keep
 	 * orphan entries with the limitation one reserved segment
-	 * for cp pack we can have max 1020*507 orphan entries
+	 * for cp pack we can have max 1020*504 orphan entries
 	 */
-	max_orphans = (sbi->blocks_per_seg - 5) * F2FS_ORPHANS_PER_BLOCK;
+	max_orphans = (sbi->blocks_per_seg - 2 - NR_CURSEG_TYPE)
+				* F2FS_ORPHANS_PER_BLOCK;
 	mutex_lock(&sbi->orphan_inode_mutex);
 	if (sbi->n_orphans >= max_orphans)
 		err = -ENOSPC;

commit f9a4e6df52edf8ce1040d1b8d340d31234a1bce3
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Nov 28 12:44:05 2013 +0900

    f2fs: bug fix on bit overflow from 32bits to 64bits
    
    This patch fixes some bit overflows by the shift operations.
    
    Dan Carpenter reported potential bugs on bit overflows as follows.
    
    fs/f2fs/segment.c:910 submit_write_page()
            warn: should 'blk_addr << ((sbi)->log_blocksize - 9)' be a 64 bit type?
    fs/f2fs/checkpoint.c:429 get_valid_checkpoint()
            warn: should '1 << ()' be a 64 bit type?
    fs/f2fs/data.c:408 f2fs_readpage()
            warn: should 'blk_addr << ((sbi)->log_blocksize - 9)' be a 64 bit type?
    fs/f2fs/data.c:457 submit_read_page()
            warn: should 'blk_addr << ((sbi)->log_blocksize - 9)' be a 64 bit type?
    fs/f2fs/data.c:525 get_data_block_ro()
            warn: should 'i << blkbits' be a 64 bit type?
    
    Bug-Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3e62987e333a..21e721534965 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -426,7 +426,8 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	cp1 = validate_checkpoint(sbi, cp_start_blk_no, &cp1_version);
 
 	/* The second checkpoint pack should start at the next segment */
-	cp_start_blk_no += 1 << le32_to_cpu(fsb->log_blocks_per_seg);
+	cp_start_blk_no += ((unsigned long long)1) <<
+				le32_to_cpu(fsb->log_blocks_per_seg);
 	cp2 = validate_checkpoint(sbi, cp_start_blk_no, &cp2_version);
 
 	if (cp1 && cp2) {

commit 36795567942a033ef9e22d8eba86396ffb9aa80c
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Tue Nov 26 16:44:16 2013 +0800

    f2fs: fix a potential out of range issue
    
    Fix a potential out of range issue introduced by commit:
    22fb72225a
    f2fs: simplify write_orphan_inodes for better readable
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7fe69ff2bfe7..3e62987e333a 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -323,9 +323,9 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 			memset(orphan_blk, 0, sizeof(*orphan_blk));
 		}
 
-		orphan_blk->ino[nentries] = cpu_to_le32(orphan->ino);
+		orphan_blk->ino[nentries++] = cpu_to_le32(orphan->ino);
 
-		if (nentries++ == F2FS_ORPHANS_PER_BLOCK) {
+		if (nentries == F2FS_ORPHANS_PER_BLOCK) {
 			/*
 			 * an orphan block is full of 1020 entries,
 			 * then we need to flush current orphan blocks

commit 03232305ff3cf44761f7ea271f7c9af5105392b9
Author: Changman Lee <cm224.lee@samsung.com>
Date:   Sun Nov 24 15:13:08 2013 +0900

    f2fs: send REQ_META or REQ_PRIO when reading meta area
    
    Let's send REQ_META or REQ_PRIO when reading meta area such as NAT/SIT
    etc.
    
    Signed-off-by: Changman Lee <cm224.lee@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index eae8dc3e1c08..7fe69ff2bfe7 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -61,7 +61,7 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	if (PageUptodate(page))
 		goto out;
 
-	if (f2fs_readpage(sbi, page, index, READ_SYNC))
+	if (f2fs_readpage(sbi, page, index, READ_SYNC | REQ_META | REQ_PRIO))
 		goto repeat;
 
 	lock_page(page);

commit ce3b7d80edad7bc5ff347b9ff02f1484265b1f05
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Tue Nov 19 18:03:47 2013 +0800

    f2fs: move the list_head initialization into the lock protection region
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 247879f0e730..eae8dc3e1c08 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -511,8 +511,8 @@ void add_dirty_dir_inode(struct inode *inode)
 void remove_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
-	struct list_head *head = &sbi->dir_inode_list;
-	struct list_head *this;
+
+	struct list_head *this, *head;
 
 	if (!S_ISDIR(inode->i_mode))
 		return;
@@ -523,6 +523,7 @@ void remove_dirty_dir_inode(struct inode *inode)
 		return;
 	}
 
+	head = &sbi->dir_inode_list;
 	list_for_each(this, head) {
 		struct dir_inode_entry *entry;
 		entry = list_entry(this, struct dir_inode_entry, list);
@@ -544,11 +545,13 @@ void remove_dirty_dir_inode(struct inode *inode)
 
 struct inode *check_dirty_dir_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
-	struct list_head *head = &sbi->dir_inode_list;
-	struct list_head *this;
+
+	struct list_head *this, *head;
 	struct inode *inode = NULL;
 
 	spin_lock(&sbi->dir_inode_lock);
+
+	head = &sbi->dir_inode_list;
 	list_for_each(this, head) {
 		struct dir_inode_entry *entry;
 		entry = list_entry(this, struct dir_inode_entry, list);
@@ -563,11 +566,13 @@ struct inode *check_dirty_dir_inode(struct f2fs_sb_info *sbi, nid_t ino)
 
 void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 {
-	struct list_head *head = &sbi->dir_inode_list;
+	struct list_head *head;
 	struct dir_inode_entry *entry;
 	struct inode *inode;
 retry:
 	spin_lock(&sbi->dir_inode_lock);
+
+	head = &sbi->dir_inode_list;
 	if (list_empty(head)) {
 		spin_unlock(&sbi->dir_inode_lock);
 		return;

commit 502c6e0bcd95d45f734548e2fcf8a0de494a9095
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Tue Nov 19 18:03:58 2013 +0800

    f2fs: simplify write_orphan_inodes for better readable
    
    Simplify write_orphan_inodes for better readable. Because we hold the
    orphan_inode_mutex, so it's safe to use list_for_each_entry instead of
    list_for_each_safe.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5716e5eb4e8e..247879f0e730 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -300,12 +300,13 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 
 static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 {
-	struct list_head *head, *this, *next;
+	struct list_head *head;
 	struct f2fs_orphan_block *orphan_blk = NULL;
 	struct page *page = NULL;
 	unsigned int nentries = 0;
 	unsigned short index = 1;
 	unsigned short orphan_blocks;
+	struct orphan_inode_entry *orphan = NULL;
 
 	orphan_blocks = (unsigned short)((sbi->n_orphans +
 		(F2FS_ORPHANS_PER_BLOCK - 1)) / F2FS_ORPHANS_PER_BLOCK);
@@ -314,12 +315,17 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 	head = &sbi->orphan_inode_list;
 
 	/* loop for each orphan inode entry and write them in Jornal block */
-	list_for_each_safe(this, next, head) {
-		struct orphan_inode_entry *orphan;
+	list_for_each_entry(orphan, head, list) {
+		if (!page) {
+			page = grab_meta_page(sbi, start_blk);
+			orphan_blk =
+				(struct f2fs_orphan_block *)page_address(page);
+			memset(orphan_blk, 0, sizeof(*orphan_blk));
+		}
 
-		orphan = list_entry(this, struct orphan_inode_entry, list);
+		orphan_blk->ino[nentries] = cpu_to_le32(orphan->ino);
 
-		if (nentries == F2FS_ORPHANS_PER_BLOCK) {
+		if (nentries++ == F2FS_ORPHANS_PER_BLOCK) {
 			/*
 			 * an orphan block is full of 1020 entries,
 			 * then we need to flush current orphan blocks
@@ -335,24 +341,16 @@ static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
 			nentries = 0;
 			page = NULL;
 		}
-		if (page)
-			goto page_exist;
+	}
 
-		page = grab_meta_page(sbi, start_blk);
-		orphan_blk = (struct f2fs_orphan_block *)page_address(page);
-		memset(orphan_blk, 0, sizeof(*orphan_blk));
-page_exist:
-		orphan_blk->ino[nentries++] = cpu_to_le32(orphan->ino);
+	if (page) {
+		orphan_blk->blk_addr = cpu_to_le16(index);
+		orphan_blk->blk_count = cpu_to_le16(orphan_blocks);
+		orphan_blk->entry_count = cpu_to_le32(nentries);
+		set_page_dirty(page);
+		f2fs_put_page(page, 1);
 	}
-	if (!page)
-		goto end;
-
-	orphan_blk->blk_addr = cpu_to_le16(index);
-	orphan_blk->blk_count = cpu_to_le16(orphan_blocks);
-	orphan_blk->entry_count = cpu_to_le32(nentries);
-	set_page_dirty(page);
-	f2fs_put_page(page, 1);
-end:
+
 	mutex_unlock(&sbi->orphan_inode_mutex);
 }
 

commit fb51b5ef9c07844f80402702bd3d3002ceca5cd9
Author: Changman Lee <cm224.lee@samsung.com>
Date:   Thu Nov 7 12:48:25 2013 +0900

    f2fs: cleanup waiting routine for writeback pages in cp
    
    use genernal method supported by kernel
    
     o changes from v1
       If any waiter exists at end io, wake up it.
    
    Signed-off-by: Changman Lee <cm224.lee@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d430157ffe60..5716e5eb4e8e 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -634,6 +634,21 @@ static void unblock_operations(struct f2fs_sb_info *sbi)
 	f2fs_unlock_all(sbi);
 }
 
+static void wait_on_all_pages_writeback(struct f2fs_sb_info *sbi)
+{
+	DEFINE_WAIT(wait);
+
+	for (;;) {
+		prepare_to_wait(&sbi->cp_wait, &wait, TASK_UNINTERRUPTIBLE);
+
+		if (!get_pages(sbi, F2FS_WRITEBACK))
+			break;
+
+		io_schedule();
+	}
+	finish_wait(&sbi->cp_wait, &wait);
+}
+
 static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
@@ -743,15 +758,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	f2fs_put_page(cp_page, 1);
 
 	/* wait for previous submitted node/meta pages writeback */
-	sbi->cp_task = current;
-	while (get_pages(sbi, F2FS_WRITEBACK)) {
-		set_current_state(TASK_UNINTERRUPTIBLE);
-		if (!get_pages(sbi, F2FS_WRITEBACK))
-			break;
-		io_schedule();
-	}
-	__set_current_state(TASK_RUNNING);
-	sbi->cp_task = NULL;
+	wait_on_all_pages_writeback(sbi);
 
 	filemap_fdatawait_range(sbi->node_inode->i_mapping, 0, LONG_MAX);
 	filemap_fdatawait_range(sbi->meta_inode->i_mapping, 0, LONG_MAX);

commit 5d56b6718a0f4e5c58cdd3cb6b7a472d7c5671b9
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Oct 29 15:14:54 2013 +0900

    f2fs: add an option to avoid unnecessary BUG_ONs
    
    If you want to remove unnecessary BUG_ONs, you can just turn off F2FS_CHECK_FS
    in your kernel config.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6526f5010621..d430157ffe60 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -142,8 +142,8 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 		for (i = 0; i < nr_pages; i++) {
 			struct page *page = pvec.pages[i];
 			lock_page(page);
-			BUG_ON(page->mapping != mapping);
-			BUG_ON(!PageDirty(page));
+			f2fs_bug_on(page->mapping != mapping);
+			f2fs_bug_on(!PageDirty(page));
 			clear_page_dirty_for_io(page);
 			if (f2fs_write_meta_page(page, &wbc)) {
 				unlock_page(page);
@@ -208,7 +208,7 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 void release_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	mutex_lock(&sbi->orphan_inode_mutex);
-	BUG_ON(sbi->n_orphans == 0);
+	f2fs_bug_on(sbi->n_orphans == 0);
 	sbi->n_orphans--;
 	mutex_unlock(&sbi->orphan_inode_mutex);
 }
@@ -252,7 +252,7 @@ void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 		if (orphan->ino == ino) {
 			list_del(&orphan->list);
 			kmem_cache_free(orphan_entry_slab, orphan);
-			BUG_ON(sbi->n_orphans == 0);
+			f2fs_bug_on(sbi->n_orphans == 0);
 			sbi->n_orphans--;
 			break;
 		}
@@ -263,7 +263,7 @@ void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 static void recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	struct inode *inode = f2fs_iget(sbi->sb, ino);
-	BUG_ON(IS_ERR(inode));
+	f2fs_bug_on(IS_ERR(inode));
 	clear_nlink(inode);
 
 	/* truncate all the data during iput */

commit 26c6b8879911df991dc780c67eaeb84c7629949d
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Oct 24 17:53:29 2013 +0900

    f2fs: add tracepoint for set_page_dirty
    
    This patch adds a tracepoint for set_page_dirty.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 5649a9d8e942..6526f5010621 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -167,6 +167,8 @@ static int f2fs_set_meta_page_dirty(struct page *page)
 	struct address_space *mapping = page->mapping;
 	struct f2fs_sb_info *sbi = F2FS_SB(mapping->host->i_sb);
 
+	trace_f2fs_set_page_dirty(page, META);
+
 	SetPageUptodate(page);
 	if (!PageDirty(page)) {
 		__set_page_dirty_nobuffers(page);

commit aabe51364f44681cbd83fb1c27ef7d3dbe567c45
Author: Haicheng Li <haicheng.li@linux.intel.com>
Date:   Wed Oct 23 12:39:32 2013 +0800

    f2fs: use bool for booleans
    
    Signed-off-by: Haicheng Li <haicheng.li@linux.intel.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b4a59cf99f1c..5649a9d8e942 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -275,7 +275,7 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	if (!is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG))
 		return 0;
 
-	sbi->por_doing = 1;
+	sbi->por_doing = true;
 	start_blk = __start_cp_addr(sbi) + 1;
 	orphan_blkaddr = __start_sum_addr(sbi) - 1;
 
@@ -292,7 +292,7 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 	}
 	/* clear Orphan Flag */
 	clear_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG);
-	sbi->por_doing = 0;
+	sbi->por_doing = false;
 	return 0;
 }
 

commit dcdfff65276fdc6dfe5eb1d0aff802dfa7a95e15
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Oct 22 20:56:10 2013 +0900

    f2fs: clean up several status-related operations
    
    This patch cleans up improper definitions that update some status information.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6fb484c84ee7..b4a59cf99f1c 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -467,9 +467,7 @@ static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
 			return -EEXIST;
 	}
 	list_add_tail(&new->list, head);
-#ifdef CONFIG_F2FS_STAT_FS
-	sbi->n_dirty_dirs++;
-#endif
+	stat_inc_dirty_dir(sbi);
 	return 0;
 }
 
@@ -531,9 +529,7 @@ void remove_dirty_dir_inode(struct inode *inode)
 		if (entry->inode == inode) {
 			list_del(&entry->list);
 			kmem_cache_free(inode_entry_slab, entry);
-#ifdef CONFIG_F2FS_STAT_FS
-			sbi->n_dirty_dirs--;
-#endif
+			stat_dec_dirty_dir(sbi);
 			break;
 		}
 	}

commit 7bd59381c82defe19875284c48b1ac9dacd16e8f
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Tue Oct 22 14:52:26 2013 +0800

    f2fs: introduce f2fs_kmem_cache_alloc to hide the unfailed, kmem cache allocation
    
    Introduce the unfailed version of kmem_cache_alloc named f2fs_kmem_cache_alloc
    to hide the retry routine and make the code a bit cleaner.
    
    v2:
       Fix the wrong use of 'retry' tag pointed out by Gao feng.
       Use more neat code to remove redundant tag suggested by Haicheng Li.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 8d16071a3b23..6fb484c84ee7 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -226,12 +226,8 @@ void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 			break;
 		orphan = NULL;
 	}
-retry:
-	new = kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
-	if (!new) {
-		cond_resched();
-		goto retry;
-	}
+
+	new = f2fs_kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
 	new->ino = ino;
 
 	/* add new_oentry into list which is sorted by inode number */
@@ -484,12 +480,8 @@ void set_dirty_dir_page(struct inode *inode, struct page *page)
 
 	if (!S_ISDIR(inode->i_mode))
 		return;
-retry:
-	new = kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
-	if (!new) {
-		cond_resched();
-		goto retry;
-	}
+
+	new = f2fs_kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
 	new->inode = inode;
 	INIT_LIST_HEAD(&new->list);
 
@@ -506,13 +498,9 @@ void set_dirty_dir_page(struct inode *inode, struct page *page)
 void add_dirty_dir_inode(struct inode *inode)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
-	struct dir_inode_entry *new;
-retry:
-	new = kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
-	if (!new) {
-		cond_resched();
-		goto retry;
-	}
+	struct dir_inode_entry *new =
+			f2fs_kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
+
 	new->inode = inode;
 	INIT_LIST_HEAD(&new->list);
 

commit 87a9bd265678ec3cc8431b14bcb14c68d0f94032
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Oct 16 15:09:26 2013 +0900

    f2fs: avoid to write during the recovery
    
    This patch enhances the recovery routine not to write any data/node/meta until
    its completion.
    If any writes are sent to the disk, it could contaminate the written history
    that will be used for further recovery.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2a5999d865b2..8d16071a3b23 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -81,7 +81,7 @@ static int f2fs_write_meta_page(struct page *page,
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
 
 	/* Should not write any meta pages, if any IO error was occurred */
-	if (wbc->for_reclaim ||
+	if (wbc->for_reclaim || sbi->por_doing ||
 			is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ERROR_FLAG)) {
 		dec_page_count(sbi, F2FS_DIRTY_META);
 		wbc->pages_skipped++;

commit e234088758fca3a669ebb1a02d8bf7bf60f0e4ff
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Mon Oct 14 18:45:56 2013 +0800

    f2fs: avoid wait if IO end up when do_checkpoint for better performance
    
    Previously, do_checkpoint() will call congestion_wait() for waiting the pages
    (previous submitted node/meta/data pages) to be written back.
    Because congestion_wait() will set a regular period (e.g. HZ / 50 ) for waiting, and
    no additional wake up mechanism was introduced if IO ends up before regular period costed.
    Yuan Zhong found there is a situation that after the pages have been written back,
    but the checkpoint thread still wait for congestion_wait to exit.
    
    So here we store checkpoint task into f2fs_sb when doing checkpoint, it'll wait for IO completes
    if there's IO going on, and in the end IO path, wake up checkpoint task when IO ends up.
    
    Thanks to Yuan Zhong's pre work about this problem.
    
    Reported-by: Yuan Zhong <yuan.mark.zhong@samsung.com>
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d80882763ffd..2a5999d865b2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -757,8 +757,15 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	f2fs_put_page(cp_page, 1);
 
 	/* wait for previous submitted node/meta pages writeback */
-	while (get_pages(sbi, F2FS_WRITEBACK))
-		congestion_wait(BLK_RW_ASYNC, HZ / 50);
+	sbi->cp_task = current;
+	while (get_pages(sbi, F2FS_WRITEBACK)) {
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		if (!get_pages(sbi, F2FS_WRITEBACK))
+			break;
+		io_schedule();
+	}
+	__set_current_state(TASK_RUNNING);
+	sbi->cp_task = NULL;
 
 	filemap_fdatawait_range(sbi->node_inode->i_mapping, 0, LONG_MAX);
 	filemap_fdatawait_range(sbi->meta_inode->i_mapping, 0, LONG_MAX);

commit e479556bfdd136669854292eb57ed0139d7253d5
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Fri Sep 27 18:08:30 2013 +0800

    f2fs: use rw_sem instead of fs_lock(locks mutex)
    
    The fs_locks is used to block other ops(ex, recovery) when doing checkpoint.
    And each other operate routine(besides checkpoint) needs to acquire a fs_lock,
    there is a terrible problem here, if these are too many concurrency threads acquiring
    fs_lock, so that they will block each other and may lead to some performance problem,
    but this is not the phenomenon we want to see.
    Though there are some optimization patches introduced to enhance the usage of fs_lock,
    but the thorough solution is using a *rw_sem* to replace the fs_lock.
    Checkpoint routine takes write_sem, and other ops take read_sem, so that we can block
    other ops(ex, recovery) when doing checkpoint, and other ops will not disturb each other,
    this can avoid the problem described above completely.
    Because of the weakness of rw_sem, the above change may introduce a potential problem
    that the checkpoint thread might get starved if other threads are intensively locking
    the read semaphore for I/O.(Pointed out by Xu Jin)
    In order to avoid this, a wait_list is introduced, the appending read semaphore ops
    will be dropped into the wait_list if checkpoint thread is waiting for write semaphore,
    and will be waked up when checkpoint thread gives up write semaphore.
    Thanks to Kim's previous review and test, and will be very glad to see other guys'
    performance tests about this patch.
    
    V2:
      -fix the potential starvation problem.
      -use more suitable func name suggested by Xu Jin.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    [Jaegeuk Kim: adjust minor coding standard]
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ca3944240db5..d80882763ffd 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -619,11 +619,10 @@ static void block_operations(struct f2fs_sb_info *sbi)
 	blk_start_plug(&plug);
 
 retry_flush_dents:
-	mutex_lock_all(sbi);
-
+	f2fs_lock_all(sbi);
 	/* write all the dirty dentry pages */
 	if (get_pages(sbi, F2FS_DIRTY_DENTS)) {
-		mutex_unlock_all(sbi);
+		f2fs_unlock_all(sbi);
 		sync_dirty_dir_inodes(sbi);
 		goto retry_flush_dents;
 	}
@@ -646,7 +645,7 @@ static void block_operations(struct f2fs_sb_info *sbi)
 static void unblock_operations(struct f2fs_sb_info *sbi)
 {
 	mutex_unlock(&sbi->node_write);
-	mutex_unlock_all(sbi);
+	f2fs_unlock_all(sbi);
 }
 
 static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)

commit 885166c03c1d0ea6d79d707229340e3161ed1316
Author: Russ W. Knize <russ@knizefamily.net>
Date:   Tue Sep 24 09:35:40 2013 -0500

    f2fs: don't let the orphan inode counter underflow
    
    Accounting errors from buggy code calling the acquire/release/remove
    orphan inode interfaces can cause n_orphans to underflow, which will
    then cause acquire_orphan_inode() to return -ENOSPC on the next
    operation.  This commit guards against that condition.
    
    Signed-off-by: Russ Knize <rknize@motorola.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index bb312201ca95..ca3944240db5 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -206,6 +206,7 @@ int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 void release_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	mutex_lock(&sbi->orphan_inode_mutex);
+	BUG_ON(sbi->n_orphans == 0);
 	sbi->n_orphans--;
 	mutex_unlock(&sbi->orphan_inode_mutex);
 }
@@ -253,6 +254,7 @@ void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 		if (orphan->ino == ino) {
 			list_del(&orphan->list);
 			kmem_cache_free(orphan_entry_slab, orphan);
+			BUG_ON(sbi->n_orphans == 0);
 			sbi->n_orphans--;
 			break;
 		}

commit d71b5564c0da4f652af2e4ca9d3c22b9c960ec1f
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Aug 9 15:03:21 2013 +0900

    f2fs: introduce cur_cp_version function to reduce code size
    
    This patch introduces a new inline function, cur_cp_version, to reduce redundant
    codes.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index c5a5c390a5cc..bb312201ca95 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -379,7 +379,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
 		goto invalid_cp1;
 
-	pre_version = le64_to_cpu(cp_block->checkpoint_ver);
+	pre_version = cur_cp_version(cp_block);
 
 	/* Read the 2nd cp block in this CP pack */
 	cp_addr += le32_to_cpu(cp_block->cp_pack_total_block_count) - 1;
@@ -394,7 +394,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
 		goto invalid_cp2;
 
-	cur_version = le64_to_cpu(cp_block->checkpoint_ver);
+	cur_version = cur_cp_version(cp_block);
 
 	if (cur_version == pre_version) {
 		*version = cur_version;
@@ -799,7 +799,7 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	 * Increase the version number so that
 	 * SIT entries and seg summaries are written at correct place
 	 */
-	ckpt_ver = le64_to_cpu(ckpt->checkpoint_ver);
+	ckpt_ver = cur_cp_version(ckpt);
 	ckpt->checkpoint_ver = cpu_to_le64(++ckpt_ver);
 
 	/* write cached NAT/SIT entries to NAT/SIT area */

commit cbd56e7d20d7188d62a85aa6986a7b2c8e755ab5
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue Jul 30 11:36:53 2013 +0900

    f2fs: fix handling orphan inodes
    
    This patch fixes mishandling of the sbi->n_orphans variable.
    
    If users request lots of f2fs_unlink(), check_orphan_space() could be contended.
    In such the case, sbi->n_orphans can be read incorrectly so that f2fs_unlink()
    would fall into the wrong state which results in the failure of
    add_orphan_inode().
    
    So, let's increment sbi->n_orphans virtually prior to the actual orphan inode
    stuffs. After that, let's release sbi->n_orphans by calling release_orphan_inode
    or remove_orphan_inode.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index fe91773de130..c5a5c390a5cc 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -182,7 +182,7 @@ const struct address_space_operations f2fs_meta_aops = {
 	.set_page_dirty	= f2fs_set_meta_page_dirty,
 };
 
-int check_orphan_space(struct f2fs_sb_info *sbi)
+int acquire_orphan_inode(struct f2fs_sb_info *sbi)
 {
 	unsigned int max_orphans;
 	int err = 0;
@@ -197,10 +197,19 @@ int check_orphan_space(struct f2fs_sb_info *sbi)
 	mutex_lock(&sbi->orphan_inode_mutex);
 	if (sbi->n_orphans >= max_orphans)
 		err = -ENOSPC;
+	else
+		sbi->n_orphans++;
 	mutex_unlock(&sbi->orphan_inode_mutex);
 	return err;
 }
 
+void release_orphan_inode(struct f2fs_sb_info *sbi)
+{
+	mutex_lock(&sbi->orphan_inode_mutex);
+	sbi->n_orphans--;
+	mutex_unlock(&sbi->orphan_inode_mutex);
+}
+
 void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
 	struct list_head *head, *this;
@@ -229,8 +238,6 @@ void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 		list_add(&new->list, this->prev);
 	else
 		list_add_tail(&new->list, head);
-
-	sbi->n_orphans++;
 out:
 	mutex_unlock(&sbi->orphan_inode_mutex);
 }

commit 60ed9a0f53c55d4be3882f7522e8349a5011a1d5
Author: Gu Zheng <guz.fnst@cn.fujitsu.com>
Date:   Fri Jul 19 16:24:06 2013 +0800

    f2fs: use list_for_each rather than list_for_each_safe, in remove_orphan_inode()
    
    As we remove the target single node, so list_for_each is enought, in order to
    clean up, we use list_for_each_entry instead.
    
    Signed-off-by: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 66a6b85a51d8..fe91773de130 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -237,13 +237,12 @@ void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 
 void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 {
-	struct list_head *this, *next, *head;
+	struct list_head *head;
 	struct orphan_inode_entry *orphan;
 
 	mutex_lock(&sbi->orphan_inode_mutex);
 	head = &sbi->orphan_inode_list;
-	list_for_each_safe(this, next, head) {
-		orphan = list_entry(this, struct orphan_inode_entry, list);
+	list_for_each_entry(orphan, head, list) {
 		if (orphan->ino == ino) {
 			list_del(&orphan->list);
 			kmem_cache_free(orphan_entry_slab, orphan);

commit 7e586fa0244578320fcced9cc08c6b124f727c35
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Jun 19 20:47:19 2013 +0900

    f2fs: fix crc endian conversion
    
    While calculating CRC for the checkpoint block, we use __u32, but when storing
    the crc value to the disk, we use __le32.
    
    Let's fix the inconsistency.
    
    Reported-and-Tested-by: Oded Gabbay <ogabbay@advaoptical.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9a7750909221..66a6b85a51d8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -357,8 +357,8 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	unsigned long blk_size = sbi->blocksize;
 	struct f2fs_checkpoint *cp_block;
 	unsigned long long cur_version = 0, pre_version = 0;
-	unsigned int crc = 0;
 	size_t crc_offset;
+	__u32 crc = 0;
 
 	/* Read the 1st cp block in this CP pack */
 	cp_page_1 = get_meta_page(sbi, cp_addr);
@@ -369,7 +369,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	if (crc_offset >= blk_size)
 		goto invalid_cp1;
 
-	crc = *(unsigned int *)((unsigned char *)cp_block + crc_offset);
+	crc = le32_to_cpu(*((__u32 *)((unsigned char *)cp_block + crc_offset)));
 	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
 		goto invalid_cp1;
 
@@ -384,7 +384,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	if (crc_offset >= blk_size)
 		goto invalid_cp2;
 
-	crc = *(unsigned int *)((unsigned char *)cp_block + crc_offset);
+	crc = le32_to_cpu(*((__u32 *)((unsigned char *)cp_block + crc_offset)));
 	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
 		goto invalid_cp2;
 
@@ -648,7 +648,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	block_t start_blk;
 	struct page *cp_page;
 	unsigned int data_sum_blocks, orphan_blocks;
-	unsigned int crc32 = 0;
+	__u32 crc32 = 0;
 	void *kaddr;
 	int i;
 
@@ -717,8 +717,8 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	get_nat_bitmap(sbi, __bitmap_ptr(sbi, NAT_BITMAP));
 
 	crc32 = f2fs_crc32(ckpt, le32_to_cpu(ckpt->checksum_offset));
-	*(__le32 *)((unsigned char *)ckpt +
-				le32_to_cpu(ckpt->checksum_offset))
+	*((__le32 *)((unsigned char *)ckpt +
+				le32_to_cpu(ckpt->checksum_offset)))
 				= cpu_to_le32(crc32);
 
 	start_blk = __start_cp_addr(sbi);

commit 5deb82671ae344b28b4e744020afcbc76df1779b
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Jun 5 17:42:45 2013 +0900

    f2fs: fix iget/iput of dir during recovery
    
    It is possible that iput is skipped after iget during the recovery.
    
    In recover_dentry(),
     dir = f2fs_iget();
     ...
     if (de && inode->i_ino == le32_to_cpu(de->ino))
            goto out;
    
    In this case, this dir is not able to be added in dirty_dir_inode_list.
    The actual linking is done only when set_page_dirty() is called.
    
    So let's add this newly got inode into the list explicitly, and put it at the
    end of the recovery routine.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6f56e5781dc3..9a7750909221 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -450,13 +450,30 @@ int get_valid_checkpoint(struct f2fs_sb_info *sbi)
 	return -EINVAL;
 }
 
-void set_dirty_dir_page(struct inode *inode, struct page *page)
+static int __add_dirty_inode(struct inode *inode, struct dir_inode_entry *new)
 {
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
 	struct list_head *head = &sbi->dir_inode_list;
-	struct dir_inode_entry *new;
 	struct list_head *this;
 
+	list_for_each(this, head) {
+		struct dir_inode_entry *entry;
+		entry = list_entry(this, struct dir_inode_entry, list);
+		if (entry->inode == inode)
+			return -EEXIST;
+	}
+	list_add_tail(&new->list, head);
+#ifdef CONFIG_F2FS_STAT_FS
+	sbi->n_dirty_dirs++;
+#endif
+	return 0;
+}
+
+void set_dirty_dir_page(struct inode *inode, struct page *page)
+{
+	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	struct dir_inode_entry *new;
+
 	if (!S_ISDIR(inode->i_mode))
 		return;
 retry:
@@ -469,25 +486,31 @@ void set_dirty_dir_page(struct inode *inode, struct page *page)
 	INIT_LIST_HEAD(&new->list);
 
 	spin_lock(&sbi->dir_inode_lock);
-	list_for_each(this, head) {
-		struct dir_inode_entry *entry;
-		entry = list_entry(this, struct dir_inode_entry, list);
-		if (entry->inode == inode) {
-			kmem_cache_free(inode_entry_slab, new);
-			goto out;
-		}
-	}
-	list_add_tail(&new->list, head);
-#ifdef CONFIG_F2FS_STAT_FS
-	sbi->n_dirty_dirs++;
-#endif
+	if (__add_dirty_inode(inode, new))
+		kmem_cache_free(inode_entry_slab, new);
 
-	BUG_ON(!S_ISDIR(inode->i_mode));
-out:
 	inc_page_count(sbi, F2FS_DIRTY_DENTS);
 	inode_inc_dirty_dents(inode);
 	SetPagePrivate(page);
+	spin_unlock(&sbi->dir_inode_lock);
+}
+
+void add_dirty_dir_inode(struct inode *inode)
+{
+	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	struct dir_inode_entry *new;
+retry:
+	new = kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
+	if (!new) {
+		cond_resched();
+		goto retry;
+	}
+	new->inode = inode;
+	INIT_LIST_HEAD(&new->list);
 
+	spin_lock(&sbi->dir_inode_lock);
+	if (__add_dirty_inode(inode, new))
+		kmem_cache_free(inode_entry_slab, new);
 	spin_unlock(&sbi->dir_inode_lock);
 }
 

commit afc3eda2a897b402e59f42f22eb89bba52297dd3
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Tue May 28 09:59:27 2013 +0900

    f2fs: fix incorrect iputs during the dentry recovery
    
    - iget/iput flow in the dentry recovery process
    
    1. *dir* = f2fs_iget
    2. set FI_DELAY_IPUT to *dir*
    3. add *dir* to the dirty_dir_list
                       - __f2fs_add_link
                         - recover_dentry)
    4. iput *dir* by remove_dirty_dir_inode
                       - sync_dirty_dir_inodes
                         - write_chekcpoint
    
    If *dir*'s i_count is not 1 (i.e., root dir), remove_dirty_dir_inode is called
    later and then iput is triggered again due to the FI_DELAY_IPUT flag.
    So, let's unset the flag properly once iput is triggered.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 0d3701dce462..6f56e5781dc3 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -521,8 +521,10 @@ void remove_dirty_dir_inode(struct inode *inode)
 	spin_unlock(&sbi->dir_inode_lock);
 
 	/* Only from the recovery routine */
-	if (is_inode_flag_set(F2FS_I(inode), FI_DELAY_IPUT))
+	if (is_inode_flag_set(F2FS_I(inode), FI_DELAY_IPUT)) {
+		clear_inode_flag(F2FS_I(inode), FI_DELAY_IPUT);
 		iput(inode);
+	}
 }
 
 struct inode *check_dirty_dir_inode(struct f2fs_sb_info *sbi, nid_t ino)

commit 3b10b1fd2b6bc82eeb346ff6a6621d065908ea6d
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Mon May 27 10:32:01 2013 +0900

    f2fs: iput only if whole data blocks are flushed
    
    If there remains some unwritten blocks from the recovery, we should not call
    iput on that directory inode.
    Otherwise, we can loose some dentry blocks after the recovery.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 01ddc911ac9b..0d3701dce462 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -501,8 +501,10 @@ void remove_dirty_dir_inode(struct inode *inode)
 		return;
 
 	spin_lock(&sbi->dir_inode_lock);
-	if (atomic_read(&F2FS_I(inode)->dirty_dents))
-		goto out;
+	if (atomic_read(&F2FS_I(inode)->dirty_dents)) {
+		spin_unlock(&sbi->dir_inode_lock);
+		return;
+	}
 
 	list_for_each(this, head) {
 		struct dir_inode_entry *entry;
@@ -516,7 +518,6 @@ void remove_dirty_dir_inode(struct inode *inode)
 			break;
 		}
 	}
-out:
 	spin_unlock(&sbi->dir_inode_lock);
 
 	/* Only from the recovery routine */

commit 35b09d82c3cf3fc0b8b6d923e7fd82ff7926aafc
Author: Namjae Jeon <namjae.jeon@samsung.com>
Date:   Thu May 23 22:57:53 2013 +0900

    f2fs: push some variables to debug part
    
    Some, counters are needed only for the statistical information
    while debugging.
    So, those can be controlled using CONFIG_F2FS_STAT_FS,
    pushing the usage for few variables under this flag.
    
    Signed-off-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Amit Sahrawat <a.sahrawat@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 3d1144908ac6..01ddc911ac9b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -478,7 +478,9 @@ void set_dirty_dir_page(struct inode *inode, struct page *page)
 		}
 	}
 	list_add_tail(&new->list, head);
+#ifdef CONFIG_F2FS_STAT_FS
 	sbi->n_dirty_dirs++;
+#endif
 
 	BUG_ON(!S_ISDIR(inode->i_mode));
 out:
@@ -508,7 +510,9 @@ void remove_dirty_dir_inode(struct inode *inode)
 		if (entry->inode == inode) {
 			list_del(&entry->list);
 			kmem_cache_free(inode_entry_slab, entry);
+#ifdef CONFIG_F2FS_STAT_FS
 			sbi->n_dirty_dirs--;
+#endif
 			break;
 		}
 	}

commit 74d0b917ef7789097e12d60fc054efa427ce9171
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed May 15 16:40:02 2013 +0900

    f2fs: fix BUG_ON during f2fs_evict_inode(dir)
    
    During the dentry recovery routine, recover_inode() triggers __f2fs_add_link
    with its directory inode.
    
    In the following scenario, a bug is captured.
     1. dir = f2fs_iget(pino)
     2. __f2fs_add_link(dir, name)
     3. iput(dir)
      -> f2fs_evict_inode() faces with BUG_ON(atomic_read(fi->dirty_dents))
    
    Kernel BUG at ffffffffa01c0676 [verbose debug info unavailable]
    [<ffffffffa01c0676>] f2fs_evict_inode+0x276/0x300 [f2fs]
    Call Trace:
     [<ffffffff8118ea00>] evict+0xb0/0x1b0
     [<ffffffff8118f1c5>] iput+0x105/0x190
     [<ffffffffa01d2dac>] recover_fsync_data+0x3bc/0x1070 [f2fs]
     [<ffffffff81692e8a>] ? io_schedule+0xaa/0xd0
     [<ffffffff81690acb>] ? __wait_on_bit_lock+0x7b/0xc0
     [<ffffffff8111a0e7>] ? __lock_page+0x67/0x70
     [<ffffffff81165e21>] ? kmem_cache_alloc+0x31/0x140
     [<ffffffff8118a502>] ? __d_instantiate+0x92/0xf0
     [<ffffffff812a949b>] ? security_d_instantiate+0x1b/0x30
     [<ffffffff8118a5b4>] ? d_instantiate+0x54/0x70
    
    This means that we should flush all the dentry pages between iget and iput().
    But, during the recovery routine, it is unallowed due to consistency, so we
    have to wait the whole recovery process.
    And then, write_checkpoint flushes all the dirty dentry blocks, and nicely we
    can put the stale dir inodes from the dirty_dir_inode_list.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index b1de01da1a40..3d1144908ac6 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -514,6 +514,29 @@ void remove_dirty_dir_inode(struct inode *inode)
 	}
 out:
 	spin_unlock(&sbi->dir_inode_lock);
+
+	/* Only from the recovery routine */
+	if (is_inode_flag_set(F2FS_I(inode), FI_DELAY_IPUT))
+		iput(inode);
+}
+
+struct inode *check_dirty_dir_inode(struct f2fs_sb_info *sbi, nid_t ino)
+{
+	struct list_head *head = &sbi->dir_inode_list;
+	struct list_head *this;
+	struct inode *inode = NULL;
+
+	spin_lock(&sbi->dir_inode_lock);
+	list_for_each(this, head) {
+		struct dir_inode_entry *entry;
+		entry = list_entry(this, struct dir_inode_entry, list);
+		if (entry->inode->i_ino == ino) {
+			inode = entry->inode;
+			break;
+		}
+	}
+	spin_unlock(&sbi->dir_inode_lock);
+	return inode;
 }
 
 void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)

commit afcb7ca01f47b0481e0b248d1542d0934fa70767
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Apr 26 11:55:17 2013 +0900

    f2fs: check truncation of mapping after lock_page
    
    We call lock_page when we need to update a page after readpage.
    Between grab and lock page, the page can be truncated by other thread.
    So, we should check the page after lock_page whether it was truncated or not.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 590ea50c80a7..b1de01da1a40 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -65,6 +65,10 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		goto repeat;
 
 	lock_page(page);
+	if (page->mapping != mapping) {
+		f2fs_put_page(page, 1);
+		goto repeat;
+	}
 out:
 	mark_page_accessed(page);
 	return page;

commit c718379b6b0954a04a153d7e5dc8b3136a301ee6
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Apr 24 13:19:56 2013 +0900

    f2fs: give a chance to merge IOs by IO scheduler
    
    Previously, background GC submits many 4KB read requests to load victim blocks
    and/or its (i)node blocks.
    
    ...
    f2fs_gc : f2fs_readpage: ino = 1, page_index = 0xb61, blkaddr = 0x3b964ed
    f2fs_gc : block_rq_complete: 8,16 R () 499854968 + 8 [0]
    f2fs_gc : f2fs_readpage: ino = 1, page_index = 0xb6f, blkaddr = 0x3b964ee
    f2fs_gc : block_rq_complete: 8,16 R () 499854976 + 8 [0]
    f2fs_gc : f2fs_readpage: ino = 1, page_index = 0xb79, blkaddr = 0x3b964ef
    f2fs_gc : block_rq_complete: 8,16 R () 499854984 + 8 [0]
    ...
    
    However, by the fact that many IOs are sequential, we can give a chance to merge
    the IOs by IO scheduler.
    In order to do that, let's use blk_plug.
    
    ...
    f2fs_gc : f2fs_iget: ino = 143
    f2fs_gc : f2fs_readpage: ino = 143, page_index = 0x1c6, blkaddr = 0x2e6ee
    f2fs_gc : f2fs_iget: ino = 143
    f2fs_gc : f2fs_readpage: ino = 143, page_index = 0x1c7, blkaddr = 0x2e6ef
    <idle> : block_rq_complete: 8,16 R () 1519616 + 8 [0]
    <idle> : block_rq_complete: 8,16 R () 1519848 + 8 [0]
    <idle> : block_rq_complete: 8,16 R () 1520432 + 96 [0]
    <idle> : block_rq_complete: 8,16 R () 1520536 + 104 [0]
    <idle> : block_rq_complete: 8,16 R () 1521008 + 112 [0]
    <idle> : block_rq_complete: 8,16 R () 1521440 + 152 [0]
    <idle> : block_rq_complete: 8,16 R () 1521688 + 144 [0]
    <idle> : block_rq_complete: 8,16 R () 1522128 + 192 [0]
    <idle> : block_rq_complete: 8,16 R () 1523256 + 328 [0]
    ...
    
    Note that this issue should be addressed in checkpoint, and some readahead
    flows too.
    
    Reviewed-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index f54b83b4d90b..590ea50c80a7 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -549,6 +549,10 @@ static void block_operations(struct f2fs_sb_info *sbi)
 		.nr_to_write = LONG_MAX,
 		.for_reclaim = 0,
 	};
+	struct blk_plug plug;
+
+	blk_start_plug(&plug);
+
 retry_flush_dents:
 	mutex_lock_all(sbi);
 
@@ -571,6 +575,7 @@ static void block_operations(struct f2fs_sb_info *sbi)
 		sync_node_pages(sbi, 0, &wbc);
 		goto retry_flush_nodes;
 	}
+	blk_finish_plug(&plug);
 }
 
 static void unblock_operations(struct f2fs_sb_info *sbi)

commit 2af4bd6ca556d690ee166200abd16fdbe749782e
Author: Namjae Jeon <namjae.jeon@samsung.com>
Date:   Tue Apr 23 18:26:54 2013 +0900

    f2fs: add tracepoints to debug checkpoint request
    
    Add tracepoints to debug checkpoint request.
    
    Signed-off-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Pankaj Kumar <pankaj.km@samsung.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    [Jaegeuk: change expressions]
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index be6aa2eef894..f54b83b4d90b 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -20,6 +20,7 @@
 #include "f2fs.h"
 #include "node.h"
 #include "segment.h"
+#include <trace/events/f2fs.h>
 
 static struct kmem_cache *orphan_entry_slab;
 static struct kmem_cache *inode_entry_slab;
@@ -714,9 +715,13 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	unsigned long long ckpt_ver;
 
+	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "start block_ops");
+
 	mutex_lock(&sbi->cp_mutex);
 	block_operations(sbi);
 
+	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish block_ops");
+
 	f2fs_submit_bio(sbi, DATA, true);
 	f2fs_submit_bio(sbi, NODE, true);
 	f2fs_submit_bio(sbi, META, true);
@@ -738,6 +743,8 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 
 	unblock_operations(sbi);
 	mutex_unlock(&sbi->cp_mutex);
+
+	trace_f2fs_write_checkpoint(sbi->sb, is_umount, "finish checkpoint");
 }
 
 void init_orphan_info(struct f2fs_sb_info *sbi)

commit 399368372ed9f3c396eadb5c2bbc98be8c774a39
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Nov 22 16:21:29 2012 +0900

    f2fs: introduce a new global lock scheme
    
    In the previous version, f2fs uses global locks according to the usage types,
    such as directory operations, block allocation, block write, and so on.
    
    Reference the following lock types in f2fs.h.
    enum lock_type {
            RENAME,         /* for renaming operations */
            DENTRY_OPS,     /* for directory operations */
            DATA_WRITE,     /* for data write */
            DATA_NEW,       /* for data allocation */
            DATA_TRUNC,     /* for data truncate */
            NODE_NEW,       /* for node allocation */
            NODE_TRUNC,     /* for node truncate */
            NODE_WRITE,     /* for node write */
            NR_LOCK_TYPE,
    };
    
    In that case, we lose the performance under the multi-threading environment,
    since every types of operations must be conducted one at a time.
    
    In order to address the problem, let's share the locks globally with a mutex
    array regardless of any types.
    So, let users grab a mutex and perform their jobs in parallel as much as
    possbile.
    
    For this, I propose a new global lock scheme as follows.
    
    0. Data structure
     - f2fs_sb_info -> mutex_lock[NR_GLOBAL_LOCKS]
     - f2fs_sb_info -> node_write
    
    1. mutex_lock_op(sbi)
     - try to get an avaiable lock from the array.
     - returns the index of the gottern lock variable.
    
    2. mutex_unlock_op(sbi, index of the lock)
     - unlock the given index of the lock.
    
    3. mutex_lock_all(sbi)
     - grab all the locks in the array before the checkpoint.
    
    4. mutex_unlock_all(sbi)
     - release all the locks in the array after checkpoint.
    
    5. block_operations()
     - call mutex_lock_all()
     - sync_dirty_dir_inodes()
     - grab node_write
     - sync_node_pages()
    
    Note that,
     the pairs of mutex_lock_op()/mutex_unlock_op() and
     mutex_lock_all()/mutex_unlock_all() should be used together.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 93fd57d491ac..be6aa2eef894 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -543,54 +543,39 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
  */
 static void block_operations(struct f2fs_sb_info *sbi)
 {
-	int t;
 	struct writeback_control wbc = {
 		.sync_mode = WB_SYNC_ALL,
 		.nr_to_write = LONG_MAX,
 		.for_reclaim = 0,
 	};
+retry_flush_dents:
+	mutex_lock_all(sbi);
 
-	/* Stop renaming operation */
-	mutex_lock_op(sbi, RENAME);
-	mutex_lock_op(sbi, DENTRY_OPS);
-
-retry_dents:
 	/* write all the dirty dentry pages */
-	sync_dirty_dir_inodes(sbi);
-
-	mutex_lock_op(sbi, DATA_WRITE);
 	if (get_pages(sbi, F2FS_DIRTY_DENTS)) {
-		mutex_unlock_op(sbi, DATA_WRITE);
-		goto retry_dents;
+		mutex_unlock_all(sbi);
+		sync_dirty_dir_inodes(sbi);
+		goto retry_flush_dents;
 	}
 
-	/* block all the operations */
-	for (t = DATA_NEW; t <= NODE_TRUNC; t++)
-		mutex_lock_op(sbi, t);
-
-	mutex_lock(&sbi->write_inode);
-
 	/*
 	 * POR: we should ensure that there is no dirty node pages
 	 * until finishing nat/sit flush.
 	 */
-retry:
-	sync_node_pages(sbi, 0, &wbc);
-
-	mutex_lock_op(sbi, NODE_WRITE);
+retry_flush_nodes:
+	mutex_lock(&sbi->node_write);
 
 	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
-		mutex_unlock_op(sbi, NODE_WRITE);
-		goto retry;
+		mutex_unlock(&sbi->node_write);
+		sync_node_pages(sbi, 0, &wbc);
+		goto retry_flush_nodes;
 	}
-	mutex_unlock(&sbi->write_inode);
 }
 
 static void unblock_operations(struct f2fs_sb_info *sbi)
 {
-	int t;
-	for (t = NODE_WRITE; t >= RENAME; t--)
-		mutex_unlock_op(sbi, t);
+	mutex_unlock(&sbi->node_write);
+	mutex_unlock_all(sbi);
 }
 
 static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)

commit 5ec4e49f9bd753e2a6857a96e01f8ae5ff00b459
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Sun Mar 31 13:26:03 2013 +0900

    f2fs: change GC bitmaps to apply the section granularity
    
    This patch removes a bitmap for victim segments selected by foreground GC, and
    modifies the other bitmap for victim segments selected by background GC.
    
    1) foreground GC bitmap
     : We don't need to manage this, since we just only one previous victim section
       number instead of the whole victim history.
       The f2fs uses the victim section number in order not to allocate currently
       GC'ed section to current active logs.
    
    2) background GC bitmap
     : This bitmap is used to avoid selecting victims repeatedly by background GCs.
       In addition, the victims are able to be selected by foreground GCs, since
       there is no need to read victim blocks during foreground GCs.
    
       By the fact that the foreground GC reclaims segments in a section unit, it'd
       be better to manage this bitmap based on the section granularity.
    
    Reviewed-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d947e66ee8a8..93fd57d491ac 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -748,8 +748,6 @@ void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	flush_nat_entries(sbi);
 	flush_sit_entries(sbi);
 
-	reset_victim_segmap(sbi);
-
 	/* unlock all the fs_lock[] in do_checkpoint() */
 	do_checkpoint(sbi, is_umount);
 

commit 393ff91f57c87d48ffed30878be6e3e486d3a00a
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Mar 8 21:29:23 2013 +0900

    f2fs: reduce unncessary locking pages during read
    
    This patch reduces redundant locking and unlocking pages during read operations.
    In f2fs_readpage, let's use wait_on_page_locked() instead of lock_page.
    And then, when we need to modify any data finally, let's lock the page so that
    we can avoid lock contention.
    
    [readpage rule]
    - The f2fs_readpage returns unlocked page, or released page too in error cases.
    - Its caller should handle read error, -EIO, after locking the page, which
      indicates read completion.
    - Its caller should check PageUptodate after grab_cache_page.
    
    Signed-off-by: Changman Lee <cm224.lee@samsung.com>
    Reviewed-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2b6fc131e2ce..d947e66ee8a8 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -57,13 +57,15 @@ struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 		cond_resched();
 		goto repeat;
 	}
-	if (f2fs_readpage(sbi, page, index, READ_SYNC)) {
-		f2fs_put_page(page, 1);
+	if (PageUptodate(page))
+		goto out;
+
+	if (f2fs_readpage(sbi, page, index, READ_SYNC))
 		goto repeat;
-	}
-	mark_page_accessed(page);
 
-	/* We do not allow returning an errorneous page */
+	lock_page(page);
+out:
+	mark_page_accessed(page);
 	return page;
 }
 

commit 437275272f9e635673f065300e5d95226a25cb06
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Mon Feb 4 15:11:17 2013 +0900

    f2fs: clarify and enhance the f2fs_gc flow
    
    This patch makes clearer the ambiguous f2fs_gc flow as follows.
    
    1. Remove intermediate checkpoint condition during f2fs_gc
     (i.e., should_do_checkpoint() and GC_BLOCKED)
    
    2. Remove unnecessary return values of f2fs_gc because of #1.
     (i.e., GC_NODE, GC_OK, etc)
    
    3. Simplify write_checkpoint() because of #2.
    
    4. Clarify the main f2fs_gc flow.
     o monitor how many freed sections during one iteration of do_garbage_collect().
     o do GC more without checkpoints if we can't get enough free sections.
     o do checkpoint once we've got enough free sections through forground GCs.
    
    5. Adopt thread-logging (Slack-Space-Recycle) scheme more aggressively on data
      log types. See. get_ssr_segement()
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 2887c196b0a2..2b6fc131e2ce 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -539,7 +539,7 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 /*
  * Freeze all the FS-operations for checkpoint.
  */
-void block_operations(struct f2fs_sb_info *sbi)
+static void block_operations(struct f2fs_sb_info *sbi)
 {
 	int t;
 	struct writeback_control wbc = {
@@ -722,15 +722,13 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 /*
  * We guarantee that this checkpoint procedure should not fail.
  */
-void write_checkpoint(struct f2fs_sb_info *sbi, bool blocked, bool is_umount)
+void write_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 {
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
 	unsigned long long ckpt_ver;
 
-	if (!blocked) {
-		mutex_lock(&sbi->cp_mutex);
-		block_operations(sbi);
-	}
+	mutex_lock(&sbi->cp_mutex);
+	block_operations(sbi);
 
 	f2fs_submit_bio(sbi, DATA, true);
 	f2fs_submit_bio(sbi, NODE, true);

commit 94787d91cba7ba168b028703b50a0224702ace9c
Author: Changman Lee <cm224.lee@samsung.com>
Date:   Fri Feb 1 18:05:09 2013 +0900

    f2fs: remove repeated F2FS_SET_SB_DIRT call
    
    F2FS_SET_SB_DIRT is called in inc_page_count and
    it is directly called one more time in the next line.
    
    Signed-off-by: Changman Lee <cm224.lee@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d3b34d05211f..2887c196b0a2 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -164,7 +164,6 @@ static int f2fs_set_meta_page_dirty(struct page *page)
 	if (!PageDirty(page)) {
 		__set_page_dirty_nobuffers(page);
 		inc_page_count(sbi, F2FS_DIRTY_META);
-		F2FS_SET_SB_DIRT(sbi);
 		return 1;
 	}
 	return 0;

commit a2617dc6863b21a8109c199ab533b3dbfe178f27
Author: majianpeng <majianpeng@gmail.com>
Date:   Tue Jan 29 16:19:02 2013 +0800

    f2fs: clean up the add_orphan_inode func
    
    For the code
    > prev = list_entry(orphan->list.prev, typeof(*prev), list);
    if orphan->list.prev == head, it can't get the right prev.
    And we can use the parameter 'this' to add.
    
    Signed-off-by: Jianpeng Ma <majianpeng@gmail.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 9c1627165039..d3b34d05211f 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -219,19 +219,11 @@ void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 	new->ino = ino;
 
 	/* add new_oentry into list which is sorted by inode number */
-	if (orphan) {
-		struct orphan_inode_entry *prev;
-
-		/* get previous entry */
-		prev = list_entry(orphan->list.prev, typeof(*prev), list);
-		if (&prev->list != head)
-			/* insert new orphan inode entry */
-			list_add(&new->list, &prev->list);
-		else
-			list_add(&new->list, head);
-	} else {
+	if (orphan)
+		list_add(&new->list, this->prev);
+	else
 		list_add_tail(&new->list, head);
-	}
+
 	sbi->n_orphans++;
 out:
 	mutex_unlock(&sbi->orphan_inode_mutex);

commit 577e349514452fa3fcd99fd06e587b02d3d1cf28
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Jan 24 19:56:11 2013 +0900

    f2fs: prevent checkpoint once any IO failure is detected
    
    This patch enhances the checkpoint routine to cope with IO errors.
    
    Basically f2fs detects IO errors from end_io_write, and the errors are able to
    be occurred during one of data, node, and meta page writes.
    
    In the previous code, when an IO error is occurred during writes, f2fs sets a
    flag, CP_ERROR_FLAG, in the raw ckeckpoint buffer which will be written to disk.
    Afterwards, write_checkpoint() will check the flag and remount f2fs as a
    read-only (ro) mode.
    
    However, even once f2fs is remounted as a ro mode, dirty checkpoint pages are
    freely able to be written to disk by flusher or kswapd in background.
    In such a case, after cold reboot, f2fs would restore the checkpoint data having
    CP_ERROR_FLAG, resulting in disabling write_checkpoint and remounting f2fs as
    a ro mode again.
    
    Therefore, let's prevent any checkpoint page (meta) writes once an IO error is
    occurred, and remount f2fs as a ro mode right away at that moment.
    
    Reported-by: Oliver Winker <oliver@oli1170.net>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>
    Reviewed-by: Namjae Jeon <namjae.jeon@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ff3c8439af87..9c1627165039 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -72,22 +72,22 @@ static int f2fs_write_meta_page(struct page *page,
 {
 	struct inode *inode = page->mapping->host;
 	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
-	int err;
 
-	wait_on_page_writeback(page);
-
-	err = write_meta_page(sbi, page, wbc);
-	if (err) {
+	/* Should not write any meta pages, if any IO error was occurred */
+	if (wbc->for_reclaim ||
+			is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ERROR_FLAG)) {
+		dec_page_count(sbi, F2FS_DIRTY_META);
 		wbc->pages_skipped++;
 		set_page_dirty(page);
+		return AOP_WRITEPAGE_ACTIVATE;
 	}
 
-	dec_page_count(sbi, F2FS_DIRTY_META);
+	wait_on_page_writeback(page);
 
-	/* In this case, we should not unlock this page */
-	if (err != AOP_WRITEPAGE_ACTIVATE)
-		unlock_page(page);
-	return err;
+	write_meta_page(sbi, page);
+	dec_page_count(sbi, F2FS_DIRTY_META);
+	unlock_page(page);
+	return 0;
 }
 
 static int f2fs_write_meta_pages(struct address_space *mapping,
@@ -138,7 +138,10 @@ long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
 			BUG_ON(page->mapping != mapping);
 			BUG_ON(!PageDirty(page));
 			clear_page_dirty_for_io(page);
-			f2fs_write_meta_page(page, &wbc);
+			if (f2fs_write_meta_page(page, &wbc)) {
+				unlock_page(page);
+				break;
+			}
 			if (nwritten++ >= nr_to_write)
 				break;
 		}
@@ -717,13 +720,12 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	sbi->alloc_valid_block_count = 0;
 
 	/* Here, we only have one bio having CP pack */
-	if (is_set_ckpt_flags(ckpt, CP_ERROR_FLAG))
-		sbi->sb->s_flags |= MS_RDONLY;
-	else
-		sync_meta_pages(sbi, META_FLUSH, LONG_MAX);
+	sync_meta_pages(sbi, META_FLUSH, LONG_MAX);
 
-	clear_prefree_segments(sbi);
-	F2FS_RESET_SB_DIRT(sbi);
+	if (!is_set_ckpt_flags(ckpt, CP_ERROR_FLAG)) {
+		clear_prefree_segments(sbi);
+		F2FS_RESET_SB_DIRT(sbi);
+	}
 }
 
 /*

commit 6e6093a8f144414d904575da5fdea40cf14fb63e
Author: Namjae Jeon <namjae.jeon@samsung.com>
Date:   Thu Jan 17 00:08:30 2013 +0900

    f2fs: add __init to functions in init_f2fs_fs
    
    Add __init to functions in init_f2fs_fs for code consistency.
    
    Signed-off-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Amit Sahrawat <a.sahrawat@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index d75c86a17893..ff3c8439af87 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -771,7 +771,7 @@ void init_orphan_info(struct f2fs_sb_info *sbi)
 	sbi->n_orphans = 0;
 }
 
-int create_checkpoint_caches(void)
+int __init create_checkpoint_caches(void)
 {
 	orphan_entry_slab = f2fs_kmem_cache_create("f2fs_orphan_entry",
 			sizeof(struct orphan_inode_entry), NULL);

commit 24c366a9ea256b86426b42e75f764495a2558861
Author: Namjae Jeon <namjae.jeon@samsung.com>
Date:   Sun Dec 30 14:53:08 2012 +0900

    f2fs: remove unneeded INIT_LIST_HEAD at few places
    
    While creating a new entry for addition to the list(orphan inode list
    and fsync inode entry list), there is no need to call HEAD initialization
    for these entries. So, remove that init part.
    
    Signed-off-by: Namjae Jeon <namjae.jeon@samsung.com>
    Signed-off-by: Amit Sahrawat <a.sahrawat@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 6ef36c37e2be..d75c86a17893 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -214,7 +214,6 @@ void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
 		goto retry;
 	}
 	new->ino = ino;
-	INIT_LIST_HEAD(&new->list);
 
 	/* add new_oentry into list which is sorted by inode number */
 	if (orphan) {

commit 0a8165d7c2cf1395059db20ab07665baf3758fcd
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Thu Nov 29 13:28:09 2012 +0900

    f2fs: adjust kernel coding style
    
    As pointed out by Randy Dunlap, this patch removes all usage of "/**" for comment
    blocks. Instead, just use "/*".
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index 7c18f8efaadc..6ef36c37e2be 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -1,4 +1,4 @@
-/**
+/*
  * fs/f2fs/checkpoint.c
  *
  * Copyright (c) 2012 Samsung Electronics Co., Ltd.
@@ -24,7 +24,7 @@
 static struct kmem_cache *orphan_entry_slab;
 static struct kmem_cache *inode_entry_slab;
 
-/**
+/*
  * We guarantee no failure on the returned page.
  */
 struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
@@ -44,7 +44,7 @@ struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
 	return page;
 }
 
-/**
+/*
  * We guarantee no failure on the returned page.
  */
 struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
@@ -543,7 +543,7 @@ void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
 	goto retry;
 }
 
-/**
+/*
  * Freeze all the FS-operations for checkpoint.
  */
 void block_operations(struct f2fs_sb_info *sbi)
@@ -727,7 +727,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	F2FS_RESET_SB_DIRT(sbi);
 }
 
-/**
+/*
  * We guarantee that this checkpoint procedure should not fail.
  */
 void write_checkpoint(struct f2fs_sb_info *sbi, bool blocked, bool is_umount)

commit 25ca923b2a766b9c93b63777ead351137533a623
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Wed Nov 28 16:12:41 2012 +0900

    f2fs: fix endian conversion bugs reported by sparse
    
    This patch should resolve the bugs reported by the sparse tool.
    Initial reports were written by "kbuild test robot" managed by fengguang.wu.
    
    In my local machines, I've tested also by running:
    > make C=2 CF="-D__CHECK_ENDIAN__"
    
    Accordingly, I've found lots of warnings and bugs related to the endian
    conversion. And I've fixed all at this moment.
    
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
index ab743f92ee06..7c18f8efaadc 100644
--- a/fs/f2fs/checkpoint.c
+++ b/fs/f2fs/checkpoint.c
@@ -268,7 +268,7 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 {
 	block_t start_blk, orphan_blkaddr, i, j;
 
-	if (!(F2FS_CKPT(sbi)->ckpt_flags & CP_ORPHAN_PRESENT_FLAG))
+	if (!is_set_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG))
 		return 0;
 
 	sbi->por_doing = 1;
@@ -287,7 +287,7 @@ int recover_orphan_inodes(struct f2fs_sb_info *sbi)
 		f2fs_put_page(page, 1);
 	}
 	/* clear Orphan Flag */
-	F2FS_CKPT(sbi)->ckpt_flags &= (~CP_ORPHAN_PRESENT_FLAG);
+	clear_ckpt_flags(F2FS_CKPT(sbi), CP_ORPHAN_PRESENT_FLAG);
 	sbi->por_doing = 0;
 	return 0;
 }
@@ -376,7 +376,7 @@ static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
 	pre_version = le64_to_cpu(cp_block->checkpoint_ver);
 
 	/* Read the 2nd cp block in this CP pack */
-	cp_addr += le64_to_cpu(cp_block->cp_pack_total_block_count) - 1;
+	cp_addr += le32_to_cpu(cp_block->cp_pack_total_block_count) - 1;
 	cp_page_2 = get_meta_page(sbi, cp_addr);
 
 	cp_block = (struct f2fs_checkpoint *)page_address(cp_page_2);
@@ -605,8 +605,8 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	block_t start_blk;
 	struct page *cp_page;
 	unsigned int data_sum_blocks, orphan_blocks;
+	unsigned int crc32 = 0;
 	void *kaddr;
-	__u32 crc32 = 0;
 	int i;
 
 	/* Flush all the NAT/SIT pages */
@@ -646,33 +646,35 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	/* 2 cp  + n data seg summary + orphan inode blocks */
 	data_sum_blocks = npages_for_summary_flush(sbi);
 	if (data_sum_blocks < 3)
-		ckpt->ckpt_flags |= CP_COMPACT_SUM_FLAG;
+		set_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
 	else
-		ckpt->ckpt_flags &= (~CP_COMPACT_SUM_FLAG);
+		clear_ckpt_flags(ckpt, CP_COMPACT_SUM_FLAG);
 
 	orphan_blocks = (sbi->n_orphans + F2FS_ORPHANS_PER_BLOCK - 1)
 					/ F2FS_ORPHANS_PER_BLOCK;
-	ckpt->cp_pack_start_sum = 1 + orphan_blocks;
-	ckpt->cp_pack_total_block_count = 2 + data_sum_blocks + orphan_blocks;
+	ckpt->cp_pack_start_sum = cpu_to_le32(1 + orphan_blocks);
 
 	if (is_umount) {
-		ckpt->ckpt_flags |= CP_UMOUNT_FLAG;
-		ckpt->cp_pack_total_block_count += NR_CURSEG_NODE_TYPE;
+		set_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+		ckpt->cp_pack_total_block_count = cpu_to_le32(2 +
+			data_sum_blocks + orphan_blocks + NR_CURSEG_NODE_TYPE);
 	} else {
-		ckpt->ckpt_flags &= (~CP_UMOUNT_FLAG);
+		clear_ckpt_flags(ckpt, CP_UMOUNT_FLAG);
+		ckpt->cp_pack_total_block_count = cpu_to_le32(2 +
+			data_sum_blocks + orphan_blocks);
 	}
 
 	if (sbi->n_orphans)
-		ckpt->ckpt_flags |= CP_ORPHAN_PRESENT_FLAG;
+		set_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 	else
-		ckpt->ckpt_flags &= (~CP_ORPHAN_PRESENT_FLAG);
+		clear_ckpt_flags(ckpt, CP_ORPHAN_PRESENT_FLAG);
 
 	/* update SIT/NAT bitmap */
 	get_sit_bitmap(sbi, __bitmap_ptr(sbi, SIT_BITMAP));
 	get_nat_bitmap(sbi, __bitmap_ptr(sbi, NAT_BITMAP));
 
 	crc32 = f2fs_crc32(ckpt, le32_to_cpu(ckpt->checksum_offset));
-	*(__u32 *)((unsigned char *)ckpt +
+	*(__le32 *)((unsigned char *)ckpt +
 				le32_to_cpu(ckpt->checksum_offset))
 				= cpu_to_le32(crc32);
 
@@ -716,7 +718,7 @@ static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
 	sbi->alloc_valid_block_count = 0;
 
 	/* Here, we only have one bio having CP pack */
-	if (sbi->ckpt->ckpt_flags & CP_ERROR_FLAG)
+	if (is_set_ckpt_flags(ckpt, CP_ERROR_FLAG))
 		sbi->sb->s_flags |= MS_RDONLY;
 	else
 		sync_meta_pages(sbi, META_FLUSH, LONG_MAX);

commit 127e670abfa7fa150f6550d620ded930f5bdb4e7
Author: Jaegeuk Kim <jaegeuk.kim@samsung.com>
Date:   Fri Nov 2 17:08:18 2012 +0900

    f2fs: add checkpoint operations
    
    This adds functions required by the checkpoint operations.
    
    Basically, f2fs adopts a roll-back model with checkpoint blocks written in the
    CP area. The checkpoint procedure includes as follows.
    
    - write_checkpoint()
    1. block_operations() freezes VFS calls.
    2. submit cached bios.
    3. flush_nat_entries() writes NAT pages updated by dirty NAT entries.
    4. flush_sit_entries() writes SIT pages updated by dirty SIT entries.
    5. do_checkpoint() writes,
      - checkpoint block (#0)
      - orphan inode blocks
      - summary blocks made by active logs
      - checkpoint block (copy of #0)
    6. unblock_opeations()
    
    In order to provide an address space for meta pages, f2fs_sb_info has a special
    inode, namely meta_inode. This patch also adds the address space operations for
    meta_inode.
    
    Signed-off-by: Chul Lee <chur.lee@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk.kim@samsung.com>

diff --git a/fs/f2fs/checkpoint.c b/fs/f2fs/checkpoint.c
new file mode 100644
index 000000000000..ab743f92ee06
--- /dev/null
+++ b/fs/f2fs/checkpoint.c
@@ -0,0 +1,792 @@
+/**
+ * fs/f2fs/checkpoint.c
+ *
+ * Copyright (c) 2012 Samsung Electronics Co., Ltd.
+ *             http://www.samsung.com/
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/fs.h>
+#include <linux/bio.h>
+#include <linux/mpage.h>
+#include <linux/writeback.h>
+#include <linux/blkdev.h>
+#include <linux/f2fs_fs.h>
+#include <linux/pagevec.h>
+#include <linux/swap.h>
+
+#include "f2fs.h"
+#include "node.h"
+#include "segment.h"
+
+static struct kmem_cache *orphan_entry_slab;
+static struct kmem_cache *inode_entry_slab;
+
+/**
+ * We guarantee no failure on the returned page.
+ */
+struct page *grab_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
+{
+	struct address_space *mapping = sbi->meta_inode->i_mapping;
+	struct page *page = NULL;
+repeat:
+	page = grab_cache_page(mapping, index);
+	if (!page) {
+		cond_resched();
+		goto repeat;
+	}
+
+	/* We wait writeback only inside grab_meta_page() */
+	wait_on_page_writeback(page);
+	SetPageUptodate(page);
+	return page;
+}
+
+/**
+ * We guarantee no failure on the returned page.
+ */
+struct page *get_meta_page(struct f2fs_sb_info *sbi, pgoff_t index)
+{
+	struct address_space *mapping = sbi->meta_inode->i_mapping;
+	struct page *page;
+repeat:
+	page = grab_cache_page(mapping, index);
+	if (!page) {
+		cond_resched();
+		goto repeat;
+	}
+	if (f2fs_readpage(sbi, page, index, READ_SYNC)) {
+		f2fs_put_page(page, 1);
+		goto repeat;
+	}
+	mark_page_accessed(page);
+
+	/* We do not allow returning an errorneous page */
+	return page;
+}
+
+static int f2fs_write_meta_page(struct page *page,
+				struct writeback_control *wbc)
+{
+	struct inode *inode = page->mapping->host;
+	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	int err;
+
+	wait_on_page_writeback(page);
+
+	err = write_meta_page(sbi, page, wbc);
+	if (err) {
+		wbc->pages_skipped++;
+		set_page_dirty(page);
+	}
+
+	dec_page_count(sbi, F2FS_DIRTY_META);
+
+	/* In this case, we should not unlock this page */
+	if (err != AOP_WRITEPAGE_ACTIVATE)
+		unlock_page(page);
+	return err;
+}
+
+static int f2fs_write_meta_pages(struct address_space *mapping,
+				struct writeback_control *wbc)
+{
+	struct f2fs_sb_info *sbi = F2FS_SB(mapping->host->i_sb);
+	struct block_device *bdev = sbi->sb->s_bdev;
+	long written;
+
+	if (wbc->for_kupdate)
+		return 0;
+
+	if (get_pages(sbi, F2FS_DIRTY_META) == 0)
+		return 0;
+
+	/* if mounting is failed, skip writing node pages */
+	mutex_lock(&sbi->cp_mutex);
+	written = sync_meta_pages(sbi, META, bio_get_nr_vecs(bdev));
+	mutex_unlock(&sbi->cp_mutex);
+	wbc->nr_to_write -= written;
+	return 0;
+}
+
+long sync_meta_pages(struct f2fs_sb_info *sbi, enum page_type type,
+						long nr_to_write)
+{
+	struct address_space *mapping = sbi->meta_inode->i_mapping;
+	pgoff_t index = 0, end = LONG_MAX;
+	struct pagevec pvec;
+	long nwritten = 0;
+	struct writeback_control wbc = {
+		.for_reclaim = 0,
+	};
+
+	pagevec_init(&pvec, 0);
+
+	while (index <= end) {
+		int i, nr_pages;
+		nr_pages = pagevec_lookup_tag(&pvec, mapping, &index,
+				PAGECACHE_TAG_DIRTY,
+				min(end - index, (pgoff_t)PAGEVEC_SIZE-1) + 1);
+		if (nr_pages == 0)
+			break;
+
+		for (i = 0; i < nr_pages; i++) {
+			struct page *page = pvec.pages[i];
+			lock_page(page);
+			BUG_ON(page->mapping != mapping);
+			BUG_ON(!PageDirty(page));
+			clear_page_dirty_for_io(page);
+			f2fs_write_meta_page(page, &wbc);
+			if (nwritten++ >= nr_to_write)
+				break;
+		}
+		pagevec_release(&pvec);
+		cond_resched();
+	}
+
+	if (nwritten)
+		f2fs_submit_bio(sbi, type, nr_to_write == LONG_MAX);
+
+	return nwritten;
+}
+
+static int f2fs_set_meta_page_dirty(struct page *page)
+{
+	struct address_space *mapping = page->mapping;
+	struct f2fs_sb_info *sbi = F2FS_SB(mapping->host->i_sb);
+
+	SetPageUptodate(page);
+	if (!PageDirty(page)) {
+		__set_page_dirty_nobuffers(page);
+		inc_page_count(sbi, F2FS_DIRTY_META);
+		F2FS_SET_SB_DIRT(sbi);
+		return 1;
+	}
+	return 0;
+}
+
+const struct address_space_operations f2fs_meta_aops = {
+	.writepage	= f2fs_write_meta_page,
+	.writepages	= f2fs_write_meta_pages,
+	.set_page_dirty	= f2fs_set_meta_page_dirty,
+};
+
+int check_orphan_space(struct f2fs_sb_info *sbi)
+{
+	unsigned int max_orphans;
+	int err = 0;
+
+	/*
+	 * considering 512 blocks in a segment 5 blocks are needed for cp
+	 * and log segment summaries. Remaining blocks are used to keep
+	 * orphan entries with the limitation one reserved segment
+	 * for cp pack we can have max 1020*507 orphan entries
+	 */
+	max_orphans = (sbi->blocks_per_seg - 5) * F2FS_ORPHANS_PER_BLOCK;
+	mutex_lock(&sbi->orphan_inode_mutex);
+	if (sbi->n_orphans >= max_orphans)
+		err = -ENOSPC;
+	mutex_unlock(&sbi->orphan_inode_mutex);
+	return err;
+}
+
+void add_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
+{
+	struct list_head *head, *this;
+	struct orphan_inode_entry *new = NULL, *orphan = NULL;
+
+	mutex_lock(&sbi->orphan_inode_mutex);
+	head = &sbi->orphan_inode_list;
+	list_for_each(this, head) {
+		orphan = list_entry(this, struct orphan_inode_entry, list);
+		if (orphan->ino == ino)
+			goto out;
+		if (orphan->ino > ino)
+			break;
+		orphan = NULL;
+	}
+retry:
+	new = kmem_cache_alloc(orphan_entry_slab, GFP_ATOMIC);
+	if (!new) {
+		cond_resched();
+		goto retry;
+	}
+	new->ino = ino;
+	INIT_LIST_HEAD(&new->list);
+
+	/* add new_oentry into list which is sorted by inode number */
+	if (orphan) {
+		struct orphan_inode_entry *prev;
+
+		/* get previous entry */
+		prev = list_entry(orphan->list.prev, typeof(*prev), list);
+		if (&prev->list != head)
+			/* insert new orphan inode entry */
+			list_add(&new->list, &prev->list);
+		else
+			list_add(&new->list, head);
+	} else {
+		list_add_tail(&new->list, head);
+	}
+	sbi->n_orphans++;
+out:
+	mutex_unlock(&sbi->orphan_inode_mutex);
+}
+
+void remove_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
+{
+	struct list_head *this, *next, *head;
+	struct orphan_inode_entry *orphan;
+
+	mutex_lock(&sbi->orphan_inode_mutex);
+	head = &sbi->orphan_inode_list;
+	list_for_each_safe(this, next, head) {
+		orphan = list_entry(this, struct orphan_inode_entry, list);
+		if (orphan->ino == ino) {
+			list_del(&orphan->list);
+			kmem_cache_free(orphan_entry_slab, orphan);
+			sbi->n_orphans--;
+			break;
+		}
+	}
+	mutex_unlock(&sbi->orphan_inode_mutex);
+}
+
+static void recover_orphan_inode(struct f2fs_sb_info *sbi, nid_t ino)
+{
+	struct inode *inode = f2fs_iget(sbi->sb, ino);
+	BUG_ON(IS_ERR(inode));
+	clear_nlink(inode);
+
+	/* truncate all the data during iput */
+	iput(inode);
+}
+
+int recover_orphan_inodes(struct f2fs_sb_info *sbi)
+{
+	block_t start_blk, orphan_blkaddr, i, j;
+
+	if (!(F2FS_CKPT(sbi)->ckpt_flags & CP_ORPHAN_PRESENT_FLAG))
+		return 0;
+
+	sbi->por_doing = 1;
+	start_blk = __start_cp_addr(sbi) + 1;
+	orphan_blkaddr = __start_sum_addr(sbi) - 1;
+
+	for (i = 0; i < orphan_blkaddr; i++) {
+		struct page *page = get_meta_page(sbi, start_blk + i);
+		struct f2fs_orphan_block *orphan_blk;
+
+		orphan_blk = (struct f2fs_orphan_block *)page_address(page);
+		for (j = 0; j < le32_to_cpu(orphan_blk->entry_count); j++) {
+			nid_t ino = le32_to_cpu(orphan_blk->ino[j]);
+			recover_orphan_inode(sbi, ino);
+		}
+		f2fs_put_page(page, 1);
+	}
+	/* clear Orphan Flag */
+	F2FS_CKPT(sbi)->ckpt_flags &= (~CP_ORPHAN_PRESENT_FLAG);
+	sbi->por_doing = 0;
+	return 0;
+}
+
+static void write_orphan_inodes(struct f2fs_sb_info *sbi, block_t start_blk)
+{
+	struct list_head *head, *this, *next;
+	struct f2fs_orphan_block *orphan_blk = NULL;
+	struct page *page = NULL;
+	unsigned int nentries = 0;
+	unsigned short index = 1;
+	unsigned short orphan_blocks;
+
+	orphan_blocks = (unsigned short)((sbi->n_orphans +
+		(F2FS_ORPHANS_PER_BLOCK - 1)) / F2FS_ORPHANS_PER_BLOCK);
+
+	mutex_lock(&sbi->orphan_inode_mutex);
+	head = &sbi->orphan_inode_list;
+
+	/* loop for each orphan inode entry and write them in Jornal block */
+	list_for_each_safe(this, next, head) {
+		struct orphan_inode_entry *orphan;
+
+		orphan = list_entry(this, struct orphan_inode_entry, list);
+
+		if (nentries == F2FS_ORPHANS_PER_BLOCK) {
+			/*
+			 * an orphan block is full of 1020 entries,
+			 * then we need to flush current orphan blocks
+			 * and bring another one in memory
+			 */
+			orphan_blk->blk_addr = cpu_to_le16(index);
+			orphan_blk->blk_count = cpu_to_le16(orphan_blocks);
+			orphan_blk->entry_count = cpu_to_le32(nentries);
+			set_page_dirty(page);
+			f2fs_put_page(page, 1);
+			index++;
+			start_blk++;
+			nentries = 0;
+			page = NULL;
+		}
+		if (page)
+			goto page_exist;
+
+		page = grab_meta_page(sbi, start_blk);
+		orphan_blk = (struct f2fs_orphan_block *)page_address(page);
+		memset(orphan_blk, 0, sizeof(*orphan_blk));
+page_exist:
+		orphan_blk->ino[nentries++] = cpu_to_le32(orphan->ino);
+	}
+	if (!page)
+		goto end;
+
+	orphan_blk->blk_addr = cpu_to_le16(index);
+	orphan_blk->blk_count = cpu_to_le16(orphan_blocks);
+	orphan_blk->entry_count = cpu_to_le32(nentries);
+	set_page_dirty(page);
+	f2fs_put_page(page, 1);
+end:
+	mutex_unlock(&sbi->orphan_inode_mutex);
+}
+
+static struct page *validate_checkpoint(struct f2fs_sb_info *sbi,
+				block_t cp_addr, unsigned long long *version)
+{
+	struct page *cp_page_1, *cp_page_2 = NULL;
+	unsigned long blk_size = sbi->blocksize;
+	struct f2fs_checkpoint *cp_block;
+	unsigned long long cur_version = 0, pre_version = 0;
+	unsigned int crc = 0;
+	size_t crc_offset;
+
+	/* Read the 1st cp block in this CP pack */
+	cp_page_1 = get_meta_page(sbi, cp_addr);
+
+	/* get the version number */
+	cp_block = (struct f2fs_checkpoint *)page_address(cp_page_1);
+	crc_offset = le32_to_cpu(cp_block->checksum_offset);
+	if (crc_offset >= blk_size)
+		goto invalid_cp1;
+
+	crc = *(unsigned int *)((unsigned char *)cp_block + crc_offset);
+	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
+		goto invalid_cp1;
+
+	pre_version = le64_to_cpu(cp_block->checkpoint_ver);
+
+	/* Read the 2nd cp block in this CP pack */
+	cp_addr += le64_to_cpu(cp_block->cp_pack_total_block_count) - 1;
+	cp_page_2 = get_meta_page(sbi, cp_addr);
+
+	cp_block = (struct f2fs_checkpoint *)page_address(cp_page_2);
+	crc_offset = le32_to_cpu(cp_block->checksum_offset);
+	if (crc_offset >= blk_size)
+		goto invalid_cp2;
+
+	crc = *(unsigned int *)((unsigned char *)cp_block + crc_offset);
+	if (!f2fs_crc_valid(crc, cp_block, crc_offset))
+		goto invalid_cp2;
+
+	cur_version = le64_to_cpu(cp_block->checkpoint_ver);
+
+	if (cur_version == pre_version) {
+		*version = cur_version;
+		f2fs_put_page(cp_page_2, 1);
+		return cp_page_1;
+	}
+invalid_cp2:
+	f2fs_put_page(cp_page_2, 1);
+invalid_cp1:
+	f2fs_put_page(cp_page_1, 1);
+	return NULL;
+}
+
+int get_valid_checkpoint(struct f2fs_sb_info *sbi)
+{
+	struct f2fs_checkpoint *cp_block;
+	struct f2fs_super_block *fsb = sbi->raw_super;
+	struct page *cp1, *cp2, *cur_page;
+	unsigned long blk_size = sbi->blocksize;
+	unsigned long long cp1_version = 0, cp2_version = 0;
+	unsigned long long cp_start_blk_no;
+
+	sbi->ckpt = kzalloc(blk_size, GFP_KERNEL);
+	if (!sbi->ckpt)
+		return -ENOMEM;
+	/*
+	 * Finding out valid cp block involves read both
+	 * sets( cp pack1 and cp pack 2)
+	 */
+	cp_start_blk_no = le32_to_cpu(fsb->cp_blkaddr);
+	cp1 = validate_checkpoint(sbi, cp_start_blk_no, &cp1_version);
+
+	/* The second checkpoint pack should start at the next segment */
+	cp_start_blk_no += 1 << le32_to_cpu(fsb->log_blocks_per_seg);
+	cp2 = validate_checkpoint(sbi, cp_start_blk_no, &cp2_version);
+
+	if (cp1 && cp2) {
+		if (ver_after(cp2_version, cp1_version))
+			cur_page = cp2;
+		else
+			cur_page = cp1;
+	} else if (cp1) {
+		cur_page = cp1;
+	} else if (cp2) {
+		cur_page = cp2;
+	} else {
+		goto fail_no_cp;
+	}
+
+	cp_block = (struct f2fs_checkpoint *)page_address(cur_page);
+	memcpy(sbi->ckpt, cp_block, blk_size);
+
+	f2fs_put_page(cp1, 1);
+	f2fs_put_page(cp2, 1);
+	return 0;
+
+fail_no_cp:
+	kfree(sbi->ckpt);
+	return -EINVAL;
+}
+
+void set_dirty_dir_page(struct inode *inode, struct page *page)
+{
+	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	struct list_head *head = &sbi->dir_inode_list;
+	struct dir_inode_entry *new;
+	struct list_head *this;
+
+	if (!S_ISDIR(inode->i_mode))
+		return;
+retry:
+	new = kmem_cache_alloc(inode_entry_slab, GFP_NOFS);
+	if (!new) {
+		cond_resched();
+		goto retry;
+	}
+	new->inode = inode;
+	INIT_LIST_HEAD(&new->list);
+
+	spin_lock(&sbi->dir_inode_lock);
+	list_for_each(this, head) {
+		struct dir_inode_entry *entry;
+		entry = list_entry(this, struct dir_inode_entry, list);
+		if (entry->inode == inode) {
+			kmem_cache_free(inode_entry_slab, new);
+			goto out;
+		}
+	}
+	list_add_tail(&new->list, head);
+	sbi->n_dirty_dirs++;
+
+	BUG_ON(!S_ISDIR(inode->i_mode));
+out:
+	inc_page_count(sbi, F2FS_DIRTY_DENTS);
+	inode_inc_dirty_dents(inode);
+	SetPagePrivate(page);
+
+	spin_unlock(&sbi->dir_inode_lock);
+}
+
+void remove_dirty_dir_inode(struct inode *inode)
+{
+	struct f2fs_sb_info *sbi = F2FS_SB(inode->i_sb);
+	struct list_head *head = &sbi->dir_inode_list;
+	struct list_head *this;
+
+	if (!S_ISDIR(inode->i_mode))
+		return;
+
+	spin_lock(&sbi->dir_inode_lock);
+	if (atomic_read(&F2FS_I(inode)->dirty_dents))
+		goto out;
+
+	list_for_each(this, head) {
+		struct dir_inode_entry *entry;
+		entry = list_entry(this, struct dir_inode_entry, list);
+		if (entry->inode == inode) {
+			list_del(&entry->list);
+			kmem_cache_free(inode_entry_slab, entry);
+			sbi->n_dirty_dirs--;
+			break;
+		}
+	}
+out:
+	spin_unlock(&sbi->dir_inode_lock);
+}
+
+void sync_dirty_dir_inodes(struct f2fs_sb_info *sbi)
+{
+	struct list_head *head = &sbi->dir_inode_list;
+	struct dir_inode_entry *entry;
+	struct inode *inode;
+retry:
+	spin_lock(&sbi->dir_inode_lock);
+	if (list_empty(head)) {
+		spin_unlock(&sbi->dir_inode_lock);
+		return;
+	}
+	entry = list_entry(head->next, struct dir_inode_entry, list);
+	inode = igrab(entry->inode);
+	spin_unlock(&sbi->dir_inode_lock);
+	if (inode) {
+		filemap_flush(inode->i_mapping);
+		iput(inode);
+	} else {
+		/*
+		 * We should submit bio, since it exists several
+		 * wribacking dentry pages in the freeing inode.
+		 */
+		f2fs_submit_bio(sbi, DATA, true);
+	}
+	goto retry;
+}
+
+/**
+ * Freeze all the FS-operations for checkpoint.
+ */
+void block_operations(struct f2fs_sb_info *sbi)
+{
+	int t;
+	struct writeback_control wbc = {
+		.sync_mode = WB_SYNC_ALL,
+		.nr_to_write = LONG_MAX,
+		.for_reclaim = 0,
+	};
+
+	/* Stop renaming operation */
+	mutex_lock_op(sbi, RENAME);
+	mutex_lock_op(sbi, DENTRY_OPS);
+
+retry_dents:
+	/* write all the dirty dentry pages */
+	sync_dirty_dir_inodes(sbi);
+
+	mutex_lock_op(sbi, DATA_WRITE);
+	if (get_pages(sbi, F2FS_DIRTY_DENTS)) {
+		mutex_unlock_op(sbi, DATA_WRITE);
+		goto retry_dents;
+	}
+
+	/* block all the operations */
+	for (t = DATA_NEW; t <= NODE_TRUNC; t++)
+		mutex_lock_op(sbi, t);
+
+	mutex_lock(&sbi->write_inode);
+
+	/*
+	 * POR: we should ensure that there is no dirty node pages
+	 * until finishing nat/sit flush.
+	 */
+retry:
+	sync_node_pages(sbi, 0, &wbc);
+
+	mutex_lock_op(sbi, NODE_WRITE);
+
+	if (get_pages(sbi, F2FS_DIRTY_NODES)) {
+		mutex_unlock_op(sbi, NODE_WRITE);
+		goto retry;
+	}
+	mutex_unlock(&sbi->write_inode);
+}
+
+static void unblock_operations(struct f2fs_sb_info *sbi)
+{
+	int t;
+	for (t = NODE_WRITE; t >= RENAME; t--)
+		mutex_unlock_op(sbi, t);
+}
+
+static void do_checkpoint(struct f2fs_sb_info *sbi, bool is_umount)
+{
+	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
+	nid_t last_nid = 0;
+	block_t start_blk;
+	struct page *cp_page;
+	unsigned int data_sum_blocks, orphan_blocks;
+	void *kaddr;
+	__u32 crc32 = 0;
+	int i;
+
+	/* Flush all the NAT/SIT pages */
+	while (get_pages(sbi, F2FS_DIRTY_META))
+		sync_meta_pages(sbi, META, LONG_MAX);
+
+	next_free_nid(sbi, &last_nid);
+
+	/*
+	 * modify checkpoint
+	 * version number is already updated
+	 */
+	ckpt->elapsed_time = cpu_to_le64(get_mtime(sbi));
+	ckpt->valid_block_count = cpu_to_le64(valid_user_blocks(sbi));
+	ckpt->free_segment_count = cpu_to_le32(free_segments(sbi));
+	for (i = 0; i < 3; i++) {
+		ckpt->cur_node_segno[i] =
+			cpu_to_le32(curseg_segno(sbi, i + CURSEG_HOT_NODE));
+		ckpt->cur_node_blkoff[i] =
+			cpu_to_le16(curseg_blkoff(sbi, i + CURSEG_HOT_NODE));
+		ckpt->alloc_type[i + CURSEG_HOT_NODE] =
+				curseg_alloc_type(sbi, i + CURSEG_HOT_NODE);
+	}
+	for (i = 0; i < 3; i++) {
+		ckpt->cur_data_segno[i] =
+			cpu_to_le32(curseg_segno(sbi, i + CURSEG_HOT_DATA));
+		ckpt->cur_data_blkoff[i] =
+			cpu_to_le16(curseg_blkoff(sbi, i + CURSEG_HOT_DATA));
+		ckpt->alloc_type[i + CURSEG_HOT_DATA] =
+				curseg_alloc_type(sbi, i + CURSEG_HOT_DATA);
+	}
+
+	ckpt->valid_node_count = cpu_to_le32(valid_node_count(sbi));
+	ckpt->valid_inode_count = cpu_to_le32(valid_inode_count(sbi));
+	ckpt->next_free_nid = cpu_to_le32(last_nid);
+
+	/* 2 cp  + n data seg summary + orphan inode blocks */
+	data_sum_blocks = npages_for_summary_flush(sbi);
+	if (data_sum_blocks < 3)
+		ckpt->ckpt_flags |= CP_COMPACT_SUM_FLAG;
+	else
+		ckpt->ckpt_flags &= (~CP_COMPACT_SUM_FLAG);
+
+	orphan_blocks = (sbi->n_orphans + F2FS_ORPHANS_PER_BLOCK - 1)
+					/ F2FS_ORPHANS_PER_BLOCK;
+	ckpt->cp_pack_start_sum = 1 + orphan_blocks;
+	ckpt->cp_pack_total_block_count = 2 + data_sum_blocks + orphan_blocks;
+
+	if (is_umount) {
+		ckpt->ckpt_flags |= CP_UMOUNT_FLAG;
+		ckpt->cp_pack_total_block_count += NR_CURSEG_NODE_TYPE;
+	} else {
+		ckpt->ckpt_flags &= (~CP_UMOUNT_FLAG);
+	}
+
+	if (sbi->n_orphans)
+		ckpt->ckpt_flags |= CP_ORPHAN_PRESENT_FLAG;
+	else
+		ckpt->ckpt_flags &= (~CP_ORPHAN_PRESENT_FLAG);
+
+	/* update SIT/NAT bitmap */
+	get_sit_bitmap(sbi, __bitmap_ptr(sbi, SIT_BITMAP));
+	get_nat_bitmap(sbi, __bitmap_ptr(sbi, NAT_BITMAP));
+
+	crc32 = f2fs_crc32(ckpt, le32_to_cpu(ckpt->checksum_offset));
+	*(__u32 *)((unsigned char *)ckpt +
+				le32_to_cpu(ckpt->checksum_offset))
+				= cpu_to_le32(crc32);
+
+	start_blk = __start_cp_addr(sbi);
+
+	/* write out checkpoint buffer at block 0 */
+	cp_page = grab_meta_page(sbi, start_blk++);
+	kaddr = page_address(cp_page);
+	memcpy(kaddr, ckpt, (1 << sbi->log_blocksize));
+	set_page_dirty(cp_page);
+	f2fs_put_page(cp_page, 1);
+
+	if (sbi->n_orphans) {
+		write_orphan_inodes(sbi, start_blk);
+		start_blk += orphan_blocks;
+	}
+
+	write_data_summaries(sbi, start_blk);
+	start_blk += data_sum_blocks;
+	if (is_umount) {
+		write_node_summaries(sbi, start_blk);
+		start_blk += NR_CURSEG_NODE_TYPE;
+	}
+
+	/* writeout checkpoint block */
+	cp_page = grab_meta_page(sbi, start_blk);
+	kaddr = page_address(cp_page);
+	memcpy(kaddr, ckpt, (1 << sbi->log_blocksize));
+	set_page_dirty(cp_page);
+	f2fs_put_page(cp_page, 1);
+
+	/* wait for previous submitted node/meta pages writeback */
+	while (get_pages(sbi, F2FS_WRITEBACK))
+		congestion_wait(BLK_RW_ASYNC, HZ / 50);
+
+	filemap_fdatawait_range(sbi->node_inode->i_mapping, 0, LONG_MAX);
+	filemap_fdatawait_range(sbi->meta_inode->i_mapping, 0, LONG_MAX);
+
+	/* update user_block_counts */
+	sbi->last_valid_block_count = sbi->total_valid_block_count;
+	sbi->alloc_valid_block_count = 0;
+
+	/* Here, we only have one bio having CP pack */
+	if (sbi->ckpt->ckpt_flags & CP_ERROR_FLAG)
+		sbi->sb->s_flags |= MS_RDONLY;
+	else
+		sync_meta_pages(sbi, META_FLUSH, LONG_MAX);
+
+	clear_prefree_segments(sbi);
+	F2FS_RESET_SB_DIRT(sbi);
+}
+
+/**
+ * We guarantee that this checkpoint procedure should not fail.
+ */
+void write_checkpoint(struct f2fs_sb_info *sbi, bool blocked, bool is_umount)
+{
+	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
+	unsigned long long ckpt_ver;
+
+	if (!blocked) {
+		mutex_lock(&sbi->cp_mutex);
+		block_operations(sbi);
+	}
+
+	f2fs_submit_bio(sbi, DATA, true);
+	f2fs_submit_bio(sbi, NODE, true);
+	f2fs_submit_bio(sbi, META, true);
+
+	/*
+	 * update checkpoint pack index
+	 * Increase the version number so that
+	 * SIT entries and seg summaries are written at correct place
+	 */
+	ckpt_ver = le64_to_cpu(ckpt->checkpoint_ver);
+	ckpt->checkpoint_ver = cpu_to_le64(++ckpt_ver);
+
+	/* write cached NAT/SIT entries to NAT/SIT area */
+	flush_nat_entries(sbi);
+	flush_sit_entries(sbi);
+
+	reset_victim_segmap(sbi);
+
+	/* unlock all the fs_lock[] in do_checkpoint() */
+	do_checkpoint(sbi, is_umount);
+
+	unblock_operations(sbi);
+	mutex_unlock(&sbi->cp_mutex);
+}
+
+void init_orphan_info(struct f2fs_sb_info *sbi)
+{
+	mutex_init(&sbi->orphan_inode_mutex);
+	INIT_LIST_HEAD(&sbi->orphan_inode_list);
+	sbi->n_orphans = 0;
+}
+
+int create_checkpoint_caches(void)
+{
+	orphan_entry_slab = f2fs_kmem_cache_create("f2fs_orphan_entry",
+			sizeof(struct orphan_inode_entry), NULL);
+	if (unlikely(!orphan_entry_slab))
+		return -ENOMEM;
+	inode_entry_slab = f2fs_kmem_cache_create("f2fs_dirty_dir_entry",
+			sizeof(struct dir_inode_entry), NULL);
+	if (unlikely(!inode_entry_slab)) {
+		kmem_cache_destroy(orphan_entry_slab);
+		return -ENOMEM;
+	}
+	return 0;
+}
+
+void destroy_checkpoint_caches(void)
+{
+	kmem_cache_destroy(orphan_entry_slab);
+	kmem_cache_destroy(inode_entry_slab);
+}
