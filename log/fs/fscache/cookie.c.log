commit efc930fa1d844869eb65586f8cdd6a7837db3607
Author: Mauro Carvalho Chehab <mchehab+huawei@kernel.org>
Date:   Mon Apr 27 23:16:55 2020 +0200

    docs: filesystems: caching/netfs-api.txt: convert it to ReST
    
    - Add a SPDX header;
    - Adjust document and section titles;
    - Some whitespace fixes and new line breaks;
    - Mark literal blocks as such;
    - Add it to filesystems/caching/index.rst.
    
    Signed-off-by: Mauro Carvalho Chehab <mchehab+huawei@kernel.org>
    Link: https://lore.kernel.org/r/cfe4cb1bf8e1f0093d44c30801ec42e74721e543.1588021877.git.mchehab+huawei@kernel.org
    Signed-off-by: Jonathan Corbet <corbet@lwn.net>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 0ce39658a620..751bc5b1cddf 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -4,7 +4,7 @@
  * Copyright (C) 2004-2007 Red Hat, Inc. All Rights Reserved.
  * Written by David Howells (dhowells@redhat.com)
  *
- * See Documentation/filesystems/caching/netfs-api.txt for more information on
+ * See Documentation/filesystems/caching/netfs-api.rst for more information on
  * the netfs API.
  */
 

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index c550512ce335..0ce39658a620 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -1,13 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /* netfs cookie management
  *
  * Copyright (C) 2004-2007 Red Hat, Inc. All Rights Reserved.
  * Written by David Howells (dhowells@redhat.com)
  *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
- *
  * See Documentation/filesystems/caching/netfs-api.txt for more information on
  * the netfs API.
  */

commit fa520c47eaa15b9baa8ad66ac18da4a31679693b
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Wed Oct 17 15:23:59 2018 +0100

    fscache: Fix out of bound read in long cookie keys
    
    fscache_set_key() can incur an out-of-bounds read, reported by KASAN:
    
     BUG: KASAN: slab-out-of-bounds in fscache_alloc_cookie+0x5b3/0x680 [fscache]
     Read of size 4 at addr ffff88084ff056d4 by task mount.nfs/32615
    
    and also reported by syzbot at https://lkml.org/lkml/2018/7/8/236
    
      BUG: KASAN: slab-out-of-bounds in fscache_set_key fs/fscache/cookie.c:120 [inline]
      BUG: KASAN: slab-out-of-bounds in fscache_alloc_cookie+0x7a9/0x880 fs/fscache/cookie.c:171
      Read of size 4 at addr ffff8801d3cc8bb4 by task syz-executor907/4466
    
    This happens for any index_key_len which is not divisible by 4 and is
    larger than the size of the inline key, because the code allocates exactly
    index_key_len for the key buffer, but the hashing loop is stepping through
    it 4 bytes (u32) at a time in the buf[] array.
    
    Fix this by calculating how many u32 buffers we'll need by using
    DIV_ROUND_UP, and then using kcalloc() to allocate a precleared allocation
    buffer to hold the index_key, then using that same count as the hashing
    index limit.
    
    Fixes: ec0328e46d6e ("fscache: Maintain a catalogue of allocated cookies")
    Reported-by: syzbot+a95b989b2dde8e806af8@syzkaller.appspotmail.com
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Cc: stable <stable@vger.kernel.org>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index b52f1dcd5dea..c550512ce335 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -70,7 +70,7 @@ void fscache_free_cookie(struct fscache_cookie *cookie)
 }
 
 /*
- * Set the index key in a cookie.  The cookie struct has space for a 12-byte
+ * Set the index key in a cookie.  The cookie struct has space for a 16-byte
  * key plus length and hash, but if that's not big enough, it's instead a
  * pointer to a buffer containing 3 bytes of hash, 1 byte of length and then
  * the key data.
@@ -80,10 +80,13 @@ static int fscache_set_key(struct fscache_cookie *cookie,
 {
 	unsigned long long h;
 	u32 *buf;
+	int bufs;
 	int i;
 
+	bufs = DIV_ROUND_UP(index_key_len, sizeof(*buf));
+
 	if (index_key_len > sizeof(cookie->inline_key)) {
-		buf = kzalloc(index_key_len, GFP_KERNEL);
+		buf = kcalloc(bufs, sizeof(*buf), GFP_KERNEL);
 		if (!buf)
 			return -ENOMEM;
 		cookie->key = buf;
@@ -98,7 +101,8 @@ static int fscache_set_key(struct fscache_cookie *cookie,
 	 */
 	h = (unsigned long)cookie->parent;
 	h += index_key_len + cookie->type;
-	for (i = 0; i < (index_key_len + sizeof(u32) - 1) / sizeof(u32); i++)
+
+	for (i = 0; i < bufs; i++)
 		h += buf[i];
 
 	cookie->key_hash = h ^ (h >> 32);

commit 1ff22883b0b2f7a73eb2609ffe879c9fd96f6328
Author: David Howells <dhowells@redhat.com>
Date:   Wed Oct 17 15:23:45 2018 +0100

    fscache: Fix incomplete initialisation of inline key space
    
    The inline key in struct rxrpc_cookie is insufficiently initialized,
    zeroing only 3 of the 4 slots, therefore an index_key_len between 13 and 15
    bytes will end up hashing uninitialized memory because the memcpy only
    partially fills the last buf[] element.
    
    Fix this by clearing fscache_cookie objects on allocation rather than using
    the slab constructor to initialise them.  We're going to pretty much fill
    in the entire struct anyway, so bringing it into our dcache writably
    shouldn't incur much overhead.
    
    This removes the need to do clearance in fscache_set_key() (where we aren't
    doing it correctly anyway).
    
    Also, we don't need to set cookie->key_len in fscache_set_key() as we
    already did it in the only caller, so remove that.
    
    Fixes: ec0328e46d6e ("fscache: Maintain a catalogue of allocated cookies")
    Reported-by: syzbot+a95b989b2dde8e806af8@syzkaller.appspotmail.com
    Reported-by: Eric Sandeen <sandeen@redhat.com>
    Cc: stable <stable@vger.kernel.org>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 83bfe04456b6..b52f1dcd5dea 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -69,19 +69,6 @@ void fscache_free_cookie(struct fscache_cookie *cookie)
 	}
 }
 
-/*
- * initialise an cookie jar slab element prior to any use
- */
-void fscache_cookie_init_once(void *_cookie)
-{
-	struct fscache_cookie *cookie = _cookie;
-
-	memset(cookie, 0, sizeof(*cookie));
-	spin_lock_init(&cookie->lock);
-	spin_lock_init(&cookie->stores_lock);
-	INIT_HLIST_HEAD(&cookie->backing_objects);
-}
-
 /*
  * Set the index key in a cookie.  The cookie struct has space for a 12-byte
  * key plus length and hash, but if that's not big enough, it's instead a
@@ -95,8 +82,6 @@ static int fscache_set_key(struct fscache_cookie *cookie,
 	u32 *buf;
 	int i;
 
-	cookie->key_len = index_key_len;
-
 	if (index_key_len > sizeof(cookie->inline_key)) {
 		buf = kzalloc(index_key_len, GFP_KERNEL);
 		if (!buf)
@@ -104,9 +89,6 @@ static int fscache_set_key(struct fscache_cookie *cookie,
 		cookie->key = buf;
 	} else {
 		buf = (u32 *)cookie->inline_key;
-		buf[0] = 0;
-		buf[1] = 0;
-		buf[2] = 0;
 	}
 
 	memcpy(buf, index_key, index_key_len);
@@ -161,7 +143,7 @@ struct fscache_cookie *fscache_alloc_cookie(
 	struct fscache_cookie *cookie;
 
 	/* allocate and initialise a cookie */
-	cookie = kmem_cache_alloc(fscache_cookie_jar, GFP_KERNEL);
+	cookie = kmem_cache_zalloc(fscache_cookie_jar, GFP_KERNEL);
 	if (!cookie)
 		return NULL;
 
@@ -192,6 +174,9 @@ struct fscache_cookie *fscache_alloc_cookie(
 	cookie->netfs_data	= netfs_data;
 	cookie->flags		= (1 << FSCACHE_COOKIE_NO_DATA_YET);
 	cookie->type		= def->type;
+	spin_lock_init(&cookie->lock);
+	spin_lock_init(&cookie->stores_lock);
+	INIT_HLIST_HEAD(&cookie->backing_objects);
 
 	/* radix tree insertion won't use the preallocation pool unless it's
 	 * told it may not wait */

commit f29507ce66701084c39aeb1b0ae71690cbff3554
Author: Kiran Kumar Modukuri <kiran.modukuri@gmail.com>
Date:   Thu Jun 21 13:31:44 2018 -0700

    fscache: Fix reference overput in fscache_attach_object() error handling
    
    When a cookie is allocated that causes fscache_object structs to be
    allocated, those objects are initialised with the cookie pointer, but
    aren't blessed with a ref on that cookie unless the attachment is
    successfully completed in fscache_attach_object().
    
    If attachment fails because the parent object was dying or there was a
    collision, fscache_attach_object() returns without incrementing the cookie
    counter - but upon failure of this function, the object is released which
    then puts the cookie, whether or not a ref was taken on the cookie.
    
    Fix this by taking a ref on the cookie when it is assigned in
    fscache_object_init(), even when we're creating a root object.
    
    
    Analysis from Kiran Kumar:
    
    This bug has been seen in 4.4.0-124-generic #148-Ubuntu kernel
    
    BugLink: https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1776277
    
    fscache cookie ref count updated incorrectly during fscache object
    allocation resulting in following Oops.
    
    kernel BUG at /build/linux-Y09MKI/linux-4.4.0/fs/fscache/internal.h:321!
    kernel BUG at /build/linux-Y09MKI/linux-4.4.0/fs/fscache/cookie.c:639!
    
    [Cause]
    Two threads are trying to do operate on a cookie and two objects.
    
    (1) One thread tries to unmount the filesystem and in process goes over a
        huge list of objects marking them dead and deleting the objects.
        cookie->usage is also decremented in following path:
    
          nfs_fscache_release_super_cookie
           -> __fscache_relinquish_cookie
            ->__fscache_cookie_put
            ->BUG_ON(atomic_read(&cookie->usage) <= 0);
    
    (2) A second thread tries to lookup an object for reading data in following
        path:
    
        fscache_alloc_object
        1) cachefiles_alloc_object
            -> fscache_object_init
               -> assign cookie, but usage not bumped.
        2) fscache_attach_object -> fails in cant_attach_object because the
             cookie's backing object or cookie's->parent object are going away
        3) fscache_put_object
            -> cachefiles_put_object
              ->fscache_object_destroy
                ->fscache_cookie_put
                   ->BUG_ON(atomic_read(&cookie->usage) <= 0);
    
    [NOTE from dhowells] It's unclear as to the circumstances in which (2) can
    take place, given that thread (1) is in nfs_kill_super(), however a
    conflicting NFS mount with slightly different parameters that creates a
    different superblock would do it.  A backtrace from Kiran seems to show
    that this is a possibility:
    
        kernel BUG at/build/linux-Y09MKI/linux-4.4.0/fs/fscache/cookie.c:639!
        ...
        RIP: __fscache_cookie_put+0x3a/0x40 [fscache]
        Call Trace:
         __fscache_relinquish_cookie+0x87/0x120 [fscache]
         nfs_fscache_release_super_cookie+0x2d/0xb0 [nfs]
         nfs_kill_super+0x29/0x40 [nfs]
         deactivate_locked_super+0x48/0x80
         deactivate_super+0x5c/0x60
         cleanup_mnt+0x3f/0x90
         __cleanup_mnt+0x12/0x20
         task_work_run+0x86/0xb0
         exit_to_usermode_loop+0xc2/0xd0
         syscall_return_slowpath+0x4e/0x60
         int_ret_from_sys_call+0x25/0x9f
    
    [Fix] Bump up the cookie usage in fscache_object_init, when it is first
    being assigned a cookie atomically such that the cookie is added and bumped
    up if its refcount is not zero.  Remove the assignment in
    fscache_attach_object().
    
    [Testcase]
    I have run ~100 hours of NFS stress tests and not seen this bug recur.
    
    [Regression Potential]
     - Limited to fscache/cachefiles.
    
    Fixes: ccc4fc3d11e9 ("FS-Cache: Implement the cookie management part of the netfs API")
    Signed-off-by: Kiran Kumar Modukuri <kiran.modukuri@gmail.com>
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 97137d7ec5ee..83bfe04456b6 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -516,6 +516,7 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 		goto error;
 	}
 
+	ASSERTCMP(object->cookie, ==, cookie);
 	fscache_stat(&fscache_n_object_alloc);
 
 	object->debug_id = atomic_inc_return(&fscache_object_debug_id);
@@ -571,6 +572,8 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 
 	_enter("{%s},{OBJ%x}", cookie->def->name, object->debug_id);
 
+	ASSERTCMP(object->cookie, ==, cookie);
+
 	spin_lock(&cookie->lock);
 
 	/* there may be multiple initial creations of this object, but we only
@@ -610,9 +613,7 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 		spin_unlock(&cache->object_list_lock);
 	}
 
-	/* attach to the cookie */
-	object->cookie = cookie;
-	fscache_cookie_get(cookie, fscache_cookie_get_attach_object);
+	/* Attach to the cookie.  The object already has a ref on it. */
 	hlist_add_head(&object->cookie_link, &cookie->backing_objects);
 
 	fscache_objlist_add(object);

commit e5a955419642e0842fd26e1ada6ab3328018ca16
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Tue Apr 10 16:36:48 2018 -0700

    fscache: use appropriate radix tree accessors
    
    Don't open-code accesses to data structure internals.
    
    Link: http://lkml.kernel.org/r/20180313132639.17387-7-willy@infradead.org
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Reviewed-by: Jeff Layton <jlayton@redhat.com>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 7dc55b93a830..97137d7ec5ee 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -832,7 +832,7 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie,
 	/* Clear pointers back to the netfs */
 	cookie->netfs_data	= NULL;
 	cookie->def		= NULL;
-	BUG_ON(cookie->stores.rnode);
+	BUG_ON(!radix_tree_empty(&cookie->stores));
 
 	if (cookie->parent) {
 		ASSERTCMP(atomic_read(&cookie->parent->usage), >, 0);

commit ec0328e46d6e5d0f17372eb90ab8e333c2ac7ca9
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:28 2018 +0100

    fscache: Maintain a catalogue of allocated cookies
    
    Maintain a catalogue of allocated cookies so that cookie collisions can be
    handled properly.  For the moment, this just involves printing a warning
    and returning a NULL cookie to the caller of fscache_acquire_cookie(), but
    in future it might make sense to wait for the old cookie to finish being
    cleaned up.
    
    This requires the cookie key to be stored attached to the cookie so that we
    still have the key available if the netfs relinquishes the cookie.  This is
    done by an earlier patch.
    
    The catalogue also renders redundant fscache_netfs_list (used for checking
    for duplicates), so that can be removed.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Anna Schumaker <anna.schumaker@netapp.com>
    Tested-by: Steve Dickson <steved@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 8ca9a932d225..7dc55b93a830 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -21,6 +21,9 @@ struct kmem_cache *fscache_cookie_jar;
 
 static atomic_t fscache_object_debug_id = ATOMIC_INIT(0);
 
+#define fscache_cookie_hash_shift 15
+static struct hlist_bl_head fscache_cookie_hash[1 << fscache_cookie_hash_shift];
+
 static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie,
 					    loff_t object_size);
 static int fscache_alloc_object(struct fscache_cache *cache,
@@ -28,6 +31,44 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 static int fscache_attach_object(struct fscache_cookie *cookie,
 				 struct fscache_object *object);
 
+static void fscache_print_cookie(struct fscache_cookie *cookie, char prefix)
+{
+	struct hlist_node *object;
+	const u8 *k;
+	unsigned loop;
+
+	pr_err("%c-cookie c=%p [p=%p fl=%lx nc=%u na=%u]\n",
+	       prefix, cookie, cookie->parent, cookie->flags,
+	       atomic_read(&cookie->n_children),
+	       atomic_read(&cookie->n_active));
+	pr_err("%c-cookie d=%p n=%p\n",
+	       prefix, cookie->def, cookie->netfs_data);
+
+	object = READ_ONCE(cookie->backing_objects.first);
+	if (object)
+		pr_err("%c-cookie o=%p\n",
+		       prefix, hlist_entry(object, struct fscache_object, cookie_link));
+
+	pr_err("%c-key=[%u] '", prefix, cookie->key_len);
+	k = (cookie->key_len <= sizeof(cookie->inline_key)) ?
+		cookie->inline_key : cookie->key;
+	for (loop = 0; loop < cookie->key_len; loop++)
+		pr_cont("%02x", k[loop]);
+	pr_cont("'\n");
+}
+
+void fscache_free_cookie(struct fscache_cookie *cookie)
+{
+	if (cookie) {
+		BUG_ON(!hlist_empty(&cookie->backing_objects));
+		if (cookie->aux_len > sizeof(cookie->inline_aux))
+			kfree(cookie->aux);
+		if (cookie->key_len > sizeof(cookie->inline_key))
+			kfree(cookie->key);
+		kmem_cache_free(fscache_cookie_jar, cookie);
+	}
+}
+
 /*
  * initialise an cookie jar slab element prior to any use
  */
@@ -41,6 +82,170 @@ void fscache_cookie_init_once(void *_cookie)
 	INIT_HLIST_HEAD(&cookie->backing_objects);
 }
 
+/*
+ * Set the index key in a cookie.  The cookie struct has space for a 12-byte
+ * key plus length and hash, but if that's not big enough, it's instead a
+ * pointer to a buffer containing 3 bytes of hash, 1 byte of length and then
+ * the key data.
+ */
+static int fscache_set_key(struct fscache_cookie *cookie,
+			   const void *index_key, size_t index_key_len)
+{
+	unsigned long long h;
+	u32 *buf;
+	int i;
+
+	cookie->key_len = index_key_len;
+
+	if (index_key_len > sizeof(cookie->inline_key)) {
+		buf = kzalloc(index_key_len, GFP_KERNEL);
+		if (!buf)
+			return -ENOMEM;
+		cookie->key = buf;
+	} else {
+		buf = (u32 *)cookie->inline_key;
+		buf[0] = 0;
+		buf[1] = 0;
+		buf[2] = 0;
+	}
+
+	memcpy(buf, index_key, index_key_len);
+
+	/* Calculate a hash and combine this with the length in the first word
+	 * or first half word
+	 */
+	h = (unsigned long)cookie->parent;
+	h += index_key_len + cookie->type;
+	for (i = 0; i < (index_key_len + sizeof(u32) - 1) / sizeof(u32); i++)
+		h += buf[i];
+
+	cookie->key_hash = h ^ (h >> 32);
+	return 0;
+}
+
+static long fscache_compare_cookie(const struct fscache_cookie *a,
+				   const struct fscache_cookie *b)
+{
+	const void *ka, *kb;
+
+	if (a->key_hash != b->key_hash)
+		return (long)a->key_hash - (long)b->key_hash;
+	if (a->parent != b->parent)
+		return (long)a->parent - (long)b->parent;
+	if (a->key_len != b->key_len)
+		return (long)a->key_len - (long)b->key_len;
+	if (a->type != b->type)
+		return (long)a->type - (long)b->type;
+
+	if (a->key_len <= sizeof(a->inline_key)) {
+		ka = &a->inline_key;
+		kb = &b->inline_key;
+	} else {
+		ka = a->key;
+		kb = b->key;
+	}
+	return memcmp(ka, kb, a->key_len);
+}
+
+/*
+ * Allocate a cookie.
+ */
+struct fscache_cookie *fscache_alloc_cookie(
+	struct fscache_cookie *parent,
+	const struct fscache_cookie_def *def,
+	const void *index_key, size_t index_key_len,
+	const void *aux_data, size_t aux_data_len,
+	void *netfs_data,
+	loff_t object_size)
+{
+	struct fscache_cookie *cookie;
+
+	/* allocate and initialise a cookie */
+	cookie = kmem_cache_alloc(fscache_cookie_jar, GFP_KERNEL);
+	if (!cookie)
+		return NULL;
+
+	cookie->key_len = index_key_len;
+	cookie->aux_len = aux_data_len;
+
+	if (fscache_set_key(cookie, index_key, index_key_len) < 0)
+		goto nomem;
+
+	if (cookie->aux_len <= sizeof(cookie->inline_aux)) {
+		memcpy(cookie->inline_aux, aux_data, cookie->aux_len);
+	} else {
+		cookie->aux = kmemdup(aux_data, cookie->aux_len, GFP_KERNEL);
+		if (!cookie->aux)
+			goto nomem;
+	}
+
+	atomic_set(&cookie->usage, 1);
+	atomic_set(&cookie->n_children, 0);
+
+	/* We keep the active count elevated until relinquishment to prevent an
+	 * attempt to wake up every time the object operations queue quiesces.
+	 */
+	atomic_set(&cookie->n_active, 1);
+
+	cookie->def		= def;
+	cookie->parent		= parent;
+	cookie->netfs_data	= netfs_data;
+	cookie->flags		= (1 << FSCACHE_COOKIE_NO_DATA_YET);
+	cookie->type		= def->type;
+
+	/* radix tree insertion won't use the preallocation pool unless it's
+	 * told it may not wait */
+	INIT_RADIX_TREE(&cookie->stores, GFP_NOFS & ~__GFP_DIRECT_RECLAIM);
+	return cookie;
+
+nomem:
+	fscache_free_cookie(cookie);
+	return NULL;
+}
+
+/*
+ * Attempt to insert the new cookie into the hash.  If there's a collision, we
+ * return the old cookie if it's not in use and an error otherwise.
+ */
+struct fscache_cookie *fscache_hash_cookie(struct fscache_cookie *candidate)
+{
+	struct fscache_cookie *cursor;
+	struct hlist_bl_head *h;
+	struct hlist_bl_node *p;
+	unsigned int bucket;
+
+	bucket = candidate->key_hash & (ARRAY_SIZE(fscache_cookie_hash) - 1);
+	h = &fscache_cookie_hash[bucket];
+
+	hlist_bl_lock(h);
+	hlist_bl_for_each_entry(cursor, p, h, hash_link) {
+		if (fscache_compare_cookie(candidate, cursor) == 0)
+			goto collision;
+	}
+
+	__set_bit(FSCACHE_COOKIE_ACQUIRED, &candidate->flags);
+	fscache_cookie_get(candidate->parent, fscache_cookie_get_acquire_parent);
+	atomic_inc(&candidate->parent->n_children);
+	hlist_bl_add_head(&candidate->hash_link, h);
+	hlist_bl_unlock(h);
+	return candidate;
+
+collision:
+	if (test_and_set_bit(FSCACHE_COOKIE_ACQUIRED, &cursor->flags)) {
+		trace_fscache_cookie(cursor, fscache_cookie_collision,
+				     atomic_read(&cursor->usage));
+		pr_err("Duplicate cookie detected\n");
+		fscache_print_cookie(cursor, 'O');
+		fscache_print_cookie(candidate, 'N');
+		hlist_bl_unlock(h);
+		return NULL;
+	}
+
+	fscache_cookie_get(cursor, fscache_cookie_get_reacquire);
+	hlist_bl_unlock(h);
+	return cursor;
+}
+
 /*
  * request a cookie to represent an object (index, datafile, xattr, etc)
  * - parent specifies the parent object
@@ -65,7 +270,7 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	loff_t object_size,
 	bool enable)
 {
-	struct fscache_cookie *cookie;
+	struct fscache_cookie *candidate, *cookie;
 
 	BUG_ON(!def);
 
@@ -95,53 +300,24 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	BUG_ON(def->type == FSCACHE_COOKIE_TYPE_INDEX &&
 	       parent->type != FSCACHE_COOKIE_TYPE_INDEX);
 
-	/* allocate and initialise a cookie */
-	cookie = kmem_cache_alloc(fscache_cookie_jar, GFP_KERNEL);
-	if (!cookie) {
+	candidate = fscache_alloc_cookie(parent, def,
+					 index_key, index_key_len,
+					 aux_data, aux_data_len,
+					 netfs_data, object_size);
+	if (!candidate) {
 		fscache_stat(&fscache_n_acquires_oom);
 		_leave(" [ENOMEM]");
 		return NULL;
 	}
 
-	cookie->key_len		= index_key_len;
-	cookie->aux_len		= aux_data_len;
-
-	if (cookie->key_len <= sizeof(cookie->inline_key)) {
-		memcpy(cookie->inline_key, index_key, cookie->key_len);
-	} else {
-		cookie->key = kmemdup(index_key, cookie->key_len, GFP_KERNEL);
-		if (!cookie->key)
-			goto nomem;
-	}
-
-	if (cookie->aux_len <= sizeof(cookie->inline_aux)) {
-		memcpy(cookie->inline_aux, aux_data, cookie->aux_len);
-	} else {
-		cookie->aux = kmemdup(aux_data, cookie->aux_len, GFP_KERNEL);
-		if (!cookie->aux)
-			goto nomem;
+	cookie = fscache_hash_cookie(candidate);
+	if (!cookie) {
+		trace_fscache_cookie(candidate, fscache_cookie_discard, 1);
+		goto out;
 	}
 
-	atomic_set(&cookie->usage, 1);
-	atomic_set(&cookie->n_children, 0);
-
-	/* We keep the active count elevated until relinquishment to prevent an
-	 * attempt to wake up every time the object operations queue quiesces.
-	 */
-	atomic_set(&cookie->n_active, 1);
-
-	fscache_cookie_get(parent, fscache_cookie_get_acquire_parent);
-	atomic_inc(&parent->n_children);
-
-	cookie->def		= def;
-	cookie->parent		= parent;
-	cookie->netfs_data	= netfs_data;
-	cookie->flags		= (1 << FSCACHE_COOKIE_NO_DATA_YET);
-	cookie->type		= def->type;
-	
-	/* radix tree insertion won't use the preallocation pool unless it's
-	 * told it may not wait */
-	INIT_RADIX_TREE(&cookie->stores, GFP_NOFS & ~__GFP_DIRECT_RECLAIM);
+	if (cookie == candidate)
+		candidate = NULL;
 
 	switch (cookie->type) {
 	case FSCACHE_COOKIE_TYPE_INDEX:
@@ -178,16 +354,10 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	}
 
 	fscache_stat(&fscache_n_acquires_ok);
-	_leave(" = %p", cookie);
-	return cookie;
 
-nomem:
-	if (cookie->aux_len > sizeof(cookie->inline_aux))
-		kfree(cookie->aux);
-	if (cookie->key_len > sizeof(cookie->inline_key))
-		kfree(cookie->key);
-	kmem_cache_free(fscache_cookie_jar, cookie);
-	return NULL;
+out:
+	fscache_free_cookie(candidate);
+	return cookie;
 }
 EXPORT_SYMBOL(__fscache_acquire_cookie);
 
@@ -678,6 +848,22 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie,
 }
 EXPORT_SYMBOL(__fscache_relinquish_cookie);
 
+/*
+ * Remove a cookie from the hash table.
+ */
+static void fscache_unhash_cookie(struct fscache_cookie *cookie)
+{
+	struct hlist_bl_head *h;
+	unsigned int bucket;
+
+	bucket = cookie->key_hash & (ARRAY_SIZE(fscache_cookie_hash) - 1);
+	h = &fscache_cookie_hash[bucket];
+
+	hlist_bl_lock(h);
+	hlist_bl_del(&cookie->hash_link);
+	hlist_bl_unlock(h);
+}
+
 /*
  * Drop a reference to a cookie.
  */
@@ -698,12 +884,8 @@ void fscache_cookie_put(struct fscache_cookie *cookie,
 		BUG_ON(usage < 0);
 
 		parent = cookie->parent;
-		BUG_ON(!hlist_empty(&cookie->backing_objects));
-		if (cookie->aux_len > sizeof(cookie->inline_aux))
-			kfree(cookie->aux);
-		if (cookie->key_len > sizeof(cookie->inline_key))
-			kfree(cookie->key);
-		kmem_cache_free(fscache_cookie_jar, cookie);
+		fscache_unhash_cookie(cookie);
+		fscache_free_cookie(cookie);
 
 		cookie = parent;
 		where = fscache_cookie_put_parent;

commit ee1235a9a06813429c201bf186397a6feeea07bf
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:28 2018 +0100

    fscache: Pass object size in rather than calling back for it
    
    Pass the object size in to fscache_acquire_cookie() and
    fscache_write_page() rather than the netfs providing a callback by which it
    can be received.  This makes it easier to update the size of the object
    when a new page is written that extends the object.
    
    The current object size is also passed by fscache to the check_aux
    function, obviating the need to store it in the aux data.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Anna Schumaker <anna.schumaker@netapp.com>
    Tested-by: Steve Dickson <steved@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 4d6210082a60..8ca9a932d225 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -21,7 +21,8 @@ struct kmem_cache *fscache_cookie_jar;
 
 static atomic_t fscache_object_debug_id = ATOMIC_INIT(0);
 
-static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie);
+static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie,
+					    loff_t object_size);
 static int fscache_alloc_object(struct fscache_cache *cache,
 				struct fscache_cookie *cookie);
 static int fscache_attach_object(struct fscache_cookie *cookie,
@@ -61,6 +62,7 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	const void *index_key, size_t index_key_len,
 	const void *aux_data, size_t aux_data_len,
 	void *netfs_data,
+	loff_t object_size,
 	bool enable)
 {
 	struct fscache_cookie *cookie;
@@ -160,7 +162,7 @@ struct fscache_cookie *__fscache_acquire_cookie(
 		 * - we create indices on disk when we need them as an index
 		 * may exist in multiple caches */
 		if (cookie->type != FSCACHE_COOKIE_TYPE_INDEX) {
-			if (fscache_acquire_non_index_cookie(cookie) == 0) {
+			if (fscache_acquire_non_index_cookie(cookie, object_size) == 0) {
 				set_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags);
 			} else {
 				atomic_dec(&parent->n_children);
@@ -194,6 +196,7 @@ EXPORT_SYMBOL(__fscache_acquire_cookie);
  */
 void __fscache_enable_cookie(struct fscache_cookie *cookie,
 			     const void *aux_data,
+			     loff_t object_size,
 			     bool (*can_enable)(void *data),
 			     void *data)
 {
@@ -215,7 +218,7 @@ void __fscache_enable_cookie(struct fscache_cookie *cookie,
 		/* Wait for outstanding disablement to complete */
 		__fscache_wait_on_invalidate(cookie);
 
-		if (fscache_acquire_non_index_cookie(cookie) == 0)
+		if (fscache_acquire_non_index_cookie(cookie, object_size) == 0)
 			set_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags);
 	} else {
 		set_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags);
@@ -232,11 +235,11 @@ EXPORT_SYMBOL(__fscache_enable_cookie);
  * - this must make sure the index chain is instantiated and instantiate the
  *   object representation too
  */
-static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie)
+static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie,
+					    loff_t object_size)
 {
 	struct fscache_object *object;
 	struct fscache_cache *cache;
-	uint64_t i_size;
 	int ret;
 
 	_enter("");
@@ -275,9 +278,6 @@ static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie)
 		return ret;
 	}
 
-	/* pass on how big the object we're caching is supposed to be */
-	cookie->def->get_attr(cookie->netfs_data, &i_size);
-
 	spin_lock(&cookie->lock);
 	if (hlist_empty(&cookie->backing_objects)) {
 		spin_unlock(&cookie->lock);
@@ -287,7 +287,7 @@ static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie)
 	object = hlist_entry(cookie->backing_objects.first,
 			     struct fscache_object, cookie_link);
 
-	fscache_set_store_limit(object, i_size);
+	fscache_set_store_limit(object, object_size);
 
 	/* initiate the process of looking up all the objects in the chain
 	 * (done by fscache_initialise_object()) */

commit 402cb8dda949d9b8c0df20ad2527d139faad7ca1
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:28 2018 +0100

    fscache: Attach the index key and aux data to the cookie
    
    Attach copies of the index key and auxiliary data to the fscache cookie so
    that:
    
     (1) The callbacks to the netfs for this stuff can be eliminated.  This
         can simplify things in the cache as the information is still
         available, even after the cache has relinquished the cookie.
    
     (2) Simplifies the locking requirements of accessing the information as we
         don't have to worry about the netfs object going away on us.
    
     (3) The cache can do lazy updating of the coherency information on disk.
         As long as the cache is flushed before reboot/poweroff, there's no
         need to update the coherency info on disk every time it changes.
    
     (4) Cookies can be hashed or put in a tree as the index key is easily
         available.  This allows:
    
         (a) Checks for duplicate cookies can be made at the top fscache layer
             rather than down in the bowels of the cache backend.
    
         (b) Caching can be added to a netfs object that has a cookie if the
             cache is brought online after the netfs object is allocated.
    
    A certain amount of space is made in the cookie for inline copies of the
    data, but if it won't fit there, extra memory will be allocated for it.
    
    The downside of this is that live cache operation requires more memory.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Anna Schumaker <anna.schumaker@netapp.com>
    Tested-by: Steve Dickson <steved@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index ea1f80daaff4..4d6210082a60 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -58,6 +58,8 @@ void fscache_cookie_init_once(void *_cookie)
 struct fscache_cookie *__fscache_acquire_cookie(
 	struct fscache_cookie *parent,
 	const struct fscache_cookie_def *def,
+	const void *index_key, size_t index_key_len,
+	const void *aux_data, size_t aux_data_len,
 	void *netfs_data,
 	bool enable)
 {
@@ -69,6 +71,13 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	       parent ? (char *) parent->def->name : "<no-parent>",
 	       def->name, netfs_data, enable);
 
+	if (!index_key || !index_key_len || index_key_len > 255 || aux_data_len > 255)
+		return NULL;
+	if (!aux_data || !aux_data_len) {
+		aux_data = NULL;
+		aux_data_len = 0;
+	}
+
 	fscache_stat(&fscache_n_acquires);
 
 	/* if there's no parent cookie, then we don't create one here either */
@@ -79,11 +88,10 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	}
 
 	/* validate the definition */
-	BUG_ON(!def->get_key);
 	BUG_ON(!def->name[0]);
 
 	BUG_ON(def->type == FSCACHE_COOKIE_TYPE_INDEX &&
-	       parent->def->type != FSCACHE_COOKIE_TYPE_INDEX);
+	       parent->type != FSCACHE_COOKIE_TYPE_INDEX);
 
 	/* allocate and initialise a cookie */
 	cookie = kmem_cache_alloc(fscache_cookie_jar, GFP_KERNEL);
@@ -93,6 +101,25 @@ struct fscache_cookie *__fscache_acquire_cookie(
 		return NULL;
 	}
 
+	cookie->key_len		= index_key_len;
+	cookie->aux_len		= aux_data_len;
+
+	if (cookie->key_len <= sizeof(cookie->inline_key)) {
+		memcpy(cookie->inline_key, index_key, cookie->key_len);
+	} else {
+		cookie->key = kmemdup(index_key, cookie->key_len, GFP_KERNEL);
+		if (!cookie->key)
+			goto nomem;
+	}
+
+	if (cookie->aux_len <= sizeof(cookie->inline_aux)) {
+		memcpy(cookie->inline_aux, aux_data, cookie->aux_len);
+	} else {
+		cookie->aux = kmemdup(aux_data, cookie->aux_len, GFP_KERNEL);
+		if (!cookie->aux)
+			goto nomem;
+	}
+
 	atomic_set(&cookie->usage, 1);
 	atomic_set(&cookie->n_children, 0);
 
@@ -108,12 +135,13 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	cookie->parent		= parent;
 	cookie->netfs_data	= netfs_data;
 	cookie->flags		= (1 << FSCACHE_COOKIE_NO_DATA_YET);
-
+	cookie->type		= def->type;
+	
 	/* radix tree insertion won't use the preallocation pool unless it's
 	 * told it may not wait */
 	INIT_RADIX_TREE(&cookie->stores, GFP_NOFS & ~__GFP_DIRECT_RECLAIM);
 
-	switch (cookie->def->type) {
+	switch (cookie->type) {
 	case FSCACHE_COOKIE_TYPE_INDEX:
 		fscache_stat(&fscache_n_cookie_index);
 		break;
@@ -131,7 +159,7 @@ struct fscache_cookie *__fscache_acquire_cookie(
 		/* if the object is an index then we need do nothing more here
 		 * - we create indices on disk when we need them as an index
 		 * may exist in multiple caches */
-		if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX) {
+		if (cookie->type != FSCACHE_COOKIE_TYPE_INDEX) {
 			if (fscache_acquire_non_index_cookie(cookie) == 0) {
 				set_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags);
 			} else {
@@ -150,6 +178,14 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	fscache_stat(&fscache_n_acquires_ok);
 	_leave(" = %p", cookie);
 	return cookie;
+
+nomem:
+	if (cookie->aux_len > sizeof(cookie->inline_aux))
+		kfree(cookie->aux);
+	if (cookie->key_len > sizeof(cookie->inline_key))
+		kfree(cookie->key);
+	kmem_cache_free(fscache_cookie_jar, cookie);
+	return NULL;
 }
 EXPORT_SYMBOL(__fscache_acquire_cookie);
 
@@ -157,6 +193,7 @@ EXPORT_SYMBOL(__fscache_acquire_cookie);
  * Enable a cookie to permit it to accept new operations.
  */
 void __fscache_enable_cookie(struct fscache_cookie *cookie,
+			     const void *aux_data,
 			     bool (*can_enable)(void *data),
 			     void *data)
 {
@@ -167,12 +204,14 @@ void __fscache_enable_cookie(struct fscache_cookie *cookie,
 	wait_on_bit_lock(&cookie->flags, FSCACHE_COOKIE_ENABLEMENT_LOCK,
 			 TASK_UNINTERRUPTIBLE);
 
+	fscache_update_aux(cookie, aux_data);
+
 	if (test_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags))
 		goto out_unlock;
 
 	if (can_enable && !can_enable(data)) {
 		/* The netfs decided it didn't want to enable after all */
-	} else if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX) {
+	} else if (cookie->type != FSCACHE_COOKIE_TYPE_INDEX) {
 		/* Wait for outstanding disablement to complete */
 		__fscache_wait_on_invalidate(cookie);
 
@@ -431,10 +470,7 @@ void __fscache_invalidate(struct fscache_cookie *cookie)
 	 * there, and if it's doing that, it may as well just retire the
 	 * cookie.
 	 */
-	ASSERTCMP(cookie->def->type, ==, FSCACHE_COOKIE_TYPE_DATAFILE);
-
-	/* We will be updating the cookie too. */
-	BUG_ON(!cookie->def->get_aux);
+	ASSERTCMP(cookie->type, ==, FSCACHE_COOKIE_TYPE_DATAFILE);
 
 	/* If there's an object, we tell the object state machine to handle the
 	 * invalidation on our behalf, otherwise there's nothing to do.
@@ -478,7 +514,7 @@ EXPORT_SYMBOL(__fscache_wait_on_invalidate);
 /*
  * update the index entries backing a cookie
  */
-void __fscache_update_cookie(struct fscache_cookie *cookie)
+void __fscache_update_cookie(struct fscache_cookie *cookie, const void *aux_data)
 {
 	struct fscache_object *object;
 
@@ -492,10 +528,10 @@ void __fscache_update_cookie(struct fscache_cookie *cookie)
 
 	_enter("{%s}", cookie->def->name);
 
-	BUG_ON(!cookie->def->get_aux);
-
 	spin_lock(&cookie->lock);
 
+	fscache_update_aux(cookie, aux_data);
+
 	if (fscache_cookie_enabled(cookie)) {
 		/* update the index entry on disk in each cache backing this
 		 * cookie.
@@ -514,7 +550,9 @@ EXPORT_SYMBOL(__fscache_update_cookie);
 /*
  * Disable a cookie to stop it from accepting new requests from the netfs.
  */
-void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
+void __fscache_disable_cookie(struct fscache_cookie *cookie,
+			      const void *aux_data,
+			      bool invalidate)
 {
 	struct fscache_object *object;
 	bool awaken = false;
@@ -533,6 +571,9 @@ void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 
 	wait_on_bit_lock(&cookie->flags, FSCACHE_COOKIE_ENABLEMENT_LOCK,
 			 TASK_UNINTERRUPTIBLE);
+
+	fscache_update_aux(cookie, aux_data);
+
 	if (!test_and_clear_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags))
 		goto out_unlock_enable;
 
@@ -570,7 +611,7 @@ void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 	}
 
 	/* Make sure any pending writes are cancelled. */
-	if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX)
+	if (cookie->type != FSCACHE_COOKIE_TYPE_INDEX)
 		fscache_invalidate_writes(cookie);
 
 	/* Reset the cookie state if it wasn't relinquished */
@@ -592,7 +633,9 @@ EXPORT_SYMBOL(__fscache_disable_cookie);
  * - all dependents of this cookie must have already been unregistered
  *   (indices/files/pages)
  */
-void __fscache_relinquish_cookie(struct fscache_cookie *cookie, bool retire)
+void __fscache_relinquish_cookie(struct fscache_cookie *cookie,
+				 const void *aux_data,
+				 bool retire)
 {
 	fscache_stat(&fscache_n_relinquishes);
 	if (retire)
@@ -614,7 +657,7 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, bool retire)
 	if (test_and_set_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags))
 		BUG();
 
-	__fscache_disable_cookie(cookie, retire);
+	__fscache_disable_cookie(cookie, aux_data, retire);
 
 	/* Clear pointers back to the netfs */
 	cookie->netfs_data	= NULL;
@@ -656,6 +699,10 @@ void fscache_cookie_put(struct fscache_cookie *cookie,
 
 		parent = cookie->parent;
 		BUG_ON(!hlist_empty(&cookie->backing_objects));
+		if (cookie->aux_len > sizeof(cookie->inline_aux))
+			kfree(cookie->aux);
+		if (cookie->key_len > sizeof(cookie->inline_key))
+			kfree(cookie->key);
 		kmem_cache_free(fscache_cookie_jar, cookie);
 
 		cookie = parent;
@@ -670,7 +717,8 @@ void fscache_cookie_put(struct fscache_cookie *cookie,
  *
  * NOTE: it only serves no-index type
  */
-int __fscache_check_consistency(struct fscache_cookie *cookie)
+int __fscache_check_consistency(struct fscache_cookie *cookie,
+				const void *aux_data)
 {
 	struct fscache_operation *op;
 	struct fscache_object *object;
@@ -679,7 +727,7 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 
 	_enter("%p,", cookie);
 
-	ASSERTCMP(cookie->def->type, ==, FSCACHE_COOKIE_TYPE_DATAFILE);
+	ASSERTCMP(cookie->type, ==, FSCACHE_COOKIE_TYPE_DATAFILE);
 
 	if (fscache_wait_for_deferred_lookup(cookie) < 0)
 		return -ERESTARTSYS;
@@ -699,6 +747,8 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 
 	spin_lock(&cookie->lock);
 
+	fscache_update_aux(cookie, aux_data);
+
 	if (!fscache_cookie_enabled(cookie) ||
 	    hlist_empty(&cookie->backing_objects))
 		goto inconsistent;

commit 08c2e3d087840cd1e7141b62d92f3dc897147984
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:27 2018 +0100

    fscache: Add more tracepoints
    
    Add more tracepoints to fscache, including:
    
     (*) fscache_page - Tracks netfs pages known to fscache.
    
     (*) fscache_check_page - Tracks the netfs querying whether a page is
         pending storage.
    
     (*) fscache_wake_cookie - Tracks cookies being woken up after a page
         completes/aborts storage in the cache.
    
     (*) fscache_op - Tracks operations being initialised.
    
     (*) fscache_wrote_page - Tracks return of the backend write_page op.
    
     (*) fscache_gang_lookup - Tracks lookup of pages to be stored in the write
         operation.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 20bc3341f113..ea1f80daaff4 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -691,10 +691,11 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 	if (!op)
 		return -ENOMEM;
 
-	fscache_operation_init(op, NULL, NULL, NULL);
+	fscache_operation_init(cookie, op, NULL, NULL, NULL);
 	op->flags = FSCACHE_OP_MYTHREAD |
 		(1 << FSCACHE_OP_WAITING) |
 		(1 << FSCACHE_OP_UNUSE_COOKIE);
+	trace_fscache_page_op(cookie, NULL, op, fscache_page_op_check_consistency);
 
 	spin_lock(&cookie->lock);
 

commit a18feb55769b705a44c4107786c4045eae2e87b6
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:27 2018 +0100

    fscache: Add tracepoints
    
    Add some tracepoints to fscache:
    
     (*) fscache_cookie - Tracks a cookie's usage count.
    
     (*) fscache_netfs - Logs registration of a network filesystem, including
         the pointer to the cookie allocated.
    
     (*) fscache_acquire - Logs cookie acquisition.
    
     (*) fscache_relinquish - Logs cookie relinquishment.
    
     (*) fscache_enable - Logs enablement of a cookie.
    
     (*) fscache_disable - Logs disablement of a cookie.
    
     (*) fscache_osm - Tracks execution of states in the object state machine.
    
    and cachefiles:
    
     (*) cachefiles_ref - Tracks a cachefiles object's usage count.
    
     (*) cachefiles_lookup - Logs result of lookup_one_len().
    
     (*) cachefiles_mkdir - Logs result of vfs_mkdir().
    
     (*) cachefiles_create - Logs result of vfs_create().
    
     (*) cachefiles_unlink - Logs calls to vfs_unlink().
    
     (*) cachefiles_rename - Logs calls to vfs_rename().
    
     (*) cachefiles_mark_active - Logs an object becoming active.
    
     (*) cachefiles_wait_active - Logs a wait for an old object to be
         destroyed.
    
     (*) cachefiles_mark_inactive - Logs an object becoming inactive.
    
     (*) cachefiles_mark_buried - Logs the burial of an object.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 98d22f495cd8..20bc3341f113 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -101,7 +101,7 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	 */
 	atomic_set(&cookie->n_active, 1);
 
-	atomic_inc(&parent->usage);
+	fscache_cookie_get(parent, fscache_cookie_get_acquire_parent);
 	atomic_inc(&parent->n_children);
 
 	cookie->def		= def;
@@ -125,6 +125,8 @@ struct fscache_cookie *__fscache_acquire_cookie(
 		break;
 	}
 
+	trace_fscache_acquire(cookie);
+
 	if (enable) {
 		/* if the object is an index then we need do nothing more here
 		 * - we create indices on disk when we need them as an index
@@ -134,7 +136,8 @@ struct fscache_cookie *__fscache_acquire_cookie(
 				set_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags);
 			} else {
 				atomic_dec(&parent->n_children);
-				__fscache_cookie_put(cookie);
+				fscache_cookie_put(cookie,
+						   fscache_cookie_put_acquire_nobufs);
 				fscache_stat(&fscache_n_acquires_nobufs);
 				_leave(" = NULL");
 				return NULL;
@@ -159,6 +162,8 @@ void __fscache_enable_cookie(struct fscache_cookie *cookie,
 {
 	_enter("%p", cookie);
 
+	trace_fscache_enable(cookie);
+
 	wait_on_bit_lock(&cookie->flags, FSCACHE_COOKIE_ENABLEMENT_LOCK,
 			 TASK_UNINTERRUPTIBLE);
 
@@ -318,7 +323,7 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 	 * attached to the cookie */
 	if (fscache_attach_object(cookie, object) < 0) {
 		fscache_stat(&fscache_n_cop_put_object);
-		cache->ops->put_object(object);
+		cache->ops->put_object(object, fscache_obj_put_attach_fail);
 		fscache_stat_d(&fscache_n_cop_put_object);
 	}
 
@@ -338,7 +343,7 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 
 error_put:
 	fscache_stat(&fscache_n_cop_put_object);
-	cache->ops->put_object(object);
+	cache->ops->put_object(object, fscache_obj_put_alloc_fail);
 	fscache_stat_d(&fscache_n_cop_put_object);
 error:
 	_leave(" = %d", ret);
@@ -398,7 +403,7 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 
 	/* attach to the cookie */
 	object->cookie = cookie;
-	atomic_inc(&cookie->usage);
+	fscache_cookie_get(cookie, fscache_cookie_get_attach_object);
 	hlist_add_head(&object->cookie_link, &cookie->backing_objects);
 
 	fscache_objlist_add(object);
@@ -516,6 +521,8 @@ void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 
 	_enter("%p,%u", cookie, invalidate);
 
+	trace_fscache_disable(cookie);
+
 	ASSERTCMP(atomic_read(&cookie->n_active), >, 0);
 
 	if (atomic_read(&cookie->n_children) != 0) {
@@ -601,6 +608,8 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, bool retire)
 	       cookie, cookie->def->name, cookie->netfs_data,
 	       atomic_read(&cookie->n_active), retire);
 
+	trace_fscache_relinquish(cookie, retire);
+
 	/* No further netfs-accessing operations on this cookie permitted */
 	if (test_and_set_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags))
 		BUG();
@@ -620,35 +629,38 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, bool retire)
 
 	/* Dispose of the netfs's link to the cookie */
 	ASSERTCMP(atomic_read(&cookie->usage), >, 0);
-	fscache_cookie_put(cookie);
+	fscache_cookie_put(cookie, fscache_cookie_put_relinquish);
 
 	_leave("");
 }
 EXPORT_SYMBOL(__fscache_relinquish_cookie);
 
 /*
- * destroy a cookie
+ * Drop a reference to a cookie.
  */
-void __fscache_cookie_put(struct fscache_cookie *cookie)
+void fscache_cookie_put(struct fscache_cookie *cookie,
+			enum fscache_cookie_trace where)
 {
 	struct fscache_cookie *parent;
+	int usage;
 
 	_enter("%p", cookie);
 
-	for (;;) {
-		_debug("FREE COOKIE %p", cookie);
+	do {
+		usage = atomic_dec_return(&cookie->usage);
+		trace_fscache_cookie(cookie, where, usage);
+
+		if (usage > 0)
+			return;
+		BUG_ON(usage < 0);
+
 		parent = cookie->parent;
 		BUG_ON(!hlist_empty(&cookie->backing_objects));
 		kmem_cache_free(fscache_cookie_jar, cookie);
 
-		if (!parent)
-			break;
-
 		cookie = parent;
-		BUG_ON(atomic_read(&cookie->usage) <= 0);
-		if (!atomic_dec_and_test(&cookie->usage))
-			break;
-	}
+		where = fscache_cookie_put_parent;
+	} while (cookie);
 
 	_leave("");
 }

commit d0fb31ecda2c3c6092d0c2a46a6a72653e7dcabb
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 4 13:41:26 2018 +0100

    fscache: Detect multiple relinquishment of a cookie
    
    Report if an fscache cookie is relinquished multiple times by the netfs.
    
    Signed-off-by: David <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index d705125665f0..98d22f495cd8 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -602,7 +602,8 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, bool retire)
 	       atomic_read(&cookie->n_active), retire);
 
 	/* No further netfs-accessing operations on this cookie permitted */
-	set_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags);
+	if (test_and_set_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags))
+		BUG();
 
 	__fscache_disable_cookie(cookie, retire);
 

commit dc5d4afbb0bf7b7746ff5e56e1a5688ad7f29b32
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Mar 15 11:43:43 2018 +0100

    sched/wait, fs/fscache: Convert wait_on_atomic_t() usage to the new wait_var_event() API
    
    The old wait_on_atomic_t() is going to get removed, use the more
    flexible wait_var_event() API instead.
    
    No change in functionality.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index ff84258132bb..d705125665f0 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -557,9 +557,10 @@ void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 	 * n_active reaches 0).  This makes sure outstanding reads and writes
 	 * have completed.
 	 */
-	if (!atomic_dec_and_test(&cookie->n_active))
-		wait_on_atomic_t(&cookie->n_active, atomic_t_wait,
-				 TASK_UNINTERRUPTIBLE);
+	if (!atomic_dec_and_test(&cookie->n_active)) {
+		wait_var_event(&cookie->n_active,
+			       !atomic_read(&cookie->n_active));
+	}
 
 	/* Make sure any pending writes are cancelled. */
 	if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX)

commit 5e4def20381678ba3ce0a4e117f97e378ecd81bc
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 2 15:27:44 2017 +0000

    Pass mode to wait_on_atomic_t() action funcs and provide default actions
    
    Make wait_on_atomic_t() pass the TASK_* mode onto its action function as an
    extra argument and make it 'unsigned int throughout.
    
    Also, consolidate a bunch of identical action functions into a default
    function that can do the appropriate thing for the mode.
    
    Also, change the argument name in the bit_wait*() function declarations to
    reflect the fact that it's the mode and not the bit number.
    
    [Peter Z gives this a grudging ACK, but thinks that the whole atomic_t wait
    should be done differently, though he's not immediately sure as to how]
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    cc: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 40d61077bead..ff84258132bb 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -558,7 +558,7 @@ void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 	 * have completed.
 	 */
 	if (!atomic_dec_and_test(&cookie->n_active))
-		wait_on_atomic_t(&cookie->n_active, fscache_wait_atomic_t,
+		wait_on_atomic_t(&cookie->n_active, atomic_t_wait,
 				 TASK_UNINTERRUPTIBLE);
 
 	/* Make sure any pending writes are cancelled. */

commit 6bdded59c8933940ac7e5b416448276ac89d1144
Author: David Howells <dhowells@redhat.com>
Date:   Wed Jan 18 14:29:25 2017 +0000

    fscache: Clear outstanding writes when disabling a cookie
    
    fscache_disable_cookie() needs to clear the outstanding writes on the
    cookie it's disabling because they cannot be completed after.
    
    Without this, fscache_nfs_open_file() gets stuck because it disables the
    cookie when the file is opened for writing but can't uncache the pages till
    afterwards - otherwise there's a race between the open routine and anyone
    who already has it open R/O and is still reading from it.
    
    Looking in /proc/pid/stack of the offending process shows:
    
    [<ffffffffa0142883>] __fscache_wait_on_page_write+0x82/0x9b [fscache]
    [<ffffffffa014336e>] __fscache_uncache_all_inode_pages+0x91/0xe1 [fscache]
    [<ffffffffa01740fa>] nfs_fscache_open_file+0x59/0x9e [nfs]
    [<ffffffffa01ccf41>] nfs4_file_open+0x17f/0x1b8 [nfsv4]
    [<ffffffff8117350e>] do_dentry_open+0x16d/0x2b7
    [<ffffffff811743ac>] vfs_open+0x5c/0x65
    [<ffffffff81184185>] path_openat+0x785/0x8fb
    [<ffffffff81184343>] do_filp_open+0x48/0x9e
    [<ffffffff81174710>] do_sys_open+0x13b/0x1cb
    [<ffffffff811747b9>] SyS_open+0x19/0x1b
    [<ffffffff81001c44>] do_syscall_64+0x80/0x17a
    [<ffffffff8165c2da>] return_from_SYSCALL_64+0x0/0x7a
    [<ffffffffffffffff>] 0xffffffffffffffff
    
    Reported-by: Jianhong Yin <jiyin@redhat.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Jeff Layton <jlayton@redhat.com>
    Acked-by: Steve Dickson <steved@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 4304072161aa..40d61077bead 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -542,6 +542,7 @@ void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 		hlist_for_each_entry(object, &cookie->backing_objects, cookie_link) {
 			if (invalidate)
 				set_bit(FSCACHE_OBJECT_RETIRED, &object->flags);
+			clear_bit(FSCACHE_OBJECT_PENDING_WRITE, &object->flags);
 			fscache_raise_event(object, FSCACHE_OBJECT_EV_KILL);
 		}
 	} else {
@@ -560,6 +561,10 @@ void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 		wait_on_atomic_t(&cookie->n_active, fscache_wait_atomic_t,
 				 TASK_UNINTERRUPTIBLE);
 
+	/* Make sure any pending writes are cancelled. */
+	if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX)
+		fscache_invalidate_writes(cookie);
+
 	/* Reset the cookie state if it wasn't relinquished */
 	if (!test_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags)) {
 		atomic_inc(&cookie->n_active);

commit d0164adc89f6bb374d304ffcc375c6d2652fe67d
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Fri Nov 6 16:28:21 2015 -0800

    mm, page_alloc: distinguish between being unable to sleep, unwilling to sleep and avoiding waking kswapd
    
    __GFP_WAIT has been used to identify atomic context in callers that hold
    spinlocks or are in interrupts.  They are expected to be high priority and
    have access one of two watermarks lower than "min" which can be referred
    to as the "atomic reserve".  __GFP_HIGH users get access to the first
    lower watermark and can be called the "high priority reserve".
    
    Over time, callers had a requirement to not block when fallback options
    were available.  Some have abused __GFP_WAIT leading to a situation where
    an optimisitic allocation with a fallback option can access atomic
    reserves.
    
    This patch uses __GFP_ATOMIC to identify callers that are truely atomic,
    cannot sleep and have no alternative.  High priority users continue to use
    __GFP_HIGH.  __GFP_DIRECT_RECLAIM identifies callers that can sleep and
    are willing to enter direct reclaim.  __GFP_KSWAPD_RECLAIM to identify
    callers that want to wake kswapd for background reclaim.  __GFP_WAIT is
    redefined as a caller that is willing to enter direct reclaim and wake
    kswapd for background reclaim.
    
    This patch then converts a number of sites
    
    o __GFP_ATOMIC is used by callers that are high priority and have memory
      pools for those requests. GFP_ATOMIC uses this flag.
    
    o Callers that have a limited mempool to guarantee forward progress clear
      __GFP_DIRECT_RECLAIM but keep __GFP_KSWAPD_RECLAIM. bio allocations fall
      into this category where kswapd will still be woken but atomic reserves
      are not used as there is a one-entry mempool to guarantee progress.
    
    o Callers that are checking if they are non-blocking should use the
      helper gfpflags_allow_blocking() where possible. This is because
      checking for __GFP_WAIT as was done historically now can trigger false
      positives. Some exceptions like dm-crypt.c exist where the code intent
      is clearer if __GFP_DIRECT_RECLAIM is used instead of the helper due to
      flag manipulations.
    
    o Callers that built their own GFP flags instead of starting with GFP_KERNEL
      and friends now also need to specify __GFP_KSWAPD_RECLAIM.
    
    The first key hazard to watch out for is callers that removed __GFP_WAIT
    and was depending on access to atomic reserves for inconspicuous reasons.
    In some cases it may be appropriate for them to use __GFP_HIGH.
    
    The second key hazard is callers that assembled their own combination of
    GFP flags instead of starting with something like GFP_KERNEL.  They may
    now wish to specify __GFP_KSWAPD_RECLAIM.  It's almost certainly harmless
    if it's missed in most cases as other activity will wake kswapd.
    
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Vitaly Wool <vitalywool@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index d403c69bee08..4304072161aa 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -111,7 +111,7 @@ struct fscache_cookie *__fscache_acquire_cookie(
 
 	/* radix tree insertion won't use the preallocation pool unless it's
 	 * told it may not wait */
-	INIT_RADIX_TREE(&cookie->stores, GFP_NOFS & ~__GFP_WAIT);
+	INIT_RADIX_TREE(&cookie->stores, GFP_NOFS & ~__GFP_DIRECT_RECLAIM);
 
 	switch (cookie->def->type) {
 	case FSCACHE_COOKIE_TYPE_INDEX:

commit d3b97ca4a99e4e6c78f5a21c968eadf5c8ba9971
Author: David Howells <dhowells@redhat.com>
Date:   Tue Feb 24 10:05:29 2015 +0000

    FS-Cache: The operation cancellation method needs calling in more places
    
    Any time an incomplete operation is cancelled, the operation cancellation
    function needs to be called to clean up.  This is currently being passed
    directly to some of the functions that might want to call it, but not all.
    
    Instead, pass the cancellation method pointer to the fscache_operation_init()
    and have that cache it in the operation struct.  Further, plug in a dummy
    cancellation handler if the caller declines to set one as this allows us to
    call the function unconditionally (the extra overhead isn't worth bothering
    about as we don't expect to be calling this typically).
    
    The cancellation method must thence be called everywhere the CANCELLED state
    is set.  Note that we call it *before* setting the CANCELLED state such that
    the method can use the old state value to guide its operation.
    
    fscache_do_cancel_retrieval() needs moving higher up in the sources so that
    the init function can use it now.
    
    Without this, the following oops may be seen:
    
            FS-Cache: Assertion failed
            FS-Cache: 3 == 0 is false
            ------------[ cut here ]------------
            kernel BUG at ../fs/fscache/page.c:261!
            ...
            RIP: 0010:[<ffffffffa0089c1b>]  fscache_release_retrieval_op+0x77/0x100
             [<ffffffffa008853d>] fscache_put_operation+0x114/0x2da
             [<ffffffffa008b8c2>] __fscache_read_or_alloc_pages+0x358/0x3b3
             [<ffffffffa00b761f>] __nfs_readpages_from_fscache+0x59/0xbf [nfs]
             [<ffffffffa00b06c5>] nfs_readpages+0x10c/0x185 [nfs]
             [<ffffffff81124925>] ? alloc_pages_current+0x119/0x13e
             [<ffffffff810ee5fd>] ? __page_cache_alloc+0xfb/0x10a
             [<ffffffff810f87f8>] __do_page_cache_readahead+0x188/0x22c
             [<ffffffff810f8b3a>] ondemand_readahead+0x29e/0x2af
             [<ffffffff810f8c92>] page_cache_sync_readahead+0x38/0x3a
             [<ffffffff810ef337>] generic_file_read_iter+0x1a2/0x55a
             [<ffffffffa00a9dff>] ? nfs_revalidate_mapping+0xd6/0x288 [nfs]
             [<ffffffffa00a6a23>] nfs_file_read+0x49/0x70 [nfs]
             [<ffffffff811363be>] new_sync_read+0x78/0x9c
             [<ffffffff81137164>] __vfs_read+0x13/0x38
             [<ffffffff8113721e>] vfs_read+0x95/0x121
             [<ffffffff811372f6>] SyS_read+0x4c/0x8a
             [<ffffffff81557a52>] system_call_fastpath+0x12/0x17
    
    The assertion is showing that the remaining number of pages (n_pages) is not 0
    when the operation is being released.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Steve Dickson <steved@redhat.com>
    Acked-by: Jeff Layton <jeff.layton@primarydata.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 8de22164f5fb..d403c69bee08 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -672,7 +672,7 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 	if (!op)
 		return -ENOMEM;
 
-	fscache_operation_init(op, NULL, NULL);
+	fscache_operation_init(op, NULL, NULL, NULL);
 	op->flags = FSCACHE_OP_MYTHREAD |
 		(1 << FSCACHE_OP_WAITING) |
 		(1 << FSCACHE_OP_UNUSE_COOKIE);
@@ -696,8 +696,7 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 	/* the work queue now carries its own ref on the object */
 	spin_unlock(&cookie->lock);
 
-	ret = fscache_wait_for_operation_activation(object, op,
-						    NULL, NULL, NULL);
+	ret = fscache_wait_for_operation_activation(object, op, NULL, NULL);
 	if (ret == 0) {
 		/* ask the cache to honour the operation */
 		ret = object->cache->ops->check_consistency(op);

commit 87021526300f1a292dd966e141e183630ac95317
Author: David Howells <dhowells@redhat.com>
Date:   Tue Feb 24 10:52:51 2015 +0000

    FS-Cache: fscache_object_is_dead() has wrong logic, kill it
    
    fscache_object_is_dead() returns true only if the object is marked dead and
    the cache got an I/O error.  This should be a logical OR instead.  Since two
    of the callers got split up into handling for separate subcases, expand the
    other callers and kill the function.  This is probably the right thing to do
    anyway since one of the subcases isn't about the object at all, but rather
    about the cache.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Steve Dickson <steved@redhat.com>
    Acked-by: Jeff Layton <jeff.layton@primarydata.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 89acec742e0b..8de22164f5fb 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -327,7 +327,8 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 
 object_already_extant:
 	ret = -ENOBUFS;
-	if (fscache_object_is_dead(object)) {
+	if (fscache_object_is_dying(object) ||
+	    fscache_cache_is_broken(object)) {
 		spin_unlock(&cookie->lock);
 		goto error;
 	}

commit 743162013d40ca612b4cb53d3a200dff2d9ab26e
Author: NeilBrown <neilb@suse.de>
Date:   Mon Jul 7 15:16:04 2014 +1000

    sched: Remove proliferation of wait_on_bit() action functions
    
    The current "wait_on_bit" interface requires an 'action'
    function to be provided which does the actual waiting.
    There are over 20 such functions, many of them identical.
    Most cases can be satisfied by one of just two functions, one
    which uses io_schedule() and one which just uses schedule().
    
    So:
     Rename wait_on_bit and        wait_on_bit_lock to
            wait_on_bit_action and wait_on_bit_lock_action
     to make it explicit that they need an action function.
    
     Introduce new wait_on_bit{,_lock} and wait_on_bit{,_lock}_io
     which are *not* given an action function but implicitly use
     a standard one.
     The decision to error-out if a signal is pending is now made
     based on the 'mode' argument rather than being encoded in the action
     function.
    
     All instances of the old wait_on_bit and wait_on_bit_lock which
     can use the new version have been changed accordingly and their
     action functions have been discarded.
     wait_on_bit{_lock} does not return any specific error code in the
     event of a signal so the caller must check for non-zero and
     interpolate their own error code as appropriate.
    
    The wait_on_bit() call in __fscache_wait_on_invalidate() was
    ambiguous as it specified TASK_UNINTERRUPTIBLE but used
    fscache_wait_bit_interruptible as an action function.
    David Howells confirms this should be uniformly
    "uninterruptible"
    
    The main remaining user of wait_on_bit{,_lock}_action is NFS
    which needs to use a freezer-aware schedule() call.
    
    A comment in fs/gfs2/glock.c notes that having multiple 'action'
    functions is useful as they display differently in the 'wchan'
    field of 'ps'. (and /proc/$PID/wchan).
    As the new bit_wait{,_io} functions are tagged "__sched", they
    will not show up at all, but something higher in the stack.  So
    the distinction will still be visible, only with different
    function names (gds2_glock_wait versus gfs2_glock_dq_wait in the
    gfs2/glock.c case).
    
    Since first version of this patch (against 3.15) two new action
    functions appeared, on in NFS and one in CIFS.  CIFS also now
    uses an action function that makes the same freezer aware
    schedule call as NFS.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Acked-by: David Howells <dhowells@redhat.com> (fscache, keys)
    Acked-by: Steven Whitehouse <swhiteho@redhat.com> (gfs2)
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Steve French <sfrench@samba.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/20140707051603.28027.72349.stgit@notabene.brown
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index aec01be91b0a..89acec742e0b 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -160,7 +160,7 @@ void __fscache_enable_cookie(struct fscache_cookie *cookie,
 	_enter("%p", cookie);
 
 	wait_on_bit_lock(&cookie->flags, FSCACHE_COOKIE_ENABLEMENT_LOCK,
-			 fscache_wait_bit, TASK_UNINTERRUPTIBLE);
+			 TASK_UNINTERRUPTIBLE);
 
 	if (test_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags))
 		goto out_unlock;
@@ -255,7 +255,7 @@ static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie)
 	if (!fscache_defer_lookup) {
 		_debug("non-deferred lookup %p", &cookie->flags);
 		wait_on_bit(&cookie->flags, FSCACHE_COOKIE_LOOKING_UP,
-			    fscache_wait_bit, TASK_UNINTERRUPTIBLE);
+			    TASK_UNINTERRUPTIBLE);
 		_debug("complete");
 		if (test_bit(FSCACHE_COOKIE_UNAVAILABLE, &cookie->flags))
 			goto unavailable;
@@ -463,7 +463,6 @@ void __fscache_wait_on_invalidate(struct fscache_cookie *cookie)
 	_enter("%p", cookie);
 
 	wait_on_bit(&cookie->flags, FSCACHE_COOKIE_INVALIDATING,
-		    fscache_wait_bit_interruptible,
 		    TASK_UNINTERRUPTIBLE);
 
 	_leave("");
@@ -525,7 +524,7 @@ void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 	}
 
 	wait_on_bit_lock(&cookie->flags, FSCACHE_COOKIE_ENABLEMENT_LOCK,
-			 fscache_wait_bit, TASK_UNINTERRUPTIBLE);
+			 TASK_UNINTERRUPTIBLE);
 	if (!test_and_clear_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags))
 		goto out_unlock_enable;
 

commit 36dfd116edd48fa6174d5694c143f1d4bd81aba8
Author: Fabian Frederick <fabf@skynet.be>
Date:   Wed Jun 4 16:05:38 2014 -0700

    fs/fscache: convert printk to pr_foo()
    
    All printk converted to pr_foo() except internal.h: printk(KERN_DEBUG
    
    Coalesce formats.
    
    Add pr_fmt
    
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 29d7feb62cf7..aec01be91b0a 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -519,7 +519,7 @@ void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 	ASSERTCMP(atomic_read(&cookie->n_active), >, 0);
 
 	if (atomic_read(&cookie->n_children) != 0) {
-		printk(KERN_ERR "FS-Cache: Cookie '%s' still has children\n",
+		pr_err("Cookie '%s' still has children\n",
 		       cookie->def->name);
 		BUG();
 	}

commit 94d30ae90a00cafe686c1057be57f4885f963abf
Author: David Howells <dhowells@redhat.com>
Date:   Sat Sep 21 00:09:31 2013 +0100

    FS-Cache: Provide the ability to enable/disable cookies
    
    Provide the ability to enable and disable fscache cookies.  A disabled cookie
    will reject or ignore further requests to:
    
            Acquire a child cookie
            Invalidate and update backing objects
            Check the consistency of a backing object
            Allocate storage for backing page
            Read backing pages
            Write to backing pages
    
    but still allows:
    
            Checks/waits on the completion of already in-progress objects
            Uncaching of pages
            Relinquishment of cookies
    
    Two new operations are provided:
    
     (1) Disable a cookie:
    
            void fscache_disable_cookie(struct fscache_cookie *cookie,
                                        bool invalidate);
    
         If the cookie is not already disabled, this locks the cookie against other
         dis/enablement ops, marks the cookie as being disabled, discards or
         invalidates any backing objects and waits for cessation of activity on any
         associated object.
    
         This is a wrapper around a chunk split out of fscache_relinquish_cookie(),
         but it reinitialises the cookie such that it can be reenabled.
    
         All possible failures are handled internally.  The caller should consider
         calling fscache_uncache_all_inode_pages() afterwards to make sure all page
         markings are cleared up.
    
     (2) Enable a cookie:
    
            void fscache_enable_cookie(struct fscache_cookie *cookie,
                                       bool (*can_enable)(void *data),
                                       void *data)
    
         If the cookie is not already enabled, this locks the cookie against other
         dis/enablement ops, invokes can_enable() and, if the cookie is not an
         index cookie, will begin the procedure of acquiring backing objects.
    
         The optional can_enable() function is passed the data argument and returns
         a ruling as to whether or not enablement should actually be permitted to
         begin.
    
         All possible failures are handled internally.  The cookie will only be
         marked as enabled if provisional backing objects are allocated.
    
    A later patch will introduce these to NFS.  Cookie enablement during nfs_open()
    is then contingent on i_writecount <= 0.  can_enable() checks for a race
    between open(O_RDONLY) and open(O_WRONLY/O_RDWR).  This simplifies NFS's cookie
    handling and allows us to get rid of open(O_RDONLY) accidentally introducing
    caching to an inode that's open for writing already.
    
    One operation has its API modified:
    
     (3) Acquire a cookie.
    
            struct fscache_cookie *fscache_acquire_cookie(
                    struct fscache_cookie *parent,
                    const struct fscache_cookie_def *def,
                    void *netfs_data,
                    bool enable);
    
         This now has an additional argument that indicates whether the requested
         cookie should be enabled by default.  It doesn't need the can_enable()
         function because the caller must prevent multiple calls for the same netfs
         object and it doesn't need to take the enablement lock because no one else
         can get at the cookie before this returns.
    
    Signed-off-by: David Howells <dhowells@redhat.com

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index d851aa555d28..29d7feb62cf7 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -58,15 +58,16 @@ void fscache_cookie_init_once(void *_cookie)
 struct fscache_cookie *__fscache_acquire_cookie(
 	struct fscache_cookie *parent,
 	const struct fscache_cookie_def *def,
-	void *netfs_data)
+	void *netfs_data,
+	bool enable)
 {
 	struct fscache_cookie *cookie;
 
 	BUG_ON(!def);
 
-	_enter("{%s},{%s},%p",
+	_enter("{%s},{%s},%p,%u",
 	       parent ? (char *) parent->def->name : "<no-parent>",
-	       def->name, netfs_data);
+	       def->name, netfs_data, enable);
 
 	fscache_stat(&fscache_n_acquires);
 
@@ -106,7 +107,7 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	cookie->def		= def;
 	cookie->parent		= parent;
 	cookie->netfs_data	= netfs_data;
-	cookie->flags		= 0;
+	cookie->flags		= (1 << FSCACHE_COOKIE_NO_DATA_YET);
 
 	/* radix tree insertion won't use the preallocation pool unless it's
 	 * told it may not wait */
@@ -124,16 +125,22 @@ struct fscache_cookie *__fscache_acquire_cookie(
 		break;
 	}
 
-	/* if the object is an index then we need do nothing more here - we
-	 * create indices on disk when we need them as an index may exist in
-	 * multiple caches */
-	if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX) {
-		if (fscache_acquire_non_index_cookie(cookie) < 0) {
-			atomic_dec(&parent->n_children);
-			__fscache_cookie_put(cookie);
-			fscache_stat(&fscache_n_acquires_nobufs);
-			_leave(" = NULL");
-			return NULL;
+	if (enable) {
+		/* if the object is an index then we need do nothing more here
+		 * - we create indices on disk when we need them as an index
+		 * may exist in multiple caches */
+		if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX) {
+			if (fscache_acquire_non_index_cookie(cookie) == 0) {
+				set_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags);
+			} else {
+				atomic_dec(&parent->n_children);
+				__fscache_cookie_put(cookie);
+				fscache_stat(&fscache_n_acquires_nobufs);
+				_leave(" = NULL");
+				return NULL;
+			}
+		} else {
+			set_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags);
 		}
 	}
 
@@ -143,6 +150,39 @@ struct fscache_cookie *__fscache_acquire_cookie(
 }
 EXPORT_SYMBOL(__fscache_acquire_cookie);
 
+/*
+ * Enable a cookie to permit it to accept new operations.
+ */
+void __fscache_enable_cookie(struct fscache_cookie *cookie,
+			     bool (*can_enable)(void *data),
+			     void *data)
+{
+	_enter("%p", cookie);
+
+	wait_on_bit_lock(&cookie->flags, FSCACHE_COOKIE_ENABLEMENT_LOCK,
+			 fscache_wait_bit, TASK_UNINTERRUPTIBLE);
+
+	if (test_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags))
+		goto out_unlock;
+
+	if (can_enable && !can_enable(data)) {
+		/* The netfs decided it didn't want to enable after all */
+	} else if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX) {
+		/* Wait for outstanding disablement to complete */
+		__fscache_wait_on_invalidate(cookie);
+
+		if (fscache_acquire_non_index_cookie(cookie) == 0)
+			set_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags);
+	} else {
+		set_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags);
+	}
+
+out_unlock:
+	clear_bit_unlock(FSCACHE_COOKIE_ENABLEMENT_LOCK, &cookie->flags);
+	wake_up_bit(&cookie->flags, FSCACHE_COOKIE_ENABLEMENT_LOCK);
+}
+EXPORT_SYMBOL(__fscache_enable_cookie);
+
 /*
  * acquire a non-index cookie
  * - this must make sure the index chain is instantiated and instantiate the
@@ -157,7 +197,7 @@ static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie)
 
 	_enter("");
 
-	cookie->flags = 1 << FSCACHE_COOKIE_UNAVAILABLE;
+	set_bit(FSCACHE_COOKIE_UNAVAILABLE, &cookie->flags);
 
 	/* now we need to see whether the backing objects for this cookie yet
 	 * exist, if not there'll be nothing to search */
@@ -180,9 +220,7 @@ static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie)
 
 	_debug("cache %s", cache->tag->name);
 
-	cookie->flags =
-		(1 << FSCACHE_COOKIE_LOOKING_UP) |
-		(1 << FSCACHE_COOKIE_NO_DATA_YET);
+	set_bit(FSCACHE_COOKIE_LOOKING_UP, &cookie->flags);
 
 	/* ask the cache to allocate objects for this cookie and its parent
 	 * chain */
@@ -398,7 +436,8 @@ void __fscache_invalidate(struct fscache_cookie *cookie)
 	if (!hlist_empty(&cookie->backing_objects)) {
 		spin_lock(&cookie->lock);
 
-		if (!hlist_empty(&cookie->backing_objects) &&
+		if (fscache_cookie_enabled(cookie) &&
+		    !hlist_empty(&cookie->backing_objects) &&
 		    !test_and_set_bit(FSCACHE_COOKIE_INVALIDATING,
 				      &cookie->flags)) {
 			object = hlist_entry(cookie->backing_objects.first,
@@ -452,10 +491,14 @@ void __fscache_update_cookie(struct fscache_cookie *cookie)
 
 	spin_lock(&cookie->lock);
 
-	/* update the index entry on disk in each cache backing this cookie */
-	hlist_for_each_entry(object,
-			     &cookie->backing_objects, cookie_link) {
-		fscache_raise_event(object, FSCACHE_OBJECT_EV_UPDATE);
+	if (fscache_cookie_enabled(cookie)) {
+		/* update the index entry on disk in each cache backing this
+		 * cookie.
+		 */
+		hlist_for_each_entry(object,
+				     &cookie->backing_objects, cookie_link) {
+			fscache_raise_event(object, FSCACHE_OBJECT_EV_UPDATE);
+		}
 	}
 
 	spin_unlock(&cookie->lock);
@@ -464,28 +507,14 @@ void __fscache_update_cookie(struct fscache_cookie *cookie)
 EXPORT_SYMBOL(__fscache_update_cookie);
 
 /*
- * release a cookie back to the cache
- * - the object will be marked as recyclable on disk if retire is true
- * - all dependents of this cookie must have already been unregistered
- *   (indices/files/pages)
+ * Disable a cookie to stop it from accepting new requests from the netfs.
  */
-void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
+void __fscache_disable_cookie(struct fscache_cookie *cookie, bool invalidate)
 {
 	struct fscache_object *object;
+	bool awaken = false;
 
-	fscache_stat(&fscache_n_relinquishes);
-	if (retire)
-		fscache_stat(&fscache_n_relinquishes_retire);
-
-	if (!cookie) {
-		fscache_stat(&fscache_n_relinquishes_null);
-		_leave(" [no cookie]");
-		return;
-	}
-
-	_enter("%p{%s,%p,%d},%d",
-	       cookie, cookie->def->name, cookie->netfs_data,
-	       atomic_read(&cookie->n_active), retire);
+	_enter("%p,%u", cookie, invalidate);
 
 	ASSERTCMP(atomic_read(&cookie->n_active), >, 0);
 
@@ -495,24 +524,82 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 		BUG();
 	}
 
-	/* No further netfs-accessing operations on this cookie permitted */
-	set_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags);
-	if (retire)
-		set_bit(FSCACHE_COOKIE_RETIRED, &cookie->flags);
+	wait_on_bit_lock(&cookie->flags, FSCACHE_COOKIE_ENABLEMENT_LOCK,
+			 fscache_wait_bit, TASK_UNINTERRUPTIBLE);
+	if (!test_and_clear_bit(FSCACHE_COOKIE_ENABLED, &cookie->flags))
+		goto out_unlock_enable;
+
+	/* If the cookie is being invalidated, wait for that to complete first
+	 * so that we can reuse the flag.
+	 */
+	__fscache_wait_on_invalidate(cookie);
+
+	/* Dispose of the backing objects */
+	set_bit(FSCACHE_COOKIE_INVALIDATING, &cookie->flags);
 
 	spin_lock(&cookie->lock);
-	hlist_for_each_entry(object, &cookie->backing_objects, cookie_link) {
-		fscache_raise_event(object, FSCACHE_OBJECT_EV_KILL);
+	if (!hlist_empty(&cookie->backing_objects)) {
+		hlist_for_each_entry(object, &cookie->backing_objects, cookie_link) {
+			if (invalidate)
+				set_bit(FSCACHE_OBJECT_RETIRED, &object->flags);
+			fscache_raise_event(object, FSCACHE_OBJECT_EV_KILL);
+		}
+	} else {
+		if (test_and_clear_bit(FSCACHE_COOKIE_INVALIDATING, &cookie->flags))
+			awaken = true;
 	}
 	spin_unlock(&cookie->lock);
+	if (awaken)
+		wake_up_bit(&cookie->flags, FSCACHE_COOKIE_INVALIDATING);
 
 	/* Wait for cessation of activity requiring access to the netfs (when
-	 * n_active reaches 0).
+	 * n_active reaches 0).  This makes sure outstanding reads and writes
+	 * have completed.
 	 */
 	if (!atomic_dec_and_test(&cookie->n_active))
 		wait_on_atomic_t(&cookie->n_active, fscache_wait_atomic_t,
 				 TASK_UNINTERRUPTIBLE);
 
+	/* Reset the cookie state if it wasn't relinquished */
+	if (!test_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags)) {
+		atomic_inc(&cookie->n_active);
+		set_bit(FSCACHE_COOKIE_NO_DATA_YET, &cookie->flags);
+	}
+
+out_unlock_enable:
+	clear_bit_unlock(FSCACHE_COOKIE_ENABLEMENT_LOCK, &cookie->flags);
+	wake_up_bit(&cookie->flags, FSCACHE_COOKIE_ENABLEMENT_LOCK);
+	_leave("");
+}
+EXPORT_SYMBOL(__fscache_disable_cookie);
+
+/*
+ * release a cookie back to the cache
+ * - the object will be marked as recyclable on disk if retire is true
+ * - all dependents of this cookie must have already been unregistered
+ *   (indices/files/pages)
+ */
+void __fscache_relinquish_cookie(struct fscache_cookie *cookie, bool retire)
+{
+	fscache_stat(&fscache_n_relinquishes);
+	if (retire)
+		fscache_stat(&fscache_n_relinquishes_retire);
+
+	if (!cookie) {
+		fscache_stat(&fscache_n_relinquishes_null);
+		_leave(" [no cookie]");
+		return;
+	}
+
+	_enter("%p{%s,%p,%d},%d",
+	       cookie, cookie->def->name, cookie->netfs_data,
+	       atomic_read(&cookie->n_active), retire);
+
+	/* No further netfs-accessing operations on this cookie permitted */
+	set_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags);
+
+	__fscache_disable_cookie(cookie, retire);
+
 	/* Clear pointers back to the netfs */
 	cookie->netfs_data	= NULL;
 	cookie->def		= NULL;
@@ -592,7 +679,8 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 
 	spin_lock(&cookie->lock);
 
-	if (hlist_empty(&cookie->backing_objects))
+	if (!fscache_cookie_enabled(cookie) ||
+	    hlist_empty(&cookie->backing_objects))
 		goto inconsistent;
 	object = hlist_entry(cookie->backing_objects.first,
 			     struct fscache_object, cookie_link);

commit 8fb883f3e30065529e4f35d4b4f355193dcdb7a2
Author: David Howells <dhowells@redhat.com>
Date:   Sat Sep 21 00:09:31 2013 +0100

    FS-Cache: Add use/unuse/wake cookie wrappers
    
    Add wrapper functions for dealing with cookie->n_active:
    
     (*) __fscache_use_cookie() to increment it.
    
     (*) __fscache_unuse_cookie() to decrement and test against zero.
    
     (*) __fscache_wake_unused_cookie() to wake up anyone waiting for it to reach
         zero.
    
    The second and third are split so that the third can be done after cookie->lock
    has been released in case the waiter wakes up whilst we're still holding it and
    tries to get it.
    
    We will need to wake-on-zero once the cookie disablement patch is applied
    because it will then be possible to see n_active become zero without the cookie
    being relinquished.
    
    Also move the cookie usement out of fscache_attr_changed_op() and into
    fscache_attr_changed() and the operation struct so that cookie disablement
    will be able to track it.
    
    Whilst we're at it, only increment n_active if we're about to do
    fscache_submit_op() so that we don't have to deal with undoing it if anything
    earlier fails.  Possibly this should be moved into fscache_submit_op() which
    could look at FSCACHE_OP_UNUSE_COOKIE.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index b2a86e324aac..d851aa555d28 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -568,6 +568,7 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 {
 	struct fscache_operation *op;
 	struct fscache_object *object;
+	bool wake_cookie = false;
 	int ret;
 
 	_enter("%p,", cookie);
@@ -600,7 +601,7 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 
 	op->debug_id = atomic_inc_return(&fscache_op_debug_id);
 
-	atomic_inc(&cookie->n_active);
+	__fscache_use_cookie(cookie);
 	if (fscache_submit_op(object, op) < 0)
 		goto submit_failed;
 
@@ -622,9 +623,11 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 	return ret;
 
 submit_failed:
-	atomic_dec(&cookie->n_active);
+	wake_cookie = __fscache_unuse_cookie(cookie);
 inconsistent:
 	spin_unlock(&cookie->lock);
+	if (wake_cookie)
+		__fscache_wake_unused_cookie(cookie);
 	kfree(op);
 	_leave(" = -ESTALE");
 	return -ESTALE;

commit 9c89d62948c4740e379a7e0085dd8d7c1561f53f
Author: Milosz Tanski <milosz@adfin.com>
Date:   Mon Sep 9 14:28:57 2013 -0400

    fscache: check consistency does not decrement refcount
    
    __fscache_check_consistency() does not decrement the count of operations
    active after it finishes in the success case. This leads to a hung tasks on
    cookie de-registration (commonly in inode eviction).
    
    INFO: task kworker/1:2:4214 blocked for more than 120 seconds.
    kworker/1:2     D ffff880443513fc0     0  4214      2 0x00000000
    Workqueue: ceph-msgr con_work [libceph]
      ...
    Call Trace:
     [<ffffffff81569fc6>] ? _raw_spin_unlock_irqrestore+0x16/0x20
     [<ffffffffa0016570>] ? fscache_wait_bit_interruptible+0x30/0x30 [fscache]
     [<ffffffff81568d09>] schedule+0x29/0x70
     [<ffffffffa001657e>] fscache_wait_atomic_t+0xe/0x20 [fscache]
     [<ffffffff815665cf>] out_of_line_wait_on_atomic_t+0x9f/0xe0
     [<ffffffff81083560>] ? autoremove_wake_function+0x40/0x40
     [<ffffffffa0015a9c>] __fscache_relinquish_cookie+0x15c/0x310 [fscache]
     [<ffffffffa00a4fae>] ceph_fscache_unregister_inode_cookie+0x3e/0x50 [ceph]
     [<ffffffffa007e373>] ceph_destroy_inode+0x33/0x200 [ceph]
     [<ffffffff811c13ae>] ? __fsnotify_inode_delete+0xe/0x10
     [<ffffffff8119ba1c>] destroy_inode+0x3c/0x70
     [<ffffffff8119bb69>] evict+0x119/0x1b0
    
    Signed-off-by: Milosz Tanski <milosz@adfin.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Sage Weil <sage@inktank.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 318e8433527c..b2a86e324aac 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -586,7 +586,8 @@ int __fscache_check_consistency(struct fscache_cookie *cookie)
 
 	fscache_operation_init(op, NULL, NULL);
 	op->flags = FSCACHE_OP_MYTHREAD |
-		(1 << FSCACHE_OP_WAITING);
+		(1 << FSCACHE_OP_WAITING) |
+		(1 << FSCACHE_OP_UNUSE_COOKIE);
 
 	spin_lock(&cookie->lock);
 

commit da9803bc8812f5bd3b26baaa90e515b843c65ff7
Author: David Howells <dhowells@redhat.com>
Date:   Wed Aug 21 17:29:38 2013 -0400

    FS-Cache: Add interface to check consistency of a cached object
    
    Extend the fscache netfs API so that the netfs can ask as to whether a cache
    object is up to date with respect to its corresponding netfs object:
    
            int fscache_check_consistency(struct fscache_cookie *cookie)
    
    This will call back to the netfs to check whether the auxiliary data associated
    with a cookie is correct.  It returns 0 if it is and -ESTALE if it isn't; it
    may also return -ENOMEM and -ERESTARTSYS.
    
    The backends now have to implement a mandatory operation pointer:
    
            int (*check_consistency)(struct fscache_object *object)
    
    that corresponds to the above API call.  FS-Cache takes care of pinning the
    object and the cookie in memory and managing this call with respect to the
    object state.
    
    Original-author: Hongyi Jia <jiayisuse@gmail.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Hongyi Jia <jiayisuse@gmail.com>
    cc: Milosz Tanski <milosz@adfin.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 0e91a3c9fdb2..318e8433527c 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -558,3 +558,74 @@ void __fscache_cookie_put(struct fscache_cookie *cookie)
 
 	_leave("");
 }
+
+/*
+ * check the consistency between the netfs inode and the backing cache
+ *
+ * NOTE: it only serves no-index type
+ */
+int __fscache_check_consistency(struct fscache_cookie *cookie)
+{
+	struct fscache_operation *op;
+	struct fscache_object *object;
+	int ret;
+
+	_enter("%p,", cookie);
+
+	ASSERTCMP(cookie->def->type, ==, FSCACHE_COOKIE_TYPE_DATAFILE);
+
+	if (fscache_wait_for_deferred_lookup(cookie) < 0)
+		return -ERESTARTSYS;
+
+	if (hlist_empty(&cookie->backing_objects))
+		return 0;
+
+	op = kzalloc(sizeof(*op), GFP_NOIO | __GFP_NOMEMALLOC | __GFP_NORETRY);
+	if (!op)
+		return -ENOMEM;
+
+	fscache_operation_init(op, NULL, NULL);
+	op->flags = FSCACHE_OP_MYTHREAD |
+		(1 << FSCACHE_OP_WAITING);
+
+	spin_lock(&cookie->lock);
+
+	if (hlist_empty(&cookie->backing_objects))
+		goto inconsistent;
+	object = hlist_entry(cookie->backing_objects.first,
+			     struct fscache_object, cookie_link);
+	if (test_bit(FSCACHE_IOERROR, &object->cache->flags))
+		goto inconsistent;
+
+	op->debug_id = atomic_inc_return(&fscache_op_debug_id);
+
+	atomic_inc(&cookie->n_active);
+	if (fscache_submit_op(object, op) < 0)
+		goto submit_failed;
+
+	/* the work queue now carries its own ref on the object */
+	spin_unlock(&cookie->lock);
+
+	ret = fscache_wait_for_operation_activation(object, op,
+						    NULL, NULL, NULL);
+	if (ret == 0) {
+		/* ask the cache to honour the operation */
+		ret = object->cache->ops->check_consistency(op);
+		fscache_op_complete(op, false);
+	} else if (ret == -ENOBUFS) {
+		ret = 0;
+	}
+
+	fscache_put_operation(op);
+	_leave(" = %d", ret);
+	return ret;
+
+submit_failed:
+	atomic_dec(&cookie->n_active);
+inconsistent:
+	spin_unlock(&cookie->lock);
+	kfree(op);
+	_leave(" = -ESTALE");
+	return -ESTALE;
+}
+EXPORT_SYMBOL(__fscache_check_consistency);

commit 1362729b169b7903c7e739dbe7904994b0d8c47f
Author: David Howells <dhowells@redhat.com>
Date:   Fri May 10 19:50:26 2013 +0100

    FS-Cache: Simplify cookie retention for fscache_objects, fixing oops
    
    Simplify the way fscache cache objects retain their cookie.  The way I
    implemented the cookie storage handling made synchronisation a pain (ie. the
    object state machine can't rely on the cookie actually still being there).
    
    Instead of the the object being detached from the cookie and the cookie being
    freed in __fscache_relinquish_cookie(), we defer both operations:
    
     (*) The detachment of the object from the list in the cookie now takes place
         in fscache_drop_object() and is thus governed by the object state machine
         (fscache_detach_from_cookie() has been removed).
    
     (*) The release of the cookie is now in fscache_object_destroy() - which is
         called by the cache backend just before it frees the object.
    
    This means that the fscache_cookie struct is now available to the cache all the
    way through from ->alloc_object() to ->drop_object() and ->put_object() -
    meaning that it's no longer necessary to take object->lock to guarantee access.
    
    However, __fscache_relinquish_cookie() doesn't wait for the object to go all
    the way through to destruction before letting the netfs proceed.  That would
    massively slow down the netfs.  Since __fscache_relinquish_cookie() leaves the
    cookie around, in must therefore break all attachments to the netfs - which
    includes ->def, ->netfs_data and any outstanding page read/writes.
    
    To handle this, struct fscache_cookie now has an n_active counter:
    
     (1) This starts off initialised to 1.
    
     (2) Any time the cache needs to get at the netfs data, it calls
         fscache_use_cookie() to increment it - if it is not zero.  If it was zero,
         then access is not permitted.
    
     (3) When the cache has finished with the data, it calls fscache_unuse_cookie()
         to decrement it.  This does a wake-up on it if it reaches 0.
    
     (4) __fscache_relinquish_cookie() decrements n_active and then waits for it to
         reach 0.  The initialisation to 1 in step (1) ensures that we only get
         wake ups when we're trying to get rid of the cookie.
    
    This leaves __fscache_relinquish_cookie() a lot simpler.
    
    
    ***
    This fixes a problem in the current code whereby if fscache_invalidate() is
    followed sufficiently quickly by fscache_relinquish_cookie() then it is
    possible for __fscache_relinquish_cookie() to have detached the cookie from the
    object and cleared the pointer before a thread is dispatched to process the
    invalidation state in the object state machine.
    
    Since the pending write clearance was deferred to the invalidation state to
    make it asynchronous, we need to either wait in relinquishment for the stores
    tree to be cleared in the invalidation state or we need to handle the clearance
    in relinquishment.
    
    Further, if the relinquishment code does clear the tree, then the invalidation
    state need to make the clearance contingent on still having the cookie to hand
    (since that's where the tree is rooted) and we have to prevent the cookie from
    disappearing for the duration.
    
    This can lead to an oops like the following:
    
    BUG: unable to handle kernel NULL pointer dereference at 000000000000000c
    ...
    RIP: 0010:[<ffffffff8151023e>] _spin_lock+0xe/0x30
    ...
    CR2: 000000000000000c ...
    ...
    Process kslowd002 (...)
    ....
    Call Trace:
     [<ffffffffa01c3278>] fscache_invalidate_writes+0x38/0xd0 [fscache]
     [<ffffffff810096f0>] ? __switch_to+0xd0/0x320
     [<ffffffff8105e759>] ? find_busiest_queue+0x69/0x150
     [<ffffffff8110ddd4>] ? slow_work_enqueue+0x104/0x180
     [<ffffffffa01c1303>] fscache_object_slow_work_execute+0x5e3/0x9d0 [fscache]
     [<ffffffff81096b67>] ? bit_waitqueue+0x17/0xd0
     [<ffffffff8110e233>] slow_work_execute+0x233/0x310
     [<ffffffff8110e515>] slow_work_thread+0x205/0x360
     [<ffffffff81096ca0>] ? autoremove_wake_function+0x0/0x40
     [<ffffffff8110e310>] ? slow_work_thread+0x0/0x360
     [<ffffffff81096936>] kthread+0x96/0xa0
     [<ffffffff8100c0ca>] child_rip+0xa/0x20
     [<ffffffff810968a0>] ? kthread+0x0/0xa0
     [<ffffffff8100c0c0>] ? child_rip+0x0/0x20
    
    The parameter to fscache_invalidate_writes() was object->cookie which is NULL.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-By: Milosz Tanski <milosz@adfin.com>
    Acked-by: Jeff Layton <jlayton@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index eee436646989..0e91a3c9fdb2 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -95,6 +95,11 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	atomic_set(&cookie->usage, 1);
 	atomic_set(&cookie->n_children, 0);
 
+	/* We keep the active count elevated until relinquishment to prevent an
+	 * attempt to wake up every time the object operations queue quiesces.
+	 */
+	atomic_set(&cookie->n_active, 1);
+
 	atomic_inc(&parent->usage);
 	atomic_inc(&parent->n_children);
 
@@ -177,7 +182,6 @@ static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie)
 
 	cookie->flags =
 		(1 << FSCACHE_COOKIE_LOOKING_UP) |
-		(1 << FSCACHE_COOKIE_CREATING) |
 		(1 << FSCACHE_COOKIE_NO_DATA_YET);
 
 	/* ask the cache to allocate objects for this cookie and its parent
@@ -467,7 +471,6 @@ EXPORT_SYMBOL(__fscache_update_cookie);
  */
 void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 {
-	struct fscache_cache *cache;
 	struct fscache_object *object;
 
 	fscache_stat(&fscache_n_relinquishes);
@@ -480,8 +483,11 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 		return;
 	}
 
-	_enter("%p{%s,%p},%d",
-	       cookie, cookie->def->name, cookie->netfs_data, retire);
+	_enter("%p{%s,%p,%d},%d",
+	       cookie, cookie->def->name, cookie->netfs_data,
+	       atomic_read(&cookie->n_active), retire);
+
+	ASSERTCMP(atomic_read(&cookie->n_active), >, 0);
 
 	if (atomic_read(&cookie->n_children) != 0) {
 		printk(KERN_ERR "FS-Cache: Cookie '%s' still has children\n",
@@ -489,62 +495,28 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 		BUG();
 	}
 
-	/* wait for the cookie to finish being instantiated (or to fail) */
-	if (test_bit(FSCACHE_COOKIE_CREATING, &cookie->flags)) {
-		fscache_stat(&fscache_n_relinquishes_waitcrt);
-		wait_on_bit(&cookie->flags, FSCACHE_COOKIE_CREATING,
-			    fscache_wait_bit, TASK_UNINTERRUPTIBLE);
-	}
+	/* No further netfs-accessing operations on this cookie permitted */
+	set_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags);
+	if (retire)
+		set_bit(FSCACHE_COOKIE_RETIRED, &cookie->flags);
 
-try_again:
 	spin_lock(&cookie->lock);
-
-	/* break links with all the active objects */
-	while (!hlist_empty(&cookie->backing_objects)) {
-		int n_reads;
-		object = hlist_entry(cookie->backing_objects.first,
-				     struct fscache_object,
-				     cookie_link);
-
-		_debug("RELEASE OBJ%x", object->debug_id);
-
-		set_bit(FSCACHE_COOKIE_WAITING_ON_READS, &cookie->flags);
-		n_reads = atomic_read(&object->n_reads);
-		if (n_reads) {
-			int n_ops = object->n_ops;
-			int n_in_progress = object->n_in_progress;
-			spin_unlock(&cookie->lock);
-			printk(KERN_ERR "FS-Cache:"
-			       " Cookie '%s' still has %d outstanding reads (%d,%d)\n",
-			       cookie->def->name,
-			       n_reads, n_ops, n_in_progress);
-			wait_on_bit(&cookie->flags, FSCACHE_COOKIE_WAITING_ON_READS,
-				    fscache_wait_bit, TASK_UNINTERRUPTIBLE);
-			printk("Wait finished\n");
-			goto try_again;
-		}
-
-		/* detach each cache object from the object cookie */
-		spin_lock(&object->lock);
-		hlist_del_init(&object->cookie_link);
-
-		cache = object->cache;
-		object->cookie = NULL;
-		if (retire)
-			set_bit(FSCACHE_OBJECT_RETIRE, &object->flags);
+	hlist_for_each_entry(object, &cookie->backing_objects, cookie_link) {
 		fscache_raise_event(object, FSCACHE_OBJECT_EV_KILL);
-		spin_unlock(&object->lock);
-
-		if (atomic_dec_and_test(&cookie->usage))
-			/* the cookie refcount shouldn't be reduced to 0 yet */
-			BUG();
 	}
+	spin_unlock(&cookie->lock);
 
-	/* detach pointers back to the netfs */
+	/* Wait for cessation of activity requiring access to the netfs (when
+	 * n_active reaches 0).
+	 */
+	if (!atomic_dec_and_test(&cookie->n_active))
+		wait_on_atomic_t(&cookie->n_active, fscache_wait_atomic_t,
+				 TASK_UNINTERRUPTIBLE);
+
+	/* Clear pointers back to the netfs */
 	cookie->netfs_data	= NULL;
 	cookie->def		= NULL;
-
-	spin_unlock(&cookie->lock);
+	BUG_ON(cookie->stores.rnode);
 
 	if (cookie->parent) {
 		ASSERTCMP(atomic_read(&cookie->parent->usage), >, 0);
@@ -552,7 +524,7 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 		atomic_dec(&cookie->parent->n_children);
 	}
 
-	/* finally dispose of the cookie */
+	/* Dispose of the netfs's link to the cookie */
 	ASSERTCMP(atomic_read(&cookie->usage), >, 0);
 	fscache_cookie_put(cookie);
 

commit caaef6900befb45689b1d1831ce3c7e7fb5b504f
Author: David Howells <dhowells@redhat.com>
Date:   Fri May 10 19:50:26 2013 +0100

    FS-Cache: Fix object state machine to have separate work and wait states
    
    Fix object state machine to have separate work and wait states as that makes
    it easier to envision.
    
    There are now three kinds of state:
    
     (1) Work state.  This is an execution state.  No event processing is performed
         by a work state.  The function attached to a work state returns a pointer
         indicating the next state to which the OSM should transition.  Returning
         NO_TRANSIT repeats the current state, but goes back to the scheduler
         first.
    
     (2) Wait state.  This is an event processing state.  No execution is
         performed by a wait state.  Wait states are just tables of "if event X
         occurs, clear it and transition to state Y".  The dispatcher returns to
         the scheduler if none of the events in which the wait state has an
         interest are currently pending.
    
     (3) Out-of-band state.  This is a special work state.  Transitions to normal
         states can be overridden when an unexpected event occurs (eg. I/O error).
         Instead the dispatcher disables and clears the OOB event and transits to
         the specified work state.  This then acts as an ordinary work state,
         though object->state points to the overridden destination.  Returning
         NO_TRANSIT resumes the overridden transition.
    
    In addition, the states have names in their definitions, so there's no need for
    tables of state names.  Further, the EV_REQUEUE event is no longer necessary as
    that is automatic for work states.
    
    Since the states are now separate structs rather than values in an enum, it's
    not possible to use comparisons other than (non-)equality between them, so use
    some object->flags to indicate what phase an object is in.
    
    The EV_RELEASE, EV_RETIRE and EV_WITHDRAW events have been squished into one
    (EV_KILL).  An object flag now carries the information about retirement.
    
    Similarly, the RELEASING, RECYCLING and WITHDRAWING states have been merged
    into an KILL_OBJECT state and additional states have been added for handling
    waiting dependent objects (JUMPSTART_DEPS and KILL_DEPENDENTS).
    
    A state has also been added for synchronising with parent object initialisation
    (WAIT_FOR_PARENT) and another for initiating look up (PARENT_READY).
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-By: Milosz Tanski <milosz@adfin.com>
    Acked-by: Jeff Layton <jlayton@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index a5f36c921e91..eee436646989 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -205,7 +205,7 @@ static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie)
 
 	/* initiate the process of looking up all the objects in the chain
 	 * (done by fscache_initialise_object()) */
-	fscache_enqueue_object(object);
+	fscache_raise_event(object, FSCACHE_OBJECT_EV_NEW_CHILD);
 
 	spin_unlock(&cookie->lock);
 
@@ -469,7 +469,6 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 {
 	struct fscache_cache *cache;
 	struct fscache_object *object;
-	unsigned long event;
 
 	fscache_stat(&fscache_n_relinquishes);
 	if (retire)
@@ -497,8 +496,6 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 			    fscache_wait_bit, TASK_UNINTERRUPTIBLE);
 	}
 
-	event = retire ? FSCACHE_OBJECT_EV_RETIRE : FSCACHE_OBJECT_EV_RELEASE;
-
 try_again:
 	spin_lock(&cookie->lock);
 
@@ -533,7 +530,9 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 
 		cache = object->cache;
 		object->cookie = NULL;
-		fscache_raise_event(object, event);
+		if (retire)
+			set_bit(FSCACHE_OBJECT_RETIRE, &object->flags);
+		fscache_raise_event(object, FSCACHE_OBJECT_EV_KILL);
 		spin_unlock(&object->lock);
 
 		if (atomic_dec_and_test(&cookie->usage))

commit 493f7bc11457bc1f6fbf25a4b2bdf215ebaf050f
Author: David Howells <dhowells@redhat.com>
Date:   Fri May 10 19:50:26 2013 +0100

    FS-Cache: Wrap checks on object state
    
    Wrap checks on object state (mostly outside of fs/fscache/object.c) with
    inline functions so that the mechanism can be replaced.
    
    Some of the state checks within object.c are left as-is as they will be
    replaced.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-By: Milosz Tanski <milosz@adfin.com>
    Acked-by: Jeff Layton <jlayton@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index e2cba1f60c21..a5f36c921e91 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -285,7 +285,7 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 
 object_already_extant:
 	ret = -ENOBUFS;
-	if (object->state >= FSCACHE_OBJECT_DYING) {
+	if (fscache_object_is_dead(object)) {
 		spin_unlock(&cookie->lock);
 		goto error;
 	}
@@ -321,7 +321,7 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 	ret = -EEXIST;
 	hlist_for_each_entry(p, &cookie->backing_objects, cookie_link) {
 		if (p->cache == object->cache) {
-			if (p->state >= FSCACHE_OBJECT_DYING)
+			if (fscache_object_is_dying(p))
 				ret = -ENOBUFS;
 			goto cant_attach_object;
 		}
@@ -332,7 +332,7 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 	hlist_for_each_entry(p, &cookie->parent->backing_objects,
 			     cookie_link) {
 		if (p->cache == object->cache) {
-			if (p->state >= FSCACHE_OBJECT_DYING) {
+			if (fscache_object_is_dying(p)) {
 				ret = -ENOBUFS;
 				spin_unlock(&cookie->parent->lock);
 				goto cant_attach_object;
@@ -400,7 +400,7 @@ void __fscache_invalidate(struct fscache_cookie *cookie)
 			object = hlist_entry(cookie->backing_objects.first,
 					     struct fscache_object,
 					     cookie_link);
-			if (object->state < FSCACHE_OBJECT_DYING)
+			if (fscache_object_is_live(object))
 				fscache_raise_event(
 					object, FSCACHE_OBJECT_EV_INVALIDATE);
 		}

commit b67bfe0d42cac56c512dd5da4b1b347a23f4b70a
Author: Sasha Levin <sasha.levin@oracle.com>
Date:   Wed Feb 27 17:06:00 2013 -0800

    hlist: drop the node parameter from iterators
    
    I'm not sure why, but the hlist for each entry iterators were conceived
    
            list_for_each_entry(pos, head, member)
    
    The hlist ones were greedy and wanted an extra parameter:
    
            hlist_for_each_entry(tpos, pos, head, member)
    
    Why did they need an extra pos parameter? I'm not quite sure. Not only
    they don't really need it, it also prevents the iterator from looking
    exactly like the list iterator, which is unfortunate.
    
    Besides the semantic patch, there was some manual work required:
    
     - Fix up the actual hlist iterators in linux/list.h
     - Fix up the declaration of other iterators based on the hlist ones.
     - A very small amount of places were using the 'node' parameter, this
     was modified to use 'obj->member' instead.
     - Coccinelle didn't handle the hlist_for_each_entry_safe iterator
     properly, so those had to be fixed up manually.
    
    The semantic patch which is mostly the work of Peter Senna Tschudin is here:
    
    @@
    iterator name hlist_for_each_entry, hlist_for_each_entry_continue, hlist_for_each_entry_from, hlist_for_each_entry_rcu, hlist_for_each_entry_rcu_bh, hlist_for_each_entry_continue_rcu_bh, for_each_busy_worker, ax25_uid_for_each, ax25_for_each, inet_bind_bucket_for_each, sctp_for_each_hentry, sk_for_each, sk_for_each_rcu, sk_for_each_from, sk_for_each_safe, sk_for_each_bound, hlist_for_each_entry_safe, hlist_for_each_entry_continue_rcu, nr_neigh_for_each, nr_neigh_for_each_safe, nr_node_for_each, nr_node_for_each_safe, for_each_gfn_indirect_valid_sp, for_each_gfn_sp, for_each_host;
    
    type T;
    expression a,c,d,e;
    identifier b;
    statement S;
    @@
    
    -T b;
        <+... when != b
    (
    hlist_for_each_entry(a,
    - b,
    c, d) S
    |
    hlist_for_each_entry_continue(a,
    - b,
    c) S
    |
    hlist_for_each_entry_from(a,
    - b,
    c) S
    |
    hlist_for_each_entry_rcu(a,
    - b,
    c, d) S
    |
    hlist_for_each_entry_rcu_bh(a,
    - b,
    c, d) S
    |
    hlist_for_each_entry_continue_rcu_bh(a,
    - b,
    c) S
    |
    for_each_busy_worker(a, c,
    - b,
    d) S
    |
    ax25_uid_for_each(a,
    - b,
    c) S
    |
    ax25_for_each(a,
    - b,
    c) S
    |
    inet_bind_bucket_for_each(a,
    - b,
    c) S
    |
    sctp_for_each_hentry(a,
    - b,
    c) S
    |
    sk_for_each(a,
    - b,
    c) S
    |
    sk_for_each_rcu(a,
    - b,
    c) S
    |
    sk_for_each_from
    -(a, b)
    +(a)
    S
    + sk_for_each_from(a) S
    |
    sk_for_each_safe(a,
    - b,
    c, d) S
    |
    sk_for_each_bound(a,
    - b,
    c) S
    |
    hlist_for_each_entry_safe(a,
    - b,
    c, d, e) S
    |
    hlist_for_each_entry_continue_rcu(a,
    - b,
    c) S
    |
    nr_neigh_for_each(a,
    - b,
    c) S
    |
    nr_neigh_for_each_safe(a,
    - b,
    c, d) S
    |
    nr_node_for_each(a,
    - b,
    c) S
    |
    nr_node_for_each_safe(a,
    - b,
    c, d) S
    |
    - for_each_gfn_sp(a, c, d, b) S
    + for_each_gfn_sp(a, c, d) S
    |
    - for_each_gfn_indirect_valid_sp(a, c, d, b) S
    + for_each_gfn_indirect_valid_sp(a, c, d) S
    |
    for_each_host(a,
    - b,
    c) S
    |
    for_each_host_safe(a,
    - b,
    c, d) S
    |
    for_each_mesh_entry(a,
    - b,
    c, d) S
    )
        ...+>
    
    [akpm@linux-foundation.org: drop bogus change from net/ipv4/raw.c]
    [akpm@linux-foundation.org: drop bogus hunk from net/ipv6/raw.c]
    [akpm@linux-foundation.org: checkpatch fixes]
    [akpm@linux-foundation.org: fix warnings]
    [akpm@linux-foudnation.org: redo intrusive kvm changes]
    Tested-by: Peter Senna Tschudin <peter.senna@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
    Cc: Wu Fengguang <fengguang.wu@intel.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Gleb Natapov <gleb@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 8dcb114758e3..e2cba1f60c21 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -237,13 +237,12 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 				struct fscache_cookie *cookie)
 {
 	struct fscache_object *object;
-	struct hlist_node *_n;
 	int ret;
 
 	_enter("%p,%p{%s}", cache, cookie, cookie->def->name);
 
 	spin_lock(&cookie->lock);
-	hlist_for_each_entry(object, _n, &cookie->backing_objects,
+	hlist_for_each_entry(object, &cookie->backing_objects,
 			     cookie_link) {
 		if (object->cache == cache)
 			goto object_already_extant;
@@ -311,7 +310,6 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 {
 	struct fscache_object *p;
 	struct fscache_cache *cache = object->cache;
-	struct hlist_node *_n;
 	int ret;
 
 	_enter("{%s},{OBJ%x}", cookie->def->name, object->debug_id);
@@ -321,7 +319,7 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 	/* there may be multiple initial creations of this object, but we only
 	 * want one */
 	ret = -EEXIST;
-	hlist_for_each_entry(p, _n, &cookie->backing_objects, cookie_link) {
+	hlist_for_each_entry(p, &cookie->backing_objects, cookie_link) {
 		if (p->cache == object->cache) {
 			if (p->state >= FSCACHE_OBJECT_DYING)
 				ret = -ENOBUFS;
@@ -331,7 +329,7 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 
 	/* pin the parent object */
 	spin_lock_nested(&cookie->parent->lock, 1);
-	hlist_for_each_entry(p, _n, &cookie->parent->backing_objects,
+	hlist_for_each_entry(p, &cookie->parent->backing_objects,
 			     cookie_link) {
 		if (p->cache == object->cache) {
 			if (p->state >= FSCACHE_OBJECT_DYING) {
@@ -435,7 +433,6 @@ EXPORT_SYMBOL(__fscache_wait_on_invalidate);
 void __fscache_update_cookie(struct fscache_cookie *cookie)
 {
 	struct fscache_object *object;
-	struct hlist_node *_p;
 
 	fscache_stat(&fscache_n_updates);
 
@@ -452,7 +449,7 @@ void __fscache_update_cookie(struct fscache_cookie *cookie)
 	spin_lock(&cookie->lock);
 
 	/* update the index entry on disk in each cache backing this cookie */
-	hlist_for_each_entry(object, _p,
+	hlist_for_each_entry(object,
 			     &cookie->backing_objects, cookie_link) {
 		fscache_raise_event(object, FSCACHE_OBJECT_EV_UPDATE);
 	}

commit ef778e7ae67cd426c30cad43378b908f5eb0bad5
Author: David Howells <dhowells@redhat.com>
Date:   Thu Dec 20 21:52:36 2012 +0000

    FS-Cache: Provide proper invalidation
    
    Provide a proper invalidation method rather than relying on the netfs retiring
    the cookie it has and getting a new one.  The problem with this is that isn't
    easy for the netfs to make sure that it has completed/cancelled all its
    outstanding storage and retrieval operations on the cookie it is retiring.
    
    Instead, have the cache provide an invalidation method that will cancel or wait
    for all currently outstanding operations before invalidating the cache, and
    will cause new operations to queue up behind that.  Whilst invalidation is in
    progress, some requests will be rejected until the cache can stack a barrier on
    the operation queue to cause new operations to be deferred behind it.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 66be9eccede0..8dcb114758e3 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -369,6 +369,66 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 	return ret;
 }
 
+/*
+ * Invalidate an object.  Callable with spinlocks held.
+ */
+void __fscache_invalidate(struct fscache_cookie *cookie)
+{
+	struct fscache_object *object;
+
+	_enter("{%s}", cookie->def->name);
+
+	fscache_stat(&fscache_n_invalidates);
+
+	/* Only permit invalidation of data files.  Invalidating an index will
+	 * require the caller to release all its attachments to the tree rooted
+	 * there, and if it's doing that, it may as well just retire the
+	 * cookie.
+	 */
+	ASSERTCMP(cookie->def->type, ==, FSCACHE_COOKIE_TYPE_DATAFILE);
+
+	/* We will be updating the cookie too. */
+	BUG_ON(!cookie->def->get_aux);
+
+	/* If there's an object, we tell the object state machine to handle the
+	 * invalidation on our behalf, otherwise there's nothing to do.
+	 */
+	if (!hlist_empty(&cookie->backing_objects)) {
+		spin_lock(&cookie->lock);
+
+		if (!hlist_empty(&cookie->backing_objects) &&
+		    !test_and_set_bit(FSCACHE_COOKIE_INVALIDATING,
+				      &cookie->flags)) {
+			object = hlist_entry(cookie->backing_objects.first,
+					     struct fscache_object,
+					     cookie_link);
+			if (object->state < FSCACHE_OBJECT_DYING)
+				fscache_raise_event(
+					object, FSCACHE_OBJECT_EV_INVALIDATE);
+		}
+
+		spin_unlock(&cookie->lock);
+	}
+
+	_leave("");
+}
+EXPORT_SYMBOL(__fscache_invalidate);
+
+/*
+ * Wait for object invalidation to complete.
+ */
+void __fscache_wait_on_invalidate(struct fscache_cookie *cookie)
+{
+	_enter("%p", cookie);
+
+	wait_on_bit(&cookie->flags, FSCACHE_COOKIE_INVALIDATING,
+		    fscache_wait_bit_interruptible,
+		    TASK_UNINTERRUPTIBLE);
+
+	_leave("");
+}
+EXPORT_SYMBOL(__fscache_wait_on_invalidate);
+
 /*
  * update the index entries backing a cookie
  */

commit ef46ed888efb1e8da33be5d33c9b54476289a43b
Author: David Howells <dhowells@redhat.com>
Date:   Thu Dec 20 21:52:35 2012 +0000

    FS-Cache: Make cookie relinquishment wait for outstanding reads
    
    Make fscache_relinquish_cookie() log a warning and wait if there are any
    outstanding reads left on the cookie it was given.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 0666996adf80..66be9eccede0 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -442,22 +442,32 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 
 	event = retire ? FSCACHE_OBJECT_EV_RETIRE : FSCACHE_OBJECT_EV_RELEASE;
 
+try_again:
 	spin_lock(&cookie->lock);
 
 	/* break links with all the active objects */
 	while (!hlist_empty(&cookie->backing_objects)) {
+		int n_reads;
 		object = hlist_entry(cookie->backing_objects.first,
 				     struct fscache_object,
 				     cookie_link);
 
 		_debug("RELEASE OBJ%x", object->debug_id);
 
-		if (atomic_read(&object->n_reads)) {
+		set_bit(FSCACHE_COOKIE_WAITING_ON_READS, &cookie->flags);
+		n_reads = atomic_read(&object->n_reads);
+		if (n_reads) {
+			int n_ops = object->n_ops;
+			int n_in_progress = object->n_in_progress;
 			spin_unlock(&cookie->lock);
 			printk(KERN_ERR "FS-Cache:"
-			       " Cookie '%s' still has %d outstanding reads\n",
-			       cookie->def->name, atomic_read(&object->n_reads));
-			BUG();
+			       " Cookie '%s' still has %d outstanding reads (%d,%d)\n",
+			       cookie->def->name,
+			       n_reads, n_ops, n_in_progress);
+			wait_on_bit(&cookie->flags, FSCACHE_COOKIE_WAITING_ON_READS,
+				    fscache_wait_bit, TASK_UNINTERRUPTIBLE);
+			printk("Wait finished\n");
+			goto try_again;
 		}
 
 		/* detach each cache object from the object cookie */

commit 0f972b5696c0a0677a9b3a18fee45cc0e8de4184
Author: David Howells <dhowells@redhat.com>
Date:   Thu Dec 20 21:52:33 2012 +0000

    FS-Cache: Check that there are no read ops when cookie relinquished
    
    Check that the netfs isn't trying to relinquish a cookie that still has read
    operations in progress upon it.  If there are, then give log a warning and BUG.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 990535071a8a..0666996adf80 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -452,6 +452,14 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 
 		_debug("RELEASE OBJ%x", object->debug_id);
 
+		if (atomic_read(&object->n_reads)) {
+			spin_unlock(&cookie->lock);
+			printk(KERN_ERR "FS-Cache:"
+			       " Cookie '%s' still has %d outstanding reads\n",
+			       cookie->def->name, atomic_read(&object->n_reads));
+			BUG();
+		}
+
 		/* detach each cache object from the object cookie */
 		spin_lock(&object->lock);
 		hlist_del_init(&object->cookie_link);

commit 2175bb06dc6cf2af9c098a1770561f9e63edae4e
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:38 2009 +0000

    FS-Cache: Add a retirement stat counter
    
    Add a stat counter to count retirement events rather than ordinary release
    events (the retire argument to fscache_relinquish_cookie()).
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index f979659c1b3f..990535071a8a 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -415,6 +415,8 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 	unsigned long event;
 
 	fscache_stat(&fscache_n_relinquishes);
+	if (retire)
+		fscache_stat(&fscache_n_relinquishes_retire);
 
 	if (!cookie) {
 		fscache_stat(&fscache_n_relinquishes_null);

commit 1bccf513ac49d44604ba1cddcc29f5886e70f1b6
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:25 2009 +0000

    FS-Cache: Fix lock misorder in fscache_write_op()
    
    FS-Cache has two structs internally for keeping track of the internal state of
    a cached file: the fscache_cookie struct, which represents the netfs's state,
    and fscache_object struct, which represents the cache's state.  Each has a
    pointer that points to the other (when both are in existence), and each has a
    spinlock for pointer maintenance.
    
    Since netfs operations approach these structures from the cookie side, they get
    the cookie lock first, then the object lock.  Cache operations, on the other
    hand, approach from the object side, and get the object lock first.  It is not
    then permitted for a cache operation to get the cookie lock whilst it is
    holding the object lock lest deadlock occur; instead, it must do one of two
    things:
    
     (1) increment the cookie usage counter, drop the object lock and then get both
         locks in order, or
    
     (2) simply hold the object lock as certain parts of the cookie may not be
         altered whilst the object lock is held.
    
    It is also not permitted to follow either pointer without holding the lock at
    the end you start with.  To break the pointers between the cookie and the
    object, both locks must be held.
    
    fscache_write_op(), however, violates the locking rules: It attempts to get the
    cookie lock without (a) checking that the cookie pointer is a valid pointer,
    and (b) holding the object lock to protect the cookie pointer whilst it follows
    it.  This is so that it can access the pending page store tree without
    interference from __fscache_write_page().
    
    This is fixed by splitting the cookie lock, such that the page store tracking
    tree is protected by its own lock, and checking that the cookie pointer is
    non-NULL before we attempt to follow it whilst holding the object lock.
    
    The new lock is subordinate to both the cookie lock and the object lock, and so
    should be taken after those.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index e6854f5222f5..f979659c1b3f 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -36,6 +36,7 @@ void fscache_cookie_init_once(void *_cookie)
 
 	memset(cookie, 0, sizeof(*cookie));
 	spin_lock_init(&cookie->lock);
+	spin_lock_init(&cookie->stores_lock);
 	INIT_HLIST_HEAD(&cookie->backing_objects);
 }
 

commit b34df792b4e9e311db47fad27949095d0629c197
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:14 2009 +0000

    FS-Cache: Use radix tree preload correctly in tracking of pages to be stored
    
    __fscache_write_page() attempts to load the radix tree preallocation pool for
    the CPU it is on before calling radix_tree_insert(), as the insertion must be
    done inside a pair of spinlocks.
    
    Use of the preallocation pool, however, is contingent on the radix tree being
    initialised without __GFP_WAIT specified.  __fscache_acquire_cookie() was
    passing GFP_NOFS to INIT_RADIX_TREE() - but that includes __GFP_WAIT.
    
    The solution is to AND out __GFP_WAIT.
    
    Additionally, the banner comment to radix_tree_preload() is altered to make
    note of this prerequisite.  Possibly there should be a WARN_ON() too.
    
    Without this fix, I have seen the following recursive deadlock caused by
    radix_tree_insert() attempting to allocate memory inside the spinlocked
    region, which resulted in FS-Cache being called back into to release memory -
    which required the spinlock already held.
    
    =============================================
    [ INFO: possible recursive locking detected ]
    2.6.32-rc6-cachefs #24
    ---------------------------------------------
    nfsiod/7916 is trying to acquire lock:
     (&cookie->lock){+.+.-.}, at: [<ffffffffa0076872>] __fscache_uncache_page+0xdb/0x160 [fscache]
    
    but task is already holding lock:
     (&cookie->lock){+.+.-.}, at: [<ffffffffa0076acc>] __fscache_write_page+0x15c/0x3f3 [fscache]
    
    other info that might help us debug this:
    5 locks held by nfsiod/7916:
     #0:  (nfsiod){+.+.+.}, at: [<ffffffff81048290>] worker_thread+0x19a/0x2e2
     #1:  (&task->u.tk_work#2){+.+.+.}, at: [<ffffffff81048290>] worker_thread+0x19a/0x2e2
     #2:  (&cookie->lock){+.+.-.}, at: [<ffffffffa0076acc>] __fscache_write_page+0x15c/0x3f3 [fscache]
     #3:  (&object->lock#2){+.+.-.}, at: [<ffffffffa0076b07>] __fscache_write_page+0x197/0x3f3 [fscache]
     #4:  (&cookie->stores_lock){+.+...}, at: [<ffffffffa0076b0f>] __fscache_write_page+0x19f/0x3f3 [fscache]
    
    stack backtrace:
    Pid: 7916, comm: nfsiod Not tainted 2.6.32-rc6-cachefs #24
    Call Trace:
     [<ffffffff8105ac7f>] __lock_acquire+0x1649/0x16e3
     [<ffffffff81059ded>] ? __lock_acquire+0x7b7/0x16e3
     [<ffffffff8100e27d>] ? dump_trace+0x248/0x257
     [<ffffffff8105ad70>] lock_acquire+0x57/0x6d
     [<ffffffffa0076872>] ? __fscache_uncache_page+0xdb/0x160 [fscache]
     [<ffffffff8135467c>] _spin_lock+0x2c/0x3b
     [<ffffffffa0076872>] ? __fscache_uncache_page+0xdb/0x160 [fscache]
     [<ffffffffa0076872>] __fscache_uncache_page+0xdb/0x160 [fscache]
     [<ffffffffa0077eb7>] ? __fscache_check_page_write+0x0/0x71 [fscache]
     [<ffffffffa00b4755>] nfs_fscache_release_page+0x86/0xc4 [nfs]
     [<ffffffffa00907f0>] nfs_release_page+0x3c/0x41 [nfs]
     [<ffffffff81087ffb>] try_to_release_page+0x32/0x3b
     [<ffffffff81092c2b>] shrink_page_list+0x316/0x4ac
     [<ffffffff81058a9b>] ? mark_held_locks+0x52/0x70
     [<ffffffff8135451b>] ? _spin_unlock_irq+0x2b/0x31
     [<ffffffff81093153>] shrink_inactive_list+0x392/0x67c
     [<ffffffff81058a9b>] ? mark_held_locks+0x52/0x70
     [<ffffffff810934ca>] shrink_list+0x8d/0x8f
     [<ffffffff81093744>] shrink_zone+0x278/0x33c
     [<ffffffff81052c70>] ? ktime_get_ts+0xad/0xba
     [<ffffffff8109453b>] try_to_free_pages+0x22e/0x392
     [<ffffffff8109184c>] ? isolate_pages_global+0x0/0x212
     [<ffffffff8108e16b>] __alloc_pages_nodemask+0x3dc/0x5cf
     [<ffffffff810ae24a>] cache_alloc_refill+0x34d/0x6c1
     [<ffffffff811bcf74>] ? radix_tree_node_alloc+0x52/0x5c
     [<ffffffff810ae929>] kmem_cache_alloc+0xb2/0x118
     [<ffffffff811bcf74>] radix_tree_node_alloc+0x52/0x5c
     [<ffffffff811bcfd5>] radix_tree_insert+0x57/0x19c
     [<ffffffffa0076b53>] __fscache_write_page+0x1e3/0x3f3 [fscache]
     [<ffffffffa00b4248>] __nfs_readpage_to_fscache+0x58/0x11e [nfs]
     [<ffffffffa009bb77>] nfs_readpage_release+0x34/0x9b [nfs]
     [<ffffffffa009c0d9>] nfs_readpage_release_full+0x32/0x4b [nfs]
     [<ffffffffa0006cff>] rpc_release_calldata+0x12/0x14 [sunrpc]
     [<ffffffffa0006e2d>] rpc_free_task+0x59/0x61 [sunrpc]
     [<ffffffffa0006f03>] rpc_async_release+0x10/0x12 [sunrpc]
     [<ffffffff810482e5>] worker_thread+0x1ef/0x2e2
     [<ffffffff81048290>] ? worker_thread+0x19a/0x2e2
     [<ffffffff81352433>] ? thread_return+0x3e/0x101
     [<ffffffffa0006ef3>] ? rpc_async_release+0x0/0x12 [sunrpc]
     [<ffffffff8104bff5>] ? autoremove_wake_function+0x0/0x34
     [<ffffffff81058d25>] ? trace_hardirqs_on+0xd/0xf
     [<ffffffff810480f6>] ? worker_thread+0x0/0x2e2
     [<ffffffff8104bd21>] kthread+0x7a/0x82
     [<ffffffff8100beda>] child_rip+0xa/0x20
     [<ffffffff8100b87c>] ? restore_args+0x0/0x30
     [<ffffffff8104c2b9>] ? add_wait_queue+0x15/0x44
     [<ffffffff8104bca7>] ? kthread+0x0/0x82
     [<ffffffff8100bed0>] ? child_rip+0x0/0x20
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index b1870a6c2cd3..e6854f5222f5 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -102,7 +102,9 @@ struct fscache_cookie *__fscache_acquire_cookie(
 	cookie->netfs_data	= netfs_data;
 	cookie->flags		= 0;
 
-	INIT_RADIX_TREE(&cookie->stores, GFP_NOFS);
+	/* radix tree insertion won't use the preallocation pool unless it's
+	 * told it may not wait */
+	INIT_RADIX_TREE(&cookie->stores, GFP_NOFS & ~__GFP_WAIT);
 
 	switch (cookie->def->type) {
 	case FSCACHE_COOKIE_TYPE_INDEX:

commit 7e311a207d596b9273d811149d6e3e14f05ac4c0
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:11 2009 +0000

    FS-Cache: Clear netfs pointers in cookie after detaching object, not before
    
    Clear the pointers from the fscache_cookie struct to netfs private data after
    clearing the pointer to the cookie from the fscache_object struct and
    releasing the object lock, rather than before.
    
    This allows the netfs private data pointers to be relied on simply by holding
    the object lock, rather than having to hold the cookie lock.  This is makes
    things simpler as the cookie lock has to be taken before the object lock, but
    sometimes the object pointer is all that the code has.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 432482edc738..b1870a6c2cd3 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -437,12 +437,8 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 
 	event = retire ? FSCACHE_OBJECT_EV_RETIRE : FSCACHE_OBJECT_EV_RELEASE;
 
-	/* detach pointers back to the netfs */
 	spin_lock(&cookie->lock);
 
-	cookie->netfs_data	= NULL;
-	cookie->def		= NULL;
-
 	/* break links with all the active objects */
 	while (!hlist_empty(&cookie->backing_objects)) {
 		object = hlist_entry(cookie->backing_objects.first,
@@ -465,6 +461,10 @@ void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
 			BUG();
 	}
 
+	/* detach pointers back to the netfs */
+	cookie->netfs_data	= NULL;
+	cookie->def		= NULL;
+
 	spin_unlock(&cookie->lock);
 
 	if (cookie->parent) {

commit 52bd75fdb135d6133d878ae60c6e7e3f4ebc1cfc
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:08 2009 +0000

    FS-Cache: Add counters for entry/exit to/from cache operation functions
    
    Count entries to and exits from cache operation table functions.  Maintain
    these as a single counter that's added to or removed from as appropriate.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 9b5187328230..432482edc738 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -249,7 +249,9 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 
 	/* ask the cache to allocate an object (we may end up with duplicate
 	 * objects at this stage, but we sort that out later) */
+	fscache_stat(&fscache_n_cop_alloc_object);
 	object = cache->ops->alloc_object(cache, cookie);
+	fscache_stat_d(&fscache_n_cop_alloc_object);
 	if (IS_ERR(object)) {
 		fscache_stat(&fscache_n_object_no_alloc);
 		ret = PTR_ERR(object);
@@ -270,8 +272,11 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 	/* only attach if we managed to allocate all we needed, otherwise
 	 * discard the object we just allocated and instead use the one
 	 * attached to the cookie */
-	if (fscache_attach_object(cookie, object) < 0)
+	if (fscache_attach_object(cookie, object) < 0) {
+		fscache_stat(&fscache_n_cop_put_object);
 		cache->ops->put_object(object);
+		fscache_stat_d(&fscache_n_cop_put_object);
+	}
 
 	_leave(" = 0");
 	return 0;
@@ -287,7 +292,9 @@ static int fscache_alloc_object(struct fscache_cache *cache,
 	return 0;
 
 error_put:
+	fscache_stat(&fscache_n_cop_put_object);
 	cache->ops->put_object(object);
+	fscache_stat_d(&fscache_n_cop_put_object);
 error:
 	_leave(" = %d", ret);
 	return ret;

commit 4fbf4291aa15926cd4fdca0ffe9122e89d0459db
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 19 18:11:04 2009 +0000

    FS-Cache: Allow the current state of all objects to be dumped
    
    Allow the current state of all fscache objects to be dumped by doing:
    
            cat /proc/fs/fscache/objects
    
    By default, all objects and all fields will be shown.  This can be restricted
    by adding a suitable key to one of the caller's keyrings (such as the session
    keyring):
    
            keyctl add user fscache:objlist "<restrictions>" @s
    
    The <restrictions> are:
    
            K       Show hexdump of object key (don't show if not given)
            A       Show hexdump of object aux data (don't show if not given)
    
    And paired restrictions:
    
            C       Show objects that have a cookie
            c       Show objects that don't have a cookie
            B       Show objects that are busy
            b       Show objects that aren't busy
            W       Show objects that have pending writes
            w       Show objects that don't have pending writes
            R       Show objects that have outstanding reads
            r       Show objects that don't have outstanding reads
            S       Show objects that have slow work queued
            s       Show objects that don't have slow work queued
    
    If neither side of a restriction pair is given, then both are implied.  For
    example:
    
            keyctl add user fscache:objlist KB @s
    
    shows objects that are busy, and lists their object keys, but does not dump
    their auxiliary data.  It also implies "CcWwRrSs", but as 'B' is given, 'b' is
    not implied.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 72fd18f6c71f..9b5187328230 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -349,6 +349,8 @@ static int fscache_attach_object(struct fscache_cookie *cookie,
 	object->cookie = cookie;
 	atomic_inc(&cookie->usage);
 	hlist_add_head(&object->cookie_link, &cookie->backing_objects);
+
+	fscache_objlist_add(object);
 	ret = 0;
 
 cant_attach_object:

commit ccc4fc3d11e91477036d1f82bfa2d442f6ce77f0
Author: David Howells <dhowells@redhat.com>
Date:   Fri Apr 3 16:42:38 2009 +0100

    FS-Cache: Implement the cookie management part of the netfs API
    
    Implement the cookie management part of the FS-Cache netfs client API.  The
    documentation and API header file were added in a previous patch.
    
    This patch implements the following three functions:
    
     (1) fscache_acquire_cookie().
    
         Acquire a cookie to represent an object to the netfs.  If the object in
         question is a non-index object, then that object and its parent indices
         will be created on disk at this point if they don't already exist.  Index
         creation is deferred because an index may reside in multiple caches.
    
     (2) fscache_relinquish_cookie().
    
         Retire or release a cookie previously acquired.  At this point, the
         object on disk may be destroyed.
    
     (3) fscache_update_cookie().
    
         Update the in-cache representation of a cookie.  This is used to update
         the auxiliary data for coherency management purposes.
    
    With this patch it is possible to have a netfs instruct a cache backend to
    look up, validate and create metadata on disk and to destroy it again.
    The ability to actually store and retrieve data in the objects so created is
    added in later patches.
    
    Note that these functions will never return an error.  _All_ errors are
    handled internally to FS-Cache.
    
    The worst that can happen is that fscache_acquire_cookie() may return a NULL
    pointer - which is considered a negative cookie pointer and can be passed back
    to any function that takes a cookie without harm.  A negative cookie pointer
    merely suppresses caching at that level.
    
    The stub in linux/fscache.h will detect inline the negative cookie pointer and
    abort the operation as fast as possible.  This means that the compiler doesn't
    have to set up for a call in that case.
    
    See the documentation in Documentation/filesystems/caching/netfs-api.txt for
    more information.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Steve Dickson <steved@redhat.com>
    Acked-by: Trond Myklebust <Trond.Myklebust@netapp.com>
    Acked-by: Al Viro <viro@zeniv.linux.org.uk>
    Tested-by: Daire Byrne <Daire.Byrne@framestore.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
index 47fd75b832e1..72fd18f6c71f 100644
--- a/fs/fscache/cookie.c
+++ b/fs/fscache/cookie.c
@@ -7,6 +7,9 @@
  * modify it under the terms of the GNU General Public License
  * as published by the Free Software Foundation; either version
  * 2 of the License, or (at your option) any later version.
+ *
+ * See Documentation/filesystems/caching/netfs-api.txt for more information on
+ * the netfs API.
  */
 
 #define FSCACHE_DEBUG_LEVEL COOKIE
@@ -16,6 +19,14 @@
 
 struct kmem_cache *fscache_cookie_jar;
 
+static atomic_t fscache_object_debug_id = ATOMIC_INIT(0);
+
+static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie);
+static int fscache_alloc_object(struct fscache_cache *cache,
+				struct fscache_cookie *cookie);
+static int fscache_attach_object(struct fscache_cookie *cookie,
+				 struct fscache_object *object);
+
 /*
  * initialise an cookie jar slab element prior to any use
  */
@@ -28,6 +39,439 @@ void fscache_cookie_init_once(void *_cookie)
 	INIT_HLIST_HEAD(&cookie->backing_objects);
 }
 
+/*
+ * request a cookie to represent an object (index, datafile, xattr, etc)
+ * - parent specifies the parent object
+ *   - the top level index cookie for each netfs is stored in the fscache_netfs
+ *     struct upon registration
+ * - def points to the definition
+ * - the netfs_data will be passed to the functions pointed to in *def
+ * - all attached caches will be searched to see if they contain this object
+ * - index objects aren't stored on disk until there's a dependent file that
+ *   needs storing
+ * - other objects are stored in a selected cache immediately, and all the
+ *   indices forming the path to it are instantiated if necessary
+ * - we never let on to the netfs about errors
+ *   - we may set a negative cookie pointer, but that's okay
+ */
+struct fscache_cookie *__fscache_acquire_cookie(
+	struct fscache_cookie *parent,
+	const struct fscache_cookie_def *def,
+	void *netfs_data)
+{
+	struct fscache_cookie *cookie;
+
+	BUG_ON(!def);
+
+	_enter("{%s},{%s},%p",
+	       parent ? (char *) parent->def->name : "<no-parent>",
+	       def->name, netfs_data);
+
+	fscache_stat(&fscache_n_acquires);
+
+	/* if there's no parent cookie, then we don't create one here either */
+	if (!parent) {
+		fscache_stat(&fscache_n_acquires_null);
+		_leave(" [no parent]");
+		return NULL;
+	}
+
+	/* validate the definition */
+	BUG_ON(!def->get_key);
+	BUG_ON(!def->name[0]);
+
+	BUG_ON(def->type == FSCACHE_COOKIE_TYPE_INDEX &&
+	       parent->def->type != FSCACHE_COOKIE_TYPE_INDEX);
+
+	/* allocate and initialise a cookie */
+	cookie = kmem_cache_alloc(fscache_cookie_jar, GFP_KERNEL);
+	if (!cookie) {
+		fscache_stat(&fscache_n_acquires_oom);
+		_leave(" [ENOMEM]");
+		return NULL;
+	}
+
+	atomic_set(&cookie->usage, 1);
+	atomic_set(&cookie->n_children, 0);
+
+	atomic_inc(&parent->usage);
+	atomic_inc(&parent->n_children);
+
+	cookie->def		= def;
+	cookie->parent		= parent;
+	cookie->netfs_data	= netfs_data;
+	cookie->flags		= 0;
+
+	INIT_RADIX_TREE(&cookie->stores, GFP_NOFS);
+
+	switch (cookie->def->type) {
+	case FSCACHE_COOKIE_TYPE_INDEX:
+		fscache_stat(&fscache_n_cookie_index);
+		break;
+	case FSCACHE_COOKIE_TYPE_DATAFILE:
+		fscache_stat(&fscache_n_cookie_data);
+		break;
+	default:
+		fscache_stat(&fscache_n_cookie_special);
+		break;
+	}
+
+	/* if the object is an index then we need do nothing more here - we
+	 * create indices on disk when we need them as an index may exist in
+	 * multiple caches */
+	if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX) {
+		if (fscache_acquire_non_index_cookie(cookie) < 0) {
+			atomic_dec(&parent->n_children);
+			__fscache_cookie_put(cookie);
+			fscache_stat(&fscache_n_acquires_nobufs);
+			_leave(" = NULL");
+			return NULL;
+		}
+	}
+
+	fscache_stat(&fscache_n_acquires_ok);
+	_leave(" = %p", cookie);
+	return cookie;
+}
+EXPORT_SYMBOL(__fscache_acquire_cookie);
+
+/*
+ * acquire a non-index cookie
+ * - this must make sure the index chain is instantiated and instantiate the
+ *   object representation too
+ */
+static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie)
+{
+	struct fscache_object *object;
+	struct fscache_cache *cache;
+	uint64_t i_size;
+	int ret;
+
+	_enter("");
+
+	cookie->flags = 1 << FSCACHE_COOKIE_UNAVAILABLE;
+
+	/* now we need to see whether the backing objects for this cookie yet
+	 * exist, if not there'll be nothing to search */
+	down_read(&fscache_addremove_sem);
+
+	if (list_empty(&fscache_cache_list)) {
+		up_read(&fscache_addremove_sem);
+		_leave(" = 0 [no caches]");
+		return 0;
+	}
+
+	/* select a cache in which to store the object */
+	cache = fscache_select_cache_for_object(cookie->parent);
+	if (!cache) {
+		up_read(&fscache_addremove_sem);
+		fscache_stat(&fscache_n_acquires_no_cache);
+		_leave(" = -ENOMEDIUM [no cache]");
+		return -ENOMEDIUM;
+	}
+
+	_debug("cache %s", cache->tag->name);
+
+	cookie->flags =
+		(1 << FSCACHE_COOKIE_LOOKING_UP) |
+		(1 << FSCACHE_COOKIE_CREATING) |
+		(1 << FSCACHE_COOKIE_NO_DATA_YET);
+
+	/* ask the cache to allocate objects for this cookie and its parent
+	 * chain */
+	ret = fscache_alloc_object(cache, cookie);
+	if (ret < 0) {
+		up_read(&fscache_addremove_sem);
+		_leave(" = %d", ret);
+		return ret;
+	}
+
+	/* pass on how big the object we're caching is supposed to be */
+	cookie->def->get_attr(cookie->netfs_data, &i_size);
+
+	spin_lock(&cookie->lock);
+	if (hlist_empty(&cookie->backing_objects)) {
+		spin_unlock(&cookie->lock);
+		goto unavailable;
+	}
+
+	object = hlist_entry(cookie->backing_objects.first,
+			     struct fscache_object, cookie_link);
+
+	fscache_set_store_limit(object, i_size);
+
+	/* initiate the process of looking up all the objects in the chain
+	 * (done by fscache_initialise_object()) */
+	fscache_enqueue_object(object);
+
+	spin_unlock(&cookie->lock);
+
+	/* we may be required to wait for lookup to complete at this point */
+	if (!fscache_defer_lookup) {
+		_debug("non-deferred lookup %p", &cookie->flags);
+		wait_on_bit(&cookie->flags, FSCACHE_COOKIE_LOOKING_UP,
+			    fscache_wait_bit, TASK_UNINTERRUPTIBLE);
+		_debug("complete");
+		if (test_bit(FSCACHE_COOKIE_UNAVAILABLE, &cookie->flags))
+			goto unavailable;
+	}
+
+	up_read(&fscache_addremove_sem);
+	_leave(" = 0 [deferred]");
+	return 0;
+
+unavailable:
+	up_read(&fscache_addremove_sem);
+	_leave(" = -ENOBUFS");
+	return -ENOBUFS;
+}
+
+/*
+ * recursively allocate cache object records for a cookie/cache combination
+ * - caller must be holding the addremove sem
+ */
+static int fscache_alloc_object(struct fscache_cache *cache,
+				struct fscache_cookie *cookie)
+{
+	struct fscache_object *object;
+	struct hlist_node *_n;
+	int ret;
+
+	_enter("%p,%p{%s}", cache, cookie, cookie->def->name);
+
+	spin_lock(&cookie->lock);
+	hlist_for_each_entry(object, _n, &cookie->backing_objects,
+			     cookie_link) {
+		if (object->cache == cache)
+			goto object_already_extant;
+	}
+	spin_unlock(&cookie->lock);
+
+	/* ask the cache to allocate an object (we may end up with duplicate
+	 * objects at this stage, but we sort that out later) */
+	object = cache->ops->alloc_object(cache, cookie);
+	if (IS_ERR(object)) {
+		fscache_stat(&fscache_n_object_no_alloc);
+		ret = PTR_ERR(object);
+		goto error;
+	}
+
+	fscache_stat(&fscache_n_object_alloc);
+
+	object->debug_id = atomic_inc_return(&fscache_object_debug_id);
+
+	_debug("ALLOC OBJ%x: %s {%lx}",
+	       object->debug_id, cookie->def->name, object->events);
+
+	ret = fscache_alloc_object(cache, cookie->parent);
+	if (ret < 0)
+		goto error_put;
+
+	/* only attach if we managed to allocate all we needed, otherwise
+	 * discard the object we just allocated and instead use the one
+	 * attached to the cookie */
+	if (fscache_attach_object(cookie, object) < 0)
+		cache->ops->put_object(object);
+
+	_leave(" = 0");
+	return 0;
+
+object_already_extant:
+	ret = -ENOBUFS;
+	if (object->state >= FSCACHE_OBJECT_DYING) {
+		spin_unlock(&cookie->lock);
+		goto error;
+	}
+	spin_unlock(&cookie->lock);
+	_leave(" = 0 [found]");
+	return 0;
+
+error_put:
+	cache->ops->put_object(object);
+error:
+	_leave(" = %d", ret);
+	return ret;
+}
+
+/*
+ * attach a cache object to a cookie
+ */
+static int fscache_attach_object(struct fscache_cookie *cookie,
+				 struct fscache_object *object)
+{
+	struct fscache_object *p;
+	struct fscache_cache *cache = object->cache;
+	struct hlist_node *_n;
+	int ret;
+
+	_enter("{%s},{OBJ%x}", cookie->def->name, object->debug_id);
+
+	spin_lock(&cookie->lock);
+
+	/* there may be multiple initial creations of this object, but we only
+	 * want one */
+	ret = -EEXIST;
+	hlist_for_each_entry(p, _n, &cookie->backing_objects, cookie_link) {
+		if (p->cache == object->cache) {
+			if (p->state >= FSCACHE_OBJECT_DYING)
+				ret = -ENOBUFS;
+			goto cant_attach_object;
+		}
+	}
+
+	/* pin the parent object */
+	spin_lock_nested(&cookie->parent->lock, 1);
+	hlist_for_each_entry(p, _n, &cookie->parent->backing_objects,
+			     cookie_link) {
+		if (p->cache == object->cache) {
+			if (p->state >= FSCACHE_OBJECT_DYING) {
+				ret = -ENOBUFS;
+				spin_unlock(&cookie->parent->lock);
+				goto cant_attach_object;
+			}
+			object->parent = p;
+			spin_lock(&p->lock);
+			p->n_children++;
+			spin_unlock(&p->lock);
+			break;
+		}
+	}
+	spin_unlock(&cookie->parent->lock);
+
+	/* attach to the cache's object list */
+	if (list_empty(&object->cache_link)) {
+		spin_lock(&cache->object_list_lock);
+		list_add(&object->cache_link, &cache->object_list);
+		spin_unlock(&cache->object_list_lock);
+	}
+
+	/* attach to the cookie */
+	object->cookie = cookie;
+	atomic_inc(&cookie->usage);
+	hlist_add_head(&object->cookie_link, &cookie->backing_objects);
+	ret = 0;
+
+cant_attach_object:
+	spin_unlock(&cookie->lock);
+	_leave(" = %d", ret);
+	return ret;
+}
+
+/*
+ * update the index entries backing a cookie
+ */
+void __fscache_update_cookie(struct fscache_cookie *cookie)
+{
+	struct fscache_object *object;
+	struct hlist_node *_p;
+
+	fscache_stat(&fscache_n_updates);
+
+	if (!cookie) {
+		fscache_stat(&fscache_n_updates_null);
+		_leave(" [no cookie]");
+		return;
+	}
+
+	_enter("{%s}", cookie->def->name);
+
+	BUG_ON(!cookie->def->get_aux);
+
+	spin_lock(&cookie->lock);
+
+	/* update the index entry on disk in each cache backing this cookie */
+	hlist_for_each_entry(object, _p,
+			     &cookie->backing_objects, cookie_link) {
+		fscache_raise_event(object, FSCACHE_OBJECT_EV_UPDATE);
+	}
+
+	spin_unlock(&cookie->lock);
+	_leave("");
+}
+EXPORT_SYMBOL(__fscache_update_cookie);
+
+/*
+ * release a cookie back to the cache
+ * - the object will be marked as recyclable on disk if retire is true
+ * - all dependents of this cookie must have already been unregistered
+ *   (indices/files/pages)
+ */
+void __fscache_relinquish_cookie(struct fscache_cookie *cookie, int retire)
+{
+	struct fscache_cache *cache;
+	struct fscache_object *object;
+	unsigned long event;
+
+	fscache_stat(&fscache_n_relinquishes);
+
+	if (!cookie) {
+		fscache_stat(&fscache_n_relinquishes_null);
+		_leave(" [no cookie]");
+		return;
+	}
+
+	_enter("%p{%s,%p},%d",
+	       cookie, cookie->def->name, cookie->netfs_data, retire);
+
+	if (atomic_read(&cookie->n_children) != 0) {
+		printk(KERN_ERR "FS-Cache: Cookie '%s' still has children\n",
+		       cookie->def->name);
+		BUG();
+	}
+
+	/* wait for the cookie to finish being instantiated (or to fail) */
+	if (test_bit(FSCACHE_COOKIE_CREATING, &cookie->flags)) {
+		fscache_stat(&fscache_n_relinquishes_waitcrt);
+		wait_on_bit(&cookie->flags, FSCACHE_COOKIE_CREATING,
+			    fscache_wait_bit, TASK_UNINTERRUPTIBLE);
+	}
+
+	event = retire ? FSCACHE_OBJECT_EV_RETIRE : FSCACHE_OBJECT_EV_RELEASE;
+
+	/* detach pointers back to the netfs */
+	spin_lock(&cookie->lock);
+
+	cookie->netfs_data	= NULL;
+	cookie->def		= NULL;
+
+	/* break links with all the active objects */
+	while (!hlist_empty(&cookie->backing_objects)) {
+		object = hlist_entry(cookie->backing_objects.first,
+				     struct fscache_object,
+				     cookie_link);
+
+		_debug("RELEASE OBJ%x", object->debug_id);
+
+		/* detach each cache object from the object cookie */
+		spin_lock(&object->lock);
+		hlist_del_init(&object->cookie_link);
+
+		cache = object->cache;
+		object->cookie = NULL;
+		fscache_raise_event(object, event);
+		spin_unlock(&object->lock);
+
+		if (atomic_dec_and_test(&cookie->usage))
+			/* the cookie refcount shouldn't be reduced to 0 yet */
+			BUG();
+	}
+
+	spin_unlock(&cookie->lock);
+
+	if (cookie->parent) {
+		ASSERTCMP(atomic_read(&cookie->parent->usage), >, 0);
+		ASSERTCMP(atomic_read(&cookie->parent->n_children), >, 0);
+		atomic_dec(&cookie->parent->n_children);
+	}
+
+	/* finally dispose of the cookie */
+	ASSERTCMP(atomic_read(&cookie->usage), >, 0);
+	fscache_cookie_put(cookie);
+
+	_leave("");
+}
+EXPORT_SYMBOL(__fscache_relinquish_cookie);
+
 /*
  * destroy a cookie
  */

commit 955d00917f0c094e0f2fb88df967e980ab66b8ca
Author: David Howells <dhowells@redhat.com>
Date:   Fri Apr 3 16:42:38 2009 +0100

    FS-Cache: Provide a slab for cookie allocation
    
    Provide a slab from which can be allocated the FS-Cache cookies that will be
    presented to the netfs.
    
    Also provide a slab constructor and a function to recursively discard a cookie
    and its ancestor chain.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Steve Dickson <steved@redhat.com>
    Acked-by: Trond Myklebust <Trond.Myklebust@netapp.com>
    Acked-by: Al Viro <viro@zeniv.linux.org.uk>
    Tested-by: Daire Byrne <Daire.Byrne@framestore.com>

diff --git a/fs/fscache/cookie.c b/fs/fscache/cookie.c
new file mode 100644
index 000000000000..47fd75b832e1
--- /dev/null
+++ b/fs/fscache/cookie.c
@@ -0,0 +1,56 @@
+/* netfs cookie management
+ *
+ * Copyright (C) 2004-2007 Red Hat, Inc. All Rights Reserved.
+ * Written by David Howells (dhowells@redhat.com)
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#define FSCACHE_DEBUG_LEVEL COOKIE
+#include <linux/module.h>
+#include <linux/slab.h>
+#include "internal.h"
+
+struct kmem_cache *fscache_cookie_jar;
+
+/*
+ * initialise an cookie jar slab element prior to any use
+ */
+void fscache_cookie_init_once(void *_cookie)
+{
+	struct fscache_cookie *cookie = _cookie;
+
+	memset(cookie, 0, sizeof(*cookie));
+	spin_lock_init(&cookie->lock);
+	INIT_HLIST_HEAD(&cookie->backing_objects);
+}
+
+/*
+ * destroy a cookie
+ */
+void __fscache_cookie_put(struct fscache_cookie *cookie)
+{
+	struct fscache_cookie *parent;
+
+	_enter("%p", cookie);
+
+	for (;;) {
+		_debug("FREE COOKIE %p", cookie);
+		parent = cookie->parent;
+		BUG_ON(!hlist_empty(&cookie->backing_objects));
+		kmem_cache_free(fscache_cookie_jar, cookie);
+
+		if (!parent)
+			break;
+
+		cookie = parent;
+		BUG_ON(atomic_read(&cookie->usage) <= 0);
+		if (!atomic_dec_and_test(&cookie->usage))
+			break;
+	}
+
+	_leave("");
+}
