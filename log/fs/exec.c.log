commit c1e8d7c6a7a682e1405e3e242d32fc377fd196ff
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:54 2020 -0700

    mmap locking API: convert mmap_sem comments
    
    Convert comments that reference mmap_sem to reference mmap_lock instead.
    
    [akpm@linux-foundation.org: fix up linux-next leftovers]
    [akpm@linux-foundation.org: s/lockaphore/lock/, per Vlastimil]
    [akpm@linux-foundation.org: more linux-next fixups, per Michel]
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Laurent Dufour <ldufour@linux.ibm.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-13-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 105b91d191eb..e6e8a9a70327 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1091,7 +1091,7 @@ static int exec_mmap(struct mm_struct *mm)
 		/*
 		 * Make sure that if there is a core dump in progress
 		 * for the old mm, we get out and die instead of going
-		 * through with the exec.  We must hold mmap_sem around
+		 * through with the exec.  We must hold mmap_lock around
 		 * checking core_state and changing tsk->mm.
 		 */
 		mmap_read_lock(old_mm);

commit d8ed45c5dcd455fc5848d47f86883a1b872ac0d0
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:25 2020 -0700

    mmap locking API: use coccinelle to convert mmap_sem rwsem call sites
    
    This change converts the existing mmap_sem rwsem calls to use the new mmap
    locking API instead.
    
    The change is generated using coccinelle with the following rule:
    
    // spatch --sp-file mmap_lock_api.cocci --in-place --include-headers --dir .
    
    @@
    expression mm;
    @@
    (
    -init_rwsem
    +mmap_init_lock
    |
    -down_write
    +mmap_write_lock
    |
    -down_write_killable
    +mmap_write_lock_killable
    |
    -down_write_trylock
    +mmap_write_trylock
    |
    -up_write
    +mmap_write_unlock
    |
    -downgrade_write
    +mmap_write_downgrade
    |
    -down_read
    +mmap_read_lock
    |
    -down_read_killable
    +mmap_read_lock_killable
    |
    -down_read_trylock
    +mmap_read_trylock
    |
    -up_read
    +mmap_read_unlock
    )
    -(&mm->mmap_sem)
    +(mm)
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Reviewed-by: Laurent Dufour <ldufour@linux.ibm.com>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-5-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 02d0c5d19be5..105b91d191eb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -252,7 +252,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 		return -ENOMEM;
 	vma_set_anonymous(vma);
 
-	if (down_write_killable(&mm->mmap_sem)) {
+	if (mmap_write_lock_killable(mm)) {
 		err = -EINTR;
 		goto err_free;
 	}
@@ -274,11 +274,11 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 		goto err;
 
 	mm->stack_vm = mm->total_vm = 1;
-	up_write(&mm->mmap_sem);
+	mmap_write_unlock(mm);
 	bprm->p = vma->vm_end - sizeof(void *);
 	return 0;
 err:
-	up_write(&mm->mmap_sem);
+	mmap_write_unlock(mm);
 err_free:
 	bprm->vma = NULL;
 	vm_area_free(vma);
@@ -763,7 +763,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 		bprm->loader -= stack_shift;
 	bprm->exec -= stack_shift;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (mmap_write_lock_killable(mm))
 		return -EINTR;
 
 	vm_flags = VM_STACK_FLAGS;
@@ -825,7 +825,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 		ret = -EFAULT;
 
 out_unlock:
-	up_write(&mm->mmap_sem);
+	mmap_write_unlock(mm);
 	return ret;
 }
 EXPORT_SYMBOL(setup_arg_pages);
@@ -1094,9 +1094,9 @@ static int exec_mmap(struct mm_struct *mm)
 		 * through with the exec.  We must hold mmap_sem around
 		 * checking core_state and changing tsk->mm.
 		 */
-		down_read(&old_mm->mmap_sem);
+		mmap_read_lock(old_mm);
 		if (unlikely(old_mm->core_state)) {
-			up_read(&old_mm->mmap_sem);
+			mmap_read_unlock(old_mm);
 			mutex_unlock(&tsk->signal->exec_update_mutex);
 			return -EINTR;
 		}
@@ -1112,7 +1112,7 @@ static int exec_mmap(struct mm_struct *mm)
 	vmacache_flush(tsk);
 	task_unlock(tsk);
 	if (old_mm) {
-		up_read(&old_mm->mmap_sem);
+		mmap_read_unlock(old_mm);
 		BUG_ON(active_mm != old_mm);
 		setmax_mm_hiwater_rss(&tsk->signal->maxrss, old_mm);
 		mm_update_next_owner(old_mm);

commit bce2b68b891af3dd02fdc1603786c1c28db8bfad
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jun 7 21:42:43 2020 -0700

    exec: use flush_icache_user_range in read_code
    
    read_code operates on user addresses.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Link: http://lkml.kernel.org/r/20200515143646.3857579-27-hch@lst.de
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 88260ec0ac34..02d0c5d19be5 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1059,7 +1059,7 @@ ssize_t read_code(struct file *file, unsigned long addr, loff_t pos, size_t len)
 {
 	ssize_t res = vfs_read(file, (void __user *)addr, len, &pos);
 	if (res > 0)
-		flush_icache_range(addr, addr + len);
+		flush_icache_user_range(addr, addr + len);
 	return res;
 }
 EXPORT_SYMBOL(read_code);

commit 48304f7994d74ef8fddde3ff27ce41aa61453d39
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jun 7 21:42:40 2020 -0700

    exec: only build read_code when needed
    
    Only build read_code when binary formats that use it are built into the
    kernel.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Link: http://lkml.kernel.org/r/20200515143646.3857579-26-hch@lst.de
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 93ff1c4c7ebb..88260ec0ac34 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1053,6 +1053,8 @@ int kernel_read_file_from_fd(int fd, void **buf, loff_t *size, loff_t max_size,
 }
 EXPORT_SYMBOL_GPL(kernel_read_file_from_fd);
 
+#if defined(CONFIG_HAVE_AOUT) || defined(CONFIG_BINFMT_FLAT) || \
+    defined(CONFIG_BINFMT_ELF_FDPIC)
 ssize_t read_code(struct file *file, unsigned long addr, loff_t pos, size_t len)
 {
 	ssize_t res = vfs_read(file, (void __user *)addr, len, &pos);
@@ -1061,6 +1063,7 @@ ssize_t read_code(struct file *file, unsigned long addr, loff_t pos, size_t len)
 	return res;
 }
 EXPORT_SYMBOL(read_code);
+#endif
 
 /*
  * Maps the mm_struct mm into the current task struct.

commit 886d7de631da71e30909980fdbf318f7caade262
Merge: 5bfea2d9b17f 469cbd016157
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 4 19:18:29 2020 -0700

    Merge branch 'akpm' (patches from Andrew)
    
    Merge yet more updates from Andrew Morton:
    
     - More MM work. 100ish more to go. Mike Rapoport's "mm: remove
       __ARCH_HAS_5LEVEL_HACK" series should fix the current ppc issue
    
     - Various other little subsystems
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (127 commits)
      lib/ubsan.c: fix gcc-10 warnings
      tools/testing/selftests/vm: remove duplicate headers
      selftests: vm: pkeys: fix multilib builds for x86
      selftests: vm: pkeys: use the correct page size on powerpc
      selftests/vm/pkeys: override access right definitions on powerpc
      selftests/vm/pkeys: test correct behaviour of pkey-0
      selftests/vm/pkeys: introduce a sub-page allocator
      selftests/vm/pkeys: detect write violation on a mapped access-denied-key page
      selftests/vm/pkeys: associate key on a mapped page and detect write violation
      selftests/vm/pkeys: associate key on a mapped page and detect access violation
      selftests/vm/pkeys: improve checks to determine pkey support
      selftests/vm/pkeys: fix assertion in test_pkey_alloc_exhaust()
      selftests/vm/pkeys: fix number of reserved powerpc pkeys
      selftests/vm/pkeys: introduce powerpc support
      selftests/vm/pkeys: introduce generic pkey abstractions
      selftests: vm: pkeys: use the correct huge page size
      selftests/vm/pkeys: fix alloc_random_pkey() to make it really random
      selftests/vm/pkeys: fix assertion in pkey_disable_set/clear()
      selftests/vm/pkeys: fix pkey_disable_clear()
      selftests: vm: pkeys: add helpers for pkey bits
      ...

commit 762a3af6faa0682e5b30b67b1db156c7df55f2c7
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Jun 4 16:51:18 2020 -0700

    exec: open code copy_string_kernel
    
    Currently copy_string_kernel is just a wrapper around copy_strings that
    simplifies the calling conventions and uses set_fs to allow passing a
    kernel pointer.  But due to the fact the we only need to handle a single
    kernel argument pointer, the logic can be sigificantly simplified while
    getting rid of the set_fs.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Link: http://lkml.kernel.org/r/20200501104105.2621149-3-hch@lst.de
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4814b26a56fb..03a85e3c49bb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -592,17 +592,42 @@ static int copy_strings(int argc, struct user_arg_ptr argv,
  */
 int copy_string_kernel(const char *arg, struct linux_binprm *bprm)
 {
-	int r;
-	mm_segment_t oldfs = get_fs();
-	struct user_arg_ptr argv = {
-		.ptr.native = (const char __user *const  __user *)&arg,
-	};
+	int len = strnlen(arg, MAX_ARG_STRLEN) + 1 /* terminating NUL */;
+	unsigned long pos = bprm->p;
+
+	if (len == 0)
+		return -EFAULT;
+	if (!valid_arg_len(bprm, len))
+		return -E2BIG;
+
+	/* We're going to work our way backwards. */
+	arg += len;
+	bprm->p -= len;
+	if (IS_ENABLED(CONFIG_MMU) && bprm->p < bprm->argmin)
+		return -E2BIG;
+
+	while (len > 0) {
+		unsigned int bytes_to_copy = min_t(unsigned int, len,
+				min_not_zero(offset_in_page(pos), PAGE_SIZE));
+		struct page *page;
+		char *kaddr;
 
-	set_fs(KERNEL_DS);
-	r = copy_strings(1, argv, bprm);
-	set_fs(oldfs);
+		pos -= bytes_to_copy;
+		arg -= bytes_to_copy;
+		len -= bytes_to_copy;
 
-	return r;
+		page = get_arg_page(bprm, pos, 1);
+		if (!page)
+			return -E2BIG;
+		kaddr = kmap_atomic(page);
+		flush_arg_page(bprm, pos & PAGE_MASK, page);
+		memcpy(kaddr + offset_in_page(pos), arg, bytes_to_copy);
+		flush_kernel_dcache_page(page);
+		kunmap_atomic(kaddr);
+		put_arg_page(page);
+	}
+
+	return 0;
 }
 EXPORT_SYMBOL(copy_string_kernel);
 

commit 986db2d14a6dca6456b63b4f5c410ae2aab4ec9d
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Jun 4 16:51:14 2020 -0700

    exec: simplify the copy_strings_kernel calling convention
    
    copy_strings_kernel is always used with a single argument,
    adjust the calling convention to that.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Link: http://lkml.kernel.org/r/20200501104105.2621149-2-hch@lst.de
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2c465119affc..4814b26a56fb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -588,24 +588,23 @@ static int copy_strings(int argc, struct user_arg_ptr argv,
 }
 
 /*
- * Like copy_strings, but get argv and its values from kernel memory.
+ * Copy and argument/environment string from the kernel to the processes stack.
  */
-int copy_strings_kernel(int argc, const char *const *__argv,
-			struct linux_binprm *bprm)
+int copy_string_kernel(const char *arg, struct linux_binprm *bprm)
 {
 	int r;
 	mm_segment_t oldfs = get_fs();
 	struct user_arg_ptr argv = {
-		.ptr.native = (const char __user *const  __user *)__argv,
+		.ptr.native = (const char __user *const  __user *)&arg,
 	};
 
 	set_fs(KERNEL_DS);
-	r = copy_strings(argc, argv, bprm);
+	r = copy_strings(1, argv, bprm);
 	set_fs(oldfs);
 
 	return r;
 }
-EXPORT_SYMBOL(copy_strings_kernel);
+EXPORT_SYMBOL(copy_string_kernel);
 
 #ifdef CONFIG_MMU
 
@@ -1865,7 +1864,7 @@ static int __do_execve_file(int fd, struct filename *filename,
 	if (retval < 0)
 		goto out;
 
-	retval = copy_strings_kernel(1, &bprm->filename, bprm);
+	retval = copy_string_kernel(bprm->filename, bprm);
 	if (retval < 0)
 		goto out;
 

commit 15a2bc4dbb9cfed1c661a657fcb10798150b7598
Merge: 9ff7258575d5 3977e285ee89
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 4 14:07:08 2020 -0700

    Merge branch 'exec-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull execve updates from Eric Biederman:
     "Last cycle for the Nth time I ran into bugs and quality of
      implementation issues related to exec that could not be easily be
      fixed because of the way exec is implemented. So I have been digging
      into exec and cleanup up what I can.
    
      I don't think I have exec sorted out enough to fix the issues I
      started with but I have made some headway this cycle with 4 sets of
      changes.
    
       - promised cleanups after introducing exec_update_mutex
    
       - trivial cleanups for exec
    
       - control flow simplifications
    
       - remove the recomputation of bprm->cred
    
      The net result is code that is a bit easier to understand and work
      with and a decrease in the number of lines of code (if you don't count
      the added tests)"
    
    * 'exec-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (24 commits)
      exec: Compute file based creds only once
      exec: Add a per bprm->file version of per_clear
      binfmt_elf_fdpic: fix execfd build regression
      selftests/exec: Add binfmt_script regression test
      exec: Remove recursion from search_binary_handler
      exec: Generic execfd support
      exec/binfmt_script: Don't modify bprm->buf and then return -ENOEXEC
      exec: Move the call of prepare_binprm into search_binary_handler
      exec: Allow load_misc_binary to call prepare_binprm unconditionally
      exec: Convert security_bprm_set_creds into security_bprm_repopulate_creds
      exec: Factor security_bprm_creds_for_exec out of security_bprm_set_creds
      exec: Teach prepare_exec_creds how exec treats uids & gids
      exec: Set the point of no return sooner
      exec: Move handling of the point of no return to the top level
      exec: Run sync_mm_rss before taking exec_update_mutex
      exec: Fix spelling of search_binary_handler in a comment
      exec: Move the comment from above de_thread to above unshare_sighand
      exec: Rename flush_old_exec begin_new_exec
      exec: Move most of setup_new_exec into flush_old_exec
      exec: In setup_new_exec cache current in the local variable me
      ...

commit 9ff7258575d5fee011649d20cc56de720a395191
Merge: 051c3556e3d6 9d78edeaec75
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 4 13:54:34 2020 -0700

    Merge branch 'proc-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull proc updates from Eric Biederman:
     "This has four sets of changes:
    
       - modernize proc to support multiple private instances
    
       - ensure we see the exit of each process tid exactly
    
       - remove has_group_leader_pid
    
       - use pids not tasks in posix-cpu-timers lookup
    
      Alexey updated proc so each mount of proc uses a new superblock. This
      allows people to actually use mount options with proc with no fear of
      messing up another mount of proc. Given the kernel's internal mounts
      of proc for things like uml this was a real problem, and resulted in
      Android's hidepid mount options being ignored and introducing security
      issues.
    
      The rest of the changes are small cleanups and fixes that came out of
      my work to allow this change to proc. In essence it is swapping the
      pids in de_thread during exec which removes a special case the code
      had to handle. Then updating the code to stop handling that special
      case"
    
    * 'proc-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace:
      proc: proc_pid_ns takes super_block as an argument
      remove the no longer needed pid_alive() check in __task_pid_nr_ns()
      posix-cpu-timers: Replace __get_task_for_clock with pid_for_clock
      posix-cpu-timers: Replace cpu_timer_pid_type with clock_pid_type
      posix-cpu-timers: Extend rcu_read_lock removing task_struct references
      signal: Remove has_group_leader_pid
      exec: Remove BUG_ON(has_group_leader_pid)
      posix-cpu-timer:  Unify the now redundant code in lookup_task
      posix-cpu-timer: Tidy up group_leader logic in lookup_task
      proc: Ensure we see the exit of each process tid exactly once
      rculist: Add hlists_swap_heads_rcu
      proc: Use PIDTYPE_TGID in next_tgid
      Use proc_pid_ns() to get pid_namespace from the proc superblock
      proc: use named enums for better readability
      proc: use human-readable values for hidepid
      docs: proc: add documentation for "hidepid=4" and "subset=pid" options and new mount behavior
      proc: add option to mount only a pids subset
      proc: instantiate only pids that we can ptrace on 'hidepid=4' mount option
      proc: allow to mount many instances of proc in one pid namespace
      proc: rename struct proc_fs_info to proc_fs_opts

commit 56305aa9b6fab91a5555a45796b79c1b0a6353d1
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri May 29 22:00:54 2020 -0500

    exec: Compute file based creds only once
    
    Move the computation of creds from prepare_binfmt into begin_new_exec
    so that the creds need only be computed once.  This is just code
    reorganization no semantic changes of any kind are made.
    
    Moving the computation is safe.  I have looked through the kernel and
    verified none of the binfmts look at bprm->cred directly, and that
    there are no helpers that look at bprm->cred indirectly.  Which means
    that it is not a problem to compute the bprm->cred later in the
    execution flow as it is not used until it becomes current->cred.
    
    A new function bprm_creds_from_file is added to contain the work that
    needs to be done.  bprm_creds_from_file first computes which file
    bprm->executable or most likely bprm->file that the bprm->creds
    will be computed from.
    
    The funciton bprm_fill_uid is updated to receive the file instead of
    accessing bprm->file.  The now unnecessary work needed to reset the
    bprm->cred->euid, and bprm->cred->egid is removed from brpm_fill_uid.
    A small comment to document that bprm_fill_uid now only deals with the
    work to handle suid and sgid files.  The default case is already
    heandled by prepare_exec_creds.
    
    The function security_bprm_repopulate_creds is renamed
    security_bprm_creds_from_file and now is explicitly passed the file
    from which to compute the creds.  The documentation of the
    bprm_creds_from_file security hook is updated to explain when the hook
    is called and what it needs to do.  The file is passed from
    cap_bprm_creds_from_file into get_file_caps so that the caps are
    computed for the appropriate file.  The now unnecessary work in
    cap_bprm_creds_from_file to reset the ambient capabilites has been
    removed.  A small comment to document that the work of
    cap_bprm_creds_from_file is to read capabilities from the files
    secureity attribute and derive capabilities from the fact the
    user had uid 0 has been added.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 0f793536e393..e8599236290d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -72,6 +72,8 @@
 
 #include <trace/events/sched.h>
 
+static int bprm_creds_from_file(struct linux_binprm *bprm);
+
 int suid_dumpable = 0;
 
 static LIST_HEAD(formats);
@@ -1304,6 +1306,11 @@ int begin_new_exec(struct linux_binprm * bprm)
 	struct task_struct *me = current;
 	int retval;
 
+	/* Once we are committed compute the creds */
+	retval = bprm_creds_from_file(bprm);
+	if (retval)
+		return retval;
+
 	/*
 	 * Ensure all future errors are fatal.
 	 */
@@ -1354,7 +1361,6 @@ int begin_new_exec(struct linux_binprm * bprm)
 	me->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD |
 					PF_NOFREEZE | PF_NO_SETAFFINITY);
 	flush_thread();
-	bprm->per_clear |= bprm->pf_per_clear;
 	me->personality &= ~bprm->per_clear;
 
 	/*
@@ -1365,13 +1371,6 @@ int begin_new_exec(struct linux_binprm * bprm)
 	 */
 	do_close_on_exec(me->files);
 
-	/*
-	 * Once here, prepare_binrpm() will not be called any more, so
-	 * the final state of setuid/setgid/fscaps can be merged into the
-	 * secureexec flag.
-	 */
-	bprm->secureexec |= bprm->active_secureexec;
-
 	if (bprm->secureexec) {
 		/* Make sure parent cannot signal privileged process. */
 		me->pdeath_signal = 0;
@@ -1587,29 +1586,21 @@ static void check_unsafe_exec(struct linux_binprm *bprm)
 	spin_unlock(&p->fs->lock);
 }
 
-static void bprm_fill_uid(struct linux_binprm *bprm)
+static void bprm_fill_uid(struct linux_binprm *bprm, struct file *file)
 {
+	/* Handle suid and sgid on files */
 	struct inode *inode;
 	unsigned int mode;
 	kuid_t uid;
 	kgid_t gid;
 
-	/*
-	 * Since this can be called multiple times (via prepare_binprm),
-	 * we must clear any previous work done when setting set[ug]id
-	 * bits from any earlier bprm->file uses (for example when run
-	 * first for a setuid script then again for its interpreter).
-	 */
-	bprm->cred->euid = current_euid();
-	bprm->cred->egid = current_egid();
-
-	if (!mnt_may_suid(bprm->file->f_path.mnt))
+	if (!mnt_may_suid(file->f_path.mnt))
 		return;
 
 	if (task_no_new_privs(current))
 		return;
 
-	inode = bprm->file->f_path.dentry->d_inode;
+	inode = file->f_path.dentry->d_inode;
 	mode = READ_ONCE(inode->i_mode);
 	if (!(mode & (S_ISUID|S_ISGID)))
 		return;
@@ -1629,19 +1620,31 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
 		return;
 
 	if (mode & S_ISUID) {
-		bprm->pf_per_clear |= PER_CLEAR_ON_SETID;
+		bprm->per_clear |= PER_CLEAR_ON_SETID;
 		bprm->cred->euid = uid;
 	}
 
 	if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP)) {
-		bprm->pf_per_clear |= PER_CLEAR_ON_SETID;
+		bprm->per_clear |= PER_CLEAR_ON_SETID;
 		bprm->cred->egid = gid;
 	}
 }
 
+/*
+ * Compute brpm->cred based upon the final binary.
+ */
+static int bprm_creds_from_file(struct linux_binprm *bprm)
+{
+	/* Compute creds based on which file? */
+	struct file *file = bprm->execfd_creds ? bprm->executable : bprm->file;
+
+	bprm_fill_uid(bprm, file);
+	return security_bprm_creds_from_file(bprm, file);
+}
+
 /*
  * Fill the binprm structure from the inode.
- * Check permissions, then read the first BINPRM_BUF_SIZE bytes
+ * Read the first BINPRM_BUF_SIZE bytes
  *
  * This may be called multiple times for binary chains (scripts for example).
  */
@@ -1649,20 +1652,6 @@ static int prepare_binprm(struct linux_binprm *bprm)
 {
 	loff_t pos = 0;
 
-	/* Can the interpreter get to the executable without races? */
-	if (!bprm->preserve_creds) {
-		int retval;
-
-		/* Recompute parts of bprm->cred based on bprm->file */
-		bprm->active_secureexec = 0;
-		bprm->pf_per_clear = 0;
-		bprm_fill_uid(bprm);
-		retval = security_bprm_repopulate_creds(bprm);
-		if (retval)
-			return retval;
-	}
-	bprm->preserve_creds = 0;
-
 	memset(bprm->buf, 0, BINPRM_BUF_SIZE);
 	return kernel_read(bprm->file, bprm->buf, BINPRM_BUF_SIZE, &pos);
 }

commit a7868323c2638a7c6c5b30b37831b73cbdf0dc15
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri May 29 08:24:10 2020 -0500

    exec: Add a per bprm->file version of per_clear
    
    There is a small bug in the code that recomputes parts of bprm->cred
    for every bprm->file.  The code never recomputes the part of
    clear_dangerous_personality_flags it is responsible for.
    
    Which means that in practice if someone creates a sgid script
    the interpreter will not be able to use any of:
            READ_IMPLIES_EXEC
            ADDR_NO_RANDOMIZE
            ADDR_COMPAT_LAYOUT
            MMAP_PAGE_ZERO.
    
    This accentially clearing of personality flags probably does
    not matter in practice because no one has complained
    but it does make the code more difficult to understand.
    
    Further remaining bug compatible prevents the recomputation from being
    removed and replaced by simply computing bprm->cred once from the
    final bprm->file.
    
    Making this change removes the last behavior difference between
    computing bprm->creds from the final file and recomputing
    bprm->cred several times.  Which allows this behavior change
    to be justified for it's own reasons, and for any but hunts
    looking into why the behavior changed to wind up here instead
    of in the code that will follow that computes bprm->cred
    from the final bprm->file.
    
    This small logic bug appears to have existed since the code
    started clearing dangerous personality bits.
    
    History Tree: git://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git
    Fixes: 1bb0fa189c6a ("[PATCH] NX: clean up legacy binary support")
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index c3c879a55d65..0f793536e393 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1354,6 +1354,7 @@ int begin_new_exec(struct linux_binprm * bprm)
 	me->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD |
 					PF_NOFREEZE | PF_NO_SETAFFINITY);
 	flush_thread();
+	bprm->per_clear |= bprm->pf_per_clear;
 	me->personality &= ~bprm->per_clear;
 
 	/*
@@ -1628,12 +1629,12 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
 		return;
 
 	if (mode & S_ISUID) {
-		bprm->per_clear |= PER_CLEAR_ON_SETID;
+		bprm->pf_per_clear |= PER_CLEAR_ON_SETID;
 		bprm->cred->euid = uid;
 	}
 
 	if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP)) {
-		bprm->per_clear |= PER_CLEAR_ON_SETID;
+		bprm->pf_per_clear |= PER_CLEAR_ON_SETID;
 		bprm->cred->egid = gid;
 	}
 }
@@ -1654,6 +1655,7 @@ static int prepare_binprm(struct linux_binprm *bprm)
 
 		/* Recompute parts of bprm->cred based on bprm->file */
 		bprm->active_secureexec = 0;
+		bprm->pf_per_clear = 0;
 		bprm_fill_uid(bprm);
 		retval = security_bprm_repopulate_creds(bprm);
 		if (retval)

commit bc2bf338d54b7aadaed49bb45b9e10d4592b2a46
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon May 18 18:43:20 2020 -0500

    exec: Remove recursion from search_binary_handler
    
    Recursion in kernel code is generally a bad idea as it can overflow
    the kernel stack.  Recursion in exec also hides that the code is
    looping and that the loop changes bprm->file.
    
    Instead of recursing in search_binary_handler have the methods that
    would recurse set bprm->interpreter and return 0.  Modify exec_binprm
    to loop when bprm->interpreter is set.  Consolidate all of the
    reassignments of bprm->file in that loop to make it clear what is
    going on.
    
    The structure of the new loop in exec_binprm is that all errors return
    immediately, while successful completion (ret == 0 &&
    !bprm->interpreter) just breaks out of the loop and runs what
    exec_bprm has always run upon successful completion.
    
    Fail if the an interpreter is being call after execfd has been set.
    The code has never properly handled an interpreter being called with
    execfd being set and with reassignments of bprm->file and the
    assignment of bprm->executable in generic code it has finally become
    possible to test and fail when if this problematic condition happens.
    
    With the reassignments of bprm->file and the assignment of
    bprm->executable moved into the generic code add a test to see if
    bprm->executable is being reassigned.
    
    In search_binary_handler remove the test for !bprm->file.  With all
    reassignments of bprm->file moved to exec_binprm bprm->file can never
    be NULL in search_binary_handler.
    
    Link: https://lkml.kernel.org/r/87sgfwyd84.fsf_-_@x220.int.ebiederm.org
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 117ad8fc012b..c3c879a55d65 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1710,16 +1710,12 @@ EXPORT_SYMBOL(remove_arg_zero);
 /*
  * cycle the list of binary formats handler, until one recognizes the image
  */
-int search_binary_handler(struct linux_binprm *bprm)
+static int search_binary_handler(struct linux_binprm *bprm)
 {
 	bool need_retry = IS_ENABLED(CONFIG_MODULES);
 	struct linux_binfmt *fmt;
 	int retval;
 
-	/* This allows 4 levels of binfmt rewrites before failing hard. */
-	if (bprm->recursion_depth > 5)
-		return -ELOOP;
-
 	retval = prepare_binprm(bprm);
 	if (retval < 0)
 		return retval;
@@ -1736,14 +1732,11 @@ int search_binary_handler(struct linux_binprm *bprm)
 			continue;
 		read_unlock(&binfmt_lock);
 
-		bprm->recursion_depth++;
 		retval = fmt->load_binary(bprm);
-		bprm->recursion_depth--;
 
 		read_lock(&binfmt_lock);
 		put_binfmt(fmt);
-		if (bprm->point_of_no_return || !bprm->file ||
-		    (retval != -ENOEXEC)) {
+		if (bprm->point_of_no_return || (retval != -ENOEXEC)) {
 			read_unlock(&binfmt_lock);
 			return retval;
 		}
@@ -1762,12 +1755,11 @@ int search_binary_handler(struct linux_binprm *bprm)
 
 	return retval;
 }
-EXPORT_SYMBOL(search_binary_handler);
 
 static int exec_binprm(struct linux_binprm *bprm)
 {
 	pid_t old_pid, old_vpid;
-	int ret;
+	int ret, depth;
 
 	/* Need to fetch pid before load_binary changes it */
 	old_pid = current->pid;
@@ -1775,15 +1767,38 @@ static int exec_binprm(struct linux_binprm *bprm)
 	old_vpid = task_pid_nr_ns(current, task_active_pid_ns(current->parent));
 	rcu_read_unlock();
 
-	ret = search_binary_handler(bprm);
-	if (ret >= 0) {
-		audit_bprm(bprm);
-		trace_sched_process_exec(current, old_pid, bprm);
-		ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
-		proc_exec_connector(current);
+	/* This allows 4 levels of binfmt rewrites before failing hard. */
+	for (depth = 0;; depth++) {
+		struct file *exec;
+		if (depth > 5)
+			return -ELOOP;
+
+		ret = search_binary_handler(bprm);
+		if (ret < 0)
+			return ret;
+		if (!bprm->interpreter)
+			break;
+
+		exec = bprm->file;
+		bprm->file = bprm->interpreter;
+		bprm->interpreter = NULL;
+
+		allow_write_access(exec);
+		if (unlikely(bprm->have_execfd)) {
+			if (bprm->executable) {
+				fput(exec);
+				return -ENOEXEC;
+			}
+			bprm->executable = exec;
+		} else
+			fput(exec);
 	}
 
-	return ret;
+	audit_bprm(bprm);
+	trace_sched_process_exec(current, old_pid, bprm);
+	ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
+	proc_exec_connector(current);
+	return 0;
 }
 
 /*

commit b8a61c9e7b4a0fec493d191429e9653d66a79ccc
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 14 15:17:40 2020 -0500

    exec: Generic execfd support
    
    Most of the support for passing the file descriptor of an executable
    to an interpreter already lives in the generic code and in binfmt_elf.
    Rework the fields in binfmt_elf that deal with executable file
    descriptor passing to make executable file descriptor passing a first
    class concept.
    
    Move the fd_install from binfmt_misc into begin_new_exec after the new
    creds have been installed.  This means that accessing the file through
    /proc/<pid>/fd/N is able to see the creds for the new executable
    before allowing access to the new executables files.
    
    Performing the install of the executables file descriptor after
    the point of no return also means that nothing special needs to
    be done on error.  The exiting of the process will close all
    of it's open files.
    
    Move the would_dump from binfmt_misc into begin_new_exec right
    after would_dump is called on the bprm->file.  This makes it
    obvious this case exists and that no nesting of bprm->file is
    currently supported.
    
    In binfmt_misc the movement of fd_install into generic code means
    that it's special error exit path is no longer needed.
    
    Link: https://lkml.kernel.org/r/87y2poyd91.fsf_-_@x220.int.ebiederm.org
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 5fc458460e44..117ad8fc012b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1323,7 +1323,10 @@ int begin_new_exec(struct linux_binprm * bprm)
 	 */
 	set_mm_exe_file(bprm->mm, bprm->file);
 
+	/* If the binary is not readable then enforce mm->dumpable=0 */
 	would_dump(bprm, bprm->file);
+	if (bprm->have_execfd)
+		would_dump(bprm, bprm->executable);
 
 	/*
 	 * Release all of the old mmap stuff
@@ -1427,6 +1430,16 @@ int begin_new_exec(struct linux_binprm * bprm)
 	 * credentials; any time after this it may be unlocked.
 	 */
 	security_bprm_committed_creds(bprm);
+
+	/* Pass the opened binary to the interpreter. */
+	if (bprm->have_execfd) {
+		retval = get_unused_fd_flags(0);
+		if (retval < 0)
+			goto out_unlock;
+		fd_install(retval, bprm->executable);
+		bprm->executable = NULL;
+		bprm->execfd = retval;
+	}
 	return 0;
 
 out_unlock:
@@ -1516,6 +1529,8 @@ static void free_bprm(struct linux_binprm *bprm)
 		allow_write_access(bprm->file);
 		fput(bprm->file);
 	}
+	if (bprm->executable)
+		fput(bprm->executable);
 	/* If a binfmt changed the interp, free it. */
 	if (bprm->interp != bprm->filename)
 		kfree(bprm->interp);

commit 8b72ca9004ed35104deb80b07990da5503bc5252
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed May 13 22:25:20 2020 -0500

    exec: Move the call of prepare_binprm into search_binary_handler
    
    The code in prepare_binary_handler needs to be run every time
    search_binary_handler is called so move the call into search_binary_handler
    itself to make the code simpler and easier to understand.
    
    Link: https://lkml.kernel.org/r/87d070zrvx.fsf_-_@x220.int.ebiederm.org
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: James Morris <jamorris@linux.microsoft.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 028e0e323af5..5fc458460e44 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1629,7 +1629,7 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
  *
  * This may be called multiple times for binary chains (scripts for example).
  */
-int prepare_binprm(struct linux_binprm *bprm)
+static int prepare_binprm(struct linux_binprm *bprm)
 {
 	loff_t pos = 0;
 
@@ -1650,8 +1650,6 @@ int prepare_binprm(struct linux_binprm *bprm)
 	return kernel_read(bprm->file, bprm->buf, BINPRM_BUF_SIZE, &pos);
 }
 
-EXPORT_SYMBOL(prepare_binprm);
-
 /*
  * Arguments are '\0' separated strings found at the location bprm->p
  * points to; chop off the first by relocating brpm->p to right after
@@ -1707,6 +1705,10 @@ int search_binary_handler(struct linux_binprm *bprm)
 	if (bprm->recursion_depth > 5)
 		return -ELOOP;
 
+	retval = prepare_binprm(bprm);
+	if (retval < 0)
+		return retval;
+
 	retval = security_bprm_check(bprm);
 	if (retval)
 		return retval;
@@ -1864,10 +1866,6 @@ static int __do_execve_file(int fd, struct filename *filename,
 	if (retval)
 		goto out;
 
-	retval = prepare_binprm(bprm);
-	if (retval < 0)
-		goto out;
-
 	retval = copy_strings_kernel(1, &bprm->filename, bprm);
 	if (retval < 0)
 		goto out;

commit a16b3357b2b8e910bb614254d8a7e84d2bd59b4c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat May 16 06:02:54 2020 -0500

    exec: Allow load_misc_binary to call prepare_binprm unconditionally
    
    Add a flag preserve_creds that binfmt_misc can set to prevent
    credentials from being updated.  This allows binfmt_misc to always
    call prepare_binprm.  Allowing the credential computation logic to be
    consolidated.
    
    Not replacing the credentials with the interpreters credentials is
    safe because because an open file descriptor to the executable is
    passed to the interpreter.   As the interpreter does not need to
    reopen the executable it is guaranteed to see the same file that
    exec sees.
    
    Ref: c407c033de84 ("[PATCH] binfmt_misc: improve calculation of interpreter's credentials")
    Link: https://lkml.kernel.org/r/87imgszrwo.fsf_-_@x220.int.ebiederm.org
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 8e3b93d51d31..028e0e323af5 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1631,15 +1631,20 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
  */
 int prepare_binprm(struct linux_binprm *bprm)
 {
-	int retval;
 	loff_t pos = 0;
 
-	/* Recompute parts of bprm->cred based on bprm->file */
-	bprm->active_secureexec = 0;
-	bprm_fill_uid(bprm);
-	retval = security_bprm_repopulate_creds(bprm);
-	if (retval)
-		return retval;
+	/* Can the interpreter get to the executable without races? */
+	if (!bprm->preserve_creds) {
+		int retval;
+
+		/* Recompute parts of bprm->cred based on bprm->file */
+		bprm->active_secureexec = 0;
+		bprm_fill_uid(bprm);
+		retval = security_bprm_repopulate_creds(bprm);
+		if (retval)
+			return retval;
+	}
+	bprm->preserve_creds = 0;
 
 	memset(bprm->buf, 0, BINPRM_BUF_SIZE);
 	return kernel_read(bprm->file, bprm->buf, BINPRM_BUF_SIZE, &pos);

commit 112b7147592e8f46bd1da4f961773e6d974f38a8
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 14 12:53:44 2020 -0500

    exec: Convert security_bprm_set_creds into security_bprm_repopulate_creds
    
    Rename bprm->cap_elevated to bprm->active_secureexec and initialize it
    in prepare_binprm instead of in cap_bprm_set_creds.  Initializing
    bprm->active_secureexec in prepare_binprm allows multiple
    implementations of security_bprm_repopulate_creds to play nicely with
    each other.
    
    Rename security_bprm_set_creds to security_bprm_reopulate_creds to
    emphasize that this path recomputes part of bprm->cred.  This
    recomputation avoids the time of check vs time of use problems that
    are inherent in unix #! interpreters.
    
    In short two renames and a move in the location of initializing
    bprm->active_secureexec.
    
    Link: https://lkml.kernel.org/r/87o8qkzrxp.fsf_-_@x220.int.ebiederm.org
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 9e70da47f8d9..8e3b93d51d31 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1366,7 +1366,7 @@ int begin_new_exec(struct linux_binprm * bprm)
 	 * the final state of setuid/setgid/fscaps can be merged into the
 	 * secureexec flag.
 	 */
-	bprm->secureexec |= bprm->cap_elevated;
+	bprm->secureexec |= bprm->active_secureexec;
 
 	if (bprm->secureexec) {
 		/* Make sure parent cannot signal privileged process. */
@@ -1634,10 +1634,10 @@ int prepare_binprm(struct linux_binprm *bprm)
 	int retval;
 	loff_t pos = 0;
 
+	/* Recompute parts of bprm->cred based on bprm->file */
+	bprm->active_secureexec = 0;
 	bprm_fill_uid(bprm);
-
-	/* fill in binprm security blob */
-	retval = security_bprm_set_creds(bprm);
+	retval = security_bprm_repopulate_creds(bprm);
 	if (retval)
 		return retval;
 

commit b8bff599261c930630385ee21d3f98e7ce7d4843
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Mar 22 15:46:24 2020 -0500

    exec: Factor security_bprm_creds_for_exec out of security_bprm_set_creds
    
    Today security_bprm_set_creds has several implementations:
    apparmor_bprm_set_creds, cap_bprm_set_creds, selinux_bprm_set_creds,
    smack_bprm_set_creds, and tomoyo_bprm_set_creds.
    
    Except for cap_bprm_set_creds they all test bprm->called_set_creds and
    return immediately if it is true.  The function cap_bprm_set_creds
    ignores bprm->calld_sed_creds entirely.
    
    Create a new LSM hook security_bprm_creds_for_exec that is called just
    before prepare_binprm in __do_execve_file, resulting in a LSM hook
    that is called exactly once for the entire of exec.  Modify the bits
    of security_bprm_set_creds that only want to be called once per exec
    into security_bprm_creds_for_exec, leaving only cap_bprm_set_creds
    behind.
    
    Remove bprm->called_set_creds all of it's former users have been moved
    to security_bprm_creds_for_exec.
    
    Add or upate comments a appropriate to bring them up to date and
    to reflect this change.
    
    Link: https://lkml.kernel.org/r/87v9kszrzh.fsf_-_@x220.int.ebiederm.org
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Acked-by: Casey Schaufler <casey@schaufler-ca.com> # For the LSM and Smack bits
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 14b786158aa9..9e70da47f8d9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1640,7 +1640,6 @@ int prepare_binprm(struct linux_binprm *bprm)
 	retval = security_bprm_set_creds(bprm);
 	if (retval)
 		return retval;
-	bprm->called_set_creds = 1;
 
 	memset(bprm->buf, 0, BINPRM_BUF_SIZE);
 	return kernel_read(bprm->file, bprm->buf, BINPRM_BUF_SIZE, &pos);
@@ -1855,6 +1854,11 @@ static int __do_execve_file(int fd, struct filename *filename,
 	if (retval < 0)
 		goto out;
 
+	/* Set the unchanging part of bprm->cred */
+	retval = security_bprm_creds_for_exec(bprm);
+	if (retval)
+		goto out;
+
 	retval = prepare_binprm(bprm);
 	if (retval < 0)
 		goto out;

commit b127c16d0603e1f995e3d08b71d2c3100727e2c1
Merge: 27e68f086393 f87d1c955916
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon May 18 07:11:17 2020 -0500

    Merge f87d1c955916 ("exec: Move would_dump into flush_old_exec")
    
    The change to exec is relevant to the cleanup work I have been doing.
    
    Merge it here so that I can build on top of it, and so hopefully
    that other merge logic can pick up on this and see how to deal
    with the conflict between that change and my exec cleanup work.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

commit f87d1c9559164294040e58f5e3b74a162bf7c6e8
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat May 16 16:29:20 2020 -0500

    exec: Move would_dump into flush_old_exec
    
    I goofed when I added mm->user_ns support to would_dump.  I missed the
    fact that in the case of binfmt_loader, binfmt_em86, binfmt_misc, and
    binfmt_script bprm->file is reassigned.  Which made the move of
    would_dump from setup_new_exec to __do_execve_file before exec_binprm
    incorrect as it can result in would_dump running on the script instead
    of the interpreter of the script.
    
    The net result is that the code stopped making unreadable interpreters
    undumpable.  Which allows them to be ptraced and written to disk
    without special permissions.  Oops.
    
    The move was necessary because the call in set_new_exec was after
    bprm->mm was no longer valid.
    
    To correct this mistake move the misplaced would_dump from
    __do_execve_file into flos_old_exec, before exec_mmap is called.
    
    I tested and confirmed that without this fix I can attach with gdb to
    a script with an unreadable interpreter, and with this fix I can not.
    
    Cc: stable@vger.kernel.org
    Fixes: f84df2a6f268 ("exec: Ensure mm->user_ns contains the execed files")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 06b4c550af5d..2c465119affc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1317,6 +1317,8 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 */
 	set_mm_exe_file(bprm->mm, bprm->file);
 
+	would_dump(bprm, bprm->file);
+
 	/*
 	 * Release all of the old mmap stuff
 	 */
@@ -1876,8 +1878,6 @@ static int __do_execve_file(int fd, struct filename *filename,
 	if (retval < 0)
 		goto out;
 
-	would_dump(bprm, bprm->file);
-
 	retval = exec_binprm(bprm);
 	if (retval < 0)
 		goto out;

commit 6834e0bb41bbe144d42b8cd843f3ee30bfe2c825
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Apr 4 12:01:37 2020 -0500

    exec: Set the point of no return sooner
    
    Make the code more robust by marking the point of no return sooner.
    This ensures that future code changes don't need to worry about how
    they return errors if they are past this point.
    
    This results in no actual change in behavior as __do_execve_file does
    not force SIGSEGV when there is a pending fatal signal pending past
    the point of no return.  Further the only error returns from de_thread
    and exec_mmap that can occur result in fatal signals being pending.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Link: https://lkml.kernel.org/r/87sgga5klu.fsf_-_@x220.int.ebiederm.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index fa265ea322b7..9aa08ce2ffcc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1304,6 +1304,11 @@ int begin_new_exec(struct linux_binprm * bprm)
 	struct task_struct *me = current;
 	int retval;
 
+	/*
+	 * Ensure all future errors are fatal.
+	 */
+	bprm->point_of_no_return = true;
+
 	/*
 	 * Make this the only thread in the thread group.
 	 */
@@ -1326,13 +1331,6 @@ int begin_new_exec(struct linux_binprm * bprm)
 	if (retval)
 		goto out;
 
-	/*
-	 * With the new mm installed it is completely impossible to
-	 * fail and return to the original process.  If anything from
-	 * here on returns an error, the check in __do_execve_file()
-	 * will SEGV current.
-	 */
-	bprm->point_of_no_return = true;
 	bprm->mm = NULL;
 
 #ifdef CONFIG_POSIX_TIMERS

commit 8890b29341f30f4a364b2eb6046bb1ac1478f955
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Apr 4 09:42:56 2020 -0500

    exec: Move handling of the point of no return to the top level
    
    Move the handing of the point of no return from search_binary_handler
    into __do_execve_file so that it is easier to find, and to keep
    things robust in the face of change.
    
    Make it clear that an existing fatal signal will take precedence over
    a forced SIGSEGV by not forcing SIGSEGV if a fatal signal is already
    pending.  This does not change the behavior but it saves a reader
    of the code the tedium of reading and understanding force_sig
    and the signal delivery code.
    
    Update the comment in begin_new_exec about where SIGSEGV is forced.
    
    Keep point_of_no_return from being a mystery by documenting
    what the code is doing where it forces SIGSEGV if the
    code is past the point of no return.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Link: https://lkml.kernel.org/r/87y2q25knl.fsf_-_@x220.int.ebiederm.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index ecee0ebebf85..fa265ea322b7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1329,8 +1329,8 @@ int begin_new_exec(struct linux_binprm * bprm)
 	/*
 	 * With the new mm installed it is completely impossible to
 	 * fail and return to the original process.  If anything from
-	 * here on returns an error, the check in
-	 * search_binary_handler() will SEGV current.
+	 * here on returns an error, the check in __do_execve_file()
+	 * will SEGV current.
 	 */
 	bprm->point_of_no_return = true;
 	bprm->mm = NULL;
@@ -1721,13 +1721,8 @@ int search_binary_handler(struct linux_binprm *bprm)
 
 		read_lock(&binfmt_lock);
 		put_binfmt(fmt);
-		if (retval < 0 && bprm->point_of_no_return) {
-			/* we got to flush_old_exec() and failed after it */
-			read_unlock(&binfmt_lock);
-			force_sigsegv(SIGSEGV);
-			return retval;
-		}
-		if (retval != -ENOEXEC || !bprm->file) {
+		if (bprm->point_of_no_return || !bprm->file ||
+		    (retval != -ENOEXEC)) {
 			read_unlock(&binfmt_lock);
 			return retval;
 		}
@@ -1898,6 +1893,14 @@ static int __do_execve_file(int fd, struct filename *filename,
 	return retval;
 
 out:
+	/*
+	 * If past the point of no return ensure the the code never
+	 * returns to the userspace process.  Use an existing fatal
+	 * signal if present otherwise terminate the process with
+	 * SIGSEGV.
+	 */
+	if (bprm->point_of_no_return && !fatal_signal_pending(current))
+		force_sigsegv(SIGSEGV);
 	if (bprm->mm) {
 		acct_arg_size(bprm, 0);
 		mmput(bprm->mm);

commit a28bf136e651e17d7e2c753aa140ce3cc1df36a0
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Mar 30 16:33:39 2020 -0500

    exec: Run sync_mm_rss before taking exec_update_mutex
    
    Like exec_mm_release sync_mm_rss is about flushing out the state of
    the old_mm, which does not need to happen under exec_update_mutex.
    
    Make this explicit by moving sync_mm_rss outside of exec_update_mutex.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Link: https://lkml.kernel.org/r/875zd66za3.fsf_-_@x220.int.ebiederm.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 82106241ed53..ecee0ebebf85 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1051,13 +1051,14 @@ static int exec_mmap(struct mm_struct *mm)
 	tsk = current;
 	old_mm = current->mm;
 	exec_mm_release(tsk, old_mm);
+	if (old_mm)
+		sync_mm_rss(old_mm);
 
 	ret = mutex_lock_killable(&tsk->signal->exec_update_mutex);
 	if (ret)
 		return ret;
 
 	if (old_mm) {
-		sync_mm_rss(old_mm);
 		/*
 		 * Make sure that if there is a core dump in progress
 		 * for the old mm, we get out and die instead of going

commit 13c432b51449dcdcfa0350fb87250b1dbd1fbd12
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Mar 19 17:16:12 2020 -0500

    exec: Fix spelling of search_binary_handler in a comment
    
    Link: https://lkml.kernel.org/r/87h7wq6zc1.fsf_-_@x220.int.ebiederm.org
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index d4387bc92292..82106241ed53 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1296,7 +1296,7 @@ void __set_task_comm(struct task_struct *tsk, const char *buf, bool exec)
  * Calling this is the point of no return. None of the failures will be
  * seen by userspace since either the process is already taking a fatal
  * signal (via de_thread() or coredump), or will have SEGV raised
- * (after exec_mmap()) by search_binary_handlers (see below).
+ * (after exec_mmap()) by search_binary_handler (see below).
  */
 int begin_new_exec(struct linux_binprm * bprm)
 {

commit 7a60ef4803d5442804d75095627e81602ff23331
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Mar 8 12:04:44 2020 -0500

    exec: Move the comment from above de_thread to above unshare_sighand
    
    The comment describes work that now happens in unshare_sighand so
    move the comment where it makes sense.
    
    Link: https://lkml.kernel.org/r/87mu6i6zcs.fsf_-_@x220.int.ebiederm.org
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 3cc40048cc65..d4387bc92292 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1093,12 +1093,6 @@ static int exec_mmap(struct mm_struct *mm)
 	return 0;
 }
 
-/*
- * This function makes sure the current process has its own signal table,
- * so that flush_signal_handlers can later reset the handlers without
- * disturbing other processes.  (Other processes might share the signal
- * table via the CLONE_SIGHAND option to clone().)
- */
 static int de_thread(struct task_struct *tsk)
 {
 	struct signal_struct *sig = tsk->signal;
@@ -1240,6 +1234,12 @@ static int de_thread(struct task_struct *tsk)
 }
 
 
+/*
+ * This function makes sure the current process has its own signal table,
+ * so that flush_signal_handlers can later reset the handlers without
+ * disturbing other processes.  (Other processes might share the signal
+ * table via the CLONE_SIGHAND option to clone().)
+ */
 static int unshare_sighand(struct task_struct *me)
 {
 	struct sighand_struct *oldsighand = me->sighand;

commit 2388777a0a5957a10b3d78677216530a9b3bd09f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun May 3 07:54:10 2020 -0500

    exec: Rename flush_old_exec begin_new_exec
    
    There is and has been for a very long time been a lot more going on in
    flush_old_exec than just flushing the old state.  After the movement
    of code from setup_new_exec there is a whole lot more going on than
    just flushing the old executables state.
    
    Rename flush_old_exec to begin_new_exec to more accurately reflect
    what this function does.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Greg Ungerer <gerg@linux-m68k.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 0eff20558735..3cc40048cc65 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1298,7 +1298,7 @@ void __set_task_comm(struct task_struct *tsk, const char *buf, bool exec)
  * signal (via de_thread() or coredump), or will have SEGV raised
  * (after exec_mmap()) by search_binary_handlers (see below).
  */
-int flush_old_exec(struct linux_binprm * bprm)
+int begin_new_exec(struct linux_binprm * bprm)
 {
 	struct task_struct *me = current;
 	int retval;
@@ -1433,7 +1433,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 out:
 	return retval;
 }
-EXPORT_SYMBOL(flush_old_exec);
+EXPORT_SYMBOL(begin_new_exec);
 
 void would_dump(struct linux_binprm *bprm, struct file *file)
 {

commit df9e4d2c4a53503a97fc08eeebdc04e3c11b4618
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun May 3 07:15:28 2020 -0500

    exec: Move most of setup_new_exec into flush_old_exec
    
    The current idiom for the callers is:
    
    flush_old_exec(bprm);
    set_personality(...);
    setup_new_exec(bprm);
    
    In 2010 Linus split flush_old_exec into flush_old_exec and
    setup_new_exec.  With the intention that setup_new_exec be what is
    called after the processes new personality is set.
    
    Move the code that doesn't depend upon the personality from
    setup_new_exec into flush_old_exec.  This is to facilitate future
    changes by having as much code together in one function as possible.
    
    To see why it is safe to move this code please note that effectively
    this change moves the personality setting in the binfmt and the following
    three lines of code after everything except unlocking the mutexes:
            arch_pick_mmap_layout
            arch_setup_new_exec
            mm->task_size = TASK_SIZE
    
    The function arch_pick_mmap_layout at most sets:
            mm->get_unmapped_area
            mm->mmap_base
            mm->mmap_legacy_base
            mm->mmap_compat_base
            mm->mmap_compat_legacy_base
    which nothing in flush_old_exec or setup_new_exec depends on.
    
    The function arch_setup_new_exec only sets architecture specific
    state and the rest of the functions only deal in state that applies
    to all architectures.
    
    The last line just sets mm->task_size and again nothing in flush_old_exec
    or setup_new_exec depend on task_size.
    
    Ref: 221af7f87b97 ("Split 'flush_old_exec' into two functions")
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Greg Ungerer <gerg@linux-m68k.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 8c3abafb9bb1..0eff20558735 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1359,39 +1359,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 * undergoing exec(2).
 	 */
 	do_close_on_exec(me->files);
-	return 0;
-
-out_unlock:
-	mutex_unlock(&me->signal->exec_update_mutex);
-out:
-	return retval;
-}
-EXPORT_SYMBOL(flush_old_exec);
-
-void would_dump(struct linux_binprm *bprm, struct file *file)
-{
-	struct inode *inode = file_inode(file);
-	if (inode_permission(inode, MAY_READ) < 0) {
-		struct user_namespace *old, *user_ns;
-		bprm->interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP;
-
-		/* Ensure mm->user_ns contains the executable */
-		user_ns = old = bprm->mm->user_ns;
-		while ((user_ns != &init_user_ns) &&
-		       !privileged_wrt_inode_uidgid(user_ns, inode))
-			user_ns = user_ns->parent;
 
-		if (old != user_ns) {
-			bprm->mm->user_ns = get_user_ns(user_ns);
-			put_user_ns(old);
-		}
-	}
-}
-EXPORT_SYMBOL(would_dump);
-
-void setup_new_exec(struct linux_binprm * bprm)
-{
-	struct task_struct *me = current;
 	/*
 	 * Once here, prepare_binrpm() will not be called any more, so
 	 * the final state of setuid/setgid/fscaps can be merged into the
@@ -1414,8 +1382,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 			bprm->rlim_stack.rlim_cur = _STK_LIM;
 	}
 
-	arch_pick_mmap_layout(me->mm, &bprm->rlim_stack);
-
 	me->sas_ss_sp = me->sas_ss_size = 0;
 
 	/*
@@ -1430,16 +1396,9 @@ void setup_new_exec(struct linux_binprm * bprm)
 	else
 		set_dumpable(current->mm, SUID_DUMP_USER);
 
-	arch_setup_new_exec();
 	perf_event_exec();
 	__set_task_comm(me, kbasename(bprm->filename), true);
 
-	/* Set the new mm task size. We have to do that late because it may
-	 * depend on TIF_32BIT which is only updated in flush_thread() on
-	 * some architectures like powerpc
-	 */
-	me->mm->task_size = TASK_SIZE;
-
 	/* An exec changes our domain. We are no longer part of the thread
 	   group */
 	WRITE_ONCE(me->self_exec_id, me->self_exec_id + 1);
@@ -1467,6 +1426,50 @@ void setup_new_exec(struct linux_binprm * bprm)
 	 * credentials; any time after this it may be unlocked.
 	 */
 	security_bprm_committed_creds(bprm);
+	return 0;
+
+out_unlock:
+	mutex_unlock(&me->signal->exec_update_mutex);
+out:
+	return retval;
+}
+EXPORT_SYMBOL(flush_old_exec);
+
+void would_dump(struct linux_binprm *bprm, struct file *file)
+{
+	struct inode *inode = file_inode(file);
+	if (inode_permission(inode, MAY_READ) < 0) {
+		struct user_namespace *old, *user_ns;
+		bprm->interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP;
+
+		/* Ensure mm->user_ns contains the executable */
+		user_ns = old = bprm->mm->user_ns;
+		while ((user_ns != &init_user_ns) &&
+		       !privileged_wrt_inode_uidgid(user_ns, inode))
+			user_ns = user_ns->parent;
+
+		if (old != user_ns) {
+			bprm->mm->user_ns = get_user_ns(user_ns);
+			put_user_ns(old);
+		}
+	}
+}
+EXPORT_SYMBOL(would_dump);
+
+void setup_new_exec(struct linux_binprm * bprm)
+{
+	/* Setup things that can depend upon the personality */
+	struct task_struct *me = current;
+
+	arch_pick_mmap_layout(me->mm, &bprm->rlim_stack);
+
+	arch_setup_new_exec();
+
+	/* Set the new mm task size. We have to do that late because it may
+	 * depend on TIF_32BIT which is only updated in flush_thread() on
+	 * some architectures like powerpc
+	 */
+	me->mm->task_size = TASK_SIZE;
 	mutex_unlock(&me->signal->exec_update_mutex);
 	mutex_unlock(&me->signal->cred_guard_mutex);
 }

commit 7d503feba0c88586b4c9f1212e9cc582c9370fa7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Apr 2 18:35:14 2020 -0500

    exec: In setup_new_exec cache current in the local variable me
    
    At least gcc 8.3 when generating code for x86_64 has a hard time
    consolidating multiple calls to current aka get_current(), and winds
    up unnecessarily rereading %gs:current_task several times in
    setup_new_exec.
    
    Caching the value of current in the local variable of me generates
    slightly better and shorter assembly.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Greg Ungerer <gerg@linux-m68k.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 93e40f865523..8c3abafb9bb1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1391,6 +1391,7 @@ EXPORT_SYMBOL(would_dump);
 
 void setup_new_exec(struct linux_binprm * bprm)
 {
+	struct task_struct *me = current;
 	/*
 	 * Once here, prepare_binrpm() will not be called any more, so
 	 * the final state of setuid/setgid/fscaps can be merged into the
@@ -1400,7 +1401,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 
 	if (bprm->secureexec) {
 		/* Make sure parent cannot signal privileged process. */
-		current->pdeath_signal = 0;
+		me->pdeath_signal = 0;
 
 		/*
 		 * For secureexec, reset the stack limit to sane default to
@@ -1413,9 +1414,9 @@ void setup_new_exec(struct linux_binprm * bprm)
 			bprm->rlim_stack.rlim_cur = _STK_LIM;
 	}
 
-	arch_pick_mmap_layout(current->mm, &bprm->rlim_stack);
+	arch_pick_mmap_layout(me->mm, &bprm->rlim_stack);
 
-	current->sas_ss_sp = current->sas_ss_size = 0;
+	me->sas_ss_sp = me->sas_ss_size = 0;
 
 	/*
 	 * Figure out dumpability. Note that this checking only of current
@@ -1431,18 +1432,18 @@ void setup_new_exec(struct linux_binprm * bprm)
 
 	arch_setup_new_exec();
 	perf_event_exec();
-	__set_task_comm(current, kbasename(bprm->filename), true);
+	__set_task_comm(me, kbasename(bprm->filename), true);
 
 	/* Set the new mm task size. We have to do that late because it may
 	 * depend on TIF_32BIT which is only updated in flush_thread() on
 	 * some architectures like powerpc
 	 */
-	current->mm->task_size = TASK_SIZE;
+	me->mm->task_size = TASK_SIZE;
 
 	/* An exec changes our domain. We are no longer part of the thread
 	   group */
-	WRITE_ONCE(current->self_exec_id, current->self_exec_id + 1);
-	flush_signal_handlers(current, 0);
+	WRITE_ONCE(me->self_exec_id, me->self_exec_id + 1);
+	flush_signal_handlers(me, 0);
 
 	/*
 	 * install the new credentials for this executable
@@ -1458,16 +1459,16 @@ void setup_new_exec(struct linux_binprm * bprm)
 	 * wait until new credentials are committed
 	 * by commit_creds() above
 	 */
-	if (get_dumpable(current->mm) != SUID_DUMP_USER)
-		perf_event_exit_task(current);
+	if (get_dumpable(me->mm) != SUID_DUMP_USER)
+		perf_event_exit_task(me);
 	/*
 	 * cred_guard_mutex must be held at least to this point to prevent
 	 * ptrace_attach() from altering our determination of the task's
 	 * credentials; any time after this it may be unlocked.
 	 */
 	security_bprm_committed_creds(bprm);
-	mutex_unlock(&current->signal->exec_update_mutex);
-	mutex_unlock(&current->signal->cred_guard_mutex);
+	mutex_unlock(&me->signal->exec_update_mutex);
+	mutex_unlock(&me->signal->cred_guard_mutex);
 }
 EXPORT_SYMBOL(setup_new_exec);
 

commit 96ecee29b0b560662ec082ee9b6f2049f2a79090
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun May 3 06:48:17 2020 -0500

    exec: Merge install_exec_creds into setup_new_exec
    
    The two functions are now always called one right after the
    other so merge them together to make future maintenance easier.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Greg Ungerer <gerg@linux-m68k.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 71de9f57ae09..93e40f865523 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1443,6 +1443,31 @@ void setup_new_exec(struct linux_binprm * bprm)
 	   group */
 	WRITE_ONCE(current->self_exec_id, current->self_exec_id + 1);
 	flush_signal_handlers(current, 0);
+
+	/*
+	 * install the new credentials for this executable
+	 */
+	security_bprm_committing_creds(bprm);
+
+	commit_creds(bprm->cred);
+	bprm->cred = NULL;
+
+	/*
+	 * Disable monitoring for regular users
+	 * when executing setuid binaries. Must
+	 * wait until new credentials are committed
+	 * by commit_creds() above
+	 */
+	if (get_dumpable(current->mm) != SUID_DUMP_USER)
+		perf_event_exit_task(current);
+	/*
+	 * cred_guard_mutex must be held at least to this point to prevent
+	 * ptrace_attach() from altering our determination of the task's
+	 * credentials; any time after this it may be unlocked.
+	 */
+	security_bprm_committed_creds(bprm);
+	mutex_unlock(&current->signal->exec_update_mutex);
+	mutex_unlock(&current->signal->cred_guard_mutex);
 }
 EXPORT_SYMBOL(setup_new_exec);
 
@@ -1458,7 +1483,7 @@ EXPORT_SYMBOL(finalize_exec);
 
 /*
  * Prepare credentials and lock ->cred_guard_mutex.
- * install_exec_creds() commits the new creds and drops the lock.
+ * setup_new_exec() commits the new creds and drops the lock.
  * Or, if exec fails before, free_bprm() should release ->cred and
  * and unlock.
  */
@@ -1504,35 +1529,6 @@ int bprm_change_interp(const char *interp, struct linux_binprm *bprm)
 }
 EXPORT_SYMBOL(bprm_change_interp);
 
-/*
- * install the new credentials for this executable
- */
-void install_exec_creds(struct linux_binprm *bprm)
-{
-	security_bprm_committing_creds(bprm);
-
-	commit_creds(bprm->cred);
-	bprm->cred = NULL;
-
-	/*
-	 * Disable monitoring for regular users
-	 * when executing setuid binaries. Must
-	 * wait until new credentials are committed
-	 * by commit_creds() above
-	 */
-	if (get_dumpable(current->mm) != SUID_DUMP_USER)
-		perf_event_exit_task(current);
-	/*
-	 * cred_guard_mutex must be held at least to this point to prevent
-	 * ptrace_attach() from altering our determination of the task's
-	 * credentials; any time after this it may be unlocked.
-	 */
-	security_bprm_committed_creds(bprm);
-	mutex_unlock(&current->signal->exec_update_mutex);
-	mutex_unlock(&current->signal->cred_guard_mutex);
-}
-EXPORT_SYMBOL(install_exec_creds);
-
 /*
  * determine how safe it is to execute the proposed program
  * - the caller must hold ->cred_guard_mutex to protect against

commit 1507b7a30ad284a2a136ee79c214c0e86c62da64
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Apr 2 18:17:50 2020 -0500

    exec: Rename the flag called_exec_mmap point_of_no_return
    
    Update the comments and make the code easier to understand by
    renaming this flag.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Greg Ungerer <gerg@linux-m68k.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 6bd82a007bfc..71de9f57ae09 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1326,12 +1326,12 @@ int flush_old_exec(struct linux_binprm * bprm)
 		goto out;
 
 	/*
-	 * After setting bprm->called_exec_mmap (to mark that current is
-	 * using the prepared mm now), we have nothing left of the original
-	 * process. If anything from here on returns an error, the check
-	 * in search_binary_handler() will SEGV current.
+	 * With the new mm installed it is completely impossible to
+	 * fail and return to the original process.  If anything from
+	 * here on returns an error, the check in
+	 * search_binary_handler() will SEGV current.
 	 */
-	bprm->called_exec_mmap = 1;
+	bprm->point_of_no_return = true;
 	bprm->mm = NULL;
 
 #ifdef CONFIG_POSIX_TIMERS
@@ -1720,7 +1720,7 @@ int search_binary_handler(struct linux_binprm *bprm)
 
 		read_lock(&binfmt_lock);
 		put_binfmt(fmt);
-		if (retval < 0 && bprm->called_exec_mmap) {
+		if (retval < 0 && bprm->point_of_no_return) {
 			/* we got to flush_old_exec() and failed after it */
 			read_unlock(&binfmt_lock);
 			force_sigsegv(SIGSEGV);

commit 89826cce37542f7950e8f4b9258284805e98430c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Apr 2 18:04:54 2020 -0500

    exec: Make unlocking exec_update_mutex explict
    
    With install_exec_creds updated to follow immediately after
    setup_new_exec, the failure of unshare_sighand is the only
    code path where exec_update_mutex is held but not explicitly
    unlocked.
    
    Update that code path to explicitly unlock exec_update_mutex.
    
    Remove the unlocking of exec_update_mutex from free_bprm.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Greg Ungerer <gerg@linux-m68k.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 06b4c550af5d..6bd82a007bfc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1344,7 +1344,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 */
 	retval = unshare_sighand(me);
 	if (retval)
-		goto out;
+		goto out_unlock;
 
 	set_fs(USER_DS);
 	me->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD |
@@ -1361,6 +1361,8 @@ int flush_old_exec(struct linux_binprm * bprm)
 	do_close_on_exec(me->files);
 	return 0;
 
+out_unlock:
+	mutex_unlock(&me->signal->exec_update_mutex);
 out:
 	return retval;
 }
@@ -1477,8 +1479,6 @@ static void free_bprm(struct linux_binprm *bprm)
 {
 	free_arg_pages(bprm);
 	if (bprm->cred) {
-		if (bprm->called_exec_mmap)
-			mutex_unlock(&current->signal->exec_update_mutex);
 		mutex_unlock(&current->signal->cred_guard_mutex);
 		abort_creds(bprm->cred);
 	}

commit 610b818856e1477964b59040c740f6ec55883045
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Apr 26 07:51:03 2020 -0500

    exec: Remove BUG_ON(has_group_leader_pid)
    
    With the introduction of exchange_tids thread_group_leader and
    has_group_leader_pid have become equivalent.  Further at this point in the
    code a thread group has exactly two threads, the previous thread_group_leader
    that is waiting to be reaped and tsk.  So we know it is impossible for tsk to
    be the thread_group_leader.
    
    This is also the last user of has_group_leader_pid so removing this check
    will allow has_group_leader_pid to be removed.
    
    So remove the "BUG_ON(has_group_leader_pid)" that will never fire.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 9b60f927afd7..6ab1c19d84fa 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1176,7 +1176,6 @@ static int de_thread(struct task_struct *tsk)
 		tsk->start_boottime = leader->start_boottime;
 
 		BUG_ON(!same_thread_group(leader, tsk));
-		BUG_ON(has_group_leader_pid(tsk));
 		/*
 		 * An exec() starts a new thread group with the
 		 * TGID of the previous thread group. Rehash the

commit 6b03d1304a32dc8450c7516000a0fe07bef7c446
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Apr 19 06:35:02 2020 -0500

    proc: Ensure we see the exit of each process tid exactly once
    
    When the thread group leader changes during exec and the old leaders
    thread is reaped proc_flush_pid will flush the dentries for the entire
    process because the leader still has it's original pid.
    
    Fix this by exchanging the pids in an rcu safe manner,
    and wrapping the code to do that up in a helper exchange_tids.
    
    When I removed switch_exec_pids and introduced this behavior
    in d73d65293e3e ("[PATCH] pidhash: kill switch_exec_pids") there
    really was nothing that cared as flushing happened with
    the cached dentry and de_thread flushed both of them on exec.
    
    This lack of fully exchanging pids became a problem a few months later
    when I introduced 48e6484d4902 ("[PATCH] proc: Rewrite the proc dentry
    flush on exit optimization").  Which overlooked the de_thread case
    was no longer swapping pids, and I was looking up proc dentries
    by task->pid.
    
    The current behavior isn't properly a bug as everything in proc will
    continue to work correctly just a little bit less efficiently.  Fix
    this just so there are no little surprise corner cases waiting to bite
    people.
    
    -- Oleg points out this could be an issue in next_tgid in proc where
       has_group_leader_pid is called, and reording some of the assignments
       should fix that.
    
    -- Oleg points out this will break the 10 year old hack in __exit_signal.c
    >       /*
    >        * This can only happen if the caller is de_thread().
    >        * FIXME: this is the temporary hack, we should teach
    >        * posix-cpu-timers to handle this case correctly.
    >        */
    >       if (unlikely(has_group_leader_pid(tsk)))
    >               posix_cpu_timers_exit_group(tsk);
    
    The code in next_tgid has been changed to use PIDTYPE_TGID,
    and the posix cpu timers code has been fixed so it does not
    need the 10 year old hack, so this should be safe to merge
    now.
    
    Link: https://lore.kernel.org/lkml/87h7x3ajll.fsf_-_@x220.int.ebiederm.org/
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Fixes: 48e6484d4902 ("[PATCH] proc: Rewrite the proc dentry flush on exit optimization").
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 06b4c550af5d..9b60f927afd7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1186,11 +1186,8 @@ static int de_thread(struct task_struct *tsk)
 
 		/* Become a process group leader with the old leader's pid.
 		 * The old leader becomes a thread of the this thread group.
-		 * Note: The old leader also uses this pid until release_task
-		 *       is called.  Odd but simple and correct.
 		 */
-		tsk->pid = leader->pid;
-		change_pid(tsk, PIDTYPE_PID, task_pid(leader));
+		exchange_tids(tsk, leader);
 		transfer_pid(leader, tsk, PIDTYPE_TGID);
 		transfer_pid(leader, tsk, PIDTYPE_PGID);
 		transfer_pid(leader, tsk, PIDTYPE_SID);

commit d987ca1c6b7e22fbd30664111e85cec7aa66000d
Merge: 919dce24701f d1e7fd6462ca
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 2 11:22:17 2020 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull exec/proc updates from Eric Biederman:
     "This contains two significant pieces of work: the work to sort out
      proc_flush_task, and the work to solve a deadlock between strace and
      exec.
    
      Fixing proc_flush_task so that it no longer requires a persistent
      mount makes improvements to proc possible. The removal of the
      persistent mount solves an old regression that that caused the hidepid
      mount option to only work on remount not on mount. The regression was
      found and reported by the Android folks. This further allows Alexey
      Gladkov's work making proc mount options specific to an individual
      mount of proc to move forward.
    
      The work on exec starts solving a long standing issue with exec that
      it takes mutexes of blocking userspace applications, which makes exec
      extremely deadlock prone. For the moment this adds a second mutex with
      a narrower scope that handles all of the easy cases. Which makes the
      tricky cases easy to spot. With a little luck the code to solve those
      deadlocks will be ready by next merge window"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (25 commits)
      signal: Extend exec_id to 64bits
      pidfd: Use new infrastructure to fix deadlocks in execve
      perf: Use new infrastructure to fix deadlocks in execve
      proc: io_accounting: Use new infrastructure to fix deadlocks in execve
      proc: Use new infrastructure to fix deadlocks in execve
      kernel/kcmp.c: Use new infrastructure to fix deadlocks in execve
      kernel: doc: remove outdated comment cred.c
      mm: docs: Fix a comment in process_vm_rw_core
      selftests/ptrace: add test cases for dead-locks
      exec: Fix a deadlock in strace
      exec: Add exec_update_mutex to replace cred_guard_mutex
      exec: Move exec_mmap right after de_thread in flush_old_exec
      exec: Move cleanup of posix timers on exec out of de_thread
      exec: Factor unshare_sighand out of de_thread and call it separately
      exec: Only compute current once in flush_old_exec
      pid: Improve the comment about waiting in zap_pid_ns_processes
      proc: Remove the now unnecessary internal mount of proc
      uml: Create a private mount of proc for mconsole
      uml: Don't consult current to find the proc_mnt in mconsole_proc
      proc: Use a list of inodes to flush from proc
      ...

commit d1e7fd6462ca9fc76650fbe6ca800e35b24267da
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Mar 30 19:01:04 2020 -0500

    signal: Extend exec_id to 64bits
    
    Replace the 32bit exec_id with a 64bit exec_id to make it impossible
    to wrap the exec_id counter.  With care an attacker can cause exec_id
    wrap and send arbitrary signals to a newly exec'd parent.  This
    bypasses the signal sending checks if the parent changes their
    credentials during exec.
    
    The severity of this problem can been seen that in my limited testing
    of a 32bit exec_id it can take as little as 19s to exec 65536 times.
    Which means that it can take as little as 14 days to wrap a 32bit
    exec_id.  Adam Zabrocki has succeeded wrapping the self_exe_id in 7
    days.  Even my slower timing is in the uptime of a typical server.
    Which means self_exec_id is simply a speed bump today, and if exec
    gets noticably faster self_exec_id won't even be a speed bump.
    
    Extending self_exec_id to 64bits introduces a problem on 32bit
    architectures where reading self_exec_id is no longer atomic and can
    take two read instructions.  Which means that is is possible to hit
    a window where the read value of exec_id does not match the written
    value.  So with very lucky timing after this change this still
    remains expoiltable.
    
    I have updated the update of exec_id on exec to use WRITE_ONCE
    and the read of exec_id in do_notify_parent to use READ_ONCE
    to make it clear that there is no locking between these two
    locations.
    
    Link: https://lore.kernel.org/kernel-hardening/20200324215049.GA3710@pi3.com.pl
    Fixes: 2.3.23pre2
    Cc: stable@vger.kernel.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 0e46ec57fe0a..d55710a36056 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1413,7 +1413,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 
 	/* An exec changes our domain. We are no longer part of the thread
 	   group */
-	current->self_exec_id++;
+	WRITE_ONCE(current->self_exec_id, current->self_exec_id + 1);
 	flush_signal_handlers(current, 0);
 }
 EXPORT_SYMBOL(setup_new_exec);

commit eea9673250db4e854e9998ef9da6d4584857f0ea
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Mar 25 10:03:36 2020 -0500

    exec: Add exec_update_mutex to replace cred_guard_mutex
    
    The cred_guard_mutex is problematic as it is held over possibly
    indefinite waits for userspace.  The possible indefinite waits for
    userspace that I have identified are: The cred_guard_mutex is held in
    PTRACE_EVENT_EXIT waiting for the tracer.  The cred_guard_mutex is
    held over "put_user(0, tsk->clear_child_tid)" in exit_mm().  The
    cred_guard_mutex is held over "get_user(futex_offset, ...")  in
    exit_robust_list.  The cred_guard_mutex held over copy_strings.
    
    The functions get_user and put_user can trigger a page fault which can
    potentially wait indefinitely in the case of userfaultfd or if
    userspace implements part of the page fault path.
    
    In any of those cases the userspace process that the kernel is waiting
    for might make a different system call that winds up taking the
    cred_guard_mutex and result in deadlock.
    
    Holding a mutex over any of those possibly indefinite waits for
    userspace does not appear necessary.  Add exec_update_mutex that will
    just cover updating the process during exec where the permissions and
    the objects pointed to by the task struct may be out of sync.
    
    The plan is to switch the users of cred_guard_mutex to
    exec_update_mutex one by one.  This lets us move forward while still
    being careful and not introducing any regressions.
    
    Link: https://lore.kernel.org/lkml/20160921152946.GA24210@dhcp22.suse.cz/
    Link: https://lore.kernel.org/lkml/AM6PR03MB5170B06F3A2B75EFB98D071AE4E60@AM6PR03MB5170.eurprd03.prod.outlook.com/
    Link: https://lore.kernel.org/linux-fsdevel/20161102181806.GB1112@redhat.com/
    Link: https://lore.kernel.org/lkml/20160923095031.GA14923@redhat.com/
    Link: https://lore.kernel.org/lkml/20170213141452.GA30203@redhat.com/
    Ref: 45c1a159b85b ("Add PTRACE_O_TRACEVFORKDONE and PTRACE_O_TRACEEXIT facilities.")
    Ref: 456f17cd1a28 ("[PATCH] user-vm-unlock-2.5.31-A2")
    Reviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index d820a7272a76..0e46ec57fe0a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1010,16 +1010,26 @@ ssize_t read_code(struct file *file, unsigned long addr, loff_t pos, size_t len)
 }
 EXPORT_SYMBOL(read_code);
 
+/*
+ * Maps the mm_struct mm into the current task struct.
+ * On success, this function returns with the mutex
+ * exec_update_mutex locked.
+ */
 static int exec_mmap(struct mm_struct *mm)
 {
 	struct task_struct *tsk;
 	struct mm_struct *old_mm, *active_mm;
+	int ret;
 
 	/* Notify parent that we're no longer interested in the old VM */
 	tsk = current;
 	old_mm = current->mm;
 	exec_mm_release(tsk, old_mm);
 
+	ret = mutex_lock_killable(&tsk->signal->exec_update_mutex);
+	if (ret)
+		return ret;
+
 	if (old_mm) {
 		sync_mm_rss(old_mm);
 		/*
@@ -1031,9 +1041,11 @@ static int exec_mmap(struct mm_struct *mm)
 		down_read(&old_mm->mmap_sem);
 		if (unlikely(old_mm->core_state)) {
 			up_read(&old_mm->mmap_sem);
+			mutex_unlock(&tsk->signal->exec_update_mutex);
 			return -EINTR;
 		}
 	}
+
 	task_lock(tsk);
 	active_mm = tsk->active_mm;
 	membarrier_exec_mmap(mm);
@@ -1288,11 +1300,12 @@ int flush_old_exec(struct linux_binprm * bprm)
 		goto out;
 
 	/*
-	 * After clearing bprm->mm (to mark that current is using the
-	 * prepared mm now), we have nothing left of the original
+	 * After setting bprm->called_exec_mmap (to mark that current is
+	 * using the prepared mm now), we have nothing left of the original
 	 * process. If anything from here on returns an error, the check
 	 * in search_binary_handler() will SEGV current.
 	 */
+	bprm->called_exec_mmap = 1;
 	bprm->mm = NULL;
 
 #ifdef CONFIG_POSIX_TIMERS
@@ -1438,6 +1451,8 @@ static void free_bprm(struct linux_binprm *bprm)
 {
 	free_arg_pages(bprm);
 	if (bprm->cred) {
+		if (bprm->called_exec_mmap)
+			mutex_unlock(&current->signal->exec_update_mutex);
 		mutex_unlock(&current->signal->cred_guard_mutex);
 		abort_creds(bprm->cred);
 	}
@@ -1487,6 +1502,7 @@ void install_exec_creds(struct linux_binprm *bprm)
 	 * credentials; any time after this it may be unlocked.
 	 */
 	security_bprm_committed_creds(bprm);
+	mutex_unlock(&current->signal->exec_update_mutex);
 	mutex_unlock(&current->signal->cred_guard_mutex);
 }
 EXPORT_SYMBOL(install_exec_creds);
@@ -1678,7 +1694,7 @@ int search_binary_handler(struct linux_binprm *bprm)
 
 		read_lock(&binfmt_lock);
 		put_binfmt(fmt);
-		if (retval < 0 && !bprm->mm) {
+		if (retval < 0 && bprm->called_exec_mmap) {
 			/* we got to flush_old_exec() and failed after it */
 			read_unlock(&binfmt_lock);
 			force_sigsegv(SIGSEGV);

commit ccf0fa6be02687868006fa0c85af32c40cae6fb6
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Mar 25 10:03:21 2020 -0500

    exec: Move exec_mmap right after de_thread in flush_old_exec
    
    I have read through the code in exec_mmap and I do not see anything
    that depends on sighand or the sighand lock, or on signals in anyway
    so this should be safe.
    
    This rearrangement of code has two significant benefits.  It makes
    the determination of passing the point of no return by testing bprm->mm
    accurate.  All failures prior to that point in flush_old_exec are
    either truly recoverable or they are fatal.
    
    Further this consolidates all of the possible indefinite waits for
    userspace together at the top of flush_old_exec.  The possible wait
    for a ptracer on PTRACE_EVENT_EXIT, the possible wait for a page fault
    to be resolved in clear_child_tid, and the possible wait for a page
    fault in exit_robust_list.
    
    This consolidation allows the creation of a mutex to replace
    cred_guard_mutex that is not held over possible indefinite userspace
    waits.  Which will allow removing deadlock scenarios from the kernel.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Reviewed-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Signed-off-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 215d86f77b63..d820a7272a76 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1272,18 +1272,6 @@ int flush_old_exec(struct linux_binprm * bprm)
 	if (retval)
 		goto out;
 
-#ifdef CONFIG_POSIX_TIMERS
-	exit_itimers(me->signal);
-	flush_itimer_signals();
-#endif
-
-	/*
-	 * Make the signal table private.
-	 */
-	retval = unshare_sighand(me);
-	if (retval)
-		goto out;
-
 	/*
 	 * Must be called _before_ exec_mmap() as bprm->mm is
 	 * not visibile until then. This also enables the update
@@ -1307,6 +1295,18 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 */
 	bprm->mm = NULL;
 
+#ifdef CONFIG_POSIX_TIMERS
+	exit_itimers(me->signal);
+	flush_itimer_signals();
+#endif
+
+	/*
+	 * Make the signal table private.
+	 */
+	retval = unshare_sighand(me);
+	if (retval)
+		goto out;
+
 	set_fs(USER_DS);
 	me->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD |
 					PF_NOFREEZE | PF_NO_SETAFFINITY);

commit 153ffb6ba49fd80dc607a9f230415af02b728d70
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Mar 25 10:00:38 2020 -0500

    exec: Move cleanup of posix timers on exec out of de_thread
    
    These functions have very little to do with de_thread move them out
    of de_thread an into flush_old_exec proper so it can be more clearly
    seen what flush_old_exec is doing.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Reviewed-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Signed-off-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index ff74b9a74d34..215d86f77b63 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1189,11 +1189,6 @@ static int de_thread(struct task_struct *tsk)
 	/* we have changed execution domain */
 	tsk->exit_signal = SIGCHLD;
 
-#ifdef CONFIG_POSIX_TIMERS
-	exit_itimers(sig);
-	flush_itimer_signals();
-#endif
-
 	BUG_ON(!thread_group_leader(tsk));
 	return 0;
 
@@ -1277,6 +1272,11 @@ int flush_old_exec(struct linux_binprm * bprm)
 	if (retval)
 		goto out;
 
+#ifdef CONFIG_POSIX_TIMERS
+	exit_itimers(me->signal);
+	flush_itimer_signals();
+#endif
+
 	/*
 	 * Make the signal table private.
 	 */

commit 021691559245498dfa15454c9fc4351f367d0b7f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Mar 25 10:00:21 2020 -0500

    exec: Factor unshare_sighand out of de_thread and call it separately
    
    This makes the code clearer and makes it easier to implement a mutex
    that is not taken over any locations that may block indefinitely waiting
    for userspace.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Reviewed-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Signed-off-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index c3f34791f2f0..ff74b9a74d34 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1194,6 +1194,23 @@ static int de_thread(struct task_struct *tsk)
 	flush_itimer_signals();
 #endif
 
+	BUG_ON(!thread_group_leader(tsk));
+	return 0;
+
+killed:
+	/* protects against exit_notify() and __exit_signal() */
+	read_lock(&tasklist_lock);
+	sig->group_exit_task = NULL;
+	sig->notify_count = 0;
+	read_unlock(&tasklist_lock);
+	return -EAGAIN;
+}
+
+
+static int unshare_sighand(struct task_struct *me)
+{
+	struct sighand_struct *oldsighand = me->sighand;
+
 	if (refcount_read(&oldsighand->count) != 1) {
 		struct sighand_struct *newsighand;
 		/*
@@ -1210,23 +1227,13 @@ static int de_thread(struct task_struct *tsk)
 
 		write_lock_irq(&tasklist_lock);
 		spin_lock(&oldsighand->siglock);
-		rcu_assign_pointer(tsk->sighand, newsighand);
+		rcu_assign_pointer(me->sighand, newsighand);
 		spin_unlock(&oldsighand->siglock);
 		write_unlock_irq(&tasklist_lock);
 
 		__cleanup_sighand(oldsighand);
 	}
-
-	BUG_ON(!thread_group_leader(tsk));
 	return 0;
-
-killed:
-	/* protects against exit_notify() and __exit_signal() */
-	read_lock(&tasklist_lock);
-	sig->group_exit_task = NULL;
-	sig->notify_count = 0;
-	read_unlock(&tasklist_lock);
-	return -EAGAIN;
 }
 
 char *__get_task_comm(char *buf, size_t buf_size, struct task_struct *tsk)
@@ -1264,13 +1271,19 @@ int flush_old_exec(struct linux_binprm * bprm)
 	int retval;
 
 	/*
-	 * Make sure we have a private signal table and that
-	 * we are unassociated from the previous thread group.
+	 * Make this the only thread in the thread group.
 	 */
 	retval = de_thread(me);
 	if (retval)
 		goto out;
 
+	/*
+	 * Make the signal table private.
+	 */
+	retval = unshare_sighand(me);
+	if (retval)
+		goto out;
+
 	/*
 	 * Must be called _before_ exec_mmap() as bprm->mm is
 	 * not visibile until then. This also enables the update

commit 2ca7be7d55ad84fb0f7c2a23fb700a28fd76b19a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Mar 25 10:00:07 2020 -0500

    exec: Only compute current once in flush_old_exec
    
    Make it clear that current only needs to be computed once in
    flush_old_exec.  This may have some efficiency improvements and it
    makes the code easier to change.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Reviewed-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Signed-off-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index db17be51b112..c3f34791f2f0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1260,13 +1260,14 @@ void __set_task_comm(struct task_struct *tsk, const char *buf, bool exec)
  */
 int flush_old_exec(struct linux_binprm * bprm)
 {
+	struct task_struct *me = current;
 	int retval;
 
 	/*
 	 * Make sure we have a private signal table and that
 	 * we are unassociated from the previous thread group.
 	 */
-	retval = de_thread(current);
+	retval = de_thread(me);
 	if (retval)
 		goto out;
 
@@ -1294,10 +1295,10 @@ int flush_old_exec(struct linux_binprm * bprm)
 	bprm->mm = NULL;
 
 	set_fs(USER_DS);
-	current->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD |
+	me->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD |
 					PF_NOFREEZE | PF_NO_SETAFFINITY);
 	flush_thread();
-	current->personality &= ~bprm->per_clear;
+	me->personality &= ~bprm->per_clear;
 
 	/*
 	 * We have to apply CLOEXEC before we change whether the process is
@@ -1305,7 +1306,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 * trying to access the should-be-closed file descriptors of a process
 	 * undergoing exec(2).
 	 */
-	do_close_on_exec(current->files);
+	do_close_on_exec(me->files);
 	return 0;
 
 out:

commit 901cff7cb96140a658a848a568b606ba764239bc
Author: Topi Miettinen <toiwoton@gmail.com>
Date:   Thu Jan 23 14:58:38 2020 +0200

    firmware_loader: load files from the mount namespace of init
    
    I have an experimental setup where almost every possible system
    service (even early startup ones) runs in separate namespace, using a
    dedicated, minimal file system. In process of minimizing the contents
    of the file systems with regards to modules and firmware files, I
    noticed that in my system, the firmware files are loaded from three
    different mount namespaces, those of systemd-udevd, init and
    systemd-networkd. The logic of the source namespace is not very clear,
    it seems to depend on the driver, but the namespace of the current
    process is used.
    
    So, this patch tries to make things a bit clearer and changes the
    loading of firmware files only from the mount namespace of init. This
    may also improve security, though I think that using firmware files as
    attack vector could be too impractical anyway.
    
    Later, it might make sense to make the mount namespace configurable,
    for example with a new file in /proc/sys/kernel/firmware_config/. That
    would allow a dedicated file system only for firmware files and those
    need not be present anywhere else. This configurability would make
    more sense if made also for kernel modules and /sbin/modprobe. Modules
    are already loaded from init namespace (usermodehelper uses kthreadd
    namespace) except when directly loaded by systemd-udevd.
    
    Instead of using the mount namespace of the current process to load
    firmware files, use the mount namespace of init process.
    
    Link: https://lore.kernel.org/lkml/bb46ebae-4746-90d9-ec5b-fce4c9328c86@gmail.com/
    Link: https://lore.kernel.org/lkml/0e3f7653-c59d-9341-9db2-c88f5b988c68@gmail.com/
    Signed-off-by: Topi Miettinen <toiwoton@gmail.com>
    Link: https://lore.kernel.org/r/20200123125839.37168-1-toiwoton@gmail.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index db17be51b112..688c824cdac8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -985,6 +985,32 @@ int kernel_read_file_from_path(const char *path, void **buf, loff_t *size,
 }
 EXPORT_SYMBOL_GPL(kernel_read_file_from_path);
 
+int kernel_read_file_from_path_initns(const char *path, void **buf,
+				      loff_t *size, loff_t max_size,
+				      enum kernel_read_file_id id)
+{
+	struct file *file;
+	struct path root;
+	int ret;
+
+	if (!path || !*path)
+		return -EINVAL;
+
+	task_lock(&init_task);
+	get_fs_root(init_task.fs, &root);
+	task_unlock(&init_task);
+
+	file = file_open_root(root.dentry, root.mnt, path, O_RDONLY, 0);
+	path_put(&root);
+	if (IS_ERR(file))
+		return PTR_ERR(file);
+
+	ret = kernel_read_file(file, buf, size, max_size, id);
+	fput(file);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(kernel_read_file_from_path_initns);
+
 int kernel_read_file_from_fd(int fd, void **buf, loff_t *size, loff_t max_size,
 			     enum kernel_read_file_id id)
 {

commit 7eec11d3a784a283f916590e5aa30b855c2ccfd7
Merge: ddaefe8947b4 43e76af85fa7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 31 12:16:36 2020 -0800

    Merge branch 'akpm' (patches from Andrew)
    
    Pull updates from Andrew Morton:
     "Most of -mm and quite a number of other subsystems: hotfixes, scripts,
      ocfs2, misc, lib, binfmt, init, reiserfs, exec, dma-mapping, kcov.
    
      MM is fairly quiet this time.  Holidays, I assume"
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (118 commits)
      kcov: ignore fault-inject and stacktrace
      include/linux/io-mapping.h-mapping: use PHYS_PFN() macro in io_mapping_map_atomic_wc()
      execve: warn if process starts with executable stack
      reiserfs: prevent NULL pointer dereference in reiserfs_insert_item()
      init/main.c: fix misleading "This architecture does not have kernel memory protection" message
      init/main.c: fix quoted value handling in unknown_bootoption
      init/main.c: remove unnecessary repair_env_string in do_initcall_level
      init/main.c: log arguments and environment passed to init
      fs/binfmt_elf.c: coredump: allow process with empty address space to coredump
      fs/binfmt_elf.c: coredump: delete duplicated overflow check
      fs/binfmt_elf.c: coredump: allocate core ELF header on stack
      fs/binfmt_elf.c: make BAD_ADDR() unlikely
      fs/binfmt_elf.c: better codegen around current->mm
      fs/binfmt_elf.c: don't copy ELF header around
      fs/binfmt_elf.c: fix ->start_code calculation
      fs/binfmt_elf.c: smaller code generation around auxv vector fill
      lib/find_bit.c: uninline helper _find_next_bit()
      lib/find_bit.c: join _find_next_bit{_le}
      uapi: rename ext2_swab() to swab() and share globally in swab.h
      lib/scatterlist.c: adjust indentation in __sg_alloc_table
      ...

commit 47a2ebb7f5053387f5753b524f4920b9b829f922
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Thu Jan 30 22:17:29 2020 -0800

    execve: warn if process starts with executable stack
    
    There were few episodes of silent downgrade to an executable stack over
    years:
    
    1) linking innocent looking assembly file will silently add executable
       stack if proper linker options is not given as well:
    
            $ cat f.S
            .intel_syntax noprefix
            .text
            .globl f
            f:
                    ret
    
            $ cat main.c
            void f(void);
            int main(void)
            {
                    f();
                    return 0;
            }
    
            $ gcc main.c f.S
            $ readelf -l ./a.out
              GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                             0x0000000000000000 0x0000000000000000  RWE    0x10
                                                                     ^^^
    
    2) converting C99 nested function into a closure
       https://nullprogram.com/blog/2019/11/15/
    
            void intsort2(int *base, size_t nmemb, _Bool invert)
            {
                int cmp(const void *a, const void *b)
                {
                    int r = *(int *)a - *(int *)b;
                    return invert ? -r : r;
                }
                qsort(base, nmemb, sizeof(*base), cmp);
            }
    
    will silently require stack trampolines while non-closure version will
    not.
    
    Without doubt this behaviour is documented somewhere, add a warning so
    that developers and users can at least notice.  After so many years of
    x86_64 having proper executable stack support it should not cause too
    many problems.
    
    Link: http://lkml.kernel.org/r/20191208171918.GC19716@avx2
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Dan Carpenter <dan.carpenter@oracle.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 74d88dab98dd..7f4e0a89aaa8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -761,6 +761,11 @@ int setup_arg_pages(struct linux_binprm *bprm,
 		goto out_unlock;
 	BUG_ON(prev != vma);
 
+	if (unlikely(vm_flags & VM_EXEC)) {
+		pr_warn_once("process '%pD4' started with executable stack\n",
+			     bprm->file);
+	}
+
 	/* Move stack pages down in memory. */
 	if (stack_shift) {
 		ret = shift_arg_pages(vma, stack_shift);

commit ccaaaf6fe5a5e1fffca5cca0f3fc4ec84d7ae752
Merge: 35c222fd3236 45fc24e89b7c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 30 16:11:50 2020 -0800

    Merge tag 'mpx-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/daveh/x86-mpx
    
    Pull x86 MPX removal from Dave Hansen:
     "MPX requires recompiling applications, which requires compiler
      support. Unfortunately, GCC 9.1 is expected to be be released without
      support for MPX. This means that there was only a relatively small
      window where folks could have ever used MPX. It failed to gain wide
      adoption in the industry, and Linux was the only mainstream OS to ever
      support it widely.
    
      Support for the feature may also disappear on future processors.
    
      This set completes the process that we started during the 5.4 merge
      window when the MPX prctl()s were removed. XSAVE support is left in
      place, which allows MPX-using KVM guests to continue to function"
    
    * tag 'mpx-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/daveh/x86-mpx:
      x86/mpx: remove MPX from arch/x86
      mm: remove arch_bprm_mm_init() hook
      x86/mpx: remove bounds exception code
      x86/mpx: remove build infrastructure
      x86/alternatives: add missing insn.h include

commit 42222eae17f7c930833dfda7896ef280879de94a
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Thu Jan 23 10:41:16 2020 -0800

    mm: remove arch_bprm_mm_init() hook
    
    From: Dave Hansen <dave.hansen@linux.intel.com>
    
    MPX is being removed from the kernel due to a lack of support
    in the toolchain going forward (gcc).
    
    arch_bprm_mm_init() is used at execve() time.  The only non-stub
    implementation is on x86 for MPX.  Remove the hook entirely from
    all architectures and generic code.
    
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: x86@kernel.org
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: linux-arch@vger.kernel.org
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Anton Ivanov <anton.ivanov@cambridgegreys.com>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>

diff --git a/fs/exec.c b/fs/exec.c
index 555e93c7dec8..6303057e0f13 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -273,7 +273,6 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 		goto err;
 
 	mm->stack_vm = mm->total_vm = 1;
-	arch_bprm_mm_init(mm, vma);
 	up_write(&mm->mmap_sem);
 	bprm->p = vma->vm_end - sizeof(void *);
 	return 0;

commit 043cf46825c102683b1027762c09c7e2b749e5a3
Merge: b22bfea7f16c 83bae01182ea
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 3 12:20:25 2019 -0800

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer updates from Ingo Molnar:
     "The main changes in the timer code in this cycle were:
    
       - Clockevent updates:
    
          - timer-of framework cleanups. (Geert Uytterhoeven)
    
          - Use timer-of for the renesas-ostm and the device name to prevent
            name collision in case of multiple timers. (Geert Uytterhoeven)
    
          - Check if there is an error after calling of_clk_get in asm9260
            (Chuhong Yuan)
    
       - ABI fix: Zero out high order bits of nanoseconds on compat
         syscalls. This got broken a year ago, with apparently no side
         effects so far.
    
         Since the kernel would use random data otherwise I don't think we'd
         have other options but to fix the bug, even if there was a side
         effect to applications (Dmitry Safonov)
    
       - Optimize ns_to_timespec64() on 32-bit systems: move away from
         div_s64_rem() which can be slow, to div_u64_rem() which is faster
         (Arnd Bergmann)
    
       - Annotate KCSAN-reported false positive data races in
         hrtimer_is_queued() users by moving timer->state handling over to
         the READ_ONCE()/WRITE_ONCE() APIs. This documents these accesses
         (Eric Dumazet)
    
       - Misc cleanups and small fixes"
    
    [ I undid the "ABI fix" and updated the comments instead. The reason
      there were apparently no side effects is that the fix was a no-op.
    
      The updated comment is to say _why_ it was a no-op.    - Linus ]
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      time: Zero the upper 32-bits in __kernel_timespec on 32-bit
      time: Rename tsk->real_start_time to ->start_boottime
      hrtimer: Remove the comment about not used HRTIMER_SOFTIRQ
      time: Fix spelling mistake in comment
      time: Optimize ns_to_timespec64()
      hrtimer: Annotate lockless access to timer->state
      clocksource/drivers/asm9260: Add a check for of_clk_get
      clocksource/drivers/renesas-ostm: Use unique device name instead of ostm
      clocksource/drivers/renesas-ostm: Convert to timer_of
      clocksource/drivers/timer-of: Use unique device name instead of timer
      clocksource/drivers/timer-of: Convert last full_name to %pOF

commit 6a965666b7e7475c2f8c8e724703db58b8a8a445
Merge: 32ef9553635a 3c0edea9b29f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Nov 30 14:12:13 2019 -0800

    Merge tag 'notifications-pipe-prep-20191115' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-fs
    
    Pull pipe rework from David Howells:
     "This is my set of preparatory patches for building a general
      notification queue on top of pipes. It makes a number of significant
      changes:
    
       - It removes the nr_exclusive argument from __wake_up_sync_key() as
         this is always 1. This prepares for the next step:
    
       - Adds wake_up_interruptible_sync_poll_locked() so that poll can be
         woken up from a function that's holding the poll waitqueue
         spinlock.
    
       - Change the pipe buffer ring to be managed in terms of unbounded
         head and tail indices rather than bounded index and length. This
         means that reading the pipe only needs to modify one index, not
         two.
    
       - A selection of helper functions are provided to query the state of
         the pipe buffer, plus a couple to apply updates to the pipe
         indices.
    
       - The pipe ring is allowed to have kernel-reserved slots. This allows
         many notification messages to be spliced in by the kernel without
         allowing userspace to pin too many pages if it writes to the same
         pipe.
    
       - Advance the head and tail indices inside the pipe waitqueue lock
         and use wake_up_interruptible_sync_poll_locked() to poke poll
         without having to take the lock twice.
    
       - Rearrange pipe_write() to preallocate the buffer it is going to
         write into and then drop the spinlock. This allows kernel
         notifications to then be added the ring whilst it is filling the
         buffer it allocated. The read side is stalled because the pipe
         mutex is still held.
    
       - Don't wake up readers on a pipe if there was already data in it
         when we added more.
    
       - Don't wake up writers on a pipe if the ring wasn't full before we
         removed a buffer"
    
    * tag 'notifications-pipe-prep-20191115' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-fs:
      pipe: Remove sync on wake_ups
      pipe: Increase the writer-wakeup threshold to reduce context-switch count
      pipe: Check for ring full inside of the spinlock in pipe_write()
      pipe: Remove redundant wakeup from pipe_write()
      pipe: Rearrange sequence in pipe_write() to preallocate slot
      pipe: Conditionalise wakeup in pipe_read()
      pipe: Advance tail pointer inside of wait spinlock in pipe_read()
      pipe: Allow pipes to have kernel-reserved slots
      pipe: Use head and tail pointers for the ring, not cursor and length
      Add wake_up_interruptible_sync_poll_locked()
      Remove the nr_exclusive argument from __wake_up_sync_key()
      pipe: Reduce #inclusion of pipe_fs_i.h

commit 4610ba7ad877fafc0a25a30c6c82015304120426
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Nov 6 22:55:38 2019 +0100

    exit/exec: Seperate mm_release()
    
    mm_release() contains the futex exit handling. mm_release() is called from
    do_exit()->exit_mm() and from exec()->exec_mm().
    
    In the exit_mm() case PF_EXITING and the futex state is updated. In the
    exec_mm() case these states are not touched.
    
    As the futex exit code needs further protections against exit races, this
    needs to be split into two functions.
    
    Preparatory only, no functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20191106224556.240518241@linutronix.de

diff --git a/fs/exec.c b/fs/exec.c
index 555e93c7dec8..c27231234764 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1015,7 +1015,7 @@ static int exec_mmap(struct mm_struct *mm)
 	/* Notify parent that we're no longer interested in the old VM */
 	tsk = current;
 	old_mm = current->mm;
-	mm_release(tsk, old_mm);
+	exec_mm_release(tsk, old_mm);
 
 	if (old_mm) {
 		sync_mm_rss(old_mm);

commit cf25e24db61cc9df42c47485a2ec2bff4e9a3692
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Nov 7 11:07:58 2019 +0100

    time: Rename tsk->real_start_time to ->start_boottime
    
    Since it stores CLOCK_BOOTTIME, not, as the name suggests,
    CLOCK_REALTIME, let's rename ->real_start_time to ->start_bootime.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 555e93c7dec8..f4d0f3acf861 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1132,7 +1132,7 @@ static int de_thread(struct task_struct *tsk)
 		 * also take its birthdate (always earlier than our own).
 		 */
 		tsk->start_time = leader->start_time;
-		tsk->real_start_time = leader->real_start_time;
+		tsk->start_boottime = leader->start_boottime;
 
 		BUG_ON(!same_thread_group(leader, tsk));
 		BUG_ON(has_group_leader_pid(tsk));

commit d055b4fb4d165b06d912e7f846610d120c3bb9fb
Author: David Howells <dhowells@redhat.com>
Date:   Wed Sep 25 15:23:01 2019 +0100

    pipe: Reduce #inclusion of pipe_fs_i.h
    
    Remove some #inclusions of linux/pipe_fs_i.h that don't seem to be
    necessary any more.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index 555e93c7dec8..57bc7ef8d31b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -59,7 +59,6 @@
 #include <linux/kmod.h>
 #include <linux/fsnotify.h>
 #include <linux/fs_struct.h>
-#include <linux/pipe_fs_i.h>
 #include <linux/oom.h>
 #include <linux/compat.h>
 #include <linux/vmalloc.h>

commit 227a4aadc75ba22fcb6c4e1c078817b8cbaae4ce
Author: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date:   Thu Sep 19 13:37:02 2019 -0400

    sched/membarrier: Fix p->mm->membarrier_state racy load
    
    The membarrier_state field is located within the mm_struct, which
    is not guaranteed to exist when used from runqueue-lock-free iteration
    on runqueues by the membarrier system call.
    
    Copy the membarrier_state from the mm_struct into the scheduler runqueue
    when the scheduler switches between mm.
    
    When registering membarrier for mm, after setting the registration bit
    in the mm membarrier state, issue a synchronize_rcu() to ensure the
    scheduler observes the change. In order to take care of the case
    where a runqueue keeps executing the target mm without swapping to
    other mm, iterate over each runqueue and issue an IPI to copy the
    membarrier_state from the mm_struct into each runqueue which have the
    same mm which state has just been modified.
    
    Move the mm membarrier_state field closer to pgd in mm_struct to use
    a cache line already touched by the scheduler switch_mm.
    
    The membarrier_execve() (now membarrier_exec_mmap) hook now needs to
    clear the runqueue's membarrier state in addition to clear the mm
    membarrier state, so move its implementation into the scheduler
    membarrier code so it can access the runqueue structure.
    
    Add memory barrier in membarrier_exec_mmap() prior to clearing
    the membarrier state, ensuring memory accesses executed prior to exec
    are not reordered with the stores clearing the membarrier state.
    
    As suggested by Linus, move all membarrier.c RCU read-side locks outside
    of the for each cpu loops.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Kirill Tkhai <tkhai@yandex.ru>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Paul E. McKenney <paulmck@linux.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King - ARM Linux admin <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20190919173705.2181-5-mathieu.desnoyers@efficios.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index f7f6a140856a..555e93c7dec8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1033,6 +1033,7 @@ static int exec_mmap(struct mm_struct *mm)
 	}
 	task_lock(tsk);
 	active_mm = tsk->active_mm;
+	membarrier_exec_mmap(mm);
 	tsk->mm = mm;
 	tsk->active_mm = mm;
 	activate_mm(active_mm, mm);
@@ -1825,7 +1826,6 @@ static int __do_execve_file(int fd, struct filename *filename,
 	/* execve succeeded */
 	current->fs->in_exec = 0;
 	current->in_execve = 0;
-	membarrier_execve(current);
 	rseq_execve(current);
 	acct_update_integrals(current);
 	task_numa_free(current, false);

commit 16d51a590a8ce3befb1308e0e7ab77f3b661af33
Author: Jann Horn <jannh@google.com>
Date:   Tue Jul 16 17:20:45 2019 +0200

    sched/fair: Don't free p->numa_faults with concurrent readers
    
    When going through execve(), zero out the NUMA fault statistics instead of
    freeing them.
    
    During execve, the task is reachable through procfs and the scheduler. A
    concurrent /proc/*/sched reader can read data from a freed ->numa_faults
    allocation (confirmed by KASAN) and write it back to userspace.
    I believe that it would also be possible for a use-after-free read to occur
    through a race between a NUMA fault and execve(): task_numa_fault() can
    lead to task_numa_compare(), which invokes task_weight() on the currently
    running task of a different CPU.
    
    Another way to fix this would be to make ->numa_faults RCU-managed or add
    extra locking, but it seems easier to wipe the NUMA fault statistics on
    execve.
    
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will@kernel.org>
    Fixes: 82727018b0d3 ("sched/numa: Call task_numa_free() from do_execve()")
    Link: https://lkml.kernel.org/r/20190716152047.14424-1-jannh@google.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index c71cbfe6826a..f7f6a140856a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1828,7 +1828,7 @@ static int __do_execve_file(int fd, struct filename *filename,
 	membarrier_execve(current);
 	rseq_execve(current);
 	acct_update_integrals(current);
-	task_numa_free(current);
+	task_numa_free(current, false);
 	free_bprm(bprm);
 	kfree(pathbuf);
 	if (filename)

commit 5ad18b2e60b75c7297a998dea702451d33a052ed
Merge: 92c1d6522135 318759b4737c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 21:48:15 2019 -0700

    Merge branch 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull force_sig() argument change from Eric Biederman:
     "A source of error over the years has been that force_sig has taken a
      task parameter when it is only safe to use force_sig with the current
      task.
    
      The force_sig function is built for delivering synchronous signals
      such as SIGSEGV where the userspace application caused a synchronous
      fault (such as a page fault) and the kernel responded with a signal.
    
      Because the name force_sig does not make this clear, and because the
      force_sig takes a task parameter the function force_sig has been
      abused for sending other kinds of signals over the years. Slowly those
      have been fixed when the oopses have been tracked down.
    
      This set of changes fixes the remaining abusers of force_sig and
      carefully rips out the task parameter from force_sig and friends
      making this kind of error almost impossible in the future"
    
    * 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (27 commits)
      signal/x86: Move tsk inside of CONFIG_MEMORY_FAILURE in do_sigbus
      signal: Remove the signal number and task parameters from force_sig_info
      signal: Factor force_sig_info_to_task out of force_sig_info
      signal: Generate the siginfo in force_sig
      signal: Move the computation of force into send_signal and correct it.
      signal: Properly set TRACE_SIGNAL_LOSE_INFO in __send_signal
      signal: Remove the task parameter from force_sig_fault
      signal: Use force_sig_fault_to_task for the two calls that don't deliver to current
      signal: Explicitly call force_sig_fault on current
      signal/unicore32: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from ptrace_break
      signal/nds32: Remove tsk parameter from send_sigtrap
      signal/riscv: Remove tsk parameter from do_trap
      signal/sh: Remove tsk parameter from force_sig_info_fault
      signal/um: Remove task parameter from send_sigtrap
      signal/x86: Remove task parameter from send_sigtrap
      signal: Remove task parameter from force_sig_mceerr
      signal: Remove task parameter from force_sig
      signal: Remove task parameter from force_sigsegv
      ...

commit cb44c9a0ab21a9ae4dfcabac1ed8e38aa872d1af
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue May 21 10:03:48 2019 -0500

    signal: Remove task parameter from force_sigsegv
    
    The function force_sigsegv is always called on the current task
    so passing in current is redundant and not passing in current
    makes this fact obvious.
    
    This also makes it clear force_sigsegv always calls force_sig
    on the current task.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index d88584ebf07f..f5568e45d521 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1662,7 +1662,7 @@ int search_binary_handler(struct linux_binprm *bprm)
 		if (retval < 0 && !bprm->mm) {
 			/* we got to flush_old_exec() and failed after it */
 			read_unlock(&binfmt_lock);
-			force_sigsegv(SIGSEGV, current);
+			force_sigsegv(SIGSEGV);
 			return retval;
 		}
 		if (retval != -ENOEXEC || !bprm->file) {

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index d88584ebf07f..89a500bb897a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  *  linux/fs/exec.c
  *

commit d53ddd0181d1c284c28c0d70a3d7039db41c6f7e
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Tue May 14 15:44:37 2019 -0700

    fs/exec.c: move ->recursion_depth out of critical sections
    
    ->recursion_depth is changed only by current, therefore decrementing can
    be done without taking any locks.
    
    Link: http://lkml.kernel.org/r/20190417213150.GA26474@avx2
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2e0033348d8e..d88584ebf07f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1652,11 +1652,13 @@ int search_binary_handler(struct linux_binprm *bprm)
 		if (!try_module_get(fmt->module))
 			continue;
 		read_unlock(&binfmt_lock);
+
 		bprm->recursion_depth++;
 		retval = fmt->load_binary(bprm);
+		bprm->recursion_depth--;
+
 		read_lock(&binfmt_lock);
 		put_binfmt(fmt);
-		bprm->recursion_depth--;
 		if (retval < 0 && !bprm->mm) {
 			/* we got to flush_old_exec() and failed after it */
 			read_unlock(&binfmt_lock);

commit 6eb3c3d0a52dca337e327ae8868ca1f44a712e02
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Mar 7 16:29:26 2019 -0800

    exec: increase BINPRM_BUF_SIZE to 256
    
    Large enterprise clients often run applications out of networked file
    systems where the IT mandated layout of project volumes can end up
    leading to paths that are longer than 128 characters.  Bumping this up
    to the next order of two solves this problem in all but the most
    egregious case while still fitting into a 512b slab.
    
    [oleg@redhat.com: update comment, per Kees]
    Link: http://lkml.kernel.org/r/20181112160956.GA28472@redhat.com
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reported-by: Ben Woodard <woodard@redhat.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index bf0ace3841ad..2e0033348d8e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1563,7 +1563,7 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
 
 /*
  * Fill the binprm structure from the inode.
- * Check permissions, then read the first 128 (BINPRM_BUF_SIZE) bytes
+ * Check permissions, then read the first BINPRM_BUF_SIZE bytes
  *
  * This may be called multiple times for binary chains (scripts for example).
  */

commit 26e152252e92999b975fe935c666a090c46905f7
Author: Vineet Gupta <vineet.gupta1@synopsys.com>
Date:   Thu Mar 7 16:29:23 2019 -0800

    fs/exec.c: replace opencoded set_mask_bits()
    
    Link: http://lkml.kernel.org/r/1548275584-18096-2-git-send-email-vgupta@synopsys.com
    Link: http://lkml.kernel.org/g/20150807115710.GA16897@redhat.com
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>
    Reviewed-by: Anthony Yznaga <anthony.yznaga@oracle.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jani Nikula <jani.nikula@intel.com>
    Cc: Miklos Szeredi <mszeredi@redhat.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 74f3672146a7..bf0ace3841ad 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1944,15 +1944,10 @@ EXPORT_SYMBOL(set_binfmt);
  */
 void set_dumpable(struct mm_struct *mm, int value)
 {
-	unsigned long old, new;
-
 	if (WARN_ON((unsigned)value > SUID_DUMP_ROOT))
 		return;
 
-	do {
-		old = READ_ONCE(mm->flags);
-		new = (old & ~MMF_DUMPABLE_MASK) | value;
-	} while (cmpxchg(&mm->flags, old, new) != old);
+	set_mask_bits(&mm->flags, MMF_DUMPABLE_MASK, value);
 }
 
 SYSCALL_DEFINE3(execve,

commit 45802da05e666a81b421422d3e302930c0e24e77
Merge: 203b6609e0ed ad01423aedaa
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 6 08:14:05 2019 -0800

    Merge branch 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull scheduler updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - refcount conversions
    
       - Solve the rq->leaf_cfs_rq_list can of worms for real.
    
       - improve power-aware scheduling
    
       - add sysctl knob for Energy Aware Scheduling
    
       - documentation updates
    
       - misc other changes"
    
    * 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (34 commits)
      kthread: Do not use TIMER_IRQSAFE
      kthread: Convert worker lock to raw spinlock
      sched/fair: Use non-atomic cpumask_{set,clear}_cpu()
      sched/fair: Remove unused 'sd' parameter from select_idle_smt()
      sched/wait: Use freezable_schedule() when possible
      sched/fair: Prune, fix and simplify the nohz_balancer_kick() comment block
      sched/fair: Explain LLC nohz kick condition
      sched/fair: Simplify nohz_balancer_kick()
      sched/topology: Fix percpu data types in struct sd_data & struct s_data
      sched/fair: Simplify post_init_entity_util_avg() by calling it with a task_struct pointer argument
      sched/fair: Fix O(nr_cgroups) in the load balancing path
      sched/fair: Optimize update_blocked_averages()
      sched/fair: Fix insertion in rq->leaf_cfs_rq_list
      sched/fair: Add tmp_alone_branch assertion
      sched/core: Use READ_ONCE()/WRITE_ONCE() in move_queued_task()/task_rq_lock()
      sched/debug: Initialize sd_sysctl_cpus if !CONFIG_CPUMASK_OFFSTACK
      sched/pelt: Skip updating util_est when utilization is higher than CPU's capacity
      sched/fair: Update scale invariance of PELT
      sched/fair: Move the rq_of() helper function
      sched/core: Convert task_struct.stack_refcount to refcount_t
      ...

commit f612acfae86af7ecad754ae6a46019be9da05b8e
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Tue Feb 19 10:10:38 2019 +0800

    exec: Fix mem leak in kernel_read_file
    
    syzkaller report this:
    BUG: memory leak
    unreferenced object 0xffffc9000488d000 (size 9195520):
      comm "syz-executor.0", pid 2752, jiffies 4294787496 (age 18.757s)
      hex dump (first 32 bytes):
        ff ff ff ff ff ff ff ff a8 00 00 00 01 00 00 00  ................
        02 00 00 00 00 00 00 00 80 a1 7a c1 ff ff ff ff  ..........z.....
      backtrace:
        [<000000000863775c>] __vmalloc_node mm/vmalloc.c:1795 [inline]
        [<000000000863775c>] __vmalloc_node_flags mm/vmalloc.c:1809 [inline]
        [<000000000863775c>] vmalloc+0x8c/0xb0 mm/vmalloc.c:1831
        [<000000003f668111>] kernel_read_file+0x58f/0x7d0 fs/exec.c:924
        [<000000002385813f>] kernel_read_file_from_fd+0x49/0x80 fs/exec.c:993
        [<0000000011953ff1>] __do_sys_finit_module+0x13b/0x2a0 kernel/module.c:3895
        [<000000006f58491f>] do_syscall_64+0x147/0x600 arch/x86/entry/common.c:290
        [<00000000ee78baf4>] entry_SYSCALL_64_after_hwframe+0x49/0xbe
        [<00000000241f889b>] 0xffffffffffffffff
    
    It should goto 'out_free' lable to free allocated buf while kernel_read
    fails.
    
    Fixes: 39d637af5aa7 ("vfs: forbid write access when reading a file into memory")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index fb72d36f7823..bcf383730bea 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -932,7 +932,7 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 		bytes = kernel_read(file, *buf + pos, i_size - pos, &pos);
 		if (bytes < 0) {
 			ret = bytes;
-			goto out;
+			goto out_free;
 		}
 
 		if (bytes == 0)

commit d036bda7d0e7269c2982eb979acfef855f5d7977
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Jan 18 14:27:26 2019 +0200

    sched/core: Convert sighand_struct.count to refcount_t
    
    atomic_t variables are currently used to implement reference
    counters with the following properties:
    
     - counter is initialized to 1 using atomic_set()
     - a resource is freed upon counter reaching zero
     - once counter reaches zero, its further
       increments aren't allowed
     - counter schema uses basic atomic operations
       (set, inc, inc_not_zero, dec_and_test, etc.)
    
    Such atomic variables should be converted to a newly provided
    refcount_t type and API that prevents accidental counter overflows
    and underflows. This is important since overflows and underflows
    can lead to use-after-free situation and be exploitable.
    
    The variable sighand_struct.count is used as pure reference counter.
    Convert it to refcount_t and fix up the operations.
    
    ** Important note for maintainers:
    
    Some functions from refcount_t API defined in lib/refcount.c
    have different memory ordering guarantees than their atomic
    counterparts.
    
    The full comparison can be seen in
    https://lkml.org/lkml/2017/11/15/57 and it is hopefully soon
    in state to be merged to the documentation tree.
    
    Normally the differences should not matter since refcount_t provides
    enough guarantees to satisfy the refcounting use cases, but in
    some rare cases it might matter.
    
    Please double check that you don't have some undocumented
    memory guarantees for this variable usage.
    
    For the sighand_struct.count it might make a difference
    in following places:
    
     - __cleanup_sighand: decrement in refcount_dec_and_test() only
       provides RELEASE ordering and control dependency on success
       vs. fully ordered atomic counterpart
    
    Suggested-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: David Windsor <dwindsor@gmail.com>
    Reviewed-by: Hans Liljestrand <ishkamiel@gmail.com>
    Reviewed-by: Andrea Parri <andrea.parri@amarulasolutions.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: akpm@linux-foundation.org
    Cc: viro@zeniv.linux.org.uk
    Link: https://lkml.kernel.org/r/1547814450-18902-2-git-send-email-elena.reshetova@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index fb72d36f7823..966cd98a2ce2 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1189,7 +1189,7 @@ static int de_thread(struct task_struct *tsk)
 	flush_itimer_signals();
 #endif
 
-	if (atomic_read(&oldsighand->count) != 1) {
+	if (refcount_read(&oldsighand->count) != 1) {
 		struct sighand_struct *newsighand;
 		/*
 		 * This ->sighand is shared with the CLONE_SIGHAND
@@ -1199,7 +1199,7 @@ static int de_thread(struct task_struct *tsk)
 		if (!newsighand)
 			return -ENOMEM;
 
-		atomic_set(&newsighand->count, 1);
+		refcount_set(&newsighand->count, 1);
 		memcpy(newsighand->action, oldsighand->action,
 		       sizeof(newsighand->action));
 

commit 9b286efeb5eb5aaa2712873fc1f928b2f879dbde
Merge: 47f3f4eb7834 e4f2283cc6ff
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 5 13:18:59 2019 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull trivial vfs updates from Al Viro:
     "A few cleanups + Neil's namespace_unlock() optimization"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      exec: make prepare_bprm_creds static
      genheaders: %-<width>s had been there since v6; %-*s - since v7
      VFS: use synchronize_rcu_expedited() in namespace_unlock()
      iov_iter: reduce code duplication

commit 08d405c8b845a4b871fa3606c9ebe0d0f3b74614
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Thu Jan 3 15:28:58 2019 -0800

    fs/: remove caller signal_pending branch predictions
    
    This is already done for us internally by the signal machinery.
    
    [akpm@linux-foundation.org: fix fs/buffer.c]
    Link: http://lkml.kernel.org/r/20181116002713.8474-7-dave@stgolabs.net
    Signed-off-by: Davidlohr Bueso <dave@stgolabs.net>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ea7d439cf79e..44320d893f1a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1087,7 +1087,7 @@ static int de_thread(struct task_struct *tsk)
 		__set_current_state(TASK_KILLABLE);
 		spin_unlock_irq(lock);
 		schedule();
-		if (unlikely(__fatal_signal_pending(tsk)))
+		if (__fatal_signal_pending(tsk))
 			goto killed;
 		spin_lock_irq(lock);
 	}
@@ -1115,7 +1115,7 @@ static int de_thread(struct task_struct *tsk)
 			write_unlock_irq(&tasklist_lock);
 			cgroup_threadgroup_change_end(tsk);
 			schedule();
-			if (unlikely(__fatal_signal_pending(tsk)))
+			if (__fatal_signal_pending(tsk))
 				goto killed;
 		}
 

commit 655c16a8ce9c15842547f40ce23fd148aeccc074
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 3 15:28:11 2019 -0800

    exec: separate MM_ANONPAGES and RLIMIT_STACK accounting
    
    get_arg_page() checks bprm->rlim_stack.rlim_cur and re-calculates the
    "extra" size for argv/envp pointers every time, this is a bit ugly and
    even not strictly correct: acct_arg_size() must not account this size.
    
    Remove all the rlimit code in get_arg_page().  Instead, add bprm->argmin
    calculated once at the start of __do_execve_file() and change
    copy_strings to check bprm->p >= bprm->argmin.
    
    The patch adds the new helper, prepare_arg_pages() which initializes
    bprm->argc/envc and bprm->argmin.
    
    [oleg@redhat.com: fix !CONFIG_MMU version of get_arg_page()]
      Link: http://lkml.kernel.org/r/20181126122307.GA1660@redhat.com
    [akpm@linux-foundation.org: use max_t]
    Link: http://lkml.kernel.org/r/20181112160910.GA28440@redhat.com
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index fc281b738a98..ea7d439cf79e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -218,55 +218,10 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 	if (ret <= 0)
 		return NULL;
 
-	if (write) {
-		unsigned long size = bprm->vma->vm_end - bprm->vma->vm_start;
-		unsigned long ptr_size, limit;
-
-		/*
-		 * Since the stack will hold pointers to the strings, we
-		 * must account for them as well.
-		 *
-		 * The size calculation is the entire vma while each arg page is
-		 * built, so each time we get here it's calculating how far it
-		 * is currently (rather than each call being just the newly
-		 * added size from the arg page).  As a result, we need to
-		 * always add the entire size of the pointers, so that on the
-		 * last call to get_arg_page() we'll actually have the entire
-		 * correct size.
-		 */
-		ptr_size = (bprm->argc + bprm->envc) * sizeof(void *);
-		if (ptr_size > ULONG_MAX - size)
-			goto fail;
-		size += ptr_size;
-
-		acct_arg_size(bprm, size / PAGE_SIZE);
-
-		/*
-		 * We've historically supported up to 32 pages (ARG_MAX)
-		 * of argument strings even with small stacks
-		 */
-		if (size <= ARG_MAX)
-			return page;
-
-		/*
-		 * Limit to 1/4 of the max stack size or 3/4 of _STK_LIM
-		 * (whichever is smaller) for the argv+env strings.
-		 * This ensures that:
-		 *  - the remaining binfmt code will not run out of stack space,
-		 *  - the program will have a reasonable amount of stack left
-		 *    to work from.
-		 */
-		limit = _STK_LIM / 4 * 3;
-		limit = min(limit, bprm->rlim_stack.rlim_cur / 4);
-		if (size > limit)
-			goto fail;
-	}
+	if (write)
+		acct_arg_size(bprm, vma_pages(bprm->vma));
 
 	return page;
-
-fail:
-	put_page(page);
-	return NULL;
 }
 
 static void put_arg_page(struct page *page)
@@ -492,6 +447,50 @@ static int count(struct user_arg_ptr argv, int max)
 	return i;
 }
 
+static int prepare_arg_pages(struct linux_binprm *bprm,
+			struct user_arg_ptr argv, struct user_arg_ptr envp)
+{
+	unsigned long limit, ptr_size;
+
+	bprm->argc = count(argv, MAX_ARG_STRINGS);
+	if (bprm->argc < 0)
+		return bprm->argc;
+
+	bprm->envc = count(envp, MAX_ARG_STRINGS);
+	if (bprm->envc < 0)
+		return bprm->envc;
+
+	/*
+	 * Limit to 1/4 of the max stack size or 3/4 of _STK_LIM
+	 * (whichever is smaller) for the argv+env strings.
+	 * This ensures that:
+	 *  - the remaining binfmt code will not run out of stack space,
+	 *  - the program will have a reasonable amount of stack left
+	 *    to work from.
+	 */
+	limit = _STK_LIM / 4 * 3;
+	limit = min(limit, bprm->rlim_stack.rlim_cur / 4);
+	/*
+	 * We've historically supported up to 32 pages (ARG_MAX)
+	 * of argument strings even with small stacks
+	 */
+	limit = max_t(unsigned long, limit, ARG_MAX);
+	/*
+	 * We must account for the size of all the argv and envp pointers to
+	 * the argv and envp strings, since they will also take up space in
+	 * the stack. They aren't stored until much later when we can't
+	 * signal to the parent that the child has run out of stack space.
+	 * Instead, calculate it here so it's possible to fail gracefully.
+	 */
+	ptr_size = (bprm->argc + bprm->envc) * sizeof(void *);
+	if (limit <= ptr_size)
+		return -E2BIG;
+	limit -= ptr_size;
+
+	bprm->argmin = bprm->p - limit;
+	return 0;
+}
+
 /*
  * 'copy_strings()' copies argument/environment strings from the old
  * processes's memory to the new process's stack.  The call to get_user_pages()
@@ -527,6 +526,10 @@ static int copy_strings(int argc, struct user_arg_ptr argv,
 		pos = bprm->p;
 		str += len;
 		bprm->p -= len;
+#ifdef CONFIG_MMU
+		if (bprm->p < bprm->argmin)
+			goto out;
+#endif
 
 		while (len > 0) {
 			int offset, bytes_to_copy;
@@ -1789,12 +1792,8 @@ static int __do_execve_file(int fd, struct filename *filename,
 	if (retval)
 		goto out_unmark;
 
-	bprm->argc = count(argv, MAX_ARG_STRINGS);
-	if ((retval = bprm->argc) < 0)
-		goto out;
-
-	bprm->envc = count(envp, MAX_ARG_STRINGS);
-	if ((retval = bprm->envc) < 0)
+	retval = prepare_arg_pages(bprm, argv, envp);
+	if (retval < 0)
 		goto out;
 
 	retval = prepare_binprm(bprm);

commit 4addd2640fcaeb150b42a8a352b6c9d13d6c00af
Author: Chanho Min <chanho.min@lge.com>
Date:   Mon Dec 10 16:49:54 2018 +0900

    exec: make prepare_bprm_creds static
    
    prepare_bprm_creds is not used outside exec.c, so there's no reason for it
    to have external linkage.
    
    Signed-off-by: Chanho Min <chanho.min@lge.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index fc281b738a98..b6c9e5f9f330 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1399,7 +1399,7 @@ EXPORT_SYMBOL(finalize_exec);
  * Or, if exec fails before, free_bprm() should release ->cred and
  * and unlock.
  */
-int prepare_bprm_creds(struct linux_binprm *bprm)
+static int prepare_bprm_creds(struct linux_binprm *bprm)
 {
 	if (mutex_lock_interruptible(&current->signal->cred_guard_mutex))
 		return -ERESTARTNOINTR;

commit a72173ecfc6774cf2d55de9fb29421ce69e3428c
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Dec 3 13:04:18 2018 +0100

    Revert "exec: make de_thread() freezable"
    
    Revert commit c22397888f1e "exec: make de_thread() freezable" as
    requested by Ingo Molnar:
    
    "So there's a new regression in v4.20-rc4, my desktop produces this
    lockdep splat:
    
    [ 1772.588771] WARNING: pkexec/4633 still has locks held!
    [ 1772.588773] 4.20.0-rc4-custom-00213-g93a49841322b #1 Not tainted
    [ 1772.588775] ------------------------------------
    [ 1772.588776] 1 lock held by pkexec/4633:
    [ 1772.588778]  #0: 00000000ed85fbf8 (&sig->cred_guard_mutex){+.+.}, at: prepare_bprm_creds+0x2a/0x70
    [ 1772.588786] stack backtrace:
    [ 1772.588789] CPU: 7 PID: 4633 Comm: pkexec Not tainted 4.20.0-rc4-custom-00213-g93a49841322b #1
    [ 1772.588792] Call Trace:
    [ 1772.588800]  dump_stack+0x85/0xcb
    [ 1772.588803]  flush_old_exec+0x116/0x890
    [ 1772.588807]  ? load_elf_phdrs+0x72/0xb0
    [ 1772.588809]  load_elf_binary+0x291/0x1620
    [ 1772.588815]  ? sched_clock+0x5/0x10
    [ 1772.588817]  ? search_binary_handler+0x6d/0x240
    [ 1772.588820]  search_binary_handler+0x80/0x240
    [ 1772.588823]  load_script+0x201/0x220
    [ 1772.588825]  search_binary_handler+0x80/0x240
    [ 1772.588828]  __do_execve_file.isra.32+0x7d2/0xa60
    [ 1772.588832]  ? strncpy_from_user+0x40/0x180
    [ 1772.588835]  __x64_sys_execve+0x34/0x40
    [ 1772.588838]  do_syscall_64+0x60/0x1c0
    
    The warning gets triggered by an ancient lockdep check in the freezer:
    
    (gdb) list *0xffffffff812ece06
    0xffffffff812ece06 is in flush_old_exec (./include/linux/freezer.h:57).
    52       * DO NOT ADD ANY NEW CALLERS OF THIS FUNCTION
    53       * If try_to_freeze causes a lockdep warning it means the caller may deadlock
    54       */
    55      static inline bool try_to_freeze_unsafe(void)
    56      {
    57              might_sleep();
    58              if (likely(!freezing(current)))
    59                      return false;
    60              return __refrigerator(false);
    61      }
    
    I reviewed the ->cred_guard_mutex code, and the mutex is held across all
    of exec() - and we always did this.
    
    But there's this recent -rc4 commit:
    
    > Chanho Min (1):
    >       exec: make de_thread() freezable
    
      c22397888f1e: exec: make de_thread() freezable
    
    I believe this commit is bogus, you cannot call try_to_freeze() from
    de_thread(), because it's holding the ->cred_guard_mutex."
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Tested-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/fs/exec.c b/fs/exec.c
index acc3a5536384..fc281b738a98 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -62,7 +62,6 @@
 #include <linux/oom.h>
 #include <linux/compat.h>
 #include <linux/vmalloc.h>
-#include <linux/freezer.h>
 
 #include <linux/uaccess.h>
 #include <asm/mmu_context.h>
@@ -1084,7 +1083,7 @@ static int de_thread(struct task_struct *tsk)
 	while (sig->notify_count) {
 		__set_current_state(TASK_KILLABLE);
 		spin_unlock_irq(lock);
-		freezable_schedule();
+		schedule();
 		if (unlikely(__fatal_signal_pending(tsk)))
 			goto killed;
 		spin_lock_irq(lock);
@@ -1112,7 +1111,7 @@ static int de_thread(struct task_struct *tsk)
 			__set_current_state(TASK_KILLABLE);
 			write_unlock_irq(&tasklist_lock);
 			cgroup_threadgroup_change_end(tsk);
-			freezable_schedule();
+			schedule();
 			if (unlikely(__fatal_signal_pending(tsk)))
 				goto killed;
 		}

commit c22397888f1eed98cd59f0a88f2a5f6925f80e15
Author: Chanho Min <chanho.min@lge.com>
Date:   Mon Nov 12 12:54:45 2018 +0900

    exec: make de_thread() freezable
    
    Suspend fails due to the exec family of functions blocking the freezer.
    The casue is that de_thread() sleeps in TASK_UNINTERRUPTIBLE waiting for
    all sub-threads to die, and we have the deadlock if one of them is frozen.
    This also can occur with the schedule() waiting for the group thread leader
    to exit if it is frozen.
    
    In our machine, it causes freeze timeout as bellows.
    
    Freezing of tasks failed after 20.010 seconds (1 tasks refusing to freeze, wq_busy=0):
    setcpushares-ls D ffffffc00008ed70     0  5817   1483 0x0040000d
     Call trace:
    [<ffffffc00008ed70>] __switch_to+0x88/0xa0
    [<ffffffc000d1c30c>] __schedule+0x1bc/0x720
    [<ffffffc000d1ca90>] schedule+0x40/0xa8
    [<ffffffc0001cd784>] flush_old_exec+0xdc/0x640
    [<ffffffc000220360>] load_elf_binary+0x2a8/0x1090
    [<ffffffc0001ccff4>] search_binary_handler+0x9c/0x240
    [<ffffffc00021c584>] load_script+0x20c/0x228
    [<ffffffc0001ccff4>] search_binary_handler+0x9c/0x240
    [<ffffffc0001ce8e0>] do_execveat_common.isra.14+0x4f8/0x6e8
    [<ffffffc0001cedd0>] compat_SyS_execve+0x38/0x48
    [<ffffffc00008de30>] el0_svc_naked+0x24/0x28
    
    To fix this, make de_thread() freezable. It looks safe and works fine.
    
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Chanho Min <chanho.min@lge.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Pavel Machek <pavel@ucw.cz>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/fs/exec.c b/fs/exec.c
index fc281b738a98..acc3a5536384 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -62,6 +62,7 @@
 #include <linux/oom.h>
 #include <linux/compat.h>
 #include <linux/vmalloc.h>
+#include <linux/freezer.h>
 
 #include <linux/uaccess.h>
 #include <asm/mmu_context.h>
@@ -1083,7 +1084,7 @@ static int de_thread(struct task_struct *tsk)
 	while (sig->notify_count) {
 		__set_current_state(TASK_KILLABLE);
 		spin_unlock_irq(lock);
-		schedule();
+		freezable_schedule();
 		if (unlikely(__fatal_signal_pending(tsk)))
 			goto killed;
 		spin_lock_irq(lock);
@@ -1111,7 +1112,7 @@ static int de_thread(struct task_struct *tsk)
 			__set_current_state(TASK_KILLABLE);
 			write_unlock_irq(&tasklist_lock);
 			cgroup_threadgroup_change_end(tsk);
-			schedule();
+			freezable_schedule();
 			if (unlikely(__fatal_signal_pending(tsk)))
 				goto killed;
 		}

commit 691115c3513ec83edf68ba6575ae85630bc94b8b
Author: Eric Biggers <ebiggers@google.com>
Date:   Fri Sep 7 12:16:24 2018 -0700

    vfs: require i_size <= SIZE_MAX in kernel_read_file()
    
    On 32-bit systems, the buffer allocated by kernel_read_file() is too
    small if the file size is > SIZE_MAX, due to truncation to size_t.
    
    Fortunately, since the 'count' argument to kernel_read() is also
    truncated to size_t, only the allocated space is filled; then, -EIO is
    returned since 'pos != i_size' after the read loop.
    
    But this is not obvious and seems incidental.  We should be more
    explicit about this case.  So, fail early if i_size > SIZE_MAX.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>

diff --git a/fs/exec.c b/fs/exec.c
index 1ebf6e5a521d..fc281b738a98 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -908,14 +908,14 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 		goto out;
 
 	i_size = i_size_read(file_inode(file));
-	if (max_size > 0 && i_size > max_size) {
-		ret = -EFBIG;
-		goto out;
-	}
 	if (i_size <= 0) {
 		ret = -EINVAL;
 		goto out;
 	}
+	if (i_size > SIZE_MAX || (max_size > 0 && i_size > max_size)) {
+		ret = -EFBIG;
+		goto out;
+	}
 
 	if (id != READING_FIRMWARE_PREALLOC_BUFFER)
 		*buf = vmalloc(i_size);

commit 0214f46b3a0383d6e33c297e7706216b6a550e4b
Merge: 40fafdcbcd7a 84fe4cc09abc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 21 13:47:29 2018 -0700

    Merge branch 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull core signal handling updates from Eric Biederman:
     "It was observed that a periodic timer in combination with a
      sufficiently expensive fork could prevent fork from every completing.
      This contains the changes to remove the need for that restart.
    
      This set of changes is split into several parts:
    
       - The first part makes PIDTYPE_TGID a proper pid type instead
         something only for very special cases. The part starts using
         PIDTYPE_TGID enough so that in __send_signal where signals are
         actually delivered we know if the signal is being sent to a a group
         of processes or just a single process.
    
       - With that prep work out of the way the logic in fork is modified so
         that fork logically makes signals received while it is running
         appear to be received after the fork completes"
    
    * 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (22 commits)
      signal: Don't send signals to tasks that don't exist
      signal: Don't restart fork when signals come in.
      fork: Have new threads join on-going signal group stops
      fork: Skip setting TIF_SIGPENDING in ptrace_init_task
      signal: Add calculate_sigpending()
      fork: Unconditionally exit if a fatal signal is pending
      fork: Move and describe why the code examines PIDNS_ADDING
      signal: Push pid type down into complete_signal.
      signal: Push pid type down into __send_signal
      signal: Push pid type down into send_signal
      signal: Pass pid type into do_send_sig_info
      signal: Pass pid type into send_sigio_to_task & send_sigurg_to_task
      signal: Pass pid type into group_send_sig_info
      signal: Pass pid and pid type into send_sigqueue
      posix-timers: Noralize good_sigevent
      signal: Use PIDTYPE_TGID to clearly store where file signals will be sent
      pid: Implement PIDTYPE_TGID
      pids: Move the pgrp and session pid pointers from task_struct to signal_struct
      kvm: Don't open code task_pid in kvm_vcpu_ioctl
      pids: Compute task_tgid using signal->leader_pid
      ...

commit bfd40eaff5abb9f62c8ef94ca13ed0d94a560f10
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Thu Jul 26 16:37:35 2018 -0700

    mm: fix vma_is_anonymous() false-positives
    
    vma_is_anonymous() relies on ->vm_ops being NULL to detect anonymous
    VMA.  This is unreliable as ->mmap may not set ->vm_ops.
    
    False-positive vma_is_anonymous() may lead to crashes:
    
            next ffff8801ce5e7040 prev ffff8801d20eca50 mm ffff88019c1e13c0
            prot 27 anon_vma ffff88019680cdd8 vm_ops 0000000000000000
            pgoff 0 file ffff8801b2ec2d00 private_data 0000000000000000
            flags: 0xff(read|write|exec|shared|mayread|maywrite|mayexec|mayshare)
            ------------[ cut here ]------------
            kernel BUG at mm/memory.c:1422!
            invalid opcode: 0000 [#1] SMP KASAN
            CPU: 0 PID: 18486 Comm: syz-executor3 Not tainted 4.18.0-rc3+ #136
            Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google
            01/01/2011
            RIP: 0010:zap_pmd_range mm/memory.c:1421 [inline]
            RIP: 0010:zap_pud_range mm/memory.c:1466 [inline]
            RIP: 0010:zap_p4d_range mm/memory.c:1487 [inline]
            RIP: 0010:unmap_page_range+0x1c18/0x2220 mm/memory.c:1508
            Call Trace:
             unmap_single_vma+0x1a0/0x310 mm/memory.c:1553
             zap_page_range_single+0x3cc/0x580 mm/memory.c:1644
             unmap_mapping_range_vma mm/memory.c:2792 [inline]
             unmap_mapping_range_tree mm/memory.c:2813 [inline]
             unmap_mapping_pages+0x3a7/0x5b0 mm/memory.c:2845
             unmap_mapping_range+0x48/0x60 mm/memory.c:2880
             truncate_pagecache+0x54/0x90 mm/truncate.c:800
             truncate_setsize+0x70/0xb0 mm/truncate.c:826
             simple_setattr+0xe9/0x110 fs/libfs.c:409
             notify_change+0xf13/0x10f0 fs/attr.c:335
             do_truncate+0x1ac/0x2b0 fs/open.c:63
             do_sys_ftruncate+0x492/0x560 fs/open.c:205
             __do_sys_ftruncate fs/open.c:215 [inline]
             __se_sys_ftruncate fs/open.c:213 [inline]
             __x64_sys_ftruncate+0x59/0x80 fs/open.c:213
             do_syscall_64+0x1b9/0x820 arch/x86/entry/common.c:290
             entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Reproducer:
    
            #include <stdio.h>
            #include <stddef.h>
            #include <stdint.h>
            #include <stdlib.h>
            #include <string.h>
            #include <sys/types.h>
            #include <sys/stat.h>
            #include <sys/ioctl.h>
            #include <sys/mman.h>
            #include <unistd.h>
            #include <fcntl.h>
    
            #define KCOV_INIT_TRACE                 _IOR('c', 1, unsigned long)
            #define KCOV_ENABLE                     _IO('c', 100)
            #define KCOV_DISABLE                    _IO('c', 101)
            #define COVER_SIZE                      (1024<<10)
    
            #define KCOV_TRACE_PC  0
            #define KCOV_TRACE_CMP 1
    
            int main(int argc, char **argv)
            {
                    int fd;
                    unsigned long *cover;
    
                    system("mount -t debugfs none /sys/kernel/debug");
                    fd = open("/sys/kernel/debug/kcov", O_RDWR);
                    ioctl(fd, KCOV_INIT_TRACE, COVER_SIZE);
                    cover = mmap(NULL, COVER_SIZE * sizeof(unsigned long),
                                    PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
                    munmap(cover, COVER_SIZE * sizeof(unsigned long));
                    cover = mmap(NULL, COVER_SIZE * sizeof(unsigned long),
                                    PROT_READ | PROT_WRITE, MAP_PRIVATE, fd, 0);
                    memset(cover, 0, COVER_SIZE * sizeof(unsigned long));
                    ftruncate(fd, 3UL << 20);
                    return 0;
            }
    
    This can be fixed by assigning anonymous VMAs own vm_ops and not relying
    on it being NULL.
    
    If ->mmap() failed to set ->vm_ops, mmap_region() will set it to
    dummy_vm_ops.  This way we will have non-NULL ->vm_ops for all VMAs.
    
    Link: http://lkml.kernel.org/r/20180724121139.62570-4-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reported-by: syzbot+3f84280d52be9b7083cc@syzkaller.appspotmail.com
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 72e961a62adb..bdd0eacefdf5 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -293,6 +293,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	bprm->vma = vma = vm_area_alloc(mm);
 	if (!vma)
 		return -ENOMEM;
+	vma_set_anonymous(vma);
 
 	if (down_write_killable(&mm->mmap_sem)) {
 		err = -EINTR;

commit 490fc053865c9cc40f1085ef8a5504f5341f79d2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 21 15:24:03 2018 -0700

    mm: make vm_area_alloc() initialize core fields
    
    Like vm_area_dup(), it initializes the anon_vma_chain head, and the
    basic mm pointer.
    
    The rest of the fields end up being different for different users,
    although the plan is to also initialize the 'vm_ops' field to a dummy
    entry.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9bd83989ea25..72e961a62adb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -290,7 +290,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	struct vm_area_struct *vma = NULL;
 	struct mm_struct *mm = bprm->mm;
 
-	bprm->vma = vma = vm_area_alloc();
+	bprm->vma = vma = vm_area_alloc(mm);
 	if (!vma)
 		return -ENOMEM;
 
@@ -298,7 +298,6 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 		err = -EINTR;
 		goto err_free;
 	}
-	vma->vm_mm = mm;
 
 	/*
 	 * Place the stack at the largest stack address the architecture
@@ -311,7 +310,6 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
 	vma->vm_flags = VM_SOFTDIRTY | VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
-	INIT_LIST_HEAD(&vma->anon_vma_chain);
 
 	err = insert_vm_struct(mm, vma);
 	if (err)

commit 3928d4f5ee37cdc523894f6e549e6aae521d8980
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 21 13:48:51 2018 -0700

    mm: use helper functions for allocating and freeing vm_area structs
    
    The vm_area_struct is one of the most fundamental memory management
    objects, but the management of it is entirely open-coded evertwhere,
    ranging from allocation and freeing (using kmem_cache_[z]alloc and
    kmem_cache_free) to initializing all the fields.
    
    We want to unify this in order to end up having some unified
    initialization of the vmas, and the first step to this is to at least
    have basic allocation functions.
    
    Right now those functions are literally just wrappers around the
    kmem_cache_*() calls.  This is a purely mechanical conversion:
    
        # new vma:
        kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL) -> vm_area_alloc()
    
        # copy old vma
        kmem_cache_alloc(vm_area_cachep, GFP_KERNEL) -> vm_area_dup(old)
    
        # free vma
        kmem_cache_free(vm_area_cachep, vma) -> vm_area_free(vma)
    
    to the point where the old vma passed in to the vm_area_dup() function
    isn't even used yet (because I've left all the old manual initialization
    alone).
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2d4e0075bd24..9bd83989ea25 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -290,7 +290,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	struct vm_area_struct *vma = NULL;
 	struct mm_struct *mm = bprm->mm;
 
-	bprm->vma = vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+	bprm->vma = vma = vm_area_alloc();
 	if (!vma)
 		return -ENOMEM;
 
@@ -326,7 +326,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	up_write(&mm->mmap_sem);
 err_free:
 	bprm->vma = NULL;
-	kmem_cache_free(vm_area_cachep, vma);
+	vm_area_free(vma);
 	return err;
 }
 

commit 6883f81aac6f44e7df70a6af189b3689ff52cbfb
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Jun 4 04:32:13 2017 -0500

    pid: Implement PIDTYPE_TGID
    
    Everywhere except in the pid array we distinguish between a tasks pid and
    a tasks tgid (thread group id).  Even in the enumeration we want that
    distinction sometimes so we have added __PIDTYPE_TGID.  With leader_pid
    we almost have an implementation of PIDTYPE_TGID in struct signal_struct.
    
    Add PIDTYPE_TGID as a first class member of the pid_type enumeration and
    into the pids array.  Then remove the __PIDTYPE_TGID special case and the
    leader_pid in signal_struct.
    
    The net size increase is just an extra pointer added to struct pid and
    an extra pair of pointers of an hlist_node added to task_struct.
    
    The effect on code maintenance is the removal of a number of special
    cases today and the potential to remove many more special cases as
    PIDTYPE_TGID gets used to it's fullest.  The long term potential
    is allowing zombie thread group leaders to exit, which will remove
    a lot more special cases in the code.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 2d4e0075bd24..79a11fbded7a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1146,6 +1146,7 @@ static int de_thread(struct task_struct *tsk)
 		 */
 		tsk->pid = leader->pid;
 		change_pid(tsk, PIDTYPE_PID, task_pid(leader));
+		transfer_pid(leader, tsk, PIDTYPE_TGID);
 		transfer_pid(leader, tsk, PIDTYPE_PGID);
 		transfer_pid(leader, tsk, PIDTYPE_SID);
 

commit d82991a8688ad128b46db1b42d5d84396487a508
Merge: f4e5b30d809d ccba8b64452b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jun 10 10:17:09 2018 -0700

    Merge branch 'core-rseq-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull restartable sequence support from Thomas Gleixner:
     "The restartable sequences syscall (finally):
    
      After a lot of back and forth discussion and massive delays caused by
      the speculative distraction of maintainers, the core set of
      restartable sequences has finally reached a consensus.
    
      It comes with the basic non disputed core implementation along with
      support for arm, powerpc and x86 and a full set of selftests
    
      It was exposed to linux-next earlier this week, so it does not fully
      comply with the merge window requirements, but there is really no
      point to drag it out for yet another cycle"
    
    * 'core-rseq-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      rseq/selftests: Provide Makefile, scripts, gitignore
      rseq/selftests: Provide parametrized tests
      rseq/selftests: Provide basic percpu ops test
      rseq/selftests: Provide basic test
      rseq/selftests: Provide rseq library
      selftests/lib.mk: Introduce OVERRIDE_TARGETS
      powerpc: Wire up restartable sequences system call
      powerpc: Add syscall detection for restartable sequences
      powerpc: Add support for restartable sequences
      x86: Wire up restartable sequence system call
      x86: Add support for restartable sequences
      arm: Wire up restartable sequences system call
      arm: Add syscall detection for restartable sequences
      arm: Add restartable sequences support
      rseq: Introduce restartable sequences system call
      uapi/headers: Provide types_32_64.h

commit d7822b1e24f2df5df98c76f0e94a5416349ff759
Author: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date:   Sat Jun 2 08:43:54 2018 -0400

    rseq: Introduce restartable sequences system call
    
    Expose a new system call allowing each thread to register one userspace
    memory area to be used as an ABI between kernel and user-space for two
    purposes: user-space restartable sequences and quick access to read the
    current CPU number value from user-space.
    
    * Restartable sequences (per-cpu atomics)
    
    Restartables sequences allow user-space to perform update operations on
    per-cpu data without requiring heavy-weight atomic operations.
    
    The restartable critical sections (percpu atomics) work has been started
    by Paul Turner and Andrew Hunter. It lets the kernel handle restart of
    critical sections. [1] [2] The re-implementation proposed here brings a
    few simplifications to the ABI which facilitates porting to other
    architectures and speeds up the user-space fast path.
    
    Here are benchmarks of various rseq use-cases.
    
    Test hardware:
    
    arm32: ARMv7 Processor rev 4 (v7l) "Cubietruck", 2-core
    x86-64: Intel E5-2630 v3@2.40GHz, 16-core, hyperthreading
    
    The following benchmarks were all performed on a single thread.
    
    * Per-CPU statistic counter increment
    
                    getcpu+atomic (ns/op)    rseq (ns/op)    speedup
    arm32:                344.0                 31.4          11.0
    x86-64:                15.3                  2.0           7.7
    
    * LTTng-UST: write event 32-bit header, 32-bit payload into tracer
                 per-cpu buffer
    
                    getcpu+atomic (ns/op)    rseq (ns/op)    speedup
    arm32:               2502.0                 2250.0         1.1
    x86-64:               117.4                   98.0         1.2
    
    * liburcu percpu: lock-unlock pair, dereference, read/compare word
    
                    getcpu+atomic (ns/op)    rseq (ns/op)    speedup
    arm32:                751.0                 128.5          5.8
    x86-64:                53.4                  28.6          1.9
    
    * jemalloc memory allocator adapted to use rseq
    
    Using rseq with per-cpu memory pools in jemalloc at Facebook (based on
    rseq 2016 implementation):
    
    The production workload response-time has 1-2% gain avg. latency, and
    the P99 overall latency drops by 2-3%.
    
    * Reading the current CPU number
    
    Speeding up reading the current CPU number on which the caller thread is
    running is done by keeping the current CPU number up do date within the
    cpu_id field of the memory area registered by the thread. This is done
    by making scheduler preemption set the TIF_NOTIFY_RESUME flag on the
    current thread. Upon return to user-space, a notify-resume handler
    updates the current CPU value within the registered user-space memory
    area. User-space can then read the current CPU number directly from
    memory.
    
    Keeping the current cpu id in a memory area shared between kernel and
    user-space is an improvement over current mechanisms available to read
    the current CPU number, which has the following benefits over
    alternative approaches:
    
    - 35x speedup on ARM vs system call through glibc
    - 20x speedup on x86 compared to calling glibc, which calls vdso
      executing a "lsl" instruction,
    - 14x speedup on x86 compared to inlined "lsl" instruction,
    - Unlike vdso approaches, this cpu_id value can be read from an inline
      assembly, which makes it a useful building block for restartable
      sequences.
    - The approach of reading the cpu id through memory mapping shared
      between kernel and user-space is portable (e.g. ARM), which is not the
      case for the lsl-based x86 vdso.
    
    On x86, yet another possible approach would be to use the gs segment
    selector to point to user-space per-cpu data. This approach performs
    similarly to the cpu id cache, but it has two disadvantages: it is
    not portable, and it is incompatible with existing applications already
    using the gs segment selector for other purposes.
    
    Benchmarking various approaches for reading the current CPU number:
    
    ARMv7 Processor rev 4 (v7l)
    Machine model: Cubietruck
    - Baseline (empty loop):                                    8.4 ns
    - Read CPU from rseq cpu_id:                               16.7 ns
    - Read CPU from rseq cpu_id (lazy register):               19.8 ns
    - glibc 2.19-0ubuntu6.6 getcpu:                           301.8 ns
    - getcpu system call:                                     234.9 ns
    
    x86-64 Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz:
    - Baseline (empty loop):                                    0.8 ns
    - Read CPU from rseq cpu_id:                                0.8 ns
    - Read CPU from rseq cpu_id (lazy register):                0.8 ns
    - Read using gs segment selector:                           0.8 ns
    - "lsl" inline assembly:                                   13.0 ns
    - glibc 2.19-0ubuntu6 getcpu:                              16.6 ns
    - getcpu system call:                                      53.9 ns
    
    - Speed (benchmark taken on v8 of patchset)
    
    Running 10 runs of hackbench -l 100000 seems to indicate, contrary to
    expectations, that enabling CONFIG_RSEQ slightly accelerates the
    scheduler:
    
    Configuration: 2 sockets * 8-core Intel(R) Xeon(R) CPU E5-2630 v3 @
    2.40GHz (directly on hardware, hyperthreading disabled in BIOS, energy
    saving disabled in BIOS, turboboost disabled in BIOS, cpuidle.off=1
    kernel parameter), with a Linux v4.6 defconfig+localyesconfig,
    restartable sequences series applied.
    
    * CONFIG_RSEQ=n
    
    avg.:      41.37 s
    std.dev.:   0.36 s
    
    * CONFIG_RSEQ=y
    
    avg.:      40.46 s
    std.dev.:   0.33 s
    
    - Size
    
    On x86-64, between CONFIG_RSEQ=n/y, the text size increase of vmlinux is
    567 bytes, and the data size increase of vmlinux is 5696 bytes.
    
    [1] https://lwn.net/Articles/650333/
    [2] http://www.linuxplumbersconf.org/2013/ocw/system/presentations/1695/original/LPC%20-%20PerCpu%20Atomics.pdf
    
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Joel Fernandes <joelaf@google.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Dave Watson <davejwatson@fb.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: "H . Peter Anvin" <hpa@zytor.com>
    Cc: Chris Lameter <cl@linux.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Andrew Hunter <ahh@google.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: "Paul E . McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Paul Turner <pjt@google.com>
    Cc: Boqun Feng <boqun.feng@gmail.com>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Ben Maurer <bmaurer@fb.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: linux-api@vger.kernel.org
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/20151027235635.16059.11630.stgit@pjt-glaptop.roam.corp.google.com
    Link: http://lkml.kernel.org/r/20150624222609.6116.86035.stgit@kitami.mtv.corp.google.com
    Link: https://lkml.kernel.org/r/20180602124408.8430-3-mathieu.desnoyers@efficios.com

diff --git a/fs/exec.c b/fs/exec.c
index 183059c427b9..2c3911612b22 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1822,6 +1822,7 @@ static int do_execveat_common(int fd, struct filename *filename,
 	current->fs->in_exec = 0;
 	current->in_execve = 0;
 	membarrier_execve(current);
+	rseq_execve(current);
 	acct_update_integrals(current);
 	task_numa_free(current);
 	free_bprm(bprm);

commit 449325b52b7a6208f65ed67d3484fd7b7184477b
Author: Alexei Starovoitov <ast@kernel.org>
Date:   Mon May 21 19:22:29 2018 -0700

    umh: introduce fork_usermode_blob() helper
    
    Introduce helper:
    int fork_usermode_blob(void *data, size_t len, struct umh_info *info);
    struct umh_info {
           struct file *pipe_to_umh;
           struct file *pipe_from_umh;
           pid_t pid;
    };
    
    that GPLed kernel modules (signed or unsigned) can use it to execute part
    of its own data as swappable user mode process.
    
    The kernel will do:
    - allocate a unique file in tmpfs
    - populate that file with [data, data + len] bytes
    - user-mode-helper code will do_execve that file and, before the process
      starts, the kernel will create two unix pipes for bidirectional
      communication between kernel module and umh
    - close tmpfs file, effectively deleting it
    - the fork_usermode_blob will return zero on success and populate
      'struct umh_info' with two unix pipes and the pid of the user process
    
    As the first step in the development of the bpfilter project
    the fork_usermode_blob() helper is introduced to allow user mode code
    to be invoked from a kernel module. The idea is that user mode code plus
    normal kernel module code are built as part of the kernel build
    and installed as traditional kernel module into distro specified location,
    such that from a distribution point of view, there is
    no difference between regular kernel modules and kernel modules + umh code.
    Such modules can be signed, modprobed, rmmod, etc. The use of this new helper
    by a kernel module doesn't make it any special from kernel and user space
    tooling point of view.
    
    Such approach enables kernel to delegate functionality traditionally done
    by the kernel modules into the user space processes (either root or !root) and
    reduces security attack surface of the new code. The buggy umh code would crash
    the user process, but not the kernel. Another advantage is that umh code
    of the kernel module can be debugged and tested out of user space
    (e.g. opening the possibility to run clang sanitizers, fuzzers or
    user space test suites on the umh code).
    In case of the bpfilter project such architecture allows complex control plane
    to be done in the user space while bpf based data plane stays in the kernel.
    
    Since umh can crash, can be oom-ed by the kernel, killed by the admin,
    the kernel module that uses them (like bpfilter) needs to manage life
    time of umh on its own via two unix pipes and the pid of umh.
    
    The exit code of such kernel module should kill the umh it started,
    so that rmmod of the kernel module will cleanup the corresponding umh.
    Just like if the kernel module does kmalloc() it should kfree() it
    in the exit code.
    
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/fs/exec.c b/fs/exec.c
index 183059c427b9..30a36c2a39bf 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1706,14 +1706,13 @@ static int exec_binprm(struct linux_binprm *bprm)
 /*
  * sys_execve() executes a new program.
  */
-static int do_execveat_common(int fd, struct filename *filename,
-			      struct user_arg_ptr argv,
-			      struct user_arg_ptr envp,
-			      int flags)
+static int __do_execve_file(int fd, struct filename *filename,
+			    struct user_arg_ptr argv,
+			    struct user_arg_ptr envp,
+			    int flags, struct file *file)
 {
 	char *pathbuf = NULL;
 	struct linux_binprm *bprm;
-	struct file *file;
 	struct files_struct *displaced;
 	int retval;
 
@@ -1752,7 +1751,8 @@ static int do_execveat_common(int fd, struct filename *filename,
 	check_unsafe_exec(bprm);
 	current->in_execve = 1;
 
-	file = do_open_execat(fd, filename, flags);
+	if (!file)
+		file = do_open_execat(fd, filename, flags);
 	retval = PTR_ERR(file);
 	if (IS_ERR(file))
 		goto out_unmark;
@@ -1760,7 +1760,9 @@ static int do_execveat_common(int fd, struct filename *filename,
 	sched_exec();
 
 	bprm->file = file;
-	if (fd == AT_FDCWD || filename->name[0] == '/') {
+	if (!filename) {
+		bprm->filename = "none";
+	} else if (fd == AT_FDCWD || filename->name[0] == '/') {
 		bprm->filename = filename->name;
 	} else {
 		if (filename->name[0] == '\0')
@@ -1826,7 +1828,8 @@ static int do_execveat_common(int fd, struct filename *filename,
 	task_numa_free(current);
 	free_bprm(bprm);
 	kfree(pathbuf);
-	putname(filename);
+	if (filename)
+		putname(filename);
 	if (displaced)
 		put_files_struct(displaced);
 	return retval;
@@ -1849,10 +1852,27 @@ static int do_execveat_common(int fd, struct filename *filename,
 	if (displaced)
 		reset_files_struct(displaced);
 out_ret:
-	putname(filename);
+	if (filename)
+		putname(filename);
 	return retval;
 }
 
+static int do_execveat_common(int fd, struct filename *filename,
+			      struct user_arg_ptr argv,
+			      struct user_arg_ptr envp,
+			      int flags)
+{
+	return __do_execve_file(fd, filename, argv, envp, flags, NULL);
+}
+
+int do_execve_file(struct file *file, void *__argv, void *__envp)
+{
+	struct user_arg_ptr argv = { .ptr.native = __argv };
+	struct user_arg_ptr envp = { .ptr.native = __envp };
+
+	return __do_execve_file(AT_FDCWD, NULL, argv, envp, 0, file);
+}
+
 int do_execve(struct filename *filename,
 	const char __user *const __user *__argv,
 	const char __user *const __user *__envp)

commit c31dbb146dd44af44bc60780ce8fa7a9f5f746df
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Apr 10 16:35:01 2018 -0700

    exec: pin stack limit during exec
    
    Since the stack rlimit is used in multiple places during exec and it can
    be changed via other threads (via setrlimit()) or processes (via
    prlimit()), the assumption that the value doesn't change cannot be made.
    This leads to races with mm layout selection and argument size
    calculations.  This changes the exec path to use the rlimit stored in
    bprm instead of in current.  Before starting the thread, the bprm stack
    rlimit is stored back to current.
    
    Link: http://lkml.kernel.org/r/1518638796-20819-4-git-send-email-keescook@chromium.org
    Fixes: 64701dee4178e ("exec: Use sane stack rlimit under secureexec")
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reported-by: Ben Hutchings <ben.hutchings@codethink.co.uk>
    Reported-by: Andy Lutomirski <luto@kernel.org>
    Reported-by: Brad Spengler <spender@grsecurity.net>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: Greg KH <greg@kroah.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: "Jason A. Donenfeld" <Jason@zx2c4.com>
    Cc: Laura Abbott <labbott@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Willy Tarreau <w@1wt.eu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 422ad79a7a03..183059c427b9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -257,7 +257,7 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		 *    to work from.
 		 */
 		limit = _STK_LIM / 4 * 3;
-		limit = min(limit, rlimit(RLIMIT_STACK) / 4);
+		limit = min(limit, bprm->rlim_stack.rlim_cur / 4);
 		if (size > limit)
 			goto fail;
 	}
@@ -411,6 +411,11 @@ static int bprm_mm_init(struct linux_binprm *bprm)
 	if (!mm)
 		goto err;
 
+	/* Save current stack limit for all calculations made during exec. */
+	task_lock(current->group_leader);
+	bprm->rlim_stack = current->signal->rlim[RLIMIT_STACK];
+	task_unlock(current->group_leader);
+
 	err = __bprm_mm_init(bprm);
 	if (err)
 		goto err;
@@ -697,7 +702,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 
 #ifdef CONFIG_STACK_GROWSUP
 	/* Limit stack size */
-	stack_base = rlimit_max(RLIMIT_STACK);
+	stack_base = bprm->rlim_stack.rlim_max;
 	if (stack_base > STACK_SIZE_MAX)
 		stack_base = STACK_SIZE_MAX;
 
@@ -770,7 +775,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	 * Align this down to a page boundary as expand_stack
 	 * will align it up.
 	 */
-	rlim_stack = rlimit(RLIMIT_STACK) & PAGE_MASK;
+	rlim_stack = bprm->rlim_stack.rlim_cur & PAGE_MASK;
 #ifdef CONFIG_STACK_GROWSUP
 	if (stack_size + stack_expand > rlim_stack)
 		stack_base = vma->vm_start + rlim_stack;
@@ -1323,8 +1328,6 @@ EXPORT_SYMBOL(would_dump);
 
 void setup_new_exec(struct linux_binprm * bprm)
 {
-	struct rlimit rlim_stack;
-
 	/*
 	 * Once here, prepare_binrpm() will not be called any more, so
 	 * the final state of setuid/setgid/fscaps can be merged into the
@@ -1343,15 +1346,11 @@ void setup_new_exec(struct linux_binprm * bprm)
 		 * RLIMIT_STACK, but after the point of no return to avoid
 		 * needing to clean up the change on failure.
 		 */
-		if (current->signal->rlim[RLIMIT_STACK].rlim_cur > _STK_LIM)
-			current->signal->rlim[RLIMIT_STACK].rlim_cur = _STK_LIM;
+		if (bprm->rlim_stack.rlim_cur > _STK_LIM)
+			bprm->rlim_stack.rlim_cur = _STK_LIM;
 	}
 
-	task_lock(current->group_leader);
-	rlim_stack = current->signal->rlim[RLIMIT_STACK];
-	task_unlock(current->group_leader);
-
-	arch_pick_mmap_layout(current->mm, &rlim_stack);
+	arch_pick_mmap_layout(current->mm, &bprm->rlim_stack);
 
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
@@ -1387,6 +1386,10 @@ EXPORT_SYMBOL(setup_new_exec);
 /* Runs immediately before start_thread() takes over. */
 void finalize_exec(struct linux_binprm *bprm)
 {
+	/* Store any stack rlimit changes before starting thread. */
+	task_lock(current->group_leader);
+	current->signal->rlim[RLIMIT_STACK] = bprm->rlim_stack;
+	task_unlock(current->group_leader);
 }
 EXPORT_SYMBOL(finalize_exec);
 

commit b83838313386f617d6bd8201be7f5b532059bba1
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Apr 10 16:34:57 2018 -0700

    exec: introduce finalize_exec() before start_thread()
    
    Provide a final callback into fs/exec.c before start_thread() takes
    over, to handle any last-minute changes, like the coming restoration of
    the stack limit.
    
    Link: http://lkml.kernel.org/r/1518638796-20819-3-git-send-email-keescook@chromium.org
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: Ben Hutchings <ben.hutchings@codethink.co.uk>
    Cc: Brad Spengler <spender@grsecurity.net>
    Cc: Greg KH <greg@kroah.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: "Jason A. Donenfeld" <Jason@zx2c4.com>
    Cc: Laura Abbott <labbott@redhat.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Willy Tarreau <w@1wt.eu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index f4469ab88c7a..422ad79a7a03 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1384,6 +1384,12 @@ void setup_new_exec(struct linux_binprm * bprm)
 }
 EXPORT_SYMBOL(setup_new_exec);
 
+/* Runs immediately before start_thread() takes over. */
+void finalize_exec(struct linux_binprm *bprm)
+{
+}
+EXPORT_SYMBOL(finalize_exec);
+
 /*
  * Prepare credentials and lock ->cred_guard_mutex.
  * install_exec_creds() commits the new creds and drops the lock.

commit 8f2af155b513583e8b149a384551f13e1ac5dc72
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Apr 10 16:34:53 2018 -0700

    exec: pass stack rlimit into mm layout functions
    
    Patch series "exec: Pin stack limit during exec".
    
    Attempts to solve problems with the stack limit changing during exec
    continue to be frustrated[1][2].  In addition to the specific issues
    around the Stack Clash family of flaws, Andy Lutomirski pointed out[3]
    other places during exec where the stack limit is used and is assumed to
    be unchanging.  Given the many places it gets used and the fact that it
    can be manipulated/raced via setrlimit() and prlimit(), I think the only
    way to handle this is to move away from the "current" view of the stack
    limit and instead attach it to the bprm, and plumb this down into the
    functions that need to know the stack limits.  This series implements
    the approach.
    
    [1] 04e35f4495dd ("exec: avoid RLIMIT_STACK races with prlimit()")
    [2] 779f4e1c6c7c ("Revert "exec: avoid RLIMIT_STACK races with prlimit()"")
    [3] to security@kernel.org, "Subject: existing rlimit races?"
    
    This patch (of 3):
    
    Since it is possible that the stack rlimit can change externally during
    exec (either via another thread calling setrlimit() or another process
    calling prlimit()), provide a way to pass the rlimit down into the
    per-architecture mm layout functions so that the rlimit can stay in the
    bprm structure instead of sitting in the signal structure until exec is
    finalized.
    
    Link: http://lkml.kernel.org/r/1518638796-20819-2-git-send-email-keescook@chromium.org
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: Willy Tarreau <w@1wt.eu>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: "Jason A. Donenfeld" <Jason@zx2c4.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Laura Abbott <labbott@redhat.com>
    Cc: Greg KH <greg@kroah.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ben Hutchings <ben.hutchings@codethink.co.uk>
    Cc: Brad Spengler <spender@grsecurity.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a919a827d181..f4469ab88c7a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1323,6 +1323,8 @@ EXPORT_SYMBOL(would_dump);
 
 void setup_new_exec(struct linux_binprm * bprm)
 {
+	struct rlimit rlim_stack;
+
 	/*
 	 * Once here, prepare_binrpm() will not be called any more, so
 	 * the final state of setuid/setgid/fscaps can be merged into the
@@ -1345,7 +1347,11 @@ void setup_new_exec(struct linux_binprm * bprm)
 			current->signal->rlim[RLIMIT_STACK].rlim_cur = _STK_LIM;
 	}
 
-	arch_pick_mmap_layout(current->mm);
+	task_lock(current->group_leader);
+	rlim_stack = current->signal->rlim[RLIMIT_STACK];
+	task_unlock(current->group_leader);
+
+	arch_pick_mmap_layout(current->mm, &rlim_stack);
 
 	current->sas_ss_sp = current->sas_ss_size = 0;
 

commit 7bd698b3c04e61ee9e03d4c2a55003f75df14dca
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Mar 9 11:30:20 2018 -0800

    exec: Set file unwritable before LSM check
    
    The LSM check should happen after the file has been confirmed to be
    unchanging. Without this, we could have a race between the Time of Check
    (the call to security_kernel_read_file() which could read the file and
    make access policy decisions) and the Time of Use (starting with
    kernel_read_file()'s reading of the file contents). In theory, file
    contents could change between the two.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Signed-off-by: James Morris <james.morris@microsoft.com>

diff --git a/fs/exec.c b/fs/exec.c
index 7eb8d21bcab9..a919a827d181 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -895,13 +895,13 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 	if (!S_ISREG(file_inode(file)->i_mode) || max_size < 0)
 		return -EINVAL;
 
-	ret = security_kernel_read_file(file, id);
+	ret = deny_write_access(file);
 	if (ret)
 		return ret;
 
-	ret = deny_write_access(file);
+	ret = security_kernel_read_file(file, id);
 	if (ret)
-		return ret;
+		goto out;
 
 	i_size = i_size_read(file_inode(file));
 	if (max_size > 0 && i_size > max_size) {

commit e816c201aed5232171f8eb80b5d46ae6516683b9
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jan 2 15:21:33 2018 -0800

    exec: Weaken dumpability for secureexec
    
    This is a logical revert of commit e37fdb785a5f ("exec: Use secureexec
    for setting dumpability")
    
    This weakens dumpability back to checking only for uid/gid changes in
    current (which is useless), but userspace depends on dumpability not
    being tied to secureexec.
    
      https://bugzilla.redhat.com/show_bug.cgi?id=1528633
    
    Reported-by: Tom Horsley <horsley1953@gmail.com>
    Fixes: e37fdb785a5f ("exec: Use secureexec for setting dumpability")
    Cc: stable@vger.kernel.org
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 5688b5e1b937..7eb8d21bcab9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1349,9 +1349,14 @@ void setup_new_exec(struct linux_binprm * bprm)
 
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
-	/* Figure out dumpability. */
+	/*
+	 * Figure out dumpability. Note that this checking only of current
+	 * is wrong, but userspace depends on it. This should be testing
+	 * bprm->secureexec instead.
+	 */
 	if (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP ||
-	    bprm->secureexec)
+	    !(uid_eq(current_euid(), current_uid()) &&
+	      gid_eq(current_egid(), current_gid())))
 		set_dumpable(current->mm, suid_dumpable);
 	else
 		set_dumpable(current->mm, SUID_DUMP_USER);

commit 779f4e1c6c7c661db40dfebd6dd6bda7b5f88aa3
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Dec 12 11:28:38 2017 -0800

    Revert "exec: avoid RLIMIT_STACK races with prlimit()"
    
    This reverts commit 04e35f4495dd560db30c25efca4eecae8ec8c375.
    
    SELinux runs with secureexec for all non-"noatsecure" domain transitions,
    which means lots of processes end up hitting the stack hard-limit change
    that was introduced in order to fix a race with prlimit(). That race fix
    will need to be redesigned.
    
    Reported-by: Laura Abbott <labbott@redhat.com>
    Reported-by: Tom Trnka <trnka@scm.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 156f56acfe8e..5688b5e1b937 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1339,15 +1339,10 @@ void setup_new_exec(struct linux_binprm * bprm)
 		 * avoid bad behavior from the prior rlimits. This has to
 		 * happen before arch_pick_mmap_layout(), which examines
 		 * RLIMIT_STACK, but after the point of no return to avoid
-		 * races from other threads changing the limits. This also
-		 * must be protected from races with prlimit() calls.
+		 * needing to clean up the change on failure.
 		 */
-		task_lock(current->group_leader);
 		if (current->signal->rlim[RLIMIT_STACK].rlim_cur > _STK_LIM)
 			current->signal->rlim[RLIMIT_STACK].rlim_cur = _STK_LIM;
-		if (current->signal->rlim[RLIMIT_STACK].rlim_max > _STK_LIM)
-			current->signal->rlim[RLIMIT_STACK].rlim_max = _STK_LIM;
-		task_unlock(current->group_leader);
 	}
 
 	arch_pick_mmap_layout(current->mm);

commit 3756f6401c302617c5e091081ca4d26ab604bec5
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Thu Dec 14 15:32:41 2017 -0800

    exec: avoid gcc-8 warning for get_task_comm
    
    gcc-8 warns about using strncpy() with the source size as the limit:
    
      fs/exec.c:1223:32: error: argument to 'sizeof' in 'strncpy' call is the same expression as the source; did you mean to use the size of the destination? [-Werror=sizeof-pointer-memaccess]
    
    This is indeed slightly suspicious, as it protects us from source
    arguments without NUL-termination, but does not guarantee that the
    destination is terminated.
    
    This keeps the strncpy() to ensure we have properly padded target
    buffer, but ensures that we use the correct length, by passing the
    actual length of the destination buffer as well as adding a build-time
    check to ensure it is exactly TASK_COMM_LEN.
    
    There are only 23 callsites which I all reviewed to ensure this is
    currently the case.  We could get away with doing only the check or
    passing the right length, but it doesn't hurt to do both.
    
    Link: http://lkml.kernel.org/r/20171205151724.1764896-1-arnd@arndb.de
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Suggested-by: Kees Cook <keescook@chromium.org>
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Serge Hallyn <serge@hallyn.com>
    Cc: James Morris <james.l.morris@oracle.com>
    Cc: Aleksa Sarai <asarai@suse.de>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Frederic Weisbecker <frederic@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6be2aa0ab26f..156f56acfe8e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1216,15 +1216,14 @@ static int de_thread(struct task_struct *tsk)
 	return -EAGAIN;
 }
 
-char *get_task_comm(char *buf, struct task_struct *tsk)
+char *__get_task_comm(char *buf, size_t buf_size, struct task_struct *tsk)
 {
-	/* buf must be at least sizeof(tsk->comm) in size */
 	task_lock(tsk);
-	strncpy(buf, tsk->comm, sizeof(tsk->comm));
+	strncpy(buf, tsk->comm, buf_size);
 	task_unlock(tsk);
 	return buf;
 }
-EXPORT_SYMBOL_GPL(get_task_comm);
+EXPORT_SYMBOL_GPL(__get_task_comm);
 
 /*
  * These functions flushes out all traces of the currently running executable

commit 04e35f4495dd560db30c25efca4eecae8ec8c375
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Nov 29 16:10:51 2017 -0800

    exec: avoid RLIMIT_STACK races with prlimit()
    
    While the defense-in-depth RLIMIT_STACK limit on setuid processes was
    protected against races from other threads calling setrlimit(), I missed
    protecting it against races from external processes calling prlimit().
    This adds locking around the change and makes sure that rlim_max is set
    too.
    
    Link: http://lkml.kernel.org/r/20171127193457.GA11348@beast
    Fixes: 64701dee4178e ("exec: Use sane stack rlimit under secureexec")
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reported-by: Ben Hutchings <ben.hutchings@codethink.co.uk>
    Reported-by: Brad Spengler <spender@grsecurity.net>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    Cc: James Morris <james.l.morris@oracle.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 1d6243d9f2b6..6be2aa0ab26f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1340,10 +1340,15 @@ void setup_new_exec(struct linux_binprm * bprm)
 		 * avoid bad behavior from the prior rlimits. This has to
 		 * happen before arch_pick_mmap_layout(), which examines
 		 * RLIMIT_STACK, but after the point of no return to avoid
-		 * needing to clean up the change on failure.
+		 * races from other threads changing the limits. This also
+		 * must be protected from races with prlimit() calls.
 		 */
+		task_lock(current->group_leader);
 		if (current->signal->rlim[RLIMIT_STACK].rlim_cur > _STK_LIM)
 			current->signal->rlim[RLIMIT_STACK].rlim_cur = _STK_LIM;
+		if (current->signal->rlim[RLIMIT_STACK].rlim_max > _STK_LIM)
+			current->signal->rlim[RLIMIT_STACK].rlim_max = _STK_LIM;
+		task_unlock(current->group_leader);
 	}
 
 	arch_pick_mmap_layout(current->mm);

commit 6aa7de059173a986114ac43b8f50b297a86f09a8
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Mon Oct 23 14:07:29 2017 -0700

    locking/atomics: COCCINELLE/treewide: Convert trivial ACCESS_ONCE() patterns to READ_ONCE()/WRITE_ONCE()
    
    Please do not apply this to mainline directly, instead please re-run the
    coccinelle script shown below and apply its output.
    
    For several reasons, it is desirable to use {READ,WRITE}_ONCE() in
    preference to ACCESS_ONCE(), and new code is expected to use one of the
    former. So far, there's been no reason to change most existing uses of
    ACCESS_ONCE(), as these aren't harmful, and changing them results in
    churn.
    
    However, for some features, the read/write distinction is critical to
    correct operation. To distinguish these cases, separate read/write
    accessors must be used. This patch migrates (most) remaining
    ACCESS_ONCE() instances to {READ,WRITE}_ONCE(), using the following
    coccinelle script:
    
    ----
    // Convert trivial ACCESS_ONCE() uses to equivalent READ_ONCE() and
    // WRITE_ONCE()
    
    // $ make coccicheck COCCI=/home/mark/once.cocci SPFLAGS="--include-headers" MODE=patch
    
    virtual patch
    
    @ depends on patch @
    expression E1, E2;
    @@
    
    - ACCESS_ONCE(E1) = E2
    + WRITE_ONCE(E1, E2)
    
    @ depends on patch @
    expression E;
    @@
    
    - ACCESS_ONCE(E)
    + READ_ONCE(E)
    ----
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: davem@davemloft.net
    Cc: linux-arch@vger.kernel.org
    Cc: mpe@ellerman.id.au
    Cc: shuah@kernel.org
    Cc: snitzer@redhat.com
    Cc: thor.thayer@linux.intel.com
    Cc: tj@kernel.org
    Cc: viro@zeniv.linux.org.uk
    Cc: will.deacon@arm.com
    Link: http://lkml.kernel.org/r/1508792849-3115-19-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 3e14ba25f678..1d6243d9f2b6 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1911,7 +1911,7 @@ void set_dumpable(struct mm_struct *mm, int value)
 		return;
 
 	do {
-		old = ACCESS_ONCE(mm->flags);
+		old = READ_ONCE(mm->flags);
 		new = (old & ~MMF_DUMPABLE_MASK) | value;
 	} while (cmpxchg(&mm->flags, old, new) != old);
 }

commit a961e40917fb14614d368d8bc9782ca4d6a8cd11
Author: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date:   Thu Oct 19 13:30:15 2017 -0400

    membarrier: Provide register expedited private command
    
    This introduces a "register private expedited" membarrier command which
    allows eventual removal of important memory barrier constraints on the
    scheduler fast-paths. It changes how the "private expedited" membarrier
    command (new to 4.14) is used from user-space.
    
    This new command allows processes to register their intent to use the
    private expedited command.  This affects how the expedited private
    command introduced in 4.14-rc is meant to be used, and should be merged
    before 4.14 final.
    
    Processes are now required to register before using
    MEMBARRIER_CMD_PRIVATE_EXPEDITED, otherwise that command returns EPERM.
    
    This fixes a problem that arose when designing requested extensions to
    sys_membarrier() to allow JITs to efficiently flush old code from
    instruction caches.  Several potential algorithms are much less painful
    if the user register intent to use this functionality early on, for
    example, before the process spawns the second thread.  Registering at
    this time removes the need to interrupt each and every thread in that
    process at the first expedited sys_membarrier() system call.
    
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 5470d3c1892a..3e14ba25f678 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1802,6 +1802,7 @@ static int do_execveat_common(int fd, struct filename *filename,
 	/* execve succeeded */
 	current->fs->in_exec = 0;
 	current->in_execve = 0;
+	membarrier_execve(current);
 	acct_update_integrals(current);
 	task_numa_free(current);
 	free_bprm(bprm);

commit c2315c187fa0d3ab363fdebe22718170b40473e3
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Oct 3 16:15:42 2017 -0700

    exec: load_script: kill the onstack interp[BINPRM_BUF_SIZE] array
    
    Patch series "exec: binfmt_misc: fix use-after-free, kill
    iname[BINPRM_BUF_SIZE]".
    
    It looks like this code was always wrong, then commit 948b701a607f
    ("binfmt_misc: add persistent opened binary handler for containers")
    added more problems.
    
    This patch (of 6):
    
    load_script() can simply use i_name instead, it points into bprm->buf[]
    and nobody can change this memory until we call prepare_binprm().
    
    The only complication is that we need to also change the signature of
    bprm_change_interp() but this change looks good too.
    
    While at it, do whitespace/style cleanups.
    
    NOTE: the real motivation for this change is that people want to
    increase BINPRM_BUF_SIZE, we need to change load_misc_binary() too but
    this looks more complicated because afaics it is very buggy.
    
    Link: http://lkml.kernel.org/r/20170918163446.GA26793@redhat.com
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Travis Gummels <tgummels@redhat.com>
    Cc: Ben Woodard <woodard@redhat.com>
    Cc: Jim Foraker <foraker1@llnl.gov>
    Cc: <tdhooge@llnl.gov>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ac34d9724684..5470d3c1892a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1410,7 +1410,7 @@ static void free_bprm(struct linux_binprm *bprm)
 	kfree(bprm);
 }
 
-int bprm_change_interp(char *interp, struct linux_binprm *bprm)
+int bprm_change_interp(const char *interp, struct linux_binprm *bprm)
 {
 	/* If a binfmt changed the interp, free it first. */
 	if (bprm->interp != bprm->filename)

commit 711aab1dbb324d321e3d84368a435a78908c7bce
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Tue Sep 12 22:45:33 2017 -0400

    vfs: constify path argument to kernel_read_file_from_path
    
    This patch constifies the path argument to kernel_read_file_from_path().
    
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 69a543259aa5..ac34d9724684 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -955,7 +955,7 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 }
 EXPORT_SYMBOL_GPL(kernel_read_file);
 
-int kernel_read_file_from_path(char *path, void **buf, loff_t *size,
+int kernel_read_file_from_path(const char *path, void **buf, loff_t *size,
 			       loff_t max_size, enum kernel_read_file_id id)
 {
 	struct file *file;

commit 581bfce969cbfc7ce43ee92273be9cb7c3fdfa61
Merge: cc73fee0bae2 9725d4cef622
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 14 18:13:32 2017 -0700

    Merge branch 'work.set_fs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull more set_fs removal from Al Viro:
     "Christoph's 'use kernel_read and friends rather than open-coding
      set_fs()' series"
    
    * 'work.set_fs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      fs: unexport vfs_readv and vfs_writev
      fs: unexport vfs_read and vfs_write
      fs: unexport __vfs_read/__vfs_write
      lustre: switch to kernel_write
      gadget/f_mass_storage: stop messing with the address limit
      mconsole: switch to kernel_read
      btrfs: switch write_buf to kernel_write
      net/9p: switch p9_fd_read to kernel_write
      mm/nommu: switch do_mmap_private to kernel_read
      serial2002: switch serial2002_tty_write to kernel_{read/write}
      fs: make the buf argument to __kernel_write a void pointer
      fs: fix kernel_write prototype
      fs: fix kernel_read prototype
      fs: move kernel_read to fs/read_write.c
      fs: move kernel_write to fs/read_write.c
      autofs4: switch autofs4_write to __kernel_write
      ashmem: switch to ->read_iter

commit 0ee931c4e31a5efb134c76440405e9219f896e33
Author: Michal Hocko <mhocko@suse.com>
Date:   Wed Sep 13 16:28:29 2017 -0700

    mm: treewide: remove GFP_TEMPORARY allocation flag
    
    GFP_TEMPORARY was introduced by commit e12ba74d8ff3 ("Group short-lived
    and reclaimable kernel allocations") along with __GFP_RECLAIMABLE.  It's
    primary motivation was to allow users to tell that an allocation is
    short lived and so the allocator can try to place such allocations close
    together and prevent long term fragmentation.  As much as this sounds
    like a reasonable semantic it becomes much less clear when to use the
    highlevel GFP_TEMPORARY allocation flag.  How long is temporary? Can the
    context holding that memory sleep? Can it take locks? It seems there is
    no good answer for those questions.
    
    The current implementation of GFP_TEMPORARY is basically GFP_KERNEL |
    __GFP_RECLAIMABLE which in itself is tricky because basically none of
    the existing caller provide a way to reclaim the allocated memory.  So
    this is rather misleading and hard to evaluate for any benefits.
    
    I have checked some random users and none of them has added the flag
    with a specific justification.  I suspect most of them just copied from
    other existing users and others just thought it might be a good idea to
    use without any measuring.  This suggests that GFP_TEMPORARY just
    motivates for cargo cult usage without any reasoning.
    
    I believe that our gfp flags are quite complex already and especially
    those with highlevel semantic should be clearly defined to prevent from
    confusion and abuse.  Therefore I propose dropping GFP_TEMPORARY and
    replace all existing users to simply use GFP_KERNEL.  Please note that
    SLAB users with shrinkers will still get __GFP_RECLAIMABLE heuristic and
    so they will be placed properly for memory fragmentation prevention.
    
    I can see reasons we might want some gfp flag to reflect shorterm
    allocations but I propose starting from a clear semantic definition and
    only then add users with proper justification.
    
    This was been brought up before LSF this year by Matthew [1] and it
    turned out that GFP_TEMPORARY really doesn't have a clear semantic.  It
    seems to be a heuristic without any measured advantage for most (if not
    all) its current users.  The follow up discussion has revealed that
    opinions on what might be temporary allocation differ a lot between
    developers.  So rather than trying to tweak existing users into a
    semantic which they haven't expected I propose to simply remove the flag
    and start from scratch if we really need a semantic for short term
    allocations.
    
    [1] http://lkml.kernel.org/r/20170118054945.GD18349@bombadil.infradead.org
    
    [akpm@linux-foundation.org: fix typo]
    [akpm@linux-foundation.org: coding-style fixes]
    [sfr@canb.auug.org.au: drm/i915: fix up]
      Link: http://lkml.kernel.org/r/20170816144703.378d4f4d@canb.auug.org.au
    Link: http://lkml.kernel.org/r/20170728091904.14627-1-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Neil Brown <neilb@suse.de>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 01a9fb9d8ac3..daa19d85c066 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1763,9 +1763,9 @@ static int do_execveat_common(int fd, struct filename *filename,
 		bprm->filename = filename->name;
 	} else {
 		if (filename->name[0] == '\0')
-			pathbuf = kasprintf(GFP_TEMPORARY, "/dev/fd/%d", fd);
+			pathbuf = kasprintf(GFP_KERNEL, "/dev/fd/%d", fd);
 		else
-			pathbuf = kasprintf(GFP_TEMPORARY, "/dev/fd/%d/%s",
+			pathbuf = kasprintf(GFP_KERNEL, "/dev/fd/%d/%s",
 					    fd, filename->name);
 		if (!pathbuf) {
 			retval = -ENOMEM;

commit bdd1d2d3d251c65b74ac4493e08db18971c09240
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Sep 1 17:39:13 2017 +0200

    fs: fix kernel_read prototype
    
    Use proper ssize_t and size_t types for the return value and count
    argument, move the offset last and make it an in/out argument like
    all other read/write helpers, and make the buf argument a void pointer
    to get rid of lots of casts in the callers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 8adcc5eaa175..15fb4d56cc43 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -922,8 +922,7 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 
 	pos = 0;
 	while (pos < i_size) {
-		bytes = kernel_read(file, pos, (char *)(*buf) + pos,
-				    i_size - pos);
+		bytes = kernel_read(file, *buf + pos, i_size - pos, &pos);
 		if (bytes < 0) {
 			ret = bytes;
 			goto out;
@@ -931,7 +930,6 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 
 		if (bytes == 0)
 			break;
-		pos += bytes;
 	}
 
 	if (pos != i_size) {
@@ -1524,6 +1522,7 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
 int prepare_binprm(struct linux_binprm *bprm)
 {
 	int retval;
+	loff_t pos = 0;
 
 	bprm_fill_uid(bprm);
 
@@ -1534,7 +1533,7 @@ int prepare_binprm(struct linux_binprm *bprm)
 	bprm->cred_prepared = 1;
 
 	memset(bprm->buf, 0, BINPRM_BUF_SIZE);
-	return kernel_read(bprm->file, 0, bprm->buf, BINPRM_BUF_SIZE);
+	return kernel_read(bprm->file, bprm->buf, BINPRM_BUF_SIZE, &pos);
 }
 
 EXPORT_SYMBOL(prepare_binprm);

commit c41fbad015dabb0a40ecca50c3ff5658eb6471ff
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Sep 1 17:39:12 2017 +0200

    fs: move kernel_read to fs/read_write.c
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 62175cbcc801..8adcc5eaa175 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -885,23 +885,6 @@ struct file *open_exec(const char *name)
 }
 EXPORT_SYMBOL(open_exec);
 
-int kernel_read(struct file *file, loff_t offset,
-		char *addr, unsigned long count)
-{
-	mm_segment_t old_fs;
-	loff_t pos = offset;
-	int result;
-
-	old_fs = get_fs();
-	set_fs(get_ds());
-	/* The cast to a user pointer is valid due to the set_fs() */
-	result = vfs_read(file, (void __user *)addr, count, &pos);
-	set_fs(old_fs);
-	return result;
-}
-
-EXPORT_SYMBOL(kernel_read);
-
 int kernel_read_file(struct file *file, void **buf, loff_t *size,
 		     loff_t max_size, enum kernel_read_file_id id)
 {

commit fe8993b3a05cbba6318a54e0f85901aaea6fc244
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:36 2017 -0700

    exec: Consolidate pdeath_signal clearing
    
    Instead of an additional secureexec check for pdeath_signal, just move it
    up into the initial secureexec test. Neither perf nor arch code touches
    pdeath_signal, so the relocation shouldn't change anything.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Serge Hallyn <serge@hallyn.com>

diff --git a/fs/exec.c b/fs/exec.c
index 3235cbd85efa..01a9fb9d8ac3 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1351,6 +1351,9 @@ void setup_new_exec(struct linux_binprm * bprm)
 	bprm->secureexec |= bprm->cap_elevated;
 
 	if (bprm->secureexec) {
+		/* Make sure parent cannot signal privileged process. */
+		current->pdeath_signal = 0;
+
 		/*
 		 * For secureexec, reset the stack limit to sane default to
 		 * avoid bad behavior from the prior rlimits. This has to
@@ -1383,10 +1386,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 	 */
 	current->mm->task_size = TASK_SIZE;
 
-	if (bprm->secureexec) {
-		current->pdeath_signal = 0;
-	}
-
 	/* An exec changes our domain. We are no longer part of the thread
 	   group */
 	current->self_exec_id++;

commit 64701dee4178eb4a771b8b36cd86560f5b0e2460
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:35 2017 -0700

    exec: Use sane stack rlimit under secureexec
    
    For a secureexec, before memory layout selection has happened, reset the
    stack rlimit to something sane to avoid the caller having control over
    the resulting layouts.
    
    $ ulimit -s
    8192
    $ ulimit -s unlimited
    $ /bin/sh -c 'ulimit -s'
    unlimited
    $ sudo /bin/sh -c 'ulimit -s'
    8192
    
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: James Morris <james.l.morris@oracle.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>

diff --git a/fs/exec.c b/fs/exec.c
index 3006c1c24304..3235cbd85efa 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1350,6 +1350,18 @@ void setup_new_exec(struct linux_binprm * bprm)
 	 */
 	bprm->secureexec |= bprm->cap_elevated;
 
+	if (bprm->secureexec) {
+		/*
+		 * For secureexec, reset the stack limit to sane default to
+		 * avoid bad behavior from the prior rlimits. This has to
+		 * happen before arch_pick_mmap_layout(), which examines
+		 * RLIMIT_STACK, but after the point of no return to avoid
+		 * needing to clean up the change on failure.
+		 */
+		if (current->signal->rlim[RLIMIT_STACK].rlim_cur > _STK_LIM)
+			current->signal->rlim[RLIMIT_STACK].rlim_cur = _STK_LIM;
+	}
+
 	arch_pick_mmap_layout(current->mm);
 
 	current->sas_ss_sp = current->sas_ss_size = 0;

commit 473d89639db0aaa0799616b397584ba4f58cd8e1
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:34 2017 -0700

    exec: Consolidate dumpability logic
    
    Since it's already valid to set dumpability in the early part of
    setup_new_exec(), we can consolidate the logic into a single place.
    The BINPRM_FLAGS_ENFORCE_NONDUMP is set during would_dump() calls
    before setup_new_exec(), so its test is safe to move as well.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    Reviewed-by: James Morris <james.l.morris@oracle.com>

diff --git a/fs/exec.c b/fs/exec.c
index 7a9288551d62..3006c1c24304 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1354,10 +1354,12 @@ void setup_new_exec(struct linux_binprm * bprm)
 
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
-	if (!bprm->secureexec)
-		set_dumpable(current->mm, SUID_DUMP_USER);
-	else
+	/* Figure out dumpability. */
+	if (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP ||
+	    bprm->secureexec)
 		set_dumpable(current->mm, suid_dumpable);
+	else
+		set_dumpable(current->mm, SUID_DUMP_USER);
 
 	arch_setup_new_exec();
 	perf_event_exec();
@@ -1371,9 +1373,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 
 	if (bprm->secureexec) {
 		current->pdeath_signal = 0;
-	} else {
-		if (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)
-			set_dumpable(current->mm, suid_dumpable);
 	}
 
 	/* An exec changes our domain. We are no longer part of the thread

commit a70423dfbc58402cc2573f95b7e842024aff7162
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:32 2017 -0700

    exec: Use secureexec for clearing pdeath_signal
    
    Like dumpability, clearing pdeath_signal happens both in setup_new_exec()
    and later in commit_creds(). The test in setup_new_exec() is different
    from all other privilege comparisons, though: it is checking the new cred
    (bprm) uid vs the old cred (current) euid. This appears to be a bug,
    introduced by commit a6f76f23d297 ("CRED: Make execve() take advantage of
    copy-on-write credentials"):
    
    -       if (bprm->e_uid != current_euid() ||
    -           bprm->e_gid != current_egid()) {
    -               set_dumpable(current->mm, suid_dumpable);
    +       if (bprm->cred->uid != current_euid() ||
    +           bprm->cred->gid != current_egid()) {
    
    It was bprm euid vs current euid (and egids), but the effective got
    dropped. Nothing in the exec flow changes bprm->cred->uid (nor gid).
    The call traces are:
    
            prepare_bprm_creds()
                prepare_exec_creds()
                    prepare_creds()
                        memcpy(new_creds, old_creds, ...)
                        security_prepare_creds() (unimplemented by commoncap)
            ...
            prepare_binprm()
                bprm_fill_uid()
                    resets euid/egid to current euid/egid
                    sets euid/egid on bprm based on set*id file bits
                security_bprm_set_creds()
                    cap_bprm_set_creds()
                            handle all caps-based manipulations
    
    so this test is effectively a test of current_uid() vs current_euid(),
    which is wrong, just like the prior dumpability tests were wrong.
    
    The commit log says "Clear pdeath_signal and set dumpable on
    certain circumstances that may not be covered by commit_creds()." This
    may be meaning the earlier old euid vs new euid (and egid) test that
    got changed.
    
    Luckily, as with dumpability, this is all masked by commit_creds()
    which performs old/new euid and egid tests and clears pdeath_signal.
    
    And again, like dumpability, we should include LSM secureexec logic for
    pdeath_signal clearing. For example, Smack goes out of its way to clear
    pdeath_signal when it finds a secureexec condition.
    
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    Reviewed-by: James Morris <james.l.morris@oracle.com>

diff --git a/fs/exec.c b/fs/exec.c
index 3536437ffd76..7a9288551d62 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1369,8 +1369,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 	 */
 	current->mm->task_size = TASK_SIZE;
 
-	if (!uid_eq(bprm->cred->uid, current_euid()) ||
-	    !gid_eq(bprm->cred->gid, current_egid())) {
+	if (bprm->secureexec) {
 		current->pdeath_signal = 0;
 	} else {
 		if (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)

commit e37fdb785a5f95ecadf43b773c97f676500ac7b8
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:31 2017 -0700

    exec: Use secureexec for setting dumpability
    
    The examination of "current" to decide dumpability is wrong. This was a
    check of and euid/uid (or egid/gid) mismatch in the existing process,
    not the newly created one. This appears to stretch back into even the
    "history.git" tree. Luckily, dumpability is later set in commit_creds().
    In earlier kernel versions before creds existed, similar checks also
    existed late in the exec flow, covering up the mistake as far back as I
    could find.
    
    Note that because the commit_creds() check examines differences of euid,
    uid, egid, gid, and capabilities between the old and new creds, it would
    look like the setup_new_exec() dumpability test could be entirely removed.
    However, the secureexec test may cover a different set of tests (specific
    to the LSMs) than what commit_creds() checks for. So, fix this test to
    use secureexec (the removed euid tests are redundant to the commoncap
    secureexec checks now).
    
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    Reviewed-by: James Morris <james.l.morris@oracle.com>

diff --git a/fs/exec.c b/fs/exec.c
index eca0cb550a06..3536437ffd76 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1354,7 +1354,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
-	if (uid_eq(current_euid(), current_uid()) && gid_eq(current_egid(), current_gid()))
+	if (!bprm->secureexec)
 		set_dumpable(current->mm, SUID_DUMP_USER);
 	else
 		set_dumpable(current->mm, suid_dumpable);

commit 2af622802696e1dbe28d81c8ea6355dc30800396
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:29 2017 -0700

    LSM: drop bprm_secureexec hook
    
    This removes the bprm_secureexec hook since the logic has been folded into
    the bprm_set_creds hook for all LSMs now.
    
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: John Johansen <john.johansen@canonical.com>
    Acked-by: James Morris <james.l.morris@oracle.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>

diff --git a/fs/exec.c b/fs/exec.c
index 1536bc4502cc..eca0cb550a06 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1343,8 +1343,6 @@ EXPORT_SYMBOL(would_dump);
 
 void setup_new_exec(struct linux_binprm * bprm)
 {
-	bprm->secureexec |= security_bprm_secureexec(bprm);
-
 	/*
 	 * Once here, prepare_binrpm() will not be called any more, so
 	 * the final state of setuid/setgid/fscaps can be merged into the

commit 46d98eb4e1d2bc225f661879e0e157a952107598
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:27 2017 -0700

    commoncap: Refactor to remove bprm_secureexec hook
    
    The commoncap implementation of the bprm_secureexec hook is the only LSM
    that depends on the final call to its bprm_set_creds hook (since it may
    be called for multiple files, it ignores bprm->called_set_creds). As a
    result, it cannot safely _clear_ bprm->secureexec since other LSMs may
    have set it.  Instead, remove the bprm_secureexec hook by introducing a
    new flag to bprm specific to commoncap: cap_elevated. This is similar to
    cap_effective, but that is used for a specific subset of elevated
    privileges, and exists solely to track state from bprm_set_creds to
    bprm_secureexec. As such, it will be removed in the next patch.
    
    Here, set the new bprm->cap_elevated flag when setuid/setgid has happened
    from bprm_fill_uid() or fscapabilities have been prepared. This temporarily
    moves the bprm_secureexec hook to a static inline. The helper will be
    removed in the next patch; this makes the step easier to review and bisect,
    since this does not introduce any changes to inputs nor outputs to the
    "elevated privileges" calculation.
    
    The new flag is merged with the bprm->secureexec flag in setup_new_exec()
    since this marks the end of any further prepare_binprm() calls.
    
    Cc: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Acked-by: James Morris <james.l.morris@oracle.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>

diff --git a/fs/exec.c b/fs/exec.c
index 0f361115c88f..1536bc4502cc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1345,6 +1345,13 @@ void setup_new_exec(struct linux_binprm * bprm)
 {
 	bprm->secureexec |= security_bprm_secureexec(bprm);
 
+	/*
+	 * Once here, prepare_binrpm() will not be called any more, so
+	 * the final state of setuid/setgid/fscaps can be merged into the
+	 * secureexec flag.
+	 */
+	bprm->secureexec |= bprm->cap_elevated;
+
 	arch_pick_mmap_layout(current->mm);
 
 	current->sas_ss_sp = current->sas_ss_size = 0;

commit c425e189ffd7720c881fe9ccd7143cea577f6d03
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:22 2017 -0700

    binfmt: Introduce secureexec flag
    
    The bprm_secureexec hook can be moved earlier. Right now, it is called
    during create_elf_tables(), via load_binary(), via search_binary_handler(),
    via exec_binprm(). Nearly all (see exception below) state used by
    bprm_secureexec is created during the bprm_set_creds hook, called from
    prepare_binprm().
    
    For all LSMs (except commoncaps described next), only the first execution
    of bprm_set_creds takes any effect (they all check bprm->called_set_creds
    which prepare_binprm() sets after the first call to the bprm_set_creds
    hook).  However, all these LSMs also only do anything with bprm_secureexec
    when they detected a secure state during their first run of bprm_set_creds.
    Therefore, it is functionally identical to move the detection into
    bprm_set_creds, since the results from secureexec here only need to be
    based on the first call to the LSM's bprm_set_creds hook.
    
    The single exception is that the commoncaps secureexec hook also examines
    euid/uid and egid/gid differences which are controlled by bprm_fill_uid(),
    via prepare_binprm(), which can be called multiple times (e.g.
    binfmt_script, binfmt_misc), and may clear the euid/egid for the final
    load (i.e. the script interpreter). However, while commoncaps specifically
    ignores bprm->cred_prepared, and runs its bprm_set_creds hook each time
    prepare_binprm() may get called, it needs to base the secureexec decision
    on the final call to bprm_set_creds. As a result, it will need special
    handling.
    
    To begin this refactoring, this adds the secureexec flag to the bprm
    struct, and calls the secureexec hook during setup_new_exec(). This is
    safe since all the cred work is finished (and past the point of no return).
    This explicit call will be removed in later patches once the hook has been
    removed.
    
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: John Johansen <john.johansen@canonical.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    Reviewed-by: James Morris <james.l.morris@oracle.com>

diff --git a/fs/exec.c b/fs/exec.c
index 26b98072be50..0f361115c88f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1343,6 +1343,8 @@ EXPORT_SYMBOL(would_dump);
 
 void setup_new_exec(struct linux_binprm * bprm)
 {
+	bprm->secureexec |= security_bprm_secureexec(bprm);
+
 	arch_pick_mmap_layout(current->mm);
 
 	current->sas_ss_sp = current->sas_ss_size = 0;

commit a9208e42ba99bfe63bdf5f76aaf0193ad3805f02
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:30 2017 -0700

    exec: Correct comments about "point of no return"
    
    In commit 221af7f87b97 ("Split 'flush_old_exec' into two functions"),
    the comment about the point of no return should have stayed in
    flush_old_exec() since it refers to "bprm->mm = NULL;" line, but prior
    changes in commits c89681ed7d0e ("remove steal_locks()"), and
    fd8328be874f ("sanitize handling of shared descriptor tables in failing
    execve()") made it look like it meant the current->sas_ss_sp line instead.
    
    The comment was referring to the fact that once bprm->mm is NULL, all
    failures from a binfmt load_binary hook (e.g. load_elf_binary), will
    get SEGV raised against current. Move this comment and expand the
    explanation a bit, putting it above the assignment this time, and add
    details about the true nature of "point of no return" being the call
    to flush_old_exec() itself.
    
    This also removes an erroneous commet about when credentials are being
    installed. That has its own dedicated function, install_exec_creds(),
    which carries a similar (and correct) comment, so remove the bogus comment
    where installation is not actually happening.
    
    Cc: David Howells <dhowells@redhat.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>

diff --git a/fs/exec.c b/fs/exec.c
index a0fff86269e4..26b98072be50 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1259,6 +1259,12 @@ void __set_task_comm(struct task_struct *tsk, const char *buf, bool exec)
 	perf_event_comm(tsk, exec);
 }
 
+/*
+ * Calling this is the point of no return. None of the failures will be
+ * seen by userspace since either the process is already taking a fatal
+ * signal (via de_thread() or coredump), or will have SEGV raised
+ * (after exec_mmap()) by search_binary_handlers (see below).
+ */
 int flush_old_exec(struct linux_binprm * bprm)
 {
 	int retval;
@@ -1286,7 +1292,13 @@ int flush_old_exec(struct linux_binprm * bprm)
 	if (retval)
 		goto out;
 
-	bprm->mm = NULL;		/* We're using it now */
+	/*
+	 * After clearing bprm->mm (to mark that current is using the
+	 * prepared mm now), we have nothing left of the original
+	 * process. If anything from here on returns an error, the check
+	 * in search_binary_handler() will SEGV current.
+	 */
+	bprm->mm = NULL;
 
 	set_fs(USER_DS);
 	current->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD |
@@ -1333,7 +1345,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 {
 	arch_pick_mmap_layout(current->mm);
 
-	/* This is the point of no return */
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
 	if (uid_eq(current_euid(), current_uid()) && gid_eq(current_egid(), current_gid()))
@@ -1351,7 +1362,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 	 */
 	current->mm->task_size = TASK_SIZE;
 
-	/* install the new credentials */
 	if (!uid_eq(bprm->cred->uid, current_euid()) ||
 	    !gid_eq(bprm->cred->gid, current_egid())) {
 		current->pdeath_signal = 0;

commit ddb4a1442def2a78b91a85b4251fb712ef23662b
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 18 15:25:23 2017 -0700

    exec: Rename bprm->cred_prepared to called_set_creds
    
    The cred_prepared bprm flag has a misleading name. It has nothing to do
    with the bprm_prepare_cred hook, and actually tracks if bprm_set_creds has
    been called. Rename this flag and improve its comment.
    
    Cc: David Howells <dhowells@redhat.com>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: Casey Schaufler <casey@schaufler-ca.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: John Johansen <john.johansen@canonical.com>
    Acked-by: James Morris <james.l.morris@oracle.com>
    Acked-by: Paul Moore <paul@paul-moore.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>

diff --git a/fs/exec.c b/fs/exec.c
index 62175cbcc801..a0fff86269e4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1548,7 +1548,7 @@ int prepare_binprm(struct linux_binprm *bprm)
 	retval = security_bprm_set_creds(bprm);
 	if (retval)
 		return retval;
-	bprm->cred_prepared = 1;
+	bprm->called_set_creds = 1;
 
 	memset(bprm->buf, 0, BINPRM_BUF_SIZE);
 	return kernel_read(bprm->file, 0, bprm->buf, BINPRM_BUF_SIZE);

commit da029c11e6b12f321f36dac8771e833b65cec962
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Jul 7 11:57:29 2017 -0700

    exec: Limit arg stack to at most 75% of _STK_LIM
    
    To avoid pathological stack usage or the need to special-case setuid
    execs, just limit all arg stack usage to at most 75% of _STK_LIM (6MB).
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 904199086490..62175cbcc801 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -220,8 +220,7 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 
 	if (write) {
 		unsigned long size = bprm->vma->vm_end - bprm->vma->vm_start;
-		unsigned long ptr_size;
-		struct rlimit *rlim;
+		unsigned long ptr_size, limit;
 
 		/*
 		 * Since the stack will hold pointers to the strings, we
@@ -250,14 +249,16 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 			return page;
 
 		/*
-		 * Limit to 1/4-th the stack size for the argv+env strings.
+		 * Limit to 1/4 of the max stack size or 3/4 of _STK_LIM
+		 * (whichever is smaller) for the argv+env strings.
 		 * This ensures that:
 		 *  - the remaining binfmt code will not run out of stack space,
 		 *  - the program will have a reasonable amount of stack left
 		 *    to work from.
 		 */
-		rlim = current->signal->rlim;
-		if (size > READ_ONCE(rlim[RLIMIT_STACK].rlim_cur) / 4)
+		limit = _STK_LIM / 4 * 3;
+		limit = min(limit, rlimit(RLIMIT_STACK) / 4);
+		if (size > limit)
 			goto fail;
 	}
 

commit 98da7d08850fb8bdeb395d6368ed15753304aa0c
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Jun 23 15:08:57 2017 -0700

    fs/exec.c: account for argv/envp pointers
    
    When limiting the argv/envp strings during exec to 1/4 of the stack limit,
    the storage of the pointers to the strings was not included.  This means
    that an exec with huge numbers of tiny strings could eat 1/4 of the stack
    limit in strings and then additional space would be later used by the
    pointers to the strings.
    
    For example, on 32-bit with a 8MB stack rlimit, an exec with 1677721
    single-byte strings would consume less than 2MB of stack, the max (8MB /
    4) amount allowed, but the pointers to the strings would consume the
    remaining additional stack space (1677721 * 4 == 6710884).
    
    The result (1677721 + 6710884 == 8388605) would exhaust stack space
    entirely.  Controlling this stack exhaustion could result in
    pathological behavior in setuid binaries (CVE-2017-1000365).
    
    [akpm@linux-foundation.org: additional commenting from Kees]
    Fixes: b6a2fea39318 ("mm: variable length argument support")
    Link: http://lkml.kernel.org/r/20170622001720.GA32173@beast
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Rik van Riel <riel@redhat.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Qualys Security Advisory <qsa@qualys.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 72934df68471..904199086490 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -220,8 +220,26 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 
 	if (write) {
 		unsigned long size = bprm->vma->vm_end - bprm->vma->vm_start;
+		unsigned long ptr_size;
 		struct rlimit *rlim;
 
+		/*
+		 * Since the stack will hold pointers to the strings, we
+		 * must account for them as well.
+		 *
+		 * The size calculation is the entire vma while each arg page is
+		 * built, so each time we get here it's calculating how far it
+		 * is currently (rather than each call being just the newly
+		 * added size from the arg page).  As a result, we need to
+		 * always add the entire size of the pointers, so that on the
+		 * last call to get_arg_page() we'll actually have the entire
+		 * correct size.
+		 */
+		ptr_size = (bprm->argc + bprm->envc) * sizeof(void *);
+		if (ptr_size > ULONG_MAX - size)
+			goto fail;
+		size += ptr_size;
+
 		acct_arg_size(bprm, size / PAGE_SIZE);
 
 		/*
@@ -239,13 +257,15 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		 *    to work from.
 		 */
 		rlim = current->signal->rlim;
-		if (size > ACCESS_ONCE(rlim[RLIMIT_STACK].rlim_cur) / 4) {
-			put_page(page);
-			return NULL;
-		}
+		if (size > READ_ONCE(rlim[RLIMIT_STACK].rlim_cur) / 4)
+			goto fail;
 	}
 
 	return page;
+
+fail:
+	put_page(page);
+	return NULL;
 }
 
 static void put_arg_page(struct page *page)

commit e9ea1e7f53b852147cbd568b0568c7ad97ec21a3
Author: Kyle Huey <me@kylehuey.com>
Date:   Mon Mar 20 01:16:26 2017 -0700

    x86/arch_prctl: Add ARCH_[GET|SET]_CPUID
    
    Intel supports faulting on the CPUID instruction beginning with Ivy Bridge.
    When enabled, the processor will fault on attempts to execute the CPUID
    instruction with CPL>0. Exposing this feature to userspace will allow a
    ptracer to trap and emulate the CPUID instruction.
    
    When supported, this feature is controlled by toggling bit 0 of
    MSR_MISC_FEATURES_ENABLES. It is documented in detail in Section 2.3.2 of
    https://bugzilla.kernel.org/attachment.cgi?id=243991
    
    Implement a new pair of arch_prctls, available on both x86-32 and x86-64.
    
    ARCH_GET_CPUID: Returns the current CPUID state, either 0 if CPUID faulting
        is enabled (and thus the CPUID instruction is not available) or 1 if
        CPUID faulting is not enabled.
    
    ARCH_SET_CPUID: Set the CPUID state to the second argument. If
        cpuid_enabled is 0 CPUID faulting will be activated, otherwise it will
        be deactivated. Returns ENODEV if CPUID faulting is not supported on
        this system.
    
    The state of the CPUID faulting flag is propagated across forks, but reset
    upon exec.
    
    Signed-off-by: Kyle Huey <khuey@kylehuey.com>
    Cc: Grzegorz Andrejczuk <grzegorz.andrejczuk@intel.com>
    Cc: kvm@vger.kernel.org
    Cc: Radim Krm <rkrcmar@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: linux-kselftest@vger.kernel.org
    Cc: Nadav Amit <nadav.amit@gmail.com>
    Cc: Robert O'Callahan <robert@ocallahan.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: "Rafael J. Wysocki" <rafael.j.wysocki@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Shuah Khan <shuah@kernel.org>
    Cc: user-mode-linux-devel@lists.sourceforge.net
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: user-mode-linux-user@lists.sourceforge.net
    Cc: David Matlack <dmatlack@google.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Dmitry Safonov <dsafonov@virtuozzo.com>
    Cc: linux-fsdevel@vger.kernel.org
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Link: http://lkml.kernel.org/r/20170320081628.18952-9-khuey@kylehuey.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/fs/exec.c b/fs/exec.c
index 65145a3df065..72934df68471 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1320,6 +1320,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 	else
 		set_dumpable(current->mm, suid_dumpable);
 
+	arch_setup_new_exec();
 	perf_event_exec();
 	__set_task_comm(current, kbasename(bprm->filename), true);
 

commit 299300258d1bc4e997b7db340a2e06636757fe2e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:36 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task.h>
    
    We are going to split <linux/sched/task.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index e857c7260b1f..65145a3df065 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -36,6 +36,7 @@
 #include <linux/sched/coredump.h>
 #include <linux/sched/signal.h>
 #include <linux/sched/numa_balancing.h>
+#include <linux/sched/task.h>
 #include <linux/pagemap.h>
 #include <linux/perf_event.h>
 #include <linux/highmem.h>

commit 6a3827d7509cbf96b7e961f8957c1f01d1bcf894
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:31 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/numa_balancing.h>
    
    We are going to split <linux/sched/numa_balancing.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/numa_balancing.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index aa228b98ad5b..e857c7260b1f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -35,6 +35,7 @@
 #include <linux/sched/mm.h>
 #include <linux/sched/coredump.h>
 #include <linux/sched/signal.h>
+#include <linux/sched/numa_balancing.h>
 #include <linux/pagemap.h>
 #include <linux/perf_event.h>
 #include <linux/highmem.h>

commit 3f07c0144132e4f59d88055ac8ff3e691a5fa2b8
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:30 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/signal.h>
    
    We are going to split <linux/sched/signal.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/signal.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9c80d011594e..aa228b98ad5b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -34,6 +34,7 @@
 #include <linux/init.h>
 #include <linux/sched/mm.h>
 #include <linux/sched/coredump.h>
+#include <linux/sched/signal.h>
 #include <linux/pagemap.h>
 #include <linux/perf_event.h>
 #include <linux/highmem.h>

commit f7ccbae45c5e2c1077654b0e857e7efb1aa31c92
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:30 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/coredump.h>
    
    We are going to split <linux/sched/coredump.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/coredump.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 8929da96cca1..9c80d011594e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -33,6 +33,7 @@
 #include <linux/string.h>
 #include <linux/init.h>
 #include <linux/sched/mm.h>
+#include <linux/sched/coredump.h>
 #include <linux/pagemap.h>
 #include <linux/perf_event.h>
 #include <linux/highmem.h>

commit 6e84f31522f931027bf695752087ece278c10d3f
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:29 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/mm.h>
    
    We are going to split <linux/sched/mm.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/mm.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    The APIs that are going to be moved first are:
    
       mm_alloc()
       __mmdrop()
       mmdrop()
       mmdrop_async_fn()
       mmdrop_async()
       mmget_not_zero()
       mmput()
       mmput_async()
       get_task_mm()
       mm_access()
       mm_release()
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index e595e1529581..8929da96cca1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -32,6 +32,7 @@
 #include <linux/swap.h>
 #include <linux/string.h>
 #include <linux/init.h>
+#include <linux/sched/mm.h>
 #include <linux/pagemap.h>
 #include <linux/perf_event.h>
 #include <linux/highmem.h>

commit 780de9dd2720debc14c501dab4dc80d1f75ad50e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Feb 2 11:50:56 2017 +0100

    sched/headers, cgroups: Remove the threadgroup_change_*() wrappery
    
    threadgroup_change_begin()/end() is a pointless wrapper around
    cgroup_threadgroup_change_begin()/end(), minus a might_sleep()
    in the !CONFIG_CGROUPS=y case.
    
    Remove the wrappery, move the might_sleep() (the down_read()
    already has a might_sleep() check).
    
    This debloats <linux/sched.h> a bit and simplifies this API.
    
    Update all call sites.
    
    No change in functionality.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 698a86094f76..e595e1529581 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1088,7 +1088,7 @@ static int de_thread(struct task_struct *tsk)
 		struct task_struct *leader = tsk->group_leader;
 
 		for (;;) {
-			threadgroup_change_begin(tsk);
+			cgroup_threadgroup_change_begin(tsk);
 			write_lock_irq(&tasklist_lock);
 			/*
 			 * Do this under tasklist_lock to ensure that
@@ -1099,7 +1099,7 @@ static int de_thread(struct task_struct *tsk)
 				break;
 			__set_current_state(TASK_KILLABLE);
 			write_unlock_irq(&tasklist_lock);
-			threadgroup_change_end(tsk);
+			cgroup_threadgroup_change_end(tsk);
 			schedule();
 			if (unlikely(__fatal_signal_pending(tsk)))
 				goto killed;
@@ -1157,7 +1157,7 @@ static int de_thread(struct task_struct *tsk)
 		if (unlikely(leader->ptrace))
 			__wake_up_parent(leader, leader->parent);
 		write_unlock_irq(&tasklist_lock);
-		threadgroup_change_end(tsk);
+		cgroup_threadgroup_change_end(tsk);
 
 		release_task(leader);
 	}

commit fea6d2a610c899bb7fd8e95fcbf46900b886e5a3
Author: Vivek Goyal <vgoyal@redhat.com>
Date:   Mon Feb 13 15:45:26 2017 -0500

    vfs: Use upper filesystem inode in bprm_fill_uid()
    
    Right now bprm_fill_uid() uses inode fetched from file_inode(bprm->file).
    This in turn returns inode of lower filesystem (in a stacked filesystem
    setup).
    
    I was playing with modified patches of shiftfs posted by james bottomley
    and realized that through shiftfs setuid bit does not take effect. And
    reason being that we fetch uid/gid from inode of lower fs (and not from
    shiftfs inode). And that results in following checks failing.
    
    /* We ignore suid/sgid if there are no mappings for them in the ns */
    if (!kuid_has_mapping(bprm->cred->user_ns, uid) ||
        !kgid_has_mapping(bprm->cred->user_ns, gid))
            return;
    
    uid/gid fetched from lower fs inode might not be mapped inside the user
    namespace of container. So we need to look at uid/gid fetched from
    upper filesystem (shiftfs in this particular case) and these should be
    mapped and setuid bit can take affect.
    
    Signed-off-by: Vivek Goyal <vgoyal@redhat.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index c195ebb8e2aa..698a86094f76 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1475,7 +1475,7 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
 	if (task_no_new_privs(current))
 		return;
 
-	inode = file_inode(bprm->file);
+	inode = bprm->file->f_path.dentry->d_inode;
 	mode = READ_ONCE(inode->i_mode);
 	if (!(mode & (S_ISUID|S_ISGID)))
 		return;

commit 9227dd2a84a765fcfef1677ff17de0958b192eda
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jan 23 17:26:31 2017 +1300

    exec: Remove LSM_UNSAFE_PTRACE_CAP
    
    With previous changes every location that tests for
    LSM_UNSAFE_PTRACE_CAP also tests for LSM_UNSAFE_PTRACE making the
    LSM_UNSAFE_PTRACE_CAP redundant, so remove it.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index e57946610733..c195ebb8e2aa 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1426,12 +1426,8 @@ static void check_unsafe_exec(struct linux_binprm *bprm)
 	struct task_struct *p = current, *t;
 	unsigned n_fs;
 
-	if (p->ptrace) {
-		if (ptracer_capable(p, current_user_ns()))
-			bprm->unsafe |= LSM_UNSAFE_PTRACE_CAP;
-		else
-			bprm->unsafe |= LSM_UNSAFE_PTRACE;
-	}
+	if (p->ptrace)
+		bprm->unsafe |= LSM_UNSAFE_PTRACE;
 
 	/*
 	 * This isn't strictly necessary, but it makes it harder for LSMs to

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index eadbf5069c38..e57946610733 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -58,7 +58,7 @@
 #include <linux/compat.h>
 #include <linux/vmalloc.h>
 
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlb.h>
 

commit 613cc2b6f272c1a8ad33aefa21cad77af23139f7
Author: Aleksa Sarai <asarai@suse.de>
Date:   Wed Dec 21 16:26:24 2016 +1100

    fs: exec: apply CLOEXEC before changing dumpable task flags
    
    If you have a process that has set itself to be non-dumpable, and it
    then undergoes exec(2), any CLOEXEC file descriptors it has open are
    "exposed" during a race window between the dumpable flags of the process
    being reset for exec(2) and CLOEXEC being applied to the file
    descriptors. This can be exploited by a process by attempting to access
    /proc/<pid>/fd/... during this window, without requiring CAP_SYS_PTRACE.
    
    The race in question is after set_dumpable has been (for get_link,
    though the trace is basically the same for readlink):
    
    [vfs]
    -> proc_pid_link_inode_operations.get_link
       -> proc_pid_get_link
          -> proc_fd_access_allowed
             -> ptrace_may_access(task, PTRACE_MODE_READ_FSCREDS);
    
    Which will return 0, during the race window and CLOEXEC file descriptors
    will still be open during this window because do_close_on_exec has not
    been called yet. As a result, the ordering of these calls should be
    reversed to avoid this race window.
    
    This is of particular concern to container runtimes, where joining a
    PID namespace with file descriptors referring to the host filesystem
    can result in security issues (since PRCTL_SET_DUMPABLE doesn't protect
    against access of CLOEXEC file descriptors -- file descriptors which may
    reference filesystem objects the container shouldn't have access to).
    
    Cc: dev@opencontainers.org
    Cc: <stable@vger.kernel.org> # v3.2+
    Reported-by: Michael Crosby <crosbymichael@gmail.com>
    Signed-off-by: Aleksa Sarai <asarai@suse.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 8112eacf10f3..eadbf5069c38 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -19,7 +19,7 @@
  * current->executable is only used by the procfs.  This allows a dispatch
  * table to check for several different types  of binary formats.  We keep
  * trying until we recognize the file or we run out of supported binary
- * formats. 
+ * formats.
  */
 
 #include <linux/slab.h>
@@ -1268,6 +1268,13 @@ int flush_old_exec(struct linux_binprm * bprm)
 	flush_thread();
 	current->personality &= ~bprm->per_clear;
 
+	/*
+	 * We have to apply CLOEXEC before we change whether the process is
+	 * dumpable (in setup_new_exec) to avoid a race with a process in userspace
+	 * trying to access the should-be-closed file descriptors of a process
+	 * undergoing exec(2).
+	 */
+	do_close_on_exec(current->files);
 	return 0;
 
 out:
@@ -1330,7 +1337,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 	   group */
 	current->self_exec_id++;
 	flush_signal_handlers(current, 0);
-	do_close_on_exec(current->files);
 }
 EXPORT_SYMBOL(setup_new_exec);
 

commit a57cb1c1d7974c62a5c80f7869e35b492ace12cd
Merge: cf1b3341afab e1e14ab8411d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 14 17:25:18 2016 -0800

    Merge branch 'akpm' (patches from Andrew)
    
    Merge more updates from Andrew Morton:
    
     - a few misc things
    
     - kexec updates
    
     - DMA-mapping updates to better support networking DMA operations
    
     - IPC updates
    
     - various MM changes to improve DAX fault handling
    
     - lots of radix-tree changes, mainly to the test suite. All leading up
       to reimplementing the IDA/IDR code to be a wrapper layer over the
       radix-tree. However the final trigger-pulling patch is held off for
       4.11.
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (114 commits)
      radix tree test suite: delete unused rcupdate.c
      radix tree test suite: add new tag check
      radix-tree: ensure counts are initialised
      radix tree test suite: cache recently freed objects
      radix tree test suite: add some more functionality
      idr: reduce the number of bits per level from 8 to 6
      rxrpc: abstract away knowledge of IDR internals
      tpm: use idr_find(), not idr_find_slowpath()
      idr: add ida_is_empty
      radix tree test suite: check multiorder iteration
      radix-tree: fix replacement for multiorder entries
      radix-tree: add radix_tree_split_preload()
      radix-tree: add radix_tree_split
      radix-tree: add radix_tree_join
      radix-tree: delete radix_tree_range_tag_if_tagged()
      radix-tree: delete radix_tree_locate_item()
      radix-tree: improve multiorder iterators
      btrfs: fix race in btrfs_free_dummy_fs_info()
      radix-tree: improve dump output
      radix-tree: make radix_tree_find_next_bit more useful
      ...

commit 5b56d49fc31dbb0487e14ead790fc81ca9fb2c99
Author: Lorenzo Stoakes <lstoakes@gmail.com>
Date:   Wed Dec 14 15:06:52 2016 -0800

    mm: add locked parameter to get_user_pages_remote()
    
    Patch series "mm: unexport __get_user_pages_unlocked()".
    
    This patch series continues the cleanup of get_user_pages*() functions
    taking advantage of the fact we can now pass gup_flags as we please.
    
    It firstly adds an additional 'locked' parameter to
    get_user_pages_remote() to allow for its callers to utilise
    VM_FAULT_RETRY functionality.  This is necessary as the invocation of
    __get_user_pages_unlocked() in process_vm_rw_single_vec() makes use of
    this and no other existing higher level function would allow it to do
    so.
    
    Secondly existing callers of __get_user_pages_unlocked() are replaced
    with the appropriate higher-level replacement -
    get_user_pages_unlocked() if the current task and memory descriptor are
    referenced, or get_user_pages_remote() if other task/memory descriptors
    are referenced (having acquiring mmap_sem.)
    
    This patch (of 2):
    
    Add a int *locked parameter to get_user_pages_remote() to allow
    VM_FAULT_RETRY faulting behaviour similar to get_user_pages_[un]locked().
    
    Taking into account the previous adjustments to get_user_pages*()
    functions allowing for the passing of gup_flags, we are now in a
    position where __get_user_pages_unlocked() need only be exported for his
    ability to allow VM_FAULT_RETRY behaviour, this adjustment allows us to
    subsequently unexport __get_user_pages_unlocked() as well as allowing
    for future flexibility in the use of get_user_pages_remote().
    
    [sfr@canb.auug.org.au: merge fix for get_user_pages_remote API change]
      Link: http://lkml.kernel.org/r/20161122210511.024ec341@canb.auug.org.au
    Link: http://lkml.kernel.org/r/20161027095141.2569-2-lstoakes@gmail.com
    Signed-off-by: Lorenzo Stoakes <lstoakes@gmail.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim Krcmar <rkrcmar@redhat.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 923c57d96899..eac60886b0ab 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -209,7 +209,7 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 	 * doing the exec and bprm->mm is the new process's mm.
 	 */
 	ret = get_user_pages_remote(current, bprm->mm, pos, 1, gup_flags,
-			&page, NULL);
+			&page, NULL, NULL);
 	if (ret <= 0)
 		return NULL;
 

commit 412ac77a9d3ec015524dacea905471d66480b7ac
Merge: dcdaa2f9480c 19339c251607
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 14 14:09:48 2016 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull namespace updates from Eric Biederman:
     "After a lot of discussion and work we have finally reachanged a basic
      understanding of what is necessary to make unprivileged mounts safe in
      the presence of EVM and IMA xattrs which the last commit in this
      series reflects. While technically it is a revert the comments it adds
      are important for people not getting confused in the future. Clearing
      up that confusion allows us to seriously work on unprivileged mounts
      of fuse in the next development cycle.
    
      The rest of the fixes in this set are in the intersection of user
      namespaces, ptrace, and exec. I started with the first fix which
      started a feedback cycle of finding additional issues during review
      and fixing them. Culiminating in a fix for a bug that has been present
      since at least Linux v1.0.
    
      Potentially these fixes were candidates for being merged during the rc
      cycle, and are certainly backport candidates but enough little things
      turned up during review and testing that I decided they should be
      handled as part of the normal development process just to be certain
      there were not any great surprises when it came time to backport some
      of these fixes"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace:
      Revert "evm: Translate user/group ids relative to s_user_ns when computing HMAC"
      exec: Ensure mm->user_ns contains the execed files
      ptrace: Don't allow accessing an undumpable mm
      ptrace: Capture the ptracer's creds not PT_PTRACE_CAP
      mm: Add a user_ns owner to mm_struct and fix ptrace permission checks

commit f84df2a6f268de584a201e8911384a2d244876e3
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Nov 16 22:06:51 2016 -0600

    exec: Ensure mm->user_ns contains the execed files
    
    When the user namespace support was merged the need to prevent
    ptrace from revealing the contents of an unreadable executable
    was overlooked.
    
    Correct this oversight by ensuring that the executed file
    or files are in mm->user_ns, by adjusting mm->user_ns.
    
    Use the new function privileged_wrt_inode_uidgid to see if
    the executable is a member of the user namespace, and as such
    if having CAP_SYS_PTRACE in the user namespace should allow
    tracing the executable.  If not update mm->user_ns to
    the parent user namespace until an appropriate parent is found.
    
    Cc: stable@vger.kernel.org
    Reported-by: Jann Horn <jann@thejh.net>
    Fixes: 9e4a36ece652 ("userns: Fail exec for suid and sgid binaries with ids outside our user namespace.")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 3cf2cfced97a..fdf53f0c421b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1275,8 +1275,22 @@ EXPORT_SYMBOL(flush_old_exec);
 
 void would_dump(struct linux_binprm *bprm, struct file *file)
 {
-	if (inode_permission(file_inode(file), MAY_READ) < 0)
+	struct inode *inode = file_inode(file);
+	if (inode_permission(inode, MAY_READ) < 0) {
+		struct user_namespace *old, *user_ns;
 		bprm->interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP;
+
+		/* Ensure mm->user_ns contains the executable */
+		user_ns = old = bprm->mm->user_ns;
+		while ((user_ns != &init_user_ns) &&
+		       !privileged_wrt_inode_uidgid(user_ns, inode))
+			user_ns = user_ns->parent;
+
+		if (old != user_ns) {
+			bprm->mm->user_ns = get_user_ns(user_ns);
+			put_user_ns(old);
+		}
+	}
 }
 EXPORT_SYMBOL(would_dump);
 
@@ -1306,7 +1320,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 	    !gid_eq(bprm->cred->gid, current_egid())) {
 		current->pdeath_signal = 0;
 	} else {
-		would_dump(bprm, bprm->file);
 		if (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)
 			set_dumpable(current->mm, suid_dumpable);
 	}
@@ -1741,6 +1754,8 @@ static int do_execveat_common(int fd, struct filename *filename,
 	if (retval < 0)
 		goto out;
 
+	would_dump(bprm, bprm->file);
+
 	retval = exec_binprm(bprm);
 	if (retval < 0)
 		goto out;

commit 64b875f7ac8a5d60a4e191479299e931ee949b67
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Nov 14 18:48:07 2016 -0600

    ptrace: Capture the ptracer's creds not PT_PTRACE_CAP
    
    When the flag PT_PTRACE_CAP was added the PTRACE_TRACEME path was
    overlooked.  This can result in incorrect behavior when an application
    like strace traces an exec of a setuid executable.
    
    Further PT_PTRACE_CAP does not have enough information for making good
    security decisions as it does not report which user namespace the
    capability is in.  This has already allowed one mistake through
    insufficient granulariy.
    
    I found this issue when I was testing another corner case of exec and
    discovered that I could not get strace to set PT_PTRACE_CAP even when
    running strace as root with a full set of caps.
    
    This change fixes the above issue with strace allowing stracing as
    root a setuid executable without disabling setuid.  More fundamentaly
    this change allows what is allowable at all times, by using the correct
    information in it's decision.
    
    Cc: stable@vger.kernel.org
    Fixes: 4214e42f96d4 ("v2.4.9.11 -> v2.4.9.12")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 4e497b9ee71e..3cf2cfced97a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1406,7 +1406,7 @@ static void check_unsafe_exec(struct linux_binprm *bprm)
 	unsigned n_fs;
 
 	if (p->ptrace) {
-		if (p->ptrace & PT_PTRACE_CAP)
+		if (ptracer_capable(p, current_user_ns()))
 			bprm->unsafe |= LSM_UNSAFE_PTRACE_CAP;
 		else
 			bprm->unsafe |= LSM_UNSAFE_PTRACE;

commit baa73d9e478ff32d62f3f9422822b59dd9a95a21
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Fri Nov 11 00:10:10 2016 -0500

    posix-timers: Make them configurable
    
    Some embedded systems have no use for them.  This removes about
    25KB from the kernel binary size when configured out.
    
    Corresponding syscalls are routed to a stub logging the attempt to
    use those syscalls which should be enough of a clue if they were
    disabled without proper consideration. They are: timer_create,
    timer_gettime: timer_getoverrun, timer_settime, timer_delete,
    clock_adjtime, setitimer, getitimer, alarm.
    
    The clock_settime, clock_gettime, clock_getres and clock_nanosleep
    syscalls are replaced by simple wrappers compatible with CLOCK_REALTIME,
    CLOCK_MONOTONIC and CLOCK_BOOTTIME only which should cover the vast
    majority of use cases with very little code.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Richard Cochran <richardcochran@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: John Stultz <john.stultz@linaro.org>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Cc: Paul Bolle <pebolle@tiscali.nl>
    Cc: linux-kbuild@vger.kernel.org
    Cc: netdev@vger.kernel.org
    Cc: Michal Marek <mmarek@suse.com>
    Cc: Edward Cree <ecree@solarflare.com>
    Link: http://lkml.kernel.org/r/1478841010-28605-7-git-send-email-nicolas.pitre@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/fs/exec.c b/fs/exec.c
index 4e497b9ee71e..923c57d96899 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1169,8 +1169,10 @@ static int de_thread(struct task_struct *tsk)
 	/* we have changed execution domain */
 	tsk->exit_signal = SIGCHLD;
 
+#ifdef CONFIG_POSIX_TIMERS
 	exit_itimers(sig);
 	flush_itimer_signals();
+#endif
 
 	if (atomic_read(&oldsighand->count) != 1) {
 		struct sighand_struct *newsighand;

commit 9beae1ea89305a9667ceaab6d0bf46a045ad71e7
Author: Lorenzo Stoakes <lstoakes@gmail.com>
Date:   Thu Oct 13 01:20:17 2016 +0100

    mm: replace get_user_pages_remote() write/force parameters with gup_flags
    
    This removes the 'write' and 'force' from get_user_pages_remote() and
    replaces them with 'gup_flags' to make the use of FOLL_FORCE explicit in
    callers as use of this flag can result in surprising behaviour (and
    hence bugs) within the mm subsystem.
    
    Signed-off-by: Lorenzo Stoakes <lstoakes@gmail.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6fcfb3f7b137..4e497b9ee71e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -191,6 +191,7 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 {
 	struct page *page;
 	int ret;
+	unsigned int gup_flags = FOLL_FORCE;
 
 #ifdef CONFIG_STACK_GROWSUP
 	if (write) {
@@ -199,12 +200,16 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 			return NULL;
 	}
 #endif
+
+	if (write)
+		gup_flags |= FOLL_WRITE;
+
 	/*
 	 * We are doing an exec().  'current' is the process
 	 * doing the exec and bprm->mm is the new process's mm.
 	 */
-	ret = get_user_pages_remote(current, bprm->mm, pos, 1, write,
-			1, &page, NULL);
+	ret = get_user_pages_remote(current, bprm->mm, pos, 1, gup_flags,
+			&page, NULL);
 	if (ret <= 0)
 		return NULL;
 

commit 8e7106a60748e74f4c76b2204e83f14e4dc041cc
Merge: c1ece7671920 002d2f01f13f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 4 18:04:44 2016 -0400

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/gerg/m68knommu
    
    Pull m68knommu updates from Greg Ungerer:
     "This series is all about Nicolas flat format support for MMU systems.
    
      Traditional m68k no-MMU flat format binaries can now be run on m68k
      MMU enabled systems too.  The series includes some nice cleanups of
      the binfmt_flat code and converts it to using proper user space
      accessor functions.
    
      With all this in place you can boot and run a complete no-MMU flat
      format based user space on an MMU enabled system"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/gerg/m68knommu:
      m68k: enable binfmt_flat on systems with an MMU
      binfmt_flat: allow compressed flat binary format to work on MMU systems
      binfmt_flat: add MMU-specific support
      binfmt_flat: update libraries' data segment pointer with userspace accessors
      binfmt_flat: use clear_user() rather than memset() to clear .bss
      binfmt_flat: use proper user space accessors with old relocs code
      binfmt_flat: use proper user space accessors with relocs processing code
      binfmt_flat: clean up create_flat_tables() and stack accesses
      binfmt_flat: use generic transfer_args_to_stack()
      elf_fdpic_transfer_args_to_stack(): make it generic
      binfmt_flat: prevent kernel dammage from corrupted executable headers
      binfmt_flat: convert printk invocations to their modern form
      binfmt_flat: assorted cleanups
      m68k: use same start_thread() on MMU and no-MMU
      m68k: fix file path comment
      m68k: fix bFLT executable running on MMU enabled systems

commit a098ecd2fa7db8fa4fcc178a43627b29b226edb9
Author: Stephen Boyd <stephen.boyd@linaro.org>
Date:   Tue Aug 2 14:04:28 2016 -0700

    firmware: support loading into a pre-allocated buffer
    
    Some systems are memory constrained but they need to load very large
    firmwares.  The firmware subsystem allows drivers to request this
    firmware be loaded from the filesystem, but this requires that the
    entire firmware be loaded into kernel memory first before it's provided
    to the driver.  This can lead to a situation where we map the firmware
    twice, once to load the firmware into kernel memory and once to copy the
    firmware into the final resting place.
    
    This creates needless memory pressure and delays loading because we have
    to copy from kernel memory to somewhere else.  Let's add a
    request_firmware_into_buf() API that allows drivers to request firmware
    be loaded directly into a pre-allocated buffer.  This skips the
    intermediate step of allocating a buffer in kernel memory to hold the
    firmware image while it's read from the filesystem.  It also requires
    that drivers know how much memory they'll require before requesting the
    firmware and negates any benefits of firmware caching because the
    firmware layer doesn't manage the buffer lifetime.
    
    For a 16MB buffer, about half the time is spent performing a memcpy from
    the buffer to the final resting place.  I see loading times go from
    0.081171 seconds to 0.047696 seconds after applying this patch.  Plus
    the vmalloc pressure is reduced.
    
    This is based on a patch from Vikram Mulukutla on codeaurora.org:
      https://www.codeaurora.org/cgit/quic/la/kernel/msm-3.18/commit/drivers/base/firmware_class.c?h=rel/msm-3.18&id=0a328c5f6cd999f5c591f172216835636f39bcb5
    
    Link: http://lkml.kernel.org/r/20160607164741.31849-4-stephen.boyd@linaro.org
    Signed-off-by: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Cc: Vikram Mulukutla <markivx@codeaurora.org>
    Cc: Mark Brown <broonie@kernel.org>
    Cc: Ming Lei <ming.lei@canonical.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ca239fc86d8d..a1789cd684bf 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -866,7 +866,8 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 		goto out;
 	}
 
-	*buf = vmalloc(i_size);
+	if (id != READING_FIRMWARE_PREALLOC_BUFFER)
+		*buf = vmalloc(i_size);
 	if (!*buf) {
 		ret = -ENOMEM;
 		goto out;
@@ -897,8 +898,10 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 
 out_free:
 	if (ret < 0) {
-		vfree(*buf);
-		*buf = NULL;
+		if (id != READING_FIRMWARE_PREALLOC_BUFFER) {
+			vfree(*buf);
+			*buf = NULL;
+		}
 	}
 
 out:

commit 7e7ec6a934349ef6983f06f7ac0da09cc8a42983
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Sun Jul 24 11:30:18 2016 -0400

    elf_fdpic_transfer_args_to_stack(): make it generic
    
    This copying of arguments and environment is common to both NOMMU
    binary formats we support. Let's make the elf_fdpic version available
    to the flat format as well.
    
    While at it, improve the code a bit not to copy below the actual
    data area.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Reviewed-by: Greg Ungerer <gerg@linux-m68k.org>
    Signed-off-by: Greg Ungerer <gerg@linux-m68k.org>

diff --git a/fs/exec.c b/fs/exec.c
index 887c1c955df8..ef0df2f09257 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -762,6 +762,39 @@ int setup_arg_pages(struct linux_binprm *bprm,
 }
 EXPORT_SYMBOL(setup_arg_pages);
 
+#else
+
+/*
+ * Transfer the program arguments and environment from the holding pages
+ * onto the stack. The provided stack pointer is adjusted accordingly.
+ */
+int transfer_args_to_stack(struct linux_binprm *bprm,
+			   unsigned long *sp_location)
+{
+	unsigned long index, stop, sp;
+	int ret = 0;
+
+	stop = bprm->p >> PAGE_SHIFT;
+	sp = *sp_location;
+
+	for (index = MAX_ARG_PAGES - 1; index >= stop; index--) {
+		unsigned int offset = index == stop ? bprm->p & ~PAGE_MASK : 0;
+		char *src = kmap(bprm->page[index]) + offset;
+		sp -= PAGE_SIZE - offset;
+		if (copy_to_user((void *) sp, src, PAGE_SIZE - offset) != 0)
+			ret = -EFAULT;
+		kunmap(bprm->page[index]);
+		if (ret)
+			goto out;
+	}
+
+	*sp_location = sp;
+
+out:
+	return ret;
+}
+EXPORT_SYMBOL(transfer_args_to_stack);
+
 #endif /* CONFIG_MMU */
 
 static struct file *do_open_execat(int fd, struct filename *name, int flags)

commit 380cf5ba6b0a0b307f4afb62b186ca801defb203
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Jun 23 16:41:05 2016 -0500

    fs: Treat foreign mounts as nosuid
    
    If a process gets access to a mount from a different user
    namespace, that process should not be able to take advantage of
    setuid files or selinux entrypoints from that filesystem.  Prevent
    this by treating mounts from other mount namespaces and those not
    owned by current_user_ns() or an ancestor as nosuid.
    
    This will make it safer to allow more complex filesystems to be
    mounted in non-root user namespaces.
    
    This does not remove the need for MNT_LOCK_NOSUID.  The setuid,
    setgid, and file capability bits can no longer be abused if code in
    a user namespace were to clear nosuid on an untrusted filesystem,
    but this patch, by itself, is insufficient to protect the system
    from abuse of files that, when execed, would increase MAC privilege.
    
    As a more concrete explanation, any task that can manipulate a
    vfsmount associated with a given user namespace already has
    capabilities in that namespace and all of its descendents.  If they
    can cause a malicious setuid, setgid, or file-caps executable to
    appear in that mount, then that executable will only allow them to
    elevate privileges in exactly the set of namespaces in which they
    are already privileges.
    
    On the other hand, if they can cause a malicious executable to
    appear with a dangerous MAC label, running it could change the
    caller's security context in a way that should not have been
    possible, even inside the namespace in which the task is confined.
    
    As a hardening measure, this would have made CVE-2014-5207 much
    more difficult to exploit.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Seth Forshee <seth.forshee@canonical.com>
    Acked-by: James Morris <james.l.morris@oracle.com>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 887c1c955df8..ca239fc86d8d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1411,7 +1411,7 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
 	bprm->cred->euid = current_euid();
 	bprm->cred->egid = current_egid();
 
-	if (bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID)
+	if (!mnt_may_suid(bprm->file->f_path.mnt))
 		return;
 
 	if (task_no_new_privs(current))

commit f268dfe905d4682150d4acbb25f59adc04cd9398
Author: Michal Hocko <mhocko@suse.com>
Date:   Mon May 23 16:26:02 2016 -0700

    exec: make exec path waiting for mmap_sem killable
    
    setup_arg_pages requires mmap_sem for write.  If the waiting task gets
    killed by the oom killer it would block oom_reaper from asynchronous
    address space reclaim and reduce the chances of timely OOM resolving.
    Wait for the lock in the killable mode and return with EINTR if the task
    got killed while waiting.  All the callers are already handling error
    path and the fatal signal doesn't need any additional treatment.
    
    The same applies to __bprm_mm_init.
    
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4f079bd083af..887c1c955df8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -263,7 +263,10 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	if (!vma)
 		return -ENOMEM;
 
-	down_write(&mm->mmap_sem);
+	if (down_write_killable(&mm->mmap_sem)) {
+		err = -EINTR;
+		goto err_free;
+	}
 	vma->vm_mm = mm;
 
 	/*
@@ -290,6 +293,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	return 0;
 err:
 	up_write(&mm->mmap_sem);
+err_free:
 	bprm->vma = NULL;
 	kmem_cache_free(vm_area_cachep, vma);
 	return err;
@@ -696,7 +700,9 @@ int setup_arg_pages(struct linux_binprm *bprm,
 		bprm->loader -= stack_shift;
 	bprm->exec -= stack_shift;
 
-	down_write(&mm->mmap_sem);
+	if (down_write_killable(&mm->mmap_sem))
+		return -EINTR;
+
 	vm_flags = VM_STACK_FLAGS;
 
 	/*

commit 9eb8a659dea694b0dcbd6287f6b1fbdc523b80bc
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon May 23 16:24:08 2016 -0700

    exec: remove the no longer needed remove_arg_zero()->free_arg_page()
    
    remove_arg_zero() does free_arg_page() for no reason.  This was needed
    before and only if CONFIG_MMU=y: see commit 4fc75ff4816c ("exec: fix
    remove_arg_zero"), install_arg_page() was called for every page != NULL
    in bprm->page[] array.  Today install_arg_page() has already gone and
    free_arg_page() is nop after another commit b6a2fea39318 ("mm: variable
    length argument support").
    
    CONFIG_MMU=n does free_arg_pages() in free_bprm() and thus it doesn't
    need remove_arg_zero()->free_arg_page() too; apart from get_arg_page()
    it never checks if the page in bprm->page[] was allocated or not, so the
    "extra" non-freed page is fine.  OTOH, this free_arg_page() can add the
    minor pessimization, the caller is going to do copy_strings_kernel()
    right after remove_arg_zero() which will likely need to re-allocate the
    same page again.
    
    And as Hujunjie pointed out, the "offset == PAGE_SIZE" check is wrong
    because we are going to increment bprm->p once again before return, so
    CONFIG_MMU=n "leaks" the page anyway if '0' is the final byte in this
    page.
    
    NOTE: remove_arg_zero() assumes that argv[0] is null-terminated but this
    is not necessarily true.  copy_strings() does "len = strnlen_user(...)",
    then copy_from_user(len) but another thread or debuger can overwrite the
    trailing '0' in between.  Afaics nothing really bad can happen because
    we must always have the null-terminated bprm->filename copied by the 1st
    copy_strings_kernel(), but perhaps we should change this code to check
    "bprm->p < bprm->exec" anyway, and/or change copy_strings() to ensure
    that the last byte in string is always zero.
    
    Link: http://lkml.kernel.org/r/20160517155335.GA31435@redhat.com
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reported by: hujunjie <jj.net@163.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e92419fd78b3..4f079bd083af 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -243,10 +243,6 @@ static void put_arg_page(struct page *page)
 	put_page(page);
 }
 
-static void free_arg_page(struct linux_binprm *bprm, int i)
-{
-}
-
 static void free_arg_pages(struct linux_binprm *bprm)
 {
 }
@@ -1499,9 +1495,6 @@ int remove_arg_zero(struct linux_binprm *bprm)
 
 		kunmap_atomic(kaddr);
 		put_arg_page(page);
-
-		if (offset == PAGE_SIZE)
-			free_arg_page(bprm, (bprm->p >> PAGE_SHIFT) - 1);
 	} while (offset == PAGE_SIZE);
 
 	bprm->p++;

commit f4f27d0028aabce57e44c16c2fdefccd6310d2f3
Merge: 2600a46ee0ed b937190c40de
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 19 09:21:36 2016 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull security subsystem updates from James Morris:
     "Highlights:
    
       - A new LSM, "LoadPin", from Kees Cook is added, which allows forcing
         of modules and firmware to be loaded from a specific device (this
         is from ChromeOS, where the device as a whole is verified
         cryptographically via dm-verity).
    
         This is disabled by default but can be configured to be enabled by
         default (don't do this if you don't know what you're doing).
    
       - Keys: allow authentication data to be stored in an asymmetric key.
         Lots of general fixes and updates.
    
       - SELinux: add restrictions for loading of kernel modules via
         finit_module().  Distinguish non-init user namespace capability
         checks.  Apply execstack check on thread stacks"
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security: (48 commits)
      LSM: LoadPin: provide enablement CONFIG
      Yama: use atomic allocations when reporting
      seccomp: Fix comment typo
      ima: add support for creating files using the mknodat syscall
      ima: fix ima_inode_post_setattr
      vfs: forbid write access when reading a file into memory
      fs: fix over-zealous use of "const"
      selinux: apply execstack check on thread stacks
      selinux: distinguish non-init user namespace capability checks
      LSM: LoadPin for kernel file loading restrictions
      fs: define a string representation of the kernel_read_file_id enumeration
      Yama: consolidate error reporting
      string_helpers: add kstrdup_quotable_file
      string_helpers: add kstrdup_quotable_cmdline
      string_helpers: add kstrdup_quotable
      selinux: check ss_initialized before revalidating an inode label
      selinux: delay inode label lookup as long as possible
      selinux: don't revalidate an inode's label when explicitly setting it
      selinux: Change bool variable name to index.
      KEYS: Add KEYCTL_DH_COMPUTE command
      ...

commit cb6fd68fdd4a94880a99ad8515844c7a25e50d3e
Author: Kees Cook <keescook@chromium.org>
Date:   Tue May 17 12:14:39 2016 -0700

    exec: clarify reasoning for euid/egid reset
    
    This section of code initially looks redundant, but is required. This
    improves the comment to explain more clearly why the reset is needed.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index c4010b8207a1..a98b21d47385 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1387,7 +1387,12 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
 	kuid_t uid;
 	kgid_t gid;
 
-	/* clear any previous set[ug]id data from a previous binary */
+	/*
+	 * Since this can be called multiple times (via prepare_binprm),
+	 * we must clear any previous work done when setting set[ug]id
+	 * bits from any earlier bprm->file uses (for example when run
+	 * first for a setuid script then again for its interpreter).
+	 */
 	bprm->cred->euid = current_euid();
 	bprm->cred->egid = current_egid();
 

commit 39d637af5aa7577f655c58b9e55587566c63a0af
Author: Dmitry Kasatkin <dmitry.kasatkin@huawei.com>
Date:   Sun Oct 26 12:42:07 2014 +0200

    vfs: forbid write access when reading a file into memory
    
    This patch is based on top of the "vfs: support for a common kernel file
    loader" patch set.  In general when the kernel is reading a file into
    memory it does not want anything else writing to it.
    
    The kernel currently only forbids write access to a file being executed.
    This patch extends this locking to files being read by the kernel.
    
    Changelog:
    - moved function to kernel_read_file() - Mimi
    - updated patch description - Mimi
    
    Signed-off-by: Dmitry Kasatkin <dmitry.kasatkin@huawei.com>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Reviewed-by: Luis R. Rodriguez <mcgrof@kernel.org>
    Acked-by: Kees Cook <keescook@chromium.org>

diff --git a/fs/exec.c b/fs/exec.c
index c4010b8207a1..fdecb7615587 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -850,15 +850,25 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 	if (ret)
 		return ret;
 
+	ret = deny_write_access(file);
+	if (ret)
+		return ret;
+
 	i_size = i_size_read(file_inode(file));
-	if (max_size > 0 && i_size > max_size)
-		return -EFBIG;
-	if (i_size <= 0)
-		return -EINVAL;
+	if (max_size > 0 && i_size > max_size) {
+		ret = -EFBIG;
+		goto out;
+	}
+	if (i_size <= 0) {
+		ret = -EINVAL;
+		goto out;
+	}
 
 	*buf = vmalloc(i_size);
-	if (!*buf)
-		return -ENOMEM;
+	if (!*buf) {
+		ret = -ENOMEM;
+		goto out;
+	}
 
 	pos = 0;
 	while (pos < i_size) {
@@ -876,18 +886,21 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 
 	if (pos != i_size) {
 		ret = -EIO;
-		goto out;
+		goto out_free;
 	}
 
 	ret = security_kernel_post_read_file(file, *buf, i_size, id);
 	if (!ret)
 		*size = pos;
 
-out:
+out_free:
 	if (ret < 0) {
 		vfree(*buf);
 		*buf = NULL;
 	}
+
+out:
+	allow_write_access(file);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(kernel_read_file);

commit 643ad15d47410d37d43daf3ef1c8ac52c281efa5
Merge: 24b5e20f11a7 0d47638f80a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Mar 20 19:08:56 2016 -0700

    Merge branch 'mm-pkeys-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 protection key support from Ingo Molnar:
     "This tree adds support for a new memory protection hardware feature
      that is available in upcoming Intel CPUs: 'protection keys' (pkeys).
    
      There's a background article at LWN.net:
    
          https://lwn.net/Articles/643797/
    
      The gist is that protection keys allow the encoding of
      user-controllable permission masks in the pte.  So instead of having a
      fixed protection mask in the pte (which needs a system call to change
      and works on a per page basis), the user can map a (handful of)
      protection mask variants and can change the masks runtime relatively
      cheaply, without having to change every single page in the affected
      virtual memory range.
    
      This allows the dynamic switching of the protection bits of large
      amounts of virtual memory, via user-space instructions.  It also
      allows more precise control of MMU permission bits: for example the
      executable bit is separate from the read bit (see more about that
      below).
    
      This tree adds the MM infrastructure and low level x86 glue needed for
      that, plus it adds a high level API to make use of protection keys -
      if a user-space application calls:
    
            mmap(..., PROT_EXEC);
    
      or
    
            mprotect(ptr, sz, PROT_EXEC);
    
      (note PROT_EXEC-only, without PROT_READ/WRITE), the kernel will notice
      this special case, and will set a special protection key on this
      memory range.  It also sets the appropriate bits in the Protection
      Keys User Rights (PKRU) register so that the memory becomes unreadable
      and unwritable.
    
      So using protection keys the kernel is able to implement 'true'
      PROT_EXEC on x86 CPUs: without protection keys PROT_EXEC implies
      PROT_READ as well.  Unreadable executable mappings have security
      advantages: they cannot be read via information leaks to figure out
      ASLR details, nor can they be scanned for ROP gadgets - and they
      cannot be used by exploits for data purposes either.
    
      We know about no user-space code that relies on pure PROT_EXEC
      mappings today, but binary loaders could start making use of this new
      feature to map binaries and libraries in a more secure fashion.
    
      There is other pending pkeys work that offers more high level system
      call APIs to manage protection keys - but those are not part of this
      pull request.
    
      Right now there's a Kconfig that controls this feature
      (CONFIG_X86_INTEL_MEMORY_PROTECTION_KEYS) that is default enabled
      (like most x86 CPU feature enablement code that has no runtime
      overhead), but it's not user-configurable at the moment.  If there's
      any serious problem with this then we can make it configurable and/or
      flip the default"
    
    * 'mm-pkeys-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (38 commits)
      x86/mm/pkeys: Fix mismerge of protection keys CPUID bits
      mm/pkeys: Fix siginfo ABI breakage caused by new u64 field
      x86/mm/pkeys: Fix access_error() denial of writes to write-only VMA
      mm/core, x86/mm/pkeys: Add execute-only protection keys support
      x86/mm/pkeys: Create an x86 arch_calc_vm_prot_bits() for VMA flags
      x86/mm/pkeys: Allow kernel to modify user pkey rights register
      x86/fpu: Allow setting of XSAVE state
      x86/mm: Factor out LDT init from context init
      mm/core, x86/mm/pkeys: Add arch_validate_pkey()
      mm/core, arch, powerpc: Pass a protection key in to calc_vm_flag_bits()
      x86/mm/pkeys: Actually enable Memory Protection Keys in the CPU
      x86/mm/pkeys: Add Kconfig prompt to existing config option
      x86/mm/pkeys: Dump pkey from VMA in /proc/pid/smaps
      x86/mm/pkeys: Dump PKRU with other kernel registers
      mm/core, x86/mm/pkeys: Differentiate instruction fetches
      x86/mm/pkeys: Optimize fault handling in access_error()
      mm/core: Do not enforce PKEY permissions on remote mm access
      um, pkeys: Add UML arch_*_access_permitted() methods
      mm/gup, x86/mm/pkeys: Check VMAs and PTEs for protection keys
      x86/mm/gup: Simplify get_user_pages() PTE bit handling
      ...

commit b844f0ecbc5626ec26cfc70cb144a4c9b85dc3f2
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Mon Feb 1 08:36:21 2016 -0500

    vfs: define kernel_copy_file_from_fd()
    
    This patch defines kernel_read_file_from_fd(), a wrapper for the VFS
    common kernel_read_file().
    
    Changelog:
    - Separated from the kernel modules patch
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Luis R. Rodriguez <mcgrof@kernel.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>

diff --git a/fs/exec.c b/fs/exec.c
index 8aaa38666119..9bdf0edf570d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -907,6 +907,22 @@ int kernel_read_file_from_path(char *path, void **buf, loff_t *size,
 }
 EXPORT_SYMBOL_GPL(kernel_read_file_from_path);
 
+int kernel_read_file_from_fd(int fd, void **buf, loff_t *size, loff_t max_size,
+			     enum kernel_read_file_id id)
+{
+	struct fd f = fdget(fd);
+	int ret = -EBADF;
+
+	if (!f.file)
+		goto out;
+
+	ret = kernel_read_file(f.file, buf, size, max_size, id);
+out:
+	fdput(f);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(kernel_read_file_from_fd);
+
 ssize_t read_code(struct file *file, unsigned long addr, loff_t pos, size_t len)
 {
 	ssize_t res = vfs_read(file, (void __user *)addr, len, &pos);

commit 39eeb4fb97f60dbdfc823c1a673a8844b9226b60
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Sat Jan 30 22:23:26 2016 -0500

    security: define kernel_read_file hook
    
    The kernel_read_file security hook is called prior to reading the file
    into memory.
    
    Changelog v4+:
    - export security_kernel_read_file()
    
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Luis R. Rodriguez <mcgrof@kernel.org>
    Acked-by: Casey Schaufler <casey@schaufler-ca.com>

diff --git a/fs/exec.c b/fs/exec.c
index 64cb3bc788c1..8aaa38666119 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -842,6 +842,10 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 	if (!S_ISREG(file_inode(file)->i_mode) || max_size < 0)
 		return -EINVAL;
 
+	ret = security_kernel_read_file(file, id);
+	if (ret)
+		return ret;
+
 	i_size = i_size_read(file_inode(file));
 	if (max_size > 0 && i_size > max_size)
 		return -EFBIG;

commit 09596b94f7d28595602482e69ed954deab707437
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Thu Nov 19 12:39:22 2015 -0500

    vfs: define kernel_read_file_from_path
    
    This patch defines kernel_read_file_from_path(), a wrapper for the VFS
    common kernel_read_file().
    
    Changelog:
    - revert error msg regression - reported by Sergey Senozhatsky
    - Separated from the IMA patch
    
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Luis R. Rodriguez <mcgrof@kernel.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 1138dc502c77..64cb3bc788c1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -884,6 +884,25 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 }
 EXPORT_SYMBOL_GPL(kernel_read_file);
 
+int kernel_read_file_from_path(char *path, void **buf, loff_t *size,
+			       loff_t max_size, enum kernel_read_file_id id)
+{
+	struct file *file;
+	int ret;
+
+	if (!path || !*path)
+		return -EINVAL;
+
+	file = filp_open(path, O_RDONLY, 0);
+	if (IS_ERR(file))
+		return PTR_ERR(file);
+
+	ret = kernel_read_file(file, buf, size, max_size, id);
+	fput(file);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(kernel_read_file_from_path);
+
 ssize_t read_code(struct file *file, unsigned long addr, loff_t pos, size_t len)
 {
 	ssize_t res = vfs_read(file, (void __user *)addr, len, &pos);

commit bc8ca5b92d54f6f005fa73ad546f02fca26ddd85
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Sun Jan 24 10:07:32 2016 -0500

    vfs: define kernel_read_file_id enumeration
    
    To differentiate between the kernel_read_file() callers, this patch
    defines a new enumeration named kernel_read_file_id and includes the
    caller identifier as an argument.
    
    Subsequent patches define READING_KEXEC_IMAGE, READING_KEXEC_INITRAMFS,
    READING_FIRMWARE, READING_MODULE, and READING_POLICY.
    
    Changelog v3:
    - Replace the IMA specific enumeration with a generic one.
    
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Luis R. Rodriguez <mcgrof@kernel.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 6b6668baa44a..1138dc502c77 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -833,7 +833,7 @@ int kernel_read(struct file *file, loff_t offset,
 EXPORT_SYMBOL(kernel_read);
 
 int kernel_read_file(struct file *file, void **buf, loff_t *size,
-		     loff_t max_size)
+		     loff_t max_size, enum kernel_read_file_id id)
 {
 	loff_t i_size, pos;
 	ssize_t bytes = 0;
@@ -871,7 +871,7 @@ int kernel_read_file(struct file *file, void **buf, loff_t *size,
 		goto out;
 	}
 
-	ret = security_kernel_post_read_file(file, *buf, i_size);
+	ret = security_kernel_post_read_file(file, *buf, i_size, id);
 	if (!ret)
 		*size = pos;
 

commit b44a7dfc6fa16e01f2497c9fa62c3926f94be174
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Mon Dec 28 16:02:29 2015 -0500

    vfs: define a generic function to read a file from the kernel
    
    For a while it was looked down upon to directly read files from Linux.
    These days there exists a few mechanisms in the kernel that do just
    this though to load a file into a local buffer.  There are minor but
    important checks differences on each.  This patch set is the first
    attempt at resolving some of these differences.
    
    This patch introduces a common function for reading files from the kernel
    with the corresponding security post-read hook and function.
    
    Changelog v4+:
    - export security_kernel_post_read_file() - Fengguang Wu
    v3:
    - additional bounds checking - Luis
    v2:
    - To simplify patch review, re-ordered patches
    
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Reviewed-by: Luis R. Rodriguez <mcgrof@suse.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index dcd4ac7d3f1e..6b6668baa44a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -56,6 +56,7 @@
 #include <linux/pipe_fs_i.h>
 #include <linux/oom.h>
 #include <linux/compat.h>
+#include <linux/vmalloc.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -831,6 +832,58 @@ int kernel_read(struct file *file, loff_t offset,
 
 EXPORT_SYMBOL(kernel_read);
 
+int kernel_read_file(struct file *file, void **buf, loff_t *size,
+		     loff_t max_size)
+{
+	loff_t i_size, pos;
+	ssize_t bytes = 0;
+	int ret;
+
+	if (!S_ISREG(file_inode(file)->i_mode) || max_size < 0)
+		return -EINVAL;
+
+	i_size = i_size_read(file_inode(file));
+	if (max_size > 0 && i_size > max_size)
+		return -EFBIG;
+	if (i_size <= 0)
+		return -EINVAL;
+
+	*buf = vmalloc(i_size);
+	if (!*buf)
+		return -ENOMEM;
+
+	pos = 0;
+	while (pos < i_size) {
+		bytes = kernel_read(file, pos, (char *)(*buf) + pos,
+				    i_size - pos);
+		if (bytes < 0) {
+			ret = bytes;
+			goto out;
+		}
+
+		if (bytes == 0)
+			break;
+		pos += bytes;
+	}
+
+	if (pos != i_size) {
+		ret = -EIO;
+		goto out;
+	}
+
+	ret = security_kernel_post_read_file(file, *buf, i_size);
+	if (!ret)
+		*size = pos;
+
+out:
+	if (ret < 0) {
+		vfree(*buf);
+		*buf = NULL;
+	}
+	return ret;
+}
+EXPORT_SYMBOL_GPL(kernel_read_file);
+
 ssize_t read_code(struct file *file, unsigned long addr, loff_t pos, size_t len)
 {
 	ssize_t res = vfs_read(file, (void __user *)addr, len, &pos);

commit 1e9877902dc7e11d2be038371c6fbf2dfcd469d7
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Feb 12 13:01:54 2016 -0800

    mm/gup: Introduce get_user_pages_remote()
    
    For protection keys, we need to understand whether protections
    should be enforced in software or not.  In general, we enforce
    protections when working on our own task, but not when on others.
    We call these "current" and "remote" operations.
    
    This patch introduces a new get_user_pages() variant:
    
            get_user_pages_remote()
    
    Which is a replacement for when get_user_pages() is called on
    non-current tsk/mm.
    
    We also introduce a new gup flag: FOLL_REMOTE which can be used
    for the "__" gup variants to get this new behavior.
    
    The uprobes is_trap_at_addr() location holds mmap_sem and
    calls get_user_pages(current->mm) on an instruction address.  This
    makes it a pretty unique gup caller.  Being an instruction access
    and also really originating from the kernel (vs. the app), I opted
    to consider this a 'remote' access where protection keys will not
    be enforced.
    
    Without protection keys, this patch should not change any behavior.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: jack@suse.cz
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20160212210154.3F0E51EA@viggo.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index dcd4ac7d3f1e..d885b98b6a00 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -198,8 +198,12 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 			return NULL;
 	}
 #endif
-	ret = get_user_pages(current, bprm->mm, pos,
-			1, write, 1, &page, NULL);
+	/*
+	 * We are doing an exec().  'current' is the process
+	 * doing the exec and bprm->mm is the new process's mm.
+	 */
+	ret = get_user_pages_remote(current, bprm->mm, pos, 1, write,
+			1, &page, NULL);
 	if (ret <= 0)
 		return NULL;
 

commit 5955102c9984fa081b2d570cfac75c97eecf8f3b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Jan 22 15:40:57 2016 -0500

    wrappers for ->i_mutex access
    
    parallel to mutex_{lock,unlock,trylock,is_locked,lock_nested},
    inode_foo(inode) being mutex_foo(&inode->i_mutex).
    
    Please, use those for access to ->i_mutex; over the coming cycle
    ->i_mutex will become rwsem, with ->lookup() done with it held
    only shared.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 828ec5f07de0..dcd4ac7d3f1e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1307,13 +1307,13 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
 		return;
 
 	/* Be careful if suid/sgid is set */
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	/* reload atomically mode/uid/gid now that lock held */
 	mode = inode->i_mode;
 	uid = inode->i_uid;
 	gid = inode->i_gid;
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	/* We ignore suid/sgid if there are no mappings for them in the ns */
 	if (!kuid_has_mapping(bprm->cred->user_ns, uid) ||

commit 62fb4a155f745285d9b1640c3ef53bf90c12f17c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Dec 26 22:33:24 2015 -0500

    don't carry MAY_OPEN in op->acc_mode
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index b06623a9347f..828ec5f07de0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -119,7 +119,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 	int error = PTR_ERR(tmp);
 	static const struct open_flags uselib_flags = {
 		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
-		.acc_mode = MAY_READ | MAY_EXEC | MAY_OPEN,
+		.acc_mode = MAY_READ | MAY_EXEC,
 		.intent = LOOKUP_OPEN,
 		.lookup_flags = LOOKUP_FOLLOW,
 	};
@@ -763,7 +763,7 @@ static struct file *do_open_execat(int fd, struct filename *name, int flags)
 	int err;
 	struct open_flags open_exec_flags = {
 		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
-		.acc_mode = MAY_EXEC | MAY_OPEN,
+		.acc_mode = MAY_EXEC,
 		.intent = LOOKUP_OPEN,
 		.lookup_flags = LOOKUP_FOLLOW,
 	};

commit 90f8572b0f021fdd1baa68e00a8c30482ee9e5f4
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jun 29 14:42:03 2015 -0500

    vfs: Commit to never having exectuables on proc and sysfs.
    
    Today proc and sysfs do not contain any executable files.  Several
    applications today mount proc or sysfs without noexec and nosuid and
    then depend on there being no exectuables files on proc or sysfs.
    Having any executable files show on proc or sysfs would cause
    a user space visible regression, and most likely security problems.
    
    Therefore commit to never allowing executables on proc and sysfs by
    adding a new flag to mark them as filesystems without executables and
    enforce that flag.
    
    Test the flag where MNT_NOEXEC is tested today, so that the only user
    visible effect will be that exectuables will be treated as if the
    execute bit is cleared.
    
    The filesystems proc and sysfs do not currently incoporate any
    executable files so this does not result in any user visible effects.
    
    This makes it unnecessary to vet changes to proc and sysfs tightly for
    adding exectuable files or changes to chattr that would modify
    existing files, as no matter what the individual file say they will
    not be treated as exectuable files by the vfs.
    
    Not having to vet changes to closely is important as without this we
    are only one proc_create call (or another goof up in the
    implementation of notify_change) from having problematic executables
    on proc.  Those mistakes are all too easy to make and would create
    a situation where there are security issues or the assumptions of
    some program having to be broken (and cause userspace regressions).
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 1977c2a553ac..b06623a9347f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -98,6 +98,12 @@ static inline void put_binfmt(struct linux_binfmt * fmt)
 	module_put(fmt->module);
 }
 
+bool path_noexec(const struct path *path)
+{
+	return (path->mnt->mnt_flags & MNT_NOEXEC) ||
+	       (path->mnt->mnt_sb->s_iflags & SB_I_NOEXEC);
+}
+
 #ifdef CONFIG_USELIB
 /*
  * Note that a shared library must be both readable and executable due to
@@ -132,7 +138,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 		goto exit;
 
 	error = -EACCES;
-	if (file->f_path.mnt->mnt_flags & MNT_NOEXEC)
+	if (path_noexec(&file->f_path))
 		goto exit;
 
 	fsnotify_open(file);
@@ -777,7 +783,7 @@ static struct file *do_open_execat(int fd, struct filename *name, int flags)
 	if (!S_ISREG(file_inode(file)->i_mode))
 		goto exit;
 
-	if (file->f_path.mnt->mnt_flags & MNT_NOEXEC)
+	if (path_noexec(&file->f_path))
 		goto exit;
 
 	err = deny_write_access(file);

commit d045c77c1a69703143a36169c224429c48b9eecd
Author: Helge Deller <deller@gmx.de>
Date:   Mon May 11 22:01:27 2015 +0200

    parisc,metag: Fix crashes due to stack randomization on stack-grows-upwards architectures
    
    On architectures where the stack grows upwards (CONFIG_STACK_GROWSUP=y,
    currently parisc and metag only) stack randomization sometimes leads to crashes
    when the stack ulimit is set to lower values than STACK_RND_MASK (which is 8 MB
    by default if not defined in arch-specific headers).
    
    The problem is, that when the stack vm_area_struct is set up in fs/exec.c, the
    additional space needed for the stack randomization (as defined by the value of
    STACK_RND_MASK) was not taken into account yet and as such, when the stack
    randomization code added a random offset to the stack start, the stack
    effectively got smaller than what the user defined via rlimit_max(RLIMIT_STACK)
    which then sometimes leads to out-of-stack situations and crashes.
    
    This patch fixes it by adding the maximum possible amount of memory (based on
    STACK_RND_MASK) which theoretically could be added by the stack randomization
    code to the initial stack size. That way, the user-defined stack size is always
    guaranteed to be at minimum what is defined via rlimit_max(RLIMIT_STACK).
    
    This bug is currently not visible on the metag architecture, because on metag
    STACK_RND_MASK is defined to 0 which effectively disables stack randomization.
    
    The changes to fs/exec.c are inside an "#ifdef CONFIG_STACK_GROWSUP"
    section, so it does not affect other platformws beside those where the
    stack grows upwards (parisc and metag).
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: linux-parisc@vger.kernel.org
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: linux-metag@vger.kernel.org
    Cc: stable@vger.kernel.org # v3.16+

diff --git a/fs/exec.c b/fs/exec.c
index 49a1c61433b7..1977c2a553ac 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -659,6 +659,9 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	if (stack_base > STACK_SIZE_MAX)
 		stack_base = STACK_SIZE_MAX;
 
+	/* Add space for stack randomization. */
+	stack_base += (STACK_RND_MASK << PAGE_SHIFT);
+
 	/* Make sure we didn't let the argument array grow too large. */
 	if (vma->vm_end - vma->vm_start > stack_base)
 		return -ENOMEM;

commit 8b01fc86b9f425899f8a3a8fc1c47d73c2c20543
Author: Jann Horn <jann@thejh.net>
Date:   Sun Apr 19 02:48:39 2015 +0200

    fs: take i_mutex during prepare_binprm for set[ug]id executables
    
    This prevents a race between chown() and execve(), where chowning a
    setuid-user binary to root would momentarily make the binary setuid
    root.
    
    This patch was mostly written by Linus Torvalds.
    
    Signed-off-by: Jann Horn <jann@thejh.net>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 02bfd980a40c..49a1c61433b7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1275,6 +1275,53 @@ static void check_unsafe_exec(struct linux_binprm *bprm)
 	spin_unlock(&p->fs->lock);
 }
 
+static void bprm_fill_uid(struct linux_binprm *bprm)
+{
+	struct inode *inode;
+	unsigned int mode;
+	kuid_t uid;
+	kgid_t gid;
+
+	/* clear any previous set[ug]id data from a previous binary */
+	bprm->cred->euid = current_euid();
+	bprm->cred->egid = current_egid();
+
+	if (bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID)
+		return;
+
+	if (task_no_new_privs(current))
+		return;
+
+	inode = file_inode(bprm->file);
+	mode = READ_ONCE(inode->i_mode);
+	if (!(mode & (S_ISUID|S_ISGID)))
+		return;
+
+	/* Be careful if suid/sgid is set */
+	mutex_lock(&inode->i_mutex);
+
+	/* reload atomically mode/uid/gid now that lock held */
+	mode = inode->i_mode;
+	uid = inode->i_uid;
+	gid = inode->i_gid;
+	mutex_unlock(&inode->i_mutex);
+
+	/* We ignore suid/sgid if there are no mappings for them in the ns */
+	if (!kuid_has_mapping(bprm->cred->user_ns, uid) ||
+		 !kgid_has_mapping(bprm->cred->user_ns, gid))
+		return;
+
+	if (mode & S_ISUID) {
+		bprm->per_clear |= PER_CLEAR_ON_SETID;
+		bprm->cred->euid = uid;
+	}
+
+	if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP)) {
+		bprm->per_clear |= PER_CLEAR_ON_SETID;
+		bprm->cred->egid = gid;
+	}
+}
+
 /*
  * Fill the binprm structure from the inode.
  * Check permissions, then read the first 128 (BINPRM_BUF_SIZE) bytes
@@ -1283,36 +1330,9 @@ static void check_unsafe_exec(struct linux_binprm *bprm)
  */
 int prepare_binprm(struct linux_binprm *bprm)
 {
-	struct inode *inode = file_inode(bprm->file);
-	umode_t mode = inode->i_mode;
 	int retval;
 
-
-	/* clear any previous set[ug]id data from a previous binary */
-	bprm->cred->euid = current_euid();
-	bprm->cred->egid = current_egid();
-
-	if (!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID) &&
-	    !task_no_new_privs(current) &&
-	    kuid_has_mapping(bprm->cred->user_ns, inode->i_uid) &&
-	    kgid_has_mapping(bprm->cred->user_ns, inode->i_gid)) {
-		/* Set-uid? */
-		if (mode & S_ISUID) {
-			bprm->per_clear |= PER_CLEAR_ON_SETID;
-			bprm->cred->euid = inode->i_uid;
-		}
-
-		/* Set-gid? */
-		/*
-		 * If setgid is set but no group execute bit then this
-		 * is a candidate for mandatory locking, not a setgid
-		 * executable.
-		 */
-		if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP)) {
-			bprm->per_clear |= PER_CLEAR_ON_SETID;
-			bprm->cred->egid = inode->i_gid;
-		}
-	}
+	bprm_fill_uid(bprm);
 
 	/* fill in binprm security blob */
 	retval = security_bprm_set_creds(bprm);

commit dfcce791fb0ad06f3f0b745a23160b9d8858fe39
Author: Kirill Tkhai <ktkhai@parallels.com>
Date:   Thu Apr 16 12:48:01 2015 -0700

    fs/exec.c:de_thread: move notify_count write under lock
    
    We set sig->notify_count = -1 between RELEASE and ACQUIRE operations:
    
            spin_unlock_irq(lock);
            ...
            if (!thread_group_leader(tsk)) {
                    ...
                    for (;;) {
                            sig->notify_count = -1;
                            write_lock_irq(&tasklist_lock);
    
    There are no restriction on it so other processors may see this STORE
    mixed with other STOREs in both areas limited by the spinlocks.
    
    Probably, it may be reordered with the above
    
            sig->group_exit_task = tsk;
            sig->notify_count = zap_other_threads(tsk);
    
    in some way.
    
    Set it under tasklist_lock locked to be sure nothing will be reordered.
    
    Signed-off-by: Kirill Tkhai <ktkhai@parallels.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a5fef835ebc5..02bfd980a40c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -926,10 +926,14 @@ static int de_thread(struct task_struct *tsk)
 	if (!thread_group_leader(tsk)) {
 		struct task_struct *leader = tsk->group_leader;
 
-		sig->notify_count = -1;	/* for exit_notify() */
 		for (;;) {
 			threadgroup_change_begin(tsk);
 			write_lock_irq(&tasklist_lock);
+			/*
+			 * Do this under tasklist_lock to ensure that
+			 * exit_notify() can't miss ->group_exit_task
+			 */
+			sig->notify_count = -1;
 			if (likely(leader->exit_state))
 				break;
 			__set_current_state(TASK_KILLABLE);

commit 6e399cd144d8500ffb5d40fa6848890e2580a80a
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Thu Apr 16 12:47:59 2015 -0700

    prctl: avoid using mmap_sem for exe_file serialization
    
    Oleg cleverly suggested using xchg() to set the new mm->exe_file instead
    of calling set_mm_exe_file() which requires some form of serialization --
    mmap_sem in this case.  For archs that do not have atomic rmw instructions
    we still fallback to a spinlock alternative, so this should always be
    safe.  As such, we only need the mmap_sem for looking up the backing
    vm_file, which can be done sharing the lock.  Naturally, this means we
    need to manually deal with both the new and old file reference counting,
    and we need not worry about the MMF_EXE_FILE_CHANGED bits, which can
    probably be deleted in the future anyway.
    
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index c7f9b733406d..a5fef835ebc5 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1078,7 +1078,13 @@ int flush_old_exec(struct linux_binprm * bprm)
 	if (retval)
 		goto out;
 
+	/*
+	 * Must be called _before_ exec_mmap() as bprm->mm is
+	 * not visibile until then. This also enables the update
+	 * to be lockless.
+	 */
 	set_mm_exe_file(bprm->mm, bprm->file);
+
 	/*
 	 * Release all of the old mmap stuff
 	 */

commit 5168910413830435fa3f0a593933a83721ec8bad
Author: Paul Moore <pmoore@redhat.com>
Date:   Thu Jan 22 00:00:03 2015 -0500

    fs: create proper filename objects using getname_kernel()
    
    There are several areas in the kernel that create temporary filename
    objects using the following pattern:
    
            int func(const char *name)
            {
                    struct filename *file = { .name = name };
                    ...
                    return 0;
            }
    
    ... which for the most part works okay, but it causes havoc within the
    audit subsystem as the filename object does not persist beyond the
    lifetime of the function.  This patch converts all of these temporary
    filename objects into proper filename objects using getname_kernel()
    and putname() which ensure that the filename object persists until the
    audit subsystem is finished with it.
    
    Also, a special thanks to Al Viro, Guenter Roeck, and Sabrina Dubroca
    for helping resolve a difficult kernel panic on boot related to a
    use-after-free problem in kern_path_create(); the thread can be seen
    at the link below:
    
     * https://lkml.org/lkml/2015/1/20/710
    
    This patch includes code that was either based on, or directly written
    by Al in the above thread.
    
    CC: viro@zeniv.linux.org.uk
    CC: linux@roeck-us.net
    CC: sd@queasysnail.net
    CC: linux-fsdevel@vger.kernel.org
    Signed-off-by: Paul Moore <pmoore@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index ad8798e26be9..c7f9b733406d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -794,8 +794,14 @@ static struct file *do_open_execat(int fd, struct filename *name, int flags)
 
 struct file *open_exec(const char *name)
 {
-	struct filename tmp = { .name = name };
-	return do_open_execat(AT_FDCWD, &tmp, 0);
+	struct filename *filename = getname_kernel(name);
+	struct file *f = ERR_CAST(filename);
+
+	if (!IS_ERR(filename)) {
+		f = do_open_execat(AT_FDCWD, filename, 0);
+		putname(filename);
+	}
+	return f;
 }
 EXPORT_SYMBOL(open_exec);
 

commit 51f39a1f0cea1cacf8c787f652f26dfee9611874
Author: David Drysdale <drysdale@google.com>
Date:   Fri Dec 12 16:57:29 2014 -0800

    syscalls: implement execveat() system call
    
    This patchset adds execveat(2) for x86, and is derived from Meredydd
    Luff's patch from Sept 2012 (https://lkml.org/lkml/2012/9/11/528).
    
    The primary aim of adding an execveat syscall is to allow an
    implementation of fexecve(3) that does not rely on the /proc filesystem,
    at least for executables (rather than scripts).  The current glibc version
    of fexecve(3) is implemented via /proc, which causes problems in sandboxed
    or otherwise restricted environments.
    
    Given the desire for a /proc-free fexecve() implementation, HPA suggested
    (https://lkml.org/lkml/2006/7/11/556) that an execveat(2) syscall would be
    an appropriate generalization.
    
    Also, having a new syscall means that it can take a flags argument without
    back-compatibility concerns.  The current implementation just defines the
    AT_EMPTY_PATH and AT_SYMLINK_NOFOLLOW flags, but other flags could be
    added in future -- for example, flags for new namespaces (as suggested at
    https://lkml.org/lkml/2006/7/11/474).
    
    Related history:
     - https://lkml.org/lkml/2006/12/27/123 is an example of someone
       realizing that fexecve() is likely to fail in a chroot environment.
     - http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=514043 covered
       documenting the /proc requirement of fexecve(3) in its manpage, to
       "prevent other people from wasting their time".
     - https://bugzilla.redhat.com/show_bug.cgi?id=241609 described a
       problem where a process that did setuid() could not fexecve()
       because it no longer had access to /proc/self/fd; this has since
       been fixed.
    
    This patch (of 4):
    
    Add a new execveat(2) system call.  execveat() is to execve() as openat()
    is to open(): it takes a file descriptor that refers to a directory, and
    resolves the filename relative to that.
    
    In addition, if the filename is empty and AT_EMPTY_PATH is specified,
    execveat() executes the file to which the file descriptor refers.  This
    replicates the functionality of fexecve(), which is a system call in other
    UNIXen, but in Linux glibc it depends on opening "/proc/self/fd/<fd>" (and
    so relies on /proc being mounted).
    
    The filename fed to the executed program as argv[0] (or the name of the
    script fed to a script interpreter) will be of the form "/dev/fd/<fd>"
    (for an empty filename) or "/dev/fd/<fd>/<filename>", effectively
    reflecting how the executable was found.  This does however mean that
    execution of a script in a /proc-less environment won't work; also, script
    execution via an O_CLOEXEC file descriptor fails (as the file will not be
    accessible after exec).
    
    Based on patches by Meredydd Luff.
    
    Signed-off-by: David Drysdale <drysdale@google.com>
    Cc: Meredydd Luff <meredydd@senatehouse.org>
    Cc: Shuah Khan <shuah.kh@samsung.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Rich Felker <dalias@aerifal.cx>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 01aebe300200..ad8798e26be9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -748,18 +748,25 @@ EXPORT_SYMBOL(setup_arg_pages);
 
 #endif /* CONFIG_MMU */
 
-static struct file *do_open_exec(struct filename *name)
+static struct file *do_open_execat(int fd, struct filename *name, int flags)
 {
 	struct file *file;
 	int err;
-	static const struct open_flags open_exec_flags = {
+	struct open_flags open_exec_flags = {
 		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
 		.acc_mode = MAY_EXEC | MAY_OPEN,
 		.intent = LOOKUP_OPEN,
 		.lookup_flags = LOOKUP_FOLLOW,
 	};
 
-	file = do_filp_open(AT_FDCWD, name, &open_exec_flags);
+	if ((flags & ~(AT_SYMLINK_NOFOLLOW | AT_EMPTY_PATH)) != 0)
+		return ERR_PTR(-EINVAL);
+	if (flags & AT_SYMLINK_NOFOLLOW)
+		open_exec_flags.lookup_flags &= ~LOOKUP_FOLLOW;
+	if (flags & AT_EMPTY_PATH)
+		open_exec_flags.lookup_flags |= LOOKUP_EMPTY;
+
+	file = do_filp_open(fd, name, &open_exec_flags);
 	if (IS_ERR(file))
 		goto out;
 
@@ -770,12 +777,13 @@ static struct file *do_open_exec(struct filename *name)
 	if (file->f_path.mnt->mnt_flags & MNT_NOEXEC)
 		goto exit;
 
-	fsnotify_open(file);
-
 	err = deny_write_access(file);
 	if (err)
 		goto exit;
 
+	if (name->name[0] != '\0')
+		fsnotify_open(file);
+
 out:
 	return file;
 
@@ -787,7 +795,7 @@ static struct file *do_open_exec(struct filename *name)
 struct file *open_exec(const char *name)
 {
 	struct filename tmp = { .name = name };
-	return do_open_exec(&tmp);
+	return do_open_execat(AT_FDCWD, &tmp, 0);
 }
 EXPORT_SYMBOL(open_exec);
 
@@ -1428,10 +1436,12 @@ static int exec_binprm(struct linux_binprm *bprm)
 /*
  * sys_execve() executes a new program.
  */
-static int do_execve_common(struct filename *filename,
-				struct user_arg_ptr argv,
-				struct user_arg_ptr envp)
+static int do_execveat_common(int fd, struct filename *filename,
+			      struct user_arg_ptr argv,
+			      struct user_arg_ptr envp,
+			      int flags)
 {
+	char *pathbuf = NULL;
 	struct linux_binprm *bprm;
 	struct file *file;
 	struct files_struct *displaced;
@@ -1472,7 +1482,7 @@ static int do_execve_common(struct filename *filename,
 	check_unsafe_exec(bprm);
 	current->in_execve = 1;
 
-	file = do_open_exec(filename);
+	file = do_open_execat(fd, filename, flags);
 	retval = PTR_ERR(file);
 	if (IS_ERR(file))
 		goto out_unmark;
@@ -1480,7 +1490,28 @@ static int do_execve_common(struct filename *filename,
 	sched_exec();
 
 	bprm->file = file;
-	bprm->filename = bprm->interp = filename->name;
+	if (fd == AT_FDCWD || filename->name[0] == '/') {
+		bprm->filename = filename->name;
+	} else {
+		if (filename->name[0] == '\0')
+			pathbuf = kasprintf(GFP_TEMPORARY, "/dev/fd/%d", fd);
+		else
+			pathbuf = kasprintf(GFP_TEMPORARY, "/dev/fd/%d/%s",
+					    fd, filename->name);
+		if (!pathbuf) {
+			retval = -ENOMEM;
+			goto out_unmark;
+		}
+		/*
+		 * Record that a name derived from an O_CLOEXEC fd will be
+		 * inaccessible after exec. Relies on having exclusive access to
+		 * current->files (due to unshare_files above).
+		 */
+		if (close_on_exec(fd, rcu_dereference_raw(current->files->fdt)))
+			bprm->interp_flags |= BINPRM_FLAGS_PATH_INACCESSIBLE;
+		bprm->filename = pathbuf;
+	}
+	bprm->interp = bprm->filename;
 
 	retval = bprm_mm_init(bprm);
 	if (retval)
@@ -1521,6 +1552,7 @@ static int do_execve_common(struct filename *filename,
 	acct_update_integrals(current);
 	task_numa_free(current);
 	free_bprm(bprm);
+	kfree(pathbuf);
 	putname(filename);
 	if (displaced)
 		put_files_struct(displaced);
@@ -1538,6 +1570,7 @@ static int do_execve_common(struct filename *filename,
 
 out_free:
 	free_bprm(bprm);
+	kfree(pathbuf);
 
 out_files:
 	if (displaced)
@@ -1553,7 +1586,18 @@ int do_execve(struct filename *filename,
 {
 	struct user_arg_ptr argv = { .ptr.native = __argv };
 	struct user_arg_ptr envp = { .ptr.native = __envp };
-	return do_execve_common(filename, argv, envp);
+	return do_execveat_common(AT_FDCWD, filename, argv, envp, 0);
+}
+
+int do_execveat(int fd, struct filename *filename,
+		const char __user *const __user *__argv,
+		const char __user *const __user *__envp,
+		int flags)
+{
+	struct user_arg_ptr argv = { .ptr.native = __argv };
+	struct user_arg_ptr envp = { .ptr.native = __envp };
+
+	return do_execveat_common(fd, filename, argv, envp, flags);
 }
 
 #ifdef CONFIG_COMPAT
@@ -1569,7 +1613,23 @@ static int compat_do_execve(struct filename *filename,
 		.is_compat = true,
 		.ptr.compat = __envp,
 	};
-	return do_execve_common(filename, argv, envp);
+	return do_execveat_common(AT_FDCWD, filename, argv, envp, 0);
+}
+
+static int compat_do_execveat(int fd, struct filename *filename,
+			      const compat_uptr_t __user *__argv,
+			      const compat_uptr_t __user *__envp,
+			      int flags)
+{
+	struct user_arg_ptr argv = {
+		.is_compat = true,
+		.ptr.compat = __argv,
+	};
+	struct user_arg_ptr envp = {
+		.is_compat = true,
+		.ptr.compat = __envp,
+	};
+	return do_execveat_common(fd, filename, argv, envp, flags);
 }
 #endif
 
@@ -1609,6 +1669,20 @@ SYSCALL_DEFINE3(execve,
 {
 	return do_execve(getname(filename), argv, envp);
 }
+
+SYSCALL_DEFINE5(execveat,
+		int, fd, const char __user *, filename,
+		const char __user *const __user *, argv,
+		const char __user *const __user *, envp,
+		int, flags)
+{
+	int lookup_flags = (flags & AT_EMPTY_PATH) ? LOOKUP_EMPTY : 0;
+
+	return do_execveat(fd,
+			   getname_flags(filename, lookup_flags, NULL),
+			   argv, envp, flags);
+}
+
 #ifdef CONFIG_COMPAT
 COMPAT_SYSCALL_DEFINE3(execve, const char __user *, filename,
 	const compat_uptr_t __user *, argv,
@@ -1616,4 +1690,17 @@ COMPAT_SYSCALL_DEFINE3(execve, const char __user *, filename,
 {
 	return compat_do_execve(getname(filename), argv, envp);
 }
+
+COMPAT_SYSCALL_DEFINE5(execveat, int, fd,
+		       const char __user *, filename,
+		       const compat_uptr_t __user *, argv,
+		       const compat_uptr_t __user *, envp,
+		       int,  flags)
+{
+	int lookup_flags = (flags & AT_EMPTY_PATH) ? LOOKUP_EMPTY : 0;
+
+	return compat_do_execveat(fd,
+				  getname_flags(filename, lookup_flags, NULL),
+				  argv, envp, flags);
+}
 #endif

commit abe1e395f6171cb2d07330c690fe0285f7f859e6
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Mon Nov 17 16:36:08 2014 -0800

    fs: Do not include mpx.h in exec.c
    
    We no longer need mpx.h in exec.c.  This will obviously also
    break the build for non-x86 builds.  We get the MPX includes that
    we need from mmu_context.h now.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Dave Hansen <dave@sr71.net>
    Link: http://lkml.kernel.org/r/20141118003608.837015B3@viggo.jf.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/fs/exec.c b/fs/exec.c
index 65d4f5c70ef4..01aebe300200 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -60,7 +60,6 @@
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlb.h>
-#include <asm/mpx.h>
 
 #include <trace/events/task.h>
 #include "internal.h"

commit fe3d197f84319d3bce379a9c0dc17b1f48ad358c
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Nov 14 07:18:29 2014 -0800

    x86, mpx: On-demand kernel allocation of bounds tables
    
    This is really the meat of the MPX patch set.  If there is one patch to
    review in the entire series, this is the one.  There is a new ABI here
    and this kernel code also interacts with userspace memory in a
    relatively unusual manner.  (small FAQ below).
    
    Long Description:
    
    This patch adds two prctl() commands to provide enable or disable the
    management of bounds tables in kernel, including on-demand kernel
    allocation (See the patch "on-demand kernel allocation of bounds tables")
    and cleanup (See the patch "cleanup unused bound tables"). Applications
    do not strictly need the kernel to manage bounds tables and we expect
    some applications to use MPX without taking advantage of this kernel
    support. This means the kernel can not simply infer whether an application
    needs bounds table management from the MPX registers.  The prctl() is an
    explicit signal from userspace.
    
    PR_MPX_ENABLE_MANAGEMENT is meant to be a signal from userspace to
    require kernel's help in managing bounds tables.
    
    PR_MPX_DISABLE_MANAGEMENT is the opposite, meaning that userspace don't
    want kernel's help any more. With PR_MPX_DISABLE_MANAGEMENT, the kernel
    won't allocate and free bounds tables even if the CPU supports MPX.
    
    PR_MPX_ENABLE_MANAGEMENT will fetch the base address of the bounds
    directory out of a userspace register (bndcfgu) and then cache it into
    a new field (->bd_addr) in  the 'mm_struct'.  PR_MPX_DISABLE_MANAGEMENT
    will set "bd_addr" to an invalid address.  Using this scheme, we can
    use "bd_addr" to determine whether the management of bounds tables in
    kernel is enabled.
    
    Also, the only way to access that bndcfgu register is via an xsaves,
    which can be expensive.  Caching "bd_addr" like this also helps reduce
    the cost of those xsaves when doing table cleanup at munmap() time.
    Unfortunately, we can not apply this optimization to #BR fault time
    because we need an xsave to get the value of BNDSTATUS.
    
    ==== Why does the hardware even have these Bounds Tables? ====
    
    MPX only has 4 hardware registers for storing bounds information.
    If MPX-enabled code needs more than these 4 registers, it needs to
    spill them somewhere. It has two special instructions for this
    which allow the bounds to be moved between the bounds registers
    and some new "bounds tables".
    
    They are similar conceptually to a page fault and will be raised by
    the MPX hardware during both bounds violations or when the tables
    are not present. This patch handles those #BR exceptions for
    not-present tables by carving the space out of the normal processes
    address space (essentially calling the new mmap() interface indroduced
    earlier in this patch set.) and then pointing the bounds-directory
    over to it.
    
    The tables *need* to be accessed and controlled by userspace because
    the instructions for moving bounds in and out of them are extremely
    frequent. They potentially happen every time a register pointing to
    memory is dereferenced. Any direct kernel involvement (like a syscall)
    to access the tables would obviously destroy performance.
    
    ==== Why not do this in userspace? ====
    
    This patch is obviously doing this allocation in the kernel.
    However, MPX does not strictly *require* anything in the kernel.
    It can theoretically be done completely from userspace. Here are
    a few ways this *could* be done. I don't think any of them are
    practical in the real-world, but here they are.
    
    Q: Can virtual space simply be reserved for the bounds tables so
       that we never have to allocate them?
    A: As noted earlier, these tables are *HUGE*. An X-GB virtual
       area needs 4*X GB of virtual space, plus 2GB for the bounds
       directory. If we were to preallocate them for the 128TB of
       user virtual address space, we would need to reserve 512TB+2GB,
       which is larger than the entire virtual address space today.
       This means they can not be reserved ahead of time. Also, a
       single process's pre-popualated bounds directory consumes 2GB
       of virtual *AND* physical memory. IOW, it's completely
       infeasible to prepopulate bounds directories.
    
    Q: Can we preallocate bounds table space at the same time memory
       is allocated which might contain pointers that might eventually
       need bounds tables?
    A: This would work if we could hook the site of each and every
       memory allocation syscall. This can be done for small,
       constrained applications. But, it isn't practical at a larger
       scale since a given app has no way of controlling how all the
       parts of the app might allocate memory (think libraries). The
       kernel is really the only place to intercept these calls.
    
    Q: Could a bounds fault be handed to userspace and the tables
       allocated there in a signal handler instead of in the kernel?
    A: (thanks to tglx) mmap() is not on the list of safe async
       handler functions and even if mmap() would work it still
       requires locking or nasty tricks to keep track of the
       allocation state there.
    
    Having ruled out all of the userspace-only approaches for managing
    bounds tables that we could think of, we create them on demand in
    the kernel.
    
    Based-on-patch-by: Qiaowei Ren <qiaowei.ren@intel.com>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: linux-mm@kvack.org
    Cc: linux-mips@linux-mips.org
    Cc: Dave Hansen <dave@sr71.net>
    Link: http://lkml.kernel.org/r/20141114151829.AD4310DE@viggo.jf.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/fs/exec.c b/fs/exec.c
index 7302b75a9820..65d4f5c70ef4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -60,6 +60,7 @@
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlb.h>
+#include <asm/mpx.h>
 
 #include <trace/events/task.h>
 #include "internal.h"
@@ -277,6 +278,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 		goto err;
 
 	mm->stack_vm = mm->total_vm = 1;
+	arch_bprm_mm_init(mm, vma);
 	up_write(&mm->mmap_sem);
 	bprm->p = vma->vm_end - sizeof(void *);
 	return 0;

commit 19d860a140beac48a1377f179e693abe86a9dac9
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun May 4 20:11:36 2014 -0400

    handle suicide on late failure exits in execve() in search_binary_handler()
    
    ... rather than doing that in the guts of ->load_binary().
    [updated to fix the bug spotted by Shentino - for SIGSEGV we really need
    something stronger than send_sig_info(); again, better do that in one place]
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index a2b42a98c743..7302b75a9820 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1372,18 +1372,23 @@ int search_binary_handler(struct linux_binprm *bprm)
 		read_unlock(&binfmt_lock);
 		bprm->recursion_depth++;
 		retval = fmt->load_binary(bprm);
+		read_lock(&binfmt_lock);
+		put_binfmt(fmt);
 		bprm->recursion_depth--;
-		if (retval >= 0 || retval != -ENOEXEC ||
-		    bprm->mm == NULL || bprm->file == NULL) {
-			put_binfmt(fmt);
+		if (retval < 0 && !bprm->mm) {
+			/* we got to flush_old_exec() and failed after it */
+			read_unlock(&binfmt_lock);
+			force_sigsegv(SIGSEGV, current);
+			return retval;
+		}
+		if (retval != -ENOEXEC || !bprm->file) {
+			read_unlock(&binfmt_lock);
 			return retval;
 		}
-		read_lock(&binfmt_lock);
-		put_binfmt(fmt);
 	}
 	read_unlock(&binfmt_lock);
 
-	if (need_retry && retval == -ENOEXEC) {
+	if (need_retry) {
 		if (printable(bprm->buf[0]) && printable(bprm->buf[1]) &&
 		    printable(bprm->buf[2]) && printable(bprm->buf[3]))
 			return retval;

commit 41f727fde1fe40efeb4fef6fdce74ff794be5aeb
Author: Vladimir Davydov <vdavydov@parallels.com>
Date:   Fri Aug 8 14:21:56 2014 -0700

    fork/exec: cleanup mm initialization
    
    mm initialization on fork/exec is spread all over the place, which makes
    the code look inconsistent.
    
    We have mm_init(), which is supposed to init/nullify mm's internals, but
    it doesn't init all the fields it should:
    
     - on fork ->mmap,mm_rb,vmacache_seqnum,map_count,mm_cpumask,locked_vm
       are zeroed in dup_mmap();
    
     - on fork ->pmd_huge_pte is zeroed in dup_mm(), immediately before
       calling mm_init();
    
     - ->cpu_vm_mask_var ptr is initialized by mm_init_cpumask(), which is
       called before mm_init() on both fork and exec;
    
     - ->context is initialized by init_new_context(), which is called after
       mm_init() on both fork and exec;
    
    Let's consolidate all the initializations in mm_init() to make the code
    look cleaner.
    
    Signed-off-by: Vladimir Davydov <vdavydov@parallels.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Christoph Lameter <cl@linux.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ab1f1200ce5d..a2b42a98c743 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -368,10 +368,6 @@ static int bprm_mm_init(struct linux_binprm *bprm)
 	if (!mm)
 		goto err;
 
-	err = init_new_context(current, mm);
-	if (err)
-		goto err;
-
 	err = __bprm_mm_init(bprm);
 	if (err)
 		goto err;

commit c2e1f2e30daa551db3c670c0ccfeab20a540b9e1
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Jun 5 00:23:17 2014 -0700

    seccomp: implement SECCOMP_FILTER_FLAG_TSYNC
    
    Applying restrictive seccomp filter programs to large or diverse
    codebases often requires handling threads which may be started early in
    the process lifetime (e.g., by code that is linked in). While it is
    possible to apply permissive programs prior to process start up, it is
    difficult to further restrict the kernel ABI to those threads after that
    point.
    
    This change adds a new seccomp syscall flag to SECCOMP_SET_MODE_FILTER for
    synchronizing thread group seccomp filters at filter installation time.
    
    When calling seccomp(SECCOMP_SET_MODE_FILTER, SECCOMP_FILTER_FLAG_TSYNC,
    filter) an attempt will be made to synchronize all threads in current's
    threadgroup to its new seccomp filter program. This is possible iff all
    threads are using a filter that is an ancestor to the filter current is
    attempting to synchronize to. NULL filters (where the task is running as
    SECCOMP_MODE_NONE) are also treated as ancestors allowing threads to be
    transitioned into SECCOMP_MODE_FILTER. If prctrl(PR_SET_NO_NEW_PRIVS,
    ...) has been set on the calling thread, no_new_privs will be set for
    all synchronized threads too. On success, 0 is returned. On failure,
    the pid of one of the failing threads will be returned and no filters
    will have been applied.
    
    The race conditions against another thread are:
    - requesting TSYNC (already handled by sighand lock)
    - performing a clone (already handled by sighand lock)
    - changing its filter (already handled by sighand lock)
    - calling exec (handled by cred_guard_mutex)
    The clone case is assisted by the fact that new threads will have their
    seccomp state duplicated from their parent before appearing on the tasklist.
    
    Holding cred_guard_mutex means that seccomp filters cannot be assigned
    while in the middle of another thread's exec (potentially bypassing
    no_new_privs or similar). The call to de_thread() may kill threads waiting
    for the mutex.
    
    Changes across threads to the filter pointer includes a barrier.
    
    Based on patches by Will Drewry.
    
    Suggested-by: Julien Tinnes <jln@chromium.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/fs/exec.c b/fs/exec.c
index 0f5c272410f6..ab1f1200ce5d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1216,7 +1216,7 @@ EXPORT_SYMBOL(install_exec_creds);
 /*
  * determine how safe it is to execute the proposed program
  * - the caller must hold ->cred_guard_mutex to protect against
- *   PTRACE_ATTACH
+ *   PTRACE_ATTACH or seccomp thread-sync
  */
 static void check_unsafe_exec(struct linux_binprm *bprm)
 {

commit 1d4457f99928a968767f6405b4a1f50845aa15fd
Author: Kees Cook <keescook@chromium.org>
Date:   Wed May 21 15:23:46 2014 -0700

    sched: move no_new_privs into new atomic flags
    
    Since seccomp transitions between threads requires updates to the
    no_new_privs flag to be atomic, the flag must be part of an atomic flag
    set. This moves the nnp flag into a separate task field, and introduces
    accessors.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/fs/exec.c b/fs/exec.c
index a3d33fe592d6..0f5c272410f6 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1234,7 +1234,7 @@ static void check_unsafe_exec(struct linux_binprm *bprm)
 	 * This isn't strictly necessary, but it makes it harder for LSMs to
 	 * mess up.
 	 */
-	if (current->no_new_privs)
+	if (task_no_new_privs(current))
 		bprm->unsafe |= LSM_UNSAFE_NO_NEW_PRIVS;
 
 	t = p;
@@ -1272,7 +1272,7 @@ int prepare_binprm(struct linux_binprm *bprm)
 	bprm->cred->egid = current_egid();
 
 	if (!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID) &&
-	    !current->no_new_privs &&
+	    !task_no_new_privs(current) &&
 	    kuid_has_mapping(bprm->cred->user_ns, inode->i_uid) &&
 	    kgid_has_mapping(bprm->cred->user_ns, inode->i_gid)) {
 		/* Set-uid? */

commit 82b897782d10fcc4930c9d4a15b175348fdd2871
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed May 28 11:45:04 2014 +0300

    perf: Differentiate exec() and non-exec() comm events
    
    perf tools like 'perf report' can aggregate samples by comm strings,
    which generally works.  However, there are other potential use-cases.
    For example, to pair up 'calls' with 'returns' accurately (from branch
    events like Intel BTS) it is necessary to identify whether the process
    has exec'd.  Although a comm event is generated when an 'exec' happens
    it is also generated whenever the comm string is changed on a whim
    (e.g. by prctl PR_SET_NAME).  This patch adds a flag to the comm event
    to differentiate one case from the other.
    
    In order to determine whether the kernel supports the new flag, a
    selection bit named 'exec' is added to struct perf_event_attr.  The
    bit does nothing but will cause perf_event_open() to fail if the bit
    is set on kernels that do not have it defined.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/537D9EBE.7030806@intel.com
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Dave Jones <davej@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: linux-fsdevel@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index a038a41a3677..a3d33fe592d6 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1046,13 +1046,13 @@ EXPORT_SYMBOL_GPL(get_task_comm);
  * so that a new one can be started
  */
 
-void set_task_comm(struct task_struct *tsk, const char *buf)
+void __set_task_comm(struct task_struct *tsk, const char *buf, bool exec)
 {
 	task_lock(tsk);
 	trace_task_rename(tsk, buf);
 	strlcpy(tsk->comm, buf, sizeof(tsk->comm));
 	task_unlock(tsk);
-	perf_event_comm(tsk);
+	perf_event_comm(tsk, exec);
 }
 
 int flush_old_exec(struct linux_binprm * bprm)
@@ -1111,7 +1111,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 		set_dumpable(current->mm, suid_dumpable);
 
 	perf_event_exec();
-	set_task_comm(current, kbasename(bprm->filename));
+	__set_task_comm(current, kbasename(bprm->filename), true);
 
 	/* Set the new mm task size. We have to do that late because it may
 	 * depend on TIF_32BIT which is only updated in flush_thread() on

commit e041e328c4b41e1db79bfe5ba9992c2ed771ad19
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed May 21 17:32:19 2014 +0200

    perf: Fix perf_event_comm() vs. exec() assumption
    
    perf_event_comm() assumes that set_task_comm() is only called on
    exec(), and in particular that its only called on current.
    
    Neither are true, as Dave reported a WARN triggered by set_task_comm()
    being called on !current.
    
    Separate the exec() hook from the comm hook.
    
    Reported-by: Dave Jones <davej@redhat.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: linux-fsdevel@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Link: http://lkml.kernel.org/r/20140521153219.GH5226@laptop.programming.kicks-ass.net
    [ Build fix. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 238b7aa26f68..a038a41a3677 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1110,6 +1110,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 	else
 		set_dumpable(current->mm, suid_dumpable);
 
+	perf_event_exec();
 	set_task_comm(current, kbasename(bprm->filename));
 
 	/* Set the new mm task size. We have to do that late because it may

commit d71f290b4e98a39f49f2595a13be3b4d5ce8e1f1
Author: James Hogan <james.hogan@imgtec.com>
Date:   Tue May 13 23:58:24 2014 +0100

    metag: Reduce maximum stack size to 256MB
    
    Specify the maximum stack size for arches where the stack grows upward
    (parisc and metag) in asm/processor.h rather than hard coding in
    fs/exec.c so that metag can specify a smaller value of 256MB rather than
    1GB.
    
    This fixes a BUG on metag if the RLIMIT_STACK hard limit is increased
    beyond a safe value by root. E.g. when starting a process after running
    "ulimit -H -s unlimited" it will then attempt to use a stack size of the
    maximum 1GB which is far too big for metag's limited user virtual
    address space (stack_top is usually 0x3ffff000):
    
    BUG: failure at fs/exec.c:589/shift_arg_pages()!
    
    Signed-off-by: James Hogan <james.hogan@imgtec.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: linux-parisc@vger.kernel.org
    Cc: linux-metag@vger.kernel.org
    Cc: John David Anglin <dave.anglin@bell.net>
    Cc: stable@vger.kernel.org # only needed for >= v3.9 (arch/metag)

diff --git a/fs/exec.c b/fs/exec.c
index 476f3ebf437e..238b7aa26f68 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -657,10 +657,10 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	unsigned long rlim_stack;
 
 #ifdef CONFIG_STACK_GROWSUP
-	/* Limit stack size to 1GB */
+	/* Limit stack size */
 	stack_base = rlimit_max(RLIMIT_STACK);
-	if (stack_base > (1 << 30))
-		stack_base = 1 << 30;
+	if (stack_base > STACK_SIZE_MAX)
+		stack_base = STACK_SIZE_MAX;
 
 	/* Make sure we didn't let the argument array grow too large. */
 	if (vma->vm_end - vma->vm_start > stack_base)

commit 5166701b368caea89d57b14bf41cf39e819dad51
Merge: 0a7418f5f569 a786c06d9f27
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 12 14:49:50 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs updates from Al Viro:
     "The first vfs pile, with deep apologies for being very late in this
      window.
    
      Assorted cleanups and fixes, plus a large preparatory part of iov_iter
      work.  There's a lot more of that, but it'll probably go into the next
      merge window - it *does* shape up nicely, removes a lot of
      boilerplate, gets rid of locking inconsistencie between aio_write and
      splice_write and I hope to get Kent's direct-io rewrite merged into
      the same queue, but some of the stuff after this point is having
      (mostly trivial) conflicts with the things already merged into
      mainline and with some I want more testing.
    
      This one passes LTP and xfstests without regressions, in addition to
      usual beating.  BTW, readahead02 in ltp syscalls testsuite has started
      giving failures since "mm/readahead.c: fix readahead failure for
      memoryless NUMA nodes and limit readahead pages" - might be a false
      positive, might be a real regression..."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (63 commits)
      missing bits of "splice: fix racy pipe->buffers uses"
      cifs: fix the race in cifs_writev()
      ceph_sync_{,direct_}write: fix an oops on ceph_osdc_new_request() failure
      kill generic_file_buffered_write()
      ocfs2_file_aio_write(): switch to generic_perform_write()
      ceph_aio_write(): switch to generic_perform_write()
      xfs_file_buffered_aio_write(): switch to generic_perform_write()
      export generic_perform_write(), start getting rid of generic_file_buffer_write()
      generic_file_direct_write(): get rid of ppos argument
      btrfs_file_aio_write(): get rid of ppos
      kill the 5th argument of generic_file_buffered_write()
      kill the 4th argument of __generic_file_aio_write()
      lustre: don't open-code kernel_recvmsg()
      ocfs2: don't open-code kernel_recvmsg()
      drbd: don't open-code kernel_recvmsg()
      constify blk_rq_map_user_iov() and friends
      lustre: switch to kernel_sendmsg()
      ocfs2: don't open-code kernel_sendmsg()
      take iov_iter stuff to mm/iov_iter.c
      process_vm_access: tidy up a bit
      ...

commit 23aebe1691a3d98a79676db6c0fd813e16478804
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Apr 7 15:38:39 2014 -0700

    exec: kill bprm->tcomm[], simplify the "basename" logic
    
    Starting from commit c4ad8f98bef7 ("execve: use 'struct filename *' for
    executable name passing") bprm->filename can not go away after
    flush_old_exec(), so we do not need to save the binary name in
    bprm->tcomm[] added by 96e02d158678 ("exec: fix use-after-free bug in
    setup_new_exec()").
    
    And there was never need for filename_to_taskname-like code, we can
    simply do set_task_comm(kbasename(filename).
    
    This patch has to change set_task_comm() and trace_task_rename() to
    accept "const char *", but I think this change is also good.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index b60ccf969a8b..9e81c630dfa7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1046,7 +1046,7 @@ EXPORT_SYMBOL_GPL(get_task_comm);
  * so that a new one can be started
  */
 
-void set_task_comm(struct task_struct *tsk, char *buf)
+void set_task_comm(struct task_struct *tsk, const char *buf)
 {
 	task_lock(tsk);
 	trace_task_rename(tsk, buf);
@@ -1055,21 +1055,6 @@ void set_task_comm(struct task_struct *tsk, char *buf)
 	perf_event_comm(tsk);
 }
 
-static void filename_to_taskname(char *tcomm, const char *fn, unsigned int len)
-{
-	int i, ch;
-
-	/* Copies the binary name from after last slash */
-	for (i = 0; (ch = *(fn++)) != '\0';) {
-		if (ch == '/')
-			i = 0; /* overwrite what we wrote */
-		else
-			if (i < len - 1)
-				tcomm[i++] = ch;
-	}
-	tcomm[i] = '\0';
-}
-
 int flush_old_exec(struct linux_binprm * bprm)
 {
 	int retval;
@@ -1083,8 +1068,6 @@ int flush_old_exec(struct linux_binprm * bprm)
 		goto out;
 
 	set_mm_exe_file(bprm->mm, bprm->file);
-
-	filename_to_taskname(bprm->tcomm, bprm->filename, sizeof(bprm->tcomm));
 	/*
 	 * Release all of the old mmap stuff
 	 */
@@ -1127,7 +1110,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 	else
 		set_dumpable(current->mm, suid_dumpable);
 
-	set_task_comm(current, bprm->tcomm);
+	set_task_comm(current, kbasename(bprm->filename));
 
 	/* Set the new mm task size. We have to do that late because it may
 	 * depend on TIF_32BIT which is only updated in flush_thread() on

commit 615d6e8756c87149f2d4c1b93d471bca002bd849
Author: Davidlohr Bueso <davidlohr@hp.com>
Date:   Mon Apr 7 15:37:25 2014 -0700

    mm: per-thread vma caching
    
    This patch is a continuation of efforts trying to optimize find_vma(),
    avoiding potentially expensive rbtree walks to locate a vma upon faults.
    The original approach (https://lkml.org/lkml/2013/11/1/410), where the
    largest vma was also cached, ended up being too specific and random,
    thus further comparison with other approaches were needed.  There are
    two things to consider when dealing with this, the cache hit rate and
    the latency of find_vma().  Improving the hit-rate does not necessarily
    translate in finding the vma any faster, as the overhead of any fancy
    caching schemes can be too high to consider.
    
    We currently cache the last used vma for the whole address space, which
    provides a nice optimization, reducing the total cycles in find_vma() by
    up to 250%, for workloads with good locality.  On the other hand, this
    simple scheme is pretty much useless for workloads with poor locality.
    Analyzing ebizzy runs shows that, no matter how many threads are
    running, the mmap_cache hit rate is less than 2%, and in many situations
    below 1%.
    
    The proposed approach is to replace this scheme with a small per-thread
    cache, maximizing hit rates at a very low maintenance cost.
    Invalidations are performed by simply bumping up a 32-bit sequence
    number.  The only expensive operation is in the rare case of a seq
    number overflow, where all caches that share the same address space are
    flushed.  Upon a miss, the proposed replacement policy is based on the
    page number that contains the virtual address in question.  Concretely,
    the following results are seen on an 80 core, 8 socket x86-64 box:
    
    1) System bootup: Most programs are single threaded, so the per-thread
       scheme does improve ~50% hit rate by just adding a few more slots to
       the cache.
    
    +----------------+----------+------------------+
    | caching scheme | hit-rate | cycles (billion) |
    +----------------+----------+------------------+
    | baseline       | 50.61%   | 19.90            |
    | patched        | 73.45%   | 13.58            |
    +----------------+----------+------------------+
    
    2) Kernel build: This one is already pretty good with the current
       approach as we're dealing with good locality.
    
    +----------------+----------+------------------+
    | caching scheme | hit-rate | cycles (billion) |
    +----------------+----------+------------------+
    | baseline       | 75.28%   | 11.03            |
    | patched        | 88.09%   | 9.31             |
    +----------------+----------+------------------+
    
    3) Oracle 11g Data Mining (4k pages): Similar to the kernel build workload.
    
    +----------------+----------+------------------+
    | caching scheme | hit-rate | cycles (billion) |
    +----------------+----------+------------------+
    | baseline       | 70.66%   | 17.14            |
    | patched        | 91.15%   | 12.57            |
    +----------------+----------+------------------+
    
    4) Ebizzy: There's a fair amount of variation from run to run, but this
       approach always shows nearly perfect hit rates, while baseline is just
       about non-existent.  The amounts of cycles can fluctuate between
       anywhere from ~60 to ~116 for the baseline scheme, but this approach
       reduces it considerably.  For instance, with 80 threads:
    
    +----------------+----------+------------------+
    | caching scheme | hit-rate | cycles (billion) |
    +----------------+----------+------------------+
    | baseline       | 1.06%    | 91.54            |
    | patched        | 99.97%   | 14.18            |
    +----------------+----------+------------------+
    
    [akpm@linux-foundation.org: fix nommu build, per Davidlohr]
    [akpm@linux-foundation.org: document vmacache_valid() logic]
    [akpm@linux-foundation.org: attempt to untangle header files]
    [akpm@linux-foundation.org: add vmacache_find() BUG_ON]
    [hughd@google.com: add vmacache_valid_mm() (from Oleg)]
    [akpm@linux-foundation.org: coding-style fixes]
    [akpm@linux-foundation.org: adjust and enhance comments]
    Signed-off-by: Davidlohr Bueso <davidlohr@hp.com>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Michel Lespinasse <walken@google.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Tested-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 25dfeba6d55f..b60ccf969a8b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -26,6 +26,7 @@
 #include <linux/file.h>
 #include <linux/fdtable.h>
 #include <linux/mm.h>
+#include <linux/vmacache.h>
 #include <linux/stat.h>
 #include <linux/fcntl.h>
 #include <linux/swap.h>
@@ -822,7 +823,7 @@ EXPORT_SYMBOL(read_code);
 static int exec_mmap(struct mm_struct *mm)
 {
 	struct task_struct *tsk;
-	struct mm_struct * old_mm, *active_mm;
+	struct mm_struct *old_mm, *active_mm;
 
 	/* Notify parent that we're no longer interested in the old VM */
 	tsk = current;
@@ -848,6 +849,8 @@ static int exec_mmap(struct mm_struct *mm)
 	tsk->mm = mm;
 	tsk->active_mm = mm;
 	activate_mm(active_mm, mm);
+	tsk->mm->vmacache_seqnum = 0;
+	vmacache_flush(tsk);
 	task_unlock(tsk);
 	if (old_mm) {
 		up_read(&old_mm->mmap_sem);

commit 69369a7003735d0d8ef22097e27a55a8bad9557a
Author: Josh Triplett <josh@joshtriplett.org>
Date:   Thu Apr 3 14:48:27 2014 -0700

    fs, kernel: permit disabling the uselib syscall
    
    uselib hasn't been used since libc5; glibc does not use it.  Support
    turning it off.
    
    When disabled, also omit the load_elf_library implementation from
    binfmt_elf.c, which only uselib invokes.
    
    bloat-o-meter:
    add/remove: 0/4 grow/shrink: 0/1 up/down: 0/-785 (-785)
    function                                     old     new   delta
    padzero                                       39      36      -3
    uselib_flags                                  20       -     -20
    sys_uselib                                   168       -    -168
    SyS_uselib                                   168       -    -168
    load_elf_library                             426       -    -426
    
    The new CONFIG_USELIB defaults to `y'.
    
    Signed-off-by: Josh Triplett <josh@joshtriplett.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4f59402fdda5..25dfeba6d55f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -97,6 +97,7 @@ static inline void put_binfmt(struct linux_binfmt * fmt)
 	module_put(fmt->module);
 }
 
+#ifdef CONFIG_USELIB
 /*
  * Note that a shared library must be both readable and executable due to
  * security reasons.
@@ -156,6 +157,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 out:
   	return error;
 }
+#endif /* #ifdef CONFIG_USELIB */
 
 #ifdef CONFIG_MMU
 /*

commit ec69557982563c97b3a7d68dd271be5105b83869
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Feb 4 19:08:21 2014 -0500

    read_code(): go through vfs_read() instead of calling the method directly
    
    ... and don't skip on sanity checks.  It's *not* a hot path, TYVM
    (a couple of calls per a.out execve(), for pity sake) and headers of
    random a.out binary are not to be trusted.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 3d78fccdd723..4cc94534ed5b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -810,7 +810,7 @@ EXPORT_SYMBOL(kernel_read);
 
 ssize_t read_code(struct file *file, unsigned long addr, loff_t pos, size_t len)
 {
-	ssize_t res = file->f_op->read(file, (void __user *)addr, len, &pos);
+	ssize_t res = vfs_read(file, (void __user *)addr, len, &pos);
 	if (res > 0)
 		flush_icache_range(addr, addr + len);
 	return res;

commit 625b1d7e812d55df8d42253a134002c006de7468
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Mar 4 10:53:50 2014 +0100

    fs/compat: convert to COMPAT_SYSCALL_DEFINE
    
    Convert all compat system call functions where all parameter types
    have a size of four or less than four bytes, or are pointer types
    to COMPAT_SYSCALL_DEFINE.
    The implicit casts within COMPAT_SYSCALL_DEFINE will perform proper
    zero and sign extension to 64 bit of all parameters if needed.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/fs/exec.c b/fs/exec.c
index 3d78fccdd723..4f59402fdda5 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1619,9 +1619,9 @@ SYSCALL_DEFINE3(execve,
 	return do_execve(getname(filename), argv, envp);
 }
 #ifdef CONFIG_COMPAT
-asmlinkage long compat_sys_execve(const char __user * filename,
-	const compat_uptr_t __user * argv,
-	const compat_uptr_t __user * envp)
+COMPAT_SYSCALL_DEFINE3(execve, const char __user *, filename,
+	const compat_uptr_t __user *, argv,
+	const compat_uptr_t __user *, envp)
 {
 	return compat_do_execve(getname(filename), argv, envp);
 }

commit c4ad8f98bef77c7356aa6a9ad9188a6acc6b849d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Feb 5 12:54:53 2014 -0800

    execve: use 'struct filename *' for executable name passing
    
    This changes 'do_execve()' to get the executable name as a 'struct
    filename', and to free it when it is done.  This is what the normal
    users want, and it simplifies and streamlines their error handling.
    
    The controlled lifetime of the executable name also fixes a
    use-after-free problem with the trace_sched_process_exec tracepoint: the
    lifetime of the passed-in string for kernel users was not at all
    obvious, and the user-mode helper code used UMH_WAIT_EXEC to serialize
    the pathname allocation lifetime with the execve() having finished,
    which in turn meant that the trace point that happened after
    mm_release() of the old process VM ended up using already free'd memory.
    
    To solve the kernel string lifetime issue, this simply introduces
    "getname_kernel()" that works like the normal user-space getname()
    function, except with the source coming from kernel memory.
    
    As Oleg points out, this also means that we could drop the tcomm[] array
    from 'struct linux_binprm', since the pathname lifetime now covers
    setup_new_exec().  That would be a separate cleanup.
    
    Reported-by: Igor Zhbanov <i.zhbanov@samsung.com>
    Tested-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e1529b4c79b1..3d78fccdd723 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -748,11 +748,10 @@ EXPORT_SYMBOL(setup_arg_pages);
 
 #endif /* CONFIG_MMU */
 
-struct file *open_exec(const char *name)
+static struct file *do_open_exec(struct filename *name)
 {
 	struct file *file;
 	int err;
-	struct filename tmp = { .name = name };
 	static const struct open_flags open_exec_flags = {
 		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
 		.acc_mode = MAY_EXEC | MAY_OPEN,
@@ -760,7 +759,7 @@ struct file *open_exec(const char *name)
 		.lookup_flags = LOOKUP_FOLLOW,
 	};
 
-	file = do_filp_open(AT_FDCWD, &tmp, &open_exec_flags);
+	file = do_filp_open(AT_FDCWD, name, &open_exec_flags);
 	if (IS_ERR(file))
 		goto out;
 
@@ -784,6 +783,12 @@ struct file *open_exec(const char *name)
 	fput(file);
 	return ERR_PTR(err);
 }
+
+struct file *open_exec(const char *name)
+{
+	struct filename tmp = { .name = name };
+	return do_open_exec(&tmp);
+}
 EXPORT_SYMBOL(open_exec);
 
 int kernel_read(struct file *file, loff_t offset,
@@ -1162,7 +1167,7 @@ int prepare_bprm_creds(struct linux_binprm *bprm)
 	return -ENOMEM;
 }
 
-void free_bprm(struct linux_binprm *bprm)
+static void free_bprm(struct linux_binprm *bprm)
 {
 	free_arg_pages(bprm);
 	if (bprm->cred) {
@@ -1432,7 +1437,7 @@ static int exec_binprm(struct linux_binprm *bprm)
 /*
  * sys_execve() executes a new program.
  */
-static int do_execve_common(const char *filename,
+static int do_execve_common(struct filename *filename,
 				struct user_arg_ptr argv,
 				struct user_arg_ptr envp)
 {
@@ -1441,6 +1446,9 @@ static int do_execve_common(const char *filename,
 	struct files_struct *displaced;
 	int retval;
 
+	if (IS_ERR(filename))
+		return PTR_ERR(filename);
+
 	/*
 	 * We move the actual failure in case of RLIMIT_NPROC excess from
 	 * set*uid() to execve() because too many poorly written programs
@@ -1473,7 +1481,7 @@ static int do_execve_common(const char *filename,
 	check_unsafe_exec(bprm);
 	current->in_execve = 1;
 
-	file = open_exec(filename);
+	file = do_open_exec(filename);
 	retval = PTR_ERR(file);
 	if (IS_ERR(file))
 		goto out_unmark;
@@ -1481,8 +1489,7 @@ static int do_execve_common(const char *filename,
 	sched_exec();
 
 	bprm->file = file;
-	bprm->filename = filename;
-	bprm->interp = filename;
+	bprm->filename = bprm->interp = filename->name;
 
 	retval = bprm_mm_init(bprm);
 	if (retval)
@@ -1523,6 +1530,7 @@ static int do_execve_common(const char *filename,
 	acct_update_integrals(current);
 	task_numa_free(current);
 	free_bprm(bprm);
+	putname(filename);
 	if (displaced)
 		put_files_struct(displaced);
 	return retval;
@@ -1544,10 +1552,11 @@ static int do_execve_common(const char *filename,
 	if (displaced)
 		reset_files_struct(displaced);
 out_ret:
+	putname(filename);
 	return retval;
 }
 
-int do_execve(const char *filename,
+int do_execve(struct filename *filename,
 	const char __user *const __user *__argv,
 	const char __user *const __user *__envp)
 {
@@ -1557,7 +1566,7 @@ int do_execve(const char *filename,
 }
 
 #ifdef CONFIG_COMPAT
-static int compat_do_execve(const char *filename,
+static int compat_do_execve(struct filename *filename,
 	const compat_uptr_t __user *__argv,
 	const compat_uptr_t __user *__envp)
 {
@@ -1607,25 +1616,13 @@ SYSCALL_DEFINE3(execve,
 		const char __user *const __user *, argv,
 		const char __user *const __user *, envp)
 {
-	struct filename *path = getname(filename);
-	int error = PTR_ERR(path);
-	if (!IS_ERR(path)) {
-		error = do_execve(path->name, argv, envp);
-		putname(path);
-	}
-	return error;
+	return do_execve(getname(filename), argv, envp);
 }
 #ifdef CONFIG_COMPAT
 asmlinkage long compat_sys_execve(const char __user * filename,
 	const compat_uptr_t __user * argv,
 	const compat_uptr_t __user * envp)
 {
-	struct filename *path = getname(filename);
-	int error = PTR_ERR(path);
-	if (!IS_ERR(path)) {
-		error = compat_do_execve(path->name, argv, envp);
-		putname(path);
-	}
-	return error;
+	return compat_do_execve(getname(filename), argv, envp);
 }
 #endif

commit 3b96d7db3b6dc99d207bca50037274d22e48dea5
Author: Richard Weinberger <richard@nod.at>
Date:   Thu Jan 23 15:55:58 2014 -0800

    fs/exec.c: call arch_pick_mmap_layout() only once
    
    Currently both setup_new_exec() and flush_old_exec() issue a call to
    arch_pick_mmap_layout().  As setup_new_exec() and flush_old_exec() are
    always called pairwise arch_pick_mmap_layout() is called twice.
    
    This patch removes one call from setup_new_exec() to have it only called
    once.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Tested-by: Pat Erley <pat-lkml@erley.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 44218a7267b2..e1529b4c79b1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -842,7 +842,6 @@ static int exec_mmap(struct mm_struct *mm)
 	tsk->active_mm = mm;
 	activate_mm(active_mm, mm);
 	task_unlock(tsk);
-	arch_pick_mmap_layout(mm);
 	if (old_mm) {
 		up_read(&old_mm->mmap_sem);
 		BUG_ON(active_mm != old_mm);

commit b88fae644e5e3922251a4b242f435f5e3b49c381
Author: Zhang Yi <zhang.yi20@zte.com.cn>
Date:   Thu Jan 23 15:55:57 2014 -0800

    exec: avoid propagating PF_NO_SETAFFINITY into userspace child
    
    Userspace process doesn't want the PF_NO_SETAFFINITY, but its parent may be
    a kernel worker thread which has PF_NO_SETAFFINITY set, and this worker thread
    can do kernel_thread() to create the child.
    Clearing this flag in usersapce child to enable its migrating capability.
    
    Signed-off-by: Zhang Yi <zhang.yi20@zte.com.cn>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 493b102a27c1..44218a7267b2 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1087,8 +1087,8 @@ int flush_old_exec(struct linux_binprm * bprm)
 	bprm->mm = NULL;		/* We're using it now */
 
 	set_fs(USER_DS);
-	current->flags &=
-		~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD | PF_NOFREEZE);
+	current->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD |
+					PF_NOFREEZE | PF_NO_SETAFFINITY);
 	flush_thread();
 	current->personality &= ~bprm->per_clear;
 

commit 98611e4e6a2b4a03fd2d4750cce8e4455a995c8d
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 23 15:55:52 2014 -0800

    exec: kill task_struct->did_exec
    
    We can kill either task->did_exec or PF_FORKNOEXEC, they are mutually
    exclusive.  The patch kills ->did_exec because it has a single user.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index f860866e04ba..493b102a27c1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1424,7 +1424,6 @@ static int exec_binprm(struct linux_binprm *bprm)
 		audit_bprm(bprm);
 		trace_sched_process_exec(current, old_pid, bprm);
 		ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
-		current->did_exec = 1;
 		proc_exec_connector(current);
 	}
 

commit 63e46b95e9eae1161832bf45cb40bbad37bfb182
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 23 15:55:51 2014 -0800

    exec: move the final allow_write_access/fput into free_bprm()
    
    Both success/failure paths cleanup bprm->file, we can move this
    code into free_bprm() to simlify and cleanup this logic.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 389fe7b0ba14..f860866e04ba 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1138,9 +1138,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 
 	/* An exec changes our domain. We are no longer part of the thread
 	   group */
-
 	current->self_exec_id++;
-			
 	flush_signal_handlers(current, 0);
 	do_close_on_exec(current->files);
 }
@@ -1172,6 +1170,10 @@ void free_bprm(struct linux_binprm *bprm)
 		mutex_unlock(&current->signal->cred_guard_mutex);
 		abort_creds(bprm->cred);
 	}
+	if (bprm->file) {
+		allow_write_access(bprm->file);
+		fput(bprm->file);
+	}
 	/* If a binfmt changed the interp, free it. */
 	if (bprm->interp != bprm->filename)
 		kfree(bprm->interp);
@@ -1424,12 +1426,6 @@ static int exec_binprm(struct linux_binprm *bprm)
 		ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
 		current->did_exec = 1;
 		proc_exec_connector(current);
-
-		if (bprm->file) {
-			allow_write_access(bprm->file);
-			fput(bprm->file);
-			bprm->file = NULL; /* to catch use-after-free */
-		}
 	}
 
 	return ret;
@@ -1492,7 +1488,7 @@ static int do_execve_common(const char *filename,
 
 	retval = bprm_mm_init(bprm);
 	if (retval)
-		goto out_file;
+		goto out_unmark;
 
 	bprm->argc = count(argv, MAX_ARG_STRINGS);
 	if ((retval = bprm->argc) < 0)
@@ -1539,12 +1535,6 @@ static int do_execve_common(const char *filename,
 		mmput(bprm->mm);
 	}
 
-out_file:
-	if (bprm->file) {
-		allow_write_access(bprm->file);
-		fput(bprm->file);
-	}
-
 out_unmark:
 	current->fs->in_exec = 0;
 	current->in_execve = 0;

commit 9e00cdb091b008cb3c78192651180896de412a63
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 23 15:55:50 2014 -0800

    exec:check_unsafe_exec: kill the dead -EAGAIN and clear_in_exec logic
    
    fs_struct->in_exec == T means that this ->fs is used by a single process
    (thread group), and one of the treads does do_execve().
    
    To avoid the mt-exec races this code has the following complications:
    
            1. check_unsafe_exec() returns -EBUSY if ->in_exec was
               already set by another thread.
    
            2. do_execve_common() records "clear_in_exec" to ensure
               that the error path can only clear ->in_exec if it was
               set by current.
    
    However, after 9b1bf12d5d51 "signals: move cred_guard_mutex from
    task_struct to signal_struct" we do not need these complications:
    
            1. We can't race with our sub-thread, this is called under
               per-process ->cred_guard_mutex. And we can't race with
               another CLONE_FS task, we already checked that this fs
               is not shared.
    
               We can remove the  dead -EAGAIN logic.
    
            2. "out_unmark:" in do_execve_common() is either called
               under ->cred_guard_mutex, or after de_thread() which
               kills other threads, so we can't race with sub-thread
               which could set ->in_exec. And if ->fs is shared with
               another process ->in_exec should be false anyway.
    
               We can clear in_exec unconditionally.
    
    This also means that check_unsafe_exec() can be void.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 81ae6212187a..389fe7b0ba14 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1223,11 +1223,10 @@ EXPORT_SYMBOL(install_exec_creds);
  * - the caller must hold ->cred_guard_mutex to protect against
  *   PTRACE_ATTACH
  */
-static int check_unsafe_exec(struct linux_binprm *bprm)
+static void check_unsafe_exec(struct linux_binprm *bprm)
 {
 	struct task_struct *p = current, *t;
 	unsigned n_fs;
-	int res = 0;
 
 	if (p->ptrace) {
 		if (p->ptrace & PT_PTRACE_CAP)
@@ -1253,22 +1252,15 @@ static int check_unsafe_exec(struct linux_binprm *bprm)
 	}
 	rcu_read_unlock();
 
-	if (p->fs->users > n_fs) {
+	if (p->fs->users > n_fs)
 		bprm->unsafe |= LSM_UNSAFE_SHARE;
-	} else {
-		res = -EAGAIN;
-		if (!p->fs->in_exec) {
-			p->fs->in_exec = 1;
-			res = 1;
-		}
-	}
+	else
+		p->fs->in_exec = 1;
 	spin_unlock(&p->fs->lock);
-
-	return res;
 }
 
-/* 
- * Fill the binprm structure from the inode. 
+/*
+ * Fill the binprm structure from the inode.
  * Check permissions, then read the first 128 (BINPRM_BUF_SIZE) bytes
  *
  * This may be called multiple times for binary chains (scripts for example).
@@ -1453,7 +1445,6 @@ static int do_execve_common(const char *filename,
 	struct linux_binprm *bprm;
 	struct file *file;
 	struct files_struct *displaced;
-	bool clear_in_exec;
 	int retval;
 
 	/*
@@ -1485,10 +1476,7 @@ static int do_execve_common(const char *filename,
 	if (retval)
 		goto out_free;
 
-	retval = check_unsafe_exec(bprm);
-	if (retval < 0)
-		goto out_free;
-	clear_in_exec = retval;
+	check_unsafe_exec(bprm);
 	current->in_execve = 1;
 
 	file = open_exec(filename);
@@ -1558,8 +1546,7 @@ static int do_execve_common(const char *filename,
 	}
 
 out_unmark:
-	if (clear_in_exec)
-		current->fs->in_exec = 0;
+	current->fs->in_exec = 0;
 	current->in_execve = 0;
 
 out_free:

commit 83f62a2eacb1d6945c78523f20e0c34b5d94913c
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 23 15:55:49 2014 -0800

    exec:check_unsafe_exec: use while_each_thread() rather than next_thread()
    
    next_thread() should be avoided, change check_unsafe_exec() to use
    while_each_thread().
    
    Nobody except signal->curr_target actually needs next_thread-like code,
    and we need to change (fix) this interface.  This particular code is fine,
    p == current.  But in general the code like this can loop forever if p
    exits and next_thread(t) can't reach the unhashed thread.
    
    This also saves 32 bytes.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9cbad5b0187e..81ae6212187a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1243,10 +1243,11 @@ static int check_unsafe_exec(struct linux_binprm *bprm)
 	if (current->no_new_privs)
 		bprm->unsafe |= LSM_UNSAFE_NO_NEW_PRIVS;
 
+	t = p;
 	n_fs = 1;
 	spin_lock(&p->fs->lock);
 	rcu_read_lock();
-	for (t = next_thread(p); t != p; t = next_thread(t)) {
+	while_each_thread(p, t) {
 		if (t->fs == p->fs)
 			n_fs++;
 	}

commit 942be3875a1931c379bbc37053829dd6847e0f3f
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 23 15:55:34 2014 -0800

    coredump: make __get_dumpable/get_dumpable inline, kill fs/coredump.h
    
    1. Remove fs/coredump.h. It is not clear why do we need it,
       it only declares __get_dumpable(), signal.c includes it
       for no reason.
    
    2. Now that get_dumpable() and __get_dumpable() are really
       trivial make them inline in linux/sched.h.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Alex Kelly <alex.page.kelly@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Petr Matousek <pmatouse@redhat.com>
    Cc: Vasily Kulikov <segoon@openwall.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index f798da06abac..9cbad5b0187e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -62,7 +62,6 @@
 
 #include <trace/events/task.h>
 #include "internal.h"
-#include "coredump.h"
 
 #include <trace/events/sched.h>
 
@@ -1609,7 +1608,6 @@ void set_binfmt(struct linux_binfmt *new)
 	if (new)
 		__module_get(new->module);
 }
-
 EXPORT_SYMBOL(set_binfmt);
 
 /*
@@ -1628,22 +1626,6 @@ void set_dumpable(struct mm_struct *mm, int value)
 	} while (cmpxchg(&mm->flags, old, new) != old);
 }
 
-int __get_dumpable(unsigned long mm_flags)
-{
-	return mm_flags & MMF_DUMPABLE_MASK;
-}
-
-/*
- * This returns the actual value of the suid_dumpable flag. For things
- * that are using this for checking for privilege transitions, it must
- * test against SUID_DUMP_USER rather than treating it as a boolean
- * value.
- */
-int get_dumpable(struct mm_struct *mm)
-{
-	return __get_dumpable(mm->flags);
-}
-
 SYSCALL_DEFINE3(execve,
 		const char __user *, filename,
 		const char __user *const __user *, argv,

commit 7288e1187ba935996232246916418c64bb88da30
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 23 15:55:32 2014 -0800

    coredump: kill MMF_DUMPABLE and MMF_DUMP_SECURELY
    
    Nobody actually needs MMF_DUMPABLE/MMF_DUMP_SECURELY, they are only used
    to enforce the encoding of SUID_DUMP_* enum in mm->flags &
    MMF_DUMPABLE_MASK.
    
    Now that set_dumpable() updates both bits atomically we can kill them and
    simply store the value "as is" in 2 lower bits.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Alex Kelly <alex.page.kelly@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Petr Matousek <pmatouse@redhat.com>
    Cc: Vasily Kulikov <segoon@openwall.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index f039386499db..f798da06abac 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1613,33 +1613,24 @@ void set_binfmt(struct linux_binfmt *new)
 EXPORT_SYMBOL(set_binfmt);
 
 /*
- * set_dumpable converts traditional three-value dumpable to two flags and
- * stores them into mm->flags.
+ * set_dumpable stores three-value SUID_DUMP_* into mm->flags.
  */
 void set_dumpable(struct mm_struct *mm, int value)
 {
 	unsigned long old, new;
 
+	if (WARN_ON((unsigned)value > SUID_DUMP_ROOT))
+		return;
+
 	do {
 		old = ACCESS_ONCE(mm->flags);
-		new = old & ~MMF_DUMPABLE_MASK;
-
-		switch (value) {
-		case SUID_DUMP_ROOT:
-			new |= (1 << MMF_DUMP_SECURELY);
-		case SUID_DUMP_USER:
-			new |= (1<< MMF_DUMPABLE);
-		}
-
+		new = (old & ~MMF_DUMPABLE_MASK) | value;
 	} while (cmpxchg(&mm->flags, old, new) != old);
 }
 
 int __get_dumpable(unsigned long mm_flags)
 {
-	int ret;
-
-	ret = mm_flags & MMF_DUMPABLE_MASK;
-	return (ret > SUID_DUMP_USER) ? SUID_DUMP_ROOT : ret;
+	return mm_flags & MMF_DUMPABLE_MASK;
 }
 
 /*

commit abacd2fe3ca10b3ade57f3634053241a660002c2
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 23 15:55:31 2014 -0800

    coredump: set_dumpable: fix the theoretical race with itself
    
    set_dumpable() updates MMF_DUMPABLE_MASK in a non-trivial way to ensure
    that get_dumpable() can't observe the intermediate state, but this all
    can't help if multiple threads call set_dumpable() at the same time.
    
    And in theory commit_creds()->set_dumpable(SUID_DUMP_ROOT) racing with
    sys_prctl()->set_dumpable(SUID_DUMP_DISABLE) can result in SUID_DUMP_USER.
    
    Change this code to update both bits atomically via cmpxchg().
    
    Note: this assumes that it is safe to mix bitops and cmpxchg.  IOW, if,
    say, an architecture implements cmpxchg() using the locking (like
    arch/parisc/lib/bitops.c does), then it should use the same locks for
    set_bit/etc.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Alex Kelly <alex.page.kelly@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Petr Matousek <pmatouse@redhat.com>
    Cc: Vasily Kulikov <segoon@openwall.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7ea097f6b341..f039386499db 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1614,43 +1614,24 @@ EXPORT_SYMBOL(set_binfmt);
 
 /*
  * set_dumpable converts traditional three-value dumpable to two flags and
- * stores them into mm->flags.  It modifies lower two bits of mm->flags, but
- * these bits are not changed atomically.  So get_dumpable can observe the
- * intermediate state.  To avoid doing unexpected behavior, get get_dumpable
- * return either old dumpable or new one by paying attention to the order of
- * modifying the bits.
- *
- * dumpable |   mm->flags (binary)
- * old  new | initial interim  final
- * ---------+-----------------------
- *  0    1  |   00      01      01
- *  0    2  |   00      10(*)   11
- *  1    0  |   01      00      00
- *  1    2  |   01      11      11
- *  2    0  |   11      10(*)   00
- *  2    1  |   11      11      01
- *
- * (*) get_dumpable regards interim value of 10 as 11.
+ * stores them into mm->flags.
  */
 void set_dumpable(struct mm_struct *mm, int value)
 {
-	switch (value) {
-	case SUID_DUMP_DISABLE:
-		clear_bit(MMF_DUMPABLE, &mm->flags);
-		smp_wmb();
-		clear_bit(MMF_DUMP_SECURELY, &mm->flags);
-		break;
-	case SUID_DUMP_USER:
-		set_bit(MMF_DUMPABLE, &mm->flags);
-		smp_wmb();
-		clear_bit(MMF_DUMP_SECURELY, &mm->flags);
-		break;
-	case SUID_DUMP_ROOT:
-		set_bit(MMF_DUMP_SECURELY, &mm->flags);
-		smp_wmb();
-		set_bit(MMF_DUMPABLE, &mm->flags);
-		break;
-	}
+	unsigned long old, new;
+
+	do {
+		old = ACCESS_ONCE(mm->flags);
+		new = old & ~MMF_DUMPABLE_MASK;
+
+		switch (value) {
+		case SUID_DUMP_ROOT:
+			new |= (1 << MMF_DUMP_SECURELY);
+		case SUID_DUMP_USER:
+			new |= (1<< MMF_DUMPABLE);
+		}
+
+	} while (cmpxchg(&mm->flags, old, new) != old);
 }
 
 int __get_dumpable(unsigned long mm_flags)

commit 3eaded86ac3e7f00fb3eeb8162d89e9a34e42fb0
Merge: 527d1511310a 9175c9d2aed5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 21 19:18:14 2013 -0800

    Merge git://git.infradead.org/users/eparis/audit
    
    Pull audit updates from Eric Paris:
     "Nothing amazing.  Formatting, small bug fixes, couple of fixes where
      we didn't get records due to some old VFS changes, and a change to how
      we collect execve info..."
    
    Fixed conflict in fs/exec.c as per Eric and linux-next.
    
    * git://git.infradead.org/users/eparis/audit: (28 commits)
      audit: fix type of sessionid in audit_set_loginuid()
      audit: call audit_bprm() only once to add AUDIT_EXECVE information
      audit: move audit_aux_data_execve contents into audit_context union
      audit: remove unused envc member of audit_aux_data_execve
      audit: Kill the unused struct audit_aux_data_capset
      audit: do not reject all AUDIT_INODE filter types
      audit: suppress stock memalloc failure warnings since already managed
      audit: log the audit_names record type
      audit: add child record before the create to handle case where create fails
      audit: use given values in tty_audit enable api
      audit: use nlmsg_len() to get message payload length
      audit: use memset instead of trying to initialize field by field
      audit: fix info leak in AUDIT_GET requests
      audit: update AUDIT_INODE filter rule to comparator function
      audit: audit feature to set loginuid immutable
      audit: audit feature to only allow unsetting the loginuid
      audit: allow unsetting the loginuid (with priv)
      audit: remove CONFIG_AUDIT_LOGINUID_IMMUTABLE
      audit: loginuid functions coding style
      selinux: apply selinux checks on new audit message types
      ...

commit 5cbb3d216e2041700231bcfc383ee5f8b7fc8b74
Merge: 9bc9ccd7db1c 4e9b45a19241
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 13 15:45:43 2013 +0900

    Merge branch 'akpm' (patches from Andrew Morton)
    
    Merge first patch-bomb from Andrew Morton:
     "Quite a lot of other stuff is banked up awaiting further
      next->mainline merging, but this batch contains:
    
       - Lots of random misc patches
       - OCFS2
       - Most of MM
       - backlight updates
       - lib/ updates
       - printk updates
       - checkpatch updates
       - epoll tweaking
       - rtc updates
       - hfs
       - hfsplus
       - documentation
       - procfs
       - update gcov to gcc-4.7 format
       - IPC"
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (269 commits)
      ipc, msg: fix message length check for negative values
      ipc/util.c: remove unnecessary work pending test
      devpts: plug the memory leak in kill_sb
      ./Makefile: export initial ramdisk compression config option
      init/Kconfig: add option to disable kernel compression
      drivers: w1: make w1_slave::flags long to avoid memory corruption
      drivers/w1/masters/ds1wm.cuse dev_get_platdata()
      drivers/memstick/core/ms_block.c: fix unreachable state in h_msb_read_page()
      drivers/memstick/core/mspro_block.c: fix attributes array allocation
      drivers/pps/clients/pps-gpio.c: remove redundant of_match_ptr
      kernel/panic.c: reduce 1 byte usage for print tainted buffer
      gcov: reuse kbasename helper
      kernel/gcov/fs.c: use pr_warn()
      kernel/module.c: use pr_foo()
      gcov: compile specific gcov implementation based on gcc version
      gcov: add support for gcc 4.7 gcov format
      gcov: move gcov structs definitions to a gcc version specific file
      kernel/taskstats.c: return -ENOMEM when alloc memory fails in add_del_listener()
      kernel/taskstats.c: add nla_nest_cancel() for failure processing between nla_nest_start() and nla_nest_end()
      kernel/sysctl_binary.c: use scnprintf() instead of snprintf()
      ...

commit 9bc9ccd7db1c9f043f75380b5a5b94912046a60e
Merge: f0230294271f bdd353661844
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 13 15:34:18 2013 +0900

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs updates from Al Viro:
     "All kinds of stuff this time around; some more notable parts:
    
       - RCU'd vfsmounts handling
       - new primitives for coredump handling
       - files_lock is gone
       - Bruce's delegations handling series
       - exportfs fixes
    
      plus misc stuff all over the place"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (101 commits)
      ecryptfs: ->f_op is never NULL
      locks: break delegations on any attribute modification
      locks: break delegations on link
      locks: break delegations on rename
      locks: helper functions for delegation breaking
      locks: break delegations on unlink
      namei: minor vfs_unlink cleanup
      locks: implement delegations
      locks: introduce new FL_DELEG lock flag
      vfs: take i_mutex on renamed file
      vfs: rename I_MUTEX_QUOTA now that it's not used for quotas
      vfs: don't use PARENT/CHILD lock classes for non-directories
      vfs: pull ext4's double-i_mutex-locking into common code
      exportfs: fix quadratic behavior in filehandle lookup
      exportfs: better variable name
      exportfs: move most of reconnect_path to helper function
      exportfs: eliminate unused "noprogress" counter
      exportfs: stop retrying once we race with rename/remove
      exportfs: clear DISCONNECTED on all parents sooner
      exportfs: more detailed comment for path_reconnect
      ...

commit d049f74f2dbe71354d43d393ac3a188947811348
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Nov 12 15:11:17 2013 -0800

    exec/ptrace: fix get_dumpable() incorrect tests
    
    The get_dumpable() return value is not boolean.  Most users of the
    function actually want to be testing for non-SUID_DUMP_USER(1) rather than
    SUID_DUMP_DISABLE(0).  The SUID_DUMP_ROOT(2) is also considered a
    protected state.  Almost all places did this correctly, excepting the two
    places fixed in this patch.
    
    Wrong logic:
        if (dumpable == SUID_DUMP_DISABLE) { /* be protective */ }
            or
        if (dumpable == 0) { /* be protective */ }
            or
        if (!dumpable) { /* be protective */ }
    
    Correct logic:
        if (dumpable != SUID_DUMP_USER) { /* be protective */ }
            or
        if (dumpable != 1) { /* be protective */ }
    
    Without this patch, if the system had set the sysctl fs/suid_dumpable=2, a
    user was able to ptrace attach to processes that had dropped privileges to
    that user.  (This may have been partially mitigated if Yama was enabled.)
    
    The macros have been moved into the file that declares get/set_dumpable(),
    which means things like the ia64 code can see them too.
    
    CVE-2013-2929
    
    Reported-by: Vasily Kulikov <segoon@openwall.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2ea437e5acf4..12120620f040 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1669,6 +1669,12 @@ int __get_dumpable(unsigned long mm_flags)
 	return (ret > SUID_DUMP_USER) ? SUID_DUMP_ROOT : ret;
 }
 
+/*
+ * This returns the actual value of the suid_dumpable flag. For things
+ * that are using this for checking for privilege transitions, it must
+ * test against SUID_DUMP_USER rather than treating it as a boolean
+ * value.
+ */
 int get_dumpable(struct mm_struct *mm)
 {
 	return __get_dumpable(mm->flags);

commit 9410d228a4cf434305306746bb799fb7acdd8648
Author: Richard Guy Briggs <rgb@redhat.com>
Date:   Wed Oct 30 18:05:24 2013 -0400

    audit: call audit_bprm() only once to add AUDIT_EXECVE information
    
    Move the audit_bprm() call from search_binary_handler() to exec_binprm().  This
    allows us to get rid of the mm member of struct audit_aux_data_execve since
    bprm->mm will equal current->mm.
    
    This also mitigates the issue that ->argc could be modified by the
    load_binary() call in search_binary_handler().
    
    audit_bprm() was being called to add an AUDIT_EXECVE record to the audit
    context every time search_binary_handler() was recursively called.  Only one
    reference is necessary.
    
    Reported-by: Oleg Nesterov <onestero@redhat.com>
    Cc: Eric Paris <eparis@redhat.com>
    Signed-off-by: Richard Guy Briggs <rgb@redhat.com>
    Signed-off-by: Eric Paris <eparis@redhat.com>
    ---
    This patch is against 3.11, but was developed on Oleg's post-3.11 patches that
    introduce exec_binprm().

diff --git a/fs/exec.c b/fs/exec.c
index fd774c7cb483..c5c24f2fc44a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1383,10 +1383,6 @@ int search_binary_handler(struct linux_binprm *bprm)
 	if (retval)
 		return retval;
 
-	retval = audit_bprm(bprm);
-	if (retval)
-		return retval;
-
 	/* Need to fetch pid before load_binary changes it */
 	old_pid = current->pid;
 	rcu_read_lock();
@@ -1408,6 +1404,7 @@ int search_binary_handler(struct linux_binprm *bprm)
 			bprm->recursion_depth = depth;
 			if (retval >= 0) {
 				if (depth == 0) {
+					audit_bprm(bprm);
 					trace_sched_process_exec(current, old_pid, bprm);
 					ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
 				}

commit 72c2d53192004845cbc19cd8a30b3212a9288140
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Sep 22 16:27:52 2013 -0400

    file->f_op is never NULL...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 8875dd10ae7a..351440fbf1ee 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -106,6 +106,7 @@ static inline void put_binfmt(struct linux_binfmt * fmt)
  */
 SYSCALL_DEFINE1(uselib, const char __user *, library)
 {
+	struct linux_binfmt *fmt;
 	struct file *file;
 	struct filename *tmp = getname(library);
 	int error = PTR_ERR(tmp);
@@ -136,24 +137,21 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 	fsnotify_open(file);
 
 	error = -ENOEXEC;
-	if(file->f_op) {
-		struct linux_binfmt * fmt;
 
-		read_lock(&binfmt_lock);
-		list_for_each_entry(fmt, &formats, lh) {
-			if (!fmt->load_shlib)
-				continue;
-			if (!try_module_get(fmt->module))
-				continue;
-			read_unlock(&binfmt_lock);
-			error = fmt->load_shlib(file);
-			read_lock(&binfmt_lock);
-			put_binfmt(fmt);
-			if (error != -ENOEXEC)
-				break;
-		}
+	read_lock(&binfmt_lock);
+	list_for_each_entry(fmt, &formats, lh) {
+		if (!fmt->load_shlib)
+			continue;
+		if (!try_module_get(fmt->module))
+			continue;
 		read_unlock(&binfmt_lock);
+		error = fmt->load_shlib(file);
+		read_lock(&binfmt_lock);
+		put_binfmt(fmt);
+		if (error != -ENOEXEC)
+			break;
 	}
+	read_unlock(&binfmt_lock);
 exit:
 	fput(file);
 out:
@@ -1277,13 +1275,10 @@ static int check_unsafe_exec(struct linux_binprm *bprm)
  */
 int prepare_binprm(struct linux_binprm *bprm)
 {
-	umode_t mode;
-	struct inode * inode = file_inode(bprm->file);
+	struct inode *inode = file_inode(bprm->file);
+	umode_t mode = inode->i_mode;
 	int retval;
 
-	mode = inode->i_mode;
-	if (bprm->file->f_op == NULL)
-		return -EACCES;
 
 	/* clear any previous set[ug]id data from a previous binary */
 	bprm->cred->euid = current_euid();

commit 82727018b0d33d188e9916bcf76f18387484cb04
Author: Rik van Riel <riel@redhat.com>
Date:   Mon Oct 7 11:29:28 2013 +0100

    sched/numa: Call task_numa_free() from do_execve()
    
    It is possible for a task in a numa group to call exec, and
    have the new (unrelated) executable inherit the numa group
    association from its former self.
    
    This has the potential to break numa grouping, and is trivial
    to fix.
    
    Signed-off-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1381141781-10992-51-git-send-email-mgorman@suse.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 8875dd10ae7a..2ea437e5acf4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1547,6 +1547,7 @@ static int do_execve_common(const char *filename,
 	current->fs->in_exec = 0;
 	current->in_execve = 0;
 	acct_update_integrals(current);
+	task_numa_free(current);
 	free_bprm(bprm);
 	if (displaced)
 		put_files_struct(displaced);

commit 6b3c538f5b2cfc53cb6803ec5001bbcf8f18a98e
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:46 2013 -0700

    exec: cleanup the error handling in search_binary_handler()
    
    The error hanling and ret-from-loop look confusing and inconsistent.
    
    - "retval >= 0" simply returns
    
    - "!bprm->file" returns too but with read_unlock() because
       binfmt_lock was already re-acquired
    
    - "retval != -ENOEXEC || bprm->mm == NULL" does "break" and
      relies on the same check after the main loop
    
    Consolidate these checks into a single if/return statement.
    
    need_retry still checks "retval == -ENOEXEC", but this and -ENOENT before
    the main loop are not needed.  This is only for pathological and
    impossible list_empty(&formats) case.
    
    It is not clear why do we check "bprm->mm == NULL", probably this
    should be removed.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 635b586de336..8875dd10ae7a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1399,22 +1399,17 @@ int search_binary_handler(struct linux_binprm *bprm)
 		bprm->recursion_depth++;
 		retval = fmt->load_binary(bprm);
 		bprm->recursion_depth--;
-		if (retval >= 0) {
+		if (retval >= 0 || retval != -ENOEXEC ||
+		    bprm->mm == NULL || bprm->file == NULL) {
 			put_binfmt(fmt);
 			return retval;
 		}
 		read_lock(&binfmt_lock);
 		put_binfmt(fmt);
-		if (retval != -ENOEXEC || bprm->mm == NULL)
-			break;
-		if (!bprm->file) {
-			read_unlock(&binfmt_lock);
-			return retval;
-		}
 	}
 	read_unlock(&binfmt_lock);
 
-	if (need_retry && retval == -ENOEXEC && bprm->mm) {
+	if (need_retry && retval == -ENOEXEC) {
 		if (printable(bprm->buf[0]) && printable(bprm->buf[1]) &&
 		    printable(bprm->buf[2]) && printable(bprm->buf[3]))
 			return retval;

commit 4e0621a07ea58a0dc15859be3b743bdeb194a51b
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:45 2013 -0700

    exec: don't retry if request_module() fails
    
    A separate one-liner for better documentation.
    
    It doesn't make sense to retry if request_module() fails to exec
    /sbin/modprobe, add the additional "request_module() < 0" check.
    
    However, this logic still doesn't look exactly right:
    
    1. It would be better to check "request_module() != 0", the user
       space modprobe process should report the correct exit code.
       But I didn't dare to add the user-visible change.
    
    2. The whole ENOEXEC logic looks suboptimal. Suppose that we try
       to exec a "#!path-to-unsupported-binary" script. In this case
       request_module() + "retry" will be done twice: first by the
       "depth == 1" code, and then again by the "depth == 0" caller
       which doesn't make sense.
    
    3. And note that in the case above bprm->buf was already changed
       by load_script()->prepare_binprm(), so this looks even more
       ugly.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ba357e6aea98..635b586de336 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1418,7 +1418,8 @@ int search_binary_handler(struct linux_binprm *bprm)
 		if (printable(bprm->buf[0]) && printable(bprm->buf[1]) &&
 		    printable(bprm->buf[2]) && printable(bprm->buf[3]))
 			return retval;
-		request_module("binfmt-%04x", *(ushort *)(bprm->buf + 2));
+		if (request_module("binfmt-%04x", *(ushort *)(bprm->buf + 2)) < 0)
+			return retval;
 		need_retry = false;
 		goto retry;
 	}

commit cb7b6b1cbc20a970c7124efae1c2478155604b54
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:44 2013 -0700

    exec: cleanup the CONFIG_MODULES logic
    
    search_binary_handler() uses "for (try=0; try<2; try++)" to avoid "goto"
    but the code looks too complicated and horrible imho.  We still need to
    check "try == 0" before request_module() and add the additional "break"
    for !CONFIG_MODULES case.
    
    Kill this loop and use a simple "bool need_retry" + "goto retry".  The
    code looks much simpler and we do not even need ifdef's, gcc can optimize
    out the "if (need_retry)" block if !IS_ENABLED().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7b92fbfa63aa..ba357e6aea98 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1367,13 +1367,15 @@ int remove_arg_zero(struct linux_binprm *bprm)
 }
 EXPORT_SYMBOL(remove_arg_zero);
 
+#define printable(c) (((c)=='\t') || ((c)=='\n') || (0x20<=(c) && (c)<=0x7e))
 /*
  * cycle the list of binary formats handler, until one recognizes the image
  */
 int search_binary_handler(struct linux_binprm *bprm)
 {
-	int try, retval;
+	bool need_retry = IS_ENABLED(CONFIG_MODULES);
 	struct linux_binfmt *fmt;
+	int retval;
 
 	/* This allows 4 levels of binfmt rewrites before failing hard. */
 	if (bprm->recursion_depth > 5)
@@ -1388,47 +1390,39 @@ int search_binary_handler(struct linux_binprm *bprm)
 		return retval;
 
 	retval = -ENOENT;
-	for (try=0; try<2; try++) {
-		read_lock(&binfmt_lock);
-		list_for_each_entry(fmt, &formats, lh) {
-			if (!try_module_get(fmt->module))
-				continue;
-			read_unlock(&binfmt_lock);
-			bprm->recursion_depth++;
-			retval = fmt->load_binary(bprm);
-			bprm->recursion_depth--;
-			if (retval >= 0) {
-				put_binfmt(fmt);
-				return retval;
-			}
-			read_lock(&binfmt_lock);
+ retry:
+	read_lock(&binfmt_lock);
+	list_for_each_entry(fmt, &formats, lh) {
+		if (!try_module_get(fmt->module))
+			continue;
+		read_unlock(&binfmt_lock);
+		bprm->recursion_depth++;
+		retval = fmt->load_binary(bprm);
+		bprm->recursion_depth--;
+		if (retval >= 0) {
 			put_binfmt(fmt);
-			if (retval != -ENOEXEC || bprm->mm == NULL)
-				break;
-			if (!bprm->file) {
-				read_unlock(&binfmt_lock);
-				return retval;
-			}
+			return retval;
 		}
-		read_unlock(&binfmt_lock);
-#ifdef CONFIG_MODULES
-		if (retval != -ENOEXEC || bprm->mm == NULL) {
+		read_lock(&binfmt_lock);
+		put_binfmt(fmt);
+		if (retval != -ENOEXEC || bprm->mm == NULL)
 			break;
-		} else {
-#define printable(c) (((c)=='\t') || ((c)=='\n') || (0x20<=(c) && (c)<=0x7e))
-			if (printable(bprm->buf[0]) &&
-			    printable(bprm->buf[1]) &&
-			    printable(bprm->buf[2]) &&
-			    printable(bprm->buf[3]))
-				break; /* -ENOEXEC */
-			if (try)
-				break; /* -ENOEXEC */
-			request_module("binfmt-%04x", *(unsigned short *)(&bprm->buf[2]));
+		if (!bprm->file) {
+			read_unlock(&binfmt_lock);
+			return retval;
 		}
-#else
-		break;
-#endif
 	}
+	read_unlock(&binfmt_lock);
+
+	if (need_retry && retval == -ENOEXEC && bprm->mm) {
+		if (printable(bprm->buf[0]) && printable(bprm->buf[1]) &&
+		    printable(bprm->buf[2]) && printable(bprm->buf[3]))
+			return retval;
+		request_module("binfmt-%04x", *(ushort *)(bprm->buf + 2));
+		need_retry = false;
+		goto retry;
+	}
+
 	return retval;
 }
 EXPORT_SYMBOL(search_binary_handler);

commit 92eaa565add62d56b90987f58ea9feafc5a7c183
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:42 2013 -0700

    exec: kill ->load_binary != NULL check in search_binary_handler()
    
    search_binary_handler() checks ->load_binary != NULL for no reason, this
    method should be always defined.  Turn this check into WARN_ON() and move
    it into __register_binfmt().
    
    Also, kill the function pointer.  The current code looks confusing, as if
    ->load_binary can go away after read_unlock(&binfmt_lock).  But we rely on
    module_get(fmt->module), this fmt can't be changed or unregistered,
    otherwise this code is buggy anyway.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a4cfd1d725e0..7b92fbfa63aa 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -74,6 +74,8 @@ static DEFINE_RWLOCK(binfmt_lock);
 void __register_binfmt(struct linux_binfmt * fmt, int insert)
 {
 	BUG_ON(!fmt);
+	if (WARN_ON(!fmt->load_binary))
+		return;
 	write_lock(&binfmt_lock);
 	insert ? list_add(&fmt->lh, &formats) :
 		 list_add_tail(&fmt->lh, &formats);
@@ -1389,14 +1391,11 @@ int search_binary_handler(struct linux_binprm *bprm)
 	for (try=0; try<2; try++) {
 		read_lock(&binfmt_lock);
 		list_for_each_entry(fmt, &formats, lh) {
-			int (*fn)(struct linux_binprm *) = fmt->load_binary;
-			if (!fn)
-				continue;
 			if (!try_module_get(fmt->module))
 				continue;
 			read_unlock(&binfmt_lock);
 			bprm->recursion_depth++;
-			retval = fn(bprm);
+			retval = fmt->load_binary(bprm);
 			bprm->recursion_depth--;
 			if (retval >= 0) {
 				put_binfmt(fmt);

commit 52f14282bb0c3d3e5ba2a9eaacb12ff37a033e7e
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:41 2013 -0700

    exec: move allow_write_access/fput to exec_binprm()
    
    When search_binary_handler() succeeds it does allow_write_access() and
    fput(), then it clears bprm->file to ensure the caller will not do the
    same.
    
    We can simply move this code to exec_binprm() which is called only once.
    In fact we could move this to free_bprm() and remove the same code in
    do_execve_common's error path.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index d51f7172832b..a4cfd1d725e0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1400,10 +1400,6 @@ int search_binary_handler(struct linux_binprm *bprm)
 			bprm->recursion_depth--;
 			if (retval >= 0) {
 				put_binfmt(fmt);
-				allow_write_access(bprm->file);
-				if (bprm->file)
-					fput(bprm->file);
-				bprm->file = NULL;
 				return retval;
 			}
 			read_lock(&binfmt_lock);
@@ -1455,6 +1451,12 @@ static int exec_binprm(struct linux_binprm *bprm)
 		ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
 		current->did_exec = 1;
 		proc_exec_connector(current);
+
+		if (bprm->file) {
+			allow_write_access(bprm->file);
+			fput(bprm->file);
+			bprm->file = NULL; /* to catch use-after-free */
+		}
 	}
 
 	return ret;

commit 9beb266f2d7e5362c5bb9f999255aa1af5318aef
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:40 2013 -0700

    exec: proc_exec_connector() should be called only once
    
    A separate one-liner with the minor fix.
    
    PROC_EVENT_EXEC reports the "exec" event, but this message is sent at
    least twice if search_binary_handler() is called by ->load_binary()
    recursively, say, load_script().
    
    Move it to exec_binprm(), this is "depth == 0" code too.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index b6e35ec818a2..d51f7172832b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1404,7 +1404,6 @@ int search_binary_handler(struct linux_binprm *bprm)
 				if (bprm->file)
 					fput(bprm->file);
 				bprm->file = NULL;
-				proc_exec_connector(current);
 				return retval;
 			}
 			read_lock(&binfmt_lock);
@@ -1455,6 +1454,7 @@ static int exec_binprm(struct linux_binprm *bprm)
 		trace_sched_process_exec(current, old_pid, bprm);
 		ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
 		current->did_exec = 1;
+		proc_exec_connector(current);
 	}
 
 	return ret;

commit 131b2f9f1214f338f0bf7c0d9760019f2b1d0c20
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:39 2013 -0700

    exec: kill "int depth" in search_binary_handler()
    
    Nobody except search_binary_handler() should touch ->recursion_depth, "int
    depth" buys nothing but complicates the code, kill it.
    
    Probably we should also kill "fn" and the !NULL check, ->load_binary
    should be always defined.  And it can not go away after read_unlock() or
    this code is buggy anyway.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4d95b4709ea0..b6e35ec818a2 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1370,12 +1370,11 @@ EXPORT_SYMBOL(remove_arg_zero);
  */
 int search_binary_handler(struct linux_binprm *bprm)
 {
-	unsigned int depth = bprm->recursion_depth;
-	int try,retval;
+	int try, retval;
 	struct linux_binfmt *fmt;
 
 	/* This allows 4 levels of binfmt rewrites before failing hard. */
-	if (depth > 5)
+	if (bprm->recursion_depth > 5)
 		return -ELOOP;
 
 	retval = security_bprm_check(bprm);
@@ -1396,9 +1395,9 @@ int search_binary_handler(struct linux_binprm *bprm)
 			if (!try_module_get(fmt->module))
 				continue;
 			read_unlock(&binfmt_lock);
-			bprm->recursion_depth = depth + 1;
+			bprm->recursion_depth++;
 			retval = fn(bprm);
-			bprm->recursion_depth = depth;
+			bprm->recursion_depth--;
 			if (retval >= 0) {
 				put_binfmt(fmt);
 				allow_write_access(bprm->file);

commit 5d1baf3b63bfc8c709dc44df85ff1475c7ef489d
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:38 2013 -0700

    exec: introduce exec_binprm() for "depth == 0" code
    
    task_pid_nr_ns() and trace/ptrace code in the middle of the recursive
    search_binary_handler() looks confusing and imho annoying.  We only need
    this code if "depth == 0", lets add a simple helper which calls
    search_binary_handler() and does trace_sched_process_exec() +
    ptrace_event().
    
    The patch also moves the setting of task->did_exec, we need to do this
    only once.
    
    Note: we can kill either task->did_exec or PF_FORKNOEXEC.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2d1e52a58fe9..4d95b4709ea0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1373,7 +1373,6 @@ int search_binary_handler(struct linux_binprm *bprm)
 	unsigned int depth = bprm->recursion_depth;
 	int try,retval;
 	struct linux_binfmt *fmt;
-	pid_t old_pid, old_vpid;
 
 	/* This allows 4 levels of binfmt rewrites before failing hard. */
 	if (depth > 5)
@@ -1387,12 +1386,6 @@ int search_binary_handler(struct linux_binprm *bprm)
 	if (retval)
 		return retval;
 
-	/* Need to fetch pid before load_binary changes it */
-	old_pid = current->pid;
-	rcu_read_lock();
-	old_vpid = task_pid_nr_ns(current, task_active_pid_ns(current->parent));
-	rcu_read_unlock();
-
 	retval = -ENOENT;
 	for (try=0; try<2; try++) {
 		read_lock(&binfmt_lock);
@@ -1407,16 +1400,11 @@ int search_binary_handler(struct linux_binprm *bprm)
 			retval = fn(bprm);
 			bprm->recursion_depth = depth;
 			if (retval >= 0) {
-				if (depth == 0) {
-					trace_sched_process_exec(current, old_pid, bprm);
-					ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
-				}
 				put_binfmt(fmt);
 				allow_write_access(bprm->file);
 				if (bprm->file)
 					fput(bprm->file);
 				bprm->file = NULL;
-				current->did_exec = 1;
 				proc_exec_connector(current);
 				return retval;
 			}
@@ -1450,9 +1438,29 @@ int search_binary_handler(struct linux_binprm *bprm)
 	}
 	return retval;
 }
-
 EXPORT_SYMBOL(search_binary_handler);
 
+static int exec_binprm(struct linux_binprm *bprm)
+{
+	pid_t old_pid, old_vpid;
+	int ret;
+
+	/* Need to fetch pid before load_binary changes it */
+	old_pid = current->pid;
+	rcu_read_lock();
+	old_vpid = task_pid_nr_ns(current, task_active_pid_ns(current->parent));
+	rcu_read_unlock();
+
+	ret = search_binary_handler(bprm);
+	if (ret >= 0) {
+		trace_sched_process_exec(current, old_pid, bprm);
+		ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
+		current->did_exec = 1;
+	}
+
+	return ret;
+}
+
 /*
  * sys_execve() executes a new program.
  */
@@ -1541,7 +1549,7 @@ static int do_execve_common(const char *filename,
 	if (retval < 0)
 		goto out;
 
-	retval = search_binary_handler(bprm);
+	retval = exec_binprm(bprm);
 	if (retval < 0)
 		goto out;
 

commit d9104d1ca9662498339c0de975b4666c30485f4e
Author: Cyrill Gorcunov <gorcunov@gmail.com>
Date:   Wed Sep 11 14:22:24 2013 -0700

    mm: track vma changes with VM_SOFTDIRTY bit
    
    Pavel reported that in case if vma area get unmapped and then mapped (or
    expanded) in-place, the soft dirty tracker won't be able to recognize this
    situation since it works on pte level and ptes are get zapped on unmap,
    loosing soft dirty bit of course.
    
    So to resolve this situation we need to track actions on vma level, there
    VM_SOFTDIRTY flag comes in.  When new vma area created (or old expanded)
    we set this bit, and keep it here until application calls for clearing
    soft dirty bit.
    
    Thus when user space application track memory changes now it can detect if
    vma area is renewed.
    
    Reported-by: Pavel Emelyanov <xemul@parallels.com>
    Signed-off-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Matt Mackall <mpm@selenic.com>
    Cc: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@gmail.com>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: "Aneesh Kumar K.V" <aneesh.kumar@linux.vnet.ibm.com>
    Cc: Rob Landley <rob@landley.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index fd774c7cb483..2d1e52a58fe9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -266,7 +266,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	BUILD_BUG_ON(VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP);
 	vma->vm_end = STACK_TOP_MAX;
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
-	vma->vm_flags = VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;
+	vma->vm_flags = VM_SOFTDIRTY | VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 	INIT_LIST_HEAD(&vma->anon_vma_chain);
 

commit 2b047252d087be7f2ba088b4933cd904f92e6fce
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 15 11:42:25 2013 -0700

    Fix TLB gather virtual address range invalidation corner cases
    
    Ben Tebulin reported:
    
     "Since v3.7.2 on two independent machines a very specific Git
      repository fails in 9/10 cases on git-fsck due to an SHA1/memory
      failures.  This only occurs on a very specific repository and can be
      reproduced stably on two independent laptops.  Git mailing list ran
      out of ideas and for me this looks like some very exotic kernel issue"
    
    and bisected the failure to the backport of commit 53a59fc67f97 ("mm:
    limit mmu_gather batching to fix soft lockups on !CONFIG_PREEMPT").
    
    That commit itself is not actually buggy, but what it does is to make it
    much more likely to hit the partial TLB invalidation case, since it
    introduces a new case in tlb_next_batch() that previously only ever
    happened when running out of memory.
    
    The real bug is that the TLB gather virtual memory range setup is subtly
    buggered.  It was introduced in commit 597e1c3580b7 ("mm/mmu_gather:
    enable tlb flush range in generic mmu_gather"), and the range handling
    was already fixed at least once in commit e6c495a96ce0 ("mm: fix the TLB
    range flushed when __tlb_remove_page() runs out of slots"), but that fix
    was not complete.
    
    The problem with the TLB gather virtual address range is that it isn't
    set up by the initial tlb_gather_mmu() initialization (which didn't get
    the TLB range information), but it is set up ad-hoc later by the
    functions that actually flush the TLB.  And so any such case that forgot
    to update the TLB range entries would potentially miss TLB invalidates.
    
    Rather than try to figure out exactly which particular ad-hoc range
    setup was missing (I personally suspect it's the hugetlb case in
    zap_huge_pmd(), which didn't have the same logic as zap_pte_range()
    did), this patch just gets rid of the problem at the source: make the
    TLB range information available to tlb_gather_mmu(), and initialize it
    when initializing all the other tlb gather fields.
    
    This makes the patch larger, but conceptually much simpler.  And the end
    result is much more understandable; even if you want to play games with
    partial ranges when invalidating the TLB contents in chunks, now the
    range information is always there, and anybody who doesn't want to
    bother with it won't introduce subtle bugs.
    
    Ben verified that this fixes his problem.
    
    Reported-bisected-and-tested-by: Ben Tebulin <tebulin@googlemail.com>
    Build-testing-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Build-testing-by: Richard Weinberger <richard.weinberger@gmail.com>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: stable@vger.kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9c73def87642..fd774c7cb483 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -608,7 +608,7 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 		return -ENOMEM;
 
 	lru_add_drain();
-	tlb_gather_mmu(&tlb, mm, 0);
+	tlb_gather_mmu(&tlb, mm, old_start, old_end);
 	if (new_end > old_start) {
 		/*
 		 * when the old and new regions overlap clear from new_end.
@@ -625,7 +625,7 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 		free_pgd_range(&tlb, old_start, old_end, new_end,
 			vma->vm_next ? vma->vm_next->vm_start : USER_PGTABLES_CEILING);
 	}
-	tlb_finish_mmu(&tlb, new_end, old_end);
+	tlb_finish_mmu(&tlb, old_start, old_end);
 
 	/*
 	 * Shrink the vma to just the new range.  Always succeeds.

commit 266b7a021f7dcc4d4531961a47f4ef74c3c4ab6b
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jul 3 15:08:35 2013 -0700

    fs/exec.c:de_thread: mt-exec should update ->real_start_time
    
    924b42d5 ("Use boot based time for process start time and boot time in
    /proc") updated copy_process/do_task_stat but forgot about de_thread().
    This breaks "ps axOT" if a sub-thread execs.
    
    Note: I think that task->start_time should die.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: John Stultz <johnstul@us.ibm.com>
    Cc: Tomas Janousek <tjanouse@redhat.com>
    Cc: Tomas Smetana <tsmetana@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 396aec2dae90..9c73def87642 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -932,6 +932,7 @@ static int de_thread(struct task_struct *tsk)
 		 * also take its birthdate (always earlier than our own).
 		 */
 		tsk->start_time = leader->start_time;
+		tsk->real_start_time = leader->real_start_time;
 
 		BUG_ON(!same_thread_group(leader, tsk));
 		BUG_ON(has_group_leader_pid(tsk));

commit bd9d43f47d6944019918a801398c587ee86c4b52
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jul 3 15:08:34 2013 -0700

    fs/exec.c: do_execve_common(): use current_user()
    
    Trivial cleanup.  do_execve_common() can use current_user() and avoid the
    unnecessary "struct cred *cred" var.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Vasiliy Kulikov <segoon@openwall.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7619dddd5622..396aec2dae90 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1464,7 +1464,6 @@ static int do_execve_common(const char *filename,
 	struct files_struct *displaced;
 	bool clear_in_exec;
 	int retval;
-	const struct cred *cred = current_cred();
 
 	/*
 	 * We move the actual failure in case of RLIMIT_NPROC excess from
@@ -1473,7 +1472,7 @@ static int do_execve_common(const char *filename,
 	 * whether NPROC limit is still exceeded.
 	 */
 	if ((current->flags & PF_NPROC_EXCEEDED) &&
-	    atomic_read(&cred->user->processes) > rlimit(RLIMIT_NPROC)) {
+	    atomic_read(&current_user()->processes) > rlimit(RLIMIT_NPROC)) {
 		retval = -EAGAIN;
 		goto out_ret;
 	}

commit 3f4185483832ccf3d2977923db576fa689c2abce
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jul 3 15:08:25 2013 -0700

    fs/exec.c:de_thread(): use change_pid() rather than detach_pid/attach_pid
    
    de_thread() can use change_pid() instead of detach + attach.  This looks
    better and this ensures that, say, next_thread() can never see a task with
    ->pid == NULL.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Cc: Sergey Dyasly <dserrg@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 03b907cfd765..7619dddd5622 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -947,9 +947,8 @@ static int de_thread(struct task_struct *tsk)
 		 * Note: The old leader also uses this pid until release_task
 		 *       is called.  Odd but simple and correct.
 		 */
-		detach_pid(tsk, PIDTYPE_PID);
 		tsk->pid = leader->pid;
-		attach_pid(tsk, PIDTYPE_PID,  task_pid(leader));
+		change_pid(tsk, PIDTYPE_PID, task_pid(leader));
 		transfer_pid(leader, tsk, PIDTYPE_PGID);
 		transfer_pid(leader, tsk, PIDTYPE_SID);
 

commit 790eac5640abf7a57fa3a644386df330e18c11b0
Merge: 0b0585c3e192 48bde8d3620f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 3 09:10:19 2013 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull second set of VFS changes from Al Viro:
     "Assorted f_pos race fixes, making do_splice_direct() safe to call with
      i_mutex on parent, O_TMPFILE support, Jeff's locks.c series,
      ->d_hash/->d_compare calling conventions changes from Linus, misc
      stuff all over the place."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (63 commits)
      Document ->tmpfile()
      ext4: ->tmpfile() support
      vfs: export lseek_execute() to modules
      lseek_execute() doesn't need an inode passed to it
      block_dev: switch to fixed_size_llseek()
      cpqphp_sysfs: switch to fixed_size_llseek()
      tile-srom: switch to fixed_size_llseek()
      proc_powerpc: switch to fixed_size_llseek()
      ubi/cdev: switch to fixed_size_llseek()
      pci/proc: switch to fixed_size_llseek()
      isapnp: switch to fixed_size_llseek()
      lpfc: switch to fixed_size_llseek()
      locks: give the blocked_hash its own spinlock
      locks: add a new "lm_owner_key" lock operation
      locks: turn the blocked_list into a hashtable
      locks: convert fl_link to a hlist_node
      locks: avoid taking global lock if possible when waking up blocked waiters
      locks: protect most of the file_lock handling with i_lock
      locks: encapsulate the fl_link list handling
      locks: make "added" in __posix_lock_file a bool
      ...

commit f9652e10c12b43d9bb957269745cf2fa5682fa92
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jun 11 08:23:01 2013 +0400

    allow build_open_flags() to return an error
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 643019585574..0f6c96c57b2f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -110,13 +110,14 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 	static const struct open_flags uselib_flags = {
 		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
 		.acc_mode = MAY_READ | MAY_EXEC | MAY_OPEN,
-		.intent = LOOKUP_OPEN
+		.intent = LOOKUP_OPEN,
+		.lookup_flags = LOOKUP_FOLLOW,
 	};
 
 	if (IS_ERR(tmp))
 		goto out;
 
-	file = do_filp_open(AT_FDCWD, tmp, &uselib_flags, LOOKUP_FOLLOW);
+	file = do_filp_open(AT_FDCWD, tmp, &uselib_flags);
 	putname(tmp);
 	error = PTR_ERR(file);
 	if (IS_ERR(file))
@@ -756,10 +757,11 @@ struct file *open_exec(const char *name)
 	static const struct open_flags open_exec_flags = {
 		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
 		.acc_mode = MAY_EXEC | MAY_OPEN,
-		.intent = LOOKUP_OPEN
+		.intent = LOOKUP_OPEN,
+		.lookup_flags = LOOKUP_FOLLOW,
 	};
 
-	file = do_filp_open(AT_FDCWD, &tmp, &open_exec_flags, LOOKUP_FOLLOW);
+	file = do_filp_open(AT_FDCWD, &tmp, &open_exec_flags);
 	if (IS_ERR(file))
 		goto out;
 

commit 2976b10f05bd7f6dab9f9e7524451ddfed656a89
Author: Stephane Eranian <eranian@google.com>
Date:   Thu Jun 20 11:36:28 2013 +0200

    perf: Disable monitoring on setuid processes for regular users
    
    There was a a bug in setup_new_exec(), whereby
    the test to disabled perf monitoring was not
    correct because the new credentials for the
    process were not yet committed and therefore
    the get_dumpable() test was never firing.
    
    The patch fixes the problem by moving the
    perf_event test until after the credentials
    are committed.
    
    Signed-off-by: Stephane Eranian <eranian@google.com>
    Tested-by: Jiri Olsa <jolsa@redhat.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: <stable@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 643019585574..ffd7a813ad3d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1135,13 +1135,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 			set_dumpable(current->mm, suid_dumpable);
 	}
 
-	/*
-	 * Flush performance counters when crossing a
-	 * security domain:
-	 */
-	if (!get_dumpable(current->mm))
-		perf_event_exit_task(current);
-
 	/* An exec changes our domain. We are no longer part of the thread
 	   group */
 
@@ -1205,6 +1198,15 @@ void install_exec_creds(struct linux_binprm *bprm)
 
 	commit_creds(bprm->cred);
 	bprm->cred = NULL;
+
+	/*
+	 * Disable monitoring for regular users
+	 * when executing setuid binaries. Must
+	 * wait until new credentials are committed
+	 * by commit_creds() above
+	 */
+	if (get_dumpable(current->mm) != SUID_DUMP_USER)
+		perf_event_exit_task(current);
 	/*
 	 * cred_guard_mutex must be held at least to this point to prevent
 	 * ptrace_attach() from altering our determination of the task's

commit 20b4fb485227404329e41ad15588afad3df23050
Merge: b9394d8a657c ac3e3c5b1164
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 1 17:51:54 2013 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull VFS updates from Al Viro,
    
    Misc cleanups all over the place, mainly wrt /proc interfaces (switch
    create_proc_entry to proc_create(), get rid of the deprecated
    create_proc_read_entry() in favor of using proc_create_data() and
    seq_file etc).
    
    7kloc removed.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (204 commits)
      don't bother with deferred freeing of fdtables
      proc: Move non-public stuff from linux/proc_fs.h to fs/proc/internal.h
      proc: Make the PROC_I() and PDE() macros internal to procfs
      proc: Supply a function to remove a proc entry by PDE
      take cgroup_open() and cpuset_open() to fs/proc/base.c
      ppc: Clean up scanlog
      ppc: Clean up rtas_flash driver somewhat
      hostap: proc: Use remove_proc_subtree()
      drm: proc: Use remove_proc_subtree()
      drm: proc: Use minor->index to label things, not PDE->name
      drm: Constify drm_proc_list[]
      zoran: Don't print proc_dir_entry data in debug
      reiserfs: Don't access the proc_dir_entry in r_open(), r_start() r_show()
      proc: Supply an accessor for getting the data from a PDE's parent
      airo: Use remove_proc_subtree()
      rtl8192u: Don't need to save device proc dir PDE
      rtl8187se: Use a dir under /proc/net/r8180/
      proc: Add proc_mkdir_data()
      proc: Move some bits from linux/proc_fs.h to linux/{of.h,signal.h,tty.h}
      proc: Move PDE_NET() to fs/proc/proc_net.c
      ...

commit e56fb2874015370e3b7f8d85051f6dce26051df9
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Apr 30 15:28:20 2013 -0700

    exec: do not abuse ->cred_guard_mutex in threadgroup_lock()
    
    threadgroup_lock() takes signal->cred_guard_mutex to ensure that
    thread_group_leader() is stable.  This doesn't look nice, the scope of
    this lock in do_execve() is huge.
    
    And as Dave pointed out this can lead to deadlock, we have the
    following dependencies:
    
            do_execve:              cred_guard_mutex -> i_mutex
            cgroup_mount:           i_mutex -> cgroup_mutex
            attach_task_by_pid:     cgroup_mutex -> cred_guard_mutex
    
    Change de_thread() to take threadgroup_change_begin() around the
    switch-the-leader code and change threadgroup_lock() to avoid
    ->cred_guard_mutex.
    
    Note that de_thread() can't sleep with ->group_rwsem held, this can
    obviously deadlock with the exiting leader if the writer is active, so it
    does threadgroup_change_end() before schedule().
    
    Reported-by: Dave Jones <davej@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 260f89f66651..963f510a25ab 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -898,11 +898,13 @@ static int de_thread(struct task_struct *tsk)
 
 		sig->notify_count = -1;	/* for exit_notify() */
 		for (;;) {
+			threadgroup_change_begin(tsk);
 			write_lock_irq(&tasklist_lock);
 			if (likely(leader->exit_state))
 				break;
 			__set_current_state(TASK_KILLABLE);
 			write_unlock_irq(&tasklist_lock);
+			threadgroup_change_end(tsk);
 			schedule();
 			if (unlikely(__fatal_signal_pending(tsk)))
 				goto killed;
@@ -960,6 +962,7 @@ static int de_thread(struct task_struct *tsk)
 		if (unlikely(leader->ptrace))
 			__wake_up_parent(leader, leader->parent);
 		write_unlock_irq(&tasklist_lock);
+		threadgroup_change_end(tsk);
 
 		release_task(leader);
 	}

commit 12eaaf309a798973d215f7f21aa5a67a760ed7c8
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Apr 30 15:28:19 2013 -0700

    set_task_comm: kill the pointless memset() + wmb()
    
    set_task_comm() does memset() + wmb() before strlcpy().  This buys
    nothing and to add to the confusion, the comment is wrong.
    
    - We do not need memset() to be "safe from non-terminating string
      reads", the final char is always zero and we never change it.
    
    - wmb() is paired with nothing, it cannot prevent from printing
      the mixture of the old/new data unless the reader takes the lock.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: John Stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 87e731f020fb..260f89f66651 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1027,17 +1027,7 @@ EXPORT_SYMBOL_GPL(get_task_comm);
 void set_task_comm(struct task_struct *tsk, char *buf)
 {
 	task_lock(tsk);
-
 	trace_task_rename(tsk, buf);
-
-	/*
-	 * Threads may access current->comm without holding
-	 * the task lock, so write the string carefully.
-	 * Readers without a lock may see incomplete new
-	 * names but are safe from non-terminating string reads.
-	 */
-	memset(tsk->comm, 0, TASK_COMM_LEN);
-	wmb();
 	strlcpy(tsk->comm, buf, sizeof(tsk->comm));
 	task_unlock(tsk);
 	perf_event_comm(tsk);

commit 6ee8630e02be6dd89926ca0fbc21af68b23dc087
Author: Hugh Dickins <hughd@google.com>
Date:   Mon Apr 29 15:07:44 2013 -0700

    mm: allow arch code to control the user page table ceiling
    
    On architectures where a pgd entry may be shared between user and kernel
    (e.g.  ARM+LPAE), freeing page tables needs a ceiling other than 0.
    This patch introduces a generic USER_PGTABLES_CEILING that arch code can
    override.  It is the responsibility of the arch code setting the ceiling
    to ensure the complete freeing of the page tables (usually in
    pgd_free()).
    
    [catalin.marinas@arm.com: commit log; shift_arg_pages(), asm-generic/pgtables.h changes]
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: <stable@vger.kernel.org>    [3.3+]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a96a4885bbbf..87e731f020fb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -613,7 +613,7 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 		 * when the old and new regions overlap clear from new_end.
 		 */
 		free_pgd_range(&tlb, new_end, old_end, new_end,
-			vma->vm_next ? vma->vm_next->vm_start : 0);
+			vma->vm_next ? vma->vm_next->vm_start : USER_PGTABLES_CEILING);
 	} else {
 		/*
 		 * otherwise, clean from old_start; this is done to not touch
@@ -622,7 +622,7 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 		 * for the others its just a little faster.
 		 */
 		free_pgd_range(&tlb, old_start, old_end, new_end,
-			vma->vm_next ? vma->vm_next->vm_start : 0);
+			vma->vm_next ? vma->vm_next->vm_start : USER_PGTABLES_CEILING);
 	}
 	tlb_finish_mmu(&tlb, new_end, old_end);
 

commit 3dc20cb282ec03cc4c997130d680c800011ed479
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Apr 13 20:31:37 2013 -0400

    new helper: read_code()
    
    switch binfmts that use ->read() to that (and to kernel_read()
    in several cases in binfmt_flat - sure, it's nommu, but still,
    doing ->read() into kmalloc'ed buffer...)
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index a96a4885bbbf..77dc9096440f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -802,6 +802,15 @@ int kernel_read(struct file *file, loff_t offset,
 
 EXPORT_SYMBOL(kernel_read);
 
+ssize_t read_code(struct file *file, unsigned long addr, loff_t pos, size_t len)
+{
+	ssize_t res = file->f_op->read(file, (void __user *)addr, len, &pos);
+	if (res > 0)
+		flush_icache_range(addr, addr + len);
+	return res;
+}
+EXPORT_SYMBOL(read_code);
+
 static int exec_mmap(struct mm_struct *mm)
 {
 	struct task_struct *tsk;

commit e579d2c259be42b6f29458327e5153b22414b031
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Feb 27 17:03:15 2013 -0800

    coredump: remove redundant defines for dumpable states
    
    The existing SUID_DUMP_* defines duplicate the newer SUID_DUMPABLE_*
    defines introduced in 54b501992dd2 ("coredump: warn about unsafe
    suid_dumpable / core_pattern combo").  Remove the new ones, and use the
    prior values instead.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reported-by: Chen Gang <gang.chen@asianux.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Alan Cox <alan@linux.intel.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Doug Ledford <dledford@redhat.com>
    Cc: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: James Morris <james.l.morris@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 864c50df660a..a96a4885bbbf 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1111,7 +1111,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
 	if (uid_eq(current_euid(), current_uid()) && gid_eq(current_egid(), current_gid()))
-		set_dumpable(current->mm, SUID_DUMPABLE_ENABLED);
+		set_dumpable(current->mm, SUID_DUMP_USER);
 	else
 		set_dumpable(current->mm, suid_dumpable);
 
@@ -1639,17 +1639,17 @@ EXPORT_SYMBOL(set_binfmt);
 void set_dumpable(struct mm_struct *mm, int value)
 {
 	switch (value) {
-	case SUID_DUMPABLE_DISABLED:
+	case SUID_DUMP_DISABLE:
 		clear_bit(MMF_DUMPABLE, &mm->flags);
 		smp_wmb();
 		clear_bit(MMF_DUMP_SECURELY, &mm->flags);
 		break;
-	case SUID_DUMPABLE_ENABLED:
+	case SUID_DUMP_USER:
 		set_bit(MMF_DUMPABLE, &mm->flags);
 		smp_wmb();
 		clear_bit(MMF_DUMP_SECURELY, &mm->flags);
 		break;
-	case SUID_DUMPABLE_SAFE:
+	case SUID_DUMP_ROOT:
 		set_bit(MMF_DUMP_SECURELY, &mm->flags);
 		smp_wmb();
 		set_bit(MMF_DUMPABLE, &mm->flags);
@@ -1662,7 +1662,7 @@ int __get_dumpable(unsigned long mm_flags)
 	int ret;
 
 	ret = mm_flags & MMF_DUMPABLE_MASK;
-	return (ret > SUID_DUMPABLE_ENABLED) ? SUID_DUMPABLE_SAFE : ret;
+	return (ret > SUID_DUMP_USER) ? SUID_DUMP_ROOT : ret;
 }
 
 int get_dumpable(struct mm_struct *mm)

commit 9cc64ceaa8b8e8c874519caee79e18cb35d3ce3e
Author: Yuanhan Liu <yuanhan.liu@linux.intel.com>
Date:   Wed Feb 20 13:16:01 2013 +1100

    fs/exec.c: make bprm_mm_init() static
    
    There is only one user of bprm_mm_init, and it's inside the same file.
    
    Signed-off-by: Yuanhan Liu <yuanhan.liu@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 7b6f4d59b26c..864c50df660a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -355,7 +355,7 @@ static bool valid_arg_len(struct linux_binprm *bprm, long len)
  * flags, permissions, and offset, so we use temporary values.  We'll update
  * them later in setup_arg_pages().
  */
-int bprm_mm_init(struct linux_binprm *bprm)
+static int bprm_mm_init(struct linux_binprm *bprm)
 {
 	int err;
 	struct mm_struct *mm = NULL;

commit 496ad9aa8ef448058e36ca7a787c61f2e63f0f54
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jan 23 17:07:38 2013 -0500

    new helper: file_inode(file)
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 20df02c1cc70..7b6f4d59b26c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -123,7 +123,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 		goto out;
 
 	error = -EINVAL;
-	if (!S_ISREG(file->f_path.dentry->d_inode->i_mode))
+	if (!S_ISREG(file_inode(file)->i_mode))
 		goto exit;
 
 	error = -EACCES;
@@ -764,7 +764,7 @@ struct file *open_exec(const char *name)
 		goto out;
 
 	err = -EACCES;
-	if (!S_ISREG(file->f_path.dentry->d_inode->i_mode))
+	if (!S_ISREG(file_inode(file)->i_mode))
 		goto exit;
 
 	if (file->f_path.mnt->mnt_flags & MNT_NOEXEC)
@@ -1098,7 +1098,7 @@ EXPORT_SYMBOL(flush_old_exec);
 
 void would_dump(struct linux_binprm *bprm, struct file *file)
 {
-	if (inode_permission(file->f_path.dentry->d_inode, MAY_READ) < 0)
+	if (inode_permission(file_inode(file), MAY_READ) < 0)
 		bprm->interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP;
 }
 EXPORT_SYMBOL(would_dump);
@@ -1270,7 +1270,7 @@ static int check_unsafe_exec(struct linux_binprm *bprm)
 int prepare_binprm(struct linux_binprm *bprm)
 {
 	umode_t mode;
-	struct inode * inode = bprm->file->f_path.dentry->d_inode;
+	struct inode * inode = file_inode(bprm->file);
 	int retval;
 
 	mode = inode->i_mode;

commit 6d92d4f6a74766cc885b18218268e0c47fbca399
Author: Xi Wang <xi.wang@gmail.com>
Date:   Fri Jan 11 14:31:48 2013 -0800

    fs/exec.c: work around icc miscompilation
    
    The tricky problem is this check:
    
            if (i++ >= max)
    
    icc (mis)optimizes this check as:
    
            if (++i > max)
    
    The check now becomes a no-op since max is MAX_ARG_STRINGS (0x7FFFFFFF).
    
    This is "allowed" by the C standard, assuming i++ never overflows,
    because signed integer overflow is undefined behavior.  This
    optimization effectively reverts the previous commit 362e6663ef23
    ("exec.c, compat.c: fix count(), compat_count() bounds checking") that
    tries to fix the check.
    
    This patch simply moves ++ after the check.
    
    Signed-off-by: Xi Wang <xi.wang@gmail.com>
    Cc: Jason Baron <jbaron@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 18c45cac368f..20df02c1cc70 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -434,8 +434,9 @@ static int count(struct user_arg_ptr argv, int max)
 			if (IS_ERR(p))
 				return -EFAULT;
 
-			if (i++ >= max)
+			if (i >= max)
 				return -E2BIG;
+			++i;
 
 			if (fatal_signal_pending(current))
 				return -ERESTARTNOHAND;

commit 4c9a44aebeaef35570a67aed17b72a2cf8d0b219
Merge: 1f0377ff088e cfde81908842
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 20 20:00:43 2012 -0800

    Merge branch 'akpm' (Andrew's patch-bomb)
    
    Merge the rest of Andrew's patches for -rc1:
     "A bunch of fixes and misc missed-out-on things.
    
      That'll do for -rc1.  I still have a batch of IPC patches which still
      have a possible bug report which I'm chasing down."
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (25 commits)
      keys: use keyring_alloc() to create module signing keyring
      keys: fix unreachable code
      sendfile: allows bypassing of notifier events
      SGI-XP: handle non-fatal traps
      fat: fix incorrect function comment
      Documentation: ABI: remove testing/sysfs-devices-node
      proc: fix inconsistent lock state
      linux/kernel.h: fix DIV_ROUND_CLOSEST with unsigned divisors
      memcg: don't register hotcpu notifier from ->css_alloc()
      checkpatch: warn on uapi #includes that #include <uapi/...
      revert "rtc: recycle id when unloading a rtc driver"
      mm: clean up transparent hugepage sysfs error messages
      hfsplus: add error message for the case of failure of sync fs in delayed_sync_fs() method
      hfsplus: rework processing of hfs_btree_write() returned error
      hfsplus: rework processing errors in hfsplus_free_extents()
      hfsplus: avoid crash on failed block map free
      kcmp: include linux/ptrace.h
      drivers/rtc/rtc-imxdi.c: must include <linux/spinlock.h>
      mm: cma: WARN if freed memory is still in use
      exec: do not leave bprm->interp on stack
      ...

commit 54d46ea993744c5408e39ce0cb4851e13cbea716
Merge: f59dc2bb5a50 50ececcfa7d1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 20 18:05:28 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull signal handling cleanups from Al Viro:
     "sigaltstack infrastructure + conversion for x86, alpha and um,
      COMPAT_SYSCALL_DEFINE infrastructure.
    
      Note that there are several conflicts between "unify
      SS_ONSTACK/SS_DISABLE definitions" and UAPI patches in mainline;
      resolution is trivial - just remove definitions of SS_ONSTACK and
      SS_DISABLED from arch/*/uapi/asm/signal.h; they are all identical and
      include/uapi/linux/signal.h contains the unified variant."
    
    Fixed up conflicts as per Al.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal:
      alpha: switch to generic sigaltstack
      new helpers: __save_altstack/__compat_save_altstack, switch x86 and um to those
      generic compat_sys_sigaltstack()
      introduce generic sys_sigaltstack(), switch x86 and um to it
      new helper: compat_user_stack_pointer()
      new helper: restore_altstack()
      unify SS_ONSTACK/SS_DISABLE definitions
      new helper: current_user_stack_pointer()
      missing user_stack_pointer() instances
      Bury the conditionals from kernel_thread/kernel_execve series
      COMPAT_SYSCALL_DEFINE: infrastructure

commit b66c5984017533316fd1951770302649baf1aa33
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Dec 20 15:05:16 2012 -0800

    exec: do not leave bprm->interp on stack
    
    If a series of scripts are executed, each triggering module loading via
    unprintable bytes in the script header, kernel stack contents can leak
    into the command line.
    
    Normally execution of binfmt_script and binfmt_misc happens recursively.
    However, when modules are enabled, and unprintable bytes exist in the
    bprm->buf, execution will restart after attempting to load matching
    binfmt modules.  Unfortunately, the logic in binfmt_script and
    binfmt_misc does not expect to get restarted.  They leave bprm->interp
    pointing to their local stack.  This means on restart bprm->interp is
    left pointing into unused stack memory which can then be copied into the
    userspace argv areas.
    
    After additional study, it seems that both recursion and restart remains
    the desirable way to handle exec with scripts, misc, and modules.  As
    such, we need to protect the changes to interp.
    
    This changes the logic to require allocation for any changes to the
    bprm->interp.  To avoid adding a new kmalloc to every exec, the default
    value is left as-is.  Only when passing through binfmt_script or
    binfmt_misc does an allocation take place.
    
    For a proof of concept, see DoTest.sh from:
    
       http://www.halfdog.net/Security/2012/LinuxKernelBinfmtScriptStackDataDisclosure/
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: halfdog <me@halfdog.net>
    Cc: P J P <ppandit@redhat.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index d8e1191cb112..237d5342786c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1175,9 +1175,24 @@ void free_bprm(struct linux_binprm *bprm)
 		mutex_unlock(&current->signal->cred_guard_mutex);
 		abort_creds(bprm->cred);
 	}
+	/* If a binfmt changed the interp, free it. */
+	if (bprm->interp != bprm->filename)
+		kfree(bprm->interp);
 	kfree(bprm);
 }
 
+int bprm_change_interp(char *interp, struct linux_binprm *bprm)
+{
+	/* If a binfmt changed the interp, free it first. */
+	if (bprm->interp != bprm->filename)
+		kfree(bprm->interp);
+	bprm->interp = kstrdup(interp, GFP_KERNEL);
+	if (!bprm->interp)
+		return -ENOMEM;
+	return 0;
+}
+EXPORT_SYMBOL(bprm_change_interp);
+
 /*
  * install the new credentials for this executable
  */

commit ae903caae267154de7cf8576b130ff474630596b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Dec 14 12:44:11 2012 -0500

    Bury the conditionals from kernel_thread/kernel_execve series
    
    All architectures have
            CONFIG_GENERIC_KERNEL_THREAD
            CONFIG_GENERIC_KERNEL_EXECVE
            __ARCH_WANT_SYS_EXECVE
    None of them have __ARCH_WANT_KERNEL_EXECVE and there are only two callers
    of kernel_execve() (which is a trivial wrapper for do_execve() now) left.
    Kill the conditionals and make both callers use do_execve().
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 721a29929511..090ac91da2e9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1657,7 +1657,6 @@ int get_dumpable(struct mm_struct *mm)
 	return __get_dumpable(mm->flags);
 }
 
-#ifdef __ARCH_WANT_SYS_EXECVE
 SYSCALL_DEFINE3(execve,
 		const char __user *, filename,
 		const char __user *const __user *, argv,
@@ -1685,23 +1684,3 @@ asmlinkage long compat_sys_execve(const char __user * filename,
 	return error;
 }
 #endif
-#endif
-
-#ifdef __ARCH_WANT_KERNEL_EXECVE
-int kernel_execve(const char *filename,
-		  const char *const argv[],
-		  const char *const envp[])
-{
-	int ret = do_execve(filename,
-			(const char __user *const __user *)argv,
-			(const char __user *const __user *)envp);
-	if (ret < 0)
-		return ret;
-
-	/*
-	 * We were successful.  We won't be returning to our caller, but
-	 * instead to user space by manipulating the kernel stack.
-	 */
-	ret_from_kernel_execve(current_pt_regs());
-}
-#endif

commit 848b81415c42ff3dc9a4204749087b015c37ef66
Merge: 992956189de5 6fd59a83b926
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 17 20:58:12 2012 -0800

    Merge branch 'akpm' (Andrew's patch-bomb)
    
    Merge misc patches from Andrew Morton:
     "Incoming:
    
       - lots of misc stuff
    
       - backlight tree updates
    
       - lib/ updates
    
       - Oleg's percpu-rwsem changes
    
       - checkpatch
    
       - rtc
    
       - aoe
    
       - more checkpoint/restart support
    
      I still have a pile of MM stuff pending - Pekka should be merging
      later today after which that is good to go.  A number of other things
      are twiddling thumbs awaiting maintainer merges."
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (180 commits)
      scatterlist: don't BUG when we can trivially return a proper error.
      docs: update documentation about /proc/<pid>/fdinfo/<fd> fanotify output
      fs, fanotify: add @mflags field to fanotify output
      docs: add documentation about /proc/<pid>/fdinfo/<fd> output
      fs, notify: add procfs fdinfo helper
      fs, exportfs: add exportfs_encode_inode_fh() helper
      fs, exportfs: escape nil dereference if no s_export_op present
      fs, epoll: add procfs fdinfo helper
      fs, eventfd: add procfs fdinfo helper
      procfs: add ability to plug in auxiliary fdinfo providers
      tools/testing/selftests/kcmp/kcmp_test.c: print reason for failure in kcmp_test
      breakpoint selftests: print failure status instead of cause make error
      kcmp selftests: print fail status instead of cause make error
      kcmp selftests: make run_tests fix
      mem-hotplug selftests: print failure status instead of cause make error
      cpu-hotplug selftests: print failure status instead of cause make error
      mqueue selftests: print failure status instead of cause make error
      vm selftests: print failure status instead of cause make error
      ubifs: use prandom_bytes
      mtd: nandsim: use prandom_bytes
      ...

commit d740269867021faf4ce38a449353d2b986c34a67
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Dec 17 16:03:20 2012 -0800

    exec: use -ELOOP for max recursion depth
    
    To avoid an explosion of request_module calls on a chain of abusive
    scripts, fail maximum recursion with -ELOOP instead of -ENOEXEC. As soon
    as maximum recursion depth is hit, the error will fail all the way back
    up the chain, aborting immediately.
    
    This also has the side-effect of stopping the user's shell from attempting
    to reexecute the top-level file as a shell script. As seen in the
    dash source:
    
            if (cmd != path_bshell && errno == ENOEXEC) {
                    *argv-- = cmd;
                    *argv = cmd = path_bshell;
                    goto repeat;
            }
    
    The above logic was designed for running scripts automatically that lacked
    the "#!" header, not to re-try failed recursion. On a legitimate -ENOEXEC,
    things continue to behave as the shell expects.
    
    Additionally, when tracking recursion, the binfmt handlers should not be
    involved. The recursion being tracked is the depth of calls through
    search_binary_handler(), so that function should be exclusively responsible
    for tracking the depth.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: halfdog <me@halfdog.net>
    Cc: P J P <ppandit@redhat.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 721a29929511..d5eb9e605ffd 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1356,6 +1356,10 @@ int search_binary_handler(struct linux_binprm *bprm)
 	struct linux_binfmt *fmt;
 	pid_t old_pid, old_vpid;
 
+	/* This allows 4 levels of binfmt rewrites before failing hard. */
+	if (depth > 5)
+		return -ELOOP;
+
 	retval = security_bprm_check(bprm);
 	if (retval)
 		return retval;
@@ -1380,12 +1384,8 @@ int search_binary_handler(struct linux_binprm *bprm)
 			if (!try_module_get(fmt->module))
 				continue;
 			read_unlock(&binfmt_lock);
+			bprm->recursion_depth = depth + 1;
 			retval = fn(bprm);
-			/*
-			 * Restore the depth counter to its starting value
-			 * in this call, so we don't have to rely on every
-			 * load_binary function to restore it on return.
-			 */
 			bprm->recursion_depth = depth;
 			if (retval >= 0) {
 				if (depth == 0) {

commit 6a2b60b17b3e48a418695a94bd2420f6ab32e519
Merge: 9228ff90387e 98f842e675f9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 17 15:44:47 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull user namespace changes from Eric Biederman:
     "While small this set of changes is very significant with respect to
      containers in general and user namespaces in particular.  The user
      space interface is now complete.
    
      This set of changes adds support for unprivileged users to create user
      namespaces and as a user namespace root to create other namespaces.
      The tyranny of supporting suid root preventing unprivileged users from
      using cool new kernel features is broken.
    
      This set of changes completes the work on setns, adding support for
      the pid, user, mount namespaces.
    
      This set of changes includes a bunch of basic pid namespace
      cleanups/simplifications.  Of particular significance is the rework of
      the pid namespace cleanup so it no longer requires sending out
      tendrils into all kinds of unexpected cleanup paths for operation.  At
      least one case of broken error handling is fixed by this cleanup.
    
      The files under /proc/<pid>/ns/ have been converted from regular files
      to magic symlinks which prevents incorrect caching by the VFS,
      ensuring the files always refer to the namespace the process is
      currently using and ensuring that the ptrace_mayaccess permission
      checks are always applied.
    
      The files under /proc/<pid>/ns/ have been given stable inode numbers
      so it is now possible to see if different processes share the same
      namespaces.
    
      Through the David Miller's net tree are changes to relax many of the
      permission checks in the networking stack to allowing the user
      namespace root to usefully use the networking stack.  Similar changes
      for the mount namespace and the pid namespace are coming through my
      tree.
    
      Two small changes to add user namespace support were commited here adn
      in David Miller's -net tree so that I could complete the work on the
      /proc/<pid>/ns/ files in this tree.
    
      Work remains to make it safe to build user namespaces and 9p, afs,
      ceph, cifs, coda, gfs2, ncpfs, nfs, nfsd, ocfs2, and xfs so the
      Kconfig guard remains in place preventing that user namespaces from
      being built when any of those filesystems are enabled.
    
      Future design work remains to allow root users outside of the initial
      user namespace to mount more than just /proc and /sys."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (38 commits)
      proc: Usable inode numbers for the namespace file descriptors.
      proc: Fix the namespace inode permission checks.
      proc: Generalize proc inode allocation
      userns: Allow unprivilged mounts of proc and sysfs
      userns: For /proc/self/{uid,gid}_map derive the lower userns from the struct file
      procfs: Print task uids and gids in the userns that opened the proc file
      userns: Implement unshare of the user namespace
      userns: Implent proc namespace operations
      userns: Kill task_user_ns
      userns: Make create_new_namespaces take a user_ns parameter
      userns: Allow unprivileged use of setns.
      userns: Allow unprivileged users to create new namespaces
      userns: Allow setting a userns mapping to your current uid.
      userns: Allow chown and setgid preservation
      userns: Allow unprivileged users to create user namespaces.
      userns: Ignore suid and sgid on binaries if the uid or gid can not be mapped
      userns: fix return value on mntns_install() failure
      vfs: Allow unprivileged manipulation of the mount namespace.
      vfs: Only support slave subtrees across different user namespaces
      vfs: Add a user namespace reference from struct mnt_namespace
      ...

commit 71613c3b871c5a9f27cc48f124251bcd3aa23be1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Oct 20 22:00:48 2012 -0400

    get rid of pt_regs argument of ->load_binary()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 2aee7ef10663..721a29929511 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1374,13 +1374,13 @@ int search_binary_handler(struct linux_binprm *bprm)
 	for (try=0; try<2; try++) {
 		read_lock(&binfmt_lock);
 		list_for_each_entry(fmt, &formats, lh) {
-			int (*fn)(struct linux_binprm *, struct pt_regs *) = fmt->load_binary;
+			int (*fn)(struct linux_binprm *) = fmt->load_binary;
 			if (!fn)
 				continue;
 			if (!try_module_get(fmt->module))
 				continue;
 			read_unlock(&binfmt_lock);
-			retval = fn(bprm, current_pt_regs());
+			retval = fn(bprm);
 			/*
 			 * Restore the depth counter to its starting value
 			 * in this call, so we don't have to rely on every

commit 3c456bfc4ba66e9cda210da7bc4fb0ba9fcc6972
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Oct 20 21:53:31 2012 -0400

    get rid of pt_regs argument of search_binary_handler()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index dc5e2830d353..2aee7ef10663 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1349,7 +1349,7 @@ EXPORT_SYMBOL(remove_arg_zero);
 /*
  * cycle the list of binary formats handler, until one recognizes the image
  */
-int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
+int search_binary_handler(struct linux_binprm *bprm)
 {
 	unsigned int depth = bprm->recursion_depth;
 	int try,retval;
@@ -1380,7 +1380,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			if (!try_module_get(fmt->module))
 				continue;
 			read_unlock(&binfmt_lock);
-			retval = fn(bprm, regs);
+			retval = fn(bprm, current_pt_regs());
 			/*
 			 * Restore the depth counter to its starting value
 			 * in this call, so we don't have to rely on every
@@ -1447,7 +1447,6 @@ static int do_execve_common(const char *filename,
 	bool clear_in_exec;
 	int retval;
 	const struct cred *cred = current_cred();
-	struct pt_regs *regs = current_pt_regs();
 
 	/*
 	 * We move the actual failure in case of RLIMIT_NPROC excess from
@@ -1524,7 +1523,7 @@ static int do_execve_common(const char *filename,
 	if (retval < 0)
 		goto out;
 
-	retval = search_binary_handler(bprm,regs);
+	retval = search_binary_handler(bprm);
 	if (retval < 0)
 		goto out;
 

commit 835ab32dff6b437e74c266468b83c4abb69041dc
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Oct 20 21:50:59 2012 -0400

    get rid of pt_regs argument of do_execve_common()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 5797ed07efd3..dc5e2830d353 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1439,8 +1439,7 @@ EXPORT_SYMBOL(search_binary_handler);
  */
 static int do_execve_common(const char *filename,
 				struct user_arg_ptr argv,
-				struct user_arg_ptr envp,
-				struct pt_regs *regs)
+				struct user_arg_ptr envp)
 {
 	struct linux_binprm *bprm;
 	struct file *file;
@@ -1448,6 +1447,7 @@ static int do_execve_common(const char *filename,
 	bool clear_in_exec;
 	int retval;
 	const struct cred *cred = current_cred();
+	struct pt_regs *regs = current_pt_regs();
 
 	/*
 	 * We move the actual failure in case of RLIMIT_NPROC excess from
@@ -1570,7 +1570,7 @@ int do_execve(const char *filename,
 {
 	struct user_arg_ptr argv = { .ptr.native = __argv };
 	struct user_arg_ptr envp = { .ptr.native = __envp };
-	return do_execve_common(filename, argv, envp, current_pt_regs());
+	return do_execve_common(filename, argv, envp);
 }
 
 #ifdef CONFIG_COMPAT
@@ -1586,7 +1586,7 @@ static int compat_do_execve(const char *filename,
 		.is_compat = true,
 		.ptr.compat = __envp,
 	};
-	return do_execve_common(filename, argv, envp, current_pt_regs());
+	return do_execve_common(filename, argv, envp);
 }
 #endif
 

commit da3d4c5fa56236dd924d77ffc4f982356816b93b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Oct 20 21:49:33 2012 -0400

    get rid of pt_regs argument of do_execve()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index f86b6cc2d6cc..5797ed07efd3 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1566,12 +1566,11 @@ static int do_execve_common(const char *filename,
 
 int do_execve(const char *filename,
 	const char __user *const __user *__argv,
-	const char __user *const __user *__envp,
-	struct pt_regs *regs)
+	const char __user *const __user *__envp)
 {
 	struct user_arg_ptr argv = { .ptr.native = __argv };
 	struct user_arg_ptr envp = { .ptr.native = __envp };
-	return do_execve_common(filename, argv, envp, regs);
+	return do_execve_common(filename, argv, envp, current_pt_regs());
 }
 
 #ifdef CONFIG_COMPAT
@@ -1668,7 +1667,7 @@ SYSCALL_DEFINE3(execve,
 	struct filename *path = getname(filename);
 	int error = PTR_ERR(path);
 	if (!IS_ERR(path)) {
-		error = do_execve(path->name, argv, envp, current_pt_regs());
+		error = do_execve(path->name, argv, envp);
 		putname(path);
 	}
 	return error;
@@ -1694,12 +1693,9 @@ int kernel_execve(const char *filename,
 		  const char *const argv[],
 		  const char *const envp[])
 {
-	struct pt_regs *p = current_pt_regs();
-	int ret;
-
-	ret = do_execve(filename,
+	int ret = do_execve(filename,
 			(const char __user *const __user *)argv,
-			(const char __user *const __user *)envp, p);
+			(const char __user *const __user *)envp);
 	if (ret < 0)
 		return ret;
 
@@ -1707,6 +1703,6 @@ int kernel_execve(const char *filename,
 	 * We were successful.  We won't be returning to our caller, but
 	 * instead to user space by manipulating the kernel stack.
 	 */
-	ret_from_kernel_execve(p);
+	ret_from_kernel_execve(current_pt_regs());
 }
 #endif

commit d03d26e58fde2ec99478e26aab47b55755189b08
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Oct 20 21:46:25 2012 -0400

    make compat_do_execve() static, lose pt_regs argument
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 0039055b1fc6..f86b6cc2d6cc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1575,10 +1575,9 @@ int do_execve(const char *filename,
 }
 
 #ifdef CONFIG_COMPAT
-int compat_do_execve(const char *filename,
+static int compat_do_execve(const char *filename,
 	const compat_uptr_t __user *__argv,
-	const compat_uptr_t __user *__envp,
-	struct pt_regs *regs)
+	const compat_uptr_t __user *__envp)
 {
 	struct user_arg_ptr argv = {
 		.is_compat = true,
@@ -1588,7 +1587,7 @@ int compat_do_execve(const char *filename,
 		.is_compat = true,
 		.ptr.compat = __envp,
 	};
-	return do_execve_common(filename, argv, envp, regs);
+	return do_execve_common(filename, argv, envp, current_pt_regs());
 }
 #endif
 
@@ -1682,8 +1681,7 @@ asmlinkage long compat_sys_execve(const char __user * filename,
 	struct filename *path = getname(filename);
 	int error = PTR_ERR(path);
 	if (!IS_ERR(path)) {
-		error = compat_do_execve(path->name, argv, envp,
-							current_pt_regs());
+		error = compat_do_execve(path->name, argv, envp);
 		putname(path);
 	}
 	return error;

commit 3cdf5b45ffbac294bcdfac0393df72f7687c01e8
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Nov 21 16:40:54 2011 -0800

    userns: Ignore suid and sgid on binaries if the uid or gid can not be mapped
    
    When performing an exec where the binary lives in one user namespace and
    the execing process lives in another usre namespace there is the possibility
    that the target uids can not be represented.
    
    Instead of failing the exec simply ignore the suid/sgid bits and run
    the binary with lower privileges.   We already do this in the case
    of MNT_NOSUID so this should be a well tested code path.
    
    As the user and group are not changed this should not introduce any
    security issues.
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 0039055b1fc6..aef0c2f19750 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1266,14 +1266,13 @@ int prepare_binprm(struct linux_binprm *bprm)
 	bprm->cred->egid = current_egid();
 
 	if (!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID) &&
-	    !current->no_new_privs) {
+	    !current->no_new_privs &&
+	    kuid_has_mapping(bprm->cred->user_ns, inode->i_uid) &&
+	    kgid_has_mapping(bprm->cred->user_ns, inode->i_gid)) {
 		/* Set-uid? */
 		if (mode & S_ISUID) {
-			if (!kuid_has_mapping(bprm->cred->user_ns, inode->i_uid))
-				return -EPERM;
 			bprm->per_clear |= PER_CLEAR_ON_SETID;
 			bprm->cred->euid = inode->i_uid;
-
 		}
 
 		/* Set-gid? */
@@ -1283,8 +1282,6 @@ int prepare_binprm(struct linux_binprm *bprm)
 		 * executable.
 		 */
 		if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP)) {
-			if (!kgid_has_mapping(bprm->cred->user_ns, inode->i_gid))
-				return -EPERM;
 			bprm->per_clear |= PER_CLEAR_ON_SETID;
 			bprm->cred->egid = inode->i_gid;
 		}

commit b40a79591ca918e7b91b0d9b6abd5d00f2e88c19
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Oct 25 22:28:12 2012 +0200

    freezer: exec should clear PF_NOFREEZE along with PF_KTHREAD
    
    flush_old_exec() clears PF_KTHREAD but forgets about PF_NOFREEZE.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Cc: stable@vger.kernel.org
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/fs/exec.c b/fs/exec.c
index 8b9011b67041..0039055b1fc6 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1083,7 +1083,8 @@ int flush_old_exec(struct linux_binprm * bprm)
 	bprm->mm = NULL;		/* We're using it now */
 
 	set_fs(USER_DS);
-	current->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD);
+	current->flags &=
+		~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD | PF_NOFREEZE);
 	flush_thread();
 	current->personality &= ~bprm->per_clear;
 

commit 669abf4e5539c8aa48bf28c965be05c0a7b58a27
Author: Jeff Layton <jlayton@redhat.com>
Date:   Wed Oct 10 16:43:10 2012 -0400

    vfs: make path_openat take a struct filename pointer
    
    ...and fix up the callers. For do_file_open_root, just declare a
    struct filename on the stack and fill out the .name field. For
    do_filp_open, make it also take a struct filename pointer, and fix up its
    callers to call it appropriately.
    
    For filp_open, add a variant that takes a struct filename pointer and turn
    filp_open into a wrapper around it.
    
    Signed-off-by: Jeff Layton <jlayton@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 4e591e20e108..8b9011b67041 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -116,7 +116,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 	if (IS_ERR(tmp))
 		goto out;
 
-	file = do_filp_open(AT_FDCWD, tmp->name, &uselib_flags, LOOKUP_FOLLOW);
+	file = do_filp_open(AT_FDCWD, tmp, &uselib_flags, LOOKUP_FOLLOW);
 	putname(tmp);
 	error = PTR_ERR(file);
 	if (IS_ERR(file))
@@ -751,13 +751,14 @@ struct file *open_exec(const char *name)
 {
 	struct file *file;
 	int err;
+	struct filename tmp = { .name = name };
 	static const struct open_flags open_exec_flags = {
 		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
 		.acc_mode = MAY_EXEC | MAY_OPEN,
 		.intent = LOOKUP_OPEN
 	};
 
-	file = do_filp_open(AT_FDCWD, name, &open_exec_flags, LOOKUP_FOLLOW);
+	file = do_filp_open(AT_FDCWD, &tmp, &open_exec_flags, LOOKUP_FOLLOW);
 	if (IS_ERR(file))
 		goto out;
 

commit 91a27b2a756784714e924e5e854b919273082d26
Author: Jeff Layton <jlayton@redhat.com>
Date:   Wed Oct 10 15:25:28 2012 -0400

    vfs: define struct filename and have getname() return it
    
    getname() is intended to copy pathname strings from userspace into a
    kernel buffer. The result is just a string in kernel space. It would
    however be quite helpful to be able to attach some ancillary info to
    the string.
    
    For instance, we could attach some audit-related info to reduce the
    amount of audit-related processing needed. When auditing is enabled,
    we could also call getname() on the string more than once and not
    need to recopy it from userspace.
    
    This patchset converts the getname()/putname() interfaces to return
    a struct instead of a string. For now, the struct just tracks the
    string in kernel space and the original userland pointer for it.
    
    Later, we'll add other information to the struct as it becomes
    convenient.
    
    Signed-off-by: Jeff Layton <jlayton@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index ca434534ae9a..4e591e20e108 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -105,7 +105,7 @@ static inline void put_binfmt(struct linux_binfmt * fmt)
 SYSCALL_DEFINE1(uselib, const char __user *, library)
 {
 	struct file *file;
-	char *tmp = getname(library);
+	struct filename *tmp = getname(library);
 	int error = PTR_ERR(tmp);
 	static const struct open_flags uselib_flags = {
 		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
@@ -116,7 +116,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 	if (IS_ERR(tmp))
 		goto out;
 
-	file = do_filp_open(AT_FDCWD, tmp, &uselib_flags, LOOKUP_FOLLOW);
+	file = do_filp_open(AT_FDCWD, tmp->name, &uselib_flags, LOOKUP_FOLLOW);
 	putname(tmp);
 	error = PTR_ERR(file);
 	if (IS_ERR(file))
@@ -1664,10 +1664,10 @@ SYSCALL_DEFINE3(execve,
 		const char __user *const __user *, argv,
 		const char __user *const __user *, envp)
 {
-	const char *path = getname(filename);
+	struct filename *path = getname(filename);
 	int error = PTR_ERR(path);
 	if (!IS_ERR(path)) {
-		error = do_execve(path, argv, envp, current_pt_regs());
+		error = do_execve(path->name, argv, envp, current_pt_regs());
 		putname(path);
 	}
 	return error;
@@ -1677,10 +1677,11 @@ asmlinkage long compat_sys_execve(const char __user * filename,
 	const compat_uptr_t __user * argv,
 	const compat_uptr_t __user * envp)
 {
-	const char *path = getname(filename);
+	struct filename *path = getname(filename);
 	int error = PTR_ERR(path);
 	if (!IS_ERR(path)) {
-		error = compat_do_execve(path, argv, envp, current_pt_regs());
+		error = compat_do_execve(path->name, argv, envp,
+							current_pt_regs());
 		putname(path);
 	}
 	return error;

commit 42859eea96ba6beabfb0369a1eeffa3c7d2bd9cb
Merge: f59b51fe3d30 f322220d6159
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 10 12:02:25 2012 +0900

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull generic execve() changes from Al Viro:
     "This introduces the generic kernel_thread() and kernel_execve()
      functions, and switches x86, arm, alpha, um and s390 over to them."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal: (26 commits)
      s390: convert to generic kernel_execve()
      s390: switch to generic kernel_thread()
      s390: fold kernel_thread_helper() into ret_from_fork()
      s390: fold execve_tail() into start_thread(), convert to generic sys_execve()
      um: switch to generic kernel_thread()
      x86, um/x86: switch to generic sys_execve and kernel_execve
      x86: split ret_from_fork
      alpha: introduce ret_from_kernel_execve(), switch to generic kernel_execve()
      alpha: switch to generic kernel_thread()
      alpha: switch to generic sys_execve()
      arm: get rid of execve wrapper, switch to generic execve() implementation
      arm: optimized current_pt_regs()
      arm: introduce ret_from_kernel_execve(), switch to generic kernel_execve()
      arm: split ret_from_fork, simplify kernel_thread() [based on patch by rmk]
      generic sys_execve()
      generic kernel_execve()
      new helper: current_pt_regs()
      preparation for generic kernel_thread()
      um: kill thread->forking
      um: let signal_delivered() do SIGTRAP on singlestepping into handler
      ...

commit 38a76013ad809beb0b52f60d365c960d035bd83c
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Oct 8 16:31:50 2012 -0700

    mm: avoid taking rmap locks in move_ptes()
    
    During mremap(), the destination VMA is generally placed after the
    original vma in rmap traversal order: in move_vma(), we always have
    new_pgoff >= vma->vm_pgoff, and as a result new_vma->vm_pgoff >=
    vma->vm_pgoff unless vma_merge() merged the new vma with an adjacent one.
    
    When the destination VMA is placed after the original in rmap traversal
    order, we can avoid taking the rmap locks in move_ptes().
    
    Essentially, this reintroduces the optimization that had been disabled in
    "mm anon rmap: remove anon_vma_moveto_tail".  The difference is that we
    don't try to impose the rmap traversal order; instead we just rely on
    things being in the desired order in the common case and fall back to
    taking locks in the uncommon case.  Also we skip the i_mmap_mutex in
    addition to the anon_vma lock: in both cases, the vmas are traversed in
    increasing vm_pgoff order with ties resolved in tree insertion order.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Daniel Santos <daniel.santos@pobox.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 19f4fb80cd17..4f2bebc276c5 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -603,7 +603,7 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 	 * process cleanup to remove whatever mess we made.
 	 */
 	if (length != move_page_tables(vma, old_start,
-				       vma, new_start, length))
+				       vma, new_start, length, false))
 		return -ENOMEM;
 
 	lru_add_drain();

commit d5bbd43d5f450c3fca058f5b85f3dfb4e8cc88c9
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Oct 8 19:13:01 2012 +0200

    exec: make de_thread() killable
    
    Change de_thread() to use KILLABLE rather than UNINTERRUPTIBLE while
    waiting for other threads.  The only complication is that we should
    clear ->group_exit_task and ->notify_count before we return, and we
    should do this under tasklist_lock.  -EAGAIN is used to match the
    initial signal_group_exit() check/return, it doesn't really matter.
    
    This fixes the (unlikely) race with coredump.  de_thread() checks
    signal_group_exit() before it starts to kill the subthreads, but this
    can't help if another CLONE_VM (but non CLONE_THREAD) task starts the
    coredumping after de_thread() unlocks ->siglock.  In this case the
    killed sub-thread can block in exit_mm() waiting for coredump_finish(),
    execing thread waits for that sub-thead, and the coredumping thread
    waits for execing thread.  Deadlock.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9824473a7ec1..19f4fb80cd17 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -878,9 +878,11 @@ static int de_thread(struct task_struct *tsk)
 		sig->notify_count--;
 
 	while (sig->notify_count) {
-		__set_current_state(TASK_UNINTERRUPTIBLE);
+		__set_current_state(TASK_KILLABLE);
 		spin_unlock_irq(lock);
 		schedule();
+		if (unlikely(__fatal_signal_pending(tsk)))
+			goto killed;
 		spin_lock_irq(lock);
 	}
 	spin_unlock_irq(lock);
@@ -898,9 +900,11 @@ static int de_thread(struct task_struct *tsk)
 			write_lock_irq(&tasklist_lock);
 			if (likely(leader->exit_state))
 				break;
-			__set_current_state(TASK_UNINTERRUPTIBLE);
+			__set_current_state(TASK_KILLABLE);
 			write_unlock_irq(&tasklist_lock);
 			schedule();
+			if (unlikely(__fatal_signal_pending(tsk)))
+				goto killed;
 		}
 
 		/*
@@ -994,6 +998,14 @@ static int de_thread(struct task_struct *tsk)
 
 	BUG_ON(!thread_group_leader(tsk));
 	return 0;
+
+killed:
+	/* protects against exit_notify() and __exit_signal() */
+	read_lock(&tasklist_lock);
+	sig->group_exit_task = NULL;
+	sig->notify_count = 0;
+	read_unlock(&tasklist_lock);
+	return -EAGAIN;
 }
 
 char *get_task_comm(char *buf, struct task_struct *tsk)

commit 0f4cfb2e4e7a7e4e97a3e90e2ba1062f07fb2cb1
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Oct 4 17:15:27 2012 -0700

    coredump: use SUID_DUMPABLE_ENABLED rather than hardcoded 1
    
    Cosmetic. Change setup_new_exec() and task_dumpable() to use
    SUID_DUMPABLE_ENABLED for /bin/grep.
    
    [akpm@linux-foundation.org: checkpatch fixes]
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index bd941a1cdbfc..9824473a7ec1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1097,7 +1097,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
 	if (uid_eq(current_euid(), current_uid()) && gid_eq(current_egid(), current_gid()))
-		set_dumpable(current->mm, 1);
+		set_dumpable(current->mm, SUID_DUMPABLE_ENABLED);
 	else
 		set_dumpable(current->mm, suid_dumpable);
 

commit 179899fd5dc780fe3bcd44d0eb7823e3d855c855
Author: Alex Kelly <alex.page.kelly@gmail.com>
Date:   Thu Oct 4 17:15:24 2012 -0700

    coredump: update coredump-related headers
    
    Create a new header file, fs/coredump.h, which contains functions only
    used by the new coredump.c.  It also moves do_coredump to the
    include/linux/coredump.h header file, for consistency.
    
    Signed-off-by: Alex Kelly <alex.page.kelly@gmail.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 48fb26ef8a1b..bd941a1cdbfc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -63,6 +63,7 @@
 
 #include <trace/events/task.h>
 #include "internal.h"
+#include "coredump.h"
 
 #include <trace/events/sched.h>
 

commit 10c28d937e2cca577c2d804106b50dd0562fb062
Author: Alex Kelly <alex.page.kelly@gmail.com>
Date:   Wed Sep 26 21:52:08 2012 -0400

    coredump: move core dump functionality into its own file
    
    This prepares for making core dump functionality optional.
    
    The variable "suid_dumpable" and associated functions are left in fs/exec.c
    because they're used elsewhere, such as in ptrace.
    
    Signed-off-by: Alex Kelly <alex.page.kelly@gmail.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index beb05a95e4a3..48fb26ef8a1b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -66,19 +66,8 @@
 
 #include <trace/events/sched.h>
 
-int core_uses_pid;
-char core_pattern[CORENAME_MAX_SIZE] = "core";
-unsigned int core_pipe_limit;
 int suid_dumpable = 0;
 
-struct core_name {
-	char *corename;
-	int used, size;
-};
-static atomic_t call_count = ATOMIC_INIT(1);
-
-/* The maximal length of core_pattern is also specified in sysctl.c */
-
 static LIST_HEAD(formats);
 static DEFINE_RWLOCK(binfmt_lock);
 
@@ -1603,353 +1592,6 @@ void set_binfmt(struct linux_binfmt *new)
 
 EXPORT_SYMBOL(set_binfmt);
 
-static int expand_corename(struct core_name *cn)
-{
-	char *old_corename = cn->corename;
-
-	cn->size = CORENAME_MAX_SIZE * atomic_inc_return(&call_count);
-	cn->corename = krealloc(old_corename, cn->size, GFP_KERNEL);
-
-	if (!cn->corename) {
-		kfree(old_corename);
-		return -ENOMEM;
-	}
-
-	return 0;
-}
-
-static int cn_printf(struct core_name *cn, const char *fmt, ...)
-{
-	char *cur;
-	int need;
-	int ret;
-	va_list arg;
-
-	va_start(arg, fmt);
-	need = vsnprintf(NULL, 0, fmt, arg);
-	va_end(arg);
-
-	if (likely(need < cn->size - cn->used - 1))
-		goto out_printf;
-
-	ret = expand_corename(cn);
-	if (ret)
-		goto expand_fail;
-
-out_printf:
-	cur = cn->corename + cn->used;
-	va_start(arg, fmt);
-	vsnprintf(cur, need + 1, fmt, arg);
-	va_end(arg);
-	cn->used += need;
-	return 0;
-
-expand_fail:
-	return ret;
-}
-
-static void cn_escape(char *str)
-{
-	for (; *str; str++)
-		if (*str == '/')
-			*str = '!';
-}
-
-static int cn_print_exe_file(struct core_name *cn)
-{
-	struct file *exe_file;
-	char *pathbuf, *path;
-	int ret;
-
-	exe_file = get_mm_exe_file(current->mm);
-	if (!exe_file) {
-		char *commstart = cn->corename + cn->used;
-		ret = cn_printf(cn, "%s (path unknown)", current->comm);
-		cn_escape(commstart);
-		return ret;
-	}
-
-	pathbuf = kmalloc(PATH_MAX, GFP_TEMPORARY);
-	if (!pathbuf) {
-		ret = -ENOMEM;
-		goto put_exe_file;
-	}
-
-	path = d_path(&exe_file->f_path, pathbuf, PATH_MAX);
-	if (IS_ERR(path)) {
-		ret = PTR_ERR(path);
-		goto free_buf;
-	}
-
-	cn_escape(path);
-
-	ret = cn_printf(cn, "%s", path);
-
-free_buf:
-	kfree(pathbuf);
-put_exe_file:
-	fput(exe_file);
-	return ret;
-}
-
-/* format_corename will inspect the pattern parameter, and output a
- * name into corename, which must have space for at least
- * CORENAME_MAX_SIZE bytes plus one byte for the zero terminator.
- */
-static int format_corename(struct core_name *cn, long signr)
-{
-	const struct cred *cred = current_cred();
-	const char *pat_ptr = core_pattern;
-	int ispipe = (*pat_ptr == '|');
-	int pid_in_pattern = 0;
-	int err = 0;
-
-	cn->size = CORENAME_MAX_SIZE * atomic_read(&call_count);
-	cn->corename = kmalloc(cn->size, GFP_KERNEL);
-	cn->used = 0;
-
-	if (!cn->corename)
-		return -ENOMEM;
-
-	/* Repeat as long as we have more pattern to process and more output
-	   space */
-	while (*pat_ptr) {
-		if (*pat_ptr != '%') {
-			if (*pat_ptr == 0)
-				goto out;
-			err = cn_printf(cn, "%c", *pat_ptr++);
-		} else {
-			switch (*++pat_ptr) {
-			/* single % at the end, drop that */
-			case 0:
-				goto out;
-			/* Double percent, output one percent */
-			case '%':
-				err = cn_printf(cn, "%c", '%');
-				break;
-			/* pid */
-			case 'p':
-				pid_in_pattern = 1;
-				err = cn_printf(cn, "%d",
-					      task_tgid_vnr(current));
-				break;
-			/* uid */
-			case 'u':
-				err = cn_printf(cn, "%d", cred->uid);
-				break;
-			/* gid */
-			case 'g':
-				err = cn_printf(cn, "%d", cred->gid);
-				break;
-			/* signal that caused the coredump */
-			case 's':
-				err = cn_printf(cn, "%ld", signr);
-				break;
-			/* UNIX time of coredump */
-			case 't': {
-				struct timeval tv;
-				do_gettimeofday(&tv);
-				err = cn_printf(cn, "%lu", tv.tv_sec);
-				break;
-			}
-			/* hostname */
-			case 'h': {
-				char *namestart = cn->corename + cn->used;
-				down_read(&uts_sem);
-				err = cn_printf(cn, "%s",
-					      utsname()->nodename);
-				up_read(&uts_sem);
-				cn_escape(namestart);
-				break;
-			}
-			/* executable */
-			case 'e': {
-				char *commstart = cn->corename + cn->used;
-				err = cn_printf(cn, "%s", current->comm);
-				cn_escape(commstart);
-				break;
-			}
-			case 'E':
-				err = cn_print_exe_file(cn);
-				break;
-			/* core limit size */
-			case 'c':
-				err = cn_printf(cn, "%lu",
-					      rlimit(RLIMIT_CORE));
-				break;
-			default:
-				break;
-			}
-			++pat_ptr;
-		}
-
-		if (err)
-			return err;
-	}
-
-	/* Backward compatibility with core_uses_pid:
-	 *
-	 * If core_pattern does not include a %p (as is the default)
-	 * and core_uses_pid is set, then .%pid will be appended to
-	 * the filename. Do not do this for piped commands. */
-	if (!ispipe && !pid_in_pattern && core_uses_pid) {
-		err = cn_printf(cn, ".%d", task_tgid_vnr(current));
-		if (err)
-			return err;
-	}
-out:
-	return ispipe;
-}
-
-static int zap_process(struct task_struct *start, int exit_code)
-{
-	struct task_struct *t;
-	int nr = 0;
-
-	start->signal->flags = SIGNAL_GROUP_EXIT;
-	start->signal->group_exit_code = exit_code;
-	start->signal->group_stop_count = 0;
-
-	t = start;
-	do {
-		task_clear_jobctl_pending(t, JOBCTL_PENDING_MASK);
-		if (t != current && t->mm) {
-			sigaddset(&t->pending.signal, SIGKILL);
-			signal_wake_up(t, 1);
-			nr++;
-		}
-	} while_each_thread(start, t);
-
-	return nr;
-}
-
-static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
-				struct core_state *core_state, int exit_code)
-{
-	struct task_struct *g, *p;
-	unsigned long flags;
-	int nr = -EAGAIN;
-
-	spin_lock_irq(&tsk->sighand->siglock);
-	if (!signal_group_exit(tsk->signal)) {
-		mm->core_state = core_state;
-		nr = zap_process(tsk, exit_code);
-	}
-	spin_unlock_irq(&tsk->sighand->siglock);
-	if (unlikely(nr < 0))
-		return nr;
-
-	if (atomic_read(&mm->mm_users) == nr + 1)
-		goto done;
-	/*
-	 * We should find and kill all tasks which use this mm, and we should
-	 * count them correctly into ->nr_threads. We don't take tasklist
-	 * lock, but this is safe wrt:
-	 *
-	 * fork:
-	 *	None of sub-threads can fork after zap_process(leader). All
-	 *	processes which were created before this point should be
-	 *	visible to zap_threads() because copy_process() adds the new
-	 *	process to the tail of init_task.tasks list, and lock/unlock
-	 *	of ->siglock provides a memory barrier.
-	 *
-	 * do_exit:
-	 *	The caller holds mm->mmap_sem. This means that the task which
-	 *	uses this mm can't pass exit_mm(), so it can't exit or clear
-	 *	its ->mm.
-	 *
-	 * de_thread:
-	 *	It does list_replace_rcu(&leader->tasks, &current->tasks),
-	 *	we must see either old or new leader, this does not matter.
-	 *	However, it can change p->sighand, so lock_task_sighand(p)
-	 *	must be used. Since p->mm != NULL and we hold ->mmap_sem
-	 *	it can't fail.
-	 *
-	 *	Note also that "g" can be the old leader with ->mm == NULL
-	 *	and already unhashed and thus removed from ->thread_group.
-	 *	This is OK, __unhash_process()->list_del_rcu() does not
-	 *	clear the ->next pointer, we will find the new leader via
-	 *	next_thread().
-	 */
-	rcu_read_lock();
-	for_each_process(g) {
-		if (g == tsk->group_leader)
-			continue;
-		if (g->flags & PF_KTHREAD)
-			continue;
-		p = g;
-		do {
-			if (p->mm) {
-				if (unlikely(p->mm == mm)) {
-					lock_task_sighand(p, &flags);
-					nr += zap_process(p, exit_code);
-					unlock_task_sighand(p, &flags);
-				}
-				break;
-			}
-		} while_each_thread(g, p);
-	}
-	rcu_read_unlock();
-done:
-	atomic_set(&core_state->nr_threads, nr);
-	return nr;
-}
-
-static int coredump_wait(int exit_code, struct core_state *core_state)
-{
-	struct task_struct *tsk = current;
-	struct mm_struct *mm = tsk->mm;
-	int core_waiters = -EBUSY;
-
-	init_completion(&core_state->startup);
-	core_state->dumper.task = tsk;
-	core_state->dumper.next = NULL;
-
-	down_write(&mm->mmap_sem);
-	if (!mm->core_state)
-		core_waiters = zap_threads(tsk, mm, core_state, exit_code);
-	up_write(&mm->mmap_sem);
-
-	if (core_waiters > 0) {
-		struct core_thread *ptr;
-
-		wait_for_completion(&core_state->startup);
-		/*
-		 * Wait for all the threads to become inactive, so that
-		 * all the thread context (extended register state, like
-		 * fpu etc) gets copied to the memory.
-		 */
-		ptr = core_state->dumper.next;
-		while (ptr != NULL) {
-			wait_task_inactive(ptr->task, 0);
-			ptr = ptr->next;
-		}
-	}
-
-	return core_waiters;
-}
-
-static void coredump_finish(struct mm_struct *mm)
-{
-	struct core_thread *curr, *next;
-	struct task_struct *task;
-
-	next = mm->core_state->dumper.next;
-	while ((curr = next) != NULL) {
-		next = curr->next;
-		task = curr->task;
-		/*
-		 * see exit_mm(), curr->task must not see
-		 * ->task == NULL before we read ->next.
-		 */
-		smp_mb();
-		curr->task = NULL;
-		wake_up_process(task);
-	}
-
-	mm->core_state = NULL;
-}
-
 /*
  * set_dumpable converts traditional three-value dumpable to two flags and
  * stores them into mm->flags.  It modifies lower two bits of mm->flags, but
@@ -1991,7 +1633,7 @@ void set_dumpable(struct mm_struct *mm, int value)
 	}
 }
 
-static int __get_dumpable(unsigned long mm_flags)
+int __get_dumpable(unsigned long mm_flags)
 {
 	int ret;
 
@@ -2003,288 +1645,3 @@ int get_dumpable(struct mm_struct *mm)
 {
 	return __get_dumpable(mm->flags);
 }
-
-static void wait_for_dump_helpers(struct file *file)
-{
-	struct pipe_inode_info *pipe;
-
-	pipe = file->f_path.dentry->d_inode->i_pipe;
-
-	pipe_lock(pipe);
-	pipe->readers++;
-	pipe->writers--;
-
-	while ((pipe->readers > 1) && (!signal_pending(current))) {
-		wake_up_interruptible_sync(&pipe->wait);
-		kill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);
-		pipe_wait(pipe);
-	}
-
-	pipe->readers--;
-	pipe->writers++;
-	pipe_unlock(pipe);
-
-}
-
-
-/*
- * umh_pipe_setup
- * helper function to customize the process used
- * to collect the core in userspace.  Specifically
- * it sets up a pipe and installs it as fd 0 (stdin)
- * for the process.  Returns 0 on success, or
- * PTR_ERR on failure.
- * Note that it also sets the core limit to 1.  This
- * is a special value that we use to trap recursive
- * core dumps
- */
-static int umh_pipe_setup(struct subprocess_info *info, struct cred *new)
-{
-	struct file *files[2];
-	struct coredump_params *cp = (struct coredump_params *)info->data;
-	int err = create_pipe_files(files, 0);
-	if (err)
-		return err;
-
-	cp->file = files[1];
-
-	replace_fd(0, files[0], 0);
-	/* and disallow core files too */
-	current->signal->rlim[RLIMIT_CORE] = (struct rlimit){1, 1};
-
-	return 0;
-}
-
-void do_coredump(long signr, int exit_code, struct pt_regs *regs)
-{
-	struct core_state core_state;
-	struct core_name cn;
-	struct mm_struct *mm = current->mm;
-	struct linux_binfmt * binfmt;
-	const struct cred *old_cred;
-	struct cred *cred;
-	int retval = 0;
-	int flag = 0;
-	int ispipe;
-	struct files_struct *displaced;
-	bool need_nonrelative = false;
-	static atomic_t core_dump_count = ATOMIC_INIT(0);
-	struct coredump_params cprm = {
-		.signr = signr,
-		.regs = regs,
-		.limit = rlimit(RLIMIT_CORE),
-		/*
-		 * We must use the same mm->flags while dumping core to avoid
-		 * inconsistency of bit flags, since this flag is not protected
-		 * by any locks.
-		 */
-		.mm_flags = mm->flags,
-	};
-
-	audit_core_dumps(signr);
-
-	binfmt = mm->binfmt;
-	if (!binfmt || !binfmt->core_dump)
-		goto fail;
-	if (!__get_dumpable(cprm.mm_flags))
-		goto fail;
-
-	cred = prepare_creds();
-	if (!cred)
-		goto fail;
-	/*
-	 * We cannot trust fsuid as being the "true" uid of the process
-	 * nor do we know its entire history. We only know it was tainted
-	 * so we dump it as root in mode 2, and only into a controlled
-	 * environment (pipe handler or fully qualified path).
-	 */
-	if (__get_dumpable(cprm.mm_flags) == SUID_DUMPABLE_SAFE) {
-		/* Setuid core dump mode */
-		flag = O_EXCL;		/* Stop rewrite attacks */
-		cred->fsuid = GLOBAL_ROOT_UID;	/* Dump root private */
-		need_nonrelative = true;
-	}
-
-	retval = coredump_wait(exit_code, &core_state);
-	if (retval < 0)
-		goto fail_creds;
-
-	old_cred = override_creds(cred);
-
-	/*
-	 * Clear any false indication of pending signals that might
-	 * be seen by the filesystem code called to write the core file.
-	 */
-	clear_thread_flag(TIF_SIGPENDING);
-
-	ispipe = format_corename(&cn, signr);
-
- 	if (ispipe) {
-		int dump_count;
-		char **helper_argv;
-
-		if (ispipe < 0) {
-			printk(KERN_WARNING "format_corename failed\n");
-			printk(KERN_WARNING "Aborting core\n");
-			goto fail_corename;
-		}
-
-		if (cprm.limit == 1) {
-			/* See umh_pipe_setup() which sets RLIMIT_CORE = 1.
-			 *
-			 * Normally core limits are irrelevant to pipes, since
-			 * we're not writing to the file system, but we use
-			 * cprm.limit of 1 here as a speacial value, this is a
-			 * consistent way to catch recursive crashes.
-			 * We can still crash if the core_pattern binary sets
-			 * RLIM_CORE = !1, but it runs as root, and can do
-			 * lots of stupid things.
-			 *
-			 * Note that we use task_tgid_vnr here to grab the pid
-			 * of the process group leader.  That way we get the
-			 * right pid if a thread in a multi-threaded
-			 * core_pattern process dies.
-			 */
-			printk(KERN_WARNING
-				"Process %d(%s) has RLIMIT_CORE set to 1\n",
-				task_tgid_vnr(current), current->comm);
-			printk(KERN_WARNING "Aborting core\n");
-			goto fail_unlock;
-		}
-		cprm.limit = RLIM_INFINITY;
-
-		dump_count = atomic_inc_return(&core_dump_count);
-		if (core_pipe_limit && (core_pipe_limit < dump_count)) {
-			printk(KERN_WARNING "Pid %d(%s) over core_pipe_limit\n",
-			       task_tgid_vnr(current), current->comm);
-			printk(KERN_WARNING "Skipping core dump\n");
-			goto fail_dropcount;
-		}
-
-		helper_argv = argv_split(GFP_KERNEL, cn.corename+1, NULL);
-		if (!helper_argv) {
-			printk(KERN_WARNING "%s failed to allocate memory\n",
-			       __func__);
-			goto fail_dropcount;
-		}
-
-		retval = call_usermodehelper_fns(helper_argv[0], helper_argv,
-					NULL, UMH_WAIT_EXEC, umh_pipe_setup,
-					NULL, &cprm);
-		argv_free(helper_argv);
-		if (retval) {
- 			printk(KERN_INFO "Core dump to %s pipe failed\n",
-			       cn.corename);
-			goto close_fail;
- 		}
-	} else {
-		struct inode *inode;
-
-		if (cprm.limit < binfmt->min_coredump)
-			goto fail_unlock;
-
-		if (need_nonrelative && cn.corename[0] != '/') {
-			printk(KERN_WARNING "Pid %d(%s) can only dump core "\
-				"to fully qualified path!\n",
-				task_tgid_vnr(current), current->comm);
-			printk(KERN_WARNING "Skipping core dump\n");
-			goto fail_unlock;
-		}
-
-		cprm.file = filp_open(cn.corename,
-				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag,
-				 0600);
-		if (IS_ERR(cprm.file))
-			goto fail_unlock;
-
-		inode = cprm.file->f_path.dentry->d_inode;
-		if (inode->i_nlink > 1)
-			goto close_fail;
-		if (d_unhashed(cprm.file->f_path.dentry))
-			goto close_fail;
-		/*
-		 * AK: actually i see no reason to not allow this for named
-		 * pipes etc, but keep the previous behaviour for now.
-		 */
-		if (!S_ISREG(inode->i_mode))
-			goto close_fail;
-		/*
-		 * Dont allow local users get cute and trick others to coredump
-		 * into their pre-created files.
-		 */
-		if (!uid_eq(inode->i_uid, current_fsuid()))
-			goto close_fail;
-		if (!cprm.file->f_op || !cprm.file->f_op->write)
-			goto close_fail;
-		if (do_truncate(cprm.file->f_path.dentry, 0, 0, cprm.file))
-			goto close_fail;
-	}
-
-	/* get us an unshared descriptor table; almost always a no-op */
-	retval = unshare_files(&displaced);
-	if (retval)
-		goto close_fail;
-	if (displaced)
-		put_files_struct(displaced);
-	retval = binfmt->core_dump(&cprm);
-	if (retval)
-		current->signal->group_exit_code |= 0x80;
-
-	if (ispipe && core_pipe_limit)
-		wait_for_dump_helpers(cprm.file);
-close_fail:
-	if (cprm.file)
-		filp_close(cprm.file, NULL);
-fail_dropcount:
-	if (ispipe)
-		atomic_dec(&core_dump_count);
-fail_unlock:
-	kfree(cn.corename);
-fail_corename:
-	coredump_finish(mm);
-	revert_creds(old_cred);
-fail_creds:
-	put_cred(cred);
-fail:
-	return;
-}
-
-/*
- * Core dumping helper functions.  These are the only things you should
- * do on a core-file: use only these functions to write out all the
- * necessary info.
- */
-int dump_write(struct file *file, const void *addr, int nr)
-{
-	return access_ok(VERIFY_READ, addr, nr) && file->f_op->write(file, addr, nr, &file->f_pos) == nr;
-}
-EXPORT_SYMBOL(dump_write);
-
-int dump_seek(struct file *file, loff_t off)
-{
-	int ret = 1;
-
-	if (file->f_op->llseek && file->f_op->llseek != no_llseek) {
-		if (file->f_op->llseek(file, off, SEEK_CUR) < 0)
-			return 0;
-	} else {
-		char *buf = (char *)get_zeroed_page(GFP_KERNEL);
-
-		if (!buf)
-			return 0;
-		while (off > 0) {
-			unsigned long n = off;
-
-			if (n > PAGE_SIZE)
-				n = PAGE_SIZE;
-			if (!dump_write(file, buf, n)) {
-				ret = 0;
-				break;
-			}
-			off -= n;
-		}
-		free_page((unsigned long)buf);
-	}
-	return ret;
-}
-EXPORT_SYMBOL(dump_seek);

commit 38b983b3461e7d3c64a981e2338bb34605c46f30
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Sep 30 13:38:55 2012 -0400

    generic sys_execve()
    
    Selected by __ARCH_WANT_SYS_EXECVE in unistd.h.  Requires
            * working current_pt_regs()
            * *NOT* doing a syscall-in-kernel kind of kernel_execve()
    implementation.  Using generic kernel_execve() is fine.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 48c525115fe4..50a1270da95b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -401,7 +401,7 @@ struct user_arg_ptr {
 	union {
 		const char __user *const __user *native;
 #ifdef CONFIG_COMPAT
-		compat_uptr_t __user *compat;
+		const compat_uptr_t __user *compat;
 #endif
 	} ptr;
 };
@@ -1600,9 +1600,9 @@ int do_execve(const char *filename,
 }
 
 #ifdef CONFIG_COMPAT
-int compat_do_execve(char *filename,
-	compat_uptr_t __user *__argv,
-	compat_uptr_t __user *__envp,
+int compat_do_execve(const char *filename,
+	const compat_uptr_t __user *__argv,
+	const compat_uptr_t __user *__envp,
 	struct pt_regs *regs)
 {
 	struct user_arg_ptr argv = {
@@ -2319,6 +2319,36 @@ int dump_seek(struct file *file, loff_t off)
 }
 EXPORT_SYMBOL(dump_seek);
 
+#ifdef __ARCH_WANT_SYS_EXECVE
+SYSCALL_DEFINE3(execve,
+		const char __user *, filename,
+		const char __user *const __user *, argv,
+		const char __user *const __user *, envp)
+{
+	const char *path = getname(filename);
+	int error = PTR_ERR(path);
+	if (!IS_ERR(path)) {
+		error = do_execve(path, argv, envp, current_pt_regs());
+		putname(path);
+	}
+	return error;
+}
+#ifdef CONFIG_COMPAT
+asmlinkage long compat_sys_execve(const char __user * filename,
+	const compat_uptr_t __user * argv,
+	const compat_uptr_t __user * envp)
+{
+	const char *path = getname(filename);
+	int error = PTR_ERR(path);
+	if (!IS_ERR(path)) {
+		error = compat_do_execve(path, argv, envp, current_pt_regs());
+		putname(path);
+	}
+	return error;
+}
+#endif
+#endif
+
 #ifdef __ARCH_WANT_KERNEL_EXECVE
 int kernel_execve(const char *filename,
 		  const char *const argv[],

commit 282124d18626379a20b41d25e0c580f290cd09d4
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Sep 30 13:20:09 2012 -0400

    generic kernel_execve()
    
    based mostly on arm and alpha versions.  Architectures can define
    __ARCH_WANT_KERNEL_EXECVE and use it, provided that
            * they have working current_pt_regs(), even for kernel threads.
            * kernel_thread-spawned threads do have space for pt_regs
    in the normal location.  Normally that's as simple as switching to
    generic kernel_thread() and making sure that kernel threads do *not*
    go through return from syscall path; call the payload from equivalent
    of ret_from_fork if we are in a kernel thread (or just have separate
    ret_from_kernel_thread and make copy_thread() use it instead of
    ret_from_fork in kernel thread case).
            * they have ret_from_kernel_execve(); it is called after
    successful do_execve() done by kernel_execve() and gets normal
    pt_regs location passed to it as argument.  It's essentially
    a longjmp() analog - it should set sp, etc. to the situation
    expected at the return for syscall and go there.  Eventually
    the need for that sucker will disappear, but that'll take some
    surgery on kernel_thread() payloads.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index d7f9e14f8977..48c525115fe4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2318,3 +2318,25 @@ int dump_seek(struct file *file, loff_t off)
 	return ret;
 }
 EXPORT_SYMBOL(dump_seek);
+
+#ifdef __ARCH_WANT_KERNEL_EXECVE
+int kernel_execve(const char *filename,
+		  const char *const argv[],
+		  const char *const envp[])
+{
+	struct pt_regs *p = current_pt_regs();
+	int ret;
+
+	ret = do_execve(filename,
+			(const char __user *const __user *)argv,
+			(const char __user *const __user *)envp, p);
+	if (ret < 0)
+		return ret;
+
+	/*
+	 * We were successful.  We won't be returning to our caller, but
+	 * instead to user space by manipulating the kernel stack.
+	 */
+	ret_from_kernel_execve(p);
+}
+#endif

commit 179e037fc1370288188cb1f90b81156d75a3cb2d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 21 22:43:47 2012 -0400

    do_coredump(): make sure that descriptor table isn't shared
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 3fc74681cc6c..beb05a95e4a3 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2066,6 +2066,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	int retval = 0;
 	int flag = 0;
 	int ispipe;
+	struct files_struct *displaced;
 	bool need_nonrelative = false;
 	static atomic_t core_dump_count = ATOMIC_INIT(0);
 	struct coredump_params cprm = {
@@ -2219,6 +2220,12 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 			goto close_fail;
 	}
 
+	/* get us an unshared descriptor table; almost always a no-op */
+	retval = unshare_files(&displaced);
+	if (retval)
+		goto close_fail;
+	if (displaced)
+		put_files_struct(displaced);
 	retval = binfmt->core_dump(&cprm);
 	if (retval)
 		current->signal->group_exit_code |= 0x80;

commit 8280d16172243702ed43432f826ca6130edb4086
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 21 12:11:46 2012 -0400

    new helper: replace_fd()
    
    analog of dup2(), except that it takes struct file * as source.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index f2b6af585d4a..3fc74681cc6c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2041,23 +2041,14 @@ static void wait_for_dump_helpers(struct file *file)
 static int umh_pipe_setup(struct subprocess_info *info, struct cred *new)
 {
 	struct file *files[2];
-	struct fdtable *fdt;
 	struct coredump_params *cp = (struct coredump_params *)info->data;
-	struct files_struct *cf = current->files;
 	int err = create_pipe_files(files, 0);
 	if (err)
 		return err;
 
 	cp->file = files[1];
 
-	sys_close(0);
-	fd_install(0, files[0]);
-	spin_lock(&cf->file_lock);
-	fdt = files_fdtable(cf);
-	__set_open_fd(0, fdt);
-	__clear_close_on_exec(0, fdt);
-	spin_unlock(&cf->file_lock);
-
+	replace_fd(0, files[0], 0);
 	/* and disallow core files too */
 	current->signal->rlim[RLIMIT_CORE] = (struct rlimit){1, 1};
 

commit 6a6d27de340c89c5323565b49f7851362619925d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 21 09:56:33 2012 -0400

    take close-on-exec logics to fs/file.c, clean it up a bit
    
    ... and add cond_resched() there, while we are at it.  We can
    get large latencies as is...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 574cf4de4ec3..f2b6af585d4a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1006,40 +1006,6 @@ static int de_thread(struct task_struct *tsk)
 	return 0;
 }
 
-/*
- * These functions flushes out all traces of the currently running executable
- * so that a new one can be started
- */
-static void flush_old_files(struct files_struct * files)
-{
-	long j = -1;
-	struct fdtable *fdt;
-
-	spin_lock(&files->file_lock);
-	for (;;) {
-		unsigned long set, i;
-
-		j++;
-		i = j * BITS_PER_LONG;
-		fdt = files_fdtable(files);
-		if (i >= fdt->max_fds)
-			break;
-		set = fdt->close_on_exec[j];
-		if (!set)
-			continue;
-		fdt->close_on_exec[j] = 0;
-		spin_unlock(&files->file_lock);
-		for ( ; set ; i++,set >>= 1) {
-			if (set & 1) {
-				sys_close(i);
-			}
-		}
-		spin_lock(&files->file_lock);
-
-	}
-	spin_unlock(&files->file_lock);
-}
-
 char *get_task_comm(char *buf, struct task_struct *tsk)
 {
 	/* buf must be at least sizeof(tsk->comm) in size */
@@ -1050,6 +1016,11 @@ char *get_task_comm(char *buf, struct task_struct *tsk)
 }
 EXPORT_SYMBOL_GPL(get_task_comm);
 
+/*
+ * These functions flushes out all traces of the currently running executable
+ * so that a new one can be started
+ */
+
 void set_task_comm(struct task_struct *tsk, char *buf)
 {
 	task_lock(tsk);
@@ -1171,7 +1142,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 	current->self_exec_id++;
 			
 	flush_signal_handlers(current, 0);
-	flush_old_files(current->files);
+	do_close_on_exec(current->files);
 }
 EXPORT_SYMBOL(setup_new_exec);
 

commit 826eba4db0c643cc0e705c8365902c63fac2b7ee
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Aug 3 12:14:44 2012 +0400

    the only place that needs to include asm/exec.h is linux/binfmts.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 574cf4de4ec3..d7f9e14f8977 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -59,7 +59,6 @@
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlb.h>
-#include <asm/exec.h>
 
 #include <trace/events/task.h>
 #include "internal.h"

commit a0e881b7c189fa2bd76c024dbff91e79511c971d
Merge: eff0d13f3823 dbc6e0222d79
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 1 10:26:23 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull second vfs pile from Al Viro:
     "The stuff in there: fsfreeze deadlock fixes by Jan (essentially, the
      deadlock reproduced by xfstests 068), symlink and hardlink restriction
      patches, plus assorted cleanups and fixes.
    
      Note that another fsfreeze deadlock (emergency thaw one) is *not*
      dealt with - the series by Fernando conflicts a lot with Jan's, breaks
      userland ABI (FIFREEZE semantics gets changed) and trades the deadlock
      for massive vfsmount leak; this is going to be handled next cycle.
      There probably will be another pull request, but that stuff won't be
      in it."
    
    Fix up trivial conflicts due to unrelated changes next to each other in
    drivers/{staging/gdm72xx/usb_boot.c, usb/gadget/storage_common.c}
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (54 commits)
      delousing target_core_file a bit
      Documentation: Correct s_umount state for freeze_fs/unfreeze_fs
      fs: Remove old freezing mechanism
      ext2: Implement freezing
      btrfs: Convert to new freezing mechanism
      nilfs2: Convert to new freezing mechanism
      ntfs: Convert to new freezing mechanism
      fuse: Convert to new freezing mechanism
      gfs2: Convert to new freezing mechanism
      ocfs2: Convert to new freezing mechanism
      xfs: Convert to new freezing code
      ext4: Convert to new freezing mechanism
      fs: Protect write paths by sb_start_write - sb_end_write
      fs: Skip atime update on frozen filesystem
      fs: Add freezing handling to mnt_want_write() / mnt_drop_write()
      fs: Improve filesystem freezing handling
      switch the protection of percpu_counter list to spinlock
      nfsd: Push mnt_want_write() outside of i_mutex
      btrfs: Push mnt_want_write() outside of i_mutex
      fat: Push mnt_want_write() outside of i_mutex
      ...

commit 108ceeb020bb3558fe175a3fc8b60fd6c1a2a279
Author: Jovi Zhang <bookjovi@gmail.com>
Date:   Mon Jul 30 14:42:23 2012 -0700

    coredump: fix wrong comments on core limits of pipe coredump case
    
    In commit 898b374af6f7 ("exec: replace call_usermodehelper_pipe with use
    of umh init function and resolve limit"), the core limits recursive
    check value was changed from 0 to 1, but the corresponding comments were
    not updated.
    
    Signed-off-by: Jovi Zhang <bookjovi@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 5af8390e0fae..3684353ebd5f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2174,15 +2174,16 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		}
 
 		if (cprm.limit == 1) {
-			/*
+			/* See umh_pipe_setup() which sets RLIMIT_CORE = 1.
+			 *
 			 * Normally core limits are irrelevant to pipes, since
 			 * we're not writing to the file system, but we use
-			 * cprm.limit of 1 here as a speacial value. Any
-			 * non-1 limit gets set to RLIM_INFINITY below, but
-			 * a limit of 0 skips the dump.  This is a consistent
-			 * way to catch recursive crashes.  We can still crash
-			 * if the core_pattern binary sets RLIM_CORE =  !1
-			 * but it runs as root, and can do lots of stupid things
+			 * cprm.limit of 1 here as a speacial value, this is a
+			 * consistent way to catch recursive crashes.
+			 * We can still crash if the core_pattern binary sets
+			 * RLIM_CORE = !1, but it runs as root, and can do
+			 * lots of stupid things.
+			 *
 			 * Note that we use task_tgid_vnr here to grab the pid
 			 * of the process group leader.  That way we get the
 			 * right pid if a thread in a multi-threaded

commit 54b501992dd2a839e94e76aa392c392b55080ce8
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Jul 30 14:39:18 2012 -0700

    coredump: warn about unsafe suid_dumpable / core_pattern combo
    
    When suid_dumpable=2, detect unsafe core_pattern settings and warn when
    they are seen.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Suggested-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Alan Cox <alan@linux.intel.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Doug Ledford <dledford@redhat.com>
    Cc: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: James Morris <james.l.morris@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 95aae3f9c036..5af8390e0fae 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2002,17 +2002,17 @@ static void coredump_finish(struct mm_struct *mm)
 void set_dumpable(struct mm_struct *mm, int value)
 {
 	switch (value) {
-	case 0:
+	case SUID_DUMPABLE_DISABLED:
 		clear_bit(MMF_DUMPABLE, &mm->flags);
 		smp_wmb();
 		clear_bit(MMF_DUMP_SECURELY, &mm->flags);
 		break;
-	case 1:
+	case SUID_DUMPABLE_ENABLED:
 		set_bit(MMF_DUMPABLE, &mm->flags);
 		smp_wmb();
 		clear_bit(MMF_DUMP_SECURELY, &mm->flags);
 		break;
-	case 2:
+	case SUID_DUMPABLE_SAFE:
 		set_bit(MMF_DUMP_SECURELY, &mm->flags);
 		smp_wmb();
 		set_bit(MMF_DUMPABLE, &mm->flags);
@@ -2025,7 +2025,7 @@ static int __get_dumpable(unsigned long mm_flags)
 	int ret;
 
 	ret = mm_flags & MMF_DUMPABLE_MASK;
-	return (ret >= 2) ? 2 : ret;
+	return (ret > SUID_DUMPABLE_ENABLED) ? SUID_DUMPABLE_SAFE : ret;
 }
 
 int get_dumpable(struct mm_struct *mm)
@@ -2142,7 +2142,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	 * so we dump it as root in mode 2, and only into a controlled
 	 * environment (pipe handler or fully qualified path).
 	 */
-	if (__get_dumpable(cprm.mm_flags) == 2) {
+	if (__get_dumpable(cprm.mm_flags) == SUID_DUMPABLE_SAFE) {
 		/* Setuid core dump mode */
 		flag = O_EXCL;		/* Stop rewrite attacks */
 		cred->fsuid = GLOBAL_ROOT_UID;	/* Dump root private */

commit 9520628e8ceb69fa9a4aee6b57f22675d9e1b709
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Jul 30 14:39:15 2012 -0700

    fs: make dumpable=2 require fully qualified path
    
    When the suid_dumpable sysctl is set to "2", and there is no core dump
    pipe defined in the core_pattern sysctl, a local user can cause core files
    to be written to root-writable directories, potentially with
    user-controlled content.
    
    This means an admin can unknowningly reintroduce a variation of
    CVE-2006-2451, allowing local users to gain root privileges.
    
      $ cat /proc/sys/fs/suid_dumpable
      2
      $ cat /proc/sys/kernel/core_pattern
      core
      $ ulimit -c unlimited
      $ cd /
      $ ls -l core
      ls: cannot access core: No such file or directory
      $ touch core
      touch: cannot touch `core': Permission denied
      $ OHAI="evil-string-here" ping localhost >/dev/null 2>&1 &
      $ pid=$!
      $ sleep 1
      $ kill -SEGV $pid
      $ ls -l core
      -rw------- 1 root kees 458752 Jun 21 11:35 core
      $ sudo strings core | grep evil
      OHAI=evil-string-here
    
    While cron has been fixed to abort reading a file when there is any
    parse error, there are still other sensitive directories that will read
    any file present and skip unparsable lines.
    
    Instead of introducing a suid_dumpable=3 mode and breaking all users of
    mode 2, this only disables the unsafe portion of mode 2 (writing to disk
    via relative path).  Most users of mode 2 (e.g.  Chrome OS) already use
    a core dump pipe handler, so this change will not break them.  For the
    situations where a pipe handler is not defined but mode 2 is still
    active, crash dumps will only be written to fully qualified paths.  If a
    relative path is defined (e.g.  the default "core" pattern), dump
    attempts will trigger a printk yelling about the lack of a fully
    qualified path.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Alan Cox <alan@linux.intel.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Doug Ledford <dledford@redhat.com>
    Cc: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: James Morris <james.l.morris@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e95aeeddd25c..95aae3f9c036 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2111,6 +2111,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	int retval = 0;
 	int flag = 0;
 	int ispipe;
+	bool need_nonrelative = false;
 	static atomic_t core_dump_count = ATOMIC_INIT(0);
 	struct coredump_params cprm = {
 		.signr = signr,
@@ -2136,14 +2137,16 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	if (!cred)
 		goto fail;
 	/*
-	 *	We cannot trust fsuid as being the "true" uid of the
-	 *	process nor do we know its entire history. We only know it
-	 *	was tainted so we dump it as root in mode 2.
+	 * We cannot trust fsuid as being the "true" uid of the process
+	 * nor do we know its entire history. We only know it was tainted
+	 * so we dump it as root in mode 2, and only into a controlled
+	 * environment (pipe handler or fully qualified path).
 	 */
 	if (__get_dumpable(cprm.mm_flags) == 2) {
 		/* Setuid core dump mode */
 		flag = O_EXCL;		/* Stop rewrite attacks */
 		cred->fsuid = GLOBAL_ROOT_UID;	/* Dump root private */
+		need_nonrelative = true;
 	}
 
 	retval = coredump_wait(exit_code, &core_state);
@@ -2223,6 +2226,14 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		if (cprm.limit < binfmt->min_coredump)
 			goto fail_unlock;
 
+		if (need_nonrelative && cn.corename[0] != '/') {
+			printk(KERN_WARNING "Pid %d(%s) can only dump core "\
+				"to fully qualified path!\n",
+				task_tgid_vnr(current), current->comm);
+			printk(KERN_WARNING "Skipping core dump\n");
+			goto fail_unlock;
+		}
+
 		cprm.file = filp_open(cn.corename,
 				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag,
 				 0600);

commit e4fad8e5d220e3dfb1050eee752ee5058f29a232
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jul 21 15:33:25 2012 +0400

    consolidate pipe file creation
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index da27b91ff1e8..b800fb87f6ce 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2069,25 +2069,18 @@ static void wait_for_dump_helpers(struct file *file)
  */
 static int umh_pipe_setup(struct subprocess_info *info, struct cred *new)
 {
-	struct file *rp, *wp;
+	struct file *files[2];
 	struct fdtable *fdt;
 	struct coredump_params *cp = (struct coredump_params *)info->data;
 	struct files_struct *cf = current->files;
+	int err = create_pipe_files(files, 0);
+	if (err)
+		return err;
 
-	wp = create_write_pipe(0);
-	if (IS_ERR(wp))
-		return PTR_ERR(wp);
-
-	rp = create_read_pipe(wp, 0);
-	if (IS_ERR(rp)) {
-		free_write_pipe(wp);
-		return PTR_ERR(rp);
-	}
-
-	cp->file = wp;
+	cp->file = files[1];
 
 	sys_close(0);
-	fd_install(0, rp);
+	fd_install(0, files[0]);
 	spin_lock(&cf->file_lock);
 	fdt = files_fdtable(cf);
 	__set_open_fd(0, fdt);

commit 8ded2bbc1845e19c771eb55209aab166ef011243
Author: Josh Boyer <jwboyer@redhat.com>
Date:   Wed Jul 25 10:40:34 2012 -0400

    posix_types.h: Cleanup stale __NFDBITS and related definitions
    
    Recently, glibc made a change to suppress sign-conversion warnings in
    FD_SET (glibc commit ceb9e56b3d1).  This uncovered an issue with the
    kernel's definition of __NFDBITS if applications #include
    <linux/types.h> after including <sys/select.h>.  A build failure would
    be seen when passing the -Werror=sign-compare and -D_FORTIFY_SOURCE=2
    flags to gcc.
    
    It was suggested that the kernel should either match the glibc
    definition of __NFDBITS or remove that entirely.  The current in-kernel
    uses of __NFDBITS can be replaced with BITS_PER_LONG, and there are no
    uses of the related __FDELT and __FDMASK defines.  Given that, we'll
    continue the cleanup that was started with commit 8b3d1cda4f5f
    ("posix_types: Remove fd_set macros") and drop the remaining unused
    macros.
    
    Additionally, linux/time.h has similar macros defined that expand to
    nothing so we'll remove those at the same time.
    
    Reported-by: Jeff Law <law@redhat.com>
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    CC: <stable@vger.kernel.org>
    Signed-off-by: Josh Boyer <jwboyer@redhat.com>
    [ .. and fix up whitespace as per akpm ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index da27b91ff1e8..e95aeeddd25c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1020,7 +1020,7 @@ static void flush_old_files(struct files_struct * files)
 		unsigned long set, i;
 
 		j++;
-		i = j * __NFDBITS;
+		i = j * BITS_PER_LONG;
 		fdt = files_fdtable(files);
 		if (i >= fdt->max_fds)
 			break;

commit 4fe7efdbdfb1c7e7a7f31decfd831c0f31d37091
Author: Konstantin Khlebnikov <khlebnikov@openvz.org>
Date:   Wed Jun 20 12:53:01 2012 -0700

    mm: correctly synchronize rss-counters at exit/exec
    
    do_exit() and exec_mmap() call sync_mm_rss() before mm_release() does
    put_user(clear_child_tid) which can update task->rss_stat and thus make
    mm->rss_stat inconsistent.  This triggers the "BUG:" printk in check_mm().
    
    Let's fix this bug in the safest way, and optimize/cleanup this later.
    
    Reported-by: Markus Trippelsdorf <markus@trippelsdorf.de>
    Signed-off-by: Konstantin Khlebnikov <khlebnikov@openvz.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a79786a8d2c8..da27b91ff1e8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -819,10 +819,10 @@ static int exec_mmap(struct mm_struct *mm)
 	/* Notify parent that we're no longer interested in the old VM */
 	tsk = current;
 	old_mm = current->mm;
-	sync_mm_rss(old_mm);
 	mm_release(tsk, old_mm);
 
 	if (old_mm) {
+		sync_mm_rss(old_mm);
 		/*
 		 * Make sure that if there is a core dump in progress
 		 * for the old mm, we get out and die instead of going

commit 48d212a2eecaca2e1875925837ad27b2f43f48a3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 7 17:54:07 2012 -0700

    Revert "mm: correctly synchronize rss-counters at exit/exec"
    
    This reverts commit 40af1bbdca47e5c8a2044039bb78ca8fd8b20f94.
    
    It's horribly and utterly broken for at least the following reasons:
    
     - calling sync_mm_rss() from mmput() is fundamentally wrong, because
       there's absolutely no reason to believe that the task that does the
       mmput() always does it on its own VM.  Example: fork, ptrace, /proc -
       you name it.
    
     - calling it *after* having done mmdrop() on it is doubly insane, since
       the mm struct may well be gone now.
    
     - testing mm against NULL before you call it is insane too, since a
    NULL mm there would have caused oopses long before.
    
    .. and those are just the three bugs I found before I decided to give up
    looking for me and revert it asap.  I should have caught it before I
    even took it, but I trusted Andrew too much.
    
    Cc: Konstantin Khlebnikov <khlebnikov@openvz.org>
    Cc: Markus Trippelsdorf <markus@trippelsdorf.de>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index b926ed19301e..a79786a8d2c8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -819,6 +819,7 @@ static int exec_mmap(struct mm_struct *mm)
 	/* Notify parent that we're no longer interested in the old VM */
 	tsk = current;
 	old_mm = current->mm;
+	sync_mm_rss(old_mm);
 	mm_release(tsk, old_mm);
 
 	if (old_mm) {

commit 40af1bbdca47e5c8a2044039bb78ca8fd8b20f94
Author: Konstantin Khlebnikov <khlebnikov@openvz.org>
Date:   Thu Jun 7 14:21:14 2012 -0700

    mm: correctly synchronize rss-counters at exit/exec
    
    mm->rss_stat counters have per-task delta: task->rss_stat.  Before
    changing task->mm pointer the kernel must flush this delta with
    sync_mm_rss().
    
    do_exit() already calls sync_mm_rss() to flush the rss-counters before
    committing the rss statistics into task->signal->maxrss, taskstats,
    audit and other stuff.  Unfortunately the kernel does this before
    calling mm_release(), which can call put_user() for processing
    task->clear_child_tid.  So at this point we can trigger page-faults and
    task->rss_stat becomes non-zero again.  As a result mm->rss_stat becomes
    inconsistent and check_mm() will print something like this:
    
    | BUG: Bad rss-counter state mm:ffff88020813c380 idx:1 val:-1
    | BUG: Bad rss-counter state mm:ffff88020813c380 idx:2 val:1
    
    This patch moves sync_mm_rss() into mm_release(), and moves mm_release()
    out of do_exit() and calls it earlier.  After mm_release() there should
    be no pagefaults.
    
    [akpm@linux-foundation.org: tweak comment]
    Signed-off-by: Konstantin Khlebnikov <khlebnikov@openvz.org>
    Reported-by: Markus Trippelsdorf <markus@trippelsdorf.de>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: <stable@vger.kernel.org>            [3.4.x]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a79786a8d2c8..b926ed19301e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -819,7 +819,6 @@ static int exec_mmap(struct mm_struct *mm)
 	/* Notify parent that we're no longer interested in the old VM */
 	tsk = current;
 	old_mm = current->mm;
-	sync_mm_rss(old_mm);
 	mm_release(tsk, old_mm);
 
 	if (old_mm) {

commit e5467859f7f79b69fc49004403009dfdba3bec53
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed May 30 13:30:51 2012 -0400

    split ->file_mmap() into ->mmap_addr()/->mmap_file()
    
    ... i.e. file-dependent and address-dependent checks.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 52c9e2ff6e6b..a79786a8d2c8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -280,10 +280,6 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 	INIT_LIST_HEAD(&vma->anon_vma_chain);
 
-	err = security_file_mmap(NULL, 0, 0, 0, vma->vm_start, 1);
-	if (err)
-		goto err;
-
 	err = insert_vm_struct(mm, vma);
 	if (err)
 		goto err;

commit 644473e9c60c1ff4f6351fed637a6e5551e3dce7
Merge: fb827ec68446 4b06a81f1dae
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 23 17:42:39 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull user namespace enhancements from Eric Biederman:
     "This is a course correction for the user namespace, so that we can
      reach an inexpensive, maintainable, and reasonably complete
      implementation.
    
      Highlights:
       - Config guards make it impossible to enable the user namespace and
         code that has not been converted to be user namespace safe.
    
       - Use of the new kuid_t type ensures the if you somehow get past the
         config guards the kernel will encounter type errors if you enable
         user namespaces and attempt to compile in code whose permission
         checks have not been updated to be user namespace safe.
    
       - All uids from child user namespaces are mapped into the initial
         user namespace before they are processed.  Removing the need to add
         an additional check to see if the user namespace of the compared
         uids remains the same.
    
       - With the user namespaces compiled out the performance is as good or
         better than it is today.
    
       - For most operations absolutely nothing changes performance or
         operationally with the user namespace enabled.
    
       - The worst case performance I could come up with was timing 1
         billion cache cold stat operations with the user namespace code
         enabled.  This went from 156s to 164s on my laptop (or 156ns to
         164ns per stat operation).
    
       - (uid_t)-1 and (gid_t)-1 are reserved as an internal error value.
         Most uid/gid setting system calls treat these value specially
         anyway so attempting to use -1 as a uid would likely cause
         entertaining failures in userspace.
    
       - If setuid is called with a uid that can not be mapped setuid fails.
         I have looked at sendmail, login, ssh and every other program I
         could think of that would call setuid and they all check for and
         handle the case where setuid fails.
    
       - If stat or a similar system call is called from a context in which
         we can not map a uid we lie and return overflowuid.  The LFS
         experience suggests not lying and returning an error code might be
         better, but the historical precedent with uids is different and I
         can not think of anything that would break by lying about a uid we
         can't map.
    
       - Capabilities are localized to the current user namespace making it
         safe to give the initial user in a user namespace all capabilities.
    
      My git tree covers all of the modifications needed to convert the core
      kernel and enough changes to make a system bootable to runlevel 1."
    
    Fix up trivial conflicts due to nearby independent changes in fs/stat.c
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (46 commits)
      userns:  Silence silly gcc warning.
      cred: use correct cred accessor with regards to rcu read lock
      userns: Convert the move_pages, and migrate_pages permission checks to use uid_eq
      userns: Convert cgroup permission checks to use uid_eq
      userns: Convert tmpfs to use kuid and kgid where appropriate
      userns: Convert sysfs to use kgid/kuid where appropriate
      userns: Convert sysctl permission checks to use kuid and kgids.
      userns: Convert proc to use kuid/kgid where appropriate
      userns: Convert ext4 to user kuid/kgid where appropriate
      userns: Convert ext3 to use kuid/kgid where appropriate
      userns: Convert ext2 to use kuid/kgid where appropriate.
      userns: Convert devpts to use kuid/kgid where appropriate
      userns: Convert binary formats to use kuid/kgid where appropriate
      userns: Add negative depends on entries to avoid building code that is userns unsafe
      userns: signal remove unnecessary map_cred_ns
      userns: Teach inode_capable to understand inodes whose uids map to other namespaces.
      userns: Fail exec for suid and sgid binaries with ids outside our user namespace.
      userns: Convert stat to return values mapped from kuids and kgids
      userns: Convert user specfied uids and gids in chown into kuids and kgid
      userns: Use uid_eq gid_eq helpers when comparing kuids and kgids in the vfs
      ...

commit ec0d7f18ab7b5097d7c0c8f3d909ca1031b9d5cd
Merge: 269af9a1a08d 1dcc8d7ba235
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 23 10:59:07 2012 -0700

    Merge branch 'x86-fpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull fpu state cleanups from Ingo Molnar:
     "This tree streamlines further aspects of FPU handling by eliminating
      the prepare_to_copy() complication and moving that logic to
      arch_dup_task_struct().
    
      It also fixes the FPU dumps in threaded core dumps, removes and old
      (and now invalid) assumption plus micro-optimizes the exit path by
      avoiding an FPU save for dead tasks."
    
    Fixed up trivial add-add conflict in arch/sh/kernel/process.c that came
    in because we now do the FPU handling in arch_dup_task_struct() rather
    than the legacy (and now gone) prepare_to_copy().
    
    * 'x86-fpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, fpu: drop the fpu state during thread exit
      x86, xsave: remove thread_has_fpu() bug check in __sanitize_i387_state()
      coredump: ensure the fpu state is flushed for proper multi-threaded core dump
      fork: move the real prepare_to_copy() users to arch_dup_task_struct()

commit 11aeca0b3a083a457f5c34fe8c677d5e86a0c6b3
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Wed May 16 15:03:52 2012 -0700

    coredump: ensure the fpu state is flushed for proper multi-threaded core dump
    
    Nalluru reported hitting the BUG_ON(__thread_has_fpu(tsk)) in
    arch/x86/kernel/xsave.c:__sanitize_i387_state() during the coredump
    of a multi-threaded application.
    
    A look at the exit seqeuence shows that other threads can still be on the
    runqueue potentially at the below shown exit_mm() code snippet:
    
                    if (atomic_dec_and_test(&core_state->nr_threads))
                            complete(&core_state->startup);
    
    ===> other threads can still be active here, but we notify the thread
    ===> dumping core to wakeup from the coredump_wait() after the last thread
    ===> joins this point. Core dumping thread will continue dumping
    ===> all the threads state to the core file.
    
                    for (;;) {
                            set_task_state(tsk, TASK_UNINTERRUPTIBLE);
                            if (!self.task) /* see coredump_finish() */
                                    break;
                            schedule();
                    }
    
    As some of those threads are on the runqueue and didn't call schedule() yet,
    their fpu state is still active in the live registers and the thread
    proceeding with the coredump will hit the above mentioned BUG_ON while
    trying to dump other threads fpustate to the coredump file.
    
    BUG_ON() in arch/x86/kernel/xsave.c:__sanitize_i387_state() is
    in the code paths for processors supporting xsaveopt. With or without
    xsaveopt, multi-threaded coredump is broken and maynot contain
    the correct fpustate at the time of exit.
    
    In coredump_wait(), wait for all the threads to be come inactive, so
    that we are sure all the extended register state is flushed to
    the memory, so that it can be reliably copied to the core file.
    
    Reported-by: Suresh Nalluru <suresh@aristanetworks.com>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Link: http://lkml.kernel.org/r/1336692811-30576-2-git-send-email-suresh.b.siddha@intel.com
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/fs/exec.c b/fs/exec.c
index b1fd2025e59a..8e2ddebaccdd 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1930,8 +1930,21 @@ static int coredump_wait(int exit_code, struct core_state *core_state)
 		core_waiters = zap_threads(tsk, mm, core_state, exit_code);
 	up_write(&mm->mmap_sem);
 
-	if (core_waiters > 0)
+	if (core_waiters > 0) {
+		struct core_thread *ptr;
+
 		wait_for_completion(&core_state->startup);
+		/*
+		 * Wait for all the threads to become inactive, so that
+		 * all the thread context (extended register state, like
+		 * fpu etc) gets copied to the memory.
+		 */
+		ptr = core_state->dumper.next;
+		while (ptr != NULL) {
+			wait_task_inactive(ptr->task, 0);
+			ptr = ptr->next;
+		}
+	}
 
 	return core_waiters;
 }

commit 9e4a36ece652908276bc4abb4324ec56292453e1
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Nov 16 23:37:59 2011 -0800

    userns: Fail exec for suid and sgid binaries with ids outside our user namespace.
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 00ae2ef100d8..e001bdfac530 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1291,8 +1291,11 @@ int prepare_binprm(struct linux_binprm *bprm)
 	if (!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID)) {
 		/* Set-uid? */
 		if (mode & S_ISUID) {
+			if (!kuid_has_mapping(bprm->cred->user_ns, inode->i_uid))
+				return -EPERM;
 			bprm->per_clear |= PER_CLEAR_ON_SETID;
 			bprm->cred->euid = inode->i_uid;
+
 		}
 
 		/* Set-gid? */
@@ -1302,6 +1305,8 @@ int prepare_binprm(struct linux_binprm *bprm)
 		 * executable.
 		 */
 		if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP)) {
+			if (!kgid_has_mapping(bprm->cred->user_ns, inode->i_gid))
+				return -EPERM;
 			bprm->per_clear |= PER_CLEAR_ON_SETID;
 			bprm->cred->egid = inode->i_gid;
 		}

commit 8e96e3b7b8407be794ab1fd8e4b332818a358e78
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Mar 3 21:17:15 2012 -0800

    userns: Use uid_eq gid_eq helpers when comparing kuids and kgids in the vfs
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/fs/exec.c b/fs/exec.c
index 9a1d9f0a60ab..00ae2ef100d8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1139,7 +1139,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 	/* This is the point of no return */
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
-	if (current_euid() == current_uid() && current_egid() == current_gid())
+	if (uid_eq(current_euid(), current_uid()) && gid_eq(current_egid(), current_gid()))
 		set_dumpable(current->mm, 1);
 	else
 		set_dumpable(current->mm, suid_dumpable);
@@ -1153,8 +1153,8 @@ void setup_new_exec(struct linux_binprm * bprm)
 	current->mm->task_size = TASK_SIZE;
 
 	/* install the new credentials */
-	if (bprm->cred->uid != current_euid() ||
-	    bprm->cred->gid != current_egid()) {
+	if (!uid_eq(bprm->cred->uid, current_euid()) ||
+	    !gid_eq(bprm->cred->gid, current_egid())) {
 		current->pdeath_signal = 0;
 	} else {
 		would_dump(bprm, bprm->file);
@@ -2120,7 +2120,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	if (__get_dumpable(cprm.mm_flags) == 2) {
 		/* Setuid core dump mode */
 		flag = O_EXCL;		/* Stop rewrite attacks */
-		cred->fsuid = 0;	/* Dump root private */
+		cred->fsuid = GLOBAL_ROOT_UID;	/* Dump root private */
 	}
 
 	retval = coredump_wait(exit_code, &core_state);
@@ -2221,7 +2221,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		 * Dont allow local users get cute and trick others to coredump
 		 * into their pre-created files.
 		 */
-		if (inode->i_uid != current_fsuid())
+		if (!uid_eq(inode->i_uid, current_fsuid()))
 			goto close_fail;
 		if (!cprm.file->f_op || !cprm.file->f_op->write)
 			goto close_fail;

commit 259e5e6c75a910f3b5e656151dc602f53f9d7548
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Apr 12 16:47:50 2012 -0500

    Add PR_{GET,SET}_NO_NEW_PRIVS to prevent execve from granting privs
    
    With this change, calling
      prctl(PR_SET_NO_NEW_PRIVS, 1, 0, 0, 0)
    disables privilege granting operations at execve-time.  For example, a
    process will not be able to execute a setuid binary to change their uid
    or gid if this bit is set.  The same is true for file capabilities.
    
    Additionally, LSM_UNSAFE_NO_NEW_PRIVS is defined to ensure that
    LSMs respect the requested behavior.
    
    To determine if the NO_NEW_PRIVS bit is set, a task may call
      prctl(PR_GET_NO_NEW_PRIVS, 0, 0, 0, 0);
    It returns 1 if set and 0 if it is not set. If any of the arguments are
    non-zero, it will return -1 and set errno to -EINVAL.
    (PR_SET_NO_NEW_PRIVS behaves similarly.)
    
    This functionality is desired for the proposed seccomp filter patch
    series.  By using PR_SET_NO_NEW_PRIVS, it allows a task to modify the
    system call behavior for itself and its child tasks without being
    able to impact the behavior of a more privileged task.
    
    Another potential use is making certain privileged operations
    unprivileged.  For example, chroot may be considered "safe" if it cannot
    affect privileged tasks.
    
    Note, this patch causes execve to fail when PR_SET_NO_NEW_PRIVS is
    set and AppArmor is in use.  It is fixed in a subsequent patch.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Eric Paris <eparis@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    
    v18: updated change desc
    v17: using new define values as per 3.4
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/fs/exec.c b/fs/exec.c
index b1fd2025e59a..d038968b54b4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1245,6 +1245,13 @@ static int check_unsafe_exec(struct linux_binprm *bprm)
 			bprm->unsafe |= LSM_UNSAFE_PTRACE;
 	}
 
+	/*
+	 * This isn't strictly necessary, but it makes it harder for LSMs to
+	 * mess up.
+	 */
+	if (current->no_new_privs)
+		bprm->unsafe |= LSM_UNSAFE_NO_NEW_PRIVS;
+
 	n_fs = 1;
 	spin_lock(&p->fs->lock);
 	rcu_read_lock();
@@ -1288,7 +1295,8 @@ int prepare_binprm(struct linux_binprm *bprm)
 	bprm->cred->euid = current_euid();
 	bprm->cred->egid = current_egid();
 
-	if (!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID)) {
+	if (!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID) &&
+	    !current->no_new_privs) {
 		/* Set-uid? */
 		if (mode & S_ISUID) {
 			bprm->per_clear |= PER_CLEAR_ON_SETID;

commit 66cfb32772495068fbb5627b2dc88649ad66c3e5
Merge: 6742259866d0 7b8e6da46b92
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 4 10:04:42 2012 -0700

    Merge branch 'perf-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull perf fixes from Ingo Molnar.
    
    * 'perf-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      perf/x86/p4: Add format attributes
      tracing, sched, vfs: Fix 'old_pid' usage in trace_sched_process_exec()

commit 6308191f6f55d3629c7dbe72dfb856ad9fa560fd
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Mar 30 18:26:36 2012 +0200

    tracing, sched, vfs: Fix 'old_pid' usage in trace_sched_process_exec()
    
    1. TRACE_EVENT(sched_process_exec) forgets to actually use the
       old pid argument, it sets ->old_pid = p->pid.
    
    2. search_binary_handler() uses the wrong pid number. tracepoint
       needs the global pid_t from the root namespace, while old_pid
       is the virtual pid number as it seen by the tracer/parent.
    
    With this patch we have two pid_t's in search_binary_handler(),
    not really nice. Perhaps we should switch to "struct pid*", but
    in this case it would be better to cleanup the current code
    first and move the "depth == 0" code outside.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: David Smith <dsmith@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Link: http://lkml.kernel.org/r/20120330162636.GA4857@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 23559c227d9c..644f6c4eb606 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1370,7 +1370,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 	unsigned int depth = bprm->recursion_depth;
 	int try,retval;
 	struct linux_binfmt *fmt;
-	pid_t old_pid;
+	pid_t old_pid, old_vpid;
 
 	retval = security_bprm_check(bprm);
 	if (retval)
@@ -1381,8 +1381,9 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 		return retval;
 
 	/* Need to fetch pid before load_binary changes it */
+	old_pid = current->pid;
 	rcu_read_lock();
-	old_pid = task_pid_nr_ns(current, task_active_pid_ns(current->parent));
+	old_vpid = task_pid_nr_ns(current, task_active_pid_ns(current->parent));
 	rcu_read_unlock();
 
 	retval = -ENOENT;
@@ -1405,7 +1406,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			if (retval >= 0) {
 				if (depth == 0) {
 					trace_sched_process_exec(current, old_pid, bprm);
-					ptrace_event(PTRACE_EVENT_EXEC, old_pid);
+					ptrace_event(PTRACE_EVENT_EXEC, old_vpid);
 				}
 				put_binfmt(fmt);
 				allow_write_access(bprm->file);

commit a591afc01d9e48affbacb365558a31e53c85af45
Merge: 820d41cf0cd0 31796ac4e8f0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 29 18:12:23 2012 -0700

    Merge branch 'x86-x32-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x32 support for x86-64 from Ingo Molnar:
     "This tree introduces the X32 binary format and execution mode for x86:
      32-bit data space binaries using 64-bit instructions and 64-bit kernel
      syscalls.
    
      This allows applications whose working set fits into a 32 bits address
      space to make use of 64-bit instructions while using a 32-bit address
      space with shorter pointers, more compressed data structures, etc."
    
    Fix up trivial context conflicts in arch/x86/{Kconfig,vdso/vma.c}
    
    * 'x86-x32-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (71 commits)
      x32: Fix alignment fail in struct compat_siginfo
      x32: Fix stupid ia32/x32 inversion in the siginfo format
      x32: Add ptrace for x32
      x32: Switch to a 64-bit clock_t
      x32: Provide separate is_ia32_task() and is_x32_task() predicates
      x86, mtrr: Use explicit sizing and padding for the 64-bit ioctls
      x86/x32: Fix the binutils auto-detect
      x32: Warn and disable rather than error if binutils too old
      x32: Only clear TIF_X32 flag once
      x32: Make sure TS_COMPAT is cleared for x32 tasks
      fs: Remove missed ->fds_bits from cessation use of fd_set structs internally
      fs: Fix close_on_exec pointer in alloc_fdtable
      x32: Drop non-__vdso weak symbols from the x32 VDSO
      x32: Fix coding style violations in the x32 VDSO code
      x32: Add x32 VDSO support
      x32: Allow x32 to be configured
      x32: If configured, add x32 system calls to system call tables
      x32: Handle process creation
      x32: Signal-related system calls
      x86: Add #ifdef CONFIG_COMPAT to <asm/sys_ia32.h>
      ...

commit 96f951edb1f1bdbbc99b0cd458f9808bb83d58ae
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:03 2012 +0100

    Add #includes needed to permit the removal of asm/system.h
    
    asm/system.h is a cause of circular dependency problems because it contains
    commonly used primitive stuff like barrier definitions and uncommonly used
    stuff like switch_to() that might require MMU definitions.
    
    asm/system.h has been disintegrated by this point on all arches into the
    following common segments:
    
     (1) asm/barrier.h
    
         Moved memory barrier definitions here.
    
     (2) asm/cmpxchg.h
    
         Moved xchg() and cmpxchg() here.  #included in asm/atomic.h.
    
     (3) asm/bug.h
    
         Moved die() and similar here.
    
     (4) asm/exec.h
    
         Moved arch_align_stack() here.
    
     (5) asm/elf.h
    
         Moved AT_VECTOR_SIZE_ARCH here.
    
     (6) asm/switch_to.h
    
         Moved switch_to() here.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index 23559c227d9c..c8b63d14da85 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -59,6 +59,7 @@
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlb.h>
+#include <asm/exec.h>
 
 #include <trace/events/task.h>
 #include "internal.h"

commit 95211279c5ad00a317c98221d7e4365e02f20836
Merge: 5375871d432a 12724850e806
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 22 09:04:48 2012 -0700

    Merge branch 'akpm' (Andrew's patch-bomb)
    
    Merge first batch of patches from Andrew Morton:
     "A few misc things and all the MM queue"
    
    * emailed from Andrew Morton <akpm@linux-foundation.org>: (92 commits)
      memcg: avoid THP split in task migration
      thp: add HPAGE_PMD_* definitions for !CONFIG_TRANSPARENT_HUGEPAGE
      memcg: clean up existing move charge code
      mm/memcontrol.c: remove unnecessary 'break' in mem_cgroup_read()
      mm/memcontrol.c: remove redundant BUG_ON() in mem_cgroup_usage_unregister_event()
      mm/memcontrol.c: s/stealed/stolen/
      memcg: fix performance of mem_cgroup_begin_update_page_stat()
      memcg: remove PCG_FILE_MAPPED
      memcg: use new logic for page stat accounting
      memcg: remove PCG_MOVE_LOCK flag from page_cgroup
      memcg: simplify move_account() check
      memcg: remove EXPORT_SYMBOL(mem_cgroup_update_page_stat)
      memcg: kill dead prev_priority stubs
      memcg: remove PCG_CACHE page_cgroup flag
      memcg: let css_get_next() rely upon rcu_read_lock()
      cgroup: revert ss_id_lock to spinlock
      idr: make idr_get_next() good for rcu_read_lock()
      memcg: remove unnecessary thp check in page stat accounting
      memcg: remove redundant returns
      memcg: enum lru_list lru
      ...

commit 05af2e104a0c282dcd9303431e1360750ba76de6
Author: David Rientjes <rientjes@google.com>
Date:   Wed Mar 21 16:34:13 2012 -0700

    mm, counters: remove task argument to sync_mm_rss() and __sync_task_rss_stat()
    
    sync_mm_rss() can only be used for current to avoid race conditions in
    iterating and clearing its per-task counters.  Remove the task argument
    for it and its helper function, __sync_task_rss_stat(), to avoid thinking
    it can be used safely for anything other than current.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 3908544f5d18..6ed164d20d7d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -824,7 +824,7 @@ static int exec_mmap(struct mm_struct *mm)
 	/* Notify parent that we're no longer interested in the old VM */
 	tsk = current;
 	old_mm = current->mm;
-	sync_mm_rss(tsk, old_mm);
+	sync_mm_rss(old_mm);
 	mm_release(tsk, old_mm);
 
 	if (old_mm) {

commit e2a0883e4071237d09b604a342c28b96b44a04b3
Merge: 3a990a52f9f2 07c0c5d8b8c1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 21 13:36:41 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs pile 1 from Al Viro:
     "This is _not_ all; in particular, Miklos' and Jan's stuff is not there
      yet."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (64 commits)
      ext4: initialization of ext4_li_mtx needs to be done earlier
      debugfs-related mode_t whack-a-mole
      hfsplus: add an ioctl to bless files
      hfsplus: change finder_info to u32
      hfsplus: initialise userflags
      qnx4: new helper - try_extent()
      qnx4: get rid of qnx4_bread/qnx4_getblk
      take removal of PF_FORKNOEXEC to flush_old_exec()
      trim includes in inode.c
      um: uml_dup_mmap() relies on ->mmap_sem being held, but activate_mm() doesn't hold it
      um: embed ->stub_pages[] into mmu_context
      gadgetfs: list_for_each_safe() misuse
      ocfs2: fix leaks on failure exits in module_init
      ecryptfs: make register_filesystem() the last potential failure exit
      ntfs: forgets to unregister sysctls on register_filesystem() failure
      logfs: missing cleanup on register_filesystem() failure
      jfs: mising cleanup on register_filesystem() failure
      make configfs_pin_fs() return root dentry on success
      configfs: configfs_create_dir() has parent dentry in dentry->d_parent
      configfs: sanitize configfs_create()
      ...

commit 9f3938346a5c1fa504647670edb5fea5756cfb00
Merge: 69a7aebcf019 317b6e128247
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 21 09:40:26 2012 -0700

    Merge branch 'kmap_atomic' of git://github.com/congwang/linux
    
    Pull kmap_atomic cleanup from Cong Wang.
    
    It's been in -next for a long time, and it gets rid of the (no longer
    used) second argument to k[un]map_atomic().
    
    Fix up a few trivial conflicts in various drivers, and do an "evil
    merge" to catch some new uses that have come in since Cong's tree.
    
    * 'kmap_atomic' of git://github.com/congwang/linux: (59 commits)
      feature-removal-schedule.txt: schedule the deprecated form of kmap_atomic() for removal
      highmem: kill all __kmap_atomic() [swarren@nvidia.com: highmem: Fix ARM build break due to __kmap_atomic rename]
      drbd: remove the second argument of k[un]map_atomic()
      zcache: remove the second argument of k[un]map_atomic()
      gma500: remove the second argument of k[un]map_atomic()
      dm: remove the second argument of k[un]map_atomic()
      tomoyo: remove the second argument of k[un]map_atomic()
      sunrpc: remove the second argument of k[un]map_atomic()
      rds: remove the second argument of k[un]map_atomic()
      net: remove the second argument of k[un]map_atomic()
      mm: remove the second argument of k[un]map_atomic()
      lib: remove the second argument of k[un]map_atomic()
      power: remove the second argument of k[un]map_atomic()
      kdb: remove the second argument of k[un]map_atomic()
      udf: remove the second argument of k[un]map_atomic()
      ubifs: remove the second argument of k[un]map_atomic()
      squashfs: remove the second argument of k[un]map_atomic()
      reiserfs: remove the second argument of k[un]map_atomic()
      ocfs2: remove the second argument of k[un]map_atomic()
      ntfs: remove the second argument of k[un]map_atomic()
      ...

commit 19e5109fef2c368ab3f8a5157270f87f4a7c0326
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Feb 23 22:29:17 2012 -0500

    take removal of PF_FORKNOEXEC to flush_old_exec()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 2c5ae338773c..60478a0e7a37 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1110,7 +1110,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	bprm->mm = NULL;		/* We're using it now */
 
 	set_fs(USER_DS);
-	current->flags &= ~(PF_RANDOMIZE | PF_KTHREAD);
+	current->flags &= ~(PF_RANDOMIZE | PF_FORKNOEXEC | PF_KTHREAD);
 	flush_thread();
 	current->personality &= ~bprm->per_clear;
 

commit 8fc3dc5a3a17aa2b353886422bd89420619af211
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 17 03:05:16 2012 -0400

    __register_binfmt() made void
    
    Just don't pass NULL to it - nobody does, anyway.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 153dee14fe55..2c5ae338773c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -79,15 +79,13 @@ static atomic_t call_count = ATOMIC_INIT(1);
 static LIST_HEAD(formats);
 static DEFINE_RWLOCK(binfmt_lock);
 
-int __register_binfmt(struct linux_binfmt * fmt, int insert)
+void __register_binfmt(struct linux_binfmt * fmt, int insert)
 {
-	if (!fmt)
-		return -EINVAL;
+	BUG_ON(!fmt);
 	write_lock(&binfmt_lock);
 	insert ? list_add(&fmt->lh, &formats) :
 		 list_add_tail(&fmt->lh, &formats);
 	write_unlock(&binfmt_lock);
-	return 0;	
 }
 
 EXPORT_SYMBOL(__register_binfmt);

commit 701085b219016d38f105b031381b9cee6200253a
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Mar 19 17:04:01 2012 +0100

    exec: move de_thread()->setmax_mm_hiwater_rss() into exec_mmap()
    
    Minor cleanup. de_thread()->setmax_mm_hiwater_rss() looks a bit
    strange, move it into exec_mmap() which plays with old_mm.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 1e94d2263ae0..95551c6da090 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -850,6 +850,7 @@ static int exec_mmap(struct mm_struct *mm)
 	if (old_mm) {
 		up_read(&old_mm->mmap_sem);
 		BUG_ON(active_mm != old_mm);
+		setmax_mm_hiwater_rss(&tsk->signal->maxrss, old_mm);
 		mm_update_next_owner(old_mm);
 		mmput(old_mm);
 		return 0;
@@ -980,9 +981,6 @@ static int de_thread(struct task_struct *tsk)
 	/* we have changed execution domain */
 	tsk->exit_signal = SIGCHLD;
 
-	if (current->mm)
-		setmax_mm_hiwater_rss(&sig->maxrss, current->mm);
-
 	exit_itimers(sig);
 	flush_itimer_signals();
 

commit e636825346b36a07ccfc8e30946d52855e21f681
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Mar 19 17:03:22 2012 +0100

    exit_signal: simplify the "we have changed execution domain" logic
    
    exit_notify() checks "tsk->self_exec_id != tsk->parent_exec_id"
    to handle the "we have changed execution domain" case.
    
    We can change do_thread() to always set ->exit_signal = SIGCHLD
    and remove this check to simplify the code.
    
    We could change setup_new_exec() instead, this looks more logical
    because it increments ->self_exec_id. But note that de_thread()
    already resets ->exit_signal if it changes the leader, let's keep
    both changes close to each other.
    
    Note that we change ->exit_signal lockless, this changes the rules.
    Thereafter ->exit_signal is not stable under tasklist but this is
    fine, the only possible change is OLDSIG -> SIGCHLD. This can race
    with eligible_child() but the race is harmless. We can race with
    reparent_leader() which changes our ->exit_signal in parallel, but
    it does the same change to SIGCHLD.
    
    The noticeable user-visible change is that the execing task is not
    "visible" to do_wait()->eligible_child(__WCLONE) right after exec.
    To me this looks more logical, and this is consistent with mt case.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index b0695a9900ef..1e94d2263ae0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -977,6 +977,9 @@ static int de_thread(struct task_struct *tsk)
 	sig->notify_count = 0;
 
 no_thread_group:
+	/* we have changed execution domain */
+	tsk->exit_signal = SIGCHLD;
+
 	if (current->mm)
 		setmax_mm_hiwater_rss(&sig->maxrss, current->mm);
 

commit e8e3c3d66fd9d1ee2250f68d778cc48c1346d228
Author: Cong Wang <amwang@redhat.com>
Date:   Fri Nov 25 23:14:27 2011 +0800

    fs: remove the second argument of k[un]map_atomic()
    
    Acked-by: Benjamin LaHaise <bcrl@kvack.org>
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index 153dee14fe55..1a07d1c2d78e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1339,13 +1339,13 @@ int remove_arg_zero(struct linux_binprm *bprm)
 			ret = -EFAULT;
 			goto out;
 		}
-		kaddr = kmap_atomic(page, KM_USER0);
+		kaddr = kmap_atomic(page);
 
 		for (; offset < PAGE_SIZE && kaddr[offset];
 				offset++, bprm->p++)
 			;
 
-		kunmap_atomic(kaddr, KM_USER0);
+		kunmap_atomic(kaddr);
 		put_arg_page(page);
 
 		if (offset == PAGE_SIZE)

commit 35239e23c66f1614c76739b62a299c3c92d6eb68
Merge: 3f33ab1c0c74 87e24f4b67e6
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Mar 12 20:44:07 2012 +0100

    Merge branch 'perf/urgent' into perf/core
    
    Merge reason: We are going to queue up a dependent patch.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 57b59c4a1400fa6c34764eab2e35a8762dc05a09
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Mar 5 14:59:13 2012 -0800

    coredump_wait: don't call complete_vfork_done()
    
    Now that CLONE_VFORK is killable, coredump_wait() no longer needs
    complete_vfork_done().  zap_threads() should find and kill all tasks with
    the same ->mm, this includes our parent if ->vfork_done is set.
    
    mm_release() becomes the only caller, unexport complete_vfork_done().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index dccdcec913e9..153dee14fe55 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1926,19 +1926,9 @@ static int coredump_wait(int exit_code, struct core_state *core_state)
 		core_waiters = zap_threads(tsk, mm, core_state, exit_code);
 	up_write(&mm->mmap_sem);
 
-	if (unlikely(core_waiters < 0))
-		goto fail;
-
-	/*
-	 * Make sure nobody is waiting for us to release the VM,
-	 * otherwise we can deadlock when we wait on each other
-	 */
-	if (tsk->vfork_done)
-		complete_vfork_done(tsk);
-
-	if (core_waiters)
+	if (core_waiters > 0)
 		wait_for_completion(&core_state->startup);
-fail:
+
 	return core_waiters;
 }
 

commit c415c3b47ea2754659d915cca387a20999044163
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Mar 5 14:59:13 2012 -0800

    vfork: introduce complete_vfork_done()
    
    No functional changes.
    
    Move the clear-and-complete-vfork_done code into the new trivial helper,
    complete_vfork_done().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 92ce83a11e90..dccdcec913e9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1915,7 +1915,6 @@ static int coredump_wait(int exit_code, struct core_state *core_state)
 {
 	struct task_struct *tsk = current;
 	struct mm_struct *mm = tsk->mm;
-	struct completion *vfork_done;
 	int core_waiters = -EBUSY;
 
 	init_completion(&core_state->startup);
@@ -1934,11 +1933,8 @@ static int coredump_wait(int exit_code, struct core_state *core_state)
 	 * Make sure nobody is waiting for us to release the VM,
 	 * otherwise we can deadlock when we wait on each other
 	 */
-	vfork_done = tsk->vfork_done;
-	if (vfork_done) {
-		tsk->vfork_done = NULL;
-		complete(vfork_done);
-	}
+	if (tsk->vfork_done)
+		complete_vfork_done(tsk);
 
 	if (core_waiters)
 		wait_for_completion(&core_state->startup);

commit 737f24bda723fdf89ecaacb99fa2bf5683c32799
Merge: 8eedce996556 b7c924274c45
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Mar 5 09:20:08 2012 +0100

    Merge branch 'perf/urgent' into perf/core
    
    Conflicts:
            tools/perf/builtin-record.c
            tools/perf/builtin-top.c
            tools/perf/perf.h
            tools/perf/util/top.h
    
    Merge reason: resolve these cherry-picking conflicts.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 4ff16c25e2cc48cbe6956e356c38a25ac063a64d
Author: David Smith <dsmith@redhat.com>
Date:   Tue Feb 7 10:11:05 2012 -0600

    tracepoint, vfs, sched: Add exec() tracepoint
    
    Added a minimal exec tracepoint. Exec is an important major event
    in the life of a task, like fork(), clone() or exit(), all of
    which we already trace.
    
    [ We also do scheduling re-balancing during exec() - so it's useful
      from a scheduler instrumentation POV as well. ]
    
    If you want to watch a task start up, when it gets exec'ed is a good place
    to start.  With the addition of this tracepoint, exec's can be monitored
    and better picture of general system activity can be obtained. This
    tracepoint will also enable better process life tracking, allowing you to
    answer questions like "what process keeps starting up binary X?".
    
    This tracepoint can also be useful in ftrace filtering and trigger
    conditions: i.e. starting or stopping filtering when exec is called.
    
    Signed-off-by: David Smith <dsmith@redhat.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/4F314D19.7030504@redhat.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/exec.c b/fs/exec.c
index aeb135c7ff5c..d0d208092773 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -63,6 +63,8 @@
 #include <trace/events/task.h>
 #include "internal.h"
 
+#include <trace/events/sched.h>
+
 int core_uses_pid;
 char core_pattern[CORENAME_MAX_SIZE] = "core";
 unsigned int core_pipe_limit;
@@ -1401,9 +1403,10 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			 */
 			bprm->recursion_depth = depth;
 			if (retval >= 0) {
-				if (depth == 0)
-					ptrace_event(PTRACE_EVENT_EXEC,
-							old_pid);
+				if (depth == 0) {
+					trace_sched_process_exec(current, old_pid, bprm);
+					ptrace_event(PTRACE_EVENT_EXEC, old_pid);
+				}
 				put_binfmt(fmt);
 				allow_write_access(bprm->file);
 				if (bprm->file)

commit 1fd36adcd98c14d2fd97f545293c488775cb2823
Author: David Howells <dhowells@redhat.com>
Date:   Thu Feb 16 17:49:54 2012 +0000

    Replace the fd_sets in struct fdtable with an array of unsigned longs
    
    Replace the fd_sets in struct fdtable with an array of unsigned longs and then
    use the standard non-atomic bit operations rather than the FD_* macros.
    
    This:
    
     (1) Removes the abuses of struct fd_set:
    
         (a) Since we don't want to allocate a full fd_set the vast majority of the
             time, we actually, in effect, just allocate a just-big-enough array of
             unsigned longs and cast it to an fd_set type - so why bother with the
             fd_set at all?
    
         (b) Some places outside of the core fdtable handling code (such as
             SELinux) want to look inside the array of unsigned longs hidden inside
             the fd_set struct for more efficient iteration over the entire set.
    
     (2) Eliminates the use of FD_*() macros in the kernel completely.
    
     (3) Permits the __FD_*() macros to be deleted entirely where not exposed to
         userspace.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Link: http://lkml.kernel.org/r/20120216174954.23314.48147.stgit@warthog.procyon.org.uk
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 22cc38d9e79f..cfd5e3047bd8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1026,10 +1026,10 @@ static void flush_old_files(struct files_struct * files)
 		fdt = files_fdtable(files);
 		if (i >= fdt->max_fds)
 			break;
-		set = fdt->close_on_exec->fds_bits[j];
+		set = fdt->close_on_exec[j];
 		if (!set)
 			continue;
-		fdt->close_on_exec->fds_bits[j] = 0;
+		fdt->close_on_exec[j] = 0;
 		spin_unlock(&files->file_lock);
 		for ( ; set ; i++,set >>= 1) {
 			if (set & 1) {

commit 1dce27c5aa6770e9d195f2bb7db1db3d4dde5591
Author: David Howells <dhowells@redhat.com>
Date:   Thu Feb 16 17:49:42 2012 +0000

    Wrap accesses to the fd_sets in struct fdtable
    
    Wrap accesses to the fd_sets in struct fdtable (for recording open files and
    close-on-exec flags) so that we can move away from using fd_sets since we
    abuse the fd_set structs by not allocating the full-sized structure under
    normal circumstances and by non-core code looking at the internals of the
    fd_sets.
    
    The first abuse means that use of FD_ZERO() on these fd_sets is not permitted,
    since that cannot be told about their abnormal lengths.
    
    This introduces six wrapper functions for setting, clearing and testing
    close-on-exec flags and fd-is-open flags:
    
            void __set_close_on_exec(int fd, struct fdtable *fdt);
            void __clear_close_on_exec(int fd, struct fdtable *fdt);
            bool close_on_exec(int fd, const struct fdtable *fdt);
            void __set_open_fd(int fd, struct fdtable *fdt);
            void __clear_open_fd(int fd, struct fdtable *fdt);
            bool fd_is_open(int fd, const struct fdtable *fdt);
    
    Note that I've prepended '__' to the names of the set/clear functions because
    they require the caller to hold a lock to use them.
    
    Note also that I haven't added wrappers for looking behind the scenes at the
    the array.  Possibly that should exist too.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Link: http://lkml.kernel.org/r/20120216174942.23314.1364.stgit@warthog.procyon.org.uk
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 92ce83a11e90..22cc38d9e79f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2078,8 +2078,8 @@ static int umh_pipe_setup(struct subprocess_info *info, struct cred *new)
 	fd_install(0, rp);
 	spin_lock(&cf->file_lock);
 	fdt = files_fdtable(cf);
-	FD_SET(0, fdt->open_fds);
-	FD_CLR(0, fdt->close_on_exec);
+	__set_open_fd(0, fdt);
+	__clear_close_on_exec(0, fdt);
 	spin_unlock(&cf->file_lock);
 
 	/* and disallow core files too */

commit 96e02d1586782eadf051fa3d6bc4132d2447ac2c
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sat Feb 4 10:47:10 2012 +0100

    exec: fix use-after-free bug in setup_new_exec()
    
    Setting the task name is done within setup_new_exec() by accessing
    bprm->filename. However this happens after flush_old_exec().
    This may result in a use after free bug, flush_old_exec() may
    "complete" vfork_done, which will wake up the parent which in turn
    may free the passed in filename.
    To fix this add a new tcomm field in struct linux_binprm which
    contains the now early generated task name until it is used.
    
    Fixes this bug on s390:
    
      Unable to handle kernel pointer dereference at virtual kernel address 0000000039768000
      Process kworker/u:3 (pid: 245, task: 000000003a3dc840, ksp: 0000000039453818)
      Krnl PSW : 0704000180000000 0000000000282e94 (setup_new_exec+0xa0/0x374)
      Call Trace:
      ([<0000000000282e2c>] setup_new_exec+0x38/0x374)
       [<00000000002dd12e>] load_elf_binary+0x402/0x1bf4
       [<0000000000280a42>] search_binary_handler+0x38e/0x5bc
       [<0000000000282b6c>] do_execve_common+0x410/0x514
       [<0000000000282cb6>] do_execve+0x46/0x58
       [<00000000005bce58>] kernel_execve+0x28/0x70
       [<000000000014ba2e>] ____call_usermodehelper+0x102/0x140
       [<00000000005bc8da>] kernel_thread_starter+0x6/0xc
       [<00000000005bc8d4>] kernel_thread_starter+0x0/0xc
      Last Breaking-Event-Address:
       [<00000000002830f0>] setup_new_exec+0x2fc/0x374
    
      Kernel panic - not syncing: Fatal exception: panic_on_oops
    
    Reported-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index aeb135c7ff5c..92ce83a11e90 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1071,6 +1071,21 @@ void set_task_comm(struct task_struct *tsk, char *buf)
 	perf_event_comm(tsk);
 }
 
+static void filename_to_taskname(char *tcomm, const char *fn, unsigned int len)
+{
+	int i, ch;
+
+	/* Copies the binary name from after last slash */
+	for (i = 0; (ch = *(fn++)) != '\0';) {
+		if (ch == '/')
+			i = 0; /* overwrite what we wrote */
+		else
+			if (i < len - 1)
+				tcomm[i++] = ch;
+	}
+	tcomm[i] = '\0';
+}
+
 int flush_old_exec(struct linux_binprm * bprm)
 {
 	int retval;
@@ -1085,6 +1100,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 
 	set_mm_exe_file(bprm->mm, bprm->file);
 
+	filename_to_taskname(bprm->tcomm, bprm->filename, sizeof(bprm->tcomm));
 	/*
 	 * Release all of the old mmap stuff
 	 */
@@ -1116,10 +1132,6 @@ EXPORT_SYMBOL(would_dump);
 
 void setup_new_exec(struct linux_binprm * bprm)
 {
-	int i, ch;
-	const char *name;
-	char tcomm[sizeof(current->comm)];
-
 	arch_pick_mmap_layout(current->mm);
 
 	/* This is the point of no return */
@@ -1130,18 +1142,7 @@ void setup_new_exec(struct linux_binprm * bprm)
 	else
 		set_dumpable(current->mm, suid_dumpable);
 
-	name = bprm->filename;
-
-	/* Copies the binary name from after last slash */
-	for (i=0; (ch = *(name++)) != '\0';) {
-		if (ch == '/')
-			i = 0; /* overwrite what we wrote */
-		else
-			if (i < (sizeof(tcomm) - 1))
-				tcomm[i++] = ch;
-	}
-	tcomm[i] = '\0';
-	set_task_comm(current, tcomm);
+	set_task_comm(current, bprm->tcomm);
 
 	/* Set the new mm task size. We have to do that late because it may
 	 * depend on TIF_32BIT which is only updated in flush_thread() on

commit 43d2b113241d6797b890318767e0af78e313414b
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Tue Jan 10 15:08:09 2012 -0800

    tracepoint: add tracepoints for debugging oom_score_adj
    
    oom_score_adj is used for guarding processes from OOM-Killer.  One of
    problem is that it's inherited at fork().  When a daemon set oom_score_adj
    and make children, it's hard to know where the value is set.
    
    This patch adds some tracepoints useful for debugging. This patch adds
    3 trace points.
      - creating new task
      - renaming a task (exec)
      - set oom_score_adj
    
    To debug, users need to enable some trace pointer. Maybe filtering is useful as
    
    # EVENT=/sys/kernel/debug/tracing/events/task/
    # echo "oom_score_adj != 0" > $EVENT/task_newtask/filter
    # echo "oom_score_adj != 0" > $EVENT/task_rename/filter
    # echo 1 > $EVENT/enable
    # EVENT=/sys/kernel/debug/tracing/events/oom/
    # echo 1 > $EVENT/enable
    
    output will be like this.
    # grep oom /sys/kernel/debug/tracing/trace
    bash-7699  [007] d..3  5140.744510: oom_score_adj_update: pid=7699 comm=bash oom_score_adj=-1000
    bash-7699  [007] ...1  5151.818022: task_newtask: pid=7729 comm=bash clone_flags=1200011 oom_score_adj=-1000
    ls-7729  [003] ...2  5151.818504: task_rename: pid=7729 oldcomm=bash newcomm=ls oom_score_adj=-1000
    bash-7699  [002] ...1  5175.701468: task_newtask: pid=7730 comm=bash clone_flags=1200011 oom_score_adj=-1000
    grep-7730  [007] ...2  5175.701993: task_rename: pid=7730 oldcomm=bash newcomm=grep oom_score_adj=-1000
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Acked-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 3f64b9f26e7d..aeb135c7ff5c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -59,6 +59,8 @@
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlb.h>
+
+#include <trace/events/task.h>
 #include "internal.h"
 
 int core_uses_pid;
@@ -1054,6 +1056,8 @@ void set_task_comm(struct task_struct *tsk, char *buf)
 {
 	task_lock(tsk);
 
+	trace_task_rename(tsk, buf);
+
 	/*
 	 * Threads may access current->comm without holding
 	 * the task lock, so write the string carefully.

commit f47ec3f28354795f000c14bf18ed967ec81a3ec3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Nov 21 21:15:42 2011 -0500

    trim fs/internal.h
    
    some stuff in there can actually become static; some belongs to pnode.h
    as it's a private interface between namespace.c and pnode.c...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 36254645b7cc..3f64b9f26e7d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1225,7 +1225,7 @@ EXPORT_SYMBOL(install_exec_creds);
  * - the caller must hold ->cred_guard_mutex to protect against
  *   PTRACE_ATTACH
  */
-int check_unsafe_exec(struct linux_binprm *bprm)
+static int check_unsafe_exec(struct linux_binprm *bprm)
 {
 	struct task_struct *p = current, *t;
 	unsigned n_fs;

commit c9f01245b6a7d77d17deaa71af10f6aca14fa24e
Author: David Rientjes <rientjes@google.com>
Date:   Mon Oct 31 17:07:15 2011 -0700

    oom: remove oom_disable_count
    
    This removes mm->oom_disable_count entirely since it's unnecessary and
    currently buggy.  The counter was intended to be per-process but it's
    currently decremented in the exit path for each thread that exits, causing
    it to underflow.
    
    The count was originally intended to prevent oom killing threads that
    share memory with threads that cannot be killed since it doesn't lead to
    future memory freeing.  The counter could be fixed to represent all
    threads sharing the same mm, but it's better to remove the count since:
    
     - it is possible that the OOM_DISABLE thread sharing memory with the
       victim is waiting on that thread to exit and will actually cause
       future memory freeing, and
    
     - there is no guarantee that a thread is disabled from oom killing just
       because another thread sharing its mm is oom disabled.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Ying Han <yinghan@google.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 25dcbe5fc356..36254645b7cc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -841,10 +841,6 @@ static int exec_mmap(struct mm_struct *mm)
 	tsk->mm = mm;
 	tsk->active_mm = mm;
 	activate_mm(active_mm, mm);
-	if (old_mm && tsk->signal->oom_score_adj == OOM_SCORE_ADJ_MIN) {
-		atomic_dec(&old_mm->oom_disable_count);
-		atomic_inc(&tsk->mm->oom_disable_count);
-	}
 	task_unlock(tsk);
 	arch_pick_mmap_layout(mm);
 	if (old_mm) {

commit 72fa59970f8698023045ab0713d66f3f4f96945c
Author: Vasiliy Kulikov <segoon@openwall.com>
Date:   Mon Aug 8 19:02:04 2011 +0400

    move RLIMIT_NPROC check from set_user() to do_execve_common()
    
    The patch http://lkml.org/lkml/2003/7/13/226 introduced an RLIMIT_NPROC
    check in set_user() to check for NPROC exceeding via setuid() and
    similar functions.
    
    Before the check there was a possibility to greatly exceed the allowed
    number of processes by an unprivileged user if the program relied on
    rlimit only.  But the check created new security threat: many poorly
    written programs simply don't check setuid() return code and believe it
    cannot fail if executed with root privileges.  So, the check is removed
    in this patch because of too often privilege escalations related to
    buggy programs.
    
    The NPROC can still be enforced in the common code flow of daemons
    spawning user processes.  Most of daemons do fork()+setuid()+execve().
    The check introduced in execve() (1) enforces the same limit as in
    setuid() and (2) doesn't create similar security issues.
    
    Neil Brown suggested to track what specific process has exceeded the
    limit by setting PF_NPROC_EXCEEDED process flag.  With the change only
    this process would fail on execve(), and other processes' execve()
    behaviour is not changed.
    
    Solar Designer suggested to re-check whether NPROC limit is still
    exceeded at the moment of execve().  If the process was sleeping for
    days between set*uid() and execve(), and the NPROC counter step down
    under the limit, the defered execve() failure because NPROC limit was
    exceeded days ago would be unexpected.  If the limit is not exceeded
    anymore, we clear the flag on successful calls to execve() and fork().
    
    The flag is also cleared on successful calls to set_user() as the limit
    was exceeded for the previous user, not the current one.
    
    Similar check was introduced in -ow patches (without the process flag).
    
    v3 - clear PF_NPROC_EXCEEDED on successful calls to set_user().
    
    Reviewed-by: James Morris <jmorris@namei.org>
    Signed-off-by: Vasiliy Kulikov <segoon@openwall.com>
    Acked-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index da80612a35f4..25dcbe5fc356 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1459,6 +1459,23 @@ static int do_execve_common(const char *filename,
 	struct files_struct *displaced;
 	bool clear_in_exec;
 	int retval;
+	const struct cred *cred = current_cred();
+
+	/*
+	 * We move the actual failure in case of RLIMIT_NPROC excess from
+	 * set*uid() to execve() because too many poorly written programs
+	 * don't check setuid() return code.  Here we additionally recheck
+	 * whether NPROC limit is still exceeded.
+	 */
+	if ((current->flags & PF_NPROC_EXCEEDED) &&
+	    atomic_read(&cred->user->processes) > rlimit(RLIMIT_NPROC)) {
+		retval = -EAGAIN;
+		goto out_ret;
+	}
+
+	/* We're below the limit (still or again), so we don't want to make
+	 * further execve() calls fail. */
+	current->flags &= ~PF_NPROC_EXCEEDED;
 
 	retval = unshare_files(&displaced);
 	if (retval)

commit 32e107f71e4a993ac438f0049aa4019457911ffb
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Jul 26 16:08:43 2011 -0700

    fs/exec.c:acct_arg_size(): ptl is no longer needed for add_mm_counter()
    
    acct_arg_size() takes ->page_table_lock around add_mm_counter() if
    !SPLIT_RSS_COUNTING.  This is not needed after commit 172703b08cd0 ("mm:
    delete non-atomic mm counter implementation").
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>
    Cc: Dave Hansen <dave@linux.vnet.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0e8e59939d09..da80612a35f4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -181,14 +181,7 @@ static void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
 		return;
 
 	bprm->vma_pages = pages;
-
-#ifdef SPLIT_RSS_COUNTING
-	add_mm_counter(mm, MM_ANONPAGES, diff);
-#else
-	spin_lock(&mm->page_table_lock);
 	add_mm_counter(mm, MM_ANONPAGES, diff);
-	spin_unlock(&mm->page_table_lock);
-#endif
 }
 
 static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,

commit b4edf8bd06916645b57df23a720b17cae4051c43
Author: Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp>
Date:   Tue Jul 26 16:08:42 2011 -0700

    exec: do not retry load_binary method if CONFIG_MODULES=n
    
    If CONFIG_MODULES=n, it makes no sense to retry the list of binary formats
    handler because the list will not be modified by request_module().
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e6770a526f34..0e8e59939d09 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1430,9 +1430,9 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			}
 		}
 		read_unlock(&binfmt_lock);
+#ifdef CONFIG_MODULES
 		if (retval != -ENOEXEC || bprm->mm == NULL) {
 			break;
-#ifdef CONFIG_MODULES
 		} else {
 #define printable(c) (((c)=='\t') || ((c)=='\n') || (0x20<=(c) && (c)<=0x7e))
 			if (printable(bprm->buf[0]) &&
@@ -1443,8 +1443,10 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			if (try)
 				break; /* -ENOEXEC */
 			request_module("binfmt-%04x", *(unsigned short *)(&bprm->buf[2]));
-#endif
 		}
+#else
+		break;
+#endif
 	}
 	return retval;
 }

commit 912193521b719fbfc2f16776febf5232fe8ba261
Author: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Date:   Tue Jul 26 16:08:41 2011 -0700

    exec: do not call request_module() twice from search_binary_handler()
    
    Currently, search_binary_handler() tries to load binary loader module
    using request_module() if a loader for the requested program is not yet
    loaded.  But second attempt of request_module() does not affect the result
    of search_binary_handler().
    
    If request_module() triggered recursion, calling request_module() twice
    causes 2 to the power of MAX_KMOD_CONCURRENT (= 50) repetitions.  It is
    not an infinite loop but is sufficient for users to consider as a hang up.
    
    Therefore, this patch changes not to call request_module() twice, making 1
    to the power of MAX_KMOD_CONCURRENT repetitions in case of recursion.
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Reported-by: Richard Weinberger <richard@nod.at>
    Tested-by: Richard Weinberger <richard@nod.at>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 01829a1cb766..e6770a526f34 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1440,6 +1440,8 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			    printable(bprm->buf[2]) &&
 			    printable(bprm->buf[3]))
 				break; /* -ENOEXEC */
+			if (try)
+				break; /* -ENOEXEC */
 			request_module("binfmt-%04x", *(unsigned short *)(&bprm->buf[2]));
 #endif
 		}

commit aacb3d17a73f6447c04e4d769391238dcf85568d
Author: Michal Hocko <mhocko@suse.cz>
Date:   Tue Jul 26 16:08:40 2011 -0700

    fs/exec.c: use BUILD_BUG_ON for VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP
    
    Commit a8bef8ff6ea1 ("mm: migration: avoid race between
    shift_arg_pages() and rmap_walk() during migration by not migrating
    temporary stacks") introduced a BUG_ON() to ensure that VM_STACK_FLAGS
    and VM_STACK_INCOMPLETE_SETUP do not overlap.  The check is a compile
    time one, so BUILD_BUG_ON is more appropriate.
    
    Signed-off-by: Michal Hocko <mhocko@suse.cz>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Richard Weinberger <richard@nod.at>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index f8fad7fc0e5f..01829a1cb766 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -277,7 +277,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	 * use STACK_TOP because that can depend on attributes which aren't
 	 * configured yet.
 	 */
-	BUG_ON(VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP);
+	BUILD_BUG_ON(VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP);
 	vma->vm_end = STACK_TOP_MAX;
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
 	vma->vm_flags = VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;

commit 99b64567486716d18b2156cad188d86478816e4f
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Jul 26 16:08:34 2011 -0700

    do_coredump: fix the "ispipe" error check
    
    do_coredump() assumes that if format_corename() fails it should return
    -ENOMEM.  This is not true, for example cn_print_exe_file() can propagate
    the error from d_path.  Even if it was true, this is too fragile.  Change
    the code to check "ispipe < 0".
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Reviewed-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 27d487f913d3..f8fad7fc0e5f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2133,16 +2133,16 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 
 	ispipe = format_corename(&cn, signr);
 
-	if (ispipe == -ENOMEM) {
-		printk(KERN_WARNING "format_corename failed\n");
-		printk(KERN_WARNING "Aborting core\n");
-		goto fail_corename;
-	}
-
  	if (ispipe) {
 		int dump_count;
 		char **helper_argv;
 
+		if (ispipe < 0) {
+			printk(KERN_WARNING "format_corename failed\n");
+			printk(KERN_WARNING "Aborting core\n");
+			goto fail_corename;
+		}
+
 		if (cprm.limit == 1) {
 			/*
 			 * Normally core limits are irrelevant to pipes, since

commit 2c563731fee0f625924f72e854957bc77601e8b3
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Tue Jul 26 16:08:33 2011 -0700

    coredump: escape / in hostname and comm
    
    Change every occurence of / in comm and hostname to !.  If the process
    changes its name to contain /, the core is not dumped (if the directory
    tree doesn't exist like that).  The same with hostname being something
    like myhost/3.  Fix this behaviour by using the escape loop used in %E.
    (We extract it to a separate function.)
    
    Now both with comm == myprocess/1 and hostname == myhost/1, the core is
    dumped like (kernel.core_pattern='core.%p.%e.%h):
    core.2349.myprocess!1.myhost!1
    
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a682624de572..27d487f913d3 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1649,15 +1649,26 @@ static int cn_printf(struct core_name *cn, const char *fmt, ...)
 	return ret;
 }
 
+static void cn_escape(char *str)
+{
+	for (; *str; str++)
+		if (*str == '/')
+			*str = '!';
+}
+
 static int cn_print_exe_file(struct core_name *cn)
 {
 	struct file *exe_file;
-	char *pathbuf, *path, *p;
+	char *pathbuf, *path;
 	int ret;
 
 	exe_file = get_mm_exe_file(current->mm);
-	if (!exe_file)
-		return cn_printf(cn, "%s (path unknown)", current->comm);
+	if (!exe_file) {
+		char *commstart = cn->corename + cn->used;
+		ret = cn_printf(cn, "%s (path unknown)", current->comm);
+		cn_escape(commstart);
+		return ret;
+	}
 
 	pathbuf = kmalloc(PATH_MAX, GFP_TEMPORARY);
 	if (!pathbuf) {
@@ -1671,9 +1682,7 @@ static int cn_print_exe_file(struct core_name *cn)
 		goto free_buf;
 	}
 
-	for (p = path; *p; p++)
-		if (*p == '/')
-			*p = '!';
+	cn_escape(path);
 
 	ret = cn_printf(cn, "%s", path);
 
@@ -1745,16 +1754,22 @@ static int format_corename(struct core_name *cn, long signr)
 				break;
 			}
 			/* hostname */
-			case 'h':
+			case 'h': {
+				char *namestart = cn->corename + cn->used;
 				down_read(&uts_sem);
 				err = cn_printf(cn, "%s",
 					      utsname()->nodename);
 				up_read(&uts_sem);
+				cn_escape(namestart);
 				break;
+			}
 			/* executable */
-			case 'e':
+			case 'e': {
+				char *commstart = cn->corename + cn->used;
 				err = cn_printf(cn, "%s", current->comm);
+				cn_escape(commstart);
 				break;
+			}
 			case 'E':
 				err = cn_print_exe_file(cn);
 				break;

commit 3141c8b165644774eb0e83d8330fbe47e45b37bf
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Tue Jul 26 16:08:32 2011 -0700

    coredump: use task comm instead of (unknown)
    
    If we don't know the file corresponding to the binary (i.e.  exe_file is
    unknown), use "task->comm (path unknown)" instead of simple "(unknown)"
    as suggested by ak.
    
    The fallback is the same as %e except it will append "(path unknown)".
    
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 842d5700c155..a682624de572 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1657,7 +1657,7 @@ static int cn_print_exe_file(struct core_name *cn)
 
 	exe_file = get_mm_exe_file(current->mm);
 	if (!exe_file)
-		return cn_printf(cn, "(unknown)");
+		return cn_printf(cn, "%s (path unknown)", current->comm);
 
 	pathbuf = kmalloc(PATH_MAX, GFP_TEMPORARY);
 	if (!pathbuf) {

commit bbd9d6f7fbb0305c9a592bf05a32e87eb364a4ff
Merge: 8e204874db00 5a9a43646cf7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 22 19:02:39 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6: (107 commits)
      vfs: use ERR_CAST for err-ptr tossing in lookup_instantiate_filp
      isofs: Remove global fs lock
      jffs2: fix IN_DELETE_SELF on overwriting rename() killing a directory
      fix IN_DELETE_SELF on overwriting rename() on ramfs et.al.
      mm/truncate.c: fix build for CONFIG_BLOCK not enabled
      fs:update the NOTE of the file_operations structure
      Remove dead code in dget_parent()
      AFS: Fix silly characters in a comment
      switch d_add_ci() to d_splice_alias() in "found negative" case as well
      simplify gfs2_lookup()
      jfs_lookup(): don't bother with . or ..
      get rid of useless dget_parent() in btrfs rename() and link()
      get rid of useless dget_parent() in fs/btrfs/ioctl.c
      fs: push i_mutex and filemap_write_and_wait down into ->fsync() handlers
      drivers: fix up various ->llseek() implementations
      fs: handle SEEK_HOLE/SEEK_DATA properly in all fs's that define their own llseek
      Ext4: handle SEEK_HOLE/SEEK_DATA generically
      Btrfs: implement our own ->llseek
      fs: add SEEK_HOLE and SEEK_DATA flags
      reiserfs: make reiserfs default to barrier=flush
      ...
    
    Fix up trivial conflicts in fs/xfs/linux-2.6/xfs_super.c due to the new
    shrinker callout for the inode cache, that clashed with the xfs code to
    start the periodic workers later.

commit 8209f53d79444747782a28520187abaf689761f2
Merge: 22a3b9771117 eac1b5e57d7a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 22 15:06:50 2011 -0700

    Merge branch 'ptrace' of git://git.kernel.org/pub/scm/linux/kernel/git/oleg/misc
    
    * 'ptrace' of git://git.kernel.org/pub/scm/linux/kernel/git/oleg/misc: (39 commits)
      ptrace: do_wait(traced_leader_killed_by_mt_exec) can block forever
      ptrace: fix ptrace_signal() && STOP_DEQUEUED interaction
      connector: add an event for monitoring process tracers
      ptrace: dont send SIGSTOP on auto-attach if PT_SEIZED
      ptrace: mv send-SIGSTOP from do_fork() to ptrace_init_task()
      ptrace_init_task: initialize child->jobctl explicitly
      has_stopped_jobs: s/task_is_stopped/SIGNAL_STOP_STOPPED/
      ptrace: make former thread ID available via PTRACE_GETEVENTMSG after PTRACE_EVENT_EXEC stop
      ptrace: wait_consider_task: s/same_thread_group/ptrace_reparented/
      ptrace: kill real_parent_is_ptracer() in in favor of ptrace_reparented()
      ptrace: ptrace_reparented() should check same_thread_group()
      redefine thread_group_leader() as exit_signal >= 0
      do not change dead_task->exit_signal
      kill task_detached()
      reparent_leader: check EXIT_DEAD instead of task_detached()
      make do_notify_parent() __must_check, update the callers
      __ptrace_detach: avoid task_detached(), check do_notify_parent()
      kill tracehook_notify_death()
      make do_notify_parent() return bool
      ptrace: s/tracehook_tracer_task()/ptrace_parent()/
      ...

commit eac1b5e57d7abc836e78fd3fbcf77dbeed01edc9
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jul 21 20:00:43 2011 +0200

    ptrace: do_wait(traced_leader_killed_by_mt_exec) can block forever
    
    Test-case:
    
            void *tfunc(void *arg)
            {
                    execvp("true", NULL);
                    return NULL;
            }
    
            int main(void)
            {
                    int pid;
    
                    if (fork()) {
                            pthread_t t;
    
                            kill(getpid(), SIGSTOP);
    
                            pthread_create(&t, NULL, tfunc, NULL);
    
                            for (;;)
                                    pause();
                    }
    
                    pid = getppid();
                    assert(ptrace(PTRACE_ATTACH, pid, 0,0) == 0);
    
                    while (wait(NULL) > 0)
                            ptrace(PTRACE_CONT, pid, 0,0);
    
                    return 0;
            }
    
    It is racy, exit_notify() does __wake_up_parent() too. But in the
    likely case it triggers the problem: de_thread() does release_task()
    and the old leader goes away without the notification, the tracer
    sleeps in do_wait() without children/tracees.
    
    Change de_thread() to do __wake_up_parent(traced_leader->parent).
    Since it is already EXIT_DEAD we can do this without ptrace_unlink(),
    EXIT_DEAD threads do not exist from do_wait's pov.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index b08367abf30e..d219541db06c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -967,6 +967,14 @@ static int de_thread(struct task_struct *tsk)
 
 		BUG_ON(leader->exit_state != EXIT_ZOMBIE);
 		leader->exit_state = EXIT_DEAD;
+
+		/*
+		 * We are going to release_task()->ptrace_unlink() silently,
+		 * the tracer can sleep in do_wait(). EXIT_DEAD guarantees
+		 * the tracer wont't block again waiting for this thread.
+		 */
+		if (unlikely(leader->ptrace))
+			__wake_up_parent(leader, leader->parent);
 		write_unlock_irq(&tasklist_lock);
 
 		release_task(leader);

commit 1b5d783c94c328d406e801566f161adcfb018dda
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jun 19 12:49:47 2011 -0400

    consolidate BINPRM_FLAGS_ENFORCE_NONDUMP handling
    
    new helper: would_dump(bprm, file).  Checks if we are allowed to
    read the file and if we are not - sets ENFORCE_NODUMP.  Exported,
    used in places that previously open-coded the same logics.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 6075a1e727ae..f9f12ad299af 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1105,6 +1105,13 @@ int flush_old_exec(struct linux_binprm * bprm)
 }
 EXPORT_SYMBOL(flush_old_exec);
 
+void would_dump(struct linux_binprm *bprm, struct file *file)
+{
+	if (inode_permission(file->f_path.dentry->d_inode, MAY_READ) < 0)
+		bprm->interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP;
+}
+EXPORT_SYMBOL(would_dump);
+
 void setup_new_exec(struct linux_binprm * bprm)
 {
 	int i, ch;
@@ -1144,9 +1151,10 @@ void setup_new_exec(struct linux_binprm * bprm)
 	if (bprm->cred->uid != current_euid() ||
 	    bprm->cred->gid != current_egid()) {
 		current->pdeath_signal = 0;
-	} else if (file_permission(bprm->file, MAY_READ) ||
-		   bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP) {
-		set_dumpable(current->mm, suid_dumpable);
+	} else {
+		would_dump(bprm, bprm->file);
+		if (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)
+			set_dumpable(current->mm, suid_dumpable);
 	}
 
 	/*

commit bb188d7e64deb0e9cf13a99f44ae0065de5352d6
Author: Denys Vlasenko <vda.linux@googlemail.com>
Date:   Wed Jun 29 04:13:39 2011 +0200

    ptrace: make former thread ID available via PTRACE_GETEVENTMSG after PTRACE_EVENT_EXEC stop
    
    When multithreaded program execs under ptrace,
    all traced threads report WIFEXITED status, except for
    thread group leader and the thread which execs.
    
    Unless tracer tracks thread group relationship between tracees,
    which is a nontrivial task, it will not detect that
    execed thread no longer exists.
    
    This patch allows tracer to figure out which thread
    performed this exec, by requesting PTRACE_GETEVENTMSG
    in PTRACE_EVENT_EXEC stop.
    
    Another, samller problem which is solved by this patch
    is that tracer now can figure out which of the several
    concurrent execs in multithreaded program succeeded.
    
    Signed-off-by: Denys Vlasenko <vda.linux@googlemail.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index c3d517bfdd27..b08367abf30e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1358,6 +1358,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 	unsigned int depth = bprm->recursion_depth;
 	int try,retval;
 	struct linux_binfmt *fmt;
+	pid_t old_pid;
 
 	retval = security_bprm_check(bprm);
 	if (retval)
@@ -1371,6 +1372,11 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 	if (retval)
 		return retval;
 
+	/* Need to fetch pid before load_binary changes it */
+	rcu_read_lock();
+	old_pid = task_pid_nr_ns(current, task_active_pid_ns(current->parent));
+	rcu_read_unlock();
+
 	retval = -ENOENT;
 	for (try=0; try<2; try++) {
 		read_lock(&binfmt_lock);
@@ -1390,7 +1396,8 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			bprm->recursion_depth = depth;
 			if (retval >= 0) {
 				if (depth == 0)
-					ptrace_event(PTRACE_EVENT_EXEC, 0);
+					ptrace_event(PTRACE_EVENT_EXEC,
+							old_pid);
 				put_binfmt(fmt);
 				allow_write_access(bprm->file);
 				if (bprm->file)

commit 087806b1281563e4ae7a5bce3155f894af5f4118
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jun 22 23:10:26 2011 +0200

    redefine thread_group_leader() as exit_signal >= 0
    
    Change de_thread() to set old_leader->exit_signal = -1. This is
    good for the consistency, it is no longer the leader and all
    sub-threads have exit_signal = -1 set by copy_process(CLONE_THREAD).
    
    And this allows us to micro-optimize thread_group_leader(), it can
    simply check exit_signal >= 0. This also makes sense because we
    should move ->group_leader from task_struct to signal_struct.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Tejun Heo <tj@kernel.org>

diff --git a/fs/exec.c b/fs/exec.c
index 8dca45b0dae8..c3d517bfdd27 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -963,6 +963,7 @@ static int de_thread(struct task_struct *tsk)
 		leader->group_leader = tsk;
 
 		tsk->exit_signal = SIGCHLD;
+		leader->exit_signal = -1;
 
 		BUG_ON(leader->exit_state != EXIT_ZOMBIE);
 		leader->exit_state = EXIT_DEAD;

commit 4b9d33e6d83cc05a8005a8f9a8b9677fa0f53626
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jun 17 16:50:38 2011 +0200

    ptrace: kill clone/exec tracehooks
    
    At this point, tracehooks aren't useful to mainline kernel and mostly
    just add an extra layer of obfuscation.  Although they have comments,
    without actual in-kernel users, it is difficult to tell what are their
    assumptions and they're actually trying to achieve.  To mainline
    kernel, they just aren't worth keeping around.
    
    This patch kills the following clone and exec related tracehooks.
    
            tracehook_prepare_clone()
            tracehook_finish_clone()
            tracehook_report_clone()
            tracehook_report_clone_complete()
            tracehook_unsafe_exec()
    
    The changes are mostly trivial - logic is moved to the caller and
    comments are merged and adjusted appropriately.
    
    The only exception is in check_unsafe_exec() where LSM_UNSAFE_PTRACE*
    are OR'd to bprm->unsafe instead of setting it, which produces the
    same result as the field is always zero on entry.  It also tests
    p->ptrace instead of (p->ptrace & PT_PTRACED) for consistency, which
    also gives the same result.
    
    This doesn't introduce any behavior change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index b37030d0a50b..8dca45b0dae8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1224,7 +1224,12 @@ int check_unsafe_exec(struct linux_binprm *bprm)
 	unsigned n_fs;
 	int res = 0;
 
-	bprm->unsafe = tracehook_unsafe_exec(p);
+	if (p->ptrace) {
+		if (p->ptrace & PT_PTRACE_CAP)
+			bprm->unsafe |= LSM_UNSAFE_PTRACE_CAP;
+		else
+			bprm->unsafe |= LSM_UNSAFE_PTRACE;
+	}
 
 	n_fs = 1;
 	spin_lock(&p->fs->lock);

commit a288eecce5253cc1565d400a52b9b476a157e040
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jun 17 16:50:37 2011 +0200

    ptrace: kill trivial tracehooks
    
    At this point, tracehooks aren't useful to mainline kernel and mostly
    just add an extra layer of obfuscation.  Although they have comments,
    without actual in-kernel users, it is difficult to tell what are their
    assumptions and they're actually trying to achieve.  To mainline
    kernel, they just aren't worth keeping around.
    
    This patch kills the following trivial tracehooks.
    
    * Ones testing whether task is ptraced.  Replace with ->ptrace test.
    
            tracehook_expect_breakpoints()
            tracehook_consider_ignored_signal()
            tracehook_consider_fatal_signal()
    
    * ptrace_event() wrappers.  Call directly.
    
            tracehook_report_exec()
            tracehook_report_exit()
            tracehook_report_vfork_done()
    
    * ptrace_release_task() wrapper.  Call directly.
    
            tracehook_finish_release_task()
    
    * noop
    
            tracehook_prepare_release_task()
            tracehook_report_death()
    
    This doesn't introduce any behavior change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index a9f2b3631bdb..b37030d0a50b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1384,7 +1384,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			bprm->recursion_depth = depth;
 			if (retval >= 0) {
 				if (depth == 0)
-					tracehook_report_exec(fmt, bprm, regs);
+					ptrace_event(PTRACE_EVENT_EXEC, 0);
 				put_binfmt(fmt);
 				allow_write_access(bprm->file);
 				if (bprm->file)

commit 879669961b11e7f40b518784863a259f735a72bf
Author: David Howells <dhowells@redhat.com>
Date:   Fri Jun 17 11:25:59 2011 +0100

    KEYS/DNS: Fix ____call_usermodehelper() to not lose the session keyring
    
    ____call_usermodehelper() now erases any credentials set by the
    subprocess_inf::init() function.  The problem is that commit
    17f60a7da150 ("capabilites: allow the application of capability limits
    to usermode helpers") creates and commits new credentials with
    prepare_kernel_cred() after the call to the init() function.  This wipes
    all keyrings after umh_keys_init() is called.
    
    The best way to deal with this is to put the init() call just prior to
    the commit_creds() call, and pass the cred pointer to init().  That
    means that umh_keys_init() and suchlike can modify the credentials
    _before_ they are published and potentially in use by the rest of the
    system.
    
    This prevents request_key() from working as it is prevented from passing
    the session keyring it set up with the authorisation token to
    /sbin/request-key, and so the latter can't assume the authority to
    instantiate the key.  This causes the in-kernel DNS resolver to fail
    with ENOKEY unconditionally.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Eric Paris <eparis@redhat.com>
    Tested-by: Jeff Layton <jlayton@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 97e0d52d72fd..6075a1e727ae 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1996,7 +1996,7 @@ static void wait_for_dump_helpers(struct file *file)
  * is a special value that we use to trap recursive
  * core dumps
  */
-static int umh_pipe_setup(struct subprocess_info *info)
+static int umh_pipe_setup(struct subprocess_info *info, struct cred *new)
 {
 	struct file *rp, *wp;
 	struct fdtable *fdt;

commit 13fca640bb8ab611a50e0ba120b186faa2994d6c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 15 21:53:52 2011 -0700

    Revert "fs/exec.c: use BUILD_BUG_ON for VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP"
    
    This reverts commit 7f81c8890c15a10f5220bebae3b6dfae4961962a.
    
    It turns out that it's not actually a build-time check on x86-64 UML,
    which does some seriously crazy stuff with VM_STACK_FLAGS.
    
    The VM_STACK_FLAGS define depends on the arch-supplied
    VM_STACK_DEFAULT_FLAGS value, and on x86-64 UML we have
    
      arch/um/sys-x86_64/shared/sysdep/vm-flags.h:
    
            #define VM_STACK_DEFAULT_FLAGS \
                    (test_thread_flag(TIF_IA32) ? vm_stack_flags32 : vm_stack_flags)
    
            #define VM_STACK_DEFAULT_FLAGS vm_stack_flags
    
    (yes, seriously: two different #define's for that thing, with the first
    one being inside an "#ifdef TIF_IA32")
    
    It's possible that it is UML that should just be fixed in this area, but
    for now let's just undo the (very small) optimization.
    
    Reported-by: Randy Dunlap <randy.dunlap@oracle.com>
    Acked-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Richard Weinberger <richard@nod.at>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index b54f74f3cd80..97e0d52d72fd 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -277,7 +277,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	 * use STACK_TOP because that can depend on attributes which aren't
 	 * configured yet.
 	 */
-	BUILD_BUG_ON(VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP);
+	BUG_ON(VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP);
 	vma->vm_end = STACK_TOP_MAX;
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
 	vma->vm_flags = VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;

commit 7f81c8890c15a10f5220bebae3b6dfae4961962a
Author: Michal Hocko <mhocko@suse.cz>
Date:   Wed Jun 15 15:08:11 2011 -0700

    fs/exec.c: use BUILD_BUG_ON for VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP
    
    Commit a8bef8ff6ea1 ("mm: migration: avoid race between shift_arg_pages()
    and rmap_walk() during migration by not migrating temporary stacks")
    introduced a BUG_ON() to ensure that VM_STACK_FLAGS and
    VM_STACK_INCOMPLETE_SETUP do not overlap.  The check is a compile time
    one, so BUILD_BUG_ON is more appropriate.
    
    Signed-off-by: Michal Hocko <mhocko@suse.cz>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 97e0d52d72fd..b54f74f3cd80 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -277,7 +277,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	 * use STACK_TOP because that can depend on attributes which aren't
 	 * configured yet.
 	 */
-	BUG_ON(VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP);
+	BUILD_BUG_ON(VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP);
 	vma->vm_end = STACK_TOP_MAX;
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
 	vma->vm_flags = VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;

commit dac853ae89043f1b7752875300faf614de43c74b
Author: Mathias Krause <minipli@googlemail.com>
Date:   Thu Jun 9 20:05:18 2011 +0200

    exec: delay address limit change until point of no return
    
    Unconditionally changing the address limit to USER_DS and not restoring
    it to its old value in the error path is wrong because it prevents us
    using kernel memory on repeated calls to this function.  This, in fact,
    breaks the fallback of hard coded paths to the init program from being
    ever successful if the first candidate fails to load.
    
    With this patch applied switching to USER_DS is delayed until the point
    of no return is reached which makes it possible to have a multi-arch
    rootfs with one arch specific init binary for each of the (hard coded)
    probed paths.
    
    Since the address limit is already set to USER_DS when start_thread()
    will be invoked, this redundancy can be safely removed.
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ea5f748906a8..97e0d52d72fd 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1093,6 +1093,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 
 	bprm->mm = NULL;		/* We're using it now */
 
+	set_fs(USER_DS);
 	current->flags &= ~(PF_RANDOMIZE | PF_KTHREAD);
 	flush_thread();
 	current->personality &= ~bprm->per_clear;
@@ -1357,10 +1358,6 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 	if (retval)
 		return retval;
 
-	/* kernel module loader fixup */
-	/* so we don't try to load run modprobe in kernel space. */
-	set_fs(USER_DS);
-
 	retval = audit_bprm(bprm);
 	if (retval)
 		return retval;

commit 6dfca32984237a8a011b5bf367e53341a265b2a4
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:14:00 2011 +0200

    job control: make task_clear_jobctl_pending() clear TRAPPING automatically
    
    JOBCTL_TRAPPING indicates that ptracer is waiting for tracee to
    (re)transit into TRACED.  task_clear_jobctl_pending() must be called
    when either tracee enters TRACED or the transition is cancelled for
    some reason.  The former is achieved by explicitly calling
    task_clear_jobctl_pending() in ptrace_stop() and the latter by calling
    it at the end of do_signal_stop().
    
    Calling task_clear_jobctl_trapping() at the end of do_signal_stop()
    limits the scope TRAPPING can be used and is fragile in that seemingly
    unrelated changes to tracee's control flow can lead to stuck TRAPPING.
    
    We already have task_clear_jobctl_pending() calls on those cancelling
    events to clear JOBCTL_STOP_PENDING.  Cancellations can be handled by
    making those call sites use JOBCTL_PENDING_MASK instead and updating
    task_clear_jobctl_pending() such that task_clear_jobctl_trapping() is
    called automatically if no stop/trap is pending.
    
    This patch makes the above changes and removes the fallback
    task_clear_jobctl_trapping() call from do_signal_stop().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index 4402105287cb..a9f2b3631bdb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1772,7 +1772,7 @@ static int zap_process(struct task_struct *start, int exit_code)
 
 	t = start;
 	do {
-		task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
+		task_clear_jobctl_pending(t, JOBCTL_PENDING_MASK);
 		if (t != current && t->mm) {
 			sigaddset(&t->pending.signal, SIGKILL);
 			signal_wake_up(t, 1);

commit 3759a0d94c18764247b66511d1038f2b93aa95de
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:14:00 2011 +0200

    job control: introduce JOBCTL_PENDING_MASK and task_clear_jobctl_pending()
    
    This patch introduces JOBCTL_PENDING_MASK and replaces
    task_clear_jobctl_stop_pending() with task_clear_jobctl_pending()
    which takes an extra @mask argument.
    
    JOBCTL_PENDING_MASK is currently equal to JOBCTL_STOP_PENDING but
    future patches will add more bits.  recalc_sigpending_tsk() is updated
    to use JOBCTL_PENDING_MASK instead.
    
    task_clear_jobctl_pending() takes @mask which in subset of
    JOBCTL_PENDING_MASK and clears the relevant jobctl bits.  If
    JOBCTL_STOP_PENDING is set, other STOP bits are cleared together.  All
    task_clear_jobctl_stop_pending() users are updated to call
    task_clear_jobctl_pending() with JOBCTL_STOP_PENDING which is
    functionally identical to task_clear_jobctl_stop_pending().
    
    This patch doesn't cause any functional change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index 8986bb0f9dc2..4402105287cb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1772,7 +1772,7 @@ static int zap_process(struct task_struct *start, int exit_code)
 
 	t = start;
 	do {
-		task_clear_jobctl_stop_pending(t);
+		task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
 		if (t != current && t->mm) {
 			sigaddset(&t->pending.signal, SIGKILL);
 			signal_wake_up(t, 1);

commit a8f072c1d624a627b67f2ace2f0c25d856ef4e54
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:13:59 2011 +0200

    job control: rename signal->group_stop and flags to jobctl and update them
    
    signal->group_stop currently hosts mostly group stop related flags;
    however, it's gonna be used for wider purposes and the GROUP_STOP_
    flag prefix becomes confusing.  Rename signal->group_stop to
    signal->jobctl and rename all GROUP_STOP_* flags to JOBCTL_*.
    
    Bit position macros JOBCTL_*_BIT are defined and JOBCTL_* flags are
    defined in terms of them to allow using bitops later.
    
    While at it, reassign JOBCTL_TRAPPING to bit 22 to better accomodate
    future additions.
    
    This doesn't cause any functional change.
    
    -v2: JOBCTL_*_BIT macros added as suggested by Linus.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index ea5f748906a8..8986bb0f9dc2 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1772,7 +1772,7 @@ static int zap_process(struct task_struct *start, int exit_code)
 
 	t = start;
 	do {
-		task_clear_group_stop_pending(t);
+		task_clear_jobctl_stop_pending(t);
 		if (t != current && t->mm) {
 			sigaddset(&t->pending.signal, SIGKILL);
 			signal_wake_up(t, 1);

commit 57cc083ad9e1bfeeb4a0ee831e7bb008c8865bf0
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu May 26 16:25:46 2011 -0700

    coredump: add support for exe_file in core name
    
    Now, exe_file is not proc FS dependent, so we can use it to name core
    file.  So we add %E pattern for core file name cration which extract path
    from mm_struct->exe_file.  Then it converts slashes to exclamation marks
    and pastes the result to the core file name itself.
    
    This is useful for environments where binary names are longer than 16
    character (the current->comm limitation).  Also where there are binaries
    with same name but in a different path.  Further in case the binery itself
    changes its current->comm after exec.
    
    So by doing (s/$/#/ -- # is treated as git comment):
    
      $ sysctl kernel.core_pattern='core.%p.%e.%E'
      $ ln /bin/cat cat45678901234567890
      $ ./cat45678901234567890
      ^Z
      $ rm cat45678901234567890
      $ fg
      ^\Quit (core dumped)
      $ ls core*
    
    we now get:
    
      core.2434.cat456789012345.!root!cat45678901234567890 (deleted)
    
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Reviewed-by: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 88a16c572282..ea5f748906a8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1623,6 +1623,41 @@ static int cn_printf(struct core_name *cn, const char *fmt, ...)
 	return ret;
 }
 
+static int cn_print_exe_file(struct core_name *cn)
+{
+	struct file *exe_file;
+	char *pathbuf, *path, *p;
+	int ret;
+
+	exe_file = get_mm_exe_file(current->mm);
+	if (!exe_file)
+		return cn_printf(cn, "(unknown)");
+
+	pathbuf = kmalloc(PATH_MAX, GFP_TEMPORARY);
+	if (!pathbuf) {
+		ret = -ENOMEM;
+		goto put_exe_file;
+	}
+
+	path = d_path(&exe_file->f_path, pathbuf, PATH_MAX);
+	if (IS_ERR(path)) {
+		ret = PTR_ERR(path);
+		goto free_buf;
+	}
+
+	for (p = path; *p; p++)
+		if (*p == '/')
+			*p = '!';
+
+	ret = cn_printf(cn, "%s", path);
+
+free_buf:
+	kfree(pathbuf);
+put_exe_file:
+	fput(exe_file);
+	return ret;
+}
+
 /* format_corename will inspect the pattern parameter, and output a
  * name into corename, which must have space for at least
  * CORENAME_MAX_SIZE bytes plus one byte for the zero terminator.
@@ -1694,6 +1729,9 @@ static int format_corename(struct core_name *cn, long signr)
 			case 'e':
 				err = cn_printf(cn, "%s", current->comm);
 				break;
+			case 'E':
+				err = cn_print_exe_file(cn);
+				break;
 			/* core limit size */
 			case 'c':
 				err = cn_printf(cn, "%lu",

commit 3864601387cf4196371e3c1897fdffa5228296f9
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu May 26 16:25:46 2011 -0700

    mm: extract exe_file handling from procfs
    
    Setup and cleanup of mm_struct->exe_file is currently done in fs/proc/.
    This was because exe_file was needed only for /proc/<pid>/exe.  Since we
    will need the exe_file functionality also for core dumps (so core name can
    contain full binary path), built this functionality always into the
    kernel.
    
    To achieve that move that out of proc FS to the kernel/ where in fact it
    should belong.  By doing that we can make dup_mm_exe_file static.  Also we
    can drop linux/proc_fs.h inclusion in fs/exec.c and kernel/fork.c.
    
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 936f5776655c..88a16c572282 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -42,7 +42,6 @@
 #include <linux/pid_namespace.h>
 #include <linux/module.h>
 #include <linux/namei.h>
-#include <linux/proc_fs.h>
 #include <linux/mount.h>
 #include <linux/security.h>
 #include <linux/syscalls.h>

commit d16dfc550f5326a4000f3322582a7c05dec91d7a
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue May 24 17:11:45 2011 -0700

    mm: mmu_gather rework
    
    Rework the existing mmu_gather infrastructure.
    
    The direct purpose of these patches was to allow preemptible mmu_gather,
    but even without that I think these patches provide an improvement to the
    status quo.
    
    The first 9 patches rework the mmu_gather infrastructure.  For review
    purpose I've split them into generic and per-arch patches with the last of
    those a generic cleanup.
    
    The next patch provides generic RCU page-table freeing, and the followup
    is a patch converting s390 to use this.  I've also got 4 patches from
    DaveM lined up (not included in this series) that uses this to implement
    gup_fast() for sparc64.
    
    Then there is one patch that extends the generic mmu_gather batching.
    
    After that follow the mm preemptibility patches, these make part of the mm
    a lot more preemptible.  It converts i_mmap_lock and anon_vma->lock to
    mutexes which together with the mmu_gather rework makes mmu_gather
    preemptible as well.
    
    Making i_mmap_lock a mutex also enables a clean-up of the truncate code.
    
    This also allows for preemptible mmu_notifiers, something that XPMEM I
    think wants.
    
    Furthermore, it removes the new and universially detested unmap_mutex.
    
    This patch:
    
    Remove the first obstacle towards a fully preemptible mmu_gather.
    
    The current scheme assumes mmu_gather is always done with preemption
    disabled and uses per-cpu storage for the page batches.  Change this to
    try and allocate a page for batching and in case of failure, use a small
    on-stack array to make some progress.
    
    Preemptible mmu_gather is desired in general and usable once i_mmap_lock
    becomes a mutex.  Doing it before the mutex conversion saves us from
    having to rework the code by moving the mmu_gather bits inside the
    pte_lock.
    
    Also avoid flushing the tlb batches from under the pte lock, this is
    useful even without the i_mmap_lock conversion as it significantly reduces
    pte lock hold times.
    
    [akpm@linux-foundation.org: fix comment tpyo]
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: David Miller <davem@davemloft.net>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Tony Luck <tony.luck@intel.com>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Hugh Dickins <hughd@google.com>
    Acked-by: Mel Gorman <mel@csn.ul.ie>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Nick Piggin <npiggin@kernel.dk>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e276d5e0abb9..936f5776655c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -600,7 +600,7 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 	unsigned long length = old_end - old_start;
 	unsigned long new_start = old_start - shift;
 	unsigned long new_end = old_end - shift;
-	struct mmu_gather *tlb;
+	struct mmu_gather tlb;
 
 	BUG_ON(new_start > new_end);
 
@@ -626,12 +626,12 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 		return -ENOMEM;
 
 	lru_add_drain();
-	tlb = tlb_gather_mmu(mm, 0);
+	tlb_gather_mmu(&tlb, mm, 0);
 	if (new_end > old_start) {
 		/*
 		 * when the old and new regions overlap clear from new_end.
 		 */
-		free_pgd_range(tlb, new_end, old_end, new_end,
+		free_pgd_range(&tlb, new_end, old_end, new_end,
 			vma->vm_next ? vma->vm_next->vm_start : 0);
 	} else {
 		/*
@@ -640,10 +640,10 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 		 * have constraints on va-space that make this illegal (IA64) -
 		 * for the others its just a little faster.
 		 */
-		free_pgd_range(tlb, old_start, old_end, new_end,
+		free_pgd_range(&tlb, old_start, old_end, new_end,
 			vma->vm_next ? vma->vm_next->vm_start : 0);
 	}
-	tlb_finish_mmu(tlb, new_end, old_end);
+	tlb_finish_mmu(&tlb, new_end, old_end);
 
 	/*
 	 * Shrink the vma to just the new range.  Always succeeds.

commit d05f3169c0fbca16132ec7c2be71685c6de638b5
Author: Michal Hocko <mhocko@suse.cz>
Date:   Tue May 24 17:11:44 2011 -0700

    mm: make expand_downwards() symmetrical with expand_upwards()
    
    Currently we have expand_upwards exported while expand_downwards is
    accessible only via expand_stack or expand_stack_downwards.
    
    check_stack_guard_page is a nice example of the asymmetry.  It uses
    expand_stack for VM_GROWSDOWN while expand_upwards is called for
    VM_GROWSUP case.
    
    Let's clean this up by exporting both functions and make those names
    consistent.  Let's use expand_{upwards,downwards} because expanding
    doesn't always involve stack manipulation (an example is
    ia64_do_page_fault which uses expand_upwards for registers backing store
    expansion).  expand_downwards has to be defined for both
    CONFIG_STACK_GROWS{UP,DOWN} because get_arg_page calls the downwards
    version in the early process initialization phase for growsup
    configuration.
    
    Signed-off-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Hugh Dickins <hughd@google.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index c1cf372f17a7..e276d5e0abb9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -200,7 +200,7 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 
 #ifdef CONFIG_STACK_GROWSUP
 	if (write) {
-		ret = expand_stack_downwards(bprm->vma, pos);
+		ret = expand_downwards(bprm->vma, pos);
 		if (ret < 0)
 			return NULL;
 	}

commit 99dff5856220a02b8711f2e8746413ea6e53ccf6
Merge: bb74e8ca352e d9a0fbfd7bc5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 23 12:23:20 2011 -0700

    Merge branch 'tty-next' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty-2.6
    
    * 'tty-next' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty-2.6: (48 commits)
      serial: 8250_pci: add support for Cronyx Omega PCI multiserial board.
      tty/serial: Fix break handling for PORT_TEGRA
      tty/serial: Add explicit PORT_TEGRA type
      n_tracerouter and n_tracesink ldisc additions.
      Intel PTI implementaiton of MIPI 1149.7.
      Kernel documentation for the PTI feature.
      export kernel call get_task_comm().
      tty: Remove to support serial for S5P6442
      pch_phub: Support new device ML7223
      8250_pci: Add support for the Digi/IBM PCIe 2-port Adapter
      ASoC: Update cx20442 for TTY API change
      pch_uart: Support new device ML7223 IOH
      parport: Use request_muxed_region for IT87 probe and lock
      tty/serial: add support for Xilinx PS UART
      n_gsm: Use print_hex_dump_bytes
      drivers/tty/moxa.c: Put correct tty value
      TTY: tty_io, annotate locking functions
      TTY: serial_core, remove superfluous set_task_state
      TTY: serial_core, remove invalid test
      Char: moxa, fix locking in moxa_write
      ...
    
    Fix up trivial conflicts in drivers/bluetooth/hci_ldisc.c and
    drivers/tty/serial/Makefile.
    
    I did the hci_ldisc thing as an evil merge, cleaning things up.

commit 4d9dec4db2efbd7edb549bd02373995b67496983
Merge: 34b064569eba ae6b585eeb74
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 23 08:28:34 2011 -0700

    Merge branch 'exec_rm_compat' of git://git.kernel.org/pub/scm/linux/kernel/git/oleg/misc
    
    * 'exec_rm_compat' of git://git.kernel.org/pub/scm/linux/kernel/git/oleg/misc:
      exec: document acct_arg_size()
      exec: unify do_execve/compat_do_execve code
      exec: introduce struct user_arg_ptr
      exec: introduce get_user_arg_ptr() helper

commit 7d74f492e4dd0034a61458eb80f70b1d2862ed07
Author: J Freyensee <james_p_freyensee@linux.intel.com>
Date:   Fri May 6 16:56:47 2011 -0700

    export kernel call get_task_comm().
    
    This allows drivers who call this function to be compiled modularly.
    Otherwise, a driver who is interested in this type of functionality
    has to implement their own get_task_comm() call, causing code
    duplication in the Linux source tree.
    
    Signed-off-by: J Freyensee <james_p_freyensee@linux.intel.com>
    Acked-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/fs/exec.c b/fs/exec.c
index 5e62d26a4fec..7de94950a5b4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1004,6 +1004,7 @@ char *get_task_comm(char *buf, struct task_struct *tsk)
 	task_unlock(tsk);
 	return buf;
 }
+EXPORT_SYMBOL_GPL(get_task_comm);
 
 void set_task_comm(struct task_struct *tsk, char *buf)
 {

commit ae6b585eeb74670a2dec1fe4394bdfbdb9395cc2
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sun Mar 6 18:03:11 2011 +0100

    exec: document acct_arg_size()
    
    Add the comment to explain acct_arg_size().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>

diff --git a/fs/exec.c b/fs/exec.c
index 89d788ca7829..5cb53f0232b1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -167,7 +167,12 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 }
 
 #ifdef CONFIG_MMU
-
+/*
+ * The nascent bprm->mm is not visible until exec_mmap() but it can
+ * use a lot of memory, account these pages in current->mm temporary
+ * for oom_badness()->get_mm_rss(). Once exec succeeds or fails, we
+ * change the counter back via acct_arg_size(0).
+ */
 static void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
 {
 	struct mm_struct *mm = current->mm;

commit 0e028465d18b7c6797fcbdea632299d16097c5cd
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sun Mar 6 18:02:54 2011 +0100

    exec: unify do_execve/compat_do_execve code
    
    Add the appropriate members into struct user_arg_ptr and teach
    get_user_arg_ptr() to handle is_compat = T case correctly.
    
    This allows us to remove the compat_do_execve() code from fs/compat.c
    and reimplement compat_do_execve() as the trivial wrapper on top of
    do_execve_common(is_compat => true).
    
    In fact, this fixes another (minor) bug. "compat_uptr_t str" can
    overflow after "str += len" in compat_copy_strings() if a 64bit
    application execs via sys32_execve().
    
    Unexport acct_arg_size() and get_arg_page(), fs/compat.c doesn't
    need them any longer.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Tested-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>

diff --git a/fs/exec.c b/fs/exec.c
index 526a0399d963..89d788ca7829 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -55,6 +55,7 @@
 #include <linux/fs_struct.h>
 #include <linux/pipe_fs_i.h>
 #include <linux/oom.h>
+#include <linux/compat.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -167,7 +168,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 
 #ifdef CONFIG_MMU
 
-void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
+static void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
 {
 	struct mm_struct *mm = current->mm;
 	long diff = (long)(pages - bprm->vma_pages);
@@ -186,7 +187,7 @@ void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
 #endif
 }
 
-struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
+static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		int write)
 {
 	struct page *page;
@@ -305,11 +306,11 @@ static bool valid_arg_len(struct linux_binprm *bprm, long len)
 
 #else
 
-void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
+static inline void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
 {
 }
 
-struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
+static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		int write)
 {
 	struct page *page;
@@ -399,17 +400,36 @@ int bprm_mm_init(struct linux_binprm *bprm)
 }
 
 struct user_arg_ptr {
-	const char __user *const __user *native;
+#ifdef CONFIG_COMPAT
+	bool is_compat;
+#endif
+	union {
+		const char __user *const __user *native;
+#ifdef CONFIG_COMPAT
+		compat_uptr_t __user *compat;
+#endif
+	} ptr;
 };
 
 static const char __user *get_user_arg_ptr(struct user_arg_ptr argv, int nr)
 {
-	const char __user *ptr;
+	const char __user *native;
+
+#ifdef CONFIG_COMPAT
+	if (unlikely(argv.is_compat)) {
+		compat_uptr_t compat;
+
+		if (get_user(compat, argv.ptr.compat + nr))
+			return ERR_PTR(-EFAULT);
 
-	if (get_user(ptr, argv.native + nr))
+		return compat_ptr(compat);
+	}
+#endif
+
+	if (get_user(native, argv.ptr.native + nr))
 		return ERR_PTR(-EFAULT);
 
-	return ptr;
+	return native;
 }
 
 /*
@@ -419,7 +439,7 @@ static int count(struct user_arg_ptr argv, int max)
 {
 	int i = 0;
 
-	if (argv.native != NULL) {
+	if (argv.ptr.native != NULL) {
 		for (;;) {
 			const char __user *p = get_user_arg_ptr(argv, i);
 
@@ -542,7 +562,7 @@ int copy_strings_kernel(int argc, const char *const *__argv,
 	int r;
 	mm_segment_t oldfs = get_fs();
 	struct user_arg_ptr argv = {
-		.native = (const char __user *const  __user *)__argv,
+		.ptr.native = (const char __user *const  __user *)__argv,
 	};
 
 	set_fs(KERNEL_DS);
@@ -1516,10 +1536,28 @@ int do_execve(const char *filename,
 	const char __user *const __user *__envp,
 	struct pt_regs *regs)
 {
-	struct user_arg_ptr argv = { .native = __argv };
-	struct user_arg_ptr envp = { .native = __envp };
+	struct user_arg_ptr argv = { .ptr.native = __argv };
+	struct user_arg_ptr envp = { .ptr.native = __envp };
+	return do_execve_common(filename, argv, envp, regs);
+}
+
+#ifdef CONFIG_COMPAT
+int compat_do_execve(char *filename,
+	compat_uptr_t __user *__argv,
+	compat_uptr_t __user *__envp,
+	struct pt_regs *regs)
+{
+	struct user_arg_ptr argv = {
+		.is_compat = true,
+		.ptr.compat = __argv,
+	};
+	struct user_arg_ptr envp = {
+		.is_compat = true,
+		.ptr.compat = __envp,
+	};
 	return do_execve_common(filename, argv, envp, regs);
 }
+#endif
 
 void set_binfmt(struct linux_binfmt *new)
 {

commit ba2d01629d0d167598cfea85adc7926822bbfc45
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sun Mar 6 18:02:37 2011 +0100

    exec: introduce struct user_arg_ptr
    
    No functional changes, preparation.
    
    Introduce struct user_arg_ptr, change do_execve() paths to use it
    instead of "char __user * const __user *argv".
    
    This makes the argv/envp arguments opaque, we are ready to handle the
    compat case which needs argv pointing to compat_uptr_t.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Tested-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>

diff --git a/fs/exec.c b/fs/exec.c
index b12e24fe1c5e..526a0399d963 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -398,12 +398,15 @@ int bprm_mm_init(struct linux_binprm *bprm)
 	return err;
 }
 
-static const char __user *
-get_user_arg_ptr(const char __user * const __user *argv, int nr)
+struct user_arg_ptr {
+	const char __user *const __user *native;
+};
+
+static const char __user *get_user_arg_ptr(struct user_arg_ptr argv, int nr)
 {
 	const char __user *ptr;
 
-	if (get_user(ptr, argv + nr))
+	if (get_user(ptr, argv.native + nr))
 		return ERR_PTR(-EFAULT);
 
 	return ptr;
@@ -412,11 +415,11 @@ get_user_arg_ptr(const char __user * const __user *argv, int nr)
 /*
  * count() counts the number of strings in array ARGV.
  */
-static int count(const char __user * const __user * argv, int max)
+static int count(struct user_arg_ptr argv, int max)
 {
 	int i = 0;
 
-	if (argv != NULL) {
+	if (argv.native != NULL) {
 		for (;;) {
 			const char __user *p = get_user_arg_ptr(argv, i);
 
@@ -442,7 +445,7 @@ static int count(const char __user * const __user * argv, int max)
  * processes's memory to the new process's stack.  The call to get_user_pages()
  * ensures the destination page is created and not swapped out.
  */
-static int copy_strings(int argc, const char __user *const __user *argv,
+static int copy_strings(int argc, struct user_arg_ptr argv,
 			struct linux_binprm *bprm)
 {
 	struct page *kmapped_page = NULL;
@@ -533,14 +536,19 @@ static int copy_strings(int argc, const char __user *const __user *argv,
 /*
  * Like copy_strings, but get argv and its values from kernel memory.
  */
-int copy_strings_kernel(int argc, const char *const *argv,
+int copy_strings_kernel(int argc, const char *const *__argv,
 			struct linux_binprm *bprm)
 {
 	int r;
 	mm_segment_t oldfs = get_fs();
+	struct user_arg_ptr argv = {
+		.native = (const char __user *const  __user *)__argv,
+	};
+
 	set_fs(KERNEL_DS);
-	r = copy_strings(argc, (const char __user *const  __user *)argv, bprm);
+	r = copy_strings(argc, argv, bprm);
 	set_fs(oldfs);
+
 	return r;
 }
 EXPORT_SYMBOL(copy_strings_kernel);
@@ -1393,10 +1401,10 @@ EXPORT_SYMBOL(search_binary_handler);
 /*
  * sys_execve() executes a new program.
  */
-int do_execve(const char * filename,
-	const char __user *const __user *argv,
-	const char __user *const __user *envp,
-	struct pt_regs * regs)
+static int do_execve_common(const char *filename,
+				struct user_arg_ptr argv,
+				struct user_arg_ptr envp,
+				struct pt_regs *regs)
 {
 	struct linux_binprm *bprm;
 	struct file *file;
@@ -1503,6 +1511,16 @@ int do_execve(const char * filename,
 	return retval;
 }
 
+int do_execve(const char *filename,
+	const char __user *const __user *__argv,
+	const char __user *const __user *__envp,
+	struct pt_regs *regs)
+{
+	struct user_arg_ptr argv = { .native = __argv };
+	struct user_arg_ptr envp = { .native = __envp };
+	return do_execve_common(filename, argv, envp, regs);
+}
+
 void set_binfmt(struct linux_binfmt *new)
 {
 	struct mm_struct *mm = current->mm;

commit 1d1dbf8135ab2f3603cc72e39e0f68784f453c39
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sun Mar 6 18:02:21 2011 +0100

    exec: introduce get_user_arg_ptr() helper
    
    Introduce get_user_arg_ptr() helper, convert count() and copy_strings()
    to use it.
    
    No functional changes, preparation. This helper is trivial, it just
    reads the pointer from argv/envp user-space array.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Tested-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>

diff --git a/fs/exec.c b/fs/exec.c
index 5e62d26a4fec..b12e24fe1c5e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -398,6 +398,17 @@ int bprm_mm_init(struct linux_binprm *bprm)
 	return err;
 }
 
+static const char __user *
+get_user_arg_ptr(const char __user * const __user *argv, int nr)
+{
+	const char __user *ptr;
+
+	if (get_user(ptr, argv + nr))
+		return ERR_PTR(-EFAULT);
+
+	return ptr;
+}
+
 /*
  * count() counts the number of strings in array ARGV.
  */
@@ -407,13 +418,14 @@ static int count(const char __user * const __user * argv, int max)
 
 	if (argv != NULL) {
 		for (;;) {
-			const char __user * p;
+			const char __user *p = get_user_arg_ptr(argv, i);
 
-			if (get_user(p, argv))
-				return -EFAULT;
 			if (!p)
 				break;
-			argv++;
+
+			if (IS_ERR(p))
+				return -EFAULT;
+
 			if (i++ >= max)
 				return -E2BIG;
 
@@ -443,16 +455,18 @@ static int copy_strings(int argc, const char __user *const __user *argv,
 		int len;
 		unsigned long pos;
 
-		if (get_user(str, argv+argc) ||
-				!(len = strnlen_user(str, MAX_ARG_STRLEN))) {
-			ret = -EFAULT;
+		ret = -EFAULT;
+		str = get_user_arg_ptr(argv, argc);
+		if (IS_ERR(str))
 			goto out;
-		}
 
-		if (!valid_arg_len(bprm, len)) {
-			ret = -E2BIG;
+		len = strnlen_user(str, MAX_ARG_STRLEN);
+		if (!len)
+			goto out;
+
+		ret = -E2BIG;
+		if (!valid_arg_len(bprm, len))
 			goto out;
-		}
 
 		/* We're going to work our way backwords. */
 		pos = bprm->p;

commit 39efa3ef3a376a4e53de2f82fc91182459d34200
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:00 2011 +0100

    signal: Use GROUP_STOP_PENDING to stop once for a single group stop
    
    Currently task->signal->group_stop_count is used to decide whether to
    stop for group stop.  However, if there is a task in the group which
    is taking a long time to stop, other tasks which are continued by
    ptrace would repeatedly stop for the same group stop until the group
    stop is complete.
    
    Conversely, if a ptraced task is in TASK_TRACED state, the debugger
    won't get notified of group stops which is inconsistent compared to
    the ptraced task in any other state.
    
    This patch introduces GROUP_STOP_PENDING which tracks whether a task
    is yet to stop for the group stop in progress.  The flag is set when a
    group stop starts and cleared when the task stops the first time for
    the group stop, and consulted whenever whether the task should
    participate in a group stop needs to be determined.  Note that now
    tasks in TASK_TRACED also participate in group stop.
    
    This results in the following behavior changes.
    
    * For a single group stop, a ptracer would see at most one stop
      reported.
    
    * A ptracee in TASK_TRACED now also participates in group stop and the
      tracer would get the notification.  However, as a ptraced task could
      be in TASK_STOPPED state or any ptrace trap could consume group
      stop, the notification may still be missing.  These will be
      addressed with further patches.
    
    * A ptracee may start a group stop while one is still in progress if
      the tracer let it continue with stop signal delivery.  Group stop
      code handles this correctly.
    
    Oleg:
    
    * Spotted that a task might skip signal check even when its
      GROUP_STOP_PENDING is set.  Fixed by updating
      recalc_sigpending_tsk() to check GROUP_STOP_PENDING instead of
      group_stop_count.
    
    * Pointed out that task->group_stop should be cleared whenever
      task->signal->group_stop_count is cleared.  Fixed accordingly.
    
    * Pointed out the behavior inconsistency between TASK_TRACED and
      RUNNING and the last behavior change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index 5e62d26a4fec..8328beb9016f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1659,6 +1659,7 @@ static int zap_process(struct task_struct *start, int exit_code)
 
 	t = start;
 	do {
+		task_clear_group_stop_pending(t);
 		if (t != current && t->mm) {
 			sigaddset(&t->pending.signal, SIGKILL);
 			signal_wake_up(t, 1);

commit 1bef82917c74249ff21982127e57defd6ca2bb1b
Author: Holger Hans Peter Freyther <holger@freyther.de>
Date:   Thu Feb 24 17:46:49 2011 +0100

    Small typo fix...
    
    Hi,
    
    I was backporting the coredump over pipe feature and noticed this small typo,
    I wish I would have something bigger to contribute...
    
    >From 15d6080e0ed4267da103c706917a33b1015e8804 Mon Sep 17 00:00:00 2001
    From: Holger Hans Peter Freyther <holger@moiji-mobile.com>
    Date: Thu, 24 Feb 2011 17:42:50 +0100
    Subject: [PATCH] fs: Fix a small typo in the comment
    
    The function is called umh_pipe_setup not uhm_pipe_setup.
    
    Signed-off-by: Holger Hans Peter Freyther <holger@moiji-mobile.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index ba99e1abb1aa..5e62d26a4fec 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1875,7 +1875,7 @@ static void wait_for_dump_helpers(struct file *file)
 
 
 /*
- * uhm_pipe_setup
+ * umh_pipe_setup
  * helper function to customize the process used
  * to collect the core in userspace.  Specifically
  * it sets up a pipe and installs it as fd 0 (stdin)

commit 47c805dc2d2dff686962f5f0baa6bac2d703ba19
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Feb 23 17:44:09 2011 -0500

    switch do_filp_open() to struct open_flags
    
    take calculation of open_flags by open(2) arguments into new helper
    in fs/open.c, move filp_open() over there, have it and do_sys_open()
    use that helper, switch exec.c callers of do_filp_open() to explicit
    (and constant) struct open_flags.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 52a447d9b6ab..ba99e1abb1aa 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -115,13 +115,16 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 	struct file *file;
 	char *tmp = getname(library);
 	int error = PTR_ERR(tmp);
+	static const struct open_flags uselib_flags = {
+		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
+		.acc_mode = MAY_READ | MAY_EXEC | MAY_OPEN,
+		.intent = LOOKUP_OPEN
+	};
 
 	if (IS_ERR(tmp))
 		goto out;
 
-	file = do_filp_open(AT_FDCWD, tmp,
-				O_LARGEFILE | O_RDONLY | __FMODE_EXEC, 0,
-				MAY_READ | MAY_EXEC | MAY_OPEN);
+	file = do_filp_open(AT_FDCWD, tmp, &uselib_flags, LOOKUP_FOLLOW);
 	putname(tmp);
 	error = PTR_ERR(file);
 	if (IS_ERR(file))
@@ -721,10 +724,13 @@ struct file *open_exec(const char *name)
 {
 	struct file *file;
 	int err;
+	static const struct open_flags open_exec_flags = {
+		.open_flag = O_LARGEFILE | O_RDONLY | __FMODE_EXEC,
+		.acc_mode = MAY_EXEC | MAY_OPEN,
+		.intent = LOOKUP_OPEN
+	};
 
-	file = do_filp_open(AT_FDCWD, name,
-				O_LARGEFILE | O_RDONLY | __FMODE_EXEC, 0,
-				MAY_EXEC | MAY_OPEN);
+	file = do_filp_open(AT_FDCWD, name, &open_exec_flags, LOOKUP_FOLLOW);
 	if (IS_ERR(file))
 		goto out;
 

commit 3cd90ea42f2c15f928b70ed66f6d8ed0a8e7aadd
Author: Namhyung Kim <namhyung@gmail.com>
Date:   Tue Feb 1 15:52:46 2011 -0800

    vfs: sparse: add __FMODE_EXEC
    
    FMODE_EXEC is a constant type of fmode_t but was used with normal integer
    constants.  This results in following warnings from sparse.  Fix it using
    new macro __FMODE_EXEC.
    
     fs/exec.c:116:58: warning: restricted fmode_t degrades to integer
     fs/exec.c:689:58: warning: restricted fmode_t degrades to integer
     fs/fcntl.c:777:9: warning: restricted fmode_t degrades to integer
    
    Signed-off-by: Namhyung Kim <namhyung@gmail.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index c62efcb959c7..52a447d9b6ab 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -120,7 +120,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 		goto out;
 
 	file = do_filp_open(AT_FDCWD, tmp,
-				O_LARGEFILE | O_RDONLY | FMODE_EXEC, 0,
+				O_LARGEFILE | O_RDONLY | __FMODE_EXEC, 0,
 				MAY_READ | MAY_EXEC | MAY_OPEN);
 	putname(tmp);
 	error = PTR_ERR(file);
@@ -723,7 +723,7 @@ struct file *open_exec(const char *name)
 	int err;
 
 	file = do_filp_open(AT_FDCWD, name,
-				O_LARGEFILE | O_RDONLY | FMODE_EXEC, 0,
+				O_LARGEFILE | O_RDONLY | __FMODE_EXEC, 0,
 				MAY_EXEC | MAY_OPEN);
 	if (IS_ERR(file))
 		goto out;

commit 462e635e5b73ba9a4c03913b77138cd57ce4b050
Author: Tavis Ormandy <taviso@cmpxchg8b.com>
Date:   Thu Dec 9 15:29:42 2010 +0100

    install_special_mapping skips security_file_mmap check.
    
    The install_special_mapping routine (used, for example, to setup the
    vdso) skips the security check before insert_vm_struct, allowing a local
    attacker to bypass the mmap_min_addr security restriction by limiting
    the available pages for special mappings.
    
    bprm_mm_init() also skips the check, and although I don't think this can
    be used to bypass any restrictions, I don't see any reason not to have
    the security check.
    
      $ uname -m
      x86_64
      $ cat /proc/sys/vm/mmap_min_addr
      65536
      $ cat install_special_mapping.s
      section .bss
          resb BSS_SIZE
      section .text
          global _start
          _start:
              mov     eax, __NR_pause
              int     0x80
      $ nasm -D__NR_pause=29 -DBSS_SIZE=0xfffed000 -f elf -o install_special_mapping.o install_special_mapping.s
      $ ld -m elf_i386 -Ttext=0x10000 -Tbss=0x11000 -o install_special_mapping install_special_mapping.o
      $ ./install_special_mapping &
      [1] 14303
      $ cat /proc/14303/maps
      0000f000-00010000 r-xp 00000000 00:00 0                                  [vdso]
      00010000-00011000 r-xp 00001000 00:19 2453665                            /home/taviso/install_special_mapping
      00011000-ffffe000 rwxp 00000000 00:00 0                                  [stack]
    
    It's worth noting that Red Hat are shipping with mmap_min_addr set to
    4096.
    
    Signed-off-by: Tavis Ormandy <taviso@google.com>
    Acked-by: Kees Cook <kees@ubuntu.com>
    Acked-by: Robert Swiecki <swiecki@google.com>
    [ Changed to not drop the error code - akpm ]
    Reviewed-by: James Morris <jmorris@namei.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index d68c378a3137..c62efcb959c7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -275,6 +275,11 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	vma->vm_flags = VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 	INIT_LIST_HEAD(&vma->anon_vma_chain);
+
+	err = security_file_mmap(NULL, 0, 0, 0, vma->vm_start, 1);
+	if (err)
+		goto err;
+
 	err = insert_vm_struct(mm, vma);
 	if (err)
 		goto err;

commit 114279be2120a916e8a04feeb2ac976a10016f2f
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Nov 30 20:56:02 2010 +0100

    exec: copy-and-paste the fixes into compat_do_execve() paths
    
    Note: this patch targets 2.6.37 and tries to be as simple as possible.
    That is why it adds more copy-and-paste horror into fs/compat.c and
    uglifies fs/exec.c, this will be cleanuped later.
    
    compat_copy_strings() plays with bprm->vma/mm directly and thus has
    two problems: it lacks the RLIMIT_STACK check and argv/envp memory
    is not visible to oom killer.
    
    Export acct_arg_size() and get_arg_page(), change compat_copy_strings()
    to use get_arg_page(), change compat_do_execve() to do acct_arg_size(0)
    as do_execve() does.
    
    Add the fatal_signal_pending/cond_resched checks into compat_count() and
    compat_copy_strings(), this matches the code in fs/exec.c and certainly
    makes sense.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4303b9035fe7..d68c378a3137 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -164,7 +164,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 
 #ifdef CONFIG_MMU
 
-static void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
+void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
 {
 	struct mm_struct *mm = current->mm;
 	long diff = (long)(pages - bprm->vma_pages);
@@ -183,7 +183,7 @@ static void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
 #endif
 }
 
-static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
+struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		int write)
 {
 	struct page *page;
@@ -297,11 +297,11 @@ static bool valid_arg_len(struct linux_binprm *bprm, long len)
 
 #else
 
-static inline void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
+void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
 {
 }
 
-static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
+struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		int write)
 {
 	struct page *page;

commit 3c77f845722158206a7209c45ccddc264d19319c
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Nov 30 20:55:34 2010 +0100

    exec: make argv/envp memory visible to oom-killer
    
    Brad Spengler published a local memory-allocation DoS that
    evades the OOM-killer (though not the virtual memory RLIMIT):
    http://www.grsecurity.net/~spender/64bit_dos.c
    
    execve()->copy_strings() can allocate a lot of memory, but
    this is not visible to oom-killer, nobody can see the nascent
    bprm->mm and take it into account.
    
    With this patch get_arg_page() increments current's MM_ANONPAGES
    counter every time we allocate the new page for argv/envp. When
    do_execve() succeds or fails, we change this counter back.
    
    Technically this is not 100% correct, we can't know if the new
    page is swapped out and turn MM_ANONPAGES into MM_SWAPENTS, but
    I don't think this really matters and everything becomes correct
    once exec changes ->mm or fails.
    
    Reported-by: Brad Spengler <spender@grsecurity.net>
    Reviewed-and-discussed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 99d33a1371e9..4303b9035fe7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -164,6 +164,25 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 
 #ifdef CONFIG_MMU
 
+static void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
+{
+	struct mm_struct *mm = current->mm;
+	long diff = (long)(pages - bprm->vma_pages);
+
+	if (!mm || !diff)
+		return;
+
+	bprm->vma_pages = pages;
+
+#ifdef SPLIT_RSS_COUNTING
+	add_mm_counter(mm, MM_ANONPAGES, diff);
+#else
+	spin_lock(&mm->page_table_lock);
+	add_mm_counter(mm, MM_ANONPAGES, diff);
+	spin_unlock(&mm->page_table_lock);
+#endif
+}
+
 static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		int write)
 {
@@ -186,6 +205,8 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		unsigned long size = bprm->vma->vm_end - bprm->vma->vm_start;
 		struct rlimit *rlim;
 
+		acct_arg_size(bprm, size / PAGE_SIZE);
+
 		/*
 		 * We've historically supported up to 32 pages (ARG_MAX)
 		 * of argument strings even with small stacks
@@ -276,6 +297,10 @@ static bool valid_arg_len(struct linux_binprm *bprm, long len)
 
 #else
 
+static inline void acct_arg_size(struct linux_binprm *bprm, unsigned long pages)
+{
+}
+
 static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		int write)
 {
@@ -1003,6 +1028,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	/*
 	 * Release all of the old mmap stuff
 	 */
+	acct_arg_size(bprm, 0);
 	retval = exec_mmap(bprm->mm);
 	if (retval)
 		goto out;
@@ -1426,8 +1452,10 @@ int do_execve(const char * filename,
 	return retval;
 
 out:
-	if (bprm->mm)
-		mmput (bprm->mm);
+	if (bprm->mm) {
+		acct_arg_size(bprm, 0);
+		mmput(bprm->mm);
+	}
 
 out_file:
 	if (bprm->file) {

commit 98391cf4dcf893e9e74e1c14189851dbc9c5ad0d
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Wed Oct 27 15:34:16 2010 -0700

    exec: don't turn PF_KTHREAD off when a target command was not found
    
    Presently do_execve() turns PF_KTHREAD off before search_binary_handler().
     THis has a theorical risk of PF_KTHREAD getting lost.  We don't have to
    turn PF_KTHREAD off in the ENOEXEC case.
    
    This patch moves this flag modification to after the finding of the
    executable file.
    
    This is only a theorical issue because kthreads do not call do_execve()
    directly.  But fixing would be better.
    
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ca01d2d0a6d4..99d33a1371e9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1009,7 +1009,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 
 	bprm->mm = NULL;		/* We're using it now */
 
-	current->flags &= ~PF_RANDOMIZE;
+	current->flags &= ~(PF_RANDOMIZE | PF_KTHREAD);
 	flush_thread();
 	current->personality &= ~bprm->per_clear;
 
@@ -1412,7 +1412,6 @@ int do_execve(const char * filename,
 	if (retval < 0)
 		goto out;
 
-	current->flags &= ~PF_KTHREAD;
 	retval = search_binary_handler(bprm,regs);
 	if (retval < 0)
 		goto out;

commit 1b0d300bd0f047e2edaf9d4b6784189e6c67c3d1
Author: Xiaotian Feng <dfeng@redhat.com>
Date:   Wed Oct 27 15:34:08 2010 -0700

    core_pattern: fix truncation by core_pattern handler with long parameters
    
    We met a parameter truncated issue, consider following:
    > echo "|/root/core_pattern_pipe_test %p /usr/libexec/blah-blah-blah \
    %s %c %p %u %g 11 12345678901234567890123456789012345678 %t" > \
    /proc/sys/kernel/core_pattern
    
    This is okay because the strings is less than CORENAME_MAX_SIZE.  "cat
    /proc/sys/kernel/core_pattern" shows the whole string.  but after we run
    core_pattern_pipe_test in man page, we found last parameter was truncated
    like below:
    
            argc[10]=<12807486>
    
    The root cause is core_pattern allows % specifiers, which need to be
    replaced during parse time, but the replace may expand the strings to
    larger than CORENAME_MAX_SIZE.  So if the last parameter is % specifiers,
    the replace code is using snprintf(out_ptr, out_end - out_ptr, ...), this
    will write out of corename array.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Xiaotian Feng <dfeng@redhat.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Reviewed-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9722909c4d88..ca01d2d0a6d4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -66,6 +66,12 @@ char core_pattern[CORENAME_MAX_SIZE] = "core";
 unsigned int core_pipe_limit;
 int suid_dumpable = 0;
 
+struct core_name {
+	char *corename;
+	int used, size;
+};
+static atomic_t call_count = ATOMIC_INIT(1);
+
 /* The maximal length of core_pattern is also specified in sysctl.c */
 
 static LIST_HEAD(formats);
@@ -1459,127 +1465,148 @@ void set_binfmt(struct linux_binfmt *new)
 
 EXPORT_SYMBOL(set_binfmt);
 
+static int expand_corename(struct core_name *cn)
+{
+	char *old_corename = cn->corename;
+
+	cn->size = CORENAME_MAX_SIZE * atomic_inc_return(&call_count);
+	cn->corename = krealloc(old_corename, cn->size, GFP_KERNEL);
+
+	if (!cn->corename) {
+		kfree(old_corename);
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+static int cn_printf(struct core_name *cn, const char *fmt, ...)
+{
+	char *cur;
+	int need;
+	int ret;
+	va_list arg;
+
+	va_start(arg, fmt);
+	need = vsnprintf(NULL, 0, fmt, arg);
+	va_end(arg);
+
+	if (likely(need < cn->size - cn->used - 1))
+		goto out_printf;
+
+	ret = expand_corename(cn);
+	if (ret)
+		goto expand_fail;
+
+out_printf:
+	cur = cn->corename + cn->used;
+	va_start(arg, fmt);
+	vsnprintf(cur, need + 1, fmt, arg);
+	va_end(arg);
+	cn->used += need;
+	return 0;
+
+expand_fail:
+	return ret;
+}
+
 /* format_corename will inspect the pattern parameter, and output a
  * name into corename, which must have space for at least
  * CORENAME_MAX_SIZE bytes plus one byte for the zero terminator.
  */
-static int format_corename(char *corename, long signr)
+static int format_corename(struct core_name *cn, long signr)
 {
 	const struct cred *cred = current_cred();
 	const char *pat_ptr = core_pattern;
 	int ispipe = (*pat_ptr == '|');
-	char *out_ptr = corename;
-	char *const out_end = corename + CORENAME_MAX_SIZE;
-	int rc;
 	int pid_in_pattern = 0;
+	int err = 0;
+
+	cn->size = CORENAME_MAX_SIZE * atomic_read(&call_count);
+	cn->corename = kmalloc(cn->size, GFP_KERNEL);
+	cn->used = 0;
+
+	if (!cn->corename)
+		return -ENOMEM;
 
 	/* Repeat as long as we have more pattern to process and more output
 	   space */
 	while (*pat_ptr) {
 		if (*pat_ptr != '%') {
-			if (out_ptr == out_end)
+			if (*pat_ptr == 0)
 				goto out;
-			*out_ptr++ = *pat_ptr++;
+			err = cn_printf(cn, "%c", *pat_ptr++);
 		} else {
 			switch (*++pat_ptr) {
+			/* single % at the end, drop that */
 			case 0:
 				goto out;
 			/* Double percent, output one percent */
 			case '%':
-				if (out_ptr == out_end)
-					goto out;
-				*out_ptr++ = '%';
+				err = cn_printf(cn, "%c", '%');
 				break;
 			/* pid */
 			case 'p':
 				pid_in_pattern = 1;
-				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%d", task_tgid_vnr(current));
-				if (rc > out_end - out_ptr)
-					goto out;
-				out_ptr += rc;
+				err = cn_printf(cn, "%d",
+					      task_tgid_vnr(current));
 				break;
 			/* uid */
 			case 'u':
-				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%d", cred->uid);
-				if (rc > out_end - out_ptr)
-					goto out;
-				out_ptr += rc;
+				err = cn_printf(cn, "%d", cred->uid);
 				break;
 			/* gid */
 			case 'g':
-				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%d", cred->gid);
-				if (rc > out_end - out_ptr)
-					goto out;
-				out_ptr += rc;
+				err = cn_printf(cn, "%d", cred->gid);
 				break;
 			/* signal that caused the coredump */
 			case 's':
-				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%ld", signr);
-				if (rc > out_end - out_ptr)
-					goto out;
-				out_ptr += rc;
+				err = cn_printf(cn, "%ld", signr);
 				break;
 			/* UNIX time of coredump */
 			case 't': {
 				struct timeval tv;
 				do_gettimeofday(&tv);
-				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%lu", tv.tv_sec);
-				if (rc > out_end - out_ptr)
-					goto out;
-				out_ptr += rc;
+				err = cn_printf(cn, "%lu", tv.tv_sec);
 				break;
 			}
 			/* hostname */
 			case 'h':
 				down_read(&uts_sem);
-				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%s", utsname()->nodename);
+				err = cn_printf(cn, "%s",
+					      utsname()->nodename);
 				up_read(&uts_sem);
-				if (rc > out_end - out_ptr)
-					goto out;
-				out_ptr += rc;
 				break;
 			/* executable */
 			case 'e':
-				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%s", current->comm);
-				if (rc > out_end - out_ptr)
-					goto out;
-				out_ptr += rc;
+				err = cn_printf(cn, "%s", current->comm);
 				break;
 			/* core limit size */
 			case 'c':
-				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%lu", rlimit(RLIMIT_CORE));
-				if (rc > out_end - out_ptr)
-					goto out;
-				out_ptr += rc;
+				err = cn_printf(cn, "%lu",
+					      rlimit(RLIMIT_CORE));
 				break;
 			default:
 				break;
 			}
 			++pat_ptr;
 		}
+
+		if (err)
+			return err;
 	}
+
 	/* Backward compatibility with core_uses_pid:
 	 *
 	 * If core_pattern does not include a %p (as is the default)
 	 * and core_uses_pid is set, then .%pid will be appended to
 	 * the filename. Do not do this for piped commands. */
 	if (!ispipe && !pid_in_pattern && core_uses_pid) {
-		rc = snprintf(out_ptr, out_end - out_ptr,
-			      ".%d", task_tgid_vnr(current));
-		if (rc > out_end - out_ptr)
-			goto out;
-		out_ptr += rc;
+		err = cn_printf(cn, ".%d", task_tgid_vnr(current));
+		if (err)
+			return err;
 	}
 out:
-	*out_ptr = 0;
 	return ispipe;
 }
 
@@ -1856,7 +1883,7 @@ static int umh_pipe_setup(struct subprocess_info *info)
 void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 {
 	struct core_state core_state;
-	char corename[CORENAME_MAX_SIZE + 1];
+	struct core_name cn;
 	struct mm_struct *mm = current->mm;
 	struct linux_binfmt * binfmt;
 	const struct cred *old_cred;
@@ -1911,7 +1938,13 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	 */
 	clear_thread_flag(TIF_SIGPENDING);
 
-	ispipe = format_corename(corename, signr);
+	ispipe = format_corename(&cn, signr);
+
+	if (ispipe == -ENOMEM) {
+		printk(KERN_WARNING "format_corename failed\n");
+		printk(KERN_WARNING "Aborting core\n");
+		goto fail_corename;
+	}
 
  	if (ispipe) {
 		int dump_count;
@@ -1948,7 +1981,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 			goto fail_dropcount;
 		}
 
-		helper_argv = argv_split(GFP_KERNEL, corename+1, NULL);
+		helper_argv = argv_split(GFP_KERNEL, cn.corename+1, NULL);
 		if (!helper_argv) {
 			printk(KERN_WARNING "%s failed to allocate memory\n",
 			       __func__);
@@ -1961,7 +1994,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		argv_free(helper_argv);
 		if (retval) {
  			printk(KERN_INFO "Core dump to %s pipe failed\n",
-			       corename);
+			       cn.corename);
 			goto close_fail;
  		}
 	} else {
@@ -1970,7 +2003,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		if (cprm.limit < binfmt->min_coredump)
 			goto fail_unlock;
 
-		cprm.file = filp_open(corename,
+		cprm.file = filp_open(cn.corename,
 				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag,
 				 0600);
 		if (IS_ERR(cprm.file))
@@ -2012,6 +2045,8 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	if (ispipe)
 		atomic_dec(&core_dump_count);
 fail_unlock:
+	kfree(cn.corename);
+fail_corename:
 	coredump_finish(mm);
 	revert_creds(old_cred);
 fail_creds:

commit 9b1bf12d5d51bca178dea21b04a0805e29d60cf1
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Wed Oct 27 15:34:08 2010 -0700

    signals: move cred_guard_mutex from task_struct to signal_struct
    
    Oleg Nesterov pointed out we have to prevent multiple-threads-inside-exec
    itself and we can reuse ->cred_guard_mutex for it.  Yes, concurrent
    execve() has no worth.
    
    Let's move ->cred_guard_mutex from task_struct to signal_struct.  It
    naturally prevent multiple-threads-inside-exec.
    
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 3aa75b8888a1..9722909c4d88 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1083,14 +1083,14 @@ EXPORT_SYMBOL(setup_new_exec);
  */
 int prepare_bprm_creds(struct linux_binprm *bprm)
 {
-	if (mutex_lock_interruptible(&current->cred_guard_mutex))
+	if (mutex_lock_interruptible(&current->signal->cred_guard_mutex))
 		return -ERESTARTNOINTR;
 
 	bprm->cred = prepare_exec_creds();
 	if (likely(bprm->cred))
 		return 0;
 
-	mutex_unlock(&current->cred_guard_mutex);
+	mutex_unlock(&current->signal->cred_guard_mutex);
 	return -ENOMEM;
 }
 
@@ -1098,7 +1098,7 @@ void free_bprm(struct linux_binprm *bprm)
 {
 	free_arg_pages(bprm);
 	if (bprm->cred) {
-		mutex_unlock(&current->cred_guard_mutex);
+		mutex_unlock(&current->signal->cred_guard_mutex);
 		abort_creds(bprm->cred);
 	}
 	kfree(bprm);
@@ -1119,13 +1119,13 @@ void install_exec_creds(struct linux_binprm *bprm)
 	 * credentials; any time after this it may be unlocked.
 	 */
 	security_bprm_committed_creds(bprm);
-	mutex_unlock(&current->cred_guard_mutex);
+	mutex_unlock(&current->signal->cred_guard_mutex);
 }
 EXPORT_SYMBOL(install_exec_creds);
 
 /*
  * determine how safe it is to execute the proposed program
- * - the caller must hold current->cred_guard_mutex to protect against
+ * - the caller must hold ->cred_guard_mutex to protect against
  *   PTRACE_ATTACH
  */
 int check_unsafe_exec(struct linux_binprm *bprm)

commit 3d5992d2ac7dc09aed8ab537cba074589f0f0a52
Author: Ying Han <yinghan@google.com>
Date:   Tue Oct 26 14:21:23 2010 -0700

    oom: add per-mm oom disable count
    
    It's pointless to kill a task if another thread sharing its mm cannot be
    killed to allow future memory freeing.  A subsequent patch will prevent
    kills in such cases, but first it's necessary to have a way to flag a task
    that shares memory with an OOM_DISABLE task that doesn't incur an
    additional tasklist scan, which would make select_bad_process() an O(n^2)
    function.
    
    This patch adds an atomic counter to struct mm_struct that follows how
    many threads attached to it have an oom_score_adj of OOM_SCORE_ADJ_MIN.
    They cannot be killed by the kernel, so their memory cannot be freed in
    oom conditions.
    
    This only requires task_lock() on the task that we're operating on, it
    does not require mm->mmap_sem since task_lock() pins the mm and the
    operation is atomic.
    
    [rientjes@google.com: changelog and sys_unshare() code]
    [rientjes@google.com: protect oom_disable_count with task_lock in fork]
    [rientjes@google.com: use old_mm for oom_disable_count in exec]
    Signed-off-by: Ying Han <yinghan@google.com>
    Signed-off-by: David Rientjes <rientjes@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6d2b6f936858..3aa75b8888a1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -54,6 +54,7 @@
 #include <linux/fsnotify.h>
 #include <linux/fs_struct.h>
 #include <linux/pipe_fs_i.h>
+#include <linux/oom.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -759,6 +760,10 @@ static int exec_mmap(struct mm_struct *mm)
 	tsk->mm = mm;
 	tsk->active_mm = mm;
 	activate_mm(active_mm, mm);
+	if (old_mm && tsk->signal->oom_score_adj == OOM_SCORE_ADJ_MIN) {
+		atomic_dec(&old_mm->oom_disable_count);
+		atomic_inc(&tsk->mm->oom_disable_count);
+	}
 	task_unlock(tsk);
 	arch_pick_mmap_layout(mm);
 	if (old_mm) {

commit 8fd01d6cfbf75465d84a4e533ed70c5f57b3ff51
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 14 19:15:28 2010 -0700

    Export dump_{write,seek} to binary loader modules
    
    If you build aout support as a module, you'll want these exported.
    
    Reported-by: Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 03278c984ba0..6d2b6f936858 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2024,6 +2024,7 @@ int dump_write(struct file *file, const void *addr, int nr)
 {
 	return access_ok(VERIFY_READ, addr, nr) && file->f_op->write(file, addr, nr, &file->f_pos) == nr;
 }
+EXPORT_SYMBOL(dump_write);
 
 int dump_seek(struct file *file, loff_t off)
 {
@@ -2052,3 +2053,4 @@ int dump_seek(struct file *file, loff_t off)
 	}
 	return ret;
 }
+EXPORT_SYMBOL(dump_seek);

commit 3aa0ce825ade0cf5506e32ccf51d01fc8d22a9cf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 14 14:32:06 2010 -0700

    Un-inline the core-dump helper functions
    
    Tony Luck reports that the addition of the access_ok() check in commit
    0eead9ab41da ("Don't dump task struct in a.out core-dumps") broke the
    ia64 compile due to missing the necessary header file includes.
    
    Rather than add yet another include (<asm/unistd.h>) to make everything
    happy, just uninline the silly core dump helper functions and move the
    bodies to fs/exec.c where they make a lot more sense.
    
    dump_seek() in particular was too big to be an inline function anyway,
    and none of them are in any way performance-critical.  And we really
    don't need to mess up our include file headers more than they already
    are.
    
    Reported-and-tested-by: Tony Luck <tony.luck@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 828dd2461d6b..03278c984ba0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -2014,3 +2014,41 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 fail:
 	return;
 }
+
+/*
+ * Core dumping helper functions.  These are the only things you should
+ * do on a core-file: use only these functions to write out all the
+ * necessary info.
+ */
+int dump_write(struct file *file, const void *addr, int nr)
+{
+	return access_ok(VERIFY_READ, addr, nr) && file->f_op->write(file, addr, nr, &file->f_pos) == nr;
+}
+
+int dump_seek(struct file *file, loff_t off)
+{
+	int ret = 1;
+
+	if (file->f_op->llseek && file->f_op->llseek != no_llseek) {
+		if (file->f_op->llseek(file, off, SEEK_CUR) < 0)
+			return 0;
+	} else {
+		char *buf = (char *)get_zeroed_page(GFP_KERNEL);
+
+		if (!buf)
+			return 0;
+		while (off > 0) {
+			unsigned long n = off;
+
+			if (n > PAGE_SIZE)
+				n = PAGE_SIZE;
+			if (!dump_write(file, buf, n)) {
+				ret = 0;
+				break;
+			}
+			off -= n;
+		}
+		free_page((unsigned long)buf);
+	}
+	return ret;
+}

commit 9aea5a65aa7a1af9a4236dfaeb0088f1624f9919
Author: Roland McGrath <roland@redhat.com>
Date:   Tue Sep 7 19:37:06 2010 -0700

    execve: make responsive to SIGKILL with large arguments
    
    An execve with a very large total of argument/environment strings
    can take a really long time in the execve system call.  It runs
    uninterruptibly to count and copy all the strings.  This change
    makes it abort the exec quickly if sent a SIGKILL.
    
    Note that this is the conservative change, to interrupt only for
    SIGKILL, by using fatal_signal_pending().  It would be perfectly
    correct semantics to let any signal interrupt the string-copying in
    execve, i.e. use signal_pending() instead of fatal_signal_pending().
    We'll save that change for later, since it could have user-visible
    consequences, such as having a timer set too quickly make it so that
    an execve can never complete, though it always happened to work before.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6f2d777431a8..828dd2461d6b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -376,6 +376,9 @@ static int count(const char __user * const __user * argv, int max)
 			argv++;
 			if (i++ >= max)
 				return -E2BIG;
+
+			if (fatal_signal_pending(current))
+				return -ERESTARTNOHAND;
 			cond_resched();
 		}
 	}
@@ -419,6 +422,10 @@ static int copy_strings(int argc, const char __user *const __user *argv,
 		while (len > 0) {
 			int offset, bytes_to_copy;
 
+			if (fatal_signal_pending(current)) {
+				ret = -ERESTARTNOHAND;
+				goto out;
+			}
 			cond_resched();
 
 			offset = pos % PAGE_SIZE;

commit 7993bc1f4663c0db67bb8f0d98e6678145b387cd
Author: Roland McGrath <roland@redhat.com>
Date:   Tue Sep 7 19:36:28 2010 -0700

    execve: improve interactivity with large arguments
    
    This adds a preemption point during the copying of the argument and
    environment strings for execve, in copy_strings().  There is already
    a preemption point in the count() loop, so this doesn't add any new
    points in the abstract sense.
    
    When the total argument+environment strings are very large, the time
    spent copying them can be much more than a normal user time slice.
    So this change improves the interactivity of the rest of the system
    when one process is doing an execve with very large arguments.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 1b63237fc6dc..6f2d777431a8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -419,6 +419,8 @@ static int copy_strings(int argc, const char __user *const __user *argv,
 		while (len > 0) {
 			int offset, bytes_to_copy;
 
+			cond_resched();
+
 			offset = pos % PAGE_SIZE;
 			if (offset == 0)
 				offset = PAGE_SIZE;

commit 1b528181b2ffa14721fb28ad1bd539fe1732c583
Author: Roland McGrath <roland@redhat.com>
Date:   Tue Sep 7 19:35:49 2010 -0700

    setup_arg_pages: diagnose excessive argument size
    
    The CONFIG_STACK_GROWSDOWN variant of setup_arg_pages() does not
    check the size of the argument/environment area on the stack.
    When it is unworkably large, shift_arg_pages() hits its BUG_ON.
    This is exploitable with a very large RLIMIT_STACK limit, to
    create a crash pretty easily.
    
    Check that the initial stack is not too large to make it possible
    to map in any executable.  We're not checking that the actual
    executable (or intepreter, for binfmt_elf) will fit.  So those
    mappings might clobber part of the initial stack mapping.  But
    that is just userland lossage that userland made happen, not a
    kernel problem.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2d9455282744..1b63237fc6dc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -594,6 +594,11 @@ int setup_arg_pages(struct linux_binprm *bprm,
 #else
 	stack_top = arch_align_stack(stack_top);
 	stack_top = PAGE_ALIGN(stack_top);
+
+	if (unlikely(stack_top < mmap_min_addr) ||
+	    unlikely(vma->vm_end - vma->vm_start >= stack_top - mmap_min_addr))
+		return -ENOMEM;
+
 	stack_shift = vma->vm_end - stack_top;
 
 	bprm->p -= stack_shift;

commit 145c3ae46b37993b0debb0b3da6256daea4a6ec5
Merge: 81ca03a0e2ea 99b7db7b8ffd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 18 09:35:08 2010 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6:
      fs: brlock vfsmount_lock
      fs: scale files_lock
      lglock: introduce special lglock and brlock spin locks
      tty: fix fu_list abuse
      fs: cleanup files_lock locking
      fs: remove extra lookup in __lookup_hash
      fs: fs_struct rwlock to spinlock
      apparmor: use task path helpers
      fs: dentry allocation consolidation
      fs: fix do_lookup false negative
      mbcache: Limit the maximum number of cache entries
      hostfs ->follow_link() braino
      hostfs: dumb (and usually harmless) tpyo - strncpy instead of strlcpy
      remove SWRITE* I/O types
      kill BH_Ordered flag
      vfs: update ctime when changing the file's permission by setfacl
      cramfs: only unlock new inodes
      fix reiserfs_evict_inode end_writeback second call

commit 2a4419b5b2a77f3f4537c14f7ad7df95770655dd
Author: Nick Piggin <npiggin@kernel.dk>
Date:   Wed Aug 18 04:37:33 2010 +1000

    fs: fs_struct rwlock to spinlock
    
    fs: fs_struct rwlock to spinlock
    
    struct fs_struct.lock is an rwlock with the read-side used to protect root and
    pwd members while taking references to them. Taking a reference to a path
    typically requires just 2 atomic ops, so the critical section is very small.
    Parallel read-side operations would have cacheline contention on the lock, the
    dentry, and the vfsmount cachelines, so the rwlock is unlikely to ever give a
    real parallelism increase.
    
    Replace it with a spinlock to avoid one or two atomic operations in typical
    path lookup fastpath.
    
    Signed-off-by: Nick Piggin <npiggin@kernel.dk>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 7761837e4500..5adab2c93eca 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1117,7 +1117,7 @@ int check_unsafe_exec(struct linux_binprm *bprm)
 	bprm->unsafe = tracehook_unsafe_exec(p);
 
 	n_fs = 1;
-	write_lock(&p->fs->lock);
+	spin_lock(&p->fs->lock);
 	rcu_read_lock();
 	for (t = next_thread(p); t != p; t = next_thread(t)) {
 		if (t->fs == p->fs)
@@ -1134,7 +1134,7 @@ int check_unsafe_exec(struct linux_binprm *bprm)
 			res = 1;
 		}
 	}
-	write_unlock(&p->fs->lock);
+	spin_unlock(&p->fs->lock);
 
 	return res;
 }

commit d7627467b7a8dd6944885290a03a07ceb28c10eb
Author: David Howells <dhowells@redhat.com>
Date:   Tue Aug 17 23:52:56 2010 +0100

    Make do_execve() take a const filename pointer
    
    Make do_execve() take a const filename pointer so that kernel_execve() compiles
    correctly on ARM:
    
    arch/arm/kernel/sys_arm.c:88: warning: passing argument 1 of 'do_execve' discards qualifiers from pointer target type
    
    This also requires the argv and envp arguments to be consted twice, once for
    the pointer array and once for the strings the array points to.  This is
    because do_execve() passes a pointer to the filename (now const) to
    copy_strings_kernel().  A simpler alternative would be to cast the filename
    pointer in do_execve() when it's passed to copy_strings_kernel().
    
    do_execve() may not change any of the strings it is passed as part of the argv
    or envp lists as they are some of them in .rodata, so marking these strings as
    const should be fine.
    
    Further kernel_execve() and sys_execve() need to be changed to match.
    
    This has been test built on x86_64, frv, arm and mips.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Ralf Baechle <ralf@linux-mips.org>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7761837e4500..05c7d6b84df7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -361,13 +361,13 @@ int bprm_mm_init(struct linux_binprm *bprm)
 /*
  * count() counts the number of strings in array ARGV.
  */
-static int count(char __user * __user * argv, int max)
+static int count(const char __user * const __user * argv, int max)
 {
 	int i = 0;
 
 	if (argv != NULL) {
 		for (;;) {
-			char __user * p;
+			const char __user * p;
 
 			if (get_user(p, argv))
 				return -EFAULT;
@@ -387,7 +387,7 @@ static int count(char __user * __user * argv, int max)
  * processes's memory to the new process's stack.  The call to get_user_pages()
  * ensures the destination page is created and not swapped out.
  */
-static int copy_strings(int argc, char __user * __user * argv,
+static int copy_strings(int argc, const char __user *const __user *argv,
 			struct linux_binprm *bprm)
 {
 	struct page *kmapped_page = NULL;
@@ -396,7 +396,7 @@ static int copy_strings(int argc, char __user * __user * argv,
 	int ret;
 
 	while (argc-- > 0) {
-		char __user *str;
+		const char __user *str;
 		int len;
 		unsigned long pos;
 
@@ -470,12 +470,13 @@ static int copy_strings(int argc, char __user * __user * argv,
 /*
  * Like copy_strings, but get argv and its values from kernel memory.
  */
-int copy_strings_kernel(int argc,char ** argv, struct linux_binprm *bprm)
+int copy_strings_kernel(int argc, const char *const *argv,
+			struct linux_binprm *bprm)
 {
 	int r;
 	mm_segment_t oldfs = get_fs();
 	set_fs(KERNEL_DS);
-	r = copy_strings(argc, (char __user * __user *)argv, bprm);
+	r = copy_strings(argc, (const char __user *const  __user *)argv, bprm);
 	set_fs(oldfs);
 	return r;
 }
@@ -997,7 +998,7 @@ EXPORT_SYMBOL(flush_old_exec);
 void setup_new_exec(struct linux_binprm * bprm)
 {
 	int i, ch;
-	char * name;
+	const char *name;
 	char tcomm[sizeof(current->comm)];
 
 	arch_pick_mmap_layout(current->mm);
@@ -1316,9 +1317,9 @@ EXPORT_SYMBOL(search_binary_handler);
 /*
  * sys_execve() executes a new program.
  */
-int do_execve(char * filename,
-	char __user *__user *argv,
-	char __user *__user *envp,
+int do_execve(const char * filename,
+	const char __user *const __user *argv,
+	const char __user *const __user *envp,
 	struct pt_regs * regs)
 {
 	struct linux_binprm *bprm;

commit 8c8946f509a494769a8c602b5ed189df01917d39
Merge: 5f248c9c251c 1968f5eed54c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 10 11:39:13 2010 -0700

    Merge branch 'for-linus' of git://git.infradead.org/users/eparis/notify
    
    * 'for-linus' of git://git.infradead.org/users/eparis/notify: (132 commits)
      fanotify: use both marks when possible
      fsnotify: pass both the vfsmount mark and inode mark
      fsnotify: walk the inode and vfsmount lists simultaneously
      fsnotify: rework ignored mark flushing
      fsnotify: remove global fsnotify groups lists
      fsnotify: remove group->mask
      fsnotify: remove the global masks
      fsnotify: cleanup should_send_event
      fanotify: use the mark in handler functions
      audit: use the mark in handler functions
      dnotify: use the mark in handler functions
      inotify: use the mark in handler functions
      fsnotify: send fsnotify_mark to groups in event handling functions
      fsnotify: Exchange list heads instead of moving elements
      fsnotify: srcu to protect read side of inode and vfsmount locks
      fsnotify: use an explicit flag to indicate fsnotify_destroy_mark has been called
      fsnotify: use _rcu functions for mark list traversal
      fsnotify: place marks on object in order of group memory address
      vfs/fsnotify: fsnotify_close can delay the final work in fput
      fsnotify: store struct file not struct path
      ...
    
    Fix up trivial delete/modify conflict in fs/notify/inotify/inotify.c.

commit 78417334b5cb6e1f915b8fdcc4fce3f1a1b4420c
Merge: cd816a0d8437 5f202bd5ca64
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Aug 7 17:06:54 2010 -0700

    Merge branch 'bkl/core' of git://git.kernel.org/pub/scm/linux/kernel/git/frederic/random-tracing
    
    * 'bkl/core' of git://git.kernel.org/pub/scm/linux/kernel/git/frederic/random-tracing:
      do_coredump: Do not take BKL
      init: Remove the BKL from startup code

commit 2a12a9d7814631e918dec93abad856e692d5286d
Author: Eric Paris <eparis@redhat.com>
Date:   Thu Dec 17 21:24:21 2009 -0500

    fsnotify: pass a file instead of an inode to open, read, and write
    
    fanotify, the upcoming notification system actually needs a struct path so it can
    do opens in the context of listeners, and it needs a file so it can get f_flags
    from the original process.  Close was the only operation that already was passing
    a struct file to the notification hook.  This patch passes a file for access,
    modify, and open as well as they are easily available to these hooks.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index e19de6a80339..f2de04a01a2a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -129,7 +129,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 	if (file->f_path.mnt->mnt_flags & MNT_NOEXEC)
 		goto exit;
 
-	fsnotify_open(file->f_path.dentry);
+	fsnotify_open(file);
 
 	error = -ENOEXEC;
 	if(file->f_op) {
@@ -683,7 +683,7 @@ struct file *open_exec(const char *name)
 	if (file->f_path.mnt->mnt_flags & MNT_NOEXEC)
 		goto exit;
 
-	fsnotify_open(file->f_path.dentry);
+	fsnotify_open(file);
 
 	err = deny_write_access(file);
 	if (err)

commit 5f202bd5ca64132cdd7f186656bc0221f257733d
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Sun Jul 4 00:02:25 2010 +0200

    do_coredump: Do not take BKL
    
    core_pattern is not actually protected and hasn't been
    ever since we introduced procfs support for sysctl -- a
    _long_ time. Don't take it here either.
    
    Also nothing inside do_coredump appears to require bkl
    protection.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    [ remove smp_lock.h headers ]
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/fs/exec.c b/fs/exec.c
index e19de6a80339..2619c767c089 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -28,7 +28,6 @@
 #include <linux/mm.h>
 #include <linux/stat.h>
 #include <linux/fcntl.h>
-#include <linux/smp_lock.h>
 #include <linux/swap.h>
 #include <linux/string.h>
 #include <linux/init.h>
@@ -1891,13 +1890,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	 */
 	clear_thread_flag(TIF_SIGPENDING);
 
-	/*
-	 * lock_kernel() because format_corename() is controlled by sysctl, which
-	 * uses lock_kernel()
-	 */
- 	lock_kernel();
 	ispipe = format_corename(corename, signr);
-	unlock_kernel();
 
  	if (ispipe) {
 		int dump_count;

commit 3af9e859281bda7eb7c20b51879cf43aa788ac2e
Author: Eric B Munson <ebmunson@us.ibm.com>
Date:   Tue May 18 15:30:49 2010 +0100

    perf: Add non-exec mmap() tracking
    
    Add the capacility to track data mmap()s. This can be used together
    with PERF_SAMPLE_ADDR for data profiling.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    [Updated code for stable perf ABI]
    Signed-off-by: Eric B Munson <ebmunson@us.ibm.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    LKML-Reference: <1274193049-25997-1-git-send-email-ebmunson@us.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/exec.c b/fs/exec.c
index e19de6a80339..97d91a03fb13 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -653,6 +653,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	else
 		stack_base = vma->vm_start - stack_expand;
 #endif
+	current->mm->start_stack = bprm->p;
 	ret = expand_stack(vma, stack_base);
 	if (ret)
 		ret = -EFAULT;

commit d344193a05da89c97e965da2c5cbf687d7385eae
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed May 26 14:43:11 2010 -0700

    exit: avoid sig->count in de_thread/__exit_signal synchronization
    
    de_thread() and __exit_signal() use signal_struct->count/notify_count for
    synchronization.  We can simplify the code and use ->notify_count only.
    Instead of comparing these two counters, we can change de_thread() to set
    ->notify_count = nr_of_sub_threads, then change __exit_signal() to
    dec-and-test this counter and notify group_exit_task.
    
    Note that __exit_signal() checks "notify_count > 0" just for symmetry with
    exit_notify(), we could just check it is != 0.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: Veaceslav Falico <vfalico@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0c72d23ed0e2..e19de6a80339 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -768,7 +768,6 @@ static int de_thread(struct task_struct *tsk)
 	struct signal_struct *sig = tsk->signal;
 	struct sighand_struct *oldsighand = tsk->sighand;
 	spinlock_t *lock = &oldsighand->siglock;
-	int count;
 
 	if (thread_group_empty(tsk))
 		goto no_thread_group;
@@ -785,13 +784,13 @@ static int de_thread(struct task_struct *tsk)
 		spin_unlock_irq(lock);
 		return -EAGAIN;
 	}
+
 	sig->group_exit_task = tsk;
-	zap_other_threads(tsk);
+	sig->notify_count = zap_other_threads(tsk);
+	if (!thread_group_leader(tsk))
+		sig->notify_count--;
 
-	/* Account for the thread group leader hanging around: */
-	count = thread_group_leader(tsk) ? 1 : 2;
-	sig->notify_count = count;
-	while (atomic_read(&sig->count) > count) {
+	while (sig->notify_count) {
 		__set_current_state(TASK_UNINTERRUPTIBLE);
 		spin_unlock_irq(lock);
 		schedule();

commit 269b005a28e124a341df4adef2c3661cf7371fcc
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed May 26 14:43:08 2010 -0700

    coredump: shift down_write(mmap_sem) into coredump_wait()
    
    - move the cprm.mm_flags checks up, before we take mmap_sem
    
    - move down_write(mmap_sem) and ->core_state check from do_coredump()
      to coredump_wait()
    
    This simplifies the code and makes the locking symmetrical.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6501823b7a1b..0c72d23ed0e2 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1662,12 +1662,15 @@ static int coredump_wait(int exit_code, struct core_state *core_state)
 	struct task_struct *tsk = current;
 	struct mm_struct *mm = tsk->mm;
 	struct completion *vfork_done;
-	int core_waiters;
+	int core_waiters = -EBUSY;
 
 	init_completion(&core_state->startup);
 	core_state->dumper.task = tsk;
 	core_state->dumper.next = NULL;
-	core_waiters = zap_threads(tsk, mm, core_state, exit_code);
+
+	down_write(&mm->mmap_sem);
+	if (!mm->core_state)
+		core_waiters = zap_threads(tsk, mm, core_state, exit_code);
 	up_write(&mm->mmap_sem);
 
 	if (unlikely(core_waiters < 0))
@@ -1860,20 +1863,12 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	binfmt = mm->binfmt;
 	if (!binfmt || !binfmt->core_dump)
 		goto fail;
+	if (!__get_dumpable(cprm.mm_flags))
+		goto fail;
 
 	cred = prepare_creds();
 	if (!cred)
 		goto fail;
-
-	down_write(&mm->mmap_sem);
-	/*
-	 * If another thread got here first, or we are not dumpable, bail out.
-	 */
-	if (mm->core_state || !__get_dumpable(cprm.mm_flags)) {
-		up_write(&mm->mmap_sem);
-		goto fail_creds;
-	}
-
 	/*
 	 *	We cannot trust fsuid as being the "true" uid of the
 	 *	process nor do we know its entire history. We only know it

commit 5e43aef530ba39206f7923295388f7ec3c5a7d93
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed May 26 14:43:07 2010 -0700

    coredump: factor out put_cred() calls
    
    Given that do_coredump() calls put_cred() on exit path, it is a bit ugly
    to do put_cred() + "goto fail" twice, just add the new "fail_creds" label.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 1221c4c43547..6501823b7a1b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1862,10 +1862,8 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		goto fail;
 
 	cred = prepare_creds();
-	if (!cred) {
-		retval = -ENOMEM;
+	if (!cred)
 		goto fail;
-	}
 
 	down_write(&mm->mmap_sem);
 	/*
@@ -1873,8 +1871,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	 */
 	if (mm->core_state || !__get_dumpable(cprm.mm_flags)) {
 		up_write(&mm->mmap_sem);
-		put_cred(cred);
-		goto fail;
+		goto fail_creds;
 	}
 
 	/*
@@ -1889,10 +1886,8 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	}
 
 	retval = coredump_wait(exit_code, &core_state);
-	if (retval < 0) {
-		put_cred(cred);
-		goto fail;
-	}
+	if (retval < 0)
+		goto fail_creds;
 
 	old_cred = override_creds(cred);
 
@@ -2009,9 +2004,10 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	if (ispipe)
 		atomic_dec(&core_dump_count);
 fail_unlock:
+	coredump_finish(mm);
 	revert_creds(old_cred);
+fail_creds:
 	put_cred(cred);
-	coredump_finish(mm);
 fail:
 	return;
 }

commit d5bf4c4f5f9dcc90b7e25dbb2f7c4436cf6e7ed0
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed May 26 14:43:06 2010 -0700

    coredump: cleanup "ispipe" code
    
    - kill "int dump_count", argv_split(argcp) accepts argcp == NULL.
    
    - move "int dump_count" under " if (ispipe)" branch, fail_dropcount
      can check ispipe.
    
    - move "char **helper_argv" as well, change the code to do argv_free()
      right after call_usermodehelper_fns().
    
    - If call_usermodehelper_fns() fails goto close_fail label instead
      of closing the file by hand.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 1d55d7536641..1221c4c43547 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1841,10 +1841,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	struct cred *cred;
 	int retval = 0;
 	int flag = 0;
-	int ispipe = 0;
-	char **helper_argv = NULL;
-	int helper_argc = 0;
-	int dump_count = 0;
+	int ispipe;
 	static atomic_t core_dump_count = ATOMIC_INIT(0);
 	struct coredump_params cprm = {
 		.signr = signr,
@@ -1914,6 +1911,9 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	unlock_kernel();
 
  	if (ispipe) {
+		int dump_count;
+		char **helper_argv;
+
 		if (cprm.limit == 1) {
 			/*
 			 * Normally core limits are irrelevant to pipes, since
@@ -1935,6 +1935,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 			printk(KERN_WARNING "Aborting core\n");
 			goto fail_unlock;
 		}
+		cprm.limit = RLIM_INFINITY;
 
 		dump_count = atomic_inc_return(&core_dump_count);
 		if (core_pipe_limit && (core_pipe_limit < dump_count)) {
@@ -1944,26 +1945,21 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 			goto fail_dropcount;
 		}
 
-		helper_argv = argv_split(GFP_KERNEL, corename+1, &helper_argc);
+		helper_argv = argv_split(GFP_KERNEL, corename+1, NULL);
 		if (!helper_argv) {
 			printk(KERN_WARNING "%s failed to allocate memory\n",
 			       __func__);
 			goto fail_dropcount;
 		}
 
-		cprm.limit = RLIM_INFINITY;
-
-		/* SIGPIPE can happen, but it's just never processed */
-		cprm.file = NULL;
-		if (call_usermodehelper_fns(helper_argv[0], helper_argv, NULL,
-					    UMH_WAIT_EXEC, umh_pipe_setup,
-					    NULL, &cprm)) {
-			if (cprm.file)
-				filp_close(cprm.file, NULL);
-
+		retval = call_usermodehelper_fns(helper_argv[0], helper_argv,
+					NULL, UMH_WAIT_EXEC, umh_pipe_setup,
+					NULL, &cprm);
+		argv_free(helper_argv);
+		if (retval) {
  			printk(KERN_INFO "Core dump to %s pipe failed\n",
 			       corename);
-			goto fail_dropcount;
+			goto close_fail;
  		}
 	} else {
 		struct inode *inode;
@@ -2003,17 +1999,16 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	retval = binfmt->core_dump(&cprm);
 	if (retval)
 		current->signal->group_exit_code |= 0x80;
-close_fail:
+
 	if (ispipe && core_pipe_limit)
 		wait_for_dump_helpers(cprm.file);
-	filp_close(cprm.file, NULL);
+close_fail:
+	if (cprm.file)
+		filp_close(cprm.file, NULL);
 fail_dropcount:
-	if (dump_count)
+	if (ispipe)
 		atomic_dec(&core_dump_count);
 fail_unlock:
-	if (helper_argv)
-		argv_free(helper_argv);
-
 	revert_creds(old_cred);
 	put_cred(cred);
 	coredump_finish(mm);

commit c713541125002b8bc9e681af3b09118e771e2d8a
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed May 26 14:43:05 2010 -0700

    coredump: factor out the not-ispipe file checks
    
    do_coredump() does a lot of file checks after it opens the file or calls
    usermode helper.  But all of these checks are only needed in !ispipe case.
    
    Move this code into the "else" branch and kill the ugly repetitive ispipe
    checks.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 63f459cf20df..1d55d7536641 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1837,7 +1837,6 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	char corename[CORENAME_MAX_SIZE + 1];
 	struct mm_struct *mm = current->mm;
 	struct linux_binfmt * binfmt;
-	struct inode * inode;
 	const struct cred *old_cred;
 	struct cred *cred;
 	int retval = 0;
@@ -1914,9 +1913,6 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	ispipe = format_corename(corename, signr);
 	unlock_kernel();
 
-	if ((!ispipe) && (cprm.limit < binfmt->min_coredump))
-		goto fail_unlock;
-
  	if (ispipe) {
 		if (cprm.limit == 1) {
 			/*
@@ -1969,39 +1965,42 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 			       corename);
 			goto fail_dropcount;
  		}
- 	} else
+	} else {
+		struct inode *inode;
+
+		if (cprm.limit < binfmt->min_coredump)
+			goto fail_unlock;
+
 		cprm.file = filp_open(corename,
 				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag,
 				 0600);
-	if (IS_ERR(cprm.file))
-		goto fail_dropcount;
-	inode = cprm.file->f_path.dentry->d_inode;
-	if (inode->i_nlink > 1)
-		goto close_fail;	/* multiple links - don't dump */
-	if (!ispipe && d_unhashed(cprm.file->f_path.dentry))
-		goto close_fail;
-
-	/* AK: actually i see no reason to not allow this for named pipes etc.,
-	   but keep the previous behaviour for now. */
-	if (!ispipe && !S_ISREG(inode->i_mode))
-		goto close_fail;
-	/*
-	 * Dont allow local users get cute and trick others to coredump
-	 * into their pre-created files:
-	 * Note, this is not relevant for pipes
-	 */
-	if (!ispipe && (inode->i_uid != current_fsuid()))
-		goto close_fail;
-	if (!cprm.file->f_op)
-		goto close_fail;
-	if (!cprm.file->f_op->write)
-		goto close_fail;
-	if (!ispipe &&
-	    do_truncate(cprm.file->f_path.dentry, 0, 0, cprm.file) != 0)
-		goto close_fail;
+		if (IS_ERR(cprm.file))
+			goto fail_unlock;
 
-	retval = binfmt->core_dump(&cprm);
+		inode = cprm.file->f_path.dentry->d_inode;
+		if (inode->i_nlink > 1)
+			goto close_fail;
+		if (d_unhashed(cprm.file->f_path.dentry))
+			goto close_fail;
+		/*
+		 * AK: actually i see no reason to not allow this for named
+		 * pipes etc, but keep the previous behaviour for now.
+		 */
+		if (!S_ISREG(inode->i_mode))
+			goto close_fail;
+		/*
+		 * Dont allow local users get cute and trick others to coredump
+		 * into their pre-created files.
+		 */
+		if (inode->i_uid != current_fsuid())
+			goto close_fail;
+		if (!cprm.file->f_op || !cprm.file->f_op->write)
+			goto close_fail;
+		if (do_truncate(cprm.file->f_path.dentry, 0, 0, cprm.file))
+			goto close_fail;
+	}
 
+	retval = binfmt->core_dump(&cprm);
 	if (retval)
 		current->signal->group_exit_code |= 0x80;
 close_fail:

commit 898b374af6f71041bd3bceebe257e564f3f1d458
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Wed May 26 14:42:59 2010 -0700

    exec: replace call_usermodehelper_pipe with use of umh init function and resolve limit
    
    The first patch in this series introduced an init function to the
    call_usermodehelper api so that processes could be customized by caller.
    This patch takes advantage of that fact, by customizing the helper in
    do_coredump to create the pipe and set its core limit to one (for our
    recusrsion check).  This lets us clean up the previous uglyness in the
    usermodehelper internals and factor call_usermodehelper out entirely.
    While I'm at it, we can also modify the helper setup to look for a core
    limit value of 1 rather than zero for our recursion check
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9badbc0bfb1d..63f459cf20df 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1787,6 +1787,50 @@ static void wait_for_dump_helpers(struct file *file)
 }
 
 
+/*
+ * uhm_pipe_setup
+ * helper function to customize the process used
+ * to collect the core in userspace.  Specifically
+ * it sets up a pipe and installs it as fd 0 (stdin)
+ * for the process.  Returns 0 on success, or
+ * PTR_ERR on failure.
+ * Note that it also sets the core limit to 1.  This
+ * is a special value that we use to trap recursive
+ * core dumps
+ */
+static int umh_pipe_setup(struct subprocess_info *info)
+{
+	struct file *rp, *wp;
+	struct fdtable *fdt;
+	struct coredump_params *cp = (struct coredump_params *)info->data;
+	struct files_struct *cf = current->files;
+
+	wp = create_write_pipe(0);
+	if (IS_ERR(wp))
+		return PTR_ERR(wp);
+
+	rp = create_read_pipe(wp, 0);
+	if (IS_ERR(rp)) {
+		free_write_pipe(wp);
+		return PTR_ERR(rp);
+	}
+
+	cp->file = wp;
+
+	sys_close(0);
+	fd_install(0, rp);
+	spin_lock(&cf->file_lock);
+	fdt = files_fdtable(cf);
+	FD_SET(0, fdt->open_fds);
+	FD_CLR(0, fdt->close_on_exec);
+	spin_unlock(&cf->file_lock);
+
+	/* and disallow core files too */
+	current->signal->rlim[RLIMIT_CORE] = (struct rlimit){1, 1};
+
+	return 0;
+}
+
 void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 {
 	struct core_state core_state;
@@ -1874,15 +1918,15 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		goto fail_unlock;
 
  	if (ispipe) {
-		if (cprm.limit == 0) {
+		if (cprm.limit == 1) {
 			/*
 			 * Normally core limits are irrelevant to pipes, since
 			 * we're not writing to the file system, but we use
-			 * cprm.limit of 0 here as a speacial value. Any
-			 * non-zero limit gets set to RLIM_INFINITY below, but
+			 * cprm.limit of 1 here as a speacial value. Any
+			 * non-1 limit gets set to RLIM_INFINITY below, but
 			 * a limit of 0 skips the dump.  This is a consistent
 			 * way to catch recursive crashes.  We can still crash
-			 * if the core_pattern binary sets RLIM_CORE =  !0
+			 * if the core_pattern binary sets RLIM_CORE =  !1
 			 * but it runs as root, and can do lots of stupid things
 			 * Note that we use task_tgid_vnr here to grab the pid
 			 * of the process group leader.  That way we get the
@@ -1890,7 +1934,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 			 * core_pattern process dies.
 			 */
 			printk(KERN_WARNING
-				"Process %d(%s) has RLIMIT_CORE set to 0\n",
+				"Process %d(%s) has RLIMIT_CORE set to 1\n",
 				task_tgid_vnr(current), current->comm);
 			printk(KERN_WARNING "Aborting core\n");
 			goto fail_unlock;
@@ -1914,8 +1958,13 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		cprm.limit = RLIM_INFINITY;
 
 		/* SIGPIPE can happen, but it's just never processed */
-		if (call_usermodehelper_pipe(helper_argv[0], helper_argv, NULL,
-				&cprm.file)) {
+		cprm.file = NULL;
+		if (call_usermodehelper_fns(helper_argv[0], helper_argv, NULL,
+					    UMH_WAIT_EXEC, umh_pipe_setup,
+					    NULL, &cprm)) {
+			if (cprm.file)
+				filp_close(cprm.file, NULL);
+
  			printk(KERN_INFO "Core dump to %s pipe failed\n",
 			       corename);
 			goto fail_dropcount;

commit a8bef8ff6ea15fa4c67433cab0f5f3484574ef7c
Author: Mel Gorman <mel@csn.ul.ie>
Date:   Mon May 24 14:32:24 2010 -0700

    mm: migration: avoid race between shift_arg_pages() and rmap_walk() during migration by not migrating temporary stacks
    
    Page migration requires rmap to be able to find all ptes mapping a page
    at all times, otherwise the migration entry can be instantiated, but it
    is possible to leave one behind if the second rmap_walk fails to find
    the page.  If this page is later faulted, migration_entry_to_page() will
    call BUG because the page is locked indicating the page was migrated by
    the migration PTE not cleaned up. For example
    
      kernel BUG at include/linux/swapops.h:105!
      invalid opcode: 0000 [#1] PREEMPT SMP
      ...
      Call Trace:
       [<ffffffff810e951a>] handle_mm_fault+0x3f8/0x76a
       [<ffffffff8130c7a2>] do_page_fault+0x44a/0x46e
       [<ffffffff813099b5>] page_fault+0x25/0x30
       [<ffffffff8114de33>] load_elf_binary+0x152a/0x192b
       [<ffffffff8111329b>] search_binary_handler+0x173/0x313
       [<ffffffff81114896>] do_execve+0x219/0x30a
       [<ffffffff8100a5c6>] sys_execve+0x43/0x5e
       [<ffffffff8100320a>] stub_execve+0x6a/0xc0
      RIP  [<ffffffff811094ff>] migration_entry_wait+0xc1/0x129
    
    There is a race between shift_arg_pages and migration that triggers this
    bug.  A temporary stack is setup during exec and later moved.  If
    migration moves a page in the temporary stack and the VMA is then removed
    before migration completes, the migration PTE may not be found leading to
    a BUG when the stack is faulted.
    
    This patch causes pages within the temporary stack during exec to be
    skipped by migration.  It does this by marking the VMA covering the
    temporary stack with an otherwise impossible combination of VMA flags.
    These flags are cleared when the temporary stack is moved to its final
    location.
    
    [kamezawa.hiroyu@jp.fujitsu.com: idea for having migration skip temporary stacks]
    Signed-off-by: Mel Gorman <mel@csn.ul.ie>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Minchan Kim <minchan.kim@gmail.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e6e94c626c2c..9badbc0bfb1d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -242,9 +242,10 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	 * use STACK_TOP because that can depend on attributes which aren't
 	 * configured yet.
 	 */
+	BUG_ON(VM_STACK_FLAGS & VM_STACK_INCOMPLETE_SETUP);
 	vma->vm_end = STACK_TOP_MAX;
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
-	vma->vm_flags = VM_STACK_FLAGS;
+	vma->vm_flags = VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 	INIT_LIST_HEAD(&vma->anon_vma_chain);
 	err = insert_vm_struct(mm, vma);
@@ -616,6 +617,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	else if (executable_stack == EXSTACK_DISABLE_X)
 		vm_flags &= ~VM_EXEC;
 	vm_flags |= mm->def_flags;
+	vm_flags |= VM_STACK_INCOMPLETE_SETUP;
 
 	ret = mprotect_fixup(vma, &prev, vma->vm_start, vma->vm_end,
 			vm_flags);
@@ -630,6 +632,9 @@ int setup_arg_pages(struct linux_binprm *bprm,
 			goto out_unlock;
 	}
 
+	/* mprotect_fixup is overkill to remove the temporary stack flags */
+	vma->vm_flags &= ~VM_STACK_INCOMPLETE_SETUP;
+
 	stack_expand = 131072UL; /* randomly 32*4k (or 2*64k) pages */
 	stack_size = vma->vm_end - vma->vm_start;
 	/*

commit 34441427aab4bdb3069a4ffcda69a99357abcb2e
Author: Robin Holt <holt@sgi.com>
Date:   Tue May 11 14:06:46 2010 -0700

    revert "procfs: provide stack information for threads" and its fixup commits
    
    Originally, commit d899bf7b ("procfs: provide stack information for
    threads") attempted to introduce a new feature for showing where the
    threadstack was located and how many pages are being utilized by the
    stack.
    
    Commit c44972f1 ("procfs: disable per-task stack usage on NOMMU") was
    applied to fix the NO_MMU case.
    
    Commit 89240ba0 ("x86, fs: Fix x86 procfs stack information for threads on
    64-bit") was applied to fix a bug in ia32 executables being loaded.
    
    Commit 9ebd4eba7 ("procfs: fix /proc/<pid>/stat stack pointer for kernel
    threads") was applied to fix a bug which had kernel threads printing a
    userland stack address.
    
    Commit 1306d603f ('proc: partially revert "procfs: provide stack
    information for threads"') was then applied to revert the stack pages
    being used to solve a significant performance regression.
    
    This patch nearly undoes the effect of all these patches.
    
    The reason for reverting these is it provides an unusable value in
    field 28.  For x86_64, a fork will result in the task->stack_start
    value being updated to the current user top of stack and not the stack
    start address.  This unpredictability of the stack_start value makes
    it worthless.  That includes the intended use of showing how much stack
    space a thread has.
    
    Other architectures will get different values.  As an example, ia64
    gets 0.  The do_fork() and copy_process() functions appear to treat the
    stack_start and stack_size parameters as architecture specific.
    
    I only partially reverted c44972f1 ("procfs: disable per-task stack usage
    on NOMMU") .  If I had completely reverted it, I would have had to change
    mm/Makefile only build pagewalk.o when CONFIG_PROC_PAGE_MONITOR is
    configured.  Since I could not test the builds without significant effort,
    I decided to not change mm/Makefile.
    
    I only partially reverted 89240ba0 ("x86, fs: Fix x86 procfs stack
    information for threads on 64-bit") .  I left the KSTK_ESP() change in
    place as that seemed worthwhile.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Cc: Stefani Seibold <stefani@seibold.net>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 49cdaa19e5b9..e6e94c626c2c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1387,8 +1387,6 @@ int do_execve(char * filename,
 	if (retval < 0)
 		goto out;
 
-	current->stack_start = current->mm->start_stack;
-
 	/* execve succeeded */
 	current->fs->in_exec = 0;
 	current->in_execve = 0;

commit 76595f79d76fbe6267a51b3a866a028d150f06d4
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Fri Mar 5 13:44:16 2010 -0800

    coredump: suppress uid comparison test if core output files are pipes
    
    Modify uid check in do_coredump so as to not apply it in the case of
    pipes.
    
    This just got noticed in testing.  The end of do_coredump validates the
    uid of the inode for the created file against the uid of the crashing
    process to ensure that no one can pre-create a core file with different
    ownership and grab the information contained in the core when they
    shouldn' tbe able to.  This causes failures when using pipes for a core
    dumps if the crashing process is not root, which is the uid of the pipe
    when it is created.
    
    The fix is simple.  Since the check for matching uid's isn't relevant for
    pipes (a process can't create a pipe that the uermodehelper code will open
    anyway), we can just just skip it in the event ispipe is non-zero
    
    Reverts a pipe-affecting change which was accidentally made in
    
    : commit c46f739dd39db3b07ab5deb4e3ec81e1c04a91af
    : Author:     Ingo Molnar <mingo@elte.hu>
    : AuthorDate: Wed Nov 28 13:59:18 2007 +0100
    : Commit:     Linus Torvalds <torvalds@woody.linux-foundation.org>
    : CommitDate: Wed Nov 28 10:58:01 2007 -0800
    :
    :     vfs: coredumping fix
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 829a6c6d1803..49cdaa19e5b9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1936,8 +1936,9 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	/*
 	 * Dont allow local users get cute and trick others to coredump
 	 * into their pre-created files:
+	 * Note, this is not relevant for pipes
 	 */
-	if (inode->i_uid != current_fsuid())
+	if (!ispipe && (inode->i_uid != current_fsuid()))
 		goto close_fail;
 	if (!cprm.file->f_op)
 		goto close_fail;

commit 5c99cbf49a6e1a1efd25b11f4604c65c455e1612
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Mar 5 13:44:14 2010 -0800

    coredump: set ->group_exit_code for other CLONE_VM tasks too
    
    User visible change.
    
    do_coredump() kills all threads which share the same ->mm but only the
    coredumping process gets the proper exit_code.  Other tasks which share
    the same ->mm die "silently" and return status == 0 to parent.
    
    This is historical behaviour, not actually a bug.  But I think Frank
    Heckenbach rightly dislikes the current behaviour.  Simple test-case:
    
            #include <stdio.h>
            #include <unistd.h>
            #include <signal.h>
            #include <sys/wait.h>
    
            int main(void)
            {
                    int stat;
    
                    if (!fork()) {
                            if (!vfork())
                                    kill(getpid(), SIGQUIT);
                    }
    
                    wait(&stat);
                    printf("stat=%x\n", stat);
                    return 0;
            }
    
    Before this patch it prints "stat=0" despite the fact the child was killed
    by SIGQUIT.  After this patch the output is "stat=3" which obviously makes
    more sense.
    
    Even with this patch, only the task which originates the coredumping gets
    "|= 0x80" if the core was actually dumped, but at least the coredumping
    signal is visible to do_wait/etc.
    
    Reported-by: Frank Heckenbach <f.heckenbach@fh-soft.de>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: WANG Cong <xiyou.wangcong@gmail.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 89d4080c1435..829a6c6d1803 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1561,12 +1561,13 @@ static int format_corename(char *corename, long signr)
 	return ispipe;
 }
 
-static int zap_process(struct task_struct *start)
+static int zap_process(struct task_struct *start, int exit_code)
 {
 	struct task_struct *t;
 	int nr = 0;
 
 	start->signal->flags = SIGNAL_GROUP_EXIT;
+	start->signal->group_exit_code = exit_code;
 	start->signal->group_stop_count = 0;
 
 	t = start;
@@ -1591,8 +1592,7 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 	spin_lock_irq(&tsk->sighand->siglock);
 	if (!signal_group_exit(tsk->signal)) {
 		mm->core_state = core_state;
-		tsk->signal->group_exit_code = exit_code;
-		nr = zap_process(tsk);
+		nr = zap_process(tsk, exit_code);
 	}
 	spin_unlock_irq(&tsk->sighand->siglock);
 	if (unlikely(nr < 0))
@@ -1641,7 +1641,7 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 			if (p->mm) {
 				if (unlikely(p->mm == mm)) {
 					lock_task_sighand(p, &flags);
-					nr += zap_process(p);
+					nr += zap_process(p, exit_code);
 					unlock_task_sighand(p, &flags);
 				}
 				break;

commit 30736a4d43f4af7f1a7836d6a266be17082195c4
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Fri Mar 5 13:44:12 2010 -0800

    coredump: pass mm->flags as a coredump parameter for consistency
    
    Pass mm->flags as a coredump parameter for consistency.
    
     ---
    1787         if (mm->core_state || !get_dumpable(mm)) {  <- (1)
    1788                 up_write(&mm->mmap_sem);
    1789                 put_cred(cred);
    1790                 goto fail;
    1791         }
    1792
    [...]
    1798         if (get_dumpable(mm) == 2) {    /* Setuid core dump mode */ <-(2)
    1799                 flag = O_EXCL;          /* Stop rewrite attacks */
    1800                 cred->fsuid = 0;        /* Dump root private */
    1801         }
     ---
    
    Since dumpable bits are not protected by lock, there is a chance to change
    these bits between (1) and (2).
    
    To solve this issue, this patch copies mm->flags to
    coredump_params.mm_flags at the beginning of do_coredump() and uses it
    instead of get_dumpable() while dumping core.
    
    This copy is also passed to binfmt->core_dump, since elf*_core_dump() uses
    dump_filter bits in mm->flags.
    
    [akpm@linux-foundation.org: fix merge]
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index da2b31dc4e1c..89d4080c1435 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1748,14 +1748,19 @@ void set_dumpable(struct mm_struct *mm, int value)
 	}
 }
 
-int get_dumpable(struct mm_struct *mm)
+static int __get_dumpable(unsigned long mm_flags)
 {
 	int ret;
 
-	ret = mm->flags & 0x3;
+	ret = mm_flags & MMF_DUMPABLE_MASK;
 	return (ret >= 2) ? 2 : ret;
 }
 
+int get_dumpable(struct mm_struct *mm)
+{
+	return __get_dumpable(mm->flags);
+}
+
 static void wait_for_dump_helpers(struct file *file)
 {
 	struct pipe_inode_info *pipe;
@@ -1799,6 +1804,12 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		.signr = signr,
 		.regs = regs,
 		.limit = rlimit(RLIMIT_CORE),
+		/*
+		 * We must use the same mm->flags while dumping core to avoid
+		 * inconsistency of bit flags, since this flag is not protected
+		 * by any locks.
+		 */
+		.mm_flags = mm->flags,
 	};
 
 	audit_core_dumps(signr);
@@ -1817,7 +1828,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	/*
 	 * If another thread got here first, or we are not dumpable, bail out.
 	 */
-	if (mm->core_state || !get_dumpable(mm)) {
+	if (mm->core_state || !__get_dumpable(cprm.mm_flags)) {
 		up_write(&mm->mmap_sem);
 		put_cred(cred);
 		goto fail;
@@ -1828,7 +1839,8 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	 *	process nor do we know its entire history. We only know it
 	 *	was tainted so we dump it as root in mode 2.
 	 */
-	if (get_dumpable(mm) == 2) {	/* Setuid core dump mode */
+	if (__get_dumpable(cprm.mm_flags) == 2) {
+		/* Setuid core dump mode */
 		flag = O_EXCL;		/* Stop rewrite attacks */
 		cred->fsuid = 0;	/* Dump root private */
 	}

commit 5ef097dd7ba4eab8b4f0026d85fcef9fe23b821f
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Mar 5 13:42:57 2010 -0800

    exec: create initial stack independent of PAGE_SIZE
    
    Currently we create the initial stack based on the PAGE_SIZE.  This is
    unnecessary.
    
    This creates this initial stack independent of the PAGE_SIZE.
    
    It also bumps up the number of 4k pages allocated from 20 to 32, to
    align with 64K page systems.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Cc: Helge Deller <deller@gmx.de>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Americo Wang <xiyou.wangcong@gmail.com>
    Cc: Anton Blanchard <anton@samba.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6348d79401de..da2b31dc4e1c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -556,8 +556,6 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 	return 0;
 }
 
-#define EXTRA_STACK_VM_PAGES	20	/* random */
-
 /*
  * Finalizes the stack vm_area_struct. The flags and permissions are updated,
  * the stack is optionally relocated, and some extra space is added.
@@ -632,7 +630,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 			goto out_unlock;
 	}
 
-	stack_expand = EXTRA_STACK_VM_PAGES * PAGE_SIZE;
+	stack_expand = 131072UL; /* randomly 32*4k (or 2*64k) pages */
 	stack_size = vma->vm_end - vma->vm_start;
 	/*
 	 * Align this down to a page boundary as expand_stack

commit d554ed895dc8f293cc712c71f14b101ace82579a
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Fri Mar 5 13:42:42 2010 -0800

    fs: use rlimit helpers
    
    Make sure compiler won't do weird things with limits.  E.g.  fetching them
    twice may return 2 different values after writable limits are implemented.
    
    I.e.  either use rlimit helpers added in commit 3e10e716abf3 ("resource:
    add helpers for fetching rlimits") or ACCESS_ONCE if not applicable.
    
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 591030735591..6348d79401de 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -195,7 +195,7 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		 *    to work from.
 		 */
 		rlim = current->signal->rlim;
-		if (size > rlim[RLIMIT_STACK].rlim_cur / 4) {
+		if (size > ACCESS_ONCE(rlim[RLIMIT_STACK].rlim_cur) / 4) {
 			put_page(page);
 			return NULL;
 		}
@@ -579,7 +579,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 
 #ifdef CONFIG_STACK_GROWSUP
 	/* Limit stack size to 1GB */
-	stack_base = current->signal->rlim[RLIMIT_STACK].rlim_max;
+	stack_base = rlimit_max(RLIMIT_STACK);
 	if (stack_base > (1 << 30))
 		stack_base = 1 << 30;
 
@@ -1535,7 +1535,7 @@ static int format_corename(char *corename, long signr)
 			/* core limit size */
 			case 'c':
 				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%lu", current->signal->rlim[RLIMIT_CORE].rlim_cur);
+					      "%lu", rlimit(RLIMIT_CORE));
 				if (rc > out_end - out_ptr)
 					goto out;
 				out_ptr += rc;
@@ -1800,7 +1800,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	struct coredump_params cprm = {
 		.signr = signr,
 		.regs = regs,
-		.limit = current->signal->rlim[RLIMIT_CORE].rlim_cur,
+		.limit = rlimit(RLIMIT_CORE),
 	};
 
 	audit_core_dumps(signr);

commit 5beb49305251e5669852ed541e8e2f2f7696c53e
Author: Rik van Riel <riel@redhat.com>
Date:   Fri Mar 5 13:42:07 2010 -0800

    mm: change anon_vma linking to fix multi-process server scalability issue
    
    The old anon_vma code can lead to scalability issues with heavily forking
    workloads.  Specifically, each anon_vma will be shared between the parent
    process and all its child processes.
    
    In a workload with 1000 child processes and a VMA with 1000 anonymous
    pages per process that get COWed, this leads to a system with a million
    anonymous pages in the same anon_vma, each of which is mapped in just one
    of the 1000 processes.  However, the current rmap code needs to walk them
    all, leading to O(N) scanning complexity for each page.
    
    This can result in systems where one CPU is walking the page tables of
    1000 processes in page_referenced_one, while all other CPUs are stuck on
    the anon_vma lock.  This leads to catastrophic failure for a benchmark
    like AIM7, where the total number of processes can reach in the tens of
    thousands.  Real workloads are still a factor 10 less process intensive
    than AIM7, but they are catching up.
    
    This patch changes the way anon_vmas and VMAs are linked, which allows us
    to associate multiple anon_vmas with a VMA.  At fork time, each child
    process gets its own anon_vmas, in which its COWed pages will be
    instantiated.  The parents' anon_vma is also linked to the VMA, because
    non-COWed pages could be present in any of the children.
    
    This reduces rmap scanning complexity to O(1) for the pages of the 1000
    child processes, with O(N) complexity for at most 1/N pages in the system.
     This reduces the average scanning cost in heavily forking workloads from
    O(N) to 2.
    
    The only real complexity in this patch stems from the fact that linking a
    VMA to anon_vmas now involves memory allocations.  This means vma_adjust
    can fail, if it needs to attach a VMA to anon_vma structures.  This in
    turn means error handling needs to be added to the calling functions.
    
    A second source of complexity is that, because there can be multiple
    anon_vmas, the anon_vma linking in vma_adjust can no longer be done under
    "the" anon_vma lock.  To prevent the rmap code from walking up an
    incomplete VMA, this patch introduces the VM_LOCK_RMAP VMA flag.  This bit
    flag uses the same slot as the NOMMU VM_MAPPED_COPY, with an ifdef in mm.h
    to make sure it is impossible to compile a kernel that needs both symbolic
    values for the same bitflag.
    
    Some test results:
    
    Without the anon_vma changes, when AIM7 hits around 9.7k users (on a test
    box with 16GB RAM and not quite enough IO), the system ends up running
    >99% in system time, with every CPU on the same anon_vma lock in the
    pageout code.
    
    With these changes, AIM7 hits the cross-over point around 29.7k users.
    This happens with ~99% IO wait time, there never seems to be any spike in
    system time.  The anon_vma lock contention appears to be resolved.
    
    [akpm@linux-foundation.org: cleanups]
    Signed-off-by: Rik van Riel <riel@redhat.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Larry Woodman <lwoodman@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>
    Cc: Minchan Kim <minchan.kim@gmail.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ea7861727efd..591030735591 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -246,6 +246,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
 	vma->vm_flags = VM_STACK_FLAGS;
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
+	INIT_LIST_HEAD(&vma->anon_vma_chain);
 	err = insert_vm_struct(mm, vma);
 	if (err)
 		goto err;
@@ -516,7 +517,8 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 	/*
 	 * cover the whole range: [new_start, old_end)
 	 */
-	vma_adjust(vma, new_start, old_end, vma->vm_pgoff, NULL);
+	if (vma_adjust(vma, new_start, old_end, vma->vm_pgoff, NULL))
+		return -ENOMEM;
 
 	/*
 	 * move the page tables downwards, on failure we rely on
@@ -547,7 +549,7 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 	tlb_finish_mmu(tlb, new_end, old_end);
 
 	/*
-	 * shrink the vma to just the new range.
+	 * Shrink the vma to just the new range.  Always succeeds.
 	 */
 	vma_adjust(vma, new_start, new_end, vma->vm_pgoff, NULL);
 

commit 34e55232e59f7b19050267a05ff1226e5cd122a5
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Fri Mar 5 13:41:40 2010 -0800

    mm: avoid false sharing of mm_counter
    
    Considering the nature of per mm stats, it's the shared object among
    threads and can be a cache-miss point in the page fault path.
    
    This patch adds per-thread cache for mm_counter.  RSS value will be
    counted into a struct in task_struct and synchronized with mm's one at
    events.
    
    Now, in this patch, the event is the number of calls to handle_mm_fault.
    Per-thread value is added to mm at each 64 calls.
    
     rough estimation with small benchmark on parallel thread (2threads) shows
     [before]
         4.5 cache-miss/faults
     [after]
         4.0 cache-miss/faults
     Anyway, the most contended object is mmap_sem if the number of threads grows.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Minchan Kim <minchan.kim@gmail.com>
    Cc: Christoph Lameter <cl@linux-foundation.org>
    Cc: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index cce6bbdbdbb1..ea7861727efd 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -718,6 +718,7 @@ static int exec_mmap(struct mm_struct *mm)
 	/* Notify parent that we're no longer interested in the old VM */
 	tsk = current;
 	old_mm = current->mm;
+	sync_mm_rss(tsk, old_mm);
 	mm_release(tsk, old_mm);
 
 	if (old_mm) {

commit a17e18790a8c47113a73139d54a375dc9ccd8f08
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Feb 22 12:44:24 2010 -0800

    fs/exec.c: fix initial stack reservation
    
    803bf5ec259941936262d10ecc84511b76a20921 ("fs/exec.c: restrict initial
    stack space expansion to rlimit") attempts to limit the initial stack to
    20*PAGE_SIZE.  Unfortunately, in attempting ensure the stack is not
    reduced in size, we ended up not changing the stack at all.
    
    This size reduction check is not necessary as the expand_stack call does
    this already.
    
    This caused a regression in UML resulting in most guest processes being
    killed.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Acked-by: WANG Cong <xiyou.wangcong@gmail.com>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Jouni Malinen <j@w1.fi>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e95c692ef0e4..cce6bbdbdbb1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -637,7 +637,6 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	 * will align it up.
 	 */
 	rlim_stack = rlimit(RLIMIT_STACK) & PAGE_MASK;
-	rlim_stack = min(rlim_stack, stack_size);
 #ifdef CONFIG_STACK_GROWSUP
 	if (stack_size + stack_expand > rlim_stack)
 		stack_base = vma->vm_start + rlim_stack;

commit 803bf5ec259941936262d10ecc84511b76a20921
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Feb 10 13:56:42 2010 -0800

    fs/exec.c: restrict initial stack space expansion to rlimit
    
    When reserving stack space for a new process, make sure we're not
    attempting to expand the stack by more than rlimit allows.
    
    This fixes a bug caused by b6a2fea39318e43fee84fa7b0b90d68bed92d2ba ("mm:
    variable length argument support") and unmasked by
    fc63cf237078c86214abcb2ee9926d8ad289da9b ("exec: setup_arg_pages() fails
    to return errors").
    
    This bug means that when limiting the stack to less the 20*PAGE_SIZE (eg.
    80K on 4K pages or 'ulimit -s 79') all processes will be killed before
    they start.  This is particularly bad with 64K pages, where a ulimit below
    1280K will kill every process.
    
    To test, do:
    
      'ulimit -s 15; ls'
    
    before and after the patch is applied.  Before it's applied, 'ls' should
    be killed.  After the patch is applied, 'ls' should no longer be killed.
    
    A stack limit of 15KB since it's small enough to trigger 20*PAGE_SIZE.
    Also 15KB not a multiple of PAGE_SIZE, which is a trickier case to handle
    correctly with this code.
    
    4K pages should be fine to test with.
    
    [kosaki.motohiro@jp.fujitsu.com: cleanup]
    [akpm@linux-foundation.org: cleanup cleanup]
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Americo Wang <xiyou.wangcong@gmail.com>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0790a107ff7e..e95c692ef0e4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -571,6 +571,9 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	struct vm_area_struct *prev = NULL;
 	unsigned long vm_flags;
 	unsigned long stack_base;
+	unsigned long stack_size;
+	unsigned long stack_expand;
+	unsigned long rlim_stack;
 
 #ifdef CONFIG_STACK_GROWSUP
 	/* Limit stack size to 1GB */
@@ -627,10 +630,24 @@ int setup_arg_pages(struct linux_binprm *bprm,
 			goto out_unlock;
 	}
 
+	stack_expand = EXTRA_STACK_VM_PAGES * PAGE_SIZE;
+	stack_size = vma->vm_end - vma->vm_start;
+	/*
+	 * Align this down to a page boundary as expand_stack
+	 * will align it up.
+	 */
+	rlim_stack = rlimit(RLIMIT_STACK) & PAGE_MASK;
+	rlim_stack = min(rlim_stack, stack_size);
 #ifdef CONFIG_STACK_GROWSUP
-	stack_base = vma->vm_end + EXTRA_STACK_VM_PAGES * PAGE_SIZE;
+	if (stack_size + stack_expand > rlim_stack)
+		stack_base = vma->vm_start + rlim_stack;
+	else
+		stack_base = vma->vm_end + stack_expand;
 #else
-	stack_base = vma->vm_start - EXTRA_STACK_VM_PAGES * PAGE_SIZE;
+	if (stack_size + stack_expand > rlim_stack)
+		stack_base = vma->vm_end - rlim_stack;
+	else
+		stack_base = vma->vm_start - stack_expand;
 #endif
 	ret = expand_stack(vma, stack_base);
 	if (ret)

commit 7ab02af428c2d312c0cf8fb0b01cc1eb21131a3d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 2 12:37:44 2010 -0800

    Fix 'flush_old_exec()/setup_new_exec()' split
    
    Commit 221af7f87b9 ("Split 'flush_old_exec' into two functions") split
    the function at the point of no return - ie right where there were no
    more error cases to check.  That made sense from a technical standpoint,
    but when we then also combined it with the actual personality setting
    going in between flush_old_exec() and setup_new_exec(), it needs to be a
    bit more careful.
    
    In particular, we need to make sure that we really flush the old
    personality bits in the 'flush' stage, rather than later in the 'setup'
    stage, since otherwise we might be flushing the _new_ personality state
    that we're just setting up.
    
    So this moves the flags and personality flushing (and 'flush_thread()',
    which is the arch-specific function that generally resets lazy FP state
    etc) of the old process into flush_old_exec(), so that it doesn't affect
    any state that execve() is setting up for the new process environment.
    
    This was reported by Michal Simek as breaking his Microblaze qemu
    environment.
    
    Reported-and-tested-by: Michal Simek <michal.simek@petalogix.com>
    Cc: Peter Anvin <hpa@zytor.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 675c3f44c2ea..0790a107ff7e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -961,6 +961,11 @@ int flush_old_exec(struct linux_binprm * bprm)
 		goto out;
 
 	bprm->mm = NULL;		/* We're using it now */
+
+	current->flags &= ~PF_RANDOMIZE;
+	flush_thread();
+	current->personality &= ~bprm->per_clear;
+
 	return 0;
 
 out:
@@ -997,9 +1002,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 	tcomm[i] = '\0';
 	set_task_comm(current, tcomm);
 
-	current->flags &= ~PF_RANDOMIZE;
-	flush_thread();
-
 	/* Set the new mm task size. We have to do that late because it may
 	 * depend on TIF_32BIT which is only updated in flush_thread() on
 	 * some architectures like powerpc
@@ -1015,8 +1017,6 @@ void setup_new_exec(struct linux_binprm * bprm)
 		set_dumpable(current->mm, suid_dumpable);
 	}
 
-	current->personality &= ~bprm->per_clear;
-
 	/*
 	 * Flush performance counters when crossing a
 	 * security domain:

commit 221af7f87b97431e3ee21ce4b0e77d5411cf1549
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 28 22:14:42 2010 -0800

    Split 'flush_old_exec' into two functions
    
    'flush_old_exec()' is the point of no return when doing an execve(), and
    it is pretty badly misnamed.  It doesn't just flush the old executable
    environment, it also starts up the new one.
    
    Which is very inconvenient for things like setting up the new
    personality, because we want the new personality to affect the starting
    of the new environment, but at the same time we do _not_ want the new
    personality to take effect if flushing the old one fails.
    
    As a result, the x86-64 '32-bit' personality is actually done using this
    insane "I'm going to change the ABI, but I haven't done it yet" bit
    (TIF_ABI_PENDING), with SET_PERSONALITY() not actually setting the
    personality, but just the "pending" bit, so that "flush_thread()" can do
    the actual personality magic.
    
    This patch in no way changes any of that insanity, but it does split the
    'flush_old_exec()' function up into a preparatory part that can fail
    (still called flush_old_exec()), and a new part that will actually set
    up the new exec environment (setup_new_exec()).  All callers are changed
    to trivially comply with the new world order.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 632b02e34ec7..675c3f44c2ea 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -941,9 +941,7 @@ void set_task_comm(struct task_struct *tsk, char *buf)
 
 int flush_old_exec(struct linux_binprm * bprm)
 {
-	char * name;
-	int i, ch, retval;
-	char tcomm[sizeof(current->comm)];
+	int retval;
 
 	/*
 	 * Make sure we have a private signal table and that
@@ -963,6 +961,20 @@ int flush_old_exec(struct linux_binprm * bprm)
 		goto out;
 
 	bprm->mm = NULL;		/* We're using it now */
+	return 0;
+
+out:
+	return retval;
+}
+EXPORT_SYMBOL(flush_old_exec);
+
+void setup_new_exec(struct linux_binprm * bprm)
+{
+	int i, ch;
+	char * name;
+	char tcomm[sizeof(current->comm)];
+
+	arch_pick_mmap_layout(current->mm);
 
 	/* This is the point of no return */
 	current->sas_ss_sp = current->sas_ss_size = 0;
@@ -1019,14 +1031,8 @@ int flush_old_exec(struct linux_binprm * bprm)
 			
 	flush_signal_handlers(current, 0);
 	flush_old_files(current->files);
-
-	return 0;
-
-out:
-	return retval;
 }
-
-EXPORT_SYMBOL(flush_old_exec);
+EXPORT_SYMBOL(setup_new_exec);
 
 /*
  * Prepare credentials and lock ->cred_guard_mutex.

commit f6151dfea21496d43dbaba32cfcd9c9f404769bc
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Thu Dec 17 15:27:16 2009 -0800

    mm: introduce coredump parameter structure
    
    Introduce coredump parameter data structure (struct coredump_params) to
    simplify binfmt->core_dump() arguments.
    
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Suggested-by: Ingo Molnar <mingo@elte.hu>
    Cc: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 77db9a97a773..632b02e34ec7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1763,17 +1763,20 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	struct mm_struct *mm = current->mm;
 	struct linux_binfmt * binfmt;
 	struct inode * inode;
-	struct file * file;
 	const struct cred *old_cred;
 	struct cred *cred;
 	int retval = 0;
 	int flag = 0;
 	int ispipe = 0;
-	unsigned long core_limit = current->signal->rlim[RLIMIT_CORE].rlim_cur;
 	char **helper_argv = NULL;
 	int helper_argc = 0;
 	int dump_count = 0;
 	static atomic_t core_dump_count = ATOMIC_INIT(0);
+	struct coredump_params cprm = {
+		.signr = signr,
+		.regs = regs,
+		.limit = current->signal->rlim[RLIMIT_CORE].rlim_cur,
+	};
 
 	audit_core_dumps(signr);
 
@@ -1829,15 +1832,15 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	ispipe = format_corename(corename, signr);
 	unlock_kernel();
 
-	if ((!ispipe) && (core_limit < binfmt->min_coredump))
+	if ((!ispipe) && (cprm.limit < binfmt->min_coredump))
 		goto fail_unlock;
 
  	if (ispipe) {
-		if (core_limit == 0) {
+		if (cprm.limit == 0) {
 			/*
 			 * Normally core limits are irrelevant to pipes, since
 			 * we're not writing to the file system, but we use
-			 * core_limit of 0 here as a speacial value. Any
+			 * cprm.limit of 0 here as a speacial value. Any
 			 * non-zero limit gets set to RLIM_INFINITY below, but
 			 * a limit of 0 skips the dump.  This is a consistent
 			 * way to catch recursive crashes.  We can still crash
@@ -1870,25 +1873,25 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 			goto fail_dropcount;
 		}
 
-		core_limit = RLIM_INFINITY;
+		cprm.limit = RLIM_INFINITY;
 
 		/* SIGPIPE can happen, but it's just never processed */
 		if (call_usermodehelper_pipe(helper_argv[0], helper_argv, NULL,
-				&file)) {
+				&cprm.file)) {
  			printk(KERN_INFO "Core dump to %s pipe failed\n",
 			       corename);
 			goto fail_dropcount;
  		}
  	} else
- 		file = filp_open(corename,
+		cprm.file = filp_open(corename,
 				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag,
 				 0600);
-	if (IS_ERR(file))
+	if (IS_ERR(cprm.file))
 		goto fail_dropcount;
-	inode = file->f_path.dentry->d_inode;
+	inode = cprm.file->f_path.dentry->d_inode;
 	if (inode->i_nlink > 1)
 		goto close_fail;	/* multiple links - don't dump */
-	if (!ispipe && d_unhashed(file->f_path.dentry))
+	if (!ispipe && d_unhashed(cprm.file->f_path.dentry))
 		goto close_fail;
 
 	/* AK: actually i see no reason to not allow this for named pipes etc.,
@@ -1901,21 +1904,22 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	 */
 	if (inode->i_uid != current_fsuid())
 		goto close_fail;
-	if (!file->f_op)
+	if (!cprm.file->f_op)
 		goto close_fail;
-	if (!file->f_op->write)
+	if (!cprm.file->f_op->write)
 		goto close_fail;
-	if (!ispipe && do_truncate(file->f_path.dentry, 0, 0, file) != 0)
+	if (!ispipe &&
+	    do_truncate(cprm.file->f_path.dentry, 0, 0, cprm.file) != 0)
 		goto close_fail;
 
-	retval = binfmt->core_dump(signr, regs, file, core_limit);
+	retval = binfmt->core_dump(&cprm);
 
 	if (retval)
 		current->signal->group_exit_code |= 0x80;
 close_fail:
 	if (ispipe && core_pipe_limit)
-		wait_for_dump_helpers(file);
-	filp_close(file, NULL);
+		wait_for_dump_helpers(cprm.file);
+	filp_close(cprm.file, NULL);
 fail_dropcount:
 	if (dump_count)
 		atomic_dec(&core_dump_count);

commit 9cd80bbb07fcd6d4d037fad4297496d3b132ac6b
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Dec 17 15:27:15 2009 -0800

    do_wait() optimization: do not place sub-threads on task_struct->children list
    
    Thanks to Roland who pointed out de_thread() issues.
    
    Currently we add sub-threads to ->real_parent->children list.  This buys
    nothing but slows down do_wait().
    
    With this patch ->children contains only main threads (group leaders).
    The only complication is that forget_original_parent() should iterate over
    sub-threads by hand, and de_thread() needs another list_replace() when it
    changes ->group_leader.
    
    Henceforth do_wait_thread() can never see task_detached() && !EXIT_DEAD
    tasks, we can remove this check (and we can unify do_wait_thread() and
    ptrace_do_wait()).
    
    This change can confuse the optimistic search in mm_update_next_owner(),
    but this is fixable and minor.
    
    Perhaps badness() and oom_kill_process() should be updated, but they
    should be fixed in any case.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Ratan Nalumasu <rnalumasu@gmail.com>
    Cc: Vitaly Mayatskikh <vmayatsk@redhat.com>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 623a5cc3076a..77db9a97a773 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -826,7 +826,9 @@ static int de_thread(struct task_struct *tsk)
 		attach_pid(tsk, PIDTYPE_PID,  task_pid(leader));
 		transfer_pid(leader, tsk, PIDTYPE_PGID);
 		transfer_pid(leader, tsk, PIDTYPE_SID);
+
 		list_replace_rcu(&leader->tasks, &tsk->tasks);
+		list_replace_init(&leader->sibling, &tsk->sibling);
 
 		tsk->group_leader = tsk;
 		leader->group_leader = tsk;

commit 4614a696bd1c3a9af3a08f0e5874830a85b889d4
Author: john stultz <johnstul@us.ibm.com>
Date:   Mon Dec 14 18:00:05 2009 -0800

    procfs: allow threads to rename siblings via /proc/pid/tasks/tid/comm
    
    Setting a thread's comm to be something unique is a very useful ability
    and is helpful for debugging complicated threaded applications.  However
    currently the only way to set a thread name is for the thread to name
    itself via the PR_SET_NAME prctl.
    
    However, there may be situations where it would be advantageous for a
    thread dispatcher to be naming the threads its managing, rather then
    having the threads self-describe themselves.  This sort of behavior is
    available on other systems via the pthread_setname_np() interface.
    
    This patch exports a task's comm via proc/pid/comm and
    proc/pid/task/tid/comm interfaces, and allows thread siblings to write to
    these values.
    
    [akpm@linux-foundation.org: cleanups]
    Signed-off-by: John Stultz <johnstul@us.ibm.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: Mike Fulton <fultonm@ca.ibm.com>
    Cc: Sean Foley <Sean_Foley@ca.ibm.com>
    Cc: Darren Hart <dvhltc@us.ibm.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index c0c636e34f60..623a5cc3076a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -923,6 +923,15 @@ char *get_task_comm(char *buf, struct task_struct *tsk)
 void set_task_comm(struct task_struct *tsk, char *buf)
 {
 	task_lock(tsk);
+
+	/*
+	 * Threads may access current->comm without holding
+	 * the task lock, so write the string carefully.
+	 * Readers without a lock may see incomplete new
+	 * names but are safe from non-terminating string reads.
+	 */
+	memset(tsk->comm, 0, TASK_COMM_LEN);
+	wmb();
 	strlcpy(tsk->comm, buf, sizeof(tsk->comm));
 	task_unlock(tsk);
 	perf_event_comm(tsk);

commit c84d6efd363a3948eb32ec40d46bab6338580454
Merge: 7539cf4b92be 22763c5cf369
Author: James Morris <jmorris@macbook.(none)>
Date:   Thu Dec 3 12:03:40 2009 +0530

    Merge branch 'master' into next

commit fc63cf237078c86214abcb2ee9926d8ad289da9b
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Nov 11 14:26:48 2009 -0800

    exec: setup_arg_pages() fails to return errors
    
    In setup_arg_pages we work hard to assign a value to ret, but on exit we
    always return 0.
    
    Also remove a now duplicated exit path and branch to out_unlock instead.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Reviewed-by: WANG Cong <xiyou.wangcong@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index d49be6bc1793..ba112bd4a339 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -624,10 +624,8 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	/* Move stack pages down in memory. */
 	if (stack_shift) {
 		ret = shift_arg_pages(vma, stack_shift);
-		if (ret) {
-			up_write(&mm->mmap_sem);
-			return ret;
-		}
+		if (ret)
+			goto out_unlock;
 	}
 
 #ifdef CONFIG_STACK_GROWSUP
@@ -641,7 +639,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 
 out_unlock:
 	up_write(&mm->mmap_sem);
-	return 0;
+	return ret;
 }
 EXPORT_SYMBOL(setup_arg_pages);
 

commit 6c21a7fb492bf7e2c4985937082ce58ddeca84bd
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Thu Oct 22 17:30:13 2009 -0400

    LSM: imbed ima calls in the security hooks
    
    Based on discussions on LKML and LSM, where there are consecutive
    security_ and ima_ calls in the vfs layer, move the ima_ calls to
    the existing security_ hooks.
    
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index d49be6bc1793..d164342c2b69 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -46,7 +46,6 @@
 #include <linux/proc_fs.h>
 #include <linux/mount.h>
 #include <linux/security.h>
-#include <linux/ima.h>
 #include <linux/syscalls.h>
 #include <linux/tsacct_kern.h>
 #include <linux/cn_proc.h>
@@ -1209,9 +1208,6 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 	struct linux_binfmt *fmt;
 
 	retval = security_bprm_check(bprm);
-	if (retval)
-		return retval;
-	retval = ima_bprm_check(bprm);
 	if (retval)
 		return retval;
 

commit 801460d0cf5c5288153b722565773059b0f44348
Author: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>
Date:   Wed Sep 23 15:57:41 2009 -0700

    task_struct cleanup: move binfmt field to mm_struct
    
    Because the binfmt is not different between threads in the same process,
    it can be moved from task_struct to mm_struct.  And binfmt moudle is
    handled per mm_struct instead of task_struct.
    
    Signed-off-by: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6dc92c39dd94..d49be6bc1793 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1397,10 +1397,12 @@ int do_execve(char * filename,
 
 void set_binfmt(struct linux_binfmt *new)
 {
-	if (current->binfmt)
-		module_put(current->binfmt->module);
+	struct mm_struct *mm = current->mm;
+
+	if (mm->binfmt)
+		module_put(mm->binfmt->module);
 
-	current->binfmt = new;
+	mm->binfmt = new;
 	if (new)
 		__module_get(new->module);
 }
@@ -1770,7 +1772,7 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 
 	audit_core_dumps(signr);
 
-	binfmt = current->binfmt;
+	binfmt = mm->binfmt;
 	if (!binfmt || !binfmt->core_dump)
 		goto fail;
 

commit 964ee7df90d799e38fb1556c57cd5c45fc736436
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 23 15:56:59 2009 -0700

    exec: fix set_binfmt() vs sys_delete_module() race
    
    sys_delete_module() can set MODULE_STATE_GOING after
    search_binary_handler() does try_module_get().  In this case
    set_binfmt()->try_module_get() fails but since none of the callers
    check the returned error, the task will run with the wrong old
    ->binfmt.
    
    The proper fix should change all ->load_binary() methods, but we can
    rely on fact that the caller must hold a reference to binfmt->module
    and use __module_get() which never fails.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 8efbdc606a1e..6dc92c39dd94 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1395,18 +1395,14 @@ int do_execve(char * filename,
 	return retval;
 }
 
-int set_binfmt(struct linux_binfmt *new)
+void set_binfmt(struct linux_binfmt *new)
 {
-	struct linux_binfmt *old = current->binfmt;
+	if (current->binfmt)
+		module_put(current->binfmt->module);
 
-	if (new) {
-		if (!try_module_get(new->module))
-			return -1;
-	}
 	current->binfmt = new;
-	if (old)
-		module_put(old->module);
-	return 0;
+	if (new)
+		__module_get(new->module);
 }
 
 EXPORT_SYMBOL(set_binfmt);

commit 61be228a06dc6e8662f30e89eda3c12083c1f379
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Wed Sep 23 15:56:58 2009 -0700

    exec: allow do_coredump() to wait for user space pipe readers to complete
    
    Allow core_pattern pipes to wait for user space to complete
    
    One of the things that user space processes like to do is look at metadata
    for a crashing process in their /proc/<pid> directory.  this is racy
    however, since do_coredump in the kernel doesn't wait for the user space
    process to complete before it reaps the crashing process.  This patch
    corrects that.  Allowing the kernel to wait for the user space process to
    complete before cleaning up the crashing process.  This is a bit tricky to
    do for a few reasons:
    
    1) The user space process isn't our child, so we can't sys_wait4 on it
    2) We need to close the pipe before waiting for the user process to complete,
    since the user process may rely on an EOF condition
    
    I've discussed several solutions with Oleg Nesterov off-list about this,
    and this is the one we've come up with.  We add ourselves as a pipe reader
    (to prevent premature cleanup of the pipe_inode_info), and remove
    ourselves as a writer (to provide an EOF condition to the writer in user
    space), then we iterate until the user space process exits (which we
    detect by pipe->readers == 1, hence the > 1 check in the loop).  When we
    exit the loop, we restore the proper reader/writer values, then we return
    and let filp_close in do_coredump clean up the pipe data properly.
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Reported-by: Earl Chew <earl_chew@agilent.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index dc022dd15d51..8efbdc606a1e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -55,6 +55,7 @@
 #include <linux/kmod.h>
 #include <linux/fsnotify.h>
 #include <linux/fs_struct.h>
+#include <linux/pipe_fs_i.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -1729,6 +1730,29 @@ int get_dumpable(struct mm_struct *mm)
 	return (ret >= 2) ? 2 : ret;
 }
 
+static void wait_for_dump_helpers(struct file *file)
+{
+	struct pipe_inode_info *pipe;
+
+	pipe = file->f_path.dentry->d_inode->i_pipe;
+
+	pipe_lock(pipe);
+	pipe->readers++;
+	pipe->writers--;
+
+	while ((pipe->readers > 1) && (!signal_pending(current))) {
+		wake_up_interruptible_sync(&pipe->wait);
+		kill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);
+		pipe_wait(pipe);
+	}
+
+	pipe->readers--;
+	pipe->writers++;
+	pipe_unlock(pipe);
+
+}
+
+
 void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 {
 	struct core_state core_state;
@@ -1886,6 +1910,8 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	if (retval)
 		current->signal->group_exit_code |= 0x80;
 close_fail:
+	if (ispipe && core_pipe_limit)
+		wait_for_dump_helpers(file);
 	filp_close(file, NULL);
 fail_dropcount:
 	if (dump_count)

commit a293980c2e261bd5b0d2a77340dd04f684caff58
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Wed Sep 23 15:56:56 2009 -0700

    exec: let do_coredump() limit the number of concurrent dumps to pipes
    
    Introduce core pipe limiting sysctl.
    
    Since we can dump cores to pipe, rather than directly to the filesystem,
    we create a condition in which a user can create a very high load on the
    system simply by running bad applications.
    
    If the pipe reader specified in core_pattern is poorly written, we can
    have lots of ourstandig resources and processes in the system.
    
    This sysctl introduces an ability to limit that resource consumption.
    core_pipe_limit defines how many in-flight dumps may be run in parallel,
    dumps beyond this value are skipped and a note is made in the kernel log.
    A special value of 0 in core_pipe_limit denotes unlimited core dumps may
    be handled (this is the default value).
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Reported-by: Earl Chew <earl_chew@agilent.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 735d9c18ec71..dc022dd15d51 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -63,6 +63,7 @@
 
 int core_uses_pid;
 char core_pattern[CORENAME_MAX_SIZE] = "core";
+unsigned int core_pipe_limit;
 int suid_dumpable = 0;
 
 /* The maximal length of core_pattern is also specified in sysctl.c */
@@ -1744,7 +1745,8 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 	unsigned long core_limit = current->signal->rlim[RLIMIT_CORE].rlim_cur;
 	char **helper_argv = NULL;
 	int helper_argc = 0;
-	char *delimit;
+	int dump_count = 0;
+	static atomic_t core_dump_count = ATOMIC_INIT(0);
 
 	audit_core_dumps(signr);
 
@@ -1826,28 +1828,36 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 			goto fail_unlock;
 		}
 
+		dump_count = atomic_inc_return(&core_dump_count);
+		if (core_pipe_limit && (core_pipe_limit < dump_count)) {
+			printk(KERN_WARNING "Pid %d(%s) over core_pipe_limit\n",
+			       task_tgid_vnr(current), current->comm);
+			printk(KERN_WARNING "Skipping core dump\n");
+			goto fail_dropcount;
+		}
+
 		helper_argv = argv_split(GFP_KERNEL, corename+1, &helper_argc);
 		if (!helper_argv) {
 			printk(KERN_WARNING "%s failed to allocate memory\n",
 			       __func__);
-			goto fail_unlock;
+			goto fail_dropcount;
 		}
 
 		core_limit = RLIM_INFINITY;
 
 		/* SIGPIPE can happen, but it's just never processed */
- 		if (call_usermodehelper_pipe(corename+1, helper_argv, NULL,
+		if (call_usermodehelper_pipe(helper_argv[0], helper_argv, NULL,
 				&file)) {
  			printk(KERN_INFO "Core dump to %s pipe failed\n",
 			       corename);
- 			goto fail_unlock;
+			goto fail_dropcount;
  		}
  	} else
  		file = filp_open(corename,
 				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag,
 				 0600);
 	if (IS_ERR(file))
-		goto fail_unlock;
+		goto fail_dropcount;
 	inode = file->f_path.dentry->d_inode;
 	if (inode->i_nlink > 1)
 		goto close_fail;	/* multiple links - don't dump */
@@ -1877,6 +1887,9 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 		current->signal->group_exit_code |= 0x80;
 close_fail:
 	filp_close(file, NULL);
+fail_dropcount:
+	if (dump_count)
+		atomic_dec(&core_dump_count);
 fail_unlock:
 	if (helper_argv)
 		argv_free(helper_argv);

commit 725eae32df7754044809973034429a47e6035158
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Wed Sep 23 15:56:54 2009 -0700

    exec: make do_coredump() more resilient to recursive crashes
    
    Change how we detect recursive dumps.
    
    Currently we have a mechanism by which we try to compare pathnames of the
    crashing process to the core_pattern path.  This is broken for a dozen
    reasons, and just doesn't work in any sort of robust way.
    
    I'm replacing it with the use of a 0 RLIMIT_CORE value.  Since helper apps
    set RLIMIT_CORE to zero, we don't write out core files for any process
    with that particular limit set.  It the core_pattern is a pipe, any
    non-zero limit is translated to RLIM_INFINITY.
    
    This allows complete dumps to be captured, but prevents infinite recursion
    in the event that the core_pattern process itself crashes.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Reported-by: Earl Chew <earl_chew@agilent.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 5c833c18d0d4..735d9c18ec71 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1799,38 +1799,39 @@ void do_coredump(long signr, int exit_code, struct pt_regs *regs)
  	lock_kernel();
 	ispipe = format_corename(corename, signr);
 	unlock_kernel();
-	/*
-	 * Don't bother to check the RLIMIT_CORE value if core_pattern points
-	 * to a pipe.  Since we're not writing directly to the filesystem
-	 * RLIMIT_CORE doesn't really apply, as no actual core file will be
-	 * created unless the pipe reader choses to write out the core file
-	 * at which point file size limits and permissions will be imposed
-	 * as it does with any other process
-	 */
+
 	if ((!ispipe) && (core_limit < binfmt->min_coredump))
 		goto fail_unlock;
 
  	if (ispipe) {
+		if (core_limit == 0) {
+			/*
+			 * Normally core limits are irrelevant to pipes, since
+			 * we're not writing to the file system, but we use
+			 * core_limit of 0 here as a speacial value. Any
+			 * non-zero limit gets set to RLIM_INFINITY below, but
+			 * a limit of 0 skips the dump.  This is a consistent
+			 * way to catch recursive crashes.  We can still crash
+			 * if the core_pattern binary sets RLIM_CORE =  !0
+			 * but it runs as root, and can do lots of stupid things
+			 * Note that we use task_tgid_vnr here to grab the pid
+			 * of the process group leader.  That way we get the
+			 * right pid if a thread in a multi-threaded
+			 * core_pattern process dies.
+			 */
+			printk(KERN_WARNING
+				"Process %d(%s) has RLIMIT_CORE set to 0\n",
+				task_tgid_vnr(current), current->comm);
+			printk(KERN_WARNING "Aborting core\n");
+			goto fail_unlock;
+		}
+
 		helper_argv = argv_split(GFP_KERNEL, corename+1, &helper_argc);
 		if (!helper_argv) {
 			printk(KERN_WARNING "%s failed to allocate memory\n",
 			       __func__);
 			goto fail_unlock;
 		}
-		/* Terminate the string before the first option */
-		delimit = strchr(corename, ' ');
-		if (delimit)
-			*delimit = '\0';
-		delimit = strrchr(helper_argv[0], '/');
-		if (delimit)
-			delimit++;
-		else
-			delimit = helper_argv[0];
-		if (!strcmp(delimit, current->comm)) {
-			printk(KERN_NOTICE "Recursive core dump detected, "
-					"aborting\n");
-			goto fail_unlock;
-		}
 
 		core_limit = RLIM_INFINITY;
 

commit d899bf7b55f503ba7d3d07ed27c3a37e270fa7db
Author: Stefani Seibold <stefani@seibold.net>
Date:   Tue Sep 22 16:45:40 2009 -0700

    procfs: provide stack information for threads
    
    A patch to give a better overview of the userland application stack usage,
    especially for embedded linux.
    
    Currently you are only able to dump the main process/thread stack usage
    which is showed in /proc/pid/status by the "VmStk" Value.  But you get no
    information about the consumed stack memory of the the threads.
    
    There is an enhancement in the /proc/<pid>/{task/*,}/*maps and which marks
    the vm mapping where the thread stack pointer reside with "[thread stack
    xxxxxxxx]".  xxxxxxxx is the maximum size of stack.  This is a value
    information, because libpthread doesn't set the start of the stack to the
    top of the mapped area, depending of the pthread usage.
    
    A sample output of /proc/<pid>/task/<tid>/maps looks like:
    
    08048000-08049000 r-xp 00000000 03:00 8312       /opt/z
    08049000-0804a000 rw-p 00001000 03:00 8312       /opt/z
    0804a000-0806b000 rw-p 00000000 00:00 0          [heap]
    a7d12000-a7d13000 ---p 00000000 00:00 0
    a7d13000-a7f13000 rw-p 00000000 00:00 0          [thread stack: 001ff4b4]
    a7f13000-a7f14000 ---p 00000000 00:00 0
    a7f14000-a7f36000 rw-p 00000000 00:00 0
    a7f36000-a8069000 r-xp 00000000 03:00 4222       /lib/libc.so.6
    a8069000-a806b000 r--p 00133000 03:00 4222       /lib/libc.so.6
    a806b000-a806c000 rw-p 00135000 03:00 4222       /lib/libc.so.6
    a806c000-a806f000 rw-p 00000000 00:00 0
    a806f000-a8083000 r-xp 00000000 03:00 14462      /lib/libpthread.so.0
    a8083000-a8084000 r--p 00013000 03:00 14462      /lib/libpthread.so.0
    a8084000-a8085000 rw-p 00014000 03:00 14462      /lib/libpthread.so.0
    a8085000-a8088000 rw-p 00000000 00:00 0
    a8088000-a80a4000 r-xp 00000000 03:00 8317       /lib/ld-linux.so.2
    a80a4000-a80a5000 r--p 0001b000 03:00 8317       /lib/ld-linux.so.2
    a80a5000-a80a6000 rw-p 0001c000 03:00 8317       /lib/ld-linux.so.2
    afaf5000-afb0a000 rw-p 00000000 00:00 0          [stack]
    ffffe000-fffff000 r-xp 00000000 00:00 0          [vdso]
    
    Also there is a new entry "stack usage" in /proc/<pid>/{task/*,}/status
    which will you give the current stack usage in kb.
    
    A sample output of /proc/self/status looks like:
    
    Name:   cat
    State:  R (running)
    Tgid:   507
    Pid:    507
    .
    .
    .
    CapBnd: fffffffffffffeff
    voluntary_ctxt_switches:        0
    nonvoluntary_ctxt_switches:     0
    Stack usage:    12 kB
    
    I also fixed stack base address in /proc/<pid>/{task/*,}/stat to the base
    address of the associated thread stack and not the one of the main
    process.  This makes more sense.
    
    [akpm@linux-foundation.org: fs/proc/array.c now needs walk_page_range()]
    Signed-off-by: Stefani Seibold <stefani@seibold.net>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 69bb9d899791..5c833c18d0d4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1357,6 +1357,8 @@ int do_execve(char * filename,
 	if (retval < 0)
 		goto out;
 
+	current->stack_start = current->mm->start_stack;
+
 	/* execve succeeded */
 	current->fs->in_exec = 0;
 	current->in_execve = 0;

commit 1f10206cf8e945220f7220a809d8bfc15c21f9a5
Author: Jiri Pirko <jpirko@redhat.com>
Date:   Tue Sep 22 16:44:10 2009 -0700

    getrusage: fill ru_maxrss value
    
    Make ->ru_maxrss value in struct rusage filled accordingly to rss hiwater
    mark.  This struct is filled as a parameter to getrusage syscall.
    ->ru_maxrss value is set to KBs which is the way it is done in BSD
    systems.  /usr/bin/time (gnu time) application converts ->ru_maxrss to KBs
    which seems to be incorrect behavior.  Maintainer of this util was
    notified by me with the patch which corrects it and cc'ed.
    
    To make this happen we extend struct signal_struct by two fields.  The
    first one is ->maxrss which we use to store rss hiwater of the task.  The
    second one is ->cmaxrss which we use to store highest rss hiwater of all
    task childs.  These values are used in k_getrusage() to actually fill
    ->ru_maxrss.  k_getrusage() uses current rss hiwater value directly if mm
    struct exists.
    
    Note:
    exec() clear mm->hiwater_rss, but doesn't clear sig->maxrss.
    it is intetionally behavior. *BSD getrusage have exec() inheriting.
    
    test programs
    ========================================================
    
    getrusage.c
    ===========
     #include <stdio.h>
     #include <stdlib.h>
     #include <string.h>
     #include <sys/types.h>
     #include <sys/time.h>
     #include <sys/resource.h>
     #include <sys/types.h>
     #include <sys/wait.h>
     #include <unistd.h>
     #include <signal.h>
     #include <sys/mman.h>
    
     #include "common.h"
    
     #define err(str) perror(str), exit(1)
    
    int main(int argc, char** argv)
    {
            int status;
    
            printf("allocate 100MB\n");
            consume(100);
    
            printf("testcase1: fork inherit? \n");
            printf("  expect: initial.self ~= child.self\n");
            show_rusage("initial");
            if (__fork()) {
                    wait(&status);
            } else {
                    show_rusage("fork child");
                    _exit(0);
            }
            printf("\n");
    
            printf("testcase2: fork inherit? (cont.) \n");
            printf("  expect: initial.children ~= 100MB, but child.children = 0\n");
            show_rusage("initial");
            if (__fork()) {
                    wait(&status);
            } else {
                    show_rusage("child");
                    _exit(0);
            }
            printf("\n");
    
            printf("testcase3: fork + malloc \n");
            printf("  expect: child.self ~= initial.self + 50MB\n");
            show_rusage("initial");
            if (__fork()) {
                    wait(&status);
            } else {
                    printf("allocate +50MB\n");
                    consume(50);
                    show_rusage("fork child");
                    _exit(0);
            }
            printf("\n");
    
            printf("testcase4: grandchild maxrss\n");
            printf("  expect: post_wait.children ~= 300MB\n");
            show_rusage("initial");
            if (__fork()) {
                    wait(&status);
                    show_rusage("post_wait");
            } else {
                    system("./child -n 0 -g 300");
                    _exit(0);
            }
            printf("\n");
    
            printf("testcase5: zombie\n");
            printf("  expect: pre_wait ~= initial, IOW the zombie process is not accounted.\n");
            printf("          post_wait ~= 400MB, IOW wait() collect child's max_rss. \n");
            show_rusage("initial");
            if (__fork()) {
                    sleep(1); /* children become zombie */
                    show_rusage("pre_wait");
                    wait(&status);
                    show_rusage("post_wait");
            } else {
                    system("./child -n 400");
                    _exit(0);
            }
            printf("\n");
    
            printf("testcase6: SIG_IGN\n");
            printf("  expect: initial ~= after_zombie (child's 500MB alloc should be ignored).\n");
            show_rusage("initial");
            signal(SIGCHLD, SIG_IGN);
            if (__fork()) {
                    sleep(1); /* children become zombie */
                    show_rusage("after_zombie");
            } else {
                    system("./child -n 500");
                    _exit(0);
            }
            printf("\n");
            signal(SIGCHLD, SIG_DFL);
    
            printf("testcase7: exec (without fork) \n");
            printf("  expect: initial ~= exec \n");
            show_rusage("initial");
            execl("./child", "child", "-v", NULL);
    
            return 0;
    }
    
    child.c
    =======
     #include <sys/types.h>
     #include <unistd.h>
     #include <sys/types.h>
     #include <sys/wait.h>
     #include <stdio.h>
     #include <stdlib.h>
     #include <string.h>
     #include <sys/types.h>
     #include <sys/time.h>
     #include <sys/resource.h>
    
     #include "common.h"
    
    int main(int argc, char** argv)
    {
            int status;
            int c;
            long consume_size = 0;
            long grandchild_consume_size = 0;
            int show = 0;
    
            while ((c = getopt(argc, argv, "n:g:v")) != -1) {
                    switch (c) {
                    case 'n':
                            consume_size = atol(optarg);
                            break;
                    case 'v':
                            show = 1;
                            break;
                    case 'g':
    
                            grandchild_consume_size = atol(optarg);
                            break;
                    default:
                            break;
                    }
            }
    
            if (show)
                    show_rusage("exec");
    
            if (consume_size) {
                    printf("child alloc %ldMB\n", consume_size);
                    consume(consume_size);
            }
    
            if (grandchild_consume_size) {
                    if (fork()) {
                            wait(&status);
                    } else {
                            printf("grandchild alloc %ldMB\n", grandchild_consume_size);
                            consume(grandchild_consume_size);
    
                            exit(0);
                    }
            }
    
            return 0;
    }
    
    common.c
    ========
     #include <stdio.h>
     #include <stdlib.h>
     #include <string.h>
     #include <sys/types.h>
     #include <sys/time.h>
     #include <sys/resource.h>
     #include <sys/types.h>
     #include <sys/wait.h>
     #include <unistd.h>
     #include <signal.h>
     #include <sys/mman.h>
    
     #include "common.h"
     #define err(str) perror(str), exit(1)
    
    void show_rusage(char *prefix)
    {
            int err, err2;
            struct rusage rusage_self;
            struct rusage rusage_children;
    
            printf("%s: ", prefix);
            err = getrusage(RUSAGE_SELF, &rusage_self);
            if (!err)
                    printf("self %ld ", rusage_self.ru_maxrss);
            err2 = getrusage(RUSAGE_CHILDREN, &rusage_children);
            if (!err2)
                    printf("children %ld ", rusage_children.ru_maxrss);
    
            printf("\n");
    }
    
    /* Some buggy OS need this worthless CPU waste. */
    void make_pagefault(void)
    {
            void *addr;
            int size = getpagesize();
            int i;
    
            for (i=0; i<1000; i++) {
                    addr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);
                    if (addr == MAP_FAILED)
                            err("make_pagefault");
                    memset(addr, 0, size);
                    munmap(addr, size);
            }
    }
    
    void consume(int mega)
    {
            size_t sz = mega * 1024 * 1024;
            void *ptr;
    
            ptr = malloc(sz);
            memset(ptr, 0, sz);
            make_pagefault();
    }
    
    pid_t __fork(void)
    {
            pid_t pid;
    
            pid = fork();
            make_pagefault();
    
            return pid;
    }
    
    common.h
    ========
    void show_rusage(char *prefix);
    void make_pagefault(void);
    void consume(int mega);
    pid_t __fork(void);
    
    FreeBSD result (expected result)
    ========================================================
    allocate 100MB
    testcase1: fork inherit?
      expect: initial.self ~= child.self
    initial: self 103492 children 0
    fork child: self 103540 children 0
    
    testcase2: fork inherit? (cont.)
      expect: initial.children ~= 100MB, but child.children = 0
    initial: self 103540 children 103540
    child: self 103564 children 0
    
    testcase3: fork + malloc
      expect: child.self ~= initial.self + 50MB
    initial: self 103564 children 103564
    allocate +50MB
    fork child: self 154860 children 0
    
    testcase4: grandchild maxrss
      expect: post_wait.children ~= 300MB
    initial: self 103564 children 154860
    grandchild alloc 300MB
    post_wait: self 103564 children 308720
    
    testcase5: zombie
      expect: pre_wait ~= initial, IOW the zombie process is not accounted.
              post_wait ~= 400MB, IOW wait() collect child's max_rss.
    initial: self 103564 children 308720
    child alloc 400MB
    pre_wait: self 103564 children 308720
    post_wait: self 103564 children 411312
    
    testcase6: SIG_IGN
      expect: initial ~= after_zombie (child's 500MB alloc should be ignored).
    initial: self 103564 children 411312
    child alloc 500MB
    after_zombie: self 103624 children 411312
    
    testcase7: exec (without fork)
      expect: initial ~= exec
    initial: self 103624 children 411312
    exec: self 103624 children 411312
    
    Linux result (actual test result)
    ========================================================
    allocate 100MB
    testcase1: fork inherit?
      expect: initial.self ~= child.self
    initial: self 102848 children 0
    fork child: self 102572 children 0
    
    testcase2: fork inherit? (cont.)
      expect: initial.children ~= 100MB, but child.children = 0
    initial: self 102876 children 102644
    child: self 102572 children 0
    
    testcase3: fork + malloc
      expect: child.self ~= initial.self + 50MB
    initial: self 102876 children 102644
    allocate +50MB
    fork child: self 153804 children 0
    
    testcase4: grandchild maxrss
      expect: post_wait.children ~= 300MB
    initial: self 102876 children 153864
    grandchild alloc 300MB
    post_wait: self 102876 children 307536
    
    testcase5: zombie
      expect: pre_wait ~= initial, IOW the zombie process is not accounted.
              post_wait ~= 400MB, IOW wait() collect child's max_rss.
    initial: self 102876 children 307536
    child alloc 400MB
    pre_wait: self 102876 children 307536
    post_wait: self 102876 children 410076
    
    testcase6: SIG_IGN
      expect: initial ~= after_zombie (child's 500MB alloc should be ignored).
    initial: self 102876 children 410076
    child alloc 500MB
    after_zombie: self 102880 children 410076
    
    testcase7: exec (without fork)
      expect: initial ~= exec
    initial: self 102880 children 410076
    exec: self 102880 children 410076
    
    Signed-off-by: Jiri Pirko <jpirko@redhat.com>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 434dba778ccc..69bb9d899791 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -845,6 +845,9 @@ static int de_thread(struct task_struct *tsk)
 	sig->notify_count = 0;
 
 no_thread_group:
+	if (current->mm)
+		setmax_mm_hiwater_rss(&sig->maxrss, current->mm);
+
 	exit_itimers(sig);
 	flush_itimer_signals();
 

commit cdd6c482c9ff9c55475ee7392ec8f672eddb7be6
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Sep 21 12:02:48 2009 +0200

    perf: Do the big rename: Performance Counters -> Performance Events
    
    Bye-bye Performance Counters, welcome Performance Events!
    
    In the past few months the perfcounters subsystem has grown out its
    initial role of counting hardware events, and has become (and is
    becoming) a much broader generic event enumeration, reporting, logging,
    monitoring, analysis facility.
    
    Naming its core object 'perf_counter' and naming the subsystem
    'perfcounters' has become more and more of a misnomer. With pending
    code like hw-breakpoints support the 'counter' name is less and
    less appropriate.
    
    All in one, we've decided to rename the subsystem to 'performance
    events' and to propagate this rename through all fields, variables
    and API names. (in an ABI compatible fashion)
    
    The word 'event' is also a bit shorter than 'counter' - which makes
    it slightly more convenient to write/handle as well.
    
    Thanks goes to Stephane Eranian who first observed this misnomer and
    suggested a rename.
    
    User-space tooling and ABI compatibility is not affected - this patch
    should be function-invariant. (Also, defconfigs were not touched to
    keep the size down.)
    
    This patch has been generated via the following script:
    
      FILES=$(find * -type f | grep -vE 'oprofile|[^K]config')
    
      sed -i \
        -e 's/PERF_EVENT_/PERF_RECORD_/g' \
        -e 's/PERF_COUNTER/PERF_EVENT/g' \
        -e 's/perf_counter/perf_event/g' \
        -e 's/nb_counters/nb_events/g' \
        -e 's/swcounter/swevent/g' \
        -e 's/tpcounter_event/tp_event/g' \
        $FILES
    
      for N in $(find . -name perf_counter.[ch]); do
        M=$(echo $N | sed 's/perf_counter/perf_event/g')
        mv $N $M
      done
    
      FILES=$(find . -name perf_event.*)
    
      sed -i \
        -e 's/COUNTER_MASK/REG_MASK/g' \
        -e 's/COUNTER/EVENT/g' \
        -e 's/\<event\>/event_id/g' \
        -e 's/counter/event/g' \
        -e 's/Counter/Event/g' \
        $FILES
    
    ... to keep it as correct as possible. This script can also be
    used by anyone who has pending perfcounters patches - it converts
    a Linux kernel tree over to the new naming. We tried to time this
    change to the point in time where the amount of pending patches
    is the smallest: the end of the merge window.
    
    Namespace clashes were fixed up in a preparatory patch - and some
    stylistic fallout will be fixed up in a subsequent patch.
    
    ( NOTE: 'counters' are still the proper terminology when we deal
      with hardware registers - and these sed scripts are a bit
      over-eager in renaming them. I've undone some of that, but
      in case there's something left where 'counter' would be
      better than 'event' we can undo that on an individual basis
      instead of touching an otherwise nicely automated patch. )
    
    Suggested-by: Stephane Eranian <eranian@google.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Reviewed-by: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: <linux-arch@vger.kernel.org>
    LKML-Reference: <new-submission>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/exec.c b/fs/exec.c
index 172ceb6edde4..434dba778ccc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -33,7 +33,7 @@
 #include <linux/string.h>
 #include <linux/init.h>
 #include <linux/pagemap.h>
-#include <linux/perf_counter.h>
+#include <linux/perf_event.h>
 #include <linux/highmem.h>
 #include <linux/spinlock.h>
 #include <linux/key.h>
@@ -923,7 +923,7 @@ void set_task_comm(struct task_struct *tsk, char *buf)
 	task_lock(tsk);
 	strlcpy(tsk->comm, buf, sizeof(tsk->comm));
 	task_unlock(tsk);
-	perf_counter_comm(tsk);
+	perf_event_comm(tsk);
 }
 
 int flush_old_exec(struct linux_binprm * bprm)
@@ -997,7 +997,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 * security domain:
 	 */
 	if (!get_dumpable(current->mm))
-		perf_counter_exit_task(current);
+		perf_event_exit_task(current);
 
 	/* An exec changes our domain. We are no longer part of the thread
 	   group */

commit a2a8474c3fff88d8dd52d05cb450563fb26fd26c
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sat Sep 5 11:17:13 2009 -0700

    exec: do not sleep in TASK_TRACED under ->cred_guard_mutex
    
    Tom Horsley reports that his debugger hangs when it tries to read
    /proc/pid_of_tracee/maps, this happens since
    
            "mm_for_maps: take ->cred_guard_mutex to fix the race with exec"
            04b836cbf19e885f8366bccb2e4b0474346c02d
    
    commit in 2.6.31.
    
    But the root of the problem lies in the fact that do_execve() path calls
    tracehook_report_exec() which can stop if the tracer sets PT_TRACE_EXEC.
    
    The tracee must not sleep in TASK_TRACED holding this mutex.  Even if we
    remove ->cred_guard_mutex from mm_for_maps() and proc_pid_attr_write(),
    another task doing PTRACE_ATTACH should not hang until it is killed or the
    tracee resumes.
    
    With this patch do_execve() does not use ->cred_guard_mutex directly and
    we do not hold it throughout, instead:
    
            - introduce prepare_bprm_creds() helper, it locks the mutex
              and calls prepare_exec_creds() to initialize bprm->cred.
    
            - install_exec_creds() drops the mutex after commit_creds(),
              and thus before tracehook_report_exec()->ptrace_stop().
    
              or, if exec fails,
    
              free_bprm() drops this mutex when bprm->cred != NULL which
              indicates install_exec_creds() was not called.
    
    Reported-by: Tom Horsley <tom.horsley@att.net>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index fb4f3cdda78c..172ceb6edde4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1015,6 +1015,35 @@ int flush_old_exec(struct linux_binprm * bprm)
 
 EXPORT_SYMBOL(flush_old_exec);
 
+/*
+ * Prepare credentials and lock ->cred_guard_mutex.
+ * install_exec_creds() commits the new creds and drops the lock.
+ * Or, if exec fails before, free_bprm() should release ->cred and
+ * and unlock.
+ */
+int prepare_bprm_creds(struct linux_binprm *bprm)
+{
+	if (mutex_lock_interruptible(&current->cred_guard_mutex))
+		return -ERESTARTNOINTR;
+
+	bprm->cred = prepare_exec_creds();
+	if (likely(bprm->cred))
+		return 0;
+
+	mutex_unlock(&current->cred_guard_mutex);
+	return -ENOMEM;
+}
+
+void free_bprm(struct linux_binprm *bprm)
+{
+	free_arg_pages(bprm);
+	if (bprm->cred) {
+		mutex_unlock(&current->cred_guard_mutex);
+		abort_creds(bprm->cred);
+	}
+	kfree(bprm);
+}
+
 /*
  * install the new credentials for this executable
  */
@@ -1024,12 +1053,13 @@ void install_exec_creds(struct linux_binprm *bprm)
 
 	commit_creds(bprm->cred);
 	bprm->cred = NULL;
-
-	/* cred_guard_mutex must be held at least to this point to prevent
+	/*
+	 * cred_guard_mutex must be held at least to this point to prevent
 	 * ptrace_attach() from altering our determination of the task's
-	 * credentials; any time after this it may be unlocked */
-
+	 * credentials; any time after this it may be unlocked.
+	 */
 	security_bprm_committed_creds(bprm);
+	mutex_unlock(&current->cred_guard_mutex);
 }
 EXPORT_SYMBOL(install_exec_creds);
 
@@ -1246,14 +1276,6 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 
 EXPORT_SYMBOL(search_binary_handler);
 
-void free_bprm(struct linux_binprm *bprm)
-{
-	free_arg_pages(bprm);
-	if (bprm->cred)
-		abort_creds(bprm->cred);
-	kfree(bprm);
-}
-
 /*
  * sys_execve() executes a new program.
  */
@@ -1277,20 +1299,15 @@ int do_execve(char * filename,
 	if (!bprm)
 		goto out_files;
 
-	retval = -ERESTARTNOINTR;
-	if (mutex_lock_interruptible(&current->cred_guard_mutex))
+	retval = prepare_bprm_creds(bprm);
+	if (retval)
 		goto out_free;
-	current->in_execve = 1;
-
-	retval = -ENOMEM;
-	bprm->cred = prepare_exec_creds();
-	if (!bprm->cred)
-		goto out_unlock;
 
 	retval = check_unsafe_exec(bprm);
 	if (retval < 0)
-		goto out_unlock;
+		goto out_free;
 	clear_in_exec = retval;
+	current->in_execve = 1;
 
 	file = open_exec(filename);
 	retval = PTR_ERR(file);
@@ -1340,7 +1357,6 @@ int do_execve(char * filename,
 	/* execve succeeded */
 	current->fs->in_exec = 0;
 	current->in_execve = 0;
-	mutex_unlock(&current->cred_guard_mutex);
 	acct_update_integrals(current);
 	free_bprm(bprm);
 	if (displaced)
@@ -1360,10 +1376,7 @@ int do_execve(char * filename,
 out_unmark:
 	if (clear_in_exec)
 		current->fs->in_exec = 0;
-
-out_unlock:
 	current->in_execve = 0;
-	mutex_unlock(&current->cred_guard_mutex);
 
 out_free:
 	free_bprm(bprm);

commit 6777d773a463ac045d333b989d4e44660f8d92ad
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Fri Aug 21 14:32:48 2009 -0400

    kernel_read: redefine offset type
    
    vfs_read() offset is defined as loff_t, but kernel_read()
    offset is only defined as unsigned long. Redefine
    kernel_read() offset as loff_t.
    
    Cc: stable@kernel.org
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4a8849e45b21..fb4f3cdda78c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -678,8 +678,8 @@ struct file *open_exec(const char *name)
 }
 EXPORT_SYMBOL(open_exec);
 
-int kernel_read(struct file *file, unsigned long offset,
-	char *addr, unsigned long count)
+int kernel_read(struct file *file, loff_t offset,
+		char *addr, unsigned long count)
 {
 	mm_segment_t old_fs;
 	loff_t pos = offset;

commit 793285fcafce4719a05e0c99fa74b188157fe7fe
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sun Jul 5 12:08:26 2009 -0700

    cred_guard_mutex: do not return -EINTR to user-space
    
    do_execve() and ptrace_attach() return -EINTR if
    mutex_lock_interruptible(->cred_guard_mutex) fails.
    
    This is not right, change the code to return ERESTARTNOINTR.
    
    Perhaps we should also change proc_pid_attr_write().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e639957d7a57..4a8849e45b21 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1277,8 +1277,8 @@ int do_execve(char * filename,
 	if (!bprm)
 		goto out_files;
 
-	retval = mutex_lock_interruptible(&current->cred_guard_mutex);
-	if (retval < 0)
+	retval = -ERESTARTNOINTR;
+	if (mutex_lock_interruptible(&current->cred_guard_mutex))
 		goto out_free;
 	current->in_execve = 1;
 

commit 8a1ca8cedd108c8e76a6ab34079d0bbb4f244799
Merge: b640f042faa2 940010c5a314
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 11 14:01:07 2009 -0700

    Merge branch 'perfcounters-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'perfcounters-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (574 commits)
      perf_counter: Turn off by default
      perf_counter: Add counter->id to the throttle event
      perf_counter: Better align code
      perf_counter: Rename L2 to LL cache
      perf_counter: Standardize event names
      perf_counter: Rename enums
      perf_counter tools: Clean up u64 usage
      perf_counter: Rename perf_counter_limit sysctl
      perf_counter: More paranoia settings
      perf_counter: powerpc: Implement generalized cache events for POWER processors
      perf_counters: powerpc: Add support for POWER7 processors
      perf_counter: Accurate period data
      perf_counter: Introduce struct for sample data
      perf_counter tools: Normalize data using per sample period data
      perf_counter: Annotate exit ctx recursion
      perf_counter tools: Propagate signals properly
      perf_counter tools: Small frequency related fixes
      perf_counter: More aggressive frequency adjustment
      perf_counter/x86: Fix the model number of Intel Core2 processors
      perf_counter, x86: Correct some event and umask values for Intel processors
      ...

commit 2c9e703c618106f5383226fbb1f526cb11034f8a
Merge: 6470c077cae1 5805977e63a3
Author: James Morris <jmorris@namei.org>
Date:   Fri May 22 18:40:59 2009 +1000

    Merge branch 'master' into next
    
    Conflicts:
            fs/exec.c
    
    Removed IMA changes (the IMA checks are now performed via may_open()).
    
    Signed-off-by: James Morris <jmorris@namei.org>

commit b9fc745db833bbf74b4988493b8cd902a84c9415
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Tue May 19 13:25:57 2009 -0400

    integrity: path_check update
    
    - Add support in ima_path_check() for integrity checking without
    incrementing the counts. (Required for nfsd.)
    - rename and export opencount_get to ima_counts_get
    - replace ima_shm_check calls with ima_counts_get
    - export ima_path_check
    
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index 998e856c3079..618d6d1e2c52 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -130,7 +130,8 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 				 MAY_READ | MAY_EXEC | MAY_OPEN);
 	if (error)
 		goto exit;
-	error = ima_path_check(&nd.path, MAY_READ | MAY_EXEC | MAY_OPEN);
+	error = ima_path_check(&nd.path, MAY_READ | MAY_EXEC | MAY_OPEN,
+			       IMA_COUNT_UPDATE);
 	if (error)
 		goto exit;
 
@@ -680,7 +681,7 @@ struct file *open_exec(const char *name)
 	err = inode_permission(nd.path.dentry->d_inode, MAY_EXEC | MAY_OPEN);
 	if (err)
 		goto out_path_put;
-	err = ima_path_check(&nd.path, MAY_EXEC | MAY_OPEN);
+	err = ima_path_check(&nd.path, MAY_EXEC | MAY_OPEN, IMA_COUNT_UPDATE);
 	if (err)
 		goto out_path_put;
 

commit dc3f81b129b5439ba7bac265bbc6a51a39275dae
Merge: d2517a49d555 1406de8e11eb
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon May 18 07:37:44 2009 +0200

    Merge commit 'v2.6.30-rc6' into perfcounters/core
    
    Merge reason: this branch was on an -rc4 base, merge it up to -rc6
                  to get the latest upstream fixes.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 5e751e992f3fb08ba35e1ca8095ec8fbf9eda523
Author: David Howells <dhowells@redhat.com>
Date:   Fri May 8 13:55:22 2009 +0100

    CRED: Rename cred_exec_mutex to reflect that it's a guard against ptrace
    
    Rename cred_exec_mutex to reflect that it's a guard against foreign
    intervention on a process's credential state, such as is made by ptrace().  The
    attachment of a debugger to a process affects execve()'s calculation of the new
    credential state - _and_ also setprocattr()'s calculation of that state.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index 639177b0eeac..998e856c3079 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1045,7 +1045,7 @@ void install_exec_creds(struct linux_binprm *bprm)
 	commit_creds(bprm->cred);
 	bprm->cred = NULL;
 
-	/* cred_exec_mutex must be held at least to this point to prevent
+	/* cred_guard_mutex must be held at least to this point to prevent
 	 * ptrace_attach() from altering our determination of the task's
 	 * credentials; any time after this it may be unlocked */
 
@@ -1055,7 +1055,7 @@ EXPORT_SYMBOL(install_exec_creds);
 
 /*
  * determine how safe it is to execute the proposed program
- * - the caller must hold current->cred_exec_mutex to protect against
+ * - the caller must hold current->cred_guard_mutex to protect against
  *   PTRACE_ATTACH
  */
 int check_unsafe_exec(struct linux_binprm *bprm)
@@ -1297,7 +1297,7 @@ int do_execve(char * filename,
 	if (!bprm)
 		goto out_files;
 
-	retval = mutex_lock_interruptible(&current->cred_exec_mutex);
+	retval = mutex_lock_interruptible(&current->cred_guard_mutex);
 	if (retval < 0)
 		goto out_free;
 	current->in_execve = 1;
@@ -1360,7 +1360,7 @@ int do_execve(char * filename,
 	/* execve succeeded */
 	current->fs->in_exec = 0;
 	current->in_execve = 0;
-	mutex_unlock(&current->cred_exec_mutex);
+	mutex_unlock(&current->cred_guard_mutex);
 	acct_update_integrals(current);
 	free_bprm(bprm);
 	if (displaced)
@@ -1383,7 +1383,7 @@ int do_execve(char * filename,
 
 out_unlock:
 	current->in_execve = 0;
-	mutex_unlock(&current->cred_exec_mutex);
+	mutex_unlock(&current->cred_guard_mutex);
 
 out_free:
 	free_bprm(bprm);

commit 6e8341a11eb21826b7192d0bb88cb5b44900a9af
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Apr 6 11:16:22 2009 -0400

    Switch open_exec() and sys_uselib() to do_open_filp()
    
    ... and make path_lookup_open() static
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 41ae8e0de72d..895823d0149d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -105,36 +105,28 @@ static inline void put_binfmt(struct linux_binfmt * fmt)
 SYSCALL_DEFINE1(uselib, const char __user *, library)
 {
 	struct file *file;
-	struct nameidata nd;
 	char *tmp = getname(library);
 	int error = PTR_ERR(tmp);
 
-	if (!IS_ERR(tmp)) {
-		error = path_lookup_open(AT_FDCWD, tmp,
-					 LOOKUP_FOLLOW, &nd,
-					 FMODE_READ|FMODE_EXEC);
-		putname(tmp);
-	}
-	if (error)
+	if (IS_ERR(tmp))
+		goto out;
+
+	file = do_filp_open(AT_FDCWD, tmp,
+				O_LARGEFILE | O_RDONLY | FMODE_EXEC, 0,
+				MAY_READ | MAY_EXEC | MAY_OPEN);
+	putname(tmp);
+	error = PTR_ERR(file);
+	if (IS_ERR(file))
 		goto out;
 
 	error = -EINVAL;
-	if (!S_ISREG(nd.path.dentry->d_inode->i_mode))
+	if (!S_ISREG(file->f_path.dentry->d_inode->i_mode))
 		goto exit;
 
 	error = -EACCES;
-	if (nd.path.mnt->mnt_flags & MNT_NOEXEC)
-		goto exit;
-
-	error = may_open(&nd.path, MAY_READ | MAY_EXEC | MAY_OPEN, 0);
-	if (error)
+	if (file->f_path.mnt->mnt_flags & MNT_NOEXEC)
 		goto exit;
 
-	file = nameidata_to_filp(&nd, O_RDONLY|O_LARGEFILE);
-	error = PTR_ERR(file);
-	if (IS_ERR(file))
-		goto out;
-
 	fsnotify_open(file->f_path.dentry);
 
 	error = -ENOEXEC;
@@ -156,13 +148,10 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 		}
 		read_unlock(&binfmt_lock);
 	}
+exit:
 	fput(file);
 out:
   	return error;
-exit:
-	release_open_intent(&nd);
-	path_put(&nd.path);
-	goto out;
 }
 
 #ifdef CONFIG_MMU
@@ -657,44 +646,33 @@ EXPORT_SYMBOL(setup_arg_pages);
 
 struct file *open_exec(const char *name)
 {
-	struct nameidata nd;
 	struct file *file;
 	int err;
 
-	err = path_lookup_open(AT_FDCWD, name, LOOKUP_FOLLOW, &nd,
-				FMODE_READ|FMODE_EXEC);
-	if (err)
+	file = do_filp_open(AT_FDCWD, name,
+				O_LARGEFILE | O_RDONLY | FMODE_EXEC, 0,
+				MAY_EXEC | MAY_OPEN);
+	if (IS_ERR(file))
 		goto out;
 
 	err = -EACCES;
-	if (!S_ISREG(nd.path.dentry->d_inode->i_mode))
-		goto out_path_put;
-
-	if (nd.path.mnt->mnt_flags & MNT_NOEXEC)
-		goto out_path_put;
-
-	err = may_open(&nd.path, MAY_EXEC | MAY_OPEN, 0);
-	if (err)
-		goto out_path_put;
+	if (!S_ISREG(file->f_path.dentry->d_inode->i_mode))
+		goto exit;
 
-	file = nameidata_to_filp(&nd, O_RDONLY|O_LARGEFILE);
-	if (IS_ERR(file))
-		return file;
+	if (file->f_path.mnt->mnt_flags & MNT_NOEXEC)
+		goto exit;
 
 	fsnotify_open(file->f_path.dentry);
 
 	err = deny_write_access(file);
-	if (err) {
-		fput(file);
-		goto out;
-	}
+	if (err)
+		goto exit;
 
+out:
 	return file;
 
- out_path_put:
-	release_open_intent(&nd);
-	path_put(&nd.path);
- out:
+exit:
+	fput(file);
 	return ERR_PTR(err);
 }
 EXPORT_SYMBOL(open_exec);

commit a44ddbb6d8a8ffe4e34e417048dfdd8f3dd1de4f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Apr 6 09:38:49 2009 -0400

    Make open_exec() and sys_uselib() use may_open(), instead of duplicating its parts
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 639177b0eeac..41ae8e0de72d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -126,11 +126,7 @@ SYSCALL_DEFINE1(uselib, const char __user *, library)
 	if (nd.path.mnt->mnt_flags & MNT_NOEXEC)
 		goto exit;
 
-	error = inode_permission(nd.path.dentry->d_inode,
-				 MAY_READ | MAY_EXEC | MAY_OPEN);
-	if (error)
-		goto exit;
-	error = ima_path_check(&nd.path, MAY_READ | MAY_EXEC | MAY_OPEN);
+	error = may_open(&nd.path, MAY_READ | MAY_EXEC | MAY_OPEN, 0);
 	if (error)
 		goto exit;
 
@@ -677,10 +673,7 @@ struct file *open_exec(const char *name)
 	if (nd.path.mnt->mnt_flags & MNT_NOEXEC)
 		goto out_path_put;
 
-	err = inode_permission(nd.path.dentry->d_inode, MAY_EXEC | MAY_OPEN);
-	if (err)
-		goto out_path_put;
-	err = ima_path_check(&nd.path, MAY_EXEC | MAY_OPEN);
+	err = may_open(&nd.path, MAY_EXEC | MAY_OPEN, 0);
 	if (err)
 		goto out_path_put;
 

commit 74641f584da8eccf30becfbb5507ab457187db22
Author: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
Date:   Thu Apr 30 15:08:49 2009 -0700

    alpha: binfmt_aout fix
    
    This fixes the problem introduced by commit 3bfacef412 (get rid of
    special-casing the /sbin/loader on alpha): osf/1 ecoff binary segfaults
    when binfmt_aout built as module.  That happens because aout binary
    handler gets on the top of the binfmt list due to late registration, and
    kernel attempts to execute the binary without preparatory work that must
    be done by binfmt_loader.
    
    Fixed by changing the registration order of the default binfmt handlers
    using list_add_tail() and introducing insert_binfmt() function which
    places new handler on the top of the binfmt list.  This might be generally
    useful for installing arch-specific frontends for default handlers or just
    for overriding them.
    
    Signed-off-by: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Richard Henderson <rth@twiddle.net
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a3a8ce83940f..639177b0eeac 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -69,17 +69,18 @@ int suid_dumpable = 0;
 static LIST_HEAD(formats);
 static DEFINE_RWLOCK(binfmt_lock);
 
-int register_binfmt(struct linux_binfmt * fmt)
+int __register_binfmt(struct linux_binfmt * fmt, int insert)
 {
 	if (!fmt)
 		return -EINVAL;
 	write_lock(&binfmt_lock);
-	list_add(&fmt->lh, &formats);
+	insert ? list_add(&fmt->lh, &formats) :
+		 list_add_tail(&fmt->lh, &formats);
 	write_unlock(&binfmt_lock);
 	return 0;	
 }
 
-EXPORT_SYMBOL(register_binfmt);
+EXPORT_SYMBOL(__register_binfmt);
 
 void unregister_binfmt(struct linux_binfmt * fmt)
 {

commit e7fd5d4b3d240f42c30a9e3d20a4689c4d3a795a
Merge: 1130b0296184 56a50adda49b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Apr 29 14:46:59 2009 +0200

    Merge branch 'linus' into perfcounters/core
    
    Merge reason: This brach was on -rc1, refresh it to almost-rc4 to pick up
                  the latest upstream fixes.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 437f7fdb607f32b737e4da9f14bebcfdac2c90c3
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Apr 24 01:02:45 2009 +0200

    check_unsafe_exec: s/lock_task_sighand/rcu_read_lock/
    
    write_lock(&current->fs->lock) guarantees we can't wrongly miss
    LSM_UNSAFE_SHARE, this is what we care about. Use rcu_read_lock()
    instead of ->siglock to iterate over the sub-threads. We must see
    all CLONE_THREAD|CLONE_FS threads which didn't pass exit_fs(), it
    takes fs->lock too.
    
    With or without this patch we can miss the freshly cloned thread
    and set LSM_UNSAFE_SHARE, we don't care.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    [ Fixed lock/unlock typo  - Hugh ]
    Acked-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a2e6989dbc3a..a3a8ce83940f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1060,7 +1060,6 @@ EXPORT_SYMBOL(install_exec_creds);
 int check_unsafe_exec(struct linux_binprm *bprm)
 {
 	struct task_struct *p = current, *t;
-	unsigned long flags;
 	unsigned n_fs;
 	int res = 0;
 
@@ -1068,11 +1067,12 @@ int check_unsafe_exec(struct linux_binprm *bprm)
 
 	n_fs = 1;
 	write_lock(&p->fs->lock);
-	lock_task_sighand(p, &flags);
+	rcu_read_lock();
 	for (t = next_thread(p); t != p; t = next_thread(t)) {
 		if (t->fs == p->fs)
 			n_fs++;
 	}
+	rcu_read_unlock();
 
 	if (p->fs->users > n_fs) {
 		bprm->unsafe |= LSM_UNSAFE_SHARE;
@@ -1083,8 +1083,6 @@ int check_unsafe_exec(struct linux_binprm *bprm)
 			res = 1;
 		}
 	}
-
-	unlock_task_sighand(p, &flags);
 	write_unlock(&p->fs->lock);
 
 	return res;

commit 8c652f96d3852b97a49c331cd0bb02d22f3cb31b
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Apr 24 01:01:56 2009 +0200

    do_execve() must not clear fs->in_exec if it was set by another thread
    
    If do_execve() fails after check_unsafe_exec(), it clears fs->in_exec
    unconditionally. This is wrong if we race with our sub-thread which
    also does do_execve:
    
            Two threads T1 and T2 and another process P, all share the same
            ->fs.
    
            T1 starts do_execve(BAD_FILE). It calls check_unsafe_exec(), since
            ->fs is shared, we set LSM_UNSAFE but not ->in_exec.
    
            P exits and decrements fs->users.
    
            T2 starts do_execve(), calls check_unsafe_exec(), now ->fs is not
            shared, we set fs->in_exec.
    
            T1 continues, open_exec(BAD_FILE) fails, we clear ->in_exec and
            return to the user-space.
    
            T1 does clone(CLONE_FS /* without CLONE_THREAD */).
    
            T2 continues without LSM_UNSAFE_SHARE while ->fs is shared with
            another process.
    
    Change check_unsafe_exec() to return res = 1 if we set ->in_exec, and change
    do_execve() to clear ->in_exec depending on res.
    
    When do_execve() suceeds, it is safe to clear ->in_exec unconditionally.
    It can be set only if we don't share ->fs with another process, and since
    we already killed all sub-threads either ->in_exec == 0 or we are the
    only user of this ->fs.
    
    Also, we do not need fs->lock to clear fs->in_exec.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Acked-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 052a961e41aa..a2e6989dbc3a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1077,9 +1077,11 @@ int check_unsafe_exec(struct linux_binprm *bprm)
 	if (p->fs->users > n_fs) {
 		bprm->unsafe |= LSM_UNSAFE_SHARE;
 	} else {
-		if (p->fs->in_exec)
-			res = -EAGAIN;
-		p->fs->in_exec = 1;
+		res = -EAGAIN;
+		if (!p->fs->in_exec) {
+			p->fs->in_exec = 1;
+			res = 1;
+		}
 	}
 
 	unlock_task_sighand(p, &flags);
@@ -1284,6 +1286,7 @@ int do_execve(char * filename,
 	struct linux_binprm *bprm;
 	struct file *file;
 	struct files_struct *displaced;
+	bool clear_in_exec;
 	int retval;
 
 	retval = unshare_files(&displaced);
@@ -1306,8 +1309,9 @@ int do_execve(char * filename,
 		goto out_unlock;
 
 	retval = check_unsafe_exec(bprm);
-	if (retval)
+	if (retval < 0)
 		goto out_unlock;
+	clear_in_exec = retval;
 
 	file = open_exec(filename);
 	retval = PTR_ERR(file);
@@ -1355,9 +1359,7 @@ int do_execve(char * filename,
 		goto out;
 
 	/* execve succeeded */
-	write_lock(&current->fs->lock);
 	current->fs->in_exec = 0;
-	write_unlock(&current->fs->lock);
 	current->in_execve = 0;
 	mutex_unlock(&current->cred_exec_mutex);
 	acct_update_integrals(current);
@@ -1377,9 +1379,8 @@ int do_execve(char * filename,
 	}
 
 out_unmark:
-	write_lock(&current->fs->lock);
-	current->fs->in_exec = 0;
-	write_unlock(&current->fs->lock);
+	if (clear_in_exec)
+		current->fs->in_exec = 0;
 
 out_unlock:
 	current->in_execve = 0;

commit 8d1b2d9361b494bfc761700c348c65ebbe3deb5b
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Wed Apr 8 15:01:30 2009 +0200

    perf_counter: track task-comm data
    
    Similar to the mmap data stream, add one that tracks the task COMM field,
    so that the userspace reporting knows what to call a task.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    LKML-Reference: <20090408130409.127422406@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/exec.c b/fs/exec.c
index e015c0b5a082..bf47ed0278ff 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -951,6 +951,7 @@ void set_task_comm(struct task_struct *tsk, char *buf)
 	task_lock(tsk);
 	strlcpy(tsk->comm, buf, sizeof(tsk->comm));
 	task_unlock(tsk);
+	perf_counter_comm(tsk);
 }
 
 int flush_old_exec(struct linux_binprm * bprm)

commit f541ae326fa120fa5c57433e4d9a133df212ce41
Merge: e255357764f9 0221c81b1b8e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Apr 6 09:02:57 2009 +0200

    Merge branch 'linus' into perfcounters/core-v2
    
    Merge reason: we have gathered quite a few conflicts, need to merge upstream
    
    Conflicts:
            arch/powerpc/kernel/Makefile
            arch/x86/ia32/ia32entry.S
            arch/x86/include/asm/hardirq.h
            arch/x86/include/asm/unistd_32.h
            arch/x86/include/asm/unistd_64.h
            arch/x86/kernel/cpu/common.c
            arch/x86/kernel/irq.c
            arch/x86/kernel/syscall_table_32.S
            arch/x86/mm/iomap_32.c
            include/linux/sched.h
            kernel/Makefile
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 5ad4e53bd5406ee214ddc5a41f03f779b8b2d526
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Mar 29 19:50:06 2009 -0400

    Get rid of indirect include of fs_struct.h
    
    Don't pull it in sched.h; very few files actually need it and those
    can include directly.  sched.h itself only needs forward declaration
    of struct fs_struct;
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 614991bf0c87..052a961e41aa 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -53,6 +53,7 @@
 #include <linux/tracehook.h>
 #include <linux/kmod.h>
 #include <linux/fsnotify.h>
+#include <linux/fs_struct.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>

commit f1191b50ec11c8e2ca766d6d99eb5bb9d2c084a3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Mar 30 07:35:18 2009 -0400

    check_unsafe_exec() doesn't care about signal handlers sharing
    
    ... since we'll unshare sighand anyway
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 07a059664b73..614991bf0c87 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1060,23 +1060,20 @@ int check_unsafe_exec(struct linux_binprm *bprm)
 {
 	struct task_struct *p = current, *t;
 	unsigned long flags;
-	unsigned n_fs, n_sighand;
+	unsigned n_fs;
 	int res = 0;
 
 	bprm->unsafe = tracehook_unsafe_exec(p);
 
 	n_fs = 1;
-	n_sighand = 1;
 	write_lock(&p->fs->lock);
 	lock_task_sighand(p, &flags);
 	for (t = next_thread(p); t != p; t = next_thread(t)) {
 		if (t->fs == p->fs)
 			n_fs++;
-		n_sighand++;
 	}
 
-	if (p->fs->users > n_fs ||
-	    atomic_read(&p->sighand->count) > n_sighand) {
+	if (p->fs->users > n_fs) {
 		bprm->unsafe |= LSM_UNSAFE_SHARE;
 	} else {
 		if (p->fs->in_exec)

commit 498052bba55ecaff58db6a1436b0e25bfd75a7ff
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Mar 30 07:20:30 2009 -0400

    New locking/refcounting for fs_struct
    
    * all changes of current->fs are done under task_lock and write_lock of
      old fs->lock
    * refcount is not atomic anymore (same protection)
    * its decrements are done when removing reference from current; at the
      same time we decide whether to free it.
    * put_fs_struct() is gone
    * new field - ->in_exec.  Set by check_unsafe_exec() if we are trying to do
      execve() and only subthreads share fs_struct.  Cleared when finishing exec
      (success and failure alike).  Makes CLONE_FS fail with -EAGAIN if set.
    * check_unsafe_exec() may fail with -EAGAIN if another execve() from subthread
      is in progress.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index c5128fbc9165..07a059664b73 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1056,16 +1056,18 @@ EXPORT_SYMBOL(install_exec_creds);
  * - the caller must hold current->cred_exec_mutex to protect against
  *   PTRACE_ATTACH
  */
-void check_unsafe_exec(struct linux_binprm *bprm)
+int check_unsafe_exec(struct linux_binprm *bprm)
 {
 	struct task_struct *p = current, *t;
 	unsigned long flags;
 	unsigned n_fs, n_sighand;
+	int res = 0;
 
 	bprm->unsafe = tracehook_unsafe_exec(p);
 
 	n_fs = 1;
 	n_sighand = 1;
+	write_lock(&p->fs->lock);
 	lock_task_sighand(p, &flags);
 	for (t = next_thread(p); t != p; t = next_thread(t)) {
 		if (t->fs == p->fs)
@@ -1073,11 +1075,19 @@ void check_unsafe_exec(struct linux_binprm *bprm)
 		n_sighand++;
 	}
 
-	if (atomic_read(&p->fs->count) > n_fs ||
-	    atomic_read(&p->sighand->count) > n_sighand)
+	if (p->fs->users > n_fs ||
+	    atomic_read(&p->sighand->count) > n_sighand) {
 		bprm->unsafe |= LSM_UNSAFE_SHARE;
+	} else {
+		if (p->fs->in_exec)
+			res = -EAGAIN;
+		p->fs->in_exec = 1;
+	}
 
 	unlock_task_sighand(p, &flags);
+	write_unlock(&p->fs->lock);
+
+	return res;
 }
 
 /* 
@@ -1296,12 +1306,15 @@ int do_execve(char * filename,
 	bprm->cred = prepare_exec_creds();
 	if (!bprm->cred)
 		goto out_unlock;
-	check_unsafe_exec(bprm);
+
+	retval = check_unsafe_exec(bprm);
+	if (retval)
+		goto out_unlock;
 
 	file = open_exec(filename);
 	retval = PTR_ERR(file);
 	if (IS_ERR(file))
-		goto out_unlock;
+		goto out_unmark;
 
 	sched_exec();
 
@@ -1344,6 +1357,9 @@ int do_execve(char * filename,
 		goto out;
 
 	/* execve succeeded */
+	write_lock(&current->fs->lock);
+	current->fs->in_exec = 0;
+	write_unlock(&current->fs->lock);
 	current->in_execve = 0;
 	mutex_unlock(&current->cred_exec_mutex);
 	acct_update_integrals(current);
@@ -1362,6 +1378,11 @@ int do_execve(char * filename,
 		fput(bprm->file);
 	}
 
+out_unmark:
+	write_lock(&current->fs->lock);
+	current->fs->in_exec = 0;
+	write_unlock(&current->fs->lock);
+
 out_unlock:
 	current->in_execve = 0;
 	mutex_unlock(&current->cred_exec_mutex);

commit e426b64c412aaa3e9eb3e4b261dc5be0d5a83e78
Author: Hugh Dickins <hugh@veritas.com>
Date:   Sat Mar 28 23:20:19 2009 +0000

    fix setuid sometimes doesn't
    
    Joe Malicki reports that setuid sometimes doesn't: very rarely,
    a setuid root program does not get root euid; and, by the way,
    they have a health check running lsof every few minutes.
    
    Right, check_unsafe_exec() notes whether the files_struct is being
    shared by more threads than will get killed by the exec, and if so
    sets LSM_UNSAFE_SHARE to make bprm_set_creds() careful about euid.
    But /proc/<pid>/fd and /proc/<pid>/fdinfo lookups make transient
    use of get_files_struct(), which also raises that sharing count.
    
    There's a rather simple fix for this: exec's check on files->count
    has been redundant ever since 2.6.1 made it unshare_files() (except
    while compat_do_execve() omitted to do so) - just remove that check.
    
    [Note to -stable: this patch will not apply before 2.6.29: earlier
    releases should just remove the files->count line from unsafe_exec().]
    
    Reported-by: Joe Malicki <jmalicki@metacarta.com>
    Narrowed-down-by: Michael Itz <mitz@metacarta.com>
    Tested-by: Joe Malicki <jmalicki@metacarta.com>
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index b9f1c144b7a1..c5128fbc9165 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1056,28 +1056,24 @@ EXPORT_SYMBOL(install_exec_creds);
  * - the caller must hold current->cred_exec_mutex to protect against
  *   PTRACE_ATTACH
  */
-void check_unsafe_exec(struct linux_binprm *bprm, struct files_struct *files)
+void check_unsafe_exec(struct linux_binprm *bprm)
 {
 	struct task_struct *p = current, *t;
 	unsigned long flags;
-	unsigned n_fs, n_files, n_sighand;
+	unsigned n_fs, n_sighand;
 
 	bprm->unsafe = tracehook_unsafe_exec(p);
 
 	n_fs = 1;
-	n_files = 1;
 	n_sighand = 1;
 	lock_task_sighand(p, &flags);
 	for (t = next_thread(p); t != p; t = next_thread(t)) {
 		if (t->fs == p->fs)
 			n_fs++;
-		if (t->files == files)
-			n_files++;
 		n_sighand++;
 	}
 
 	if (atomic_read(&p->fs->count) > n_fs ||
-	    atomic_read(&p->files->count) > n_files ||
 	    atomic_read(&p->sighand->count) > n_sighand)
 		bprm->unsafe |= LSM_UNSAFE_SHARE;
 
@@ -1300,7 +1296,7 @@ int do_execve(char * filename,
 	bprm->cred = prepare_exec_creds();
 	if (!bprm->cred)
 		goto out_unlock;
-	check_unsafe_exec(bprm, displaced);
+	check_unsafe_exec(bprm);
 
 	file = open_exec(filename);
 	retval = PTR_ERR(file);

commit 703a3cd72817e99201cef84a8a7aecc60b2b3581
Merge: df7f54c012b9 8e0ee43bc2c3
Author: James Morris <jmorris@namei.org>
Date:   Tue Mar 24 10:52:46 2009 +1100

    Merge branch 'master' into next

commit f9ce1f1cda8b73a36f47e424975a9dfa78b7840c
Author: Kentaro Takeda <takedakn@nttdata.co.jp>
Date:   Thu Feb 5 17:18:11 2009 +0900

    Add in_execve flag into task_struct.
    
    This patch allows LSM modules to determine whether current process is in an
    execve operation or not so that they can behave differently while an execve
    operation is in progress.
    
    This patch is needed by TOMOYO. Please see another patch titled "LSM adapter
    functions." for backgrounds.
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index febfd8ed6ad1..9881dc3bb488 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1278,6 +1278,7 @@ int do_execve(char * filename,
 	retval = mutex_lock_interruptible(&current->cred_exec_mutex);
 	if (retval < 0)
 		goto out_free;
+	current->in_execve = 1;
 
 	retval = -ENOMEM;
 	bprm->cred = prepare_exec_creds();
@@ -1331,6 +1332,7 @@ int do_execve(char * filename,
 		goto out;
 
 	/* execve succeeded */
+	current->in_execve = 0;
 	mutex_unlock(&current->cred_exec_mutex);
 	acct_update_integrals(current);
 	free_bprm(bprm);
@@ -1349,6 +1351,7 @@ int do_execve(char * filename,
 	}
 
 out_unlock:
+	current->in_execve = 0;
 	mutex_unlock(&current->cred_exec_mutex);
 
 out_free:

commit 95fd4845ed0ffcab305b4f30ce1c12dc34f1b56c
Merge: d278c4843562 8e4921515c1a
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Feb 11 09:22:04 2009 +0100

    Merge commit 'v2.6.29-rc4' into perfcounters/core
    
    Conflicts:
            arch/x86/kernel/setup_percpu.c
            arch/x86/mm/fault.c
            drivers/acpi/processor_idle.c
            kernel/irq/handle.c

commit 0bf2f3aec5474da80a60e1baca629af87ecb67b6
Author: David Howells <dhowells@redhat.com>
Date:   Fri Feb 6 11:45:46 2009 +0000

    CRED: Fix SUID exec regression
    
    The patch:
    
            commit a6f76f23d297f70e2a6b3ec607f7aeeea9e37e8d
            CRED: Make execve() take advantage of copy-on-write credentials
    
    moved the place in which the 'safeness' of a SUID/SGID exec was performed to
    before de_thread() was called.  This means that LSM_UNSAFE_SHARE is now
    calculated incorrectly.  This flag is set if any of the usage counts for
    fs_struct, files_struct and sighand_struct are greater than 1 at the time the
    determination is made.  All of which are true for threads created by the
    pthread library.
    
    However, since we wish to make the security calculation before irrevocably
    damaging the process so that we can return it an error code in the case where
    we decide we want to reject the exec request on this basis, we have to make the
    determination before calling de_thread().
    
    So, instead, we count up the number of threads (CLONE_THREAD) that are sharing
    our fs_struct (CLONE_FS), files_struct (CLONE_FILES) and sighand_structs
    (CLONE_SIGHAND/CLONE_THREAD) with us.  These will be killed by de_thread() and
    so can be discounted by check_unsafe_exec().
    
    We do have to be careful because CLONE_THREAD does not imply FS or FILES.
    
    We _assume_ that there will be no extra references to these structs held by the
    threads we're going to kill.
    
    This can be tested with the attached pair of programs.  Build the two programs
    using the Makefile supplied, and run ./test1 as a non-root user.  If
    successful, you should see something like:
    
            [dhowells@andromeda tmp]$ ./test1
            --TEST1--
            uid=4043, euid=4043 suid=4043
            exec ./test2
            --TEST2--
            uid=4043, euid=0 suid=0
            SUCCESS - Correct effective user ID
    
    and if unsuccessful, something like:
    
            [dhowells@andromeda tmp]$ ./test1
            --TEST1--
            uid=4043, euid=4043 suid=4043
            exec ./test2
            --TEST2--
            uid=4043, euid=4043 suid=4043
            ERROR - Incorrect effective user ID!
    
    The non-root user ID you see will depend on the user you run as.
    
    [test1.c]
    #include <stdio.h>
    #include <stdlib.h>
    #include <unistd.h>
    #include <pthread.h>
    
    static void *thread_func(void *arg)
    {
            while (1) {}
    }
    
    int main(int argc, char **argv)
    {
            pthread_t tid;
            uid_t uid, euid, suid;
    
            printf("--TEST1--\n");
            getresuid(&uid, &euid, &suid);
            printf("uid=%d, euid=%d suid=%d\n", uid, euid, suid);
    
            if (pthread_create(&tid, NULL, thread_func, NULL) < 0) {
                    perror("pthread_create");
                    exit(1);
            }
    
            printf("exec ./test2\n");
            execlp("./test2", "test2", NULL);
            perror("./test2");
            _exit(1);
    }
    
    [test2.c]
    #include <stdio.h>
    #include <stdlib.h>
    #include <unistd.h>
    
    int main(int argc, char **argv)
    {
            uid_t uid, euid, suid;
    
            getresuid(&uid, &euid, &suid);
            printf("--TEST2--\n");
            printf("uid=%d, euid=%d suid=%d\n", uid, euid, suid);
    
            if (euid != 0) {
                    fprintf(stderr, "ERROR - Incorrect effective user ID!\n");
                    exit(1);
            }
            printf("SUCCESS - Correct effective user ID\n");
            exit(0);
    }
    
    [Makefile]
    CFLAGS = -D_GNU_SOURCE -Wall -Werror -Wunused
    all: test1 test2
    
    test1: test1.c
            gcc $(CFLAGS) -o test1 test1.c -lpthread
    
    test2: test2.c
            gcc $(CFLAGS) -o test2 test2.c
            sudo chown root.root test2
            sudo chmod +s test2
    
    Reported-by: David Smith <dsmith@redhat.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: David Smith <dsmith@redhat.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0dd60a01f1b4..929b58004b7e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1049,16 +1049,32 @@ EXPORT_SYMBOL(install_exec_creds);
  * - the caller must hold current->cred_exec_mutex to protect against
  *   PTRACE_ATTACH
  */
-void check_unsafe_exec(struct linux_binprm *bprm)
+void check_unsafe_exec(struct linux_binprm *bprm, struct files_struct *files)
 {
-	struct task_struct *p = current;
+	struct task_struct *p = current, *t;
+	unsigned long flags;
+	unsigned n_fs, n_files, n_sighand;
 
 	bprm->unsafe = tracehook_unsafe_exec(p);
 
-	if (atomic_read(&p->fs->count) > 1 ||
-	    atomic_read(&p->files->count) > 1 ||
-	    atomic_read(&p->sighand->count) > 1)
+	n_fs = 1;
+	n_files = 1;
+	n_sighand = 1;
+	lock_task_sighand(p, &flags);
+	for (t = next_thread(p); t != p; t = next_thread(t)) {
+		if (t->fs == p->fs)
+			n_fs++;
+		if (t->files == files)
+			n_files++;
+		n_sighand++;
+	}
+
+	if (atomic_read(&p->fs->count) > n_fs ||
+	    atomic_read(&p->files->count) > n_files ||
+	    atomic_read(&p->sighand->count) > n_sighand)
 		bprm->unsafe |= LSM_UNSAFE_SHARE;
+
+	unlock_task_sighand(p, &flags);
 }
 
 /* 
@@ -1273,7 +1289,7 @@ int do_execve(char * filename,
 	bprm->cred = prepare_exec_creds();
 	if (!bprm->cred)
 		goto out_unlock;
-	check_unsafe_exec(bprm);
+	check_unsafe_exec(bprm, displaced);
 
 	file = open_exec(filename);
 	retval = PTR_ERR(file);

commit cb5629b10d64a8006622ce3a52bc887d91057d69
Merge: 8920d5ad6ba7 f01d1d546abb
Author: James Morris <jmorris@namei.org>
Date:   Fri Feb 6 11:01:45 2009 +1100

    Merge branch 'master' into next
    
    Conflicts:
            fs/namei.c
    
    Manually merged per:
    
    diff --cc fs/namei.c
    index 734f2b5,bbc15c2..0000000
    --- a/fs/namei.c
    +++ b/fs/namei.c
    @@@ -860,9 -848,8 +849,10 @@@ static int __link_path_walk(const char
                    nd->flags |= LOOKUP_CONTINUE;
                    err = exec_permission_lite(inode);
                    if (err == -EAGAIN)
    -                       err = vfs_permission(nd, MAY_EXEC);
    +                       err = inode_permission(nd->path.dentry->d_inode,
    +                                              MAY_EXEC);
     +              if (!err)
     +                      err = ima_path_check(&nd->path, MAY_EXEC);
                    if (err)
                            break;
    
    @@@ -1525,14 -1506,9 +1509,14 @@@ int may_open(struct path *path, int acc
                    flag &= ~O_TRUNC;
            }
    
    -       error = vfs_permission(nd, acc_mode);
    +       error = inode_permission(inode, acc_mode);
            if (error)
                    return error;
     +
    -       error = ima_path_check(&nd->path,
    ++      error = ima_path_check(path,
     +                             acc_mode & (MAY_READ | MAY_WRITE | MAY_EXEC));
     +      if (error)
     +              return error;
            /*
             * An append-only file must be opened in append mode for writing.
             */
    
    Signed-off-by: James Morris <jmorris@namei.org>

commit 6146f0d5e47ca4047ffded0fb79b6c25359b386c
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Wed Feb 4 09:06:57 2009 -0500

    integrity: IMA hooks
    
    This patch replaces the generic integrity hooks, for which IMA registered
    itself, with IMA integrity hooks in the appropriate places directly
    in the fs directory.
    
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index 02d2e120542d..9c789a525cc4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -45,6 +45,7 @@
 #include <linux/proc_fs.h>
 #include <linux/mount.h>
 #include <linux/security.h>
+#include <linux/ima.h>
 #include <linux/syscalls.h>
 #include <linux/tsacct_kern.h>
 #include <linux/cn_proc.h>
@@ -128,6 +129,9 @@ asmlinkage long sys_uselib(const char __user * library)
 		goto exit;
 
 	error = vfs_permission(&nd, MAY_READ | MAY_EXEC | MAY_OPEN);
+	if (error)
+		goto exit;
+	error = ima_path_check(&nd.path, MAY_READ | MAY_EXEC | MAY_OPEN);
 	if (error)
 		goto exit;
 
@@ -681,6 +685,9 @@ struct file *open_exec(const char *name)
 		goto out_path_put;
 
 	err = vfs_permission(&nd, MAY_EXEC | MAY_OPEN);
+	if (err)
+		goto out_path_put;
+	err = ima_path_check(&nd.path, MAY_EXEC | MAY_OPEN);
 	if (err)
 		goto out_path_put;
 
@@ -1207,6 +1214,9 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 	}
 #endif
 	retval = security_bprm_check(bprm);
+	if (retval)
+		return retval;
+	retval = ima_bprm_check(bprm);
 	if (retval)
 		return retval;
 

commit 77835492ed489c0b870f82f4c50687bd267acc0a
Merge: af37501c7921 1de9e8e70f5a
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 21 16:37:27 2009 +0100

    Merge commit 'v2.6.29-rc2' into perfcounters/core
    
    Conflicts:
            include/linux/syscalls.h

commit 1e7bfb2134dfec37ce04fb3a4ca89299e892d10c
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 14 14:14:29 2009 +0100

    [CVE-2009-0029] System call wrappers part 27
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/fs/exec.c b/fs/exec.c
index 71a6efe5d8bd..0dd60a01f1b4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -99,7 +99,7 @@ static inline void put_binfmt(struct linux_binfmt * fmt)
  *
  * Also note that we take the address to load from from the file itself.
  */
-asmlinkage long sys_uselib(const char __user * library)
+SYSCALL_DEFINE1(uselib, const char __user *, library)
 {
 	struct file *file;
 	struct nameidata nd;

commit 506c10f26c481b7f8ef27c1c79290f68989b2e9e
Merge: e1df957670ae c59765042f53
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 11 02:42:53 2009 +0100

    Merge commit 'v2.6.29-rc1' into perfcounters/core
    
    Conflicts:
            include/linux/kernel_stat.h

commit 8cd3ac3aca3f2afe8570708066d64d893da468e8
Author: WANG Cong <wangcong@zeuux.org>
Date:   Tue Jan 6 14:42:48 2009 -0800

    fs/exec.c: make do_coredump() void
    
    No one cares do_coredump()'s return value, and also it seems that it
    is also not necessary. So make it void.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: WANG Cong <wangcong@zeuux.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6b09d6fa4f7e..71a6efe5d8bd 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1686,7 +1686,7 @@ int get_dumpable(struct mm_struct *mm)
 	return (ret >= 2) ? 2 : ret;
 }
 
-int do_coredump(long signr, int exit_code, struct pt_regs * regs)
+void do_coredump(long signr, int exit_code, struct pt_regs *regs)
 {
 	struct core_state core_state;
 	char corename[CORENAME_MAX_SIZE + 1];
@@ -1842,5 +1842,5 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	put_cred(cred);
 	coredump_finish(mm);
 fail:
-	return retval;
+	return;
 }

commit 350eaf791bebccb9ad5999351f3e328319545f03
Author: Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp>
Date:   Tue Jan 6 14:41:11 2009 -0800

    do_coredump(): check return from argv_split()
    
    do_coredump() accesses helper_argv[0] without checking helper_argv !=
    NULL.  This can happen if page allocation failed.
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6ca4e3d22a3d..6b09d6fa4f7e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1770,6 +1770,11 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 
  	if (ispipe) {
 		helper_argv = argv_split(GFP_KERNEL, corename+1, &helper_argc);
+		if (!helper_argv) {
+			printk(KERN_WARNING "%s failed to allocate memory\n",
+			       __func__);
+			goto fail_unlock;
+		}
 		/* Terminate the string before the first option */
 		delimit = strchr(corename, ' ');
 		if (delimit)

commit eaccbfa564e48c87626594511f42dc8c0ad2daae
Author: Luiz Fernando N. Capitulino <lcapitulino@mandriva.com.br>
Date:   Tue Jan 6 14:40:44 2009 -0800

    fs/exec.c:__bprm_mm_init(): clean up error handling
    
    Untangle the error unwinding in this function, saving a test of local
    variable `vma'.
    
    Signed-off-by: Luiz Fernando N. Capitulino <lcapitulino@mandriva.com.br>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9c33f542dc77..6ca4e3d22a3d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -232,13 +232,13 @@ static void flush_arg_page(struct linux_binprm *bprm, unsigned long pos,
 
 static int __bprm_mm_init(struct linux_binprm *bprm)
 {
-	int err = -ENOMEM;
+	int err;
 	struct vm_area_struct *vma = NULL;
 	struct mm_struct *mm = bprm->mm;
 
 	bprm->vma = vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
 	if (!vma)
-		goto err;
+		return -ENOMEM;
 
 	down_write(&mm->mmap_sem);
 	vma->vm_mm = mm;
@@ -251,28 +251,20 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	 */
 	vma->vm_end = STACK_TOP_MAX;
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
-
 	vma->vm_flags = VM_STACK_FLAGS;
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 	err = insert_vm_struct(mm, vma);
-	if (err) {
-		up_write(&mm->mmap_sem);
+	if (err)
 		goto err;
-	}
 
 	mm->stack_vm = mm->total_vm = 1;
 	up_write(&mm->mmap_sem);
-
 	bprm->p = vma->vm_end - sizeof(void *);
-
 	return 0;
-
 err:
-	if (vma) {
-		bprm->vma = NULL;
-		kmem_cache_free(vm_area_cachep, vma);
-	}
-
+	up_write(&mm->mmap_sem);
+	bprm->vma = NULL;
+	kmem_cache_free(vm_area_cachep, vma);
 	return err;
 }
 

commit 6110e3abbff8b785907d4db50240e63c1be726e3
Author: Eric Paris <eparis@redhat.com>
Date:   Wed Dec 17 13:53:20 2008 -0500

    sys_execve and sys_uselib do not call into fsnotify
    
    sys_execve and sys_uselib do not call into fsnotify so inotify does not get
    open events for these types of syscalls.  This patch simply makes the
    requisite fsnotify calls.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 3ef9cf9b1871..9c33f542dc77 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -51,6 +51,7 @@
 #include <linux/audit.h>
 #include <linux/tracehook.h>
 #include <linux/kmod.h>
+#include <linux/fsnotify.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -132,6 +133,8 @@ asmlinkage long sys_uselib(const char __user * library)
 	if (IS_ERR(file))
 		goto out;
 
+	fsnotify_open(file->f_path.dentry);
+
 	error = -ENOEXEC;
 	if(file->f_op) {
 		struct linux_binfmt * fmt;
@@ -684,6 +687,8 @@ struct file *open_exec(const char *name)
 	if (IS_ERR(file))
 		return file;
 
+	fsnotify_open(file->f_path.dentry);
+
 	err = deny_write_access(file);
 	if (err) {
 		fput(file);

commit 3bfacef412b4bc993a8992217e50f1245f2fd3a6
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Sat Jan 3 07:16:33 2009 +0000

    get rid of special-casing the /sbin/loader on alpha
    
    ... just make it a binfmt handler like #! one.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index dfbf7009fbe7..3ef9cf9b1871 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -57,11 +57,6 @@
 #include <asm/tlb.h>
 #include "internal.h"
 
-#ifdef __alpha__
-/* for /sbin/loader handling in search_binary_handler() */
-#include <linux/a.out.h>
-#endif
-
 int core_uses_pid;
 char core_pattern[CORENAME_MAX_SIZE] = "core";
 int suid_dumpable = 0;
@@ -1172,41 +1167,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 	unsigned int depth = bprm->recursion_depth;
 	int try,retval;
 	struct linux_binfmt *fmt;
-#ifdef __alpha__
-	/* handle /sbin/loader.. */
-	{
-	    struct exec * eh = (struct exec *) bprm->buf;
 
-	    if (!bprm->loader && eh->fh.f_magic == 0x183 &&
-		(eh->fh.f_flags & 0x3000) == 0x3000)
-	    {
-		struct file * file;
-		unsigned long loader;
-
-		allow_write_access(bprm->file);
-		fput(bprm->file);
-		bprm->file = NULL;
-
-		loader = bprm->vma->vm_end - sizeof(void *);
-
-		file = open_exec("/sbin/loader");
-		retval = PTR_ERR(file);
-		if (IS_ERR(file))
-			return retval;
-
-		/* Remember if the application is TASO.  */
-		bprm->taso = eh->ah.entry < 0x100000000UL;
-
-		bprm->file = file;
-		bprm->loader = loader;
-		retval = prepare_binprm(bprm);
-		if (retval<0)
-			return retval;
-		/* should call search_binary_handler recursively here,
-		   but it does not matter */
-	    }
-	}
-#endif
 	retval = security_bprm_check(bprm);
 	if (retval)
 		return retval;

commit cb23beb55100171646e69e248fb45f10db6e99a4
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Oct 24 09:59:29 2008 +0200

    kill vfs_permission
    
    With all the nameidata removal there's no point anymore for this helper.
    Of the three callers left two will go away with the next lookup series
    anyway.
    
    Also add proper kerneldoc to inode_permission as this is the main
    permission check routine now.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 02d2e120542d..dfbf7009fbe7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -127,7 +127,8 @@ asmlinkage long sys_uselib(const char __user * library)
 	if (nd.path.mnt->mnt_flags & MNT_NOEXEC)
 		goto exit;
 
-	error = vfs_permission(&nd, MAY_READ | MAY_EXEC | MAY_OPEN);
+	error = inode_permission(nd.path.dentry->d_inode,
+				 MAY_READ | MAY_EXEC | MAY_OPEN);
 	if (error)
 		goto exit;
 
@@ -680,7 +681,7 @@ struct file *open_exec(const char *name)
 	if (nd.path.mnt->mnt_flags & MNT_NOEXEC)
 		goto out_path_put;
 
-	err = vfs_permission(&nd, MAY_EXEC | MAY_OPEN);
+	err = inode_permission(nd.path.dentry->d_inode, MAY_EXEC | MAY_OPEN);
 	if (err)
 		goto out_path_put;
 

commit bb758e9637e5ddcff84a97177415499ae1fed498
Merge: 5f34fe1cfc1b 32e8d18683ad
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 30 16:16:21 2008 -0800

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      hrtimers: fix warning in kernel/hrtimer.c
      x86: make sure we really have an hpet mapping before using it
      x86: enable HPET on Fujitsu u9200
      linux/timex.h: cleanup for userspace
      posix-timers: simplify de_thread()->exit_itimers() path
      posix-timers: check ->it_signal instead of ->it_pid to validate the timer
      posix-timers: use "struct pid*" instead of "struct task_struct*"
      nohz: suppress needless timer reprogramming
      clocksource, acpi_pm.c: put acpi_pm_read_slow() under CONFIG_PCI
      nohz: no softirq pending warnings for offline cpus
      hrtimer: removing all ur callback modes, fix
      hrtimer: removing all ur callback modes, fix hotplug
      hrtimer: removing all ur callback modes
      x86: correct link to HPET timer specification
      rtc-cmos: export second NVRAM bank
    
    Fixed up conflicts in sound/drivers/pcsp/pcsp.c and sound/core/hrtimer.c
    manually.

commit e1df957670aef74ffd9a4ad93e6d2c90bf6b4845
Merge: 2b583d8bc8d7 3c92ec8ae91e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Dec 29 09:45:15 2008 +0100

    Merge branch 'linus' into perfcounters/core
    
    Conflicts:
            fs/exec.c
            include/linux/init_task.h
    
    Simple context conflicts.

commit cbacc2c7f066a1e01b33b0e27ae5efbf534bc2db
Merge: 4a6908a3a050 74192246910f
Author: James Morris <jmorris@namei.org>
Date:   Thu Dec 25 11:40:09 2008 +1100

    Merge branch 'next' into for-linus

commit f65cb45cba63f249458b669aa67069eabc37b2f5
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Dec 16 13:40:44 2008 +0100

    perfcounters: flush on setuid exec
    
    Pavel Machek pointed out that performance counters should be flushed
    when crossing protection domains on setuid execution.
    
    Reported-by: Pavel Machek <pavel@suse.cz>
    Acked-by: Pavel Machek <pavel@suse.cz>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/exec.c b/fs/exec.c
index ec5df9a38313..d5165d899a49 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -33,6 +33,7 @@
 #include <linux/string.h>
 #include <linux/init.h>
 #include <linux/pagemap.h>
+#include <linux/perf_counter.h>
 #include <linux/highmem.h>
 #include <linux/spinlock.h>
 #include <linux/key.h>
@@ -1017,6 +1018,13 @@ int flush_old_exec(struct linux_binprm * bprm)
 		set_dumpable(current->mm, suid_dumpable);
 	}
 
+	/*
+	 * Flush performance counters when crossing a
+	 * security domain:
+	 */
+	if (!get_dumpable(current->mm))
+		perf_counter_exit_task(current);
+
 	/* An exec changes our domain. We are no longer part of the thread
 	   group */
 

commit 8187926bdae98648db24db3391c4efd21ec669b1
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Dec 1 14:18:16 2008 -0800

    posix-timers: simplify de_thread()->exit_itimers() path
    
    Impact: simplify code
    
    de_thread() postpones release_task(leader) until after exit_itimers().
    This was needed because !SIGEV_THREAD_ID timers could use ->group_leader
    without get_task_struct(). With the recent changes we can release the
    leader earlier and simplify the code.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/fs/exec.c b/fs/exec.c
index ec5df9a38313..b4e5b8a9216a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -772,7 +772,6 @@ static int de_thread(struct task_struct *tsk)
 	struct signal_struct *sig = tsk->signal;
 	struct sighand_struct *oldsighand = tsk->sighand;
 	spinlock_t *lock = &oldsighand->siglock;
-	struct task_struct *leader = NULL;
 	int count;
 
 	if (thread_group_empty(tsk))
@@ -810,7 +809,7 @@ static int de_thread(struct task_struct *tsk)
 	 * and to assume its PID:
 	 */
 	if (!thread_group_leader(tsk)) {
-		leader = tsk->group_leader;
+		struct task_struct *leader = tsk->group_leader;
 
 		sig->notify_count = -1;	/* for exit_notify() */
 		for (;;) {
@@ -862,8 +861,9 @@ static int de_thread(struct task_struct *tsk)
 
 		BUG_ON(leader->exit_state != EXIT_ZOMBIE);
 		leader->exit_state = EXIT_DEAD;
-
 		write_unlock_irq(&tasklist_lock);
+
+		release_task(leader);
 	}
 
 	sig->group_exit_task = NULL;
@@ -872,8 +872,6 @@ static int de_thread(struct task_struct *tsk)
 no_thread_group:
 	exit_itimers(sig);
 	flush_itimer_signals();
-	if (leader)
-		release_task(leader);
 
 	if (atomic_read(&oldsighand->count) != 1) {
 		struct sighand_struct *newsighand;

commit 85f334666a771680472722eee43ae0fc8730a619
Author: Roland McGrath <roland@redhat.com>
Date:   Tue Dec 9 19:36:38 2008 -0800

    tracehook: exec double-reporting fix
    
    The patch 6341c39 "tracehook: exec" introduced a small regression in
    2.6.27 regarding binfmt_misc exec event reporting.  Since the reporting
    is now done in the common search_binary_handler() function, an exec
    of a misc binary will result in two (or possibly multiple) exec events
    being reported, instead of just a single one, because the misc handler
    contains a recursive call to search_binary_handler.
    
    To add to the confusion, if PTRACE_O_TRACEEXEC is not active, the multiple
    SIGTRAP signals will in fact cause only a single ptrace intercept, as the
    signals are not queued.  However, if PTRACE_O_TRACEEXEC is on, the debugger
    will actually see multiple ptrace intercepts (PTRACE_EVENT_EXEC).
    
    The test program included below demonstrates the problem.
    
    This change fixes the bug by calling tracehook_report_exec() only in the
    outermost search_binary_handler() call (bprm->recursion_depth == 0).
    
    The additional change to restore bprm->recursion_depth after each binfmt
    load_binary call is actually superfluous for this bug, since we test the
    value saved on entry to search_binary_handler().  But it keeps the use of
    of the depth count to its most obvious expected meaning.  Depending on what
    binfmt handlers do in certain cases, there could have been false-positive
    tests for recursion limits before this change.
    
        /* Test program using PTRACE_O_TRACEEXEC.
           This forks and exec's the first argument with the rest of the arguments,
           while ptrace'ing.  It expects to see one PTRACE_EVENT_EXEC stop and
           then a successful exit, with no other signals or events in between.
    
           Test for kernel doing two PTRACE_EVENT_EXEC stops for a binfmt_misc exec:
    
           $ gcc -g traceexec.c -o traceexec
           $ sudo sh -c 'echo :test:M::foobar::/bin/cat: > /proc/sys/fs/binfmt_misc/register'
           $ echo 'foobar test' > ./foobar
           $ chmod +x ./foobar
           $ ./traceexec ./foobar; echo $?
           ==> good <==
           foobar test
           0
           $
           ==> bad <==
           foobar test
           unexpected status 0x4057f != 0
           3
           $
    
        */
    
        #include <stdio.h>
        #include <sys/types.h>
        #include <sys/wait.h>
        #include <sys/ptrace.h>
        #include <unistd.h>
        #include <signal.h>
        #include <stdlib.h>
    
        static void
        wait_for (pid_t child, int expect)
        {
          int status;
          pid_t p = wait (&status);
          if (p != child)
            {
              perror ("wait");
              exit (2);
            }
          if (status != expect)
            {
              fprintf (stderr, "unexpected status %#x != %#x\n", status, expect);
              exit (3);
            }
        }
    
        int
        main (int argc, char **argv)
        {
          pid_t child = fork ();
    
          if (child < 0)
            {
              perror ("fork");
              return 127;
            }
          else if (child == 0)
            {
              ptrace (PTRACE_TRACEME);
              raise (SIGUSR1);
              execv (argv[1], &argv[1]);
              perror ("execve");
              _exit (127);
            }
    
          wait_for (child, W_STOPCODE (SIGUSR1));
    
          if (ptrace (PTRACE_SETOPTIONS, child,
                      0L, (void *) (long) PTRACE_O_TRACEEXEC) != 0)
            {
              perror ("PTRACE_SETOPTIONS");
              return 4;
            }
    
          if (ptrace (PTRACE_CONT, child, 0L, 0L) != 0)
            {
              perror ("PTRACE_CONT");
              return 5;
            }
    
          wait_for (child, W_STOPCODE (SIGTRAP | (PTRACE_EVENT_EXEC << 8)));
    
          if (ptrace (PTRACE_CONT, child, 0L, 0L) != 0)
            {
              perror ("PTRACE_CONT");
              return 6;
            }
    
          wait_for (child, W_EXITCODE (0, 0));
    
          return 0;
        }
    
    Reported-by: Arnd Bergmann <arnd@arndb.de>
    CC: Ulrich Weigand <ulrich.weigand@de.ibm.com>
    Signed-off-by: Roland McGrath <roland@redhat.com>

diff --git a/fs/exec.c b/fs/exec.c
index 4e834f16d9da..ec5df9a38313 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1159,6 +1159,7 @@ EXPORT_SYMBOL(remove_arg_zero);
  */
 int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 {
+	unsigned int depth = bprm->recursion_depth;
 	int try,retval;
 	struct linux_binfmt *fmt;
 #ifdef __alpha__
@@ -1219,8 +1220,15 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 				continue;
 			read_unlock(&binfmt_lock);
 			retval = fn(bprm, regs);
+			/*
+			 * Restore the depth counter to its starting value
+			 * in this call, so we don't have to rely on every
+			 * load_binary function to restore it on return.
+			 */
+			bprm->recursion_depth = depth;
 			if (retval >= 0) {
-				tracehook_report_exec(fmt, bprm, regs);
+				if (depth == 0)
+					tracehook_report_exec(fmt, bprm, regs);
 				put_binfmt(fmt);
 				allow_write_access(bprm->file);
 				if (bprm->file)

commit a6f76f23d297f70e2a6b3ec607f7aeeea9e37e8d
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:24 2008 +1100

    CRED: Make execve() take advantage of copy-on-write credentials
    
    Make execve() take advantage of copy-on-write credentials, allowing it to set
    up the credentials in advance, and then commit the whole lot after the point
    of no return.
    
    This patch and the preceding patches have been tested with the LTP SELinux
    testsuite.
    
    This patch makes several logical sets of alteration:
    
     (1) execve().
    
         The credential bits from struct linux_binprm are, for the most part,
         replaced with a single credentials pointer (bprm->cred).  This means that
         all the creds can be calculated in advance and then applied at the point
         of no return with no possibility of failure.
    
         I would like to replace bprm->cap_effective with:
    
            cap_isclear(bprm->cap_effective)
    
         but this seems impossible due to special behaviour for processes of pid 1
         (they always retain their parent's capability masks where normally they'd
         be changed - see cap_bprm_set_creds()).
    
         The following sequence of events now happens:
    
         (a) At the start of do_execve, the current task's cred_exec_mutex is
             locked to prevent PTRACE_ATTACH from obsoleting the calculation of
             creds that we make.
    
         (a) prepare_exec_creds() is then called to make a copy of the current
             task's credentials and prepare it.  This copy is then assigned to
             bprm->cred.
    
             This renders security_bprm_alloc() and security_bprm_free()
             unnecessary, and so they've been removed.
    
         (b) The determination of unsafe execution is now performed immediately
             after (a) rather than later on in the code.  The result is stored in
             bprm->unsafe for future reference.
    
         (c) prepare_binprm() is called, possibly multiple times.
    
             (i) This applies the result of set[ug]id binaries to the new creds
                 attached to bprm->cred.  Personality bit clearance is recorded,
                 but now deferred on the basis that the exec procedure may yet
                 fail.
    
             (ii) This then calls the new security_bprm_set_creds().  This should
                 calculate the new LSM and capability credentials into *bprm->cred.
    
                 This folds together security_bprm_set() and parts of
                 security_bprm_apply_creds() (these two have been removed).
                 Anything that might fail must be done at this point.
    
             (iii) bprm->cred_prepared is set to 1.
    
                 bprm->cred_prepared is 0 on the first pass of the security
                 calculations, and 1 on all subsequent passes.  This allows SELinux
                 in (ii) to base its calculations only on the initial script and
                 not on the interpreter.
    
         (d) flush_old_exec() is called to commit the task to execution.  This
             performs the following steps with regard to credentials:
    
             (i) Clear pdeath_signal and set dumpable on certain circumstances that
                 may not be covered by commit_creds().
    
             (ii) Clear any bits in current->personality that were deferred from
                 (c.i).
    
         (e) install_exec_creds() [compute_creds() as was] is called to install the
             new credentials.  This performs the following steps with regard to
             credentials:
    
             (i) Calls security_bprm_committing_creds() to apply any security
                 requirements, such as flushing unauthorised files in SELinux, that
                 must be done before the credentials are changed.
    
                 This is made up of bits of security_bprm_apply_creds() and
                 security_bprm_post_apply_creds(), both of which have been removed.
                 This function is not allowed to fail; anything that might fail
                 must have been done in (c.ii).
    
             (ii) Calls commit_creds() to apply the new credentials in a single
                 assignment (more or less).  Possibly pdeath_signal and dumpable
                 should be part of struct creds.
    
             (iii) Unlocks the task's cred_replace_mutex, thus allowing
                 PTRACE_ATTACH to take place.
    
             (iv) Clears The bprm->cred pointer as the credentials it was holding
                 are now immutable.
    
             (v) Calls security_bprm_committed_creds() to apply any security
                 alterations that must be done after the creds have been changed.
                 SELinux uses this to flush signals and signal handlers.
    
         (f) If an error occurs before (d.i), bprm_free() will call abort_creds()
             to destroy the proposed new credentials and will then unlock
             cred_replace_mutex.  No changes to the credentials will have been
             made.
    
     (2) LSM interface.
    
         A number of functions have been changed, added or removed:
    
         (*) security_bprm_alloc(), ->bprm_alloc_security()
         (*) security_bprm_free(), ->bprm_free_security()
    
             Removed in favour of preparing new credentials and modifying those.
    
         (*) security_bprm_apply_creds(), ->bprm_apply_creds()
         (*) security_bprm_post_apply_creds(), ->bprm_post_apply_creds()
    
             Removed; split between security_bprm_set_creds(),
             security_bprm_committing_creds() and security_bprm_committed_creds().
    
         (*) security_bprm_set(), ->bprm_set_security()
    
             Removed; folded into security_bprm_set_creds().
    
         (*) security_bprm_set_creds(), ->bprm_set_creds()
    
             New.  The new credentials in bprm->creds should be checked and set up
             as appropriate.  bprm->cred_prepared is 0 on the first call, 1 on the
             second and subsequent calls.
    
         (*) security_bprm_committing_creds(), ->bprm_committing_creds()
         (*) security_bprm_committed_creds(), ->bprm_committed_creds()
    
             New.  Apply the security effects of the new credentials.  This
             includes closing unauthorised files in SELinux.  This function may not
             fail.  When the former is called, the creds haven't yet been applied
             to the process; when the latter is called, they have.
    
             The former may access bprm->cred, the latter may not.
    
     (3) SELinux.
    
         SELinux has a number of changes, in addition to those to support the LSM
         interface changes mentioned above:
    
         (a) The bprm_security_struct struct has been removed in favour of using
             the credentials-under-construction approach.
    
         (c) flush_unauthorized_files() now takes a cred pointer and passes it on
             to inode_has_perm(), file_has_perm() and dentry_open().
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9bd3559ddece..32f13e299417 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -55,6 +55,7 @@
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlb.h>
+#include "internal.h"
 
 #ifdef __alpha__
 /* for /sbin/loader handling in search_binary_handler() */
@@ -1007,15 +1008,17 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 */
 	current->mm->task_size = TASK_SIZE;
 
-	if (bprm->e_uid != current_euid() ||
-	    bprm->e_gid != current_egid()) {
-		set_dumpable(current->mm, suid_dumpable);
+	/* install the new credentials */
+	if (bprm->cred->uid != current_euid() ||
+	    bprm->cred->gid != current_egid()) {
 		current->pdeath_signal = 0;
 	} else if (file_permission(bprm->file, MAY_READ) ||
-			(bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)) {
+		   bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP) {
 		set_dumpable(current->mm, suid_dumpable);
 	}
 
+	current->personality &= ~bprm->per_clear;
+
 	/* An exec changes our domain. We are no longer part of the thread
 	   group */
 
@@ -1032,13 +1035,50 @@ int flush_old_exec(struct linux_binprm * bprm)
 
 EXPORT_SYMBOL(flush_old_exec);
 
+/*
+ * install the new credentials for this executable
+ */
+void install_exec_creds(struct linux_binprm *bprm)
+{
+	security_bprm_committing_creds(bprm);
+
+	commit_creds(bprm->cred);
+	bprm->cred = NULL;
+
+	/* cred_exec_mutex must be held at least to this point to prevent
+	 * ptrace_attach() from altering our determination of the task's
+	 * credentials; any time after this it may be unlocked */
+
+	security_bprm_committed_creds(bprm);
+}
+EXPORT_SYMBOL(install_exec_creds);
+
+/*
+ * determine how safe it is to execute the proposed program
+ * - the caller must hold current->cred_exec_mutex to protect against
+ *   PTRACE_ATTACH
+ */
+void check_unsafe_exec(struct linux_binprm *bprm)
+{
+	struct task_struct *p = current;
+
+	bprm->unsafe = tracehook_unsafe_exec(p);
+
+	if (atomic_read(&p->fs->count) > 1 ||
+	    atomic_read(&p->files->count) > 1 ||
+	    atomic_read(&p->sighand->count) > 1)
+		bprm->unsafe |= LSM_UNSAFE_SHARE;
+}
+
 /* 
  * Fill the binprm structure from the inode. 
  * Check permissions, then read the first 128 (BINPRM_BUF_SIZE) bytes
+ *
+ * This may be called multiple times for binary chains (scripts for example).
  */
 int prepare_binprm(struct linux_binprm *bprm)
 {
-	int mode;
+	umode_t mode;
 	struct inode * inode = bprm->file->f_path.dentry->d_inode;
 	int retval;
 
@@ -1046,14 +1086,15 @@ int prepare_binprm(struct linux_binprm *bprm)
 	if (bprm->file->f_op == NULL)
 		return -EACCES;
 
-	bprm->e_uid = current_euid();
-	bprm->e_gid = current_egid();
+	/* clear any previous set[ug]id data from a previous binary */
+	bprm->cred->euid = current_euid();
+	bprm->cred->egid = current_egid();
 
-	if(!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID)) {
+	if (!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID)) {
 		/* Set-uid? */
 		if (mode & S_ISUID) {
-			current->personality &= ~PER_CLEAR_ON_SETID;
-			bprm->e_uid = inode->i_uid;
+			bprm->per_clear |= PER_CLEAR_ON_SETID;
+			bprm->cred->euid = inode->i_uid;
 		}
 
 		/* Set-gid? */
@@ -1063,50 +1104,23 @@ int prepare_binprm(struct linux_binprm *bprm)
 		 * executable.
 		 */
 		if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP)) {
-			current->personality &= ~PER_CLEAR_ON_SETID;
-			bprm->e_gid = inode->i_gid;
+			bprm->per_clear |= PER_CLEAR_ON_SETID;
+			bprm->cred->egid = inode->i_gid;
 		}
 	}
 
 	/* fill in binprm security blob */
-	retval = security_bprm_set(bprm);
+	retval = security_bprm_set_creds(bprm);
 	if (retval)
 		return retval;
+	bprm->cred_prepared = 1;
 
-	memset(bprm->buf,0,BINPRM_BUF_SIZE);
-	return kernel_read(bprm->file,0,bprm->buf,BINPRM_BUF_SIZE);
+	memset(bprm->buf, 0, BINPRM_BUF_SIZE);
+	return kernel_read(bprm->file, 0, bprm->buf, BINPRM_BUF_SIZE);
 }
 
 EXPORT_SYMBOL(prepare_binprm);
 
-static int unsafe_exec(struct task_struct *p)
-{
-	int unsafe = tracehook_unsafe_exec(p);
-
-	if (atomic_read(&p->fs->count) > 1 ||
-	    atomic_read(&p->files->count) > 1 ||
-	    atomic_read(&p->sighand->count) > 1)
-		unsafe |= LSM_UNSAFE_SHARE;
-
-	return unsafe;
-}
-
-void compute_creds(struct linux_binprm *bprm)
-{
-	int unsafe;
-
-	if (bprm->e_uid != current_uid())
-		current->pdeath_signal = 0;
-	exec_keys(current);
-
-	task_lock(current);
-	unsafe = unsafe_exec(current);
-	security_bprm_apply_creds(bprm, unsafe);
-	task_unlock(current);
-	security_bprm_post_apply_creds(bprm);
-}
-EXPORT_SYMBOL(compute_creds);
-
 /*
  * Arguments are '\0' separated strings found at the location bprm->p
  * points to; chop off the first by relocating brpm->p to right after
@@ -1259,6 +1273,8 @@ EXPORT_SYMBOL(search_binary_handler);
 void free_bprm(struct linux_binprm *bprm)
 {
 	free_arg_pages(bprm);
+	if (bprm->cred)
+		abort_creds(bprm->cred);
 	kfree(bprm);
 }
 
@@ -1284,10 +1300,20 @@ int do_execve(char * filename,
 	if (!bprm)
 		goto out_files;
 
+	retval = mutex_lock_interruptible(&current->cred_exec_mutex);
+	if (retval < 0)
+		goto out_free;
+
+	retval = -ENOMEM;
+	bprm->cred = prepare_exec_creds();
+	if (!bprm->cred)
+		goto out_unlock;
+	check_unsafe_exec(bprm);
+
 	file = open_exec(filename);
 	retval = PTR_ERR(file);
 	if (IS_ERR(file))
-		goto out_kfree;
+		goto out_unlock;
 
 	sched_exec();
 
@@ -1301,14 +1327,10 @@ int do_execve(char * filename,
 
 	bprm->argc = count(argv, MAX_ARG_STRINGS);
 	if ((retval = bprm->argc) < 0)
-		goto out_mm;
+		goto out;
 
 	bprm->envc = count(envp, MAX_ARG_STRINGS);
 	if ((retval = bprm->envc) < 0)
-		goto out_mm;
-
-	retval = security_bprm_alloc(bprm);
-	if (retval)
 		goto out;
 
 	retval = prepare_binprm(bprm);
@@ -1330,21 +1352,18 @@ int do_execve(char * filename,
 
 	current->flags &= ~PF_KTHREAD;
 	retval = search_binary_handler(bprm,regs);
-	if (retval >= 0) {
-		/* execve success */
-		security_bprm_free(bprm);
-		acct_update_integrals(current);
-		free_bprm(bprm);
-		if (displaced)
-			put_files_struct(displaced);
-		return retval;
-	}
+	if (retval < 0)
+		goto out;
 
-out:
-	if (bprm->security)
-		security_bprm_free(bprm);
+	/* execve succeeded */
+	mutex_unlock(&current->cred_exec_mutex);
+	acct_update_integrals(current);
+	free_bprm(bprm);
+	if (displaced)
+		put_files_struct(displaced);
+	return retval;
 
-out_mm:
+out:
 	if (bprm->mm)
 		mmput (bprm->mm);
 
@@ -1353,7 +1372,11 @@ int do_execve(char * filename,
 		allow_write_access(bprm->file);
 		fput(bprm->file);
 	}
-out_kfree:
+
+out_unlock:
+	mutex_unlock(&current->cred_exec_mutex);
+
+out_free:
 	free_bprm(bprm);
 
 out_files:

commit d84f4f992cbd76e8f39c488cf0c5d123843923b1
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:23 2008 +1100

    CRED: Inaugurate COW credentials
    
    Inaugurate copy-on-write credentials management.  This uses RCU to manage the
    credentials pointer in the task_struct with respect to accesses by other tasks.
    A process may only modify its own credentials, and so does not need locking to
    access or modify its own credentials.
    
    A mutex (cred_replace_mutex) is added to the task_struct to control the effect
    of PTRACE_ATTACHED on credential calculations, particularly with respect to
    execve().
    
    With this patch, the contents of an active credentials struct may not be
    changed directly; rather a new set of credentials must be prepared, modified
    and committed using something like the following sequence of events:
    
            struct cred *new = prepare_creds();
            int ret = blah(new);
            if (ret < 0) {
                    abort_creds(new);
                    return ret;
            }
            return commit_creds(new);
    
    There are some exceptions to this rule: the keyrings pointed to by the active
    credentials may be instantiated - keyrings violate the COW rule as managing
    COW keyrings is tricky, given that it is possible for a task to directly alter
    the keys in a keyring in use by another task.
    
    To help enforce this, various pointers to sets of credentials, such as those in
    the task_struct, are declared const.  The purpose of this is compile-time
    discouragement of altering credentials through those pointers.  Once a set of
    credentials has been made public through one of these pointers, it may not be
    modified, except under special circumstances:
    
      (1) Its reference count may incremented and decremented.
    
      (2) The keyrings to which it points may be modified, but not replaced.
    
    The only safe way to modify anything else is to create a replacement and commit
    using the functions described in Documentation/credentials.txt (which will be
    added by a later patch).
    
    This patch and the preceding patches have been tested with the LTP SELinux
    testsuite.
    
    This patch makes several logical sets of alteration:
    
     (1) execve().
    
         This now prepares and commits credentials in various places in the
         security code rather than altering the current creds directly.
    
     (2) Temporary credential overrides.
    
         do_coredump() and sys_faccessat() now prepare their own credentials and
         temporarily override the ones currently on the acting thread, whilst
         preventing interference from other threads by holding cred_replace_mutex
         on the thread being dumped.
    
         This will be replaced in a future patch by something that hands down the
         credentials directly to the functions being called, rather than altering
         the task's objective credentials.
    
     (3) LSM interface.
    
         A number of functions have been changed, added or removed:
    
         (*) security_capset_check(), ->capset_check()
         (*) security_capset_set(), ->capset_set()
    
             Removed in favour of security_capset().
    
         (*) security_capset(), ->capset()
    
             New.  This is passed a pointer to the new creds, a pointer to the old
             creds and the proposed capability sets.  It should fill in the new
             creds or return an error.  All pointers, barring the pointer to the
             new creds, are now const.
    
         (*) security_bprm_apply_creds(), ->bprm_apply_creds()
    
             Changed; now returns a value, which will cause the process to be
             killed if it's an error.
    
         (*) security_task_alloc(), ->task_alloc_security()
    
             Removed in favour of security_prepare_creds().
    
         (*) security_cred_free(), ->cred_free()
    
             New.  Free security data attached to cred->security.
    
         (*) security_prepare_creds(), ->cred_prepare()
    
             New. Duplicate any security data attached to cred->security.
    
         (*) security_commit_creds(), ->cred_commit()
    
             New. Apply any security effects for the upcoming installation of new
             security by commit_creds().
    
         (*) security_task_post_setuid(), ->task_post_setuid()
    
             Removed in favour of security_task_fix_setuid().
    
         (*) security_task_fix_setuid(), ->task_fix_setuid()
    
             Fix up the proposed new credentials for setuid().  This is used by
             cap_set_fix_setuid() to implicitly adjust capabilities in line with
             setuid() changes.  Changes are made to the new credentials, rather
             than the task itself as in security_task_post_setuid().
    
         (*) security_task_reparent_to_init(), ->task_reparent_to_init()
    
             Removed.  Instead the task being reparented to init is referred
             directly to init's credentials.
    
             NOTE!  This results in the loss of some state: SELinux's osid no
             longer records the sid of the thread that forked it.
    
         (*) security_key_alloc(), ->key_alloc()
         (*) security_key_permission(), ->key_permission()
    
             Changed.  These now take cred pointers rather than task pointers to
             refer to the security context.
    
     (4) sys_capset().
    
         This has been simplified and uses less locking.  The LSM functions it
         calls have been merged.
    
     (5) reparent_to_kthreadd().
    
         This gives the current thread the same credentials as init by simply using
         commit_thread() to point that way.
    
     (6) __sigqueue_alloc() and switch_uid()
    
         __sigqueue_alloc() can't stop the target task from changing its creds
         beneath it, so this function gets a reference to the currently applicable
         user_struct which it then passes into the sigqueue struct it returns if
         successful.
    
         switch_uid() is now called from commit_creds(), and possibly should be
         folded into that.  commit_creds() should take care of protecting
         __sigqueue_alloc().
    
     (7) [sg]et[ug]id() and co and [sg]et_current_groups.
    
         The set functions now all use prepare_creds(), commit_creds() and
         abort_creds() to build and check a new set of credentials before applying
         it.
    
         security_task_set[ug]id() is called inside the prepared section.  This
         guarantees that nothing else will affect the creds until we've finished.
    
         The calling of set_dumpable() has been moved into commit_creds().
    
         Much of the functionality of set_user() has been moved into
         commit_creds().
    
         The get functions all simply access the data directly.
    
     (8) security_task_prctl() and cap_task_prctl().
    
         security_task_prctl() has been modified to return -ENOSYS if it doesn't
         want to handle a function, or otherwise return the return value directly
         rather than through an argument.
    
         Additionally, cap_task_prctl() now prepares a new set of credentials, even
         if it doesn't end up using it.
    
     (9) Keyrings.
    
         A number of changes have been made to the keyrings code:
    
         (a) switch_uid_keyring(), copy_keys(), exit_keys() and suid_keys() have
             all been dropped and built in to the credentials functions directly.
             They may want separating out again later.
    
         (b) key_alloc() and search_process_keyrings() now take a cred pointer
             rather than a task pointer to specify the security context.
    
         (c) copy_creds() gives a new thread within the same thread group a new
             thread keyring if its parent had one, otherwise it discards the thread
             keyring.
    
         (d) The authorisation key now points directly to the credentials to extend
             the search into rather pointing to the task that carries them.
    
         (e) Installing thread, process or session keyrings causes a new set of
             credentials to be created, even though it's not strictly necessary for
             process or session keyrings (they're shared).
    
    (10) Usermode helper.
    
         The usermode helper code now carries a cred struct pointer in its
         subprocess_info struct instead of a new session keyring pointer.  This set
         of credentials is derived from init_cred and installed on the new process
         after it has been cloned.
    
         call_usermodehelper_setup() allocates the new credentials and
         call_usermodehelper_freeinfo() discards them if they haven't been used.  A
         special cred function (prepare_usermodeinfo_creds()) is provided
         specifically for call_usermodehelper_setup() to call.
    
         call_usermodehelper_setkeys() adjusts the credentials to sport the
         supplied keyring as the new session keyring.
    
    (11) SELinux.
    
         SELinux has a number of changes, in addition to those to support the LSM
         interface changes mentioned above:
    
         (a) selinux_setprocattr() no longer does its check for whether the
             current ptracer can access processes with the new SID inside the lock
             that covers getting the ptracer's SID.  Whilst this lock ensures that
             the check is done with the ptracer pinned, the result is only valid
             until the lock is released, so there's no point doing it inside the
             lock.
    
    (12) is_single_threaded().
    
         This function has been extracted from selinux_setprocattr() and put into
         a file of its own in the lib/ directory as join_session_keyring() now
         wants to use it too.
    
         The code in SELinux just checked to see whether a task shared mm_structs
         with other tasks (CLONE_VM), but that isn't good enough.  We really want
         to know if they're part of the same thread group (CLONE_THREAD).
    
    (13) nfsd.
    
         The NFS server daemon now has to use the COW credentials to set the
         credentials it is going to use.  It really needs to pass the credentials
         down to the functions it calls, but it can't do that until other patches
         in this series have been applied.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: James Morris <jmorris@namei.org>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index a5330e1a2216..9bd3559ddece 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1007,13 +1007,12 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 */
 	current->mm->task_size = TASK_SIZE;
 
-	if (bprm->e_uid != current_euid() || bprm->e_gid != current_egid()) {
-		suid_keys(current);
+	if (bprm->e_uid != current_euid() ||
+	    bprm->e_gid != current_egid()) {
 		set_dumpable(current->mm, suid_dumpable);
 		current->pdeath_signal = 0;
 	} else if (file_permission(bprm->file, MAY_READ) ||
 			(bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)) {
-		suid_keys(current);
 		set_dumpable(current->mm, suid_dumpable);
 	}
 
@@ -1096,10 +1095,8 @@ void compute_creds(struct linux_binprm *bprm)
 {
 	int unsafe;
 
-	if (bprm->e_uid != current_uid()) {
-		suid_keys(current);
+	if (bprm->e_uid != current_uid())
 		current->pdeath_signal = 0;
-	}
 	exec_keys(current);
 
 	task_lock(current);
@@ -1709,8 +1706,9 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	struct linux_binfmt * binfmt;
 	struct inode * inode;
 	struct file * file;
+	const struct cred *old_cred;
+	struct cred *cred;
 	int retval = 0;
-	int fsuid = current_fsuid();
 	int flag = 0;
 	int ispipe = 0;
 	unsigned long core_limit = current->signal->rlim[RLIMIT_CORE].rlim_cur;
@@ -1723,12 +1721,20 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	binfmt = current->binfmt;
 	if (!binfmt || !binfmt->core_dump)
 		goto fail;
+
+	cred = prepare_creds();
+	if (!cred) {
+		retval = -ENOMEM;
+		goto fail;
+	}
+
 	down_write(&mm->mmap_sem);
 	/*
 	 * If another thread got here first, or we are not dumpable, bail out.
 	 */
 	if (mm->core_state || !get_dumpable(mm)) {
 		up_write(&mm->mmap_sem);
+		put_cred(cred);
 		goto fail;
 	}
 
@@ -1739,12 +1745,16 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 */
 	if (get_dumpable(mm) == 2) {	/* Setuid core dump mode */
 		flag = O_EXCL;		/* Stop rewrite attacks */
-		current->cred->fsuid = 0;	/* Dump root private */
+		cred->fsuid = 0;	/* Dump root private */
 	}
 
 	retval = coredump_wait(exit_code, &core_state);
-	if (retval < 0)
+	if (retval < 0) {
+		put_cred(cred);
 		goto fail;
+	}
+
+	old_cred = override_creds(cred);
 
 	/*
 	 * Clear any false indication of pending signals that might
@@ -1835,7 +1845,8 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	if (helper_argv)
 		argv_free(helper_argv);
 
-	current->cred->fsuid = fsuid;
+	revert_creds(old_cred);
+	put_cred(cred);
 	coredump_finish(mm);
 fail:
 	return retval;

commit 86a264abe542cfececb4df129bc45a0338d8cdb9
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:18 2008 +1100

    CRED: Wrap current->cred and a few other accessors
    
    Wrap current->cred and a few other accessors to hide their actual
    implementation.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index 31149e430a89..a5330e1a2216 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1388,6 +1388,7 @@ EXPORT_SYMBOL(set_binfmt);
  */
 static int format_corename(char *corename, long signr)
 {
+	const struct cred *cred = current_cred();
 	const char *pat_ptr = core_pattern;
 	int ispipe = (*pat_ptr == '|');
 	char *out_ptr = corename;
@@ -1424,7 +1425,7 @@ static int format_corename(char *corename, long signr)
 			/* uid */
 			case 'u':
 				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%d", current_uid());
+					      "%d", cred->uid);
 				if (rc > out_end - out_ptr)
 					goto out;
 				out_ptr += rc;
@@ -1432,7 +1433,7 @@ static int format_corename(char *corename, long signr)
 			/* gid */
 			case 'g':
 				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%d", current_gid());
+					      "%d", cred->gid);
 				if (rc > out_end - out_ptr)
 					goto out;
 				out_ptr += rc;

commit b6dff3ec5e116e3af6f537d4caedcad6b9e5082a
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:16 2008 +1100

    CRED: Separate task security context from task_struct
    
    Separate the task security context from task_struct.  At this point, the
    security data is temporarily embedded in the task_struct with two pointers
    pointing to it.
    
    Note that the Alpha arch is altered as it refers to (E)UID and (E)GID in
    entry.S via asm-offsets.
    
    With comment fixes Signed-off-by: Marc Dionne <marc.c.dionne@gmail.com>
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index 604834f3b208..31149e430a89 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1738,7 +1738,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 */
 	if (get_dumpable(mm) == 2) {	/* Setuid core dump mode */
 		flag = O_EXCL;		/* Stop rewrite attacks */
-		current->fsuid = 0;	/* Dump root private */
+		current->cred->fsuid = 0;	/* Dump root private */
 	}
 
 	retval = coredump_wait(exit_code, &core_state);
@@ -1834,7 +1834,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	if (helper_argv)
 		argv_free(helper_argv);
 
-	current->fsuid = fsuid;
+	current->cred->fsuid = fsuid;
 	coredump_finish(mm);
 fail:
 	return retval;

commit da9592edebceeba1b9301beafe80ec8b9c2db0ce
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:05 2008 +1100

    CRED: Wrap task credential accesses in the filesystem subsystem
    
    Wrap access to task credentials so that they can be separated more easily from
    the task_struct during the introduction of COW creds.
    
    Change most current->(|e|s|fs)[ug]id to current_(|e|s|fs)[ug]id().
    
    Change some task->e?[ug]id to task_e?[ug]id().  In some places it makes more
    sense to use RCU directly rather than a convenient wrapper; these will be
    addressed by later patches.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4e834f16d9da..604834f3b208 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -980,7 +980,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	/* This is the point of no return */
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
-	if (current->euid == current->uid && current->egid == current->gid)
+	if (current_euid() == current_uid() && current_egid() == current_gid())
 		set_dumpable(current->mm, 1);
 	else
 		set_dumpable(current->mm, suid_dumpable);
@@ -1007,7 +1007,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 */
 	current->mm->task_size = TASK_SIZE;
 
-	if (bprm->e_uid != current->euid || bprm->e_gid != current->egid) {
+	if (bprm->e_uid != current_euid() || bprm->e_gid != current_egid()) {
 		suid_keys(current);
 		set_dumpable(current->mm, suid_dumpable);
 		current->pdeath_signal = 0;
@@ -1047,8 +1047,8 @@ int prepare_binprm(struct linux_binprm *bprm)
 	if (bprm->file->f_op == NULL)
 		return -EACCES;
 
-	bprm->e_uid = current->euid;
-	bprm->e_gid = current->egid;
+	bprm->e_uid = current_euid();
+	bprm->e_gid = current_egid();
 
 	if(!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID)) {
 		/* Set-uid? */
@@ -1096,7 +1096,7 @@ void compute_creds(struct linux_binprm *bprm)
 {
 	int unsafe;
 
-	if (bprm->e_uid != current->uid) {
+	if (bprm->e_uid != current_uid()) {
 		suid_keys(current);
 		current->pdeath_signal = 0;
 	}
@@ -1424,7 +1424,7 @@ static int format_corename(char *corename, long signr)
 			/* uid */
 			case 'u':
 				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%d", current->uid);
+					      "%d", current_uid());
 				if (rc > out_end - out_ptr)
 					goto out;
 				out_ptr += rc;
@@ -1432,7 +1432,7 @@ static int format_corename(char *corename, long signr)
 			/* gid */
 			case 'g':
 				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%d", current->gid);
+					      "%d", current_gid());
 				if (rc > out_end - out_ptr)
 					goto out;
 				out_ptr += rc;
@@ -1709,7 +1709,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	struct inode * inode;
 	struct file * file;
 	int retval = 0;
-	int fsuid = current->fsuid;
+	int fsuid = current_fsuid();
 	int flag = 0;
 	int ispipe = 0;
 	unsigned long core_limit = current->signal->rlim[RLIMIT_CORE].rlim_cur;
@@ -1815,7 +1815,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 * Dont allow local users get cute and trick others to coredump
 	 * into their pre-created files:
 	 */
-	if (inode->i_uid != current->fsuid)
+	if (inode->i_uid != current_fsuid())
 		goto close_fail;
 	if (!file->f_op)
 		goto close_fail;

commit 6409324b385f3f63a03645b4422e3be67348d922
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sat Oct 18 20:28:22 2008 -0700

    coredump: format_corename: don't append .%pid if multi-threaded
    
    If the coredumping is multi-threaded, format_corename() appends .%pid to
    the corename.  This was needed before the proper multi-thread core dump
    support, now all the threads in the mm go into a single unified core file.
    
    Remove this special case, it is not even documented and we have "%p"
    and core_uses_pid.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Michael Kerrisk <mtk.manpages@googlemail.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: La Monte Yarroll <piggy@laurelnetworks.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a41e7902ed0b..4e834f16d9da 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1386,7 +1386,7 @@ EXPORT_SYMBOL(set_binfmt);
  * name into corename, which must have space for at least
  * CORENAME_MAX_SIZE bytes plus one byte for the zero terminator.
  */
-static int format_corename(char *corename, int nr_threads, long signr)
+static int format_corename(char *corename, long signr)
 {
 	const char *pat_ptr = core_pattern;
 	int ispipe = (*pat_ptr == '|');
@@ -1493,8 +1493,7 @@ static int format_corename(char *corename, int nr_threads, long signr)
 	 * If core_pattern does not include a %p (as is the default)
 	 * and core_uses_pid is set, then .%pid will be appended to
 	 * the filename. Do not do this for piped commands. */
-	if (!ispipe && !pid_in_pattern
-	    && (core_uses_pid || nr_threads)) {
+	if (!ispipe && !pid_in_pattern && core_uses_pid) {
 		rc = snprintf(out_ptr, out_end - out_ptr,
 			      ".%d", task_tgid_vnr(current));
 		if (rc > out_end - out_ptr)
@@ -1757,7 +1756,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 * uses lock_kernel()
 	 */
  	lock_kernel();
-	ispipe = format_corename(corename, retval, signr);
+	ispipe = format_corename(corename, signr);
 	unlock_kernel();
 	/*
 	 * Don't bother to check the RLIMIT_CORE value if core_pattern points

commit c8d8a2321f9c4ee18fbcc399fdc2a77e580a03b9
Merge: e4856a70cfc2 118a9069f06f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 16 12:38:34 2008 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/rusty/linux-2.6-for-linus
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/rusty/linux-2.6-for-linus:
      module: remove CONFIG_KMOD in comment after #endif
      remove CONFIG_KMOD from fs
      remove CONFIG_KMOD from drivers
    
    Manually fix conflict due to include cleanups in drivers/md/md.c

commit 07edbde508869be63c38c5f2504bd8e8279cc535
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Oct 15 22:04:25 2008 -0700

    pid_ns: de_thread: kill the now unneeded ->child_reaper change
    
    de_thread() checks if the old leader was the ->child_reaper, this is not
    possible any longer.  With the previous patch ->group_leader itself will
    change ->child_reaper on exit.
    
    Henceforth find_new_reaper() is the only function (apart from
    initialization) which plays with ->child_reaper.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Acked-by: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4a790f2e224e..cfb5656b2cdc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -825,8 +825,6 @@ static int de_thread(struct task_struct *tsk)
 			schedule();
 		}
 
-		if (unlikely(task_child_reaper(tsk) == leader))
-			task_active_pid_ns(tsk)->child_reaper = tsk;
 		/*
 		 * The only record we have of the real-time age of a
 		 * process, regardless of execs it's done, is start_time.

commit 53112488bebe25c0f5f8a002470046c0fe9a6c61
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Wed Oct 15 22:02:37 2008 -0700

    alpha: introduce field 'taso' into struct linux_binprm
    
    This change is Alpha-specific.  It adds field 'taso' into struct
    linux_binprm to remember if the application is TASO.  Previously, field
    sh_bang was used for this purpose.
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7b5ed50eadeb..4a790f2e224e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1189,7 +1189,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			return retval;
 
 		/* Remember if the application is TASO.  */
-		bprm->sh_bang = eh->ah.entry < 0x100000000UL;
+		bprm->taso = eh->ah.entry < 0x100000000UL;
 
 		bprm->file = file;
 		bprm->loader = loader;

commit 362e6663ef2369d77251496d865ad02a2376f962
Author: Jason Baron <jbaron@redhat.com>
Date:   Wed Oct 15 22:01:52 2008 -0700

    exec.c, compat.c: fix count(), compat_count() bounds checking
    
    With MAX_ARG_STRINGS set to 0x7FFFFFFF, and being passed to 'count()' and
    compat_count(), it would appear that the current max bounds check of
    fs/exec.c:394:
    
            if(++i > max)
                    return -E2BIG;
    
    would never trigger. Since 'i' is of type int, so values would wrap and the
    function would continue looping.
    
    Simple fix seems to be chaning ++i to i++ and checking for '>='.
    
    Signed-off-by: Jason Baron <jbaron@redhat.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: "Ollie Wild" <aaw@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index cecee501ce78..7b5ed50eadeb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -391,7 +391,7 @@ static int count(char __user * __user * argv, int max)
 			if (!p)
 				break;
 			argv++;
-			if(++i > max)
+			if (i++ >= max)
 				return -E2BIG;
 			cond_resched();
 		}

commit 5f4123be3cdb1dbd77fa9d6d2bb96bb9689a0a19
Author: Johannes Berg <johannes@sipsolutions.net>
Date:   Wed Jul 9 10:28:40 2008 +0200

    remove CONFIG_KMOD from fs
    
    Just always compile the code when the kernel is modular.
    Convert load_nls to use try_then_request_module to tidy
    up the code.
    
    Signed-off-by: Johannes Berg <johannes@sipsolutions.net>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/fs/exec.c b/fs/exec.c
index cecee501ce78..9811679b0695 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -50,15 +50,12 @@
 #include <linux/cn_proc.h>
 #include <linux/audit.h>
 #include <linux/tracehook.h>
+#include <linux/kmod.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlb.h>
 
-#ifdef CONFIG_KMOD
-#include <linux/kmod.h>
-#endif
-
 #ifdef __alpha__
 /* for /sbin/loader handling in search_binary_handler() */
 #include <linux/a.out.h>
@@ -1247,8 +1244,8 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 		read_unlock(&binfmt_lock);
 		if (retval != -ENOEXEC || bprm->mm == NULL) {
 			break;
-#ifdef CONFIG_KMOD
-		}else{
+#ifdef CONFIG_MODULES
+		} else {
 #define printable(c) (((c)=='\t') || ((c)=='\n') || (0x20<=(c) && (c)<=0x7e))
 			if (printable(bprm->buf[0]) &&
 			    printable(bprm->buf[1]) &&

commit 31a78f23bac0069004e69f98808b6988baccb6b6
Author: Balbir Singh <balbir@linux.vnet.ibm.com>
Date:   Sun Sep 28 23:09:31 2008 +0100

    mm owner: fix race between swapoff and exit
    
    There's a race between mm->owner assignment and swapoff, more easily
    seen when task slab poisoning is turned on.  The condition occurs when
    try_to_unuse() runs in parallel with an exiting task.  A similar race
    can occur with callers of get_task_mm(), such as /proc/<pid>/<mmstats>
    or ptrace or page migration.
    
    CPU0                                    CPU1
                                            try_to_unuse
                                            looks at mm = task0->mm
                                            increments mm->mm_users
    task 0 exits
    mm->owner needs to be updated, but no
    new owner is found (mm_users > 1, but
    no other task has task->mm = task0->mm)
    mm_update_next_owner() leaves
                                            mmput(mm) decrements mm->mm_users
    task0 freed
                                            dereferencing mm->owner fails
    
    The fix is to notify the subsystem via mm_owner_changed callback(),
    if no new owner is found, by specifying the new task as NULL.
    
    Jiri Slaby:
    mm->owner was set to NULL prior to calling cgroup_mm_owner_callbacks(), but
    must be set after that, so as not to pass NULL as old owner causing oops.
    
    Daisuke Nishimura:
    mm_update_next_owner() may set mm->owner to NULL, but mem_cgroup_from_task()
    and its callers need to take account of this situation to avoid oops.
    
    Hugh Dickins:
    Lockdep warning and hang below exec_mmap() when testing these patches.
    exit_mm() up_reads mmap_sem before calling mm_update_next_owner(),
    so exec_mmap() now needs to do the same.  And with that repositioning,
    there's now no point in mm_need_new_owner() allowing for NULL mm.
    
    Reported-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Balbir Singh <balbir@linux.vnet.ibm.com>
    Signed-off-by: Jiri Slaby <jirislaby@gmail.com>
    Signed-off-by: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 32993beecbe9..cecee501ce78 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -752,11 +752,11 @@ static int exec_mmap(struct mm_struct *mm)
 	tsk->active_mm = mm;
 	activate_mm(active_mm, mm);
 	task_unlock(tsk);
-	mm_update_next_owner(old_mm);
 	arch_pick_mmap_layout(mm);
 	if (old_mm) {
 		up_read(&old_mm->mmap_sem);
 		BUG_ON(active_mm != old_mm);
+		mm_update_next_owner(old_mm);
 		mmput(old_mm);
 		return 0;
 	}

commit ca5b172bd2b2fe489e7ba11cedd46ddf772d132f
Author: Hugh Dickins <hugh@veritas.com>
Date:   Mon Jul 28 15:46:18 2008 -0700

    exec: include pagemap.h again to fix build
    
    Fix compilation errors on avr32 and without CONFIG_SWAP, introduced by
    ba92a43dbaee339cf5915ef766d3d3ffbaaf103c ("exec: remove some includes")
    
      In file included from include/asm/tlb.h:24,
                       from fs/exec.c:55:
      include/asm-generic/tlb.h: In function 'tlb_flush_mmu':
      include/asm-generic/tlb.h:76: error: implicit declaration of function 'release_pages'
      include/asm-generic/tlb.h: In function 'tlb_remove_page':
      include/asm-generic/tlb.h:105: error: implicit declaration of function 'page_cache_release'
      make[1]: *** [fs/exec.o] Error 1
    
    This straightforward part-revert is nobody's favourite patch to address
    the underlying tlb.h needs swap.h needs pagemap.h (but sparc won't like
    that) mess; but appropriate to fix the build now before any overhaul.
    
    Reported-by: Yoichi Yuasa <yoichi_yuasa@tripeaks.co.jp>
    Reported-by: Haavard Skinnemoen <haavard.skinnemoen@atmel.com>
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Tested-by: Adrian Bunk <bunk@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9696bbf0f0b1..32993beecbe9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -32,6 +32,7 @@
 #include <linux/swap.h>
 #include <linux/string.h>
 #include <linux/init.h>
+#include <linux/pagemap.h>
 #include <linux/highmem.h>
 #include <linux/spinlock.h>
 #include <linux/key.h>

commit 964bd183624c03680796b63b4ab97ee3905a806a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jul 26 03:33:14 2008 -0400

    [PATCH] get rid of __user_path_lookup_open
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index eca58c29eded..9696bbf0f0b1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -106,11 +106,17 @@ static inline void put_binfmt(struct linux_binfmt * fmt)
  */
 asmlinkage long sys_uselib(const char __user * library)
 {
-	struct file * file;
+	struct file *file;
 	struct nameidata nd;
-	int error;
-
-	error = __user_path_lookup_open(library, LOOKUP_FOLLOW, &nd, FMODE_READ|FMODE_EXEC);
+	char *tmp = getname(library);
+	int error = PTR_ERR(tmp);
+
+	if (!IS_ERR(tmp)) {
+		error = path_lookup_open(AT_FDCWD, tmp,
+					 LOOKUP_FOLLOW, &nd,
+					 FMODE_READ|FMODE_EXEC);
+		putname(tmp);
+	}
 	if (error)
 		goto out;
 

commit 30524472c2f728c20d6bf35191042a5d455c0a64
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jul 22 00:02:33 2008 -0400

    [PATCH] take noexec checks to very few callers that care
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 346e3f69c6e0..eca58c29eded 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -118,6 +118,10 @@ asmlinkage long sys_uselib(const char __user * library)
 	if (!S_ISREG(nd.path.dentry->d_inode->i_mode))
 		goto exit;
 
+	error = -EACCES;
+	if (nd.path.mnt->mnt_flags & MNT_NOEXEC)
+		goto exit;
+
 	error = vfs_permission(&nd, MAY_READ | MAY_EXEC | MAY_OPEN);
 	if (error)
 		goto exit;
@@ -668,6 +672,9 @@ struct file *open_exec(const char *name)
 	if (!S_ISREG(nd.path.dentry->d_inode->i_mode))
 		goto out_path_put;
 
+	if (nd.path.mnt->mnt_flags & MNT_NOEXEC)
+		goto out_path_put;
+
 	err = vfs_permission(&nd, MAY_EXEC | MAY_OPEN);
 	if (err)
 		goto out_path_put;

commit e56b6a5dda1a36ffaa532df6f975ea324298fa4d
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 19 07:53:34 2008 +0200

    Re: [PATCH 3/6] vfs: open_exec cleanup
    
    On Mon, May 19, 2008 at 12:01:49AM +0200, Marcin Slusarz wrote:
    > open_exec is needlessly indented, calls ERR_PTR with 0 argument
    > (which is not valid errno) and jumps into middle of function
    > just to return value.
    > So clean it up a bit.
    
    Still looks rather messy.  See below for a better version.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 0ba5d355c5a1..346e3f69c6e0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -656,38 +656,40 @@ EXPORT_SYMBOL(setup_arg_pages);
 struct file *open_exec(const char *name)
 {
 	struct nameidata nd;
-	int err;
 	struct file *file;
+	int err;
 
-	err = path_lookup_open(AT_FDCWD, name, LOOKUP_FOLLOW, &nd, FMODE_READ|FMODE_EXEC);
-	file = ERR_PTR(err);
-
-	if (!err) {
-		struct inode *inode = nd.path.dentry->d_inode;
-		file = ERR_PTR(-EACCES);
-		if (S_ISREG(inode->i_mode)) {
-			int err = vfs_permission(&nd, MAY_EXEC | MAY_OPEN);
-			file = ERR_PTR(err);
-			if (!err) {
-				file = nameidata_to_filp(&nd,
-							O_RDONLY|O_LARGEFILE);
-				if (!IS_ERR(file)) {
-					err = deny_write_access(file);
-					if (err) {
-						fput(file);
-						file = ERR_PTR(err);
-					}
-				}
-out:
-				return file;
-			}
-		}
-		release_open_intent(&nd);
-		path_put(&nd.path);
+	err = path_lookup_open(AT_FDCWD, name, LOOKUP_FOLLOW, &nd,
+				FMODE_READ|FMODE_EXEC);
+	if (err)
+		goto out;
+
+	err = -EACCES;
+	if (!S_ISREG(nd.path.dentry->d_inode->i_mode))
+		goto out_path_put;
+
+	err = vfs_permission(&nd, MAY_EXEC | MAY_OPEN);
+	if (err)
+		goto out_path_put;
+
+	file = nameidata_to_filp(&nd, O_RDONLY|O_LARGEFILE);
+	if (IS_ERR(file))
+		return file;
+
+	err = deny_write_access(file);
+	if (err) {
+		fput(file);
+		goto out;
 	}
-	goto out;
-}
 
+	return file;
+
+ out_path_put:
+	release_open_intent(&nd);
+	path_put(&nd.path);
+ out:
+	return ERR_PTR(err);
+}
 EXPORT_SYMBOL(open_exec);
 
 int kernel_read(struct file *file, unsigned long offset,

commit b77b0646ef4efe31a7449bb3d9360fd00f95433d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Jul 17 09:37:02 2008 -0400

    [PATCH] pass MAY_OPEN to vfs_permission() explicitly
    
    ... and get rid of the last "let's deduce mask from nameidata->flags"
    bit.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index b8792a131533..0ba5d355c5a1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -118,7 +118,7 @@ asmlinkage long sys_uselib(const char __user * library)
 	if (!S_ISREG(nd.path.dentry->d_inode->i_mode))
 		goto exit;
 
-	error = vfs_permission(&nd, MAY_READ | MAY_EXEC);
+	error = vfs_permission(&nd, MAY_READ | MAY_EXEC | MAY_OPEN);
 	if (error)
 		goto exit;
 
@@ -666,7 +666,7 @@ struct file *open_exec(const char *name)
 		struct inode *inode = nd.path.dentry->d_inode;
 		file = ERR_PTR(-EACCES);
 		if (S_ISREG(inode->i_mode)) {
-			int err = vfs_permission(&nd, MAY_EXEC);
+			int err = vfs_permission(&nd, MAY_EXEC | MAY_OPEN);
 			file = ERR_PTR(err);
 			if (!err) {
 				file = nameidata_to_filp(&nd,

commit 6341c393fcc37d58727865f1ee2f65e632e9d4f0
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Jul 25 19:45:44 2008 -0700

    tracehook: exec
    
    This moves all the ptrace hooks related to exec into tracehook.h inlines.
    
    This also lifts the calls for tracing out of the binfmt load_binary hooks
    into search_binary_handler() after it calls into the binfmt module.  This
    change has no effect, since all the binfmt modules' load_binary functions
    did the call at the end on success, and now search_binary_handler() does
    it immediately after return if successful.  We consolidate the repeated
    code, and binfmt modules no longer need to import ptrace_notify().
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 5e559013e303..b8792a131533 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -42,13 +42,13 @@
 #include <linux/module.h>
 #include <linux/namei.h>
 #include <linux/proc_fs.h>
-#include <linux/ptrace.h>
 #include <linux/mount.h>
 #include <linux/security.h>
 #include <linux/syscalls.h>
 #include <linux/tsacct_kern.h>
 #include <linux/cn_proc.h>
 #include <linux/audit.h>
+#include <linux/tracehook.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -1071,13 +1071,8 @@ EXPORT_SYMBOL(prepare_binprm);
 
 static int unsafe_exec(struct task_struct *p)
 {
-	int unsafe = 0;
-	if (p->ptrace & PT_PTRACED) {
-		if (p->ptrace & PT_PTRACE_CAP)
-			unsafe |= LSM_UNSAFE_PTRACE_CAP;
-		else
-			unsafe |= LSM_UNSAFE_PTRACE;
-	}
+	int unsafe = tracehook_unsafe_exec(p);
+
 	if (atomic_read(&p->fs->count) > 1 ||
 	    atomic_read(&p->files->count) > 1 ||
 	    atomic_read(&p->sighand->count) > 1)
@@ -1214,6 +1209,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 			read_unlock(&binfmt_lock);
 			retval = fn(bprm, regs);
 			if (retval >= 0) {
+				tracehook_report_exec(fmt, bprm, regs);
 				put_binfmt(fmt);
 				allow_write_access(bprm->file);
 				if (bprm->file)

commit 565b9b14e7f48131bca58840aa404bbef058fa89
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:47 2008 -0700

    coredump: format_corename: fix the "core_uses_pid" logic
    
    I don't understand why the multi-thread coredump implies the core_uses_pid
    behaviour, but we shouldn't use mm->mm_users for that.  This counter can
    be incremented by get_task_mm().  Use the valued returned by
    coredump_wait() instead.
    
    Also, remove the "const char *pattern" argument, format_corename() can use
    core_pattern directly.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index bff43aeb235e..5e559013e303 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1379,17 +1379,14 @@ EXPORT_SYMBOL(set_binfmt);
  * name into corename, which must have space for at least
  * CORENAME_MAX_SIZE bytes plus one byte for the zero terminator.
  */
-static int format_corename(char *corename, const char *pattern, long signr)
+static int format_corename(char *corename, int nr_threads, long signr)
 {
-	const char *pat_ptr = pattern;
+	const char *pat_ptr = core_pattern;
+	int ispipe = (*pat_ptr == '|');
 	char *out_ptr = corename;
 	char *const out_end = corename + CORENAME_MAX_SIZE;
 	int rc;
 	int pid_in_pattern = 0;
-	int ispipe = 0;
-
-	if (*pattern == '|')
-		ispipe = 1;
 
 	/* Repeat as long as we have more pattern to process and more output
 	   space */
@@ -1490,7 +1487,7 @@ static int format_corename(char *corename, const char *pattern, long signr)
 	 * and core_uses_pid is set, then .%pid will be appended to
 	 * the filename. Do not do this for piped commands. */
 	if (!ispipe && !pid_in_pattern
-            && (core_uses_pid || atomic_read(&current->mm->mm_users) != 1)) {
+	    && (core_uses_pid || nr_threads)) {
 		rc = snprintf(out_ptr, out_end - out_ptr,
 			      ".%d", task_tgid_vnr(current));
 		if (rc > out_end - out_ptr)
@@ -1753,7 +1750,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 * uses lock_kernel()
 	 */
  	lock_kernel();
-	ispipe = format_corename(corename, core_pattern, signr);
+	ispipe = format_corename(corename, retval, signr);
 	unlock_kernel();
 	/*
 	 * Don't bother to check the RLIMIT_CORE value if core_pattern points

commit a94e2d408eaedbd85aae259621d46fafc10479a2
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:46 2008 -0700

    coredump: kill mm->core_done
    
    Now that we have core_state->dumper list we can use it to wake up the
    sub-threads waiting for the coredump completion.
    
    This uglifies the code and .text grows by 47 bytes, but otoh mm_struct
    lessens by sizeof(struct completion).  Also, with this change we can
    decouple exit_mm() from the coredumping code.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index fe2873b8037f..bff43aeb235e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1602,7 +1602,6 @@ static int coredump_wait(int exit_code, struct core_state *core_state)
 	struct completion *vfork_done;
 	int core_waiters;
 
-	init_completion(&mm->core_done);
 	init_completion(&core_state->startup);
 	core_state->dumper.task = tsk;
 	core_state->dumper.next = NULL;
@@ -1628,6 +1627,27 @@ static int coredump_wait(int exit_code, struct core_state *core_state)
 	return core_waiters;
 }
 
+static void coredump_finish(struct mm_struct *mm)
+{
+	struct core_thread *curr, *next;
+	struct task_struct *task;
+
+	next = mm->core_state->dumper.next;
+	while ((curr = next) != NULL) {
+		next = curr->next;
+		task = curr->task;
+		/*
+		 * see exit_mm(), curr->task must not see
+		 * ->task == NULL before we read ->next.
+		 */
+		smp_mb();
+		curr->task = NULL;
+		wake_up_process(task);
+	}
+
+	mm->core_state = NULL;
+}
+
 /*
  * set_dumpable converts traditional three-value dumpable to two flags and
  * stores them into mm->flags.  It modifies lower two bits of mm->flags, but
@@ -1812,8 +1832,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		argv_free(helper_argv);
 
 	current->fsuid = fsuid;
-	complete_all(&mm->core_done);
-	mm->core_state = NULL;
+	coredump_finish(mm);
 fail:
 	return retval;
 }

commit b564daf806d492dd4f7afe9b6c83b8d35d137669
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:44 2008 -0700

    coredump: construct the list of coredumping threads at startup time
    
    binfmt->core_dump() has to iterate over the all threads in system in order
    to find the coredumping threads and construct the list using the
    GFP_ATOMIC allocations.
    
    With this patch each thread allocates the list node on exit_mm()'s stack and
    adds itself to the list.
    
    This allows us to do further changes:
    
            - simplify ->core_dump()
    
            - change exit_mm() to clear ->mm first, then wait for ->core_done.
              this makes the coredumping process visible to oom_kill
    
            - kill mm->core_done
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index b8ee842d93cd..fe2873b8037f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1604,6 +1604,8 @@ static int coredump_wait(int exit_code, struct core_state *core_state)
 
 	init_completion(&mm->core_done);
 	init_completion(&core_state->startup);
+	core_state->dumper.task = tsk;
+	core_state->dumper.next = NULL;
 	core_waiters = zap_threads(tsk, mm, core_state, exit_code);
 	up_write(&mm->mmap_sem);
 

commit 9d5b327bf198d2720666de958dcc2ae219d86952
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:43 2008 -0700

    coredump: make mm->core_state visible to ->core_dump()
    
    Move the "struct core_state core_state" from coredump_wait() to
    do_coredump(), this makes mm->core_state visible to binfmt->core_dump().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 15d493fe8aa3..b8ee842d93cd 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1595,17 +1595,16 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 	return nr;
 }
 
-static int coredump_wait(int exit_code)
+static int coredump_wait(int exit_code, struct core_state *core_state)
 {
 	struct task_struct *tsk = current;
 	struct mm_struct *mm = tsk->mm;
-	struct core_state core_state;
 	struct completion *vfork_done;
 	int core_waiters;
 
 	init_completion(&mm->core_done);
-	init_completion(&core_state.startup);
-	core_waiters = zap_threads(tsk, mm, &core_state, exit_code);
+	init_completion(&core_state->startup);
+	core_waiters = zap_threads(tsk, mm, core_state, exit_code);
 	up_write(&mm->mmap_sem);
 
 	if (unlikely(core_waiters < 0))
@@ -1622,8 +1621,7 @@ static int coredump_wait(int exit_code)
 	}
 
 	if (core_waiters)
-		wait_for_completion(&core_state.startup);
-	mm->core_state = NULL;
+		wait_for_completion(&core_state->startup);
 fail:
 	return core_waiters;
 }
@@ -1679,6 +1677,7 @@ int get_dumpable(struct mm_struct *mm)
 
 int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 {
+	struct core_state core_state;
 	char corename[CORENAME_MAX_SIZE + 1];
 	struct mm_struct *mm = current->mm;
 	struct linux_binfmt * binfmt;
@@ -1717,7 +1716,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		current->fsuid = 0;	/* Dump root private */
 	}
 
-	retval = coredump_wait(exit_code);
+	retval = coredump_wait(exit_code, &core_state);
 	if (retval < 0)
 		goto fail;
 
@@ -1812,6 +1811,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 
 	current->fsuid = fsuid;
 	complete_all(&mm->core_done);
+	mm->core_state = NULL;
 fail:
 	return retval;
 }

commit c5f1cc8c1828486a61ab3e575da6e2c62b34d399
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:42 2008 -0700

    coredump: turn core_state->nr_threads into atomic_t
    
    Turn core_state->nr_threads into atomic_t and kill now unneeded
    down_write(&mm->mmap_sem) in exit_mm().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index c74bb34eeeff..15d493fe8aa3 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1591,7 +1591,7 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 	}
 	rcu_read_unlock();
 done:
-	core_state->nr_threads = nr;
+	atomic_set(&core_state->nr_threads, nr);
 	return nr;
 }
 

commit 8cd9c249128a59e8e833d454a784b0cbd338d468
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:42 2008 -0700

    coredump: simplify core_state->nr_threads calculation
    
    Change zap_process() to return int instead of incrementing
    mm->core_state->nr_threads directly.  Change zap_threads() to set
    mm->core_state only on success.
    
    This patch restores the original size of .text, and more importantly now
    ->nr_threads is used in two places only.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 50de3aaff4d0..c74bb34eeeff 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1502,9 +1502,10 @@ static int format_corename(char *corename, const char *pattern, long signr)
 	return ispipe;
 }
 
-static void zap_process(struct task_struct *start)
+static int zap_process(struct task_struct *start)
 {
 	struct task_struct *t;
+	int nr = 0;
 
 	start->signal->flags = SIGNAL_GROUP_EXIT;
 	start->signal->group_stop_count = 0;
@@ -1512,31 +1513,33 @@ static void zap_process(struct task_struct *start)
 	t = start;
 	do {
 		if (t != current && t->mm) {
-			t->mm->core_state->nr_threads++;
 			sigaddset(&t->pending.signal, SIGKILL);
 			signal_wake_up(t, 1);
+			nr++;
 		}
 	} while_each_thread(start, t);
+
+	return nr;
 }
 
 static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
-				int exit_code)
+				struct core_state *core_state, int exit_code)
 {
 	struct task_struct *g, *p;
 	unsigned long flags;
-	int err = -EAGAIN;
+	int nr = -EAGAIN;
 
 	spin_lock_irq(&tsk->sighand->siglock);
 	if (!signal_group_exit(tsk->signal)) {
+		mm->core_state = core_state;
 		tsk->signal->group_exit_code = exit_code;
-		zap_process(tsk);
-		err = 0;
+		nr = zap_process(tsk);
 	}
 	spin_unlock_irq(&tsk->sighand->siglock);
-	if (err)
-		return err;
+	if (unlikely(nr < 0))
+		return nr;
 
-	if (atomic_read(&mm->mm_users) == mm->core_state->nr_threads + 1)
+	if (atomic_read(&mm->mm_users) == nr + 1)
 		goto done;
 	/*
 	 * We should find and kill all tasks which use this mm, and we should
@@ -1579,7 +1582,7 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 			if (p->mm) {
 				if (unlikely(p->mm == mm)) {
 					lock_task_sighand(p, &flags);
-					zap_process(p);
+					nr += zap_process(p);
 					unlock_task_sighand(p, &flags);
 				}
 				break;
@@ -1588,7 +1591,8 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 	}
 	rcu_read_unlock();
 done:
-	return mm->core_state->nr_threads;
+	core_state->nr_threads = nr;
+	return nr;
 }
 
 static int coredump_wait(int exit_code)
@@ -1601,12 +1605,7 @@ static int coredump_wait(int exit_code)
 
 	init_completion(&mm->core_done);
 	init_completion(&core_state.startup);
-	core_state.nr_threads = 0;
-	mm->core_state = &core_state;
-
-	core_waiters = zap_threads(tsk, mm, exit_code);
-	if (core_waiters < 0)
-		mm->core_state = NULL;
+	core_waiters = zap_threads(tsk, mm, &core_state, exit_code);
 	up_write(&mm->mmap_sem);
 
 	if (unlikely(core_waiters < 0))

commit 999d9fc1670bc082928b93b11d1f2e0e417d973c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:41 2008 -0700

    coredump: move mm->core_waiters into struct core_state
    
    Move mm->core_waiters into "struct core_state" allocated on stack.  This
    shrinks mm_struct a little bit and allows further changes.
    
    This patch mostly does s/core_waiters/core_state.  The only essential
    change is that coredump_wait() must clear mm->core_state before return.
    
    The coredump_wait()'s path is uglified and .text grows by 30 bytes, this
    is fixed by the next patch.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 71734568f018..50de3aaff4d0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -722,12 +722,10 @@ static int exec_mmap(struct mm_struct *mm)
 		 * Make sure that if there is a core dump in progress
 		 * for the old mm, we get out and die instead of going
 		 * through with the exec.  We must hold mmap_sem around
-		 * checking core_waiters and changing tsk->mm.  The
-		 * core-inducing thread will increment core_waiters for
-		 * each thread whose ->mm == old_mm.
+		 * checking core_state and changing tsk->mm.
 		 */
 		down_read(&old_mm->mmap_sem);
-		if (unlikely(old_mm->core_waiters)) {
+		if (unlikely(old_mm->core_state)) {
 			up_read(&old_mm->mmap_sem);
 			return -EINTR;
 		}
@@ -1514,7 +1512,7 @@ static void zap_process(struct task_struct *start)
 	t = start;
 	do {
 		if (t != current && t->mm) {
-			t->mm->core_waiters++;
+			t->mm->core_state->nr_threads++;
 			sigaddset(&t->pending.signal, SIGKILL);
 			signal_wake_up(t, 1);
 		}
@@ -1538,11 +1536,11 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 	if (err)
 		return err;
 
-	if (atomic_read(&mm->mm_users) == mm->core_waiters + 1)
+	if (atomic_read(&mm->mm_users) == mm->core_state->nr_threads + 1)
 		goto done;
 	/*
 	 * We should find and kill all tasks which use this mm, and we should
-	 * count them correctly into mm->core_waiters. We don't take tasklist
+	 * count them correctly into ->nr_threads. We don't take tasklist
 	 * lock, but this is safe wrt:
 	 *
 	 * fork:
@@ -1590,7 +1588,7 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 	}
 	rcu_read_unlock();
 done:
-	return mm->core_waiters;
+	return mm->core_state->nr_threads;
 }
 
 static int coredump_wait(int exit_code)
@@ -1603,9 +1601,12 @@ static int coredump_wait(int exit_code)
 
 	init_completion(&mm->core_done);
 	init_completion(&core_state.startup);
+	core_state.nr_threads = 0;
 	mm->core_state = &core_state;
 
 	core_waiters = zap_threads(tsk, mm, exit_code);
+	if (core_waiters < 0)
+		mm->core_state = NULL;
 	up_write(&mm->mmap_sem);
 
 	if (unlikely(core_waiters < 0))
@@ -1623,8 +1624,8 @@ static int coredump_wait(int exit_code)
 
 	if (core_waiters)
 		wait_for_completion(&core_state.startup);
+	mm->core_state = NULL;
 fail:
-	BUG_ON(mm->core_waiters);
 	return core_waiters;
 }
 
@@ -1702,7 +1703,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	/*
 	 * If another thread got here first, or we are not dumpable, bail out.
 	 */
-	if (mm->core_waiters || !get_dumpable(mm)) {
+	if (mm->core_state || !get_dumpable(mm)) {
 		up_write(&mm->mmap_sem);
 		goto fail;
 	}

commit 32ecb1f26dd50eeaac4e3f4dea4541c97848e459
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:41 2008 -0700

    coredump: turn mm->core_startup_done into the pointer to struct core_state
    
    mm->core_startup_done points to "struct completion startup_done" allocated
    on the coredump_wait()'s stack.  Introduce the new structure, core_state,
    which holds this "struct completion".  This way we can add more info
    visible to the threads participating in coredump without enlarging
    mm_struct.
    
    No changes in affected .o files.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e347e6ed1617..71734568f018 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1597,13 +1597,13 @@ static int coredump_wait(int exit_code)
 {
 	struct task_struct *tsk = current;
 	struct mm_struct *mm = tsk->mm;
-	struct completion startup_done;
+	struct core_state core_state;
 	struct completion *vfork_done;
 	int core_waiters;
 
 	init_completion(&mm->core_done);
-	init_completion(&startup_done);
-	mm->core_startup_done = &startup_done;
+	init_completion(&core_state.startup);
+	mm->core_state = &core_state;
 
 	core_waiters = zap_threads(tsk, mm, exit_code);
 	up_write(&mm->mmap_sem);
@@ -1622,7 +1622,7 @@ static int coredump_wait(int exit_code)
 	}
 
 	if (core_waiters)
-		wait_for_completion(&startup_done);
+		wait_for_completion(&core_state.startup);
 fail:
 	BUG_ON(mm->core_waiters);
 	return core_waiters;

commit 15b9f360c0316c06d37c09b02d85565edbaf9dd3
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:39 2008 -0700

    coredump: zap_threads() must skip kernel threads
    
    The main loop in zap_threads() must skip kthreads which may use the same
    mm.  Otherwise we "kill" this thread erroneously (for example, it can not
    fork or exec after that), and the coredumping task stucks in the
    TASK_UNINTERRUPTIBLE state forever because of the wrong ->core_waiters
    count.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index cd2e8c9b1249..e347e6ed1617 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1574,11 +1574,12 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 	for_each_process(g) {
 		if (g == tsk->group_leader)
 			continue;
-
+		if (g->flags & PF_KTHREAD)
+			continue;
 		p = g;
 		do {
 			if (p->mm) {
-				if (p->mm == mm) {
+				if (unlikely(p->mm == mm)) {
 					lock_task_sighand(p, &flags);
 					zap_process(p);
 					unlock_task_sighand(p, &flags);

commit 7b34e4283c685f5cc6ba6d30e939906eee0d4bcf
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:37 2008 -0700

    introduce PF_KTHREAD flag
    
    Introduce the new PF_KTHREAD flag to mark the kernel threads.  It is set
    by INIT_TASK() and copied to the forked childs (we could set it in
    kthreadd() along with PF_NOFREEZE instead).
    
    daemonize() was changed as well.  In that case testing of PF_KTHREAD is
    racy, but daemonize() is hopeless anyway.
    
    This flag is cleared in do_execve(), before search_binary_handler().
    Probably not the best place, we can do this in exec_mmap() or in
    start_thread(), or clear it along with PF_FORKNOEXEC.  But I think this
    doesn't matter in practice, and if do_execve() fails kthread should die
    soon.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index af249af4ccab..cd2e8c9b1249 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1326,6 +1326,7 @@ int do_execve(char * filename,
 	if (retval < 0)
 		goto out;
 
+	current->flags &= ~PF_KTHREAD;
 	retval = search_binary_handler(bprm,regs);
 	if (retval >= 0) {
 		/* execve success */

commit e4901f92a8dbe843e76651a50f7a2a6dd3d53474
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:31 2008 -0700

    coredump: zap_threads: comments && use while_each_thread()
    
    No changes in fs/exec.o
    
    The for_each_process() loop in zap_threads() is very subtle, it is not
    clear why we don't race with fork/exit/exec.  Add the fat comment.
    
    Also, change the code to use while_each_thread().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index e41aef0fb351..af249af4ccab 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1517,7 +1517,7 @@ static void zap_process(struct task_struct *start)
 			sigaddset(&t->pending.signal, SIGKILL);
 			signal_wake_up(t, 1);
 		}
-	} while ((t = next_thread(t)) != start);
+	} while_each_thread(start, t);
 }
 
 static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
@@ -1539,7 +1539,36 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 
 	if (atomic_read(&mm->mm_users) == mm->core_waiters + 1)
 		goto done;
-
+	/*
+	 * We should find and kill all tasks which use this mm, and we should
+	 * count them correctly into mm->core_waiters. We don't take tasklist
+	 * lock, but this is safe wrt:
+	 *
+	 * fork:
+	 *	None of sub-threads can fork after zap_process(leader). All
+	 *	processes which were created before this point should be
+	 *	visible to zap_threads() because copy_process() adds the new
+	 *	process to the tail of init_task.tasks list, and lock/unlock
+	 *	of ->siglock provides a memory barrier.
+	 *
+	 * do_exit:
+	 *	The caller holds mm->mmap_sem. This means that the task which
+	 *	uses this mm can't pass exit_mm(), so it can't exit or clear
+	 *	its ->mm.
+	 *
+	 * de_thread:
+	 *	It does list_replace_rcu(&leader->tasks, &current->tasks),
+	 *	we must see either old or new leader, this does not matter.
+	 *	However, it can change p->sighand, so lock_task_sighand(p)
+	 *	must be used. Since p->mm != NULL and we hold ->mmap_sem
+	 *	it can't fail.
+	 *
+	 *	Note also that "g" can be the old leader with ->mm == NULL
+	 *	and already unhashed and thus removed from ->thread_group.
+	 *	This is OK, __unhash_process()->list_del_rcu() does not
+	 *	clear the ->next pointer, we will find the new leader via
+	 *	next_thread().
+	 */
 	rcu_read_lock();
 	for_each_process(g) {
 		if (g == tsk->group_leader)
@@ -1549,17 +1578,13 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 		do {
 			if (p->mm) {
 				if (p->mm == mm) {
-					/*
-					 * p->sighand can't disappear, but
-					 * may be changed by de_thread()
-					 */
 					lock_task_sighand(p, &flags);
 					zap_process(p);
 					unlock_task_sighand(p, &flags);
 				}
 				break;
 			}
-		} while ((p = next_thread(p)) != g);
+		} while_each_thread(g, p);
 	}
 	rcu_read_unlock();
 done:

commit ba92a43dbaee339cf5915ef766d3d3ffbaaf103c
Author: Hugh Dickins <hugh@veritas.com>
Date:   Fri Jul 25 01:45:43 2008 -0700

    exec: remove some includes
    
    fs/exec.c used to need mman.h pagemap.h swap.h and rmap.h when it did
    mm-ish stuff in install_arg_page(); but no need for them after 2.6.22.
    
    [akpm@linux-foundation.org: unbreak arm]
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 190ed1f92774..e41aef0fb351 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -25,19 +25,18 @@
 #include <linux/slab.h>
 #include <linux/file.h>
 #include <linux/fdtable.h>
-#include <linux/mman.h>
+#include <linux/mm.h>
 #include <linux/stat.h>
 #include <linux/fcntl.h>
 #include <linux/smp_lock.h>
+#include <linux/swap.h>
 #include <linux/string.h>
 #include <linux/init.h>
-#include <linux/pagemap.h>
 #include <linux/highmem.h>
 #include <linux/spinlock.h>
 #include <linux/key.h>
 #include <linux/personality.h>
 #include <linux/binfmts.h>
-#include <linux/swap.h>
 #include <linux/utsname.h>
 #include <linux/pid_namespace.h>
 #include <linux/module.h>
@@ -47,7 +46,6 @@
 #include <linux/mount.h>
 #include <linux/security.h>
 #include <linux/syscalls.h>
-#include <linux/rmap.h>
 #include <linux/tsacct_kern.h>
 #include <linux/cn_proc.h>
 #include <linux/audit.h>

commit 42b7772812d15b86543a23b82bd6070eef9a08b1
Author: Jan Beulich <jbeulich@novell.com>
Date:   Wed Jul 23 21:27:10 2008 -0700

    mm: remove double indirection on tlb parameter to free_pgd_range() & Co
    
    The double indirection here is not needed anywhere and hence (at least)
    confusing.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: Nick Piggin <npiggin@suse.de>
    Cc: Christoph Lameter <cl@linux-foundation.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Acked-by: Jeremy Fitzhardinge <jeremy@goop.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index fd9234379e8d..190ed1f92774 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -541,7 +541,7 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 		/*
 		 * when the old and new regions overlap clear from new_end.
 		 */
-		free_pgd_range(&tlb, new_end, old_end, new_end,
+		free_pgd_range(tlb, new_end, old_end, new_end,
 			vma->vm_next ? vma->vm_next->vm_start : 0);
 	} else {
 		/*
@@ -550,7 +550,7 @@ static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 		 * have constraints on va-space that make this illegal (IA64) -
 		 * for the others its just a little faster.
 		 */
-		free_pgd_range(&tlb, old_start, old_end, new_end,
+		free_pgd_range(tlb, old_start, old_end, new_end,
 			vma->vm_next ? vma->vm_next->vm_start : 0);
 	}
 	tlb_finish_mmu(tlb, new_end, old_end);

commit 96a8e13ed44e380fc2bb6c711d74d5ba698c00b2
Author: Hugh Dickins <hugh@veritas.com>
Date:   Thu Jul 10 21:19:20 2008 +0100

    exec: fix stack excutability without PT_GNU_STACK
    
    Kernel Bugzilla #11063 points out that on some architectures (e.g. x86_32)
    exec'ing an ELF without a PT_GNU_STACK program header should default to an
    executable stack; but this got broken by the unlimited argv feature because
    stack vma is now created before the right personality has been established:
    so breaking old binaries using nested function trampolines.
    
    Therefore re-evaluate VM_STACK_FLAGS in setup_arg_pages, where stack
    vm_flags used to be set, before the mprotect_fixup.  Checking through
    our existing VM_flags, none would have changed since insert_vm_struct:
    so this seems safer than finding a way through the personality labyrinth.
    
    Reported-by: pageexec@freemail.hu
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index da94a6f05df3..fd9234379e8d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -610,7 +610,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	bprm->exec -= stack_shift;
 
 	down_write(&mm->mmap_sem);
-	vm_flags = vma->vm_flags;
+	vm_flags = VM_STACK_FLAGS;
 
 	/*
 	 * Adjust stack execute permissions; explicitly enable for

commit 702773b16e83fcddc41e0019b8214d3c3cecedbe
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Mon Jun 16 12:11:54 2008 +0100

    Include <asm/a.out.h> in fs/exec.c only for Alpha.
    
    We only need it for the /sbin/loader hack for OSF/1 executables, and we
    don't want to include it otherwise.
    
    While we're at it, remove the redundant '&& CONFIG_ARCH_SUPPORTS_AOUT'
    in the ifdef around that code. It's already dependent on __alpha__, and
    CONFIG_ARCH_SUPPORTS_AOUT is hard-coded to 'y' there.
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>
    Acked-by: Peter Korsgaard <jacmet@sunsite.dk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9448f1b50b4a..da94a6f05df3 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -26,7 +26,6 @@
 #include <linux/file.h>
 #include <linux/fdtable.h>
 #include <linux/mman.h>
-#include <linux/a.out.h>
 #include <linux/stat.h>
 #include <linux/fcntl.h>
 #include <linux/smp_lock.h>
@@ -61,6 +60,11 @@
 #include <linux/kmod.h>
 #endif
 
+#ifdef __alpha__
+/* for /sbin/loader handling in search_binary_handler() */
+#include <linux/a.out.h>
+#endif
+
 int core_uses_pid;
 char core_pattern[CORENAME_MAX_SIZE] = "core";
 int suid_dumpable = 0;
@@ -1155,7 +1159,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 {
 	int try,retval;
 	struct linux_binfmt *fmt;
-#if defined(__alpha__) && defined(CONFIG_ARCH_SUPPORTS_AOUT)
+#ifdef __alpha__
 	/* handle /sbin/loader.. */
 	{
 	    struct exec * eh = (struct exec *) bprm->buf;

commit cbaffba12ce08beb3e80bfda148ee0fa14aac188
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon May 26 20:55:42 2008 +0400

    posix timers: discard SI_TIMER signals on exec
    
    Based on Roland's patch. This approach was suggested by Austin Clements
    from the very beginning, and then by Linus.
    
    As Austin pointed out, the execing task can be killed by SI_TIMER signal
    because exec flushes the signal handlers, but doesn't discard the pending
    signals generated by posix timers. Perhaps not a bug, but people find this
    surprising. See http://bugzilla.kernel.org/show_bug.cgi?id=10460
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Austin Clements <amdragon+kernelbugzilla@mit.edu>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 3c2ba7ce11d4..9448f1b50b4a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -860,6 +860,7 @@ static int de_thread(struct task_struct *tsk)
 
 no_thread_group:
 	exit_itimers(sig);
+	flush_itimer_signals();
 	if (leader)
 		release_task(leader);
 

commit 08a6fac1c63233c87eec129938022f1a9a4d51f6
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat May 10 16:38:25 2008 -0400

    [PATCH] get rid of leak in compat_execve()
    
    Even though copy_compat_strings() doesn't cache the pages,
    copy_strings_kernel() and stuff indirectly called by e.g.
    ->load_binary() is doing that, so we need to drop the
    cache contents in the end.
    
    [found by WANG Cong <wangcong@zeuux.org>]
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 1f8a24aa1f8b..3c2ba7ce11d4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1251,6 +1251,12 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 
 EXPORT_SYMBOL(search_binary_handler);
 
+void free_bprm(struct linux_binprm *bprm)
+{
+	free_arg_pages(bprm);
+	kfree(bprm);
+}
+
 /*
  * sys_execve() executes a new program.
  */
@@ -1320,17 +1326,15 @@ int do_execve(char * filename,
 	retval = search_binary_handler(bprm,regs);
 	if (retval >= 0) {
 		/* execve success */
-		free_arg_pages(bprm);
 		security_bprm_free(bprm);
 		acct_update_integrals(current);
-		kfree(bprm);
+		free_bprm(bprm);
 		if (displaced)
 			put_files_struct(displaced);
 		return retval;
 	}
 
 out:
-	free_arg_pages(bprm);
 	if (bprm->security)
 		security_bprm_free(bprm);
 
@@ -1344,7 +1348,7 @@ int do_execve(char * filename,
 		fput(bprm->file);
 	}
 out_kfree:
-	kfree(bprm);
+	free_bprm(bprm);
 
 out_files:
 	if (displaced)

commit 4cd1a8fc3d3cd740416b14ece2693dbb5d065eaf
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Mon May 12 14:02:31 2008 -0700

    memcg: fix possible panic when CONFIG_MM_OWNER=y
    
    When mm destruction happens, we should pass mm_update_next_owner() the old mm.
     But unfortunately new mm is passed in exec_mmap().
    
    Thus, kernel panic is possible when a multi-threaded process uses exec().
    
    Also, the owner member comment description is wrong.  mm->owner does not
    necessarily point to the thread group leader.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Acked-by: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: "Paul Menage" <menage@google.com>
    Cc: "KAMEZAWA Hiroyuki" <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index aeaa9791d8be..1f8a24aa1f8b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -736,7 +736,7 @@ static int exec_mmap(struct mm_struct *mm)
 	tsk->active_mm = mm;
 	activate_mm(active_mm, mm);
 	task_unlock(tsk);
-	mm_update_next_owner(mm);
+	mm_update_next_owner(old_mm);
 	arch_pick_mmap_layout(mm);
 	if (old_mm) {
 		up_read(&old_mm->mmap_sem);

commit 9f3acc3140444a900ab280de942291959f0f615d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Apr 24 07:44:08 2008 -0400

    [PATCH] split linux/file.h
    
    Initial splitoff of the low-level stuff; taken to fdtable.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 9f9f931ef949..aeaa9791d8be 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -24,6 +24,7 @@
 
 #include <linux/slab.h>
 #include <linux/file.h>
+#include <linux/fdtable.h>
 #include <linux/mman.h>
 #include <linux/a.out.h>
 #include <linux/stat.h>

commit 2800d8d19e51414403df8144eaa214bb03400b87
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:53:12 2008 -0700

    document de_thread() with exit_notify() connection
    
    Add a couple of small comments, it is not easy to see what this code does.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 8fccc276d40d..9f9f931ef949 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -798,7 +798,7 @@ static int de_thread(struct task_struct *tsk)
 	if (!thread_group_leader(tsk)) {
 		leader = tsk->group_leader;
 
-		sig->notify_count = -1;
+		sig->notify_count = -1;	/* for exit_notify() */
 		for (;;) {
 			write_lock_irq(&tasklist_lock);
 			if (likely(leader->exit_state))

commit 7a5e873f096e04e6d8719e4ecb7b70d2decca503
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:53:04 2008 -0700

    signals: de_thread: simplify the ->child_reaper switching
    
    Now that we rely on SIGNAL_UNKILLABLE flag, de_thread() doesn't need the nasty
    hack to kill the old ->child_reaper during the mt-exec.
    
    This also means we can avoid taking tasklist_lock around zap_other_threads().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a13883903ee9..8fccc276d40d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -766,9 +766,7 @@ static int de_thread(struct task_struct *tsk)
 
 	/*
 	 * Kill all other threads in the thread group.
-	 * We must hold tasklist_lock to call zap_other_threads.
 	 */
-	read_lock(&tasklist_lock);
 	spin_lock_irq(lock);
 	if (signal_group_exit(sig)) {
 		/*
@@ -776,21 +774,10 @@ static int de_thread(struct task_struct *tsk)
 		 * return so that the signal is processed.
 		 */
 		spin_unlock_irq(lock);
-		read_unlock(&tasklist_lock);
 		return -EAGAIN;
 	}
-
-	/*
-	 * child_reaper ignores SIGKILL, change it now.
-	 * Reparenting needs write_lock on tasklist_lock,
-	 * so it is safe to do it under read_lock.
-	 */
-	if (unlikely(tsk->group_leader == task_child_reaper(tsk)))
-		task_active_pid_ns(tsk)->child_reaper = tsk;
-
 	sig->group_exit_task = tsk;
 	zap_other_threads(tsk);
-	read_unlock(&tasklist_lock);
 
 	/* Account for the thread group leader hanging around: */
 	count = thread_group_leader(tsk) ? 1 : 2;
@@ -821,6 +808,8 @@ static int de_thread(struct task_struct *tsk)
 			schedule();
 		}
 
+		if (unlikely(task_child_reaper(tsk) == leader))
+			task_active_pid_ns(tsk)->child_reaper = tsk;
 		/*
 		 * The only record we have of the real-time age of a
 		 * process, regardless of execs it's done, is start_time.

commit 925d1c401fa6cfd0df5d2e37da8981494ccdec07
Author: Matt Helsley <matthltc@us.ibm.com>
Date:   Tue Apr 29 01:01:36 2008 -0700

    procfs task exe symlink
    
    The kernel implements readlink of /proc/pid/exe by getting the file from
    the first executable VMA.  Then the path to the file is reconstructed and
    reported as the result.
    
    Because of the VMA walk the code is slightly different on nommu systems.
    This patch avoids separate /proc/pid/exe code on nommu systems.  Instead of
    walking the VMAs to find the first executable file-backed VMA we store a
    reference to the exec'd file in the mm_struct.
    
    That reference would prevent the filesystem holding the executable file
    from being unmounted even after unmapping the VMAs.  So we track the number
    of VM_EXECUTABLE VMAs and drop the new reference when the last one is
    unmapped.  This avoids pinning the mounted filesystem.
    
    [akpm@linux-foundation.org: improve comments]
    [yamamoto@valinux.co.jp: fix dup_mmap]
    Signed-off-by: Matt Helsley <matthltc@us.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: David Howells <dhowells@redhat.com>
    Cc:"Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: YAMAMOTO Takashi <yamamoto@valinux.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 711bc45d789c..a13883903ee9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -964,6 +964,8 @@ int flush_old_exec(struct linux_binprm * bprm)
 	if (retval)
 		goto out;
 
+	set_mm_exe_file(bprm->mm, bprm->file);
+
 	/*
 	 * Release all of the old mmap stuff
 	 */

commit cf475ad28ac35cc9ba612d67158f29b73b38b05d
Author: Balbir Singh <balbir@linux.vnet.ibm.com>
Date:   Tue Apr 29 01:00:16 2008 -0700

    cgroups: add an owner to the mm_struct
    
    Remove the mem_cgroup member from mm_struct and instead adds an owner.
    
    This approach was suggested by Paul Menage.  The advantage of this approach
    is that, once the mm->owner is known, using the subsystem id, the cgroup
    can be determined.  It also allows several control groups that are
    virtually grouped by mm_struct, to exist independent of the memory
    controller i.e., without adding mem_cgroup's for each controller, to
    mm_struct.
    
    A new config option CONFIG_MM_OWNER is added and the memory resource
    controller selects this config option.
    
    This patch also adds cgroup callbacks to notify subsystems when mm->owner
    changes.  The mm_cgroup_changed callback is called with the task_lock() of
    the new task held and is called just prior to changing the mm->owner.
    
    I am indebted to Paul Menage for the several reviews of this patchset and
    helping me make it lighter and simpler.
    
    This patch was tested on a powerpc box, it was compiled with both the
    MM_OWNER config turned on and off.
    
    After the thread group leader exits, it's moved to init_css_state by
    cgroup_exit(), thus all future charges from runnings threads would be
    redirected to the init_css_set's subsystem.
    
    Signed-off-by: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Pavel Emelianov <xemul@openvz.org>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: Sudhir Kumar <skumar@linux.vnet.ibm.com>
    Cc: YAMAMOTO Takashi <yamamoto@valinux.co.jp>
    Cc: Hirokazu Takahashi <taka@valinux.co.jp>
    Cc: David Rientjes <rientjes@google.com>,
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Reviewed-by: Paul Menage <menage@google.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7768453dc986..711bc45d789c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -735,6 +735,7 @@ static int exec_mmap(struct mm_struct *mm)
 	tsk->active_mm = mm;
 	activate_mm(active_mm, mm);
 	task_unlock(tsk);
+	mm_update_next_owner(mm);
 	arch_pick_mmap_layout(mm);
 	if (old_mm) {
 		up_read(&old_mm->mmap_sem);

commit 175a06ae300188af8a61db68a78e1af44dc7d44f
Author: Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp>
Date:   Tue Apr 29 00:59:17 2008 -0700

    exec: remove argv_len from struct linux_binprm
    
    I noticed that 2.6.24.2 calculates bprm->argv_len at do_execve().  But it
    doesn't update bprm->argv_len after "remove_arg_zero() +
    copy_strings_kernel()" at load_script() etc.
    
    audit_bprm() is called from search_binary_handler() and
    search_binary_handler() is called from load_script() etc.  Thus, I think the
    condition check
    
      if (bprm->argv_len > (audit_argv_kb << 10))
              return -E2BIG;
    
    in audit_bprm() might return wrong result when strlen(removed_arg) !=
    strlen(spliced_args).  Why not update bprm->argv_len at load_script() etc.  ?
    
    By the way, 2.6.25-rc3 seems to not doing the condition check.  Is the field
    bprm->argv_len no longer needed?
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Cc: Ollie Wild <aaw@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index b152029f18f6..7768453dc986 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1268,7 +1268,6 @@ int do_execve(char * filename,
 {
 	struct linux_binprm *bprm;
 	struct file *file;
-	unsigned long env_p;
 	struct files_struct *displaced;
 	int retval;
 
@@ -1321,11 +1320,9 @@ int do_execve(char * filename,
 	if (retval < 0)
 		goto out;
 
-	env_p = bprm->p;
 	retval = copy_strings(bprm->argc, argv, bprm);
 	if (retval < 0)
 		goto out;
-	bprm->argv_len = env_p - bprm->p;
 
 	retval = search_binary_handler(bprm,regs);
 	if (retval >= 0) {

commit 3b1253880b7a9e6db54b943b2d40bcf2202f58ab
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Apr 22 05:31:30 2008 -0400

    [PATCH] sanitize unshare_files/reset_files_struct
    
    * let unshare_files() give caller the displaced files_struct
    * don't bother with grabbing reference only to drop it in the
      caller if it hadn't been shared in the first place
    * in that form unshare_files() is trivially implemented via
      unshare_fd(), so we eliminate the duplicate logics in fork.c
    * reset_files_struct() is not just only called for current;
      it will break the system if somebody ever calls it for anything
      else (we can't modify ->files of somebody else).  Lose the
      task_struct * argument.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 475543002f13..b152029f18f6 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1269,19 +1269,13 @@ int do_execve(char * filename,
 	struct linux_binprm *bprm;
 	struct file *file;
 	unsigned long env_p;
-	struct files_struct *files;
+	struct files_struct *displaced;
 	int retval;
 
-	files = current->files;
-	retval = unshare_files();
+	retval = unshare_files(&displaced);
 	if (retval)
 		goto out_ret;
 
-	if (files == current->files) {
-		put_files_struct(files);
-		files = NULL;
-	}
-
 	retval = -ENOMEM;
 	bprm = kzalloc(sizeof(*bprm), GFP_KERNEL);
 	if (!bprm)
@@ -1340,8 +1334,8 @@ int do_execve(char * filename,
 		security_bprm_free(bprm);
 		acct_update_integrals(current);
 		kfree(bprm);
-		if (files)
-			put_files_struct(files);
+		if (displaced)
+			put_files_struct(displaced);
 		return retval;
 	}
 
@@ -1363,8 +1357,8 @@ int do_execve(char * filename,
 	kfree(bprm);
 
 out_files:
-	if (files)
-		reset_files_struct(current, files);
+	if (displaced)
+		reset_files_struct(displaced);
 out_ret:
 	return retval;
 }

commit fd8328be874f4190a811c58cd4778ec2c74d2c05
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Apr 22 05:11:59 2008 -0400

    [PATCH] sanitize handling of shared descriptor tables in failing execve()
    
    * unshare_files() can fail; doing it after irreversible actions is wrong
      and de_thread() is certainly irreversible.
    * since we do it unconditionally anyway, we might as well do it in do_execve()
      and save ourselves the PITA in binfmt handlers, etc.
    * while we are at it, binfmt_som actually leaked files_struct on failure.
    
    As a side benefit, unshare_files(), put_files_struct() and reset_files_struct()
    become unexported.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 54a0a557b678..475543002f13 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -953,7 +953,6 @@ int flush_old_exec(struct linux_binprm * bprm)
 {
 	char * name;
 	int i, ch, retval;
-	struct files_struct *files;
 	char tcomm[sizeof(current->comm)];
 
 	/*
@@ -964,27 +963,16 @@ int flush_old_exec(struct linux_binprm * bprm)
 	if (retval)
 		goto out;
 
-	/*
-	 * Make sure we have private file handles. Ask the
-	 * fork helper to do the work for us and the exit
-	 * helper to do the cleanup of the old one.
-	 */
-	files = current->files;		/* refcounted so safe to hold */
-	retval = unshare_files();
-	if (retval)
-		goto out;
 	/*
 	 * Release all of the old mmap stuff
 	 */
 	retval = exec_mmap(bprm->mm);
 	if (retval)
-		goto mmap_failed;
+		goto out;
 
 	bprm->mm = NULL;		/* We're using it now */
 
 	/* This is the point of no return */
-	put_files_struct(files);
-
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
 	if (current->euid == current->uid && current->egid == current->gid)
@@ -1034,8 +1022,6 @@ int flush_old_exec(struct linux_binprm * bprm)
 
 	return 0;
 
-mmap_failed:
-	reset_files_struct(current, files);
 out:
 	return retval;
 }
@@ -1283,12 +1269,23 @@ int do_execve(char * filename,
 	struct linux_binprm *bprm;
 	struct file *file;
 	unsigned long env_p;
+	struct files_struct *files;
 	int retval;
 
+	files = current->files;
+	retval = unshare_files();
+	if (retval)
+		goto out_ret;
+
+	if (files == current->files) {
+		put_files_struct(files);
+		files = NULL;
+	}
+
 	retval = -ENOMEM;
 	bprm = kzalloc(sizeof(*bprm), GFP_KERNEL);
 	if (!bprm)
-		goto out_ret;
+		goto out_files;
 
 	file = open_exec(filename);
 	retval = PTR_ERR(file);
@@ -1343,6 +1340,8 @@ int do_execve(char * filename,
 		security_bprm_free(bprm);
 		acct_update_integrals(current);
 		kfree(bprm);
+		if (files)
+			put_files_struct(files);
 		return retval;
 	}
 
@@ -1363,6 +1362,9 @@ int do_execve(char * filename,
 out_kfree:
 	kfree(bprm);
 
+out_files:
+	if (files)
+		reset_files_struct(current, files);
 out_ret:
 	return retval;
 }

commit a64e715fc74b1a7dcc5944f848acc38b2c4d4ee2
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Mon Mar 3 10:12:14 2008 -0800

    Allow ARG_MAX execve string space even with a small stack limit
    
    The new code that removed the limitation on the execve string size
    (which was historically 32 pages) replaced it with a much softer limit
    based on RLIMIT_STACK which is usually much larger than the traditional
    limit.  See commit b6a2fea39318e43fee84fa7b0b90d68bed92d2ba ("mm:
    variable length argument support") for details.
    
    However, if you have a small stack limit (perhaps because you need lots
    of stacks in a threaded environment), the new heuristic of allowing up
    to 1/4th of RLIMIT_STACK to be used for argument and environment strings
    could actually be smaller than the old limit.
    
    So just say that it's ok to have up to ARG_MAX strings regardless of the
    value of RLIMIT_STACK, and check the rlimit only when going over that
    traditional limit.
    
    (Of course, if you actually have a *really* small stack limit, the whole
    stack itself will be limited before you hit ARG_MAX, but that has always
    been true and is clearly the right behaviour anyway).
    
    Acked-by: Carlos O'Donell <carlos@codesourcery.com>
    Cc: Michael Kerrisk <michael.kerrisk@googlemail.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Ollie Wild <aaw@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index a44b142fb460..54a0a557b678 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -173,8 +173,15 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		return NULL;
 
 	if (write) {
-		struct rlimit *rlim = current->signal->rlim;
 		unsigned long size = bprm->vma->vm_end - bprm->vma->vm_start;
+		struct rlimit *rlim;
+
+		/*
+		 * We've historically supported up to 32 pages (ARG_MAX)
+		 * of argument strings even with small stacks
+		 */
+		if (size <= ARG_MAX)
+			return page;
 
 		/*
 		 * Limit to 1/4-th the stack size for the argv+env strings.
@@ -183,6 +190,7 @@ static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
 		 *  - the program will have a reasonable amount of stack left
 		 *    to work from.
 		 */
+		rlim = current->signal->rlim;
 		if (size > rlim[RLIMIT_STACK].rlim_cur / 4) {
 			put_page(page);
 			return NULL;

commit 1d957f9bf87da74f420424d16ece005202bbebd3
Author: Jan Blunck <jblunck@suse.de>
Date:   Thu Feb 14 19:34:35 2008 -0800

    Introduce path_put()
    
    * Add path_put() functions for releasing a reference to the dentry and
      vfsmount of a struct path in the right order
    
    * Switch from path_release(nd) to path_put(&nd->path)
    
    * Rename dput_path() to path_put_conditional()
    
    [akpm@linux-foundation.org: fix cifs]
    Signed-off-by: Jan Blunck <jblunck@suse.de>
    Signed-off-by: Andreas Gruenbacher <agruen@suse.de>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Cc: <linux-fsdevel@vger.kernel.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Steven French <sfrench@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7a12d2d1ac11..a44b142fb460 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -148,7 +148,7 @@ asmlinkage long sys_uselib(const char __user * library)
   	return error;
 exit:
 	release_open_intent(&nd);
-	path_release(&nd);
+	path_put(&nd.path);
 	goto out;
 }
 
@@ -672,7 +672,7 @@ struct file *open_exec(const char *name)
 			}
 		}
 		release_open_intent(&nd);
-		path_release(&nd);
+		path_put(&nd.path);
 	}
 	goto out;
 }

commit 4ac9137858e08a19f29feac4e1f4df7c268b0ba5
Author: Jan Blunck <jblunck@suse.de>
Date:   Thu Feb 14 19:34:32 2008 -0800

    Embed a struct path into struct nameidata instead of nd->{dentry,mnt}
    
    This is the central patch of a cleanup series. In most cases there is no good
    reason why someone would want to use a dentry for itself. This series reflects
    that fact and embeds a struct path into nameidata.
    
    Together with the other patches of this series
    - it enforced the correct order of getting/releasing the reference count on
      <dentry,vfsmount> pairs
    - it prepares the VFS for stacking support since it is essential to have a
      struct path in every place where the stack can be traversed
    - it reduces the overall code size:
    
    without patch series:
       text    data     bss     dec     hex filename
    5321639  858418  715768 6895825  6938d1 vmlinux
    
    with patch series:
       text    data     bss     dec     hex filename
    5320026  858418  715768 6894212  693284 vmlinux
    
    This patch:
    
    Switch from nd->{dentry,mnt} to nd->path.{dentry,mnt} everywhere.
    
    [akpm@linux-foundation.org: coding-style fixes]
    [akpm@linux-foundation.org: fix cifs]
    [akpm@linux-foundation.org: fix smack]
    Signed-off-by: Jan Blunck <jblunck@suse.de>
    Signed-off-by: Andreas Gruenbacher <agruen@suse.de>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Casey Schaufler <casey@schaufler-ca.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9ff6069094d8..7a12d2d1ac11 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -112,7 +112,7 @@ asmlinkage long sys_uselib(const char __user * library)
 		goto out;
 
 	error = -EINVAL;
-	if (!S_ISREG(nd.dentry->d_inode->i_mode))
+	if (!S_ISREG(nd.path.dentry->d_inode->i_mode))
 		goto exit;
 
 	error = vfs_permission(&nd, MAY_READ | MAY_EXEC);
@@ -652,7 +652,7 @@ struct file *open_exec(const char *name)
 	file = ERR_PTR(err);
 
 	if (!err) {
-		struct inode *inode = nd.dentry->d_inode;
+		struct inode *inode = nd.path.dentry->d_inode;
 		file = ERR_PTR(-EACCES);
 		if (S_ISREG(inode->i_mode)) {
 			int err = vfs_permission(&nd, MAY_EXEC);

commit abe8be3abe4c2043bd766f32d7eba62c12dbb0b3
Author: Andi Kleen <andi@firstfloor.org>
Date:   Fri Feb 8 04:20:23 2008 -0800

    Allow executables larger than 2GB
    
    This allows us to use executables >2GB.
    
    Based on a patch by Dave Anderson
    
    Signed-off-by: Andi Kleen <ak@suse.de>
    Cc: Dave Anderson <anderson@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9f9c27224d7c..9ff6069094d8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -119,7 +119,7 @@ asmlinkage long sys_uselib(const char __user * library)
 	if (error)
 		goto exit;
 
-	file = nameidata_to_filp(&nd, O_RDONLY);
+	file = nameidata_to_filp(&nd, O_RDONLY|O_LARGEFILE);
 	error = PTR_ERR(file);
 	if (IS_ERR(file))
 		goto out;
@@ -658,7 +658,8 @@ struct file *open_exec(const char *name)
 			int err = vfs_permission(&nd, MAY_EXEC);
 			file = ERR_PTR(err);
 			if (!err) {
-				file = nameidata_to_filp(&nd, O_RDONLY);
+				file = nameidata_to_filp(&nd,
+							O_RDONLY|O_LARGEFILE);
 				if (!IS_ERR(file)) {
 					err = deny_write_access(file);
 					if (err) {

commit 7fa3031500ec9b0a7460c8c23751799006ffee74
Author: David Howells <dhowells@redhat.com>
Date:   Fri Feb 8 04:19:28 2008 -0800

    aout: suppress A.OUT library support if !CONFIG_ARCH_SUPPORTS_AOUT
    
    Suppress A.OUT library support if CONFIG_ARCH_SUPPORTS_AOUT is not set.
    
    Not all architectures support the A.OUT binfmt, so the ELF binfmt should not
    be permitted to go looking for A.OUT libraries to load in such a case.  Not
    only that, but under such conditions A.OUT core dumps are not produced either.
    
    To make this work, this patch also does the following:
    
     (1) Makes the existence of the contents of linux/a.out.h contingent on
         CONFIG_ARCH_SUPPORTS_AOUT.
    
     (2) Renames dump_thread() to aout_dump_thread() as it's only called by A.OUT
         core dumping code.
    
     (3) Moves aout_dump_thread() into asm/a.out-core.h and makes it inline.  This
         is then included only where needed.  This means that this bit of arch
         code will be stored in the appropriate A.OUT binfmt module rather than
         the core kernel.
    
     (4) Drops A.OUT support for Blackfin (according to Mike Frysinger it's not
         needed) and FRV.
    
    This patch depends on the previous patch to move STACK_TOP[_MAX] out of
    asm/a.out.h and into asm/processor.h as they're required whether or not A.OUT
    format is available.
    
    [jdike@addtoit.com: uml: re-remove accidentally restored code]
    Signed-off-by: David Howells <dhowells@redhat.com>
    Cc: <linux-arch@vger.kernel.org>
    Signed-off-by: Jeff Dike <jdike@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 927a7c5ef4af..9f9c27224d7c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1166,7 +1166,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 {
 	int try,retval;
 	struct linux_binfmt *fmt;
-#ifdef __alpha__
+#if defined(__alpha__) && defined(CONFIG_ARCH_SUPPORTS_AOUT)
 	/* handle /sbin/loader.. */
 	{
 	    struct exec * eh = (struct exec *) bprm->buf;

commit fea9d175545b38cb3e84569400419eb81bc90fa3
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Feb 8 04:19:19 2008 -0800

    ITIMER_REAL: convert to use struct pid
    
    signal_struct->tsk points to the ->group_leader and thus we have the nasty
    code in de_thread() which has to change it and restart ->real_timer if the
    leader is changed.
    
    Use "struct pid *leader_pid" instead.  This also allows us to kill now
    unneeded send_group_sig_info().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Roland McGrath <roland@redhat.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index be923e4bc389..927a7c5ef4af 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -782,26 +782,8 @@ static int de_thread(struct task_struct *tsk)
 	zap_other_threads(tsk);
 	read_unlock(&tasklist_lock);
 
-	/*
-	 * Account for the thread group leader hanging around:
-	 */
-	count = 1;
-	if (!thread_group_leader(tsk)) {
-		count = 2;
-		/*
-		 * The SIGALRM timer survives the exec, but needs to point
-		 * at us as the new group leader now.  We have a race with
-		 * a timer firing now getting the old leader, so we need to
-		 * synchronize with any firing (by calling del_timer_sync)
-		 * before we can safely let the old group leader die.
-		 */
-		sig->tsk = tsk;
-		spin_unlock_irq(lock);
-		if (hrtimer_cancel(&sig->real_timer))
-			hrtimer_restart(&sig->real_timer);
-		spin_lock_irq(lock);
-	}
-
+	/* Account for the thread group leader hanging around: */
+	count = thread_group_leader(tsk) ? 1 : 2;
 	sig->notify_count = count;
 	while (atomic_read(&sig->count) > count) {
 		__set_current_state(TASK_UNINTERRUPTIBLE);

commit ed5d2cac114202fe2978a9cbcab8f5032796d538
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Feb 4 22:27:24 2008 -0800

    exec: rework the group exit and fix the race with kill
    
    As Roland pointed out, we have the very old problem with exec.  de_thread()
    sets SIGNAL_GROUP_EXIT, kills other threads, changes ->group_leader and then
    clears signal->flags.  All signals (even fatal ones) sent in this window
    (which is not too small) will be lost.
    
    With this patch exec doesn't abuse SIGNAL_GROUP_EXIT.  signal_group_exit(),
    the new helper, should be used to detect exit_group() or exec() in progress.
    It can have more users, but this patch does only strictly necessary changes.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Robin Holt <holt@sgi.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 966c5c5b6741..be923e4bc389 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -760,7 +760,7 @@ static int de_thread(struct task_struct *tsk)
 	 */
 	read_lock(&tasklist_lock);
 	spin_lock_irq(lock);
-	if (sig->flags & SIGNAL_GROUP_EXIT) {
+	if (signal_group_exit(sig)) {
 		/*
 		 * Another group action in progress, just
 		 * return so that the signal is processed.
@@ -778,6 +778,7 @@ static int de_thread(struct task_struct *tsk)
 	if (unlikely(tsk->group_leader == task_child_reaper(tsk)))
 		task_active_pid_ns(tsk)->child_reaper = tsk;
 
+	sig->group_exit_task = tsk;
 	zap_other_threads(tsk);
 	read_unlock(&tasklist_lock);
 
@@ -802,7 +803,6 @@ static int de_thread(struct task_struct *tsk)
 	}
 
 	sig->notify_count = count;
-	sig->group_exit_task = tsk;
 	while (atomic_read(&sig->count) > count) {
 		__set_current_state(TASK_UNINTERRUPTIBLE);
 		spin_unlock_irq(lock);
@@ -871,15 +871,10 @@ static int de_thread(struct task_struct *tsk)
 		leader->exit_state = EXIT_DEAD;
 
 		write_unlock_irq(&tasklist_lock);
-        }
+	}
 
 	sig->group_exit_task = NULL;
 	sig->notify_count = 0;
-	/*
-	 * There may be one thread left which is just exiting,
-	 * but it's safe to stop telling the group to kill themselves.
-	 */
-	sig->flags = 0;
 
 no_thread_group:
 	exit_itimers(sig);
@@ -1549,7 +1544,7 @@ static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 	int err = -EAGAIN;
 
 	spin_lock_irq(&tsk->sighand->siglock);
-	if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT)) {
+	if (!signal_group_exit(tsk->signal)) {
 		tsk->signal->group_exit_code = exit_code;
 		zap_process(tsk);
 		err = 0;

commit 59714d65dfbc86d5cb93adc5bac57a921cc2fa84
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Mon Feb 4 22:27:21 2008 -0800

    get_task_comm(): return the result
    
    It was dumb to make get_task_comm() return void.  Change it to return a
    pointer to the resulting output for caller convenience.
    
    Cc: Ulrich Drepper <drepper@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 282240afe99e..966c5c5b6741 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -947,12 +947,13 @@ static void flush_old_files(struct files_struct * files)
 	spin_unlock(&files->file_lock);
 }
 
-void get_task_comm(char *buf, struct task_struct *tsk)
+char *get_task_comm(char *buf, struct task_struct *tsk)
 {
 	/* buf must be at least sizeof(tsk->comm) in size */
 	task_lock(tsk);
 	strncpy(buf, tsk->comm, sizeof(tsk->comm));
 	task_unlock(tsk);
+	return buf;
 }
 
 void set_task_comm(struct task_struct *tsk, char *buf)

commit c46f739dd39db3b07ab5deb4e3ec81e1c04a91af
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Nov 28 13:59:18 2007 +0100

    vfs: coredumping fix
    
    fix: http://bugzilla.kernel.org/show_bug.cgi?id=3043
    
    only allow coredumping to the same uid that the coredumping
    task runs under.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Alan Cox <alan@redhat.com>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Al Viro <viro@ftp.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4ccaaa4b13b2..282240afe99e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1780,6 +1780,12 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	   but keep the previous behaviour for now. */
 	if (!ispipe && !S_ISREG(inode->i_mode))
 		goto close_fail;
+	/*
+	 * Dont allow local users get cute and trick others to coredump
+	 * into their pre-created files:
+	 */
+	if (inode->i_uid != current->fsuid)
+		goto close_fail;
 	if (!file->f_op)
 		goto close_fail;
 	if (!file->f_op->write)

commit 00ec99da43a7c2aed46c6595aa271b84bb1b1462
Author: Roland McGrath <roland@redhat.com>
Date:   Sun Nov 11 19:13:43 2007 -0800

    core dump: remain dumpable
    
    The coredump code always calls set_dumpable(0) when it starts (even
    if RLIMIT_CORE prevents any core from being dumped).  The effect of
    this (via task_dumpable) is to make /proc/pid/* files owned by root
    instead of the user, so the user can no longer examine his own
    process--in a case where there was never any privileged data to
    protect.  This affects e.g. auxv, environ, fd; in Fedora (execshield)
    kernels, also maps.  In practice, you can only notice this when a
    debugger has requested PTRACE_EVENT_EXIT tracing.
    
    set_dumpable was only used in do_coredump for synchronization and not
    intended for any security purpose.  (It doesn't secure anything that wasn't
    already unsecured when a process dies by SIGTERM instead of SIGQUIT.)
    
    This changes do_coredump to check the core_waiters count as the means of
    synchronization, which is sufficient.  Now we leave the "dumpable" bits alone.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2c942e2d14ea..4ccaaa4b13b2 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1692,7 +1692,10 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	if (!binfmt || !binfmt->core_dump)
 		goto fail;
 	down_write(&mm->mmap_sem);
-	if (!get_dumpable(mm)) {
+	/*
+	 * If another thread got here first, or we are not dumpable, bail out.
+	 */
+	if (mm->core_waiters || !get_dumpable(mm)) {
 		up_write(&mm->mmap_sem);
 		goto fail;
 	}
@@ -1706,7 +1709,6 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		flag = O_EXCL;		/* Stop rewrite attacks */
 		current->fsuid = 0;	/* Dump root private */
 	}
-	set_dumpable(mm, 0);
 
 	retval = coredump_wait(exit_code);
 	if (retval < 0)

commit bac0abd6174e427404dd197cdbefece31e97329b
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:18 2007 -0700

    Isolate some explicit usage of task->tgid
    
    With pid namespaces this field is now dangerous to use explicitly, so hide
    it behind the helpers.
    
    Also the pid and pgrp fields o task_struct and signal_struct are to be
    deprecated.  Unfortunately this patch cannot be sent right now as this
    leads to tons of warnings, so start isolating them, and deprecate later.
    
    Actually the p->tgid == pid has to be changed to has_group_leader_pid(),
    but Oleg pointed out that in case of posix cpu timers this is the same, and
    thread_group_leader() is more preferable.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 007d0d814bf0..2c942e2d14ea 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -841,8 +841,8 @@ static int de_thread(struct task_struct *tsk)
 		 */
 		tsk->start_time = leader->start_time;
 
-		BUG_ON(leader->tgid != tsk->tgid);
-		BUG_ON(tsk->pid == tsk->tgid);
+		BUG_ON(!same_thread_group(leader, tsk));
+		BUG_ON(has_group_leader_pid(tsk));
 		/*
 		 * An exec() starts a new thread group with the
 		 * TGID of the previous thread group. Rehash the

commit b488893a390edfe027bae7a46e9af8083e740668
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:14 2007 -0700

    pid namespaces: changes to show virtual ids to user
    
    This is the largest patch in the set. Make all (I hope) the places where
    the pid is shown to or get from user operate on the virtual pids.
    
    The idea is:
     - all in-kernel data structures must store either struct pid itself
       or the pid's global nr, obtained with pid_nr() call;
     - when seeking the task from kernel code with the stored id one
       should use find_task_by_pid() call that works with global pids;
     - when showing pid's numerical value to the user the virtual one
       should be used, but however when one shows task's pid outside this
       task's namespace the global one is to be used;
     - when getting the pid from userspace one need to consider this as
       the virtual one and use appropriate task/pid-searching functions.
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: nuther build fix]
    [akpm@linux-foundation.org: yet nuther build fix]
    [akpm@linux-foundation.org: remove unneeded casts]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Alexey Dobriyan <adobriyan@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 92d2703d87b2..007d0d814bf0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1433,7 +1433,7 @@ static int format_corename(char *corename, const char *pattern, long signr)
 			case 'p':
 				pid_in_pattern = 1;
 				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%d", current->tgid);
+					      "%d", task_tgid_vnr(current));
 				if (rc > out_end - out_ptr)
 					goto out;
 				out_ptr += rc;
@@ -1513,7 +1513,7 @@ static int format_corename(char *corename, const char *pattern, long signr)
 	if (!ispipe && !pid_in_pattern
             && (core_uses_pid || atomic_read(&current->mm->mm_users) != 1)) {
 		rc = snprintf(out_ptr, out_end - out_ptr,
-			      ".%d", current->tgid);
+			      ".%d", task_tgid_vnr(current));
 		if (rc > out_end - out_ptr)
 			goto out;
 		out_ptr += rc;

commit 3743ca05ff464b8a9e345c08a6c9ce30485f9805
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu Oct 18 23:39:51 2007 -0700

    pid namespaces: use task_pid() to find leader's pid
    
    Use task_pid() to get leader's 'struct pid' and avoid the find_pid().
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4b5bbb87e494..92d2703d87b2 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -857,7 +857,7 @@ static int de_thread(struct task_struct *tsk)
 		 */
 		detach_pid(tsk, PIDTYPE_PID);
 		tsk->pid = leader->pid;
-		attach_pid(tsk, PIDTYPE_PID,  find_pid(tsk->pid));
+		attach_pid(tsk, PIDTYPE_PID,  task_pid(leader));
 		transfer_pid(leader, tsk, PIDTYPE_PGID);
 		transfer_pid(leader, tsk, PIDTYPE_SID);
 		list_replace_rcu(&leader->tasks, &tsk->tasks);

commit 88f21d818255bc61c002478d21caf52f8a9b8def
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu Oct 18 23:39:50 2007 -0700

    pid namespaces: rename child_reaper() function
    
    Rename the child_reaper() function to task_child_reaper() to be similar to
    other task_* functions and to distinguish the function from 'struct
    pid_namspace.child_reaper'.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6ffb769ed955..4b5bbb87e494 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -775,7 +775,7 @@ static int de_thread(struct task_struct *tsk)
 	 * Reparenting needs write_lock on tasklist_lock,
 	 * so it is safe to do it under read_lock.
 	 */
-	if (unlikely(tsk->group_leader == child_reaper(tsk)))
+	if (unlikely(tsk->group_leader == task_child_reaper(tsk)))
 		task_active_pid_ns(tsk)->child_reaper = tsk;
 
 	zap_other_threads(tsk);

commit 2894d650cd9715d00ca196c711265819ef6ebd2d
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu Oct 18 23:39:49 2007 -0700

    pid namespaces: define and use task_active_pid_ns() wrapper
    
    With multiple pid namespaces, a process is known by some pid_t in every
    ancestor pid namespace.  Every time the process forks, the child process also
    gets a pid_t in every ancestor pid namespace.
    
    While a process is visible in >=1 pid namespaces, it can see pid_t's in only
    one pid namespace.  We call this pid namespace it's "active pid namespace",
    and it is always the youngest pid namespace in which the process is known.
    
    This patch defines and uses a wrapper to find the active pid namespace of a
    process.  The implementation of the wrapper will be changed in when support
    for multiple pid namespaces are added.
    
    Changelog:
            2.6.22-rc4-mm2-pidns1:
            - [Pavel Emelianov, Alexey Dobriyan] Back out the change to use
              task_active_pid_ns() in child_reaper() since task->nsproxy
              can be NULL during task exit (so child_reaper() continues to
              use init_pid_ns).
    
              to implement child_reaper() since init_pid_ns.child_reaper to
              implement child_reaper() since tsk->nsproxy can be NULL during exit.
    
            2.6.21-rc6-mm1:
            - Rename task_pid_ns() to task_active_pid_ns() to reflect that a
              process can have multiple pid namespaces.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0b09447ae040..6ffb769ed955 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -776,7 +776,7 @@ static int de_thread(struct task_struct *tsk)
 	 * so it is safe to do it under read_lock.
 	 */
 	if (unlikely(tsk->group_leader == child_reaper(tsk)))
-		tsk->nsproxy->pid_ns->child_reaper = tsk;
+		task_active_pid_ns(tsk)->child_reaper = tsk;
 
 	zap_other_threads(tsk);
 	read_unlock(&tasklist_lock);

commit 3ed75eb8f1cd89565966599c4f77d2edb086d5b0
Author: Coly Li <coyli@suse.de>
Date:   Thu Oct 18 23:39:15 2007 -0700

    setup vma->vm_page_prot by vm_get_page_prot()
    
    This patch uses vm_get_page_prot() to setup vma->vm_page_prot.
    
    Though inside vm_get_page_prot() the protection flags is AND with
    (VM_READ|VM_WRITE|VM_EXEC|VM_SHARED), it does not hurt correct code.
    
    Signed-off-by: Coly Li <coyli@suse.de>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 070ddf13cb71..0b09447ae040 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -234,7 +234,7 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
 
 	vma->vm_flags = VM_STACK_FLAGS;
-	vma->vm_page_prot = protection_map[vma->vm_flags & 0x7];
+	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 	err = insert_vm_struct(mm, vma);
 	if (err) {
 		up_write(&mm->mmap_sem);

commit cbfee34520666862f8ff539e580c48958fbb7706
Author: Adrian Bunk <bunk@kernel.org>
Date:   Tue Oct 16 23:31:38 2007 -0700

    security/ cleanups
    
    This patch contains the following cleanups that are now possible:
    - remove the unused security_operations->inode_xattr_getsuffix
    - remove the no longer used security_operations->unregister_security
    - remove some no longer required exit code
    - remove a bunch of no longer used exports
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Acked-by: James Morris <jmorris@namei.org>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index aa470a93540a..070ddf13cb71 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -64,7 +64,6 @@ int core_uses_pid;
 char core_pattern[CORENAME_MAX_SIZE] = "core";
 int suid_dumpable = 0;
 
-EXPORT_SYMBOL(suid_dumpable);
 /* The maximal length of core_pattern is also specified in sysctl.c */
 
 static LIST_HEAD(formats);
@@ -1662,7 +1661,6 @@ void set_dumpable(struct mm_struct *mm, int value)
 		break;
 	}
 }
-EXPORT_SYMBOL_GPL(set_dumpable);
 
 int get_dumpable(struct mm_struct *mm)
 {

commit 6db840fa7887980ef68a649640d506fe069eef0c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Oct 16 23:27:23 2007 -0700

    exec: RT sub-thread can livelock and monopolize CPU on exec
    
    de_thread() yields waiting for ->group_leader to be a zombie. This deadlocks
    if an rt-prio execer shares the same cpu with ->group_leader. Change the code
    to use ->group_exit_task/notify_count mechanics.
    
    This patch certainly uglifies the code, perhaps someone can suggest something
    better.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ab5a4a3ece46..aa470a93540a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -801,16 +801,15 @@ static int de_thread(struct task_struct *tsk)
 			hrtimer_restart(&sig->real_timer);
 		spin_lock_irq(lock);
 	}
+
+	sig->notify_count = count;
+	sig->group_exit_task = tsk;
 	while (atomic_read(&sig->count) > count) {
-		sig->group_exit_task = tsk;
-		sig->notify_count = count;
 		__set_current_state(TASK_UNINTERRUPTIBLE);
 		spin_unlock_irq(lock);
 		schedule();
 		spin_lock_irq(lock);
 	}
-	sig->group_exit_task = NULL;
-	sig->notify_count = 0;
 	spin_unlock_irq(lock);
 
 	/*
@@ -819,14 +818,17 @@ static int de_thread(struct task_struct *tsk)
 	 * and to assume its PID:
 	 */
 	if (!thread_group_leader(tsk)) {
-		/*
-		 * Wait for the thread group leader to be a zombie.
-		 * It should already be zombie at this point, most
-		 * of the time.
-		 */
 		leader = tsk->group_leader;
-		while (leader->exit_state != EXIT_ZOMBIE)
-			yield();
+
+		sig->notify_count = -1;
+		for (;;) {
+			write_lock_irq(&tasklist_lock);
+			if (likely(leader->exit_state))
+				break;
+			__set_current_state(TASK_UNINTERRUPTIBLE);
+			write_unlock_irq(&tasklist_lock);
+			schedule();
+		}
 
 		/*
 		 * The only record we have of the real-time age of a
@@ -840,8 +842,6 @@ static int de_thread(struct task_struct *tsk)
 		 */
 		tsk->start_time = leader->start_time;
 
-		write_lock_irq(&tasklist_lock);
-
 		BUG_ON(leader->tgid != tsk->tgid);
 		BUG_ON(tsk->pid == tsk->tgid);
 		/*
@@ -874,6 +874,8 @@ static int de_thread(struct task_struct *tsk)
 		write_unlock_irq(&tasklist_lock);
         }
 
+	sig->group_exit_task = NULL;
+	sig->notify_count = 0;
 	/*
 	 * There may be one thread left which is just exiting,
 	 * but it's safe to stop telling the group to kill themselves.

commit 356d6d5058c8082b9e811838ab2fa27825c947e4
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Oct 16 23:27:23 2007 -0700

    exec: consolidate 2 fast-paths
    
    Now that we don't pre-allocate the new ->sighand, we can kill the first fast
    path, it doesn't make sense any longer. At best, it can save one "list_empty()"
    check but leads to the code duplication.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index c6e91c3dc2a1..ab5a4a3ece46 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -752,15 +752,6 @@ static int de_thread(struct task_struct *tsk)
 	struct task_struct *leader = NULL;
 	int count;
 
-	/*
-	 * If we don't share sighandlers, then we aren't sharing anything
-	 * and we can just re-use it all.
-	 */
-	if (atomic_read(&oldsighand->count) <= 1) {
-		exit_itimers(sig);
-		return 0;
-	}
-
 	if (thread_group_empty(tsk))
 		goto no_thread_group;
 

commit b2c903b8790467ae400f6992ac01bc8913b49e19
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Oct 16 23:27:22 2007 -0700

    exec: simplify the new ->sighand allocation
    
    de_thread() pre-allocates newsighand to make sure that exec() can't fail after
    killing all sub-threads. Imho, this buys nothing, but complicates the code:
    
            - this is (mostly) needed to handle CLONE_SIGHAND without CLONE_THREAD
              tasks, this is very unlikely (if ever used) case
    
            - unless we already have some serious problems, GFP_KERNEL allocation
              should not fail
    
            - ENOMEM still can happen after de_thread(), ->sighand is not the last
              object we have to allocate
    
    Change the code to allocate the new ->sighand on demand.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7f325df5e014..c6e91c3dc2a1 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -747,7 +747,7 @@ static int exec_mmap(struct mm_struct *mm)
 static int de_thread(struct task_struct *tsk)
 {
 	struct signal_struct *sig = tsk->signal;
-	struct sighand_struct *newsighand, *oldsighand = tsk->sighand;
+	struct sighand_struct *oldsighand = tsk->sighand;
 	spinlock_t *lock = &oldsighand->siglock;
 	struct task_struct *leader = NULL;
 	int count;
@@ -761,10 +761,6 @@ static int de_thread(struct task_struct *tsk)
 		return 0;
 	}
 
-	newsighand = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);
-	if (!newsighand)
-		return -ENOMEM;
-
 	if (thread_group_empty(tsk))
 		goto no_thread_group;
 
@@ -781,7 +777,6 @@ static int de_thread(struct task_struct *tsk)
 		 */
 		spin_unlock_irq(lock);
 		read_unlock(&tasklist_lock);
-		kmem_cache_free(sighand_cachep, newsighand);
 		return -EAGAIN;
 	}
 
@@ -899,17 +894,16 @@ static int de_thread(struct task_struct *tsk)
 	if (leader)
 		release_task(leader);
 
-	if (atomic_read(&oldsighand->count) == 1) {
-		/*
-		 * Now that we nuked the rest of the thread group,
-		 * it turns out we are not sharing sighand any more either.
-		 * So we can just keep it.
-		 */
-		kmem_cache_free(sighand_cachep, newsighand);
-	} else {
+	if (atomic_read(&oldsighand->count) != 1) {
+		struct sighand_struct *newsighand;
 		/*
-		 * Move our state over to newsighand and switch it in.
+		 * This ->sighand is shared with the CLONE_SIGHAND
+		 * but not CLONE_THREAD task, switch to the new one.
 		 */
+		newsighand = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);
+		if (!newsighand)
+			return -ENOMEM;
+
 		atomic_set(&newsighand->count, 1);
 		memcpy(newsighand->action, oldsighand->action,
 		       sizeof(newsighand->action));

commit 0840a90d943bcde2fbfeabd3c256236eed2273cd
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Oct 16 23:27:22 2007 -0700

    exec: simplify ->sighand switching
    
    There is no any reason to do recalc_sigpending() after changing ->sighand.
    To begin with, recalc_sigpending() does not take ->sighand into account.
    
    This means we don't need to take newsighand->siglock while changing sighands.
    rcu_assign_pointer() provides a necessary barrier, and if another process
    reads the new ->sighand it should either take tasklist_lock or it should use
    lock_task_sighand() which has a corresponding smp_read_barrier_depends().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 59c0038baa4f..7f325df5e014 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -916,12 +916,7 @@ static int de_thread(struct task_struct *tsk)
 
 		write_lock_irq(&tasklist_lock);
 		spin_lock(&oldsighand->siglock);
-		spin_lock_nested(&newsighand->siglock, SINGLE_DEPTH_NESTING);
-
 		rcu_assign_pointer(tsk->sighand, newsighand);
-		recalc_sigpending();
-
-		spin_unlock(&newsighand->siglock);
 		spin_unlock(&oldsighand->siglock);
 		write_unlock_irq(&tasklist_lock);
 
@@ -931,12 +926,11 @@ static int de_thread(struct task_struct *tsk)
 	BUG_ON(!thread_group_leader(tsk));
 	return 0;
 }
-	
+
 /*
  * These functions flushes out all traces of the currently running executable
  * so that a new one can be started
  */
-
 static void flush_old_files(struct files_struct * files)
 {
 	long j = -1;

commit 1a159dd229e6a70e3ffd3f785cb51fa61b232279
Author: Miklos Szeredi <mszeredi@suse.cz>
Date:   Tue Oct 16 23:27:08 2007 -0700

    exec: remove unnecessary check for MNT_NOEXEC
    
    vfs_permission(MAY_EXEC) checks if the filesystem is mounted with "noexec", so
    there's no need to repeat this check in sys_uselib() and open_exec().
    
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index cbd183daaad4..59c0038baa4f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -112,9 +112,6 @@ asmlinkage long sys_uselib(const char __user * library)
 	if (error)
 		goto out;
 
-	error = -EACCES;
-	if (nd.mnt->mnt_flags & MNT_NOEXEC)
-		goto exit;
 	error = -EINVAL;
 	if (!S_ISREG(nd.dentry->d_inode->i_mode))
 		goto exit;
@@ -658,8 +655,7 @@ struct file *open_exec(const char *name)
 	if (!err) {
 		struct inode *inode = nd.dentry->d_inode;
 		file = ERR_PTR(-EACCES);
-		if (!(nd.mnt->mnt_flags & MNT_NOEXEC) &&
-		    S_ISREG(inode->i_mode)) {
+		if (S_ISREG(inode->i_mode)) {
 			int err = vfs_permission(&nd, MAY_EXEC);
 			file = ERR_PTR(err);
 			if (!err) {

commit 323211371073ce4a99b6efc69379589d6a640d35
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Tue Oct 16 23:26:36 2007 -0700

    core_pattern: fix up a few miscellaneous bugs
    
    Fix do_coredump to detect a crash in the user mode helper process and abort
    the attempt to recursively dump core to another copy of the helper process,
    potentially ad-infinitum.
    
    [akpm@linux-foundation.org: cleanups]
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: <martin.pitt@ubuntu.com>
    Cc: <wwoods@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6450157062ea..cbd183daaad4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1762,14 +1762,27 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		goto fail_unlock;
 
  	if (ispipe) {
-		core_limit = RLIM_INFINITY;
 		helper_argv = argv_split(GFP_KERNEL, corename+1, &helper_argc);
 		/* Terminate the string before the first option */
 		delimit = strchr(corename, ' ');
 		if (delimit)
 			*delimit = '\0';
+		delimit = strrchr(helper_argv[0], '/');
+		if (delimit)
+			delimit++;
+		else
+			delimit = helper_argv[0];
+		if (!strcmp(delimit, current->comm)) {
+			printk(KERN_NOTICE "Recursive core dump detected, "
+					"aborting\n");
+			goto fail_unlock;
+		}
+
+		core_limit = RLIM_INFINITY;
+
 		/* SIGPIPE can happen, but it's just never processed */
- 		if(call_usermodehelper_pipe(corename+1, helper_argv, NULL, &file)) {
+ 		if (call_usermodehelper_pipe(corename+1, helper_argv, NULL,
+				&file)) {
  			printk(KERN_INFO "Core dump to %s pipe failed\n",
 			       corename);
  			goto fail_unlock;

commit 74aadce986052f20088c2678f589ea0e8d3a4b59
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Tue Oct 16 23:26:35 2007 -0700

    core_pattern: allow passing of arguments to user mode helper when core_pattern is a pipe
    
    A rewrite of my previous post for this enhancement.  It uses jeremy's
    split_argv/free_argv library functions to translate core_pattern into an argv
    array to be passed to the user mode helper process.  It also adds a
    translation to format_corename such that the origional value of RLIMIT_CORE
    can be passed to userspace as an argument.
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: <martin.pitt@ubuntu.com>
    Cc: <wwoods@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 86c455447bc8..6450157062ea 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -29,6 +29,7 @@
 #include <linux/stat.h>
 #include <linux/fcntl.h>
 #include <linux/smp_lock.h>
+#include <linux/string.h>
 #include <linux/init.h>
 #include <linux/pagemap.h>
 #include <linux/highmem.h>
@@ -1514,6 +1515,14 @@ static int format_corename(char *corename, const char *pattern, long signr)
 					goto out;
 				out_ptr += rc;
 				break;
+			/* core limit size */
+			case 'c':
+				rc = snprintf(out_ptr, out_end - out_ptr,
+					      "%lu", current->signal->rlim[RLIMIT_CORE].rlim_cur);
+				if (rc > out_end - out_ptr)
+					goto out;
+				out_ptr += rc;
+				break;
 			default:
 				break;
 			}
@@ -1698,6 +1707,9 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	int flag = 0;
 	int ispipe = 0;
 	unsigned long core_limit = current->signal->rlim[RLIMIT_CORE].rlim_cur;
+	char **helper_argv = NULL;
+	int helper_argc = 0;
+	char *delimit;
 
 	audit_core_dumps(signr);
 
@@ -1746,14 +1758,18 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 * at which point file size limits and permissions will be imposed
 	 * as it does with any other process
 	 */
-	if ((!ispipe) &&
-	   (core_limit < binfmt->min_coredump))
+	if ((!ispipe) && (core_limit < binfmt->min_coredump))
 		goto fail_unlock;
 
  	if (ispipe) {
 		core_limit = RLIM_INFINITY;
+		helper_argv = argv_split(GFP_KERNEL, corename+1, &helper_argc);
+		/* Terminate the string before the first option */
+		delimit = strchr(corename, ' ');
+		if (delimit)
+			*delimit = '\0';
 		/* SIGPIPE can happen, but it's just never processed */
- 		if(call_usermodehelper_pipe(corename+1, NULL, NULL, &file)) {
+ 		if(call_usermodehelper_pipe(corename+1, helper_argv, NULL, &file)) {
  			printk(KERN_INFO "Core dump to %s pipe failed\n",
 			       corename);
  			goto fail_unlock;
@@ -1788,6 +1804,9 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 close_fail:
 	filp_close(file, NULL);
 fail_unlock:
+	if (helper_argv)
+		argv_free(helper_argv);
+
 	current->fsuid = fsuid;
 	complete_all(&mm->core_done);
 fail:

commit 7dc0b22e3c54f1f4730354fef84a20f5944f6c5e
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Tue Oct 16 23:26:34 2007 -0700

    core_pattern: ignore RLIMIT_CORE if core_pattern is a pipe
    
    For some time /proc/sys/kernel/core_pattern has been able to set its output
    destination as a pipe, allowing a user space helper to receive and
    intellegently process a core.  This infrastructure however has some
    shortcommings which can be enhanced.  Specifically:
    
    1) The coredump code in the kernel should ignore RLIMIT_CORE limitation
       when core_pattern is a pipe, since file system resources are not being
       consumed in this case, unless the user application wishes to save the core,
       at which point the app is restricted by usual file system limits and
       restrictions.
    
    2) The core_pattern code should be able to parse and pass options to the
       user space helper as an argv array.  The real core limit of the uid of the
       crashing proces should also be passable to the user space helper (since it
       is overridden to zero when called).
    
    3) Some miscellaneous bugs need to be cleaned up (specifically the
       recognition of a recursive core dump, should the user mode helper itself
       crash.  Also, the core dump code in the kernel should not wait for the user
       mode helper to exit, since the same context is responsible for writing to
       the pipe, and a read of the pipe by the user mode helper will result in a
       deadlock.
    
    This patch:
    
    Remove the check of RLIMIT_CORE if core_pattern is a pipe.  In the event that
    core_pattern is a pipe, the entire core will be fed to the user mode helper.
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: <martin.pitt@ubuntu.com>
    Cc: <wwoods@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 550ae9b22f8d..86c455447bc8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1697,6 +1697,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	int fsuid = current->fsuid;
 	int flag = 0;
 	int ispipe = 0;
+	unsigned long core_limit = current->signal->rlim[RLIMIT_CORE].rlim_cur;
 
 	audit_core_dumps(signr);
 
@@ -1730,9 +1731,6 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 */
 	clear_thread_flag(TIF_SIGPENDING);
 
-	if (current->signal->rlim[RLIMIT_CORE].rlim_cur < binfmt->min_coredump)
-		goto fail_unlock;
-
 	/*
 	 * lock_kernel() because format_corename() is controlled by sysctl, which
 	 * uses lock_kernel()
@@ -1740,7 +1738,20 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
  	lock_kernel();
 	ispipe = format_corename(corename, core_pattern, signr);
 	unlock_kernel();
+	/*
+	 * Don't bother to check the RLIMIT_CORE value if core_pattern points
+	 * to a pipe.  Since we're not writing directly to the filesystem
+	 * RLIMIT_CORE doesn't really apply, as no actual core file will be
+	 * created unless the pipe reader choses to write out the core file
+	 * at which point file size limits and permissions will be imposed
+	 * as it does with any other process
+	 */
+	if ((!ispipe) &&
+	   (core_limit < binfmt->min_coredump))
+		goto fail_unlock;
+
  	if (ispipe) {
+		core_limit = RLIM_INFINITY;
 		/* SIGPIPE can happen, but it's just never processed */
  		if(call_usermodehelper_pipe(corename+1, NULL, NULL, &file)) {
  			printk(KERN_INFO "Core dump to %s pipe failed\n",
@@ -1770,7 +1781,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	if (!ispipe && do_truncate(file->f_path.dentry, 0, 0, file) != 0)
 		goto close_fail;
 
-	retval = binfmt->core_dump(signr, regs, file);
+	retval = binfmt->core_dump(signr, regs, file, core_limit);
 
 	if (retval)
 		current->signal->group_exit_code |= 0x80;

commit f6b450d489f2fb4e909447beacad64edb8aa0cda
Author: Alexey Dobriyan <adobriyan@sw.ru>
Date:   Tue Oct 16 23:26:04 2007 -0700

    Make unregister_binfmt() return void
    
    list_del() hardly can fail, so checking for return value is pointless
    (and current code always return 0).
    
    Nobody really cared that return value anyway.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 65825bdc4475..550ae9b22f8d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -81,12 +81,11 @@ int register_binfmt(struct linux_binfmt * fmt)
 
 EXPORT_SYMBOL(register_binfmt);
 
-int unregister_binfmt(struct linux_binfmt * fmt)
+void unregister_binfmt(struct linux_binfmt * fmt)
 {
 	write_lock(&binfmt_lock);
 	list_del(&fmt->lh);
 	write_unlock(&binfmt_lock);
-	return 0;
 }
 
 EXPORT_SYMBOL(unregister_binfmt);

commit e4dc1b14d8dc57c3975bf69740e4f5cda6bfba09
Author: Alexey Dobriyan <adobriyan@sw.ru>
Date:   Tue Oct 16 23:26:03 2007 -0700

    Use list_head in binfmt handling
    
    Switch single-linked binfmt formats list to usual list_head's.  This leads
    to one-liners in register_binfmt() and unregister_binfmt().  The downside
    is one pointer more in struct linux_binfmt.  This is not a problem, since
    the set of registered binfmts on typical box is very small -- (ELF +
    something distro enabled for you).
    
    Test-booted, played with executable .txt files, modprobe/rmmod binfmt_misc.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 073b0b8c6d05..65825bdc4475 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -66,27 +66,15 @@ int suid_dumpable = 0;
 EXPORT_SYMBOL(suid_dumpable);
 /* The maximal length of core_pattern is also specified in sysctl.c */
 
-static struct linux_binfmt *formats;
+static LIST_HEAD(formats);
 static DEFINE_RWLOCK(binfmt_lock);
 
 int register_binfmt(struct linux_binfmt * fmt)
 {
-	struct linux_binfmt ** tmp = &formats;
-
 	if (!fmt)
 		return -EINVAL;
-	if (fmt->next)
-		return -EBUSY;
 	write_lock(&binfmt_lock);
-	while (*tmp) {
-		if (fmt == *tmp) {
-			write_unlock(&binfmt_lock);
-			return -EBUSY;
-		}
-		tmp = &(*tmp)->next;
-	}
-	fmt->next = formats;
-	formats = fmt;
+	list_add(&fmt->lh, &formats);
 	write_unlock(&binfmt_lock);
 	return 0;	
 }
@@ -95,20 +83,10 @@ EXPORT_SYMBOL(register_binfmt);
 
 int unregister_binfmt(struct linux_binfmt * fmt)
 {
-	struct linux_binfmt ** tmp = &formats;
-
 	write_lock(&binfmt_lock);
-	while (*tmp) {
-		if (fmt == *tmp) {
-			*tmp = fmt->next;
-			fmt->next = NULL;
-			write_unlock(&binfmt_lock);
-			return 0;
-		}
-		tmp = &(*tmp)->next;
-	}
+	list_del(&fmt->lh);
 	write_unlock(&binfmt_lock);
-	return -EINVAL;
+	return 0;
 }
 
 EXPORT_SYMBOL(unregister_binfmt);
@@ -155,7 +133,7 @@ asmlinkage long sys_uselib(const char __user * library)
 		struct linux_binfmt * fmt;
 
 		read_lock(&binfmt_lock);
-		for (fmt = formats ; fmt ; fmt = fmt->next) {
+		list_for_each_entry(fmt, &formats, lh) {
 			if (!fmt->load_shlib)
 				continue;
 			if (!try_module_get(fmt->module))
@@ -1284,7 +1262,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 	retval = -ENOENT;
 	for (try=0; try<2; try++) {
 		read_lock(&binfmt_lock);
-		for (fmt = formats ; fmt ; fmt = fmt->next) {
+		list_for_each_entry(fmt, &formats, lh) {
 			int (*fn)(struct linux_binprm *, struct pt_regs *) = fmt->load_binary;
 			if (!fn)
 				continue;

commit b8fceee17a310f189188599a8fa5e9beaff57eb0
Author: Davide Libenzi <davidel@xmailserver.org>
Date:   Thu Sep 20 12:40:16 2007 -0700

    signalfd simplification
    
    This simplifies signalfd code, by avoiding it to remain attached to the
    sighand during its lifetime.
    
    In this way, the signalfd remain attached to the sighand only during
    poll(2) (and select and epoll) and read(2).  This also allows to remove
    all the custom "tsk == current" checks in kernel/signal.c, since
    dequeue_signal() will only be called by "current".
    
    I think this is also what Ben was suggesting time ago.
    
    The external effect of this, is that a thread can extract only its own
    private signals and the group ones.  I think this is an acceptable
    behaviour, in that those are the signals the thread would be able to
    fetch w/out signalfd.
    
    Signed-off-by: Davide Libenzi <davidel@xmailserver.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index c21a8cc06277..073b0b8c6d05 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -50,7 +50,6 @@
 #include <linux/tsacct_kern.h>
 #include <linux/cn_proc.h>
 #include <linux/audit.h>
-#include <linux/signalfd.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -784,7 +783,6 @@ static int de_thread(struct task_struct *tsk)
 	 * and we can just re-use it all.
 	 */
 	if (atomic_read(&oldsighand->count) <= 1) {
-		signalfd_detach(tsk);
 		exit_itimers(sig);
 		return 0;
 	}
@@ -923,7 +921,6 @@ static int de_thread(struct task_struct *tsk)
 	sig->flags = 0;
 
 no_thread_group:
-	signalfd_detach(tsk);
 	exit_itimers(sig);
 	if (leader)
 		release_task(leader);

commit abd96ecb298675a21c412a29f5de2f80174d5f18
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Aug 22 14:01:58 2007 -0700

    exec: kill unsafe BUG_ON(sig->count) checks
    
    de_thread:
    
            if (atomic_read(&oldsighand->count) <= 1)
                    BUG_ON(atomic_read(&sig->count) != 1);
    
    This is not safe without the rmb() in between.  The results of two
    correctly ordered __exit_signal()->atomic_dec_and_test()'s could be seen
    out of order on our CPU.
    
    The same is true for the "thread_group_empty()" case, __unhash_process()'s
    changes could be seen before atomic_dec_and_test(&sig->count).
    
    On some platforms (including i386) atomic_read() doesn't provide even the
    compiler barrier, in that case these checks are simply racy.
    
    Remove these BUG_ON()'s. Alternatively, we can do something like
    
            BUG_ON( ({ smp_rmb(); atomic_read(&sig->count) != 1; }) );
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index af4361c927a9..c21a8cc06277 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -784,7 +784,6 @@ static int de_thread(struct task_struct *tsk)
 	 * and we can just re-use it all.
 	 */
 	if (atomic_read(&oldsighand->count) <= 1) {
-		BUG_ON(atomic_read(&sig->count) != 1);
 		signalfd_detach(tsk);
 		exit_itimers(sig);
 		return 0;
@@ -929,8 +928,6 @@ static int de_thread(struct task_struct *tsk)
 	if (leader)
 		release_task(leader);
 
-	BUG_ON(atomic_read(&sig->count) != 1);
-
 	if (atomic_read(&oldsighand->count) == 1) {
 		/*
 		 * Now that we nuked the rest of the thread group,

commit f9ee228bdc82cff8ea1ec00fd952890e00679dd8
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Aug 22 14:01:48 2007 -0700

    signalfd: make it group-wide, fix posix-timers scheduling
    
    With this patch any thread can dequeue its own private signals via signalfd,
    even if it was created by another sub-thread.
    
    To do so, we pass "current" to dequeue_signal() if the caller is from the same
    thread group. This also fixes the scheduling of posix timers broken by the
    previous patch.
    
    If the caller doesn't belong to this thread group, we can't handle __SI_TIMER
    case properly anyway. Perhaps we should forbid the cross-process signalfd usage
    and convert ctx->tsk to ctx->sighand.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Michael Kerrisk <mtk-manpages@gmx.net>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index ce62f7b65f17..af4361c927a9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -779,19 +779,13 @@ static int de_thread(struct task_struct *tsk)
 	struct task_struct *leader = NULL;
 	int count;
 
-	/*
-	 * Tell all the sighand listeners that this sighand has
-	 * been detached. The signalfd_detach() function grabs the
-	 * sighand lock, if signal listeners are present on the sighand.
-	 */
-	signalfd_detach(tsk);
-
 	/*
 	 * If we don't share sighandlers, then we aren't sharing anything
 	 * and we can just re-use it all.
 	 */
 	if (atomic_read(&oldsighand->count) <= 1) {
 		BUG_ON(atomic_read(&sig->count) != 1);
+		signalfd_detach(tsk);
 		exit_itimers(sig);
 		return 0;
 	}
@@ -930,6 +924,7 @@ static int de_thread(struct task_struct *tsk)
 	sig->flags = 0;
 
 no_thread_group:
+	signalfd_detach(tsk);
 	exit_itimers(sig);
 	if (leader)
 		release_task(leader);

commit d2d56c5f51028cb9f3d800882eb6f4cbd3f9099f
Author: Marcel Holtmann <marcel@holtmann.org>
Date:   Fri Aug 17 21:47:58 2007 +0200

    Reset current->pdeath_signal on SUID binary execution
    
    This fixes a vulnerability in the "parent process death signal"
    implementation discoverd by Wojciech Purczynski of COSEINC PTE Ltd.
    and iSEC Security Research.
    
    http://marc.info/?l=bugtraq&m=118711306802632&w=2
    
    Signed-off-by: Marcel Holtmann <marcel@holtmann.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7bdea7937ee8..ce62f7b65f17 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1084,9 +1084,12 @@ int flush_old_exec(struct linux_binprm * bprm)
 	 */
 	current->mm->task_size = TASK_SIZE;
 
-	if (bprm->e_uid != current->euid || bprm->e_gid != current->egid || 
-	    file_permission(bprm->file, MAY_READ) ||
-	    (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)) {
+	if (bprm->e_uid != current->euid || bprm->e_gid != current->egid) {
+		suid_keys(current);
+		set_dumpable(current->mm, suid_dumpable);
+		current->pdeath_signal = 0;
+	} else if (file_permission(bprm->file, MAY_READ) ||
+			(bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)) {
 		suid_keys(current);
 		set_dumpable(current->mm, suid_dumpable);
 	}
@@ -1177,8 +1180,10 @@ void compute_creds(struct linux_binprm *bprm)
 {
 	int unsafe;
 
-	if (bprm->e_uid != current->uid)
+	if (bprm->e_uid != current->uid) {
 		suid_keys(current);
+		current->pdeath_signal = 0;
+	}
 	exec_keys(current);
 
 	task_lock(current);

commit 6c5d523826dc639df709ed0f88c5d2ce25379652
Author: Kawai, Hidehiro <hidehiro.kawai.ez@hitachi.com>
Date:   Thu Jul 19 01:48:27 2007 -0700

    coredump masking: reimplementation of dumpable using two flags
    
    This patch changes mm_struct.dumpable to a pair of bit flags.
    
    set_dumpable() converts three-value dumpable to two flags and stores it into
    lower two bits of mm_struct.flags instead of mm_struct.dumpable.
    get_dumpable() behaves in the opposite way.
    
    [akpm@linux-foundation.org: export set_dumpable]
    Signed-off-by: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 498f2b3dca20..7bdea7937ee8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1058,9 +1058,9 @@ int flush_old_exec(struct linux_binprm * bprm)
 	current->sas_ss_sp = current->sas_ss_size = 0;
 
 	if (current->euid == current->uid && current->egid == current->gid)
-		current->mm->dumpable = 1;
+		set_dumpable(current->mm, 1);
 	else
-		current->mm->dumpable = suid_dumpable;
+		set_dumpable(current->mm, suid_dumpable);
 
 	name = bprm->filename;
 
@@ -1088,7 +1088,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	    file_permission(bprm->file, MAY_READ) ||
 	    (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)) {
 		suid_keys(current);
-		current->mm->dumpable = suid_dumpable;
+		set_dumpable(current->mm, suid_dumpable);
 	}
 
 	/* An exec changes our domain. We are no longer part of the thread
@@ -1665,6 +1665,56 @@ static int coredump_wait(int exit_code)
 	return core_waiters;
 }
 
+/*
+ * set_dumpable converts traditional three-value dumpable to two flags and
+ * stores them into mm->flags.  It modifies lower two bits of mm->flags, but
+ * these bits are not changed atomically.  So get_dumpable can observe the
+ * intermediate state.  To avoid doing unexpected behavior, get get_dumpable
+ * return either old dumpable or new one by paying attention to the order of
+ * modifying the bits.
+ *
+ * dumpable |   mm->flags (binary)
+ * old  new | initial interim  final
+ * ---------+-----------------------
+ *  0    1  |   00      01      01
+ *  0    2  |   00      10(*)   11
+ *  1    0  |   01      00      00
+ *  1    2  |   01      11      11
+ *  2    0  |   11      10(*)   00
+ *  2    1  |   11      11      01
+ *
+ * (*) get_dumpable regards interim value of 10 as 11.
+ */
+void set_dumpable(struct mm_struct *mm, int value)
+{
+	switch (value) {
+	case 0:
+		clear_bit(MMF_DUMPABLE, &mm->flags);
+		smp_wmb();
+		clear_bit(MMF_DUMP_SECURELY, &mm->flags);
+		break;
+	case 1:
+		set_bit(MMF_DUMPABLE, &mm->flags);
+		smp_wmb();
+		clear_bit(MMF_DUMP_SECURELY, &mm->flags);
+		break;
+	case 2:
+		set_bit(MMF_DUMP_SECURELY, &mm->flags);
+		smp_wmb();
+		set_bit(MMF_DUMPABLE, &mm->flags);
+		break;
+	}
+}
+EXPORT_SYMBOL_GPL(set_dumpable);
+
+int get_dumpable(struct mm_struct *mm)
+{
+	int ret;
+
+	ret = mm->flags & 0x3;
+	return (ret >= 2) ? 2 : ret;
+}
+
 int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 {
 	char corename[CORENAME_MAX_SIZE + 1];
@@ -1683,7 +1733,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	if (!binfmt || !binfmt->core_dump)
 		goto fail;
 	down_write(&mm->mmap_sem);
-	if (!mm->dumpable) {
+	if (!get_dumpable(mm)) {
 		up_write(&mm->mmap_sem);
 		goto fail;
 	}
@@ -1693,11 +1743,11 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 *	process nor do we know its entire history. We only know it
 	 *	was tainted so we dump it as root in mode 2.
 	 */
-	if (mm->dumpable == 2) {	/* Setuid core dump mode */
+	if (get_dumpable(mm) == 2) {	/* Setuid core dump mode */
 		flag = O_EXCL;		/* Stop rewrite attacks */
 		current->fsuid = 0;	/* Dump root private */
 	}
-	mm->dumpable = 0;
+	set_dumpable(mm, 0);
 
 	retval = coredump_wait(exit_code);
 	if (retval < 0)

commit b6a2fea39318e43fee84fa7b0b90d68bed92d2ba
Author: Ollie Wild <aaw@google.com>
Date:   Thu Jul 19 01:48:16 2007 -0700

    mm: variable length argument support
    
    Remove the arg+env limit of MAX_ARG_PAGES by copying the strings directly from
    the old mm into the new mm.
    
    We create the new mm before the binfmt code runs, and place the new stack at
    the very top of the address space.  Once the binfmt code runs and figures out
    where the stack should be, we move it downwards.
    
    It is a bit peculiar in that we have one task with two mm's, one of which is
    inactive.
    
    [a.p.zijlstra@chello.nl: limit stack size]
    Signed-off-by: Ollie Wild <aaw@google.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: <linux-arch@vger.kernel.org>
    Cc: Hugh Dickins <hugh@veritas.com>
    [bunk@stusta.de: unexport bprm_mm_init]
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2e3f7950c185..498f2b3dca20 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -54,6 +54,7 @@
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
+#include <asm/tlb.h>
 
 #ifdef CONFIG_KMOD
 #include <linux/kmod.h>
@@ -178,6 +179,207 @@ asmlinkage long sys_uselib(const char __user * library)
 	goto out;
 }
 
+#ifdef CONFIG_MMU
+
+static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
+		int write)
+{
+	struct page *page;
+	int ret;
+
+#ifdef CONFIG_STACK_GROWSUP
+	if (write) {
+		ret = expand_stack_downwards(bprm->vma, pos);
+		if (ret < 0)
+			return NULL;
+	}
+#endif
+	ret = get_user_pages(current, bprm->mm, pos,
+			1, write, 1, &page, NULL);
+	if (ret <= 0)
+		return NULL;
+
+	if (write) {
+		struct rlimit *rlim = current->signal->rlim;
+		unsigned long size = bprm->vma->vm_end - bprm->vma->vm_start;
+
+		/*
+		 * Limit to 1/4-th the stack size for the argv+env strings.
+		 * This ensures that:
+		 *  - the remaining binfmt code will not run out of stack space,
+		 *  - the program will have a reasonable amount of stack left
+		 *    to work from.
+		 */
+		if (size > rlim[RLIMIT_STACK].rlim_cur / 4) {
+			put_page(page);
+			return NULL;
+		}
+	}
+
+	return page;
+}
+
+static void put_arg_page(struct page *page)
+{
+	put_page(page);
+}
+
+static void free_arg_page(struct linux_binprm *bprm, int i)
+{
+}
+
+static void free_arg_pages(struct linux_binprm *bprm)
+{
+}
+
+static void flush_arg_page(struct linux_binprm *bprm, unsigned long pos,
+		struct page *page)
+{
+	flush_cache_page(bprm->vma, pos, page_to_pfn(page));
+}
+
+static int __bprm_mm_init(struct linux_binprm *bprm)
+{
+	int err = -ENOMEM;
+	struct vm_area_struct *vma = NULL;
+	struct mm_struct *mm = bprm->mm;
+
+	bprm->vma = vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+	if (!vma)
+		goto err;
+
+	down_write(&mm->mmap_sem);
+	vma->vm_mm = mm;
+
+	/*
+	 * Place the stack at the largest stack address the architecture
+	 * supports. Later, we'll move this to an appropriate place. We don't
+	 * use STACK_TOP because that can depend on attributes which aren't
+	 * configured yet.
+	 */
+	vma->vm_end = STACK_TOP_MAX;
+	vma->vm_start = vma->vm_end - PAGE_SIZE;
+
+	vma->vm_flags = VM_STACK_FLAGS;
+	vma->vm_page_prot = protection_map[vma->vm_flags & 0x7];
+	err = insert_vm_struct(mm, vma);
+	if (err) {
+		up_write(&mm->mmap_sem);
+		goto err;
+	}
+
+	mm->stack_vm = mm->total_vm = 1;
+	up_write(&mm->mmap_sem);
+
+	bprm->p = vma->vm_end - sizeof(void *);
+
+	return 0;
+
+err:
+	if (vma) {
+		bprm->vma = NULL;
+		kmem_cache_free(vm_area_cachep, vma);
+	}
+
+	return err;
+}
+
+static bool valid_arg_len(struct linux_binprm *bprm, long len)
+{
+	return len <= MAX_ARG_STRLEN;
+}
+
+#else
+
+static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,
+		int write)
+{
+	struct page *page;
+
+	page = bprm->page[pos / PAGE_SIZE];
+	if (!page && write) {
+		page = alloc_page(GFP_HIGHUSER|__GFP_ZERO);
+		if (!page)
+			return NULL;
+		bprm->page[pos / PAGE_SIZE] = page;
+	}
+
+	return page;
+}
+
+static void put_arg_page(struct page *page)
+{
+}
+
+static void free_arg_page(struct linux_binprm *bprm, int i)
+{
+	if (bprm->page[i]) {
+		__free_page(bprm->page[i]);
+		bprm->page[i] = NULL;
+	}
+}
+
+static void free_arg_pages(struct linux_binprm *bprm)
+{
+	int i;
+
+	for (i = 0; i < MAX_ARG_PAGES; i++)
+		free_arg_page(bprm, i);
+}
+
+static void flush_arg_page(struct linux_binprm *bprm, unsigned long pos,
+		struct page *page)
+{
+}
+
+static int __bprm_mm_init(struct linux_binprm *bprm)
+{
+	bprm->p = PAGE_SIZE * MAX_ARG_PAGES - sizeof(void *);
+	return 0;
+}
+
+static bool valid_arg_len(struct linux_binprm *bprm, long len)
+{
+	return len <= bprm->p;
+}
+
+#endif /* CONFIG_MMU */
+
+/*
+ * Create a new mm_struct and populate it with a temporary stack
+ * vm_area_struct.  We don't have enough context at this point to set the stack
+ * flags, permissions, and offset, so we use temporary values.  We'll update
+ * them later in setup_arg_pages().
+ */
+int bprm_mm_init(struct linux_binprm *bprm)
+{
+	int err;
+	struct mm_struct *mm = NULL;
+
+	bprm->mm = mm = mm_alloc();
+	err = -ENOMEM;
+	if (!mm)
+		goto err;
+
+	err = init_new_context(current, mm);
+	if (err)
+		goto err;
+
+	err = __bprm_mm_init(bprm);
+	if (err)
+		goto err;
+
+	return 0;
+
+err:
+	if (mm) {
+		bprm->mm = NULL;
+		mmdrop(mm);
+	}
+
+	return err;
+}
+
 /*
  * count() counts the number of strings in array ARGV.
  */
@@ -203,15 +405,16 @@ static int count(char __user * __user * argv, int max)
 }
 
 /*
- * 'copy_strings()' copies argument/environment strings from user
- * memory to free pages in kernel mem. These are in a format ready
- * to be put directly into the top of new user memory.
+ * 'copy_strings()' copies argument/environment strings from the old
+ * processes's memory to the new process's stack.  The call to get_user_pages()
+ * ensures the destination page is created and not swapped out.
  */
 static int copy_strings(int argc, char __user * __user * argv,
 			struct linux_binprm *bprm)
 {
 	struct page *kmapped_page = NULL;
 	char *kaddr = NULL;
+	unsigned long kpos = 0;
 	int ret;
 
 	while (argc-- > 0) {
@@ -220,69 +423,69 @@ static int copy_strings(int argc, char __user * __user * argv,
 		unsigned long pos;
 
 		if (get_user(str, argv+argc) ||
-				!(len = strnlen_user(str, bprm->p))) {
+				!(len = strnlen_user(str, MAX_ARG_STRLEN))) {
 			ret = -EFAULT;
 			goto out;
 		}
 
-		if (bprm->p < len)  {
+		if (!valid_arg_len(bprm, len)) {
 			ret = -E2BIG;
 			goto out;
 		}
 
-		bprm->p -= len;
-		/* XXX: add architecture specific overflow check here. */
+		/* We're going to work our way backwords. */
 		pos = bprm->p;
+		str += len;
+		bprm->p -= len;
 
 		while (len > 0) {
-			int i, new, err;
 			int offset, bytes_to_copy;
-			struct page *page;
 
 			offset = pos % PAGE_SIZE;
-			i = pos/PAGE_SIZE;
-			page = bprm->page[i];
-			new = 0;
-			if (!page) {
-				page = alloc_page(GFP_HIGHUSER);
-				bprm->page[i] = page;
+			if (offset == 0)
+				offset = PAGE_SIZE;
+
+			bytes_to_copy = offset;
+			if (bytes_to_copy > len)
+				bytes_to_copy = len;
+
+			offset -= bytes_to_copy;
+			pos -= bytes_to_copy;
+			str -= bytes_to_copy;
+			len -= bytes_to_copy;
+
+			if (!kmapped_page || kpos != (pos & PAGE_MASK)) {
+				struct page *page;
+
+				page = get_arg_page(bprm, pos, 1);
 				if (!page) {
-					ret = -ENOMEM;
+					ret = -E2BIG;
 					goto out;
 				}
-				new = 1;
-			}
 
-			if (page != kmapped_page) {
-				if (kmapped_page)
+				if (kmapped_page) {
+					flush_kernel_dcache_page(kmapped_page);
 					kunmap(kmapped_page);
+					put_arg_page(kmapped_page);
+				}
 				kmapped_page = page;
 				kaddr = kmap(kmapped_page);
+				kpos = pos & PAGE_MASK;
+				flush_arg_page(bprm, kpos, kmapped_page);
 			}
-			if (new && offset)
-				memset(kaddr, 0, offset);
-			bytes_to_copy = PAGE_SIZE - offset;
-			if (bytes_to_copy > len) {
-				bytes_to_copy = len;
-				if (new)
-					memset(kaddr+offset+len, 0,
-						PAGE_SIZE-offset-len);
-			}
-			err = copy_from_user(kaddr+offset, str, bytes_to_copy);
-			if (err) {
+			if (copy_from_user(kaddr+offset, str, bytes_to_copy)) {
 				ret = -EFAULT;
 				goto out;
 			}
-
-			pos += bytes_to_copy;
-			str += bytes_to_copy;
-			len -= bytes_to_copy;
 		}
 	}
 	ret = 0;
 out:
-	if (kmapped_page)
+	if (kmapped_page) {
+		flush_kernel_dcache_page(kmapped_page);
 		kunmap(kmapped_page);
+		put_arg_page(kmapped_page);
+	}
 	return ret;
 }
 
@@ -298,181 +501,172 @@ int copy_strings_kernel(int argc,char ** argv, struct linux_binprm *bprm)
 	set_fs(oldfs);
 	return r;
 }
-
 EXPORT_SYMBOL(copy_strings_kernel);
 
 #ifdef CONFIG_MMU
+
 /*
- * This routine is used to map in a page into an address space: needed by
- * execve() for the initial stack and environment pages.
+ * During bprm_mm_init(), we create a temporary stack at STACK_TOP_MAX.  Once
+ * the binfmt code determines where the new stack should reside, we shift it to
+ * its final location.  The process proceeds as follows:
  *
- * vma->vm_mm->mmap_sem is held for writing.
+ * 1) Use shift to calculate the new vma endpoints.
+ * 2) Extend vma to cover both the old and new ranges.  This ensures the
+ *    arguments passed to subsequent functions are consistent.
+ * 3) Move vma's page tables to the new range.
+ * 4) Free up any cleared pgd range.
+ * 5) Shrink the vma to cover only the new range.
  */
-void install_arg_page(struct vm_area_struct *vma,
-			struct page *page, unsigned long address)
+static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift)
 {
 	struct mm_struct *mm = vma->vm_mm;
-	pte_t * pte;
-	spinlock_t *ptl;
+	unsigned long old_start = vma->vm_start;
+	unsigned long old_end = vma->vm_end;
+	unsigned long length = old_end - old_start;
+	unsigned long new_start = old_start - shift;
+	unsigned long new_end = old_end - shift;
+	struct mmu_gather *tlb;
 
-	if (unlikely(anon_vma_prepare(vma)))
-		goto out;
+	BUG_ON(new_start > new_end);
 
-	flush_dcache_page(page);
-	pte = get_locked_pte(mm, address, &ptl);
-	if (!pte)
-		goto out;
-	if (!pte_none(*pte)) {
-		pte_unmap_unlock(pte, ptl);
-		goto out;
+	/*
+	 * ensure there are no vmas between where we want to go
+	 * and where we are
+	 */
+	if (vma != find_vma(mm, new_start))
+		return -EFAULT;
+
+	/*
+	 * cover the whole range: [new_start, old_end)
+	 */
+	vma_adjust(vma, new_start, old_end, vma->vm_pgoff, NULL);
+
+	/*
+	 * move the page tables downwards, on failure we rely on
+	 * process cleanup to remove whatever mess we made.
+	 */
+	if (length != move_page_tables(vma, old_start,
+				       vma, new_start, length))
+		return -ENOMEM;
+
+	lru_add_drain();
+	tlb = tlb_gather_mmu(mm, 0);
+	if (new_end > old_start) {
+		/*
+		 * when the old and new regions overlap clear from new_end.
+		 */
+		free_pgd_range(&tlb, new_end, old_end, new_end,
+			vma->vm_next ? vma->vm_next->vm_start : 0);
+	} else {
+		/*
+		 * otherwise, clean from old_start; this is done to not touch
+		 * the address space in [new_end, old_start) some architectures
+		 * have constraints on va-space that make this illegal (IA64) -
+		 * for the others its just a little faster.
+		 */
+		free_pgd_range(&tlb, old_start, old_end, new_end,
+			vma->vm_next ? vma->vm_next->vm_start : 0);
 	}
-	inc_mm_counter(mm, anon_rss);
-	lru_cache_add_active(page);
-	set_pte_at(mm, address, pte, pte_mkdirty(pte_mkwrite(mk_pte(
-					page, vma->vm_page_prot))));
-	page_add_new_anon_rmap(page, vma, address);
-	pte_unmap_unlock(pte, ptl);
-
-	/* no need for flush_tlb */
-	return;
-out:
-	__free_page(page);
-	force_sig(SIGKILL, current);
+	tlb_finish_mmu(tlb, new_end, old_end);
+
+	/*
+	 * shrink the vma to just the new range.
+	 */
+	vma_adjust(vma, new_start, new_end, vma->vm_pgoff, NULL);
+
+	return 0;
 }
 
 #define EXTRA_STACK_VM_PAGES	20	/* random */
 
+/*
+ * Finalizes the stack vm_area_struct. The flags and permissions are updated,
+ * the stack is optionally relocated, and some extra space is added.
+ */
 int setup_arg_pages(struct linux_binprm *bprm,
 		    unsigned long stack_top,
 		    int executable_stack)
 {
-	unsigned long stack_base;
-	struct vm_area_struct *mpnt;
+	unsigned long ret;
+	unsigned long stack_shift;
 	struct mm_struct *mm = current->mm;
-	int i, ret;
-	long arg_size;
+	struct vm_area_struct *vma = bprm->vma;
+	struct vm_area_struct *prev = NULL;
+	unsigned long vm_flags;
+	unsigned long stack_base;
 
 #ifdef CONFIG_STACK_GROWSUP
-	/* Move the argument and environment strings to the bottom of the
-	 * stack space.
-	 */
-	int offset, j;
-	char *to, *from;
-
-	/* Start by shifting all the pages down */
-	i = 0;
-	for (j = 0; j < MAX_ARG_PAGES; j++) {
-		struct page *page = bprm->page[j];
-		if (!page)
-			continue;
-		bprm->page[i++] = page;
-	}
-
-	/* Now move them within their pages */
-	offset = bprm->p % PAGE_SIZE;
-	to = kmap(bprm->page[0]);
-	for (j = 1; j < i; j++) {
-		memmove(to, to + offset, PAGE_SIZE - offset);
-		from = kmap(bprm->page[j]);
-		memcpy(to + PAGE_SIZE - offset, from, offset);
-		kunmap(bprm->page[j - 1]);
-		to = from;
-	}
-	memmove(to, to + offset, PAGE_SIZE - offset);
-	kunmap(bprm->page[j - 1]);
-
 	/* Limit stack size to 1GB */
 	stack_base = current->signal->rlim[RLIMIT_STACK].rlim_max;
 	if (stack_base > (1 << 30))
 		stack_base = 1 << 30;
-	stack_base = PAGE_ALIGN(stack_top - stack_base);
 
-	/* Adjust bprm->p to point to the end of the strings. */
-	bprm->p = stack_base + PAGE_SIZE * i - offset;
+	/* Make sure we didn't let the argument array grow too large. */
+	if (vma->vm_end - vma->vm_start > stack_base)
+		return -ENOMEM;
 
-	mm->arg_start = stack_base;
-	arg_size = i << PAGE_SHIFT;
+	stack_base = PAGE_ALIGN(stack_top - stack_base);
 
-	/* zero pages that were copied above */
-	while (i < MAX_ARG_PAGES)
-		bprm->page[i++] = NULL;
+	stack_shift = vma->vm_start - stack_base;
+	mm->arg_start = bprm->p - stack_shift;
+	bprm->p = vma->vm_end - stack_shift;
 #else
-	stack_base = arch_align_stack(stack_top - MAX_ARG_PAGES*PAGE_SIZE);
-	stack_base = PAGE_ALIGN(stack_base);
-	bprm->p += stack_base;
+	stack_top = arch_align_stack(stack_top);
+	stack_top = PAGE_ALIGN(stack_top);
+	stack_shift = vma->vm_end - stack_top;
+
+	bprm->p -= stack_shift;
 	mm->arg_start = bprm->p;
-	arg_size = stack_top - (PAGE_MASK & (unsigned long) mm->arg_start);
 #endif
 
-	arg_size += EXTRA_STACK_VM_PAGES * PAGE_SIZE;
-
 	if (bprm->loader)
-		bprm->loader += stack_base;
-	bprm->exec += stack_base;
-
-	mpnt = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
-	if (!mpnt)
-		return -ENOMEM;
+		bprm->loader -= stack_shift;
+	bprm->exec -= stack_shift;
 
 	down_write(&mm->mmap_sem);
-	{
-		mpnt->vm_mm = mm;
-#ifdef CONFIG_STACK_GROWSUP
-		mpnt->vm_start = stack_base;
-		mpnt->vm_end = stack_base + arg_size;
-#else
-		mpnt->vm_end = stack_top;
-		mpnt->vm_start = mpnt->vm_end - arg_size;
-#endif
-		/* Adjust stack execute permissions; explicitly enable
-		 * for EXSTACK_ENABLE_X, disable for EXSTACK_DISABLE_X
-		 * and leave alone (arch default) otherwise. */
-		if (unlikely(executable_stack == EXSTACK_ENABLE_X))
-			mpnt->vm_flags = VM_STACK_FLAGS |  VM_EXEC;
-		else if (executable_stack == EXSTACK_DISABLE_X)
-			mpnt->vm_flags = VM_STACK_FLAGS & ~VM_EXEC;
-		else
-			mpnt->vm_flags = VM_STACK_FLAGS;
-		mpnt->vm_flags |= mm->def_flags;
-		mpnt->vm_page_prot = protection_map[mpnt->vm_flags & 0x7];
-		if ((ret = insert_vm_struct(mm, mpnt))) {
+	vm_flags = vma->vm_flags;
+
+	/*
+	 * Adjust stack execute permissions; explicitly enable for
+	 * EXSTACK_ENABLE_X, disable for EXSTACK_DISABLE_X and leave alone
+	 * (arch default) otherwise.
+	 */
+	if (unlikely(executable_stack == EXSTACK_ENABLE_X))
+		vm_flags |= VM_EXEC;
+	else if (executable_stack == EXSTACK_DISABLE_X)
+		vm_flags &= ~VM_EXEC;
+	vm_flags |= mm->def_flags;
+
+	ret = mprotect_fixup(vma, &prev, vma->vm_start, vma->vm_end,
+			vm_flags);
+	if (ret)
+		goto out_unlock;
+	BUG_ON(prev != vma);
+
+	/* Move stack pages down in memory. */
+	if (stack_shift) {
+		ret = shift_arg_pages(vma, stack_shift);
+		if (ret) {
 			up_write(&mm->mmap_sem);
-			kmem_cache_free(vm_area_cachep, mpnt);
 			return ret;
 		}
-		mm->stack_vm = mm->total_vm = vma_pages(mpnt);
 	}
 
-	for (i = 0 ; i < MAX_ARG_PAGES ; i++) {
-		struct page *page = bprm->page[i];
-		if (page) {
-			bprm->page[i] = NULL;
-			install_arg_page(mpnt, page, stack_base);
-		}
-		stack_base += PAGE_SIZE;
-	}
+#ifdef CONFIG_STACK_GROWSUP
+	stack_base = vma->vm_end + EXTRA_STACK_VM_PAGES * PAGE_SIZE;
+#else
+	stack_base = vma->vm_start - EXTRA_STACK_VM_PAGES * PAGE_SIZE;
+#endif
+	ret = expand_stack(vma, stack_base);
+	if (ret)
+		ret = -EFAULT;
+
+out_unlock:
 	up_write(&mm->mmap_sem);
-	
 	return 0;
 }
-
 EXPORT_SYMBOL(setup_arg_pages);
 
-#define free_arg_pages(bprm) do { } while (0)
-
-#else
-
-static inline void free_arg_pages(struct linux_binprm *bprm)
-{
-	int i;
-
-	for (i = 0; i < MAX_ARG_PAGES; i++) {
-		if (bprm->page[i])
-			__free_page(bprm->page[i]);
-		bprm->page[i] = NULL;
-	}
-}
-
 #endif /* CONFIG_MMU */
 
 struct file *open_exec(const char *name)
@@ -1000,43 +1194,42 @@ EXPORT_SYMBOL(compute_creds);
  * points to; chop off the first by relocating brpm->p to right after
  * the first '\0' encountered.
  */
-void remove_arg_zero(struct linux_binprm *bprm)
+int remove_arg_zero(struct linux_binprm *bprm)
 {
-	if (bprm->argc) {
-		char ch;
+	int ret = 0;
+	unsigned long offset;
+	char *kaddr;
+	struct page *page;
 
-		do {
-			unsigned long offset;
-			unsigned long index;
-			char *kaddr;
-			struct page *page;
-
-			offset = bprm->p & ~PAGE_MASK;
-			index = bprm->p >> PAGE_SHIFT;
+	if (!bprm->argc)
+		return 0;
 
-			page = bprm->page[index];
-			kaddr = kmap_atomic(page, KM_USER0);
+	do {
+		offset = bprm->p & ~PAGE_MASK;
+		page = get_arg_page(bprm, bprm->p, 0);
+		if (!page) {
+			ret = -EFAULT;
+			goto out;
+		}
+		kaddr = kmap_atomic(page, KM_USER0);
 
-			/* run through page until we reach end or find NUL */
-			do {
-				ch = *(kaddr + offset);
+		for (; offset < PAGE_SIZE && kaddr[offset];
+				offset++, bprm->p++)
+			;
 
-				/* discard that character... */
-				bprm->p++;
-				offset++;
-			} while (offset < PAGE_SIZE && ch != '\0');
+		kunmap_atomic(kaddr, KM_USER0);
+		put_arg_page(page);
 
-			kunmap_atomic(kaddr, KM_USER0);
+		if (offset == PAGE_SIZE)
+			free_arg_page(bprm, (bprm->p >> PAGE_SHIFT) - 1);
+	} while (offset == PAGE_SIZE);
 
-			/* free the old page */
-			if (offset == PAGE_SIZE) {
-				__free_page(page);
-				bprm->page[index] = NULL;
-			}
-		} while (ch != '\0');
+	bprm->p++;
+	bprm->argc--;
+	ret = 0;
 
-		bprm->argc--;
-	}
+out:
+	return ret;
 }
 EXPORT_SYMBOL(remove_arg_zero);
 
@@ -1062,7 +1255,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 		fput(bprm->file);
 		bprm->file = NULL;
 
-	        loader = PAGE_SIZE*MAX_ARG_PAGES-sizeof(void *);
+		loader = bprm->vma->vm_end - sizeof(void *);
 
 		file = open_exec("/sbin/loader");
 		retval = PTR_ERR(file);
@@ -1156,7 +1349,6 @@ int do_execve(char * filename,
 	struct file *file;
 	unsigned long env_p;
 	int retval;
-	int i;
 
 	retval = -ENOMEM;
 	bprm = kzalloc(sizeof(*bprm), GFP_KERNEL);
@@ -1170,25 +1362,19 @@ int do_execve(char * filename,
 
 	sched_exec();
 
-	bprm->p = PAGE_SIZE*MAX_ARG_PAGES-sizeof(void *);
-
 	bprm->file = file;
 	bprm->filename = filename;
 	bprm->interp = filename;
-	bprm->mm = mm_alloc();
-	retval = -ENOMEM;
-	if (!bprm->mm)
-		goto out_file;
 
-	retval = init_new_context(current, bprm->mm);
-	if (retval < 0)
-		goto out_mm;
+	retval = bprm_mm_init(bprm);
+	if (retval)
+		goto out_file;
 
-	bprm->argc = count(argv, bprm->p / sizeof(void *));
+	bprm->argc = count(argv, MAX_ARG_STRINGS);
 	if ((retval = bprm->argc) < 0)
 		goto out_mm;
 
-	bprm->envc = count(envp, bprm->p / sizeof(void *));
+	bprm->envc = count(envp, MAX_ARG_STRINGS);
 	if ((retval = bprm->envc) < 0)
 		goto out_mm;
 
@@ -1217,9 +1403,8 @@ int do_execve(char * filename,
 
 	retval = search_binary_handler(bprm,regs);
 	if (retval >= 0) {
-		free_arg_pages(bprm);
-
 		/* execve success */
+		free_arg_pages(bprm);
 		security_bprm_free(bprm);
 		acct_update_integrals(current);
 		kfree(bprm);
@@ -1227,26 +1412,19 @@ int do_execve(char * filename,
 	}
 
 out:
-	/* Something went wrong, return the inode and free the argument pages*/
-	for (i = 0 ; i < MAX_ARG_PAGES ; i++) {
-		struct page * page = bprm->page[i];
-		if (page)
-			__free_page(page);
-	}
-
+	free_arg_pages(bprm);
 	if (bprm->security)
 		security_bprm_free(bprm);
 
 out_mm:
 	if (bprm->mm)
-		mmdrop(bprm->mm);
+		mmput (bprm->mm);
 
 out_file:
 	if (bprm->file) {
 		allow_write_access(bprm->file);
 		fput(bprm->file);
 	}
-
 out_kfree:
 	kfree(bprm);
 

commit bdf4c48af20a3b0f01671799ace345e3d49576da
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Jul 19 01:48:15 2007 -0700

    audit: rework execve audit
    
    The purpose of audit_bprm() is to log the argv array to a userspace daemon at
    the end of the execve system call.  Since user-space hasn't had time to run,
    this array is still in pristine state on the process' stack; so no need to
    copy it, we can just grab it from there.
    
    In order to minimize the damage to audit_log_*() copy each string into a
    temporary kernel buffer first.
    
    Currently the audit code requires that the full argument vector fits in a
    single packet.  So currently it does clip the argv size to a (sysctl) limit,
    but only when execve auditing is enabled.
    
    If the audit protocol gets extended to allow for multiple packets this check
    can be removed.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Ollie Wild <aaw@google.com>
    Cc: <linux-audit@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index f20561ff4528..2e3f7950c185 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1154,6 +1154,7 @@ int do_execve(char * filename,
 {
 	struct linux_binprm *bprm;
 	struct file *file;
+	unsigned long env_p;
 	int retval;
 	int i;
 
@@ -1208,9 +1209,11 @@ int do_execve(char * filename,
 	if (retval < 0)
 		goto out;
 
+	env_p = bprm->p;
 	retval = copy_strings(bprm->argc, argv, bprm);
 	if (retval < 0)
 		goto out;
+	bprm->argv_len = env_p - bprm->p;
 
 	retval = search_binary_handler(bprm,regs);
 	if (retval >= 0) {

commit 492c8b332e3af279ffadf49b85967d5e43810923
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 23 13:57:53 2007 -0700

    uselib: add missing MNT_NOEXEC check
    
    We don't allow loading ELF shared library from noexec points so the
    same should apply to sys_uselib aswell.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Ulrich Drepper <drepper@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0b685888ff6f..f20561ff4528 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -134,6 +134,9 @@ asmlinkage long sys_uselib(const char __user * library)
 	if (error)
 		goto out;
 
+	error = -EACCES;
+	if (nd.mnt->mnt_flags & MNT_NOEXEC)
+		goto exit;
 	error = -EINVAL;
 	if (!S_ISREG(nd.dentry->d_inode->i_mode))
 		goto exit;

commit 71ce92f3fa442069670a52fa6230a6064c4517b3
Author: Dan Aloni <da-x@monatomic.org>
Date:   Wed May 16 22:11:16 2007 -0700

    make sysctl/kernel/core_pattern and fs/exec.c agree on maximum core filename size
    
    Make sysctl/kernel/core_pattern and fs/exec.c agree on maximum core
    filename size and change it to 128, so that extensive patterns such as
    '/local/cores/%e-%h-%s-%t-%p.core' won't result in truncated filename
    generation.
    
    Signed-off-by: Dan Aloni <da-x@monatomic.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 70fa36554c14..0b685888ff6f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -60,7 +60,7 @@
 #endif
 
 int core_uses_pid;
-char core_pattern[128] = "core";
+char core_pattern[CORENAME_MAX_SIZE] = "core";
 int suid_dumpable = 0;
 
 EXPORT_SYMBOL(suid_dumpable);
@@ -1264,8 +1264,6 @@ int set_binfmt(struct linux_binfmt *new)
 
 EXPORT_SYMBOL(set_binfmt);
 
-#define CORENAME_MAX_SIZE 64
-
 /* format_corename will inspect the pattern parameter, and output a
  * name into corename, which must have space for at least
  * CORENAME_MAX_SIZE bytes plus one byte for the zero terminator.

commit 853da0022023c046e0a5ccc51d427745f0c94de7
Merge: 5884c40668a9 0a4ff8c2598b
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Fri May 11 09:57:16 2007 -0700

    Merge branch 'audit.b38' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/audit-current
    
    * 'audit.b38' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/audit-current:
      [PATCH] Abnormal End of Processes
      [PATCH] match audit name data
      [PATCH] complete message queue auditing
      [PATCH] audit inode for all xattr syscalls
      [PATCH] initialize name osid
      [PATCH] audit signal recipients
      [PATCH] add SIGNAL syscall class (v3)
      [PATCH] auditing ptrace

commit fba2afaaec790dc5ab4ae8827972f342211bbb86
Author: Davide Libenzi <davidel@xmailserver.org>
Date:   Thu May 10 22:23:13 2007 -0700

    signal/timer/event: signalfd core
    
    This patch series implements the new signalfd() system call.
    
    I took part of the original Linus code (and you know how badly it can be
    broken :), and I added even more breakage ;) Signals are fetched from the same
    signal queue used by the process, so signalfd will compete with standard
    kernel delivery in dequeue_signal().  If you want to reliably fetch signals on
    the signalfd file, you need to block them with sigprocmask(SIG_BLOCK).  This
    seems to be working fine on my Dual Opteron machine.  I made a quick test
    program for it:
    
    http://www.xmailserver.org/signafd-test.c
    
    The signalfd() system call implements signal delivery into a file descriptor
    receiver.  The signalfd file descriptor if created with the following API:
    
    int signalfd(int ufd, const sigset_t *mask, size_t masksize);
    
    The "ufd" parameter allows to change an existing signalfd sigmask, w/out going
    to close/create cycle (Linus idea).  Use "ufd" == -1 if you want a brand new
    signalfd file.
    
    The "mask" allows to specify the signal mask of signals that we are interested
    in.  The "masksize" parameter is the size of "mask".
    
    The signalfd fd supports the poll(2) and read(2) system calls.  The poll(2)
    will return POLLIN when signals are available to be dequeued.  As a direct
    consequence of supporting the Linux poll subsystem, the signalfd fd can use
    used together with epoll(2) too.
    
    The read(2) system call will return a "struct signalfd_siginfo" structure in
    the userspace supplied buffer.  The return value is the number of bytes copied
    in the supplied buffer, or -1 in case of error.  The read(2) call can also
    return 0, in case the sighand structure to which the signalfd was attached,
    has been orphaned.  The O_NONBLOCK flag is also supported, and read(2) will
    return -EAGAIN in case no signal is available.
    
    If the size of the buffer passed to read(2) is lower than sizeof(struct
    signalfd_siginfo), -EINVAL is returned.  A read from the signalfd can also
    return -ERESTARTSYS in case a signal hits the process.  The format of the
    struct signalfd_siginfo is, and the valid fields depends of the (->code &
    __SI_MASK) value, in the same way a struct siginfo would:
    
    struct signalfd_siginfo {
            __u32 signo;    /* si_signo */
            __s32 err;      /* si_errno */
            __s32 code;     /* si_code */
            __u32 pid;      /* si_pid */
            __u32 uid;      /* si_uid */
            __s32 fd;       /* si_fd */
            __u32 tid;      /* si_fd */
            __u32 band;     /* si_band */
            __u32 overrun;  /* si_overrun */
            __u32 trapno;   /* si_trapno */
            __s32 status;   /* si_status */
            __s32 svint;    /* si_int */
            __u64 svptr;    /* si_ptr */
            __u64 utime;    /* si_utime */
            __u64 stime;    /* si_stime */
            __u64 addr;     /* si_addr */
    };
    
    [akpm@linux-foundation.org: fix signalfd_copyinfo() on i386]
    Signed-off-by: Davide Libenzi <davidel@xmailserver.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2255dc72deef..955a8eb66d70 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -50,6 +50,7 @@
 #include <linux/tsacct_kern.h>
 #include <linux/cn_proc.h>
 #include <linux/audit.h>
+#include <linux/signalfd.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -581,6 +582,13 @@ static int de_thread(struct task_struct *tsk)
 	struct task_struct *leader = NULL;
 	int count;
 
+	/*
+	 * Tell all the sighand listeners that this sighand has
+	 * been detached. The signalfd_detach() function grabs the
+	 * sighand lock, if signal listeners are present on the sighand.
+	 */
+	signalfd_detach(tsk);
+
 	/*
 	 * If we don't share sighandlers, then we aren't sharing anything
 	 * and we can just re-use it all.
@@ -757,8 +765,7 @@ static int de_thread(struct task_struct *tsk)
 		spin_unlock(&oldsighand->siglock);
 		write_unlock_irq(&tasklist_lock);
 
-		if (atomic_dec_and_test(&oldsighand->count))
-			kmem_cache_free(sighand_cachep, oldsighand);
+		__cleanup_sighand(oldsighand);
 	}
 
 	BUG_ON(!thread_group_leader(tsk));

commit e713d0dab21a68500720e222fa02567fc7dfb14b
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu May 10 22:22:58 2007 -0700

    attach_pid() with struct pid parameter
    
    attach_pid() currently takes a pid_t and then uses find_pid() to find the
    corresponding struct pid.  Sometimes we already have the struct pid.  We can
    then skip find_pid() if attach_pid() were to take a struct pid parameter.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: <containers@lists.osdl.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 1ba85c7fc6af..2255dc72deef 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -702,7 +702,7 @@ static int de_thread(struct task_struct *tsk)
 		 */
 		detach_pid(tsk, PIDTYPE_PID);
 		tsk->pid = leader->pid;
-		attach_pid(tsk, PIDTYPE_PID,  tsk->pid);
+		attach_pid(tsk, PIDTYPE_PID,  find_pid(tsk->pid));
 		transfer_pid(leader, tsk, PIDTYPE_PGID);
 		transfer_pid(leader, tsk, PIDTYPE_SID);
 		list_replace_rcu(&leader->tasks, &tsk->tasks);

commit 0a4ff8c2598b72f2fa9d50aae9e1809e684dbf41
Author: Steve Grubb <sgrubb@redhat.com>
Date:   Thu Apr 19 10:28:21 2007 -0400

    [PATCH] Abnormal End of Processes
    
    Hi,
    
    I have been working on some code that detects abnormal events based on audit
    system events. One kind of event that we currently have no visibility for is
    when a program terminates due to segfault - which should never happen on a
    production machine. And if it did, you'd want to investigate it. Attached is a
    patch that collects these events and sends them into the audit system.
    
    Signed-off-by: Steve Grubb <sgrubb@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 1ba85c7fc6af..7cf078ec758e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1488,6 +1488,8 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	int flag = 0;
 	int ispipe = 0;
 
+	audit_core_dumps(signr);
+
 	binfmt = current->binfmt;
 	if (!binfmt || !binfmt->core_dump)
 		goto fail;

commit 98701d1b0fe98b477b53df89114e6862547f8107
Author: kalash nainwal <kalash.nainwal@gmail.com>
Date:   Tue May 8 00:28:31 2007 -0700

    (re)register_binfmt returns with -EBUSY
    
    When a binary format is unregistered and re-registered, register_binfmt
    fails with -EBUSY.  The reason is that unregister_binfmt does not set
    fmt->next to NULL, and seeing (fmt->next != NULL), register_binfmt fails
    with -EBUSY.
    
    One can find his way around by explicitly setting fmt->next to NULL after
    unregistering, but that is kind of unclean (one should better be using only
    the interfaces, and not the interal members, isn't it?)
    
    Attached one-liner can fix it.
    
    Signed-off-by: Kalash Nainwal <kalash.nainwal@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index f1691cd0c9d2..1ba85c7fc6af 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -100,6 +100,7 @@ int unregister_binfmt(struct linux_binfmt * fmt)
 	while (*tmp) {
 		if (fmt == *tmp) {
 			*tmp = fmt->next;
+			fmt->next = NULL;
 			write_unlock(&binfmt_lock);
 			return 0;
 		}

commit 4fc75ff4816c3483b4b772b2f6cb3d8fd88ca547
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue May 8 00:25:16 2007 -0700

    exec: fix remove_arg_zero
    
    Petr Tesarik discovered a problem in remove_arg_zero(). He writes:
    
     When a script is loaded, load_script() replaces argv[0] with the
     name of the interpreter and the filename passed to the exec syscall.
     However, there is no guarantee that the length of the interpreter
     name plus the length of the filename is greater than the length of
     the original argv[0]. If the difference happens to cross a page boundary,
     setup_arg_pages() will call put_dirty_page() [aka install_arg_page()]
     with an address outside the VMA.
    
     Therefore, remove_arg_zero() must free all pages which would be unused
     after the argument is removed.
    
    So, rewrite the remove_arg_zero function without gotos, with a few comments,
    and with the commonly used explicit index/offset. This fixes the problem
    and makes it easier to understand as well.
    
    [a.p.zijlstra@chello.nl: add comment]
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Petr Tesarik <ptesarik@suse.cz>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 3155e915307a..f1691cd0c9d2 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -982,33 +982,51 @@ void compute_creds(struct linux_binprm *bprm)
 	task_unlock(current);
 	security_bprm_post_apply_creds(bprm);
 }
-
 EXPORT_SYMBOL(compute_creds);
 
+/*
+ * Arguments are '\0' separated strings found at the location bprm->p
+ * points to; chop off the first by relocating brpm->p to right after
+ * the first '\0' encountered.
+ */
 void remove_arg_zero(struct linux_binprm *bprm)
 {
 	if (bprm->argc) {
-		unsigned long offset;
-		char * kaddr;
-		struct page *page;
+		char ch;
 
-		offset = bprm->p % PAGE_SIZE;
-		goto inside;
+		do {
+			unsigned long offset;
+			unsigned long index;
+			char *kaddr;
+			struct page *page;
 
-		while (bprm->p++, *(kaddr+offset++)) {
-			if (offset != PAGE_SIZE)
-				continue;
-			offset = 0;
-			kunmap_atomic(kaddr, KM_USER0);
-inside:
-			page = bprm->page[bprm->p/PAGE_SIZE];
+			offset = bprm->p & ~PAGE_MASK;
+			index = bprm->p >> PAGE_SHIFT;
+
+			page = bprm->page[index];
 			kaddr = kmap_atomic(page, KM_USER0);
-		}
-		kunmap_atomic(kaddr, KM_USER0);
+
+			/* run through page until we reach end or find NUL */
+			do {
+				ch = *(kaddr + offset);
+
+				/* discard that character... */
+				bprm->p++;
+				offset++;
+			} while (offset < PAGE_SIZE && ch != '\0');
+
+			kunmap_atomic(kaddr, KM_USER0);
+
+			/* free the old page */
+			if (offset == PAGE_SIZE) {
+				__free_page(page);
+				bprm->page[index] = NULL;
+			}
+		} while (ch != '\0');
+
 		bprm->argc--;
 	}
 }
-
 EXPORT_SYMBOL(remove_arg_zero);
 
 /*

commit c4bbafda70a0fc95c6595bffd6825ef264050d01
Author: Alan Cox <alan@lxorguk.ukuu.org.uk>
Date:   Mon Apr 16 22:53:13 2007 -0700

    exec.c: fix coredump to pipe problem and obscure "security hole"
    
    The patch checks for "|" in the pattern not the output and doesn't nail a
    pid on to a piped name (as it is a program name not a file)
    
    Also fixes a very very obscure security corner case.  If you happen to have
    decided on a core pattern that starts with the program name then the user
    can run a program called "|myevilhack" as it stands.  I doubt anyone does
    this.
    
    Signed-off-by: Alan Cox <alan@redhat.com>
    Confirmed-by: Christopher S. Aker <caker@theshore.net>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7e36c6f6f538..3155e915307a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1244,13 +1244,17 @@ EXPORT_SYMBOL(set_binfmt);
  * name into corename, which must have space for at least
  * CORENAME_MAX_SIZE bytes plus one byte for the zero terminator.
  */
-static void format_corename(char *corename, const char *pattern, long signr)
+static int format_corename(char *corename, const char *pattern, long signr)
 {
 	const char *pat_ptr = pattern;
 	char *out_ptr = corename;
 	char *const out_end = corename + CORENAME_MAX_SIZE;
 	int rc;
 	int pid_in_pattern = 0;
+	int ispipe = 0;
+
+	if (*pattern == '|')
+		ispipe = 1;
 
 	/* Repeat as long as we have more pattern to process and more output
 	   space */
@@ -1341,8 +1345,8 @@ static void format_corename(char *corename, const char *pattern, long signr)
 	 *
 	 * If core_pattern does not include a %p (as is the default)
 	 * and core_uses_pid is set, then .%pid will be appended to
-	 * the filename */
-	if (!pid_in_pattern
+	 * the filename. Do not do this for piped commands. */
+	if (!ispipe && !pid_in_pattern
             && (core_uses_pid || atomic_read(&current->mm->mm_users) != 1)) {
 		rc = snprintf(out_ptr, out_end - out_ptr,
 			      ".%d", current->tgid);
@@ -1350,8 +1354,9 @@ static void format_corename(char *corename, const char *pattern, long signr)
 			goto out;
 		out_ptr += rc;
 	}
-      out:
+out:
 	*out_ptr = 0;
+	return ispipe;
 }
 
 static void zap_process(struct task_struct *start)
@@ -1502,16 +1507,15 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 * uses lock_kernel()
 	 */
  	lock_kernel();
-	format_corename(corename, core_pattern, signr);
+	ispipe = format_corename(corename, core_pattern, signr);
 	unlock_kernel();
- 	if (corename[0] == '|') {
+ 	if (ispipe) {
 		/* SIGPIPE can happen, but it's just never processed */
  		if(call_usermodehelper_pipe(corename+1, NULL, NULL, &file)) {
  			printk(KERN_INFO "Core dump to %s pipe failed\n",
 			       corename);
  			goto fail_unlock;
  		}
-		ispipe = 1;
  	} else
  		file = filp_open(corename,
 				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag,

commit c376222960ae91d5ffb9197ee36771aaed1d9f90
Author: Robert P. J. Day <rpjday@mindspring.com>
Date:   Sat Feb 10 01:45:03 2007 -0800

    [PATCH] Transform kmem_cache_alloc()+memset(0) -> kmem_cache_zalloc().
    
    Replace appropriate pairs of "kmem_cache_alloc()" + "memset(0)" with the
    corresponding "kmem_cache_zalloc()" call.
    
    Signed-off-by: Robert P. J. Day <rpjday@mindspring.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Cc: Greg KH <greg@kroah.com>
    Acked-by: Joel Becker <Joel.Becker@oracle.com>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Jan Kara <jack@ucw.cz>
    Cc: Michael Halcrow <mhalcrow@us.ibm.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: James Morris <jmorris@namei.org>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/exec.c b/fs/exec.c
index 11fe93f7363c..7e36c6f6f538 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -405,12 +405,10 @@ int setup_arg_pages(struct linux_binprm *bprm,
 		bprm->loader += stack_base;
 	bprm->exec += stack_base;
 
-	mpnt = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
+	mpnt = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
 	if (!mpnt)
 		return -ENOMEM;
 
-	memset(mpnt, 0, sizeof(*mpnt));
-
 	down_write(&mm->mmap_sem);
 	{
 		mpnt->vm_mm = mm;

commit bbea9f69668a3d0cf9feba15a724cd02896f8675
Author: Vadim Lobanov <vlobanov@speakeasy.net>
Date:   Sun Dec 10 02:21:12 2006 -0800

    [PATCH] fdtable: Make fdarray and fdsets equal in size
    
    Currently, each fdtable supports three dynamically-sized arrays of data: the
    fdarray and two fdsets.  The code allows the number of fds supported by the
    fdarray (fdtable->max_fds) to differ from the number of fds supported by each
    of the fdsets (fdtable->max_fdset).
    
    In practice, it is wasteful for these two sizes to differ: whenever we hit a
    limit on the smaller-capacity structure, we will reallocate the entire fdtable
    and all the dynamic arrays within it, so any delta in the memory used by the
    larger-capacity structure will never be touched at all.
    
    Rather than hogging this excess, we shouldn't even allocate it in the first
    place, and keep the capacities of the fdarray and the fdsets equal.  This
    patch removes fdtable->max_fdset.  As an added bonus, most of the supporting
    code becomes simpler.
    
    Signed-off-by: Vadim Lobanov <vlobanov@speakeasy.net>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 12d8cd461b41..11fe93f7363c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -783,7 +783,7 @@ static void flush_old_files(struct files_struct * files)
 		j++;
 		i = j * __NFDBITS;
 		fdt = files_fdtable(files);
-		if (i >= fdt->max_fds || i >= fdt->max_fdset)
+		if (i >= fdt->max_fds)
 			break;
 		set = fdt->close_on_exec->fds_bits[j];
 		if (!set)

commit 84d737866e2babdeab0c6b18ea155c6a649663b8
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Fri Dec 8 02:38:01 2006 -0800

    [PATCH] add child reaper to pid_namespace
    
    Add a per pid_namespace child-reaper.  This is needed so processes are reaped
    within the same pid space and do not spill over to the parent pid space.  Its
    also needed so containers preserve existing semantic that pid == 1 would reap
    orphaned children.
    
    This is based on Eric Biederman's patch: http://lkml.org/lkml/2006/2/6/285
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 60433e2254a4..12d8cd461b41 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -38,6 +38,7 @@
 #include <linux/binfmts.h>
 #include <linux/swap.h>
 #include <linux/utsname.h>
+#include <linux/pid_namespace.h>
 #include <linux/module.h>
 #include <linux/namei.h>
 #include <linux/proc_fs.h>
@@ -620,8 +621,8 @@ static int de_thread(struct task_struct *tsk)
 	 * Reparenting needs write_lock on tasklist_lock,
 	 * so it is safe to do it under read_lock.
 	 */
-	if (unlikely(tsk->group_leader == child_reaper))
-		child_reaper = tsk;
+	if (unlikely(tsk->group_leader == child_reaper(tsk)))
+		tsk->nsproxy->pid_ns->child_reaper = tsk;
 
 	zap_other_threads(tsk);
 	read_unlock(&tasklist_lock);

commit 0f7fc9e4d03987fe29f6dd4aa67e4c56eb7ecb05
Author: Josef "Jeff" Sipek <jsipek@cs.sunysb.edu>
Date:   Fri Dec 8 02:36:35 2006 -0800

    [PATCH] VFS: change struct file to use struct path
    
    This patch changes struct file to use struct path instead of having
    independent pointers to struct dentry and struct vfsmount, and converts all
    users of f_{dentry,vfsmnt} in fs/ to use f_path.{dentry,mnt}.
    
    Additionally, it adds two #define's to make the transition easier for users of
    the f_dentry and f_vfsmnt.
    
    Signed-off-by: Josef "Jeff" Sipek <jsipek@cs.sunysb.edu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index add0e03c3ea9..60433e2254a4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -912,7 +912,7 @@ EXPORT_SYMBOL(flush_old_exec);
 int prepare_binprm(struct linux_binprm *bprm)
 {
 	int mode;
-	struct inode * inode = bprm->file->f_dentry->d_inode;
+	struct inode * inode = bprm->file->f_path.dentry->d_inode;
 	int retval;
 
 	mode = inode->i_mode;
@@ -922,7 +922,7 @@ int prepare_binprm(struct linux_binprm *bprm)
 	bprm->e_uid = current->euid;
 	bprm->e_gid = current->egid;
 
-	if(!(bprm->file->f_vfsmnt->mnt_flags & MNT_NOSUID)) {
+	if(!(bprm->file->f_path.mnt->mnt_flags & MNT_NOSUID)) {
 		/* Set-uid? */
 		if (mode & S_ISUID) {
 			current->personality &= ~PER_CLEAR_ON_SETID;
@@ -1519,10 +1519,10 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 				 0600);
 	if (IS_ERR(file))
 		goto fail_unlock;
-	inode = file->f_dentry->d_inode;
+	inode = file->f_path.dentry->d_inode;
 	if (inode->i_nlink > 1)
 		goto close_fail;	/* multiple links - don't dump */
-	if (!ispipe && d_unhashed(file->f_dentry))
+	if (!ispipe && d_unhashed(file->f_path.dentry))
 		goto close_fail;
 
 	/* AK: actually i see no reason to not allow this for named pipes etc.,
@@ -1533,7 +1533,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		goto close_fail;
 	if (!file->f_op->write)
 		goto close_fail;
-	if (!ispipe && do_truncate(file->f_dentry, 0, 0, file) != 0)
+	if (!ispipe && do_truncate(file->f_path.dentry, 0, 0, file) != 0)
 		goto close_fail;
 
 	retval = binfmt->core_dump(signr, regs, file);

commit 6d4df677f8a60ea6bc0ef1a596c1a3a79b1d4882
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Wed Dec 6 20:40:39 2006 -0800

    [PATCH] do_coredump() and not stopping rewrite attacks?
    
    On Sat, Dec 02, 2006 at 11:47:44PM +0300, Alexey Dobriyan wrote:
    > David Binderman compiled 2.6.19 with icc and grepped for "was set but never
    > used". Many warnings are on
    >       http://coderock.org/kj/unused-2.6.19-fs
    
    Heh, the very first line:
    fs/exec.c(1465): remark #593: variable "flag" was set but never used
    
    fs/exec.c:
      1477          /*
      1478           *      We cannot trust fsuid as being the "true" uid of the
      1479           *      process nor do we know its entire history. We only know it
      1480           *      was tainted so we dump it as root in mode 2.
      1481           */
      1482          if (mm->dumpable == 2) {        /* Setuid core dump mode */
      1483                  flag = O_EXCL;          /* Stop rewrite attacks */
      1484                  current->fsuid = 0;     /* Dump root private */
      1485          }
    
    And then filp_open follows with "flag" totally ignored.
    
    (akpm: this restores the code to Alan's original version.  Andi's "Support
    piping into commands in /proc/sys/kernel/core_pattern" (cset d025c9db) broke
    it).
    
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: <stable@kerenl.org>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2092bd207463..add0e03c3ea9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1515,7 +1515,8 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		ispipe = 1;
  	} else
  		file = filp_open(corename,
-				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE, 0600);
+				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag,
+				 0600);
 	if (IS_ERR(file))
 		goto fail_unlock;
 	inode = file->f_dentry->d_inode;

commit e94b1766097d53e6f3ccfb36c8baa562ffeda3fc
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed Dec 6 20:33:17 2006 -0800

    [PATCH] slab: remove SLAB_KERNEL
    
    SLAB_KERNEL is an alias of GFP_KERNEL.
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index d993ea1a81ae..2092bd207463 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -404,7 +404,7 @@ int setup_arg_pages(struct linux_binprm *bprm,
 		bprm->loader += stack_base;
 	bprm->exec += stack_base;
 
-	mpnt = kmem_cache_alloc(vm_area_cachep, SLAB_KERNEL);
+	mpnt = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
 	if (!mpnt)
 		return -ENOMEM;
 

commit e9ff3990f08e9a0c2839cc22808b01732ea5b3e4
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Mon Oct 2 02:18:11 2006 -0700

    [PATCH] namespaces: utsname: switch to using uts namespaces
    
    Replace references to system_utsname to the per-process uts namespace
    where appropriate.  This includes things like uname.
    
    Changes: Per Eric Biederman's comments, use the per-process uts namespace
            for ELF_PLATFORM, sunrpc, and parts of net/ipv4/ipconfig.c
    
    [jdike@addtoit.com: UML fix]
    [clg@fr.ibm.com: cleanup]
    [akpm@osdl.org: build fix]
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Andrey Savochkin <saw@sw.ru>
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Jeff Dike <jdike@addtoit.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6270f8f20a63..d993ea1a81ae 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1318,7 +1318,7 @@ static void format_corename(char *corename, const char *pattern, long signr)
 			case 'h':
 				down_read(&uts_sem);
 				rc = snprintf(out_ptr, out_end - out_ptr,
-					      "%s", system_utsname.nodename);
+					      "%s", utsname()->nodename);
 				up_read(&uts_sem);
 				if (rc > out_end - out_ptr)
 					goto out;

commit d025c9db7f31fc0554ce7fb2dfc78d35a77f3487
Author: Andi Kleen <ak@suse.de>
Date:   Sat Sep 30 23:29:28 2006 -0700

    [PATCH] Support piping into commands in /proc/sys/kernel/core_pattern
    
    Using the infrastructure created in previous patches implement support to
    pipe core dumps into programs.
    
    This is done by overloading the existing core_pattern sysctl
    with a new syntax:
    
    |program
    
    When the first character of the pattern is a '|' the kernel will instead
    threat the rest of the pattern as a command to run.  The core dump will be
    written to the standard input of that program instead of to a file.
    
    This is useful for having automatic core dump analysis without filling up
    disks.  The program can do some simple analysis and save only a summary of
    the core dump.
    
    The core dump proces will run with the privileges and in the name space of
    the process that caused the core dump.
    
    I also increased the core pattern size to 128 bytes so that longer command
    lines fit.
    
    Most of the changes comes from allowing core dumps without seeks.  They are
    fairly straight forward though.
    
    One small incompatibility is that if someone had a core pattern previously
    that started with '|' they will get suddenly new behaviour.  I think that's
    unlikely to be a real problem though.
    
    Additional background:
    
    > Very nice, do you happen to have a program that can accept this kind of
    > input for crash dumps?  I'm guessing that the embedded people will
    > really want this functionality.
    
    I had a cheesy demo/prototype.  Basically it wrote the dump to a file again,
    ran gdb on it to get a backtrace and wrote the summary to a shared directory.
    Then there was a simple CGI script to generate a "top 10" crashes HTML
    listing.
    
    Unfortunately this still had the disadvantage to needing full disk space for a
    dump except for deleting it afterwards (in fact it was worse because over the
    pipe holes didn't work so if you have a holey address map it would require
    more space).
    
    Fortunately gdb seems to be happy to handle /proc/pid/fd/xxx input pipes as
    cores (at least it worked with zsh's =(cat core) syntax), so it would be
    likely possible to do it without temporary space with a simple wrapper that
    calls it in the right way.  I ran out of time before doing that though.
    
    The demo prototype scripts weren't very good.  If there is really interest I
    can dig them out (they are currently on a laptop disk on the desk with the
    laptop itself being in service), but I would recommend to rewrite them for any
    serious application of this and fix the disk space problem.
    
    Also to be really useful it should probably find a way to automatically fetch
    the debuginfos (I cheated and just installed them in advance).  If nobody else
    does it I can probably do the rewrite myself again at some point.
    
    My hope at some point was that desktops would support it in their builtin
    crash reporters, but at least the KDE people I talked too seemed to be happy
    with their user space only solution.
    
    Alan sayeth:
    
      I don't believe that piping as such as neccessarily the right model, but
      the ability to intercept and processes core dumps from user space is asked
      for by many enterprise users as well.  They want to know about, capture,
      analyse and process core dumps, often centrally and in automated form.
    
    [akpm@osdl.org: loff_t != unsigned long]
    Signed-off-by: Andi Kleen <ak@suse.de>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0db3fc3c5f0f..6270f8f20a63 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -58,7 +58,7 @@
 #endif
 
 int core_uses_pid;
-char core_pattern[65] = "core";
+char core_pattern[128] = "core";
 int suid_dumpable = 0;
 
 EXPORT_SYMBOL(suid_dumpable);
@@ -1463,6 +1463,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	int retval = 0;
 	int fsuid = current->fsuid;
 	int flag = 0;
+	int ispipe = 0;
 
 	binfmt = current->binfmt;
 	if (!binfmt || !binfmt->core_dump)
@@ -1504,22 +1505,34 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
  	lock_kernel();
 	format_corename(corename, core_pattern, signr);
 	unlock_kernel();
-	file = filp_open(corename, O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag, 0600);
+ 	if (corename[0] == '|') {
+		/* SIGPIPE can happen, but it's just never processed */
+ 		if(call_usermodehelper_pipe(corename+1, NULL, NULL, &file)) {
+ 			printk(KERN_INFO "Core dump to %s pipe failed\n",
+			       corename);
+ 			goto fail_unlock;
+ 		}
+		ispipe = 1;
+ 	} else
+ 		file = filp_open(corename,
+				 O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE, 0600);
 	if (IS_ERR(file))
 		goto fail_unlock;
 	inode = file->f_dentry->d_inode;
 	if (inode->i_nlink > 1)
 		goto close_fail;	/* multiple links - don't dump */
-	if (d_unhashed(file->f_dentry))
+	if (!ispipe && d_unhashed(file->f_dentry))
 		goto close_fail;
 
-	if (!S_ISREG(inode->i_mode))
+	/* AK: actually i see no reason to not allow this for named pipes etc.,
+	   but keep the previous behaviour for now. */
+	if (!ispipe && !S_ISREG(inode->i_mode))
 		goto close_fail;
 	if (!file->f_op)
 		goto close_fail;
 	if (!file->f_op->write)
 		goto close_fail;
-	if (do_truncate(file->f_dentry, 0, 0, file) != 0)
+	if (!ispipe && do_truncate(file->f_dentry, 0, 0, file) != 0)
 		goto close_fail;
 
 	retval = binfmt->core_dump(signr, regs, file);

commit 8f0ab5147951267134612570604cf8341901a80c
Author: Jay Lan <jlan@engr.sgi.com>
Date:   Sat Sep 30 23:28:59 2006 -0700

    [PATCH] csa: convert CONFIG tag for extended accounting routines
    
    There were a few accounting data/macros that are used in CSA but are #ifdef'ed
    inside CONFIG_BSD_PROCESS_ACCT.  This patch is to change those ifdef's from
    CONFIG_BSD_PROCESS_ACCT to CONFIG_TASK_XACCT.  A few defines are moved from
    kernel/acct.c and include/linux/acct.h to kernel/tsacct.c and
    include/linux/tsacct_kern.h.
    
    Signed-off-by: Jay Lan <jlan@sgi.com>
    Cc: Shailabh Nagar <nagar@watson.ibm.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Jes Sorensen <jes@sgi.com>
    Cc: Chris Sturtivant <csturtiv@sgi.com>
    Cc: Tony Ernst <tee@sgi.com>
    Cc: Guillaume Thouvenin <guillaume.thouvenin@bull.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index a8efe35176b0..0db3fc3c5f0f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -46,7 +46,7 @@
 #include <linux/security.h>
 #include <linux/syscalls.h>
 #include <linux/rmap.h>
-#include <linux/acct.h>
+#include <linux/tsacct_kern.h>
 #include <linux/cn_proc.h>
 #include <linux/audit.h>
 

commit 3b9b8ab65d8eed784b9164d03807cb2bda7b5cd6
Author: Kirill Korotaev <dev@sw.ru>
Date:   Fri Sep 29 02:00:05 2006 -0700

    [PATCH] Fix unserialized task->files changing
    
    Fixed race on put_files_struct on exec with proc.  Restoring files on
    current on error path may lead to proc having a pointer to already kfree-d
    files_struct.
    
    ->files changing at exit.c and khtread.c are safe as exit_files() makes all
    things under lock.
    
    Found during OpenVZ stress testing.
    
    [akpm@osdl.org: add export]
    Signed-off-by: Pavel Emelianov <xemul@openvz.org>
    Signed-off-by: Kirill Korotaev <dev@openvz.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 97df6e0aeaee..a8efe35176b0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -898,8 +898,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	return 0;
 
 mmap_failed:
-	put_files_struct(current->files);
-	current->files = files;
+	reset_files_struct(current, files);
 out:
 	return retval;
 }

commit aafe6c2a2b6bce5a3a4913ce5c07e85ea143144d
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Sep 27 01:51:13 2006 -0700

    [PATCH] de_thread: Use tsk not current
    
    Ingo Oeser pointed out that because current expands to an inline function
    it is more space efficient and somewhat faster to simply keep a cached copy
    of current in another variable.  This patch implements that for the
    de_thread function.
    
    (akpm: saves nearly 100 bytes of text on x86)
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index b7aa3d6422d6..97df6e0aeaee 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -595,7 +595,7 @@ static int de_thread(struct task_struct *tsk)
 	if (!newsighand)
 		return -ENOMEM;
 
-	if (thread_group_empty(current))
+	if (thread_group_empty(tsk))
 		goto no_thread_group;
 
 	/*
@@ -620,17 +620,17 @@ static int de_thread(struct task_struct *tsk)
 	 * Reparenting needs write_lock on tasklist_lock,
 	 * so it is safe to do it under read_lock.
 	 */
-	if (unlikely(current->group_leader == child_reaper))
-		child_reaper = current;
+	if (unlikely(tsk->group_leader == child_reaper))
+		child_reaper = tsk;
 
-	zap_other_threads(current);
+	zap_other_threads(tsk);
 	read_unlock(&tasklist_lock);
 
 	/*
 	 * Account for the thread group leader hanging around:
 	 */
 	count = 1;
-	if (!thread_group_leader(current)) {
+	if (!thread_group_leader(tsk)) {
 		count = 2;
 		/*
 		 * The SIGALRM timer survives the exec, but needs to point
@@ -639,14 +639,14 @@ static int de_thread(struct task_struct *tsk)
 		 * synchronize with any firing (by calling del_timer_sync)
 		 * before we can safely let the old group leader die.
 		 */
-		sig->tsk = current;
+		sig->tsk = tsk;
 		spin_unlock_irq(lock);
 		if (hrtimer_cancel(&sig->real_timer))
 			hrtimer_restart(&sig->real_timer);
 		spin_lock_irq(lock);
 	}
 	while (atomic_read(&sig->count) > count) {
-		sig->group_exit_task = current;
+		sig->group_exit_task = tsk;
 		sig->notify_count = count;
 		__set_current_state(TASK_UNINTERRUPTIBLE);
 		spin_unlock_irq(lock);
@@ -662,13 +662,13 @@ static int de_thread(struct task_struct *tsk)
 	 * do is to wait for the thread group leader to become inactive,
 	 * and to assume its PID:
 	 */
-	if (!thread_group_leader(current)) {
+	if (!thread_group_leader(tsk)) {
 		/*
 		 * Wait for the thread group leader to be a zombie.
 		 * It should already be zombie at this point, most
 		 * of the time.
 		 */
-		leader = current->group_leader;
+		leader = tsk->group_leader;
 		while (leader->exit_state != EXIT_ZOMBIE)
 			yield();
 
@@ -682,12 +682,12 @@ static int de_thread(struct task_struct *tsk)
 		 * When we take on its identity by switching to its PID, we
 		 * also take its birthdate (always earlier than our own).
 		 */
-		current->start_time = leader->start_time;
+		tsk->start_time = leader->start_time;
 
 		write_lock_irq(&tasklist_lock);
 
-		BUG_ON(leader->tgid != current->tgid);
-		BUG_ON(current->pid == current->tgid);
+		BUG_ON(leader->tgid != tsk->tgid);
+		BUG_ON(tsk->pid == tsk->tgid);
 		/*
 		 * An exec() starts a new thread group with the
 		 * TGID of the previous thread group. Rehash the
@@ -700,17 +700,17 @@ static int de_thread(struct task_struct *tsk)
 		 * Note: The old leader also uses this pid until release_task
 		 *       is called.  Odd but simple and correct.
 		 */
-		detach_pid(current, PIDTYPE_PID);
-		current->pid = leader->pid;
-		attach_pid(current, PIDTYPE_PID,  current->pid);
-		transfer_pid(leader, current, PIDTYPE_PGID);
-		transfer_pid(leader, current, PIDTYPE_SID);
-		list_replace_rcu(&leader->tasks, &current->tasks);
+		detach_pid(tsk, PIDTYPE_PID);
+		tsk->pid = leader->pid;
+		attach_pid(tsk, PIDTYPE_PID,  tsk->pid);
+		transfer_pid(leader, tsk, PIDTYPE_PGID);
+		transfer_pid(leader, tsk, PIDTYPE_SID);
+		list_replace_rcu(&leader->tasks, &tsk->tasks);
 
-		current->group_leader = current;
-		leader->group_leader = current;
+		tsk->group_leader = tsk;
+		leader->group_leader = tsk;
 
-		current->exit_signal = SIGCHLD;
+		tsk->exit_signal = SIGCHLD;
 
 		BUG_ON(leader->exit_state != EXIT_ZOMBIE);
 		leader->exit_state = EXIT_DEAD;
@@ -750,7 +750,7 @@ static int de_thread(struct task_struct *tsk)
 		spin_lock(&oldsighand->siglock);
 		spin_lock_nested(&newsighand->siglock, SINGLE_DEPTH_NESTING);
 
-		rcu_assign_pointer(current->sighand, newsighand);
+		rcu_assign_pointer(tsk->sighand, newsighand);
 		recalc_sigpending();
 
 		spin_unlock(&newsighand->siglock);
@@ -761,7 +761,7 @@ static int de_thread(struct task_struct *tsk)
 			kmem_cache_free(sighand_cachep, oldsighand);
 	}
 
-	BUG_ON(!thread_group_leader(current));
+	BUG_ON(!thread_group_leader(tsk));
 	return 0;
 }
 	

commit c18258c6f0848f97e85287f6271c511a092bb784
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Sep 27 01:51:06 2006 -0700

    [PATCH] pid: Implement transfer_pid and use it to simplify de_thread
    
    In de_thread we move pids from one process to another, a rather ugly case.
    The function transfer_pid makes it clear what we are doing, and makes the
    action atomic.  This is useful we ever want to atomically traverse the
    process group and session lists, in a rcu safe manner.
    
    Even if the atomic properties this change should be a win as transfer_pid
    should be less code to execute than executing both attach_pid and
    detach_pid, and this should make de_thread slightly smaller as only a
    single function call needs to be emitted.  The only downside is that the
    code might be slower to execute as the odds are against transfer_pid being
    in cache.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 54135df2a966..b7aa3d6422d6 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -696,23 +696,20 @@ static int de_thread(struct task_struct *tsk)
 		 */
 
 		/* Become a process group leader with the old leader's pid.
-		 * Note: The old leader also uses thispid until release_task
+		 * The old leader becomes a thread of the this thread group.
+		 * Note: The old leader also uses this pid until release_task
 		 *       is called.  Odd but simple and correct.
 		 */
 		detach_pid(current, PIDTYPE_PID);
 		current->pid = leader->pid;
 		attach_pid(current, PIDTYPE_PID,  current->pid);
-		attach_pid(current, PIDTYPE_PGID, current->signal->pgrp);
-		attach_pid(current, PIDTYPE_SID,  current->signal->session);
+		transfer_pid(leader, current, PIDTYPE_PGID);
+		transfer_pid(leader, current, PIDTYPE_SID);
 		list_replace_rcu(&leader->tasks, &current->tasks);
 
 		current->group_leader = current;
 		leader->group_leader = current;
 
-		/* Reduce leader to a thread */
-		detach_pid(leader, PIDTYPE_PGID);
-		detach_pid(leader, PIDTYPE_SID);
-
 		current->exit_signal = SIGCHLD;
 
 		BUG_ON(leader->exit_state != EXIT_ZOMBIE);

commit 513627d7fec6fcb7b3d56ce355cb4d192c76b530
Author: Dave Jones <davej@redhat.com>
Date:   Sun Aug 27 01:23:57 2006 -0700

    [PATCH] fix up lockdep trace in fs/exec.c
    
    This fixes the locking error noticed by lockdep:
    
      =============================================
      [ INFO: possible recursive locking detected ]
      ---------------------------------------------
      init/1 is trying to acquire lock:
       (&sighand->siglock){....}, at: [<c047a78a>] flush_old_exec+0x3ae/0x859
    
      but task is already holding lock:
       (&sighand->siglock){....}, at: [<c047a77a>] flush_old_exec+0x39e/0x859
    
      other info that might help us debug this:
      2 locks held by init/1:
       #0:  (tasklist_lock){..--}, at: [<c047a76a>] flush_old_exec+0x38e/0x859
       #1:  (&sighand->siglock){....}, at: [<c047a77a>] flush_old_exec+0x39e/0x859
    
      stack backtrace:
       [<c04051e1>] show_trace_log_lvl+0x54/0xfd
       [<c040579d>] show_trace+0xd/0x10
       [<c04058b6>] dump_stack+0x19/0x1b
       [<c043b33a>] __lock_acquire+0x773/0x997
       [<c043bacf>] lock_acquire+0x4b/0x6c
       [<c060630b>] _spin_lock+0x19/0x28
       [<c047a78a>] flush_old_exec+0x3ae/0x859
       [<c0498053>] load_elf_binary+0x4aa/0x1628
       [<c0479cab>] search_binary_handler+0xa7/0x24e
       [<c047b577>] do_execve+0x15b/0x1f9
       [<c04022b4>] sys_execve+0x29/0x4d
       [<c0403faf>] syscall_call+0x7/0xb
    
    Signed-off-by: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Dave Jones <davej@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index f7aabfeca033..54135df2a966 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -751,7 +751,7 @@ static int de_thread(struct task_struct *tsk)
 
 		write_lock_irq(&tasklist_lock);
 		spin_lock(&oldsighand->siglock);
-		spin_lock(&newsighand->siglock);
+		spin_lock_nested(&newsighand->siglock, SINGLE_DEPTH_NESTING);
 
 		rcu_assign_pointer(current->sighand, newsighand);
 		recalc_sigpending();

commit a969fd5a4e162c4485ae8f3e49d674656a18fa36
Author: Trond Myklebust <Trond.Myklebust@netapp.com>
Date:   Tue Aug 22 20:06:04 2006 -0400

    VFS: Remove redundant open-coded mode bit checks in open_exec().
    
    The check in open_exec() for inode->i_mode & 0111 has been made
    redundant by the fix to permission().
    
    Signed-off-by: Trond Myklebust <Trond.Myklebust@netapp.com>
    (cherry picked from 1d3741c5d991686699f100b65b9956f7ee7ae0ae commit)

diff --git a/fs/exec.c b/fs/exec.c
index a6f64a98ac50..f7aabfeca033 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -486,8 +486,6 @@ struct file *open_exec(const char *name)
 		if (!(nd.mnt->mnt_flags & MNT_NOEXEC) &&
 		    S_ISREG(inode->i_mode)) {
 			int err = vfs_permission(&nd, MAY_EXEC);
-			if (!err && !(inode->i_mode & 0111))
-				err = -EACCES;
 			file = ERR_PTR(err);
 			if (!err) {
 				file = nameidata_to_filp(&nd, O_RDONLY);

commit 9167b0b9a0ab7907191523f5a0528e3b9c288e21
Author: Trond Myklebust <Trond.Myklebust@netapp.com>
Date:   Tue Aug 22 20:06:03 2006 -0400

    VFS: Remove redundant open-coded mode bit check in prepare_binfmt().
    
    The check in prepare_binfmt() for inode->i_mode & 0111 is redundant,
    since open_exec() will already have done that.
    
    Signed-off-by: Trond Myklebust <Trond.Myklebust@netapp.com>
    (cherry picked from 822dec482ced07af32c378cd936d77345786572b commit)

diff --git a/fs/exec.c b/fs/exec.c
index 8344ba73a2a6..a6f64a98ac50 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -922,12 +922,6 @@ int prepare_binprm(struct linux_binprm *bprm)
 	int retval;
 
 	mode = inode->i_mode;
-	/*
-	 * Check execute perms again - if the caller has CAP_DAC_OVERRIDE,
-	 * generic_permission lets a non-executable through
-	 */
-	if (!(mode & 0111))	/* with at least _one_ execute bit set */
-		return -EACCES;
 	if (bprm->file->f_op == NULL)
 		return -EACCES;
 

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jrn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jrn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/fs/exec.c b/fs/exec.c
index c8494f513eaf..8344ba73a2a6 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -22,7 +22,6 @@
  * formats. 
  */
 
-#include <linux/config.h>
 #include <linux/slab.h>
 #include <linux/file.h>
 #include <linux/mman.h>

commit 5debfa6da5b06954bc79fe8deed0d1062c58dcec
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Jun 26 00:26:09 2006 -0700

    [PATCH] coredump: shutdown current process first
    
    This patch optimizes zap_threads() for the case when there are no ->mm
    users except the current's thread group.  In that case we can avoid
    'for_each_process()' loop.
    
    It also adds a useful invariant: SIGNAL_GROUP_EXIT (if checked under
    ->siglock) always implies that all threads (except may be current) have
    pending SIGKILL.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 8c8f2894949d..c8494f513eaf 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1371,13 +1371,7 @@ static void format_corename(char *corename, const char *pattern, long signr)
 static void zap_process(struct task_struct *start)
 {
 	struct task_struct *t;
-	unsigned long flags;
 
-	/*
-	 * start->sighand can't disappear, but may be
-	 * changed by de_thread()
-	 */
-	lock_task_sighand(start, &flags);
 	start->signal->flags = SIGNAL_GROUP_EXIT;
 	start->signal->group_stop_count = 0;
 
@@ -1389,40 +1383,51 @@ static void zap_process(struct task_struct *start)
 			signal_wake_up(t, 1);
 		}
 	} while ((t = next_thread(t)) != start);
-
-	unlock_task_sighand(start, &flags);
 }
 
 static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
 				int exit_code)
 {
 	struct task_struct *g, *p;
+	unsigned long flags;
 	int err = -EAGAIN;
 
 	spin_lock_irq(&tsk->sighand->siglock);
 	if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT)) {
-		tsk->signal->flags = SIGNAL_GROUP_EXIT;
 		tsk->signal->group_exit_code = exit_code;
-		tsk->signal->group_stop_count = 0;
+		zap_process(tsk);
 		err = 0;
 	}
 	spin_unlock_irq(&tsk->sighand->siglock);
 	if (err)
 		return err;
 
+	if (atomic_read(&mm->mm_users) == mm->core_waiters + 1)
+		goto done;
+
 	rcu_read_lock();
 	for_each_process(g) {
+		if (g == tsk->group_leader)
+			continue;
+
 		p = g;
 		do {
 			if (p->mm) {
-				if (p->mm == mm)
+				if (p->mm == mm) {
+					/*
+					 * p->sighand can't disappear, but
+					 * may be changed by de_thread()
+					 */
+					lock_task_sighand(p, &flags);
 					zap_process(p);
+					unlock_task_sighand(p, &flags);
+				}
 				break;
 			}
 		} while ((p = next_thread(p)) != g);
 	}
 	rcu_read_unlock();
-
+done:
 	return mm->core_waiters;
 }
 

commit dcf560c59330945a231d5e52f95dfedde4e32c9d
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Jun 26 00:26:08 2006 -0700

    [PATCH] coredump: some code relocations
    
    This is a preparation for the next patch.  No functional changes.
    Basically, this patch moves '->flags & SIGNAL_GROUP_EXIT' check into
    zap_threads(), and 'complete(vfork_done)' into coredump_wait outside of
    ->mmap_sem protected area.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 49fa0127a330..8c8f2894949d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1393,20 +1393,22 @@ static void zap_process(struct task_struct *start)
 	unlock_task_sighand(start, &flags);
 }
 
-static void zap_threads(struct mm_struct *mm)
+static inline int zap_threads(struct task_struct *tsk, struct mm_struct *mm,
+				int exit_code)
 {
 	struct task_struct *g, *p;
-	struct task_struct *tsk = current;
-	struct completion *vfork_done = tsk->vfork_done;
-
-	/*
-	 * Make sure nobody is waiting for us to release the VM,
-	 * otherwise we can deadlock when we wait on each other
-	 */
-	if (vfork_done) {
-		tsk->vfork_done = NULL;
-		complete(vfork_done);
+	int err = -EAGAIN;
+
+	spin_lock_irq(&tsk->sighand->siglock);
+	if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT)) {
+		tsk->signal->flags = SIGNAL_GROUP_EXIT;
+		tsk->signal->group_exit_code = exit_code;
+		tsk->signal->group_stop_count = 0;
+		err = 0;
 	}
+	spin_unlock_irq(&tsk->sighand->siglock);
+	if (err)
+		return err;
 
 	rcu_read_lock();
 	for_each_process(g) {
@@ -1420,22 +1422,43 @@ static void zap_threads(struct mm_struct *mm)
 		} while ((p = next_thread(p)) != g);
 	}
 	rcu_read_unlock();
+
+	return mm->core_waiters;
 }
 
-static void coredump_wait(struct mm_struct *mm)
+static int coredump_wait(int exit_code)
 {
-	DECLARE_COMPLETION(startup_done);
+	struct task_struct *tsk = current;
+	struct mm_struct *mm = tsk->mm;
+	struct completion startup_done;
+	struct completion *vfork_done;
 	int core_waiters;
 
+	init_completion(&mm->core_done);
+	init_completion(&startup_done);
 	mm->core_startup_done = &startup_done;
 
-	zap_threads(mm);
-	core_waiters = mm->core_waiters;
+	core_waiters = zap_threads(tsk, mm, exit_code);
 	up_write(&mm->mmap_sem);
 
+	if (unlikely(core_waiters < 0))
+		goto fail;
+
+	/*
+	 * Make sure nobody is waiting for us to release the VM,
+	 * otherwise we can deadlock when we wait on each other
+	 */
+	vfork_done = tsk->vfork_done;
+	if (vfork_done) {
+		tsk->vfork_done = NULL;
+		complete(vfork_done);
+	}
+
 	if (core_waiters)
 		wait_for_completion(&startup_done);
+fail:
 	BUG_ON(mm->core_waiters);
+	return core_waiters;
 }
 
 int do_coredump(long signr, int exit_code, struct pt_regs * regs)
@@ -1469,22 +1492,9 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	}
 	mm->dumpable = 0;
 
-	retval = -EAGAIN;
-	spin_lock_irq(&current->sighand->siglock);
-	if (!(current->signal->flags & SIGNAL_GROUP_EXIT)) {
-		current->signal->flags = SIGNAL_GROUP_EXIT;
-		current->signal->group_exit_code = exit_code;
-		current->signal->group_stop_count = 0;
-		retval = 0;
-	}
-	spin_unlock_irq(&current->sighand->siglock);
-	if (retval) {
-		up_write(&mm->mmap_sem);
+	retval = coredump_wait(exit_code);
+	if (retval < 0)
 		goto fail;
-	}
-
-	init_completion(&mm->core_done);
-	coredump_wait(mm);
 
 	/*
 	 * Clear any false indication of pending signals that might

commit 7b1c6154fa8bb937e0b1b4f2adbb315d70270f10
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Jun 26 00:26:08 2006 -0700

    [PATCH] coredump: don't take tasklist_lock
    
    This patch removes tasklist_lock from zap_threads().
    This is safe wrt:
    
            do_exit:
                    The caller holds mm->mmap_sem. This means that task which
                    shares the same ->mm can't pass exit_mm(), so it can't be
                    unhashed from init_task.tasks or ->thread_group lists.
    
            fork:
                    None of sub-threads can fork after zap_process(leader). All
                    processes which were created before this point should be
                    visible to zap_threads() because copy_process() adds the new
                    process to the tail of init_task.tasks list, and ->siglock
                    lock/unlock provides a memory barrier.
    
            de_thread:
                    It does list_replace_rcu(&leader->tasks, &current->tasks).
                    So zap_threads() will see either old or new leader, it does
                    not matter. However, it can change p->sighand, so we should
                    use lock_task_sighand() in zap_process().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index b58ba7d127e0..49fa0127a330 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1373,7 +1373,11 @@ static void zap_process(struct task_struct *start)
 	struct task_struct *t;
 	unsigned long flags;
 
-	spin_lock_irqsave(&start->sighand->siglock, flags);
+	/*
+	 * start->sighand can't disappear, but may be
+	 * changed by de_thread()
+	 */
+	lock_task_sighand(start, &flags);
 	start->signal->flags = SIGNAL_GROUP_EXIT;
 	start->signal->group_stop_count = 0;
 
@@ -1386,7 +1390,7 @@ static void zap_process(struct task_struct *start)
 		}
 	} while ((t = next_thread(t)) != start);
 
-	spin_unlock_irqrestore(&start->sighand->siglock, flags);
+	unlock_task_sighand(start, &flags);
 }
 
 static void zap_threads(struct mm_struct *mm)
@@ -1404,7 +1408,7 @@ static void zap_threads(struct mm_struct *mm)
 		complete(vfork_done);
 	}
 
-	read_lock(&tasklist_lock);
+	rcu_read_lock();
 	for_each_process(g) {
 		p = g;
 		do {
@@ -1415,7 +1419,7 @@ static void zap_threads(struct mm_struct *mm)
 			}
 		} while ((p = next_thread(p)) != g);
 	}
-	read_unlock(&tasklist_lock);
+	rcu_read_unlock();
 }
 
 static void coredump_wait(struct mm_struct *mm)

commit d5f70c00ad24cd1158d3678b44ff969b4c971d49
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Jun 26 00:26:07 2006 -0700

    [PATCH] coredump: kill ptrace related stuff
    
    With this patch zap_process() sets SIGNAL_GROUP_EXIT while sending SIGKILL to
    the thread group.  This means that a TASK_TRACED task
    
            1. Will be awakened by signal_wake_up(1)
    
            2. Can't sleep again via ptrace_notify()
    
            3. Can't go to do_signal_stop() after return
               from ptrace_stop() in get_signal_to_deliver()
    
    So we can remove all ptrace related stuff from coredump path.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index a5c51646d1ad..b58ba7d127e0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1368,12 +1368,14 @@ static void format_corename(char *corename, const char *pattern, long signr)
 	*out_ptr = 0;
 }
 
-static void zap_process(struct task_struct *start, int *ptraced)
+static void zap_process(struct task_struct *start)
 {
 	struct task_struct *t;
 	unsigned long flags;
 
 	spin_lock_irqsave(&start->sighand->siglock, flags);
+	start->signal->flags = SIGNAL_GROUP_EXIT;
+	start->signal->group_stop_count = 0;
 
 	t = start;
 	do {
@@ -1381,22 +1383,17 @@ static void zap_process(struct task_struct *start, int *ptraced)
 			t->mm->core_waiters++;
 			sigaddset(&t->pending.signal, SIGKILL);
 			signal_wake_up(t, 1);
-
-			if (unlikely(t->ptrace) &&
-			    unlikely(t->parent->mm == t->mm))
-				*ptraced = 1;
 		}
 	} while ((t = next_thread(t)) != start);
 
 	spin_unlock_irqrestore(&start->sighand->siglock, flags);
 }
 
-static void zap_threads (struct mm_struct *mm)
+static void zap_threads(struct mm_struct *mm)
 {
 	struct task_struct *g, *p;
 	struct task_struct *tsk = current;
 	struct completion *vfork_done = tsk->vfork_done;
-	int traced = 0;
 
 	/*
 	 * Make sure nobody is waiting for us to release the VM,
@@ -1413,29 +1410,12 @@ static void zap_threads (struct mm_struct *mm)
 		do {
 			if (p->mm) {
 				if (p->mm == mm)
-					zap_process(p, &traced);
+					zap_process(p);
 				break;
 			}
 		} while ((p = next_thread(p)) != g);
 	}
 	read_unlock(&tasklist_lock);
-
-	if (unlikely(traced)) {
-		/*
-		 * We are zapping a thread and the thread it ptraces.
-		 * If the tracee went into a ptrace stop for exit tracing,
-		 * we could deadlock since the tracer is waiting for this
-		 * coredump to finish.  Detach them so they can both die.
-		 */
-		write_lock_irq(&tasklist_lock);
-		do_each_thread(g,p) {
-			if (mm == p->mm && p != tsk &&
-			    p->ptrace && p->parent->mm == mm) {
-				__ptrace_detach(p, 0);
-			}
-		} while_each_thread(g,p);
-		write_unlock_irq(&tasklist_lock);
-	}
 }
 
 static void coredump_wait(struct mm_struct *mm)

commit 281de339ceb822ca6c04d4373ecb9a45c1890ce4
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Jun 26 00:26:06 2006 -0700

    [PATCH] coredump: speedup SIGKILL sending
    
    With this patch a thread group is killed atomically under ->siglock.  This is
    faster because we can use sigaddset() instead of force_sig_info() and this is
    used in further patches.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 80fe7bcfa094..a5c51646d1ad 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1371,17 +1371,24 @@ static void format_corename(char *corename, const char *pattern, long signr)
 static void zap_process(struct task_struct *start, int *ptraced)
 {
 	struct task_struct *t;
+	unsigned long flags;
+
+	spin_lock_irqsave(&start->sighand->siglock, flags);
 
 	t = start;
 	do {
 		if (t != current && t->mm) {
 			t->mm->core_waiters++;
-			force_sig_specific(SIGKILL, t);
+			sigaddset(&t->pending.signal, SIGKILL);
+			signal_wake_up(t, 1);
+
 			if (unlikely(t->ptrace) &&
 			    unlikely(t->parent->mm == t->mm))
 				*ptraced = 1;
 		}
 	} while ((t = next_thread(t)) != start);
+
+	spin_unlock_irqrestore(&start->sighand->siglock, flags);
 }
 
 static void zap_threads (struct mm_struct *mm)

commit aceecc041217b35df753d1ed6e25bd17c0c558d8
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Jun 26 00:26:05 2006 -0700

    [PATCH] coredump: optimize ->mm users traversal
    
    zap_threads() iterates over all threads to find those ones which share
    current->mm.  All threads in the thread group share the same ->mm, so we can
    skip entire thread group if it has another ->mm.
    
    This patch shifts the killing of thread group into the newly added
    zap_process() function.  This looks as unnecessary complication, but it is
    used in further patches.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index fffea1eef8dc..80fe7bcfa094 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1368,6 +1368,22 @@ static void format_corename(char *corename, const char *pattern, long signr)
 	*out_ptr = 0;
 }
 
+static void zap_process(struct task_struct *start, int *ptraced)
+{
+	struct task_struct *t;
+
+	t = start;
+	do {
+		if (t != current && t->mm) {
+			t->mm->core_waiters++;
+			force_sig_specific(SIGKILL, t);
+			if (unlikely(t->ptrace) &&
+			    unlikely(t->parent->mm == t->mm))
+				*ptraced = 1;
+		}
+	} while ((t = next_thread(t)) != start);
+}
+
 static void zap_threads (struct mm_struct *mm)
 {
 	struct task_struct *g, *p;
@@ -1385,16 +1401,16 @@ static void zap_threads (struct mm_struct *mm)
 	}
 
 	read_lock(&tasklist_lock);
-	do_each_thread(g,p)
-		if (mm == p->mm && p != tsk) {
-			force_sig_specific(SIGKILL, p);
-			mm->core_waiters++;
-			if (unlikely(p->ptrace) &&
-			    unlikely(p->parent->mm == mm))
-				traced = 1;
-		}
-	while_each_thread(g,p);
-
+	for_each_process(g) {
+		p = g;
+		do {
+			if (p->mm) {
+				if (p->mm == mm)
+					zap_process(p, &traced);
+				break;
+			}
+		} while ((p = next_thread(p)) != g);
+	}
 	read_unlock(&tasklist_lock);
 
 	if (unlikely(traced)) {

commit 2ceb8693ef63ae3d154ce1a05d275f2bb20a5e4c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Jun 26 00:26:04 2006 -0700

    [PATCH] de_thread: fix lockless do_each_thread
    
    We should keep the value of old_leader->tasks.next in de_thread, otherwise
    we can't do for_each_process/do_each_thread without tasklist_lock held.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 8c5196087f31..fffea1eef8dc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -707,7 +707,7 @@ static int de_thread(struct task_struct *tsk)
 		attach_pid(current, PIDTYPE_PID,  current->pid);
 		attach_pid(current, PIDTYPE_PGID, current->signal->pgrp);
 		attach_pid(current, PIDTYPE_SID,  current->signal->session);
-		list_add_tail_rcu(&current->tasks, &init_task.tasks);
+		list_replace_rcu(&leader->tasks, &current->tasks);
 
 		current->group_leader = current;
 		leader->group_leader = current;
@@ -715,7 +715,6 @@ static int de_thread(struct task_struct *tsk)
 		/* Reduce leader to a thread */
 		detach_pid(leader, PIDTYPE_PGID);
 		detach_pid(leader, PIDTYPE_SID);
-		list_del_init(&leader->tasks);
 
 		current->exit_signal = SIGCHLD;
 

commit 48e6484d49020dba3578ad117b461e8a391e8f0f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jun 26 00:25:48 2006 -0700

    [PATCH] proc: Rewrite the proc dentry flush on exit optimization
    
    To keep the dcache from filling up with dead /proc entries we flush them on
    process exit.  However over the years that code has gotten hairy with a
    dentry_pointer and a lock in task_struct and misdocumented as a correctness
    feature.
    
    I have rewritten this code to look and see if we have a corresponding entry in
    the dcache and if so flush it on process exit.  This removes the extra fields
    in the task_struct and allows me to trivially handle the case of a
    /proc/<tgid>/task/<pid> entry as well as the current /proc/<pid> entries.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0b88bf646143..8c5196087f31 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -666,8 +666,6 @@ static int de_thread(struct task_struct *tsk)
 	 * and to assume its PID:
 	 */
 	if (!thread_group_leader(current)) {
-		struct dentry *proc_dentry1, *proc_dentry2;
-
 		/*
 		 * Wait for the thread group leader to be a zombie.
 		 * It should already be zombie at this point, most
@@ -689,10 +687,6 @@ static int de_thread(struct task_struct *tsk)
 		 */
 		current->start_time = leader->start_time;
 
-		spin_lock(&leader->proc_lock);
-		spin_lock(&current->proc_lock);
-		proc_dentry1 = proc_pid_unhash(current);
-		proc_dentry2 = proc_pid_unhash(leader);
 		write_lock_irq(&tasklist_lock);
 
 		BUG_ON(leader->tgid != current->tgid);
@@ -729,10 +723,6 @@ static int de_thread(struct task_struct *tsk)
 		leader->exit_state = EXIT_DEAD;
 
 		write_unlock_irq(&tasklist_lock);
-		spin_unlock(&leader->proc_lock);
-		spin_unlock(&current->proc_lock);
-		proc_pid_flush(proc_dentry1);
-		proc_pid_flush(proc_dentry2);
         }
 
 	/*

commit c89681ed7d0e4a61d35bdc12c06c6733b718b2cb
Author: Miklos Szeredi <miklos@szeredi.hu>
Date:   Thu Jun 22 14:47:22 2006 -0700

    [PATCH] remove steal_locks()
    
    This patch removes the steal_locks() function.
    
    steal_locks() doesn't work correctly with any filesystem that does it's own
    lock management, including NFS, CIFS, etc.
    
    In addition it has weird semantics on local filesystems in case tasks
    sharing file-descriptor tables are doing POSIX locking operations in
    parallel to execve().
    
    The steal_locks() function has an effect on applications doing:
    
    clone(CLONE_FILES)
      /* in child */
      lock
      execve
      lock
    
    POSIX locks acquired before execve (by "child", "parent" or any further
    task sharing files_struct) will after the execve be owned exclusively by
    "child".
    
    According to Chris Wright some LSB/LTP kind of suite triggers without the
    stealing behavior, but there's no known real-world application that would
    also fail.
    
    Apps using NPTL are not affected, since all other threads are killed before
    execve.
    
    Apps using LinuxThreads are only affected if they
    
      - have multiple threads during exec (LinuxThreads doesn't kill other
        threads, the app may do it with pthread_kill_other_threads_np())
      - rely on POSIX locks being inherited across exec
    
    Both conditions are documented, but not their interaction.
    
    Apps using clone() natively are affected if they
    
      - use clone(CLONE_FILES)
      - rely on POSIX locks being inherited across exec
    
    The above scenarios are unlikely, but possible.
    
    If the patch is vetoed, there's a plan B, that involves mostly keeping the
    weird stealing semantics, but changing the way lock ownership is handled so
    that network and local filesystems work consistently.
    
    That would add more complexity though, so this solution seems to be
    preferred by most people.
    
    Signed-off-by: Miklos Szeredi <miklos@szeredi.hu>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Cc: Matthew Wilcox <willy@debian.org>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Steven French <sfrench@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index d07858c0b7c4..0b88bf646143 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -866,7 +866,6 @@ int flush_old_exec(struct linux_binprm * bprm)
 	bprm->mm = NULL;		/* We're using it now */
 
 	/* This is the point of no return */
-	steal_locks(files);
 	put_files_struct(files);
 
 	current->sas_ss_sp = current->sas_ss_size = 0;

commit 473ae30bc7b1dda5c5791c773f95e9424ddfead9
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Apr 26 14:04:08 2006 -0400

    [PATCH] execve argument logging
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/exec.c b/fs/exec.c
index 3a79d97ac234..d07858c0b7c4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -49,6 +49,7 @@
 #include <linux/rmap.h>
 #include <linux/acct.h>
 #include <linux/cn_proc.h>
+#include <linux/audit.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -1085,6 +1086,11 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 	/* kernel module loader fixup */
 	/* so we don't try to load run modprobe in kernel space. */
 	set_fs(USER_DS);
+
+	retval = audit_bprm(bprm);
+	if (retval)
+		return retval;
+
 	retval = -ENOENT;
 	for (try=0; try<2; try++) {
 		read_lock(&binfmt_lock);

commit 5e85d4abe3f43bb5362f384bab0e20ef082ce0b5
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Apr 18 22:20:16 2006 -0700

    [PATCH] task: Make task list manipulations RCU safe
    
    While we can currently walk through thread groups, process groups, and
    sessions with just the rcu_read_lock, this opens the door to walking the
    entire task list.
    
    We already have all of the other RCU guarantees so there is no cost in
    doing this, this should be enough so that proc can stop taking the
    tasklist lock during readdir.
    
    prev_task was killed because it has no users, and using it will miss new
    tasks when doing an rcu traversal.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4121bb559739..3a79d97ac234 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -712,7 +712,7 @@ static int de_thread(struct task_struct *tsk)
 		attach_pid(current, PIDTYPE_PID,  current->pid);
 		attach_pid(current, PIDTYPE_PGID, current->signal->pgrp);
 		attach_pid(current, PIDTYPE_SID,  current->signal->session);
-		list_add_tail(&current->tasks, &init_task.tasks);
+		list_add_tail_rcu(&current->tasks, &init_task.tasks);
 
 		current->group_leader = current;
 		leader->group_leader = current;

commit c06511d12d720b23c8dffff23004f0a888698f20
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Apr 14 04:05:55 2006 -0600

    [PATCH] de_thread: Don't change our parents and ptrace flags.
    
    This is two distinct changes.
     - Not changing our real parents.
     - Not changing our ptrace parents.
    
    Not changing our real parents is trivially correct because both tasks
    have the same real parents as they are part of a thread group.  Now that
    we demote the leader to a thread there is no longer any reason to change
    it's parentage.
    
    Not changing our ptrace parents is a user visible change if someone
    looks hard enough.  I don't think user space applications will care or
    even notice.
    
    In the practical and I think common case a debugger will have attached
    to all of the threads using the same ptrace flags.  From my quick skim
    of strace and gdb that appears to be the case.  Which if true means
    debuggers will not notice a change.
    
    Before this point we have already generated a ptrace event in do_exit
    that reports the leaders pid has died so de_thread is visible to a
    debugger.  Which means attempting to hide this case by copying flags
    around appears excessive.
    
    By not doing anything it avoids all of the weird locking issues between
    de_thread and ptrace attach, and removes one case from consideration for
    fixing the ptrace locking.
    
    This only addresses Oleg's first concern with ptrace_attach, that of the
    problems caused by reparenting.  Oleg's second concern is essentially a
    race between ptrace_attach and release_task that causes an oops when we
    get to force_sig_specific.  There is nothing special about de_thread
    with respect to that race.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 3234a0c32d54..4121bb559739 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -665,9 +665,7 @@ static int de_thread(struct task_struct *tsk)
 	 * and to assume its PID:
 	 */
 	if (!thread_group_leader(current)) {
-		struct task_struct *parent;
 		struct dentry *proc_dentry1, *proc_dentry2;
-		unsigned long ptrace;
 
 		/*
 		 * Wait for the thread group leader to be a zombie.
@@ -704,22 +702,6 @@ static int de_thread(struct task_struct *tsk)
 		 * two threads with a switched PID, and release
 		 * the former thread group leader:
 		 */
-		ptrace = leader->ptrace;
-		parent = leader->parent;
-		if (unlikely(ptrace) && unlikely(parent == current)) {
-			/*
-			 * Joker was ptracing his own group leader,
-			 * and now he wants to be his own parent!
-			 * We can't have that.
-			 */
-			ptrace = 0;
-		}
-
-		ptrace_unlink(current);
-		ptrace_unlink(leader);
-		remove_parent(current);
-		remove_parent(leader);
-
 
 		/* Become a process group leader with the old leader's pid.
 		 * Note: The old leader also uses thispid until release_task
@@ -732,8 +714,6 @@ static int de_thread(struct task_struct *tsk)
 		attach_pid(current, PIDTYPE_SID,  current->signal->session);
 		list_add_tail(&current->tasks, &init_task.tasks);
 
-		current->parent = current->real_parent = leader->real_parent;
-		leader->parent = leader->real_parent = child_reaper;
 		current->group_leader = current;
 		leader->group_leader = current;
 
@@ -742,13 +722,6 @@ static int de_thread(struct task_struct *tsk)
 		detach_pid(leader, PIDTYPE_SID);
 		list_del_init(&leader->tasks);
 
-		add_parent(current);
-		add_parent(leader);
-		if (ptrace) {
-			current->ptrace = ptrace;
-			__ptrace_link(current, parent);
-		}
-
 		current->exit_signal = SIGCHLD;
 
 		BUG_ON(leader->exit_state != EXIT_ZOMBIE);

commit f5e902817fee1589badca1284f49eecc0ef0c200
Author: Roland McGrath <roland@redhat.com>
Date:   Mon Apr 10 22:54:16 2006 -0700

    [PATCH] process accounting: take original leader's start_time in non-leader exec
    
    The only record we have of the real-time age of a process, regardless of
    execs it's done, is start_time.  When a non-leader thread exec, the
    original start_time of the process is lost.  Things looking at the
    real-time age of the process are fooled, for example the process accounting
    record when the process finally dies.  This change makes the oldest
    start_time stick around with the process after a non-leader exec.  This way
    the association between PID and start_time is kept constant, which seems
    correct to me.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 4d38ad0b70d6..3234a0c32d54 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -678,6 +678,18 @@ static int de_thread(struct task_struct *tsk)
 		while (leader->exit_state != EXIT_ZOMBIE)
 			yield();
 
+		/*
+		 * The only record we have of the real-time age of a
+		 * process, regardless of execs it's done, is start_time.
+		 * All the past CPU time is accumulated in signal_struct
+		 * from sister threads now dead.  But in this non-leader
+		 * exec, nothing survives from the original leader thread,
+		 * whose birth marks the true age of this process now.
+		 * When we take on its identity by switching to its PID, we
+		 * also take its birthdate (always earlier than our own).
+		 */
+		current->start_time = leader->start_time;
+
 		spin_lock(&leader->proc_lock);
 		spin_lock(&current->proc_lock);
 		proc_dentry1 = proc_pid_unhash(current);

commit de12a7878c11f3b282d640888aa635e0711d0b5e
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Apr 10 17:16:49 2006 -0600

    [PATCH] de_thread: Don't confuse users do_each_thread.
    
    Oleg Nesterov spotted two interesting bugs with the current de_thread
    code.  The simplest is a long standing double decrement of
    __get_cpu_var(process_counts) in __unhash_process.  Caused by
    two processes exiting when only one was created.
    
    The other is that since we no longer detach from the thread_group list
    it is possible for do_each_thread when run under the tasklist_lock to
    see the same task_struct twice.  Once on the task list as a
    thread_group_leader, and once on the thread list of another
    thread.
    
    The double appearance in do_each_thread can cause a double increment
    of mm_core_waiters in zap_threads resulting in problems later on in
    coredump_wait.
    
    To remedy those two problems this patch takes the simple approach
    of changing the old thread group leader into a child thread.
    The only routine in release_task that cares is __unhash_process,
    and it can be trivially seen that we handle cleaning up a
    thread group leader properly.
    
    Since de_thread doesn't change the pid of the exiting leader process
    and instead shares it with the new leader process.  I change
    thread_group_leader to recognize group leadership based on the
    group_leader field and not based on pids.  This should also be
    slightly cheaper then the existing thread_group_leader macro.
    
    I performed a quick audit and I couldn't see any user of
    thread_group_leader that cared about the difference.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0291a68a3626..4d38ad0b70d6 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -723,7 +723,12 @@ static int de_thread(struct task_struct *tsk)
 		current->parent = current->real_parent = leader->real_parent;
 		leader->parent = leader->real_parent = child_reaper;
 		current->group_leader = current;
-		leader->group_leader = leader;
+		leader->group_leader = current;
+
+		/* Reduce leader to a thread */
+		detach_pid(leader, PIDTYPE_PGID);
+		detach_pid(leader, PIDTYPE_SID);
+		list_del_init(&leader->tasks);
 
 		add_parent(current);
 		add_parent(leader);

commit 7dddb12c63553db850365cfd066a00416aa8c6cb
Author: Eric Sesterhenn <snakebyte@gmx.de>
Date:   Sat Apr 1 01:13:38 2006 +0200

    BUG_ON() Conversion in fs/exec.c
    
    this changes if() BUG(); constructs to BUG_ON() which is
    cleaner and can better optimized away
    
    Signed-off-by: Eric Sesterhenn <snakebyte@gmx.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/fs/exec.c b/fs/exec.c
index 950ebd43cdc3..0291a68a3626 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -561,7 +561,7 @@ static int exec_mmap(struct mm_struct *mm)
 	arch_pick_mmap_layout(mm);
 	if (old_mm) {
 		up_read(&old_mm->mmap_sem);
-		if (active_mm != old_mm) BUG();
+		BUG_ON(active_mm != old_mm);
 		mmput(old_mm);
 		return 0;
 	}

commit aa1757f90bea3f598b6e5d04d922a6a60200f1da
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:12 2006 -0800

    [PATCH] convert sighand_cache to use SLAB_DESTROY_BY_RCU
    
    This patch borrows a clever Hugh's 'struct anon_vma' trick.
    
    Without tasklist_lock held we can't trust task->sighand until we locked it
    and re-checked that it is still the same.
    
    But this means we don't need to defer 'kmem_cache_free(sighand)'.  We can
    return the memory to slab immediately, all we need is to be sure that
    sighand->siglock can't dissapear inside rcu protected section.
    
    To do so we need to initialize ->siglock inside ctor function,
    SLAB_DESTROY_BY_RCU does the rest.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9046ad2b0614..950ebd43cdc3 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -768,7 +768,6 @@ static int de_thread(struct task_struct *tsk)
 		/*
 		 * Move our state over to newsighand and switch it in.
 		 */
-		spin_lock_init(&newsighand->siglock);
 		atomic_set(&newsighand->count, 1);
 		memcpy(newsighand->action, oldsighand->action,
 		       sizeof(newsighand->action));
@@ -785,7 +784,7 @@ static int de_thread(struct task_struct *tsk)
 		write_unlock_irq(&tasklist_lock);
 
 		if (atomic_dec_and_test(&oldsighand->count))
-			sighand_free(oldsighand);
+			kmem_cache_free(sighand_cachep, oldsighand);
 	}
 
 	BUG_ON(!thread_group_leader(current));

commit 8fafabd86f1b75ed3cc6a6ffbe6c3e53e3d8457d
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:05 2006 -0800

    [PATCH] remove add_parent()'s parent argument
    
    add_parent(p, parent) is always called with parent == p->parent, and it makes
    no sense to do it differently.  This patch removes this argument.
    
    No changes in affected .o files.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index db0769447d33..9046ad2b0614 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -725,8 +725,8 @@ static int de_thread(struct task_struct *tsk)
 		current->group_leader = current;
 		leader->group_leader = leader;
 
-		add_parent(current, current->parent);
-		add_parent(leader, leader->parent);
+		add_parent(current);
+		add_parent(leader);
 		if (ptrace) {
 			current->ptrace = ptrace;
 			__ptrace_link(current, parent);

commit d73d65293e3e2de7e916a89c8da30be0948afab7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Mar 28 16:11:03 2006 -0800

    [PATCH] pidhash: kill switch_exec_pids
    
    switch_exec_pids is only called from de_thread by way of exec, and it is
    only called when we are exec'ing from a non thread group leader.
    
    Currently switch_exec_pids gives the leader the pid of the thread and
    unhashes and rehashes all of the process groups.  The leader is already in
    the EXIT_DEAD state so no one cares about it's pids.  The only concern for
    the leader is that __unhash_process called from release_task will function
    correctly.  If we don't touch the leader at all we know that
    __unhash_process will work fine so there is no need to touch the leader.
    
    For the task becomming the thread group leader, we just need to give it the
    pid of the old thread group leader, add it to the task list, and attach it
    to the session and the process group of the thread group.
    
    Currently de_thread is also adding the task to the task list which is just
    silly.
    
    Currently the only leader of __detach_pid besides detach_pid is
    switch_exec_pids because of the ugly extra work that was being
    performed.
    
    So this patch removes switch_exec_pids because it is doing too much, it is
    creating an unnecessary special case in pid.c, duing work duplicated in
    de_thread, and generally obscuring what it is going on.
    
    The necessary work is added to de_thread, and it seems to be a little
    clearer there what is going on.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index dd194923c52c..db0769447d33 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -708,7 +708,17 @@ static int de_thread(struct task_struct *tsk)
 		remove_parent(current);
 		remove_parent(leader);
 
-		switch_exec_pids(leader, current);
+
+		/* Become a process group leader with the old leader's pid.
+		 * Note: The old leader also uses thispid until release_task
+		 *       is called.  Odd but simple and correct.
+		 */
+		detach_pid(current, PIDTYPE_PID);
+		current->pid = leader->pid;
+		attach_pid(current, PIDTYPE_PID,  current->pid);
+		attach_pid(current, PIDTYPE_PGID, current->signal->pgrp);
+		attach_pid(current, PIDTYPE_SID,  current->signal->session);
+		list_add_tail(&current->tasks, &init_task.tasks);
 
 		current->parent = current->real_parent = leader->real_parent;
 		leader->parent = leader->real_parent = child_reaper;
@@ -722,8 +732,6 @@ static int de_thread(struct task_struct *tsk)
 			__ptrace_link(current, parent);
 		}
 
-		list_del(&current->tasks);
-		list_add_tail(&current->tasks, &init_task.tasks);
 		current->exit_signal = SIGCHLD;
 
 		BUG_ON(leader->exit_state != EXIT_ZOMBIE);

commit 1434261c07bcebd5ef8b8a18f919fdee533b84e0
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:10:59 2006 -0800

    [PATCH] simplify exec from init's subthread
    
    I think it is enough to take tasklist_lock for reading while changing
    child_reaper:
    
            Reparenting needs write_lock(tasklist_lock)
    
            Only one thread in a thread group can do exec()
    
            sighand->siglock garantees that get_signal_to_deliver()
            will not see a stale value of child_reaper.
    
    This means that we can change child_reaper earlier, without calling
    zap_other_threads() twice.
    
    "child_reaper = current" is a NOOP when init does exec from main thread, we
    don't care.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index d0ecea0781f7..dd194923c52c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -616,6 +616,15 @@ static int de_thread(struct task_struct *tsk)
 		kmem_cache_free(sighand_cachep, newsighand);
 		return -EAGAIN;
 	}
+
+	/*
+	 * child_reaper ignores SIGKILL, change it now.
+	 * Reparenting needs write_lock on tasklist_lock,
+	 * so it is safe to do it under read_lock.
+	 */
+	if (unlikely(current->group_leader == child_reaper))
+		child_reaper = current;
+
 	zap_other_threads(current);
 	read_unlock(&tasklist_lock);
 
@@ -660,23 +669,12 @@ static int de_thread(struct task_struct *tsk)
 		struct dentry *proc_dentry1, *proc_dentry2;
 		unsigned long ptrace;
 
-		leader = current->group_leader;
-		/*
-		 * If our leader is the child_reaper become
-		 * the child_reaper and resend SIGKILL signal.
-		 */
-		if (unlikely(leader == child_reaper)) {
-			write_lock(&tasklist_lock);
-			child_reaper = current;
-			zap_other_threads(current);
-			write_unlock(&tasklist_lock);
-		}
-
 		/*
 		 * Wait for the thread group leader to be a zombie.
 		 * It should already be zombie at this point, most
 		 * of the time.
 		 */
+		leader = current->group_leader;
 		while (leader->exit_state != EXIT_ZOMBIE)
 			yield();
 

commit fef23e7fbb11a0a78cd61935f7056bc2b237995a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Mar 28 16:10:58 2006 -0800

    [PATCH] exec: allow init to exec from any thread.
    
    After looking at the problem of init calling exec some more I figured out
    an easy way to make the code work.
    
    The actual symptom without out this patch is that all threads will die
    except pid == 1, and the thread calling exec.  The thread calling exec will
    wait forever for pid == 1 to die.
    
    Since pid == 1 does not install a handler for SIGKILL it will never die.
    
    This modifies the tests for init from current->pid == 1 to the equivalent
    current == child_reaper.  And then it causes exec in the ugly case to
    modify child_reaper.
    
    The only weird symptom is that you wind up with an init process that
    doesn't have the oldest start time on the box.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index c7397c46ad6d..d0ecea0781f7 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -660,12 +660,23 @@ static int de_thread(struct task_struct *tsk)
 		struct dentry *proc_dentry1, *proc_dentry2;
 		unsigned long ptrace;
 
+		leader = current->group_leader;
+		/*
+		 * If our leader is the child_reaper become
+		 * the child_reaper and resend SIGKILL signal.
+		 */
+		if (unlikely(leader == child_reaper)) {
+			write_lock(&tasklist_lock);
+			child_reaper = current;
+			zap_other_threads(current);
+			write_unlock(&tasklist_lock);
+		}
+
 		/*
 		 * Wait for the thread group leader to be a zombie.
 		 * It should already be zombie at this point, most
 		 * of the time.
 		 */
-		leader = current->group_leader;
 		while (leader->exit_state != EXIT_ZOMBIE)
 			yield();
 

commit 05cfb614ddbf3181540ce09d44d96486f8ba8d6a
Author: Roman Zippel <zippel@linux-m68k.org>
Date:   Sun Mar 26 01:38:12 2006 -0800

    [PATCH] hrtimers: remove data field
    
    The nanosleep cleanup allows to remove the data field of hrtimer.  The
    callback function can use container_of() to get it's own data.  Since the
    hrtimer structure is anyway embedded in other structures, this adds no
    overhead.
    
    Signed-off-by: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 995cba3c62b8..c7397c46ad6d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -632,7 +632,7 @@ static int de_thread(struct task_struct *tsk)
 		 * synchronize with any firing (by calling del_timer_sync)
 		 * before we can safely let the old group leader die.
 		 */
-		sig->real_timer.data = current;
+		sig->tsk = current;
 		spin_unlock_irq(lock);
 		if (hrtimer_cancel(&sig->real_timer))
 			hrtimer_restart(&sig->real_timer);

commit 11b0b5abb2097a63c1081d9b7e825b987b227972
Author: Oliver Neukum <neukum@fachschaft.cup.uni-muenchen.de>
Date:   Sat Mar 25 03:08:13 2006 -0800

    [PATCH] use kzalloc and kcalloc in core fs code
    
    Signed-off-by: Oliver Neukum <oliver@neukum.name>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index d8c477a56257..995cba3c62b8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1143,10 +1143,9 @@ int do_execve(char * filename,
 	int i;
 
 	retval = -ENOMEM;
-	bprm = kmalloc(sizeof(*bprm), GFP_KERNEL);
+	bprm = kzalloc(sizeof(*bprm), GFP_KERNEL);
 	if (!bprm)
 		goto out_ret;
-	memset(bprm, 0, sizeof(*bprm));
 
 	file = open_exec(filename);
 	retval = PTR_ERR(file);

commit b500531e6f5f234ed267bd7060ee06d144faf0ca
Author: Oleg Drokin <green@linuxhacker.ru>
Date:   Sat Mar 25 03:07:01 2006 -0800

    [PATCH] Introduce FMODE_EXEC file flag
    
    Introduce FMODE_EXEC file flag, to indicate that file is being opened for
    execution.  This is useful for distributed filesystems to maintain
    consistent behavior for returning ETXTBUSY when opening for write and
    execution happens on different nodes.
    
    akpm:
    
      Needed by Lustre at present.  I assume their objective to to work towards
      being able to install Lustre on an unmodified distro kernel, which seems
      sane.  It should have zero runtime cost.
    
      Trond and Chuck indicate that NFS4 can probably use this too, for the same
      thing.
    
      Steven says it's also on the GFS todo list.
    
    Signed-off-by: Oleg Drokin <green@linuxhacker.ru>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Cc: Chuck Lever <cel@citi.umich.edu>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0b515ac53134..d8c477a56257 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -127,7 +127,7 @@ asmlinkage long sys_uselib(const char __user * library)
 	struct nameidata nd;
 	int error;
 
-	error = __user_path_lookup_open(library, LOOKUP_FOLLOW, &nd, FMODE_READ);
+	error = __user_path_lookup_open(library, LOOKUP_FOLLOW, &nd, FMODE_READ|FMODE_EXEC);
 	if (error)
 		goto out;
 
@@ -477,7 +477,7 @@ struct file *open_exec(const char *name)
 	int err;
 	struct file *file;
 
-	err = path_lookup_open(AT_FDCWD, name, LOOKUP_FOLLOW, &nd, FMODE_READ);
+	err = path_lookup_open(AT_FDCWD, name, LOOKUP_FOLLOW, &nd, FMODE_READ|FMODE_EXEC);
 	file = ERR_PTR(err);
 
 	if (!err) {

commit 0551fbd29e16fccd46e41b7d01bf0f8f39b14212
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Feb 28 16:59:19 2006 -0800

    [PATCH] Add mm->task_size and fix powerpc vdso
    
    This patch adds mm->task_size to keep track of the task size of a given mm
    and uses that to fix the powerpc vdso so that it uses the mm task size to
    decide what pages to fault in instead of the current thread flags (which
    broke when ptracing).
    
    (akpm: I expect that mm_struct.task_size will become the way in which we
    finally sort out the confusion between 32-bit processes and 32-bit mm's.  It
    may need tweaks, but at this stage this patch is powerpc-only.)
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 0e1c95074d42..0b515ac53134 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -885,6 +885,12 @@ int flush_old_exec(struct linux_binprm * bprm)
 	current->flags &= ~PF_RANDOMIZE;
 	flush_thread();
 
+	/* Set the new mm task size. We have to do that late because it may
+	 * depend on TIF_32BIT which is only updated in flush_thread() on
+	 * some architectures like powerpc
+	 */
+	current->mm->task_size = TASK_SIZE;
+
 	if (bprm->e_uid != current->euid || bprm->e_gid != current->egid || 
 	    file_permission(bprm->file, MAY_READ) ||
 	    (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)) {

commit 5ecfbae093f0c37311e89b29bfc0c9d586eace87
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Feb 15 22:50:10 2006 +0300

    [PATCH] fix zap_thread's ptrace related problems
    
    1. The tracee can go from ptrace_stop() to do_signal_stop()
       after __ptrace_unlink(p).
    
    2. It is unsafe to __ptrace_unlink(p) while p->parent may wait
       for tasklist_lock in ptrace_detach().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 055378d2513e..0e1c95074d42 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1403,7 +1403,7 @@ static void zap_threads (struct mm_struct *mm)
 		do_each_thread(g,p) {
 			if (mm == p->mm && p != tsk &&
 			    p->ptrace && p->parent->mm == mm) {
-				__ptrace_unlink(p);
+				__ptrace_detach(p, 0);
 			}
 		} while_each_thread(g,p);
 		write_unlock_irq(&tasklist_lock);

commit 5590ff0d5528b60153c0b4e7b771472b5a95e297
Author: Ulrich Drepper <drepper@redhat.com>
Date:   Wed Jan 18 17:43:53 2006 -0800

    [PATCH] vfs: *at functions: core
    
    Here is a series of patches which introduce in total 13 new system calls
    which take a file descriptor/filename pair instead of a single file
    name.  These functions, openat etc, have been discussed on numerous
    occasions.  They are needed to implement race-free filesystem traversal,
    they are necessary to implement a virtual per-thread current working
    directory (think multi-threaded backup software), etc.
    
    We have in glibc today implementations of the interfaces which use the
    /proc/self/fd magic.  But this code is rather expensive.  Here are some
    results (similar to what Jim Meyering posted before).
    
    The test creates a deep directory hierarchy on a tmpfs filesystem.  Then
    rm -fr is used to remove all directories.  Without syscall support I get
    this:
    
    real    0m31.921s
    user    0m0.688s
    sys     0m31.234s
    
    With syscall support the results are much better:
    
    real    0m20.699s
    user    0m0.536s
    sys     0m20.149s
    
    The interfaces are for obvious reasons currently not much used.  But they'll
    be used.  coreutils (and Jeff's posixutils) are already using them.
    Furthermore, code like ftw/fts in libc (maybe even glob) will also start using
    them.  I expect a patch to make follow soon.  Every program which is walking
    the filesystem tree will benefit.
    
    Signed-off-by: Ulrich Drepper <drepper@redhat.com>
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@ftp.linux.org.uk>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: Michael Kerrisk <mtk-manpages@gmx.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 62b40af68cc4..055378d2513e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -477,7 +477,7 @@ struct file *open_exec(const char *name)
 	int err;
 	struct file *file;
 
-	err = path_lookup_open(name, LOOKUP_FOLLOW, &nd, FMODE_READ);
+	err = path_lookup_open(AT_FDCWD, name, LOOKUP_FOLLOW, &nd, FMODE_READ);
 	file = ERR_PTR(err);
 
 	if (!err) {

commit 858119e159384308a5dde67776691a2ebf70df0f
Author: Arjan van de Ven <arjan@infradead.org>
Date:   Sat Jan 14 13:20:43 2006 -0800

    [PATCH] Unlinline a bunch of other functions
    
    Remove the "inline" keyword from a bunch of big functions in the kernel with
    the goal of shrinking it by 30kb to 40kb
    
    Signed-off-by: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Jeff Garzik <jgarzik@pobox.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index b5bcf1aae0ab..62b40af68cc4 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -575,7 +575,7 @@ static int exec_mmap(struct mm_struct *mm)
  * disturbing other processes.  (Other processes might share the signal
  * table via the CLONE_SIGHAND option to clone().)
  */
-static inline int de_thread(struct task_struct *tsk)
+static int de_thread(struct task_struct *tsk)
 {
 	struct signal_struct *sig = tsk->signal;
 	struct sighand_struct *newsighand, *oldsighand = tsk->sighand;
@@ -780,7 +780,7 @@ static inline int de_thread(struct task_struct *tsk)
  * so that a new one can be started
  */
 
-static inline void flush_old_files(struct files_struct * files)
+static void flush_old_files(struct files_struct * files)
 {
 	long j = -1;
 	struct fdtable *fdt;
@@ -964,7 +964,7 @@ int prepare_binprm(struct linux_binprm *bprm)
 
 EXPORT_SYMBOL(prepare_binprm);
 
-static inline int unsafe_exec(struct task_struct *p)
+static int unsafe_exec(struct task_struct *p)
 {
 	int unsafe = 0;
 	if (p->ptrace & PT_PTRACED) {

commit 2ff678b8da6478d861c1b0ecb3ac14575760e906
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jan 9 20:52:34 2006 -0800

    [PATCH] hrtimer: switch itimers to hrtimer
    
    switch itimers to a hrtimers-based implementation
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index fd02ea4a81e9..b5bcf1aae0ab 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -632,10 +632,10 @@ static inline int de_thread(struct task_struct *tsk)
 		 * synchronize with any firing (by calling del_timer_sync)
 		 * before we can safely let the old group leader die.
 		 */
-		sig->real_timer.data = (unsigned long)current;
+		sig->real_timer.data = current;
 		spin_unlock_irq(lock);
-		if (del_timer_sync(&sig->real_timer))
-			add_timer(&sig->real_timer);
+		if (hrtimer_cancel(&sig->real_timer))
+			hrtimer_restart(&sig->real_timer);
 		spin_lock_irq(lock);
 	}
 	while (atomic_read(&sig->count) > count) {

commit bb6f6dbaa48c53525a7a4f9d4df719c3b0b582af
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Jan 8 01:03:13 2006 -0800

    [PATCH] do_coredump() should reset group_stop_count earlier
    
    __group_complete_signal() sets ->group_stop_count in sig_kernel_coredump()
    path and marks the target thread as ->group_exit_task.  So any thread
    except group_exit_task will go to handle_group_stop()->finish_stop().
    
    However, when group_exit_task actually starts do_coredump(), it sets
    SIGNAL_GROUP_EXIT, but does not reset ->group_stop_count while killing
    other threads.  If we have not yet stopped threads in the same thread
    group, they all will spin in kernel mode until group_exit_task sends them
    SIGKILL, because ->group_stop_count > 0 means:
    
            recalc_sigpending_tsk() never clears TIF_SIGPENDING
    
            get_signal_to_deliver() goes to handle_group_stop()
    
            handle_group_stop() returns when SIGNAL_GROUP_EXIT set
    
            syscall_exit/resume_userspace notice TIF_SIGPENDING,
            call get_signal_to_deliver() again.
    
    So we are wasting cpu cycles, and if one of these threads is rt_task() this
    may be a serious problem.
    
    NOTE: do_coredump() holds ->mmap_sem, so not stopped threads can't escape
    coredumping after clearing ->group_stop_count.
    
    See also this thread: http://marc.theaimsgroup.com/?t=112739139900002
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 2075b674d85e..fd02ea4a81e9 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1462,6 +1462,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	if (!(current->signal->flags & SIGNAL_GROUP_EXIT)) {
 		current->signal->flags = SIGNAL_GROUP_EXIT;
 		current->signal->group_exit_code = exit_code;
+		current->signal->group_stop_count = 0;
 		retval = 0;
 	}
 	spin_unlock_irq(&current->sighand->siglock);
@@ -1477,7 +1478,6 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	 * Clear any false indication of pending signals that might
 	 * be seen by the filesystem code called to write the core file.
 	 */
-	current->signal->group_stop_count = 0;
 	clear_thread_flag(TIF_SIGPENDING);
 
 	if (current->signal->rlim[RLIMIT_CORE].rlim_cur < binfmt->min_coredump)

commit 4a30131e7dbb17e5fec6958bfac9da9aff1fa29b
Author: NeilBrown <neilb@suse.de>
Date:   Sun Jan 8 01:02:39 2006 -0800

    [PATCH] Fix some problems with truncate and mtime semantics.
    
    SUS requires that when truncating a file to the size that it currently
    is:
      truncate and ftruncate should NOT modify ctime or mtime
      O_TRUNC SHOULD modify ctime and mtime.
    
    Currently mtime and ctime are always modified on most local
    filesystems (side effect of ->truncate) or never modified (on NFS).
    
    With this patch:
      ATTR_CTIME|ATTR_MTIME are sent with ATTR_SIZE precisely when
        an update of these times is required whether size changes or not
        (via a new argument to do_truncate).  This allows NFS to do
        the right thing for O_TRUNC.
      inode_setattr nolonger forces ATTR_MTIME|ATTR_CTIME when the ATTR_SIZE
        sets the size to it's current value.  This allows local filesystems
        to do the right thing for f?truncate.
    
    Also, the logic in inode_setattr is changed a bit so there are two return
    points.  One returns the error from vmtruncate if it failed, the other
    returns 0 (there can be no other failure).
    
    Finally, if vmtruncate succeeds, and ATTR_SIZE is the only change
    requested, we now fall-through and mark_inode_dirty.  If a filesystem did
    not have a ->truncate function, then vmtruncate will have changed i_size,
    without marking the inode as 'dirty', and I think this is wrong.
    
    Signed-off-by: Neil Brown <neilb@suse.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index e9650cd22a3b..2075b674d85e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1505,7 +1505,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		goto close_fail;
 	if (!file->f_op->write)
 		goto close_fail;
-	if (do_truncate(file->f_dentry, 0, file) != 0)
+	if (do_truncate(file->f_dentry, 0, 0, file) != 0)
 		goto close_fail;
 
 	retval = binfmt->core_dump(signr, regs, file);

commit e56d090310d7625ecb43a1eeebd479f04affb48b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 8 01:01:37 2006 -0800

    [PATCH] RCU signal handling
    
    RCU tasklist_lock and RCU signal handling: send signals RCU-read-locked
    instead of tasklist_lock read-locked.  This is a scalability improvement on
    SMP and a preemption-latency improvement under PREEMPT_RCU.
    
    Signed-off-by: Paul E. McKenney <paulmck@us.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: William Irwin <wli@holomorphy.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index e75a9548da8e..e9650cd22a3b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -760,7 +760,7 @@ static inline int de_thread(struct task_struct *tsk)
 		spin_lock(&oldsighand->siglock);
 		spin_lock(&newsighand->siglock);
 
-		current->sighand = newsighand;
+		rcu_assign_pointer(current->sighand, newsighand);
 		recalc_sigpending();
 
 		spin_unlock(&newsighand->siglock);
@@ -768,7 +768,7 @@ static inline int de_thread(struct task_struct *tsk)
 		write_unlock_irq(&tasklist_lock);
 
 		if (atomic_dec_and_test(&oldsighand->count))
-			kmem_cache_free(sighand_cachep, oldsighand);
+			sighand_free(oldsighand);
 	}
 
 	BUG_ON(!thread_group_leader(current));

commit 9617d95e6e9ffd883cf90a89724fe60d7ab22f9a
Author: Nick Piggin <nickpiggin@yahoo.com.au>
Date:   Fri Jan 6 00:11:12 2006 -0800

    [PATCH] mm: rmap optimisation
    
    Optimise rmap functions by minimising atomic operations when we know there
    will be no concurrent modifications.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 22533cce0611..e75a9548da8e 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -324,7 +324,7 @@ void install_arg_page(struct vm_area_struct *vma,
 	lru_cache_add_active(page);
 	set_pte_at(mm, address, pte, pte_mkdirty(pte_mkwrite(mk_pte(
 					page, vma->vm_page_prot))));
-	page_add_anon_rmap(page, vma, address);
+	page_add_new_anon_rmap(page, vma, address);
 	pte_unmap_unlock(pte, ptl);
 
 	/* no need for flush_tlb */

commit c9cfcddfd65735437a4cb8563d6b66a6da8a5ed6
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Tue Nov 29 14:03:14 2005 -0800

    VM: add common helper function to create the page tables
    
    This logic was duplicated four times, for no good reason.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 1f8a9fd2c9ed..22533cce0611 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -306,9 +306,6 @@ void install_arg_page(struct vm_area_struct *vma,
 			struct page *page, unsigned long address)
 {
 	struct mm_struct *mm = vma->vm_mm;
-	pgd_t * pgd;
-	pud_t * pud;
-	pmd_t * pmd;
 	pte_t * pte;
 	spinlock_t *ptl;
 
@@ -316,14 +313,7 @@ void install_arg_page(struct vm_area_struct *vma,
 		goto out;
 
 	flush_dcache_page(page);
-	pgd = pgd_offset(mm, address);
-	pud = pud_alloc(mm, pgd, address);
-	if (!pud)
-		goto out;
-	pmd = pmd_alloc(mm, pud, address);
-	if (!pmd)
-		goto out;
-	pte = pte_alloc_map_lock(mm, pmd, address, &ptl);
+	pte = get_locked_pte(mm, address, &ptl);
 	if (!pte)
 		goto out;
 	if (!pte_none(*pte)) {

commit 962b564cf1ec8041e8890a3c3847e3a630a08f42
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Nov 23 13:37:43 2005 -0800

    [PATCH] fix do_wait() vs exec() race
    
    When non-leader thread does exec, de_thread adds old leader to the init's
    ->children list in EXIT_ZOMBIE state and drops tasklist_lock.
    
    This means that release_task(leader) in de_thread() is racy vs do_wait()
    from init task.
    
    I think de_thread() should set old leader's state to EXIT_DEAD instead.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: george anzinger <george@mvista.com>
    Cc: Roland Dreier <rolandd@cisco.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Linus Torvalds <torvalds@osdl.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index c466fec5de20..1f8a9fd2c9ed 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -668,7 +668,7 @@ static inline int de_thread(struct task_struct *tsk)
 	if (!thread_group_leader(current)) {
 		struct task_struct *parent;
 		struct dentry *proc_dentry1, *proc_dentry2;
-		unsigned long exit_state, ptrace;
+		unsigned long ptrace;
 
 		/*
 		 * Wait for the thread group leader to be a zombie.
@@ -726,15 +726,15 @@ static inline int de_thread(struct task_struct *tsk)
 		list_del(&current->tasks);
 		list_add_tail(&current->tasks, &init_task.tasks);
 		current->exit_signal = SIGCHLD;
-		exit_state = leader->exit_state;
+
+		BUG_ON(leader->exit_state != EXIT_ZOMBIE);
+		leader->exit_state = EXIT_DEAD;
 
 		write_unlock_irq(&tasklist_lock);
 		spin_unlock(&leader->proc_lock);
 		spin_unlock(&current->proc_lock);
 		proc_pid_flush(proc_dentry1);
 		proc_pid_flush(proc_dentry2);
-
-		BUG_ON(exit_state != EXIT_ZOMBIE);
         }
 
 	/*

commit 8c744fb83da0771afa04695028e3550b798dad90
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 8 21:35:04 2005 -0800

    [PATCH] add a file_permission helper
    
    A few more callers of permission() just want to check for a different access
    pattern on an already open file.  This patch adds a wrapper for permission()
    that takes a file in preparation of per-mount read-only support and to clean
    up the callers a little.  The helper is not intended for new code, everything
    without the interface set in stone should use vfs_permission()
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 7bbb781b9ac6..c466fec5de20 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -896,7 +896,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	flush_thread();
 
 	if (bprm->e_uid != current->euid || bprm->e_gid != current->egid || 
-	    permission(bprm->file->f_dentry->d_inode,MAY_READ, NULL) ||
+	    file_permission(bprm->file, MAY_READ) ||
 	    (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)) {
 		suid_keys(current);
 		current->mm->dumpable = suid_dumpable;

commit e4543eddfd3bf3e0d625841377fa695a519edfd4
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 8 21:35:04 2005 -0800

    [PATCH] add a vfs_permission helper
    
    Most permission() calls have a struct nameidata * available.  This helper
    takes that as an argument and thus makes sure we pass it down for lookup
    intents and prepares for per-mount read-only support where we need a struct
    vfsmount for checking whether a file is writeable.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 5a4e3acc2e9f..7bbb781b9ac6 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -135,7 +135,7 @@ asmlinkage long sys_uselib(const char __user * library)
 	if (!S_ISREG(nd.dentry->d_inode->i_mode))
 		goto exit;
 
-	error = permission(nd.dentry->d_inode, MAY_READ | MAY_EXEC, &nd);
+	error = vfs_permission(&nd, MAY_READ | MAY_EXEC);
 	if (error)
 		goto exit;
 
@@ -495,7 +495,7 @@ struct file *open_exec(const char *name)
 		file = ERR_PTR(-EACCES);
 		if (!(nd.mnt->mnt_flags & MNT_NOEXEC) &&
 		    S_ISREG(inode->i_mode)) {
-			int err = permission(inode, MAY_EXEC, &nd);
+			int err = vfs_permission(&nd, MAY_EXEC);
 			if (!err && !(inode->i_mode & 0111))
 				err = -EACCES;
 			file = ERR_PTR(err);

commit 329f7dba5f7dc3bc9a30ad00cf373d2e83115aa1
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Nov 7 21:12:43 2005 +0300

    [PATCH] fix de_thread() vs send_group_sigqueue() race
    
    When non-leader thread does exec, de_thread calls release_task(leader) before
    calling exit_itimers(). If local timer interrupt happens in between, it can
    oops in send_group_sigqueue() while taking ->sighand->siglock == NULL.
    
    However, we can't change send_group_sigqueue() to check p->signal != NULL,
    because sys_timer_create() does get_task_struct() only in SIGEV_THREAD_ID
    case. So it is possible that this task_struct was already freed and we can't
    trust p->signal.
    
    This patch changes de_thread() so that leader released after exit_itimers()
    call.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Chris Wright <chrisw@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index cd6c574557dc..5a4e3acc2e9f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -590,6 +590,7 @@ static inline int de_thread(struct task_struct *tsk)
 	struct signal_struct *sig = tsk->signal;
 	struct sighand_struct *newsighand, *oldsighand = tsk->sighand;
 	spinlock_t *lock = &oldsighand->siglock;
+	struct task_struct *leader = NULL;
 	int count;
 
 	/*
@@ -665,7 +666,7 @@ static inline int de_thread(struct task_struct *tsk)
 	 * and to assume its PID:
 	 */
 	if (!thread_group_leader(current)) {
-		struct task_struct *leader = current->group_leader, *parent;
+		struct task_struct *parent;
 		struct dentry *proc_dentry1, *proc_dentry2;
 		unsigned long exit_state, ptrace;
 
@@ -674,6 +675,7 @@ static inline int de_thread(struct task_struct *tsk)
 		 * It should already be zombie at this point, most
 		 * of the time.
 		 */
+		leader = current->group_leader;
 		while (leader->exit_state != EXIT_ZOMBIE)
 			yield();
 
@@ -733,7 +735,6 @@ static inline int de_thread(struct task_struct *tsk)
 		proc_pid_flush(proc_dentry2);
 
 		BUG_ON(exit_state != EXIT_ZOMBIE);
-		release_task(leader);
         }
 
 	/*
@@ -743,8 +744,11 @@ static inline int de_thread(struct task_struct *tsk)
 	sig->flags = 0;
 
 no_thread_group:
-	BUG_ON(atomic_read(&sig->count) != 1);
 	exit_itimers(sig);
+	if (leader)
+		release_task(leader);
+
+	BUG_ON(atomic_read(&sig->count) != 1);
 
 	if (atomic_read(&oldsighand->count) == 1) {
 		/*

commit cc4e69dee4a080f6eae3f410daec2593f4fa6f00
Author: Miklos Szeredi <miklos@szeredi.hu>
Date:   Mon Nov 7 00:59:49 2005 -0800

    [PATCH] VFS: pass file pointer to filesystem from ftruncate()
    
    This patch extends the iattr structure with a file pointer memeber, and adds
    an ATTR_FILE validity flag for this member.
    
    This is set if do_truncate() is invoked from ftruncate() or from
    do_coredump().
    
    The change is source and binary compatible.
    
    Signed-off-by: Miklos Szeredi <miklos@szeredi.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index ce76b33f25ac..cd6c574557dc 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1511,7 +1511,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		goto close_fail;
 	if (!file->f_op->write)
 		goto close_fail;
-	if (do_truncate(file->f_dentry, 0) != 0)
+	if (do_truncate(file->f_dentry, 0, file) != 0)
 		goto close_fail;
 
 	retval = binfmt->core_dump(signr, regs, file);

commit 9f46080c41d5f3f7c00b4e169ba4b0b2865258bf
Author: Matt Helsley <matthltc@us.ibm.com>
Date:   Mon Nov 7 00:59:16 2005 -0800

    [PATCH] Process Events Connector
    
    This patch adds a connector that reports fork, exec, id change, and exit
    events for all processes to userspace.  It replaces the fork_advisor patch
    that ELSA is currently using.  Applications that may find these events
    useful include accounting/auditing (e.g.  ELSA), system activity monitoring
    (e.g.  top), security, and resource management (e.g.  CKRM).
    
    Signed-off-by: Matt Helsley <matthltc@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 10d493fea7ce..ce76b33f25ac 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -48,6 +48,7 @@
 #include <linux/syscalls.h>
 #include <linux/rmap.h>
 #include <linux/acct.h>
+#include <linux/cn_proc.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -1096,6 +1097,7 @@ int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
 					fput(bprm->file);
 				bprm->file = NULL;
 				current->did_exec = 1;
+				proc_exec_connector(current);
 				return retval;
 			}
 			read_lock(&binfmt_lock);

commit 1291cf4163d21f1b4999d697cbf68d38e7151c28
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Oct 30 15:02:54 2005 -0800

    [PATCH] fix de_thread() vs do_coredump() deadlock
    
    de_thread() sends SIGKILL to all sub-threads and waits them to die in 'D'
    state.  It is possible that one of the threads already dequeued coredump
    signal.  When de_thread() unlocks ->sighand->lock that thread can enter
    do_coredump()->coredump_wait() and cause a deadlock.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6d9521636aaa..10d493fea7ce 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1460,11 +1460,21 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		current->fsuid = 0;	/* Dump root private */
 	}
 	mm->dumpable = 0;
-	init_completion(&mm->core_done);
+
+	retval = -EAGAIN;
 	spin_lock_irq(&current->sighand->siglock);
-	current->signal->flags = SIGNAL_GROUP_EXIT;
-	current->signal->group_exit_code = exit_code;
+	if (!(current->signal->flags & SIGNAL_GROUP_EXIT)) {
+		current->signal->flags = SIGNAL_GROUP_EXIT;
+		current->signal->group_exit_code = exit_code;
+		retval = 0;
+	}
 	spin_unlock_irq(&current->sighand->siglock);
+	if (retval) {
+		up_write(&mm->mmap_sem);
+		goto fail;
+	}
+
+	init_completion(&mm->core_done);
 	coredump_wait(mm);
 
 	/*

commit 2384f55f8aa520172c995965bd2f8a9740d53095
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Oct 30 15:02:47 2005 -0800

    [PATCH] coredump_wait() cleanup
    
    This patch deletes pointless code from coredump_wait().
    
    1. It does useless mm->core_waiters inc/dec under mm->mmap_sem,
       but any changes to ->core_waiters have no effect until we drop
       ->mmap_sem.
    
    2. It calls yield() for absolutely unknown reason.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index fc02dadc604a..6d9521636aaa 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1417,19 +1417,16 @@ static void zap_threads (struct mm_struct *mm)
 static void coredump_wait(struct mm_struct *mm)
 {
 	DECLARE_COMPLETION(startup_done);
+	int core_waiters;
 
-	mm->core_waiters++; /* let other threads block */
 	mm->core_startup_done = &startup_done;
 
-	/* give other threads a chance to run: */
-	yield();
-
 	zap_threads(mm);
-	if (--mm->core_waiters) {
-		up_write(&mm->mmap_sem);
+	core_waiters = mm->core_waiters;
+	up_write(&mm->mmap_sem);
+
+	if (core_waiters)
 		wait_for_completion(&startup_done);
-	} else
-		up_write(&mm->mmap_sem);
 	BUG_ON(mm->core_waiters);
 }
 

commit 932aeafbe8521a9a9d790152d66020e0fef2029b
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Oct 30 15:02:17 2005 -0800

    [PATCH] fix de_thread vs it_real_fn() deadlock
    
    de_thread() calls del_timer_sync(->real_timer) under ->sighand->siglock.
    This is deadlockable, it_real_fn sends a signal and needs this lock too.
    
    Also, delete unneeded ->real_timer.data assignment.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 1de69cdc0e6c..fc02dadc604a 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -641,8 +641,10 @@ static inline int de_thread(struct task_struct *tsk)
 		 * before we can safely let the old group leader die.
 		 */
 		sig->real_timer.data = (unsigned long)current;
+		spin_unlock_irq(lock);
 		if (del_timer_sync(&sig->real_timer))
 			add_timer(&sig->real_timer);
+		spin_lock_irq(lock);
 	}
 	while (atomic_read(&sig->count) > count) {
 		sig->group_exit_task = current;
@@ -654,7 +656,6 @@ static inline int de_thread(struct task_struct *tsk)
 	}
 	sig->group_exit_task = NULL;
 	sig->notify_count = 0;
-	sig->real_timer.data = (unsigned long)current;
 	spin_unlock_irq(lock);
 
 	/*

commit 9e4e23bccb127fac109e765dfb7f9372661cb415
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Oct 30 15:01:37 2005 -0800

    [PATCH] little de_thread() cleanup
    
    Trivial, saves one 'if' branch in de_thread().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index ba73797eb4cb..1de69cdc0e6c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -630,10 +630,9 @@ static inline int de_thread(struct task_struct *tsk)
 	/*
 	 * Account for the thread group leader hanging around:
 	 */
-	count = 2;
-	if (thread_group_leader(current))
-		count = 1;
-	else {
+	count = 1;
+	if (!thread_group_leader(current)) {
+		count = 2;
 		/*
 		 * The SIGALRM timer survives the exec, but needs to point
 		 * at us as the new group leader now.  We have a race with

commit c74df32c724a1652ad8399b4891bb02c9d43743a
Author: Hugh Dickins <hugh@veritas.com>
Date:   Sat Oct 29 18:16:23 2005 -0700

    [PATCH] mm: ptd_alloc take ptlock
    
    Second step in pushing down the page_table_lock.  Remove the temporary
    bridging hack from __pud_alloc, __pmd_alloc, __pte_alloc: expect callers not
    to hold page_table_lock, whether it's on init_mm or a user mm; take
    page_table_lock internally to check if a racing task already allocated.
    
    Convert their callers from common code.  But avoid coming back to change them
    again later: instead of moving the spin_lock(&mm->page_table_lock) down,
    switch over to new macros pte_alloc_map_lock and pte_unmap_unlock, which
    encapsulate the mapping+locking and unlocking+unmapping together, and in the
    end may use alternatives to the mm page_table_lock itself.
    
    These callers all hold mmap_sem (some exclusively, some not), so at no level
    can a page table be whipped away from beneath them; and pte_alloc uses the
    "atomic" pmd_present to test whether it needs to allocate.  It appears that on
    all arches we can safely descend without page_table_lock.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 9bb55c8cf224..ba73797eb4cb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -309,25 +309,24 @@ void install_arg_page(struct vm_area_struct *vma,
 	pud_t * pud;
 	pmd_t * pmd;
 	pte_t * pte;
+	spinlock_t *ptl;
 
 	if (unlikely(anon_vma_prepare(vma)))
-		goto out_sig;
+		goto out;
 
 	flush_dcache_page(page);
 	pgd = pgd_offset(mm, address);
-
-	spin_lock(&mm->page_table_lock);
 	pud = pud_alloc(mm, pgd, address);
 	if (!pud)
 		goto out;
 	pmd = pmd_alloc(mm, pud, address);
 	if (!pmd)
 		goto out;
-	pte = pte_alloc_map(mm, pmd, address);
+	pte = pte_alloc_map_lock(mm, pmd, address, &ptl);
 	if (!pte)
 		goto out;
 	if (!pte_none(*pte)) {
-		pte_unmap(pte);
+		pte_unmap_unlock(pte, ptl);
 		goto out;
 	}
 	inc_mm_counter(mm, anon_rss);
@@ -335,14 +334,11 @@ void install_arg_page(struct vm_area_struct *vma,
 	set_pte_at(mm, address, pte, pte_mkdirty(pte_mkwrite(mk_pte(
 					page, vma->vm_page_prot))));
 	page_add_anon_rmap(page, vma, address);
-	pte_unmap(pte);
-	spin_unlock(&mm->page_table_lock);
+	pte_unmap_unlock(pte, ptl);
 
 	/* no need for flush_tlb */
 	return;
 out:
-	spin_unlock(&mm->page_table_lock);
-out_sig:
 	__free_page(page);
 	force_sig(SIGKILL, current);
 }

commit 365e9c87a982c03d0af3886e29d877f581b59611
Author: Hugh Dickins <hugh@veritas.com>
Date:   Sat Oct 29 18:16:18 2005 -0700

    [PATCH] mm: update_hiwaters just in time
    
    update_mem_hiwater has attracted various criticisms, in particular from those
    concerned with mm scalability.  Originally it was called whenever rss or
    total_vm got raised.  Then many of those callsites were replaced by a timer
    tick call from account_system_time.  Now Frank van Maarseveen reports that to
    be found inadequate.  How about this?  Works for Frank.
    
    Replace update_mem_hiwater, a poor combination of two unrelated ops, by macros
    update_hiwater_rss and update_hiwater_vm.  Don't attempt to keep
    mm->hiwater_rss up to date at timer tick, nor every time we raise rss (usually
    by 1): those are hot paths.  Do the opposite, update only when about to lower
    rss (usually by many), or just before final accounting in do_exit.  Handle
    mm->hiwater_vm in the same way, though it's much less of an issue.  Demand
    that whoever collects these hiwater statistics do the work of taking the
    maximum with rss or total_vm.
    
    And there has been no collector of these hiwater statistics in the tree.  The
    new convention needs an example, so match Frank's usage by adding a VmPeak
    line above VmSize to /proc/<pid>/status, and also a VmHWM line above VmRSS
    (High-Water-Mark or High-Water-Memory).
    
    There was a particular anomaly during mremap move, that hiwater_vm might be
    captured too high.  A fleeting such anomaly remains, but it's quickly
    corrected now, whereas before it would stick.
    
    What locking?  None: if the app is racy then these statistics will be racy,
    it's not worth any overhead to make them exact.  But whenever it suits,
    hiwater_vm is updated under exclusive mmap_sem, and hiwater_rss under
    page_table_lock (for now) or with preemption disabled (later on): without
    going to any trouble, minimize the time between reading current values and
    updating, to minimize those occasions when a racing thread bumps a count up
    and back down in between.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index cefadf5ab83b..9bb55c8cf224 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1207,7 +1207,6 @@ int do_execve(char * filename,
 		/* execve success */
 		security_bprm_free(bprm);
 		acct_update_integrals(current);
-		update_mem_hiwater(current);
 		kfree(bprm);
 		return retval;
 	}

commit 4294621f41a85497019fae64341aa5351a1921b7
Author: Hugh Dickins <hugh@veritas.com>
Date:   Sat Oct 29 18:16:05 2005 -0700

    [PATCH] mm: rss = file_rss + anon_rss
    
    I was lazy when we added anon_rss, and chose to change as few places as
    possible.  So currently each anonymous page has to be counted twice, in rss
    and in anon_rss.  Which won't be so good if those are atomic counts in some
    configurations.
    
    Change that around: keep file_rss and anon_rss separately, and add them
    together (with get_mm_rss macro) when the total is needed - reading two
    atomics is much cheaper than updating two atomics.  And update anon_rss
    upfront, typically in memory.c, not tucked away in page_add_anon_rmap.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index d2208f7c87db..cefadf5ab83b 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -330,7 +330,7 @@ void install_arg_page(struct vm_area_struct *vma,
 		pte_unmap(pte);
 		goto out;
 	}
-	inc_mm_counter(mm, rss);
+	inc_mm_counter(mm, anon_rss);
 	lru_cache_add_active(page);
 	set_pte_at(mm, address, pte, pte_mkdirty(pte_mkwrite(mk_pte(
 					page, vma->vm_page_prot))));

commit 834f2a4a1554dc5b2598038b3fe8703defcbe467
Author: Trond Myklebust <Trond.Myklebust@netapp.com>
Date:   Tue Oct 18 14:20:16 2005 -0700

    VFS: Allow the filesystem to return a full file pointer on open intent
    
     This is needed by NFSv4 for atomicity reasons: our open command is in
     fact a lookup+open, so we need to be able to propagate open context
     information from lookup() into the resulting struct file's
     private_data field.
    
     Signed-off-by: Trond Myklebust <Trond.Myklebust@netapp.com>

diff --git a/fs/exec.c b/fs/exec.c
index a04a575ad433..d2208f7c87db 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -126,8 +126,7 @@ asmlinkage long sys_uselib(const char __user * library)
 	struct nameidata nd;
 	int error;
 
-	nd.intent.open.flags = FMODE_READ;
-	error = __user_walk(library, LOOKUP_FOLLOW|LOOKUP_OPEN, &nd);
+	error = __user_path_lookup_open(library, LOOKUP_FOLLOW, &nd, FMODE_READ);
 	if (error)
 		goto out;
 
@@ -139,7 +138,7 @@ asmlinkage long sys_uselib(const char __user * library)
 	if (error)
 		goto exit;
 
-	file = dentry_open(nd.dentry, nd.mnt, O_RDONLY);
+	file = nameidata_to_filp(&nd, O_RDONLY);
 	error = PTR_ERR(file);
 	if (IS_ERR(file))
 		goto out;
@@ -167,6 +166,7 @@ asmlinkage long sys_uselib(const char __user * library)
 out:
   	return error;
 exit:
+	release_open_intent(&nd);
 	path_release(&nd);
 	goto out;
 }
@@ -490,8 +490,7 @@ struct file *open_exec(const char *name)
 	int err;
 	struct file *file;
 
-	nd.intent.open.flags = FMODE_READ;
-	err = path_lookup(name, LOOKUP_FOLLOW|LOOKUP_OPEN, &nd);
+	err = path_lookup_open(name, LOOKUP_FOLLOW, &nd, FMODE_READ);
 	file = ERR_PTR(err);
 
 	if (!err) {
@@ -504,7 +503,7 @@ struct file *open_exec(const char *name)
 				err = -EACCES;
 			file = ERR_PTR(err);
 			if (!err) {
-				file = dentry_open(nd.dentry, nd.mnt, O_RDONLY);
+				file = nameidata_to_filp(&nd, O_RDONLY);
 				if (!IS_ERR(file)) {
 					err = deny_write_access(file);
 					if (err) {
@@ -516,6 +515,7 @@ struct file *open_exec(const char *name)
 				return file;
 			}
 		}
+		release_open_intent(&nd);
 		path_release(&nd);
 	}
 	goto out;

commit 2fd4ef85e0db9ed75c98e13953257a967ea55e03
Author: Hugh Dickins <hugh@veritas.com>
Date:   Wed Sep 14 06:13:02 2005 +0100

    [PATCH] error path in setup_arg_pages() misses vm_unacct_memory()
    
    Pavel Emelianov and Kirill Korotaev observe that fs and arch users of
    security_vm_enough_memory tend to forget to vm_unacct_memory when a
    failure occurs further down (typically in setup_arg_pages variants).
    
    These are all users of insert_vm_struct, and that reservation will only
    be unaccounted on exit if the vma is marked VM_ACCOUNT: which in some
    cases it is (hidden inside VM_STACK_FLAGS) and in some cases it isn't.
    
    So x86_64 32-bit and ppc64 vDSO ELFs have been leaking memory into
    Committed_AS each time they're run.  But don't add VM_ACCOUNT to them,
    it's inappropriate to reserve against the very unlikely case that gdb
    be used to COW a vDSO page - we ought to do something about that in
    do_wp_page, but there are yet other inconsistencies to be resolved.
    
    The safe and economical way to fix this is to let insert_vm_struct do
    the security_vm_enough_memory check when it finds VM_ACCOUNT is set.
    
    And the MIPS irix_brk has been calling security_vm_enough_memory before
    calling do_brk which repeats it, doubly accounting and so also leaking.
    Remove that, and all the fs and arch calls to security_vm_enough_memory:
    give it a less misleading name later on.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-Off-By: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 6fae59a22b43..a04a575ad433 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -421,11 +421,6 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	if (!mpnt)
 		return -ENOMEM;
 
-	if (security_vm_enough_memory(arg_size >> PAGE_SHIFT)) {
-		kmem_cache_free(vm_area_cachep, mpnt);
-		return -ENOMEM;
-	}
-
 	memset(mpnt, 0, sizeof(*mpnt));
 
 	down_write(&mm->mmap_sem);

commit fb085cf1d4294824571815d487daccc0609543f0
Author: Alexander Nyberg <alexn@telia.com>
Date:   Wed Sep 14 18:54:06 2005 +0200

    [PATCH] Fix fs/exec.c:788 (de_thread()) BUG_ON
    
    It turns out that the BUG_ON() in fs/exec.c: de_thread() is unreliable
    and can trigger due to the test itself being racy.
    
    de_thread() does
            while (atomic_read(&sig->count) > count) {
            }
            .....
            .....
            BUG_ON(!thread_group_empty(current));
    
    but release_task does
            write_lock_irq(&tasklist_lock)
            __exit_signal
                    (this is where atomic_dec(&sig->count) is run)
            __exit_sighand
            __unhash_process
                    takes write lock on tasklist_lock
                    remove itself out of PIDTYPE_TGID list
            write_unlock_irq(&tasklist_lock)
    
    so there's a clear (although small) window between the
    atomic_dec(&sig->count) and the actual PIDTYPE_TGID unhashing of the
    thread.
    
    And actually there is no need for all threads to have exited at this
    point, so we simply kill the BUG_ON.
    
    Big thanks to Marc Lehmann who provided the test-case.
    
    Fixes Bug 5170 (http://bugme.osdl.org/show_bug.cgi?id=5170)
    
    Signed-off-by: Alexander Nyberg <alexn@telia.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Andrew Morton <akpm@osdl.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Acked-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 14dd03907ccb..6fae59a22b43 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -745,8 +745,8 @@ static inline int de_thread(struct task_struct *tsk)
         }
 
 	/*
-	 * Now there are really no other threads at all,
-	 * so it's safe to stop telling them to kill themselves.
+	 * There may be one thread left which is just exiting,
+	 * but it's safe to stop telling the group to kill themselves.
 	 */
 	sig->flags = 0;
 
@@ -785,7 +785,6 @@ static inline int de_thread(struct task_struct *tsk)
 			kmem_cache_free(sighand_cachep, oldsighand);
 	}
 
-	BUG_ON(!thread_group_empty(current));
 	BUG_ON(!thread_group_leader(current));
 	return 0;
 }

commit badf16621c1f9d1ac753be056fce11b43d6e0be5
Author: Dipankar Sarma <dipankar@in.ibm.com>
Date:   Fri Sep 9 13:04:10 2005 -0700

    [PATCH] files: break up files struct
    
    In order for the RCU to work, the file table array, sets and their sizes must
    be updated atomically.  Instead of ensuring this through too many memory
    barriers, we put the arrays and their sizes in a separate structure.  This
    patch takes the first step of putting the file table elements in a separate
    structure fdtable that is embedded withing files_struct.  It also changes all
    the users to refer to the file table using files_fdtable() macro.  Subsequent
    applciation of RCU becomes easier after this.
    
    Signed-off-by: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-Off-By: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 222ab1c572d8..14dd03907ccb 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -798,6 +798,7 @@ static inline int de_thread(struct task_struct *tsk)
 static inline void flush_old_files(struct files_struct * files)
 {
 	long j = -1;
+	struct fdtable *fdt;
 
 	spin_lock(&files->file_lock);
 	for (;;) {
@@ -805,12 +806,13 @@ static inline void flush_old_files(struct files_struct * files)
 
 		j++;
 		i = j * __NFDBITS;
-		if (i >= files->max_fds || i >= files->max_fdset)
+		fdt = files_fdtable(files);
+		if (i >= fdt->max_fds || i >= fdt->max_fdset)
 			break;
-		set = files->close_on_exec->fds_bits[j];
+		set = fdt->close_on_exec->fds_bits[j];
 		if (!set)
 			continue;
-		files->close_on_exec->fds_bits[j] = 0;
+		fdt->close_on_exec->fds_bits[j] = 0;
 		spin_unlock(&files->file_lock);
 		for ( ; set ; i++,set >>= 1) {
 			if (set & 1) {

commit 5323125031799a7fd8602ce150c3902aedfdcba6
Author: Roland McGrath <roland@redhat.com>
Date:   Tue Jul 12 13:58:27 2005 -0700

    [PATCH] reset real_timer target on exec leader change
    
    When a noninitial thread does exec, it becomes the new group leader.  If
    there is a ITIMER_REAL timer running, it points at the old group leader and
    when it fires it can follow a stale pointer.  The timer data needs to be
    reset to point at the exec'ing thread that is becoming the group leader.
    This has to synchronize with any concurrent firing of the timer to make
    sure that it_real_fn can never run when the data points to a thread that
    might have been reaped already.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 48871917d363..222ab1c572d8 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -642,6 +642,18 @@ static inline int de_thread(struct task_struct *tsk)
 	count = 2;
 	if (thread_group_leader(current))
 		count = 1;
+	else {
+		/*
+		 * The SIGALRM timer survives the exec, but needs to point
+		 * at us as the new group leader now.  We have a race with
+		 * a timer firing now getting the old leader, so we need to
+		 * synchronize with any firing (by calling del_timer_sync)
+		 * before we can safely let the old group leader die.
+		 */
+		sig->real_timer.data = (unsigned long)current;
+		if (del_timer_sync(&sig->real_timer))
+			add_timer(&sig->real_timer);
+	}
 	while (atomic_read(&sig->count) > count) {
 		sig->group_exit_task = current;
 		sig->notify_count = count;

commit d6e711448137ca3301512cec41a2c2ce852b3d0a
Author: Alan Cox <alan@lxorguk.ukuu.org.uk>
Date:   Thu Jun 23 00:09:43 2005 -0700

    [PATCH] setuid core dump
    
    Add a new `suid_dumpable' sysctl:
    
    This value can be used to query and set the core dump mode for setuid
    or otherwise protected/tainted binaries. The modes are
    
    0 - (default) - traditional behaviour.  Any process which has changed
        privilege levels or is execute only will not be dumped
    
    1 - (debug) - all processes dump core when possible.  The core dump is
        owned by the current user and no security is applied.  This is intended
        for system debugging situations only.  Ptrace is unchecked.
    
    2 - (suidsafe) - any binary which normally would not be dumped is dumped
        readable by root only.  This allows the end user to remove such a dump but
        not access it directly.  For security reasons core dumps in this mode will
        not overwrite one another or other files.  This mode is appropriate when
        adminstrators are attempting to debug problems in a normal environment.
    
    (akpm:
    
    > > +EXPORT_SYMBOL(suid_dumpable);
    >
    > EXPORT_SYMBOL_GPL?
    
    No problem to me.
    
    > >     if (current->euid == current->uid && current->egid == current->gid)
    > >             current->mm->dumpable = 1;
    >
    > Should this be SUID_DUMP_USER?
    
    Actually the feedback I had from last time was that the SUID_ defines
    should go because its clearer to follow the numbers. They can go
    everywhere (and there are lots of places where dumpable is tested/used
    as a bool in untouched code)
    
    > Maybe this should be renamed to `dump_policy' or something.  Doing that
    > would help us catch any code which isn't using the #defines, too.
    
    Fair comment. The patch was designed to be easy to maintain for Red Hat
    rather than for merging. Changing that field would create a gigantic
    diff because it is used all over the place.
    
    )
    
    Signed-off-by: Alan Cox <alan@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 3a4b35a14c0d..48871917d363 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -58,6 +58,9 @@
 
 int core_uses_pid;
 char core_pattern[65] = "core";
+int suid_dumpable = 0;
+
+EXPORT_SYMBOL(suid_dumpable);
 /* The maximal length of core_pattern is also specified in sysctl.c */
 
 static struct linux_binfmt *formats;
@@ -864,6 +867,9 @@ int flush_old_exec(struct linux_binprm * bprm)
 
 	if (current->euid == current->uid && current->egid == current->gid)
 		current->mm->dumpable = 1;
+	else
+		current->mm->dumpable = suid_dumpable;
+
 	name = bprm->filename;
 
 	/* Copies the binary name from after last slash */
@@ -884,7 +890,7 @@ int flush_old_exec(struct linux_binprm * bprm)
 	    permission(bprm->file->f_dentry->d_inode,MAY_READ, NULL) ||
 	    (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)) {
 		suid_keys(current);
-		current->mm->dumpable = 0;
+		current->mm->dumpable = suid_dumpable;
 	}
 
 	/* An exec changes our domain. We are no longer part of the thread
@@ -1432,6 +1438,8 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 	struct inode * inode;
 	struct file * file;
 	int retval = 0;
+	int fsuid = current->fsuid;
+	int flag = 0;
 
 	binfmt = current->binfmt;
 	if (!binfmt || !binfmt->core_dump)
@@ -1441,6 +1449,16 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 		up_write(&mm->mmap_sem);
 		goto fail;
 	}
+
+	/*
+	 *	We cannot trust fsuid as being the "true" uid of the
+	 *	process nor do we know its entire history. We only know it
+	 *	was tainted so we dump it as root in mode 2.
+	 */
+	if (mm->dumpable == 2) {	/* Setuid core dump mode */
+		flag = O_EXCL;		/* Stop rewrite attacks */
+		current->fsuid = 0;	/* Dump root private */
+	}
 	mm->dumpable = 0;
 	init_completion(&mm->core_done);
 	spin_lock_irq(&current->sighand->siglock);
@@ -1466,7 +1484,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
  	lock_kernel();
 	format_corename(corename, core_pattern, signr);
 	unlock_kernel();
-	file = filp_open(corename, O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE, 0600);
+	file = filp_open(corename, O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE | flag, 0600);
 	if (IS_ERR(file))
 		goto fail_unlock;
 	inode = file->f_dentry->d_inode;
@@ -1491,6 +1509,7 @@ int do_coredump(long signr, int exit_code, struct pt_regs * regs)
 close_fail:
 	filp_close(file, NULL);
 fail_unlock:
+	current->fsuid = fsuid;
 	complete_all(&mm->core_done);
 fail:
 	return retval;

commit c2a0f5943d8935766a42b2d0870aa4c645e3423d
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Jun 18 13:06:22 2005 -0700

    Clean up subthread exec
    
    Make sure we re-parent itimers, and use BUG_ON() instead of an explicit
    conditional BUG().

diff --git a/fs/exec.c b/fs/exec.c
index e56ee2437025..3a4b35a14c0d 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -649,6 +649,7 @@ static inline int de_thread(struct task_struct *tsk)
 	}
 	sig->group_exit_task = NULL;
 	sig->notify_count = 0;
+	sig->real_timer.data = (unsigned long)current;
 	spin_unlock_irq(lock);
 
 	/*
@@ -675,10 +676,8 @@ static inline int de_thread(struct task_struct *tsk)
 		proc_dentry2 = proc_pid_unhash(leader);
 		write_lock_irq(&tasklist_lock);
 
-		if (leader->tgid != current->tgid)
-			BUG();
-		if (current->pid == current->tgid)
-			BUG();
+		BUG_ON(leader->tgid != current->tgid);
+		BUG_ON(current->pid == current->tgid);
 		/*
 		 * An exec() starts a new thread group with the
 		 * TGID of the previous thread group. Rehash the
@@ -726,8 +725,7 @@ static inline int de_thread(struct task_struct *tsk)
 		proc_pid_flush(proc_dentry1);
 		proc_pid_flush(proc_dentry2);
 
-		if (exit_state != EXIT_ZOMBIE)
-			BUG();
+		BUG_ON(exit_state != EXIT_ZOMBIE);
 		release_task(leader);
         }
 
@@ -772,10 +770,8 @@ static inline int de_thread(struct task_struct *tsk)
 			kmem_cache_free(sighand_cachep, oldsighand);
 	}
 
-	if (!thread_group_empty(current))
-		BUG();
-	if (!thread_group_leader(current))
-		BUG();
+	BUG_ON(!thread_group_empty(current));
+	BUG_ON(!thread_group_leader(current));
 	return 0;
 }
 	

commit 3677209239ed71d2654e73eecfab1dbec2af11a9
Author: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
Date:   Thu May 5 16:16:12 2005 -0700

    [PATCH] comments on locking of task->comm
    
    Add some comments about task->comm, to explain what it is near its definition
    and provide some important pointers to its uses.
    
    Signed-off-by: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index 52acff3f44f0..e56ee2437025 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -869,9 +869,11 @@ int flush_old_exec(struct linux_binprm * bprm)
 	if (current->euid == current->uid && current->egid == current->gid)
 		current->mm->dumpable = 1;
 	name = bprm->filename;
+
+	/* Copies the binary name from after last slash */
 	for (i=0; (ch = *(name++)) != '\0';) {
 		if (ch == '/')
-			i = 0;
+			i = 0; /* overwrite what we wrote */
 		else
 			if (i < (sizeof(tcomm) - 1))
 				tcomm[i++] = ch;

commit 75c96f85845a6707b0f9916cb263cb3584f7d48f
Author: Adrian Bunk <bunk@stusta.de>
Date:   Thu May 5 16:16:09 2005 -0700

    [PATCH] make some things static
    
    This patch makes some needlessly global identifiers static.
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Acked-by: Arjan van de Ven <arjanv@infradead.org>
    Acked-by: Trond Myklebust <trond.myklebust@fys.uio.no>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/exec.c b/fs/exec.c
index a8394499926c..52acff3f44f0 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -197,7 +197,8 @@ static int count(char __user * __user * argv, int max)
  * memory to free pages in kernel mem. These are in a format ready
  * to be put directly into the top of new user memory.
  */
-int copy_strings(int argc,char __user * __user * argv, struct linux_binprm *bprm)
+static int copy_strings(int argc, char __user * __user * argv,
+			struct linux_binprm *bprm)
 {
 	struct page *kmapped_page = NULL;
 	char *kaddr = NULL;

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/fs/exec.c b/fs/exec.c
new file mode 100644
index 000000000000..a8394499926c
--- /dev/null
+++ b/fs/exec.c
@@ -0,0 +1,1498 @@
+/*
+ *  linux/fs/exec.c
+ *
+ *  Copyright (C) 1991, 1992  Linus Torvalds
+ */
+
+/*
+ * #!-checking implemented by tytso.
+ */
+/*
+ * Demand-loading implemented 01.12.91 - no need to read anything but
+ * the header into memory. The inode of the executable is put into
+ * "current->executable", and page faults do the actual loading. Clean.
+ *
+ * Once more I can proudly say that linux stood up to being changed: it
+ * was less than 2 hours work to get demand-loading completely implemented.
+ *
+ * Demand loading changed July 1993 by Eric Youngdale.   Use mmap instead,
+ * current->executable is only used by the procfs.  This allows a dispatch
+ * table to check for several different types  of binary formats.  We keep
+ * trying until we recognize the file or we run out of supported binary
+ * formats. 
+ */
+
+#include <linux/config.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#include <linux/mman.h>
+#include <linux/a.out.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/smp_lock.h>
+#include <linux/init.h>
+#include <linux/pagemap.h>
+#include <linux/highmem.h>
+#include <linux/spinlock.h>
+#include <linux/key.h>
+#include <linux/personality.h>
+#include <linux/binfmts.h>
+#include <linux/swap.h>
+#include <linux/utsname.h>
+#include <linux/module.h>
+#include <linux/namei.h>
+#include <linux/proc_fs.h>
+#include <linux/ptrace.h>
+#include <linux/mount.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/rmap.h>
+#include <linux/acct.h>
+
+#include <asm/uaccess.h>
+#include <asm/mmu_context.h>
+
+#ifdef CONFIG_KMOD
+#include <linux/kmod.h>
+#endif
+
+int core_uses_pid;
+char core_pattern[65] = "core";
+/* The maximal length of core_pattern is also specified in sysctl.c */
+
+static struct linux_binfmt *formats;
+static DEFINE_RWLOCK(binfmt_lock);
+
+int register_binfmt(struct linux_binfmt * fmt)
+{
+	struct linux_binfmt ** tmp = &formats;
+
+	if (!fmt)
+		return -EINVAL;
+	if (fmt->next)
+		return -EBUSY;
+	write_lock(&binfmt_lock);
+	while (*tmp) {
+		if (fmt == *tmp) {
+			write_unlock(&binfmt_lock);
+			return -EBUSY;
+		}
+		tmp = &(*tmp)->next;
+	}
+	fmt->next = formats;
+	formats = fmt;
+	write_unlock(&binfmt_lock);
+	return 0;	
+}
+
+EXPORT_SYMBOL(register_binfmt);
+
+int unregister_binfmt(struct linux_binfmt * fmt)
+{
+	struct linux_binfmt ** tmp = &formats;
+
+	write_lock(&binfmt_lock);
+	while (*tmp) {
+		if (fmt == *tmp) {
+			*tmp = fmt->next;
+			write_unlock(&binfmt_lock);
+			return 0;
+		}
+		tmp = &(*tmp)->next;
+	}
+	write_unlock(&binfmt_lock);
+	return -EINVAL;
+}
+
+EXPORT_SYMBOL(unregister_binfmt);
+
+static inline void put_binfmt(struct linux_binfmt * fmt)
+{
+	module_put(fmt->module);
+}
+
+/*
+ * Note that a shared library must be both readable and executable due to
+ * security reasons.
+ *
+ * Also note that we take the address to load from from the file itself.
+ */
+asmlinkage long sys_uselib(const char __user * library)
+{
+	struct file * file;
+	struct nameidata nd;
+	int error;
+
+	nd.intent.open.flags = FMODE_READ;
+	error = __user_walk(library, LOOKUP_FOLLOW|LOOKUP_OPEN, &nd);
+	if (error)
+		goto out;
+
+	error = -EINVAL;
+	if (!S_ISREG(nd.dentry->d_inode->i_mode))
+		goto exit;
+
+	error = permission(nd.dentry->d_inode, MAY_READ | MAY_EXEC, &nd);
+	if (error)
+		goto exit;
+
+	file = dentry_open(nd.dentry, nd.mnt, O_RDONLY);
+	error = PTR_ERR(file);
+	if (IS_ERR(file))
+		goto out;
+
+	error = -ENOEXEC;
+	if(file->f_op) {
+		struct linux_binfmt * fmt;
+
+		read_lock(&binfmt_lock);
+		for (fmt = formats ; fmt ; fmt = fmt->next) {
+			if (!fmt->load_shlib)
+				continue;
+			if (!try_module_get(fmt->module))
+				continue;
+			read_unlock(&binfmt_lock);
+			error = fmt->load_shlib(file);
+			read_lock(&binfmt_lock);
+			put_binfmt(fmt);
+			if (error != -ENOEXEC)
+				break;
+		}
+		read_unlock(&binfmt_lock);
+	}
+	fput(file);
+out:
+  	return error;
+exit:
+	path_release(&nd);
+	goto out;
+}
+
+/*
+ * count() counts the number of strings in array ARGV.
+ */
+static int count(char __user * __user * argv, int max)
+{
+	int i = 0;
+
+	if (argv != NULL) {
+		for (;;) {
+			char __user * p;
+
+			if (get_user(p, argv))
+				return -EFAULT;
+			if (!p)
+				break;
+			argv++;
+			if(++i > max)
+				return -E2BIG;
+			cond_resched();
+		}
+	}
+	return i;
+}
+
+/*
+ * 'copy_strings()' copies argument/environment strings from user
+ * memory to free pages in kernel mem. These are in a format ready
+ * to be put directly into the top of new user memory.
+ */
+int copy_strings(int argc,char __user * __user * argv, struct linux_binprm *bprm)
+{
+	struct page *kmapped_page = NULL;
+	char *kaddr = NULL;
+	int ret;
+
+	while (argc-- > 0) {
+		char __user *str;
+		int len;
+		unsigned long pos;
+
+		if (get_user(str, argv+argc) ||
+				!(len = strnlen_user(str, bprm->p))) {
+			ret = -EFAULT;
+			goto out;
+		}
+
+		if (bprm->p < len)  {
+			ret = -E2BIG;
+			goto out;
+		}
+
+		bprm->p -= len;
+		/* XXX: add architecture specific overflow check here. */
+		pos = bprm->p;
+
+		while (len > 0) {
+			int i, new, err;
+			int offset, bytes_to_copy;
+			struct page *page;
+
+			offset = pos % PAGE_SIZE;
+			i = pos/PAGE_SIZE;
+			page = bprm->page[i];
+			new = 0;
+			if (!page) {
+				page = alloc_page(GFP_HIGHUSER);
+				bprm->page[i] = page;
+				if (!page) {
+					ret = -ENOMEM;
+					goto out;
+				}
+				new = 1;
+			}
+
+			if (page != kmapped_page) {
+				if (kmapped_page)
+					kunmap(kmapped_page);
+				kmapped_page = page;
+				kaddr = kmap(kmapped_page);
+			}
+			if (new && offset)
+				memset(kaddr, 0, offset);
+			bytes_to_copy = PAGE_SIZE - offset;
+			if (bytes_to_copy > len) {
+				bytes_to_copy = len;
+				if (new)
+					memset(kaddr+offset+len, 0,
+						PAGE_SIZE-offset-len);
+			}
+			err = copy_from_user(kaddr+offset, str, bytes_to_copy);
+			if (err) {
+				ret = -EFAULT;
+				goto out;
+			}
+
+			pos += bytes_to_copy;
+			str += bytes_to_copy;
+			len -= bytes_to_copy;
+		}
+	}
+	ret = 0;
+out:
+	if (kmapped_page)
+		kunmap(kmapped_page);
+	return ret;
+}
+
+/*
+ * Like copy_strings, but get argv and its values from kernel memory.
+ */
+int copy_strings_kernel(int argc,char ** argv, struct linux_binprm *bprm)
+{
+	int r;
+	mm_segment_t oldfs = get_fs();
+	set_fs(KERNEL_DS);
+	r = copy_strings(argc, (char __user * __user *)argv, bprm);
+	set_fs(oldfs);
+	return r;
+}
+
+EXPORT_SYMBOL(copy_strings_kernel);
+
+#ifdef CONFIG_MMU
+/*
+ * This routine is used to map in a page into an address space: needed by
+ * execve() for the initial stack and environment pages.
+ *
+ * vma->vm_mm->mmap_sem is held for writing.
+ */
+void install_arg_page(struct vm_area_struct *vma,
+			struct page *page, unsigned long address)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	pgd_t * pgd;
+	pud_t * pud;
+	pmd_t * pmd;
+	pte_t * pte;
+
+	if (unlikely(anon_vma_prepare(vma)))
+		goto out_sig;
+
+	flush_dcache_page(page);
+	pgd = pgd_offset(mm, address);
+
+	spin_lock(&mm->page_table_lock);
+	pud = pud_alloc(mm, pgd, address);
+	if (!pud)
+		goto out;
+	pmd = pmd_alloc(mm, pud, address);
+	if (!pmd)
+		goto out;
+	pte = pte_alloc_map(mm, pmd, address);
+	if (!pte)
+		goto out;
+	if (!pte_none(*pte)) {
+		pte_unmap(pte);
+		goto out;
+	}
+	inc_mm_counter(mm, rss);
+	lru_cache_add_active(page);
+	set_pte_at(mm, address, pte, pte_mkdirty(pte_mkwrite(mk_pte(
+					page, vma->vm_page_prot))));
+	page_add_anon_rmap(page, vma, address);
+	pte_unmap(pte);
+	spin_unlock(&mm->page_table_lock);
+
+	/* no need for flush_tlb */
+	return;
+out:
+	spin_unlock(&mm->page_table_lock);
+out_sig:
+	__free_page(page);
+	force_sig(SIGKILL, current);
+}
+
+#define EXTRA_STACK_VM_PAGES	20	/* random */
+
+int setup_arg_pages(struct linux_binprm *bprm,
+		    unsigned long stack_top,
+		    int executable_stack)
+{
+	unsigned long stack_base;
+	struct vm_area_struct *mpnt;
+	struct mm_struct *mm = current->mm;
+	int i, ret;
+	long arg_size;
+
+#ifdef CONFIG_STACK_GROWSUP
+	/* Move the argument and environment strings to the bottom of the
+	 * stack space.
+	 */
+	int offset, j;
+	char *to, *from;
+
+	/* Start by shifting all the pages down */
+	i = 0;
+	for (j = 0; j < MAX_ARG_PAGES; j++) {
+		struct page *page = bprm->page[j];
+		if (!page)
+			continue;
+		bprm->page[i++] = page;
+	}
+
+	/* Now move them within their pages */
+	offset = bprm->p % PAGE_SIZE;
+	to = kmap(bprm->page[0]);
+	for (j = 1; j < i; j++) {
+		memmove(to, to + offset, PAGE_SIZE - offset);
+		from = kmap(bprm->page[j]);
+		memcpy(to + PAGE_SIZE - offset, from, offset);
+		kunmap(bprm->page[j - 1]);
+		to = from;
+	}
+	memmove(to, to + offset, PAGE_SIZE - offset);
+	kunmap(bprm->page[j - 1]);
+
+	/* Limit stack size to 1GB */
+	stack_base = current->signal->rlim[RLIMIT_STACK].rlim_max;
+	if (stack_base > (1 << 30))
+		stack_base = 1 << 30;
+	stack_base = PAGE_ALIGN(stack_top - stack_base);
+
+	/* Adjust bprm->p to point to the end of the strings. */
+	bprm->p = stack_base + PAGE_SIZE * i - offset;
+
+	mm->arg_start = stack_base;
+	arg_size = i << PAGE_SHIFT;
+
+	/* zero pages that were copied above */
+	while (i < MAX_ARG_PAGES)
+		bprm->page[i++] = NULL;
+#else
+	stack_base = arch_align_stack(stack_top - MAX_ARG_PAGES*PAGE_SIZE);
+	stack_base = PAGE_ALIGN(stack_base);
+	bprm->p += stack_base;
+	mm->arg_start = bprm->p;
+	arg_size = stack_top - (PAGE_MASK & (unsigned long) mm->arg_start);
+#endif
+
+	arg_size += EXTRA_STACK_VM_PAGES * PAGE_SIZE;
+
+	if (bprm->loader)
+		bprm->loader += stack_base;
+	bprm->exec += stack_base;
+
+	mpnt = kmem_cache_alloc(vm_area_cachep, SLAB_KERNEL);
+	if (!mpnt)
+		return -ENOMEM;
+
+	if (security_vm_enough_memory(arg_size >> PAGE_SHIFT)) {
+		kmem_cache_free(vm_area_cachep, mpnt);
+		return -ENOMEM;
+	}
+
+	memset(mpnt, 0, sizeof(*mpnt));
+
+	down_write(&mm->mmap_sem);
+	{
+		mpnt->vm_mm = mm;
+#ifdef CONFIG_STACK_GROWSUP
+		mpnt->vm_start = stack_base;
+		mpnt->vm_end = stack_base + arg_size;
+#else
+		mpnt->vm_end = stack_top;
+		mpnt->vm_start = mpnt->vm_end - arg_size;
+#endif
+		/* Adjust stack execute permissions; explicitly enable
+		 * for EXSTACK_ENABLE_X, disable for EXSTACK_DISABLE_X
+		 * and leave alone (arch default) otherwise. */
+		if (unlikely(executable_stack == EXSTACK_ENABLE_X))
+			mpnt->vm_flags = VM_STACK_FLAGS |  VM_EXEC;
+		else if (executable_stack == EXSTACK_DISABLE_X)
+			mpnt->vm_flags = VM_STACK_FLAGS & ~VM_EXEC;
+		else
+			mpnt->vm_flags = VM_STACK_FLAGS;
+		mpnt->vm_flags |= mm->def_flags;
+		mpnt->vm_page_prot = protection_map[mpnt->vm_flags & 0x7];
+		if ((ret = insert_vm_struct(mm, mpnt))) {
+			up_write(&mm->mmap_sem);
+			kmem_cache_free(vm_area_cachep, mpnt);
+			return ret;
+		}
+		mm->stack_vm = mm->total_vm = vma_pages(mpnt);
+	}
+
+	for (i = 0 ; i < MAX_ARG_PAGES ; i++) {
+		struct page *page = bprm->page[i];
+		if (page) {
+			bprm->page[i] = NULL;
+			install_arg_page(mpnt, page, stack_base);
+		}
+		stack_base += PAGE_SIZE;
+	}
+	up_write(&mm->mmap_sem);
+	
+	return 0;
+}
+
+EXPORT_SYMBOL(setup_arg_pages);
+
+#define free_arg_pages(bprm) do { } while (0)
+
+#else
+
+static inline void free_arg_pages(struct linux_binprm *bprm)
+{
+	int i;
+
+	for (i = 0; i < MAX_ARG_PAGES; i++) {
+		if (bprm->page[i])
+			__free_page(bprm->page[i]);
+		bprm->page[i] = NULL;
+	}
+}
+
+#endif /* CONFIG_MMU */
+
+struct file *open_exec(const char *name)
+{
+	struct nameidata nd;
+	int err;
+	struct file *file;
+
+	nd.intent.open.flags = FMODE_READ;
+	err = path_lookup(name, LOOKUP_FOLLOW|LOOKUP_OPEN, &nd);
+	file = ERR_PTR(err);
+
+	if (!err) {
+		struct inode *inode = nd.dentry->d_inode;
+		file = ERR_PTR(-EACCES);
+		if (!(nd.mnt->mnt_flags & MNT_NOEXEC) &&
+		    S_ISREG(inode->i_mode)) {
+			int err = permission(inode, MAY_EXEC, &nd);
+			if (!err && !(inode->i_mode & 0111))
+				err = -EACCES;
+			file = ERR_PTR(err);
+			if (!err) {
+				file = dentry_open(nd.dentry, nd.mnt, O_RDONLY);
+				if (!IS_ERR(file)) {
+					err = deny_write_access(file);
+					if (err) {
+						fput(file);
+						file = ERR_PTR(err);
+					}
+				}
+out:
+				return file;
+			}
+		}
+		path_release(&nd);
+	}
+	goto out;
+}
+
+EXPORT_SYMBOL(open_exec);
+
+int kernel_read(struct file *file, unsigned long offset,
+	char *addr, unsigned long count)
+{
+	mm_segment_t old_fs;
+	loff_t pos = offset;
+	int result;
+
+	old_fs = get_fs();
+	set_fs(get_ds());
+	/* The cast to a user pointer is valid due to the set_fs() */
+	result = vfs_read(file, (void __user *)addr, count, &pos);
+	set_fs(old_fs);
+	return result;
+}
+
+EXPORT_SYMBOL(kernel_read);
+
+static int exec_mmap(struct mm_struct *mm)
+{
+	struct task_struct *tsk;
+	struct mm_struct * old_mm, *active_mm;
+
+	/* Notify parent that we're no longer interested in the old VM */
+	tsk = current;
+	old_mm = current->mm;
+	mm_release(tsk, old_mm);
+
+	if (old_mm) {
+		/*
+		 * Make sure that if there is a core dump in progress
+		 * for the old mm, we get out and die instead of going
+		 * through with the exec.  We must hold mmap_sem around
+		 * checking core_waiters and changing tsk->mm.  The
+		 * core-inducing thread will increment core_waiters for
+		 * each thread whose ->mm == old_mm.
+		 */
+		down_read(&old_mm->mmap_sem);
+		if (unlikely(old_mm->core_waiters)) {
+			up_read(&old_mm->mmap_sem);
+			return -EINTR;
+		}
+	}
+	task_lock(tsk);
+	active_mm = tsk->active_mm;
+	tsk->mm = mm;
+	tsk->active_mm = mm;
+	activate_mm(active_mm, mm);
+	task_unlock(tsk);
+	arch_pick_mmap_layout(mm);
+	if (old_mm) {
+		up_read(&old_mm->mmap_sem);
+		if (active_mm != old_mm) BUG();
+		mmput(old_mm);
+		return 0;
+	}
+	mmdrop(active_mm);
+	return 0;
+}
+
+/*
+ * This function makes sure the current process has its own signal table,
+ * so that flush_signal_handlers can later reset the handlers without
+ * disturbing other processes.  (Other processes might share the signal
+ * table via the CLONE_SIGHAND option to clone().)
+ */
+static inline int de_thread(struct task_struct *tsk)
+{
+	struct signal_struct *sig = tsk->signal;
+	struct sighand_struct *newsighand, *oldsighand = tsk->sighand;
+	spinlock_t *lock = &oldsighand->siglock;
+	int count;
+
+	/*
+	 * If we don't share sighandlers, then we aren't sharing anything
+	 * and we can just re-use it all.
+	 */
+	if (atomic_read(&oldsighand->count) <= 1) {
+		BUG_ON(atomic_read(&sig->count) != 1);
+		exit_itimers(sig);
+		return 0;
+	}
+
+	newsighand = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);
+	if (!newsighand)
+		return -ENOMEM;
+
+	if (thread_group_empty(current))
+		goto no_thread_group;
+
+	/*
+	 * Kill all other threads in the thread group.
+	 * We must hold tasklist_lock to call zap_other_threads.
+	 */
+	read_lock(&tasklist_lock);
+	spin_lock_irq(lock);
+	if (sig->flags & SIGNAL_GROUP_EXIT) {
+		/*
+		 * Another group action in progress, just
+		 * return so that the signal is processed.
+		 */
+		spin_unlock_irq(lock);
+		read_unlock(&tasklist_lock);
+		kmem_cache_free(sighand_cachep, newsighand);
+		return -EAGAIN;
+	}
+	zap_other_threads(current);
+	read_unlock(&tasklist_lock);
+
+	/*
+	 * Account for the thread group leader hanging around:
+	 */
+	count = 2;
+	if (thread_group_leader(current))
+		count = 1;
+	while (atomic_read(&sig->count) > count) {
+		sig->group_exit_task = current;
+		sig->notify_count = count;
+		__set_current_state(TASK_UNINTERRUPTIBLE);
+		spin_unlock_irq(lock);
+		schedule();
+		spin_lock_irq(lock);
+	}
+	sig->group_exit_task = NULL;
+	sig->notify_count = 0;
+	spin_unlock_irq(lock);
+
+	/*
+	 * At this point all other threads have exited, all we have to
+	 * do is to wait for the thread group leader to become inactive,
+	 * and to assume its PID:
+	 */
+	if (!thread_group_leader(current)) {
+		struct task_struct *leader = current->group_leader, *parent;
+		struct dentry *proc_dentry1, *proc_dentry2;
+		unsigned long exit_state, ptrace;
+
+		/*
+		 * Wait for the thread group leader to be a zombie.
+		 * It should already be zombie at this point, most
+		 * of the time.
+		 */
+		while (leader->exit_state != EXIT_ZOMBIE)
+			yield();
+
+		spin_lock(&leader->proc_lock);
+		spin_lock(&current->proc_lock);
+		proc_dentry1 = proc_pid_unhash(current);
+		proc_dentry2 = proc_pid_unhash(leader);
+		write_lock_irq(&tasklist_lock);
+
+		if (leader->tgid != current->tgid)
+			BUG();
+		if (current->pid == current->tgid)
+			BUG();
+		/*
+		 * An exec() starts a new thread group with the
+		 * TGID of the previous thread group. Rehash the
+		 * two threads with a switched PID, and release
+		 * the former thread group leader:
+		 */
+		ptrace = leader->ptrace;
+		parent = leader->parent;
+		if (unlikely(ptrace) && unlikely(parent == current)) {
+			/*
+			 * Joker was ptracing his own group leader,
+			 * and now he wants to be his own parent!
+			 * We can't have that.
+			 */
+			ptrace = 0;
+		}
+
+		ptrace_unlink(current);
+		ptrace_unlink(leader);
+		remove_parent(current);
+		remove_parent(leader);
+
+		switch_exec_pids(leader, current);
+
+		current->parent = current->real_parent = leader->real_parent;
+		leader->parent = leader->real_parent = child_reaper;
+		current->group_leader = current;
+		leader->group_leader = leader;
+
+		add_parent(current, current->parent);
+		add_parent(leader, leader->parent);
+		if (ptrace) {
+			current->ptrace = ptrace;
+			__ptrace_link(current, parent);
+		}
+
+		list_del(&current->tasks);
+		list_add_tail(&current->tasks, &init_task.tasks);
+		current->exit_signal = SIGCHLD;
+		exit_state = leader->exit_state;
+
+		write_unlock_irq(&tasklist_lock);
+		spin_unlock(&leader->proc_lock);
+		spin_unlock(&current->proc_lock);
+		proc_pid_flush(proc_dentry1);
+		proc_pid_flush(proc_dentry2);
+
+		if (exit_state != EXIT_ZOMBIE)
+			BUG();
+		release_task(leader);
+        }
+
+	/*
+	 * Now there are really no other threads at all,
+	 * so it's safe to stop telling them to kill themselves.
+	 */
+	sig->flags = 0;
+
+no_thread_group:
+	BUG_ON(atomic_read(&sig->count) != 1);
+	exit_itimers(sig);
+
+	if (atomic_read(&oldsighand->count) == 1) {
+		/*
+		 * Now that we nuked the rest of the thread group,
+		 * it turns out we are not sharing sighand any more either.
+		 * So we can just keep it.
+		 */
+		kmem_cache_free(sighand_cachep, newsighand);
+	} else {
+		/*
+		 * Move our state over to newsighand and switch it in.
+		 */
+		spin_lock_init(&newsighand->siglock);
+		atomic_set(&newsighand->count, 1);
+		memcpy(newsighand->action, oldsighand->action,
+		       sizeof(newsighand->action));
+
+		write_lock_irq(&tasklist_lock);
+		spin_lock(&oldsighand->siglock);
+		spin_lock(&newsighand->siglock);
+
+		current->sighand = newsighand;
+		recalc_sigpending();
+
+		spin_unlock(&newsighand->siglock);
+		spin_unlock(&oldsighand->siglock);
+		write_unlock_irq(&tasklist_lock);
+
+		if (atomic_dec_and_test(&oldsighand->count))
+			kmem_cache_free(sighand_cachep, oldsighand);
+	}
+
+	if (!thread_group_empty(current))
+		BUG();
+	if (!thread_group_leader(current))
+		BUG();
+	return 0;
+}
+	
+/*
+ * These functions flushes out all traces of the currently running executable
+ * so that a new one can be started
+ */
+
+static inline void flush_old_files(struct files_struct * files)
+{
+	long j = -1;
+
+	spin_lock(&files->file_lock);
+	for (;;) {
+		unsigned long set, i;
+
+		j++;
+		i = j * __NFDBITS;
+		if (i >= files->max_fds || i >= files->max_fdset)
+			break;
+		set = files->close_on_exec->fds_bits[j];
+		if (!set)
+			continue;
+		files->close_on_exec->fds_bits[j] = 0;
+		spin_unlock(&files->file_lock);
+		for ( ; set ; i++,set >>= 1) {
+			if (set & 1) {
+				sys_close(i);
+			}
+		}
+		spin_lock(&files->file_lock);
+
+	}
+	spin_unlock(&files->file_lock);
+}
+
+void get_task_comm(char *buf, struct task_struct *tsk)
+{
+	/* buf must be at least sizeof(tsk->comm) in size */
+	task_lock(tsk);
+	strncpy(buf, tsk->comm, sizeof(tsk->comm));
+	task_unlock(tsk);
+}
+
+void set_task_comm(struct task_struct *tsk, char *buf)
+{
+	task_lock(tsk);
+	strlcpy(tsk->comm, buf, sizeof(tsk->comm));
+	task_unlock(tsk);
+}
+
+int flush_old_exec(struct linux_binprm * bprm)
+{
+	char * name;
+	int i, ch, retval;
+	struct files_struct *files;
+	char tcomm[sizeof(current->comm)];
+
+	/*
+	 * Make sure we have a private signal table and that
+	 * we are unassociated from the previous thread group.
+	 */
+	retval = de_thread(current);
+	if (retval)
+		goto out;
+
+	/*
+	 * Make sure we have private file handles. Ask the
+	 * fork helper to do the work for us and the exit
+	 * helper to do the cleanup of the old one.
+	 */
+	files = current->files;		/* refcounted so safe to hold */
+	retval = unshare_files();
+	if (retval)
+		goto out;
+	/*
+	 * Release all of the old mmap stuff
+	 */
+	retval = exec_mmap(bprm->mm);
+	if (retval)
+		goto mmap_failed;
+
+	bprm->mm = NULL;		/* We're using it now */
+
+	/* This is the point of no return */
+	steal_locks(files);
+	put_files_struct(files);
+
+	current->sas_ss_sp = current->sas_ss_size = 0;
+
+	if (current->euid == current->uid && current->egid == current->gid)
+		current->mm->dumpable = 1;
+	name = bprm->filename;
+	for (i=0; (ch = *(name++)) != '\0';) {
+		if (ch == '/')
+			i = 0;
+		else
+			if (i < (sizeof(tcomm) - 1))
+				tcomm[i++] = ch;
+	}
+	tcomm[i] = '\0';
+	set_task_comm(current, tcomm);
+
+	current->flags &= ~PF_RANDOMIZE;
+	flush_thread();
+
+	if (bprm->e_uid != current->euid || bprm->e_gid != current->egid || 
+	    permission(bprm->file->f_dentry->d_inode,MAY_READ, NULL) ||
+	    (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)) {
+		suid_keys(current);
+		current->mm->dumpable = 0;
+	}
+
+	/* An exec changes our domain. We are no longer part of the thread
+	   group */
+
+	current->self_exec_id++;
+			
+	flush_signal_handlers(current, 0);
+	flush_old_files(current->files);
+
+	return 0;
+
+mmap_failed:
+	put_files_struct(current->files);
+	current->files = files;
+out:
+	return retval;
+}
+
+EXPORT_SYMBOL(flush_old_exec);
+
+/* 
+ * Fill the binprm structure from the inode. 
+ * Check permissions, then read the first 128 (BINPRM_BUF_SIZE) bytes
+ */
+int prepare_binprm(struct linux_binprm *bprm)
+{
+	int mode;
+	struct inode * inode = bprm->file->f_dentry->d_inode;
+	int retval;
+
+	mode = inode->i_mode;
+	/*
+	 * Check execute perms again - if the caller has CAP_DAC_OVERRIDE,
+	 * generic_permission lets a non-executable through
+	 */
+	if (!(mode & 0111))	/* with at least _one_ execute bit set */
+		return -EACCES;
+	if (bprm->file->f_op == NULL)
+		return -EACCES;
+
+	bprm->e_uid = current->euid;
+	bprm->e_gid = current->egid;
+
+	if(!(bprm->file->f_vfsmnt->mnt_flags & MNT_NOSUID)) {
+		/* Set-uid? */
+		if (mode & S_ISUID) {
+			current->personality &= ~PER_CLEAR_ON_SETID;
+			bprm->e_uid = inode->i_uid;
+		}
+
+		/* Set-gid? */
+		/*
+		 * If setgid is set but no group execute bit then this
+		 * is a candidate for mandatory locking, not a setgid
+		 * executable.
+		 */
+		if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP)) {
+			current->personality &= ~PER_CLEAR_ON_SETID;
+			bprm->e_gid = inode->i_gid;
+		}
+	}
+
+	/* fill in binprm security blob */
+	retval = security_bprm_set(bprm);
+	if (retval)
+		return retval;
+
+	memset(bprm->buf,0,BINPRM_BUF_SIZE);
+	return kernel_read(bprm->file,0,bprm->buf,BINPRM_BUF_SIZE);
+}
+
+EXPORT_SYMBOL(prepare_binprm);
+
+static inline int unsafe_exec(struct task_struct *p)
+{
+	int unsafe = 0;
+	if (p->ptrace & PT_PTRACED) {
+		if (p->ptrace & PT_PTRACE_CAP)
+			unsafe |= LSM_UNSAFE_PTRACE_CAP;
+		else
+			unsafe |= LSM_UNSAFE_PTRACE;
+	}
+	if (atomic_read(&p->fs->count) > 1 ||
+	    atomic_read(&p->files->count) > 1 ||
+	    atomic_read(&p->sighand->count) > 1)
+		unsafe |= LSM_UNSAFE_SHARE;
+
+	return unsafe;
+}
+
+void compute_creds(struct linux_binprm *bprm)
+{
+	int unsafe;
+
+	if (bprm->e_uid != current->uid)
+		suid_keys(current);
+	exec_keys(current);
+
+	task_lock(current);
+	unsafe = unsafe_exec(current);
+	security_bprm_apply_creds(bprm, unsafe);
+	task_unlock(current);
+	security_bprm_post_apply_creds(bprm);
+}
+
+EXPORT_SYMBOL(compute_creds);
+
+void remove_arg_zero(struct linux_binprm *bprm)
+{
+	if (bprm->argc) {
+		unsigned long offset;
+		char * kaddr;
+		struct page *page;
+
+		offset = bprm->p % PAGE_SIZE;
+		goto inside;
+
+		while (bprm->p++, *(kaddr+offset++)) {
+			if (offset != PAGE_SIZE)
+				continue;
+			offset = 0;
+			kunmap_atomic(kaddr, KM_USER0);
+inside:
+			page = bprm->page[bprm->p/PAGE_SIZE];
+			kaddr = kmap_atomic(page, KM_USER0);
+		}
+		kunmap_atomic(kaddr, KM_USER0);
+		bprm->argc--;
+	}
+}
+
+EXPORT_SYMBOL(remove_arg_zero);
+
+/*
+ * cycle the list of binary formats handler, until one recognizes the image
+ */
+int search_binary_handler(struct linux_binprm *bprm,struct pt_regs *regs)
+{
+	int try,retval;
+	struct linux_binfmt *fmt;
+#ifdef __alpha__
+	/* handle /sbin/loader.. */
+	{
+	    struct exec * eh = (struct exec *) bprm->buf;
+
+	    if (!bprm->loader && eh->fh.f_magic == 0x183 &&
+		(eh->fh.f_flags & 0x3000) == 0x3000)
+	    {
+		struct file * file;
+		unsigned long loader;
+
+		allow_write_access(bprm->file);
+		fput(bprm->file);
+		bprm->file = NULL;
+
+	        loader = PAGE_SIZE*MAX_ARG_PAGES-sizeof(void *);
+
+		file = open_exec("/sbin/loader");
+		retval = PTR_ERR(file);
+		if (IS_ERR(file))
+			return retval;
+
+		/* Remember if the application is TASO.  */
+		bprm->sh_bang = eh->ah.entry < 0x100000000UL;
+
+		bprm->file = file;
+		bprm->loader = loader;
+		retval = prepare_binprm(bprm);
+		if (retval<0)
+			return retval;
+		/* should call search_binary_handler recursively here,
+		   but it does not matter */
+	    }
+	}
+#endif
+	retval = security_bprm_check(bprm);
+	if (retval)
+		return retval;
+
+	/* kernel module loader fixup */
+	/* so we don't try to load run modprobe in kernel space. */
+	set_fs(USER_DS);
+	retval = -ENOENT;
+	for (try=0; try<2; try++) {
+		read_lock(&binfmt_lock);
+		for (fmt = formats ; fmt ; fmt = fmt->next) {
+			int (*fn)(struct linux_binprm *, struct pt_regs *) = fmt->load_binary;
+			if (!fn)
+				continue;
+			if (!try_module_get(fmt->module))
+				continue;
+			read_unlock(&binfmt_lock);
+			retval = fn(bprm, regs);
+			if (retval >= 0) {
+				put_binfmt(fmt);
+				allow_write_access(bprm->file);
+				if (bprm->file)
+					fput(bprm->file);
+				bprm->file = NULL;
+				current->did_exec = 1;
+				return retval;
+			}
+			read_lock(&binfmt_lock);
+			put_binfmt(fmt);
+			if (retval != -ENOEXEC || bprm->mm == NULL)
+				break;
+			if (!bprm->file) {
+				read_unlock(&binfmt_lock);
+				return retval;
+			}
+		}
+		read_unlock(&binfmt_lock);
+		if (retval != -ENOEXEC || bprm->mm == NULL) {
+			break;
+#ifdef CONFIG_KMOD
+		}else{
+#define printable(c) (((c)=='\t') || ((c)=='\n') || (0x20<=(c) && (c)<=0x7e))
+			if (printable(bprm->buf[0]) &&
+			    printable(bprm->buf[1]) &&
+			    printable(bprm->buf[2]) &&
+			    printable(bprm->buf[3]))
+				break; /* -ENOEXEC */
+			request_module("binfmt-%04x", *(unsigned short *)(&bprm->buf[2]));
+#endif
+		}
+	}
+	return retval;
+}
+
+EXPORT_SYMBOL(search_binary_handler);
+
+/*
+ * sys_execve() executes a new program.
+ */
+int do_execve(char * filename,
+	char __user *__user *argv,
+	char __user *__user *envp,
+	struct pt_regs * regs)
+{
+	struct linux_binprm *bprm;
+	struct file *file;
+	int retval;
+	int i;
+
+	retval = -ENOMEM;
+	bprm = kmalloc(sizeof(*bprm), GFP_KERNEL);
+	if (!bprm)
+		goto out_ret;
+	memset(bprm, 0, sizeof(*bprm));
+
+	file = open_exec(filename);
+	retval = PTR_ERR(file);
+	if (IS_ERR(file))
+		goto out_kfree;
+
+	sched_exec();
+
+	bprm->p = PAGE_SIZE*MAX_ARG_PAGES-sizeof(void *);
+
+	bprm->file = file;
+	bprm->filename = filename;
+	bprm->interp = filename;
+	bprm->mm = mm_alloc();
+	retval = -ENOMEM;
+	if (!bprm->mm)
+		goto out_file;
+
+	retval = init_new_context(current, bprm->mm);
+	if (retval < 0)
+		goto out_mm;
+
+	bprm->argc = count(argv, bprm->p / sizeof(void *));
+	if ((retval = bprm->argc) < 0)
+		goto out_mm;
+
+	bprm->envc = count(envp, bprm->p / sizeof(void *));
+	if ((retval = bprm->envc) < 0)
+		goto out_mm;
+
+	retval = security_bprm_alloc(bprm);
+	if (retval)
+		goto out;
+
+	retval = prepare_binprm(bprm);
+	if (retval < 0)
+		goto out;
+
+	retval = copy_strings_kernel(1, &bprm->filename, bprm);
+	if (retval < 0)
+		goto out;
+
+	bprm->exec = bprm->p;
+	retval = copy_strings(bprm->envc, envp, bprm);
+	if (retval < 0)
+		goto out;
+
+	retval = copy_strings(bprm->argc, argv, bprm);
+	if (retval < 0)
+		goto out;
+
+	retval = search_binary_handler(bprm,regs);
+	if (retval >= 0) {
+		free_arg_pages(bprm);
+
+		/* execve success */
+		security_bprm_free(bprm);
+		acct_update_integrals(current);
+		update_mem_hiwater(current);
+		kfree(bprm);
+		return retval;
+	}
+
+out:
+	/* Something went wrong, return the inode and free the argument pages*/
+	for (i = 0 ; i < MAX_ARG_PAGES ; i++) {
+		struct page * page = bprm->page[i];
+		if (page)
+			__free_page(page);
+	}
+
+	if (bprm->security)
+		security_bprm_free(bprm);
+
+out_mm:
+	if (bprm->mm)
+		mmdrop(bprm->mm);
+
+out_file:
+	if (bprm->file) {
+		allow_write_access(bprm->file);
+		fput(bprm->file);
+	}
+
+out_kfree:
+	kfree(bprm);
+
+out_ret:
+	return retval;
+}
+
+int set_binfmt(struct linux_binfmt *new)
+{
+	struct linux_binfmt *old = current->binfmt;
+
+	if (new) {
+		if (!try_module_get(new->module))
+			return -1;
+	}
+	current->binfmt = new;
+	if (old)
+		module_put(old->module);
+	return 0;
+}
+
+EXPORT_SYMBOL(set_binfmt);
+
+#define CORENAME_MAX_SIZE 64
+
+/* format_corename will inspect the pattern parameter, and output a
+ * name into corename, which must have space for at least
+ * CORENAME_MAX_SIZE bytes plus one byte for the zero terminator.
+ */
+static void format_corename(char *corename, const char *pattern, long signr)
+{
+	const char *pat_ptr = pattern;
+	char *out_ptr = corename;
+	char *const out_end = corename + CORENAME_MAX_SIZE;
+	int rc;
+	int pid_in_pattern = 0;
+
+	/* Repeat as long as we have more pattern to process and more output
+	   space */
+	while (*pat_ptr) {
+		if (*pat_ptr != '%') {
+			if (out_ptr == out_end)
+				goto out;
+			*out_ptr++ = *pat_ptr++;
+		} else {
+			switch (*++pat_ptr) {
+			case 0:
+				goto out;
+			/* Double percent, output one percent */
+			case '%':
+				if (out_ptr == out_end)
+					goto out;
+				*out_ptr++ = '%';
+				break;
+			/* pid */
+			case 'p':
+				pid_in_pattern = 1;
+				rc = snprintf(out_ptr, out_end - out_ptr,
+					      "%d", current->tgid);
+				if (rc > out_end - out_ptr)
+					goto out;
+				out_ptr += rc;
+				break;
+			/* uid */
+			case 'u':
+				rc = snprintf(out_ptr, out_end - out_ptr,
+					      "%d", current->uid);
+				if (rc > out_end - out_ptr)
+					goto out;
+				out_ptr += rc;
+				break;
+			/* gid */
+			case 'g':
+				rc = snprintf(out_ptr, out_end - out_ptr,
+					      "%d", current->gid);
+				if (rc > out_end - out_ptr)
+					goto out;
+				out_ptr += rc;
+				break;
+			/* signal that caused the coredump */
+			case 's':
+				rc = snprintf(out_ptr, out_end - out_ptr,
+					      "%ld", signr);
+				if (rc > out_end - out_ptr)
+					goto out;
+				out_ptr += rc;
+				break;
+			/* UNIX time of coredump */
+			case 't': {
+				struct timeval tv;
+				do_gettimeofday(&tv);
+				rc = snprintf(out_ptr, out_end - out_ptr,
+					      "%lu", tv.tv_sec);
+				if (rc > out_end - out_ptr)
+					goto out;
+				out_ptr += rc;
+				break;
+			}
+			/* hostname */
+			case 'h':
+				down_read(&uts_sem);
+				rc = snprintf(out_ptr, out_end - out_ptr,
+					      "%s", system_utsname.nodename);
+				up_read(&uts_sem);
+				if (rc > out_end - out_ptr)
+					goto out;
+				out_ptr += rc;
+				break;
+			/* executable */
+			case 'e':
+				rc = snprintf(out_ptr, out_end - out_ptr,
+					      "%s", current->comm);
+				if (rc > out_end - out_ptr)
+					goto out;
+				out_ptr += rc;
+				break;
+			default:
+				break;
+			}
+			++pat_ptr;
+		}
+	}
+	/* Backward compatibility with core_uses_pid:
+	 *
+	 * If core_pattern does not include a %p (as is the default)
+	 * and core_uses_pid is set, then .%pid will be appended to
+	 * the filename */
+	if (!pid_in_pattern
+            && (core_uses_pid || atomic_read(&current->mm->mm_users) != 1)) {
+		rc = snprintf(out_ptr, out_end - out_ptr,
+			      ".%d", current->tgid);
+		if (rc > out_end - out_ptr)
+			goto out;
+		out_ptr += rc;
+	}
+      out:
+	*out_ptr = 0;
+}
+
+static void zap_threads (struct mm_struct *mm)
+{
+	struct task_struct *g, *p;
+	struct task_struct *tsk = current;
+	struct completion *vfork_done = tsk->vfork_done;
+	int traced = 0;
+
+	/*
+	 * Make sure nobody is waiting for us to release the VM,
+	 * otherwise we can deadlock when we wait on each other
+	 */
+	if (vfork_done) {
+		tsk->vfork_done = NULL;
+		complete(vfork_done);
+	}
+
+	read_lock(&tasklist_lock);
+	do_each_thread(g,p)
+		if (mm == p->mm && p != tsk) {
+			force_sig_specific(SIGKILL, p);
+			mm->core_waiters++;
+			if (unlikely(p->ptrace) &&
+			    unlikely(p->parent->mm == mm))
+				traced = 1;
+		}
+	while_each_thread(g,p);
+
+	read_unlock(&tasklist_lock);
+
+	if (unlikely(traced)) {
+		/*
+		 * We are zapping a thread and the thread it ptraces.
+		 * If the tracee went into a ptrace stop for exit tracing,
+		 * we could deadlock since the tracer is waiting for this
+		 * coredump to finish.  Detach them so they can both die.
+		 */
+		write_lock_irq(&tasklist_lock);
+		do_each_thread(g,p) {
+			if (mm == p->mm && p != tsk &&
+			    p->ptrace && p->parent->mm == mm) {
+				__ptrace_unlink(p);
+			}
+		} while_each_thread(g,p);
+		write_unlock_irq(&tasklist_lock);
+	}
+}
+
+static void coredump_wait(struct mm_struct *mm)
+{
+	DECLARE_COMPLETION(startup_done);
+
+	mm->core_waiters++; /* let other threads block */
+	mm->core_startup_done = &startup_done;
+
+	/* give other threads a chance to run: */
+	yield();
+
+	zap_threads(mm);
+	if (--mm->core_waiters) {
+		up_write(&mm->mmap_sem);
+		wait_for_completion(&startup_done);
+	} else
+		up_write(&mm->mmap_sem);
+	BUG_ON(mm->core_waiters);
+}
+
+int do_coredump(long signr, int exit_code, struct pt_regs * regs)
+{
+	char corename[CORENAME_MAX_SIZE + 1];
+	struct mm_struct *mm = current->mm;
+	struct linux_binfmt * binfmt;
+	struct inode * inode;
+	struct file * file;
+	int retval = 0;
+
+	binfmt = current->binfmt;
+	if (!binfmt || !binfmt->core_dump)
+		goto fail;
+	down_write(&mm->mmap_sem);
+	if (!mm->dumpable) {
+		up_write(&mm->mmap_sem);
+		goto fail;
+	}
+	mm->dumpable = 0;
+	init_completion(&mm->core_done);
+	spin_lock_irq(&current->sighand->siglock);
+	current->signal->flags = SIGNAL_GROUP_EXIT;
+	current->signal->group_exit_code = exit_code;
+	spin_unlock_irq(&current->sighand->siglock);
+	coredump_wait(mm);
+
+	/*
+	 * Clear any false indication of pending signals that might
+	 * be seen by the filesystem code called to write the core file.
+	 */
+	current->signal->group_stop_count = 0;
+	clear_thread_flag(TIF_SIGPENDING);
+
+	if (current->signal->rlim[RLIMIT_CORE].rlim_cur < binfmt->min_coredump)
+		goto fail_unlock;
+
+	/*
+	 * lock_kernel() because format_corename() is controlled by sysctl, which
+	 * uses lock_kernel()
+	 */
+ 	lock_kernel();
+	format_corename(corename, core_pattern, signr);
+	unlock_kernel();
+	file = filp_open(corename, O_CREAT | 2 | O_NOFOLLOW | O_LARGEFILE, 0600);
+	if (IS_ERR(file))
+		goto fail_unlock;
+	inode = file->f_dentry->d_inode;
+	if (inode->i_nlink > 1)
+		goto close_fail;	/* multiple links - don't dump */
+	if (d_unhashed(file->f_dentry))
+		goto close_fail;
+
+	if (!S_ISREG(inode->i_mode))
+		goto close_fail;
+	if (!file->f_op)
+		goto close_fail;
+	if (!file->f_op->write)
+		goto close_fail;
+	if (do_truncate(file->f_dentry, 0) != 0)
+		goto close_fail;
+
+	retval = binfmt->core_dump(signr, regs, file);
+
+	if (retval)
+		current->signal->group_exit_code |= 0x80;
+close_fail:
+	filp_close(file, NULL);
+fail_unlock:
+	complete_all(&mm->core_done);
+fail:
+	return retval;
+}
