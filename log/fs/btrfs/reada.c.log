commit 32da5386d9a4fd5c1155cecf703df104d918954c
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 29 19:20:18 2019 +0100

    btrfs: rename btrfs_block_group_cache
    
    The type name is misleading, a single entry is named 'cache' while this
    normally means a collection of objects. Rename that everywhere. Also the
    identifier was quite long, making function prototypes harder to format.
    
    Suggested-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 907c5d79a197..243a2e44526e 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -227,7 +227,7 @@ static struct reada_zone *reada_find_zone(struct btrfs_device *dev, u64 logical,
 	struct btrfs_fs_info *fs_info = dev->fs_info;
 	int ret;
 	struct reada_zone *zone;
-	struct btrfs_block_group_cache *cache = NULL;
+	struct btrfs_block_group *cache = NULL;
 	u64 start;
 	u64 end;
 	int i;

commit b3470b5dbe1300dea94191ae4b7d070be9a5cdc9
Author: David Sterba <dsterba@suse.com>
Date:   Wed Oct 23 18:48:22 2019 +0200

    btrfs: add dedicated members for start and length of a block group
    
    The on-disk format of block group item makes use of the key that stores
    the offset and length. This is further used in the code, although this
    makes thing harder to understand. The key is also packed so the
    offset/length is not properly aligned as u64.
    
    Add start (key.objectid) and length (key.offset) members to block group
    and remove the embedded key.  When the item is searched or written, a
    local variable for key is used.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 1feaeadc8cf5..907c5d79a197 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -248,8 +248,8 @@ static struct reada_zone *reada_find_zone(struct btrfs_device *dev, u64 logical,
 	if (!cache)
 		return NULL;
 
-	start = cache->key.objectid;
-	end = start + cache->key.offset - 1;
+	start = cache->start;
+	end = start + cache->length - 1;
 	btrfs_put_block_group(cache);
 
 	zone = kzalloc(sizeof(*zone), GFP_KERNEL);

commit a0cac0ec961f0d42828eeef196ac2246a2f07659
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Sep 16 11:30:57 2019 -0700

    btrfs: get rid of unique workqueue helper functions
    
    Commit 9e0af2376434 ("Btrfs: fix task hang under heavy compressed
    write") worked around the issue that a recycled work item could get a
    false dependency on the original work item due to how the workqueue code
    guarantees non-reentrancy. It did so by giving different work functions
    to different types of work.
    
    However, the fixes in the previous few patches are more complete, as
    they prevent a work item from being recycled at all (except for a tiny
    window that the kernel workqueue code handles for us). This obsoletes
    the previous fix, so we don't need the unique helpers for correctness.
    The only other reason to keep them would be so they show up in stack
    traces, but they always seem to be optimized to a tail call, so they
    don't show up anyways. So, let's just get rid of the extra indirection.
    
    While we're here, rename normal_work_helper() to the more informative
    btrfs_work_helper().
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index dd4f9c2b7107..1feaeadc8cf5 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -819,8 +819,7 @@ static void reada_start_machine(struct btrfs_fs_info *fs_info)
 		/* FIXME we cannot handle this properly right now */
 		BUG();
 	}
-	btrfs_init_work(&rmw->work, btrfs_readahead_helper,
-			reada_start_machine_worker, NULL, NULL);
+	btrfs_init_work(&rmw->work, reada_start_machine_worker, NULL, NULL);
 	rmw->fs_info = fs_info;
 
 	btrfs_queue_work(fs_info->readahead_workers, &rmw->work);

commit e732fe95e4cad35fc1df278c23a32903341b08b3
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Sep 16 11:30:55 2019 -0700

    btrfs: don't prematurely free work in reada_start_machine_worker()
    
    Currently, reada_start_machine_worker() frees the reada_machine_work and
    then calls __reada_start_machine() to do readahead. This is another
    potential instance of the bug in "btrfs: don't prematurely free work in
    run_ordered_work()".
    
    There _might_ already be a deadlock here: reada_start_machine_worker()
    can depend on itself through stacked filesystems (__read_start_machine()
    -> reada_start_machine_dev() -> reada_tree_block_flagged() ->
    read_extent_buffer_pages() -> submit_one_bio() ->
    btree_submit_bio_hook() -> btrfs_map_bio() -> submit_stripe_bio() ->
    submit_bio() onto a loop device can trigger readahead on the lower
    filesystem).
    
    Either way, let's fix it by freeing the work at the end.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index ee6f60547a8d..dd4f9c2b7107 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -752,21 +752,19 @@ static int reada_start_machine_dev(struct btrfs_device *dev)
 static void reada_start_machine_worker(struct btrfs_work *work)
 {
 	struct reada_machine_work *rmw;
-	struct btrfs_fs_info *fs_info;
 	int old_ioprio;
 
 	rmw = container_of(work, struct reada_machine_work, work);
-	fs_info = rmw->fs_info;
-
-	kfree(rmw);
 
 	old_ioprio = IOPRIO_PRIO_VALUE(task_nice_ioclass(current),
 				       task_nice_ioprio(current));
 	set_task_ioprio(current, BTRFS_IOPRIO_READA);
-	__reada_start_machine(fs_info);
+	__reada_start_machine(rmw->fs_info);
 	set_task_ioprio(current, old_ioprio);
 
-	atomic_dec(&fs_info->reada_works_cnt);
+	atomic_dec(&rmw->fs_info->reada_works_cnt);
+
+	kfree(rmw);
 }
 
 static void __reada_start_machine(struct btrfs_fs_info *fs_info)

commit 4f84bd7f99fb67475e17e1cdca412e5d14bd3f45
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Aug 21 16:38:15 2019 +0300

    btrfs: Make reada_tree_block_flagged private
    
    This function is used only for the readahead machinery. It makes no
    sense to keep it external to reada.c file. Place it above its sole
    caller and make it static. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 0b034c494355..ee6f60547a8d 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -639,6 +639,35 @@ static int reada_pick_zone(struct btrfs_device *dev)
 	return 1;
 }
 
+static int reada_tree_block_flagged(struct btrfs_fs_info *fs_info, u64 bytenr,
+				    int mirror_num, struct extent_buffer **eb)
+{
+	struct extent_buffer *buf = NULL;
+	int ret;
+
+	buf = btrfs_find_create_tree_block(fs_info, bytenr);
+	if (IS_ERR(buf))
+		return 0;
+
+	set_bit(EXTENT_BUFFER_READAHEAD, &buf->bflags);
+
+	ret = read_extent_buffer_pages(buf, WAIT_PAGE_LOCK, mirror_num);
+	if (ret) {
+		free_extent_buffer_stale(buf);
+		return ret;
+	}
+
+	if (test_bit(EXTENT_BUFFER_CORRUPT, &buf->bflags)) {
+		free_extent_buffer_stale(buf);
+		return -EIO;
+	} else if (extent_buffer_uptodate(buf)) {
+		*eb = buf;
+	} else {
+		free_extent_buffer(buf);
+	}
+	return 0;
+}
+
 static int reada_start_machine_dev(struct btrfs_device *dev)
 {
 	struct btrfs_fs_info *fs_info = dev->fs_info;

commit aac0023c2106952538414254960c51dcf0dc39e9
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:44 2019 -0400

    btrfs: move basic block_group definitions to their own header
    
    This is prep work for moving all of the block group cache code into its
    own file.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor comment updates ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index bb5bd49573b4..0b034c494355 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -14,6 +14,7 @@
 #include "disk-io.h"
 #include "transaction.h"
 #include "dev-replace.h"
+#include "block-group.h"
 
 #undef DEBUG
 

commit c4e0540d0ad49c8ceab06cceed1de27c4fe29f6e
Author: Naohiro Aota <naohiro.aota@wdc.com>
Date:   Thu Jun 6 16:54:44 2019 +0900

    btrfs: start readahead also in seed devices
    
    Currently, btrfs does not consult seed devices to start readahead. As a
    result, if readahead zone is added to the seed devices, btrfs_reada_wait()
    indefinitely wait for the reada_ctl to finish.
    
    You can reproduce the hung by modifying btrfs/163 to have larger initial
    file size (e.g. xfs_io pwrite 4M instead of current 256K).
    
    Fixes: 7414a03fbf9e ("btrfs: initial readahead code and prototypes")
    Cc: stable@vger.kernel.org # 3.2+: ce7791ffee1e: Btrfs: fix race between readahead and device replace/removal
    Cc: stable@vger.kernel.org # 3.2+
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Naohiro Aota <naohiro.aota@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 10d9589001a9..bb5bd49573b4 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -747,6 +747,7 @@ static void __reada_start_machine(struct btrfs_fs_info *fs_info)
 	u64 total = 0;
 	int i;
 
+again:
 	do {
 		enqueued = 0;
 		mutex_lock(&fs_devices->device_list_mutex);
@@ -758,6 +759,10 @@ static void __reada_start_machine(struct btrfs_fs_info *fs_info)
 		mutex_unlock(&fs_devices->device_list_mutex);
 		total += enqueued;
 	} while (enqueued && total < 10000);
+	if (fs_devices->seed) {
+		fs_devices = fs_devices->seed;
+		goto again;
+	}
 
 	if (enqueued == 0)
 		return;

commit cb5583dd52fab469a001a007385066fcd60629c5
Author: David Sterba <dsterba@suse.com>
Date:   Fri Sep 7 16:11:23 2018 +0200

    btrfs: dev-replace: open code trivial locking helpers
    
    The dev-replace locking functions are now trivial wrappers around rw
    semaphore that can be used directly everywhere. No functional change.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 6f81f3e88b6d..10d9589001a9 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -377,10 +377,10 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 	}
 
 	/* Insert extent in reada tree + all per-device trees, all or nothing */
-	btrfs_dev_replace_read_lock(&fs_info->dev_replace);
+	down_read(&fs_info->dev_replace.rwsem);
 	ret = radix_tree_preload(GFP_KERNEL);
 	if (ret) {
-		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
+		up_read(&fs_info->dev_replace.rwsem);
 		goto error;
 	}
 
@@ -391,13 +391,13 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 		re_exist->refcnt++;
 		spin_unlock(&fs_info->reada_lock);
 		radix_tree_preload_end();
-		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
+		up_read(&fs_info->dev_replace.rwsem);
 		goto error;
 	}
 	if (ret) {
 		spin_unlock(&fs_info->reada_lock);
 		radix_tree_preload_end();
-		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
+		up_read(&fs_info->dev_replace.rwsem);
 		goto error;
 	}
 	radix_tree_preload_end();
@@ -439,13 +439,13 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 			}
 			radix_tree_delete(&fs_info->reada_tree, index);
 			spin_unlock(&fs_info->reada_lock);
-			btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
+			up_read(&fs_info->dev_replace.rwsem);
 			goto error;
 		}
 		have_zone = 1;
 	}
 	spin_unlock(&fs_info->reada_lock);
-	btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
+	up_read(&fs_info->dev_replace.rwsem);
 
 	if (!have_zone)
 		goto error;

commit ceb21a8db48559fd0809e03c4df9eb37743d9170
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 24 19:35:04 2018 +0200

    btrfs: reada: reorder dev-replace locks before radix tree preload
    
    The device-replace read lock is going to use rw semaphore in followup
    commits. The semaphore might sleep which is not possible in the radix
    tree preload section. The lock nesting is now:
    
    * device replace
      * radix tree preload
        * readahead spinlock
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index dec14b739b10..6f81f3e88b6d 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -376,26 +376,28 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 		goto error;
 	}
 
+	/* Insert extent in reada tree + all per-device trees, all or nothing */
+	btrfs_dev_replace_read_lock(&fs_info->dev_replace);
 	ret = radix_tree_preload(GFP_KERNEL);
-	if (ret)
+	if (ret) {
+		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
 		goto error;
+	}
 
-	/* insert extent in reada_tree + all per-device trees, all or nothing */
-	btrfs_dev_replace_read_lock(&fs_info->dev_replace);
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_insert(&fs_info->reada_tree, index, re);
 	if (ret == -EEXIST) {
 		re_exist = radix_tree_lookup(&fs_info->reada_tree, index);
 		re_exist->refcnt++;
 		spin_unlock(&fs_info->reada_lock);
-		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
 		radix_tree_preload_end();
+		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
 		goto error;
 	}
 	if (ret) {
 		spin_unlock(&fs_info->reada_lock);
-		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
 		radix_tree_preload_end();
+		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
 		goto error;
 	}
 	radix_tree_preload_end();

commit d7f663fa3ff906247a979c1115bc92cbabfb19ba
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 29 10:56:47 2018 +0200

    btrfs: prune unused includes
    
    Remove includes if none of the interfaces and exports is used in the
    given source file.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 4be425f70c2d..dec14b739b10 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -7,7 +7,6 @@
 #include <linux/pagemap.h>
 #include <linux/writeback.h>
 #include <linux/blkdev.h>
-#include <linux/rbtree.h>
 #include <linux/slab.h>
 #include <linux/workqueue.h>
 #include "ctree.h"

commit bece2e8239331d382f98b381f90e425a11157653
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Wed Jun 20 10:03:31 2018 -0700

    btrfs: Fix misleading indentation reported by smatch
    
    This patch avoids that building the BTRFS source code with smatch
    triggers complaints about inconsistent indenting.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 40f1bcef394d..4be425f70c2d 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -355,7 +355,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 		dev = bbio->stripes[nzones].dev;
 
 		/* cannot read ahead on missing device. */
-		 if (!dev->bdev)
+		if (!dev->bdev)
 			continue;
 
 		zone = reada_find_zone(dev, logical, bbio);

commit c1d7c514f745628eb096c5cbb10737855879ae25
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:23:33 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- sources
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index a52dd12af648..40f1bcef394d 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -1,19 +1,6 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 2011 STRATO.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
 #include <linux/sched.h>

commit 7e79cb86be28ed8073870c22f479b3b1293ecb85
Author: David Sterba <dsterba@suse.com>
Date:   Sat Mar 24 02:11:38 2018 +0100

    btrfs: split dev-replace locking helpers for read and write
    
    The current calls are unclear in what way btrfs_dev_replace_lock takes
    the locks, so drop the argument, split the helpers and use similar
    naming as for read and write locks.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index ab852b8e3e37..a52dd12af648 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -395,20 +395,20 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 		goto error;
 
 	/* insert extent in reada_tree + all per-device trees, all or nothing */
-	btrfs_dev_replace_lock(&fs_info->dev_replace, 0);
+	btrfs_dev_replace_read_lock(&fs_info->dev_replace);
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_insert(&fs_info->reada_tree, index, re);
 	if (ret == -EEXIST) {
 		re_exist = radix_tree_lookup(&fs_info->reada_tree, index);
 		re_exist->refcnt++;
 		spin_unlock(&fs_info->reada_lock);
-		btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
+		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
 		radix_tree_preload_end();
 		goto error;
 	}
 	if (ret) {
 		spin_unlock(&fs_info->reada_lock);
-		btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
+		btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
 		radix_tree_preload_end();
 		goto error;
 	}
@@ -451,13 +451,13 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 			}
 			radix_tree_delete(&fs_info->reada_tree, index);
 			spin_unlock(&fs_info->reada_lock);
-			btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
+			btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
 			goto error;
 		}
 		have_zone = 1;
 	}
 	spin_unlock(&fs_info->reada_lock);
-	btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
+	btrfs_dev_replace_read_unlock(&fs_info->dev_replace);
 
 	if (!have_zone)
 		goto error;

commit 106204f191774d427a1992d76410d6d8a0006568
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 13 19:11:04 2017 +0200

    btrfs: remove unused member err from reada_extent
    
    Seems to be unused since the initial commit, we ignore readahead errors
    anyway, the full read will handle that if necessary.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index a17e775a4a89..ab852b8e3e37 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -66,7 +66,6 @@ struct reada_extctl {
 struct reada_extent {
 	u64			logical;
 	struct btrfs_key	top;
-	int			err;
 	struct list_head	extctl;
 	int 			refcnt;
 	spinlock_t		lock;

commit 994a5d2bc758792f1808d7b112990a14182ef847
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 15 16:39:59 2017 +0100

    btrfs: remove local blocksize variable in reada_find_extent
    
    The name is misleading and the local variable serves no purpose.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 5c1e6bbed132..a17e775a4a89 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -320,7 +320,6 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 	struct btrfs_bio *bbio = NULL;
 	struct btrfs_device *dev;
 	struct btrfs_device *prev_dev;
-	u32 blocksize;
 	u64 length;
 	int real_stripes;
 	int nzones = 0;
@@ -341,7 +340,6 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 	if (!re)
 		return NULL;
 
-	blocksize = fs_info->nodesize;
 	re->logical = logical;
 	re->top = *top;
 	INIT_LIST_HEAD(&re->extctl);
@@ -351,10 +349,10 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 	/*
 	 * map block
 	 */
-	length = blocksize;
+	length = fs_info->nodesize;
 	ret = btrfs_map_block(fs_info, BTRFS_MAP_GET_READ_MIRRORS, logical,
 			&length, &bbio, 0);
-	if (ret || !bbio || length < blocksize)
+	if (ret || !bbio || length < fs_info->nodesize)
 		goto error;
 
 	if (bbio->num_stripes > BTRFS_MAX_MIRRORS) {

commit 5721b8ad260f6ed15e3c82447981dd7a2f4bdf72
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 2 19:43:30 2017 +0100

    btrfs: remove redundant parameter from reada_start_machine_dev
    
    We can read fs_info from dev.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 2deba18886db..5c1e6bbed132 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -653,9 +653,9 @@ static int reada_pick_zone(struct btrfs_device *dev)
 	return 1;
 }
 
-static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
-				   struct btrfs_device *dev)
+static int reada_start_machine_dev(struct btrfs_device *dev)
 {
+	struct btrfs_fs_info *fs_info = dev->fs_info;
 	struct reada_extent *re = NULL;
 	int mirror_num = 0;
 	struct extent_buffer *eb = NULL;
@@ -768,8 +768,7 @@ static void __reada_start_machine(struct btrfs_fs_info *fs_info)
 		list_for_each_entry(device, &fs_devices->devices, dev_list) {
 			if (atomic_read(&device->reada_in_flight) <
 			    MAX_IN_FLIGHT)
-				enqueued += reada_start_machine_dev(fs_info,
-								    device);
+				enqueued += reada_start_machine_dev(device);
 		}
 		mutex_unlock(&fs_devices->device_list_mutex);
 		total += enqueued;

commit 0ceaf282137f261abf634f96b15c535baa6a9c93
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 2 19:43:30 2017 +0100

    btrfs: remove redundant parameter from reada_find_zone
    
    We can read fs_info from dev.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 306e5108aac7..2deba18886db 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -235,10 +235,10 @@ int btree_readahead_hook(struct extent_buffer *eb, int err)
 	return ret;
 }
 
-static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
-					  struct btrfs_device *dev, u64 logical,
+static struct reada_zone *reada_find_zone(struct btrfs_device *dev, u64 logical,
 					  struct btrfs_bio *bbio)
 {
+	struct btrfs_fs_info *fs_info = dev->fs_info;
 	int ret;
 	struct reada_zone *zone;
 	struct btrfs_block_group_cache *cache = NULL;
@@ -374,7 +374,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 		 if (!dev->bdev)
 			continue;
 
-		zone = reada_find_zone(fs_info, dev, logical, bbio);
+		zone = reada_find_zone(dev, logical, bbio);
 		if (!zone)
 			continue;
 

commit d48d71aa9977473b6515bb48933617a06cdc7be9
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 2 19:43:30 2017 +0100

    btrfs: remove redundant parameter from btree_readahead_hook
    
    We can read fs_info from eb.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index a7fa4a5cb296..306e5108aac7 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -209,9 +209,9 @@ static void __readahead_hook(struct btrfs_fs_info *fs_info,
 	return;
 }
 
-int btree_readahead_hook(struct btrfs_fs_info *fs_info,
-			 struct extent_buffer *eb, int err)
+int btree_readahead_hook(struct extent_buffer *eb, int err)
 {
+	struct btrfs_fs_info *fs_info = eb->fs_info;
 	int ret = 0;
 	struct reada_extent *re;
 

commit 7ef70b4d9987a78d39c4e40a02093493333e5408
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 2 18:54:52 2017 +0100

    btrfs: preallocate radix tree node for global readahead tree
    
    We can preallocate the node so insertion does not have to do that under
    the lock. The GFP flags for the global radix tree are initialized to
     GFP_NOFS & ~__GFP_DIRECT_RECLAIM
    but we can use GFP_KERNEL, because readahead is optional and not on any
    critical writeout path.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index fdae8ca79401..a7fa4a5cb296 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -393,6 +393,10 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 		goto error;
 	}
 
+	ret = radix_tree_preload(GFP_KERNEL);
+	if (ret)
+		goto error;
+
 	/* insert extent in reada_tree + all per-device trees, all or nothing */
 	btrfs_dev_replace_lock(&fs_info->dev_replace, 0);
 	spin_lock(&fs_info->reada_lock);
@@ -402,13 +406,16 @@ static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 		re_exist->refcnt++;
 		spin_unlock(&fs_info->reada_lock);
 		btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
+		radix_tree_preload_end();
 		goto error;
 	}
 	if (ret) {
 		spin_unlock(&fs_info->reada_lock);
 		btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
+		radix_tree_preload_end();
 		goto error;
 	}
+	radix_tree_preload_end();
 	prev_dev = NULL;
 	dev_replace_is_ongoing = btrfs_dev_replace_is_ongoing(
 			&fs_info->dev_replace);

commit cc8385b59e17d489814d54d6a846aba7051fdea5
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 2 18:54:52 2017 +0100

    btrfs: preallocate radix tree node for readahead
    
    We can preallocate the node so insertion does not have to do that under
    the lock. The GFP flags for the per-device radix tree are initialized to
     GFP_NOFS & ~__GFP_DIRECT_RECLAIM
    but we can use GFP_KERNEL, same as an allocation above anyway, but also
    because readahead is optional and not on any critical writeout path.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index e88bca87f5d2..fdae8ca79401 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -270,6 +270,12 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 	if (!zone)
 		return NULL;
 
+	ret = radix_tree_preload(GFP_KERNEL);
+	if (ret) {
+		kfree(zone);
+		return NULL;
+	}
+
 	zone->start = start;
 	zone->end = end;
 	INIT_LIST_HEAD(&zone->list);
@@ -299,6 +305,7 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 			zone = NULL;
 	}
 	spin_unlock(&fs_info->reada_lock);
+	radix_tree_preload_end();
 
 	return zone;
 }

commit 2ff7e61e0d30ff166a2ae94575526bffe11fd1a8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:24 2016 -0400

    btrfs: take an fs_info directly when the root is not used otherwise
    
    There are loads of functions in btrfs that accept a root parameter
    but only use it to obtain an fs_info pointer.  Let's convert those to
    just accept an fs_info pointer directly.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 8d36fb457594..e88bca87f5d2 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -303,14 +303,13 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 	return zone;
 }
 
-static struct reada_extent *reada_find_extent(struct btrfs_root *root,
+static struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,
 					      u64 logical,
 					      struct btrfs_key *top)
 {
 	int ret;
 	struct reada_extent *re = NULL;
 	struct reada_extent *re_exist = NULL;
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_bio *bbio = NULL;
 	struct btrfs_device *dev;
 	struct btrfs_device *prev_dev;
@@ -549,7 +548,7 @@ static int reada_add_block(struct reada_control *rc, u64 logical,
 	struct reada_extctl *rec;
 
 	/* takes one ref */
-	re = reada_find_extent(fs_info->tree_root, logical, top);
+	re = reada_find_extent(fs_info, logical, top);
 	if (!re)
 		return -1;
 
@@ -705,8 +704,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	logical = re->logical;
 
 	atomic_inc(&dev->reada_in_flight);
-	ret = reada_tree_block_flagged(fs_info->extent_root, logical,
-			mirror_num, &eb);
+	ret = reada_tree_block_flagged(fs_info, logical, mirror_num, &eb);
 	if (ret)
 		__readahead_hook(fs_info, re, NULL, ret);
 	else if (eb)

commit 0b246afa62b0cf5b09d078121f543135f28492ad
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:23 2016 -0400

    btrfs: root->fs_info cleanup, add fs_info convenience variables
    
    In routines where someptr->fs_info is referenced multiple times, we
    introduce a convenience variable.  This makes the code considerably
    more readable.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index c51292abbd03..8d36fb457594 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -335,7 +335,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	if (!re)
 		return NULL;
 
-	blocksize = root->fs_info->nodesize;
+	blocksize = fs_info->nodesize;
 	re->logical = logical;
 	re->top = *top;
 	INIT_LIST_HEAD(&re->extctl);
@@ -352,7 +352,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		goto error;
 
 	if (bbio->num_stripes > BTRFS_MAX_MIRRORS) {
-		btrfs_err(root->fs_info,
+		btrfs_err(fs_info,
 			   "readahead: more than %d copies not supported",
 			   BTRFS_MAX_MIRRORS);
 		goto error;
@@ -950,11 +950,10 @@ int btrfs_reada_wait(void *handle)
 			reada_start_machine(fs_info);
 		wait_event_timeout(rc->wait, atomic_read(&rc->elems) == 0,
 				   5 * HZ);
-		dump_devs(rc->root->fs_info,
-			  atomic_read(&rc->elems) < 10 ? 1 : 0);
+		dump_devs(fs_info, atomic_read(&rc->elems) < 10 ? 1 : 0);
 	}
 
-	dump_devs(rc->root->fs_info, atomic_read(&rc->elems) < 10 ? 1 : 0);
+	dump_devs(fs_info, atomic_read(&rc->elems) < 10 ? 1 : 0);
 
 	kref_put(&rc->refcnt, reada_control_release);
 

commit da17066c40472c2d6a1aab7bb0090c3d285531c9
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 09:22:56 2016 -0400

    btrfs: pull node/sector/stripe sizes out of root and into fs_info
    
    We track the node sizes per-root, but they never vary from the values
    in the superblock.  This patch messes with the 80-column style a bit,
    but subsequent patches to factor out root->fs_info into a convenience
    variable fix it up again.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 540e729975be..c51292abbd03 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -335,7 +335,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	if (!re)
 		return NULL;
 
-	blocksize = root->nodesize;
+	blocksize = root->fs_info->nodesize;
 	re->logical = logical;
 	re->top = *top;
 	INIT_LIST_HEAD(&re->extctl);
@@ -679,7 +679,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 		spin_unlock(&fs_info->reada_lock);
 		return 0;
 	}
-	dev->reada_next = re->logical + fs_info->tree_root->nodesize;
+	dev->reada_next = re->logical + fs_info->nodesize;
 	re->refcnt++;
 
 	spin_unlock(&fs_info->reada_lock);
@@ -843,7 +843,7 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 			if (ret == 0)
 				break;
 			pr_debug("  re: logical %llu size %u empty %d scheduled %d",
-				re->logical, fs_info->tree_root->nodesize,
+				re->logical, fs_info->nodesize,
 				list_empty(&re->extctl), re->scheduled);
 
 			for (i = 0; i < re->nzones; ++i) {
@@ -876,7 +876,7 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 			continue;
 		}
 		pr_debug("re: logical %llu size %u list empty %d scheduled %d",
-			re->logical, fs_info->tree_root->nodesize,
+			re->logical, fs_info->nodesize,
 			list_empty(&re->extctl), re->scheduled);
 		for (i = 0; i < re->nzones; ++i) {
 			pr_cont(" zone %llu-%llu devs",

commit c28f158e5ee78621ae693b8b18a9b89c7695af40
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:56:44 2016 -0400

    btrfs: struct reada_control.root -> reada_control.fs_info
    
    The root is never used.  We substitute extent_root in for the
    reada_find_extent call, since it's only ever used to obtain the node
    size.  This call site will be changed to use fs_info in a later patch.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index f0beb63a6d82..540e729975be 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -544,17 +544,18 @@ static void reada_control_release(struct kref *kref)
 static int reada_add_block(struct reada_control *rc, u64 logical,
 			   struct btrfs_key *top, u64 generation)
 {
-	struct btrfs_root *root = rc->root;
+	struct btrfs_fs_info *fs_info = rc->fs_info;
 	struct reada_extent *re;
 	struct reada_extctl *rec;
 
-	re = reada_find_extent(root, logical, top); /* takes one ref */
+	/* takes one ref */
+	re = reada_find_extent(fs_info->tree_root, logical, top);
 	if (!re)
 		return -1;
 
 	rec = kzalloc(sizeof(*rec), GFP_KERNEL);
 	if (!rec) {
-		reada_extent_put(root->fs_info, re);
+		reada_extent_put(fs_info, re);
 		return -ENOMEM;
 	}
 
@@ -914,7 +915,7 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 	if (!rc)
 		return ERR_PTR(-ENOMEM);
 
-	rc->root = root;
+	rc->fs_info = root->fs_info;
 	rc->key_start = *key_start;
 	rc->key_end = *key_end;
 	atomic_set(&rc->elems, 0);
@@ -942,7 +943,7 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 int btrfs_reada_wait(void *handle)
 {
 	struct reada_control *rc = handle;
-	struct btrfs_fs_info *fs_info = rc->root->fs_info;
+	struct btrfs_fs_info *fs_info = rc->fs_info;
 
 	while (atomic_read(&rc->elems)) {
 		if (!atomic_read(&fs_info->reada_works_cnt))
@@ -963,7 +964,7 @@ int btrfs_reada_wait(void *handle)
 int btrfs_reada_wait(void *handle)
 {
 	struct reada_control *rc = handle;
-	struct btrfs_fs_info *fs_info = rc->root->fs_info;
+	struct btrfs_fs_info *fs_info = rc->fs_info;
 
 	while (atomic_read(&rc->elems)) {
 		if (!atomic_read(&fs_info->reada_works_cnt))

commit b917bb387812f9abb81fc842e4c3b3ec727e10cf
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 17:18:35 2016 +0100

    btrfs: reada, remove pointless BUG_ON check for fs_info
    
    We dereference fs_info several times, besides that post-mount functions
    should never see a NULL fs_info.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 380ab6629e90..f0beb63a6d82 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -439,7 +439,6 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 				/* ignore whether the entry was inserted */
 				radix_tree_delete(&dev->reada_extents, index);
 			}
-			BUG_ON(fs_info == NULL);
 			radix_tree_delete(&fs_info->reada_tree, index);
 			spin_unlock(&fs_info->reada_lock);
 			btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);

commit 8694bb61360554e751f43688a9ff1793609884c4
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 17:11:27 2016 +0100

    btrfs: reada, remove pointless BUG_ON in reada_find_extent
    
    The lock is held, we make the same lookup that previously failed with
    EEXIST and we don't insert NULL pointers.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index e910bd9b1588..380ab6629e90 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -393,7 +393,6 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	ret = radix_tree_insert(&fs_info->reada_tree, index, re);
 	if (ret == -EEXIST) {
 		re_exist = radix_tree_lookup(&fs_info->reada_tree, index);
-		BUG_ON(!re_exist);
 		re_exist->refcnt++;
 		spin_unlock(&fs_info->reada_lock);
 		btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);

commit fc2e901f26859a87b7cd5c49015552805b7a00e0
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 13:50:03 2016 +0100

    btrfs: reada, sink start parameter to btree_readahead_hook
    
    Originally, the eb and start were passed separately in case eb is NULL.
    Since the readahead has been refactored in 4.6, this is not true anymore
    and we can get rid of the parameter.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 9c7a0424af1b..e910bd9b1588 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -209,12 +209,8 @@ static void __readahead_hook(struct btrfs_fs_info *fs_info,
 	return;
 }
 
-/*
- * start is passed separately in case eb in NULL, which may be the case with
- * failed I/O
- */
 int btree_readahead_hook(struct btrfs_fs_info *fs_info,
-			 struct extent_buffer *eb, u64 start, int err)
+			 struct extent_buffer *eb, int err)
 {
 	int ret = 0;
 	struct reada_extent *re;
@@ -222,7 +218,7 @@ int btree_readahead_hook(struct btrfs_fs_info *fs_info,
 	/* find extent */
 	spin_lock(&fs_info->reada_lock);
 	re = radix_tree_lookup(&fs_info->reada_tree,
-			       start >> PAGE_SHIFT);
+			       eb->start >> PAGE_SHIFT);
 	if (re)
 		re->refcnt++;
 	spin_unlock(&fs_info->reada_lock);

commit bcdc51b2043a363b67d97bc99799e505d31391a9
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 13:39:05 2016 +0100

    btrfs: reada, remove unused parameter from __readahead_hook
    
    'start' is not used since "btrfs: reada: Pass reada_extent into
    __readahead_hook directly" (6e39dbe8b9e55280c).
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 84a5beb48d46..9c7a0424af1b 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -107,7 +107,7 @@ static int reada_add_block(struct reada_control *rc, u64 logical,
 /* in case of err, eb might be NULL */
 static void __readahead_hook(struct btrfs_fs_info *fs_info,
 			     struct reada_extent *re, struct extent_buffer *eb,
-			     u64 start, int err)
+			     int err)
 {
 	int nritems;
 	int i;
@@ -231,7 +231,7 @@ int btree_readahead_hook(struct btrfs_fs_info *fs_info,
 		goto start_machine;
 	}
 
-	__readahead_hook(fs_info, re, eb, start, err);
+	__readahead_hook(fs_info, re, eb, err);
 	reada_extent_put(fs_info, re);	/* our ref */
 
 start_machine:
@@ -713,9 +713,9 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	ret = reada_tree_block_flagged(fs_info->extent_root, logical,
 			mirror_num, &eb);
 	if (ret)
-		__readahead_hook(fs_info, re, NULL, logical, ret);
+		__readahead_hook(fs_info, re, NULL, ret);
 	else if (eb)
-		__readahead_hook(fs_info, re, eb, eb->start, ret);
+		__readahead_hook(fs_info, re, eb, ret);
 
 	if (eb)
 		free_extent_buffer(eb);

commit 04998b3324fc8aa8f0af9b820e865f8c9665120c
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 13:32:43 2016 +0100

    btrfs: reada, cleanup remove unneeded variable in __readahead_hook
    
    We can't touch the eb directly in case the function is called with a
    non-zero error, so we can read the eb level when needed.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index f7dd892669a5..84a5beb48d46 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -109,16 +109,12 @@ static void __readahead_hook(struct btrfs_fs_info *fs_info,
 			     struct reada_extent *re, struct extent_buffer *eb,
 			     u64 start, int err)
 {
-	int level = 0;
 	int nritems;
 	int i;
 	u64 bytenr;
 	u64 generation;
 	struct list_head list;
 
-	if (eb)
-		level = btrfs_header_level(eb);
-
 	spin_lock(&re->lock);
 	/*
 	 * just take the full list from the extent. afterwards we
@@ -143,7 +139,7 @@ static void __readahead_hook(struct btrfs_fs_info *fs_info,
 	 * trigger more readahead depending from the content, e.g.
 	 * fetch the checksums for the extents in the leaf.
 	 */
-	if (!level)
+	if (!btrfs_header_level(eb))
 		goto cleanup;
 
 	nritems = btrfs_header_nritems(eb);

commit cf8cddd38bab31b284af8d51fee536be9914f6ef
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Oct 27 09:27:36 2016 +0200

    btrfs: don't abuse REQ_OP_* flags for btrfs_map_block
    
    btrfs_map_block supports different types of mappings, which to a large
    extent resemble block layer operations.  But they don't always do, and
    currently btrfs dangerously overlays it's own flag over the block layer
    flags.  This is just asking for a conflict, so introduce a different
    map flags enum inside of btrfs instead.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 75bab76739be..f7dd892669a5 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -354,8 +354,8 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	 * map block
 	 */
 	length = blocksize;
-	ret = btrfs_map_block(fs_info, REQ_GET_READ_MIRRORS, logical, &length,
-			      &bbio, 0);
+	ret = btrfs_map_block(fs_info, BTRFS_MAP_GET_READ_MIRRORS, logical,
+			&length, &bbio, 0);
 	if (ret || !bbio || length < blocksize)
 		goto error;
 

commit ab8d0fc48dba09e0a2b8b0dbfe144d4de9eb874f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:02 2016 -0400

    btrfs: convert pr_* to btrfs_* where possible
    
    For many printks, we want to know which file system issued the message.
    
    This patch converts most pr_* calls to use the btrfs_* versions instead.
    In some cases, this means adding plumbing to allow call sites access to
    an fs_info pointer.
    
    fs/btrfs/check-integrity.c is left alone for another day.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 9e85300051cc..75bab76739be 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -820,7 +820,7 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 
 	spin_lock(&fs_info->reada_lock);
 	list_for_each_entry(device, &fs_devices->devices, dev_list) {
-		pr_debug("dev %lld has %d in flight\n", device->devid,
+		btrfs_debug(fs_info, "dev %lld has %d in flight", device->devid,
 			atomic_read(&device->reada_in_flight));
 		index = 0;
 		while (1) {
@@ -830,8 +830,8 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 			if (ret == 0)
 				break;
 			pr_debug("  zone %llu-%llu elems %llu locked %d devs",
-			       zone->start, zone->end, zone->elems,
-			       zone->locked);
+				    zone->start, zone->end, zone->elems,
+				    zone->locked);
 			for (j = 0; j < zone->ndevs; ++j) {
 				pr_cont(" %lld",
 					zone->devs[j]->devid);

commit 62e855771dacf7c4d6daf9741642a965e7066d31
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:01 2016 -0400

    btrfs: convert printk(KERN_* to use pr_* calls
    
    This patch converts printk(KERN_* style messages to use the pr_* versions.
    
    One side effect is that anything that was KERN_DEBUG is now automatically
    a dynamic debug message.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 9e1bdafbd44b..9e85300051cc 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -820,7 +820,7 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 
 	spin_lock(&fs_info->reada_lock);
 	list_for_each_entry(device, &fs_devices->devices, dev_list) {
-		printk(KERN_DEBUG "dev %lld has %d in flight\n", device->devid,
+		pr_debug("dev %lld has %d in flight\n", device->devid,
 			atomic_read(&device->reada_in_flight));
 		index = 0;
 		while (1) {
@@ -829,17 +829,17 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 						     (void **)&zone, index, 1);
 			if (ret == 0)
 				break;
-			printk(KERN_DEBUG "  zone %llu-%llu elems %llu locked %d devs",
+			pr_debug("  zone %llu-%llu elems %llu locked %d devs",
 			       zone->start, zone->end, zone->elems,
 			       zone->locked);
 			for (j = 0; j < zone->ndevs; ++j) {
-				printk(KERN_CONT " %lld",
+				pr_cont(" %lld",
 					zone->devs[j]->devid);
 			}
 			if (device->reada_curr_zone == zone)
-				printk(KERN_CONT " curr off %llu",
+				pr_cont(" curr off %llu",
 					device->reada_next - zone->start);
-			printk(KERN_CONT "\n");
+			pr_cont("\n");
 			index = (zone->end >> PAGE_SHIFT) + 1;
 		}
 		cnt = 0;
@@ -851,21 +851,20 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 						     (void **)&re, index, 1);
 			if (ret == 0)
 				break;
-			printk(KERN_DEBUG
-				"  re: logical %llu size %u empty %d scheduled %d",
+			pr_debug("  re: logical %llu size %u empty %d scheduled %d",
 				re->logical, fs_info->tree_root->nodesize,
 				list_empty(&re->extctl), re->scheduled);
 
 			for (i = 0; i < re->nzones; ++i) {
-				printk(KERN_CONT " zone %llu-%llu devs",
+				pr_cont(" zone %llu-%llu devs",
 					re->zones[i]->start,
 					re->zones[i]->end);
 				for (j = 0; j < re->zones[i]->ndevs; ++j) {
-					printk(KERN_CONT " %lld",
+					pr_cont(" %lld",
 						re->zones[i]->devs[j]->devid);
 				}
 			}
-			printk(KERN_CONT "\n");
+			pr_cont("\n");
 			index = (re->logical >> PAGE_SHIFT) + 1;
 			if (++cnt > 15)
 				break;
@@ -885,20 +884,19 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 			index = (re->logical >> PAGE_SHIFT) + 1;
 			continue;
 		}
-		printk(KERN_DEBUG
-			"re: logical %llu size %u list empty %d scheduled %d",
+		pr_debug("re: logical %llu size %u list empty %d scheduled %d",
 			re->logical, fs_info->tree_root->nodesize,
 			list_empty(&re->extctl), re->scheduled);
 		for (i = 0; i < re->nzones; ++i) {
-			printk(KERN_CONT " zone %llu-%llu devs",
+			pr_cont(" zone %llu-%llu devs",
 				re->zones[i]->start,
 				re->zones[i]->end);
 			for (j = 0; j < re->zones[i]->ndevs; ++j) {
-				printk(KERN_CONT " %lld",
+				pr_cont(" %lld",
 				       re->zones[i]->devs[j]->devid);
 			}
 		}
-		printk(KERN_CONT "\n");
+		pr_cont("\n");
 		index = (re->logical >> PAGE_SHIFT) + 1;
 	}
 	spin_unlock(&fs_info->reada_lock);

commit 5d163e0e68ce743e1e919ddd3264c96ac02e9026
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:00 2016 -0400

    btrfs: unsplit printed strings
    
    CodingStyle chapter 2:
    "[...] never break user-visible strings such as printk messages,
    because that breaks the ability to grep for them."
    
    This patch unsplits user-visible strings.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 8428db7cd88f..9e1bdafbd44b 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -829,9 +829,9 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 						     (void **)&zone, index, 1);
 			if (ret == 0)
 				break;
-			printk(KERN_DEBUG "  zone %llu-%llu elems %llu locked "
-				"%d devs", zone->start, zone->end, zone->elems,
-				zone->locked);
+			printk(KERN_DEBUG "  zone %llu-%llu elems %llu locked %d devs",
+			       zone->start, zone->end, zone->elems,
+			       zone->locked);
 			for (j = 0; j < zone->ndevs; ++j) {
 				printk(KERN_CONT " %lld",
 					zone->devs[j]->devid);

commit ce7791ffee1e1ee9f97193b817c7dd1fa6746aad
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri May 20 01:57:20 2016 +0100

    Btrfs: fix race between readahead and device replace/removal
    
    The list of devices is protected by the device_list_mutex and the device
    replace code, in its finishing phase correctly takes that mutex before
    removing the source device from that list. However the readahead code was
    iterating that list without acquiring the respective mutex leading to
    crashes later on due to invalid memory accesses:
    
    [125671.831036] general protection fault: 0000 [#1] PREEMPT SMP
    [125671.832129] Modules linked in: btrfs dm_flakey dm_mod crc32c_generic xor raid6_pq acpi_cpufreq tpm_tis tpm ppdev evdev parport_pc psmouse sg parport
    processor ser
    [125671.834973] CPU: 10 PID: 19603 Comm: kworker/u32:19 Tainted: G        W       4.6.0-rc7-btrfs-next-29+ #1
    [125671.834973] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [125671.834973] Workqueue: btrfs-readahead btrfs_readahead_helper [btrfs]
    [125671.834973] task: ffff8801ac520540 ti: ffff8801ac918000 task.ti: ffff8801ac918000
    [125671.834973] RIP: 0010:[<ffffffff81270479>]  [<ffffffff81270479>] __radix_tree_lookup+0x6a/0x105
    [125671.834973] RSP: 0018:ffff8801ac91bc28  EFLAGS: 00010206
    [125671.834973] RAX: 0000000000000000 RBX: 6b6b6b6b6b6b6b6a RCX: 0000000000000000
    [125671.834973] RDX: 0000000000000000 RSI: 00000000000c1bff RDI: ffff88002ebd62a8
    [125671.834973] RBP: ffff8801ac91bc70 R08: 0000000000000001 R09: 0000000000000000
    [125671.834973] R10: ffff8801ac91bc70 R11: 0000000000000000 R12: ffff88002ebd62a8
    [125671.834973] R13: 0000000000000000 R14: 0000000000000000 R15: 00000000000c1bff
    [125671.834973] FS:  0000000000000000(0000) GS:ffff88023fd40000(0000) knlGS:0000000000000000
    [125671.834973] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [125671.834973] CR2: 000000000073cae4 CR3: 00000000b7723000 CR4: 00000000000006e0
    [125671.834973] Stack:
    [125671.834973]  0000000000000000 ffff8801422d5600 ffff8802286bbc00 0000000000000000
    [125671.834973]  0000000000000001 ffff8802286bbc00 00000000000c1bff 0000000000000000
    [125671.834973]  ffff88002e639eb8 ffff8801ac91bc80 ffffffff81270541 ffff8801ac91bcb0
    [125671.834973] Call Trace:
    [125671.834973]  [<ffffffff81270541>] radix_tree_lookup+0xd/0xf
    [125671.834973]  [<ffffffffa04ae6a6>] reada_peer_zones_set_lock+0x3e/0x60 [btrfs]
    [125671.834973]  [<ffffffffa04ae8b9>] reada_pick_zone+0x29/0x103 [btrfs]
    [125671.834973]  [<ffffffffa04af42f>] reada_start_machine_worker+0x129/0x2d3 [btrfs]
    [125671.834973]  [<ffffffffa04880be>] btrfs_scrubparity_helper+0x185/0x3aa [btrfs]
    [125671.834973]  [<ffffffffa0488341>] btrfs_readahead_helper+0xe/0x10 [btrfs]
    [125671.834973]  [<ffffffff81069691>] process_one_work+0x271/0x4e9
    [125671.834973]  [<ffffffff81069dda>] worker_thread+0x1eb/0x2c9
    [125671.834973]  [<ffffffff81069bef>] ? rescuer_thread+0x2b3/0x2b3
    [125671.834973]  [<ffffffff8106f403>] kthread+0xd4/0xdc
    [125671.834973]  [<ffffffff8149e242>] ret_from_fork+0x22/0x40
    [125671.834973]  [<ffffffff8106f32f>] ? kthread_stop+0x286/0x286
    
    So fix this by taking the device_list_mutex in the readahead code. We
    can't use here the lighter approach of using a rcu_read_lock() and
    rcu_read_unlock() pair together with a list_for_each_entry_rcu() call
    because we end up doing calls to sleeping functions (kzalloc()) in the
    respective code path.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 298631eaee78..8428db7cd88f 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -761,12 +761,14 @@ static void __reada_start_machine(struct btrfs_fs_info *fs_info)
 
 	do {
 		enqueued = 0;
+		mutex_lock(&fs_devices->device_list_mutex);
 		list_for_each_entry(device, &fs_devices->devices, dev_list) {
 			if (atomic_read(&device->reada_in_flight) <
 			    MAX_IN_FLIGHT)
 				enqueued += reada_start_machine_dev(fs_info,
 								    device);
 		}
+		mutex_unlock(&fs_devices->device_list_mutex);
 		total += enqueued;
 	} while (enqueued && total < 10000);
 

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index b892914968c1..298631eaee78 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -226,7 +226,7 @@ int btree_readahead_hook(struct btrfs_fs_info *fs_info,
 	/* find extent */
 	spin_lock(&fs_info->reada_lock);
 	re = radix_tree_lookup(&fs_info->reada_tree,
-			       start >> PAGE_CACHE_SHIFT);
+			       start >> PAGE_SHIFT);
 	if (re)
 		re->refcnt++;
 	spin_unlock(&fs_info->reada_lock);
@@ -257,7 +257,7 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 	zone = NULL;
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,
-				     logical >> PAGE_CACHE_SHIFT, 1);
+				     logical >> PAGE_SHIFT, 1);
 	if (ret == 1 && logical >= zone->start && logical <= zone->end) {
 		kref_get(&zone->refcnt);
 		spin_unlock(&fs_info->reada_lock);
@@ -294,13 +294,13 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_insert(&dev->reada_zones,
-				(unsigned long)(zone->end >> PAGE_CACHE_SHIFT),
+				(unsigned long)(zone->end >> PAGE_SHIFT),
 				zone);
 
 	if (ret == -EEXIST) {
 		kfree(zone);
 		ret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,
-					     logical >> PAGE_CACHE_SHIFT, 1);
+					     logical >> PAGE_SHIFT, 1);
 		if (ret == 1 && logical >= zone->start && logical <= zone->end)
 			kref_get(&zone->refcnt);
 		else
@@ -326,7 +326,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	u64 length;
 	int real_stripes;
 	int nzones = 0;
-	unsigned long index = logical >> PAGE_CACHE_SHIFT;
+	unsigned long index = logical >> PAGE_SHIFT;
 	int dev_replace_is_ongoing;
 	int have_zone = 0;
 
@@ -495,7 +495,7 @@ static void reada_extent_put(struct btrfs_fs_info *fs_info,
 			     struct reada_extent *re)
 {
 	int i;
-	unsigned long index = re->logical >> PAGE_CACHE_SHIFT;
+	unsigned long index = re->logical >> PAGE_SHIFT;
 
 	spin_lock(&fs_info->reada_lock);
 	if (--re->refcnt) {
@@ -538,7 +538,7 @@ static void reada_zone_release(struct kref *kref)
 	struct reada_zone *zone = container_of(kref, struct reada_zone, refcnt);
 
 	radix_tree_delete(&zone->device->reada_zones,
-			  zone->end >> PAGE_CACHE_SHIFT);
+			  zone->end >> PAGE_SHIFT);
 
 	kfree(zone);
 }
@@ -587,7 +587,7 @@ static int reada_add_block(struct reada_control *rc, u64 logical,
 static void reada_peer_zones_set_lock(struct reada_zone *zone, int lock)
 {
 	int i;
-	unsigned long index = zone->end >> PAGE_CACHE_SHIFT;
+	unsigned long index = zone->end >> PAGE_SHIFT;
 
 	for (i = 0; i < zone->ndevs; ++i) {
 		struct reada_zone *peer;
@@ -622,7 +622,7 @@ static int reada_pick_zone(struct btrfs_device *dev)
 					     (void **)&zone, index, 1);
 		if (ret == 0)
 			break;
-		index = (zone->end >> PAGE_CACHE_SHIFT) + 1;
+		index = (zone->end >> PAGE_SHIFT) + 1;
 		if (zone->locked) {
 			if (zone->elems > top_locked_elems) {
 				top_locked_elems = zone->elems;
@@ -673,7 +673,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	 * plugging to speed things up
 	 */
 	ret = radix_tree_gang_lookup(&dev->reada_extents, (void **)&re,
-				     dev->reada_next >> PAGE_CACHE_SHIFT, 1);
+				     dev->reada_next >> PAGE_SHIFT, 1);
 	if (ret == 0 || re->logical > dev->reada_curr_zone->end) {
 		ret = reada_pick_zone(dev);
 		if (!ret) {
@@ -682,7 +682,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 		}
 		re = NULL;
 		ret = radix_tree_gang_lookup(&dev->reada_extents, (void **)&re,
-					dev->reada_next >> PAGE_CACHE_SHIFT, 1);
+					dev->reada_next >> PAGE_SHIFT, 1);
 	}
 	if (ret == 0) {
 		spin_unlock(&fs_info->reada_lock);
@@ -838,7 +838,7 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 				printk(KERN_CONT " curr off %llu",
 					device->reada_next - zone->start);
 			printk(KERN_CONT "\n");
-			index = (zone->end >> PAGE_CACHE_SHIFT) + 1;
+			index = (zone->end >> PAGE_SHIFT) + 1;
 		}
 		cnt = 0;
 		index = 0;
@@ -864,7 +864,7 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 				}
 			}
 			printk(KERN_CONT "\n");
-			index = (re->logical >> PAGE_CACHE_SHIFT) + 1;
+			index = (re->logical >> PAGE_SHIFT) + 1;
 			if (++cnt > 15)
 				break;
 		}
@@ -880,7 +880,7 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 		if (ret == 0)
 			break;
 		if (!re->scheduled) {
-			index = (re->logical >> PAGE_CACHE_SHIFT) + 1;
+			index = (re->logical >> PAGE_SHIFT) + 1;
 			continue;
 		}
 		printk(KERN_DEBUG
@@ -897,7 +897,7 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 			}
 		}
 		printk(KERN_CONT "\n");
-		index = (re->logical >> PAGE_CACHE_SHIFT) + 1;
+		index = (re->logical >> PAGE_SHIFT) + 1;
 	}
 	spin_unlock(&fs_info->reada_lock);
 }

commit 675d276b322b45e7bf7c616a2847bdc425745b99
Merge: e9ddd77a31e6 73beece9ca07
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:32 2016 +0100

    Merge branch 'foreign/liubo/replace-lockup' into for-chris-4.6

commit ff7db6e05a93a23eb43c7d20dc2027bcc939b6a8
Merge: 23c1a966f252 7aff8cf4a6d6
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:30 2016 +0100

    Merge branch 'foreign/zhaolei/reada' into for-chris-4.6

commit 73beece9ca07c003e0e4f4825b12be167334d4ad
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Jul 17 16:49:19 2015 +0800

    Btrfs: fix lockdep deadlock warning due to dev_replace
    
    Xfstests btrfs/011 complains about a deadlock warning,
    
    [ 1226.649039] =========================================================
    [ 1226.649039] [ INFO: possible irq lock inversion dependency detected ]
    [ 1226.649039] 4.1.0+ #270 Not tainted
    [ 1226.649039] ---------------------------------------------------------
    [ 1226.652955] kswapd0/46 just changed the state of lock:
    [ 1226.652955]  (&delayed_node->mutex){+.+.-.}, at: [<ffffffff81458735>] __btrfs_release_delayed_node+0x45/0x1d0
    [ 1226.652955] but this lock took another, RECLAIM_FS-unsafe lock in the past:
    [ 1226.652955]  (&fs_info->dev_replace.lock){+.+.+.}
    
    and interrupts could create inverse lock ordering between them.
    
    [ 1226.652955]
    other info that might help us debug this:
    [ 1226.652955] Chain exists of:
      &delayed_node->mutex --> &found->groups_sem --> &fs_info->dev_replace.lock
    
    [ 1226.652955]  Possible interrupt unsafe locking scenario:
    
    [ 1226.652955]        CPU0                    CPU1
    [ 1226.652955]        ----                    ----
    [ 1226.652955]   lock(&fs_info->dev_replace.lock);
    [ 1226.652955]                                local_irq_disable();
    [ 1226.652955]                                lock(&delayed_node->mutex);
    [ 1226.652955]                                lock(&found->groups_sem);
    [ 1226.652955]   <Interrupt>
    [ 1226.652955]     lock(&delayed_node->mutex);
    [ 1226.652955]
     *** DEADLOCK ***
    
    Commit 084b6e7c7607 ("btrfs: Fix a lockdep warning when running xfstest.") tried
    to fix a similar one that has the exactly same warning, but with that, we still
    run to this.
    
    The above lock chain comes from
    btrfs_commit_transaction
      ->btrfs_run_delayed_items
        ...
        ->__btrfs_update_delayed_inode
          ...
          ->__btrfs_cow_block
             ...
             ->find_free_extent
                ->cache_block_group
                  ->load_free_space_cache
                    ->btrfs_readpages
                      ->submit_one_bio
                        ...
                        ->__btrfs_map_block
                          ->btrfs_dev_replace_lock
    
    However, with high memory pressure, tasks which hold dev_replace.lock can
    be interrupted by kswapd and then kswapd is intended to release memory occupied
    by superblock, inodes and dentries, where we may call evict_inode, and it comes
    to
    
    [ 1226.652955]  [<ffffffff81458735>] __btrfs_release_delayed_node+0x45/0x1d0
    [ 1226.652955]  [<ffffffff81459e74>] btrfs_remove_delayed_node+0x24/0x30
    [ 1226.652955]  [<ffffffff8140c5fe>] btrfs_evict_inode+0x34e/0x700
    
    delayed_node->mutex may be acquired in __btrfs_release_delayed_node(), and it leads
    to a ABBA deadlock.
    
    To fix this, we can use "blocking rwlock" used in the case of extent_buffer, but
    things are simpler here since we only needs read's spinlock to blocking lock.
    
    With this, btrfs/011 no more produces warnings in dmesg.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 619f92963e27..fe3d4c7b6342 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -396,7 +396,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	}
 
 	/* insert extent in reada_tree + all per-device trees, all or nothing */
-	btrfs_dev_replace_lock(&fs_info->dev_replace);
+	btrfs_dev_replace_lock(&fs_info->dev_replace, 0);
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_insert(&fs_info->reada_tree, index, re);
 	if (ret == -EEXIST) {
@@ -404,12 +404,12 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		BUG_ON(!re_exist);
 		re_exist->refcnt++;
 		spin_unlock(&fs_info->reada_lock);
-		btrfs_dev_replace_unlock(&fs_info->dev_replace);
+		btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
 		goto error;
 	}
 	if (ret) {
 		spin_unlock(&fs_info->reada_lock);
-		btrfs_dev_replace_unlock(&fs_info->dev_replace);
+		btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
 		goto error;
 	}
 	prev_dev = NULL;
@@ -456,12 +456,12 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 			BUG_ON(fs_info == NULL);
 			radix_tree_delete(&fs_info->reada_tree, index);
 			spin_unlock(&fs_info->reada_lock);
-			btrfs_dev_replace_unlock(&fs_info->dev_replace);
+			btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
 			goto error;
 		}
 	}
 	spin_unlock(&fs_info->reada_lock);
-	btrfs_dev_replace_unlock(&fs_info->dev_replace);
+	btrfs_dev_replace_unlock(&fs_info->dev_replace, 0);
 
 	btrfs_put_bbio(bbio);
 	return re;

commit 7aff8cf4a6d6190e64386f407a7f5cc5f24c60d2
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Jan 14 18:39:00 2016 +0800

    btrfs: reada: ignore creating reada_extent for a non-existent device
    
    For a non-existent device, old code bypasses adding it in dev's reada
    queue.
    
    And to solve problem of unfinished waitting in raid5/6,
    commit 5fbc7c59fd22 ("Btrfs: fix unfinished readahead thread for
    raid5/6 degraded mounting")
    adding an exception for the first stripe, in short, the first
    stripe will always be processed whether the device exists or not.
    
    Actually we have a better way for the above request: just bypass
    creation of the reada_extent for non-existent device, it will make
    code simple and effective.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 5bcd567f4827..dd5f361f1a8e 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -371,6 +371,11 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		struct reada_zone *zone;
 
 		dev = bbio->stripes[nzones].dev;
+
+		/* cannot read ahead on missing device. */
+		 if (!dev->bdev)
+			continue;
+
 		zone = reada_find_zone(fs_info, dev, logical, bbio);
 		if (!zone)
 			continue;
@@ -423,15 +428,9 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 			 */
 			continue;
 		}
-		if (!dev->bdev) {
-			/*
-			 * cannot read ahead on missing device, but for RAID5/6,
-			 * REQ_GET_READ_MIRRORS return 1. So don't skip missing
-			 * device for such case.
-			 */
-			if (nzones > 1)
-				continue;
-		}
+		if (!dev->bdev)
+			continue;
+
 		if (dev_replace_is_ongoing &&
 		    dev == fs_info->dev_replace.tgtdev) {
 			/*

commit 4fe7a0e13864238fe5b4cc2640e963581f96429e
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Tue Jan 26 18:42:40 2016 +0800

    btrfs: reada: avoid undone reada extents in btrfs_reada_wait
    
    Reada background works is not designed to finish all jobs
    completely, it will break in following case:
    1: When a device reaches workload limit (MAX_IN_FLIGHT)
    2: Total reads reach max limit (10000)
    3: All devices don't have queued more jobs, often happened in DUP case
    
    And if all background works exit with remaining jobs,
    btrfs_reada_wait() will wait indefinetelly.
    
    Above problem is rarely happened in old code, because:
    1: Every work queues 2x new works
       So many works reduced chances of undone jobs.
    2: One work will continue 10000 times loop in case of no-jobs
       It reduced no-thread window time.
    
    But after we fixed above case, the "undone reada extents" frequently
    happened.
    
    Fix:
     Check to ensure we have at least one thread if there are undone jobs
     in btrfs_reada_wait().
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index e97bc8eb01e2..5bcd567f4827 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -953,8 +953,11 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 int btrfs_reada_wait(void *handle)
 {
 	struct reada_control *rc = handle;
+	struct btrfs_fs_info *fs_info = rc->root->fs_info;
 
 	while (atomic_read(&rc->elems)) {
+		if (!atomic_read(&fs_info->reada_works_cnt))
+			reada_start_machine(fs_info);
 		wait_event_timeout(rc->wait, atomic_read(&rc->elems) == 0,
 				   5 * HZ);
 		dump_devs(rc->root->fs_info,
@@ -971,9 +974,13 @@ int btrfs_reada_wait(void *handle)
 int btrfs_reada_wait(void *handle)
 {
 	struct reada_control *rc = handle;
+	struct btrfs_fs_info *fs_info = rc->root->fs_info;
 
 	while (atomic_read(&rc->elems)) {
-		wait_event(rc->wait, atomic_read(&rc->elems) == 0);
+		if (!atomic_read(&fs_info->reada_works_cnt))
+			reada_start_machine(fs_info);
+		wait_event_timeout(rc->wait, atomic_read(&rc->elems) == 0,
+				   (HZ + 9) / 10);
 	}
 
 	kref_put(&rc->refcnt, reada_control_release);

commit 2fefd5583f8b86171c898f90cadac7c09ccf9d73
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Jan 7 18:38:48 2016 +0800

    btrfs: reada: limit max works count
    
    Reada creates 2 works for each level of tree recursively.
    
    In case of a tree having many levels, the number of created works
    is 2^level_of_tree.
    Actually we don't need so many works in parallel, this patch limits
    max works to BTRFS_MAX_MIRRORS * 2.
    
    The per-fs works_counter will be also used for btrfs_reada_wait() to
    check is there are background workers.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 9157d789ae86..e97bc8eb01e2 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -748,6 +748,8 @@ static void reada_start_machine_worker(struct btrfs_work *work)
 	set_task_ioprio(current, BTRFS_IOPRIO_READA);
 	__reada_start_machine(fs_info);
 	set_task_ioprio(current, old_ioprio);
+
+	atomic_dec(&fs_info->reada_works_cnt);
 }
 
 static void __reada_start_machine(struct btrfs_fs_info *fs_info)
@@ -779,8 +781,12 @@ static void __reada_start_machine(struct btrfs_fs_info *fs_info)
 	 * enqueue to workers to finish it. This will distribute the load to
 	 * the cores.
 	 */
-	for (i = 0; i < 2; ++i)
+	for (i = 0; i < 2; ++i) {
 		reada_start_machine(fs_info);
+		if (atomic_read(&fs_info->reada_works_cnt) >
+		    BTRFS_MAX_MIRRORS * 2)
+			break;
+	}
 }
 
 static void reada_start_machine(struct btrfs_fs_info *fs_info)
@@ -797,6 +803,7 @@ static void reada_start_machine(struct btrfs_fs_info *fs_info)
 	rmw->fs_info = fs_info;
 
 	btrfs_queue_work(fs_info->readahead_workers, &rmw->work);
+	atomic_inc(&fs_info->reada_works_cnt);
 }
 
 #ifdef DEBUG

commit 895a11b868347ca8e287f152f7816862ad4b179d
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Tue Jan 12 14:58:39 2016 +0800

    btrfs: reada: simplify dev->reada_in_flight processing
    
    No need to decrease dev->reada_in_flight in __readahead_hook()'s
    internal and reada_extent_put().
    reada_extent_put() have no chance to decrease dev->reada_in_flight
    in free operation, because reada_extent have additional refcnt when
    scheduled to a dev.
    
    We can put inc and dec operation for dev->reada_in_flight to one
    place instead to make logic simple and safe, and move useless
    reada_extent->scheduled_for to a bool flag instead.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 5871306a5a3b..9157d789ae86 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -72,7 +72,7 @@ struct reada_extent {
 	spinlock_t		lock;
 	struct reada_zone	*zones[BTRFS_MAX_MIRRORS];
 	int			nzones;
-	struct btrfs_device	*scheduled_for;
+	int			scheduled;
 };
 
 struct reada_zone {
@@ -115,7 +115,6 @@ static void __readahead_hook(struct btrfs_fs_info *fs_info,
 	u64 bytenr;
 	u64 generation;
 	struct list_head list;
-	struct btrfs_device *for_dev;
 
 	if (eb)
 		level = btrfs_header_level(eb);
@@ -126,8 +125,7 @@ static void __readahead_hook(struct btrfs_fs_info *fs_info,
 	 * don't need the lock anymore
 	 */
 	list_replace_init(&re->extctl, &list);
-	for_dev = re->scheduled_for;
-	re->scheduled_for = NULL;
+	re->scheduled = 0;
 	spin_unlock(&re->lock);
 
 	/*
@@ -212,9 +210,6 @@ static void __readahead_hook(struct btrfs_fs_info *fs_info,
 		reada_extent_put(fs_info, re);	/* one ref for each entry */
 	}
 
-	if (for_dev)
-		atomic_dec(&for_dev->reada_in_flight);
-
 	return;
 }
 
@@ -535,8 +530,6 @@ static void reada_extent_put(struct btrfs_fs_info *fs_info,
 		kref_put(&zone->refcnt, reada_zone_release);
 		spin_unlock(&fs_info->reada_lock);
 	}
-	if (re->scheduled_for)
-		atomic_dec(&re->scheduled_for->reada_in_flight);
 
 	kfree(re);
 }
@@ -702,12 +695,12 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	spin_unlock(&fs_info->reada_lock);
 
 	spin_lock(&re->lock);
-	if (re->scheduled_for || list_empty(&re->extctl)) {
+	if (re->scheduled || list_empty(&re->extctl)) {
 		spin_unlock(&re->lock);
 		reada_extent_put(fs_info, re);
 		return 0;
 	}
-	re->scheduled_for = dev;
+	re->scheduled = 1;
 	spin_unlock(&re->lock);
 
 	/*
@@ -732,6 +725,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	if (eb)
 		free_extent_buffer(eb);
 
+	atomic_dec(&dev->reada_in_flight);
 	reada_extent_put(fs_info, re);
 
 	return 1;
@@ -850,10 +844,9 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 			if (ret == 0)
 				break;
 			printk(KERN_DEBUG
-				"  re: logical %llu size %u empty %d for %lld",
+				"  re: logical %llu size %u empty %d scheduled %d",
 				re->logical, fs_info->tree_root->nodesize,
-				list_empty(&re->extctl), re->scheduled_for ?
-				re->scheduled_for->devid : -1);
+				list_empty(&re->extctl), re->scheduled);
 
 			for (i = 0; i < re->nzones; ++i) {
 				printk(KERN_CONT " zone %llu-%llu devs",
@@ -880,15 +873,14 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 					     index, 1);
 		if (ret == 0)
 			break;
-		if (!re->scheduled_for) {
+		if (!re->scheduled) {
 			index = (re->logical >> PAGE_CACHE_SHIFT) + 1;
 			continue;
 		}
 		printk(KERN_DEBUG
-			"re: logical %llu size %u list empty %d for %lld",
+			"re: logical %llu size %u list empty %d scheduled %d",
 			re->logical, fs_info->tree_root->nodesize,
-			list_empty(&re->extctl),
-			re->scheduled_for ? re->scheduled_for->devid : -1);
+			list_empty(&re->extctl), re->scheduled);
 		for (i = 0; i < re->nzones; ++i) {
 			printk(KERN_CONT " zone %llu-%llu devs",
 				re->zones[i]->start,

commit 8afd6841e13f8bbdf543c576bc1b919d331003ea
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 22:28:51 2015 +0800

    btrfs: reada: Fix a debug code typo
    
    Remove one copy of loop to fix the typo of iterate zones.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 04d3e7c8ada0..5871306a5a3b 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -893,14 +893,9 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 			printk(KERN_CONT " zone %llu-%llu devs",
 				re->zones[i]->start,
 				re->zones[i]->end);
-			for (i = 0; i < re->nzones; ++i) {
-				printk(KERN_CONT " zone %llu-%llu devs",
-					re->zones[i]->start,
-					re->zones[i]->end);
-				for (j = 0; j < re->zones[i]->ndevs; ++j) {
-					printk(KERN_CONT " %lld",
-						re->zones[i]->devs[j]->devid);
-				}
+			for (j = 0; j < re->zones[i]->ndevs; ++j) {
+				printk(KERN_CONT " %lld",
+				       re->zones[i]->devs[j]->devid);
 			}
 		}
 		printk(KERN_CONT "\n");

commit 57f16e08269c6a91fb77508b2fe58130c6442d94
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 22:20:59 2015 +0800

    btrfs: reada: Jump into cleanup in direct way for __readahead_hook()
    
    Current code set nritems to 0 to make for_loop useless to bypass it,
    and set generation's value which is not necessary.
    Jump into cleanup directly is better choise.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 6d9069d01914..04d3e7c8ada0 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -130,26 +130,26 @@ static void __readahead_hook(struct btrfs_fs_info *fs_info,
 	re->scheduled_for = NULL;
 	spin_unlock(&re->lock);
 
-	if (err == 0) {
-		nritems = level ? btrfs_header_nritems(eb) : 0;
-		generation = btrfs_header_generation(eb);
-		/*
-		 * FIXME: currently we just set nritems to 0 if this is a leaf,
-		 * effectively ignoring the content. In a next step we could
-		 * trigger more readahead depending from the content, e.g.
-		 * fetch the checksums for the extents in the leaf.
-		 */
-	} else {
-		/*
-		 * this is the error case, the extent buffer has not been
-		 * read correctly. We won't access anything from it and
-		 * just cleanup our data structures. Effectively this will
-		 * cut the branch below this node from read ahead.
-		 */
-		nritems = 0;
-		generation = 0;
-	}
+	/*
+	 * this is the error case, the extent buffer has not been
+	 * read correctly. We won't access anything from it and
+	 * just cleanup our data structures. Effectively this will
+	 * cut the branch below this node from read ahead.
+	 */
+	if (err)
+		goto cleanup;
 
+	/*
+	 * FIXME: currently we just set nritems to 0 if this is a leaf,
+	 * effectively ignoring the content. In a next step we could
+	 * trigger more readahead depending from the content, e.g.
+	 * fetch the checksums for the extents in the leaf.
+	 */
+	if (!level)
+		goto cleanup;
+
+	nritems = btrfs_header_nritems(eb);
+	generation = btrfs_header_generation(eb);
 	for (i = 0; i < nritems; i++) {
 		struct reada_extctl *rec;
 		u64 n_gen;
@@ -188,6 +188,8 @@ static void __readahead_hook(struct btrfs_fs_info *fs_info,
 				reada_add_block(rc, bytenr, &next_key, n_gen);
 		}
 	}
+
+cleanup:
 	/*
 	 * free extctl records
 	 */

commit 02873e432518f84ad8f15d8911e79659ea38085f
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 22:46:45 2015 +0800

    btrfs: reada: Use fs_info instead of root in __readahead_hook's argument
    
    What __readahead_hook() need exactly is fs_info, no need to convert
    fs_info to root in caller and convert back in __readahead_hook()
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 203bec4823e1..6d9069d01914 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -105,15 +105,15 @@ static int reada_add_block(struct reada_control *rc, u64 logical,
 
 /* recurses */
 /* in case of err, eb might be NULL */
-static void __readahead_hook(struct btrfs_root *root, struct reada_extent *re,
-			     struct extent_buffer *eb, u64 start, int err)
+static void __readahead_hook(struct btrfs_fs_info *fs_info,
+			     struct reada_extent *re, struct extent_buffer *eb,
+			     u64 start, int err)
 {
 	int level = 0;
 	int nritems;
 	int i;
 	u64 bytenr;
 	u64 generation;
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct list_head list;
 	struct btrfs_device *for_dev;
 
@@ -176,10 +176,10 @@ static void __readahead_hook(struct btrfs_root *root, struct reada_extent *re,
 			 */
 #ifdef DEBUG
 			if (rec->generation != generation) {
-				btrfs_debug(root->fs_info,
-					   "generation mismatch for (%llu,%d,%llu) %llu != %llu",
-				       key.objectid, key.type, key.offset,
-				       rec->generation, generation);
+				btrfs_debug(fs_info,
+					    "generation mismatch for (%llu,%d,%llu) %llu != %llu",
+					    key.objectid, key.type, key.offset,
+					    rec->generation, generation);
 			}
 #endif
 			if (rec->generation == generation &&
@@ -220,12 +220,11 @@ static void __readahead_hook(struct btrfs_root *root, struct reada_extent *re,
  * start is passed separately in case eb in NULL, which may be the case with
  * failed I/O
  */
-int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
-			 u64 start, int err)
+int btree_readahead_hook(struct btrfs_fs_info *fs_info,
+			 struct extent_buffer *eb, u64 start, int err)
 {
 	int ret = 0;
 	struct reada_extent *re;
-	struct btrfs_fs_info *fs_info = root->fs_info;
 
 	/* find extent */
 	spin_lock(&fs_info->reada_lock);
@@ -724,9 +723,9 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	ret = reada_tree_block_flagged(fs_info->extent_root, logical,
 			mirror_num, &eb);
 	if (ret)
-		__readahead_hook(fs_info->extent_root, re, NULL, logical, ret);
+		__readahead_hook(fs_info, re, NULL, logical, ret);
 	else if (eb)
-		__readahead_hook(fs_info->extent_root, re, eb, eb->start, ret);
+		__readahead_hook(fs_info, re, eb, eb->start, ret);
 
 	if (eb)
 		free_extent_buffer(eb);

commit 6e39dbe8b9e55280c396a19fb92e82f1b56f83d7
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 22:09:05 2015 +0800

    btrfs: reada: Pass reada_extent into __readahead_hook directly
    
    reada_start_machine_dev() already have reada_extent pointer, pass
    it into __readahead_hook() directly instead of search radix_tree
    will make code run faster.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index f7642e569bd9..203bec4823e1 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -105,33 +105,21 @@ static int reada_add_block(struct reada_control *rc, u64 logical,
 
 /* recurses */
 /* in case of err, eb might be NULL */
-static int __readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
-			    u64 start, int err)
+static void __readahead_hook(struct btrfs_root *root, struct reada_extent *re,
+			     struct extent_buffer *eb, u64 start, int err)
 {
 	int level = 0;
 	int nritems;
 	int i;
 	u64 bytenr;
 	u64 generation;
-	struct reada_extent *re;
 	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct list_head list;
-	unsigned long index = start >> PAGE_CACHE_SHIFT;
 	struct btrfs_device *for_dev;
 
 	if (eb)
 		level = btrfs_header_level(eb);
 
-	/* find extent */
-	spin_lock(&fs_info->reada_lock);
-	re = radix_tree_lookup(&fs_info->reada_tree, index);
-	if (re)
-		re->refcnt++;
-	spin_unlock(&fs_info->reada_lock);
-
-	if (!re)
-		return -1;
-
 	spin_lock(&re->lock);
 	/*
 	 * just take the full list from the extent. afterwards we
@@ -221,11 +209,11 @@ static int __readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 
 		reada_extent_put(fs_info, re);	/* one ref for each entry */
 	}
-	reada_extent_put(fs_info, re);	/* our ref */
+
 	if (for_dev)
 		atomic_dec(&for_dev->reada_in_flight);
 
-	return 0;
+	return;
 }
 
 /*
@@ -235,12 +223,27 @@ static int __readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 			 u64 start, int err)
 {
-	int ret;
+	int ret = 0;
+	struct reada_extent *re;
+	struct btrfs_fs_info *fs_info = root->fs_info;
 
-	ret = __readahead_hook(root, eb, start, err);
+	/* find extent */
+	spin_lock(&fs_info->reada_lock);
+	re = radix_tree_lookup(&fs_info->reada_tree,
+			       start >> PAGE_CACHE_SHIFT);
+	if (re)
+		re->refcnt++;
+	spin_unlock(&fs_info->reada_lock);
+	if (!re) {
+		ret = -1;
+		goto start_machine;
+	}
 
-	reada_start_machine(root->fs_info);
+	__readahead_hook(fs_info, re, eb, start, err);
+	reada_extent_put(fs_info, re);	/* our ref */
 
+start_machine:
+	reada_start_machine(fs_info);
 	return ret;
 }
 
@@ -721,9 +724,9 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	ret = reada_tree_block_flagged(fs_info->extent_root, logical,
 			mirror_num, &eb);
 	if (ret)
-		__readahead_hook(fs_info->extent_root, NULL, logical, ret);
+		__readahead_hook(fs_info->extent_root, re, NULL, logical, ret);
 	else if (eb)
-		__readahead_hook(fs_info->extent_root, eb, eb->start, ret);
+		__readahead_hook(fs_info->extent_root, re, eb, eb->start, ret);
 
 	if (eb)
 		free_extent_buffer(eb);

commit b257cf50060cada63a3fe11a932909b9badf4595
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 21:07:17 2015 +0800

    btrfs: reada: move reada_extent_put to place after __readahead_hook()
    
    We can't release reada_extent earlier than __readahead_hook(), because
    __readahead_hook() still need to use it, it is necessary to hode a refcnt
    to avoid it be freed.
    
    Actually it is not a problem after my patch named:
      Avoid many times of empty loop
    It make reada_extent in above line include at least one reada_extctl,
    which keeps additional one refcnt for reada_extent.
    
    But we still need this patch to make the code in pretty logic.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index b40dbf717737..f7642e569bd9 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -717,8 +717,6 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	}
 	logical = re->logical;
 
-	reada_extent_put(fs_info, re);
-
 	atomic_inc(&dev->reada_in_flight);
 	ret = reada_tree_block_flagged(fs_info->extent_root, logical,
 			mirror_num, &eb);
@@ -730,6 +728,8 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	if (eb)
 		free_extent_buffer(eb);
 
+	reada_extent_put(fs_info, re);
+
 	return 1;
 
 }

commit 1e7970c0f31d6916e0ab523e5f05c9741f71955f
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 20:30:00 2015 +0800

    btrfs: reada: Remove level argument in severial functions
    
    level is not used in severial functions, remove them from arguments,
    and remove relative code for get its value.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 1d00de7369a8..b40dbf717737 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -101,7 +101,7 @@ static void reada_start_machine(struct btrfs_fs_info *fs_info);
 static void __reada_start_machine(struct btrfs_fs_info *fs_info);
 
 static int reada_add_block(struct reada_control *rc, u64 logical,
-			   struct btrfs_key *top, int level, u64 generation);
+			   struct btrfs_key *top, u64 generation);
 
 /* recurses */
 /* in case of err, eb might be NULL */
@@ -197,8 +197,7 @@ static int __readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 			if (rec->generation == generation &&
 			    btrfs_comp_cpu_keys(&key, &rc->key_end) < 0 &&
 			    btrfs_comp_cpu_keys(&next_key, &rc->key_start) > 0)
-				reada_add_block(rc, bytenr, &next_key,
-						level - 1, n_gen);
+				reada_add_block(rc, bytenr, &next_key, n_gen);
 		}
 	}
 	/*
@@ -315,7 +314,7 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 
 static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 					      u64 logical,
-					      struct btrfs_key *top, int level)
+					      struct btrfs_key *top)
 {
 	int ret;
 	struct reada_extent *re = NULL;
@@ -557,13 +556,13 @@ static void reada_control_release(struct kref *kref)
 }
 
 static int reada_add_block(struct reada_control *rc, u64 logical,
-			   struct btrfs_key *top, int level, u64 generation)
+			   struct btrfs_key *top, u64 generation)
 {
 	struct btrfs_root *root = rc->root;
 	struct reada_extent *re;
 	struct reada_extctl *rec;
 
-	re = reada_find_extent(root, logical, top, level); /* takes one ref */
+	re = reada_find_extent(root, logical, top); /* takes one ref */
 	if (!re)
 		return -1;
 
@@ -916,7 +915,6 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 	struct reada_control *rc;
 	u64 start;
 	u64 generation;
-	int level;
 	int ret;
 	struct extent_buffer *node;
 	static struct btrfs_key max_key = {
@@ -939,11 +937,10 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 
 	node = btrfs_root_node(root);
 	start = node->start;
-	level = btrfs_header_level(node);
 	generation = btrfs_header_generation(node);
 	free_extent_buffer(node);
 
-	ret = reada_add_block(rc, start, &max_key, level, generation);
+	ret = reada_add_block(rc, start, &max_key, generation);
 	if (ret) {
 		kfree(rc);
 		return ERR_PTR(ret);

commit 319450211842ba92d0604af6e4ddf15f445efbcf
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 18:48:54 2015 +0800

    btrfs: reada: bypass adding extent when all zone failed
    
    When failed adding all dev_zones for a reada_extent, the extent
    will have no chance to be selected to run, and keep in memory
    for ever.
    
    We should bypass this extent to avoid above case.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 27a2fe914c67..1d00de7369a8 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -330,6 +330,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	int nzones = 0;
 	unsigned long index = logical >> PAGE_CACHE_SHIFT;
 	int dev_replace_is_ongoing;
+	int have_zone = 0;
 
 	spin_lock(&fs_info->reada_lock);
 	re = radix_tree_lookup(&fs_info->reada_tree, index);
@@ -456,10 +457,14 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 			btrfs_dev_replace_unlock(&fs_info->dev_replace);
 			goto error;
 		}
+		have_zone = 1;
 	}
 	spin_unlock(&fs_info->reada_lock);
 	btrfs_dev_replace_unlock(&fs_info->dev_replace);
 
+	if (!have_zone)
+		goto error;
+
 	btrfs_put_bbio(bbio);
 	return re;
 

commit 6a159d2ae488a835a8ca5f1f658db72b7e13d064
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 18:15:47 2015 +0800

    btrfs: reada: add all reachable mirrors into reada device list
    
    If some device is not reachable, we should bypass and continus addingb
    next, instead of break on bad device.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index b2f768a3174a..27a2fe914c67 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -328,7 +328,6 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	u64 length;
 	int real_stripes;
 	int nzones = 0;
-	int i;
 	unsigned long index = logical >> PAGE_CACHE_SHIFT;
 	int dev_replace_is_ongoing;
 
@@ -375,9 +374,9 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		dev = bbio->stripes[nzones].dev;
 		zone = reada_find_zone(fs_info, dev, logical, bbio);
 		if (!zone)
-			break;
+			continue;
 
-		re->zones[nzones] = zone;
+		re->zones[re->nzones++] = zone;
 		spin_lock(&zone->lock);
 		if (!zone->elems)
 			kref_get(&zone->refcnt);
@@ -387,8 +386,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		kref_put(&zone->refcnt, reada_zone_release);
 		spin_unlock(&fs_info->reada_lock);
 	}
-	re->nzones = nzones;
-	if (nzones == 0) {
+	if (re->nzones == 0) {
 		/* not a single zone found, error and out */
 		goto error;
 	}
@@ -413,8 +411,9 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	prev_dev = NULL;
 	dev_replace_is_ongoing = btrfs_dev_replace_is_ongoing(
 			&fs_info->dev_replace);
-	for (i = 0; i < nzones; ++i) {
-		dev = bbio->stripes[i].dev;
+	for (nzones = 0; nzones < re->nzones; ++nzones) {
+		dev = re->zones[nzones]->device;
+
 		if (dev == prev_dev) {
 			/*
 			 * in case of DUP, just add the first zone. As both
@@ -445,8 +444,8 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		prev_dev = dev;
 		ret = radix_tree_insert(&dev->reada_extents, index, re);
 		if (ret) {
-			while (--i >= 0) {
-				dev = bbio->stripes[i].dev;
+			while (--nzones >= 0) {
+				dev = re->zones[nzones]->device;
 				BUG_ON(dev == NULL);
 				/* ignore whether the entry was inserted */
 				radix_tree_delete(&dev->reada_extents, index);
@@ -465,10 +464,9 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	return re;
 
 error:
-	while (nzones) {
+	for (nzones = 0; nzones < re->nzones; ++nzones) {
 		struct reada_zone *zone;
 
-		--nzones;
 		zone = re->zones[nzones];
 		kref_get(&zone->refcnt);
 		spin_lock(&zone->lock);

commit a3f7fde24350a17a589c470265ac2d5a0e6f119f
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 22:57:52 2015 +0800

    btrfs: reada: Move is_need_to_readahead contition earlier
    
    Move is_need_to_readahead contition earlier to avoid useless loop
    to get relative data for readahead.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index f0cf5f3b865a..b2f768a3174a 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -660,7 +660,6 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	u64 logical;
 	int ret;
 	int i;
-	int need_kick = 0;
 
 	spin_lock(&fs_info->reada_lock);
 	if (dev->reada_curr_zone == NULL) {
@@ -696,6 +695,15 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 
 	spin_unlock(&fs_info->reada_lock);
 
+	spin_lock(&re->lock);
+	if (re->scheduled_for || list_empty(&re->extctl)) {
+		spin_unlock(&re->lock);
+		reada_extent_put(fs_info, re);
+		return 0;
+	}
+	re->scheduled_for = dev;
+	spin_unlock(&re->lock);
+
 	/*
 	 * find mirror num
 	 */
@@ -707,18 +715,8 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	}
 	logical = re->logical;
 
-	spin_lock(&re->lock);
-	if (!re->scheduled_for && !list_empty(&re->extctl)) {
-		re->scheduled_for = dev;
-		need_kick = 1;
-	}
-	spin_unlock(&re->lock);
-
 	reada_extent_put(fs_info, re);
 
-	if (!need_kick)
-		return 0;
-
 	atomic_inc(&dev->reada_in_flight);
 	ret = reada_tree_block_flagged(fs_info->extent_root, logical,
 			mirror_num, &eb);

commit 97d5f0e63d78a48cef35349261f90d0d4266dc24
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 16:57:21 2015 +0800

    btrfs: reada: Avoid many times of empty loop
    
    We can see following loop(10000 times) in trace_log:
     [   75.416137] ZL_DEBUG: reada_start_machine_dev:730: pid=771 comm=kworker/u2:3 re->ref_cnt ffff88003741e0c0 1 -> 2
     [   75.417413] ZL_DEBUG: reada_extent_put:524: pid=771 comm=kworker/u2:3 re = ffff88003741e0c0, refcnt = 2 -> 1
     [   75.418611] ZL_DEBUG: __readahead_hook:129: pid=771 comm=kworker/u2:3 re->ref_cnt ffff88003741e0c0 1 -> 2
     [   75.419793] ZL_DEBUG: reada_extent_put:524: pid=771 comm=kworker/u2:3 re = ffff88003741e0c0, refcnt = 2 -> 1
    
     [   75.421016] ZL_DEBUG: reada_start_machine_dev:730: pid=771 comm=kworker/u2:3 re->ref_cnt ffff88003741e0c0 1 -> 2
     [   75.422324] ZL_DEBUG: reada_extent_put:524: pid=771 comm=kworker/u2:3 re = ffff88003741e0c0, refcnt = 2 -> 1
     [   75.423661] ZL_DEBUG: __readahead_hook:129: pid=771 comm=kworker/u2:3 re->ref_cnt ffff88003741e0c0 1 -> 2
     [   75.424882] ZL_DEBUG: reada_extent_put:524: pid=771 comm=kworker/u2:3 re = ffff88003741e0c0, refcnt = 2 -> 1
    
     ...(10000 times)
    
     [  124.101672] ZL_DEBUG: reada_start_machine_dev:730: pid=771 comm=kworker/u2:3 re->ref_cnt ffff88003741e0c0 1 -> 2
     [  124.102850] ZL_DEBUG: reada_extent_put:524: pid=771 comm=kworker/u2:3 re = ffff88003741e0c0, refcnt = 2 -> 1
     [  124.104008] ZL_DEBUG: __readahead_hook:129: pid=771 comm=kworker/u2:3 re->ref_cnt ffff88003741e0c0 1 -> 2
     [  124.105121] ZL_DEBUG: reada_extent_put:524: pid=771 comm=kworker/u2:3 re = ffff88003741e0c0, refcnt = 2 -> 1
    
    Reason:
     If more than one user trigger reada in same extent, the first task
     finished setting of reada data struct and call reada_start_machine()
     to start, and the second task only add a ref_count but have not
     add reada_extctl struct completely, the reada_extent can not finished
     all jobs, and will be selected in __reada_start_machine() for 10000
     times(total times in __reada_start_machine()).
    
    Fix:
     For a reada_extent without job, we don't need to run it, just return
     0 to let caller break.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 7e5d4ac800d9..f0cf5f3b865a 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -708,7 +708,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	logical = re->logical;
 
 	spin_lock(&re->lock);
-	if (re->scheduled_for == NULL) {
+	if (!re->scheduled_for && !list_empty(&re->extctl)) {
 		re->scheduled_for = dev;
 		need_kick = 1;
 	}

commit 8e9aa51f5405b2a01a44818120116b65a2ba4d3a
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Fri Dec 18 21:56:08 2015 +0800

    btrfs: reada: Add missed segment checking in reada_find_zone
    
    In rechecking zone-in-tree, we still need to check zone include
    our logical address.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 74480809be76..7e5d4ac800d9 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -303,8 +303,10 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 		kfree(zone);
 		ret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,
 					     logical >> PAGE_CACHE_SHIFT, 1);
-		if (ret == 1)
+		if (ret == 1 && logical >= zone->start && logical <= zone->end)
 			kref_get(&zone->refcnt);
+		else
+			zone = NULL;
 	}
 	spin_unlock(&fs_info->reada_lock);
 

commit c37f49c7ef317fb8043fd28594d1e5d728a1ef89
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Fri Dec 18 21:48:48 2015 +0800

    btrfs: reada: reduce additional fs_info->reada_lock in reada_find_zone
    
    We can avoid additional locking-acquirment and one pair of
    kref_get/put by combine two condition.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 49b3fb73ffbf..74480809be76 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -260,18 +260,14 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,
 				     logical >> PAGE_CACHE_SHIFT, 1);
-	if (ret == 1)
+	if (ret == 1 && logical >= zone->start && logical <= zone->end) {
 		kref_get(&zone->refcnt);
-	spin_unlock(&fs_info->reada_lock);
-
-	if (ret == 1) {
-		if (logical >= zone->start && logical <= zone->end)
-			return zone;
-		spin_lock(&fs_info->reada_lock);
-		kref_put(&zone->refcnt, reada_zone_release);
 		spin_unlock(&fs_info->reada_lock);
+		return zone;
 	}
 
+	spin_unlock(&fs_info->reada_lock);
+
 	cache = btrfs_lookup_block_group(fs_info, logical);
 	if (!cache)
 		return NULL;

commit 503785306d182ab624a2232856ef8ab503ee85f9
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Fri Dec 18 21:33:05 2015 +0800

    btrfs: reada: Fix in-segment calculation for reada
    
    reada_zone->end is end pos of segment:
     end = start + cache->key.offset - 1;
    
    So we need to use "<=" in condition to judge is a pos in the
    segment.
    
    The problem happened rearly, because logical pos rarely pointed
    to last 4k of a blockgroup, but we need to fix it to make code
    right in logic.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 619f92963e27..49b3fb73ffbf 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -265,7 +265,7 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 	spin_unlock(&fs_info->reada_lock);
 
 	if (ret == 1) {
-		if (logical >= zone->start && logical < zone->end)
+		if (logical >= zone->start && logical <= zone->end)
 			return zone;
 		spin_lock(&fs_info->reada_lock);
 		kref_put(&zone->refcnt, reada_zone_release);
@@ -679,7 +679,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	 */
 	ret = radix_tree_gang_lookup(&dev->reada_extents, (void **)&re,
 				     dev->reada_next >> PAGE_CACHE_SHIFT, 1);
-	if (ret == 0 || re->logical >= dev->reada_curr_zone->end) {
+	if (ret == 0 || re->logical > dev->reada_curr_zone->end) {
 		ret = reada_pick_zone(dev);
 		if (!ret) {
 			spin_unlock(&fs_info->reada_lock);

commit ed0244faf59e33ff915b83acd15c903b81fd357b
Author: David Sterba <dsterba@suse.com>
Date:   Mon Jan 18 18:42:13 2016 +0100

    btrfs: reada: use GFP_KERNEL everywhere
    
    The readahead framework is not on the critical writeback path we don't
    need to use GFP_NOFS for allocations. All error paths are handled and
    the readahead failures are not fatal. The actual users (scrub,
    dev-replace) will trigger reads if the blocks are not found in cache.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 619f92963e27..c5f1773c4794 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -280,7 +280,7 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 	end = start + cache->key.offset - 1;
 	btrfs_put_block_group(cache);
 
-	zone = kzalloc(sizeof(*zone), GFP_NOFS);
+	zone = kzalloc(sizeof(*zone), GFP_KERNEL);
 	if (!zone)
 		return NULL;
 
@@ -343,7 +343,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	if (re)
 		return re;
 
-	re = kzalloc(sizeof(*re), GFP_NOFS);
+	re = kzalloc(sizeof(*re), GFP_KERNEL);
 	if (!re)
 		return NULL;
 
@@ -566,7 +566,7 @@ static int reada_add_block(struct reada_control *rc, u64 logical,
 	if (!re)
 		return -1;
 
-	rec = kzalloc(sizeof(*rec), GFP_NOFS);
+	rec = kzalloc(sizeof(*rec), GFP_KERNEL);
 	if (!rec) {
 		reada_extent_put(root->fs_info, re);
 		return -ENOMEM;
@@ -791,7 +791,7 @@ static void reada_start_machine(struct btrfs_fs_info *fs_info)
 {
 	struct reada_machine_work *rmw;
 
-	rmw = kzalloc(sizeof(*rmw), GFP_NOFS);
+	rmw = kzalloc(sizeof(*rmw), GFP_KERNEL);
 	if (!rmw) {
 		/* FIXME we cannot handle this properly right now */
 		BUG();
@@ -926,7 +926,7 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 		.offset = (u64)-1
 	};
 
-	rc = kzalloc(sizeof(*rc), GFP_NOFS);
+	rc = kzalloc(sizeof(*rc), GFP_KERNEL);
 	if (!rc)
 		return ERR_PTR(-ENOMEM);
 

commit ddd664f4478a4aaf0ac67a4297e33f1992bc9be2
Author: Luis de Bethencourt <luisbg@osg.samsung.com>
Date:   Tue Oct 20 14:56:23 2015 +0100

    btrfs: reada: Fix returned errno code
    
    reada is using -1 instead of the -ENOMEM defined macro to specify that
    a buffer allocation failed. Since the error number is propagated, the
    caller will get a -EPERM which is the wrong error condition.
    
    Also, updating the caller to return the exact value from
    reada_add_block.
    
    Smatch tool warning:
    reada_add_block() warn: returning -1 instead of -ENOMEM is sloppy
    
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Luis de Bethencourt <luisbg@osg.samsung.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 4645cd16d5ba..619f92963e27 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -569,7 +569,7 @@ static int reada_add_block(struct reada_control *rc, u64 logical,
 	rec = kzalloc(sizeof(*rec), GFP_NOFS);
 	if (!rec) {
 		reada_extent_put(root->fs_info, re);
-		return -1;
+		return -ENOMEM;
 	}
 
 	rec->rc = rc;
@@ -918,6 +918,7 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 	u64 start;
 	u64 generation;
 	int level;
+	int ret;
 	struct extent_buffer *node;
 	static struct btrfs_key max_key = {
 		.objectid = (u64)-1,
@@ -943,9 +944,10 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 	generation = btrfs_header_generation(node);
 	free_extent_buffer(node);
 
-	if (reada_add_block(rc, start, &max_key, level, generation)) {
+	ret = reada_add_block(rc, start, &max_key, level, generation);
+	if (ret) {
 		kfree(rc);
-		return ERR_PTR(-ENOMEM);
+		return ERR_PTR(ret);
 	}
 
 	reada_start_machine(root->fs_info);

commit 7cb2c4202ed5730ecbf13c5d34c2cadff4cbe88f
Author: Omar Sandoval <osandov@fb.com>
Date:   Fri Jun 19 11:52:49 2015 -0700

    Btrfs: count devices correctly in readahead during RAID 5/6 replace
    
    Commit 5fbc7c59fd22 ("Btrfs: fix unfinished readahead thread for raid5/6
    degraded mounting") fixed a problem where we would skip a missing device
    when we shouldn't have because there are no other mirrors to read from
    in RAID 5/6. After commit 2c8cdd6ee4e7 ("Btrfs, replace: write dirty
    pages into the replace target device"), the fix doesn't work when we're
    doing a missing device replace on RAID 5/6 because the replace device is
    counted as a mirror so we're tricked into thinking we can safely skip
    the missing device. The fix is to count only the real stripes and decide
    based on that.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 0e7beea92b4c..4645cd16d5ba 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -328,6 +328,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	struct btrfs_device *prev_dev;
 	u32 blocksize;
 	u64 length;
+	int real_stripes;
 	int nzones = 0;
 	int i;
 	unsigned long index = logical >> PAGE_CACHE_SHIFT;
@@ -369,7 +370,8 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		goto error;
 	}
 
-	for (nzones = 0; nzones < bbio->num_stripes; ++nzones) {
+	real_stripes = bbio->num_stripes - bbio->num_tgtdevs;
+	for (nzones = 0; nzones < real_stripes; ++nzones) {
 		struct reada_zone *zone;
 
 		dev = bbio->stripes[nzones].dev;

commit 6e9606d2a2dce098c1739fb3cd82a1c34fd73d3a
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Tue Jan 20 15:11:34 2015 +0800

    Btrfs: add ref_count and free function for btrfs_bio
    
    1: ref_count is simple than current RBIO_HOLD_BBIO_MAP_BIT flag
       to keep btrfs_bio's memory in raid56 recovery implement.
    2: free function for bbio will make code clean and flexible, plus
       forced data type checking in compile.
    
    Changelog v1->v2:
     Rename following by David Sterba's suggestion:
     put_btrfs_bio() -> btrfs_put_bio()
     get_btrfs_bio() -> btrfs_get_bio()
     bbio->ref_count -> bbio->refs
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 4d3d4e5287c5..0e7beea92b4c 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -461,7 +461,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	spin_unlock(&fs_info->reada_lock);
 	btrfs_dev_replace_unlock(&fs_info->dev_replace);
 
-	kfree(bbio);
+	btrfs_put_bbio(bbio);
 	return re;
 
 error:
@@ -486,7 +486,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		kref_put(&zone->refcnt, reada_zone_release);
 		spin_unlock(&fs_info->reada_lock);
 	}
-	kfree(bbio);
+	btrfs_put_bbio(bbio);
 	kfree(re);
 	return re_exist;
 }

commit c0dcaa4d7b66b788b315c418bda3cca75c5938dc
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 02:24:21 2014 +0200

    btrfs: sink blocksize parameter to reada_tree_block_flagged
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 5c3fde6571bb..4d3d4e5287c5 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -721,7 +721,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 
 	atomic_inc(&dev->reada_in_flight);
 	ret = reada_tree_block_flagged(fs_info->extent_root, logical,
-			fs_info->tree_root->nodesize, mirror_num, &eb);
+			mirror_num, &eb);
 	if (ret)
 		__readahead_hook(fs_info->extent_root, NULL, logical, ret);
 	else if (eb)

commit b6ae40ec76dc7589d9f77bd281515be3ad58c533
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 02:18:25 2014 +0200

    btrfs: remove blocksize from reada_extent
    
    Replace with global nodesize instead.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index b63ae20618fb..5c3fde6571bb 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -66,7 +66,6 @@ struct reada_extctl {
 struct reada_extent {
 	u64			logical;
 	struct btrfs_key	top;
-	u32			blocksize;
 	int			err;
 	struct list_head	extctl;
 	int 			refcnt;
@@ -349,7 +348,6 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 
 	blocksize = root->nodesize;
 	re->logical = logical;
-	re->blocksize = blocksize;
 	re->top = *top;
 	INIT_LIST_HEAD(&re->extctl);
 	spin_lock_init(&re->lock);
@@ -660,7 +658,6 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 	int mirror_num = 0;
 	struct extent_buffer *eb = NULL;
 	u64 logical;
-	u32 blocksize;
 	int ret;
 	int i;
 	int need_kick = 0;
@@ -694,7 +691,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 		spin_unlock(&fs_info->reada_lock);
 		return 0;
 	}
-	dev->reada_next = re->logical + re->blocksize;
+	dev->reada_next = re->logical + fs_info->tree_root->nodesize;
 	re->refcnt++;
 
 	spin_unlock(&fs_info->reada_lock);
@@ -709,7 +706,6 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 		}
 	}
 	logical = re->logical;
-	blocksize = re->blocksize;
 
 	spin_lock(&re->lock);
 	if (re->scheduled_for == NULL) {
@@ -724,8 +720,8 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 		return 0;
 
 	atomic_inc(&dev->reada_in_flight);
-	ret = reada_tree_block_flagged(fs_info->extent_root, logical, blocksize,
-			 mirror_num, &eb);
+	ret = reada_tree_block_flagged(fs_info->extent_root, logical,
+			fs_info->tree_root->nodesize, mirror_num, &eb);
 	if (ret)
 		__readahead_hook(fs_info->extent_root, NULL, logical, ret);
 	else if (eb)
@@ -851,7 +847,7 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 				break;
 			printk(KERN_DEBUG
 				"  re: logical %llu size %u empty %d for %lld",
-				re->logical, re->blocksize,
+				re->logical, fs_info->tree_root->nodesize,
 				list_empty(&re->extctl), re->scheduled_for ?
 				re->scheduled_for->devid : -1);
 
@@ -886,7 +882,8 @@ static void dump_devs(struct btrfs_fs_info *fs_info, int all)
 		}
 		printk(KERN_DEBUG
 			"re: logical %llu size %u list empty %d for %lld",
-			re->logical, re->blocksize, list_empty(&re->extctl),
+			re->logical, fs_info->tree_root->nodesize,
+			list_empty(&re->extctl),
 			re->scheduled_for ? re->scheduled_for->devid : -1);
 		for (i = 0; i < re->nzones; ++i) {
 			printk(KERN_CONT " zone %llu-%llu devs",

commit 707e8a071528385a87b63a72a37c2322e463c7b8
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Jun 4 19:22:26 2014 +0200

    btrfs: use nodesize everywhere, kill leafsize
    
    The nodesize and leafsize were never of different values. Unify the
    usage and make nodesize the one. Cleanup the redundant checks and
    helpers.
    
    Shaves a few bytes from .text:
    
      text    data     bss     dec     hex filename
    852418   24560   23112  900090   dbbfa btrfs.ko.before
    851074   24584   23112  898770   db6d2 btrfs.ko.after
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 20408c6b665a..b63ae20618fb 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -347,7 +347,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	if (!re)
 		return NULL;
 
-	blocksize = btrfs_level_size(root, level);
+	blocksize = root->nodesize;
 	re->logical = logical;
 	re->blocksize = blocksize;
 	re->top = *top;

commit 9e0af23764344f7f1b68e4eefbe7dc865018b63d
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Aug 15 23:36:53 2014 +0800

    Btrfs: fix task hang under heavy compressed write
    
    This has been reported and discussed for a long time, and this hang occurs in
    both 3.15 and 3.16.
    
    Btrfs now migrates to use kernel workqueue, but it introduces this hang problem.
    
    Btrfs has a kind of work queued as an ordered way, which means that its
    ordered_func() must be processed in the way of FIFO, so it usually looks like --
    
    normal_work_helper(arg)
        work = container_of(arg, struct btrfs_work, normal_work);
    
        work->func() <---- (we name it work X)
        for ordered_work in wq->ordered_list
                ordered_work->ordered_func()
                ordered_work->ordered_free()
    
    The hang is a rare case, first when we find free space, we get an uncached block
    group, then we go to read its free space cache inode for free space information,
    so it will
    
    file a readahead request
        btrfs_readpages()
             for page that is not in page cache
                    __do_readpage()
                         submit_extent_page()
                               btrfs_submit_bio_hook()
                                     btrfs_bio_wq_end_io()
                                     submit_bio()
                                     end_workqueue_bio() <--(ret by the 1st endio)
                                          queue a work(named work Y) for the 2nd
                                          also the real endio()
    
    So the hang occurs when work Y's work_struct and work X's work_struct happens
    to share the same address.
    
    A bit more explanation,
    
    A,B,C -- struct btrfs_work
    arg   -- struct work_struct
    
    kthread:
    worker_thread()
        pick up a work_struct from @worklist
        process_one_work(arg)
            worker->current_work = arg;  <-- arg is A->normal_work
            worker->current_func(arg)
                    normal_work_helper(arg)
                         A = container_of(arg, struct btrfs_work, normal_work);
    
                         A->func()
                         A->ordered_func()
                         A->ordered_free()  <-- A gets freed
    
                         B->ordered_func()
                              submit_compressed_extents()
                                  find_free_extent()
                                      load_free_space_inode()
                                          ...   <-- (the above readhead stack)
                                          end_workqueue_bio()
                                               btrfs_queue_work(work C)
                         B->ordered_free()
    
    As if work A has a high priority in wq->ordered_list and there are more ordered
    works queued after it, such as B->ordered_func(), its memory could have been
    freed before normal_work_helper() returns, which means that kernel workqueue
    code worker_thread() still has worker->current_work pointer to be work
    A->normal_work's, ie. arg's address.
    
    Meanwhile, work C is allocated after work A is freed, work C->normal_work
    and work A->normal_work are likely to share the same address(I confirmed this
    with ftrace output, so I'm not just guessing, it's rare though).
    
    When another kthread picks up work C->normal_work to process, and finds our
    kthread is processing it(see find_worker_executing_work()), it'll think
    work C as a collision and skip then, which ends up nobody processing work C.
    
    So the situation is that our kthread is waiting forever on work C.
    
    Besides, there're other cases that can lead to deadlock, but the real problem
    is that all btrfs workqueue shares one work->func, -- normal_work_helper,
    so this makes each workqueue to have its own helper function, but only a
    wraper pf normal_work_helper.
    
    With this patch, I no long hit the above hang.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 09230cf3a244..20408c6b665a 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -798,7 +798,8 @@ static void reada_start_machine(struct btrfs_fs_info *fs_info)
 		/* FIXME we cannot handle this properly right now */
 		BUG();
 	}
-	btrfs_init_work(&rmw->work, reada_start_machine_worker, NULL, NULL);
+	btrfs_init_work(&rmw->work, btrfs_readahead_helper,
+			reada_start_machine_worker, NULL, NULL);
 	rmw->fs_info = fs_info;
 
 	btrfs_queue_work(fs_info->readahead_workers, &rmw->work);

commit 5fbc7c59fd22c5a6531b40b0759624b680a95e52
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Wed Jun 11 10:55:22 2014 +0800

    Btrfs: fix unfinished readahead thread for raid5/6 degraded mounting
    
    Steps to reproduce:
    
     # mkfs.btrfs -f /dev/sd[b-f] -m raid5 -d raid5
     # mkfs.ext4 /dev/sdc --->corrupt one of btrfs device
     # mount /dev/sdb /mnt -o degraded
     # btrfs scrub start -BRd /mnt
    
    This is because readahead would skip missing device, this is not true
    for RAID5/6, because REQ_GET_READ_MIRRORS return 1 for RAID5/6 block
    mapping. If expected data locates in missing device, readahead thread
    would not call __readahead_hook() which makes event @rc->elems=0
    wait forever.
    
    Fix this problem by checking return value of btrfs_map_block(),we
    can only skip missing device safely if there are several mirrors.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 30947f923620..09230cf3a244 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -428,8 +428,13 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 			continue;
 		}
 		if (!dev->bdev) {
-			/* cannot read ahead on missing device */
-			continue;
+			/*
+			 * cannot read ahead on missing device, but for RAID5/6,
+			 * REQ_GET_READ_MIRRORS return 1. So don't skip missing
+			 * device for such case.
+			 */
+			if (nzones > 1)
+				continue;
 		}
 		if (dev_replace_is_ongoing &&
 		    dev == fs_info->dev_replace.tgtdev) {

commit d458b0540ebd728b4d6ef47cc5ef0dbfd4dd361a
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:19 2014 +0800

    btrfs: Cleanup the "_struct" suffix in btrfs_workequeue
    
    Since the "_struct" suffix is mainly used for distinguish the differnt
    btrfs_work between the original and the newly created one,
    there is no need using the suffix since all btrfs_workers are changed
    into btrfs_workqueue.
    
    Also this patch fixed some codes whose code style is changed due to the
    too long "_struct" suffix.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 9e01d3677355..30947f923620 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -91,8 +91,7 @@ struct reada_zone {
 };
 
 struct reada_machine_work {
-	struct btrfs_work_struct
-				work;
+	struct btrfs_work	work;
 	struct btrfs_fs_info	*fs_info;
 };
 
@@ -734,7 +733,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 
 }
 
-static void reada_start_machine_worker(struct btrfs_work_struct *work)
+static void reada_start_machine_worker(struct btrfs_work *work)
 {
 	struct reada_machine_work *rmw;
 	struct btrfs_fs_info *fs_info;

commit 736cfa15e89a654436d4149c109bf1ae09fc67cf
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:13 2014 +0800

    btrfs: Replace fs_info->readahead_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->readahead_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 31c797c48c3e..9e01d3677355 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -91,7 +91,8 @@ struct reada_zone {
 };
 
 struct reada_machine_work {
-	struct btrfs_work	work;
+	struct btrfs_work_struct
+				work;
 	struct btrfs_fs_info	*fs_info;
 };
 
@@ -733,7 +734,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 
 }
 
-static void reada_start_machine_worker(struct btrfs_work *work)
+static void reada_start_machine_worker(struct btrfs_work_struct *work)
 {
 	struct reada_machine_work *rmw;
 	struct btrfs_fs_info *fs_info;
@@ -793,10 +794,10 @@ static void reada_start_machine(struct btrfs_fs_info *fs_info)
 		/* FIXME we cannot handle this properly right now */
 		BUG();
 	}
-	rmw->work.func = reada_start_machine_worker;
+	btrfs_init_work(&rmw->work, reada_start_machine_worker, NULL, NULL);
 	rmw->fs_info = fs_info;
 
-	btrfs_queue_worker(&fs_info->readahead_workers, &rmw->work);
+	btrfs_queue_work(fs_info->readahead_workers, &rmw->work);
 }
 
 #ifdef DEBUG

commit efe120a067c8674a8ae21b194f0e68f098b61ee2
Author: Frank Holton <fholton@gmail.com>
Date:   Fri Dec 20 11:37:06 2013 -0500

    Btrfs: convert printk to btrfs_ and fix BTRFS prefix
    
    Convert all applicable cases of printk and pr_* to the btrfs_* macros.
    
    Fix all uses of the BTRFS prefix.
    
    Signed-off-by: Frank Holton <fholton@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 1031b69252c5..31c797c48c3e 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -189,8 +189,8 @@ static int __readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 			 */
 #ifdef DEBUG
 			if (rec->generation != generation) {
-				printk(KERN_DEBUG "generation mismatch for "
-						"(%llu,%d,%llu) %llu != %llu\n",
+				btrfs_debug(root->fs_info,
+					   "generation mismatch for (%llu,%d,%llu) %llu != %llu",
 				       key.objectid, key.type, key.offset,
 				       rec->generation, generation);
 			}
@@ -365,8 +365,9 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		goto error;
 
 	if (bbio->num_stripes > BTRFS_MAX_MIRRORS) {
-		printk(KERN_ERR "btrfs readahead: more than %d copies not "
-				"supported", BTRFS_MAX_MIRRORS);
+		btrfs_err(root->fs_info,
+			   "readahead: more than %d copies not supported",
+			   BTRFS_MAX_MIRRORS);
 		goto error;
 	}
 

commit 3c59ccd32abb8f636b1573533d3e77972e80a9c9
Author: Vincent <vincent.stehle@laposte.net>
Date:   Tue Apr 16 08:15:25 2013 +0000

    Btrfs: fix reada debug code compilation
    
    This fixes the following errors:
    
      fs/btrfs/reada.c: In function btrfs_reada_wait:
      fs/btrfs/reada.c:958:42: error: invalid operands to binary < (have atomic_t and int)
      fs/btrfs/reada.c:961:41: error: invalid operands to binary < (have atomic_t and int)
    
    Signed-off-by: Vincent Stehl <vincent.stehle@laposte.net>
    Cc: Chris Mason <chris.mason@fusionio.com>
    Cc: linux-btrfs@vger.kernel.org
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 96b93daa0bbb..1031b69252c5 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -955,10 +955,11 @@ int btrfs_reada_wait(void *handle)
 	while (atomic_read(&rc->elems)) {
 		wait_event_timeout(rc->wait, atomic_read(&rc->elems) == 0,
 				   5 * HZ);
-		dump_devs(rc->root->fs_info, rc->elems < 10 ? 1 : 0);
+		dump_devs(rc->root->fs_info,
+			  atomic_read(&rc->elems) < 10 ? 1 : 0);
 	}
 
-	dump_devs(rc->root->fs_info, rc->elems < 10 ? 1 : 0);
+	dump_devs(rc->root->fs_info, atomic_read(&rc->elems) < 10 ? 1 : 0);
 
 	kref_put(&rc->refcnt, reada_control_release);
 

commit 29a8d9a0bce6a5abac1f313400c2e189e8d10e67
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Nov 6 14:16:24 2012 +0100

    Btrfs: introduce GET_READ_MIRRORS functionality for btrfs_map_block()
    
    Before this commit, btrfs_map_block() was called with REQ_WRITE
    in order to retrieve the list of mirrors for a disk block.
    This needs to be changed for the device replace procedure since
    it makes a difference whether you are asking for read mirrors
    or for locations to write to.
    GET_READ_MIRRORS is introduced as a new interface to call
    btrfs_map_block().
    In the current commit, the functionality is not yet changed,
    only the interface for GET_READ_MIRRORS is introduced and all
    the places that should use this new interface are adapted.
    
    The reason that REQ_WRITE cannot be abused anymore to retrieve
    a list of read mirrors is that during a running dev replace
    operation all write requests to the live filesystem are
    duplicated to also write to the target drive.
    Keep in mind that the target disk is only partially a valid
    copy of the source disk while the operation is ongoing. All
    writes go to the target disk, but not all reads would return
    valid data on the target disk. Therefore it is not possible
    anymore to abuse a REQ_WRITE interface to find valid mirrors
    for a REQ_READ.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index c705a48e676b..96b93daa0bbb 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -359,7 +359,8 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	 * map block
 	 */
 	length = blocksize;
-	ret = btrfs_map_block(fs_info, REQ_WRITE, logical, &length, &bbio, 0);
+	ret = btrfs_map_block(fs_info, REQ_GET_READ_MIRRORS, logical, &length,
+			      &bbio, 0);
 	if (ret || !bbio || length < blocksize)
 		goto error;
 

commit 8dabb7420f014ab0f9f04afae8ae046c0f48b270
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Nov 6 13:15:27 2012 +0100

    Btrfs: change core code of btrfs to support the device replace operations
    
    This commit contains all the essential changes to the core code
    of Btrfs for support of the device replace procedure.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 9f363e17ec74..c705a48e676b 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -27,6 +27,7 @@
 #include "volumes.h"
 #include "disk-io.h"
 #include "transaction.h"
+#include "dev-replace.h"
 
 #undef DEBUG
 
@@ -331,6 +332,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	int nzones = 0;
 	int i;
 	unsigned long index = logical >> PAGE_CACHE_SHIFT;
+	int dev_replace_is_ongoing;
 
 	spin_lock(&fs_info->reada_lock);
 	re = radix_tree_lookup(&fs_info->reada_tree, index);
@@ -392,6 +394,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	}
 
 	/* insert extent in reada_tree + all per-device trees, all or nothing */
+	btrfs_dev_replace_lock(&fs_info->dev_replace);
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_insert(&fs_info->reada_tree, index, re);
 	if (ret == -EEXIST) {
@@ -399,13 +402,17 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		BUG_ON(!re_exist);
 		re_exist->refcnt++;
 		spin_unlock(&fs_info->reada_lock);
+		btrfs_dev_replace_unlock(&fs_info->dev_replace);
 		goto error;
 	}
 	if (ret) {
 		spin_unlock(&fs_info->reada_lock);
+		btrfs_dev_replace_unlock(&fs_info->dev_replace);
 		goto error;
 	}
 	prev_dev = NULL;
+	dev_replace_is_ongoing = btrfs_dev_replace_is_ongoing(
+			&fs_info->dev_replace);
 	for (i = 0; i < nzones; ++i) {
 		dev = bbio->stripes[i].dev;
 		if (dev == prev_dev) {
@@ -422,6 +429,14 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 			/* cannot read ahead on missing device */
 			continue;
 		}
+		if (dev_replace_is_ongoing &&
+		    dev == fs_info->dev_replace.tgtdev) {
+			/*
+			 * as this device is selected for reading only as
+			 * a last resort, skip it for read ahead.
+			 */
+			continue;
+		}
 		prev_dev = dev;
 		ret = radix_tree_insert(&dev->reada_extents, index, re);
 		if (ret) {
@@ -434,10 +449,12 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 			BUG_ON(fs_info == NULL);
 			radix_tree_delete(&fs_info->reada_tree, index);
 			spin_unlock(&fs_info->reada_lock);
+			btrfs_dev_replace_unlock(&fs_info->dev_replace);
 			goto error;
 		}
 	}
 	spin_unlock(&fs_info->reada_lock);
+	btrfs_dev_replace_unlock(&fs_info->dev_replace);
 
 	kfree(bbio);
 	return re;

commit ff023aac31198e88507d626825379b28ea481d4d
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Nov 6 11:43:11 2012 +0100

    Btrfs: add code to scrub to copy read data to another disk
    
    The device replace procedure makes use of the scrub code. The scrub
    code is the most efficient code to read the allocated data of a disk,
    i.e. it reads sequentially in order to avoid disk head movements, it
    skips unallocated blocks, it uses read ahead mechanisms, and it
    contains all the code to detect and repair defects.
    This commit adds code to scrub to allow the scrub code to copy read
    data to another disk.
    One goal is to be able to perform as fast as possible. Therefore the
    write requests are collected until huge bios are built, and the
    write process is decoupled from the read process with some kind of
    flow control, of course, in order to limit the allocated memory.
    The best performance on spinning disks could by reached when the
    head movements are avoided as much as possible. Therefore a single
    worker is used to interface the read process with the write process.
    The regular scrub operation works as fast as before, it is not
    negatively influenced and actually it is more or less unchanged.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 0ddc5659f946..9f363e17ec74 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -418,12 +418,17 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 			 */
 			continue;
 		}
+		if (!dev->bdev) {
+			/* cannot read ahead on missing device */
+			continue;
+		}
 		prev_dev = dev;
 		ret = radix_tree_insert(&dev->reada_extents, index, re);
 		if (ret) {
 			while (--i >= 0) {
 				dev = bbio->stripes[i].dev;
 				BUG_ON(dev == NULL);
+				/* ignore whether the entry was inserted */
 				radix_tree_delete(&dev->reada_extents, index);
 			}
 			BUG_ON(fs_info == NULL);
@@ -914,7 +919,10 @@ struct reada_control *btrfs_reada_add(struct btrfs_root *root,
 	generation = btrfs_header_generation(node);
 	free_extent_buffer(node);
 
-	reada_add_block(rc, start, &max_key, level, generation);
+	if (reada_add_block(rc, start, &max_key, level, generation)) {
+		kfree(rc);
+		return ERR_PTR(-ENOMEM);
+	}
 
 	reada_start_machine(root->fs_info);
 

commit 3ec706c831d4c96905c287013c8228b21619a1d9
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 15:46:42 2012 +0100

    Btrfs: pass fs_info to btrfs_map_block() instead of mapping_tree
    
    This is required for the device replace procedure in a later step.
    Two calling functions also had to be changed to have the fs_info
    pointer: repair_io_failure() and scrub_setup_recheck_block().
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index a955669519a2..0ddc5659f946 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -323,7 +323,6 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	struct reada_extent *re = NULL;
 	struct reada_extent *re_exist = NULL;
 	struct btrfs_fs_info *fs_info = root->fs_info;
-	struct btrfs_mapping_tree *map_tree = &fs_info->mapping_tree;
 	struct btrfs_bio *bbio = NULL;
 	struct btrfs_device *dev;
 	struct btrfs_device *prev_dev;
@@ -358,7 +357,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	 * map block
 	 */
 	length = blocksize;
-	ret = btrfs_map_block(map_tree, REQ_WRITE, logical, &length, &bbio, 0);
+	ret = btrfs_map_block(fs_info, REQ_WRITE, logical, &length, &bbio, 0);
 	if (ret || !bbio || length < blocksize)
 		goto error;
 

commit 99621b44aa194eab594e1f17217231c02b519211
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Aug 29 16:31:33 2012 -0400

    btrfs: reada_extent doesn't need kref for refcount
    
    All increments and decrements are under the same spinlock - have to be,
    since they need to protect the radix_tree it's found in.  Just use
    int, no need to wank with kref...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 48a4882d8ad5..a955669519a2 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -68,7 +68,7 @@ struct reada_extent {
 	u32			blocksize;
 	int			err;
 	struct list_head	extctl;
-	struct kref		refcnt;
+	int 			refcnt;
 	spinlock_t		lock;
 	struct reada_zone	*zones[BTRFS_MAX_MIRRORS];
 	int			nzones;
@@ -126,7 +126,7 @@ static int __readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 	spin_lock(&fs_info->reada_lock);
 	re = radix_tree_lookup(&fs_info->reada_tree, index);
 	if (re)
-		kref_get(&re->refcnt);
+		re->refcnt++;
 	spin_unlock(&fs_info->reada_lock);
 
 	if (!re)
@@ -336,7 +336,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	spin_lock(&fs_info->reada_lock);
 	re = radix_tree_lookup(&fs_info->reada_tree, index);
 	if (re)
-		kref_get(&re->refcnt);
+		re->refcnt++;
 	spin_unlock(&fs_info->reada_lock);
 
 	if (re)
@@ -352,7 +352,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	re->top = *top;
 	INIT_LIST_HEAD(&re->extctl);
 	spin_lock_init(&re->lock);
-	kref_init(&re->refcnt);
+	re->refcnt = 1;
 
 	/*
 	 * map block
@@ -398,7 +398,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	if (ret == -EEXIST) {
 		re_exist = radix_tree_lookup(&fs_info->reada_tree, index);
 		BUG_ON(!re_exist);
-		kref_get(&re_exist->refcnt);
+		re_exist->refcnt++;
 		spin_unlock(&fs_info->reada_lock);
 		goto error;
 	}
@@ -465,10 +465,6 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	return re_exist;
 }
 
-static void reada_kref_dummy(struct kref *kr)
-{
-}
-
 static void reada_extent_put(struct btrfs_fs_info *fs_info,
 			     struct reada_extent *re)
 {
@@ -476,7 +472,7 @@ static void reada_extent_put(struct btrfs_fs_info *fs_info,
 	unsigned long index = re->logical >> PAGE_CACHE_SHIFT;
 
 	spin_lock(&fs_info->reada_lock);
-	if (!kref_put(&re->refcnt, reada_kref_dummy)) {
+	if (--re->refcnt) {
 		spin_unlock(&fs_info->reada_lock);
 		return;
 	}
@@ -671,7 +667,7 @@ static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
 		return 0;
 	}
 	dev->reada_next = re->logical + re->blocksize;
-	kref_get(&re->refcnt);
+	re->refcnt++;
 
 	spin_unlock(&fs_info->reada_lock);
 

commit 3d136a1131c66f7d26fb171e4c5b0b8baacd3129
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri Feb 3 11:20:04 2012 +0100

    Btrfs: set ioprio of scrub readahead to idle
    
    Reduce ioprio class of scrub readahead threads to idle priority.
    This setting is fixed. This priority has shown the best performance
    during all measurements.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index ac5d01085884..48a4882d8ad5 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -718,13 +718,18 @@ static void reada_start_machine_worker(struct btrfs_work *work)
 {
 	struct reada_machine_work *rmw;
 	struct btrfs_fs_info *fs_info;
+	int old_ioprio;
 
 	rmw = container_of(work, struct reada_machine_work, work);
 	fs_info = rmw->fs_info;
 
 	kfree(rmw);
 
+	old_ioprio = IOPRIO_PRIO_VALUE(task_nice_ioclass(current),
+				       task_nice_ioprio(current));
+	set_task_ioprio(current, BTRFS_IOPRIO_READA);
 	__reada_start_machine(fs_info);
+	set_task_ioprio(current, old_ioprio);
 }
 
 static void __reada_start_machine(struct btrfs_fs_info *fs_info)

commit 207a232ccac0a8cb79d304bd17298dbc96e2e082
Author: Arne Jansen <sensille@gmx.net>
Date:   Sat Feb 25 09:09:47 2012 +0100

    btrfs: don't add both copies of DUP to reada extent tree
    
    Normally when there are 2 copies of a block, we add both to the
    reada extent tree and prefetch only the one that is easier to reach.
    This way we can better utilize multiple devices.
    In case of DUP this makes no sense as both copies reside on the
    same device.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 8dec650099c8..ac5d01085884 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -326,6 +326,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	struct btrfs_mapping_tree *map_tree = &fs_info->mapping_tree;
 	struct btrfs_bio *bbio = NULL;
 	struct btrfs_device *dev;
+	struct btrfs_device *prev_dev;
 	u32 blocksize;
 	u64 length;
 	int nzones = 0;
@@ -405,8 +406,20 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		spin_unlock(&fs_info->reada_lock);
 		goto error;
 	}
+	prev_dev = NULL;
 	for (i = 0; i < nzones; ++i) {
 		dev = bbio->stripes[i].dev;
+		if (dev == prev_dev) {
+			/*
+			 * in case of DUP, just add the first zone. As both
+			 * are on the same device, there's nothing to gain
+			 * from adding both.
+			 * Also, it wouldn't work, as the tree is per device
+			 * and adding would fail with EEXIST
+			 */
+			continue;
+		}
+		prev_dev = dev;
 		ret = radix_tree_insert(&dev->reada_extents, index, re);
 		if (ret) {
 			while (--i >= 0) {

commit 8c9c2bf7a3c4f7e9d158c0be9c49f372fb943ad2
Author: Arne Jansen <sensille@gmx.net>
Date:   Sat Feb 25 09:09:30 2012 +0100

    btrfs: fix race in reada
    
    When inserting into the radix tree returns EEXIST, get the existing
    entry without giving up the spinlock in between.
    There was a race for both the zones trees and the extent tree.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index dc5d33146fdb..8dec650099c8 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -250,14 +250,12 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 					  struct btrfs_bio *bbio)
 {
 	int ret;
-	int looped = 0;
 	struct reada_zone *zone;
 	struct btrfs_block_group_cache *cache = NULL;
 	u64 start;
 	u64 end;
 	int i;
 
-again:
 	zone = NULL;
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,
@@ -274,9 +272,6 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 		spin_unlock(&fs_info->reada_lock);
 	}
 
-	if (looped)
-		return NULL;
-
 	cache = btrfs_lookup_block_group(fs_info, logical);
 	if (!cache)
 		return NULL;
@@ -307,13 +302,15 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 	ret = radix_tree_insert(&dev->reada_zones,
 				(unsigned long)(zone->end >> PAGE_CACHE_SHIFT),
 				zone);
-	spin_unlock(&fs_info->reada_lock);
 
-	if (ret) {
+	if (ret == -EEXIST) {
 		kfree(zone);
-		looped = 1;
-		goto again;
+		ret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,
+					     logical >> PAGE_CACHE_SHIFT, 1);
+		if (ret == 1)
+			kref_get(&zone->refcnt);
 	}
+	spin_unlock(&fs_info->reada_lock);
 
 	return zone;
 }
@@ -323,8 +320,8 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 					      struct btrfs_key *top, int level)
 {
 	int ret;
-	int looped = 0;
 	struct reada_extent *re = NULL;
+	struct reada_extent *re_exist = NULL;
 	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_mapping_tree *map_tree = &fs_info->mapping_tree;
 	struct btrfs_bio *bbio = NULL;
@@ -335,14 +332,13 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	int i;
 	unsigned long index = logical >> PAGE_CACHE_SHIFT;
 
-again:
 	spin_lock(&fs_info->reada_lock);
 	re = radix_tree_lookup(&fs_info->reada_tree, index);
 	if (re)
 		kref_get(&re->refcnt);
 	spin_unlock(&fs_info->reada_lock);
 
-	if (re || looped)
+	if (re)
 		return re;
 
 	re = kzalloc(sizeof(*re), GFP_NOFS);
@@ -398,12 +394,15 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	/* insert extent in reada_tree + all per-device trees, all or nothing */
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_insert(&fs_info->reada_tree, index, re);
+	if (ret == -EEXIST) {
+		re_exist = radix_tree_lookup(&fs_info->reada_tree, index);
+		BUG_ON(!re_exist);
+		kref_get(&re_exist->refcnt);
+		spin_unlock(&fs_info->reada_lock);
+		goto error;
+	}
 	if (ret) {
 		spin_unlock(&fs_info->reada_lock);
-		if (ret != -ENOMEM) {
-			/* someone inserted the extent in the meantime */
-			looped = 1;
-		}
 		goto error;
 	}
 	for (i = 0; i < nzones; ++i) {
@@ -450,9 +449,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	}
 	kfree(bbio);
 	kfree(re);
-	if (looped)
-		goto again;
-	return NULL;
+	return re_exist;
 }
 
 static void reada_kref_dummy(struct kref *kr)

commit 94598ba8d8ff066115508fb99e593d2de1ca67e1
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Mar 27 14:21:26 2012 -0400

    Btrfs: introduce common define for max number of mirrors
    
    Readahead already has a define for the max number of mirrors. Scrub
    needs such a define now, the rest of the code will need something
    like this soon. Therefore the define was added to ctree.h and removed
    from the readahead code.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 22db04550f6a..dc5d33146fdb 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -54,7 +54,6 @@
  * than the 2 started one after another.
  */
 
-#define MAX_MIRRORS 2
 #define MAX_IN_FLIGHT 6
 
 struct reada_extctl {
@@ -71,7 +70,7 @@ struct reada_extent {
 	struct list_head	extctl;
 	struct kref		refcnt;
 	spinlock_t		lock;
-	struct reada_zone	*zones[MAX_MIRRORS];
+	struct reada_zone	*zones[BTRFS_MAX_MIRRORS];
 	int			nzones;
 	struct btrfs_device	*scheduled_for;
 };
@@ -84,7 +83,8 @@ struct reada_zone {
 	spinlock_t		lock;
 	int			locked;
 	struct btrfs_device	*device;
-	struct btrfs_device	*devs[MAX_MIRRORS]; /* full list, incl self */
+	struct btrfs_device	*devs[BTRFS_MAX_MIRRORS]; /* full list, incl
+							   * self */
 	int			ndevs;
 	struct kref		refcnt;
 };
@@ -365,9 +365,9 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	if (ret || !bbio || length < blocksize)
 		goto error;
 
-	if (bbio->num_stripes > MAX_MIRRORS) {
+	if (bbio->num_stripes > BTRFS_MAX_MIRRORS) {
 		printk(KERN_ERR "btrfs readahead: more than %d copies not "
-				"supported", MAX_MIRRORS);
+				"supported", BTRFS_MAX_MIRRORS);
 		goto error;
 	}
 

commit a175423c831ea582c06784d1e172d2ce1d79923a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Feb 28 12:42:44 2012 -0500

    Btrfs: fix casting error in scrub reada code
    
    The reada code from scrub was casting down a u64 to
    an unsigned long so it could insert it into a radix tree.
    
    What it really wanted to do was cast down the result of a shift, instead
    of casting down the u64.  The bug resulted in trying to insert our
    reada struct into the wrong place, which caused soft lockups and other
    problems.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 2373b39a132b..22db04550f6a 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -305,7 +305,7 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_insert(&dev->reada_zones,
-				(unsigned long)zone->end >> PAGE_CACHE_SHIFT,
+				(unsigned long)(zone->end >> PAGE_CACHE_SHIFT),
 				zone);
 	spin_unlock(&fs_info->reada_lock);
 

commit 21ca543efc12674fddb22ddf4ea4906427f4e982
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Fri Nov 4 09:41:02 2011 -0400

    Btrfs: rename btrfs_bio multi -> bbio for consistency
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index 35eaf6893679..2373b39a132b 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -247,7 +247,7 @@ int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
 
 static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 					  struct btrfs_device *dev, u64 logical,
-					  struct btrfs_bio *multi)
+					  struct btrfs_bio *bbio)
 {
 	int ret;
 	int looped = 0;
@@ -297,11 +297,11 @@ static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
 	kref_init(&zone->refcnt);
 	zone->elems = 0;
 	zone->device = dev; /* our device always sits at index 0 */
-	for (i = 0; i < multi->num_stripes; ++i) {
+	for (i = 0; i < bbio->num_stripes; ++i) {
 		/* bounds have already been checked */
-		zone->devs[i] = multi->stripes[i].dev;
+		zone->devs[i] = bbio->stripes[i].dev;
 	}
-	zone->ndevs = multi->num_stripes;
+	zone->ndevs = bbio->num_stripes;
 
 	spin_lock(&fs_info->reada_lock);
 	ret = radix_tree_insert(&dev->reada_zones,
@@ -327,7 +327,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	struct reada_extent *re = NULL;
 	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_mapping_tree *map_tree = &fs_info->mapping_tree;
-	struct btrfs_bio *multi = NULL;
+	struct btrfs_bio *bbio = NULL;
 	struct btrfs_device *dev;
 	u32 blocksize;
 	u64 length;
@@ -361,21 +361,21 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	 * map block
 	 */
 	length = blocksize;
-	ret = btrfs_map_block(map_tree, REQ_WRITE, logical, &length, &multi, 0);
-	if (ret || !multi || length < blocksize)
+	ret = btrfs_map_block(map_tree, REQ_WRITE, logical, &length, &bbio, 0);
+	if (ret || !bbio || length < blocksize)
 		goto error;
 
-	if (multi->num_stripes > MAX_MIRRORS) {
+	if (bbio->num_stripes > MAX_MIRRORS) {
 		printk(KERN_ERR "btrfs readahead: more than %d copies not "
 				"supported", MAX_MIRRORS);
 		goto error;
 	}
 
-	for (nzones = 0; nzones < multi->num_stripes; ++nzones) {
+	for (nzones = 0; nzones < bbio->num_stripes; ++nzones) {
 		struct reada_zone *zone;
 
-		dev = multi->stripes[nzones].dev;
-		zone = reada_find_zone(fs_info, dev, logical, multi);
+		dev = bbio->stripes[nzones].dev;
+		zone = reada_find_zone(fs_info, dev, logical, bbio);
 		if (!zone)
 			break;
 
@@ -407,11 +407,11 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		goto error;
 	}
 	for (i = 0; i < nzones; ++i) {
-		dev = multi->stripes[i].dev;
+		dev = bbio->stripes[i].dev;
 		ret = radix_tree_insert(&dev->reada_extents, index, re);
 		if (ret) {
 			while (--i >= 0) {
-				dev = multi->stripes[i].dev;
+				dev = bbio->stripes[i].dev;
 				BUG_ON(dev == NULL);
 				radix_tree_delete(&dev->reada_extents, index);
 			}
@@ -423,7 +423,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	}
 	spin_unlock(&fs_info->reada_lock);
 
-	kfree(multi);
+	kfree(bbio);
 	return re;
 
 error:
@@ -448,7 +448,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		kref_put(&zone->refcnt, reada_zone_release);
 		spin_unlock(&fs_info->reada_lock);
 	}
-	kfree(multi);
+	kfree(bbio);
 	kfree(re);
 	if (looped)
 		goto again;

commit 9510dc4c62252e96dca44a94948327c76774f25b
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Fri Nov 4 09:41:02 2011 -0400

    Btrfs: stop leaking btrfs_bios on readahead
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
index cd857119ba8a..35eaf6893679 100644
--- a/fs/btrfs/reada.c
+++ b/fs/btrfs/reada.c
@@ -423,6 +423,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 	}
 	spin_unlock(&fs_info->reada_lock);
 
+	kfree(multi);
 	return re;
 
 error:
@@ -447,6 +448,7 @@ static struct reada_extent *reada_find_extent(struct btrfs_root *root,
 		kref_put(&zone->refcnt, reada_zone_release);
 		spin_unlock(&fs_info->reada_lock);
 	}
+	kfree(multi);
 	kfree(re);
 	if (looped)
 		goto again;

commit 806468f8bf76a3cb2b626dd282946a6c9c0a50f0
Merge: 531f4b1ae5e0 5da6fcbc4eb5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Nov 6 03:07:10 2011 -0500

    Merge git://git.jan-o-sch.net/btrfs-unstable into integration
    
    Conflicts:
            fs/btrfs/Makefile
            fs/btrfs/extent_io.c
            fs/btrfs/extent_io.h
            fs/btrfs/scrub.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 7414a03fbf9e75fbbf2a3c16828cd862e572aa44
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon May 23 14:33:49 2011 +0200

    btrfs: initial readahead code and prototypes
    
    This is the implementation for the generic read ahead framework.
    
    To trigger a readahead, btrfs_reada_add must be called. It will start
    a read ahead for the given range [start, end) on tree root. The returned
    handle can either be used to wait on the readahead to finish
    (btrfs_reada_wait), or to send it to the background (btrfs_reada_detach).
    
    The read ahead works as follows:
    On btrfs_reada_add, the root of the tree is inserted into a radix_tree.
    reada_start_machine will then search for extents to prefetch and trigger
    some reads. When a read finishes for a node, all contained node/leaf
    pointers that lie in the given range will also be enqueued. The reads will
    be triggered in sequential order, thus giving a big win over a naive
    enumeration. It will also make use of multi-device layouts. Each disk
    will have its on read pointer and all disks will by utilized in parallel.
    Also will no two disks read both sides of a mirror simultaneously, as this
    would waste seeking capacity. Instead both disks will read different parts
    of the filesystem.
    Any number of readaheads can be started in parallel. The read order will be
    determined globally, i.e. 2 parallel readaheads will normally finish faster
    than the 2 started one after another.
    
    Changes v2:
     - protect root->node by transaction instead of node_lock
     - fix missed branches:
        The readahead had a too simple check to determine if a branch from
        a node should be checked or not. It now also records the upper bound
        of each node to see if the requested RA range lies within.
     - use KERN_CONT to debug output, to avoid line breaks
     - defer reada_start_machine to worker to avoid deadlock
    
    Changes v3:
     - protect root->node by rcu
    
    Changes v5:
     - changed EIO-semantics of reada_tree_block_flagged
     - remove spin_lock from reada_control and make elems an atomic_t
     - remove unused read_total from reada_control
     - kill reada_key_cmp, use btrfs_comp_cpu_keys instead
     - use kref-style release functions where possible
     - return struct reada_control * instead of void * from btrfs_reada_add
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/reada.c b/fs/btrfs/reada.c
new file mode 100644
index 000000000000..2b701d082227
--- /dev/null
+++ b/fs/btrfs/reada.c
@@ -0,0 +1,949 @@
+/*
+ * Copyright (C) 2011 STRATO.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
+#include <linux/sched.h>
+#include <linux/pagemap.h>
+#include <linux/writeback.h>
+#include <linux/blkdev.h>
+#include <linux/rbtree.h>
+#include <linux/slab.h>
+#include <linux/workqueue.h>
+#include "ctree.h"
+#include "volumes.h"
+#include "disk-io.h"
+#include "transaction.h"
+
+#undef DEBUG
+
+/*
+ * This is the implementation for the generic read ahead framework.
+ *
+ * To trigger a readahead, btrfs_reada_add must be called. It will start
+ * a read ahead for the given range [start, end) on tree root. The returned
+ * handle can either be used to wait on the readahead to finish
+ * (btrfs_reada_wait), or to send it to the background (btrfs_reada_detach).
+ *
+ * The read ahead works as follows:
+ * On btrfs_reada_add, the root of the tree is inserted into a radix_tree.
+ * reada_start_machine will then search for extents to prefetch and trigger
+ * some reads. When a read finishes for a node, all contained node/leaf
+ * pointers that lie in the given range will also be enqueued. The reads will
+ * be triggered in sequential order, thus giving a big win over a naive
+ * enumeration. It will also make use of multi-device layouts. Each disk
+ * will have its on read pointer and all disks will by utilized in parallel.
+ * Also will no two disks read both sides of a mirror simultaneously, as this
+ * would waste seeking capacity. Instead both disks will read different parts
+ * of the filesystem.
+ * Any number of readaheads can be started in parallel. The read order will be
+ * determined globally, i.e. 2 parallel readaheads will normally finish faster
+ * than the 2 started one after another.
+ */
+
+#define MAX_MIRRORS 2
+#define MAX_IN_FLIGHT 6
+
+struct reada_extctl {
+	struct list_head	list;
+	struct reada_control	*rc;
+	u64			generation;
+};
+
+struct reada_extent {
+	u64			logical;
+	struct btrfs_key	top;
+	u32			blocksize;
+	int			err;
+	struct list_head	extctl;
+	struct kref		refcnt;
+	spinlock_t		lock;
+	struct reada_zone	*zones[MAX_MIRRORS];
+	int			nzones;
+	struct btrfs_device	*scheduled_for;
+};
+
+struct reada_zone {
+	u64			start;
+	u64			end;
+	u64			elems;
+	struct list_head	list;
+	spinlock_t		lock;
+	int			locked;
+	struct btrfs_device	*device;
+	struct btrfs_device	*devs[MAX_MIRRORS]; /* full list, incl self */
+	int			ndevs;
+	struct kref		refcnt;
+};
+
+struct reada_machine_work {
+	struct btrfs_work	work;
+	struct btrfs_fs_info	*fs_info;
+};
+
+static void reada_extent_put(struct btrfs_fs_info *, struct reada_extent *);
+static void reada_control_release(struct kref *kref);
+static void reada_zone_release(struct kref *kref);
+static void reada_start_machine(struct btrfs_fs_info *fs_info);
+static void __reada_start_machine(struct btrfs_fs_info *fs_info);
+
+static int reada_add_block(struct reada_control *rc, u64 logical,
+			   struct btrfs_key *top, int level, u64 generation);
+
+/* recurses */
+/* in case of err, eb might be NULL */
+static int __readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
+			    u64 start, int err)
+{
+	int level = 0;
+	int nritems;
+	int i;
+	u64 bytenr;
+	u64 generation;
+	struct reada_extent *re;
+	struct btrfs_fs_info *fs_info = root->fs_info;
+	struct list_head list;
+	unsigned long index = start >> PAGE_CACHE_SHIFT;
+	struct btrfs_device *for_dev;
+
+	if (eb)
+		level = btrfs_header_level(eb);
+
+	/* find extent */
+	spin_lock(&fs_info->reada_lock);
+	re = radix_tree_lookup(&fs_info->reada_tree, index);
+	if (re)
+		kref_get(&re->refcnt);
+	spin_unlock(&fs_info->reada_lock);
+
+	if (!re)
+		return -1;
+
+	spin_lock(&re->lock);
+	/*
+	 * just take the full list from the extent. afterwards we
+	 * don't need the lock anymore
+	 */
+	list_replace_init(&re->extctl, &list);
+	for_dev = re->scheduled_for;
+	re->scheduled_for = NULL;
+	spin_unlock(&re->lock);
+
+	if (err == 0) {
+		nritems = level ? btrfs_header_nritems(eb) : 0;
+		generation = btrfs_header_generation(eb);
+		/*
+		 * FIXME: currently we just set nritems to 0 if this is a leaf,
+		 * effectively ignoring the content. In a next step we could
+		 * trigger more readahead depending from the content, e.g.
+		 * fetch the checksums for the extents in the leaf.
+		 */
+	} else {
+		/*
+		 * this is the error case, the extent buffer has not been
+		 * read correctly. We won't access anything from it and
+		 * just cleanup our data structures. Effectively this will
+		 * cut the branch below this node from read ahead.
+		 */
+		nritems = 0;
+		generation = 0;
+	}
+
+	for (i = 0; i < nritems; i++) {
+		struct reada_extctl *rec;
+		u64 n_gen;
+		struct btrfs_key key;
+		struct btrfs_key next_key;
+
+		btrfs_node_key_to_cpu(eb, &key, i);
+		if (i + 1 < nritems)
+			btrfs_node_key_to_cpu(eb, &next_key, i + 1);
+		else
+			next_key = re->top;
+		bytenr = btrfs_node_blockptr(eb, i);
+		n_gen = btrfs_node_ptr_generation(eb, i);
+
+		list_for_each_entry(rec, &list, list) {
+			struct reada_control *rc = rec->rc;
+
+			/*
+			 * if the generation doesn't match, just ignore this
+			 * extctl. This will probably cut off a branch from
+			 * prefetch. Alternatively one could start a new (sub-)
+			 * prefetch for this branch, starting again from root.
+			 * FIXME: move the generation check out of this loop
+			 */
+#ifdef DEBUG
+			if (rec->generation != generation) {
+				printk(KERN_DEBUG "generation mismatch for "
+						"(%llu,%d,%llu) %llu != %llu\n",
+				       key.objectid, key.type, key.offset,
+				       rec->generation, generation);
+			}
+#endif
+			if (rec->generation == generation &&
+			    btrfs_comp_cpu_keys(&key, &rc->key_end) < 0 &&
+			    btrfs_comp_cpu_keys(&next_key, &rc->key_start) > 0)
+				reada_add_block(rc, bytenr, &next_key,
+						level - 1, n_gen);
+		}
+	}
+	/*
+	 * free extctl records
+	 */
+	while (!list_empty(&list)) {
+		struct reada_control *rc;
+		struct reada_extctl *rec;
+
+		rec = list_first_entry(&list, struct reada_extctl, list);
+		list_del(&rec->list);
+		rc = rec->rc;
+		kfree(rec);
+
+		kref_get(&rc->refcnt);
+		if (atomic_dec_and_test(&rc->elems)) {
+			kref_put(&rc->refcnt, reada_control_release);
+			wake_up(&rc->wait);
+		}
+		kref_put(&rc->refcnt, reada_control_release);
+
+		reada_extent_put(fs_info, re);	/* one ref for each entry */
+	}
+	reada_extent_put(fs_info, re);	/* our ref */
+	if (for_dev)
+		atomic_dec(&for_dev->reada_in_flight);
+
+	return 0;
+}
+
+/*
+ * start is passed separately in case eb in NULL, which may be the case with
+ * failed I/O
+ */
+int btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,
+			 u64 start, int err)
+{
+	int ret;
+
+	ret = __readahead_hook(root, eb, start, err);
+
+	reada_start_machine(root->fs_info);
+
+	return ret;
+}
+
+static struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,
+					  struct btrfs_device *dev, u64 logical,
+					  struct btrfs_multi_bio *multi)
+{
+	int ret;
+	int looped = 0;
+	struct reada_zone *zone;
+	struct btrfs_block_group_cache *cache = NULL;
+	u64 start;
+	u64 end;
+	int i;
+
+again:
+	zone = NULL;
+	spin_lock(&fs_info->reada_lock);
+	ret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,
+				     logical >> PAGE_CACHE_SHIFT, 1);
+	if (ret == 1)
+		kref_get(&zone->refcnt);
+	spin_unlock(&fs_info->reada_lock);
+
+	if (ret == 1) {
+		if (logical >= zone->start && logical < zone->end)
+			return zone;
+		spin_lock(&fs_info->reada_lock);
+		kref_put(&zone->refcnt, reada_zone_release);
+		spin_unlock(&fs_info->reada_lock);
+	}
+
+	if (looped)
+		return NULL;
+
+	cache = btrfs_lookup_block_group(fs_info, logical);
+	if (!cache)
+		return NULL;
+
+	start = cache->key.objectid;
+	end = start + cache->key.offset - 1;
+	btrfs_put_block_group(cache);
+
+	zone = kzalloc(sizeof(*zone), GFP_NOFS);
+	if (!zone)
+		return NULL;
+
+	zone->start = start;
+	zone->end = end;
+	INIT_LIST_HEAD(&zone->list);
+	spin_lock_init(&zone->lock);
+	zone->locked = 0;
+	kref_init(&zone->refcnt);
+	zone->elems = 0;
+	zone->device = dev; /* our device always sits at index 0 */
+	for (i = 0; i < multi->num_stripes; ++i) {
+		/* bounds have already been checked */
+		zone->devs[i] = multi->stripes[i].dev;
+	}
+	zone->ndevs = multi->num_stripes;
+
+	spin_lock(&fs_info->reada_lock);
+	ret = radix_tree_insert(&dev->reada_zones,
+				(unsigned long)zone->end >> PAGE_CACHE_SHIFT,
+				zone);
+	spin_unlock(&fs_info->reada_lock);
+
+	if (ret) {
+		kfree(zone);
+		looped = 1;
+		goto again;
+	}
+
+	return zone;
+}
+
+static struct reada_extent *reada_find_extent(struct btrfs_root *root,
+					      u64 logical,
+					      struct btrfs_key *top, int level)
+{
+	int ret;
+	int looped = 0;
+	struct reada_extent *re = NULL;
+	struct btrfs_fs_info *fs_info = root->fs_info;
+	struct btrfs_mapping_tree *map_tree = &fs_info->mapping_tree;
+	struct btrfs_multi_bio *multi = NULL;
+	struct btrfs_device *dev;
+	u32 blocksize;
+	u64 length;
+	int nzones = 0;
+	int i;
+	unsigned long index = logical >> PAGE_CACHE_SHIFT;
+
+again:
+	spin_lock(&fs_info->reada_lock);
+	re = radix_tree_lookup(&fs_info->reada_tree, index);
+	if (re)
+		kref_get(&re->refcnt);
+	spin_unlock(&fs_info->reada_lock);
+
+	if (re || looped)
+		return re;
+
+	re = kzalloc(sizeof(*re), GFP_NOFS);
+	if (!re)
+		return NULL;
+
+	blocksize = btrfs_level_size(root, level);
+	re->logical = logical;
+	re->blocksize = blocksize;
+	re->top = *top;
+	INIT_LIST_HEAD(&re->extctl);
+	spin_lock_init(&re->lock);
+	kref_init(&re->refcnt);
+
+	/*
+	 * map block
+	 */
+	length = blocksize;
+	ret = btrfs_map_block(map_tree, REQ_WRITE, logical, &length, &multi, 0);
+	if (ret || !multi || length < blocksize)
+		goto error;
+
+	if (multi->num_stripes > MAX_MIRRORS) {
+		printk(KERN_ERR "btrfs readahead: more than %d copies not "
+				"supported", MAX_MIRRORS);
+		goto error;
+	}
+
+	for (nzones = 0; nzones < multi->num_stripes; ++nzones) {
+		struct reada_zone *zone;
+
+		dev = multi->stripes[nzones].dev;
+		zone = reada_find_zone(fs_info, dev, logical, multi);
+		if (!zone)
+			break;
+
+		re->zones[nzones] = zone;
+		spin_lock(&zone->lock);
+		if (!zone->elems)
+			kref_get(&zone->refcnt);
+		++zone->elems;
+		spin_unlock(&zone->lock);
+		spin_lock(&fs_info->reada_lock);
+		kref_put(&zone->refcnt, reada_zone_release);
+		spin_unlock(&fs_info->reada_lock);
+	}
+	re->nzones = nzones;
+	if (nzones == 0) {
+		/* not a single zone found, error and out */
+		goto error;
+	}
+
+	/* insert extent in reada_tree + all per-device trees, all or nothing */
+	spin_lock(&fs_info->reada_lock);
+	ret = radix_tree_insert(&fs_info->reada_tree, index, re);
+	if (ret) {
+		spin_unlock(&fs_info->reada_lock);
+		if (ret != -ENOMEM) {
+			/* someone inserted the extent in the meantime */
+			looped = 1;
+		}
+		goto error;
+	}
+	for (i = 0; i < nzones; ++i) {
+		dev = multi->stripes[i].dev;
+		ret = radix_tree_insert(&dev->reada_extents, index, re);
+		if (ret) {
+			while (--i >= 0) {
+				dev = multi->stripes[i].dev;
+				BUG_ON(dev == NULL);
+				radix_tree_delete(&dev->reada_extents, index);
+			}
+			BUG_ON(fs_info == NULL);
+			radix_tree_delete(&fs_info->reada_tree, index);
+			spin_unlock(&fs_info->reada_lock);
+			goto error;
+		}
+	}
+	spin_unlock(&fs_info->reada_lock);
+
+	return re;
+
+error:
+	while (nzones) {
+		struct reada_zone *zone;
+
+		--nzones;
+		zone = re->zones[nzones];
+		kref_get(&zone->refcnt);
+		spin_lock(&zone->lock);
+		--zone->elems;
+		if (zone->elems == 0) {
+			/*
+			 * no fs_info->reada_lock needed, as this can't be
+			 * the last ref
+			 */
+			kref_put(&zone->refcnt, reada_zone_release);
+		}
+		spin_unlock(&zone->lock);
+
+		spin_lock(&fs_info->reada_lock);
+		kref_put(&zone->refcnt, reada_zone_release);
+		spin_unlock(&fs_info->reada_lock);
+	}
+	kfree(re);
+	if (looped)
+		goto again;
+	return NULL;
+}
+
+static void reada_kref_dummy(struct kref *kr)
+{
+}
+
+static void reada_extent_put(struct btrfs_fs_info *fs_info,
+			     struct reada_extent *re)
+{
+	int i;
+	unsigned long index = re->logical >> PAGE_CACHE_SHIFT;
+
+	spin_lock(&fs_info->reada_lock);
+	if (!kref_put(&re->refcnt, reada_kref_dummy)) {
+		spin_unlock(&fs_info->reada_lock);
+		return;
+	}
+
+	radix_tree_delete(&fs_info->reada_tree, index);
+	for (i = 0; i < re->nzones; ++i) {
+		struct reada_zone *zone = re->zones[i];
+
+		radix_tree_delete(&zone->device->reada_extents, index);
+	}
+
+	spin_unlock(&fs_info->reada_lock);
+
+	for (i = 0; i < re->nzones; ++i) {
+		struct reada_zone *zone = re->zones[i];
+
+		kref_get(&zone->refcnt);
+		spin_lock(&zone->lock);
+		--zone->elems;
+		if (zone->elems == 0) {
+			/* no fs_info->reada_lock needed, as this can't be
+			 * the last ref */
+			kref_put(&zone->refcnt, reada_zone_release);
+		}
+		spin_unlock(&zone->lock);
+
+		spin_lock(&fs_info->reada_lock);
+		kref_put(&zone->refcnt, reada_zone_release);
+		spin_unlock(&fs_info->reada_lock);
+	}
+	if (re->scheduled_for)
+		atomic_dec(&re->scheduled_for->reada_in_flight);
+
+	kfree(re);
+}
+
+static void reada_zone_release(struct kref *kref)
+{
+	struct reada_zone *zone = container_of(kref, struct reada_zone, refcnt);
+
+	radix_tree_delete(&zone->device->reada_zones,
+			  zone->end >> PAGE_CACHE_SHIFT);
+
+	kfree(zone);
+}
+
+static void reada_control_release(struct kref *kref)
+{
+	struct reada_control *rc = container_of(kref, struct reada_control,
+						refcnt);
+
+	kfree(rc);
+}
+
+static int reada_add_block(struct reada_control *rc, u64 logical,
+			   struct btrfs_key *top, int level, u64 generation)
+{
+	struct btrfs_root *root = rc->root;
+	struct reada_extent *re;
+	struct reada_extctl *rec;
+
+	re = reada_find_extent(root, logical, top, level); /* takes one ref */
+	if (!re)
+		return -1;
+
+	rec = kzalloc(sizeof(*rec), GFP_NOFS);
+	if (!rec) {
+		reada_extent_put(root->fs_info, re);
+		return -1;
+	}
+
+	rec->rc = rc;
+	rec->generation = generation;
+	atomic_inc(&rc->elems);
+
+	spin_lock(&re->lock);
+	list_add_tail(&rec->list, &re->extctl);
+	spin_unlock(&re->lock);
+
+	/* leave the ref on the extent */
+
+	return 0;
+}
+
+/*
+ * called with fs_info->reada_lock held
+ */
+static void reada_peer_zones_set_lock(struct reada_zone *zone, int lock)
+{
+	int i;
+	unsigned long index = zone->end >> PAGE_CACHE_SHIFT;
+
+	for (i = 0; i < zone->ndevs; ++i) {
+		struct reada_zone *peer;
+		peer = radix_tree_lookup(&zone->devs[i]->reada_zones, index);
+		if (peer && peer->device != zone->device)
+			peer->locked = lock;
+	}
+}
+
+/*
+ * called with fs_info->reada_lock held
+ */
+static int reada_pick_zone(struct btrfs_device *dev)
+{
+	struct reada_zone *top_zone = NULL;
+	struct reada_zone *top_locked_zone = NULL;
+	u64 top_elems = 0;
+	u64 top_locked_elems = 0;
+	unsigned long index = 0;
+	int ret;
+
+	if (dev->reada_curr_zone) {
+		reada_peer_zones_set_lock(dev->reada_curr_zone, 0);
+		kref_put(&dev->reada_curr_zone->refcnt, reada_zone_release);
+		dev->reada_curr_zone = NULL;
+	}
+	/* pick the zone with the most elements */
+	while (1) {
+		struct reada_zone *zone;
+
+		ret = radix_tree_gang_lookup(&dev->reada_zones,
+					     (void **)&zone, index, 1);
+		if (ret == 0)
+			break;
+		index = (zone->end >> PAGE_CACHE_SHIFT) + 1;
+		if (zone->locked) {
+			if (zone->elems > top_locked_elems) {
+				top_locked_elems = zone->elems;
+				top_locked_zone = zone;
+			}
+		} else {
+			if (zone->elems > top_elems) {
+				top_elems = zone->elems;
+				top_zone = zone;
+			}
+		}
+	}
+	if (top_zone)
+		dev->reada_curr_zone = top_zone;
+	else if (top_locked_zone)
+		dev->reada_curr_zone = top_locked_zone;
+	else
+		return 0;
+
+	dev->reada_next = dev->reada_curr_zone->start;
+	kref_get(&dev->reada_curr_zone->refcnt);
+	reada_peer_zones_set_lock(dev->reada_curr_zone, 1);
+
+	return 1;
+}
+
+static int reada_start_machine_dev(struct btrfs_fs_info *fs_info,
+				   struct btrfs_device *dev)
+{
+	struct reada_extent *re = NULL;
+	int mirror_num = 0;
+	struct extent_buffer *eb = NULL;
+	u64 logical;
+	u32 blocksize;
+	int ret;
+	int i;
+	int need_kick = 0;
+
+	spin_lock(&fs_info->reada_lock);
+	if (dev->reada_curr_zone == NULL) {
+		ret = reada_pick_zone(dev);
+		if (!ret) {
+			spin_unlock(&fs_info->reada_lock);
+			return 0;
+		}
+	}
+	/*
+	 * FIXME currently we issue the reads one extent at a time. If we have
+	 * a contiguous block of extents, we could also coagulate them or use
+	 * plugging to speed things up
+	 */
+	ret = radix_tree_gang_lookup(&dev->reada_extents, (void **)&re,
+				     dev->reada_next >> PAGE_CACHE_SHIFT, 1);
+	if (ret == 0 || re->logical >= dev->reada_curr_zone->end) {
+		ret = reada_pick_zone(dev);
+		if (!ret) {
+			spin_unlock(&fs_info->reada_lock);
+			return 0;
+		}
+		re = NULL;
+		ret = radix_tree_gang_lookup(&dev->reada_extents, (void **)&re,
+					dev->reada_next >> PAGE_CACHE_SHIFT, 1);
+	}
+	if (ret == 0) {
+		spin_unlock(&fs_info->reada_lock);
+		return 0;
+	}
+	dev->reada_next = re->logical + re->blocksize;
+	kref_get(&re->refcnt);
+
+	spin_unlock(&fs_info->reada_lock);
+
+	/*
+	 * find mirror num
+	 */
+	for (i = 0; i < re->nzones; ++i) {
+		if (re->zones[i]->device == dev) {
+			mirror_num = i + 1;
+			break;
+		}
+	}
+	logical = re->logical;
+	blocksize = re->blocksize;
+
+	spin_lock(&re->lock);
+	if (re->scheduled_for == NULL) {
+		re->scheduled_for = dev;
+		need_kick = 1;
+	}
+	spin_unlock(&re->lock);
+
+	reada_extent_put(fs_info, re);
+
+	if (!need_kick)
+		return 0;
+
+	atomic_inc(&dev->reada_in_flight);
+	ret = reada_tree_block_flagged(fs_info->extent_root, logical, blocksize,
+			 mirror_num, &eb);
+	if (ret)
+		__readahead_hook(fs_info->extent_root, NULL, logical, ret);
+	else if (eb)
+		__readahead_hook(fs_info->extent_root, eb, eb->start, ret);
+
+	if (eb)
+		free_extent_buffer(eb);
+
+	return 1;
+
+}
+
+static void reada_start_machine_worker(struct btrfs_work *work)
+{
+	struct reada_machine_work *rmw;
+	struct btrfs_fs_info *fs_info;
+
+	rmw = container_of(work, struct reada_machine_work, work);
+	fs_info = rmw->fs_info;
+
+	kfree(rmw);
+
+	__reada_start_machine(fs_info);
+}
+
+static void __reada_start_machine(struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_device *device;
+	struct btrfs_fs_devices *fs_devices = fs_info->fs_devices;
+	u64 enqueued;
+	u64 total = 0;
+	int i;
+
+	do {
+		enqueued = 0;
+		list_for_each_entry(device, &fs_devices->devices, dev_list) {
+			if (atomic_read(&device->reada_in_flight) <
+			    MAX_IN_FLIGHT)
+				enqueued += reada_start_machine_dev(fs_info,
+								    device);
+		}
+		total += enqueued;
+	} while (enqueued && total < 10000);
+
+	if (enqueued == 0)
+		return;
+
+	/*
+	 * If everything is already in the cache, this is effectively single
+	 * threaded. To a) not hold the caller for too long and b) to utilize
+	 * more cores, we broke the loop above after 10000 iterations and now
+	 * enqueue to workers to finish it. This will distribute the load to
+	 * the cores.
+	 */
+	for (i = 0; i < 2; ++i)
+		reada_start_machine(fs_info);
+}
+
+static void reada_start_machine(struct btrfs_fs_info *fs_info)
+{
+	struct reada_machine_work *rmw;
+
+	rmw = kzalloc(sizeof(*rmw), GFP_NOFS);
+	if (!rmw) {
+		/* FIXME we cannot handle this properly right now */
+		BUG();
+	}
+	rmw->work.func = reada_start_machine_worker;
+	rmw->fs_info = fs_info;
+
+	btrfs_queue_worker(&fs_info->readahead_workers, &rmw->work);
+}
+
+#ifdef DEBUG
+static void dump_devs(struct btrfs_fs_info *fs_info, int all)
+{
+	struct btrfs_device *device;
+	struct btrfs_fs_devices *fs_devices = fs_info->fs_devices;
+	unsigned long index;
+	int ret;
+	int i;
+	int j;
+	int cnt;
+
+	spin_lock(&fs_info->reada_lock);
+	list_for_each_entry(device, &fs_devices->devices, dev_list) {
+		printk(KERN_DEBUG "dev %lld has %d in flight\n", device->devid,
+			atomic_read(&device->reada_in_flight));
+		index = 0;
+		while (1) {
+			struct reada_zone *zone;
+			ret = radix_tree_gang_lookup(&device->reada_zones,
+						     (void **)&zone, index, 1);
+			if (ret == 0)
+				break;
+			printk(KERN_DEBUG "  zone %llu-%llu elems %llu locked "
+				"%d devs", zone->start, zone->end, zone->elems,
+				zone->locked);
+			for (j = 0; j < zone->ndevs; ++j) {
+				printk(KERN_CONT " %lld",
+					zone->devs[j]->devid);
+			}
+			if (device->reada_curr_zone == zone)
+				printk(KERN_CONT " curr off %llu",
+					device->reada_next - zone->start);
+			printk(KERN_CONT "\n");
+			index = (zone->end >> PAGE_CACHE_SHIFT) + 1;
+		}
+		cnt = 0;
+		index = 0;
+		while (all) {
+			struct reada_extent *re = NULL;
+
+			ret = radix_tree_gang_lookup(&device->reada_extents,
+						     (void **)&re, index, 1);
+			if (ret == 0)
+				break;
+			printk(KERN_DEBUG
+				"  re: logical %llu size %u empty %d for %lld",
+				re->logical, re->blocksize,
+				list_empty(&re->extctl), re->scheduled_for ?
+				re->scheduled_for->devid : -1);
+
+			for (i = 0; i < re->nzones; ++i) {
+				printk(KERN_CONT " zone %llu-%llu devs",
+					re->zones[i]->start,
+					re->zones[i]->end);
+				for (j = 0; j < re->zones[i]->ndevs; ++j) {
+					printk(KERN_CONT " %lld",
+						re->zones[i]->devs[j]->devid);
+				}
+			}
+			printk(KERN_CONT "\n");
+			index = (re->logical >> PAGE_CACHE_SHIFT) + 1;
+			if (++cnt > 15)
+				break;
+		}
+	}
+
+	index = 0;
+	cnt = 0;
+	while (all) {
+		struct reada_extent *re = NULL;
+
+		ret = radix_tree_gang_lookup(&fs_info->reada_tree, (void **)&re,
+					     index, 1);
+		if (ret == 0)
+			break;
+		if (!re->scheduled_for) {
+			index = (re->logical >> PAGE_CACHE_SHIFT) + 1;
+			continue;
+		}
+		printk(KERN_DEBUG
+			"re: logical %llu size %u list empty %d for %lld",
+			re->logical, re->blocksize, list_empty(&re->extctl),
+			re->scheduled_for ? re->scheduled_for->devid : -1);
+		for (i = 0; i < re->nzones; ++i) {
+			printk(KERN_CONT " zone %llu-%llu devs",
+				re->zones[i]->start,
+				re->zones[i]->end);
+			for (i = 0; i < re->nzones; ++i) {
+				printk(KERN_CONT " zone %llu-%llu devs",
+					re->zones[i]->start,
+					re->zones[i]->end);
+				for (j = 0; j < re->zones[i]->ndevs; ++j) {
+					printk(KERN_CONT " %lld",
+						re->zones[i]->devs[j]->devid);
+				}
+			}
+		}
+		printk(KERN_CONT "\n");
+		index = (re->logical >> PAGE_CACHE_SHIFT) + 1;
+	}
+	spin_unlock(&fs_info->reada_lock);
+}
+#endif
+
+/*
+ * interface
+ */
+struct reada_control *btrfs_reada_add(struct btrfs_root *root,
+			struct btrfs_key *key_start, struct btrfs_key *key_end)
+{
+	struct reada_control *rc;
+	u64 start;
+	u64 generation;
+	int level;
+	struct extent_buffer *node;
+	static struct btrfs_key max_key = {
+		.objectid = (u64)-1,
+		.type = (u8)-1,
+		.offset = (u64)-1
+	};
+
+	rc = kzalloc(sizeof(*rc), GFP_NOFS);
+	if (!rc)
+		return ERR_PTR(-ENOMEM);
+
+	rc->root = root;
+	rc->key_start = *key_start;
+	rc->key_end = *key_end;
+	atomic_set(&rc->elems, 0);
+	init_waitqueue_head(&rc->wait);
+	kref_init(&rc->refcnt);
+	kref_get(&rc->refcnt); /* one ref for having elements */
+
+	node = btrfs_root_node(root);
+	start = node->start;
+	level = btrfs_header_level(node);
+	generation = btrfs_header_generation(node);
+	free_extent_buffer(node);
+
+	reada_add_block(rc, start, &max_key, level, generation);
+
+	reada_start_machine(root->fs_info);
+
+	return rc;
+}
+
+#ifdef DEBUG
+int btrfs_reada_wait(void *handle)
+{
+	struct reada_control *rc = handle;
+
+	while (atomic_read(&rc->elems)) {
+		wait_event_timeout(rc->wait, atomic_read(&rc->elems) == 0,
+				   5 * HZ);
+		dump_devs(rc->root->fs_info, rc->elems < 10 ? 1 : 0);
+	}
+
+	dump_devs(rc->root->fs_info, rc->elems < 10 ? 1 : 0);
+
+	kref_put(&rc->refcnt, reada_control_release);
+
+	return 0;
+}
+#else
+int btrfs_reada_wait(void *handle)
+{
+	struct reada_control *rc = handle;
+
+	while (atomic_read(&rc->elems)) {
+		wait_event(rc->wait, atomic_read(&rc->elems) == 0);
+	}
+
+	kref_put(&rc->refcnt, reada_control_release);
+
+	return 0;
+}
+#endif
+
+void btrfs_reada_detach(void *handle)
+{
+	struct reada_control *rc = handle;
+
+	kref_put(&rc->refcnt, reada_control_release);
+}
