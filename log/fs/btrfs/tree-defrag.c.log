commit 92a7cc4252231d1641b36c38cf845cfc50308ab0
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri May 15 14:01:40 2020 +0800

    btrfs: rename BTRFS_ROOT_REF_COWS to BTRFS_ROOT_SHAREABLE
    
    The name BTRFS_ROOT_REF_COWS is not very clear about the meaning.
    
    In fact, that bit can only be set to those trees:
    
    - Subvolume roots
    - Data reloc root
    - Reloc roots for above roots
    
    All other trees won't get this bit set.  So just by the result, it is
    obvious that, roots with this bit set can have tree blocks shared with
    other trees.  Either shared by snapshots, or by reloc roots (an special
    snapshot created by relocation).
    
    This patch will rename BTRFS_ROOT_REF_COWS to BTRFS_ROOT_SHAREABLE to
    make it easier to understand, and update all comment mentioning
    "reference counted" to follow the rename.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 5f9e2dd413af..16c3a6d2586d 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -35,7 +35,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		goto out;
 	}
 
-	if (!test_bit(BTRFS_ROOT_REF_COWS, &root->state))
+	if (!test_bit(BTRFS_ROOT_SHAREABLE, &root->state))
 		goto out;
 
 	path = btrfs_alloc_path();

commit 8bead258206f4d4f485ad55bc1e39d23bbfe2fdd
Author: David Sterba <dsterba@suse.com>
Date:   Wed Apr 4 02:03:48 2018 +0200

    btrfs: open code now trivial btrfs_set_lock_blocking
    
    btrfs_set_lock_blocking is now only a simple wrapper around
    btrfs_set_lock_blocking_write. The name does not bring any semantic
    value that could not be inferred from the new function so there's no
    point keeping it.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 3c0987ab587d..5f9e2dd413af 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -52,7 +52,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		u32 nritems;
 
 		root_node = btrfs_lock_root_node(root);
-		btrfs_set_lock_blocking(root_node);
+		btrfs_set_lock_blocking_write(root_node);
 		nritems = btrfs_header_nritems(root_node);
 		root->defrag_max.objectid = 0;
 		/* from above we know this is not a leaf */

commit c1d7c514f745628eb096c5cbb10737855879ae25
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:23:33 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- sources
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index c09dbe4bd6e7..3c0987ab587d 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -1,19 +1,6 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 2007 Oracle.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
 #include <linux/sched.h>

commit 7c829b722dffb22aaf9e3ea1b1d88dac49bd0768
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Mar 7 17:29:18 2018 +0800

    btrfs: add define for oldest generation
    
    Some functions can filter metadata by the generation. Add a define that
    will annotate such arguments.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index cb65089127cc..c09dbe4bd6e7 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -39,7 +39,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	int level;
 	int next_key_ret = 0;
 	u64 last_ret = 0;
-	u64 min_trans = 0;
 
 	if (root->fs_info->extent_root == root) {
 		/*
@@ -81,7 +80,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 
 	path->keep_locks = 1;
 
-	ret = btrfs_search_forward(root, &key, path, min_trans);
+	ret = btrfs_search_forward(root, &key, path, BTRFS_OLDEST_GENERATION);
 	if (ret < 0)
 		goto out;
 	if (ret > 0) {
@@ -130,7 +129,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	 */
 	path->slots[1] = btrfs_header_nritems(path->nodes[1]);
 	next_key_ret = btrfs_find_next_key(root, path, &key, 1,
-					   min_trans);
+					   BTRFS_OLDEST_GENERATION);
 	if (next_key_ret == 0) {
 		memcpy(&root->defrag_progress, &key, sizeof(key));
 		ret = -EAGAIN;

commit 0376374a98abd533fb49c6db12967bddc2f4b4b3
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Dec 18 01:57:29 2015 +0000

    Btrfs: fix locking bugs when defragging leaves
    
    When running fstests btrfs/070, with a higher number of fsstress
    operations, I ran frequently into two different locking bugs when
    defragging directories.
    
    The first bug produced the following traces:
    
    [133860.229792] ------------[ cut here ]------------
    [133860.251062] WARNING: CPU: 2 PID: 26057 at fs/btrfs/locking.c:46 btrfs_set_lock_blocking_rw+0x57/0xbd [btrfs]()
    [133860.253576] Modules linked in: btrfs crc32c_generic xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd grace fscache sunrpc loop fuse parport_pc i2c_piix4 psmouse parport
    [133860.282566] CPU: 2 PID: 26057 Comm: btrfs Tainted: G        W       4.3.0-rc5-btrfs-next-17+ #1
    [133860.284393] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.1-0-g4adadbd-20150316_085822-nilsson.home.kraxel.org 04/01/2014
    [133860.286827]  0000000000000000 ffff880207697b78 ffffffff812566f4 0000000000000000
    [133860.288341]  ffff880207697bb0 ffffffff8104d0a6 ffffffffa052d4c1 ffff880178f60e00
    [133860.294219]  ffff880178f60e00 0000000000000000 00000000000000f6 ffff880207697bc0
    [133860.295831] Call Trace:
    [133860.306518]  [<ffffffff812566f4>] dump_stack+0x4e/0x79
    [133860.307473]  [<ffffffff8104d0a6>] warn_slowpath_common+0x9f/0xb8
    [133860.308619]  [<ffffffffa052d4c1>] ? btrfs_set_lock_blocking_rw+0x57/0xbd [btrfs]
    [133860.310068]  [<ffffffff8104d172>] warn_slowpath_null+0x1a/0x1c
    [133860.312552]  [<ffffffffa052d4c1>] btrfs_set_lock_blocking_rw+0x57/0xbd [btrfs]
    [133860.314630]  [<ffffffffa04d5787>] btrfs_set_lock_blocking+0xe/0x10 [btrfs]
    [133860.323596]  [<ffffffffa04d99cb>] btrfs_realloc_node+0xb3/0x341 [btrfs]
    [133860.325233]  [<ffffffffa050e396>] btrfs_defrag_leaves+0x239/0x2fa [btrfs]
    [133860.332427]  [<ffffffffa04fc2ce>] btrfs_defrag_root+0x63/0xca [btrfs]
    [133860.337259]  [<ffffffffa052a34e>] btrfs_ioctl_defrag+0x78/0x14e [btrfs]
    [133860.340147]  [<ffffffffa052b00b>] btrfs_ioctl+0x746/0x24c6 [btrfs]
    [133860.344833]  [<ffffffff81087481>] ? arch_local_irq_save+0x9/0xc
    [133860.346343]  [<ffffffff8113ad61>] ? __might_fault+0x4c/0xa7
    [133860.353248]  [<ffffffff8113ad61>] ? __might_fault+0x4c/0xa7
    [133860.354242]  [<ffffffff8113adba>] ? __might_fault+0xa5/0xa7
    [133860.355232]  [<ffffffff81171139>] ? cp_new_stat+0x15d/0x174
    [133860.356237]  [<ffffffff8117c610>] do_vfs_ioctl+0x427/0x4e6
    [133860.358587]  [<ffffffff81171175>] ? SYSC_newfstat+0x25/0x2e
    [133860.360195]  [<ffffffff8118574d>] ? __fget_light+0x4d/0x71
    [133860.361380]  [<ffffffff8117c726>] SyS_ioctl+0x57/0x79
    [133860.363578]  [<ffffffff8147cd97>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [133860.366217] ---[ end trace 2cadb2f653437e49 ]---
    [133860.367399] ------------[ cut here ]------------
    [133860.368162] kernel BUG at fs/btrfs/locking.c:307!
    [133860.369430] invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
    [133860.370205] Modules linked in: btrfs crc32c_generic xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd grace fscache sunrpc loop fuse parport_pc i2c_piix4 psmouse parport
    [133860.370205] CPU: 2 PID: 26057 Comm: btrfs Tainted: G        W       4.3.0-rc5-btrfs-next-17+ #1
    [133860.370205] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.1-0-g4adadbd-20150316_085822-nilsson.home.kraxel.org 04/01/2014
    [133860.370205] task: ffff8800aec6db40 ti: ffff880207694000 task.ti: ffff880207694000
    [133860.370205] RIP: 0010:[<ffffffffa052d466>]  [<ffffffffa052d466>] btrfs_assert_tree_locked+0x10/0x14 [btrfs]
    [133860.370205] RSP: 0018:ffff880207697bc0  EFLAGS: 00010246
    [133860.370205] RAX: 0000000000000000 RBX: ffff880178f60e00 RCX: 0000000000000000
    [133860.370205] RDX: ffff88023ec4fb50 RSI: 00000000ffffffff RDI: ffff880178f60e00
    [133860.370205] RBP: ffff880207697bc0 R08: 0000000000000001 R09: 0000000000000000
    [133860.370205] R10: 0000160000000000 R11: ffffffff81651000 R12: ffff880178f60e00
    [133860.370205] R13: 0000000000000000 R14: 00000000000000f6 R15: ffff8801ff409000
    [133860.370205] FS:  00007f763efd48c0(0000) GS:ffff88023ec40000(0000) knlGS:0000000000000000
    [133860.370205] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [133860.370205] CR2: 0000000002158048 CR3: 000000003fd6c000 CR4: 00000000000006e0
    [133860.370205] Stack:
    [133860.370205]  ffff880207697bd8 ffffffffa052d4d0 0000000000000000 ffff880207697be8
    [133860.370205]  ffffffffa04d5787 ffff880207697c80 ffffffffa04d99cb ffff8801ff409590
    [133860.370205]  ffff880207697ca8 000000f507697c80 ffff880183c11bb8 0000000000000000
    [133860.370205] Call Trace:
    [133860.370205]  [<ffffffffa052d4d0>] btrfs_set_lock_blocking_rw+0x66/0xbd [btrfs]
    [133860.370205]  [<ffffffffa04d5787>] btrfs_set_lock_blocking+0xe/0x10 [btrfs]
    [133860.370205]  [<ffffffffa04d99cb>] btrfs_realloc_node+0xb3/0x341 [btrfs]
    [133860.370205]  [<ffffffffa050e396>] btrfs_defrag_leaves+0x239/0x2fa [btrfs]
    [133860.370205]  [<ffffffffa04fc2ce>] btrfs_defrag_root+0x63/0xca [btrfs]
    [133860.370205]  [<ffffffffa052a34e>] btrfs_ioctl_defrag+0x78/0x14e [btrfs]
    [133860.370205]  [<ffffffffa052b00b>] btrfs_ioctl+0x746/0x24c6 [btrfs]
    [133860.370205]  [<ffffffff81087481>] ? arch_local_irq_save+0x9/0xc
    [133860.370205]  [<ffffffff8113ad61>] ? __might_fault+0x4c/0xa7
    [133860.370205]  [<ffffffff8113ad61>] ? __might_fault+0x4c/0xa7
    [133860.370205]  [<ffffffff8113adba>] ? __might_fault+0xa5/0xa7
    [133860.370205]  [<ffffffff81171139>] ? cp_new_stat+0x15d/0x174
    [133860.370205]  [<ffffffff8117c610>] do_vfs_ioctl+0x427/0x4e6
    [133860.370205]  [<ffffffff81171175>] ? SYSC_newfstat+0x25/0x2e
    [133860.370205]  [<ffffffff8118574d>] ? __fget_light+0x4d/0x71
    [133860.370205]  [<ffffffff8117c726>] SyS_ioctl+0x57/0x79
    [133860.370205]  [<ffffffff8147cd97>] entry_SYSCALL_64_fastpath+0x12/0x6f
    
    This bug happened because we assumed that by setting keep_locks to 1 in
    our search path, our path after a call to btrfs_search_slot() would have
    all nodes locked, which is not always true because unlock_up() (called by
    btrfs_search_slot()) will unlock a node in a path if the slot of the node
    below it doesn't point to the last item or beyond the last item. For
    example, when the tree has a heigth of 2 and path->slots[0] has a value
    smaller than btrfs_header_nritems(path->nodes[0]) - 1, the node at level 2
    will be unlocked (also because lowest_unlock is set to 1 due to the fact
    that the value passed as ins_len to btrfs_search_slot is 0).
    This resulted in btrfs_find_next_key(), called before btrfs_realloc_node(),
    to release out path and call again btrfs_search_slot(), but this time with
    the cow parameter set to 0, meaning the resulting path got only read locks.
    Therefore when we called btrfs_realloc_node(), with path->nodes[1] having
    a read lock, it resulted in the warning and BUG_ON when calling
    btrfs_set_lock_blocking() against the node, as that function expects the
    node to have a write lock.
    
    The second bug happened often when the first bug didn't happen, and made
    us hang and hitting the following warning at fs/btrfs/locking.c:
    
       251  void btrfs_tree_lock(struct extent_buffer *eb)
       252  {
       253          WARN_ON(eb->lock_owner == current->pid);
    
    This happened because the tree search we made at btrfs_defrag_leaves()
    before calling btrfs_find_next_key() locked a leaf and all the other
    nodes in the path, so btrfs_find_next_key() had no need to release the
    path and make a new search (with path->lowest_level set to 1). This
    made btrfs_realloc_node() attempt to write lock the same leaf again,
    resulting in a hang/deadlock.
    
    So fix these issues by calling btrfs_find_next_key() after calling
    btrfs_realloc_node() and setting the search path's lowest_level to 1
    to avoid the hang/deadlock when attempting to write lock the leaves
    at btrfs_realloc_node().
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index f31db4325339..cb65089127cc 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -89,6 +89,12 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		goto out;
 	}
 	btrfs_release_path(path);
+	/*
+	 * We don't need a lock on a leaf. btrfs_realloc_node() will lock all
+	 * leafs from path->nodes[1], so set lowest_level to 1 to avoid later
+	 * a deadlock (attempting to write lock an already write locked leaf).
+	 */
+	path->lowest_level = 1;
 	wret = btrfs_search_slot(trans, root, &key, path, 0, 1);
 
 	if (wret < 0) {
@@ -99,9 +105,12 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		ret = 0;
 		goto out;
 	}
-	path->slots[1] = btrfs_header_nritems(path->nodes[1]);
-	next_key_ret = btrfs_find_next_key(root, path, &key, 1,
-					   min_trans);
+	/*
+	 * The node at level 1 must always be locked when our path has
+	 * keep_locks set and lowest_level is 1, regardless of the value of
+	 * path->slots[1].
+	 */
+	BUG_ON(path->locks[1] == 0);
 	ret = btrfs_realloc_node(trans, root,
 				 path->nodes[1], 0,
 				 &last_ret,
@@ -110,6 +119,18 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		WARN_ON(ret == -EAGAIN);
 		goto out;
 	}
+	/*
+	 * Now that we reallocated the node we can find the next key. Note that
+	 * btrfs_find_next_key() can release our path and do another search
+	 * without COWing, this is because even with path->keep_locks = 1,
+	 * btrfs_search_slot() / ctree.c:unlock_up() does not keeps a lock on a
+	 * node when path->slots[node_level - 1] does not point to the last
+	 * item or a slot beyond the last item (ctree.c:unlock_up()). Therefore
+	 * we search for the next key after reallocating our node.
+	 */
+	path->slots[1] = btrfs_header_nritems(path->nodes[1]);
+	next_key_ret = btrfs_find_next_key(root, path, &key, 1,
+					   min_trans);
 	if (next_key_ret == 0) {
 		memcpy(&root->defrag_progress, &key, sizeof(key));
 		ret = -EAGAIN;

commit 527afb4493c2892ce89fb74648e72a30b68ba120
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Wed Aug 19 14:55:00 2015 +0900

    Btrfs: cleanup: remove unnecessary check before btrfs_free_path is called
    
    We need not check path before btrfs_free_path() is called because
    path is checked in btrfs_free_path().
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Reviewed-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index a4b9c8b2d35a..f31db4325339 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -115,8 +115,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		ret = -EAGAIN;
 	}
 out:
-	if (path)
-		btrfs_free_path(path);
+	btrfs_free_path(path);
 	if (ret == -EAGAIN) {
 		if (root->defrag_max.objectid > root->defrag_progress.objectid)
 			goto done;

commit 13028901a4a62096e97a0fc44388ea859587f690
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Apr 24 16:44:30 2015 +0200

    btrfs: let tree defrag work in SSD mode
    
    Long time ago (2008) the defrag was automatic for new b-tree writes but
    has been disabled after performance problems. There was a leftover in
    tree-defrag.c that effectively stops any defragmentation on b-trees.
    This is a bit unexpected and IMHO undesired. The SSD mode is an
    optimization and defrag is supposed to work if the users asks for it.
    
    Related commits:
    
    6702ed490ca0bb44e17131818a5a18b773957c5a
    Btrfs: Add run time btree defrag, and an ioctl to force btree defrag
    
    e18e4809b10e6c9efb5fe10c1ddcb4ebb690d517
    Btrfs: Add mount -o ssd, which includes optimizations for seek free
    storage
    
    b3236e68bf86b3ae87f58984a1822369225211cb
    Btrfs: Leave on the tree defragger in mount -o ssd, it still helps there
    
    9afbb0b752ef30a429c45b9de6706e28ad1a36e1
    Btrfs: Disable tree defrag in SSD mode
    
    The last three commits switch the defrag+ssd off/on/off and the last one
    
    3f157a2fd2ad731e1ed9964fecdc5f459f04a4a4
    Btrfs: Online btree defragmentation fixes
    
    misses the bits from tree-defrag.c to revert to the behaviour introduced
    in e18e4809b10e.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index a63719cc9578..a4b9c8b2d35a 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -52,9 +52,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	if (!test_bit(BTRFS_ROOT_REF_COWS, &root->state))
 		goto out;
 
-	if (btrfs_test_opt(root, SSD))
-		goto out;
-
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;

commit 27cdeb7096b86f05ad018a24cdb63acdf0850a5d
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Apr 2 19:51:05 2014 +0800

    Btrfs: use bitfield instead of integer data type for the some variants in btrfs_root
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 76928ca97741..a63719cc9578 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -49,7 +49,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		goto out;
 	}
 
-	if (root->ref_cows == 0)
+	if (!test_bit(BTRFS_ROOT_REF_COWS, &root->state))
 		goto out;
 
 	if (btrfs_test_opt(root, SSD))

commit 8319bfe13642ea2d411c885400377d5fc6f32271
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Tue Oct 8 18:19:14 2013 +0800

    Btrfs: cleanup dead code of defragment
    
    @is_extent is no more needed since we don't defrag extent root.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index cbaa73c871a9..76928ca97741 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -37,7 +37,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	int ret = 0;
 	int wret;
 	int level;
-	int is_extent = 0;
 	int next_key_ret = 0;
 	u64 last_ret = 0;
 	u64 min_trans = 0;
@@ -50,7 +49,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		goto out;
 	}
 
-	if (root->ref_cows == 0 && !is_extent)
+	if (root->ref_cows == 0)
 		goto out;
 
 	if (btrfs_test_opt(root, SSD))

commit 6174d3cb43aa974d0c8590a3e628ac35ab0bbc13
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Tue Oct 1 16:13:42 2013 +0100

    Btrfs: remove unused max_key arg from btrfs_search_forward
    
    It is not used for anything.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 94e05c1f118a..cbaa73c871a9 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -85,7 +85,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 
 	path->keep_locks = 1;
 
-	ret = btrfs_search_forward(root, &key, NULL, path, min_trans);
+	ret = btrfs_search_forward(root, &key, path, min_trans);
 	if (ret < 0)
 		goto out;
 	if (ret > 0) {

commit de78b51a2852bddccd6535e9e12de65f92787a1e
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Jan 31 18:21:12 2013 +0000

    btrfs: remove cache only arguments from defrag path
    
    The entry point at the defrag ioctl always sets "cache only" to 0;
    the codepaths haven't run for a long time as far as I can
    tell.  Chris says they're dead code, so remove them.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 3b580ee8ab1d..94e05c1f118a 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -23,13 +23,14 @@
 #include "transaction.h"
 #include "locking.h"
 
-/* defrag all the leaves in a given btree.  If cache_only == 1, don't read
- * things from disk, otherwise read all the leaves and try to get key order to
+/*
+ * Defrag all the leaves in a given btree.
+ * Read all the leaves and try to get key order to
  * better reflect disk order
  */
 
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root, int cache_only)
+			struct btrfs_root *root)
 {
 	struct btrfs_path *path = NULL;
 	struct btrfs_key key;
@@ -41,9 +42,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	u64 last_ret = 0;
 	u64 min_trans = 0;
 
-	if (cache_only)
-		goto out;
-
 	if (root->fs_info->extent_root == root) {
 		/*
 		 * there's recursion here right now in the tree locking,
@@ -86,11 +84,8 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	}
 
 	path->keep_locks = 1;
-	if (cache_only)
-		min_trans = root->defrag_trans_start;
 
-	ret = btrfs_search_forward(root, &key, NULL, path,
-				   cache_only, min_trans);
+	ret = btrfs_search_forward(root, &key, NULL, path, min_trans);
 	if (ret < 0)
 		goto out;
 	if (ret > 0) {
@@ -109,11 +104,11 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		goto out;
 	}
 	path->slots[1] = btrfs_header_nritems(path->nodes[1]);
-	next_key_ret = btrfs_find_next_key(root, path, &key, 1, cache_only,
+	next_key_ret = btrfs_find_next_key(root, path, &key, 1,
 					   min_trans);
 	ret = btrfs_realloc_node(trans, root,
 				 path->nodes[1], 0,
-				 cache_only, &last_ret,
+				 &last_ret,
 				 &root->defrag_progress);
 	if (ret) {
 		WARN_ON(ret == -EAGAIN);

commit b3b4aa74b58bded927f579fff787fb6fa1c0393c
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Apr 21 01:20:15 2011 +0200

    btrfs: drop unused parameter from btrfs_release_path
    
    parameter tree root it's not used since commit
    5f39d397dfbe140a14edecd4e73c34ce23c4f9ee ("Btrfs: Create extent_buffer
    interface for large blocksizes")
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 992ab425599d..3b580ee8ab1d 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -97,7 +97,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		ret = 0;
 		goto out;
 	}
-	btrfs_release_path(root, path);
+	btrfs_release_path(path);
 	wret = btrfs_search_slot(trans, root, &key, path, 0, 1);
 
 	if (wret < 0) {

commit 559af8211433b8c0b20e6c43c61409cb9c9c2996
Author: Andi Kleen <andi@firstfloor.org>
Date:   Fri Oct 29 15:14:37 2010 -0400

    Btrfs: cleanup warnings from gcc 4.6 (nonbugs)
    
    These are all the cases where a variable is set, but not read which are
    not bugs as far as I can see, but simply leftovers.
    
    Still needs more review.
    
    Found by gcc 4.6's new warnings
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index f7ac8e013ed7..992ab425599d 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -36,7 +36,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	int ret = 0;
 	int wret;
 	int level;
-	int orig_level;
 	int is_extent = 0;
 	int next_key_ret = 0;
 	u64 last_ret = 0;
@@ -64,7 +63,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		return -ENOMEM;
 
 	level = btrfs_header_level(root->node);
-	orig_level = level;
 
 	if (level == 0)
 		goto out;

commit 8929ecfa50f266163832eeacfbc3642ed5eb83b6
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:58 2010 -0400

    Btrfs: Introduce global metadata reservation
    
    Reserve metadata space for extent tree, checksum tree and root tree
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index b10eacdb1620..f7ac8e013ed7 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -117,13 +117,14 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 				 path->nodes[1], 0,
 				 cache_only, &last_ret,
 				 &root->defrag_progress);
-	WARN_ON(ret && ret != -EAGAIN);
+	if (ret) {
+		WARN_ON(ret == -EAGAIN);
+		goto out;
+	}
 	if (next_key_ret == 0) {
 		memcpy(&root->defrag_progress, &key, sizeof(key));
 		ret = -EAGAIN;
 	}
-
-	btrfs_release_path(root, path);
 out:
 	if (path)
 		btrfs_free_path(path);

commit 56bec294dea971335d4466b30f2d959f28f6e36d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 10:10:06 2009 -0400

    Btrfs: do extent allocation and reference count updates in the background
    
    The extent allocation tree maintains a reference count and full
    back reference information for every extent allocated in the
    filesystem.  For subvolume and snapshot trees, every time
    a block goes through COW, the new copy of the block adds a reference
    on every block it points to.
    
    If a btree node points to 150 leaves, then the COW code needs to go
    and add backrefs on 150 different extents, which might be spread all
    over the extent allocation tree.
    
    These updates currently happen during btrfs_cow_block, and most COWs
    happen during btrfs_search_slot.  btrfs_search_slot has locks held
    on both the parent and the node we are COWing, and so we really want
    to avoid IO during the COW if we can.
    
    This commit adds an rbtree of pending reference count updates and extent
    allocations.  The tree is ordered by byte number of the extent and byte number
    of the parent for the back reference.  The tree allows us to:
    
    1) Modify back references in something close to disk order, reducing seeks
    2) Significantly reduce the number of modifications made as block pointers
    are balanced around
    3) Do all of the extent insertion and back reference modifications outside
    of the performance critical btrfs_search_slot code.
    
    #3 has the added benefit of greatly reducing the btrfs stack footprint.
    The extent allocation tree modifications are done without the deep
    (and somewhat recursive) call chains used in the past.
    
    These delayed back reference updates must be done before the transaction
    commits, and so the rbtree is tied to the transaction.  Throttling is
    implemented to help keep the queue of backrefs at a reasonable size.
    
    Since there was a similar mechanism in place for the extent tree
    extents, that is removed and replaced by the delayed reference tree.
    
    Yan Zheng <yan.zheng@oracle.com> helped review and fixup this code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 98d25fa4570e..b10eacdb1620 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -124,8 +124,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	}
 
 	btrfs_release_path(root, path);
-	if (is_extent)
-		btrfs_extent_post_op(trans, root);
 out:
 	if (path)
 		btrfs_free_path(path);

commit b4ce94de9b4d64e8ab3cf155d13653c666e22b9b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 4 09:25:08 2009 -0500

    Btrfs: Change btree locking to use explicit blocking points
    
    Most of the btrfs metadata operations can be protected by a spinlock,
    but some operations still need to schedule.
    
    So far, btrfs has been using a mutex along with a trylock loop,
    most of the time it is able to avoid going for the full mutex, so
    the trylock loop is a big performance gain.
    
    This commit is step one for getting rid of the blocking locks entirely.
    btrfs_tree_lock takes a spinlock, and the code explicitly switches
    to a blocking lock when it starts an operation that can schedule.
    
    We'll be able get rid of the blocking locks in smaller pieces over time.
    Tracing allows us to find the most common cause of blocking, so we
    can start with the hot spots first.
    
    The basic idea is:
    
    btrfs_tree_lock() returns with the spin lock held
    
    btrfs_set_lock_blocking() sets the EXTENT_BUFFER_BLOCKING bit in
    the extent buffer flags, and then drops the spin lock.  The buffer is
    still considered locked by all of the btrfs code.
    
    If btrfs_tree_lock gets the spinlock but finds the blocking bit set, it drops
    the spin lock and waits on a wait queue for the blocking bit to go away.
    
    Much of the code that needs to set the blocking bit finishes without actually
    blocking a good percentage of the time.  So, an adaptive spin is still
    used against the blocking bit to avoid very high context switch rates.
    
    btrfs_clear_lock_blocking() clears the blocking bit and returns
    with the spinlock held again.
    
    btrfs_tree_unlock() can be called on either blocking or spinning locks,
    it does the right thing based on the blocking bit.
    
    ctree.c has a helper function to set/clear all the locked buffers in a
    path as blocking.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 3e8358c36165..98d25fa4570e 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -74,6 +74,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		u32 nritems;
 
 		root_node = btrfs_lock_root_node(root);
+		btrfs_set_lock_blocking(root_node);
 		nritems = btrfs_header_nritems(root_node);
 		root->defrag_max.objectid = 0;
 		/* from above we know this is not a leaf */

commit d397712bcc6a759a560fd247e6053ecae091f958
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 5 21:25:51 2009 -0500

    Btrfs: Fix checkpatch.pl warnings
    
    There were many, most are fixed now.  struct-funcs.c generates some warnings
    but these are bogus.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index a6a3956cedfb..3e8358c36165 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -23,10 +23,11 @@
 #include "transaction.h"
 #include "locking.h"
 
-/* defrag all the leaves in a given btree.  If cache_only == 1, don't read things
- * from disk, otherwise read all the leaves and try to get key order to
+/* defrag all the leaves in a given btree.  If cache_only == 1, don't read
+ * things from disk, otherwise read all the leaves and try to get key order to
  * better reflect disk order
  */
+
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, int cache_only)
 {
@@ -65,9 +66,9 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	level = btrfs_header_level(root->node);
 	orig_level = level;
 
-	if (level == 0) {
+	if (level == 0)
 		goto out;
-	}
+
 	if (root->defrag_progress.objectid == 0) {
 		struct extent_buffer *root_node;
 		u32 nritems;

commit 2517920135b0d29e70453e5b03d70d7b94207df3
Author: Josef Bacik <jbacik@redhat.com>
Date:   Wed Oct 29 14:49:05 2008 -0400

    Btrfs: nuke fs wide allocation mutex V2
    
    This patch removes the giant fs_info->alloc_mutex and replaces it with a bunch
    of little locks.
    
    There is now a pinned_mutex, which is used when messing with the pinned_extents
    extent io tree, and the extent_ins_mutex which is used with the pending_del and
    extent_ins extent io trees.
    
    The locking for the extent tree stuff was inspired by a patch that Yan Zheng
    wrote to fix a race condition, I cleaned it up some and changed the locking
    around a little bit, but the idea remains the same.  Basically instead of
    holding the extent_ins_mutex throughout the processing of an extent on the
    extent_ins or pending_del trees, we just hold it while we're searching and when
    we clear the bits on those trees, and lock the extent for the duration of the
    operations on the extent.
    
    Also to keep from getting hung up waiting to lock an extent, I've added a
    try_lock_extent so if we cannot lock the extent, move on to the next one in the
    tree and we'll come back to that one.  I have tested this heavily and it does
    not appear to break anything.  This has to be applied on top of my
    find_free_extent redo patch.
    
    I tested this patch on top of Yan's space reblancing code and it worked fine.
    The only thing that has changed since the last version is I pulled out all my
    debugging stuff, apparently I forgot to run guilt refresh before I sent the
    last patch out.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 6f57d0889b1e..a6a3956cedfb 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -125,9 +125,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	if (is_extent)
 		btrfs_extent_post_op(trans, root);
 out:
-	if (is_extent)
-		mutex_unlock(&root->fs_info->alloc_mutex);
-
 	if (path)
 		btrfs_free_path(path);
 	if (ret == -EAGAIN) {

commit d352ac68148b69937d39ca5d48bcc4478e118dbf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 29 15:18:18 2008 -0400

    Btrfs: add and improve comments
    
    This improves the comments at the top of many functions.  It didn't
    dive into the guts of functions because I was trying to
    avoid merging problems with the new allocator and back reference work.
    
    extent-tree.c and volumes.c were both skipped, and there is definitely
    more work todo in cleaning and commenting the code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index b3bb5bbad76e..6f57d0889b1e 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -23,6 +23,10 @@
 #include "transaction.h"
 #include "locking.h"
 
+/* defrag all the leaves in a given btree.  If cache_only == 1, don't read things
+ * from disk, otherwise read all the leaves and try to get key order to
+ * better reflect disk order
+ */
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, int cache_only)
 {

commit e02119d5a7b4396c5a872582fddc8bd6d305a70a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 5 16:13:11 2008 -0400

    Btrfs: Add a write ahead tree log to optimize synchronous operations
    
    File syncs and directory syncs are optimized by copying their
    items into a special (copy-on-write) log tree.  There is one log tree per
    subvolume and the btrfs super block points to a tree of log tree roots.
    
    After a crash, items are copied out of the log tree and back into the
    subvolume.  See tree-log.c for all the details.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index cc2650b06952..b3bb5bbad76e 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -81,12 +81,12 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		memcpy(&key, &root->defrag_progress, sizeof(key));
 	}
 
-	path->lowest_level = 1;
 	path->keep_locks = 1;
 	if (cache_only)
 		min_trans = root->defrag_trans_start;
 
-	ret = btrfs_search_forward(root, &key, path, cache_only, min_trans);
+	ret = btrfs_search_forward(root, &key, NULL, path,
+				   cache_only, min_trans);
 	if (ret < 0)
 		goto out;
 	if (ret > 0) {

commit 3f157a2fd2ad731e1ed9964fecdc5f459f04a4a4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Online btree defragmentation fixes
    
    The btree defragger wasn't making forward progress because the new key wasn't
    being saved by the btrfs_search_forward function.
    
    This also disables the automatic btree defrag, it wasn't scaling well to
    huge filesystems.  The auto-defrag needs to be done differently.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index b17693f61fbc..cc2650b06952 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -32,10 +32,13 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	int wret;
 	int level;
 	int orig_level;
-	int i;
 	int is_extent = 0;
 	int next_key_ret = 0;
 	u64 last_ret = 0;
+	u64 min_trans = 0;
+
+	if (cache_only)
+		goto out;
 
 	if (root->fs_info->extent_root == root) {
 		/*
@@ -43,10 +46,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		 * we can't defrag the extent root without deadlock
 		 */
 		goto out;
-#if 0
-		mutex_lock(&root->fs_info->alloc_mutex);
-		is_extent = 1;
-#endif
 	}
 
 	if (root->ref_cows == 0 && !is_extent)
@@ -84,6 +83,17 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 
 	path->lowest_level = 1;
 	path->keep_locks = 1;
+	if (cache_only)
+		min_trans = root->defrag_trans_start;
+
+	ret = btrfs_search_forward(root, &key, path, cache_only, min_trans);
+	if (ret < 0)
+		goto out;
+	if (ret > 0) {
+		ret = 0;
+		goto out;
+	}
+	btrfs_release_path(root, path);
 	wret = btrfs_search_slot(trans, root, &key, path, 0, 1);
 
 	if (wret < 0) {
@@ -95,7 +105,8 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		goto out;
 	}
 	path->slots[1] = btrfs_header_nritems(path->nodes[1]);
-	next_key_ret = btrfs_find_next_key(root, path, &key, 1);
+	next_key_ret = btrfs_find_next_key(root, path, &key, 1, cache_only,
+					   min_trans);
 	ret = btrfs_realloc_node(trans, root,
 				 path->nodes[1], 0,
 				 cache_only, &last_ret,
@@ -106,19 +117,9 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		ret = -EAGAIN;
 	}
 
-	for (i = 1; i < BTRFS_MAX_LEVEL; i++) {
-		if (path->locks[i]) {
-			btrfs_tree_unlock(path->nodes[i]);
-			path->locks[i] = 0;
-		}
-		if (path->nodes[i]) {
-			free_extent_buffer(path->nodes[i]);
-			path->nodes[i] = NULL;
-		}
-	}
+	btrfs_release_path(root, path);
 	if (is_extent)
 		btrfs_extent_post_op(trans, root);
-
 out:
 	if (is_extent)
 		mutex_unlock(&root->fs_info->alloc_mutex);
@@ -138,6 +139,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	if (ret != -EAGAIN) {
 		memset(&root->defrag_progress, 0,
 		       sizeof(root->defrag_progress));
+		root->defrag_trans_start = trans->transid;
 	}
 	return ret;
 }

commit 1b1e2135dc1e4efbcf25ac9ac9979316d4e1193e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Add a per-inode csum mutex to avoid races creating csum items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 1677e4edaf6f..b17693f61fbc 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -38,8 +38,15 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	u64 last_ret = 0;
 
 	if (root->fs_info->extent_root == root) {
+		/*
+		 * there's recursion here right now in the tree locking,
+		 * we can't defrag the extent root without deadlock
+		 */
+		goto out;
+#if 0
 		mutex_lock(&root->fs_info->alloc_mutex);
 		is_extent = 1;
+#endif
 	}
 
 	if (root->ref_cows == 0 && !is_extent)

commit e7a84565bcdb239caad29ccbe559ef978090ac7e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Add btree locking to the tree defragmentation code
    
    The online btree defragger is simplified and rewritten to use
    standard btree searches instead of a walk up / down mechanism.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index fab851d85383..1677e4edaf6f 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -21,167 +21,26 @@
 #include "disk-io.h"
 #include "print-tree.h"
 #include "transaction.h"
-
-static void reada_defrag(struct btrfs_root *root,
-			 struct extent_buffer *node)
-{
-	int i;
-	u32 nritems;
-	u64 bytenr;
-	u64 gen;
-	u32 blocksize;
-	int ret;
-
-	blocksize = btrfs_level_size(root, btrfs_header_level(node) - 1);
-	nritems = btrfs_header_nritems(node);
-	for (i = 0; i < nritems; i++) {
-		bytenr = btrfs_node_blockptr(node, i);
-		gen = btrfs_node_ptr_generation(node, i);
-		ret = readahead_tree_block(root, bytenr, blocksize, gen);
-		if (ret)
-			break;
-	}
-}
-
-static int defrag_walk_down(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root,
-			    struct btrfs_path *path, int *level,
-			    int cache_only, u64 *last_ret)
-{
-	struct extent_buffer *next;
-	struct extent_buffer *cur;
-	u64 bytenr;
-	u64 ptr_gen;
-	int ret = 0;
-	int is_extent = 0;
-
-	WARN_ON(*level < 0);
-	WARN_ON(*level >= BTRFS_MAX_LEVEL);
-
-	if (root->fs_info->extent_root == root)
-		is_extent = 1;
-
-	if (*level == 1 && cache_only && path->nodes[1] &&
-	    !btrfs_buffer_defrag(path->nodes[1])) {
-		goto out;
-	}
-	while(*level > 0) {
-		WARN_ON(*level < 0);
-		WARN_ON(*level >= BTRFS_MAX_LEVEL);
-		cur = path->nodes[*level];
-
-		if (!cache_only && *level > 1 && path->slots[*level] == 0)
-			reada_defrag(root, cur);
-
-		if (btrfs_header_level(cur) != *level)
-			WARN_ON(1);
-
-		if (path->slots[*level] >=
-		    btrfs_header_nritems(cur))
-			break;
-
-		if (*level == 1) {
-			WARN_ON(btrfs_header_generation(path->nodes[*level]) !=
-							trans->transid);
-			ret = btrfs_realloc_node(trans, root,
-						 path->nodes[*level],
-						 path->slots[*level],
-						 cache_only, last_ret,
-						 &root->defrag_progress);
-			if (is_extent)
-				btrfs_extent_post_op(trans, root);
-
-			break;
-		}
-		bytenr = btrfs_node_blockptr(cur, path->slots[*level]);
-		ptr_gen = btrfs_node_ptr_generation(cur, path->slots[*level]);
-
-		if (cache_only) {
-			next = btrfs_find_tree_block(root, bytenr,
-					   btrfs_level_size(root, *level - 1));
-			if (!next || !btrfs_buffer_uptodate(next, ptr_gen) ||
-			    !btrfs_buffer_defrag(next)) {
-				free_extent_buffer(next);
-				path->slots[*level]++;
-				continue;
-			}
-		} else {
-			next = read_tree_block(root, bytenr,
-				       btrfs_level_size(root, *level - 1),
-				       ptr_gen);
-		}
-		ret = btrfs_cow_block(trans, root, next, path->nodes[*level],
-				      path->slots[*level], &next);
-		BUG_ON(ret);
-		if (is_extent)
-			btrfs_extent_post_op(trans, root);
-
-		WARN_ON(*level <= 0);
-		if (path->nodes[*level-1])
-			free_extent_buffer(path->nodes[*level-1]);
-		path->nodes[*level-1] = next;
-		*level = btrfs_header_level(next);
-		path->slots[*level] = 0;
-	}
-	WARN_ON(*level < 0);
-	WARN_ON(*level >= BTRFS_MAX_LEVEL);
-
-	btrfs_clear_buffer_defrag(path->nodes[*level]);
-out:
-	free_extent_buffer(path->nodes[*level]);
-	path->nodes[*level] = NULL;
-	*level += 1;
-	WARN_ON(ret && ret != -EAGAIN);
-	return ret;
-}
-
-static int defrag_walk_up(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root,
-			  struct btrfs_path *path, int *level,
-			  int cache_only)
-{
-	int i;
-	int slot;
-	struct extent_buffer *node;
-
-	for(i = *level; i < BTRFS_MAX_LEVEL - 1 && path->nodes[i]; i++) {
-		slot = path->slots[i];
-		if (slot < btrfs_header_nritems(path->nodes[i]) - 1) {
-			path->slots[i]++;
-			*level = i;
-			node = path->nodes[i];
-			WARN_ON(i == 0);
-			btrfs_node_key_to_cpu(node, &root->defrag_progress,
-					      path->slots[i]);
-			root->defrag_level = i;
-			return 0;
-		} else {
-			btrfs_clear_buffer_defrag(path->nodes[*level]);
-			free_extent_buffer(path->nodes[*level]);
-			path->nodes[*level] = NULL;
-			*level = i + 1;
-		}
-	}
-	return 1;
-}
+#include "locking.h"
 
 int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, int cache_only)
 {
 	struct btrfs_path *path = NULL;
-	struct extent_buffer *tmp;
+	struct btrfs_key key;
 	int ret = 0;
 	int wret;
 	int level;
 	int orig_level;
 	int i;
 	int is_extent = 0;
+	int next_key_ret = 0;
 	u64 last_ret = 0;
 
-	if (root->fs_info->extent_root == root)
+	if (root->fs_info->extent_root == root) {
+		mutex_lock(&root->fs_info->alloc_mutex);
 		is_extent = 1;
-
-	goto out;
+	}
 
 	if (root->ref_cows == 0 && !is_extent)
 		goto out;
@@ -200,67 +59,63 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		goto out;
 	}
 	if (root->defrag_progress.objectid == 0) {
+		struct extent_buffer *root_node;
 		u32 nritems;
 
-		nritems = btrfs_header_nritems(root->node);
+		root_node = btrfs_lock_root_node(root);
+		nritems = btrfs_header_nritems(root_node);
 		root->defrag_max.objectid = 0;
 		/* from above we know this is not a leaf */
-		btrfs_node_key_to_cpu(root->node, &root->defrag_max,
+		btrfs_node_key_to_cpu(root_node, &root->defrag_max,
 				      nritems - 1);
-		extent_buffer_get(root->node);
-		ret = btrfs_cow_block(trans, root, root->node, NULL, 0, &tmp);
-		BUG_ON(ret);
-		path->nodes[level] = root->node;
-		path->slots[level] = 0;
-		if (is_extent)
-			btrfs_extent_post_op(trans, root);
+		btrfs_tree_unlock(root_node);
+		free_extent_buffer(root_node);
+		memset(&key, 0, sizeof(key));
 	} else {
-		level = root->defrag_level;
-		path->lowest_level = level;
-		wret = btrfs_search_slot(trans, root, &root->defrag_progress,
-					 path, 0, 1);
-
-		if (is_extent)
-			btrfs_extent_post_op(trans, root);
-
-		if (wret < 0) {
-			ret = wret;
-			goto out;
-		}
-
-		while(level > 0 && !path->nodes[level])
-			level--;
-
-		if (!path->nodes[level]) {
-			ret = 0;
-			goto out;
-		}
+		memcpy(&key, &root->defrag_progress, sizeof(key));
 	}
 
-	while(1) {
-		wret = defrag_walk_down(trans, root, path, &level, cache_only,
-					&last_ret);
-		if (wret > 0)
-			break;
-		if (wret < 0)
-			ret = wret;
+	path->lowest_level = 1;
+	path->keep_locks = 1;
+	wret = btrfs_search_slot(trans, root, &key, path, 0, 1);
 
-		wret = defrag_walk_up(trans, root, path, &level, cache_only);
-		if (wret > 0)
-			break;
-		if (wret < 0)
-			ret = wret;
-		else
-			ret = -EAGAIN;
-		break;
+	if (wret < 0) {
+		ret = wret;
+		goto out;
+	}
+	if (!path->nodes[1]) {
+		ret = 0;
+		goto out;
+	}
+	path->slots[1] = btrfs_header_nritems(path->nodes[1]);
+	next_key_ret = btrfs_find_next_key(root, path, &key, 1);
+	ret = btrfs_realloc_node(trans, root,
+				 path->nodes[1], 0,
+				 cache_only, &last_ret,
+				 &root->defrag_progress);
+	WARN_ON(ret && ret != -EAGAIN);
+	if (next_key_ret == 0) {
+		memcpy(&root->defrag_progress, &key, sizeof(key));
+		ret = -EAGAIN;
 	}
-	for (i = 0; i <= orig_level; i++) {
+
+	for (i = 1; i < BTRFS_MAX_LEVEL; i++) {
+		if (path->locks[i]) {
+			btrfs_tree_unlock(path->nodes[i]);
+			path->locks[i] = 0;
+		}
 		if (path->nodes[i]) {
 			free_extent_buffer(path->nodes[i]);
 			path->nodes[i] = NULL;
 		}
 	}
+	if (is_extent)
+		btrfs_extent_post_op(trans, root);
+
 out:
+	if (is_extent)
+		mutex_unlock(&root->fs_info->alloc_mutex);
+
 	if (path)
 		btrfs_free_path(path);
 	if (ret == -EAGAIN) {

commit 925baeddc5b0764a53f2214a1253251bab0e0324
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Btrfs: Start btree concurrency work.
    
    The allocation trees and the chunk trees are serialized via their own
    dedicated mutexes.  This means allocation location is still not very
    fine grained.
    
    The main FS btree is protected by locks on each block in the btree.  Locks
    are taken top / down, and as processing finishes on a given level of the
    tree, the lock is released after locking the lower level.
    
    The end result of a search is now a path where only the lowest level
    is locked.  Releasing or freeing the path drops any locks held.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 155961c7b4d5..fab851d85383 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -181,6 +181,8 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	if (root->fs_info->extent_root == root)
 		is_extent = 1;
 
+	goto out;
+
 	if (root->ref_cows == 0 && !is_extent)
 		goto out;
 

commit 0ef3e66b6700eb8f052daa8b89443ff872fbbdfc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat May 24 14:04:53 2008 -0400

    Btrfs: Allocator fix variety pack
    
    * Force chunk allocation when find_free_extent has to do a full scan
    * Record the max key at the start of defrag so it doesn't run forever
    * Block groups might not be contiguous, make a forward search for the
      next block group in extent-tree.c
    * Get rid of extra checks for total fs size
    * Fix relocate_one_reference to avoid relocating the same file data block
      twice when referenced by an older transaction
    * Use the open device count when allocating chunks so that we don't
      try to allocate from devices that don't exist
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index c02e2bf2f028..155961c7b4d5 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -198,6 +198,13 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		goto out;
 	}
 	if (root->defrag_progress.objectid == 0) {
+		u32 nritems;
+
+		nritems = btrfs_header_nritems(root->node);
+		root->defrag_max.objectid = 0;
+		/* from above we know this is not a leaf */
+		btrfs_node_key_to_cpu(root->node, &root->defrag_max,
+				      nritems - 1);
 		extent_buffer_get(root->node);
 		ret = btrfs_cow_block(trans, root, root->node, NULL, 0, &tmp);
 		BUG_ON(ret);
@@ -254,6 +261,16 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 out:
 	if (path)
 		btrfs_free_path(path);
+	if (ret == -EAGAIN) {
+		if (root->defrag_max.objectid > root->defrag_progress.objectid)
+			goto done;
+		if (root->defrag_max.type > root->defrag_progress.type)
+			goto done;
+		if (root->defrag_max.offset > root->defrag_progress.offset)
+			goto done;
+		ret = 0;
+	}
+done:
 	if (ret != -EAGAIN) {
 		memset(&root->defrag_progress, 0,
 		       sizeof(root->defrag_progress));

commit 1259ab75c62462b8ffad90067b5e1f6312786a18
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 12 13:39:03 2008 -0400

    Btrfs: Handle write errors on raid1 and raid10
    
    When duplicate copies exist, writes are allowed to fail to one of those
    copies.  This changeset includes a few changes that allow the FS to
    continue even when some IOs fail.
    
    It also adds verification of the parent generation number for btree blocks.
    This generation is stored in the pointer to a block, and it ensures
    that missed writes to are detected.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 5085e9e693b9..c02e2bf2f028 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -51,6 +51,7 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 	struct extent_buffer *next;
 	struct extent_buffer *cur;
 	u64 bytenr;
+	u64 ptr_gen;
 	int ret = 0;
 	int is_extent = 0;
 
@@ -93,11 +94,12 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 			break;
 		}
 		bytenr = btrfs_node_blockptr(cur, path->slots[*level]);
+		ptr_gen = btrfs_node_ptr_generation(cur, path->slots[*level]);
 
 		if (cache_only) {
 			next = btrfs_find_tree_block(root, bytenr,
 					   btrfs_level_size(root, *level - 1));
-			if (!next || !btrfs_buffer_uptodate(next) ||
+			if (!next || !btrfs_buffer_uptodate(next, ptr_gen) ||
 			    !btrfs_buffer_defrag(next)) {
 				free_extent_buffer(next);
 				path->slots[*level]++;
@@ -106,8 +108,7 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 		} else {
 			next = read_tree_block(root, bytenr,
 				       btrfs_level_size(root, *level - 1),
-				       btrfs_node_ptr_generation(cur,
-							 path->slots[*level]));
+				       ptr_gen);
 		}
 		ret = btrfs_cow_block(trans, root, next, path->nodes[*level],
 				      path->slots[*level], &next);

commit ca7a79ad8dbe24669a8ced01f9fc0126b872745d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 12 12:59:19 2008 -0400

    Btrfs: Pass down the expected generation number when reading tree blocks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 256af1870eef..5085e9e693b9 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -28,6 +28,7 @@ static void reada_defrag(struct btrfs_root *root,
 	int i;
 	u32 nritems;
 	u64 bytenr;
+	u64 gen;
 	u32 blocksize;
 	int ret;
 
@@ -35,7 +36,8 @@ static void reada_defrag(struct btrfs_root *root,
 	nritems = btrfs_header_nritems(node);
 	for (i = 0; i < nritems; i++) {
 		bytenr = btrfs_node_blockptr(node, i);
-		ret = readahead_tree_block(root, bytenr, blocksize);
+		gen = btrfs_node_ptr_generation(node, i);
+		ret = readahead_tree_block(root, bytenr, blocksize, gen);
 		if (ret)
 			break;
 	}
@@ -101,10 +103,11 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 				path->slots[*level]++;
 				continue;
 			}
-			btrfs_verify_block_csum(root, next);
 		} else {
 			next = read_tree_block(root, bytenr,
-				       btrfs_level_size(root, *level - 1));
+				       btrfs_level_size(root, *level - 1),
+				       btrfs_node_ptr_generation(cur,
+							 path->slots[*level]));
 		}
 		ret = btrfs_cow_block(trans, root, next, path->nodes[*level],
 				      path->slots[*level], &next);

commit 0999df54f850fe1aba29b10d5c869493af107478
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 1 13:48:14 2008 -0400

    Btrfs: Verify checksums on tree blocks found without read_tree_block
    
    Checksums were only verified by btrfs_read_tree_block, which meant the
    functions to probe the page cache for blocks were not validating checksums.
    Normally this is fine because the buffers will only be in cache if they
    have already been validated.
    
    But, there is a window while the buffer is being read from disk where
    it could be up to date in the cache but not yet verified.  This patch
    makes sure all buffers go through checksum verification before they
    are used.
    
    This is safer, and it prevents modification of buffers before they go
    through the csum code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 5935cbd8f2b8..256af1870eef 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -101,6 +101,7 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 				path->slots[*level]++;
 				continue;
 			}
+			btrfs_verify_block_csum(root, next);
 		} else {
 			next = read_tree_block(root, bytenr,
 				       btrfs_level_size(root, *level - 1));

commit 9afbb0b752ef30a429c45b9de6706e28ad1a36e1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Feb 15 13:19:35 2008 -0500

    Btrfs: Disable tree defrag in SSD mode
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 5c58630dce03..5935cbd8f2b8 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -179,6 +179,9 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	if (root->ref_cows == 0 && !is_extent)
 		goto out;
 
+	if (btrfs_test_opt(root, SSD))
+		goto out;
+
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;

commit b3236e68bf86b3ae87f58984a1822369225211cb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 29 16:06:37 2008 -0500

    Btrfs: Leave on the tree defragger in mount -o ssd, it still helps there
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 5935cbd8f2b8..5c58630dce03 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -179,9 +179,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	if (root->ref_cows == 0 && !is_extent)
 		goto out;
 
-	if (btrfs_test_opt(root, SSD))
-		goto out;
-
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;

commit e18e4809b10e6c9efb5fe10c1ddcb4ebb690d517
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jan 18 10:54:22 2008 -0500

    Btrfs: Add mount -o ssd, which includes optimizations for seek free storage
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 5c58630dce03..5935cbd8f2b8 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -179,6 +179,9 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	if (root->ref_cows == 0 && !is_extent)
 		goto out;
 
+	if (btrfs_test_opt(root, SSD))
+		goto out;
+
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;

commit 7bb86316c3961d1bc401ef184fd996f999556c7f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 11 09:25:06 2007 -0500

    Btrfs: Add back pointers from extents to the btree or file referencing them
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 3994795edfeb..5c58630dce03 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -78,6 +78,8 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 			break;
 
 		if (*level == 1) {
+			WARN_ON(btrfs_header_generation(path->nodes[*level]) !=
+							trans->transid);
 			ret = btrfs_realloc_node(trans, root,
 						 path->nodes[*level],
 						 path->slots[*level],

commit f84a8b362d9785ca1fa0598d8a90f35184bd8750
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 6 10:26:29 2007 -0500

    Btrfs: Optimize allocations as we need to mix data and metadata into one group
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 6ef1ba5f9c2f..3994795edfeb 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -58,6 +58,10 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 	if (root->fs_info->extent_root == root)
 		is_extent = 1;
 
+	if (*level == 1 && cache_only && path->nodes[1] &&
+	    !btrfs_buffer_defrag(path->nodes[1])) {
+		goto out;
+	}
 	while(*level > 0) {
 		WARN_ON(*level < 0);
 		WARN_ON(*level >= BTRFS_MAX_LEVEL);
@@ -116,7 +120,7 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 	WARN_ON(*level >= BTRFS_MAX_LEVEL);
 
 	btrfs_clear_buffer_defrag(path->nodes[*level]);
-
+out:
 	free_extent_buffer(path->nodes[*level]);
 	path->nodes[*level] = NULL;
 	*level += 1;

commit 081e95736d9118a96e9f6dcc5cec02dc75c9e1cb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 6 10:26:24 2007 -0500

    Btrfs: Make defrag check nodes against the progress key to prevent repeating work
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 65ef12351566..6ef1ba5f9c2f 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -227,7 +227,8 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			break;
 		if (wret < 0)
 			ret = wret;
-		ret = -EAGAIN;
+		else
+			ret = -EAGAIN;
 		break;
 	}
 	for (i = 0; i <= orig_level; i++) {

commit 5708b9591617486bf1aa5b1a97f2c0549ec87933
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Oct 25 15:43:18 2007 -0400

    Btrfs: Tune the automatic defrag code
    
    1) Forced defrag wasn't working properly (btrfsctl -d) because some
    cache only checks were incorrect.
    
    2) Defrag only the leaves unless in forced defrag mode.
    
    3) Don't use complex logic to figure out if a leaf is needs defrag
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index b02355a7b143..65ef12351566 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -183,7 +183,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	if (level == 0) {
 		goto out;
 	}
-
 	if (root->defrag_progress.objectid == 0) {
 		extent_buffer_get(root->node);
 		ret = btrfs_cow_block(trans, root, root->node, NULL, 0, &tmp);

commit a6b6e75e096f436f0cc56edf5bca96301e194491
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:22:39 2007 -0400

    Btrfs: Defrag only leaves, and only when the parent node has a single objectid
    
    This allows us to defrag huge directories, but skip the expensive defrag
    case in more common usage, where it does not help as much.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index f86eccf511b9..b02355a7b143 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -76,7 +76,9 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 		if (*level == 1) {
 			ret = btrfs_realloc_node(trans, root,
 						 path->nodes[*level],
-						 cache_only, last_ret);
+						 path->slots[*level],
+						 cache_only, last_ret,
+						 &root->defrag_progress);
 			if (is_extent)
 				btrfs_extent_post_op(trans, root);
 
@@ -100,10 +102,6 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 		ret = btrfs_cow_block(trans, root, next, path->nodes[*level],
 				      path->slots[*level], &next);
 		BUG_ON(ret);
-		ret = btrfs_realloc_node(trans, root, next, cache_only,
-					 last_ret);
-		BUG_ON(ret);
-
 		if (is_extent)
 			btrfs_extent_post_op(trans, root);
 
@@ -122,8 +120,8 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 	free_extent_buffer(path->nodes[*level]);
 	path->nodes[*level] = NULL;
 	*level += 1;
-	WARN_ON(ret);
-	return 0;
+	WARN_ON(ret && ret != -EAGAIN);
+	return ret;
 }
 
 static int defrag_walk_up(struct btrfs_trans_handle *trans,
@@ -147,27 +145,6 @@ static int defrag_walk_up(struct btrfs_trans_handle *trans,
 			root->defrag_level = i;
 			return 0;
 		} else {
-			if (*level > 1 && path->nodes[*level] != root->node &&
-			    btrfs_buffer_defrag(path->nodes[*level])) {
-				struct extent_buffer *next;
-				u64 last;
-				int ret;
-				ret = btrfs_cow_block(trans, root,
-						      path->nodes[*level],
-						      path->nodes[*level + 1],
-						      path->slots[*level + 1],
-						      &next);
-				BUG_ON(ret);
-				path->nodes[*level] = next;
-				last = next->start;
-				ret = btrfs_realloc_node(trans, root, next,
-							 cache_only, &last);
-				BUG_ON(ret);
-
-				if (root == root->fs_info->extent_root)
-					btrfs_extent_post_op(trans, root);
-			}
-
 			btrfs_clear_buffer_defrag(path->nodes[*level]);
 			free_extent_buffer(path->nodes[*level]);
 			path->nodes[*level] = NULL;
@@ -211,9 +188,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		extent_buffer_get(root->node);
 		ret = btrfs_cow_block(trans, root, root->node, NULL, 0, &tmp);
 		BUG_ON(ret);
-		ret = btrfs_realloc_node(trans, root, root->node, cache_only,
-					 &last_ret);
-		BUG_ON(ret);
 		path->nodes[level] = root->node;
 		path->slots[level] = 0;
 		if (is_extent)

commit cf786e79e3f96f4bc037c69e1a7afb5fb85c6111
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:22:11 2007 -0400

    Btrfs: Defrag: only walk into nodes with the defrag bit set
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index d31c21ac6f23..f86eccf511b9 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -87,8 +87,8 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 		if (cache_only) {
 			next = btrfs_find_tree_block(root, bytenr,
 					   btrfs_level_size(root, *level - 1));
-			/* FIXME, test for defrag */
-			if (!next || !btrfs_buffer_uptodate(next)) {
+			if (!next || !btrfs_buffer_uptodate(next) ||
+			    !btrfs_buffer_defrag(next)) {
 				free_extent_buffer(next);
 				path->slots[*level]++;
 				continue;
@@ -147,7 +147,8 @@ static int defrag_walk_up(struct btrfs_trans_handle *trans,
 			root->defrag_level = i;
 			return 0;
 		} else {
-			if (*level > 1 && path->nodes[*level] != root->node) {
+			if (*level > 1 && path->nodes[*level] != root->node &&
+			    btrfs_buffer_defrag(path->nodes[*level])) {
 				struct extent_buffer *next;
 				u64 last;
 				int ret;
@@ -168,7 +169,6 @@ static int defrag_walk_up(struct btrfs_trans_handle *trans,
 			}
 
 			btrfs_clear_buffer_defrag(path->nodes[*level]);
-			btrfs_clear_buffer_defrag_done(path->nodes[*level]);
 			free_extent_buffer(path->nodes[*level]);
 			path->nodes[*level] = NULL;
 			*level = i + 1;

commit 0f1ebbd159baade0417f8f62f0cd6810cc950832
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:19:46 2007 -0400

    Btrfs: Large block related defrag optimizations
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 0d1a1be0995c..d31c21ac6f23 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -118,7 +118,6 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 	WARN_ON(*level >= BTRFS_MAX_LEVEL);
 
 	btrfs_clear_buffer_defrag(path->nodes[*level]);
-	btrfs_clear_buffer_defrag_done(path->nodes[*level]);
 
 	free_extent_buffer(path->nodes[*level]);
 	path->nodes[*level] = NULL;
@@ -148,6 +147,26 @@ static int defrag_walk_up(struct btrfs_trans_handle *trans,
 			root->defrag_level = i;
 			return 0;
 		} else {
+			if (*level > 1 && path->nodes[*level] != root->node) {
+				struct extent_buffer *next;
+				u64 last;
+				int ret;
+				ret = btrfs_cow_block(trans, root,
+						      path->nodes[*level],
+						      path->nodes[*level + 1],
+						      path->slots[*level + 1],
+						      &next);
+				BUG_ON(ret);
+				path->nodes[*level] = next;
+				last = next->start;
+				ret = btrfs_realloc_node(trans, root, next,
+							 cache_only, &last);
+				BUG_ON(ret);
+
+				if (root == root->fs_info->extent_root)
+					btrfs_extent_post_op(trans, root);
+			}
+
 			btrfs_clear_buffer_defrag(path->nodes[*level]);
 			btrfs_clear_buffer_defrag_done(path->nodes[*level]);
 			free_extent_buffer(path->nodes[*level]);
@@ -183,9 +202,11 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 
 	level = btrfs_header_level(root->node);
 	orig_level = level;
+
 	if (level == 0) {
 		goto out;
 	}
+
 	if (root->defrag_progress.objectid == 0) {
 		extent_buffer_get(root->node);
 		ret = btrfs_cow_block(trans, root, root->node, NULL, 0, &tmp);

commit 0f82731fc56448c2733f58e1f5db6c2cbfc90652
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:18:56 2007 -0400

    Breakout BTRFS_SETGET_FUNCS into a separate C file, the inlines were too big.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index d23216aa4ab5..0d1a1be0995c 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -239,7 +239,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	for (i = 0; i <= orig_level; i++) {
 		if (path->nodes[i]) {
 			free_extent_buffer(path->nodes[i]);
-			path->nodes[i] = 0;
+			path->nodes[i] = NULL;
 		}
 	}
 out:

commit 6b80053d02be41886344b5007d04e345311ec0b5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:17:34 2007 -0400

    Btrfs: Add back the online defragging code
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 3feac2f28628..d23216aa4ab5 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -116,10 +116,10 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 	}
 	WARN_ON(*level < 0);
 	WARN_ON(*level >= BTRFS_MAX_LEVEL);
-#if 0
-	clear_buffer_defrag(path->nodes[*level]);
-	clear_buffer_defrag_done(path->nodes[*level]);
-#endif
+
+	btrfs_clear_buffer_defrag(path->nodes[*level]);
+	btrfs_clear_buffer_defrag_done(path->nodes[*level]);
+
 	free_extent_buffer(path->nodes[*level]);
 	path->nodes[*level] = NULL;
 	*level += 1;
@@ -148,10 +148,8 @@ static int defrag_walk_up(struct btrfs_trans_handle *trans,
 			root->defrag_level = i;
 			return 0;
 		} else {
-			/*
-			clear_buffer_defrag(path->nodes[*level]);
-			clear_buffer_defrag_done(path->nodes[*level]);
-			*/
+			btrfs_clear_buffer_defrag(path->nodes[*level]);
+			btrfs_clear_buffer_defrag_done(path->nodes[*level]);
 			free_extent_buffer(path->nodes[*level]);
 			path->nodes[*level] = NULL;
 			*level = i + 1;

commit db94535db75e67fab12ccbb7f5ee548e33fed891
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:15:53 2007 -0400

    Btrfs: Allow tree blocks larger than the page size
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index daf019afa0a1..3feac2f28628 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -27,13 +27,15 @@ static void reada_defrag(struct btrfs_root *root,
 {
 	int i;
 	u32 nritems;
-	u64 blocknr;
+	u64 bytenr;
+	u32 blocksize;
 	int ret;
 
+	blocksize = btrfs_level_size(root, btrfs_header_level(node) - 1);
 	nritems = btrfs_header_nritems(node);
 	for (i = 0; i < nritems; i++) {
-		blocknr = btrfs_node_blockptr(node, i);
-		ret = readahead_tree_block(root, blocknr);
+		bytenr = btrfs_node_blockptr(node, i);
+		ret = readahead_tree_block(root, bytenr, blocksize);
 		if (ret)
 			break;
 	}
@@ -46,7 +48,7 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 {
 	struct extent_buffer *next;
 	struct extent_buffer *cur;
-	u64 blocknr;
+	u64 bytenr;
 	int ret = 0;
 	int is_extent = 0;
 
@@ -80,10 +82,11 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 
 			break;
 		}
-		blocknr = btrfs_node_blockptr(cur, path->slots[*level]);
+		bytenr = btrfs_node_blockptr(cur, path->slots[*level]);
 
 		if (cache_only) {
-			next = btrfs_find_tree_block(root, blocknr);
+			next = btrfs_find_tree_block(root, bytenr,
+					   btrfs_level_size(root, *level - 1));
 			/* FIXME, test for defrag */
 			if (!next || !btrfs_buffer_uptodate(next)) {
 				free_extent_buffer(next);
@@ -91,7 +94,8 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 				continue;
 			}
 		} else {
-			next = read_tree_block(root, blocknr);
+			next = read_tree_block(root, bytenr,
+				       btrfs_level_size(root, *level - 1));
 		}
 		ret = btrfs_cow_block(trans, root, next, path->nodes[*level],
 				      path->slots[*level], &next);

commit 5f39d397dfbe140a14edecd4e73c34ce23c4f9ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:19 2007 -0400

    Btrfs: Create extent_buffer interface for large blocksizes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 420597127ed1..daf019afa0a1 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -23,14 +23,14 @@
 #include "transaction.h"
 
 static void reada_defrag(struct btrfs_root *root,
-			 struct btrfs_node *node)
+			 struct extent_buffer *node)
 {
 	int i;
 	u32 nritems;
 	u64 blocknr;
 	int ret;
 
-	nritems = btrfs_header_nritems(&node->header);
+	nritems = btrfs_header_nritems(node);
 	for (i = 0; i < nritems; i++) {
 		blocknr = btrfs_node_blockptr(node, i);
 		ret = readahead_tree_block(root, blocknr);
@@ -44,8 +44,8 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 			    struct btrfs_path *path, int *level,
 			    int cache_only, u64 *last_ret)
 {
-	struct buffer_head *next;
-	struct buffer_head *cur;
+	struct extent_buffer *next;
+	struct extent_buffer *cur;
 	u64 blocknr;
 	int ret = 0;
 	int is_extent = 0;
@@ -62,13 +62,13 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 		cur = path->nodes[*level];
 
 		if (!cache_only && *level > 1 && path->slots[*level] == 0)
-			reada_defrag(root, btrfs_buffer_node(cur));
+			reada_defrag(root, cur);
 
-		if (btrfs_header_level(btrfs_buffer_header(cur)) != *level)
+		if (btrfs_header_level(cur) != *level)
 			WARN_ON(1);
 
 		if (path->slots[*level] >=
-		    btrfs_header_nritems(btrfs_buffer_header(cur)))
+		    btrfs_header_nritems(cur))
 			break;
 
 		if (*level == 1) {
@@ -80,14 +80,13 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 
 			break;
 		}
-		blocknr = btrfs_node_blockptr(btrfs_buffer_node(cur),
-					      path->slots[*level]);
+		blocknr = btrfs_node_blockptr(cur, path->slots[*level]);
 
 		if (cache_only) {
 			next = btrfs_find_tree_block(root, blocknr);
-			if (!next || !buffer_uptodate(next) ||
-			   buffer_locked(next) || !buffer_defrag(next)) {
-				brelse(next);
+			/* FIXME, test for defrag */
+			if (!next || !btrfs_buffer_uptodate(next)) {
+				free_extent_buffer(next);
 				path->slots[*level]++;
 				continue;
 			}
@@ -106,16 +105,18 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 
 		WARN_ON(*level <= 0);
 		if (path->nodes[*level-1])
-			btrfs_block_release(root, path->nodes[*level-1]);
+			free_extent_buffer(path->nodes[*level-1]);
 		path->nodes[*level-1] = next;
-		*level = btrfs_header_level(btrfs_buffer_header(next));
+		*level = btrfs_header_level(next);
 		path->slots[*level] = 0;
 	}
 	WARN_ON(*level < 0);
 	WARN_ON(*level >= BTRFS_MAX_LEVEL);
+#if 0
 	clear_buffer_defrag(path->nodes[*level]);
 	clear_buffer_defrag_done(path->nodes[*level]);
-	btrfs_block_release(root, path->nodes[*level]);
+#endif
+	free_extent_buffer(path->nodes[*level]);
 	path->nodes[*level] = NULL;
 	*level += 1;
 	WARN_ON(ret);
@@ -129,24 +130,25 @@ static int defrag_walk_up(struct btrfs_trans_handle *trans,
 {
 	int i;
 	int slot;
-	struct btrfs_node *node;
+	struct extent_buffer *node;
 
 	for(i = *level; i < BTRFS_MAX_LEVEL - 1 && path->nodes[i]; i++) {
 		slot = path->slots[i];
-		if (slot < btrfs_header_nritems(
-		    btrfs_buffer_header(path->nodes[i])) - 1) {
+		if (slot < btrfs_header_nritems(path->nodes[i]) - 1) {
 			path->slots[i]++;
 			*level = i;
-			node = btrfs_buffer_node(path->nodes[i]);
+			node = path->nodes[i];
 			WARN_ON(i == 0);
-			btrfs_disk_key_to_cpu(&root->defrag_progress,
-					      &node->ptrs[path->slots[i]].key);
+			btrfs_node_key_to_cpu(node, &root->defrag_progress,
+					      path->slots[i]);
 			root->defrag_level = i;
 			return 0;
 		} else {
+			/*
 			clear_buffer_defrag(path->nodes[*level]);
 			clear_buffer_defrag_done(path->nodes[*level]);
-			btrfs_block_release(root, path->nodes[*level]);
+			*/
+			free_extent_buffer(path->nodes[*level]);
 			path->nodes[*level] = NULL;
 			*level = i + 1;
 		}
@@ -158,7 +160,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			struct btrfs_root *root, int cache_only)
 {
 	struct btrfs_path *path = NULL;
-	struct buffer_head *tmp;
+	struct extent_buffer *tmp;
 	int ret = 0;
 	int wret;
 	int level;
@@ -172,17 +174,18 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 
 	if (root->ref_cows == 0 && !is_extent)
 		goto out;
+
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;
 
-	level = btrfs_header_level(btrfs_buffer_header(root->node));
+	level = btrfs_header_level(root->node);
 	orig_level = level;
 	if (level == 0) {
 		goto out;
 	}
 	if (root->defrag_progress.objectid == 0) {
-		get_bh(root->node);
+		extent_buffer_get(root->node);
 		ret = btrfs_cow_block(trans, root, root->node, NULL, 0, &tmp);
 		BUG_ON(ret);
 		ret = btrfs_realloc_node(trans, root, root->node, cache_only,
@@ -200,12 +203,15 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 
 		if (is_extent)
 			btrfs_extent_post_op(trans, root);
+
 		if (wret < 0) {
 			ret = wret;
 			goto out;
 		}
+
 		while(level > 0 && !path->nodes[level])
 			level--;
+
 		if (!path->nodes[level]) {
 			ret = 0;
 			goto out;
@@ -230,7 +236,7 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	}
 	for (i = 0; i <= orig_level; i++) {
 		if (path->nodes[i]) {
-			btrfs_block_release(root, path->nodes[i]);
+			free_extent_buffer(path->nodes[i]);
 			path->nodes[i] = 0;
 		}
 	}

commit 86479a04eef8f304a13aeb8b64bcc8e506a68268
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 10 19:58:16 2007 -0400

    Add support for defragging files via btrfsctl -d.  Avoid OOM on extent tree
    defrag.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 35fd20d24645..420597127ed1 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -113,6 +113,8 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 	}
 	WARN_ON(*level < 0);
 	WARN_ON(*level >= BTRFS_MAX_LEVEL);
+	clear_buffer_defrag(path->nodes[*level]);
+	clear_buffer_defrag_done(path->nodes[*level]);
 	btrfs_block_release(root, path->nodes[*level]);
 	path->nodes[*level] = NULL;
 	*level += 1;
@@ -143,6 +145,7 @@ static int defrag_walk_up(struct btrfs_trans_handle *trans,
 			return 0;
 		} else {
 			clear_buffer_defrag(path->nodes[*level]);
+			clear_buffer_defrag_done(path->nodes[*level]);
 			btrfs_block_release(root, path->nodes[*level]);
 			path->nodes[*level] = NULL;
 			*level = i + 1;

commit f2183bde1a918d338337955c8e8ba29bd8f5e7b1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 10 14:42:37 2007 -0400

    Btrfs: Add BH_Defrag to mark buffers that are in need of defragging
    
    This allows the tree walking code to defrag only the newly allocated
    buffers, it seems to be a good balance between perfect defragging and the
    performance hit of repeatedly reallocating blocks.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index a09064a9a41c..35fd20d24645 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -86,7 +86,7 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 		if (cache_only) {
 			next = btrfs_find_tree_block(root, blocknr);
 			if (!next || !buffer_uptodate(next) ||
-			   buffer_locked(next)) {
+			   buffer_locked(next) || !buffer_defrag(next)) {
 				brelse(next);
 				path->slots[*level]++;
 				continue;
@@ -142,6 +142,7 @@ static int defrag_walk_up(struct btrfs_trans_handle *trans,
 			root->defrag_level = i;
 			return 0;
 		} else {
+			clear_buffer_defrag(path->nodes[*level]);
 			btrfs_block_release(root, path->nodes[*level]);
 			path->nodes[*level] = NULL;
 			*level = i + 1;

commit e9d0b13b5bbb58c9b840e407a8d181442f799966
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 10 14:06:19 2007 -0400

    Btrfs: Btree defrag on the extent-mapping tree as well
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 7ea66b4aa5c2..a09064a9a41c 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -42,16 +42,20 @@ static void reada_defrag(struct btrfs_root *root,
 static int defrag_walk_down(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root,
 			    struct btrfs_path *path, int *level,
-			    int cache_only)
+			    int cache_only, u64 *last_ret)
 {
 	struct buffer_head *next;
 	struct buffer_head *cur;
 	u64 blocknr;
 	int ret = 0;
+	int is_extent = 0;
 
 	WARN_ON(*level < 0);
 	WARN_ON(*level >= BTRFS_MAX_LEVEL);
 
+	if (root->fs_info->extent_root == root)
+		is_extent = 1;
+
 	while(*level > 0) {
 		WARN_ON(*level < 0);
 		WARN_ON(*level >= BTRFS_MAX_LEVEL);
@@ -70,7 +74,10 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 		if (*level == 1) {
 			ret = btrfs_realloc_node(trans, root,
 						 path->nodes[*level],
-						 cache_only);
+						 cache_only, last_ret);
+			if (is_extent)
+				btrfs_extent_post_op(trans, root);
+
 			break;
 		}
 		blocknr = btrfs_node_blockptr(btrfs_buffer_node(cur),
@@ -90,8 +97,13 @@ static int defrag_walk_down(struct btrfs_trans_handle *trans,
 		ret = btrfs_cow_block(trans, root, next, path->nodes[*level],
 				      path->slots[*level], &next);
 		BUG_ON(ret);
-		ret = btrfs_realloc_node(trans, root, next, cache_only);
+		ret = btrfs_realloc_node(trans, root, next, cache_only,
+					 last_ret);
 		BUG_ON(ret);
+
+		if (is_extent)
+			btrfs_extent_post_op(trans, root);
+
 		WARN_ON(*level <= 0);
 		if (path->nodes[*level-1])
 			btrfs_block_release(root, path->nodes[*level-1]);
@@ -148,10 +160,14 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	int level;
 	int orig_level;
 	int i;
+	int is_extent = 0;
+	u64 last_ret = 0;
+
+	if (root->fs_info->extent_root == root)
+		is_extent = 1;
 
-	if (root->ref_cows == 0) {
+	if (root->ref_cows == 0 && !is_extent)
 		goto out;
-	}
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;
@@ -165,16 +181,21 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 		get_bh(root->node);
 		ret = btrfs_cow_block(trans, root, root->node, NULL, 0, &tmp);
 		BUG_ON(ret);
-		ret = btrfs_realloc_node(trans, root, root->node, cache_only);
+		ret = btrfs_realloc_node(trans, root, root->node, cache_only,
+					 &last_ret);
 		BUG_ON(ret);
 		path->nodes[level] = root->node;
 		path->slots[level] = 0;
+		if (is_extent)
+			btrfs_extent_post_op(trans, root);
 	} else {
 		level = root->defrag_level;
 		path->lowest_level = level;
 		wret = btrfs_search_slot(trans, root, &root->defrag_progress,
 					 path, 0, 1);
 
+		if (is_extent)
+			btrfs_extent_post_op(trans, root);
 		if (wret < 0) {
 			ret = wret;
 			goto out;
@@ -188,7 +209,8 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	}
 
 	while(1) {
-		wret = defrag_walk_down(trans, root, path, &level, cache_only);
+		wret = defrag_walk_down(trans, root, path, &level, cache_only,
+					&last_ret);
 		if (wret > 0)
 			break;
 		if (wret < 0)

commit 409eb95d7f6632d5af32b795244ce68a29e49319
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Aug 8 20:17:12 2007 -0400

    Btrfs: Further reduce the concurrency penalty of defrag and drop_snapshot
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
index 15d0a486fb59..7ea66b4aa5c2 100644
--- a/fs/btrfs/tree-defrag.c
+++ b/fs/btrfs/tree-defrag.c
@@ -148,7 +148,6 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 	int level;
 	int orig_level;
 	int i;
-	int num_runs = 0;
 
 	if (root->ref_cows == 0) {
 		goto out;
@@ -200,10 +199,8 @@ int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
 			break;
 		if (wret < 0)
 			ret = wret;
-		if (num_runs++ > 8) {
-			ret = -EAGAIN;
-			break;
-		}
+		ret = -EAGAIN;
+		break;
 	}
 	for (i = 0; i <= orig_level; i++) {
 		if (path->nodes[i]) {

commit 6702ed490ca0bb44e17131818a5a18b773957c5a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Aug 7 16:15:09 2007 -0400

    Btrfs: Add run time btree defrag, and an ioctl to force btree defrag
    
    This adds two types of btree defrag, a run time form that tries to
    defrag recently allocated blocks in the btree when they are still in ram,
    and an ioctl that forces defrag of all btree blocks.
    
    File data blocks are not defragged yet, but this can make a huge difference
    in sequential btree reads.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/tree-defrag.c b/fs/btrfs/tree-defrag.c
new file mode 100644
index 000000000000..15d0a486fb59
--- /dev/null
+++ b/fs/btrfs/tree-defrag.c
@@ -0,0 +1,222 @@
+/*
+ * Copyright (C) 2007 Oracle.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
+#include <linux/sched.h>
+#include "ctree.h"
+#include "disk-io.h"
+#include "print-tree.h"
+#include "transaction.h"
+
+static void reada_defrag(struct btrfs_root *root,
+			 struct btrfs_node *node)
+{
+	int i;
+	u32 nritems;
+	u64 blocknr;
+	int ret;
+
+	nritems = btrfs_header_nritems(&node->header);
+	for (i = 0; i < nritems; i++) {
+		blocknr = btrfs_node_blockptr(node, i);
+		ret = readahead_tree_block(root, blocknr);
+		if (ret)
+			break;
+	}
+}
+
+static int defrag_walk_down(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root,
+			    struct btrfs_path *path, int *level,
+			    int cache_only)
+{
+	struct buffer_head *next;
+	struct buffer_head *cur;
+	u64 blocknr;
+	int ret = 0;
+
+	WARN_ON(*level < 0);
+	WARN_ON(*level >= BTRFS_MAX_LEVEL);
+
+	while(*level > 0) {
+		WARN_ON(*level < 0);
+		WARN_ON(*level >= BTRFS_MAX_LEVEL);
+		cur = path->nodes[*level];
+
+		if (!cache_only && *level > 1 && path->slots[*level] == 0)
+			reada_defrag(root, btrfs_buffer_node(cur));
+
+		if (btrfs_header_level(btrfs_buffer_header(cur)) != *level)
+			WARN_ON(1);
+
+		if (path->slots[*level] >=
+		    btrfs_header_nritems(btrfs_buffer_header(cur)))
+			break;
+
+		if (*level == 1) {
+			ret = btrfs_realloc_node(trans, root,
+						 path->nodes[*level],
+						 cache_only);
+			break;
+		}
+		blocknr = btrfs_node_blockptr(btrfs_buffer_node(cur),
+					      path->slots[*level]);
+
+		if (cache_only) {
+			next = btrfs_find_tree_block(root, blocknr);
+			if (!next || !buffer_uptodate(next) ||
+			   buffer_locked(next)) {
+				brelse(next);
+				path->slots[*level]++;
+				continue;
+			}
+		} else {
+			next = read_tree_block(root, blocknr);
+		}
+		ret = btrfs_cow_block(trans, root, next, path->nodes[*level],
+				      path->slots[*level], &next);
+		BUG_ON(ret);
+		ret = btrfs_realloc_node(trans, root, next, cache_only);
+		BUG_ON(ret);
+		WARN_ON(*level <= 0);
+		if (path->nodes[*level-1])
+			btrfs_block_release(root, path->nodes[*level-1]);
+		path->nodes[*level-1] = next;
+		*level = btrfs_header_level(btrfs_buffer_header(next));
+		path->slots[*level] = 0;
+	}
+	WARN_ON(*level < 0);
+	WARN_ON(*level >= BTRFS_MAX_LEVEL);
+	btrfs_block_release(root, path->nodes[*level]);
+	path->nodes[*level] = NULL;
+	*level += 1;
+	WARN_ON(ret);
+	return 0;
+}
+
+static int defrag_walk_up(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root,
+			  struct btrfs_path *path, int *level,
+			  int cache_only)
+{
+	int i;
+	int slot;
+	struct btrfs_node *node;
+
+	for(i = *level; i < BTRFS_MAX_LEVEL - 1 && path->nodes[i]; i++) {
+		slot = path->slots[i];
+		if (slot < btrfs_header_nritems(
+		    btrfs_buffer_header(path->nodes[i])) - 1) {
+			path->slots[i]++;
+			*level = i;
+			node = btrfs_buffer_node(path->nodes[i]);
+			WARN_ON(i == 0);
+			btrfs_disk_key_to_cpu(&root->defrag_progress,
+					      &node->ptrs[path->slots[i]].key);
+			root->defrag_level = i;
+			return 0;
+		} else {
+			btrfs_block_release(root, path->nodes[*level]);
+			path->nodes[*level] = NULL;
+			*level = i + 1;
+		}
+	}
+	return 1;
+}
+
+int btrfs_defrag_leaves(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root, int cache_only)
+{
+	struct btrfs_path *path = NULL;
+	struct buffer_head *tmp;
+	int ret = 0;
+	int wret;
+	int level;
+	int orig_level;
+	int i;
+	int num_runs = 0;
+
+	if (root->ref_cows == 0) {
+		goto out;
+	}
+	path = btrfs_alloc_path();
+	if (!path)
+		return -ENOMEM;
+
+	level = btrfs_header_level(btrfs_buffer_header(root->node));
+	orig_level = level;
+	if (level == 0) {
+		goto out;
+	}
+	if (root->defrag_progress.objectid == 0) {
+		get_bh(root->node);
+		ret = btrfs_cow_block(trans, root, root->node, NULL, 0, &tmp);
+		BUG_ON(ret);
+		ret = btrfs_realloc_node(trans, root, root->node, cache_only);
+		BUG_ON(ret);
+		path->nodes[level] = root->node;
+		path->slots[level] = 0;
+	} else {
+		level = root->defrag_level;
+		path->lowest_level = level;
+		wret = btrfs_search_slot(trans, root, &root->defrag_progress,
+					 path, 0, 1);
+
+		if (wret < 0) {
+			ret = wret;
+			goto out;
+		}
+		while(level > 0 && !path->nodes[level])
+			level--;
+		if (!path->nodes[level]) {
+			ret = 0;
+			goto out;
+		}
+	}
+
+	while(1) {
+		wret = defrag_walk_down(trans, root, path, &level, cache_only);
+		if (wret > 0)
+			break;
+		if (wret < 0)
+			ret = wret;
+
+		wret = defrag_walk_up(trans, root, path, &level, cache_only);
+		if (wret > 0)
+			break;
+		if (wret < 0)
+			ret = wret;
+		if (num_runs++ > 8) {
+			ret = -EAGAIN;
+			break;
+		}
+	}
+	for (i = 0; i <= orig_level; i++) {
+		if (path->nodes[i]) {
+			btrfs_block_release(root, path->nodes[i]);
+			path->nodes[i] = 0;
+		}
+	}
+out:
+	if (path)
+		btrfs_free_path(path);
+	if (ret != -EAGAIN) {
+		memset(&root->defrag_progress, 0,
+		       sizeof(root->defrag_progress));
+	}
+	return ret;
+}
