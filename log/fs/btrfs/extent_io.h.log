commit 0b166a57e6222666292a481b742af92b50c3ba50
Merge: b25c6644bfd3 6b8ed62008a4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 5 16:19:28 2020 -0700

    Merge tag 'ext4_for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4
    
    Pull ext4 updates from Ted Ts'o:
     "A lot of bug fixes and cleanups for ext4, including:
    
       - Fix performance problems found in dioread_nolock now that it is the
         default, caused by transaction leaks.
    
       - Clean up fiemap handling in ext4
    
       - Clean up and refactor multiple block allocator (mballoc) code
    
       - Fix a problem with mballoc with a smaller file systems running out
         of blocks because they couldn't properly use blocks that had been
         reserved by inode preallocation.
    
       - Fixed a race in ext4_sync_parent() versus rename()
    
       - Simplify the error handling in the extent manipulation code
    
       - Make sure all metadata I/O errors are felected to
         ext4_ext_dirty()'s and ext4_make_inode_dirty()'s callers.
    
       - Avoid passing an error pointer to brelse in ext4_xattr_set()
    
       - Fix race which could result to freeing an inode on the dirty last
         in data=journal mode.
    
       - Fix refcount handling if ext4_iget() fails
    
       - Fix a crash in generic/019 caused by a corrupted extent node"
    
    * tag 'ext4_for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4: (58 commits)
      ext4: avoid unnecessary transaction starts during writeback
      ext4: don't block for O_DIRECT if IOCB_NOWAIT is set
      ext4: remove the access_ok() check in ext4_ioctl_get_es_cache
      fs: remove the access_ok() check in ioctl_fiemap
      fs: handle FIEMAP_FLAG_SYNC in fiemap_prep
      fs: move fiemap range validation into the file systems instances
      iomap: fix the iomap_fiemap prototype
      fs: move the fiemap definitions out of fs.h
      fs: mark __generic_block_fiemap static
      ext4: remove the call to fiemap_check_flags in ext4_fiemap
      ext4: split _ext4_fiemap
      ext4: fix fiemap size checks for bitmap files
      ext4: fix EXT4_MAX_LOGICAL_BLOCK macro
      add comment for ext4_dir_entry_2 file_type member
      jbd2: avoid leaking transaction credits when unreserving handle
      ext4: drop ext4_journal_free_reserved()
      ext4: mballoc: use lock for checking free blocks while retrying
      ext4: mballoc: refactor ext4_mb_good_group()
      ext4: mballoc: introduce pcpu seqcnt for freeing PA to improve ENOSPC handling
      ext4: mballoc: refactor ext4_mb_discard_preallocations()
      ...

commit 10c5db286452b8c60e8f58e9a4c1cbc5a91e4e5b
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat May 23 09:30:11 2020 +0200

    fs: move the fiemap definitions out of fs.h
    
    No need to pull the fiemap definitions into almost every file in the
    kernel build.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Ritesh Harjani <riteshh@linux.ibm.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Link: https://lore.kernel.org/r/20200523073016.2944131-5-hch@lst.de
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 2ed65bd0760e..817698bc0669 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -5,6 +5,7 @@
 
 #include <linux/rbtree.h>
 #include <linux/refcount.h>
+#include <linux/fiemap.h>
 #include "ulist.h"
 
 /*

commit f3cdc8ae116e27d84e1f33c7a2995960cebb73ac
Merge: 8eeae5bae123 2166e5edce9a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 2 19:59:25 2020 -0700

    Merge tag 'for-5.8-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "Highlights:
    
       - speedup dead root detection during orphan cleanup, eg. when there
         are many deleted subvolumes waiting to be cleaned, the trees are
         now looked up in radix tree instead of a O(N^2) search
    
       - snapshot creation with inherited qgroup will mark the qgroup
         inconsistent, requires a rescan
    
       - send will emit file capabilities after chown, this produces a
         stream that does not need postprocessing to set the capabilities
         again
    
       - direct io ported to iomap infrastructure, cleaned up and simplified
         code, notably removing last use of struct buffer_head in btrfs code
    
      Core changes:
    
       - factor out backreference iteration, to be used by ordinary
         backreferences and relocation code
    
       - improved global block reserve utilization
          * better logic to serialize requests
          * increased maximum available for unlink
          * improved handling on large pages (64K)
    
       - direct io cleanups and fixes
          * simplify layering, where cloned bios were unnecessarily created
            for some cases
          * error handling fixes (submit, endio)
          * remove repair worker thread, used to avoid deadlocks during
            repair
    
       - refactored block group reading code, preparatory work for new type
         of block group storage that should improve mount time on large
         filesystems
    
      Cleanups:
    
       - cleaned up (and slightly sped up) set/get helpers for metadata data
         structure members
    
       - root bit REF_COWS got renamed to SHAREABLE to reflect the that the
         blocks of the tree get shared either among subvolumes or with the
         relocation trees
    
      Fixes:
    
       - when subvolume deletion fails due to ENOSPC, the filesystem is not
         turned read-only
    
       - device scan deals with devices from other filesystems that changed
         ownership due to overwrite (mkfs)
    
       - fix a race between scrub and block group removal/allocation
    
       - fix long standing bug of a runaway balance operation, printing the
         same line to the syslog, caused by a stale status bit on a reloc
         tree that prevented progress
    
       - fix corrupt log due to concurrent fsync of inodes with shared
         extents
    
       - fix space underflow for NODATACOW and buffered writes when it for
         some reason needs to fallback to COW mode"
    
    * tag 'for-5.8-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (133 commits)
      btrfs: fix space_info bytes_may_use underflow during space cache writeout
      btrfs: fix space_info bytes_may_use underflow after nocow buffered write
      btrfs: fix wrong file range cleanup after an error filling dealloc range
      btrfs: remove redundant local variable in read_block_for_search
      btrfs: open code key_search
      btrfs: split btrfs_direct_IO to read and write part
      btrfs: remove BTRFS_INODE_READDIO_NEED_LOCK
      fs: remove dio_end_io()
      btrfs: switch to iomap_dio_rw() for dio
      iomap: remove lockdep_assert_held()
      iomap: add a filesystem hook for direct I/O bio submission
      fs: export generic_file_buffered_read()
      btrfs: turn space cache writeout failure messages into debug messages
      btrfs: include error on messages about failure to write space/inode caches
      btrfs: remove useless 'fail_unlock' label from btrfs_csum_file_blocks()
      btrfs: do not ignore error from btrfs_next_leaf() when inserting checksums
      btrfs: make checksum item extension more efficient
      btrfs: fix corrupt log due to concurrent fsync of inodes with shared extents
      btrfs: unexport btrfs_compress_set_level()
      btrfs: simplify iget helpers
      ...

commit ba206a026ff4cd0f11033ccaa4bf99c30567ded4
Author: Matthew Wilcox (Oracle) <willy@infradead.org>
Date:   Mon Jun 1 21:47:05 2020 -0700

    btrfs: convert from readpages to readahead
    
    Implement the new readahead method in btrfs using the new
    readahead_page_batch() function.
    
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: William Kucharski <william.kucharski@oracle.com>
    Cc: Chao Yu <yuchao0@huawei.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Cong Wang <xiyou.wangcong@gmail.com>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Dave Chinner <dchinner@redhat.com>
    Cc: Eric Biggers <ebiggers@google.com>
    Cc: Gao Xiang <gaoxiang25@huawei.com>
    Cc: Jaegeuk Kim <jaegeuk@kernel.org>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Joseph Qi <joseph.qi@linux.alibaba.com>
    Cc: Junxiao Bi <junxiao.bi@oracle.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Cc: Miklos Szeredi <mszeredi@redhat.com>
    Link: http://lkml.kernel.org/r/20200414150233.24495-18-willy@infradead.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 2ed65bd0760e..25594e09fdcd 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -198,8 +198,7 @@ int extent_writepages(struct address_space *mapping,
 		      struct writeback_control *wbc);
 int btree_write_cache_pages(struct address_space *mapping,
 			    struct writeback_control *wbc);
-int extent_readpages(struct address_space *mapping, struct list_head *pages,
-		     unsigned nr_pages);
+void extent_readahead(struct readahead_control *rac);
 int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 		__u64 start, __u64 len);
 void set_page_extent_mapped(struct page *page);

commit 2b48966a4da4bcb35f0883bc23dcaf63fcb8557f
Author: David Sterba <dsterba@suse.com>
Date:   Wed Apr 29 03:04:10 2020 +0200

    btrfs: constify extent_buffer in the API functions
    
    There are many helpers around extent buffers, found in extent_io.h and
    ctree.h. Most of them can be converted to take constified eb as there
    are no changes to the extent buffer structure itself but rather the
    pages.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 9ed89c01e2da..9a10681b12bf 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -213,7 +213,7 @@ struct extent_buffer *__alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
 						  u64 start, unsigned long len);
 struct extent_buffer *alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
 						u64 start);
-struct extent_buffer *btrfs_clone_extent_buffer(struct extent_buffer *src);
+struct extent_buffer *btrfs_clone_extent_buffer(const struct extent_buffer *src);
 struct extent_buffer *find_extent_buffer(struct btrfs_fs_info *fs_info,
 					 u64 start);
 void free_extent_buffer(struct extent_buffer *eb);
@@ -231,7 +231,7 @@ static inline int num_extent_pages(const struct extent_buffer *eb)
 	       (eb->start >> PAGE_SHIFT);
 }
 
-static inline int extent_buffer_uptodate(struct extent_buffer *eb)
+static inline int extent_buffer_uptodate(const struct extent_buffer *eb)
 {
 	return test_bit(EXTENT_BUFFER_UPTODATE, &eb->bflags);
 }
@@ -244,33 +244,37 @@ void read_extent_buffer(const struct extent_buffer *eb, void *dst,
 int read_extent_buffer_to_user(const struct extent_buffer *eb,
 			       void __user *dst, unsigned long start,
 			       unsigned long len);
-void write_extent_buffer_fsid(struct extent_buffer *eb, const void *src);
-void write_extent_buffer_chunk_tree_uuid(struct extent_buffer *eb,
+void write_extent_buffer_fsid(const struct extent_buffer *eb, const void *src);
+void write_extent_buffer_chunk_tree_uuid(const struct extent_buffer *eb,
 		const void *src);
-void write_extent_buffer(struct extent_buffer *eb, const void *src,
+void write_extent_buffer(const struct extent_buffer *eb, const void *src,
 			 unsigned long start, unsigned long len);
-void copy_extent_buffer_full(struct extent_buffer *dst,
-			     struct extent_buffer *src);
-void copy_extent_buffer(struct extent_buffer *dst, struct extent_buffer *src,
+void copy_extent_buffer_full(const struct extent_buffer *dst,
+			     const struct extent_buffer *src);
+void copy_extent_buffer(const struct extent_buffer *dst,
+			const struct extent_buffer *src,
 			unsigned long dst_offset, unsigned long src_offset,
 			unsigned long len);
-void memcpy_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
-			   unsigned long src_offset, unsigned long len);
-void memmove_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
-			   unsigned long src_offset, unsigned long len);
-void memzero_extent_buffer(struct extent_buffer *eb, unsigned long start,
+void memcpy_extent_buffer(const struct extent_buffer *dst,
+			  unsigned long dst_offset, unsigned long src_offset,
+			  unsigned long len);
+void memmove_extent_buffer(const struct extent_buffer *dst,
+			   unsigned long dst_offset, unsigned long src_offset,
 			   unsigned long len);
-int extent_buffer_test_bit(struct extent_buffer *eb, unsigned long start,
+void memzero_extent_buffer(const struct extent_buffer *eb, unsigned long start,
+			   unsigned long len);
+int extent_buffer_test_bit(const struct extent_buffer *eb, unsigned long start,
 			   unsigned long pos);
-void extent_buffer_bitmap_set(struct extent_buffer *eb, unsigned long start,
+void extent_buffer_bitmap_set(const struct extent_buffer *eb, unsigned long start,
 			      unsigned long pos, unsigned long len);
-void extent_buffer_bitmap_clear(struct extent_buffer *eb, unsigned long start,
-				unsigned long pos, unsigned long len);
-void clear_extent_buffer_dirty(struct extent_buffer *eb);
+void extent_buffer_bitmap_clear(const struct extent_buffer *eb,
+				unsigned long start, unsigned long pos,
+				unsigned long len);
+void clear_extent_buffer_dirty(const struct extent_buffer *eb);
 bool set_extent_buffer_dirty(struct extent_buffer *eb);
 void set_extent_buffer_uptodate(struct extent_buffer *eb);
 void clear_extent_buffer_uptodate(struct extent_buffer *eb);
-int extent_buffer_under_io(struct extent_buffer *eb);
+int extent_buffer_under_io(const struct extent_buffer *eb);
 void extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
@@ -289,7 +293,7 @@ int repair_io_failure(struct btrfs_fs_info *fs_info, u64 ino, u64 start,
 		      u64 length, u64 logical, struct page *page,
 		      unsigned int pg_offset, int mirror_num);
 void end_extent_writepage(struct page *page, int err, u64 start, u64 end);
-int btrfs_repair_eb_io_failure(struct extent_buffer *eb, int mirror_num);
+int btrfs_repair_eb_io_failure(const struct extent_buffer *eb, int mirror_num);
 
 /*
  * When IO fails, either with EIO or csum verification fails, we

commit db3756c879773c4c7986fce3dac8355f210df807
Author: David Sterba <dsterba@suse.com>
Date:   Wed Apr 29 23:36:03 2020 +0200

    btrfs: remove unused map_private_extent_buffer
    
    All uses of map_private_extent_buffer have been replaced by more
    effective way. The set/get helpers have their own bounds checker.
    The function name was confusing since the non-private helper was removed
    in a65917156e34 ("Btrfs: stop using highmem for extent_buffers") many
    years ago.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a2842b2d9a98..9ed89c01e2da 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -271,10 +271,6 @@ bool set_extent_buffer_dirty(struct extent_buffer *eb);
 void set_extent_buffer_uptodate(struct extent_buffer *eb);
 void clear_extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_under_io(struct extent_buffer *eb);
-int map_private_extent_buffer(const struct extent_buffer *eb,
-			      unsigned long offset, unsigned long min_len,
-			      char **map, unsigned long *map_start,
-			      unsigned long *map_len);
 void extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,

commit 77d5d6893106ea7b19709bed2491f93ff10a86d7
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Apr 16 14:46:25 2020 -0700

    btrfs: unify buffered and direct I/O read repair
    
    Currently, direct I/O has its own versions of bio_readpage_error() and
    btrfs_check_repairable() (dio_read_error() and
    btrfs_check_dio_repairable(), respectively). The main difference is that
    the direct I/O version doesn't do read validation. The rework of direct
    I/O repair makes it possible to do validation, so we can get rid of
    btrfs_check_dio_repairable() and combine bio_readpage_error() and
    dio_read_error() into a new helper, btrfs_submit_read_repair().
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f4dfac756455..a2842b2d9a98 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -66,6 +66,10 @@ struct btrfs_io_bio;
 struct io_failure_record;
 struct extent_io_tree;
 
+typedef blk_status_t (submit_bio_hook_t)(struct inode *inode, struct bio *bio,
+					 int mirror_num,
+					 unsigned long bio_flags);
+
 typedef blk_status_t (extent_submit_bio_start_t)(void *private_data,
 		struct bio *bio, u64 bio_offset);
 
@@ -74,8 +78,7 @@ struct extent_io_ops {
 	 * The following callbacks must be always defined, the function
 	 * pointer will be called unconditionally.
 	 */
-	blk_status_t (*submit_bio_hook)(struct inode *inode, struct bio *bio,
-					int mirror_num, unsigned long bio_flags);
+	submit_bio_hook_t *submit_bio_hook;
 	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,
 				    struct page *page, u64 start, u64 end,
 				    int mirror);
@@ -312,10 +315,12 @@ struct io_failure_record {
 };
 
 
-struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
-				    struct io_failure_record *failrec,
-				    struct page *page, int pg_offset, int icsum,
-				    bio_end_io_t *endio_func, void *data);
+blk_status_t btrfs_submit_read_repair(struct inode *inode,
+				      struct bio *failed_bio, u64 phy_offset,
+				      struct page *page, unsigned int pgoff,
+				      u64 start, u64 end, int failed_mirror,
+				      submit_bio_hook_t *submit_bio_hook);
+
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 bool find_lock_delalloc_range(struct inode *inode,
 			     struct page *locked_page, u64 *start,

commit ce06d3ec2b5aed70b95ee080a7a3d55ef08ce7f3
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Apr 16 14:46:18 2020 -0700

    btrfs: make btrfs_check_repairable() static
    
    Since its introduction in commit 2fe6303e7cd0 ("Btrfs: split
    bio_readpage_error into several functions"), btrfs_check_repairable()
    has only been used from extent_io.c where it is defined.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e042c771893d..f4dfac756455 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -312,9 +312,6 @@ struct io_failure_record {
 };
 
 
-bool btrfs_check_repairable(struct inode *inode, bool needs_validation,
-			    struct io_failure_record *failrec,
-			    int failed_mirror);
 struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
 				    struct io_failure_record *failrec,
 				    struct page *page, int pg_offset, int icsum,

commit c7333972b9b571a03bf9aecd1aeecfab81243e8d
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Apr 16 14:46:14 2020 -0700

    btrfs: look at full bi_io_vec for repair decision
    
    Read repair does two things: it finds a good copy of data to return to
    the reader, and it corrects the bad copy on disk. If a read of multiple
    sectors has an I/O error, repair does an extra "validation" step that
    issues a separate read for each sector. This allows us to find the exact
    failing sectors and only rewrite those.
    
    This heuristic is implemented in
    bio_readpage_error()/btrfs_check_repairable() as:
    
            failed_bio_pages = failed_bio->bi_iter.bi_size >> PAGE_SHIFT;
            if (failed_bio_pages > 1)
                    do validation
    
    However, at this point, bi_iter may have already been advanced. This
    means that we'll skip the validation step and rewrite the entire failed
    read.
    
    Fix it by getting the actual size from the biovec (which we can do
    because this is only called for non-cloned bios, although that will
    change in a later commit).
    
    Fixes: 8a2ee44a371c ("btrfs: look at bi_size for repair decisions")
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 2ed65bd0760e..e042c771893d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -312,8 +312,9 @@ struct io_failure_record {
 };
 
 
-bool btrfs_check_repairable(struct inode *inode, unsigned failed_bio_pages,
-			    struct io_failure_record *failrec, int fail_mirror);
+bool btrfs_check_repairable(struct inode *inode, bool needs_validation,
+			    struct io_failure_record *failrec,
+			    int failed_mirror);
 struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
 				    struct io_failure_record *failrec,
 				    struct page *page, int pg_offset, int icsum,

commit 3fd6372758d91d8ba801e0733b17d082066a04ef
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:40 2020 -0500

    btrfs: make the extent buffer leak check per fs info
    
    I'm going to make the entire destruction of btrfs_root's controlled by
    their refcount, so it will be helpful to notice if we're leaking their
    eb's on umount.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 234622101230..2ed65bd0760e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -325,4 +325,11 @@ bool find_lock_delalloc_range(struct inode *inode,
 #endif
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
 					       u64 start);
+
+#ifdef CONFIG_BTRFS_DEBUG
+void btrfs_extent_buffer_leak_debug_check(struct btrfs_fs_info *fs_info);
+#else
+#define btrfs_extent_buffer_leak_debug_check(fs_info)	do {} while (0)
+#endif
+
 #endif

commit 71ad38b44eaa758c70c34ca97a5c3848d6b67e03
Author: David Sterba <dsterba@suse.com>
Date:   Wed Feb 5 19:09:35 2020 +0100

    btrfs: sink argument tree to extent_read_full_page
    
    The tree pointer can be safely read from the page's inode, use it and
    drop the redundant argument.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 5d205bbaafdc..234622101230 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -189,8 +189,8 @@ typedef struct extent_map *(get_extent_t)(struct btrfs_inode *inode,
 int try_release_extent_mapping(struct page *page, gfp_t mask);
 int try_release_extent_buffer(struct page *page);
 
-int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
-			  get_extent_t *get_extent, int mirror_num);
+int extent_read_full_page(struct page *page, get_extent_t *get_extent,
+			  int mirror_num);
 int extent_write_full_page(struct page *page, struct writeback_control *wbc);
 int extent_write_locked_range(struct inode *inode, u64 start, u64 end,
 			      int mode);

commit 39b07b5d7072f8e9fd8cc2f840d3749f86699bbb
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Dec 2 17:34:23 2019 -0800

    btrfs: drop create parameter to btrfs_get_extent()
    
    We only pass this as 1 from __extent_writepage_io(). The parameter
    basically means "pretend I didn't pass in a page". This is silly since
    we can simply not pass in the page. Get rid of the parameter from
    btrfs_get_extent(), and since it's used as a get_extent_t callback,
    remove it from get_extent_t and btree_get_extent(), neither of which
    need it.
    
    While we're here, let's document btrfs_get_extent().
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a8551a1f56e2..5d205bbaafdc 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -183,10 +183,8 @@ static inline int extent_compress_type(unsigned long bio_flags)
 struct extent_map_tree;
 
 typedef struct extent_map *(get_extent_t)(struct btrfs_inode *inode,
-					  struct page *page,
-					  size_t pg_offset,
-					  u64 start, u64 len,
-					  int create);
+					  struct page *page, size_t pg_offset,
+					  u64 start, u64 len);
 
 int try_release_extent_mapping(struct page *page, gfp_t mask);
 int try_release_extent_buffer(struct page *page);

commit 67439dadb03ad9da45bfccb4cdb6ef6b1a7f8da9
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 8 13:28:47 2019 +0200

    btrfs: opencode extent_buffer_get
    
    The helper is trivial and we can understand what the atomic_inc on
    something named refs does.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e22045cef89b..a8551a1f56e2 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -230,11 +230,6 @@ static inline int num_extent_pages(const struct extent_buffer *eb)
 	       (eb->start >> PAGE_SHIFT);
 }
 
-static inline void extent_buffer_get(struct extent_buffer *eb)
-{
-	atomic_inc(&eb->refs);
-}
-
 static inline int extent_buffer_uptodate(struct extent_buffer *eb)
 {
 	return test_bit(EXTENT_BUFFER_UPTODATE, &eb->bflags);

commit b3f167aa6c7053b87fa53364fc40dd4757f053c9
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Mon Sep 23 10:05:21 2019 -0400

    btrfs: move the failrec tree stuff into extent-io-tree.h
    
    This needs to be cleaned up in the future, but for now it belongs to the
    extent-io-tree stuff since it uses the internal tree search code.
    Needed to export get_state_failrec and set_state_failrec as well since
    we're not going to move the actual IO part of the failrec stuff out at
    this point.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 8c782d061132..e22045cef89b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -296,10 +296,6 @@ struct btrfs_inode;
 int repair_io_failure(struct btrfs_fs_info *fs_info, u64 ino, u64 start,
 		      u64 length, u64 logical, struct page *page,
 		      unsigned int pg_offset, int mirror_num);
-int clean_io_failure(struct btrfs_fs_info *fs_info,
-		     struct extent_io_tree *failure_tree,
-		     struct extent_io_tree *io_tree, u64 start,
-		     struct page *page, u64 ino, unsigned int pg_offset);
 void end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 int btrfs_repair_eb_io_failure(struct extent_buffer *eb, int mirror_num);
 
@@ -323,19 +319,12 @@ struct io_failure_record {
 };
 
 
-void btrfs_free_io_failure_record(struct btrfs_inode *inode, u64 start,
-		u64 end);
-int btrfs_get_io_failure_record(struct inode *inode, u64 start, u64 end,
-				struct io_failure_record **failrec_ret);
 bool btrfs_check_repairable(struct inode *inode, unsigned failed_bio_pages,
 			    struct io_failure_record *failrec, int fail_mirror);
 struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
 				    struct io_failure_record *failrec,
 				    struct page *page, int pg_offset, int icsum,
 				    bio_end_io_t *endio_func, void *data);
-int free_io_failure(struct extent_io_tree *failure_tree,
-		    struct extent_io_tree *io_tree,
-		    struct io_failure_record *rec);
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 bool find_lock_delalloc_range(struct inode *inode,
 			     struct page *locked_page, u64 *start,

commit 9c7d3a548331e72ba3613eaa5c8a74839462b764
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Mon Sep 23 10:05:19 2019 -0400

    btrfs: move extent_io_tree defs to their own header
    
    extent_io.c/h are huge, encompassing a bunch of different things.  The
    extent_io_tree code can live on its own, so separate this out.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e813f593202d..8c782d061132 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -7,35 +7,6 @@
 #include <linux/refcount.h>
 #include "ulist.h"
 
-/* bits for the extent state */
-#define EXTENT_DIRTY		(1U << 0)
-#define EXTENT_UPTODATE		(1U << 1)
-#define EXTENT_LOCKED		(1U << 2)
-#define EXTENT_NEW		(1U << 3)
-#define EXTENT_DELALLOC		(1U << 4)
-#define EXTENT_DEFRAG		(1U << 5)
-#define EXTENT_BOUNDARY		(1U << 6)
-#define EXTENT_NODATASUM	(1U << 7)
-#define EXTENT_CLEAR_META_RESV	(1U << 8)
-#define EXTENT_NEED_WAIT	(1U << 9)
-#define EXTENT_DAMAGED		(1U << 10)
-#define EXTENT_NORESERVE	(1U << 11)
-#define EXTENT_QGROUP_RESERVED	(1U << 12)
-#define EXTENT_CLEAR_DATA_RESV	(1U << 13)
-#define EXTENT_DELALLOC_NEW	(1U << 14)
-#define EXTENT_DO_ACCOUNTING    (EXTENT_CLEAR_META_RESV | \
-				 EXTENT_CLEAR_DATA_RESV)
-#define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING)
-
-/*
- * Redefined bits above which are used only in the device allocation tree,
- * shouldn't be using EXTENT_LOCKED / EXTENT_BOUNDARY / EXTENT_CLEAR_META_RESV
- * / EXTENT_CLEAR_DATA_RESV because they have special meaning to the bit
- * manipulation functions
- */
-#define CHUNK_ALLOCATED EXTENT_DIRTY
-#define CHUNK_TRIMMED   EXTENT_DEFRAG
-
 /*
  * flags for bio submission. The high bits indicate the compression
  * type for this bio
@@ -89,12 +60,11 @@ enum {
 #define BITMAP_LAST_BYTE_MASK(nbits) \
 	(BYTE_MASK >> (-(nbits) & (BITS_PER_BYTE - 1)))
 
-struct extent_state;
 struct btrfs_root;
 struct btrfs_inode;
 struct btrfs_io_bio;
 struct io_failure_record;
-
+struct extent_io_tree;
 
 typedef blk_status_t (extent_submit_bio_start_t)(void *private_data,
 		struct bio *bio, u64 bio_offset);
@@ -111,47 +81,6 @@ struct extent_io_ops {
 				    int mirror);
 };
 
-enum {
-	IO_TREE_FS_INFO_FREED_EXTENTS0,
-	IO_TREE_FS_INFO_FREED_EXTENTS1,
-	IO_TREE_INODE_IO,
-	IO_TREE_INODE_IO_FAILURE,
-	IO_TREE_RELOC_BLOCKS,
-	IO_TREE_TRANS_DIRTY_PAGES,
-	IO_TREE_ROOT_DIRTY_LOG_PAGES,
-	IO_TREE_SELFTEST,
-};
-
-struct extent_io_tree {
-	struct rb_root state;
-	struct btrfs_fs_info *fs_info;
-	void *private_data;
-	u64 dirty_bytes;
-	bool track_uptodate;
-
-	/* Who owns this io tree, should be one of IO_TREE_* */
-	u8 owner;
-
-	spinlock_t lock;
-	const struct extent_io_ops *ops;
-};
-
-struct extent_state {
-	u64 start;
-	u64 end; /* inclusive */
-	struct rb_node rb_node;
-
-	/* ADD NEW ELEMENTS AFTER THIS */
-	wait_queue_head_t wq;
-	refcount_t refs;
-	unsigned state;
-
-	struct io_failure_record *failrec;
-
-#ifdef CONFIG_BTRFS_DEBUG
-	struct list_head leak_list;
-#endif
-};
 
 #define INLINE_EXTENT_BUFFER_PAGES 16
 #define MAX_INLINE_EXTENT_BUFFER_SIZE (INLINE_EXTENT_BUFFER_PAGES * PAGE_SIZE)
@@ -259,152 +188,11 @@ typedef struct extent_map *(get_extent_t)(struct btrfs_inode *inode,
 					  u64 start, u64 len,
 					  int create);
 
-void extent_io_tree_init(struct btrfs_fs_info *fs_info,
-			 struct extent_io_tree *tree, unsigned int owner,
-			 void *private_data);
-void extent_io_tree_release(struct extent_io_tree *tree);
 int try_release_extent_mapping(struct page *page, gfp_t mask);
 int try_release_extent_buffer(struct page *page);
-int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		     struct extent_state **cached);
 
-static inline int lock_extent(struct extent_io_tree *tree, u64 start, u64 end)
-{
-	return lock_extent_bits(tree, start, end, NULL);
-}
-
-int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent, int mirror_num);
-int __init extent_io_init(void);
-void __cold extent_io_exit(void);
-
-u64 count_range_bits(struct extent_io_tree *tree,
-		     u64 *start, u64 search_end,
-		     u64 max_bytes, unsigned bits, int contig);
-
-void free_extent_state(struct extent_state *state);
-int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		   unsigned bits, int filled,
-		   struct extent_state *cached_state);
-int clear_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		unsigned bits, struct extent_changeset *changeset);
-int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		     unsigned bits, int wake, int delete,
-		     struct extent_state **cached);
-int __clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		     unsigned bits, int wake, int delete,
-		     struct extent_state **cached, gfp_t mask,
-		     struct extent_changeset *changeset);
-
-static inline int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end)
-{
-	return clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, NULL);
-}
-
-static inline int unlock_extent_cached(struct extent_io_tree *tree, u64 start,
-		u64 end, struct extent_state **cached)
-{
-	return __clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, cached,
-				GFP_NOFS, NULL);
-}
-
-static inline int unlock_extent_cached_atomic(struct extent_io_tree *tree,
-		u64 start, u64 end, struct extent_state **cached)
-{
-	return __clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, cached,
-				GFP_ATOMIC, NULL);
-}
-
-static inline int clear_extent_bits(struct extent_io_tree *tree, u64 start,
-		u64 end, unsigned bits)
-{
-	int wake = 0;
-
-	if (bits & EXTENT_LOCKED)
-		wake = 1;
-
-	return clear_extent_bit(tree, start, end, bits, wake, 0, NULL);
-}
-
-int set_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-			   unsigned bits, struct extent_changeset *changeset);
-int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		   unsigned bits, u64 *failed_start,
-		   struct extent_state **cached_state, gfp_t mask);
-int set_extent_bits_nowait(struct extent_io_tree *tree, u64 start, u64 end,
-			   unsigned bits);
-
-static inline int set_extent_bits(struct extent_io_tree *tree, u64 start,
-		u64 end, unsigned bits)
-{
-	return set_extent_bit(tree, start, end, bits, NULL, NULL, GFP_NOFS);
-}
-
-static inline int clear_extent_uptodate(struct extent_io_tree *tree, u64 start,
-		u64 end, struct extent_state **cached_state)
-{
-	return __clear_extent_bit(tree, start, end, EXTENT_UPTODATE, 0, 0,
-				cached_state, GFP_NOFS, NULL);
-}
-
-static inline int set_extent_dirty(struct extent_io_tree *tree, u64 start,
-		u64 end, gfp_t mask)
-{
-	return set_extent_bit(tree, start, end, EXTENT_DIRTY, NULL,
-			      NULL, mask);
-}
-
-static inline int clear_extent_dirty(struct extent_io_tree *tree, u64 start,
-				     u64 end, struct extent_state **cached)
-{
-	return clear_extent_bit(tree, start, end,
-				EXTENT_DIRTY | EXTENT_DELALLOC |
-				EXTENT_DO_ACCOUNTING, 0, 0, cached);
-}
-
-int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		       unsigned bits, unsigned clear_bits,
-		       struct extent_state **cached_state);
-
-static inline int set_extent_delalloc(struct extent_io_tree *tree, u64 start,
-				      u64 end, unsigned int extra_bits,
-				      struct extent_state **cached_state)
-{
-	return set_extent_bit(tree, start, end,
-			      EXTENT_DELALLOC | EXTENT_UPTODATE | extra_bits,
-			      NULL, cached_state, GFP_NOFS);
-}
-
-static inline int set_extent_defrag(struct extent_io_tree *tree, u64 start,
-		u64 end, struct extent_state **cached_state)
-{
-	return set_extent_bit(tree, start, end,
-			      EXTENT_DELALLOC | EXTENT_UPTODATE | EXTENT_DEFRAG,
-			      NULL, cached_state, GFP_NOFS);
-}
-
-static inline int set_extent_new(struct extent_io_tree *tree, u64 start,
-		u64 end)
-{
-	return set_extent_bit(tree, start, end, EXTENT_NEW, NULL, NULL,
-			GFP_NOFS);
-}
-
-static inline int set_extent_uptodate(struct extent_io_tree *tree, u64 start,
-		u64 end, struct extent_state **cached_state, gfp_t mask)
-{
-	return set_extent_bit(tree, start, end, EXTENT_UPTODATE, NULL,
-			      cached_state, mask);
-}
-
-int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
-			  u64 *start_ret, u64 *end_ret, unsigned bits,
-			  struct extent_state **cached_state);
-void find_first_clear_extent_bit(struct extent_io_tree *tree, u64 start,
-				 u64 *start_ret, u64 *end_ret, unsigned bits);
-int extent_invalidatepage(struct extent_io_tree *tree,
-			  struct page *page, unsigned long offset);
 int extent_write_full_page(struct page *page, struct writeback_control *wbc);
 int extent_write_locked_range(struct inode *inode, u64 start, u64 end,
 			      int mode);
@@ -555,7 +343,4 @@ bool find_lock_delalloc_range(struct inode *inode,
 #endif
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
 					       u64 start);
-
-int __init extent_state_cache_init(void);
-void __cold extent_state_cache_exit(void);
 #endif

commit 6f0d04f8e72e1c7fd17e7fac0fea82553a6443b4
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Mon Sep 23 10:05:18 2019 -0400

    btrfs: separate out the extent io init function
    
    We are moving extent_io_tree into it's on file, so separate out the
    extent_state init stuff from extent_io_tree_init().
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index cf3424d58fec..e813f593202d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -556,4 +556,6 @@ bool find_lock_delalloc_range(struct inode *inode,
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
 					       u64 start);
 
+int __init extent_state_cache_init(void);
+void __cold extent_state_cache_exit(void);
 #endif

commit 74e9194afb2c5c6b45ada5653b2609499c372d77
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jul 17 16:18:16 2019 +0300

    btrfs: Remove delalloc_end argument from extent_clear_unlock_delalloc
    
    It was added in ba8b04c1d4ad ("btrfs: extend btrfs_set_extent_delalloc
    and its friends to support in-band dedupe and subpage size patchset") as
    a preparatory patch for in-band and subapge block size patchsets.
    However neither of those are likely to be merged anytime soon and the
    code has diverged significantly from the last public post of either
    of those patchsets.
    
    It's unlikely either of the patchests are going to use those preparatory
    steps so just remove the variables. Since cow_file_range also took
    delalloc_end to pass it to extent_clear_unlock_delalloc remove the
    parameter from that function as well.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 401423b16976..cf3424d58fec 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -494,9 +494,9 @@ int map_private_extent_buffer(const struct extent_buffer *eb,
 void extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
-				 u64 delalloc_end, struct page *locked_page,
-				 unsigned bits_to_clear,
-				 unsigned long page_ops);
+				  struct page *locked_page,
+				  unsigned bits_to_clear,
+				  unsigned long page_ops);
 struct bio *btrfs_bio_alloc(u64 first_byte);
 struct bio *btrfs_io_bio_alloc(unsigned int nr_iovecs);
 struct bio *btrfs_bio_clone(struct bio *bio);

commit 9978059be8a1afd68bc0f7ab4c1883633ddd0312
Author: Goldwyn Rodrigues <rgoldwyn@suse.de>
Date:   Fri Jun 21 10:02:54 2019 -0500

    btrfs: Evaluate io_tree in find_lock_delalloc_range()
    
    Simplification.  No point passing the tree variable when it can be
    evaluated from inode. The tests now use the io_tree from btrfs_inode as
    opposed to creating one.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6e13a62a2974..401423b16976 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -549,7 +549,7 @@ int free_io_failure(struct extent_io_tree *failure_tree,
 		    struct extent_io_tree *io_tree,
 		    struct io_failure_record *rec);
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-bool find_lock_delalloc_range(struct inode *inode, struct extent_io_tree *tree,
+bool find_lock_delalloc_range(struct inode *inode,
 			     struct page *locked_page, u64 *start,
 			     u64 *end);
 #endif

commit e749af443fa8dac67a896d38f5eca450a5b9026a
Author: David Sterba <dsterba@suse.com>
Date:   Tue Jun 18 20:00:16 2019 +0200

    btrfs: lift bio_set_dev from bio allocation helpers
    
    The block device is passed around for the only purpose to set it in new
    bios. Move the assignment one level up. This is a preparatory patch for
    further bdev cleanups.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 844e595cde5b..6e13a62a2974 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -497,7 +497,7 @@ void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
 				 u64 delalloc_end, struct page *locked_page,
 				 unsigned bits_to_clear,
 				 unsigned long page_ops);
-struct bio *btrfs_bio_alloc(struct block_device *bdev, u64 first_byte);
+struct bio *btrfs_bio_alloc(u64 first_byte);
 struct bio *btrfs_io_bio_alloc(unsigned int nr_iovecs);
 struct bio *btrfs_bio_clone(struct bio *bio);
 struct bio *btrfs_bio_clone_partial(struct bio *orig, int offset, int size);

commit 00801ae4bb2be5f5af46502ef239ac5f4b536094
Author: David Sterba <dsterba@suse.com>
Date:   Thu May 2 16:53:47 2019 +0200

    btrfs: switch extent_buffer write_locks from atomic to int
    
    The write_locks is either 0 or 1 and always updated under the lock,
    so we don't need the atomic_t semantics.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 5616b96c365d..844e595cde5b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -190,7 +190,7 @@ struct extent_buffer {
 	int spinning_writers;
 	atomic_t spinning_readers;
 	atomic_t read_locks;
-	atomic_t write_locks;
+	int write_locks;
 	struct list_head leak_list;
 #endif
 };

commit f3dc24c52a28c700e35757dce7b38456888071e1
Author: David Sterba <dsterba@suse.com>
Date:   Thu May 2 16:51:53 2019 +0200

    btrfs: switch extent_buffer spinning_writers from atomic to int
    
    The spinning_writers is either 0 or 1 and always updated under the lock,
    so we don't need the atomic_t semantics.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 201da61dfc21..5616b96c365d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -187,7 +187,7 @@ struct extent_buffer {
 	wait_queue_head_t read_lock_wq;
 	struct page *pages[INLINE_EXTENT_BUFFER_PAGES];
 #ifdef CONFIG_BTRFS_DEBUG
-	atomic_t spinning_writers;
+	int spinning_writers;
 	atomic_t spinning_readers;
 	atomic_t read_locks;
 	atomic_t write_locks;

commit 06297d8cefcaa2029c4cb71b79285d2bfff06d4d
Author: David Sterba <dsterba@suse.com>
Date:   Thu May 2 16:47:23 2019 +0200

    btrfs: switch extent_buffer blocking_writers from atomic to int
    
    The blocking_writers is either 0 or 1 and always updated under the lock,
    so we don't need the atomic_t semantics.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index aa18a16a6ed7..201da61dfc21 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -167,7 +167,7 @@ struct extent_buffer {
 	struct rcu_head rcu_head;
 	pid_t lock_owner;
 
-	atomic_t blocking_writers;
+	int blocking_writers;
 	atomic_t blocking_readers;
 	bool lock_nested;
 	/* >= 0 if eb belongs to a log tree, -1 otherwise */

commit 50489a5734ec77e0a0613143512de09e2229f852
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 19:46:04 2019 +0300

    btrfs: Remove bio_offset argument from submit_bio_hook
    
    None of the implementers of the submit_bio_hook use the bio_offset
    parameter, simply remove it. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 37240e03c4e3..aa18a16a6ed7 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -105,8 +105,7 @@ struct extent_io_ops {
 	 * pointer will be called unconditionally.
 	 */
 	blk_status_t (*submit_bio_hook)(struct inode *inode, struct bio *bio,
-					int mirror_num, unsigned long bio_flags,
-					u64 bio_offset);
+					int mirror_num, unsigned long bio_flags);
 	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,
 				    struct page *page, u64 start, u64 end,
 				    int mirror);

commit c2ccfbc62e9f00979fc1a82ab93ff0a4ddd8944a
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 17:24:40 2019 +0300

    btrfs: Remove 'tree' argument from read_extent_buffer_pages
    
    This function always uses the btree inode's io_tree. Stop taking the
    tree as a function argument and instead access it internally from
    read_extent_buffer_pages. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index abafb48947ef..37240e03c4e3 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -433,8 +433,7 @@ void free_extent_buffer_stale(struct extent_buffer *eb);
 #define WAIT_NONE	0
 #define WAIT_COMPLETE	1
 #define WAIT_PAGE_LOCK	2
-int read_extent_buffer_pages(struct extent_io_tree *tree,
-			     struct extent_buffer *eb, int wait,
+int read_extent_buffer_pages(struct extent_buffer *eb, int wait,
 			     int mirror_num);
 void wait_on_extent_buffer_writeback(struct extent_buffer *eb);
 

commit a56b1c7bc83c2c5439e4a5d44f35cea36fbe2c9d
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 17:24:39 2019 +0300

    btrfs: Change submit_bio_hook to taking an inode directly
    
    The only possible 'private_data' that is passed to this function is
    actually an inode. Make that explicit by changing the signature of the
    call back. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 79bd20cf4226..abafb48947ef 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -104,7 +104,7 @@ struct extent_io_ops {
 	 * The following callbacks must be always defined, the function
 	 * pointer will be called unconditionally.
 	 */
-	blk_status_t (*submit_bio_hook)(void *private_data, struct bio *bio,
+	blk_status_t (*submit_bio_hook)(struct inode *inode, struct bio *bio,
 					int mirror_num, unsigned long bio_flags,
 					u64 bio_offset);
 	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,

commit a9355a0ef32f109b08bb0ff51d8ad5bd173cf21b
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 17:24:38 2019 +0300

    btrfs: Define submit_bio_hook's type directly
    
    There is no need to use a typedef to define the type of the function and
    then use that to define the respective member in extent_io_ops.  Define
    struct's member directly. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f7ca1516f70b..79bd20cf4226 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -95,9 +95,6 @@ struct btrfs_inode;
 struct btrfs_io_bio;
 struct io_failure_record;
 
-typedef	blk_status_t (extent_submit_bio_hook_t)(void *private_data, struct bio *bio,
-				       int mirror_num, unsigned long bio_flags,
-				       u64 bio_offset);
 
 typedef blk_status_t (extent_submit_bio_start_t)(void *private_data,
 		struct bio *bio, u64 bio_offset);
@@ -107,7 +104,9 @@ struct extent_io_ops {
 	 * The following callbacks must be always defined, the function
 	 * pointer will be called unconditionally.
 	 */
-	extent_submit_bio_hook_t *submit_bio_hook;
+	blk_status_t (*submit_bio_hook)(void *private_data, struct bio *bio,
+					int mirror_num, unsigned long bio_flags,
+					u64 bio_offset);
 	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,
 				    struct page *page, u64 start, u64 end,
 				    int mirror);

commit 45bfcfc168f84f498d9825ec20ff3f4ee9208e04
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Mar 27 14:24:17 2019 +0200

    btrfs: Implement find_first_clear_extent_bit
    
    This function is very similar to find_first_extent_bit except that it
    locates the first contiguous span of space which does not have bits set.
    It's intended use is in the freespace trimming code.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1680832d2c88..f7ca1516f70b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -403,6 +403,8 @@ static inline int set_extent_uptodate(struct extent_io_tree *tree, u64 start,
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
 			  u64 *start_ret, u64 *end_ret, unsigned bits,
 			  struct extent_state **cached_state);
+void find_first_clear_extent_bit(struct extent_io_tree *tree, u64 start,
+				 u64 *start_ret, u64 *end_ret, unsigned bits);
 int extent_invalidatepage(struct extent_io_tree *tree,
 			  struct page *page, unsigned long offset);
 int extent_write_full_page(struct page *page, struct writeback_control *wbc);

commit 8811133d8a982d3cef5d25eef54a8dca9e8e6ded
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Mar 27 14:24:16 2019 +0200

    btrfs: Optimize unallocated chunks discard
    
    Currently unallocated chunks are always trimmed. For example
    2 consecutive trims on large storage would trim freespace twice
    irrespective of whether the space was actually allocated or not between
    those trims.
    
    Optimise this behavior by exploiting the newly introduced alloc_state
    tree of btrfs_device. A new CHUNK_TRIMMED bit is used to mark
    those unallocated chunks which have been trimmed and have not been
    allocated afterwards. On chunk allocation the respective underlying devices'
    physical space will have its CHUNK_TRIMMED flag cleared. This avoids
    submitting discards for space which hasn't been changed since the last
    time discard was issued.
    
    This applies to the single mount period of the filesystem as the
    information is not stored permanently.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6435c2818ec3..1680832d2c88 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -27,8 +27,14 @@
 				 EXTENT_CLEAR_DATA_RESV)
 #define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING)
 
-/* Redefined bits above which are used only in the device allocation tree */
+/*
+ * Redefined bits above which are used only in the device allocation tree,
+ * shouldn't be using EXTENT_LOCKED / EXTENT_BOUNDARY / EXTENT_CLEAR_META_RESV
+ * / EXTENT_CLEAR_DATA_RESV because they have special meaning to the bit
+ * manipulation functions
+ */
 #define CHUNK_ALLOCATED EXTENT_DIRTY
+#define CHUNK_TRIMMED   EXTENT_DEFRAG
 
 /*
  * flags for bio submission. The high bits indicate the compression

commit 4ca7365606ca08282da248fbc270abf58a515e20
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Mar 27 14:24:10 2019 +0200

    btrfs: Implement set_extent_bits_nowait
    
    It will be used in a future patch that will require modifying an
    extent_io_tree struct under a spinlock.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 71213438db3a..6435c2818ec3 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -328,6 +328,8 @@ int set_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   unsigned bits, u64 *failed_start,
 		   struct extent_state **cached_state, gfp_t mask);
+int set_extent_bits_nowait(struct extent_io_tree *tree, u64 start, u64 end,
+			   unsigned bits);
 
 static inline int set_extent_bits(struct extent_io_tree *tree, u64 start,
 		u64 end, unsigned bits)

commit 930b09072977583226a05b4f2e1db259f9a2417b
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Mar 25 14:31:26 2019 +0200

    btrfs: Introduce new bits for device allocation tree
    
    Rather than hijacking the existing defines let's just define new bits,
    with more descriptive names. Instead of using yet more (currently at 18)
    bits for the new flags, use the fact those flags will be specific to
    the device allocation tree so define them using existing EXTENT_* flags.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 722dc7d1b674..71213438db3a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -27,6 +27,9 @@
 				 EXTENT_CLEAR_DATA_RESV)
 #define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING)
 
+/* Redefined bits above which are used only in the device allocation tree */
+#define CHUNK_ALLOCATED EXTENT_DIRTY
+
 /*
  * flags for bio submission. The high bits indicate the compression
  * type for this bio

commit 41e7acd38c1ae82f24f51d302bbdecdb4675b6b2
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Mar 25 14:31:24 2019 +0200

    btrfs: Rename and export clear_btree_io_tree
    
    This function is going to be used to clear out the device extent
    allocation information. Give it a more generic name and export it. This
    is in preparation to replacing the pending/pinned chunk lists with an
    extent tree. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c4ec104ac157..722dc7d1b674 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -255,6 +255,7 @@ typedef struct extent_map *(get_extent_t)(struct btrfs_inode *inode,
 void extent_io_tree_init(struct btrfs_fs_info *fs_info,
 			 struct extent_io_tree *tree, unsigned int owner,
 			 void *private_data);
+void extent_io_tree_release(struct extent_io_tree *tree);
 int try_release_extent_mapping(struct page *page, gfp_t mask);
 int try_release_extent_buffer(struct page *page);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,

commit 20a1fbf97e11204e099a95167f1851fc54296a00
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 11:23:44 2019 +0100

    btrfs: get fs_info from eb in repair_eb_io_failure
    
    We can read fs_info from extent buffer and can drop it from the
    parameters. As all callsites are updated, add the btrfs_ prefix as the
    function is exported.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 586baed03780..c4ec104ac157 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -502,8 +502,7 @@ int clean_io_failure(struct btrfs_fs_info *fs_info,
 		     struct extent_io_tree *io_tree, u64 start,
 		     struct page *page, u64 ino, unsigned int pg_offset);
 void end_extent_writepage(struct page *page, int err, u64 start, u64 end);
-int repair_eb_io_failure(struct btrfs_fs_info *fs_info,
-			 struct extent_buffer *eb, int mirror_num);
+int btrfs_repair_eb_io_failure(struct extent_buffer *eb, int mirror_num);
 
 /*
  * When IO fails, either with EIO or csum verification fails, we

commit ed1b4ed79df258f08f16eac4a4fb96dc6d1a0f3a
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 24 16:31:17 2018 +0200

    btrfs: switch extent_buffer::lock_nested to bool
    
    The member is tracking simple status of the lock, we can use bool for
    that and make some room for further space reduction in the structure.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 43a9530279db..586baed03780 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -162,7 +162,7 @@ struct extent_buffer {
 
 	atomic_t blocking_writers;
 	atomic_t blocking_readers;
-	short lock_nested;
+	bool lock_nested;
 	/* >= 0 if eb belongs to a log tree, -1 otherwise */
 	short log_index;
 

commit c79adfc085c0662385cfcb55f15590303212e8e9
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 24 16:24:26 2018 +0200

    btrfs: use assertion helpers for extent buffer write lock counters
    
    Use the helpers where open coded. On non-debug builds, the warnings will
    not trigger and extent_buffer::write_locks become unused and can be
    moved to the appropriate section, saving a few bytes.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 41c5d0e9dc75..43a9530279db 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -160,8 +160,6 @@ struct extent_buffer {
 	struct rcu_head rcu_head;
 	pid_t lock_owner;
 
-	/* count of read lock holders on the extent buffer */
-	atomic_t write_locks;
 	atomic_t blocking_writers;
 	atomic_t blocking_readers;
 	short lock_nested;
@@ -185,6 +183,7 @@ struct extent_buffer {
 	atomic_t spinning_writers;
 	atomic_t spinning_readers;
 	atomic_t read_locks;
+	atomic_t write_locks;
 	struct list_head leak_list;
 #endif
 };

commit 5c9c799ab78336a4161b16126952a7e1320a8c77
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 24 16:15:51 2018 +0200

    btrfs: use assertion helpers for extent buffer read lock counters
    
    Use the helpers where open coded. On non-debug builds, the warnings will
    not trigger and extent_buffer::read_locks become unused and can be
    moved to the appropriate section, saving a few bytes.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 89e56df64d6c..41c5d0e9dc75 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -162,7 +162,6 @@ struct extent_buffer {
 
 	/* count of read lock holders on the extent buffer */
 	atomic_t write_locks;
-	atomic_t read_locks;
 	atomic_t blocking_writers;
 	atomic_t blocking_readers;
 	short lock_nested;
@@ -185,6 +184,7 @@ struct extent_buffer {
 #ifdef CONFIG_BTRFS_DEBUG
 	atomic_t spinning_writers;
 	atomic_t spinning_readers;
+	atomic_t read_locks;
 	struct list_head leak_list;
 #endif
 };

commit afd495a8264fb25cef49834b5c3559b8aaa612ee
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 24 15:57:38 2018 +0200

    btrfs: use assertion helpers for spinning readers
    
    Use the helpers where open coded. On non-debug builds, the warnings will
    not trigger and extent_buffer::spining_readers become unused and can be
    moved to the appropriate section, saving a few bytes.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3577ef33bc36..89e56df64d6c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -165,7 +165,6 @@ struct extent_buffer {
 	atomic_t read_locks;
 	atomic_t blocking_writers;
 	atomic_t blocking_readers;
-	atomic_t spinning_readers;
 	short lock_nested;
 	/* >= 0 if eb belongs to a log tree, -1 otherwise */
 	short log_index;
@@ -185,6 +184,7 @@ struct extent_buffer {
 	struct page *pages[INLINE_EXTENT_BUFFER_PAGES];
 #ifdef CONFIG_BTRFS_DEBUG
 	atomic_t spinning_writers;
+	atomic_t spinning_readers;
 	struct list_head leak_list;
 #endif
 };

commit 843ccf9f46baff289946e897b11fd813de62d06f
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 24 14:56:28 2018 +0200

    btrfs: use assertion helpers for spinning writers
    
    Use the helpers where open coded. On non-debug builds, the warnings will
    not trigger and extent_buffer::spining_writers become unused and can be
    moved to the appropriate section, saving a few bytes.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1e5be66c7e0b..3577ef33bc36 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -166,7 +166,6 @@ struct extent_buffer {
 	atomic_t blocking_writers;
 	atomic_t blocking_readers;
 	atomic_t spinning_readers;
-	atomic_t spinning_writers;
 	short lock_nested;
 	/* >= 0 if eb belongs to a log tree, -1 otherwise */
 	short log_index;
@@ -185,6 +184,7 @@ struct extent_buffer {
 	wait_queue_head_t read_lock_wq;
 	struct page *pages[INLINE_EXTENT_BUFFER_PAGES];
 #ifdef CONFIG_BTRFS_DEBUG
+	atomic_t spinning_writers;
 	struct list_head leak_list;
 #endif
 };

commit 8882679ea50b9ceb8b86cbceb061322a97876534
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Mar 14 15:28:31 2019 +0200

    btrfs: Remove EXTENT_IOBITS
    
    This flag just became synonymous to EXTENT_LOCKED, so just remove it and
    used EXTENT_LOCKED directly. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a1dc61b7945d..1e5be66c7e0b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -23,7 +23,6 @@
 #define EXTENT_QGROUP_RESERVED	(1U << 12)
 #define EXTENT_CLEAR_DATA_RESV	(1U << 13)
 #define EXTENT_DELALLOC_NEW	(1U << 14)
-#define EXTENT_IOBITS		(EXTENT_LOCKED)
 #define EXTENT_DO_ACCOUNTING    (EXTENT_CLEAR_META_RESV | \
 				 EXTENT_CLEAR_DATA_RESV)
 #define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING)

commit 4e586ca3c3e63269e136b8c1f20bf5943a0b94ca
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Mar 14 15:28:30 2019 +0200

    btrfs: Remove EXTENT_WRITEBACK
    
    This flag was introduced in a52d9a8033c4 ("Btrfs: Extent based page
    cache code.") and subsequently it's usage effectively was removed by
    1edbb734b4e0 ("Btrfs: reduce CPU usage in the extent_state tree") and
    f2a97a9dbd86 ("btrfs: remove all unused functions"). Just remove it,
    no functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index aef7a46b1e61..a1dc61b7945d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -9,22 +9,21 @@
 
 /* bits for the extent state */
 #define EXTENT_DIRTY		(1U << 0)
-#define EXTENT_WRITEBACK	(1U << 1)
-#define EXTENT_UPTODATE		(1U << 2)
-#define EXTENT_LOCKED		(1U << 3)
-#define EXTENT_NEW		(1U << 4)
-#define EXTENT_DELALLOC		(1U << 5)
-#define EXTENT_DEFRAG		(1U << 6)
-#define EXTENT_BOUNDARY		(1U << 9)
-#define EXTENT_NODATASUM	(1U << 10)
-#define EXTENT_CLEAR_META_RESV	(1U << 11)
-#define EXTENT_NEED_WAIT	(1U << 12)
-#define EXTENT_DAMAGED		(1U << 13)
-#define EXTENT_NORESERVE	(1U << 14)
-#define EXTENT_QGROUP_RESERVED	(1U << 15)
-#define EXTENT_CLEAR_DATA_RESV	(1U << 16)
-#define EXTENT_DELALLOC_NEW	(1U << 17)
-#define EXTENT_IOBITS		(EXTENT_LOCKED | EXTENT_WRITEBACK)
+#define EXTENT_UPTODATE		(1U << 1)
+#define EXTENT_LOCKED		(1U << 2)
+#define EXTENT_NEW		(1U << 3)
+#define EXTENT_DELALLOC		(1U << 4)
+#define EXTENT_DEFRAG		(1U << 5)
+#define EXTENT_BOUNDARY		(1U << 6)
+#define EXTENT_NODATASUM	(1U << 7)
+#define EXTENT_CLEAR_META_RESV	(1U << 8)
+#define EXTENT_NEED_WAIT	(1U << 9)
+#define EXTENT_DAMAGED		(1U << 10)
+#define EXTENT_NORESERVE	(1U << 11)
+#define EXTENT_QGROUP_RESERVED	(1U << 12)
+#define EXTENT_CLEAR_DATA_RESV	(1U << 13)
+#define EXTENT_DELALLOC_NEW	(1U << 14)
+#define EXTENT_IOBITS		(EXTENT_LOCKED)
 #define EXTENT_DO_ACCOUNTING    (EXTENT_CLEAR_META_RESV | \
 				 EXTENT_CLEAR_DATA_RESV)
 #define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING)

commit 43eb5f2975848743e5b14c5bef20f40d404a7a04
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Mar 1 10:47:59 2019 +0800

    btrfs: Introduce extent_io_tree::owner to distinguish different io_trees
    
    Btrfs has the following different extent_io_trees used:
    
    - fs_info::free_extents[2]
    - btrfs_inode::io_tree - for both normal inodes and the btree inode
    - btrfs_inode::io_failure_tree
    - btrfs_transaction::dirty_pages
    - btrfs_root::dirty_log_pages
    
    If we want to trace changes in those trees, it will be pretty hard to
    distinguish them.
    
    Instead of using hard-to-read pointer address, this patch will introduce
    a new member extent_io_tree::owner to track the owner.
    
    This modification needs all the callers of extent_io_tree_init() to
    accept a new parameter @owner.
    
    This patch provides the basis for later trace events.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index bd5c12599057..aef7a46b1e61 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -106,12 +106,27 @@ struct extent_io_ops {
 				    int mirror);
 };
 
+enum {
+	IO_TREE_FS_INFO_FREED_EXTENTS0,
+	IO_TREE_FS_INFO_FREED_EXTENTS1,
+	IO_TREE_INODE_IO,
+	IO_TREE_INODE_IO_FAILURE,
+	IO_TREE_RELOC_BLOCKS,
+	IO_TREE_TRANS_DIRTY_PAGES,
+	IO_TREE_ROOT_DIRTY_LOG_PAGES,
+	IO_TREE_SELFTEST,
+};
+
 struct extent_io_tree {
 	struct rb_root state;
 	struct btrfs_fs_info *fs_info;
 	void *private_data;
 	u64 dirty_bytes;
 	bool track_uptodate;
+
+	/* Who owns this io tree, should be one of IO_TREE_* */
+	u8 owner;
+
 	spinlock_t lock;
 	const struct extent_io_ops *ops;
 };
@@ -241,7 +256,8 @@ typedef struct extent_map *(get_extent_t)(struct btrfs_inode *inode,
 					  int create);
 
 void extent_io_tree_init(struct btrfs_fs_info *fs_info,
-			 struct extent_io_tree *tree, void *private_data);
+			 struct extent_io_tree *tree, unsigned int owner,
+			 void *private_data);
 int try_release_extent_mapping(struct page *page, gfp_t mask);
 int try_release_extent_buffer(struct page *page);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,

commit 7b4397386fbdc606eb053bc2a1cfd985aea59916
Author: David Sterba <dsterba@suse.com>
Date:   Mon Mar 11 15:58:30 2019 +0100

    btrfs: switch extent_io_tree::track_uptodate to bool
    
    This patch is split from the following one "btrfs: Introduce
    extent_io_tree::owner to distinguish different io_trees" from Qu, so the
    different changes are not mixed together.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e63215d69299..bd5c12599057 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -111,7 +111,7 @@ struct extent_io_tree {
 	struct btrfs_fs_info *fs_info;
 	void *private_data;
 	u64 dirty_bytes;
-	int track_uptodate;
+	bool track_uptodate;
 	spinlock_t lock;
 	const struct extent_io_ops *ops;
 };

commit c258d6e36442eb5d3363f6dbc0e6f2c162bfb66d
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Mar 1 10:47:58 2019 +0800

    btrfs: Introduce fs_info to extent_io_tree
    
    This patch will add a new member fs_info to extent_io_tree.
    
    This provides the basis for later trace events to distinguish the output
    between different btrfs filesystems. While this increases the size of
    the structure, we want to know the source of the trace events and
    passing the fs_info as an argument to all contexts is not possible.
    
    The selftests are now allowed to set it to NULL as they don't use the
    tracepoints.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 08749e0b9c32..e63215d69299 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -108,6 +108,7 @@ struct extent_io_ops {
 
 struct extent_io_tree {
 	struct rb_root state;
+	struct btrfs_fs_info *fs_info;
 	void *private_data;
 	u64 dirty_bytes;
 	int track_uptodate;
@@ -239,7 +240,8 @@ typedef struct extent_map *(get_extent_t)(struct btrfs_inode *inode,
 					  u64 start, u64 len,
 					  int create);
 
-void extent_io_tree_init(struct extent_io_tree *tree, void *private_data);
+void extent_io_tree_init(struct btrfs_fs_info *fs_info,
+			 struct extent_io_tree *tree, void *private_data);
 int try_release_extent_mapping(struct page *page, gfp_t mask);
 int try_release_extent_buffer(struct page *page);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,

commit ba8f5206a4fc579dcbc5e7dd571965236a9842d3
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jan 30 16:50:50 2019 +0200

    btrfs: Remove EXTENT_FIRST_DELALLOC bit
    
    With the refactoring introduced in 8b62f87bad9c ("Btrfs: reworki
    outstanding_extents") this flag became unused. Remove it and renumber
    the following flags accordingly. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 9673be3f3d1f..08749e0b9c32 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -18,17 +18,16 @@
 #define EXTENT_BOUNDARY		(1U << 9)
 #define EXTENT_NODATASUM	(1U << 10)
 #define EXTENT_CLEAR_META_RESV	(1U << 11)
-#define EXTENT_FIRST_DELALLOC	(1U << 12)
-#define EXTENT_NEED_WAIT	(1U << 13)
-#define EXTENT_DAMAGED		(1U << 14)
-#define EXTENT_NORESERVE	(1U << 15)
-#define EXTENT_QGROUP_RESERVED	(1U << 16)
-#define EXTENT_CLEAR_DATA_RESV	(1U << 17)
-#define EXTENT_DELALLOC_NEW	(1U << 18)
+#define EXTENT_NEED_WAIT	(1U << 12)
+#define EXTENT_DAMAGED		(1U << 13)
+#define EXTENT_NORESERVE	(1U << 14)
+#define EXTENT_QGROUP_RESERVED	(1U << 15)
+#define EXTENT_CLEAR_DATA_RESV	(1U << 16)
+#define EXTENT_DELALLOC_NEW	(1U << 17)
 #define EXTENT_IOBITS		(EXTENT_LOCKED | EXTENT_WRITEBACK)
 #define EXTENT_DO_ACCOUNTING    (EXTENT_CLEAR_META_RESV | \
 				 EXTENT_CLEAR_DATA_RESV)
-#define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
+#define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING)
 
 /*
  * flags for bio submission. The high bits indicate the compression

commit 52042d8e82ff50d40e76a275ac0b97aa663328b0
Author: Andrea Gelmini <andrea.gelmini@gelma.net>
Date:   Wed Nov 28 12:05:13 2018 +0100

    btrfs: Fix typos in comments and strings
    
    The typos accumulate over time so once in a while time they get fixed in
    a large patch.
    
    Signed-off-by: Andrea Gelmini <andrea.gelmini@gelma.net>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 04eefa93fe1f..9673be3f3d1f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -98,7 +98,7 @@ typedef blk_status_t (extent_submit_bio_start_t)(void *private_data,
 
 struct extent_io_ops {
 	/*
-	 * The following callbacks must be allways defined, the function
+	 * The following callbacks must be always defined, the function
 	 * pointer will be called unconditionally.
 	 */
 	extent_submit_bio_hook_t *submit_bio_hook;

commit 3522e90301d7a669288611cb7e73cab4ac135545
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Thu Nov 29 11:33:38 2018 +0800

    btrfs: remove always true if branch in find_delalloc_range
    
    The @found is always false when it comes to the if branch. Besides, the
    bool type is more suitable for @found. Change the return value of the
    function and its caller to bool as well.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index fd42492e62e5..04eefa93fe1f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -525,7 +525,7 @@ int free_io_failure(struct extent_io_tree *failure_tree,
 		    struct extent_io_tree *io_tree,
 		    struct io_failure_record *rec);
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-u64 find_lock_delalloc_range(struct inode *inode, struct extent_io_tree *tree,
+bool find_lock_delalloc_range(struct inode *inode, struct extent_io_tree *tree,
 			     struct page *locked_page, u64 *start,
 			     u64 *end);
 #endif

commit 80cb38362d330e1e4156a4904c17ce994589bd7d
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 27 15:03:20 2018 +0100

    btrfs: switch EXTENT_BUFFER_* to enums
    
    We can use simple enum for values that are not part of on-disk format:
    extent buffer flags;
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a1d3ea5a0d32..fd42492e62e5 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -37,18 +37,22 @@
 #define EXTENT_BIO_COMPRESSED 1
 #define EXTENT_BIO_FLAG_SHIFT 16
 
-/* these are bit numbers for test/set bit */
-#define EXTENT_BUFFER_UPTODATE 0
-#define EXTENT_BUFFER_DIRTY 2
-#define EXTENT_BUFFER_CORRUPT 3
-#define EXTENT_BUFFER_READAHEAD 4	/* this got triggered by readahead */
-#define EXTENT_BUFFER_TREE_REF 5
-#define EXTENT_BUFFER_STALE 6
-#define EXTENT_BUFFER_WRITEBACK 7
-#define EXTENT_BUFFER_READ_ERR 8        /* read IO error */
-#define EXTENT_BUFFER_UNMAPPED 9
-#define EXTENT_BUFFER_IN_TREE 10
-#define EXTENT_BUFFER_WRITE_ERR 11    /* write IO error */
+enum {
+	EXTENT_BUFFER_UPTODATE,
+	EXTENT_BUFFER_DIRTY,
+	EXTENT_BUFFER_CORRUPT,
+	/* this got triggered by readahead */
+	EXTENT_BUFFER_READAHEAD,
+	EXTENT_BUFFER_TREE_REF,
+	EXTENT_BUFFER_STALE,
+	EXTENT_BUFFER_WRITEBACK,
+	/* read IO error */
+	EXTENT_BUFFER_READ_ERR,
+	EXTENT_BUFFER_UNMAPPED,
+	EXTENT_BUFFER_IN_TREE,
+	/* write IO error */
+	EXTENT_BUFFER_WRITE_ERR,
+};
 
 /* these are flags for __process_pages_contig */
 #define PAGE_UNLOCK		(1 << 0)

commit 78e62c02abb94e49ea739226a70325a6bf7a6603
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 22 10:17:49 2018 +0200

    btrfs: Remove extent_io_ops::readpage_io_failed_hook
    
    For data inodes this hook does nothing but to return -EAGAIN which is
    used to signal to the endio routines that this bio belongs to a data
    inode. If this is the case the actual retrying is handled by
    bio_readpage_error. Alternatively, if this bio belongs to the btree
    inode then btree_io_failed_hook just does some cleanup and doesn't retry
    anything.
    
    This patch simplifies the code flow by eliminating
    readpage_io_failed_hook and instead open-coding btree_io_failed_hook in
    end_bio_extent_readpage. Also eliminate some needless checks since IO is
    always performed on either data inode or btree inode, both of which are
    guaranteed to have their extent_io_tree::ops set.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 17878eef9bcc..a1d3ea5a0d32 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -101,7 +101,6 @@ struct extent_io_ops {
 	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,
 				    struct page *page, u64 start, u64 end,
 				    int mirror);
-	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
 };
 
 struct extent_io_tree {

commit 0e6ec385b55f6001da8c6b1532494241e52c550d
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Nov 16 13:04:44 2018 +0000

    Btrfs: allow clear_extent_dirty() to receive a cached extent state record
    
    We can have a lot freed extents during the life span of transaction, so
    the red black tree that keeps track of the ranges of each freed extent
    (fs_info->freed_extents[]) can get quite big. When finishing a
    transaction commit we find each range, process it (discard the extents,
    unpin them) and then remove it from the red black tree.
    
    We can use an extent state record as a cache when searching for a range,
    so that when we clean the range we can use the cached extent state we
    passed to the search function instead of iterating the red black tree
    again. Doing things as fast as possible when finishing a transaction (in
    state TRANS_STATE_UNBLOCKED) is convenient as it reduces the time we
    block another task that wants to commit the next transaction.
    
    So change clear_extent_dirty() to allow an optional extent state record to
    be passed as an argument, which will be passed down to __clear_extent_bit.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 22b34426f9f8..17878eef9bcc 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -329,11 +329,11 @@ static inline int set_extent_dirty(struct extent_io_tree *tree, u64 start,
 }
 
 static inline int clear_extent_dirty(struct extent_io_tree *tree, u64 start,
-		u64 end)
+				     u64 end, struct extent_state **cached)
 {
 	return clear_extent_bit(tree, start, end,
 				EXTENT_DIRTY | EXTENT_DELALLOC |
-				EXTENT_DO_ACCOUNTING, 0, 0, NULL);
+				EXTENT_DO_ACCOUNTING, 0, 0, cached);
 }
 
 int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,

commit ce9f967f31ea91365c0aa897dbc2bddbd39d7a73
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Nov 19 10:38:17 2018 +0100

    btrfs: use EXPORT_FOR_TESTS for conditionally exported functions
    
    Several functions in BTRFS are only used inside the source file they are
    declared if CONFIG_BTRFS_FS_RUN_SANITY_TESTS is not defined. However if
    CONFIG_BTRFS_FS_RUN_SANITY_TESTS is defined these functions are shared
    with the unit tests code.
    
    Before the introduction of the EXPORT_FOR_TESTS macro, these functions
    could not be declared as static and the compiler had a harder task when
    optimizing and inlining them.
    
    As we have EXPORT_FOR_TESTS now, use it where appropriate to support the
    compiler.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 30bfeefa2d89..22b34426f9f8 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -522,10 +522,9 @@ int free_io_failure(struct extent_io_tree *failure_tree,
 		    struct extent_io_tree *io_tree,
 		    struct io_failure_record *rec);
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-u64 btrfs_find_lock_delalloc_range(struct inode *inode,
-				      struct extent_io_tree *tree,
-				      struct page *locked_page, u64 *start,
-				      u64 *end);
+u64 find_lock_delalloc_range(struct inode *inode, struct extent_io_tree *tree,
+			     struct page *locked_page, u64 *start,
+			     u64 *end);
 #endif
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
 					       u64 start);

commit 917aacecc567d56d0ec5f244043f403f7102eda8
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Fri Oct 26 14:43:20 2018 +0300

    btrfs: Sink find_lock_delalloc_range's 'max_bytes' argument
    
    All callers of this function pass BTRFS_MAX_EXTENT_SIZE (128M) so let's
    reduce the argument count and make that a local variable. No functional
    changes.
    
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index d96fd534f144..30bfeefa2d89 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -525,7 +525,7 @@ int free_io_failure(struct extent_io_tree *failure_tree,
 u64 btrfs_find_lock_delalloc_range(struct inode *inode,
 				      struct extent_io_tree *tree,
 				      struct page *locked_page, u64 *start,
-				      u64 *end, u64 max_bytes);
+				      u64 *end);
 #endif
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
 					       u64 start);

commit abbb55f4cd56dffb20ba7dd8dfc53154c79934f1
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:53 2018 +0200

    btrfs: Remove extent_io_ops::split_extent_hook callback
    
    This is the counterpart to merge_extent_hook, similarly, it's used only
    for data/freespace inodes so let's remove it, rename it and call it
    directly where necessary. No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 7d181a378d90..d96fd534f144 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -102,12 +102,6 @@ struct extent_io_ops {
 				    struct page *page, u64 start, u64 end,
 				    int mirror);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
-
-	/*
-	 * Optional hooks, called if the pointer is not NULL
-	 */
-	void (*split_extent_hook)(void *private_data,
-				  struct extent_state *orig, u64 split);
 };
 
 struct extent_io_tree {

commit 5c848198aad3ad1c68309aa7002fa571a540568c
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:52 2018 +0200

    btrfs: Remove extent_io_ops::merge_extent_hook callback
    
    This callback is used only for data and free space inodes. Such inodes
    are guaranteed to have their extent_io_tree::private_data set to the
    inode struct. Exploit this fact to directly call the function. Also give
    it a more descriptive name. No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a3a3302f3625..7d181a378d90 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -106,9 +106,6 @@ struct extent_io_ops {
 	/*
 	 * Optional hooks, called if the pointer is not NULL
 	 */
-	void (*merge_extent_hook)(void *private_data,
-				  struct extent_state *new,
-				  struct extent_state *other);
 	void (*split_extent_hook)(void *private_data,
 				  struct extent_state *orig, u64 split);
 };

commit a36bb5f9a90c9bab05b7084d21718450e8067fb0
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:51 2018 +0200

    btrfs: Remove extent_io_ops::clear_bit_hook callback
    
    This is the counterpart to ex-set_bit_hook (now btrfs_set_delalloc_extent),
    similar to what was done before remove clear_bit_hook and rename the
    function. No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b3235d46b5c3..a3a3302f3625 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -106,9 +106,6 @@ struct extent_io_ops {
 	/*
 	 * Optional hooks, called if the pointer is not NULL
 	 */
-	void (*clear_bit_hook)(void *private_data,
-			struct extent_state *state,
-			unsigned *bits);
 	void (*merge_extent_hook)(void *private_data,
 				  struct extent_state *new,
 				  struct extent_state *other);

commit e06a1fc99cc7eca09118cc02c4d7540fa69e9d09
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:50 2018 +0200

    btrfs: Remove extent_io_ops::set_bit_hook extent_io callback
    
    This callback is used to properly account delalloc extents for data
    inodes (ordinary file inodes and freespace v1 inodes). Those can be
    easily identified since they have their extent_io trees ->private_data
    member point to the inode. Let's exploit this fact to remove the
    needless indirection through extent_io_hooks and directly call the
    function. Also give the function a name which reflects its purpose -
    btrfs_set_delalloc_extent.
    
    This patch also modified test_find_delalloc so that the extent_io_tree
    used for testing doesn't have its ->private_data set which would have
    caused a crash in btrfs_set_delalloc_extent due to the btrfs_inode->root
    member not being initialised. The old version of the code also didn't
    call set_bit_hook since the extent_io ops weren't set for the inode.  No
    functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3cb84a0fbaab..b3235d46b5c3 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -106,8 +106,6 @@ struct extent_io_ops {
 	/*
 	 * Optional hooks, called if the pointer is not NULL
 	 */
-	void (*set_bit_hook)(void *private_data, struct extent_state *state,
-			     unsigned *bits);
 	void (*clear_bit_hook)(void *private_data,
 			struct extent_state *state,
 			unsigned *bits);

commit 65a680f6b7d6e83ca3a440588d3581f4a38265bf
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:49 2018 +0200

    btrfs: Remove extent_io_ops::check_extent_io_range callback
    
    This callback was only used in debug builds by btrfs_leak_debug_check.
    A better approach is to move its implementation in
    btrfs_leak_debug_check and ensure the latter is only executed for extent
    tree which have ->private_data set i.e. relate to a data node and not
    the btree one. No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 415ea7c2b058..3cb84a0fbaab 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -116,8 +116,6 @@ struct extent_io_ops {
 				  struct extent_state *other);
 	void (*split_extent_hook)(void *private_data,
 				  struct extent_state *orig, u64 split);
-	void (*check_extent_io_range)(void *private_data, const char *caller,
-				      u64 start, u64 end);
 };
 
 struct extent_io_tree {

commit 7087a9d8db88ef9b7f8a30ac5706aa396b78e6c9
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:48 2018 +0200

    btrfs: Remove extent_io_ops::writepage_end_io_hook
    
    This callback is ony ever called for data page writeout so there is no
    need to actually abstract it via extent_io_ops. Lets just export it,
    remove the definition of the callback and call it directly in the
    functions that invoke the callback. Also rename the function to
    btrfs_writepage_endio_finish_ordered since what it really does is
    account finished io in the ordered extent data structures.  No
    functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4275a1061f5a..415ea7c2b058 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -106,8 +106,6 @@ struct extent_io_ops {
 	/*
 	 * Optional hooks, called if the pointer is not NULL
 	 */
-	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
-				      struct extent_state *state, int uptodate);
 	void (*set_bit_hook)(void *private_data, struct extent_state *state,
 			     unsigned *bits);
 	void (*clear_bit_hook)(void *private_data,

commit d75855b4518b525dbba4e461819b26bc5bb89a82
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:47 2018 +0200

    btrfs: Remove extent_io_ops::writepage_start_hook
    
    This hook is called only from __extent_writepage_io which is already
    called only from the data page writeout path. So there is no need to
    make an indirect call via extent_io_ops. This patch just removes the
    callback definition, exports the callback function and calls it directly
    at the only call site. Also give the function a more descriptive name.
    No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index ca48187b86ba..4275a1061f5a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -106,7 +106,6 @@ struct extent_io_ops {
 	/*
 	 * Optional hooks, called if the pointer is not NULL
 	 */
-	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
 	void (*set_bit_hook)(void *private_data, struct extent_state *state,

commit 5eaad97af8aeff38debe7d3c69ec3a0d71f8350f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 1 14:09:46 2018 +0200

    btrfs: Remove extent_io_ops::fill_delalloc
    
    This callback is called only from writepage_delalloc which in turn is
    guaranteed to be called from the data page writeout path. In the end
    there is no reason to have the call to this function to be indrected via
    the extent_io_ops structure. This patch removes the callback definition,
    exports the function and calls it directly. No functional changes.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ rename to btrfs_run_delalloc_range ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 369daa5d4f73..ca48187b86ba 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -106,11 +106,6 @@ struct extent_io_ops {
 	/*
 	 * Optional hooks, called if the pointer is not NULL
 	 */
-	int (*fill_delalloc)(void *private_data, struct page *locked_page,
-			     u64 start, u64 end, int *page_started,
-			     unsigned long *nr_written,
-			     struct writeback_control *wbc);
-
 	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);

commit 9c36396c2a788facd4282a2b0646a1c4ac19847a
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 17 17:28:06 2018 +0200

    btrfs: tests: add separate stub for find_lock_delalloc_range
    
    The helper find_lock_delalloc_range is now conditionally built static,
    dpending on whether the self-tests are enabled or not. There's a macro
    that is supposed to hide the export, used only once. To discourage
    further use, drop it an add a public wrapper for the helper needed by
    tests.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f2ab42d57f02..369daa5d4f73 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -546,7 +546,7 @@ int free_io_failure(struct extent_io_tree *failure_tree,
 		    struct extent_io_tree *io_tree,
 		    struct io_failure_record *rec);
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-noinline u64 find_lock_delalloc_range(struct inode *inode,
+u64 btrfs_find_lock_delalloc_range(struct inode *inode,
 				      struct extent_io_tree *tree,
 				      struct page *locked_page, u64 *start,
 				      u64 *end, u64 max_bytes);

commit abb57ef3ff9720c42bbc06bcd1788da9ce1a3eb8
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Fri Sep 14 01:44:42 2018 +0800

    Btrfs: skip set_page_dirty if eb pages are already dirty
    
    As long as @eb is marked with EXTENT_BUFFER_DIRTY, all of its pages
    are dirty, so no need to set pages dirty again.
    
    Ftrace showed that the loop took 10us on my dev box, so removing this
    can save us at least 10us if eb is already dirty and otherwise avoid a
    potentially expensive calls to set_page_dirty.
    
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b4d03e677e1d..f2ab42d57f02 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -479,7 +479,7 @@ void extent_buffer_bitmap_set(struct extent_buffer *eb, unsigned long start,
 void extent_buffer_bitmap_clear(struct extent_buffer *eb, unsigned long start,
 				unsigned long pos, unsigned long len);
 void clear_extent_buffer_dirty(struct extent_buffer *eb);
-int set_extent_buffer_dirty(struct extent_buffer *eb);
+bool set_extent_buffer_dirty(struct extent_buffer *eb);
 void set_extent_buffer_uptodate(struct extent_buffer *eb);
 void clear_extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_under_io(struct extent_buffer *eb);

commit 5cdc84bfde22dc17b11ee7cb18cebd48f4a09f70
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 20:32:52 2018 +0200

    btrfs: drop extent_io_ops::set_range_writeback callback
    
    The data and metadata callback implementation both use the same
    function. We can remove the call indirection and intermediate helper
    completely.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 5c07f87c2ec9..b4d03e677e1d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -102,7 +102,6 @@ struct extent_io_ops {
 				    struct page *page, u64 start, u64 end,
 				    int mirror);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
-	void (*set_range_writeback)(void *private_data, u64 start, u64 end);
 
 	/*
 	 * Optional hooks, called if the pointer is not NULL

commit 00032d38eaa89c76de7d9c1ae6de8c48c14edd74
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 19:28:09 2018 +0200

    btrfs: drop extent_io_ops::merge_bio_hook callback
    
    The data and metadata callback implementation both use the same
    function. We can remove the call indirection completely.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 004517f3eb35..5c07f87c2ec9 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -101,9 +101,6 @@ struct extent_io_ops {
 	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,
 				    struct page *page, u64 start, u64 end,
 				    int mirror);
-	int (*merge_bio_hook)(struct page *page, unsigned long offset,
-			      size_t size, struct bio *bio,
-			      unsigned long bio_flags);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
 	void (*set_range_writeback)(void *private_data, u64 start, u64 end);
 

commit 05912a3c04ebca217507b4323b679c60eda4ac11
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 19:23:45 2018 +0200

    btrfs: drop extent_io_ops::tree_fs_info callback
    
    All implementations of the callback are trivial and do the same and
    there's only one user. Merge everything together.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4e6d34dd7caf..004517f3eb35 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -105,7 +105,6 @@ struct extent_io_ops {
 			      size_t size, struct bio *bio,
 			      unsigned long bio_flags);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
-	struct btrfs_fs_info *(*tree_fs_info)(void *private_data);
 	void (*set_range_writeback)(void *private_data, u64 start, u64 end);
 
 	/*

commit e288c080dddd1fdc3b7e0165cebd7af51a52d016
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 17:36:24 2018 +0200

    btrfs: unify end_io callbacks of async_submit_bio
    
    The end_io callbacks passed to btrfs_wq_submit_bio
    (btrfs_submit_bio_done and btree_submit_bio_done) are effectively the
    same code, there's no point to do the indirection. Export
    btrfs_submit_bio_done and call it directly.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 0ecc13b7d6f7..4e6d34dd7caf 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -92,9 +92,6 @@ typedef	blk_status_t (extent_submit_bio_hook_t)(void *private_data, struct bio *
 typedef blk_status_t (extent_submit_bio_start_t)(void *private_data,
 		struct bio *bio, u64 bio_offset);
 
-typedef blk_status_t (extent_submit_bio_done_t)(void *private_data,
-		struct bio *bio, int mirror_num);
-
 struct extent_io_ops {
 	/*
 	 * The following callbacks must be allways defined, the function

commit b0132a3be5daf84116833542717ff5692f51640e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jun 27 16:38:24 2018 +0300

    btrfs: Rename EXTENT_BUFFER_DUMMY to EXTENT_BUFFER_UNMAPPED
    
    EXTENT_BUFFER_DUMMY is an awful name for this flag. Buffers which have
    this flag set are not in any way dummy. Rather, they are private in the
    sense that are not mapped and linked to the global buffer tree. This
    flag has subtle implications to the way free_extent_buffer works for
    example, as well as controls whether page->mapping->private_lock is held
    during extent_buffer release. Pages for an unmapped buffer cannot be
    under io, nor can they be written by a 3rd party so taking the lock is
    unnecessary.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ EXTENT_BUFFER_UNMAPPED, update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 48f1ee9ad379..0ecc13b7d6f7 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -46,7 +46,7 @@
 #define EXTENT_BUFFER_STALE 6
 #define EXTENT_BUFFER_WRITEBACK 7
 #define EXTENT_BUFFER_READ_ERR 8        /* read IO error */
-#define EXTENT_BUFFER_DUMMY 9
+#define EXTENT_BUFFER_UNMAPPED 9
 #define EXTENT_BUFFER_IN_TREE 10
 #define EXTENT_BUFFER_WRITE_ERR 11    /* write IO error */
 

commit cc5e31a4775d0d6b98139fdee51868a270bda42f
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 1 18:20:27 2018 +0100

    btrfs: switch types to int when counting eb pages
    
    The loops iterating eb pages use unsigned long, that's an overkill as
    we know that there are at most 16 pages (64k / 4k), and 4 by default
    (with nodesize 16k).
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 7a3c15b55f2b..48f1ee9ad379 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -440,7 +440,7 @@ int read_extent_buffer_pages(struct extent_io_tree *tree,
 			     int mirror_num);
 void wait_on_extent_buffer_writeback(struct extent_buffer *eb);
 
-static inline unsigned long num_extent_pages(const struct extent_buffer *eb)
+static inline int num_extent_pages(const struct extent_buffer *eb)
 {
 	return (round_up(eb->start + eb->len, PAGE_SIZE) >> PAGE_SHIFT) -
 	       (eb->start >> PAGE_SHIFT);

commit 8791d43207966f40d8ffba18c663514aca5a6f3e
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 4 17:49:31 2018 +0200

    btrfs: use round_up wrapper in num_extent_pages
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index d8382a4a7f46..7a3c15b55f2b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -442,8 +442,8 @@ void wait_on_extent_buffer_writeback(struct extent_buffer *eb);
 
 static inline unsigned long num_extent_pages(const struct extent_buffer *eb)
 {
-	return ((eb->start + eb->len + PAGE_SIZE - 1) >> PAGE_SHIFT) -
-		(eb->start >> PAGE_SHIFT);
+	return (round_up(eb->start + eb->len, PAGE_SIZE) >> PAGE_SHIFT) -
+	       (eb->start >> PAGE_SHIFT);
 }
 
 static inline void extent_buffer_get(struct extent_buffer *eb)

commit 65ad010488a5cc0f123a9924f7ad26a1b3f6a4f6
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 29 10:56:49 2018 +0200

    btrfs: pass only eb to num_extent_pages
    
    Almost all callers pass the start and len as 2 arguments but this is not
    necessary, all the information is provided by the eb. By reordering the
    calls to num_extent_pages, we don't need the local variables with
    start/len.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 0bfd4aeb822d..d8382a4a7f46 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -440,10 +440,10 @@ int read_extent_buffer_pages(struct extent_io_tree *tree,
 			     int mirror_num);
 void wait_on_extent_buffer_writeback(struct extent_buffer *eb);
 
-static inline unsigned long num_extent_pages(u64 start, u64 len)
+static inline unsigned long num_extent_pages(const struct extent_buffer *eb)
 {
-	return ((start + len + PAGE_SIZE - 1) >> PAGE_SHIFT) -
-		(start >> PAGE_SHIFT);
+	return ((eb->start + eb->len + PAGE_SIZE - 1) >> PAGE_SHIFT) -
+		(eb->start >> PAGE_SHIFT);
 }
 
 static inline void extent_buffer_get(struct extent_buffer *eb)

commit 8ae225a8a4f9054ffc6566e14aaf05dfc559743e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Apr 19 10:46:38 2018 +0300

    btrfs: Remove tree argument from extent_writepages
    
    It can be directly referenced from the passed address_space so do that.
    No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 752ad87e40d5..0bfd4aeb822d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -411,8 +411,7 @@ int extent_invalidatepage(struct extent_io_tree *tree,
 int extent_write_full_page(struct page *page, struct writeback_control *wbc);
 int extent_write_locked_range(struct inode *inode, u64 start, u64 end,
 			      int mode);
-int extent_writepages(struct extent_io_tree *tree,
-		      struct address_space *mapping,
+int extent_writepages(struct address_space *mapping,
 		      struct writeback_control *wbc);
 int btree_write_cache_pages(struct address_space *mapping,
 			    struct writeback_control *wbc);

commit 2a3ff0adc92069122a75c3e37271d7ab7ce0dc1c
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Apr 19 10:46:36 2018 +0300

    btrfs: Remove redundant tree argument from extent_readpages
    
    This function is called only from btrfs_readpage and is already passed
    the mapping. Simplify its signature by moving the code obtaining
    reference to the extent tree in the function. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 29d47383b113..752ad87e40d5 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -416,9 +416,8 @@ int extent_writepages(struct extent_io_tree *tree,
 		      struct writeback_control *wbc);
 int btree_write_cache_pages(struct address_space *mapping,
 			    struct writeback_control *wbc);
-int extent_readpages(struct extent_io_tree *tree,
-		     struct address_space *mapping,
-		     struct list_head *pages, unsigned nr_pages);
+int extent_readpages(struct address_space *mapping, struct list_head *pages,
+		     unsigned nr_pages);
 int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 		__u64 start, __u64 len);
 void set_page_extent_mapped(struct page *page);

commit 477a30ba5f8dfb3fe951ed0352277bb26a616cb8
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Apr 19 10:46:34 2018 +0300

    btrfs: Sink extent_tree arguments in try_release_extent_mapping
    
    This function already gets the page from which the two extent trees
    are referenced. Simplify its signature by moving the code getting the
    trees inside the function. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c5e80d60d71b..29d47383b113 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -270,9 +270,7 @@ typedef struct extent_map *(get_extent_t)(struct btrfs_inode *inode,
 					  int create);
 
 void extent_io_tree_init(struct extent_io_tree *tree, void *private_data);
-int try_release_extent_mapping(struct extent_map_tree *map,
-			       struct extent_io_tree *tree, struct page *page,
-			       gfp_t mask);
+int try_release_extent_mapping(struct page *page, gfp_t mask);
 int try_release_extent_buffer(struct page *page);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		     struct extent_state **cached);

commit 3b079a919a2386f7e080222b25f1cffe9c91666b
Author: Howard McLauchlan <hmclauchlan@fb.com>
Date:   Wed Apr 18 18:02:37 2018 -0700

    btrfs: remove unused le_test_bit()
    
    With commit b18253ec57c0 ("btrfs: optimize free space tree bitmap
    conversion"), there are no more callers to le_test_bit(). This patch
    removes le_test_bit().
    
    Signed-off-by: Howard McLauchlan <hmclauchlan@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index d34416c831bf..c5e80d60d71b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -79,11 +79,6 @@
 #define BITMAP_LAST_BYTE_MASK(nbits) \
 	(BYTE_MASK >> (-(nbits) & (BITS_PER_BYTE - 1)))
 
-static inline int le_test_bit(int nr, const u8 *addr)
-{
-	return 1U & (addr[BIT_BYTE(nr)] >> (nr & (BITS_PER_BYTE-1)));
-}
-
 struct extent_state;
 struct btrfs_root;
 struct btrfs_inode;

commit 6faa8f475eeaf5d89f985ad3b91b90ab0cf219e6
Author: Howard McLauchlan <hmclauchlan@fb.com>
Date:   Wed Apr 18 18:02:35 2018 -0700

    btrfs: clean up le_bitmap_{set, clear}()
    
    le_bitmap_set() is only used by free-space-tree, so move it there and
    make it static. le_bitmap_clear() is not used, so remove it.
    
    Signed-off-by: Howard McLauchlan <hmclauchlan@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a53009694b16..d34416c831bf 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -84,9 +84,6 @@ static inline int le_test_bit(int nr, const u8 *addr)
 	return 1U & (addr[BIT_BYTE(nr)] >> (nr & (BITS_PER_BYTE-1)));
 }
 
-void le_bitmap_set(u8 *map, unsigned int start, int len);
-void le_bitmap_clear(u8 *map, unsigned int start, int len);
-
 struct extent_state;
 struct btrfs_root;
 struct btrfs_inode;

commit 9888c3402c8567a977de37f61e9dd87792723064
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:16:55 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- headers
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Unify the include protection macros to match the file names.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b77d84909863..a53009694b16 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -1,6 +1,7 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-#ifndef __EXTENTIO__
-#define __EXTENTIO__
+
+#ifndef BTRFS_EXTENT_IO_H
+#define BTRFS_EXTENT_IO_H
 
 #include <linux/rbtree.h>
 #include <linux/refcount.h>
@@ -572,4 +573,5 @@ noinline u64 find_lock_delalloc_range(struct inode *inode,
 #endif
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
 					       u64 start);
+
 #endif

commit 6c553435870bf351c594437b4ba8babbdb0bb37e
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 8 13:47:33 2018 +0100

    btrfs: remove unused parameters from extent_submit_bio_done_t
    
    Remove parameters not used by any of the callbacks.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6596b697b827..b77d84909863 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -100,8 +100,7 @@ typedef blk_status_t (extent_submit_bio_start_t)(void *private_data,
 		struct bio *bio, u64 bio_offset);
 
 typedef blk_status_t (extent_submit_bio_done_t)(void *private_data,
-		struct bio *bio, int mirror_num, unsigned long bio_flags,
-		u64 bio_offset);
+		struct bio *bio, int mirror_num);
 
 struct extent_io_ops {
 	/*

commit d0779291b1e9666aa4aac46ffd8062e3c3b0f2ab
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 8 13:47:33 2018 +0100

    btrfs: remove unused parameters from extent_submit_bio_start_t
    
    Remove parameters not used by any of the callbacks.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index bbfae2abfb39..6596b697b827 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -97,8 +97,7 @@ typedef	blk_status_t (extent_submit_bio_hook_t)(void *private_data, struct bio *
 				       u64 bio_offset);
 
 typedef blk_status_t (extent_submit_bio_start_t)(void *private_data,
-		struct bio *bio, int mirror_num, unsigned long bio_flags,
-		u64 bio_offset);
+		struct bio *bio, u64 bio_offset);
 
 typedef blk_status_t (extent_submit_bio_done_t)(void *private_data,
 		struct bio *bio, int mirror_num, unsigned long bio_flags,

commit a758781d4b76c38374f155e2f2cf902e13b9e50e
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 23 03:05:23 2017 +0200

    btrfs: separate types for submit_bio_start and submit_bio_done
    
    The callbacks make use of different parameters that are passed to the
    other type unnecessarily. This patch adds separate types for each and
    the unused parameters will be removed.
    
    The type extent_submit_bio_hook_t keeps all parameters and can be used
    where the start/done types are not appropriate.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c82a5842d524..bbfae2abfb39 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -95,6 +95,15 @@ struct io_failure_record;
 typedef	blk_status_t (extent_submit_bio_hook_t)(void *private_data, struct bio *bio,
 				       int mirror_num, unsigned long bio_flags,
 				       u64 bio_offset);
+
+typedef blk_status_t (extent_submit_bio_start_t)(void *private_data,
+		struct bio *bio, int mirror_num, unsigned long bio_flags,
+		u64 bio_offset);
+
+typedef blk_status_t (extent_submit_bio_done_t)(void *private_data,
+		struct bio *bio, int mirror_num, unsigned long bio_flags,
+		u64 bio_offset);
+
 struct extent_io_ops {
 	/*
 	 * The following callbacks must be allways defined, the function

commit ab0d09361662b7593fe166d27ad49b8852a2ef3e
Author: David Sterba <dsterba@suse.com>
Date:   Tue Feb 27 15:48:54 2018 +0100

    btrfs: drop extern from function declarations
    
    Extern for functions does not make any difference, there are only a few
    so let's remove them before it's too late.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e359c5d4305c..c82a5842d524 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -83,8 +83,8 @@ static inline int le_test_bit(int nr, const u8 *addr)
 	return 1U & (addr[BIT_BYTE(nr)] >> (nr & (BITS_PER_BYTE-1)));
 }
 
-extern void le_bitmap_set(u8 *map, unsigned int start, int len);
-extern void le_bitmap_clear(u8 *map, unsigned int start, int len);
+void le_bitmap_set(u8 *map, unsigned int start, int len);
+void le_bitmap_clear(u8 *map, unsigned int start, int len);
 
 struct extent_state;
 struct btrfs_root;

commit e67c718b5b9a306bde7e966be7b4ca48fa063d73
Author: David Sterba <dsterba@suse.com>
Date:   Mon Feb 19 17:24:18 2018 +0100

    btrfs: add more __cold annotations
    
    The __cold functions are placed to a special section, as they're
    expected to be called rarely. This could help i-cache prefetches or help
    compiler to decide which branches are more/less likely to be taken
    without any other annotations needed.
    
    Though we can't add more __exit annotations, it's still possible to add
    __cold (that's also added with __exit). That way the following function
    categories are tagged:
    
    - printf wrappers, error messages
    - exit helpers
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index da9be2fb0502..e359c5d4305c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -286,7 +286,7 @@ int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent, int mirror_num);
 int __init extent_io_init(void);
-void extent_io_exit(void);
+void __cold extent_io_exit(void);
 
 u64 count_range_bits(struct extent_io_tree *tree,
 		     u64 *start, u64 search_end,

commit ba020491c8d08ec500ce1ddfd0715168a0ab9241
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Tue Feb 13 12:35:44 2018 +0800

    btrfs: extent_buffer_uptodate() make it static and inline
    
    extent_buffer_uptodate() is a trivial wrapper around test_bit() and
    nothing else. So make it static and inline, save on code space and call
    indirection.
    
    Before:
       text    data     bss     dec     hex filename
    1131257   82898   18992 1233147  12d0fb fs/btrfs/btrfs.ko
    
    After:
       text    data     bss     dec     hex filename
    1131090   82898   18992 1232980  12d054 fs/btrfs/btrfs.ko
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a7a850abd600..da9be2fb0502 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -455,6 +455,11 @@ static inline void extent_buffer_get(struct extent_buffer *eb)
 	atomic_inc(&eb->refs);
 }
 
+static inline int extent_buffer_uptodate(struct extent_buffer *eb)
+{
+	return test_bit(EXTENT_BUFFER_UPTODATE, &eb->bflags);
+}
+
 int memcmp_extent_buffer(const struct extent_buffer *eb, const void *ptrv,
 			 unsigned long start, unsigned long len);
 void read_extent_buffer(const struct extent_buffer *eb, void *dst,
@@ -489,7 +494,6 @@ void clear_extent_buffer_dirty(struct extent_buffer *eb);
 int set_extent_buffer_dirty(struct extent_buffer *eb);
 void set_extent_buffer_uptodate(struct extent_buffer *eb);
 void clear_extent_buffer_uptodate(struct extent_buffer *eb);
-int extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_under_io(struct extent_buffer *eb);
 int map_private_extent_buffer(const struct extent_buffer *eb,
 			      unsigned long offset, unsigned long min_len,

commit 31466f3ed710e5761077190809e694f55aed5deb
Merge: 6787dc24b72b 3acbcbfc8f06
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 29 14:04:23 2018 -0800

    Merge tag 'for-4.16-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "Features or user visible changes:
    
       - fallocate: implement zero range mode
    
       - avoid losing data raid profile when deleting a device
    
       - tree item checker: more checks for directory items and xattrs
    
      Notable fixes:
    
       - raid56 recovery: don't use cached stripes, that could be
         potentially changed and a later RMW or recovery would lead to
         corruptions or failures
    
       - let raid56 try harder to rebuild damaged data, reading from all
         stripes if necessary
    
       - fix scrub to repair raid56 in a similar way as in the case above
    
      Other:
    
       - cleanups: device freeing, removed some call indirections, redundant
         bio_put/_get, unused parameters, refactorings and renames
    
       - RCU list traversal fixups
    
       - simplify mount callchain, remove recursing back when mounting a
         subvolume
    
       - plug for fsync, may improve bio merging on multiple devices
    
       - compression heurisic: replace heap sort with radix sort, gains some
         performance
    
       - add extent map selftests, buffered write vs dio"
    
    * tag 'for-4.16-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (155 commits)
      btrfs: drop devid as device_list_add() arg
      btrfs: get device pointer from device_list_add()
      btrfs: set the total_devices in device_list_add()
      btrfs: move pr_info into device_list_add
      btrfs: make btrfs_free_stale_devices() to match the path
      btrfs: rename btrfs_free_stale_devices() arg to skip_dev
      btrfs: make btrfs_free_stale_devices() argument optional
      btrfs: make btrfs_free_stale_device() to iterate all stales
      btrfs: no need to check for btrfs_fs_devices::seeding
      btrfs: Use IS_ALIGNED in btrfs_truncate_block instead of opencoding it
      Btrfs: noinline merge_extent_mapping
      Btrfs: add WARN_ONCE to detect unexpected error from merge_extent_mapping
      Btrfs: extent map selftest: dio write vs dio read
      Btrfs: extent map selftest: buffered write vs dio read
      Btrfs: add extent map selftests
      Btrfs: move extent map specific code to extent_map.c
      Btrfs: add helper for em merge logic
      Btrfs: fix unexpected EEXIST from btrfs_get_extent
      Btrfs: fix incorrect block_len in merge_extent_mapping
      btrfs: Remove unused readahead spinlock
      ...

commit e43bbe5e16d87b40f3b382b3a43b0142d6d1193d
Author: David Sterba <dsterba@suse.com>
Date:   Tue Dec 12 21:43:52 2017 +0100

    btrfs: sink unlock_extent parameter gfp_flags
    
    All callers pass either GFP_NOFS or GFP_KERNEL now, so we can sink the
    parameter to the function, though we lose some of the slightly better
    semantics of GFP_KERNEL in some places, it's worth cleaning up the
    callchains.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 978351e8e8dc..72e5af2965a8 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -312,10 +312,10 @@ static inline int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end)
 }
 
 static inline int unlock_extent_cached(struct extent_io_tree *tree, u64 start,
-		u64 end, struct extent_state **cached, gfp_t mask)
+		u64 end, struct extent_state **cached)
 {
 	return __clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, cached,
-				mask, NULL);
+				GFP_NOFS, NULL);
 }
 
 static inline int unlock_extent_cached_atomic(struct extent_io_tree *tree,

commit d810a4be1a625aafb2602c56c1256047f1e27380
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 7 18:52:54 2017 +0100

    btrfs: add separate helper for unlock_extent_cached with GFP_ATOMIC
    
    There's only one instance where we pass different gfp mask to
    unlock_extent_cached. Add a separate helper for that and then we can
    drop the gfp parameter from unlock_extent_cached.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index db2558b0cad4..978351e8e8dc 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -318,6 +318,13 @@ static inline int unlock_extent_cached(struct extent_io_tree *tree, u64 start,
 				mask, NULL);
 }
 
+static inline int unlock_extent_cached_atomic(struct extent_io_tree *tree,
+		u64 start, u64 end, struct extent_state **cached)
+{
+	return __clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, cached,
+				GFP_ATOMIC, NULL);
+}
+
 static inline int clear_extent_bits(struct extent_io_tree *tree, u64 start,
 		u64 end, unsigned bits)
 {

commit 0a9b0e5351818d43ac013c00a1474cc3601fc5bb
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Fri Dec 8 15:55:59 2017 +0200

    btrfs: sink extent_write_full_page tree argument
    
    The tree argument passed to extent_write_full_page is referenced from
    the page being passed to the same function. Since we already have
    enough information to get the reference, remove the function parameter.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f2cbabb2306a..db2558b0cad4 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -403,8 +403,7 @@ int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
 			  struct extent_state **cached_state);
 int extent_invalidatepage(struct extent_io_tree *tree,
 			  struct page *page, unsigned long offset);
-int extent_write_full_page(struct extent_io_tree *tree, struct page *page,
-			  struct writeback_control *wbc);
+int extent_write_full_page(struct page *page, struct writeback_control *wbc);
 int extent_write_locked_range(struct inode *inode, u64 start, u64 end,
 			      int mode);
 int extent_writepages(struct extent_io_tree *tree,

commit 5e3ee23648a20dfaf72eeb88f884aae25ea7d8fb
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Fri Dec 8 15:55:58 2017 +0200

    btrfs: sink extent_write_locked_range tree parameter
    
    This function is called only from submit_compressed_extents and the
    io tree being passed is always that of the inode. But we are also
    passing the inode, so just move getting the io tree pointer in
    extent_write_locked_range to simplify the signature.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c28f5ef88f42..f2cbabb2306a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -405,8 +405,8 @@ int extent_invalidatepage(struct extent_io_tree *tree,
 			  struct page *page, unsigned long offset);
 int extent_write_full_page(struct extent_io_tree *tree, struct page *page,
 			  struct writeback_control *wbc);
-int extent_write_locked_range(struct extent_io_tree *tree, struct inode *inode,
-			      u64 start, u64 end, int mode);
+int extent_write_locked_range(struct inode *inode, u64 start, u64 end,
+			      int mode);
 int extent_writepages(struct extent_io_tree *tree,
 		      struct address_space *mapping,
 		      struct writeback_control *wbc);

commit 6af49dbde9532c95f53d2c45fe9cc0012226c5e7
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 23 04:09:57 2017 +0200

    btrfs: sink get_extent parameter to read_extent_buffer_pages
    
    All callers pass btree_get_extent, which needs to be exported.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6cf4a0e5b0ea..c28f5ef88f42 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -435,7 +435,7 @@ void free_extent_buffer_stale(struct extent_buffer *eb);
 #define WAIT_PAGE_LOCK	2
 int read_extent_buffer_pages(struct extent_io_tree *tree,
 			     struct extent_buffer *eb, int wait,
-			     get_extent_t *get_extent, int mirror_num);
+			     int mirror_num);
 void wait_on_extent_buffer_writeback(struct extent_buffer *eb);
 
 static inline unsigned long num_extent_pages(u64 start, u64 len)

commit 0932584b66e97aea91eb8c0b610e1d1083951b32
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 23 04:09:57 2017 +0200

    btrfs: sink get_extent parameter to extent_readpages
    
    There's only one caller that passes btrfs_get_extent.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index afc169d04b22..6cf4a0e5b0ea 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -414,8 +414,7 @@ int btree_write_cache_pages(struct address_space *mapping,
 			    struct writeback_control *wbc);
 int extent_readpages(struct extent_io_tree *tree,
 		     struct address_space *mapping,
-		     struct list_head *pages, unsigned nr_pages,
-		     get_extent_t get_extent);
+		     struct list_head *pages, unsigned nr_pages);
 int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 		__u64 start, __u64 len);
 void set_page_extent_mapped(struct page *page);

commit 2135fb9bb4b8d05d288d994c4f9f8077ce90d890
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 23 04:09:57 2017 +0200

    btrfs: sink get_extent parameter to extent_fiemap
    
    All callers pass btrfs_get_extent_fiemap and we don't expect anything
    else in the context of extent_fiemap.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index abe4feea1539..afc169d04b22 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -417,7 +417,7 @@ int extent_readpages(struct extent_io_tree *tree,
 		     struct list_head *pages, unsigned nr_pages,
 		     get_extent_t get_extent);
 int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
-		__u64 start, __u64 len, get_extent_t *get_extent);
+		__u64 start, __u64 len);
 void set_page_extent_mapped(struct page *page);
 
 struct extent_buffer *alloc_extent_buffer(struct btrfs_fs_info *fs_info,

commit deac642d7e0fd83efd3372c4093fe60ac7436db6
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 23 03:47:28 2017 +0200

    btrfs: sink get_extent parameter to extent_write_full_page
    
    There's only one caller.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b67fc0153b73..abe4feea1539 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -404,7 +404,6 @@ int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
 int extent_invalidatepage(struct extent_io_tree *tree,
 			  struct page *page, unsigned long offset);
 int extent_write_full_page(struct extent_io_tree *tree, struct page *page,
-			  get_extent_t *get_extent,
 			  struct writeback_control *wbc);
 int extent_write_locked_range(struct extent_io_tree *tree, struct inode *inode,
 			      u64 start, u64 end, int mode);

commit 916b929831a92a2a432274cd264311893f22a46d
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 23 03:47:28 2017 +0200

    btrfs: sink get_extent parameter to extent_write_locked_range
    
    There's only one caller.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e07f9e1c34e8..b67fc0153b73 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -407,8 +407,7 @@ int extent_write_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent,
 			  struct writeback_control *wbc);
 int extent_write_locked_range(struct extent_io_tree *tree, struct inode *inode,
-			      u64 start, u64 end, get_extent_t *get_extent,
-			      int mode);
+			      u64 start, u64 end, int mode);
 int extent_writepages(struct extent_io_tree *tree,
 		      struct address_space *mapping,
 		      struct writeback_control *wbc);

commit 433175992c1775db6cbc7c92294345408a333bee
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 23 03:46:07 2017 +0200

    btrfs: sink get_extent parameter to extent_writepages
    
    There's only one caller.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 9f6a5133ce8a..e07f9e1c34e8 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -411,7 +411,6 @@ int extent_write_locked_range(struct extent_io_tree *tree, struct inode *inode,
 			      int mode);
 int extent_writepages(struct extent_io_tree *tree,
 		      struct address_space *mapping,
-		      get_extent_t *get_extent,
 		      struct writeback_control *wbc);
 int btree_write_cache_pages(struct address_space *mapping,
 			    struct writeback_control *wbc);

commit f08dc36f781af622be5398ac3ab2ec9c3749889d
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 31 17:02:39 2017 +0100

    btrfs: sink gfp parameter to clear_extent_uptodate
    
    There's only one callsite with GFP_NOFS.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b679309545d8..9f6a5133ce8a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -342,10 +342,10 @@ static inline int set_extent_bits(struct extent_io_tree *tree, u64 start,
 }
 
 static inline int clear_extent_uptodate(struct extent_io_tree *tree, u64 start,
-		u64 end, struct extent_state **cached_state, gfp_t mask)
+		u64 end, struct extent_state **cached_state)
 {
 	return __clear_extent_bit(tree, start, end, EXTENT_UPTODATE, 0, 0,
-				cached_state, mask, NULL);
+				cached_state, GFP_NOFS, NULL);
 }
 
 static inline int set_extent_dirty(struct extent_io_tree *tree, u64 start,

commit ae0f162534e98afccc7d055cfaa3d3e920a928f0
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 31 16:37:52 2017 +0100

    btrfs: sink gfp parameter to clear_extent_bit
    
    All callers use GFP_NOFS, we don't have to pass it as an argument. The
    built-in tests pass GFP_KERNEL, but they run only at module load time
    and NOFS works there as well.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 2cdfc64a1356..b679309545d8 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -300,7 +300,7 @@ int clear_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		unsigned bits, struct extent_changeset *changeset);
 int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		     unsigned bits, int wake, int delete,
-		     struct extent_state **cached, gfp_t mask);
+		     struct extent_state **cached);
 int __clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		     unsigned bits, int wake, int delete,
 		     struct extent_state **cached, gfp_t mask,
@@ -308,8 +308,7 @@ int __clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 
 static inline int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end)
 {
-	return clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, NULL,
-				GFP_NOFS);
+	return clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, NULL);
 }
 
 static inline int unlock_extent_cached(struct extent_io_tree *tree, u64 start,
@@ -327,8 +326,7 @@ static inline int clear_extent_bits(struct extent_io_tree *tree, u64 start,
 	if (bits & EXTENT_LOCKED)
 		wake = 1;
 
-	return clear_extent_bit(tree, start, end, bits, wake, 0, NULL,
-			GFP_NOFS);
+	return clear_extent_bit(tree, start, end, bits, wake, 0, NULL);
 }
 
 int set_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
@@ -362,7 +360,7 @@ static inline int clear_extent_dirty(struct extent_io_tree *tree, u64 start,
 {
 	return clear_extent_bit(tree, start, end,
 				EXTENT_DIRTY | EXTENT_DELALLOC |
-				EXTENT_DO_ACCOUNTING, 0, 0, NULL, GFP_NOFS);
+				EXTENT_DO_ACCOUNTING, 0, 0, NULL);
 }
 
 int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,

commit 66b0c887bbf61555fde648587644485388dddb78
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 31 16:30:47 2017 +0100

    btrfs: prepare to drop gfp mask parameter from clear_extent_bit
    
    Use __clear_extent_bit directly in case we want to pass unknown
    gfp flags. Otherwise all clear_extent_bit callers use GFP_NOFS, so we
    can sink them to the function and reduce argument count, at the cost
    that __clear_extent_bit has to be exported.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 93dcae0c3183..2cdfc64a1356 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -301,6 +301,10 @@ int clear_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		     unsigned bits, int wake, int delete,
 		     struct extent_state **cached, gfp_t mask);
+int __clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
+		     unsigned bits, int wake, int delete,
+		     struct extent_state **cached, gfp_t mask,
+		     struct extent_changeset *changeset);
 
 static inline int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end)
 {
@@ -311,8 +315,8 @@ static inline int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end)
 static inline int unlock_extent_cached(struct extent_io_tree *tree, u64 start,
 		u64 end, struct extent_state **cached, gfp_t mask)
 {
-	return clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, cached,
-				mask);
+	return __clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, cached,
+				mask, NULL);
 }
 
 static inline int clear_extent_bits(struct extent_io_tree *tree, u64 start,
@@ -342,8 +346,8 @@ static inline int set_extent_bits(struct extent_io_tree *tree, u64 start,
 static inline int clear_extent_uptodate(struct extent_io_tree *tree, u64 start,
 		u64 end, struct extent_state **cached_state, gfp_t mask)
 {
-	return clear_extent_bit(tree, start, end, EXTENT_UPTODATE, 0, 0,
-				cached_state, mask);
+	return __clear_extent_bit(tree, start, end, EXTENT_UPTODATE, 0, 0,
+				cached_state, mask, NULL);
 }
 
 static inline int set_extent_dirty(struct extent_io_tree *tree, u64 start,

commit a0b60d725e54f1caba4f5dc0dfef68040bcf9a8e
Author: Ming Lei <ming.lei@redhat.com>
Date:   Mon Dec 18 20:22:11 2017 +0800

    btrfs: avoid access to .bi_vcnt directly
    
    BTRFS uses bio->bi_vcnt to figure out page numbers, this approach is no
    longer valid once we start enabling multipage bvecs.
    correct once we start to enable multipage bvec.
    
    Use bio_nr_pages() to do that instead.
    
    Cc: Chris Mason <clm@fb.com>
    Cc: Josef Bacik <jbacik@fb.com>
    Cc: David Sterba <dsterba@suse.com>
    Cc: linux-btrfs@vger.kernel.org
    Acked-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 93dcae0c3183..20854d63c75b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -540,7 +540,7 @@ void btrfs_free_io_failure_record(struct btrfs_inode *inode, u64 start,
 		u64 end);
 int btrfs_get_io_failure_record(struct inode *inode, u64 start, u64 end,
 				struct io_failure_record **failrec_ret);
-bool btrfs_check_repairable(struct inode *inode, struct bio *failed_bio,
+bool btrfs_check_repairable(struct inode *inode, unsigned failed_bio_pages,
 			    struct io_failure_record *failrec, int fail_mirror);
 struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
 				    struct io_failure_record *failrec,

commit 26cd94744e142dd5d5a21e2c1e31bacc120b2d74
Merge: 198e0c0c61b6 ea37d5998b50
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 29 14:26:50 2017 -0800

    Merge tag 'for-4.15-rc2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "We've collected some fixes in since the pre-merge window freeze.
    
      There's technically only one regression fix for 4.15, but the rest
      seems important and candidates for stable.
    
       - fix missing flush bio puts in error cases (is serious, but rarely
         happens)
    
       - fix reporting stat::st_blocks for buffered append writes
    
       - fix space cache invalidation
    
       - fix out of bound memory access when setting zlib level
    
       - fix potential memory corruption when fsync fails in the middle
    
       - fix crash in integrity checker
    
       - incremetnal send fix, path mixup for certain unlink/rename
         combination
    
       - pass flags to writeback so compressed writes can be throttled
         properly
    
       - error handling fixes"
    
    * tag 'for-4.15-rc2-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      Btrfs: incremental send, fix wrong unlink path after renaming file
      btrfs: tree-checker: Fix false panic for sanity test
      Btrfs: fix list_add corruption and soft lockups in fsync
      btrfs: Fix wild memory access in compression level parser
      btrfs: fix deadlock when writing out space cache
      btrfs: clear space cache inode generation always
      Btrfs: fix reported number of inode blocks after buffered append writes
      Btrfs: move definition of the function btrfs_find_new_delalloc_bytes
      Btrfs: bail out gracefully rather than BUG_ON
      btrfs: dev_alloc_list is not protected by RCU, use normal list_del
      btrfs: add missing device::flush_bio puts
      btrfs: Fix transaction abort during failure in btrfs_rm_dev_item
      Btrfs: add write_flags for compression bio

commit e3b8a4858566a6cc25422fbfdfdd760b13b79280
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Nov 4 00:16:59 2017 +0000

    Btrfs: fix reported number of inode blocks after buffered append writes
    
    The patch from commit a7e3b975a0f9 ("Btrfs: fix reported number of inode
    blocks") introduced a regression where if we do a buffered write starting
    at position equal to or greater than the file's size and then stat(2) the
    file before writeback is triggered, the number of used blocks does not
    change (unless there's a prealloc/unwritten extent). Example:
    
      $ xfs_io -f -c "pwrite -S 0xab 0 64K" foobar
      $ du -h foobar
      0     foobar
      $ sync
      $ du -h foobar
      64K   foobar
    
    The first version of that patch didn't had this regression and the second
    version, which was the one committed, was made only to address some
    performance regression detected by the intel test robots using fs_mark.
    
    This fixes the regression by setting the new delaloc bit in the range, and
    doing it at btrfs_dirty_pages() while setting the regular dealloc bit as
    well, so that this way we set both bits at once avoiding navigation of the
    inode's io tree twice. Doing it at btrfs_dirty_pages() is also the most
    meaninful place, as we should set the new dellaloc bit when if we set the
    delalloc bit, which happens only if we copied bytes into the pages at
    __btrfs_buffered_write().
    
    This was making some of LTP's du tests fail, which can be quickly run
    using a command line like the following:
    
      $ ./runltp -q -p -l /ltp.log -f commands -s du -d /mnt
    
    Fixes: a7e3b975a0f9 ("Btrfs: fix reported number of inode blocks")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index d8b27af7101e..2ef824b58e3c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -365,10 +365,11 @@ int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		       struct extent_state **cached_state);
 
 static inline int set_extent_delalloc(struct extent_io_tree *tree, u64 start,
-		u64 end, struct extent_state **cached_state)
+				      u64 end, unsigned int extra_bits,
+				      struct extent_state **cached_state)
 {
 	return set_extent_bit(tree, start, end,
-			      EXTENT_DELALLOC | EXTENT_UPTODATE,
+			      EXTENT_DELALLOC | EXTENT_UPTODATE | extra_bits,
 			      NULL, cached_state, GFP_NOFS);
 }
 

commit f82b735936ffd58b6711cf1f1054616517d8ffcd
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Oct 23 23:18:16 2017 -0600

    Btrfs: add write_flags for compression bio
    
    Compression code path has only flaged bios with REQ_OP_WRITE no matter
    where the bios come from, but it could be a sync write if fsync starts
    this writeback or a normal writeback write if wb kthread starts a
    periodic writeback.
    
    It breaks the rule that sync writes and writeback writes need to be
    differentiated from each other, because from the POV of block layer,
    all bios need to be recognized by these flags in order to do some
    management, e.g. throttlling.
    
    This passes writeback_control to compression write path so that it can
    send bios with proper flags to block layer.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 861dacb371c7..d8b27af7101e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -115,7 +115,8 @@ struct extent_io_ops {
 	 */
 	int (*fill_delalloc)(void *private_data, struct page *locked_page,
 			     u64 start, u64 end, int *page_started,
-			     unsigned long *nr_written);
+			     unsigned long *nr_written,
+			     struct writeback_control *wbc);
 
 	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,

commit 5cea7647e64657138138a3794ae172ee0fc175da
Merge: 808eb24e0e09 d28e649a5c58
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 14 13:35:29 2017 -0800

    Merge branch 'for-4.15' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "There are some new user features and the usual load of invisible
      enhancements or cleanups.
    
      New features:
    
       - extend mount options to specify zlib compression level, -o
         compress=zlib:9
    
       - v2 of ioctl "extent to inode mapping", addressing a usecase where
         we want to retrieve more but inaccurate results and do the
         postprocessing in userspace, aiding defragmentation or
         deduplication tools
    
       - populate compression heuristics logic, do data sampling and try to
         guess compressibility by: looking for repeated patterns, counting
         unique byte values and distribution, calculating Shannon entropy;
         this will need more benchmarking and possibly fine tuning, but the
         base should be good enough
    
       - enable indexing for btrfs as lower filesystem in overlayfs
    
       - speedup page cache readahead during send on large files
    
      Internal enhancements:
    
       - more sanity checks of b-tree items when reading them from disk
    
       - more EINVAL/EUCLEAN fixups, missing BLK_STS_* conversion, other
         errno or error handling fixes
    
       - remove some homegrown IO-related logic, that's been obsoleted by
         core block layer changes (batching, plug/unplug, own counters)
    
       - add ref-verify, optional debugging feature to verify extent
         reference accounting
    
       - simplify code handling outstanding extents, make it more clear
         where and how the accounting is done
    
       - make delalloc reservations per-inode, simplify the code and make
         the logic more straightforward
    
       - extensive cleanup of delayed refs code
    
      Notable fixes:
    
       - fix send ioctl on 32bit with 64bit kernel"
    
    * 'for-4.15' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (102 commits)
      btrfs: Fix bug for misused dev_t when lookup in dev state hash table.
      Btrfs: heuristic: add Shannon entropy calculation
      Btrfs: heuristic: add byte core set calculation
      Btrfs: heuristic: add byte set calculation
      Btrfs: heuristic: add detection of repeated data patterns
      Btrfs: heuristic: implement sampling logic
      Btrfs: heuristic: add bucket and sample counters and other defines
      Btrfs: compression: separate heuristic/compression workspaces
      btrfs: move btrfs_truncate_block out of trans handle
      btrfs: don't call btrfs_start_delalloc_roots in flushoncommit
      btrfs: track refs in a rb_tree instead of a list
      btrfs: add a comp_refs() helper
      btrfs: switch args for comp_*_refs
      btrfs: make the delalloc block rsv per inode
      btrfs: add tracepoints for outstanding extents mods
      Btrfs: rework outstanding_extents
      btrfs: increase output size for LOGICAL_INO_V2 ioctl
      btrfs: add a flags argument to LOGICAL_INO and call it LOGICAL_INO_V2
      btrfs: add a flag to iterate_inodes_from_logical to find all extent refs for uncompressed extents
      btrfs: send: remove unused code
      ...

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index faffa28ba707..e5535bbe6953 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef __EXTENTIO__
 #define __EXTENTIO__
 

commit 18fdc67900c5bfd1eeb41cfa50ea6f2eb7266f73
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Sep 13 12:18:22 2017 -0600

    Btrfs: remove bio_flags which indicates a meta block of log-tree
    
    Since both committing transaction and writing log-tree are doing
    plugging on metadata IO, we can unify to use %sync_writers to benefit
    both cases, instead of checking bio_flags while writing meta blocks of
    log-tree.
    
    We can remove this bio_flags because in order to write dirty blocks,
    log tree also uses btrfs_write_marked_extents(), inside which we
    have enabled %sync_writers, therefore, every write goes in a
    synchronous way, so does checksuming.
    
    Please also note that, bio_flags is applied per-context while
    %sync_writers is applied per-inode, so this might incur some overhead, ie.
    
    1) while log tree is flushing its dirty blocks via
       btrfs_write_marked_extents(), in which %sync_writers is increased
       by one.
    
    2) in the meantime, some writeback operations may happen upon btrfs's
       metadata inode, so these writes go synchronously, too.
    
    However, AFAICS, the overhead is not a big one while the win is that
    we unify the two places that needs synchronous way and remove a
    special hack/flag.
    
    This removes the bio_flags related stuff for writing log-tree.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index faffa28ba707..861dacb371c7 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -33,7 +33,6 @@
  * type for this bio
  */
 #define EXTENT_BIO_COMPRESSED 1
-#define EXTENT_BIO_TREE_LOG 2
 #define EXTENT_BIO_FLAG_SHIFT 16
 
 /* these are bit numbers for test/set bit */

commit 1cbb1f454e5321e47fc1e6b233066c7ccc979d15
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 28 21:56:53 2017 -0600

    btrfs: struct-funcs, constify readers
    
    We have reader helpers for most of the on-disk structures that use
    an extent_buffer and pointer as offset into the buffer that are
    read-only.  We should mark them as const and, in turn, allow consumers
    of these interfaces to mark the buffers const as well.
    
    No impact on code, but serves as documentation that a buffer is intended
    not to be modified.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4f030912f3ef..faffa28ba707 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -449,14 +449,13 @@ static inline void extent_buffer_get(struct extent_buffer *eb)
 	atomic_inc(&eb->refs);
 }
 
-int memcmp_extent_buffer(struct extent_buffer *eb, const void *ptrv,
-			  unsigned long start,
-			  unsigned long len);
-void read_extent_buffer(struct extent_buffer *eb, void *dst,
+int memcmp_extent_buffer(const struct extent_buffer *eb, const void *ptrv,
+			 unsigned long start, unsigned long len);
+void read_extent_buffer(const struct extent_buffer *eb, void *dst,
 			unsigned long start,
 			unsigned long len);
-int read_extent_buffer_to_user(struct extent_buffer *eb, void __user *dst,
-			       unsigned long start,
+int read_extent_buffer_to_user(const struct extent_buffer *eb,
+			       void __user *dst, unsigned long start,
 			       unsigned long len);
 void write_extent_buffer_fsid(struct extent_buffer *eb, const void *src);
 void write_extent_buffer_chunk_tree_uuid(struct extent_buffer *eb,
@@ -486,10 +485,10 @@ void set_extent_buffer_uptodate(struct extent_buffer *eb);
 void clear_extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_under_io(struct extent_buffer *eb);
-int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
-		      unsigned long min_len, char **map,
-		      unsigned long *map_start,
-		      unsigned long *map_len);
+int map_private_extent_buffer(const struct extent_buffer *eb,
+			      unsigned long offset, unsigned long min_len,
+			      char **map, unsigned long *map_start,
+			      unsigned long *map_len);
 void extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,

commit bc243704fb3c97f3631994bbe543782a09482afb
Merge: 0ffff118b16b c3cfb6563075
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 14 22:55:52 2017 -0700

    Merge branch 'for-4.13-part2' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "We've identified and fixed a silent corruption (introduced by code in
      the first pull), a fixup after the blk_status_t merge and two fixes to
      incremental send that Filipe has been hunting for some time"
    
    * 'for-4.13-part2' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      Btrfs: fix unexpected return value of bio_readpage_error
      btrfs: btrfs_create_repair_bio never fails, skip error handling
      btrfs: cloned bios must not be iterated by bio_for_each_segment_all
      Btrfs: fix write corruption due to bio cloning on raid5/6
      Btrfs: incremental send, fix invalid memory access
      Btrfs: incremental send, fix invalid path for link commands

commit c3cfb656307583ddfea45375c10183737593c195
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Jul 13 15:00:50 2017 -0700

    Btrfs: fix unexpected return value of bio_readpage_error
    
    With blk_status_t conversion (that are now present in master),
    bio_readpage_error() may return 1 as now ->submit_bio_hook() may not set
    %ret if it runs without problems.
    
    This fixes that unexpected return value by changing
    btrfs_check_repairable() to return a bool instead of updating %ret, and
    patch is applicable to both codebases with and without blk_status_t.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index aeafdb35d90b..cfdbb9efaaed 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -539,8 +539,8 @@ void btrfs_free_io_failure_record(struct btrfs_inode *inode, u64 start,
 		u64 end);
 int btrfs_get_io_failure_record(struct inode *inode, u64 start, u64 end,
 				struct io_failure_record **failrec_ret);
-int btrfs_check_repairable(struct inode *inode, struct bio *failed_bio,
-			   struct io_failure_record *failrec, int fail_mirror);
+bool btrfs_check_repairable(struct inode *inode, struct bio *failed_bio,
+			    struct io_failure_record *failrec, int fail_mirror);
 struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
 				    struct io_failure_record *failrec,
 				    struct page *page, int pg_offset, int icsum,

commit 8c27cb3566762613a23c080e3db7d0501af9a787
Merge: 7114f51fcb97 848c23b78faf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 5 16:41:23 2017 -0700

    Merge branch 'for-4.13-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "The core updates improve error handling (mostly related to bios), with
      the usual incremental work on the GFP_NOFS (mis)use removal,
      refactoring or cleanups. Except the two top patches, all have been in
      for-next for an extensive amount of time.
    
      User visible changes:
    
       - statx support
    
       - quota override tunable
    
       - improved compression thresholds
    
       - obsoleted mount option alloc_start
    
      Core updates:
    
       - bio-related updates:
           - faster bio cloning
           - no allocation failures
           - preallocated flush bios
    
       - more kvzalloc use, memalloc_nofs protections, GFP_NOFS updates
    
       - prep work for btree_inode removal
    
       - dir-item validation
    
       - qgoup fixes and updates
    
       - cleanups:
           - removed unused struct members, unused code, refactoring
           - argument refactoring (fs_info/root, caller -> callee sink)
           - SEARCH_TREE ioctl docs"
    
    * 'for-4.13-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (115 commits)
      btrfs: Remove false alert when fiemap range is smaller than on-disk extent
      btrfs: Don't clear SGID when inheriting ACLs
      btrfs: fix integer overflow in calc_reclaim_items_nr
      btrfs: scrub: fix target device intialization while setting up scrub context
      btrfs: qgroup: Fix qgroup reserved space underflow by only freeing reserved ranges
      btrfs: qgroup: Introduce extent changeset for qgroup reserve functions
      btrfs: qgroup: Fix qgroup reserved space underflow caused by buffered write and quotas being enabled
      btrfs: qgroup: Return actually freed bytes for qgroup release or free data
      btrfs: qgroup: Cleanup btrfs_qgroup_prepare_account_extents function
      btrfs: qgroup: Add quick exit for non-fs extents
      Btrfs: rework delayed ref total_bytes_pinned accounting
      Btrfs: return old and new total ref mods when adding delayed refs
      Btrfs: always account pinned bytes when dropping a tree block ref
      Btrfs: update total_bytes_pinned when pinning down extents
      Btrfs: make BUG_ON() in add_pinned_bytes() an ASSERT()
      Btrfs: make add_pinned_bytes() take an s64 num_bytes instead of u64
      btrfs: fix validation of XATTR_ITEM dir items
      btrfs: Verify dir_item in iterate_object_props
      btrfs: Check name_len before in btrfs_del_root_ref
      btrfs: Check name_len before reading btrfs_get_name
      ...

commit 364ecf3651e0862152c8b340d7cb3021dc0122c7
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Feb 27 15:10:38 2017 +0800

    btrfs: qgroup: Introduce extent changeset for qgroup reserve functions
    
    Introduce a new parameter, struct extent_changeset for
    btrfs_qgroup_reserved_data() and its callers.
    
    Such extent_changeset was used in btrfs_qgroup_reserve_data() to record
    which range it reserved in current reserve, so it can free it in error
    paths.
    
    The reason we need to export it to callers is, at buffered write error
    path, without knowing what exactly which range we reserved in current
    allocation, we can free space which is not reserved by us.
    
    This will lead to qgroup reserved space underflow.
    
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index ce670d213913..aeafdb35d90b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -215,6 +215,40 @@ struct extent_changeset {
 	struct ulist range_changed;
 };
 
+static inline void extent_changeset_init(struct extent_changeset *changeset)
+{
+	changeset->bytes_changed = 0;
+	ulist_init(&changeset->range_changed);
+}
+
+static inline struct extent_changeset *extent_changeset_alloc(void)
+{
+	struct extent_changeset *ret;
+
+	ret = kmalloc(sizeof(*ret), GFP_KERNEL);
+	if (!ret)
+		return NULL;
+
+	extent_changeset_init(ret);
+	return ret;
+}
+
+static inline void extent_changeset_release(struct extent_changeset *changeset)
+{
+	if (!changeset)
+		return;
+	changeset->bytes_changed = 0;
+	ulist_release(&changeset->range_changed);
+}
+
+static inline void extent_changeset_free(struct extent_changeset *changeset)
+{
+	if (!changeset)
+		return;
+	extent_changeset_release(changeset);
+	kfree(changeset);
+}
+
 static inline void extent_set_compress_type(unsigned long *bio_flags,
 					    int compress_type)
 {

commit 7bc329c1836866ffac8b2613f780a51b3ffe786d
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Feb 27 15:10:36 2017 +0800

    btrfs: qgroup: Return actually freed bytes for qgroup release or free data
    
    btrfs_qgroup_release/free_data() only returns 0 or a negative error
    number (ENOMEM is the only possible error).
    
    This is normally good enough, but sometimes we need the exact byte
    count it freed/released.
    
    Change it to return actually released/freed bytenr number instead of 0
    for success.
    And slightly modify related extent_changeset structure, since in btrfs
    one no-hole data extent won't be larger than 128M, so "unsigned int"
    is large enough for the use case.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1e508a8f876e..ce670d213913 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -209,7 +209,7 @@ struct extent_buffer {
  */
 struct extent_changeset {
 	/* How many bytes are set/cleared in this operation */
-	u64 bytes_changed;
+	unsigned int bytes_changed;
 
 	/* Changed ranges */
 	struct ulist range_changed;

commit c5e4c3d7503453832444475641988ffa02b88b6d
Author: David Sterba <dsterba@suse.com>
Date:   Mon Jun 12 17:29:41 2017 +0200

    btrfs: sink gfp parameter to btrfs_io_bio_alloc
    
    We can hardcode GFP_NOFS to btrfs_io_bio_alloc, although it means we
    change it back from GFP_KERNEL in scrub. I'd rather save a few stack
    bytes from not passing the gfp flags in the remaining, more imporatant,
    contexts and the bio allocating API now looks more consistent.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 8071e3977614..1e508a8f876e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -463,7 +463,7 @@ void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
 				 unsigned bits_to_clear,
 				 unsigned long page_ops);
 struct bio *btrfs_bio_alloc(struct block_device *bdev, u64 first_byte);
-struct bio *btrfs_io_bio_alloc(gfp_t gfp_mask, unsigned int nr_iovecs);
+struct bio *btrfs_io_bio_alloc(unsigned int nr_iovecs);
 struct bio *btrfs_bio_clone(struct bio *bio);
 struct bio *btrfs_bio_clone_partial(struct bio *orig, int offset, int size);
 

commit c821e7f3daa4d02d6303f4f97a3243ea8a6f9411
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 2 18:35:36 2017 +0200

    btrfs: pass bytes to btrfs_bio_alloc
    
    Most callers of btrfs_bio_alloc convert from bytes to sectors. Hide that
    in the helper and simplify the logic in the callsers.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index fb7a938ecbc9..8071e3977614 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -462,7 +462,7 @@ void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
 				 u64 delalloc_end, struct page *locked_page,
 				 unsigned bits_to_clear,
 				 unsigned long page_ops);
-struct bio *btrfs_bio_alloc(struct block_device *bdev, u64 first_sector);
+struct bio *btrfs_bio_alloc(struct block_device *bdev, u64 first_byte);
 struct bio *btrfs_io_bio_alloc(gfp_t gfp_mask, unsigned int nr_iovecs);
 struct bio *btrfs_bio_clone(struct bio *bio);
 struct bio *btrfs_bio_clone_partial(struct bio *orig, int offset, int size);

commit 9f2179a5e72b794f8af22a6818d83d1600050c5c
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 2 17:55:44 2017 +0200

    btrfs: remove redundant parameters from btrfs_bio_alloc
    
    All callers pass gfp_flags=GFP_NOFS and nr_vecs=BIO_MAX_PAGES.
    
    submit_extent_page adds __GFP_HIGH that does not make a difference in
    our case as it allows access to memory reserves but otherwise does not
    change the constraints.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4fe643a5aeaf..fb7a938ecbc9 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -462,9 +462,7 @@ void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
 				 u64 delalloc_end, struct page *locked_page,
 				 unsigned bits_to_clear,
 				 unsigned long page_ops);
-struct bio *
-btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,
-		gfp_t gfp_flags);
+struct bio *btrfs_bio_alloc(struct block_device *bdev, u64 first_sector);
 struct bio *btrfs_io_bio_alloc(gfp_t gfp_mask, unsigned int nr_iovecs);
 struct bio *btrfs_bio_clone(struct bio *bio);
 struct bio *btrfs_bio_clone_partial(struct bio *orig, int offset, int size);

commit 8b6c1d56f2f5094b14b22a226b798ca3d186c0e9
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 2 17:48:13 2017 +0200

    btrfs: sink gfp parameter to btrfs_bio_clone
    
    All callers pass GFP_NOFS.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e3512c5d8770..4fe643a5aeaf 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -466,7 +466,7 @@ struct bio *
 btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,
 		gfp_t gfp_flags);
 struct bio *btrfs_io_bio_alloc(gfp_t gfp_mask, unsigned int nr_iovecs);
-struct bio *btrfs_bio_clone(struct bio *bio, gfp_t gfp_mask);
+struct bio *btrfs_bio_clone(struct bio *bio);
 struct bio *btrfs_bio_clone_partial(struct bio *orig, int offset, int size);
 
 struct btrfs_fs_info;

commit e477094f0d3ce35b30d230bda3f31fc060cfe93b
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Tue May 16 10:57:14 2017 -0700

    Btrfs: hardcode GFP_NOFS for btrfs_bio_clone_partial
    
    We only pass GFP_NOFS to btrfs_bio_clone_partial, so lets hardcode it.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3df018549ce4..e3512c5d8770 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -467,8 +467,7 @@ btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,
 		gfp_t gfp_flags);
 struct bio *btrfs_io_bio_alloc(gfp_t gfp_mask, unsigned int nr_iovecs);
 struct bio *btrfs_bio_clone(struct bio *bio, gfp_t gfp_mask);
-struct bio *btrfs_bio_clone_partial(struct bio *orig, gfp_t gfp_mask,
-				    int offset, int size);
+struct bio *btrfs_bio_clone_partial(struct bio *orig, int offset, int size);
 
 struct btrfs_fs_info;
 struct btrfs_inode;

commit 2f8e9140426dff6091b7a40d441befc791882658
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon May 15 17:43:31 2017 -0700

    Btrfs: new helper btrfs_bio_clone_partial
    
    This adds a new helper btrfs_bio_clone_partial, it'll allocate a cloned
    bio that only owns a part of the original bio's data.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1383afdf1eeb..3df018549ce4 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -467,6 +467,8 @@ btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,
 		gfp_t gfp_flags);
 struct bio *btrfs_io_bio_alloc(gfp_t gfp_mask, unsigned int nr_iovecs);
 struct bio *btrfs_bio_clone(struct bio *bio, gfp_t gfp_mask);
+struct bio *btrfs_bio_clone_partial(struct bio *orig, gfp_t gfp_mask,
+				    int offset, int size);
 
 struct btrfs_fs_info;
 struct btrfs_inode;

commit 7870d0822be99bdb9353b542007c046966ec18f3
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri May 5 11:57:15 2017 -0400

    Btrfs: don't pass the inode through clean_io_failure
    
    Instead pass around the failure tree and the io tree.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index aa3b1fcfc15f..1383afdf1eeb 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -474,8 +474,10 @@ struct btrfs_inode;
 int repair_io_failure(struct btrfs_fs_info *fs_info, u64 ino, u64 start,
 		      u64 length, u64 logical, struct page *page,
 		      unsigned int pg_offset, int mirror_num);
-int clean_io_failure(struct btrfs_inode *inode, u64 start,
-		struct page *page, unsigned int pg_offset);
+int clean_io_failure(struct btrfs_fs_info *fs_info,
+		     struct extent_io_tree *failure_tree,
+		     struct extent_io_tree *io_tree, u64 start,
+		     struct page *page, u64 ino, unsigned int pg_offset);
 void end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 int repair_eb_io_failure(struct btrfs_fs_info *fs_info,
 			 struct extent_buffer *eb, int mirror_num);
@@ -510,7 +512,9 @@ struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
 				    struct io_failure_record *failrec,
 				    struct page *page, int pg_offset, int icsum,
 				    bio_end_io_t *endio_func, void *data);
-int free_io_failure(struct btrfs_inode *inode, struct io_failure_record *rec);
+int free_io_failure(struct extent_io_tree *failure_tree,
+		    struct extent_io_tree *io_tree,
+		    struct io_failure_record *rec);
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 noinline u64 find_lock_delalloc_range(struct inode *inode,
 				      struct extent_io_tree *tree,

commit 6ec656bc0fde92c3cb14d5dc9dca69ec8cce68c6
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri May 5 11:57:14 2017 -0400

    btrfs: remove inode argument from repair_io_failure
    
    Once we remove the btree_inode we won't have an inode to pass anymore,
    just pass the fs_info directly and the inum since we use that to print
    out the repair message.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 15ef696dda51..aa3b1fcfc15f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -471,9 +471,9 @@ struct bio *btrfs_bio_clone(struct bio *bio, gfp_t gfp_mask);
 struct btrfs_fs_info;
 struct btrfs_inode;
 
-int repair_io_failure(struct btrfs_inode *inode, u64 start, u64 length,
-		u64 logical, struct page *page,
-		unsigned int pg_offset, int mirror_num);
+int repair_io_failure(struct btrfs_fs_info *fs_info, u64 ino, u64 start,
+		      u64 length, u64 logical, struct page *page,
+		      unsigned int pg_offset, int mirror_num);
 int clean_io_failure(struct btrfs_inode *inode, u64 start,
 		struct page *page, unsigned int pg_offset);
 void end_extent_writepage(struct page *page, int err, u64 start, u64 end);

commit c6100a4b4e3d1650deafda45e49571b83270c714
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri May 5 11:57:13 2017 -0400

    Btrfs: replace tree->mapping with tree->private_data
    
    For extent_io tree's we have carried the address_mapping of the inode
    around in the io tree in order to pull the inode back out for calling
    into various tree ops hooks.  This works fine when everything that has
    an extent_io_tree has an inode.  But we are going to remove the
    btree_inode, so we need to change this.  Instead just have a generic
    void * for private data that we can initialize with, and have all the
    tree ops use that instead.  This had a lot of cascading changes but
    should be relatively straightforward.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor reordering of the callback prototypes ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1eafa2f0ede3..15ef696dda51 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -92,7 +92,7 @@ struct btrfs_inode;
 struct btrfs_io_bio;
 struct io_failure_record;
 
-typedef	int (extent_submit_bio_hook_t)(struct inode *inode, struct bio *bio,
+typedef	int (extent_submit_bio_hook_t)(void *private_data, struct bio *bio,
 				       int mirror_num, unsigned long bio_flags,
 				       u64 bio_offset);
 struct extent_io_ops {
@@ -108,32 +108,36 @@ struct extent_io_ops {
 			      size_t size, struct bio *bio,
 			      unsigned long bio_flags);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
+	struct btrfs_fs_info *(*tree_fs_info)(void *private_data);
+	void (*set_range_writeback)(void *private_data, u64 start, u64 end);
 
 	/*
 	 * Optional hooks, called if the pointer is not NULL
 	 */
-	int (*fill_delalloc)(struct inode *inode, struct page *locked_page,
+	int (*fill_delalloc)(void *private_data, struct page *locked_page,
 			     u64 start, u64 end, int *page_started,
 			     unsigned long *nr_written);
 
 	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
-	void (*set_bit_hook)(struct inode *inode, struct extent_state *state,
+	void (*set_bit_hook)(void *private_data, struct extent_state *state,
 			     unsigned *bits);
-	void (*clear_bit_hook)(struct btrfs_inode *inode,
+	void (*clear_bit_hook)(void *private_data,
 			struct extent_state *state,
 			unsigned *bits);
-	void (*merge_extent_hook)(struct inode *inode,
+	void (*merge_extent_hook)(void *private_data,
 				  struct extent_state *new,
 				  struct extent_state *other);
-	void (*split_extent_hook)(struct inode *inode,
+	void (*split_extent_hook)(void *private_data,
 				  struct extent_state *orig, u64 split);
+	void (*check_extent_io_range)(void *private_data, const char *caller,
+				      u64 start, u64 end);
 };
 
 struct extent_io_tree {
 	struct rb_root state;
-	struct address_space *mapping;
+	void *private_data;
 	u64 dirty_bytes;
 	int track_uptodate;
 	spinlock_t lock;
@@ -230,8 +234,7 @@ typedef struct extent_map *(get_extent_t)(struct btrfs_inode *inode,
 					  u64 start, u64 len,
 					  int create);
 
-void extent_io_tree_init(struct extent_io_tree *tree,
-			 struct address_space *mapping);
+void extent_io_tree_init(struct extent_io_tree *tree, void *private_data);
 int try_release_extent_mapping(struct extent_map_tree *map,
 			       struct extent_io_tree *tree, struct page *page,
 			       gfp_t mask);

commit 4e4cbee93d56137ebff722be022cae5f70ef84fb
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:06 2017 +0200

    block: switch bios to blk_status_t
    
    Replace bi_error with a new bi_status to allow for a clear conversion.
    Note that device mapper overloaded bi_error with a private value, which
    we'll have to keep arround at least for now and thus propagate to a
    proper blk_status_t value.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1eafa2f0ede3..487ca0207cb6 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -92,9 +92,9 @@ struct btrfs_inode;
 struct btrfs_io_bio;
 struct io_failure_record;
 
-typedef	int (extent_submit_bio_hook_t)(struct inode *inode, struct bio *bio,
-				       int mirror_num, unsigned long bio_flags,
-				       u64 bio_offset);
+typedef	blk_status_t (extent_submit_bio_hook_t)(struct inode *inode,
+		struct bio *bio, int mirror_num, unsigned long bio_flags,
+		u64 bio_offset);
 struct extent_io_ops {
 	/*
 	 * The following callbacks must be allways defined, the function

commit bce19f9d232b71c4eef9ca7d0947035bbb922cef
Merge: c2a9c7ab475b a7e3b975a0f9
Author: Chris Mason <clm@fb.com>
Date:   Thu Apr 27 14:13:09 2017 -0700

    Merge branch 'for-chris-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/fdmanana/linux into for-linus-4.12

commit a7e3b975a0f9296162b72ac6ab7fad9631a07630
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Apr 3 10:45:46 2017 +0100

    Btrfs: fix reported number of inode blocks
    
    Currently when there are buffered writes that were not yet flushed and
    they fall within allocated ranges of the file (that is, not in holes or
    beyond eof assuming there are no prealloc extents beyond eof), btrfs
    simply reports an incorrect number of used blocks through the stat(2)
    system call (or any of its variants), regardless of mount options or
    inode flags (compress, compress-force, nodatacow). This is because the
    number of blocks used that is reported is based on the current number
    of bytes in the vfs inode plus the number of dealloc bytes in the btrfs
    inode. The later covers bytes that both fall within allocated regions
    of the file and holes.
    
    Example scenarios where the number of reported blocks is wrong while the
    buffered writes are not flushed:
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt/sdc
    
      $ xfs_io -f -c "pwrite -S 0xaa 0 64K" /mnt/sdc/foo1
      wrote 65536/65536 bytes at offset 0
      64 KiB, 16 ops; 0.0000 sec (259.336 MiB/sec and 66390.0415 ops/sec)
    
      $ sync
    
      $ xfs_io -c "pwrite -S 0xbb 0 64K" /mnt/sdc/foo1
      wrote 65536/65536 bytes at offset 0
      64 KiB, 16 ops; 0.0000 sec (192.308 MiB/sec and 49230.7692 ops/sec)
    
      # The following should have reported 64K...
      $ du -h /mnt/sdc/foo1
      128K  /mnt/sdc/foo1
    
      $ sync
    
      # After flushing the buffered write, it now reports the correct value.
      $ du -h /mnt/sdc/foo1
      64K   /mnt/sdc/foo1
    
      $ xfs_io -f -c "falloc -k 0 128K" -c "pwrite -S 0xaa 0 64K" /mnt/sdc/foo2
      wrote 65536/65536 bytes at offset 0
      64 KiB, 16 ops; 0.0000 sec (520.833 MiB/sec and 133333.3333 ops/sec)
    
      $ sync
    
      $ xfs_io -c "pwrite -S 0xbb 64K 64K" /mnt/sdc/foo2
      wrote 65536/65536 bytes at offset 65536
      64 KiB, 16 ops; 0.0000 sec (260.417 MiB/sec and 66666.6667 ops/sec)
    
      # The following should have reported 128K...
      $ du -h /mnt/sdc/foo2
      192K  /mnt/sdc/foo2
    
      $ sync
    
      # After flushing the buffered write, it now reports the correct value.
      $ du -h /mnt/sdc/foo2
      128K  /mnt/sdc/foo2
    
    So the number of used file blocks is simply incorrect, unlike in other
    filesystems such as ext4 and xfs for example, but only while the buffered
    writes are not flushed.
    
    Fix this by tracking the number of delalloc bytes that fall within holes
    and beyond eof of a file, and use instead this new counter when reporting
    the number of used blocks for an inode.
    
    Another different problem that exists is that the delalloc bytes counter
    is reset when writeback starts (by clearing the EXTENT_DEALLOC flag from
    the respective range in the inode's iotree) and the vfs inode's bytes
    counter is only incremented when writeback finishes (through
    insert_reserved_file_extent()). Therefore while writeback is ongoing we
    simply report a wrong number of blocks used by an inode if the write
    operation covers a range previously unallocated. While this change does
    not fix this problem, it does minimizes it a lot by shortening that time
    window, as the new dealloc bytes counter (new_delalloc_bytes) is only
    decremented when writeback finishes right before updating the vfs inode's
    bytes counter. Fully fixing this second problem is not trivial and will
    be addressed later by a different patch.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 48a30d0e71fb..d5ff51b973a4 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -21,6 +21,7 @@
 #define EXTENT_NORESERVE	(1U << 15)
 #define EXTENT_QGROUP_RESERVED	(1U << 16)
 #define EXTENT_CLEAR_DATA_RESV	(1U << 17)
+#define EXTENT_DELALLOC_NEW	(1U << 18)
 #define EXTENT_IOBITS		(EXTENT_LOCKED | EXTENT_WRITEBACK)
 #define EXTENT_DO_ACCOUNTING    (EXTENT_CLEAR_META_RESV | \
 				 EXTENT_CLEAR_DATA_RESV)

commit a315e68f6e8b3006c29482dbfc4d928f098c449c
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Mar 6 23:04:20 2017 +0000

    Btrfs: fix invalid attempt to free reserved space on failure to cow range
    
    When attempting to COW a file range (we are starting writeback and doing
    COW), if we manage to reserve an extent for the range we will write into
    but fail after reserving it and before creating the respective ordered
    extent, we end up in an error path where we attempt to decrement the
    data space's bytes_may_use counter after we already did it while
    reserving the extent, leading to a warning/trace like the following:
    
    [  847.621524] ------------[ cut here ]------------
    [  847.625441] WARNING: CPU: 5 PID: 4905 at fs/btrfs/extent-tree.c:4316 btrfs_free_reserved_data_space_noquota+0x60/0x9f [btrfs]
    [  847.633704] Modules linked in: btrfs crc32c_generic xor raid6_pq acpi_cpufreq i2c_piix4 ppdev psmouse tpm_tis serio_raw pcspkr parport_pc tpm_tis_core i2c_core sg
    [  847.644616] CPU: 5 PID: 4905 Comm: xfs_io Not tainted 4.10.0-rc8-btrfs-next-37+ #2
    [  847.648601] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.1-0-gb3ef39f-prebuilt.qemu-project.org 04/01/2014
    [  847.648601] Call Trace:
    [  847.648601]  dump_stack+0x67/0x90
    [  847.648601]  __warn+0xc2/0xdd
    [  847.648601]  warn_slowpath_null+0x1d/0x1f
    [  847.648601]  btrfs_free_reserved_data_space_noquota+0x60/0x9f [btrfs]
    [  847.648601]  btrfs_clear_bit_hook+0x140/0x258 [btrfs]
    [  847.648601]  clear_state_bit+0x87/0x128 [btrfs]
    [  847.648601]  __clear_extent_bit+0x222/0x2b7 [btrfs]
    [  847.648601]  clear_extent_bit+0x17/0x19 [btrfs]
    [  847.648601]  extent_clear_unlock_delalloc+0x3b/0x6b [btrfs]
    [  847.648601]  cow_file_range.isra.39+0x387/0x39a [btrfs]
    [  847.648601]  run_delalloc_nocow+0x4d7/0x70e [btrfs]
    [  847.648601]  ? arch_local_irq_save+0x9/0xc
    [  847.648601]  run_delalloc_range+0xa7/0x2b5 [btrfs]
    [  847.648601]  writepage_delalloc.isra.31+0xb9/0x15c [btrfs]
    [  847.648601]  __extent_writepage+0x249/0x2e8 [btrfs]
    [  847.648601]  extent_write_cache_pages.constprop.33+0x28b/0x36c [btrfs]
    [  847.648601]  ? arch_local_irq_save+0x9/0xc
    [  847.648601]  ? mark_lock+0x24/0x201
    [  847.648601]  extent_writepages+0x4b/0x5c [btrfs]
    [  847.648601]  ? btrfs_writepage_start_hook+0xed/0xed [btrfs]
    [  847.648601]  btrfs_writepages+0x28/0x2a [btrfs]
    [  847.648601]  do_writepages+0x23/0x2c
    [  847.648601]  __filemap_fdatawrite_range+0x5a/0x61
    [  847.648601]  filemap_fdatawrite_range+0x13/0x15
    [  847.648601]  btrfs_fdatawrite_range+0x20/0x46 [btrfs]
    [  847.648601]  start_ordered_ops+0x19/0x23 [btrfs]
    [  847.648601]  btrfs_sync_file+0x136/0x42c [btrfs]
    [  847.648601]  vfs_fsync_range+0x8c/0x9e
    [  847.648601]  vfs_fsync+0x1c/0x1e
    [  847.648601]  do_fsync+0x31/0x4a
    [  847.648601]  SyS_fsync+0x10/0x14
    [  847.648601]  entry_SYSCALL_64_fastpath+0x18/0xad
    [  847.648601] RIP: 0033:0x7f5b05200800
    [  847.648601] RSP: 002b:00007ffe204f71c8 EFLAGS: 00000246 ORIG_RAX: 000000000000004a
    [  847.648601] RAX: ffffffffffffffda RBX: ffffffff8109637b RCX: 00007f5b05200800
    [  847.648601] RDX: 00000000008bd0a0 RSI: 00000000008bd2e0 RDI: 0000000000000003
    [  847.648601] RBP: ffffc90001d67f98 R08: 000000000000ffff R09: 000000000000001f
    [  847.648601] R10: 00000000000001f6 R11: 0000000000000246 R12: 0000000000000046
    [  847.648601] R13: ffffc90001d67f78 R14: 00007f5b054be740 R15: 00007f5b054be740
    [  847.648601]  ? trace_hardirqs_off_caller+0x3f/0xaa
    [  847.685787] ---[ end trace 2a4a3e15382508e8 ]---
    
    So fix this by not attempting to decrement the data space info's
    bytes_may_use counter if we already reserved the extent and an error
    happened before creating the ordered extent. We are already correctly
    freeing the reserved extent if an error happens, so there's no additional
    measure needed.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3e4fad4a909d..48a30d0e71fb 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -14,7 +14,7 @@
 #define EXTENT_DEFRAG		(1U << 6)
 #define EXTENT_BOUNDARY		(1U << 9)
 #define EXTENT_NODATASUM	(1U << 10)
-#define EXTENT_DO_ACCOUNTING	(1U << 11)
+#define EXTENT_CLEAR_META_RESV	(1U << 11)
 #define EXTENT_FIRST_DELALLOC	(1U << 12)
 #define EXTENT_NEED_WAIT	(1U << 13)
 #define EXTENT_DAMAGED		(1U << 14)
@@ -22,6 +22,8 @@
 #define EXTENT_QGROUP_RESERVED	(1U << 16)
 #define EXTENT_CLEAR_DATA_RESV	(1U << 17)
 #define EXTENT_IOBITS		(EXTENT_LOCKED | EXTENT_WRITEBACK)
+#define EXTENT_DO_ACCOUNTING    (EXTENT_CLEAR_META_RESV | \
+				 EXTENT_CLEAR_DATA_RESV)
 #define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
 
 /*

commit b7ac31b7b2ebd735b7b67c85711ef6d16648051a
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Mar 3 10:55:19 2017 +0200

    btrfs: convert extent_state.refs from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3e4fad4a909d..8d2d6e4272d5 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -2,6 +2,7 @@
 #define __EXTENTIO__
 
 #include <linux/rbtree.h>
+#include <linux/refcount.h>
 #include "ulist.h"
 
 /* bits for the extent state */
@@ -143,7 +144,7 @@ struct extent_state {
 
 	/* ADD NEW ELEMENTS AFTER THIS */
 	wait_queue_head_t wq;
-	atomic_t refs;
+	refcount_t refs;
 	unsigned state;
 
 	struct io_failure_record *failrec;

commit 20a7db8ab3f2057a518448b1728d504ffadef65e
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 17 16:24:29 2017 +0100

    btrfs: add dummy callback for readpage_io_failed and drop checks
    
    Make extent_io_ops::readpage_io_failed_hook callback mandatory and
    define a dummy function for btrfs_extent_io_ops. As the failed IO
    callback is not performance critical, the branch vs extra trade off does
    not hurt.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1f8478dc9f8e..3e4fad4a909d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -103,6 +103,7 @@ struct extent_io_ops {
 	int (*merge_bio_hook)(struct page *page, unsigned long offset,
 			      size_t size, struct bio *bio,
 			      unsigned long bio_flags);
+	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
 
 	/*
 	 * Optional hooks, called if the pointer is not NULL
@@ -110,7 +111,6 @@ struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, struct page *locked_page,
 			     u64 start, u64 end, int *page_started,
 			     unsigned long *nr_written);
-	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
 
 	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,

commit 4d53dddbec671bcb64a936a3d2b7bf1ce2252ed0
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 17 15:27:44 2017 +0100

    btrfs: document existence of extent_io ops callbacks
    
    Some of the callbacks defined in btree_extent_io_ops and
    btrfs_extent_io_ops do always exist so we don't need to check the
    existence before each call. This patch just reorders the definition and
    documents which are mandatory/optional.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 78bb4d76127b..1f8478dc9f8e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -92,18 +92,27 @@ typedef	int (extent_submit_bio_hook_t)(struct inode *inode, struct bio *bio,
 				       int mirror_num, unsigned long bio_flags,
 				       u64 bio_offset);
 struct extent_io_ops {
-	int (*fill_delalloc)(struct inode *inode, struct page *locked_page,
-			     u64 start, u64 end, int *page_started,
-			     unsigned long *nr_written);
-	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
+	/*
+	 * The following callbacks must be allways defined, the function
+	 * pointer will be called unconditionally.
+	 */
 	extent_submit_bio_hook_t *submit_bio_hook;
+	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,
+				    struct page *page, u64 start, u64 end,
+				    int mirror);
 	int (*merge_bio_hook)(struct page *page, unsigned long offset,
 			      size_t size, struct bio *bio,
 			      unsigned long bio_flags);
+
+	/*
+	 * Optional hooks, called if the pointer is not NULL
+	 */
+	int (*fill_delalloc)(struct inode *inode, struct page *locked_page,
+			     u64 start, u64 end, int *page_started,
+			     unsigned long *nr_written);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
-	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,
-				    struct page *page, u64 start, u64 end,
-				    int mirror);
+
+	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
 	void (*set_bit_hook)(struct inode *inode, struct extent_state *state,

commit c3988d630a4dfec5c09f2b6496734f320949ea9c
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 17 15:18:32 2017 +0100

    btrfs: let writepage_end_io_hook return void
    
    There's no error path in any of the instances, always return 0.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c16260c6c14f..78bb4d76127b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -104,7 +104,7 @@ struct extent_io_ops {
 	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,
 				    struct page *page, u64 start, u64 end,
 				    int mirror);
-	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
+	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
 	void (*set_bit_hook)(struct inode *inode, struct extent_state *state,
 			     unsigned *bits);

commit fc4f21b1d8d023cf0a2b1b050ae18e15dbe7068e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:51:06 2017 +0200

    btrfs: Make get_extent_t take btrfs_inode
    
    In addition to changing the signature, this patch also switches
    all the functions which are used as an argument to also take btrfs_inode.
    Namely those are: btrfs_get_extent and btrfs_get_extent_filemap.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index cd8b3dd6948d..c16260c6c14f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -211,7 +211,7 @@ static inline int extent_compress_type(unsigned long bio_flags)
 
 struct extent_map_tree;
 
-typedef struct extent_map *(get_extent_t)(struct inode *inode,
+typedef struct extent_map *(get_extent_t)(struct btrfs_inode *inode,
 					  struct page *page,
 					  size_t pg_offset,
 					  u64 start, u64 len,

commit 6fc0ef687029760476e309aa85d437a47313eb08
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:51:03 2017 +0200

    btrfs: Make btrfs_clear_bit_hook take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 345fc33f843d..cd8b3dd6948d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -84,6 +84,7 @@ extern void le_bitmap_clear(u8 *map, unsigned int start, int len);
 
 struct extent_state;
 struct btrfs_root;
+struct btrfs_inode;
 struct btrfs_io_bio;
 struct io_failure_record;
 
@@ -107,8 +108,9 @@ struct extent_io_ops {
 				      struct extent_state *state, int uptodate);
 	void (*set_bit_hook)(struct inode *inode, struct extent_state *state,
 			     unsigned *bits);
-	void (*clear_bit_hook)(struct inode *inode, struct extent_state *state,
-			       unsigned *bits);
+	void (*clear_bit_hook)(struct btrfs_inode *inode,
+			struct extent_state *state,
+			unsigned *bits);
 	void (*merge_extent_hook)(struct inode *inode,
 				  struct extent_state *new,
 				  struct extent_state *other);

commit 7ab7956ec3fc77667739d065748d96f87bff6c5d
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:57 2017 +0200

    btrfs: make btrfs_free_io_failure_record take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 0f67222f4464..345fc33f843d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -482,7 +482,8 @@ struct io_failure_record {
 };
 
 
-void btrfs_free_io_failure_record(struct inode *inode, u64 start, u64 end);
+void btrfs_free_io_failure_record(struct btrfs_inode *inode, u64 start,
+		u64 end);
 int btrfs_get_io_failure_record(struct inode *inode, u64 start, u64 end,
 				struct io_failure_record **failrec_ret);
 int btrfs_check_repairable(struct inode *inode, struct bio *failed_bio,

commit b30cb441fcf8786773dab590739ca4ebc2b4628b
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:56 2017 +0200

    btrfs: make clean_io_failure take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 039a6daa392b..0f67222f4464 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -456,8 +456,8 @@ struct btrfs_inode;
 int repair_io_failure(struct btrfs_inode *inode, u64 start, u64 length,
 		u64 logical, struct page *page,
 		unsigned int pg_offset, int mirror_num);
-int clean_io_failure(struct inode *inode, u64 start, struct page *page,
-		     unsigned int pg_offset);
+int clean_io_failure(struct btrfs_inode *inode, u64 start,
+		struct page *page, unsigned int pg_offset);
 void end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 int repair_eb_io_failure(struct btrfs_fs_info *fs_info,
 			 struct extent_buffer *eb, int mirror_num);

commit 9d4f7f8ad69112137da0bbe4036b94739ae25f78
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:55 2017 +0200

    btrfs: make repair_io_failure take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 5b4132a9093a..039a6daa392b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -451,10 +451,11 @@ struct bio *btrfs_io_bio_alloc(gfp_t gfp_mask, unsigned int nr_iovecs);
 struct bio *btrfs_bio_clone(struct bio *bio, gfp_t gfp_mask);
 
 struct btrfs_fs_info;
+struct btrfs_inode;
 
-int repair_io_failure(struct inode *inode, u64 start, u64 length, u64 logical,
-		      struct page *page, unsigned int pg_offset,
-		      int mirror_num);
+int repair_io_failure(struct btrfs_inode *inode, u64 start, u64 length,
+		u64 logical, struct page *page,
+		unsigned int pg_offset, int mirror_num);
 int clean_io_failure(struct inode *inode, u64 start, struct page *page,
 		     unsigned int pg_offset);
 void end_extent_writepage(struct page *page, int err, u64 start, u64 end);
@@ -480,7 +481,6 @@ struct io_failure_record {
 	int in_validation;
 };
 
-struct btrfs_inode;
 
 void btrfs_free_io_failure_record(struct inode *inode, u64 start, u64 end);
 int btrfs_get_io_failure_record(struct inode *inode, u64 start, u64 end,

commit 4ac1f4acd7c60c95e3efa63d463418093aff9ce5
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:52 2017 +0200

    btrfs: make free_io_failure take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 270d03be290e..5b4132a9093a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -480,6 +480,8 @@ struct io_failure_record {
 	int in_validation;
 };
 
+struct btrfs_inode;
+
 void btrfs_free_io_failure_record(struct inode *inode, u64 start, u64 end);
 int btrfs_get_io_failure_record(struct inode *inode, u64 start, u64 end,
 				struct io_failure_record **failrec_ret);
@@ -489,7 +491,7 @@ struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
 				    struct io_failure_record *failrec,
 				    struct page *page, int pg_offset, int icsum,
 				    bio_end_io_t *endio_func, void *data);
-int free_io_failure(struct inode *inode, struct io_failure_record *rec);
+int free_io_failure(struct btrfs_inode *inode, struct io_failure_record *rec);
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 noinline u64 find_lock_delalloc_range(struct inode *inode,
 				      struct extent_io_tree *tree,

commit 53d3235995b3f87754a42de24d707f158c1b3b40
Author: David Sterba <dsterba@suse.com>
Date:   Mon Feb 13 13:42:29 2017 +0100

    btrfs: embed extent_changeset::range_changed to the structure
    
    We can embed range_changed to the extent changeset to address following
    problems:
    
    - no need to allocate ulist dynamically, we also get rid of the GFP_NOFS
      for free
    - fix lack of allocation failure checking in btrfs_qgroup_reserve_data
    
    The stack consuption where extent_changeset is used slightly increases:
    
    before: 16
    after: 16 - 8 (for pointer) + 32 (sizeof ulist) = 40
    
    Which is bearable.
    
    Reviewed-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4551a5b4b8f5..270d03be290e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -193,7 +193,7 @@ struct extent_changeset {
 	u64 bytes_changed;
 
 	/* Changed ranges */
-	struct ulist *range_changed;
+	struct ulist range_changed;
 };
 
 static inline void extent_set_compress_type(unsigned long *bio_flags,

commit da2c7009f6cafe0a550cf57a1aa79e0f1b3093d6
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Feb 10 16:41:05 2017 +0100

    btrfs: teach __process_pages_contig about PAGE_LOCK operation
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ changes to the helper separated from the following patch ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 17f9ce479ed7..4551a5b4b8f5 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -45,13 +45,14 @@
 #define EXTENT_BUFFER_IN_TREE 10
 #define EXTENT_BUFFER_WRITE_ERR 11    /* write IO error */
 
-/* these are flags for extent_clear_unlock_delalloc */
+/* these are flags for __process_pages_contig */
 #define PAGE_UNLOCK		(1 << 0)
 #define PAGE_CLEAR_DIRTY	(1 << 1)
 #define PAGE_SET_WRITEBACK	(1 << 2)
 #define PAGE_END_WRITEBACK	(1 << 3)
 #define PAGE_SET_PRIVATE2	(1 << 4)
 #define PAGE_SET_ERROR		(1 << 5)
+#define PAGE_LOCK		(1 << 6)
 
 /*
  * page->private values.  Every page that is controlled by the extent

commit 2ff7e61e0d30ff166a2ae94575526bffe11fd1a8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:24 2016 -0400

    btrfs: take an fs_info directly when the root is not used otherwise
    
    There are loads of functions in btrfs that accept a root parameter
    but only use it to obtain an fs_info pointer.  Let's convert those to
    just accept an fs_info pointer directly.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f786156bd7e2..17f9ce479ed7 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -457,8 +457,8 @@ int repair_io_failure(struct inode *inode, u64 start, u64 length, u64 logical,
 int clean_io_failure(struct inode *inode, u64 start, struct page *page,
 		     unsigned int pg_offset);
 void end_extent_writepage(struct page *page, int err, u64 start, u64 end);
-int repair_eb_io_failure(struct btrfs_root *root, struct extent_buffer *eb,
-			 int mirror_num);
+int repair_eb_io_failure(struct btrfs_fs_info *fs_info,
+			 struct extent_buffer *eb, int mirror_num);
 
 /*
  * When IO fails, either with EIO or csum verification fails, we

commit da17066c40472c2d6a1aab7bb0090c3d285531c9
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 09:22:56 2016 -0400

    btrfs: pull node/sector/stripe sizes out of root and into fs_info
    
    We track the node sizes per-root, but they never vary from the values
    in the superblock.  This patch messes with the 80-column style a bit,
    but subsequent patches to factor out root->fs_info into a convenience
    variable fix it up again.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index ae64c1917d0a..f786156bd7e2 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -371,7 +371,7 @@ struct extent_buffer *alloc_extent_buffer(struct btrfs_fs_info *fs_info,
 struct extent_buffer *__alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
 						  u64 start, unsigned long len);
 struct extent_buffer *alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
-						u64 start, u32 nodesize);
+						u64 start);
 struct extent_buffer *btrfs_clone_extent_buffer(struct extent_buffer *src);
 struct extent_buffer *find_extent_buffer(struct btrfs_fs_info *fs_info,
 					 u64 start);
@@ -496,5 +496,5 @@ noinline u64 find_lock_delalloc_range(struct inode *inode,
 				      u64 *end, u64 max_bytes);
 #endif
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
-					       u64 start, u32 nodesize);
+					       u64 start);
 #endif

commit 58e8012cc12b3cdebea118981c4fd7136d52f2c7
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 18:30:31 2016 +0100

    btrfs: add optimized version of eb to eb copy
    
    Using copy_extent_buffer is suitable for copying betwenn buffers from an
    arbitrary offset and deals with page boundaries. This is not necessary
    when doing a full extent_buffer-to-extent_buffer copy. We can utilize
    the copy_page helper as well.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 12fe17523df2..ae64c1917d0a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -410,6 +410,8 @@ void write_extent_buffer_chunk_tree_uuid(struct extent_buffer *eb,
 		const void *src);
 void write_extent_buffer(struct extent_buffer *eb, const void *src,
 			 unsigned long start, unsigned long len);
+void copy_extent_buffer_full(struct extent_buffer *dst,
+			     struct extent_buffer *src);
 void copy_extent_buffer(struct extent_buffer *dst, struct extent_buffer *src,
 			unsigned long dst_offset, unsigned long src_offset,
 			unsigned long len);

commit b159fa2808b1b53d784807a48ad95fa809be10b0
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 18:09:03 2016 +0100

    btrfs: remove constant parameter to memset_extent_buffer and rename it
    
    The only memset we do is to 0, so sink the parameter to the function and
    simplify all calls. Rename the function to reflect the behaviour.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 065c77d43921..12fe17523df2 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -417,8 +417,8 @@ void memcpy_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
 			   unsigned long src_offset, unsigned long len);
 void memmove_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
 			   unsigned long src_offset, unsigned long len);
-void memset_extent_buffer(struct extent_buffer *eb, char c,
-			  unsigned long start, unsigned long len);
+void memzero_extent_buffer(struct extent_buffer *eb, unsigned long start,
+			   unsigned long len);
 int extent_buffer_test_bit(struct extent_buffer *eb, unsigned long start,
 			   unsigned long pos);
 void extent_buffer_bitmap_set(struct extent_buffer *eb, unsigned long start,

commit f157bf765b3773efb5e981dea286cd311fca3b59
Author: David Sterba <dsterba@suse.com>
Date:   Wed Nov 9 17:43:38 2016 +0100

    btrfs: introduce helpers for updating eb uuids
    
    The fsid and chunk tree uuid are always located in the first page,
    we don't need the to use write_extent_buffer.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index ab31d145227e..065c77d43921 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -405,6 +405,9 @@ void read_extent_buffer(struct extent_buffer *eb, void *dst,
 int read_extent_buffer_to_user(struct extent_buffer *eb, void __user *dst,
 			       unsigned long start,
 			       unsigned long len);
+void write_extent_buffer_fsid(struct extent_buffer *eb, const void *src);
+void write_extent_buffer_chunk_tree_uuid(struct extent_buffer *eb,
+		const void *src);
 void write_extent_buffer(struct extent_buffer *eb, const void *src,
 			 unsigned long start, unsigned long len);
 void copy_extent_buffer(struct extent_buffer *dst, struct extent_buffer *src,

commit d9ed71e5457c8c5bf1dc706e06468eab9e2aa87e
Merge: 19c4d2f99478 0e6757859efe
Author: Chris Mason <clm@fb.com>
Date:   Wed Oct 12 13:16:00 2016 -0700

    Merge branch 'fst-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.9
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 2fe1d55134fce05c17ea118a2e37a4af771887bc
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Sep 22 17:24:20 2016 -0700

    Btrfs: fix free space tree bitmaps on big-endian systems
    
    In convert_free_space_to_{bitmaps,extents}(), we buffer the free space
    bitmaps in memory and copy them directly to/from the extent buffers with
    {read,write}_extent_buffer(). The extent buffer bitmap helpers use byte
    granularity, which is equivalent to a little-endian bitmap. This means
    that on big-endian systems, the in-memory bitmaps will be written to
    disk byte-swapped. To fix this, use byte-granularity for the bitmaps in
    memory.
    
    Fixes: a5ed91828518 ("Btrfs: implement the free space B-tree")
    Cc: stable@vger.kernel.org # 4.5+
    Tested-by: Holger Hoffstätte <holger@applied-asynchrony.com>
    Tested-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 28cd88fccc7e..1cf4e4226fc8 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -59,6 +59,28 @@
  */
 #define EXTENT_PAGE_PRIVATE 1
 
+/*
+ * The extent buffer bitmap operations are done with byte granularity instead of
+ * word granularity for two reasons:
+ * 1. The bitmaps must be little-endian on disk.
+ * 2. Bitmap items are not guaranteed to be aligned to a word and therefore a
+ *    single word in a bitmap may straddle two pages in the extent buffer.
+ */
+#define BIT_BYTE(nr) ((nr) / BITS_PER_BYTE)
+#define BYTE_MASK ((1 << BITS_PER_BYTE) - 1)
+#define BITMAP_FIRST_BYTE_MASK(start) \
+	((BYTE_MASK << ((start) & (BITS_PER_BYTE - 1))) & BYTE_MASK)
+#define BITMAP_LAST_BYTE_MASK(nbits) \
+	(BYTE_MASK >> (-(nbits) & (BITS_PER_BYTE - 1)))
+
+static inline int le_test_bit(int nr, const u8 *addr)
+{
+	return 1U & (addr[BIT_BYTE(nr)] >> (nr & (BITS_PER_BYTE-1)));
+}
+
+extern void le_bitmap_set(u8 *map, unsigned int start, int len);
+extern void le_bitmap_clear(u8 *map, unsigned int start, int len);
+
 struct extent_state;
 struct btrfs_root;
 struct btrfs_io_bio;

commit 8436ea91a1c4fd8ed57ff0c0ca482ee3dbe744c7
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Sep 2 15:40:03 2016 -0400

    Btrfs: kill the start argument to read_extent_buffer_pages
    
    Nobody uses this, it makes no sense to do partial reads of extent buffers.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 60536f3bf434..4a094f1dc7ef 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -359,7 +359,7 @@ void free_extent_buffer_stale(struct extent_buffer *eb);
 #define WAIT_COMPLETE	1
 #define WAIT_PAGE_LOCK	2
 int read_extent_buffer_pages(struct extent_io_tree *tree,
-			     struct extent_buffer *eb, u64 start, int wait,
+			     struct extent_buffer *eb, int wait,
 			     get_extent_t *get_extent, int mirror_num);
 void wait_on_extent_buffer_writeback(struct extent_buffer *eb);
 

commit ba8b04c1d4adbc66f3653e3de5bd6c74a9a003bf
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Jul 19 16:50:36 2016 +0800

    btrfs: extend btrfs_set_extent_delalloc and its friends to support in-band dedupe and subpage size patchset
    
    Extend btrfs_set_extent_delalloc() and extent_clear_unlock_delalloc()
    parameters for both in-band dedupe and subpage sector size patchset.
    
    This should reduce conflict of both patchset and the effort to rebase
    them.
    
    Cc: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 28cd88fccc7e..60536f3bf434 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -413,7 +413,7 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 void extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
-				 struct page *locked_page,
+				 u64 delalloc_end, struct page *locked_page,
 				 unsigned bits_to_clear,
 				 unsigned long page_ops);
 struct bio *

commit 28687b935e93a9041a485b9ecdcab0e335f8eda5
Merge: 370f6017295d 28a235931b56
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 26 20:22:01 2016 -0700

    Merge branch 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "We've queued up a few different fixes in here.  These range from
      enospc corners to fsync and quota fixes, and a few targeted at error
      handling for corrupt metadata/fuzzing"
    
    * 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix lockdep warning on deadlock against an inode's log mutex
      Btrfs: detect corruption when non-root leaf has zero item
      Btrfs: check btree node's nritems
      btrfs: don't create or leak aliased root while cleaning up orphans
      Btrfs: fix em leak in find_first_block_group
      btrfs: do not background blkdev_put()
      Btrfs: clarify do_chunk_alloc()'s return value
      btrfs: fix fsfreeze hang caused by delayed iputs deal
      btrfs: update btrfs_space_info's bytes_may_use timely
      btrfs: divide btrfs_update_reserved_bytes() into two functions
      btrfs: use correct offset for reloc_inode in prealloc_file_extent_cluster()
      btrfs: qgroup: Fix qgroup incorrectness caused by log replay
      btrfs: relocation: Fix leaking qgroups numbers on data extents
      btrfs: qgroup: Refactor btrfs_qgroup_insert_dirty_extent()
      btrfs: waiting on qgroup rescan should not always be interruptible
      btrfs: properly track when rescan worker is running
      btrfs: flush_space: treat return value of do_chunk_alloc properly
      Btrfs: add ASSERT for block group's memory leak
      btrfs: backref: Fix soft lockup in __merge_refs function
      Btrfs: fix memory leak of reloc_root

commit 18513091af9483ba84328d42092bd4d42a3c958f
Author: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
Date:   Mon Jul 25 15:51:40 2016 +0800

    btrfs: update btrfs_space_info's bytes_may_use timely
    
    This patch can fix some false ENOSPC errors, below test script can
    reproduce one false ENOSPC error:
            #!/bin/bash
            dd if=/dev/zero of=fs.img bs=$((1024*1024)) count=128
            dev=$(losetup --show -f fs.img)
            mkfs.btrfs -f -M $dev
            mkdir /tmp/mntpoint
            mount $dev /tmp/mntpoint
            cd /tmp/mntpoint
            xfs_io -f -c "falloc 0 $((64*1024*1024))" testfile
    
    Above script will fail for ENOSPC reason, but indeed fs still has free
    space to satisfy this request. Please see call graph:
    btrfs_fallocate()
    |-> btrfs_alloc_data_chunk_ondemand()
    |   bytes_may_use += 64M
    |-> btrfs_prealloc_file_range()
        |-> btrfs_reserve_extent()
            |-> btrfs_add_reserved_bytes()
            |   alloc_type is RESERVE_ALLOC_NO_ACCOUNT, so it does not
            |   change bytes_may_use, and bytes_reserved += 64M. Now
            |   bytes_may_use + bytes_reserved == 128M, which is greater
            |   than btrfs_space_info's total_bytes, false enospc occurs.
            |   Note, the bytes_may_use decrease operation will be done in
            |   end of btrfs_fallocate(), which is too late.
    
    Here is another simple case for buffered write:
                        CPU 1              |              CPU 2
                                           |
    |-> cow_file_range()                   |-> __btrfs_buffered_write()
        |-> btrfs_reserve_extent()         |   |
        |                                  |   |
        |                                  |   |
        |    .....                         |   |-> btrfs_check_data_free_space()
        |                                  |
        |                                  |
        |-> extent_clear_unlock_delalloc() |
    
    In CPU 1, btrfs_reserve_extent()->find_free_extent()->
    btrfs_add_reserved_bytes() do not decrease bytes_may_use, the decrease
    operation will be delayed to be done in extent_clear_unlock_delalloc().
    Assume in this case, btrfs_reserve_extent() reserved 128MB data, CPU2's
    btrfs_check_data_free_space() tries to reserve 100MB data space.
    If
            100MB > data_sinfo->total_bytes - data_sinfo->bytes_used -
                    data_sinfo->bytes_reserved - data_sinfo->bytes_pinned -
                    data_sinfo->bytes_readonly - data_sinfo->bytes_may_use
    btrfs_check_data_free_space() will try to allcate new data chunk or call
    btrfs_start_delalloc_roots(), or commit current transaction in order to
    reserve some free space, obviously a lot of work. But indeed it's not
    necessary as long as decreasing bytes_may_use timely, we still have
    free space, decreasing 128M from bytes_may_use.
    
    To fix this issue, this patch chooses to update bytes_may_use for both
    data and metadata in btrfs_add_reserved_bytes(). For compress path, real
    extent length may not be equal to file content length, so introduce a
    ram_bytes argument for btrfs_reserve_extent(), find_free_extent() and
    btrfs_add_reserved_bytes(), it's becasue bytes_may_use is increased by
    file content length. Then compress path can update bytes_may_use
    correctly. Also now we can discard RESERVE_ALLOC_NO_ACCOUNT, RESERVE_ALLOC
    and RESERVE_FREE.
    
    As we know, usually EXTENT_DO_ACCOUNTING is used for error path. In
    run_delalloc_nocow(), for inode marked as NODATACOW or extent marked as
    PREALLOC, we also need to update bytes_may_use, but can not pass
    EXTENT_DO_ACCOUNTING, because it also clears metadata reservation, so
    here we introduce EXTENT_CLEAR_DATA_RESV flag to indicate btrfs_clear_bit_hook()
    to update btrfs_space_info's bytes_may_use.
    
    Meanwhile __btrfs_prealloc_file_range() will call
    btrfs_free_reserved_data_space() internally for both sucessful and failed
    path, btrfs_prealloc_file_range()'s callers does not need to call
    btrfs_free_reserved_data_space() any more.
    
    Signed-off-by: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c0c1c4fef6ce..b52ca5db01cb 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -20,6 +20,7 @@
 #define EXTENT_DAMAGED		(1U << 14)
 #define EXTENT_NORESERVE	(1U << 15)
 #define EXTENT_QGROUP_RESERVED	(1U << 16)
+#define EXTENT_CLEAR_DATA_RESV	(1U << 17)
 #define EXTENT_IOBITS		(EXTENT_LOCKED | EXTENT_WRITEBACK)
 #define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
 

commit d05d7f40791ccbb6e543cc5dd6a6aa08fc71d635
Merge: 75a442efb1ca 17007f3994cd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 26 15:03:07 2016 -0700

    Merge branch 'for-4.8/core' of git://git.kernel.dk/linux-block
    
    Pull core block updates from Jens Axboe:
    
       - the big change is the cleanup from Mike Christie, cleaning up our
         uses of command types and modified flags.  This is what will throw
         some merge conflicts
    
       - regression fix for the above for btrfs, from Vincent
    
       - following up to the above, better packing of struct request from
         Christoph
    
       - a 2038 fix for blktrace from Arnd
    
       - a few trivial/spelling fixes from Bart Van Assche
    
       - a front merge check fix from Damien, which could cause issues on
         SMR drives
    
       - Atari partition fix from Gabriel
    
       - convert cfq to highres timers, since jiffies isn't granular enough
         for some devices these days.  From Jan and Jeff
    
       - CFQ priority boost fix idle classes, from me
    
       - cleanup series from Ming, improving our bio/bvec iteration
    
       - a direct issue fix for blk-mq from Omar
    
       - fix for plug merging not involving the IO scheduler, like we do for
         other types of merges.  From Tahsin
    
       - expose DAX type internally and through sysfs.  From Toshi and Yigal
    
    * 'for-4.8/core' of git://git.kernel.dk/linux-block: (76 commits)
      block: Fix front merge check
      block: do not merge requests without consulting with io scheduler
      block: Fix spelling in a source code comment
      block: expose QUEUE_FLAG_DAX in sysfs
      block: add QUEUE_FLAG_DAX for devices to advertise their DAX support
      Btrfs: fix comparison in __btrfs_map_block()
      block: atari: Return early for unsupported sector size
      Doc: block: Fix a typo in queue-sysfs.txt
      cfq-iosched: Charge at least 1 jiffie instead of 1 ns
      cfq-iosched: Fix regression in bonnie++ rewrite performance
      cfq-iosched: Convert slice_resid from u64 to s64
      block: Convert fifo_time from ulong to u64
      blktrace: avoid using timespec
      block/blk-cgroup.c: Declare local symbols static
      block/bio-integrity.c: Add #include "blk.h"
      block/partition-generic.c: Remove a set-but-not-used variable
      block: bio: kill BIO_MAX_SIZE
      cfq-iosched: temporarily boost queue priority for idle classes
      block: drbd: avoid to use BIO_MAX_SIZE
      block: bio: remove BIO_MAX_SECTORS
      ...

commit 81a75f6781deb7a3b5274b4c683e327e5cb5b883
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:54 2016 -0500

    btrfs: use bio fields for op and flags
    
    The bio REQ_OP and bi_rw rq_flag_bits are now always setup, so there is
    no need to pass around the rq_flag_bits bits too. btrfs users should
    should access the bio insead.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1baf19c9b79d..fb9dcc9f46be 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -63,16 +63,16 @@ struct btrfs_root;
 struct btrfs_io_bio;
 struct io_failure_record;
 
-typedef	int (extent_submit_bio_hook_t)(struct inode *inode, int rw,
-				       struct bio *bio, int mirror_num,
-				       unsigned long bio_flags, u64 bio_offset);
+typedef	int (extent_submit_bio_hook_t)(struct inode *inode, struct bio *bio,
+				       int mirror_num, unsigned long bio_flags,
+				       u64 bio_offset);
 struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, struct page *locked_page,
 			     u64 start, u64 end, int *page_started,
 			     unsigned long *nr_written);
 	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	extent_submit_bio_hook_t *submit_bio_hook;
-	int (*merge_bio_hook)(int rw, struct page *page, unsigned long offset,
+	int (*merge_bio_hook)(struct page *page, unsigned long offset,
 			      size_t size, struct bio *bio,
 			      unsigned long bio_flags);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);

commit b9ef22dedde08ab1b4ccd5f53344984c4dcb89f4
Author: Feifei Xu <xufeifei@linux.vnet.ibm.com>
Date:   Wed Jun 1 19:18:25 2016 +0800

    Btrfs: self-tests: Support non-4k page size
    
    self-tests code assumes 4k as the sectorsize and nodesize. This commit
    fix hardcoded 4K. Enables the self-tests code to be executed on non-4k
    page sized systems (e.g. ppc64).
    
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Feifei Xu <xufeifei@linux.vnet.ibm.com>
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1baf19c9b79d..c0c1c4fef6ce 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -348,7 +348,7 @@ struct extent_buffer *alloc_extent_buffer(struct btrfs_fs_info *fs_info,
 struct extent_buffer *__alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
 						  u64 start, unsigned long len);
 struct extent_buffer *alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
-						u64 start);
+						u64 start, u32 nodesize);
 struct extent_buffer *btrfs_clone_extent_buffer(struct extent_buffer *src);
 struct extent_buffer *find_extent_buffer(struct btrfs_fs_info *fs_info,
 					 u64 start);
@@ -468,5 +468,5 @@ noinline u64 find_lock_delalloc_range(struct inode *inode,
 				      u64 *end, u64 max_bytes);
 #endif
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
-					       u64 start);
+					       u64 start, u32 nodesize);
 #endif

commit 42f31734eb7658fd01fb186d56312be869450a42
Merge: e73440868fde 0132761017e0
Author: David Sterba <dsterba@suse.com>
Date:   Wed May 25 22:51:03 2016 +0200

    Merge branch 'cleanups-4.7' into for-chris-4.7-20160525

commit 58409edd2d5cc24716cb9ce690803696c5118503
Author: David Sterba <dsterba@suse.com>
Date:   Wed May 4 11:46:10 2016 +0200

    btrfs: kill unused writepage_io_hook callback
    
    It seems to be long time unused, since 2008 and
    6885f308b5570 ("Btrfs: Misc 2.6.25 updates").
    
    Propagating the removal touches some code but has no functional effect.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b5e0ade90e88..981f402bf754 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -71,7 +71,6 @@ struct extent_io_ops {
 			     u64 start, u64 end, int *page_started,
 			     unsigned long *nr_written);
 	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
-	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
 	extent_submit_bio_hook_t *submit_bio_hook;
 	int (*merge_bio_hook)(int rw, struct page *page, unsigned long offset,
 			      size_t size, struct bio *bio,

commit 210aa27768bec4297a9d6ad0e5cab45935c775e9
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to convert_extent_bit
    
    Single caller passes GFP_NOFS. We can get rid of the
    gfpflags_allow_blocking checks as NOFS can block but does not recurse to
    filesystem through reclaim.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 94b376446042..9c1f160c5984 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -287,7 +287,7 @@ static inline int clear_extent_dirty(struct extent_io_tree *tree, u64 start,
 
 int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		       unsigned bits, unsigned clear_bits,
-		       struct extent_state **cached_state, gfp_t mask);
+		       struct extent_state **cached_state);
 
 static inline int set_extent_delalloc(struct extent_io_tree *tree, u64 start,
 		u64 end, struct extent_state **cached_state)

commit 2c53b912ae317e560bce1fc446e76915a5b30587
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to set_record_extent_bits
    
    Single caller passes GFP_NOFS.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 566cf86d7e63..94b376446042 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -252,8 +252,7 @@ static inline int clear_extent_bits(struct extent_io_tree *tree, u64 start,
 }
 
 int set_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-			   unsigned bits, gfp_t mask,
-			   struct extent_changeset *changeset);
+			   unsigned bits, struct extent_changeset *changeset);
 int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   unsigned bits, u64 *failed_start,
 		   struct extent_state **cached_state, gfp_t mask);

commit 3744dbeb7033825e53b919ae0887e08e924841a9
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to set_extent_new
    
    Single caller passes GFP_NOFS.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a1cf4b1dd290..566cf86d7e63 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -307,9 +307,10 @@ static inline int set_extent_defrag(struct extent_io_tree *tree, u64 start,
 }
 
 static inline int set_extent_new(struct extent_io_tree *tree, u64 start,
-		u64 end, gfp_t mask)
+		u64 end)
 {
-	return set_extent_bit(tree, start, end, EXTENT_NEW, NULL, NULL, mask);
+	return set_extent_bit(tree, start, end, EXTENT_NEW, NULL, NULL,
+			GFP_NOFS);
 }
 
 static inline int set_extent_uptodate(struct extent_io_tree *tree, u64 start,

commit 018ed4f788870fdf6e625d04aa287080bdc8a54f
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to set_extent_defrag
    
    Single caller passes GFP_NOFS.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e99a6befdbf5..a1cf4b1dd290 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -299,11 +299,11 @@ static inline int set_extent_delalloc(struct extent_io_tree *tree, u64 start,
 }
 
 static inline int set_extent_defrag(struct extent_io_tree *tree, u64 start,
-		u64 end, struct extent_state **cached_state, gfp_t mask)
+		u64 end, struct extent_state **cached_state)
 {
 	return set_extent_bit(tree, start, end,
 			      EXTENT_DELALLOC | EXTENT_UPTODATE | EXTENT_DEFRAG,
-			      NULL, cached_state, mask);
+			      NULL, cached_state, GFP_NOFS);
 }
 
 static inline int set_extent_new(struct extent_io_tree *tree, u64 start,

commit 7cd8c7527cb3ad3b397fecfa1bdc8eec9fa33dd8
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to set_extent_delalloc
    
    Callers pass GFP_NOFS and tests pass GFP_KERNEL, but using NOFS there
    does not hurt. No need to pass the flags around.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 9e987ee03361..e99a6befdbf5 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -291,11 +291,11 @@ int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		       struct extent_state **cached_state, gfp_t mask);
 
 static inline int set_extent_delalloc(struct extent_io_tree *tree, u64 start,
-		u64 end, struct extent_state **cached_state, gfp_t mask)
+		u64 end, struct extent_state **cached_state)
 {
 	return set_extent_bit(tree, start, end,
 			      EXTENT_DELALLOC | EXTENT_UPTODATE,
-			      NULL, cached_state, mask);
+			      NULL, cached_state, GFP_NOFS);
 }
 
 static inline int set_extent_defrag(struct extent_io_tree *tree, u64 start,

commit af6f8f604d44e05f98ed45a69830547ed133adf8
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to clear_extent_dirty
    
    Callers pass GFP_NOFS. No need to pass the flags around.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b7c258c9fa2d..9e987ee03361 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -279,11 +279,11 @@ static inline int set_extent_dirty(struct extent_io_tree *tree, u64 start,
 }
 
 static inline int clear_extent_dirty(struct extent_io_tree *tree, u64 start,
-		u64 end, gfp_t mask)
+		u64 end)
 {
 	return clear_extent_bit(tree, start, end,
 				EXTENT_DIRTY | EXTENT_DELALLOC |
-				EXTENT_DO_ACCOUNTING, 0, 0, NULL, mask);
+				EXTENT_DO_ACCOUNTING, 0, 0, NULL, GFP_NOFS);
 }
 
 int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,

commit f734c44a1bfffd762f6f5829cb41224d267b80d9
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to clear_record_extent_bits
    
    Callers pass GFP_NOFS. No need to pass the flags around.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 90c5c8176162..b7c258c9fa2d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -221,8 +221,7 @@ int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   unsigned bits, int filled,
 		   struct extent_state *cached_state);
 int clear_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-			     unsigned bits, gfp_t mask,
-			     struct extent_changeset *changeset);
+		unsigned bits, struct extent_changeset *changeset);
 int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		     unsigned bits, int wake, int delete,
 		     struct extent_state **cached, gfp_t mask);

commit 91166212e0ffbb4db50aa8a238548e967008b33d
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to clear_extent_bits
    
    Callers pass GFP_NOFS and GFP_KERNEL. No need to pass the flags around.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 447c6e6ff88c..90c5c8176162 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -241,14 +241,15 @@ static inline int unlock_extent_cached(struct extent_io_tree *tree, u64 start,
 }
 
 static inline int clear_extent_bits(struct extent_io_tree *tree, u64 start,
-		u64 end, unsigned bits, gfp_t mask)
+		u64 end, unsigned bits)
 {
 	int wake = 0;
 
 	if (bits & EXTENT_LOCKED)
 		wake = 1;
 
-	return clear_extent_bit(tree, start, end, bits, wake, 0, NULL, mask);
+	return clear_extent_bit(tree, start, end, bits, wake, 0, NULL,
+			GFP_NOFS);
 }
 
 int set_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,

commit ceeb0ae7bf42a3deaaaee981d2da02e5d3ad2b0f
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to set_extent_bits
    
    All callers pass GFP_NOFS.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b5e0ade90e88..447c6e6ff88c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -259,9 +259,9 @@ int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   struct extent_state **cached_state, gfp_t mask);
 
 static inline int set_extent_bits(struct extent_io_tree *tree, u64 start,
-		u64 end, unsigned bits, gfp_t mask)
+		u64 end, unsigned bits)
 {
-	return set_extent_bit(tree, start, end, bits, NULL, NULL, mask);
+	return set_extent_bit(tree, start, end, bits, NULL, NULL, GFP_NOFS);
 }
 
 static inline int clear_extent_uptodate(struct extent_io_tree *tree, u64 start,

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 5dbf92e68fbd..b5e0ade90e88 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -120,7 +120,7 @@ struct extent_state {
 };
 
 #define INLINE_EXTENT_BUFFER_PAGES 16
-#define MAX_INLINE_EXTENT_BUFFER_SIZE (INLINE_EXTENT_BUFFER_PAGES * PAGE_CACHE_SIZE)
+#define MAX_INLINE_EXTENT_BUFFER_SIZE (INLINE_EXTENT_BUFFER_PAGES * PAGE_SIZE)
 struct extent_buffer {
 	u64 start;
 	unsigned long len;
@@ -365,8 +365,8 @@ void wait_on_extent_buffer_writeback(struct extent_buffer *eb);
 
 static inline unsigned long num_extent_pages(u64 start, u64 len)
 {
-	return ((start + len + PAGE_CACHE_SIZE - 1) >> PAGE_CACHE_SHIFT) -
-		(start >> PAGE_CACHE_SHIFT);
+	return ((start + len + PAGE_SIZE - 1) >> PAGE_SHIFT) -
+		(start >> PAGE_SHIFT);
 }
 
 static inline void extent_buffer_get(struct extent_buffer *eb)

commit f004fae0cfeb96d33240eb5471f14cb6fbbd4eea
Merge: 675d276b322b f827ba9a641b
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:33 2016 +0100

    Merge branch 'cleanups-4.6' into for-chris-4.6

commit 47dc196ae719c197b961c09d72d1b5ab90c66dc5
Author: David Sterba <dsterba@suse.com>
Date:   Thu Feb 11 13:24:13 2016 +0100

    btrfs: use proper type for failrec in extent_state
    
    We use the private member of extent_state to store the failrec and play
    pointless pointer games.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 0377413bd4b9..98a25a100674 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -62,6 +62,7 @@
 struct extent_state;
 struct btrfs_root;
 struct btrfs_io_bio;
+struct io_failure_record;
 
 typedef	int (extent_submit_bio_hook_t)(struct inode *inode, int rw,
 				       struct bio *bio, int mirror_num,
@@ -112,8 +113,7 @@ struct extent_state {
 	atomic_t refs;
 	unsigned state;
 
-	/* for use by the FS */
-	u64 private;
+	struct io_failure_record *failrec;
 
 #ifdef CONFIG_BTRFS_DEBUG
 	struct list_head leak_list;
@@ -345,7 +345,6 @@ int extent_readpages(struct extent_io_tree *tree,
 		     get_extent_t get_extent);
 int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 		__u64 start, __u64 len, get_extent_t *get_extent);
-int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);
 void set_page_extent_mapped(struct page *page);
 
 struct extent_buffer *alloc_extent_buffer(struct btrfs_fs_info *fs_info,

commit 7f042a8370a5bb7e29a6a6372e8180a56d44aa5c
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Jan 27 19:17:20 2016 +0000

    Btrfs: remove no longer used function extent_read_full_page_nolock()
    
    Not needed after the previous patch named
    "Btrfs: fix page reading in extent_same ioctl leading to csum errors".
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 0377413bd4b9..880d5292e972 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -29,7 +29,6 @@
  */
 #define EXTENT_BIO_COMPRESSED 1
 #define EXTENT_BIO_TREE_LOG 2
-#define EXTENT_BIO_PARENT_LOCKED 4
 #define EXTENT_BIO_FLAG_SHIFT 16
 
 /* these are bit numbers for test/set bit */
@@ -210,8 +209,6 @@ static inline int lock_extent(struct extent_io_tree *tree, u64 start, u64 end)
 int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent, int mirror_num);
-int extent_read_full_page_nolock(struct extent_io_tree *tree, struct page *page,
-				 get_extent_t *get_extent, int mirror_num);
 int __init extent_io_init(void);
 void extent_io_exit(void);
 

commit f0f76413d332d74446d0ee9535a29a900c4f63e4
Merge: a53fe2576955 f7d3d2f99eea
Author: Chris Mason <clm@fb.com>
Date:   Wed Dec 23 13:29:09 2015 -0800

    Merge branch 'freespace-4.5' into for-linus-4.5

commit bb9d687618695e8291f1e6209eb3211d231f97bb
Merge: 13d5d15d6301 cd716d8fea12
Author: Chris Mason <clm@fb.com>
Date:   Wed Dec 23 13:17:42 2015 -0800

    Merge branch 'dev/simplify-set-bit' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.5
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit f7d3d2f99eeaa9f5c111965b1516972f4fc5e449
Merge: 9f9499ae8e64 70f6d82ec73c
Author: Chris Mason <clm@fb.com>
Date:   Fri Dec 18 11:11:10 2015 -0800

    Merge branch 'freespace-tree' into for-linus-4.5
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 0f3312295d3ce1d82392244236a52b3b663480ef
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Sep 29 20:50:31 2015 -0700

    Btrfs: add extent buffer bitmap sanity tests
    
    Sanity test the extent buffer bitmap operations (test, set, and clear)
    against the equivalent standard kernel operations.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 9185a20081d7..9f8d7d1a7015 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -263,8 +263,10 @@ void set_page_extent_mapped(struct page *page);
 
 struct extent_buffer *alloc_extent_buffer(struct btrfs_fs_info *fs_info,
 					  u64 start);
+struct extent_buffer *__alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
+						  u64 start, unsigned long len);
 struct extent_buffer *alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
-		u64 start);
+						u64 start);
 struct extent_buffer *btrfs_clone_extent_buffer(struct extent_buffer *src);
 struct extent_buffer *find_extent_buffer(struct btrfs_fs_info *fs_info,
 					 u64 start);

commit 3e1e8bb770dba29645b302c5499ffcb8e3906712
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Sep 29 20:50:30 2015 -0700

    Btrfs: add extent buffer bitmap operations
    
    These are going to be used for the free space tree bitmap items.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c668f36898d3..9185a20081d7 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -309,6 +309,12 @@ void memmove_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
 			   unsigned long src_offset, unsigned long len);
 void memset_extent_buffer(struct extent_buffer *eb, char c,
 			  unsigned long start, unsigned long len);
+int extent_buffer_test_bit(struct extent_buffer *eb, unsigned long start,
+			   unsigned long pos);
+void extent_buffer_bitmap_set(struct extent_buffer *eb, unsigned long start,
+			      unsigned long pos, unsigned long len);
+void extent_buffer_bitmap_clear(struct extent_buffer *eb, unsigned long start,
+				unsigned long pos, unsigned long len);
 void clear_extent_buffer_dirty(struct extent_buffer *eb);
 int set_extent_buffer_dirty(struct extent_buffer *eb);
 int set_extent_buffer_uptodate(struct extent_buffer *eb);

commit f6311572762a9ccaa533e60bf7929d63be914bde
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 13:08:59 2015 +0100

    btrfs: make extent_range_redirty_for_io return void
    
    Does not return any errors, nor anything from the callgraph. There's a
    BUG_ON but it's a sanity check and not an error condition we could
    recover from.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b0b2d20ffd3c..fbc6448e70e4 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -339,7 +339,7 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long *map_start,
 		      unsigned long *map_len);
 void extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
-int extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
+void extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
 				 struct page *locked_page,
 				 unsigned bits_to_clear,

commit bd1fa4f0b0ddbed05ef98c28048d00db727c4b0e
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 13:08:59 2015 +0100

    btrfs: make extent_range_clear_dirty_for_io return void
    
    Does not return any errors, nor anything from the callgraph. There's a
    BUG_ON but it's a sanity check and not an error condition we could
    recover from.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 81f84f1f488b..b0b2d20ffd3c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -338,7 +338,7 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long min_len, char **map,
 		      unsigned long *map_start,
 		      unsigned long *map_len);
-int extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
+void extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 int extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
 				 struct page *locked_page,

commit b5227c075b5c11d5cf653bac5c01b9f7f03f2a8f
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 13:08:59 2015 +0100

    btrfs: make end_extent_writepage return void
    
    Does not return any errors, nor anything from the callgraph.  The branch
    in end_bio_extent_writepage has been skipped since
    5fd02043553b ("Btrfs: finish ordered extents in their own thread").
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 2d57166e20d0..81f84f1f488b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -357,7 +357,7 @@ int repair_io_failure(struct inode *inode, u64 start, u64 length, u64 logical,
 		      int mirror_num);
 int clean_io_failure(struct inode *inode, u64 start, struct page *page,
 		     unsigned int pg_offset);
-int end_extent_writepage(struct page *page, int err, u64 start, u64 end);
+void end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 int repair_eb_io_failure(struct btrfs_root *root, struct extent_buffer *eb,
 			 int mirror_num);
 

commit a9d93e1778f3a92852d3816cd203cbec179b8813
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 13:08:59 2015 +0100

    btrfs: make extent_clear_unlock_delalloc return void
    
    Does not return any errors, nor anything from the callgraph.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index ad1d28c1cfd4..2d57166e20d0 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -340,7 +340,7 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long *map_len);
 int extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 int extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
-int extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
+void extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
 				 struct page *locked_page,
 				 unsigned bits_to_clear,
 				 unsigned long page_ops);

commit 69ba39272c519a34a4a0169b839ca177bf0f0104
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 13:08:59 2015 +0100

    btrfs: make clear_extent_buffer_uptodate return void
    
    Does not return any errors, nor anything from the callgraph.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 013af0512f1a..ad1d28c1cfd4 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -331,7 +331,7 @@ void memset_extent_buffer(struct extent_buffer *eb, char c,
 void clear_extent_buffer_dirty(struct extent_buffer *eb);
 int set_extent_buffer_dirty(struct extent_buffer *eb);
 void set_extent_buffer_uptodate(struct extent_buffer *eb);
-int clear_extent_buffer_uptodate(struct extent_buffer *eb);
+void clear_extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_under_io(struct extent_buffer *eb);
 int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,

commit 09c25a8cda5baf6537234be0954173a18568423d
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 13:08:59 2015 +0100

    btrfs: make set_extent_buffer_uptodate return void
    
    Does not return any errors, nor anything from the callgraph.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f4c1ae11855f..013af0512f1a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -330,7 +330,7 @@ void memset_extent_buffer(struct extent_buffer *eb, char c,
 			  unsigned long start, unsigned long len);
 void clear_extent_buffer_dirty(struct extent_buffer *eb);
 int set_extent_buffer_dirty(struct extent_buffer *eb);
-int set_extent_buffer_uptodate(struct extent_buffer *eb);
+void set_extent_buffer_uptodate(struct extent_buffer *eb);
 int clear_extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_under_io(struct extent_buffer *eb);

commit cd716d8fea125e5531003e66aaf7ca7323277f83
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 14:41:30 2015 +0100

    btrfs: make lock_extent static inline
    
    One call less reduces stack usage, code slightly reduced as well.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e5726a3f9ce5..7cb9fa5845dc 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -199,9 +199,14 @@ int try_release_extent_mapping(struct extent_map_tree *map,
 			       struct extent_io_tree *tree, struct page *page,
 			       gfp_t mask);
 int try_release_extent_buffer(struct page *page);
-int lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		     struct extent_state **cached);
+
+static inline int lock_extent(struct extent_io_tree *tree, u64 start, u64 end)
+{
+	return lock_extent_bits(tree, start, end, NULL);
+}
+
 int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent, int mirror_num);

commit ff13db41f184f8222aca0cb653347ccdd48a057a
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 14:30:40 2015 +0100

    btrfs: drop unused parameter from lock_extent_bits
    
    We've always passed 0. Stack usage will slightly decrease.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 07cae0cccd43..e5726a3f9ce5 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -201,7 +201,7 @@ int try_release_extent_mapping(struct extent_map_tree *map,
 int try_release_extent_buffer(struct page *page);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		     unsigned bits, struct extent_state **cached);
+		     struct extent_state **cached);
 int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent, int mirror_num);

commit e83b1d91f872a4cf7bf0d3528044fc9e43260e2b
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 14:08:11 2015 +0100

    btrfs: make clear_extent_bit helpers static inline
    
    The funcions just wrap the clear_extent_bit API and generate function
    calls. This increases stack consumption and may negatively affect
    performance due to icache misses. We can simply make the helpers static
    inline and keep the type checking and API untouched. The code slightly
    decreases:
    
       text    data     bss     dec     hex filename
     938667   43670   23144 1005481   f57a9 fs/btrfs/btrfs.ko.before
     939651   43670   23144 1006465   f5b81 fs/btrfs/btrfs.ko.after
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4b89ee583782..07cae0cccd43 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -202,9 +202,6 @@ int try_release_extent_buffer(struct page *page);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		     unsigned bits, struct extent_state **cached);
-int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end);
-int unlock_extent_cached(struct extent_io_tree *tree, u64 start, u64 end,
-			 struct extent_state **cached, gfp_t mask);
 int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent, int mirror_num);
@@ -221,8 +218,6 @@ void free_extent_state(struct extent_state *state);
 int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   unsigned bits, int filled,
 		   struct extent_state *cached_state);
-int clear_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		      unsigned bits, gfp_t mask);
 int clear_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 			     unsigned bits, gfp_t mask,
 			     struct extent_changeset *changeset);
@@ -230,6 +225,30 @@ int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		     unsigned bits, int wake, int delete,
 		     struct extent_state **cached, gfp_t mask);
 
+static inline int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end)
+{
+	return clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, NULL,
+				GFP_NOFS);
+}
+
+static inline int unlock_extent_cached(struct extent_io_tree *tree, u64 start,
+		u64 end, struct extent_state **cached, gfp_t mask)
+{
+	return clear_extent_bit(tree, start, end, EXTENT_LOCKED, 1, 0, cached,
+				mask);
+}
+
+static inline int clear_extent_bits(struct extent_io_tree *tree, u64 start,
+		u64 end, unsigned bits, gfp_t mask)
+{
+	int wake = 0;
+
+	if (bits & EXTENT_LOCKED)
+		wake = 1;
+
+	return clear_extent_bit(tree, start, end, bits, wake, 0, NULL, mask);
+}
+
 int set_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 			   unsigned bits, gfp_t mask,
 			   struct extent_changeset *changeset);
@@ -243,8 +262,12 @@ static inline int set_extent_bits(struct extent_io_tree *tree, u64 start,
 	return set_extent_bit(tree, start, end, bits, NULL, NULL, mask);
 }
 
-int clear_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
-			  struct extent_state **cached_state, gfp_t mask);
+static inline int clear_extent_uptodate(struct extent_io_tree *tree, u64 start,
+		u64 end, struct extent_state **cached_state, gfp_t mask)
+{
+	return clear_extent_bit(tree, start, end, EXTENT_UPTODATE, 0, 0,
+				cached_state, mask);
+}
 
 static inline int set_extent_dirty(struct extent_io_tree *tree, u64 start,
 		u64 end, gfp_t mask)
@@ -253,8 +276,14 @@ static inline int set_extent_dirty(struct extent_io_tree *tree, u64 start,
 			      NULL, mask);
 }
 
-int clear_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
-		       gfp_t mask);
+static inline int clear_extent_dirty(struct extent_io_tree *tree, u64 start,
+		u64 end, gfp_t mask)
+{
+	return clear_extent_bit(tree, start, end,
+				EXTENT_DIRTY | EXTENT_DELALLOC |
+				EXTENT_DO_ACCOUNTING, 0, 0, NULL, mask);
+}
+
 int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		       unsigned bits, unsigned clear_bits,
 		       struct extent_state **cached_state, gfp_t mask);

commit c63179556af1335585e53cd8a23da40bf69cb2e2
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 14:08:11 2015 +0100

    btrfs: make set_extent_bit helpers static inline
    
    The funcions just wrap the set_extent_bit API and generate function
    calls. This increases stack consumption and may negatively affect
    performance due to icache misses. We can simply make the helpers static
    inline and keep the type checking and API untouched. The code slightly
    increases:
    
       text    data     bss     dec     hex filename
     938427   43670   23144 1005241   f56b9 fs/btrfs/btrfs.ko.before
     938667   43670   23144 1005481   f57a9 fs/btrfs/btrfs.ko
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f4c1ae11855f..4b89ee583782 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -229,31 +229,65 @@ int clear_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		     unsigned bits, int wake, int delete,
 		     struct extent_state **cached, gfp_t mask);
-int set_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		    unsigned bits, gfp_t mask);
+
 int set_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 			   unsigned bits, gfp_t mask,
 			   struct extent_changeset *changeset);
 int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   unsigned bits, u64 *failed_start,
 		   struct extent_state **cached_state, gfp_t mask);
-int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
-			struct extent_state **cached_state, gfp_t mask);
+
+static inline int set_extent_bits(struct extent_io_tree *tree, u64 start,
+		u64 end, unsigned bits, gfp_t mask)
+{
+	return set_extent_bit(tree, start, end, bits, NULL, NULL, mask);
+}
+
 int clear_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
 			  struct extent_state **cached_state, gfp_t mask);
-int set_extent_new(struct extent_io_tree *tree, u64 start, u64 end,
-		   gfp_t mask);
-int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
-		     gfp_t mask);
+
+static inline int set_extent_dirty(struct extent_io_tree *tree, u64 start,
+		u64 end, gfp_t mask)
+{
+	return set_extent_bit(tree, start, end, EXTENT_DIRTY, NULL,
+			      NULL, mask);
+}
+
 int clear_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		       gfp_t mask);
 int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		       unsigned bits, unsigned clear_bits,
 		       struct extent_state **cached_state, gfp_t mask);
-int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
-			struct extent_state **cached_state, gfp_t mask);
-int set_extent_defrag(struct extent_io_tree *tree, u64 start, u64 end,
-		      struct extent_state **cached_state, gfp_t mask);
+
+static inline int set_extent_delalloc(struct extent_io_tree *tree, u64 start,
+		u64 end, struct extent_state **cached_state, gfp_t mask)
+{
+	return set_extent_bit(tree, start, end,
+			      EXTENT_DELALLOC | EXTENT_UPTODATE,
+			      NULL, cached_state, mask);
+}
+
+static inline int set_extent_defrag(struct extent_io_tree *tree, u64 start,
+		u64 end, struct extent_state **cached_state, gfp_t mask)
+{
+	return set_extent_bit(tree, start, end,
+			      EXTENT_DELALLOC | EXTENT_UPTODATE | EXTENT_DEFRAG,
+			      NULL, cached_state, mask);
+}
+
+static inline int set_extent_new(struct extent_io_tree *tree, u64 start,
+		u64 end, gfp_t mask)
+{
+	return set_extent_bit(tree, start, end, EXTENT_NEW, NULL, NULL, mask);
+}
+
+static inline int set_extent_uptodate(struct extent_io_tree *tree, u64 start,
+		u64 end, struct extent_state **cached_state, gfp_t mask)
+{
+	return set_extent_bit(tree, start, end, EXTENT_UPTODATE, NULL,
+			      cached_state, mask);
+}
+
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
 			  u64 *start_ret, u64 *end_ret, unsigned bits,
 			  struct extent_state **cached_state);

commit 524725537023bb25a371722b1329446e5a2adcdb
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Oct 12 16:05:40 2015 +0800

    btrfs: qgroup: Introduce btrfs_qgroup_reserve_data function
    
    Introduce a new function, btrfs_qgroup_reserve_data(), which will use
    io_tree to accurate qgroup reserve, to avoid reserved space leaking.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 51e1b7143256..f4c1ae11855f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -19,6 +19,7 @@
 #define EXTENT_NEED_WAIT	(1U << 13)
 #define EXTENT_DAMAGED		(1U << 14)
 #define EXTENT_NORESERVE	(1U << 15)
+#define EXTENT_QGROUP_RESERVED	(1U << 16)
 #define EXTENT_IOBITS		(EXTENT_LOCKED | EXTENT_WRITEBACK)
 #define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
 

commit fefdc55702a5f9f99778b6bdce4c4e1185ff943f
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Oct 12 15:35:38 2015 +0800

    btrfs: extent_io: Introduce new function clear_record_extent_bits()
    
    Introduce new function clear_record_extent_bits(), which will clear bits
    for given range and record the details about which ranges are cleared
    and how many bytes in total it changes.
    
    This provides the basis for later qgroup reserve codes.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4a7c9d9fbb4f..51e1b7143256 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -222,6 +222,9 @@ int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   struct extent_state *cached_state);
 int clear_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		      unsigned bits, gfp_t mask);
+int clear_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
+			     unsigned bits, gfp_t mask,
+			     struct extent_changeset *changeset);
 int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		     unsigned bits, int wake, int delete,
 		     struct extent_state **cached, gfp_t mask);

commit d38ed27f0442c8cd520e093081127949d4bcf9bc
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Oct 12 14:53:37 2015 +0800

    btrfs: extent_io: Introduce new function set_record_extent_bits
    
    Introduce new function set_record_extent_bits(), which will not only set
    given bits, but also record how many bytes are changed, and detailed
    range info.
    
    This is quite important for later qgroup reserve framework.
    The number of bytes will be used to do qgroup reserve, and detailed
    range info will be used to cleanup for EQUOT case.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3107a6eb8e78..4a7c9d9fbb4f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -227,6 +227,9 @@ int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		     struct extent_state **cached, gfp_t mask);
 int set_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		    unsigned bits, gfp_t mask);
+int set_record_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
+			   unsigned bits, gfp_t mask,
+			   struct extent_changeset *changeset);
 int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   unsigned bits, u64 *failed_start,
 		   struct extent_state **cached_state, gfp_t mask);

commit ac46777213e00e26b9210060586f473368c54da2
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Oct 12 12:08:16 2015 +0800

    btrfs: extent_io: Introduce needed structure for recoding set/clear bits
    
    Add a new structure, extent_change_set, to record how many bytes are
    changed in one set/clear_extent_bits() operation, with detailed changed
    ranges info.
    
    This provides the needed facilities for later qgroup reserve framework.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c668f36898d3..3107a6eb8e78 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -2,6 +2,7 @@
 #define __EXTENTIO__
 
 #include <linux/rbtree.h>
+#include "ulist.h"
 
 /* bits for the extent state */
 #define EXTENT_DIRTY		(1U << 0)
@@ -161,6 +162,17 @@ struct extent_buffer {
 #endif
 };
 
+/*
+ * Structure to record how many bytes and which ranges are set/cleared
+ */
+struct extent_changeset {
+	/* How many bytes are set/cleared in this operation */
+	u64 bytes_changed;
+
+	/* Changed ranges */
+	struct ulist *range_changed;
+};
+
 static inline void extent_set_compress_type(unsigned long *bio_flags,
 					    int compress_type)
 {

commit e8c9f18603f7ce2beca233401e228de730f121fa
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Jan 2 18:23:10 2015 +0100

    btrfs: constify structs with op functions or static definitions
    
    There are some op tables that can be easily made const, similarly the
    sysfs feature and raid tables. This is motivated by PaX CONSTIFY plugin.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 695b0ccfb755..c668f36898d3 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -97,7 +97,7 @@ struct extent_io_tree {
 	u64 dirty_bytes;
 	int track_uptodate;
 	spinlock_t lock;
-	struct extent_io_ops *ops;
+	const struct extent_io_ops *ops;
 };
 
 struct extent_state {

commit 9ee49a047dc53fd21808cbb7f3b6a3345463e834
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Jan 14 19:52:13 2015 +0100

    btrfs: switch extent_state state to unsigned
    
    Currently there's a 4B hole in the structure between refs and state and there
    are only 16 bits used so we can make it unsigned. This will get a better
    packing and may save some stack space for local variables.
    
    The size of extent_state gets reduced by 8B and there are usually a lot
    of slab objects.
    
    struct extent_state {
            u64                        start;                /*     0     8 */
            u64                        end;                  /*     8     8 */
            struct rb_node             rb_node;              /*    16    24 */
            wait_queue_head_t          wq;                   /*    40    24 */
            /* --- cacheline 1 boundary (64 bytes) --- */
            atomic_t                   refs;                 /*    64     4 */
    
            /* XXX 4 bytes hole, try to pack */
    
            long unsigned int          state;                /*    72     8 */
            u64                        private;              /*    80     8 */
    
            /* size: 88, cachelines: 2, members: 7 */
            /* sum members: 84, holes: 1, sum holes: 4 */
            /* last cacheline: 24 bytes */
    };
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 71268e508b7a..695b0ccfb755 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -4,22 +4,22 @@
 #include <linux/rbtree.h>
 
 /* bits for the extent state */
-#define EXTENT_DIRTY 1
-#define EXTENT_WRITEBACK (1 << 1)
-#define EXTENT_UPTODATE (1 << 2)
-#define EXTENT_LOCKED (1 << 3)
-#define EXTENT_NEW (1 << 4)
-#define EXTENT_DELALLOC (1 << 5)
-#define EXTENT_DEFRAG (1 << 6)
-#define EXTENT_BOUNDARY (1 << 9)
-#define EXTENT_NODATASUM (1 << 10)
-#define EXTENT_DO_ACCOUNTING (1 << 11)
-#define EXTENT_FIRST_DELALLOC (1 << 12)
-#define EXTENT_NEED_WAIT (1 << 13)
-#define EXTENT_DAMAGED (1 << 14)
-#define EXTENT_NORESERVE (1 << 15)
-#define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
-#define EXTENT_CTLBITS (EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
+#define EXTENT_DIRTY		(1U << 0)
+#define EXTENT_WRITEBACK	(1U << 1)
+#define EXTENT_UPTODATE		(1U << 2)
+#define EXTENT_LOCKED		(1U << 3)
+#define EXTENT_NEW		(1U << 4)
+#define EXTENT_DELALLOC		(1U << 5)
+#define EXTENT_DEFRAG		(1U << 6)
+#define EXTENT_BOUNDARY		(1U << 9)
+#define EXTENT_NODATASUM	(1U << 10)
+#define EXTENT_DO_ACCOUNTING	(1U << 11)
+#define EXTENT_FIRST_DELALLOC	(1U << 12)
+#define EXTENT_NEED_WAIT	(1U << 13)
+#define EXTENT_DAMAGED		(1U << 14)
+#define EXTENT_NORESERVE	(1U << 15)
+#define EXTENT_IOBITS		(EXTENT_LOCKED | EXTENT_WRITEBACK)
+#define EXTENT_CTLBITS		(EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
 
 /*
  * flags for bio submission. The high bits indicate the compression
@@ -81,9 +81,9 @@ struct extent_io_ops {
 	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
 	void (*set_bit_hook)(struct inode *inode, struct extent_state *state,
-			     unsigned long *bits);
+			     unsigned *bits);
 	void (*clear_bit_hook)(struct inode *inode, struct extent_state *state,
-			       unsigned long *bits);
+			       unsigned *bits);
 	void (*merge_extent_hook)(struct inode *inode,
 				  struct extent_state *new,
 				  struct extent_state *other);
@@ -108,7 +108,7 @@ struct extent_state {
 	/* ADD NEW ELEMENTS AFTER THIS */
 	wait_queue_head_t wq;
 	atomic_t refs;
-	unsigned long state;
+	unsigned state;
 
 	/* for use by the FS */
 	u64 private;
@@ -188,7 +188,7 @@ int try_release_extent_mapping(struct extent_map_tree *map,
 int try_release_extent_buffer(struct page *page);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		     unsigned long bits, struct extent_state **cached);
+		     unsigned bits, struct extent_state **cached);
 int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int unlock_extent_cached(struct extent_io_tree *tree, u64 start, u64 end,
 			 struct extent_state **cached, gfp_t mask);
@@ -202,21 +202,21 @@ void extent_io_exit(void);
 
 u64 count_range_bits(struct extent_io_tree *tree,
 		     u64 *start, u64 search_end,
-		     u64 max_bytes, unsigned long bits, int contig);
+		     u64 max_bytes, unsigned bits, int contig);
 
 void free_extent_state(struct extent_state *state);
 int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		   unsigned long bits, int filled,
+		   unsigned bits, int filled,
 		   struct extent_state *cached_state);
 int clear_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		      unsigned long bits, gfp_t mask);
+		      unsigned bits, gfp_t mask);
 int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		     unsigned long bits, int wake, int delete,
+		     unsigned bits, int wake, int delete,
 		     struct extent_state **cached, gfp_t mask);
 int set_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		    unsigned long bits, gfp_t mask);
+		    unsigned bits, gfp_t mask);
 int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		   unsigned long bits, u64 *failed_start,
+		   unsigned bits, u64 *failed_start,
 		   struct extent_state **cached_state, gfp_t mask);
 int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);
@@ -229,14 +229,14 @@ int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 int clear_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		       gfp_t mask);
 int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		       unsigned long bits, unsigned long clear_bits,
+		       unsigned bits, unsigned clear_bits,
 		       struct extent_state **cached_state, gfp_t mask);
 int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);
 int set_extent_defrag(struct extent_io_tree *tree, u64 start, u64 end,
 		      struct extent_state **cached_state, gfp_t mask);
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
-			  u64 *start_ret, u64 *end_ret, unsigned long bits,
+			  u64 *start_ret, u64 *end_ret, unsigned bits,
 			  struct extent_state **cached_state);
 int extent_invalidatepage(struct extent_io_tree *tree,
 			  struct page *page, unsigned long offset);
@@ -323,7 +323,7 @@ int extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 int extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 int extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
 				 struct page *locked_page,
-				 unsigned long bits_to_clear,
+				 unsigned bits_to_clear,
 				 unsigned long page_ops);
 struct bio *
 btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,

commit ce3e69847e3ec79a38421bfd3d6f554d5e481231
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 03:00:04 2014 +0200

    btrfs: sink parameter len to alloc_extent_buffer
    
    Because we're using globally known nodesize. Do the same for the sanity
    test function variant.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e6553e3d35c8..71268e508b7a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -262,7 +262,7 @@ int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);
 void set_page_extent_mapped(struct page *page);
 
 struct extent_buffer *alloc_extent_buffer(struct btrfs_fs_info *fs_info,
-					  u64 start, unsigned long len);
+					  u64 start);
 struct extent_buffer *alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
 		u64 start);
 struct extent_buffer *btrfs_clone_extent_buffer(struct extent_buffer *src);
@@ -378,5 +378,5 @@ noinline u64 find_lock_delalloc_range(struct inode *inode,
 				      u64 *end, u64 max_bytes);
 #endif
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
-					       u64 start, unsigned long len);
+					       u64 start);
 #endif

commit 3f556f7853ec4845a7c219d026cbcdf4cfa8cea7
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 03:20:26 2014 +0200

    btrfs: unify extent buffer allocation api
    
    Make the extent buffer allocation interface consistent.  Cloned eb will
    set a valid fs_info.  For dummy eb, we can drop the length parameter and
    set it from fs_info.
    
    The built-in sanity checks may pass a NULL fs_info that's queried for
    nodesize, but we know it's 4096.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index ece9ce87edff..e6553e3d35c8 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -263,7 +263,8 @@ void set_page_extent_mapped(struct page *page);
 
 struct extent_buffer *alloc_extent_buffer(struct btrfs_fs_info *fs_info,
 					  u64 start, unsigned long len);
-struct extent_buffer *alloc_dummy_extent_buffer(u64 start, unsigned long len);
+struct extent_buffer *alloc_dummy_extent_buffer(struct btrfs_fs_info *fs_info,
+		u64 start);
 struct extent_buffer *btrfs_clone_extent_buffer(struct extent_buffer *src);
 struct extent_buffer *find_extent_buffer(struct btrfs_fs_info *fs_info,
 					 u64 start);

commit 704de49d2be665be44933300f60023c889832fca
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Oct 6 22:14:22 2014 +0100

    Btrfs: set page and mapping error on compressed write failure
    
    If we fail in submit_compressed_extents() before calling btrfs_submit_compressed_write(),
    we start and end the writeback for the pages (clear their dirty flag, unlock them, etc)
    but we don't tag the pages, nor the inode's mapping, with an error. This makes it
    impossible for a caller of filemap_fdatawait_range() (fsync, or transaction commit
    for e.g.) know that there was an error.
    
    Note that the return value of submit_compressed_extents() is useless, as that function
    is executed by a workqueue task and not directly by the fill_delalloc callback. This
    means the writepage/s callbacks of the inode's address space operations don't get that
    return value.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6d4b938be986..ece9ce87edff 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -49,6 +49,7 @@
 #define PAGE_SET_WRITEBACK	(1 << 2)
 #define PAGE_END_WRITEBACK	(1 << 3)
 #define PAGE_SET_PRIVATE2	(1 << 4)
+#define PAGE_SET_ERROR		(1 << 5)
 
 /*
  * page->private values.  Every page that is controlled by the extent

commit 0d4cf4e6bf29033709ae8aba4645d873ed0167cc
Author: Chris Mason <clm@fb.com>
Date:   Tue Oct 7 13:24:20 2014 -0700

    Btrfs: fix compiles when CONFIG_BTRFS_FS_RUN_SANITY_TESTS is off
    
    Commit fccb84c94 moved added some helpers to cleanup our sanity tests,
    but it looks like both Dave and I always compile with the tests enabled.
    
    This fixes things to work when they are turned off too.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f40d67f5866b..6d4b938be986 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -374,7 +374,7 @@ noinline u64 find_lock_delalloc_range(struct inode *inode,
 				      struct extent_io_tree *tree,
 				      struct page *locked_page, u64 *start,
 				      u64 *end, u64 max_bytes);
+#endif
 struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
 					       u64 start, unsigned long len);
 #endif
-#endif

commit bbf65cf0b5b67843ca094df01019222b85af2183
Merge: bf8e8ca6fd4a fccb84c94a97
Author: Chris Mason <clm@fb.com>
Date:   Sat Oct 4 09:56:45 2014 -0700

    Merge branch 'cleanup/misc-for-3.18' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus
    
    Signed-off-by: Chris Mason <clm@fb.com>
    
    Conflicts:
            fs/btrfs/extent_io.c

commit 656f30dba7ab8179c9a2e04293b0c7b383fa9ce9
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Sep 26 12:25:56 2014 +0100

    Btrfs: be aware of btree inode write errors to avoid fs corruption
    
    While we have a transaction ongoing, the VM might decide at any time
    to call btree_inode->i_mapping->a_ops->writepages(), which will start
    writeback of dirty pages belonging to btree nodes/leafs. This call
    might return an error or the writeback might finish with an error
    before we attempt to commit the running transaction. If this happens,
    we might have no way of knowing that such error happened when we are
    committing the transaction - because the pages might no longer be
    marked dirty nor tagged for writeback (if a subsequent modification
    to the extent buffer didn't happen before the transaction commit) which
    makes filemap_fdata[write|wait]_range unable to find such pages (even
    if they're marked with SetPageError).
    So if this happens we must abort the transaction, otherwise we commit
    a super block with btree roots that point to btree nodes/leafs whose
    content on disk is invalid - either garbage or the content of some
    node/leaf from a past generation that got cowed or deleted and is no
    longer valid (for this later case we end up getting error messages like
    "parent transid verify failed on 10826481664 wanted 25748 found 29562"
    when reading btree nodes/leafs from disk).
    
    Note that setting and checking AS_EIO/AS_ENOSPC in the btree inode's
    i_mapping would not be enough because we need to distinguish between
    log tree extents (not fatal) vs non-log tree extents (fatal) and
    because the next call to filemap_fdatawait_range() will catch and clear
    such errors in the mapping - and that call might be from a log sync and
    not from a transaction commit, which means we would not know about the
    error at transaction commit time. Also, checking for the eb flag
    EXTENT_BUFFER_IOERR at transaction commit time isn't done and would
    not be completely reliable, as the eb might be removed from memory and
    read back when trying to get it, which clears that flag right before
    reading the eb's pages from disk, making us not know about the previous
    write error.
    
    Using the new 3 flags for the btree inode also makes us achieve the
    goal of AS_EIO/AS_ENOSPC when writepages() returns success, started
    writeback for all dirty pages and before filemap_fdatawait_range() is
    called, the writeback for all dirty pages had already finished with
    errors - because we were not using AS_EIO/AS_ENOSPC,
    filemap_fdatawait_range() would return success, as it could not know
    that writeback errors happened (the pages were no longer tagged for
    writeback).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 5e91fb9d1764..06f030c0084c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -41,9 +41,10 @@
 #define EXTENT_BUFFER_TREE_REF 5
 #define EXTENT_BUFFER_STALE 6
 #define EXTENT_BUFFER_WRITEBACK 7
-#define EXTENT_BUFFER_IOERR 8
+#define EXTENT_BUFFER_READ_ERR 8        /* read IO error */
 #define EXTENT_BUFFER_DUMMY 9
 #define EXTENT_BUFFER_IN_TREE 10
+#define EXTENT_BUFFER_WRITE_ERR 11    /* write IO error */
 
 /* these are flags for extent_clear_unlock_delalloc */
 #define PAGE_UNLOCK		(1 << 0)
@@ -141,7 +142,9 @@ struct extent_buffer {
 	atomic_t blocking_readers;
 	atomic_t spinning_readers;
 	atomic_t spinning_writers;
-	int lock_nested;
+	short lock_nested;
+	/* >= 0 if eb belongs to a log tree, -1 otherwise */
+	short log_index;
 
 	/* protects write locks */
 	rwlock_t lock;

commit fb85fc9a675738ee2746b51c3aedde944b18ca02
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Jul 31 01:03:53 2014 +0200

    btrfs: kill extent_buffer_page helper
    
    It used to be more complex but now it's just a simple array access.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1e06f0e4a185..63f2b10ee763 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -279,12 +279,6 @@ static inline unsigned long num_extent_pages(u64 start, u64 len)
 		(start >> PAGE_CACHE_SHIFT);
 }
 
-static inline struct page *extent_buffer_page(struct extent_buffer *eb,
-					      unsigned long i)
-{
-	return eb->pages[i];
-}
-
 static inline void extent_buffer_get(struct extent_buffer *eb)
 {
 	atomic_inc(&eb->refs);

commit 01d5bc3789f8464abd13cc44e3cd6df9d17f2802
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Jul 30 00:03:56 2014 +0200

    btrfs: remove unused extent state bits
    
    The last users are long gone.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 5e91fb9d1764..1e06f0e4a185 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -11,8 +11,6 @@
 #define EXTENT_NEW (1 << 4)
 #define EXTENT_DELALLOC (1 << 5)
 #define EXTENT_DEFRAG (1 << 6)
-#define EXTENT_DEFRAG_DONE (1 << 7)
-#define EXTENT_BUFFER_FILLED (1 << 8)
 #define EXTENT_BOUNDARY (1 << 9)
 #define EXTENT_NODATASUM (1 << 10)
 #define EXTENT_DO_ACCOUNTING (1 << 11)
@@ -34,7 +32,6 @@
 
 /* these are bit numbers for test/set bit */
 #define EXTENT_BUFFER_UPTODATE 0
-#define EXTENT_BUFFER_BLOCKING 1
 #define EXTENT_BUFFER_DIRTY 2
 #define EXTENT_BUFFER_CORRUPT 3
 #define EXTENT_BUFFER_READAHEAD 4	/* this got triggered by readahead */
@@ -57,7 +54,6 @@
  * map has page->private set to one.
  */
 #define EXTENT_PAGE_PRIVATE 1
-#define EXTENT_PAGE_PRIVATE_FIRST_PAGE 3
 
 struct extent_state;
 struct btrfs_root;

commit f612496bca664bff6a09a99a9a7506410b6e876e
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 12 18:44:04 2014 +0800

    Btrfs: cleanup the read failure record after write or when the inode is freeing
    
    After the data is written successfully, we should cleanup the read failure record
    in that range because
    - If we set data COW for the file, the range that the failure record pointed to is
      mapped to a new place, so it is invalid.
    - If we set no data COW for the file, and if there is no error during writting,
      the corrupted data is corrected, so the failure record can be removed. And if
      some errors happen on the mirrors, we also needn't worry about it because the
      failure record will be recreated if we read the same place again.
    
    Sometimes, we may fail to correct the data, so the failure records will be left
    in the tree, we need free them when we free the inode or the memory leak happens.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 176a4b1ed520..5e91fb9d1764 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -366,6 +366,7 @@ struct io_failure_record {
 	int in_validation;
 };
 
+void btrfs_free_io_failure_record(struct inode *inode, u64 start, u64 end);
 int btrfs_get_io_failure_record(struct inode *inode, u64 start, u64 end,
 				struct io_failure_record **failrec_ret);
 int btrfs_check_repairable(struct inode *inode, struct bio *failed_bio,

commit 8b110e393c5a6e72d50fcdf9fa7ed8b647cfdfc9
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 12 18:44:03 2014 +0800

    Btrfs: implement repair function when direct read fails
    
    This patch implement data repair function when direct read fails.
    
    The detail of the implementation is:
    - When we find the data is not right, we try to read the data from the other
      mirror.
    - When the io on the mirror ends, we will insert the endio work into the
      dedicated btrfs workqueue, not common read endio workqueue, because the
      original endio work is still blocked in the btrfs endio workqueue, if we
      insert the endio work of the io on the mirror into that workqueue, deadlock
      would happen.
    - After we get right data, we write it back to the corrupted mirror.
    - And if the data on the new mirror is still corrupted, we will try next
      mirror until we read right data or all the mirrors are traversed.
    - After the above work, we set the uptodate flag according to the result.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index bf0597f3a9e7..176a4b1ed520 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -341,6 +341,8 @@ struct btrfs_fs_info;
 int repair_io_failure(struct inode *inode, u64 start, u64 length, u64 logical,
 		      struct page *page, unsigned int pg_offset,
 		      int mirror_num);
+int clean_io_failure(struct inode *inode, u64 start, struct page *page,
+		     unsigned int pg_offset);
 int end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 int repair_eb_io_failure(struct btrfs_root *root, struct extent_buffer *eb,
 			 int mirror_num);
@@ -371,7 +373,8 @@ int btrfs_check_repairable(struct inode *inode, struct bio *failed_bio,
 struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
 				    struct io_failure_record *failrec,
 				    struct page *page, int pg_offset, int icsum,
-				    bio_end_io_t *endio_func);
+				    bio_end_io_t *endio_func, void *data);
+int free_io_failure(struct inode *inode, struct io_failure_record *rec);
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 noinline u64 find_lock_delalloc_range(struct inode *inode,
 				      struct extent_io_tree *tree,

commit 1203b6813ee84add8b4baa6d75e50ba85517e99c
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 12 18:44:01 2014 +0800

    Btrfs: modify clean_io_failure and make it suit direct io
    
    We could not use clean_io_failure in the direct IO path because it got the
    filesystem information from the page structure, but the page in the direct
    IO bio didn't have the filesystem information in its structure. So we need
    modify it and pass all the information it need by parameters.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a82ecbc2b842..bf0597f3a9e7 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -338,9 +338,9 @@ struct bio *btrfs_bio_clone(struct bio *bio, gfp_t gfp_mask);
 
 struct btrfs_fs_info;
 
-int repair_io_failure(struct btrfs_fs_info *fs_info, u64 start,
-			u64 length, u64 logical, struct page *page,
-			unsigned int pg_offset, int mirror_num);
+int repair_io_failure(struct inode *inode, u64 start, u64 length, u64 logical,
+		      struct page *page, unsigned int pg_offset,
+		      int mirror_num);
 int end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 int repair_eb_io_failure(struct btrfs_root *root, struct extent_buffer *eb,
 			 int mirror_num);

commit ffdd2018dd0bbfc0d9855ed811dba67201766a2d
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 12 18:44:00 2014 +0800

    Btrfs: modify repair_io_failure and make it suit direct io
    
    The original code of repair_io_failure was just used for buffered read,
    because it got some filesystem data from page structure, it is safe for
    the page in the page cache. But when we do a direct read, the pages in bio
    are not in the page cache, that is there is no filesystem data in the page
    structure. In order to implement direct read data repair, we need modify
    repair_io_failure and pass all filesystem data it need by function
    parameters.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 75b621b7cd9f..a82ecbc2b842 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -340,7 +340,7 @@ struct btrfs_fs_info;
 
 int repair_io_failure(struct btrfs_fs_info *fs_info, u64 start,
 			u64 length, u64 logical, struct page *page,
-			int mirror_num);
+			unsigned int pg_offset, int mirror_num);
 int end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 int repair_eb_io_failure(struct btrfs_root *root, struct extent_buffer *eb,
 			 int mirror_num);

commit 2fe6303e7cd099334cdb09370cece6bc168de131
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 12 18:43:59 2014 +0800

    Btrfs: split bio_readpage_error into several functions
    
    The data repair function of direct read will be implemented later, and some code
    in bio_readpage_error will be reused, so split bio_readpage_error into
    several functions which will be used in direct read repair later.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 844b4c5029cd..75b621b7cd9f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -344,6 +344,34 @@ int repair_io_failure(struct btrfs_fs_info *fs_info, u64 start,
 int end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 int repair_eb_io_failure(struct btrfs_root *root, struct extent_buffer *eb,
 			 int mirror_num);
+
+/*
+ * When IO fails, either with EIO or csum verification fails, we
+ * try other mirrors that might have a good copy of the data.  This
+ * io_failure_record is used to record state as we go through all the
+ * mirrors.  If another mirror has good data, the page is set up to date
+ * and things continue.  If a good mirror can't be found, the original
+ * bio end_io callback is called to indicate things have failed.
+ */
+struct io_failure_record {
+	struct page *page;
+	u64 start;
+	u64 len;
+	u64 logical;
+	unsigned long bio_flags;
+	int this_mirror;
+	int failed_mirror;
+	int in_validation;
+};
+
+int btrfs_get_io_failure_record(struct inode *inode, u64 start, u64 end,
+				struct io_failure_record **failrec_ret);
+int btrfs_check_repairable(struct inode *inode, struct bio *failed_bio,
+			   struct io_failure_record *failrec, int fail_mirror);
+struct bio *btrfs_create_repair_bio(struct inode *inode, struct bio *failed_bio,
+				    struct io_failure_record *failrec,
+				    struct page *page, int pg_offset, int icsum,
+				    bio_end_io_t *endio_func);
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 noinline u64 find_lock_delalloc_range(struct inode *inode,
 				      struct extent_io_tree *tree,

commit 2a39e5980257c77f48b5c31f9fb483a72a03b213
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Aug 14 12:25:14 2014 +0100

    Btrfs: shrink further sizeof(struct extent_buffer)
    
    The map_start and map_len fields aren't used anywhere, so just remove
    them. On a x86_64 system, this reduced sizeof(struct extent_buffer)
    from 296 bytes to 280 bytes, and therefore 14 extent_buffer structs can
    now fit into a page instead of 13.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1f608166fe67..844b4c5029cd 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -125,8 +125,6 @@ struct extent_state {
 struct extent_buffer {
 	u64 start;
 	unsigned long len;
-	unsigned long map_start;
-	unsigned long map_len;
 	unsigned long bflags;
 	struct btrfs_fs_info *fs_info;
 	spinlock_t refs_lock;

commit 27a3507de91e3dd51a2cf8dca4b33623dd6eaa88
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sun Jul 6 20:09:59 2014 +0100

    Btrfs: reduce size of struct extent_state
    
    The tree field of struct extent_state was only used to figure out if
    an extent state was connected to an inode's io tree or not. For this
    we can just use the rb_node field itself.
    
    On a x86_64 system with this change the sizeof(struct extent_state) is
    reduced from 96 bytes down to 88 bytes, meaning that with a page size
    of 4096 bytes we can now store 46 extent states per page instead of 42.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index ccc264e7bde1..1f608166fe67 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -108,7 +108,6 @@ struct extent_state {
 	struct rb_node rb_node;
 
 	/* ADD NEW ELEMENTS AFTER THIS */
-	struct extent_io_tree *tree;
 	wait_queue_head_t wq;
 	atomic_t refs;
 	unsigned long state;

commit 46fefe41b5360106ebfed228fbfba62f75ad4fcd
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Mon Jun 16 13:14:25 2014 +0100

    Btrfs: remove unused wait queue in struct extent_buffer
    
    The lock_wq wait queue is not used anywhere, therefore just remove it.
    On a x86_64 system, this reduced sizeof(struct extent_buffer) from 320
    bytes down to 296 bytes, which means a 4Kb page can now be used for
    13 extent buffers instead of 12.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 15ce5f2a2b62..ccc264e7bde1 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -158,7 +158,6 @@ struct extent_buffer {
 	 * to unlock
 	 */
 	wait_queue_head_t read_lock_wq;
-	wait_queue_head_t lock_wq;
 	struct page *pages[INLINE_EXTENT_BUFFER_PAGES];
 #ifdef CONFIG_BTRFS_DEBUG
 	struct list_head leak_list;

commit 550ac1d85ef99f3390a6ea87c70b7683647f6110
Author: Gerhard Heift <gerhard@heift.name>
Date:   Thu Jan 30 16:24:01 2014 +0100

    btrfs: new function read_extent_buffer_to_user
    
    This new function reads the content of an extent directly to user memory.
    
    Signed-off-by: Gerhard Heift <Gerhard@Heift.Name>
    Signed-off-by: Chris Mason <clm@fb.com>
    Acked-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 8b63f2d46518..15ce5f2a2b62 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -304,6 +304,9 @@ int memcmp_extent_buffer(struct extent_buffer *eb, const void *ptrv,
 void read_extent_buffer(struct extent_buffer *eb, void *dst,
 			unsigned long start,
 			unsigned long len);
+int read_extent_buffer_to_user(struct extent_buffer *eb, void __user *dst,
+			       unsigned long start,
+			       unsigned long len);
 void write_extent_buffer(struct extent_buffer *eb, const void *src,
 			 unsigned long start, unsigned long len);
 void copy_extent_buffer(struct extent_buffer *dst, struct extent_buffer *src,

commit faa2dbf004e89e8f7ccd28fbe6f07c308417b8ae
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed May 7 17:06:09 2014 -0400

    Btrfs: add sanity tests for new qgroup accounting code
    
    This exercises the various parts of the new qgroup accounting code.  We do some
    basic stuff and do some things with the shared refs to make sure all that code
    works.  I had to add a bunch of infrastructure because I needed to be able to
    insert items into a fake tree without having to do all the hard work myself,
    hopefully this will be usefull in the future.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c488b45237bf..8b63f2d46518 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -350,5 +350,7 @@ noinline u64 find_lock_delalloc_range(struct inode *inode,
 				      struct extent_io_tree *tree,
 				      struct page *locked_page, u64 *start,
 				      u64 *end, u64 max_bytes);
+struct extent_buffer *alloc_test_extent_buffer(struct btrfs_fs_info *fs_info,
+					       u64 start, unsigned long len);
 #endif
 #endif

commit a26e8c9f75b0bfd8cccc9e8f110737b136eb5994
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Mar 28 17:07:27 2014 -0400

    Btrfs: don't clear uptodate if the eb is under IO
    
    So I have an awful exercise script that will run snapshot, balance and
    send/receive in parallel.  This sometimes would crash spectacularly and when it
    came back up the fs would be completely hosed.  Turns out this is because of a
    bad interaction of balance and send/receive.  Send will hold onto its entire
    path for the whole send, but its blocks could get relocated out from underneath
    it, and because it doesn't old tree locks theres nothing to keep this from
    happening.  So it will go to read in a slot with an old transid, and we could
    have re-allocated this block for something else and it could have a completely
    different transid.  But because we think it is invalid we clear uptodate and
    re-read in the block.  If we do this before we actually write out the new block
    we could write back stale data to the fs, and boom we're screwed.
    
    Now we definitely need to fix this disconnect between send and balance, but we
    really really need to not allow ourselves to accidently read in stale data over
    new data.  So make sure we check if the extent buffer is not under io before
    clearing uptodate, this will kick back EIO to the caller instead of reading in
    stale data and keep us from corrupting the fs.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 58b27e5ab521..c488b45237bf 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -320,6 +320,7 @@ int set_extent_buffer_dirty(struct extent_buffer *eb);
 int set_extent_buffer_uptodate(struct extent_buffer *eb);
 int clear_extent_buffer_uptodate(struct extent_buffer *eb);
 int extent_buffer_uptodate(struct extent_buffer *eb);
+int extent_buffer_under_io(struct extent_buffer *eb);
 int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long min_len, char **map,
 		      unsigned long *map_start,

commit f28491e0a6c46d99cbbef0f8ef7e314afa2359c8
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Dec 16 13:24:27 2013 -0500

    Btrfs: move the extent buffer radix tree into the fs_info
    
    I need to create a fake tree to test qgroups and I don't want to have to setup a
    fake btree_inode.  The fact is we only use the radix tree for the fs_info, so
    everybody else who allocates an extent_io_tree is just wasting the space anyway.
    This patch moves the radix tree and its lock into btrfs_fs_info so there is less
    stuff I have to fake to do qgroup sanity tests.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 92e4347315e6..58b27e5ab521 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -95,12 +95,10 @@ struct extent_io_ops {
 
 struct extent_io_tree {
 	struct rb_root state;
-	struct radix_tree_root buffer;
 	struct address_space *mapping;
 	u64 dirty_bytes;
 	int track_uptodate;
 	spinlock_t lock;
-	spinlock_t buffer_lock;
 	struct extent_io_ops *ops;
 };
 
@@ -131,7 +129,7 @@ struct extent_buffer {
 	unsigned long map_start;
 	unsigned long map_len;
 	unsigned long bflags;
-	struct extent_io_tree *tree;
+	struct btrfs_fs_info *fs_info;
 	spinlock_t refs_lock;
 	atomic_t refs;
 	atomic_t io_pages;
@@ -267,11 +265,11 @@ int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);
 void set_page_extent_mapped(struct page *page);
 
-struct extent_buffer *alloc_extent_buffer(struct extent_io_tree *tree,
+struct extent_buffer *alloc_extent_buffer(struct btrfs_fs_info *fs_info,
 					  u64 start, unsigned long len);
 struct extent_buffer *alloc_dummy_extent_buffer(u64 start, unsigned long len);
 struct extent_buffer *btrfs_clone_extent_buffer(struct extent_buffer *src);
-struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
+struct extent_buffer *find_extent_buffer(struct btrfs_fs_info *fs_info,
 					 u64 start);
 void free_extent_buffer(struct extent_buffer *eb);
 void free_extent_buffer_stale(struct extent_buffer *eb);

commit 34b41acec1ccc06373ec584de19618d48ceb09fc
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Dec 13 10:41:51 2013 -0500

    Btrfs: use a bit to track if we're in the radix tree
    
    For creating a dummy in-memory btree I need to be able to use the radix tree to
    keep track of the buffers like normal extent buffers.  With dummy buffers we
    skip the radix tree step, and we still want to do that for the tree mod log
    dummy buffers but for my test buffers we need to be able to remove them from the
    radix tree like normal.  This will give me a way to do that.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 19620c58f096..92e4347315e6 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -43,6 +43,7 @@
 #define EXTENT_BUFFER_WRITEBACK 7
 #define EXTENT_BUFFER_IOERR 8
 #define EXTENT_BUFFER_DUMMY 9
+#define EXTENT_BUFFER_IN_TREE 10
 
 /* these are flags for extent_clear_unlock_delalloc */
 #define PAGE_UNLOCK		(1 << 0)

commit 452c75c3d2187089f6e846710e6ea7883bf30f8a
Author: Chandra Seetharaman <sekharan@us.ibm.com>
Date:   Mon Oct 7 10:45:25 2013 -0500

    Btrfs: Simplify the logic in alloc_extent_buffer() for existing extent buffer case
    
    alloc_extent_buffer() uses radix_tree_lookup() when radix_tree_insert()
    fails with EEXIST. That part of the code is very similar to the code in
    find_extent_buffer(). This patch replaces radix_tree_lookup() and
    surrounding code in alloc_extent_buffer() with find_extent_buffer().
    
    Note that radix_tree_lookup() does not need to be protected by
    tree->buffer_lock. It is protected by eb->refs.
    
    While at it, this patch
      - changes the other usage of radix_tree_lookup() in alloc_extent_buffer()
        with find_extent_buffer() to reduce redundancy.
      - removes the unused argument 'len' to find_extent_buffer().
    
    Signed-Off-by: Chandra Seetharaman <sekharan@us.ibm.com>
    Reviewed-by: Zach Brown <zab@redhat.com>
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f98602eac808..19620c58f096 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -271,7 +271,7 @@ struct extent_buffer *alloc_extent_buffer(struct extent_io_tree *tree,
 struct extent_buffer *alloc_dummy_extent_buffer(u64 start, unsigned long len);
 struct extent_buffer *btrfs_clone_extent_buffer(struct extent_buffer *src);
 struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
-					 u64 start, unsigned long len);
+					 u64 start);
 void free_extent_buffer(struct extent_buffer *eb);
 void free_extent_buffer_stale(struct extent_buffer *eb);
 #define WAIT_NONE	0

commit 294e30fee35d3151d100cfe59e839c2dbc16a374
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Oct 9 12:00:56 2013 -0400

    Btrfs: add tests for find_lock_delalloc_range
    
    So both Liu and I made huge messes of find_lock_delalloc_range trying to fix
    stuff, me first by fixing extent size, then him by fixing something I broke and
    then me again telling him to fix it a different way.  So this is obviously a
    candidate for some testing.  This patch adds a pseudo fs so we can allocate fake
    inodes for tests that need an inode or pages.  Then it addes a bunch of tests to
    make sure find_lock_delalloc_range is acting the way it is supposed to.  With
    this patch and all of our previous patches to find_lock_delalloc_range I am sure
    it is working as expected now.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6dbc645f1f3d..f98602eac808 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -345,4 +345,10 @@ int repair_io_failure(struct btrfs_fs_info *fs_info, u64 start,
 int end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 int repair_eb_io_failure(struct btrfs_root *root, struct extent_buffer *eb,
 			 int mirror_num);
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+noinline u64 find_lock_delalloc_range(struct inode *inode,
+				      struct extent_io_tree *tree,
+				      struct page *locked_page, u64 *start,
+				      u64 *end, u64 max_bytes);
+#endif
 #endif

commit 171170c1c5625cab9687ecf6714e09e0c8a6ed3c
Author: Sergei Trofimovich <slyfox@gentoo.org>
Date:   Wed Aug 14 23:27:46 2013 +0300

    btrfs: mark some local function as 'static'
    
    Cc: Josef Bacik <jbacik@fusionio.com>
    Cc: Chris Mason <chris.mason@fusionio.com>
    Signed-off-by: Sergei Trofimovich <slyfox@gentoo.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3940a0386865..6dbc645f1f3d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -263,7 +263,6 @@ int extent_readpages(struct extent_io_tree *tree,
 		     get_extent_t get_extent);
 int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 		__u64 start, __u64 len, get_extent_t *get_extent);
-int set_state_private(struct extent_io_tree *tree, u64 start, u64 private);
 int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);
 void set_page_extent_mapped(struct page *page);
 

commit 4b384318a74e38eb248f74f9a92a700d2ce841f1
Author: Mark Fasheh <mfasheh@suse.de>
Date:   Tue Aug 6 11:42:50 2013 -0700

    btrfs: Introduce extent_read_full_page_nolock()
    
    We want this for btrfs_extent_same. Basically readpage and friends do their
    own extent locking but for the purposes of dedupe, we want to have both
    files locked down across a set of readpage operations (so that we can
    compare data). Introduce this variant and a flag which can be set for
    extent_read_full_page() to indicate that we are already locked.
    
    Partial credit for this patch goes to Gabriel de Perthuis <g2p.code@gmail.com>
    as I have included a fix from him to the original patch which avoids a
    deadlock on compressed extents.
    
    Signed-off-by: Mark Fasheh <mfasheh@suse.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c450620a333f..3940a0386865 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -29,6 +29,7 @@
  */
 #define EXTENT_BIO_COMPRESSED 1
 #define EXTENT_BIO_TREE_LOG 2
+#define EXTENT_BIO_PARENT_LOCKED 4
 #define EXTENT_BIO_FLAG_SHIFT 16
 
 /* these are bit numbers for test/set bit */
@@ -199,6 +200,8 @@ int unlock_extent_cached(struct extent_io_tree *tree, u64 start, u64 end,
 int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent, int mirror_num);
+int extent_read_full_page_nolock(struct extent_io_tree *tree, struct page *page,
+				 get_extent_t *get_extent, int mirror_num);
 int __init extent_io_init(void);
 void extent_io_exit(void);
 

commit c2790a2e2bc824084717fde031a8e0d370fc8650
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Jul 29 11:20:47 2013 -0400

    Btrfs: cleanup arguments to extent_clear_unlock_delalloc
    
    This patch removes the io_tree argument for extent_clear_unlock_delalloc since
    we always use &BTRFS_I(inode)->io_tree, and it separates out the extent tree
    operations from the page operations.  This way we just pass in the extent bits
    we want to clear and then pass in the operations we want done to the pages.
    This is because I'm going to fix what extent bits we clear in some cases and
    rather than add a bunch of new flags we'll just use the actual extent bits we
    want to clear.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f7544afefdb9..c450620a333f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -44,14 +44,11 @@
 #define EXTENT_BUFFER_DUMMY 9
 
 /* these are flags for extent_clear_unlock_delalloc */
-#define EXTENT_CLEAR_UNLOCK_PAGE 0x1
-#define EXTENT_CLEAR_UNLOCK	 0x2
-#define EXTENT_CLEAR_DELALLOC	 0x4
-#define EXTENT_CLEAR_DIRTY	 0x8
-#define EXTENT_SET_WRITEBACK	 0x10
-#define EXTENT_END_WRITEBACK	 0x20
-#define EXTENT_SET_PRIVATE2	 0x40
-#define EXTENT_CLEAR_ACCOUNTING  0x80
+#define PAGE_UNLOCK		(1 << 0)
+#define PAGE_CLEAR_DIRTY	(1 << 1)
+#define PAGE_SET_WRITEBACK	(1 << 2)
+#define PAGE_END_WRITEBACK	(1 << 3)
+#define PAGE_SET_PRIVATE2	(1 << 4)
 
 /*
  * page->private values.  Every page that is controlled by the extent
@@ -328,10 +325,10 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long *map_len);
 int extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 int extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
-int extent_clear_unlock_delalloc(struct inode *inode,
-				struct extent_io_tree *tree,
-				u64 start, u64 end, struct page *locked_page,
-				unsigned long op);
+int extent_clear_unlock_delalloc(struct inode *inode, u64 start, u64 end,
+				 struct page *locked_page,
+				 unsigned long bits_to_clear,
+				 unsigned long page_ops);
 struct bio *
 btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,
 		gfp_t gfp_flags);

commit facc8a2247340a9735fe8cc123c5da2102f5ef1b
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jul 25 19:22:34 2013 +0800

    Btrfs: don't cache the csum value into the extent state tree
    
    Before applying this patch, we cached the csum value into the extent state
    tree when reading some data from the disk, this operation increased the lock
    contention of the state tree.
    
    Now, we just store the csum value into the bio structure or other unshared
    structure, so we can reduce the lock contention.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3b8c4e26e1da..f7544afefdb9 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -62,6 +62,7 @@
 
 struct extent_state;
 struct btrfs_root;
+struct btrfs_io_bio;
 
 typedef	int (extent_submit_bio_hook_t)(struct inode *inode, int rw,
 				       struct bio *bio, int mirror_num,
@@ -77,8 +78,9 @@ struct extent_io_ops {
 			      size_t size, struct bio *bio,
 			      unsigned long bio_flags);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
-	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
-				    struct extent_state *state, int mirror);
+	int (*readpage_end_io_hook)(struct btrfs_io_bio *io_bio, u64 phy_offset,
+				    struct page *page, u64 start, u64 end,
+				    int mirror);
 	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
 	void (*set_bit_hook)(struct inode *inode, struct extent_state *state,
@@ -262,10 +264,6 @@ int extent_readpages(struct extent_io_tree *tree,
 int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 		__u64 start, __u64 len, get_extent_t *get_extent);
 int set_state_private(struct extent_io_tree *tree, u64 start, u64 private);
-void extent_cache_csums_dio(struct extent_io_tree *tree, u64 start, u32 csums[],
-			    int count);
-void extent_cache_csums(struct extent_io_tree *tree, struct bio *bio,
-			int bvec_index, u32 csums[], int count);
 int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);
 void set_page_extent_mapped(struct page *page);
 

commit 7ee9e4405f264e9eda808aa5ca4522746a1af9c1
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Jun 21 16:37:03 2013 -0400

    Btrfs: check if we can nocow if we don't have data space
    
    We always just try and reserve data space when we write, but if we are out of
    space but have prealloc'ed extents we should still successfully write.  This
    patch will try and see if we can write to prealloc'ed space and if we can go
    ahead and allow the write to continue.  With this patch we now pass xfstests
    generic/274.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 41fb81e7ec53..3b8c4e26e1da 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -19,6 +19,7 @@
 #define EXTENT_FIRST_DELALLOC (1 << 12)
 #define EXTENT_NEED_WAIT (1 << 13)
 #define EXTENT_DAMAGED (1 << 14)
+#define EXTENT_NORESERVE (1 << 15)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 #define EXTENT_CTLBITS (EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
 

commit 9be3395bcd4ad4af76476ac38152b4cafa6b6159
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Fri May 17 18:30:14 2013 -0400

    Btrfs: use a btrfs bioset instead of abusing bio internals
    
    Btrfs has been pointer tagging bi_private and using bi_bdev
    to store the stripe index and mirror number of failed IOs.
    
    As bios bubble back up through the call chain, we use these
    to decide if and how to retry our IOs.  They are also used
    to count IO failures on a per device basis.
    
    Recently a bio tracepoint was added lead to crashes because
    we were abusing bi_bdev.
    
    This commit adds a btrfs bioset, and creates explicit fields
    for the mirror number and stripe index.  The plan is to
    extend this structure for all of the fields currently in
    struct btrfs_bio, which will mean one less kmalloc in
    our IO path.
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>
    Reported-by: Tejun Heo <tj@kernel.org>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a2c03a175009..41fb81e7ec53 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -336,6 +336,8 @@ int extent_clear_unlock_delalloc(struct inode *inode,
 struct bio *
 btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,
 		gfp_t gfp_flags);
+struct bio *btrfs_io_bio_alloc(gfp_t gfp_mask, unsigned int nr_iovecs);
+struct bio *btrfs_bio_clone(struct bio *bio, gfp_t gfp_mask);
 
 struct btrfs_fs_info;
 

commit 410748882ac703aa0550aa6c3c5656edd0462001
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Apr 29 13:38:46 2013 +0000

    btrfs: use unsigned long type for extent state bits
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3af58bf55ddc..a2c03a175009 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -81,9 +81,9 @@ struct extent_io_ops {
 	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
 	void (*set_bit_hook)(struct inode *inode, struct extent_state *state,
-			     int *bits);
+			     unsigned long *bits);
 	void (*clear_bit_hook)(struct inode *inode, struct extent_state *state,
-			       int *bits);
+			       unsigned long *bits);
 	void (*merge_extent_hook)(struct inode *inode,
 				  struct extent_state *new,
 				  struct extent_state *other);
@@ -192,7 +192,7 @@ int try_release_extent_mapping(struct extent_map_tree *map,
 int try_release_extent_buffer(struct page *page);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		     int bits, struct extent_state **cached);
+		     unsigned long bits, struct extent_state **cached);
 int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int unlock_extent_cached(struct extent_io_tree *tree, u64 start, u64 end,
 			 struct extent_state **cached, gfp_t mask);
@@ -208,16 +208,17 @@ u64 count_range_bits(struct extent_io_tree *tree,
 
 void free_extent_state(struct extent_state *state);
 int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		   int bits, int filled, struct extent_state *cached_state);
+		   unsigned long bits, int filled,
+		   struct extent_state *cached_state);
 int clear_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		      int bits, gfp_t mask);
+		      unsigned long bits, gfp_t mask);
 int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		     int bits, int wake, int delete, struct extent_state **cached,
-		     gfp_t mask);
+		     unsigned long bits, int wake, int delete,
+		     struct extent_state **cached, gfp_t mask);
 int set_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		    int bits, gfp_t mask);
+		    unsigned long bits, gfp_t mask);
 int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		   int bits, u64 *failed_start,
+		   unsigned long bits, u64 *failed_start,
 		   struct extent_state **cached_state, gfp_t mask);
 int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);
@@ -230,14 +231,14 @@ int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 int clear_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		       gfp_t mask);
 int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		       int bits, int clear_bits,
+		       unsigned long bits, unsigned long clear_bits,
 		       struct extent_state **cached_state, gfp_t mask);
 int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);
 int set_extent_defrag(struct extent_io_tree *tree, u64 start, u64 end,
 		      struct extent_state **cached_state, gfp_t mask);
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
-			  u64 *start_ret, u64 *end_ret, int bits,
+			  u64 *start_ret, u64 *end_ret, unsigned long bits,
 			  struct extent_state **cached_state);
 int extent_invalidatepage(struct extent_io_tree *tree,
 			  struct page *page, unsigned long offset);

commit f7a52a40cabea38b99b5053bc4f7cf45f4997603
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Apr 26 14:56:29 2013 +0000

    btrfs: remove unused gfp mask parameter from release_extent_buffer callchain
    
    It's unused since 0b32f4bbb423f02ac.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 9ebb4c7b86d1..3af58bf55ddc 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -189,7 +189,7 @@ void extent_io_tree_init(struct extent_io_tree *tree,
 int try_release_extent_mapping(struct extent_map_tree *map,
 			       struct extent_io_tree *tree, struct page *page,
 			       gfp_t mask);
-int try_release_extent_buffer(struct page *page, gfp_t mask);
+int try_release_extent_buffer(struct page *page);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		     int bits, struct extent_state **cached);

commit 48a3b6366f6913683563d934eb16fea67dead9c1
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Apr 25 20:41:01 2013 +0000

    btrfs: make static code static & remove dead code
    
    Big patch, but all it does is add statics to functions which
    are in fact static, then remove the associated dead-code fallout.
    
    removed functions:
    
    btrfs_iref_to_path()
    __btrfs_lookup_delayed_deletion_item()
    __btrfs_search_delayed_insertion_item()
    __btrfs_search_delayed_deletion_item()
    find_eb_for_page()
    btrfs_find_block_group()
    range_straddles_pages()
    extent_range_uptodate()
    btrfs_file_extent_length()
    btrfs_scrub_cancel_devid()
    btrfs_start_transaction_lflush()
    
    btrfs_print_tree() is left because it is used for debugging.
    btrfs_start_transaction_lflush() and btrfs_reada_detach() are
    left for symmetry.
    
    ulist.c functions are left, another patch will take care of those.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 59d883bc3ed3..9ebb4c7b86d1 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -190,9 +190,6 @@ int try_release_extent_mapping(struct extent_map_tree *map,
 			       struct extent_io_tree *tree, struct page *page,
 			       gfp_t mask);
 int try_release_extent_buffer(struct page *page, gfp_t mask);
-int try_release_extent_state(struct extent_map_tree *map,
-			     struct extent_io_tree *tree, struct page *page,
-			     gfp_t mask);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		     int bits, struct extent_state **cached);
@@ -242,8 +239,6 @@ int set_extent_defrag(struct extent_io_tree *tree, u64 start, u64 end,
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
 			  u64 *start_ret, u64 *end_ret, int bits,
 			  struct extent_state **cached_state);
-struct extent_state *find_first_extent_bit_state(struct extent_io_tree *tree,
-						 u64 start, int bits);
 int extent_invalidatepage(struct extent_io_tree *tree,
 			  struct page *page, unsigned long offset);
 int extent_write_full_page(struct extent_io_tree *tree, struct page *page,
@@ -322,7 +317,6 @@ void memmove_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
 			   unsigned long src_offset, unsigned long len);
 void memset_extent_buffer(struct extent_buffer *eb, char c,
 			  unsigned long start, unsigned long len);
-void wait_extent_bit(struct extent_io_tree *tree, u64 start, u64 end, int bits);
 void clear_extent_buffer_dirty(struct extent_buffer *eb);
 int set_extent_buffer_dirty(struct extent_buffer *eb);
 int set_extent_buffer_uptodate(struct extent_buffer *eb);
@@ -332,8 +326,6 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long min_len, char **map,
 		      unsigned long *map_start,
 		      unsigned long *map_len);
-int extent_range_uptodate(struct extent_io_tree *tree,
-			  u64 start, u64 end);
 int extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
 int extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 int extent_clear_unlock_delalloc(struct inode *inode,

commit 6d49ba1b47b9c6822d08f90af6f1a2d8ca1cf533
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Mon Apr 22 16:12:31 2013 +0000

    btrfs: move leak debug code to functions
    
    Clean up the leak debugging in extent_io.c by moving
    the debug code into functions.  This also removes the
    list_heads used for debugging from the extent_buffer
    and extent_state structures when debug is not enabled.
    
    Since we need a global debug config to do that last
    part, implement CONFIG_BTRFS_DEBUG to accommodate.
    
    Thanks to Dave Sterba for the Kconfig bit.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index fa86861de244..59d883bc3ed3 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -116,7 +116,9 @@ struct extent_state {
 	/* for use by the FS */
 	u64 private;
 
+#ifdef CONFIG_BTRFS_DEBUG
 	struct list_head leak_list;
+#endif
 };
 
 #define INLINE_EXTENT_BUFFER_PAGES 16
@@ -132,7 +134,6 @@ struct extent_buffer {
 	atomic_t refs;
 	atomic_t io_pages;
 	int read_mirror;
-	struct list_head leak_list;
 	struct rcu_head rcu_head;
 	pid_t lock_owner;
 
@@ -159,6 +160,9 @@ struct extent_buffer {
 	wait_queue_head_t read_lock_wq;
 	wait_queue_head_t lock_wq;
 	struct page *pages[INLINE_EXTENT_BUFFER_PAGES];
+#ifdef CONFIG_BTRFS_DEBUG
+	struct list_head leak_list;
+#endif
 };
 
 static inline void extent_set_compress_type(unsigned long *bio_flags,

commit fd8b2b611580929ab1aa01e3942dce20f9e95732
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Apr 24 16:41:19 2013 -0400

    Btrfs: cleanup destroy_marked_extents
    
    We can just look up the extent_buffers for the range and free stuff that way.
    This makes the cleanup a bit cleaner and we can make sure to evict the
    extent_buffers pretty quickly by marking them as stale.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index db009d80bef4..fa86861de244 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -282,6 +282,7 @@ void free_extent_buffer_stale(struct extent_buffer *eb);
 int read_extent_buffer_pages(struct extent_io_tree *tree,
 			     struct extent_buffer *eb, u64 start, int wait,
 			     get_extent_t *get_extent, int mirror_num);
+void wait_on_extent_buffer_writeback(struct extent_buffer *eb);
 
 static inline unsigned long num_extent_pages(u64 start, u64 len)
 {

commit e4100d987b2437596ebcf11809022b79507f3db1
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Apr 5 07:20:56 2013 +0000

    Btrfs: improve the performance of the csums lookup
    
    It is very likely that there are several blocks in bio, it is very
    inefficient if we get their csums one by one. This patch improves
    this problem by getting the csums in batch.
    
    According to the result of the following test, the execute time of
    __btrfs_lookup_bio_sums() is down by ~28%(300us -> 217us).
    
     # dd if=<mnt>/file of=/dev/null bs=1M count=1024
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 258c92156857..db009d80bef4 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -261,6 +261,10 @@ int extent_readpages(struct extent_io_tree *tree,
 int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 		__u64 start, __u64 len, get_extent_t *get_extent);
 int set_state_private(struct extent_io_tree *tree, u64 start, u64 private);
+void extent_cache_csums_dio(struct extent_io_tree *tree, u64 start, u32 csums[],
+			    int count);
+void extent_cache_csums(struct extent_io_tree *tree, struct bio *bio,
+			int bvec_index, u32 csums[], int count);
 int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);
 void set_page_extent_mapped(struct page *page);
 

commit 4adaa611020fa6ac65b0ac8db78276af4ec04e63
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Tue Mar 26 13:07:00 2013 -0400

    Btrfs: fix race between mmap writes and compression
    
    Btrfs uses page_mkwrite to ensure stable pages during
    crc calculations and mmap workloads.  We call clear_page_dirty_for_io
    before we do any crcs, and this forces any application with the file
    mapped to wait for the crc to finish before it is allowed to change
    the file.
    
    With compression on, the clear_page_dirty_for_io step is happening after
    we've compressed the pages.  This means the applications might be
    changing the pages while we are compressing them, and some of those
    modifications might not hit the disk.
    
    This commit adds the clear_page_dirty_for_io before compression starts
    and makes sure to redirty the page if we have to fallback to
    uncompressed IO as well.
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>
    Reported-by: Alexandre Oliva <oliva@gnu.org>
    cc: stable@vger.kernel.org

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6068a1985560..258c92156857 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -325,6 +325,8 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long *map_len);
 int extent_range_uptodate(struct extent_io_tree *tree,
 			  u64 start, u64 end);
+int extent_range_clear_dirty_for_io(struct inode *inode, u64 start, u64 end);
+int extent_range_redirty_for_io(struct inode *inode, u64 start, u64 end);
 int extent_clear_unlock_delalloc(struct inode *inode,
 				struct extent_io_tree *tree,
 				u64 start, u64 end, struct page *locked_page,

commit b8dae3138876080d4dd98cc438ff759338d632ef
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Feb 28 14:54:18 2013 +0000

    btrfs: use only inline_pages from extent buffer
    
    The nodesize is capped at 64k and there are enough pages preallocated in
    extent_buffer::inline_pages. The fallback to kmalloc never happened
    because even on the smallest page size considered (4k) inline_pages
    covered the needs.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index dc81868d975a..6068a1985560 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -158,8 +158,7 @@ struct extent_buffer {
 	 */
 	wait_queue_head_t read_lock_wq;
 	wait_queue_head_t lock_wq;
-	struct page *inline_pages[INLINE_EXTENT_BUFFER_PAGES];
-	struct page **pages;
+	struct page *pages[INLINE_EXTENT_BUFFER_PAGES];
 };
 
 static inline void extent_set_compress_type(unsigned long *bio_flags,

commit e942f883bc6651d50be139477baf6fb0eed3d5bb
Merge: b2c6b3e0611c 0e4e02636611
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Feb 20 14:06:05 2013 -0500

    Merge branch 'raid56-experimental' into for-linus-3.9
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>
    
    Conflicts:
            fs/btrfs/ctree.h
            fs/btrfs/extent-tree.c
            fs/btrfs/inode.c
            fs/btrfs/volumes.c

commit c8f2f24bd56a9f0bc7372e6d6aded6fc122b9120
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Feb 11 11:33:00 2013 -0500

    Btrfs: remove unused extent io tree ops V2
    
    Nobody uses these io tree ops anymore so just remove them and clean up the code
    a bit.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 2eacfabd3263..ff182322d112 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -75,7 +75,6 @@ struct extent_io_ops {
 	int (*merge_bio_hook)(struct page *page, unsigned long offset,
 			      size_t size, struct bio *bio,
 			      unsigned long bio_flags);
-	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
 	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
 				    struct extent_state *state, int mirror);
@@ -90,8 +89,6 @@ struct extent_io_ops {
 				  struct extent_state *other);
 	void (*split_extent_hook)(struct inode *inode,
 				  struct extent_state *orig, u64 split);
-	int (*write_cache_pages_lock_hook)(struct page *page, void *data,
-					   void (*flush_fn)(void *));
 };
 
 struct extent_io_tree {

commit 64a167011bcabc1e855658387c8a4464b71f3138
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Wed Jul 15 23:29:37 2009 +0100

    Btrfs: add rw argument to merge_bio_hook()
    
    We'll want to merge writes so they can fill a full RAID[56] stripe, but
    not necessarily reads.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 2eacfabd3263..b14b36a80eba 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -72,7 +72,7 @@ struct extent_io_ops {
 	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
 	extent_submit_bio_hook_t *submit_bio_hook;
-	int (*merge_bio_hook)(struct page *page, unsigned long offset,
+	int (*merge_bio_hook)(int rw, struct page *page, unsigned long offset,
 			      size_t size, struct bio *bio,
 			      unsigned long bio_flags);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);

commit 3ec706c831d4c96905c287013c8228b21619a1d9
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 15:46:42 2012 +0100

    Btrfs: pass fs_info to btrfs_map_block() instead of mapping_tree
    
    This is required for the device replace procedure in a later step.
    Two calling functions also had to be changed to have the fs_info
    pointer: repair_io_failure() and scrub_setup_recheck_block().
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 711d12b80028..2eacfabd3263 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -337,9 +337,9 @@ struct bio *
 btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,
 		gfp_t gfp_flags);
 
-struct btrfs_mapping_tree;
+struct btrfs_fs_info;
 
-int repair_io_failure(struct btrfs_mapping_tree *map_tree, u64 start,
+int repair_io_failure(struct btrfs_fs_info *fs_info, u64 start,
 			u64 length, u64 logical, struct page *page,
 			int mirror_num);
 int end_extent_writepage(struct page *page, int err, u64 start, u64 end);

commit 479ed9abdbeec5d9ed0005f3bee9c9bc06a102bb
Author: Robin Dong <sanbai@taobao.com>
Date:   Sat Sep 29 02:07:47 2012 -0600

    btrfs: move inline function code to header file
    
    When building btrfs from kernel code, it will report:
    
            fs/btrfs/extent_io.h:281: warning: 'extent_buffer_page' declared inline after being called
            fs/btrfs/extent_io.h:281: warning: previous declaration of 'extent_buffer_page' was here
            fs/btrfs/extent_io.h:280: warning: 'num_extent_pages' declared inline after being called
            fs/btrfs/extent_io.h:280: warning: previous declaration of 'num_extent_pages' was here
    
    because of the wrong declaration of inline functions.
    
    Signed-off-by: Robin Dong <sanbai@taobao.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 7aeb31087f88..711d12b80028 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -282,8 +282,18 @@ void free_extent_buffer_stale(struct extent_buffer *eb);
 int read_extent_buffer_pages(struct extent_io_tree *tree,
 			     struct extent_buffer *eb, u64 start, int wait,
 			     get_extent_t *get_extent, int mirror_num);
-unsigned long num_extent_pages(u64 start, u64 len);
-struct page *extent_buffer_page(struct extent_buffer *eb, unsigned long i);
+
+static inline unsigned long num_extent_pages(u64 start, u64 len)
+{
+	return ((start + len + PAGE_CACHE_SIZE - 1) >> PAGE_CACHE_SHIFT) -
+		(start >> PAGE_CACHE_SHIFT);
+}
+
+static inline struct page *extent_buffer_page(struct extent_buffer *eb,
+					      unsigned long i)
+{
+	return eb->pages[i];
+}
 
 static inline void extent_buffer_get(struct extent_buffer *eb)
 {

commit e6138876ad8327250d77291b3262fee356267211
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Sep 27 17:07:30 2012 -0400

    Btrfs: cache extent state when writing out dirty metadata pages
    
    Everytime we write out dirty pages we search for an offset in the tree,
    convert the bits in the state, and then when we wait we search for the
    offset again and clear the bits.  So for every dirty range in the io tree we
    are doing 4 rb searches, which is suboptimal.  With this patch we are only
    doing 2 searches for every cycle (modulo weird things happening).  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a69dea219044..7aeb31087f88 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -233,13 +233,15 @@ int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 int clear_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		       gfp_t mask);
 int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		       int bits, int clear_bits, gfp_t mask);
+		       int bits, int clear_bits,
+		       struct extent_state **cached_state, gfp_t mask);
 int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);
 int set_extent_defrag(struct extent_io_tree *tree, u64 start, u64 end,
 		      struct extent_state **cached_state, gfp_t mask);
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
-			  u64 *start_ret, u64 *end_ret, int bits);
+			  u64 *start_ret, u64 *end_ret, int bits,
+			  struct extent_state **cached_state);
 struct extent_state *find_first_extent_bit_state(struct extent_io_tree *tree,
 						 u64 start, int bits);
 int extent_invalidatepage(struct extent_io_tree *tree,

commit de0022b9da616b95ea5b41eab32da825b0b5150f
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Sep 25 14:25:58 2012 -0400

    Btrfs: do not async metadata csumming in certain situations
    
    There are a coule scenarios where farming metadata csumming off to an async
    thread doesn't help.  The first is if our processor supports crc32c, in
    which case the csumming will be fast and so the overhead of the async model
    is not worth the cost.  The other case is for our tree log.  We will be
    making that stuff dirty and writing it out and waiting for it immediately.
    Even with software crc32c this gives me a ~15% increase in speed with O_SYNC
    workloads.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 512f8da041f1..a69dea219044 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -27,6 +27,7 @@
  * type for this bio
  */
 #define EXTENT_BIO_COMPRESSED 1
+#define EXTENT_BIO_TREE_LOG 2
 #define EXTENT_BIO_FLAG_SHIFT 16
 
 /* these are bit numbers for test/set bit */

commit 9e8a4a8b0b9484e8d14674fc62c9ad8ac9dbce5b
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Sep 5 19:10:51 2012 -0600

    Btrfs: use flag EXTENT_DEFRAG for snapshot-aware defrag
    
    We're going to use this flag EXTENT_DEFRAG to indicate which range
    belongs to defragment so that we can implement snapshow-aware defrag:
    
    We set the EXTENT_DEFRAG flag when dirtying the extents that need
    defragmented, so later on writeback thread can differentiate between
    normal writeback and writeback started by defragmentation.
    
    Original-Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 25900af5b15d..512f8da041f1 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -235,6 +235,8 @@ int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		       int bits, int clear_bits, gfp_t mask);
 int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);
+int set_extent_defrag(struct extent_io_tree *tree, u64 start, u64 end,
+		      struct extent_state **cached_state, gfp_t mask);
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
 			  u64 *start_ret, u64 *end_ret, int bits);
 struct extent_state *find_first_extent_bit_state(struct extent_io_tree *tree,

commit 1e20932a23578bb1ec59107843574e259b96193f
Merge: cfc442b69696 c31931088fd6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 31 16:50:28 2012 -0400

    Merge branch 'for-chris' of git://git.jan-o-sch.net/btrfs-unstable into for-linus
    
    Conflicts:
            fs/btrfs/ulist.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 5fd02043553b02867b29de1ac9fff2ec16b84def
Author: Josef Bacik <josef@redhat.com>
Date:   Wed May 2 14:00:54 2012 -0400

    Btrfs: finish ordered extents in their own thread
    
    We noticed that the ordered extent completion doesn't really rely on having
    a page and that it could be done independantly of ending the writeback on a
    page.  This patch makes us not do the threaded endio stuff for normal
    buffered writes and direct writes so we can end page writeback as soon as
    possible (in irq context) and only start threads to do the ordered work when
    it is actually done.  Compression needs to be reworked some to take
    advantage of this as well, but atm it has to do a find_get_page in its endio
    handler so it must be done in its own thread.  This makes direct writes
    quite a bit faster.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b516c3b8dec6..4d8124b64577 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -75,9 +75,6 @@ struct extent_io_ops {
 			      unsigned long bio_flags);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
-	int (*writepage_io_failed_hook)(struct bio *bio, struct page *page,
-					u64 start, u64 end,
-				       struct extent_state *state);
 	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
 				    struct extent_state *state, int mirror);
 	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
@@ -225,6 +222,8 @@ int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   struct extent_state **cached_state, gfp_t mask);
 int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);
+int clear_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
+			  struct extent_state **cached_state, gfp_t mask);
 int set_extent_new(struct extent_io_tree *tree, u64 start, u64 end,
 		   gfp_t mask);
 int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,

commit 815a51c74ad14864d0a8fff5eea983819c18feae
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed May 16 17:00:02 2012 +0200

    Btrfs: dummy extent buffers for tree mod log
    
    The tree modification log needs two ways to create dummy extent buffers,
    once by allocating a fresh one (to rebuild an old root) and once by
    cloning an existing one (to make private rewind modifications) to it.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b516c3b8dec6..96434a61d7c2 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -39,6 +39,7 @@
 #define EXTENT_BUFFER_STALE 6
 #define EXTENT_BUFFER_WRITEBACK 7
 #define EXTENT_BUFFER_IOERR 8
+#define EXTENT_BUFFER_DUMMY 9
 
 /* these are flags for extent_clear_unlock_delalloc */
 #define EXTENT_CLEAR_UNLOCK_PAGE 0x1
@@ -265,6 +266,8 @@ void set_page_extent_mapped(struct page *page);
 
 struct extent_buffer *alloc_extent_buffer(struct extent_io_tree *tree,
 					  u64 start, unsigned long len);
+struct extent_buffer *alloc_dummy_extent_buffer(u64 start, unsigned long len);
+struct extent_buffer *btrfs_clone_extent_buffer(struct extent_buffer *src);
 struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
 					 u64 start, unsigned long len);
 void free_extent_buffer(struct extent_buffer *eb);

commit 5cf1ab56133ad7b712673c071b439d4a555a2d1e
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Apr 16 09:42:26 2012 -0400

    Btrfs: always store the mirror we read the eb from
    
    A user reported a panic where we were trying to fix a bad mirror but the
    mirror number we were giving was 0, which is invalid.  This is because we
    don't do the transid verification until after the read, so as far as the
    read code is concerned the read was a success.  So instead store the mirror
    we read from so that if there is some failure post read we know which mirror
    to try next and which mirror needs to be fixed if we find a good copy of the
    block.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index faf10eb57f75..b516c3b8dec6 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -79,7 +79,7 @@ struct extent_io_ops {
 					u64 start, u64 end,
 				       struct extent_state *state);
 	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
-				    struct extent_state *state);
+				    struct extent_state *state, int mirror);
 	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
 	void (*set_bit_hook)(struct inode *inode, struct extent_state *state,
@@ -135,7 +135,7 @@ struct extent_buffer {
 	spinlock_t refs_lock;
 	atomic_t refs;
 	atomic_t io_pages;
-	int failed_mirror;
+	int read_mirror;
 	struct list_head leak_list;
 	struct rcu_head rcu_head;
 	pid_t lock_owner;

commit 1d4284bd6e8d7dd1d5521a6747bdb6dc1caf0225
Merge: b5d67f64f9bc 65139ed99234
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 28 20:31:37 2012 -0400

    Merge branch 'error-handling' into for-linus
    
    Conflicts:
            fs/btrfs/ctree.c
            fs/btrfs/disk-io.c
            fs/btrfs/extent-tree.c
            fs/btrfs/extent_io.c
            fs/btrfs/extent_io.h
            fs/btrfs/inode.c
            fs/btrfs/scrub.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit ea466794084f55d8fcc100711cf17923bf57e962
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Mar 26 21:57:36 2012 -0400

    Btrfs: deal with read errors on extent buffers differently
    
    Since we need to read and write extent buffers in their entirety we can't use
    the normal bio_readpage_error stuff since it only works on a per page basis.  So
    instead make it so that if we see an io error in endio we just mark the eb as
    having an IO error and then in btree_read_extent_buffer_pages we will manually
    try other mirrors and then overwrite the bad mirror if we find a good copy.
    This works with larger than page size blocks.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 489d7945154f..38c1af7092f3 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -58,6 +58,7 @@
 #define EXTENT_PAGE_PRIVATE_FIRST_PAGE 3
 
 struct extent_state;
+struct btrfs_root;
 
 typedef	int (extent_submit_bio_hook_t)(struct inode *inode, int rw,
 				       struct bio *bio, int mirror_num,
@@ -73,9 +74,7 @@ struct extent_io_ops {
 			      size_t size, struct bio *bio,
 			      unsigned long bio_flags);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
-	int (*readpage_io_failed_hook)(struct bio *bio, struct page *page,
-				       u64 start, u64 end, int failed_mirror,
-				       struct extent_state *state);
+	int (*readpage_io_failed_hook)(struct page *page, int failed_mirror);
 	int (*writepage_io_failed_hook)(struct bio *bio, struct page *page,
 					u64 start, u64 end,
 				       struct extent_state *state);
@@ -136,6 +135,7 @@ struct extent_buffer {
 	spinlock_t refs_lock;
 	atomic_t refs;
 	atomic_t io_pages;
+	int failed_mirror;
 	struct list_head leak_list;
 	struct rcu_head rcu_head;
 	pid_t lock_owner;
@@ -327,4 +327,6 @@ int repair_io_failure(struct btrfs_mapping_tree *map_tree, u64 start,
 			u64 length, u64 logical, struct page *page,
 			int mirror_num);
 int end_extent_writepage(struct page *page, int err, u64 start, u64 end);
+int repair_eb_io_failure(struct btrfs_root *root, struct extent_buffer *eb,
+			 int mirror_num);
 #endif

commit 0b32f4bbb423f02acee6d43cd442f5f0775db7e0
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Mar 13 09:38:00 2012 -0400

    Btrfs: ensure an entire eb is written at once
    
    This patch simplifies how we track our extent buffers.  Previously we could exit
    writepages with only having written half of an extent buffer, which meant we had
    to track the state of the pages and the state of the extent buffers differently.
    Now we only read in entire extent buffers and write out entire extent buffers,
    this allows us to simply set bits in our bflags to indicate the state of the eb
    and we no longer have to do things like track uptodate with our iotree.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 60628341f156..489d7945154f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -37,6 +37,8 @@
 #define EXTENT_BUFFER_READAHEAD 4	/* this got triggered by readahead */
 #define EXTENT_BUFFER_TREE_REF 5
 #define EXTENT_BUFFER_STALE 6
+#define EXTENT_BUFFER_WRITEBACK 7
+#define EXTENT_BUFFER_IOERR 8
 
 /* these are flags for extent_clear_unlock_delalloc */
 #define EXTENT_CLEAR_UNLOCK_PAGE 0x1
@@ -99,6 +101,7 @@ struct extent_io_tree {
 	struct radix_tree_root buffer;
 	struct address_space *mapping;
 	u64 dirty_bytes;
+	int track_uptodate;
 	spinlock_t lock;
 	spinlock_t buffer_lock;
 	struct extent_io_ops *ops;
@@ -132,7 +135,7 @@ struct extent_buffer {
 	struct extent_io_tree *tree;
 	spinlock_t refs_lock;
 	atomic_t refs;
-	atomic_t pages_reading;
+	atomic_t io_pages;
 	struct list_head leak_list;
 	struct rcu_head rcu_head;
 	pid_t lock_owner;
@@ -249,6 +252,8 @@ int extent_writepages(struct extent_io_tree *tree,
 		      struct address_space *mapping,
 		      get_extent_t *get_extent,
 		      struct writeback_control *wbc);
+int btree_write_cache_pages(struct address_space *mapping,
+			    struct writeback_control *wbc);
 int extent_readpages(struct extent_io_tree *tree,
 		     struct address_space *mapping,
 		     struct list_head *pages, unsigned nr_pages,
@@ -297,18 +302,11 @@ void memmove_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
 void memset_extent_buffer(struct extent_buffer *eb, char c,
 			  unsigned long start, unsigned long len);
 int wait_extent_bit(struct extent_io_tree *tree, u64 start, u64 end, int bits);
-int clear_extent_buffer_dirty(struct extent_io_tree *tree,
-			      struct extent_buffer *eb);
-int set_extent_buffer_dirty(struct extent_io_tree *tree,
-			     struct extent_buffer *eb);
-int set_extent_buffer_uptodate(struct extent_io_tree *tree,
-			       struct extent_buffer *eb);
-int clear_extent_buffer_uptodate(struct extent_io_tree *tree,
-				struct extent_buffer *eb,
-				struct extent_state **cached_state);
-int extent_buffer_uptodate(struct extent_io_tree *tree,
-			   struct extent_buffer *eb,
-			   struct extent_state *cached_state);
+int clear_extent_buffer_dirty(struct extent_buffer *eb);
+int set_extent_buffer_dirty(struct extent_buffer *eb);
+int set_extent_buffer_uptodate(struct extent_buffer *eb);
+int clear_extent_buffer_uptodate(struct extent_buffer *eb);
+int extent_buffer_uptodate(struct extent_buffer *eb);
 int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long min_len, char **map,
 		      unsigned long *map_start,

commit 3083ee2e18b701122a3b841db83448543a87a583
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Mar 9 16:01:49 2012 -0500

    Btrfs: introduce free_extent_buffer_stale
    
    Because btrfs cow's we can end up with extent buffers that are no longer
    necessary just sitting around in memory.  So instead of evicting these pages, we
    could end up evicting things we actually care about.  Thus we have
    free_extent_buffer_stale for use when we are freeing tree blocks.  This will
    make it so that the ref for the eb being in the radix tree is dropped as soon as
    possible and then is freed when the refcount hits 0 instead of waiting to be
    released by releasepage.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 83e432da2e26..60628341f156 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -35,6 +35,8 @@
 #define EXTENT_BUFFER_DIRTY 2
 #define EXTENT_BUFFER_CORRUPT 3
 #define EXTENT_BUFFER_READAHEAD 4	/* this got triggered by readahead */
+#define EXTENT_BUFFER_TREE_REF 5
+#define EXTENT_BUFFER_STALE 6
 
 /* these are flags for extent_clear_unlock_delalloc */
 #define EXTENT_CLEAR_UNLOCK_PAGE 0x1
@@ -128,6 +130,7 @@ struct extent_buffer {
 	unsigned long map_len;
 	unsigned long bflags;
 	struct extent_io_tree *tree;
+	spinlock_t refs_lock;
 	atomic_t refs;
 	atomic_t pages_reading;
 	struct list_head leak_list;
@@ -184,7 +187,7 @@ void extent_io_tree_init(struct extent_io_tree *tree,
 int try_release_extent_mapping(struct extent_map_tree *map,
 			       struct extent_io_tree *tree, struct page *page,
 			       gfp_t mask);
-int try_release_extent_buffer(struct extent_io_tree *tree, struct page *page);
+int try_release_extent_buffer(struct page *page, gfp_t mask);
 int try_release_extent_state(struct extent_map_tree *map,
 			     struct extent_io_tree *tree, struct page *page,
 			     gfp_t mask);
@@ -261,6 +264,7 @@ struct extent_buffer *alloc_extent_buffer(struct extent_io_tree *tree,
 struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
 					 u64 start, unsigned long len);
 void free_extent_buffer(struct extent_buffer *eb);
+void free_extent_buffer_stale(struct extent_buffer *eb);
 #define WAIT_NONE	0
 #define WAIT_COMPLETE	1
 #define WAIT_PAGE_LOCK	2

commit 4f2de97acee6532b36dd6e995b858343771ad126
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Mar 7 16:20:05 2012 -0500

    Btrfs: set page->private to the eb
    
    We spend a lot of time looking up extent buffers from pages when we could just
    store the pointer to the eb the page is associated with in page->private.  This
    patch does just that, and it makes things a little simpler and reduces a bit of
    CPU overhead involved with doing metadata IO.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4e38a3d9631a..83e432da2e26 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -127,6 +127,7 @@ struct extent_buffer {
 	unsigned long map_start;
 	unsigned long map_len;
 	unsigned long bflags;
+	struct extent_io_tree *tree;
 	atomic_t refs;
 	atomic_t pages_reading;
 	struct list_head leak_list;

commit 727011e07cbdf87772fcc1999cccd15cc915eb62
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 6 13:21:20 2010 -0400

    Btrfs: allow metadata blocks larger than the page size
    
    A few years ago the btrfs code to support blocks lager than
    the page size was disabled to fix a few corner cases in the
    page cache handling.  This fixes the code to properly support
    large metadata blocks again.
    
    Since current kernels will crash early and often with larger
    metadata blocks, this adds an incompat bit so that older kernels
    can't mount it.
    
    This also does away with different blocksizes for nodes and leaves.
    You get a single block size for all tree blocks.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index cecc3518c121..4e38a3d9631a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -119,16 +119,18 @@ struct extent_state {
 	struct list_head leak_list;
 };
 
+#define INLINE_EXTENT_BUFFER_PAGES 16
+#define MAX_INLINE_EXTENT_BUFFER_SIZE (INLINE_EXTENT_BUFFER_PAGES * PAGE_CACHE_SIZE)
 struct extent_buffer {
 	u64 start;
 	unsigned long len;
 	unsigned long map_start;
 	unsigned long map_len;
-	struct page *first_page;
 	unsigned long bflags;
+	atomic_t refs;
+	atomic_t pages_reading;
 	struct list_head leak_list;
 	struct rcu_head rcu_head;
-	atomic_t refs;
 	pid_t lock_owner;
 
 	/* count of read lock holders on the extent buffer */
@@ -152,6 +154,9 @@ struct extent_buffer {
 	 * to unlock
 	 */
 	wait_queue_head_t read_lock_wq;
+	wait_queue_head_t lock_wq;
+	struct page *inline_pages[INLINE_EXTENT_BUFFER_PAGES];
+	struct page **pages;
 };
 
 static inline void extent_set_compress_type(unsigned long *bio_flags,
@@ -251,8 +256,7 @@ int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);
 void set_page_extent_mapped(struct page *page);
 
 struct extent_buffer *alloc_extent_buffer(struct extent_io_tree *tree,
-					  u64 start, unsigned long len,
-					  struct page *page0);
+					  u64 start, unsigned long len);
 struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
 					 u64 start, unsigned long len);
 void free_extent_buffer(struct extent_buffer *eb);

commit 3fbe5c02ae5a59053d779392b9a12aa8f6d6198e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:57:19 2012 +0100

    btrfs: split extent_state ops
    
     set_extent_bit can do exclusive locking but only when called by lock_extent*,
    
     Drop the exclusive bits argument except when called by lock_extent.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 439e183d45bb..3a171c259276 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -209,7 +209,7 @@ int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 int set_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		    int bits, gfp_t mask);
 int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		   int bits, int exclusive_bits, u64 *failed_start,
+		   int bits, u64 *failed_start,
 		   struct extent_state **cached_state, gfp_t mask);
 int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);

commit d0082371cf086e0ba2bbd0367b2c9920532df24f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:57:19 2012 +0100

    btrfs: drop gfp_t from lock_extent
    
     lock_extent and unlock_extent are always called with GFP_NOFS, drop the
     argument and use GFP_NOFS consistently.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f7f321ee4ba1..439e183d45bb 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -182,14 +182,13 @@ int try_release_extent_buffer(struct extent_io_tree *tree, struct page *page);
 int try_release_extent_state(struct extent_map_tree *map,
 			     struct extent_io_tree *tree, struct page *page,
 			     gfp_t mask);
-int lock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
+int lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		     int bits, struct extent_state **cached, gfp_t mask);
-int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
+		     int bits, struct extent_state **cached);
+int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int unlock_extent_cached(struct extent_io_tree *tree, u64 start, u64 end,
 			 struct extent_state **cached, gfp_t mask);
-int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end,
-		    gfp_t mask);
+int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent, int mirror_num);
 int __init extent_io_init(void);

commit 143bede527b054a271053f41bfaca2b57baa9408
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:56:26 2012 +0100

    btrfs: return void in functions without error conditions
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index cecc3518c121..f7f321ee4ba1 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -287,8 +287,8 @@ void memmove_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
 			   unsigned long src_offset, unsigned long len);
 void memset_extent_buffer(struct extent_buffer *eb, char c,
 			  unsigned long start, unsigned long len);
-int wait_extent_bit(struct extent_io_tree *tree, u64 start, u64 end, int bits);
-int clear_extent_buffer_dirty(struct extent_io_tree *tree,
+void wait_extent_bit(struct extent_io_tree *tree, u64 start, u64 end, int bits);
+void clear_extent_buffer_dirty(struct extent_io_tree *tree,
 			      struct extent_buffer *eb);
 int set_extent_buffer_dirty(struct extent_io_tree *tree,
 			     struct extent_buffer *eb);

commit 87826df0ec36fc28884b4ddbb3f3af41c4c2008f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Feb 15 16:23:57 2012 +0100

    btrfs: delalloc for page dirtied out-of-band in fixup worker
    
     We encountered an issue that was easily observable on s/390 systems but
     could really happen anywhere. The timing just seemed to hit reliably
     on s/390 with limited memory.
    
     The gist is that when an unexpected set_page_dirty() happened, we'd
     run into the BUG() in btrfs_writepage_fixup_worker since it wasn't
     properly set up for delalloc.
    
     This patch does the following:
     - Performs the missing delalloc in the fixup worker
     - Allow the start hook to return -EBUSY which informs __extent_writepage
       that it should mark the page skipped and not to redirty it. This is
       required since the fixup worker can fail with -ENOSPC and the page
       will have already been redirtied. That causes an Oops in
       drop_outstanding_extents later. Retrying the fixup worker could
       lead to an infinite loop. Deferring the page redirty also saves us
       some cycles since the page would be stuck in a resubmit-redirty loop
       until the fixup worker completes. It's not harmful, just wasteful.
     - If the fixup worker fails, we mark the page and mapping as errored,
       and end the writeback, similar to what we would do had the page
       actually been submitted to writeback.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index bc6a042cb6fc..cecc3518c121 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -319,4 +319,5 @@ struct btrfs_mapping_tree;
 int repair_io_failure(struct btrfs_mapping_tree *map_tree, u64 start,
 			u64 length, u64 logical, struct page *page,
 			int mirror_num);
+int end_extent_writepage(struct page *page, int err, u64 start, u64 end);
 #endif

commit 5b25f70f4200766355cdabda604e131d2fb6010d
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 10:55:48 2011 +0200

    Btrfs: add nested locking mode for paths
    
    This patch adds the possibilty to read-lock an extent even if it is already
    write-locked from the same thread. btrfs_find_all_roots() needs this
    capability.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 7604c3001322..bc6a042cb6fc 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -129,6 +129,7 @@ struct extent_buffer {
 	struct list_head leak_list;
 	struct rcu_head rcu_head;
 	atomic_t refs;
+	pid_t lock_owner;
 
 	/* count of read lock holders on the extent buffer */
 	atomic_t write_locks;
@@ -137,6 +138,7 @@ struct extent_buffer {
 	atomic_t blocking_readers;
 	atomic_t spinning_readers;
 	atomic_t spinning_writers;
+	int lock_nested;
 
 	/* protects write locks */
 	rwlock_t lock;

commit 32240a913d9f3a5aad42175d7696590ea1bfdb08
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Sun Nov 20 07:33:38 2011 -0500

    btrfs: mirror_num should be int, not u64
    
    My previous patch introduced some u64 for failed_mirror variables, this one
    makes it consistent again.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index feb9be0e23bc..7604c3001322 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -70,7 +70,7 @@ struct extent_io_ops {
 			      unsigned long bio_flags);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*readpage_io_failed_hook)(struct bio *bio, struct page *page,
-				       u64 start, u64 end, u64 failed_mirror,
+				       u64 start, u64 end, int failed_mirror,
 				       struct extent_state *state);
 	int (*writepage_io_failed_hook)(struct bio *bio, struct page *page,
 					u64 start, u64 end,

commit 806468f8bf76a3cb2b626dd282946a6c9c0a50f0
Merge: 531f4b1ae5e0 5da6fcbc4eb5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Nov 6 03:07:10 2011 -0500

    Merge git://git.jan-o-sch.net/btrfs-unstable into integration
    
    Conflicts:
            fs/btrfs/Makefile
            fs/btrfs/extent_io.c
            fs/btrfs/extent_io.h
            fs/btrfs/scrub.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 531f4b1ae5e0fc8c9b3f03838218e5ea178f80d3
Merge: c06a0e120a4e 7a26285eea8e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Nov 6 03:05:08 2011 -0500

    Merge branch 'for-chris' of git://github.com/sensille/linux into integration
    
    Conflicts:
            fs/btrfs/ctree.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 01d658f2ca3c85c1ffb20b306e30d16197000ce7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 1 10:08:06 2011 -0400

    Btrfs: make sure to flush queued bios if write_cache_pages waits
    
    write_cache_pages tries to build up a large bio to stuff down the pipe.
    But if it needs to wait for a page lock, it needs to make sure and send
    down any pending writes so we don't deadlock with anyone who has the
    page lock and is waiting for writeback of things inside the bio.
    
    Dave Sterba triggered this as a deadlock between the autodefrag code and
    the extent write_cache_pages
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 325a346369da..cbd4824a7c94 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -86,7 +86,8 @@ struct extent_io_ops {
 				  struct extent_state *other);
 	void (*split_extent_hook)(struct inode *inode,
 				  struct extent_state *orig, u64 split);
-	int (*write_cache_pages_lock_hook)(struct page *page);
+	int (*write_cache_pages_lock_hook)(struct page *page, void *data,
+					   void (*flush_fn)(void *));
 };
 
 struct extent_io_tree {

commit 1728366efa5ebf48bd2ed544afa8700cd07ba822
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Sep 26 13:58:47 2011 -0400

    Btrfs: stop using write_one_page
    
    While looking for a performance regression a user was complaining about, I
    noticed that we had a regression with the varmail test of filebench.  This was
    introduced by
    
    0d10ee2e6deb5c8409ae65b970846344897d5e4e
    
    which keeps us from calling writepages in writepage.  This is a correct change,
    however it happens to help the varmail test because we write out in larger
    chunks.  This is largly to do with how we write out dirty pages for each
    transaction.  If you run filebench with
    
    load varmail
    set $dir=/mnt/btrfs-test
    run 60
    
    prior to this patch you would get ~1420 ops/second, but with the patch you get
    ~1200 ops/second.  This is a 16% decrease.  So since we know the range of dirty
    pages we want to write out, don't write out in one page chunks, write out in
    ranges.  So to do this we call filemap_fdatawrite_range() on the range of bytes.
    Then we convert the DIRTY extents to NEED_WAIT extents.  When we then call
    btrfs_wait_marked_extents() we only have to filemap_fdatawait_range() on that
    range and clear the NEED_WAIT extents.  This doesn't get us back to our original
    speeds, but I've been seeing ~1380 ops/second, which is a <5% regression as
    opposed to a >15% regression.  That is acceptable given that the original commit
    greatly reduces our latency to begin with.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index cea445dcd806..325a346369da 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -17,6 +17,7 @@
 #define EXTENT_NODATASUM (1 << 10)
 #define EXTENT_DO_ACCOUNTING (1 << 11)
 #define EXTENT_FIRST_DELALLOC (1 << 12)
+#define EXTENT_NEED_WAIT (1 << 13)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 #define EXTENT_CTLBITS (EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
 

commit 462d6fac8960a3ba797927adfcbd29d503eb16fd
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Sep 26 13:56:12 2011 -0400

    Btrfs: introduce convert_extent_bit
    
    If I have a range where I know a certain bit is and I want to set it to another
    bit the only option I have is to call set and then clear bit, which will result
    in 2 tree searches.  This is inefficient, so introduce convert_extent_bit which
    will go through and set the bit I want and clear the old bit I don't want.
    Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 7b2f0c3e7929..cea445dcd806 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -214,6 +214,8 @@ int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		     gfp_t mask);
 int clear_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		       gfp_t mask);
+int convert_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
+		       int bits, int clear_bits, gfp_t mask);
 int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,

commit ab0fff03055d2d1b01a7581badeba18db9c4f55c
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon May 23 14:25:41 2011 +0200

    btrfs: add READAHEAD extent buffer flag
    
    Add a READAHEAD extent buffer flag.
    Add a function to trigger a read with this flag set.
    
    Changes v2:
     - use extent buffer flags instead of extent state flags
    
    Changes v5:
     - adapt to changed read_extent_buffer_pages interface
     - don't return eb from reada_tree_block_flagged if it has CORRUPT flag set
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6d74c6b34691..fcaf49bcb880 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -32,6 +32,7 @@
 #define EXTENT_BUFFER_BLOCKING 1
 #define EXTENT_BUFFER_DIRTY 2
 #define EXTENT_BUFFER_CORRUPT 3
+#define EXTENT_BUFFER_READAHEAD 4	/* this got triggered by readahead */
 
 /* these are flags for extent_clear_unlock_delalloc */
 #define EXTENT_CLEAR_UNLOCK_PAGE 0x1

commit bb82ab88dfdb12948af58989c75bfe904bc1b09d
Author: Arne Jansen <sensille@gmx.net>
Date:   Fri Jun 10 14:06:53 2011 +0200

    btrfs: add an extra wait mode to read_extent_buffer_pages
    
    read_extent_buffer_pages currently has two modes, either trigger a read
    without waiting for anything, or wait for the I/O to finish. The former
    also bails when it's unable to lock the page. This patch now adds an
    additional parameter to allow it to block on page lock, but don't wait
    for completion.
    
    Changes v5:
     - merge the 2 wait parameters into one and define WAIT_NONE, WAIT_COMPLETE and
       WAIT_PAGE_LOCK
    
    Change v6:
     - fix bug introduced in v5
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 7b2f0c3e7929..6d74c6b34691 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -248,6 +248,9 @@ struct extent_buffer *alloc_extent_buffer(struct extent_io_tree *tree,
 struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
 					 u64 start, unsigned long len);
 void free_extent_buffer(struct extent_buffer *eb);
+#define WAIT_NONE	0
+#define WAIT_COMPLETE	1
+#define WAIT_PAGE_LOCK	2
 int read_extent_buffer_pages(struct extent_io_tree *tree,
 			     struct extent_buffer *eb, u64 start, int wait,
 			     get_extent_t *get_extent, int mirror_num);

commit 4a54c8c165b66300830a67349fc7595e3fc442f7
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Fri Jul 22 15:41:52 2011 +0200

    btrfs: Moved repair code from inode.c to extent_io.c
    
    The raid-retry code in inode.c can be generalized so that it works for
    metadata as well. Thus, this patch moves it to extent_io.c and makes the
    raid-retry code a raid-repair code.
    
    Repair works that way: Whenever a read error occurs and we have more
    mirrors to try, note the failed mirror, and retry another. If we find a
    good one, check if we did note a failure earlier and if so, do not allow
    the read to complete until after the bad sector was written with the good
    data we just fetched. As we have the extent locked while reading, no one
    can change the data in between.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 435d454b9926..a8e20b672922 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -68,7 +68,7 @@ struct extent_io_ops {
 			      unsigned long bio_flags);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*readpage_io_failed_hook)(struct bio *bio, struct page *page,
-				       u64 start, u64 end,
+				       u64 start, u64 end, u64 failed_mirror,
 				       struct extent_state *state);
 	int (*writepage_io_failed_hook)(struct bio *bio, struct page *page,
 					u64 start, u64 end,
@@ -252,6 +252,8 @@ void free_extent_buffer(struct extent_buffer *eb);
 int read_extent_buffer_pages(struct extent_io_tree *tree,
 			     struct extent_buffer *eb, u64 start, int wait,
 			     get_extent_t *get_extent, int mirror_num);
+unsigned long num_extent_pages(u64 start, u64 len);
+struct page *extent_buffer_page(struct extent_buffer *eb, unsigned long i);
 
 static inline void extent_buffer_get(struct extent_buffer *eb)
 {
@@ -301,4 +303,10 @@ int extent_clear_unlock_delalloc(struct inode *inode,
 struct bio *
 btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,
 		gfp_t gfp_flags);
+
+struct btrfs_mapping_tree;
+
+int repair_io_failure(struct btrfs_mapping_tree *map_tree, u64 start,
+			u64 length, u64 logical, struct page *page,
+			int mirror_num);
 #endif

commit 0ef8e45158f97dde4801b535e25f70f7caf01a27
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Mon Jun 13 20:04:15 2011 +0200

    btrfs scrub: add fixup code for errors on nodatasum files
    
    This removes a FIXME comment and introduces the first part of nodatasum
    fixup: It gets the corresponding inode for a logical address and triggers a
    regular readpage for the corrupted sector.
    
    Once we have on-the-fly error correction our error will be automatically
    corrected. The correction code is expected to clear the newly introduced
    EXTENT_DAMAGED flag, making scrub report that error as "corrected" instead
    of "uncorrectable" eventually.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a9dd994bf826..435d454b9926 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -17,6 +17,7 @@
 #define EXTENT_NODATASUM (1 << 10)
 #define EXTENT_DO_ACCOUNTING (1 << 11)
 #define EXTENT_FIRST_DELALLOC (1 << 12)
+#define EXTENT_DAMAGED (1 << 13)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 #define EXTENT_CTLBITS (EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
 

commit 8ddc7d9cd0a00062247c732b96386ec2462bdbc7
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Mon Jun 13 20:02:58 2011 +0200

    btrfs: add mirror_num to extent_read_full_page
    
    Currently, extent_read_full_page always assumes we are trying to read mirror
    0, which generally is the best we can do. To add flexibility, pass it as a
    parameter. This will be needed by scrub fixup code.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 7b2f0c3e7929..a9dd994bf826 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -185,7 +185,7 @@ int unlock_extent_cached(struct extent_io_tree *tree, u64 start, u64 end,
 int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end,
 		    gfp_t mask);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
-			  get_extent_t *get_extent);
+			  get_extent_t *get_extent, int mirror_num);
 int __init extent_io_init(void);
 void extent_io_exit(void);
 

commit 3a6d457ec79d4cdf2313189b4e852e53f2b8d2b2
Author: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
Date:   Thu Jul 14 03:18:52 2011 +0000

    Btrfs: remove unused members from struct extent_state
    
    These members are not used at all.
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index d6871dc7524f..7b2f0c3e7929 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -108,8 +108,6 @@ struct extent_state {
 	wait_queue_head_t wq;
 	atomic_t refs;
 	unsigned long state;
-	u64 split_start;
-	u64 split_end;
 
 	/* for use by the FS */
 	u64 private;

commit 1bf85046e493c88be1c1bad9084428373089f618
Author: Jeff Mahoney <jeffm@suse.de>
Date:   Thu Jul 21 16:56:09 2011 +0000

    btrfs: Make extent-io callbacks that never fail return void
    
    The set/clear bit and the extent split/merge hooks only ever return 0.
    
     Changing them to return void simplifies the error handling cases later.
    
     This patch changes the hook prototypes, the single implementation of each,
     and the functions that call them to return void instead.
    
     Since all four of these hooks execute under a spinlock, they're necessarily
     simple.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 21a7ca9e7282..d6871dc7524f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -76,15 +76,15 @@ struct extent_io_ops {
 				    struct extent_state *state);
 	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
-	int (*set_bit_hook)(struct inode *inode, struct extent_state *state,
-			    int *bits);
-	int (*clear_bit_hook)(struct inode *inode, struct extent_state *state,
-			      int *bits);
-	int (*merge_extent_hook)(struct inode *inode,
-				 struct extent_state *new,
-				 struct extent_state *other);
-	int (*split_extent_hook)(struct inode *inode,
-				 struct extent_state *orig, u64 split);
+	void (*set_bit_hook)(struct inode *inode, struct extent_state *state,
+			     int *bits);
+	void (*clear_bit_hook)(struct inode *inode, struct extent_state *state,
+			       int *bits);
+	void (*merge_extent_hook)(struct inode *inode,
+				  struct extent_state *new,
+				  struct extent_state *other);
+	void (*split_extent_hook)(struct inode *inode,
+				  struct extent_state *orig, u64 split);
 	int (*write_cache_pages_lock_hook)(struct page *page);
 };
 

commit bd681513fa6f2ff29aa391f01e413a2d1c59fd77
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat Jul 16 15:23:14 2011 -0400

    Btrfs: switch the btrfs tree locks to reader/writer
    
    The btrfs metadata btree is the source of significant
    lock contention, especially in the root node.   This
    commit changes our locking to use a reader/writer
    lock.
    
    The lock is built on top of rw spinlocks, and it
    extends the lock tracking to remember if we have a
    read lock or a write lock when we go to blocking.  Atomics
    count the number of blocking readers or writers at any
    given time.
    
    It removes all of the adaptive spinning from the old code
    and uses only the spinning/blocking hints inside of btrfs
    to decide when it should continue spinning.
    
    In read heavy workloads this is dramatically faster.  In write
    heavy workloads we're still faster because of less contention
    on the root node lock.
    
    We suffer slightly in dbench because we schedule more often
    during write locks, but all other benchmarks so far are improved.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b5f120cca916..21a7ca9e7282 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -128,14 +128,26 @@ struct extent_buffer {
 	struct rcu_head rcu_head;
 	atomic_t refs;
 
-	/* the spinlock is used to protect most operations */
-	spinlock_t lock;
+	/* count of read lock holders on the extent buffer */
+	atomic_t write_locks;
+	atomic_t read_locks;
+	atomic_t blocking_writers;
+	atomic_t blocking_readers;
+	atomic_t spinning_readers;
+	atomic_t spinning_writers;
+
+	/* protects write locks */
+	rwlock_t lock;
+
+	/* readers use lock_wq while they wait for the write
+	 * lock holders to unlock
+	 */
+	wait_queue_head_t write_lock_wq;
 
-	/*
-	 * when we keep the lock held while blocking, waiters go onto
-	 * the wq
+	/* writers use read_lock_wq while they wait for readers
+	 * to unlock
 	 */
-	wait_queue_head_t lock_wq;
+	wait_queue_head_t read_lock_wq;
 };
 
 static inline void extent_set_compress_type(unsigned long *bio_flags,

commit a65917156e345946dbde3d7effd28124c6d6a8c2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 19 12:04:14 2011 -0400

    Btrfs: stop using highmem for extent_buffers
    
    The extent_buffers have a very complex interface where
    we use HIGHMEM for metadata and try to cache a kmap mapping
    to access the memory.
    
    The next commit adds reader/writer locks, and concurrent use
    of this kmap cache would make it even more complex.
    
    This commit drops the ability to use HIGHMEM with extent buffers,
    and rips out all of the related code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a11a92ee2d30..b5f120cca916 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -120,8 +120,6 @@ struct extent_state {
 struct extent_buffer {
 	u64 start;
 	unsigned long len;
-	char *map_token;
-	char *kaddr;
 	unsigned long map_start;
 	unsigned long map_len;
 	struct page *first_page;
@@ -279,15 +277,10 @@ int clear_extent_buffer_uptodate(struct extent_io_tree *tree,
 int extent_buffer_uptodate(struct extent_io_tree *tree,
 			   struct extent_buffer *eb,
 			   struct extent_state *cached_state);
-int map_extent_buffer(struct extent_buffer *eb, unsigned long offset,
-		      unsigned long min_len, char **token, char **map,
-		      unsigned long *map_start,
-		      unsigned long *map_len, int km);
 int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
-		      unsigned long min_len, char **token, char **map,
+		      unsigned long min_len, char **map,
 		      unsigned long *map_start,
-		      unsigned long *map_len, int km);
-void unmap_extent_buffer(struct extent_buffer *eb, char *token, int km);
+		      unsigned long *map_len);
 int extent_range_uptodate(struct extent_io_tree *tree,
 			  u64 start, u64 end);
 int extent_clear_unlock_delalloc(struct inode *inode,

commit 9eb9104c665aae2401a1723c044669eb10240072
Author: richard kennedy <richard@rsk.demon.co.uk>
Date:   Tue Jun 7 10:46:32 2011 +0000

    btrfs: remove 64bit alignment padding to allow extent_buffer to fit into one fewer cacheline
    
    Reorder extent_buffer to remove 8 bytes of alignment padding on 64 bit
    builds. This shrinks its size to 128 bytes allowing it to fit into one
    fewer cache lines and allows more objects per slab in its kmem_cache.
    
    slabinfo extent_buffer reports :-
    
     before:-
        Sizes (bytes)     Slabs
        ----------------------------------
        Object :     136  Total  :     123
        SlabObj:     136  Full   :     121
        SlabSiz:    4096  Partial:       0
        Loss   :       0  CpuSlab:       2
        Align  :       8  Objects:      30
    
     after :-
        Object :     128  Total  :       4
        SlabObj:     128  Full   :       2
        SlabSiz:    4096  Partial:       0
        Loss   :       0  CpuSlab:       2
        Align  :       8  Objects:      32
    
    Signed-off-by: Richard Kennedy <richard@rsk.demon.co.uk>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4e8445a4757c..a11a92ee2d30 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -126,9 +126,9 @@ struct extent_buffer {
 	unsigned long map_len;
 	struct page *first_page;
 	unsigned long bflags;
-	atomic_t refs;
 	struct list_head leak_list;
 	struct rcu_head rcu_head;
+	atomic_t refs;
 
 	/* the spinlock is used to protect most operations */
 	spinlock_t lock;

commit f2a97a9dbd86eb1ef956bdf20e05c507b32beb96
Author: David Sterba <dsterba@suse.cz>
Date:   Thu May 5 12:44:41 2011 +0200

    btrfs: remove all unused functions
    
    Remove static and global declarations and/or definitions. Reduces size
    of btrfs.ko by ~3.4kB.
    
      text    data     bss     dec     hex filename
    402081    7464     200  409745   64091 btrfs.ko.base
    398620    7144     200  405964   631cc btrfs.ko.remove-all
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index d1c5a57c9984..4e8445a4757c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -153,15 +153,6 @@ static inline int extent_compress_type(unsigned long bio_flags)
 
 struct extent_map_tree;
 
-static inline struct extent_state *extent_state_next(struct extent_state *state)
-{
-	struct rb_node *node;
-	node = rb_next(&state->rb_node);
-	if (!node)
-		return NULL;
-	return rb_entry(node, struct extent_state, rb_node);
-}
-
 typedef struct extent_map *(get_extent_t)(struct inode *inode,
 					  struct page *page,
 					  size_t pg_offset,
@@ -237,17 +228,8 @@ int extent_readpages(struct extent_io_tree *tree,
 		     struct address_space *mapping,
 		     struct list_head *pages, unsigned nr_pages,
 		     get_extent_t get_extent);
-int extent_prepare_write(struct extent_io_tree *tree,
-			 struct inode *inode, struct page *page,
-			 unsigned from, unsigned to, get_extent_t *get_extent);
-int extent_commit_write(struct extent_io_tree *tree,
-			struct inode *inode, struct page *page,
-			unsigned from, unsigned to);
-sector_t extent_bmap(struct address_space *mapping, sector_t iblock,
-		get_extent_t *get_extent);
 int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 		__u64 start, __u64 len, get_extent_t *get_extent);
-int set_range_dirty(struct extent_io_tree *tree, u64 start, u64 end);
 int set_state_private(struct extent_io_tree *tree, u64 start, u64 private);
 int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);
 void set_page_extent_mapped(struct page *page);
@@ -284,9 +266,6 @@ void memmove_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
 			   unsigned long src_offset, unsigned long len);
 void memset_extent_buffer(struct extent_buffer *eb, char c,
 			  unsigned long start, unsigned long len);
-int wait_on_extent_buffer_writeback(struct extent_io_tree *tree,
-				    struct extent_buffer *eb);
-int wait_on_extent_writeback(struct extent_io_tree *tree, u64 start, u64 end);
 int wait_extent_bit(struct extent_io_tree *tree, u64 start, u64 end, int bits);
 int clear_extent_buffer_dirty(struct extent_io_tree *tree,
 			      struct extent_buffer *eb);

commit 621496f4fd56195b7b273521f467c2945165481f
Author: David Sterba <dsterba@suse.cz>
Date:   Wed May 4 12:56:49 2011 +0200

    btrfs: remove unused function prototypes
    
    function prototypes without a body
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3c3be74c934e..d1c5a57c9984 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -215,14 +215,8 @@ int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		     gfp_t mask);
 int clear_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		       gfp_t mask);
-int clear_extent_ordered(struct extent_io_tree *tree, u64 start, u64 end,
-		       gfp_t mask);
-int clear_extent_ordered_metadata(struct extent_io_tree *tree, u64 start,
-				  u64 end, gfp_t mask);
 int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
 			struct extent_state **cached_state, gfp_t mask);
-int set_extent_ordered(struct extent_io_tree *tree, u64 start, u64 end,
-		     gfp_t mask);
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
 			  u64 *start_ret, u64 *end_ret, int bits);
 struct extent_state *find_first_extent_bit_state(struct extent_io_tree *tree,
@@ -298,8 +292,6 @@ int clear_extent_buffer_dirty(struct extent_io_tree *tree,
 			      struct extent_buffer *eb);
 int set_extent_buffer_dirty(struct extent_io_tree *tree,
 			     struct extent_buffer *eb);
-int test_extent_buffer_dirty(struct extent_io_tree *tree,
-			     struct extent_buffer *eb);
 int set_extent_buffer_uptodate(struct extent_io_tree *tree,
 			       struct extent_buffer *eb);
 int clear_extent_buffer_uptodate(struct extent_io_tree *tree,
@@ -317,7 +309,6 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long *map_start,
 		      unsigned long *map_len, int km);
 void unmap_extent_buffer(struct extent_buffer *eb, char *token, int km);
-int release_extent_buffer_tail_pages(struct extent_buffer *eb);
 int extent_range_uptodate(struct extent_io_tree *tree,
 			  u64 start, u64 end);
 int extent_clear_unlock_delalloc(struct inode *inode,

commit ba14419264684b290f0d0b7f48d26eafb11fc0c6
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Apr 21 01:12:06 2011 +0200

    btrfs: drop gfp parameter from alloc_extent_buffer
    
    pass GFP_NOFS directly to kmem_cache_alloc
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index ff220c3c01b0..3c3be74c934e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -260,8 +260,7 @@ void set_page_extent_mapped(struct page *page);
 
 struct extent_buffer *alloc_extent_buffer(struct extent_io_tree *tree,
 					  u64 start, unsigned long len,
-					  struct page *page0,
-					  gfp_t mask);
+					  struct page *page0);
 struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
 					 u64 start, unsigned long len);
 void free_extent_buffer(struct extent_buffer *eb);

commit f09d1f60e6aa82fb4cfaa525e21f6287fc1516f4
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Apr 21 01:08:01 2011 +0200

    btrfs: drop gfp parameter from find_extent_buffer
    
    pass GFP_NOFS directly to kmem_cache_alloc
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e9cfe8d1661c..ff220c3c01b0 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -263,8 +263,7 @@ struct extent_buffer *alloc_extent_buffer(struct extent_io_tree *tree,
 					  struct page *page0,
 					  gfp_t mask);
 struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
-					 u64 start, unsigned long len,
-					  gfp_t mask);
+					 u64 start, unsigned long len);
 void free_extent_buffer(struct extent_buffer *eb);
 int read_extent_buffer_pages(struct extent_io_tree *tree,
 			     struct extent_buffer *eb, u64 start, int wait,

commit f993c883ad8e111fb9e9ae603540acbe94f7246c
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Apr 20 23:35:57 2011 +0200

    btrfs: drop unused argument from extent_io_tree_init
    
    all callers pass GFP_NOFS, but the GFP mask argument is not used in the
    function; GFP_ATOMIC is passed to radix tree initialization and it's the
    only correct one, since we're using the preload/insert mechanism of
    radix tree.
    Let's drop the gfp mask from btrfs function, this will not change
    behaviour.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b9ce2f720742..e9cfe8d1661c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -169,7 +169,7 @@ typedef struct extent_map *(get_extent_t)(struct inode *inode,
 					  int create);
 
 void extent_io_tree_init(struct extent_io_tree *tree,
-			  struct address_space *mapping, gfp_t mask);
+			 struct address_space *mapping);
 int try_release_extent_mapping(struct extent_map_tree *map,
 			       struct extent_io_tree *tree, struct page *page,
 			       gfp_t mask);

commit 306e16ce13c0f3d4fc071b45803b5b83c2606011
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Apr 19 14:29:38 2011 +0200

    btrfs: rename variables clashing with global function names
    
    reported by gcc -Wshadow:
    page_index, page_offset, new_inode, dev_name
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index af2d7179c372..b9ce2f720742 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -164,7 +164,7 @@ static inline struct extent_state *extent_state_next(struct extent_state *state)
 
 typedef struct extent_map *(get_extent_t)(struct inode *inode,
 					  struct page *page,
-					  size_t page_offset,
+					  size_t pg_offset,
 					  u64 start, u64 len,
 					  int create);
 

commit 507903b81840a70cc6a179d4eb03584ad50e8c5b
Author: Arne Jansen <sensille@gmx.net>
Date:   Wed Apr 6 10:02:20 2011 +0000

    btrfs: using cached extent_state in set/unlock combinations
    
    In several places the sequence (set_extent_uptodate, unlock_extent) is used.
    This leads to a duplicate lookup of the extent state. This patch lets
    set_extent_uptodate return a cached extent_state which can be passed to
    unlock_extent_cached.
    The occurences of the above sequences are updated to use the cache. Only
    end_bio_extent_readpage is updated that it first gets a cached state to
    pass it to the readpage_end_io_hook as the prototype requested and is later
    on being used for set/unlock.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f62c5442835d..af2d7179c372 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -208,7 +208,7 @@ int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   int bits, int exclusive_bits, u64 *failed_start,
 		   struct extent_state **cached_state, gfp_t mask);
 int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
-			gfp_t mask);
+			struct extent_state **cached_state, gfp_t mask);
 int set_extent_new(struct extent_io_tree *tree, u64 start, u64 end,
 		   gfp_t mask);
 int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,

commit a826d6dcb32d811b4c81df57a5ef1367516586b0
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Mar 16 13:42:43 2011 -0400

    Btrfs: check items for correctness as we search
    
    Currently if we have corrupted items things will blow up in spectacular ways.
    So as we read in blocks and they are leaves, check the entire leaf to make sure
    all of the items are correct and point to valid parts in the leaf for the item
    data the are responsible for.  If the item is corrupt we will kick back EIO and
    not read any of the copies since they are likely to not be correct either.  This
    will catch generic corruptions, it will be up to the individual callers of
    btrfs_search_slot to make sure their items are right.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 9318dfefd59c..f62c5442835d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -31,6 +31,7 @@
 #define EXTENT_BUFFER_UPTODATE 0
 #define EXTENT_BUFFER_BLOCKING 1
 #define EXTENT_BUFFER_DIRTY 2
+#define EXTENT_BUFFER_CORRUPT 3
 
 /* these are flags for extent_clear_unlock_delalloc */
 #define EXTENT_CLEAR_UNLOCK_PAGE 0x1

commit ec29ed5b407d618a8128f5942aade9e1758aa14b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 23 16:23:20 2011 -0500

    Btrfs: fix fiemap bugs with delalloc
    
    The Btrfs fiemap code wasn't properly returning delalloc extents,
    so applications that trust fiemap to decide if there are holes in the
    file see holes instead of delalloc.
    
    This reworks the btrfs fiemap code, adding a get_extent helper that
    searches for delalloc ranges and also adding a helper for extent_fiemap
    that skips past holes in the file.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 7083cfafd061..9318dfefd59c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -191,7 +191,7 @@ void extent_io_exit(void);
 
 u64 count_range_bits(struct extent_io_tree *tree,
 		     u64 *start, u64 search_end,
-		     u64 max_bytes, unsigned long bits);
+		     u64 max_bytes, unsigned long bits, int contig);
 
 void free_extent_state(struct extent_state *state);
 int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,

commit 261507a02ccba9afda919852263b6bc1581ce1ef
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Dec 17 14:21:50 2010 +0800

    btrfs: Allow to add new compression algorithm
    
    Make the code aware of compression type, instead of always assuming
    zlib compression.
    
    Also make the zlib workspace function as common code for all
    compression types.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4183c8178f01..7083cfafd061 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -20,8 +20,12 @@
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 #define EXTENT_CTLBITS (EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
 
-/* flags for bio submission */
+/*
+ * flags for bio submission. The high bits indicate the compression
+ * type for this bio
+ */
 #define EXTENT_BIO_COMPRESSED 1
+#define EXTENT_BIO_FLAG_SHIFT 16
 
 /* these are bit numbers for test/set bit */
 #define EXTENT_BUFFER_UPTODATE 0
@@ -135,6 +139,17 @@ struct extent_buffer {
 	wait_queue_head_t lock_wq;
 };
 
+static inline void extent_set_compress_type(unsigned long *bio_flags,
+					    int compress_type)
+{
+	*bio_flags |= compress_type << EXTENT_BIO_FLAG_SHIFT;
+}
+
+static inline int extent_compress_type(unsigned long bio_flags)
+{
+	return bio_flags >> EXTENT_BIO_FLAG_SHIFT;
+}
+
 struct extent_map_tree;
 
 static inline struct extent_state *extent_state_next(struct extent_state *state)

commit 88f794ede7fadd4b63135b94d1561c1f2d5eb5f5
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Mon Nov 22 03:02:55 2010 +0000

    btrfs: cleanup duplicate bio allocating functions
    
    extent_bio_alloc() and compressed_bio_alloc() are similar, cleanup
    similar source code.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1c6d4f342ef7..4183c8178f01 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -310,4 +310,7 @@ int extent_clear_unlock_delalloc(struct inode *inode,
 				struct extent_io_tree *tree,
 				u64 start, u64 end, struct page *locked_page,
 				unsigned long op);
+struct bio *
+btrfs_bio_alloc(struct block_device *bdev, u64 first_sector, int nr_vecs,
+		gfp_t gfp_flags);
 #endif

commit 19fe0a8b787d7c7f9318975b5a8c6e7e5e54e925
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Oct 26 20:57:29 2010 -0400

    Btrfs: Switch the extent buffer rbtree into a radix tree
    
    This patch reduces the CPU time spent in the extent buffer search by using the
    radix tree instead of the rbtree and using the rcu lock instead of the spin
    lock.
    
    I did a quick test by the benchmark tool[1] and found the patch improve the
    file creation/deletion performance problem that I have reported[2].
    
    Before applying this patch:
    Create files:
            Total files: 50000
            Total time: 0.971531
            Average time: 0.000019
    Delete files:
            Total files: 50000
            Total time: 1.366761
            Average time: 0.000027
    
    After applying this patch:
    Create files:
            Total files: 50000
            Total time: 0.927455
            Average time: 0.000019
    Delete files:
            Total files: 50000
            Total time: 1.292280
            Average time: 0.000026
    
    [1] http://marc.info/?l=linux-btrfs&m=128212635122920&q=p3
    [2] http://marc.info/?l=linux-btrfs&m=128212635122920&w=2
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 5691c7b590da..1c6d4f342ef7 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -85,7 +85,7 @@ struct extent_io_ops {
 
 struct extent_io_tree {
 	struct rb_root state;
-	struct rb_root buffer;
+	struct radix_tree_root buffer;
 	struct address_space *mapping;
 	u64 dirty_bytes;
 	spinlock_t lock;
@@ -123,7 +123,7 @@ struct extent_buffer {
 	unsigned long bflags;
 	atomic_t refs;
 	struct list_head leak_list;
-	struct rb_node rb_node;
+	struct rcu_head rcu_head;
 
 	/* the spinlock is used to protect most operations */
 	spinlock_t lock;

commit 4845e44ffdb26be9b25610664228e8ecaf949a0d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 25 20:56:50 2010 -0400

    Btrfs: rework O_DIRECT enospc handling
    
    This changes O_DIRECT write code to mark extents as delalloc
    while it is processing them.  Yan Zheng has reworked the
    enospc accounting based on tracking delalloc extents and
    this makes it much easier to track enospc in the O_DIRECT code.
    
    There are a few space cases with the O_DIRECT code though,
    it only sets the EXTENT_DELALLOC bits, instead of doing
    EXTENT_DELALLOC | EXTENT_DIRTY | EXTENT_UPTODATE, because
    we don't want to mess with clearing the dirty and uptodate
    bits when things go wrong.  This is important because there
    are no pages in the page cache, so any extent state structs
    that we put in the tree won't get freed by releasepage.  We have
    to clear them ourselves as the DIO ends.
    
    With this commit, we reserve space at in btrfs_file_aio_write,
    and then as each btrfs_direct_IO call progresses it sets
    EXTENT_DELALLOC on the range.
    
    btrfs_get_blocks_direct is responsible for clearing the delalloc
    at the same time it drops the extent lock.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 86c7b341d070..5691c7b590da 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -178,6 +178,7 @@ u64 count_range_bits(struct extent_io_tree *tree,
 		     u64 *start, u64 search_end,
 		     u64 max_bytes, unsigned long bits);
 
+void free_extent_state(struct extent_state *state);
 int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   int bits, int filled, struct extent_state *cached_state);
 int clear_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
@@ -187,6 +188,9 @@ int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		     gfp_t mask);
 int set_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		    int bits, gfp_t mask);
+int set_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
+		   int bits, int exclusive_bits, u64 *failed_start,
+		   struct extent_state **cached_state, gfp_t mask);
 int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
 			gfp_t mask);
 int set_extent_new(struct extent_io_tree *tree, u64 start, u64 end,

commit eaf25d933e64c2bf3c79b83e8820404f36fdfc52
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 25 09:48:28 2010 -0400

    Btrfs: use async helpers for DIO write checksumming
    
    The async helper threads offload crc work onto all the
    CPUs, and make streaming writes much faster.  This
    changes the O_DIRECT write code to use them.  The only
    small complication was that we need to pass in the
    logical offset in the file for each bio, because we can't
    find it in the bio's pages.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 86f10dc791d9..86c7b341d070 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -49,7 +49,7 @@ struct extent_state;
 
 typedef	int (extent_submit_bio_hook_t)(struct inode *inode, int rw,
 				       struct bio *bio, int mirror_num,
-				       unsigned long bio_flags);
+				       unsigned long bio_flags, u64 bio_offset);
 struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, struct page *locked_page,
 			     u64 start, u64 end, int *page_started,

commit 0ca1f7ceb1991099ed5273885ebcf4323948c72e
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:48:47 2010 -0400

    Btrfs: Update metadata reservation for delayed allocation
    
    Introduce metadata reservation context for delayed allocation
    and update various related functions.
    
    This patch also introduces EXTENT_FIRST_DELALLOC control bit for
    set/clear_extent_bit. It tells set/clear_bit_hook whether they
    are processing the first extent_state with EXTENT_DELALLOC bit
    set. This change is important if set/clear_extent_bit involves
    multiple extent_state.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index bbab4813646f..86f10dc791d9 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -16,7 +16,9 @@
 #define EXTENT_BOUNDARY (1 << 9)
 #define EXTENT_NODATASUM (1 << 10)
 #define EXTENT_DO_ACCOUNTING (1 << 11)
+#define EXTENT_FIRST_DELALLOC (1 << 12)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
+#define EXTENT_CTLBITS (EXTENT_DO_ACCOUNTING | EXTENT_FIRST_DELALLOC)
 
 /* flags for bio submission */
 #define EXTENT_BIO_COMPRESSED 1
@@ -69,10 +71,10 @@ struct extent_io_ops {
 				    struct extent_state *state);
 	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state, int uptodate);
-	int (*set_bit_hook)(struct inode *inode, u64 start, u64 end,
-			    unsigned long old, unsigned long bits);
+	int (*set_bit_hook)(struct inode *inode, struct extent_state *state,
+			    int *bits);
 	int (*clear_bit_hook)(struct inode *inode, struct extent_state *state,
-			      unsigned long bits);
+			      int *bits);
 	int (*merge_extent_hook)(struct inode *inode,
 				 struct extent_state *new,
 				 struct extent_state *other);

commit 2ac55d41b5d6bf49e76bc85db5431240617e2f8f
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Feb 3 19:33:23 2010 +0000

    Btrfs: cache the extent state everywhere we possibly can V2
    
    This patch just goes through and fixes everybody that does
    
    lock_extent()
    blah
    unlock_extent()
    
    to use
    
    lock_extent_bits()
    blah
    unlock_extent_cached()
    
    and pass around a extent_state so we only have to do the searches once per
    function.  This gives me about a 3 mb/s boots on my random write test.  I have
    not converted some things, like the relocation and ioctl's, since they aren't
    heavily used and the relocation stuff is in the middle of being re-written.  I
    also changed the clear_extent_bit() to only unset the cached state if we are
    clearing EXTENT_LOCKED and related stuff, so we can do things like this
    
    lock_extent_bits()
    clear delalloc bits
    unlock_extent_cached()
    
    without losing our cached state.  I tested this thoroughly and turned on
    LEAK_DEBUG to make sure we weren't leaking extent states, everything worked out
    fine.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 36de250a7b2b..bbab4813646f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -163,6 +163,8 @@ int lock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		     int bits, struct extent_state **cached, gfp_t mask);
 int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
+int unlock_extent_cached(struct extent_io_tree *tree, u64 start, u64 end,
+			 struct extent_state **cached, gfp_t mask);
 int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end,
 		    gfp_t mask);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
@@ -196,7 +198,7 @@ int clear_extent_ordered(struct extent_io_tree *tree, u64 start, u64 end,
 int clear_extent_ordered_metadata(struct extent_io_tree *tree, u64 start,
 				  u64 end, gfp_t mask);
 int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
-		     gfp_t mask);
+			struct extent_state **cached_state, gfp_t mask);
 int set_extent_ordered(struct extent_io_tree *tree, u64 start, u64 end,
 		     gfp_t mask);
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
@@ -281,9 +283,11 @@ int test_extent_buffer_dirty(struct extent_io_tree *tree,
 int set_extent_buffer_uptodate(struct extent_io_tree *tree,
 			       struct extent_buffer *eb);
 int clear_extent_buffer_uptodate(struct extent_io_tree *tree,
-				struct extent_buffer *eb);
+				struct extent_buffer *eb,
+				struct extent_state **cached_state);
 int extent_buffer_uptodate(struct extent_io_tree *tree,
-			   struct extent_buffer *eb);
+			   struct extent_buffer *eb,
+			   struct extent_state *cached_state);
 int map_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long min_len, char **token, char **map,
 		      unsigned long *map_start,

commit 32c00aff718bb54a214b39146bdd9ac01511cd25
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Oct 8 13:34:05 2009 -0400

    Btrfs: release delalloc reservations on extent item insertion
    
    This patch fixes an issue with the delalloc metadata space reservation
    code.  The problem is we used to free the reservation as soon as we
    allocated the delalloc region.  The problem with this is if we are not
    inserting an inline extent, we don't actually insert the extent item until
    after the ordered extent is written out.  This patch does 3 things,
    
    1) It moves the reservation clearing stuff into the ordered code, so when
    we remove the ordered extent we remove the reservation.
    2) It adds a EXTENT_DO_ACCOUNTING flag that gets passed when we clear
    delalloc bits in the cases where we want to clear the metadata reservation
    when we clear the delalloc extent, in the case that we do an inline extent
    or we invalidate the page.
    3) It adds another waitqueue to the space info so that when we start a fs
    wide delalloc flush, anybody else who also hits that area will simply wait
    for the flush to finish and then try to make their allocation.
    
    This has been tested thoroughly to make sure we did not regress on
    performance.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 41d2a47ecf38..36de250a7b2b 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -15,6 +15,7 @@
 #define EXTENT_BUFFER_FILLED (1 << 8)
 #define EXTENT_BOUNDARY (1 << 9)
 #define EXTENT_NODATASUM (1 << 10)
+#define EXTENT_DO_ACCOUNTING (1 << 11)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 
 /* flags for bio submission */
@@ -33,6 +34,7 @@
 #define EXTENT_SET_WRITEBACK	 0x10
 #define EXTENT_END_WRITEBACK	 0x20
 #define EXTENT_SET_PRIVATE2	 0x40
+#define EXTENT_CLEAR_ACCOUNTING  0x80
 
 /*
  * page->private values.  Every page that is controlled by the extent

commit a791e35e12ff672e8a0e140abeeaf900c3b2ea77
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Oct 8 11:27:10 2009 -0400

    Btrfs: cleanup extent_clear_unlock_delalloc flags
    
    extent_clear_unlock_delalloc has a growing set of ugly parameters
    that is very difficult to read and maintain.
    
    This switches to a flag field and well named flag defines.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 4794ec891fed..41d2a47ecf38 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -25,6 +25,15 @@
 #define EXTENT_BUFFER_BLOCKING 1
 #define EXTENT_BUFFER_DIRTY 2
 
+/* these are flags for extent_clear_unlock_delalloc */
+#define EXTENT_CLEAR_UNLOCK_PAGE 0x1
+#define EXTENT_CLEAR_UNLOCK	 0x2
+#define EXTENT_CLEAR_DELALLOC	 0x4
+#define EXTENT_CLEAR_DIRTY	 0x8
+#define EXTENT_SET_WRITEBACK	 0x10
+#define EXTENT_END_WRITEBACK	 0x20
+#define EXTENT_SET_PRIVATE2	 0x40
+
 /*
  * page->private values.  Every page that is controlled by the extent
  * map has page->private set to one.
@@ -288,10 +297,5 @@ int extent_range_uptodate(struct extent_io_tree *tree,
 int extent_clear_unlock_delalloc(struct inode *inode,
 				struct extent_io_tree *tree,
 				u64 start, u64 end, struct page *locked_page,
-				int unlock_page,
-				int clear_unlock,
-				int clear_delalloc, int clear_dirty,
-				int set_writeback,
-				int end_writeback,
-				int set_private2);
+				unsigned long op);
 #endif

commit 9ed74f2dba6ebf9f30b80554290bfc73cc3ef083
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Sep 11 16:12:44 2009 -0400

    Btrfs: proper -ENOSPC handling
    
    At the start of a transaction we do a btrfs_reserve_metadata_space() and
    specify how many items we plan on modifying.  Then once we've done our
    modifications and such, just call btrfs_unreserve_metadata_space() for
    the same number of items we reserved.
    
    For keeping track of metadata needed for data I've had to add an extent_io op
    for when we merge extents.  This lets us track space properly when we are doing
    sequential writes, so we don't end up reserving way more metadata space than
    what we need.
    
    The only place where the metadata space accounting is not done is in the
    relocation code.  This is because Yan is going to be reworking that code in the
    near future, so running btrfs-vol -b could still possibly result in a ENOSPC
    related panic.  This patch also turns off the metadata_ratio stuff in order to
    allow users to more efficiently use their disk space.
    
    This patch makes it so we track how much metadata we need for an inode's
    delayed allocation extents by tracking how many extents are currently
    waiting for allocation.  It introduces two new callbacks for the
    extent_io tree's, merge_extent_hook and split_extent_hook.  These help
    us keep track of when we merge delalloc extents together and split them
    up.  Reservations are handled prior to any actually dirty'ing occurs,
    and then we unreserve after we dirty.
    
    btrfs_unreserve_metadata_for_delalloc() will make the appropriate
    unreservations as needed based on the number of reservations we
    currently have and the number of extents we currently have.  Doing the
    reservation outside of doing any of the actual dirty'ing lets us do
    things like filemap_flush() the inode to try and force delalloc to
    happen, or as a last resort actually start allocation on all delalloc
    inodes in the fs.  This has survived dbench, fs_mark and an fsx torture
    test.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 14ed16fd862d..4794ec891fed 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -60,8 +60,13 @@ struct extent_io_ops {
 				      struct extent_state *state, int uptodate);
 	int (*set_bit_hook)(struct inode *inode, u64 start, u64 end,
 			    unsigned long old, unsigned long bits);
-	int (*clear_bit_hook)(struct inode *inode, u64 start, u64 end,
-			    unsigned long old, unsigned long bits);
+	int (*clear_bit_hook)(struct inode *inode, struct extent_state *state,
+			      unsigned long bits);
+	int (*merge_extent_hook)(struct inode *inode,
+				 struct extent_state *new,
+				 struct extent_state *other);
+	int (*split_extent_hook)(struct inode *inode,
+				 struct extent_state *orig, u64 split);
 	int (*write_cache_pages_lock_hook)(struct page *page);
 };
 
@@ -79,10 +84,14 @@ struct extent_state {
 	u64 start;
 	u64 end; /* inclusive */
 	struct rb_node rb_node;
+
+	/* ADD NEW ELEMENTS AFTER THIS */
 	struct extent_io_tree *tree;
 	wait_queue_head_t wq;
 	atomic_t refs;
 	unsigned long state;
+	u64 split_start;
+	u64 split_end;
 
 	/* for use by the FS */
 	u64 private;

commit 8b62b72b26bcd72082c4a69d179dd906bcc22200
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Sep 2 16:53:46 2009 -0400

    Btrfs: Use PagePrivate2 to track pages in the data=ordered code.
    
    Btrfs writes go through delalloc to the data=ordered code.  This
    makes sure that all of the data is on disk before the metadata
    that references it.  The tracking means that we have to make sure
    each page in an extent is fully written before we add that extent into
    the on-disk btree.
    
    This was done in the past by setting the EXTENT_ORDERED bit for the
    range of an extent when it was added to the data=ordered code, and then
    clearing the EXTENT_ORDERED bit in the extent state tree as each page
    finished IO.
    
    One of the reasons we had to do this was because sometimes pages are
    magically dirtied without page_mkwrite being called.  The EXTENT_ORDERED
    bit is checked at writepage time, and if it isn't there, our page become
    dirty without going through the proper path.
    
    These bit operations make for a number of rbtree searches for each page,
    and can cause considerable lock contention.
    
    This commit switches from the EXTENT_ORDERED bit to use PagePrivate2.
    As pages go into the ordered code, PagePrivate2 is set on each one.
    This is a cheap operation because we already have all the pages locked
    and ready to go.
    
    As IO finishes, the PagePrivate2 bit is cleared and the ordered
    accoutning is updated for each page.
    
    At writepage time, if the PagePrivate2 bit is missing, we go into the
    writepage fixup code to handle improperly dirtied pages.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 09cd6fa3cc86..14ed16fd862d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -13,10 +13,8 @@
 #define EXTENT_DEFRAG (1 << 6)
 #define EXTENT_DEFRAG_DONE (1 << 7)
 #define EXTENT_BUFFER_FILLED (1 << 8)
-#define EXTENT_ORDERED (1 << 9)
-#define EXTENT_ORDERED_METADATA (1 << 10)
-#define EXTENT_BOUNDARY (1 << 11)
-#define EXTENT_NODATASUM (1 << 12)
+#define EXTENT_BOUNDARY (1 << 9)
+#define EXTENT_NODATASUM (1 << 10)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 
 /* flags for bio submission */
@@ -285,5 +283,6 @@ int extent_clear_unlock_delalloc(struct inode *inode,
 				int clear_unlock,
 				int clear_delalloc, int clear_dirty,
 				int set_writeback,
-				int end_writeback);
+				int end_writeback,
+				int set_private2);
 #endif

commit 9655d2982b53fdb38a9e0f2f11315b99b92d66e2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Sep 2 15:22:30 2009 -0400

    Btrfs: use a cached state for extent state operations during delalloc
    
    This changes the btrfs code to find delalloc ranges in the extent state
    tree to use the new state caching code from set/test bit.  It reduces
    one of the biggest causes of rbtree searches in the writeback path.
    
    test_range_bit is also modified to take the cached state as a starting
    point while searching.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c8ead2b8c4c9..09cd6fa3cc86 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -157,7 +157,7 @@ u64 count_range_bits(struct extent_io_tree *tree,
 		     u64 max_bytes, unsigned long bits);
 
 int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		   int bits, int filled);
+		   int bits, int filled, struct extent_state *cached_state);
 int clear_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		      int bits, gfp_t mask);
 int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,

commit 2c64c53d8d30d43d0670482503a3914dfd3d6d46
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Sep 2 15:04:12 2009 -0400

    Btrfs: cache values for locking extents
    
    Many of the btrfs extent state tree users follow the same pattern.
    They lock an extent range in the tree, do some operation and then
    unlock.
    
    This translates to at least 2 rbtree searches, and maybe more if they
    are doing operations on the extent state tree.  A locked extent
    in the tree isn't going to be merged or changed, and so we can
    safely return the extent state structure as a cached handle.
    
    This changes set_extent_bit to give back a cached handle, and also
    changes both set_extent_bit and clear_extent_bit to use the cached
    handle if it is available.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 88d134d01fbc..c8ead2b8c4c9 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -143,7 +143,7 @@ int try_release_extent_state(struct extent_map_tree *map,
 			     gfp_t mask);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
 int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
-		     int bits, gfp_t mask);
+		     int bits, struct extent_state **cached, gfp_t mask);
 int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
 int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end,
 		    gfp_t mask);
@@ -161,7 +161,8 @@ int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
 int clear_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		      int bits, gfp_t mask);
 int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
-		     int bits, int wake, int delete, gfp_t mask);
+		     int bits, int wake, int delete, struct extent_state **cached,
+		     gfp_t mask);
 int set_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		    int bits, gfp_t mask);
 int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,

commit 1edbb734b4e010974c41d2859d22a43d04f5f1cf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Sep 2 13:24:36 2009 -0400

    Btrfs: reduce CPU usage in the extent_state tree
    
    Btrfs is currently mirroring some of the page state bits into
    its extent state tree.  The goal behind this was to use it in supporting
    blocksizes other than the page size.
    
    But, we don't currently support that, and we're using quite a lot of CPU
    on the rb tree and its spin lock.  This commit starts a series of
    cleanups to reduce the amount of work done in the extent state tree as
    part of each IO.
    
    This commit:
    
    * Adds the ability to lock an extent in the state tree and also set
    other bits.  The idea is to do locking and delalloc in one call
    
    * Removes the EXTENT_WRITEBACK and EXTENT_DIRTY bits.  Btrfs is using
    a combination of the page bits and the ordered write code for this
    instead.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 5bc20abf3f3d..88d134d01fbc 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -142,6 +142,8 @@ int try_release_extent_state(struct extent_map_tree *map,
 			     struct extent_io_tree *tree, struct page *page,
 			     gfp_t mask);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
+int lock_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
+		     int bits, gfp_t mask);
 int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
 int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end,
 		    gfp_t mask);

commit b9473439d3e84d9fc1a0a83faca69cc1b7566341
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 11:00:37 2009 -0400

    Btrfs: leave btree locks spinning more often
    
    btrfs_mark_buffer dirty would set dirty bits in the extent_io tree
    for the buffers it was dirtying.  This may require a kmalloc and it
    was not atomic.  So, anyone who called btrfs_mark_buffer_dirty had to
    set any btree locks they were holding to blocking first.
    
    This commit changes dirty tracking for extent buffers to just use a flag
    in the extent buffer.  Now that we have one and only one extent buffer
    per page, this can be safely done without losing dirty bits along the way.
    
    This also introduces a path->leave_spinning flag that callers of
    btrfs_search_slot can use to indicate they will properly deal with a
    path returned where all the locks are spinning instead of blocking.
    
    Many of the btree search callers now expect spinning paths,
    resulting in better btree concurrency overall.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 1f9df88afbf6..5bc20abf3f3d 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -25,6 +25,7 @@
 /* these are bit numbers for test/set bit */
 #define EXTENT_BUFFER_UPTODATE 0
 #define EXTENT_BUFFER_BLOCKING 1
+#define EXTENT_BUFFER_DIRTY 2
 
 /*
  * page->private values.  Every page that is controlled by the extent
@@ -254,6 +255,8 @@ int clear_extent_buffer_dirty(struct extent_io_tree *tree,
 			      struct extent_buffer *eb);
 int set_extent_buffer_dirty(struct extent_io_tree *tree,
 			     struct extent_buffer *eb);
+int test_extent_buffer_dirty(struct extent_io_tree *tree,
+			     struct extent_buffer *eb);
 int set_extent_buffer_uptodate(struct extent_io_tree *tree,
 			       struct extent_buffer *eb);
 int clear_extent_buffer_uptodate(struct extent_io_tree *tree,

commit b4ce94de9b4d64e8ab3cf155d13653c666e22b9b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 4 09:25:08 2009 -0500

    Btrfs: Change btree locking to use explicit blocking points
    
    Most of the btrfs metadata operations can be protected by a spinlock,
    but some operations still need to schedule.
    
    So far, btrfs has been using a mutex along with a trylock loop,
    most of the time it is able to avoid going for the full mutex, so
    the trylock loop is a big performance gain.
    
    This commit is step one for getting rid of the blocking locks entirely.
    btrfs_tree_lock takes a spinlock, and the code explicitly switches
    to a blocking lock when it starts an operation that can schedule.
    
    We'll be able get rid of the blocking locks in smaller pieces over time.
    Tracing allows us to find the most common cause of blocking, so we
    can start with the hot spots first.
    
    The basic idea is:
    
    btrfs_tree_lock() returns with the spin lock held
    
    btrfs_set_lock_blocking() sets the EXTENT_BUFFER_BLOCKING bit in
    the extent buffer flags, and then drops the spin lock.  The buffer is
    still considered locked by all of the btrfs code.
    
    If btrfs_tree_lock gets the spinlock but finds the blocking bit set, it drops
    the spin lock and waits on a wait queue for the blocking bit to go away.
    
    Much of the code that needs to set the blocking bit finishes without actually
    blocking a good percentage of the time.  So, an adaptive spin is still
    used against the blocking bit to avoid very high context switch rates.
    
    btrfs_clear_lock_blocking() clears the blocking bit and returns
    with the spinlock held again.
    
    btrfs_tree_unlock() can be called on either blocking or spinning locks,
    it does the right thing based on the blocking bit.
    
    ctree.c has a helper function to set/clear all the locked buffers in a
    path as blocking.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e80c6d96b318..1f9df88afbf6 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -22,6 +22,10 @@
 /* flags for bio submission */
 #define EXTENT_BIO_COMPRESSED 1
 
+/* these are bit numbers for test/set bit */
+#define EXTENT_BUFFER_UPTODATE 0
+#define EXTENT_BUFFER_BLOCKING 1
+
 /*
  * page->private values.  Every page that is controlled by the extent
  * map has page->private set to one.
@@ -95,11 +99,19 @@ struct extent_buffer {
 	unsigned long map_start;
 	unsigned long map_len;
 	struct page *first_page;
+	unsigned long bflags;
 	atomic_t refs;
-	int flags;
 	struct list_head leak_list;
 	struct rb_node rb_node;
-	struct mutex mutex;
+
+	/* the spinlock is used to protect most operations */
+	spinlock_t lock;
+
+	/*
+	 * when we keep the lock held while blocking, waiters go onto
+	 * the wq
+	 */
+	wait_queue_head_t lock_wq;
 };
 
 struct extent_map_tree;

commit 1506fcc8189cdd4b95e06df7845a09f18b4526a6
Author: Yehuda Sadeh <yehuda@hq.newdream.net>
Date:   Wed Jan 21 14:39:14 2009 -0500

    Btrfs: fiemap support
    
    Now that bmap support is gone, this is the only way to get extent
    mappings for userland.  These are still not valid for IO, but they
    can tell us if a file has holes or how much fragmentation there is.
    
    Signed-off-by: Yehuda Sadeh <yehuda@hq.newdream.net>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c5b483a79137..e80c6d96b318 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -193,6 +193,8 @@ int extent_commit_write(struct extent_io_tree *tree,
 			unsigned from, unsigned to);
 sector_t extent_bmap(struct address_space *mapping, sector_t iblock,
 		get_extent_t *get_extent);
+int extent_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
+		__u64 start, __u64 len, get_extent_t *get_extent);
 int set_range_dirty(struct extent_io_tree *tree, u64 start, u64 end);
 int set_state_private(struct extent_io_tree *tree, u64 start, u64 private);
 int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);

commit 17d217fe970d34720f4f1633dca73a6aa2f3d9d1
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Fri Dec 12 10:03:38 2008 -0500

    Btrfs: fix nodatasum handling in balancing code
    
    Checksums on data can be disabled by mount option, so it's
    possible some data extents don't have checksums or have
    invalid checksums. This causes trouble for data relocation.
    This patch contains following things to make data relocation
    work.
    
    1) make nodatasum/nodatacow mount option only affects new
    files. Checksums and COW on data are only controlled by the
    inode flags.
    
    2) check the existence of checksum in the nodatacow checker.
    If checksums exist, force COW the data extent. This ensure that
    checksum for a given block is either valid or does not exist.
    
    3) update data relocation code to properly handle the case
    of checksum missing.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 2d5f67065b69..c5b483a79137 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -16,6 +16,7 @@
 #define EXTENT_ORDERED (1 << 9)
 #define EXTENT_ORDERED_METADATA (1 << 10)
 #define EXTENT_BOUNDARY (1 << 11)
+#define EXTENT_NODATASUM (1 << 12)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 
 /* flags for bio submission */

commit 771ed689d2cd53439e28e095bc38fbe40a71429e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 6 22:02:51 2008 -0500

    Btrfs: Optimize compressed writeback and reads
    
    When reading compressed extents, try to put pages into the page cache
    for any pages covered by the compressed extent that readpages didn't already
    preload.
    
    Add an async work queue to handle transformations at delayed allocation processing
    time.  Right now this is just compression.  The workflow is:
    
    1) Find offsets in the file marked for delayed allocation
    2) Lock the pages
    3) Lock the state bits
    4) Call the async delalloc code
    
    The async delalloc code clears the state lock bits and delalloc bits.  It is
    important this happens before the range goes into the work queue because
    otherwise it might deadlock with other work queue items that try to lock
    those extent bits.
    
    The file pages are compressed, and if the compression doesn't work the
    pages are written back directly.
    
    An ordered work queue is used to make sure the inodes are written in the same
    order that pdflush or writepages sent them down.
    
    This changes extent_write_cache_pages to let the writepage function
    update the wbc nr_written count.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 283110ec4ee0..2d5f67065b69 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -35,7 +35,8 @@ typedef	int (extent_submit_bio_hook_t)(struct inode *inode, int rw,
 				       unsigned long bio_flags);
 struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, struct page *locked_page,
-			     u64 start, u64 end, int *page_started);
+			     u64 start, u64 end, int *page_started,
+			     unsigned long *nr_written);
 	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
 	extent_submit_bio_hook_t *submit_bio_hook;
@@ -172,6 +173,9 @@ int extent_invalidatepage(struct extent_io_tree *tree,
 int extent_write_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent,
 			  struct writeback_control *wbc);
+int extent_write_locked_range(struct extent_io_tree *tree, struct inode *inode,
+			      u64 start, u64 end, get_extent_t *get_extent,
+			      int mode);
 int extent_writepages(struct extent_io_tree *tree,
 		      struct address_space *mapping,
 		      get_extent_t *get_extent,
@@ -256,6 +260,9 @@ int extent_range_uptodate(struct extent_io_tree *tree,
 int extent_clear_unlock_delalloc(struct inode *inode,
 				struct extent_io_tree *tree,
 				u64 start, u64 end, struct page *locked_page,
-				int clear_dirty, int set_writeback,
-				int clear_writeback);
+				int unlock_page,
+				int clear_unlock,
+				int clear_delalloc, int clear_dirty,
+				int set_writeback,
+				int end_writeback);
 #endif

commit 2517920135b0d29e70453e5b03d70d7b94207df3
Author: Josef Bacik <jbacik@redhat.com>
Date:   Wed Oct 29 14:49:05 2008 -0400

    Btrfs: nuke fs wide allocation mutex V2
    
    This patch removes the giant fs_info->alloc_mutex and replaces it with a bunch
    of little locks.
    
    There is now a pinned_mutex, which is used when messing with the pinned_extents
    extent io tree, and the extent_ins_mutex which is used with the pending_del and
    extent_ins extent io trees.
    
    The locking for the extent tree stuff was inspired by a patch that Yan Zheng
    wrote to fix a race condition, I cleaned it up some and changed the locking
    around a little bit, but the idea remains the same.  Basically instead of
    holding the extent_ins_mutex throughout the processing of an extent on the
    extent_ins or pending_del trees, we just hold it while we're searching and when
    we clear the bits on those trees, and lock the extent for the duration of the
    operations on the extent.
    
    Also to keep from getting hung up waiting to lock an extent, I've added a
    try_lock_extent so if we cannot lock the extent, move on to the next one in the
    tree and we'll come back to that one.  I have tested this heavily and it does
    not appear to break anything.  This has to be applied on top of my
    find_free_extent redo patch.
    
    I tested this patch on top of Yan's space reblancing code and it worked fine.
    The only thing that has changed since the last version is I pulled out all my
    debugging stuff, apparently I forgot to run guilt refresh before I sent the
    last patch out.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 86f859b87a6e..283110ec4ee0 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -128,6 +128,8 @@ int try_release_extent_state(struct extent_map_tree *map,
 			     gfp_t mask);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
 int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
+int try_lock_extent(struct extent_io_tree *tree, u64 start, u64 end,
+		    gfp_t mask);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
 			  get_extent_t *get_extent);
 int __init extent_io_init(void);

commit c8b978188c9a0fd3d535c13debd19d522b726f1f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Oct 29 14:49:59 2008 -0400

    Btrfs: Add zlib compression support
    
    This is a large change for adding compression on reading and writing,
    both for inline and regular extents.  It does some fairly large
    surgery to the writeback paths.
    
    Compression is off by default and enabled by mount -o compress.  Even
    when the -o compress mount option is not used, it is possible to read
    compressed extents off the disk.
    
    If compression for a given set of pages fails to make them smaller, the
    file is flagged to avoid future compression attempts later.
    
    * While finding delalloc extents, the pages are locked before being sent down
    to the delalloc handler.  This allows the delalloc handler to do complex things
    such as cleaning the pages, marking them writeback and starting IO on their
    behalf.
    
    * Inline extents are inserted at delalloc time now.  This allows us to compress
    the data before inserting the inline extent, and it allows us to insert
    an inline extent that spans multiple pages.
    
    * All of the in-memory extent representations (extent_map.c, ordered-data.c etc)
    are changed to record both an in-memory size and an on disk size, as well
    as a flag for compression.
    
    From a disk format point of view, the extent pointers in the file are changed
    to record the on disk size of a given extent and some encoding flags.
    Space in the disk format is allocated for compression encoding, as well
    as encryption and a generic 'other' field.  Neither the encryption or the
    'other' field are currently used.
    
    In order to limit the amount of data read for a single random read in the
    file, the size of a compressed extent is limited to 128k.  This is a
    software only limit, the disk format supports u64 sized compressed extents.
    
    In order to limit the ram consumed while processing extents, the uncompressed
    size of a compressed extent is limited to 256k.  This is a software only limit
    and will be subject to tuning later.
    
    Checksumming is still done on compressed extents, and it is done on the
    uncompressed version of the data.  This way additional encodings can be
    layered on without having to figure out which encoding to checksum.
    
    Compression happens at delalloc time, which is basically singled threaded because
    it is usually done by a single pdflush thread.  This makes it tricky to
    spread the compression load across all the cpus on the box.  We'll have to
    look at parallel pdflush walks of dirty inodes at a later time.
    
    Decompression is hooked into readpages and it does spread across CPUs nicely.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index c9d1908a1ae3..86f859b87a6e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -18,6 +18,9 @@
 #define EXTENT_BOUNDARY (1 << 11)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 
+/* flags for bio submission */
+#define EXTENT_BIO_COMPRESSED 1
+
 /*
  * page->private values.  Every page that is controlled by the extent
  * map has page->private set to one.
@@ -28,14 +31,17 @@
 struct extent_state;
 
 typedef	int (extent_submit_bio_hook_t)(struct inode *inode, int rw,
-				       struct bio *bio, int mirror_num);
+				       struct bio *bio, int mirror_num,
+				       unsigned long bio_flags);
 struct extent_io_ops {
-	int (*fill_delalloc)(struct inode *inode, u64 start, u64 end);
+	int (*fill_delalloc)(struct inode *inode, struct page *locked_page,
+			     u64 start, u64 end, int *page_started);
 	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
 	extent_submit_bio_hook_t *submit_bio_hook;
 	int (*merge_bio_hook)(struct page *page, unsigned long offset,
-			      size_t size, struct bio *bio);
+			      size_t size, struct bio *bio,
+			      unsigned long bio_flags);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*readpage_io_failed_hook)(struct bio *bio, struct page *page,
 				       u64 start, u64 end,
@@ -245,4 +251,9 @@ void unmap_extent_buffer(struct extent_buffer *eb, char *token, int km);
 int release_extent_buffer_tail_pages(struct extent_buffer *eb);
 int extent_range_uptodate(struct extent_io_tree *tree,
 			  u64 start, u64 end);
+int extent_clear_unlock_delalloc(struct inode *inode,
+				struct extent_io_tree *tree,
+				u64 start, u64 end, struct page *locked_page,
+				int clear_dirty, int set_writeback,
+				int clear_writeback);
 #endif

commit 5b21f2ed3f2947b5195b65c9fdbdd9e52904cc03
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Fri Sep 26 10:05:38 2008 -0400

    Btrfs: extent_map and data=ordered fixes for space balancing
    
    * Add an EXTENT_BOUNDARY state bit to keep the writepage code
    from merging data extents that are in the process of being
    relocated.  This allows us to do accounting for them properly.
    
    * The balancing code relocates data extents indepdent of the underlying
    inode.  The extent_map code was modified to properly account for
    things moving around (invalidating extent_map caches in the inode).
    
    * Don't take the drop_mutex in the create_subvol ioctl.  It isn't
    required.
    
    * Fix walking of the ordered extent list to avoid races with sys_unlink
    
    * Change the lock ordering rules.  Transaction start goes outside
    the drop_mutex.  This allows btrfs_commit_transaction to directly
    drop the relocation trees.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 3cb411a5f4d3..c9d1908a1ae3 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -15,6 +15,7 @@
 #define EXTENT_BUFFER_FILLED (1 << 8)
 #define EXTENT_ORDERED (1 << 9)
 #define EXTENT_ORDERED_METADATA (1 << 10)
+#define EXTENT_BOUNDARY (1 << 11)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 
 /*

commit 4bef084857ab8fe71cf49eae349c25e440a49150
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 8 11:18:08 2008 -0400

    Btrfs: Tree logging fixes
    
    * Pin down data blocks to prevent them from being reallocated like so:
    
    trans 1: allocate file extent
    trans 2: free file extent
    trans 3: free file extent during old snapshot deletion
    trans 3: allocate file extent to new file
    trans 3: fsync new file
    
    Before the tree logging code, this was legal because the fsync
    would commit the transation that did the final data extent free
    and the transaction that allocated the extent to the new file
    at the same time.
    
    With the tree logging code, the tree log subtransaction can commit
    before the transaction that freed the extent.  If we crash,
    we're left with two different files using the extent.
    
    * Don't wait in start_transaction if log replay is going on.  This
    avoids deadlocks from iput while we're cleaning up link counts in the
    replay code.
    
    * Don't deadlock in replay_one_name by trying to read an inode off
    the disk while holding paths for the directory
    
    * Hold the buffer lock while we mark a buffer as written.  This
    closes a race where someone is changing a buffer while we write it.
    They are supposed to mark it dirty again after they change it, but
    this violates the cow rules.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 315cfceae312..3cb411a5f4d3 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -50,6 +50,7 @@ struct extent_io_ops {
 			    unsigned long old, unsigned long bits);
 	int (*clear_bit_hook)(struct inode *inode, u64 start, u64 end,
 			    unsigned long old, unsigned long bits);
+	int (*write_cache_pages_lock_hook)(struct page *page);
 };
 
 struct extent_io_tree {

commit f421950f86bf96a11fef932e167ab2e70d4c43a0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 11:18:09 2008 -0400

    Btrfs: Fix some data=ordered related data corruptions
    
    Stress testing was showing data checksum errors, most of which were caused
    by a lookup bug in the extent_map tree.  The tree was caching the last
    pointer returned, and searches would check the last pointer first.
    
    But, search callers also expect the search to return the very first
    matching extent in the range, which wasn't always true with the last
    pointer usage.
    
    For now, the code to cache the last return value is just removed.  It is
    easy to fix, but I think lookups are rare enough that it isn't required anymore.
    
    This commit also replaces do_sync_mapping_range with a local copy of the
    related functions.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6c03e6a19938..315cfceae312 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -60,7 +60,6 @@ struct extent_io_tree {
 	spinlock_t lock;
 	spinlock_t buffer_lock;
 	struct extent_io_ops *ops;
-	struct extent_state *last;
 };
 
 struct extent_state {

commit a61e6f29dc7c9d56a776a518eed92bbc61848263
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 11:18:08 2008 -0400

    Btrfs: Use a mutex in the extent buffer for tree block locking
    
    This replaces the use of the page cache lock bit for locking, which wasn't
    suitable for block size < page size and couldn't be used recursively.
    
    The mutexes alone don't fix either problem, but they are the first step.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index dd367617d780..6c03e6a19938 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -90,6 +90,7 @@ struct extent_buffer {
 	int flags;
 	struct list_head leak_list;
 	struct rb_node rb_node;
+	struct mutex mutex;
 };
 
 struct extent_map_tree;

commit 6af118ce51b52ceda357c671550c79628b9c4a65
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 11:18:07 2008 -0400

    Btrfs: Index extent buffers in an rbtree
    
    Before, extent buffers were a temporary object, meant to map a number of pages
    at once and collect operations on them.
    
    But, a few extra fields have crept in, and they are also the best place to
    store a per-tree block lock field as well.  This commit puts the extent
    buffers into an rbtree, and ensures a single extent buffer for each
    tree block.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 23affd27af5e..dd367617d780 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -54,13 +54,12 @@ struct extent_io_ops {
 
 struct extent_io_tree {
 	struct rb_root state;
+	struct rb_root buffer;
 	struct address_space *mapping;
 	u64 dirty_bytes;
 	spinlock_t lock;
+	spinlock_t buffer_lock;
 	struct extent_io_ops *ops;
-	spinlock_t lru_lock;
-	struct list_head buffer_lru;
-	int lru_size;
 	struct extent_state *last;
 };
 
@@ -87,10 +86,10 @@ struct extent_buffer {
 	unsigned long map_start;
 	unsigned long map_len;
 	struct page *first_page;
-	struct list_head lru;
 	atomic_t refs;
 	int flags;
 	struct list_head leak_list;
+	struct rb_node rb_node;
 };
 
 struct extent_map_tree;
@@ -112,10 +111,10 @@ typedef struct extent_map *(get_extent_t)(struct inode *inode,
 
 void extent_io_tree_init(struct extent_io_tree *tree,
 			  struct address_space *mapping, gfp_t mask);
-void extent_io_tree_empty_lru(struct extent_io_tree *tree);
 int try_release_extent_mapping(struct extent_map_tree *map,
 			       struct extent_io_tree *tree, struct page *page,
 			       gfp_t mask);
+int try_release_extent_buffer(struct extent_io_tree *tree, struct page *page);
 int try_release_extent_state(struct extent_map_tree *map,
 			     struct extent_io_tree *tree, struct page *page,
 			     gfp_t mask);
@@ -241,8 +240,6 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long *map_start,
 		      unsigned long *map_len, int km);
 void unmap_extent_buffer(struct extent_buffer *eb, char *token, int km);
-int invalidate_extent_lru(struct extent_io_tree *tree, u64 start,
-			  unsigned long len);
 int release_extent_buffer_tail_pages(struct extent_buffer *eb);
 int extent_range_uptodate(struct extent_io_tree *tree,
 			  u64 start, u64 end);

commit 247e743cbe6e655768c3679f84821e03c1577902
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:53:51 2008 -0400

    Btrfs: Use async helpers to deal with pages that have been improperly dirtied
    
    Higher layers sometimes call set_page_dirty without asking the filesystem
    to help.  This causes many problems for the data=ordered and cow code.
    This commit detects pages that haven't been properly setup for IO and
    kicks off an async helper to deal with them.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 2268a7995896..23affd27af5e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -30,6 +30,7 @@ typedef	int (extent_submit_bio_hook_t)(struct inode *inode, int rw,
 				       struct bio *bio, int mirror_num);
 struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, u64 start, u64 end);
+	int (*writepage_start_hook)(struct page *page, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
 	extent_submit_bio_hook_t *submit_bio_hook;
 	int (*merge_bio_hook)(struct page *page, unsigned long offset,

commit e6dcd2dc9c489108648e2ed543315dd134d50a9a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:53:50 2008 -0400

    Btrfs: New data=ordered implementation
    
    The old data=ordered code would force commit to wait until
    all the data extents from the transaction were fully on disk.  This
    introduced large latencies into the commit and stalled new writers
    in the transaction for a long time.
    
    The new code changes the way data allocations and extents work:
    
    * When delayed allocation is filled, data extents are reserved, and
      the extent bit EXTENT_ORDERED is set on the entire range of the extent.
      A struct btrfs_ordered_extent is allocated an inserted into a per-inode
      rbtree to track the pending extents.
    
    * As each page is written EXTENT_ORDERED is cleared on the bytes corresponding
      to that page.
    
    * When all of the bytes corresponding to a single struct btrfs_ordered_extent
      are written, The previously reserved extent is inserted into the FS
      btree and into the extent allocation trees.  The checksums for the file
      data are also updated.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f1960dafaa19..2268a7995896 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -13,6 +13,8 @@
 #define EXTENT_DEFRAG (1 << 6)
 #define EXTENT_DEFRAG_DONE (1 << 7)
 #define EXTENT_BUFFER_FILLED (1 << 8)
+#define EXTENT_ORDERED (1 << 9)
+#define EXTENT_ORDERED_METADATA (1 << 10)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 
 /*
@@ -42,7 +44,7 @@ struct extent_io_ops {
 	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
 				    struct extent_state *state);
 	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
-				      struct extent_state *state);
+				      struct extent_state *state, int uptodate);
 	int (*set_bit_hook)(struct inode *inode, u64 start, u64 end,
 			    unsigned long old, unsigned long bits);
 	int (*clear_bit_hook)(struct inode *inode, u64 start, u64 end,
@@ -131,6 +133,8 @@ int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
 		   int bits, int filled);
 int clear_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		      int bits, gfp_t mask);
+int clear_extent_bit(struct extent_io_tree *tree, u64 start, u64 end,
+		     int bits, int wake, int delete, gfp_t mask);
 int set_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
 		    int bits, gfp_t mask);
 int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
@@ -141,8 +145,14 @@ int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		     gfp_t mask);
 int clear_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
 		       gfp_t mask);
+int clear_extent_ordered(struct extent_io_tree *tree, u64 start, u64 end,
+		       gfp_t mask);
+int clear_extent_ordered_metadata(struct extent_io_tree *tree, u64 start,
+				  u64 end, gfp_t mask);
 int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
 		     gfp_t mask);
+int set_extent_ordered(struct extent_io_tree *tree, u64 start, u64 end,
+		     gfp_t mask);
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
 			  u64 *start_ret, u64 *end_ret, int bits);
 struct extent_state *find_first_extent_bit_state(struct extent_io_tree *tree,
@@ -209,6 +219,8 @@ void memset_extent_buffer(struct extent_buffer *eb, char c,
 			  unsigned long start, unsigned long len);
 int wait_on_extent_buffer_writeback(struct extent_io_tree *tree,
 				    struct extent_buffer *eb);
+int wait_on_extent_writeback(struct extent_io_tree *tree, u64 start, u64 end);
+int wait_extent_bit(struct extent_io_tree *tree, u64 start, u64 end, int bits);
 int clear_extent_buffer_dirty(struct extent_io_tree *tree,
 			      struct extent_buffer *eb);
 int set_extent_buffer_dirty(struct extent_io_tree *tree,

commit 1259ab75c62462b8ffad90067b5e1f6312786a18
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 12 13:39:03 2008 -0400

    Btrfs: Handle write errors on raid1 and raid10
    
    When duplicate copies exist, writes are allowed to fail to one of those
    copies.  This changeset includes a few changes that allow the FS to
    continue even when some IOs fail.
    
    It also adds verification of the parent generation number for btree blocks.
    This generation is stored in the pointer to a block, and it ensures
    that missed writes to are detected.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index e48346147514..f1960dafaa19 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -36,9 +36,12 @@ struct extent_io_ops {
 	int (*readpage_io_failed_hook)(struct bio *bio, struct page *page,
 				       u64 start, u64 end,
 				       struct extent_state *state);
+	int (*writepage_io_failed_hook)(struct bio *bio, struct page *page,
+					u64 start, u64 end,
+				       struct extent_state *state);
 	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
 				    struct extent_state *state);
-	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
+	int (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state);
 	int (*set_bit_hook)(struct inode *inode, u64 start, u64 end,
 			    unsigned long old, unsigned long bits);
@@ -212,6 +215,8 @@ int set_extent_buffer_dirty(struct extent_io_tree *tree,
 			     struct extent_buffer *eb);
 int set_extent_buffer_uptodate(struct extent_io_tree *tree,
 			       struct extent_buffer *eb);
+int clear_extent_buffer_uptodate(struct extent_io_tree *tree,
+				struct extent_buffer *eb);
 int extent_buffer_uptodate(struct extent_io_tree *tree,
 			   struct extent_buffer *eb);
 int map_extent_buffer(struct extent_buffer *eb, unsigned long offset,

commit 7b13b7b119c932a5eca486db4113f4c1fe3b97a8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 18 10:29:50 2008 -0400

    Btrfs: Don't drop extent_map cache during releasepage on the btree inode
    
    The btree inode should only have a single extent_map in the cache,
    it doesn't make sense to ever drop it.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 232300d13be2..e48346147514 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -110,6 +110,9 @@ void extent_io_tree_empty_lru(struct extent_io_tree *tree);
 int try_release_extent_mapping(struct extent_map_tree *map,
 			       struct extent_io_tree *tree, struct page *page,
 			       gfp_t mask);
+int try_release_extent_state(struct extent_map_tree *map,
+			     struct extent_io_tree *tree, struct page *page,
+			     gfp_t mask);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
 int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,

commit 44b8bd7edda4f63de180d0f7325c9fb704b3806b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 16 11:14:51 2008 -0400

    Btrfs: Create a work queue for bio writes
    
    This allows checksumming to happen in parallel among many cpus, and
    keeps us from bogging down pdflush with the checksumming code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index b47859ccd78a..232300d13be2 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -24,11 +24,12 @@
 
 struct extent_state;
 
+typedef	int (extent_submit_bio_hook_t)(struct inode *inode, int rw,
+				       struct bio *bio, int mirror_num);
 struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
-	int (*submit_bio_hook)(struct inode *inode, int rw, struct bio *bio,
-			       int mirror_num);
+	extent_submit_bio_hook_t *submit_bio_hook;
 	int (*merge_bio_hook)(struct page *page, unsigned long offset,
 			      size_t size, struct bio *bio);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);

commit 7e38326f5b125288a2baea1d815c500502ab9fc0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 9 16:28:12 2008 -0400

    Btrfs: Handle checksumming errors while reading data blocks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 8d6b8a14cc30..b47859ccd78a 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -32,6 +32,9 @@ struct extent_io_ops {
 	int (*merge_bio_hook)(struct page *page, unsigned long offset,
 			      size_t size, struct bio *bio);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
+	int (*readpage_io_failed_hook)(struct bio *bio, struct page *page,
+				       u64 start, u64 end,
+				       struct extent_state *state);
 	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
 				    struct extent_state *state);
 	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,

commit f188591e987e21b6f7f8864c66a02858b95b530e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 9 16:28:12 2008 -0400

    Btrfs: Retry metadata reads in the face of checksum failures
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 9d2991d1d3ce..8d6b8a14cc30 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -27,7 +27,8 @@ struct extent_state;
 struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
-	int (*submit_bio_hook)(struct inode *inode, int rw, struct bio *bio);
+	int (*submit_bio_hook)(struct inode *inode, int rw, struct bio *bio,
+			       int mirror_num);
 	int (*merge_bio_hook)(struct page *page, unsigned long offset,
 			      size_t size, struct bio *bio);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
@@ -172,7 +173,7 @@ struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
 void free_extent_buffer(struct extent_buffer *eb);
 int read_extent_buffer_pages(struct extent_io_tree *tree,
 			     struct extent_buffer *eb, u64 start, int wait,
-			     get_extent_t *get_extent);
+			     get_extent_t *get_extent, int mirror_num);
 
 static inline void extent_buffer_get(struct extent_buffer *eb)
 {

commit ce9adaa5a792c2099a83246265eb4055bc38b6b8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 9 16:28:12 2008 -0400

    Btrfs: Do metadata checksums for reads via a workqueue
    
    Before, metadata checksumming was done by the callers of read_tree_block,
    which would set EXTENT_CSUM bits in the extent tree to show that a given
    range of pages was already checksummed and didn't need to be verified
    again.
    
    But, those bits could go away via try_to_releasepage, and the end
    result was bogus checksum failures on pages that never left the cache.
    
    The new code validates checksums when the page is read.  It is a little
    tricky because metadata blocks can span pages and a single read may
    end up going via multiple bios.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index d9f5bc4dbd7f..9d2991d1d3ce 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -13,7 +13,6 @@
 #define EXTENT_DEFRAG (1 << 6)
 #define EXTENT_DEFRAG_DONE (1 << 7)
 #define EXTENT_BUFFER_FILLED (1 << 8)
-#define EXTENT_CSUM (1 << 9)
 #define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
 
 /*
@@ -218,4 +217,7 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 void unmap_extent_buffer(struct extent_buffer *eb, char *token, int km);
 int invalidate_extent_lru(struct extent_io_tree *tree, u64 start,
 			  unsigned long len);
+int release_extent_buffer_tail_pages(struct extent_buffer *eb);
+int extent_range_uptodate(struct extent_io_tree *tree,
+			  u64 start, u64 end);
 #endif

commit 728131d8e40c2a47c59ca91a806299c4708029f9
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 9 16:28:12 2008 -0400

    Btrfs: Add additional debugging for metadata checksum failures
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 16d67a61a25c..d9f5bc4dbd7f 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -216,4 +216,6 @@ int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
 		      unsigned long *map_start,
 		      unsigned long *map_len, int km);
 void unmap_extent_buffer(struct extent_buffer *eb, char *token, int km);
+int invalidate_extent_lru(struct extent_io_tree *tree, u64 start,
+			  unsigned long len);
 #endif

commit 2d2ae547979854d10b75d557b3abdb3eb7511bbc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 26 16:24:23 2008 -0400

    Btrfs: Add leak debugging for extent_buffer and extent_state
    
    This also fixes one leak around the super block when failing to mount the
    FS.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 8b5319db2516..16d67a61a25c 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -66,7 +66,7 @@ struct extent_state {
 	/* for use by the FS */
 	u64 private;
 
-	struct list_head list;
+	struct list_head leak_list;
 };
 
 struct extent_buffer {
@@ -80,6 +80,7 @@ struct extent_buffer {
 	struct list_head lru;
 	atomic_t refs;
 	int flags;
+	struct list_head leak_list;
 };
 
 struct extent_map_tree;

commit 239b14b32dc39232ebf9cce29ff77c4c564355fd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:02:07 2008 -0400

    Btrfs: Bring back mount -o ssd optimizations
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 0dca89328f98..8b5319db2516 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -29,6 +29,8 @@ struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*submit_bio_hook)(struct inode *inode, int rw, struct bio *bio);
+	int (*merge_bio_hook)(struct page *page, unsigned long offset,
+			      size_t size, struct bio *bio);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
 				    struct extent_state *state);

commit 0b86a832a1f38abec695864ec2eaedc9d2383f1b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:01:56 2008 -0400

    Btrfs: Add support for multiple devices per filesystem
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 9d6654667089..0dca89328f98 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -28,7 +28,7 @@ struct extent_state;
 struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
-	int (*submit_bio_hook)(int rw, struct bio *bio);
+	int (*submit_bio_hook)(struct inode *inode, int rw, struct bio *bio);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
 				    struct extent_state *state);

commit 065631f6dccea07bfad48d8981369f6d9cfd6e2b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 20 12:07:25 2008 -0500

    Btrfs: checksum file data at bio submission time instead of during writepage
    
    When we checkum file data during writepage, the checksumming is done one
    page at a time, making it difficult to do bulk metadata modifications
    to insert checksums for large ranges of the file at once.
    
    This patch changes btrfs to checksum on a per-bio basis instead.  The
    bios are checksummed before they are handed off to the block layer, so
    each bio is contiguous and only has pages from the same inode.
    
    Checksumming on a bio basis allows us to insert and modify the file
    checksum items in large groups.  It also allows the checksumming to
    be done more easily by async worker threads.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index fcc4bb078c24..9d6654667089 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -28,6 +28,7 @@ struct extent_state;
 struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
+	int (*submit_bio_hook)(int rw, struct bio *bio);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
 				    struct extent_state *state);

commit d7fc640e6fed46932f7c74e14f9b58b8637c66cf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Feb 18 12:12:38 2008 -0500

    Btrfs: Allocator improvements
    
    Reduce CPU time searching for free blocks by optimizing find_first_extent_bit
    
    Fix find_free_extent to make better use of the last_alloc hint.  Before it
    was often finding blocks just before the hint.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 151fdada4dc4..fcc4bb078c24 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -81,6 +81,15 @@ struct extent_buffer {
 
 struct extent_map_tree;
 
+static inline struct extent_state *extent_state_next(struct extent_state *state)
+{
+	struct rb_node *node;
+	node = rb_next(&state->rb_node);
+	if (!node)
+		return NULL;
+	return rb_entry(node, struct extent_state, rb_node);
+}
+
 typedef struct extent_map *(get_extent_t)(struct inode *inode,
 					  struct page *page,
 					  size_t page_offset,
@@ -122,6 +131,8 @@ int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
 		     gfp_t mask);
 int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
 			  u64 *start_ret, u64 *end_ret, int bits);
+struct extent_state *find_first_extent_bit_state(struct extent_io_tree *tree,
+						 u64 start, int bits);
 int extent_invalidatepage(struct extent_io_tree *tree,
 			  struct page *page, unsigned long offset);
 int extent_write_full_page(struct extent_io_tree *tree, struct page *page,

commit a86c12c73d982c545a37a8ecdd66528ab260b770
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Feb 7 10:50:54 2008 -0500

    Btrfs: Create larger bios for btree blocks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 160da3f9d78e..151fdada4dc4 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -157,7 +157,8 @@ struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
 					  gfp_t mask);
 void free_extent_buffer(struct extent_buffer *eb);
 int read_extent_buffer_pages(struct extent_io_tree *tree,
-			     struct extent_buffer *eb, u64 start, int wait);
+			     struct extent_buffer *eb, u64 start, int wait,
+			     get_extent_t *get_extent);
 
 static inline void extent_buffer_get(struct extent_buffer *eb)
 {

commit 80ea96b1f3bd2431e0d71c9df6ab45c3de0c5840
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Feb 1 14:51:59 2008 -0500

    Btrfs: Add a lookup cache to the extent state tree
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 6fd5e2c90615..160da3f9d78e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -48,6 +48,7 @@ struct extent_io_tree {
 	spinlock_t lru_lock;
 	struct list_head buffer_lru;
 	int lru_size;
+	struct extent_state *last;
 };
 
 struct extent_state {

commit b0c68f8bed058d9f2023b067b16ed06a8c439544
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 31 11:05:37 2008 -0500

    Btrfs: Enable delalloc accounting
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index a96c5a14134e..6fd5e2c90615 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -34,9 +34,9 @@ struct extent_io_ops {
 	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state);
 	int (*set_bit_hook)(struct inode *inode, u64 start, u64 end,
-			    unsigned long bits);
+			    unsigned long old, unsigned long bits);
 	int (*clear_bit_hook)(struct inode *inode, u64 start, u64 end,
-			    unsigned long bits);
+			    unsigned long old, unsigned long bits);
 };
 
 struct extent_io_tree {

commit 291d673e6a22d9c6834e939f66c7cfef90669021
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 29 15:55:23 2008 -0500

    Btrfs: Do delalloc accounting via hooks in the extent_state code
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index f1e8bf251f32..a96c5a14134e 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -33,6 +33,10 @@ struct extent_io_ops {
 				    struct extent_state *state);
 	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
 				      struct extent_state *state);
+	int (*set_bit_hook)(struct inode *inode, u64 start, u64 end,
+			    unsigned long bits);
+	int (*clear_bit_hook)(struct inode *inode, u64 start, u64 end,
+			    unsigned long bits);
 };
 
 struct extent_io_tree {

commit 70dec8079d78691e476cc6c7cede40656078ad30
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 29 09:59:12 2008 -0500

    Btrfs: extent_io and extent_state optimizations
    
    The end_bio routines are changed to take a pointer to the extent state
    struct, and the state tree is walked in order to set/clear appropriate
    bits as IO completes.  This greatly reduces the number of rbtree searches
    done by the end_bio handlers, and reduces lock contention.
    
    The extent_io releasepage function is changed to avoid expensive searches
    for locked state.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
index 06be1fe84b29..f1e8bf251f32 100644
--- a/fs/btrfs/extent_io.h
+++ b/fs/btrfs/extent_io.h
@@ -23,19 +23,23 @@
 #define EXTENT_PAGE_PRIVATE 1
 #define EXTENT_PAGE_PRIVATE_FIRST_PAGE 3
 
+struct extent_state;
+
 struct extent_io_ops {
 	int (*fill_delalloc)(struct inode *inode, u64 start, u64 end);
 	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
 	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
-	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end);
-	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end);
+	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end,
+				    struct extent_state *state);
+	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end,
+				      struct extent_state *state);
 };
 
 struct extent_io_tree {
 	struct rb_root state;
 	struct address_space *mapping;
 	u64 dirty_bytes;
-	rwlock_t lock;
+	spinlock_t lock;
 	struct extent_io_ops *ops;
 	spinlock_t lru_lock;
 	struct list_head buffer_lru;
@@ -45,8 +49,8 @@ struct extent_io_tree {
 struct extent_state {
 	u64 start;
 	u64 end; /* inclusive */
-	int in_tree;
 	struct rb_node rb_node;
+	struct extent_io_tree *tree;
 	wait_queue_head_t wq;
 	atomic_t refs;
 	unsigned long state;
@@ -82,7 +86,8 @@ void extent_io_tree_init(struct extent_io_tree *tree,
 			  struct address_space *mapping, gfp_t mask);
 void extent_io_tree_empty_lru(struct extent_io_tree *tree);
 int try_release_extent_mapping(struct extent_map_tree *map,
-			       struct extent_io_tree *tree, struct page *page);
+			       struct extent_io_tree *tree, struct page *page,
+			       gfp_t mask);
 int lock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
 int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
 int extent_read_full_page(struct extent_io_tree *tree, struct page *page,

commit d1310b2e0cd98eb1348553e69b73827b436dca7b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 24 16:13:08 2008 -0500

    Btrfs: Split the extent_map code into two parts
    
    There is now extent_map for mapping offsets in the file to disk and
    extent_io for state tracking, IO submission and extent_bufers.
    
    The new extent_map code shifts from [start,end] pairs to [start,len], and
    pushes the locking out into the caller.  This allows a few performance
    optimizations and is easier to use.
    
    A number of extent_map usage bugs were fixed, mostly with failing
    to remove extent_map entries when changing the file.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h
new file mode 100644
index 000000000000..06be1fe84b29
--- /dev/null
+++ b/fs/btrfs/extent_io.h
@@ -0,0 +1,193 @@
+#ifndef __EXTENTIO__
+#define __EXTENTIO__
+
+#include <linux/rbtree.h>
+
+/* bits for the extent state */
+#define EXTENT_DIRTY 1
+#define EXTENT_WRITEBACK (1 << 1)
+#define EXTENT_UPTODATE (1 << 2)
+#define EXTENT_LOCKED (1 << 3)
+#define EXTENT_NEW (1 << 4)
+#define EXTENT_DELALLOC (1 << 5)
+#define EXTENT_DEFRAG (1 << 6)
+#define EXTENT_DEFRAG_DONE (1 << 7)
+#define EXTENT_BUFFER_FILLED (1 << 8)
+#define EXTENT_CSUM (1 << 9)
+#define EXTENT_IOBITS (EXTENT_LOCKED | EXTENT_WRITEBACK)
+
+/*
+ * page->private values.  Every page that is controlled by the extent
+ * map has page->private set to one.
+ */
+#define EXTENT_PAGE_PRIVATE 1
+#define EXTENT_PAGE_PRIVATE_FIRST_PAGE 3
+
+struct extent_io_ops {
+	int (*fill_delalloc)(struct inode *inode, u64 start, u64 end);
+	int (*writepage_io_hook)(struct page *page, u64 start, u64 end);
+	int (*readpage_io_hook)(struct page *page, u64 start, u64 end);
+	int (*readpage_end_io_hook)(struct page *page, u64 start, u64 end);
+	void (*writepage_end_io_hook)(struct page *page, u64 start, u64 end);
+};
+
+struct extent_io_tree {
+	struct rb_root state;
+	struct address_space *mapping;
+	u64 dirty_bytes;
+	rwlock_t lock;
+	struct extent_io_ops *ops;
+	spinlock_t lru_lock;
+	struct list_head buffer_lru;
+	int lru_size;
+};
+
+struct extent_state {
+	u64 start;
+	u64 end; /* inclusive */
+	int in_tree;
+	struct rb_node rb_node;
+	wait_queue_head_t wq;
+	atomic_t refs;
+	unsigned long state;
+
+	/* for use by the FS */
+	u64 private;
+
+	struct list_head list;
+};
+
+struct extent_buffer {
+	u64 start;
+	unsigned long len;
+	char *map_token;
+	char *kaddr;
+	unsigned long map_start;
+	unsigned long map_len;
+	struct page *first_page;
+	struct list_head lru;
+	atomic_t refs;
+	int flags;
+};
+
+struct extent_map_tree;
+
+typedef struct extent_map *(get_extent_t)(struct inode *inode,
+					  struct page *page,
+					  size_t page_offset,
+					  u64 start, u64 len,
+					  int create);
+
+void extent_io_tree_init(struct extent_io_tree *tree,
+			  struct address_space *mapping, gfp_t mask);
+void extent_io_tree_empty_lru(struct extent_io_tree *tree);
+int try_release_extent_mapping(struct extent_map_tree *map,
+			       struct extent_io_tree *tree, struct page *page);
+int lock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
+int unlock_extent(struct extent_io_tree *tree, u64 start, u64 end, gfp_t mask);
+int extent_read_full_page(struct extent_io_tree *tree, struct page *page,
+			  get_extent_t *get_extent);
+int __init extent_io_init(void);
+void extent_io_exit(void);
+
+u64 count_range_bits(struct extent_io_tree *tree,
+		     u64 *start, u64 search_end,
+		     u64 max_bytes, unsigned long bits);
+
+int test_range_bit(struct extent_io_tree *tree, u64 start, u64 end,
+		   int bits, int filled);
+int clear_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
+		      int bits, gfp_t mask);
+int set_extent_bits(struct extent_io_tree *tree, u64 start, u64 end,
+		    int bits, gfp_t mask);
+int set_extent_uptodate(struct extent_io_tree *tree, u64 start, u64 end,
+			gfp_t mask);
+int set_extent_new(struct extent_io_tree *tree, u64 start, u64 end,
+		   gfp_t mask);
+int set_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
+		     gfp_t mask);
+int clear_extent_dirty(struct extent_io_tree *tree, u64 start, u64 end,
+		       gfp_t mask);
+int set_extent_delalloc(struct extent_io_tree *tree, u64 start, u64 end,
+		     gfp_t mask);
+int find_first_extent_bit(struct extent_io_tree *tree, u64 start,
+			  u64 *start_ret, u64 *end_ret, int bits);
+int extent_invalidatepage(struct extent_io_tree *tree,
+			  struct page *page, unsigned long offset);
+int extent_write_full_page(struct extent_io_tree *tree, struct page *page,
+			  get_extent_t *get_extent,
+			  struct writeback_control *wbc);
+int extent_writepages(struct extent_io_tree *tree,
+		      struct address_space *mapping,
+		      get_extent_t *get_extent,
+		      struct writeback_control *wbc);
+int extent_readpages(struct extent_io_tree *tree,
+		     struct address_space *mapping,
+		     struct list_head *pages, unsigned nr_pages,
+		     get_extent_t get_extent);
+int extent_prepare_write(struct extent_io_tree *tree,
+			 struct inode *inode, struct page *page,
+			 unsigned from, unsigned to, get_extent_t *get_extent);
+int extent_commit_write(struct extent_io_tree *tree,
+			struct inode *inode, struct page *page,
+			unsigned from, unsigned to);
+sector_t extent_bmap(struct address_space *mapping, sector_t iblock,
+		get_extent_t *get_extent);
+int set_range_dirty(struct extent_io_tree *tree, u64 start, u64 end);
+int set_state_private(struct extent_io_tree *tree, u64 start, u64 private);
+int get_state_private(struct extent_io_tree *tree, u64 start, u64 *private);
+void set_page_extent_mapped(struct page *page);
+
+struct extent_buffer *alloc_extent_buffer(struct extent_io_tree *tree,
+					  u64 start, unsigned long len,
+					  struct page *page0,
+					  gfp_t mask);
+struct extent_buffer *find_extent_buffer(struct extent_io_tree *tree,
+					 u64 start, unsigned long len,
+					  gfp_t mask);
+void free_extent_buffer(struct extent_buffer *eb);
+int read_extent_buffer_pages(struct extent_io_tree *tree,
+			     struct extent_buffer *eb, u64 start, int wait);
+
+static inline void extent_buffer_get(struct extent_buffer *eb)
+{
+	atomic_inc(&eb->refs);
+}
+
+int memcmp_extent_buffer(struct extent_buffer *eb, const void *ptrv,
+			  unsigned long start,
+			  unsigned long len);
+void read_extent_buffer(struct extent_buffer *eb, void *dst,
+			unsigned long start,
+			unsigned long len);
+void write_extent_buffer(struct extent_buffer *eb, const void *src,
+			 unsigned long start, unsigned long len);
+void copy_extent_buffer(struct extent_buffer *dst, struct extent_buffer *src,
+			unsigned long dst_offset, unsigned long src_offset,
+			unsigned long len);
+void memcpy_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
+			   unsigned long src_offset, unsigned long len);
+void memmove_extent_buffer(struct extent_buffer *dst, unsigned long dst_offset,
+			   unsigned long src_offset, unsigned long len);
+void memset_extent_buffer(struct extent_buffer *eb, char c,
+			  unsigned long start, unsigned long len);
+int wait_on_extent_buffer_writeback(struct extent_io_tree *tree,
+				    struct extent_buffer *eb);
+int clear_extent_buffer_dirty(struct extent_io_tree *tree,
+			      struct extent_buffer *eb);
+int set_extent_buffer_dirty(struct extent_io_tree *tree,
+			     struct extent_buffer *eb);
+int set_extent_buffer_uptodate(struct extent_io_tree *tree,
+			       struct extent_buffer *eb);
+int extent_buffer_uptodate(struct extent_io_tree *tree,
+			   struct extent_buffer *eb);
+int map_extent_buffer(struct extent_buffer *eb, unsigned long offset,
+		      unsigned long min_len, char **token, char **map,
+		      unsigned long *map_start,
+		      unsigned long *map_len, int km);
+int map_private_extent_buffer(struct extent_buffer *eb, unsigned long offset,
+		      unsigned long min_len, char **token, char **map,
+		      unsigned long *map_start,
+		      unsigned long *map_len, int km);
+void unmap_extent_buffer(struct extent_buffer *eb, char *token, int km);
+#endif
