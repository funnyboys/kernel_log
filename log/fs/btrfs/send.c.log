commit f3cdc8ae116e27d84e1f33c7a2995960cebb73ac
Merge: 8eeae5bae123 2166e5edce9a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 2 19:59:25 2020 -0700

    Merge tag 'for-5.8-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "Highlights:
    
       - speedup dead root detection during orphan cleanup, eg. when there
         are many deleted subvolumes waiting to be cleaned, the trees are
         now looked up in radix tree instead of a O(N^2) search
    
       - snapshot creation with inherited qgroup will mark the qgroup
         inconsistent, requires a rescan
    
       - send will emit file capabilities after chown, this produces a
         stream that does not need postprocessing to set the capabilities
         again
    
       - direct io ported to iomap infrastructure, cleaned up and simplified
         code, notably removing last use of struct buffer_head in btrfs code
    
      Core changes:
    
       - factor out backreference iteration, to be used by ordinary
         backreferences and relocation code
    
       - improved global block reserve utilization
          * better logic to serialize requests
          * increased maximum available for unlink
          * improved handling on large pages (64K)
    
       - direct io cleanups and fixes
          * simplify layering, where cloned bios were unnecessarily created
            for some cases
          * error handling fixes (submit, endio)
          * remove repair worker thread, used to avoid deadlocks during
            repair
    
       - refactored block group reading code, preparatory work for new type
         of block group storage that should improve mount time on large
         filesystems
    
      Cleanups:
    
       - cleaned up (and slightly sped up) set/get helpers for metadata data
         structure members
    
       - root bit REF_COWS got renamed to SHAREABLE to reflect the that the
         blocks of the tree get shared either among subvolumes or with the
         relocation trees
    
      Fixes:
    
       - when subvolume deletion fails due to ENOSPC, the filesystem is not
         turned read-only
    
       - device scan deals with devices from other filesystems that changed
         ownership due to overwrite (mkfs)
    
       - fix a race between scrub and block group removal/allocation
    
       - fix long standing bug of a runaway balance operation, printing the
         same line to the syslog, caused by a stale status bit on a reloc
         tree that prevented progress
    
       - fix corrupt log due to concurrent fsync of inodes with shared
         extents
    
       - fix space underflow for NODATACOW and buffered writes when it for
         some reason needs to fallback to COW mode"
    
    * tag 'for-5.8-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (133 commits)
      btrfs: fix space_info bytes_may_use underflow during space cache writeout
      btrfs: fix space_info bytes_may_use underflow after nocow buffered write
      btrfs: fix wrong file range cleanup after an error filling dealloc range
      btrfs: remove redundant local variable in read_block_for_search
      btrfs: open code key_search
      btrfs: split btrfs_direct_IO to read and write part
      btrfs: remove BTRFS_INODE_READDIO_NEED_LOCK
      fs: remove dio_end_io()
      btrfs: switch to iomap_dio_rw() for dio
      iomap: remove lockdep_assert_held()
      iomap: add a filesystem hook for direct I/O bio submission
      fs: export generic_file_buffered_read()
      btrfs: turn space cache writeout failure messages into debug messages
      btrfs: include error on messages about failure to write space/inode caches
      btrfs: remove useless 'fail_unlock' label from btrfs_csum_file_blocks()
      btrfs: do not ignore error from btrfs_next_leaf() when inserting checksums
      btrfs: make checksum item extension more efficient
      btrfs: fix corrupt log due to concurrent fsync of inodes with shared extents
      btrfs: unexport btrfs_compress_set_level()
      btrfs: simplify iget helpers
      ...

commit 0202e83fdab05b3bf641804afea57a2bfcbcbd70
Author: David Sterba <dsterba@suse.com>
Date:   Fri May 15 19:35:59 2020 +0200

    btrfs: simplify iget helpers
    
    The inode lookup starting at btrfs_iget takes the full location key,
    while only the objectid is used to match the inode, because the lookup
    happens inside the given root thus the inode number is unique.
    The entire location key is properly set up in btrfs_init_locked_inode.
    
    Simplify the helpers and pass only inode number, renaming it to 'ino'
    instead of 'objectid'. This allows to remove temporary variables key,
    saving some stack space.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 3ddd3b9778c7..0f37660b14b2 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4806,17 +4806,12 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 	struct inode *inode;
 	struct page *page;
 	char *addr;
-	struct btrfs_key key;
 	pgoff_t index = offset >> PAGE_SHIFT;
 	pgoff_t last_index;
 	unsigned pg_offset = offset_in_page(offset);
 	ssize_t ret = 0;
 
-	key.objectid = sctx->cur_ino;
-	key.type = BTRFS_INODE_ITEM_KEY;
-	key.offset = 0;
-
-	inode = btrfs_iget(fs_info->sb, &key, root);
+	inode = btrfs_iget(fs_info->sb, sctx->cur_ino, root);
 	if (IS_ERR(inode))
 		return PTR_ERR(inode);
 

commit 56e9357a1e8167134388d4c70654795353765c7b
Author: David Sterba <dsterba@suse.com>
Date:   Fri May 15 19:35:55 2020 +0200

    btrfs: simplify root lookup by id
    
    The main function to lookup a root by its id btrfs_get_fs_root takes the
    whole key, while only using the objectid. The value of offset is preset
    to (u64)-1 but not actually used until btrfs_find_root that does the
    actual search.
    
    Switch btrfs_get_fs_root to use only objectid and remove all local
    variables that existed just for the lookup. The actual key for search is
    set up in btrfs_get_fs_root, reusing another key variable.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 4f3b8d2bb56b..3ddd3b9778c7 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -7088,7 +7088,6 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 	struct btrfs_root *send_root = BTRFS_I(file_inode(mnt_file))->root;
 	struct btrfs_fs_info *fs_info = send_root->fs_info;
 	struct btrfs_root *clone_root;
-	struct btrfs_key key;
 	struct send_ctx *sctx = NULL;
 	u32 i;
 	u64 *clone_sources_tmp = NULL;
@@ -7217,11 +7216,8 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 		}
 
 		for (i = 0; i < arg->clone_sources_count; i++) {
-			key.objectid = clone_sources_tmp[i];
-			key.type = BTRFS_ROOT_ITEM_KEY;
-			key.offset = (u64)-1;
-
-			clone_root = btrfs_get_fs_root(fs_info, &key, true);
+			clone_root = btrfs_get_fs_root(fs_info,
+						clone_sources_tmp[i], true);
 			if (IS_ERR(clone_root)) {
 				ret = PTR_ERR(clone_root);
 				goto out;
@@ -7252,11 +7248,8 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 	}
 
 	if (arg->parent_root) {
-		key.objectid = arg->parent_root;
-		key.type = BTRFS_ROOT_ITEM_KEY;
-		key.offset = (u64)-1;
-
-		sctx->parent_root = btrfs_get_fs_root(fs_info, &key, true);
+		sctx->parent_root = btrfs_get_fs_root(fs_info, arg->parent_root,
+						      true);
 		if (IS_ERR(sctx->parent_root)) {
 			ret = PTR_ERR(sctx->parent_root);
 			goto out;

commit 89efda52e6b6930f80f5adda9c3c9edfb1397191
Author: Marcos Paulo de Souza <mpdesouza@suse.com>
Date:   Sun May 10 23:15:07 2020 -0300

    btrfs: send: emit file capabilities after chown
    
    Whenever a chown is executed, all capabilities of the file being touched
    are lost.  When doing incremental send with a file with capabilities,
    there is a situation where the capability can be lost on the receiving
    side. The sequence of actions bellow shows the problem:
    
      $ mount /dev/sda fs1
      $ mount /dev/sdb fs2
    
      $ touch fs1/foo.bar
      $ setcap cap_sys_nice+ep fs1/foo.bar
      $ btrfs subvolume snapshot -r fs1 fs1/snap_init
      $ btrfs send fs1/snap_init | btrfs receive fs2
    
      $ chgrp adm fs1/foo.bar
      $ setcap cap_sys_nice+ep fs1/foo.bar
    
      $ btrfs subvolume snapshot -r fs1 fs1/snap_complete
      $ btrfs subvolume snapshot -r fs1 fs1/snap_incremental
    
      $ btrfs send fs1/snap_complete | btrfs receive fs2
      $ btrfs send -p fs1/snap_init fs1/snap_incremental | btrfs receive fs2
    
    At this point, only a chown was emitted by "btrfs send" since only the
    group was changed. This makes the cap_sys_nice capability to be dropped
    from fs2/snap_incremental/foo.bar
    
    To fix that, only emit capabilities after chown is emitted. The current
    code first checks for xattrs that are new/changed, emits them, and later
    emit the chown. Now, __process_new_xattr skips capabilities, letting
    only finish_inode_if_needed to emit them, if they exist, for the inode
    being processed.
    
    This behavior was being worked around in "btrfs receive" side by caching
    the capability and only applying it after chown. Now, xattrs are only
    emmited _after_ chown, making that workaround not needed anymore.
    
    Link: https://github.com/kdave/btrfs-progs/issues/202
    CC: stable@vger.kernel.org # 4.4+
    Suggested-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Marcos Paulo de Souza <mpdesouza@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c5f41bd86765..4f3b8d2bb56b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -23,6 +23,7 @@
 #include "btrfs_inode.h"
 #include "transaction.h"
 #include "compression.h"
+#include "xattr.h"
 
 /*
  * Maximum number of references an extent can have in order for us to attempt to
@@ -4545,6 +4546,10 @@ static int __process_new_xattr(int num, struct btrfs_key *di_key,
 	struct fs_path *p;
 	struct posix_acl_xattr_header dummy_acl;
 
+	/* Capabilities are emitted by finish_inode_if_needed */
+	if (!strncmp(name, XATTR_NAME_CAPS, name_len))
+		return 0;
+
 	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
@@ -5107,6 +5112,64 @@ static int send_extent_data(struct send_ctx *sctx,
 	return 0;
 }
 
+/*
+ * Search for a capability xattr related to sctx->cur_ino. If the capability is
+ * found, call send_set_xattr function to emit it.
+ *
+ * Return 0 if there isn't a capability, or when the capability was emitted
+ * successfully, or < 0 if an error occurred.
+ */
+static int send_capabilities(struct send_ctx *sctx)
+{
+	struct fs_path *fspath = NULL;
+	struct btrfs_path *path;
+	struct btrfs_dir_item *di;
+	struct extent_buffer *leaf;
+	unsigned long data_ptr;
+	char *buf = NULL;
+	int buf_len;
+	int ret = 0;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	di = btrfs_lookup_xattr(NULL, sctx->send_root, path, sctx->cur_ino,
+				XATTR_NAME_CAPS, strlen(XATTR_NAME_CAPS), 0);
+	if (!di) {
+		/* There is no xattr for this inode */
+		goto out;
+	} else if (IS_ERR(di)) {
+		ret = PTR_ERR(di);
+		goto out;
+	}
+
+	leaf = path->nodes[0];
+	buf_len = btrfs_dir_data_len(leaf, di);
+
+	fspath = fs_path_alloc();
+	buf = kmalloc(buf_len, GFP_KERNEL);
+	if (!fspath || !buf) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, fspath);
+	if (ret < 0)
+		goto out;
+
+	data_ptr = (unsigned long)(di + 1) + btrfs_dir_name_len(leaf, di);
+	read_extent_buffer(leaf, buf, data_ptr, buf_len);
+
+	ret = send_set_xattr(sctx, fspath, XATTR_NAME_CAPS,
+			strlen(XATTR_NAME_CAPS), buf, buf_len);
+out:
+	kfree(buf);
+	fs_path_free(fspath);
+	btrfs_free_path(path);
+	return ret;
+}
+
 static int clone_range(struct send_ctx *sctx,
 		       struct clone_root *clone_root,
 		       const u64 disk_byte,
@@ -5972,6 +6035,10 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 			goto out;
 	}
 
+	ret = send_capabilities(sctx);
+	if (ret < 0)
+		goto out;
+
 	/*
 	 * If other directory inodes depended on our current directory
 	 * inode's move/rename, now do their move/rename operations.

commit 502fd722fe1ed0133d1108bff1d5911f46de6641
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Feb 19 09:35:32 2020 -0500

    btrfs_ioctl_send(): don't bother with access_ok()
    
    we do copy_from_user() on that range anyway
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c5f41bd86765..6a92ecf9eaa2 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -7065,13 +7065,6 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 		goto out;
 	}
 
-	if (!access_ok(arg->clone_sources,
-			sizeof(*arg->clone_sources) *
-			arg->clone_sources_count)) {
-		ret = -EFAULT;
-		goto out;
-	}
-
 	if (arg->flags & ~BTRFS_SEND_FLAG_MASK) {
 		ret = -EINVAL;
 		goto out;

commit c75e839414d3610e6487ae3145199c500d55f7f7
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:47 2020 -0500

    btrfs: kill the subvol_srcu
    
    Now that we have proper root ref counting everywhere we can kill the
    subvol_srcu.
    
    * removal of fs_info::subvol_srcu reduces size of fs_info by 1176 bytes
    
    * the refcount_t used for the references checks for accidental 0->1
      in cases where the root lifetime would not be properly protected
    
    * there's a leak detector for roots to catch unfreed roots at umount
      time
    
    * SRCU served us well over the years but is was not a proper
      synchronization mechanism for some cases
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e47f768cec3d..c5f41bd86765 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -7028,7 +7028,6 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 	int clone_sources_to_rollback = 0;
 	unsigned alloc_size;
 	int sort_clone_roots = 0;
-	int index;
 
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
@@ -7155,11 +7154,8 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 			key.type = BTRFS_ROOT_ITEM_KEY;
 			key.offset = (u64)-1;
 
-			index = srcu_read_lock(&fs_info->subvol_srcu);
-
 			clone_root = btrfs_get_fs_root(fs_info, &key, true);
 			if (IS_ERR(clone_root)) {
-				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = PTR_ERR(clone_root);
 				goto out;
 			}
@@ -7168,7 +7164,6 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 			    btrfs_root_dead(clone_root)) {
 				spin_unlock(&clone_root->root_item_lock);
 				btrfs_put_root(clone_root);
-				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = -EPERM;
 				goto out;
 			}
@@ -7176,13 +7171,11 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 				dedupe_in_progress_warn(clone_root);
 				spin_unlock(&clone_root->root_item_lock);
 				btrfs_put_root(clone_root);
-				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = -EAGAIN;
 				goto out;
 			}
 			clone_root->send_in_progress++;
 			spin_unlock(&clone_root->root_item_lock);
-			srcu_read_unlock(&fs_info->subvol_srcu, index);
 
 			sctx->clone_roots[i].root = clone_root;
 			clone_sources_to_rollback = i + 1;
@@ -7196,11 +7189,8 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 		key.type = BTRFS_ROOT_ITEM_KEY;
 		key.offset = (u64)-1;
 
-		index = srcu_read_lock(&fs_info->subvol_srcu);
-
 		sctx->parent_root = btrfs_get_fs_root(fs_info, &key, true);
 		if (IS_ERR(sctx->parent_root)) {
-			srcu_read_unlock(&fs_info->subvol_srcu, index);
 			ret = PTR_ERR(sctx->parent_root);
 			goto out;
 		}
@@ -7210,20 +7200,16 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 		if (!btrfs_root_readonly(sctx->parent_root) ||
 				btrfs_root_dead(sctx->parent_root)) {
 			spin_unlock(&sctx->parent_root->root_item_lock);
-			srcu_read_unlock(&fs_info->subvol_srcu, index);
 			ret = -EPERM;
 			goto out;
 		}
 		if (sctx->parent_root->dedupe_in_progress) {
 			dedupe_in_progress_warn(sctx->parent_root);
 			spin_unlock(&sctx->parent_root->root_item_lock);
-			srcu_read_unlock(&fs_info->subvol_srcu, index);
 			ret = -EAGAIN;
 			goto out;
 		}
 		spin_unlock(&sctx->parent_root->root_item_lock);
-
-		srcu_read_unlock(&fs_info->subvol_srcu, index);
 	}
 
 	/*

commit a5eeb3d17b979f7afe3ac68fe049ce8b0a039b03
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Mar 9 12:41:06 2020 +0000

    btrfs: add helper to get the end offset of a file extent item
    
    Getting the end offset for a file extent item requires a bit of code since
    the extent can be either inline or regular/prealloc. There are some places
    all over the code base that open code this logic and in another patch
    later in this series it will be needed again. Therefore encapsulate this
    logic in a helper function and use it.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 6b86841315be..e47f768cec3d 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5586,10 +5586,7 @@ static int get_last_extent(struct send_ctx *sctx, u64 offset)
 {
 	struct btrfs_path *path;
 	struct btrfs_root *root = sctx->send_root;
-	struct btrfs_file_extent_item *fi;
 	struct btrfs_key key;
-	u64 extent_end;
-	u8 type;
 	int ret;
 
 	path = alloc_path_for_send();
@@ -5609,18 +5606,7 @@ static int get_last_extent(struct send_ctx *sctx, u64 offset)
 	if (key.objectid != sctx->cur_ino || key.type != BTRFS_EXTENT_DATA_KEY)
 		goto out;
 
-	fi = btrfs_item_ptr(path->nodes[0], path->slots[0],
-			    struct btrfs_file_extent_item);
-	type = btrfs_file_extent_type(path->nodes[0], fi);
-	if (type == BTRFS_FILE_EXTENT_INLINE) {
-		u64 size = btrfs_file_extent_ram_bytes(path->nodes[0], fi);
-		extent_end = ALIGN(key.offset + size,
-				   sctx->send_root->fs_info->sectorsize);
-	} else {
-		extent_end = key.offset +
-			btrfs_file_extent_num_bytes(path->nodes[0], fi);
-	}
-	sctx->cur_inode_last_extent = extent_end;
+	sctx->cur_inode_last_extent = btrfs_file_extent_end(path);
 out:
 	btrfs_free_path(path);
 	return ret;
@@ -5674,16 +5660,7 @@ static int range_is_hole_in_parent(struct send_ctx *sctx,
 			break;
 
 		fi = btrfs_item_ptr(leaf, slot, struct btrfs_file_extent_item);
-		if (btrfs_file_extent_type(leaf, fi) ==
-		    BTRFS_FILE_EXTENT_INLINE) {
-			u64 size = btrfs_file_extent_ram_bytes(leaf, fi);
-
-			extent_end = ALIGN(key.offset + size,
-					   root->fs_info->sectorsize);
-		} else {
-			extent_end = key.offset +
-				btrfs_file_extent_num_bytes(leaf, fi);
-		}
+		extent_end = btrfs_file_extent_end(path);
 		if (extent_end <= start)
 			goto next;
 		if (btrfs_file_extent_disk_bytenr(leaf, fi) == 0) {
@@ -5704,9 +5681,6 @@ static int range_is_hole_in_parent(struct send_ctx *sctx,
 static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
 			   struct btrfs_key *key)
 {
-	struct btrfs_file_extent_item *fi;
-	u64 extent_end;
-	u8 type;
 	int ret = 0;
 
 	if (sctx->cur_ino != key->objectid || !need_send_hole(sctx))
@@ -5718,18 +5692,6 @@ static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
 			return ret;
 	}
 
-	fi = btrfs_item_ptr(path->nodes[0], path->slots[0],
-			    struct btrfs_file_extent_item);
-	type = btrfs_file_extent_type(path->nodes[0], fi);
-	if (type == BTRFS_FILE_EXTENT_INLINE) {
-		u64 size = btrfs_file_extent_ram_bytes(path->nodes[0], fi);
-		extent_end = ALIGN(key->offset + size,
-				   sctx->send_root->fs_info->sectorsize);
-	} else {
-		extent_end = key->offset +
-			btrfs_file_extent_num_bytes(path->nodes[0], fi);
-	}
-
 	if (path->slots[0] == 0 &&
 	    sctx->cur_inode_last_extent < key->offset) {
 		/*
@@ -5755,7 +5717,7 @@ static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
 		else
 			ret = 0;
 	}
-	sctx->cur_inode_last_extent = extent_end;
+	sctx->cur_inode_last_extent = btrfs_file_extent_end(path);
 	return ret;
 }
 

commit 0024652895e3479cd0d372f63b57d9581a0bdd38
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:33:01 2020 -0500

    btrfs: rename btrfs_put_fs_root and btrfs_grab_fs_root
    
    We are now using these for all roots, rename them to btrfs_put_root()
    and btrfs_grab_root();
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 3e243ad4a95f..6b86841315be 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -7205,7 +7205,7 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 			if (!btrfs_root_readonly(clone_root) ||
 			    btrfs_root_dead(clone_root)) {
 				spin_unlock(&clone_root->root_item_lock);
-				btrfs_put_fs_root(clone_root);
+				btrfs_put_root(clone_root);
 				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = -EPERM;
 				goto out;
@@ -7213,7 +7213,7 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 			if (clone_root->dedupe_in_progress) {
 				dedupe_in_progress_warn(clone_root);
 				spin_unlock(&clone_root->root_item_lock);
-				btrfs_put_fs_root(clone_root);
+				btrfs_put_root(clone_root);
 				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = -EAGAIN;
 				goto out;
@@ -7270,7 +7270,7 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 	 * for possible clone sources.
 	 */
 	sctx->clone_roots[sctx->clone_roots_cnt++].root =
-		btrfs_grab_fs_root(sctx->send_root);
+		btrfs_grab_root(sctx->send_root);
 
 	/* We do a bsearch later */
 	sort(sctx->clone_roots, sctx->clone_roots_cnt,
@@ -7358,20 +7358,20 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 		for (i = 0; i < sctx->clone_roots_cnt; i++) {
 			btrfs_root_dec_send_in_progress(
 					sctx->clone_roots[i].root);
-			btrfs_put_fs_root(sctx->clone_roots[i].root);
+			btrfs_put_root(sctx->clone_roots[i].root);
 		}
 	} else {
 		for (i = 0; sctx && i < clone_sources_to_rollback; i++) {
 			btrfs_root_dec_send_in_progress(
 					sctx->clone_roots[i].root);
-			btrfs_put_fs_root(sctx->clone_roots[i].root);
+			btrfs_put_root(sctx->clone_roots[i].root);
 		}
 
 		btrfs_root_dec_send_in_progress(send_root);
 	}
 	if (sctx && !IS_ERR_OR_NULL(sctx->parent_root)) {
 		btrfs_root_dec_send_in_progress(sctx->parent_root);
-		btrfs_put_fs_root(sctx->parent_root);
+		btrfs_put_root(sctx->parent_root);
 	}
 
 	kvfree(clone_sources_tmp);

commit bc44d7c4b2b179c4b74fba208b9908e2ecbc1b4d
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:56 2020 -0500

    btrfs: push btrfs_grab_fs_root into btrfs_get_fs_root
    
    Now that all callers of btrfs_get_fs_root are subsequently calling
    btrfs_grab_fs_root and handling dropping the ref when they are done
    appropriately, go ahead and push btrfs_grab_fs_root up into
    btrfs_get_fs_root.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 31495cdf1877..3e243ad4a95f 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -7201,11 +7201,6 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 				ret = PTR_ERR(clone_root);
 				goto out;
 			}
-			if (!btrfs_grab_fs_root(clone_root)) {
-				srcu_read_unlock(&fs_info->subvol_srcu, index);
-				ret = -ENOENT;
-				goto out;
-			}
 			spin_lock(&clone_root->root_item_lock);
 			if (!btrfs_root_readonly(clone_root) ||
 			    btrfs_root_dead(clone_root)) {
@@ -7247,12 +7242,6 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 			ret = PTR_ERR(sctx->parent_root);
 			goto out;
 		}
-		if (!btrfs_grab_fs_root(sctx->parent_root)) {
-			srcu_read_unlock(&fs_info->subvol_srcu, index);
-			ret = -ENOENT;
-			sctx->parent_root = ERR_PTR(ret);
-			goto out;
-		}
 
 		spin_lock(&sctx->parent_root->root_item_lock);
 		sctx->parent_root->send_in_progress++;

commit 6f9a3da5da9e7e59f3a5a5909aab5f680fe919c9
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:48 2020 -0500

    btrfs: hold a ref on the root in btrfs_ioctl_send
    
    We lookup all the clone roots and the parent root for send, so we need
    to hold refs on all of these roots while we're processing them.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 27e580564e49..31495cdf1877 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -7201,10 +7201,16 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 				ret = PTR_ERR(clone_root);
 				goto out;
 			}
+			if (!btrfs_grab_fs_root(clone_root)) {
+				srcu_read_unlock(&fs_info->subvol_srcu, index);
+				ret = -ENOENT;
+				goto out;
+			}
 			spin_lock(&clone_root->root_item_lock);
 			if (!btrfs_root_readonly(clone_root) ||
 			    btrfs_root_dead(clone_root)) {
 				spin_unlock(&clone_root->root_item_lock);
+				btrfs_put_fs_root(clone_root);
 				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = -EPERM;
 				goto out;
@@ -7212,6 +7218,7 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 			if (clone_root->dedupe_in_progress) {
 				dedupe_in_progress_warn(clone_root);
 				spin_unlock(&clone_root->root_item_lock);
+				btrfs_put_fs_root(clone_root);
 				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = -EAGAIN;
 				goto out;
@@ -7240,6 +7247,12 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 			ret = PTR_ERR(sctx->parent_root);
 			goto out;
 		}
+		if (!btrfs_grab_fs_root(sctx->parent_root)) {
+			srcu_read_unlock(&fs_info->subvol_srcu, index);
+			ret = -ENOENT;
+			sctx->parent_root = ERR_PTR(ret);
+			goto out;
+		}
 
 		spin_lock(&sctx->parent_root->root_item_lock);
 		sctx->parent_root->send_in_progress++;
@@ -7267,7 +7280,8 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 	 * is behind the current send position. This is checked while searching
 	 * for possible clone sources.
 	 */
-	sctx->clone_roots[sctx->clone_roots_cnt++].root = sctx->send_root;
+	sctx->clone_roots[sctx->clone_roots_cnt++].root =
+		btrfs_grab_fs_root(sctx->send_root);
 
 	/* We do a bsearch later */
 	sort(sctx->clone_roots, sctx->clone_roots_cnt,
@@ -7352,18 +7366,24 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 	}
 
 	if (sort_clone_roots) {
-		for (i = 0; i < sctx->clone_roots_cnt; i++)
+		for (i = 0; i < sctx->clone_roots_cnt; i++) {
 			btrfs_root_dec_send_in_progress(
 					sctx->clone_roots[i].root);
+			btrfs_put_fs_root(sctx->clone_roots[i].root);
+		}
 	} else {
-		for (i = 0; sctx && i < clone_sources_to_rollback; i++)
+		for (i = 0; sctx && i < clone_sources_to_rollback; i++) {
 			btrfs_root_dec_send_in_progress(
 					sctx->clone_roots[i].root);
+			btrfs_put_fs_root(sctx->clone_roots[i].root);
+		}
 
 		btrfs_root_dec_send_in_progress(send_root);
 	}
-	if (sctx && !IS_ERR_OR_NULL(sctx->parent_root))
+	if (sctx && !IS_ERR_OR_NULL(sctx->parent_root)) {
 		btrfs_root_dec_send_in_progress(sctx->parent_root);
+		btrfs_put_fs_root(sctx->parent_root);
+	}
 
 	kvfree(clone_sources_tmp);
 

commit 3619c94f073e4e96bef4cc15e70adbc36f3cb203
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:24 2020 -0500

    btrfs: open code btrfs_read_fs_root_no_name
    
    All this does is call btrfs_get_fs_root() with check_ref == true.  Just
    use btrfs_get_fs_root() so we don't have a bunch of different helpers
    that do the same thing.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a055b657cb85..27e580564e49 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -7195,7 +7195,7 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 
 			index = srcu_read_lock(&fs_info->subvol_srcu);
 
-			clone_root = btrfs_read_fs_root_no_name(fs_info, &key);
+			clone_root = btrfs_get_fs_root(fs_info, &key, true);
 			if (IS_ERR(clone_root)) {
 				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = PTR_ERR(clone_root);
@@ -7234,7 +7234,7 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 
 		index = srcu_read_lock(&fs_info->subvol_srcu);
 
-		sctx->parent_root = btrfs_read_fs_root_no_name(fs_info, &key);
+		sctx->parent_root = btrfs_get_fs_root(fs_info, &key, true);
 		if (IS_ERR(sctx->parent_root)) {
 			srcu_read_unlock(&fs_info->subvol_srcu, index);
 			ret = PTR_ERR(sctx->parent_root);

commit 9722b10148504c4153a74a9c89725af271e490fc
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Jan 29 17:09:53 2020 +0000

    Btrfs: send, fix emission of invalid clone operations within the same file
    
    When doing an incremental send and a file has extents shared with itself
    at different file offsets, it's possible for send to emit clone operations
    that will fail at the destination because the source range goes beyond the
    file's current size. This happens when the file size has increased in the
    send snapshot, there is a hole between the shared extents and both shared
    extents are at file offsets which are greater the file's size in the
    parent snapshot.
    
    Example:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt/sdb
    
      $ xfs_io -f -c "pwrite -S 0xf1 0 64K" /mnt/sdb/foobar
      $ btrfs subvolume snapshot -r /mnt/sdb /mnt/sdb/base
      $ btrfs send -f /tmp/1.snap /mnt/sdb/base
    
      # Create a 320K extent at file offset 512K.
      $ xfs_io -c "pwrite -S 0xab 512K 64K" /mnt/sdb/foobar
      $ xfs_io -c "pwrite -S 0xcd 576K 64K" /mnt/sdb/foobar
      $ xfs_io -c "pwrite -S 0xef 640K 64K" /mnt/sdb/foobar
      $ xfs_io -c "pwrite -S 0x64 704K 64K" /mnt/sdb/foobar
      $ xfs_io -c "pwrite -S 0x73 768K 64K" /mnt/sdb/foobar
    
      # Clone part of that 320K extent into a lower file offset (192K).
      # This file offset is greater than the file's size in the parent
      # snapshot (64K). Also the clone range is a bit behind the offset of
      # the 320K extent so that we leave a hole between the shared extents.
      $ xfs_io -c "reflink /mnt/sdb/foobar 448K 192K 192K" /mnt/sdb/foobar
    
      $ btrfs subvolume snapshot -r /mnt/sdb /mnt/sdb/incr
      $ btrfs send -p /mnt/sdb/base -f /tmp/2.snap /mnt/sdb/incr
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt/sdc
    
      $ btrfs receive -f /tmp/1.snap /mnt/sdc
      $ btrfs receive -f /tmp/2.snap /mnt/sdc
      ERROR: failed to clone extents to foobar: Invalid argument
    
    The problem is that after processing the extent at file offset 256K, which
    refers to the first 128K of the 320K extent created by the buffered write
    operations, we have 'cur_inode_next_write_offset' set to 384K, which
    corresponds to the end offset of the partially shared extent (256K + 128K)
    and to the current file size in the receiver. Then when we process the
    extent at offset 512K, we do extent backreference iteration to figure out
    if we can clone the extent from some other inode or from the same inode,
    and we consider the extent at offset 256K of the same inode as a valid
    source for a clone operation, which is not correct because at that point
    the current file size in the receiver is 384K, which corresponds to the
    end of last processed extent (at file offset 256K), so using a clone
    source range from 256K to 256K + 320K is invalid because that goes past
    the current size of the file (384K) - this makes the receiver get an
    -EINVAL error when attempting the clone operation.
    
    So fix this by excluding clone sources that have a range that goes beyond
    the current file size in the receiver when iterating extent backreferences.
    
    A test case for fstests follows soon.
    
    Fixes: 11f2069c113e02 ("Btrfs: send, allow clone operations within the same file")
    CC: stable@vger.kernel.org # 5.5+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 091e5bc8c7ea..a055b657cb85 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1269,7 +1269,8 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 		 * destination of the stream.
 		 */
 		if (ino == bctx->cur_objectid &&
-		    offset >= bctx->sctx->cur_inode_next_write_offset)
+		    offset + bctx->extent_len >
+		    bctx->sctx->cur_inode_next_write_offset)
 			return 0;
 	}
 

commit fbd542971aa1e9ec33212afe1d9b4f1106cd85a1
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Dec 5 19:39:07 2019 +0800

    btrfs: send: remove WARN_ON for readonly mount
    
    We log warning if root::orphan_cleanup_state is not set to
    ORPHAN_CLEANUP_DONE in btrfs_ioctl_send(). However if the filesystem is
    mounted as readonly we skip the orphan item cleanup during the lookup
    and root::orphan_cleanup_state remains at the init state 0 instead of
    ORPHAN_CLEANUP_DONE (2). So during send in btrfs_ioctl_send() we hit the
    warning as below.
    
      WARN_ON(send_root->orphan_cleanup_state != ORPHAN_CLEANUP_DONE);
    
    WARNING: CPU: 0 PID: 2616 at /Volumes/ws/btrfs-devel/fs/btrfs/send.c:7090 btrfs_ioctl_send+0xb2f/0x18c0 [btrfs]
    ::
    RIP: 0010:btrfs_ioctl_send+0xb2f/0x18c0 [btrfs]
    ::
    Call Trace:
    ::
    _btrfs_ioctl_send+0x7b/0x110 [btrfs]
    btrfs_ioctl+0x150a/0x2b00 [btrfs]
    ::
    do_vfs_ioctl+0xa9/0x620
    ? __fget+0xac/0xe0
    ksys_ioctl+0x60/0x90
    __x64_sys_ioctl+0x16/0x20
    do_syscall_64+0x49/0x130
    entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Reproducer:
      mkfs.btrfs -fq /dev/sdb
      mount /dev/sdb /btrfs
      btrfs subvolume create /btrfs/sv1
      btrfs subvolume snapshot -r /btrfs/sv1 /btrfs/ss1
      umount /btrfs
      mount -o ro /dev/sdb /btrfs
      btrfs send /btrfs/ss1 -f /tmp/f
    
    The warning exists because having orphan inodes could confuse send and
    cause it to fail or produce incorrect streams.  The two cases that would
    cause such send failures, which are already fixed are:
    
    1) Inodes that were unlinked - these are orphanized and remain with a
       link count of 0. These caused send operations to fail because it
       expected to always find at least one path for an inode. However this
       is no longer a problem since send is now able to deal with such
       inodes since commit 46b2f4590aab ("Btrfs: fix send failure when root
       has deleted files still open") and treats them as having been
       completely removed (the state after an orphan cleanup is performed).
    
    2) Inodes that were in the process of being truncated. These resulted in
       send not knowing about the truncation and potentially issue write
       operations full of zeroes for the range from the new file size to the
       old file size. This is no longer a problem because we no longer
       create orphan items for truncation since commit f7e9e8fc792f ("Btrfs:
       stop creating orphan items for truncate").
    
    As such before these commits, the WARN_ON here provided a clue in case
    something went wrong. Instead of being a warning against the
    root::orphan_cleanup_state value, it could have been more accurate by
    checking if there were actually any orphan items, and then issue a
    warning only if any exists, but that would be more expensive to check.
    Since orphanized inodes no longer cause problems for send, just remove
    the warning.
    
    Reported-by: Christoph Anton Mitterer <calestyo@scientia.net>
    Link: https://lore.kernel.org/linux-btrfs/21cb5e8d059f6e1496a903fa7bfc0a297e2f5370.camel@scientia.net/
    CC: stable@vger.kernel.org # 4.19+
    Suggested-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ae2db5eb1549..091e5bc8c7ea 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -7083,12 +7083,6 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 	send_root->send_in_progress++;
 	spin_unlock(&send_root->root_item_lock);
 
-	/*
-	 * This is done when we lookup the root, it should already be complete
-	 * by the time we get here.
-	 */
-	WARN_ON(send_root->orphan_cleanup_state != ORPHAN_CLEANUP_DONE);
-
 	/*
 	 * Userspace tools do the checks and warn the user if it's
 	 * not RO.

commit fd0ddbe2509568b00df364156f47561e9f469f15
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Oct 30 12:23:01 2019 +0000

    Btrfs: send, skip backreference walking for extents with many references
    
    Backreference walking, which is used by send to figure if it can issue
    clone operations instead of write operations, can be very slow and use
    too much memory when extents have many references. This change simply
    skips backreference walking when an extent has more than 64 references,
    in which case we fallback to a write operation instead of a clone
    operation. This limit is conservative and in practice I observed no
    signicant slowdown with up to 100 references and still low memory usage
    up to that limit.
    
    This is a temporary workaround until there are speedups in the backref
    walking code, and as such it does not attempt to add extra interfaces or
    knobs to tweak the threshold.
    
    Reported-by: Atemu <atemu.main@gmail.com>
    Link: https://lore.kernel.org/linux-btrfs/CAE4GHgkvqVADtS4AzcQJxo0Q1jKQgKaW3JGp3SGdoinVo=C9eQ@mail.gmail.com/T/#me55dc0987f9cc2acaa54372ce0492c65782be3fa
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index cbf4909f5cd9..ae2db5eb1549 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -24,6 +24,14 @@
 #include "transaction.h"
 #include "compression.h"
 
+/*
+ * Maximum number of references an extent can have in order for us to attempt to
+ * issue clone operations instead of write operations. This currently exists to
+ * avoid hitting limitations of the backreference walking code (taking a lot of
+ * time and using too much memory for extents with large number of references).
+ */
+#define SEND_MAX_EXTENT_REFS	64
+
 /*
  * A fs_path is a helper to dynamically build path names with unknown size.
  * It reallocates the internal buffer on demand.
@@ -1310,6 +1318,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	struct clone_root *cur_clone_root;
 	struct btrfs_key found_key;
 	struct btrfs_path *tmp_path;
+	struct btrfs_extent_item *ei;
 	int compressed;
 	u32 i;
 
@@ -1357,7 +1366,6 @@ static int find_extent_clone(struct send_ctx *sctx,
 	ret = extent_from_logical(fs_info, disk_byte, tmp_path,
 				  &found_key, &flags);
 	up_read(&fs_info->commit_root_sem);
-	btrfs_release_path(tmp_path);
 
 	if (ret < 0)
 		goto out;
@@ -1366,6 +1374,21 @@ static int find_extent_clone(struct send_ctx *sctx,
 		goto out;
 	}
 
+	ei = btrfs_item_ptr(tmp_path->nodes[0], tmp_path->slots[0],
+			    struct btrfs_extent_item);
+	/*
+	 * Backreference walking (iterate_extent_inodes() below) is currently
+	 * too expensive when an extent has a large number of references, both
+	 * in time spent and used memory. So for now just fallback to write
+	 * operations instead of clone operations when an extent has more than
+	 * a certain amount of references.
+	 */
+	if (btrfs_extent_refs(tmp_path->nodes[0], ei) > SEND_MAX_EXTENT_REFS) {
+		ret = -ENOENT;
+		goto out;
+	}
+	btrfs_release_path(tmp_path);
+
 	/*
 	 * Setup the clone roots.
 	 */

commit 11f2069c113e02971b8db6fda62f9b9cd31a030f
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Oct 30 12:23:11 2019 +0000

    Btrfs: send, allow clone operations within the same file
    
    For send we currently skip clone operations when the source and
    destination files are the same. This is so because clone didn't support
    this case in its early days, but support for it was added back in May
    2013 by commit a96fbc72884fcb ("Btrfs: allow file data clone within a
    file"). This change adds support for it.
    
    Example:
    
      $ mkfs.btrfs -f /dev/sdd
      $ mount /dev/sdd /mnt/sdd
    
      $ xfs_io -f -c "pwrite -S 0xab -b 64K 0 64K" /mnt/sdd/foobar
      $ xfs_io -c "reflink /mnt/sdd/foobar 0 64K 64K" /mnt/sdd/foobar
    
      $ btrfs subvolume snapshot -r /mnt/sdd /mnt/sdd/snap
    
      $ mkfs.btrfs -f /dev/sde
      $ mount /dev/sde /mnt/sde
    
      $ btrfs send /mnt/sdd/snap | btrfs receive /mnt/sde
    
    Without this change file foobar at the destination has a single 128Kb
    extent:
    
      $ filefrag -v /mnt/sde/snap/foobar
      Filesystem type is: 9123683e
      File size of /mnt/sde/snap/foobar is 131072 (32 blocks of 4096 bytes)
       ext:     logical_offset:        physical_offset: length:   expected: flags:
         0:        0..      31:          0..        31:     32:             last,unknown_loc,delalloc,eof
      /mnt/sde/snap/foobar: 1 extent found
    
    With this we get a single 64Kb extent that is shared at file offsets 0
    and 64K, just like in the source filesystem:
    
      $ filefrag -v /mnt/sde/snap/foobar
      Filesystem type is: 9123683e
      File size of /mnt/sde/snap/foobar is 131072 (32 blocks of 4096 bytes)
       ext:     logical_offset:        physical_offset: length:   expected: flags:
         0:        0..      15:       3328..      3343:     16:             shared
         1:       16..      31:       3328..      3343:     16:       3344: last,shared,eof
      /mnt/sde/snap/foobar: 2 extents found
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 27e92594a81b..cbf4909f5cd9 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1248,12 +1248,20 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 	 */
 	if (found->root == bctx->sctx->send_root) {
 		/*
-		 * TODO for the moment we don't accept clones from the inode
-		 * that is currently send. We may change this when
-		 * BTRFS_IOC_CLONE_RANGE supports cloning from and to the same
-		 * file.
+		 * If the source inode was not yet processed we can't issue a
+		 * clone operation, as the source extent does not exist yet at
+		 * the destination of the stream.
 		 */
-		if (ino >= bctx->cur_objectid)
+		if (ino > bctx->cur_objectid)
+			return 0;
+		/*
+		 * We clone from the inode currently being sent as long as the
+		 * source extent is already processed, otherwise we could try
+		 * to clone from an extent that does not exist yet at the
+		 * destination of the stream.
+		 */
+		if (ino == bctx->cur_objectid &&
+		    offset >= bctx->sctx->cur_inode_next_write_offset)
 			return 0;
 	}
 

commit 4c66e0d4243bb8829f2c936e966030d967726e90
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 3 19:09:35 2019 +0200

    btrfs: drop unused parameter is_new from btrfs_iget
    
    The parameter is now always set to NULL and could be dropped. The last
    user was get_default_root but that got reworked in 05dbe6837b60 ("Btrfs:
    unify subvol= and subvolid= mounting") and the parameter became unused.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 123ac54af071..27e92594a81b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4779,7 +4779,7 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 	key.type = BTRFS_INODE_ITEM_KEY;
 	key.offset = 0;
 
-	inode = btrfs_iget(fs_info->sb, &key, root, NULL);
+	inode = btrfs_iget(fs_info->sb, &key, root);
 	if (IS_ERR(inode))
 		return PTR_ERR(inode);
 

commit 431d39887d6273d6d84edf3c2eab09f4200e788a
Author: Austin Kim <austindh.kim@gmail.com>
Date:   Tue Sep 3 12:30:19 2019 +0900

    btrfs: silence maybe-uninitialized warning in clone_range
    
    GCC throws warning message as below:
    
    ‘clone_src_i_size’ may be used uninitialized in this function
    [-Wmaybe-uninitialized]
     #define IS_ALIGNED(x, a)  (((x) & ((typeof(x))(a) - 1)) == 0)
                           ^
    fs/btrfs/send.c:5088:6: note: ‘clone_src_i_size’ was declared here
     u64 clone_src_i_size;
       ^
    The clone_src_i_size is only used as call-by-reference
    in a call to get_inode_info().
    
    Silence the warning by initializing clone_src_i_size to 0.
    
    Note that the warning is a false positive and reported by older versions
    of GCC (eg. 7.x) but not eg 9.x. As there have been numerous people, the
    patch is applied. Setting clone_src_i_size to 0 does not otherwise make
    sense and would not do any action in case the code changes in the future.
    
    Signed-off-by: Austin Kim <austindh.kim@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add note ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index f3215028235c..123ac54af071 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5085,7 +5085,7 @@ static int clone_range(struct send_ctx *sctx,
 	struct btrfs_path *path;
 	struct btrfs_key key;
 	int ret;
-	u64 clone_src_i_size;
+	u64 clone_src_i_size = 0;
 
 	/*
 	 * Prevent cloning from a zero offset with a length matching the sector

commit 6af112b11a4bc1b560f60a618ac9c1dcefe9836e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Sep 4 19:33:58 2019 +0300

    btrfs: Relinquish CPUs in btrfs_compare_trees
    
    When doing any form of incremental send the parent and the child trees
    need to be compared via btrfs_compare_trees. This  can result in long
    loop chains without ever relinquishing the CPU. This causes softlockup
    detector to trigger when comparing trees with a lot of items. Example
    report:
    
    watchdog: BUG: soft lockup - CPU#0 stuck for 24s! [snapperd:16153]
    CPU: 0 PID: 16153 Comm: snapperd Not tainted 5.2.9-1-default #1 openSUSE Tumbleweed (unreleased)
    Hardware name: QEMU KVM Virtual Machine, BIOS 0.0.0 02/06/2015
    pstate: 40000005 (nZcv daif -PAN -UAO)
    pc : __ll_sc_arch_atomic_sub_return+0x14/0x20
    lr : btrfs_release_extent_buffer_pages+0xe0/0x1e8 [btrfs]
    sp : ffff00001273b7e0
    Call trace:
     __ll_sc_arch_atomic_sub_return+0x14/0x20
     release_extent_buffer+0xdc/0x120 [btrfs]
     free_extent_buffer.part.0+0xb0/0x118 [btrfs]
     free_extent_buffer+0x24/0x30 [btrfs]
     btrfs_release_path+0x4c/0xa0 [btrfs]
     btrfs_free_path.part.0+0x20/0x40 [btrfs]
     btrfs_free_path+0x24/0x30 [btrfs]
     get_inode_info+0xa8/0xf8 [btrfs]
     finish_inode_if_needed+0xe0/0x6d8 [btrfs]
     changed_cb+0x9c/0x410 [btrfs]
     btrfs_compare_trees+0x284/0x648 [btrfs]
     send_subvol+0x33c/0x520 [btrfs]
     btrfs_ioctl_send+0x8a0/0xaf0 [btrfs]
     btrfs_ioctl+0x199c/0x2288 [btrfs]
     do_vfs_ioctl+0x4b0/0x820
     ksys_ioctl+0x84/0xb8
     __arm64_sys_ioctl+0x28/0x38
     el0_svc_common.constprop.0+0x7c/0x188
     el0_svc_handler+0x34/0x90
     el0_svc+0x8/0xc
    
    Fix this by adding a call to cond_resched at the beginning of the main
    loop in btrfs_compare_trees.
    
    Fixes: 7069830a9e38 ("Btrfs: add btrfs_compare_trees function")
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index f856d6ca3771..f3215028235c 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6757,6 +6757,7 @@ static int btrfs_compare_trees(struct btrfs_root *left_root,
 	advance_left = advance_right = 0;
 
 	while (1) {
+		cond_resched();
 		if (advance_left && !left_end_reached) {
 			ret = tree_advance(left_path, &left_level,
 					left_root_level,

commit 18d0f5c6e16ce762f92ab7879c30ff2e37cd9cef
Author: David Sterba <dsterba@suse.com>
Date:   Wed Aug 21 19:12:59 2019 +0200

    btrfs: move functions for tree compare to send.c
    
    Send is the only user of tree_compare, we can move it there along with
    the other helpers and definitions.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c3c0c064c25d..f856d6ca3771 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -260,6 +260,21 @@ struct name_cache_entry {
 	char name[];
 };
 
+#define ADVANCE							1
+#define ADVANCE_ONLY_NEXT					-1
+
+enum btrfs_compare_tree_result {
+	BTRFS_COMPARE_TREE_NEW,
+	BTRFS_COMPARE_TREE_DELETED,
+	BTRFS_COMPARE_TREE_CHANGED,
+	BTRFS_COMPARE_TREE_SAME,
+};
+typedef int (*btrfs_changed_cb_t)(struct btrfs_path *left_path,
+				  struct btrfs_path *right_path,
+				  struct btrfs_key *key,
+				  enum btrfs_compare_tree_result result,
+				  void *ctx);
+
 __cold
 static void inconsistent_snapshot_error(struct send_ctx *sctx,
 					enum btrfs_compare_tree_result result,
@@ -6514,6 +6529,365 @@ static int full_send_tree(struct send_ctx *sctx)
 	return ret;
 }
 
+static int tree_move_down(struct btrfs_path *path, int *level)
+{
+	struct extent_buffer *eb;
+
+	BUG_ON(*level == 0);
+	eb = btrfs_read_node_slot(path->nodes[*level], path->slots[*level]);
+	if (IS_ERR(eb))
+		return PTR_ERR(eb);
+
+	path->nodes[*level - 1] = eb;
+	path->slots[*level - 1] = 0;
+	(*level)--;
+	return 0;
+}
+
+static int tree_move_next_or_upnext(struct btrfs_path *path,
+				    int *level, int root_level)
+{
+	int ret = 0;
+	int nritems;
+	nritems = btrfs_header_nritems(path->nodes[*level]);
+
+	path->slots[*level]++;
+
+	while (path->slots[*level] >= nritems) {
+		if (*level == root_level)
+			return -1;
+
+		/* move upnext */
+		path->slots[*level] = 0;
+		free_extent_buffer(path->nodes[*level]);
+		path->nodes[*level] = NULL;
+		(*level)++;
+		path->slots[*level]++;
+
+		nritems = btrfs_header_nritems(path->nodes[*level]);
+		ret = 1;
+	}
+	return ret;
+}
+
+/*
+ * Returns 1 if it had to move up and next. 0 is returned if it moved only next
+ * or down.
+ */
+static int tree_advance(struct btrfs_path *path,
+			int *level, int root_level,
+			int allow_down,
+			struct btrfs_key *key)
+{
+	int ret;
+
+	if (*level == 0 || !allow_down) {
+		ret = tree_move_next_or_upnext(path, level, root_level);
+	} else {
+		ret = tree_move_down(path, level);
+	}
+	if (ret >= 0) {
+		if (*level == 0)
+			btrfs_item_key_to_cpu(path->nodes[*level], key,
+					path->slots[*level]);
+		else
+			btrfs_node_key_to_cpu(path->nodes[*level], key,
+					path->slots[*level]);
+	}
+	return ret;
+}
+
+static int tree_compare_item(struct btrfs_path *left_path,
+			     struct btrfs_path *right_path,
+			     char *tmp_buf)
+{
+	int cmp;
+	int len1, len2;
+	unsigned long off1, off2;
+
+	len1 = btrfs_item_size_nr(left_path->nodes[0], left_path->slots[0]);
+	len2 = btrfs_item_size_nr(right_path->nodes[0], right_path->slots[0]);
+	if (len1 != len2)
+		return 1;
+
+	off1 = btrfs_item_ptr_offset(left_path->nodes[0], left_path->slots[0]);
+	off2 = btrfs_item_ptr_offset(right_path->nodes[0],
+				right_path->slots[0]);
+
+	read_extent_buffer(left_path->nodes[0], tmp_buf, off1, len1);
+
+	cmp = memcmp_extent_buffer(right_path->nodes[0], tmp_buf, off2, len1);
+	if (cmp)
+		return 1;
+	return 0;
+}
+
+/*
+ * This function compares two trees and calls the provided callback for
+ * every changed/new/deleted item it finds.
+ * If shared tree blocks are encountered, whole subtrees are skipped, making
+ * the compare pretty fast on snapshotted subvolumes.
+ *
+ * This currently works on commit roots only. As commit roots are read only,
+ * we don't do any locking. The commit roots are protected with transactions.
+ * Transactions are ended and rejoined when a commit is tried in between.
+ *
+ * This function checks for modifications done to the trees while comparing.
+ * If it detects a change, it aborts immediately.
+ */
+static int btrfs_compare_trees(struct btrfs_root *left_root,
+			struct btrfs_root *right_root,
+			btrfs_changed_cb_t changed_cb, void *ctx)
+{
+	struct btrfs_fs_info *fs_info = left_root->fs_info;
+	int ret;
+	int cmp;
+	struct btrfs_path *left_path = NULL;
+	struct btrfs_path *right_path = NULL;
+	struct btrfs_key left_key;
+	struct btrfs_key right_key;
+	char *tmp_buf = NULL;
+	int left_root_level;
+	int right_root_level;
+	int left_level;
+	int right_level;
+	int left_end_reached;
+	int right_end_reached;
+	int advance_left;
+	int advance_right;
+	u64 left_blockptr;
+	u64 right_blockptr;
+	u64 left_gen;
+	u64 right_gen;
+
+	left_path = btrfs_alloc_path();
+	if (!left_path) {
+		ret = -ENOMEM;
+		goto out;
+	}
+	right_path = btrfs_alloc_path();
+	if (!right_path) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	tmp_buf = kvmalloc(fs_info->nodesize, GFP_KERNEL);
+	if (!tmp_buf) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	left_path->search_commit_root = 1;
+	left_path->skip_locking = 1;
+	right_path->search_commit_root = 1;
+	right_path->skip_locking = 1;
+
+	/*
+	 * Strategy: Go to the first items of both trees. Then do
+	 *
+	 * If both trees are at level 0
+	 *   Compare keys of current items
+	 *     If left < right treat left item as new, advance left tree
+	 *       and repeat
+	 *     If left > right treat right item as deleted, advance right tree
+	 *       and repeat
+	 *     If left == right do deep compare of items, treat as changed if
+	 *       needed, advance both trees and repeat
+	 * If both trees are at the same level but not at level 0
+	 *   Compare keys of current nodes/leafs
+	 *     If left < right advance left tree and repeat
+	 *     If left > right advance right tree and repeat
+	 *     If left == right compare blockptrs of the next nodes/leafs
+	 *       If they match advance both trees but stay at the same level
+	 *         and repeat
+	 *       If they don't match advance both trees while allowing to go
+	 *         deeper and repeat
+	 * If tree levels are different
+	 *   Advance the tree that needs it and repeat
+	 *
+	 * Advancing a tree means:
+	 *   If we are at level 0, try to go to the next slot. If that's not
+	 *   possible, go one level up and repeat. Stop when we found a level
+	 *   where we could go to the next slot. We may at this point be on a
+	 *   node or a leaf.
+	 *
+	 *   If we are not at level 0 and not on shared tree blocks, go one
+	 *   level deeper.
+	 *
+	 *   If we are not at level 0 and on shared tree blocks, go one slot to
+	 *   the right if possible or go up and right.
+	 */
+
+	down_read(&fs_info->commit_root_sem);
+	left_level = btrfs_header_level(left_root->commit_root);
+	left_root_level = left_level;
+	left_path->nodes[left_level] =
+			btrfs_clone_extent_buffer(left_root->commit_root);
+	if (!left_path->nodes[left_level]) {
+		up_read(&fs_info->commit_root_sem);
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	right_level = btrfs_header_level(right_root->commit_root);
+	right_root_level = right_level;
+	right_path->nodes[right_level] =
+			btrfs_clone_extent_buffer(right_root->commit_root);
+	if (!right_path->nodes[right_level]) {
+		up_read(&fs_info->commit_root_sem);
+		ret = -ENOMEM;
+		goto out;
+	}
+	up_read(&fs_info->commit_root_sem);
+
+	if (left_level == 0)
+		btrfs_item_key_to_cpu(left_path->nodes[left_level],
+				&left_key, left_path->slots[left_level]);
+	else
+		btrfs_node_key_to_cpu(left_path->nodes[left_level],
+				&left_key, left_path->slots[left_level]);
+	if (right_level == 0)
+		btrfs_item_key_to_cpu(right_path->nodes[right_level],
+				&right_key, right_path->slots[right_level]);
+	else
+		btrfs_node_key_to_cpu(right_path->nodes[right_level],
+				&right_key, right_path->slots[right_level]);
+
+	left_end_reached = right_end_reached = 0;
+	advance_left = advance_right = 0;
+
+	while (1) {
+		if (advance_left && !left_end_reached) {
+			ret = tree_advance(left_path, &left_level,
+					left_root_level,
+					advance_left != ADVANCE_ONLY_NEXT,
+					&left_key);
+			if (ret == -1)
+				left_end_reached = ADVANCE;
+			else if (ret < 0)
+				goto out;
+			advance_left = 0;
+		}
+		if (advance_right && !right_end_reached) {
+			ret = tree_advance(right_path, &right_level,
+					right_root_level,
+					advance_right != ADVANCE_ONLY_NEXT,
+					&right_key);
+			if (ret == -1)
+				right_end_reached = ADVANCE;
+			else if (ret < 0)
+				goto out;
+			advance_right = 0;
+		}
+
+		if (left_end_reached && right_end_reached) {
+			ret = 0;
+			goto out;
+		} else if (left_end_reached) {
+			if (right_level == 0) {
+				ret = changed_cb(left_path, right_path,
+						&right_key,
+						BTRFS_COMPARE_TREE_DELETED,
+						ctx);
+				if (ret < 0)
+					goto out;
+			}
+			advance_right = ADVANCE;
+			continue;
+		} else if (right_end_reached) {
+			if (left_level == 0) {
+				ret = changed_cb(left_path, right_path,
+						&left_key,
+						BTRFS_COMPARE_TREE_NEW,
+						ctx);
+				if (ret < 0)
+					goto out;
+			}
+			advance_left = ADVANCE;
+			continue;
+		}
+
+		if (left_level == 0 && right_level == 0) {
+			cmp = btrfs_comp_cpu_keys(&left_key, &right_key);
+			if (cmp < 0) {
+				ret = changed_cb(left_path, right_path,
+						&left_key,
+						BTRFS_COMPARE_TREE_NEW,
+						ctx);
+				if (ret < 0)
+					goto out;
+				advance_left = ADVANCE;
+			} else if (cmp > 0) {
+				ret = changed_cb(left_path, right_path,
+						&right_key,
+						BTRFS_COMPARE_TREE_DELETED,
+						ctx);
+				if (ret < 0)
+					goto out;
+				advance_right = ADVANCE;
+			} else {
+				enum btrfs_compare_tree_result result;
+
+				WARN_ON(!extent_buffer_uptodate(left_path->nodes[0]));
+				ret = tree_compare_item(left_path, right_path,
+							tmp_buf);
+				if (ret)
+					result = BTRFS_COMPARE_TREE_CHANGED;
+				else
+					result = BTRFS_COMPARE_TREE_SAME;
+				ret = changed_cb(left_path, right_path,
+						 &left_key, result, ctx);
+				if (ret < 0)
+					goto out;
+				advance_left = ADVANCE;
+				advance_right = ADVANCE;
+			}
+		} else if (left_level == right_level) {
+			cmp = btrfs_comp_cpu_keys(&left_key, &right_key);
+			if (cmp < 0) {
+				advance_left = ADVANCE;
+			} else if (cmp > 0) {
+				advance_right = ADVANCE;
+			} else {
+				left_blockptr = btrfs_node_blockptr(
+						left_path->nodes[left_level],
+						left_path->slots[left_level]);
+				right_blockptr = btrfs_node_blockptr(
+						right_path->nodes[right_level],
+						right_path->slots[right_level]);
+				left_gen = btrfs_node_ptr_generation(
+						left_path->nodes[left_level],
+						left_path->slots[left_level]);
+				right_gen = btrfs_node_ptr_generation(
+						right_path->nodes[right_level],
+						right_path->slots[right_level]);
+				if (left_blockptr == right_blockptr &&
+				    left_gen == right_gen) {
+					/*
+					 * As we're on a shared block, don't
+					 * allow to go deeper.
+					 */
+					advance_left = ADVANCE_ONLY_NEXT;
+					advance_right = ADVANCE_ONLY_NEXT;
+				} else {
+					advance_left = ADVANCE;
+					advance_right = ADVANCE;
+				}
+			}
+		} else if (left_level < right_level) {
+			advance_right = ADVANCE;
+		} else {
+			advance_left = ADVANCE;
+		}
+	}
+
+out:
+	btrfs_free_path(left_path);
+	btrfs_free_path(right_path);
+	kvfree(tmp_buf);
+	return ret;
+}
+
 static int send_subvol(struct send_ctx *sctx)
 {
 	int ret;

commit b4f9a1a87a48c255bb90d8a6c3d555a1abb88130
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Jul 17 13:23:39 2019 +0100

    Btrfs: fix incremental send failure after deduplication
    
    When doing an incremental send operation we can fail if we previously did
    deduplication operations against a file that exists in both snapshots. In
    that case we will fail the send operation with -EIO and print a message
    to dmesg/syslog like the following:
    
      BTRFS error (device sdc): Send: inconsistent snapshot, found updated \
      extent for inode 257 without updated inode item, send root is 258, \
      parent root is 257
    
    This requires that we deduplicate to the same file in both snapshots for
    the same amount of times on each snapshot. The issue happens because a
    deduplication only updates the iversion of an inode and does not update
    any other field of the inode, therefore if we deduplicate the file on
    each snapshot for the same amount of time, the inode will have the same
    iversion value (stored as the "sequence" field on the inode item) on both
    snapshots, therefore it will be seen as unchanged between in the send
    snapshot while there are new/updated/deleted extent items when comparing
    to the parent snapshot. This makes the send operation return -EIO and
    print an error message.
    
    Example reproducer:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
    
      # Create our first file. The first half of the file has several 64Kb
      # extents while the second half as a single 512Kb extent.
      $ xfs_io -f -s -c "pwrite -S 0xb8 -b 64K 0 512K" /mnt/foo
      $ xfs_io -c "pwrite -S 0xb8 512K 512K" /mnt/foo
    
      # Create the base snapshot and the parent send stream from it.
      $ btrfs subvolume snapshot -r /mnt /mnt/mysnap1
      $ btrfs send -f /tmp/1.snap /mnt/mysnap1
    
      # Create our second file, that has exactly the same data as the first
      # file.
      $ xfs_io -f -c "pwrite -S 0xb8 0 1M" /mnt/bar
    
      # Create the second snapshot, used for the incremental send, before
      # doing the file deduplication.
      $ btrfs subvolume snapshot -r /mnt /mnt/mysnap2
    
      # Now before creating the incremental send stream:
      #
      # 1) Deduplicate into a subrange of file foo in snapshot mysnap1. This
      #    will drop several extent items and add a new one, also updating
      #    the inode's iversion (sequence field in inode item) by 1, but not
      #    any other field of the inode;
      #
      # 2) Deduplicate into a different subrange of file foo in snapshot
      #    mysnap2. This will replace an extent item with a new one, also
      #    updating the inode's iversion by 1 but not any other field of the
      #    inode.
      #
      # After these two deduplication operations, the inode items, for file
      # foo, are identical in both snapshots, but we have different extent
      # items for this inode in both snapshots. We want to check this doesn't
      # cause send to fail with an error or produce an incorrect stream.
    
      $ xfs_io -r -c "dedupe /mnt/bar 0 0 512K" /mnt/mysnap1/foo
      $ xfs_io -r -c "dedupe /mnt/bar 512K 512K 512K" /mnt/mysnap2/foo
    
      # Create the incremental send stream.
      $ btrfs send -p /mnt/mysnap1 -f /tmp/2.snap /mnt/mysnap2
      ERROR: send ioctl failed with -5: Input/output error
    
    This issue started happening back in 2015 when deduplication was updated
    to not update the inode's ctime and mtime and update only the iversion.
    Back then we would hit a BUG_ON() in send, but later in 2016 send was
    updated to return -EIO and print the error message instead of doing the
    BUG_ON().
    
    A test case for fstests follows soon.
    
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=203933
    Fixes: 1c919a5e13702c ("btrfs: don't update mtime/ctime on deduped inodes")
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 69b59bf75882..c3c0c064c25d 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6322,68 +6322,21 @@ static int changed_extent(struct send_ctx *sctx,
 {
 	int ret = 0;
 
-	if (sctx->cur_ino != sctx->cmp_key->objectid) {
-
-		if (result == BTRFS_COMPARE_TREE_CHANGED) {
-			struct extent_buffer *leaf_l;
-			struct extent_buffer *leaf_r;
-			struct btrfs_file_extent_item *ei_l;
-			struct btrfs_file_extent_item *ei_r;
-
-			leaf_l = sctx->left_path->nodes[0];
-			leaf_r = sctx->right_path->nodes[0];
-			ei_l = btrfs_item_ptr(leaf_l,
-					      sctx->left_path->slots[0],
-					      struct btrfs_file_extent_item);
-			ei_r = btrfs_item_ptr(leaf_r,
-					      sctx->right_path->slots[0],
-					      struct btrfs_file_extent_item);
-
-			/*
-			 * We may have found an extent item that has changed
-			 * only its disk_bytenr field and the corresponding
-			 * inode item was not updated. This case happens due to
-			 * very specific timings during relocation when a leaf
-			 * that contains file extent items is COWed while
-			 * relocation is ongoing and its in the stage where it
-			 * updates data pointers. So when this happens we can
-			 * safely ignore it since we know it's the same extent,
-			 * but just at different logical and physical locations
-			 * (when an extent is fully replaced with a new one, we
-			 * know the generation number must have changed too,
-			 * since snapshot creation implies committing the current
-			 * transaction, and the inode item must have been updated
-			 * as well).
-			 * This replacement of the disk_bytenr happens at
-			 * relocation.c:replace_file_extents() through
-			 * relocation.c:btrfs_reloc_cow_block().
-			 */
-			if (btrfs_file_extent_generation(leaf_l, ei_l) ==
-			    btrfs_file_extent_generation(leaf_r, ei_r) &&
-			    btrfs_file_extent_ram_bytes(leaf_l, ei_l) ==
-			    btrfs_file_extent_ram_bytes(leaf_r, ei_r) &&
-			    btrfs_file_extent_compression(leaf_l, ei_l) ==
-			    btrfs_file_extent_compression(leaf_r, ei_r) &&
-			    btrfs_file_extent_encryption(leaf_l, ei_l) ==
-			    btrfs_file_extent_encryption(leaf_r, ei_r) &&
-			    btrfs_file_extent_other_encoding(leaf_l, ei_l) ==
-			    btrfs_file_extent_other_encoding(leaf_r, ei_r) &&
-			    btrfs_file_extent_type(leaf_l, ei_l) ==
-			    btrfs_file_extent_type(leaf_r, ei_r) &&
-			    btrfs_file_extent_disk_bytenr(leaf_l, ei_l) !=
-			    btrfs_file_extent_disk_bytenr(leaf_r, ei_r) &&
-			    btrfs_file_extent_disk_num_bytes(leaf_l, ei_l) ==
-			    btrfs_file_extent_disk_num_bytes(leaf_r, ei_r) &&
-			    btrfs_file_extent_offset(leaf_l, ei_l) ==
-			    btrfs_file_extent_offset(leaf_r, ei_r) &&
-			    btrfs_file_extent_num_bytes(leaf_l, ei_l) ==
-			    btrfs_file_extent_num_bytes(leaf_r, ei_r))
-				return 0;
-		}
-
-		inconsistent_snapshot_error(sctx, result, "extent");
-		return -EIO;
-	}
+	/*
+	 * We have found an extent item that changed without the inode item
+	 * having changed. This can happen either after relocation (where the
+	 * disk_bytenr of an extent item is replaced at
+	 * relocation.c:replace_file_extents()) or after deduplication into a
+	 * file in both the parent and send snapshots (where an extent item can
+	 * get modified or replaced with a new one). Note that deduplication
+	 * updates the inode item, but it only changes the iversion (sequence
+	 * field in the inode item) of the inode, so if a file is deduplicated
+	 * the same amount of times in both the parent and send snapshots, its
+	 * iversion becames the same in both snapshots, whence the inode item is
+	 * the same on both snapshots.
+	 */
+	if (sctx->cur_ino != sctx->cmp_key->objectid)
+		return 0;
 
 	if (!sctx->cur_inode_new_gen && !sctx->cur_inode_deleted) {
 		if (result != BTRFS_COMPARE_TREE_DELETED)

commit 9e967495e0e0ae8bb08f52aa71b29affc7075d31
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Apr 22 16:44:09 2019 +0100

    Btrfs: prevent send failures and crashes due to concurrent relocation
    
    Send always operates on read-only trees and always expected that while it
    is in progress, nothing changes in those trees. Due to that expectation
    and the fact that send is a read-only operation, it operates on commit
    roots and does not hold transaction handles. However relocation can COW
    nodes and leafs from read-only trees, which can cause unexpected failures
    and crashes (hitting BUG_ONs). while send using a node/leaf, it gets
    COWed, the transaction used to COW it is committed, a new transaction
    starts, the extent previously used for that node/leaf gets allocated,
    possibly for another tree, and the respective extent buffer' content
    changes while send is still using it. When this happens send normally
    fails with EIO being returned to user space and messages like the
    following are found in dmesg/syslog:
    
      [ 3408.699121] BTRFS error (device sdc): parent transid verify failed on 58703872 wanted 250 found 253
      [ 3441.523123] BTRFS error (device sdc): did not find backref in send_root. inode=63211, offset=0, disk_byte=5222825984 found extent=5222825984
    
    Other times, less often, we hit a BUG_ON() because an extent buffer that
    send is using used to be a node, and while send is still using it, it
    got COWed and got reused as a leaf while send is still using, producing
    the following trace:
    
     [ 3478.466280] ------------[ cut here ]------------
     [ 3478.466282] kernel BUG at fs/btrfs/ctree.c:1806!
     [ 3478.466965] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
     [ 3478.467635] CPU: 0 PID: 2165 Comm: btrfs Not tainted 5.0.0-btrfs-next-46 #1
     [ 3478.468311] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.2-0-gf9626ccb91-prebuilt.qemu-project.org 04/01/2014
     [ 3478.469681] RIP: 0010:read_node_slot+0x122/0x130 [btrfs]
     (...)
     [ 3478.471758] RSP: 0018:ffffa437826bfaa0 EFLAGS: 00010246
     [ 3478.472457] RAX: ffff961416ed7000 RBX: 000000000000003d RCX: 0000000000000002
     [ 3478.473151] RDX: 000000000000003d RSI: ffff96141e387408 RDI: ffff961599b30000
     [ 3478.473837] RBP: ffffa437826bfb8e R08: 0000000000000001 R09: ffffa437826bfb8e
     [ 3478.474515] R10: ffffa437826bfa70 R11: 0000000000000000 R12: ffff9614385c8708
     [ 3478.475186] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     [ 3478.475840] FS:  00007f8e0e9cc8c0(0000) GS:ffff9615b6a00000(0000) knlGS:0000000000000000
     [ 3478.476489] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     [ 3478.477127] CR2: 00007f98b67a056e CR3: 0000000005df6005 CR4: 00000000003606f0
     [ 3478.477762] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     [ 3478.478385] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     [ 3478.479003] Call Trace:
     [ 3478.479600]  ? do_raw_spin_unlock+0x49/0xc0
     [ 3478.480202]  tree_advance+0x173/0x1d0 [btrfs]
     [ 3478.480810]  btrfs_compare_trees+0x30c/0x690 [btrfs]
     [ 3478.481388]  ? process_extent+0x1280/0x1280 [btrfs]
     [ 3478.481954]  btrfs_ioctl_send+0x1037/0x1270 [btrfs]
     [ 3478.482510]  _btrfs_ioctl_send+0x80/0x110 [btrfs]
     [ 3478.483062]  btrfs_ioctl+0x13fe/0x3120 [btrfs]
     [ 3478.483581]  ? rq_clock_task+0x2e/0x60
     [ 3478.484086]  ? wake_up_new_task+0x1f3/0x370
     [ 3478.484582]  ? do_vfs_ioctl+0xa2/0x6f0
     [ 3478.485075]  ? btrfs_ioctl_get_supported_features+0x30/0x30 [btrfs]
     [ 3478.485552]  do_vfs_ioctl+0xa2/0x6f0
     [ 3478.486016]  ? __fget+0x113/0x200
     [ 3478.486467]  ksys_ioctl+0x70/0x80
     [ 3478.486911]  __x64_sys_ioctl+0x16/0x20
     [ 3478.487337]  do_syscall_64+0x60/0x1b0
     [ 3478.487751]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
     [ 3478.488159] RIP: 0033:0x7f8e0d7d4dd7
     (...)
     [ 3478.489349] RSP: 002b:00007ffcf6fb4908 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
     [ 3478.489742] RAX: ffffffffffffffda RBX: 0000000000000105 RCX: 00007f8e0d7d4dd7
     [ 3478.490142] RDX: 00007ffcf6fb4990 RSI: 0000000040489426 RDI: 0000000000000005
     [ 3478.490548] RBP: 0000000000000005 R08: 00007f8e0d6f3700 R09: 00007f8e0d6f3700
     [ 3478.490953] R10: 00007f8e0d6f39d0 R11: 0000000000000202 R12: 0000000000000005
     [ 3478.491343] R13: 00005624e0780020 R14: 0000000000000000 R15: 0000000000000001
     (...)
     [ 3478.493352] ---[ end trace d5f537302be4f8c8 ]---
    
    Another possibility, much less likely to happen, is that send will not
    fail but the contents of the stream it produces may not be correct.
    
    To avoid this, do not allow send and relocation (balance) to run in
    parallel. In the long term the goal is to allow for both to be able to
    run concurrently without any problems, but that will take a significant
    effort in development and testing.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 49edcc709a99..69b59bf75882 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6929,9 +6929,23 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 	if (ret)
 		goto out;
 
+	mutex_lock(&fs_info->balance_mutex);
+	if (test_bit(BTRFS_FS_BALANCE_RUNNING, &fs_info->flags)) {
+		mutex_unlock(&fs_info->balance_mutex);
+		btrfs_warn_rl(fs_info,
+		"cannot run send because a balance operation is in progress");
+		ret = -EAGAIN;
+		goto out;
+	}
+	fs_info->send_in_progress++;
+	mutex_unlock(&fs_info->balance_mutex);
+
 	current->journal_info = BTRFS_SEND_TRANS_STUB;
 	ret = send_subvol(sctx);
 	current->journal_info = NULL;
+	mutex_lock(&fs_info->balance_mutex);
+	fs_info->send_in_progress--;
+	mutex_unlock(&fs_info->balance_mutex);
 	if (ret < 0)
 		goto out;
 

commit 65019df8c3b0efa363c30ca4dd69a1a370a3ebe8
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed May 22 10:18:59 2019 +0200

    btrfs: resurrect btrfs_crc32c()
    
    Commit 9678c54388b6 ("btrfs: Remove custom crc32c init code") removed
    the btrfs_crc32c() function, because it was a duplicate of the crc32c()
    library function we already have in the kernel.
    
    Resurrect it as a shim wrapper over crc32c() to make following
    transformations of the checksumming code in btrfs easier.
    
    Also provide a btrfs_crc32_final() to ease following transformations.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index f7fe4770f0e5..49edcc709a99 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -686,7 +686,7 @@ static int send_cmd(struct send_ctx *sctx)
 	hdr->len = cpu_to_le32(sctx->send_size - sizeof(*hdr));
 	hdr->crc = 0;
 
-	crc = crc32c(0, (unsigned char *)sctx->send_buf, sctx->send_size);
+	crc = btrfs_crc32c(0, (unsigned char *)sctx->send_buf, sctx->send_size);
 	hdr->crc = cpu_to_le32(crc);
 
 	ret = write_buf(sctx->send_filp, sctx->send_buf, sctx->send_size,

commit 3c850b45110950ee8b6eeba587b4bca8cb5c9793
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 20 09:57:00 2019 +0100

    Btrfs: incremental send, fix emission of invalid clone operations
    
    When doing an incremental send we can now issue clone operations with a
    source range that ends at the source's file eof and with a destination
    range that ends at an offset smaller then the destination's file eof.
    If the eof of the source file is not aligned to the sector size of the
    filesystem, the receiver will get a -EINVAL error when trying to do the
    operation or, on older kernels, silently corrupt the destination file.
    The corruption happens on kernels without commit ac765f83f1397646
    ("Btrfs: fix data corruption due to cloning of eof block"), while the
    failure to clone happens on kernels with that commit.
    
    Example reproducer:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt/sdb
    
      $ xfs_io -f -c "pwrite -S 0xb1 0 2M" /mnt/sdb/foo
      $ xfs_io -f -c "pwrite -S 0xc7 0 2M" /mnt/sdb/bar
      $ xfs_io -f -c "pwrite -S 0x4d 0 2M" /mnt/sdb/baz
      $ xfs_io -f -c "pwrite -S 0xe2 0 2M" /mnt/sdb/zoo
    
      $ btrfs subvolume snapshot -r /mnt/sdb /mnt/sdb/base
    
      $ btrfs send -f /tmp/base.send /mnt/sdb/base
    
      $ xfs_io -c "reflink /mnt/sdb/bar 1560K 500K 100K" /mnt/sdb/bar
      $ xfs_io -c "reflink /mnt/sdb/bar 1560K 0 100K" /mnt/sdb/zoo
      $ xfs_io -c "truncate 550K" /mnt/sdb/bar
    
      $ btrfs subvolume snapshot -r /mnt/sdb /mnt/sdb/incr
    
      $ btrfs send -f /tmp/incr.send -p /mnt/sdb/base /mnt/sdb/incr
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt/sdc
    
      $ btrfs receive -f /tmp/base.send /mnt/sdc
      $ btrfs receive -vv -f /tmp/incr.send /mnt/sdc
      (...)
      truncate bar size=563200
      utimes bar
      clone zoo - source=bar source offset=512000 offset=0 length=51200
      ERROR: failed to clone extents to zoo
      Invalid argument
    
    The failure happens because the clone source range ends at the eof of file
    bar, 563200, which is not aligned to the filesystems sector size (4Kb in
    this case), and the destination range ends at offset 0 + 51200, which is
    less then the size of the file zoo (2Mb).
    
    So fix this by detecting such case and instead of issuing a clone
    operation for the whole range, do a clone operation for smaller range
    that is sector size aligned followed by a write operation for the block
    containing the eof. Here we will always be pessimistic and assume the
    destination filesystem of the send stream has the largest possible sector
    size (64Kb), since we have no way of determining it.
    
    This fixes a recent regression introduced in kernel 5.2-rc1.
    
    Fixes: 040ee6120cb6706 ("Btrfs: send, improve clone range")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ca30b1f06e2d..f7fe4770f0e5 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5224,10 +5224,50 @@ static int clone_range(struct send_ctx *sctx,
 		clone_len = min_t(u64, ext_len, len);
 
 		if (btrfs_file_extent_disk_bytenr(leaf, ei) == disk_byte &&
-		    clone_data_offset == data_offset)
-			ret = send_clone(sctx, offset, clone_len, clone_root);
-		else
+		    clone_data_offset == data_offset) {
+			const u64 src_end = clone_root->offset + clone_len;
+			const u64 sectorsize = SZ_64K;
+
+			/*
+			 * We can't clone the last block, when its size is not
+			 * sector size aligned, into the middle of a file. If we
+			 * do so, the receiver will get a failure (-EINVAL) when
+			 * trying to clone or will silently corrupt the data in
+			 * the destination file if it's on a kernel without the
+			 * fix introduced by commit ac765f83f1397646
+			 * ("Btrfs: fix data corruption due to cloning of eof
+			 * block).
+			 *
+			 * So issue a clone of the aligned down range plus a
+			 * regular write for the eof block, if we hit that case.
+			 *
+			 * Also, we use the maximum possible sector size, 64K,
+			 * because we don't know what's the sector size of the
+			 * filesystem that receives the stream, so we have to
+			 * assume the largest possible sector size.
+			 */
+			if (src_end == clone_src_i_size &&
+			    !IS_ALIGNED(src_end, sectorsize) &&
+			    offset + clone_len < sctx->cur_inode_size) {
+				u64 slen;
+
+				slen = ALIGN_DOWN(src_end - clone_root->offset,
+						  sectorsize);
+				if (slen > 0) {
+					ret = send_clone(sctx, offset, slen,
+							 clone_root);
+					if (ret < 0)
+						goto out;
+				}
+				ret = send_extent_data(sctx, offset + slen,
+						       clone_len - slen);
+			} else {
+				ret = send_clone(sctx, offset, clone_len,
+						 clone_root);
+			}
+		} else {
 			ret = send_extent_data(sctx, offset, clone_len);
+		}
 
 		if (ret < 0)
 			goto out;

commit 6b1f72e5b82a5c2a4da4d1ebb8cc01913ddbea21
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 20 09:55:42 2019 +0100

    Btrfs: incremental send, fix file corruption when no-holes feature is enabled
    
    When using the no-holes feature, if we have a file with prealloc extents
    with a start offset beyond the file's eof, doing an incremental send can
    cause corruption of the file due to incorrect hole detection. Such case
    requires that the prealloc extent(s) exist in both the parent and send
    snapshots, and that a hole is punched into the file that covers all its
    extents that do not cross the eof boundary.
    
    Example reproducer:
    
      $ mkfs.btrfs -f -O no-holes /dev/sdb
      $ mount /dev/sdb /mnt/sdb
    
      $ xfs_io -f -c "pwrite -S 0xab 0 500K" /mnt/sdb/foobar
      $ xfs_io -c "falloc -k 1200K 800K" /mnt/sdb/foobar
    
      $ btrfs subvolume snapshot -r /mnt/sdb /mnt/sdb/base
    
      $ btrfs send -f /tmp/base.snap /mnt/sdb/base
    
      $ xfs_io -c "fpunch 0 500K" /mnt/sdb/foobar
    
      $ btrfs subvolume snapshot -r /mnt/sdb /mnt/sdb/incr
    
      $ btrfs send -p /mnt/sdb/base -f /tmp/incr.snap /mnt/sdb/incr
    
      $ md5sum /mnt/sdb/incr/foobar
      816df6f64deba63b029ca19d880ee10a   /mnt/sdb/incr/foobar
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt/sdc
    
      $ btrfs receive -f /tmp/base.snap /mnt/sdc
      $ btrfs receive -f /tmp/incr.snap /mnt/sdc
    
      $ md5sum /mnt/sdc/incr/foobar
      cf2ef71f4a9e90c2f6013ba3b2257ed2   /mnt/sdc/incr/foobar
    
        --> Different checksum, because the prealloc extent beyond the
            file's eof confused the hole detection code and it assumed
            a hole starting at offset 0 and ending at the offset of the
            prealloc extent (1200Kb) instead of ending at the offset
            500Kb (the file's size).
    
    Fix this by ensuring we never cross the file's size when issuing the
    write operations for a hole.
    
    Fixes: 16e7549f045d33 ("Btrfs: incompatible format change to remove hole extents")
    CC: stable@vger.kernel.org # 3.14+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index dd38dfe174df..ca30b1f06e2d 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4999,6 +4999,12 @@ static int send_hole(struct send_ctx *sctx, u64 end)
 	if (offset >= sctx->cur_inode_size)
 		return 0;
 
+	/*
+	 * Don't go beyond the inode's i_size due to prealloc extents that start
+	 * after the i_size.
+	 */
+	end = min_t(u64, end, sctx->cur_inode_size);
+
 	if (sctx->flags & BTRFS_SEND_FLAG_NO_FILE_DATA)
 		return send_update_extent(sctx, offset, end - offset);
 

commit 62d54f3a7fa27ef6a74d6cdf643ce04beba3afa7
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Apr 22 16:43:42 2019 +0100

    Btrfs: fix race between send and deduplication that lead to failures and crashes
    
    Send operates on read only trees and expects them to never change while it
    is using them. This is part of its initial design, and this expection is
    due to two different reasons:
    
    1) When it was introduced, no operations were allowed to modifiy read-only
       subvolumes/snapshots (including defrag for example).
    
    2) It keeps send from having an impact on other filesystem operations.
       Namely send does not need to keep locks on the trees nor needs to hold on
       to transaction handles and delay transaction commits. This ends up being
       a consequence of the former reason.
    
    However the deduplication feature was introduced later (on September 2013,
    while send was introduced in July 2012) and it allowed for deduplication
    with destination files that belong to read-only trees (subvolumes and
    snapshots).
    
    That means that having a send operation (either full or incremental) running
    in parallel with a deduplication that has the destination inode in one of
    the trees used by the send operation, can result in tree nodes and leaves
    getting freed and reused while send is using them. This problem is similar
    to the problem solved for the root nodes getting freed and reused when a
    snapshot is made against one tree that is currenly being used by a send
    operation, fixed in commits [1] and [2]. These commits explain in detail
    how the problem happens and the explanation is valid for any node or leaf
    that is not the root of a tree as well. This problem was also discussed
    and explained recently in a thread [3].
    
    The problem is very easy to reproduce when using send with large trees
    (snapshots) and just a few concurrent deduplication operations that target
    files in the trees used by send. A stress test case is being sent for
    fstests that triggers the issue easily. The most common error to hit is
    the send ioctl return -EIO with the following messages in dmesg/syslog:
    
     [1631617.204075] BTRFS error (device sdc): did not find backref in send_root. inode=63292, offset=0, disk_byte=5228134400 found extent=5228134400
     [1631633.251754] BTRFS error (device sdc): parent transid verify failed on 32243712 wanted 24 found 27
    
    The first one is very easy to hit while the second one happens much less
    frequently, except for very large trees (in that test case, snapshots
    with 100000 files having large xattrs to get deep and wide trees).
    Less frequently, at least one BUG_ON can be hit:
    
     [1631742.130080] ------------[ cut here ]------------
     [1631742.130625] kernel BUG at fs/btrfs/ctree.c:1806!
     [1631742.131188] invalid opcode: 0000 [#6] SMP DEBUG_PAGEALLOC PTI
     [1631742.131726] CPU: 1 PID: 13394 Comm: btrfs Tainted: G    B D W         5.0.0-rc8-btrfs-next-45 #1
     [1631742.132265] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.2-0-gf9626ccb91-prebuilt.qemu-project.org 04/01/2014
     [1631742.133399] RIP: 0010:read_node_slot+0x122/0x130 [btrfs]
     (...)
     [1631742.135061] RSP: 0018:ffffb530021ebaa0 EFLAGS: 00010246
     [1631742.135615] RAX: ffff93ac8912e000 RBX: 000000000000009d RCX: 0000000000000002
     [1631742.136173] RDX: 000000000000009d RSI: ffff93ac564b0d08 RDI: ffff93ad5b48c000
     [1631742.136759] RBP: ffffb530021ebb7d R08: 0000000000000001 R09: ffffb530021ebb7d
     [1631742.137324] R10: ffffb530021eba70 R11: 0000000000000000 R12: ffff93ac87d0a708
     [1631742.137900] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000001
     [1631742.138455] FS:  00007f4cdb1528c0(0000) GS:ffff93ad76a80000(0000) knlGS:0000000000000000
     [1631742.139010] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     [1631742.139568] CR2: 00007f5acb3d0420 CR3: 000000012be3e006 CR4: 00000000003606e0
     [1631742.140131] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     [1631742.140719] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     [1631742.141272] Call Trace:
     [1631742.141826]  ? do_raw_spin_unlock+0x49/0xc0
     [1631742.142390]  tree_advance+0x173/0x1d0 [btrfs]
     [1631742.142948]  btrfs_compare_trees+0x268/0x690 [btrfs]
     [1631742.143533]  ? process_extent+0x1070/0x1070 [btrfs]
     [1631742.144088]  btrfs_ioctl_send+0x1037/0x1270 [btrfs]
     [1631742.144645]  _btrfs_ioctl_send+0x80/0x110 [btrfs]
     [1631742.145161]  ? trace_sched_stick_numa+0xe0/0xe0
     [1631742.145685]  btrfs_ioctl+0x13fe/0x3120 [btrfs]
     [1631742.146179]  ? account_entity_enqueue+0xd3/0x100
     [1631742.146662]  ? reweight_entity+0x154/0x1a0
     [1631742.147135]  ? update_curr+0x20/0x2a0
     [1631742.147593]  ? check_preempt_wakeup+0x103/0x250
     [1631742.148053]  ? do_vfs_ioctl+0xa2/0x6f0
     [1631742.148510]  ? btrfs_ioctl_get_supported_features+0x30/0x30 [btrfs]
     [1631742.148942]  do_vfs_ioctl+0xa2/0x6f0
     [1631742.149361]  ? __fget+0x113/0x200
     [1631742.149767]  ksys_ioctl+0x70/0x80
     [1631742.150159]  __x64_sys_ioctl+0x16/0x20
     [1631742.150543]  do_syscall_64+0x60/0x1b0
     [1631742.150931]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
     [1631742.151326] RIP: 0033:0x7f4cd9f5add7
     (...)
     [1631742.152509] RSP: 002b:00007ffe91017708 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
     [1631742.152892] RAX: ffffffffffffffda RBX: 0000000000000105 RCX: 00007f4cd9f5add7
     [1631742.153268] RDX: 00007ffe91017790 RSI: 0000000040489426 RDI: 0000000000000007
     [1631742.153633] RBP: 0000000000000007 R08: 00007f4cd9e79700 R09: 00007f4cd9e79700
     [1631742.153999] R10: 00007f4cd9e799d0 R11: 0000000000000202 R12: 0000000000000003
     [1631742.154365] R13: 0000555dfae53020 R14: 0000000000000000 R15: 0000000000000001
     (...)
     [1631742.156696] ---[ end trace 5dac9f96dcc3fd6b ]---
    
    That BUG_ON happens because while send is using a node, that node is COWed
    by a concurrent deduplication, gets freed and gets reused as a leaf (because
    a transaction commit happened in between), so when it attempts to read a
    slot from the extent buffer, at ctree.c:read_node_slot(), the extent buffer
    contents were wiped out and it now matches a leaf (which can even belong to
    some other tree now), hitting the BUG_ON(level == 0).
    
    Fix this concurrency issue by not allowing send and deduplication to run
    in parallel if both operate on the same readonly trees, returning EAGAIN
    to user space and logging an exlicit warning in dmesg/syslog.
    
    [1] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=be6821f82c3cc36e026f5afd10249988852b35ea
    [2] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=6f2f0b394b54e2b159ef969a0b5274e9bbf82ff2
    [3] https://lore.kernel.org/linux-btrfs/CAL3q7H7iqSEEyFaEtpRZw3cp613y+4k2Q8b4W7mweR3tZA05bQ@mail.gmail.com/
    
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 12363081f53b..dd38dfe174df 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6640,6 +6640,13 @@ static void btrfs_root_dec_send_in_progress(struct btrfs_root* root)
 	spin_unlock(&root->root_item_lock);
 }
 
+static void dedupe_in_progress_warn(const struct btrfs_root *root)
+{
+	btrfs_warn_rl(root->fs_info,
+"cannot use root %llu for send while deduplications on it are in progress (%d in progress)",
+		      root->root_key.objectid, root->dedupe_in_progress);
+}
+
 long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 {
 	int ret = 0;
@@ -6663,6 +6670,11 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 	 * making it RW. This also protects against deletion.
 	 */
 	spin_lock(&send_root->root_item_lock);
+	if (btrfs_root_readonly(send_root) && send_root->dedupe_in_progress) {
+		dedupe_in_progress_warn(send_root);
+		spin_unlock(&send_root->root_item_lock);
+		return -EAGAIN;
+	}
 	send_root->send_in_progress++;
 	spin_unlock(&send_root->root_item_lock);
 
@@ -6797,6 +6809,13 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 				ret = -EPERM;
 				goto out;
 			}
+			if (clone_root->dedupe_in_progress) {
+				dedupe_in_progress_warn(clone_root);
+				spin_unlock(&clone_root->root_item_lock);
+				srcu_read_unlock(&fs_info->subvol_srcu, index);
+				ret = -EAGAIN;
+				goto out;
+			}
 			clone_root->send_in_progress++;
 			spin_unlock(&clone_root->root_item_lock);
 			srcu_read_unlock(&fs_info->subvol_srcu, index);
@@ -6831,6 +6850,13 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 			ret = -EPERM;
 			goto out;
 		}
+		if (sctx->parent_root->dedupe_in_progress) {
+			dedupe_in_progress_warn(sctx->parent_root);
+			spin_unlock(&sctx->parent_root->root_item_lock);
+			srcu_read_unlock(&fs_info->subvol_srcu, index);
+			ret = -EAGAIN;
+			goto out;
+		}
 		spin_unlock(&sctx->parent_root->root_item_lock);
 
 		srcu_read_unlock(&fs_info->subvol_srcu, index);

commit 9f89d5de8631c7930898a601b6612e271aa2261c
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Apr 15 09:29:36 2019 +0100

    Btrfs: send, flush dellaloc in order to avoid data loss
    
    When we set a subvolume to read-only mode we do not flush dellaloc for any
    of its inodes (except if the filesystem is mounted with -o flushoncommit),
    since it does not affect correctness for any subsequent operations - except
    for a future send operation. The send operation will not be able to see the
    delalloc data since the respective file extent items, inode item updates,
    backreferences, etc, have not hit yet the subvolume and extent trees.
    
    Effectively this means data loss, since the send stream will not contain
    any data from existing delalloc. Another problem from this is that if the
    writeback starts and finishes while the send operation is in progress, we
    have the subvolume tree being being modified concurrently which can result
    in send failing unexpectedly with EIO or hitting runtime errors, assertion
    failures or hitting BUG_ONs, etc.
    
    Simple reproducer:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
    
      $ btrfs subvolume create /mnt/sv
      $ xfs_io -f -c "pwrite -S 0xea 0 108K" /mnt/sv/foo
    
      $ btrfs property set /mnt/sv ro true
      $ btrfs send -f /tmp/send.stream /mnt/sv
    
      $ od -t x1 -A d /mnt/sv/foo
      0000000 ea ea ea ea ea ea ea ea ea ea ea ea ea ea ea ea
      *
      0110592
    
      $ umount /mnt
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt
    
      $ btrfs receive -f /tmp/send.stream /mnt
      $ echo $?
      0
      $ od -t x1 -A d /mnt/sv/foo
      0000000
      # ---> empty file
    
    Since this a problem that affects send only, fix it in send by flushing
    dellaloc for all the roots used by the send operation before send starts
    to process the commit roots.
    
    This is a problem that affects send since it was introduced (commit
    31db9f7c23fbf7 ("Btrfs: introduce BTRFS_IOC_SEND for btrfs send/receive"))
    but backporting it to older kernels has some dependencies:
    
    - For kernels between 3.19 and 4.20, it depends on commit 3cd24c698004d2
      ("btrfs: use tagged writepage to mitigate livelock of snapshot") because
      the function btrfs_start_delalloc_snapshot() does not exist before that
      commit. So one has to either pick that commit or replace the calls to
      btrfs_start_delalloc_snapshot() in this patch with calls to
      btrfs_start_delalloc_inodes().
    
    - For kernels older than 3.19 it also requires commit e5fa8f865b3324
      ("Btrfs: ensure send always works on roots without orphans") because
      it depends on the function ensure_commit_roots_uptodate() which that
      commits introduced.
    
    - No dependencies for 5.0+ kernels.
    
    A test case for fstests follows soon.
    
    CC: stable@vger.kernel.org # 3.19+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 1e9caa552235..12363081f53b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6593,6 +6593,38 @@ static int ensure_commit_roots_uptodate(struct send_ctx *sctx)
 	return btrfs_commit_transaction(trans);
 }
 
+/*
+ * Make sure any existing dellaloc is flushed for any root used by a send
+ * operation so that we do not miss any data and we do not race with writeback
+ * finishing and changing a tree while send is using the tree. This could
+ * happen if a subvolume is in RW mode, has delalloc, is turned to RO mode and
+ * a send operation then uses the subvolume.
+ * After flushing delalloc ensure_commit_roots_uptodate() must be called.
+ */
+static int flush_delalloc_roots(struct send_ctx *sctx)
+{
+	struct btrfs_root *root = sctx->parent_root;
+	int ret;
+	int i;
+
+	if (root) {
+		ret = btrfs_start_delalloc_snapshot(root);
+		if (ret)
+			return ret;
+		btrfs_wait_ordered_extents(root, U64_MAX, 0, U64_MAX);
+	}
+
+	for (i = 0; i < sctx->clone_roots_cnt; i++) {
+		root = sctx->clone_roots[i].root;
+		ret = btrfs_start_delalloc_snapshot(root);
+		if (ret)
+			return ret;
+		btrfs_wait_ordered_extents(root, U64_MAX, 0, U64_MAX);
+	}
+
+	return 0;
+}
+
 static void btrfs_root_dec_send_in_progress(struct btrfs_root* root)
 {
 	spin_lock(&root->root_item_lock);
@@ -6817,6 +6849,10 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 			NULL);
 	sort_clone_roots = 1;
 
+	ret = flush_delalloc_roots(sctx);
+	if (ret)
+		goto out;
+
 	ret = ensure_commit_roots_uptodate(sctx);
 	if (ret)
 		goto out;

commit 040ee6120cb6706aa840a62f3b7966ebce9bfcd3
Author: Robbie Ko <robbieko@synology.com>
Date:   Fri Mar 29 18:03:27 2019 +0800

    Btrfs: send, improve clone range
    
    Improve clone_range in two scenarios.
    
    1. Remove the limit of inode size when find clone inodes We can do
       partial clone, so there is no need to limit the size of the candidate
       inode.  When clone a range, we clone the legal range only by bytenr,
       offset, len, inode size.
    
    2. In the scenarios of rewrite or clone_range, data_offset rarely
       matches exactly, so the chance of a clone is missed.
    
    e.g.
        1. Write a 1M file
            dd if=/dev/zero of=1M bs=1M count=1
    
        2. Clone 1M file
           cp --reflink 1M clone
    
        3. Rewrite 4k on the clone file
           dd if=/dev/zero of=clone bs=4k count=1 conv=notrunc
    
        The disk layout is as follows:
        item 16 key (257 EXTENT_DATA 0) itemoff 15353 itemsize 53
            extent data disk byte 1103101952 nr 1048576
            extent data offset 0 nr 1048576 ram 1048576
            extent compression(none)
        ...
        item 22 key (258 EXTENT_DATA 0) itemoff 14959 itemsize 53
            extent data disk byte 1104150528 nr 4096
            extent data offset 0 nr 4096 ram 4096
            extent compression(none)
        item 23 key (258 EXTENT_DATA 4096) itemoff 14906 itemsize 53
            extent data disk byte 1103101952 nr 1048576
            extent data offset 4096 nr 1044480 ram 1048576
            extent compression(none)
    
    When send, inode 258 file offset 4096~1048576 (item 23) has a chance to
    clone_range, but because data_offset does not match inode 257 (item 16),
    it causes missed clone and can only transfer actual data.
    
    Improve the problem by judging whether the current data_offset has
    overlap with the file extent item, and if so, adjusting offset and
    extent_len so that we can clone correctly.
    
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 7ea2d6b1f170..1e9caa552235 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1160,7 +1160,6 @@ static int get_inode_path(struct btrfs_root *root,
 struct backref_ctx {
 	struct send_ctx *sctx;
 
-	struct btrfs_path *path;
 	/* number of total found references */
 	u64 found;
 
@@ -1213,8 +1212,6 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 {
 	struct backref_ctx *bctx = ctx_;
 	struct clone_root *found;
-	int ret;
-	u64 i_size;
 
 	/* First check if the root is in the list of accepted clone sources */
 	found = bsearch((void *)(uintptr_t)root, bctx->sctx->clone_roots,
@@ -1230,19 +1227,6 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 		bctx->found_itself = 1;
 	}
 
-	/*
-	 * There are inodes that have extents that lie behind its i_size. Don't
-	 * accept clones from these extents.
-	 */
-	ret = __get_inode_info(found->root, bctx->path, ino, &i_size, NULL, NULL,
-			       NULL, NULL, NULL);
-	btrfs_release_path(bctx->path);
-	if (ret < 0)
-		return ret;
-
-	if (offset + bctx->data_offset + bctx->extent_len > i_size)
-		return 0;
-
 	/*
 	 * Make sure we don't consider clones from send_root that are
 	 * behind the current inode/offset.
@@ -1319,8 +1303,6 @@ static int find_extent_clone(struct send_ctx *sctx,
 		goto out;
 	}
 
-	backref_ctx->path = tmp_path;
-
 	if (data_offset >= ino_size) {
 		/*
 		 * There may be extents that lie behind the file's size.
@@ -5082,6 +5064,7 @@ static int clone_range(struct send_ctx *sctx,
 	struct btrfs_path *path;
 	struct btrfs_key key;
 	int ret;
+	u64 clone_src_i_size;
 
 	/*
 	 * Prevent cloning from a zero offset with a length matching the sector
@@ -5106,6 +5089,16 @@ static int clone_range(struct send_ctx *sctx,
 	if (!path)
 		return -ENOMEM;
 
+	/*
+	 * There are inodes that have extents that lie behind its i_size. Don't
+	 * accept clones from these extents.
+	 */
+	ret = __get_inode_info(clone_root->root, path, clone_root->ino,
+			       &clone_src_i_size, NULL, NULL, NULL, NULL, NULL);
+	btrfs_release_path(path);
+	if (ret < 0)
+		goto out;
+
 	/*
 	 * We can't send a clone operation for the entire range if we find
 	 * extent items in the respective range in the source file that
@@ -5148,6 +5141,7 @@ static int clone_range(struct send_ctx *sctx,
 		u8 type;
 		u64 ext_len;
 		u64 clone_len;
+		u64 clone_data_offset;
 
 		if (slot >= btrfs_header_nritems(leaf)) {
 			ret = btrfs_next_leaf(clone_root->root, path);
@@ -5201,10 +5195,30 @@ static int clone_range(struct send_ctx *sctx,
 		if (key.offset >= clone_root->offset + len)
 			break;
 
+		if (key.offset >= clone_src_i_size)
+			break;
+
+		if (key.offset + ext_len > clone_src_i_size)
+			ext_len = clone_src_i_size - key.offset;
+
+		clone_data_offset = btrfs_file_extent_offset(leaf, ei);
+		if (btrfs_file_extent_disk_bytenr(leaf, ei) == disk_byte) {
+			clone_root->offset = key.offset;
+			if (clone_data_offset < data_offset &&
+				clone_data_offset + ext_len > data_offset) {
+				u64 extent_offset;
+
+				extent_offset = data_offset - clone_data_offset;
+				ext_len -= extent_offset;
+				clone_data_offset += extent_offset;
+				clone_root->offset += extent_offset;
+			}
+		}
+
 		clone_len = min_t(u64, ext_len, len);
 
 		if (btrfs_file_extent_disk_bytenr(leaf, ei) == disk_byte &&
-		    btrfs_file_extent_offset(leaf, ei) == data_offset)
+		    clone_data_offset == data_offset)
 			ret = send_clone(sctx, offset, clone_len, clone_root);
 		else
 			ret = send_extent_data(sctx, offset, clone_len);

commit 96d4f267e40f9509e8a66e2b39e8b95655617693
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 3 18:57:57 2019 -0800

    Remove 'type' argument from access_ok() function
    
    Nobody has actually used the type (VERIFY_READ vs VERIFY_WRITE) argument
    of the user address range verification function since we got rid of the
    old racy i386-only code to walk page tables by hand.
    
    It existed because the original 80386 would not honor the write protect
    bit when in kernel mode, so you had to do COW by hand before doing any
    user access.  But we haven't supported that in a long time, and these
    days the 'type' argument is a purely historical artifact.
    
    A discussion about extending 'user_access_begin()' to do the range
    checking resulted this patch, because there is no way we're going to
    move the old VERIFY_xyz interface to that model.  And it's best done at
    the end of the merge window when I've done most of my merges, so let's
    just get this done once and for all.
    
    This patch was mostly done with a sed-script, with manual fix-ups for
    the cases that weren't of the trivial 'access_ok(VERIFY_xyz' form.
    
    There were a couple of notable cases:
    
     - csky still had the old "verify_area()" name as an alias.
    
     - the iter_iov code had magical hardcoded knowledge of the actual
       values of VERIFY_{READ,WRITE} (not that they mattered, since nothing
       really used it)
    
     - microblaze used the type argument for a debug printout
    
    but other than those oddities this should be a total no-op patch.
    
    I tried to fix up all architectures, did fairly extensive grepping for
    access_ok() uses, and the changes are trivial, but I may have missed
    something.  Any missed conversion should be trivially fixable, though.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 1b15b43905f8..7ea2d6b1f170 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6646,7 +6646,7 @@ long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 		goto out;
 	}
 
-	if (!access_ok(VERIFY_READ, arg->clone_sources,
+	if (!access_ok(arg->clone_sources,
 			sizeof(*arg->clone_sources) *
 			arg->clone_sources_count)) {
 		ret = -EFAULT;

commit 52042d8e82ff50d40e76a275ac0b97aa663328b0
Author: Andrea Gelmini <andrea.gelmini@gelma.net>
Date:   Wed Nov 28 12:05:13 2018 +0100

    btrfs: Fix typos in comments and strings
    
    The typos accumulate over time so once in a while time they get fixed in
    a large patch.
    
    Signed-off-by: Andrea Gelmini <andrea.gelmini@gelma.net>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 9df4c0b0e789..1b15b43905f8 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2238,7 +2238,7 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
  * inodes "orphan" name instead of the real name and stop. Same with new inodes
  * that were not created yet and overwritten inodes/refs.
  *
- * When do we have have orphan inodes:
+ * When do we have orphan inodes:
  * 1. When an inode is freshly created and thus no valid refs are available yet
  * 2. When a directory lost all it's refs (deleted) but still has dir items
  *    inside which were not processed yet (pending for move/delete). If anyone
@@ -3854,7 +3854,7 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 		/*
 		 * We may have refs where the parent directory does not exist
 		 * yet. This happens if the parent directories inum is higher
-		 * the the current inum. To handle this case, we create the
+		 * than the current inum. To handle this case, we create the
 		 * parent directory out of order. But we need to check if this
 		 * did already happen before due to other refs in the same dir.
 		 */

commit 7073017aeb98db311ca407f0f552f2bfc1af3015
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed Dec 5 15:23:03 2018 +0100

    btrfs: use offset_in_page instead of open-coding it
    
    Constructs like 'var & (PAGE_SIZE - 1)' or 'var & ~PAGE_MASK' can denote an
    offset into a page.
    
    So replace them by the offset_in_page() macro instead of open-coding it if
    they're not used as an alignment check.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 5be83b5a1b43..9df4c0b0e789 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4775,7 +4775,7 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 	struct btrfs_key key;
 	pgoff_t index = offset >> PAGE_SHIFT;
 	pgoff_t last_index;
-	unsigned pg_offset = offset & ~PAGE_MASK;
+	unsigned pg_offset = offset_in_page(offset);
 	ssize_t ret = 0;
 
 	key.objectid = sctx->cur_ino;

commit a4390aee72713d9e73f1132bcdeb17d72fbbf974
Author: Robbie Ko <robbieko@synology.com>
Date:   Wed Nov 14 18:32:37 2018 +0000

    Btrfs: send, fix infinite loop due to directory rename dependencies
    
    When doing an incremental send, due to the need of delaying directory move
    (rename) operations we can end up in infinite loop at
    apply_children_dir_moves().
    
    An example scenario that triggers this problem is described below, where
    directory names correspond to the numbers of their respective inodes.
    
    Parent snapshot:
    
     .
     |--- 261/
           |--- 271/
                 |--- 266/
                       |--- 259/
                       |--- 260/
                       |     |--- 267
                       |
                       |--- 264/
                       |     |--- 258/
                       |           |--- 257/
                       |
                       |--- 265/
                       |--- 268/
                       |--- 269/
                       |     |--- 262/
                       |
                       |--- 270/
                       |--- 272/
                       |     |--- 263/
                       |     |--- 275/
                       |
                       |--- 274/
                             |--- 273/
    
    Send snapshot:
    
     .
     |-- 275/
          |-- 274/
               |-- 273/
                    |-- 262/
                         |-- 269/
                              |-- 258/
                                   |-- 271/
                                        |-- 268/
                                             |-- 267/
                                                  |-- 270/
                                                       |-- 259/
                                                       |    |-- 265/
                                                       |
                                                       |-- 272/
                                                            |-- 257/
                                                                 |-- 260/
                                                                 |-- 264/
                                                                      |-- 263/
                                                                           |-- 261/
                                                                                |-- 266/
    
    When processing inode 257 we delay its move (rename) operation because its
    new parent in the send snapshot, inode 272, was not yet processed. Then
    when processing inode 272, we delay the move operation for that inode
    because inode 274 is its ancestor in the send snapshot. Finally we delay
    the move operation for inode 274 when processing it because inode 275 is
    its new parent in the send snapshot and was not yet moved.
    
    When finishing processing inode 275, we start to do the move operations
    that were previously delayed (at apply_children_dir_moves()), resulting in
    the following iterations:
    
    1) We issue the move operation for inode 274;
    
    2) Because inode 262 depended on the move operation of inode 274 (it was
       delayed because 274 is its ancestor in the send snapshot), we issue the
       move operation for inode 262;
    
    3) We issue the move operation for inode 272, because it was delayed by
       inode 274 too (ancestor of 272 in the send snapshot);
    
    4) We issue the move operation for inode 269 (it was delayed by 262);
    
    5) We issue the move operation for inode 257 (it was delayed by 272);
    
    6) We issue the move operation for inode 260 (it was delayed by 272);
    
    7) We issue the move operation for inode 258 (it was delayed by 269);
    
    8) We issue the move operation for inode 264 (it was delayed by 257);
    
    9) We issue the move operation for inode 271 (it was delayed by 258);
    
    10) We issue the move operation for inode 263 (it was delayed by 264);
    
    11) We issue the move operation for inode 268 (it was delayed by 271);
    
    12) We verify if we can issue the move operation for inode 270 (it was
        delayed by 271). We detect a path loop in the current state, because
        inode 267 needs to be moved first before we can issue the move
        operation for inode 270. So we delay again the move operation for
        inode 270, this time we will attempt to do it after inode 267 is
        moved;
    
    13) We issue the move operation for inode 261 (it was delayed by 263);
    
    14) We verify if we can issue the move operation for inode 266 (it was
        delayed by 263). We detect a path loop in the current state, because
        inode 270 needs to be moved first before we can issue the move
        operation for inode 266. So we delay again the move operation for
        inode 266, this time we will attempt to do it after inode 270 is
        moved (its move operation was delayed in step 12);
    
    15) We issue the move operation for inode 267 (it was delayed by 268);
    
    16) We verify if we can issue the move operation for inode 266 (it was
        delayed by 270). We detect a path loop in the current state, because
        inode 270 needs to be moved first before we can issue the move
        operation for inode 266. So we delay again the move operation for
        inode 266, this time we will attempt to do it after inode 270 is
        moved (its move operation was delayed in step 12). So here we added
        again the same delayed move operation that we added in step 14;
    
    17) We attempt again to see if we can issue the move operation for inode
        266, and as in step 16, we realize we can not due to a path loop in
        the current state due to a dependency on inode 270. Again we delay
        inode's 266 rename to happen after inode's 270 move operation, adding
        the same dependency to the empty stack that we did in steps 14 and 16.
        The next iteration will pick the same move dependency on the stack
        (the only entry) and realize again there is still a path loop and then
        again the same dependency to the stack, over and over, resulting in
        an infinite loop.
    
    So fix this by preventing adding the same move dependency entries to the
    stack by removing each pending move record from the red black tree of
    pending moves. This way the next call to get_pending_dir_moves() will
    not return anything for the current parent inode.
    
    A test case for fstests, with this reproducer, follows soon.
    
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    [Wrote changelog with example and more clear explanation]
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 094cc1444a90..5be83b5a1b43 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3340,7 +3340,8 @@ static void free_pending_move(struct send_ctx *sctx, struct pending_dir_move *m)
 	kfree(m);
 }
 
-static void tail_append_pending_moves(struct pending_dir_move *moves,
+static void tail_append_pending_moves(struct send_ctx *sctx,
+				      struct pending_dir_move *moves,
 				      struct list_head *stack)
 {
 	if (list_empty(&moves->list)) {
@@ -3351,6 +3352,10 @@ static void tail_append_pending_moves(struct pending_dir_move *moves,
 		list_add_tail(&moves->list, stack);
 		list_splice_tail(&list, stack);
 	}
+	if (!RB_EMPTY_NODE(&moves->node)) {
+		rb_erase(&moves->node, &sctx->pending_dir_moves);
+		RB_CLEAR_NODE(&moves->node);
+	}
 }
 
 static int apply_children_dir_moves(struct send_ctx *sctx)
@@ -3365,7 +3370,7 @@ static int apply_children_dir_moves(struct send_ctx *sctx)
 		return 0;
 
 	INIT_LIST_HEAD(&stack);
-	tail_append_pending_moves(pm, &stack);
+	tail_append_pending_moves(sctx, pm, &stack);
 
 	while (!list_empty(&stack)) {
 		pm = list_first_entry(&stack, struct pending_dir_move, list);
@@ -3376,7 +3381,7 @@ static int apply_children_dir_moves(struct send_ctx *sctx)
 			goto out;
 		pm = get_pending_dir_moves(sctx, parent_ino);
 		if (pm)
-			tail_append_pending_moves(pm, &stack);
+			tail_append_pending_moves(sctx, pm, &stack);
 	}
 	return 0;
 

commit 3cf5068f3d068d788871b0da1a0348048e68b9d6
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Wed Sep 12 06:06:26 2018 +0800

    Btrfs: unify error handling of btrfs_lookup_dir_item
    
    Unify the error handling of directory item lookups using IS_ERR_OR_NULL.
    No functional changes.
    
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index bd5756504709..094cc1444a90 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1693,12 +1693,8 @@ static int lookup_dir_item_inode(struct btrfs_root *root,
 
 	di = btrfs_lookup_dir_item(NULL, root, path,
 			dir, name, name_len, 0);
-	if (!di) {
-		ret = -ENOENT;
-		goto out;
-	}
-	if (IS_ERR(di)) {
-		ret = PTR_ERR(di);
+	if (IS_ERR_OR_NULL(di)) {
+		ret = di ? PTR_ERR(di) : -ENOENT;
 		goto out;
 	}
 	btrfs_dir_item_key_to_cpu(path->nodes[0], di, &key);

commit 4fd786e6c3d67b1348e0ad4f450efe9fc9d7a306
Author: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
Date:   Mon Aug 6 14:25:24 2018 +0900

    btrfs: Remove 'objectid' member from struct btrfs_root
    
    There are two members in struct btrfs_root which indicate root's
    objectid: objectid and root_key.objectid.
    
    They are both set to the same value in __setup_root():
    
      static void __setup_root(struct btrfs_root *root,
                               struct btrfs_fs_info *fs_info,
                               u64 objectid)
      {
        ...
        root->objectid = objectid;
        ...
        root->root_key.objectid = objecitd;
        ...
      }
    
    and not changed to other value after initialization.
    
    grep in btrfs directory shows both are used in many places:
      $ grep -rI "root->root_key.objectid" | wc -l
      133
      $ grep -rI "root->objectid" | wc -l
      55
     (4.17, inc. some noise)
    
    It is confusing to have two similar variable names and it seems
    that there is no rule about which should be used in a certain case.
    
    Since ->root_key itself is needed for tree reloc tree, let's remove
    'objecitd' member and unify code to use ->root_key.objectid in all places.
    
    Signed-off-by: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ba8950bfd9c7..bd5756504709 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1186,9 +1186,9 @@ static int __clone_root_cmp_bsearch(const void *key, const void *elt)
 	u64 root = (u64)(uintptr_t)key;
 	struct clone_root *cr = (struct clone_root *)elt;
 
-	if (root < cr->root->objectid)
+	if (root < cr->root->root_key.objectid)
 		return -1;
-	if (root > cr->root->objectid)
+	if (root > cr->root->root_key.objectid)
 		return 1;
 	return 0;
 }
@@ -1198,9 +1198,9 @@ static int __clone_root_cmp_sort(const void *e1, const void *e2)
 	struct clone_root *cr1 = (struct clone_root *)e1;
 	struct clone_root *cr2 = (struct clone_root *)e2;
 
-	if (cr1->root->objectid < cr2->root->objectid)
+	if (cr1->root->root_key.objectid < cr2->root->root_key.objectid)
 		return -1;
-	if (cr1->root->objectid > cr2->root->objectid)
+	if (cr1->root->root_key.objectid > cr2->root->root_key.objectid)
 		return 1;
 	return 0;
 }
@@ -2346,7 +2346,7 @@ static int send_subvol_begin(struct send_ctx *sctx)
 		return -ENOMEM;
 	}
 
-	key.objectid = send_root->objectid;
+	key.objectid = send_root->root_key.objectid;
 	key.type = BTRFS_ROOT_BACKREF_KEY;
 	key.offset = 0;
 
@@ -2362,7 +2362,7 @@ static int send_subvol_begin(struct send_ctx *sctx)
 	leaf = path->nodes[0];
 	btrfs_item_key_to_cpu(leaf, &key, path->slots[0]);
 	if (key.type != BTRFS_ROOT_BACKREF_KEY ||
-	    key.objectid != send_root->objectid) {
+	    key.objectid != send_root->root_key.objectid) {
 		ret = -ENOENT;
 		goto out;
 	}
@@ -4907,8 +4907,8 @@ static int send_clone(struct send_ctx *sctx,
 
 	btrfs_debug(sctx->send_root->fs_info,
 		    "send_clone offset=%llu, len=%d, clone_root=%llu, clone_inode=%llu, clone_offset=%llu",
-		    offset, len, clone_root->root->objectid, clone_root->ino,
-		    clone_root->offset);
+		    offset, len, clone_root->root->root_key.objectid,
+		    clone_root->ino, clone_root->offset);
 
 	p = fs_path_alloc();
 	if (!p)

commit 22d3151c2c4cb517a309154d1e828a28106508c7
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Jul 30 12:39:58 2018 +0100

    Btrfs: send, fix incorrect file layout after hole punching beyond eof
    
    When doing an incremental send, if we have a file in the parent snapshot
    that has prealloc extents beyond EOF and in the send snapshot it got a
    hole punch that partially covers the prealloc extents, the send stream,
    when replayed by a receiver, can result in a file that has a size bigger
    than it should and filled with zeroes past the correct EOF.
    
    For example:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
    
      $ xfs_io -f -c "falloc -k 0 4M" /mnt/foobar
      $ xfs_io -c "pwrite -S 0xea 0 1M" /mnt/foobar
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap1
      $ btrfs send -f /tmp/1.send /mnt/snap1
    
      $ xfs_io -c "fpunch 1M 2M" /mnt/foobar
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap2
      $ btrfs send -f /tmp/2.send -p /mnt/snap1 /mnt/snap2
    
      $ stat --format %s /mnt/snap2/foobar
      1048576
      $ md5sum /mnt/snap2/foobar
      d31659e82e87798acd4669a1e0a19d4f  /mnt/snap2/foobar
    
      $ umount /mnt
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt
    
      $ btrfs receive -f /mnt/1.snap /mnt
      $ btrfs receive -f /mnt/2.snap /mnt
    
      $ stat --format %s /mnt/snap2/foobar
      3145728
      # --> should be 1Mb and not 3Mb (which was the end offset of hole
      #     punch operation)
      $ md5sum /mnt/snap2/foobar
      117baf295297c2a995f92da725b0b651  /mnt/snap2/foobar
      # --> should be d31659e82e87798acd4669a1e0a19d4f as in the original fs
    
    This issue actually happens only since commit ffa7c4296e93 ("Btrfs: send,
    do not issue unnecessary truncate operations"), but before that commit we
    were issuing a write operation full of zeroes (to "punch" a hole) which
    was extending the file size beyond the correct value and then immediately
    issue a truncate operation to the correct size and undoing the previous
    write operation. Since the send protocol does not support fallocate, for
    extent preallocation and hole punching, fix this by not even attempting
    to send a "hole" (regular write full of zeroes) if it starts at an offset
    greater then or equals to the file's size. This approach, besides being
    much more simple then making send issue the truncate operation, adds the
    benefit of avoiding the useless pair of write of zeroes and truncate
    operations, saving time and IO at the receiver and reducing the size of
    the send stream.
    
    A test case for fstests follows soon.
    
    Fixes: ffa7c4296e93 ("Btrfs: send, do not issue unnecessary truncate operations")
    CC: stable@vger.kernel.org # 4.17+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 551294a6c9e2..ba8950bfd9c7 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5007,6 +5007,15 @@ static int send_hole(struct send_ctx *sctx, u64 end)
 	u64 len;
 	int ret = 0;
 
+	/*
+	 * A hole that starts at EOF or beyond it. Since we do not yet support
+	 * fallocate (for extent preallocation and hole punching), sending a
+	 * write of zeroes starting at EOF or beyond would later require issuing
+	 * a truncate operation which would undo the write and achieve nothing.
+	 */
+	if (offset >= sctx->cur_inode_size)
+		return 0;
+
 	if (sctx->flags & BTRFS_SEND_FLAG_NO_FILE_DATA)
 		return send_update_extent(sctx, offset, end - offset);
 

commit 46b2f4590aab71d31088a265c86026b1e96c9de4
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Jul 24 11:54:04 2018 +0100

    Btrfs: fix send failure when root has deleted files still open
    
    The more common use case of send involves creating a RO snapshot and then
    use it for a send operation. In this case it's not possible to have inodes
    in the snapshot that have a link count of zero (inode with an orphan item)
    since during snapshot creation we do the orphan cleanup. However, other
    less common use cases for send can end up seeing inodes with a link count
    of zero and in this case the send operation fails with a ENOENT error
    because any attempt to generate a path for the inode, with the purpose
    of creating it or updating it at the receiver, fails since there are no
    inode reference items. One use case it to use a regular subvolume for
    a send operation after turning it to RO mode or turning a RW snapshot
    into RO mode and then using it for a send operation. In both cases, if a
    file gets all its hard links deleted while there is an open file
    descriptor before turning the subvolume/snapshot into RO mode, the send
    operation will encounter an inode with a link count of zero and then
    fail with errno ENOENT.
    
    Example using a full send with a subvolume:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
    
      $ btrfs subvolume create /mnt/sv1
      $ touch /mnt/sv1/foo
      $ touch /mnt/sv1/bar
    
      # keep an open file descriptor on file bar
      $ exec 73</mnt/sv1/bar
      $ unlink /mnt/sv1/bar
    
      # Turn the subvolume to RO mode and use it for a full send, while
      # holding the open file descriptor.
      $ btrfs property set /mnt/sv1 ro true
    
      $ btrfs send -f /tmp/full.send /mnt/sv1
      At subvol /mnt/sv1
      ERROR: send ioctl failed with -2: No such file or directory
    
    Example using an incremental send with snapshots:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
    
      $ btrfs subvolume create /mnt/sv1
      $ touch /mnt/sv1/foo
      $ touch /mnt/sv1/bar
    
      $ btrfs subvolume snapshot -r /mnt/sv1 /mnt/snap1
    
      $ echo "hello world" >> /mnt/sv1/bar
    
      $ btrfs subvolume snapshot -r /mnt/sv1 /mnt/snap2
    
      # Turn the second snapshot to RW mode and delete file foo while
      # holding an open file descriptor on it.
      $ btrfs property set /mnt/snap2 ro false
      $ exec 73</mnt/snap2/foo
      $ unlink /mnt/snap2/foo
    
      # Set the second snapshot back to RO mode and do an incremental send.
      $ btrfs property set /mnt/snap2 ro true
    
      $ btrfs send -f /tmp/inc.send -p /mnt/snap1 /mnt/snap2
      At subvol /mnt/snap2
      ERROR: send ioctl failed with -2: No such file or directory
    
    So fix this by ignoring inodes with a link count of zero if we are either
    doing a full send or if they do not exist in the parent snapshot (they
    are new in the send snapshot), and unlink all paths found in the parent
    snapshot when doing an incremental send (and ignoring all other inode
    items, such as xattrs and extents).
    
    A test case for fstests follows soon.
    
    CC: stable@vger.kernel.org # 4.4+
    Reported-by: Martin Wilck <martin.wilck@suse.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 42e04cd3cd95..551294a6c9e2 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -100,6 +100,7 @@ struct send_ctx {
 	u64 cur_inode_rdev;
 	u64 cur_inode_last_extent;
 	u64 cur_inode_next_write_offset;
+	bool ignore_cur_inode;
 
 	u64 send_progress;
 
@@ -5796,6 +5797,9 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 	int pending_move = 0;
 	int refs_processed = 0;
 
+	if (sctx->ignore_cur_inode)
+		return 0;
+
 	ret = process_recorded_refs_if_needed(sctx, at_end, &pending_move,
 					      &refs_processed);
 	if (ret < 0)
@@ -5914,6 +5918,93 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 	return ret;
 }
 
+struct parent_paths_ctx {
+	struct list_head *refs;
+	struct send_ctx *sctx;
+};
+
+static int record_parent_ref(int num, u64 dir, int index, struct fs_path *name,
+			     void *ctx)
+{
+	struct parent_paths_ctx *ppctx = ctx;
+
+	return record_ref(ppctx->sctx->parent_root, dir, name, ppctx->sctx,
+			  ppctx->refs);
+}
+
+/*
+ * Issue unlink operations for all paths of the current inode found in the
+ * parent snapshot.
+ */
+static int btrfs_unlink_all_paths(struct send_ctx *sctx)
+{
+	LIST_HEAD(deleted_refs);
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	struct parent_paths_ctx ctx;
+	int ret;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	key.objectid = sctx->cur_ino;
+	key.type = BTRFS_INODE_REF_KEY;
+	key.offset = 0;
+	ret = btrfs_search_slot(NULL, sctx->parent_root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
+
+	ctx.refs = &deleted_refs;
+	ctx.sctx = sctx;
+
+	while (true) {
+		struct extent_buffer *eb = path->nodes[0];
+		int slot = path->slots[0];
+
+		if (slot >= btrfs_header_nritems(eb)) {
+			ret = btrfs_next_leaf(sctx->parent_root, path);
+			if (ret < 0)
+				goto out;
+			else if (ret > 0)
+				break;
+			continue;
+		}
+
+		btrfs_item_key_to_cpu(eb, &key, slot);
+		if (key.objectid != sctx->cur_ino)
+			break;
+		if (key.type != BTRFS_INODE_REF_KEY &&
+		    key.type != BTRFS_INODE_EXTREF_KEY)
+			break;
+
+		ret = iterate_inode_ref(sctx->parent_root, path, &key, 1,
+					record_parent_ref, &ctx);
+		if (ret < 0)
+			goto out;
+
+		path->slots[0]++;
+	}
+
+	while (!list_empty(&deleted_refs)) {
+		struct recorded_ref *ref;
+
+		ref = list_first_entry(&deleted_refs, struct recorded_ref, list);
+		ret = send_unlink(sctx, ref->full_path);
+		if (ret < 0)
+			goto out;
+		fs_path_free(ref->full_path);
+		list_del(&ref->list);
+		kfree(ref);
+	}
+	ret = 0;
+out:
+	btrfs_free_path(path);
+	if (ret)
+		__free_recorded_refs(&deleted_refs);
+	return ret;
+}
+
 static int changed_inode(struct send_ctx *sctx,
 			 enum btrfs_compare_tree_result result)
 {
@@ -5928,6 +6019,7 @@ static int changed_inode(struct send_ctx *sctx,
 	sctx->cur_inode_new_gen = 0;
 	sctx->cur_inode_last_extent = (u64)-1;
 	sctx->cur_inode_next_write_offset = 0;
+	sctx->ignore_cur_inode = false;
 
 	/*
 	 * Set send_progress to current inode. This will tell all get_cur_xxx
@@ -5968,6 +6060,33 @@ static int changed_inode(struct send_ctx *sctx,
 			sctx->cur_inode_new_gen = 1;
 	}
 
+	/*
+	 * Normally we do not find inodes with a link count of zero (orphans)
+	 * because the most common case is to create a snapshot and use it
+	 * for a send operation. However other less common use cases involve
+	 * using a subvolume and send it after turning it to RO mode just
+	 * after deleting all hard links of a file while holding an open
+	 * file descriptor against it or turning a RO snapshot into RW mode,
+	 * keep an open file descriptor against a file, delete it and then
+	 * turn the snapshot back to RO mode before using it for a send
+	 * operation. So if we find such cases, ignore the inode and all its
+	 * items completely if it's a new inode, or if it's a changed inode
+	 * make sure all its previous paths (from the parent snapshot) are all
+	 * unlinked and all other the inode items are ignored.
+	 */
+	if (result == BTRFS_COMPARE_TREE_NEW ||
+	    result == BTRFS_COMPARE_TREE_CHANGED) {
+		u32 nlinks;
+
+		nlinks = btrfs_inode_nlink(sctx->left_path->nodes[0], left_ii);
+		if (nlinks == 0) {
+			sctx->ignore_cur_inode = true;
+			if (result == BTRFS_COMPARE_TREE_CHANGED)
+				ret = btrfs_unlink_all_paths(sctx);
+			goto out;
+		}
+	}
+
 	if (result == BTRFS_COMPARE_TREE_NEW) {
 		sctx->cur_inode_gen = left_gen;
 		sctx->cur_inode_new = 1;
@@ -6306,15 +6425,17 @@ static int changed_cb(struct btrfs_path *left_path,
 	    key->objectid == BTRFS_FREE_SPACE_OBJECTID)
 		goto out;
 
-	if (key->type == BTRFS_INODE_ITEM_KEY)
+	if (key->type == BTRFS_INODE_ITEM_KEY) {
 		ret = changed_inode(sctx, result);
-	else if (key->type == BTRFS_INODE_REF_KEY ||
-		 key->type == BTRFS_INODE_EXTREF_KEY)
-		ret = changed_ref(sctx, result);
-	else if (key->type == BTRFS_XATTR_ITEM_KEY)
-		ret = changed_xattr(sctx, result);
-	else if (key->type == BTRFS_EXTENT_DATA_KEY)
-		ret = changed_extent(sctx, result);
+	} else if (!sctx->ignore_cur_inode) {
+		if (key->type == BTRFS_INODE_REF_KEY ||
+		    key->type == BTRFS_INODE_EXTREF_KEY)
+			ret = changed_ref(sctx, result);
+		else if (key->type == BTRFS_XATTR_ITEM_KEY)
+			ret = changed_xattr(sctx, result);
+		else if (key->type == BTRFS_EXTENT_DATA_KEY)
+			ret = changed_extent(sctx, result);
+	}
 
 out:
 	return ret;

commit ca5d2ba1ae2dfd651b798218d56c3277784fa499
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Jul 23 09:10:09 2018 +0100

    Btrfs: remove unused key assignment when doing a full send
    
    At send.c:full_send_tree() we were setting the 'key' variable in the loop
    while never using it later. We were also using two btrfs_key variables
    to store the initial key for search and the key found in every iteration
    of the loop. So remove this useless key assignment and use the same
    btrfs_key variable to store the initial search key and the key found in
    each iteration. This was introduced in the initial send commit but was
    never used (commit 31db9f7c23fb ("Btrfs: introduce BTRFS_IOC_SEND for
    btrfs send/receive").
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 6ff7a1315e52..42e04cd3cd95 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6325,7 +6325,6 @@ static int full_send_tree(struct send_ctx *sctx)
 	int ret;
 	struct btrfs_root *send_root = sctx->send_root;
 	struct btrfs_key key;
-	struct btrfs_key found_key;
 	struct btrfs_path *path;
 	struct extent_buffer *eb;
 	int slot;
@@ -6347,17 +6346,13 @@ static int full_send_tree(struct send_ctx *sctx)
 	while (1) {
 		eb = path->nodes[0];
 		slot = path->slots[0];
-		btrfs_item_key_to_cpu(eb, &found_key, slot);
+		btrfs_item_key_to_cpu(eb, &key, slot);
 
-		ret = changed_cb(path, NULL, &found_key,
+		ret = changed_cb(path, NULL, &key,
 				 BTRFS_COMPARE_TREE_NEW, sctx);
 		if (ret < 0)
 			goto out;
 
-		key.objectid = found_key.objectid;
-		key.type = found_key.type;
-		key.offset = found_key.offset + 1;
-
 		ret = btrfs_next_item(send_root, path);
 		if (ret < 0)
 			goto out;

commit e41ca5897489b1c18af75ff0cc8f5c80260b3281
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jun 6 15:41:49 2018 +0800

    btrfs: Get rid of the confusing btrfs_file_extent_inline_len
    
    We used to call btrfs_file_extent_inline_len() to get the uncompressed
    data size of an inlined extent.
    
    However this function is hiding evil, for compressed extent, it has no
    choice but to directly read out ram_bytes from btrfs_file_extent_item.
    While for uncompressed extent, it uses item size to calculate the real
    data size, and ignoring ram_bytes completely.
    
    In fact, for corrupted ram_bytes, due to above behavior kernel
    btrfs_print_leaf() can't even print correct ram_bytes to expose the bug.
    
    Since we have the tree-checker to verify all EXTENT_DATA, such mismatch
    can be detected pretty easily, thus we can trust ram_bytes without the
    evil btrfs_file_extent_inline_len().
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c47f62b19226..6ff7a1315e52 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1500,7 +1500,7 @@ static int read_symlink(struct btrfs_root *root,
 	BUG_ON(compression);
 
 	off = btrfs_file_extent_inline_start(ei);
-	len = btrfs_file_extent_inline_len(path->nodes[0], path->slots[0], ei);
+	len = btrfs_file_extent_ram_bytes(path->nodes[0], ei);
 
 	ret = fs_path_add_from_extent_buffer(dest, path->nodes[0], off, len);
 
@@ -5160,7 +5160,7 @@ static int clone_range(struct send_ctx *sctx,
 		ei = btrfs_item_ptr(leaf, slot, struct btrfs_file_extent_item);
 		type = btrfs_file_extent_type(leaf, ei);
 		if (type == BTRFS_FILE_EXTENT_INLINE) {
-			ext_len = btrfs_file_extent_inline_len(leaf, slot, ei);
+			ext_len = btrfs_file_extent_ram_bytes(leaf, ei);
 			ext_len = PAGE_ALIGN(ext_len);
 		} else {
 			ext_len = btrfs_file_extent_num_bytes(leaf, ei);
@@ -5236,8 +5236,7 @@ static int send_write_or_clone(struct send_ctx *sctx,
 			struct btrfs_file_extent_item);
 	type = btrfs_file_extent_type(path->nodes[0], ei);
 	if (type == BTRFS_FILE_EXTENT_INLINE) {
-		len = btrfs_file_extent_inline_len(path->nodes[0],
-						   path->slots[0], ei);
+		len = btrfs_file_extent_ram_bytes(path->nodes[0], ei);
 		/*
 		 * it is possible the inline item won't cover the whole page,
 		 * but there may be items after this page.  Make
@@ -5375,7 +5374,7 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 		}
 
 		if (right_type == BTRFS_FILE_EXTENT_INLINE) {
-			right_len = btrfs_file_extent_inline_len(eb, slot, ei);
+			right_len = btrfs_file_extent_ram_bytes(eb, ei);
 			right_len = PAGE_ALIGN(right_len);
 		} else {
 			right_len = btrfs_file_extent_num_bytes(eb, ei);
@@ -5496,8 +5495,7 @@ static int get_last_extent(struct send_ctx *sctx, u64 offset)
 			    struct btrfs_file_extent_item);
 	type = btrfs_file_extent_type(path->nodes[0], fi);
 	if (type == BTRFS_FILE_EXTENT_INLINE) {
-		u64 size = btrfs_file_extent_inline_len(path->nodes[0],
-							path->slots[0], fi);
+		u64 size = btrfs_file_extent_ram_bytes(path->nodes[0], fi);
 		extent_end = ALIGN(key.offset + size,
 				   sctx->send_root->fs_info->sectorsize);
 	} else {
@@ -5560,7 +5558,7 @@ static int range_is_hole_in_parent(struct send_ctx *sctx,
 		fi = btrfs_item_ptr(leaf, slot, struct btrfs_file_extent_item);
 		if (btrfs_file_extent_type(leaf, fi) ==
 		    BTRFS_FILE_EXTENT_INLINE) {
-			u64 size = btrfs_file_extent_inline_len(leaf, slot, fi);
+			u64 size = btrfs_file_extent_ram_bytes(leaf, fi);
 
 			extent_end = ALIGN(key.offset + size,
 					   root->fs_info->sectorsize);
@@ -5606,8 +5604,7 @@ static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
 			    struct btrfs_file_extent_item);
 	type = btrfs_file_extent_type(path->nodes[0], fi);
 	if (type == BTRFS_FILE_EXTENT_INLINE) {
-		u64 size = btrfs_file_extent_inline_len(path->nodes[0],
-							path->slots[0], fi);
+		u64 size = btrfs_file_extent_ram_bytes(path->nodes[0], fi);
 		extent_end = ALIGN(key->offset + size,
 				   sctx->send_root->fs_info->sectorsize);
 	} else {

commit 0f96f517dcaa58346c32be094aecd610b7d3c008
Author: Robbie Ko <robbieko@synology.com>
Date:   Tue May 8 18:11:38 2018 +0800

    btrfs: incremental send, improve rmdir performance for large directory
    
    Currently when checking if a directory can be deleted, we always check
    if all its children have been processed.
    
    Example: A directory with 2,000,000 files was deleted
    
    original: 1994m57.071s
    patch:       1m38.554s
    
    [FIX]
    Instead of checking all children on all calls to can_rmdir(), we keep
    track of the directory index offset of the child last checked in the
    last call to can_rmdir(), and then use it as the starting point for
    future calls to can_rmdir().
    
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 29cfc0df1f27..c47f62b19226 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -235,6 +235,7 @@ struct orphan_dir_info {
 	struct rb_node node;
 	u64 ino;
 	u64 gen;
+	u64 last_dir_index_offset;
 };
 
 struct name_cache_entry {
@@ -2861,6 +2862,7 @@ add_orphan_dir_info(struct send_ctx *sctx, u64 dir_ino)
 		return ERR_PTR(-ENOMEM);
 	odi->ino = dir_ino;
 	odi->gen = 0;
+	odi->last_dir_index_offset = 0;
 
 	rb_link_node(&odi->node, parent, p);
 	rb_insert_color(&odi->node, &sctx->orphan_dirs);
@@ -2916,6 +2918,7 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 	struct btrfs_key found_key;
 	struct btrfs_key loc;
 	struct btrfs_dir_item *di;
+	struct orphan_dir_info *odi = NULL;
 
 	/*
 	 * Don't try to rmdir the top/root subvolume dir.
@@ -2930,6 +2933,11 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 	key.objectid = dir;
 	key.type = BTRFS_DIR_INDEX_KEY;
 	key.offset = 0;
+
+	odi = get_orphan_dir_info(sctx, dir);
+	if (odi)
+		key.offset = odi->last_dir_index_offset;
+
 	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
 	if (ret < 0)
 		goto out;
@@ -2957,30 +2965,33 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 
 		dm = get_waiting_dir_move(sctx, loc.objectid);
 		if (dm) {
-			struct orphan_dir_info *odi;
-
 			odi = add_orphan_dir_info(sctx, dir);
 			if (IS_ERR(odi)) {
 				ret = PTR_ERR(odi);
 				goto out;
 			}
 			odi->gen = dir_gen;
+			odi->last_dir_index_offset = found_key.offset;
 			dm->rmdir_ino = dir;
 			ret = 0;
 			goto out;
 		}
 
 		if (loc.objectid > send_progress) {
-			struct orphan_dir_info *odi;
-
-			odi = get_orphan_dir_info(sctx, dir);
-			free_orphan_dir_info(sctx, odi);
+			odi = add_orphan_dir_info(sctx, dir);
+			if (IS_ERR(odi)) {
+				ret = PTR_ERR(odi);
+				goto out;
+			}
+			odi->gen = dir_gen;
+			odi->last_dir_index_offset = found_key.offset;
 			ret = 0;
 			goto out;
 		}
 
 		path->slots[0]++;
 	}
+	free_orphan_dir_info(sctx, odi);
 
 	ret = 1;
 
@@ -3258,13 +3269,16 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 
 	if (rmdir_ino) {
 		struct orphan_dir_info *odi;
+		u64 gen;
 
 		odi = get_orphan_dir_info(sctx, rmdir_ino);
 		if (!odi) {
 			/* already deleted */
 			goto finish;
 		}
-		ret = can_rmdir(sctx, rmdir_ino, odi->gen, sctx->cur_ino);
+		gen = odi->gen;
+
+		ret = can_rmdir(sctx, rmdir_ino, gen, sctx->cur_ino);
 		if (ret < 0)
 			goto out;
 		if (!ret)
@@ -3275,13 +3289,12 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 			ret = -ENOMEM;
 			goto out;
 		}
-		ret = get_cur_path(sctx, rmdir_ino, odi->gen, name);
+		ret = get_cur_path(sctx, rmdir_ino, gen, name);
 		if (ret < 0)
 			goto out;
 		ret = send_rmdir(sctx, name);
 		if (ret < 0)
 			goto out;
-		free_orphan_dir_info(sctx, odi);
 	}
 
 finish:

commit 35c8eda12fc69e8a3f67c4615050ca4e76adec32
Author: Robbie Ko <robbieko@synology.com>
Date:   Tue May 8 18:11:37 2018 +0800

    btrfs: incremental send, move allocation until it's needed in orphan_dir_info
    
    Move the allocation after the search when it's clear that the new entry
    will be added.
    
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 6e8184f239e0..29cfc0df1f27 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2844,12 +2844,6 @@ add_orphan_dir_info(struct send_ctx *sctx, u64 dir_ino)
 	struct rb_node *parent = NULL;
 	struct orphan_dir_info *entry, *odi;
 
-	odi = kmalloc(sizeof(*odi), GFP_KERNEL);
-	if (!odi)
-		return ERR_PTR(-ENOMEM);
-	odi->ino = dir_ino;
-	odi->gen = 0;
-
 	while (*p) {
 		parent = *p;
 		entry = rb_entry(parent, struct orphan_dir_info, node);
@@ -2858,11 +2852,16 @@ add_orphan_dir_info(struct send_ctx *sctx, u64 dir_ino)
 		} else if (dir_ino > entry->ino) {
 			p = &(*p)->rb_right;
 		} else {
-			kfree(odi);
 			return entry;
 		}
 	}
 
+	odi = kmalloc(sizeof(*odi), GFP_KERNEL);
+	if (!odi)
+		return ERR_PTR(-ENOMEM);
+	odi->ino = dir_ino;
+	odi->gen = 0;
+
 	rb_link_node(&odi->node, parent, p);
 	rb_insert_color(&odi->node, &sctx->orphan_dirs);
 	return odi;

commit f5686e3acdfd8b2559ed6988f85374c36e1fed4c
Author: Colin Ian King <colin.king@canonical.com>
Date:   Fri May 4 12:11:12 2018 +0100

    btrfs: send: fix spelling mistake: "send_in_progres" -> "send_in_progress"
    
    Trivial fix to spelling mistake of function name in btrfs_err message
    
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c0074d2d7d6d..6e8184f239e0 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6454,7 +6454,7 @@ static void btrfs_root_dec_send_in_progress(struct btrfs_root* root)
 	 */
 	if (root->send_in_progress < 0)
 		btrfs_err(root->fs_info,
-			  "send_in_progres unbalanced %d root %llu",
+			  "send_in_progress unbalanced %d root %llu",
 			  root->send_in_progress, root->root_key.objectid);
 	spin_unlock(&root->root_item_lock);
 }

commit a6aa10c70bf72fb28504cb5de5deac75da78b0f5
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Apr 30 19:05:07 2018 +0100

    Btrfs: send, fix missing truncate for inode with prealloc extent past eof
    
    An incremental send operation can miss a truncate operation when an inode
    has an increased size in the send snapshot and a prealloc extent beyond
    its size.
    
    Consider the following scenario where a necessary truncate operation is
    missing in the incremental send stream:
    
    1) In the parent snapshot an inode has a size of 1282957 bytes and it has
       no prealloc extents beyond its size;
    
    2) In the the send snapshot it has a size of 5738496 bytes and has a new
       extent at offsets 1884160 (length of 106496 bytes) and a prealloc
       extent beyond eof at offset 6729728 (and a length of 339968 bytes);
    
    3) When processing the prealloc extent, at offset 6729728, we end up at
       send.c:send_write_or_clone() and set the @len variable to a value of
       18446744073708560384 because @offset plus the original @len value is
       larger then the inode's size (6729728 + 339968 > 5738496). We then
       call send_extent_data(), with that @offset and @len, which in turn
       calls send_write(), and then the later calls fill_read_buf(). Because
       the offset passed to fill_read_buf() is greater then inode's i_size,
       this function returns 0 immediately, which makes send_write() and
       send_extent_data() do nothing and return immediately as well. When
       we get back to send.c:send_write_or_clone() we adjust the value
       of sctx->cur_inode_next_write_offset to @offset plus @len, which
       corresponds to 6729728 + 18446744073708560384 = 5738496, which is
       precisely the the size of the inode in the send snapshot;
    
    4) Later when at send.c:finish_inode_if_needed() we determine that
       we don't need to issue a truncate operation because the value of
       sctx->cur_inode_next_write_offset corresponds to the inode's new
       size, 5738496 bytes. This is wrong because the last write operation
       that was issued started at offset 1884160 with a length of 106496
       bytes, so the correct value for sctx->cur_inode_next_write_offset
       should be 1990656 (1884160 + 106496), so that a truncate operation
       with a value of 5738496 bytes would have been sent to insert a
       trailing hole at the destination.
    
    So fix the issue by making send.c:send_write_or_clone() not attempt
    to send write or clone operations for extents that start beyond the
    inode's size, since such attempts do nothing but waste time by
    calling helper functions and allocating path structures, and send
    currently has no fallocate command in order to create prealloc extents
    at the destination (either beyond a file's eof or not).
    
    The issue was found running the test btrfs/007 from fstests using a seed
    value of 1524346151 for fsstress.
    
    Reported-by: Gu, Jinxiang <gujx@cn.fujitsu.com>
    Fixes: ffa7c4296e93 ("Btrfs: send, do not issue unnecessary truncate operations")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 221e5cdb060b..c0074d2d7d6d 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5236,6 +5236,10 @@ static int send_write_or_clone(struct send_ctx *sctx,
 		len = btrfs_file_extent_num_bytes(path->nodes[0], ei);
 	}
 
+	if (offset >= sctx->cur_inode_size) {
+		ret = 0;
+		goto out;
+	}
 	if (offset + len > sctx->cur_inode_size)
 		len = sctx->cur_inode_size - offset;
 	if (len == 0) {

commit c1d7c514f745628eb096c5cbb10737855879ae25
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:23:33 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- sources
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 1f5748c7d1c7..221e5cdb060b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1,19 +1,6 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 2012 Alexander Block.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
 #include <linux/bsearch.h>

commit 895a72be411e9a6b40c1062f0f54faca2bb03568
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Mar 2 18:05:49 2018 -0700

    Btrfs: send: fix typo in TLV_PUT
    
    According to tlv_put()'s prototype, data and attrlen needs to be
    exchanged in the macro, but seems all callers are already aware of
    this misorder and are therefore not affected.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 6615d849f0f0..1f5748c7d1c7 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -613,9 +613,9 @@ static int tlv_put_btrfs_timespec(struct send_ctx *sctx, u16 attr,
 }
 
 
-#define TLV_PUT(sctx, attrtype, attrlen, data) \
+#define TLV_PUT(sctx, attrtype, data, attrlen) \
 	do { \
-		ret = tlv_put(sctx, attrtype, attrlen, data); \
+		ret = tlv_put(sctx, attrtype, data, attrlen); \
 		if (ret < 0) \
 			goto tlv_put_failure; \
 	} while (0)

commit ffa7c4296e93b25fc302c209ae488e57aad4c973
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Feb 6 20:40:40 2018 +0000

    Btrfs: send, do not issue unnecessary truncate operations
    
    When send finishes processing an inode representing a regular file, it
    always issues a truncate operation for that file, even if its size did
    not change or the last write sets the file size correctly. In the most
    common cases, the issued write operations set the file to correct size
    (either full or incremental sends) or the file size did not change (for
    incremental sends), so the only case where a truncate operation is needed
    is when a file size becomes smaller in the send snapshot when compared
    to the parent snapshot.
    
    By not issuing unnecessary truncate operations we reduce the stream size
    and save time in the receiver. Currently truncating a file to the same
    size triggers writeback of its last page (if it's dirty) and waits for it
    to complete (only if the file size is not aligned with the filesystem's
    sector size). This is being fixed by another patch and is independent of
    this change (that patch's title is "Btrfs: skip writeback of last page
    when truncating file to same size").
    
    The following script was used to measure time spent by a receiver without
    this change applied, with this change applied, and without this change and
    with the truncate fix applied (the fix to not make it start and wait for
    writeback to complete).
    
      $ cat test_send.sh
      #!/bin/bash
    
      SRC_DEV=/dev/sdc
      DST_DEV=/dev/sdd
      SRC_MNT=/mnt/sdc
      DST_MNT=/mnt/sdd
    
      mkfs.btrfs -f $SRC_DEV >/dev/null
      mkfs.btrfs -f $DST_DEV >/dev/null
      mount $SRC_DEV $SRC_MNT
      mount $DST_DEV $DST_MNT
    
      echo "Creating source filesystem"
      for ((t = 0; t < 10; t++)); do
          (
              for ((i = 1; i <= 20000; i++)); do
                  xfs_io -f -c "pwrite -S 0xab 0 5000" \
                      $SRC_MNT/file_$i > /dev/null
              done
          ) &
         worker_pids[$t]=$!
      done
      wait ${worker_pids[@]}
    
      echo "Creating and sending snapshot"
      btrfs subvolume snapshot -r $SRC_MNT $SRC_MNT/snap1 >/dev/null
      /usr/bin/time -f "send took %e seconds"    \
             btrfs send -f $SRC_MNT/send_file $SRC_MNT/snap1
      /usr/bin/time -f "receive took %e seconds" \
             btrfs receive -f $SRC_MNT/send_file $DST_MNT
    
      umount $SRC_MNT
      umount $DST_MNT
    
    The results, which are averages for 5 runs for each case, were the
    following:
    
    * Without this change
    
    average receive time was 26.49 seconds
    standard deviation of 2.53 seconds
    
    * Without this change and with the truncate fix
    
    average receive time was 12.51 seconds
    standard deviation of 0.32 seconds
    
    * With this change and without the truncate fix
    
    average receive time was 10.02 seconds
    standard deviation of 1.11 seconds
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 085542832b9a..6615d849f0f0 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -112,6 +112,7 @@ struct send_ctx {
 	u64 cur_inode_mode;
 	u64 cur_inode_rdev;
 	u64 cur_inode_last_extent;
+	u64 cur_inode_next_write_offset;
 
 	u64 send_progress;
 
@@ -5030,6 +5031,7 @@ static int send_hole(struct send_ctx *sctx, u64 end)
 			break;
 		offset += len;
 	}
+	sctx->cur_inode_next_write_offset = offset;
 tlv_put_failure:
 	fs_path_free(p);
 	return ret;
@@ -5265,6 +5267,7 @@ static int send_write_or_clone(struct send_ctx *sctx,
 	} else {
 		ret = send_extent_data(sctx, offset, len);
 	}
+	sctx->cur_inode_next_write_offset = offset + len;
 out:
 	return ret;
 }
@@ -5789,6 +5792,7 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 	u64 right_gid;
 	int need_chmod = 0;
 	int need_chown = 0;
+	int need_truncate = 1;
 	int pending_move = 0;
 	int refs_processed = 0;
 
@@ -5826,9 +5830,13 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 		need_chown = 1;
 		if (!S_ISLNK(sctx->cur_inode_mode))
 			need_chmod = 1;
+		if (sctx->cur_inode_next_write_offset == sctx->cur_inode_size)
+			need_truncate = 0;
 	} else {
+		u64 old_size;
+
 		ret = get_inode_info(sctx->parent_root, sctx->cur_ino,
-				NULL, NULL, &right_mode, &right_uid,
+				&old_size, NULL, &right_mode, &right_uid,
 				&right_gid, NULL);
 		if (ret < 0)
 			goto out;
@@ -5837,6 +5845,10 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 			need_chown = 1;
 		if (!S_ISLNK(sctx->cur_inode_mode) && left_mode != right_mode)
 			need_chmod = 1;
+		if ((old_size == sctx->cur_inode_size) ||
+		    (sctx->cur_inode_size > old_size &&
+		     sctx->cur_inode_next_write_offset == sctx->cur_inode_size))
+			need_truncate = 0;
 	}
 
 	if (S_ISREG(sctx->cur_inode_mode)) {
@@ -5855,10 +5867,13 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 					goto out;
 			}
 		}
-		ret = send_truncate(sctx, sctx->cur_ino, sctx->cur_inode_gen,
-				sctx->cur_inode_size);
-		if (ret < 0)
-			goto out;
+		if (need_truncate) {
+			ret = send_truncate(sctx, sctx->cur_ino,
+					    sctx->cur_inode_gen,
+					    sctx->cur_inode_size);
+			if (ret < 0)
+				goto out;
+		}
 	}
 
 	if (need_chown) {
@@ -5912,6 +5927,7 @@ static int changed_inode(struct send_ctx *sctx,
 	sctx->cur_ino = key->objectid;
 	sctx->cur_inode_new_gen = 0;
 	sctx->cur_inode_last_extent = (u64)-1;
+	sctx->cur_inode_next_write_offset = 0;
 
 	/*
 	 * Set send_progress to current inode. This will tell all get_cur_xxx

commit e67c718b5b9a306bde7e966be7b4ca48fa063d73
Author: David Sterba <dsterba@suse.com>
Date:   Mon Feb 19 17:24:18 2018 +0100

    btrfs: add more __cold annotations
    
    The __cold functions are placed to a special section, as they're
    expected to be called rarely. This could help i-cache prefetches or help
    compiler to decide which branches are more/less likely to be taken
    without any other annotations needed.
    
    Though we can't add more __exit annotations, it's still possible to add
    __cold (that's also added with __exit). That way the following function
    categories are tagged:
    
    - printf wrappers, error messages
    - exit helpers
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index b0c5d710183e..085542832b9a 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -270,6 +270,7 @@ struct name_cache_entry {
 	char name[];
 };
 
+__cold
 static void inconsistent_snapshot_error(struct send_ctx *sctx,
 					enum btrfs_compare_tree_result result,
 					const char *what)

commit 9678c54388b6a6b309ff7ee5c8d23fa9eba7c06f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 8 11:45:05 2018 +0200

    btrfs: Remove custom crc32c init code
    
    The custom crc32 init code was introduced in
    14a958e678cd ("Btrfs: fix btrfs boot when compiled as built-in") to
    enable using btrfs as a built-in. However, later as pointed out by
    60efa5eb2e88 ("Btrfs: use late_initcall instead of module_init") this
    wasn't enough and finally btrfs was switched to late_initcall which
    comes after the generic crc32c implementation is initiliased. The
    latter commit superseeded the former. Now that we don't have to
    maintain our own code let's just remove it and switch to using the
    generic implementation.
    
    Despite touching a lot of files the patch is really simple. Here is the gist of
    the changes:
    
    1. Select LIBCRC32C rather than the low-level modules.
    2. s/btrfs_crc32c/crc32c/g
    3. replace hash.h with linux/crc32c.h
    4. Move the btrfs namehash funcs to ctree.h and change the tree accordingly.
    
    I've tested this with btrfs being both a module and a built-in and xfstest
    doesn't complain.
    
    Does seem to fix the longstanding problem of not automatically selectiong
    the crc32c module when btrfs is used. Possibly there is a workaround in
    dracut.
    
    The modinfo confirms that now all the module dependencies are there:
    
    before:
    depends:        zstd_compress,zstd_decompress,raid6_pq,xor,zlib_deflate
    
    after:
    depends:        libcrc32c,zstd_compress,zstd_decompress,raid6_pq,xor,zlib_deflate
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add more info to changelog from mails ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 484e2af793de..b0c5d710183e 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -27,10 +27,10 @@
 #include <linux/vmalloc.h>
 #include <linux/string.h>
 #include <linux/compat.h>
+#include <linux/crc32c.h>
 
 #include "send.h"
 #include "backref.h"
-#include "hash.h"
 #include "locking.h"
 #include "disk-io.h"
 #include "btrfs_inode.h"
@@ -695,7 +695,7 @@ static int send_cmd(struct send_ctx *sctx)
 	hdr->len = cpu_to_le32(sctx->send_size - sizeof(*hdr));
 	hdr->crc = 0;
 
-	crc = btrfs_crc32c(0, (unsigned char *)sctx->send_buf, sctx->send_size);
+	crc = crc32c(0, (unsigned char *)sctx->send_buf, sctx->send_size);
 	hdr->crc = cpu_to_le32(crc);
 
 	ret = write_buf(sctx->send_filp, sctx->send_buf, sctx->send_size,

commit d4dfc0f4d39475ccbbac947880b5464a74c30b99
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Feb 6 20:39:20 2018 +0000

    Btrfs: send, fix issuing write op when processing hole in no data mode
    
    When doing an incremental send of a filesystem with the no-holes feature
    enabled, we end up issuing a write operation when using the no data mode
    send flag, instead of issuing an update extent operation. Fix this by
    issuing the update extent operation instead.
    
    Trivial reproducer:
    
      $ mkfs.btrfs -f -O no-holes /dev/sdc
      $ mkfs.btrfs -f /dev/sdd
      $ mount /dev/sdc /mnt/sdc
      $ mount /dev/sdd /mnt/sdd
    
      $ xfs_io -f -c "pwrite -S 0xab 0 32K" /mnt/sdc/foobar
      $ btrfs subvolume snapshot -r /mnt/sdc /mnt/sdc/snap1
    
      $ xfs_io -c "fpunch 8K 8K" /mnt/sdc/foobar
      $ btrfs subvolume snapshot -r /mnt/sdc /mnt/sdc/snap2
    
      $ btrfs send /mnt/sdc/snap1 | btrfs receive /mnt/sdd
      $ btrfs send --no-data -p /mnt/sdc/snap1 /mnt/sdc/snap2 \
           | btrfs receive -vv /mnt/sdd
    
    Before this change the output of the second receive command is:
    
      receiving snapshot snap2 uuid=f6922049-8c22-e544-9ff9-fc6755918447...
      utimes
      write foobar, offset 8192, len 8192
      utimes foobar
      BTRFS_IOC_SET_RECEIVED_SUBVOL uuid=f6922049-8c22-e544-9ff9-...
    
    After this change it is:
    
      receiving snapshot snap2 uuid=564d36a3-ebc8-7343-aec9-bf6fda278e64...
      utimes
      update_extent foobar: offset=8192, len=8192
      utimes foobar
      BTRFS_IOC_SET_RECEIVED_SUBVOL uuid=564d36a3-ebc8-7343-aec9-bf6fda278e64...
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index f306c608dc28..484e2af793de 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5005,6 +5005,9 @@ static int send_hole(struct send_ctx *sctx, u64 end)
 	u64 len;
 	int ret = 0;
 
+	if (sctx->flags & BTRFS_SEND_FLAG_NO_FILE_DATA)
+		return send_update_extent(sctx, offset, end - offset);
+
 	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;

commit bae15d95e247f94ceb32caaf13d1d71ecbfc8735
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Nov 8 08:54:26 2017 +0800

    btrfs: Cleanup existing name_len checks
    
    Since tree-checker has verified leaf when reading from disk, we don't
    need the existing verify_dir_item() or btrfs_is_name_len_valid() checks.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 20d3300bd268..f306c608dc28 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1059,12 +1059,6 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 			}
 		}
 
-		ret = btrfs_is_name_len_valid(eb, path->slots[0],
-			  (unsigned long)(di + 1), name_len + data_len);
-		if (!ret) {
-			ret = -EIO;
-			goto out;
-		}
 		if (name_len + data_len > buf_len) {
 			buf_len = name_len + data_len;
 			if (is_vmalloc_addr(buf)) {

commit ea37d5998b50a72b9045ba60a132eeb20e1c4230
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Nov 17 01:54:00 2017 +0000

    Btrfs: incremental send, fix wrong unlink path after renaming file
    
    Under some circumstances, an incremental send operation can issue wrong
    paths for unlink commands related to files that have multiple hard links
    and some (or all) of those links were renamed between the parent and send
    snapshots. Consider the following example:
    
    Parent snapshot
    
     .                                                      (ino 256)
     |---- a/                                               (ino 257)
     |     |---- b/                                         (ino 259)
     |     |     |---- c/                                   (ino 260)
     |     |     |---- f2                                   (ino 261)
     |     |
     |     |---- f2l1                                       (ino 261)
     |
     |---- d/                                               (ino 262)
           |---- f1l1_2                                     (ino 258)
           |---- f2l2                                       (ino 261)
           |---- f1_2                                       (ino 258)
    
    Send snapshot
    
     .                                                      (ino 256)
     |---- a/                                               (ino 257)
     |     |---- f2l1/                                      (ino 263)
     |             |---- b2/                                (ino 259)
     |                   |---- c/                           (ino 260)
     |                   |     |---- d3                     (ino 262)
     |                   |           |---- f1l1_2           (ino 258)
     |                   |           |---- f2l2_2           (ino 261)
     |                   |           |---- f1_2             (ino 258)
     |                   |
     |                   |---- f2                           (ino 261)
     |                   |---- f1l2                         (ino 258)
     |
     |---- d                                                (ino 261)
    
    When computing the incremental send stream the following steps happen:
    
    1) When processing inode 261, a rename operation is issued that renames
       inode 262, which currently as a path of "d", to an orphan name of
       "o262-7-0". This is done because in the send snapshot, inode 261 has
       of its hard links with a path of "d" as well.
    
    2) Two link operations are issued that create the new hard links for
       inode 261, whose names are "d" and "f2l2_2", at paths "/" and
       "o262-7-0/" respectively.
    
    3) Still while processing inode 261, unlink operations are issued to
       remove the old hard links of inode 261, with names "f2l1" and "f2l2",
       at paths "a/" and "d/". However path "d/" does not correspond anymore
       to the directory inode 262 but corresponds instead to a hard link of
       inode 261 (link command issued in the previous step). This makes the
       receiver fail with a ENOTDIR error when attempting the unlink
       operation.
    
    The problem happens because before sending the unlink operation, we failed
    to detect that inode 262 was one of ancestors for inode 261 in the parent
    snapshot, and therefore we didn't recompute the path for inode 262 before
    issuing the unlink operation for the link named "f2l2" of inode 262. The
    detection failed because the function "is_ancestor()" only follows the
    first hard link it finds for an inode instead of all of its hard links
    (as it was originally created for being used with directories only, for
    which only one hard link exists). So fix this by making "is_ancestor()"
    follow all hard links of the input inode.
    
    A test case for fstests follows soon.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c10e4c70f02d..20d3300bd268 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3521,7 +3521,40 @@ static int wait_for_dest_dir_move(struct send_ctx *sctx,
 }
 
 /*
- * Check if ino ino1 is an ancestor of inode ino2 in the given root.
+ * Check if inode ino2, or any of its ancestors, is inode ino1.
+ * Return 1 if true, 0 if false and < 0 on error.
+ */
+static int check_ino_in_path(struct btrfs_root *root,
+			     const u64 ino1,
+			     const u64 ino1_gen,
+			     const u64 ino2,
+			     const u64 ino2_gen,
+			     struct fs_path *fs_path)
+{
+	u64 ino = ino2;
+
+	if (ino1 == ino2)
+		return ino1_gen == ino2_gen;
+
+	while (ino > BTRFS_FIRST_FREE_OBJECTID) {
+		u64 parent;
+		u64 parent_gen;
+		int ret;
+
+		fs_path_reset(fs_path);
+		ret = get_first_ref(root, ino, &parent, &parent_gen, fs_path);
+		if (ret < 0)
+			return ret;
+		if (parent == ino1)
+			return parent_gen == ino1_gen;
+		ino = parent;
+	}
+	return 0;
+}
+
+/*
+ * Check if ino ino1 is an ancestor of inode ino2 in the given root for any
+ * possible path (in case ino2 is not a directory and has multiple hard links).
  * Return 1 if true, 0 if false and < 0 on error.
  */
 static int is_ancestor(struct btrfs_root *root,
@@ -3530,36 +3563,91 @@ static int is_ancestor(struct btrfs_root *root,
 		       const u64 ino2,
 		       struct fs_path *fs_path)
 {
-	u64 ino = ino2;
-	bool free_path = false;
+	bool free_fs_path = false;
 	int ret = 0;
+	struct btrfs_path *path = NULL;
+	struct btrfs_key key;
 
 	if (!fs_path) {
 		fs_path = fs_path_alloc();
 		if (!fs_path)
 			return -ENOMEM;
-		free_path = true;
+		free_fs_path = true;
 	}
 
-	while (ino > BTRFS_FIRST_FREE_OBJECTID) {
-		u64 parent;
-		u64 parent_gen;
+	path = alloc_path_for_send();
+	if (!path) {
+		ret = -ENOMEM;
+		goto out;
+	}
 
-		fs_path_reset(fs_path);
-		ret = get_first_ref(root, ino, &parent, &parent_gen, fs_path);
-		if (ret < 0) {
-			if (ret == -ENOENT && ino == ino2)
-				ret = 0;
-			goto out;
+	key.objectid = ino2;
+	key.type = BTRFS_INODE_REF_KEY;
+	key.offset = 0;
+
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
+
+	while (true) {
+		struct extent_buffer *leaf = path->nodes[0];
+		int slot = path->slots[0];
+		u32 cur_offset = 0;
+		u32 item_size;
+
+		if (slot >= btrfs_header_nritems(leaf)) {
+			ret = btrfs_next_leaf(root, path);
+			if (ret < 0)
+				goto out;
+			if (ret > 0)
+				break;
+			continue;
 		}
-		if (parent == ino1) {
-			ret = parent_gen == ino1_gen ? 1 : 0;
-			goto out;
+
+		btrfs_item_key_to_cpu(leaf, &key, slot);
+		if (key.objectid != ino2)
+			break;
+		if (key.type != BTRFS_INODE_REF_KEY &&
+		    key.type != BTRFS_INODE_EXTREF_KEY)
+			break;
+
+		item_size = btrfs_item_size_nr(leaf, slot);
+		while (cur_offset < item_size) {
+			u64 parent;
+			u64 parent_gen;
+
+			if (key.type == BTRFS_INODE_EXTREF_KEY) {
+				unsigned long ptr;
+				struct btrfs_inode_extref *extref;
+
+				ptr = btrfs_item_ptr_offset(leaf, slot);
+				extref = (struct btrfs_inode_extref *)
+					(ptr + cur_offset);
+				parent = btrfs_inode_extref_parent(leaf,
+								   extref);
+				cur_offset += sizeof(*extref);
+				cur_offset += btrfs_inode_extref_name_len(leaf,
+								  extref);
+			} else {
+				parent = key.offset;
+				cur_offset = item_size;
+			}
+
+			ret = get_inode_info(root, parent, NULL, &parent_gen,
+					     NULL, NULL, NULL, NULL);
+			if (ret < 0)
+				goto out;
+			ret = check_ino_in_path(root, ino1, ino1_gen,
+						parent, parent_gen, fs_path);
+			if (ret)
+				goto out;
 		}
-		ino = parent;
+		path->slots[0]++;
 	}
+	ret = 0;
  out:
-	if (free_path)
+	btrfs_free_path(path);
+	if (free_fs_path)
 		fs_path_free(fs_path);
 	return ret;
 }

commit c995ab3cda3f4178c1f1a47926bea5f8372880cb
Author: Zygo Blaxell <ce3g8jdj@umail.furryterror.org>
Date:   Fri Sep 22 13:58:45 2017 -0400

    btrfs: add a flag to iterate_inodes_from_logical to find all extent refs for uncompressed extents
    
    The LOGICAL_INO ioctl provides a backward mapping from extent bytenr and
    offset (encoded as a single logical address) to a list of extent refs.
    LOGICAL_INO complements TREE_SEARCH, which provides the forward mapping
    (extent ref -> extent bytenr and offset, or logical address).  These are
    useful capabilities for programs that manipulate extents and extent
    references from userspace (e.g. dedup and defrag utilities).
    
    When the extents are uncompressed (and not encrypted and not other),
    check_extent_in_eb performs filtering of the extent refs to remove any
    extent refs which do not contain the same extent offset as the 'logical'
    parameter's extent offset.  This prevents LOGICAL_INO from returning
    references to more than a single block.
    
    To find the set of extent references to an uncompressed extent from [a, b),
    userspace has to run a loop like this pseudocode:
    
            for (i = a; i < b; ++i)
                    extent_ref_set += LOGICAL_INO(i);
    
    At each iteration of the loop (up to 32768 iterations for a 128M extent),
    data we are interested in is collected in the kernel, then deleted by
    the filter in check_extent_in_eb.
    
    When the extents are compressed (or encrypted or other), the 'logical'
    parameter must be an extent bytenr (the 'a' parameter in the loop).
    No filtering by extent offset is done (or possible?) so the result is
    the complete set of extent refs for the entire extent.  This removes
    the need for the loop, since we get all the extent refs in one call.
    
    Add an 'ignore_offset' argument to iterate_inodes_from_logical,
    [...several levels of function call graph...], and check_extent_in_eb, so
    that we can disable the extent offset filtering for uncompressed extents.
    This flag can be set by an improved version of the LOGICAL_INO ioctl to
    get either behavior as desired.
    
    There is no functional change in this patch.  The new flag is always
    false.
    
    Signed-off-by: Zygo Blaxell <ce3g8jdj@umail.furryterror.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor coding style fixes ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 13b98a554aab..c10e4c70f02d 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1423,7 +1423,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 		extent_item_pos = 0;
 	ret = iterate_extent_inodes(fs_info, found_key.objectid,
 				    extent_item_pos, 1, __iterate_backrefs,
-				    backref_ctx);
+				    backref_ctx, false);
 
 	if (ret < 0)
 		goto out;

commit eb7b9d6a467409cc0b6c369b0a72489bf3be6801
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Oct 16 16:29:23 2017 +0300

    btrfs: send: remove unused code
    
    This code was first introduced in 31db9f7c23fb ("Btrfs: introduce
    BTRFS_IOC_SEND for btrfs send/receive") and it was not functional, then
    it got slightly refactored in e938c8ad543c ("Btrfs: code cleanups for
    send/receive"), alas it was still dead. So let's remove it for good!
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d9ddcdbdd2e7..13b98a554aab 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1271,12 +1271,6 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 		 */
 		if (ino >= bctx->cur_objectid)
 			return 0;
-#if 0
-		if (ino > bctx->cur_objectid)
-			return 0;
-		if (offset + bctx->extent_len > bctx->cur_offset)
-			return 0;
-#endif
 	}
 
 	bctx->found++;

commit 2351f431f727223b4d82851ee8fc045bf51edd34
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Sep 27 10:43:13 2017 -0400

    btrfs: fix send ioctl on 32bit with 64bit kernel
    
    We pass in a pointer in our send arg struct, this means the struct size
    doesn't match with 32bit user space and 64bit kernel space.  Fix this by
    adding a compat mode and doing the appropriate conversion.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ move structure to the beginning, next to receive 32bit compat ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 0746eda7231d..d9ddcdbdd2e7 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -26,6 +26,7 @@
 #include <linux/radix-tree.h>
 #include <linux/vmalloc.h>
 #include <linux/string.h>
+#include <linux/compat.h>
 
 #include "send.h"
 #include "backref.h"
@@ -6371,13 +6372,12 @@ static void btrfs_root_dec_send_in_progress(struct btrfs_root* root)
 	spin_unlock(&root->root_item_lock);
 }
 
-long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
+long btrfs_ioctl_send(struct file *mnt_file, struct btrfs_ioctl_send_args *arg)
 {
 	int ret = 0;
 	struct btrfs_root *send_root = BTRFS_I(file_inode(mnt_file))->root;
 	struct btrfs_fs_info *fs_info = send_root->fs_info;
 	struct btrfs_root *clone_root;
-	struct btrfs_ioctl_send_args *arg = NULL;
 	struct btrfs_key key;
 	struct send_ctx *sctx = NULL;
 	u32 i;
@@ -6413,13 +6413,6 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		goto out;
 	}
 
-	arg = memdup_user(arg_, sizeof(*arg));
-	if (IS_ERR(arg)) {
-		ret = PTR_ERR(arg);
-		arg = NULL;
-		goto out;
-	}
-
 	/*
 	 * Check that we don't overflow at later allocations, we request
 	 * clone_sources_count + 1 items, and compare to unsigned long inside
@@ -6660,7 +6653,6 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	if (sctx && !IS_ERR_OR_NULL(sctx->parent_root))
 		btrfs_root_dec_send_in_progress(sctx->parent_root);
 
-	kfree(arg);
 	kvfree(clone_sources_tmp);
 
 	if (sctx) {

commit eef16ba269ea1d55ca1b4eab8d91f02e185835c9
Author: Kuanling Huang <peterh@synology.com>
Date:   Fri Sep 15 16:47:45 2017 +0800

    Btrfs: send, apply asynchronous page cache readahead to enhance page read
    
    By analyzing the perf on btrfs send, we found it take large amount of
    cpu time on page_cache_sync_readahead. This effort can be reduced after
    switching to asynchronous one. Overall performance gain on HDD and SSD
    were 9 and 15 percent if simply send a large file.
    
    Signed-off-by: Kuanling Huang <peterh@synology.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 07445be8c1cc..0746eda7231d 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4720,16 +4720,27 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 	/* initial readahead */
 	memset(&sctx->ra, 0, sizeof(struct file_ra_state));
 	file_ra_state_init(&sctx->ra, inode->i_mapping);
-	page_cache_sync_readahead(inode->i_mapping, &sctx->ra, NULL, index,
-		       last_index - index + 1);
 
 	while (index <= last_index) {
 		unsigned cur_len = min_t(unsigned, len,
 					 PAGE_SIZE - pg_offset);
-		page = find_or_create_page(inode->i_mapping, index, GFP_KERNEL);
+
+		page = find_lock_page(inode->i_mapping, index);
 		if (!page) {
-			ret = -ENOMEM;
-			break;
+			page_cache_sync_readahead(inode->i_mapping, &sctx->ra,
+				NULL, index, last_index + 1 - index);
+
+			page = find_or_create_page(inode->i_mapping, index,
+					GFP_KERNEL);
+			if (!page) {
+				ret = -ENOMEM;
+				break;
+			}
+		}
+
+		if (PageReadahead(page)) {
+			page_cache_async_readahead(inode->i_mapping, &sctx->ra,
+				NULL, page, index, last_index + 1 - index);
 		}
 
 		if (!PageUptodate(page)) {

commit ee8c494f88736c1a1873fdd65559828f9a734bcf
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Aug 21 12:43:45 2017 +0300

    btrfs: Remove unused arguments from btrfs_changed_cb_t
    
    btrfs_changed_cb_t represents the signature of the callback being passed
    to btrfs_compare_trees. Currently there is only one such callback,
    namely changed_cb in send.c. This function doesn't really uses the first
    2 parameters, i.e. the roots. Since there are not other functions
    implementing the btrfs_changed_cb_t let's remove the unused parameters
    from the prototype and implementation.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e4ad2fa82acf..07445be8c1cc 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6159,9 +6159,7 @@ static int compare_refs(struct send_ctx *sctx, struct btrfs_path *path,
  * Updates compare related fields in sctx and simply forwards to the actual
  * changed_xxx functions.
  */
-static int changed_cb(struct btrfs_root *left_root,
-		      struct btrfs_root *right_root,
-		      struct btrfs_path *left_path,
+static int changed_cb(struct btrfs_path *left_path,
 		      struct btrfs_path *right_path,
 		      struct btrfs_key *key,
 		      enum btrfs_compare_tree_result result,
@@ -6243,8 +6241,8 @@ static int full_send_tree(struct send_ctx *sctx)
 		slot = path->slots[0];
 		btrfs_item_key_to_cpu(eb, &found_key, slot);
 
-		ret = changed_cb(send_root, NULL, path, NULL,
-				&found_key, BTRFS_COMPARE_TREE_NEW, sctx);
+		ret = changed_cb(path, NULL, &found_key,
+				 BTRFS_COMPARE_TREE_NEW, sctx);
 		if (ret < 0)
 			goto out;
 

commit a0357511f29f9b83e2c0d12621c339a5900eaa5a
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Aug 21 12:43:44 2017 +0300

    btrfs: Remove unused parameters from various functions
    
    iterate_dir_item:found_key - introduced in 31db9f7c23fb ("Btrfs:
      introduce BTRFS_IOC_SEND for btrfs send/receive"), yet never used.
    
    record_ref:num - ditto
    
    This is a first pass with the low-hanging fruit. There are still quite a
    few unsued parameters in some function which have to abide by a callback
    interface.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 8fd195cfe81b..e4ad2fa82acf 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -992,7 +992,6 @@ typedef int (*iterate_dir_item_t)(int num, struct btrfs_key *di_key,
  * path must point to the dir item when called.
  */
 static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
-			    struct btrfs_key *found_key,
 			    iterate_dir_item_t iterate, void *ctx)
 {
 	int ret = 0;
@@ -4106,8 +4105,8 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 	return ret;
 }
 
-static int record_ref(struct btrfs_root *root, int num, u64 dir, int index,
-		      struct fs_path *name, void *ctx, struct list_head *refs)
+static int record_ref(struct btrfs_root *root, u64 dir, struct fs_path *name,
+		      void *ctx, struct list_head *refs)
 {
 	int ret = 0;
 	struct send_ctx *sctx = ctx;
@@ -4143,8 +4142,7 @@ static int __record_new_ref(int num, u64 dir, int index,
 			    void *ctx)
 {
 	struct send_ctx *sctx = ctx;
-	return record_ref(sctx->send_root, num, dir, index, name,
-			  ctx, &sctx->new_refs);
+	return record_ref(sctx->send_root, dir, name, ctx, &sctx->new_refs);
 }
 
 
@@ -4153,8 +4151,8 @@ static int __record_deleted_ref(int num, u64 dir, int index,
 				void *ctx)
 {
 	struct send_ctx *sctx = ctx;
-	return record_ref(sctx->parent_root, num, dir, index, name,
-			  ctx, &sctx->deleted_refs);
+	return record_ref(sctx->parent_root, dir, name, ctx,
+			  &sctx->deleted_refs);
 }
 
 static int record_new_ref(struct send_ctx *sctx)
@@ -4498,7 +4496,7 @@ static int process_new_xattr(struct send_ctx *sctx)
 	int ret = 0;
 
 	ret = iterate_dir_item(sctx->send_root, sctx->left_path,
-			       sctx->cmp_key, __process_new_xattr, sctx);
+			       __process_new_xattr, sctx);
 
 	return ret;
 }
@@ -4506,7 +4504,7 @@ static int process_new_xattr(struct send_ctx *sctx)
 static int process_deleted_xattr(struct send_ctx *sctx)
 {
 	return iterate_dir_item(sctx->parent_root, sctx->right_path,
-				sctx->cmp_key, __process_deleted_xattr, sctx);
+				__process_deleted_xattr, sctx);
 }
 
 struct find_xattr_ctx {
@@ -4551,7 +4549,7 @@ static int find_xattr(struct btrfs_root *root,
 	ctx.found_data = NULL;
 	ctx.found_data_len = 0;
 
-	ret = iterate_dir_item(root, path, key, __find_xattr, &ctx);
+	ret = iterate_dir_item(root, path, __find_xattr, &ctx);
 	if (ret < 0)
 		return ret;
 
@@ -4621,11 +4619,11 @@ static int process_changed_xattr(struct send_ctx *sctx)
 	int ret = 0;
 
 	ret = iterate_dir_item(sctx->send_root, sctx->left_path,
-			sctx->cmp_key, __process_changed_new_xattr, sctx);
+			__process_changed_new_xattr, sctx);
 	if (ret < 0)
 		goto out;
 	ret = iterate_dir_item(sctx->parent_root, sctx->right_path,
-			sctx->cmp_key, __process_changed_deleted_xattr, sctx);
+			__process_changed_deleted_xattr, sctx);
 
 out:
 	return ret;
@@ -4675,8 +4673,7 @@ static int process_all_new_xattrs(struct send_ctx *sctx)
 			goto out;
 		}
 
-		ret = iterate_dir_item(root, path, &found_key,
-				       __process_new_xattr, sctx);
+		ret = iterate_dir_item(root, path, __process_new_xattr, sctx);
 		if (ret < 0)
 			goto out;
 

commit 5ba88cd6e9a658be0cdcaf4fc0438b7d63d32bf6
Merge: 7b5ef82336e7 8c6c592831a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 29 12:57:35 2017 -0700

    Merge branch 'for-4.14-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "We've collected a bunch of isolated fixes, for crashes, user-visible
      behaviour or missing bits from other subsystem cleanups from the past.
    
      The overall number is not small but I was not able to make it
      significantly smaller. Most of the patches are supposed to go to
      stable"
    
    * 'for-4.14-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      btrfs: log csums for all modified extents
      Btrfs: fix unexpected result when dio reading corrupted blocks
      btrfs: Report error on removing qgroup if del_qgroup_item fails
      Btrfs: skip checksum when reading compressed data if some IO have failed
      Btrfs: fix kernel oops while reading compressed data
      Btrfs: use btrfs_op instead of bio_op in __btrfs_map_block
      Btrfs: do not backup tree roots when fsync
      btrfs: remove BTRFS_FS_QUOTA_DISABLING flag
      btrfs: propagate error to btrfs_cmp_data_prepare caller
      btrfs: prevent to set invalid default subvolid
      Btrfs: send: fix error number for unknown inode types
      btrfs: fix NULL pointer dereference from free_reloc_roots()
      btrfs: finish ordered extent cleaning if no progress is found
      btrfs: clear ordered flag on cleaning up ordered extents
      Btrfs: fix incorrect {node,sector}size endianness from BTRFS_IOC_FS_INFO
      Btrfs: do not reset bio->bi_ops while writing bio
      Btrfs: use the new helper wbc_to_write_flags

commit ca6842bf01dc1ad41195eac1e343b4f08c496ba8
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Fri Jan 22 09:13:25 2016 +0900

    Btrfs: send: fix error number for unknown inode types
    
    ENOTSUPP should not be returned to the user program.
     (cf. include/linux/errno.h)
    Therefore, EOPNOTSUPP is used instead of ENOTSUPP.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 8f1d3d6e7087..43430e6c99aa 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2640,7 +2640,7 @@ static int send_create_inode(struct send_ctx *sctx, u64 ino)
 	} else {
 		btrfs_warn(sctx->send_root->fs_info, "unexpected inode type %o",
 				(int)(mode & S_IFMT));
-		ret = -ENOTSUPP;
+		ret = -EOPNOTSUPP;
 		goto out;
 	}
 

commit 581bfce969cbfc7ce43ee92273be9cb7c3fdfa61
Merge: cc73fee0bae2 9725d4cef622
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 14 18:13:32 2017 -0700

    Merge branch 'work.set_fs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull more set_fs removal from Al Viro:
     "Christoph's 'use kernel_read and friends rather than open-coding
      set_fs()' series"
    
    * 'work.set_fs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      fs: unexport vfs_readv and vfs_writev
      fs: unexport vfs_read and vfs_write
      fs: unexport __vfs_read/__vfs_write
      lustre: switch to kernel_write
      gadget/f_mass_storage: stop messing with the address limit
      mconsole: switch to kernel_read
      btrfs: switch write_buf to kernel_write
      net/9p: switch p9_fd_read to kernel_write
      mm/nommu: switch do_mmap_private to kernel_read
      serial2002: switch serial2002_tty_write to kernel_{read/write}
      fs: make the buf argument to __kernel_write a void pointer
      fs: fix kernel_write prototype
      fs: fix kernel_read prototype
      fs: move kernel_read to fs/read_write.c
      fs: move kernel_write to fs/read_write.c
      autofs4: switch autofs4_write to __kernel_write
      ashmem: switch to ->read_iter

commit 8e93157bdd4a9718ce8e05c370ab9fe48debb4c2
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Sep 1 17:39:19 2017 +0200

    btrfs: switch write_buf to kernel_write
    
    Instead of playing with the addressing limits.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index b082210df9c8..24b989fd130c 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -539,33 +539,23 @@ static struct btrfs_path *alloc_path_for_send(void)
 static int write_buf(struct file *filp, const void *buf, u32 len, loff_t *off)
 {
 	int ret;
-	mm_segment_t old_fs;
 	u32 pos = 0;
 
-	old_fs = get_fs();
-	set_fs(KERNEL_DS);
-
 	while (pos < len) {
-		ret = vfs_write(filp, (__force const char __user *)buf + pos,
-				len - pos, off);
+		ret = kernel_write(filp, buf + pos, len - pos, off);
 		/* TODO handle that correctly */
 		/*if (ret == -ERESTARTSYS) {
 			continue;
 		}*/
 		if (ret < 0)
-			goto out;
+			return ret;
 		if (ret == 0) {
-			ret = -EIO;
-			goto out;
+			return -EIO;
 		}
 		pos += ret;
 	}
 
-	ret = 0;
-
-out:
-	set_fs(old_fs);
-	return ret;
+	return 0;
 }
 
 static int tlv_put(struct send_ctx *sctx, u16 attr, const void *data, int len)

commit 72610b1b40005fa19a107ea62b8bcc0ca84ef11b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Aug 10 22:54:51 2017 +0100

    Btrfs: incremental send, fix emission of invalid clone operations
    
    When doing an incremental send it's possible that the computed send stream
    contains clone operations that will fail on the receiver if the receiver
    has compression enabled and the clone operations target a sector sized
    extent that starts at a zero file offset, is not compressed on the source
    filesystem but ends up being compressed and inlined at the destination
    filesystem.
    
    Example scenario:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount -o compress /dev/sdb /mnt
    
      # By doing a direct IO write, the data is not compressed.
      $ xfs_io -f -d -c "pwrite -S 0xab 0 4K" /mnt/foobar
      $ btrfs subvolume snapshot -r /mnt /mnt/mysnap1
    
      $ xfs_io -c "reflink /mnt/foobar 0 8K 4K" /mnt/foobar
      $ btrfs subvolume snapshot -r /mnt /mnt/mysnap2
    
      $ btrfs send -f /tmp/1.snap /mnt/mysnap1
      $ btrfs send -f /tmp/2.snap -p /mnt/mysnap1 /mnt/mysnap2
      $ umount /mnt
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount -o compress /dev/sdc /mnt
      $ btrfs receive -f /tmp/1.snap /mnt
      $ btrfs receive -f /tmp/2.snap /mnt
      ERROR: failed to clone extents to foobar
      Operation not supported
    
    The same could be achieved by mounting the source filesystem without
    compression and doing a buffered IO write instead of a direct IO one,
    and mounting the destination filesystem with compression enabled.
    
    So fix this by issuing regular write operations in the send stream
    instead of clone operations when the source offset is zero and the
    range has a length matching the sector size.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 59fb1ed6ca20..8f1d3d6e7087 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4992,6 +4992,25 @@ static int clone_range(struct send_ctx *sctx,
 	struct btrfs_key key;
 	int ret;
 
+	/*
+	 * Prevent cloning from a zero offset with a length matching the sector
+	 * size because in some scenarios this will make the receiver fail.
+	 *
+	 * For example, if in the source filesystem the extent at offset 0
+	 * has a length of sectorsize and it was written using direct IO, then
+	 * it can never be an inline extent (even if compression is enabled).
+	 * Then this extent can be cloned in the original filesystem to a non
+	 * zero file offset, but it may not be possible to clone in the
+	 * destination filesystem because it can be inlined due to compression
+	 * on the destination filesystem (as the receiver's write operations are
+	 * always done using buffered IO). The same happens when the original
+	 * filesystem does not have compression enabled but the destination
+	 * filesystem has.
+	 */
+	if (clone_root->offset == 0 &&
+	    len == sctx->send_root->fs_info->sectorsize)
+		return send_extent_data(sctx, offset, len);
+
 	path = alloc_path_for_send();
 	if (!path)
 		return -ENOMEM;

commit d3c0bab5632337f6d3841fbe0dc238a743cb4472
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 22 03:35:28 2017 +0200

    btrfs: remove trivial wrapper btrfs_force_ra
    
    It's a simple call page_cache_sync_readahead, same arguments in the same
    order.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index b082210df9c8..59fb1ed6ca20 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4733,7 +4733,7 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 	/* initial readahead */
 	memset(&sctx->ra, 0, sizeof(struct file_ra_state));
 	file_ra_state_init(&sctx->ra, inode->i_mapping);
-	btrfs_force_ra(inode->i_mapping, &sctx->ra, NULL, index,
+	page_cache_sync_readahead(inode->i_mapping, &sctx->ra, NULL, index,
 		       last_index - index + 1);
 
 	while (index <= last_index) {

commit 24e52b11e0ca788513b945a87b57cc0522a92933
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jul 6 15:31:46 2017 +0100

    Btrfs: incremental send, fix invalid memory access
    
    When doing an incremental send, while processing an extent that changed
    between the parent and send snapshots and that extent was an inline extent
    in the parent snapshot, it's possible to access a memory region beyond
    the end of leaf if the inline extent is very small and it is the first
    item in a leaf.
    
    An example scenario is described below.
    
    The send snapshot has the following leaf:
    
     leaf 33865728 items 33 free space 773 generation 46 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            (...)
            item 14 key (335 EXTENT_DATA 0) itemoff 3052 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 12791808 nr 4096
                    extent data offset 0 nr 4096 ram 4096
                    extent compression 0 (none)
            item 15 key (335 EXTENT_DATA 8192) itemoff 2999 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 138170368 nr 225280
                    extent data offset 0 nr 225280 ram 225280
                    extent compression 0 (none)
            (...)
    
    And the parent snapshot has the following leaf:
    
     leaf 31272960 items 17 free space 17 generation 31 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            item 0 key (335 EXTENT_DATA 0) itemoff 3951 itemsize 44
                    generation 31 type 0 (inline)
                    inline extent data size 23 ram_bytes 613 compression 1 (zlib)
            (...)
    
    When computing the send stream, it is detected that the extent of inode
    335, at file offset 0, and at fs/btrfs/send.c:is_extent_unchanged() we
    grab the leaf from the parent snapshot and access the inline extent item.
    However, before jumping to the 'out' label, we access the 'offset' and
    'disk_bytenr' fields of the extent item, which should not be done for
    inline extents since the inlined data starts at the offset of the
    'disk_bytenr' field and can be very small. For example accessing the
    'offset' field of the file extent item results in the following trace:
    
    [  599.705368] general protection fault: 0000 [#1] PREEMPT SMP
    [  599.706296] Modules linked in: btrfs psmouse i2c_piix4 ppdev acpi_cpufreq serio_raw parport_pc i2c_core evdev tpm_tis tpm_tis_core sg pcspkr parport tpm button su$
    [  599.709340] CPU: 7 PID: 5283 Comm: btrfs Not tainted 4.10.0-rc8-btrfs-next-46+ #1
    [  599.709340] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.1-0-gb3ef39f-prebuilt.qemu-project.org 04/01/2014
    [  599.709340] task: ffff88023eedd040 task.stack: ffffc90006658000
    [  599.709340] RIP: 0010:read_extent_buffer+0xdb/0xf4 [btrfs]
    [  599.709340] RSP: 0018:ffffc9000665ba00 EFLAGS: 00010286
    [  599.709340] RAX: db73880000000000 RBX: 0000000000000000 RCX: 0000000000000001
    [  599.709340] RDX: ffffc9000665ba60 RSI: db73880000000000 RDI: ffffc9000665ba5f
    [  599.709340] RBP: ffffc9000665ba30 R08: 0000000000000001 R09: ffff88020dc5e098
    [  599.709340] R10: 0000000000001000 R11: 0000160000000000 R12: 6db6db6db6db6db7
    [  599.709340] R13: ffff880000000000 R14: 0000000000000000 R15: ffff88020dc5e088
    [  599.709340] FS:  00007f519555a8c0(0000) GS:ffff88023f3c0000(0000) knlGS:0000000000000000
    [  599.709340] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  599.709340] CR2: 00007f1411afd000 CR3: 0000000235f8e000 CR4: 00000000000006e0
    [  599.709340] Call Trace:
    [  599.709340]  btrfs_get_token_64+0x93/0xce [btrfs]
    [  599.709340]  ? printk+0x48/0x50
    [  599.709340]  btrfs_get_64+0xb/0xd [btrfs]
    [  599.709340]  process_extent+0x3a1/0x1106 [btrfs]
    [  599.709340]  ? btree_read_extent_buffer_pages+0x5/0xef [btrfs]
    [  599.709340]  changed_cb+0xb03/0xb3d [btrfs]
    [  599.709340]  ? btrfs_get_token_32+0x7a/0xcc [btrfs]
    [  599.709340]  btrfs_compare_trees+0x432/0x53d [btrfs]
    [  599.709340]  ? process_extent+0x1106/0x1106 [btrfs]
    [  599.709340]  btrfs_ioctl_send+0x960/0xe26 [btrfs]
    [  599.709340]  btrfs_ioctl+0x181b/0x1fed [btrfs]
    [  599.709340]  ? trace_hardirqs_on_caller+0x150/0x1ac
    [  599.709340]  vfs_ioctl+0x21/0x38
    [  599.709340]  ? vfs_ioctl+0x21/0x38
    [  599.709340]  do_vfs_ioctl+0x611/0x645
    [  599.709340]  ? rcu_read_unlock+0x5b/0x5d
    [  599.709340]  ? __fget+0x6d/0x79
    [  599.709340]  SyS_ioctl+0x57/0x7b
    [  599.709340]  entry_SYSCALL_64_fastpath+0x18/0xad
    [  599.709340] RIP: 0033:0x7f51945eec47
    [  599.709340] RSP: 002b:00007ffc21c13e98 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
    [  599.709340] RAX: ffffffffffffffda RBX: ffffffff81096459 RCX: 00007f51945eec47
    [  599.709340] RDX: 00007ffc21c13f20 RSI: 0000000040489426 RDI: 0000000000000004
    [  599.709340] RBP: ffffc9000665bf98 R08: 00007f519450d700 R09: 00007f519450d700
    [  599.709340] R10: 00007f519450d9d0 R11: 0000000000000202 R12: 0000000000000046
    [  599.709340] R13: ffffc9000665bf78 R14: 0000000000000000 R15: 00007f5195574040
    [  599.709340]  ? trace_hardirqs_off_caller+0x43/0xb1
    [  599.709340] Code: 29 f0 49 39 d8 4c 0f 47 c3 49 03 81 58 01 00 00 44 89 c1 4c 01 c2 4c 29 c3 48 c1 f8 03 49 0f af c4 48 c1 e0 0c 4c 01 e8 48 01 c6 <f3> a4 31 f6 4$
    [  599.709340] RIP: read_extent_buffer+0xdb/0xf4 [btrfs] RSP: ffffc9000665ba00
    [  599.762057] ---[ end trace fe00d7af61b9f49e ]---
    
    This is because the 'offset' field starts at an offset of 37 bytes
    (offsetof(struct btrfs_file_extent_item, offset)), has a length of 8
    bytes and therefore attemping to read it causes a 1 byte access beyond
    the end of the leaf, as the first item's content in a leaf is located
    at the tail of the leaf, the item size is 44 bytes and the offset of
    that field plus its length (37 + 8 = 45) goes beyond the item's size
    by 1 byte.
    
    So fix this by accessing the 'offset' and 'disk_bytenr' fields after
    jumping to the 'out' label if we are processing an inline extent. We
    move the reading operation of the 'disk_bytenr' field too because we
    have the same problem as for the 'offset' field explained above when
    the inline data is less then 8 bytes. The access to the 'generation'
    field is also moved but just for the sake of grouping access to all
    the fields.
    
    Fixes: e1cbfd7bf6da ("Btrfs: send, fix file hole not being preserved due to inline extent")
    Cc: <stable@vger.kernel.org>  # v4.12+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 7eaccfb72b47..b082210df9c8 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5270,15 +5270,12 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 			goto out;
 		}
 
-		right_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
 		if (right_type == BTRFS_FILE_EXTENT_INLINE) {
 			right_len = btrfs_file_extent_inline_len(eb, slot, ei);
 			right_len = PAGE_ALIGN(right_len);
 		} else {
 			right_len = btrfs_file_extent_num_bytes(eb, ei);
 		}
-		right_offset = btrfs_file_extent_offset(eb, ei);
-		right_gen = btrfs_file_extent_generation(eb, ei);
 
 		/*
 		 * Are we at extent 8? If yes, we know the extent is changed.
@@ -5303,6 +5300,10 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 			goto out;
 		}
 
+		right_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
+		right_offset = btrfs_file_extent_offset(eb, ei);
+		right_gen = btrfs_file_extent_generation(eb, ei);
+
 		left_offset_fixed = left_offset;
 		if (key.offset < ekey->offset) {
 			/* Fix the right offset for 2a and 7. */

commit f59627810e18d4435051d982b5d05cab18c6e653
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jun 22 20:03:51 2017 +0100

    Btrfs: incremental send, fix invalid path for link commands
    
    In some scenarios an incremental send stream can contain link commands
    with an invalid target path. Such scenarios happen after moving some
    directory inode A, renaming a regular file inode B into the old name of
    inode A and finally creating a new hard link for inode B at directory
    inode A.
    
    Consider the following example scenario where this issue happens.
    
    Parent snapshot:
    
      .                                                      (ino 256)
      |
      |--- dir1/                                             (ino 257)
      |      |--- dir2/                                      (ino 258)
      |             |--- dir3/                               (ino 259)
      |                   |--- file1                         (ino 261)
      |                   |--- dir4/                         (ino 262)
      |
      |--- dir5/                                             (ino 260)
    
    Send snapshot:
    
      .                                                      (ino 256)
      |
      |--- dir1/                                             (ino 257)
             |--- dir2/                                      (ino 258)
             |      |--- dir3/                               (ino 259)
             |            |--- dir4                          (ino 261)
             |
             |--- dir6/                                      (ino 263)
                    |--- dir44/                              (ino 262)
                           |--- file11                       (ino 261)
                           |--- dir55/                       (ino 260)
    
    When attempting to apply the corresponding incremental send stream, a
    link command contains an invalid target path which makes the receiver
    fail. The following is the verbose output of the btrfs receive command:
    
      receiving snapshot mysnap2 uuid=90076fe6-5ba6-e64a-9321-9279670ed16b (...)
      utimes
      utimes dir1
      utimes dir1/dir2/dir3
      utimes
      rename dir1/dir2/dir3/dir4 -> o262-7-0
      link dir1/dir2/dir3/dir4 -> dir1/dir2/dir3/file1
      link dir1/dir2/dir3/dir4/file11 -> dir1/dir2/dir3/file1
      ERROR: link dir1/dir2/dir3/dir4/file11 -> dir1/dir2/dir3/file1 failed: Not a directory
    
    The following steps happen during the computation of the incremental send
    stream the lead to this issue:
    
    1) When processing inode 261, we orphanize inode 262 due to a name/location
       collision with one of the new hard links for inode 261 (created in the
       second step below).
    
    2) We create one of the 2 new hard links for inode 261, the one whose
       location is at "dir1/dir2/dir3/dir4".
    
    3) We then attempt to create the other new hard link for inode 261, which
       has inode 262 as its parent directory. Because the path for this new
       hard link was computed before we started processing the new references
       (hard links), it reflects the old name/location of inode 262, that is,
       it does not account for the orphanization step that happened when
       we started processing the new references for inode 261, whence it is
       no longer valid, causing the receiver to fail.
    
    So fix this issue by recomputing the full path of new references if we
    ended up orphanizing other inodes which are directories.
    
    A test case for fstests follows soon.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e937c10b8287..7eaccfb72b47 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1856,7 +1856,7 @@ static int is_first_ref(struct btrfs_root *root,
  */
 static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 			      const char *name, int name_len,
-			      u64 *who_ino, u64 *who_gen)
+			      u64 *who_ino, u64 *who_gen, u64 *who_mode)
 {
 	int ret = 0;
 	u64 gen;
@@ -1905,7 +1905,7 @@ static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 	if (other_inode > sctx->send_progress ||
 	    is_waiting_for_move(sctx, other_inode)) {
 		ret = get_inode_info(sctx->parent_root, other_inode, NULL,
-				who_gen, NULL, NULL, NULL, NULL);
+				who_gen, who_mode, NULL, NULL, NULL);
 		if (ret < 0)
 			goto out;
 
@@ -3683,6 +3683,36 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 	return ret;
 }
 
+static int update_ref_path(struct send_ctx *sctx, struct recorded_ref *ref)
+{
+	int ret;
+	struct fs_path *new_path;
+
+	/*
+	 * Our reference's name member points to its full_path member string, so
+	 * we use here a new path.
+	 */
+	new_path = fs_path_alloc();
+	if (!new_path)
+		return -ENOMEM;
+
+	ret = get_cur_path(sctx, ref->dir, ref->dir_gen, new_path);
+	if (ret < 0) {
+		fs_path_free(new_path);
+		return ret;
+	}
+	ret = fs_path_add(new_path, ref->name, ref->name_len);
+	if (ret < 0) {
+		fs_path_free(new_path);
+		return ret;
+	}
+
+	fs_path_free(ref->full_path);
+	set_ref_path(ref, new_path);
+
+	return 0;
+}
+
 /*
  * This does all the move/link/unlink/rmdir magic.
  */
@@ -3696,10 +3726,12 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 	struct fs_path *valid_path = NULL;
 	u64 ow_inode = 0;
 	u64 ow_gen;
+	u64 ow_mode;
 	int did_overwrite = 0;
 	int is_orphan = 0;
 	u64 last_dir_ino_rm = 0;
 	bool can_rename = true;
+	bool orphanized_dir = false;
 	bool orphanized_ancestor = false;
 
 	btrfs_debug(fs_info, "process_recorded_refs %llu", sctx->cur_ino);
@@ -3798,7 +3830,7 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 		 */
 		ret = will_overwrite_ref(sctx, cur->dir, cur->dir_gen,
 				cur->name, cur->name_len,
-				&ow_inode, &ow_gen);
+				&ow_inode, &ow_gen, &ow_mode);
 		if (ret < 0)
 			goto out;
 		if (ret) {
@@ -3815,6 +3847,8 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 						cur->full_path);
 				if (ret < 0)
 					goto out;
+				if (S_ISDIR(ow_mode))
+					orphanized_dir = true;
 
 				/*
 				 * If ow_inode has its rename operation delayed
@@ -3920,6 +3954,18 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 				if (ret < 0)
 					goto out;
 			} else {
+				/*
+				 * We might have previously orphanized an inode
+				 * which is an ancestor of our current inode,
+				 * so our reference's full path, which was
+				 * computed before any such orphanizations, must
+				 * be updated.
+				 */
+				if (orphanized_dir) {
+					ret = update_ref_path(sctx, cur);
+					if (ret < 0)
+						goto out;
+				}
 				ret = send_link(sctx, cur->full_path,
 						valid_path);
 				if (ret < 0)
@@ -3990,34 +4036,9 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 				 * ancestor inode.
 				 */
 				if (orphanized_ancestor) {
-					struct fs_path *new_path;
-
-					/*
-					 * Our reference's name member points to
-					 * its full_path member string, so we
-					 * use here a new path.
-					 */
-					new_path = fs_path_alloc();
-					if (!new_path) {
-						ret = -ENOMEM;
-						goto out;
-					}
-					ret = get_cur_path(sctx, cur->dir,
-							   cur->dir_gen,
-							   new_path);
-					if (ret < 0) {
-						fs_path_free(new_path);
-						goto out;
-					}
-					ret = fs_path_add(new_path,
-							  cur->name,
-							  cur->name_len);
-					if (ret < 0) {
-						fs_path_free(new_path);
+					ret = update_ref_path(sctx, cur);
+					if (ret < 0)
 						goto out;
-					}
-					fs_path_free(cur->full_path);
-					set_ref_path(cur, new_path);
 				}
 				ret = send_unlink(sctx, cur->full_path);
 				if (ret < 0)

commit 59b0a7f2c7c1bf374db319fcc2c99305133d00d5
Author: Su Yue <suy.fnst@cn.fujitsu.com>
Date:   Tue Jun 6 17:57:05 2017 +0800

    btrfs: Check name_len before read in iterate_dir_item
    
    Since iterate_dir_item checks name_len in its own way,
    so use btrfs_is_name_len_valid not 'verify_dir_item' to make more strict
    name_len check.
    
    Signed-off-by: Su Yue <suy.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ switched ENAMETOOLONG to EIO ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a562dc228794..e937c10b8287 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1069,6 +1069,12 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 			}
 		}
 
+		ret = btrfs_is_name_len_valid(eb, path->slots[0],
+			  (unsigned long)(di + 1), name_len + data_len);
+		if (!ret) {
+			ret = -EIO;
+			goto out;
+		}
 		if (name_len + data_len > buf_len) {
 			buf_len = name_len + data_len;
 			if (is_vmalloc_addr(buf)) {

commit fdb1388994e2ed0e1512006244022c721c650c5b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Jun 13 14:13:11 2017 +0100

    Btrfs: incremental send, fix invalid path for unlink commands
    
    An incremental send can contain unlink operations with an invalid target
    path when we rename some directory inode A, then rename some file inode B
    to the old name of inode A and directory inode A is an ancestor of inode B
    in the parent snapshot (but not anymore in the send snapshot).
    
    Consider the following example scenario where this issue happens.
    
    Parent snapshot:
    
     .                                                      (ino 256)
     |
     |--- dir1/                                             (ino 257)
           |--- dir2/                                       (ino 258)
           |     |--- file1                                 (ino 259)
           |     |--- file3                                 (ino 261)
           |
           |--- dir3/                                       (ino 262)
                 |--- file22                                (ino 260)
                 |--- dir4/                                 (ino 263)
    
    Send snapshot:
    
     .                                                      (ino 256)
     |
     |--- dir1/                                             (ino 257)
           |--- dir2/                                       (ino 258)
           |--- dir3                                        (ino 260)
           |--- file3/                                      (ino 262)
                 |--- dir4/                                 (ino 263)
                       |--- file11                          (ino 269)
                       |--- file33                          (ino 261)
    
    When attempting to apply the corresponding incremental send stream, an
    unlink operation contains an invalid path which makes the receiver fail.
    The following is verbose output of the btrfs receive command:
    
     receiving snapshot snap2 uuid=7d5450da-a573-e043-a451-ec85f4879f0f (...)
     utimes
     utimes dir1
     utimes dir1/dir2
     link dir1/dir3/dir4/file11 -> dir1/dir2/file1
     unlink dir1/dir2/file1
     utimes dir1/dir2
     truncate dir1/dir3/dir4/file11 size=0
     utimes dir1/dir3/dir4/file11
     rename dir1/dir3 -> o262-7-0
     link dir1/dir3 -> o262-7-0/file22
     unlink dir1/dir3/file22
     ERROR: unlink dir1/dir3/file22 failed. Not a directory
    
    The following steps happen during the computation of the incremental send
    stream the lead to this issue:
    
    1) Before we start processing the new and deleted references for inode
       260, we compute the full path of the deleted reference
       ("dir1/dir3/file22") and cache it in the list of deleted references
       for our inode.
    
    2) We then start processing the new references for inode 260, for which
       there is only one new, located at "dir1/dir3". When processing this
       new reference, we check that inode 262, which was not yet processed,
       collides with the new reference and because of that we orphanize
       inode 262 so its new full path becomes "o262-7-0".
    
    3) After the orphanization of inode 262, we create the new reference for
       inode 260 by issuing a link command with a target path of "dir1/dir3"
       and a source path of "o262-7-0/file22".
    
    4) We then start processing the deleted references for inode 260, for
       which there is only one with the base name of "file22", and issue
       an unlink operation containing the target path computed at step 1,
       which is wrong because that path no longer exists and should be
       replaced with "o262-7-0/file22".
    
    So fix this issue by recomputing the full path of deleted references if
    when we processed the new references for an inode we ended up orphanizing
    any other inode that is an ancestor of our inode in the parent snapshot.
    
    A test case for fstests follows soon.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    [ adjusted after prev patch removed fs_path::dir_path and dir_path_len ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ddd2b786f4d5..a562dc228794 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2776,6 +2776,13 @@ struct recorded_ref {
 	int name_len;
 };
 
+static void set_ref_path(struct recorded_ref *ref, struct fs_path *path)
+{
+	ref->full_path = path;
+	ref->name = (char *)kbasename(ref->full_path->start);
+	ref->name_len = ref->full_path->end - ref->name;
+}
+
 /*
  * We need to process new refs before deleted refs, but compare_tree gives us
  * everything mixed. So we first record all refs and later process them.
@@ -2792,11 +2799,7 @@ static int __record_ref(struct list_head *head, u64 dir,
 
 	ref->dir = dir;
 	ref->dir_gen = dir_gen;
-	ref->full_path = path;
-
-	ref->name = (char *)kbasename(ref->full_path->start);
-	ref->name_len = ref->full_path->end - ref->name;
-
+	set_ref_path(ref, path);
 	list_add_tail(&ref->list, head);
 	return 0;
 }
@@ -3691,6 +3694,7 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 	int is_orphan = 0;
 	u64 last_dir_ino_rm = 0;
 	bool can_rename = true;
+	bool orphanized_ancestor = false;
 
 	btrfs_debug(fs_info, "process_recorded_refs %llu", sctx->cur_ino);
 
@@ -3846,6 +3850,7 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 						  ow_inode, ow_gen,
 						  sctx->cur_ino, NULL);
 				if (ret > 0) {
+					orphanized_ancestor = true;
 					fs_path_reset(valid_path);
 					ret = get_cur_path(sctx, sctx->cur_ino,
 							   sctx->cur_inode_gen,
@@ -3971,6 +3976,43 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 			if (ret < 0)
 				goto out;
 			if (!ret) {
+				/*
+				 * If we orphanized any ancestor before, we need
+				 * to recompute the full path for deleted names,
+				 * since any such path was computed before we
+				 * processed any references and orphanized any
+				 * ancestor inode.
+				 */
+				if (orphanized_ancestor) {
+					struct fs_path *new_path;
+
+					/*
+					 * Our reference's name member points to
+					 * its full_path member string, so we
+					 * use here a new path.
+					 */
+					new_path = fs_path_alloc();
+					if (!new_path) {
+						ret = -ENOMEM;
+						goto out;
+					}
+					ret = get_cur_path(sctx, cur->dir,
+							   cur->dir_gen,
+							   new_path);
+					if (ret < 0) {
+						fs_path_free(new_path);
+						goto out;
+					}
+					ret = fs_path_add(new_path,
+							  cur->name,
+							  cur->name_len);
+					if (ret < 0) {
+						fs_path_free(new_path);
+						goto out;
+					}
+					fs_path_free(cur->full_path);
+					set_ref_path(cur, new_path);
+				}
 				ret = send_unlink(sctx, cur->full_path);
 				if (ret < 0)
 					goto out;

commit 72c3668fed2b3eec7c6fc059e7b54855361e3011
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Jun 7 11:41:29 2017 +0100

    Btrfs: send, fix invalid path after renaming and linking file
    
    Currently an incremental snapshot can generate link operations which
    contain an invalid target path. Such case happens when in the send
    snapshot a file was renamed, a new hard link added for it and some
    other inode (with a lower number) got renamed to the former name of
    that file. Example:
    
    Parent snapshot
    
     .                  (ino 256)
     |
     |--- f1            (ino 257)
     |--- f2            (ino 258)
     |--- f3            (ino 259)
    
    Send snapshot
    
     .                  (ino 256)
     |
     |--- f2            (ino 257)
     |--- f3            (ino 258)
     |--- f4            (ino 259)
     |--- f5            (ino 258)
    
    The following steps happen when computing the incremental send stream:
    
    1) When processing inode 257, inode 258 is orphanized (renamed to
       "o258-7-0"), because its current reference has the same name as the
       new reference for inode 257;
    
    2) When processing inode 258, we iterate over all its new references,
       which have the names "f3" and "f5". The first iteration sees name
       "f5" and renames the inode from its orphan name ("o258-7-0") to
       "f5", while the second iteration sees the name "f3" and, incorrectly,
       issues a link operation with a target name matching the orphan name,
       which no longer exists. The first iteration had reset the current
       valid path of the inode to "f5", but in the second iteration we lost
       it because we found another inode, with a higher number of 259, which
       has a reference named "f3" as well, so we orphanized inode 259 and
       recomputed the current valid path of inode 258 to its old orphan
       name because inode 259 could be an ancestor of inode 258 and therefore
       the current valid path could contain the pre-orphanization name of
       inode 259. However in this case inode 259 is not an ancestor of inode
       258 so the current valid path should not be recomputed.
       This makes the receiver fail with the following error:
    
       ERROR: link f3 -> o258-7-0 failed: No such file or directory
    
    So fix this by not recomputing the current valid path for an inode
    whenever we find a colliding reference from some not yet processed inode
    (inode number higher then the one currently being processed), unless
    that other inode is an ancestor of the one we are currently processing.
    
    A test case for fstests will follow soon.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 7416b17c0eac..ddd2b786f4d5 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3538,9 +3538,17 @@ static int is_ancestor(struct btrfs_root *root,
 		       struct fs_path *fs_path)
 {
 	u64 ino = ino2;
+	bool free_path = false;
+	int ret = 0;
+
+	if (!fs_path) {
+		fs_path = fs_path_alloc();
+		if (!fs_path)
+			return -ENOMEM;
+		free_path = true;
+	}
 
 	while (ino > BTRFS_FIRST_FREE_OBJECTID) {
-		int ret;
 		u64 parent;
 		u64 parent_gen;
 
@@ -3549,13 +3557,18 @@ static int is_ancestor(struct btrfs_root *root,
 		if (ret < 0) {
 			if (ret == -ENOENT && ino == ino2)
 				ret = 0;
-			return ret;
+			goto out;
+		}
+		if (parent == ino1) {
+			ret = parent_gen == ino1_gen ? 1 : 0;
+			goto out;
 		}
-		if (parent == ino1)
-			return parent_gen == ino1_gen ? 1 : 0;
 		ino = parent;
 	}
-	return 0;
+ out:
+	if (free_path)
+		fs_path_free(fs_path);
+	return ret;
 }
 
 static int wait_for_parent_move(struct send_ctx *sctx,
@@ -3829,9 +3842,15 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 				 * might contain the pre-orphanization name of
 				 * ow_inode, which is no longer valid.
 				 */
-				fs_path_reset(valid_path);
-				ret = get_cur_path(sctx, sctx->cur_ino,
-					   sctx->cur_inode_gen, valid_path);
+				ret = is_ancestor(sctx->parent_root,
+						  ow_inode, ow_gen,
+						  sctx->cur_ino, NULL);
+				if (ret > 0) {
+					fs_path_reset(valid_path);
+					ret = get_cur_path(sctx, sctx->cur_ino,
+							   sctx->cur_inode_gen,
+							   valid_path);
+				}
 				if (ret < 0)
 					goto out;
 			} else {

commit f11f74416ae6e63a6d6db9c5b22666a0aa57b881
Author: David Sterba <dsterba@suse.com>
Date:   Wed May 31 18:40:02 2017 +0200

    btrfs: send: use kvmalloc in iterate_dir_item
    
    We use a growing buffer for xattrs larger than a page size, at some
    point vmalloc is unconditionally used for larger buffers. We can still
    try to avoid it using the kvmalloc helper.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 924b1d941b53..7416b17c0eac 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1083,7 +1083,7 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 				buf = tmp;
 			}
 			if (!buf) {
-				buf = vmalloc(buf_len);
+				buf = kvmalloc(buf_len, GFP_KERNEL);
 				if (!buf) {
 					ret = -ENOMEM;
 					goto out;

commit 818e010bf9d02b144569898506995bcff8918875
Author: David Sterba <dsterba@suse.com>
Date:   Wed May 31 18:40:02 2017 +0200

    btrfs: replace opencoded kvzalloc with the helper
    
    The logic of kmalloc and vmalloc fallback is opencoded in
    several places, we can now use the existing helper.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e8185c83f667..924b1d941b53 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6389,13 +6389,10 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 
 	alloc_size = sizeof(struct clone_root) * (arg->clone_sources_count + 1);
 
-	sctx->clone_roots = kzalloc(alloc_size, GFP_KERNEL | __GFP_NOWARN);
+	sctx->clone_roots = kzalloc(alloc_size, GFP_KERNEL);
 	if (!sctx->clone_roots) {
-		sctx->clone_roots = vzalloc(alloc_size);
-		if (!sctx->clone_roots) {
-			ret = -ENOMEM;
-			goto out;
-		}
+		ret = -ENOMEM;
+		goto out;
 	}
 
 	alloc_size = arg->clone_sources_count * sizeof(*arg->clone_sources);

commit ee4ea69852409d9e102d4d61020c9a7370146edf
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 13 19:11:04 2017 +0200

    btrfs: remove unused members dir_path from recorded_ref
    
    The two members do not seem to be used since the initial commit.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index fc496a6f842a..e8185c83f667 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2769,12 +2769,10 @@ static int send_create_inode_if_needed(struct send_ctx *sctx)
 
 struct recorded_ref {
 	struct list_head list;
-	char *dir_path;
 	char *name;
 	struct fs_path *full_path;
 	u64 dir;
 	u64 dir_gen;
-	int dir_path_len;
 	int name_len;
 };
 
@@ -2798,12 +2796,6 @@ static int __record_ref(struct list_head *head, u64 dir,
 
 	ref->name = (char *)kbasename(ref->full_path->start);
 	ref->name_len = ref->full_path->end - ref->name;
-	ref->dir_path = ref->full_path->start;
-	if (ref->name == ref->full_path->start)
-		ref->dir_path_len = 0;
-	else
-		ref->dir_path_len = ref->full_path->end -
-				ref->full_path->start - 1 - ref->name_len;
 
 	list_add_tail(&ref->list, head);
 	return 0;

commit 1176032cb12bb89ad558a3e57e82f2f25b817eff
Merge: 56868a460b83 9bcaaea7418d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 10 08:33:17 2017 -0700

    Merge branch 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This has fixes and cleanups Dave Sterba collected for the merge
      window.
    
      The biggest functional fixes are between btrfs raid5/6 and scrub, and
      raid5/6 and device replacement. Some of our pending qgroup fixes are
      included as well while I bash on the rest in testing.
    
      We also have the usual set of cleanups, including one that makes
      __btrfs_map_block() much more maintainable, and conversions from
      atomic_t to refcount_t"
    
    * 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (71 commits)
      btrfs: fix the gfp_mask for the reada_zones radix tree
      Btrfs: fix reported number of inode blocks
      Btrfs: send, fix file hole not being preserved due to inline extent
      Btrfs: fix extent map leak during fallocate error path
      Btrfs: fix incorrect space accounting after failure to insert inline extent
      Btrfs: fix invalid attempt to free reserved space on failure to cow range
      btrfs: Handle delalloc error correctly to avoid ordered extent hang
      btrfs: Fix metadata underflow caused by btrfs_reloc_clone_csum error
      btrfs: check if the device is flush capable
      btrfs: delete unused member nobarriers
      btrfs: scrub: Fix RAID56 recovery race condition
      btrfs: scrub: Introduce full stripe lock for RAID56
      btrfs: Use ktime_get_real_ts for root ctime
      Btrfs: handle only applicable errors returned by btrfs_get_extent
      btrfs: qgroup: Fix qgroup corruption caused by inode_cache mount option
      btrfs: use q which is already obtained from bdev_get_queue
      Btrfs: switch to div64_u64 if with a u64 divisor
      Btrfs: update scrub_parity to use u64 stripe_len
      Btrfs: enable repair during read for raid56 profile
      btrfs: use clear_page where appropriate
      ...

commit 752ade68cbd81d0321dfecc188f655a945551b25
Author: Michal Hocko <mhocko@suse.com>
Date:   Mon May 8 15:57:27 2017 -0700

    treewide: use kv[mz]alloc* rather than opencoded variants
    
    There are many code paths opencoding kvmalloc.  Let's use the helper
    instead.  The main difference to kvmalloc is that those users are
    usually not considering all the aspects of the memory allocator.  E.g.
    allocation requests <= 32kB (with 4kB pages) are basically never failing
    and invoke OOM killer to satisfy the allocation.  This sounds too
    disruptive for something that has a reasonable fallback - the vmalloc.
    On the other hand those requests might fallback to vmalloc even when the
    memory allocator would succeed after several more reclaim/compaction
    attempts previously.  There is no guarantee something like that happens
    though.
    
    This patch converts many of those places to kv[mz]alloc* helpers because
    they are more conservative.
    
    Link: http://lkml.kernel.org/r/20170306103327.2766-2-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com> # Xen bits
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Andreas Dilger <andreas.dilger@intel.com> # Lustre
    Acked-by: Christian Borntraeger <borntraeger@de.ibm.com> # KVM/s390
    Acked-by: Dan Williams <dan.j.williams@intel.com> # nvdim
    Acked-by: David Sterba <dsterba@suse.com> # btrfs
    Acked-by: Ilya Dryomov <idryomov@gmail.com> # Ceph
    Acked-by: Tariq Toukan <tariqt@mellanox.com> # mlx4
    Acked-by: Leon Romanovsky <leonro@mellanox.com> # mlx5
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Anton Vorontsov <anton@enomsg.org>
    Cc: Colin Cross <ccross@android.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Ben Skeggs <bskeggs@redhat.com>
    Cc: Kent Overstreet <kent.overstreet@gmail.com>
    Cc: Santosh Raspatur <santosh@chelsio.com>
    Cc: Hariprasad S <hariprasad@chelsio.com>
    Cc: Yishai Hadas <yishaih@mellanox.com>
    Cc: Oleg Drokin <oleg.drokin@intel.com>
    Cc: "Yan, Zheng" <zyan@redhat.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: David Miller <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a60d5bfb8a49..3f645cd67b54 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6360,22 +6360,16 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	sctx->clone_roots_cnt = arg->clone_sources_count;
 
 	sctx->send_max_size = BTRFS_SEND_BUF_SIZE;
-	sctx->send_buf = kmalloc(sctx->send_max_size, GFP_KERNEL | __GFP_NOWARN);
+	sctx->send_buf = kvmalloc(sctx->send_max_size, GFP_KERNEL);
 	if (!sctx->send_buf) {
-		sctx->send_buf = vmalloc(sctx->send_max_size);
-		if (!sctx->send_buf) {
-			ret = -ENOMEM;
-			goto out;
-		}
+		ret = -ENOMEM;
+		goto out;
 	}
 
-	sctx->read_buf = kmalloc(BTRFS_SEND_READ_SIZE, GFP_KERNEL | __GFP_NOWARN);
+	sctx->read_buf = kvmalloc(BTRFS_SEND_READ_SIZE, GFP_KERNEL);
 	if (!sctx->read_buf) {
-		sctx->read_buf = vmalloc(BTRFS_SEND_READ_SIZE);
-		if (!sctx->read_buf) {
-			ret = -ENOMEM;
-			goto out;
-		}
+		ret = -ENOMEM;
+		goto out;
 	}
 
 	sctx->pending_dir_moves = RB_ROOT;
@@ -6396,13 +6390,10 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	alloc_size = arg->clone_sources_count * sizeof(*arg->clone_sources);
 
 	if (arg->clone_sources_count) {
-		clone_sources_tmp = kmalloc(alloc_size, GFP_KERNEL | __GFP_NOWARN);
+		clone_sources_tmp = kvmalloc(alloc_size, GFP_KERNEL);
 		if (!clone_sources_tmp) {
-			clone_sources_tmp = vmalloc(alloc_size);
-			if (!clone_sources_tmp) {
-				ret = -ENOMEM;
-				goto out;
-			}
+			ret = -ENOMEM;
+			goto out;
 		}
 
 		ret = copy_from_user(clone_sources_tmp, arg->clone_sources,

commit e1cbfd7bf6dabdac561c75d08357571f44040a45
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Apr 4 20:31:00 2017 +0100

    Btrfs: send, fix file hole not being preserved due to inline extent
    
    Normally we don't have inline extents followed by regular extents, but
    there's currently at least one harmless case where this happens. For
    example, when the page size is 4Kb and compression is enabled:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount -o compress /dev/sdb /mnt
      $ xfs_io -f -c "pwrite -S 0xaa 0 4K" -c "fsync" /mnt/foobar
      $ xfs_io -c "pwrite -S 0xbb 8K 4K" -c "fsync" /mnt/foobar
    
    In this case we get a compressed inline extent, representing 4Kb of
    data, followed by a hole extent and then a regular data extent. The
    inline extent was not expanded/converted to a regular extent exactly
    because it represents 4Kb of data. This does not cause any apparent
    problem (such as the issue solved by commit e1699d2d7bf6
    ("btrfs: add missing memset while reading compressed inline extents"))
    except trigger an unexpected case in the incremental send code path
    that makes us issue an operation to write a hole when it's not needed,
    resulting in more writes at the receiver and wasting space at the
    receiver.
    
    So teach the incremental send code to deal with this particular case.
    
    The issue can be currently triggered by running fstests btrfs/137 with
    compression enabled (MOUNT_OPTIONS="-o compress" ./check btrfs/137).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a60d5bfb8a49..5b40d617bb03 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5184,13 +5184,19 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 	while (key.offset < ekey->offset + left_len) {
 		ei = btrfs_item_ptr(eb, slot, struct btrfs_file_extent_item);
 		right_type = btrfs_file_extent_type(eb, ei);
-		if (right_type != BTRFS_FILE_EXTENT_REG) {
+		if (right_type != BTRFS_FILE_EXTENT_REG &&
+		    right_type != BTRFS_FILE_EXTENT_INLINE) {
 			ret = 0;
 			goto out;
 		}
 
 		right_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
-		right_len = btrfs_file_extent_num_bytes(eb, ei);
+		if (right_type == BTRFS_FILE_EXTENT_INLINE) {
+			right_len = btrfs_file_extent_inline_len(eb, slot, ei);
+			right_len = PAGE_ALIGN(right_len);
+		} else {
+			right_len = btrfs_file_extent_num_bytes(eb, ei);
+		}
 		right_offset = btrfs_file_extent_offset(eb, ei);
 		right_gen = btrfs_file_extent_generation(eb, ei);
 
@@ -5204,6 +5210,19 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 			goto out;
 		}
 
+		/*
+		 * We just wanted to see if when we have an inline extent, what
+		 * follows it is a regular extent (wanted to check the above
+		 * condition for inline extents too). This should normally not
+		 * happen but it's possible for example when we have an inline
+		 * compressed extent representing data with a size matching
+		 * the page size (currently the same as sector size).
+		 */
+		if (right_type == BTRFS_FILE_EXTENT_INLINE) {
+			ret = 0;
+			goto out;
+		}
+
 		left_offset_fixed = left_offset;
 		if (key.offset < ekey->offset) {
 			/* Fix the right offset for 2a and 7. */

commit 457ae7268b29c33dee1c0feb143a15f6029d177b
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Fri Mar 17 23:51:20 2017 +0300

    Btrfs: fix an integer overflow check
    
    This isn't super serious because you need CAP_ADMIN to run this code.
    
    I added this integer overflow check last year but apparently I am
    rubbish at writing integer overflow checks...  There are two issues.
    First, access_ok() works on unsigned long type and not u64 so on 32 bit
    systems the access_ok() could be checking a truncated size.  The other
    issue is that we should be using a stricter limit so we don't overflow
    the kzalloc() setting ctx->clone_roots later in the function after the
    access_ok():
    
            alloc_size = sizeof(struct clone_root) * (arg->clone_sources_count + 1);
            sctx->clone_roots = kzalloc(alloc_size, GFP_KERNEL | __GFP_NOWARN);
    
    Fixes: f5ecec3ce21f ("btrfs: send: silence an integer overflow warning")
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ added comment ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 456c8901489b..a60d5bfb8a49 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6305,8 +6305,13 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		goto out;
 	}
 
+	/*
+	 * Check that we don't overflow at later allocations, we request
+	 * clone_sources_count + 1 items, and compare to unsigned long inside
+	 * access_ok.
+	 */
 	if (arg->clone_sources_count >
-	    ULLONG_MAX / sizeof(*arg->clone_sources)) {
+	    ULONG_MAX / sizeof(struct clone_root) - 1) {
 		ret = -EINVAL;
 		goto out;
 	}

commit 82bfb2e7b645c8f228dc3b6d3b27b0b10125ca4f
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Feb 14 17:56:32 2017 +0000

    Btrfs: incremental send, fix unnecessary hole writes for sparse files
    
    When using the NO_HOLES feature, during an incremental send we often issue
    write operations for holes when we should not, because that range is already
    a hole in the destination snapshot. While that does not change the contents
    of the file at the receiver, it avoids preservation of file holes, leading
    to wasted disk space and extra IO during send/receive.
    
    A couple examples where the holes are not preserved follows.
    
     $ mkfs.btrfs -O no-holes -f /dev/sdb
     $ mount /dev/sdb /mnt
     $ xfs_io -f -c "pwrite -S 0xaa 0 4K" /mnt/foo
     $ xfs_io -f -c "pwrite -S 0xaa 0 4K" -c "pwrite -S 0xbb 1028K 4K" /mnt/bar
     $ btrfs subvolume snapshot -r /mnt /mnt/snap1
    
     # Now add one new extent to our first test file, increasing its size and
     # leaving a 1Mb hole between the first extent and this new extent.
     $ xfs_io -c "pwrite -S 0xbb 1028K 4K" /mnt/foo
    
     # Now overwrite the last extent of our second test file.
     $ xfs_io -c "pwrite -S 0xcc 1028K 4K" /mnt/bar
    
     $ btrfs subvolume snapshot -r /mnt /mnt/snap2
    
     $ xfs_io -r -c "fiemap -v" /mnt/snap2/foo
     /mnt/snap2/foo:
     EXT: FILE-OFFSET      BLOCK-RANGE      TOTAL FLAGS
       0: [0..7]:          25088..25095         8 0x2000
       1: [8..2055]:       hole              2048
       2: [2056..2063]:    24576..24583         8 0x2001
    
     $ xfs_io -r -c "fiemap -v" /mnt/snap2/bar
     /mnt/snap2/bar:
     EXT: FILE-OFFSET      BLOCK-RANGE      TOTAL FLAGS
       0: [0..7]:          25096..25103         8 0x2000
       1: [8..2055]:       hole              2048
       2: [2056..2063]:    24584..24591         8 0x2001
    
      $ btrfs send /mnt/snap1 -f /tmp/1.snap
      $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/2.snap
    
      $ umount /mnt
      # It's not relevant to enable no-holes in the new filesystem.
      $ mkfs.btrfs -O no-holes -f /dev/sdc
      $ mount /dev/sdc /mnt
      $ btrfs receive /mnt -f /tmp/1.snap
      $ btrfs receive /mnt -f /tmp/2.snap
    
      $ xfs_io -r -c "fiemap -v" /mnt/snap2/foo
      /mnt/snap2/foo:
      EXT: FILE-OFFSET      BLOCK-RANGE      TOTAL FLAGS
        0: [0..7]:          24576..24583         8 0x2000
        1: [8..2063]:       25624..27679      2056   0x1
    
      $ xfs_io -r -c "fiemap -v" /mnt/snap2/bar
      /mnt/snap2/bar:
      EXT: FILE-OFFSET      BLOCK-RANGE      TOTAL FLAGS
        0: [0..7]:          24584..24591         8 0x2000
        1: [8..2063]:       27680..29735      2056   0x1
    
    The holes do not exist in the second filesystem and they were replaced
    with extents filled with the byte 0x00, making each file take 1032Kb of
    space instead of 8Kb.
    
    So fix this by not issuing the write operations consisting of buffers
    filled with the byte 0x00 when the destination snapshot already has a
    hole for the respective range.
    
    A test case for fstests will follow soon.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 712922ea64d2..456c8901489b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5306,6 +5306,81 @@ static int get_last_extent(struct send_ctx *sctx, u64 offset)
 	return ret;
 }
 
+static int range_is_hole_in_parent(struct send_ctx *sctx,
+				   const u64 start,
+				   const u64 end)
+{
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	struct btrfs_root *root = sctx->parent_root;
+	u64 search_start = start;
+	int ret;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	key.objectid = sctx->cur_ino;
+	key.type = BTRFS_EXTENT_DATA_KEY;
+	key.offset = search_start;
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
+	if (ret > 0 && path->slots[0] > 0)
+		path->slots[0]--;
+
+	while (search_start < end) {
+		struct extent_buffer *leaf = path->nodes[0];
+		int slot = path->slots[0];
+		struct btrfs_file_extent_item *fi;
+		u64 extent_end;
+
+		if (slot >= btrfs_header_nritems(leaf)) {
+			ret = btrfs_next_leaf(root, path);
+			if (ret < 0)
+				goto out;
+			else if (ret > 0)
+				break;
+			continue;
+		}
+
+		btrfs_item_key_to_cpu(leaf, &key, slot);
+		if (key.objectid < sctx->cur_ino ||
+		    key.type < BTRFS_EXTENT_DATA_KEY)
+			goto next;
+		if (key.objectid > sctx->cur_ino ||
+		    key.type > BTRFS_EXTENT_DATA_KEY ||
+		    key.offset >= end)
+			break;
+
+		fi = btrfs_item_ptr(leaf, slot, struct btrfs_file_extent_item);
+		if (btrfs_file_extent_type(leaf, fi) ==
+		    BTRFS_FILE_EXTENT_INLINE) {
+			u64 size = btrfs_file_extent_inline_len(leaf, slot, fi);
+
+			extent_end = ALIGN(key.offset + size,
+					   root->fs_info->sectorsize);
+		} else {
+			extent_end = key.offset +
+				btrfs_file_extent_num_bytes(leaf, fi);
+		}
+		if (extent_end <= start)
+			goto next;
+		if (btrfs_file_extent_disk_bytenr(leaf, fi) == 0) {
+			search_start = extent_end;
+			goto next;
+		}
+		ret = 0;
+		goto out;
+next:
+		path->slots[0]++;
+	}
+	ret = 1;
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
 static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
 			   struct btrfs_key *key)
 {
@@ -5350,8 +5425,17 @@ static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
 			return ret;
 	}
 
-	if (sctx->cur_inode_last_extent < key->offset)
-		ret = send_hole(sctx, key->offset);
+	if (sctx->cur_inode_last_extent < key->offset) {
+		ret = range_is_hole_in_parent(sctx,
+					      sctx->cur_inode_last_extent,
+					      key->offset);
+		if (ret < 0)
+			return ret;
+		else if (ret == 0)
+			ret = send_hole(sctx, key->offset);
+		else
+			ret = 0;
+	}
 	sctx->cur_inode_last_extent = extent_end;
 	return ret;
 }

commit 0191410158840d6176de3267daa4604ad6a773fb
Author: Robbie Ko <robbieko@synology.com>
Date:   Thu Jan 5 16:24:58 2017 +0800

    Btrfs: incremental send, do not issue invalid rmdir operations
    
    When both the parent and send snapshots have a directory inode with the
    same number but different generations (therefore they are different
    inodes) and both have an entry with the same name, an incremental send
    stream will contain an invalid rmdir operation that refers to the
    orphanized name of the inode from the parent snapshot.
    
    The following example scenario shows how this happens.
    
    Parent snapshot:
    
     .
     |---- d259_old/               (ino 259, gen 9)
     |         |---- d1/           (ino 258, gen 9)
     |
     |---- f                       (ino 257, gen 9)
    
    Send snapshot:
    
     .
     |---- d258/                   (ino 258, gen 7)
     |---- d259/                   (ino 259, gen 7)
             |---- d1/             (ino 257, gen 7)
    
    When the kernel is processing inode 258 it notices that in both snapshots
    there is an inode numbered 259 that is a parent of an inode 258. However
    it ignores the fact that the inodes numbered 259 have different generations
    in both snapshots, which means they are effectively different inodes.
    Then it checks that both inodes 259 have a dentry named "d1" and because
    of that it issues a rmdir operation with orphanized name of the inode 258
    from the parent snapshot. This happens at send.c:process_record_refs(),
    which calls send.c:did_overwrite_first_ref() that returns true and because
    of that later on at process_recorded_refs() such rmdir operation is issued
    because the inode being currently processed (258) is a directory and it
    was deleted in the send snapshot (and replaced with another inode that has
    the same number and is a directory too).
    Fix this issue by comparing the generations of parent directory inodes
    that have the same number and make send.c:did_overwrite_first_ref() when
    the generations are different.
    
    The following steps reproduce the problem.
    
     $ mkfs.btrfs -f /dev/sdb
     $ mount /dev/sdb /mnt
     $ touch /mnt/f
     $ mkdir /mnt/d1
     $ mkdir /mnt/d259_old
     $ mv /mnt/d1 /mnt/d259_old/d1
     $ btrfs subvolume snapshot -r /mnt /mnt/snap1
     $ btrfs send /mnt/snap1 -f /tmp/1.snap
     $ umount /mnt
    
     $ mkfs.btrfs -f /dev/sdc
     $ mount /dev/sdc /mnt
     $ mkdir /mnt/d1
     $ mkdir /mnt/dir258
     $ mkdir /mnt/dir259
     $ mv /mnt/d1 /mnt/dir259/d1
     $ btrfs subvolume snapshot -r /mnt /mnt/snap2
     $ btrfs receive /mnt/ -f /tmp/1.snap
     # Take note that once the filesystem is created, its current
     # generation has value 7 so the inodes from the second snapshot all have
     # a generation value of 7. And after receiving the first snapshot
     # the filesystem is at a generation value of 10, because the call to
     # create the second snapshot bumps the generation to 8 (the snapshot
     # creation ioctl does a transaction commit), the receive command calls
     # the snapshot creation ioctl to create the first snapshot, which bumps
     # the filesystem's generation to 9, and finally when the receive
     # operation finishes it calls an ioctl to transition the first snapshot
     # (snap1) from RW mode to RO mode, which does another transaction commit
     # and bumps the filesystem's generation to 10. This means all the inodes
     # in the first snapshot (snap1) have a generation value of 9.
     $ rm -f /tmp/1.snap
     $ btrfs send /mnt/snap1 -f /tmp/1.snap
     $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/2.snap
     $ umount /mnt
    
     $ mkfs.btrfs -f /dev/sdd
     $ mount /dev/sdd /mnt
     $ btrfs receive /mnt -f /tmp/1.snap
     $ btrfs receive -vv /mnt -f /tmp/2.snap
     receiving snapshot mysnap2 uuid=9c03962f-f620-0047-9f98-32e5a87116d9, ctransid=7 parent_uuid=d17a6e3f-14e5-df4f-be39-a7951a5399aa, parent_ctransid=9
     utimes
     unlink f
     mkdir o257-7-0
     mkdir o259-7-0
     rename o257-7-0 -> o259-7-0/d1
     chown o259-7-0/d1 - uid=0, gid=0
     chmod o259-7-0/d1 - mode=0755
     utimes o259-7-0/d1
     rmdir o258-9-0
     ERROR: rmdir o258-9-0 failed: No such file or directory
    
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    [Rewrote changelog to be more precise and clear]
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 2742324514e4..712922ea64d2 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1937,6 +1937,19 @@ static int did_overwrite_ref(struct send_ctx *sctx,
 	if (ret <= 0)
 		goto out;
 
+	if (dir != BTRFS_FIRST_FREE_OBJECTID) {
+		ret = get_inode_info(sctx->send_root, dir, NULL, &gen, NULL,
+				     NULL, NULL, NULL);
+		if (ret < 0 && ret != -ENOENT)
+			goto out;
+		if (ret) {
+			ret = 0;
+			goto out;
+		}
+		if (gen != dir_gen)
+			goto out;
+	}
+
 	/* check if the ref was overwritten by another ref */
 	ret = lookup_dir_item_inode(sctx->send_root, dir, name, name_len,
 			&ow_inode, &other_type);

commit fe9c798dbf4c78322549068255f611e4038a5b28
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Jan 11 02:15:39 2017 +0000

    Btrfs: incremental send, do not delay rename when parent inode is new
    
    When we are checking if we need to delay the rename operation for an
    inode we not checking if a parent inode that exists in the send and
    parent snapshots is really the same inode or not, that is, we are not
    comparing the generation number of the parent inode in the send and
    parent snapshots. Not only this results in unnecessarily delaying a
    rename operation but also can later on make us generate an incorrect
    name for a new inode in the send snapshot that has the same number
    as another inode in the parent snapshot but a different generation.
    
    Here follows an example where this happens.
    
    Parent snapshot:
    
     .                                                  (ino 256, gen 3)
     |--- dir258/                                       (ino 258, gen 7)
     |       |--- dir257/                               (ino 257, gen 7)
     |
     |--- dir259/                                       (ino 259, gen 7)
    
    Send snapshot:
    
     .                                                  (ino 256, gen 3)
     |--- file258                                       (ino 258, gen 10)
     |
     |--- new_dir259/                                   (ino 259, gen 10)
              |--- dir257/                              (ino 257, gen 7)
    
    The following steps happen when computing the incremental send stream:
    
    1) When processing inode 257, its new parent is created using its orphan
       name (o257-21-0), and the rename operation for inode 257 is delayed
       because its new parent (inode 259) was not yet processed - this
       decision to delay the rename operation does not make much sense
       because the inode 259 in the send snapshot is a new inode, it's not
       the same as inode 259 in the parent snapshot.
    
    2) When processing inode 258 we end up delaying its rmdir operation,
       because inode 257 was not yet renamed (moved away from the directory
       inode 258 represents). We also create the new inode 258 using its
       orphan name "o258-10-0", then rename it to its final name of "file258"
       and then issue a truncate operation for it. However this truncate
       operation contains an incorrect name, which corresponds to the orphan
       name and not to the final name, which makes the receiver fail. This
       happens because when we attempt to compute the inode's current name
       we verify that there's another inode with the same number (258) that
       has its rmdir operation pending and because of that we generate an
       orphan name for the new inode 258 (we do this in the function
       get_cur_path()).
    
    Fix this by not delayed the rename operation of an inode if it has parents
    with the same number but different generations in both snapshots.
    
    The following steps reproduce this example scenario.
    
     $ mkfs.btrfs -f /dev/sdb
     $ mount /dev/sdb /mnt
     $ mkdir /mnt/dir257
     $ mkdir /mnt/dir258
     $ mkdir /mnt/dir259
     $ mv /mnt/dir257 /mnt/dir258/dir257
     $ btrfs subvolume snapshot -r /mnt /mnt/snap1
    
     $ mv /mnt/dir258/dir257 /mnt/dir257
     $ rmdir /mnt/dir258
     $ rmdir /mnt/dir259
    
     # Remount the filesystem so that the next created inodes will have the
     # numbers 258 and 259. This is because when a filesystem is mounted,
     # btrfs sets the subvolume's inode counter to a value corresponding to
     # the highest inode number in the subvolume plus 1. This inode counter
     # is used to assign a unique number to each new inode and it's
     # incremented by 1 after very inode creation.
     # Note: we unmount and then mount instead of doing a mount with
     # "-o remount" because otherwise the inode counter remains at value 260.
     $ umount /mnt
     $ mount /dev/sdb /mnt
     $ touch /mnt/file258
     $ mkdir /mnt/new_dir259
     $ mv /mnt/dir257 /mnt/new_dir259/dir257
     $ btrfs subvolume snapshot -r /mnt /mnt/snap2
    
     $ btrfs send /mnt/snap1 -f /tmp/1.snap
     $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/2.snap
    
     $ umount /mnt
     $ mkfs.btrfs -f /dev/sdc
     $ mount /dev/sdc /mnt
     $ btrfs receive /mnt -f /tmo/1.snap
     $ btrfs receive /mnt -f /tmo/2.snap -vv
     receiving snapshot mysnap2 uuid=e059b6d1-7f55-f140-8d7c-9a3039d23c97, ctransid=10 parent_uuid=77e98cb6-8762-814f-9e05-e8ba877fc0b0, parent_ctransid=7
     utimes
     mkdir o259-10-0
     rename dir258 -> o258-7-0
     utimes
     mkfile o258-10-0
     rename o258-10-0 -> file258
     utimes
     truncate o258-10-0 size=0
     ERROR: truncate o258-10-0 failed: No such file or directory
    
    Reported-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 2ae32c4f7dd7..2742324514e4 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3559,6 +3559,7 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 {
 	int ret = 0;
 	u64 ino = parent_ref->dir;
+	u64 ino_gen = parent_ref->dir_gen;
 	u64 parent_ino_before, parent_ino_after;
 	struct fs_path *path_before = NULL;
 	struct fs_path *path_after = NULL;
@@ -3579,6 +3580,8 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 	 * at get_cur_path()).
 	 */
 	while (ino > BTRFS_FIRST_FREE_OBJECTID) {
+		u64 parent_ino_after_gen;
+
 		if (is_waiting_for_move(sctx, ino)) {
 			/*
 			 * If the current inode is an ancestor of ino in the
@@ -3601,7 +3604,7 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 		fs_path_reset(path_after);
 
 		ret = get_first_ref(sctx->send_root, ino, &parent_ino_after,
-				    NULL, path_after);
+				    &parent_ino_after_gen, path_after);
 		if (ret < 0)
 			goto out;
 		ret = get_first_ref(sctx->parent_root, ino, &parent_ino_before,
@@ -3618,10 +3621,20 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 		if (ino > sctx->cur_ino &&
 		    (parent_ino_before != parent_ino_after || len1 != len2 ||
 		     memcmp(path_before->start, path_after->start, len1))) {
-			ret = 1;
-			break;
+			u64 parent_ino_gen;
+
+			ret = get_inode_info(sctx->parent_root, ino, NULL,
+					     &parent_ino_gen, NULL, NULL, NULL,
+					     NULL);
+			if (ret < 0)
+				goto out;
+			if (ino_gen == parent_ino_gen) {
+				ret = 1;
+				break;
+			}
 		}
 		ino = parent_ino_after;
+		ino_gen = parent_ino_after_gen;
 	}
 
 out:

commit 4dd9920d991745c4a16f53a8f615f706fbe4b3f7
Author: Robbie Ko <robbieko@synology.com>
Date:   Thu Jan 5 16:24:55 2017 +0800

    Btrfs: send, fix failure to rename top level inode due to name collision
    
    Under certain situations, an incremental send operation can fail due to a
    premature attempt to create a new top level inode (a direct child of the
    subvolume/snapshot root) whose name collides with another inode that was
    removed from the send snapshot.
    
    Consider the following example scenario.
    
    Parent snapshot:
    
      .                 (ino 256, gen 8)
      |---- a1/         (ino 257, gen 9)
      |---- a2/         (ino 258, gen 9)
    
    Send snapshot:
    
      .                 (ino 256, gen 3)
      |---- a2/         (ino 257, gen 7)
    
    In this scenario, when receiving the incremental send stream, the btrfs
    receive command fails like this (ran in verbose mode, -vv argument):
    
      rmdir a1
      mkfile o257-7-0
      rename o257-7-0 -> a2
      ERROR: rename o257-7-0 -> a2 failed: Is a directory
    
    What happens when computing the incremental send stream is:
    
    1) An operation to remove the directory with inode number 257 and
       generation 9 is issued.
    
    2) An operation to create the inode with number 257 and generation 7 is
       issued. This creates the inode with an orphanized name of "o257-7-0".
    
    3) An operation rename the new inode 257 to its final name, "a2", is
       issued. This is incorrect because inode 258, which has the same name
       and it's a child of the same parent (root inode 256), was not yet
       processed and therefore no rmdir operation for it was yet issued.
       The rename operation is issued because we fail to detect that the
       name of the new inode 257 collides with inode 258, because their
       parent, a subvolume/snapshot root (inode 256) has a different
       generation in both snapshots.
    
    So fix this by ignoring the generation value of a parent directory that
    matches a root inode (number 256) when we are checking if the name of the
    inode currently being processed collides with the name of some other
    inode that was not yet processed.
    
    We can achieve this scenario of different inodes with the same number but
    different generation values either by mounting a filesystem with the inode
    cache option (-o inode_cache) or by creating and sending snapshots across
    different filesystems, like in the following example:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
      $ mkdir /mnt/a1
      $ mkdir /mnt/a2
      $ btrfs subvolume snapshot -r /mnt /mnt/snap1
      $ btrfs send /mnt/snap1 -f /tmp/1.snap
      $ umount /mnt
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt
      $ touch /mnt/a2
      $ btrfs subvolume snapshot -r /mnt /mnt/snap2
      $ btrfs receive /mnt -f /tmp/1.snap
      # Take note that once the filesystem is created, its current
      # generation has value 7 so the inode from the second snapshot has
      # a generation value of 7. And after receiving the first snapshot
      # the filesystem is at a generation value of 10, because the call to
      # create the second snapshot bumps the generation to 8 (the snapshot
      # creation ioctl does a transaction commit), the receive command calls
      # the snapshot creation ioctl to create the first snapshot, which bumps
      # the filesystem's generation to 9, and finally when the receive
      # operation finishes it calls an ioctl to transition the first snapshot
      # (snap1) from RW mode to RO mode, which does another transaction commit
      # and bumps the filesystem's generation to 10.
      $ rm -f /tmp/1.snap
      $ btrfs send /mnt/snap1 -f /tmp/1.snap
      $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/2.snap
      $ umount /mnt
    
      $ mkfs.btrfs -f /dev/sdd
      $ mount /dev/sdd /mnt
      $ btrfs receive /mnt /tmp/1.snap
      # Receive of snapshot snap2 used to fail.
      $ btrfs receive /mnt /tmp/2.snap
    
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    [Rewrote changelog to be more precise and clear]
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d145ce804620..2ae32c4f7dd7 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1681,6 +1681,9 @@ static int is_inode_existent(struct send_ctx *sctx, u64 ino, u64 gen)
 {
 	int ret;
 
+	if (ino == BTRFS_FIRST_FREE_OBJECTID)
+		return 1;
+
 	ret = get_cur_inode_state(sctx, ino, gen);
 	if (ret < 0)
 		goto out;
@@ -1866,7 +1869,7 @@ static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 	 * not deleted and then re-created, if it was then we have no overwrite
 	 * and we can just unlink this entry.
 	 */
-	if (sctx->parent_root) {
+	if (sctx->parent_root && dir != BTRFS_FIRST_FREE_OBJECTID) {
 		ret = get_inode_info(sctx->parent_root, dir, NULL, &gen, NULL,
 				     NULL, NULL, NULL);
 		if (ret < 0 && ret != -ENOENT)

commit 3a45bb207ee2c5548ebf6f5fcc7d249e141f15e8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Sep 9 21:39:03 2016 -0400

    btrfs: remove root parameter from transaction commit/end routines
    
    Now we only use the root parameter to print the root objectid in
    a tracepoint.  We can use the root parameter from the transaction
    handle for that.  It's also used to join the transaction with
    async commits, so we remove the comment that it's just for checking.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 1df3b8798323..d145ce804620 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6112,7 +6112,7 @@ static int ensure_commit_roots_uptodate(struct send_ctx *sctx)
 			goto commit_trans;
 
 	if (trans)
-		return btrfs_end_transaction(trans, sctx->send_root);
+		return btrfs_end_transaction(trans);
 
 	return 0;
 
@@ -6125,7 +6125,7 @@ static int ensure_commit_roots_uptodate(struct send_ctx *sctx)
 		goto again;
 	}
 
-	return btrfs_commit_transaction(trans, sctx->send_root);
+	return btrfs_commit_transaction(trans);
 }
 
 static void btrfs_root_dec_send_in_progress(struct btrfs_root* root)

commit 2ff7e61e0d30ff166a2ae94575526bffe11fd1a8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:24 2016 -0400

    btrfs: take an fs_info directly when the root is not used otherwise
    
    There are loads of functions in btrfs that accept a root parameter
    but only use it to obtain an fs_info pointer.  Let's convert those to
    just accept an fs_info pointer directly.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 399b36b2a182..1df3b8798323 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3435,6 +3435,7 @@ static int wait_for_dest_dir_move(struct send_ctx *sctx,
 				  struct recorded_ref *parent_ref,
 				  const bool is_orphan)
 {
+	struct btrfs_fs_info *fs_info = sctx->parent_root->fs_info;
 	struct btrfs_path *path;
 	struct btrfs_key key;
 	struct btrfs_key di_key;
@@ -3463,8 +3464,8 @@ static int wait_for_dest_dir_move(struct send_ctx *sctx,
 		goto out;
 	}
 
-	di = btrfs_match_dir_item_name(sctx->parent_root, path,
-				       parent_ref->name, parent_ref->name_len);
+	di = btrfs_match_dir_item_name(fs_info, path, parent_ref->name,
+				       parent_ref->name_len);
 	if (!di) {
 		ret = 0;
 		goto out;

commit 0b246afa62b0cf5b09d078121f543135f28492ad
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:23 2016 -0400

    btrfs: root->fs_info cleanup, add fs_info convenience variables
    
    In routines where someptr->fs_info is referenced multiple times, we
    introduce a convenience variable.  This makes the code considerably
    more readable.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 78845cc81dd6..399b36b2a182 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1431,9 +1431,9 @@ static int find_extent_clone(struct send_ctx *sctx,
 		extent_item_pos = logical - found_key.objectid;
 	else
 		extent_item_pos = 0;
-	ret = iterate_extent_inodes(fs_info,
-					found_key.objectid, extent_item_pos, 1,
-					__iterate_backrefs, backref_ctx);
+	ret = iterate_extent_inodes(fs_info, found_key.objectid,
+				    extent_item_pos, 1, __iterate_backrefs,
+				    backref_ctx);
 
 	if (ret < 0)
 		goto out;
@@ -6137,17 +6137,17 @@ static void btrfs_root_dec_send_in_progress(struct btrfs_root* root)
 	 */
 	if (root->send_in_progress < 0)
 		btrfs_err(root->fs_info,
-			"send_in_progres unbalanced %d root %llu",
-			root->send_in_progress, root->root_key.objectid);
+			  "send_in_progres unbalanced %d root %llu",
+			  root->send_in_progress, root->root_key.objectid);
 	spin_unlock(&root->root_item_lock);
 }
 
 long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 {
 	int ret = 0;
-	struct btrfs_root *send_root;
+	struct btrfs_root *send_root = BTRFS_I(file_inode(mnt_file))->root;
+	struct btrfs_fs_info *fs_info = send_root->fs_info;
 	struct btrfs_root *clone_root;
-	struct btrfs_fs_info *fs_info;
 	struct btrfs_ioctl_send_args *arg = NULL;
 	struct btrfs_key key;
 	struct send_ctx *sctx = NULL;
@@ -6161,9 +6161,6 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
-	send_root = BTRFS_I(file_inode(mnt_file))->root;
-	fs_info = send_root->fs_info;
-
 	/*
 	 * The subvolume must remain read-only during send, protect against
 	 * making it RW. This also protects against deletion.

commit da17066c40472c2d6a1aab7bb0090c3d285531c9
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 09:22:56 2016 -0400

    btrfs: pull node/sector/stripe sizes out of root and into fs_info
    
    We track the node sizes per-root, but they never vary from the values
    in the superblock.  This patch messes with the 80-column style a bit,
    but subsequent patches to factor out root->fs_info into a convenience
    variable fix it up again.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 71261b459863..78845cc81dd6 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1054,7 +1054,8 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 				ret = -ENAMETOOLONG;
 				goto out;
 			}
-			if (name_len + data_len > BTRFS_MAX_XATTR_SIZE(root)) {
+			if (name_len + data_len >
+					BTRFS_MAX_XATTR_SIZE(root->fs_info)) {
 				ret = -E2BIG;
 				goto out;
 			}
@@ -5264,7 +5265,7 @@ static int get_last_extent(struct send_ctx *sctx, u64 offset)
 		u64 size = btrfs_file_extent_inline_len(path->nodes[0],
 							path->slots[0], fi);
 		extent_end = ALIGN(key.offset + size,
-				   sctx->send_root->sectorsize);
+				   sctx->send_root->fs_info->sectorsize);
 	} else {
 		extent_end = key.offset +
 			btrfs_file_extent_num_bytes(path->nodes[0], fi);
@@ -5299,7 +5300,7 @@ static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
 		u64 size = btrfs_file_extent_inline_len(path->nodes[0],
 							path->slots[0], fi);
 		extent_end = ALIGN(key->offset + size,
-				   sctx->send_root->sectorsize);
+				   sctx->send_root->fs_info->sectorsize);
 	} else {
 		extent_end = key->offset +
 			btrfs_file_extent_num_bytes(path->nodes[0], fi);

commit f6167514c819cb7794e60cf36b9466598a789013
Merge: 2cd0b50a189f 570dd45042a7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 28 10:07:35 2016 -0700

    Merge branch 'for-linus-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "My patch fixes the btrfs list_head abuse that we tracked down during
      Dave Jones' memory corruption investigation. With both Jens and my
      patches in place, I'm no longer able to trigger problems.
    
      Filipe is fixing a difficult old bug between snapshots, balance and
      send. Dave is cooking a few more for the next rc, but these are tested
      and ready"
    
    * 'for-linus-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      btrfs: fix races on root_log_ctx lists
      btrfs: fix incremental send failure caused by balance

commit d5e84fd8d0634d056248b67463b42f6c85896a19
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Sep 19 10:57:40 2016 +0100

    Btrfs: fix incremental send failure caused by balance
    
    Commit 951555856b88 ("Btrfs: send, don't bug on inconsistent snapshots")
    removed some BUG_ON() statements (replacing them with returning errors
    to user space and logging error messages) when a snapshot is in an
    inconsistent state due to failures to update a delayed inode item (ENOMEM
    or ENOSPC) after adding/updating/deleting references, xattrs or file
    extent items.
    
    However there is a case, when no errors happen, where a file extent item
    can be modified without having the corresponding inode item updated. This
    case happens during balance under very specific timings, when relocation
    is in the stage where it updates data pointers and a leaf that contains
    file extent items is COWed. When that happens file extent items get their
    disk_bytenr field updated to a new value that reflects the post relocation
    logical address of the extent, without updating their respective inode
    items (as there is nothing that needs to be updated on them). This is
    performed at relocation.c:replace_file_extents() through
    relocation.c:btrfs_reloc_cow_block().
    
    So make an incremental send deal with this case and don't do any processing
    for a file extent item that got its disk_bytenr field updated by relocation,
    since the extent's data is the same as the one pointed by the file extent
    item in the parent snapshot.
    
    After the recent commit mentioned above this case resulted in EIO errors
    returned to user space (and an error message logged to dmesg/syslog) when
    doing an incremental send, while before it, it resulted in hitting a
    BUG_ON leading to the following trace:
    
    [  952.206705] ------------[ cut here ]------------
    [  952.206714] kernel BUG at ../fs/btrfs/send.c:5653!
    [  952.206719] Internal error: Oops - BUG: 0 [#1] SMP
    [  952.209854] Modules linked in: st dm_mod nls_utf8 isofs fuse nf_log_ipv6 xt_pkttype xt_physdev br_netfilter nf_log_ipv4 nf_log_common xt_LOG xt_limit ebtable_filter ebtables af_packet bridge stp llc ip6t_REJECT xt_tcpudp nf_conntrack_ipv6 nf_defrag_ipv6 ip6table_raw ipt_REJECT iptable_raw xt_CT iptable_filter ip6table_mangle nf_conntrack_netbios_ns nf_conntrack_broadcast nf_conntrack_ipv4 nf_defrag_ipv4 ip_tables xt_conntrack nf_conntrack ip6table_filter ip6_tables x_tables xfs libcrc32c nls_iso8859_1 nls_cp437 vfat fat joydev aes_ce_blk ablk_helper cryptd snd_intel8x0 aes_ce_cipher snd_ac97_codec ac97_bus snd_pcm ghash_ce sha2_ce sha1_ce snd_timer snd virtio_net soundcore btrfs xor sr_mod cdrom hid_generic usbhid raid6_pq virtio_blk virtio_scsi bochs_drm drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops ttm virtio_mmio xhci_pci xhci_hcd usbcore usb_common virtio_pci virtio_ring virtio drm sg efivarfs
    [  952.228333] Supported: Yes
    [  952.228908] CPU: 0 PID: 12779 Comm: snapperd Not tainted 4.4.14-50-default #1
    [  952.230329] Hardware name: QEMU KVM Virtual Machine, BIOS 0.0.0 02/06/2015
    [  952.231683] task: ffff800058e94100 ti: ffff8000d866c000 task.ti: ffff8000d866c000
    [  952.233279] PC is at changed_cb+0x9f4/0xa48 [btrfs]
    [  952.234375] LR is at changed_cb+0x58/0xa48 [btrfs]
    [  952.236552] pc : [<ffff7ffffc39de7c>] lr : [<ffff7ffffc39d4e0>] pstate: 80000145
    [  952.238049] sp : ffff8000d866fa20
    [  952.238732] x29: ffff8000d866fa20 x28: 0000000000000019
    [  952.239840] x27: 00000000000028d5 x26: 00000000000024a2
    [  952.241008] x25: 0000000000000002 x24: ffff8000e66e92f0
    [  952.242131] x23: ffff8000b8c76800 x22: ffff800092879140
    [  952.243238] x21: 0000000000000002 x20: ffff8000d866fb78
    [  952.244348] x19: ffff8000b8f8c200 x18: 0000000000002710
    [  952.245607] x17: 0000ffff90d42480 x16: ffff800000237dc0
    [  952.246719] x15: 0000ffff90de7510 x14: ab000c000a2faf08
    [  952.247835] x13: 0000000000577c2b x12: ab000c000b696665
    [  952.248981] x11: 2e65726f632f6966 x10: 652d34366d72612f
    [  952.250101] x9 : 32627572672f746f x8 : ab000c00092f1671
    [  952.251352] x7 : 8000000000577c2b x6 : ffff800053eadf45
    [  952.252468] x5 : 0000000000000000 x4 : ffff80005e169494
    [  952.253582] x3 : 0000000000000004 x2 : ffff8000d866fb78
    [  952.254695] x1 : 000000000003e2a3 x0 : 000000000003e2a4
    [  952.255803]
    [  952.256150] Process snapperd (pid: 12779, stack limit = 0xffff8000d866c020)
    [  952.257516] Stack: (0xffff8000d866fa20 to 0xffff8000d8670000)
    [  952.258654] fa20: ffff8000d866fae0 ffff7ffffc308fc0 ffff800092879140 ffff8000e66e92f0
    [  952.260219] fa40: 0000000000000035 ffff800055de6000 ffff8000b8c76800 ffff8000d866fb78
    [  952.261745] fa60: 0000000000000002 00000000000024a2 00000000000028d5 0000000000000019
    [  952.263269] fa80: ffff8000d866fae0 ffff7ffffc3090f0 ffff8000d866fae0 ffff7ffffc309128
    [  952.264797] faa0: ffff800092879140 ffff8000e66e92f0 0000000000000035 ffff800055de6000
    [  952.268261] fac0: ffff8000b8c76800 ffff8000d866fb78 0000000000000002 0000000000001000
    [  952.269822] fae0: ffff8000d866fbc0 ffff7ffffc39ecfc ffff8000b8f8c200 ffff8000b8f8c368
    [  952.271368] fb00: ffff8000b8f8c378 ffff800055de6000 0000000000000001 ffff8000ecb17500
    [  952.272893] fb20: ffff8000b8c76800 ffff800092879140 ffff800062b6d000 ffff80007a9e2470
    [  952.274420] fb40: ffff8000b8f8c208 0000000005784000 ffff8000580a8000 ffff8000b8f8c200
    [  952.276088] fb60: ffff7ffffc39d488 00000002b8f8c368 0000000000000000 000000000003e2a4
    [  952.280275] fb80: 000000000000006c ffff7ffffc39ec00 000000000003e2a4 000000000000006c
    [  952.283219] fba0: ffff8000b8f8c300 0000000000000100 0000000000000001 ffff8000ecb17500
    [  952.286166] fbc0: ffff8000d866fcd0 ffff7ffffc3643c0 ffff8000f8842700 0000ffff8ffe9278
    [  952.289136] fbe0: 0000000040489426 ffff800055de6000 0000ffff8ffe9278 0000000040489426
    [  952.292083] fc00: 000000000000011d 000000000000001d ffff80007a9e4598 ffff80007a9e43e8
    [  952.294959] fc20: ffff8000b8c7693f 0000000000003b24 0000000000000019 ffff8000b8f8c218
    [  952.301161] fc40: 00000001d866fc70 ffff8000b8c76800 0000000000000128 ffffffffffffff84
    [  952.305749] fc60: ffff800058e941ff 0000000000003a58 ffff8000d866fcb0 ffff8000000f7390
    [  952.308875] fc80: 000000000000012a 0000000000010290 ffff8000d866fc00 000000000000007b
    [  952.311915] fca0: 0000000000010290 ffff800046c1b100 74732d7366727462 000001006d616572
    [  952.314937] fcc0: ffff8000fffc4100 cb88537fdc8ba60e ffff8000d866fe10 ffff8000002499e8
    [  952.318008] fce0: 0000000040489426 ffff8000f8842700 0000ffff8ffe9278 ffff80007a9e4598
    [  952.321321] fd00: 0000ffff8ffe9278 0000000040489426 000000000000011d 000000000000001d
    [  952.324280] fd20: ffff80000072c000 ffff8000d866c000 ffff8000d866fda0 ffff8000000e997c
    [  952.327156] fd40: ffff8000fffc4180 00000000000031ed ffff8000fffc4180 ffff800046c1b7d4
    [  952.329895] fd60: 0000000000000140 0000ffff907ea170 000000000000011d 00000000000000dc
    [  952.334641] fd80: ffff80000072c000 ffff8000d866c000 0000000000000000 0000000000000002
    [  952.338002] fda0: ffff8000d866fdd0 ffff8000000ebacc ffff800046c1b080 ffff800046c1b7d4
    [  952.340724] fdc0: ffff8000d866fdf0 ffff8000000db67c 0000000000000040 ffff800000e69198
    [  952.343415] fde0: 0000ffff8ffea790 00000000000031ed ffff8000d866fe20 ffff800000254000
    [  952.346101] fe00: 000000000000001d 0000000000000004 ffff8000d866fe90 ffff800000249d3c
    [  952.348980] fe20: ffff8000f8842700 0000000000000000 ffff8000f8842701 0000000000000008
    [  952.351696] fe40: ffff8000d866fe70 0000000000000008 ffff8000d866fe90 ffff800000249cf8
    [  952.354387] fe60: ffff8000f8842700 0000ffff8ffe9170 ffff8000f8842701 0000000000000008
    [  952.357083] fe80: 0000ffff8ffe9278 ffff80008ff85500 0000ffff8ffe90c0 ffff800000085c84
    [  952.359800] fea0: 0000000000000000 0000ffff8ffe9170 ffffffffffffffff 0000ffff90d473bc
    [  952.365351] fec0: 0000000000000000 0000000000000015 0000000000000008 0000000040489426
    [  952.369550] fee0: 0000ffff8ffe9278 0000ffff907ea790 0000ffff907ea170 0000ffff907ea790
    [  952.372416] ff00: 0000ffff907ea170 0000000000000000 000000000000001d 0000000000000004
    [  952.375223] ff20: 0000ffff90a32220 00000000003d0f00 0000ffff907ea0a0 0000ffff8ffe8f30
    [  952.378099] ff40: 0000ffff9100f554 0000ffff91147000 0000ffff91117bc0 0000ffff90d473b0
    [  952.381115] ff60: 0000ffff9100f620 0000ffff880069b0 0000ffff8ffe9170 0000ffff8ffe91a0
    [  952.384003] ff80: 0000ffff8ffe9160 0000ffff8ffe9140 0000ffff88006990 0000ffff8ffe9278
    [  952.386860] ffa0: 0000ffff88008a60 0000ffff8ffe9480 0000ffff88014ca0 0000ffff8ffe90c0
    [  952.389654] ffc0: 0000ffff910be8e8 0000ffff8ffe90c0 0000ffff90d473bc 0000000000000000
    [  952.410986] ffe0: 0000000000000008 000000000000001d 6e2079747265706f 72616d223d656d61
    [  952.415497] Call trace:
    [  952.417403] [<ffff7ffffc39de7c>] changed_cb+0x9f4/0xa48 [btrfs]
    [  952.420023] [<ffff7ffffc308fc0>] btrfs_compare_trees+0x500/0x6b0 [btrfs]
    [  952.422759] [<ffff7ffffc39ecfc>] btrfs_ioctl_send+0xb4c/0xe10 [btrfs]
    [  952.425601] [<ffff7ffffc3643c0>] btrfs_ioctl+0x374/0x29a4 [btrfs]
    [  952.428031] [<ffff8000002499e8>] do_vfs_ioctl+0x33c/0x600
    [  952.430360] [<ffff800000249d3c>] SyS_ioctl+0x90/0xa4
    [  952.432552] [<ffff800000085c84>] el0_svc_naked+0x38/0x3c
    [  952.434803] Code: 2a1503e0 17fffdac b9404282 17ffff28 (d4210000)
    [  952.437457] ---[ end trace 9afd7090c466cf15 ]---
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 978796865bfc..0b4628999b77 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5805,6 +5805,64 @@ static int changed_extent(struct send_ctx *sctx,
 	int ret = 0;
 
 	if (sctx->cur_ino != sctx->cmp_key->objectid) {
+
+		if (result == BTRFS_COMPARE_TREE_CHANGED) {
+			struct extent_buffer *leaf_l;
+			struct extent_buffer *leaf_r;
+			struct btrfs_file_extent_item *ei_l;
+			struct btrfs_file_extent_item *ei_r;
+
+			leaf_l = sctx->left_path->nodes[0];
+			leaf_r = sctx->right_path->nodes[0];
+			ei_l = btrfs_item_ptr(leaf_l,
+					      sctx->left_path->slots[0],
+					      struct btrfs_file_extent_item);
+			ei_r = btrfs_item_ptr(leaf_r,
+					      sctx->right_path->slots[0],
+					      struct btrfs_file_extent_item);
+
+			/*
+			 * We may have found an extent item that has changed
+			 * only its disk_bytenr field and the corresponding
+			 * inode item was not updated. This case happens due to
+			 * very specific timings during relocation when a leaf
+			 * that contains file extent items is COWed while
+			 * relocation is ongoing and its in the stage where it
+			 * updates data pointers. So when this happens we can
+			 * safely ignore it since we know it's the same extent,
+			 * but just at different logical and physical locations
+			 * (when an extent is fully replaced with a new one, we
+			 * know the generation number must have changed too,
+			 * since snapshot creation implies committing the current
+			 * transaction, and the inode item must have been updated
+			 * as well).
+			 * This replacement of the disk_bytenr happens at
+			 * relocation.c:replace_file_extents() through
+			 * relocation.c:btrfs_reloc_cow_block().
+			 */
+			if (btrfs_file_extent_generation(leaf_l, ei_l) ==
+			    btrfs_file_extent_generation(leaf_r, ei_r) &&
+			    btrfs_file_extent_ram_bytes(leaf_l, ei_l) ==
+			    btrfs_file_extent_ram_bytes(leaf_r, ei_r) &&
+			    btrfs_file_extent_compression(leaf_l, ei_l) ==
+			    btrfs_file_extent_compression(leaf_r, ei_r) &&
+			    btrfs_file_extent_encryption(leaf_l, ei_l) ==
+			    btrfs_file_extent_encryption(leaf_r, ei_r) &&
+			    btrfs_file_extent_other_encoding(leaf_l, ei_l) ==
+			    btrfs_file_extent_other_encoding(leaf_r, ei_r) &&
+			    btrfs_file_extent_type(leaf_l, ei_l) ==
+			    btrfs_file_extent_type(leaf_r, ei_r) &&
+			    btrfs_file_extent_disk_bytenr(leaf_l, ei_l) !=
+			    btrfs_file_extent_disk_bytenr(leaf_r, ei_r) &&
+			    btrfs_file_extent_disk_num_bytes(leaf_l, ei_l) ==
+			    btrfs_file_extent_disk_num_bytes(leaf_r, ei_r) &&
+			    btrfs_file_extent_offset(leaf_l, ei_l) ==
+			    btrfs_file_extent_offset(leaf_r, ei_r) &&
+			    btrfs_file_extent_num_bytes(leaf_l, ei_l) ==
+			    btrfs_file_extent_num_bytes(leaf_r, ei_r))
+				return 0;
+		}
+
 		inconsistent_snapshot_error(sctx, result, "extent");
 		return -EIO;
 	}

commit f29135b54bcbfe1fea97d94e2ae860bade1d5a31
Merge: 4c609922a3ae 19c4d2f99478
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 11 11:23:06 2016 -0700

    Merge branch 'for-linus-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This is a big variety of fixes and cleanups.
    
      Liu Bo continues to fixup fuzzer related problems, and some of Josef's
      cleanups are prep for his bigger extent buffer changes (slated for
      v4.10)"
    
    * 'for-linus-4.9' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (39 commits)
      Revert "btrfs: let btrfs_delete_unused_bgs() to clean relocated bgs"
      Btrfs: remove unnecessary btrfs_mark_buffer_dirty in split_leaf
      Btrfs: don't BUG() during drop snapshot
      btrfs: fix btrfs_no_printk stub helper
      Btrfs: memset to avoid stale content in btree leaf
      btrfs: parent_start initialization cleanup
      btrfs: Remove already completed TODO comment
      btrfs: Do not reassign count in btrfs_run_delayed_refs
      btrfs: fix a possible umount deadlock
      Btrfs: fix memory leak in do_walk_down
      btrfs: btrfs_debug should consume fs_info when DEBUG is not defined
      btrfs: convert send's verbose_printk to btrfs_debug
      btrfs: convert pr_* to btrfs_* where possible
      btrfs: convert printk(KERN_* to use pr_* calls
      btrfs: unsplit printed strings
      btrfs: clean the old superblocks before freeing the device
      Btrfs: kill BUG_ON in run_delayed_tree_ref
      Btrfs: don't leak reloc root nodes on error
      btrfs: squash lines for simple wrapper functions
      Btrfs: improve check_node to avoid reading corrupted nodes
      ...

commit 2211d5ba5c6c4e972ba6dbc912b2897425ea6621
Author: Andreas Gruenbacher <agruenba@redhat.com>
Date:   Tue Sep 27 13:03:22 2016 +0200

    posix_acl: xattr representation cleanups
    
    Remove the unnecessary typedefs and the zero-length a_entries array in
    struct posix_acl_xattr_header.
    
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a87675ffd02b..1379e59277e2 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4329,7 +4329,7 @@ static int __process_new_xattr(int num, struct btrfs_key *di_key,
 	int ret;
 	struct send_ctx *sctx = ctx;
 	struct fs_path *p;
-	posix_acl_xattr_header dummy_acl;
+	struct posix_acl_xattr_header dummy_acl;
 
 	p = fs_path_alloc();
 	if (!p)

commit 04ab956ee69cdbe8627f6e34b88af5c308eede84
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:03 2016 -0400

    btrfs: convert send's verbose_printk to btrfs_debug
    
    This was basically an open-coded, less flexible dynamic printk.  We can
    just use btrfs_debug instead.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 1f4e78d8b0fe..978796865bfc 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -36,10 +36,6 @@
 #include "transaction.h"
 #include "compression.h"
 
-static int g_verbose = 0;
-
-#define verbose_printk(...) if (g_verbose) printk(__VA_ARGS__)
-
 /*
  * A fs_path is a helper to dynamically build path names with unknown size.
  * It reallocates the internal buffer on demand.
@@ -727,9 +723,10 @@ static int send_cmd(struct send_ctx *sctx)
 static int send_rename(struct send_ctx *sctx,
 		     struct fs_path *from, struct fs_path *to)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret;
 
-verbose_printk("btrfs: send_rename %s -> %s\n", from->start, to->start);
+	btrfs_debug(fs_info, "send_rename %s -> %s", from->start, to->start);
 
 	ret = begin_cmd(sctx, BTRFS_SEND_C_RENAME);
 	if (ret < 0)
@@ -751,9 +748,10 @@ verbose_printk("btrfs: send_rename %s -> %s\n", from->start, to->start);
 static int send_link(struct send_ctx *sctx,
 		     struct fs_path *path, struct fs_path *lnk)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret;
 
-verbose_printk("btrfs: send_link %s -> %s\n", path->start, lnk->start);
+	btrfs_debug(fs_info, "send_link %s -> %s", path->start, lnk->start);
 
 	ret = begin_cmd(sctx, BTRFS_SEND_C_LINK);
 	if (ret < 0)
@@ -774,9 +772,10 @@ verbose_printk("btrfs: send_link %s -> %s\n", path->start, lnk->start);
  */
 static int send_unlink(struct send_ctx *sctx, struct fs_path *path)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret;
 
-verbose_printk("btrfs: send_unlink %s\n", path->start);
+	btrfs_debug(fs_info, "send_unlink %s", path->start);
 
 	ret = begin_cmd(sctx, BTRFS_SEND_C_UNLINK);
 	if (ret < 0)
@@ -796,9 +795,10 @@ verbose_printk("btrfs: send_unlink %s\n", path->start);
  */
 static int send_rmdir(struct send_ctx *sctx, struct fs_path *path)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret;
 
-verbose_printk("btrfs: send_rmdir %s\n", path->start);
+	btrfs_debug(fs_info, "send_rmdir %s", path->start);
 
 	ret = begin_cmd(sctx, BTRFS_SEND_C_RMDIR);
 	if (ret < 0)
@@ -1313,6 +1313,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 			     u64 ino_size,
 			     struct clone_root **found)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret;
 	int extent_type;
 	u64 logical;
@@ -1371,10 +1372,10 @@ static int find_extent_clone(struct send_ctx *sctx,
 	}
 	logical = disk_byte + btrfs_file_extent_offset(eb, fi);
 
-	down_read(&sctx->send_root->fs_info->commit_root_sem);
-	ret = extent_from_logical(sctx->send_root->fs_info, disk_byte, tmp_path,
+	down_read(&fs_info->commit_root_sem);
+	ret = extent_from_logical(fs_info, disk_byte, tmp_path,
 				  &found_key, &flags);
-	up_read(&sctx->send_root->fs_info->commit_root_sem);
+	up_read(&fs_info->commit_root_sem);
 	btrfs_release_path(tmp_path);
 
 	if (ret < 0)
@@ -1429,7 +1430,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 		extent_item_pos = logical - found_key.objectid;
 	else
 		extent_item_pos = 0;
-	ret = iterate_extent_inodes(sctx->send_root->fs_info,
+	ret = iterate_extent_inodes(fs_info,
 					found_key.objectid, extent_item_pos, 1,
 					__iterate_backrefs, backref_ctx);
 
@@ -1439,17 +1440,18 @@ static int find_extent_clone(struct send_ctx *sctx,
 	if (!backref_ctx->found_itself) {
 		/* found a bug in backref code? */
 		ret = -EIO;
-		btrfs_err(sctx->send_root->fs_info,
+		btrfs_err(fs_info,
 			  "did not find backref in send_root. inode=%llu, offset=%llu, disk_byte=%llu found extent=%llu",
-				ino, data_offset, disk_byte, found_key.objectid);
+			  ino, data_offset, disk_byte, found_key.objectid);
 		goto out;
 	}
 
-verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, ino=%llu, num_bytes=%llu, logical=%llu\n",
-		data_offset, ino, num_bytes, logical);
+	btrfs_debug(fs_info,
+		    "find_extent_clone: data_offset=%llu, ino=%llu, num_bytes=%llu, logical=%llu",
+		    data_offset, ino, num_bytes, logical);
 
 	if (!backref_ctx->found)
-		verbose_printk("btrfs:    no clones found\n");
+		btrfs_debug(fs_info, "no clones found");
 
 	cur_clone_root = NULL;
 	for (i = 0; i < sctx->clone_roots_cnt; i++) {
@@ -2420,10 +2422,11 @@ static int send_subvol_begin(struct send_ctx *sctx)
 
 static int send_truncate(struct send_ctx *sctx, u64 ino, u64 gen, u64 size)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret = 0;
 	struct fs_path *p;
 
-verbose_printk("btrfs: send_truncate %llu size=%llu\n", ino, size);
+	btrfs_debug(fs_info, "send_truncate %llu size=%llu", ino, size);
 
 	p = fs_path_alloc();
 	if (!p)
@@ -2449,10 +2452,11 @@ verbose_printk("btrfs: send_truncate %llu size=%llu\n", ino, size);
 
 static int send_chmod(struct send_ctx *sctx, u64 ino, u64 gen, u64 mode)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret = 0;
 	struct fs_path *p;
 
-verbose_printk("btrfs: send_chmod %llu mode=%llu\n", ino, mode);
+	btrfs_debug(fs_info, "send_chmod %llu mode=%llu", ino, mode);
 
 	p = fs_path_alloc();
 	if (!p)
@@ -2478,10 +2482,12 @@ verbose_printk("btrfs: send_chmod %llu mode=%llu\n", ino, mode);
 
 static int send_chown(struct send_ctx *sctx, u64 ino, u64 gen, u64 uid, u64 gid)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret = 0;
 	struct fs_path *p;
 
-verbose_printk("btrfs: send_chown %llu uid=%llu, gid=%llu\n", ino, uid, gid);
+	btrfs_debug(fs_info, "send_chown %llu uid=%llu, gid=%llu",
+		    ino, uid, gid);
 
 	p = fs_path_alloc();
 	if (!p)
@@ -2508,6 +2514,7 @@ verbose_printk("btrfs: send_chown %llu uid=%llu, gid=%llu\n", ino, uid, gid);
 
 static int send_utimes(struct send_ctx *sctx, u64 ino, u64 gen)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret = 0;
 	struct fs_path *p = NULL;
 	struct btrfs_inode_item *ii;
@@ -2516,7 +2523,7 @@ static int send_utimes(struct send_ctx *sctx, u64 ino, u64 gen)
 	struct btrfs_key key;
 	int slot;
 
-verbose_printk("btrfs: send_utimes %llu\n", ino);
+	btrfs_debug(fs_info, "send_utimes %llu", ino);
 
 	p = fs_path_alloc();
 	if (!p)
@@ -2570,6 +2577,7 @@ verbose_printk("btrfs: send_utimes %llu\n", ino);
  */
 static int send_create_inode(struct send_ctx *sctx, u64 ino)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret = 0;
 	struct fs_path *p;
 	int cmd;
@@ -2577,7 +2585,7 @@ static int send_create_inode(struct send_ctx *sctx, u64 ino)
 	u64 mode;
 	u64 rdev;
 
-verbose_printk("btrfs: send_create_inode %llu\n", ino);
+	btrfs_debug(fs_info, "send_create_inode %llu", ino);
 
 	p = fs_path_alloc();
 	if (!p)
@@ -3635,6 +3643,7 @@ static int wait_for_parent_move(struct send_ctx *sctx,
  */
 static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret = 0;
 	struct recorded_ref *cur;
 	struct recorded_ref *cur2;
@@ -3647,7 +3656,7 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 	u64 last_dir_ino_rm = 0;
 	bool can_rename = true;
 
-verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
+	btrfs_debug(fs_info, "process_recorded_refs %llu", sctx->cur_ino);
 
 	/*
 	 * This should never happen as the root dir always has the same ref
@@ -4657,6 +4666,7 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
  */
 static int send_write(struct send_ctx *sctx, u64 offset, u32 len)
 {
+	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
 	int ret = 0;
 	struct fs_path *p;
 	ssize_t num_read = 0;
@@ -4665,7 +4675,7 @@ static int send_write(struct send_ctx *sctx, u64 offset, u32 len)
 	if (!p)
 		return -ENOMEM;
 
-verbose_printk("btrfs: send_write offset=%llu, len=%d\n", offset, len);
+	btrfs_debug(fs_info, "send_write offset=%llu, len=%d", offset, len);
 
 	num_read = fill_read_buf(sctx, offset, len);
 	if (num_read <= 0) {
@@ -4707,9 +4717,10 @@ static int send_clone(struct send_ctx *sctx,
 	struct fs_path *p;
 	u64 gen;
 
-verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, clone_inode=%llu, clone_offset=%llu\n",
-		offset, len, clone_root->root->objectid, clone_root->ino,
-		clone_root->offset);
+	btrfs_debug(sctx->send_root->fs_info,
+		    "send_clone offset=%llu, len=%d, clone_root=%llu, clone_inode=%llu, clone_offset=%llu",
+		    offset, len, clone_root->root->objectid, clone_root->ino,
+		    clone_root->offset);
 
 	p = fs_path_alloc();
 	if (!p)

commit 5d163e0e68ce743e1e919ddd3264c96ac02e9026
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:00 2016 -0400

    btrfs: unsplit printed strings
    
    CodingStyle chapter 2:
    "[...] never break user-visible strings such as printk messages,
    because that breaks the ability to grep for them."
    
    This patch unsplits user-visible strings.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index bc7185c20f32..1f4e78d8b0fe 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1439,16 +1439,13 @@ static int find_extent_clone(struct send_ctx *sctx,
 	if (!backref_ctx->found_itself) {
 		/* found a bug in backref code? */
 		ret = -EIO;
-		btrfs_err(sctx->send_root->fs_info, "did not find backref in "
-				"send_root. inode=%llu, offset=%llu, "
-				"disk_byte=%llu found extent=%llu",
+		btrfs_err(sctx->send_root->fs_info,
+			  "did not find backref in send_root. inode=%llu, offset=%llu, disk_byte=%llu found extent=%llu",
 				ino, data_offset, disk_byte, found_key.objectid);
 		goto out;
 	}
 
-verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, "
-		"ino=%llu, "
-		"num_bytes=%llu, logical=%llu\n",
+verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, ino=%llu, num_bytes=%llu, logical=%llu\n",
 		data_offset, ino, num_bytes, logical);
 
 	if (!backref_ctx->found)
@@ -4710,9 +4707,8 @@ static int send_clone(struct send_ctx *sctx,
 	struct fs_path *p;
 	u64 gen;
 
-verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
-	       "clone_inode=%llu, clone_offset=%llu\n", offset, len,
-		clone_root->root->objectid, clone_root->ino,
+verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, clone_inode=%llu, clone_offset=%llu\n",
+		offset, len, clone_root->root->objectid, clone_root->ino,
 		clone_root->offset);
 
 	p = fs_path_alloc();

commit e2c8990734874061d144184dbf0d66e2827c216f
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Tue Sep 13 04:35:52 2016 +0900

    btrfs: squash lines for simple wrapper functions
    
    Remove unneeded variables and assignments.
    
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a87675ffd02b..bc7185c20f32 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4398,12 +4398,8 @@ static int process_new_xattr(struct send_ctx *sctx)
 
 static int process_deleted_xattr(struct send_ctx *sctx)
 {
-	int ret;
-
-	ret = iterate_dir_item(sctx->parent_root, sctx->right_path,
-			       sctx->cmp_key, __process_deleted_xattr, sctx);
-
-	return ret;
+	return iterate_dir_item(sctx->parent_root, sctx->right_path,
+				sctx->cmp_key, __process_deleted_xattr, sctx);
 }
 
 struct find_xattr_ctx {

commit 3dc09ec895f098cedd789a620c90ff1bf7f779a1
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed Aug 24 11:57:52 2016 -0400

    Btrfs: kill invalid ASSERT() in process_all_refs()
    
    Suppose you have the following tree in snap1 on a file system mounted with -o
    inode_cache so that inode numbers are recycled
    
    └── [    258]  a
        └── [    257]  b
    
    and then you remove b, rename a to c, and then re-create b in c so you have the
    following tree
    
    └── [    258]  c
        └── [    257]  b
    
    and then you try to do an incremental send you will hit
    
    ASSERT(pending_move == 0);
    
    in process_all_refs().  This is because we assume that any recycling of inodes
    will not have a pending change in our path, which isn't the case.  This is the
    case for the DELETE side, since we want to remove the old file using the old
    path, but on the create side we could have a pending move and need to do the
    normal pending rename dance.  So remove this ASSERT() and put a comment about
    why we ignore pending_move.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index efe129fe2678..a87675ffd02b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4268,10 +4268,12 @@ static int process_all_refs(struct send_ctx *sctx,
 	}
 	btrfs_release_path(path);
 
+	/*
+	 * We don't actually care about pending_move as we are simply
+	 * re-creating this inode and will be rename'ing it into place once we
+	 * rename the parent directory.
+	 */
 	ret = process_recorded_refs(sctx, &pending_move);
-	/* Only applicable to an incremental send. */
-	ASSERT(pending_move == 0);
-
 out:
 	btrfs_free_path(path);
 	return ret;

commit 951555856b88aa47bc238de6b4c6e97bfd9d36df
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Aug 1 01:50:37 2016 +0100

    Btrfs: send, don't bug on inconsistent snapshots
    
    When doing an incremental send, if we find a new/modified/deleted extent,
    reference or xattr without having previously processed the corresponding
    inode item we end up exexuting a BUG_ON(). This is because whenever an
    extent, xattr or reference is added, modified or deleted, we always expect
    to have the corresponding inode item updated. However there are situations
    where this will not happen due to transient -ENOMEM or -ENOSPC errors when
    doing delayed inode updates.
    
    For example, when punching holes we can succeed in deleting and modifying
    (shrinking) extents but later fail to do the delayed inode update. So after
    such failure we close our transaction handle and right after a snapshot of
    the fs/subvol tree can be made and used later for a send operation. The
    same thing can happen during truncate, link, unlink, and xattr related
    operations.
    
    So instead of executing a BUG_ON, make send return an -EIO error and print
    an informative error message do dmesg/syslog.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 2db8dc89ca41..efe129fe2678 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -273,6 +273,39 @@ struct name_cache_entry {
 	char name[];
 };
 
+static void inconsistent_snapshot_error(struct send_ctx *sctx,
+					enum btrfs_compare_tree_result result,
+					const char *what)
+{
+	const char *result_string;
+
+	switch (result) {
+	case BTRFS_COMPARE_TREE_NEW:
+		result_string = "new";
+		break;
+	case BTRFS_COMPARE_TREE_DELETED:
+		result_string = "deleted";
+		break;
+	case BTRFS_COMPARE_TREE_CHANGED:
+		result_string = "updated";
+		break;
+	case BTRFS_COMPARE_TREE_SAME:
+		ASSERT(0);
+		result_string = "unchanged";
+		break;
+	default:
+		ASSERT(0);
+		result_string = "unexpected";
+	}
+
+	btrfs_err(sctx->send_root->fs_info,
+		  "Send: inconsistent snapshot, found %s %s for inode %llu without updated inode item, send root is %llu, parent root is %llu",
+		  result_string, what, sctx->cmp_key->objectid,
+		  sctx->send_root->root_key.objectid,
+		  (sctx->parent_root ?
+		   sctx->parent_root->root_key.objectid : 0));
+}
+
 static int is_waiting_for_move(struct send_ctx *sctx, u64 ino);
 
 static struct waiting_dir_move *
@@ -5711,7 +5744,10 @@ static int changed_ref(struct send_ctx *sctx,
 {
 	int ret = 0;
 
-	BUG_ON(sctx->cur_ino != sctx->cmp_key->objectid);
+	if (sctx->cur_ino != sctx->cmp_key->objectid) {
+		inconsistent_snapshot_error(sctx, result, "reference");
+		return -EIO;
+	}
 
 	if (!sctx->cur_inode_new_gen &&
 	    sctx->cur_ino != BTRFS_FIRST_FREE_OBJECTID) {
@@ -5736,7 +5772,10 @@ static int changed_xattr(struct send_ctx *sctx,
 {
 	int ret = 0;
 
-	BUG_ON(sctx->cur_ino != sctx->cmp_key->objectid);
+	if (sctx->cur_ino != sctx->cmp_key->objectid) {
+		inconsistent_snapshot_error(sctx, result, "xattr");
+		return -EIO;
+	}
 
 	if (!sctx->cur_inode_new_gen && !sctx->cur_inode_deleted) {
 		if (result == BTRFS_COMPARE_TREE_NEW)
@@ -5760,7 +5799,10 @@ static int changed_extent(struct send_ctx *sctx,
 {
 	int ret = 0;
 
-	BUG_ON(sctx->cur_ino != sctx->cmp_key->objectid);
+	if (sctx->cur_ino != sctx->cmp_key->objectid) {
+		inconsistent_snapshot_error(sctx, result, "extent");
+		return -EIO;
+	}
 
 	if (!sctx->cur_inode_new_gen && !sctx->cur_inode_deleted) {
 		if (result != BTRFS_COMPARE_TREE_DELETED)

commit 15b253eace1f98dabbc6e03f6793fcf8603b1655
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Jul 2 05:43:46 2016 +0100

    Btrfs: send, avoid incorrect leaf accesses when sending utimes operations
    
    The caller of send_utimes() is supposed to be sure that the inode number
    it passes to this function does actually exists in the send snapshot.
    However due to logic/algorithm bugs (such as the one fixed by the patch
    titled "Btrfs: send, fix invalid leaf accesses due to incorrect utimes
    operations"), this might not be the case and when that happens it makes
    send_utimes() access use an unrelated leaf item as the target inode item
    or access beyond a leaf's boundaries (when the leaf is full and
    path->slots[0] matches the number of items in the leaf).
    
    So if the call to btrfs_search_slot() done by send_utimes() does not find
    the inode item, just make sure send_utimes() returns -ENOENT and does not
    silently accesses unrelated leaf items or does invalid leaf accesses, also
    allowing us to easialy and deterministically catch such algorithmic/logic
    bugs.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 8b653967b163..2db8dc89ca41 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2502,6 +2502,8 @@ verbose_printk("btrfs: send_utimes %llu\n", ino);
 	key.type = BTRFS_INODE_ITEM_KEY;
 	key.offset = 0;
 	ret = btrfs_search_slot(NULL, sctx->send_root, &key, path, 0, 0);
+	if (ret > 0)
+		ret = -ENOENT;
 	if (ret < 0)
 		goto out;
 

commit 764433a12e78e1a2161793c02eceafdfed2d652b
Author: Robbie Ko <robbieko@synology.com>
Date:   Tue Jun 23 18:39:50 2015 +0800

    Btrfs: send, fix invalid leaf accesses due to incorrect utimes operations
    
    During an incremental send, if we have delayed rename operations for inodes
    that were children of directories which were removed in the send snapshot,
    we can end up accessing incorrect items in a leaf or accessing beyond the
    last item of the leaf due to issuing utimes operations for the removed
    inodes. Consider the following example:
    
      Parent snapshot:
      .                                                             (ino 256)
      |--- a/                                                       (ino 257)
      |    |--- c/                                                  (ino 262)
      |
      |--- b/                                                       (ino 258)
      |    |--- d/                                                  (ino 263)
      |
      |--- del/                                                     (ino 261)
            |--- x/                                                 (ino 259)
            |--- y/                                                 (ino 260)
    
      Send snapshot:
    
      .                                                             (ino 256)
      |--- a/                                                       (ino 257)
      |
      |--- b/                                                       (ino 258)
      |
      |--- c/                                                       (ino 262)
      |    |--- y/                                                  (ino 260)
      |
      |--- d/                                                       (ino 263)
           |--- x/                                                  (ino 259)
    
    1) When processing inodes 259 and 260, we end up delaying their rename
       operations because their parents, inodes 263 and 262 respectively, were
       not yet processed and therefore not yet renamed;
    
    2) When processing inode 262, its rename operation is issued and right
       after the rename operation for inode 260 is issued. However right after
       issuing the rename operation for inode 260, at send.c:apply_dir_move(),
       we issue utimes operations for all current and past parents of inode
       260. This means we try to send a utimes operation for its old parent,
       inode 261 (deleted in the send snapshot), which does not cause any
       immediate and deterministic failure, because when the target inode is
       not found in the send snapshot, the send.c:send_utimes() function
       ignores it and uses the leaf region pointed to by path->slots[0],
       which can be any unrelated item (belonging to other inode) or it can
       be a region outside the leaf boundaries, if the leaf is full and
       path->slots[0] matches the number of items in the leaf. So we end
       up either successfully sending a utimes operation, which is fine
       and irrelevant because the old parent (inode 261) will end up being
       deleted later, or we end up doing an invalid memory access tha
       crashes the kernel.
    
    So fix this by making apply_dir_move() issue utimes operations only for
    parents that still exist in the send snapshot. In a separate patch we
    will make send_utimes() return an error (-ENOENT) if the given inode
    does not exists in the send snapshot.
    
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    [Rewrote change log to be more detailed and better organized]
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e552c33e72c0..8b653967b163 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3270,8 +3270,18 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	 * and old parent(s).
 	 */
 	list_for_each_entry(cur, &pm->update_refs, list) {
-		if (cur->dir == rmdir_ino)
+		/*
+		 * The parent inode might have been deleted in the send snapshot
+		 */
+		ret = get_inode_info(sctx->send_root, cur->dir, NULL,
+				     NULL, NULL, NULL, NULL, NULL);
+		if (ret == -ENOENT) {
+			ret = 0;
 			continue;
+		}
+		if (ret < 0)
+			goto out;
+
 		ret = send_utimes(sctx, cur->dir, cur->dir_gen);
 		if (ret < 0)
 			goto out;

commit 443f9d266c4848a3a9ea386f66c4bed2f5997940
Author: Robbie Ko <robbieko@synology.com>
Date:   Mon Jun 22 17:08:45 2015 +0800

    Btrfs: send, fix warning due to late freeing of orphan_dir_info structures
    
    Under certain situations, when doing an incremental send, we can end up
    not freeing orphan_dir_info structures as soon as they are no longer
    needed. Instead we end up freeing them only after finishing the send
    stream, which causes a warning to be emitted:
    
    [282735.229200] ------------[ cut here ]------------
    [282735.229968] WARNING: CPU: 9 PID: 10588 at fs/btrfs/send.c:6298 btrfs_ioctl_send+0xe2f/0xe51 [btrfs]
    [282735.231282] Modules linked in: btrfs crc32c_generic xor raid6_pq acpi_cpufreq tpm_tis ppdev tpm parport_pc psmouse parport sg pcspkr i2c_piix4 i2c_core evdev processor serio_raw button loop autofs4 ext4 crc16 jbd2 mbcache sr_mod cdrom sd_mod ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring virtio e1000 scsi_mod floppy [last unloaded: btrfs]
    [282735.237130] CPU: 9 PID: 10588 Comm: btrfs Tainted: G        W       4.6.0-rc7-btrfs-next-31+ #1
    [282735.239309] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [282735.240160]  0000000000000000 ffff880224273ca8 ffffffff8126b42c 0000000000000000
    [282735.240160]  0000000000000000 ffff880224273ce8 ffffffff81052b14 0000189a24273ac8
    [282735.240160]  ffff8802210c9800 0000000000000000 0000000000000001 0000000000000000
    [282735.240160] Call Trace:
    [282735.240160]  [<ffffffff8126b42c>] dump_stack+0x67/0x90
    [282735.240160]  [<ffffffff81052b14>] __warn+0xc2/0xdd
    [282735.240160]  [<ffffffff81052beb>] warn_slowpath_null+0x1d/0x1f
    [282735.240160]  [<ffffffffa03c99d5>] btrfs_ioctl_send+0xe2f/0xe51 [btrfs]
    [282735.240160]  [<ffffffffa0398358>] btrfs_ioctl+0x14f/0x1f81 [btrfs]
    [282735.240160]  [<ffffffff8108e456>] ? arch_local_irq_save+0x9/0xc
    [282735.240160]  [<ffffffff8118da05>] vfs_ioctl+0x18/0x34
    [282735.240160]  [<ffffffff8118e00c>] do_vfs_ioctl+0x550/0x5be
    [282735.240160]  [<ffffffff81196f0c>] ? __fget+0x6b/0x77
    [282735.240160]  [<ffffffff81196fa1>] ? __fget_light+0x62/0x71
    [282735.240160]  [<ffffffff8118e0d1>] SyS_ioctl+0x57/0x79
    [282735.240160]  [<ffffffff8149e025>] entry_SYSCALL_64_fastpath+0x18/0xa8
    [282735.240160]  [<ffffffff81100c6b>] ? time_hardirqs_off+0x9/0x14
    [282735.240160]  [<ffffffff8108e87d>] ? trace_hardirqs_off_caller+0x1f/0xaa
    [282735.256343] ---[ end trace a4539270c8056f93 ]---
    
    Consider the following example:
    
      Parent snapshot:
    
      .                                                             (ino 256)
      |--- a/                                                       (ino 257)
      |    |--- c/                                                  (ino 260)
      |
      |--- del/                                                     (ino 259)
            |--- tmp/                                               (ino 258)
            |--- x/                                                 (ino 261)
            |--- y/                                                 (ino 262)
    
      Send snapshot:
    
      .                                                             (ino 256)
      |--- a/                                                       (ino 257)
      |    |--- x/                                                  (ino 261)
      |    |--- y/                                                  (ino 262)
      |
      |--- c/                                                       (ino 260)
           |--- tmp/                                                (ino 258)
    
    1) When processing inode 258, we end up delaying its rename operation
       because it has an ancestor (in the send snapshot) that has a higher
       inode number (inode 260) which was also renamed in the send snapshot,
       therefore we delay the rename of inode 258 so that it happens after
       inode 260 is renamed;
    
    2) When processing inode 259, we end up delaying its deletion (rmdir
       operation) because it has a child inode (258) that has its rename
       operation delayed. At this point we allocate an orphan_dir_info
       structure and tag inode 258 so that we later attempt to see if we
       can delete (rmdir) inode 259 once inode 258 is renamed;
    
    3) When we process inode 260, after renaming it we finally do the rename
       operation for inode 258. Once we issue the rename operation for inode
       258 we notice that this inode was tagged so that we attempt to see
       if at this point we can delete (rmdir) inode 259. But at this point
       we can not still delete inode 259 because it has 2 children, inodes
       261 and 262, that were not yet processed and therefore not yet
       moved (renamed) away from inode 259. We end up not freeing the
       orphan_dir_info structure allocated in step 2;
    
    4) We process inodes 261 and 262, and once we move/rename inode 262
       we issue the rmdir operation for inode 260;
    
    5) We finish the send stream and notice that red black tree that
       contains orphan_dir_info structures is not empty, so we emit
       a warning and then free any orphan_dir_structures left.
    
    So fix this by freeing an orphan_dir_info structure once we try to
    apply a pending rename operation if we can not delete yet the tagged
    directory.
    
    A test case for fstests follows soon.
    
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    [Modified changelog to be more detailed and easier to understand]

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 4115aba001ad..e552c33e72c0 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2947,6 +2947,10 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 		}
 
 		if (loc.objectid > send_progress) {
+			struct orphan_dir_info *odi;
+
+			odi = get_orphan_dir_info(sctx, dir);
+			free_orphan_dir_info(sctx, odi);
 			ret = 0;
 			goto out;
 		}

commit 99ea42ddb13bad6188d4f183f8866cacd14fa141
Author: Robbie Ko <robbieko@synology.com>
Date:   Tue Jun 23 18:39:49 2015 +0800

    Btrfs: incremental send, fix premature rmdir operations
    
    Under certain situations, an incremental send operation can contain
    a rmdir operation that will make the receiving end fail when attempting
    to execute it, because the target directory is not yet empty.
    
    Consider the following example:
    
      Parent snapshot:
    
      .                                                             (ino 256)
      |--- a/                                                       (ino 257)
      |    |--- c/                                                  (ino 260)
      |
      |--- del/                                                     (ino 259)
            |--- tmp/                                               (ino 258)
            |--- x/                                                 (ino 261)
    
      Send snapshot:
    
      .                                                             (ino 256)
      |--- a/                                                       (ino 257)
      |    |--- x/                                                  (ino 261)
      |
      |--- c/                                                       (ino 260)
           |--- tmp/                                                (ino 258)
    
    1) When processing inode 258, we delay its rename operation because inode
       260 is its new parent in the send snapshot and it was not yet renamed
       (since 260 > 258, that is, beyond the current progress);
    
    2) When processing inode 259, we realize we can not yet send an rmdir
       operation (against inode 259) because inode 258 was still not yet
       renamed/moved away from inode 259. Therefore we update data structures
       so that after inode 258 is renamed, we try again to see if we can
       finally send an rmdir operation for inode 259;
    
    3) When we process inode 260, we send a rename operation for it followed
       by a rename operation for inode 258. Once we send the rename operation
       for inode 258 we then check if we can finally issue an rmdir for its
       previous parent, inode 259, by calling the can_rmdir() function with
       a value of sctx->cur_ino + 1 (260 + 1 = 261) for its "progress"
       argument. This makes can_rmdir() return true (value 1) because even
       though there's still a child inode of inode 259 that was not yet
       renamed/moved, which is inode 261, the given value of progress (261)
       is not lower then 261 (that is, not lower than the inode number of
       some child of inode 259). So we end up sending a rmdir operation for
       inode 259 before its child inode 261 is processed and renamed.
    
    So fix this by passing the correct progress value to the call to
    can_rmdir() from within apply_dir_move() (where we issue delayed rename
    operations), which should match stcx->cur_ino (the number of the inode
    currently being processed) and not sctx->cur_ino + 1.
    
    A test case for fstests follows soon.
    
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    [Rewrote change log to be more detailed, clear and well formatted]
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 3d6a4dde8fe4..4115aba001ad 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3236,7 +3236,7 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 			/* already deleted */
 			goto finish;
 		}
-		ret = can_rmdir(sctx, rmdir_ino, odi->gen, sctx->cur_ino + 1);
+		ret = can_rmdir(sctx, rmdir_ino, odi->gen, sctx->cur_ino);
 		if (ret < 0)
 			goto out;
 		if (!ret)

commit 4122ea64f877f632390bca1886c8a6f666f28398
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Jun 27 16:54:44 2016 +0100

    Btrfs: incremental send, fix invalid paths for rename operations
    
    Example scenario:
    
      Parent snapshot:
    
      .                                                       (ino 277)
      |---- tmp/                                              (ino 278)
      |---- pre/                                              (ino 280)
      |      |---- wait_dir/                                  (ino 281)
      |
      |---- desc/                                             (ino 282)
      |---- ance/                                             (ino 283)
      |       |---- below_ance/                               (ino 279)
      |
      |---- other_dir/                                        (ino 284)
    
      Send snapshot:
    
      .                                                       (ino 277)
      |---- tmp/                                              (ino 278)
             |---- other_dir/                                 (ino 284)
                       |---- below_ance/                      (ino 279)
                       |            |---- pre/                (ino 280)
                       |
                       |---- wait_dir/                        (ino 281)
                                  |---- desc/                 (ino 282)
                                          |---- ance/         (ino 283)
    
    While computing the send stream the following steps happen:
    
    1) While processing inode 279 we end up delaying its rename operation
       because its new parent in the send snapshot, inode 284, was not
       yet processed and therefore not yet renamed;
    
    2) Later when processing inode 280 we end up renaming it immediately to
       "ance/below_once/pre" and not delay its rename operation because its
       new parent (inode 279 in the send snapshot) has its rename operation
       delayed and inode 280 is not an encestor of inode 279 (its parent in
       the send snapshot) in the parent snapshot;
    
    3) When processing inode 281 we end up delaying its rename operation
       because its new parent in the send snapshot, inode 284, was not yet
       processed and therefore not yet renamed;
    
    4) When processing inode 282 we do not delay its rename operation because
       its parent in the send snapshot, inode 281, already has its own rename
       operation delayed and our current inode (282) is not an ancestor of
       inode 281 in the parent snapshot. Therefore inode 282 is renamed to
       "ance/below_ance/pre/wait_dir";
    
    5) When processing inode 283 we realize that we can rename it because one
       of its ancestors in the send snapshot, inode 281, has its rename
       operation delayed and inode 283 is not an ancestor of inode 281 in the
       parent snapshot. So a rename operation to rename inode 283 to
       "ance/below_ance/pre/wait_dir/desc/ance" is issued. This path is
       invalid due to a missing path building loop that was undetected by
       the incremental send implementation, as inode 283 ends up getting
       included twice in the path (once with its path in the parent snapshot).
       Therefore its rename operation must wait before the ancestor inode 284
       is renamed.
    
    Fix this by not terminating the rename dependency checks when we find an
    ancestor, in the send snapshot, that has its rename operation delayed. So
    that we continue doing the same checks if the current inode is not an
    ancestor, in the parent snapshot, of an ancestor in the send snapshot we
    are processing in the loop.
    
    The problem and reproducer were reported by Robbie Ko, as part of a patch
    titled "Btrfs: incremental send, avoid ancestor rename to descendant".
    However the fix was unnecessarily complicated and can be addressed with
    much less code and effort.
    
    Reported-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 0dc05bb856ff..3d6a4dde8fe4 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3534,7 +3534,8 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 			ret = is_ancestor(sctx->parent_root,
 					  sctx->cur_ino, sctx->cur_inode_gen,
 					  ino, path_before);
-			break;
+			if (ret)
+				break;
 		}
 
 		fs_path_reset(path_before);

commit 7969e77a73164b418da851cbae35cdd6c1b43fee
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Jun 17 17:13:36 2016 +0100

    Btrfs: send, add missing error check for calls to path_loop()
    
    The function path_loop() can return a negative integer, signaling an
    error, 0 if there's no path loop and 1 if there's a path loop. We were
    treating any non zero values as meaning that a path loop exists. Fix
    this by explicitly checking for errors and gracefully return them to
    user space.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 993e1bab0a6b..0dc05bb856ff 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3200,6 +3200,8 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 
 	sctx->send_progress = sctx->cur_ino + 1;
 	ret = path_loop(sctx, name, pm->ino, pm->gen, &ancestor);
+	if (ret < 0)
+		goto out;
 	if (ret) {
 		LIST_HEAD(deleted_refs);
 		ASSERT(ancestor > BTRFS_FIRST_FREE_OBJECTID);

commit 801bec365e0e19f2ba066cd3e25a67dee21b4aae
Author: Robbie Ko <robbieko@synology.com>
Date:   Tue Jun 23 18:39:46 2015 +0800

    Btrfs: send, fix failure to move directories with the same name around
    
    When doing an incremental send we can end up not moving directories that
    have the same name. This happens when the same parent directory has
    different child directories with the same name in the parent and send
    snapshots.
    
    For example, consider the following scenario:
    
      Parent snapshot:
    
      .                   (ino 256)
      |---- d/            (ino 257)
      |     |--- p1/      (ino 258)
      |
      |---- p1/           (ino 259)
    
      Send snapshot:
    
      .                    (ino 256)
      |--- d/              (ino 257)
           |--- p1/        (ino 259)
                 |--- p1/  (ino 258)
    
    The directory named "d" (inode 257) has in both snapshots an entry with
    the name "p1" but it refers to different inodes in both snapshots (inode
    258 in the parent snapshot and inode 259 in the send snapshot). When
    attempting to move inode 258, the operation is delayed because its new
    parent, inode 259, was not yet moved/renamed (as the stream is currently
    processing inode 258). Then when processing inode 259, we also end up
    delaying its move/rename operation so that it happens after inode 258 is
    moved/renamed. This decision to delay the move/rename rename operation
    of inode 259 is due to the fact that the new parent inode (257) still
    has inode 258 as its child, which has the same name has inode 259. So
    we end up with inode 258 move/rename operation waiting for inode's 259
    move/rename operation, which in turn it waiting for inode's 258
    move/rename. This results in ending the send stream without issuing
    move/rename operations for inodes 258 and 259 and generating the
    following warnings in syslog/dmesg:
    
    [148402.979747] ------------[ cut here ]------------
    [148402.980588] WARNING: CPU: 14 PID: 4117 at fs/btrfs/send.c:6177 btrfs_ioctl_send+0xe03/0xe51 [btrfs]
    [148402.981928] Modules linked in: btrfs crc32c_generic xor raid6_pq acpi_cpufreq tpm_tis ppdev tpm parport_pc psmouse parport sg pcspkr i2c_piix4 i2c_core evdev processor serio_raw button loop autofs4 ext4 crc16 jbd2 mbcache sr_mod cdrom sd_mod ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring virtio e1000 scsi_mod floppy [last unloaded: btrfs]
    [148402.986999] CPU: 14 PID: 4117 Comm: btrfs Tainted: G        W       4.6.0-rc7-btrfs-next-31+ #1
    [148402.988136] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [148402.988136]  0000000000000000 ffff88022139fca8 ffffffff8126b42c 0000000000000000
    [148402.988136]  0000000000000000 ffff88022139fce8 ffffffff81052b14 000018212139fac8
    [148402.988136]  ffff88022b0db400 0000000000000000 0000000000000001 0000000000000000
    [148402.988136] Call Trace:
    [148402.988136]  [<ffffffff8126b42c>] dump_stack+0x67/0x90
    [148402.988136]  [<ffffffff81052b14>] __warn+0xc2/0xdd
    [148402.988136]  [<ffffffff81052beb>] warn_slowpath_null+0x1d/0x1f
    [148402.988136]  [<ffffffffa04bc831>] btrfs_ioctl_send+0xe03/0xe51 [btrfs]
    [148402.988136]  [<ffffffffa048b358>] btrfs_ioctl+0x14f/0x1f81 [btrfs]
    [148402.988136]  [<ffffffff8108e456>] ? arch_local_irq_save+0x9/0xc
    [148402.988136]  [<ffffffff8108eb51>] ? __lock_is_held+0x3c/0x57
    [148402.988136]  [<ffffffff8118da05>] vfs_ioctl+0x18/0x34
    [148402.988136]  [<ffffffff8118e00c>] do_vfs_ioctl+0x550/0x5be
    [148402.988136]  [<ffffffff81196f0c>] ? __fget+0x6b/0x77
    [148402.988136]  [<ffffffff81196fa1>] ? __fget_light+0x62/0x71
    [148402.988136]  [<ffffffff8118e0d1>] SyS_ioctl+0x57/0x79
    [148402.988136]  [<ffffffff8149e025>] entry_SYSCALL_64_fastpath+0x18/0xa8
    [148402.988136]  [<ffffffff8108e89d>] ? trace_hardirqs_off_caller+0x3f/0xaa
    [148403.011373] ---[ end trace a4539270c8056f8b ]---
    [148403.012296] ------------[ cut here ]------------
    [148403.013071] WARNING: CPU: 14 PID: 4117 at fs/btrfs/send.c:6194 btrfs_ioctl_send+0xe19/0xe51 [btrfs]
    [148403.014447] Modules linked in: btrfs crc32c_generic xor raid6_pq acpi_cpufreq tpm_tis ppdev tpm parport_pc psmouse parport sg pcspkr i2c_piix4 i2c_core evdev processor serio_raw button loop autofs4 ext4 crc16 jbd2 mbcache sr_mod cdrom sd_mod ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring virtio e1000 scsi_mod floppy [last unloaded: btrfs]
    [148403.019708] CPU: 14 PID: 4117 Comm: btrfs Tainted: G        W       4.6.0-rc7-btrfs-next-31+ #1
    [148403.020104] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [148403.020104]  0000000000000000 ffff88022139fca8 ffffffff8126b42c 0000000000000000
    [148403.020104]  0000000000000000 ffff88022139fce8 ffffffff81052b14 000018322139fac8
    [148403.020104]  ffff88022b0db400 0000000000000000 0000000000000001 0000000000000000
    [148403.020104] Call Trace:
    [148403.020104]  [<ffffffff8126b42c>] dump_stack+0x67/0x90
    [148403.020104]  [<ffffffff81052b14>] __warn+0xc2/0xdd
    [148403.020104]  [<ffffffff81052beb>] warn_slowpath_null+0x1d/0x1f
    [148403.020104]  [<ffffffffa04bc847>] btrfs_ioctl_send+0xe19/0xe51 [btrfs]
    [148403.020104]  [<ffffffffa048b358>] btrfs_ioctl+0x14f/0x1f81 [btrfs]
    [148403.020104]  [<ffffffff8108e456>] ? arch_local_irq_save+0x9/0xc
    [148403.020104]  [<ffffffff8108eb51>] ? __lock_is_held+0x3c/0x57
    [148403.020104]  [<ffffffff8118da05>] vfs_ioctl+0x18/0x34
    [148403.020104]  [<ffffffff8118e00c>] do_vfs_ioctl+0x550/0x5be
    [148403.020104]  [<ffffffff81196f0c>] ? __fget+0x6b/0x77
    [148403.020104]  [<ffffffff81196fa1>] ? __fget_light+0x62/0x71
    [148403.020104]  [<ffffffff8118e0d1>] SyS_ioctl+0x57/0x79
    [148403.020104]  [<ffffffff8149e025>] entry_SYSCALL_64_fastpath+0x18/0xa8
    [148403.020104]  [<ffffffff8108e89d>] ? trace_hardirqs_off_caller+0x3f/0xaa
    [148403.038981] ---[ end trace a4539270c8056f8c ]---
    
    There's another issue caused by similar (but more complex) changes in the
    directory hierarchy that makes move/rename operations fail, described with
    the following example:
    
      Parent snapshot:
    
      .
      |---- a/                                                   (ino 262)
      |     |---- c/                                             (ino 268)
      |
      |---- d/                                                   (ino 263)
            |---- ance/                                          (ino 267)
                    |---- e/                                     (ino 264)
                    |---- f/                                     (ino 265)
                    |---- ance/                                  (ino 266)
    
      Send snapshot:
    
      .
      |---- a/                                                   (ino 262)
      |---- c/                                                   (ino 268)
      |     |---- ance/                                          (ino 267)
      |
      |---- d/                                                   (ino 263)
      |     |---- ance/                                          (ino 266)
      |
      |---- f/                                                   (ino 265)
            |---- e/                                             (ino 264)
    
    When the inode 265 is processed, the path for inode 267 is computed, which
    at that time corresponds to "d/ance", and it's stored in the names cache.
    Later on when processing inode 266, we end up orphanizing (renaming to a
    name matching the pattern o<ino>-<gen>-<seq>) inode 267 because it has
    the same name as inode 266 and it's currently a child of the new parent
    directory (inode 263) for inode 266. After the orphanization and while we
    are still processing inode 266, a rename operation for inode 266 is
    generated. However the source path for that rename operation is incorrect
    because it ends up using the old, pre-orphanization, name of inode 267.
    The no longer valid name for inode 267 was previously cached when
    processing inode 265 and it remains usable and considered valid until
    the inode currently being processed has a number greater than 267.
    This resulted in the receiving side failing with the following error:
    
      ERROR: rename d/ance/ance -> d/ance failed: No such file or directory
    
    So fix these issues by detecting such circular dependencies for rename
    operations and by clearing the cached name of an inode once the inode
    is orphanized.
    
    A test case for fstests will follow soon.
    
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    [Rewrote change log to be more detailed and organized, and improved
     comments]
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index b71dd298385c..993e1bab0a6b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -231,7 +231,6 @@ struct pending_dir_move {
 	u64 parent_ino;
 	u64 ino;
 	u64 gen;
-	bool is_orphan;
 	struct list_head update_refs;
 };
 
@@ -1861,7 +1860,8 @@ static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 	 * was already unlinked/moved, so we can safely assume that we will not
 	 * overwrite anything at this point in time.
 	 */
-	if (other_inode > sctx->send_progress) {
+	if (other_inode > sctx->send_progress ||
+	    is_waiting_for_move(sctx, other_inode)) {
 		ret = get_inode_info(sctx->parent_root, other_inode, NULL,
 				who_gen, NULL, NULL, NULL, NULL);
 		if (ret < 0)
@@ -3047,7 +3047,6 @@ static int add_pending_dir_move(struct send_ctx *sctx,
 	pm->parent_ino = parent_ino;
 	pm->ino = ino;
 	pm->gen = ino_gen;
-	pm->is_orphan = is_orphan;
 	INIT_LIST_HEAD(&pm->list);
 	INIT_LIST_HEAD(&pm->update_refs);
 	RB_CLEAR_NODE(&pm->node);
@@ -3113,6 +3112,48 @@ static struct pending_dir_move *get_pending_dir_moves(struct send_ctx *sctx,
 	return NULL;
 }
 
+static int path_loop(struct send_ctx *sctx, struct fs_path *name,
+		     u64 ino, u64 gen, u64 *ancestor_ino)
+{
+	int ret = 0;
+	u64 parent_inode = 0;
+	u64 parent_gen = 0;
+	u64 start_ino = ino;
+
+	*ancestor_ino = 0;
+	while (ino != BTRFS_FIRST_FREE_OBJECTID) {
+		fs_path_reset(name);
+
+		if (is_waiting_for_rm(sctx, ino))
+			break;
+		if (is_waiting_for_move(sctx, ino)) {
+			if (*ancestor_ino == 0)
+				*ancestor_ino = ino;
+			ret = get_first_ref(sctx->parent_root, ino,
+					    &parent_inode, &parent_gen, name);
+		} else {
+			ret = __get_cur_name_and_parent(sctx, ino, gen,
+							&parent_inode,
+							&parent_gen, name);
+			if (ret > 0) {
+				ret = 0;
+				break;
+			}
+		}
+		if (ret < 0)
+			break;
+		if (parent_inode == start_ino) {
+			ret = 1;
+			if (*ancestor_ino == 0)
+				*ancestor_ino = ino;
+			break;
+		}
+		ino = parent_inode;
+		gen = parent_gen;
+	}
+	return ret;
+}
+
 static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 {
 	struct fs_path *from_path = NULL;
@@ -3123,6 +3164,8 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	u64 parent_ino, parent_gen;
 	struct waiting_dir_move *dm = NULL;
 	u64 rmdir_ino = 0;
+	u64 ancestor;
+	bool is_orphan;
 	int ret;
 
 	name = fs_path_alloc();
@@ -3135,9 +3178,10 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	dm = get_waiting_dir_move(sctx, pm->ino);
 	ASSERT(dm);
 	rmdir_ino = dm->rmdir_ino;
+	is_orphan = dm->orphanized;
 	free_waiting_dir_move(sctx, dm);
 
-	if (pm->is_orphan) {
+	if (is_orphan) {
 		ret = gen_unique_name(sctx, pm->ino,
 				      pm->gen, from_path);
 	} else {
@@ -3155,6 +3199,22 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 		goto out;
 
 	sctx->send_progress = sctx->cur_ino + 1;
+	ret = path_loop(sctx, name, pm->ino, pm->gen, &ancestor);
+	if (ret) {
+		LIST_HEAD(deleted_refs);
+		ASSERT(ancestor > BTRFS_FIRST_FREE_OBJECTID);
+		ret = add_pending_dir_move(sctx, pm->ino, pm->gen, ancestor,
+					   &pm->update_refs, &deleted_refs,
+					   is_orphan);
+		if (ret < 0)
+			goto out;
+		if (rmdir_ino) {
+			dm = get_waiting_dir_move(sctx, pm->ino);
+			ASSERT(dm);
+			dm->rmdir_ino = rmdir_ino;
+		}
+		goto out;
+	}
 	fs_path_reset(name);
 	to_path = name;
 	name = NULL;
@@ -3325,6 +3385,7 @@ static int wait_for_dest_dir_move(struct send_ctx *sctx,
 	u64 left_gen;
 	u64 right_gen;
 	int ret = 0;
+	struct waiting_dir_move *wdm;
 
 	if (RB_EMPTY_ROOT(&sctx->waiting_dir_moves))
 		return 0;
@@ -3383,7 +3444,8 @@ static int wait_for_dest_dir_move(struct send_ctx *sctx,
 		goto out;
 	}
 
-	if (is_waiting_for_move(sctx, di_key.objectid)) {
+	wdm = get_waiting_dir_move(sctx, di_key.objectid);
+	if (wdm && !wdm->orphanized) {
 		ret = add_pending_dir_move(sctx,
 					   sctx->cur_ino,
 					   sctx->cur_inode_gen,
@@ -3643,11 +3705,26 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 				goto out;
 			if (ret) {
 				struct name_cache_entry *nce;
+				struct waiting_dir_move *wdm;
 
 				ret = orphanize_inode(sctx, ow_inode, ow_gen,
 						cur->full_path);
 				if (ret < 0)
 					goto out;
+
+				/*
+				 * If ow_inode has its rename operation delayed
+				 * make sure that its orphanized name is used in
+				 * the source path when performing its rename
+				 * operation.
+				 */
+				if (is_waiting_for_move(sctx, ow_inode)) {
+					wdm = get_waiting_dir_move(sctx,
+								   ow_inode);
+					ASSERT(wdm);
+					wdm->orphanized = true;
+				}
+
 				/*
 				 * Make sure we clear our orphanized inode's
 				 * name from the name cache. This is because the
@@ -3663,6 +3740,19 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 					name_cache_delete(sctx, nce);
 					kfree(nce);
 				}
+
+				/*
+				 * ow_inode might currently be an ancestor of
+				 * cur_ino, therefore compute valid_path (the
+				 * current path of cur_ino) again because it
+				 * might contain the pre-orphanization name of
+				 * ow_inode, which is no longer valid.
+				 */
+				fs_path_reset(valid_path);
+				ret = get_cur_path(sctx, sctx->cur_ino,
+					   sctx->cur_inode_gen, valid_path);
+				if (ret < 0)
+					goto out;
 			} else {
 				ret = send_unlink(sctx, cur->full_path);
 				if (ret < 0)

commit 42f31734eb7658fd01fb186d56312be869450a42
Merge: e73440868fde 0132761017e0
Author: David Sterba <dsterba@suse.com>
Date:   Wed May 25 22:51:03 2016 +0200

    Merge branch 'cleanups-4.7' into for-chris-4.7-20160525

commit 0132761017e012ab4dc8584d679503f2ba26ca86
Author: Nicholas D Steeves <nsteeves@gmail.com>
Date:   Thu May 19 21:18:45 2016 -0400

    btrfs: fix string and comment grammatical issues and typos
    
    Signed-off-by: Nicholas D Steeves <nsteeves@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 8d358c547c59..e9710f461008 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1831,7 +1831,7 @@ static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 
 	/*
 	 * If we have a parent root we need to verify that the parent dir was
-	 * not delted and then re-created, if it was then we have no overwrite
+	 * not deleted and then re-created, if it was then we have no overwrite
 	 * and we can just unlink this entry.
 	 */
 	if (sctx->parent_root) {
@@ -4192,9 +4192,9 @@ static int __process_new_xattr(int num, struct btrfs_key *di_key,
 		return -ENOMEM;
 
 	/*
-	 * This hack is needed because empty acl's are stored as zero byte
+	 * This hack is needed because empty acls are stored as zero byte
 	 * data in xattrs. Problem with that is, that receiving these zero byte
-	 * acl's will fail later. To fix this, we send a dummy acl list that
+	 * acls will fail later. To fix this, we send a dummy acl list that
 	 * only contains the version number and no entries.
 	 */
 	if (!strncmp(name, XATTR_NAME_POSIX_ACL_ACCESS, name_len) ||

commit 2f91306a37809907474a06c1defdb1ff50be06f0
Author: David Sterba <dsterba@suse.com>
Date:   Mon Apr 11 18:40:08 2016 +0200

    btrfs: send: use vmalloc only as fallback for clone_sources_tmp
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 5a5d37b37150..6a8c86074aa4 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6065,10 +6065,13 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	alloc_size = arg->clone_sources_count * sizeof(*arg->clone_sources);
 
 	if (arg->clone_sources_count) {
-		clone_sources_tmp = vmalloc(alloc_size);
+		clone_sources_tmp = kmalloc(alloc_size, GFP_KERNEL | __GFP_NOWARN);
 		if (!clone_sources_tmp) {
-			ret = -ENOMEM;
-			goto out;
+			clone_sources_tmp = vmalloc(alloc_size);
+			if (!clone_sources_tmp) {
+				ret = -ENOMEM;
+				goto out;
+			}
 		}
 
 		ret = copy_from_user(clone_sources_tmp, arg->clone_sources,
@@ -6106,7 +6109,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			sctx->clone_roots[i].root = clone_root;
 			clone_sources_to_rollback = i + 1;
 		}
-		vfree(clone_sources_tmp);
+		kvfree(clone_sources_tmp);
 		clone_sources_tmp = NULL;
 	}
 
@@ -6224,7 +6227,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		btrfs_root_dec_send_in_progress(sctx->parent_root);
 
 	kfree(arg);
-	vfree(clone_sources_tmp);
+	kvfree(clone_sources_tmp);
 
 	if (sctx) {
 		if (sctx->send_filp)

commit c03d01f3404282712b9fd280297f133860c91c93
Author: David Sterba <dsterba@suse.com>
Date:   Mon Apr 11 18:40:08 2016 +0200

    btrfs: send: use vmalloc only as fallback for clone_roots
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 4f85a47c2f55..5a5d37b37150 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6053,10 +6053,13 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 
 	alloc_size = sizeof(struct clone_root) * (arg->clone_sources_count + 1);
 
-	sctx->clone_roots = vzalloc(alloc_size);
+	sctx->clone_roots = kzalloc(alloc_size, GFP_KERNEL | __GFP_NOWARN);
 	if (!sctx->clone_roots) {
-		ret = -ENOMEM;
-		goto out;
+		sctx->clone_roots = vzalloc(alloc_size);
+		if (!sctx->clone_roots) {
+			ret = -ENOMEM;
+			goto out;
+		}
 	}
 
 	alloc_size = arg->clone_sources_count * sizeof(*arg->clone_sources);
@@ -6227,7 +6230,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		if (sctx->send_filp)
 			fput(sctx->send_filp);
 
-		vfree(sctx->clone_roots);
+		kvfree(sctx->clone_roots);
 		kvfree(sctx->send_buf);
 		kvfree(sctx->read_buf);
 

commit e55d1153dbf48485a74eb4bf4eefeaedcf1486a9
Author: David Sterba <dsterba@suse.com>
Date:   Mon Apr 11 18:52:02 2016 +0200

    btrfs: send: use temporary variable to store allocation size
    
    We're going to use the argument multiple times later.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 4e950ebbef53..4f85a47c2f55 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5939,6 +5939,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	u32 i;
 	u64 *clone_sources_tmp = NULL;
 	int clone_sources_to_rollback = 0;
+	unsigned alloc_size;
 	int sort_clone_roots = 0;
 	int index;
 
@@ -6050,24 +6051,25 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	sctx->waiting_dir_moves = RB_ROOT;
 	sctx->orphan_dirs = RB_ROOT;
 
-	sctx->clone_roots = vzalloc(sizeof(struct clone_root) *
-			(arg->clone_sources_count + 1));
+	alloc_size = sizeof(struct clone_root) * (arg->clone_sources_count + 1);
+
+	sctx->clone_roots = vzalloc(alloc_size);
 	if (!sctx->clone_roots) {
 		ret = -ENOMEM;
 		goto out;
 	}
 
+	alloc_size = arg->clone_sources_count * sizeof(*arg->clone_sources);
+
 	if (arg->clone_sources_count) {
-		clone_sources_tmp = vmalloc(arg->clone_sources_count *
-				sizeof(*arg->clone_sources));
+		clone_sources_tmp = vmalloc(alloc_size);
 		if (!clone_sources_tmp) {
 			ret = -ENOMEM;
 			goto out;
 		}
 
 		ret = copy_from_user(clone_sources_tmp, arg->clone_sources,
-				arg->clone_sources_count *
-				sizeof(*arg->clone_sources));
+				alloc_size);
 		if (ret) {
 			ret = -EFAULT;
 			goto out;

commit eb5b75fe2e61a9ba907785b70318736112b0cf93
Author: David Sterba <dsterba@suse.com>
Date:   Mon Apr 11 18:40:08 2016 +0200

    btrfs: send: use vmalloc only as fallback for read_buf
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index b6e2c6ec4ee5..4e950ebbef53 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6037,10 +6037,13 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		}
 	}
 
-	sctx->read_buf = vmalloc(BTRFS_SEND_READ_SIZE);
+	sctx->read_buf = kmalloc(BTRFS_SEND_READ_SIZE, GFP_KERNEL | __GFP_NOWARN);
 	if (!sctx->read_buf) {
-		ret = -ENOMEM;
-		goto out;
+		sctx->read_buf = vmalloc(BTRFS_SEND_READ_SIZE);
+		if (!sctx->read_buf) {
+			ret = -ENOMEM;
+			goto out;
+		}
 	}
 
 	sctx->pending_dir_moves = RB_ROOT;
@@ -6224,7 +6227,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 
 		vfree(sctx->clone_roots);
 		kvfree(sctx->send_buf);
-		vfree(sctx->read_buf);
+		kvfree(sctx->read_buf);
 
 		name_cache_free(sctx);
 

commit 6ff48ce06b07255a6459cd8b816a110971a81f00
Author: David Sterba <dsterba@suse.com>
Date:   Mon Apr 11 18:40:08 2016 +0200

    btrfs: send: use vmalloc only as fallback for send_buf
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ec433795fa71..b6e2c6ec4ee5 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -6028,10 +6028,13 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	sctx->clone_roots_cnt = arg->clone_sources_count;
 
 	sctx->send_max_size = BTRFS_SEND_BUF_SIZE;
-	sctx->send_buf = vmalloc(sctx->send_max_size);
+	sctx->send_buf = kmalloc(sctx->send_max_size, GFP_KERNEL | __GFP_NOWARN);
 	if (!sctx->send_buf) {
-		ret = -ENOMEM;
-		goto out;
+		sctx->send_buf = vmalloc(sctx->send_max_size);
+		if (!sctx->send_buf) {
+			ret = -ENOMEM;
+			goto out;
+		}
 	}
 
 	sctx->read_buf = vmalloc(BTRFS_SEND_READ_SIZE);
@@ -6220,7 +6223,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			fput(sctx->send_filp);
 
 		vfree(sctx->clone_roots);
-		vfree(sctx->send_buf);
+		kvfree(sctx->send_buf);
 		vfree(sctx->read_buf);
 
 		name_cache_free(sctx);

commit f5ecec3ce21f706e9e7a330b2e8e5a2941927b46
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Wed Apr 13 09:40:59 2016 +0300

    btrfs: send: silence an integer overflow warning
    
    The "sizeof(*arg->clone_sources) * arg->clone_sources_count" expression
    can overflow.  It causes several static checker warnings.  It's all
    under CAP_SYS_ADMIN so it's not that serious but lets silence the
    warnings.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 8d358c547c59..ec433795fa71 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5978,6 +5978,12 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		goto out;
 	}
 
+	if (arg->clone_sources_count >
+	    ULLONG_MAX / sizeof(*arg->clone_sources)) {
+		ret = -EINVAL;
+		goto out;
+	}
+
 	if (!access_ok(VERIFY_READ, arg->clone_sources,
 			sizeof(*arg->clone_sources) *
 			arg->clone_sources_count)) {

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 19b7bf4284ee..8d358c547c59 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4449,9 +4449,9 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 	struct page *page;
 	char *addr;
 	struct btrfs_key key;
-	pgoff_t index = offset >> PAGE_CACHE_SHIFT;
+	pgoff_t index = offset >> PAGE_SHIFT;
 	pgoff_t last_index;
-	unsigned pg_offset = offset & ~PAGE_CACHE_MASK;
+	unsigned pg_offset = offset & ~PAGE_MASK;
 	ssize_t ret = 0;
 
 	key.objectid = sctx->cur_ino;
@@ -4471,7 +4471,7 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 	if (len == 0)
 		goto out;
 
-	last_index = (offset + len - 1) >> PAGE_CACHE_SHIFT;
+	last_index = (offset + len - 1) >> PAGE_SHIFT;
 
 	/* initial readahead */
 	memset(&sctx->ra, 0, sizeof(struct file_ra_state));
@@ -4481,7 +4481,7 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 
 	while (index <= last_index) {
 		unsigned cur_len = min_t(unsigned, len,
-					 PAGE_CACHE_SIZE - pg_offset);
+					 PAGE_SIZE - pg_offset);
 		page = find_or_create_page(inode->i_mapping, index, GFP_KERNEL);
 		if (!page) {
 			ret = -ENOMEM;
@@ -4493,7 +4493,7 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 			lock_page(page);
 			if (!PageUptodate(page)) {
 				unlock_page(page);
-				page_cache_release(page);
+				put_page(page);
 				ret = -EIO;
 				break;
 			}
@@ -4503,7 +4503,7 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 		memcpy(sctx->read_buf + ret, addr + pg_offset, cur_len);
 		kunmap(page);
 		unlock_page(page);
-		page_cache_release(page);
+		put_page(page);
 		index++;
 		pg_offset = 0;
 		len -= cur_len;
@@ -4804,7 +4804,7 @@ static int clone_range(struct send_ctx *sctx,
 		type = btrfs_file_extent_type(leaf, ei);
 		if (type == BTRFS_FILE_EXTENT_INLINE) {
 			ext_len = btrfs_file_extent_inline_len(leaf, slot, ei);
-			ext_len = PAGE_CACHE_ALIGN(ext_len);
+			ext_len = PAGE_ALIGN(ext_len);
 		} else {
 			ext_len = btrfs_file_extent_num_bytes(leaf, ei);
 		}
@@ -4886,7 +4886,7 @@ static int send_write_or_clone(struct send_ctx *sctx,
 		 * but there may be items after this page.  Make
 		 * sure to send the whole thing
 		 */
-		len = PAGE_CACHE_ALIGN(len);
+		len = PAGE_ALIGN(len);
 	} else {
 		len = btrfs_file_extent_num_bytes(path->nodes[0], ei);
 	}

commit ebb8765b2ded869b75bf5154b048119eb52571f7
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Mar 10 17:26:59 2016 +0800

    btrfs: move btrfs_compression_type to compression.h
    
    So that its better organized.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d2e29925f1da..19b7bf4284ee 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -34,6 +34,7 @@
 #include "disk-io.h"
 #include "btrfs_inode.h"
 #include "transaction.h"
+#include "compression.h"
 
 static int g_verbose = 0;
 

commit e780b0d1c1523ec8cd489c6910fb8c5ee452bb6c
Author: David Sterba <dsterba@suse.com>
Date:   Mon Jan 18 18:42:13 2016 +0100

    btrfs: send: use GFP_KERNEL everywhere
    
    The send operation is not on the critical writeback path we don't need
    to use GFP_NOFS for allocations. All error paths are handled and the
    whole operation is restartable.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 63a6152be04b..d2e29925f1da 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -304,7 +304,7 @@ static struct fs_path *fs_path_alloc(void)
 {
 	struct fs_path *p;
 
-	p = kmalloc(sizeof(*p), GFP_NOFS);
+	p = kmalloc(sizeof(*p), GFP_KERNEL);
 	if (!p)
 		return NULL;
 	p->reversed = 0;
@@ -363,11 +363,11 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 	 * First time the inline_buf does not suffice
 	 */
 	if (p->buf == p->inline_buf) {
-		tmp_buf = kmalloc(len, GFP_NOFS);
+		tmp_buf = kmalloc(len, GFP_KERNEL);
 		if (tmp_buf)
 			memcpy(tmp_buf, p->buf, old_buf_len);
 	} else {
-		tmp_buf = krealloc(p->buf, len, GFP_NOFS);
+		tmp_buf = krealloc(p->buf, len, GFP_KERNEL);
 	}
 	if (!tmp_buf)
 		return -ENOMEM;
@@ -995,7 +995,7 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 	 * values are small.
 	 */
 	buf_len = PATH_MAX;
-	buf = kmalloc(buf_len, GFP_NOFS);
+	buf = kmalloc(buf_len, GFP_KERNEL);
 	if (!buf) {
 		ret = -ENOMEM;
 		goto out;
@@ -1042,7 +1042,7 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 				buf = NULL;
 			} else {
 				char *tmp = krealloc(buf, buf_len,
-						     GFP_NOFS | __GFP_NOWARN);
+						GFP_KERNEL | __GFP_NOWARN);
 
 				if (!tmp)
 					kfree(buf);
@@ -1303,7 +1303,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	/* We only use this path under the commit sem */
 	tmp_path->need_commit_sem = 0;
 
-	backref_ctx = kmalloc(sizeof(*backref_ctx), GFP_NOFS);
+	backref_ctx = kmalloc(sizeof(*backref_ctx), GFP_KERNEL);
 	if (!backref_ctx) {
 		ret = -ENOMEM;
 		goto out;
@@ -1984,7 +1984,7 @@ static int name_cache_insert(struct send_ctx *sctx,
 	nce_head = radix_tree_lookup(&sctx->name_cache,
 			(unsigned long)nce->ino);
 	if (!nce_head) {
-		nce_head = kmalloc(sizeof(*nce_head), GFP_NOFS);
+		nce_head = kmalloc(sizeof(*nce_head), GFP_KERNEL);
 		if (!nce_head) {
 			kfree(nce);
 			return -ENOMEM;
@@ -2179,7 +2179,7 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	/*
 	 * Store the result of the lookup in the name cache.
 	 */
-	nce = kmalloc(sizeof(*nce) + fs_path_len(dest) + 1, GFP_NOFS);
+	nce = kmalloc(sizeof(*nce) + fs_path_len(dest) + 1, GFP_KERNEL);
 	if (!nce) {
 		ret = -ENOMEM;
 		goto out;
@@ -2315,7 +2315,7 @@ static int send_subvol_begin(struct send_ctx *sctx)
 	if (!path)
 		return -ENOMEM;
 
-	name = kmalloc(BTRFS_PATH_NAME_MAX, GFP_NOFS);
+	name = kmalloc(BTRFS_PATH_NAME_MAX, GFP_KERNEL);
 	if (!name) {
 		btrfs_free_path(path);
 		return -ENOMEM;
@@ -2730,7 +2730,7 @@ static int __record_ref(struct list_head *head, u64 dir,
 {
 	struct recorded_ref *ref;
 
-	ref = kmalloc(sizeof(*ref), GFP_NOFS);
+	ref = kmalloc(sizeof(*ref), GFP_KERNEL);
 	if (!ref)
 		return -ENOMEM;
 
@@ -2755,7 +2755,7 @@ static int dup_ref(struct recorded_ref *ref, struct list_head *list)
 {
 	struct recorded_ref *new;
 
-	new = kmalloc(sizeof(*ref), GFP_NOFS);
+	new = kmalloc(sizeof(*ref), GFP_KERNEL);
 	if (!new)
 		return -ENOMEM;
 
@@ -2818,7 +2818,7 @@ add_orphan_dir_info(struct send_ctx *sctx, u64 dir_ino)
 	struct rb_node *parent = NULL;
 	struct orphan_dir_info *entry, *odi;
 
-	odi = kmalloc(sizeof(*odi), GFP_NOFS);
+	odi = kmalloc(sizeof(*odi), GFP_KERNEL);
 	if (!odi)
 		return ERR_PTR(-ENOMEM);
 	odi->ino = dir_ino;
@@ -2973,7 +2973,7 @@ static int add_waiting_dir_move(struct send_ctx *sctx, u64 ino, bool orphanized)
 	struct rb_node *parent = NULL;
 	struct waiting_dir_move *entry, *dm;
 
-	dm = kmalloc(sizeof(*dm), GFP_NOFS);
+	dm = kmalloc(sizeof(*dm), GFP_KERNEL);
 	if (!dm)
 		return -ENOMEM;
 	dm->ino = ino;
@@ -3040,7 +3040,7 @@ static int add_pending_dir_move(struct send_ctx *sctx,
 	int exists = 0;
 	int ret;
 
-	pm = kmalloc(sizeof(*pm), GFP_NOFS);
+	pm = kmalloc(sizeof(*pm), GFP_KERNEL);
 	if (!pm)
 		return -ENOMEM;
 	pm->parent_ino = parent_ino;
@@ -4280,7 +4280,7 @@ static int __find_xattr(int num, struct btrfs_key *di_key,
 	    strncmp(name, ctx->name, name_len) == 0) {
 		ctx->found_idx = num;
 		ctx->found_data_len = data_len;
-		ctx->found_data = kmemdup(data, data_len, GFP_NOFS);
+		ctx->found_data = kmemdup(data, data_len, GFP_KERNEL);
 		if (!ctx->found_data)
 			return -ENOMEM;
 		return 1;
@@ -4481,7 +4481,7 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 	while (index <= last_index) {
 		unsigned cur_len = min_t(unsigned, len,
 					 PAGE_CACHE_SIZE - pg_offset);
-		page = find_or_create_page(inode->i_mapping, index, GFP_NOFS);
+		page = find_or_create_page(inode->i_mapping, index, GFP_KERNEL);
 		if (!page) {
 			ret = -ENOMEM;
 			break;
@@ -5989,7 +5989,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		goto out;
 	}
 
-	sctx = kzalloc(sizeof(struct send_ctx), GFP_NOFS);
+	sctx = kzalloc(sizeof(struct send_ctx), GFP_KERNEL);
 	if (!sctx) {
 		ret = -ENOMEM;
 		goto out;
@@ -5997,7 +5997,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 
 	INIT_LIST_HEAD(&sctx->new_refs);
 	INIT_LIST_HEAD(&sctx->deleted_refs);
-	INIT_RADIX_TREE(&sctx->name_cache, GFP_NOFS);
+	INIT_RADIX_TREE(&sctx->name_cache, GFP_KERNEL);
 	INIT_LIST_HEAD(&sctx->name_cache_list);
 
 	sctx->flags = arg->flags;

commit a879719b8c90e15c9e7fa7266d5e3c0ca962f9df
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Dec 31 18:07:59 2015 +0000

    Btrfs: send, don't BUG_ON() when an empty symlink is found
    
    When a symlink is successfully created it always has an inline extent
    containing the source path. However if an error happens when creating
    the symlink, we can leave in the subvolume's tree a symlink inode without
    any such inline extent item - this happens if after btrfs_symlink() calls
    btrfs_end_transaction() and before it calls the inode eviction handler
    (through the final iput() call), the transaction gets committed and a
    crash happens before the eviction handler gets called, or if a snapshot
    of the subvolume is made before the eviction handler gets called. Sadly
    we can't just avoid this by making btrfs_symlink() call
    btrfs_end_transaction() after it calls the eviction handler, because the
    later can commit the current transaction before it removes any items from
    the subvolume tree (if it encounters ENOSPC errors while reserving space
    for removing all the items).
    
    So make send fail more gracefully, with an -EIO error, and print a
    message to dmesg/syslog informing that there's an empty symlink inode,
    so that the user can delete the empty symlink or do something else
    about it.
    
    Reported-by: Stephen R. van den Berg <srb@cuci.nl>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 355a458cba1a..63a6152be04b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1469,7 +1469,21 @@ static int read_symlink(struct btrfs_root *root,
 	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
 	if (ret < 0)
 		goto out;
-	BUG_ON(ret);
+	if (ret) {
+		/*
+		 * An empty symlink inode. Can happen in rare error paths when
+		 * creating a symlink (transaction committed before the inode
+		 * eviction handler removed the symlink inode items and a crash
+		 * happened in between or the subvol was snapshoted in between).
+		 * Print an informative message to dmesg/syslog so that the user
+		 * can delete the symlink.
+		 */
+		btrfs_err(root->fs_info,
+			  "Found empty symlink inode %llu at root %llu",
+			  ino, root->root_key.objectid);
+		ret = -EIO;
+		goto out;
+	}
 
 	ei = btrfs_item_ptr(path->nodes[0], path->slots[0],
 			struct btrfs_file_extent_item);

commit b96b1db039ebc584d03a9933b279e0d3e704c528
Author: Robin Ruede <r.ruede@gmail.com>
Date:   Wed Sep 30 21:23:33 2015 +0200

    btrfs: fix resending received snapshot with parent
    
    This fixes a regression introduced by 37b8d27d between v4.1 and v4.2.
    
    When a snapshot is received, its received_uuid is set to the original
    uuid of the subvolume. When that snapshot is then resent to a third
    filesystem, it's received_uuid is set to the second uuid
    instead of the original one. The same was true for the parent_uuid.
    This behaviour was partially changed in 37b8d27d, but in that patch
    only the parent_uuid was taken from the real original,
    not the uuid itself, causing the search for the parent to fail in
    the case below.
    
    This happens for example when trying to send a series of linked
    snapshots (e.g. created by snapper) from the backup file system back
    to the original one.
    
    The following commands reproduce the issue in v4.2.1
    (no error in 4.1.6)
    
        # setup three test file systems
        for i in 1 2 3; do
                truncate -s 50M fs$i
                mkfs.btrfs fs$i
                mkdir $i
                mount fs$i $i
        done
        echo "content" > 1/testfile
        btrfs su snapshot -r 1/ 1/snap1
        echo "changed content" > 1/testfile
        btrfs su snapshot -r 1/ 1/snap2
    
        # works fine:
        btrfs send 1/snap1 | btrfs receive 2/
        btrfs send -p 1/snap1 1/snap2 | btrfs receive 2/
    
        # ERROR: could not find parent subvolume
        btrfs send 2/snap1 | btrfs receive 3/
        btrfs send -p 2/snap1 2/snap2 | btrfs receive 3/
    
    Signed-off-by: Robin Ruede <rruede+git@gmail.com>
    Fixes: 37b8d27de5d0 ("Btrfs: use received_uuid of parent during send")
    Cc: stable@vger.kernel.org # v4.2+
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Tested-by: Ed Tomlinson <edt@aei.ca>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ced935bf5f95..355a458cba1a 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2343,8 +2343,14 @@ static int send_subvol_begin(struct send_ctx *sctx)
 	}
 
 	TLV_PUT_STRING(sctx, BTRFS_SEND_A_PATH, name, namelen);
-	TLV_PUT_UUID(sctx, BTRFS_SEND_A_UUID,
-			sctx->send_root->root_item.uuid);
+
+	if (!btrfs_is_empty_uuid(sctx->send_root->root_item.received_uuid))
+		TLV_PUT_UUID(sctx, BTRFS_SEND_A_UUID,
+			    sctx->send_root->root_item.received_uuid);
+	else
+		TLV_PUT_UUID(sctx, BTRFS_SEND_A_UUID,
+			    sctx->send_root->root_item.uuid);
+
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_CTRANSID,
 		    le64_to_cpu(sctx->send_root->root_item.ctransid));
 	if (parent_root) {

commit d906d49fc5f49a0129527e8fbc13312f36b9b9ce
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Oct 2 10:47:34 2015 +0100

    Btrfs: send, fix file corruption due to incorrect cloning operations
    
    If we have a file that shares an extent with other files, when processing
    the extent item relative to a shared extent, we blindly issue a clone
    operation that will target a length matching the length in the extent item
    and uses as a source some other file the receiver already has and points
    to the same extent. However that range in the other file might not
    exclusively point only to the shared extent, and so using that length
    will result in the receiver getting a file with different data from the
    one in the send snapshot. This issue happened both for incremental and
    full send operations.
    
    So fix this by issuing clone operations with lengths that don't cover
    regions of the source file that point to different extents (or have holes).
    
    The following test case for fstests reproduces the problem.
    
      seq=`basename $0`
      seqres=$RESULT_DIR/$seq
      echo "QA output created by $seq"
    
      tmp=/tmp/$$
      status=1      # failure is the default!
      trap "_cleanup; exit \$status" 0 1 2 3 15
    
      _cleanup()
      {
          rm -fr $send_files_dir
          rm -f $tmp.*
      }
    
      # get standard environment, filters and checks
      . ./common/rc
      . ./common/filter
    
      # real QA test starts here
      _supported_fs btrfs
      _supported_os Linux
      _require_scratch
      _need_to_be_root
      _require_cp_reflink
      _require_xfs_io_command "fpunch"
    
      send_files_dir=$TEST_DIR/btrfs-test-$seq
    
      rm -f $seqres.full
      rm -fr $send_files_dir
      mkdir $send_files_dir
    
      _scratch_mkfs >>$seqres.full 2>&1
      _scratch_mount
    
      # Create our test file with a single 100K extent.
      $XFS_IO_PROG -f -c "pwrite -S 0xaa 0K 100K" \
         $SCRATCH_MNT/foo | _filter_xfs_io
    
      # Clone our file into a new file named bar.
      cp --reflink=always $SCRATCH_MNT/foo $SCRATCH_MNT/bar
    
      # Now overwrite parts of our foo file.
      $XFS_IO_PROG -c "pwrite -S 0xbb 50K 10K" \
         -c "pwrite -S 0xcc 90K 10K" \
         -c "fpunch 70K 10k" \
         $SCRATCH_MNT/foo | _filter_xfs_io
    
      _run_btrfs_util_prog subvolume snapshot -r $SCRATCH_MNT \
         $SCRATCH_MNT/snap
    
      echo "File digests in the original filesystem:"
      md5sum $SCRATCH_MNT/snap/foo | _filter_scratch
      md5sum $SCRATCH_MNT/snap/bar | _filter_scratch
    
      _run_btrfs_util_prog send $SCRATCH_MNT/snap -f $send_files_dir/1.snap
    
      # Now recreate the filesystem by receiving the send stream and verify
      # we get the same file contents that the original filesystem had.
      _scratch_unmount
      _scratch_mkfs >>$seqres.full 2>&1
      _scratch_mount
    
      _run_btrfs_util_prog receive $SCRATCH_MNT -f $send_files_dir/1.snap
    
      # We expect the destination filesystem to have exactly the same file
      # data as the original filesystem.
      # The btrfs send implementation had a bug where it sent a clone
      # operation from file foo into file bar covering the whole [0, 100K[
      # range after creating and writing the file foo. This was incorrect
      # because the file bar now included the updates done to file foo after
      # we cloned foo to bar, breaking the COW nature of reflink copies
      # (cloned extents).
      echo "File digests in the new filesystem:"
      md5sum $SCRATCH_MNT/snap/foo | _filter_scratch
      md5sum $SCRATCH_MNT/snap/bar | _filter_scratch
    
      status=0
      exit
    
    Another test case that reproduces the problem when we have compressed
    extents:
    
      seq=`basename $0`
      seqres=$RESULT_DIR/$seq
      echo "QA output created by $seq"
    
      tmp=/tmp/$$
      status=1      # failure is the default!
      trap "_cleanup; exit \$status" 0 1 2 3 15
    
      _cleanup()
      {
          rm -fr $send_files_dir
          rm -f $tmp.*
      }
    
      # get standard environment, filters and checks
      . ./common/rc
      . ./common/filter
    
      # real QA test starts here
      _supported_fs btrfs
      _supported_os Linux
      _require_scratch
      _need_to_be_root
      _require_cp_reflink
    
      send_files_dir=$TEST_DIR/btrfs-test-$seq
    
      rm -f $seqres.full
      rm -fr $send_files_dir
      mkdir $send_files_dir
    
      _scratch_mkfs >>$seqres.full 2>&1
      _scratch_mount "-o compress"
    
      # Create our file with an extent of 100K starting at file offset 0K.
      $XFS_IO_PROG -f -c "pwrite -S 0xaa 0K 100K"       \
                      -c "fsync"                        \
                      $SCRATCH_MNT/foo | _filter_xfs_io
    
      # Rewrite part of the previous extent (its first 40K) and write a new
      # 100K extent starting at file offset 100K.
      $XFS_IO_PROG -c "pwrite -S 0xbb 0K 40K"    \
              -c "pwrite -S 0xcc 100K 100K"      \
              $SCRATCH_MNT/foo | _filter_xfs_io
    
      # Our file foo now has 3 file extent items in its metadata:
      #
      # 1) One covering the file range 0 to 40K;
      # 2) One covering the file range 40K to 100K, which points to the first
      #    extent we wrote to the file and has a data offset field with value
      #    40K (our file no longer uses the first 40K of data from that
      #    extent);
      # 3) One covering the file range 100K to 200K.
    
      # Now clone our file foo into file bar.
      cp --reflink=always $SCRATCH_MNT/foo $SCRATCH_MNT/bar
    
      # Create our snapshot for the send operation.
      _run_btrfs_util_prog subvolume snapshot -r $SCRATCH_MNT \
              $SCRATCH_MNT/snap
    
      echo "File digests in the original filesystem:"
      md5sum $SCRATCH_MNT/snap/foo | _filter_scratch
      md5sum $SCRATCH_MNT/snap/bar | _filter_scratch
    
      _run_btrfs_util_prog send $SCRATCH_MNT/snap -f $send_files_dir/1.snap
    
      # Now recreate the filesystem by receiving the send stream and verify we
      # get the same file contents that the original filesystem had.
      # Btrfs send used to issue a clone operation from foo's range
      # [80K, 140K[ to bar's range [40K, 100K[ when cloning the extent pointed
      # to by foo's second file extent item, this was incorrect because of bad
      # accounting of the file extent item's data offset field. The correct
      # range to clone from should have been [40K, 100K[.
      _scratch_unmount
      _scratch_mkfs >>$seqres.full 2>&1
      _scratch_mount "-o compress"
    
      _run_btrfs_util_prog receive $SCRATCH_MNT -f $send_files_dir/1.snap
    
      echo "File digests in the new filesystem:"
      # Must match the digests we got in the original filesystem.
      md5sum $SCRATCH_MNT/snap/foo | _filter_scratch
      md5sum $SCRATCH_MNT/snap/bar | _filter_scratch
    
      status=0
      exit
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index b5d47b9400ba..ced935bf5f95 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1434,16 +1434,6 @@ verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, "
 	}
 
 	if (cur_clone_root) {
-		if (compressed != BTRFS_COMPRESS_NONE) {
-			/*
-			 * Offsets given by iterate_extent_inodes() are relative
-			 * to the start of the extent, we need to add logical
-			 * offset from the file extent item.
-			 * (See why at backref.c:check_extent_in_eb())
-			 */
-			cur_clone_root->offset += btrfs_file_extent_offset(eb,
-									   fi);
-		}
 		*found = cur_clone_root;
 		ret = 0;
 	} else {
@@ -4687,6 +4677,171 @@ static int send_hole(struct send_ctx *sctx, u64 end)
 	return ret;
 }
 
+static int send_extent_data(struct send_ctx *sctx,
+			    const u64 offset,
+			    const u64 len)
+{
+	u64 sent = 0;
+
+	if (sctx->flags & BTRFS_SEND_FLAG_NO_FILE_DATA)
+		return send_update_extent(sctx, offset, len);
+
+	while (sent < len) {
+		u64 size = len - sent;
+		int ret;
+
+		if (size > BTRFS_SEND_READ_SIZE)
+			size = BTRFS_SEND_READ_SIZE;
+		ret = send_write(sctx, offset + sent, size);
+		if (ret < 0)
+			return ret;
+		if (!ret)
+			break;
+		sent += ret;
+	}
+	return 0;
+}
+
+static int clone_range(struct send_ctx *sctx,
+		       struct clone_root *clone_root,
+		       const u64 disk_byte,
+		       u64 data_offset,
+		       u64 offset,
+		       u64 len)
+{
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	int ret;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	/*
+	 * We can't send a clone operation for the entire range if we find
+	 * extent items in the respective range in the source file that
+	 * refer to different extents or if we find holes.
+	 * So check for that and do a mix of clone and regular write/copy
+	 * operations if needed.
+	 *
+	 * Example:
+	 *
+	 * mkfs.btrfs -f /dev/sda
+	 * mount /dev/sda /mnt
+	 * xfs_io -f -c "pwrite -S 0xaa 0K 100K" /mnt/foo
+	 * cp --reflink=always /mnt/foo /mnt/bar
+	 * xfs_io -c "pwrite -S 0xbb 50K 50K" /mnt/foo
+	 * btrfs subvolume snapshot -r /mnt /mnt/snap
+	 *
+	 * If when we send the snapshot and we are processing file bar (which
+	 * has a higher inode number than foo) we blindly send a clone operation
+	 * for the [0, 100K[ range from foo to bar, the receiver ends up getting
+	 * a file bar that matches the content of file foo - iow, doesn't match
+	 * the content from bar in the original filesystem.
+	 */
+	key.objectid = clone_root->ino;
+	key.type = BTRFS_EXTENT_DATA_KEY;
+	key.offset = clone_root->offset;
+	ret = btrfs_search_slot(NULL, clone_root->root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
+	if (ret > 0 && path->slots[0] > 0) {
+		btrfs_item_key_to_cpu(path->nodes[0], &key, path->slots[0] - 1);
+		if (key.objectid == clone_root->ino &&
+		    key.type == BTRFS_EXTENT_DATA_KEY)
+			path->slots[0]--;
+	}
+
+	while (true) {
+		struct extent_buffer *leaf = path->nodes[0];
+		int slot = path->slots[0];
+		struct btrfs_file_extent_item *ei;
+		u8 type;
+		u64 ext_len;
+		u64 clone_len;
+
+		if (slot >= btrfs_header_nritems(leaf)) {
+			ret = btrfs_next_leaf(clone_root->root, path);
+			if (ret < 0)
+				goto out;
+			else if (ret > 0)
+				break;
+			continue;
+		}
+
+		btrfs_item_key_to_cpu(leaf, &key, slot);
+
+		/*
+		 * We might have an implicit trailing hole (NO_HOLES feature
+		 * enabled). We deal with it after leaving this loop.
+		 */
+		if (key.objectid != clone_root->ino ||
+		    key.type != BTRFS_EXTENT_DATA_KEY)
+			break;
+
+		ei = btrfs_item_ptr(leaf, slot, struct btrfs_file_extent_item);
+		type = btrfs_file_extent_type(leaf, ei);
+		if (type == BTRFS_FILE_EXTENT_INLINE) {
+			ext_len = btrfs_file_extent_inline_len(leaf, slot, ei);
+			ext_len = PAGE_CACHE_ALIGN(ext_len);
+		} else {
+			ext_len = btrfs_file_extent_num_bytes(leaf, ei);
+		}
+
+		if (key.offset + ext_len <= clone_root->offset)
+			goto next;
+
+		if (key.offset > clone_root->offset) {
+			/* Implicit hole, NO_HOLES feature enabled. */
+			u64 hole_len = key.offset - clone_root->offset;
+
+			if (hole_len > len)
+				hole_len = len;
+			ret = send_extent_data(sctx, offset, hole_len);
+			if (ret < 0)
+				goto out;
+
+			len -= hole_len;
+			if (len == 0)
+				break;
+			offset += hole_len;
+			clone_root->offset += hole_len;
+			data_offset += hole_len;
+		}
+
+		if (key.offset >= clone_root->offset + len)
+			break;
+
+		clone_len = min_t(u64, ext_len, len);
+
+		if (btrfs_file_extent_disk_bytenr(leaf, ei) == disk_byte &&
+		    btrfs_file_extent_offset(leaf, ei) == data_offset)
+			ret = send_clone(sctx, offset, clone_len, clone_root);
+		else
+			ret = send_extent_data(sctx, offset, clone_len);
+
+		if (ret < 0)
+			goto out;
+
+		len -= clone_len;
+		if (len == 0)
+			break;
+		offset += clone_len;
+		clone_root->offset += clone_len;
+		data_offset += clone_len;
+next:
+		path->slots[0]++;
+	}
+
+	if (len > 0)
+		ret = send_extent_data(sctx, offset, len);
+	else
+		ret = 0;
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
 static int send_write_or_clone(struct send_ctx *sctx,
 			       struct btrfs_path *path,
 			       struct btrfs_key *key,
@@ -4695,9 +4850,7 @@ static int send_write_or_clone(struct send_ctx *sctx,
 	int ret = 0;
 	struct btrfs_file_extent_item *ei;
 	u64 offset = key->offset;
-	u64 pos = 0;
 	u64 len;
-	u32 l;
 	u8 type;
 	u64 bs = sctx->send_root->fs_info->sb->s_blocksize;
 
@@ -4725,22 +4878,15 @@ static int send_write_or_clone(struct send_ctx *sctx,
 	}
 
 	if (clone_root && IS_ALIGNED(offset + len, bs)) {
-		ret = send_clone(sctx, offset, len, clone_root);
-	} else if (sctx->flags & BTRFS_SEND_FLAG_NO_FILE_DATA) {
-		ret = send_update_extent(sctx, offset, len);
+		u64 disk_byte;
+		u64 data_offset;
+
+		disk_byte = btrfs_file_extent_disk_bytenr(path->nodes[0], ei);
+		data_offset = btrfs_file_extent_offset(path->nodes[0], ei);
+		ret = clone_range(sctx, clone_root, disk_byte, data_offset,
+				  offset, len);
 	} else {
-		while (pos < len) {
-			l = len - pos;
-			if (l > BTRFS_SEND_READ_SIZE)
-				l = BTRFS_SEND_READ_SIZE;
-			ret = send_write(sctx, pos + offset, l);
-			if (ret < 0)
-				goto out;
-			if (!ret)
-				break;
-			pos += ret;
-		}
-		ret = 0;
+		ret = send_extent_data(sctx, offset, len);
 	}
 out:
 	return ret;

commit 640926ffdda7e817965d3bfb5bbbc51598ccf49b
Merge: 25cb62b76430 f14d104dbdb5
Author: Chris Mason <clm@fb.com>
Date:   Mon Oct 12 16:22:26 2015 -0700

    Merge branch 'cleanup/messages' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.4

commit f14d104dbdb5044dac9acd0e983ffb60f706c746
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 8 11:37:06 2015 +0200

    btrfs: switch more printks to our helpers
    
    Convert the simple cases, not all functions provide a way to reach the
    fs_info. Also skipped debugging messages (print-tree, integrity
    checker and pr_debug) and messages that are printed from possibly
    unfinished mount.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index aa72bfd28f7d..4ea07c8cd6c2 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2562,7 +2562,7 @@ verbose_printk("btrfs: send_create_inode %llu\n", ino);
 	} else if (S_ISSOCK(mode)) {
 		cmd = BTRFS_SEND_C_MKSOCK;
 	} else {
-		printk(KERN_WARNING "btrfs: unexpected inode type %o",
+		btrfs_warn(sctx->send_root->fs_info, "unexpected inode type %o",
 				(int)(mode & S_IFMT));
 		ret = -ENOTSUPP;
 		goto out;

commit b786f16ac3c5d4f7a5fd136656b6a1301b29b73b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Sep 26 15:30:23 2015 +0100

    Btrfs: send, fix corner case for reference overwrite detection
    
    When the inode given to did_overwrite_ref() matches the current progress
    and has a reference that collides with the reference of other inode that
    has the same number as the current progress, we were always telling our
    caller that the inode's reference was overwritten, which is incorrect
    because the other inode might be a new inode (different generation number)
    in which case we must return false from did_overwrite_ref() so that its
    callers don't use an orphanized path for the inode (as it will never be
    orphanized, instead it will be unlinked and the new inode created later).
    
    The following test case for fstests reproduces the issue:
    
      seq=`basename $0`
      seqres=$RESULT_DIR/$seq
      echo "QA output created by $seq"
    
      tmp=/tmp/$$
      status=1      # failure is the default!
      trap "_cleanup; exit \$status" 0 1 2 3 15
    
      _cleanup()
      {
          rm -fr $send_files_dir
          rm -f $tmp.*
      }
    
      # get standard environment, filters and checks
      . ./common/rc
      . ./common/filter
    
      # real QA test starts here
      _supported_fs btrfs
      _supported_os Linux
      _require_scratch
      _need_to_be_root
    
      send_files_dir=$TEST_DIR/btrfs-test-$seq
    
      rm -f $seqres.full
      rm -fr $send_files_dir
      mkdir $send_files_dir
    
      _scratch_mkfs >>$seqres.full 2>&1
      _scratch_mount
    
      # Create our test file with a single extent of 64K.
      mkdir -p $SCRATCH_MNT/foo
      $XFS_IO_PROG -f -c "pwrite -S 0xaa 0 64K" $SCRATCH_MNT/foo/bar \
          | _filter_xfs_io
    
      _run_btrfs_util_prog subvolume snapshot -r $SCRATCH_MNT \
          $SCRATCH_MNT/mysnap1
      _run_btrfs_util_prog subvolume snapshot $SCRATCH_MNT \
          $SCRATCH_MNT/mysnap2
    
      echo "File digest before being replaced:"
      md5sum $SCRATCH_MNT/mysnap1/foo/bar | _filter_scratch
    
      # Remove the file and then create a new one in the same location with
      # the same name but with different content. This new file ends up
      # getting the same inode number as the previous one, because that inode
      # number was the highest inode number used by the snapshot's root and
      # therefore when attempting to find the a new inode number for the new
      # file, we end up reusing the same inode number. This happens because
      # currently btrfs uses the highest inode number summed by 1 for the
      # first inode created once a snapshot's root is loaded (done at
      # fs/btrfs/inode-map.c:btrfs_find_free_objectid in the linux kernel
      # tree).
      # Having these two different files in the snapshots with the same inode
      # number (but different generation numbers) caused the btrfs send code
      # to emit an incorrect path for the file when issuing an unlink
      # operation because it failed to realize they were different files.
      rm -f $SCRATCH_MNT/mysnap2/foo/bar
      $XFS_IO_PROG -f -c "pwrite -S 0xbb 0 96K" \
          $SCRATCH_MNT/mysnap2/foo/bar | _filter_xfs_io
    
      _run_btrfs_util_prog subvolume snapshot -r $SCRATCH_MNT/mysnap2 \
          $SCRATCH_MNT/mysnap2_ro
    
      _run_btrfs_util_prog send $SCRATCH_MNT/mysnap1 -f $send_files_dir/1.snap
      _run_btrfs_util_prog send -p $SCRATCH_MNT/mysnap1 \
          $SCRATCH_MNT/mysnap2_ro -f $send_files_dir/2.snap
    
      echo "File digest in the original filesystem after being replaced:"
      md5sum $SCRATCH_MNT/mysnap2_ro/foo/bar | _filter_scratch
    
      # Now recreate the filesystem by receiving both send streams and verify
      # we get the same file contents that the original filesystem had.
      _scratch_unmount
      _scratch_mkfs >>$seqres.full 2>&1
      _scratch_mount
    
      _run_btrfs_util_prog receive -vv $SCRATCH_MNT -f $send_files_dir/1.snap
      _run_btrfs_util_prog receive -vv $SCRATCH_MNT -f $send_files_dir/2.snap
    
      echo "File digest in the new filesystem:"
      # Must match the digest from the new file.
      md5sum $SCRATCH_MNT/mysnap2_ro/foo/bar | _filter_scratch
    
      status=0
      exit
    
    Reported-by: Martin Raiber <martin@urbackup.org>
    Fixes: 8b191a684968 ("Btrfs: incremental send, check if orphanized dir inode needs delayed rename")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index aa72bfd28f7d..a739b825bdd3 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1920,10 +1920,12 @@ static int did_overwrite_ref(struct send_ctx *sctx,
 	/*
 	 * We know that it is or will be overwritten. Check this now.
 	 * The current inode being processed might have been the one that caused
-	 * inode 'ino' to be orphanized, therefore ow_inode can actually be the
-	 * same as sctx->send_progress.
+	 * inode 'ino' to be orphanized, therefore check if ow_inode matches
+	 * the current inode being processed.
 	 */
-	if (ow_inode <= sctx->send_progress)
+	if ((ow_inode < sctx->send_progress) ||
+	    (ino != sctx->cur_ino && ow_inode == sctx->cur_ino &&
+	     gen == sctx->cur_inode_gen))
 		ret = 1;
 	else
 		ret = 0;

commit 37b8d27de5d0079e1ecef2711061048e13054ebe
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Jun 4 17:17:25 2015 -0400

    Btrfs: use received_uuid of parent during send
    
    Neil Horman pointed out a problem where if he did something like this
    
    receive A
    snap A B
    change B
    send -p A B
    
    and then on another box do
    
    recieve A
    receive B
    
    the receive B would fail because we use the UUID of A for the clone sources for
    B.  This makes sense most of the time because normally you are sending from the
    original sources, not a received source.  However when you use a recieved subvol
    its UUID is going to be something completely different, so if you then try to
    receive the diff on a different volume it won't find the UUID because the new A
    will be something else.  The only constant is the received uuid.  So instead
    check to see if we have received_uuid set on the root, and if so use that as the
    clone source, as btrfs receive looks for matches either in received_uuid or
    uuid.  Thanks,
    
    Reported-by: Neil Horman <nhorman@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Hugo Mills <hugo@carfax.org.uk>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 50ebc622a324..aa72bfd28f7d 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2356,8 +2356,12 @@ static int send_subvol_begin(struct send_ctx *sctx)
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_CTRANSID,
 		    le64_to_cpu(sctx->send_root->root_item.ctransid));
 	if (parent_root) {
-		TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
-				sctx->parent_root->root_item.uuid);
+		if (!btrfs_is_empty_uuid(parent_root->root_item.received_uuid))
+			TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
+				     parent_root->root_item.received_uuid);
+		else
+			TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
+				     parent_root->root_item.uuid);
 		TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_CTRANSID,
 			    le64_to_cpu(sctx->parent_root->root_item.ctransid));
 	}
@@ -4586,8 +4590,21 @@ verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
 	if (ret < 0)
 		goto out;
 
-	TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
-			clone_root->root->root_item.uuid);
+	/*
+	 * If the parent we're using has a received_uuid set then use that as
+	 * our clone source as that is what we will look for when doing a
+	 * receive.
+	 *
+	 * This covers the case that we create a snapshot off of a received
+	 * subvolume and then use that as the parent and try to receive on a
+	 * different host.
+	 */
+	if (!btrfs_is_empty_uuid(clone_root->root->root_item.received_uuid))
+		TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
+			     clone_root->root->root_item.received_uuid);
+	else
+		TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
+			     clone_root->root->root_item.uuid);
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_CTRANSID,
 		    le64_to_cpu(clone_root->root->root_item.ctransid));
 	TLV_PUT_PATH(sctx, BTRFS_SEND_A_CLONE_PATH, p);

commit 1ab818b137e198e4d06e987a4b089411f2e39d40
Merge: 6ca070975671 8b191a684968
Author: Chris Mason <clm@fb.com>
Date:   Wed Jun 3 19:44:59 2015 -0700

    Merge branch 'send_fixes_4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/fdmanana/linux into for-linus-4.2

commit 619d8c4ef7c5dd346add55da82c9179cd2e3387e
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sun May 3 01:56:00 2015 +0100

    Btrfs: incremental send, fix clone operations for compressed extents
    
    Marc reported a problem where the receiving end of an incremental send
    was performing clone operations that failed with -EINVAL. This happened
    because, unlike for uncompressed extents, we were not checking if the
    source clone offset and length, after summing the data offset, falls
    within the source file's boundaries.
    
    So make sure we do such checks when attempting to issue clone operations
    for compressed extents.
    
    Problem reproducible with the following steps:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount -o compress /dev/sdb /mnt
      $ mkfs.btrfs -f /dev/sdc
      $ mount -o compress /dev/sdc /mnt2
    
      # Create the file with a single extent of 128K. This creates a metadata file
      # extent item with a data start offset of 0 and a logical length of 128K.
      $ xfs_io -f -c "pwrite -S 0xaa 64K 128K" -c "fsync" /mnt/foo
    
      # Now rewrite the range 64K to 112K of our file. This will make the inode's
      # metadata continue to point to the 128K extent we created before, but now
      # with an extent item that points to the extent with a data start offset of
      # 112K and a logical length of 16K.
      # That metadata file extent item is associated with the logical file offset
      # at 176K and covers the logical file range 176K to 192K.
      $ xfs_io -c "pwrite -S 0xbb 64K 112K" -c "fsync" /mnt/foo
    
      # Now rewrite the range 180K to 12K. This will make the inode's metadata
      # continue to point the the 128K extent we created earlier, with a single
      # extent item that points to it with a start offset of 112K and a logical
      # length of 4K.
      # That metadata file extent item is associated with the logical file offset
      # at 176K and covers the logical file range 176K to 180K.
      $ xfs_io -c "pwrite -S 0xcc 180K 12K" -c "fsync" /mnt/foo
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap1
    
      $ touch /mnt/bar
      # Calls the btrfs clone ioctl.
      $ ~/xfstests/src/cloner -s $((176 * 1024)) -d $((176 * 1024)) \
        -l $((4 * 1024)) /mnt/foo /mnt/bar
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap2
    
      $ btrfs send /mnt/snap1 | btrfs receive /mnt2
      At subvol /mnt/snap1
      At subvol snap1
    
      $ btrfs send -p /mnt/snap1 /mnt/snap2 | btrfs receive /mnt2
      At subvol /mnt/snap2
      At snapshot snap2
      ERROR: failed to clone extents to bar
      Invalid argument
    
    A test case for fstests follows soon.
    
    Reported-by: Marc MERLIN <marc@merlins.org>
    Tested-by: Marc MERLIN <marc@merlins.org>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Tested-by: Jan Alexander Steffens (heftig) <jan.steffens@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a1216f9b4917..5cf7838fb5e5 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1158,6 +1158,9 @@ struct backref_ctx {
 	/* may be truncated in case it's the last extent in a file */
 	u64 extent_len;
 
+	/* data offset in the file extent item */
+	u64 data_offset;
+
 	/* Just to check for bugs in backref resolving */
 	int found_itself;
 };
@@ -1221,7 +1224,7 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 	if (ret < 0)
 		return ret;
 
-	if (offset + bctx->extent_len > i_size)
+	if (offset + bctx->data_offset + bctx->extent_len > i_size)
 		return 0;
 
 	/*
@@ -1363,6 +1366,19 @@ static int find_extent_clone(struct send_ctx *sctx,
 	backref_ctx->cur_offset = data_offset;
 	backref_ctx->found_itself = 0;
 	backref_ctx->extent_len = num_bytes;
+	/*
+	 * For non-compressed extents iterate_extent_inodes() gives us extent
+	 * offsets that already take into account the data offset, but not for
+	 * compressed extents, since the offset is logical and not relative to
+	 * the physical extent locations. We must take this into account to
+	 * avoid sending clone offsets that go beyond the source file's size,
+	 * which would result in the clone ioctl failing with -EINVAL on the
+	 * receiving end.
+	 */
+	if (compressed == BTRFS_COMPRESS_NONE)
+		backref_ctx->data_offset = 0;
+	else
+		backref_ctx->data_offset = btrfs_file_extent_offset(eb, fi);
 
 	/*
 	 * The last extent of a file may be too large due to page alignment.

commit 8b191a684968e24b34c9894024b37532c68e6ae8
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Apr 9 14:09:14 2015 +0100

    Btrfs: incremental send, check if orphanized dir inode needs delayed rename
    
    If a directory inode is orphanized, because some inode previously
    processed has a new name that collides with the old name of the current
    inode, we need to check if it needs its rename operation delayed too,
    as its ancestor-descendent relationship with some other inode might
    have been reversed between the parent and send snapshots and therefore
    its rename operation needs to happen after that other inode is renamed.
    
    For example, for the following reproducer where this is needed (provided
    by Robbie Ko):
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt2
    
      $ mkdir -p /mnt/data/n1/n2
      $ mkdir /mnt/data/n4
      $ mkdir -p /mnt/data/t6/t7
      $ mkdir /mnt/data/t5
      $ mkdir /mnt/data/t7
      $ mkdir /mnt/data/n4/t2
      $ mkdir /mnt/data/t4
      $ mkdir /mnt/data/t3
      $ mv /mnt/data/t7 /mnt/data/n4/t2
      $ mv /mnt/data/t4 /mnt/data/n4/t2/t7
      $ mv /mnt/data/t5 /mnt/data/n4/t2/t7/t4
      $ mv /mnt/data/t6 /mnt/data/n4/t2/t7/t4/t5
      $ mv /mnt/data/n1/n2 /mnt/data/n4/t2/t7/t4/t5/t6
      $ mv /mnt/data/n1 /mnt/data/n4/t2/t7/t4/t5/t6
      $ mv /mnt/data/n4/t2/t7/t4/t5/t6/t7 /mnt/data/n4/t2/t7/t4/t5/t6/n2
      $ mv /mnt/data/t3 /mnt/data/n4/t2/t7/t4/t5/t6/n2/t7
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap1
    
      $ mv /mnt/data/n4/t2/t7/t4/t5/t6/n1 /mnt/data/n4
      $ mv /mnt/data/n4/t2 /mnt/data/n4/n1
      $ mv /mnt/data/n4/n1/t2/t7/t4/t5/t6/n2 /mnt/data/n4/n1/t2
      $ mv /mnt/data/n4/n1/t2/n2/t7/t3 /mnt/data/n4/n1/t2
      $ mv /mnt/data/n4/n1/t2/t7/t4/t5/t6 /mnt/data/n4/n1/t2
      $ mv /mnt/data/n4/n1/t2/t7/t4 /mnt/data/n4/n1/t2/t6
      $ mv /mnt/data/n4/n1/t2/t7 /mnt/data/n4/n1/t2/t3
      $ mv /mnt/data/n4/n1/t2/n2/t7 /mnt/data/n4/n1/t2
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap2
    
      $ btrfs send /mnt/snap1 | btrfs receive /mnt2
      $ btrfs send -p /mnt/snap1 /mnt/snap2 | btrfs receive /mnt2
      ERROR: send ioctl failed with -12: Cannot allocate memory
    
    Where the parent snapshot directory hierarchy is the following:
    
      .                                                        (ino 256)
      |-- data/                                                (ino 257)
            |-- n4/                                            (ino 260)
                 |-- t2/                                       (ino 265)
                      |-- t7/                                  (ino 264)
                           |-- t4/                             (ino 266)
                                |-- t5/                        (ino 263)
                                     |-- t6/                   (ino 261)
                                          |-- n1/              (ino 258)
                                          |-- n2/              (ino 259)
                                               |-- t7/         (ino 262)
                                                    |-- t3/    (ino 267)
    
    And the send snapshot's directory hierarchy is the following:
    
      .                                                        (ino 256)
      |-- data/                                                (ino 257)
            |-- n4/                                            (ino 260)
                 |-- n1/                                       (ino 258)
                      |-- t2/                                  (ino 265)
                           |-- n2/                             (ino 259)
                           |-- t3/                             (ino 267)
                           |    |-- t7                         (ino 264)
                           |
                           |-- t6/                             (ino 261)
                           |    |-- t4/                        (ino 266)
                           |         |-- t5/                   (ino 263)
                           |
                           |-- t7/                             (ino 262)
    
    While processing inode 262 we orphanize inode 264 and later attempt
    to rename inode 264 to its new name/location, which resulted in building
    an incorrect destination path string for the rename operation with the
    value "data/n4/t2/t7/t4/t5/t6/n2/t7/t3/t7". This rename operation must
    have been done only after inode 267 is processed and renamed, as the
    ancestor-descendent relationship between inodes 264 and 267 was reversed
    between both snapshots, because otherwise it results in an infinite loop
    when building the path string for inode 264 when we are processing an
    inode with a number larger than 264. That loop is the following:
    
      start inode 264, send progress of 265 for example
      parent of 264 -> 267
      parent of 267 -> 262
      parent of 262 -> 259
      parent of 259 -> 261
      parent of 261 -> 263
      parent of 263 -> 266
      parent of 266 -> 264
        |--> back to first iteration while current path string length
             is <= PATH_MAX, and fail with -ENOMEM otherwise
    
    So fix this by making the check if we need to delay a directory rename
    regardless of the current inode having been orphanized or not.
    
    A test case for fstests follows soon.
    
    Thanks to Robbie Ko for providing a reproducer for this problem.
    
    Reported-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 2ed36af6e43a..895f1b180b2f 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -243,6 +243,7 @@ struct waiting_dir_move {
 	 * after this directory is moved, we can try to rmdir the ino rmdir_ino.
 	 */
 	u64 rmdir_ino;
+	bool orphanized;
 };
 
 struct orphan_dir_info {
@@ -1900,8 +1901,13 @@ static int did_overwrite_ref(struct send_ctx *sctx,
 		goto out;
 	}
 
-	/* we know that it is or will be overwritten. check this now */
-	if (ow_inode < sctx->send_progress)
+	/*
+	 * We know that it is or will be overwritten. Check this now.
+	 * The current inode being processed might have been the one that caused
+	 * inode 'ino' to be orphanized, therefore ow_inode can actually be the
+	 * same as sctx->send_progress.
+	 */
+	if (ow_inode <= sctx->send_progress)
 		ret = 1;
 	else
 		ret = 0;
@@ -2223,6 +2229,8 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 	fs_path_reset(dest);
 
 	while (!stop && ino != BTRFS_FIRST_FREE_OBJECTID) {
+		struct waiting_dir_move *wdm;
+
 		fs_path_reset(name);
 
 		if (is_waiting_for_rm(sctx, ino)) {
@@ -2233,7 +2241,11 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 			break;
 		}
 
-		if (is_waiting_for_move(sctx, ino)) {
+		wdm = get_waiting_dir_move(sctx, ino);
+		if (wdm && wdm->orphanized) {
+			ret = gen_unique_name(sctx, ino, gen, name);
+			stop = 1;
+		} else if (wdm) {
 			ret = get_first_ref(sctx->parent_root, ino,
 					    &parent_inode, &parent_gen, name);
 		} else {
@@ -2923,7 +2935,7 @@ static int is_waiting_for_move(struct send_ctx *sctx, u64 ino)
 	return entry != NULL;
 }
 
-static int add_waiting_dir_move(struct send_ctx *sctx, u64 ino)
+static int add_waiting_dir_move(struct send_ctx *sctx, u64 ino, bool orphanized)
 {
 	struct rb_node **p = &sctx->waiting_dir_moves.rb_node;
 	struct rb_node *parent = NULL;
@@ -2934,6 +2946,7 @@ static int add_waiting_dir_move(struct send_ctx *sctx, u64 ino)
 		return -ENOMEM;
 	dm->ino = ino;
 	dm->rmdir_ino = 0;
+	dm->orphanized = orphanized;
 
 	while (*p) {
 		parent = *p;
@@ -3030,7 +3043,7 @@ static int add_pending_dir_move(struct send_ctx *sctx,
 			goto out;
 	}
 
-	ret = add_waiting_dir_move(sctx, pm->ino);
+	ret = add_waiting_dir_move(sctx, pm->ino, is_orphan);
 	if (ret)
 		goto out;
 
@@ -3385,7 +3398,8 @@ static int is_ancestor(struct btrfs_root *root,
 }
 
 static int wait_for_parent_move(struct send_ctx *sctx,
-				struct recorded_ref *parent_ref)
+				struct recorded_ref *parent_ref,
+				const bool is_orphan)
 {
 	int ret = 0;
 	u64 ino = parent_ref->dir;
@@ -3464,7 +3478,7 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 					   ino,
 					   &sctx->new_refs,
 					   &sctx->deleted_refs,
-					   false);
+					   is_orphan);
 		if (!ret)
 			ret = 1;
 	}
@@ -3633,6 +3647,17 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 			}
 		}
 
+		if (S_ISDIR(sctx->cur_inode_mode) && sctx->parent_root &&
+		    can_rename) {
+			ret = wait_for_parent_move(sctx, cur, is_orphan);
+			if (ret < 0)
+				goto out;
+			if (ret == 1) {
+				can_rename = false;
+				*pending_move = 1;
+			}
+		}
+
 		/*
 		 * link/move the ref to the new place. If we have an orphan
 		 * inode, move it and update valid_path. If not, link or move
@@ -3653,18 +3678,11 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 				 * dirs, we always have one new and one deleted
 				 * ref. The deleted ref is ignored later.
 				 */
-				ret = wait_for_parent_move(sctx, cur);
-				if (ret < 0)
-					goto out;
-				if (ret) {
-					*pending_move = 1;
-				} else {
-					ret = send_rename(sctx, valid_path,
-							  cur->full_path);
-					if (!ret)
-						ret = fs_path_copy(valid_path,
-							       cur->full_path);
-				}
+				ret = send_rename(sctx, valid_path,
+						  cur->full_path);
+				if (!ret)
+					ret = fs_path_copy(valid_path,
+							   cur->full_path);
 				if (ret < 0)
 					goto out;
 			} else {

commit 80aa6027561eef12b49031d46fd6724daf1e7fb6
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Mar 27 17:50:45 2015 +0000

    Btrfs: incremental send, don't delay directory renames unnecessarily
    
    Even though we delay the rename of directories when they become
    descendents of other directories that were also renamed in the send
    root to prevent infinite path build loops, we were doing it in cases
    where this was not needed and was actually harmful resulting in
    infinite path build loops as we ended up with a circular dependency
    of delayed directory renames.
    
    Consider the following reproducer:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt2
    
      $ mkdir /mnt/data
      $ mkdir /mnt/data/n1
      $ mkdir /mnt/data/n1/n2
      $ mkdir /mnt/data/n4
      $ mkdir /mnt/data/n1/n2/p1
      $ mkdir /mnt/data/n1/n2/p1/p2
      $ mkdir /mnt/data/t6
      $ mkdir /mnt/data/t7
      $ mkdir -p /mnt/data/t5/t7
      $ mkdir /mnt/data/t2
      $ mkdir /mnt/data/t4
      $ mkdir -p /mnt/data/t1/t3
      $ mkdir /mnt/data/p1
      $ mv /mnt/data/t1 /mnt/data/p1
      $ mkdir -p /mnt/data/p1/p2
      $ mv /mnt/data/t4 /mnt/data/p1/p2/t1
      $ mv /mnt/data/t5 /mnt/data/n4/t5
      $ mv /mnt/data/n1/n2/p1/p2 /mnt/data/n4/t5/p2
      $ mv /mnt/data/t7 /mnt/data/n4/t5/p2/t7
      $ mv /mnt/data/t2 /mnt/data/n4/t1
      $ mv /mnt/data/p1 /mnt/data/n4/t5/p2/p1
      $ mv /mnt/data/n1/n2 /mnt/data/n4/t5/p2/p1/p2/n2
      $ mv /mnt/data/n4/t5/p2/p1/p2/t1 /mnt/data/n4/t5/p2/p1/p2/n2/t1
      $ mv /mnt/data/n4/t5/t7 /mnt/data/n4/t5/p2/p1/p2/n2/t1/t7
      $ mv /mnt/data/n4/t5/p2/p1/t1/t3 /mnt/data/n4/t5/p2/p1/p2/n2/t1/t3
      $ mv /mnt/data/n4/t5/p2/p1/p2/n2/p1 /mnt/data/n4/t5/p2/p1/p2/n2/t1/t7/p1
      $ mv /mnt/data/t6 /mnt/data/n4/t5/p2/p1/p2/n2/t1/t3/t5
      $ mv /mnt/data/n4/t5/p2/p1/t1 /mnt/data/n4/t5/p2/p1/p2/n2/t1/t3/t1
      $ mv /mnt/data/n1 /mnt/data/n4/t5/p2/p1/p2/n2/t1/t7/p1/n1
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap1
    
      $ mv /mnt/data/n4/t1 /mnt/data/n4/t5/p2/p1/p2/n2/t1/t7/p1/t1
      $ mv /mnt/data/n4/t5/p2/p1/p2/n2/t1 /mnt/data/n4/
      $ mv /mnt/data/n4/t5/p2/p1/p2/n2 /mnt/data/n4/t1/n2
      $ mv /mnt/data/n4/t1/t7/p1 /mnt/data/n4/t1/n2/p1
      $ mv /mnt/data/n4/t1/t3/t1 /mnt/data/n4/t1/n2/t1
      $ mv /mnt/data/n4/t1/t3 /mnt/data/n4/t1/n2/t1/t3
      $ mv /mnt/data/n4/t5/p2/p1/p2 /mnt/data/n4/t1/n2/p1/p2
      $ mv /mnt/data/n4/t1/t7 /mnt/data/n4/t1/n2/p1/t7
      $ mv /mnt/data/n4/t5/p2/p1 /mnt/data/n4/t1/n2/p1/p2/p1
      $ mv /mnt/data/n4/t1/n2/t1/t3/t5 /mnt/data/n4/t1/n2/p1/p2/t5
      $ mv /mnt/data/n4/t5 /mnt/data/n4/t1/n2/p1/p2/p1/t5
      $ mv /mnt/data/n4/t1/n2/p1/p2/p1/t5/p2 /mnt/data/n4/t1/n2/p1/p2/p1/p2
      $ mv /mnt/data/n4/t1/n2/p1/p2/p1/p2/t7 /mnt/data/n4/t1/t7
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap2
    
      $ btrfs send /mnt/snap1 | btrfs receive /mnt2
      $ btrfs send -p /mnt/snap1 /mnt/snap2 | btrfs receive -vv /mnt2
      ERROR: send ioctl failed with -12: Cannot allocate memory
    
    This reproducer resulted in an infinite path build loop when building the
    path for inode 266 because the following circular dependency of delayed
    directory renames was created:
    
       ino 272 <- ino 261 <- ino 259 <- ino 268 <- ino 267 <- ino 261
    
    Where the notation "X <- Y" means the rename of inode X is delayed by the
    rename of inode Y (X will be renamed after Y is renamed). This resulted
    in an infinite path build loop of inode 266 because that inode has inode
    261 as an ancestor in the send root and inode 261 is in the circular
    dependency of delayed renames listed above.
    
    Fix this by not delaying the rename of a directory inode if an ancestor of
    the inode in the send root, which has a delayed rename operation, is not
    also a descendent of the inode in the parent root.
    
    Thanks to Robbie Ko for sending the reproducer example.
    A test case for xfstests follows soon.
    
    Reported-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a1216f9b4917..2ed36af6e43a 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3353,6 +3353,37 @@ static int wait_for_dest_dir_move(struct send_ctx *sctx,
 	return ret;
 }
 
+/*
+ * Check if ino ino1 is an ancestor of inode ino2 in the given root.
+ * Return 1 if true, 0 if false and < 0 on error.
+ */
+static int is_ancestor(struct btrfs_root *root,
+		       const u64 ino1,
+		       const u64 ino1_gen,
+		       const u64 ino2,
+		       struct fs_path *fs_path)
+{
+	u64 ino = ino2;
+
+	while (ino > BTRFS_FIRST_FREE_OBJECTID) {
+		int ret;
+		u64 parent;
+		u64 parent_gen;
+
+		fs_path_reset(fs_path);
+		ret = get_first_ref(root, ino, &parent, &parent_gen, fs_path);
+		if (ret < 0) {
+			if (ret == -ENOENT && ino == ino2)
+				ret = 0;
+			return ret;
+		}
+		if (parent == ino1)
+			return parent_gen == ino1_gen ? 1 : 0;
+		ino = parent;
+	}
+	return 0;
+}
+
 static int wait_for_parent_move(struct send_ctx *sctx,
 				struct recorded_ref *parent_ref)
 {
@@ -3374,11 +3405,24 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 	 * Our current directory inode may not yet be renamed/moved because some
 	 * ancestor (immediate or not) has to be renamed/moved first. So find if
 	 * such ancestor exists and make sure our own rename/move happens after
-	 * that ancestor is processed.
+	 * that ancestor is processed to avoid path build infinite loops (done
+	 * at get_cur_path()).
 	 */
 	while (ino > BTRFS_FIRST_FREE_OBJECTID) {
 		if (is_waiting_for_move(sctx, ino)) {
-			ret = 1;
+			/*
+			 * If the current inode is an ancestor of ino in the
+			 * parent root, we need to delay the rename of the
+			 * current inode, otherwise don't delayed the rename
+			 * because we can end up with a circular dependency
+			 * of renames, resulting in some directories never
+			 * getting the respective rename operations issued in
+			 * the send stream or getting into infinite path build
+			 * loops.
+			 */
+			ret = is_ancestor(sctx->parent_root,
+					  sctx->cur_ino, sctx->cur_inode_gen,
+					  ino, path_before);
 			break;
 		}
 

commit 5f806c3ae2ff6263a10a6901f97abb74dac03d36
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Mar 12 16:04:50 2015 +0000

    Btrfs: incremental send, remove dead code
    
    The logic to detect path loops when attempting to apply a pending
    directory rename, introduced in commit
    f959492fc15b (Btrfs: send, fix more issues related to directory renames)
    is no longer needed, and the respective fstests test case for that commit,
    btrfs/045, now passes without this code (as well as all the other test
    cases for send/receive).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 00cb924884f5..a1216f9b4917 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3067,48 +3067,6 @@ static struct pending_dir_move *get_pending_dir_moves(struct send_ctx *sctx,
 	return NULL;
 }
 
-static int path_loop(struct send_ctx *sctx, struct fs_path *name,
-		     u64 ino, u64 gen, u64 *ancestor_ino)
-{
-	int ret = 0;
-	u64 parent_inode = 0;
-	u64 parent_gen = 0;
-	u64 start_ino = ino;
-
-	*ancestor_ino = 0;
-	while (ino != BTRFS_FIRST_FREE_OBJECTID) {
-		fs_path_reset(name);
-
-		if (is_waiting_for_rm(sctx, ino))
-			break;
-		if (is_waiting_for_move(sctx, ino)) {
-			if (*ancestor_ino == 0)
-				*ancestor_ino = ino;
-			ret = get_first_ref(sctx->parent_root, ino,
-					    &parent_inode, &parent_gen, name);
-		} else {
-			ret = __get_cur_name_and_parent(sctx, ino, gen,
-							&parent_inode,
-							&parent_gen, name);
-			if (ret > 0) {
-				ret = 0;
-				break;
-			}
-		}
-		if (ret < 0)
-			break;
-		if (parent_inode == start_ino) {
-			ret = 1;
-			if (*ancestor_ino == 0)
-				*ancestor_ino = ino;
-			break;
-		}
-		ino = parent_inode;
-		gen = parent_gen;
-	}
-	return ret;
-}
-
 static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 {
 	struct fs_path *from_path = NULL;
@@ -3120,7 +3078,6 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	struct waiting_dir_move *dm = NULL;
 	u64 rmdir_ino = 0;
 	int ret;
-	u64 ancestor = 0;
 
 	name = fs_path_alloc();
 	from_path = fs_path_alloc();
@@ -3152,22 +3109,6 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 		goto out;
 
 	sctx->send_progress = sctx->cur_ino + 1;
-	ret = path_loop(sctx, name, pm->ino, pm->gen, &ancestor);
-	if (ret) {
-		LIST_HEAD(deleted_refs);
-		ASSERT(ancestor > BTRFS_FIRST_FREE_OBJECTID);
-		ret = add_pending_dir_move(sctx, pm->ino, pm->gen, ancestor,
-					   &pm->update_refs, &deleted_refs,
-					   pm->is_orphan);
-		if (ret < 0)
-			goto out;
-		if (rmdir_ino) {
-			dm = get_waiting_dir_move(sctx, pm->ino);
-			ASSERT(dm);
-			dm->rmdir_ino = rmdir_ino;
-		}
-		goto out;
-	}
 	fs_path_reset(name);
 	to_path = name;
 	name = NULL;

commit 8996a48c0a8ed01c55f52e6794625c95a9977ee6
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Mar 12 15:16:20 2015 +0000

    Btrfs: incremental send, clear name from cache after orphanization
    
    If a directory's reference ends up being orphanized, because the inode
    currently being processed has a new path that matches that directory's
    path, make sure we evict the name of the directory from the name cache.
    This is because there might be descendent inodes (either directories or
    regular files) that will be orphanized later too, and therefore the
    orphan name of the ancestor must be used, otherwise we send issue rename
    operations with a wrong path in the send stream.
    
    Reproducer:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
    
      $ mkdir -p /mnt/data/n1/n2/p1/p2
      $ mkdir /mnt/data/n4
      $ mkdir -p /mnt/data/p1/p2
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap1
    
      $ mv /mnt/data/p1/p2 /mnt/data
      $ mv /mnt/data/n1/n2/p1/p2 /mnt/data/p1
      $ mv /mnt/data/p2 /mnt/data/n1/n2/p1
      $ mv /mnt/data/n1/n2 /mnt/data/p1
      $ mv /mnt/data/p1 /mnt/data/n4
      $ mv /mnt/data/n4/p1/n2/p1 /mnt/data
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap2
    
      $ btrfs send /mnt/snap1 -f /tmp/1.send
      $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/2.send
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt2
      $ btrfs receive /mnt2 -f /tmp/1.send
      $ btrfs receive /mnt2 -f /tmp/2.send
      ERROR: rename data/p1/p2 -> data/n4/p1/p2 failed. no such file or directory
    
    Directories data/p1 (inode 263) and data/p1/p2 (inode 264) in the parent
    snapshot are both orphanized during the incremental send, and as soon as
    data/p1 is orphanized, we must make sure that when orphanizing data/p1/p2
    we use a source path of o263-6-o/p2 for the rename operation instead of
    the old path data/p1/p2 (the one before the orphanization of inode 263).
    
    A test case for xfstests follows soon.
    
    Reported-by: Robbie Ko <robbieko@synology.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 571de5a08fe7..00cb924884f5 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3610,10 +3610,27 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 			if (ret < 0)
 				goto out;
 			if (ret) {
+				struct name_cache_entry *nce;
+
 				ret = orphanize_inode(sctx, ow_inode, ow_gen,
 						cur->full_path);
 				if (ret < 0)
 					goto out;
+				/*
+				 * Make sure we clear our orphanized inode's
+				 * name from the name cache. This is because the
+				 * inode ow_inode might be an ancestor of some
+				 * other inode that will be orphanized as well
+				 * later and has an inode number greater than
+				 * sctx->send_progress. We need to prevent
+				 * future name lookups from using the old name
+				 * and get instead the orphan name.
+				 */
+				nce = name_cache_search(sctx, ow_inode, ow_gen);
+				if (nce) {
+					name_cache_delete(sctx, nce);
+					kfree(nce);
+				}
 			} else {
 				ret = send_unlink(sctx, cur->full_path);
 				if (ret < 0)

commit 2f1f465ae6da244099af55c066e5355abd8ff620
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Mar 2 20:53:53 2015 +0000

    Btrfs: send, don't leave without decrementing clone root's send_progress
    
    If the clone root was not readonly or the dead flag was set on it, we were
    leaving without decrementing the root's send_progress counter (and before
    we just incremented it). If a concurrent snapshot deletion was in progress
    and ended up being aborted, it would be impossible to later attempt to
    delete again the snapshot, since the root's send_in_progress counter could
    never go back to 0.
    
    We were also setting clone_sources_to_rollback to i + 1 too early - if we
    bailed out because the clone root we got is not readonly or flagged as dead
    we ended up later derreferencing a null pointer because we didn't assign
    the clone root to sctx->clone_roots[i].root:
    
                    for (i = 0; sctx && i < clone_sources_to_rollback; i++)
                            btrfs_root_dec_send_in_progress(
                                            sctx->clone_roots[i].root);
    
    So just don't increment the send_in_progress counter if the root is readonly
    or flagged as dead.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 6ec28f13659e..571de5a08fe7 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5852,9 +5852,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 				ret = PTR_ERR(clone_root);
 				goto out;
 			}
-			clone_sources_to_rollback = i + 1;
 			spin_lock(&clone_root->root_item_lock);
-			clone_root->send_in_progress++;
 			if (!btrfs_root_readonly(clone_root) ||
 			    btrfs_root_dead(clone_root)) {
 				spin_unlock(&clone_root->root_item_lock);
@@ -5862,10 +5860,12 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 				ret = -EPERM;
 				goto out;
 			}
+			clone_root->send_in_progress++;
 			spin_unlock(&clone_root->root_item_lock);
 			srcu_read_unlock(&fs_info->subvol_srcu, index);
 
 			sctx->clone_roots[i].root = clone_root;
+			clone_sources_to_rollback = i + 1;
 		}
 		vfree(clone_sources_tmp);
 		clone_sources_tmp = NULL;

commit 5cc2b17e80cf5770f2e585c2d90fd8af1b901258
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Mar 2 20:53:52 2015 +0000

    Btrfs: send, add missing check for dead clone root
    
    After we locked the root's root item, a concurrent snapshot deletion
    call might have set the dead flag on it. So check if the dead flag
    is set and abort if it is, just like we do for the parent root.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d6033f540cc7..6ec28f13659e 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5855,7 +5855,8 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			clone_sources_to_rollback = i + 1;
 			spin_lock(&clone_root->root_item_lock);
 			clone_root->send_in_progress++;
-			if (!btrfs_root_readonly(clone_root)) {
+			if (!btrfs_root_readonly(clone_root) ||
+			    btrfs_root_dead(clone_root)) {
 				spin_unlock(&clone_root->root_item_lock);
 				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = -EPERM;

commit 84471e2429ed82fdbac0c56d5b2a18d450f99f6a
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Feb 28 22:29:22 2015 +0000

    Btrfs: incremental send, don't rename a directory too soon
    
    There's one more case where we can't issue a rename operation for a
    directory as soon as we process it. We used to delay directory renames
    only if they have some ancestor directory with a higher inode number
    that got renamed too, but there's another case where we need to delay
    the rename too - when a directory A is renamed to the old name of a
    directory B but that directory B has its rename delayed because it
    has now (in the send root) an ancestor with a higher inode number that
    was renamed. If we don't delay the directory rename in this case, the
    receiving end of the send stream will attempt to rename A to the old
    name of B before B got renamed to its new name, which results in a
    "directory not empty" error. So fix this by delaying directory renames
    for this case too.
    
    Steps to reproduce:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
    
      $ mkdir /mnt/a
      $ mkdir /mnt/b
      $ mkdir /mnt/c
      $ touch /mnt/a/file
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap1
    
      $ mv /mnt/c /mnt/x
      $ mv /mnt/a /mnt/x/y
      $ mv /mnt/b /mnt/a
    
      $ btrfs subvolume snapshot -r /mnt /mnt/snap2
    
      $ btrfs send /mnt/snap1 -f /tmp/1.send
      $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/2.send
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt2
      $ btrfs receive /mnt2 -f /tmp/1.send
      $ btrfs receive /mnt2 -f /tmp/2.send
      ERROR: rename b -> a failed. Directory not empty
    
    A test case for xfstests follows soon.
    
    Reported-by: Ames Cornish <ames@cornishes.net>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index fe5857223515..d6033f540cc7 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -230,6 +230,7 @@ struct pending_dir_move {
 	u64 parent_ino;
 	u64 ino;
 	u64 gen;
+	bool is_orphan;
 	struct list_head update_refs;
 };
 
@@ -2984,7 +2985,8 @@ static int add_pending_dir_move(struct send_ctx *sctx,
 				u64 ino_gen,
 				u64 parent_ino,
 				struct list_head *new_refs,
-				struct list_head *deleted_refs)
+				struct list_head *deleted_refs,
+				const bool is_orphan)
 {
 	struct rb_node **p = &sctx->pending_dir_moves.rb_node;
 	struct rb_node *parent = NULL;
@@ -2999,6 +3001,7 @@ static int add_pending_dir_move(struct send_ctx *sctx,
 	pm->parent_ino = parent_ino;
 	pm->ino = ino;
 	pm->gen = ino_gen;
+	pm->is_orphan = is_orphan;
 	INIT_LIST_HEAD(&pm->list);
 	INIT_LIST_HEAD(&pm->update_refs);
 	RB_CLEAR_NODE(&pm->node);
@@ -3131,16 +3134,20 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	rmdir_ino = dm->rmdir_ino;
 	free_waiting_dir_move(sctx, dm);
 
-	ret = get_first_ref(sctx->parent_root, pm->ino,
-			    &parent_ino, &parent_gen, name);
-	if (ret < 0)
-		goto out;
-
-	ret = get_cur_path(sctx, parent_ino, parent_gen,
-			   from_path);
-	if (ret < 0)
-		goto out;
-	ret = fs_path_add_path(from_path, name);
+	if (pm->is_orphan) {
+		ret = gen_unique_name(sctx, pm->ino,
+				      pm->gen, from_path);
+	} else {
+		ret = get_first_ref(sctx->parent_root, pm->ino,
+				    &parent_ino, &parent_gen, name);
+		if (ret < 0)
+			goto out;
+		ret = get_cur_path(sctx, parent_ino, parent_gen,
+				   from_path);
+		if (ret < 0)
+			goto out;
+		ret = fs_path_add_path(from_path, name);
+	}
 	if (ret < 0)
 		goto out;
 
@@ -3150,7 +3157,8 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 		LIST_HEAD(deleted_refs);
 		ASSERT(ancestor > BTRFS_FIRST_FREE_OBJECTID);
 		ret = add_pending_dir_move(sctx, pm->ino, pm->gen, ancestor,
-					   &pm->update_refs, &deleted_refs);
+					   &pm->update_refs, &deleted_refs,
+					   pm->is_orphan);
 		if (ret < 0)
 			goto out;
 		if (rmdir_ino) {
@@ -3283,6 +3291,127 @@ static int apply_children_dir_moves(struct send_ctx *sctx)
 	return ret;
 }
 
+/*
+ * We might need to delay a directory rename even when no ancestor directory
+ * (in the send root) with a higher inode number than ours (sctx->cur_ino) was
+ * renamed. This happens when we rename a directory to the old name (the name
+ * in the parent root) of some other unrelated directory that got its rename
+ * delayed due to some ancestor with higher number that got renamed.
+ *
+ * Example:
+ *
+ * Parent snapshot:
+ * .                                       (ino 256)
+ * |---- a/                                (ino 257)
+ * |     |---- file                        (ino 260)
+ * |
+ * |---- b/                                (ino 258)
+ * |---- c/                                (ino 259)
+ *
+ * Send snapshot:
+ * .                                       (ino 256)
+ * |---- a/                                (ino 258)
+ * |---- x/                                (ino 259)
+ *       |---- y/                          (ino 257)
+ *             |----- file                 (ino 260)
+ *
+ * Here we can not rename 258 from 'b' to 'a' without the rename of inode 257
+ * from 'a' to 'x/y' happening first, which in turn depends on the rename of
+ * inode 259 from 'c' to 'x'. So the order of rename commands the send stream
+ * must issue is:
+ *
+ * 1 - rename 259 from 'c' to 'x'
+ * 2 - rename 257 from 'a' to 'x/y'
+ * 3 - rename 258 from 'b' to 'a'
+ *
+ * Returns 1 if the rename of sctx->cur_ino needs to be delayed, 0 if it can
+ * be done right away and < 0 on error.
+ */
+static int wait_for_dest_dir_move(struct send_ctx *sctx,
+				  struct recorded_ref *parent_ref,
+				  const bool is_orphan)
+{
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	struct btrfs_key di_key;
+	struct btrfs_dir_item *di;
+	u64 left_gen;
+	u64 right_gen;
+	int ret = 0;
+
+	if (RB_EMPTY_ROOT(&sctx->waiting_dir_moves))
+		return 0;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	key.objectid = parent_ref->dir;
+	key.type = BTRFS_DIR_ITEM_KEY;
+	key.offset = btrfs_name_hash(parent_ref->name, parent_ref->name_len);
+
+	ret = btrfs_search_slot(NULL, sctx->parent_root, &key, path, 0, 0);
+	if (ret < 0) {
+		goto out;
+	} else if (ret > 0) {
+		ret = 0;
+		goto out;
+	}
+
+	di = btrfs_match_dir_item_name(sctx->parent_root, path,
+				       parent_ref->name, parent_ref->name_len);
+	if (!di) {
+		ret = 0;
+		goto out;
+	}
+	/*
+	 * di_key.objectid has the number of the inode that has a dentry in the
+	 * parent directory with the same name that sctx->cur_ino is being
+	 * renamed to. We need to check if that inode is in the send root as
+	 * well and if it is currently marked as an inode with a pending rename,
+	 * if it is, we need to delay the rename of sctx->cur_ino as well, so
+	 * that it happens after that other inode is renamed.
+	 */
+	btrfs_dir_item_key_to_cpu(path->nodes[0], di, &di_key);
+	if (di_key.type != BTRFS_INODE_ITEM_KEY) {
+		ret = 0;
+		goto out;
+	}
+
+	ret = get_inode_info(sctx->parent_root, di_key.objectid, NULL,
+			     &left_gen, NULL, NULL, NULL, NULL);
+	if (ret < 0)
+		goto out;
+	ret = get_inode_info(sctx->send_root, di_key.objectid, NULL,
+			     &right_gen, NULL, NULL, NULL, NULL);
+	if (ret < 0) {
+		if (ret == -ENOENT)
+			ret = 0;
+		goto out;
+	}
+
+	/* Different inode, no need to delay the rename of sctx->cur_ino */
+	if (right_gen != left_gen) {
+		ret = 0;
+		goto out;
+	}
+
+	if (is_waiting_for_move(sctx, di_key.objectid)) {
+		ret = add_pending_dir_move(sctx,
+					   sctx->cur_ino,
+					   sctx->cur_inode_gen,
+					   di_key.objectid,
+					   &sctx->new_refs,
+					   &sctx->deleted_refs,
+					   is_orphan);
+		if (!ret)
+			ret = 1;
+	}
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
 static int wait_for_parent_move(struct send_ctx *sctx,
 				struct recorded_ref *parent_ref)
 {
@@ -3349,7 +3478,8 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 					   sctx->cur_inode_gen,
 					   ino,
 					   &sctx->new_refs,
-					   &sctx->deleted_refs);
+					   &sctx->deleted_refs,
+					   false);
 		if (!ret)
 			ret = 1;
 	}
@@ -3372,6 +3502,7 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 	int did_overwrite = 0;
 	int is_orphan = 0;
 	u64 last_dir_ino_rm = 0;
+	bool can_rename = true;
 
 verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 
@@ -3490,12 +3621,22 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 			}
 		}
 
+		if (S_ISDIR(sctx->cur_inode_mode) && sctx->parent_root) {
+			ret = wait_for_dest_dir_move(sctx, cur, is_orphan);
+			if (ret < 0)
+				goto out;
+			if (ret == 1) {
+				can_rename = false;
+				*pending_move = 1;
+			}
+		}
+
 		/*
 		 * link/move the ref to the new place. If we have an orphan
 		 * inode, move it and update valid_path. If not, link or move
 		 * it depending on the inode mode.
 		 */
-		if (is_orphan) {
+		if (is_orphan && can_rename) {
 			ret = send_rename(sctx, valid_path, cur->full_path);
 			if (ret < 0)
 				goto out;
@@ -3503,7 +3644,7 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 			ret = fs_path_copy(valid_path, cur->full_path);
 			if (ret < 0)
 				goto out;
-		} else {
+		} else if (can_rename) {
 			if (S_ISDIR(sctx->cur_inode_mode)) {
 				/*
 				 * Dirs can't be linked, so move it. For moved

commit a937b9791ec2ee71d5e303d2c02c8c1ad8abff35
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Dec 12 17:39:12 2014 +0100

    btrfs: kill btrfs_inode_*time helpers
    
    They just opencode taking address of the timespec member.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 804432dbc351..fe5857223515 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2471,12 +2471,9 @@ verbose_printk("btrfs: send_utimes %llu\n", ino);
 	if (ret < 0)
 		goto out;
 	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
-	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_ATIME, eb,
-			btrfs_inode_atime(ii));
-	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_MTIME, eb,
-			btrfs_inode_mtime(ii));
-	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_CTIME, eb,
-			btrfs_inode_ctime(ii));
+	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_ATIME, eb, &ii->atime);
+	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_MTIME, eb, &ii->mtime);
+	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_CTIME, eb, &ii->ctime);
 	/* TODO Add otime support when the otime patches get into upstream */
 
 	ret = send_cmd(sctx);

commit e5fa8f865b3324aebd055e4054bf479cbab37e5a
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Oct 21 11:11:41 2014 +0100

    Btrfs: ensure send always works on roots without orphans
    
    Move the logic from the snapshot creation ioctl into send. This avoids
    doing the transaction commit if send isn't used, and ensures that if
    a crash/reboot happens after the transaction commit that created the
    snapshot and before the transaction commit that switched the commit
    root, send will not get a commit root that differs from the main root
    (that has orphan items).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 874828dd0a86..804432dbc351 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5507,6 +5507,51 @@ static int send_subvol(struct send_ctx *sctx)
 	return ret;
 }
 
+/*
+ * If orphan cleanup did remove any orphans from a root, it means the tree
+ * was modified and therefore the commit root is not the same as the current
+ * root anymore. This is a problem, because send uses the commit root and
+ * therefore can see inode items that don't exist in the current root anymore,
+ * and for example make calls to btrfs_iget, which will do tree lookups based
+ * on the current root and not on the commit root. Those lookups will fail,
+ * returning a -ESTALE error, and making send fail with that error. So make
+ * sure a send does not see any orphans we have just removed, and that it will
+ * see the same inodes regardless of whether a transaction commit happened
+ * before it started (meaning that the commit root will be the same as the
+ * current root) or not.
+ */
+static int ensure_commit_roots_uptodate(struct send_ctx *sctx)
+{
+	int i;
+	struct btrfs_trans_handle *trans = NULL;
+
+again:
+	if (sctx->parent_root &&
+	    sctx->parent_root->node != sctx->parent_root->commit_root)
+		goto commit_trans;
+
+	for (i = 0; i < sctx->clone_roots_cnt; i++)
+		if (sctx->clone_roots[i].root->node !=
+		    sctx->clone_roots[i].root->commit_root)
+			goto commit_trans;
+
+	if (trans)
+		return btrfs_end_transaction(trans, sctx->send_root);
+
+	return 0;
+
+commit_trans:
+	/* Use any root, all fs roots will get their commit roots updated. */
+	if (!trans) {
+		trans = btrfs_join_transaction(sctx->send_root);
+		if (IS_ERR(trans))
+			return PTR_ERR(trans);
+		goto again;
+	}
+
+	return btrfs_commit_transaction(trans, sctx->send_root);
+}
+
 static void btrfs_root_dec_send_in_progress(struct btrfs_root* root)
 {
 	spin_lock(&root->root_item_lock);
@@ -5728,6 +5773,10 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			NULL);
 	sort_clone_roots = 1;
 
+	ret = ensure_commit_roots_uptodate(sctx);
+	if (ret)
+		goto out;
+
 	current->journal_info = BTRFS_SEND_TRANS_STUB;
 	ret = send_subvol(sctx);
 	current->journal_info = NULL;

commit bbf65cf0b5b67843ca094df01019222b85af2183
Merge: bf8e8ca6fd4a fccb84c94a97
Author: Chris Mason <clm@fb.com>
Date:   Sat Oct 4 09:56:45 2014 -0700

    Merge branch 'cleanup/misc-for-3.18' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus
    
    Signed-off-by: Chris Mason <clm@fb.com>
    
    Conflicts:
            fs/btrfs/extent_io.c

commit bf8e8ca6fd4ac6e8edc58b92cffb2ffd51933138
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Oct 2 19:17:32 2014 +0100

    Btrfs: send, don't delay dir move if there's a new parent inode
    
    If between two snapshots we rename an existing directory named X to Y and
    make it a child (direct or not) of a new inode named X, we were delaying
    the move/rename of the former directory unnecessarily, which would result
    in attempting to rename the new directory from its orphan name to name X
    prematurely.
    
    Minimal reproducer:
    
        $ mkfs.btrfs -f /dev/vdd
        $ mount /dev/vdd /mnt
        $ mkdir -p /mnt/merlin/RC/OSD/Source
    
        $ btrfs subvolume snapshot -r /mnt /mnt/mysnap1
    
        $ mkdir /mnt/OSD
        $ mv /mnt/merlin/RC/OSD /mnt/OSD/OSD-Plane_788
        $ mv /mnt/OSD /mnt/merlin/RC
    
        $ btrfs subvolume snapshot -r /mnt /mnt/mysnap2
    
        $ btrfs send /mnt/mysnap1 -f /tmp/1.snap
        $ btrfs send -p /mnt/mysnap1 /mnt/mysnap2 -f /tmp/2.snap
    
        $ mkfs.btrfs -f /dev/vdc
        $ mount /dev/vdc /mnt2
    
        $ btrfs receive /mnt2 -f /tmp/1.snap
        $ btrfs receive /mnt2 -f /tmp/2.snap
    
    The second receive (from an incremental send) failed with the following
    error message: "rename o261-7-0 -> merlin/RC/OSD failed".
    This is a regression introduced in the 3.16 kernel.
    
    A test case for xfstests follows.
    
    Reported-by: Marc Merlin <marc@merlins.org>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 7edfc7cebda4..b9c27aa38d76 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3327,7 +3327,7 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 		if (ret < 0 && ret != -ENOENT) {
 			goto out;
 		} else if (ret == -ENOENT) {
-			ret = 1;
+			ret = 0;
 			break;
 		}
 

commit 2755a0de64693501741fb3603cd8ca928b0b7e81
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Jul 31 00:43:18 2014 +0200

    btrfs: hide typecast to definition of BTRFS_SEND_TRANS_STUB
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 7edfc7cebda4..8b44630f4abf 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5728,7 +5728,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			NULL);
 	sort_clone_roots = 1;
 
-	current->journal_info = (void *)BTRFS_SEND_TRANS_STUB;
+	current->journal_info = BTRFS_SEND_TRANS_STUB;
 	ret = send_subvol(sctx);
 	current->journal_info = NULL;
 	if (ret < 0)

commit 4395e0c4da486f007dcb45b0336427be7ec08ab1
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Aug 20 10:45:45 2014 +0100

    Btrfs: send, lower mem requirements for processing xattrs
    
    Maximum xattr size can be up to nearly the leaf size. For an fs with a
    leaf size larger than the page size, using kmalloc requires allocating
    multiple pages that are contiguous, which might not be possible if
    there's heavy memory fragmentation. Therefore fallback to vmalloc if
    we fail to allocate with kmalloc. Also start with a smaller buffer size,
    since xattr values typically are smaller than a page.
    
    Reported-by: Chris Murphy <lists@colorremedies.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index b67e12eb7ca9..7edfc7cebda4 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -986,11 +986,13 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 	int num;
 	u8 type;
 
-	if (found_key->type == BTRFS_XATTR_ITEM_KEY)
-		buf_len = BTRFS_MAX_XATTR_SIZE(root);
-	else
-		buf_len = PATH_MAX;
-
+	/*
+	 * Start with a small buffer (1 page). If later we end up needing more
+	 * space, which can happen for xattrs on a fs with a leaf size greater
+	 * then the page size, attempt to increase the buffer. Typically xattr
+	 * values are small.
+	 */
+	buf_len = PATH_MAX;
 	buf = kmalloc(buf_len, GFP_NOFS);
 	if (!buf) {
 		ret = -ENOMEM;
@@ -1017,7 +1019,7 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 				ret = -ENAMETOOLONG;
 				goto out;
 			}
-			if (name_len + data_len > buf_len) {
+			if (name_len + data_len > BTRFS_MAX_XATTR_SIZE(root)) {
 				ret = -E2BIG;
 				goto out;
 			}
@@ -1025,12 +1027,34 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 			/*
 			 * Path too long
 			 */
-			if (name_len + data_len > buf_len) {
+			if (name_len + data_len > PATH_MAX) {
 				ret = -ENAMETOOLONG;
 				goto out;
 			}
 		}
 
+		if (name_len + data_len > buf_len) {
+			buf_len = name_len + data_len;
+			if (is_vmalloc_addr(buf)) {
+				vfree(buf);
+				buf = NULL;
+			} else {
+				char *tmp = krealloc(buf, buf_len,
+						     GFP_NOFS | __GFP_NOWARN);
+
+				if (!tmp)
+					kfree(buf);
+				buf = tmp;
+			}
+			if (!buf) {
+				buf = vmalloc(buf_len);
+				if (!buf) {
+					ret = -ENOMEM;
+					goto out;
+				}
+			}
+		}
+
 		read_extent_buffer(eb, buf, (unsigned long)(di + 1),
 				name_len + data_len);
 
@@ -1051,7 +1075,7 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 	}
 
 out:
-	kfree(buf);
+	kvfree(buf);
 	return ret;
 }
 

commit d447d0da44cd7d396277d1d8f46b418c721fbc02
Author: Fabian Frederick <fabf@skynet.be>
Date:   Tue Jul 15 21:17:17 2014 +0200

    Btrfs: fix sparse warning
    
    Fix the following sparse warning:
    fs/btrfs/send.c:518:51: warning: incorrect type in argument 2 (different address spaces)
    fs/btrfs/send.c:518:51:    expected char const [noderef] <asn:1>*<noident>
    fs/btrfs/send.c:518:51:    got char *
    
    We can safely use (const char __user *) with set_fs(KERNEL_DS)
    
    __force added to avoid sparse-all warning:
    fs/btrfs/send.c:518:40: warning: cast adds address space to expression (<asn:1>)
    
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Reviewed-by: Zach Brown <zab@zabbo.net>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 6528aa662181..b67e12eb7ca9 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -515,7 +515,8 @@ static int write_buf(struct file *filp, const void *buf, u32 len, loff_t *off)
 	set_fs(KERNEL_DS);
 
 	while (pos < len) {
-		ret = vfs_write(filp, (char *)buf + pos, len - pos, off);
+		ret = vfs_write(filp, (__force const char __user *)buf + pos,
+				len - pos, off);
 		/* TODO handle that correctly */
 		/*if (ret == -ERESTARTSYS) {
 			continue;

commit 7e3ae33efad1490d01040f552ef50e58ed6376ca
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Fri May 23 20:15:16 2014 +0100

    Btrfs: send, use the right limits for xattr names and values
    
    We were limiting the sum of the xattr name and value lengths to PATH_MAX,
    which is not correct, specially on filesystems created with btrfs-progs
    v3.12 or higher, where the default leaf size is max(16384, PAGE_SIZE), or
    systems with page sizes larger than 4096 bytes.
    
    Xattrs have their own specific maximum name and value lengths, which depend
    on the leaf size, therefore use these limits to be able to send xattrs with
    sizes larger than PATH_MAX.
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 15cdc67ce9ad..6528aa662181 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -975,7 +975,7 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 	struct btrfs_dir_item *di;
 	struct btrfs_key di_key;
 	char *buf = NULL;
-	const int buf_len = PATH_MAX;
+	int buf_len;
 	u32 name_len;
 	u32 data_len;
 	u32 cur;
@@ -985,6 +985,11 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 	int num;
 	u8 type;
 
+	if (found_key->type == BTRFS_XATTR_ITEM_KEY)
+		buf_len = BTRFS_MAX_XATTR_SIZE(root);
+	else
+		buf_len = PATH_MAX;
+
 	buf = kmalloc(buf_len, GFP_NOFS);
 	if (!buf) {
 		ret = -ENOMEM;
@@ -1006,12 +1011,23 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 		type = btrfs_dir_type(eb, di);
 		btrfs_dir_item_key_to_cpu(eb, di, &di_key);
 
-		/*
-		 * Path too long
-		 */
-		if (name_len + data_len > buf_len) {
-			ret = -ENAMETOOLONG;
-			goto out;
+		if (type == BTRFS_FT_XATTR) {
+			if (name_len > XATTR_NAME_MAX) {
+				ret = -ENAMETOOLONG;
+				goto out;
+			}
+			if (name_len + data_len > buf_len) {
+				ret = -E2BIG;
+				goto out;
+			}
+		} else {
+			/*
+			 * Path too long
+			 */
+			if (name_len + data_len > buf_len) {
+				ret = -ENAMETOOLONG;
+				goto out;
+			}
 		}
 
 		read_extent_buffer(eb, buf, (unsigned long)(di + 1),

commit 1af56070e3ef9477dbc7eba3b9ad7446979c7974
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Sun May 25 04:49:24 2014 +0100

    Btrfs: send, don't error in the presence of subvols/snapshots
    
    If we are doing an incremental send and the base snapshot has a
    directory with name X that doesn't exist anymore in the second
    snapshot and a new subvolume/snapshot exists in the second snapshot
    that has the same name as the directory (name X), the incremental
    send would fail with -ENOENT error. This is because it attempts
    to lookup for an inode with a number matching the objectid of a
    root, which doesn't exist.
    
    Steps to reproduce:
    
        mkfs.btrfs -f /dev/sdd
        mount /dev/sdd /mnt
    
        mkdir /mnt/testdir
        btrfs subvolume snapshot -r /mnt /mnt/mysnap1
    
        rmdir /mnt/testdir
        btrfs subvolume create /mnt/testdir
        btrfs subvolume snapshot -r /mnt /mnt/mysnap2
    
        btrfs send -p /mnt/mysnap1 /mnt/mysnap2 -f /tmp/send.data
    
    A test case for xfstests follows.
    
    Reported-by: Robert White <rwhite@pobox.com>
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a86c049932f9..15cdc67ce9ad 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1628,6 +1628,10 @@ static int lookup_dir_item_inode(struct btrfs_root *root,
 		goto out;
 	}
 	btrfs_dir_item_key_to_cpu(path->nodes[0], di, &key);
+	if (key.type == BTRFS_ROOT_ITEM_KEY) {
+		ret = -ENOENT;
+		goto out;
+	}
 	*found_inode = key.objectid;
 	*found_type = btrfs_dir_type(path->nodes[0], di);
 

commit 351fd3532159441e810d458a5b681090ff8449fd
Author: David Sterba <dsterba@suse.cz>
Date:   Thu May 15 16:48:20 2014 +0200

    btrfs: remove stale newlines from log messages
    
    I've noticed an extra line after "use no compression", but search
    revealed much more in messages of more critical levels and rare errors.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 3f14b31c0c96..a86c049932f9 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1349,7 +1349,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 		ret = -EIO;
 		btrfs_err(sctx->send_root->fs_info, "did not find backref in "
 				"send_root. inode=%llu, offset=%llu, "
-				"disk_byte=%llu found extent=%llu\n",
+				"disk_byte=%llu found extent=%llu",
 				ino, data_offset, disk_byte, found_key.objectid);
 		goto out;
 	}
@@ -5472,7 +5472,7 @@ static void btrfs_root_dec_send_in_progress(struct btrfs_root* root)
 	 */
 	if (root->send_in_progress < 0)
 		btrfs_err(root->fs_info,
-			"send_in_progres unbalanced %d root %llu\n",
+			"send_in_progres unbalanced %d root %llu",
 			root->send_in_progress, root->root_key.objectid);
 	spin_unlock(&root->root_item_lock);
 }

commit f959492fc15b60d874a9cbf55ae4760f2ef261ed
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Thu Mar 27 20:14:01 2014 +0000

    Btrfs: send, fix more issues related to directory renames
    
    This is a continuation of the previous changes titled:
    
       Btrfs: fix incremental send's decision to delay a dir move/rename
       Btrfs: part 2, fix incremental send's decision to delay a dir move/rename
    
    There's a few more cases where a directory rename/move must be delayed which was
    previously overlooked. If our immediate ancestor has a lower inode number than
    ours and it doesn't have a delayed rename/move operation associated to it, it
    doesn't mean there isn't any non-direct ancestor of our current inode that needs
    to be renamed/moved before our current inode (i.e. with a higher inode number
    than ours).
    
    So we can't stop the search if our immediate ancestor has a lower inode number than
    ours, we need to navigate the directory hierarchy upwards until we hit the root or:
    
    1) find an ancestor with an higher inode number that was renamed/moved in the send
       root too (or already has a pending rename/move registered);
    2) find an ancestor that is a new directory (higher inode number than ours and
       exists only in the send root).
    
    Reproducer for case 1)
    
        $ mkfs.btrfs -f /dev/sdd
        $ mount /dev/sdd /mnt
    
        $ mkdir -p /mnt/a/b
        $ mkdir -p /mnt/a/c/d
        $ mkdir /mnt/a/b/e
        $ mkdir /mnt/a/c/d/f
        $ mv /mnt/a/b /mnt/a/c/d/2b
        $ mkdir /mnt/a/x
        $ mkdir /mnt/a/y
    
        $ btrfs subvolume snapshot -r /mnt /mnt/snap1
        $ btrfs send /mnt/snap1 -f /tmp/base.send
    
        $ mv /mnt/a/x /mnt/a/y
        $ mv /mnt/a/c/d/2b/e /mnt/a/c/d/2b/2e
        $ mv /mnt/a/c/d /mnt/a/h/2d
        $ mv /mnt/a/c /mnt/a/h/2d/2b/2c
    
        $ btrfs subvolume snapshot -r /mnt /mnt/snap2
        $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/incremental.send
    
    Simple reproducer for case 2)
    
        $ mkfs.btrfs -f /dev/sdd
        $ mount /dev/sdd /mnt
    
        $ mkdir -p /mnt/a/b
        $ mkdir /mnt/a/c
        $ mv /mnt/a/b /mnt/a/c/b2
        $ mkdir /mnt/a/e
    
        $ btrfs subvolume snapshot -r /mnt /mnt/snap1
        $ btrfs send /mnt/snap1 -f /tmp/base.send
    
        $ mv /mnt/a/c/b2 /mnt/a/e/b3
        $ mkdir /mnt/a/e/b3/f
        $ mkdir /mnt/a/h
        $ mv /mnt/a/c /mnt/a/e/b3/f/c2
        $ mv /mnt/a/e /mnt/a/h/e2
    
        $ btrfs subvolume snapshot -r /mnt /mnt/snap2
        $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/incremental.send
    
    Another simple reproducer for case 2)
    
        $ mkfs.btrfs -f /dev/sdd
        $ mount /dev/sdd /mnt
    
        $ mkdir -p /mnt/a/b
        $ mkdir /mnt/a/c
        $ mkdir /mnt/a/b/d
        $ mkdir /mnt/a/c/e
    
        $ btrfs subvolume snapshot -r /mnt /mnt/snap1
        $ btrfs send /mnt/snap1 -f /tmp/base.send
    
        $ mkdir /mnt/a/b/d/f
        $ mkdir /mnt/a/b/g
        $ mv /mnt/a/c/e /mnt/a/b/g/e2
        $ mv /mnt/a/c /mnt/a/b/d/f/c2
        $ mv /mnt/a/b/d/f /mnt/a/b/g/e2/f2
    
        $ btrfs subvolume snapshot -r /mnt /mnt/snap2
        $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/incremental.send
    
    More complex reproducer for case 2)
    
        $ mkfs.btrfs -f /dev/sdd
        $ mount /dev/sdd /mnt
    
        $ mkdir -p /mnt/a/b
        $ mkdir -p /mnt/a/c/d
        $ mkdir /mnt/a/b/e
        $ mkdir /mnt/a/c/d/f
        $ mv /mnt/a/b /mnt/a/c/d/2b
        $ mkdir /mnt/a/x
        $ mkdir /mnt/a/y
    
        $ btrfs subvolume snapshot -r /mnt /mnt/snap1
        $ btrfs send /mnt/snap1 -f /tmp/base.send
    
        $ mv /mnt/a/x /mnt/a/y
        $ mv /mnt/a/c/d/2b/e /mnt/a/c/d/2b/2e
        $ mv /mnt/a/c/d /mnt/a/h/2d
        $ mv /mnt/a/c /mnt/a/h/2d/2b/2c
    
        $ btrfs subvolume snapshot -r /mnt /mnt/snap2
        $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/incremental.send
    
    For both cases the incremental send would enter an infinite loop when building
    path strings.
    
    While solving these cases, this change also re-implements the code to detect
    when directory moves/renames should be delayed. Instead of dealing with several
    specific cases separately, it's now more generic handling all cases with a simple
    detection algorithm and if when applying a delayed move/rename there's a path loop
    detected, it further delays the move/rename registering a new ancestor inode as
    the dependency inode (so our rename happens after that ancestor is renamed).
    
    Tests for these cases is being added to xfstests too.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index fb6aeed9c223..3f14b31c0c96 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2940,7 +2940,9 @@ static void free_waiting_dir_move(struct send_ctx *sctx,
 static int add_pending_dir_move(struct send_ctx *sctx,
 				u64 ino,
 				u64 ino_gen,
-				u64 parent_ino)
+				u64 parent_ino,
+				struct list_head *new_refs,
+				struct list_head *deleted_refs)
 {
 	struct rb_node **p = &sctx->pending_dir_moves.rb_node;
 	struct rb_node *parent = NULL;
@@ -2972,12 +2974,12 @@ static int add_pending_dir_move(struct send_ctx *sctx,
 		}
 	}
 
-	list_for_each_entry(cur, &sctx->deleted_refs, list) {
+	list_for_each_entry(cur, deleted_refs, list) {
 		ret = dup_ref(cur, &pm->update_refs);
 		if (ret < 0)
 			goto out;
 	}
-	list_for_each_entry(cur, &sctx->new_refs, list) {
+	list_for_each_entry(cur, new_refs, list) {
 		ret = dup_ref(cur, &pm->update_refs);
 		if (ret < 0)
 			goto out;
@@ -3020,6 +3022,48 @@ static struct pending_dir_move *get_pending_dir_moves(struct send_ctx *sctx,
 	return NULL;
 }
 
+static int path_loop(struct send_ctx *sctx, struct fs_path *name,
+		     u64 ino, u64 gen, u64 *ancestor_ino)
+{
+	int ret = 0;
+	u64 parent_inode = 0;
+	u64 parent_gen = 0;
+	u64 start_ino = ino;
+
+	*ancestor_ino = 0;
+	while (ino != BTRFS_FIRST_FREE_OBJECTID) {
+		fs_path_reset(name);
+
+		if (is_waiting_for_rm(sctx, ino))
+			break;
+		if (is_waiting_for_move(sctx, ino)) {
+			if (*ancestor_ino == 0)
+				*ancestor_ino = ino;
+			ret = get_first_ref(sctx->parent_root, ino,
+					    &parent_inode, &parent_gen, name);
+		} else {
+			ret = __get_cur_name_and_parent(sctx, ino, gen,
+							&parent_inode,
+							&parent_gen, name);
+			if (ret > 0) {
+				ret = 0;
+				break;
+			}
+		}
+		if (ret < 0)
+			break;
+		if (parent_inode == start_ino) {
+			ret = 1;
+			if (*ancestor_ino == 0)
+				*ancestor_ino = ino;
+			break;
+		}
+		ino = parent_inode;
+		gen = parent_gen;
+	}
+	return ret;
+}
+
 static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 {
 	struct fs_path *from_path = NULL;
@@ -3031,6 +3075,7 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	struct waiting_dir_move *dm = NULL;
 	u64 rmdir_ino = 0;
 	int ret;
+	u64 ancestor = 0;
 
 	name = fs_path_alloc();
 	from_path = fs_path_alloc();
@@ -3057,11 +3102,25 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	if (ret < 0)
 		goto out;
 
+	sctx->send_progress = sctx->cur_ino + 1;
+	ret = path_loop(sctx, name, pm->ino, pm->gen, &ancestor);
+	if (ret) {
+		LIST_HEAD(deleted_refs);
+		ASSERT(ancestor > BTRFS_FIRST_FREE_OBJECTID);
+		ret = add_pending_dir_move(sctx, pm->ino, pm->gen, ancestor,
+					   &pm->update_refs, &deleted_refs);
+		if (ret < 0)
+			goto out;
+		if (rmdir_ino) {
+			dm = get_waiting_dir_move(sctx, pm->ino);
+			ASSERT(dm);
+			dm->rmdir_ino = rmdir_ino;
+		}
+		goto out;
+	}
 	fs_path_reset(name);
 	to_path = name;
 	name = NULL;
-
-	sctx->send_progress = sctx->cur_ino + 1;
 	ret = get_cur_path(sctx, pm->ino, pm->gen, to_path);
 	if (ret < 0)
 		goto out;
@@ -3185,127 +3244,74 @@ static int apply_children_dir_moves(struct send_ctx *sctx)
 static int wait_for_parent_move(struct send_ctx *sctx,
 				struct recorded_ref *parent_ref)
 {
-	int ret;
+	int ret = 0;
 	u64 ino = parent_ref->dir;
 	u64 parent_ino_before, parent_ino_after;
-	u64 old_gen;
 	struct fs_path *path_before = NULL;
 	struct fs_path *path_after = NULL;
 	int len1, len2;
-	int register_upper_dirs;
-	u64 gen;
-
-	if (is_waiting_for_move(sctx, ino))
-		return 1;
-
-	if (parent_ref->dir <= sctx->cur_ino)
-		return 0;
-
-	ret = get_inode_info(sctx->parent_root, ino, NULL, &old_gen,
-			     NULL, NULL, NULL, NULL);
-	if (ret == -ENOENT)
-		return 0;
-	else if (ret < 0)
-		return ret;
-
-	if (parent_ref->dir_gen != old_gen)
-		return 0;
-
-	path_before = fs_path_alloc();
-	if (!path_before)
-		return -ENOMEM;
-
-	ret = get_first_ref(sctx->parent_root, ino, &parent_ino_before,
-			    NULL, path_before);
-	if (ret == -ENOENT) {
-		ret = 0;
-		goto out;
-	} else if (ret < 0) {
-		goto out;
-	}
 
 	path_after = fs_path_alloc();
-	if (!path_after) {
+	path_before = fs_path_alloc();
+	if (!path_after || !path_before) {
 		ret = -ENOMEM;
 		goto out;
 	}
 
-	ret = get_first_ref(sctx->send_root, ino, &parent_ino_after,
-			    &gen, path_after);
-	if (ret == -ENOENT) {
-		ret = 0;
-		goto out;
-	} else if (ret < 0) {
-		goto out;
-	}
-
-	len1 = fs_path_len(path_before);
-	len2 = fs_path_len(path_after);
-	if (parent_ino_before != parent_ino_after || len1 != len2 ||
-	     memcmp(path_before->start, path_after->start, len1)) {
-		ret = 1;
-		goto out;
-	}
-	ret = 0;
-
 	/*
-	 * Ok, our new most direct ancestor has a higher inode number but
-	 * wasn't moved/renamed. So maybe some of the new ancestors higher in
-	 * the hierarchy have an higher inode number too *and* were renamed
-	 * or moved - in this case we need to wait for the ancestor's rename
-	 * or move operation before we can do the move/rename for the current
-	 * inode.
+	 * Our current directory inode may not yet be renamed/moved because some
+	 * ancestor (immediate or not) has to be renamed/moved first. So find if
+	 * such ancestor exists and make sure our own rename/move happens after
+	 * that ancestor is processed.
 	 */
-	register_upper_dirs = 0;
-	ino = parent_ino_after;
-again:
-	while ((ret == 0 || register_upper_dirs) && ino > sctx->cur_ino) {
-		u64 parent_gen;
+	while (ino > BTRFS_FIRST_FREE_OBJECTID) {
+		if (is_waiting_for_move(sctx, ino)) {
+			ret = 1;
+			break;
+		}
 
 		fs_path_reset(path_before);
 		fs_path_reset(path_after);
 
 		ret = get_first_ref(sctx->send_root, ino, &parent_ino_after,
-				    &parent_gen, path_after);
+				    NULL, path_after);
 		if (ret < 0)
 			goto out;
 		ret = get_first_ref(sctx->parent_root, ino, &parent_ino_before,
 				    NULL, path_before);
-		if (ret == -ENOENT) {
-			ret = 0;
-			break;
-		} else if (ret < 0) {
+		if (ret < 0 && ret != -ENOENT) {
 			goto out;
+		} else if (ret == -ENOENT) {
+			ret = 1;
+			break;
 		}
 
 		len1 = fs_path_len(path_before);
 		len2 = fs_path_len(path_after);
-		if (parent_ino_before != parent_ino_after || len1 != len2 ||
-		    memcmp(path_before->start, path_after->start, len1)) {
+		if (ino > sctx->cur_ino &&
+		    (parent_ino_before != parent_ino_after || len1 != len2 ||
+		     memcmp(path_before->start, path_after->start, len1))) {
 			ret = 1;
-			if (register_upper_dirs) {
-				break;
-			} else {
-				register_upper_dirs = 1;
-				ino = parent_ref->dir;
-				gen = parent_ref->dir_gen;
-				goto again;
-			}
-		} else if (register_upper_dirs) {
-			ret = add_pending_dir_move(sctx, ino, gen,
-						   parent_ino_after);
-			if (ret < 0 && ret != -EEXIST)
-				goto out;
+			break;
 		}
-
 		ino = parent_ino_after;
-		gen = parent_gen;
 	}
 
 out:
 	fs_path_free(path_before);
 	fs_path_free(path_after);
 
+	if (ret == 1) {
+		ret = add_pending_dir_move(sctx,
+					   sctx->cur_ino,
+					   sctx->cur_inode_gen,
+					   ino,
+					   &sctx->new_refs,
+					   &sctx->deleted_refs);
+		if (!ret)
+			ret = 1;
+	}
+
 	return ret;
 }
 
@@ -3466,10 +3472,6 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 				if (ret < 0)
 					goto out;
 				if (ret) {
-					ret = add_pending_dir_move(sctx,
-							   sctx->cur_ino,
-							   sctx->cur_inode_gen,
-							   cur->dir);
 					*pending_move = 1;
 				} else {
 					ret = send_rename(sctx, valid_path,

commit a10c40766c30a002affc0c47dd515d048c3959b4
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Sat Mar 22 17:16:30 2014 +0000

    Btrfs: send, remove dead code from __get_cur_name_and_parent
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c2bfd60ba245..fb6aeed9c223 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2030,7 +2030,6 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 {
 	int ret;
 	int nce_ret;
-	struct btrfs_path *path = NULL;
 	struct name_cache_entry *nce = NULL;
 
 	/*
@@ -2056,10 +2055,6 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 		}
 	}
 
-	path = alloc_path_for_send();
-	if (!path)
-		return -ENOMEM;
-
 	/*
 	 * If the inode is not existent yet, add the orphan name and return 1.
 	 * This should only happen for the parent dir that we determine in
@@ -2135,7 +2130,6 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	name_cache_clean_unused(sctx);
 
 out:
-	btrfs_free_path(path);
 	return ret;
 }
 

commit c992ec94f24c3e7135d6c23860615f269f0b1d87
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Sat Mar 22 17:15:24 2014 +0000

    Btrfs: send, account for orphan directories when building path strings
    
    If we have directories with a pending move/rename operation, we must take into
    account any orphan directories that got created before executing the pending
    move/rename. Those orphan directories are directories with an inode number higher
    then the current send progress and that don't exist in the parent snapshot, they
    are created before current progress reaches their inode number, with a generated
    name of the form oN-M-I and at the root of the filesystem tree, and later when
    progress matches their inode number, moved/renamed to their final location.
    
    Reproducer:
    
              $ mkfs.btrfs -f /dev/sdd
              $ mount /dev/sdd /mnt
    
              $ mkdir -p /mnt/a/b/c/d
              $ mkdir /mnt/a/b/e
              $ mv /mnt/a/b/c /mnt/a/b/e/CC
              $ mkdir /mnt/a/b/e/CC/d/f
              $ mkdir /mnt/a/g
    
              $ btrfs subvolume snapshot -r /mnt /mnt/snap1
              $ btrfs send /mnt/snap1 -f /tmp/base.send
    
              $ mkdir /mnt/a/g/h
              $ mv /mnt/a/b/e /mnt/a/g/h/EE
              $ mv /mnt/a/g/h/EE/CC/d /mnt/a/g/h/EE/DD
    
              $ btrfs subvolume snapshot -r /mnt /mnt/snap2
              $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/incremental.send
    
    The second receive command failed with the following error:
    
        ERROR: rename a/b/e/CC/d -> o264-7-0/EE/DD failed. No such file or directory
    
    A test case for xfstests follows soon.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 98e9e0cf7e8e..c2bfd60ba245 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3055,33 +3055,18 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	if (ret < 0)
 		goto out;
 
-	if (parent_ino == sctx->cur_ino) {
-		/* child only renamed, not moved */
-		ASSERT(parent_gen == sctx->cur_inode_gen);
-		ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen,
-				   from_path);
-		if (ret < 0)
-			goto out;
-		ret = fs_path_add_path(from_path, name);
-		if (ret < 0)
-			goto out;
-	} else {
-		/* child moved and maybe renamed too */
-		sctx->send_progress = pm->ino;
-		ret = get_cur_path(sctx, pm->ino, pm->gen, from_path);
-		if (ret < 0)
-			goto out;
-	}
+	ret = get_cur_path(sctx, parent_ino, parent_gen,
+			   from_path);
+	if (ret < 0)
+		goto out;
+	ret = fs_path_add_path(from_path, name);
+	if (ret < 0)
+		goto out;
 
-	fs_path_free(name);
+	fs_path_reset(name);
+	to_path = name;
 	name = NULL;
 
-	to_path = fs_path_alloc();
-	if (!to_path) {
-		ret = -ENOMEM;
-		goto out;
-	}
-
 	sctx->send_progress = sctx->cur_ino + 1;
 	ret = get_cur_path(sctx, pm->ino, pm->gen, to_path);
 	if (ret < 0)

commit b46ab97bcd4ae7954b3a150f642a82cdd1434f40
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Fri Mar 21 12:46:54 2014 +0000

    Btrfs: send, avoid unnecessary inode item lookup in the btree
    
    Regardless of whether the caller is interested or not in knowing the inode's
    generation (dir_gen != NULL), get_first_ref always does a btree lookup to get
    the inode item. Avoid this useless lookup if dir_gen parameter is NULL (which
    is in some cases).
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c76400dda4df..98e9e0cf7e8e 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1693,10 +1693,12 @@ static int get_first_ref(struct btrfs_root *root, u64 ino,
 		goto out;
 	btrfs_release_path(path);
 
-	ret = get_inode_info(root, parent_dir, NULL, dir_gen, NULL, NULL,
-			NULL, NULL);
-	if (ret < 0)
-		goto out;
+	if (dir_gen) {
+		ret = get_inode_info(root, parent_dir, NULL, dir_gen, NULL,
+				     NULL, NULL, NULL);
+		if (ret < 0)
+			goto out;
+	}
 
 	*dir = parent_dir;
 
@@ -1712,13 +1714,12 @@ static int is_first_ref(struct btrfs_root *root,
 	int ret;
 	struct fs_path *tmp_name;
 	u64 tmp_dir;
-	u64 tmp_dir_gen;
 
 	tmp_name = fs_path_alloc();
 	if (!tmp_name)
 		return -ENOMEM;
 
-	ret = get_first_ref(root, ino, &tmp_dir, &tmp_dir_gen, tmp_name);
+	ret = get_first_ref(root, ino, &tmp_dir, NULL, tmp_name);
 	if (ret < 0)
 		goto out;
 

commit 521e0546c970c3d845076f243828fa7abd71edfc
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Apr 15 16:41:44 2014 +0200

    btrfs: protect snapshots from deleting during send
    
    The patch "Btrfs: fix protection between send and root deletion"
    (18f687d538449373c37c) does not actually prevent to delete the snapshot
    and just takes care during background cleaning, but this seems rather
    user unfriendly, this patch implements the idea presented in
    
    http://www.spinics.net/lists/linux-btrfs/msg30813.html
    
    - add an internal root_item flag to denote a dead root
    - check if the send_in_progress is set and refuse to delete, otherwise
      set the flag and proceed
    - check the flag in send similar to the btrfs_root_readonly checks, for
      all involved roots
    
    The root lookup in send via btrfs_read_fs_root_no_name will check if the
    root is really dead or not. If it is, ENOENT, aborted send. If it's
    alive, it's protected by send_in_progress, send can continue.
    
    CC: Miao Xie <miaox@cn.fujitsu.com>
    CC: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 484aacac2c89..c76400dda4df 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5518,7 +5518,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 
 	/*
 	 * The subvolume must remain read-only during send, protect against
-	 * making it RW.
+	 * making it RW. This also protects against deletion.
 	 */
 	spin_lock(&send_root->root_item_lock);
 	send_root->send_in_progress++;
@@ -5578,6 +5578,15 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	}
 
 	sctx->send_root = send_root;
+	/*
+	 * Unlikely but possible, if the subvolume is marked for deletion but
+	 * is slow to remove the directory entry, send can still be started
+	 */
+	if (btrfs_root_dead(sctx->send_root)) {
+		ret = -EPERM;
+		goto out;
+	}
+
 	sctx->clone_roots_cnt = arg->clone_sources_count;
 
 	sctx->send_max_size = BTRFS_SEND_BUF_SIZE;
@@ -5667,7 +5676,8 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 
 		spin_lock(&sctx->parent_root->root_item_lock);
 		sctx->parent_root->send_in_progress++;
-		if (!btrfs_root_readonly(sctx->parent_root)) {
+		if (!btrfs_root_readonly(sctx->parent_root) ||
+				btrfs_root_dead(sctx->parent_root)) {
 			spin_unlock(&sctx->parent_root->root_item_lock);
 			srcu_read_unlock(&fs_info->subvol_srcu, index);
 			ret = -EPERM;

commit 01a9a8a9e20012f5676ec9cd16b6aed08b267066
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Wed May 21 17:38:13 2014 +0100

    Btrfs: send, fix corrupted path strings for long paths
    
    If a path has more than 230 characters, we allocate a new buffer to
    use for the path, but we were forgotting to copy the contents of the
    previous buffer into the new one, which has random content from the
    kmalloc call.
    
    Test:
    
        mkfs.btrfs -f /dev/sdd
        mount /dev/sdd /mnt
    
        TEST_PATH="/mnt/fdmanana/.config/google-chrome-mysetup/Default/Pepper_Data/Shockwave_Flash/WritableRoot/#SharedObjects/JSHJ4ZKN/s.wsj.net/[[IMPORT]]/players.edgesuite.net/flash/plugins/osmf/advanced-streaming-plugin/v2.7/osmf1.6/Ak#"
        mkdir -p $TEST_PATH
        echo "hello world" > $TEST_PATH/amaiAdvancedStreamingPlugin.txt
    
        btrfs subvolume snapshot -r /mnt /mnt/mysnap1
        btrfs send /mnt/mysnap1 -f /tmp/1.snap
    
    A test for xfstests follows.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Cc: Marc Merlin <marc@merlins.org>
    Tested-by: Marc MERLIN <marc@merlins.org>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index fd38b5053479..484aacac2c89 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -360,10 +360,13 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 	/*
 	 * First time the inline_buf does not suffice
 	 */
-	if (p->buf == p->inline_buf)
+	if (p->buf == p->inline_buf) {
 		tmp_buf = kmalloc(len, GFP_NOFS);
-	else
+		if (tmp_buf)
+			memcpy(tmp_buf, p->buf, old_buf_len);
+	} else {
 		tmp_buf = krealloc(p->buf, len, GFP_NOFS);
+	}
 	if (!tmp_buf)
 		return -ENOMEM;
 	p->buf = tmp_buf;

commit 51a60253a58514524b7a347c4e68553821a79d04
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Tue May 13 22:01:02 2014 +0100

    Btrfs: send, fix incorrect ref access when using extrefs
    
    When running send, if an inode only has extended reference items
    associated to it and no regular references, send.c:get_first_ref()
    was incorrectly assuming the reference it found was of type
    BTRFS_INODE_REF_KEY due to use of the wrong key variable.
    This caused weird behaviour when using the found item has a regular
    reference, such as weird path string, and occasionally (when lucky)
    a crash:
    
    [  190.600652] general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC
    [  190.600994] Modules linked in: btrfs xor raid6_pq binfmt_misc nfsd auth_rpcgss oid_registry nfs_acl nfs lockd fscache sunrpc psmouse serio_raw evbug pcspkr i2c_piix4 e1000 floppy
    [  190.602565] CPU: 2 PID: 14520 Comm: btrfs Not tainted 3.13.0-fdm-btrfs-next-26+ #1
    [  190.602728] Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
    [  190.602868] task: ffff8800d447c920 ti: ffff8801fa79e000 task.ti: ffff8801fa79e000
    [  190.603030] RIP: 0010:[<ffffffff813266b4>]  [<ffffffff813266b4>] memcpy+0x54/0x110
    [  190.603262] RSP: 0018:ffff8801fa79f880  EFLAGS: 00010202
    [  190.603395] RAX: ffff8800d4326e3f RBX: 000000000000036a RCX: ffff880000000000
    [  190.603553] RDX: 000000000000032a RSI: ffe708844042936a RDI: ffff8800d43271a9
    [  190.603710] RBP: ffff8801fa79f8c8 R08: 00000000003a4ef0 R09: 0000000000000000
    [  190.603867] R10: 793a4ef09f000000 R11: 9f0000000053726f R12: ffff8800d43271a9
    [  190.604020] R13: 0000160000000000 R14: ffff8802110134f0 R15: 000000000000036a
    [  190.604020] FS:  00007fb423d09b80(0000) GS:ffff880216200000(0000) knlGS:0000000000000000
    [  190.604020] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [  190.604020] CR2: 00007fb4229d4b78 CR3: 00000001f5d76000 CR4: 00000000000006e0
    [  190.604020] Stack:
    [  190.604020]  ffffffffa01f4d49 ffff8801fa79f8f0 00000000000009f9 ffff8801fa79f8c8
    [  190.604020]  00000000000009f9 ffff880211013260 000000000000f971 ffff88021147dba8
    [  190.604020]  00000000000009f9 ffff8801fa79f918 ffffffffa02367f5 ffff8801fa79f928
    [  190.604020] Call Trace:
    [  190.604020]  [<ffffffffa01f4d49>] ? read_extent_buffer+0xb9/0x120 [btrfs]
    [  190.604020]  [<ffffffffa02367f5>] fs_path_add_from_extent_buffer+0x45/0x60 [btrfs]
    [  190.604020]  [<ffffffffa0238806>] get_first_ref+0x1f6/0x210 [btrfs]
    [  190.604020]  [<ffffffffa0238994>] __get_cur_name_and_parent+0x174/0x3a0 [btrfs]
    [  190.604020]  [<ffffffff8118df3d>] ? kmem_cache_alloc_trace+0x11d/0x1e0
    [  190.604020]  [<ffffffffa0236674>] ? fs_path_alloc+0x24/0x60 [btrfs]
    [  190.604020]  [<ffffffffa0238c91>] get_cur_path+0xd1/0x240 [btrfs]
    (...)
    
    Steps to reproduce (either crash or some weirdness like an odd path string):
    
        mkfs.btrfs -f -O extref /dev/sdd
        mount /dev/sdd /mnt
    
        mkdir /mnt/testdir
        touch /mnt/testdir/foobar
    
        for i in `seq 1 2550`; do
            ln /mnt/testdir/foobar /mnt/testdir/foobar_link_`printf "%04d" $i`
        done
    
        ln /mnt/testdir/foobar /mnt/testdir/final_foobar_name
    
        rm -f /mnt/testdir/foobar
        for i in `seq 1 2550`; do
            rm -f /mnt/testdir/foobar_link_`printf "%04d" $i`
        done
    
        btrfs subvolume snapshot -r /mnt /mnt/mysnap
        btrfs send /mnt/mysnap -f /tmp/mysnap.send
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index eb6537a08c1b..fd38b5053479 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1668,7 +1668,7 @@ static int get_first_ref(struct btrfs_root *root, u64 ino,
 		goto out;
 	}
 
-	if (key.type == BTRFS_INODE_REF_KEY) {
+	if (found_key.type == BTRFS_INODE_REF_KEY) {
 		struct btrfs_inode_ref *iref;
 		iref = btrfs_item_ptr(path->nodes[0], path->slots[0],
 				      struct btrfs_inode_ref);

commit cfd4a535b68faf651b238586011f5bae128391c4
Author: Chris Mason <clm@fb.com>
Date:   Sat Apr 26 05:02:03 2014 -0700

    Btrfs: limit the path size in send to PATH_MAX
    
    fs_path_ensure_buf is used to make sure our path buffers for
    send are big enough for the path names as we construct them.
    The buffer size is limited to 32K by the length field in
    the struct.
    
    But bugs in the path construction can end up trying to build
    a huge buffer, and we'll do invalid memmmoves when the
    buffer length field wraps.
    
    This patch is step one, preventing the overflows.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 1ac3ca98c429..eb6537a08c1b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -349,6 +349,11 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 	if (p->buf_len >= len)
 		return 0;
 
+	if (len > PATH_MAX) {
+		WARN_ON(1);
+		return -ENOMEM;
+	}
+
 	path_len = p->end - p->start;
 	old_buf_len = p->buf_len;
 

commit c715e155c94ba0b3657820d676ec3c7213a5ce81
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Mon Mar 31 14:52:14 2014 +0100

    Btrfs: send, build path string only once in send_hole
    
    There's no point building the path string in each iteration of the
    send_hole loop, as it produces always the same string.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e8e9f354f341..1ac3ca98c429 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4436,14 +4436,14 @@ static int send_hole(struct send_ctx *sctx, u64 end)
 	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
+	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
+	if (ret < 0)
+		goto tlv_put_failure;
 	memset(sctx->read_buf, 0, BTRFS_SEND_READ_SIZE);
 	while (offset < end) {
 		len = min_t(u64, end - offset, BTRFS_SEND_READ_SIZE);
 
 		ret = begin_cmd(sctx, BTRFS_SEND_C_WRITE);
-		if (ret < 0)
-			break;
-		ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
 		if (ret < 0)
 			break;
 		TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);

commit 766b5e5ae78dd04a93a275690a49e23d7dcb1f39
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Sun Mar 30 23:02:53 2014 +0100

    Btrfs: send, fix data corruption due to incorrect hole detection
    
    During an incremental send, when we finish processing an inode (corresponding to
    a regular file) we would assume the gap between the end of the last processed file
    extent and the file's size corresponded to a file hole, and therefore incorrectly
    send a bunch of zero bytes to overwrite that region in the file.
    
    This affects only kernel 3.14.
    
    Reproducer:
    
        mkfs.btrfs -f /dev/sdc
        mount /dev/sdc /mnt
    
        xfs_io -f -c "falloc -k 0 268435456" /mnt/foo
    
        btrfs subvolume snapshot -r /mnt /mnt/mysnap0
    
        xfs_io -c "pwrite -S 0x01 -b 9216 16190218 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x02 -b 1121 198720104 1121" /mnt/foo
        xfs_io -c "pwrite -S 0x05 -b 9216 107887439 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x06 -b 9216 225520207 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x07 -b 67584 102138300 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x08 -b 7000 94897484 7000" /mnt/foo
        xfs_io -c "pwrite -S 0x09 -b 113664 245083212 113664" /mnt/foo
        xfs_io -c "pwrite -S 0x10 -b 123 17937788 123" /mnt/foo
        xfs_io -c "pwrite -S 0x11 -b 39936 229573311 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x12 -b 67584 174792222 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x13 -b 9216 249253213 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x16 -b 67584 150046083 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x17 -b 39936 118246040 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x18 -b 67584 215965442 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x19 -b 33792 97096725 33792" /mnt/foo
        xfs_io -c "pwrite -S 0x20 -b 125952 166300596 125952" /mnt/foo
        xfs_io -c "pwrite -S 0x21 -b 123 1078957 123" /mnt/foo
        xfs_io -c "pwrite -S 0x25 -b 9216 212044492 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x26 -b 7000 265037146 7000" /mnt/foo
        xfs_io -c "pwrite -S 0x27 -b 42757 215922685 42757" /mnt/foo
        xfs_io -c "pwrite -S 0x28 -b 7000 69865411 7000" /mnt/foo
        xfs_io -c "pwrite -S 0x29 -b 67584 67948958 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x30 -b 39936 266967019 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x31 -b 1121 19582453 1121" /mnt/foo
        xfs_io -c "pwrite -S 0x32 -b 17408 257710255 17408" /mnt/foo
        xfs_io -c "pwrite -S 0x33 -b 39936 3895518 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x34 -b 125952 12045847 125952" /mnt/foo
        xfs_io -c "pwrite -S 0x35 -b 17408 19156379 17408" /mnt/foo
        xfs_io -c "pwrite -S 0x36 -b 39936 50160066 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x37 -b 113664 9549793 113664" /mnt/foo
        xfs_io -c "pwrite -S 0x38 -b 105472 94391506 105472" /mnt/foo
        xfs_io -c "pwrite -S 0x39 -b 23552 143632863 23552" /mnt/foo
        xfs_io -c "pwrite -S 0x40 -b 39936 241283845 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x41 -b 113664 199937606 113664" /mnt/foo
        xfs_io -c "pwrite -S 0x42 -b 67584 67380093 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x43 -b 67584 26793129 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x44 -b 39936 14421913 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x45 -b 123 253097405 123" /mnt/foo
        xfs_io -c "pwrite -S 0x46 -b 1121 128233424 1121" /mnt/foo
        xfs_io -c "pwrite -S 0x47 -b 105472 91577959 105472" /mnt/foo
        xfs_io -c "pwrite -S 0x48 -b 1121 7245381 1121" /mnt/foo
        xfs_io -c "pwrite -S 0x49 -b 113664 182414694 113664" /mnt/foo
        xfs_io -c "pwrite -S 0x50 -b 9216 32750608 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x51 -b 67584 266546049 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x52 -b 67584 87969398 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x53 -b 9216 260848797 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x54 -b 39936 119461243 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x55 -b 7000 200178693 7000" /mnt/foo
        xfs_io -c "pwrite -S 0x56 -b 9216 243316029 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x57 -b 7000 209658229 7000" /mnt/foo
        xfs_io -c "pwrite -S 0x58 -b 101376 179745192 101376" /mnt/foo
        xfs_io -c "pwrite -S 0x59 -b 9216 64012300 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x60 -b 125952 181705139 125952" /mnt/foo
        xfs_io -c "pwrite -S 0x61 -b 23552 235737348 23552" /mnt/foo
        xfs_io -c "pwrite -S 0x62 -b 113664 106021355 113664" /mnt/foo
        xfs_io -c "pwrite -S 0x63 -b 67584 135753552 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x64 -b 23552 95730888 23552" /mnt/foo
        xfs_io -c "pwrite -S 0x65 -b 11 17311415 11" /mnt/foo
        xfs_io -c "pwrite -S 0x66 -b 33792 120695553 33792" /mnt/foo
        xfs_io -c "pwrite -S 0x67 -b 9216 17164631 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x68 -b 9216 136065853 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x69 -b 67584 37752198 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x70 -b 101376 189717473 101376" /mnt/foo
        xfs_io -c "pwrite -S 0x71 -b 7000 227463698 7000" /mnt/foo
        xfs_io -c "pwrite -S 0x72 -b 9216 12655137 9216" /mnt/foo
        xfs_io -c "pwrite -S 0x73 -b 7000 7488866 7000" /mnt/foo
        xfs_io -c "pwrite -S 0x74 -b 113664 87813649 113664" /mnt/foo
        xfs_io -c "pwrite -S 0x75 -b 33792 25802183 33792" /mnt/foo
        xfs_io -c "pwrite -S 0x76 -b 39936 93524024 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x77 -b 33792 113336388 33792" /mnt/foo
        xfs_io -c "pwrite -S 0x78 -b 105472 184955320 105472" /mnt/foo
        xfs_io -c "pwrite -S 0x79 -b 101376 225691598 101376" /mnt/foo
        xfs_io -c "pwrite -S 0x80 -b 23552 77023155 23552" /mnt/foo
        xfs_io -c "pwrite -S 0x81 -b 11 201888192 11" /mnt/foo
        xfs_io -c "pwrite -S 0x82 -b 11 115332492 11" /mnt/foo
        xfs_io -c "pwrite -S 0x83 -b 67584 230278015 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x84 -b 11 120589073 11" /mnt/foo
        xfs_io -c "pwrite -S 0x85 -b 125952 202207819 125952" /mnt/foo
        xfs_io -c "pwrite -S 0x86 -b 113664 86672080 113664" /mnt/foo
        xfs_io -c "pwrite -S 0x87 -b 17408 208459603 17408" /mnt/foo
        xfs_io -c "pwrite -S 0x88 -b 7000 73372211 7000" /mnt/foo
        xfs_io -c "pwrite -S 0x89 -b 7000 42252122 7000" /mnt/foo
        xfs_io -c "pwrite -S 0x90 -b 23552 46784881 23552" /mnt/foo
        xfs_io -c "pwrite -S 0x91 -b 101376 63172351 101376" /mnt/foo
        xfs_io -c "pwrite -S 0x92 -b 23552 59341931 23552" /mnt/foo
        xfs_io -c "pwrite -S 0x93 -b 39936 239599283 39936" /mnt/foo
        xfs_io -c "pwrite -S 0x94 -b 67584 175643105 67584" /mnt/foo
        xfs_io -c "pwrite -S 0x97 -b 23552 105534880 23552" /mnt/foo
        xfs_io -c "pwrite -S 0x98 -b 113664 8236844 113664" /mnt/foo
        xfs_io -c "pwrite -S 0x99 -b 125952 144489686 125952" /mnt/foo
        xfs_io -c "pwrite -S 0xa0 -b 7000 73273112 7000" /mnt/foo
        xfs_io -c "pwrite -S 0xa1 -b 125952 194580243 125952" /mnt/foo
        xfs_io -c "pwrite -S 0xa2 -b 123 56296779 123" /mnt/foo
        xfs_io -c "pwrite -S 0xa3 -b 11 233066845 11" /mnt/foo
        xfs_io -c "pwrite -S 0xa4 -b 39936 197727090 39936" /mnt/foo
        xfs_io -c "pwrite -S 0xa5 -b 101376 53579812 101376" /mnt/foo
        xfs_io -c "pwrite -S 0xa6 -b 9216 85669738 9216" /mnt/foo
        xfs_io -c "pwrite -S 0xa7 -b 125952 21266322 125952" /mnt/foo
        xfs_io -c "pwrite -S 0xa8 -b 23552 125726568 23552" /mnt/foo
        xfs_io -c "pwrite -S 0xa9 -b 9216 18423680 9216" /mnt/foo
        xfs_io -c "pwrite -S 0xb0 -b 1121 165901483 1121" /mnt/foo
    
        btrfs subvolume snapshot -r /mnt /mnt/mysnap1
    
        xfs_io -c "pwrite -S 0xff -b 10 16190218 10" /mnt/foo
    
        btrfs subvolume snapshot -r /mnt /mnt/mysnap2
    
        md5sum /mnt/foo          # returns 79e53f1466bfc09fd82b450689e6119e
        md5sum /mnt/mysnap2/foo  # returns 79e53f1466bfc09fd82b450689e6119e too
    
        btrfs send /mnt/mysnap1 -f /tmp/1.snap
        btrfs send -p /mnt/mysnap1 /mnt/mysnap2 -f /tmp/2.snap
    
        mkfs.btrfs -f /dev/sdc
        mount /dev/sdc /mnt
    
        btrfs receive /mnt -f /tmp/1.snap
        btrfs receive /mnt -f /tmp/2.snap
    
        md5sum /mnt/mysnap2/foo  # returns 2bb414c5155767cedccd7063e51beabd !!
    
    A testcase for xfstests follows soon too.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ab34a23838ef..e8e9f354f341 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4986,7 +4986,9 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 
 	if (S_ISREG(sctx->cur_inode_mode)) {
 		if (need_send_hole(sctx)) {
-			if (sctx->cur_inode_last_extent == (u64)-1) {
+			if (sctx->cur_inode_last_extent == (u64)-1 ||
+			    sctx->cur_inode_last_extent <
+			    sctx->cur_inode_size) {
 				ret = get_last_extent(sctx, (u64)-1);
 				if (ret)
 					goto out;

commit 3f8a18cc53bd1be26eb5b5247e1386ad0e21b623
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Mar 28 17:16:01 2014 -0400

    Btrfs: hold the commit_root_sem when getting the commit root during send
    
    We currently rely too heavily on roots being read-only to save us from just
    accessing root->commit_root.  We can easily balance blocks out from underneath a
    read only root, so to save us from getting screwed make sure we only access
    root->commit_root under the commit root sem.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 6b5f13659317..ab34a23838ef 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -493,6 +493,7 @@ static struct btrfs_path *alloc_path_for_send(void)
 		return NULL;
 	path->search_commit_root = 1;
 	path->skip_locking = 1;
+	path->need_commit_sem = 1;
 	return path;
 }
 
@@ -771,29 +772,22 @@ verbose_printk("btrfs: send_rmdir %s\n", path->start);
 /*
  * Helper function to retrieve some fields from an inode item.
  */
-static int get_inode_info(struct btrfs_root *root,
-			  u64 ino, u64 *size, u64 *gen,
-			  u64 *mode, u64 *uid, u64 *gid,
-			  u64 *rdev)
+static int __get_inode_info(struct btrfs_root *root, struct btrfs_path *path,
+			  u64 ino, u64 *size, u64 *gen, u64 *mode, u64 *uid,
+			  u64 *gid, u64 *rdev)
 {
 	int ret;
 	struct btrfs_inode_item *ii;
 	struct btrfs_key key;
-	struct btrfs_path *path;
-
-	path = alloc_path_for_send();
-	if (!path)
-		return -ENOMEM;
 
 	key.objectid = ino;
 	key.type = BTRFS_INODE_ITEM_KEY;
 	key.offset = 0;
 	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
-	if (ret < 0)
-		goto out;
 	if (ret) {
-		ret = -ENOENT;
-		goto out;
+		if (ret > 0)
+			ret = -ENOENT;
+		return ret;
 	}
 
 	ii = btrfs_item_ptr(path->nodes[0], path->slots[0],
@@ -811,7 +805,22 @@ static int get_inode_info(struct btrfs_root *root,
 	if (rdev)
 		*rdev = btrfs_inode_rdev(path->nodes[0], ii);
 
-out:
+	return ret;
+}
+
+static int get_inode_info(struct btrfs_root *root,
+			  u64 ino, u64 *size, u64 *gen,
+			  u64 *mode, u64 *uid, u64 *gid,
+			  u64 *rdev)
+{
+	struct btrfs_path *path;
+	int ret;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+	ret = __get_inode_info(root, path, ino, size, gen, mode, uid, gid,
+			       rdev);
 	btrfs_free_path(path);
 	return ret;
 }
@@ -1085,6 +1094,7 @@ static int get_inode_path(struct btrfs_root *root,
 struct backref_ctx {
 	struct send_ctx *sctx;
 
+	struct btrfs_path *path;
 	/* number of total found references */
 	u64 found;
 
@@ -1155,8 +1165,9 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 	 * There are inodes that have extents that lie behind its i_size. Don't
 	 * accept clones from these extents.
 	 */
-	ret = get_inode_info(found->root, ino, &i_size, NULL, NULL, NULL, NULL,
-			NULL);
+	ret = __get_inode_info(found->root, bctx->path, ino, &i_size, NULL, NULL,
+			       NULL, NULL, NULL);
+	btrfs_release_path(bctx->path);
 	if (ret < 0)
 		return ret;
 
@@ -1235,12 +1246,17 @@ static int find_extent_clone(struct send_ctx *sctx,
 	if (!tmp_path)
 		return -ENOMEM;
 
+	/* We only use this path under the commit sem */
+	tmp_path->need_commit_sem = 0;
+
 	backref_ctx = kmalloc(sizeof(*backref_ctx), GFP_NOFS);
 	if (!backref_ctx) {
 		ret = -ENOMEM;
 		goto out;
 	}
 
+	backref_ctx->path = tmp_path;
+
 	if (data_offset >= ino_size) {
 		/*
 		 * There may be extents that lie behind the file's size.

commit 9e351cc862b098d8ec8f8022d110932490794925
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Mar 13 15:42:13 2014 -0400

    Btrfs: remove transaction from send
    
    Lets try this again.  We can deadlock the box if we send on a box and try to
    write onto the same fs with the app that is trying to listen to the send pipe.
    This is because the writer could get stuck waiting for a transaction commit
    which is being blocked by the send.  So fix this by making sure looking at the
    commit roots is always going to be consistent.  We do this by keeping track of
    which roots need to have their commit roots swapped during commit, and then
    taking the commit_root_sem and swapping them all at once.  Then make sure we
    take a read lock on the commit_root_sem in cases where we search the commit root
    to make sure we're always looking at a consistent view of the commit roots.
    Previously we had problems with this because we would swap a fs tree commit root
    and then swap the extent tree commit root independently which would cause the
    backref walking code to screw up sometimes.  With this patch we no longer
    deadlock and pass all the weird send/receive corner cases.  Thanks,
    
    Reportedy-by: Hugo Mills <hugo@carfax.org.uk>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d00534b78382..6b5f13659317 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1268,8 +1268,10 @@ static int find_extent_clone(struct send_ctx *sctx,
 	}
 	logical = disk_byte + btrfs_file_extent_offset(eb, fi);
 
+	down_read(&sctx->send_root->fs_info->commit_root_sem);
 	ret = extent_from_logical(sctx->send_root->fs_info, disk_byte, tmp_path,
 				  &found_key, &flags);
+	up_read(&sctx->send_root->fs_info->commit_root_sem);
 	btrfs_release_path(tmp_path);
 
 	if (ret < 0)
@@ -5367,57 +5369,21 @@ static int changed_cb(struct btrfs_root *left_root,
 static int full_send_tree(struct send_ctx *sctx)
 {
 	int ret;
-	struct btrfs_trans_handle *trans = NULL;
 	struct btrfs_root *send_root = sctx->send_root;
 	struct btrfs_key key;
 	struct btrfs_key found_key;
 	struct btrfs_path *path;
 	struct extent_buffer *eb;
 	int slot;
-	u64 start_ctransid;
-	u64 ctransid;
 
 	path = alloc_path_for_send();
 	if (!path)
 		return -ENOMEM;
 
-	spin_lock(&send_root->root_item_lock);
-	start_ctransid = btrfs_root_ctransid(&send_root->root_item);
-	spin_unlock(&send_root->root_item_lock);
-
 	key.objectid = BTRFS_FIRST_FREE_OBJECTID;
 	key.type = BTRFS_INODE_ITEM_KEY;
 	key.offset = 0;
 
-join_trans:
-	/*
-	 * We need to make sure the transaction does not get committed
-	 * while we do anything on commit roots. Join a transaction to prevent
-	 * this.
-	 */
-	trans = btrfs_join_transaction(send_root);
-	if (IS_ERR(trans)) {
-		ret = PTR_ERR(trans);
-		trans = NULL;
-		goto out;
-	}
-
-	/*
-	 * Make sure the tree has not changed after re-joining. We detect this
-	 * by comparing start_ctransid and ctransid. They should always match.
-	 */
-	spin_lock(&send_root->root_item_lock);
-	ctransid = btrfs_root_ctransid(&send_root->root_item);
-	spin_unlock(&send_root->root_item_lock);
-
-	if (ctransid != start_ctransid) {
-		WARN(1, KERN_WARNING "BTRFS: the root that you're trying to "
-				     "send was modified in between. This is "
-				     "probably a bug.\n");
-		ret = -EIO;
-		goto out;
-	}
-
 	ret = btrfs_search_slot_for_read(send_root, &key, path, 1, 0);
 	if (ret < 0)
 		goto out;
@@ -5425,19 +5391,6 @@ static int full_send_tree(struct send_ctx *sctx)
 		goto out_finish;
 
 	while (1) {
-		/*
-		 * When someone want to commit while we iterate, end the
-		 * joined transaction and rejoin.
-		 */
-		if (btrfs_should_end_transaction(trans, send_root)) {
-			ret = btrfs_end_transaction(trans, send_root);
-			trans = NULL;
-			if (ret < 0)
-				goto out;
-			btrfs_release_path(path);
-			goto join_trans;
-		}
-
 		eb = path->nodes[0];
 		slot = path->slots[0];
 		btrfs_item_key_to_cpu(eb, &found_key, slot);
@@ -5465,12 +5418,6 @@ static int full_send_tree(struct send_ctx *sctx)
 
 out:
 	btrfs_free_path(path);
-	if (trans) {
-		if (!ret)
-			ret = btrfs_end_transaction(trans, send_root);
-		else
-			btrfs_end_transaction(trans, send_root);
-	}
 	return ret;
 }
 

commit a26e8c9f75b0bfd8cccc9e8f110737b136eb5994
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Mar 28 17:07:27 2014 -0400

    Btrfs: don't clear uptodate if the eb is under IO
    
    So I have an awful exercise script that will run snapshot, balance and
    send/receive in parallel.  This sometimes would crash spectacularly and when it
    came back up the fs would be completely hosed.  Turns out this is because of a
    bad interaction of balance and send/receive.  Send will hold onto its entire
    path for the whole send, but its blocks could get relocated out from underneath
    it, and because it doesn't old tree locks theres nothing to keep this from
    happening.  So it will go to read in a slot with an old transid, and we could
    have re-allocated this block for something else and it could have a completely
    different transid.  But because we think it is invalid we clear uptodate and
    re-read in the block.  If we do this before we actually write out the new block
    we could write back stale data to the fs, and boom we're screwed.
    
    Now we definitely need to fix this disconnect between send and balance, but we
    really really need to not allow ourselves to accidently read in stale data over
    new data.  So make sure we check if the extent buffer is not under io before
    clearing uptodate, this will kick back EIO to the caller instead of reading in
    stale data and keep us from corrupting the fs.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 9b6da9d55f9a..d00534b78382 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5718,7 +5718,9 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			NULL);
 	sort_clone_roots = 1;
 
+	current->journal_info = (void *)BTRFS_SEND_TRANS_STUB;
 	ret = send_subvol(sctx);
+	current->journal_info = NULL;
 	if (ret < 0)
 		goto out;
 

commit 73b802f44747e824f6efe273903149ede9ddf741
Author: Chris Mason <clm@fb.com>
Date:   Fri Mar 21 15:30:44 2014 -0700

    btrfs: fix uninit variable warning
    
    fs/btrfs/send.c:2926: warning: ‘entry’ may be used uninitialized in this
    function
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 143fed3f4586..9b6da9d55f9a 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2923,7 +2923,7 @@ static int add_pending_dir_move(struct send_ctx *sctx,
 {
 	struct rb_node **p = &sctx->pending_dir_moves.rb_node;
 	struct rb_node *parent = NULL;
-	struct pending_dir_move *entry, *pm;
+	struct pending_dir_move *entry = NULL, *pm;
 	struct recorded_ref *cur;
 	int exists = 0;
 	int ret;

commit bfa7e1f8be4bd7118e485a42cc8889530d415d05
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Wed Mar 19 14:20:54 2014 +0000

    Btrfs: part 2, fix incremental send's decision to delay a dir move/rename
    
    For an incremental send, fix the process of determining whether the directory
    inode we're currently processing needs to have its move/rename operation delayed.
    
    We were ignoring the fact that if the inode's new immediate ancestor has a higher
    inode number than ours but wasn't renamed/moved, we might still need to delay our
    move/rename, because some other ancestor directory higher in the hierarchy might
    have an inode number higher than ours *and* was renamed/moved too - in this case
    we have to wait for rename/move of that ancestor to happen before our current
    directory's rename/move operation.
    
    Simple steps to reproduce this issue:
    
          $ mkfs.btrfs -f /dev/sdd
          $ mount /dev/sdd /mnt
    
          $ mkdir -p /mnt/a/x1/x2
          $ mkdir /mnt/a/Z
          $ mkdir -p /mnt/a/x1/x2/x3/x4/x5
    
          $ btrfs subvolume snapshot -r /mnt /mnt/snap1
          $ btrfs send /mnt/snap1 -f /tmp/base.send
    
          $ mv /mnt/a/x1/x2/x3 /mnt/a/Z/X33
          $ mv /mnt/a/x1/x2 /mnt/a/Z/X33/x4/x5/X22
    
          $ btrfs subvolume snapshot -r /mnt /mnt/snap2
          $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/incremental.send
    
    The incremental send caused the kernel code to enter an infinite loop when
    building the path string for directory Z after its references are processed.
    
    A more complex scenario:
    
          $ mkfs.btrfs -f /dev/sdd
          $ mount /dev/sdd /mnt
    
          $ mkdir -p /mnt/a/b/c/d
          $ mkdir /mnt/a/b/c/d/e
          $ mkdir /mnt/a/b/c/d/f
          $ mv /mnt/a/b/c/d/e /mnt/a/b/c/d/f/E2
          $ mkdir /mmt/a/b/c/g
          $ mv /mnt/a/b/c/d /mnt/a/b/D2
    
          $ btrfs subvolume snapshot -r /mnt /mnt/snap1
          $ btrfs send /mnt/snap1 -f /tmp/base.send
    
          $ mkdir /mnt/a/o
          $ mv /mnt/a/b/c/g /mnt/a/b/D2/f/G2
          $ mv /mnt/a/b/D2 /mnt/a/b/dd
          $ mv /mnt/a/b/c /mnt/a/C2
          $ mv /mnt/a/b/dd/f /mnt/a/o/FF
          $ mv /mnt/a/b /mnt/a/o/FF/E2/BB
    
          $ btrfs subvolume snapshot -r /mnt /mnt/snap2
          $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/incremental.send
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index f16472409eec..143fed3f4586 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2916,7 +2916,10 @@ static void free_waiting_dir_move(struct send_ctx *sctx,
 	kfree(dm);
 }
 
-static int add_pending_dir_move(struct send_ctx *sctx, u64 parent_ino)
+static int add_pending_dir_move(struct send_ctx *sctx,
+				u64 ino,
+				u64 ino_gen,
+				u64 parent_ino)
 {
 	struct rb_node **p = &sctx->pending_dir_moves.rb_node;
 	struct rb_node *parent = NULL;
@@ -2929,8 +2932,8 @@ static int add_pending_dir_move(struct send_ctx *sctx, u64 parent_ino)
 	if (!pm)
 		return -ENOMEM;
 	pm->parent_ino = parent_ino;
-	pm->ino = sctx->cur_ino;
-	pm->gen = sctx->cur_inode_gen;
+	pm->ino = ino;
+	pm->gen = ino_gen;
 	INIT_LIST_HEAD(&pm->list);
 	INIT_LIST_HEAD(&pm->update_refs);
 	RB_CLEAR_NODE(&pm->node);
@@ -3183,6 +3186,8 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 	struct fs_path *path_before = NULL;
 	struct fs_path *path_after = NULL;
 	int len1, len2;
+	int register_upper_dirs;
+	u64 gen;
 
 	if (is_waiting_for_move(sctx, ino))
 		return 1;
@@ -3220,7 +3225,7 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 	}
 
 	ret = get_first_ref(sctx->send_root, ino, &parent_ino_after,
-			    NULL, path_after);
+			    &gen, path_after);
 	if (ret == -ENOENT) {
 		ret = 0;
 		goto out;
@@ -3237,6 +3242,60 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 	}
 	ret = 0;
 
+	/*
+	 * Ok, our new most direct ancestor has a higher inode number but
+	 * wasn't moved/renamed. So maybe some of the new ancestors higher in
+	 * the hierarchy have an higher inode number too *and* were renamed
+	 * or moved - in this case we need to wait for the ancestor's rename
+	 * or move operation before we can do the move/rename for the current
+	 * inode.
+	 */
+	register_upper_dirs = 0;
+	ino = parent_ino_after;
+again:
+	while ((ret == 0 || register_upper_dirs) && ino > sctx->cur_ino) {
+		u64 parent_gen;
+
+		fs_path_reset(path_before);
+		fs_path_reset(path_after);
+
+		ret = get_first_ref(sctx->send_root, ino, &parent_ino_after,
+				    &parent_gen, path_after);
+		if (ret < 0)
+			goto out;
+		ret = get_first_ref(sctx->parent_root, ino, &parent_ino_before,
+				    NULL, path_before);
+		if (ret == -ENOENT) {
+			ret = 0;
+			break;
+		} else if (ret < 0) {
+			goto out;
+		}
+
+		len1 = fs_path_len(path_before);
+		len2 = fs_path_len(path_after);
+		if (parent_ino_before != parent_ino_after || len1 != len2 ||
+		    memcmp(path_before->start, path_after->start, len1)) {
+			ret = 1;
+			if (register_upper_dirs) {
+				break;
+			} else {
+				register_upper_dirs = 1;
+				ino = parent_ref->dir;
+				gen = parent_ref->dir_gen;
+				goto again;
+			}
+		} else if (register_upper_dirs) {
+			ret = add_pending_dir_move(sctx, ino, gen,
+						   parent_ino_after);
+			if (ret < 0 && ret != -EEXIST)
+				goto out;
+		}
+
+		ino = parent_ino_after;
+		gen = parent_gen;
+	}
+
 out:
 	fs_path_free(path_before);
 	fs_path_free(path_after);
@@ -3402,7 +3461,9 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 					goto out;
 				if (ret) {
 					ret = add_pending_dir_move(sctx,
-								   cur->dir);
+							   sctx->cur_ino,
+							   sctx->cur_inode_gen,
+							   cur->dir);
 					*pending_move = 1;
 				} else {
 					ret = send_rename(sctx, valid_path,

commit 7b119a8b8998f17abd6caf928dee5bf203eef8c5
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Sun Mar 16 20:37:26 2014 +0000

    Btrfs: fix incremental send's decision to delay a dir move/rename
    
    It's possible to change the parent/child relationship between directories
    in such a way that if a child directory has a higher inode number than
    its parent, it doesn't necessarily means the child rename/move operation
    can be performed immediately. The parent migth have its own rename/move
    operation delayed, therefore in this case the child needs to have its
    rename/move operation delayed too, and be performed after its new parent's
    rename/move.
    
    Steps to reproduce the issue:
    
          $ umount /mnt
          $ mkfs.btrfs -f /dev/sdd
          $ mount /dev/sdd /mnt
    
          $ mkdir /mnt/A
          $ mkdir /mnt/B
          $ mkdir /mnt/C
          $ mv /mnt/C /mnt/A
          $ mv /mnt/B /mnt/A/C
          $ mkdir /mnt/A/C/D
    
          $ btrfs subvolume snapshot -r /mnt /mnt/snap1
          $ btrfs send /mnt/snap1 -f /tmp/base.send
    
          $ mv /mnt/A/C/D /mnt/A/D2
          $ mv /mnt/A/C/B /mnt/A/D2/B2
          $ mv /mnt/A/C /mnt/A/D2/B2/C2
    
          $ btrfs subvolume snapshot -r /mnt /mnt/snap2
          $ btrfs send -p /mnt/snap1 /mnt/snap2 -f /tmp/incremental.send
    
    The incremental send caused the kernel code to enter an infinite loop when
    building the path string for directory C after its references are processed.
    
    The necessary conditions here are that C has an inode number higher than both
    A and B, and B as an higher inode number higher than A, and D has the highest
    inode number, that is:
        inode_number(A) < inode_number(B) < inode_number(C) < inode_number(D)
    
    The same issue could happen if after the first snapshot there's any number
    of intermediary parent directories between A2 and B2, and between B2 and C2.
    
    A test case for xfstests follows, covering this simple case and more advanced
    ones, with files and hard links created inside the directories.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 92d4ae8a8ae6..f16472409eec 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3184,12 +3184,12 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 	struct fs_path *path_after = NULL;
 	int len1, len2;
 
-	if (parent_ref->dir <= sctx->cur_ino)
-		return 0;
-
 	if (is_waiting_for_move(sctx, ino))
 		return 1;
 
+	if (parent_ref->dir <= sctx->cur_ino)
+		return 0;
+
 	ret = get_inode_info(sctx->parent_root, ino, NULL, &old_gen,
 			     NULL, NULL, NULL, NULL);
 	if (ret == -ENOENT)

commit 425b5dafc8738d3d6d6b05827f40bd32bf04a20b
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Tue Mar 18 17:56:06 2014 +0000

    Btrfs: remove unnecessary inode generation lookup in send
    
    No need to search in the send tree for the generation number of the inode,
    we already have it in the recorded_ref structure passed to us.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 646369179697..92d4ae8a8ae6 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3179,7 +3179,7 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 	int ret;
 	u64 ino = parent_ref->dir;
 	u64 parent_ino_before, parent_ino_after;
-	u64 new_gen, old_gen;
+	u64 old_gen;
 	struct fs_path *path_before = NULL;
 	struct fs_path *path_after = NULL;
 	int len1, len2;
@@ -3197,12 +3197,7 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 	else if (ret < 0)
 		return ret;
 
-	ret = get_inode_info(sctx->send_root, ino, NULL, &new_gen,
-			     NULL, NULL, NULL, NULL);
-	if (ret < 0)
-		return ret;
-
-	if (new_gen != old_gen)
+	if (parent_ref->dir_gen != old_gen)
 		return 0;
 
 	path_before = fs_path_alloc();

commit 2131bcd38b18167f499f190acf3409dfe5b3c280
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Mar 5 10:07:35 2014 +0800

    Btrfs: add readahead for send_write
    
    Btrfs send reads data from disk and then writes to a stream via pipe or
    a file via flush.
    
    Currently we're going to read each page a time, so every page results
    in a disk read, which is not friendly to disks, esp. HDD.  Given that,
    the performance can be gained by adding readahead for those pages.
    
    Here is a quick test:
    $ btrfs subvolume create send
    $ xfs_io -f -c "pwrite 0 1G" send/foobar
    $ btrfs subvolume snap -r send ro
    $ time "btrfs send ro -f /dev/null"
    
               w/o             w
    real    1m37.527s       0m9.097s
    user    0m0.122s        0m0.086s
    sys     0m53.191s       0m12.857s
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 112eb647b5cd..646369179697 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -124,6 +124,8 @@ struct send_ctx {
 	struct list_head name_cache_list;
 	int name_cache_size;
 
+	struct file_ra_state ra;
+
 	char *read_buf;
 
 	/*
@@ -4170,6 +4172,13 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
 		goto out;
 
 	last_index = (offset + len - 1) >> PAGE_CACHE_SHIFT;
+
+	/* initial readahead */
+	memset(&sctx->ra, 0, sizeof(struct file_ra_state));
+	file_ra_state_init(&sctx->ra, inode->i_mapping);
+	btrfs_force_ra(inode->i_mapping, &sctx->ra, NULL, index,
+		       last_index - index + 1);
+
 	while (index <= last_index) {
 		unsigned cur_len = min_t(unsigned, len,
 					 PAGE_CACHE_SIZE - pg_offset);

commit a4d96d6254590df5eb9a6ac32434ed9d33a46d19
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Mar 3 21:31:03 2014 +0800

    Btrfs: share the same code for __record_{new,deleted}_ref
    
    This has no functional change, only picks out the same part of two functions,
    and makes it shared.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 9d057ef5adef..112eb647b5cd 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2615,7 +2615,7 @@ struct recorded_ref {
  * everything mixed. So we first record all refs and later process them.
  * This function is a helper to record one ref.
  */
-static int record_ref(struct list_head *head, u64 dir,
+static int __record_ref(struct list_head *head, u64 dir,
 		      u64 dir_gen, struct fs_path *path)
 {
 	struct recorded_ref *ref;
@@ -3555,9 +3555,8 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 	return ret;
 }
 
-static int __record_new_ref(int num, u64 dir, int index,
-			    struct fs_path *name,
-			    void *ctx)
+static int record_ref(struct btrfs_root *root, int num, u64 dir, int index,
+		      struct fs_path *name, void *ctx, struct list_head *refs)
 {
 	int ret = 0;
 	struct send_ctx *sctx = ctx;
@@ -3568,7 +3567,7 @@ static int __record_new_ref(int num, u64 dir, int index,
 	if (!p)
 		return -ENOMEM;
 
-	ret = get_inode_info(sctx->send_root, dir, NULL, &gen, NULL, NULL,
+	ret = get_inode_info(root, dir, NULL, &gen, NULL, NULL,
 			NULL, NULL);
 	if (ret < 0)
 		goto out;
@@ -3580,7 +3579,7 @@ static int __record_new_ref(int num, u64 dir, int index,
 	if (ret < 0)
 		goto out;
 
-	ret = record_ref(&sctx->new_refs, dir, gen, p);
+	ret = __record_ref(refs, dir, gen, p);
 
 out:
 	if (ret)
@@ -3588,37 +3587,23 @@ static int __record_new_ref(int num, u64 dir, int index,
 	return ret;
 }
 
+static int __record_new_ref(int num, u64 dir, int index,
+			    struct fs_path *name,
+			    void *ctx)
+{
+	struct send_ctx *sctx = ctx;
+	return record_ref(sctx->send_root, num, dir, index, name,
+			  ctx, &sctx->new_refs);
+}
+
+
 static int __record_deleted_ref(int num, u64 dir, int index,
 				struct fs_path *name,
 				void *ctx)
 {
-	int ret = 0;
 	struct send_ctx *sctx = ctx;
-	struct fs_path *p;
-	u64 gen;
-
-	p = fs_path_alloc();
-	if (!p)
-		return -ENOMEM;
-
-	ret = get_inode_info(sctx->parent_root, dir, NULL, &gen, NULL, NULL,
-			NULL, NULL);
-	if (ret < 0)
-		goto out;
-
-	ret = get_cur_path(sctx, dir, gen, p);
-	if (ret < 0)
-		goto out;
-	ret = fs_path_add_path(p, name);
-	if (ret < 0)
-		goto out;
-
-	ret = record_ref(&sctx->deleted_refs, dir, gen, p);
-
-out:
-	if (ret)
-		fs_path_free(p);
-	return ret;
+	return record_ref(sctx->parent_root, num, dir, index, name,
+			  ctx, &sctx->deleted_refs);
 }
 
 static int record_new_ref(struct send_ctx *sctx)

commit fcbd2154d16431395e86a48859a5b547c33c09ad
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Mon Mar 3 12:28:40 2014 +0000

    Btrfs: avoid unnecessary utimes update in incremental send
    
    When we're finishing processing of an inode, if we're dealing with a
    directory inode that has a pending move/rename operation, we don't
    need to send a utimes update instruction to the send stream, as we'll
    do it later after doing the move/rename operation. Therefore we save
    some time here building paths and doing btree lookups.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c2522e4e2c59..9d057ef5adef 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4957,18 +4957,19 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 		ret = apply_children_dir_moves(sctx);
 		if (ret)
 			goto out;
+		/*
+		 * Need to send that every time, no matter if it actually
+		 * changed between the two trees as we have done changes to
+		 * the inode before. If our inode is a directory and it's
+		 * waiting to be moved/renamed, we will send its utimes when
+		 * it's moved/renamed, therefore we don't need to do it here.
+		 */
+		sctx->send_progress = sctx->cur_ino + 1;
+		ret = send_utimes(sctx, sctx->cur_ino, sctx->cur_inode_gen);
+		if (ret < 0)
+			goto out;
 	}
 
-	/*
-	 * Need to send that every time, no matter if it actually
-	 * changed between the two trees as we have done changes to
-	 * the inode before.
-	 */
-	sctx->send_progress = sctx->cur_ino + 1;
-	ret = send_utimes(sctx, sctx->cur_ino, sctx->cur_inode_gen);
-	if (ret < 0)
-		goto out;
-
 out:
 	return ret;
 }

commit 644d1940ab0f20d1ba13295827a86a8a0c8583f3
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Feb 27 17:29:01 2014 +0800

    Btrfs: skip search tree for REG files
    
    It is really unnecessary to search tree again for @gen, @mode and @rdev
    in the case of REG inodes' creation, as we've got btrfs_inode_item in sctx,
    and @gen, @mode and @rdev can easily be fetched.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ba23fef3c5e5..c2522e4e2c59 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -112,6 +112,7 @@ struct send_ctx {
 	int cur_inode_deleted;
 	u64 cur_inode_size;
 	u64 cur_inode_mode;
+	u64 cur_inode_rdev;
 	u64 cur_inode_last_extent;
 
 	u64 send_progress;
@@ -2439,10 +2440,16 @@ verbose_printk("btrfs: send_create_inode %llu\n", ino);
 	if (!p)
 		return -ENOMEM;
 
-	ret = get_inode_info(sctx->send_root, ino, NULL, &gen, &mode, NULL,
-			NULL, &rdev);
-	if (ret < 0)
-		goto out;
+	if (ino != sctx->cur_ino) {
+		ret = get_inode_info(sctx->send_root, ino, NULL, &gen, &mode,
+				     NULL, NULL, &rdev);
+		if (ret < 0)
+			goto out;
+	} else {
+		gen = sctx->cur_inode_gen;
+		mode = sctx->cur_inode_mode;
+		rdev = sctx->cur_inode_rdev;
+	}
 
 	if (S_ISREG(mode)) {
 		cmd = BTRFS_SEND_C_MKFILE;
@@ -5027,6 +5034,8 @@ static int changed_inode(struct send_ctx *sctx,
 				sctx->left_path->nodes[0], left_ii);
 		sctx->cur_inode_mode = btrfs_inode_mode(
 				sctx->left_path->nodes[0], left_ii);
+		sctx->cur_inode_rdev = btrfs_inode_rdev(
+				sctx->left_path->nodes[0], left_ii);
 		if (sctx->cur_ino != BTRFS_FIRST_FREE_OBJECTID)
 			ret = send_create_inode_if_needed(sctx);
 	} else if (result == BTRFS_COMPARE_TREE_DELETED) {
@@ -5071,6 +5080,8 @@ static int changed_inode(struct send_ctx *sctx,
 					sctx->left_path->nodes[0], left_ii);
 			sctx->cur_inode_mode = btrfs_inode_mode(
 					sctx->left_path->nodes[0], left_ii);
+			sctx->cur_inode_rdev = btrfs_inode_rdev(
+					sctx->left_path->nodes[0], left_ii);
 			ret = send_create_inode_if_needed(sctx);
 			if (ret < 0)
 				goto out;

commit 9c9ca00bd31989f1a3dcbf54e97c979024e44409
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Feb 25 19:33:08 2014 +0100

    btrfs: send: simplify allocation code in fs_path_ensure_buf
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 246df8513c8a..ba23fef3c5e5 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -352,24 +352,18 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 	/*
 	 * First time the inline_buf does not suffice
 	 */
-	if (p->buf == p->inline_buf) {
-		p->buf = kmalloc(len, GFP_NOFS);
-		if (!p->buf)
-			return -ENOMEM;
-		/*
-		 * The real size of the buffer is bigger, this will let the
-		 * fast path happen most of the time
-		 */
-		p->buf_len = ksize(p->buf);
-	} else {
-		char *tmp;
-
-		tmp = krealloc(p->buf, len, GFP_NOFS);
-		if (!tmp)
-			return -ENOMEM;
-		p->buf = tmp;
-		p->buf_len = ksize(p->buf);
-	}
+	if (p->buf == p->inline_buf)
+		tmp_buf = kmalloc(len, GFP_NOFS);
+	else
+		tmp_buf = krealloc(p->buf, len, GFP_NOFS);
+	if (!tmp_buf)
+		return -ENOMEM;
+	p->buf = tmp_buf;
+	/*
+	 * The real size of the buffer is bigger, this will let the fast path
+	 * happen most of the time
+	 */
+	p->buf_len = ksize(p->buf);
 
 	if (p->reversed) {
 		tmp_buf = p->buf + old_buf_len - path_len - 1;

commit 1b2782c8ed24db03ad49942fa37c9f196b7c4af3
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Feb 25 19:32:59 2014 +0100

    btrfs: send: fix old buffer length in fs_path_ensure_buf
    
    In "btrfs: send: lower memory requirements in common case" the code to
    save the old_buf_len was incorrectly moved to a wrong place and broke
    the original logic.
    
    Reported-by: Filipe David Manana <fdmanana@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Reviewed-by: Filipe David Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 298e25de13ab..246df8513c8a 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -346,6 +346,9 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 	if (p->buf_len >= len)
 		return 0;
 
+	path_len = p->end - p->start;
+	old_buf_len = p->buf_len;
+
 	/*
 	 * First time the inline_buf does not suffice
 	 */
@@ -368,9 +371,6 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 		p->buf_len = ksize(p->buf);
 	}
 
-	path_len = p->end - p->start;
-	old_buf_len = p->buf_len;
-
 	if (p->reversed) {
 		tmp_buf = p->buf + old_buf_len - path_len - 1;
 		p->end = p->buf + p->buf_len - 1;

commit bf0d1f441d1679136c25e6141dd7e66cc7a14218
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Fri Feb 21 00:01:32 2014 +0000

    Btrfs: fix send issuing outdated paths for utimes, chown and chmod
    
    When doing an incremental send, if we had a directory pending a move/rename
    operation and none of its parents, except for the immediate parent, were
    pending a move/rename, after processing the directory's references, we would
    be issuing utimes, chown and chmod intructions against am outdated path - a
    path which matched the one in the parent root.
    
    This change also simplifies a bit the code that deals with building a path
    for a directory which has a move/rename operation delayed.
    
    Steps to reproduce:
    
        $ mkfs.btrfs -f /dev/sdb3
        $ mount /dev/sdb3 /mnt/btrfs
        $ mkdir -p /mnt/btrfs/a/b/c/d/e
        $ mkdir /mnt/btrfs/a/b/c/f
        $ chmod 0777 /mnt/btrfs/a/b/c/d/e
        $ btrfs subvolume snapshot -r /mnt/btrfs /mnt/btrfs/snap1
        $ btrfs send /mnt/btrfs/snap1 -f /tmp/base.send
        $ mv /mnt/btrfs/a/b/c/f /mnt/btrfs/a/b/f2
        $ mv /mnt/btrfs/a/b/c/d/e /mnt/btrfs/a/b/f2/e2
        $ mv /mnt/btrfs/a/b/c /mnt/btrfs/a/b/c2
        $ mv /mnt/btrfs/a/b/c2/d /mnt/btrfs/a/b/c2/d2
        $ chmod 0700 /mnt/btrfs/a/b/f2/e2
        $ btrfs subvolume snapshot -r /mnt/btrfs /mnt/btrfs/snap2
        $ btrfs send -p /mnt/btrfs/snap1 /mnt/btrfs/snap2 -f /tmp/incremental.send
    
        $ umount /mnt/btrfs
        $ mkfs.btrfs -f /dev/sdb3
        $ mount /dev/sdb3 /mnt/btrfs
        $ btrfs receive /mnt/btrfs -f /tmp/base.send
        $ btrfs receive /mnt/btrfs -f /tmp/incremental.send
    
    The second btrfs receive command failed with:
    
        ERROR: chmod a/b/c/d/e failed. No such file or directory
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 46c6b5442f20..298e25de13ab 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2000,7 +2000,6 @@ static void name_cache_free(struct send_ctx *sctx)
  */
 static int __get_cur_name_and_parent(struct send_ctx *sctx,
 				     u64 ino, u64 gen,
-				     int skip_name_cache,
 				     u64 *parent_ino,
 				     u64 *parent_gen,
 				     struct fs_path *dest)
@@ -2010,8 +2009,6 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	struct btrfs_path *path = NULL;
 	struct name_cache_entry *nce = NULL;
 
-	if (skip_name_cache)
-		goto get_ref;
 	/*
 	 * First check if we already did a call to this function with the same
 	 * ino/gen. If yes, check if the cache entry is still up-to-date. If yes
@@ -2056,12 +2053,11 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 		goto out_cache;
 	}
 
-get_ref:
 	/*
 	 * Depending on whether the inode was already processed or not, use
 	 * send_root or parent_root for ref lookup.
 	 */
-	if (ino < sctx->send_progress && !skip_name_cache)
+	if (ino < sctx->send_progress)
 		ret = get_first_ref(sctx->send_root, ino,
 				    parent_ino, parent_gen, dest);
 	else
@@ -2085,8 +2081,6 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 			goto out;
 		ret = 1;
 	}
-	if (skip_name_cache)
-		goto out;
 
 out_cache:
 	/*
@@ -2154,7 +2148,6 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 	u64 parent_inode = 0;
 	u64 parent_gen = 0;
 	int stop = 0;
-	int skip_name_cache = 0;
 
 	name = fs_path_alloc();
 	if (!name) {
@@ -2162,9 +2155,6 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 		goto out;
 	}
 
-	if (is_waiting_for_move(sctx, ino))
-		skip_name_cache = 1;
-
 	dest->reversed = 1;
 	fs_path_reset(dest);
 
@@ -2179,16 +2169,19 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 			break;
 		}
 
-		ret = __get_cur_name_and_parent(sctx, ino, gen, skip_name_cache,
-				&parent_inode, &parent_gen, name);
+		if (is_waiting_for_move(sctx, ino)) {
+			ret = get_first_ref(sctx->parent_root, ino,
+					    &parent_inode, &parent_gen, name);
+		} else {
+			ret = __get_cur_name_and_parent(sctx, ino, gen,
+							&parent_inode,
+							&parent_gen, name);
+			if (ret)
+				stop = 1;
+		}
+
 		if (ret < 0)
 			goto out;
-		if (ret)
-			stop = 1;
-
-		if (!skip_name_cache &&
-		    is_waiting_for_move(sctx, parent_inode))
-			skip_name_cache = 1;
 
 		ret = fs_path_add_path(dest, name);
 		if (ret < 0)

commit 9dc442143b9874ba677fc83bf8c60744ec642998
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Wed Feb 19 14:31:44 2014 +0000

    Btrfs: fix send attempting to rmdir non-empty directories
    
    The incremental send algorithm assumed that it was possible to issue
    a directory remove (rmdir) if the the inode number it was currently
    processing was greater than (or equal) to any inode that referenced
    the directory's inode. This wasn't a valid assumption because any such
    inode might be a child directory that is pending a move/rename operation,
    because it was moved into a directory that has a higher inode number and
    was moved/renamed too - in other words, the case the following commit
    addressed:
    
        9f03740a956d7ac6a1b8f8c455da6fa5cae11c22
        (Btrfs: fix infinite path build loops in incremental send)
    
    This made an incremental send issue an rmdir operation before the
    target directory was actually empty, which made btrfs receive fail.
    Therefore it needs to wait for all pending child directory inodes to
    be moved/renamed before sending an rmdir operation.
    
    Simple steps to reproduce this issue:
    
        $ mkfs.btrfs -f /dev/sdb3
        $ mount /dev/sdb3 /mnt/btrfs
        $ mkdir -p /mnt/btrfs/a/b/c/x
        $ mkdir /mnt/btrfs/a/b/y
        $ btrfs subvolume snapshot -r /mnt/btrfs /mnt/btrfs/snap1
        $ btrfs send /mnt/btrfs/snap1 -f /tmp/base.send
        $ mv /mnt/btrfs/a/b/y /mnt/btrfs/a/b/YY
        $ mv /mnt/btrfs/a/b/c/x /mnt/btrfs/a/b/YY
        $ rmdir /mnt/btrfs/a/b/c
        $ btrfs subvolume snapshot -r /mnt/btrfs /mnt/btrfs/snap2
        $ btrfs send -p /mnt/btrfs/snap1 /mnt/btrfs/snap2 -f /tmp/incremental.send
    
        $ umount /mnt/btrfs
        $ mkfs.btrfs -f /dev/sdb3
        $ mount /dev/sdb3 /mnt/btrfs
        $ btrfs receive /mnt/btrfs -f /tmp/base.send
        $ btrfs receive /mnt/btrfs -f /tmp/incremental.send
    
    The second btrfs receive command failed with:
    
        ERROR: rmdir o259-6-0 failed. Directory not empty
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index cdfd4357a784..46c6b5442f20 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -178,6 +178,47 @@ struct send_ctx {
 	 * own move/rename can be performed.
 	 */
 	struct rb_root waiting_dir_moves;
+
+	/*
+	 * A directory that is going to be rm'ed might have a child directory
+	 * which is in the pending directory moves index above. In this case,
+	 * the directory can only be removed after the move/rename of its child
+	 * is performed. Example:
+	 *
+	 * Parent snapshot:
+	 *
+	 * .                        (ino 256)
+	 * |-- a/                   (ino 257)
+	 *     |-- b/               (ino 258)
+	 *         |-- c/           (ino 259)
+	 *         |   |-- x/       (ino 260)
+	 *         |
+	 *         |-- y/           (ino 261)
+	 *
+	 * Send snapshot:
+	 *
+	 * .                        (ino 256)
+	 * |-- a/                   (ino 257)
+	 *     |-- b/               (ino 258)
+	 *         |-- YY/          (ino 261)
+	 *              |-- x/      (ino 260)
+	 *
+	 * Sequence of steps that lead to the send snapshot:
+	 * rm -f /a/b/c/foo.txt
+	 * mv /a/b/y /a/b/YY
+	 * mv /a/b/c/x /a/b/YY
+	 * rmdir /a/b/c
+	 *
+	 * When the child is processed, its move/rename is delayed until its
+	 * parent is processed (as explained above), but all other operations
+	 * like update utimes, chown, chgrp, etc, are performed and the paths
+	 * that it uses for those operations must use the orphanized name of
+	 * its parent (the directory we're going to rm later), so we need to
+	 * memorize that name.
+	 *
+	 * Indexed by the inode number of the directory to be deleted.
+	 */
+	struct rb_root orphan_dirs;
 };
 
 struct pending_dir_move {
@@ -192,6 +233,18 @@ struct pending_dir_move {
 struct waiting_dir_move {
 	struct rb_node node;
 	u64 ino;
+	/*
+	 * There might be some directory that could not be removed because it
+	 * was waiting for this directory inode to be moved first. Therefore
+	 * after this directory is moved, we can try to rmdir the ino rmdir_ino.
+	 */
+	u64 rmdir_ino;
+};
+
+struct orphan_dir_info {
+	struct rb_node node;
+	u64 ino;
+	u64 gen;
 };
 
 struct name_cache_entry {
@@ -217,6 +270,11 @@ struct name_cache_entry {
 
 static int is_waiting_for_move(struct send_ctx *sctx, u64 ino);
 
+static struct waiting_dir_move *
+get_waiting_dir_move(struct send_ctx *sctx, u64 ino);
+
+static int is_waiting_for_rm(struct send_ctx *sctx, u64 dir_ino);
+
 static int need_send_hole(struct send_ctx *sctx)
 {
 	return (sctx->parent_root && !sctx->cur_inode_new &&
@@ -2113,6 +2171,14 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 	while (!stop && ino != BTRFS_FIRST_FREE_OBJECTID) {
 		fs_path_reset(name);
 
+		if (is_waiting_for_rm(sctx, ino)) {
+			ret = gen_unique_name(sctx, ino, gen, name);
+			if (ret < 0)
+				goto out;
+			ret = fs_path_add_path(dest, name);
+			break;
+		}
+
 		ret = __get_cur_name_and_parent(sctx, ino, gen, skip_name_cache,
 				&parent_inode, &parent_gen, name);
 		if (ret < 0)
@@ -2641,12 +2707,78 @@ static int orphanize_inode(struct send_ctx *sctx, u64 ino, u64 gen,
 	return ret;
 }
 
+static struct orphan_dir_info *
+add_orphan_dir_info(struct send_ctx *sctx, u64 dir_ino)
+{
+	struct rb_node **p = &sctx->orphan_dirs.rb_node;
+	struct rb_node *parent = NULL;
+	struct orphan_dir_info *entry, *odi;
+
+	odi = kmalloc(sizeof(*odi), GFP_NOFS);
+	if (!odi)
+		return ERR_PTR(-ENOMEM);
+	odi->ino = dir_ino;
+	odi->gen = 0;
+
+	while (*p) {
+		parent = *p;
+		entry = rb_entry(parent, struct orphan_dir_info, node);
+		if (dir_ino < entry->ino) {
+			p = &(*p)->rb_left;
+		} else if (dir_ino > entry->ino) {
+			p = &(*p)->rb_right;
+		} else {
+			kfree(odi);
+			return entry;
+		}
+	}
+
+	rb_link_node(&odi->node, parent, p);
+	rb_insert_color(&odi->node, &sctx->orphan_dirs);
+	return odi;
+}
+
+static struct orphan_dir_info *
+get_orphan_dir_info(struct send_ctx *sctx, u64 dir_ino)
+{
+	struct rb_node *n = sctx->orphan_dirs.rb_node;
+	struct orphan_dir_info *entry;
+
+	while (n) {
+		entry = rb_entry(n, struct orphan_dir_info, node);
+		if (dir_ino < entry->ino)
+			n = n->rb_left;
+		else if (dir_ino > entry->ino)
+			n = n->rb_right;
+		else
+			return entry;
+	}
+	return NULL;
+}
+
+static int is_waiting_for_rm(struct send_ctx *sctx, u64 dir_ino)
+{
+	struct orphan_dir_info *odi = get_orphan_dir_info(sctx, dir_ino);
+
+	return odi != NULL;
+}
+
+static void free_orphan_dir_info(struct send_ctx *sctx,
+				 struct orphan_dir_info *odi)
+{
+	if (!odi)
+		return;
+	rb_erase(&odi->node, &sctx->orphan_dirs);
+	kfree(odi);
+}
+
 /*
  * Returns 1 if a directory can be removed at this point in time.
  * We check this by iterating all dir items and checking if the inode behind
  * the dir item was already processed.
  */
-static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
+static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 dir_gen,
+		     u64 send_progress)
 {
 	int ret = 0;
 	struct btrfs_root *root = sctx->parent_root;
@@ -2674,6 +2806,8 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
 		goto out;
 
 	while (1) {
+		struct waiting_dir_move *dm;
+
 		if (path->slots[0] >= btrfs_header_nritems(path->nodes[0])) {
 			ret = btrfs_next_leaf(root, path);
 			if (ret < 0)
@@ -2692,6 +2826,21 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
 				struct btrfs_dir_item);
 		btrfs_dir_item_key_to_cpu(path->nodes[0], di, &loc);
 
+		dm = get_waiting_dir_move(sctx, loc.objectid);
+		if (dm) {
+			struct orphan_dir_info *odi;
+
+			odi = add_orphan_dir_info(sctx, dir);
+			if (IS_ERR(odi)) {
+				ret = PTR_ERR(odi);
+				goto out;
+			}
+			odi->gen = dir_gen;
+			dm->rmdir_ino = dir;
+			ret = 0;
+			goto out;
+		}
+
 		if (loc.objectid > send_progress) {
 			ret = 0;
 			goto out;
@@ -2709,19 +2858,9 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
 
 static int is_waiting_for_move(struct send_ctx *sctx, u64 ino)
 {
-	struct rb_node *n = sctx->waiting_dir_moves.rb_node;
-	struct waiting_dir_move *entry;
+	struct waiting_dir_move *entry = get_waiting_dir_move(sctx, ino);
 
-	while (n) {
-		entry = rb_entry(n, struct waiting_dir_move, node);
-		if (ino < entry->ino)
-			n = n->rb_left;
-		else if (ino > entry->ino)
-			n = n->rb_right;
-		else
-			return 1;
-	}
-	return 0;
+	return entry != NULL;
 }
 
 static int add_waiting_dir_move(struct send_ctx *sctx, u64 ino)
@@ -2734,6 +2873,7 @@ static int add_waiting_dir_move(struct send_ctx *sctx, u64 ino)
 	if (!dm)
 		return -ENOMEM;
 	dm->ino = ino;
+	dm->rmdir_ino = 0;
 
 	while (*p) {
 		parent = *p;
@@ -2753,24 +2893,31 @@ static int add_waiting_dir_move(struct send_ctx *sctx, u64 ino)
 	return 0;
 }
 
-static int del_waiting_dir_move(struct send_ctx *sctx, u64 ino)
+static struct waiting_dir_move *
+get_waiting_dir_move(struct send_ctx *sctx, u64 ino)
 {
 	struct rb_node *n = sctx->waiting_dir_moves.rb_node;
 	struct waiting_dir_move *entry;
 
 	while (n) {
 		entry = rb_entry(n, struct waiting_dir_move, node);
-		if (ino < entry->ino) {
+		if (ino < entry->ino)
 			n = n->rb_left;
-		} else if (ino > entry->ino) {
+		else if (ino > entry->ino)
 			n = n->rb_right;
-		} else {
-			rb_erase(&entry->node, &sctx->waiting_dir_moves);
-			kfree(entry);
-			return 0;
-		}
+		else
+			return entry;
 	}
-	return -ENOENT;
+	return NULL;
+}
+
+static void free_waiting_dir_move(struct send_ctx *sctx,
+				  struct waiting_dir_move *dm)
+{
+	if (!dm)
+		return;
+	rb_erase(&dm->node, &sctx->waiting_dir_moves);
+	kfree(dm);
 }
 
 static int add_pending_dir_move(struct send_ctx *sctx, u64 parent_ino)
@@ -2861,6 +3008,8 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	u64 orig_progress = sctx->send_progress;
 	struct recorded_ref *cur;
 	u64 parent_ino, parent_gen;
+	struct waiting_dir_move *dm = NULL;
+	u64 rmdir_ino = 0;
 	int ret;
 
 	name = fs_path_alloc();
@@ -2870,8 +3019,10 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 		goto out;
 	}
 
-	ret = del_waiting_dir_move(sctx, pm->ino);
-	ASSERT(ret == 0);
+	dm = get_waiting_dir_move(sctx, pm->ino);
+	ASSERT(dm);
+	rmdir_ino = dm->rmdir_ino;
+	free_waiting_dir_move(sctx, dm);
 
 	ret = get_first_ref(sctx->parent_root, pm->ino,
 			    &parent_ino, &parent_gen, name);
@@ -2914,6 +3065,35 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	if (ret < 0)
 		goto out;
 
+	if (rmdir_ino) {
+		struct orphan_dir_info *odi;
+
+		odi = get_orphan_dir_info(sctx, rmdir_ino);
+		if (!odi) {
+			/* already deleted */
+			goto finish;
+		}
+		ret = can_rmdir(sctx, rmdir_ino, odi->gen, sctx->cur_ino + 1);
+		if (ret < 0)
+			goto out;
+		if (!ret)
+			goto finish;
+
+		name = fs_path_alloc();
+		if (!name) {
+			ret = -ENOMEM;
+			goto out;
+		}
+		ret = get_cur_path(sctx, rmdir_ino, odi->gen, name);
+		if (ret < 0)
+			goto out;
+		ret = send_rmdir(sctx, name);
+		if (ret < 0)
+			goto out;
+		free_orphan_dir_info(sctx, odi);
+	}
+
+finish:
 	ret = send_utimes(sctx, pm->ino, pm->gen);
 	if (ret < 0)
 		goto out;
@@ -2923,6 +3103,8 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	 * and old parent(s).
 	 */
 	list_for_each_entry(cur, &pm->update_refs, list) {
+		if (cur->dir == rmdir_ino)
+			continue;
 		ret = send_utimes(sctx, cur->dir, cur->dir_gen);
 		if (ret < 0)
 			goto out;
@@ -3259,7 +3441,8 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 		 * later, we do this check again and rmdir it then if possible.
 		 * See the use of check_dirs for more details.
 		 */
-		ret = can_rmdir(sctx, sctx->cur_ino, sctx->cur_ino);
+		ret = can_rmdir(sctx, sctx->cur_ino, sctx->cur_inode_gen,
+				sctx->cur_ino);
 		if (ret < 0)
 			goto out;
 		if (ret) {
@@ -3352,7 +3535,8 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 				goto out;
 		} else if (ret == inode_state_did_delete &&
 			   cur->dir != last_dir_ino_rm) {
-			ret = can_rmdir(sctx, cur->dir, sctx->cur_ino);
+			ret = can_rmdir(sctx, cur->dir, cur->dir_gen,
+					sctx->cur_ino);
 			if (ret < 0)
 				goto out;
 			if (ret) {
@@ -5389,6 +5573,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 
 	sctx->pending_dir_moves = RB_ROOT;
 	sctx->waiting_dir_moves = RB_ROOT;
+	sctx->orphan_dirs = RB_ROOT;
 
 	sctx->clone_roots = vzalloc(sizeof(struct clone_root) *
 			(arg->clone_sources_count + 1));
@@ -5526,6 +5711,16 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		kfree(dm);
 	}
 
+	WARN_ON(sctx && !ret && !RB_EMPTY_ROOT(&sctx->orphan_dirs));
+	while (sctx && !RB_EMPTY_ROOT(&sctx->orphan_dirs)) {
+		struct rb_node *n;
+		struct orphan_dir_info *odi;
+
+		n = rb_first(&sctx->orphan_dirs);
+		odi = rb_entry(n, struct orphan_dir_info, node);
+		free_orphan_dir_info(sctx, odi);
+	}
+
 	if (sort_clone_roots) {
 		for (i = 0; i < sctx->clone_roots_cnt; i++)
 			btrfs_root_dec_send_in_progress(

commit 29d6d30f5c8aa58b04f40a58442df3bcaae5a1d5
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Sun Feb 16 21:01:39 2014 +0000

    Btrfs: send, don't send rmdir for same target multiple times
    
    When doing an incremental send, if we delete a directory that has N > 1
    hardlinks for the same file and that file has the highest inode number
    inside the directory contents, an incremental send would send N times an
    rmdir operation against the directory. This made the btrfs receive command
    fail on the second rmdir instruction, as the target directory didn't exist
    anymore.
    
    Steps to reproduce the issue:
    
        $ mkfs.btrfs -f /dev/sdb3
        $ mount /dev/sdb3 /mnt/btrfs
        $ mkdir -p /mnt/btrfs/a/b/c
        $ echo 'ola mundo' > /mnt/btrfs/a/b/c/foo.txt
        $ ln /mnt/btrfs/a/b/c/foo.txt /mnt/btrfs/a/b/c/bar.txt
        $ btrfs subvolume snapshot -r /mnt/btrfs /mnt/btrfs/snap1
        $ btrfs send /mnt/btrfs/snap1 -f /tmp/base.send
        $ rm -f /mnt/btrfs/a/b/c/foo.txt
        $ rm -f /mnt/btrfs/a/b/c/bar.txt
        $ rmdir /mnt/btrfs/a/b/c
        $ btrfs subvolume snapshot -r /mnt/btrfs /mnt/btrfs/snap2
        $ btrfs send -p /mnt/btrfs/snap1 /mnt/btrfs/snap2 -f /tmp/incremental.send
    
        $ umount /mnt/btrfs
        $ mkfs.btrfs -f /dev/sdb3
        $ mount /dev/sdb3 /mnt/btrfs
        $ btrfs receive /mnt/btrfs -f /tmp/base.send
        $ btrfs receive /mnt/btrfs -f /tmp/incremental.send
    
    The second btrfs receive command failed with:
    
        ERROR: rmdir o259-6-0 failed. No such file or directory
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index cb9502adccdc..cdfd4357a784 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3085,6 +3085,7 @@ static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 	u64 ow_gen;
 	int did_overwrite = 0;
 	int is_orphan = 0;
+	u64 last_dir_ino_rm = 0;
 
 verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 
@@ -3349,7 +3350,8 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 			ret = send_utimes(sctx, cur->dir, cur->dir_gen);
 			if (ret < 0)
 				goto out;
-		} else if (ret == inode_state_did_delete) {
+		} else if (ret == inode_state_did_delete &&
+			   cur->dir != last_dir_ino_rm) {
 			ret = can_rmdir(sctx, cur->dir, sctx->cur_ino);
 			if (ret < 0)
 				goto out;
@@ -3361,6 +3363,7 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 				ret = send_rmdir(sctx, valid_path);
 				if (ret < 0)
 					goto out;
+				last_dir_ino_rm = cur->dir;
 			}
 		}
 	}

commit 2b863a135f22f242ba4fc669f3a6b2f6c826832c
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Sun Feb 16 13:43:11 2014 +0000

    Btrfs: incremental send, fix invalid path after dir rename
    
    This fixes yet one more case not caught by the commit titled:
    
       Btrfs: fix infinite path build loops in incremental send
    
    In this case, even before the initial full send, we have a directory
    which is a child of a directory with a higher inode number. Then we
    perform the initial send, and after we rename both the child and the
    parent, without moving them around. After doing these 2 renames, an
    incremental send sent a rename instruction for the child directory
    which contained an invalid "from" path (referenced the parent's old
    name, not the new one), which made the btrfs receive command fail.
    
    Steps to reproduce:
    
        $ mkfs.btrfs -f /dev/sdb3
        $ mount /dev/sdb3 /mnt/btrfs
        $ mkdir -p /mnt/btrfs/a/b
        $ mkdir /mnt/btrfs/d
        $ mkdir /mnt/btrfs/a/b/c
        $ mv /mnt/btrfs/d /mnt/btrfs/a/b/c
        $ btrfs subvolume snapshot -r /mnt/btrfs /mnt/btrfs/snap1
        $ btrfs send /mnt/btrfs/snap1 -f /tmp/base.send
        $ mv /mnt/btrfs/a/b/c /mnt/btrfs/a/b/x
        $ mv /mnt/btrfs/a/b/x/d /mnt/btrfs/a/b/x/y
        $ btrfs subvolume snapshot -r /mnt/btrfs /mnt/btrfs/snap2
        $ btrfs send -p /mnt/btrfs/snap1 /mnt/btrfs/snap2 -f /tmp/incremental.send
    
        $ umout /mnt/btrfs
        $ mkfs.btrfs -f /dev/sdb3
        $ mount /dev/sdb3 /mnt/btrfs
        $ btrfs receive /mnt/btrfs -f /tmp/base.send
        $ btrfs receive /mnt/btrfs -f /tmp/incremental.send
    
    The second btrfs receive command failed with:
      "ERROR: rename a/b/c/d -> a/b/x/y failed. No such file or directory"
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 3ddd2bb75083..cb9502adccdc 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2857,19 +2857,48 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 {
 	struct fs_path *from_path = NULL;
 	struct fs_path *to_path = NULL;
+	struct fs_path *name = NULL;
 	u64 orig_progress = sctx->send_progress;
 	struct recorded_ref *cur;
+	u64 parent_ino, parent_gen;
 	int ret;
 
+	name = fs_path_alloc();
 	from_path = fs_path_alloc();
-	if (!from_path)
-		return -ENOMEM;
+	if (!name || !from_path) {
+		ret = -ENOMEM;
+		goto out;
+	}
 
-	sctx->send_progress = pm->ino;
-	ret = get_cur_path(sctx, pm->ino, pm->gen, from_path);
+	ret = del_waiting_dir_move(sctx, pm->ino);
+	ASSERT(ret == 0);
+
+	ret = get_first_ref(sctx->parent_root, pm->ino,
+			    &parent_ino, &parent_gen, name);
 	if (ret < 0)
 		goto out;
 
+	if (parent_ino == sctx->cur_ino) {
+		/* child only renamed, not moved */
+		ASSERT(parent_gen == sctx->cur_inode_gen);
+		ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen,
+				   from_path);
+		if (ret < 0)
+			goto out;
+		ret = fs_path_add_path(from_path, name);
+		if (ret < 0)
+			goto out;
+	} else {
+		/* child moved and maybe renamed too */
+		sctx->send_progress = pm->ino;
+		ret = get_cur_path(sctx, pm->ino, pm->gen, from_path);
+		if (ret < 0)
+			goto out;
+	}
+
+	fs_path_free(name);
+	name = NULL;
+
 	to_path = fs_path_alloc();
 	if (!to_path) {
 		ret = -ENOMEM;
@@ -2877,9 +2906,6 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	}
 
 	sctx->send_progress = sctx->cur_ino + 1;
-	ret = del_waiting_dir_move(sctx, pm->ino);
-	ASSERT(ret == 0);
-
 	ret = get_cur_path(sctx, pm->ino, pm->gen, to_path);
 	if (ret < 0)
 		goto out;
@@ -2903,6 +2929,7 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	}
 
 out:
+	fs_path_free(name);
 	fs_path_free(from_path);
 	fs_path_free(to_path);
 	sctx->send_progress = orig_progress;

commit dcfd5ad2fc3337a959873e9d20ca33ad9809aa90
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Sat Feb 8 23:46:36 2014 +0800

    Revert "Btrfs: remove transaction from btrfs send"
    
    This reverts commit 41ce9970a8a6a362ae8df145f7a03d789e9ef9d2.
    Previously i was thinking we can use readonly root's commit root
    safely while it is not true, readonly root may be cowed with the
    following cases.
    
    1.snapshot send root will cow source root.
    2.balance,device operations will also cow readonly send root
    to relocate.
    
    So i have two ideas to make us safe to use commit root.
    
    -->approach 1:
    make it protected by transaction and end transaction properly and we research
    next item from root node(see btrfs_search_slot_for_read()).
    
    -->approach 2:
    add another counter to local root structure to sync snapshot with send.
    and add a global counter to sync send with exclusive device operations.
    
    So with approach 2, send can use commit root safely, because we make sure
    send root can not be cowed during send. Unfortunately, it make codes *ugly*
    and more complex to maintain.
    
    To make snapshot and send exclusively, device operations and send operation
    exclusively with each other is a little confusing for common users.
    
    So why not drop into previous way.
    
    Cc: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a5da82f49120..3ddd2bb75083 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -5104,6 +5104,7 @@ static int changed_cb(struct btrfs_root *left_root,
 static int full_send_tree(struct send_ctx *sctx)
 {
 	int ret;
+	struct btrfs_trans_handle *trans = NULL;
 	struct btrfs_root *send_root = sctx->send_root;
 	struct btrfs_key key;
 	struct btrfs_key found_key;
@@ -5125,6 +5126,19 @@ static int full_send_tree(struct send_ctx *sctx)
 	key.type = BTRFS_INODE_ITEM_KEY;
 	key.offset = 0;
 
+join_trans:
+	/*
+	 * We need to make sure the transaction does not get committed
+	 * while we do anything on commit roots. Join a transaction to prevent
+	 * this.
+	 */
+	trans = btrfs_join_transaction(send_root);
+	if (IS_ERR(trans)) {
+		ret = PTR_ERR(trans);
+		trans = NULL;
+		goto out;
+	}
+
 	/*
 	 * Make sure the tree has not changed after re-joining. We detect this
 	 * by comparing start_ctransid and ctransid. They should always match.
@@ -5148,6 +5162,19 @@ static int full_send_tree(struct send_ctx *sctx)
 		goto out_finish;
 
 	while (1) {
+		/*
+		 * When someone want to commit while we iterate, end the
+		 * joined transaction and rejoin.
+		 */
+		if (btrfs_should_end_transaction(trans, send_root)) {
+			ret = btrfs_end_transaction(trans, send_root);
+			trans = NULL;
+			if (ret < 0)
+				goto out;
+			btrfs_release_path(path);
+			goto join_trans;
+		}
+
 		eb = path->nodes[0];
 		slot = path->slots[0];
 		btrfs_item_key_to_cpu(eb, &found_key, slot);
@@ -5175,6 +5202,12 @@ static int full_send_tree(struct send_ctx *sctx)
 
 out:
 	btrfs_free_path(path);
+	if (trans) {
+		if (!ret)
+			ret = btrfs_end_transaction(trans, send_root);
+		else
+			btrfs_end_transaction(trans, send_root);
+	}
 	return ret;
 }
 

commit ace0105076a493c04e6d5e91e6a19f222d6b3875
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Feb 5 16:17:34 2014 +0100

    btrfs: send: lower memory requirements in common case
    
    The fs_path structure uses an inline buffer and falls back to a chain of
    allocations, but vmalloc is not necessary because PATH_MAX fits into
    PAGE_SIZE.
    
    The size of fs_path has been reduced to 256 bytes from PAGE_SIZE,
    usually 4k. Experimental measurements show that most paths on a single
    filesystem do not exceed 200 bytes, and these get stored into the inline
    buffer directly, which is now 230 bytes. Longer paths are kmalloced when
    needed.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a2621e7aaa5c..a5da82f49120 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -57,7 +57,12 @@ struct fs_path {
 			unsigned short reversed:1;
 			char inline_buf[];
 		};
-		char pad[PAGE_SIZE];
+		/*
+		 * Average path length does not exceed 200 bytes, we'll have
+		 * better packing in the slab and higher chance to satisfy
+		 * a allocation later during send.
+		 */
+		char pad[256];
 	};
 };
 #define FS_PATH_INLINE_SIZE \
@@ -262,12 +267,8 @@ static void fs_path_free(struct fs_path *p)
 {
 	if (!p)
 		return;
-	if (p->buf != p->inline_buf) {
-		if (is_vmalloc_addr(p->buf))
-			vfree(p->buf);
-		else
-			kfree(p->buf);
-	}
+	if (p->buf != p->inline_buf)
+		kfree(p->buf);
 	kfree(p);
 }
 
@@ -287,40 +288,31 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 	if (p->buf_len >= len)
 		return 0;
 
-	path_len = p->end - p->start;
-	old_buf_len = p->buf_len;
-	len = PAGE_ALIGN(len);
-
+	/*
+	 * First time the inline_buf does not suffice
+	 */
 	if (p->buf == p->inline_buf) {
-		tmp_buf = kmalloc(len, GFP_NOFS | __GFP_NOWARN);
-		if (!tmp_buf) {
-			tmp_buf = vmalloc(len);
-			if (!tmp_buf)
-				return -ENOMEM;
-		}
-		memcpy(tmp_buf, p->buf, p->buf_len);
-		p->buf = tmp_buf;
-		p->buf_len = len;
+		p->buf = kmalloc(len, GFP_NOFS);
+		if (!p->buf)
+			return -ENOMEM;
+		/*
+		 * The real size of the buffer is bigger, this will let the
+		 * fast path happen most of the time
+		 */
+		p->buf_len = ksize(p->buf);
 	} else {
-		if (is_vmalloc_addr(p->buf)) {
-			tmp_buf = vmalloc(len);
-			if (!tmp_buf)
-				return -ENOMEM;
-			memcpy(tmp_buf, p->buf, p->buf_len);
-			vfree(p->buf);
-		} else {
-			tmp_buf = krealloc(p->buf, len, GFP_NOFS);
-			if (!tmp_buf) {
-				tmp_buf = vmalloc(len);
-				if (!tmp_buf)
-					return -ENOMEM;
-				memcpy(tmp_buf, p->buf, p->buf_len);
-				kfree(p->buf);
-			}
-		}
-		p->buf = tmp_buf;
-		p->buf_len = len;
+		char *tmp;
+
+		tmp = krealloc(p->buf, len, GFP_NOFS);
+		if (!tmp)
+			return -ENOMEM;
+		p->buf = tmp;
+		p->buf_len = ksize(p->buf);
 	}
+
+	path_len = p->end - p->start;
+	old_buf_len = p->buf_len;
+
 	if (p->reversed) {
 		tmp_buf = p->buf + old_buf_len - path_len - 1;
 		p->end = p->buf + p->buf_len - 1;
@@ -911,9 +903,7 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 	struct btrfs_dir_item *di;
 	struct btrfs_key di_key;
 	char *buf = NULL;
-	char *buf2 = NULL;
-	int buf_len;
-	int buf_virtual = 0;
+	const int buf_len = PATH_MAX;
 	u32 name_len;
 	u32 data_len;
 	u32 cur;
@@ -923,7 +913,6 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 	int num;
 	u8 type;
 
-	buf_len = PAGE_SIZE;
 	buf = kmalloc(buf_len, GFP_NOFS);
 	if (!buf) {
 		ret = -ENOMEM;
@@ -945,30 +934,12 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 		type = btrfs_dir_type(eb, di);
 		btrfs_dir_item_key_to_cpu(eb, di, &di_key);
 
+		/*
+		 * Path too long
+		 */
 		if (name_len + data_len > buf_len) {
-			buf_len = PAGE_ALIGN(name_len + data_len);
-			if (buf_virtual) {
-				buf2 = vmalloc(buf_len);
-				if (!buf2) {
-					ret = -ENOMEM;
-					goto out;
-				}
-				vfree(buf);
-			} else {
-				buf2 = krealloc(buf, buf_len, GFP_NOFS);
-				if (!buf2) {
-					buf2 = vmalloc(buf_len);
-					if (!buf2) {
-						ret = -ENOMEM;
-						goto out;
-					}
-					kfree(buf);
-					buf_virtual = 1;
-				}
-			}
-
-			buf = buf2;
-			buf2 = NULL;
+			ret = -ENAMETOOLONG;
+			goto out;
 		}
 
 		read_extent_buffer(eb, buf, (unsigned long)(di + 1),
@@ -991,10 +962,7 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 	}
 
 out:
-	if (buf_virtual)
-		vfree(buf);
-	else
-		kfree(buf);
+	kfree(buf);
 	return ret;
 }
 

commit dff6d0adbe998927f72fc8d9ceee8ff72b124328
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Wed Feb 5 16:48:56 2014 +0000

    Btrfs: make some tree searches in send.c more efficient
    
    We have this pattern where we do search for a contiguous group of
    items in a tree and everytime we find an item, we process it, then
    we release our path, increment the offset of the search key, do
    another full tree search and repeat these steps until a tree search
    can't find more items we're interested in.
    
    Instead of doing these full tree searches after processing each item,
    just process the next item/slot in our leaf and don't release the path.
    Since all these trees are read only and we always use the commit root
    for a search and skip node/leaf locks, we're not affecting concurrency
    on the trees.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 89fefbd955f3..a2621e7aaa5c 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2501,17 +2501,26 @@ static int did_create_dir(struct send_ctx *sctx, u64 dir)
 	key.objectid = dir;
 	key.type = BTRFS_DIR_INDEX_KEY;
 	key.offset = 0;
+	ret = btrfs_search_slot(NULL, sctx->send_root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
+
 	while (1) {
-		ret = btrfs_search_slot_for_read(sctx->send_root, &key, path,
-				1, 0);
-		if (ret < 0)
-			goto out;
-		if (!ret) {
-			eb = path->nodes[0];
-			slot = path->slots[0];
-			btrfs_item_key_to_cpu(eb, &found_key, slot);
+		eb = path->nodes[0];
+		slot = path->slots[0];
+		if (slot >= btrfs_header_nritems(eb)) {
+			ret = btrfs_next_leaf(sctx->send_root, path);
+			if (ret < 0) {
+				goto out;
+			} else if (ret > 0) {
+				ret = 0;
+				break;
+			}
+			continue;
 		}
-		if (ret || found_key.objectid != key.objectid ||
+
+		btrfs_item_key_to_cpu(eb, &found_key, slot);
+		if (found_key.objectid != key.objectid ||
 		    found_key.type != key.type) {
 			ret = 0;
 			goto out;
@@ -2526,8 +2535,7 @@ static int did_create_dir(struct send_ctx *sctx, u64 dir)
 			goto out;
 		}
 
-		key.offset = found_key.offset + 1;
-		btrfs_release_path(path);
+		path->slots[0]++;
 	}
 
 out:
@@ -2693,19 +2701,24 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
 	key.objectid = dir;
 	key.type = BTRFS_DIR_INDEX_KEY;
 	key.offset = 0;
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
 
 	while (1) {
-		ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
-		if (ret < 0)
-			goto out;
-		if (!ret) {
-			btrfs_item_key_to_cpu(path->nodes[0], &found_key,
-					path->slots[0]);
+		if (path->slots[0] >= btrfs_header_nritems(path->nodes[0])) {
+			ret = btrfs_next_leaf(root, path);
+			if (ret < 0)
+				goto out;
+			else if (ret > 0)
+				break;
+			continue;
 		}
-		if (ret || found_key.objectid != key.objectid ||
-		    found_key.type != key.type) {
+		btrfs_item_key_to_cpu(path->nodes[0], &found_key,
+				      path->slots[0]);
+		if (found_key.objectid != key.objectid ||
+		    found_key.type != key.type)
 			break;
-		}
 
 		di = btrfs_item_ptr(path->nodes[0], path->slots[0],
 				struct btrfs_dir_item);
@@ -2716,8 +2729,7 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
 			goto out;
 		}
 
-		btrfs_release_path(path);
-		key.offset = found_key.offset + 1;
+		path->slots[0]++;
 	}
 
 	ret = 1;
@@ -3620,15 +3632,22 @@ static int process_all_refs(struct send_ctx *sctx,
 	key.objectid = sctx->cmp_key->objectid;
 	key.type = BTRFS_INODE_REF_KEY;
 	key.offset = 0;
-	while (1) {
-		ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
-		if (ret < 0)
-			goto out;
-		if (ret)
-			break;
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
 
+	while (1) {
 		eb = path->nodes[0];
 		slot = path->slots[0];
+		if (slot >= btrfs_header_nritems(eb)) {
+			ret = btrfs_next_leaf(root, path);
+			if (ret < 0)
+				goto out;
+			else if (ret > 0)
+				break;
+			continue;
+		}
+
 		btrfs_item_key_to_cpu(eb, &found_key, slot);
 
 		if (found_key.objectid != key.objectid ||
@@ -3637,11 +3656,10 @@ static int process_all_refs(struct send_ctx *sctx,
 			break;
 
 		ret = iterate_inode_ref(root, path, &found_key, 0, cb, sctx);
-		btrfs_release_path(path);
 		if (ret < 0)
 			goto out;
 
-		key.offset = found_key.offset + 1;
+		path->slots[0]++;
 	}
 	btrfs_release_path(path);
 
@@ -3922,19 +3940,25 @@ static int process_all_new_xattrs(struct send_ctx *sctx)
 	key.objectid = sctx->cmp_key->objectid;
 	key.type = BTRFS_XATTR_ITEM_KEY;
 	key.offset = 0;
-	while (1) {
-		ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
-		if (ret < 0)
-			goto out;
-		if (ret) {
-			ret = 0;
-			goto out;
-		}
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
 
+	while (1) {
 		eb = path->nodes[0];
 		slot = path->slots[0];
-		btrfs_item_key_to_cpu(eb, &found_key, slot);
+		if (slot >= btrfs_header_nritems(eb)) {
+			ret = btrfs_next_leaf(root, path);
+			if (ret < 0) {
+				goto out;
+			} else if (ret > 0) {
+				ret = 0;
+				break;
+			}
+			continue;
+		}
 
+		btrfs_item_key_to_cpu(eb, &found_key, slot);
 		if (found_key.objectid != key.objectid ||
 		    found_key.type != key.type) {
 			ret = 0;
@@ -3946,8 +3970,7 @@ static int process_all_new_xattrs(struct send_ctx *sctx)
 		if (ret < 0)
 			goto out;
 
-		btrfs_release_path(path);
-		key.offset = found_key.offset + 1;
+		path->slots[0]++;
 	}
 
 out:

commit a0859c0998605d2dc1b021543398cd84a40589db
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Wed Feb 5 16:48:55 2014 +0000

    Btrfs: use right extent item position in send when finding extent clones
    
    This was a leftover from the commit:
    
       74dd17fbe3d65829e75d84f00a9525b2ace93998
       (Btrfs: fix btrfs send for inline items and compression)
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index bef7ba638dee..89fefbd955f3 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1288,8 +1288,6 @@ static int find_extent_clone(struct send_ctx *sctx,
 		extent_item_pos = logical - found_key.objectid;
 	else
 		extent_item_pos = 0;
-
-	extent_item_pos = logical - found_key.objectid;
 	ret = iterate_extent_inodes(sctx->send_root->fs_info,
 					found_key.objectid, extent_item_pos, 1,
 					__iterate_backrefs, backref_ctx);

commit 57fb8910c24004ec924103c9a8c8542119f7629a
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Feb 3 19:24:40 2014 +0100

    btrfs: send: remove BUG_ON from name_cache_delete
    
    If cleaning the name cache fails, we could try to proceed at the cost of
    some memory leak. This is not expected to happen often.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d3ed9df77422..bef7ba638dee 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1890,13 +1890,20 @@ static void name_cache_delete(struct send_ctx *sctx,
 
 	nce_head = radix_tree_lookup(&sctx->name_cache,
 			(unsigned long)nce->ino);
-	BUG_ON(!nce_head);
+	if (!nce_head) {
+		btrfs_err(sctx->send_root->fs_info,
+	      "name_cache_delete lookup failed ino %llu cache size %d, leaking memory",
+			nce->ino, sctx->name_cache_size);
+	}
 
 	list_del(&nce->radix_list);
 	list_del(&nce->list);
 	sctx->name_cache_size--;
 
-	if (list_empty(nce_head)) {
+	/*
+	 * We may not get to the final release of nce_head if the lookup fails
+	 */
+	if (nce_head && list_empty(nce_head)) {
 		radix_tree_delete(&sctx->name_cache, (unsigned long)nce->ino);
 		kfree(nce_head);
 	}

commit 4d1a63b21b4f77a82efe7d78fc1ae1cc7532691c
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Feb 3 19:24:19 2014 +0100

    btrfs: send: remove BUG from process_all_refs
    
    There are only 2 static callers, the BUG would normally be never
    reached, but let's be nice.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 4405aae05281..d3ed9df77422 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3606,7 +3606,10 @@ static int process_all_refs(struct send_ctx *sctx,
 		root = sctx->parent_root;
 		cb = __record_deleted_ref;
 	} else {
-		BUG();
+		btrfs_err(sctx->send_root->fs_info,
+				"Wrong command %d in process_all_refs", cmd);
+		ret = -EINVAL;
+		goto out;
 	}
 
 	key.objectid = sctx->cmp_key->objectid;

commit 1f5a7ff999523e9996befbe03e196eb73370fe36
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Feb 3 19:23:47 2014 +0100

    btrfs: send: squeeze bitfilelds in fs_path
    
    We know that buf_len is at most PATH_MAX, 4k, and can merge it with the
    reversed member. This saves 3 bytes in favor of inline_buf.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 5b9b82b32cde..4405aae05281 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -53,8 +53,8 @@ struct fs_path {
 			char *end;
 
 			char *buf;
-			int buf_len;
-			unsigned int reversed:1;
+			unsigned short buf_len:15;
+			unsigned short reversed:1;
 			char inline_buf[];
 		};
 		char pad[PAGE_SIZE];

commit e25a8122061edcde6175cbcfd2e21367ad017212
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Feb 3 19:23:33 2014 +0100

    btrfs: send: remove virtual_mem member from fs_path
    
    We don't need to keep track of that, it's available via is_vmalloc_addr.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 851ebfd43aa7..5b9b82b32cde 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -55,7 +55,6 @@ struct fs_path {
 			char *buf;
 			int buf_len;
 			unsigned int reversed:1;
-			unsigned int virtual_mem:1;
 			char inline_buf[];
 		};
 		char pad[PAGE_SIZE];
@@ -241,7 +240,6 @@ static struct fs_path *fs_path_alloc(void)
 	if (!p)
 		return NULL;
 	p->reversed = 0;
-	p->virtual_mem = 0;
 	p->buf = p->inline_buf;
 	p->buf_len = FS_PATH_INLINE_SIZE;
 	fs_path_reset(p);
@@ -265,7 +263,7 @@ static void fs_path_free(struct fs_path *p)
 	if (!p)
 		return;
 	if (p->buf != p->inline_buf) {
-		if (p->virtual_mem)
+		if (is_vmalloc_addr(p->buf))
 			vfree(p->buf);
 		else
 			kfree(p->buf);
@@ -299,13 +297,12 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 			tmp_buf = vmalloc(len);
 			if (!tmp_buf)
 				return -ENOMEM;
-			p->virtual_mem = 1;
 		}
 		memcpy(tmp_buf, p->buf, p->buf_len);
 		p->buf = tmp_buf;
 		p->buf_len = len;
 	} else {
-		if (p->virtual_mem) {
+		if (is_vmalloc_addr(p->buf)) {
 			tmp_buf = vmalloc(len);
 			if (!tmp_buf)
 				return -ENOMEM;
@@ -319,7 +316,6 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 					return -ENOMEM;
 				memcpy(tmp_buf, p->buf, p->buf_len);
 				kfree(p->buf);
-				p->virtual_mem = 1;
 			}
 		}
 		p->buf = tmp_buf;

commit b23ab57d485c985c10ee7c03627359bfbba590d8
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Feb 3 19:23:19 2014 +0100

    btrfs: send: remove prepared member from fs_path
    
    The member is used only to return value back from
    fs_path_prepare_for_add, we can do it locally and save 8 bytes for the
    inline_buf path.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 08edd0a7fff1..851ebfd43aa7 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -51,7 +51,6 @@ struct fs_path {
 		struct {
 			char *start;
 			char *end;
-			char *prepared;
 
 			char *buf;
 			int buf_len;
@@ -338,7 +337,8 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 	return 0;
 }
 
-static int fs_path_prepare_for_add(struct fs_path *p, int name_len)
+static int fs_path_prepare_for_add(struct fs_path *p, int name_len,
+				   char **prepared)
 {
 	int ret;
 	int new_len;
@@ -354,11 +354,11 @@ static int fs_path_prepare_for_add(struct fs_path *p, int name_len)
 		if (p->start != p->end)
 			*--p->start = '/';
 		p->start -= name_len;
-		p->prepared = p->start;
+		*prepared = p->start;
 	} else {
 		if (p->start != p->end)
 			*p->end++ = '/';
-		p->prepared = p->end;
+		*prepared = p->end;
 		p->end += name_len;
 		*p->end = 0;
 	}
@@ -370,12 +370,12 @@ static int fs_path_prepare_for_add(struct fs_path *p, int name_len)
 static int fs_path_add(struct fs_path *p, const char *name, int name_len)
 {
 	int ret;
+	char *prepared;
 
-	ret = fs_path_prepare_for_add(p, name_len);
+	ret = fs_path_prepare_for_add(p, name_len, &prepared);
 	if (ret < 0)
 		goto out;
-	memcpy(p->prepared, name, name_len);
-	p->prepared = NULL;
+	memcpy(prepared, name, name_len);
 
 out:
 	return ret;
@@ -384,12 +384,12 @@ static int fs_path_add(struct fs_path *p, const char *name, int name_len)
 static int fs_path_add_path(struct fs_path *p, struct fs_path *p2)
 {
 	int ret;
+	char *prepared;
 
-	ret = fs_path_prepare_for_add(p, p2->end - p2->start);
+	ret = fs_path_prepare_for_add(p, p2->end - p2->start, &prepared);
 	if (ret < 0)
 		goto out;
-	memcpy(p->prepared, p2->start, p2->end - p2->start);
-	p->prepared = NULL;
+	memcpy(prepared, p2->start, p2->end - p2->start);
 
 out:
 	return ret;
@@ -400,13 +400,13 @@ static int fs_path_add_from_extent_buffer(struct fs_path *p,
 					  unsigned long off, int len)
 {
 	int ret;
+	char *prepared;
 
-	ret = fs_path_prepare_for_add(p, len);
+	ret = fs_path_prepare_for_add(p, len, &prepared);
 	if (ret < 0)
 		goto out;
 
-	read_extent_buffer(eb, p->prepared, off, len);
-	p->prepared = NULL;
+	read_extent_buffer(eb, prepared, off, len);
 
 out:
 	return ret;

commit 64792f253508268eb390a86f42f128d877b40776
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Feb 3 18:24:09 2014 +0100

    btrfs: send: replace check with an assert in gen_unique_name
    
    The buffer passed to snprintf can hold the fully expanded format string,
    64 = 3x largest ULL + 3x char + trailing null.  I don't think that removing the
    check entirely is a good idea, hence the ASSERT.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 154a717d2a3c..08edd0a7fff1 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1418,11 +1418,7 @@ static int gen_unique_name(struct send_ctx *sctx,
 	while (1) {
 		len = snprintf(tmp, sizeof(tmp), "o%llu-%llu-%llu",
 				ino, gen, idx);
-		if (len >= sizeof(tmp)) {
-			/* should really not happen */
-			ret = -EOVERFLOW;
-			goto out;
-		}
+		ASSERT(len < sizeof(tmp));
 
 		di = btrfs_lookup_dir_item(NULL, sctx->send_root,
 				path, BTRFS_FIRST_FREE_OBJECTID,

commit 5ed7f9ff15e6ea56bcb78f69e9503dc1a587caf0
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Sat Feb 1 02:02:16 2014 +0000

    Btrfs: more send support for parent/child dir relationship inversion
    
    The commit titled "Btrfs: fix infinite path build loops in incremental send"
    didn't cover a particular case where the parent-child relationship inversion
    of directories doesn't imply a rename of the new parent directory. This was
    due to a simple logic mistake, a logical and instead of a logical or.
    
    Steps to reproduce:
    
      $ mkfs.btrfs -f /dev/sdb3
      $ mount /dev/sdb3 /mnt/btrfs
      $ mkdir -p /mnt/btrfs/a/b/bar1/bar2/bar3/bar4
      $ btrfs subvol snapshot -r /mnt/btrfs /mnt/btrfs/snap1
      $ mv /mnt/btrfs/a/b/bar1/bar2/bar3/bar4 /mnt/btrfs/a/b/k44
      $ mv /mnt/btrfs/a/b/bar1/bar2/bar3 /mnt/btrfs/a/b/k44
      $ mv /mnt/btrfs/a/b/bar1/bar2 /mnt/btrfs/a/b/k44/bar3
      $ mv /mnt/btrfs/a/b/bar1 /mnt/btrfs/a/b/k44/bar3/bar2/k11
      $ btrfs subvol snapshot -r /mnt/btrfs /mnt/btrfs/snap2
      $ btrfs send -p /mnt/btrfs/snap1 /mnt/btrfs/snap2 > /tmp/incremental.send
    
    A patch to update the test btrfs/030 from xfstests, so that it covers
    this case, will be submitted soon.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 8bd0505ee2f9..154a717d2a3c 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3053,8 +3053,8 @@ static int wait_for_parent_move(struct send_ctx *sctx,
 
 	len1 = fs_path_len(path_before);
 	len2 = fs_path_len(path_after);
-	if ((parent_ino_before != parent_ino_after) && (len1 != len2 ||
-	     memcmp(path_before->start, path_after->start, len1))) {
+	if (parent_ino_before != parent_ino_after || len1 != len2 ||
+	     memcmp(path_before->start, path_after->start, len1)) {
 		ret = 1;
 		goto out;
 	}

commit 03cb4fb9d86d591bc8a3f66eac6fb874b50b1b4d
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Sat Feb 1 02:00:15 2014 +0000

    Btrfs: fix send dealing with file renames and directory moves
    
    This fixes a case that the commit titled:
    
       Btrfs: fix infinite path build loops in incremental send
    
    didn't cover. If the parent-child relationship between 2 directories
    is inverted, both get renamed, and the former parent has a file that
    got renamed too (but remains a child of that directory), the incremental
    send operation would use the file's old path after sending an unlink
    operation for that old path, causing receive to fail on future operations
    like changing owner, permissions or utimes of the corresponding inode.
    
    This is not a regression from the commit mentioned before, as without
    that commit we would fall into the issues that commit fixed, so it's
    just one case that wasn't covered before.
    
    Simple steps to reproduce this issue are:
    
          $ mkfs.btrfs -f /dev/sdb3
          $ mount /dev/sdb3 /mnt/btrfs
          $ mkdir -p /mnt/btrfs/a/b/c/d
          $ touch /mnt/btrfs/a/b/c/d/file
          $ mkdir -p /mnt/btrfs/a/b/x
          $ btrfs subvol snapshot -r /mnt/btrfs /mnt/btrfs/snap1
          $ mv /mnt/btrfs/a/b/x /mnt/btrfs/a/b/c/x2
          $ mv /mnt/btrfs/a/b/c/d /mnt/btrfs/a/b/c/x2/d2
          $ mv /mnt/btrfs/a/b/c/x2/d2/file /mnt/btrfs/a/b/c/x2/d2/file2
          $ btrfs subvol snapshot -r /mnt/btrfs /mnt/btrfs/snap2
          $ btrfs send -p /mnt/btrfs/snap1 /mnt/btrfs/snap2 > /tmp/incremental.send
    
    A patch to update the test btrfs/030 from xfstests, so that it covers
    this case, will be submitted soon.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 70272e1d2b1e..8bd0505ee2f9 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2131,8 +2131,6 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 	u64 parent_inode = 0;
 	u64 parent_gen = 0;
 	int stop = 0;
-	u64 start_ino = ino;
-	u64 start_gen = gen;
 	int skip_name_cache = 0;
 
 	name = fs_path_alloc();
@@ -2144,7 +2142,6 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 	if (is_waiting_for_move(sctx, ino))
 		skip_name_cache = 1;
 
-again:
 	dest->reversed = 1;
 	fs_path_reset(dest);
 
@@ -2159,13 +2156,8 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 			stop = 1;
 
 		if (!skip_name_cache &&
-		    is_waiting_for_move(sctx, parent_inode)) {
-			ino = start_ino;
-			gen = start_gen;
-			stop = 0;
+		    is_waiting_for_move(sctx, parent_inode))
 			skip_name_cache = 1;
-			goto again;
-		}
 
 		ret = fs_path_add_path(dest, name);
 		if (ret < 0)

commit d86477b303da51832002eec1cdec2938c42fccc3
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Thu Jan 30 13:27:12 2014 +0000

    Btrfs: add missing error check in incremental send
    
    Function wait_for_parent_move() returns negative value if an error
    happened, 0 if we don't need to wait for the parent's move, and
    1 if the wait is needed.
    Before this change an error return value was being treated like the
    return value 1, which was not correct.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 9dde9717c1b9..70272e1d2b1e 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3227,7 +3227,10 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 				 * dirs, we always have one new and one deleted
 				 * ref. The deleted ref is ignored later.
 				 */
-				if (wait_for_parent_move(sctx, cur)) {
+				ret = wait_for_parent_move(sctx, cur);
+				if (ret < 0)
+					goto out;
+				if (ret) {
 					ret = add_pending_dir_move(sctx,
 								   cur->dir);
 					*pending_move = 1;

commit 93de4ba86480a9e0d1062cb1d535fa97fb81af48
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Sat Feb 15 15:53:16 2014 +0000

    Btrfs: use right clone root offset for compressed extents
    
    For non compressed extents, iterate_extent_inodes() gives us offsets
    that take into account the data offset from the file extent items, while
    for compressed extents it doesn't. Therefore we have to adjust them before
    placing them in a send clone instruction. Not doing this adjustment leads to
    the receiving end requesting for a wrong a file range to the clone ioctl,
    which results in different file content from the one in the original send
    root.
    
    Issue reproducible with the following excerpt from the test I made for
    xfstests:
    
      _scratch_mkfs
      _scratch_mount "-o compress-force=lzo"
    
      $XFS_IO_PROG -f -c "truncate 118811" $SCRATCH_MNT/foo
      $XFS_IO_PROG -c "pwrite -S 0x0d -b 39987 92267 39987" $SCRATCH_MNT/foo
    
      $BTRFS_UTIL_PROG subvolume snapshot -r $SCRATCH_MNT $SCRATCH_MNT/mysnap1
    
      $XFS_IO_PROG -c "pwrite -S 0x3e -b 80000 200000 80000" $SCRATCH_MNT/foo
      $BTRFS_UTIL_PROG filesystem sync $SCRATCH_MNT
      $XFS_IO_PROG -c "pwrite -S 0xdc -b 10000 250000 10000" $SCRATCH_MNT/foo
      $XFS_IO_PROG -c "pwrite -S 0xff -b 10000 300000 10000" $SCRATCH_MNT/foo
    
      # will be used for incremental send to be able to issue clone operations
      $BTRFS_UTIL_PROG subvolume snapshot -r $SCRATCH_MNT $SCRATCH_MNT/clones_snap
    
      $BTRFS_UTIL_PROG subvolume snapshot -r $SCRATCH_MNT $SCRATCH_MNT/mysnap2
    
      $FSSUM_PROG -A -f -w $tmp/1.fssum $SCRATCH_MNT/mysnap1
      $FSSUM_PROG -A -f -w $tmp/2.fssum -x $SCRATCH_MNT/mysnap2/mysnap1 \
          -x $SCRATCH_MNT/mysnap2/clones_snap $SCRATCH_MNT/mysnap2
      $FSSUM_PROG -A -f -w $tmp/clones.fssum $SCRATCH_MNT/clones_snap \
          -x $SCRATCH_MNT/clones_snap/mysnap1 -x $SCRATCH_MNT/clones_snap/mysnap2
    
      $BTRFS_UTIL_PROG send $SCRATCH_MNT/mysnap1 -f $tmp/1.snap
      $BTRFS_UTIL_PROG send $SCRATCH_MNT/clones_snap -f $tmp/clones.snap
      $BTRFS_UTIL_PROG send -p $SCRATCH_MNT/mysnap1 \
          -c $SCRATCH_MNT/clones_snap $SCRATCH_MNT/mysnap2 -f $tmp/2.snap
    
      _scratch_unmount
      _scratch_mkfs
      _scratch_mount
    
      $BTRFS_UTIL_PROG receive $SCRATCH_MNT -f $tmp/1.snap
      $FSSUM_PROG -r $tmp/1.fssum $SCRATCH_MNT/mysnap1 2>> $seqres.full
    
      $BTRFS_UTIL_PROG receive $SCRATCH_MNT -f $tmp/clones.snap
      $FSSUM_PROG -r $tmp/clones.fssum $SCRATCH_MNT/clones_snap 2>> $seqres.full
    
      $BTRFS_UTIL_PROG receive $SCRATCH_MNT -f $tmp/2.snap
      $FSSUM_PROG -r $tmp/2.fssum $SCRATCH_MNT/mysnap2 2>> $seqres.full
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 9c8d1a3fdc3a..9dde9717c1b9 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1332,6 +1332,16 @@ verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, "
 	}
 
 	if (cur_clone_root) {
+		if (compressed != BTRFS_COMPRESS_NONE) {
+			/*
+			 * Offsets given by iterate_extent_inodes() are relative
+			 * to the start of the extent, we need to add logical
+			 * offset from the file extent item.
+			 * (See why at backref.c:check_extent_in_eb())
+			 */
+			cur_clone_root->offset += btrfs_file_extent_offset(eb,
+									   fi);
+		}
 		*found = cur_clone_root;
 		ret = 0;
 	} else {

commit 6cc98d90f8d14f8ebce2391323929024d7eef39f
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed Feb 5 16:19:21 2014 -0500

    Btrfs: fix assert screwup for the pending move stuff
    
    Wang noticed that he was failing btrfs/030 even though me and Filipe couldn't
    reproduce.  Turns out this is because Wang didn't have CONFIG_BTRFS_ASSERT set,
    which meant that a key part of Filipe's original patch was not being built in.
    This appears to be a mess up with merging Filipe's patch as it does not exist in
    his original patch.  Fix this by changing how we make sure del_waiting_dir_move
    asserts that it did not error and take the function out of the ifdef check.
    This makes btrfs/030 pass with the assert on or off.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Filipe Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index cf9107a64204..9c8d1a3fdc3a 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2774,8 +2774,6 @@ static int add_waiting_dir_move(struct send_ctx *sctx, u64 ino)
 	return 0;
 }
 
-#ifdef CONFIG_BTRFS_ASSERT
-
 static int del_waiting_dir_move(struct send_ctx *sctx, u64 ino)
 {
 	struct rb_node *n = sctx->waiting_dir_moves.rb_node;
@@ -2796,8 +2794,6 @@ static int del_waiting_dir_move(struct send_ctx *sctx, u64 ino)
 	return -ENOENT;
 }
 
-#endif
-
 static int add_pending_dir_move(struct send_ctx *sctx, u64 parent_ino)
 {
 	struct rb_node **p = &sctx->pending_dir_moves.rb_node;
@@ -2902,7 +2898,9 @@ static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
 	}
 
 	sctx->send_progress = sctx->cur_ino + 1;
-	ASSERT(del_waiting_dir_move(sctx, pm->ino) == 0);
+	ret = del_waiting_dir_move(sctx, pm->ino);
+	ASSERT(ret == 0);
+
 	ret = get_cur_path(sctx, pm->ino, pm->gen, to_path);
 	if (ret < 0)
 		goto out;

commit 0b947aff1599afbbd2ec07ada87b05af0f94cf10
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Wed Jan 29 21:06:04 2014 +0000

    Btrfs: use btrfs_crc32c everywhere instead of libcrc32c
    
    After the commit titled "Btrfs: fix btrfs boot when compiled as built-in",
    LIBCRC32C requirement was removed from btrfs' Kconfig. This made it not
    possible to build a kernel with btrfs enabled (either as module or built-in)
    if libcrc32c is not enabled as well. So just replace all uses of libcrc32c
    with the equivalent function in btrfs hash.h - btrfs_crc32c.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 730dce395858..cf9107a64204 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -24,12 +24,12 @@
 #include <linux/xattr.h>
 #include <linux/posix_acl_xattr.h>
 #include <linux/radix-tree.h>
-#include <linux/crc32c.h>
 #include <linux/vmalloc.h>
 #include <linux/string.h>
 
 #include "send.h"
 #include "backref.h"
+#include "hash.h"
 #include "locking.h"
 #include "disk-io.h"
 #include "btrfs_inode.h"
@@ -620,7 +620,7 @@ static int send_cmd(struct send_ctx *sctx)
 	hdr->len = cpu_to_le32(sctx->send_size - sizeof(*hdr));
 	hdr->crc = 0;
 
-	crc = crc32c(0, (unsigned char *)sctx->send_buf, sctx->send_size);
+	crc = btrfs_crc32c(0, (unsigned char *)sctx->send_buf, sctx->send_size);
 	hdr->crc = cpu_to_le32(crc);
 
 	ret = write_buf(sctx->send_filp, sctx->send_buf, sctx->send_size,

commit 514ac8ad8793a097c0c9d89202c642479d6dfa34
Author: Chris Mason <clm@fb.com>
Date:   Fri Jan 3 21:07:00 2014 -0800

    Btrfs: don't use ram_bytes for uncompressed inline items
    
    If we truncate an uncompressed inline item, ram_bytes isn't updated to reflect
    the new size.  The fixe uses the size directly from the item header when
    reading uncompressed inlines, and also fixes truncate to update the
    size as it goes.
    
    Reported-by: Jens Axboe <axboe@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    CC: stable@vger.kernel.org

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 85259cba784a..730dce395858 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1377,7 +1377,7 @@ static int read_symlink(struct btrfs_root *root,
 	BUG_ON(compression);
 
 	off = btrfs_file_extent_inline_start(ei);
-	len = btrfs_file_extent_inline_len(path->nodes[0], ei);
+	len = btrfs_file_extent_inline_len(path->nodes[0], path->slots[0], ei);
 
 	ret = fs_path_add_from_extent_buffer(dest, path->nodes[0], off, len);
 
@@ -4207,7 +4207,8 @@ static int send_write_or_clone(struct send_ctx *sctx,
 			struct btrfs_file_extent_item);
 	type = btrfs_file_extent_type(path->nodes[0], ei);
 	if (type == BTRFS_FILE_EXTENT_INLINE) {
-		len = btrfs_file_extent_inline_len(path->nodes[0], ei);
+		len = btrfs_file_extent_inline_len(path->nodes[0],
+						   path->slots[0], ei);
 		/*
 		 * it is possible the inline item won't cover the whole page,
 		 * but there may be items after this page.  Make
@@ -4448,7 +4449,8 @@ static int get_last_extent(struct send_ctx *sctx, u64 offset)
 			    struct btrfs_file_extent_item);
 	type = btrfs_file_extent_type(path->nodes[0], fi);
 	if (type == BTRFS_FILE_EXTENT_INLINE) {
-		u64 size = btrfs_file_extent_inline_len(path->nodes[0], fi);
+		u64 size = btrfs_file_extent_inline_len(path->nodes[0],
+							path->slots[0], fi);
 		extent_end = ALIGN(key.offset + size,
 				   sctx->send_root->sectorsize);
 	} else {
@@ -4482,7 +4484,8 @@ static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
 			    struct btrfs_file_extent_item);
 	type = btrfs_file_extent_type(path->nodes[0], fi);
 	if (type == BTRFS_FILE_EXTENT_INLINE) {
-		u64 size = btrfs_file_extent_inline_len(path->nodes[0], fi);
+		u64 size = btrfs_file_extent_inline_len(path->nodes[0],
+							path->slots[0], fi);
 		extent_end = ALIGN(key->offset + size,
 				   sctx->send_root->sectorsize);
 	} else {

commit bf54f412f0624786ac8a115110b5203430a9eebb
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Tue Jan 28 01:38:06 2014 +0000

    Btrfs: fix send file hole detection leading to data corruption
    
    There was a case where file hole detection was incorrect and it would
    cause an incremental send to override a section of a file with zeroes.
    
    This happened in the case where between the last leaf we processed which
    contained a file extent item for our current inode and the leaf we're
    currently are at (and has a file extent item for our current inode) there
    are only leafs containing exclusively file extent items for our current
    inode, and none of them was updated since the previous send operation.
    The file hole detection code would incorrectly consider the file range
    covered by these leafs as a hole.
    
    A test case for xfstests follows soon.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 4d31f72bdf41..85259cba784a 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4489,6 +4489,21 @@ static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
 		extent_end = key->offset +
 			btrfs_file_extent_num_bytes(path->nodes[0], fi);
 	}
+
+	if (path->slots[0] == 0 &&
+	    sctx->cur_inode_last_extent < key->offset) {
+		/*
+		 * We might have skipped entire leafs that contained only
+		 * file extent items for our current inode. These leafs have
+		 * a generation number smaller (older) than the one in the
+		 * current leaf and the leaf our last extent came from, and
+		 * are located between these 2 leafs.
+		 */
+		ret = get_last_extent(sctx, key->offset - 1);
+		if (ret)
+			return ret;
+	}
+
 	if (sctx->cur_inode_last_extent < key->offset)
 		ret = send_hole(sctx, key->offset);
 	sctx->cur_inode_last_extent = extent_end;

commit 7fdd29d02e0ab595a857fe9c7b71e752ff665372
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Fri Jan 24 17:42:09 2014 +0000

    Btrfs: make send's file extent item search more efficient
    
    Instead of looking for a file extent item, process it, release the path
    and do a btree search for the next file extent item, just process all
    file extent items in a leaf without intermediate btree searches. This way
    we save cpu and we're not blocking other tasks or affecting concurrency on
    the btree, because send's paths use the commit root and skip btree node/leaf
    locking.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c96e879bcb16..4d31f72bdf41 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4573,17 +4573,25 @@ static int process_all_extents(struct send_ctx *sctx)
 	key.objectid = sctx->cmp_key->objectid;
 	key.type = BTRFS_EXTENT_DATA_KEY;
 	key.offset = 0;
-	while (1) {
-		ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
-		if (ret < 0)
-			goto out;
-		if (ret) {
-			ret = 0;
-			goto out;
-		}
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
 
+	while (1) {
 		eb = path->nodes[0];
 		slot = path->slots[0];
+
+		if (slot >= btrfs_header_nritems(eb)) {
+			ret = btrfs_next_leaf(root, path);
+			if (ret < 0) {
+				goto out;
+			} else if (ret > 0) {
+				ret = 0;
+				break;
+			}
+			continue;
+		}
+
 		btrfs_item_key_to_cpu(eb, &found_key, slot);
 
 		if (found_key.objectid != key.objectid ||
@@ -4596,8 +4604,7 @@ static int process_all_extents(struct send_ctx *sctx)
 		if (ret < 0)
 			goto out;
 
-		btrfs_release_path(path);
-		key.offset = found_key.offset + 1;
+		path->slots[0]++;
 	}
 
 out:

commit 9f03740a956d7ac6a1b8f8c455da6fa5cae11c22
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Wed Jan 22 10:00:53 2014 +0000

    Btrfs: fix infinite path build loops in incremental send
    
    The send operation processes inodes by their ascending number, and assumes
    that any rename/move operation can be successfully performed (sent to the
    caller) once all previous inodes (those with a smaller inode number than the
    one we're currently processing) were processed.
    
    This is not true when an incremental send had to process an hierarchical change
    between 2 snapshots where the parent-children relationship between directory
    inodes was reversed - that is, parents became children and children became
    parents. This situation made the path building code go into an infinite loop,
    which kept allocating more and more memory that eventually lead to a krealloc
    warning being displayed in dmesg:
    
      WARNING: CPU: 1 PID: 5705 at mm/page_alloc.c:2477 __alloc_pages_nodemask+0x365/0xad0()
      Modules linked in: btrfs raid6_pq xor pci_stub vboxpci(O) vboxnetadp(O) vboxnetflt(O) vboxdrv(O) snd_hda_codec_hdmi snd_hda_codec_realtek joydev radeon snd_hda_intel snd_hda_codec snd_hwdep snd_seq_midi snd_pcm psmouse i915 snd_rawmidi serio_raw snd_seq_midi_event lpc_ich snd_seq snd_timer ttm snd_seq_device rfcomm drm_kms_helper parport_pc bnep bluetooth drm ppdev snd soundcore i2c_algo_bit snd_page_alloc binfmt_misc video lp parport r8169 mii hid_generic usbhid hid
      CPU: 1 PID: 5705 Comm: btrfs Tainted: G           O 3.13.0-rc7-fdm-btrfs-next-18+ #3
      Hardware name: To Be Filled By O.E.M. To Be Filled By O.E.M./Z77 Pro4, BIOS P1.50 09/04/2012
      [ 5381.660441]  00000000000009ad ffff8806f6f2f4e8 ffffffff81777434 0000000000000007
      [ 5381.660447]  0000000000000000 ffff8806f6f2f528 ffffffff8104a9ec ffff8807038f36f0
      [ 5381.660452]  0000000000000000 0000000000000206 ffff8807038f2490 ffff8807038f36f0
      [ 5381.660457] Call Trace:
      [ 5381.660464]  [<ffffffff81777434>] dump_stack+0x4e/0x68
      [ 5381.660471]  [<ffffffff8104a9ec>] warn_slowpath_common+0x8c/0xc0
      [ 5381.660476]  [<ffffffff8104aa3a>] warn_slowpath_null+0x1a/0x20
      [ 5381.660480]  [<ffffffff81144995>] __alloc_pages_nodemask+0x365/0xad0
      [ 5381.660487]  [<ffffffff8108313f>] ? local_clock+0x4f/0x60
      [ 5381.660491]  [<ffffffff811430e8>] ? free_one_page+0x98/0x440
      [ 5381.660495]  [<ffffffff8108313f>] ? local_clock+0x4f/0x60
      [ 5381.660502]  [<ffffffff8113fae4>] ? __get_free_pages+0x14/0x50
      [ 5381.660508]  [<ffffffff81095fb8>] ? trace_hardirqs_off_caller+0x28/0xd0
      [ 5381.660515]  [<ffffffff81183caf>] alloc_pages_current+0x10f/0x1f0
      [ 5381.660520]  [<ffffffff8113fae4>] ? __get_free_pages+0x14/0x50
      [ 5381.660524]  [<ffffffff8113fae4>] __get_free_pages+0x14/0x50
      [ 5381.660530]  [<ffffffff8115dace>] kmalloc_order_trace+0x3e/0x100
      [ 5381.660536]  [<ffffffff81191ea0>] __kmalloc_track_caller+0x220/0x230
      [ 5381.660560]  [<ffffffffa0729fdb>] ? fs_path_ensure_buf.part.12+0x6b/0x200 [btrfs]
      [ 5381.660564]  [<ffffffff8178085c>] ? retint_restore_args+0xe/0xe
      [ 5381.660569]  [<ffffffff811580ef>] krealloc+0x6f/0xb0
      [ 5381.660586]  [<ffffffffa0729fdb>] fs_path_ensure_buf.part.12+0x6b/0x200 [btrfs]
      [ 5381.660601]  [<ffffffffa072a208>] fs_path_prepare_for_add+0x98/0xb0 [btrfs]
      [ 5381.660615]  [<ffffffffa072a2bc>] fs_path_add_path+0x2c/0x60 [btrfs]
      [ 5381.660628]  [<ffffffffa072c55c>] get_cur_path+0x7c/0x1c0 [btrfs]
    
    Even without this loop, the incremental send couldn't succeed, because it would attempt
    to send a rename/move operation for the lower inode before the highest inode number was
    renamed/move. This issue is easy to trigger with the following steps:
    
      $ mkfs.btrfs -f /dev/sdb3
      $ mount /dev/sdb3 /mnt/btrfs
      $ mkdir -p /mnt/btrfs/a/b/c/d
      $ mkdir /mnt/btrfs/a/b/c2
      $ btrfs subvol snapshot -r /mnt/btrfs /mnt/btrfs/snap1
      $ mv /mnt/btrfs/a/b/c/d /mnt/btrfs/a/b/c2/d2
      $ mv /mnt/btrfs/a/b/c /mnt/btrfs/a/b/c2/d2/cc
      $ btrfs subvol snapshot -r /mnt/btrfs /mnt/btrfs/snap2
      $ btrfs send -p /mnt/btrfs/snap1 /mnt/btrfs/snap2 > /tmp/incremental.send
    
    The structure of the filesystem when the first snapshot is taken is:
    
             .                       (ino 256)
             |-- a                   (ino 257)
                 |-- b               (ino 258)
                     |-- c           (ino 259)
                     |   |-- d       (ino 260)
                     |
                     |-- c2          (ino 261)
    
    And its structure when the second snapshot is taken is:
    
             .                       (ino 256)
             |-- a                   (ino 257)
                 |-- b               (ino 258)
                     |-- c2          (ino 261)
                         |-- d2      (ino 260)
                             |-- cc  (ino 259)
    
    Before the move/rename operation is performed for the inode 259, the
    move/rename for inode 260 must be performed, since 259 is now a child
    of 260.
    
    A test case for xfstests, with a more complex scenario, will follow soon.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index fc1f0abb8fe4..c96e879bcb16 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -121,6 +121,74 @@ struct send_ctx {
 	int name_cache_size;
 
 	char *read_buf;
+
+	/*
+	 * We process inodes by their increasing order, so if before an
+	 * incremental send we reverse the parent/child relationship of
+	 * directories such that a directory with a lower inode number was
+	 * the parent of a directory with a higher inode number, and the one
+	 * becoming the new parent got renamed too, we can't rename/move the
+	 * directory with lower inode number when we finish processing it - we
+	 * must process the directory with higher inode number first, then
+	 * rename/move it and then rename/move the directory with lower inode
+	 * number. Example follows.
+	 *
+	 * Tree state when the first send was performed:
+	 *
+	 * .
+	 * |-- a                   (ino 257)
+	 *     |-- b               (ino 258)
+	 *         |
+	 *         |
+	 *         |-- c           (ino 259)
+	 *         |   |-- d       (ino 260)
+	 *         |
+	 *         |-- c2          (ino 261)
+	 *
+	 * Tree state when the second (incremental) send is performed:
+	 *
+	 * .
+	 * |-- a                   (ino 257)
+	 *     |-- b               (ino 258)
+	 *         |-- c2          (ino 261)
+	 *             |-- d2      (ino 260)
+	 *                 |-- cc  (ino 259)
+	 *
+	 * The sequence of steps that lead to the second state was:
+	 *
+	 * mv /a/b/c/d /a/b/c2/d2
+	 * mv /a/b/c /a/b/c2/d2/cc
+	 *
+	 * "c" has lower inode number, but we can't move it (2nd mv operation)
+	 * before we move "d", which has higher inode number.
+	 *
+	 * So we just memorize which move/rename operations must be performed
+	 * later when their respective parent is processed and moved/renamed.
+	 */
+
+	/* Indexed by parent directory inode number. */
+	struct rb_root pending_dir_moves;
+
+	/*
+	 * Reverse index, indexed by the inode number of a directory that
+	 * is waiting for the move/rename of its immediate parent before its
+	 * own move/rename can be performed.
+	 */
+	struct rb_root waiting_dir_moves;
+};
+
+struct pending_dir_move {
+	struct rb_node node;
+	struct list_head list;
+	u64 parent_ino;
+	u64 ino;
+	u64 gen;
+	struct list_head update_refs;
+};
+
+struct waiting_dir_move {
+	struct rb_node node;
+	u64 ino;
 };
 
 struct name_cache_entry {
@@ -144,6 +212,8 @@ struct name_cache_entry {
 	char name[];
 };
 
+static int is_waiting_for_move(struct send_ctx *sctx, u64 ino);
+
 static int need_send_hole(struct send_ctx *sctx)
 {
 	return (sctx->parent_root && !sctx->cur_inode_new &&
@@ -1897,6 +1967,7 @@ static void name_cache_free(struct send_ctx *sctx)
  */
 static int __get_cur_name_and_parent(struct send_ctx *sctx,
 				     u64 ino, u64 gen,
+				     int skip_name_cache,
 				     u64 *parent_ino,
 				     u64 *parent_gen,
 				     struct fs_path *dest)
@@ -1906,6 +1977,8 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	struct btrfs_path *path = NULL;
 	struct name_cache_entry *nce = NULL;
 
+	if (skip_name_cache)
+		goto get_ref;
 	/*
 	 * First check if we already did a call to this function with the same
 	 * ino/gen. If yes, check if the cache entry is still up-to-date. If yes
@@ -1950,11 +2023,12 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 		goto out_cache;
 	}
 
+get_ref:
 	/*
 	 * Depending on whether the inode was already processed or not, use
 	 * send_root or parent_root for ref lookup.
 	 */
-	if (ino < sctx->send_progress)
+	if (ino < sctx->send_progress && !skip_name_cache)
 		ret = get_first_ref(sctx->send_root, ino,
 				    parent_ino, parent_gen, dest);
 	else
@@ -1978,6 +2052,8 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 			goto out;
 		ret = 1;
 	}
+	if (skip_name_cache)
+		goto out;
 
 out_cache:
 	/*
@@ -2045,6 +2121,9 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 	u64 parent_inode = 0;
 	u64 parent_gen = 0;
 	int stop = 0;
+	u64 start_ino = ino;
+	u64 start_gen = gen;
+	int skip_name_cache = 0;
 
 	name = fs_path_alloc();
 	if (!name) {
@@ -2052,19 +2131,32 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 		goto out;
 	}
 
+	if (is_waiting_for_move(sctx, ino))
+		skip_name_cache = 1;
+
+again:
 	dest->reversed = 1;
 	fs_path_reset(dest);
 
 	while (!stop && ino != BTRFS_FIRST_FREE_OBJECTID) {
 		fs_path_reset(name);
 
-		ret = __get_cur_name_and_parent(sctx, ino, gen,
+		ret = __get_cur_name_and_parent(sctx, ino, gen, skip_name_cache,
 				&parent_inode, &parent_gen, name);
 		if (ret < 0)
 			goto out;
 		if (ret)
 			stop = 1;
 
+		if (!skip_name_cache &&
+		    is_waiting_for_move(sctx, parent_inode)) {
+			ino = start_ino;
+			gen = start_gen;
+			stop = 0;
+			skip_name_cache = 1;
+			goto again;
+		}
+
 		ret = fs_path_add_path(dest, name);
 		if (ret < 0)
 			goto out;
@@ -2636,10 +2728,349 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
 	return ret;
 }
 
+static int is_waiting_for_move(struct send_ctx *sctx, u64 ino)
+{
+	struct rb_node *n = sctx->waiting_dir_moves.rb_node;
+	struct waiting_dir_move *entry;
+
+	while (n) {
+		entry = rb_entry(n, struct waiting_dir_move, node);
+		if (ino < entry->ino)
+			n = n->rb_left;
+		else if (ino > entry->ino)
+			n = n->rb_right;
+		else
+			return 1;
+	}
+	return 0;
+}
+
+static int add_waiting_dir_move(struct send_ctx *sctx, u64 ino)
+{
+	struct rb_node **p = &sctx->waiting_dir_moves.rb_node;
+	struct rb_node *parent = NULL;
+	struct waiting_dir_move *entry, *dm;
+
+	dm = kmalloc(sizeof(*dm), GFP_NOFS);
+	if (!dm)
+		return -ENOMEM;
+	dm->ino = ino;
+
+	while (*p) {
+		parent = *p;
+		entry = rb_entry(parent, struct waiting_dir_move, node);
+		if (ino < entry->ino) {
+			p = &(*p)->rb_left;
+		} else if (ino > entry->ino) {
+			p = &(*p)->rb_right;
+		} else {
+			kfree(dm);
+			return -EEXIST;
+		}
+	}
+
+	rb_link_node(&dm->node, parent, p);
+	rb_insert_color(&dm->node, &sctx->waiting_dir_moves);
+	return 0;
+}
+
+#ifdef CONFIG_BTRFS_ASSERT
+
+static int del_waiting_dir_move(struct send_ctx *sctx, u64 ino)
+{
+	struct rb_node *n = sctx->waiting_dir_moves.rb_node;
+	struct waiting_dir_move *entry;
+
+	while (n) {
+		entry = rb_entry(n, struct waiting_dir_move, node);
+		if (ino < entry->ino) {
+			n = n->rb_left;
+		} else if (ino > entry->ino) {
+			n = n->rb_right;
+		} else {
+			rb_erase(&entry->node, &sctx->waiting_dir_moves);
+			kfree(entry);
+			return 0;
+		}
+	}
+	return -ENOENT;
+}
+
+#endif
+
+static int add_pending_dir_move(struct send_ctx *sctx, u64 parent_ino)
+{
+	struct rb_node **p = &sctx->pending_dir_moves.rb_node;
+	struct rb_node *parent = NULL;
+	struct pending_dir_move *entry, *pm;
+	struct recorded_ref *cur;
+	int exists = 0;
+	int ret;
+
+	pm = kmalloc(sizeof(*pm), GFP_NOFS);
+	if (!pm)
+		return -ENOMEM;
+	pm->parent_ino = parent_ino;
+	pm->ino = sctx->cur_ino;
+	pm->gen = sctx->cur_inode_gen;
+	INIT_LIST_HEAD(&pm->list);
+	INIT_LIST_HEAD(&pm->update_refs);
+	RB_CLEAR_NODE(&pm->node);
+
+	while (*p) {
+		parent = *p;
+		entry = rb_entry(parent, struct pending_dir_move, node);
+		if (parent_ino < entry->parent_ino) {
+			p = &(*p)->rb_left;
+		} else if (parent_ino > entry->parent_ino) {
+			p = &(*p)->rb_right;
+		} else {
+			exists = 1;
+			break;
+		}
+	}
+
+	list_for_each_entry(cur, &sctx->deleted_refs, list) {
+		ret = dup_ref(cur, &pm->update_refs);
+		if (ret < 0)
+			goto out;
+	}
+	list_for_each_entry(cur, &sctx->new_refs, list) {
+		ret = dup_ref(cur, &pm->update_refs);
+		if (ret < 0)
+			goto out;
+	}
+
+	ret = add_waiting_dir_move(sctx, pm->ino);
+	if (ret)
+		goto out;
+
+	if (exists) {
+		list_add_tail(&pm->list, &entry->list);
+	} else {
+		rb_link_node(&pm->node, parent, p);
+		rb_insert_color(&pm->node, &sctx->pending_dir_moves);
+	}
+	ret = 0;
+out:
+	if (ret) {
+		__free_recorded_refs(&pm->update_refs);
+		kfree(pm);
+	}
+	return ret;
+}
+
+static struct pending_dir_move *get_pending_dir_moves(struct send_ctx *sctx,
+						      u64 parent_ino)
+{
+	struct rb_node *n = sctx->pending_dir_moves.rb_node;
+	struct pending_dir_move *entry;
+
+	while (n) {
+		entry = rb_entry(n, struct pending_dir_move, node);
+		if (parent_ino < entry->parent_ino)
+			n = n->rb_left;
+		else if (parent_ino > entry->parent_ino)
+			n = n->rb_right;
+		else
+			return entry;
+	}
+	return NULL;
+}
+
+static int apply_dir_move(struct send_ctx *sctx, struct pending_dir_move *pm)
+{
+	struct fs_path *from_path = NULL;
+	struct fs_path *to_path = NULL;
+	u64 orig_progress = sctx->send_progress;
+	struct recorded_ref *cur;
+	int ret;
+
+	from_path = fs_path_alloc();
+	if (!from_path)
+		return -ENOMEM;
+
+	sctx->send_progress = pm->ino;
+	ret = get_cur_path(sctx, pm->ino, pm->gen, from_path);
+	if (ret < 0)
+		goto out;
+
+	to_path = fs_path_alloc();
+	if (!to_path) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	sctx->send_progress = sctx->cur_ino + 1;
+	ASSERT(del_waiting_dir_move(sctx, pm->ino) == 0);
+	ret = get_cur_path(sctx, pm->ino, pm->gen, to_path);
+	if (ret < 0)
+		goto out;
+
+	ret = send_rename(sctx, from_path, to_path);
+	if (ret < 0)
+		goto out;
+
+	ret = send_utimes(sctx, pm->ino, pm->gen);
+	if (ret < 0)
+		goto out;
+
+	/*
+	 * After rename/move, need to update the utimes of both new parent(s)
+	 * and old parent(s).
+	 */
+	list_for_each_entry(cur, &pm->update_refs, list) {
+		ret = send_utimes(sctx, cur->dir, cur->dir_gen);
+		if (ret < 0)
+			goto out;
+	}
+
+out:
+	fs_path_free(from_path);
+	fs_path_free(to_path);
+	sctx->send_progress = orig_progress;
+
+	return ret;
+}
+
+static void free_pending_move(struct send_ctx *sctx, struct pending_dir_move *m)
+{
+	if (!list_empty(&m->list))
+		list_del(&m->list);
+	if (!RB_EMPTY_NODE(&m->node))
+		rb_erase(&m->node, &sctx->pending_dir_moves);
+	__free_recorded_refs(&m->update_refs);
+	kfree(m);
+}
+
+static void tail_append_pending_moves(struct pending_dir_move *moves,
+				      struct list_head *stack)
+{
+	if (list_empty(&moves->list)) {
+		list_add_tail(&moves->list, stack);
+	} else {
+		LIST_HEAD(list);
+		list_splice_init(&moves->list, &list);
+		list_add_tail(&moves->list, stack);
+		list_splice_tail(&list, stack);
+	}
+}
+
+static int apply_children_dir_moves(struct send_ctx *sctx)
+{
+	struct pending_dir_move *pm;
+	struct list_head stack;
+	u64 parent_ino = sctx->cur_ino;
+	int ret = 0;
+
+	pm = get_pending_dir_moves(sctx, parent_ino);
+	if (!pm)
+		return 0;
+
+	INIT_LIST_HEAD(&stack);
+	tail_append_pending_moves(pm, &stack);
+
+	while (!list_empty(&stack)) {
+		pm = list_first_entry(&stack, struct pending_dir_move, list);
+		parent_ino = pm->ino;
+		ret = apply_dir_move(sctx, pm);
+		free_pending_move(sctx, pm);
+		if (ret)
+			goto out;
+		pm = get_pending_dir_moves(sctx, parent_ino);
+		if (pm)
+			tail_append_pending_moves(pm, &stack);
+	}
+	return 0;
+
+out:
+	while (!list_empty(&stack)) {
+		pm = list_first_entry(&stack, struct pending_dir_move, list);
+		free_pending_move(sctx, pm);
+	}
+	return ret;
+}
+
+static int wait_for_parent_move(struct send_ctx *sctx,
+				struct recorded_ref *parent_ref)
+{
+	int ret;
+	u64 ino = parent_ref->dir;
+	u64 parent_ino_before, parent_ino_after;
+	u64 new_gen, old_gen;
+	struct fs_path *path_before = NULL;
+	struct fs_path *path_after = NULL;
+	int len1, len2;
+
+	if (parent_ref->dir <= sctx->cur_ino)
+		return 0;
+
+	if (is_waiting_for_move(sctx, ino))
+		return 1;
+
+	ret = get_inode_info(sctx->parent_root, ino, NULL, &old_gen,
+			     NULL, NULL, NULL, NULL);
+	if (ret == -ENOENT)
+		return 0;
+	else if (ret < 0)
+		return ret;
+
+	ret = get_inode_info(sctx->send_root, ino, NULL, &new_gen,
+			     NULL, NULL, NULL, NULL);
+	if (ret < 0)
+		return ret;
+
+	if (new_gen != old_gen)
+		return 0;
+
+	path_before = fs_path_alloc();
+	if (!path_before)
+		return -ENOMEM;
+
+	ret = get_first_ref(sctx->parent_root, ino, &parent_ino_before,
+			    NULL, path_before);
+	if (ret == -ENOENT) {
+		ret = 0;
+		goto out;
+	} else if (ret < 0) {
+		goto out;
+	}
+
+	path_after = fs_path_alloc();
+	if (!path_after) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	ret = get_first_ref(sctx->send_root, ino, &parent_ino_after,
+			    NULL, path_after);
+	if (ret == -ENOENT) {
+		ret = 0;
+		goto out;
+	} else if (ret < 0) {
+		goto out;
+	}
+
+	len1 = fs_path_len(path_before);
+	len2 = fs_path_len(path_after);
+	if ((parent_ino_before != parent_ino_after) && (len1 != len2 ||
+	     memcmp(path_before->start, path_after->start, len1))) {
+		ret = 1;
+		goto out;
+	}
+	ret = 0;
+
+out:
+	fs_path_free(path_before);
+	fs_path_free(path_after);
+
+	return ret;
+}
+
 /*
  * This does all the move/link/unlink/rmdir magic.
  */
-static int process_recorded_refs(struct send_ctx *sctx)
+static int process_recorded_refs(struct send_ctx *sctx, int *pending_move)
 {
 	int ret = 0;
 	struct recorded_ref *cur;
@@ -2788,11 +3219,17 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 				 * dirs, we always have one new and one deleted
 				 * ref. The deleted ref is ignored later.
 				 */
-				ret = send_rename(sctx, valid_path,
-						cur->full_path);
-				if (ret < 0)
-					goto out;
-				ret = fs_path_copy(valid_path, cur->full_path);
+				if (wait_for_parent_move(sctx, cur)) {
+					ret = add_pending_dir_move(sctx,
+								   cur->dir);
+					*pending_move = 1;
+				} else {
+					ret = send_rename(sctx, valid_path,
+							  cur->full_path);
+					if (!ret)
+						ret = fs_path_copy(valid_path,
+							       cur->full_path);
+				}
 				if (ret < 0)
 					goto out;
 			} else {
@@ -3161,6 +3598,7 @@ static int process_all_refs(struct send_ctx *sctx,
 	struct extent_buffer *eb;
 	int slot;
 	iterate_inode_ref_t cb;
+	int pending_move = 0;
 
 	path = alloc_path_for_send();
 	if (!path)
@@ -3204,7 +3642,9 @@ static int process_all_refs(struct send_ctx *sctx,
 	}
 	btrfs_release_path(path);
 
-	ret = process_recorded_refs(sctx);
+	ret = process_recorded_refs(sctx, &pending_move);
+	/* Only applicable to an incremental send. */
+	ASSERT(pending_move == 0);
 
 out:
 	btrfs_free_path(path);
@@ -4165,7 +4605,9 @@ static int process_all_extents(struct send_ctx *sctx)
 	return ret;
 }
 
-static int process_recorded_refs_if_needed(struct send_ctx *sctx, int at_end)
+static int process_recorded_refs_if_needed(struct send_ctx *sctx, int at_end,
+					   int *pending_move,
+					   int *refs_processed)
 {
 	int ret = 0;
 
@@ -4177,17 +4619,11 @@ static int process_recorded_refs_if_needed(struct send_ctx *sctx, int at_end)
 	if (list_empty(&sctx->new_refs) && list_empty(&sctx->deleted_refs))
 		goto out;
 
-	ret = process_recorded_refs(sctx);
+	ret = process_recorded_refs(sctx, pending_move);
 	if (ret < 0)
 		goto out;
 
-	/*
-	 * We have processed the refs and thus need to advance send_progress.
-	 * Now, calls to get_cur_xxx will take the updated refs of the current
-	 * inode into account.
-	 */
-	sctx->send_progress = sctx->cur_ino + 1;
-
+	*refs_processed = 1;
 out:
 	return ret;
 }
@@ -4203,11 +4639,29 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 	u64 right_gid;
 	int need_chmod = 0;
 	int need_chown = 0;
+	int pending_move = 0;
+	int refs_processed = 0;
 
-	ret = process_recorded_refs_if_needed(sctx, at_end);
+	ret = process_recorded_refs_if_needed(sctx, at_end, &pending_move,
+					      &refs_processed);
 	if (ret < 0)
 		goto out;
 
+	/*
+	 * We have processed the refs and thus need to advance send_progress.
+	 * Now, calls to get_cur_xxx will take the updated refs of the current
+	 * inode into account.
+	 *
+	 * On the other hand, if our current inode is a directory and couldn't
+	 * be moved/renamed because its parent was renamed/moved too and it has
+	 * a higher inode number, we can only move/rename our current inode
+	 * after we moved/renamed its parent. Therefore in this case operate on
+	 * the old path (pre move/rename) of our current inode, and the
+	 * move/rename will be performed later.
+	 */
+	if (refs_processed && !pending_move)
+		sctx->send_progress = sctx->cur_ino + 1;
+
 	if (sctx->cur_ino == 0 || sctx->cur_inode_deleted)
 		goto out;
 	if (!at_end && sctx->cmp_key->objectid == sctx->cur_ino)
@@ -4269,9 +4723,21 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 	}
 
 	/*
-	 * Need to send that every time, no matter if it actually changed
-	 * between the two trees as we have done changes to the inode before.
+	 * If other directory inodes depended on our current directory
+	 * inode's move/rename, now do their move/rename operations.
 	 */
+	if (!is_waiting_for_move(sctx, sctx->cur_ino)) {
+		ret = apply_children_dir_moves(sctx);
+		if (ret)
+			goto out;
+	}
+
+	/*
+	 * Need to send that every time, no matter if it actually
+	 * changed between the two trees as we have done changes to
+	 * the inode before.
+	 */
+	sctx->send_progress = sctx->cur_ino + 1;
 	ret = send_utimes(sctx, sctx->cur_ino, sctx->cur_inode_gen);
 	if (ret < 0)
 		goto out;
@@ -4839,6 +5305,9 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		goto out;
 	}
 
+	sctx->pending_dir_moves = RB_ROOT;
+	sctx->waiting_dir_moves = RB_ROOT;
+
 	sctx->clone_roots = vzalloc(sizeof(struct clone_root) *
 			(arg->clone_sources_count + 1));
 	if (!sctx->clone_roots) {
@@ -4947,6 +5416,34 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	}
 
 out:
+	WARN_ON(sctx && !ret && !RB_EMPTY_ROOT(&sctx->pending_dir_moves));
+	while (sctx && !RB_EMPTY_ROOT(&sctx->pending_dir_moves)) {
+		struct rb_node *n;
+		struct pending_dir_move *pm;
+
+		n = rb_first(&sctx->pending_dir_moves);
+		pm = rb_entry(n, struct pending_dir_move, node);
+		while (!list_empty(&pm->list)) {
+			struct pending_dir_move *pm2;
+
+			pm2 = list_first_entry(&pm->list,
+					       struct pending_dir_move, list);
+			free_pending_move(sctx, pm2);
+		}
+		free_pending_move(sctx, pm);
+	}
+
+	WARN_ON(sctx && !ret && !RB_EMPTY_ROOT(&sctx->waiting_dir_moves));
+	while (sctx && !RB_EMPTY_ROOT(&sctx->waiting_dir_moves)) {
+		struct rb_node *n;
+		struct waiting_dir_move *dm;
+
+		n = rb_first(&sctx->waiting_dir_moves);
+		dm = rb_entry(n, struct waiting_dir_move, node);
+		rb_erase(&dm->node, &sctx->waiting_dir_moves);
+		kfree(dm);
+	}
+
 	if (sort_clone_roots) {
 		for (i = 0; i < sctx->clone_roots_cnt; i++)
 			btrfs_root_dec_send_in_progress(

commit f74b86d85533a98ef7f573487af38f9dd514becb
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Tue Jan 21 23:36:38 2014 +0000

    Btrfs: fix snprintf usage by send's gen_unique_name
    
    The buffer size argument passed to snprintf must account for the
    trailing null byte added by snprintf, and it returns a value >= then
    sizeof(buffer) when the string can't fit in the buffer.
    
    Since our buffer has a size of 64 characters, and the maximum orphan
    name we can generate is 63 characters wide, we must pass 64 as the
    buffer size to snprintf, and not 63.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index aa60cbe7066c..fc1f0abb8fe4 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1336,7 +1336,7 @@ static int gen_unique_name(struct send_ctx *sctx,
 		return -ENOMEM;
 
 	while (1) {
-		len = snprintf(tmp, sizeof(tmp) - 1, "o%llu-%llu-%llu",
+		len = snprintf(tmp, sizeof(tmp), "o%llu-%llu-%llu",
 				ino, gen, idx);
 		if (len >= sizeof(tmp)) {
 			/* should really not happen */

commit ffcfaf81795471be3c07d6e3143bff31edca5d5a
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Wed Jan 15 00:26:43 2014 +0800

    Btrfs: fix wrong search path initialization before searching tree root
    
    To search tree root without transaction protection, we should neither search commit
    root nor skip locking here, fix it.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 84aed2f30aa2..aa60cbe7066c 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2095,7 +2095,7 @@ static int send_subvol_begin(struct send_ctx *sctx)
 	char *name = NULL;
 	int namelen;
 
-	path = alloc_path_for_send();
+	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;
 

commit 28e5dd8f35202ff56b2eb1725ac77f0d0fcb4758
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Sun Jan 12 02:26:28 2014 +0000

    Btrfs: fix send to not send non-aligned clone operations
    
    It is possible for the send feature to send clone operations that
    request a cloning range (offset + length) that is not aligned with
    the block size. This makes the btrfs receive command send issue a
    clone ioctl call that will fail, as the ioctl will return an -EINVAL
    error because of the unaligned range.
    
    Fix this by not sending clone operations for non block aligned ranges,
    and instead send regular write operation for these (less common) cases.
    
    The following xfstest reproduces this issue, which fails on the second
    btrfs receive command without this change:
    
      seq=`basename $0`
      seqres=$RESULT_DIR/$seq
      echo "QA output created by $seq"
    
      tmp=`mktemp -d`
    
      status=1      # failure is the default!
      trap "_cleanup; exit \$status" 0 1 2 3 15
    
      _cleanup()
      {
          rm -fr $tmp
      }
    
      # get standard environment, filters and checks
      . ./common/rc
      . ./common/filter
    
      # real QA test starts here
      _supported_fs btrfs
      _supported_os Linux
      _require_scratch
      _need_to_be_root
    
      rm -f $seqres.full
    
      _scratch_mkfs >/dev/null 2>&1
      _scratch_mount
    
      $XFS_IO_PROG -f -c "truncate 819200" $SCRATCH_MNT/foo | _filter_xfs_io
      $BTRFS_UTIL_PROG filesystem sync $SCRATCH_MNT | _filter_scratch
    
      $XFS_IO_PROG -c "falloc -k 819200 667648" $SCRATCH_MNT/foo | _filter_xfs_io
      $BTRFS_UTIL_PROG filesystem sync $SCRATCH_MNT | _filter_scratch
    
      $XFS_IO_PROG -f -c "pwrite 1482752 2978" $SCRATCH_MNT/foo | _filter_xfs_io
      $BTRFS_UTIL_PROG filesystem sync $SCRATCH_MNT | _filter_scratch
    
      $BTRFS_UTIL_PROG subvol snapshot -r $SCRATCH_MNT $SCRATCH_MNT/mysnap1 | \
          _filter_scratch
    
      $XFS_IO_PROG -f -c "truncate 883305" $SCRATCH_MNT/foo | _filter_xfs_io
      $BTRFS_UTIL_PROG filesystem sync $SCRATCH_MNT | _filter_scratch
    
      $BTRFS_UTIL_PROG subvol snapshot -r $SCRATCH_MNT $SCRATCH_MNT/mysnap2 | \
          _filter_scratch
    
      $BTRFS_UTIL_PROG send $SCRATCH_MNT/mysnap1 -f $tmp/1.snap 2>&1 | _filter_scratch
      $BTRFS_UTIL_PROG send -p $SCRATCH_MNT/mysnap1 $SCRATCH_MNT/mysnap2 \
          -f $tmp/2.snap 2>&1 | _filter_scratch
    
      md5sum $SCRATCH_MNT/foo | _filter_scratch
      md5sum $SCRATCH_MNT/mysnap1/foo | _filter_scratch
      md5sum $SCRATCH_MNT/mysnap2/foo | _filter_scratch
    
      _scratch_unmount
      _check_btrfs_filesystem $SCRATCH_DEV
      _scratch_mkfs >/dev/null 2>&1
      _scratch_mount
    
      $BTRFS_UTIL_PROG receive $SCRATCH_MNT -f $tmp/1.snap
      md5sum $SCRATCH_MNT/mysnap1/foo | _filter_scratch
    
      $BTRFS_UTIL_PROG receive $SCRATCH_MNT -f $tmp/2.snap
      md5sum $SCRATCH_MNT/mysnap2/foo | _filter_scratch
    
      _scratch_unmount
      _check_btrfs_filesystem $SCRATCH_DEV
    
      status=0
      exit
    
    The tests expected output is:
    
      QA output created by 025
      FSSync 'SCRATCH_MNT'
      FSSync 'SCRATCH_MNT'
      wrote 2978/2978 bytes at offset 1482752
      XXX Bytes, X ops; XX:XX:XX.X (XXX YYY/sec and XXX ops/sec)
      FSSync 'SCRATCH_MNT'
      Create a readonly snapshot of 'SCRATCH_MNT' in 'SCRATCH_MNT/mysnap1'
      FSSync 'SCRATCH_MNT'
      Create a readonly snapshot of 'SCRATCH_MNT' in 'SCRATCH_MNT/mysnap2'
      At subvol SCRATCH_MNT/mysnap1
      At subvol SCRATCH_MNT/mysnap2
      129b8eaee8d3c2bcad49bec596591cb3  SCRATCH_MNT/foo
      42b6369eae2a8725c1aacc0440e597aa  SCRATCH_MNT/mysnap1/foo
      129b8eaee8d3c2bcad49bec596591cb3  SCRATCH_MNT/mysnap2/foo
      At subvol mysnap1
      42b6369eae2a8725c1aacc0440e597aa  SCRATCH_MNT/mysnap1/foo
      At snapshot mysnap2
      129b8eaee8d3c2bcad49bec596591cb3  SCRATCH_MNT/mysnap2/foo
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 591063dac0e6..84aed2f30aa2 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3761,6 +3761,7 @@ static int send_write_or_clone(struct send_ctx *sctx,
 	u64 len;
 	u32 l;
 	u8 type;
+	u64 bs = sctx->send_root->fs_info->sb->s_blocksize;
 
 	ei = btrfs_item_ptr(path->nodes[0], path->slots[0],
 			struct btrfs_file_extent_item);
@@ -3784,7 +3785,7 @@ static int send_write_or_clone(struct send_ctx *sctx,
 		goto out;
 	}
 
-	if (clone_root) {
+	if (clone_root && IS_ALIGNED(offset + len, bs)) {
 		ret = send_clone(sctx, offset, len, clone_root);
 	} else if (sctx->flags & BTRFS_SEND_FLAG_NO_FILE_DATA) {
 		ret = send_update_extent(sctx, offset, len);

commit 8e56338d7d0ee38ecae86d35dae43020356acca1
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Tue Jan 7 17:26:57 2014 +0800

    Btrfs: remove unnecessary transaction commit before send
    
    We will finish orphan cleanups during snapshot, so we don't
    have to commit transaction here.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Reviewed-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 4e2461b857f3..591063dac0e6 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4775,35 +4775,6 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	 */
 	WARN_ON(send_root->orphan_cleanup_state != ORPHAN_CLEANUP_DONE);
 
-	/*
-	 * If we just created this root we need to make sure that the orphan
-	 * cleanup has been done and committed since we search the commit root,
-	 * so check its commit root transid with our otransid and if they match
-	 * commit the transaction to make sure everything is updated.
-	 */
-	down_read(&send_root->fs_info->extent_commit_sem);
-	if (btrfs_header_generation(send_root->commit_root) ==
-	    btrfs_root_otransid(&send_root->root_item)) {
-		struct btrfs_trans_handle *trans;
-
-		up_read(&send_root->fs_info->extent_commit_sem);
-
-		trans = btrfs_attach_transaction_barrier(send_root);
-		if (IS_ERR(trans)) {
-			if (PTR_ERR(trans) != -ENOENT) {
-				ret = PTR_ERR(trans);
-				goto out;
-			}
-			/* ENOENT means theres no transaction */
-		} else {
-			ret = btrfs_commit_transaction(trans, send_root);
-			if (ret)
-				goto out;
-		}
-	} else {
-		up_read(&send_root->fs_info->extent_commit_sem);
-	}
-
 	/*
 	 * Userspace tools do the checks and warn the user if it's
 	 * not RO.

commit 18f687d538449373c37cbe52b03f5f3d42b7c7ed
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Tue Jan 7 17:25:19 2014 +0800

    Btrfs: fix protection between send and root deletion
    
    We should gurantee that parent and clone roots can not be destroyed
    during send, for this we have two ideas.
    
    1.by holding @subvol_sem, this might be a nightmare, because it will
    block all subvolumes deletion for a long time.
    
    2.Miao pointed out we can reuse @send_in_progress, that mean we will
    skip snapshot deletion if root sending is in progress.
    
    Here we adopt the second approach since it won't block other subvolumes
    deletion for a long time.
    
    Besides in btrfs_clean_one_deleted_snapshot(), we only check first root
    , if this root is involved in send, we return directly rather than
    continue to check.There are several reasons about it:
    
    1.this case happen seldomly.
    2.after sending,cleaner thread can continue to drop that root.
    3.make code simple
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Reviewed-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 5b6978516461..4e2461b857f3 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4753,6 +4753,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	u64 *clone_sources_tmp = NULL;
 	int clone_sources_to_rollback = 0;
 	int sort_clone_roots = 0;
+	int index;
 
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
@@ -4893,8 +4894,12 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			key.objectid = clone_sources_tmp[i];
 			key.type = BTRFS_ROOT_ITEM_KEY;
 			key.offset = (u64)-1;
+
+			index = srcu_read_lock(&fs_info->subvol_srcu);
+
 			clone_root = btrfs_read_fs_root_no_name(fs_info, &key);
 			if (IS_ERR(clone_root)) {
+				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = PTR_ERR(clone_root);
 				goto out;
 			}
@@ -4903,10 +4908,13 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			clone_root->send_in_progress++;
 			if (!btrfs_root_readonly(clone_root)) {
 				spin_unlock(&clone_root->root_item_lock);
+				srcu_read_unlock(&fs_info->subvol_srcu, index);
 				ret = -EPERM;
 				goto out;
 			}
 			spin_unlock(&clone_root->root_item_lock);
+			srcu_read_unlock(&fs_info->subvol_srcu, index);
+
 			sctx->clone_roots[i].root = clone_root;
 		}
 		vfree(clone_sources_tmp);
@@ -4917,19 +4925,27 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		key.objectid = arg->parent_root;
 		key.type = BTRFS_ROOT_ITEM_KEY;
 		key.offset = (u64)-1;
+
+		index = srcu_read_lock(&fs_info->subvol_srcu);
+
 		sctx->parent_root = btrfs_read_fs_root_no_name(fs_info, &key);
 		if (IS_ERR(sctx->parent_root)) {
+			srcu_read_unlock(&fs_info->subvol_srcu, index);
 			ret = PTR_ERR(sctx->parent_root);
 			goto out;
 		}
+
 		spin_lock(&sctx->parent_root->root_item_lock);
 		sctx->parent_root->send_in_progress++;
 		if (!btrfs_root_readonly(sctx->parent_root)) {
 			spin_unlock(&sctx->parent_root->root_item_lock);
+			srcu_read_unlock(&fs_info->subvol_srcu, index);
 			ret = -EPERM;
 			goto out;
 		}
 		spin_unlock(&sctx->parent_root->root_item_lock);
+
+		srcu_read_unlock(&fs_info->subvol_srcu, index);
 	}
 
 	/*

commit 896c14f97f700aec6565154f2451605d7c5ce3ed
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Tue Jan 7 17:25:18 2014 +0800

    Btrfs: fix wrong send_in_progress accounting
    
    Steps to reproduce:
     # mkfs.btrfs -f /dev/sda8
     # mount /dev/sda8 /mnt
     # btrfs sub snapshot -r /mnt /mnt/snap1
     # btrfs sub snapshot -r /mnt /mnt/snap2
     # btrfs send /mnt/snap1 -p /mnt/snap2 -f /mnt/1
     # dmesg
    
    The problem is that we will sort clone roots(include @send_root), it
    might push @send_root before thus @send_root's @send_in_progress will
    be decreased twice.
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index bff0b1ac3be7..5b6978516461 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4752,6 +4752,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	u32 i;
 	u64 *clone_sources_tmp = NULL;
 	int clone_sources_to_rollback = 0;
+	int sort_clone_roots = 0;
 
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
@@ -4942,6 +4943,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	sort(sctx->clone_roots, sctx->clone_roots_cnt,
 			sizeof(*sctx->clone_roots), __clone_root_cmp_sort,
 			NULL);
+	sort_clone_roots = 1;
 
 	ret = send_subvol(sctx);
 	if (ret < 0)
@@ -4957,11 +4959,19 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	}
 
 out:
-	for (i = 0; sctx && i < clone_sources_to_rollback; i++)
-		btrfs_root_dec_send_in_progress(sctx->clone_roots[i].root);
+	if (sort_clone_roots) {
+		for (i = 0; i < sctx->clone_roots_cnt; i++)
+			btrfs_root_dec_send_in_progress(
+					sctx->clone_roots[i].root);
+	} else {
+		for (i = 0; sctx && i < clone_sources_to_rollback; i++)
+			btrfs_root_dec_send_in_progress(
+					sctx->clone_roots[i].root);
+
+		btrfs_root_dec_send_in_progress(send_root);
+	}
 	if (sctx && !IS_ERR_OR_NULL(sctx->parent_root))
 		btrfs_root_dec_send_in_progress(sctx->parent_root);
-	btrfs_root_dec_send_in_progress(send_root);
 
 	kfree(arg);
 	vfree(clone_sources_tmp);

commit efe120a067c8674a8ae21b194f0e68f098b61ee2
Author: Frank Holton <fholton@gmail.com>
Date:   Fri Dec 20 11:37:06 2013 -0500

    Btrfs: convert printk to btrfs_ and fix BTRFS prefix
    
    Convert all applicable cases of printk and pr_* to the btrfs_* macros.
    
    Fix all uses of the BTRFS prefix.
    
    Signed-off-by: Frank Holton <fholton@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 8877adc45394..bff0b1ac3be7 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1234,7 +1234,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	if (!backref_ctx->found_itself) {
 		/* found a bug in backref code? */
 		ret = -EIO;
-		printk(KERN_ERR "btrfs: ERROR did not find backref in "
+		btrfs_err(sctx->send_root->fs_info, "did not find backref in "
 				"send_root. inode=%llu, offset=%llu, "
 				"disk_byte=%llu found extent=%llu\n",
 				ino, data_offset, disk_byte, found_key.objectid);
@@ -4648,7 +4648,7 @@ static int full_send_tree(struct send_ctx *sctx)
 	spin_unlock(&send_root->root_item_lock);
 
 	if (ctransid != start_ctransid) {
-		WARN(1, KERN_WARNING "btrfs: the root that you're trying to "
+		WARN(1, KERN_WARNING "BTRFS: the root that you're trying to "
 				     "send was modified in between. This is "
 				     "probably a bug.\n");
 		ret = -EIO;

commit 66ef7d65c3fc6e5300b9359f1c6537efb23781bb
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Dec 17 15:07:20 2013 +0100

    btrfs: check balance of send_in_progress
    
    Warn if the balance goes below zero, which appears to be unlikely
    though. Otherwise cleans up the code a bit.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 78a43b2e5c8e..8877adc45394 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4725,6 +4725,21 @@ static int send_subvol(struct send_ctx *sctx)
 	return ret;
 }
 
+static void btrfs_root_dec_send_in_progress(struct btrfs_root* root)
+{
+	spin_lock(&root->root_item_lock);
+	root->send_in_progress--;
+	/*
+	 * Not much left to do, we don't know why it's unbalanced and
+	 * can't blindly reset it to 0.
+	 */
+	if (root->send_in_progress < 0)
+		btrfs_err(root->fs_info,
+			"send_in_progres unbalanced %d root %llu\n",
+			root->send_in_progress, root->root_key.objectid);
+	spin_unlock(&root->root_item_lock);
+}
+
 long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 {
 	int ret = 0;
@@ -4942,24 +4957,11 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	}
 
 out:
-	for (i = 0; sctx && i < clone_sources_to_rollback; i++) {
-		struct btrfs_root *r = sctx->clone_roots[i].root;
-
-		spin_lock(&r->root_item_lock);
-		r->send_in_progress--;
-		spin_unlock(&r->root_item_lock);
-	}
-	if (sctx && !IS_ERR_OR_NULL(sctx->parent_root)) {
-		struct btrfs_root *r = sctx->parent_root;
-
-		spin_lock(&r->root_item_lock);
-		r->send_in_progress--;
-		spin_unlock(&r->root_item_lock);
-	}
-
-	spin_lock(&send_root->root_item_lock);
-	send_root->send_in_progress--;
-	spin_unlock(&send_root->root_item_lock);
+	for (i = 0; sctx && i < clone_sources_to_rollback; i++)
+		btrfs_root_dec_send_in_progress(sctx->clone_roots[i].root);
+	if (sctx && !IS_ERR_OR_NULL(sctx->parent_root))
+		btrfs_root_dec_send_in_progress(sctx->parent_root);
+	btrfs_root_dec_send_in_progress(send_root);
 
 	kfree(arg);
 	vfree(clone_sources_tmp);

commit 41ce9970a8a6a362ae8df145f7a03d789e9ef9d2
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Tue Dec 17 19:57:21 2013 +0800

    Btrfs: remove transaction from btrfs send
    
    Since daivd did the work that force us to use readonly snapshot,
    we can safely remove transaction protection from btrfs send.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 572e8c758712..78a43b2e5c8e 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4618,7 +4618,6 @@ static int changed_cb(struct btrfs_root *left_root,
 static int full_send_tree(struct send_ctx *sctx)
 {
 	int ret;
-	struct btrfs_trans_handle *trans = NULL;
 	struct btrfs_root *send_root = sctx->send_root;
 	struct btrfs_key key;
 	struct btrfs_key found_key;
@@ -4640,19 +4639,6 @@ static int full_send_tree(struct send_ctx *sctx)
 	key.type = BTRFS_INODE_ITEM_KEY;
 	key.offset = 0;
 
-join_trans:
-	/*
-	 * We need to make sure the transaction does not get committed
-	 * while we do anything on commit roots. Join a transaction to prevent
-	 * this.
-	 */
-	trans = btrfs_join_transaction(send_root);
-	if (IS_ERR(trans)) {
-		ret = PTR_ERR(trans);
-		trans = NULL;
-		goto out;
-	}
-
 	/*
 	 * Make sure the tree has not changed after re-joining. We detect this
 	 * by comparing start_ctransid and ctransid. They should always match.
@@ -4676,19 +4662,6 @@ static int full_send_tree(struct send_ctx *sctx)
 		goto out_finish;
 
 	while (1) {
-		/*
-		 * When someone want to commit while we iterate, end the
-		 * joined transaction and rejoin.
-		 */
-		if (btrfs_should_end_transaction(trans, send_root)) {
-			ret = btrfs_end_transaction(trans, send_root);
-			trans = NULL;
-			if (ret < 0)
-				goto out;
-			btrfs_release_path(path);
-			goto join_trans;
-		}
-
 		eb = path->nodes[0];
 		slot = path->slots[0];
 		btrfs_item_key_to_cpu(eb, &found_key, slot);
@@ -4716,12 +4689,6 @@ static int full_send_tree(struct send_ctx *sctx)
 
 out:
 	btrfs_free_path(path);
-	if (trans) {
-		if (!ret)
-			ret = btrfs_end_transaction(trans, send_root);
-		else
-			btrfs_end_transaction(trans, send_root);
-	}
 	return ret;
 }
 

commit 2c68653787f91c62f8891209dc1f617088c822e4
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Dec 16 17:34:17 2013 +0100

    btrfs: Check read-only status of roots during send
    
    All the subvolues that are involved in send must be read-only during the
    whole operation. The ioctl SUBVOL_SETFLAGS could be used to change the
    status to read-write and the result of send stream is undefined if the
    data change unexpectedly.
    
    Fix that by adding a refcount for all involved roots and verify that
    there's no send in progress during SUBVOL_SETFLAGS ioctl call that does
    read-only -> read-write transition.
    
    We need refcounts because there are no restrictions on number of send
    parallel operations currently run on a single subvolume, be it source,
    parent or one of the multiple clone sources.
    
    Kernel is silent when the RO checks fail and returns EPERM. The same set
    of checks is done already in userspace before send starts.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e98c9bc003c8..572e8c758712 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4769,6 +4769,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	struct send_ctx *sctx = NULL;
 	u32 i;
 	u64 *clone_sources_tmp = NULL;
+	int clone_sources_to_rollback = 0;
 
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
@@ -4776,6 +4777,14 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	send_root = BTRFS_I(file_inode(mnt_file))->root;
 	fs_info = send_root->fs_info;
 
+	/*
+	 * The subvolume must remain read-only during send, protect against
+	 * making it RW.
+	 */
+	spin_lock(&send_root->root_item_lock);
+	send_root->send_in_progress++;
+	spin_unlock(&send_root->root_item_lock);
+
 	/*
 	 * This is done when we lookup the root, it should already be complete
 	 * by the time we get here.
@@ -4811,6 +4820,15 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		up_read(&send_root->fs_info->extent_commit_sem);
 	}
 
+	/*
+	 * Userspace tools do the checks and warn the user if it's
+	 * not RO.
+	 */
+	if (!btrfs_root_readonly(send_root)) {
+		ret = -EPERM;
+		goto out;
+	}
+
 	arg = memdup_user(arg_, sizeof(*arg));
 	if (IS_ERR(arg)) {
 		ret = PTR_ERR(arg);
@@ -4897,6 +4915,15 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 				ret = PTR_ERR(clone_root);
 				goto out;
 			}
+			clone_sources_to_rollback = i + 1;
+			spin_lock(&clone_root->root_item_lock);
+			clone_root->send_in_progress++;
+			if (!btrfs_root_readonly(clone_root)) {
+				spin_unlock(&clone_root->root_item_lock);
+				ret = -EPERM;
+				goto out;
+			}
+			spin_unlock(&clone_root->root_item_lock);
 			sctx->clone_roots[i].root = clone_root;
 		}
 		vfree(clone_sources_tmp);
@@ -4912,6 +4939,14 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			ret = PTR_ERR(sctx->parent_root);
 			goto out;
 		}
+		spin_lock(&sctx->parent_root->root_item_lock);
+		sctx->parent_root->send_in_progress++;
+		if (!btrfs_root_readonly(sctx->parent_root)) {
+			spin_unlock(&sctx->parent_root->root_item_lock);
+			ret = -EPERM;
+			goto out;
+		}
+		spin_unlock(&sctx->parent_root->root_item_lock);
 	}
 
 	/*
@@ -4940,6 +4975,25 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	}
 
 out:
+	for (i = 0; sctx && i < clone_sources_to_rollback; i++) {
+		struct btrfs_root *r = sctx->clone_roots[i].root;
+
+		spin_lock(&r->root_item_lock);
+		r->send_in_progress--;
+		spin_unlock(&r->root_item_lock);
+	}
+	if (sctx && !IS_ERR_OR_NULL(sctx->parent_root)) {
+		struct btrfs_root *r = sctx->parent_root;
+
+		spin_lock(&r->root_item_lock);
+		r->send_in_progress--;
+		spin_unlock(&r->root_item_lock);
+	}
+
+	spin_lock(&send_root->root_item_lock);
+	send_root->send_in_progress--;
+	spin_unlock(&send_root->root_item_lock);
+
 	kfree(arg);
 	vfree(clone_sources_tmp);
 

commit a8d89f5ba0e17622cde8f5ac48ef745a9fb1e13b
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Dec 16 17:34:14 2013 +0100

    btrfs: remove unused mnt from send_ctx
    
    Unused since ed2590953bd06b892f0411fc94e19175d32f197a
    "Btrfs: stop using vfs_read in send".
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 8230d11f2cca..e98c9bc003c8 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -88,8 +88,6 @@ struct send_ctx {
 	u64 cmd_send_size[BTRFS_SEND_C_MAX + 1];
 	u64 flags;	/* 'flags' member of btrfs_ioctl_send_args is u64 */
 
-	struct vfsmount *mnt;
-
 	struct btrfs_root *send_root;
 	struct btrfs_root *parent_root;
 	struct clone_root *clone_roots;
@@ -4851,8 +4849,6 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		goto out;
 	}
 
-	sctx->mnt = mnt_file->f_path.mnt;
-
 	sctx->send_root = send_root;
 	sctx->clone_roots_cnt = arg->clone_sources_count;
 

commit 95bc79d50d0ec20c0cdb071629dc3f276a053782
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Dec 16 17:34:10 2013 +0100

    btrfs: send: clean up dead code
    
    Remove ifdefed code:
    
    - tlv_put for 8, 16 and 32, add a generic tempalte if needed in future
    - tlv_put_timespec - the btrfs_timespec fields are used
    - fs_path_remove obsoleted long ago
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 1896e394d59f..8230d11f2cca 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -344,16 +344,6 @@ static int fs_path_add_from_extent_buffer(struct fs_path *p,
 	return ret;
 }
 
-#if 0
-static void fs_path_remove(struct fs_path *p)
-{
-	BUG_ON(p->reversed);
-	while (p->start != p->end && *p->end != '/')
-		p->end--;
-	*p->end = 0;
-}
-#endif
-
 static int fs_path_copy(struct fs_path *p, struct fs_path *from)
 {
 	int ret;
@@ -444,30 +434,15 @@ static int tlv_put(struct send_ctx *sctx, u16 attr, const void *data, int len)
 	return 0;
 }
 
-#if 0
-static int tlv_put_u8(struct send_ctx *sctx, u16 attr, u8 value)
-{
-	return tlv_put(sctx, attr, &value, sizeof(value));
-}
-
-static int tlv_put_u16(struct send_ctx *sctx, u16 attr, u16 value)
-{
-	__le16 tmp = cpu_to_le16(value);
-	return tlv_put(sctx, attr, &tmp, sizeof(tmp));
-}
-
-static int tlv_put_u32(struct send_ctx *sctx, u16 attr, u32 value)
-{
-	__le32 tmp = cpu_to_le32(value);
-	return tlv_put(sctx, attr, &tmp, sizeof(tmp));
-}
-#endif
+#define TLV_PUT_DEFINE_INT(bits) \
+	static int tlv_put_u##bits(struct send_ctx *sctx,	 	\
+			u##bits attr, u##bits value)			\
+	{								\
+		__le##bits __tmp = cpu_to_le##bits(value);		\
+		return tlv_put(sctx, attr, &__tmp, sizeof(__tmp));	\
+	}
 
-static int tlv_put_u64(struct send_ctx *sctx, u16 attr, u64 value)
-{
-	__le64 tmp = cpu_to_le64(value);
-	return tlv_put(sctx, attr, &tmp, sizeof(tmp));
-}
+TLV_PUT_DEFINE_INT(64)
 
 static int tlv_put_string(struct send_ctx *sctx, u16 attr,
 			  const char *str, int len)
@@ -483,17 +458,6 @@ static int tlv_put_uuid(struct send_ctx *sctx, u16 attr,
 	return tlv_put(sctx, attr, uuid, BTRFS_UUID_SIZE);
 }
 
-#if 0
-static int tlv_put_timespec(struct send_ctx *sctx, u16 attr,
-			    struct timespec *ts)
-{
-	struct btrfs_timespec bts;
-	bts.sec = cpu_to_le64(ts->tv_sec);
-	bts.nsec = cpu_to_le32(ts->tv_nsec);
-	return tlv_put(sctx, attr, &bts, sizeof(bts));
-}
-#endif
-
 static int tlv_put_btrfs_timespec(struct send_ctx *sctx, u16 attr,
 				  struct extent_buffer *eb,
 				  struct btrfs_timespec *ts)
@@ -541,12 +505,6 @@ static int tlv_put_btrfs_timespec(struct send_ctx *sctx, u16 attr,
 		if (ret < 0) \
 			goto tlv_put_failure; \
 	} while (0)
-#define TLV_PUT_TIMESPEC(sctx, attrtype, ts) \
-	do { \
-		ret = tlv_put_timespec(sctx, attrtype, ts); \
-		if (ret < 0) \
-			goto tlv_put_failure; \
-	} while (0)
 #define TLV_PUT_BTRFS_TIMESPEC(sctx, attrtype, eb, ts) \
 	do { \
 		ret = tlv_put_btrfs_timespec(sctx, attrtype, eb, ts); \

commit 5a0f4e2c2b47a755e37dbbb6f691e6504e3147b3
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Tue Dec 3 15:55:48 2013 +0000

    Btrfs: fix pass of transid with wrong endianness in send.c
    
    fs/btrfs/send.c:2190:9: warning: incorrect type in argument 3 (different base types)
    fs/btrfs/send.c:2190:9:    expected unsigned long long [unsigned] [usertype] value
    fs/btrfs/send.c:2190:9:    got restricted __le64 [usertype] ctransid
    fs/btrfs/send.c:2195:17: warning: incorrect type in argument 3 (different base types)
    fs/btrfs/send.c:2195:17:    expected unsigned long long [unsigned] [usertype] value
    fs/btrfs/send.c:2195:17:    got restricted __le64 [usertype] ctransid
    fs/btrfs/send.c:3716:9: warning: incorrect type in argument 3 (different base types)
    fs/btrfs/send.c:3716:9:    expected unsigned long long [unsigned] [usertype] value
    fs/btrfs/send.c:3716:9:    got restricted __le64 [usertype] ctransid
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 29803b4129fc..1896e394d59f 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2188,12 +2188,12 @@ static int send_subvol_begin(struct send_ctx *sctx)
 	TLV_PUT_UUID(sctx, BTRFS_SEND_A_UUID,
 			sctx->send_root->root_item.uuid);
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_CTRANSID,
-			sctx->send_root->root_item.ctransid);
+		    le64_to_cpu(sctx->send_root->root_item.ctransid));
 	if (parent_root) {
 		TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
 				sctx->parent_root->root_item.uuid);
 		TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_CTRANSID,
-				sctx->parent_root->root_item.ctransid);
+			    le64_to_cpu(sctx->parent_root->root_item.ctransid));
 	}
 
 	ret = send_cmd(sctx);
@@ -3714,7 +3714,7 @@ verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
 	TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
 			clone_root->root->root_item.uuid);
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_CTRANSID,
-			clone_root->root->root_item.ctransid);
+		    le64_to_cpu(clone_root->root->root_item.ctransid));
 	TLV_PUT_PATH(sctx, BTRFS_SEND_A_CLONE_PATH, p);
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_OFFSET,
 			clone_root->offset);

commit 16e7549f045d33b0c5b0ebf19d08439e9221d40c
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Oct 22 12:18:51 2013 -0400

    Btrfs: incompatible format change to remove hole extents
    
    Btrfs has always had these filler extent data items for holes in inodes.  This
    has made somethings very easy, like logging hole punches and sending hole
    punches.  However for large holey files these extent data items are pure
    overhead.  So add an incompatible feature to no longer add hole extents to
    reduce the amount of metadata used by these sort of files.  This has a few
    changes for logging and send obviously since they will need to detect holes and
    log/send the holes if there are any.  I've tested this thoroughly with xfstests
    and it doesn't cause any issues with and without the incompat format set.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 945d1db98f26..29803b4129fc 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -111,6 +111,7 @@ struct send_ctx {
 	int cur_inode_deleted;
 	u64 cur_inode_size;
 	u64 cur_inode_mode;
+	u64 cur_inode_last_extent;
 
 	u64 send_progress;
 
@@ -145,6 +146,13 @@ struct name_cache_entry {
 	char name[];
 };
 
+static int need_send_hole(struct send_ctx *sctx)
+{
+	return (sctx->parent_root && !sctx->cur_inode_new &&
+		!sctx->cur_inode_new_gen && !sctx->cur_inode_deleted &&
+		S_ISREG(sctx->cur_inode_mode));
+}
+
 static void fs_path_reset(struct fs_path *p)
 {
 	if (p->reversed) {
@@ -3752,6 +3760,39 @@ static int send_update_extent(struct send_ctx *sctx,
 	return ret;
 }
 
+static int send_hole(struct send_ctx *sctx, u64 end)
+{
+	struct fs_path *p = NULL;
+	u64 offset = sctx->cur_inode_last_extent;
+	u64 len;
+	int ret = 0;
+
+	p = fs_path_alloc();
+	if (!p)
+		return -ENOMEM;
+	memset(sctx->read_buf, 0, BTRFS_SEND_READ_SIZE);
+	while (offset < end) {
+		len = min_t(u64, end - offset, BTRFS_SEND_READ_SIZE);
+
+		ret = begin_cmd(sctx, BTRFS_SEND_C_WRITE);
+		if (ret < 0)
+			break;
+		ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
+		if (ret < 0)
+			break;
+		TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
+		TLV_PUT_U64(sctx, BTRFS_SEND_A_FILE_OFFSET, offset);
+		TLV_PUT(sctx, BTRFS_SEND_A_DATA, sctx->read_buf, len);
+		ret = send_cmd(sctx);
+		if (ret < 0)
+			break;
+		offset += len;
+	}
+tlv_put_failure:
+	fs_path_free(p);
+	return ret;
+}
+
 static int send_write_or_clone(struct send_ctx *sctx,
 			       struct btrfs_path *path,
 			       struct btrfs_key *key,
@@ -3979,6 +4020,84 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 	return ret;
 }
 
+static int get_last_extent(struct send_ctx *sctx, u64 offset)
+{
+	struct btrfs_path *path;
+	struct btrfs_root *root = sctx->send_root;
+	struct btrfs_file_extent_item *fi;
+	struct btrfs_key key;
+	u64 extent_end;
+	u8 type;
+	int ret;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	sctx->cur_inode_last_extent = 0;
+
+	key.objectid = sctx->cur_ino;
+	key.type = BTRFS_EXTENT_DATA_KEY;
+	key.offset = offset;
+	ret = btrfs_search_slot_for_read(root, &key, path, 0, 1);
+	if (ret < 0)
+		goto out;
+	ret = 0;
+	btrfs_item_key_to_cpu(path->nodes[0], &key, path->slots[0]);
+	if (key.objectid != sctx->cur_ino || key.type != BTRFS_EXTENT_DATA_KEY)
+		goto out;
+
+	fi = btrfs_item_ptr(path->nodes[0], path->slots[0],
+			    struct btrfs_file_extent_item);
+	type = btrfs_file_extent_type(path->nodes[0], fi);
+	if (type == BTRFS_FILE_EXTENT_INLINE) {
+		u64 size = btrfs_file_extent_inline_len(path->nodes[0], fi);
+		extent_end = ALIGN(key.offset + size,
+				   sctx->send_root->sectorsize);
+	} else {
+		extent_end = key.offset +
+			btrfs_file_extent_num_bytes(path->nodes[0], fi);
+	}
+	sctx->cur_inode_last_extent = extent_end;
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+static int maybe_send_hole(struct send_ctx *sctx, struct btrfs_path *path,
+			   struct btrfs_key *key)
+{
+	struct btrfs_file_extent_item *fi;
+	u64 extent_end;
+	u8 type;
+	int ret = 0;
+
+	if (sctx->cur_ino != key->objectid || !need_send_hole(sctx))
+		return 0;
+
+	if (sctx->cur_inode_last_extent == (u64)-1) {
+		ret = get_last_extent(sctx, key->offset - 1);
+		if (ret)
+			return ret;
+	}
+
+	fi = btrfs_item_ptr(path->nodes[0], path->slots[0],
+			    struct btrfs_file_extent_item);
+	type = btrfs_file_extent_type(path->nodes[0], fi);
+	if (type == BTRFS_FILE_EXTENT_INLINE) {
+		u64 size = btrfs_file_extent_inline_len(path->nodes[0], fi);
+		extent_end = ALIGN(key->offset + size,
+				   sctx->send_root->sectorsize);
+	} else {
+		extent_end = key->offset +
+			btrfs_file_extent_num_bytes(path->nodes[0], fi);
+	}
+	if (sctx->cur_inode_last_extent < key->offset)
+		ret = send_hole(sctx, key->offset);
+	sctx->cur_inode_last_extent = extent_end;
+	return ret;
+}
+
 static int process_extent(struct send_ctx *sctx,
 			  struct btrfs_path *path,
 			  struct btrfs_key *key)
@@ -3995,7 +4114,7 @@ static int process_extent(struct send_ctx *sctx,
 			goto out;
 		if (ret) {
 			ret = 0;
-			goto out;
+			goto out_hole;
 		}
 	} else {
 		struct btrfs_file_extent_item *ei;
@@ -4031,7 +4150,10 @@ static int process_extent(struct send_ctx *sctx,
 		goto out;
 
 	ret = send_write_or_clone(sctx, path, key, found_clone);
-
+	if (ret)
+		goto out;
+out_hole:
+	ret = maybe_send_hole(sctx, path, key);
 out:
 	return ret;
 }
@@ -4157,6 +4279,19 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 	}
 
 	if (S_ISREG(sctx->cur_inode_mode)) {
+		if (need_send_hole(sctx)) {
+			if (sctx->cur_inode_last_extent == (u64)-1) {
+				ret = get_last_extent(sctx, (u64)-1);
+				if (ret)
+					goto out;
+			}
+			if (sctx->cur_inode_last_extent <
+			    sctx->cur_inode_size) {
+				ret = send_hole(sctx, sctx->cur_inode_size);
+				if (ret)
+					goto out;
+			}
+		}
 		ret = send_truncate(sctx, sctx->cur_ino, sctx->cur_inode_gen,
 				sctx->cur_inode_size);
 		if (ret < 0)
@@ -4200,6 +4335,7 @@ static int changed_inode(struct send_ctx *sctx,
 
 	sctx->cur_ino = key->objectid;
 	sctx->cur_inode_new_gen = 0;
+	sctx->cur_inode_last_extent = (u64)-1;
 
 	/*
 	 * Set send_progress to current inode. This will tell all get_cur_xxx
@@ -4480,14 +4616,18 @@ static int changed_cb(struct btrfs_root *left_root,
 	struct send_ctx *sctx = ctx;
 
 	if (result == BTRFS_COMPARE_TREE_SAME) {
-		if (key->type != BTRFS_INODE_REF_KEY &&
-		    key->type != BTRFS_INODE_EXTREF_KEY)
-			return 0;
-		ret = compare_refs(sctx, left_path, key);
-		if (!ret)
+		if (key->type == BTRFS_INODE_REF_KEY ||
+		    key->type == BTRFS_INODE_EXTREF_KEY) {
+			ret = compare_refs(sctx, left_path, key);
+			if (!ret)
+				return 0;
+			if (ret < 0)
+				return ret;
+		} else if (key->type == BTRFS_EXTENT_DATA_KEY) {
+			return maybe_send_hole(sctx, left_path, key);
+		} else {
 			return 0;
-		if (ret < 0)
-			return ret;
+		}
 		result = BTRFS_COMPARE_TREE_CHANGED;
 		ret = 0;
 	}

commit 700ff4f095d78af0998953e922e041d75254518b
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Thu Jan 10 03:57:25 2013 -0500

    Btrfs: fix access_ok() check in btrfs_ioctl_send()
    
    The closing parenthesis is in the wrong place.  We want to check
    "sizeof(*arg->clone_sources) * arg->clone_sources_count" instead of
    "sizeof(*arg->clone_sources * arg->clone_sources_count)".
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: Jie Liu <jeff.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    cc: stable@vger.kernel.org

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 6837fe87f3a6..945d1db98f26 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4723,8 +4723,8 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	}
 
 	if (!access_ok(VERIFY_READ, arg->clone_sources,
-			sizeof(*arg->clone_sources *
-			arg->clone_sources_count))) {
+			sizeof(*arg->clone_sources) *
+			arg->clone_sources_count)) {
 		ret = -EFAULT;
 		goto out;
 	}

commit 007d31f755294b9db69c3d18e90d6edae9f1604d
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Oct 31 16:49:02 2013 -0400

    Btrfs: check file extent type before anything else
    
    I hit this problem with my no holes patch and it made me realize what the
    problem was for bz 60834.  If the first item in the leaf is an inline extent and
    we try to read anything starting from disk_bytenr onward we will read off the
    end of the leaf.  So we need to check to see what it's type is, and if it's not
    REG we can just break out.  This should fix this problem.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ec2f02435287..6837fe87f3a6 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3902,16 +3902,16 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 	while (key.offset < ekey->offset + left_len) {
 		ei = btrfs_item_ptr(eb, slot, struct btrfs_file_extent_item);
 		right_type = btrfs_file_extent_type(eb, ei);
-		right_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
-		right_len = btrfs_file_extent_num_bytes(eb, ei);
-		right_offset = btrfs_file_extent_offset(eb, ei);
-		right_gen = btrfs_file_extent_generation(eb, ei);
-
 		if (right_type != BTRFS_FILE_EXTENT_REG) {
 			ret = 0;
 			goto out;
 		}
 
+		right_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
+		right_len = btrfs_file_extent_num_bytes(eb, ei);
+		right_offset = btrfs_file_extent_offset(eb, ei);
+		right_gen = btrfs_file_extent_generation(eb, ei);
+
 		/*
 		 * Are we at extent 8? If yes, we know the extent is changed.
 		 * This may only happen on the first iteration.

commit fae7f21cece9a4c181a8d8131870c7247e153f65
Author: Dulshani Gunawardhana <dulshani.gunawardhana89@gmail.com>
Date:   Thu Oct 31 10:30:08 2013 +0530

    btrfs: Use WARN_ON()'s return value in place of WARN_ON(1)
    
    Use WARN_ON()'s return value in place of WARN_ON(1) for cleaner source
    code that outputs a more descriptive warnings. Also fix the styling
    warning of redundant braces that came up as a result of this fix.
    
    Signed-off-by: Dulshani Gunawardhana <dulshani.gunawardhana89@gmail.com>
    Reviewed-by: Zach Brown <zab@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e26a3a62fd3f..ec2f02435287 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -564,10 +564,8 @@ static int begin_cmd(struct send_ctx *sctx, int cmd)
 {
 	struct btrfs_cmd_header *hdr;
 
-	if (!sctx->send_buf) {
-		WARN_ON(1);
+	if (WARN_ON(!sctx->send_buf))
 		return -EINVAL;
-	}
 
 	BUG_ON(sctx->send_size);
 

commit ed2590953bd06b892f0411fc94e19175d32f197a
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Oct 25 11:36:01 2013 -0400

    Btrfs: stop using vfs_read in send
    
    Apparently we don't actually close the files until we return to userspace, so
    stop using vfs_read in send.  This is actually better for us since we can avoid
    all the extra logic of holding the file we're sending open and making sure to
    clean it up.  This will fix people who have been hitting too many files open
    errors when trying to send.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 0a894399be16..e26a3a62fd3f 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -121,7 +121,6 @@ struct send_ctx {
 	struct list_head name_cache_list;
 	int name_cache_size;
 
-	struct file *cur_inode_filp;
 	char *read_buf;
 };
 
@@ -2119,77 +2118,6 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 	return ret;
 }
 
-/*
- * Called for regular files when sending extents data. Opens a struct file
- * to read from the file.
- */
-static int open_cur_inode_file(struct send_ctx *sctx)
-{
-	int ret = 0;
-	struct btrfs_key key;
-	struct path path;
-	struct inode *inode;
-	struct dentry *dentry;
-	struct file *filp;
-	int new = 0;
-
-	if (sctx->cur_inode_filp)
-		goto out;
-
-	key.objectid = sctx->cur_ino;
-	key.type = BTRFS_INODE_ITEM_KEY;
-	key.offset = 0;
-
-	inode = btrfs_iget(sctx->send_root->fs_info->sb, &key, sctx->send_root,
-			&new);
-	if (IS_ERR(inode)) {
-		ret = PTR_ERR(inode);
-		goto out;
-	}
-
-	dentry = d_obtain_alias(inode);
-	inode = NULL;
-	if (IS_ERR(dentry)) {
-		ret = PTR_ERR(dentry);
-		goto out;
-	}
-
-	path.mnt = sctx->mnt;
-	path.dentry = dentry;
-	filp = dentry_open(&path, O_RDONLY | O_LARGEFILE, current_cred());
-	dput(dentry);
-	dentry = NULL;
-	if (IS_ERR(filp)) {
-		ret = PTR_ERR(filp);
-		goto out;
-	}
-	sctx->cur_inode_filp = filp;
-
-out:
-	/*
-	 * no xxxput required here as every vfs op
-	 * does it by itself on failure
-	 */
-	return ret;
-}
-
-/*
- * Closes the struct file that was created in open_cur_inode_file
- */
-static int close_cur_inode_file(struct send_ctx *sctx)
-{
-	int ret = 0;
-
-	if (!sctx->cur_inode_filp)
-		goto out;
-
-	ret = filp_close(sctx->cur_inode_filp, NULL);
-	sctx->cur_inode_filp = NULL;
-
-out:
-	return ret;
-}
-
 /*
  * Sends a BTRFS_SEND_C_SUBVOL command/item to userspace
  */
@@ -3622,6 +3550,72 @@ static int process_all_new_xattrs(struct send_ctx *sctx)
 	return ret;
 }
 
+static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
+{
+	struct btrfs_root *root = sctx->send_root;
+	struct btrfs_fs_info *fs_info = root->fs_info;
+	struct inode *inode;
+	struct page *page;
+	char *addr;
+	struct btrfs_key key;
+	pgoff_t index = offset >> PAGE_CACHE_SHIFT;
+	pgoff_t last_index;
+	unsigned pg_offset = offset & ~PAGE_CACHE_MASK;
+	ssize_t ret = 0;
+
+	key.objectid = sctx->cur_ino;
+	key.type = BTRFS_INODE_ITEM_KEY;
+	key.offset = 0;
+
+	inode = btrfs_iget(fs_info->sb, &key, root, NULL);
+	if (IS_ERR(inode))
+		return PTR_ERR(inode);
+
+	if (offset + len > i_size_read(inode)) {
+		if (offset > i_size_read(inode))
+			len = 0;
+		else
+			len = offset - i_size_read(inode);
+	}
+	if (len == 0)
+		goto out;
+
+	last_index = (offset + len - 1) >> PAGE_CACHE_SHIFT;
+	while (index <= last_index) {
+		unsigned cur_len = min_t(unsigned, len,
+					 PAGE_CACHE_SIZE - pg_offset);
+		page = find_or_create_page(inode->i_mapping, index, GFP_NOFS);
+		if (!page) {
+			ret = -ENOMEM;
+			break;
+		}
+
+		if (!PageUptodate(page)) {
+			btrfs_readpage(NULL, page);
+			lock_page(page);
+			if (!PageUptodate(page)) {
+				unlock_page(page);
+				page_cache_release(page);
+				ret = -EIO;
+				break;
+			}
+		}
+
+		addr = kmap(page);
+		memcpy(sctx->read_buf + ret, addr + pg_offset, cur_len);
+		kunmap(page);
+		unlock_page(page);
+		page_cache_release(page);
+		index++;
+		pg_offset = 0;
+		len -= cur_len;
+		ret += cur_len;
+	}
+out:
+	iput(inode);
+	return ret;
+}
+
 /*
  * Read some bytes from the current inode/file and send a write command to
  * user space.
@@ -3630,35 +3624,20 @@ static int send_write(struct send_ctx *sctx, u64 offset, u32 len)
 {
 	int ret = 0;
 	struct fs_path *p;
-	loff_t pos = offset;
-	int num_read = 0;
-	mm_segment_t old_fs;
+	ssize_t num_read = 0;
 
 	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
-	/*
-	 * vfs normally only accepts user space buffers for security reasons.
-	 * we only read from the file and also only provide the read_buf buffer
-	 * to vfs. As this buffer does not come from a user space call, it's
-	 * ok to temporary allow kernel space buffers.
-	 */
-	old_fs = get_fs();
-	set_fs(KERNEL_DS);
-
 verbose_printk("btrfs: send_write offset=%llu, len=%d\n", offset, len);
 
-	ret = open_cur_inode_file(sctx);
-	if (ret < 0)
-		goto out;
-
-	ret = vfs_read(sctx->cur_inode_filp, sctx->read_buf, len, &pos);
-	if (ret < 0)
-		goto out;
-	num_read = ret;
-	if (!num_read)
+	num_read = fill_read_buf(sctx, offset, len);
+	if (num_read <= 0) {
+		if (num_read < 0)
+			ret = num_read;
 		goto out;
+	}
 
 	ret = begin_cmd(sctx, BTRFS_SEND_C_WRITE);
 	if (ret < 0)
@@ -3677,7 +3656,6 @@ verbose_printk("btrfs: send_write offset=%llu, len=%d\n", offset, len);
 tlv_put_failure:
 out:
 	fs_path_free(p);
-	set_fs(old_fs);
 	if (ret < 0)
 		return ret;
 	return num_read;
@@ -4222,10 +4200,6 @@ static int changed_inode(struct send_ctx *sctx,
 	u64 left_gen = 0;
 	u64 right_gen = 0;
 
-	ret = close_cur_inode_file(sctx);
-	if (ret < 0)
-		goto out;
-
 	sctx->cur_ino = key->objectid;
 	sctx->cur_inode_new_gen = 0;
 
@@ -4686,11 +4660,6 @@ static int send_subvol(struct send_ctx *sctx)
 	}
 
 out:
-	if (!ret)
-		ret = close_cur_inode_file(sctx);
-	else
-		close_cur_inode_file(sctx);
-
 	free_recorded_refs(sctx);
 	return ret;
 }

commit dd3cc16b8750251ea9b1a843ce7806e82b015d5e
Author: Ross Kirk <ross.kirk@gmail.com>
Date:   Mon Sep 16 15:58:09 2013 +0100

    btrfs: drop unused parameter from btrfs_item_nr
    
    Remove unused eb parameter from btrfs_item_nr
    
    Signed-off-by: Ross Kirk <ross.kirk@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e46e0ed74925..0a894399be16 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -791,7 +791,7 @@ static int iterate_inode_ref(struct btrfs_root *root, struct btrfs_path *path,
 	if (found_key->type == BTRFS_INODE_REF_KEY) {
 		ptr = (unsigned long)btrfs_item_ptr(eb, slot,
 						    struct btrfs_inode_ref);
-		item = btrfs_item_nr(eb, slot);
+		item = btrfs_item_nr(slot);
 		total = btrfs_item_size(eb, item);
 		elem_size = sizeof(*iref);
 	} else {
@@ -905,7 +905,7 @@ static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 
 	eb = path->nodes[0];
 	slot = path->slots[0];
-	item = btrfs_item_nr(eb, slot);
+	item = btrfs_item_nr(slot);
 	di = btrfs_item_ptr(eb, slot, struct btrfs_dir_item);
 	cur = 0;
 	len = 0;

commit b7c09ad4014e3678e8cc01fdf663c9f43b272dc6
Merge: 1812997720ab d7396f07358a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 12 09:58:51 2013 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This is against 3.11-rc7, but was pulled and tested against your tree
      as of yesterday.  We do have two small incrementals queued up, but I
      wanted to get this bunch out the door before I hop on an airplane.
    
      This is a fairly large batch of fixes, performance improvements, and
      cleanups from the usual Btrfs suspects.
    
      We've included Stefan Behren's work to index subvolume UUIDs, which is
      targeted at speeding up send/receive with many subvolumes or snapshots
      in place.  It closes a long standing performance issue that was built
      in to the disk format.
    
      Mark Fasheh's offline dedup work is also here.  In this case offline
      means the FS is mounted and active, but the dedup work is not done
      inline during file IO.  This is a building block where utilities are
      able to ask the FS to dedup a series of extents.  The kernel takes
      care of verifying the data involved really is the same.  Today this
      involves reading both extents, but we'll continue to evolve the
      patches"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (118 commits)
      Btrfs: optimize key searches in btrfs_search_slot
      Btrfs: don't use an async starter for most of our workers
      Btrfs: only update disk_i_size as we remove extents
      Btrfs: fix deadlock in uuid scan kthread
      Btrfs: stop refusing the relocation of chunk 0
      Btrfs: fix memory leak of uuid_root in free_fs_info
      btrfs: reuse kbasename helper
      btrfs: return btrfs error code for dev excl ops err
      Btrfs: allow partial ordered extent completion
      Btrfs: convert all bug_ons in free-space-cache.c
      Btrfs: add support for asserts
      Btrfs: adjust the fs_devices->missing count on unmount
      Btrf: cleanup: don't check for root_refs == 0 twice
      Btrfs: fix for patch "cleanup: don't check the same thing twice"
      Btrfs: get rid of one BUG() in write_all_supers()
      Btrfs: allocate prelim_ref with a slab allocater
      Btrfs: pass gfp_t to __add_prelim_ref() to avoid always using GFP_ATOMIC
      Btrfs: fix race conditions in BTRFS_IOC_FS_INFO ioctl
      Btrfs: fix race between removing a dev and writing sbs
      Btrfs: remove ourselves from the cluster list under lock
      ...

commit ed84885d1e03839b8508ab707657d8d1002edea6
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Wed Aug 21 10:32:13 2013 +0300

    btrfs: reuse kbasename helper
    
    To get name of the file from a pathname let's use kbasename() helper. It allows
    to simplify code a bit.
    
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index cbe92da5f33b..b4b15467426b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -26,6 +26,7 @@
 #include <linux/radix-tree.h>
 #include <linux/crc32c.h>
 #include <linux/vmalloc.h>
+#include <linux/string.h>
 
 #include "send.h"
 #include "backref.h"
@@ -2601,7 +2602,6 @@ static int record_ref(struct list_head *head, u64 dir,
 		      u64 dir_gen, struct fs_path *path)
 {
 	struct recorded_ref *ref;
-	char *tmp;
 
 	ref = kmalloc(sizeof(*ref), GFP_NOFS);
 	if (!ref)
@@ -2611,20 +2611,14 @@ static int record_ref(struct list_head *head, u64 dir,
 	ref->dir_gen = dir_gen;
 	ref->full_path = path;
 
-	tmp = strrchr(ref->full_path->start, '/');
-	if (!tmp) {
-		ref->name_len = ref->full_path->end - ref->full_path->start;
-		ref->name = ref->full_path->start;
+	ref->name = (char *)kbasename(ref->full_path->start);
+	ref->name_len = ref->full_path->end - ref->name;
+	ref->dir_path = ref->full_path->start;
+	if (ref->name == ref->full_path->start)
 		ref->dir_path_len = 0;
-		ref->dir_path = ref->full_path->start;
-	} else {
-		tmp++;
-		ref->name_len = ref->full_path->end - tmp;
-		ref->name = tmp;
-		ref->dir_path = ref->full_path->start;
+	else
 		ref->dir_path_len = ref->full_path->end -
 				ref->full_path->start - 1 - ref->name_len;
-	}
 
 	list_add_tail(&ref->list, head);
 	return 0;

commit 57cfd4627046efc43081d26b5db77dbfb7595caa
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Aug 20 15:55:39 2013 -0400

    Btrfs: fix send to deal with sparse files properly
    
    Send was just sending everything it found, even if the extent was a hole.  This
    is unpleasant for users, so just skip holes when we are sending.  This will also
    skip sending prealloc extents since the send spec doesn't have a prealloc
    command.  Eventually we will add a prealloc command and rev the send version so
    we can send down the prealloc info.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index db7da682f0d2..cbe92da5f33b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3920,7 +3920,8 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 	btrfs_item_key_to_cpu(eb, &found_key, slot);
 	if (found_key.objectid != key.objectid ||
 	    found_key.type != key.type) {
-		ret = 0;
+		/* If we're a hole then just pretend nothing changed */
+		ret = (left_disknr) ? 0 : 1;
 		goto out;
 	}
 
@@ -3946,7 +3947,8 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 		 * This may only happen on the first iteration.
 		 */
 		if (found_key.offset + right_len <= ekey->offset) {
-			ret = 0;
+			/* If we're a hole just pretend nothing changed */
+			ret = (left_disknr) ? 0 : 1;
 			goto out;
 		}
 
@@ -4011,8 +4013,8 @@ static int process_extent(struct send_ctx *sctx,
 			  struct btrfs_path *path,
 			  struct btrfs_key *key)
 {
-	int ret = 0;
 	struct clone_root *found_clone = NULL;
+	int ret = 0;
 
 	if (S_ISLNK(sctx->cur_inode_mode))
 		return 0;
@@ -4025,6 +4027,32 @@ static int process_extent(struct send_ctx *sctx,
 			ret = 0;
 			goto out;
 		}
+	} else {
+		struct btrfs_file_extent_item *ei;
+		u8 type;
+
+		ei = btrfs_item_ptr(path->nodes[0], path->slots[0],
+				    struct btrfs_file_extent_item);
+		type = btrfs_file_extent_type(path->nodes[0], ei);
+		if (type == BTRFS_FILE_EXTENT_PREALLOC ||
+		    type == BTRFS_FILE_EXTENT_REG) {
+			/*
+			 * The send spec does not have a prealloc command yet,
+			 * so just leave a hole for prealloc'ed extents until
+			 * we have enough commands queued up to justify rev'ing
+			 * the send spec.
+			 */
+			if (type == BTRFS_FILE_EXTENT_PREALLOC) {
+				ret = 0;
+				goto out;
+			}
+
+			/* Have a hole, just skip it. */
+			if (btrfs_file_extent_disk_bytenr(path->nodes[0], ei) == 0) {
+				ret = 0;
+				goto out;
+			}
+		}
 	}
 
 	ret = find_extent_clone(sctx, path, key->objectid, key->offset,

commit 35a3621beb3e2face3e7954eaee20a8fa0043fac
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Aug 14 18:12:25 2013 +0200

    Btrfs: get rid of sparse warnings
    
    make C=2 fs/btrfs/ CF=-D__CHECK_ENDIAN__
    
    I tried to filter out the warnings for which patches have already
    been sent to the mailing list, pending for inclusion in btrfs-next.
    
    All these changes should be obviously safe.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index fc03a5755a6b..db7da682f0d2 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -54,8 +54,8 @@ struct fs_path {
 
 			char *buf;
 			int buf_len;
-			int reversed:1;
-			int virtual_mem:1;
+			unsigned int reversed:1;
+			unsigned int virtual_mem:1;
 			char inline_buf[];
 		};
 		char pad[PAGE_SIZE];

commit ba5e8f2e2d3074bf151dd222dae9bb400e621b82
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Aug 16 16:52:55 2013 -0400

    Btrfs: fix send issues related to inode number reuse
    
    If you are sending a snapshot and specifying a parent snapshot we will walk the
    trees and figure out where they differ and send the differences only.  The way
    we check for differences are if the leaves aren't the same and if the keys are
    not the same within the leaves.  So if neither leaf is the same (ie the leaf has
    been cow'ed from the parent snapshot) we walk each item in the send root and
    check it against the parent root.  If the items match exactly then we don't do
    anything.  This doesn't quite work for inode refs, since they will just have the
    name and the parent objectid.  If you move the file from a directory and then
    remove that directory and re-create a directory with the same inode number as
    the old directory and then move that file back into that directory we will
    assume that nothing changed and you will get errors when you try to receive.
    
    In order to fix this we need to do extra checking to see if the inode ref really
    is the same or not.  So do this by passing down BTRFS_COMPARE_TREE_SAME if the
    items match.  Then if the key type is an inode ref we can do some extra
    checking, otherwise we just keep processing.  The extra checking is to look up
    the generation of the directory in the parent volume and compare it to the
    generation of the send volume.  If they match then they are the same directory
    and we are good to go.  If they don't we have to add them to the changed refs
    list.
    
    This means we have to track the generation of the ref we're trying to lookup
    when we iterate all the refs for a particular inode.  So in the case of looking
    for new refs we have to get the generation from the parent volume, and in the
    case of looking for deleted refs we have to get the generation from the send
    volume to compare with.
    
    There was also the issue of using a ulist to keep track of the directories we
    needed to check.  Because we can get a deleted ref and a new ref for the same
    inode number the ulist won't work since it indexes based on the value.  So
    instead just dup any directory ref we find and add it to a local list, and then
    process that list as normal and do away with using a ulist for this altogether.
    
    Before we would fail all of the tests in the far-progs that related to moving
    directories (test group 32).  With this patch we now pass these tests, and all
    of the tests in the far-progs send testing suite.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index f8f8b1f3bb2b..fc03a5755a6b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2630,6 +2630,22 @@ static int record_ref(struct list_head *head, u64 dir,
 	return 0;
 }
 
+static int dup_ref(struct recorded_ref *ref, struct list_head *list)
+{
+	struct recorded_ref *new;
+
+	new = kmalloc(sizeof(*ref), GFP_NOFS);
+	if (!new)
+		return -ENOMEM;
+
+	new->dir = ref->dir;
+	new->dir_gen = ref->dir_gen;
+	new->full_path = NULL;
+	INIT_LIST_HEAD(&new->list);
+	list_add_tail(&new->list, list);
+	return 0;
+}
+
 static void __free_recorded_refs(struct list_head *head)
 {
 	struct recorded_ref *cur;
@@ -2744,9 +2760,7 @@ static int process_recorded_refs(struct send_ctx *sctx)
 	int ret = 0;
 	struct recorded_ref *cur;
 	struct recorded_ref *cur2;
-	struct ulist *check_dirs = NULL;
-	struct ulist_iterator uit;
-	struct ulist_node *un;
+	struct list_head check_dirs;
 	struct fs_path *valid_path = NULL;
 	u64 ow_inode = 0;
 	u64 ow_gen;
@@ -2760,6 +2774,7 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 	 * which is always '..'
 	 */
 	BUG_ON(sctx->cur_ino <= BTRFS_FIRST_FREE_OBJECTID);
+	INIT_LIST_HEAD(&check_dirs);
 
 	valid_path = fs_path_alloc();
 	if (!valid_path) {
@@ -2767,12 +2782,6 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 		goto out;
 	}
 
-	check_dirs = ulist_alloc(GFP_NOFS);
-	if (!check_dirs) {
-		ret = -ENOMEM;
-		goto out;
-	}
-
 	/*
 	 * First, check if the first ref of the current inode was overwritten
 	 * before. If yes, we know that the current inode was already orphanized
@@ -2909,8 +2918,7 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 					goto out;
 			}
 		}
-		ret = ulist_add(check_dirs, cur->dir, cur->dir_gen,
-				GFP_NOFS);
+		ret = dup_ref(cur, &check_dirs);
 		if (ret < 0)
 			goto out;
 	}
@@ -2938,8 +2946,7 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 		}
 
 		list_for_each_entry(cur, &sctx->deleted_refs, list) {
-			ret = ulist_add(check_dirs, cur->dir, cur->dir_gen,
-					GFP_NOFS);
+			ret = dup_ref(cur, &check_dirs);
 			if (ret < 0)
 				goto out;
 		}
@@ -2950,8 +2957,7 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 		 */
 		cur = list_entry(sctx->deleted_refs.next, struct recorded_ref,
 				list);
-		ret = ulist_add(check_dirs, cur->dir, cur->dir_gen,
-				GFP_NOFS);
+		ret = dup_ref(cur, &check_dirs);
 		if (ret < 0)
 			goto out;
 	} else if (!S_ISDIR(sctx->cur_inode_mode)) {
@@ -2971,12 +2977,10 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 				if (ret < 0)
 					goto out;
 			}
-			ret = ulist_add(check_dirs, cur->dir, cur->dir_gen,
-					GFP_NOFS);
+			ret = dup_ref(cur, &check_dirs);
 			if (ret < 0)
 				goto out;
 		}
-
 		/*
 		 * If the inode is still orphan, unlink the orphan. This may
 		 * happen when a previous inode did overwrite the first ref
@@ -2998,33 +3002,32 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 	 * deletion and if it's finally possible to perform the rmdir now.
 	 * We also update the inode stats of the parent dirs here.
 	 */
-	ULIST_ITER_INIT(&uit);
-	while ((un = ulist_next(check_dirs, &uit))) {
+	list_for_each_entry(cur, &check_dirs, list) {
 		/*
 		 * In case we had refs into dirs that were not processed yet,
 		 * we don't need to do the utime and rmdir logic for these dirs.
 		 * The dir will be processed later.
 		 */
-		if (un->val > sctx->cur_ino)
+		if (cur->dir > sctx->cur_ino)
 			continue;
 
-		ret = get_cur_inode_state(sctx, un->val, un->aux);
+		ret = get_cur_inode_state(sctx, cur->dir, cur->dir_gen);
 		if (ret < 0)
 			goto out;
 
 		if (ret == inode_state_did_create ||
 		    ret == inode_state_no_change) {
 			/* TODO delayed utimes */
-			ret = send_utimes(sctx, un->val, un->aux);
+			ret = send_utimes(sctx, cur->dir, cur->dir_gen);
 			if (ret < 0)
 				goto out;
 		} else if (ret == inode_state_did_delete) {
-			ret = can_rmdir(sctx, un->val, sctx->cur_ino);
+			ret = can_rmdir(sctx, cur->dir, sctx->cur_ino);
 			if (ret < 0)
 				goto out;
 			if (ret) {
-				ret = get_cur_path(sctx, un->val, un->aux,
-						valid_path);
+				ret = get_cur_path(sctx, cur->dir,
+						   cur->dir_gen, valid_path);
 				if (ret < 0)
 					goto out;
 				ret = send_rmdir(sctx, valid_path);
@@ -3037,8 +3040,8 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 	ret = 0;
 
 out:
+	__free_recorded_refs(&check_dirs);
 	free_recorded_refs(sctx);
-	ulist_free(check_dirs);
 	fs_path_free(valid_path);
 	return ret;
 }
@@ -3139,6 +3142,8 @@ static int record_deleted_ref(struct send_ctx *sctx)
 
 struct find_ref_ctx {
 	u64 dir;
+	u64 dir_gen;
+	struct btrfs_root *root;
 	struct fs_path *name;
 	int found_idx;
 };
@@ -3148,9 +3153,21 @@ static int __find_iref(int num, u64 dir, int index,
 		       void *ctx_)
 {
 	struct find_ref_ctx *ctx = ctx_;
+	u64 dir_gen;
+	int ret;
 
 	if (dir == ctx->dir && fs_path_len(name) == fs_path_len(ctx->name) &&
 	    strncmp(name->start, ctx->name->start, fs_path_len(name)) == 0) {
+		/*
+		 * To avoid doing extra lookups we'll only do this if everything
+		 * else matches.
+		 */
+		ret = get_inode_info(ctx->root, dir, NULL, &dir_gen, NULL,
+				     NULL, NULL, NULL);
+		if (ret)
+			return ret;
+		if (dir_gen != ctx->dir_gen)
+			return 0;
 		ctx->found_idx = num;
 		return 1;
 	}
@@ -3160,14 +3177,16 @@ static int __find_iref(int num, u64 dir, int index,
 static int find_iref(struct btrfs_root *root,
 		     struct btrfs_path *path,
 		     struct btrfs_key *key,
-		     u64 dir, struct fs_path *name)
+		     u64 dir, u64 dir_gen, struct fs_path *name)
 {
 	int ret;
 	struct find_ref_ctx ctx;
 
 	ctx.dir = dir;
 	ctx.name = name;
+	ctx.dir_gen = dir_gen;
 	ctx.found_idx = -1;
+	ctx.root = root;
 
 	ret = iterate_inode_ref(root, path, key, 0, __find_iref, &ctx);
 	if (ret < 0)
@@ -3183,11 +3202,17 @@ static int __record_changed_new_ref(int num, u64 dir, int index,
 				    struct fs_path *name,
 				    void *ctx)
 {
+	u64 dir_gen;
 	int ret;
 	struct send_ctx *sctx = ctx;
 
+	ret = get_inode_info(sctx->send_root, dir, NULL, &dir_gen, NULL,
+			     NULL, NULL, NULL);
+	if (ret)
+		return ret;
+
 	ret = find_iref(sctx->parent_root, sctx->right_path,
-			sctx->cmp_key, dir, name);
+			sctx->cmp_key, dir, dir_gen, name);
 	if (ret == -ENOENT)
 		ret = __record_new_ref(num, dir, index, name, sctx);
 	else if (ret > 0)
@@ -3200,11 +3225,17 @@ static int __record_changed_deleted_ref(int num, u64 dir, int index,
 					struct fs_path *name,
 					void *ctx)
 {
+	u64 dir_gen;
 	int ret;
 	struct send_ctx *sctx = ctx;
 
+	ret = get_inode_info(sctx->parent_root, dir, NULL, &dir_gen, NULL,
+			     NULL, NULL, NULL);
+	if (ret)
+		return ret;
+
 	ret = find_iref(sctx->send_root, sctx->left_path, sctx->cmp_key,
-			dir, name);
+			dir, dir_gen, name);
 	if (ret == -ENOENT)
 		ret = __record_deleted_ref(num, dir, index, name, sctx);
 	else if (ret > 0)
@@ -4381,6 +4412,64 @@ static int changed_extent(struct send_ctx *sctx,
 	return ret;
 }
 
+static int dir_changed(struct send_ctx *sctx, u64 dir)
+{
+	u64 orig_gen, new_gen;
+	int ret;
+
+	ret = get_inode_info(sctx->send_root, dir, NULL, &new_gen, NULL, NULL,
+			     NULL, NULL);
+	if (ret)
+		return ret;
+
+	ret = get_inode_info(sctx->parent_root, dir, NULL, &orig_gen, NULL,
+			     NULL, NULL, NULL);
+	if (ret)
+		return ret;
+
+	return (orig_gen != new_gen) ? 1 : 0;
+}
+
+static int compare_refs(struct send_ctx *sctx, struct btrfs_path *path,
+			struct btrfs_key *key)
+{
+	struct btrfs_inode_extref *extref;
+	struct extent_buffer *leaf;
+	u64 dirid = 0, last_dirid = 0;
+	unsigned long ptr;
+	u32 item_size;
+	u32 cur_offset = 0;
+	int ref_name_len;
+	int ret = 0;
+
+	/* Easy case, just check this one dirid */
+	if (key->type == BTRFS_INODE_REF_KEY) {
+		dirid = key->offset;
+
+		ret = dir_changed(sctx, dirid);
+		goto out;
+	}
+
+	leaf = path->nodes[0];
+	item_size = btrfs_item_size_nr(leaf, path->slots[0]);
+	ptr = btrfs_item_ptr_offset(leaf, path->slots[0]);
+	while (cur_offset < item_size) {
+		extref = (struct btrfs_inode_extref *)(ptr +
+						       cur_offset);
+		dirid = btrfs_inode_extref_parent(leaf, extref);
+		ref_name_len = btrfs_inode_extref_name_len(leaf, extref);
+		cur_offset += ref_name_len + sizeof(*extref);
+		if (dirid == last_dirid)
+			continue;
+		ret = dir_changed(sctx, dirid);
+		if (ret)
+			break;
+		last_dirid = dirid;
+	}
+out:
+	return ret;
+}
+
 /*
  * Updates compare related fields in sctx and simply forwards to the actual
  * changed_xxx functions.
@@ -4396,6 +4485,19 @@ static int changed_cb(struct btrfs_root *left_root,
 	int ret = 0;
 	struct send_ctx *sctx = ctx;
 
+	if (result == BTRFS_COMPARE_TREE_SAME) {
+		if (key->type != BTRFS_INODE_REF_KEY &&
+		    key->type != BTRFS_INODE_EXTREF_KEY)
+			return 0;
+		ret = compare_refs(sctx, left_path, key);
+		if (!ret)
+			return 0;
+		if (ret < 0)
+			return ret;
+		result = BTRFS_COMPARE_TREE_CHANGED;
+		ret = 0;
+	}
+
 	sctx->left_path = left_path;
 	sctx->right_path = right_path;
 	sctx->cmp_key = key;

commit a05254143cd183b18002cbba7759a1e4629aa762
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Aug 12 10:56:14 2013 -0400

    Btrfs: skip subvol entries when checking if we've created a dir already
    
    We have logic to see if we've already created a parent directory by check to see
    if an inode inside of that directory has a lower inode number than the one we
    are currently processing.  The logic is that if there is a lower inode number
    then we would have had to made sure the directory was created at that previous
    point.  The problem is that subvols inode numbers count from the lowest objectid
    in the root tree, which may be less than our current progress.  So just skip if
    our dir item key is a root item.  This fixes the original test and the xfstest
    version I made that added an extra subvol create.  Thanks,
    
    Reported-by: Emil Karlson <jekarlson@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 0efc2e2f253c..f8f8b1f3bb2b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2538,7 +2538,8 @@ static int did_create_dir(struct send_ctx *sctx, u64 dir)
 		di = btrfs_item_ptr(eb, slot, struct btrfs_dir_item);
 		btrfs_dir_item_key_to_cpu(eb, di, &di_key);
 
-		if (di_key.objectid < sctx->send_progress) {
+		if (di_key.type != BTRFS_ROOT_ITEM_KEY &&
+		    di_key.objectid < sctx->send_progress) {
 			ret = 1;
 			goto out;
 		}

commit ebdad913aa9c86a63d3be28b4610e143204c6f3c
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Aug 6 16:47:48 2013 -0400

    Btrfs: check our parent dir when doing a compare send
    
    When doing a send with a parent subvol we will check to see if the file we are
    acting on is being overwritten and move it if we think it may be needed further
    down the line during the send.  We check this by checking its directory and
    making sure it existed in the parent and making sure the file existed in the
    parent.  The problem with this check is that if we create a directory and a file
    in that directory, and then snapshot, and then remove and re-create that same
    directory and file with different inode numbers and then try to snapshot and
    send with the original parent we will try and save the original file inside of
    that directory.  This is a problem because during the receive we move the
    directory out of the way because it is a completely new inode, which makes us
    unable to find the old file inside of the directory when we try to move that out
    of the way for the overwrite.  We fix this by checking the parent directory of
    the inode we think we are overwriting.  If the parent directory generation in
    the send root != the parent directory generation in the parent root then we know
    it is a completely new directory and we need not bother with moving the file out
    of the way because it would have been completely destroyed.  This fixes bz
    60673.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d3f3b43cae0b..0efc2e2f253c 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1668,6 +1668,7 @@ static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 			      u64 *who_ino, u64 *who_gen)
 {
 	int ret = 0;
+	u64 gen;
 	u64 other_inode = 0;
 	u8 other_type = 0;
 
@@ -1678,6 +1679,24 @@ static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 	if (ret <= 0)
 		goto out;
 
+	/*
+	 * If we have a parent root we need to verify that the parent dir was
+	 * not delted and then re-created, if it was then we have no overwrite
+	 * and we can just unlink this entry.
+	 */
+	if (sctx->parent_root) {
+		ret = get_inode_info(sctx->parent_root, dir, NULL, &gen, NULL,
+				     NULL, NULL, NULL);
+		if (ret < 0 && ret != -ENOENT)
+			goto out;
+		if (ret) {
+			ret = 0;
+			goto out;
+		}
+		if (gen != dir_gen)
+			goto out;
+	}
+
 	ret = lookup_dir_item_inode(sctx->parent_root, dir, name, name_len,
 			&other_inode, &other_type);
 	if (ret < 0 && ret != -ENOENT)

commit 8be04b9374e59923fa337766aaa74151b95b7099
Author: Joe Perches <joe@perches.com>
Date:   Wed Jun 19 12:15:53 2013 -0700

    treewide: Add __GFP_NOWARN to k.alloc calls with v.alloc fallbacks
    
    Don't emit OOM warnings when k.alloc calls fail when
    there there is a v.alloc immediately afterwards.
    
    Converted a kmalloc/vmalloc with memset to kzalloc/vzalloc.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Acked-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d3f3b43cae0b..2e14fd89a8b4 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -219,7 +219,7 @@ static int fs_path_ensure_buf(struct fs_path *p, int len)
 	len = PAGE_ALIGN(len);
 
 	if (p->buf == p->inline_buf) {
-		tmp_buf = kmalloc(len, GFP_NOFS);
+		tmp_buf = kmalloc(len, GFP_NOFS | __GFP_NOWARN);
 		if (!tmp_buf) {
 			tmp_buf = vmalloc(len);
 			if (!tmp_buf)

commit a5959bc0a1920d54c07b26a67b104caaf28f0a8c
Author: Thomas Meyer <thomas@m3y3r.de>
Date:   Sat Jun 1 09:37:50 2013 +0000

    Btrfs: Cocci spatch "memdup.spatch"
    
    Signed-off-by: Thomas Meyer <thomas@m3y3r.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index db381cf94943..d3f3b43cae0b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3422,10 +3422,9 @@ static int __find_xattr(int num, struct btrfs_key *di_key,
 	    strncmp(name, ctx->name, name_len) == 0) {
 		ctx->found_idx = num;
 		ctx->found_data_len = data_len;
-		ctx->found_data = kmalloc(data_len, GFP_NOFS);
+		ctx->found_data = kmemdup(data, data_len, GFP_NOFS);
 		if (!ctx->found_data)
 			return -ENOMEM;
-		memcpy(ctx->found_data, data, data_len);
 		return 1;
 	}
 	return 0;

commit 139f807a1eba1e484941a98fb93ee32ad859a6a1
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon May 20 11:26:50 2013 -0400

    Btrfs: fix estale with btrfs send
    
    This fixes bugzilla 57491.  If we take a snapshot of a fs with a unlink ongoing
    and then try to send that root we will run into problems.  When comparing with a
    parent root we will search the parents and the send roots commit_root, which if
    we've just created the snapshot will include the file that needs to be evicted
    by the orphan cleanup.  So when we find a changed extent we will try and copy
    that info into the send stream, but when we lookup the inode we use the normal
    root, which no longer has the inode because the orphan cleanup deleted it.  The
    best solution I have for this is to check our otransid with the generation of
    the commit root and if they match just commit the transaction again, that way we
    get the changes from the orphan cleanup.  With this patch the reproducer I made
    for this bugzilla no longer returns ESTALE when trying to do the send.  Thanks,
    
    Cc: stable@vger.kernel.org
    Reported-by: Chris Wilson <jakdaw@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index dc43fed3f4bb..db381cf94943 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4570,6 +4570,41 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	send_root = BTRFS_I(file_inode(mnt_file))->root;
 	fs_info = send_root->fs_info;
 
+	/*
+	 * This is done when we lookup the root, it should already be complete
+	 * by the time we get here.
+	 */
+	WARN_ON(send_root->orphan_cleanup_state != ORPHAN_CLEANUP_DONE);
+
+	/*
+	 * If we just created this root we need to make sure that the orphan
+	 * cleanup has been done and committed since we search the commit root,
+	 * so check its commit root transid with our otransid and if they match
+	 * commit the transaction to make sure everything is updated.
+	 */
+	down_read(&send_root->fs_info->extent_commit_sem);
+	if (btrfs_header_generation(send_root->commit_root) ==
+	    btrfs_root_otransid(&send_root->root_item)) {
+		struct btrfs_trans_handle *trans;
+
+		up_read(&send_root->fs_info->extent_commit_sem);
+
+		trans = btrfs_attach_transaction_barrier(send_root);
+		if (IS_ERR(trans)) {
+			if (PTR_ERR(trans) != -ENOENT) {
+				ret = PTR_ERR(trans);
+				goto out;
+			}
+			/* ENOENT means theres no transaction */
+		} else {
+			ret = btrfs_commit_transaction(trans, send_root);
+			if (ret)
+				goto out;
+		}
+	} else {
+		up_read(&send_root->fs_info->extent_commit_sem);
+	}
+
 	arg = memdup_user(arg_, sizeof(*arg));
 	if (IS_ERR(arg)) {
 		ret = PTR_ERR(arg);

commit b1b195969fe6d936f8c8bb63abf7efd2cc4cd5cf
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon May 13 14:42:57 2013 +0000

    Btrfs: cleanup, btrfs_read_fs_root_no_name() doesn't return NULL
    
    No need to check for NULL in send.c and disk-io.c.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index fedec7ba3537..dc43fed3f4bb 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4654,10 +4654,6 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 			key.type = BTRFS_ROOT_ITEM_KEY;
 			key.offset = (u64)-1;
 			clone_root = btrfs_read_fs_root_no_name(fs_info, &key);
-			if (!clone_root) {
-				ret = -EINVAL;
-				goto out;
-			}
 			if (IS_ERR(clone_root)) {
 				ret = PTR_ERR(clone_root);
 				goto out;
@@ -4673,8 +4669,8 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		key.type = BTRFS_ROOT_ITEM_KEY;
 		key.offset = (u64)-1;
 		sctx->parent_root = btrfs_read_fs_root_no_name(fs_info, &key);
-		if (!sctx->parent_root) {
-			ret = -EINVAL;
+		if (IS_ERR(sctx->parent_root)) {
+			ret = PTR_ERR(sctx->parent_root);
 			goto out;
 		}
 	}

commit 924794c93690ff7d2909fd32e9d88282c700e224
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Wed May 8 07:51:52 2013 +0000

    Btrfs: cleanup unused arguments in send.c
    
    sctx is removed from the argument of the function that
    doesn't use sctx.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index ff40f1c00ce3..fedec7ba3537 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -158,7 +158,7 @@ static void fs_path_reset(struct fs_path *p)
 	}
 }
 
-static struct fs_path *fs_path_alloc(struct send_ctx *sctx)
+static struct fs_path *fs_path_alloc(void)
 {
 	struct fs_path *p;
 
@@ -173,11 +173,11 @@ static struct fs_path *fs_path_alloc(struct send_ctx *sctx)
 	return p;
 }
 
-static struct fs_path *fs_path_alloc_reversed(struct send_ctx *sctx)
+static struct fs_path *fs_path_alloc_reversed(void)
 {
 	struct fs_path *p;
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return NULL;
 	p->reversed = 1;
@@ -185,7 +185,7 @@ static struct fs_path *fs_path_alloc_reversed(struct send_ctx *sctx)
 	return p;
 }
 
-static void fs_path_free(struct send_ctx *sctx, struct fs_path *p)
+static void fs_path_free(struct fs_path *p)
 {
 	if (!p)
 		return;
@@ -753,8 +753,7 @@ typedef int (*iterate_inode_ref_t)(int num, u64 dir, int index,
  *
  * path must point to the INODE_REF or INODE_EXTREF when called.
  */
-static int iterate_inode_ref(struct send_ctx *sctx,
-			     struct btrfs_root *root, struct btrfs_path *path,
+static int iterate_inode_ref(struct btrfs_root *root, struct btrfs_path *path,
 			     struct btrfs_key *found_key, int resolve,
 			     iterate_inode_ref_t iterate, void *ctx)
 {
@@ -777,13 +776,13 @@ static int iterate_inode_ref(struct send_ctx *sctx,
 	unsigned long elem_size;
 	unsigned long ptr;
 
-	p = fs_path_alloc_reversed(sctx);
+	p = fs_path_alloc_reversed();
 	if (!p)
 		return -ENOMEM;
 
 	tmp_path = alloc_path_for_send();
 	if (!tmp_path) {
-		fs_path_free(sctx, p);
+		fs_path_free(p);
 		return -ENOMEM;
 	}
 
@@ -858,7 +857,7 @@ static int iterate_inode_ref(struct send_ctx *sctx,
 
 out:
 	btrfs_free_path(tmp_path);
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	return ret;
 }
 
@@ -874,8 +873,7 @@ typedef int (*iterate_dir_item_t)(int num, struct btrfs_key *di_key,
  *
  * path must point to the dir item when called.
  */
-static int iterate_dir_item(struct send_ctx *sctx,
-			    struct btrfs_root *root, struct btrfs_path *path,
+static int iterate_dir_item(struct btrfs_root *root, struct btrfs_path *path,
 			    struct btrfs_key *found_key,
 			    iterate_dir_item_t iterate, void *ctx)
 {
@@ -990,7 +988,7 @@ static int __copy_first_ref(int num, u64 dir, int index,
  * Retrieve the first path of an inode. If an inode has more then one
  * ref/hardlink, this is ignored.
  */
-static int get_inode_path(struct send_ctx *sctx, struct btrfs_root *root,
+static int get_inode_path(struct btrfs_root *root,
 			  u64 ino, struct fs_path *path)
 {
 	int ret;
@@ -1022,8 +1020,8 @@ static int get_inode_path(struct send_ctx *sctx, struct btrfs_root *root,
 		goto out;
 	}
 
-	ret = iterate_inode_ref(sctx, root, p, &found_key, 1,
-			__copy_first_ref, path);
+	ret = iterate_inode_ref(root, p, &found_key, 1,
+				__copy_first_ref, path);
 	if (ret < 0)
 		goto out;
 	ret = 0;
@@ -1314,8 +1312,7 @@ verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, "
 	return ret;
 }
 
-static int read_symlink(struct send_ctx *sctx,
-			struct btrfs_root *root,
+static int read_symlink(struct btrfs_root *root,
 			u64 ino,
 			struct fs_path *dest)
 {
@@ -1562,8 +1559,7 @@ static int lookup_dir_item_inode(struct btrfs_root *root,
  * Looks up the first btrfs_inode_ref of a given ino. It returns the parent dir,
  * generation of the parent dir and the name of the dir entry.
  */
-static int get_first_ref(struct send_ctx *sctx,
-			 struct btrfs_root *root, u64 ino,
+static int get_first_ref(struct btrfs_root *root, u64 ino,
 			 u64 *dir, u64 *dir_gen, struct fs_path *name)
 {
 	int ret;
@@ -1628,8 +1624,7 @@ static int get_first_ref(struct send_ctx *sctx,
 	return ret;
 }
 
-static int is_first_ref(struct send_ctx *sctx,
-			struct btrfs_root *root,
+static int is_first_ref(struct btrfs_root *root,
 			u64 ino, u64 dir,
 			const char *name, int name_len)
 {
@@ -1638,11 +1633,11 @@ static int is_first_ref(struct send_ctx *sctx,
 	u64 tmp_dir;
 	u64 tmp_dir_gen;
 
-	tmp_name = fs_path_alloc(sctx);
+	tmp_name = fs_path_alloc();
 	if (!tmp_name)
 		return -ENOMEM;
 
-	ret = get_first_ref(sctx, root, ino, &tmp_dir, &tmp_dir_gen, tmp_name);
+	ret = get_first_ref(root, ino, &tmp_dir, &tmp_dir_gen, tmp_name);
 	if (ret < 0)
 		goto out;
 
@@ -1654,7 +1649,7 @@ static int is_first_ref(struct send_ctx *sctx,
 	ret = !memcmp(tmp_name->start, name, name_len);
 
 out:
-	fs_path_free(sctx, tmp_name);
+	fs_path_free(tmp_name);
 	return ret;
 }
 
@@ -1783,11 +1778,11 @@ static int did_overwrite_first_ref(struct send_ctx *sctx, u64 ino, u64 gen)
 	if (!sctx->parent_root)
 		goto out;
 
-	name = fs_path_alloc(sctx);
+	name = fs_path_alloc();
 	if (!name)
 		return -ENOMEM;
 
-	ret = get_first_ref(sctx, sctx->parent_root, ino, &dir, &dir_gen, name);
+	ret = get_first_ref(sctx->parent_root, ino, &dir, &dir_gen, name);
 	if (ret < 0)
 		goto out;
 
@@ -1795,7 +1790,7 @@ static int did_overwrite_first_ref(struct send_ctx *sctx, u64 ino, u64 gen)
 			name->start, fs_path_len(name));
 
 out:
-	fs_path_free(sctx, name);
+	fs_path_free(name);
 	return ret;
 }
 
@@ -1979,11 +1974,11 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	 * send_root or parent_root for ref lookup.
 	 */
 	if (ino < sctx->send_progress)
-		ret = get_first_ref(sctx, sctx->send_root, ino,
-				parent_ino, parent_gen, dest);
+		ret = get_first_ref(sctx->send_root, ino,
+				    parent_ino, parent_gen, dest);
 	else
-		ret = get_first_ref(sctx, sctx->parent_root, ino,
-				parent_ino, parent_gen, dest);
+		ret = get_first_ref(sctx->parent_root, ino,
+				    parent_ino, parent_gen, dest);
 	if (ret < 0)
 		goto out;
 
@@ -2070,7 +2065,7 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 	u64 parent_gen = 0;
 	int stop = 0;
 
-	name = fs_path_alloc(sctx);
+	name = fs_path_alloc();
 	if (!name) {
 		ret = -ENOMEM;
 		goto out;
@@ -2098,7 +2093,7 @@ static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
 	}
 
 out:
-	fs_path_free(sctx, name);
+	fs_path_free(name);
 	if (!ret)
 		fs_path_unreverse(dest);
 	return ret;
@@ -2263,7 +2258,7 @@ static int send_truncate(struct send_ctx *sctx, u64 ino, u64 gen, u64 size)
 
 verbose_printk("btrfs: send_truncate %llu size=%llu\n", ino, size);
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -2281,7 +2276,7 @@ verbose_printk("btrfs: send_truncate %llu size=%llu\n", ino, size);
 
 tlv_put_failure:
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	return ret;
 }
 
@@ -2292,7 +2287,7 @@ static int send_chmod(struct send_ctx *sctx, u64 ino, u64 gen, u64 mode)
 
 verbose_printk("btrfs: send_chmod %llu mode=%llu\n", ino, mode);
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -2310,7 +2305,7 @@ verbose_printk("btrfs: send_chmod %llu mode=%llu\n", ino, mode);
 
 tlv_put_failure:
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	return ret;
 }
 
@@ -2321,7 +2316,7 @@ static int send_chown(struct send_ctx *sctx, u64 ino, u64 gen, u64 uid, u64 gid)
 
 verbose_printk("btrfs: send_chown %llu uid=%llu, gid=%llu\n", ino, uid, gid);
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -2340,7 +2335,7 @@ verbose_printk("btrfs: send_chown %llu uid=%llu, gid=%llu\n", ino, uid, gid);
 
 tlv_put_failure:
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	return ret;
 }
 
@@ -2356,7 +2351,7 @@ static int send_utimes(struct send_ctx *sctx, u64 ino, u64 gen)
 
 verbose_printk("btrfs: send_utimes %llu\n", ino);
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -2397,7 +2392,7 @@ verbose_printk("btrfs: send_utimes %llu\n", ino);
 
 tlv_put_failure:
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	btrfs_free_path(path);
 	return ret;
 }
@@ -2418,7 +2413,7 @@ static int send_create_inode(struct send_ctx *sctx, u64 ino)
 
 verbose_printk("btrfs: send_create_inode %llu\n", ino);
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -2459,7 +2454,7 @@ verbose_printk("btrfs: send_create_inode %llu\n", ino);
 
 	if (S_ISLNK(mode)) {
 		fs_path_reset(p);
-		ret = read_symlink(sctx, sctx->send_root, ino, p);
+		ret = read_symlink(sctx->send_root, ino, p);
 		if (ret < 0)
 			goto out;
 		TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH_LINK, p);
@@ -2476,7 +2471,7 @@ verbose_printk("btrfs: send_create_inode %llu\n", ino);
 
 tlv_put_failure:
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	return ret;
 }
 
@@ -2615,13 +2610,13 @@ static int record_ref(struct list_head *head, u64 dir,
 	return 0;
 }
 
-static void __free_recorded_refs(struct send_ctx *sctx, struct list_head *head)
+static void __free_recorded_refs(struct list_head *head)
 {
 	struct recorded_ref *cur;
 
 	while (!list_empty(head)) {
 		cur = list_entry(head->next, struct recorded_ref, list);
-		fs_path_free(sctx, cur->full_path);
+		fs_path_free(cur->full_path);
 		list_del(&cur->list);
 		kfree(cur);
 	}
@@ -2629,8 +2624,8 @@ static void __free_recorded_refs(struct send_ctx *sctx, struct list_head *head)
 
 static void free_recorded_refs(struct send_ctx *sctx)
 {
-	__free_recorded_refs(sctx, &sctx->new_refs);
-	__free_recorded_refs(sctx, &sctx->deleted_refs);
+	__free_recorded_refs(&sctx->new_refs);
+	__free_recorded_refs(&sctx->deleted_refs);
 }
 
 /*
@@ -2644,7 +2639,7 @@ static int orphanize_inode(struct send_ctx *sctx, u64 ino, u64 gen,
 	int ret;
 	struct fs_path *orphan;
 
-	orphan = fs_path_alloc(sctx);
+	orphan = fs_path_alloc();
 	if (!orphan)
 		return -ENOMEM;
 
@@ -2655,7 +2650,7 @@ static int orphanize_inode(struct send_ctx *sctx, u64 ino, u64 gen,
 	ret = send_rename(sctx, path, orphan);
 
 out:
-	fs_path_free(sctx, orphan);
+	fs_path_free(orphan);
 	return ret;
 }
 
@@ -2746,7 +2741,7 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 	 */
 	BUG_ON(sctx->cur_ino <= BTRFS_FIRST_FREE_OBJECTID);
 
-	valid_path = fs_path_alloc(sctx);
+	valid_path = fs_path_alloc();
 	if (!valid_path) {
 		ret = -ENOMEM;
 		goto out;
@@ -2843,9 +2838,9 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 		if (ret < 0)
 			goto out;
 		if (ret) {
-			ret = is_first_ref(sctx, sctx->parent_root,
-					ow_inode, cur->dir, cur->name,
-					cur->name_len);
+			ret = is_first_ref(sctx->parent_root,
+					   ow_inode, cur->dir, cur->name,
+					   cur->name_len);
 			if (ret < 0)
 				goto out;
 			if (ret) {
@@ -3024,7 +3019,7 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 out:
 	free_recorded_refs(sctx);
 	ulist_free(check_dirs);
-	fs_path_free(sctx, valid_path);
+	fs_path_free(valid_path);
 	return ret;
 }
 
@@ -3037,7 +3032,7 @@ static int __record_new_ref(int num, u64 dir, int index,
 	struct fs_path *p;
 	u64 gen;
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -3057,7 +3052,7 @@ static int __record_new_ref(int num, u64 dir, int index,
 
 out:
 	if (ret)
-		fs_path_free(sctx, p);
+		fs_path_free(p);
 	return ret;
 }
 
@@ -3070,7 +3065,7 @@ static int __record_deleted_ref(int num, u64 dir, int index,
 	struct fs_path *p;
 	u64 gen;
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -3090,7 +3085,7 @@ static int __record_deleted_ref(int num, u64 dir, int index,
 
 out:
 	if (ret)
-		fs_path_free(sctx, p);
+		fs_path_free(p);
 	return ret;
 }
 
@@ -3098,8 +3093,8 @@ static int record_new_ref(struct send_ctx *sctx)
 {
 	int ret;
 
-	ret = iterate_inode_ref(sctx, sctx->send_root, sctx->left_path,
-			sctx->cmp_key, 0, __record_new_ref, sctx);
+	ret = iterate_inode_ref(sctx->send_root, sctx->left_path,
+				sctx->cmp_key, 0, __record_new_ref, sctx);
 	if (ret < 0)
 		goto out;
 	ret = 0;
@@ -3112,8 +3107,8 @@ static int record_deleted_ref(struct send_ctx *sctx)
 {
 	int ret;
 
-	ret = iterate_inode_ref(sctx, sctx->parent_root, sctx->right_path,
-			sctx->cmp_key, 0, __record_deleted_ref, sctx);
+	ret = iterate_inode_ref(sctx->parent_root, sctx->right_path,
+				sctx->cmp_key, 0, __record_deleted_ref, sctx);
 	if (ret < 0)
 		goto out;
 	ret = 0;
@@ -3142,8 +3137,7 @@ static int __find_iref(int num, u64 dir, int index,
 	return 0;
 }
 
-static int find_iref(struct send_ctx *sctx,
-		     struct btrfs_root *root,
+static int find_iref(struct btrfs_root *root,
 		     struct btrfs_path *path,
 		     struct btrfs_key *key,
 		     u64 dir, struct fs_path *name)
@@ -3155,7 +3149,7 @@ static int find_iref(struct send_ctx *sctx,
 	ctx.name = name;
 	ctx.found_idx = -1;
 
-	ret = iterate_inode_ref(sctx, root, path, key, 0, __find_iref, &ctx);
+	ret = iterate_inode_ref(root, path, key, 0, __find_iref, &ctx);
 	if (ret < 0)
 		return ret;
 
@@ -3172,7 +3166,7 @@ static int __record_changed_new_ref(int num, u64 dir, int index,
 	int ret;
 	struct send_ctx *sctx = ctx;
 
-	ret = find_iref(sctx, sctx->parent_root, sctx->right_path,
+	ret = find_iref(sctx->parent_root, sctx->right_path,
 			sctx->cmp_key, dir, name);
 	if (ret == -ENOENT)
 		ret = __record_new_ref(num, dir, index, name, sctx);
@@ -3189,7 +3183,7 @@ static int __record_changed_deleted_ref(int num, u64 dir, int index,
 	int ret;
 	struct send_ctx *sctx = ctx;
 
-	ret = find_iref(sctx, sctx->send_root, sctx->left_path, sctx->cmp_key,
+	ret = find_iref(sctx->send_root, sctx->left_path, sctx->cmp_key,
 			dir, name);
 	if (ret == -ENOENT)
 		ret = __record_deleted_ref(num, dir, index, name, sctx);
@@ -3203,11 +3197,11 @@ static int record_changed_ref(struct send_ctx *sctx)
 {
 	int ret = 0;
 
-	ret = iterate_inode_ref(sctx, sctx->send_root, sctx->left_path,
+	ret = iterate_inode_ref(sctx->send_root, sctx->left_path,
 			sctx->cmp_key, 0, __record_changed_new_ref, sctx);
 	if (ret < 0)
 		goto out;
-	ret = iterate_inode_ref(sctx, sctx->parent_root, sctx->right_path,
+	ret = iterate_inode_ref(sctx->parent_root, sctx->right_path,
 			sctx->cmp_key, 0, __record_changed_deleted_ref, sctx);
 	if (ret < 0)
 		goto out;
@@ -3266,8 +3260,7 @@ static int process_all_refs(struct send_ctx *sctx,
 		     found_key.type != BTRFS_INODE_EXTREF_KEY))
 			break;
 
-		ret = iterate_inode_ref(sctx, root, path, &found_key, 0, cb,
-				sctx);
+		ret = iterate_inode_ref(root, path, &found_key, 0, cb, sctx);
 		btrfs_release_path(path);
 		if (ret < 0)
 			goto out;
@@ -3335,7 +3328,7 @@ static int __process_new_xattr(int num, struct btrfs_key *di_key,
 	struct fs_path *p;
 	posix_acl_xattr_header dummy_acl;
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -3362,7 +3355,7 @@ static int __process_new_xattr(int num, struct btrfs_key *di_key,
 	ret = send_set_xattr(sctx, p, name, name_len, data, data_len);
 
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	return ret;
 }
 
@@ -3375,7 +3368,7 @@ static int __process_deleted_xattr(int num, struct btrfs_key *di_key,
 	struct send_ctx *sctx = ctx;
 	struct fs_path *p;
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -3386,7 +3379,7 @@ static int __process_deleted_xattr(int num, struct btrfs_key *di_key,
 	ret = send_remove_xattr(sctx, p, name, name_len);
 
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	return ret;
 }
 
@@ -3394,8 +3387,8 @@ static int process_new_xattr(struct send_ctx *sctx)
 {
 	int ret = 0;
 
-	ret = iterate_dir_item(sctx, sctx->send_root, sctx->left_path,
-			sctx->cmp_key, __process_new_xattr, sctx);
+	ret = iterate_dir_item(sctx->send_root, sctx->left_path,
+			       sctx->cmp_key, __process_new_xattr, sctx);
 
 	return ret;
 }
@@ -3404,8 +3397,8 @@ static int process_deleted_xattr(struct send_ctx *sctx)
 {
 	int ret;
 
-	ret = iterate_dir_item(sctx, sctx->parent_root, sctx->right_path,
-			sctx->cmp_key, __process_deleted_xattr, sctx);
+	ret = iterate_dir_item(sctx->parent_root, sctx->right_path,
+			       sctx->cmp_key, __process_deleted_xattr, sctx);
 
 	return ret;
 }
@@ -3438,8 +3431,7 @@ static int __find_xattr(int num, struct btrfs_key *di_key,
 	return 0;
 }
 
-static int find_xattr(struct send_ctx *sctx,
-		      struct btrfs_root *root,
+static int find_xattr(struct btrfs_root *root,
 		      struct btrfs_path *path,
 		      struct btrfs_key *key,
 		      const char *name, int name_len,
@@ -3454,7 +3446,7 @@ static int find_xattr(struct send_ctx *sctx,
 	ctx.found_data = NULL;
 	ctx.found_data_len = 0;
 
-	ret = iterate_dir_item(sctx, root, path, key, __find_xattr, &ctx);
+	ret = iterate_dir_item(root, path, key, __find_xattr, &ctx);
 	if (ret < 0)
 		return ret;
 
@@ -3480,9 +3472,9 @@ static int __process_changed_new_xattr(int num, struct btrfs_key *di_key,
 	char *found_data = NULL;
 	int found_data_len  = 0;
 
-	ret = find_xattr(sctx, sctx->parent_root, sctx->right_path,
-			sctx->cmp_key, name, name_len, &found_data,
-			&found_data_len);
+	ret = find_xattr(sctx->parent_root, sctx->right_path,
+			 sctx->cmp_key, name, name_len, &found_data,
+			 &found_data_len);
 	if (ret == -ENOENT) {
 		ret = __process_new_xattr(num, di_key, name, name_len, data,
 				data_len, type, ctx);
@@ -3508,8 +3500,8 @@ static int __process_changed_deleted_xattr(int num, struct btrfs_key *di_key,
 	int ret;
 	struct send_ctx *sctx = ctx;
 
-	ret = find_xattr(sctx, sctx->send_root, sctx->left_path, sctx->cmp_key,
-			name, name_len, NULL, NULL);
+	ret = find_xattr(sctx->send_root, sctx->left_path, sctx->cmp_key,
+			 name, name_len, NULL, NULL);
 	if (ret == -ENOENT)
 		ret = __process_deleted_xattr(num, di_key, name, name_len, data,
 				data_len, type, ctx);
@@ -3523,11 +3515,11 @@ static int process_changed_xattr(struct send_ctx *sctx)
 {
 	int ret = 0;
 
-	ret = iterate_dir_item(sctx, sctx->send_root, sctx->left_path,
+	ret = iterate_dir_item(sctx->send_root, sctx->left_path,
 			sctx->cmp_key, __process_changed_new_xattr, sctx);
 	if (ret < 0)
 		goto out;
-	ret = iterate_dir_item(sctx, sctx->parent_root, sctx->right_path,
+	ret = iterate_dir_item(sctx->parent_root, sctx->right_path,
 			sctx->cmp_key, __process_changed_deleted_xattr, sctx);
 
 out:
@@ -3572,8 +3564,8 @@ static int process_all_new_xattrs(struct send_ctx *sctx)
 			goto out;
 		}
 
-		ret = iterate_dir_item(sctx, root, path, &found_key,
-				__process_new_xattr, sctx);
+		ret = iterate_dir_item(root, path, &found_key,
+				       __process_new_xattr, sctx);
 		if (ret < 0)
 			goto out;
 
@@ -3598,7 +3590,7 @@ static int send_write(struct send_ctx *sctx, u64 offset, u32 len)
 	int num_read = 0;
 	mm_segment_t old_fs;
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -3640,7 +3632,7 @@ verbose_printk("btrfs: send_write offset=%llu, len=%d\n", offset, len);
 
 tlv_put_failure:
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	set_fs(old_fs);
 	if (ret < 0)
 		return ret;
@@ -3663,7 +3655,7 @@ verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
 		clone_root->root->objectid, clone_root->ino,
 		clone_root->offset);
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -3686,8 +3678,7 @@ verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
 			goto out;
 		ret = get_cur_path(sctx, clone_root->ino, gen, p);
 	} else {
-		ret = get_inode_path(sctx, clone_root->root,
-				clone_root->ino, p);
+		ret = get_inode_path(clone_root->root, clone_root->ino, p);
 	}
 	if (ret < 0)
 		goto out;
@@ -3704,7 +3695,7 @@ verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
 
 tlv_put_failure:
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	return ret;
 }
 
@@ -3717,7 +3708,7 @@ static int send_update_extent(struct send_ctx *sctx,
 	int ret = 0;
 	struct fs_path *p;
 
-	p = fs_path_alloc(sctx);
+	p = fs_path_alloc();
 	if (!p)
 		return -ENOMEM;
 
@@ -3737,7 +3728,7 @@ static int send_update_extent(struct send_ctx *sctx,
 
 tlv_put_failure:
 out:
-	fs_path_free(sctx, p);
+	fs_path_free(p);
 	return ret;
 }
 

commit 48a3b6366f6913683563d934eb16fea67dead9c1
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Apr 25 20:41:01 2013 +0000

    btrfs: make static code static & remove dead code
    
    Big patch, but all it does is add statics to functions which
    are in fact static, then remove the associated dead-code fallout.
    
    removed functions:
    
    btrfs_iref_to_path()
    __btrfs_lookup_delayed_deletion_item()
    __btrfs_search_delayed_insertion_item()
    __btrfs_search_delayed_deletion_item()
    find_eb_for_page()
    btrfs_find_block_group()
    range_straddles_pages()
    extent_range_uptodate()
    btrfs_file_extent_length()
    btrfs_scrub_cancel_devid()
    btrfs_start_transaction_lflush()
    
    btrfs_print_tree() is left because it is used for debugging.
    btrfs_start_transaction_lflush() and btrfs_reada_detach() are
    left for symmetry.
    
    ulist.c functions are left, another patch will take care of those.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 2037fc0efab1..ff40f1c00ce3 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -387,7 +387,7 @@ static struct btrfs_path *alloc_path_for_send(void)
 	return path;
 }
 
-int write_buf(struct file *filp, const void *buf, u32 len, loff_t *off)
+static int write_buf(struct file *filp, const void *buf, u32 len, loff_t *off)
 {
 	int ret;
 	mm_segment_t old_fs;

commit ecc7ada77b5cd1ac525db8f7d4d266e88af66cc7
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Fri Apr 19 01:04:46 2013 +0000

    Btrfs: fix error handling in btrfs_ioctl_send()
    
    fget() returns NULL if error. So, we should check NULL or not.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 158b91984b60..2037fc0efab1 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4612,8 +4612,8 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	sctx->flags = arg->flags;
 
 	sctx->send_filp = fget(arg->send_fd);
-	if (IS_ERR(sctx->send_filp)) {
-		ret = PTR_ERR(sctx->send_filp);
+	if (!sctx->send_filp) {
+		ret = -EBADF;
 		goto out;
 	}
 

commit ba1eeaac99ce15063d8bc156e03f8b75aa471647
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Thu Apr 18 07:10:44 2013 +0000

    Btrfs: remove unused variable in __process_changed_new_xattr()
    
    Variable 'p' is not used any more. So, remove it.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e0c69a106c77..158b91984b60 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3479,7 +3479,6 @@ static int __process_changed_new_xattr(int num, struct btrfs_key *di_key,
 	struct send_ctx *sctx = ctx;
 	char *found_data = NULL;
 	int found_data_len  = 0;
-	struct fs_path *p = NULL;
 
 	ret = find_xattr(sctx, sctx->parent_root, sctx->right_path,
 			sctx->cmp_key, name, name_len, &found_data,
@@ -3498,7 +3497,6 @@ static int __process_changed_new_xattr(int num, struct btrfs_key *di_key,
 	}
 
 	kfree(found_data);
-	fs_path_free(sctx, p);
 	return ret;
 }
 

commit c2c71324ecb471c932bc1ff59e46ffcf82f274fc
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Apr 10 17:10:52 2013 +0000

    Btrfs: allow omitting stream header and end-cmd for btrfs send
    
    Two new flags are added to allow omitting the stream header and the
    end command for btrfs send streams. This is used in cases where you
    send multiple snapshots back-to-back in one stream.
    
    This used to be encoded like this (with 2 snapshots in this example):
    <stream header> + <sequence of commands> + <end cmd> +
    <stream header> + <sequence of commands> + <end cmd> + EOF
    
    The new format (if the two new flags are used) is this one:
    <stream header> + <sequence of commands> +
                      <sequence of commands> + <end cmd>
    
    Note that the currently existing receivers treat <end cmd> only as
    an indication that a new <stream header> is following. This means,
    you can just skip the sequence <end cmd> <stream header> without
    loosing compatibility. As long as an EOF is following, the currently
    existing receivers handle the new format (if the two new flags are
    used) exactly as the old one.
    
    So what is the benefit of this change? The goal is to be able to use
    a single stream (one TCP connection) to multiplex a request/response
    handshake plus Btrfs send streams, all in the same stream. In this
    case you cannot evaluate an EOF condition as an end of the Btrfs send
    stream. You need something else, and the <end cmd> is just perfect
    for this purpose.
    
    The summary is:
    The format change is driven by the need to send several Btrfs send
    streams over a single TCP connections, with the ability for a repeated
    request/response handshake in the middle. And this format change does
    not break any existing tool, it is completely compatible.
    
    You could compare the old behaviour of the Btrfs send stream to the
    one of ftp where you need a seperate request/response channel and
    newly opened data transfer channels for each file, while the new
    behaviour is more like http using a single stream for everything.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c85e7c6b4598..e0c69a106c77 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4529,9 +4529,11 @@ static int send_subvol(struct send_ctx *sctx)
 {
 	int ret;
 
-	ret = send_header(sctx);
-	if (ret < 0)
-		goto out;
+	if (!(sctx->flags & BTRFS_SEND_FLAG_OMIT_STREAM_HEADER)) {
+		ret = send_header(sctx);
+		if (ret < 0)
+			goto out;
+	}
 
 	ret = send_subvol_begin(sctx);
 	if (ret < 0)
@@ -4593,7 +4595,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		goto out;
 	}
 
-	if (arg->flags & ~BTRFS_SEND_FLAG_NO_FILE_DATA) {
+	if (arg->flags & ~BTRFS_SEND_FLAG_MASK) {
 		ret = -EINVAL;
 		goto out;
 	}
@@ -4704,12 +4706,14 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	if (ret < 0)
 		goto out;
 
-	ret = begin_cmd(sctx, BTRFS_SEND_C_END);
-	if (ret < 0)
-		goto out;
-	ret = send_cmd(sctx);
-	if (ret < 0)
-		goto out;
+	if (!(sctx->flags & BTRFS_SEND_FLAG_OMIT_END_CMD)) {
+		ret = begin_cmd(sctx, BTRFS_SEND_C_END);
+		if (ret < 0)
+			goto out;
+		ret = send_cmd(sctx);
+		if (ret < 0)
+			goto out;
+	}
 
 out:
 	kfree(arg);

commit 3615db41c4b82896de450b6b4e3dab2420dcae51
Merge: ed176886b68f d8fe29e9dea8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 29 11:13:25 2013 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "We've had a busy two weeks of bug fixing.  The biggest patches in here
      are some long standing early-enospc problems (Josef) and a very old
      race where compression and mmap combine forces to lose writes (me).
      I'm fairly sure the mmap bug goes all the way back to the introduction
      of the compression code, which is proof that fsx doesn't trigger every
      possible mmap corner after all.
    
      I'm sure you'll notice one of these is from this morning, it's a small
      and isolated use-after-free fix in our scrub error reporting.  I
      double checked it here."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: don't drop path when printing out tree errors in scrub
      Btrfs: fix wrong return value of btrfs_lookup_csum()
      Btrfs: fix wrong reservation of csums
      Btrfs: fix double free in the btrfs_qgroup_account_ref()
      Btrfs: limit the global reserve to 512mb
      Btrfs: hold the ordered operations mutex when waiting on ordered extents
      Btrfs: fix space accounting for unlink and rename
      Btrfs: fix space leak when we fail to reserve metadata space
      Btrfs: fix EIO from btrfs send in is_extent_unchanged for punched holes
      Btrfs: fix race between mmap writes and compression
      Btrfs: fix memory leak in btrfs_create_tree()
      Btrfs: fix locking on ROOT_REPLACE operations in tree mod log
      Btrfs: fix missing qgroup reservation before fallocating
      Btrfs: handle a bogus chunk tree nicely
      Btrfs: update to use fs_state bit

commit adaa4b8e4d47eeb114513c2f7a172929154b94bd
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Thu Mar 21 14:30:23 2013 +0000

    Btrfs: fix EIO from btrfs send in is_extent_unchanged for punched holes
    
    When you take a snapshot, punch a hole where there has been data, then take
    another snapshot and try to send an incremental stream, btrfs send would
    give you EIO. That is because is_extent_unchanged had no support for holes
    being punched. With this patch, instead of returning EIO we just return
    0 (== the extent is not unchanged) and we're good.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Cc: Alexander Block <ablock84@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 68da757615ae..ed897dc11356 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3945,12 +3945,10 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 		    found_key.type != key.type) {
 			key.offset += right_len;
 			break;
-		} else {
-			if (found_key.offset != key.offset + right_len) {
-				/* Should really not happen */
-				ret = -EIO;
-				goto out;
-			}
+		}
+		if (found_key.offset != key.offset + right_len) {
+			ret = 0;
+			goto out;
 		}
 		key = found_key;
 	}

commit b695188dd39162a1a6bff11fdbcc4c0b65b933ab
Merge: 48476df99894 180e001cd5fc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 2 16:41:54 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs update from Chris Mason:
     "The biggest feature in the pull is the new (and still experimental)
      raid56 code that David Woodhouse started long ago.  I'm still working
      on the parity logging setup that will avoid inconsistent parity after
      a crash, so this is only for testing right now.  But, I'd really like
      to get it out to a broader audience to hammer out any performance
      issues or other problems.
    
      scrub does not yet correct errors on raid5/6 either.
    
      Josef has another pass at fsync performance.  The big change here is
      to combine waiting for metadata with waiting for data, which is a big
      latency win.  It is also step one toward using atomics from the
      hardware during a commit.
    
      Mark Fasheh has a new way to use btrfs send/receive to send only the
      metadata changes.  SUSE is using this to make snapper more efficient
      at finding changes between snapshosts.
    
      Snapshot-aware defrag is also included.
    
      Otherwise we have a large number of fixes and cleanups.  Eric Sandeen
      wins the award for removing the most lines, and I'm hoping we steal
      this idea from XFS over and over again."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (118 commits)
      btrfs: fixup/remove module.h usage as required
      Btrfs: delete inline extents when we find them during logging
      btrfs: try harder to allocate raid56 stripe cache
      Btrfs: cleanup to make the function btrfs_delalloc_reserve_metadata more logic
      Btrfs: don't call btrfs_qgroup_free if just btrfs_qgroup_reserve fails
      Btrfs: remove reduplicate check about root in the function btrfs_clean_quota_tree
      Btrfs: return ENOMEM rather than use BUG_ON when btrfs_alloc_path fails
      Btrfs: fix missing deleted items in btrfs_clean_quota_tree
      btrfs: use only inline_pages from extent buffer
      Btrfs: fix wrong reserved space when deleting a snapshot/subvolume
      Btrfs: fix wrong reserved space in qgroup during snap/subv creation
      Btrfs: remove unnecessary dget_parent/dput when creating the pending snapshot
      btrfs: remove a printk from scan_one_device
      Btrfs: fix NULL pointer after aborting a transaction
      Btrfs: fix memory leak of log roots
      Btrfs: copy everything if we've created an inline extent
      btrfs: cleanup for open-coded alignment
      Btrfs: do not change inode flags in rename
      Btrfs: use reserved space for creating a snapshot
      clear chunk_alloc flag on retryable failure
      ...

commit d895cb1af15c04c522a25c79cc429076987c089b
Merge: 9626357371b5 d3d009cb965e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 26 20:16:07 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs pile (part one) from Al Viro:
     "Assorted stuff - cleaning namei.c up a bit, fixing ->d_name/->d_parent
      locking violations, etc.
    
      The most visible changes here are death of FS_REVAL_DOT (replaced with
      "has ->d_weak_revalidate()") and a new helper getting from struct file
      to inode.  Some bits of preparation to xattr method interface changes.
    
      Misc patches by various people sent this cycle *and* ocfs2 fixes from
      several cycles ago that should've been upstream right then.
    
      PS: the next vfs pile will be xattr stuff."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (46 commits)
      saner proc_get_inode() calling conventions
      proc: avoid extra pde_put() in proc_fill_super()
      fs: change return values from -EACCES to -EPERM
      fs/exec.c: make bprm_mm_init() static
      ocfs2/dlm: use GFP_ATOMIC inside a spin_lock
      ocfs2: fix possible use-after-free with AIO
      ocfs2: Fix oops in ocfs2_fast_symlink_readpage() code path
      get_empty_filp()/alloc_file() leave both ->f_pos and ->f_version zero
      target: writev() on single-element vector is pointless
      export kernel_write(), convert open-coded instances
      fs: encode_fh: return FILEID_INVALID if invalid fid_type
      kill f_vfsmnt
      vfs: kill FS_REVAL_DOT by adding a d_weak_revalidate dentry op
      nfsd: handle vfs_getattr errors in acl protocol
      switch vfs_getattr() to struct path
      default SET_PERSONALITY() in linux/elf.h
      ceph: prepopulate inodes only when request is aborted
      d_hash_and_lookup(): export, switch open-coded instances
      9p: switch v9fs_set_create_acl() to inode+fid, do it before d_instantiate()
      9p: split dropping the acls from v9fs_set_create_acl()
      ...

commit 496ad9aa8ef448058e36ca7a787c61f2e63f0f54
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jan 23 17:07:38 2013 -0500

    new helper: file_inode(file)
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 54454542ad40..f80df6b04648 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4542,7 +4542,7 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
-	send_root = BTRFS_I(fdentry(mnt_file)->d_inode)->root;
+	send_root = BTRFS_I(file_inode(mnt_file))->root;
 	fs_info = send_root->fs_info;
 
 	arg = memdup_user(arg_, sizeof(*arg));

commit cb95e7bf7ba481c3d35b238b1cd671b63f54238a
Author: Mark Fasheh <mfasheh@suse.de>
Date:   Mon Feb 4 20:54:57 2013 +0000

    btrfs: add "no file data" flag to btrfs send ioctl
    
    This patch adds the flag, BTRFS_SEND_FLAG_NO_FILE_DATA to the btrfs send
    ioctl code. When this flag is set, the btrfs send code will never write file
    data into the stream (thus also avoiding expensive reads of that data in the
    first place). BTRFS_SEND_C_UPDATE_EXTENT commands will be sent (instead of
    BTRFS_SEND_C_WRITE) with an offset, length pair indicating the extent in
    question.
    
    This patch does not affect the operation of BTRFS_SEND_C_CLONE commands -
    they will continue to be sent when a search finds an appropriate extent to
    clone from.
    
    Signed-off-by: Mark Fasheh <mfasheh@suse.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 614da0d44d56..68da757615ae 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -85,6 +85,7 @@ struct send_ctx {
 	u32 send_max_size;
 	u64 total_send_size;
 	u64 cmd_send_size[BTRFS_SEND_C_MAX + 1];
+	u64 flags;	/* 'flags' member of btrfs_ioctl_send_args is u64 */
 
 	struct vfsmount *mnt;
 
@@ -3709,6 +3710,39 @@ verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
 	return ret;
 }
 
+/*
+ * Send an update extent command to user space.
+ */
+static int send_update_extent(struct send_ctx *sctx,
+			      u64 offset, u32 len)
+{
+	int ret = 0;
+	struct fs_path *p;
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_UPDATE_EXTENT);
+	if (ret < 0)
+		goto out;
+
+	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_FILE_OFFSET, offset);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_SIZE, len);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	fs_path_free(sctx, p);
+	return ret;
+}
+
 static int send_write_or_clone(struct send_ctx *sctx,
 			       struct btrfs_path *path,
 			       struct btrfs_key *key,
@@ -3744,7 +3778,11 @@ static int send_write_or_clone(struct send_ctx *sctx,
 		goto out;
 	}
 
-	if (!clone_root) {
+	if (clone_root) {
+		ret = send_clone(sctx, offset, len, clone_root);
+	} else if (sctx->flags & BTRFS_SEND_FLAG_NO_FILE_DATA) {
+		ret = send_update_extent(sctx, offset, len);
+	} else {
 		while (pos < len) {
 			l = len - pos;
 			if (l > BTRFS_SEND_READ_SIZE)
@@ -3757,10 +3795,7 @@ static int send_write_or_clone(struct send_ctx *sctx,
 			pos += ret;
 		}
 		ret = 0;
-	} else {
-		ret = send_clone(sctx, offset, len, clone_root);
 	}
-
 out:
 	return ret;
 }
@@ -4560,6 +4595,11 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		goto out;
 	}
 
+	if (arg->flags & ~BTRFS_SEND_FLAG_NO_FILE_DATA) {
+		ret = -EINVAL;
+		goto out;
+	}
+
 	sctx = kzalloc(sizeof(struct send_ctx), GFP_NOFS);
 	if (!sctx) {
 		ret = -ENOMEM;
@@ -4571,6 +4611,8 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	INIT_RADIX_TREE(&sctx->name_cache, GFP_NOFS);
 	INIT_LIST_HEAD(&sctx->name_cache_list);
 
+	sctx->flags = arg->flags;
+
 	sctx->send_filp = fget(arg->send_fd);
 	if (IS_ERR(sctx->send_filp)) {
 		ret = PTR_ERR(sctx->send_filp);

commit b4c6f7b75ce9fa3bb78af314e1841af5716bb643
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Jan 31 00:54:52 2013 +0000

    btrfs: remove unused fd in btrfs_ioctl_send()
    
    All we do is set it to NULL and test it :)
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 321b7fb4e441..614da0d44d56 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4536,7 +4536,6 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 	struct btrfs_fs_info *fs_info;
 	struct btrfs_ioctl_send_args *arg = NULL;
 	struct btrfs_key key;
-	struct file *filp = NULL;
 	struct send_ctx *sctx = NULL;
 	u32 i;
 	u64 *clone_sources_tmp = NULL;
@@ -4673,8 +4672,6 @@ long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
 		goto out;
 
 out:
-	if (filp)
-		fput(filp);
 	kfree(arg);
 	vfree(clone_sources_tmp);
 

commit cfa7a9ccda711ac6ab8f0d17c3a9b540092d305a
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Mon Dec 17 06:38:51 2012 +0000

    Btrfs: fix memory leak in name_cache_insert()
    
    We should free name_cache_entry before returning from the
    error handling code.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 54454542ad40..321b7fb4e441 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1814,8 +1814,10 @@ static int name_cache_insert(struct send_ctx *sctx,
 			(unsigned long)nce->ino);
 	if (!nce_head) {
 		nce_head = kmalloc(sizeof(*nce_head), GFP_NOFS);
-		if (!nce_head)
+		if (!nce_head) {
+			kfree(nce);
 			return -ENOMEM;
+		}
 		INIT_LIST_HEAD(nce_head);
 
 		ret = radix_tree_insert(&sctx->name_cache, nce->ino, nce_head);

commit 5f3ab90a72f98adbf00c50ac2d4d2b47cf4a9685
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Dec 7 09:28:54 2012 +0000

    Btrfs: rename root_times_lock to root_item_lock
    
    Originally root_times_lock was introduced as part of send/receive
    code however newly developed patch to label the subvol reused
    the same lock, so renaming it for a meaningful name.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e78b297b0b00..54454542ad40 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4397,9 +4397,9 @@ static int full_send_tree(struct send_ctx *sctx)
 	if (!path)
 		return -ENOMEM;
 
-	spin_lock(&send_root->root_times_lock);
+	spin_lock(&send_root->root_item_lock);
 	start_ctransid = btrfs_root_ctransid(&send_root->root_item);
-	spin_unlock(&send_root->root_times_lock);
+	spin_unlock(&send_root->root_item_lock);
 
 	key.objectid = BTRFS_FIRST_FREE_OBJECTID;
 	key.type = BTRFS_INODE_ITEM_KEY;
@@ -4422,9 +4422,9 @@ static int full_send_tree(struct send_ctx *sctx)
 	 * Make sure the tree has not changed after re-joining. We detect this
 	 * by comparing start_ctransid and ctransid. They should always match.
 	 */
-	spin_lock(&send_root->root_times_lock);
+	spin_lock(&send_root->root_item_lock);
 	ctransid = btrfs_root_ctransid(&send_root->root_item);
-	spin_unlock(&send_root->root_times_lock);
+	spin_unlock(&send_root->root_item_lock);
 
 	if (ctransid != start_ctransid) {
 		WARN(1, KERN_WARNING "btrfs: the root that you're trying to "

commit e2d044fe77f8e845333bb1bd29587dc08a4346a0
Author: Alex Lyakas <alex.btrfs@zadarastorage.com>
Date:   Wed Oct 17 13:52:47 2012 +0000

    Btrfs: Send: preserve ownership (uid and gid) also for symlinks.
    
    This patch also requires a change in the user-space part of "receive".
    We need to use "lchown" instead of "chown". We will do this in the
    following patch.
    
    Signed-off-by: Alex Lyakas <alex.btrfs@zadarastorage.com>
    
            if (S_ISREG(sctx->cur_inode_mode)) {

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 97cc5399306b..e78b297b0b00 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4067,22 +4067,21 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 	if (ret < 0)
 		goto out;
 
-	if (!S_ISLNK(sctx->cur_inode_mode)) {
-		if (!sctx->parent_root || sctx->cur_inode_new) {
+	if (!sctx->parent_root || sctx->cur_inode_new) {
+		need_chown = 1;
+		if (!S_ISLNK(sctx->cur_inode_mode))
 			need_chmod = 1;
-			need_chown = 1;
-		} else {
-			ret = get_inode_info(sctx->parent_root, sctx->cur_ino,
-					NULL, NULL, &right_mode, &right_uid,
-					&right_gid, NULL);
-			if (ret < 0)
-				goto out;
+	} else {
+		ret = get_inode_info(sctx->parent_root, sctx->cur_ino,
+				NULL, NULL, &right_mode, &right_uid,
+				&right_gid, NULL);
+		if (ret < 0)
+			goto out;
 
-			if (left_uid != right_uid || left_gid != right_gid)
-				need_chown = 1;
-			if (left_mode != right_mode)
-				need_chmod = 1;
-		}
+		if (left_uid != right_uid || left_gid != right_gid)
+			need_chown = 1;
+		if (!S_ISLNK(sctx->cur_inode_mode) && left_mode != right_mode)
+			need_chmod = 1;
 	}
 
 	if (S_ISREG(sctx->cur_inode_mode)) {

commit d79e50433b2bea09eb680ed5fae15e8a12356353
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon Oct 15 18:28:46 2012 +0000

    Btrfs: send correct rdev and mode in btrfs-send
    
    When sending a device file, the stream was missing the mode. Also the
    rdev was encoded wrongly.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 4f20c49edd58..97cc5399306b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2462,7 +2462,8 @@ verbose_printk("btrfs: send_create_inode %llu\n", ino);
 		TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH_LINK, p);
 	} else if (S_ISCHR(mode) || S_ISBLK(mode) ||
 		   S_ISFIFO(mode) || S_ISSOCK(mode)) {
-		TLV_PUT_U64(sctx, BTRFS_SEND_A_RDEV, rdev);
+		TLV_PUT_U64(sctx, BTRFS_SEND_A_RDEV, new_encode_dev(rdev));
+		TLV_PUT_U64(sctx, BTRFS_SEND_A_MODE, mode);
 	}
 
 	ret = send_cmd(sctx);

commit 96b5bd777118bb673b458b41bbefc7f0f31d65c9
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Mon Oct 15 08:30:45 2012 +0000

    Btrfs: extended inode refs support for send mechanism
    
    This adds support for the new extended inode refs to btrfs send.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c7beb543a4a8..4f20c49edd58 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -745,31 +745,36 @@ typedef int (*iterate_inode_ref_t)(int num, u64 dir, int index,
 				   void *ctx);
 
 /*
- * Helper function to iterate the entries in ONE btrfs_inode_ref.
+ * Helper function to iterate the entries in ONE btrfs_inode_ref or
+ * btrfs_inode_extref.
  * The iterate callback may return a non zero value to stop iteration. This can
  * be a negative value for error codes or 1 to simply stop it.
  *
- * path must point to the INODE_REF when called.
+ * path must point to the INODE_REF or INODE_EXTREF when called.
  */
 static int iterate_inode_ref(struct send_ctx *sctx,
 			     struct btrfs_root *root, struct btrfs_path *path,
 			     struct btrfs_key *found_key, int resolve,
 			     iterate_inode_ref_t iterate, void *ctx)
 {
-	struct extent_buffer *eb;
+	struct extent_buffer *eb = path->nodes[0];
 	struct btrfs_item *item;
 	struct btrfs_inode_ref *iref;
+	struct btrfs_inode_extref *extref;
 	struct btrfs_path *tmp_path;
 	struct fs_path *p;
-	u32 cur;
-	u32 len;
+	u32 cur = 0;
 	u32 total;
-	int slot;
+	int slot = path->slots[0];
 	u32 name_len;
 	char *start;
 	int ret = 0;
-	int num;
+	int num = 0;
 	int index;
+	u64 dir;
+	unsigned long name_off;
+	unsigned long elem_size;
+	unsigned long ptr;
 
 	p = fs_path_alloc_reversed(sctx);
 	if (!p)
@@ -781,24 +786,40 @@ static int iterate_inode_ref(struct send_ctx *sctx,
 		return -ENOMEM;
 	}
 
-	eb = path->nodes[0];
-	slot = path->slots[0];
-	item = btrfs_item_nr(eb, slot);
-	iref = btrfs_item_ptr(eb, slot, struct btrfs_inode_ref);
-	cur = 0;
-	len = 0;
-	total = btrfs_item_size(eb, item);
 
-	num = 0;
+	if (found_key->type == BTRFS_INODE_REF_KEY) {
+		ptr = (unsigned long)btrfs_item_ptr(eb, slot,
+						    struct btrfs_inode_ref);
+		item = btrfs_item_nr(eb, slot);
+		total = btrfs_item_size(eb, item);
+		elem_size = sizeof(*iref);
+	} else {
+		ptr = btrfs_item_ptr_offset(eb, slot);
+		total = btrfs_item_size_nr(eb, slot);
+		elem_size = sizeof(*extref);
+	}
+
 	while (cur < total) {
 		fs_path_reset(p);
 
-		name_len = btrfs_inode_ref_name_len(eb, iref);
-		index = btrfs_inode_ref_index(eb, iref);
+		if (found_key->type == BTRFS_INODE_REF_KEY) {
+			iref = (struct btrfs_inode_ref *)(ptr + cur);
+			name_len = btrfs_inode_ref_name_len(eb, iref);
+			name_off = (unsigned long)(iref + 1);
+			index = btrfs_inode_ref_index(eb, iref);
+			dir = found_key->offset;
+		} else {
+			extref = (struct btrfs_inode_extref *)(ptr + cur);
+			name_len = btrfs_inode_extref_name_len(eb, extref);
+			name_off = (unsigned long)&extref->name;
+			index = btrfs_inode_extref_index(eb, extref);
+			dir = btrfs_inode_extref_parent(eb, extref);
+		}
+
 		if (resolve) {
-			start = btrfs_iref_to_path(root, tmp_path, iref, eb,
-						found_key->offset, p->buf,
-						p->buf_len);
+			start = btrfs_ref_to_path(root, tmp_path, name_len,
+						  name_off, eb, dir,
+						  p->buf, p->buf_len);
 			if (IS_ERR(start)) {
 				ret = PTR_ERR(start);
 				goto out;
@@ -809,9 +830,10 @@ static int iterate_inode_ref(struct send_ctx *sctx,
 						p->buf_len + p->buf - start);
 				if (ret < 0)
 					goto out;
-				start = btrfs_iref_to_path(root, tmp_path, iref,
-						eb, found_key->offset, p->buf,
-						p->buf_len);
+				start = btrfs_ref_to_path(root, tmp_path,
+							  name_len, name_off,
+							  eb, dir,
+							  p->buf, p->buf_len);
 				if (IS_ERR(start)) {
 					ret = PTR_ERR(start);
 					goto out;
@@ -820,21 +842,16 @@ static int iterate_inode_ref(struct send_ctx *sctx,
 			}
 			p->start = start;
 		} else {
-			ret = fs_path_add_from_extent_buffer(p, eb,
-					(unsigned long)(iref + 1), name_len);
+			ret = fs_path_add_from_extent_buffer(p, eb, name_off,
+							     name_len);
 			if (ret < 0)
 				goto out;
 		}
 
-
-		len = sizeof(*iref) + name_len;
-		iref = (struct btrfs_inode_ref *)((char *)iref + len);
-		cur += len;
-
-		ret = iterate(num, found_key->offset, index, p, ctx);
+		cur += elem_size + name_len;
+		ret = iterate(num, dir, index, p, ctx);
 		if (ret)
 			goto out;
-
 		num++;
 	}
 
@@ -998,7 +1015,8 @@ static int get_inode_path(struct send_ctx *sctx, struct btrfs_root *root,
 	}
 	btrfs_item_key_to_cpu(p->nodes[0], &found_key, p->slots[0]);
 	if (found_key.objectid != ino ||
-		found_key.type != BTRFS_INODE_REF_KEY) {
+	    (found_key.type != BTRFS_INODE_REF_KEY &&
+	     found_key.type != BTRFS_INODE_EXTREF_KEY)) {
 		ret = -ENOENT;
 		goto out;
 	}
@@ -1551,8 +1569,8 @@ static int get_first_ref(struct send_ctx *sctx,
 	struct btrfs_key key;
 	struct btrfs_key found_key;
 	struct btrfs_path *path;
-	struct btrfs_inode_ref *iref;
 	int len;
+	u64 parent_dir;
 
 	path = alloc_path_for_send();
 	if (!path)
@@ -1568,27 +1586,41 @@ static int get_first_ref(struct send_ctx *sctx,
 	if (!ret)
 		btrfs_item_key_to_cpu(path->nodes[0], &found_key,
 				path->slots[0]);
-	if (ret || found_key.objectid != key.objectid ||
-	    found_key.type != key.type) {
+	if (ret || found_key.objectid != ino ||
+	    (found_key.type != BTRFS_INODE_REF_KEY &&
+	     found_key.type != BTRFS_INODE_EXTREF_KEY)) {
 		ret = -ENOENT;
 		goto out;
 	}
 
-	iref = btrfs_item_ptr(path->nodes[0], path->slots[0],
-			struct btrfs_inode_ref);
-	len = btrfs_inode_ref_name_len(path->nodes[0], iref);
-	ret = fs_path_add_from_extent_buffer(name, path->nodes[0],
-			(unsigned long)(iref + 1), len);
+	if (key.type == BTRFS_INODE_REF_KEY) {
+		struct btrfs_inode_ref *iref;
+		iref = btrfs_item_ptr(path->nodes[0], path->slots[0],
+				      struct btrfs_inode_ref);
+		len = btrfs_inode_ref_name_len(path->nodes[0], iref);
+		ret = fs_path_add_from_extent_buffer(name, path->nodes[0],
+						     (unsigned long)(iref + 1),
+						     len);
+		parent_dir = found_key.offset;
+	} else {
+		struct btrfs_inode_extref *extref;
+		extref = btrfs_item_ptr(path->nodes[0], path->slots[0],
+					struct btrfs_inode_extref);
+		len = btrfs_inode_extref_name_len(path->nodes[0], extref);
+		ret = fs_path_add_from_extent_buffer(name, path->nodes[0],
+					(unsigned long)&extref->name, len);
+		parent_dir = btrfs_inode_extref_parent(path->nodes[0], extref);
+	}
 	if (ret < 0)
 		goto out;
 	btrfs_release_path(path);
 
-	ret = get_inode_info(root, found_key.offset, NULL, dir_gen, NULL, NULL,
+	ret = get_inode_info(root, parent_dir, NULL, dir_gen, NULL, NULL,
 			NULL, NULL);
 	if (ret < 0)
 		goto out;
 
-	*dir = found_key.offset;
+	*dir = parent_dir;
 
 out:
 	btrfs_free_path(path);
@@ -3226,7 +3258,8 @@ static int process_all_refs(struct send_ctx *sctx,
 		btrfs_item_key_to_cpu(eb, &found_key, slot);
 
 		if (found_key.objectid != key.objectid ||
-		    found_key.type != key.type)
+		    (found_key.type != BTRFS_INODE_REF_KEY &&
+		     found_key.type != BTRFS_INODE_EXTREF_KEY))
 			break;
 
 		ret = iterate_inode_ref(sctx, root, path, &found_key, 0, cb,
@@ -3987,7 +4020,7 @@ static int process_recorded_refs_if_needed(struct send_ctx *sctx, int at_end)
 	if (sctx->cur_ino == 0)
 		goto out;
 	if (!at_end && sctx->cur_ino == sctx->cmp_key->objectid &&
-	    sctx->cmp_key->type <= BTRFS_INODE_REF_KEY)
+	    sctx->cmp_key->type <= BTRFS_INODE_EXTREF_KEY)
 		goto out;
 	if (list_empty(&sctx->new_refs) && list_empty(&sctx->deleted_refs))
 		goto out;
@@ -4335,7 +4368,8 @@ static int changed_cb(struct btrfs_root *left_root,
 
 	if (key->type == BTRFS_INODE_ITEM_KEY)
 		ret = changed_inode(sctx, result);
-	else if (key->type == BTRFS_INODE_REF_KEY)
+	else if (key->type == BTRFS_INODE_REF_KEY ||
+		 key->type == BTRFS_INODE_EXTREF_KEY)
 		ret = changed_ref(sctx, result);
 	else if (key->type == BTRFS_XATTR_ITEM_KEY)
 		ret = changed_xattr(sctx, result);

commit 1bcea35597693b3ac1ec1b311cfd42d52972a710
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Sep 14 00:04:21 2012 -0600

    Btrfs: write_buf is now callable outside send.c
    
    Developing service cmds needs it.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c6ef070a8dca..c7beb543a4a8 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -386,7 +386,7 @@ static struct btrfs_path *alloc_path_for_send(void)
 	return path;
 }
 
-static int write_buf(struct send_ctx *sctx, const void *buf, u32 len)
+int write_buf(struct file *filp, const void *buf, u32 len, loff_t *off)
 {
 	int ret;
 	mm_segment_t old_fs;
@@ -396,8 +396,7 @@ static int write_buf(struct send_ctx *sctx, const void *buf, u32 len)
 	set_fs(KERNEL_DS);
 
 	while (pos < len) {
-		ret = vfs_write(sctx->send_filp, (char *)buf + pos, len - pos,
-				&sctx->send_off);
+		ret = vfs_write(filp, (char *)buf + pos, len - pos, off);
 		/* TODO handle that correctly */
 		/*if (ret == -ERESTARTSYS) {
 			continue;
@@ -553,7 +552,8 @@ static int send_header(struct send_ctx *sctx)
 	strcpy(hdr.magic, BTRFS_SEND_STREAM_MAGIC);
 	hdr.version = cpu_to_le32(BTRFS_SEND_STREAM_VERSION);
 
-	return write_buf(sctx, &hdr, sizeof(hdr));
+	return write_buf(sctx->send_filp, &hdr, sizeof(hdr),
+					&sctx->send_off);
 }
 
 /*
@@ -590,7 +590,8 @@ static int send_cmd(struct send_ctx *sctx)
 	crc = crc32c(0, (unsigned char *)sctx->send_buf, sctx->send_size);
 	hdr->crc = cpu_to_le32(crc);
 
-	ret = write_buf(sctx, sctx->send_buf, sctx->send_size);
+	ret = write_buf(sctx->send_filp, sctx->send_buf, sctx->send_size,
+					&sctx->send_off);
 
 	sctx->total_send_size += sctx->send_size;
 	sctx->cmd_send_size[le16_to_cpu(hdr->cmd)] += sctx->send_size;

commit 69917e431210f8712fe050f47b7561e7dae89521
Author: Liu Bo <liub.liubo@gmail.com>
Date:   Fri Sep 7 20:01:28 2012 -0600

    Btrfs: fix a bug in parsing return value in logical resolve
    
    In logical resolve, we parse extent_from_logical()'s 'ret' as a kind of flag.
    
    It is possible to lose our errors because
    (-EXXXX & BTRFS_EXTENT_FLAG_TREE_BLOCK) is true.
    
    I'm not sure if it is on purpose, it just looks too hacky if it is.
    I'd rather use a real flag and a 'ret' to catch errors.
    
    Acked-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Liu Bo <liub.liubo@gmail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index e5c867996aa0..c6ef070a8dca 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1152,6 +1152,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	u64 disk_byte;
 	u64 num_bytes;
 	u64 extent_item_pos;
+	u64 flags = 0;
 	struct btrfs_file_extent_item *fi;
 	struct extent_buffer *eb = path->nodes[0];
 	struct backref_ctx *backref_ctx = NULL;
@@ -1198,13 +1199,13 @@ static int find_extent_clone(struct send_ctx *sctx,
 	}
 	logical = disk_byte + btrfs_file_extent_offset(eb, fi);
 
-	ret = extent_from_logical(sctx->send_root->fs_info,
-			disk_byte, tmp_path, &found_key);
+	ret = extent_from_logical(sctx->send_root->fs_info, disk_byte, tmp_path,
+				  &found_key, &flags);
 	btrfs_release_path(tmp_path);
 
 	if (ret < 0)
 		goto out;
-	if (ret & BTRFS_EXTENT_FLAG_TREE_BLOCK) {
+	if (flags & BTRFS_EXTENT_FLAG_TREE_BLOCK) {
 		ret = -EIO;
 		goto out;
 	}

commit 995e01b7af745b8aaa5e882cfb7bfd5baab3f335
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Mon Aug 13 02:52:38 2012 -0600

    Btrfs: fix gcc warnings for 32bit compiles
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index f22fdd41ff49..e5c867996aa0 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1035,7 +1035,7 @@ struct backref_ctx {
 
 static int __clone_root_cmp_bsearch(const void *key, const void *elt)
 {
-	u64 root = (u64)key;
+	u64 root = (u64)(uintptr_t)key;
 	struct clone_root *cr = (struct clone_root *)elt;
 
 	if (root < cr->root->objectid)
@@ -1069,7 +1069,7 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 	u64 i_size;
 
 	/* First check if the root is in the list of accepted clone sources */
-	found = bsearch((void *)root, bctx->sctx->clone_roots,
+	found = bsearch((void *)(uintptr_t)root, bctx->sctx->clone_roots,
 			bctx->sctx->clone_roots_cnt,
 			sizeof(struct clone_root),
 			__clone_root_cmp_bsearch);

commit 74dd17fbe3d65829e75d84f00a9525b2ace93998
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Tue Aug 7 16:25:13 2012 -0400

    Btrfs: fix btrfs send for inline items and compression
    
    The btrfs send code was assuming the offset of the file item into the
    extent translated to bytes on disk.  If we're compressed, this isn't
    true, and so it was off into extents owned by other files.
    
    It was also improperly handling inline extents.  This solves a crash
    where we may have gone past the end of the file extent item by not
    testing early enough for an inline extent.  It also solves problems
    where we have a whole between the end of the inline item and the start
    of the full extent.
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d17d75ebc482..f22fdd41ff49 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1149,6 +1149,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	int ret;
 	int extent_type;
 	u64 logical;
+	u64 disk_byte;
 	u64 num_bytes;
 	u64 extent_item_pos;
 	struct btrfs_file_extent_item *fi;
@@ -1157,6 +1158,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	struct clone_root *cur_clone_root;
 	struct btrfs_key found_key;
 	struct btrfs_path *tmp_path;
+	int compressed;
 	u32 i;
 
 	tmp_path = alloc_path_for_send();
@@ -1186,17 +1188,18 @@ static int find_extent_clone(struct send_ctx *sctx,
 		ret = -ENOENT;
 		goto out;
 	}
+	compressed = btrfs_file_extent_compression(eb, fi);
 
 	num_bytes = btrfs_file_extent_num_bytes(eb, fi);
-	logical = btrfs_file_extent_disk_bytenr(eb, fi);
-	if (logical == 0) {
+	disk_byte = btrfs_file_extent_disk_bytenr(eb, fi);
+	if (disk_byte == 0) {
 		ret = -ENOENT;
 		goto out;
 	}
-	logical += btrfs_file_extent_offset(eb, fi);
+	logical = disk_byte + btrfs_file_extent_offset(eb, fi);
 
 	ret = extent_from_logical(sctx->send_root->fs_info,
-			logical, tmp_path, &found_key);
+			disk_byte, tmp_path, &found_key);
 	btrfs_release_path(tmp_path);
 
 	if (ret < 0)
@@ -1234,10 +1237,16 @@ static int find_extent_clone(struct send_ctx *sctx,
 	/*
 	 * Now collect all backrefs.
 	 */
+	if (compressed == BTRFS_COMPRESS_NONE)
+		extent_item_pos = logical - found_key.objectid;
+	else
+		extent_item_pos = 0;
+
 	extent_item_pos = logical - found_key.objectid;
 	ret = iterate_extent_inodes(sctx->send_root->fs_info,
 					found_key.objectid, extent_item_pos, 1,
 					__iterate_backrefs, backref_ctx);
+
 	if (ret < 0)
 		goto out;
 
@@ -1246,8 +1255,8 @@ static int find_extent_clone(struct send_ctx *sctx,
 		ret = -EIO;
 		printk(KERN_ERR "btrfs: ERROR did not find backref in "
 				"send_root. inode=%llu, offset=%llu, "
-				"logical=%llu\n",
-				ino, data_offset, logical);
+				"disk_byte=%llu found extent=%llu\n",
+				ino, data_offset, disk_byte, found_key.objectid);
 		goto out;
 	}
 
@@ -3678,10 +3687,17 @@ static int send_write_or_clone(struct send_ctx *sctx,
 	ei = btrfs_item_ptr(path->nodes[0], path->slots[0],
 			struct btrfs_file_extent_item);
 	type = btrfs_file_extent_type(path->nodes[0], ei);
-	if (type == BTRFS_FILE_EXTENT_INLINE)
+	if (type == BTRFS_FILE_EXTENT_INLINE) {
 		len = btrfs_file_extent_inline_len(path->nodes[0], ei);
-	else
+		/*
+		 * it is possible the inline item won't cover the whole page,
+		 * but there may be items after this page.  Make
+		 * sure to send the whole thing
+		 */
+		len = PAGE_CACHE_ALIGN(len);
+	} else {
 		len = btrfs_file_extent_num_bytes(path->nodes[0], ei);
+	}
 
 	if (offset + len > sctx->cur_inode_size)
 		len = sctx->cur_inode_size - offset;
@@ -3729,6 +3745,8 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 	u64 left_offset_fixed;
 	u64 left_len;
 	u64 right_len;
+	u64 left_gen;
+	u64 right_gen;
 	u8 left_type;
 	u8 right_type;
 
@@ -3738,17 +3756,17 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 
 	eb = left_path->nodes[0];
 	slot = left_path->slots[0];
-
 	ei = btrfs_item_ptr(eb, slot, struct btrfs_file_extent_item);
 	left_type = btrfs_file_extent_type(eb, ei);
-	left_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
-	left_len = btrfs_file_extent_num_bytes(eb, ei);
-	left_offset = btrfs_file_extent_offset(eb, ei);
 
 	if (left_type != BTRFS_FILE_EXTENT_REG) {
 		ret = 0;
 		goto out;
 	}
+	left_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
+	left_len = btrfs_file_extent_num_bytes(eb, ei);
+	left_offset = btrfs_file_extent_offset(eb, ei);
+	left_gen = btrfs_file_extent_generation(eb, ei);
 
 	/*
 	 * Following comments will refer to these graphics. L is the left
@@ -3804,6 +3822,7 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 		right_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
 		right_len = btrfs_file_extent_num_bytes(eb, ei);
 		right_offset = btrfs_file_extent_offset(eb, ei);
+		right_gen = btrfs_file_extent_generation(eb, ei);
 
 		if (right_type != BTRFS_FILE_EXTENT_REG) {
 			ret = 0;
@@ -3832,7 +3851,8 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 		 * Check if we have the same extent.
 		 */
 		if (left_disknr != right_disknr ||
-		    left_offset_fixed != right_offset) {
+		    left_offset_fixed != right_offset ||
+		    left_gen != right_gen) {
 			ret = 0;
 			goto out;
 		}

commit 6d85ed05e16e7ff747025c8374f23d7d81c98540
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Aug 1 14:48:59 2012 +0200

    Btrfs: don't treat top/root directory inode as deleted/reused
    
    We can't do the deleted/reused logic for top/root inodes as it would
    create a stream that tries to delete and recreate the root dir.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a4011a9148fd..d17d75ebc482 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2627,6 +2627,12 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
 	struct btrfs_key loc;
 	struct btrfs_dir_item *di;
 
+	/*
+	 * Don't try to rmdir the top/root subvolume dir.
+	 */
+	if (dir == BTRFS_FIRST_FREE_OBJECTID)
+		return 0;
+
 	path = alloc_path_for_send();
 	if (!path)
 		return -ENOMEM;
@@ -2687,6 +2693,12 @@ static int process_recorded_refs(struct send_ctx *sctx)
 
 verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 
+	/*
+	 * This should never happen as the root dir always has the same ref
+	 * which is always '..'
+	 */
+	BUG_ON(sctx->cur_ino <= BTRFS_FIRST_FREE_OBJECTID);
+
 	valid_path = fs_path_alloc(sctx);
 	if (!valid_path) {
 		ret = -ENOMEM;
@@ -4094,7 +4106,14 @@ static int changed_inode(struct send_ctx *sctx,
 
 		right_gen = btrfs_inode_generation(sctx->right_path->nodes[0],
 				right_ii);
-		if (left_gen != right_gen)
+
+		/*
+		 * The cur_ino = root dir case is special here. We can't treat
+		 * the inode as deleted+reused because it would generate a
+		 * stream that tries to delete/mkdir the root dir.
+		 */
+		if (left_gen != right_gen &&
+		    sctx->cur_ino != BTRFS_FIRST_FREE_OBJECTID)
 			sctx->cur_inode_new_gen = 1;
 	}
 

commit 2981e225f7048b36470383bf5622c42139bd96f7
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Aug 1 14:47:03 2012 +0200

    Btrfs: ignore non-FS inodes for send/receive
    
    We have to ignore inode/space cache objects in send/receive.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index db051d17b0be..a4011a9148fd 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -4287,6 +4287,11 @@ static int changed_cb(struct btrfs_root *left_root,
 	if (ret < 0)
 		goto out;
 
+	/* Ignore non-FS objects */
+	if (key->objectid == BTRFS_FREE_INO_OBJECTID ||
+	    key->objectid == BTRFS_FREE_SPACE_OBJECTID)
+		goto out;
+
 	if (key->type == BTRFS_INODE_ITEM_KEY)
 		ret = changed_inode(sctx, result);
 	else if (key->type == BTRFS_INODE_REF_KEY)

commit 2f28f4787c0fc37c508cfb6b7b11c00ce5072940
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Aug 1 14:42:14 2012 +0200

    Btrfs: pass root instead of parent_root to iterate_inode_ref
    
    We need to pass the root that we determined earlier to iterate_inode_ref.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c6c10a43153c..db051d17b0be 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3206,8 +3206,8 @@ static int process_all_refs(struct send_ctx *sctx,
 		    found_key.type != key.type)
 			break;
 
-		ret = iterate_inode_ref(sctx, sctx->parent_root, path,
-				&found_key, 0, cb, sctx);
+		ret = iterate_inode_ref(sctx, root, path, &found_key, 0, cb,
+				sctx);
 		btrfs_release_path(path);
 		if (ret < 0)
 			goto out;

commit d8347fa444c682dc8a1e24e7158bfa2dd4c9ca71
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Aug 1 12:49:15 2012 +0200

    Btrfs: use <= instead of < in is_extent_unchanged
    
    Used the wrong compare operator here.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 35222d5420f6..c6c10a43153c 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3802,7 +3802,7 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 		 * Are we at extent 8? If yes, we know the extent is changed.
 		 * This may only happen on the first iteration.
 		 */
-		if (found_key.offset + right_len < ekey->offset) {
+		if (found_key.offset + right_len <= ekey->offset) {
 			ret = 0;
 			goto out;
 		}

commit 3954096d4b1adab6fbb3c26de37ddd4f781e072f
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Aug 1 12:46:05 2012 +0200

    Btrfs: fix check for changed extent in is_extent_unchanged
    
    The previous check was working fine, but this check should be
    easier to read. Also, we could theoritically have some exotic
    bugs with the previous checks.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index cfbe987f854b..35222d5420f6 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -3819,8 +3819,8 @@ static int is_extent_unchanged(struct send_ctx *sctx,
 		/*
 		 * Check if we have the same extent.
 		 */
-		if (left_disknr + left_offset_fixed !=
-				right_disknr + right_offset) {
+		if (left_disknr != right_disknr ||
+		    left_offset_fixed != right_offset) {
 			ret = 0;
 			goto out;
 		}

commit 5dc67d0ba915cda01ed3a980502945edf2c46b70
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Aug 1 12:07:43 2012 +0200

    Btrfs: free nce and nce_head on error in name_cache_insert
    
    Both were leaked in case of error.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index b0f9df30f24d..cfbe987f854b 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1759,6 +1759,7 @@ static int did_overwrite_first_ref(struct send_ctx *sctx, u64 ino, u64 gen)
  * Insert a name cache entry. On 32bit kernels the radix tree index is 32bit,
  * so we need to do some special handling in case we have clashes. This function
  * takes care of this with the help of name_cache_entry::radix_list.
+ * In case of error, nce is kfreed.
  */
 static int name_cache_insert(struct send_ctx *sctx,
 			     struct name_cache_entry *nce)
@@ -1775,8 +1776,11 @@ static int name_cache_insert(struct send_ctx *sctx,
 		INIT_LIST_HEAD(nce_head);
 
 		ret = radix_tree_insert(&sctx->name_cache, nce->ino, nce_head);
-		if (ret < 0)
+		if (ret < 0) {
+			kfree(nce_head);
+			kfree(nce);
 			return ret;
+		}
 	}
 	list_add_tail(&nce->radix_list, nce_head);
 	list_add_tail(&nce->list, &sctx->name_cache_list);

commit 3e126f32f88095ad1bd01b3c451e52aa9094f45c
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Aug 1 12:03:09 2012 +0200

    Btrfs: remove unused tmp_path from iterate_dir_item
    
    A leftover from older code and unused now.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 3bc921aa5e21..b0f9df30f24d 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -864,7 +864,6 @@ static int iterate_dir_item(struct send_ctx *sctx,
 	struct extent_buffer *eb;
 	struct btrfs_item *item;
 	struct btrfs_dir_item *di;
-	struct btrfs_path *tmp_path = NULL;
 	struct btrfs_key di_key;
 	char *buf = NULL;
 	char *buf2 = NULL;
@@ -886,12 +885,6 @@ static int iterate_dir_item(struct send_ctx *sctx,
 		goto out;
 	}
 
-	tmp_path = alloc_path_for_send();
-	if (!tmp_path) {
-		ret = -ENOMEM;
-		goto out;
-	}
-
 	eb = path->nodes[0];
 	slot = path->slots[0];
 	item = btrfs_item_nr(eb, slot);
@@ -953,7 +946,6 @@ static int iterate_dir_item(struct send_ctx *sctx,
 	}
 
 out:
-	btrfs_free_path(tmp_path);
 	if (buf_virtual)
 		vfree(buf);
 	else

commit e938c8ad543cd5ffe344371747484303ad51dfba
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 16:33:49 2012 +0200

    Btrfs: code cleanups for send/receive
    
    Doing some code cleanups as suggested by Arne.
    Changes do not change any logic.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 6926546939f6..3bc921aa5e21 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1115,10 +1115,12 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 		 */
 		if (ino >= bctx->cur_objectid)
 			return 0;
-		/*if (ino > ctx->cur_objectid)
+#if 0
+		if (ino > bctx->cur_objectid)
+			return 0;
+		if (offset + bctx->extent_len > bctx->cur_offset)
 			return 0;
-		if (offset + ctx->extent_len > ctx->cur_offset)
-			return 0;*/
+#endif
 	}
 
 	bctx->found++;
@@ -1327,8 +1329,6 @@ static int read_symlink(struct send_ctx *sctx,
 	len = btrfs_file_extent_inline_len(path->nodes[0], ei);
 
 	ret = fs_path_add_from_extent_buffer(dest, path->nodes[0], off, len);
-	if (ret < 0)
-		goto out;
 
 out:
 	btrfs_free_path(path);
@@ -1440,9 +1440,9 @@ static int get_cur_inode_state(struct send_ctx *sctx, u64 ino, u64 gen)
 	}
 
 	if (!left_ret && !right_ret) {
-		if (left_gen == gen && right_gen == gen)
+		if (left_gen == gen && right_gen == gen) {
 			ret = inode_state_no_change;
-		else if (left_gen == gen) {
+		} else if (left_gen == gen) {
 			if (ino < sctx->send_progress)
 				ret = inode_state_did_create;
 			else
@@ -1615,11 +1615,7 @@ static int is_first_ref(struct send_ctx *sctx,
 		goto out;
 	}
 
-	ret = memcmp(tmp_name->start, name, name_len);
-	if (ret)
-		ret = 0;
-	else
-		ret = 1;
+	ret = !memcmp(tmp_name->start, name, name_len);
 
 out:
 	fs_path_free(sctx, tmp_name);
@@ -1761,8 +1757,6 @@ static int did_overwrite_first_ref(struct send_ctx *sctx, u64 ino, u64 gen)
 
 	ret = did_overwrite_ref(sctx, dir, dir_gen, ino, gen,
 			name->start, fs_path_len(name));
-	if (ret < 0)
-		goto out;
 
 out:
 	fs_path_free(sctx, name);
@@ -1866,9 +1860,10 @@ static void name_cache_clean_unused(struct send_ctx *sctx)
 static void name_cache_free(struct send_ctx *sctx)
 {
 	struct name_cache_entry *nce;
-	struct name_cache_entry *tmp;
 
-	list_for_each_entry_safe(nce, tmp, &sctx->name_cache_list, list) {
+	while (!list_empty(&sctx->name_cache_list)) {
+		nce = list_entry(sctx->name_cache_list.next,
+				struct name_cache_entry, list);
 		name_cache_delete(sctx, nce);
 		kfree(nce);
 	}
@@ -2188,9 +2183,6 @@ static int send_subvol_begin(struct send_ctx *sctx)
 	read_extent_buffer(leaf, name, (unsigned long)(ref + 1), namelen);
 	btrfs_release_path(path);
 
-	if (ret < 0)
-		goto out;
-
 	if (parent_root) {
 		ret = begin_cmd(sctx, BTRFS_SEND_C_SNAPSHOT);
 		if (ret < 0)
@@ -2393,19 +2385,19 @@ verbose_printk("btrfs: send_create_inode %llu\n", ino);
 	if (ret < 0)
 		goto out;
 
-	if (S_ISREG(mode))
+	if (S_ISREG(mode)) {
 		cmd = BTRFS_SEND_C_MKFILE;
-	else if (S_ISDIR(mode))
+	} else if (S_ISDIR(mode)) {
 		cmd = BTRFS_SEND_C_MKDIR;
-	else if (S_ISLNK(mode))
+	} else if (S_ISLNK(mode)) {
 		cmd = BTRFS_SEND_C_SYMLINK;
-	else if (S_ISCHR(mode) || S_ISBLK(mode))
+	} else if (S_ISCHR(mode) || S_ISBLK(mode)) {
 		cmd = BTRFS_SEND_C_MKNOD;
-	else if (S_ISFIFO(mode))
+	} else if (S_ISFIFO(mode)) {
 		cmd = BTRFS_SEND_C_MKFIFO;
-	else if (S_ISSOCK(mode))
+	} else if (S_ISSOCK(mode)) {
 		cmd = BTRFS_SEND_C_MKSOCK;
-	else {
+	} else {
 		printk(KERN_WARNING "btrfs: unexpected inode type %o",
 				(int)(mode & S_IFMT));
 		ret = -ENOTSUPP;
@@ -2583,13 +2575,13 @@ static int record_ref(struct list_head *head, u64 dir,
 static void __free_recorded_refs(struct send_ctx *sctx, struct list_head *head)
 {
 	struct recorded_ref *cur;
-	struct recorded_ref *tmp;
 
-	list_for_each_entry_safe(cur, tmp, head, list) {
+	while (!list_empty(head)) {
+		cur = list_entry(head->next, struct recorded_ref, list);
 		fs_path_free(sctx, cur->full_path);
+		list_del(&cur->list);
 		kfree(cur);
 	}
-	INIT_LIST_HEAD(head);
 }
 
 static void free_recorded_refs(struct send_ctx *sctx)
@@ -3205,24 +3197,18 @@ static int process_all_refs(struct send_ctx *sctx,
 	key.offset = 0;
 	while (1) {
 		ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
-		if (ret < 0) {
-			btrfs_release_path(path);
+		if (ret < 0)
 			goto out;
-		}
-		if (ret) {
-			btrfs_release_path(path);
+		if (ret)
 			break;
-		}
 
 		eb = path->nodes[0];
 		slot = path->slots[0];
 		btrfs_item_key_to_cpu(eb, &found_key, slot);
 
 		if (found_key.objectid != key.objectid ||
-		    found_key.type != key.type) {
-			btrfs_release_path(path);
+		    found_key.type != key.type)
 			break;
-		}
 
 		ret = iterate_inode_ref(sctx, sctx->parent_root, path,
 				&found_key, 0, cb, sctx);
@@ -3232,6 +3218,7 @@ static int process_all_refs(struct send_ctx *sctx,
 
 		key.offset = found_key.offset + 1;
 	}
+	btrfs_release_path(path);
 
 	ret = process_recorded_refs(sctx);
 
@@ -3554,7 +3541,7 @@ static int send_write(struct send_ctx *sctx, u64 offset, u32 len)
 	int ret = 0;
 	struct fs_path *p;
 	loff_t pos = offset;
-	int readed = 0;
+	int num_read = 0;
 	mm_segment_t old_fs;
 
 	p = fs_path_alloc(sctx);
@@ -3579,8 +3566,8 @@ verbose_printk("btrfs: send_write offset=%llu, len=%d\n", offset, len);
 	ret = vfs_read(sctx->cur_inode_filp, sctx->read_buf, len, &pos);
 	if (ret < 0)
 		goto out;
-	readed = ret;
-	if (!readed)
+	num_read = ret;
+	if (!num_read)
 		goto out;
 
 	ret = begin_cmd(sctx, BTRFS_SEND_C_WRITE);
@@ -3593,7 +3580,7 @@ verbose_printk("btrfs: send_write offset=%llu, len=%d\n", offset, len);
 
 	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_FILE_OFFSET, offset);
-	TLV_PUT(sctx, BTRFS_SEND_A_DATA, sctx->read_buf, readed);
+	TLV_PUT(sctx, BTRFS_SEND_A_DATA, sctx->read_buf, num_read);
 
 	ret = send_cmd(sctx);
 
@@ -3603,7 +3590,7 @@ verbose_printk("btrfs: send_write offset=%llu, len=%d\n", offset, len);
 	set_fs(old_fs);
 	if (ret < 0)
 		return ret;
-	return readed;
+	return num_read;
 }
 
 /*
@@ -3614,7 +3601,6 @@ static int send_clone(struct send_ctx *sctx,
 		      struct clone_root *clone_root)
 {
 	int ret = 0;
-	struct btrfs_root *clone_root2 = clone_root->root;
 	struct fs_path *p;
 	u64 gen;
 
@@ -3639,22 +3625,23 @@ verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_LEN, len);
 	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
 
-	if (clone_root2 == sctx->send_root) {
+	if (clone_root->root == sctx->send_root) {
 		ret = get_inode_info(sctx->send_root, clone_root->ino, NULL,
 				&gen, NULL, NULL, NULL, NULL);
 		if (ret < 0)
 			goto out;
 		ret = get_cur_path(sctx, clone_root->ino, gen, p);
 	} else {
-		ret = get_inode_path(sctx, clone_root2, clone_root->ino, p);
+		ret = get_inode_path(sctx, clone_root->root,
+				clone_root->ino, p);
 	}
 	if (ret < 0)
 		goto out;
 
 	TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
-			clone_root2->root_item.uuid);
+			clone_root->root->root_item.uuid);
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_CTRANSID,
-			clone_root2->root_item.ctransid);
+			clone_root->root->root_item.ctransid);
 	TLV_PUT_PATH(sctx, BTRFS_SEND_A_CLONE_PATH, p);
 	TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_OFFSET,
 			clone_root->offset);

commit 766702ef49b8b5299d819f3a0ac42613c23424d1
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 14:11:31 2012 +0200

    Btrfs: add/fix comments/documentation for send/receive
    
    As the subject already said, add/fix comments.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index f618224d2326..6926546939f6 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1067,6 +1067,7 @@ static int __clone_root_cmp_sort(const void *e1, const void *e2)
 
 /*
  * Called for every backref that is found for the current extent.
+ * Results are collected in sctx->clone_roots->ino/offset/found_refs
  */
 static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 {
@@ -1090,7 +1091,7 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 	}
 
 	/*
-	 * There are inodes that have extents that lie behind it's i_size. Don't
+	 * There are inodes that have extents that lie behind its i_size. Don't
 	 * accept clones from these extents.
 	 */
 	ret = get_inode_info(found->root, ino, &i_size, NULL, NULL, NULL, NULL,
@@ -1137,6 +1138,12 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 }
 
 /*
+ * Given an inode, offset and extent item, it finds a good clone for a clone
+ * instruction. Returns -ENOENT when none could be found. The function makes
+ * sure that the returned clone is usable at the point where sending is at the
+ * moment. This means, that no clones are accepted which lie behind the current
+ * inode+offset.
+ *
  * path must point to the extent item when called.
  */
 static int find_extent_clone(struct send_ctx *sctx,
@@ -1529,6 +1536,10 @@ static int lookup_dir_item_inode(struct btrfs_root *root,
 	return ret;
 }
 
+/*
+ * Looks up the first btrfs_inode_ref of a given ino. It returns the parent dir,
+ * generation of the parent dir and the name of the dir entry.
+ */
 static int get_first_ref(struct send_ctx *sctx,
 			 struct btrfs_root *root, u64 ino,
 			 u64 *dir, u64 *dir_gen, struct fs_path *name)
@@ -1615,6 +1626,16 @@ static int is_first_ref(struct send_ctx *sctx,
 	return ret;
 }
 
+/*
+ * Used by process_recorded_refs to determine if a new ref would overwrite an
+ * already existing ref. In case it detects an overwrite, it returns the
+ * inode/gen in who_ino/who_gen.
+ * When an overwrite is detected, process_recorded_refs does proper orphanizing
+ * to make sure later references to the overwritten inode are possible.
+ * Orphanizing is however only required for the first ref of an inode.
+ * process_recorded_refs does an additional is_first_ref check to see if
+ * orphanizing is really required.
+ */
 static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 			      const char *name, int name_len,
 			      u64 *who_ino, u64 *who_gen)
@@ -1639,6 +1660,11 @@ static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 		goto out;
 	}
 
+	/*
+	 * Check if the overwritten ref was already processed. If yes, the ref
+	 * was already unlinked/moved, so we can safely assume that we will not
+	 * overwrite anything at this point in time.
+	 */
 	if (other_inode > sctx->send_progress) {
 		ret = get_inode_info(sctx->parent_root, other_inode, NULL,
 				who_gen, NULL, NULL, NULL, NULL);
@@ -1655,6 +1681,13 @@ static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 	return ret;
 }
 
+/*
+ * Checks if the ref was overwritten by an already processed inode. This is
+ * used by __get_cur_name_and_parent to find out if the ref was orphanized and
+ * thus the orphan name needs be used.
+ * process_recorded_refs also uses it to avoid unlinking of refs that were
+ * overwritten.
+ */
 static int did_overwrite_ref(struct send_ctx *sctx,
 			    u64 dir, u64 dir_gen,
 			    u64 ino, u64 ino_gen,
@@ -1703,6 +1736,11 @@ static int did_overwrite_ref(struct send_ctx *sctx,
 	return ret;
 }
 
+/*
+ * Same as did_overwrite_ref, but also checks if it is the first ref of an inode
+ * that got overwritten. This is used by process_recorded_refs to determine
+ * if it has to use the path as returned by get_cur_path or the orphan name.
+ */
 static int did_overwrite_first_ref(struct send_ctx *sctx, u64 ino, u64 gen)
 {
 	int ret = 0;
@@ -1731,6 +1769,11 @@ static int did_overwrite_first_ref(struct send_ctx *sctx, u64 ino, u64 gen)
 	return ret;
 }
 
+/*
+ * Insert a name cache entry. On 32bit kernels the radix tree index is 32bit,
+ * so we need to do some special handling in case we have clashes. This function
+ * takes care of this with the help of name_cache_entry::radix_list.
+ */
 static int name_cache_insert(struct send_ctx *sctx,
 			     struct name_cache_entry *nce)
 {
@@ -1792,12 +1835,19 @@ static struct name_cache_entry *name_cache_search(struct send_ctx *sctx,
 	return NULL;
 }
 
+/*
+ * Removes the entry from the list and adds it back to the end. This marks the
+ * entry as recently used so that name_cache_clean_unused does not remove it.
+ */
 static void name_cache_used(struct send_ctx *sctx, struct name_cache_entry *nce)
 {
 	list_del(&nce->list);
 	list_add_tail(&nce->list, &sctx->name_cache_list);
 }
 
+/*
+ * Remove some entries from the beginning of name_cache_list.
+ */
 static void name_cache_clean_unused(struct send_ctx *sctx)
 {
 	struct name_cache_entry *nce;
@@ -1824,6 +1874,14 @@ static void name_cache_free(struct send_ctx *sctx)
 	}
 }
 
+/*
+ * Used by get_cur_path for each ref up to the root.
+ * Returns 0 if it succeeded.
+ * Returns 1 if the inode is not existent or got overwritten. In that case, the
+ * name is an orphan name. This instructs get_cur_path to stop iterating. If 1
+ * is returned, parent_ino/parent_gen are not guaranteed to be valid.
+ * Returns <0 in case of error.
+ */
 static int __get_cur_name_and_parent(struct send_ctx *sctx,
 				     u64 ino, u64 gen,
 				     u64 *parent_ino,
@@ -1835,6 +1893,11 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	struct btrfs_path *path = NULL;
 	struct name_cache_entry *nce = NULL;
 
+	/*
+	 * First check if we already did a call to this function with the same
+	 * ino/gen. If yes, check if the cache entry is still up-to-date. If yes
+	 * return the cached result.
+	 */
 	nce = name_cache_search(sctx, ino, gen);
 	if (nce) {
 		if (ino < sctx->send_progress && nce->need_later_update) {
@@ -1857,6 +1920,11 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	if (!path)
 		return -ENOMEM;
 
+	/*
+	 * If the inode is not existent yet, add the orphan name and return 1.
+	 * This should only happen for the parent dir that we determine in
+	 * __record_new_ref
+	 */
 	ret = is_inode_existent(sctx, ino, gen);
 	if (ret < 0)
 		goto out;
@@ -1869,6 +1937,10 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 		goto out_cache;
 	}
 
+	/*
+	 * Depending on whether the inode was already processed or not, use
+	 * send_root or parent_root for ref lookup.
+	 */
 	if (ino < sctx->send_progress)
 		ret = get_first_ref(sctx, sctx->send_root, ino,
 				parent_ino, parent_gen, dest);
@@ -1878,6 +1950,10 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	if (ret < 0)
 		goto out;
 
+	/*
+	 * Check if the ref was overwritten by an inode's ref that was processed
+	 * earlier. If yes, treat as orphan and return 1.
+	 */
 	ret = did_overwrite_ref(sctx, *parent_ino, *parent_gen, ino, gen,
 			dest->start, dest->end - dest->start);
 	if (ret < 0)
@@ -1891,6 +1967,9 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	}
 
 out_cache:
+	/*
+	 * Store the result of the lookup in the name cache.
+	 */
 	nce = kmalloc(sizeof(*nce) + fs_path_len(dest) + 1, GFP_NOFS);
 	if (!nce) {
 		ret = -ENOMEM;
@@ -2278,7 +2357,7 @@ verbose_printk("btrfs: send_utimes %llu\n", ino);
 			btrfs_inode_mtime(ii));
 	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_CTIME, eb,
 			btrfs_inode_ctime(ii));
-	/* TODO otime? */
+	/* TODO Add otime support when the otime patches get into upstream */
 
 	ret = send_cmd(sctx);
 
@@ -2520,7 +2599,7 @@ static void free_recorded_refs(struct send_ctx *sctx)
 }
 
 /*
- * Renames/moves a file/dir to it's orphan name. Used when the first
+ * Renames/moves a file/dir to its orphan name. Used when the first
  * ref of an unprocessed inode gets overwritten and for all non empty
  * directories.
  */
@@ -2840,7 +2919,9 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 		 * If the inode is still orphan, unlink the orphan. This may
 		 * happen when a previous inode did overwrite the first ref
 		 * of this inode and no new refs were added for the current
-		 * inode.
+		 * inode. Unlinking does not mean that the inode is deleted in
+		 * all cases. There may still be links to this inode in other
+		 * places.
 		 */
 		if (is_orphan) {
 			ret = send_unlink(sctx, valid_path);
@@ -2857,6 +2938,11 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 	 */
 	ULIST_ITER_INIT(&uit);
 	while ((un = ulist_next(check_dirs, &uit))) {
+		/*
+		 * In case we had refs into dirs that were not processed yet,
+		 * we don't need to do the utime and rmdir logic for these dirs.
+		 * The dir will be processed later.
+		 */
 		if (un->val > sctx->cur_ino)
 			continue;
 
@@ -4048,7 +4134,17 @@ static int changed_inode(struct send_ctx *sctx,
 		sctx->cur_inode_mode = btrfs_inode_mode(
 				sctx->right_path->nodes[0], right_ii);
 	} else if (result == BTRFS_COMPARE_TREE_CHANGED) {
+		/*
+		 * We need to do some special handling in case the inode was
+		 * reported as changed with a changed generation number. This
+		 * means that the original inode was deleted and new inode
+		 * reused the same inum. So we have to treat the old inode as
+		 * deleted and the new one as new.
+		 */
 		if (sctx->cur_inode_new_gen) {
+			/*
+			 * First, process the inode as if it was deleted.
+			 */
 			sctx->cur_inode_gen = right_gen;
 			sctx->cur_inode_new = 0;
 			sctx->cur_inode_deleted = 1;
@@ -4061,6 +4157,9 @@ static int changed_inode(struct send_ctx *sctx,
 			if (ret < 0)
 				goto out;
 
+			/*
+			 * Now process the inode as if it was new.
+			 */
 			sctx->cur_inode_gen = left_gen;
 			sctx->cur_inode_new = 1;
 			sctx->cur_inode_deleted = 0;
@@ -4080,6 +4179,11 @@ static int changed_inode(struct send_ctx *sctx,
 			 * process_recorded_refs_if_needed in the new_gen case.
 			 */
 			sctx->send_progress = sctx->cur_ino + 1;
+
+			/*
+			 * Now process all extents and xattrs of the inode as if
+			 * they were all new.
+			 */
 			ret = process_all_extents(sctx);
 			if (ret < 0)
 				goto out;
@@ -4102,6 +4206,16 @@ static int changed_inode(struct send_ctx *sctx,
 	return ret;
 }
 
+/*
+ * We have to process new refs before deleted refs, but compare_trees gives us
+ * the new and deleted refs mixed. To fix this, we record the new/deleted refs
+ * first and later process them in process_recorded_refs.
+ * For the cur_inode_new_gen case, we skip recording completely because
+ * changed_inode did already initiate processing of refs. The reason for this is
+ * that in this case, compare_tree actually compares the refs of 2 different
+ * inodes. To fix this, process_all_refs is used in changed_inode to handle all
+ * refs of the right tree as deleted and all refs of the left tree as new.
+ */
 static int changed_ref(struct send_ctx *sctx,
 		       enum btrfs_compare_tree_result result)
 {
@@ -4122,6 +4236,11 @@ static int changed_ref(struct send_ctx *sctx,
 	return ret;
 }
 
+/*
+ * Process new/deleted/changed xattrs. We skip processing in the
+ * cur_inode_new_gen case because changed_inode did already initiate processing
+ * of xattrs. The reason is the same as in changed_ref
+ */
 static int changed_xattr(struct send_ctx *sctx,
 			 enum btrfs_compare_tree_result result)
 {
@@ -4141,6 +4260,11 @@ static int changed_xattr(struct send_ctx *sctx,
 	return ret;
 }
 
+/*
+ * Process new/deleted/changed extents. We skip processing in the
+ * cur_inode_new_gen case because changed_inode did already initiate processing
+ * of extents. The reason is the same as in changed_ref
+ */
 static int changed_extent(struct send_ctx *sctx,
 			  enum btrfs_compare_tree_result result)
 {
@@ -4157,7 +4281,10 @@ static int changed_extent(struct send_ctx *sctx,
 	return ret;
 }
 
-
+/*
+ * Updates compare related fields in sctx and simply forwards to the actual
+ * changed_xxx functions.
+ */
 static int changed_cb(struct btrfs_root *left_root,
 		      struct btrfs_root *right_root,
 		      struct btrfs_path *left_path,
@@ -4229,7 +4356,8 @@ static int full_send_tree(struct send_ctx *sctx)
 	}
 
 	/*
-	 * Make sure the tree has not changed
+	 * Make sure the tree has not changed after re-joining. We detect this
+	 * by comparing start_ctransid and ctransid. They should always match.
 	 */
 	spin_lock(&send_root->root_times_lock);
 	ctransid = btrfs_root_ctransid(&send_root->root_item);

commit e479d9bb5f8366a064915b3c9ac47ed6e9fcc7d3
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 16:09:35 2012 +0200

    Btrfs: update send_progress at correct places
    
    Updating send_progress in process_recorded_refs was not correct.
    It got updated too early in the cur_inode_new_gen case.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Reported-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 02e901adc3e8..f618224d2326 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2886,12 +2886,6 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 		}
 	}
 
-	/*
-	 * Current inode is now at it's new position, so we must increase
-	 * send_progress
-	 */
-	sctx->send_progress = sctx->cur_ino + 1;
-
 	ret = 0;
 
 out:
@@ -3896,6 +3890,15 @@ static int process_recorded_refs_if_needed(struct send_ctx *sctx, int at_end)
 		goto out;
 
 	ret = process_recorded_refs(sctx);
+	if (ret < 0)
+		goto out;
+
+	/*
+	 * We have processed the refs and thus need to advance send_progress.
+	 * Now, calls to get_cur_xxx will take the updated refs of the current
+	 * inode into account.
+	 */
+	sctx->send_progress = sctx->cur_ino + 1;
 
 out:
 	return ret;
@@ -3993,6 +3996,12 @@ static int changed_inode(struct send_ctx *sctx,
 
 	sctx->cur_ino = key->objectid;
 	sctx->cur_inode_new_gen = 0;
+
+	/*
+	 * Set send_progress to current inode. This will tell all get_cur_xxx
+	 * functions that the current inode's refs are not updated yet. Later,
+	 * when process_recorded_refs is finished, it is set to cur_ino + 1.
+	 */
 	sctx->send_progress = sctx->cur_ino;
 
 	if (result == BTRFS_COMPARE_TREE_NEW ||
@@ -4066,6 +4075,11 @@ static int changed_inode(struct send_ctx *sctx,
 			ret = process_all_refs(sctx, BTRFS_COMPARE_TREE_NEW);
 			if (ret < 0)
 				goto out;
+			/*
+			 * Advance send_progress now as we did not get into
+			 * process_recorded_refs_if_needed in the new_gen case.
+			 */
+			sctx->send_progress = sctx->cur_ino + 1;
 			ret = process_all_extents(sctx);
 			if (ret < 0)
 				goto out;

commit 7e0926fe5f20b5c88e51cba68512302b10f73d2a
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 14:20:58 2012 +0200

    Btrfs: fix use of radix_tree for name_cache in send/receive
    
    We can't easily use the index of the radix tree for inums as the
    radix tree uses 32bit indexes on 32bit kernels. For 32bit kernels,
    we now use the lower 32bit of the inum as index and an additional
    list to store multiple entries per radix tree entry.
    
    Reported-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 9cee678c0fb6..02e901adc3e8 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -125,6 +125,15 @@ struct send_ctx {
 
 struct name_cache_entry {
 	struct list_head list;
+	/*
+	 * radix_tree has only 32bit entries but we need to handle 64bit inums.
+	 * We use the lower 32bit of the 64bit inum to store it in the tree. If
+	 * more then one inum would fall into the same entry, we use radix_list
+	 * to store the additional entries. radix_list is also used to store
+	 * entries where two entries have the same inum but different
+	 * generations.
+	 */
+	struct list_head radix_list;
 	u64 ino;
 	u64 gen;
 	u64 parent_ino;
@@ -1726,27 +1735,21 @@ static int name_cache_insert(struct send_ctx *sctx,
 			     struct name_cache_entry *nce)
 {
 	int ret = 0;
-	struct name_cache_entry **ncea;
-
-	ncea = radix_tree_lookup(&sctx->name_cache, nce->ino);
-	if (ncea) {
-		if (!ncea[0])
-			ncea[0] = nce;
-		else if (!ncea[1])
-			ncea[1] = nce;
-		else
-			BUG();
-	} else {
-		ncea = kmalloc(sizeof(void *) * 2, GFP_NOFS);
-		if (!ncea)
+	struct list_head *nce_head;
+
+	nce_head = radix_tree_lookup(&sctx->name_cache,
+			(unsigned long)nce->ino);
+	if (!nce_head) {
+		nce_head = kmalloc(sizeof(*nce_head), GFP_NOFS);
+		if (!nce_head)
 			return -ENOMEM;
+		INIT_LIST_HEAD(nce_head);
 
-		ncea[0] = nce;
-		ncea[1] = NULL;
-		ret = radix_tree_insert(&sctx->name_cache, nce->ino, ncea);
+		ret = radix_tree_insert(&sctx->name_cache, nce->ino, nce_head);
 		if (ret < 0)
 			return ret;
 	}
+	list_add_tail(&nce->radix_list, nce_head);
 	list_add_tail(&nce->list, &sctx->name_cache_list);
 	sctx->name_cache_size++;
 
@@ -1756,41 +1759,36 @@ static int name_cache_insert(struct send_ctx *sctx,
 static void name_cache_delete(struct send_ctx *sctx,
 			      struct name_cache_entry *nce)
 {
-	struct name_cache_entry **ncea;
-
-	ncea = radix_tree_lookup(&sctx->name_cache, nce->ino);
-	BUG_ON(!ncea);
-
-	if (ncea[0] == nce)
-		ncea[0] = NULL;
-	else if (ncea[1] == nce)
-		ncea[1] = NULL;
-	else
-		BUG();
+	struct list_head *nce_head;
 
-	if (!ncea[0] && !ncea[1]) {
-		radix_tree_delete(&sctx->name_cache, nce->ino);
-		kfree(ncea);
-	}
+	nce_head = radix_tree_lookup(&sctx->name_cache,
+			(unsigned long)nce->ino);
+	BUG_ON(!nce_head);
 
+	list_del(&nce->radix_list);
 	list_del(&nce->list);
-
 	sctx->name_cache_size--;
+
+	if (list_empty(nce_head)) {
+		radix_tree_delete(&sctx->name_cache, (unsigned long)nce->ino);
+		kfree(nce_head);
+	}
 }
 
 static struct name_cache_entry *name_cache_search(struct send_ctx *sctx,
 						    u64 ino, u64 gen)
 {
-	struct name_cache_entry **ncea;
+	struct list_head *nce_head;
+	struct name_cache_entry *cur;
 
-	ncea = radix_tree_lookup(&sctx->name_cache, ino);
-	if (!ncea)
+	nce_head = radix_tree_lookup(&sctx->name_cache, (unsigned long)ino);
+	if (!nce_head)
 		return NULL;
 
-	if (ncea[0] && ncea[0]->gen == gen)
-		return ncea[0];
-	else if (ncea[1] && ncea[1]->gen == gen)
-		return ncea[1];
+	list_for_each_entry(cur, nce_head, radix_list) {
+		if (cur->ino == ino && cur->gen == gen)
+			return cur;
+	}
 	return NULL;
 }
 

commit 17589bd96eeb7c2ef2d3baeb05005a24932cd1e9
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 14:13:35 2012 +0200

    Btrfs: fix memory leak for name_cache in send/receive
    
    When everything is done, name_cache_free is called which however
    forgot to call kfree on the cache entries.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 68b2543e5d6c..9cee678c0fb6 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1822,6 +1822,7 @@ static void name_cache_free(struct send_ctx *sctx)
 
 	list_for_each_entry_safe(nce, tmp, &sctx->name_cache_list, list) {
 		name_cache_delete(sctx, nce);
+		kfree(nce);
 	}
 }
 

commit adbe7fb6c4750621a56867d9bb1980da3a4b8f33
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 12:51:32 2012 +0200

    Btrfs: don't break in the final loop of find_extent_clone
    
    If we break, we may miss the clone from send_root which we prefer
    over all other clones.
    
    Commit is a result of Arne's review.
    
    Reported-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index d2a4ee9125df..68b2543e5d6c 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1257,7 +1257,6 @@ verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, "
 			else if (sctx->clone_roots[i].root == sctx->send_root)
 				/* prefer clones from send_root over others */
 				cur_clone_root = sctx->clone_roots + i;
-			break;
 		}
 
 	}

commit 52f9e53ede8e1b261e68216c6c2f32bb3f26c795
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 16:32:45 2012 +0200

    Btrfs: use normal return path for root == send_root case
    
    Don't have a seperate return path for the mentioned case. Now
    we do the same "take lowest inode/offset" logic for all found clones.
    
    Commit is a result of Arne's review.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 36711123bdcf..d2a4ee9125df 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1109,12 +1109,6 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 			return 0;
 		if (offset + ctx->extent_len > ctx->cur_offset)
 			return 0;*/
-
-		bctx->found++;
-		found->found_refs++;
-		found->ino = ino;
-		found->offset = offset;
-		return 0;
 	}
 
 	bctx->found++;

commit 35075bb046cc91f42a0e5336bdc07f3279061add
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 12:44:34 2012 +0200

    Btrfs: use kmalloc instead of stack for backref_ctx
    
    Make sure to never get in trouble due to the backref_ctx
    which was on the stack before.
    
    Commit is a result of Arne's review.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a25be0c1a6b9..36711123bdcf 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1149,7 +1149,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	u64 extent_item_pos;
 	struct btrfs_file_extent_item *fi;
 	struct extent_buffer *eb = path->nodes[0];
-	struct backref_ctx backref_ctx;
+	struct backref_ctx *backref_ctx = NULL;
 	struct clone_root *cur_clone_root;
 	struct btrfs_key found_key;
 	struct btrfs_path *tmp_path;
@@ -1159,6 +1159,12 @@ static int find_extent_clone(struct send_ctx *sctx,
 	if (!tmp_path)
 		return -ENOMEM;
 
+	backref_ctx = kmalloc(sizeof(*backref_ctx), GFP_NOFS);
+	if (!backref_ctx) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
 	if (data_offset >= ino_size) {
 		/*
 		 * There may be extents that lie behind the file's size.
@@ -1206,12 +1212,12 @@ static int find_extent_clone(struct send_ctx *sctx,
 		cur_clone_root->found_refs = 0;
 	}
 
-	backref_ctx.sctx = sctx;
-	backref_ctx.found = 0;
-	backref_ctx.cur_objectid = ino;
-	backref_ctx.cur_offset = data_offset;
-	backref_ctx.found_itself = 0;
-	backref_ctx.extent_len = num_bytes;
+	backref_ctx->sctx = sctx;
+	backref_ctx->found = 0;
+	backref_ctx->cur_objectid = ino;
+	backref_ctx->cur_offset = data_offset;
+	backref_ctx->found_itself = 0;
+	backref_ctx->extent_len = num_bytes;
 
 	/*
 	 * The last extent of a file may be too large due to page alignment.
@@ -1219,7 +1225,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	 * __iterate_backrefs work.
 	 */
 	if (data_offset + num_bytes >= ino_size)
-		backref_ctx.extent_len = ino_size - data_offset;
+		backref_ctx->extent_len = ino_size - data_offset;
 
 	/*
 	 * Now collect all backrefs.
@@ -1227,11 +1233,11 @@ static int find_extent_clone(struct send_ctx *sctx,
 	extent_item_pos = logical - found_key.objectid;
 	ret = iterate_extent_inodes(sctx->send_root->fs_info,
 					found_key.objectid, extent_item_pos, 1,
-					__iterate_backrefs, &backref_ctx);
+					__iterate_backrefs, backref_ctx);
 	if (ret < 0)
 		goto out;
 
-	if (!backref_ctx.found_itself) {
+	if (!backref_ctx->found_itself) {
 		/* found a bug in backref code? */
 		ret = -EIO;
 		printk(KERN_ERR "btrfs: ERROR did not find backref in "
@@ -1246,7 +1252,7 @@ verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, "
 		"num_bytes=%llu, logical=%llu\n",
 		data_offset, ino, num_bytes, logical);
 
-	if (!backref_ctx.found)
+	if (!backref_ctx->found)
 		verbose_printk("btrfs:    no clones found\n");
 
 	cur_clone_root = NULL;
@@ -1271,6 +1277,7 @@ verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, "
 
 out:
 	btrfs_free_path(tmp_path);
+	kfree(backref_ctx);
 	return ret;
 }
 

commit ee849c0472a9fe1dc09fe8390965d993b9c4e979
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 12:42:05 2012 +0200

    Btrfs: rename backref_ctx::found_in_send_root to found_itself
    
    The new name should be easier to understand/read.
    
    Commit is a result of Arne's review.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index f1d44b125beb..a25be0c1a6b9 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1029,7 +1029,7 @@ struct backref_ctx {
 	u64 extent_len;
 
 	/* Just to check for bugs in backref resolving */
-	int found_in_send_root;
+	int found_itself;
 };
 
 static int __clone_root_cmp_bsearch(const void *key, const void *elt)
@@ -1077,7 +1077,7 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 	if (found->root == bctx->sctx->send_root &&
 	    ino == bctx->cur_objectid &&
 	    offset == bctx->cur_offset) {
-		bctx->found_in_send_root = 1;
+		bctx->found_itself = 1;
 	}
 
 	/*
@@ -1210,7 +1210,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	backref_ctx.found = 0;
 	backref_ctx.cur_objectid = ino;
 	backref_ctx.cur_offset = data_offset;
-	backref_ctx.found_in_send_root = 0;
+	backref_ctx.found_itself = 0;
 	backref_ctx.extent_len = num_bytes;
 
 	/*
@@ -1231,7 +1231,7 @@ static int find_extent_clone(struct send_ctx *sctx,
 	if (ret < 0)
 		goto out;
 
-	if (!backref_ctx.found_in_send_root) {
+	if (!backref_ctx.found_itself) {
 		/* found a bug in backref code? */
 		ret = -EIO;
 		printk(KERN_ERR "btrfs: ERROR did not find backref in "

commit d27aed5e24f8e7bb2b0d11e7a579f2bbdebafc2f
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 12:04:16 2012 +0200

    Btrfs: remove unused use_list from send/receive code
    
    use_list is a leftover and unused.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 328654ea4400..f1d44b125beb 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -125,7 +125,6 @@ struct send_ctx {
 
 struct name_cache_entry {
 	struct list_head list;
-	struct list_head use_list;
 	u64 ino;
 	u64 gen;
 	u64 parent_ino;
@@ -1906,7 +1905,6 @@ static int __get_cur_name_and_parent(struct send_ctx *sctx,
 	nce->name_len = fs_path_len(dest);
 	nce->ret = ret;
 	strcpy(nce->name, dest->start);
-	memset(&nce->use_list, 0, sizeof(nce->use_list));
 
 	if (ino < sctx->send_progress)
 		nce->need_later_update = 0;

commit ccf1626b49a94d66f3bb58d634888049ac695b46
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 11:46:29 2012 +0200

    Btrfs: add correct parent to check_dirs when dir got moved
    
    We only added the parent for the new position of a moved dir.
    We also need to add the old parent of the moved dir.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 9e3f6d127d82..328654ea4400 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2805,6 +2805,17 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 			if (ret < 0)
 				goto out;
 		}
+	} else if (S_ISDIR(sctx->cur_inode_mode) &&
+		   !list_empty(&sctx->deleted_refs)) {
+		/*
+		 * We have a moved dir. Add the old parent to check_dirs
+		 */
+		cur = list_entry(sctx->deleted_refs.next, struct recorded_ref,
+				list);
+		ret = ulist_add(check_dirs, cur->dir, cur->dir_gen,
+				GFP_NOFS);
+		if (ret < 0)
+			goto out;
 	} else if (!S_ISDIR(sctx->cur_inode_mode)) {
 		/*
 		 * We have a non dir inode. Go through all deleted refs and

commit 9ea3ef516d828e435d283b7d5f0de05fd72a23ac
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 11:08:09 2012 +0200

    Btrfs: remove unused code with #if 0
    
    fs_path_remove is not used at the moment due to a previous patch.
    Remove it for now (with #if 0) to avoid compile warnings.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index bea5b4378cc5..9e3f6d127d82 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -327,6 +327,7 @@ static int fs_path_add_from_extent_buffer(struct fs_path *p,
 	return ret;
 }
 
+#if 0
 static void fs_path_remove(struct fs_path *p)
 {
 	BUG_ON(p->reversed);
@@ -334,6 +335,7 @@ static void fs_path_remove(struct fs_path *p)
 		p->end--;
 	*p->end = 0;
 }
+#endif
 
 static int fs_path_copy(struct fs_path *p, struct fs_path *from)
 {

commit b9291affaa4576762c30fb31083f33f5d745dea1
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 11:07:18 2012 +0200

    Btrfs: add missing check for dir != tmp_dir to is_first_ref
    
    We missed that check which resultet in all refs with the same name
    being reported as first_ref.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index a5fae484d4e1..bea5b4378cc5 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -1589,7 +1589,7 @@ static int is_first_ref(struct send_ctx *sctx,
 	if (ret < 0)
 		goto out;
 
-	if (name_len != fs_path_len(tmp_name)) {
+	if (dir != tmp_dir || name_len != fs_path_len(tmp_name)) {
 		ret = 0;
 		goto out;
 	}

commit 1f4692da951af4179a6522c6b48a09a43d37e614
Author: Alexander Block <ablock84@googlemail.com>
Date:   Sat Jul 28 10:42:24 2012 +0200

    Btrfs: fix cur_ino < parent_ino case for send/receive
    
    When the current inodes inum is smaller then the inum of the
    parent directory strange things were happending due to wrong
    path resolution and other bugs. Fix this with a new approach
    for the problem.
    
    Reported-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 5721401548e8..a5fae484d4e1 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -107,7 +107,6 @@ struct send_ctx {
 	int cur_inode_new;
 	int cur_inode_new_gen;
 	int cur_inode_deleted;
-	int cur_inode_first_ref_orphan;
 	u64 cur_inode_size;
 	u64 cur_inode_mode;
 
@@ -2296,25 +2295,25 @@ verbose_printk("btrfs: send_utimes %llu\n", ino);
  * a valid path yet because we did not process the refs yet. So, the inode
  * is created as orphan.
  */
-static int send_create_inode(struct send_ctx *sctx, struct btrfs_path *path,
-			     struct btrfs_key *key)
+static int send_create_inode(struct send_ctx *sctx, u64 ino)
 {
 	int ret = 0;
-	struct extent_buffer *eb = path->nodes[0];
-	struct btrfs_inode_item *ii;
 	struct fs_path *p;
-	int slot = path->slots[0];
 	int cmd;
+	u64 gen;
 	u64 mode;
+	u64 rdev;
 
-verbose_printk("btrfs: send_create_inode %llu\n", sctx->cur_ino);
+verbose_printk("btrfs: send_create_inode %llu\n", ino);
 
 	p = fs_path_alloc(sctx);
 	if (!p)
 		return -ENOMEM;
 
-	ii = btrfs_item_ptr(eb, slot, struct btrfs_inode_item);
-	mode = btrfs_inode_mode(eb, ii);
+	ret = get_inode_info(sctx->send_root, ino, NULL, &gen, &mode, NULL,
+			NULL, &rdev);
+	if (ret < 0)
+		goto out;
 
 	if (S_ISREG(mode))
 		cmd = BTRFS_SEND_C_MKFILE;
@@ -2339,22 +2338,22 @@ verbose_printk("btrfs: send_create_inode %llu\n", sctx->cur_ino);
 	if (ret < 0)
 		goto out;
 
-	ret = gen_unique_name(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
+	ret = gen_unique_name(sctx, ino, gen, p);
 	if (ret < 0)
 		goto out;
 
 	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
-	TLV_PUT_U64(sctx, BTRFS_SEND_A_INO, sctx->cur_ino);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_INO, ino);
 
 	if (S_ISLNK(mode)) {
 		fs_path_reset(p);
-		ret = read_symlink(sctx, sctx->send_root, sctx->cur_ino, p);
+		ret = read_symlink(sctx, sctx->send_root, ino, p);
 		if (ret < 0)
 			goto out;
 		TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH_LINK, p);
 	} else if (S_ISCHR(mode) || S_ISBLK(mode) ||
 		   S_ISFIFO(mode) || S_ISSOCK(mode)) {
-		TLV_PUT_U64(sctx, BTRFS_SEND_A_RDEV, btrfs_inode_rdev(eb, ii));
+		TLV_PUT_U64(sctx, BTRFS_SEND_A_RDEV, rdev);
 	}
 
 	ret = send_cmd(sctx);
@@ -2368,6 +2367,92 @@ verbose_printk("btrfs: send_create_inode %llu\n", sctx->cur_ino);
 	return ret;
 }
 
+/*
+ * We need some special handling for inodes that get processed before the parent
+ * directory got created. See process_recorded_refs for details.
+ * This function does the check if we already created the dir out of order.
+ */
+static int did_create_dir(struct send_ctx *sctx, u64 dir)
+{
+	int ret = 0;
+	struct btrfs_path *path = NULL;
+	struct btrfs_key key;
+	struct btrfs_key found_key;
+	struct btrfs_key di_key;
+	struct extent_buffer *eb;
+	struct btrfs_dir_item *di;
+	int slot;
+
+	path = alloc_path_for_send();
+	if (!path) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	key.objectid = dir;
+	key.type = BTRFS_DIR_INDEX_KEY;
+	key.offset = 0;
+	while (1) {
+		ret = btrfs_search_slot_for_read(sctx->send_root, &key, path,
+				1, 0);
+		if (ret < 0)
+			goto out;
+		if (!ret) {
+			eb = path->nodes[0];
+			slot = path->slots[0];
+			btrfs_item_key_to_cpu(eb, &found_key, slot);
+		}
+		if (ret || found_key.objectid != key.objectid ||
+		    found_key.type != key.type) {
+			ret = 0;
+			goto out;
+		}
+
+		di = btrfs_item_ptr(eb, slot, struct btrfs_dir_item);
+		btrfs_dir_item_key_to_cpu(eb, di, &di_key);
+
+		if (di_key.objectid < sctx->send_progress) {
+			ret = 1;
+			goto out;
+		}
+
+		key.offset = found_key.offset + 1;
+		btrfs_release_path(path);
+	}
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+/*
+ * Only creates the inode if it is:
+ * 1. Not a directory
+ * 2. Or a directory which was not created already due to out of order
+ *    directories. See did_create_dir and process_recorded_refs for details.
+ */
+static int send_create_inode_if_needed(struct send_ctx *sctx)
+{
+	int ret;
+
+	if (S_ISDIR(sctx->cur_inode_mode)) {
+		ret = did_create_dir(sctx, sctx->cur_ino);
+		if (ret < 0)
+			goto out;
+		if (ret) {
+			ret = 0;
+			goto out;
+		}
+	}
+
+	ret = send_create_inode(sctx, sctx->cur_ino);
+	if (ret < 0)
+		goto out;
+
+out:
+	return ret;
+}
+
 struct recorded_ref {
 	struct list_head list;
 	char *dir_path;
@@ -2517,160 +2602,6 @@ static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
 	return ret;
 }
 
-struct finish_unordered_dir_ctx {
-	struct send_ctx *sctx;
-	struct fs_path *cur_path;
-	struct fs_path *dir_path;
-	u64 dir_ino;
-	int need_delete;
-	int delete_pass;
-};
-
-int __finish_unordered_dir(int num, struct btrfs_key *di_key,
-			   const char *name, int name_len,
-			   const char *data, int data_len,
-			   u8 type, void *ctx)
-{
-	int ret = 0;
-	struct finish_unordered_dir_ctx *fctx = ctx;
-	struct send_ctx *sctx = fctx->sctx;
-	u64 di_gen;
-	u64 di_mode;
-	int is_orphan = 0;
-
-	if (di_key->objectid >= fctx->dir_ino)
-		goto out;
-
-	fs_path_reset(fctx->cur_path);
-
-	ret = get_inode_info(sctx->send_root, di_key->objectid,
-			NULL, &di_gen, &di_mode, NULL, NULL, NULL);
-	if (ret < 0)
-		goto out;
-
-	ret = is_first_ref(sctx, sctx->send_root, di_key->objectid,
-			fctx->dir_ino, name, name_len);
-	if (ret < 0)
-		goto out;
-	if (ret) {
-		is_orphan = 1;
-		ret = gen_unique_name(sctx, di_key->objectid, di_gen,
-				fctx->cur_path);
-	} else {
-		ret = get_cur_path(sctx, di_key->objectid, di_gen,
-				fctx->cur_path);
-	}
-	if (ret < 0)
-		goto out;
-
-	ret = fs_path_add(fctx->dir_path, name, name_len);
-	if (ret < 0)
-		goto out;
-
-	if (!fctx->delete_pass) {
-		if (S_ISDIR(di_mode)) {
-			ret = send_rename(sctx, fctx->cur_path,
-					fctx->dir_path);
-		} else {
-			ret = send_link(sctx, fctx->dir_path,
-					fctx->cur_path);
-			if (is_orphan)
-				fctx->need_delete = 1;
-		}
-	} else if (!S_ISDIR(di_mode)) {
-		ret = send_unlink(sctx, fctx->cur_path);
-	} else {
-		ret = 0;
-	}
-
-	fs_path_remove(fctx->dir_path);
-
-out:
-	return ret;
-}
-
-/*
- * Go through all dir items and see if we find refs which could not be created
- * in the past because the dir did not exist at that time.
- */
-static int finish_outoforder_dir(struct send_ctx *sctx, u64 dir, u64 dir_gen)
-{
-	int ret = 0;
-	struct btrfs_path *path = NULL;
-	struct btrfs_key key;
-	struct btrfs_key found_key;
-	struct extent_buffer *eb;
-	struct finish_unordered_dir_ctx fctx;
-	int slot;
-
-	path = alloc_path_for_send();
-	if (!path) {
-		ret = -ENOMEM;
-		goto out;
-	}
-
-	memset(&fctx, 0, sizeof(fctx));
-	fctx.sctx = sctx;
-	fctx.cur_path = fs_path_alloc(sctx);
-	fctx.dir_path = fs_path_alloc(sctx);
-	if (!fctx.cur_path || !fctx.dir_path) {
-		ret = -ENOMEM;
-		goto out;
-	}
-	fctx.dir_ino = dir;
-
-	ret = get_cur_path(sctx, dir, dir_gen, fctx.dir_path);
-	if (ret < 0)
-		goto out;
-
-	/*
-	 * We do two passes. The first links in the new refs and the second
-	 * deletes orphans if required. Deletion of orphans is not required for
-	 * directory inodes, as we always have only one ref and use rename
-	 * instead of link for those.
-	 */
-
-again:
-	key.objectid = dir;
-	key.type = BTRFS_DIR_ITEM_KEY;
-	key.offset = 0;
-	while (1) {
-		ret = btrfs_search_slot_for_read(sctx->send_root, &key, path,
-				1, 0);
-		if (ret < 0)
-			goto out;
-		eb = path->nodes[0];
-		slot = path->slots[0];
-		btrfs_item_key_to_cpu(eb, &found_key, slot);
-
-		if (found_key.objectid != key.objectid ||
-		    found_key.type != key.type) {
-			btrfs_release_path(path);
-			break;
-		}
-
-		ret = iterate_dir_item(sctx, sctx->send_root, path,
-				&found_key, __finish_unordered_dir,
-				&fctx);
-		if (ret < 0)
-			goto out;
-
-		key.offset = found_key.offset + 1;
-		btrfs_release_path(path);
-	}
-
-	if (!fctx.delete_pass && fctx.need_delete) {
-		fctx.delete_pass = 1;
-		goto again;
-	}
-
-out:
-	btrfs_free_path(path);
-	fs_path_free(sctx, fctx.cur_path);
-	fs_path_free(sctx, fctx.dir_path);
-	return ret;
-}
-
 /*
  * This does all the move/link/unlink/rmdir magic.
  */
@@ -2678,6 +2609,7 @@ static int process_recorded_refs(struct send_ctx *sctx)
 {
 	int ret = 0;
 	struct recorded_ref *cur;
+	struct recorded_ref *cur2;
 	struct ulist *check_dirs = NULL;
 	struct ulist_iterator uit;
 	struct ulist_node *un;
@@ -2734,6 +2666,46 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 	}
 
 	list_for_each_entry(cur, &sctx->new_refs, list) {
+		/*
+		 * We may have refs where the parent directory does not exist
+		 * yet. This happens if the parent directories inum is higher
+		 * the the current inum. To handle this case, we create the
+		 * parent directory out of order. But we need to check if this
+		 * did already happen before due to other refs in the same dir.
+		 */
+		ret = get_cur_inode_state(sctx, cur->dir, cur->dir_gen);
+		if (ret < 0)
+			goto out;
+		if (ret == inode_state_will_create) {
+			ret = 0;
+			/*
+			 * First check if any of the current inodes refs did
+			 * already create the dir.
+			 */
+			list_for_each_entry(cur2, &sctx->new_refs, list) {
+				if (cur == cur2)
+					break;
+				if (cur2->dir == cur->dir) {
+					ret = 1;
+					break;
+				}
+			}
+
+			/*
+			 * If that did not happen, check if a previous inode
+			 * did already create the dir.
+			 */
+			if (!ret)
+				ret = did_create_dir(sctx, cur->dir);
+			if (ret < 0)
+				goto out;
+			if (!ret) {
+				ret = send_create_inode(sctx, cur->dir);
+				if (ret < 0)
+					goto out;
+			}
+		}
+
 		/*
 		 * Check if this new ref would overwrite the first ref of
 		 * another unprocessed inode. If yes, orphanize the
@@ -2768,7 +2740,7 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 		 * inode, move it and update valid_path. If not, link or move
 		 * it depending on the inode mode.
 		 */
-		if (is_orphan && !sctx->cur_inode_first_ref_orphan) {
+		if (is_orphan) {
 			ret = send_rename(sctx, valid_path, cur->full_path);
 			if (ret < 0)
 				goto out;
@@ -2844,35 +2816,9 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 			if (ret < 0)
 				goto out;
 			if (!ret) {
-				/*
-				 * In case the inode was moved to a directory
-				 * that was not created yet (see
-				 * __record_new_ref), we can not unlink the ref
-				 * as it will be needed later when the parent
-				 * directory is created, so that we can move in
-				 * the inode to the new dir.
-				 */
-				if (!is_orphan &&
-				    sctx->cur_inode_first_ref_orphan) {
-					ret = orphanize_inode(sctx,
-							sctx->cur_ino,
-							sctx->cur_inode_gen,
-							cur->full_path);
-					if (ret < 0)
-						goto out;
-					ret = gen_unique_name(sctx,
-							sctx->cur_ino,
-							sctx->cur_inode_gen,
-							valid_path);
-					if (ret < 0)
-						goto out;
-					is_orphan = 1;
-
-				} else {
-					ret = send_unlink(sctx, cur->full_path);
-					if (ret < 0)
-						goto out;
-				}
+				ret = send_unlink(sctx, cur->full_path);
+				if (ret < 0)
+					goto out;
 			}
 			ret = ulist_add(check_dirs, cur->dir, cur->dir_gen,
 					GFP_NOFS);
@@ -2885,11 +2831,8 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 		 * happen when a previous inode did overwrite the first ref
 		 * of this inode and no new refs were added for the current
 		 * inode.
-		 * We can however not delete the orphan in case the inode relies
-		 * in a directory that was not created yet (see
-		 * __record_new_ref)
 		 */
-		if (is_orphan && !sctx->cur_inode_first_ref_orphan) {
+		if (is_orphan) {
 			ret = send_unlink(sctx, valid_path);
 			if (ret < 0)
 				goto out;
@@ -2939,19 +2882,6 @@ verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
 	 */
 	sctx->send_progress = sctx->cur_ino + 1;
 
-	/*
-	 * We may have a directory here that has pending refs which could not
-	 * be created before (because the dir did not exist before, see
-	 * __record_new_ref). finish_outoforder_dir will link/move the pending
-	 * refs.
-	 */
-	if (S_ISDIR(sctx->cur_inode_mode) && sctx->cur_inode_new) {
-		ret = finish_outoforder_dir(sctx, sctx->cur_ino,
-				sctx->cur_inode_gen);
-		if (ret < 0)
-			goto out;
-	}
-
 	ret = 0;
 
 out:
@@ -2979,31 +2909,6 @@ static int __record_new_ref(int num, u64 dir, int index,
 	if (ret < 0)
 		goto out;
 
-	/*
-	 * The parent may be non-existent at this point in time. This happens
-	 * if the ino of the parent dir is higher then the current ino. In this
-	 * case, we can not process this ref until the parent dir is finally
-	 * created. If we reach the parent dir later, process_recorded_refs
-	 * will go through all dir items and process the refs that could not be
-	 * processed before. In case this is the first ref, we set
-	 * cur_inode_first_ref_orphan to 1 to inform process_recorded_refs to
-	 * keep an orphan of the inode so that it later can be used for
-	 * link/move
-	 */
-	ret = is_inode_existent(sctx, dir, gen);
-	if (ret < 0)
-		goto out;
-	if (!ret) {
-		ret = is_first_ref(sctx, sctx->send_root, sctx->cur_ino, dir,
-				name->start, fs_path_len(name));
-		if (ret < 0)
-			goto out;
-		if (ret)
-			sctx->cur_inode_first_ref_orphan = 1;
-		ret = 0;
-		goto out;
-	}
-
 	ret = get_cur_path(sctx, dir, gen, p);
 	if (ret < 0)
 		goto out;
@@ -4078,7 +3983,6 @@ static int changed_inode(struct send_ctx *sctx,
 
 	sctx->cur_ino = key->objectid;
 	sctx->cur_inode_new_gen = 0;
-	sctx->cur_inode_first_ref_orphan = 0;
 	sctx->send_progress = sctx->cur_ino;
 
 	if (result == BTRFS_COMPARE_TREE_NEW ||
@@ -4115,8 +4019,7 @@ static int changed_inode(struct send_ctx *sctx,
 		sctx->cur_inode_mode = btrfs_inode_mode(
 				sctx->left_path->nodes[0], left_ii);
 		if (sctx->cur_ino != BTRFS_FIRST_FREE_OBJECTID)
-			ret = send_create_inode(sctx, sctx->left_path,
-					sctx->cmp_key);
+			ret = send_create_inode_if_needed(sctx);
 	} else if (result == BTRFS_COMPARE_TREE_DELETED) {
 		sctx->cur_inode_gen = right_gen;
 		sctx->cur_inode_new = 0;
@@ -4146,8 +4049,7 @@ static int changed_inode(struct send_ctx *sctx,
 					sctx->left_path->nodes[0], left_ii);
 			sctx->cur_inode_mode = btrfs_inode_mode(
 					sctx->left_path->nodes[0], left_ii);
-			ret = send_create_inode(sctx, sctx->left_path,
-					sctx->cmp_key);
+			ret = send_create_inode_if_needed(sctx);
 			if (ret < 0)
 				goto out;
 

commit 85a7b33b9653ade7b26b9f29765cb1f0719c1e84
Author: Alexander Block <ablock84@googlemail.com>
Date:   Thu Jul 26 23:39:10 2012 +0200

    Btrfs: add rdev to get_inode_info in send/receive
    
    We need rdev in the next commit.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index fb5ffe95f869..5721401548e8 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -687,7 +687,8 @@ verbose_printk("btrfs: send_rmdir %s\n", path->start);
  */
 static int get_inode_info(struct btrfs_root *root,
 			  u64 ino, u64 *size, u64 *gen,
-			  u64 *mode, u64 *uid, u64 *gid)
+			  u64 *mode, u64 *uid, u64 *gid,
+			  u64 *rdev)
 {
 	int ret;
 	struct btrfs_inode_item *ii;
@@ -721,6 +722,8 @@ static int get_inode_info(struct btrfs_root *root,
 		*uid = btrfs_inode_uid(path->nodes[0], ii);
 	if (gid)
 		*gid = btrfs_inode_gid(path->nodes[0], ii);
+	if (rdev)
+		*rdev = btrfs_inode_rdev(path->nodes[0], ii);
 
 out:
 	btrfs_free_path(path);
@@ -1081,7 +1084,8 @@ static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
 	 * There are inodes that have extents that lie behind it's i_size. Don't
 	 * accept clones from these extents.
 	 */
-	ret = get_inode_info(found->root, ino, &i_size, NULL, NULL, NULL, NULL);
+	ret = get_inode_info(found->root, ino, &i_size, NULL, NULL, NULL, NULL,
+			NULL);
 	if (ret < 0)
 		return ret;
 
@@ -1404,7 +1408,7 @@ static int get_cur_inode_state(struct send_ctx *sctx, u64 ino, u64 gen)
 	u64 right_gen;
 
 	ret = get_inode_info(sctx->send_root, ino, NULL, &left_gen, NULL, NULL,
-			NULL);
+			NULL, NULL);
 	if (ret < 0 && ret != -ENOENT)
 		goto out;
 	left_ret = ret;
@@ -1413,7 +1417,7 @@ static int get_cur_inode_state(struct send_ctx *sctx, u64 ino, u64 gen)
 		right_ret = -ENOENT;
 	} else {
 		ret = get_inode_info(sctx->parent_root, ino, NULL, &right_gen,
-				NULL, NULL, NULL);
+				NULL, NULL, NULL, NULL);
 		if (ret < 0 && ret != -ENOENT)
 			goto out;
 		right_ret = ret;
@@ -1557,7 +1561,7 @@ static int get_first_ref(struct send_ctx *sctx,
 	btrfs_release_path(path);
 
 	ret = get_inode_info(root, found_key.offset, NULL, dir_gen, NULL, NULL,
-			NULL);
+			NULL, NULL);
 	if (ret < 0)
 		goto out;
 
@@ -1628,7 +1632,7 @@ static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
 
 	if (other_inode > sctx->send_progress) {
 		ret = get_inode_info(sctx->parent_root, other_inode, NULL,
-				who_gen, NULL, NULL, NULL);
+				who_gen, NULL, NULL, NULL, NULL);
 		if (ret < 0)
 			goto out;
 
@@ -1671,7 +1675,7 @@ static int did_overwrite_ref(struct send_ctx *sctx,
 	}
 
 	ret = get_inode_info(sctx->send_root, ow_inode, NULL, &gen, NULL, NULL,
-			NULL);
+			NULL, NULL);
 	if (ret < 0)
 		goto out;
 
@@ -2540,7 +2544,7 @@ int __finish_unordered_dir(int num, struct btrfs_key *di_key,
 	fs_path_reset(fctx->cur_path);
 
 	ret = get_inode_info(sctx->send_root, di_key->objectid,
-			NULL, &di_gen, &di_mode, NULL, NULL);
+			NULL, &di_gen, &di_mode, NULL, NULL, NULL);
 	if (ret < 0)
 		goto out;
 
@@ -2971,7 +2975,7 @@ static int __record_new_ref(int num, u64 dir, int index,
 		return -ENOMEM;
 
 	ret = get_inode_info(sctx->send_root, dir, NULL, &gen, NULL, NULL,
-			NULL);
+			NULL, NULL);
 	if (ret < 0)
 		goto out;
 
@@ -3029,7 +3033,7 @@ static int __record_deleted_ref(int num, u64 dir, int index,
 		return -ENOMEM;
 
 	ret = get_inode_info(sctx->parent_root, dir, NULL, &gen, NULL, NULL,
-			NULL);
+			NULL, NULL);
 	if (ret < 0)
 		goto out;
 
@@ -3642,7 +3646,7 @@ verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
 
 	if (clone_root2 == sctx->send_root) {
 		ret = get_inode_info(sctx->send_root, clone_root->ino, NULL,
-				&gen, NULL, NULL, NULL);
+				&gen, NULL, NULL, NULL, NULL);
 		if (ret < 0)
 			goto out;
 		ret = get_cur_path(sctx, clone_root->ino, gen, p);
@@ -4004,7 +4008,7 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 		goto out;
 
 	ret = get_inode_info(sctx->send_root, sctx->cur_ino, NULL, NULL,
-			&left_mode, &left_uid, &left_gid);
+			&left_mode, &left_uid, &left_gid, NULL);
 	if (ret < 0)
 		goto out;
 
@@ -4015,7 +4019,7 @@ static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
 		} else {
 			ret = get_inode_info(sctx->parent_root, sctx->cur_ino,
 					NULL, NULL, &right_mode, &right_uid,
-					&right_gid);
+					&right_gid, NULL);
 			if (ret < 0)
 				goto out;
 

commit a1857ebe752d77d96c89d964500a9528df6d320e
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Fri Jul 27 10:11:13 2012 +1000

    Btrfs: using vmalloc and friends needs vmalloc.h
    
    On powerpc, we don't get the implicit vmalloc.h include, and as a result
    the build fails noisily:
    
      fs/btrfs/send.c: In function 'fs_path_free':
      fs/btrfs/send.c:185:4: error: implicit declaration of function 'vfree' [-Werror=implicit-function-declaration]
      fs/btrfs/send.c: In function 'fs_path_ensure_buf':
      fs/btrfs/send.c:215:4: error: implicit declaration of function 'vmalloc' [-Werror=implicit-function-declaration]
      fs/btrfs/send.c:215:12: warning: assignment makes pointer from integer without a cast [enabled by default]
      fs/btrfs/send.c:225:12: warning: assignment makes pointer from integer without a cast [enabled by default]
      fs/btrfs/send.c:233:13: warning: assignment makes pointer from integer without a cast [enabled by default]
      fs/btrfs/send.c: In function 'iterate_dir_item':
      fs/btrfs/send.c:900:10: warning: assignment makes pointer from integer without a cast [enabled by default]
      fs/btrfs/send.c:909:11: warning: assignment makes pointer from integer without a cast [enabled by default]
      fs/btrfs/send.c: In function 'btrfs_ioctl_send':
      fs/btrfs/send.c:4463:17: warning: assignment makes pointer from integer without a cast [enabled by default]
      fs/btrfs/send.c:4469:17: warning: assignment makes pointer from integer without a cast [enabled by default]
      fs/btrfs/send.c:4475:2: error: implicit declaration of function 'vzalloc' [-Werror=implicit-function-declaration]
      fs/btrfs/send.c:4475:20: warning: assignment makes pointer from integer without a cast [enabled by default]
      fs/btrfs/send.c:4483:21: warning: assignment makes pointer from integer without a cast [enabled by default]
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index c8ca49b1bb4d..fb5ffe95f869 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -25,6 +25,7 @@
 #include <linux/posix_acl_xattr.h>
 #include <linux/radix-tree.h>
 #include <linux/crc32c.h>
+#include <linux/vmalloc.h>
 
 #include "send.h"
 #include "backref.h"

commit e2aed8dfa50bb061747eeb14e6af099554a03b76
Merge: 476525004ac7 b24baf6917a3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 26 14:48:55 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull large btrfs update from Chris Mason:
     "This pull request is very large, and the two main features in here
      have been under testing/devel for quite a while.
    
      We have subvolume quotas from the strato developers.  This enables
      full tracking of how many blocks are allocated to each subvolume (and
      all snapshots) and you can set limits on a per-subvolume basis.  You
      can also create quota groups and toss multiple subvolumes into a big
      group.  It's everything you need to be a web hosting company and give
      each user their own subvolume.
    
      The userland side of the quotas is being refreshed, they'll send out
      details on where to grab it soon.
    
      Next is the kernel side of btrfs send/receive from Alexander Block.
      This leverages the same infrastructure as the quota code to figure out
      relationships between blocks and their owners.  It can then compute
      the difference between two snapshots and sends the diffs in a neutral
      format into userland.
    
      The basic model:
    
            create a snapshot
            send that snapshot as the initial backup
            make changes
            create a second snapshot
            send the incremental as a backup
            delete the first snapshot
            (use the second snapshot for the next incremental)
    
      The receive portion is all in userland, and in the 'next' branch of my
      btrfs-progs repo.
    
      There's still some work to do in terms of optimizing the send side
      from kernel to userland.  The really important part is figuring out
      how two snapshots are different, and this is where we are
      concentrating right now.  The initial send of a dataset is a little
      slower than tar, but the incremental sends are dramatically faster
      than what rsync can do.
    
      On top of all of that, we have a nice queue of fixes, cleanups and
      optimizations."
    
    Fix up trivial modify/del conflict in fs/btrfs/ioctl.c
    
    Also fix up semantic conflict in fs/btrfs/send.c: the interface to
    dentry_open() changed in commit 765927b2d508 ("switch dentry_open() to
    struct path, make it grab references itself"), and since it now grabs
    whatever references it needs, we should no longer do the mntget() on the
    mnt (and we need to dput() the dentry reference we took).
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (65 commits)
      Btrfs: uninit variable fixes in send/receive
      Btrfs: introduce BTRFS_IOC_SEND for btrfs send/receive
      Btrfs: add btrfs_compare_trees function
      Btrfs: introduce subvol uuids and times
      Btrfs: make iref_to_path non static
      Btrfs: add a barrier before a waitqueue_active check
      Btrfs: call the ordered free operation without any locks held
      Btrfs: Check INCOMPAT flags on remount and add helper function
      Btrfs: add helper for tree enumeration
      btrfs: allow cross-subvolume file clone
      Btrfs: improve multi-thread buffer read
      Btrfs: make btrfs's allocation smoothly with preallocation
      Btrfs: lock the transition from dirty to writeback for an eb
      Btrfs: fix potential race in extent buffer freeing
      Btrfs: don't return true in releasepage unless we actually freed the eb
      Btrfs: suppress printk() if all device I/O stats are zero
      Btrfs: remove unwanted printk() for btrfs device I/O stats
      Btrfs: rewrite BTRFS_SETGET_FUNCS
      Btrfs: zero unused bytes in inode item
      Btrfs: kill free_space pointer from inode structure
      ...
    
    Conflicts:
            fs/btrfs/ioctl.c

commit b24baf6917a376420d535548e1f88744028bcf24
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Jul 25 19:21:10 2012 -0400

    Btrfs: uninit variable fixes in send/receive
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 5394cb75012a..bf232c88a0bf 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -2676,7 +2676,7 @@ static int process_recorded_refs(struct send_ctx *sctx)
 	struct ulist_iterator uit;
 	struct ulist_node *un;
 	struct fs_path *valid_path = NULL;
-	u64 ow_inode;
+	u64 ow_inode = 0;
 	u64 ow_gen;
 	int did_overwrite = 0;
 	int is_orphan = 0;
@@ -3553,7 +3553,7 @@ static int send_write(struct send_ctx *sctx, u64 offset, u32 len)
 	int ret = 0;
 	struct fs_path *p;
 	loff_t pos = offset;
-	int readed;
+	int readed = 0;
 	mm_segment_t old_fs;
 
 	p = fs_path_alloc(sctx);

commit 31db9f7c23fbf7e95026143f79645de6507b583b
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Jul 25 23:19:24 2012 +0200

    Btrfs: introduce BTRFS_IOC_SEND for btrfs send/receive
    
    This patch introduces the BTRFS_IOC_SEND ioctl that is
    required for send. It allows btrfs-progs to implement
    full and incremental sends. Patches for btrfs-progs will
    follow.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>
    Reviewed-by: David Sterba <dave@jikos.cz>
    Reviewed-by: Arne Jansen <sensille@gmx.net>
    Reviewed-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Reviewed-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
new file mode 100644
index 000000000000..5394cb75012a
--- /dev/null
+++ b/fs/btrfs/send.c
@@ -0,0 +1,4570 @@
+/*
+ * Copyright (C) 2012 Alexander Block.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
+#include <linux/bsearch.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/sort.h>
+#include <linux/mount.h>
+#include <linux/xattr.h>
+#include <linux/posix_acl_xattr.h>
+#include <linux/radix-tree.h>
+#include <linux/crc32c.h>
+
+#include "send.h"
+#include "backref.h"
+#include "locking.h"
+#include "disk-io.h"
+#include "btrfs_inode.h"
+#include "transaction.h"
+
+static int g_verbose = 0;
+
+#define verbose_printk(...) if (g_verbose) printk(__VA_ARGS__)
+
+/*
+ * A fs_path is a helper to dynamically build path names with unknown size.
+ * It reallocates the internal buffer on demand.
+ * It allows fast adding of path elements on the right side (normal path) and
+ * fast adding to the left side (reversed path). A reversed path can also be
+ * unreversed if needed.
+ */
+struct fs_path {
+	union {
+		struct {
+			char *start;
+			char *end;
+			char *prepared;
+
+			char *buf;
+			int buf_len;
+			int reversed:1;
+			int virtual_mem:1;
+			char inline_buf[];
+		};
+		char pad[PAGE_SIZE];
+	};
+};
+#define FS_PATH_INLINE_SIZE \
+	(sizeof(struct fs_path) - offsetof(struct fs_path, inline_buf))
+
+
+/* reused for each extent */
+struct clone_root {
+	struct btrfs_root *root;
+	u64 ino;
+	u64 offset;
+
+	u64 found_refs;
+};
+
+#define SEND_CTX_MAX_NAME_CACHE_SIZE 128
+#define SEND_CTX_NAME_CACHE_CLEAN_SIZE (SEND_CTX_MAX_NAME_CACHE_SIZE * 2)
+
+struct send_ctx {
+	struct file *send_filp;
+	loff_t send_off;
+	char *send_buf;
+	u32 send_size;
+	u32 send_max_size;
+	u64 total_send_size;
+	u64 cmd_send_size[BTRFS_SEND_C_MAX + 1];
+
+	struct vfsmount *mnt;
+
+	struct btrfs_root *send_root;
+	struct btrfs_root *parent_root;
+	struct clone_root *clone_roots;
+	int clone_roots_cnt;
+
+	/* current state of the compare_tree call */
+	struct btrfs_path *left_path;
+	struct btrfs_path *right_path;
+	struct btrfs_key *cmp_key;
+
+	/*
+	 * infos of the currently processed inode. In case of deleted inodes,
+	 * these are the values from the deleted inode.
+	 */
+	u64 cur_ino;
+	u64 cur_inode_gen;
+	int cur_inode_new;
+	int cur_inode_new_gen;
+	int cur_inode_deleted;
+	int cur_inode_first_ref_orphan;
+	u64 cur_inode_size;
+	u64 cur_inode_mode;
+
+	u64 send_progress;
+
+	struct list_head new_refs;
+	struct list_head deleted_refs;
+
+	struct radix_tree_root name_cache;
+	struct list_head name_cache_list;
+	int name_cache_size;
+
+	struct file *cur_inode_filp;
+	char *read_buf;
+};
+
+struct name_cache_entry {
+	struct list_head list;
+	struct list_head use_list;
+	u64 ino;
+	u64 gen;
+	u64 parent_ino;
+	u64 parent_gen;
+	int ret;
+	int need_later_update;
+	int name_len;
+	char name[];
+};
+
+static void fs_path_reset(struct fs_path *p)
+{
+	if (p->reversed) {
+		p->start = p->buf + p->buf_len - 1;
+		p->end = p->start;
+		*p->start = 0;
+	} else {
+		p->start = p->buf;
+		p->end = p->start;
+		*p->start = 0;
+	}
+}
+
+static struct fs_path *fs_path_alloc(struct send_ctx *sctx)
+{
+	struct fs_path *p;
+
+	p = kmalloc(sizeof(*p), GFP_NOFS);
+	if (!p)
+		return NULL;
+	p->reversed = 0;
+	p->virtual_mem = 0;
+	p->buf = p->inline_buf;
+	p->buf_len = FS_PATH_INLINE_SIZE;
+	fs_path_reset(p);
+	return p;
+}
+
+static struct fs_path *fs_path_alloc_reversed(struct send_ctx *sctx)
+{
+	struct fs_path *p;
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return NULL;
+	p->reversed = 1;
+	fs_path_reset(p);
+	return p;
+}
+
+static void fs_path_free(struct send_ctx *sctx, struct fs_path *p)
+{
+	if (!p)
+		return;
+	if (p->buf != p->inline_buf) {
+		if (p->virtual_mem)
+			vfree(p->buf);
+		else
+			kfree(p->buf);
+	}
+	kfree(p);
+}
+
+static int fs_path_len(struct fs_path *p)
+{
+	return p->end - p->start;
+}
+
+static int fs_path_ensure_buf(struct fs_path *p, int len)
+{
+	char *tmp_buf;
+	int path_len;
+	int old_buf_len;
+
+	len++;
+
+	if (p->buf_len >= len)
+		return 0;
+
+	path_len = p->end - p->start;
+	old_buf_len = p->buf_len;
+	len = PAGE_ALIGN(len);
+
+	if (p->buf == p->inline_buf) {
+		tmp_buf = kmalloc(len, GFP_NOFS);
+		if (!tmp_buf) {
+			tmp_buf = vmalloc(len);
+			if (!tmp_buf)
+				return -ENOMEM;
+			p->virtual_mem = 1;
+		}
+		memcpy(tmp_buf, p->buf, p->buf_len);
+		p->buf = tmp_buf;
+		p->buf_len = len;
+	} else {
+		if (p->virtual_mem) {
+			tmp_buf = vmalloc(len);
+			if (!tmp_buf)
+				return -ENOMEM;
+			memcpy(tmp_buf, p->buf, p->buf_len);
+			vfree(p->buf);
+		} else {
+			tmp_buf = krealloc(p->buf, len, GFP_NOFS);
+			if (!tmp_buf) {
+				tmp_buf = vmalloc(len);
+				if (!tmp_buf)
+					return -ENOMEM;
+				memcpy(tmp_buf, p->buf, p->buf_len);
+				kfree(p->buf);
+				p->virtual_mem = 1;
+			}
+		}
+		p->buf = tmp_buf;
+		p->buf_len = len;
+	}
+	if (p->reversed) {
+		tmp_buf = p->buf + old_buf_len - path_len - 1;
+		p->end = p->buf + p->buf_len - 1;
+		p->start = p->end - path_len;
+		memmove(p->start, tmp_buf, path_len + 1);
+	} else {
+		p->start = p->buf;
+		p->end = p->start + path_len;
+	}
+	return 0;
+}
+
+static int fs_path_prepare_for_add(struct fs_path *p, int name_len)
+{
+	int ret;
+	int new_len;
+
+	new_len = p->end - p->start + name_len;
+	if (p->start != p->end)
+		new_len++;
+	ret = fs_path_ensure_buf(p, new_len);
+	if (ret < 0)
+		goto out;
+
+	if (p->reversed) {
+		if (p->start != p->end)
+			*--p->start = '/';
+		p->start -= name_len;
+		p->prepared = p->start;
+	} else {
+		if (p->start != p->end)
+			*p->end++ = '/';
+		p->prepared = p->end;
+		p->end += name_len;
+		*p->end = 0;
+	}
+
+out:
+	return ret;
+}
+
+static int fs_path_add(struct fs_path *p, const char *name, int name_len)
+{
+	int ret;
+
+	ret = fs_path_prepare_for_add(p, name_len);
+	if (ret < 0)
+		goto out;
+	memcpy(p->prepared, name, name_len);
+	p->prepared = NULL;
+
+out:
+	return ret;
+}
+
+static int fs_path_add_path(struct fs_path *p, struct fs_path *p2)
+{
+	int ret;
+
+	ret = fs_path_prepare_for_add(p, p2->end - p2->start);
+	if (ret < 0)
+		goto out;
+	memcpy(p->prepared, p2->start, p2->end - p2->start);
+	p->prepared = NULL;
+
+out:
+	return ret;
+}
+
+static int fs_path_add_from_extent_buffer(struct fs_path *p,
+					  struct extent_buffer *eb,
+					  unsigned long off, int len)
+{
+	int ret;
+
+	ret = fs_path_prepare_for_add(p, len);
+	if (ret < 0)
+		goto out;
+
+	read_extent_buffer(eb, p->prepared, off, len);
+	p->prepared = NULL;
+
+out:
+	return ret;
+}
+
+static void fs_path_remove(struct fs_path *p)
+{
+	BUG_ON(p->reversed);
+	while (p->start != p->end && *p->end != '/')
+		p->end--;
+	*p->end = 0;
+}
+
+static int fs_path_copy(struct fs_path *p, struct fs_path *from)
+{
+	int ret;
+
+	p->reversed = from->reversed;
+	fs_path_reset(p);
+
+	ret = fs_path_add_path(p, from);
+
+	return ret;
+}
+
+
+static void fs_path_unreverse(struct fs_path *p)
+{
+	char *tmp;
+	int len;
+
+	if (!p->reversed)
+		return;
+
+	tmp = p->start;
+	len = p->end - p->start;
+	p->start = p->buf;
+	p->end = p->start + len;
+	memmove(p->start, tmp, len + 1);
+	p->reversed = 0;
+}
+
+static struct btrfs_path *alloc_path_for_send(void)
+{
+	struct btrfs_path *path;
+
+	path = btrfs_alloc_path();
+	if (!path)
+		return NULL;
+	path->search_commit_root = 1;
+	path->skip_locking = 1;
+	return path;
+}
+
+static int write_buf(struct send_ctx *sctx, const void *buf, u32 len)
+{
+	int ret;
+	mm_segment_t old_fs;
+	u32 pos = 0;
+
+	old_fs = get_fs();
+	set_fs(KERNEL_DS);
+
+	while (pos < len) {
+		ret = vfs_write(sctx->send_filp, (char *)buf + pos, len - pos,
+				&sctx->send_off);
+		/* TODO handle that correctly */
+		/*if (ret == -ERESTARTSYS) {
+			continue;
+		}*/
+		if (ret < 0)
+			goto out;
+		if (ret == 0) {
+			ret = -EIO;
+			goto out;
+		}
+		pos += ret;
+	}
+
+	ret = 0;
+
+out:
+	set_fs(old_fs);
+	return ret;
+}
+
+static int tlv_put(struct send_ctx *sctx, u16 attr, const void *data, int len)
+{
+	struct btrfs_tlv_header *hdr;
+	int total_len = sizeof(*hdr) + len;
+	int left = sctx->send_max_size - sctx->send_size;
+
+	if (unlikely(left < total_len))
+		return -EOVERFLOW;
+
+	hdr = (struct btrfs_tlv_header *) (sctx->send_buf + sctx->send_size);
+	hdr->tlv_type = cpu_to_le16(attr);
+	hdr->tlv_len = cpu_to_le16(len);
+	memcpy(hdr + 1, data, len);
+	sctx->send_size += total_len;
+
+	return 0;
+}
+
+#if 0
+static int tlv_put_u8(struct send_ctx *sctx, u16 attr, u8 value)
+{
+	return tlv_put(sctx, attr, &value, sizeof(value));
+}
+
+static int tlv_put_u16(struct send_ctx *sctx, u16 attr, u16 value)
+{
+	__le16 tmp = cpu_to_le16(value);
+	return tlv_put(sctx, attr, &tmp, sizeof(tmp));
+}
+
+static int tlv_put_u32(struct send_ctx *sctx, u16 attr, u32 value)
+{
+	__le32 tmp = cpu_to_le32(value);
+	return tlv_put(sctx, attr, &tmp, sizeof(tmp));
+}
+#endif
+
+static int tlv_put_u64(struct send_ctx *sctx, u16 attr, u64 value)
+{
+	__le64 tmp = cpu_to_le64(value);
+	return tlv_put(sctx, attr, &tmp, sizeof(tmp));
+}
+
+static int tlv_put_string(struct send_ctx *sctx, u16 attr,
+			  const char *str, int len)
+{
+	if (len == -1)
+		len = strlen(str);
+	return tlv_put(sctx, attr, str, len);
+}
+
+static int tlv_put_uuid(struct send_ctx *sctx, u16 attr,
+			const u8 *uuid)
+{
+	return tlv_put(sctx, attr, uuid, BTRFS_UUID_SIZE);
+}
+
+#if 0
+static int tlv_put_timespec(struct send_ctx *sctx, u16 attr,
+			    struct timespec *ts)
+{
+	struct btrfs_timespec bts;
+	bts.sec = cpu_to_le64(ts->tv_sec);
+	bts.nsec = cpu_to_le32(ts->tv_nsec);
+	return tlv_put(sctx, attr, &bts, sizeof(bts));
+}
+#endif
+
+static int tlv_put_btrfs_timespec(struct send_ctx *sctx, u16 attr,
+				  struct extent_buffer *eb,
+				  struct btrfs_timespec *ts)
+{
+	struct btrfs_timespec bts;
+	read_extent_buffer(eb, &bts, (unsigned long)ts, sizeof(bts));
+	return tlv_put(sctx, attr, &bts, sizeof(bts));
+}
+
+
+#define TLV_PUT(sctx, attrtype, attrlen, data) \
+	do { \
+		ret = tlv_put(sctx, attrtype, attrlen, data); \
+		if (ret < 0) \
+			goto tlv_put_failure; \
+	} while (0)
+
+#define TLV_PUT_INT(sctx, attrtype, bits, value) \
+	do { \
+		ret = tlv_put_u##bits(sctx, attrtype, value); \
+		if (ret < 0) \
+			goto tlv_put_failure; \
+	} while (0)
+
+#define TLV_PUT_U8(sctx, attrtype, data) TLV_PUT_INT(sctx, attrtype, 8, data)
+#define TLV_PUT_U16(sctx, attrtype, data) TLV_PUT_INT(sctx, attrtype, 16, data)
+#define TLV_PUT_U32(sctx, attrtype, data) TLV_PUT_INT(sctx, attrtype, 32, data)
+#define TLV_PUT_U64(sctx, attrtype, data) TLV_PUT_INT(sctx, attrtype, 64, data)
+#define TLV_PUT_STRING(sctx, attrtype, str, len) \
+	do { \
+		ret = tlv_put_string(sctx, attrtype, str, len); \
+		if (ret < 0) \
+			goto tlv_put_failure; \
+	} while (0)
+#define TLV_PUT_PATH(sctx, attrtype, p) \
+	do { \
+		ret = tlv_put_string(sctx, attrtype, p->start, \
+			p->end - p->start); \
+		if (ret < 0) \
+			goto tlv_put_failure; \
+	} while(0)
+#define TLV_PUT_UUID(sctx, attrtype, uuid) \
+	do { \
+		ret = tlv_put_uuid(sctx, attrtype, uuid); \
+		if (ret < 0) \
+			goto tlv_put_failure; \
+	} while (0)
+#define TLV_PUT_TIMESPEC(sctx, attrtype, ts) \
+	do { \
+		ret = tlv_put_timespec(sctx, attrtype, ts); \
+		if (ret < 0) \
+			goto tlv_put_failure; \
+	} while (0)
+#define TLV_PUT_BTRFS_TIMESPEC(sctx, attrtype, eb, ts) \
+	do { \
+		ret = tlv_put_btrfs_timespec(sctx, attrtype, eb, ts); \
+		if (ret < 0) \
+			goto tlv_put_failure; \
+	} while (0)
+
+static int send_header(struct send_ctx *sctx)
+{
+	struct btrfs_stream_header hdr;
+
+	strcpy(hdr.magic, BTRFS_SEND_STREAM_MAGIC);
+	hdr.version = cpu_to_le32(BTRFS_SEND_STREAM_VERSION);
+
+	return write_buf(sctx, &hdr, sizeof(hdr));
+}
+
+/*
+ * For each command/item we want to send to userspace, we call this function.
+ */
+static int begin_cmd(struct send_ctx *sctx, int cmd)
+{
+	struct btrfs_cmd_header *hdr;
+
+	if (!sctx->send_buf) {
+		WARN_ON(1);
+		return -EINVAL;
+	}
+
+	BUG_ON(sctx->send_size);
+
+	sctx->send_size += sizeof(*hdr);
+	hdr = (struct btrfs_cmd_header *)sctx->send_buf;
+	hdr->cmd = cpu_to_le16(cmd);
+
+	return 0;
+}
+
+static int send_cmd(struct send_ctx *sctx)
+{
+	int ret;
+	struct btrfs_cmd_header *hdr;
+	u32 crc;
+
+	hdr = (struct btrfs_cmd_header *)sctx->send_buf;
+	hdr->len = cpu_to_le32(sctx->send_size - sizeof(*hdr));
+	hdr->crc = 0;
+
+	crc = crc32c(0, (unsigned char *)sctx->send_buf, sctx->send_size);
+	hdr->crc = cpu_to_le32(crc);
+
+	ret = write_buf(sctx, sctx->send_buf, sctx->send_size);
+
+	sctx->total_send_size += sctx->send_size;
+	sctx->cmd_send_size[le16_to_cpu(hdr->cmd)] += sctx->send_size;
+	sctx->send_size = 0;
+
+	return ret;
+}
+
+/*
+ * Sends a move instruction to user space
+ */
+static int send_rename(struct send_ctx *sctx,
+		     struct fs_path *from, struct fs_path *to)
+{
+	int ret;
+
+verbose_printk("btrfs: send_rename %s -> %s\n", from->start, to->start);
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_RENAME);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, from);
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH_TO, to);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	return ret;
+}
+
+/*
+ * Sends a link instruction to user space
+ */
+static int send_link(struct send_ctx *sctx,
+		     struct fs_path *path, struct fs_path *lnk)
+{
+	int ret;
+
+verbose_printk("btrfs: send_link %s -> %s\n", path->start, lnk->start);
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_LINK);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, path);
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH_LINK, lnk);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	return ret;
+}
+
+/*
+ * Sends an unlink instruction to user space
+ */
+static int send_unlink(struct send_ctx *sctx, struct fs_path *path)
+{
+	int ret;
+
+verbose_printk("btrfs: send_unlink %s\n", path->start);
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_UNLINK);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, path);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	return ret;
+}
+
+/*
+ * Sends a rmdir instruction to user space
+ */
+static int send_rmdir(struct send_ctx *sctx, struct fs_path *path)
+{
+	int ret;
+
+verbose_printk("btrfs: send_rmdir %s\n", path->start);
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_RMDIR);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, path);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	return ret;
+}
+
+/*
+ * Helper function to retrieve some fields from an inode item.
+ */
+static int get_inode_info(struct btrfs_root *root,
+			  u64 ino, u64 *size, u64 *gen,
+			  u64 *mode, u64 *uid, u64 *gid)
+{
+	int ret;
+	struct btrfs_inode_item *ii;
+	struct btrfs_key key;
+	struct btrfs_path *path;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	key.objectid = ino;
+	key.type = BTRFS_INODE_ITEM_KEY;
+	key.offset = 0;
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
+	if (ret) {
+		ret = -ENOENT;
+		goto out;
+	}
+
+	ii = btrfs_item_ptr(path->nodes[0], path->slots[0],
+			struct btrfs_inode_item);
+	if (size)
+		*size = btrfs_inode_size(path->nodes[0], ii);
+	if (gen)
+		*gen = btrfs_inode_generation(path->nodes[0], ii);
+	if (mode)
+		*mode = btrfs_inode_mode(path->nodes[0], ii);
+	if (uid)
+		*uid = btrfs_inode_uid(path->nodes[0], ii);
+	if (gid)
+		*gid = btrfs_inode_gid(path->nodes[0], ii);
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+typedef int (*iterate_inode_ref_t)(int num, u64 dir, int index,
+				   struct fs_path *p,
+				   void *ctx);
+
+/*
+ * Helper function to iterate the entries in ONE btrfs_inode_ref.
+ * The iterate callback may return a non zero value to stop iteration. This can
+ * be a negative value for error codes or 1 to simply stop it.
+ *
+ * path must point to the INODE_REF when called.
+ */
+static int iterate_inode_ref(struct send_ctx *sctx,
+			     struct btrfs_root *root, struct btrfs_path *path,
+			     struct btrfs_key *found_key, int resolve,
+			     iterate_inode_ref_t iterate, void *ctx)
+{
+	struct extent_buffer *eb;
+	struct btrfs_item *item;
+	struct btrfs_inode_ref *iref;
+	struct btrfs_path *tmp_path;
+	struct fs_path *p;
+	u32 cur;
+	u32 len;
+	u32 total;
+	int slot;
+	u32 name_len;
+	char *start;
+	int ret = 0;
+	int num;
+	int index;
+
+	p = fs_path_alloc_reversed(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	tmp_path = alloc_path_for_send();
+	if (!tmp_path) {
+		fs_path_free(sctx, p);
+		return -ENOMEM;
+	}
+
+	eb = path->nodes[0];
+	slot = path->slots[0];
+	item = btrfs_item_nr(eb, slot);
+	iref = btrfs_item_ptr(eb, slot, struct btrfs_inode_ref);
+	cur = 0;
+	len = 0;
+	total = btrfs_item_size(eb, item);
+
+	num = 0;
+	while (cur < total) {
+		fs_path_reset(p);
+
+		name_len = btrfs_inode_ref_name_len(eb, iref);
+		index = btrfs_inode_ref_index(eb, iref);
+		if (resolve) {
+			start = btrfs_iref_to_path(root, tmp_path, iref, eb,
+						found_key->offset, p->buf,
+						p->buf_len);
+			if (IS_ERR(start)) {
+				ret = PTR_ERR(start);
+				goto out;
+			}
+			if (start < p->buf) {
+				/* overflow , try again with larger buffer */
+				ret = fs_path_ensure_buf(p,
+						p->buf_len + p->buf - start);
+				if (ret < 0)
+					goto out;
+				start = btrfs_iref_to_path(root, tmp_path, iref,
+						eb, found_key->offset, p->buf,
+						p->buf_len);
+				if (IS_ERR(start)) {
+					ret = PTR_ERR(start);
+					goto out;
+				}
+				BUG_ON(start < p->buf);
+			}
+			p->start = start;
+		} else {
+			ret = fs_path_add_from_extent_buffer(p, eb,
+					(unsigned long)(iref + 1), name_len);
+			if (ret < 0)
+				goto out;
+		}
+
+
+		len = sizeof(*iref) + name_len;
+		iref = (struct btrfs_inode_ref *)((char *)iref + len);
+		cur += len;
+
+		ret = iterate(num, found_key->offset, index, p, ctx);
+		if (ret)
+			goto out;
+
+		num++;
+	}
+
+out:
+	btrfs_free_path(tmp_path);
+	fs_path_free(sctx, p);
+	return ret;
+}
+
+typedef int (*iterate_dir_item_t)(int num, struct btrfs_key *di_key,
+				  const char *name, int name_len,
+				  const char *data, int data_len,
+				  u8 type, void *ctx);
+
+/*
+ * Helper function to iterate the entries in ONE btrfs_dir_item.
+ * The iterate callback may return a non zero value to stop iteration. This can
+ * be a negative value for error codes or 1 to simply stop it.
+ *
+ * path must point to the dir item when called.
+ */
+static int iterate_dir_item(struct send_ctx *sctx,
+			    struct btrfs_root *root, struct btrfs_path *path,
+			    struct btrfs_key *found_key,
+			    iterate_dir_item_t iterate, void *ctx)
+{
+	int ret = 0;
+	struct extent_buffer *eb;
+	struct btrfs_item *item;
+	struct btrfs_dir_item *di;
+	struct btrfs_path *tmp_path = NULL;
+	struct btrfs_key di_key;
+	char *buf = NULL;
+	char *buf2 = NULL;
+	int buf_len;
+	int buf_virtual = 0;
+	u32 name_len;
+	u32 data_len;
+	u32 cur;
+	u32 len;
+	u32 total;
+	int slot;
+	int num;
+	u8 type;
+
+	buf_len = PAGE_SIZE;
+	buf = kmalloc(buf_len, GFP_NOFS);
+	if (!buf) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	tmp_path = alloc_path_for_send();
+	if (!tmp_path) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	eb = path->nodes[0];
+	slot = path->slots[0];
+	item = btrfs_item_nr(eb, slot);
+	di = btrfs_item_ptr(eb, slot, struct btrfs_dir_item);
+	cur = 0;
+	len = 0;
+	total = btrfs_item_size(eb, item);
+
+	num = 0;
+	while (cur < total) {
+		name_len = btrfs_dir_name_len(eb, di);
+		data_len = btrfs_dir_data_len(eb, di);
+		type = btrfs_dir_type(eb, di);
+		btrfs_dir_item_key_to_cpu(eb, di, &di_key);
+
+		if (name_len + data_len > buf_len) {
+			buf_len = PAGE_ALIGN(name_len + data_len);
+			if (buf_virtual) {
+				buf2 = vmalloc(buf_len);
+				if (!buf2) {
+					ret = -ENOMEM;
+					goto out;
+				}
+				vfree(buf);
+			} else {
+				buf2 = krealloc(buf, buf_len, GFP_NOFS);
+				if (!buf2) {
+					buf2 = vmalloc(buf_len);
+					if (!buf2) {
+						ret = -ENOMEM;
+						goto out;
+					}
+					kfree(buf);
+					buf_virtual = 1;
+				}
+			}
+
+			buf = buf2;
+			buf2 = NULL;
+		}
+
+		read_extent_buffer(eb, buf, (unsigned long)(di + 1),
+				name_len + data_len);
+
+		len = sizeof(*di) + name_len + data_len;
+		di = (struct btrfs_dir_item *)((char *)di + len);
+		cur += len;
+
+		ret = iterate(num, &di_key, buf, name_len, buf + name_len,
+				data_len, type, ctx);
+		if (ret < 0)
+			goto out;
+		if (ret) {
+			ret = 0;
+			goto out;
+		}
+
+		num++;
+	}
+
+out:
+	btrfs_free_path(tmp_path);
+	if (buf_virtual)
+		vfree(buf);
+	else
+		kfree(buf);
+	return ret;
+}
+
+static int __copy_first_ref(int num, u64 dir, int index,
+			    struct fs_path *p, void *ctx)
+{
+	int ret;
+	struct fs_path *pt = ctx;
+
+	ret = fs_path_copy(pt, p);
+	if (ret < 0)
+		return ret;
+
+	/* we want the first only */
+	return 1;
+}
+
+/*
+ * Retrieve the first path of an inode. If an inode has more then one
+ * ref/hardlink, this is ignored.
+ */
+static int get_inode_path(struct send_ctx *sctx, struct btrfs_root *root,
+			  u64 ino, struct fs_path *path)
+{
+	int ret;
+	struct btrfs_key key, found_key;
+	struct btrfs_path *p;
+
+	p = alloc_path_for_send();
+	if (!p)
+		return -ENOMEM;
+
+	fs_path_reset(path);
+
+	key.objectid = ino;
+	key.type = BTRFS_INODE_REF_KEY;
+	key.offset = 0;
+
+	ret = btrfs_search_slot_for_read(root, &key, p, 1, 0);
+	if (ret < 0)
+		goto out;
+	if (ret) {
+		ret = 1;
+		goto out;
+	}
+	btrfs_item_key_to_cpu(p->nodes[0], &found_key, p->slots[0]);
+	if (found_key.objectid != ino ||
+		found_key.type != BTRFS_INODE_REF_KEY) {
+		ret = -ENOENT;
+		goto out;
+	}
+
+	ret = iterate_inode_ref(sctx, root, p, &found_key, 1,
+			__copy_first_ref, path);
+	if (ret < 0)
+		goto out;
+	ret = 0;
+
+out:
+	btrfs_free_path(p);
+	return ret;
+}
+
+struct backref_ctx {
+	struct send_ctx *sctx;
+
+	/* number of total found references */
+	u64 found;
+
+	/*
+	 * used for clones found in send_root. clones found behind cur_objectid
+	 * and cur_offset are not considered as allowed clones.
+	 */
+	u64 cur_objectid;
+	u64 cur_offset;
+
+	/* may be truncated in case it's the last extent in a file */
+	u64 extent_len;
+
+	/* Just to check for bugs in backref resolving */
+	int found_in_send_root;
+};
+
+static int __clone_root_cmp_bsearch(const void *key, const void *elt)
+{
+	u64 root = (u64)key;
+	struct clone_root *cr = (struct clone_root *)elt;
+
+	if (root < cr->root->objectid)
+		return -1;
+	if (root > cr->root->objectid)
+		return 1;
+	return 0;
+}
+
+static int __clone_root_cmp_sort(const void *e1, const void *e2)
+{
+	struct clone_root *cr1 = (struct clone_root *)e1;
+	struct clone_root *cr2 = (struct clone_root *)e2;
+
+	if (cr1->root->objectid < cr2->root->objectid)
+		return -1;
+	if (cr1->root->objectid > cr2->root->objectid)
+		return 1;
+	return 0;
+}
+
+/*
+ * Called for every backref that is found for the current extent.
+ */
+static int __iterate_backrefs(u64 ino, u64 offset, u64 root, void *ctx_)
+{
+	struct backref_ctx *bctx = ctx_;
+	struct clone_root *found;
+	int ret;
+	u64 i_size;
+
+	/* First check if the root is in the list of accepted clone sources */
+	found = bsearch((void *)root, bctx->sctx->clone_roots,
+			bctx->sctx->clone_roots_cnt,
+			sizeof(struct clone_root),
+			__clone_root_cmp_bsearch);
+	if (!found)
+		return 0;
+
+	if (found->root == bctx->sctx->send_root &&
+	    ino == bctx->cur_objectid &&
+	    offset == bctx->cur_offset) {
+		bctx->found_in_send_root = 1;
+	}
+
+	/*
+	 * There are inodes that have extents that lie behind it's i_size. Don't
+	 * accept clones from these extents.
+	 */
+	ret = get_inode_info(found->root, ino, &i_size, NULL, NULL, NULL, NULL);
+	if (ret < 0)
+		return ret;
+
+	if (offset + bctx->extent_len > i_size)
+		return 0;
+
+	/*
+	 * Make sure we don't consider clones from send_root that are
+	 * behind the current inode/offset.
+	 */
+	if (found->root == bctx->sctx->send_root) {
+		/*
+		 * TODO for the moment we don't accept clones from the inode
+		 * that is currently send. We may change this when
+		 * BTRFS_IOC_CLONE_RANGE supports cloning from and to the same
+		 * file.
+		 */
+		if (ino >= bctx->cur_objectid)
+			return 0;
+		/*if (ino > ctx->cur_objectid)
+			return 0;
+		if (offset + ctx->extent_len > ctx->cur_offset)
+			return 0;*/
+
+		bctx->found++;
+		found->found_refs++;
+		found->ino = ino;
+		found->offset = offset;
+		return 0;
+	}
+
+	bctx->found++;
+	found->found_refs++;
+	if (ino < found->ino) {
+		found->ino = ino;
+		found->offset = offset;
+	} else if (found->ino == ino) {
+		/*
+		 * same extent found more then once in the same file.
+		 */
+		if (found->offset > offset + bctx->extent_len)
+			found->offset = offset;
+	}
+
+	return 0;
+}
+
+/*
+ * path must point to the extent item when called.
+ */
+static int find_extent_clone(struct send_ctx *sctx,
+			     struct btrfs_path *path,
+			     u64 ino, u64 data_offset,
+			     u64 ino_size,
+			     struct clone_root **found)
+{
+	int ret;
+	int extent_type;
+	u64 logical;
+	u64 num_bytes;
+	u64 extent_item_pos;
+	struct btrfs_file_extent_item *fi;
+	struct extent_buffer *eb = path->nodes[0];
+	struct backref_ctx backref_ctx;
+	struct clone_root *cur_clone_root;
+	struct btrfs_key found_key;
+	struct btrfs_path *tmp_path;
+	u32 i;
+
+	tmp_path = alloc_path_for_send();
+	if (!tmp_path)
+		return -ENOMEM;
+
+	if (data_offset >= ino_size) {
+		/*
+		 * There may be extents that lie behind the file's size.
+		 * I at least had this in combination with snapshotting while
+		 * writing large files.
+		 */
+		ret = 0;
+		goto out;
+	}
+
+	fi = btrfs_item_ptr(eb, path->slots[0],
+			struct btrfs_file_extent_item);
+	extent_type = btrfs_file_extent_type(eb, fi);
+	if (extent_type == BTRFS_FILE_EXTENT_INLINE) {
+		ret = -ENOENT;
+		goto out;
+	}
+
+	num_bytes = btrfs_file_extent_num_bytes(eb, fi);
+	logical = btrfs_file_extent_disk_bytenr(eb, fi);
+	if (logical == 0) {
+		ret = -ENOENT;
+		goto out;
+	}
+	logical += btrfs_file_extent_offset(eb, fi);
+
+	ret = extent_from_logical(sctx->send_root->fs_info,
+			logical, tmp_path, &found_key);
+	btrfs_release_path(tmp_path);
+
+	if (ret < 0)
+		goto out;
+	if (ret & BTRFS_EXTENT_FLAG_TREE_BLOCK) {
+		ret = -EIO;
+		goto out;
+	}
+
+	/*
+	 * Setup the clone roots.
+	 */
+	for (i = 0; i < sctx->clone_roots_cnt; i++) {
+		cur_clone_root = sctx->clone_roots + i;
+		cur_clone_root->ino = (u64)-1;
+		cur_clone_root->offset = 0;
+		cur_clone_root->found_refs = 0;
+	}
+
+	backref_ctx.sctx = sctx;
+	backref_ctx.found = 0;
+	backref_ctx.cur_objectid = ino;
+	backref_ctx.cur_offset = data_offset;
+	backref_ctx.found_in_send_root = 0;
+	backref_ctx.extent_len = num_bytes;
+
+	/*
+	 * The last extent of a file may be too large due to page alignment.
+	 * We need to adjust extent_len in this case so that the checks in
+	 * __iterate_backrefs work.
+	 */
+	if (data_offset + num_bytes >= ino_size)
+		backref_ctx.extent_len = ino_size - data_offset;
+
+	/*
+	 * Now collect all backrefs.
+	 */
+	extent_item_pos = logical - found_key.objectid;
+	ret = iterate_extent_inodes(sctx->send_root->fs_info,
+					found_key.objectid, extent_item_pos, 1,
+					__iterate_backrefs, &backref_ctx);
+	if (ret < 0)
+		goto out;
+
+	if (!backref_ctx.found_in_send_root) {
+		/* found a bug in backref code? */
+		ret = -EIO;
+		printk(KERN_ERR "btrfs: ERROR did not find backref in "
+				"send_root. inode=%llu, offset=%llu, "
+				"logical=%llu\n",
+				ino, data_offset, logical);
+		goto out;
+	}
+
+verbose_printk(KERN_DEBUG "btrfs: find_extent_clone: data_offset=%llu, "
+		"ino=%llu, "
+		"num_bytes=%llu, logical=%llu\n",
+		data_offset, ino, num_bytes, logical);
+
+	if (!backref_ctx.found)
+		verbose_printk("btrfs:    no clones found\n");
+
+	cur_clone_root = NULL;
+	for (i = 0; i < sctx->clone_roots_cnt; i++) {
+		if (sctx->clone_roots[i].found_refs) {
+			if (!cur_clone_root)
+				cur_clone_root = sctx->clone_roots + i;
+			else if (sctx->clone_roots[i].root == sctx->send_root)
+				/* prefer clones from send_root over others */
+				cur_clone_root = sctx->clone_roots + i;
+			break;
+		}
+
+	}
+
+	if (cur_clone_root) {
+		*found = cur_clone_root;
+		ret = 0;
+	} else {
+		ret = -ENOENT;
+	}
+
+out:
+	btrfs_free_path(tmp_path);
+	return ret;
+}
+
+static int read_symlink(struct send_ctx *sctx,
+			struct btrfs_root *root,
+			u64 ino,
+			struct fs_path *dest)
+{
+	int ret;
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	struct btrfs_file_extent_item *ei;
+	u8 type;
+	u8 compression;
+	unsigned long off;
+	int len;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	key.objectid = ino;
+	key.type = BTRFS_EXTENT_DATA_KEY;
+	key.offset = 0;
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
+	BUG_ON(ret);
+
+	ei = btrfs_item_ptr(path->nodes[0], path->slots[0],
+			struct btrfs_file_extent_item);
+	type = btrfs_file_extent_type(path->nodes[0], ei);
+	compression = btrfs_file_extent_compression(path->nodes[0], ei);
+	BUG_ON(type != BTRFS_FILE_EXTENT_INLINE);
+	BUG_ON(compression);
+
+	off = btrfs_file_extent_inline_start(ei);
+	len = btrfs_file_extent_inline_len(path->nodes[0], ei);
+
+	ret = fs_path_add_from_extent_buffer(dest, path->nodes[0], off, len);
+	if (ret < 0)
+		goto out;
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+/*
+ * Helper function to generate a file name that is unique in the root of
+ * send_root and parent_root. This is used to generate names for orphan inodes.
+ */
+static int gen_unique_name(struct send_ctx *sctx,
+			   u64 ino, u64 gen,
+			   struct fs_path *dest)
+{
+	int ret = 0;
+	struct btrfs_path *path;
+	struct btrfs_dir_item *di;
+	char tmp[64];
+	int len;
+	u64 idx = 0;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	while (1) {
+		len = snprintf(tmp, sizeof(tmp) - 1, "o%llu-%llu-%llu",
+				ino, gen, idx);
+		if (len >= sizeof(tmp)) {
+			/* should really not happen */
+			ret = -EOVERFLOW;
+			goto out;
+		}
+
+		di = btrfs_lookup_dir_item(NULL, sctx->send_root,
+				path, BTRFS_FIRST_FREE_OBJECTID,
+				tmp, strlen(tmp), 0);
+		btrfs_release_path(path);
+		if (IS_ERR(di)) {
+			ret = PTR_ERR(di);
+			goto out;
+		}
+		if (di) {
+			/* not unique, try again */
+			idx++;
+			continue;
+		}
+
+		if (!sctx->parent_root) {
+			/* unique */
+			ret = 0;
+			break;
+		}
+
+		di = btrfs_lookup_dir_item(NULL, sctx->parent_root,
+				path, BTRFS_FIRST_FREE_OBJECTID,
+				tmp, strlen(tmp), 0);
+		btrfs_release_path(path);
+		if (IS_ERR(di)) {
+			ret = PTR_ERR(di);
+			goto out;
+		}
+		if (di) {
+			/* not unique, try again */
+			idx++;
+			continue;
+		}
+		/* unique */
+		break;
+	}
+
+	ret = fs_path_add(dest, tmp, strlen(tmp));
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+enum inode_state {
+	inode_state_no_change,
+	inode_state_will_create,
+	inode_state_did_create,
+	inode_state_will_delete,
+	inode_state_did_delete,
+};
+
+static int get_cur_inode_state(struct send_ctx *sctx, u64 ino, u64 gen)
+{
+	int ret;
+	int left_ret;
+	int right_ret;
+	u64 left_gen;
+	u64 right_gen;
+
+	ret = get_inode_info(sctx->send_root, ino, NULL, &left_gen, NULL, NULL,
+			NULL);
+	if (ret < 0 && ret != -ENOENT)
+		goto out;
+	left_ret = ret;
+
+	if (!sctx->parent_root) {
+		right_ret = -ENOENT;
+	} else {
+		ret = get_inode_info(sctx->parent_root, ino, NULL, &right_gen,
+				NULL, NULL, NULL);
+		if (ret < 0 && ret != -ENOENT)
+			goto out;
+		right_ret = ret;
+	}
+
+	if (!left_ret && !right_ret) {
+		if (left_gen == gen && right_gen == gen)
+			ret = inode_state_no_change;
+		else if (left_gen == gen) {
+			if (ino < sctx->send_progress)
+				ret = inode_state_did_create;
+			else
+				ret = inode_state_will_create;
+		} else if (right_gen == gen) {
+			if (ino < sctx->send_progress)
+				ret = inode_state_did_delete;
+			else
+				ret = inode_state_will_delete;
+		} else  {
+			ret = -ENOENT;
+		}
+	} else if (!left_ret) {
+		if (left_gen == gen) {
+			if (ino < sctx->send_progress)
+				ret = inode_state_did_create;
+			else
+				ret = inode_state_will_create;
+		} else {
+			ret = -ENOENT;
+		}
+	} else if (!right_ret) {
+		if (right_gen == gen) {
+			if (ino < sctx->send_progress)
+				ret = inode_state_did_delete;
+			else
+				ret = inode_state_will_delete;
+		} else {
+			ret = -ENOENT;
+		}
+	} else {
+		ret = -ENOENT;
+	}
+
+out:
+	return ret;
+}
+
+static int is_inode_existent(struct send_ctx *sctx, u64 ino, u64 gen)
+{
+	int ret;
+
+	ret = get_cur_inode_state(sctx, ino, gen);
+	if (ret < 0)
+		goto out;
+
+	if (ret == inode_state_no_change ||
+	    ret == inode_state_did_create ||
+	    ret == inode_state_will_delete)
+		ret = 1;
+	else
+		ret = 0;
+
+out:
+	return ret;
+}
+
+/*
+ * Helper function to lookup a dir item in a dir.
+ */
+static int lookup_dir_item_inode(struct btrfs_root *root,
+				 u64 dir, const char *name, int name_len,
+				 u64 *found_inode,
+				 u8 *found_type)
+{
+	int ret = 0;
+	struct btrfs_dir_item *di;
+	struct btrfs_key key;
+	struct btrfs_path *path;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	di = btrfs_lookup_dir_item(NULL, root, path,
+			dir, name, name_len, 0);
+	if (!di) {
+		ret = -ENOENT;
+		goto out;
+	}
+	if (IS_ERR(di)) {
+		ret = PTR_ERR(di);
+		goto out;
+	}
+	btrfs_dir_item_key_to_cpu(path->nodes[0], di, &key);
+	*found_inode = key.objectid;
+	*found_type = btrfs_dir_type(path->nodes[0], di);
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+static int get_first_ref(struct send_ctx *sctx,
+			 struct btrfs_root *root, u64 ino,
+			 u64 *dir, u64 *dir_gen, struct fs_path *name)
+{
+	int ret;
+	struct btrfs_key key;
+	struct btrfs_key found_key;
+	struct btrfs_path *path;
+	struct btrfs_inode_ref *iref;
+	int len;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	key.objectid = ino;
+	key.type = BTRFS_INODE_REF_KEY;
+	key.offset = 0;
+
+	ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
+	if (ret < 0)
+		goto out;
+	if (!ret)
+		btrfs_item_key_to_cpu(path->nodes[0], &found_key,
+				path->slots[0]);
+	if (ret || found_key.objectid != key.objectid ||
+	    found_key.type != key.type) {
+		ret = -ENOENT;
+		goto out;
+	}
+
+	iref = btrfs_item_ptr(path->nodes[0], path->slots[0],
+			struct btrfs_inode_ref);
+	len = btrfs_inode_ref_name_len(path->nodes[0], iref);
+	ret = fs_path_add_from_extent_buffer(name, path->nodes[0],
+			(unsigned long)(iref + 1), len);
+	if (ret < 0)
+		goto out;
+	btrfs_release_path(path);
+
+	ret = get_inode_info(root, found_key.offset, NULL, dir_gen, NULL, NULL,
+			NULL);
+	if (ret < 0)
+		goto out;
+
+	*dir = found_key.offset;
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+static int is_first_ref(struct send_ctx *sctx,
+			struct btrfs_root *root,
+			u64 ino, u64 dir,
+			const char *name, int name_len)
+{
+	int ret;
+	struct fs_path *tmp_name;
+	u64 tmp_dir;
+	u64 tmp_dir_gen;
+
+	tmp_name = fs_path_alloc(sctx);
+	if (!tmp_name)
+		return -ENOMEM;
+
+	ret = get_first_ref(sctx, root, ino, &tmp_dir, &tmp_dir_gen, tmp_name);
+	if (ret < 0)
+		goto out;
+
+	if (name_len != fs_path_len(tmp_name)) {
+		ret = 0;
+		goto out;
+	}
+
+	ret = memcmp(tmp_name->start, name, name_len);
+	if (ret)
+		ret = 0;
+	else
+		ret = 1;
+
+out:
+	fs_path_free(sctx, tmp_name);
+	return ret;
+}
+
+static int will_overwrite_ref(struct send_ctx *sctx, u64 dir, u64 dir_gen,
+			      const char *name, int name_len,
+			      u64 *who_ino, u64 *who_gen)
+{
+	int ret = 0;
+	u64 other_inode = 0;
+	u8 other_type = 0;
+
+	if (!sctx->parent_root)
+		goto out;
+
+	ret = is_inode_existent(sctx, dir, dir_gen);
+	if (ret <= 0)
+		goto out;
+
+	ret = lookup_dir_item_inode(sctx->parent_root, dir, name, name_len,
+			&other_inode, &other_type);
+	if (ret < 0 && ret != -ENOENT)
+		goto out;
+	if (ret) {
+		ret = 0;
+		goto out;
+	}
+
+	if (other_inode > sctx->send_progress) {
+		ret = get_inode_info(sctx->parent_root, other_inode, NULL,
+				who_gen, NULL, NULL, NULL);
+		if (ret < 0)
+			goto out;
+
+		ret = 1;
+		*who_ino = other_inode;
+	} else {
+		ret = 0;
+	}
+
+out:
+	return ret;
+}
+
+static int did_overwrite_ref(struct send_ctx *sctx,
+			    u64 dir, u64 dir_gen,
+			    u64 ino, u64 ino_gen,
+			    const char *name, int name_len)
+{
+	int ret = 0;
+	u64 gen;
+	u64 ow_inode;
+	u8 other_type;
+
+	if (!sctx->parent_root)
+		goto out;
+
+	ret = is_inode_existent(sctx, dir, dir_gen);
+	if (ret <= 0)
+		goto out;
+
+	/* check if the ref was overwritten by another ref */
+	ret = lookup_dir_item_inode(sctx->send_root, dir, name, name_len,
+			&ow_inode, &other_type);
+	if (ret < 0 && ret != -ENOENT)
+		goto out;
+	if (ret) {
+		/* was never and will never be overwritten */
+		ret = 0;
+		goto out;
+	}
+
+	ret = get_inode_info(sctx->send_root, ow_inode, NULL, &gen, NULL, NULL,
+			NULL);
+	if (ret < 0)
+		goto out;
+
+	if (ow_inode == ino && gen == ino_gen) {
+		ret = 0;
+		goto out;
+	}
+
+	/* we know that it is or will be overwritten. check this now */
+	if (ow_inode < sctx->send_progress)
+		ret = 1;
+	else
+		ret = 0;
+
+out:
+	return ret;
+}
+
+static int did_overwrite_first_ref(struct send_ctx *sctx, u64 ino, u64 gen)
+{
+	int ret = 0;
+	struct fs_path *name = NULL;
+	u64 dir;
+	u64 dir_gen;
+
+	if (!sctx->parent_root)
+		goto out;
+
+	name = fs_path_alloc(sctx);
+	if (!name)
+		return -ENOMEM;
+
+	ret = get_first_ref(sctx, sctx->parent_root, ino, &dir, &dir_gen, name);
+	if (ret < 0)
+		goto out;
+
+	ret = did_overwrite_ref(sctx, dir, dir_gen, ino, gen,
+			name->start, fs_path_len(name));
+	if (ret < 0)
+		goto out;
+
+out:
+	fs_path_free(sctx, name);
+	return ret;
+}
+
+static int name_cache_insert(struct send_ctx *sctx,
+			     struct name_cache_entry *nce)
+{
+	int ret = 0;
+	struct name_cache_entry **ncea;
+
+	ncea = radix_tree_lookup(&sctx->name_cache, nce->ino);
+	if (ncea) {
+		if (!ncea[0])
+			ncea[0] = nce;
+		else if (!ncea[1])
+			ncea[1] = nce;
+		else
+			BUG();
+	} else {
+		ncea = kmalloc(sizeof(void *) * 2, GFP_NOFS);
+		if (!ncea)
+			return -ENOMEM;
+
+		ncea[0] = nce;
+		ncea[1] = NULL;
+		ret = radix_tree_insert(&sctx->name_cache, nce->ino, ncea);
+		if (ret < 0)
+			return ret;
+	}
+	list_add_tail(&nce->list, &sctx->name_cache_list);
+	sctx->name_cache_size++;
+
+	return ret;
+}
+
+static void name_cache_delete(struct send_ctx *sctx,
+			      struct name_cache_entry *nce)
+{
+	struct name_cache_entry **ncea;
+
+	ncea = radix_tree_lookup(&sctx->name_cache, nce->ino);
+	BUG_ON(!ncea);
+
+	if (ncea[0] == nce)
+		ncea[0] = NULL;
+	else if (ncea[1] == nce)
+		ncea[1] = NULL;
+	else
+		BUG();
+
+	if (!ncea[0] && !ncea[1]) {
+		radix_tree_delete(&sctx->name_cache, nce->ino);
+		kfree(ncea);
+	}
+
+	list_del(&nce->list);
+
+	sctx->name_cache_size--;
+}
+
+static struct name_cache_entry *name_cache_search(struct send_ctx *sctx,
+						    u64 ino, u64 gen)
+{
+	struct name_cache_entry **ncea;
+
+	ncea = radix_tree_lookup(&sctx->name_cache, ino);
+	if (!ncea)
+		return NULL;
+
+	if (ncea[0] && ncea[0]->gen == gen)
+		return ncea[0];
+	else if (ncea[1] && ncea[1]->gen == gen)
+		return ncea[1];
+	return NULL;
+}
+
+static void name_cache_used(struct send_ctx *sctx, struct name_cache_entry *nce)
+{
+	list_del(&nce->list);
+	list_add_tail(&nce->list, &sctx->name_cache_list);
+}
+
+static void name_cache_clean_unused(struct send_ctx *sctx)
+{
+	struct name_cache_entry *nce;
+
+	if (sctx->name_cache_size < SEND_CTX_NAME_CACHE_CLEAN_SIZE)
+		return;
+
+	while (sctx->name_cache_size > SEND_CTX_MAX_NAME_CACHE_SIZE) {
+		nce = list_entry(sctx->name_cache_list.next,
+				struct name_cache_entry, list);
+		name_cache_delete(sctx, nce);
+		kfree(nce);
+	}
+}
+
+static void name_cache_free(struct send_ctx *sctx)
+{
+	struct name_cache_entry *nce;
+	struct name_cache_entry *tmp;
+
+	list_for_each_entry_safe(nce, tmp, &sctx->name_cache_list, list) {
+		name_cache_delete(sctx, nce);
+	}
+}
+
+static int __get_cur_name_and_parent(struct send_ctx *sctx,
+				     u64 ino, u64 gen,
+				     u64 *parent_ino,
+				     u64 *parent_gen,
+				     struct fs_path *dest)
+{
+	int ret;
+	int nce_ret;
+	struct btrfs_path *path = NULL;
+	struct name_cache_entry *nce = NULL;
+
+	nce = name_cache_search(sctx, ino, gen);
+	if (nce) {
+		if (ino < sctx->send_progress && nce->need_later_update) {
+			name_cache_delete(sctx, nce);
+			kfree(nce);
+			nce = NULL;
+		} else {
+			name_cache_used(sctx, nce);
+			*parent_ino = nce->parent_ino;
+			*parent_gen = nce->parent_gen;
+			ret = fs_path_add(dest, nce->name, nce->name_len);
+			if (ret < 0)
+				goto out;
+			ret = nce->ret;
+			goto out;
+		}
+	}
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	ret = is_inode_existent(sctx, ino, gen);
+	if (ret < 0)
+		goto out;
+
+	if (!ret) {
+		ret = gen_unique_name(sctx, ino, gen, dest);
+		if (ret < 0)
+			goto out;
+		ret = 1;
+		goto out_cache;
+	}
+
+	if (ino < sctx->send_progress)
+		ret = get_first_ref(sctx, sctx->send_root, ino,
+				parent_ino, parent_gen, dest);
+	else
+		ret = get_first_ref(sctx, sctx->parent_root, ino,
+				parent_ino, parent_gen, dest);
+	if (ret < 0)
+		goto out;
+
+	ret = did_overwrite_ref(sctx, *parent_ino, *parent_gen, ino, gen,
+			dest->start, dest->end - dest->start);
+	if (ret < 0)
+		goto out;
+	if (ret) {
+		fs_path_reset(dest);
+		ret = gen_unique_name(sctx, ino, gen, dest);
+		if (ret < 0)
+			goto out;
+		ret = 1;
+	}
+
+out_cache:
+	nce = kmalloc(sizeof(*nce) + fs_path_len(dest) + 1, GFP_NOFS);
+	if (!nce) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	nce->ino = ino;
+	nce->gen = gen;
+	nce->parent_ino = *parent_ino;
+	nce->parent_gen = *parent_gen;
+	nce->name_len = fs_path_len(dest);
+	nce->ret = ret;
+	strcpy(nce->name, dest->start);
+	memset(&nce->use_list, 0, sizeof(nce->use_list));
+
+	if (ino < sctx->send_progress)
+		nce->need_later_update = 0;
+	else
+		nce->need_later_update = 1;
+
+	nce_ret = name_cache_insert(sctx, nce);
+	if (nce_ret < 0)
+		ret = nce_ret;
+	name_cache_clean_unused(sctx);
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+/*
+ * Magic happens here. This function returns the first ref to an inode as it
+ * would look like while receiving the stream at this point in time.
+ * We walk the path up to the root. For every inode in between, we check if it
+ * was already processed/sent. If yes, we continue with the parent as found
+ * in send_root. If not, we continue with the parent as found in parent_root.
+ * If we encounter an inode that was deleted at this point in time, we use the
+ * inodes "orphan" name instead of the real name and stop. Same with new inodes
+ * that were not created yet and overwritten inodes/refs.
+ *
+ * When do we have have orphan inodes:
+ * 1. When an inode is freshly created and thus no valid refs are available yet
+ * 2. When a directory lost all it's refs (deleted) but still has dir items
+ *    inside which were not processed yet (pending for move/delete). If anyone
+ *    tried to get the path to the dir items, it would get a path inside that
+ *    orphan directory.
+ * 3. When an inode is moved around or gets new links, it may overwrite the ref
+ *    of an unprocessed inode. If in that case the first ref would be
+ *    overwritten, the overwritten inode gets "orphanized". Later when we
+ *    process this overwritten inode, it is restored at a new place by moving
+ *    the orphan inode.
+ *
+ * sctx->send_progress tells this function at which point in time receiving
+ * would be.
+ */
+static int get_cur_path(struct send_ctx *sctx, u64 ino, u64 gen,
+			struct fs_path *dest)
+{
+	int ret = 0;
+	struct fs_path *name = NULL;
+	u64 parent_inode = 0;
+	u64 parent_gen = 0;
+	int stop = 0;
+
+	name = fs_path_alloc(sctx);
+	if (!name) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	dest->reversed = 1;
+	fs_path_reset(dest);
+
+	while (!stop && ino != BTRFS_FIRST_FREE_OBJECTID) {
+		fs_path_reset(name);
+
+		ret = __get_cur_name_and_parent(sctx, ino, gen,
+				&parent_inode, &parent_gen, name);
+		if (ret < 0)
+			goto out;
+		if (ret)
+			stop = 1;
+
+		ret = fs_path_add_path(dest, name);
+		if (ret < 0)
+			goto out;
+
+		ino = parent_inode;
+		gen = parent_gen;
+	}
+
+out:
+	fs_path_free(sctx, name);
+	if (!ret)
+		fs_path_unreverse(dest);
+	return ret;
+}
+
+/*
+ * Called for regular files when sending extents data. Opens a struct file
+ * to read from the file.
+ */
+static int open_cur_inode_file(struct send_ctx *sctx)
+{
+	int ret = 0;
+	struct btrfs_key key;
+	struct vfsmount *mnt;
+	struct inode *inode;
+	struct dentry *dentry;
+	struct file *filp;
+	int new = 0;
+
+	if (sctx->cur_inode_filp)
+		goto out;
+
+	key.objectid = sctx->cur_ino;
+	key.type = BTRFS_INODE_ITEM_KEY;
+	key.offset = 0;
+
+	inode = btrfs_iget(sctx->send_root->fs_info->sb, &key, sctx->send_root,
+			&new);
+	if (IS_ERR(inode)) {
+		ret = PTR_ERR(inode);
+		goto out;
+	}
+
+	dentry = d_obtain_alias(inode);
+	inode = NULL;
+	if (IS_ERR(dentry)) {
+		ret = PTR_ERR(dentry);
+		goto out;
+	}
+
+	mnt = mntget(sctx->mnt);
+	filp = dentry_open(dentry, mnt, O_RDONLY | O_LARGEFILE, current_cred());
+	dentry = NULL;
+	mnt = NULL;
+	if (IS_ERR(filp)) {
+		ret = PTR_ERR(filp);
+		goto out;
+	}
+	sctx->cur_inode_filp = filp;
+
+out:
+	/*
+	 * no xxxput required here as every vfs op
+	 * does it by itself on failure
+	 */
+	return ret;
+}
+
+/*
+ * Closes the struct file that was created in open_cur_inode_file
+ */
+static int close_cur_inode_file(struct send_ctx *sctx)
+{
+	int ret = 0;
+
+	if (!sctx->cur_inode_filp)
+		goto out;
+
+	ret = filp_close(sctx->cur_inode_filp, NULL);
+	sctx->cur_inode_filp = NULL;
+
+out:
+	return ret;
+}
+
+/*
+ * Sends a BTRFS_SEND_C_SUBVOL command/item to userspace
+ */
+static int send_subvol_begin(struct send_ctx *sctx)
+{
+	int ret;
+	struct btrfs_root *send_root = sctx->send_root;
+	struct btrfs_root *parent_root = sctx->parent_root;
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	struct btrfs_root_ref *ref;
+	struct extent_buffer *leaf;
+	char *name = NULL;
+	int namelen;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	name = kmalloc(BTRFS_PATH_NAME_MAX, GFP_NOFS);
+	if (!name) {
+		btrfs_free_path(path);
+		return -ENOMEM;
+	}
+
+	key.objectid = send_root->objectid;
+	key.type = BTRFS_ROOT_BACKREF_KEY;
+	key.offset = 0;
+
+	ret = btrfs_search_slot_for_read(send_root->fs_info->tree_root,
+				&key, path, 1, 0);
+	if (ret < 0)
+		goto out;
+	if (ret) {
+		ret = -ENOENT;
+		goto out;
+	}
+
+	leaf = path->nodes[0];
+	btrfs_item_key_to_cpu(leaf, &key, path->slots[0]);
+	if (key.type != BTRFS_ROOT_BACKREF_KEY ||
+	    key.objectid != send_root->objectid) {
+		ret = -ENOENT;
+		goto out;
+	}
+	ref = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_root_ref);
+	namelen = btrfs_root_ref_name_len(leaf, ref);
+	read_extent_buffer(leaf, name, (unsigned long)(ref + 1), namelen);
+	btrfs_release_path(path);
+
+	if (ret < 0)
+		goto out;
+
+	if (parent_root) {
+		ret = begin_cmd(sctx, BTRFS_SEND_C_SNAPSHOT);
+		if (ret < 0)
+			goto out;
+	} else {
+		ret = begin_cmd(sctx, BTRFS_SEND_C_SUBVOL);
+		if (ret < 0)
+			goto out;
+	}
+
+	TLV_PUT_STRING(sctx, BTRFS_SEND_A_PATH, name, namelen);
+	TLV_PUT_UUID(sctx, BTRFS_SEND_A_UUID,
+			sctx->send_root->root_item.uuid);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_CTRANSID,
+			sctx->send_root->root_item.ctransid);
+	if (parent_root) {
+		TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
+				sctx->parent_root->root_item.uuid);
+		TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_CTRANSID,
+				sctx->parent_root->root_item.ctransid);
+	}
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	btrfs_free_path(path);
+	kfree(name);
+	return ret;
+}
+
+static int send_truncate(struct send_ctx *sctx, u64 ino, u64 gen, u64 size)
+{
+	int ret = 0;
+	struct fs_path *p;
+
+verbose_printk("btrfs: send_truncate %llu size=%llu\n", ino, size);
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_TRUNCATE);
+	if (ret < 0)
+		goto out;
+
+	ret = get_cur_path(sctx, ino, gen, p);
+	if (ret < 0)
+		goto out;
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_SIZE, size);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	fs_path_free(sctx, p);
+	return ret;
+}
+
+static int send_chmod(struct send_ctx *sctx, u64 ino, u64 gen, u64 mode)
+{
+	int ret = 0;
+	struct fs_path *p;
+
+verbose_printk("btrfs: send_chmod %llu mode=%llu\n", ino, mode);
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_CHMOD);
+	if (ret < 0)
+		goto out;
+
+	ret = get_cur_path(sctx, ino, gen, p);
+	if (ret < 0)
+		goto out;
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_MODE, mode & 07777);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	fs_path_free(sctx, p);
+	return ret;
+}
+
+static int send_chown(struct send_ctx *sctx, u64 ino, u64 gen, u64 uid, u64 gid)
+{
+	int ret = 0;
+	struct fs_path *p;
+
+verbose_printk("btrfs: send_chown %llu uid=%llu, gid=%llu\n", ino, uid, gid);
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_CHOWN);
+	if (ret < 0)
+		goto out;
+
+	ret = get_cur_path(sctx, ino, gen, p);
+	if (ret < 0)
+		goto out;
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_UID, uid);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_GID, gid);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	fs_path_free(sctx, p);
+	return ret;
+}
+
+static int send_utimes(struct send_ctx *sctx, u64 ino, u64 gen)
+{
+	int ret = 0;
+	struct fs_path *p = NULL;
+	struct btrfs_inode_item *ii;
+	struct btrfs_path *path = NULL;
+	struct extent_buffer *eb;
+	struct btrfs_key key;
+	int slot;
+
+verbose_printk("btrfs: send_utimes %llu\n", ino);
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	path = alloc_path_for_send();
+	if (!path) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	key.objectid = ino;
+	key.type = BTRFS_INODE_ITEM_KEY;
+	key.offset = 0;
+	ret = btrfs_search_slot(NULL, sctx->send_root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
+
+	eb = path->nodes[0];
+	slot = path->slots[0];
+	ii = btrfs_item_ptr(eb, slot, struct btrfs_inode_item);
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_UTIMES);
+	if (ret < 0)
+		goto out;
+
+	ret = get_cur_path(sctx, ino, gen, p);
+	if (ret < 0)
+		goto out;
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
+	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_ATIME, eb,
+			btrfs_inode_atime(ii));
+	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_MTIME, eb,
+			btrfs_inode_mtime(ii));
+	TLV_PUT_BTRFS_TIMESPEC(sctx, BTRFS_SEND_A_CTIME, eb,
+			btrfs_inode_ctime(ii));
+	/* TODO otime? */
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	fs_path_free(sctx, p);
+	btrfs_free_path(path);
+	return ret;
+}
+
+/*
+ * Sends a BTRFS_SEND_C_MKXXX or SYMLINK command to user space. We don't have
+ * a valid path yet because we did not process the refs yet. So, the inode
+ * is created as orphan.
+ */
+static int send_create_inode(struct send_ctx *sctx, struct btrfs_path *path,
+			     struct btrfs_key *key)
+{
+	int ret = 0;
+	struct extent_buffer *eb = path->nodes[0];
+	struct btrfs_inode_item *ii;
+	struct fs_path *p;
+	int slot = path->slots[0];
+	int cmd;
+	u64 mode;
+
+verbose_printk("btrfs: send_create_inode %llu\n", sctx->cur_ino);
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	ii = btrfs_item_ptr(eb, slot, struct btrfs_inode_item);
+	mode = btrfs_inode_mode(eb, ii);
+
+	if (S_ISREG(mode))
+		cmd = BTRFS_SEND_C_MKFILE;
+	else if (S_ISDIR(mode))
+		cmd = BTRFS_SEND_C_MKDIR;
+	else if (S_ISLNK(mode))
+		cmd = BTRFS_SEND_C_SYMLINK;
+	else if (S_ISCHR(mode) || S_ISBLK(mode))
+		cmd = BTRFS_SEND_C_MKNOD;
+	else if (S_ISFIFO(mode))
+		cmd = BTRFS_SEND_C_MKFIFO;
+	else if (S_ISSOCK(mode))
+		cmd = BTRFS_SEND_C_MKSOCK;
+	else {
+		printk(KERN_WARNING "btrfs: unexpected inode type %o",
+				(int)(mode & S_IFMT));
+		ret = -ENOTSUPP;
+		goto out;
+	}
+
+	ret = begin_cmd(sctx, cmd);
+	if (ret < 0)
+		goto out;
+
+	ret = gen_unique_name(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_INO, sctx->cur_ino);
+
+	if (S_ISLNK(mode)) {
+		fs_path_reset(p);
+		ret = read_symlink(sctx, sctx->send_root, sctx->cur_ino, p);
+		if (ret < 0)
+			goto out;
+		TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH_LINK, p);
+	} else if (S_ISCHR(mode) || S_ISBLK(mode) ||
+		   S_ISFIFO(mode) || S_ISSOCK(mode)) {
+		TLV_PUT_U64(sctx, BTRFS_SEND_A_RDEV, btrfs_inode_rdev(eb, ii));
+	}
+
+	ret = send_cmd(sctx);
+	if (ret < 0)
+		goto out;
+
+
+tlv_put_failure:
+out:
+	fs_path_free(sctx, p);
+	return ret;
+}
+
+struct recorded_ref {
+	struct list_head list;
+	char *dir_path;
+	char *name;
+	struct fs_path *full_path;
+	u64 dir;
+	u64 dir_gen;
+	int dir_path_len;
+	int name_len;
+};
+
+/*
+ * We need to process new refs before deleted refs, but compare_tree gives us
+ * everything mixed. So we first record all refs and later process them.
+ * This function is a helper to record one ref.
+ */
+static int record_ref(struct list_head *head, u64 dir,
+		      u64 dir_gen, struct fs_path *path)
+{
+	struct recorded_ref *ref;
+	char *tmp;
+
+	ref = kmalloc(sizeof(*ref), GFP_NOFS);
+	if (!ref)
+		return -ENOMEM;
+
+	ref->dir = dir;
+	ref->dir_gen = dir_gen;
+	ref->full_path = path;
+
+	tmp = strrchr(ref->full_path->start, '/');
+	if (!tmp) {
+		ref->name_len = ref->full_path->end - ref->full_path->start;
+		ref->name = ref->full_path->start;
+		ref->dir_path_len = 0;
+		ref->dir_path = ref->full_path->start;
+	} else {
+		tmp++;
+		ref->name_len = ref->full_path->end - tmp;
+		ref->name = tmp;
+		ref->dir_path = ref->full_path->start;
+		ref->dir_path_len = ref->full_path->end -
+				ref->full_path->start - 1 - ref->name_len;
+	}
+
+	list_add_tail(&ref->list, head);
+	return 0;
+}
+
+static void __free_recorded_refs(struct send_ctx *sctx, struct list_head *head)
+{
+	struct recorded_ref *cur;
+	struct recorded_ref *tmp;
+
+	list_for_each_entry_safe(cur, tmp, head, list) {
+		fs_path_free(sctx, cur->full_path);
+		kfree(cur);
+	}
+	INIT_LIST_HEAD(head);
+}
+
+static void free_recorded_refs(struct send_ctx *sctx)
+{
+	__free_recorded_refs(sctx, &sctx->new_refs);
+	__free_recorded_refs(sctx, &sctx->deleted_refs);
+}
+
+/*
+ * Renames/moves a file/dir to it's orphan name. Used when the first
+ * ref of an unprocessed inode gets overwritten and for all non empty
+ * directories.
+ */
+static int orphanize_inode(struct send_ctx *sctx, u64 ino, u64 gen,
+			  struct fs_path *path)
+{
+	int ret;
+	struct fs_path *orphan;
+
+	orphan = fs_path_alloc(sctx);
+	if (!orphan)
+		return -ENOMEM;
+
+	ret = gen_unique_name(sctx, ino, gen, orphan);
+	if (ret < 0)
+		goto out;
+
+	ret = send_rename(sctx, path, orphan);
+
+out:
+	fs_path_free(sctx, orphan);
+	return ret;
+}
+
+/*
+ * Returns 1 if a directory can be removed at this point in time.
+ * We check this by iterating all dir items and checking if the inode behind
+ * the dir item was already processed.
+ */
+static int can_rmdir(struct send_ctx *sctx, u64 dir, u64 send_progress)
+{
+	int ret = 0;
+	struct btrfs_root *root = sctx->parent_root;
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	struct btrfs_key found_key;
+	struct btrfs_key loc;
+	struct btrfs_dir_item *di;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	key.objectid = dir;
+	key.type = BTRFS_DIR_INDEX_KEY;
+	key.offset = 0;
+
+	while (1) {
+		ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
+		if (ret < 0)
+			goto out;
+		if (!ret) {
+			btrfs_item_key_to_cpu(path->nodes[0], &found_key,
+					path->slots[0]);
+		}
+		if (ret || found_key.objectid != key.objectid ||
+		    found_key.type != key.type) {
+			break;
+		}
+
+		di = btrfs_item_ptr(path->nodes[0], path->slots[0],
+				struct btrfs_dir_item);
+		btrfs_dir_item_key_to_cpu(path->nodes[0], di, &loc);
+
+		if (loc.objectid > send_progress) {
+			ret = 0;
+			goto out;
+		}
+
+		btrfs_release_path(path);
+		key.offset = found_key.offset + 1;
+	}
+
+	ret = 1;
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+struct finish_unordered_dir_ctx {
+	struct send_ctx *sctx;
+	struct fs_path *cur_path;
+	struct fs_path *dir_path;
+	u64 dir_ino;
+	int need_delete;
+	int delete_pass;
+};
+
+int __finish_unordered_dir(int num, struct btrfs_key *di_key,
+			   const char *name, int name_len,
+			   const char *data, int data_len,
+			   u8 type, void *ctx)
+{
+	int ret = 0;
+	struct finish_unordered_dir_ctx *fctx = ctx;
+	struct send_ctx *sctx = fctx->sctx;
+	u64 di_gen;
+	u64 di_mode;
+	int is_orphan = 0;
+
+	if (di_key->objectid >= fctx->dir_ino)
+		goto out;
+
+	fs_path_reset(fctx->cur_path);
+
+	ret = get_inode_info(sctx->send_root, di_key->objectid,
+			NULL, &di_gen, &di_mode, NULL, NULL);
+	if (ret < 0)
+		goto out;
+
+	ret = is_first_ref(sctx, sctx->send_root, di_key->objectid,
+			fctx->dir_ino, name, name_len);
+	if (ret < 0)
+		goto out;
+	if (ret) {
+		is_orphan = 1;
+		ret = gen_unique_name(sctx, di_key->objectid, di_gen,
+				fctx->cur_path);
+	} else {
+		ret = get_cur_path(sctx, di_key->objectid, di_gen,
+				fctx->cur_path);
+	}
+	if (ret < 0)
+		goto out;
+
+	ret = fs_path_add(fctx->dir_path, name, name_len);
+	if (ret < 0)
+		goto out;
+
+	if (!fctx->delete_pass) {
+		if (S_ISDIR(di_mode)) {
+			ret = send_rename(sctx, fctx->cur_path,
+					fctx->dir_path);
+		} else {
+			ret = send_link(sctx, fctx->dir_path,
+					fctx->cur_path);
+			if (is_orphan)
+				fctx->need_delete = 1;
+		}
+	} else if (!S_ISDIR(di_mode)) {
+		ret = send_unlink(sctx, fctx->cur_path);
+	} else {
+		ret = 0;
+	}
+
+	fs_path_remove(fctx->dir_path);
+
+out:
+	return ret;
+}
+
+/*
+ * Go through all dir items and see if we find refs which could not be created
+ * in the past because the dir did not exist at that time.
+ */
+static int finish_outoforder_dir(struct send_ctx *sctx, u64 dir, u64 dir_gen)
+{
+	int ret = 0;
+	struct btrfs_path *path = NULL;
+	struct btrfs_key key;
+	struct btrfs_key found_key;
+	struct extent_buffer *eb;
+	struct finish_unordered_dir_ctx fctx;
+	int slot;
+
+	path = alloc_path_for_send();
+	if (!path) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	memset(&fctx, 0, sizeof(fctx));
+	fctx.sctx = sctx;
+	fctx.cur_path = fs_path_alloc(sctx);
+	fctx.dir_path = fs_path_alloc(sctx);
+	if (!fctx.cur_path || !fctx.dir_path) {
+		ret = -ENOMEM;
+		goto out;
+	}
+	fctx.dir_ino = dir;
+
+	ret = get_cur_path(sctx, dir, dir_gen, fctx.dir_path);
+	if (ret < 0)
+		goto out;
+
+	/*
+	 * We do two passes. The first links in the new refs and the second
+	 * deletes orphans if required. Deletion of orphans is not required for
+	 * directory inodes, as we always have only one ref and use rename
+	 * instead of link for those.
+	 */
+
+again:
+	key.objectid = dir;
+	key.type = BTRFS_DIR_ITEM_KEY;
+	key.offset = 0;
+	while (1) {
+		ret = btrfs_search_slot_for_read(sctx->send_root, &key, path,
+				1, 0);
+		if (ret < 0)
+			goto out;
+		eb = path->nodes[0];
+		slot = path->slots[0];
+		btrfs_item_key_to_cpu(eb, &found_key, slot);
+
+		if (found_key.objectid != key.objectid ||
+		    found_key.type != key.type) {
+			btrfs_release_path(path);
+			break;
+		}
+
+		ret = iterate_dir_item(sctx, sctx->send_root, path,
+				&found_key, __finish_unordered_dir,
+				&fctx);
+		if (ret < 0)
+			goto out;
+
+		key.offset = found_key.offset + 1;
+		btrfs_release_path(path);
+	}
+
+	if (!fctx.delete_pass && fctx.need_delete) {
+		fctx.delete_pass = 1;
+		goto again;
+	}
+
+out:
+	btrfs_free_path(path);
+	fs_path_free(sctx, fctx.cur_path);
+	fs_path_free(sctx, fctx.dir_path);
+	return ret;
+}
+
+/*
+ * This does all the move/link/unlink/rmdir magic.
+ */
+static int process_recorded_refs(struct send_ctx *sctx)
+{
+	int ret = 0;
+	struct recorded_ref *cur;
+	struct ulist *check_dirs = NULL;
+	struct ulist_iterator uit;
+	struct ulist_node *un;
+	struct fs_path *valid_path = NULL;
+	u64 ow_inode;
+	u64 ow_gen;
+	int did_overwrite = 0;
+	int is_orphan = 0;
+
+verbose_printk("btrfs: process_recorded_refs %llu\n", sctx->cur_ino);
+
+	valid_path = fs_path_alloc(sctx);
+	if (!valid_path) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	check_dirs = ulist_alloc(GFP_NOFS);
+	if (!check_dirs) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	/*
+	 * First, check if the first ref of the current inode was overwritten
+	 * before. If yes, we know that the current inode was already orphanized
+	 * and thus use the orphan name. If not, we can use get_cur_path to
+	 * get the path of the first ref as it would like while receiving at
+	 * this point in time.
+	 * New inodes are always orphan at the beginning, so force to use the
+	 * orphan name in this case.
+	 * The first ref is stored in valid_path and will be updated if it
+	 * gets moved around.
+	 */
+	if (!sctx->cur_inode_new) {
+		ret = did_overwrite_first_ref(sctx, sctx->cur_ino,
+				sctx->cur_inode_gen);
+		if (ret < 0)
+			goto out;
+		if (ret)
+			did_overwrite = 1;
+	}
+	if (sctx->cur_inode_new || did_overwrite) {
+		ret = gen_unique_name(sctx, sctx->cur_ino,
+				sctx->cur_inode_gen, valid_path);
+		if (ret < 0)
+			goto out;
+		is_orphan = 1;
+	} else {
+		ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen,
+				valid_path);
+		if (ret < 0)
+			goto out;
+	}
+
+	list_for_each_entry(cur, &sctx->new_refs, list) {
+		/*
+		 * Check if this new ref would overwrite the first ref of
+		 * another unprocessed inode. If yes, orphanize the
+		 * overwritten inode. If we find an overwritten ref that is
+		 * not the first ref, simply unlink it.
+		 */
+		ret = will_overwrite_ref(sctx, cur->dir, cur->dir_gen,
+				cur->name, cur->name_len,
+				&ow_inode, &ow_gen);
+		if (ret < 0)
+			goto out;
+		if (ret) {
+			ret = is_first_ref(sctx, sctx->parent_root,
+					ow_inode, cur->dir, cur->name,
+					cur->name_len);
+			if (ret < 0)
+				goto out;
+			if (ret) {
+				ret = orphanize_inode(sctx, ow_inode, ow_gen,
+						cur->full_path);
+				if (ret < 0)
+					goto out;
+			} else {
+				ret = send_unlink(sctx, cur->full_path);
+				if (ret < 0)
+					goto out;
+			}
+		}
+
+		/*
+		 * link/move the ref to the new place. If we have an orphan
+		 * inode, move it and update valid_path. If not, link or move
+		 * it depending on the inode mode.
+		 */
+		if (is_orphan && !sctx->cur_inode_first_ref_orphan) {
+			ret = send_rename(sctx, valid_path, cur->full_path);
+			if (ret < 0)
+				goto out;
+			is_orphan = 0;
+			ret = fs_path_copy(valid_path, cur->full_path);
+			if (ret < 0)
+				goto out;
+		} else {
+			if (S_ISDIR(sctx->cur_inode_mode)) {
+				/*
+				 * Dirs can't be linked, so move it. For moved
+				 * dirs, we always have one new and one deleted
+				 * ref. The deleted ref is ignored later.
+				 */
+				ret = send_rename(sctx, valid_path,
+						cur->full_path);
+				if (ret < 0)
+					goto out;
+				ret = fs_path_copy(valid_path, cur->full_path);
+				if (ret < 0)
+					goto out;
+			} else {
+				ret = send_link(sctx, cur->full_path,
+						valid_path);
+				if (ret < 0)
+					goto out;
+			}
+		}
+		ret = ulist_add(check_dirs, cur->dir, cur->dir_gen,
+				GFP_NOFS);
+		if (ret < 0)
+			goto out;
+	}
+
+	if (S_ISDIR(sctx->cur_inode_mode) && sctx->cur_inode_deleted) {
+		/*
+		 * Check if we can already rmdir the directory. If not,
+		 * orphanize it. For every dir item inside that gets deleted
+		 * later, we do this check again and rmdir it then if possible.
+		 * See the use of check_dirs for more details.
+		 */
+		ret = can_rmdir(sctx, sctx->cur_ino, sctx->cur_ino);
+		if (ret < 0)
+			goto out;
+		if (ret) {
+			ret = send_rmdir(sctx, valid_path);
+			if (ret < 0)
+				goto out;
+		} else if (!is_orphan) {
+			ret = orphanize_inode(sctx, sctx->cur_ino,
+					sctx->cur_inode_gen, valid_path);
+			if (ret < 0)
+				goto out;
+			is_orphan = 1;
+		}
+
+		list_for_each_entry(cur, &sctx->deleted_refs, list) {
+			ret = ulist_add(check_dirs, cur->dir, cur->dir_gen,
+					GFP_NOFS);
+			if (ret < 0)
+				goto out;
+		}
+	} else if (!S_ISDIR(sctx->cur_inode_mode)) {
+		/*
+		 * We have a non dir inode. Go through all deleted refs and
+		 * unlink them if they were not already overwritten by other
+		 * inodes.
+		 */
+		list_for_each_entry(cur, &sctx->deleted_refs, list) {
+			ret = did_overwrite_ref(sctx, cur->dir, cur->dir_gen,
+					sctx->cur_ino, sctx->cur_inode_gen,
+					cur->name, cur->name_len);
+			if (ret < 0)
+				goto out;
+			if (!ret) {
+				/*
+				 * In case the inode was moved to a directory
+				 * that was not created yet (see
+				 * __record_new_ref), we can not unlink the ref
+				 * as it will be needed later when the parent
+				 * directory is created, so that we can move in
+				 * the inode to the new dir.
+				 */
+				if (!is_orphan &&
+				    sctx->cur_inode_first_ref_orphan) {
+					ret = orphanize_inode(sctx,
+							sctx->cur_ino,
+							sctx->cur_inode_gen,
+							cur->full_path);
+					if (ret < 0)
+						goto out;
+					ret = gen_unique_name(sctx,
+							sctx->cur_ino,
+							sctx->cur_inode_gen,
+							valid_path);
+					if (ret < 0)
+						goto out;
+					is_orphan = 1;
+
+				} else {
+					ret = send_unlink(sctx, cur->full_path);
+					if (ret < 0)
+						goto out;
+				}
+			}
+			ret = ulist_add(check_dirs, cur->dir, cur->dir_gen,
+					GFP_NOFS);
+			if (ret < 0)
+				goto out;
+		}
+
+		/*
+		 * If the inode is still orphan, unlink the orphan. This may
+		 * happen when a previous inode did overwrite the first ref
+		 * of this inode and no new refs were added for the current
+		 * inode.
+		 * We can however not delete the orphan in case the inode relies
+		 * in a directory that was not created yet (see
+		 * __record_new_ref)
+		 */
+		if (is_orphan && !sctx->cur_inode_first_ref_orphan) {
+			ret = send_unlink(sctx, valid_path);
+			if (ret < 0)
+				goto out;
+		}
+	}
+
+	/*
+	 * We did collect all parent dirs where cur_inode was once located. We
+	 * now go through all these dirs and check if they are pending for
+	 * deletion and if it's finally possible to perform the rmdir now.
+	 * We also update the inode stats of the parent dirs here.
+	 */
+	ULIST_ITER_INIT(&uit);
+	while ((un = ulist_next(check_dirs, &uit))) {
+		if (un->val > sctx->cur_ino)
+			continue;
+
+		ret = get_cur_inode_state(sctx, un->val, un->aux);
+		if (ret < 0)
+			goto out;
+
+		if (ret == inode_state_did_create ||
+		    ret == inode_state_no_change) {
+			/* TODO delayed utimes */
+			ret = send_utimes(sctx, un->val, un->aux);
+			if (ret < 0)
+				goto out;
+		} else if (ret == inode_state_did_delete) {
+			ret = can_rmdir(sctx, un->val, sctx->cur_ino);
+			if (ret < 0)
+				goto out;
+			if (ret) {
+				ret = get_cur_path(sctx, un->val, un->aux,
+						valid_path);
+				if (ret < 0)
+					goto out;
+				ret = send_rmdir(sctx, valid_path);
+				if (ret < 0)
+					goto out;
+			}
+		}
+	}
+
+	/*
+	 * Current inode is now at it's new position, so we must increase
+	 * send_progress
+	 */
+	sctx->send_progress = sctx->cur_ino + 1;
+
+	/*
+	 * We may have a directory here that has pending refs which could not
+	 * be created before (because the dir did not exist before, see
+	 * __record_new_ref). finish_outoforder_dir will link/move the pending
+	 * refs.
+	 */
+	if (S_ISDIR(sctx->cur_inode_mode) && sctx->cur_inode_new) {
+		ret = finish_outoforder_dir(sctx, sctx->cur_ino,
+				sctx->cur_inode_gen);
+		if (ret < 0)
+			goto out;
+	}
+
+	ret = 0;
+
+out:
+	free_recorded_refs(sctx);
+	ulist_free(check_dirs);
+	fs_path_free(sctx, valid_path);
+	return ret;
+}
+
+static int __record_new_ref(int num, u64 dir, int index,
+			    struct fs_path *name,
+			    void *ctx)
+{
+	int ret = 0;
+	struct send_ctx *sctx = ctx;
+	struct fs_path *p;
+	u64 gen;
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	ret = get_inode_info(sctx->send_root, dir, NULL, &gen, NULL, NULL,
+			NULL);
+	if (ret < 0)
+		goto out;
+
+	/*
+	 * The parent may be non-existent at this point in time. This happens
+	 * if the ino of the parent dir is higher then the current ino. In this
+	 * case, we can not process this ref until the parent dir is finally
+	 * created. If we reach the parent dir later, process_recorded_refs
+	 * will go through all dir items and process the refs that could not be
+	 * processed before. In case this is the first ref, we set
+	 * cur_inode_first_ref_orphan to 1 to inform process_recorded_refs to
+	 * keep an orphan of the inode so that it later can be used for
+	 * link/move
+	 */
+	ret = is_inode_existent(sctx, dir, gen);
+	if (ret < 0)
+		goto out;
+	if (!ret) {
+		ret = is_first_ref(sctx, sctx->send_root, sctx->cur_ino, dir,
+				name->start, fs_path_len(name));
+		if (ret < 0)
+			goto out;
+		if (ret)
+			sctx->cur_inode_first_ref_orphan = 1;
+		ret = 0;
+		goto out;
+	}
+
+	ret = get_cur_path(sctx, dir, gen, p);
+	if (ret < 0)
+		goto out;
+	ret = fs_path_add_path(p, name);
+	if (ret < 0)
+		goto out;
+
+	ret = record_ref(&sctx->new_refs, dir, gen, p);
+
+out:
+	if (ret)
+		fs_path_free(sctx, p);
+	return ret;
+}
+
+static int __record_deleted_ref(int num, u64 dir, int index,
+				struct fs_path *name,
+				void *ctx)
+{
+	int ret = 0;
+	struct send_ctx *sctx = ctx;
+	struct fs_path *p;
+	u64 gen;
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	ret = get_inode_info(sctx->parent_root, dir, NULL, &gen, NULL, NULL,
+			NULL);
+	if (ret < 0)
+		goto out;
+
+	ret = get_cur_path(sctx, dir, gen, p);
+	if (ret < 0)
+		goto out;
+	ret = fs_path_add_path(p, name);
+	if (ret < 0)
+		goto out;
+
+	ret = record_ref(&sctx->deleted_refs, dir, gen, p);
+
+out:
+	if (ret)
+		fs_path_free(sctx, p);
+	return ret;
+}
+
+static int record_new_ref(struct send_ctx *sctx)
+{
+	int ret;
+
+	ret = iterate_inode_ref(sctx, sctx->send_root, sctx->left_path,
+			sctx->cmp_key, 0, __record_new_ref, sctx);
+	if (ret < 0)
+		goto out;
+	ret = 0;
+
+out:
+	return ret;
+}
+
+static int record_deleted_ref(struct send_ctx *sctx)
+{
+	int ret;
+
+	ret = iterate_inode_ref(sctx, sctx->parent_root, sctx->right_path,
+			sctx->cmp_key, 0, __record_deleted_ref, sctx);
+	if (ret < 0)
+		goto out;
+	ret = 0;
+
+out:
+	return ret;
+}
+
+struct find_ref_ctx {
+	u64 dir;
+	struct fs_path *name;
+	int found_idx;
+};
+
+static int __find_iref(int num, u64 dir, int index,
+		       struct fs_path *name,
+		       void *ctx_)
+{
+	struct find_ref_ctx *ctx = ctx_;
+
+	if (dir == ctx->dir && fs_path_len(name) == fs_path_len(ctx->name) &&
+	    strncmp(name->start, ctx->name->start, fs_path_len(name)) == 0) {
+		ctx->found_idx = num;
+		return 1;
+	}
+	return 0;
+}
+
+static int find_iref(struct send_ctx *sctx,
+		     struct btrfs_root *root,
+		     struct btrfs_path *path,
+		     struct btrfs_key *key,
+		     u64 dir, struct fs_path *name)
+{
+	int ret;
+	struct find_ref_ctx ctx;
+
+	ctx.dir = dir;
+	ctx.name = name;
+	ctx.found_idx = -1;
+
+	ret = iterate_inode_ref(sctx, root, path, key, 0, __find_iref, &ctx);
+	if (ret < 0)
+		return ret;
+
+	if (ctx.found_idx == -1)
+		return -ENOENT;
+
+	return ctx.found_idx;
+}
+
+static int __record_changed_new_ref(int num, u64 dir, int index,
+				    struct fs_path *name,
+				    void *ctx)
+{
+	int ret;
+	struct send_ctx *sctx = ctx;
+
+	ret = find_iref(sctx, sctx->parent_root, sctx->right_path,
+			sctx->cmp_key, dir, name);
+	if (ret == -ENOENT)
+		ret = __record_new_ref(num, dir, index, name, sctx);
+	else if (ret > 0)
+		ret = 0;
+
+	return ret;
+}
+
+static int __record_changed_deleted_ref(int num, u64 dir, int index,
+					struct fs_path *name,
+					void *ctx)
+{
+	int ret;
+	struct send_ctx *sctx = ctx;
+
+	ret = find_iref(sctx, sctx->send_root, sctx->left_path, sctx->cmp_key,
+			dir, name);
+	if (ret == -ENOENT)
+		ret = __record_deleted_ref(num, dir, index, name, sctx);
+	else if (ret > 0)
+		ret = 0;
+
+	return ret;
+}
+
+static int record_changed_ref(struct send_ctx *sctx)
+{
+	int ret = 0;
+
+	ret = iterate_inode_ref(sctx, sctx->send_root, sctx->left_path,
+			sctx->cmp_key, 0, __record_changed_new_ref, sctx);
+	if (ret < 0)
+		goto out;
+	ret = iterate_inode_ref(sctx, sctx->parent_root, sctx->right_path,
+			sctx->cmp_key, 0, __record_changed_deleted_ref, sctx);
+	if (ret < 0)
+		goto out;
+	ret = 0;
+
+out:
+	return ret;
+}
+
+/*
+ * Record and process all refs at once. Needed when an inode changes the
+ * generation number, which means that it was deleted and recreated.
+ */
+static int process_all_refs(struct send_ctx *sctx,
+			    enum btrfs_compare_tree_result cmd)
+{
+	int ret;
+	struct btrfs_root *root;
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	struct btrfs_key found_key;
+	struct extent_buffer *eb;
+	int slot;
+	iterate_inode_ref_t cb;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	if (cmd == BTRFS_COMPARE_TREE_NEW) {
+		root = sctx->send_root;
+		cb = __record_new_ref;
+	} else if (cmd == BTRFS_COMPARE_TREE_DELETED) {
+		root = sctx->parent_root;
+		cb = __record_deleted_ref;
+	} else {
+		BUG();
+	}
+
+	key.objectid = sctx->cmp_key->objectid;
+	key.type = BTRFS_INODE_REF_KEY;
+	key.offset = 0;
+	while (1) {
+		ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
+		if (ret < 0) {
+			btrfs_release_path(path);
+			goto out;
+		}
+		if (ret) {
+			btrfs_release_path(path);
+			break;
+		}
+
+		eb = path->nodes[0];
+		slot = path->slots[0];
+		btrfs_item_key_to_cpu(eb, &found_key, slot);
+
+		if (found_key.objectid != key.objectid ||
+		    found_key.type != key.type) {
+			btrfs_release_path(path);
+			break;
+		}
+
+		ret = iterate_inode_ref(sctx, sctx->parent_root, path,
+				&found_key, 0, cb, sctx);
+		btrfs_release_path(path);
+		if (ret < 0)
+			goto out;
+
+		key.offset = found_key.offset + 1;
+	}
+
+	ret = process_recorded_refs(sctx);
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+static int send_set_xattr(struct send_ctx *sctx,
+			  struct fs_path *path,
+			  const char *name, int name_len,
+			  const char *data, int data_len)
+{
+	int ret = 0;
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_SET_XATTR);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, path);
+	TLV_PUT_STRING(sctx, BTRFS_SEND_A_XATTR_NAME, name, name_len);
+	TLV_PUT(sctx, BTRFS_SEND_A_XATTR_DATA, data, data_len);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	return ret;
+}
+
+static int send_remove_xattr(struct send_ctx *sctx,
+			  struct fs_path *path,
+			  const char *name, int name_len)
+{
+	int ret = 0;
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_REMOVE_XATTR);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, path);
+	TLV_PUT_STRING(sctx, BTRFS_SEND_A_XATTR_NAME, name, name_len);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	return ret;
+}
+
+static int __process_new_xattr(int num, struct btrfs_key *di_key,
+			       const char *name, int name_len,
+			       const char *data, int data_len,
+			       u8 type, void *ctx)
+{
+	int ret;
+	struct send_ctx *sctx = ctx;
+	struct fs_path *p;
+	posix_acl_xattr_header dummy_acl;
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	/*
+	 * This hack is needed because empty acl's are stored as zero byte
+	 * data in xattrs. Problem with that is, that receiving these zero byte
+	 * acl's will fail later. To fix this, we send a dummy acl list that
+	 * only contains the version number and no entries.
+	 */
+	if (!strncmp(name, XATTR_NAME_POSIX_ACL_ACCESS, name_len) ||
+	    !strncmp(name, XATTR_NAME_POSIX_ACL_DEFAULT, name_len)) {
+		if (data_len == 0) {
+			dummy_acl.a_version =
+					cpu_to_le32(POSIX_ACL_XATTR_VERSION);
+			data = (char *)&dummy_acl;
+			data_len = sizeof(dummy_acl);
+		}
+	}
+
+	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
+	if (ret < 0)
+		goto out;
+
+	ret = send_set_xattr(sctx, p, name, name_len, data, data_len);
+
+out:
+	fs_path_free(sctx, p);
+	return ret;
+}
+
+static int __process_deleted_xattr(int num, struct btrfs_key *di_key,
+				   const char *name, int name_len,
+				   const char *data, int data_len,
+				   u8 type, void *ctx)
+{
+	int ret;
+	struct send_ctx *sctx = ctx;
+	struct fs_path *p;
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
+	if (ret < 0)
+		goto out;
+
+	ret = send_remove_xattr(sctx, p, name, name_len);
+
+out:
+	fs_path_free(sctx, p);
+	return ret;
+}
+
+static int process_new_xattr(struct send_ctx *sctx)
+{
+	int ret = 0;
+
+	ret = iterate_dir_item(sctx, sctx->send_root, sctx->left_path,
+			sctx->cmp_key, __process_new_xattr, sctx);
+
+	return ret;
+}
+
+static int process_deleted_xattr(struct send_ctx *sctx)
+{
+	int ret;
+
+	ret = iterate_dir_item(sctx, sctx->parent_root, sctx->right_path,
+			sctx->cmp_key, __process_deleted_xattr, sctx);
+
+	return ret;
+}
+
+struct find_xattr_ctx {
+	const char *name;
+	int name_len;
+	int found_idx;
+	char *found_data;
+	int found_data_len;
+};
+
+static int __find_xattr(int num, struct btrfs_key *di_key,
+			const char *name, int name_len,
+			const char *data, int data_len,
+			u8 type, void *vctx)
+{
+	struct find_xattr_ctx *ctx = vctx;
+
+	if (name_len == ctx->name_len &&
+	    strncmp(name, ctx->name, name_len) == 0) {
+		ctx->found_idx = num;
+		ctx->found_data_len = data_len;
+		ctx->found_data = kmalloc(data_len, GFP_NOFS);
+		if (!ctx->found_data)
+			return -ENOMEM;
+		memcpy(ctx->found_data, data, data_len);
+		return 1;
+	}
+	return 0;
+}
+
+static int find_xattr(struct send_ctx *sctx,
+		      struct btrfs_root *root,
+		      struct btrfs_path *path,
+		      struct btrfs_key *key,
+		      const char *name, int name_len,
+		      char **data, int *data_len)
+{
+	int ret;
+	struct find_xattr_ctx ctx;
+
+	ctx.name = name;
+	ctx.name_len = name_len;
+	ctx.found_idx = -1;
+	ctx.found_data = NULL;
+	ctx.found_data_len = 0;
+
+	ret = iterate_dir_item(sctx, root, path, key, __find_xattr, &ctx);
+	if (ret < 0)
+		return ret;
+
+	if (ctx.found_idx == -1)
+		return -ENOENT;
+	if (data) {
+		*data = ctx.found_data;
+		*data_len = ctx.found_data_len;
+	} else {
+		kfree(ctx.found_data);
+	}
+	return ctx.found_idx;
+}
+
+
+static int __process_changed_new_xattr(int num, struct btrfs_key *di_key,
+				       const char *name, int name_len,
+				       const char *data, int data_len,
+				       u8 type, void *ctx)
+{
+	int ret;
+	struct send_ctx *sctx = ctx;
+	char *found_data = NULL;
+	int found_data_len  = 0;
+	struct fs_path *p = NULL;
+
+	ret = find_xattr(sctx, sctx->parent_root, sctx->right_path,
+			sctx->cmp_key, name, name_len, &found_data,
+			&found_data_len);
+	if (ret == -ENOENT) {
+		ret = __process_new_xattr(num, di_key, name, name_len, data,
+				data_len, type, ctx);
+	} else if (ret >= 0) {
+		if (data_len != found_data_len ||
+		    memcmp(data, found_data, data_len)) {
+			ret = __process_new_xattr(num, di_key, name, name_len,
+					data, data_len, type, ctx);
+		} else {
+			ret = 0;
+		}
+	}
+
+	kfree(found_data);
+	fs_path_free(sctx, p);
+	return ret;
+}
+
+static int __process_changed_deleted_xattr(int num, struct btrfs_key *di_key,
+					   const char *name, int name_len,
+					   const char *data, int data_len,
+					   u8 type, void *ctx)
+{
+	int ret;
+	struct send_ctx *sctx = ctx;
+
+	ret = find_xattr(sctx, sctx->send_root, sctx->left_path, sctx->cmp_key,
+			name, name_len, NULL, NULL);
+	if (ret == -ENOENT)
+		ret = __process_deleted_xattr(num, di_key, name, name_len, data,
+				data_len, type, ctx);
+	else if (ret >= 0)
+		ret = 0;
+
+	return ret;
+}
+
+static int process_changed_xattr(struct send_ctx *sctx)
+{
+	int ret = 0;
+
+	ret = iterate_dir_item(sctx, sctx->send_root, sctx->left_path,
+			sctx->cmp_key, __process_changed_new_xattr, sctx);
+	if (ret < 0)
+		goto out;
+	ret = iterate_dir_item(sctx, sctx->parent_root, sctx->right_path,
+			sctx->cmp_key, __process_changed_deleted_xattr, sctx);
+
+out:
+	return ret;
+}
+
+static int process_all_new_xattrs(struct send_ctx *sctx)
+{
+	int ret;
+	struct btrfs_root *root;
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	struct btrfs_key found_key;
+	struct extent_buffer *eb;
+	int slot;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	root = sctx->send_root;
+
+	key.objectid = sctx->cmp_key->objectid;
+	key.type = BTRFS_XATTR_ITEM_KEY;
+	key.offset = 0;
+	while (1) {
+		ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
+		if (ret < 0)
+			goto out;
+		if (ret) {
+			ret = 0;
+			goto out;
+		}
+
+		eb = path->nodes[0];
+		slot = path->slots[0];
+		btrfs_item_key_to_cpu(eb, &found_key, slot);
+
+		if (found_key.objectid != key.objectid ||
+		    found_key.type != key.type) {
+			ret = 0;
+			goto out;
+		}
+
+		ret = iterate_dir_item(sctx, root, path, &found_key,
+				__process_new_xattr, sctx);
+		if (ret < 0)
+			goto out;
+
+		btrfs_release_path(path);
+		key.offset = found_key.offset + 1;
+	}
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+/*
+ * Read some bytes from the current inode/file and send a write command to
+ * user space.
+ */
+static int send_write(struct send_ctx *sctx, u64 offset, u32 len)
+{
+	int ret = 0;
+	struct fs_path *p;
+	loff_t pos = offset;
+	int readed;
+	mm_segment_t old_fs;
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	/*
+	 * vfs normally only accepts user space buffers for security reasons.
+	 * we only read from the file and also only provide the read_buf buffer
+	 * to vfs. As this buffer does not come from a user space call, it's
+	 * ok to temporary allow kernel space buffers.
+	 */
+	old_fs = get_fs();
+	set_fs(KERNEL_DS);
+
+verbose_printk("btrfs: send_write offset=%llu, len=%d\n", offset, len);
+
+	ret = open_cur_inode_file(sctx);
+	if (ret < 0)
+		goto out;
+
+	ret = vfs_read(sctx->cur_inode_filp, sctx->read_buf, len, &pos);
+	if (ret < 0)
+		goto out;
+	readed = ret;
+	if (!readed)
+		goto out;
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_WRITE);
+	if (ret < 0)
+		goto out;
+
+	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_FILE_OFFSET, offset);
+	TLV_PUT(sctx, BTRFS_SEND_A_DATA, sctx->read_buf, readed);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	fs_path_free(sctx, p);
+	set_fs(old_fs);
+	if (ret < 0)
+		return ret;
+	return readed;
+}
+
+/*
+ * Send a clone command to user space.
+ */
+static int send_clone(struct send_ctx *sctx,
+		      u64 offset, u32 len,
+		      struct clone_root *clone_root)
+{
+	int ret = 0;
+	struct btrfs_root *clone_root2 = clone_root->root;
+	struct fs_path *p;
+	u64 gen;
+
+verbose_printk("btrfs: send_clone offset=%llu, len=%d, clone_root=%llu, "
+	       "clone_inode=%llu, clone_offset=%llu\n", offset, len,
+		clone_root->root->objectid, clone_root->ino,
+		clone_root->offset);
+
+	p = fs_path_alloc(sctx);
+	if (!p)
+		return -ENOMEM;
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_CLONE);
+	if (ret < 0)
+		goto out;
+
+	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_FILE_OFFSET, offset);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_LEN, len);
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_PATH, p);
+
+	if (clone_root2 == sctx->send_root) {
+		ret = get_inode_info(sctx->send_root, clone_root->ino, NULL,
+				&gen, NULL, NULL, NULL);
+		if (ret < 0)
+			goto out;
+		ret = get_cur_path(sctx, clone_root->ino, gen, p);
+	} else {
+		ret = get_inode_path(sctx, clone_root2, clone_root->ino, p);
+	}
+	if (ret < 0)
+		goto out;
+
+	TLV_PUT_UUID(sctx, BTRFS_SEND_A_CLONE_UUID,
+			clone_root2->root_item.uuid);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_CTRANSID,
+			clone_root2->root_item.ctransid);
+	TLV_PUT_PATH(sctx, BTRFS_SEND_A_CLONE_PATH, p);
+	TLV_PUT_U64(sctx, BTRFS_SEND_A_CLONE_OFFSET,
+			clone_root->offset);
+
+	ret = send_cmd(sctx);
+
+tlv_put_failure:
+out:
+	fs_path_free(sctx, p);
+	return ret;
+}
+
+static int send_write_or_clone(struct send_ctx *sctx,
+			       struct btrfs_path *path,
+			       struct btrfs_key *key,
+			       struct clone_root *clone_root)
+{
+	int ret = 0;
+	struct btrfs_file_extent_item *ei;
+	u64 offset = key->offset;
+	u64 pos = 0;
+	u64 len;
+	u32 l;
+	u8 type;
+
+	ei = btrfs_item_ptr(path->nodes[0], path->slots[0],
+			struct btrfs_file_extent_item);
+	type = btrfs_file_extent_type(path->nodes[0], ei);
+	if (type == BTRFS_FILE_EXTENT_INLINE)
+		len = btrfs_file_extent_inline_len(path->nodes[0], ei);
+	else
+		len = btrfs_file_extent_num_bytes(path->nodes[0], ei);
+
+	if (offset + len > sctx->cur_inode_size)
+		len = sctx->cur_inode_size - offset;
+	if (len == 0) {
+		ret = 0;
+		goto out;
+	}
+
+	if (!clone_root) {
+		while (pos < len) {
+			l = len - pos;
+			if (l > BTRFS_SEND_READ_SIZE)
+				l = BTRFS_SEND_READ_SIZE;
+			ret = send_write(sctx, pos + offset, l);
+			if (ret < 0)
+				goto out;
+			if (!ret)
+				break;
+			pos += ret;
+		}
+		ret = 0;
+	} else {
+		ret = send_clone(sctx, offset, len, clone_root);
+	}
+
+out:
+	return ret;
+}
+
+static int is_extent_unchanged(struct send_ctx *sctx,
+			       struct btrfs_path *left_path,
+			       struct btrfs_key *ekey)
+{
+	int ret = 0;
+	struct btrfs_key key;
+	struct btrfs_path *path = NULL;
+	struct extent_buffer *eb;
+	int slot;
+	struct btrfs_key found_key;
+	struct btrfs_file_extent_item *ei;
+	u64 left_disknr;
+	u64 right_disknr;
+	u64 left_offset;
+	u64 right_offset;
+	u64 left_offset_fixed;
+	u64 left_len;
+	u64 right_len;
+	u8 left_type;
+	u8 right_type;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	eb = left_path->nodes[0];
+	slot = left_path->slots[0];
+
+	ei = btrfs_item_ptr(eb, slot, struct btrfs_file_extent_item);
+	left_type = btrfs_file_extent_type(eb, ei);
+	left_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
+	left_len = btrfs_file_extent_num_bytes(eb, ei);
+	left_offset = btrfs_file_extent_offset(eb, ei);
+
+	if (left_type != BTRFS_FILE_EXTENT_REG) {
+		ret = 0;
+		goto out;
+	}
+
+	/*
+	 * Following comments will refer to these graphics. L is the left
+	 * extents which we are checking at the moment. 1-8 are the right
+	 * extents that we iterate.
+	 *
+	 *       |-----L-----|
+	 * |-1-|-2a-|-3-|-4-|-5-|-6-|
+	 *
+	 *       |-----L-----|
+	 * |--1--|-2b-|...(same as above)
+	 *
+	 * Alternative situation. Happens on files where extents got split.
+	 *       |-----L-----|
+	 * |-----------7-----------|-6-|
+	 *
+	 * Alternative situation. Happens on files which got larger.
+	 *       |-----L-----|
+	 * |-8-|
+	 * Nothing follows after 8.
+	 */
+
+	key.objectid = ekey->objectid;
+	key.type = BTRFS_EXTENT_DATA_KEY;
+	key.offset = ekey->offset;
+	ret = btrfs_search_slot_for_read(sctx->parent_root, &key, path, 0, 0);
+	if (ret < 0)
+		goto out;
+	if (ret) {
+		ret = 0;
+		goto out;
+	}
+
+	/*
+	 * Handle special case where the right side has no extents at all.
+	 */
+	eb = path->nodes[0];
+	slot = path->slots[0];
+	btrfs_item_key_to_cpu(eb, &found_key, slot);
+	if (found_key.objectid != key.objectid ||
+	    found_key.type != key.type) {
+		ret = 0;
+		goto out;
+	}
+
+	/*
+	 * We're now on 2a, 2b or 7.
+	 */
+	key = found_key;
+	while (key.offset < ekey->offset + left_len) {
+		ei = btrfs_item_ptr(eb, slot, struct btrfs_file_extent_item);
+		right_type = btrfs_file_extent_type(eb, ei);
+		right_disknr = btrfs_file_extent_disk_bytenr(eb, ei);
+		right_len = btrfs_file_extent_num_bytes(eb, ei);
+		right_offset = btrfs_file_extent_offset(eb, ei);
+
+		if (right_type != BTRFS_FILE_EXTENT_REG) {
+			ret = 0;
+			goto out;
+		}
+
+		/*
+		 * Are we at extent 8? If yes, we know the extent is changed.
+		 * This may only happen on the first iteration.
+		 */
+		if (found_key.offset + right_len < ekey->offset) {
+			ret = 0;
+			goto out;
+		}
+
+		left_offset_fixed = left_offset;
+		if (key.offset < ekey->offset) {
+			/* Fix the right offset for 2a and 7. */
+			right_offset += ekey->offset - key.offset;
+		} else {
+			/* Fix the left offset for all behind 2a and 2b */
+			left_offset_fixed += key.offset - ekey->offset;
+		}
+
+		/*
+		 * Check if we have the same extent.
+		 */
+		if (left_disknr + left_offset_fixed !=
+				right_disknr + right_offset) {
+			ret = 0;
+			goto out;
+		}
+
+		/*
+		 * Go to the next extent.
+		 */
+		ret = btrfs_next_item(sctx->parent_root, path);
+		if (ret < 0)
+			goto out;
+		if (!ret) {
+			eb = path->nodes[0];
+			slot = path->slots[0];
+			btrfs_item_key_to_cpu(eb, &found_key, slot);
+		}
+		if (ret || found_key.objectid != key.objectid ||
+		    found_key.type != key.type) {
+			key.offset += right_len;
+			break;
+		} else {
+			if (found_key.offset != key.offset + right_len) {
+				/* Should really not happen */
+				ret = -EIO;
+				goto out;
+			}
+		}
+		key = found_key;
+	}
+
+	/*
+	 * We're now behind the left extent (treat as unchanged) or at the end
+	 * of the right side (treat as changed).
+	 */
+	if (key.offset >= ekey->offset + left_len)
+		ret = 1;
+	else
+		ret = 0;
+
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+static int process_extent(struct send_ctx *sctx,
+			  struct btrfs_path *path,
+			  struct btrfs_key *key)
+{
+	int ret = 0;
+	struct clone_root *found_clone = NULL;
+
+	if (S_ISLNK(sctx->cur_inode_mode))
+		return 0;
+
+	if (sctx->parent_root && !sctx->cur_inode_new) {
+		ret = is_extent_unchanged(sctx, path, key);
+		if (ret < 0)
+			goto out;
+		if (ret) {
+			ret = 0;
+			goto out;
+		}
+	}
+
+	ret = find_extent_clone(sctx, path, key->objectid, key->offset,
+			sctx->cur_inode_size, &found_clone);
+	if (ret != -ENOENT && ret < 0)
+		goto out;
+
+	ret = send_write_or_clone(sctx, path, key, found_clone);
+
+out:
+	return ret;
+}
+
+static int process_all_extents(struct send_ctx *sctx)
+{
+	int ret;
+	struct btrfs_root *root;
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	struct btrfs_key found_key;
+	struct extent_buffer *eb;
+	int slot;
+
+	root = sctx->send_root;
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	key.objectid = sctx->cmp_key->objectid;
+	key.type = BTRFS_EXTENT_DATA_KEY;
+	key.offset = 0;
+	while (1) {
+		ret = btrfs_search_slot_for_read(root, &key, path, 1, 0);
+		if (ret < 0)
+			goto out;
+		if (ret) {
+			ret = 0;
+			goto out;
+		}
+
+		eb = path->nodes[0];
+		slot = path->slots[0];
+		btrfs_item_key_to_cpu(eb, &found_key, slot);
+
+		if (found_key.objectid != key.objectid ||
+		    found_key.type != key.type) {
+			ret = 0;
+			goto out;
+		}
+
+		ret = process_extent(sctx, path, &found_key);
+		if (ret < 0)
+			goto out;
+
+		btrfs_release_path(path);
+		key.offset = found_key.offset + 1;
+	}
+
+out:
+	btrfs_free_path(path);
+	return ret;
+}
+
+static int process_recorded_refs_if_needed(struct send_ctx *sctx, int at_end)
+{
+	int ret = 0;
+
+	if (sctx->cur_ino == 0)
+		goto out;
+	if (!at_end && sctx->cur_ino == sctx->cmp_key->objectid &&
+	    sctx->cmp_key->type <= BTRFS_INODE_REF_KEY)
+		goto out;
+	if (list_empty(&sctx->new_refs) && list_empty(&sctx->deleted_refs))
+		goto out;
+
+	ret = process_recorded_refs(sctx);
+
+out:
+	return ret;
+}
+
+static int finish_inode_if_needed(struct send_ctx *sctx, int at_end)
+{
+	int ret = 0;
+	u64 left_mode;
+	u64 left_uid;
+	u64 left_gid;
+	u64 right_mode;
+	u64 right_uid;
+	u64 right_gid;
+	int need_chmod = 0;
+	int need_chown = 0;
+
+	ret = process_recorded_refs_if_needed(sctx, at_end);
+	if (ret < 0)
+		goto out;
+
+	if (sctx->cur_ino == 0 || sctx->cur_inode_deleted)
+		goto out;
+	if (!at_end && sctx->cmp_key->objectid == sctx->cur_ino)
+		goto out;
+
+	ret = get_inode_info(sctx->send_root, sctx->cur_ino, NULL, NULL,
+			&left_mode, &left_uid, &left_gid);
+	if (ret < 0)
+		goto out;
+
+	if (!S_ISLNK(sctx->cur_inode_mode)) {
+		if (!sctx->parent_root || sctx->cur_inode_new) {
+			need_chmod = 1;
+			need_chown = 1;
+		} else {
+			ret = get_inode_info(sctx->parent_root, sctx->cur_ino,
+					NULL, NULL, &right_mode, &right_uid,
+					&right_gid);
+			if (ret < 0)
+				goto out;
+
+			if (left_uid != right_uid || left_gid != right_gid)
+				need_chown = 1;
+			if (left_mode != right_mode)
+				need_chmod = 1;
+		}
+	}
+
+	if (S_ISREG(sctx->cur_inode_mode)) {
+		ret = send_truncate(sctx, sctx->cur_ino, sctx->cur_inode_gen,
+				sctx->cur_inode_size);
+		if (ret < 0)
+			goto out;
+	}
+
+	if (need_chown) {
+		ret = send_chown(sctx, sctx->cur_ino, sctx->cur_inode_gen,
+				left_uid, left_gid);
+		if (ret < 0)
+			goto out;
+	}
+	if (need_chmod) {
+		ret = send_chmod(sctx, sctx->cur_ino, sctx->cur_inode_gen,
+				left_mode);
+		if (ret < 0)
+			goto out;
+	}
+
+	/*
+	 * Need to send that every time, no matter if it actually changed
+	 * between the two trees as we have done changes to the inode before.
+	 */
+	ret = send_utimes(sctx, sctx->cur_ino, sctx->cur_inode_gen);
+	if (ret < 0)
+		goto out;
+
+out:
+	return ret;
+}
+
+static int changed_inode(struct send_ctx *sctx,
+			 enum btrfs_compare_tree_result result)
+{
+	int ret = 0;
+	struct btrfs_key *key = sctx->cmp_key;
+	struct btrfs_inode_item *left_ii = NULL;
+	struct btrfs_inode_item *right_ii = NULL;
+	u64 left_gen = 0;
+	u64 right_gen = 0;
+
+	ret = close_cur_inode_file(sctx);
+	if (ret < 0)
+		goto out;
+
+	sctx->cur_ino = key->objectid;
+	sctx->cur_inode_new_gen = 0;
+	sctx->cur_inode_first_ref_orphan = 0;
+	sctx->send_progress = sctx->cur_ino;
+
+	if (result == BTRFS_COMPARE_TREE_NEW ||
+	    result == BTRFS_COMPARE_TREE_CHANGED) {
+		left_ii = btrfs_item_ptr(sctx->left_path->nodes[0],
+				sctx->left_path->slots[0],
+				struct btrfs_inode_item);
+		left_gen = btrfs_inode_generation(sctx->left_path->nodes[0],
+				left_ii);
+	} else {
+		right_ii = btrfs_item_ptr(sctx->right_path->nodes[0],
+				sctx->right_path->slots[0],
+				struct btrfs_inode_item);
+		right_gen = btrfs_inode_generation(sctx->right_path->nodes[0],
+				right_ii);
+	}
+	if (result == BTRFS_COMPARE_TREE_CHANGED) {
+		right_ii = btrfs_item_ptr(sctx->right_path->nodes[0],
+				sctx->right_path->slots[0],
+				struct btrfs_inode_item);
+
+		right_gen = btrfs_inode_generation(sctx->right_path->nodes[0],
+				right_ii);
+		if (left_gen != right_gen)
+			sctx->cur_inode_new_gen = 1;
+	}
+
+	if (result == BTRFS_COMPARE_TREE_NEW) {
+		sctx->cur_inode_gen = left_gen;
+		sctx->cur_inode_new = 1;
+		sctx->cur_inode_deleted = 0;
+		sctx->cur_inode_size = btrfs_inode_size(
+				sctx->left_path->nodes[0], left_ii);
+		sctx->cur_inode_mode = btrfs_inode_mode(
+				sctx->left_path->nodes[0], left_ii);
+		if (sctx->cur_ino != BTRFS_FIRST_FREE_OBJECTID)
+			ret = send_create_inode(sctx, sctx->left_path,
+					sctx->cmp_key);
+	} else if (result == BTRFS_COMPARE_TREE_DELETED) {
+		sctx->cur_inode_gen = right_gen;
+		sctx->cur_inode_new = 0;
+		sctx->cur_inode_deleted = 1;
+		sctx->cur_inode_size = btrfs_inode_size(
+				sctx->right_path->nodes[0], right_ii);
+		sctx->cur_inode_mode = btrfs_inode_mode(
+				sctx->right_path->nodes[0], right_ii);
+	} else if (result == BTRFS_COMPARE_TREE_CHANGED) {
+		if (sctx->cur_inode_new_gen) {
+			sctx->cur_inode_gen = right_gen;
+			sctx->cur_inode_new = 0;
+			sctx->cur_inode_deleted = 1;
+			sctx->cur_inode_size = btrfs_inode_size(
+					sctx->right_path->nodes[0], right_ii);
+			sctx->cur_inode_mode = btrfs_inode_mode(
+					sctx->right_path->nodes[0], right_ii);
+			ret = process_all_refs(sctx,
+					BTRFS_COMPARE_TREE_DELETED);
+			if (ret < 0)
+				goto out;
+
+			sctx->cur_inode_gen = left_gen;
+			sctx->cur_inode_new = 1;
+			sctx->cur_inode_deleted = 0;
+			sctx->cur_inode_size = btrfs_inode_size(
+					sctx->left_path->nodes[0], left_ii);
+			sctx->cur_inode_mode = btrfs_inode_mode(
+					sctx->left_path->nodes[0], left_ii);
+			ret = send_create_inode(sctx, sctx->left_path,
+					sctx->cmp_key);
+			if (ret < 0)
+				goto out;
+
+			ret = process_all_refs(sctx, BTRFS_COMPARE_TREE_NEW);
+			if (ret < 0)
+				goto out;
+			ret = process_all_extents(sctx);
+			if (ret < 0)
+				goto out;
+			ret = process_all_new_xattrs(sctx);
+			if (ret < 0)
+				goto out;
+		} else {
+			sctx->cur_inode_gen = left_gen;
+			sctx->cur_inode_new = 0;
+			sctx->cur_inode_new_gen = 0;
+			sctx->cur_inode_deleted = 0;
+			sctx->cur_inode_size = btrfs_inode_size(
+					sctx->left_path->nodes[0], left_ii);
+			sctx->cur_inode_mode = btrfs_inode_mode(
+					sctx->left_path->nodes[0], left_ii);
+		}
+	}
+
+out:
+	return ret;
+}
+
+static int changed_ref(struct send_ctx *sctx,
+		       enum btrfs_compare_tree_result result)
+{
+	int ret = 0;
+
+	BUG_ON(sctx->cur_ino != sctx->cmp_key->objectid);
+
+	if (!sctx->cur_inode_new_gen &&
+	    sctx->cur_ino != BTRFS_FIRST_FREE_OBJECTID) {
+		if (result == BTRFS_COMPARE_TREE_NEW)
+			ret = record_new_ref(sctx);
+		else if (result == BTRFS_COMPARE_TREE_DELETED)
+			ret = record_deleted_ref(sctx);
+		else if (result == BTRFS_COMPARE_TREE_CHANGED)
+			ret = record_changed_ref(sctx);
+	}
+
+	return ret;
+}
+
+static int changed_xattr(struct send_ctx *sctx,
+			 enum btrfs_compare_tree_result result)
+{
+	int ret = 0;
+
+	BUG_ON(sctx->cur_ino != sctx->cmp_key->objectid);
+
+	if (!sctx->cur_inode_new_gen && !sctx->cur_inode_deleted) {
+		if (result == BTRFS_COMPARE_TREE_NEW)
+			ret = process_new_xattr(sctx);
+		else if (result == BTRFS_COMPARE_TREE_DELETED)
+			ret = process_deleted_xattr(sctx);
+		else if (result == BTRFS_COMPARE_TREE_CHANGED)
+			ret = process_changed_xattr(sctx);
+	}
+
+	return ret;
+}
+
+static int changed_extent(struct send_ctx *sctx,
+			  enum btrfs_compare_tree_result result)
+{
+	int ret = 0;
+
+	BUG_ON(sctx->cur_ino != sctx->cmp_key->objectid);
+
+	if (!sctx->cur_inode_new_gen && !sctx->cur_inode_deleted) {
+		if (result != BTRFS_COMPARE_TREE_DELETED)
+			ret = process_extent(sctx, sctx->left_path,
+					sctx->cmp_key);
+	}
+
+	return ret;
+}
+
+
+static int changed_cb(struct btrfs_root *left_root,
+		      struct btrfs_root *right_root,
+		      struct btrfs_path *left_path,
+		      struct btrfs_path *right_path,
+		      struct btrfs_key *key,
+		      enum btrfs_compare_tree_result result,
+		      void *ctx)
+{
+	int ret = 0;
+	struct send_ctx *sctx = ctx;
+
+	sctx->left_path = left_path;
+	sctx->right_path = right_path;
+	sctx->cmp_key = key;
+
+	ret = finish_inode_if_needed(sctx, 0);
+	if (ret < 0)
+		goto out;
+
+	if (key->type == BTRFS_INODE_ITEM_KEY)
+		ret = changed_inode(sctx, result);
+	else if (key->type == BTRFS_INODE_REF_KEY)
+		ret = changed_ref(sctx, result);
+	else if (key->type == BTRFS_XATTR_ITEM_KEY)
+		ret = changed_xattr(sctx, result);
+	else if (key->type == BTRFS_EXTENT_DATA_KEY)
+		ret = changed_extent(sctx, result);
+
+out:
+	return ret;
+}
+
+static int full_send_tree(struct send_ctx *sctx)
+{
+	int ret;
+	struct btrfs_trans_handle *trans = NULL;
+	struct btrfs_root *send_root = sctx->send_root;
+	struct btrfs_key key;
+	struct btrfs_key found_key;
+	struct btrfs_path *path;
+	struct extent_buffer *eb;
+	int slot;
+	u64 start_ctransid;
+	u64 ctransid;
+
+	path = alloc_path_for_send();
+	if (!path)
+		return -ENOMEM;
+
+	spin_lock(&send_root->root_times_lock);
+	start_ctransid = btrfs_root_ctransid(&send_root->root_item);
+	spin_unlock(&send_root->root_times_lock);
+
+	key.objectid = BTRFS_FIRST_FREE_OBJECTID;
+	key.type = BTRFS_INODE_ITEM_KEY;
+	key.offset = 0;
+
+join_trans:
+	/*
+	 * We need to make sure the transaction does not get committed
+	 * while we do anything on commit roots. Join a transaction to prevent
+	 * this.
+	 */
+	trans = btrfs_join_transaction(send_root);
+	if (IS_ERR(trans)) {
+		ret = PTR_ERR(trans);
+		trans = NULL;
+		goto out;
+	}
+
+	/*
+	 * Make sure the tree has not changed
+	 */
+	spin_lock(&send_root->root_times_lock);
+	ctransid = btrfs_root_ctransid(&send_root->root_item);
+	spin_unlock(&send_root->root_times_lock);
+
+	if (ctransid != start_ctransid) {
+		WARN(1, KERN_WARNING "btrfs: the root that you're trying to "
+				     "send was modified in between. This is "
+				     "probably a bug.\n");
+		ret = -EIO;
+		goto out;
+	}
+
+	ret = btrfs_search_slot_for_read(send_root, &key, path, 1, 0);
+	if (ret < 0)
+		goto out;
+	if (ret)
+		goto out_finish;
+
+	while (1) {
+		/*
+		 * When someone want to commit while we iterate, end the
+		 * joined transaction and rejoin.
+		 */
+		if (btrfs_should_end_transaction(trans, send_root)) {
+			ret = btrfs_end_transaction(trans, send_root);
+			trans = NULL;
+			if (ret < 0)
+				goto out;
+			btrfs_release_path(path);
+			goto join_trans;
+		}
+
+		eb = path->nodes[0];
+		slot = path->slots[0];
+		btrfs_item_key_to_cpu(eb, &found_key, slot);
+
+		ret = changed_cb(send_root, NULL, path, NULL,
+				&found_key, BTRFS_COMPARE_TREE_NEW, sctx);
+		if (ret < 0)
+			goto out;
+
+		key.objectid = found_key.objectid;
+		key.type = found_key.type;
+		key.offset = found_key.offset + 1;
+
+		ret = btrfs_next_item(send_root, path);
+		if (ret < 0)
+			goto out;
+		if (ret) {
+			ret  = 0;
+			break;
+		}
+	}
+
+out_finish:
+	ret = finish_inode_if_needed(sctx, 1);
+
+out:
+	btrfs_free_path(path);
+	if (trans) {
+		if (!ret)
+			ret = btrfs_end_transaction(trans, send_root);
+		else
+			btrfs_end_transaction(trans, send_root);
+	}
+	return ret;
+}
+
+static int send_subvol(struct send_ctx *sctx)
+{
+	int ret;
+
+	ret = send_header(sctx);
+	if (ret < 0)
+		goto out;
+
+	ret = send_subvol_begin(sctx);
+	if (ret < 0)
+		goto out;
+
+	if (sctx->parent_root) {
+		ret = btrfs_compare_trees(sctx->send_root, sctx->parent_root,
+				changed_cb, sctx);
+		if (ret < 0)
+			goto out;
+		ret = finish_inode_if_needed(sctx, 1);
+		if (ret < 0)
+			goto out;
+	} else {
+		ret = full_send_tree(sctx);
+		if (ret < 0)
+			goto out;
+	}
+
+out:
+	if (!ret)
+		ret = close_cur_inode_file(sctx);
+	else
+		close_cur_inode_file(sctx);
+
+	free_recorded_refs(sctx);
+	return ret;
+}
+
+long btrfs_ioctl_send(struct file *mnt_file, void __user *arg_)
+{
+	int ret = 0;
+	struct btrfs_root *send_root;
+	struct btrfs_root *clone_root;
+	struct btrfs_fs_info *fs_info;
+	struct btrfs_ioctl_send_args *arg = NULL;
+	struct btrfs_key key;
+	struct file *filp = NULL;
+	struct send_ctx *sctx = NULL;
+	u32 i;
+	u64 *clone_sources_tmp = NULL;
+
+	if (!capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	send_root = BTRFS_I(fdentry(mnt_file)->d_inode)->root;
+	fs_info = send_root->fs_info;
+
+	arg = memdup_user(arg_, sizeof(*arg));
+	if (IS_ERR(arg)) {
+		ret = PTR_ERR(arg);
+		arg = NULL;
+		goto out;
+	}
+
+	if (!access_ok(VERIFY_READ, arg->clone_sources,
+			sizeof(*arg->clone_sources *
+			arg->clone_sources_count))) {
+		ret = -EFAULT;
+		goto out;
+	}
+
+	sctx = kzalloc(sizeof(struct send_ctx), GFP_NOFS);
+	if (!sctx) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	INIT_LIST_HEAD(&sctx->new_refs);
+	INIT_LIST_HEAD(&sctx->deleted_refs);
+	INIT_RADIX_TREE(&sctx->name_cache, GFP_NOFS);
+	INIT_LIST_HEAD(&sctx->name_cache_list);
+
+	sctx->send_filp = fget(arg->send_fd);
+	if (IS_ERR(sctx->send_filp)) {
+		ret = PTR_ERR(sctx->send_filp);
+		goto out;
+	}
+
+	sctx->mnt = mnt_file->f_path.mnt;
+
+	sctx->send_root = send_root;
+	sctx->clone_roots_cnt = arg->clone_sources_count;
+
+	sctx->send_max_size = BTRFS_SEND_BUF_SIZE;
+	sctx->send_buf = vmalloc(sctx->send_max_size);
+	if (!sctx->send_buf) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	sctx->read_buf = vmalloc(BTRFS_SEND_READ_SIZE);
+	if (!sctx->read_buf) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	sctx->clone_roots = vzalloc(sizeof(struct clone_root) *
+			(arg->clone_sources_count + 1));
+	if (!sctx->clone_roots) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	if (arg->clone_sources_count) {
+		clone_sources_tmp = vmalloc(arg->clone_sources_count *
+				sizeof(*arg->clone_sources));
+		if (!clone_sources_tmp) {
+			ret = -ENOMEM;
+			goto out;
+		}
+
+		ret = copy_from_user(clone_sources_tmp, arg->clone_sources,
+				arg->clone_sources_count *
+				sizeof(*arg->clone_sources));
+		if (ret) {
+			ret = -EFAULT;
+			goto out;
+		}
+
+		for (i = 0; i < arg->clone_sources_count; i++) {
+			key.objectid = clone_sources_tmp[i];
+			key.type = BTRFS_ROOT_ITEM_KEY;
+			key.offset = (u64)-1;
+			clone_root = btrfs_read_fs_root_no_name(fs_info, &key);
+			if (!clone_root) {
+				ret = -EINVAL;
+				goto out;
+			}
+			if (IS_ERR(clone_root)) {
+				ret = PTR_ERR(clone_root);
+				goto out;
+			}
+			sctx->clone_roots[i].root = clone_root;
+		}
+		vfree(clone_sources_tmp);
+		clone_sources_tmp = NULL;
+	}
+
+	if (arg->parent_root) {
+		key.objectid = arg->parent_root;
+		key.type = BTRFS_ROOT_ITEM_KEY;
+		key.offset = (u64)-1;
+		sctx->parent_root = btrfs_read_fs_root_no_name(fs_info, &key);
+		if (!sctx->parent_root) {
+			ret = -EINVAL;
+			goto out;
+		}
+	}
+
+	/*
+	 * Clones from send_root are allowed, but only if the clone source
+	 * is behind the current send position. This is checked while searching
+	 * for possible clone sources.
+	 */
+	sctx->clone_roots[sctx->clone_roots_cnt++].root = sctx->send_root;
+
+	/* We do a bsearch later */
+	sort(sctx->clone_roots, sctx->clone_roots_cnt,
+			sizeof(*sctx->clone_roots), __clone_root_cmp_sort,
+			NULL);
+
+	ret = send_subvol(sctx);
+	if (ret < 0)
+		goto out;
+
+	ret = begin_cmd(sctx, BTRFS_SEND_C_END);
+	if (ret < 0)
+		goto out;
+	ret = send_cmd(sctx);
+	if (ret < 0)
+		goto out;
+
+out:
+	if (filp)
+		fput(filp);
+	kfree(arg);
+	vfree(clone_sources_tmp);
+
+	if (sctx) {
+		if (sctx->send_filp)
+			fput(sctx->send_filp);
+
+		vfree(sctx->clone_roots);
+		vfree(sctx->send_buf);
+		vfree(sctx->read_buf);
+
+		name_cache_free(sctx);
+
+		kfree(sctx);
+	}
+
+	return ret;
+}
