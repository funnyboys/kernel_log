commit 918cdf442326e5eaa808258e403c6a6e2dc23113
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 18 12:15:18 2020 +0100

    btrfs: remove useless 'fail_unlock' label from btrfs_csum_file_blocks()
    
    The label 'fail_unlock' is pointless, all it does is to jump to the label
    'out', so just remove it.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index c3f3c25dda38..706a3128e192 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -871,7 +871,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	}
 	ret = PTR_ERR(item);
 	if (ret != -EFBIG && ret != -ENOENT)
-		goto fail_unlock;
+		goto out;
 
 	if (ret == -EFBIG) {
 		u32 item_size;
@@ -929,7 +929,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	ret = btrfs_search_slot(trans, root, &file_key, path,
 				csum_size, 1);
 	if (ret < 0)
-		goto fail_unlock;
+		goto out;
 
 	if (ret > 0) {
 		if (path->slots[0] == 0)
@@ -996,9 +996,9 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 				      ins_size);
 	path->leave_spinning = 0;
 	if (ret < 0)
-		goto fail_unlock;
+		goto out;
 	if (WARN_ON(ret != 0))
-		goto fail_unlock;
+		goto out;
 	leaf = path->nodes[0];
 csum:
 	item = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
@@ -1028,9 +1028,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 out:
 	btrfs_free_path(path);
 	return ret;
-
-fail_unlock:
-	goto out;
 }
 
 void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,

commit 7e4a3f7ed5d54926ec671bbb13e171cfe179cc50
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 18 12:15:09 2020 +0100

    btrfs: do not ignore error from btrfs_next_leaf() when inserting checksums
    
    We are currently treating any non-zero return value from btrfs_next_leaf()
    the same way, by going to the code that inserts a new checksum item in the
    tree. However if btrfs_next_leaf() returns an error (a value < 0), we
    should just stop and return the error, and not behave as if nothing has
    happened, since in that case we do not have a way to know if there is a
    next leaf or we are currently at the last leaf already.
    
    So fix that by returning the error from btrfs_next_leaf().
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 687529c61d13..c3f3c25dda38 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -889,10 +889,12 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		nritems = btrfs_header_nritems(path->nodes[0]);
 		if (!nritems || (path->slots[0] >= nritems - 1)) {
 			ret = btrfs_next_leaf(root, path);
-			if (ret == 1)
+			if (ret < 0) {
+				goto out;
+			} else if (ret > 0) {
 				found_next = 1;
-			if (ret != 0)
 				goto insert;
+			}
 			slot = path->slots[0];
 		}
 		btrfs_item_key_to_cpu(path->nodes[0], &found_key, slot);

commit cc14600c1516f6c679cab1c503a34841d58050a6
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 18 12:15:00 2020 +0100

    btrfs: make checksum item extension more efficient
    
    When we want to add checksums into the checksums tree, or a log tree, we
    try whenever possible to extend existing checksum items, as this helps
    reduce amount of metadata space used, since adding a new item uses extra
    metadata space for a btrfs_item structure (25 bytes).
    
    However we have two inefficiencies in the current approach:
    
    1) After finding a checksum item that covers a range with an end offset
       that matches the start offset of the checksum range we want to insert,
       we release the search path populated by btrfs_lookup_csum() and then
       do another COW search on tree with the goal of getting additional
       space for at least one checksum. Doing this path release and then
       searching again is a waste of time because very often the leaf already
       has enough free space for at least one more checksum;
    
    2) After the COW search that guarantees we get free space in the leaf for
       at least one more checksum, we end up not doing the extension of the
       previous checksum item, and fallback to insertion of a new checksum
       item, if the leaf doesn't have an amount of free space larger then the
       space required for 2 checksums plus one btrfs_item structure - this is
       pointless for two reasons:
    
       a) We want to extend an existing item, so we don't need to account for
          a btrfs_item structure (25 bytes);
    
       b) We made the COW search with an insertion size for 1 single checksum,
          so if the leaf ends up with a free space amount smaller then 2
          checksums plus the size of a btrfs_item structure, we give up on the
          extension of the existing item and jump to the 'insert' label, where
          we end up releasing the path and then doing yet another search to
          insert a new checksum item for a single checksum.
    
    Fix these inefficiencies by doing the following:
    
    - For case 1), before releasing the path just check if the leaf already
      has enough space for at least 1 more checksum, and if it does, jump
      directly to the item extension code, with releasing our current path,
      which was already COWed by btrfs_lookup_csum();
    
    - For case 2), fix the logic so that for item extension we require only
      that the leaf has enough free space for 1 checksum, and not a minimum
      of 2 checksums plus space for a btrfs_item structure.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 8cdd06ea0e67..687529c61d13 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -907,9 +907,22 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	}
 
 	/*
-	 * at this point, we know the tree has an item, but it isn't big
-	 * enough yet to put our csum in.  Grow it
+	 * At this point, we know the tree has a checksum item that ends at an
+	 * offset matching the start of the checksum range we want to insert.
+	 * We try to extend that item as much as possible and then add as many
+	 * checksums to it as they fit.
+	 *
+	 * First check if the leaf has enough free space for at least one
+	 * checksum. If it has go directly to the item extension code, otherwise
+	 * release the path and do a search for insertion before the extension.
 	 */
+	if (btrfs_leaf_free_space(leaf) >= csum_size) {
+		btrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);
+		csum_offset = (bytenr - found_key.offset) >>
+			fs_info->sb->s_blocksize_bits;
+		goto extend_csum;
+	}
+
 	btrfs_release_path(path);
 	ret = btrfs_search_slot(trans, root, &file_key, path,
 				csum_size, 1);
@@ -933,19 +946,13 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		goto insert;
 	}
 
+extend_csum:
 	if (csum_offset == btrfs_item_size_nr(leaf, path->slots[0]) /
 	    csum_size) {
 		int extend_nr;
 		u64 tmp;
 		u32 diff;
-		u32 free_space;
-
-		if (btrfs_leaf_free_space(leaf) <
-				 sizeof(struct btrfs_item) + csum_size * 2)
-			goto insert;
 
-		free_space = btrfs_leaf_free_space(leaf) -
-					 sizeof(struct btrfs_item) - csum_size;
 		tmp = sums->len - total_bytes;
 		tmp >>= fs_info->sb->s_blocksize_bits;
 		WARN_ON(tmp < 1);
@@ -956,7 +963,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   MAX_CSUM_ITEMS(fs_info, csum_size) * csum_size);
 
 		diff = diff - btrfs_item_size_nr(leaf, path->slots[0]);
-		diff = min(free_space, diff);
+		diff = min_t(u32, btrfs_leaf_free_space(leaf), diff);
 		diff /= csum_size;
 		diff *= csum_size;
 

commit fd08001f17c7f0a5b19bf4026bbaace19d8fbdb6
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Apr 30 23:51:59 2020 -0700

    btrfs: use crypto_shash_digest() instead of open coding
    
    Use crypto_shash_digest() instead of crypto_shash_init() +
    crypto_shash_update() + crypto_shash_final().  This is more efficient.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 22cbb4da6d42..8cdd06ea0e67 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -601,13 +601,12 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 				index = 0;
 			}
 
-			crypto_shash_init(shash);
 			data = kmap_atomic(bvec.bv_page);
-			crypto_shash_update(shash, data + bvec.bv_offset
+			crypto_shash_digest(shash, data + bvec.bv_offset
 					    + (i * fs_info->sectorsize),
-					    fs_info->sectorsize);
+					    fs_info->sectorsize,
+					    sums->sums + index);
 			kunmap_atomic(data);
-			crypto_shash_final(shash, (char *)(sums->sums + index));
 			index += csum_size;
 			offset += fs_info->sectorsize;
 			this_sum_bytes += fs_info->sectorsize;

commit fb30f4707d421add0f4bf9a08bb228daac273b9f
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Apr 16 14:46:16 2020 -0700

    btrfs: clarify btrfs_lookup_bio_sums documentation
    
    Fix a couple of issues in the btrfs_lookup_bio_sums documentation:
    
    * The bio doesn't need to be a btrfs_io_bio if dst was provided. Move
      the declaration in the code to make that clear, too.
    * dst must be large enough to hold nblocks * csum_size, not just
      csum_size.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b618ad5339ba..22cbb4da6d42 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -242,11 +242,13 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 /**
  * btrfs_lookup_bio_sums - Look up checksums for a bio.
  * @inode: inode that the bio is for.
- * @bio: bio embedded in btrfs_io_bio.
+ * @bio: bio to look up.
  * @offset: Unless (u64)-1, look up checksums for this offset in the file.
  *          If (u64)-1, use the page offsets from the bio instead.
- * @dst: Buffer of size btrfs_super_csum_size() used to return checksum. If
- *       NULL, the checksum is returned in btrfs_io_bio(bio)->csum instead.
+ * @dst: Buffer of size nblocks * btrfs_super_csum_size() used to return
+ *       checksum (nblocks = bio->bi_iter.bi_size / fs_info->sectorsize). If
+ *       NULL, the checksum buffer is allocated and returned in
+ *       btrfs_io_bio(bio)->csum instead.
  *
  * Return: BLK_STS_RESOURCE if allocating memory fails, BLK_STS_OK otherwise.
  */
@@ -256,7 +258,6 @@ blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	struct bio_vec bvec;
 	struct bvec_iter iter;
-	struct btrfs_io_bio *btrfs_bio = btrfs_io_bio(bio);
 	struct btrfs_csum_item *item = NULL;
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
 	struct btrfs_path *path;
@@ -277,6 +278,8 @@ blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 
 	nblocks = bio->bi_iter.bi_size >> inode->i_sb->s_blocksize_bits;
 	if (!dst) {
+		struct btrfs_io_bio *btrfs_bio = btrfs_io_bio(bio);
+
 		if (nblocks * csum_size > BTRFS_BIO_INLINE_CSUM_SIZE) {
 			btrfs_bio->csum = kmalloc_array(nblocks, csum_size,
 							GFP_NOFS);

commit a5eeb3d17b979f7afe3ac68fe049ce8b0a039b03
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Mar 9 12:41:06 2020 +0000

    btrfs: add helper to get the end offset of a file extent item
    
    Getting the end offset for a file extent item requires a bit of code since
    the extent can be either inline or regular/prealloc. There are some places
    all over the code base that open code this logic and in another patch
    later in this series it will be needed again. Therefore encapsulate this
    logic in a helper function and use it.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 6c849e8fd5a1..b618ad5339ba 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -1040,18 +1040,7 @@ void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 
 	btrfs_item_key_to_cpu(leaf, &key, slot);
 	extent_start = key.offset;
-
-	if (type == BTRFS_FILE_EXTENT_REG ||
-	    type == BTRFS_FILE_EXTENT_PREALLOC) {
-		extent_end = extent_start +
-			btrfs_file_extent_num_bytes(leaf, fi);
-	} else if (type == BTRFS_FILE_EXTENT_INLINE) {
-		size_t size;
-		size = btrfs_file_extent_ram_bytes(leaf, fi);
-		extent_end = ALIGN(extent_start + size,
-				   fs_info->sectorsize);
-	}
-
+	extent_end = btrfs_file_extent_end(path);
 	em->ram_bytes = btrfs_file_extent_ram_bytes(leaf, fi);
 	if (type == BTRFS_FILE_EXTENT_REG ||
 	    type == BTRFS_FILE_EXTENT_PREALLOC) {
@@ -1098,3 +1087,30 @@ void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 			  root->root_key.objectid);
 	}
 }
+
+/*
+ * Returns the end offset (non inclusive) of the file extent item the given path
+ * points to. If it points to an inline extent, the returned offset is rounded
+ * up to the sector size.
+ */
+u64 btrfs_file_extent_end(const struct btrfs_path *path)
+{
+	const struct extent_buffer *leaf = path->nodes[0];
+	const int slot = path->slots[0];
+	struct btrfs_file_extent_item *fi;
+	struct btrfs_key key;
+	u64 end;
+
+	btrfs_item_key_to_cpu(leaf, &key, slot);
+	ASSERT(key.type == BTRFS_EXTENT_DATA_KEY);
+	fi = btrfs_item_ptr(leaf, slot, struct btrfs_file_extent_item);
+
+	if (btrfs_file_extent_type(leaf, fi) == BTRFS_FILE_EXTENT_INLINE) {
+		end = btrfs_file_extent_ram_bytes(leaf, fi);
+		end = ALIGN(key.offset + end, leaf->fs_info->sectorsize);
+	} else {
+		end = key.offset + btrfs_file_extent_num_bytes(leaf, fi);
+	}
+
+	return end;
+}

commit 41a2ee75aab0290a5899677437736ec715dcd1b6
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 17 09:02:21 2020 -0500

    btrfs: introduce per-inode file extent tree
    
    In order to keep track of where we have file extents on disk, and thus
    where it is safe to adjust the i_size to, we need to have a tree in
    place to keep track of the contiguous areas we have file extents for.
    
    Add helpers to use this tree, as it's not required for NO_HOLES file
    systems.  We will use this by setting DIRTY for areas we know we have
    file extent item's set, and clearing it when we remove file extent items
    for truncation.
    
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index c2f365662d55..6c849e8fd5a1 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -23,6 +23,97 @@
 #define MAX_CSUM_ITEMS(r, size) (min_t(u32, __MAX_CSUM_ITEMS(r, size), \
 				       PAGE_SIZE))
 
+/**
+ * @inode - the inode we want to update the disk_i_size for
+ * @new_i_size - the i_size we want to set to, 0 if we use i_size
+ *
+ * With NO_HOLES set this simply sets the disk_is_size to whatever i_size_read()
+ * returns as it is perfectly fine with a file that has holes without hole file
+ * extent items.
+ *
+ * However without NO_HOLES we need to only return the area that is contiguous
+ * from the 0 offset of the file.  Otherwise we could end up adjust i_size up
+ * to an extent that has a gap in between.
+ *
+ * Finally new_i_size should only be set in the case of truncate where we're not
+ * ready to use i_size_read() as the limiter yet.
+ */
+void btrfs_inode_safe_disk_i_size_write(struct inode *inode, u64 new_i_size)
+{
+	struct btrfs_fs_info *fs_info = BTRFS_I(inode)->root->fs_info;
+	u64 start, end, i_size;
+	int ret;
+
+	i_size = new_i_size ?: i_size_read(inode);
+	if (btrfs_fs_incompat(fs_info, NO_HOLES)) {
+		BTRFS_I(inode)->disk_i_size = i_size;
+		return;
+	}
+
+	spin_lock(&BTRFS_I(inode)->lock);
+	ret = find_contiguous_extent_bit(&BTRFS_I(inode)->file_extent_tree, 0,
+					 &start, &end, EXTENT_DIRTY);
+	if (!ret && start == 0)
+		i_size = min(i_size, end + 1);
+	else
+		i_size = 0;
+	BTRFS_I(inode)->disk_i_size = i_size;
+	spin_unlock(&BTRFS_I(inode)->lock);
+}
+
+/**
+ * @inode - the inode we're modifying
+ * @start - the start file offset of the file extent we've inserted
+ * @len - the logical length of the file extent item
+ *
+ * Call when we are inserting a new file extent where there was none before.
+ * Does not need to call this in the case where we're replacing an existing file
+ * extent, however if not sure it's fine to call this multiple times.
+ *
+ * The start and len must match the file extent item, so thus must be sectorsize
+ * aligned.
+ */
+int btrfs_inode_set_file_extent_range(struct btrfs_inode *inode, u64 start,
+				      u64 len)
+{
+	if (len == 0)
+		return 0;
+
+	ASSERT(IS_ALIGNED(start + len, inode->root->fs_info->sectorsize));
+
+	if (btrfs_fs_incompat(inode->root->fs_info, NO_HOLES))
+		return 0;
+	return set_extent_bits(&inode->file_extent_tree, start, start + len - 1,
+			       EXTENT_DIRTY);
+}
+
+/**
+ * @inode - the inode we're modifying
+ * @start - the start file offset of the file extent we've inserted
+ * @len - the logical length of the file extent item
+ *
+ * Called when we drop a file extent, for example when we truncate.  Doesn't
+ * need to be called for cases where we're replacing a file extent, like when
+ * we've COWed a file extent.
+ *
+ * The start and len must match the file extent item, so thus must be sectorsize
+ * aligned.
+ */
+int btrfs_inode_clear_file_extent_range(struct btrfs_inode *inode, u64 start,
+					u64 len)
+{
+	if (len == 0)
+		return 0;
+
+	ASSERT(IS_ALIGNED(start + len, inode->root->fs_info->sectorsize) ||
+	       len == (u64)-1);
+
+	if (btrfs_fs_incompat(inode->root->fs_info, NO_HOLES))
+		return 0;
+	return clear_extent_bit(&inode->file_extent_tree, start,
+				start + len - 1, EXTENT_DIRTY, 0, 0, NULL);
+}
+
 static inline u32 max_ordered_sum_bytes(struct btrfs_fs_info *fs_info,
 					u16 csum_size)
 {

commit 4babad10198fa73fe73239d02c2e99e3333f5f5c
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jan 8 15:29:53 2020 +0100

    btrfs: safely advance counter when looking up bio csums
    
    Dan's smatch tool reports
    
      fs/btrfs/file-item.c:295 btrfs_lookup_bio_sums()
      warn: should this be 'count == -1'
    
    which points to the while (count--) loop. With count == 0 the check
    itself could decrement it to -1. There's a WARN_ON a few lines below
    that has never been seen in practice though.
    
    It turns out that the value of page_bytes_left matches the count (by
    sectorsize multiples). The loop never reaches the state where count
    would go to -1, because page_bytes_left == 0 is found first and this
    breaks out.
    
    For clarity, use only plain check on count (and only for positive
    value), decrement safely inside the loop. Any other discrepancy after
    the whole bio list processing should be reported by the exising
    WARN_ON_ONCE as well.
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index bb374042d297..c2f365662d55 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -283,7 +283,8 @@ blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 		csum += count * csum_size;
 		nblocks -= count;
 next:
-		while (count--) {
+		while (count > 0) {
+			count--;
 			disk_bytenr += fs_info->sectorsize;
 			offset += fs_info->sectorsize;
 			page_bytes_left -= fs_info->sectorsize;

commit bffe633e00fb6b904817137fc17a44b42efcd985
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Dec 2 17:34:19 2019 -0800

    btrfs: make btrfs_ordered_extent naming consistent with btrfs_file_extent_item
    
    ordered->start, ordered->len, and ordered->disk_len correspond to
    fi->disk_bytenr, fi->num_bytes, and fi->disk_num_bytes, respectively.
    It's confusing to translate between the two naming schemes. Since a
    btrfs_ordered_extent is basically a pending btrfs_file_extent_item,
    let's make the former use the naming from the latter.
    
    Note that I didn't touch the names in tracepoints just in case there are
    scripts depending on the current naming.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b670014bfc1c..bb374042d297 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -481,8 +481,8 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 						 - 1);
 
 		for (i = 0; i < nr_sectors; i++) {
-			if (offset >= ordered->file_offset + ordered->len ||
-				offset < ordered->file_offset) {
+			if (offset >= ordered->file_offset + ordered->num_bytes ||
+			    offset < ordered->file_offset) {
 				unsigned long bytes_left;
 
 				sums->len = this_sum_bytes;

commit db72e47f79c5dbd95611edd453328d46c1eae93a
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Dec 10 10:37:35 2019 -0800

    btrfs: get rid of at_offset parameter to btrfs_lookup_bio_sums()
    
    We can encode this in the offset parameter: -1 means use the page
    offsets, anything else is a valid offset.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b7f5394c37a1..b670014bfc1c 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -152,17 +152,15 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
  * btrfs_lookup_bio_sums - Look up checksums for a bio.
  * @inode: inode that the bio is for.
  * @bio: bio embedded in btrfs_io_bio.
- * @at_offset: If true, look up checksums for the extent at @offset.
- *             If false, use the page offsets from the bio.
- * @offset: If @at_offset is true, offset in file to look up checksums for.
- *          Ignored otherwise.
+ * @offset: Unless (u64)-1, look up checksums for this offset in the file.
+ *          If (u64)-1, use the page offsets from the bio instead.
  * @dst: Buffer of size btrfs_super_csum_size() used to return checksum. If
  *       NULL, the checksum is returned in btrfs_io_bio(bio)->csum instead.
  *
  * Return: BLK_STS_RESOURCE if allocating memory fails, BLK_STS_OK otherwise.
  */
 blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
-				   bool at_offset, u64 offset, u8 *dst)
+				   u64 offset, u8 *dst)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	struct bio_vec bvec;
@@ -171,6 +169,7 @@ blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 	struct btrfs_csum_item *item = NULL;
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
 	struct btrfs_path *path;
+	const bool page_offsets = (offset == (u64)-1);
 	u8 *csum;
 	u64 item_start_offset = 0;
 	u64 item_last_offset = 0;
@@ -223,7 +222,7 @@ blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 		if (count)
 			goto next;
 
-		if (!at_offset)
+		if (page_offsets)
 			offset = page_offset(bvec.bv_page) + bvec.bv_offset;
 		count = btrfs_find_ordered_sum(inode, offset, disk_bytenr,
 					       csum, nblocks);

commit e62958fce94b30ef6aab99bb1bc49fde7fac73ea
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Dec 2 17:34:17 2019 -0800

    btrfs: get rid of trivial __btrfs_lookup_bio_sums() wrappers
    
    Currently, we have two wrappers for __btrfs_lookup_bio_sums():
    btrfs_lookup_bio_sums_dio(), which is used for direct I/O, and
    btrfs_lookup_bio_sums(), which is used everywhere else. The only
    difference is that the _dio variant looks up csums starting at the given
    offset instead of using the page index, which isn't actually direct
    I/O-specific. Let's clean up the signature and return value of
    __btrfs_lookup_bio_sums(), rename it to btrfs_lookup_bio_sums(), and get
    rid of the trivial helpers.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b1bfdc5c1387..b7f5394c37a1 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -148,8 +148,21 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
-				   u64 logical_offset, u8 *dst, int dio)
+/**
+ * btrfs_lookup_bio_sums - Look up checksums for a bio.
+ * @inode: inode that the bio is for.
+ * @bio: bio embedded in btrfs_io_bio.
+ * @at_offset: If true, look up checksums for the extent at @offset.
+ *             If false, use the page offsets from the bio.
+ * @offset: If @at_offset is true, offset in file to look up checksums for.
+ *          Ignored otherwise.
+ * @dst: Buffer of size btrfs_super_csum_size() used to return checksum. If
+ *       NULL, the checksum is returned in btrfs_io_bio(bio)->csum instead.
+ *
+ * Return: BLK_STS_RESOURCE if allocating memory fails, BLK_STS_OK otherwise.
+ */
+blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
+				   bool at_offset, u64 offset, u8 *dst)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	struct bio_vec bvec;
@@ -159,7 +172,6 @@ static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
 	struct btrfs_path *path;
 	u8 *csum;
-	u64 offset = 0;
 	u64 item_start_offset = 0;
 	u64 item_last_offset = 0;
 	u64 disk_bytenr;
@@ -205,15 +217,13 @@ static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio
 	}
 
 	disk_bytenr = (u64)bio->bi_iter.bi_sector << 9;
-	if (dio)
-		offset = logical_offset;
 
 	bio_for_each_segment(bvec, bio, iter) {
 		page_bytes_left = bvec.bv_len;
 		if (count)
 			goto next;
 
-		if (!dio)
+		if (!at_offset)
 			offset = page_offset(bvec.bv_page) + bvec.bv_offset;
 		count = btrfs_find_ordered_sum(inode, offset, disk_bytenr,
 					       csum, nblocks);
@@ -285,18 +295,7 @@ static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio
 
 	WARN_ON_ONCE(count);
 	btrfs_free_path(path);
-	return 0;
-}
-
-blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
-				   u8 *dst)
-{
-	return __btrfs_lookup_bio_sums(inode, bio, 0, dst, 0);
-}
-
-blk_status_t btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio, u64 offset)
-{
-	return __btrfs_lookup_bio_sums(inode, bio, offset, NULL, 1);
+	return BLK_STS_OK;
 }
 
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,

commit 40e046acbd2f369cfbf93c3413639c66514cec2d
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Dec 5 16:58:30 2019 +0000

    Btrfs: fix missing data checksums after replaying a log tree
    
    When logging a file that has shared extents (reflinked with other files or
    with itself), we can end up logging multiple checksum items that cover
    overlapping ranges. This confuses the search for checksums at log replay
    time causing some checksums to never be added to the fs/subvolume tree.
    
    Consider the following example of a file that shares the same extent at
    offsets 0 and 256Kb:
    
       [ bytenr 13893632, offset 64Kb, len 64Kb  ]
       0                                         64Kb
    
       [ bytenr 13631488, offset 64Kb, len 192Kb ]
       64Kb                                      256Kb
    
       [ bytenr 13893632, offset 0, len 256Kb    ]
       256Kb                                     512Kb
    
    When logging the inode, at tree-log.c:copy_items(), when processing the
    file extent item at offset 0, we log a checksum item covering the range
    13959168 to 14024704, which corresponds to 13893632 + 64Kb and 13893632 +
    64Kb + 64Kb, respectively.
    
    Later when processing the extent item at offset 256K, we log the checksums
    for the range from 13893632 to 14155776 (which corresponds to 13893632 +
    256Kb). These checksums get merged with the checksum item for the range
    from 13631488 to 13893632 (13631488 + 256Kb), logged by a previous fsync.
    So after this we get the two following checksum items in the log tree:
    
       (...)
       item 6 key (EXTENT_CSUM EXTENT_CSUM 13631488) itemoff 3095 itemsize 512
               range start 13631488 end 14155776 length 524288
       item 7 key (EXTENT_CSUM EXTENT_CSUM 13959168) itemoff 3031 itemsize 64
               range start 13959168 end 14024704 length 65536
    
    The first one covers the range from the second one, they overlap.
    
    So far this does not cause a problem after replaying the log, because
    when replaying the file extent item for offset 256K, we copy all the
    checksums for the extent 13893632 from the log tree to the fs/subvolume
    tree, since searching for an checksum item for bytenr 13893632 leaves us
    at the first checksum item, which covers the whole range of the extent.
    
    However if we write 64Kb to file offset 256Kb for example, we will
    not be able to find and copy the checksums for the last 128Kb of the
    extent at bytenr 13893632, referenced by the file range 384Kb to 512Kb.
    
    After writing 64Kb into file offset 256Kb we get the following extent
    layout for our file:
    
       [ bytenr 13893632, offset 64K, len 64Kb   ]
       0                                         64Kb
    
       [ bytenr 13631488, offset 64Kb, len 192Kb ]
       64Kb                                      256Kb
    
       [ bytenr 14155776, offset 0, len 64Kb     ]
       256Kb                                     320Kb
    
       [ bytenr 13893632, offset 64Kb, len 192Kb ]
       320Kb                                     512Kb
    
    After fsync'ing the file, if we have a power failure and then mount
    the filesystem to replay the log, the following happens:
    
    1) When replaying the file extent item for file offset 320Kb, we
       lookup for the checksums for the extent range from 13959168
       (13893632 + 64Kb) to 14155776 (13893632 + 256Kb), through a call
       to btrfs_lookup_csums_range();
    
    2) btrfs_lookup_csums_range() finds the checksum item that starts
       precisely at offset 13959168 (item 7 in the log tree, shown before);
    
    3) However that checksum item only covers 64Kb of data, and not 192Kb
       of data;
    
    4) As a result only the checksums for the first 64Kb of data referenced
       by the file extent item are found and copied to the fs/subvolume tree.
       The remaining 128Kb of data, file range 384Kb to 512Kb, doesn't get
       the corresponding data checksums found and copied to the fs/subvolume
       tree.
    
    5) After replaying the log userspace will not be able to read the file
       range from 384Kb to 512Kb, because the checksums are missing and
       resulting in an -EIO error.
    
    The following steps reproduce this scenario:
    
      $ mkfs.btrfs -f /dev/sdc
      $ mount /dev/sdc /mnt/sdc
    
      $ xfs_io -f -c "pwrite -S 0xa3 0 256K" /mnt/sdc/foobar
      $ xfs_io -c "fsync" /mnt/sdc/foobar
      $ xfs_io -c "pwrite -S 0xc7 256K 256K" /mnt/sdc/foobar
    
      $ xfs_io -c "reflink /mnt/sdc/foobar 320K 0 64K" /mnt/sdc/foobar
      $ xfs_io -c "fsync" /mnt/sdc/foobar
    
      $ xfs_io -c "pwrite -S 0xe5 256K 64K" /mnt/sdc/foobar
      $ xfs_io -c "fsync" /mnt/sdc/foobar
    
      <power failure>
    
      $ mount /dev/sdc /mnt/sdc
      $ md5sum /mnt/sdc/foobar
      md5sum: /mnt/sdc/foobar: Input/output error
    
      $ dmesg | tail
      [165305.003464] BTRFS info (device sdc): no csum found for inode 257 start 401408
      [165305.004014] BTRFS info (device sdc): no csum found for inode 257 start 405504
      [165305.004559] BTRFS info (device sdc): no csum found for inode 257 start 409600
      [165305.005101] BTRFS info (device sdc): no csum found for inode 257 start 413696
      [165305.005627] BTRFS info (device sdc): no csum found for inode 257 start 417792
      [165305.006134] BTRFS info (device sdc): no csum found for inode 257 start 421888
      [165305.006625] BTRFS info (device sdc): no csum found for inode 257 start 425984
      [165305.007278] BTRFS info (device sdc): no csum found for inode 257 start 430080
      [165305.008248] BTRFS warning (device sdc): csum failed root 5 ino 257 off 393216 csum 0x1337385e expected csum 0x00000000 mirror 1
      [165305.009550] BTRFS warning (device sdc): csum failed root 5 ino 257 off 393216 csum 0x1337385e expected csum 0x00000000 mirror 1
    
    Fix this simply by deleting first any checksums, from the log tree, for the
    range of the extent we are logging at copy_items(). This ensures we do not
    get checksum items in the log tree that have overlapping ranges.
    
    This is a long time issue that has been present since we have the clone
    (and deduplication) ioctl, and can happen both when an extent is shared
    between different files and within the same file.
    
    A test case for fstests follows soon.
    
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 3270a40b0777..b1bfdc5c1387 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -590,9 +590,9 @@ static noinline void truncate_one_csum(struct btrfs_fs_info *fs_info,
  * range of bytes.
  */
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
-		    struct btrfs_fs_info *fs_info, u64 bytenr, u64 len)
+		    struct btrfs_root *root, u64 bytenr, u64 len)
 {
-	struct btrfs_root *root = fs_info->csum_root;
+	struct btrfs_fs_info *fs_info = trans->fs_info;
 	struct btrfs_path *path;
 	struct btrfs_key key;
 	u64 end_byte = bytenr + len;
@@ -602,6 +602,9 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 	int blocksize_bits = fs_info->sb->s_blocksize_bits;
 
+	ASSERT(root == fs_info->csum_root ||
+	       root->root_key.objectid == BTRFS_TREE_LOG_OBJECTID);
+
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;

commit a019e9e197eaa68ffe2efeba00d685581b1a5416
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 30 15:40:53 2019 +0200

    btrfs: remove extent_map::bdev
    
    We can now remove the bdev from extent_map. Previous patches made sure
    that bio_set_dev is correctly in all places and that we don't need to
    grab it from latest_bdev or pass it around inside the extent map.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 1a599f50837b..3270a40b0777 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -945,7 +945,6 @@ void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 	u8 type = btrfs_file_extent_type(leaf, fi);
 	int compress_type = btrfs_file_extent_compression(leaf, fi);
 
-	em->bdev = fs_info->fs_devices->latest_bdev;
 	btrfs_item_key_to_cpu(leaf, &key, slot);
 	extent_start = key.offset;
 

commit d5178578bcd461cc79118c7a139882350fe505aa
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Jun 3 16:58:57 2019 +0200

    btrfs: directly call into crypto framework for checksumming
    
    Currently btrfs_csum_data() relied on the crc32c() wrapper around the
    crypto framework for calculating the CRCs.
    
    As we have our own crypto_shash structure in the fs_info now, we can
    directly call into the crypto framework without going trough the wrapper.
    
    This way we can even remove the btrfs_csum_data() and btrfs_csum_final()
    wrappers.
    
    The module dependency on crc32c is preserved via MODULE_SOFTDEP("pre:
    crc32c"), which was previously provided by LIBCRC32C config option doing
    the same.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index de89fd1310a6..1a599f50837b 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -8,6 +8,7 @@
 #include <linux/pagemap.h>
 #include <linux/highmem.h>
 #include <linux/sched/mm.h>
+#include <crypto/hash.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -432,6 +433,7 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 		       u64 file_start, int contig)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
+	SHASH_DESC_ON_STACK(shash, fs_info->csum_shash);
 	struct btrfs_ordered_sum *sums;
 	struct btrfs_ordered_extent *ordered = NULL;
 	char *data;
@@ -465,6 +467,8 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 	sums->bytenr = (u64)bio->bi_iter.bi_sector << 9;
 	index = 0;
 
+	shash->tfm = fs_info->csum_shash;
+
 	bio_for_each_segment(bvec, bio, iter) {
 		if (!contig)
 			offset = page_offset(bvec.bv_page) + bvec.bv_offset;
@@ -479,8 +483,6 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 						 - 1);
 
 		for (i = 0; i < nr_sectors; i++) {
-			u32 tmp;
-
 			if (offset >= ordered->file_offset + ordered->len ||
 				offset < ordered->file_offset) {
 				unsigned long bytes_left;
@@ -506,15 +508,13 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 				index = 0;
 			}
 
-			memset(&sums->sums[index], 0xff, csum_size);
+			crypto_shash_init(shash);
 			data = kmap_atomic(bvec.bv_page);
-			tmp = btrfs_csum_data(data + bvec.bv_offset
-						+ (i * fs_info->sectorsize),
-						*(u32 *)&sums->sums[index],
-						fs_info->sectorsize);
+			crypto_shash_update(shash, data + bvec.bv_offset
+					    + (i * fs_info->sectorsize),
+					    fs_info->sectorsize);
 			kunmap_atomic(data);
-			btrfs_csum_final(tmp,
-					(char *)(sums->sums + index));
+			crypto_shash_final(shash, (char *)(sums->sums + index));
 			index += csum_size;
 			offset += fs_info->sectorsize;
 			this_sum_bytes += fs_info->sectorsize;

commit 10fe6ca80d9d25eca9fd6d98eccf6c795532fe96
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed May 22 10:19:02 2019 +0200

    btrfs: don't assume compressed_bio sums to be 4 bytes
    
    BTRFS has the implicit assumption that a checksum in compressed_bio is 4
    bytes. While this is true for CRC32C, it is not for any other checksum.
    
    Change the data type to be a byte array and adjust loop index calculation
    accordingly.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 0464dd4c0579..de89fd1310a6 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -186,7 +186,7 @@ static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio
 		}
 		csum = btrfs_bio->csum;
 	} else {
-		csum = (u8 *)dst;
+		csum = dst;
 	}
 
 	if (bio->bi_iter.bi_size > PAGE_SIZE * 8)

commit 1e25a2e3ca0dab0ed1030570e95d98af47113eae
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed May 22 10:19:01 2019 +0200

    btrfs: don't assume ordered sums to be 4 bytes
    
    BTRFS has the implicit assumption that a checksum in btrfs_orderd_sums
    is 4 bytes. While this is true for CRC32C, it is not for any other
    checksum.
    
    Change the data type to be a byte array and adjust loop index
    calculation accordingly.
    
    This includes moving the adjustment of 'index' by 'ins_size' in
    btrfs_csum_file_blocks() before dividing 'ins_size' by the checksum
    size, because before this patch the 'sums' member of 'struct
    btrfs_ordered_sum' was 4 Bytes in size and afterwards it is only one
    byte.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index d431ea8198e4..0464dd4c0579 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -22,9 +22,13 @@
 #define MAX_CSUM_ITEMS(r, size) (min_t(u32, __MAX_CSUM_ITEMS(r, size), \
 				       PAGE_SIZE))
 
-#define MAX_ORDERED_SUM_BYTES(fs_info) ((PAGE_SIZE - \
-				   sizeof(struct btrfs_ordered_sum)) / \
-				   sizeof(u32) * (fs_info)->sectorsize)
+static inline u32 max_ordered_sum_bytes(struct btrfs_fs_info *fs_info,
+					u16 csum_size)
+{
+	u32 ncsums = (PAGE_SIZE - sizeof(struct btrfs_ordered_sum)) / csum_size;
+
+	return ncsums * fs_info->sectorsize;
+}
 
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
@@ -144,7 +148,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 }
 
 static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
-				   u64 logical_offset, u32 *dst, int dio)
+				   u64 logical_offset, u8 *dst, int dio)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	struct bio_vec bvec;
@@ -211,7 +215,7 @@ static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio
 		if (!dio)
 			offset = page_offset(bvec.bv_page) + bvec.bv_offset;
 		count = btrfs_find_ordered_sum(inode, offset, disk_bytenr,
-					       (u32 *)csum, nblocks);
+					       csum, nblocks);
 		if (count)
 			goto found;
 
@@ -283,7 +287,8 @@ static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio
 	return 0;
 }
 
-blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio, u32 *dst)
+blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
+				   u8 *dst)
 {
 	return __btrfs_lookup_bio_sums(inode, bio, 0, dst, 0);
 }
@@ -374,7 +379,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 				      struct btrfs_csum_item);
 		while (start < csum_end) {
 			size = min_t(size_t, csum_end - start,
-				     MAX_ORDERED_SUM_BYTES(fs_info));
+				     max_ordered_sum_bytes(fs_info, csum_size));
 			sums = kzalloc(btrfs_ordered_sum_size(fs_info, size),
 				       GFP_NOFS);
 			if (!sums) {
@@ -439,6 +444,7 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 	int i;
 	u64 offset;
 	unsigned nofs_flag;
+	const u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 
 	nofs_flag = memalloc_nofs_save();
 	sums = kvzalloc(btrfs_ordered_sum_size(fs_info, bio->bi_iter.bi_size),
@@ -473,6 +479,8 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 						 - 1);
 
 		for (i = 0; i < nr_sectors; i++) {
+			u32 tmp;
+
 			if (offset >= ordered->file_offset + ordered->len ||
 				offset < ordered->file_offset) {
 				unsigned long bytes_left;
@@ -498,17 +506,16 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 				index = 0;
 			}
 
-			sums->sums[index] = ~(u32)0;
+			memset(&sums->sums[index], 0xff, csum_size);
 			data = kmap_atomic(bvec.bv_page);
-			sums->sums[index]
-				= btrfs_csum_data(data + bvec.bv_offset
+			tmp = btrfs_csum_data(data + bvec.bv_offset
 						+ (i * fs_info->sectorsize),
-						sums->sums[index],
+						*(u32 *)&sums->sums[index],
 						fs_info->sectorsize);
 			kunmap_atomic(data);
-			btrfs_csum_final(sums->sums[index],
+			btrfs_csum_final(tmp,
 					(char *)(sums->sums + index));
-			index++;
+			index += csum_size;
 			offset += fs_info->sectorsize;
 			this_sum_bytes += fs_info->sectorsize;
 			total_bytes += fs_info->sectorsize;
@@ -904,9 +911,9 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	write_extent_buffer(leaf, sums->sums + index, (unsigned long)item,
 			    ins_size);
 
+	index += ins_size;
 	ins_size /= csum_size;
 	total_bytes += ins_size * fs_info->sectorsize;
-	index += ins_size;
 
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 	if (total_bytes < sums->len) {

commit 51d470aeaa3a4ac5bdf98743ac1d32008e8dafa4
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Apr 22 16:07:31 2019 +0300

    btrfs: Document btrfs_csum_one_bio
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 5a3be16ca93d..d431ea8198e4 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -413,6 +413,16 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	return ret;
 }
 
+/*
+ * btrfs_csum_one_bio - Calculates checksums of the data contained inside a bio
+ * @inode:	 Owner of the data inside the bio
+ * @bio:	 Contains the data to be checksummed
+ * @file_start:  offset in file this bio begins to describe
+ * @contig:	 Boolean. If true/1 means all bio vecs in this bio are
+ *		 contiguous and they begin at @file_start in the file. False/0
+ *		 means this bio can contains potentially discontigous bio vecs
+ *		 so the logical offset of each should be calculated separately.
+ */
 blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 		       u64 file_start, int contig)
 {

commit c71dd88007bdc8ba62e99439d93050b0778f101a
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 14:51:10 2019 +0100

    btrfs: remove unused parameter fs_info from btrfs_extend_item
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 9f6ceb8eb451..5a3be16ca93d 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -848,7 +848,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		diff /= csum_size;
 		diff *= csum_size;
 
-		btrfs_extend_item(fs_info, path, diff);
+		btrfs_extend_item(path, diff);
 		ret = 0;
 		goto csum;
 	}

commit 78ac4f9e5ae022bd183ca21da7b373d300b7be17
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 14:49:12 2019 +0100

    btrfs: remove unused parameter fs_info from btrfs_truncate_item
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a120d6ba3a28..9f6ceb8eb451 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -547,7 +547,7 @@ static noinline void truncate_one_csum(struct btrfs_fs_info *fs_info,
 		 */
 		u32 new_size = (bytenr - key->offset) >> blocksize_bits;
 		new_size *= csum_size;
-		btrfs_truncate_item(fs_info, path, new_size, 1);
+		btrfs_truncate_item(path, new_size, 1);
 	} else if (key->offset >= bytenr && csum_end > end_byte &&
 		   end_byte > key->offset) {
 		/*
@@ -559,7 +559,7 @@ static noinline void truncate_one_csum(struct btrfs_fs_info *fs_info,
 		u32 new_size = (csum_end - end_byte) >> blocksize_bits;
 		new_size *= csum_size;
 
-		btrfs_truncate_item(fs_info, path, new_size, 0);
+		btrfs_truncate_item(path, new_size, 0);
 
 		key->offset = end_byte;
 		btrfs_set_item_key_safe(fs_info, path, key);

commit f9756261c28c0acdaac8a7a8894d3e25d334d5f3
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 16:16:11 2019 +0300

    btrfs: Remove redundant inode argument from btrfs_add_ordered_sum
    
    Ordered csums are keyed off of a btrfs_ordered_extent, which already has
    a reference to the inode. This implies that an explicit inode argument
    is redundant. So remove it.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 0867fca4b63d..a120d6ba3a28 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -469,7 +469,7 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 
 				sums->len = this_sum_bytes;
 				this_sum_bytes = 0;
-				btrfs_add_ordered_sum(inode, ordered, sums);
+				btrfs_add_ordered_sum(ordered, sums);
 				btrfs_put_ordered_extent(ordered);
 
 				bytes_left = bio->bi_iter.bi_size - total_bytes;
@@ -506,7 +506,7 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 
 	}
 	this_sum_bytes = 0;
-	btrfs_add_ordered_sum(inode, ordered, sums);
+	btrfs_add_ordered_sum(ordered, sums);
 	btrfs_put_ordered_extent(ordered);
 	return 0;
 }

commit e902baac656479bdb956224ed693578424cf9e96
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 14:36:46 2019 +0100

    btrfs: get fs_info from eb in btrfs_leaf_free_space
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 6fccac9eab96..0867fca4b63d 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -828,11 +828,11 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		u32 diff;
 		u32 free_space;
 
-		if (btrfs_leaf_free_space(fs_info, leaf) <
+		if (btrfs_leaf_free_space(leaf) <
 				 sizeof(struct btrfs_item) + csum_size * 2)
 			goto insert;
 
-		free_space = btrfs_leaf_free_space(fs_info, leaf) -
+		free_space = btrfs_leaf_free_space(leaf) -
 					 sizeof(struct btrfs_item) - csum_size;
 		tmp = sums->len - total_bytes;
 		tmp >>= fs_info->sb->s_blocksize_bits;

commit 443c8e2a839f18084cfdb5b0b62d90b8159f48ae
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Thu Mar 7 17:14:00 2019 +0100

    btrfs: reduce kmap_atomic time for checksumming
    
    Since commit c40a3d38aff4 ("Btrfs: Compute and look up csums based on
    sectorsized blocks") we do a kmap_atomic() on the contents of a bvec.
    The code before c40a3d38aff4 had the kmap region just around the
    checksumming too.
    
    kmap_atomic() in turn does a preempt_disable() and pagefault_disable(),
    so we shouldn't map the data for too long. Reduce the time the bvec's
    page is mapped to when we actually need it.
    
    Performance wise it doesn't seem to make a huge difference with a 2 vcpu VM
    on a /dev/zram device:
    
           vanilla      patched      delta
    write  17.4MiB/s    17.8MiB/s   +0.4MiB/s (+2%)
    read   40.6MiB/s    41.5MiB/s   +0.9MiB/s (+2%)
    
    The following fio job profile was used in the comparision:
    
    [global]
    ioengine=libaio
    direct=1
    sync=1
    norandommap
    time_based
    runtime=10m
    size=100m
    group_reporting
    numjobs=2
    
    [test]
    filename=/mnt/test/fio
    rw=randrw
    rwmixread=70
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index cccc75d15970..6fccac9eab96 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -458,8 +458,6 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 			BUG_ON(!ordered); /* Logic error */
 		}
 
-		data = kmap_atomic(bvec.bv_page);
-
 		nr_sectors = BTRFS_BYTES_TO_BLKS(fs_info,
 						 bvec.bv_len + fs_info->sectorsize
 						 - 1);
@@ -469,7 +467,6 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 				offset < ordered->file_offset) {
 				unsigned long bytes_left;
 
-				kunmap_atomic(data);
 				sums->len = this_sum_bytes;
 				this_sum_bytes = 0;
 				btrfs_add_ordered_sum(inode, ordered, sums);
@@ -489,16 +486,16 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 				sums->bytenr = ((u64)bio->bi_iter.bi_sector << 9)
 					+ total_bytes;
 				index = 0;
-
-				data = kmap_atomic(bvec.bv_page);
 			}
 
 			sums->sums[index] = ~(u32)0;
+			data = kmap_atomic(bvec.bv_page);
 			sums->sums[index]
 				= btrfs_csum_data(data + bvec.bv_offset
 						+ (i * fs_info->sectorsize),
 						sums->sums[index],
 						fs_info->sectorsize);
+			kunmap_atomic(data);
 			btrfs_csum_final(sums->sums[index],
 					(char *)(sums->sums + index));
 			index++;
@@ -507,7 +504,6 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 			total_bytes += fs_info->sectorsize;
 		}
 
-		kunmap_atomic(data);
 	}
 	this_sum_bytes = 0;
 	btrfs_add_ordered_sum(inode, ordered, sums);

commit a3d46aea46f99d134b4e0726e4826b824c3e5980
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Apr 1 11:29:58 2019 +0300

    btrfs: Switch memory allocations in async csum calculation path to kvmalloc
    
    Recent multi-page biovec rework allowed creation of bios that can span
    large regions - up to 128 megabytes in the case of btrfs. OTOH btrfs'
    submission path currently allocates a contiguous array to store the
    checksums for every bio submitted. This means we can request up to
    (128mb / BTRFS_SECTOR_SIZE) * 4 bytes + 32bytes of memory from kmalloc.
    On busy systems with possibly fragmented memory said kmalloc can fail
    which will trigger BUG_ON due to improper error handling IO submission
    context in btrfs.
    
    Until error handling is improved or bios in btrfs limited to a more
    manageable size (e.g. 1m) let's use kvmalloc to fallback to vmalloc for
    such large allocations. There is no hard requirement that the memory
    allocated for checksums during IO submission has to be contiguous, but
    this is a simple fix that does not require several non-contiguous
    allocations.
    
    For small writes this is unlikely to have any visible effect since
    kmalloc will still satisfy allocation requests as usual. For larger
    requests the code will just fallback to vmalloc.
    
    We've performed evaluation on several workload types and there was no
    significant difference kmalloc vs kvmalloc.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 920bf3b4b0ef..cccc75d15970 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -7,6 +7,7 @@
 #include <linux/slab.h>
 #include <linux/pagemap.h>
 #include <linux/highmem.h>
+#include <linux/sched/mm.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -427,9 +428,13 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 	unsigned long this_sum_bytes = 0;
 	int i;
 	u64 offset;
+	unsigned nofs_flag;
+
+	nofs_flag = memalloc_nofs_save();
+	sums = kvzalloc(btrfs_ordered_sum_size(fs_info, bio->bi_iter.bi_size),
+		       GFP_KERNEL);
+	memalloc_nofs_restore(nofs_flag);
 
-	sums = kzalloc(btrfs_ordered_sum_size(fs_info, bio->bi_iter.bi_size),
-		       GFP_NOFS);
 	if (!sums)
 		return BLK_STS_RESOURCE;
 
@@ -472,8 +477,10 @@ blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 
 				bytes_left = bio->bi_iter.bi_size - total_bytes;
 
-				sums = kzalloc(btrfs_ordered_sum_size(fs_info, bytes_left),
-					       GFP_NOFS);
+				nofs_flag = memalloc_nofs_save();
+				sums = kvzalloc(btrfs_ordered_sum_size(fs_info,
+						      bytes_left), GFP_KERNEL);
+				memalloc_nofs_restore(nofs_flag);
 				BUG_ON(!sums); /* -ENOMEM */
 				sums->len = bytes_left;
 				ordered = btrfs_lookup_ordered_extent(inode,

commit b3a0dd50c3951ec1b9a12ec39034194022fd8693
Author: David Sterba <dsterba@suse.com>
Date:   Thu Nov 22 17:16:49 2018 +0100

    btrfs: replace btrfs_io_bio::end_io with a simple helper
    
    The end_io callback implemented as btrfs_io_bio_endio_readpage only
    calls kfree. Also the callback is set only in case the csum buffer is
    allocated and not pointing to the inline buffer. We can use that
    information to drop the indirection and call a helper that will free the
    csums only in the right case.
    
    This shrinks struct btrfs_io_bio by 8 bytes.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 1f2d0a6ab634..920bf3b4b0ef 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -142,14 +142,6 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-static void btrfs_io_bio_endio_readpage(struct btrfs_io_bio *bio, int err)
-{
-	if (bio->csum != bio->csum_inline) {
-		kfree(bio->csum);
-		bio->csum = NULL;
-	}
-}
-
 static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 				   u64 logical_offset, u32 *dst, int dio)
 {
@@ -184,7 +176,6 @@ static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio
 				btrfs_free_path(path);
 				return BLK_STS_RESOURCE;
 			}
-			btrfs_bio->end_io = btrfs_io_bio_endio_readpage;
 		} else {
 			btrfs_bio->csum = btrfs_bio->csum_inline;
 		}

commit 31fecccbd7b2174487a6b7361153b60a4eda6108
Author: David Sterba <dsterba@suse.com>
Date:   Thu Nov 22 17:16:46 2018 +0100

    btrfs: remove redundant csum buffer in btrfs_io_bio
    
    The io_bio tracks checksums and has an inline buffer or an allocated
    one. And there's a third member that points to the right one, but we
    don't need to use an extra pointer for that. Let btrfs_io_bio::csum
    point to the right buffer and check that the inline buffer is not
    accidentally freed.
    
    This shrinks struct btrfs_io_bio by 8 bytes.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index ba74827beb32..1f2d0a6ab634 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -144,7 +144,10 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 
 static void btrfs_io_bio_endio_readpage(struct btrfs_io_bio *bio, int err)
 {
-	kfree(bio->csum_allocated);
+	if (bio->csum != bio->csum_inline) {
+		kfree(bio->csum);
+		bio->csum = NULL;
+	}
 }
 
 static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
@@ -175,13 +178,12 @@ static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio
 	nblocks = bio->bi_iter.bi_size >> inode->i_sb->s_blocksize_bits;
 	if (!dst) {
 		if (nblocks * csum_size > BTRFS_BIO_INLINE_CSUM_SIZE) {
-			btrfs_bio->csum_allocated = kmalloc_array(nblocks,
-					csum_size, GFP_NOFS);
-			if (!btrfs_bio->csum_allocated) {
+			btrfs_bio->csum = kmalloc_array(nblocks, csum_size,
+							GFP_NOFS);
+			if (!btrfs_bio->csum) {
 				btrfs_free_path(path);
 				return BLK_STS_RESOURCE;
 			}
-			btrfs_bio->csum = btrfs_bio->csum_allocated;
 			btrfs_bio->end_io = btrfs_io_bio_endio_readpage;
 		} else {
 			btrfs_bio->csum = btrfs_bio->csum_inline;

commit 3ffbd68c48320730ef64ebfb5e639220f1f65483
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 29 10:56:42 2018 +0200

    btrfs: simplify pointer chasing of local fs_info variables
    
    Functions that get btrfs inode can simply reach the fs_info by
    dereferencing the root and this looks a bit more straightforward
    compared to the btrfs_sb(...) indirection.
    
    If the transaction handle is available and not NULL it's used instead.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 8c3cd7072caf..ba74827beb32 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -922,7 +922,7 @@ void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 				     const bool new_inline,
 				     struct extent_map *em)
 {
-	struct btrfs_fs_info *fs_info = btrfs_sb(inode->vfs_inode.i_sb);
+	struct btrfs_fs_info *fs_info = inode->root->fs_info;
 	struct btrfs_root *root = inode->root;
 	struct extent_buffer *leaf = path->nodes[0];
 	const int slot = path->slots[0];

commit e41ca5897489b1c18af75ff0cc8f5c80260b3281
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jun 6 15:41:49 2018 +0800

    btrfs: Get rid of the confusing btrfs_file_extent_inline_len
    
    We used to call btrfs_file_extent_inline_len() to get the uncompressed
    data size of an inlined extent.
    
    However this function is hiding evil, for compressed extent, it has no
    choice but to directly read out ram_bytes from btrfs_file_extent_item.
    While for uncompressed extent, it uses item size to calculate the real
    data size, and ignoring ram_bytes completely.
    
    In fact, for corrupted ram_bytes, due to above behavior kernel
    btrfs_print_leaf() can't even print correct ram_bytes to expose the bug.
    
    Since we have the tree-checker to verify all EXTENT_DATA, such mismatch
    can be detected pretty easily, thus we can trust ram_bytes without the
    evil btrfs_file_extent_inline_len().
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f9dd6d1836a3..8c3cd7072caf 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -942,7 +942,7 @@ void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 			btrfs_file_extent_num_bytes(leaf, fi);
 	} else if (type == BTRFS_FILE_EXTENT_INLINE) {
 		size_t size;
-		size = btrfs_file_extent_inline_len(leaf, slot, fi);
+		size = btrfs_file_extent_ram_bytes(leaf, fi);
 		extent_end = ALIGN(extent_start + size,
 				   fs_info->sectorsize);
 	}

commit c1d7c514f745628eb096c5cbb10737855879ae25
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:23:33 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- sources
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index fdcb41002623..f9dd6d1836a3 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -1,19 +1,6 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 2007 Oracle.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
 #include <linux/bio.h>

commit 8c27cb3566762613a23c080e3db7d0501af9a787
Merge: 7114f51fcb97 848c23b78faf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 5 16:41:23 2017 -0700

    Merge branch 'for-4.13-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "The core updates improve error handling (mostly related to bios), with
      the usual incremental work on the GFP_NOFS (mis)use removal,
      refactoring or cleanups. Except the two top patches, all have been in
      for-next for an extensive amount of time.
    
      User visible changes:
    
       - statx support
    
       - quota override tunable
    
       - improved compression thresholds
    
       - obsoleted mount option alloc_start
    
      Core updates:
    
       - bio-related updates:
           - faster bio cloning
           - no allocation failures
           - preallocated flush bios
    
       - more kvzalloc use, memalloc_nofs protections, GFP_NOFS updates
    
       - prep work for btree_inode removal
    
       - dir-item validation
    
       - qgoup fixes and updates
    
       - cleanups:
           - removed unused struct members, unused code, refactoring
           - argument refactoring (fs_info/root, caller -> callee sink)
           - SEARCH_TREE ioctl docs"
    
    * 'for-4.13-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (115 commits)
      btrfs: Remove false alert when fiemap range is smaller than on-disk extent
      btrfs: Don't clear SGID when inheriting ACLs
      btrfs: fix integer overflow in calc_reclaim_items_nr
      btrfs: scrub: fix target device intialization while setting up scrub context
      btrfs: qgroup: Fix qgroup reserved space underflow by only freeing reserved ranges
      btrfs: qgroup: Introduce extent changeset for qgroup reserve functions
      btrfs: qgroup: Fix qgroup reserved space underflow caused by buffered write and quotas being enabled
      btrfs: qgroup: Return actually freed bytes for qgroup release or free data
      btrfs: qgroup: Cleanup btrfs_qgroup_prepare_account_extents function
      btrfs: qgroup: Add quick exit for non-fs extents
      Btrfs: rework delayed ref total_bytes_pinned accounting
      Btrfs: return old and new total ref mods when adding delayed refs
      Btrfs: always account pinned bytes when dropping a tree block ref
      Btrfs: update total_bytes_pinned when pinning down extents
      Btrfs: make BUG_ON() in add_pinned_bytes() an ASSERT()
      Btrfs: make add_pinned_bytes() take an s64 num_bytes instead of u64
      btrfs: fix validation of XATTR_ITEM dir items
      btrfs: Verify dir_item in iterate_object_props
      btrfs: Check name_len before in btrfs_del_root_ref
      btrfs: Check name_len before reading btrfs_get_name
      ...

commit 17347cec15f919901c90cdbf98af47ed2ed28b9f
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon May 15 15:33:27 2017 -0700

    Btrfs: change how we iterate bios in endio
    
    Since dio submit has used bio_clone_fast, the submitted bio may not have a
    reliable bi_vcnt, for the bio vector iterations in checksum related
    functions, bio->bi_iter is not modified yet and it's safe to use
    bio_for_each_segment, while for those bio vector iterations in dio read's
    endio, we now save a copy of bvec_iter in struct btrfs_io_bio when cloning
    bios and use the helper __bio_for_each_segment with the saved bvec_iter to
    access each bvec.
    
    Also for dio reads which don't get split, we also need to save a copy of
    bio iterator in btrfs_bio_clone to let __bio_for_each_segments to access
    each bvec in dio read's endio.  Note that it doesn't affect other calls of
    btrfs_bio_clone() because they don't need to use this iterator.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 64fcb31d7163..9f6062c82419 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -164,7 +164,8 @@ static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 				   u64 logical_offset, u32 *dst, int dio)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
-	struct bio_vec *bvec;
+	struct bio_vec bvec;
+	struct bvec_iter iter;
 	struct btrfs_io_bio *btrfs_bio = btrfs_io_bio(bio);
 	struct btrfs_csum_item *item = NULL;
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
@@ -177,7 +178,7 @@ static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 	u64 page_bytes_left;
 	u32 diff;
 	int nblocks;
-	int count = 0, i;
+	int count = 0;
 	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 
 	path = btrfs_alloc_path();
@@ -206,8 +207,6 @@ static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 	if (bio->bi_iter.bi_size > PAGE_SIZE * 8)
 		path->reada = READA_FORWARD;
 
-	WARN_ON(bio->bi_vcnt <= 0);
-
 	/*
 	 * the free space stuff is only read when it hasn't been
 	 * updated in the current transaction.  So, we can safely
@@ -223,13 +222,13 @@ static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 	if (dio)
 		offset = logical_offset;
 
-	bio_for_each_segment_all(bvec, bio, i) {
-		page_bytes_left = bvec->bv_len;
+	bio_for_each_segment(bvec, bio, iter) {
+		page_bytes_left = bvec.bv_len;
 		if (count)
 			goto next;
 
 		if (!dio)
-			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+			offset = page_offset(bvec.bv_page) + bvec.bv_offset;
 		count = btrfs_find_ordered_sum(inode, offset, disk_bytenr,
 					       (u32 *)csum, nblocks);
 		if (count)
@@ -440,15 +439,15 @@ int btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 	struct btrfs_ordered_sum *sums;
 	struct btrfs_ordered_extent *ordered = NULL;
 	char *data;
-	struct bio_vec *bvec;
+	struct bvec_iter iter;
+	struct bio_vec bvec;
 	int index;
 	int nr_sectors;
-	int i, j;
 	unsigned long total_bytes = 0;
 	unsigned long this_sum_bytes = 0;
+	int i;
 	u64 offset;
 
-	WARN_ON(bio->bi_vcnt <= 0);
 	sums = kzalloc(btrfs_ordered_sum_size(fs_info, bio->bi_iter.bi_size),
 		       GFP_NOFS);
 	if (!sums)
@@ -465,19 +464,19 @@ int btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 	sums->bytenr = (u64)bio->bi_iter.bi_sector << 9;
 	index = 0;
 
-	bio_for_each_segment_all(bvec, bio, j) {
+	bio_for_each_segment(bvec, bio, iter) {
 		if (!contig)
-			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+			offset = page_offset(bvec.bv_page) + bvec.bv_offset;
 
 		if (!ordered) {
 			ordered = btrfs_lookup_ordered_extent(inode, offset);
 			BUG_ON(!ordered); /* Logic error */
 		}
 
-		data = kmap_atomic(bvec->bv_page);
+		data = kmap_atomic(bvec.bv_page);
 
 		nr_sectors = BTRFS_BYTES_TO_BLKS(fs_info,
-						 bvec->bv_len + fs_info->sectorsize
+						 bvec.bv_len + fs_info->sectorsize
 						 - 1);
 
 		for (i = 0; i < nr_sectors; i++) {
@@ -504,12 +503,12 @@ int btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 					+ total_bytes;
 				index = 0;
 
-				data = kmap_atomic(bvec->bv_page);
+				data = kmap_atomic(bvec.bv_page);
 			}
 
 			sums->sums[index] = ~(u32)0;
 			sums->sums[index]
-				= btrfs_csum_data(data + bvec->bv_offset
+				= btrfs_csum_data(data + bvec.bv_offset
 						+ (i * fs_info->sectorsize),
 						sums->sums[index],
 						fs_info->sectorsize);

commit 4e4cbee93d56137ebff722be022cae5f70ef84fb
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:06 2017 +0200

    block: switch bios to blk_status_t
    
    Replace bi_error with a new bi_status to allow for a clear conversion.
    Note that device mapper overloaded bi_error with a private value, which
    we'll have to keep arround at least for now and thus propagate to a
    proper blk_status_t value.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 64fcb31d7163..5b1c7090e546 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -160,7 +160,7 @@ static void btrfs_io_bio_endio_readpage(struct btrfs_io_bio *bio, int err)
 	kfree(bio->csum_allocated);
 }
 
-static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
+static blk_status_t __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 				   u64 logical_offset, u32 *dst, int dio)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
@@ -182,7 +182,7 @@ static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 
 	path = btrfs_alloc_path();
 	if (!path)
-		return -ENOMEM;
+		return BLK_STS_RESOURCE;
 
 	nblocks = bio->bi_iter.bi_size >> inode->i_sb->s_blocksize_bits;
 	if (!dst) {
@@ -191,7 +191,7 @@ static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 					csum_size, GFP_NOFS);
 			if (!btrfs_bio->csum_allocated) {
 				btrfs_free_path(path);
-				return -ENOMEM;
+				return BLK_STS_RESOURCE;
 			}
 			btrfs_bio->csum = btrfs_bio->csum_allocated;
 			btrfs_bio->end_io = btrfs_io_bio_endio_readpage;
@@ -303,12 +303,12 @@ static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 	return 0;
 }
 
-int btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio, u32 *dst)
+blk_status_t btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio, u32 *dst)
 {
 	return __btrfs_lookup_bio_sums(inode, bio, 0, dst, 0);
 }
 
-int btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio, u64 offset)
+blk_status_t btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio, u64 offset)
 {
 	return __btrfs_lookup_bio_sums(inode, bio, offset, NULL, 1);
 }
@@ -433,7 +433,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	return ret;
 }
 
-int btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
+blk_status_t btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 		       u64 file_start, int contig)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
@@ -452,7 +452,7 @@ int btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
 	sums = kzalloc(btrfs_ordered_sum_size(fs_info, bio->bi_iter.bi_size),
 		       GFP_NOFS);
 	if (!sums)
-		return -ENOMEM;
+		return BLK_STS_RESOURCE;
 
 	sums->len = bio->bi_iter.bi_size;
 	INIT_LIST_HEAD(&sums->list);

commit e9f467d028cd7d8bee2a4d6c4fb806caf8cd580b
Merge: ef6ebf324216 20a7db8ab3f2
Author: Chris Mason <clm@fb.com>
Date:   Tue Feb 28 14:35:09 2017 -0800

    Merge branch 'for-chris-4.11-part2' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.11

commit 9cdc51241090a36d3b7b4ff374fb18b764b3b3a4
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:51:02 2017 +0200

    btrfs: Make btrfs_extent_item_to_extent_map take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a8a0dd217084..54ec6d6ef016 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -904,14 +904,14 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	goto out;
 }
 
-void btrfs_extent_item_to_extent_map(struct inode *inode,
+void btrfs_extent_item_to_extent_map(struct btrfs_inode *inode,
 				     const struct btrfs_path *path,
 				     struct btrfs_file_extent_item *fi,
 				     const bool new_inline,
 				     struct extent_map *em)
 {
-	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
-	struct btrfs_root *root = BTRFS_I(inode)->root;
+	struct btrfs_fs_info *fs_info = btrfs_sb(inode->vfs_inode.i_sb);
+	struct btrfs_root *root = inode->root;
 	struct extent_buffer *leaf = path->nodes[0];
 	const int slot = path->slots[0];
 	struct btrfs_key key;
@@ -976,8 +976,8 @@ void btrfs_extent_item_to_extent_map(struct inode *inode,
 		}
 	} else {
 		btrfs_err(fs_info,
-			  "unknown file extent item type %d, inode %llu, offset %llu, root %llu",
-			  type, btrfs_ino(BTRFS_I(inode)), extent_start,
+			  "unknown file extent item type %d, inode %llu, offset %llu, "
+			  "root %llu", type, btrfs_ino(inode), extent_start,
 			  root->root_key.objectid);
 	}
 }

commit 70ddc553b5522b96e65a162be1cecba532630841
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:50:35 2017 +0200

    btrfs: make btrfs_is_free_space_inode take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f7b9a92ad56d..a8a0dd217084 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -214,7 +214,7 @@ static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 	 * read from the commit root and sidestep a nasty deadlock
 	 * between reading the free space cache and updating the csum tree.
 	 */
-	if (btrfs_is_free_space_inode(inode)) {
+	if (btrfs_is_free_space_inode(BTRFS_I(inode))) {
 		path->search_commit_root = 1;
 		path->skip_locking = 1;
 	}

commit 6f546216e9f9e95d6783547ce6113eb13e2daa54
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Jan 28 01:47:56 2017 +0000

    Btrfs: bulk delete checksum items in the same leaf
    
    Very often we have the checksums for an extent spread in multiple items
    in the checksums tree, and currently the algorithm to delete them starts
    by looking for them one by one and then deleting them one by one, which
    is not optimal since each deletion involves shifting all the other items
    in the leaf and when the leaf reaches some low threshold, to move items
    off the leaf into its left and right neighbor leafs. Also, after each
    item deletion we release our search path and start a new search for other
    checksums items.
    
    So optimize this by deleting in bulk all the items in the same leaf that
    contain checksums for the extent being freed.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f7b9a92ad56d..e35df48b4383 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -643,7 +643,33 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 
 		/* delete the entire item, it is inside our range */
 		if (key.offset >= bytenr && csum_end <= end_byte) {
-			ret = btrfs_del_item(trans, root, path);
+			int del_nr = 1;
+
+			/*
+			 * Check how many csum items preceding this one in this
+			 * leaf correspond to our range and then delete them all
+			 * at once.
+			 */
+			if (key.offset > bytenr && path->slots[0] > 0) {
+				int slot = path->slots[0] - 1;
+
+				while (slot >= 0) {
+					struct btrfs_key pk;
+
+					btrfs_item_key_to_cpu(leaf, &pk, slot);
+					if (pk.offset < bytenr ||
+					    pk.type != BTRFS_EXTENT_CSUM_KEY ||
+					    pk.objectid !=
+					    BTRFS_EXTENT_CSUM_OBJECTID)
+						break;
+					path->slots[0] = slot;
+					del_nr++;
+					key.offset = pk.offset;
+					slot--;
+				}
+			}
+			ret = btrfs_del_items(trans, root, path,
+					      path->slots[0], del_nr);
 			if (ret)
 				goto out;
 			if (key.offset == bytenr)

commit 4a0cc7ca6c40b607b8aaa0bf6e97ffd74d64c2d8
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Tue Jan 10 20:35:31 2017 +0200

    btrfs: Make btrfs_ino take a struct btrfs_inode
    
    Currently btrfs_ino takes a struct inode and this causes a lot of
    internal btrfs functions which consume this ino to take a VFS inode,
    rather than btrfs' own struct btrfs_inode. In order to fix this "leak"
    of VFS structs into the internals of btrfs first it's necessary to
    eliminate all uses of struct inode for the purpose of inode. This patch
    does that by using BTRFS_I to convert an inode to btrfs_inode. With
    this problem eliminated subsequent patches will start eliminating the
    passing of struct inode altogether, eventually resulting in a lot cleaner
    code.
    
    Signed-off-by: Nikolay Borisov <n.borisov.lkml@gmail.com>
    [ fix btrfs_get_extent tracepoint prototype ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 42a97c910302..f7b9a92ad56d 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -255,7 +255,7 @@ static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 				} else {
 					btrfs_info_rl(fs_info,
 						   "no csum found for inode %llu start %llu",
-					       btrfs_ino(inode), offset);
+					       btrfs_ino(BTRFS_I(inode)), offset);
 				}
 				item = NULL;
 				btrfs_release_path(path);
@@ -977,7 +977,7 @@ void btrfs_extent_item_to_extent_map(struct inode *inode,
 	} else {
 		btrfs_err(fs_info,
 			  "unknown file extent item type %d, inode %llu, offset %llu, root %llu",
-			  type, btrfs_ino(inode), extent_start,
+			  type, btrfs_ino(BTRFS_I(inode)), extent_start,
 			  root->root_key.objectid);
 	}
 }

commit 50d0446e68fa0b687bd06288cc6cc25c475ab3fb
Author: Seraphime Kirkovski <kirkseraph@gmail.com>
Date:   Thu Dec 15 14:38:28 2016 +0100

    Btrfs: code cleanup min/max -> min_t/max_t
    
    This cleans up the cases where the min/max macros were used with a cast
    rather than using directly min_t/max_t.
    
    Signed-off-by: Seraphime Kirkovski <kirkseraph@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index e97e322c28f0..42a97c910302 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -856,8 +856,8 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		tmp = min(tmp, (next_offset - file_key.offset) >>
 					 fs_info->sb->s_blocksize_bits);
 
-		tmp = max((u64)1, tmp);
-		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(fs_info, csum_size));
+		tmp = max_t(u64, 1, tmp);
+		tmp = min_t(u64, tmp, MAX_CSUM_ITEMS(fs_info, csum_size));
 		ins_size = csum_size * tmp;
 	} else {
 		ins_size = csum_size;

commit 2ff7e61e0d30ff166a2ae94575526bffe11fd1a8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:24 2016 -0400

    btrfs: take an fs_info directly when the root is not used otherwise
    
    There are loads of functions in btrfs that accept a root parameter
    but only use it to obtain an fs_info pointer.  Let's convert those to
    just accept an fs_info pointer directly.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 672a36554363..e97e322c28f0 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -160,8 +160,7 @@ static void btrfs_io_bio_endio_readpage(struct btrfs_io_bio *bio, int err)
 	kfree(bio->csum_allocated);
 }
 
-static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
-				   struct inode *inode, struct bio *bio,
+static int __btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio,
 				   u64 logical_offset, u32 *dst, int dio)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
@@ -304,16 +303,14 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	return 0;
 }
 
-int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
-			  struct bio *bio, u32 *dst)
+int btrfs_lookup_bio_sums(struct inode *inode, struct bio *bio, u32 *dst)
 {
-	return __btrfs_lookup_bio_sums(root, inode, bio, 0, dst, 0);
+	return __btrfs_lookup_bio_sums(inode, bio, 0, dst, 0);
 }
 
-int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
-			      struct bio *bio, u64 offset)
+int btrfs_lookup_bio_sums_dio(struct inode *inode, struct bio *bio, u64 offset)
 {
-	return __btrfs_lookup_bio_sums(root, inode, bio, offset, NULL, 1);
+	return __btrfs_lookup_bio_sums(inode, bio, offset, NULL, 1);
 }
 
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
@@ -436,8 +433,8 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	return ret;
 }
 
-int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
-		       struct bio *bio, u64 file_start, int contig)
+int btrfs_csum_one_bio(struct inode *inode, struct bio *bio,
+		       u64 file_start, int contig)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	struct btrfs_ordered_sum *sums;
@@ -543,12 +540,11 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
  * This calls btrfs_truncate_item with the correct args based on the
  * overlap, and fixes up the key as required.
  */
-static noinline void truncate_one_csum(struct btrfs_root *root,
+static noinline void truncate_one_csum(struct btrfs_fs_info *fs_info,
 				       struct btrfs_path *path,
 				       struct btrfs_key *key,
 				       u64 bytenr, u64 len)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct extent_buffer *leaf;
 	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 	u64 csum_end;
@@ -569,7 +565,7 @@ static noinline void truncate_one_csum(struct btrfs_root *root,
 		 */
 		u32 new_size = (bytenr - key->offset) >> blocksize_bits;
 		new_size *= csum_size;
-		btrfs_truncate_item(root, path, new_size, 1);
+		btrfs_truncate_item(fs_info, path, new_size, 1);
 	} else if (key->offset >= bytenr && csum_end > end_byte &&
 		   end_byte > key->offset) {
 		/*
@@ -581,7 +577,7 @@ static noinline void truncate_one_csum(struct btrfs_root *root,
 		u32 new_size = (csum_end - end_byte) >> blocksize_bits;
 		new_size *= csum_size;
 
-		btrfs_truncate_item(root, path, new_size, 0);
+		btrfs_truncate_item(fs_info, path, new_size, 0);
 
 		key->offset = end_byte;
 		btrfs_set_item_key_safe(fs_info, path, key);
@@ -698,7 +694,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 
 			key.offset = end_byte - 1;
 		} else {
-			truncate_one_csum(root, path, &key, bytenr, len);
+			truncate_one_csum(fs_info, path, &key, bytenr, len);
 			if (key.offset < bytenr)
 				break;
 		}
@@ -824,11 +820,11 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		u32 diff;
 		u32 free_space;
 
-		if (btrfs_leaf_free_space(root, leaf) <
+		if (btrfs_leaf_free_space(fs_info, leaf) <
 				 sizeof(struct btrfs_item) + csum_size * 2)
 			goto insert;
 
-		free_space = btrfs_leaf_free_space(root, leaf) -
+		free_space = btrfs_leaf_free_space(fs_info, leaf) -
 					 sizeof(struct btrfs_item) - csum_size;
 		tmp = sums->len - total_bytes;
 		tmp >>= fs_info->sb->s_blocksize_bits;
@@ -844,7 +840,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		diff /= csum_size;
 		diff *= csum_size;
 
-		btrfs_extend_item(root, path, diff);
+		btrfs_extend_item(fs_info, path, diff);
 		ret = 0;
 		goto csum;
 	}

commit 0b246afa62b0cf5b09d078121f543135f28492ad
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:23 2016 -0400

    btrfs: root->fs_info cleanup, add fs_info convenience variables
    
    In routines where someptr->fs_info is referenced multiple times, we
    introduce a convenience variable.  This makes the code considerably
    more readable.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 5349e8e9bbaa..672a36554363 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -90,13 +90,14 @@ btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 		  struct btrfs_path *path,
 		  u64 bytenr, int cow)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	int ret;
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
 	struct btrfs_csum_item *item;
 	struct extent_buffer *leaf;
 	u64 csum_offset = 0;
-	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 	int csums_in_item;
 
 	file_key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
@@ -116,7 +117,7 @@ btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 			goto fail;
 
 		csum_offset = (bytenr - found_key.offset) >>
-				root->fs_info->sb->s_blocksize_bits;
+				fs_info->sb->s_blocksize_bits;
 		csums_in_item = btrfs_item_size_nr(leaf, path->slots[0]);
 		csums_in_item /= csum_size;
 
@@ -163,6 +164,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				   struct inode *inode, struct bio *bio,
 				   u64 logical_offset, u32 *dst, int dio)
 {
+	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	struct bio_vec *bvec;
 	struct btrfs_io_bio *btrfs_bio = btrfs_io_bio(bio);
 	struct btrfs_csum_item *item = NULL;
@@ -177,7 +179,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	u32 diff;
 	int nblocks;
 	int count = 0, i;
-	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 
 	path = btrfs_alloc_path();
 	if (!path)
@@ -241,7 +243,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 
 			if (item)
 				btrfs_release_path(path);
-			item = btrfs_lookup_csum(NULL, root->fs_info->csum_root,
+			item = btrfs_lookup_csum(NULL, fs_info->csum_root,
 						 path, disk_bytenr, 0);
 			if (IS_ERR(item)) {
 				count = 1;
@@ -249,10 +251,10 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				if (BTRFS_I(inode)->root->root_key.objectid ==
 				    BTRFS_DATA_RELOC_TREE_OBJECTID) {
 					set_extent_bits(io_tree, offset,
-						offset + root->fs_info->sectorsize - 1,
+						offset + fs_info->sectorsize - 1,
 						EXTENT_NODATASUM);
 				} else {
-					btrfs_info_rl(BTRFS_I(inode)->root->fs_info,
+					btrfs_info_rl(fs_info,
 						   "no csum found for inode %llu start %llu",
 					       btrfs_ino(inode), offset);
 				}
@@ -268,7 +270,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 						       path->slots[0]);
 			item_last_offset = item_start_offset +
 				(item_size / csum_size) *
-				root->fs_info->sectorsize;
+				fs_info->sectorsize;
 			item = btrfs_item_ptr(path->nodes[0], path->slots[0],
 					      struct btrfs_csum_item);
 		}
@@ -277,7 +279,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 		 * a single leaf so it will also fit inside a u32
 		 */
 		diff = disk_bytenr - item_start_offset;
-		diff = diff / root->fs_info->sectorsize;
+		diff = diff / fs_info->sectorsize;
 		diff = diff * csum_size;
 		count = min_t(int, nblocks, (item_last_offset - disk_bytenr) >>
 					    inode->i_sb->s_blocksize_bits);
@@ -289,9 +291,9 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 		nblocks -= count;
 next:
 		while (count--) {
-			disk_bytenr += root->fs_info->sectorsize;
-			offset += root->fs_info->sectorsize;
-			page_bytes_left -= root->fs_info->sectorsize;
+			disk_bytenr += fs_info->sectorsize;
+			offset += fs_info->sectorsize;
+			page_bytes_left -= fs_info->sectorsize;
 			if (!page_bytes_left)
 				break; /* move to next bio */
 		}
@@ -317,6 +319,7 @@ int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			     struct list_head *list, int search_commit)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_key key;
 	struct btrfs_path *path;
 	struct extent_buffer *leaf;
@@ -327,10 +330,10 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	int ret;
 	size_t size;
 	u64 csum_end;
-	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 
-	ASSERT(IS_ALIGNED(start, root->fs_info->sectorsize) &&
-	       IS_ALIGNED(end + 1, root->fs_info->sectorsize));
+	ASSERT(IS_ALIGNED(start, fs_info->sectorsize) &&
+	       IS_ALIGNED(end + 1, fs_info->sectorsize));
 
 	path = btrfs_alloc_path();
 	if (!path)
@@ -355,7 +358,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 		if (key.objectid == BTRFS_EXTENT_CSUM_OBJECTID &&
 		    key.type == BTRFS_EXTENT_CSUM_KEY) {
 			offset = (start - key.offset) >>
-				 root->fs_info->sb->s_blocksize_bits;
+				 fs_info->sb->s_blocksize_bits;
 			if (offset * csum_size <
 			    btrfs_item_size_nr(leaf, path->slots[0] - 1))
 				path->slots[0]--;
@@ -383,7 +386,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			start = key.offset;
 
 		size = btrfs_item_size_nr(leaf, path->slots[0]);
-		csum_end = key.offset + (size / csum_size) * root->fs_info->sectorsize;
+		csum_end = key.offset + (size / csum_size) * fs_info->sectorsize;
 		if (csum_end <= start) {
 			path->slots[0]++;
 			continue;
@@ -394,9 +397,8 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 				      struct btrfs_csum_item);
 		while (start < csum_end) {
 			size = min_t(size_t, csum_end - start,
-				     MAX_ORDERED_SUM_BYTES(root->fs_info));
-			sums = kzalloc(btrfs_ordered_sum_size(root->fs_info,
-							      size),
+				     MAX_ORDERED_SUM_BYTES(fs_info));
+			sums = kzalloc(btrfs_ordered_sum_size(fs_info, size),
 				       GFP_NOFS);
 			if (!sums) {
 				ret = -ENOMEM;
@@ -407,16 +409,16 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			sums->len = (int)size;
 
 			offset = (start - key.offset) >>
-				root->fs_info->sb->s_blocksize_bits;
+				fs_info->sb->s_blocksize_bits;
 			offset *= csum_size;
-			size >>= root->fs_info->sb->s_blocksize_bits;
+			size >>= fs_info->sb->s_blocksize_bits;
 
 			read_extent_buffer(path->nodes[0],
 					   sums->sums,
 					   ((unsigned long)item) + offset,
 					   csum_size * size);
 
-			start += root->fs_info->sectorsize * size;
+			start += fs_info->sectorsize * size;
 			list_add_tail(&sums->list, &tmplist);
 		}
 		path->slots[0]++;
@@ -437,6 +439,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio, u64 file_start, int contig)
 {
+	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	struct btrfs_ordered_sum *sums;
 	struct btrfs_ordered_extent *ordered = NULL;
 	char *data;
@@ -449,8 +452,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	u64 offset;
 
 	WARN_ON(bio->bi_vcnt <= 0);
-	sums = kzalloc(btrfs_ordered_sum_size(root->fs_info,
-					      bio->bi_iter.bi_size),
+	sums = kzalloc(btrfs_ordered_sum_size(fs_info, bio->bi_iter.bi_size),
 		       GFP_NOFS);
 	if (!sums)
 		return -ENOMEM;
@@ -477,9 +479,9 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 
 		data = kmap_atomic(bvec->bv_page);
 
-		nr_sectors = BTRFS_BYTES_TO_BLKS(root->fs_info,
-						bvec->bv_len + root->fs_info->sectorsize
-						- 1);
+		nr_sectors = BTRFS_BYTES_TO_BLKS(fs_info,
+						 bvec->bv_len + fs_info->sectorsize
+						 - 1);
 
 		for (i = 0; i < nr_sectors; i++) {
 			if (offset >= ordered->file_offset + ordered->len ||
@@ -494,8 +496,8 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 
 				bytes_left = bio->bi_iter.bi_size - total_bytes;
 
-				sums = kzalloc(btrfs_ordered_sum_size(root->fs_info, bytes_left),
-					GFP_NOFS);
+				sums = kzalloc(btrfs_ordered_sum_size(fs_info, bytes_left),
+					       GFP_NOFS);
 				BUG_ON(!sums); /* -ENOMEM */
 				sums->len = bytes_left;
 				ordered = btrfs_lookup_ordered_extent(inode,
@@ -511,15 +513,15 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 			sums->sums[index] = ~(u32)0;
 			sums->sums[index]
 				= btrfs_csum_data(data + bvec->bv_offset
-						+ (i * root->fs_info->sectorsize),
+						+ (i * fs_info->sectorsize),
 						sums->sums[index],
-						root->fs_info->sectorsize);
+						fs_info->sectorsize);
 			btrfs_csum_final(sums->sums[index],
 					(char *)(sums->sums + index));
 			index++;
-			offset += root->fs_info->sectorsize;
-			this_sum_bytes += root->fs_info->sectorsize;
-			total_bytes += root->fs_info->sectorsize;
+			offset += fs_info->sectorsize;
+			this_sum_bytes += fs_info->sectorsize;
+			total_bytes += fs_info->sectorsize;
 		}
 
 		kunmap_atomic(data);
@@ -546,15 +548,16 @@ static noinline void truncate_one_csum(struct btrfs_root *root,
 				       struct btrfs_key *key,
 				       u64 bytenr, u64 len)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct extent_buffer *leaf;
-	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 	u64 csum_end;
 	u64 end_byte = bytenr + len;
-	u32 blocksize_bits = root->fs_info->sb->s_blocksize_bits;
+	u32 blocksize_bits = fs_info->sb->s_blocksize_bits;
 
 	leaf = path->nodes[0];
 	csum_end = btrfs_item_size_nr(leaf, path->slots[0]) / csum_size;
-	csum_end <<= root->fs_info->sb->s_blocksize_bits;
+	csum_end <<= fs_info->sb->s_blocksize_bits;
 	csum_end += key->offset;
 
 	if (key->offset < bytenr && csum_end <= end_byte) {
@@ -581,7 +584,7 @@ static noinline void truncate_one_csum(struct btrfs_root *root,
 		btrfs_truncate_item(root, path, new_size, 0);
 
 		key->offset = end_byte;
-		btrfs_set_item_key_safe(root->fs_info, path, key);
+		btrfs_set_item_key_safe(fs_info, path, key);
 	} else {
 		BUG();
 	}
@@ -601,8 +604,8 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 	u64 csum_end;
 	struct extent_buffer *leaf;
 	int ret;
-	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
-	int blocksize_bits = root->fs_info->sb->s_blocksize_bits;
+	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
+	int blocksize_bits = fs_info->sb->s_blocksize_bits;
 
 	path = btrfs_alloc_path();
 	if (!path)
@@ -711,6 +714,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
 	struct btrfs_path *path;
@@ -726,7 +730,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	int index = 0;
 	int found_next;
 	int ret;
-	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 
 	path = btrfs_alloc_path();
 	if (!path)
@@ -759,7 +763,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		leaf = path->nodes[0];
 		item_size = btrfs_item_size_nr(leaf, path->slots[0]);
 		if ((item_size / csum_size) >=
-		    MAX_CSUM_ITEMS(root->fs_info, csum_size)) {
+		    MAX_CSUM_ITEMS(fs_info, csum_size)) {
 			/* already at max size, make a new one */
 			goto insert;
 		}
@@ -805,11 +809,11 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	leaf = path->nodes[0];
 	btrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);
 	csum_offset = (bytenr - found_key.offset) >>
-			root->fs_info->sb->s_blocksize_bits;
+			fs_info->sb->s_blocksize_bits;
 
 	if (found_key.type != BTRFS_EXTENT_CSUM_KEY ||
 	    found_key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
-	    csum_offset >= MAX_CSUM_ITEMS(root->fs_info, csum_size)) {
+	    csum_offset >= MAX_CSUM_ITEMS(fs_info, csum_size)) {
 		goto insert;
 	}
 
@@ -827,12 +831,13 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		free_space = btrfs_leaf_free_space(root, leaf) -
 					 sizeof(struct btrfs_item) - csum_size;
 		tmp = sums->len - total_bytes;
-		tmp >>= root->fs_info->sb->s_blocksize_bits;
+		tmp >>= fs_info->sb->s_blocksize_bits;
 		WARN_ON(tmp < 1);
 
 		extend_nr = max_t(int, 1, (int)tmp);
 		diff = (csum_offset + extend_nr) * csum_size;
-		diff = min(diff, MAX_CSUM_ITEMS(root->fs_info, csum_size) * csum_size);
+		diff = min(diff,
+			   MAX_CSUM_ITEMS(fs_info, csum_size) * csum_size);
 
 		diff = diff - btrfs_item_size_nr(leaf, path->slots[0]);
 		diff = min(free_space, diff);
@@ -851,12 +856,12 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		u64 tmp;
 
 		tmp = sums->len - total_bytes;
-		tmp >>= root->fs_info->sb->s_blocksize_bits;
+		tmp >>= fs_info->sb->s_blocksize_bits;
 		tmp = min(tmp, (next_offset - file_key.offset) >>
-					 root->fs_info->sb->s_blocksize_bits);
+					 fs_info->sb->s_blocksize_bits);
 
 		tmp = max((u64)1, tmp);
-		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(root->fs_info, csum_size));
+		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(fs_info, csum_size));
 		ins_size = csum_size * tmp;
 	} else {
 		ins_size = csum_size;
@@ -878,7 +883,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 					  csum_offset * csum_size);
 found:
 	ins_size = (u32)(sums->len - total_bytes) >>
-		   root->fs_info->sb->s_blocksize_bits;
+		   fs_info->sb->s_blocksize_bits;
 	ins_size *= csum_size;
 	ins_size = min_t(u32, (unsigned long)item_end - (unsigned long)item,
 			      ins_size);
@@ -886,7 +891,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			    ins_size);
 
 	ins_size /= csum_size;
-	total_bytes += ins_size * root->fs_info->sectorsize;
+	total_bytes += ins_size * fs_info->sectorsize;
 	index += ins_size;
 
 	btrfs_mark_buffer_dirty(path->nodes[0]);
@@ -909,6 +914,7 @@ void btrfs_extent_item_to_extent_map(struct inode *inode,
 				     const bool new_inline,
 				     struct extent_map *em)
 {
+	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	struct btrfs_root *root = BTRFS_I(inode)->root;
 	struct extent_buffer *leaf = path->nodes[0];
 	const int slot = path->slots[0];
@@ -918,7 +924,7 @@ void btrfs_extent_item_to_extent_map(struct inode *inode,
 	u8 type = btrfs_file_extent_type(leaf, fi);
 	int compress_type = btrfs_file_extent_compression(leaf, fi);
 
-	em->bdev = root->fs_info->fs_devices->latest_bdev;
+	em->bdev = fs_info->fs_devices->latest_bdev;
 	btrfs_item_key_to_cpu(leaf, &key, slot);
 	extent_start = key.offset;
 
@@ -930,7 +936,7 @@ void btrfs_extent_item_to_extent_map(struct inode *inode,
 		size_t size;
 		size = btrfs_file_extent_inline_len(leaf, slot, fi);
 		extent_end = ALIGN(extent_start + size,
-				   root->fs_info->sectorsize);
+				   fs_info->sectorsize);
 	}
 
 	em->ram_bytes = btrfs_file_extent_ram_bytes(leaf, fi);
@@ -973,7 +979,7 @@ void btrfs_extent_item_to_extent_map(struct inode *inode,
 			em->compress_type = compress_type;
 		}
 	} else {
-		btrfs_err(root->fs_info,
+		btrfs_err(fs_info,
 			  "unknown file extent item type %d, inode %llu, offset %llu, root %llu",
 			  type, btrfs_ino(inode), extent_start,
 			  root->root_key.objectid);

commit da17066c40472c2d6a1aab7bb0090c3d285531c9
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 09:22:56 2016 -0400

    btrfs: pull node/sector/stripe sizes out of root and into fs_info
    
    We track the node sizes per-root, but they never vary from the values
    in the superblock.  This patch messes with the 80-column style a bit,
    but subsequent patches to factor out root->fs_info into a convenience
    variable fix it up again.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 41c1145cbce1..5349e8e9bbaa 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -34,9 +34,9 @@
 #define MAX_CSUM_ITEMS(r, size) (min_t(u32, __MAX_CSUM_ITEMS(r, size), \
 				       PAGE_SIZE))
 
-#define MAX_ORDERED_SUM_BYTES(r) ((PAGE_SIZE - \
+#define MAX_ORDERED_SUM_BYTES(fs_info) ((PAGE_SIZE - \
 				   sizeof(struct btrfs_ordered_sum)) / \
-				   sizeof(u32) * (r)->sectorsize)
+				   sizeof(u32) * (fs_info)->sectorsize)
 
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
@@ -249,7 +249,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				if (BTRFS_I(inode)->root->root_key.objectid ==
 				    BTRFS_DATA_RELOC_TREE_OBJECTID) {
 					set_extent_bits(io_tree, offset,
-						offset + root->sectorsize - 1,
+						offset + root->fs_info->sectorsize - 1,
 						EXTENT_NODATASUM);
 				} else {
 					btrfs_info_rl(BTRFS_I(inode)->root->fs_info,
@@ -268,7 +268,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 						       path->slots[0]);
 			item_last_offset = item_start_offset +
 				(item_size / csum_size) *
-				root->sectorsize;
+				root->fs_info->sectorsize;
 			item = btrfs_item_ptr(path->nodes[0], path->slots[0],
 					      struct btrfs_csum_item);
 		}
@@ -277,7 +277,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 		 * a single leaf so it will also fit inside a u32
 		 */
 		diff = disk_bytenr - item_start_offset;
-		diff = diff / root->sectorsize;
+		diff = diff / root->fs_info->sectorsize;
 		diff = diff * csum_size;
 		count = min_t(int, nblocks, (item_last_offset - disk_bytenr) >>
 					    inode->i_sb->s_blocksize_bits);
@@ -289,9 +289,9 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 		nblocks -= count;
 next:
 		while (count--) {
-			disk_bytenr += root->sectorsize;
-			offset += root->sectorsize;
-			page_bytes_left -= root->sectorsize;
+			disk_bytenr += root->fs_info->sectorsize;
+			offset += root->fs_info->sectorsize;
+			page_bytes_left -= root->fs_info->sectorsize;
 			if (!page_bytes_left)
 				break; /* move to next bio */
 		}
@@ -329,8 +329,8 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	u64 csum_end;
 	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 
-	ASSERT(IS_ALIGNED(start, root->sectorsize) &&
-	       IS_ALIGNED(end + 1, root->sectorsize));
+	ASSERT(IS_ALIGNED(start, root->fs_info->sectorsize) &&
+	       IS_ALIGNED(end + 1, root->fs_info->sectorsize));
 
 	path = btrfs_alloc_path();
 	if (!path)
@@ -383,7 +383,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			start = key.offset;
 
 		size = btrfs_item_size_nr(leaf, path->slots[0]);
-		csum_end = key.offset + (size / csum_size) * root->sectorsize;
+		csum_end = key.offset + (size / csum_size) * root->fs_info->sectorsize;
 		if (csum_end <= start) {
 			path->slots[0]++;
 			continue;
@@ -394,8 +394,9 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 				      struct btrfs_csum_item);
 		while (start < csum_end) {
 			size = min_t(size_t, csum_end - start,
-				     MAX_ORDERED_SUM_BYTES(root));
-			sums = kzalloc(btrfs_ordered_sum_size(root, size),
+				     MAX_ORDERED_SUM_BYTES(root->fs_info));
+			sums = kzalloc(btrfs_ordered_sum_size(root->fs_info,
+							      size),
 				       GFP_NOFS);
 			if (!sums) {
 				ret = -ENOMEM;
@@ -415,7 +416,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 					   ((unsigned long)item) + offset,
 					   csum_size * size);
 
-			start += root->sectorsize * size;
+			start += root->fs_info->sectorsize * size;
 			list_add_tail(&sums->list, &tmplist);
 		}
 		path->slots[0]++;
@@ -448,7 +449,8 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	u64 offset;
 
 	WARN_ON(bio->bi_vcnt <= 0);
-	sums = kzalloc(btrfs_ordered_sum_size(root, bio->bi_iter.bi_size),
+	sums = kzalloc(btrfs_ordered_sum_size(root->fs_info,
+					      bio->bi_iter.bi_size),
 		       GFP_NOFS);
 	if (!sums)
 		return -ENOMEM;
@@ -476,7 +478,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		data = kmap_atomic(bvec->bv_page);
 
 		nr_sectors = BTRFS_BYTES_TO_BLKS(root->fs_info,
-						bvec->bv_len + root->sectorsize
+						bvec->bv_len + root->fs_info->sectorsize
 						- 1);
 
 		for (i = 0; i < nr_sectors; i++) {
@@ -492,7 +494,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 
 				bytes_left = bio->bi_iter.bi_size - total_bytes;
 
-				sums = kzalloc(btrfs_ordered_sum_size(root, bytes_left),
+				sums = kzalloc(btrfs_ordered_sum_size(root->fs_info, bytes_left),
 					GFP_NOFS);
 				BUG_ON(!sums); /* -ENOMEM */
 				sums->len = bytes_left;
@@ -509,15 +511,15 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 			sums->sums[index] = ~(u32)0;
 			sums->sums[index]
 				= btrfs_csum_data(data + bvec->bv_offset
-						+ (i * root->sectorsize),
+						+ (i * root->fs_info->sectorsize),
 						sums->sums[index],
-						root->sectorsize);
+						root->fs_info->sectorsize);
 			btrfs_csum_final(sums->sums[index],
 					(char *)(sums->sums + index));
 			index++;
-			offset += root->sectorsize;
-			this_sum_bytes += root->sectorsize;
-			total_bytes += root->sectorsize;
+			offset += root->fs_info->sectorsize;
+			this_sum_bytes += root->fs_info->sectorsize;
+			total_bytes += root->fs_info->sectorsize;
 		}
 
 		kunmap_atomic(data);
@@ -757,7 +759,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		leaf = path->nodes[0];
 		item_size = btrfs_item_size_nr(leaf, path->slots[0]);
 		if ((item_size / csum_size) >=
-		    MAX_CSUM_ITEMS(root, csum_size)) {
+		    MAX_CSUM_ITEMS(root->fs_info, csum_size)) {
 			/* already at max size, make a new one */
 			goto insert;
 		}
@@ -807,7 +809,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 
 	if (found_key.type != BTRFS_EXTENT_CSUM_KEY ||
 	    found_key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
-	    csum_offset >= MAX_CSUM_ITEMS(root, csum_size)) {
+	    csum_offset >= MAX_CSUM_ITEMS(root->fs_info, csum_size)) {
 		goto insert;
 	}
 
@@ -830,7 +832,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 
 		extend_nr = max_t(int, 1, (int)tmp);
 		diff = (csum_offset + extend_nr) * csum_size;
-		diff = min(diff, MAX_CSUM_ITEMS(root, csum_size) * csum_size);
+		diff = min(diff, MAX_CSUM_ITEMS(root->fs_info, csum_size) * csum_size);
 
 		diff = diff - btrfs_item_size_nr(leaf, path->slots[0]);
 		diff = min(free_space, diff);
@@ -854,7 +856,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 					 root->fs_info->sb->s_blocksize_bits);
 
 		tmp = max((u64)1, tmp);
-		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(root, csum_size));
+		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(root->fs_info, csum_size));
 		ins_size = csum_size * tmp;
 	} else {
 		ins_size = csum_size;
@@ -884,7 +886,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			    ins_size);
 
 	ins_size /= csum_size;
-	total_bytes += ins_size * root->sectorsize;
+	total_bytes += ins_size * root->fs_info->sectorsize;
 	index += ins_size;
 
 	btrfs_mark_buffer_dirty(path->nodes[0]);
@@ -927,7 +929,8 @@ void btrfs_extent_item_to_extent_map(struct inode *inode,
 	} else if (type == BTRFS_FILE_EXTENT_INLINE) {
 		size_t size;
 		size = btrfs_file_extent_inline_len(leaf, slot, fi);
-		extent_end = ALIGN(extent_start + size, root->sectorsize);
+		extent_end = ALIGN(extent_start + size,
+				   root->fs_info->sectorsize);
 	}
 
 	em->ram_bytes = btrfs_file_extent_ram_bytes(leaf, fi);

commit 5b4aacefb8fbfc996e68b9b083d30f8bc0972449
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jun 21 10:40:19 2016 -0400

    btrfs: call functions that overwrite their root parameter with fs_info
    
    There are 11 functions that accept a root parameter and immediately
    overwrite it.  We can pass those an fs_info pointer instead.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 5e74178ba9d9..41c1145cbce1 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -590,8 +590,9 @@ static noinline void truncate_one_csum(struct btrfs_root *root,
  * range of bytes.
  */
 int btrfs_del_csums(struct btrfs_trans_handle *trans,
-		    struct btrfs_root *root, u64 bytenr, u64 len)
+		    struct btrfs_fs_info *fs_info, u64 bytenr, u64 len)
 {
+	struct btrfs_root *root = fs_info->csum_root;
 	struct btrfs_path *path;
 	struct btrfs_key key;
 	u64 end_byte = bytenr + len;
@@ -601,8 +602,6 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 	int blocksize_bits = root->fs_info->sb->s_blocksize_bits;
 
-	root = root->fs_info->csum_root;
-
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;

commit 4989d277eb4b36cc1aacf72725b53977c6b5260d
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Nov 25 09:07:52 2016 +0100

    btrfs: refactor __btrfs_lookup_bio_sums to use bio_for_each_segment_all
    
    Rework the loop a little bit to use the generic bio_for_each_segment_all
    helper for iterating over the bio.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index fad3804fc335..5e74178ba9d9 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -163,7 +163,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				   struct inode *inode, struct bio *bio,
 				   u64 logical_offset, u32 *dst, int dio)
 {
-	struct bio_vec *bvec = bio->bi_io_vec;
+	struct bio_vec *bvec;
 	struct btrfs_io_bio *btrfs_bio = btrfs_io_bio(bio);
 	struct btrfs_csum_item *item = NULL;
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
@@ -176,8 +176,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	u64 page_bytes_left;
 	u32 diff;
 	int nblocks;
-	int bio_index = 0;
-	int count;
+	int count = 0, i;
 	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 
 	path = btrfs_alloc_path();
@@ -223,8 +222,11 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	if (dio)
 		offset = logical_offset;
 
-	page_bytes_left = bvec->bv_len;
-	while (bio_index < bio->bi_vcnt) {
+	bio_for_each_segment_all(bvec, bio, i) {
+		page_bytes_left = bvec->bv_len;
+		if (count)
+			goto next;
+
 		if (!dio)
 			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 		count = btrfs_find_ordered_sum(inode, offset, disk_bytenr,
@@ -285,29 +287,17 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 found:
 		csum += count * csum_size;
 		nblocks -= count;
-
+next:
 		while (count--) {
 			disk_bytenr += root->sectorsize;
 			offset += root->sectorsize;
 			page_bytes_left -= root->sectorsize;
-			if (!page_bytes_left) {
-				bio_index++;
-				/*
-				 * make sure we're still inside the
-				 * bio before we update page_bytes_left
-				 */
-				if (bio_index >= bio->bi_vcnt) {
-					WARN_ON_ONCE(count);
-					goto done;
-				}
-				bvec++;
-				page_bytes_left = bvec->bv_len;
-			}
-
+			if (!page_bytes_left)
+				break; /* move to next bio */
 		}
 	}
 
-done:
+	WARN_ON_ONCE(count);
 	btrfs_free_path(path);
 	return 0;
 }

commit 6cd7ce4935485c203e0bda815dbabb50e30f31e9
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Nov 25 09:07:49 2016 +0100

    btrfs: don't access the bio directly in btrfs_csum_one_bio
    
    Use bio_for_each_segment_all to iterate over the segments instead.
    This requires a bit of reshuffling so that we only lookup up the ordered
    item once inside the bio_for_each_segment_all loop.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 43418c08b110..fad3804fc335 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -447,13 +447,12 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio, u64 file_start, int contig)
 {
 	struct btrfs_ordered_sum *sums;
-	struct btrfs_ordered_extent *ordered;
+	struct btrfs_ordered_extent *ordered = NULL;
 	char *data;
-	struct bio_vec *bvec = bio->bi_io_vec;
-	int bio_index = 0;
+	struct bio_vec *bvec;
 	int index;
 	int nr_sectors;
-	int i;
+	int i, j;
 	unsigned long total_bytes = 0;
 	unsigned long this_sum_bytes = 0;
 	u64 offset;
@@ -470,17 +469,20 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	if (contig)
 		offset = file_start;
 	else
-		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+		offset = 0; /* shut up gcc */
 
-	ordered = btrfs_lookup_ordered_extent(inode, offset);
-	BUG_ON(!ordered); /* Logic error */
 	sums->bytenr = (u64)bio->bi_iter.bi_sector << 9;
 	index = 0;
 
-	while (bio_index < bio->bi_vcnt) {
+	bio_for_each_segment_all(bvec, bio, j) {
 		if (!contig)
 			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 
+		if (!ordered) {
+			ordered = btrfs_lookup_ordered_extent(inode, offset);
+			BUG_ON(!ordered); /* Logic error */
+		}
+
 		data = kmap_atomic(bvec->bv_page);
 
 		nr_sectors = BTRFS_BYTES_TO_BLKS(root->fs_info,
@@ -529,9 +531,6 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		}
 
 		kunmap_atomic(data);
-
-		bio_index++;
-		bvec++;
 	}
 	this_sum_bytes = 0;
 	btrfs_add_ordered_sum(inode, ordered, sums);

commit b159fa2808b1b53d784807a48ad95fa809be10b0
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 18:09:03 2016 +0100

    btrfs: remove constant parameter to memset_extent_buffer and rename it
    
    The only memset we do is to 0, so sink the parameter to the function and
    simplify all calls. Rename the function to reflect the behaviour.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index d0d571c47d33..43418c08b110 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -689,7 +689,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 			item_offset = btrfs_item_ptr_offset(leaf,
 							    path->slots[0]);
 
-			memset_extent_buffer(leaf, 0, item_offset + offset,
+			memzero_extent_buffer(leaf, item_offset + offset,
 					     shift_len);
 			key.offset = bytenr;
 

commit 42049bf60db4c01e0432fc861463dcd3208c0d93
Author: Chris Mason <clm@fb.com>
Date:   Wed Aug 3 14:05:46 2016 -0700

    Btrfs: fix __MAX_CSUM_ITEMS
    
    Jeff Mahoney's cleanup commit (14a1e067b4) wasn't correct for csums on
    machines where the pagesize >= metadata blocksize.
    
    This just reverts the relevant hunks to bring the old math back.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 2fc803da4680..d0d571c47d33 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -27,8 +27,9 @@
 #include "print-tree.h"
 #include "compression.h"
 
-#define __MAX_CSUM_ITEMS(r, size) \
-	((unsigned long)(((BTRFS_MAX_ITEM_SIZE(r) * 2) / size) - 1))
+#define __MAX_CSUM_ITEMS(r, size) ((unsigned long)(((BTRFS_LEAF_DATA_SIZE(r) - \
+				   sizeof(struct btrfs_item) * 2) / \
+				  size) - 1))
 
 #define MAX_CSUM_ITEMS(r, size) (min_t(u32, __MAX_CSUM_ITEMS(r, size), \
 				       PAGE_SIZE))

commit 66642832f06a4351e23cea6cf254967c227f8224
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Jun 10 18:19:25 2016 -0400

    btrfs: btrfs_abort_transaction, drop root parameter
    
    __btrfs_abort_transaction doesn't use its root parameter except to
    obtain an fs_info pointer.  We can obtain that from trans->root->fs_info
    for now and from trans->fs_info in a later patch.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index cdbbf85a269b..2fc803da4680 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -698,7 +698,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 			 */
 			ret = btrfs_split_item(trans, root, path, &key, offset);
 			if (ret && ret != -EAGAIN) {
-				btrfs_abort_transaction(trans, root, ret);
+				btrfs_abort_transaction(trans, ret);
 				goto out;
 			}
 

commit 14a1e067b45614d6236e3c82b36f62caef44ac62
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 10:25:38 2016 -0400

    btrfs: introduce BTRFS_MAX_ITEM_SIZE
    
    We use BTRFS_LEAF_DATA_SIZE - sizeof(struct btrfs_item) in
    several places.  This introduces a BTRFS_MAX_ITEM_SIZE macro to do the
    same.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 6b58d0620e2f..cdbbf85a269b 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -27,9 +27,8 @@
 #include "print-tree.h"
 #include "compression.h"
 
-#define __MAX_CSUM_ITEMS(r, size) ((unsigned long)(((BTRFS_LEAF_DATA_SIZE(r) - \
-				   sizeof(struct btrfs_item) * 2) / \
-				  size) - 1))
+#define __MAX_CSUM_ITEMS(r, size) \
+	((unsigned long)(((BTRFS_MAX_ITEM_SIZE(r) * 2) / size) - 1))
 
 #define MAX_CSUM_ITEMS(r, size) (min_t(u32, __MAX_CSUM_ITEMS(r, size), \
 				       PAGE_SIZE))

commit aee133afcdf77641be66c5c9f32975feca8e6bd0
Author: Nikolay Borisov <kernel@kyup.com>
Date:   Wed Jul 13 16:19:14 2016 +0300

    btrfs: Ratelimit "no csum found" info message
    
    Recently during a crash it became apparent that this particular message
    can be printed so many times that it causes the softlockup detector to
    trigger. Fix it by ratelimiting it.
    
    Signed-off-by: Nikolay Borisov <kernel@kyup.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 62a81ee13a5f..6b58d0620e2f 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -250,7 +250,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 						offset + root->sectorsize - 1,
 						EXTENT_NODATASUM);
 				} else {
-					btrfs_info(BTRFS_I(inode)->root->fs_info,
+					btrfs_info_rl(BTRFS_I(inode)->root->fs_info,
 						   "no csum found for inode %llu start %llu",
 					       btrfs_ino(inode), offset);
 				}

commit ceeb0ae7bf42a3deaaaee981d2da02e5d3ad2b0f
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to set_extent_bits
    
    All callers pass GFP_NOFS.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 7a7d6e253cfc..62a81ee13a5f 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -248,7 +248,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				    BTRFS_DATA_RELOC_TREE_OBJECTID) {
 					set_extent_bits(io_tree, offset,
 						offset + root->sectorsize - 1,
-						EXTENT_NODATASUM, GFP_NOFS);
+						EXTENT_NODATASUM);
 				} else {
 					btrfs_info(BTRFS_I(inode)->root->fs_info,
 						   "no csum found for inode %llu start %llu",

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b5baf5bdc8e1..7a7d6e253cfc 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -32,7 +32,7 @@
 				  size) - 1))
 
 #define MAX_CSUM_ITEMS(r, size) (min_t(u32, __MAX_CSUM_ITEMS(r, size), \
-				       PAGE_CACHE_SIZE))
+				       PAGE_SIZE))
 
 #define MAX_ORDERED_SUM_BYTES(r) ((PAGE_SIZE - \
 				   sizeof(struct btrfs_ordered_sum)) / \
@@ -203,7 +203,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 		csum = (u8 *)dst;
 	}
 
-	if (bio->bi_iter.bi_size > PAGE_CACHE_SIZE * 8)
+	if (bio->bi_iter.bi_size > PAGE_SIZE * 8)
 		path->reada = READA_FORWARD;
 
 	WARN_ON(bio->bi_vcnt <= 0);

commit 389f239c53420802ad5085e51e88c37e2df5e003
Author: Chris Mason <clm@fb.com>
Date:   Mon Mar 21 06:59:09 2016 -0700

    btrfs: make sure we stay inside the bvec during __btrfs_lookup_bio_sums
    
    Commit c40a3d38aff4e1c (Btrfs: Compute and look up csums based on
    sectorsized blocks) changes around how we walk the bios while looking up
    crcs.  There's an inner loop that is jumping to the next bvec based on
    sectors and before it derefs the next bvec, it needs to make sure we're
    still in the bio.
    
    In this case, the outer loop would have decided to stop moving forward
    too, and the bvec deref is never actually used for anything.  But
    CONFIG_DEBUG_PAGEALLOC catches it because we're outside our bio.
    
    Signed-off-by: Chris Mason <clm@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 763fd170ff16..b5baf5bdc8e1 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -292,12 +292,22 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 			page_bytes_left -= root->sectorsize;
 			if (!page_bytes_left) {
 				bio_index++;
+				/*
+				 * make sure we're still inside the
+				 * bio before we update page_bytes_left
+				 */
+				if (bio_index >= bio->bi_vcnt) {
+					WARN_ON_ONCE(count);
+					goto done;
+				}
 				bvec++;
 				page_bytes_left = bvec->bv_len;
 			}
 
 		}
 	}
+
+done:
 	btrfs_free_path(path);
 	return 0;
 }

commit ebb8765b2ded869b75bf5154b048119eb52571f7
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Mar 10 17:26:59 2016 +0800

    btrfs: move btrfs_compression_type to compression.h
    
    So that its better organized.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 1c50a7b09b4e..763fd170ff16 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -25,6 +25,7 @@
 #include "transaction.h"
 #include "volumes.h"
 #include "print-tree.h"
+#include "compression.h"
 
 #define __MAX_CSUM_ITEMS(r, size) ((unsigned long)(((BTRFS_LEAF_DATA_SIZE(r) - \
 				   sizeof(struct btrfs_item) * 2) / \

commit c40a3d38aff4e1c832d1692850621be7d5e5308c
Author: Chandan Rajendra <chandan@linux.vnet.ibm.com>
Date:   Thu Jan 21 15:55:54 2016 +0530

    Btrfs: Compute and look up csums based on sectorsized blocks
    
    Checksums are applicable to sectorsize units. The current code uses
    bio->bv_len units to compute and look up checksums. This works on machines
    where sectorsize == PAGE_SIZE. This patch makes the checksum computation and
    look up code to work with sectorsize units.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a67e1c828d0f..1c50a7b09b4e 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -172,6 +172,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	u64 item_start_offset = 0;
 	u64 item_last_offset = 0;
 	u64 disk_bytenr;
+	u64 page_bytes_left;
 	u32 diff;
 	int nblocks;
 	int bio_index = 0;
@@ -220,6 +221,8 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	disk_bytenr = (u64)bio->bi_iter.bi_sector << 9;
 	if (dio)
 		offset = logical_offset;
+
+	page_bytes_left = bvec->bv_len;
 	while (bio_index < bio->bi_vcnt) {
 		if (!dio)
 			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
@@ -243,7 +246,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				if (BTRFS_I(inode)->root->root_key.objectid ==
 				    BTRFS_DATA_RELOC_TREE_OBJECTID) {
 					set_extent_bits(io_tree, offset,
-						offset + bvec->bv_len - 1,
+						offset + root->sectorsize - 1,
 						EXTENT_NODATASUM, GFP_NOFS);
 				} else {
 					btrfs_info(BTRFS_I(inode)->root->fs_info,
@@ -281,11 +284,17 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 found:
 		csum += count * csum_size;
 		nblocks -= count;
-		bio_index += count;
+
 		while (count--) {
-			disk_bytenr += bvec->bv_len;
-			offset += bvec->bv_len;
-			bvec++;
+			disk_bytenr += root->sectorsize;
+			offset += root->sectorsize;
+			page_bytes_left -= root->sectorsize;
+			if (!page_bytes_left) {
+				bio_index++;
+				bvec++;
+				page_bytes_left = bvec->bv_len;
+			}
+
 		}
 	}
 	btrfs_free_path(path);
@@ -432,6 +441,8 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	struct bio_vec *bvec = bio->bi_io_vec;
 	int bio_index = 0;
 	int index;
+	int nr_sectors;
+	int i;
 	unsigned long total_bytes = 0;
 	unsigned long this_sum_bytes = 0;
 	u64 offset;
@@ -459,41 +470,56 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		if (!contig)
 			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 
-		if (offset >= ordered->file_offset + ordered->len ||
-		    offset < ordered->file_offset) {
-			unsigned long bytes_left;
-			sums->len = this_sum_bytes;
-			this_sum_bytes = 0;
-			btrfs_add_ordered_sum(inode, ordered, sums);
-			btrfs_put_ordered_extent(ordered);
+		data = kmap_atomic(bvec->bv_page);
 
-			bytes_left = bio->bi_iter.bi_size - total_bytes;
+		nr_sectors = BTRFS_BYTES_TO_BLKS(root->fs_info,
+						bvec->bv_len + root->sectorsize
+						- 1);
+
+		for (i = 0; i < nr_sectors; i++) {
+			if (offset >= ordered->file_offset + ordered->len ||
+				offset < ordered->file_offset) {
+				unsigned long bytes_left;
+
+				kunmap_atomic(data);
+				sums->len = this_sum_bytes;
+				this_sum_bytes = 0;
+				btrfs_add_ordered_sum(inode, ordered, sums);
+				btrfs_put_ordered_extent(ordered);
+
+				bytes_left = bio->bi_iter.bi_size - total_bytes;
+
+				sums = kzalloc(btrfs_ordered_sum_size(root, bytes_left),
+					GFP_NOFS);
+				BUG_ON(!sums); /* -ENOMEM */
+				sums->len = bytes_left;
+				ordered = btrfs_lookup_ordered_extent(inode,
+								offset);
+				ASSERT(ordered); /* Logic error */
+				sums->bytenr = ((u64)bio->bi_iter.bi_sector << 9)
+					+ total_bytes;
+				index = 0;
+
+				data = kmap_atomic(bvec->bv_page);
+			}
 
-			sums = kzalloc(btrfs_ordered_sum_size(root, bytes_left),
-				       GFP_NOFS);
-			BUG_ON(!sums); /* -ENOMEM */
-			sums->len = bytes_left;
-			ordered = btrfs_lookup_ordered_extent(inode, offset);
-			BUG_ON(!ordered); /* Logic error */
-			sums->bytenr = ((u64)bio->bi_iter.bi_sector << 9) +
-				       total_bytes;
-			index = 0;
+			sums->sums[index] = ~(u32)0;
+			sums->sums[index]
+				= btrfs_csum_data(data + bvec->bv_offset
+						+ (i * root->sectorsize),
+						sums->sums[index],
+						root->sectorsize);
+			btrfs_csum_final(sums->sums[index],
+					(char *)(sums->sums + index));
+			index++;
+			offset += root->sectorsize;
+			this_sum_bytes += root->sectorsize;
+			total_bytes += root->sectorsize;
 		}
 
-		data = kmap_atomic(bvec->bv_page);
-		sums->sums[index] = ~(u32)0;
-		sums->sums[index] = btrfs_csum_data(data + bvec->bv_offset,
-						    sums->sums[index],
-						    bvec->bv_len);
 		kunmap_atomic(data);
-		btrfs_csum_final(sums->sums[index],
-				 (char *)(sums->sums + index));
 
 		bio_index++;
-		index++;
-		total_bytes += bvec->bv_len;
-		this_sum_bytes += bvec->bv_len;
-		offset += bvec->bv_len;
 		bvec++;
 	}
 	this_sum_bytes = 0;

commit e4058b54d1e442b6b3eca949f0d63d49ba2b020d
Author: David Sterba <dsterba@suse.com>
Date:   Fri Nov 27 16:31:35 2015 +0100

    btrfs: cleanup, use enum values for btrfs_path reada
    
    Replace the integers by enums for better readability. The value 2 does
    not have any meaning since a717531942f488209dded30f6bc648167bcefa72
    "Btrfs: do less aggressive btree readahead" (2009-01-22).
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 58ece6558430..a67e1c828d0f 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -202,7 +202,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	}
 
 	if (bio->bi_iter.bi_size > PAGE_CACHE_SIZE * 8)
-		path->reada = 2;
+		path->reada = READA_FORWARD;
 
 	WARN_ON(bio->bi_vcnt <= 0);
 
@@ -328,7 +328,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 
 	if (search_commit) {
 		path->skip_locking = 1;
-		path->reada = 2;
+		path->reada = READA_FORWARD;
 		path->search_commit_root = 1;
 	}
 

commit fc4c3c872f44bf425963feba57eb9c3f8ac2d7eb
Merge: 9deed229fa8a a4f3d2c4efe2
Author: Chris Mason <clm@fb.com>
Date:   Wed Mar 25 10:52:48 2015 -0700

    Merge branch 'cleanups-post-3.19' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.1
    
    Signed-off-by: Chris Mason <clm@fb.com>
    
    Conflicts:
            fs/btrfs/disk-io.c

commit 31e818fe7375d60de9953051f7bd1615cebc3681
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Feb 20 18:00:26 2015 +0100

    btrfs: cleanup, use kmalloc_array/kcalloc array helpers
    
    Convert kmalloc(nr * size, ..) to kmalloc_array that does additional
    overflow checks, the zeroing variant is kcalloc.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 84a2d1868271..3a4a7924fa38 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -185,8 +185,8 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	nblocks = bio->bi_iter.bi_size >> inode->i_sb->s_blocksize_bits;
 	if (!dst) {
 		if (nblocks * csum_size > BTRFS_BIO_INLINE_CSUM_SIZE) {
-			btrfs_bio->csum_allocated = kmalloc(nblocks * csum_size,
-							    GFP_NOFS);
+			btrfs_bio->csum_allocated = kmalloc_array(nblocks,
+					csum_size, GFP_NOFS);
 			if (!btrfs_bio->csum_allocated) {
 				btrfs_free_path(path);
 				return -ENOMEM;

commit b7a0365ec7a0fb1d39113846fd34038af68ebd01
Author: Daniel Dressler <danieru.dressler@gmail.com>
Date:   Wed Nov 12 13:43:09 2014 +0900

    Btrfs: ctree: reduce args where only fs_info used
    
    This patch is part of a larger project to cleanup btrfs's internal usage
    of struct btrfs_root. Many functions take btrfs_root only to grab a
    pointer to fs_info.
    
    This causes programmers to ponder which root can be passed. Since only
    the fs_info is read affected functions can accept any root, except this
    is only obvious upon inspection.
    
    This patch reduces the specificty of such functions to accept the
    fs_info directly.
    
    This patch does not address the two functions in ctree.c (insert_ptr,
    and split_item) which only use root for BUG_ONs in ctree.c
    
    This patch affects the following functions:
      1) fixup_low_keys
      2) btrfs_set_item_key_safe
    
    Signed-off-by: Daniel Dressler <danieru.dressler@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 84a2d1868271..fc003321bdd4 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -553,7 +553,7 @@ static noinline void truncate_one_csum(struct btrfs_root *root,
 		btrfs_truncate_item(root, path, new_size, 0);
 
 		key->offset = end_byte;
-		btrfs_set_item_key_safe(root, path, key);
+		btrfs_set_item_key_safe(root->fs_info, path, key);
 	} else {
 		BUG();
 	}

commit 6e5aafb27419f32575b27ef9d6a31e5d54661aca
Author: Chris Mason <clm@fb.com>
Date:   Tue Nov 4 06:59:04 2014 -0800

    Btrfs: fix kfree on list_head in btrfs_lookup_csums_range error cleanup
    
    If we hit any errors in btrfs_lookup_csums_range, we'll loop through all
    the csums we allocate and free them.  But the code was using list_entry
    incorrectly, and ended up trying to free the on-stack list_head instead.
    
    This bug came from commit 0678b6185
    
    btrfs: Don't BUG_ON kzalloc error in btrfs_lookup_csums_range()
    
    Signed-off-by: Chris Mason <clm@fb.com>
    Reported-by: Erik Berg <btrfs@slipsprogrammoer.no>
    cc: stable@vger.kernel.org # 3.3 or newer

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 783a94355efd..84a2d1868271 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -413,7 +413,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	ret = 0;
 fail:
 	while (ret < 0 && !list_empty(&tmplist)) {
-		sums = list_entry(&tmplist, struct btrfs_ordered_sum, list);
+		sums = list_entry(tmplist.next, struct btrfs_ordered_sum, list);
 		list_del(&sums->list);
 		kfree(sums);
 	}

commit 23ea8e5a07673127d05cb5cf6f9914d7a53e0847
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 12 18:43:54 2014 +0800

    Btrfs: load checksum data once when submitting a direct read io
    
    The current code would load checksum data for several times when we split
    a whole direct read io because of the limit of the raid stripe, it would
    make us search the csum tree for several times. In fact, it just wasted time,
    and made the contention of the csum tree root be more serious. This patch
    improves this problem by loading the data at once.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 6e6262eca8b7..783a94355efd 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -299,19 +299,9 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 }
 
 int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
-			      struct btrfs_dio_private *dip, struct bio *bio,
-			      u64 offset)
+			      struct bio *bio, u64 offset)
 {
-	int len = (bio->bi_iter.bi_sector << 9) - dip->disk_bytenr;
-	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
-	int ret;
-
-	len >>= inode->i_sb->s_blocksize_bits;
-	len *= csum_size;
-
-	ret = __btrfs_lookup_bio_sums(root, inode, bio, offset,
-				      (u32 *)(dip->csum + len), 1);
-	return ret;
+	return __btrfs_lookup_bio_sums(root, inode, bio, offset, NULL, 1);
 }
 
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,

commit d1b00a4711d5b953b13ccc859bc30c447c96860e
Author: Satoru Takeuchi <takeuchi_satoru@jp.fujitsu.com>
Date:   Fri Jul 25 17:07:48 2014 +0900

    btrfs: use IS_ALIGNED() for assertion in btrfs_lookup_csums_range() for simplicity
    
    btrfs_lookup_csums_range() uses ALIGN() to check if "start"
    and "end + 1" are aligned to "root->sectorsize". It's better to
    replace these with IS_ALIGNED() for simplicity.
    
    Signed-off-by: Satoru Takeuchi <takeuchi_satoru@jp.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 991f056acab2..6e6262eca8b7 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -329,8 +329,8 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	u64 csum_end;
 	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 
-	ASSERT(start == ALIGN(start, root->sectorsize) &&
-	       (end + 1) == ALIGN(end + 1, root->sectorsize));
+	ASSERT(IS_ALIGNED(start, root->sectorsize) &&
+	       IS_ALIGNED(end + 1, root->sectorsize));
 
 	path = btrfs_alloc_path();
 	if (!path)

commit 962a298f35110edd8f326814ae41a3dd306ecb64
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Jun 4 18:41:45 2014 +0200

    btrfs: kill the key type accessor helpers
    
    btrfs_set_key_type and btrfs_key_type are used inconsistently along with
    open coded variants. Other members of btrfs_key are accessed directly
    without any helpers anyway.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 54c84daec9b5..991f056acab2 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -55,7 +55,7 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 		return -ENOMEM;
 	file_key.objectid = objectid;
 	file_key.offset = pos;
-	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
+	file_key.type = BTRFS_EXTENT_DATA_KEY;
 
 	path->leave_spinning = 1;
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
@@ -100,7 +100,7 @@ btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 
 	file_key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
 	file_key.offset = bytenr;
-	btrfs_set_key_type(&file_key, BTRFS_EXTENT_CSUM_KEY);
+	file_key.type = BTRFS_EXTENT_CSUM_KEY;
 	ret = btrfs_search_slot(trans, root, &file_key, path, 0, cow);
 	if (ret < 0)
 		goto fail;
@@ -111,7 +111,7 @@ btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 			goto fail;
 		path->slots[0]--;
 		btrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);
-		if (btrfs_key_type(&found_key) != BTRFS_EXTENT_CSUM_KEY)
+		if (found_key.type != BTRFS_EXTENT_CSUM_KEY)
 			goto fail;
 
 		csum_offset = (bytenr - found_key.offset) >>
@@ -148,7 +148,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 
 	file_key.objectid = objectid;
 	file_key.offset = offset;
-	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
+	file_key.type = BTRFS_EXTENT_DATA_KEY;
 	ret = btrfs_search_slot(trans, root, &file_key, path, ins_len, cow);
 	return ret;
 }
@@ -720,7 +720,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	bytenr = sums->bytenr + total_bytes;
 	file_key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
 	file_key.offset = bytenr;
-	btrfs_set_key_type(&file_key, BTRFS_EXTENT_CSUM_KEY);
+	file_key.type = BTRFS_EXTENT_CSUM_KEY;
 
 	item = btrfs_lookup_csum(trans, root, path, bytenr, 1);
 	if (!IS_ERR(item)) {
@@ -790,7 +790,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	csum_offset = (bytenr - found_key.offset) >>
 			root->fs_info->sb->s_blocksize_bits;
 
-	if (btrfs_key_type(&found_key) != BTRFS_EXTENT_CSUM_KEY ||
+	if (found_key.type != BTRFS_EXTENT_CSUM_KEY ||
 	    found_key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
 	    csum_offset >= MAX_CSUM_ITEMS(root, csum_size)) {
 		goto insert;

commit 27b9a8122ff71a8cadfbffb9c4f0694300464f3b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Aug 9 21:22:27 2014 +0100

    Btrfs: fix csum tree corruption, duplicate and outdated checksums
    
    Under rare circumstances we can end up leaving 2 versions of a checksum
    for the same file extent range.
    
    The reason for this is that after calling btrfs_next_leaf we process
    slot 0 of the leaf it returns, instead of processing the slot set in
    path->slots[0]. Most of the time (by far) path->slots[0] is 0, but after
    btrfs_next_leaf() releases the path and before it searches for the next
    leaf, another task might cause a split of the next leaf, which migrates
    some of its keys to the leaf we were processing before calling
    btrfs_next_leaf(). In this case btrfs_next_leaf() returns again the
    same leaf but with path->slots[0] having a slot number corresponding
    to the first new key it got, that is, a slot number that didn't exist
    before calling btrfs_next_leaf(), as the leaf now has more keys than
    it had before. So we must really process the returned leaf starting at
    path->slots[0] always, as it isn't always 0, and the key at slot 0 can
    have an offset much lower than our search offset/bytenr.
    
    For example, consider the following scenario, where we have:
    
    sums->bytenr: 40157184, sums->len: 16384, sums end: 40173568
    four 4kb file data blocks with offsets 40157184, 40161280, 40165376, 40169472
    
      Leaf N:
    
        slot = 0                           slot = btrfs_header_nritems() - 1
      |-------------------------------------------------------------------|
      | [(CSUM CSUM 39239680), size 8] ... [(CSUM CSUM 40116224), size 4] |
      |-------------------------------------------------------------------|
    
      Leaf N + 1:
    
          slot = 0                          slot = btrfs_header_nritems() - 1
      |--------------------------------------------------------------------|
      | [(CSUM CSUM 40161280), size 32] ... [((CSUM CSUM 40615936), size 8 |
      |--------------------------------------------------------------------|
    
    Because we are at the last slot of leaf N, we call btrfs_next_leaf() to
    find the next highest key, which releases the current path and then searches
    for that next key. However after releasing the path and before finding that
    next key, the item at slot 0 of leaf N + 1 gets moved to leaf N, due to a call
    to ctree.c:push_leaf_left() (via ctree.c:split_leaf()), and therefore
    btrfs_next_leaf() will returns us a path again with leaf N but with the slot
    pointing to its new last key (CSUM CSUM 40161280). This new version of leaf N
    is then:
    
        slot = 0                        slot = btrfs_header_nritems() - 2  slot = btrfs_header_nritems() - 1
      |----------------------------------------------------------------------------------------------------|
      | [(CSUM CSUM 39239680), size 8] ... [(CSUM CSUM 40116224), size 4]  [(CSUM CSUM 40161280), size 32] |
      |----------------------------------------------------------------------------------------------------|
    
    And incorrecly using slot 0, makes us set next_offset to 39239680 and we jump
    into the "insert:" label, which will set tmp to:
    
        tmp = min((sums->len - total_bytes) >> blocksize_bits,
            (next_offset - file_key.offset) >> blocksize_bits) =
        min((16384 - 0) >> 12, (39239680 - 40157184) >> 12) =
        min(4, (u64)-917504 = 18446744073708634112 >> 12) = 4
    
    and
    
       ins_size = csum_size * tmp = 4 * 4 = 16 bytes.
    
    In other words, we insert a new csum item in the tree with key
    (CSUM_OBJECTID CSUM_KEY 40157184 = sums->bytenr) that contains the checksums
    for all the data (4 blocks of 4096 bytes each = sums->len). Which is wrong,
    because the item with key (CSUM CSUM 40161280) (the one that was moved from
    leaf N + 1 to the end of leaf N) contains the old checksums of the last 12288
    bytes of our data and won't get those old checksums removed.
    
    So this leaves us 2 different checksums for 3 4kb blocks of data in the tree,
    and breaks the logical rule:
    
       Key_N+1.offset >= Key_N.offset + length_of_data_its_checksums_cover
    
    An obvious bad effect of this is that a subsequent csum tree lookup to get
    the checksum of any of the blocks with logical offset of 40161280, 40165376
    or 40169472 (the last 3 4kb blocks of file data), will get the old checksums.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f46cfe45d686..54c84daec9b5 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -756,7 +756,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 				found_next = 1;
 			if (ret != 0)
 				goto insert;
-			slot = 0;
+			slot = path->slots[0];
 		}
 		btrfs_item_key_to_cpu(path->nodes[0], &found_key, slot);
 		if (found_key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||

commit 7ffbb598a059b73487909619d73150f99b50337a
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Mon Jun 9 03:48:05 2014 +0100

    Btrfs: make fsync work after cloning into a file
    
    When cloning into a file, we were correctly replacing the extent
    items in the target range and removing the extent maps. However
    we weren't replacing the extent maps with new ones that point to
    the new extents - as a consequence, an incremental fsync (when the
    inode doesn't have the full sync flag) was a NOOP, since it relies
    on the existence of extent maps in the modified list of the inode's
    extent map tree, which was empty. Therefore add new extent maps to
    reflect the target clone range.
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 609d56b9fd8e..f46cfe45d686 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -885,3 +885,79 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 fail_unlock:
 	goto out;
 }
+
+void btrfs_extent_item_to_extent_map(struct inode *inode,
+				     const struct btrfs_path *path,
+				     struct btrfs_file_extent_item *fi,
+				     const bool new_inline,
+				     struct extent_map *em)
+{
+	struct btrfs_root *root = BTRFS_I(inode)->root;
+	struct extent_buffer *leaf = path->nodes[0];
+	const int slot = path->slots[0];
+	struct btrfs_key key;
+	u64 extent_start, extent_end;
+	u64 bytenr;
+	u8 type = btrfs_file_extent_type(leaf, fi);
+	int compress_type = btrfs_file_extent_compression(leaf, fi);
+
+	em->bdev = root->fs_info->fs_devices->latest_bdev;
+	btrfs_item_key_to_cpu(leaf, &key, slot);
+	extent_start = key.offset;
+
+	if (type == BTRFS_FILE_EXTENT_REG ||
+	    type == BTRFS_FILE_EXTENT_PREALLOC) {
+		extent_end = extent_start +
+			btrfs_file_extent_num_bytes(leaf, fi);
+	} else if (type == BTRFS_FILE_EXTENT_INLINE) {
+		size_t size;
+		size = btrfs_file_extent_inline_len(leaf, slot, fi);
+		extent_end = ALIGN(extent_start + size, root->sectorsize);
+	}
+
+	em->ram_bytes = btrfs_file_extent_ram_bytes(leaf, fi);
+	if (type == BTRFS_FILE_EXTENT_REG ||
+	    type == BTRFS_FILE_EXTENT_PREALLOC) {
+		em->start = extent_start;
+		em->len = extent_end - extent_start;
+		em->orig_start = extent_start -
+			btrfs_file_extent_offset(leaf, fi);
+		em->orig_block_len = btrfs_file_extent_disk_num_bytes(leaf, fi);
+		bytenr = btrfs_file_extent_disk_bytenr(leaf, fi);
+		if (bytenr == 0) {
+			em->block_start = EXTENT_MAP_HOLE;
+			return;
+		}
+		if (compress_type != BTRFS_COMPRESS_NONE) {
+			set_bit(EXTENT_FLAG_COMPRESSED, &em->flags);
+			em->compress_type = compress_type;
+			em->block_start = bytenr;
+			em->block_len = em->orig_block_len;
+		} else {
+			bytenr += btrfs_file_extent_offset(leaf, fi);
+			em->block_start = bytenr;
+			em->block_len = em->len;
+			if (type == BTRFS_FILE_EXTENT_PREALLOC)
+				set_bit(EXTENT_FLAG_PREALLOC, &em->flags);
+		}
+	} else if (type == BTRFS_FILE_EXTENT_INLINE) {
+		em->block_start = EXTENT_MAP_INLINE;
+		em->start = extent_start;
+		em->len = extent_end - extent_start;
+		/*
+		 * Initialize orig_start and block_len with the same values
+		 * as in inode.c:btrfs_get_extent().
+		 */
+		em->orig_start = EXTENT_MAP_HOLE;
+		em->block_len = (u64)-1;
+		if (!new_inline && compress_type != BTRFS_COMPRESS_NONE) {
+			set_bit(EXTENT_FLAG_COMPRESSED, &em->flags);
+			em->compress_type = compress_type;
+		}
+	} else {
+		btrfs_err(root->fs_info,
+			  "unknown file extent item type %d, inode %llu, offset %llu, root %llu",
+			  type, btrfs_ino(inode), extent_start,
+			  root->root_key.objectid);
+	}
+}

commit 35045bf2fd7c030f2583dbd80a2015f427778bf1
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Wed Apr 9 14:38:34 2014 +0100

    Btrfs: don't access non-existent key when csum tree is empty
    
    When the csum tree is empty, our leaf (path->nodes[0]) has a number
    of items equal to 0 and since btrfs_header_nritems() returns an
    unsigned integer (and so is our local nritems variable) the following
    comparison always evaluates to false:
    
         if (path->slots[0] >= nritems - 1) {
    
    As the casting rules lead to:
    
         if ((u32)0 >= (u32)4294967295) {
    
    This makes us access key at slot paths->slots[0] + 1 (1) of the empty leaf
    some lines below:
    
        btrfs_item_key_to_cpu(path->nodes[0], &found_key, slot);
        if (found_key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
            found_key.type != BTRFS_EXTENT_CSUM_KEY) {
                    found_next = 1;
                    goto insert;
        }
    
    So just don't access such non-existent slot and don't set found_next to 1
    when the tree is empty. It's very unlikely we'll get a random key with the
    objectid and type values above, which is where we could go into trouble.
    
    If nritems is 0, just set found_next to 1 anyway as it will make us insert
    a csum item covering our whole extent (or the whole leaf) when the tree is
    empty.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 67751b776c7b..609d56b9fd8e 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -750,7 +750,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		int slot = path->slots[0] + 1;
 		/* we didn't find a csum item, insert one */
 		nritems = btrfs_header_nritems(path->nodes[0]);
-		if (path->slots[0] >= nritems - 1) {
+		if (!nritems || (path->slots[0] >= nritems - 1)) {
 			ret = btrfs_next_leaf(root, path);
 			if (ret == 1)
 				found_next = 1;

commit d2cbf2a260ab18c833f07fda66e30c4d4344162e
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Tue Apr 29 13:07:58 2014 +0800

    Btrfs: do not increment on bio_index one by one
    
    'bio_index' is just a index, it's really not necessary to do increment
    one by one.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 127555b29f58..67751b776c7b 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -281,10 +281,10 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 found:
 		csum += count * csum_size;
 		nblocks -= count;
+		bio_index += count;
 		while (count--) {
 			disk_bytenr += bvec->bv_len;
 			offset += bvec->bv_len;
-			bio_index++;
 			bvec++;
 		}
 	}

commit e7651b819e90da924991d727d3c007200a18670d
Merge: 060e8e3b6f8f cf93da7bcf45
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 30 20:08:20 2014 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This is a pretty big pull, and most of these changes have been
      floating in btrfs-next for a long time.  Filipe's properties work is a
      cool building block for inheriting attributes like compression down on
      a per inode basis.
    
      Jeff Mahoney kicked in code to export filesystem info into sysfs.
    
      Otherwise, lots of performance improvements, cleanups and bug fixes.
    
      Looks like there are still a few other small pending incrementals, but
      I wanted to get the bulk of this in first"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (149 commits)
      Btrfs: fix spin_unlock in check_ref_cleanup
      Btrfs: setup inode location during btrfs_init_inode_locked
      Btrfs: don't use ram_bytes for uncompressed inline items
      Btrfs: fix btrfs_search_slot_for_read backwards iteration
      Btrfs: do not export ulist functions
      Btrfs: rework ulist with list+rb_tree
      Btrfs: fix memory leaks on walking backrefs failure
      Btrfs: fix send file hole detection leading to data corruption
      Btrfs: add a reschedule point in btrfs_find_all_roots()
      Btrfs: make send's file extent item search more efficient
      Btrfs: fix to catch all errors when resolving indirect ref
      Btrfs: fix protection between walking backrefs and root deletion
      btrfs: fix warning while merging two adjacent extents
      Btrfs: fix infinite path build loops in incremental send
      btrfs: undo sysfs when open_ctree() fails
      Btrfs: fix snprintf usage by send's gen_unique_name
      btrfs: fix defrag 32-bit integer overflow
      btrfs: sysfs: list the NO_HOLES feature
      btrfs: sysfs: don't show reserved incompat feature
      btrfs: call permission checks earlier in ioctls and return EPERM
      ...

commit efe120a067c8674a8ae21b194f0e68f098b61ee2
Author: Frank Holton <fholton@gmail.com>
Date:   Fri Dec 20 11:37:06 2013 -0500

    Btrfs: convert printk to btrfs_ and fix BTRFS prefix
    
    Convert all applicable cases of printk and pr_* to the btrfs_* macros.
    
    Fix all uses of the BTRFS prefix.
    
    Signed-off-by: Frank Holton <fholton@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 6f3848860283..9d846588f722 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -246,8 +246,8 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 						offset + bvec->bv_len - 1,
 						EXTENT_NODATASUM, GFP_NOFS);
 				} else {
-					printk(KERN_INFO "btrfs no csum found "
-					       "for inode %llu start %llu\n",
+					btrfs_info(BTRFS_I(inode)->root->fs_info,
+						   "no csum found for inode %llu start %llu",
 					       btrfs_ino(inode), offset);
 				}
 				item = NULL;

commit 4f024f3797c43cb4b73cd2c50cec728842d0e49e
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Fri Oct 11 15:44:27 2013 -0700

    block: Abstract out bvec iterator
    
    Immutable biovecs are going to require an explicit iterator. To
    implement immutable bvecs, a later patch is going to add a bi_bvec_done
    member to this struct; for now, this patch effectively just renames
    things.
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: "Ed L. Cashin" <ecashin@coraid.com>
    Cc: Nick Piggin <npiggin@kernel.dk>
    Cc: Lars Ellenberg <drbd-dev@lists.linbit.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Geoff Levand <geoff@infradead.org>
    Cc: Yehuda Sadeh <yehuda@inktank.com>
    Cc: Sage Weil <sage@inktank.com>
    Cc: Alex Elder <elder@inktank.com>
    Cc: ceph-devel@vger.kernel.org
    Cc: Joshua Morris <josh.h.morris@us.ibm.com>
    Cc: Philip Kelleher <pjk1939@linux.vnet.ibm.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Alasdair Kergon <agk@redhat.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: dm-devel@redhat.com
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: linux390@de.ibm.com
    Cc: Boaz Harrosh <bharrosh@panasas.com>
    Cc: Benny Halevy <bhalevy@tonian.com>
    Cc: "James E.J. Bottomley" <JBottomley@parallels.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: "Nicholas A. Bellinger" <nab@linux-iscsi.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Chris Mason <chris.mason@fusionio.com>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: Jaegeuk Kim <jaegeuk.kim@samsung.com>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Dave Kleikamp <shaggy@kernel.org>
    Cc: Joern Engel <joern@logfs.org>
    Cc: Prasad Joshi <prasadjoshi.linux@gmail.com>
    Cc: Trond Myklebust <Trond.Myklebust@netapp.com>
    Cc: KONISHI Ryusuke <konishi.ryusuke@lab.ntt.co.jp>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <jlbec@evilplan.org>
    Cc: Ben Myers <bpm@sgi.com>
    Cc: xfs@oss.sgi.com
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Herton Ronaldo Krzesinski <herton.krzesinski@canonical.com>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Guo Chao <yan@linux.vnet.ibm.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Asai Thambi S P <asamymuthupa@micron.com>
    Cc: Selvan Mani <smani@micron.com>
    Cc: Sam Bradshaw <sbradshaw@micron.com>
    Cc: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
    Cc: "Roger Pau Monné" <roger.pau@citrix.com>
    Cc: Jan Beulich <jbeulich@suse.com>
    Cc: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Cc: Ian Campbell <Ian.Campbell@citrix.com>
    Cc: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Jiang Liu <jiang.liu@huawei.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Jerome Marchand <jmarchand@redhat.com>
    Cc: Joe Perches <joe@perches.com>
    Cc: Peng Tao <tao.peng@emc.com>
    Cc: Andy Adamson <andros@netapp.com>
    Cc: fanchaoting <fanchaoting@cn.fujitsu.com>
    Cc: Jie Liu <jeff.liu@oracle.com>
    Cc: Sunil Mushran <sunil.mushran@gmail.com>
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>
    Cc: Namjae Jeon <namjae.jeon@samsung.com>
    Cc: Pankaj Kumar <pankaj.km@samsung.com>
    Cc: Dan Magenheimer <dan.magenheimer@oracle.com>
    Cc: Mel Gorman <mgorman@suse.de>6

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 6f3848860283..84a46a42d262 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -182,7 +182,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	if (!path)
 		return -ENOMEM;
 
-	nblocks = bio->bi_size >> inode->i_sb->s_blocksize_bits;
+	nblocks = bio->bi_iter.bi_size >> inode->i_sb->s_blocksize_bits;
 	if (!dst) {
 		if (nblocks * csum_size > BTRFS_BIO_INLINE_CSUM_SIZE) {
 			btrfs_bio->csum_allocated = kmalloc(nblocks * csum_size,
@@ -201,7 +201,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 		csum = (u8 *)dst;
 	}
 
-	if (bio->bi_size > PAGE_CACHE_SIZE * 8)
+	if (bio->bi_iter.bi_size > PAGE_CACHE_SIZE * 8)
 		path->reada = 2;
 
 	WARN_ON(bio->bi_vcnt <= 0);
@@ -217,7 +217,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 		path->skip_locking = 1;
 	}
 
-	disk_bytenr = (u64)bio->bi_sector << 9;
+	disk_bytenr = (u64)bio->bi_iter.bi_sector << 9;
 	if (dio)
 		offset = logical_offset;
 	while (bio_index < bio->bi_vcnt) {
@@ -302,7 +302,7 @@ int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
 			      struct btrfs_dio_private *dip, struct bio *bio,
 			      u64 offset)
 {
-	int len = (bio->bi_sector << 9) - dip->disk_bytenr;
+	int len = (bio->bi_iter.bi_sector << 9) - dip->disk_bytenr;
 	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 	int ret;
 
@@ -447,11 +447,12 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	u64 offset;
 
 	WARN_ON(bio->bi_vcnt <= 0);
-	sums = kzalloc(btrfs_ordered_sum_size(root, bio->bi_size), GFP_NOFS);
+	sums = kzalloc(btrfs_ordered_sum_size(root, bio->bi_iter.bi_size),
+		       GFP_NOFS);
 	if (!sums)
 		return -ENOMEM;
 
-	sums->len = bio->bi_size;
+	sums->len = bio->bi_iter.bi_size;
 	INIT_LIST_HEAD(&sums->list);
 
 	if (contig)
@@ -461,7 +462,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 
 	ordered = btrfs_lookup_ordered_extent(inode, offset);
 	BUG_ON(!ordered); /* Logic error */
-	sums->bytenr = (u64)bio->bi_sector << 9;
+	sums->bytenr = (u64)bio->bi_iter.bi_sector << 9;
 	index = 0;
 
 	while (bio_index < bio->bi_vcnt) {
@@ -476,7 +477,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 			btrfs_add_ordered_sum(inode, ordered, sums);
 			btrfs_put_ordered_extent(ordered);
 
-			bytes_left = bio->bi_size - total_bytes;
+			bytes_left = bio->bi_iter.bi_size - total_bytes;
 
 			sums = kzalloc(btrfs_ordered_sum_size(root, bytes_left),
 				       GFP_NOFS);
@@ -484,7 +485,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 			sums->len = bytes_left;
 			ordered = btrfs_lookup_ordered_extent(inode, offset);
 			BUG_ON(!ordered); /* Logic error */
-			sums->bytenr = ((u64)bio->bi_sector << 9) +
+			sums->bytenr = ((u64)bio->bi_iter.bi_sector << 9) +
 				       total_bytes;
 			index = 0;
 		}

commit fae7f21cece9a4c181a8d8131870c7247e153f65
Author: Dulshani Gunawardhana <dulshani.gunawardhana89@gmail.com>
Date:   Thu Oct 31 10:30:08 2013 +0530

    btrfs: Use WARN_ON()'s return value in place of WARN_ON(1)
    
    Use WARN_ON()'s return value in place of WARN_ON(1) for cleaner source
    code that outputs a more descriptive warnings. Also fix the styling
    warning of redundant braces that came up as a result of this fix.
    
    Signed-off-by: Dulshani Gunawardhana <dulshani.gunawardhana89@gmail.com>
    Reviewed-by: Zach Brown <zab@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index ae8a5139e0ee..6f3848860283 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -849,10 +849,8 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	path->leave_spinning = 0;
 	if (ret < 0)
 		goto fail_unlock;
-	if (ret != 0) {
-		WARN_ON(1);
+	if (WARN_ON(ret != 0))
 		goto fail_unlock;
-	}
 	leaf = path->nodes[0];
 csum:
 	item = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);

commit 4277a9c3b3665f2830c55ece015163867b9414cc
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Oct 15 09:36:40 2013 -0400

    Btrfs: add an assert to btrfs_lookup_csums_range for alignment
    
    I was hitting weird issues when trying to remove hole extents and it turned out
    it was because I was sending non-aligned offsets down to
    btrfs_lookup_csums_range.  So add an assert for this in case somebody trips over
    this in the future.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 4f53159bdb9d..ae8a5139e0ee 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -329,6 +329,9 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	u64 csum_end;
 	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 
+	ASSERT(start == ALIGN(start, root->sectorsize) &&
+	       (end + 1) == ALIGN(end + 1, root->sectorsize));
+
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;

commit c1c9ff7c94e83fae89a742df74db51156869bad5
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:07 2013 +0200

    Btrfs: Remove superfluous casts from u64 to unsigned long long
    
    u64 is "unsigned long long" on all architectures now, so there's no need to
    cast it when formatting it using the "ll" length modifier.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f87d09a0dfaa..4f53159bdb9d 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -248,9 +248,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				} else {
 					printk(KERN_INFO "btrfs no csum found "
 					       "for inode %llu start %llu\n",
-					       (unsigned long long)
-					       btrfs_ino(inode),
-					       (unsigned long long)offset);
+					       btrfs_ino(inode), offset);
 				}
 				item = NULL;
 				btrfs_release_path(path);

commit facc8a2247340a9735fe8cc123c5da2102f5ef1b
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jul 25 19:22:34 2013 +0800

    Btrfs: don't cache the csum value into the extent state tree
    
    Before applying this patch, we cached the csum value into the extent state
    tree when reading some data from the disk, this operation increased the lock
    contention of the state tree.
    
    Now, we just store the csum value into the bio structure or other unshared
    structure, so we can reduce the lock contention.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a7bfc9541803..f87d09a0dfaa 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -23,6 +23,7 @@
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
+#include "volumes.h"
 #include "print-tree.h"
 
 #define __MAX_CSUM_ITEMS(r, size) ((unsigned long)(((BTRFS_LEAF_DATA_SIZE(r) - \
@@ -152,28 +153,54 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
+static void btrfs_io_bio_endio_readpage(struct btrfs_io_bio *bio, int err)
+{
+	kfree(bio->csum_allocated);
+}
+
 static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				   struct inode *inode, struct bio *bio,
 				   u64 logical_offset, u32 *dst, int dio)
 {
-	u32 sum[16];
-	int len;
 	struct bio_vec *bvec = bio->bi_io_vec;
-	int bio_index = 0;
+	struct btrfs_io_bio *btrfs_bio = btrfs_io_bio(bio);
+	struct btrfs_csum_item *item = NULL;
+	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
+	struct btrfs_path *path;
+	u8 *csum;
 	u64 offset = 0;
 	u64 item_start_offset = 0;
 	u64 item_last_offset = 0;
 	u64 disk_bytenr;
 	u32 diff;
-	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
+	int nblocks;
+	int bio_index = 0;
 	int count;
-	struct btrfs_path *path;
-	struct btrfs_csum_item *item = NULL;
-	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
+	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;
+
+	nblocks = bio->bi_size >> inode->i_sb->s_blocksize_bits;
+	if (!dst) {
+		if (nblocks * csum_size > BTRFS_BIO_INLINE_CSUM_SIZE) {
+			btrfs_bio->csum_allocated = kmalloc(nblocks * csum_size,
+							    GFP_NOFS);
+			if (!btrfs_bio->csum_allocated) {
+				btrfs_free_path(path);
+				return -ENOMEM;
+			}
+			btrfs_bio->csum = btrfs_bio->csum_allocated;
+			btrfs_bio->end_io = btrfs_io_bio_endio_readpage;
+		} else {
+			btrfs_bio->csum = btrfs_bio->csum_inline;
+		}
+		csum = btrfs_bio->csum;
+	} else {
+		csum = (u8 *)dst;
+	}
+
 	if (bio->bi_size > PAGE_CACHE_SIZE * 8)
 		path->reada = 2;
 
@@ -194,11 +221,10 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	if (dio)
 		offset = logical_offset;
 	while (bio_index < bio->bi_vcnt) {
-		len = min_t(int, ARRAY_SIZE(sum), bio->bi_vcnt - bio_index);
 		if (!dio)
 			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
-		count = btrfs_find_ordered_sum(inode, offset, disk_bytenr, sum,
-					       len);
+		count = btrfs_find_ordered_sum(inode, offset, disk_bytenr,
+					       (u32 *)csum, nblocks);
 		if (count)
 			goto found;
 
@@ -213,7 +239,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 						 path, disk_bytenr, 0);
 			if (IS_ERR(item)) {
 				count = 1;
-				sum[0] = 0;
+				memset(csum, 0, csum_size);
 				if (BTRFS_I(inode)->root->root_key.objectid ==
 				    BTRFS_DATA_RELOC_TREE_OBJECTID) {
 					set_extent_bits(io_tree, offset,
@@ -249,23 +275,14 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 		diff = disk_bytenr - item_start_offset;
 		diff = diff / root->sectorsize;
 		diff = diff * csum_size;
-		count = min_t(int, len, (item_last_offset - disk_bytenr) >>
-					inode->i_sb->s_blocksize_bits);
-		read_extent_buffer(path->nodes[0], sum,
+		count = min_t(int, nblocks, (item_last_offset - disk_bytenr) >>
+					    inode->i_sb->s_blocksize_bits);
+		read_extent_buffer(path->nodes[0], csum,
 				   ((unsigned long)item) + diff,
 				   csum_size * count);
 found:
-		if (dst) {
-			memcpy(dst, sum, count * csum_size);
-			dst += count;
-		} else {
-			if (dio)
-				extent_cache_csums_dio(io_tree, offset, sum,
-						       count);
-			else
-				extent_cache_csums(io_tree, bio, bio_index, sum,
-					    count);
-		}
+		csum += count * csum_size;
+		nblocks -= count;
 		while (count--) {
 			disk_bytenr += bvec->bv_len;
 			offset += bvec->bv_len;
@@ -284,9 +301,19 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 }
 
 int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
-			      struct bio *bio, u64 offset)
+			      struct btrfs_dio_private *dip, struct bio *bio,
+			      u64 offset)
 {
-	return __btrfs_lookup_bio_sums(root, inode, bio, offset, NULL, 1);
+	int len = (bio->bi_sector << 9) - dip->disk_bytenr;
+	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
+	int ret;
+
+	len >>= inode->i_sb->s_blocksize_bits;
+	len *= csum_size;
+
+	ret = __btrfs_lookup_bio_sums(root, inode, bio, offset,
+				      (u32 *)(dip->csum + len), 1);
+	return ret;
 }
 
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,

commit f51a4a1826ff810eb9c00cadff8978b028c40756
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Jun 19 10:36:09 2013 +0800

    Btrfs: remove btrfs_sector_sum structure
    
    Using the structure btrfs_sector_sum to keep the checksum value is
    unnecessary, because the extents that btrfs_sector_sum points to are
    continuous, we can find out the expected checksums by btrfs_ordered_sum's
    bytenr and the offset, so we can remove btrfs_sector_sum's bytenr. After
    removing bytenr, there is only one member in the structure, so it makes
    no sense to keep the structure, just remove it, and use a u32 array to
    store the checksum value.
    
    By this change, we don't use the while loop to get the checksums one by
    one. Now, we can get several checksum value at one time, it improved the
    performance by ~74% on my SSD (31MB/s -> 54MB/s).
    
    test command:
     # dd if=/dev/zero of=/mnt/btrfs/file0 bs=1M count=1024 oflag=sync
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b193bf324a41..a7bfc9541803 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -34,8 +34,7 @@
 
 #define MAX_ORDERED_SUM_BYTES(r) ((PAGE_SIZE - \
 				   sizeof(struct btrfs_ordered_sum)) / \
-				   sizeof(struct btrfs_sector_sum) * \
-				   (r)->sectorsize - (r)->sectorsize)
+				   sizeof(u32) * (r)->sectorsize)
 
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
@@ -297,7 +296,6 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	struct btrfs_path *path;
 	struct extent_buffer *leaf;
 	struct btrfs_ordered_sum *sums;
-	struct btrfs_sector_sum *sector_sum;
 	struct btrfs_csum_item *item;
 	LIST_HEAD(tmplist);
 	unsigned long offset;
@@ -368,34 +366,28 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 				      struct btrfs_csum_item);
 		while (start < csum_end) {
 			size = min_t(size_t, csum_end - start,
-					MAX_ORDERED_SUM_BYTES(root));
+				     MAX_ORDERED_SUM_BYTES(root));
 			sums = kzalloc(btrfs_ordered_sum_size(root, size),
-					GFP_NOFS);
+				       GFP_NOFS);
 			if (!sums) {
 				ret = -ENOMEM;
 				goto fail;
 			}
 
-			sector_sum = sums->sums;
 			sums->bytenr = start;
-			sums->len = size;
+			sums->len = (int)size;
 
 			offset = (start - key.offset) >>
 				root->fs_info->sb->s_blocksize_bits;
 			offset *= csum_size;
+			size >>= root->fs_info->sb->s_blocksize_bits;
 
-			while (size > 0) {
-				read_extent_buffer(path->nodes[0],
-						&sector_sum->sum,
-						((unsigned long)item) +
-						offset, csum_size);
-				sector_sum->bytenr = start;
-
-				size -= root->sectorsize;
-				start += root->sectorsize;
-				offset += csum_size;
-				sector_sum++;
-			}
+			read_extent_buffer(path->nodes[0],
+					   sums->sums,
+					   ((unsigned long)item) + offset,
+					   csum_size * size);
+
+			start += root->sectorsize * size;
 			list_add_tail(&sums->list, &tmplist);
 		}
 		path->slots[0]++;
@@ -417,23 +409,20 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio, u64 file_start, int contig)
 {
 	struct btrfs_ordered_sum *sums;
-	struct btrfs_sector_sum *sector_sum;
 	struct btrfs_ordered_extent *ordered;
 	char *data;
 	struct bio_vec *bvec = bio->bi_io_vec;
 	int bio_index = 0;
+	int index;
 	unsigned long total_bytes = 0;
 	unsigned long this_sum_bytes = 0;
 	u64 offset;
-	u64 disk_bytenr;
 
 	WARN_ON(bio->bi_vcnt <= 0);
 	sums = kzalloc(btrfs_ordered_sum_size(root, bio->bi_size), GFP_NOFS);
 	if (!sums)
 		return -ENOMEM;
 
-	sector_sum = sums->sums;
-	disk_bytenr = (u64)bio->bi_sector << 9;
 	sums->len = bio->bi_size;
 	INIT_LIST_HEAD(&sums->list);
 
@@ -444,7 +433,8 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 
 	ordered = btrfs_lookup_ordered_extent(inode, offset);
 	BUG_ON(!ordered); /* Logic error */
-	sums->bytenr = ordered->start;
+	sums->bytenr = (u64)bio->bi_sector << 9;
+	index = 0;
 
 	while (bio_index < bio->bi_vcnt) {
 		if (!contig)
@@ -463,28 +453,27 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 			sums = kzalloc(btrfs_ordered_sum_size(root, bytes_left),
 				       GFP_NOFS);
 			BUG_ON(!sums); /* -ENOMEM */
-			sector_sum = sums->sums;
 			sums->len = bytes_left;
 			ordered = btrfs_lookup_ordered_extent(inode, offset);
 			BUG_ON(!ordered); /* Logic error */
-			sums->bytenr = ordered->start;
+			sums->bytenr = ((u64)bio->bi_sector << 9) +
+				       total_bytes;
+			index = 0;
 		}
 
 		data = kmap_atomic(bvec->bv_page);
-		sector_sum->sum = ~(u32)0;
-		sector_sum->sum = btrfs_csum_data(data + bvec->bv_offset,
-						  sector_sum->sum,
-						  bvec->bv_len);
+		sums->sums[index] = ~(u32)0;
+		sums->sums[index] = btrfs_csum_data(data + bvec->bv_offset,
+						    sums->sums[index],
+						    bvec->bv_len);
 		kunmap_atomic(data);
-		btrfs_csum_final(sector_sum->sum,
-				 (char *)&sector_sum->sum);
-		sector_sum->bytenr = disk_bytenr;
+		btrfs_csum_final(sums->sums[index],
+				 (char *)(sums->sums + index));
 
-		sector_sum++;
 		bio_index++;
+		index++;
 		total_bytes += bvec->bv_len;
 		this_sum_bytes += bvec->bv_len;
-		disk_bytenr += bvec->bv_len;
 		offset += bvec->bv_len;
 		bvec++;
 	}
@@ -672,62 +661,46 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-static u64 btrfs_sector_sum_left(struct btrfs_ordered_sum *sums,
-				 struct btrfs_sector_sum *sector_sum,
-				 u64 total_bytes, u64 sectorsize)
-{
-	u64 tmp = sectorsize;
-	u64 next_sector = sector_sum->bytenr;
-	struct btrfs_sector_sum *next = sector_sum + 1;
-
-	while ((tmp + total_bytes) < sums->len) {
-		if (next_sector + sectorsize != next->bytenr)
-			break;
-		tmp += sectorsize;
-		next_sector = next->bytenr;
-		next++;
-	}
-	return tmp;
-}
-
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums)
 {
-	u64 bytenr;
-	int ret;
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
-	u64 next_offset;
-	u64 total_bytes = 0;
-	int found_next;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
 	struct btrfs_csum_item *item_end;
 	struct extent_buffer *leaf = NULL;
+	u64 next_offset;
+	u64 total_bytes = 0;
 	u64 csum_offset;
-	struct btrfs_sector_sum *sector_sum;
+	u64 bytenr;
 	u32 nritems;
 	u32 ins_size;
+	int index = 0;
+	int found_next;
+	int ret;
 	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;
-
-	sector_sum = sums->sums;
 again:
 	next_offset = (u64)-1;
 	found_next = 0;
+	bytenr = sums->bytenr + total_bytes;
 	file_key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
-	file_key.offset = sector_sum->bytenr;
-	bytenr = sector_sum->bytenr;
+	file_key.offset = bytenr;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_CSUM_KEY);
 
-	item = btrfs_lookup_csum(trans, root, path, sector_sum->bytenr, 1);
+	item = btrfs_lookup_csum(trans, root, path, bytenr, 1);
 	if (!IS_ERR(item)) {
-		leaf = path->nodes[0];
 		ret = 0;
+		leaf = path->nodes[0];
+		item_end = btrfs_item_ptr(leaf, path->slots[0],
+					  struct btrfs_csum_item);
+		item_end = (struct btrfs_csum_item *)((char *)item_end +
+			   btrfs_item_size_nr(leaf, path->slots[0]));
 		goto found;
 	}
 	ret = PTR_ERR(item);
@@ -807,8 +780,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 
 		free_space = btrfs_leaf_free_space(root, leaf) -
 					 sizeof(struct btrfs_item) - csum_size;
-		tmp = btrfs_sector_sum_left(sums, sector_sum, total_bytes,
-					    root->sectorsize);
+		tmp = sums->len - total_bytes;
 		tmp >>= root->fs_info->sb->s_blocksize_bits;
 		WARN_ON(tmp < 1);
 
@@ -822,6 +794,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		diff *= csum_size;
 
 		btrfs_extend_item(root, path, diff);
+		ret = 0;
 		goto csum;
 	}
 
@@ -831,8 +804,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	if (found_next) {
 		u64 tmp;
 
-		tmp = btrfs_sector_sum_left(sums, sector_sum, total_bytes,
-					    root->sectorsize);
+		tmp = sums->len - total_bytes;
 		tmp >>= root->fs_info->sb->s_blocksize_bits;
 		tmp = min(tmp, (next_offset - file_key.offset) >>
 					 root->fs_info->sb->s_blocksize_bits);
@@ -853,31 +825,25 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		WARN_ON(1);
 		goto fail_unlock;
 	}
-csum:
 	leaf = path->nodes[0];
+csum:
 	item = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
-	ret = 0;
+	item_end = (struct btrfs_csum_item *)((unsigned char *)item +
+				      btrfs_item_size_nr(leaf, path->slots[0]));
 	item = (struct btrfs_csum_item *)((unsigned char *)item +
 					  csum_offset * csum_size);
 found:
-	item_end = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
-	item_end = (struct btrfs_csum_item *)((unsigned char *)item_end +
-				      btrfs_item_size_nr(leaf, path->slots[0]));
-next_sector:
-
-	write_extent_buffer(leaf, &sector_sum->sum, (unsigned long)item, csum_size);
-
-	total_bytes += root->sectorsize;
-	sector_sum++;
-	if (total_bytes < sums->len) {
-		item = (struct btrfs_csum_item *)((char *)item +
-						  csum_size);
-		if (item < item_end && bytenr + PAGE_CACHE_SIZE ==
-		    sector_sum->bytenr) {
-			bytenr = sector_sum->bytenr;
-			goto next_sector;
-		}
-	}
+	ins_size = (u32)(sums->len - total_bytes) >>
+		   root->fs_info->sb->s_blocksize_bits;
+	ins_size *= csum_size;
+	ins_size = min_t(u32, (unsigned long)item_end - (unsigned long)item,
+			      ins_size);
+	write_extent_buffer(leaf, sums->sums + index, (unsigned long)item,
+			    ins_size);
+
+	ins_size /= csum_size;
+	total_bytes += ins_size * root->sectorsize;
+	index += ins_size;
 
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 	if (total_bytes < sums->len) {

commit 48a3b6366f6913683563d934eb16fea67dead9c1
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Apr 25 20:41:01 2013 +0000

    btrfs: make static code static & remove dead code
    
    Big patch, but all it does is add statics to functions which
    are in fact static, then remove the associated dead-code fallout.
    
    removed functions:
    
    btrfs_iref_to_path()
    __btrfs_lookup_delayed_deletion_item()
    __btrfs_search_delayed_insertion_item()
    __btrfs_search_delayed_deletion_item()
    find_eb_for_page()
    btrfs_find_block_group()
    range_straddles_pages()
    extent_range_uptodate()
    btrfs_file_extent_length()
    btrfs_scrub_cancel_devid()
    btrfs_start_transaction_lflush()
    
    btrfs_print_tree() is left because it is used for debugging.
    btrfs_start_transaction_lflush() and btrfs_reada_detach() are
    left for symmetry.
    
    ulist.c functions are left, another patch will take care of those.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 769eb86f890c..b193bf324a41 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -83,10 +83,11 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
-					  struct btrfs_root *root,
-					  struct btrfs_path *path,
-					  u64 bytenr, int cow)
+static struct btrfs_csum_item *
+btrfs_lookup_csum(struct btrfs_trans_handle *trans,
+		  struct btrfs_root *root,
+		  struct btrfs_path *path,
+		  u64 bytenr, int cow)
 {
 	int ret;
 	struct btrfs_key file_key;
@@ -152,27 +153,6 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-u64 btrfs_file_extent_length(struct btrfs_path *path)
-{
-	int extent_type;
-	struct btrfs_file_extent_item *fi;
-	u64 len;
-
-	fi = btrfs_item_ptr(path->nodes[0], path->slots[0],
-			    struct btrfs_file_extent_item);
-	extent_type = btrfs_file_extent_type(path->nodes[0], fi);
-
-	if (extent_type == BTRFS_FILE_EXTENT_REG ||
-	    extent_type == BTRFS_FILE_EXTENT_PREALLOC)
-		len = btrfs_file_extent_num_bytes(path->nodes[0], fi);
-	else if (extent_type == BTRFS_FILE_EXTENT_INLINE)
-		len = btrfs_file_extent_inline_len(path->nodes[0], fi);
-	else
-		BUG();
-
-	return len;
-}
-
 static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				   struct inode *inode, struct bio *bio,
 				   u64 logical_offset, u32 *dst, int dio)

commit 4b90c68015a7c0863292d6306501552d4ffa33ff
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Tue Apr 16 05:18:49 2013 +0000

    Btrfs: remove unused argument of btrfs_extend_item()
    
    Argument 'trans' is not used in btrfs_extend_item().
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index ea14ecb0af47..769eb86f890c 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -841,7 +841,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		diff /= csum_size;
 		diff *= csum_size;
 
-		btrfs_extend_item(trans, root, path, diff);
+		btrfs_extend_item(root, path, diff);
 		goto csum;
 	}
 

commit afe5fea72bd50b1df2e6a721ef50559427d42f2b
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Tue Apr 16 05:18:22 2013 +0000

    Btrfs: cleanup of function where fixup_low_keys() is called
    
    If argument 'trans' is unnecessary in the function where
    fixup_low_keys() is called, 'trans' is deleted.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 18f12aab6ebf..ea14ecb0af47 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -525,8 +525,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
  * This calls btrfs_truncate_item with the correct args based on the
  * overlap, and fixes up the key as required.
  */
-static noinline void truncate_one_csum(struct btrfs_trans_handle *trans,
-				       struct btrfs_root *root,
+static noinline void truncate_one_csum(struct btrfs_root *root,
 				       struct btrfs_path *path,
 				       struct btrfs_key *key,
 				       u64 bytenr, u64 len)
@@ -551,7 +550,7 @@ static noinline void truncate_one_csum(struct btrfs_trans_handle *trans,
 		 */
 		u32 new_size = (bytenr - key->offset) >> blocksize_bits;
 		new_size *= csum_size;
-		btrfs_truncate_item(trans, root, path, new_size, 1);
+		btrfs_truncate_item(root, path, new_size, 1);
 	} else if (key->offset >= bytenr && csum_end > end_byte &&
 		   end_byte > key->offset) {
 		/*
@@ -563,10 +562,10 @@ static noinline void truncate_one_csum(struct btrfs_trans_handle *trans,
 		u32 new_size = (csum_end - end_byte) >> blocksize_bits;
 		new_size *= csum_size;
 
-		btrfs_truncate_item(trans, root, path, new_size, 0);
+		btrfs_truncate_item(root, path, new_size, 0);
 
 		key->offset = end_byte;
-		btrfs_set_item_key_safe(trans, root, path, key);
+		btrfs_set_item_key_safe(root, path, key);
 	} else {
 		BUG();
 	}
@@ -681,7 +680,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 
 			key.offset = end_byte - 1;
 		} else {
-			truncate_one_csum(trans, root, path, &key, bytenr, len);
+			truncate_one_csum(root, path, &key, bytenr, len);
 			if (key.offset < bytenr)
 				break;
 		}

commit e4100d987b2437596ebcf11809022b79507f3db1
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Apr 5 07:20:56 2013 +0000

    Btrfs: improve the performance of the csums lookup
    
    It is very likely that there are several blocks in bio, it is very
    inefficient if we get their csums one by one. This patch improves
    this problem by getting the csums in batch.
    
    According to the result of the following test, the execute time of
    __btrfs_lookup_bio_sums() is down by ~28%(300us -> 217us).
    
     # dd if=<mnt>/file of=/dev/null bs=1M count=1024
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index ad3cd8614d29..18f12aab6ebf 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -177,7 +177,8 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				   struct inode *inode, struct bio *bio,
 				   u64 logical_offset, u32 *dst, int dio)
 {
-	u32 sum;
+	u32 sum[16];
+	int len;
 	struct bio_vec *bvec = bio->bi_io_vec;
 	int bio_index = 0;
 	u64 offset = 0;
@@ -186,7 +187,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	u64 disk_bytenr;
 	u32 diff;
 	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
-	int ret;
+	int count;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item = NULL;
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
@@ -214,10 +215,12 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	if (dio)
 		offset = logical_offset;
 	while (bio_index < bio->bi_vcnt) {
+		len = min_t(int, ARRAY_SIZE(sum), bio->bi_vcnt - bio_index);
 		if (!dio)
 			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
-		ret = btrfs_find_ordered_sum(inode, offset, disk_bytenr, &sum);
-		if (ret == 0)
+		count = btrfs_find_ordered_sum(inode, offset, disk_bytenr, sum,
+					       len);
+		if (count)
 			goto found;
 
 		if (!item || disk_bytenr < item_start_offset ||
@@ -230,10 +233,8 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 			item = btrfs_lookup_csum(NULL, root->fs_info->csum_root,
 						 path, disk_bytenr, 0);
 			if (IS_ERR(item)) {
-				ret = PTR_ERR(item);
-				if (ret == -ENOENT || ret == -EFBIG)
-					ret = 0;
-				sum = 0;
+				count = 1;
+				sum[0] = 0;
 				if (BTRFS_I(inode)->root->root_key.objectid ==
 				    BTRFS_DATA_RELOC_TREE_OBJECTID) {
 					set_extent_bits(io_tree, offset,
@@ -269,19 +270,29 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 		diff = disk_bytenr - item_start_offset;
 		diff = diff / root->sectorsize;
 		diff = diff * csum_size;
-
-		read_extent_buffer(path->nodes[0], &sum,
+		count = min_t(int, len, (item_last_offset - disk_bytenr) >>
+					inode->i_sb->s_blocksize_bits);
+		read_extent_buffer(path->nodes[0], sum,
 				   ((unsigned long)item) + diff,
-				   csum_size);
+				   csum_size * count);
 found:
-		if (dst)
-			*dst++ = sum;
-		else
-			set_state_private(io_tree, offset, sum);
-		disk_bytenr += bvec->bv_len;
-		offset += bvec->bv_len;
-		bio_index++;
-		bvec++;
+		if (dst) {
+			memcpy(dst, sum, count * csum_size);
+			dst += count;
+		} else {
+			if (dio)
+				extent_cache_csums_dio(io_tree, offset, sum,
+						       count);
+			else
+				extent_cache_csums(io_tree, bio, bio_index, sum,
+					    count);
+		}
+		while (count--) {
+			disk_bytenr += bvec->bv_len;
+			offset += bvec->bv_len;
+			bio_index++;
+			bvec++;
+		}
 	}
 	btrfs_free_path(path);
 	return 0;

commit 628c8282bed73c18ff056d655d4a6a63ef55284a
Author: Zhi Yong Wu <wuzhy@linux.vnet.ibm.com>
Date:   Mon Mar 18 09:18:09 2013 +0000

    btrfs: Cleanup some redundant codes in btrfs_lookup_csums_range()
    
    Signed-off-by: Zhi Yong Wu <wuzhy@linux.vnet.ibm.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index bc3c92466045..ad3cd8614d29 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -358,11 +358,8 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 
 		btrfs_item_key_to_cpu(leaf, &key, path->slots[0]);
 		if (key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
-		    key.type != BTRFS_EXTENT_CSUM_KEY)
-			break;
-
-		btrfs_item_key_to_cpu(leaf, &key, path->slots[0]);
-		if (key.offset > end)
+		    key.type != BTRFS_EXTENT_CSUM_KEY ||
+		    key.offset > end)
 			break;
 
 		if (key.offset > start)

commit b0496686ba0da69cfd2433ef55fb2d1dc7465084
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Mar 14 14:57:45 2013 +0000

    Btrfs: cleanup unused arguments of btrfs_csum_data
    
    Argument 'root' is no more used in btrfs_csum_data().
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index c4628a201cb3..bc3c92466045 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -484,8 +484,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 
 		data = kmap_atomic(bvec->bv_page);
 		sector_sum->sum = ~(u32)0;
-		sector_sum->sum = btrfs_csum_data(root,
-						  data + bvec->bv_offset,
+		sector_sum->sum = btrfs_csum_data(data + bvec->bv_offset,
 						  sector_sum->sum,
 						  bvec->bv_len);
 		kunmap_atomic(data);

commit 82d130ff390be67d980d8b6f39e921c0b1d8d8e0
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Mar 28 08:12:15 2013 +0000

    Btrfs: fix wrong return value of btrfs_lookup_csum()
    
    If we don't find the expected csum item, but find a csum item which is
    adjacent to the specified extent, we should return -EFBIG, or we should
    return -ENOENT. But btrfs_lookup_csum() return -EFBIG even the csum item
    is not adjacent to the specified extent. Fix it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b7e529d2860f..c4628a201cb3 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -118,9 +118,11 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 		csums_in_item = btrfs_item_size_nr(leaf, path->slots[0]);
 		csums_in_item /= csum_size;
 
-		if (csum_offset >= csums_in_item) {
+		if (csum_offset == csums_in_item) {
 			ret = -EFBIG;
 			goto fail;
+		} else if (csum_offset > csums_in_item) {
+			goto fail;
 		}
 	}
 	item = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);

commit 39847c4d3d91f487f9ab3d083ee5d0f8419f105c
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Mar 28 08:08:20 2013 +0000

    Btrfs: fix wrong reservation of csums
    
    We reserve the space for csums only when we write data into a file, in
    the other cases, such as tree log, log replay, we don't do reservation,
    so we can use the reservation of the transaction handle just for the former.
    And for the latter, we should use the tree's own reservation. But the
    function - btrfs_csum_file_blocks() didn't differentiate between these
    two types of the cases, fix it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index ec160202be3e..b7e529d2860f 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -728,7 +728,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		return -ENOMEM;
 
 	sector_sum = sums->sums;
-	trans->adding_csums = 1;
 again:
 	next_offset = (u64)-1;
 	found_next = 0;
@@ -899,7 +898,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		goto again;
 	}
 out:
-	trans->adding_csums = 0;
 	btrfs_free_path(path);
 	return ret;
 

commit 2f697dc6a648d3a16f512fe7a53281d55cce1570
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Feb 4 13:12:18 2013 +0000

    Btrfs: extend the checksum item as much as possible
    
    For write, we also reserve some space for COW blocks during updating
    the checksum tree, and we calculate the number of blocks by checking
    if the number of bytes outstanding that are going to need csums needs
    one more block for csum.
    
    When we add these checksum into the checksum tree, we use ordered sums
    list.
    Every ordered sum contains csums for each sector, and we'll first try
    to look up an existing csum item,
    a) if we don't yet have a proper csum item, then we need to insert one,
    b) or if we find one but the csum item is not big enough, then we need
    to extend it.
    
    The point is we'll unlock the whole path and then insert or extend.
    So others can hack in and update the tree.
    
    Each insert or extend needs update the tree with COW on, and we may need
    to insert/extend for many times.
    
    That means what we've reserved for updating checksum tree is NOT enough
    indeed.
    
    The case is even more serious with having several write threads at the
    same time, it can end up eating our reserved space quickly and starting
    eating globle reserve pool instead.
    
    I don't yet come up with a way to calculate the worse case for updating
    csum, but extending the checksum item as much as possible can be helpful
    in my test.
    
    The idea behind is that it can reduce the times we insert/extend so that
    it saves us precious reserved space.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 94aa53b38721..ec160202be3e 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -684,6 +684,24 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
+static u64 btrfs_sector_sum_left(struct btrfs_ordered_sum *sums,
+				 struct btrfs_sector_sum *sector_sum,
+				 u64 total_bytes, u64 sectorsize)
+{
+	u64 tmp = sectorsize;
+	u64 next_sector = sector_sum->bytenr;
+	struct btrfs_sector_sum *next = sector_sum + 1;
+
+	while ((tmp + total_bytes) < sums->len) {
+		if (next_sector + sectorsize != next->bytenr)
+			break;
+		tmp += sectorsize;
+		next_sector = next->bytenr;
+		next++;
+	}
+	return tmp;
+}
+
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums)
@@ -789,20 +807,32 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		goto insert;
 	}
 
-	if (csum_offset >= btrfs_item_size_nr(leaf, path->slots[0]) /
+	if (csum_offset == btrfs_item_size_nr(leaf, path->slots[0]) /
 	    csum_size) {
-		u32 diff = (csum_offset + 1) * csum_size;
+		int extend_nr;
+		u64 tmp;
+		u32 diff;
+		u32 free_space;
 
-		/*
-		 * is the item big enough already?  we dropped our lock
-		 * before and need to recheck
-		 */
-		if (diff < btrfs_item_size_nr(leaf, path->slots[0]))
-			goto csum;
+		if (btrfs_leaf_free_space(root, leaf) <
+				 sizeof(struct btrfs_item) + csum_size * 2)
+			goto insert;
+
+		free_space = btrfs_leaf_free_space(root, leaf) -
+					 sizeof(struct btrfs_item) - csum_size;
+		tmp = btrfs_sector_sum_left(sums, sector_sum, total_bytes,
+					    root->sectorsize);
+		tmp >>= root->fs_info->sb->s_blocksize_bits;
+		WARN_ON(tmp < 1);
+
+		extend_nr = max_t(int, 1, (int)tmp);
+		diff = (csum_offset + extend_nr) * csum_size;
+		diff = min(diff, MAX_CSUM_ITEMS(root, csum_size) * csum_size);
 
 		diff = diff - btrfs_item_size_nr(leaf, path->slots[0]);
-		if (diff != csum_size)
-			goto insert;
+		diff = min(free_space, diff);
+		diff /= csum_size;
+		diff *= csum_size;
 
 		btrfs_extend_item(trans, root, path, diff);
 		goto csum;
@@ -812,19 +842,14 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	btrfs_release_path(path);
 	csum_offset = 0;
 	if (found_next) {
-		u64 tmp = total_bytes + root->sectorsize;
-		u64 next_sector = sector_sum->bytenr;
-		struct btrfs_sector_sum *next = sector_sum + 1;
+		u64 tmp;
 
-		while (tmp < sums->len) {
-			if (next_sector + root->sectorsize != next->bytenr)
-				break;
-			tmp += root->sectorsize;
-			next_sector = next->bytenr;
-			next++;
-		}
-		tmp = min(tmp, next_offset - file_key.offset);
+		tmp = btrfs_sector_sum_left(sums, sector_sum, total_bytes,
+					    root->sectorsize);
 		tmp >>= root->fs_info->sb->s_blocksize_bits;
+		tmp = min(tmp, (next_offset - file_key.offset) >>
+					 root->fs_info->sb->s_blocksize_bits);
+
 		tmp = max((u64)1, tmp);
 		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(root, csum_size));
 		ins_size = csum_size * tmp;

commit e58dd74bccb4317e39e4b675bf9c6cd133608fac
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Jan 22 15:43:09 2013 -0500

    Btrfs: put csums on the right ordered extent
    
    I noticed a WARN_ON going off when adding csums because we were going over
    the amount of csum bytes that should have been allowed for an ordered
    extent.  This is a leftover from when we used to hold the csums privately
    for direct io, but now we use the normal ordered sum stuff so we need to
    make sure and check if we've moved on to another extent so that the csums
    are added to the right extent.  Without this we could end up with csums for
    bytenrs that don't have extents to cover them yet.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index bd38cef42358..94aa53b38721 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -460,8 +460,8 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		if (!contig)
 			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 
-		if (!contig && (offset >= ordered->file_offset + ordered->len ||
-		    offset < ordered->file_offset)) {
+		if (offset >= ordered->file_offset + ordered->len ||
+		    offset < ordered->file_offset) {
 			unsigned long bytes_left;
 			sums->len = this_sum_bytes;
 			this_sum_bytes = 0;

commit 315a9850da2b89c83971b26fe54a60f22bdd91ad
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Nov 1 07:33:59 2012 +0000

    Btrfs: fix wrong file extent length
    
    There are two types of the file extent - inline extent and regular extent,
    When we log file extents, we didn't take inline extent into account, fix it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 1ad08e4e4a15..bd38cef42358 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -133,7 +133,6 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 	return ERR_PTR(ret);
 }
 
-
 int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
@@ -151,6 +150,26 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
+u64 btrfs_file_extent_length(struct btrfs_path *path)
+{
+	int extent_type;
+	struct btrfs_file_extent_item *fi;
+	u64 len;
+
+	fi = btrfs_item_ptr(path->nodes[0], path->slots[0],
+			    struct btrfs_file_extent_item);
+	extent_type = btrfs_file_extent_type(path->nodes[0], fi);
+
+	if (extent_type == BTRFS_FILE_EXTENT_REG ||
+	    extent_type == BTRFS_FILE_EXTENT_PREALLOC)
+		len = btrfs_file_extent_num_bytes(path->nodes[0], fi);
+	else if (extent_type == BTRFS_FILE_EXTENT_INLINE)
+		len = btrfs_file_extent_inline_len(path->nodes[0], fi);
+	else
+		BUG();
+
+	return len;
+}
 
 static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 				   struct inode *inode, struct bio *bio,

commit 221b831835421f9451182611fa25fa60f440662f
Author: Zach Brown <zab@zabbo.net>
Date:   Thu Sep 20 14:33:00 2012 -0600

    btrfs: fix min csum item size warnings in 32bit
    
    commit 7ca4be45a0255ac8f08c05491c6add2dd87dd4f8 limited csum items to
    PAGE_CACHE_SIZE.  It used min() with incompatible types in 32bit which
    generates warnings:
    
    fs/btrfs/file-item.c: In function ‘btrfs_csum_file_blocks’:
    fs/btrfs/file-item.c:717: warning: comparison of distinct pointer types lacks a cast
    
    This uses min_t(u32,) to fix the warnings.  u32 seemed reasonable
    because btrfs_root->leafsize is u32 and PAGE_CACHE_SIZE is unsigned
    long.
    
    Signed-off-by: Zach Brown <zab@zabbo.net>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 54f03354bed1..1ad08e4e4a15 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -29,7 +29,8 @@
 				   sizeof(struct btrfs_item) * 2) / \
 				  size) - 1))
 
-#define MAX_CSUM_ITEMS(r, size) (min(__MAX_CSUM_ITEMS(r, size), PAGE_CACHE_SIZE))
+#define MAX_CSUM_ITEMS(r, size) (min_t(u32, __MAX_CSUM_ITEMS(r, size), \
+				       PAGE_CACHE_SIZE))
 
 #define MAX_ORDERED_SUM_BYTES(r) ((PAGE_SIZE - \
 				   sizeof(struct btrfs_ordered_sum)) / \

commit 995e01b7af745b8aaa5e882cfb7bfd5baab3f335
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Mon Aug 13 02:52:38 2012 -0600

    Btrfs: fix gcc warnings for 32bit compiles
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 857d93cd01dc..54f03354bed1 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -25,7 +25,7 @@
 #include "transaction.h"
 #include "print-tree.h"
 
-#define __MAX_CSUM_ITEMS(r, size) ((((BTRFS_LEAF_DATA_SIZE(r) - \
+#define __MAX_CSUM_ITEMS(r, size) ((unsigned long)(((BTRFS_LEAF_DATA_SIZE(r) - \
 				   sizeof(struct btrfs_item) * 2) / \
 				  size) - 1))
 

commit c329861da40623cd838b8c9ee31a850242fd88cf
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Aug 3 16:49:19 2012 -0400

    Btrfs: don't allocate a seperate csums array for direct reads
    
    We've been allocating a big array for csums instead of storing them in the
    io_tree like we do for buffered reads because previously we were locking the
    entire range, so we didn't have an extent state for each sector of the
    range.  But now that we do the range locking as we map the buffers we can
    limit the mapping lenght to sectorsize and use the private part of the
    io_tree for our csums.  This allows us to avoid an extra memory allocation
    for direct reads which could incur latency.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b45b9de0c21d..857d93cd01dc 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -272,9 +272,9 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 }
 
 int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
-			      struct bio *bio, u64 offset, u32 *dst)
+			      struct bio *bio, u64 offset)
 {
-	return __btrfs_lookup_bio_sums(root, inode, bio, offset, dst, 1);
+	return __btrfs_lookup_bio_sums(root, inode, bio, offset, NULL, 1);
 }
 
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,

commit 83eea1f1bacd5dc7b44dcf84f5fdca54fdea5453
Author: Liu Bo <liubo2009@cn.fujitsu.com>
Date:   Tue Jul 10 05:28:39 2012 -0600

    Btrfs: kill root from btrfs_is_free_space_inode
    
    Since root can be fetched via BTRFS_I macro directly, we can save an args
    for btrfs_is_free_space_inode().
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 863c34d111b5..b45b9de0c21d 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -183,7 +183,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	 * read from the commit root and sidestep a nasty deadlock
 	 * between reading the free space cache and updating the csum tree.
 	 */
-	if (btrfs_is_free_space_inode(root, inode)) {
+	if (btrfs_is_free_space_inode(inode)) {
 		path->search_commit_root = 1;
 		path->skip_locking = 1;
 	}

commit 0e721106923be82f651dd0ee504742a8a3eb089f
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Jun 26 16:13:18 2012 -0400

    Btrfs: change how we indicate we're adding csums
    
    There is weird logic I had to put in place to make sure that when we were
    adding csums that we'd used the delalloc block rsv instead of the global
    block rsv.  Part of this meant that we had to free up our transaction
    reservation before we ran the delayed refs since csum deletion happens
    during the delayed ref work.  The problem with this is that when we release
    a reservation we will add it to the global reserve if it is not full in
    order to keep us going along longer before we have to force a transaction
    commit.  By releasing our reservation before we run delayed refs we don't
    get the opportunity to drain down the global reserve for the work we did, so
    we won't refill it as often.  This isn't a problem per-se, it just results
    in us possibly committing transactions more and more often, and in rare
    cases could cause those WARN_ON()'s to pop in use_block_rsv because we ran
    out of space in our block rsv.
    
    This also helps us by holding onto space while the delayed refs run so we
    don't end up with as many people trying to do things at the same time, which
    again will help us not force commits or hit the use_block_rsv warnings.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 5d158d320233..863c34d111b5 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -690,6 +690,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		return -ENOMEM;
 
 	sector_sum = sums->sums;
+	trans->adding_csums = 1;
 again:
 	next_offset = (u64)-1;
 	found_next = 0;
@@ -853,6 +854,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		goto again;
 	}
 out:
+	trans->adding_csums = 0;
 	btrfs_free_path(path);
 	return ret;
 

commit 9613bebb223dea3179c265dc31e1bb41ae39f321
Merge: 40380f1c7841 bc3f116fec19
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 30 12:44:29 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes and features from Chris Mason:
     "We've merged in the error handling patches from SuSE.  These are
      already shipping in the sles kernel, and they give btrfs the ability
      to abort transactions and go readonly on errors.  It involves a lot of
      churn as they clarify BUG_ONs, and remove the ones we now properly
      deal with.
    
      Josef reworked the way our metadata interacts with the page cache.
      page->private now points to the btrfs extent_buffer object, which
      makes everything faster.  He changed it so we write an whole extent
      buffer at a time instead of allowing individual pages to go down,,
      which will be important for the raid5/6 code (for the 3.5 merge
      window ;)
    
      Josef also made us more aggressive about dropping pages for metadata
      blocks that were freed due to COW.  Overall, our metadata caching is
      much faster now.
    
      We've integrated my patch for metadata bigger than the page size.
      This allows metadata blocks up to 64KB in size.  In practice 16K and
      32K seem to work best.  For workloads with lots of metadata, this cuts
      down the size of the extent allocation tree dramatically and fragments
      much less.
    
      Scrub was updated to support the larger block sizes, which ended up
      being a fairly large change (thanks Stefan Behrens).
    
      We also have an assortment of fixes and updates, especially to the
      balancing code (Ilya Dryomov), the back ref walker (Jan Schmidt) and
      the defragging code (Liu Bo)."
    
    Fixed up trivial conflicts in fs/btrfs/scrub.c that were just due to
    removal of the second argument to k[un]map_atomic() in commit
    7ac687d9e047.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (75 commits)
      Btrfs: update the checks for mixed block groups with big metadata blocks
      Btrfs: update to the right index of defragment
      Btrfs: do not bother to defrag an extent if it is a big real extent
      Btrfs: add a check to decide if we should defrag the range
      Btrfs: fix recursive defragment with autodefrag option
      Btrfs: fix the mismatch of page->mapping
      Btrfs: fix race between direct io and autodefrag
      Btrfs: fix deadlock during allocating chunks
      Btrfs: show useful info in space reservation tracepoint
      Btrfs: don't use crc items bigger than 4KB
      Btrfs: flush out and clean up any block device pages during mount
      btrfs: disallow unequal data/metadata blocksize for mixed block groups
      Btrfs: enhance superblock sanity checks
      Btrfs: change scrub to support big blocks
      Btrfs: minor cleanup in scrub
      Btrfs: introduce common define for max number of mirrors
      Btrfs: fix infinite loop in btrfs_shrink_device()
      Btrfs: fix memory leak in resolver code
      Btrfs: allow dup for data chunks in mixed mode
      Btrfs: validate target profiles only if we are going to use them
      ...

commit 7ca4be45a0255ac8f08c05491c6add2dd87dd4f8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 31 20:19:02 2012 -0500

    Btrfs: don't use crc items bigger than 4KB
    
    With the big metadata blocks, we can have crc items
    that are much bigger than a page.  There are a few
    places that we try to kmalloc memory to hold the
    items during a split.
    
    Items bigger than 4KB don't really have a huge benefit
    in efficiency, but they do trigger larger order allocations.
    This commits changes the csums to make sure they stay under
    4KB.  This is not a format change, just a #define to limit
    huge items.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a14dbca5974e..cab0ffb5ef3b 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -25,10 +25,12 @@
 #include "transaction.h"
 #include "print-tree.h"
 
-#define MAX_CSUM_ITEMS(r, size) ((((BTRFS_LEAF_DATA_SIZE(r) - \
+#define __MAX_CSUM_ITEMS(r, size) ((((BTRFS_LEAF_DATA_SIZE(r) - \
 				   sizeof(struct btrfs_item) * 2) / \
 				  size) - 1))
 
+#define MAX_CSUM_ITEMS(r, size) (min(__MAX_CSUM_ITEMS(r, size), PAGE_CACHE_SIZE))
+
 #define MAX_ORDERED_SUM_BYTES(r) ((PAGE_SIZE - \
 				   sizeof(struct btrfs_ordered_sum)) / \
 				   sizeof(struct btrfs_sector_sum) * \

commit 79787eaab46121d4713ed03c8fc63b9ec3eaec76
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 12 16:03:00 2012 +0100

    btrfs: replace many BUG_ONs with proper error handling
    
     btrfs currently handles most errors with BUG_ON. This patch is a work-in-
     progress but aims to handle most errors other than internal logic
     errors and ENOMEM more gracefully.
    
     This iteration prevents most crashes but can run into lockups with
     the page lock on occasion when the timing "works out."
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 89af104c7569..a14dbca5974e 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -59,7 +59,7 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 				      sizeof(*item));
 	if (ret < 0)
 		goto out;
-	BUG_ON(ret);
+	BUG_ON(ret); /* Can't happen */
 	leaf = path->nodes[0];
 	item = btrfs_item_ptr(leaf, path->slots[0],
 			      struct btrfs_file_extent_item);
@@ -431,7 +431,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 
 	ordered = btrfs_lookup_ordered_extent(inode, offset);
-	BUG_ON(!ordered);
+	BUG_ON(!ordered); /* Logic error */
 	sums->bytenr = ordered->start;
 
 	while (bio_index < bio->bi_vcnt) {
@@ -450,11 +450,11 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 
 			sums = kzalloc(btrfs_ordered_sum_size(root, bytes_left),
 				       GFP_NOFS);
-			BUG_ON(!sums);
+			BUG_ON(!sums); /* -ENOMEM */
 			sector_sum = sums->sums;
 			sums->len = bytes_left;
 			ordered = btrfs_lookup_ordered_extent(inode, offset);
-			BUG_ON(!ordered);
+			BUG_ON(!ordered); /* Logic error */
 			sums->bytenr = ordered->start;
 		}
 
@@ -643,7 +643,10 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 			 * item changed size or key
 			 */
 			ret = btrfs_split_item(trans, root, path, &key, offset);
-			BUG_ON(ret && ret != -EAGAIN);
+			if (ret && ret != -EAGAIN) {
+				btrfs_abort_transaction(trans, root, ret);
+				goto out;
+			}
 
 			key.offset = end_byte - 1;
 		} else {

commit 0678b61851b510ba68341dff59cd9b47e1712e91
Author: Mark Fasheh <mfasheh@suse.com>
Date:   Fri Aug 5 15:46:16 2011 -0700

    btrfs: Don't BUG_ON kzalloc error in btrfs_lookup_csums_range()
    
    Unfortunately it isn't enough to just exit here - the kzalloc() happens in a
    loop and the allocated items are added to a linked list whose head is passed
    in from the caller.
    
    To fix the BUG_ON() and also provide the semantic that the list passed in is
    only modified on success, I create function-local temporary list that we add
    items too. If no error is met, that list is spliced to the callers at the
    end of the function. Otherwise the list will be walked and all items freed
    before the error value is returned.
    
    I did a simple test on this patch by forcing an error at the kzalloc() point
    and verifying that when this hits (git clone seemed to exercise this), the
    function throws the proper error. Unfortunately but predictably, we later
    hit a BUG_ON(ret) type line that still hasn't been fixed up ;)
    
    Signed-off-by: Mark Fasheh <mfasheh@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index edb69b4d5335..89af104c7569 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -284,6 +284,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	struct btrfs_ordered_sum *sums;
 	struct btrfs_sector_sum *sector_sum;
 	struct btrfs_csum_item *item;
+	LIST_HEAD(tmplist);
 	unsigned long offset;
 	int ret;
 	size_t size;
@@ -358,7 +359,10 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 					MAX_ORDERED_SUM_BYTES(root));
 			sums = kzalloc(btrfs_ordered_sum_size(root, size),
 					GFP_NOFS);
-			BUG_ON(!sums);
+			if (!sums) {
+				ret = -ENOMEM;
+				goto fail;
+			}
 
 			sector_sum = sums->sums;
 			sums->bytenr = start;
@@ -380,12 +384,19 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 				offset += csum_size;
 				sector_sum++;
 			}
-			list_add_tail(&sums->list, list);
+			list_add_tail(&sums->list, &tmplist);
 		}
 		path->slots[0]++;
 	}
 	ret = 0;
 fail:
+	while (ret < 0 && !list_empty(&tmplist)) {
+		sums = list_entry(&tmplist, struct btrfs_ordered_sum, list);
+		list_del(&sums->list);
+		kfree(sums);
+	}
+	list_splice_tail(&tmplist, list);
+
 	btrfs_free_path(path);
 	return ret;
 }

commit 143bede527b054a271053f41bfaca2b57baa9408
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:56:26 2012 +0100

    btrfs: return void in functions without error conditions
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index c7fb3a4247d3..edb69b4d5335 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -483,18 +483,17 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
  * This calls btrfs_truncate_item with the correct args based on the
  * overlap, and fixes up the key as required.
  */
-static noinline int truncate_one_csum(struct btrfs_trans_handle *trans,
-				      struct btrfs_root *root,
-				      struct btrfs_path *path,
-				      struct btrfs_key *key,
-				      u64 bytenr, u64 len)
+static noinline void truncate_one_csum(struct btrfs_trans_handle *trans,
+				       struct btrfs_root *root,
+				       struct btrfs_path *path,
+				       struct btrfs_key *key,
+				       u64 bytenr, u64 len)
 {
 	struct extent_buffer *leaf;
 	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 	u64 csum_end;
 	u64 end_byte = bytenr + len;
 	u32 blocksize_bits = root->fs_info->sb->s_blocksize_bits;
-	int ret;
 
 	leaf = path->nodes[0];
 	csum_end = btrfs_item_size_nr(leaf, path->slots[0]) / csum_size;
@@ -510,7 +509,7 @@ static noinline int truncate_one_csum(struct btrfs_trans_handle *trans,
 		 */
 		u32 new_size = (bytenr - key->offset) >> blocksize_bits;
 		new_size *= csum_size;
-		ret = btrfs_truncate_item(trans, root, path, new_size, 1);
+		btrfs_truncate_item(trans, root, path, new_size, 1);
 	} else if (key->offset >= bytenr && csum_end > end_byte &&
 		   end_byte > key->offset) {
 		/*
@@ -522,15 +521,13 @@ static noinline int truncate_one_csum(struct btrfs_trans_handle *trans,
 		u32 new_size = (csum_end - end_byte) >> blocksize_bits;
 		new_size *= csum_size;
 
-		ret = btrfs_truncate_item(trans, root, path, new_size, 0);
+		btrfs_truncate_item(trans, root, path, new_size, 0);
 
 		key->offset = end_byte;
-		ret = btrfs_set_item_key_safe(trans, root, path, key);
-		BUG_ON(ret);
+		btrfs_set_item_key_safe(trans, root, path, key);
 	} else {
 		BUG();
 	}
-	return 0;
 }
 
 /*
@@ -639,9 +636,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 
 			key.offset = end_byte - 1;
 		} else {
-			ret = truncate_one_csum(trans, root, path,
-						&key, bytenr, len);
-			BUG_ON(ret);
+			truncate_one_csum(trans, root, path, &key, bytenr, len);
 			if (key.offset < bytenr)
 				break;
 		}
@@ -772,7 +767,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		if (diff != csum_size)
 			goto insert;
 
-		ret = btrfs_extend_item(trans, root, path, diff);
+		btrfs_extend_item(trans, root, path, diff);
 		goto csum;
 	}
 

commit 7ac687d9e047b3fa335f04e18c7188db6a170334
Author: Cong Wang <amwang@redhat.com>
Date:   Fri Nov 25 23:14:28 2011 +0800

    btrfs: remove the second argument of k[un]map_atomic()
    
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index c7fb3a4247d3..078b4fd54500 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -447,13 +447,13 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 			sums->bytenr = ordered->start;
 		}
 
-		data = kmap_atomic(bvec->bv_page, KM_USER0);
+		data = kmap_atomic(bvec->bv_page);
 		sector_sum->sum = ~(u32)0;
 		sector_sum->sum = btrfs_csum_data(root,
 						  data + bvec->bv_offset,
 						  sector_sum->sum,
 						  bvec->bv_len);
-		kunmap_atomic(data, KM_USER0);
+		kunmap_atomic(data);
 		btrfs_csum_final(sector_sum->sum,
 				 (char *)&sector_sum->sum);
 		sector_sum->bytenr = disk_bytenr;

commit 6c41761fc6efe1503103a1afe03a6635c0b5d4ec
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Apr 13 15:41:04 2011 +0200

    btrfs: separate superblock items out of fs_info
    
    fs_info has now ~9kb, more than fits into one page. This will cause
    mount failure when memory is too fragmented. Top space consumers are
    super block structures super_copy and super_for_commit, ~2.8kb each.
    Allocate them dynamically. fs_info will be ~3.5kb. (measured on x86_64)
    
    Add a wrapper for freeing fs_info and all of it's dynamically allocated
    members.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a1cb7821becd..c7fb3a4247d3 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -91,8 +91,7 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 	struct btrfs_csum_item *item;
 	struct extent_buffer *leaf;
 	u64 csum_offset = 0;
-	u16 csum_size =
-		btrfs_super_csum_size(&root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 	int csums_in_item;
 
 	file_key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
@@ -162,8 +161,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	u64 item_last_offset = 0;
 	u64 disk_bytenr;
 	u32 diff;
-	u16 csum_size =
-		btrfs_super_csum_size(&root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 	int ret;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item = NULL;
@@ -290,7 +288,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	int ret;
 	size_t size;
 	u64 csum_end;
-	u16 csum_size = btrfs_super_csum_size(&root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 
 	path = btrfs_alloc_path();
 	if (!path)
@@ -492,8 +490,7 @@ static noinline int truncate_one_csum(struct btrfs_trans_handle *trans,
 				      u64 bytenr, u64 len)
 {
 	struct extent_buffer *leaf;
-	u16 csum_size =
-		btrfs_super_csum_size(&root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 	u64 csum_end;
 	u64 end_byte = bytenr + len;
 	u32 blocksize_bits = root->fs_info->sb->s_blocksize_bits;
@@ -549,8 +546,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 	u64 csum_end;
 	struct extent_buffer *leaf;
 	int ret;
-	u16 csum_size =
-		btrfs_super_csum_size(&root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 	int blocksize_bits = root->fs_info->sb->s_blocksize_bits;
 
 	root = root->fs_info->csum_root;
@@ -676,8 +672,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	struct btrfs_sector_sum *sector_sum;
 	u32 nritems;
 	u32 ins_size;
-	u16 csum_size =
-		btrfs_super_csum_size(&root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 
 	path = btrfs_alloc_path();
 	if (!path)

commit ddf23b3fc6850bd4654d51ec9457fe7c77cde51e
Author: Josef Bacik <josef@redhat.com>
Date:   Sun Sep 11 10:52:24 2011 -0400

    Btrfs: skip locking if searching the commit root in csum lookup
    
    It's not enough to just search the commit root, since we could be cow'ing the
    very block we need to search through, which would mean that its locked and we'll
    still deadlock.  So use path->skip_locking as well.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b910694f61ed..a1cb7821becd 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -183,8 +183,10 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	 * read from the commit root and sidestep a nasty deadlock
 	 * between reading the free space cache and updating the csum tree.
 	 */
-	if (btrfs_is_free_space_inode(root, inode))
+	if (btrfs_is_free_space_inode(root, inode)) {
 		path->search_commit_root = 1;
+		path->skip_locking = 1;
+	}
 
 	disk_bytenr = (u64)bio->bi_sector << 9;
 	if (dio)

commit b43b31bdf2e662006c27cc4dcccf863312d62bc1
Merge: ff95acb6733d 38a1a9195357
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Aug 1 14:27:34 2011 -0400

    Merge branch 'alloc_path' of git://git.kernel.org/pub/scm/linux/kernel/git/mfasheh/btrfs-error-handling into for-linus

commit 2cf8572dac62cc2ff7e995173e95b6c694401b3f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 26 15:35:09 2011 -0400

    Btrfs: use the commit_root for reading free_space_inode crcs
    
    Now that we are using regular file crcs for the free space cache,
    we can deadlock if we try to read the free_space_inode while we are
    updating the crc tree.
    
    This commit fixes things by using the commit_root to read the crcs.  This is
    safe because we the free space cache file would already be loaded if
    that block group had been changed in the current transaction.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index bb22a4435b2d..08bcfa92a222 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -177,6 +177,15 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 
 	WARN_ON(bio->bi_vcnt <= 0);
 
+	/*
+	 * the free space stuff is only read when it hasn't been
+	 * updated in the current transaction.  So, we can safely
+	 * read from the commit root and sidestep a nasty deadlock
+	 * between reading the free space cache and updating the csum tree.
+	 */
+	if (btrfs_is_free_space_inode(root, inode))
+		path->search_commit_root = 1;
+
 	disk_bytenr = (u64)bio->bi_sector << 9;
 	if (dio)
 		offset = logical_offset;

commit a65917156e345946dbde3d7effd28124c6d6a8c2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 19 12:04:14 2011 -0400

    Btrfs: stop using highmem for extent_buffers
    
    The extent_buffers have a very complex interface where
    we use HIGHMEM for metadata and try to cache a kmap mapping
    to access the memory.
    
    The next commit adds reader/writer locks, and concurrent use
    of this kmap cache would make it even more complex.
    
    This commit drops the ability to use HIGHMEM with extent buffers,
    and rips out all of the related code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 90d4ee52cd45..bb22a4435b2d 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -664,10 +664,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	struct btrfs_sector_sum *sector_sum;
 	u32 nritems;
 	u32 ins_size;
-	char *eb_map;
-	char *eb_token;
-	unsigned long map_len;
-	unsigned long map_start;
 	u16 csum_size =
 		btrfs_super_csum_size(&root->fs_info->super_copy);
 
@@ -814,30 +810,9 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	item_end = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
 	item_end = (struct btrfs_csum_item *)((unsigned char *)item_end +
 				      btrfs_item_size_nr(leaf, path->slots[0]));
-	eb_token = NULL;
 next_sector:
 
-	if (!eb_token ||
-	   (unsigned long)item + csum_size >= map_start + map_len) {
-		int err;
-
-		if (eb_token)
-			unmap_extent_buffer(leaf, eb_token, KM_USER1);
-		eb_token = NULL;
-		err = map_private_extent_buffer(leaf, (unsigned long)item,
-						csum_size,
-						&eb_token, &eb_map,
-						&map_start, &map_len, KM_USER1);
-		if (err)
-			eb_token = NULL;
-	}
-	if (eb_token) {
-		memcpy(eb_token + ((unsigned long)item & (PAGE_CACHE_SIZE - 1)),
-		       &sector_sum->sum, csum_size);
-	} else {
-		write_extent_buffer(leaf, &sector_sum->sum,
-				    (unsigned long)item, csum_size);
-	}
+	write_extent_buffer(leaf, &sector_sum->sum, (unsigned long)item, csum_size);
 
 	total_bytes += root->sectorsize;
 	sector_sum++;
@@ -850,10 +825,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			goto next_sector;
 		}
 	}
-	if (eb_token) {
-		unmap_extent_buffer(leaf, eb_token, KM_USER1);
-		eb_token = NULL;
-	}
+
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 	if (total_bytes < sums->len) {
 		btrfs_release_path(path);

commit d8926bb3badd36670fecf2de4a062c78bc37430b
Author: Mark Fasheh <mfasheh@suse.com>
Date:   Wed Jul 13 10:38:47 2011 -0700

    btrfs: don't BUG_ON btrfs_alloc_path() errors
    
    This patch fixes many callers of btrfs_alloc_path() which BUG_ON allocation
    failure. All the sites that are fixed in this patch were checked by me to
    be fairly trivial to fix because of at least one of two criteria:
    
     - Callers of the function catch errors from it already so bubbling the
       error up will be handled.
     - Callers of the function might BUG_ON any nonzero return code in which
       case there is no behavior changed (but we still got to remove a BUG_ON)
    
    The following functions were updated:
    
    btrfs_lookup_extent, alloc_reserved_tree_block, btrfs_remove_block_group,
    btrfs_lookup_csums_range, btrfs_csum_file_blocks, btrfs_mark_extent_written,
    btrfs_inode_by_name, btrfs_new_inode, btrfs_symlink,
    insert_reserved_file_extent, and run_delalloc_nocow
    
    Signed-off-by: Mark Fasheh <mfasheh@suse.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 90d4ee52cd45..f92ff0ed6e03 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -282,7 +282,8 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	u16 csum_size = btrfs_super_csum_size(&root->fs_info->super_copy);
 
 	path = btrfs_alloc_path();
-	BUG_ON(!path);
+	if (!path)
+		return -ENOMEM;
 
 	if (search_commit) {
 		path->skip_locking = 1;
@@ -672,7 +673,9 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		btrfs_super_csum_size(&root->fs_info->super_copy);
 
 	path = btrfs_alloc_path();
-	BUG_ON(!path);
+	if (!path)
+		return -ENOMEM;
+
 	sector_sum = sums->sums;
 again:
 	next_offset = (u64)-1;

commit d6c0cb379c5198487e4ac124728cbb2346d63b1f
Merge: 8e531cdfeb75 1f78160ce1b1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 23 14:37:47 2011 -0400

    Merge branch 'cleanups_and_fixes' into inode_numbers
    
    Conflicts:
            fs/btrfs/tree-log.c
            fs/btrfs/volumes.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 1cd307990d6e2b4965620e339a92e0d7ae853e13
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Thu May 19 05:19:08 2011 +0000

    Btrfs: BUG_ON is deleted from the caller of btrfs_truncate_item & btrfs_extend_item
    
    Currently, btrfs_truncate_item and btrfs_extend_item returns only 0.
    So, the check by BUG_ON in the caller is unnecessary.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 6e7556aa02e8..fb9b02667e75 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -495,7 +495,6 @@ static noinline int truncate_one_csum(struct btrfs_trans_handle *trans,
 		u32 new_size = (bytenr - key->offset) >> blocksize_bits;
 		new_size *= csum_size;
 		ret = btrfs_truncate_item(trans, root, path, new_size, 1);
-		BUG_ON(ret);
 	} else if (key->offset >= bytenr && csum_end > end_byte &&
 		   end_byte > key->offset) {
 		/*
@@ -508,7 +507,6 @@ static noinline int truncate_one_csum(struct btrfs_trans_handle *trans,
 		new_size *= csum_size;
 
 		ret = btrfs_truncate_item(trans, root, path, new_size, 0);
-		BUG_ON(ret);
 
 		key->offset = end_byte;
 		ret = btrfs_set_item_key_safe(trans, root, path, key);
@@ -763,7 +761,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			goto insert;
 
 		ret = btrfs_extend_item(trans, root, path, diff);
-		BUG_ON(ret);
 		goto csum;
 	}
 

commit 65a246c5ffe3b487a001de025816326939e63362
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Thu May 19 04:37:44 2011 +0000

    Btrfs: return error code to caller when btrfs_del_item fails
    
    The error code is returned instead of calling BUG_ON when
    btrfs_del_item returns the error.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a6a9d4e8b491..6e7556aa02e8 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -551,10 +551,10 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		ret = btrfs_search_slot(trans, root, &key, path, -1, 1);
 		if (ret > 0) {
 			if (path->slots[0] == 0)
-				goto out;
+				break;
 			path->slots[0]--;
 		} else if (ret < 0) {
-			goto out;
+			break;
 		}
 
 		leaf = path->nodes[0];
@@ -579,7 +579,8 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		/* delete the entire item, it is inside our range */
 		if (key.offset >= bytenr && csum_end <= end_byte) {
 			ret = btrfs_del_item(trans, root, path);
-			BUG_ON(ret);
+			if (ret)
+				goto out;
 			if (key.offset == bytenr)
 				break;
 		} else if (key.offset < bytenr && csum_end > end_byte) {
@@ -633,9 +634,10 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		}
 		btrfs_release_path(root, path);
 	}
+	ret = 0;
 out:
 	btrfs_free_path(path);
-	return 0;
+	return ret;
 }
 
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,

commit 712673339a0d085358fd1cd3a6477cc7979bb69f
Merge: aa2dfb372a2a 8628764e1a5e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 23 06:30:52 2011 -0400

    Merge branch 'for-chris' of git://git.kernel.org/pub/scm/linux/kernel/git/arne/btrfs-unstable-arne into inode_numbers
    
    Conflicts:
            fs/btrfs/Makefile
            fs/btrfs/ctree.h
            fs/btrfs/volumes.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 945d8962ceee6bb273365d0bdf42f763225b290f
Merge: 0d0ca30f1809 4ea028859bbd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun May 22 12:33:42 2011 -0400

    Merge branch 'cleanups' of git://repo.or.cz/linux-2.6/btrfs-unstable into inode_numbers
    
    Conflicts:
            fs/btrfs/extent-tree.c
            fs/btrfs/free-space-cache.c
            fs/btrfs/inode.c
            fs/btrfs/tree-log.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit a2de733c78fa7af51ba9670482fa7d392aa67c57
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Mar 8 14:14:00 2011 +0100

    btrfs: scrub
    
    This adds an initial implementation for scrub. It works quite
    straightforward. The usermode issues an ioctl for each device in the
    fs. For each device, it enumerates the allocated device chunks. For
    each chunk, the contained extents are enumerated and the data checksums
    fetched. The extents are read sequentially and the checksums verified.
    If an error occurs (checksum or EIO), a good copy is searched for. If
    one is found, the bad copy will be rewritten.
    All enumerations happen from the commit roots. During a transaction
    commit, the scrubs get paused and afterwards continue from the new
    roots.
    
    This commit is based on the series originally posted to linux-btrfs
    with some improvements that resulted from comments from David Sterba,
    Ilya Dryomov and Jan Schmidt.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a6a9d4e8b491..39ca7c1250e7 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -266,7 +266,7 @@ int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
 }
 
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
-			     struct list_head *list)
+			     struct list_head *list, int search_commit)
 {
 	struct btrfs_key key;
 	struct btrfs_path *path;
@@ -283,6 +283,12 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
 
+	if (search_commit) {
+		path->skip_locking = 1;
+		path->reada = 2;
+		path->search_commit_root = 1;
+	}
+
 	key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
 	key.offset = start;
 	key.type = BTRFS_EXTENT_CSUM_KEY;

commit b3b4aa74b58bded927f579fff787fb6fa1c0393c
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Apr 21 01:20:15 2011 +0200

    btrfs: drop unused parameter from btrfs_release_path
    
    parameter tree root it's not used since commit
    5f39d397dfbe140a14edecd4e73c34ce23c4f9ee ("Btrfs: Create extent_buffer
    interface for large blocksizes")
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a6a9d4e8b491..f47e43d855aa 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -193,7 +193,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 			u32 item_size;
 
 			if (item)
-				btrfs_release_path(root, path);
+				btrfs_release_path(path);
 			item = btrfs_lookup_csum(NULL, root->fs_info->csum_root,
 						 path, disk_bytenr, 0);
 			if (IS_ERR(item)) {
@@ -213,7 +213,7 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 					       (unsigned long long)offset);
 				}
 				item = NULL;
-				btrfs_release_path(root, path);
+				btrfs_release_path(path);
 				goto found;
 			}
 			btrfs_item_key_to_cpu(path->nodes[0], &found_key,
@@ -631,7 +631,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 			if (key.offset < bytenr)
 				break;
 		}
-		btrfs_release_path(root, path);
+		btrfs_release_path(path);
 	}
 out:
 	btrfs_free_path(path);
@@ -722,7 +722,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	 * at this point, we know the tree has an item, but it isn't big
 	 * enough yet to put our csum in.  Grow it
 	 */
-	btrfs_release_path(root, path);
+	btrfs_release_path(path);
 	ret = btrfs_search_slot(trans, root, &file_key, path,
 				csum_size, 1);
 	if (ret < 0)
@@ -766,7 +766,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	}
 
 insert:
-	btrfs_release_path(root, path);
+	btrfs_release_path(path);
 	csum_offset = 0;
 	if (found_next) {
 		u64 tmp = total_bytes + root->sectorsize;
@@ -850,7 +850,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	}
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 	if (total_bytes < sums->len) {
-		btrfs_release_path(root, path);
+		btrfs_release_path(path);
 		cond_resched();
 		goto again;
 	}

commit 33345d01522f8152f99dc84a3e7a1a45707f387f
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Apr 20 10:31:50 2011 +0800

    Btrfs: Always use 64bit inode number
    
    There's a potential problem in 32bit system when we exhaust 32bit inode
    numbers and start to allocate big inode numbers, because btrfs uses
    inode->i_ino in many places.
    
    So here we always use BTRFS_I(inode)->location.objectid, which is an
    u64 variable.
    
    There are 2 exceptions that BTRFS_I(inode)->location.objectid !=
    inode->i_ino: the btree inode (0 vs 1) and empty subvol dirs (256 vs 2),
    and inode->i_ino will be used in those cases.
    
    Another reason to make this change is I'm going to use a special inode
    to save free ino cache, and the inode number must be > (u64)-256.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a6a9d4e8b491..1d9410e39212 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -208,8 +208,9 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 						EXTENT_NODATASUM, GFP_NOFS);
 				} else {
 					printk(KERN_INFO "btrfs no csum found "
-					       "for inode %lu start %llu\n",
-					       inode->i_ino,
+					       "for inode %llu start %llu\n",
+					       (unsigned long long)
+					       btrfs_ino(inode),
 					       (unsigned long long)offset);
 				}
 				item = NULL;

commit c2db1073fdf9757e6fd8b4a59d15b6ecc7a2af8a
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Tue Mar 1 06:48:31 2011 +0000

    Btrfs: check return value of btrfs_alloc_path()
    
    Adding the check on the return value of btrfs_alloc_path() to several places.
    And, some of callers are modified by this change.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a2134195a85e..a6a9d4e8b491 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -170,6 +170,8 @@ static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
 
 	path = btrfs_alloc_path();
+	if (!path)
+		return -ENOMEM;
 	if (bio->bi_size > PAGE_CACHE_SIZE * 8)
 		path->reada = 2;
 

commit db5b493ac78e46c7b6bad22cd25d8041564cd8ea
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Wed Mar 23 08:14:16 2011 +0000

    Btrfs: cleanup some BUG_ON()
    
    This patch changes some BUG_ON() to the error return.
    (but, most callers still use BUG_ON())
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 4f19a3e1bf32..a2134195a85e 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -48,7 +48,8 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	struct extent_buffer *leaf;
 
 	path = btrfs_alloc_path();
-	BUG_ON(!path);
+	if (!path)
+		return -ENOMEM;
 	file_key.objectid = objectid;
 	file_key.offset = pos;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);

commit ad0397a7a97f55fd7f70998ec208c5d8b90310ff
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Jan 28 18:44:44 2011 +0000

    Btrfs: do error checking in btrfs_del_csums
    
    Got a report of a box panicing because we got a NULL eb in read_extent_buffer.
    His fs was borked and btrfs_search_path returned EIO, but we don't check for
    errors so the box paniced.  Yes I know this will just make something higher up
    the stack panic, but that's a problem for future Josef.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index d0bc72657cd7..4f19a3e1bf32 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -550,7 +550,10 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 			if (path->slots[0] == 0)
 				goto out;
 			path->slots[0]--;
+		} else if (ret < 0) {
+			goto out;
 		}
+
 		leaf = path->nodes[0];
 		btrfs_item_key_to_cpu(leaf, &key, path->slots[0]);
 

commit 2a29edc6b60a5248ccab588e7ba7dad38cef0235
Author: liubo <liubo2009@cn.fujitsu.com>
Date:   Wed Jan 26 06:22:08 2011 +0000

    btrfs: fix several uncheck memory allocations
    
    To make btrfs more stable, add several missing necessary memory allocation
    checks, and when no memory, return proper errno.
    
    We've checked that some of those -ENOMEM errors will be returned to
    userspace, and some will be catched by BUG_ON() in the upper callers,
    and none will be ignored silently.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a562a250ae77..d0bc72657cd7 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -536,6 +536,8 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 	root = root->fs_info->csum_root;
 
 	path = btrfs_alloc_path();
+	if (!path)
+		return -ENOMEM;
 
 	while (1) {
 		key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;

commit 4b46fce23349bfca781a32e2707a18328ca5ae22
Author: Josef Bacik <josef@redhat.com>
Date:   Sun May 23 11:00:55 2010 -0400

    Btrfs: add basic DIO read/write support
    
    This provides basic DIO support for reading and writing.  It does not do the
    work to recover from mismatching checksums, that will come later.  A few design
    changes have been made from Jim's code (sorry Jim!)
    
    1) Use the generic direct-io code.  Jim originally re-wrote all the generic DIO
    code in order to account for all of BTRFS's oddities, but thanks to that work it
    seems like the best bet is to just ignore compression and such and just opt to
    fallback on buffered IO.
    
    2) Fallback on buffered IO for compressed or inline extents.  Jim's code did
    it's own buffering to make dio with compressed extents work.  Now we just
    fallback onto normal buffered IO.
    
    3) Use ordered extents for the writes so that all of the
    
    lock_extent()
    lookup_ordered()
    
    type checks continue to work.
    
    4) Do the lock_extent() lookup_ordered() loop in readpage so we don't race with
    DIO writes.
    
    I've tested this with fsx and everything works great.  This patch depends on my
    dio and filemap.c patches to work.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 21aead39a76c..a562a250ae77 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -149,13 +149,14 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 }
 
 
-int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
-			  struct bio *bio, u32 *dst)
+static int __btrfs_lookup_bio_sums(struct btrfs_root *root,
+				   struct inode *inode, struct bio *bio,
+				   u64 logical_offset, u32 *dst, int dio)
 {
 	u32 sum;
 	struct bio_vec *bvec = bio->bi_io_vec;
 	int bio_index = 0;
-	u64 offset;
+	u64 offset = 0;
 	u64 item_start_offset = 0;
 	u64 item_last_offset = 0;
 	u64 disk_bytenr;
@@ -174,8 +175,11 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	WARN_ON(bio->bi_vcnt <= 0);
 
 	disk_bytenr = (u64)bio->bi_sector << 9;
+	if (dio)
+		offset = logical_offset;
 	while (bio_index < bio->bi_vcnt) {
-		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+		if (!dio)
+			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 		ret = btrfs_find_ordered_sum(inode, offset, disk_bytenr, &sum);
 		if (ret == 0)
 			goto found;
@@ -238,6 +242,7 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 		else
 			set_state_private(io_tree, offset, sum);
 		disk_bytenr += bvec->bv_len;
+		offset += bvec->bv_len;
 		bio_index++;
 		bvec++;
 	}
@@ -245,6 +250,18 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	return 0;
 }
 
+int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
+			  struct bio *bio, u32 *dst)
+{
+	return __btrfs_lookup_bio_sums(root, inode, bio, 0, dst, 0);
+}
+
+int btrfs_lookup_bio_sums_dio(struct btrfs_root *root, struct inode *inode,
+			      struct bio *bio, u64 offset, u32 *dst)
+{
+	return __btrfs_lookup_bio_sums(root, inode, bio, offset, dst, 1);
+}
+
 int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			     struct list_head *list)
 {

commit 4a500fd178c89b96fa166a2d9e7855df33429841
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:59 2010 -0400

    Btrfs: Metadata ENOSPC handling for tree log
    
    Previous patches make the allocater return -ENOSPC if there is no
    unreserved free metadata space. This patch updates tree log code
    and various other places to propagate/handle the ENOSPC error.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 54a255065aa3..21aead39a76c 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -657,6 +657,9 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		goto found;
 	}
 	ret = PTR_ERR(item);
+	if (ret != -EFBIG && ret != -ENOENT)
+		goto fail_unlock;
+
 	if (ret == -EFBIG) {
 		u32 item_size;
 		/* we found one, but it isn't big enough yet */

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 9b99886562d0..54a255065aa3 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -17,6 +17,7 @@
  */
 
 #include <linux/bio.h>
+#include <linux/slab.h>
 #include <linux/pagemap.h>
 #include <linux/highmem.h>
 #include "ctree.h"

commit b9473439d3e84d9fc1a0a83faca69cc1b7566341
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 11:00:37 2009 -0400

    Btrfs: leave btree locks spinning more often
    
    btrfs_mark_buffer dirty would set dirty bits in the extent_io tree
    for the buffers it was dirtying.  This may require a kmalloc and it
    was not atomic.  So, anyone who called btrfs_mark_buffer_dirty had to
    set any btree locks they were holding to blocking first.
    
    This commit changes dirty tracking for extent buffers to just use a flag
    in the extent buffer.  Now that we have one and only one extent buffer
    per page, this can be safely done without losing dirty bits along the way.
    
    This also introduces a path->leave_spinning flag that callers of
    btrfs_search_slot can use to indicate they will properly deal with a
    path returned where all the locks are spinning instead of blocking.
    
    Many of the btree search callers now expect spinning paths,
    resulting in better btree concurrency overall.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 964652435fd1..9b99886562d0 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -52,6 +52,7 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	file_key.offset = pos;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
 
+	path->leave_spinning = 1;
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      sizeof(*item));
 	if (ret < 0)
@@ -523,6 +524,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		key.offset = end_byte - 1;
 		key.type = BTRFS_EXTENT_CSUM_KEY;
 
+		path->leave_spinning = 1;
 		ret = btrfs_search_slot(trans, root, &key, path, -1, 1);
 		if (ret > 0) {
 			if (path->slots[0] == 0)
@@ -757,8 +759,10 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	} else {
 		ins_size = csum_size;
 	}
+	path->leave_spinning = 1;
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      ins_size);
+	path->leave_spinning = 0;
 	if (ret < 0)
 		goto fail_unlock;
 	if (ret != 0) {
@@ -776,7 +780,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	item_end = (struct btrfs_csum_item *)((unsigned char *)item_end +
 				      btrfs_item_size_nr(leaf, path->slots[0]));
 	eb_token = NULL;
-	cond_resched();
 next_sector:
 
 	if (!eb_token ||
@@ -817,9 +820,9 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		eb_token = NULL;
 	}
 	btrfs_mark_buffer_dirty(path->nodes[0]);
-	cond_resched();
 	if (total_bytes < sums->len) {
 		btrfs_release_path(root, path);
+		cond_resched();
 		goto again;
 	}
 out:

commit 07d400a6df4767a90d49a153fdb7f4cfa1e3f23e
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Tue Jan 6 11:42:00 2009 -0500

    Btrfs: tree logging checksum fixes
    
    This patch contains following things.
    
    1) Limit the max size of btrfs_ordered_sum structure to PAGE_SIZE.  This
    struct is kmalloced so we want to keep it reasonable.
    
    2) Replace copy_extent_csums by btrfs_lookup_csums_range.  This was
    duplicated code in tree-log.c
    
    3) Remove replay_one_csum. csum items are replayed at the same time as
       replaying file extents. This guarantees we only replay useful csums.
    
    4) nbytes accounting fix.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index b11abfad81a5..964652435fd1 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -27,6 +27,12 @@
 #define MAX_CSUM_ITEMS(r, size) ((((BTRFS_LEAF_DATA_SIZE(r) - \
 				   sizeof(struct btrfs_item) * 2) / \
 				  size) - 1))
+
+#define MAX_ORDERED_SUM_BYTES(r) ((PAGE_SIZE - \
+				   sizeof(struct btrfs_ordered_sum)) / \
+				   sizeof(struct btrfs_sector_sum) * \
+				   (r)->sectorsize - (r)->sectorsize)
+
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,
@@ -259,8 +265,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	key.offset = start;
 	key.type = BTRFS_EXTENT_CSUM_KEY;
 
-	ret = btrfs_search_slot(NULL, root->fs_info->csum_root,
-				&key, path, 0, 0);
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
 	if (ret < 0)
 		goto fail;
 	if (ret > 0 && path->slots[0] > 0) {
@@ -279,7 +284,7 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 	while (start <= end) {
 		leaf = path->nodes[0];
 		if (path->slots[0] >= btrfs_header_nritems(leaf)) {
-			ret = btrfs_next_leaf(root->fs_info->csum_root, path);
+			ret = btrfs_next_leaf(root, path);
 			if (ret < 0)
 				goto fail;
 			if (ret > 0)
@@ -306,33 +311,38 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 			continue;
 		}
 
-		size = min(csum_end, end + 1) - start;
-		sums = kzalloc(btrfs_ordered_sum_size(root, size), GFP_NOFS);
-		BUG_ON(!sums);
+		csum_end = min(csum_end, end + 1);
+		item = btrfs_item_ptr(path->nodes[0], path->slots[0],
+				      struct btrfs_csum_item);
+		while (start < csum_end) {
+			size = min_t(size_t, csum_end - start,
+					MAX_ORDERED_SUM_BYTES(root));
+			sums = kzalloc(btrfs_ordered_sum_size(root, size),
+					GFP_NOFS);
+			BUG_ON(!sums);
 
-		sector_sum = sums->sums;
-		sums->bytenr = start;
-		sums->len = size;
+			sector_sum = sums->sums;
+			sums->bytenr = start;
+			sums->len = size;
 
-		offset = (start - key.offset) >>
-			 root->fs_info->sb->s_blocksize_bits;
-		offset *= csum_size;
+			offset = (start - key.offset) >>
+				root->fs_info->sb->s_blocksize_bits;
+			offset *= csum_size;
 
-		item = btrfs_item_ptr(path->nodes[0], path->slots[0],
-				      struct btrfs_csum_item);
-		while (size > 0) {
-			read_extent_buffer(path->nodes[0], &sector_sum->sum,
-					   ((unsigned long)item) + offset,
-					   csum_size);
-			sector_sum->bytenr = start;
-
-			size -= root->sectorsize;
-			start += root->sectorsize;
-			offset += csum_size;
-			sector_sum++;
+			while (size > 0) {
+				read_extent_buffer(path->nodes[0],
+						&sector_sum->sum,
+						((unsigned long)item) +
+						offset, csum_size);
+				sector_sum->bytenr = start;
+
+				size -= root->sectorsize;
+				start += root->sectorsize;
+				offset += csum_size;
+				sector_sum++;
+			}
+			list_add_tail(&sums->list, list);
 		}
-		list_add_tail(&sums->list, list);
-
 		path->slots[0]++;
 	}
 	ret = 0;

commit d397712bcc6a759a560fd247e6053ecae091f958
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 5 21:25:51 2009 -0500

    Btrfs: Fix checkpatch.pl warnings
    
    There were many, most are fixed now.  struct-funcs.c generates some warnings
    but these are bogus.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index cc6e0b6de949..b11abfad81a5 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -24,7 +24,7 @@
 #include "transaction.h"
 #include "print-tree.h"
 
-#define MAX_CSUM_ITEMS(r,size) ((((BTRFS_LEAF_DATA_SIZE(r) - \
+#define MAX_CSUM_ITEMS(r, size) ((((BTRFS_LEAF_DATA_SIZE(r) - \
 				   sizeof(struct btrfs_item) * 2) / \
 				  size) - 1))
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
@@ -166,7 +166,7 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	WARN_ON(bio->bi_vcnt <= 0);
 
 	disk_bytenr = (u64)bio->bi_sector << 9;
-	while(bio_index < bio->bi_vcnt) {
+	while (bio_index < bio->bi_vcnt) {
 		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 		ret = btrfs_find_ordered_sum(inode, offset, disk_bytenr, &sum);
 		if (ret == 0)
@@ -192,8 +192,9 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 						offset + bvec->bv_len - 1,
 						EXTENT_NODATASUM, GFP_NOFS);
 				} else {
-					printk("no csum found for inode %lu "
-					       "start %llu\n", inode->i_ino,
+					printk(KERN_INFO "btrfs no csum found "
+					       "for inode %lu start %llu\n",
+					       inode->i_ino,
 					       (unsigned long long)offset);
 				}
 				item = NULL;
@@ -373,7 +374,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	BUG_ON(!ordered);
 	sums->bytenr = ordered->start;
 
-	while(bio_index < bio->bi_vcnt) {
+	while (bio_index < bio->bi_vcnt) {
 		if (!contig)
 			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 
@@ -507,7 +508,7 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 
 	path = btrfs_alloc_path();
 
-	while(1) {
+	while (1) {
 		key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
 		key.offset = end_byte - 1;
 		key.type = BTRFS_EXTENT_CSUM_KEY;
@@ -715,9 +716,8 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			goto csum;
 
 		diff = diff - btrfs_item_size_nr(leaf, path->slots[0]);
-		if (diff != csum_size) {
+		if (diff != csum_size)
 			goto insert;
-		}
 
 		ret = btrfs_extend_item(trans, root, path, diff);
 		BUG_ON(ret);
@@ -732,7 +732,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		u64 next_sector = sector_sum->bytenr;
 		struct btrfs_sector_sum *next = sector_sum + 1;
 
-		while(tmp < sums->len) {
+		while (tmp < sums->len) {
 			if (next_sector + root->sectorsize != next->bytenr)
 				break;
 			tmp += root->sectorsize;

commit 87b29b208c6c38f3446d2de6ece946e2459052cf
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Dec 17 10:21:48 2008 -0500

    Btrfs: properly check free space for tree balancing
    
    btrfs_insert_empty_items takes the space needed by the btrfs_item
    structure into account when calculating the required free space.
    
    So the tree balancing code shouldn't add sizeof(struct btrfs_item)
    to the size when checking the free space. This patch removes these
    superfluous additions.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 7acadf3b742a..cc6e0b6de949 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -300,6 +300,10 @@ int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
 
 		size = btrfs_item_size_nr(leaf, path->slots[0]);
 		csum_end = key.offset + (size / csum_size) * root->sectorsize;
+		if (csum_end <= start) {
+			path->slots[0]++;
+			continue;
+		}
 
 		size = min(csum_end, end + 1) - start;
 		sums = kzalloc(btrfs_ordered_sum_size(root, size), GFP_NOFS);

commit dcbdd4dcb9793b00b46ab023e9330922c8c7c54c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 16 13:51:01 2008 -0500

    Btrfs: delete checksum items before marking blocks free
    
    Btrfs maintains a cache of blocks available for allocation in ram.  The
    code that frees extents was marking the extents free and then deleting
    the checksum items.
    
    This meant it was possible the extent would be reallocated before the
    checksum item was actually deleted, leading to races and other
    problems as the checksums were updated for the newly allocated extent.
    
    The fix is to delete the checksum before marking the extent free.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index df0447632dbd..7acadf3b742a 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -537,6 +537,8 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 		if (key.offset >= bytenr && csum_end <= end_byte) {
 			ret = btrfs_del_item(trans, root, path);
 			BUG_ON(ret);
+			if (key.offset == bytenr)
+				break;
 		} else if (key.offset < bytenr && csum_end > end_byte) {
 			unsigned long offset;
 			unsigned long shift_len;
@@ -583,6 +585,8 @@ int btrfs_del_csums(struct btrfs_trans_handle *trans,
 			ret = truncate_one_csum(trans, root, path,
 						&key, bytenr, len);
 			BUG_ON(ret);
+			if (key.offset < bytenr)
+				break;
 		}
 		btrfs_release_path(root, path);
 	}

commit 17d217fe970d34720f4f1633dca73a6aa2f3d9d1
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Fri Dec 12 10:03:38 2008 -0500

    Btrfs: fix nodatasum handling in balancing code
    
    Checksums on data can be disabled by mount option, so it's
    possible some data extents don't have checksums or have
    invalid checksums. This causes trouble for data relocation.
    This patch contains following things to make data relocation
    work.
    
    1) make nodatasum/nodatacow mount option only affects new
    files. Checksums and COW on data are only controlled by the
    inode flags.
    
    2) check the existence of checksum in the nodatacow checker.
    If checksums exist, force COW the data extent. This ensure that
    checksum for a given block is either valid or does not exist.
    
    3) update data relocation code to properly handle the case
    of checksum missing.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 3ebef871ee6c..df0447632dbd 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -140,6 +140,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
+
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio, u32 *dst)
 {
@@ -185,9 +186,16 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 				if (ret == -ENOENT || ret == -EFBIG)
 					ret = 0;
 				sum = 0;
-				printk("no csum found for inode %lu start "
-				       "%llu\n", inode->i_ino,
-				       (unsigned long long)offset);
+				if (BTRFS_I(inode)->root->root_key.objectid ==
+				    BTRFS_DATA_RELOC_TREE_OBJECTID) {
+					set_extent_bits(io_tree, offset,
+						offset + bvec->bv_len - 1,
+						EXTENT_NODATASUM, GFP_NOFS);
+				} else {
+					printk("no csum found for inode %lu "
+					       "start %llu\n", inode->i_ino,
+					       (unsigned long long)offset);
+				}
 				item = NULL;
 				btrfs_release_path(root, path);
 				goto found;
@@ -228,6 +236,106 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	return 0;
 }
 
+int btrfs_lookup_csums_range(struct btrfs_root *root, u64 start, u64 end,
+			     struct list_head *list)
+{
+	struct btrfs_key key;
+	struct btrfs_path *path;
+	struct extent_buffer *leaf;
+	struct btrfs_ordered_sum *sums;
+	struct btrfs_sector_sum *sector_sum;
+	struct btrfs_csum_item *item;
+	unsigned long offset;
+	int ret;
+	size_t size;
+	u64 csum_end;
+	u16 csum_size = btrfs_super_csum_size(&root->fs_info->super_copy);
+
+	path = btrfs_alloc_path();
+	BUG_ON(!path);
+
+	key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
+	key.offset = start;
+	key.type = BTRFS_EXTENT_CSUM_KEY;
+
+	ret = btrfs_search_slot(NULL, root->fs_info->csum_root,
+				&key, path, 0, 0);
+	if (ret < 0)
+		goto fail;
+	if (ret > 0 && path->slots[0] > 0) {
+		leaf = path->nodes[0];
+		btrfs_item_key_to_cpu(leaf, &key, path->slots[0] - 1);
+		if (key.objectid == BTRFS_EXTENT_CSUM_OBJECTID &&
+		    key.type == BTRFS_EXTENT_CSUM_KEY) {
+			offset = (start - key.offset) >>
+				 root->fs_info->sb->s_blocksize_bits;
+			if (offset * csum_size <
+			    btrfs_item_size_nr(leaf, path->slots[0] - 1))
+				path->slots[0]--;
+		}
+	}
+
+	while (start <= end) {
+		leaf = path->nodes[0];
+		if (path->slots[0] >= btrfs_header_nritems(leaf)) {
+			ret = btrfs_next_leaf(root->fs_info->csum_root, path);
+			if (ret < 0)
+				goto fail;
+			if (ret > 0)
+				break;
+			leaf = path->nodes[0];
+		}
+
+		btrfs_item_key_to_cpu(leaf, &key, path->slots[0]);
+		if (key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
+		    key.type != BTRFS_EXTENT_CSUM_KEY)
+			break;
+
+		btrfs_item_key_to_cpu(leaf, &key, path->slots[0]);
+		if (key.offset > end)
+			break;
+
+		if (key.offset > start)
+			start = key.offset;
+
+		size = btrfs_item_size_nr(leaf, path->slots[0]);
+		csum_end = key.offset + (size / csum_size) * root->sectorsize;
+
+		size = min(csum_end, end + 1) - start;
+		sums = kzalloc(btrfs_ordered_sum_size(root, size), GFP_NOFS);
+		BUG_ON(!sums);
+
+		sector_sum = sums->sums;
+		sums->bytenr = start;
+		sums->len = size;
+
+		offset = (start - key.offset) >>
+			 root->fs_info->sb->s_blocksize_bits;
+		offset *= csum_size;
+
+		item = btrfs_item_ptr(path->nodes[0], path->slots[0],
+				      struct btrfs_csum_item);
+		while (size > 0) {
+			read_extent_buffer(path->nodes[0], &sector_sum->sum,
+					   ((unsigned long)item) + offset,
+					   csum_size);
+			sector_sum->bytenr = start;
+
+			size -= root->sectorsize;
+			start += root->sectorsize;
+			offset += csum_size;
+			sector_sum++;
+		}
+		list_add_tail(&sums->list, list);
+
+		path->slots[0]++;
+	}
+	ret = 0;
+fail:
+	btrfs_free_path(path);
+	return ret;
+}
+
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio, u64 file_start, int contig)
 {

commit 459931eca5f4b8c9ad259d07cc1ca49afed54804
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Dec 10 09:10:46 2008 -0500

    Btrfs: Delete csum items when freeing extents
    
    This finishes off the new checksumming code by removing csum items
    for extents that are no longer in use.
    
    The trick is doing it without racing because a single csum item may
    hold csums for more than one extent.  Extra checks are added to
    btrfs_csum_file_blocks to make sure that we are using the correct
    csum item after dropping locks.
    
    A new btrfs_split_item is added to split a single csum item so it
    can be split without dropping the leaf lock.  This is used to
    remove csum bytes from the middle of an item.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a3ad2ce00116..3ebef871ee6c 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -310,6 +310,179 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	return 0;
 }
 
+/*
+ * helper function for csum removal, this expects the
+ * key to describe the csum pointed to by the path, and it expects
+ * the csum to overlap the range [bytenr, len]
+ *
+ * The csum should not be entirely contained in the range and the
+ * range should not be entirely contained in the csum.
+ *
+ * This calls btrfs_truncate_item with the correct args based on the
+ * overlap, and fixes up the key as required.
+ */
+static noinline int truncate_one_csum(struct btrfs_trans_handle *trans,
+				      struct btrfs_root *root,
+				      struct btrfs_path *path,
+				      struct btrfs_key *key,
+				      u64 bytenr, u64 len)
+{
+	struct extent_buffer *leaf;
+	u16 csum_size =
+		btrfs_super_csum_size(&root->fs_info->super_copy);
+	u64 csum_end;
+	u64 end_byte = bytenr + len;
+	u32 blocksize_bits = root->fs_info->sb->s_blocksize_bits;
+	int ret;
+
+	leaf = path->nodes[0];
+	csum_end = btrfs_item_size_nr(leaf, path->slots[0]) / csum_size;
+	csum_end <<= root->fs_info->sb->s_blocksize_bits;
+	csum_end += key->offset;
+
+	if (key->offset < bytenr && csum_end <= end_byte) {
+		/*
+		 *         [ bytenr - len ]
+		 *         [   ]
+		 *   [csum     ]
+		 *   A simple truncate off the end of the item
+		 */
+		u32 new_size = (bytenr - key->offset) >> blocksize_bits;
+		new_size *= csum_size;
+		ret = btrfs_truncate_item(trans, root, path, new_size, 1);
+		BUG_ON(ret);
+	} else if (key->offset >= bytenr && csum_end > end_byte &&
+		   end_byte > key->offset) {
+		/*
+		 *         [ bytenr - len ]
+		 *                 [ ]
+		 *                 [csum     ]
+		 * we need to truncate from the beginning of the csum
+		 */
+		u32 new_size = (csum_end - end_byte) >> blocksize_bits;
+		new_size *= csum_size;
+
+		ret = btrfs_truncate_item(trans, root, path, new_size, 0);
+		BUG_ON(ret);
+
+		key->offset = end_byte;
+		ret = btrfs_set_item_key_safe(trans, root, path, key);
+		BUG_ON(ret);
+	} else {
+		BUG();
+	}
+	return 0;
+}
+
+/*
+ * deletes the csum items from the csum tree for a given
+ * range of bytes.
+ */
+int btrfs_del_csums(struct btrfs_trans_handle *trans,
+		    struct btrfs_root *root, u64 bytenr, u64 len)
+{
+	struct btrfs_path *path;
+	struct btrfs_key key;
+	u64 end_byte = bytenr + len;
+	u64 csum_end;
+	struct extent_buffer *leaf;
+	int ret;
+	u16 csum_size =
+		btrfs_super_csum_size(&root->fs_info->super_copy);
+	int blocksize_bits = root->fs_info->sb->s_blocksize_bits;
+
+	root = root->fs_info->csum_root;
+
+	path = btrfs_alloc_path();
+
+	while(1) {
+		key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
+		key.offset = end_byte - 1;
+		key.type = BTRFS_EXTENT_CSUM_KEY;
+
+		ret = btrfs_search_slot(trans, root, &key, path, -1, 1);
+		if (ret > 0) {
+			if (path->slots[0] == 0)
+				goto out;
+			path->slots[0]--;
+		}
+		leaf = path->nodes[0];
+		btrfs_item_key_to_cpu(leaf, &key, path->slots[0]);
+
+		if (key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
+		    key.type != BTRFS_EXTENT_CSUM_KEY) {
+			break;
+		}
+
+		if (key.offset >= end_byte)
+			break;
+
+		csum_end = btrfs_item_size_nr(leaf, path->slots[0]) / csum_size;
+		csum_end <<= blocksize_bits;
+		csum_end += key.offset;
+
+		/* this csum ends before we start, we're done */
+		if (csum_end <= bytenr)
+			break;
+
+		/* delete the entire item, it is inside our range */
+		if (key.offset >= bytenr && csum_end <= end_byte) {
+			ret = btrfs_del_item(trans, root, path);
+			BUG_ON(ret);
+		} else if (key.offset < bytenr && csum_end > end_byte) {
+			unsigned long offset;
+			unsigned long shift_len;
+			unsigned long item_offset;
+			/*
+			 *        [ bytenr - len ]
+			 *     [csum                ]
+			 *
+			 * Our bytes are in the middle of the csum,
+			 * we need to split this item and insert a new one.
+			 *
+			 * But we can't drop the path because the
+			 * csum could change, get removed, extended etc.
+			 *
+			 * The trick here is the max size of a csum item leaves
+			 * enough room in the tree block for a single
+			 * item header.  So, we split the item in place,
+			 * adding a new header pointing to the existing
+			 * bytes.  Then we loop around again and we have
+			 * a nicely formed csum item that we can neatly
+			 * truncate.
+			 */
+			offset = (bytenr - key.offset) >> blocksize_bits;
+			offset *= csum_size;
+
+			shift_len = (len >> blocksize_bits) * csum_size;
+
+			item_offset = btrfs_item_ptr_offset(leaf,
+							    path->slots[0]);
+
+			memset_extent_buffer(leaf, 0, item_offset + offset,
+					     shift_len);
+			key.offset = bytenr;
+
+			/*
+			 * btrfs_split_item returns -EAGAIN when the
+			 * item changed size or key
+			 */
+			ret = btrfs_split_item(trans, root, path, &key, offset);
+			BUG_ON(ret && ret != -EAGAIN);
+
+			key.offset = end_byte - 1;
+		} else {
+			ret = truncate_one_csum(trans, root, path,
+						&key, bytenr, len);
+			BUG_ON(ret);
+		}
+		btrfs_release_path(root, path);
+	}
+out:
+	btrfs_free_path(path);
+	return 0;
+}
+
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums)
@@ -396,28 +569,40 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 				csum_size, 1);
 	if (ret < 0)
 		goto fail_unlock;
-	if (ret == 0) {
-		BUG();
-	}
-	if (path->slots[0] == 0) {
-		goto insert;
+
+	if (ret > 0) {
+		if (path->slots[0] == 0)
+			goto insert;
+		path->slots[0]--;
 	}
-	path->slots[0]--;
+
 	leaf = path->nodes[0];
 	btrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);
 	csum_offset = (bytenr - found_key.offset) >>
 			root->fs_info->sb->s_blocksize_bits;
+
 	if (btrfs_key_type(&found_key) != BTRFS_EXTENT_CSUM_KEY ||
 	    found_key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
 	    csum_offset >= MAX_CSUM_ITEMS(root, csum_size)) {
 		goto insert;
 	}
+
 	if (csum_offset >= btrfs_item_size_nr(leaf, path->slots[0]) /
 	    csum_size) {
 		u32 diff = (csum_offset + 1) * csum_size;
+
+		/*
+		 * is the item big enough already?  we dropped our lock
+		 * before and need to recheck
+		 */
+		if (diff < btrfs_item_size_nr(leaf, path->slots[0]))
+			goto csum;
+
 		diff = diff - btrfs_item_size_nr(leaf, path->slots[0]);
-		if (diff != csum_size)
+		if (diff != csum_size) {
 			goto insert;
+		}
+
 		ret = btrfs_extend_item(trans, root, path, diff);
 		BUG_ON(ret);
 		goto csum;
@@ -518,30 +703,3 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 fail_unlock:
 	goto out;
 }
-
-int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
-			struct btrfs_root *root, struct btrfs_path *path,
-			u64 isize)
-{
-	struct btrfs_key key;
-	struct extent_buffer *leaf = path->nodes[0];
-	int slot = path->slots[0];
-	int ret;
-	u32 new_item_size;
-	u64 new_item_span;
-	u64 blocks;
-
-	btrfs_item_key_to_cpu(leaf, &key, slot);
-	if (isize <= key.offset)
-		return 0;
-	new_item_span = isize - key.offset;
-	blocks = (new_item_span + root->sectorsize - 1) >>
-		root->fs_info->sb->s_blocksize_bits;
-	new_item_size = blocks *
-		btrfs_super_csum_size(&root->fs_info->super_copy);
-	if (new_item_size >= btrfs_item_size_nr(leaf, slot))
-		return 0;
-	ret = btrfs_truncate_item(trans, root, path, new_item_size, 1);
-	BUG_ON(ret);
-	return ret;
-}

commit d20f7043fa65659136c1a7c3c456eeeb5c6f431f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 8 16:58:54 2008 -0500

    Btrfs: move data checksumming into a dedicated tree
    
    Btrfs stores checksums for each data block.  Until now, they have
    been stored in the subvolume trees, indexed by the inode that is
    referencing the data block.  This means that when we read the inode,
    we've probably read in at least some checksums as well.
    
    But, this has a few problems:
    
    * The checksums are indexed by logical offset in the file.  When
    compression is on, this means we have to do the expensive checksumming
    on the uncompressed data.  It would be faster if we could checksum
    the compressed data instead.
    
    * If we implement encryption, we'll be checksumming the plain text and
    storing that on disk.  This is significantly less secure.
    
    * For either compression or encryption, we have to get the plain text
    back before we can verify the checksum as correct.  This makes the raid
    layer balancing and extent moving much more expensive.
    
    * It makes the front end caching code more complex, as we have touch
    the subvolume and inodes as we cache extents.
    
    * There is potentitally one copy of the checksum in each subvolume
    referencing an extent.
    
    The solution used here is to store the extent checksums in a dedicated
    tree.  This allows us to index the checksums by phyiscal extent
    start and length.  It means:
    
    * The checksum is against the data stored on disk, after any compression
    or encryption is done.
    
    * The checksum is stored in a central location, and can be verified without
    following back references, or reading inodes.
    
    This makes compression significantly faster by reducing the amount of
    data that needs to be checksummed.  It will also allow much faster
    raid management code in general.
    
    The checksums are indexed by a key with a fixed objectid (a magic value
    in ctree.h) and offset set to the starting byte of the extent.  This
    allows us to copy the checksum items into the fsync log tree directly (or
    any other tree), without having to invent a second format for them.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 234ed441736c..a3ad2ce00116 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -74,8 +74,7 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 					  struct btrfs_root *root,
 					  struct btrfs_path *path,
-					  u64 objectid, u64 offset,
-					  int cow)
+					  u64 bytenr, int cow)
 {
 	int ret;
 	struct btrfs_key file_key;
@@ -87,9 +86,9 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 		btrfs_super_csum_size(&root->fs_info->super_copy);
 	int csums_in_item;
 
-	file_key.objectid = objectid;
-	file_key.offset = offset;
-	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
+	file_key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
+	file_key.offset = bytenr;
+	btrfs_set_key_type(&file_key, BTRFS_EXTENT_CSUM_KEY);
 	ret = btrfs_search_slot(trans, root, &file_key, path, 0, cow);
 	if (ret < 0)
 		goto fail;
@@ -100,11 +99,10 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 			goto fail;
 		path->slots[0]--;
 		btrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);
-		if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
-		    found_key.objectid != objectid) {
+		if (btrfs_key_type(&found_key) != BTRFS_EXTENT_CSUM_KEY)
 			goto fail;
-		}
-		csum_offset = (offset - found_key.offset) >>
+
+		csum_offset = (bytenr - found_key.offset) >>
 				root->fs_info->sb->s_blocksize_bits;
 		csums_in_item = btrfs_item_size_nr(leaf, path->slots[0]);
 		csums_in_item /= csum_size;
@@ -143,7 +141,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 }
 
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
-			  struct bio *bio)
+			  struct bio *bio, u32 *dst)
 {
 	u32 sum;
 	struct bio_vec *bvec = bio->bi_io_vec;
@@ -151,6 +149,7 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	u64 offset;
 	u64 item_start_offset = 0;
 	u64 item_last_offset = 0;
+	u64 disk_bytenr;
 	u32 diff;
 	u16 csum_size =
 		btrfs_super_csum_size(&root->fs_info->super_copy);
@@ -165,21 +164,22 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 
 	WARN_ON(bio->bi_vcnt <= 0);
 
+	disk_bytenr = (u64)bio->bi_sector << 9;
 	while(bio_index < bio->bi_vcnt) {
 		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
-		ret = btrfs_find_ordered_sum(inode, offset, &sum);
+		ret = btrfs_find_ordered_sum(inode, offset, disk_bytenr, &sum);
 		if (ret == 0)
 			goto found;
 
-		if (!item || offset < item_start_offset ||
-		    offset >= item_last_offset) {
+		if (!item || disk_bytenr < item_start_offset ||
+		    disk_bytenr >= item_last_offset) {
 			struct btrfs_key found_key;
 			u32 item_size;
 
 			if (item)
 				btrfs_release_path(root, path);
-			item = btrfs_lookup_csum(NULL, root, path,
-						 inode->i_ino, offset, 0);
+			item = btrfs_lookup_csum(NULL, root->fs_info->csum_root,
+						 path, disk_bytenr, 0);
 			if (IS_ERR(item)) {
 				ret = PTR_ERR(item);
 				if (ret == -ENOENT || ret == -EFBIG)
@@ -208,7 +208,7 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 		 * this byte range must be able to fit inside
 		 * a single leaf so it will also fit inside a u32
 		 */
-		diff = offset - item_start_offset;
+		diff = disk_bytenr - item_start_offset;
 		diff = diff / root->sectorsize;
 		diff = diff * csum_size;
 
@@ -216,7 +216,11 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 				   ((unsigned long)item) + diff,
 				   csum_size);
 found:
-		set_state_private(io_tree, offset, sum);
+		if (dst)
+			*dst++ = sum;
+		else
+			set_state_private(io_tree, offset, sum);
+		disk_bytenr += bvec->bv_len;
 		bio_index++;
 		bvec++;
 	}
@@ -224,75 +228,8 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	return 0;
 }
 
-int btrfs_csum_file_bytes(struct btrfs_root *root, struct inode *inode,
-			  u64 start, unsigned long len)
-{
-	struct btrfs_ordered_sum *sums;
-	struct btrfs_sector_sum *sector_sum;
-	struct btrfs_ordered_extent *ordered;
-	char *data;
-	struct page *page;
-	unsigned long total_bytes = 0;
-	unsigned long this_sum_bytes = 0;
-
-	sums = kzalloc(btrfs_ordered_sum_size(root, len), GFP_NOFS);
-	if (!sums)
-		return -ENOMEM;
-
-	sector_sum = sums->sums;
-	sums->file_offset = start;
-	sums->len = len;
-	INIT_LIST_HEAD(&sums->list);
-	ordered = btrfs_lookup_ordered_extent(inode, sums->file_offset);
-	BUG_ON(!ordered);
-
-	while(len > 0) {
-		if (start >= ordered->file_offset + ordered->len ||
-		    start < ordered->file_offset) {
-			sums->len = this_sum_bytes;
-			this_sum_bytes = 0;
-			btrfs_add_ordered_sum(inode, ordered, sums);
-			btrfs_put_ordered_extent(ordered);
-
-			sums = kzalloc(btrfs_ordered_sum_size(root, len),
-				       GFP_NOFS);
-			BUG_ON(!sums);
-			sector_sum = sums->sums;
-			sums->len = len;
-			sums->file_offset = start;
-			ordered = btrfs_lookup_ordered_extent(inode,
-						      sums->file_offset);
-			BUG_ON(!ordered);
-		}
-
-		page = find_get_page(inode->i_mapping,
-				     start >> PAGE_CACHE_SHIFT);
-
-		data = kmap_atomic(page, KM_USER0);
-		sector_sum->sum = ~(u32)0;
-		sector_sum->sum = btrfs_csum_data(root, data, sector_sum->sum,
-						  PAGE_CACHE_SIZE);
-		kunmap_atomic(data, KM_USER0);
-		btrfs_csum_final(sector_sum->sum,
-				 (char *)&sector_sum->sum);
-		sector_sum->offset = page_offset(page);
-		page_cache_release(page);
-
-		sector_sum++;
-		total_bytes += PAGE_CACHE_SIZE;
-		this_sum_bytes += PAGE_CACHE_SIZE;
-		start += PAGE_CACHE_SIZE;
-
-		WARN_ON(len < PAGE_CACHE_SIZE);
-		len -= PAGE_CACHE_SIZE;
-	}
-	btrfs_add_ordered_sum(inode, ordered, sums);
-	btrfs_put_ordered_extent(ordered);
-	return 0;
-}
-
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
-		       struct bio *bio)
+		       struct bio *bio, u64 file_start, int contig)
 {
 	struct btrfs_ordered_sum *sums;
 	struct btrfs_sector_sum *sector_sum;
@@ -303,6 +240,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	unsigned long total_bytes = 0;
 	unsigned long this_sum_bytes = 0;
 	u64 offset;
+	u64 disk_bytenr;
 
 	WARN_ON(bio->bi_vcnt <= 0);
 	sums = kzalloc(btrfs_ordered_sum_size(root, bio->bi_size), GFP_NOFS);
@@ -310,16 +248,25 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		return -ENOMEM;
 
 	sector_sum = sums->sums;
-	sums->file_offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+	disk_bytenr = (u64)bio->bi_sector << 9;
 	sums->len = bio->bi_size;
 	INIT_LIST_HEAD(&sums->list);
-	ordered = btrfs_lookup_ordered_extent(inode, sums->file_offset);
+
+	if (contig)
+		offset = file_start;
+	else
+		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+
+	ordered = btrfs_lookup_ordered_extent(inode, offset);
 	BUG_ON(!ordered);
+	sums->bytenr = ordered->start;
 
 	while(bio_index < bio->bi_vcnt) {
-		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
-		if (offset >= ordered->file_offset + ordered->len ||
-		    offset < ordered->file_offset) {
+		if (!contig)
+			offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+
+		if (!contig && (offset >= ordered->file_offset + ordered->len ||
+		    offset < ordered->file_offset)) {
 			unsigned long bytes_left;
 			sums->len = this_sum_bytes;
 			this_sum_bytes = 0;
@@ -333,10 +280,9 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 			BUG_ON(!sums);
 			sector_sum = sums->sums;
 			sums->len = bytes_left;
-			sums->file_offset = offset;
-			ordered = btrfs_lookup_ordered_extent(inode,
-						      sums->file_offset);
+			ordered = btrfs_lookup_ordered_extent(inode, offset);
 			BUG_ON(!ordered);
+			sums->bytenr = ordered->start;
 		}
 
 		data = kmap_atomic(bvec->bv_page, KM_USER0);
@@ -348,13 +294,14 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		kunmap_atomic(data, KM_USER0);
 		btrfs_csum_final(sector_sum->sum,
 				 (char *)&sector_sum->sum);
-		sector_sum->offset = page_offset(bvec->bv_page) +
-			bvec->bv_offset;
+		sector_sum->bytenr = disk_bytenr;
 
 		sector_sum++;
 		bio_index++;
 		total_bytes += bvec->bv_len;
 		this_sum_bytes += bvec->bv_len;
+		disk_bytenr += bvec->bv_len;
+		offset += bvec->bv_len;
 		bvec++;
 	}
 	this_sum_bytes = 0;
@@ -364,11 +311,10 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 }
 
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
-			   struct btrfs_root *root, struct inode *inode,
+			   struct btrfs_root *root,
 			   struct btrfs_ordered_sum *sums)
 {
-	u64 objectid = inode->i_ino;
-	u64 offset;
+	u64 bytenr;
 	int ret;
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
@@ -396,13 +342,12 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 again:
 	next_offset = (u64)-1;
 	found_next = 0;
-	offset = sector_sum->offset;
-	file_key.objectid = objectid;
-	file_key.offset = offset;
-	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
+	file_key.objectid = BTRFS_EXTENT_CSUM_OBJECTID;
+	file_key.offset = sector_sum->bytenr;
+	bytenr = sector_sum->bytenr;
+	btrfs_set_key_type(&file_key, BTRFS_EXTENT_CSUM_KEY);
 
-	mutex_lock(&BTRFS_I(inode)->csum_mutex);
-	item = btrfs_lookup_csum(trans, root, path, objectid, offset, 1);
+	item = btrfs_lookup_csum(trans, root, path, sector_sum->bytenr, 1);
 	if (!IS_ERR(item)) {
 		leaf = path->nodes[0];
 		ret = 0;
@@ -432,8 +377,8 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			slot = 0;
 		}
 		btrfs_item_key_to_cpu(path->nodes[0], &found_key, slot);
-		if (found_key.objectid != objectid ||
-		    found_key.type != BTRFS_CSUM_ITEM_KEY) {
+		if (found_key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
+		    found_key.type != BTRFS_EXTENT_CSUM_KEY) {
 			found_next = 1;
 			goto insert;
 		}
@@ -460,10 +405,10 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	path->slots[0]--;
 	leaf = path->nodes[0];
 	btrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);
-	csum_offset = (offset - found_key.offset) >>
+	csum_offset = (bytenr - found_key.offset) >>
 			root->fs_info->sb->s_blocksize_bits;
-	if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
-	    found_key.objectid != objectid ||
+	if (btrfs_key_type(&found_key) != BTRFS_EXTENT_CSUM_KEY ||
+	    found_key.objectid != BTRFS_EXTENT_CSUM_OBJECTID ||
 	    csum_offset >= MAX_CSUM_ITEMS(root, csum_size)) {
 		goto insert;
 	}
@@ -482,8 +427,18 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	btrfs_release_path(root, path);
 	csum_offset = 0;
 	if (found_next) {
-		u64 tmp = min((u64)i_size_read(inode), next_offset);
-		tmp -= offset & ~((u64)root->sectorsize -1);
+		u64 tmp = total_bytes + root->sectorsize;
+		u64 next_sector = sector_sum->bytenr;
+		struct btrfs_sector_sum *next = sector_sum + 1;
+
+		while(tmp < sums->len) {
+			if (next_sector + root->sectorsize != next->bytenr)
+				break;
+			tmp += root->sectorsize;
+			next_sector = next->bytenr;
+			next++;
+		}
+		tmp = min(tmp, next_offset - file_key.offset);
 		tmp >>= root->fs_info->sb->s_blocksize_bits;
 		tmp = max((u64)1, tmp);
 		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(root, csum_size));
@@ -510,7 +465,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	item_end = (struct btrfs_csum_item *)((unsigned char *)item_end +
 				      btrfs_item_size_nr(leaf, path->slots[0]));
 	eb_token = NULL;
-	mutex_unlock(&BTRFS_I(inode)->csum_mutex);
 	cond_resched();
 next_sector:
 
@@ -541,9 +495,9 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	if (total_bytes < sums->len) {
 		item = (struct btrfs_csum_item *)((char *)item +
 						  csum_size);
-		if (item < item_end && offset + PAGE_CACHE_SIZE ==
-		    sector_sum->offset) {
-			    offset = sector_sum->offset;
+		if (item < item_end && bytenr + PAGE_CACHE_SIZE ==
+		    sector_sum->bytenr) {
+			bytenr = sector_sum->bytenr;
 			goto next_sector;
 		}
 	}
@@ -562,7 +516,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	return ret;
 
 fail_unlock:
-	mutex_unlock(&BTRFS_I(inode)->csum_mutex);
 	goto out;
 }
 

commit 607d432da0542e84ddcd358adfddac6f68500e3d
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Dec 2 07:17:45 2008 -0500

    Btrfs: add support for multiple csum algorithms
    
    This patch gives us the space we will need in order to have different csum
    algorithims at some point in the future.  We save the csum algorithim type
    in the superblock, and use those instead of define's.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f76378831407..234ed441736c 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -24,9 +24,9 @@
 #include "transaction.h"
 #include "print-tree.h"
 
-#define MAX_CSUM_ITEMS(r) ((((BTRFS_LEAF_DATA_SIZE(r) - \
-			       sizeof(struct btrfs_item) * 2) / \
-			       BTRFS_CRC32_SIZE) - 1))
+#define MAX_CSUM_ITEMS(r,size) ((((BTRFS_LEAF_DATA_SIZE(r) - \
+				   sizeof(struct btrfs_item) * 2) / \
+				  size) - 1))
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,
@@ -83,6 +83,8 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 	struct btrfs_csum_item *item;
 	struct extent_buffer *leaf;
 	u64 csum_offset = 0;
+	u16 csum_size =
+		btrfs_super_csum_size(&root->fs_info->super_copy);
 	int csums_in_item;
 
 	file_key.objectid = objectid;
@@ -105,7 +107,7 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 		csum_offset = (offset - found_key.offset) >>
 				root->fs_info->sb->s_blocksize_bits;
 		csums_in_item = btrfs_item_size_nr(leaf, path->slots[0]);
-		csums_in_item /= BTRFS_CRC32_SIZE;
+		csums_in_item /= csum_size;
 
 		if (csum_offset >= csums_in_item) {
 			ret = -EFBIG;
@@ -114,7 +116,7 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 	}
 	item = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
 	item = (struct btrfs_csum_item *)((unsigned char *)item +
-					  csum_offset * BTRFS_CRC32_SIZE);
+					  csum_offset * csum_size);
 	return item;
 fail:
 	if (ret > 0)
@@ -150,6 +152,8 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	u64 item_start_offset = 0;
 	u64 item_last_offset = 0;
 	u32 diff;
+	u16 csum_size =
+		btrfs_super_csum_size(&root->fs_info->super_copy);
 	int ret;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item = NULL;
@@ -195,7 +199,7 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			item_size = btrfs_item_size_nr(path->nodes[0],
 						       path->slots[0]);
 			item_last_offset = item_start_offset +
-				(item_size / BTRFS_CRC32_SIZE) *
+				(item_size / csum_size) *
 				root->sectorsize;
 			item = btrfs_item_ptr(path->nodes[0], path->slots[0],
 					      struct btrfs_csum_item);
@@ -206,11 +210,11 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 		 */
 		diff = offset - item_start_offset;
 		diff = diff / root->sectorsize;
-		diff = diff * BTRFS_CRC32_SIZE;
+		diff = diff * csum_size;
 
 		read_extent_buffer(path->nodes[0], &sum,
 				   ((unsigned long)item) + diff,
-				   BTRFS_CRC32_SIZE);
+				   csum_size);
 found:
 		set_state_private(io_tree, offset, sum);
 		bio_index++;
@@ -383,6 +387,8 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	char *eb_token;
 	unsigned long map_len;
 	unsigned long map_start;
+	u16 csum_size =
+		btrfs_super_csum_size(&root->fs_info->super_copy);
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
@@ -408,7 +414,8 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		/* we found one, but it isn't big enough yet */
 		leaf = path->nodes[0];
 		item_size = btrfs_item_size_nr(leaf, path->slots[0]);
-		if ((item_size / BTRFS_CRC32_SIZE) >= MAX_CSUM_ITEMS(root)) {
+		if ((item_size / csum_size) >=
+		    MAX_CSUM_ITEMS(root, csum_size)) {
 			/* already at max size, make a new one */
 			goto insert;
 		}
@@ -441,7 +448,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	 */
 	btrfs_release_path(root, path);
 	ret = btrfs_search_slot(trans, root, &file_key, path,
-				BTRFS_CRC32_SIZE, 1);
+				csum_size, 1);
 	if (ret < 0)
 		goto fail_unlock;
 	if (ret == 0) {
@@ -457,14 +464,14 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			root->fs_info->sb->s_blocksize_bits;
 	if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
 	    found_key.objectid != objectid ||
-	    csum_offset >= MAX_CSUM_ITEMS(root)) {
+	    csum_offset >= MAX_CSUM_ITEMS(root, csum_size)) {
 		goto insert;
 	}
 	if (csum_offset >= btrfs_item_size_nr(leaf, path->slots[0]) /
-	    BTRFS_CRC32_SIZE) {
-		u32 diff = (csum_offset + 1) * BTRFS_CRC32_SIZE;
+	    csum_size) {
+		u32 diff = (csum_offset + 1) * csum_size;
 		diff = diff - btrfs_item_size_nr(leaf, path->slots[0]);
-		if (diff != BTRFS_CRC32_SIZE)
+		if (diff != csum_size)
 			goto insert;
 		ret = btrfs_extend_item(trans, root, path, diff);
 		BUG_ON(ret);
@@ -479,10 +486,10 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		tmp -= offset & ~((u64)root->sectorsize -1);
 		tmp >>= root->fs_info->sb->s_blocksize_bits;
 		tmp = max((u64)1, tmp);
-		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(root));
-		ins_size = BTRFS_CRC32_SIZE * tmp;
+		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(root, csum_size));
+		ins_size = csum_size * tmp;
 	} else {
-		ins_size = BTRFS_CRC32_SIZE;
+		ins_size = csum_size;
 	}
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      ins_size);
@@ -497,7 +504,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	item = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
 	ret = 0;
 	item = (struct btrfs_csum_item *)((unsigned char *)item +
-					  csum_offset * BTRFS_CRC32_SIZE);
+					  csum_offset * csum_size);
 found:
 	item_end = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
 	item_end = (struct btrfs_csum_item *)((unsigned char *)item_end +
@@ -508,14 +515,14 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 next_sector:
 
 	if (!eb_token ||
-	   (unsigned long)item  + BTRFS_CRC32_SIZE >= map_start + map_len) {
+	   (unsigned long)item + csum_size >= map_start + map_len) {
 		int err;
 
 		if (eb_token)
 			unmap_extent_buffer(leaf, eb_token, KM_USER1);
 		eb_token = NULL;
 		err = map_private_extent_buffer(leaf, (unsigned long)item,
-						BTRFS_CRC32_SIZE,
+						csum_size,
 						&eb_token, &eb_map,
 						&map_start, &map_len, KM_USER1);
 		if (err)
@@ -523,17 +530,17 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	}
 	if (eb_token) {
 		memcpy(eb_token + ((unsigned long)item & (PAGE_CACHE_SIZE - 1)),
-		       &sector_sum->sum, BTRFS_CRC32_SIZE);
+		       &sector_sum->sum, csum_size);
 	} else {
 		write_extent_buffer(leaf, &sector_sum->sum,
-				    (unsigned long)item, BTRFS_CRC32_SIZE);
+				    (unsigned long)item, csum_size);
 	}
 
 	total_bytes += root->sectorsize;
 	sector_sum++;
 	if (total_bytes < sums->len) {
 		item = (struct btrfs_csum_item *)((char *)item +
-						  BTRFS_CRC32_SIZE);
+						  csum_size);
 		if (item < item_end && offset + PAGE_CACHE_SIZE ==
 		    sector_sum->offset) {
 			    offset = sector_sum->offset;
@@ -577,7 +584,8 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 	new_item_span = isize - key.offset;
 	blocks = (new_item_span + root->sectorsize - 1) >>
 		root->fs_info->sb->s_blocksize_bits;
-	new_item_size = blocks * BTRFS_CRC32_SIZE;
+	new_item_size = blocks *
+		btrfs_super_csum_size(&root->fs_info->super_copy);
 	if (new_item_size >= btrfs_item_size_nr(leaf, slot))
 		return 0;
 	ret = btrfs_truncate_item(trans, root, path, new_item_size, 1);

commit 39be25cd89450940b0e5f8a6aad71d1ec99b17bf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 10 11:50:50 2008 -0500

    Btrfs: Use invalidatepage when writepage finds a page outside of i_size
    
    With all the recent fixes to the delalloc locking, it is now safe
    again to use invalidatepage inside the writepage code for
    pages outside of i_size.  This used to deadlock against some of the
    code to write locked ranges of pages, but all of that has been fixed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f4d3fa71bc41..f76378831407 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -185,6 +185,7 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 				       "%llu\n", inode->i_ino,
 				       (unsigned long long)offset);
 				item = NULL;
+				btrfs_release_path(root, path);
 				goto found;
 			}
 			btrfs_item_key_to_cpu(path->nodes[0], &found_key,

commit c8b978188c9a0fd3d535c13debd19d522b726f1f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Oct 29 14:49:59 2008 -0400

    Btrfs: Add zlib compression support
    
    This is a large change for adding compression on reading and writing,
    both for inline and regular extents.  It does some fairly large
    surgery to the writeback paths.
    
    Compression is off by default and enabled by mount -o compress.  Even
    when the -o compress mount option is not used, it is possible to read
    compressed extents off the disk.
    
    If compression for a given set of pages fails to make them smaller, the
    file is flagged to avoid future compression attempts later.
    
    * While finding delalloc extents, the pages are locked before being sent down
    to the delalloc handler.  This allows the delalloc handler to do complex things
    such as cleaning the pages, marking them writeback and starting IO on their
    behalf.
    
    * Inline extents are inserted at delalloc time now.  This allows us to compress
    the data before inserting the inline extent, and it allows us to insert
    an inline extent that spans multiple pages.
    
    * All of the in-memory extent representations (extent_map.c, ordered-data.c etc)
    are changed to record both an in-memory size and an on disk size, as well
    as a flag for compression.
    
    From a disk format point of view, the extent pointers in the file are changed
    to record the on disk size of a given extent and some encoding flags.
    Space in the disk format is allocated for compression encoding, as well
    as encryption and a generic 'other' field.  Neither the encryption or the
    'other' field are currently used.
    
    In order to limit the amount of data read for a single random read in the
    file, the size of a compressed extent is limited to 128k.  This is a
    software only limit, the disk format supports u64 sized compressed extents.
    
    In order to limit the ram consumed while processing extents, the uncompressed
    size of a compressed extent is limited to 256k.  This is a software only limit
    and will be subject to tuning later.
    
    Checksumming is still done on compressed extents, and it is done on the
    uncompressed version of the data.  This way additional encodings can be
    layered on without having to figure out which encoding to checksum.
    
    Compression happens at delalloc time, which is basically singled threaded because
    it is usually done by a single pdflush thread.  This makes it tricky to
    spread the compression load across all the cpus on the box.  We'll have to
    look at parallel pdflush walks of dirty inodes at a later time.
    
    Decompression is hooked into readpages and it does spread across CPUs nicely.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 6dbe88b9d7d4..f4d3fa71bc41 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -31,7 +31,8 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     u64 objectid, u64 pos,
 			     u64 disk_offset, u64 disk_num_bytes,
-			     u64 num_bytes, u64 offset)
+			     u64 num_bytes, u64 offset, u64 ram_bytes,
+			     u8 compression, u8 encryption, u16 other_encoding)
 {
 	int ret = 0;
 	struct btrfs_file_extent_item *item;
@@ -57,8 +58,13 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	btrfs_set_file_extent_disk_num_bytes(leaf, item, disk_num_bytes);
 	btrfs_set_file_extent_offset(leaf, item, offset);
 	btrfs_set_file_extent_num_bytes(leaf, item, num_bytes);
+	btrfs_set_file_extent_ram_bytes(leaf, item, ram_bytes);
 	btrfs_set_file_extent_generation(leaf, item, trans->transid);
 	btrfs_set_file_extent_type(leaf, item, BTRFS_FILE_EXTENT_REG);
+	btrfs_set_file_extent_compression(leaf, item, compression);
+	btrfs_set_file_extent_encryption(leaf, item, encryption);
+	btrfs_set_file_extent_other_encoding(leaf, item, other_encoding);
+
 	btrfs_mark_buffer_dirty(leaf);
 out:
 	btrfs_free_path(path);
@@ -213,6 +219,73 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	return 0;
 }
 
+int btrfs_csum_file_bytes(struct btrfs_root *root, struct inode *inode,
+			  u64 start, unsigned long len)
+{
+	struct btrfs_ordered_sum *sums;
+	struct btrfs_sector_sum *sector_sum;
+	struct btrfs_ordered_extent *ordered;
+	char *data;
+	struct page *page;
+	unsigned long total_bytes = 0;
+	unsigned long this_sum_bytes = 0;
+
+	sums = kzalloc(btrfs_ordered_sum_size(root, len), GFP_NOFS);
+	if (!sums)
+		return -ENOMEM;
+
+	sector_sum = sums->sums;
+	sums->file_offset = start;
+	sums->len = len;
+	INIT_LIST_HEAD(&sums->list);
+	ordered = btrfs_lookup_ordered_extent(inode, sums->file_offset);
+	BUG_ON(!ordered);
+
+	while(len > 0) {
+		if (start >= ordered->file_offset + ordered->len ||
+		    start < ordered->file_offset) {
+			sums->len = this_sum_bytes;
+			this_sum_bytes = 0;
+			btrfs_add_ordered_sum(inode, ordered, sums);
+			btrfs_put_ordered_extent(ordered);
+
+			sums = kzalloc(btrfs_ordered_sum_size(root, len),
+				       GFP_NOFS);
+			BUG_ON(!sums);
+			sector_sum = sums->sums;
+			sums->len = len;
+			sums->file_offset = start;
+			ordered = btrfs_lookup_ordered_extent(inode,
+						      sums->file_offset);
+			BUG_ON(!ordered);
+		}
+
+		page = find_get_page(inode->i_mapping,
+				     start >> PAGE_CACHE_SHIFT);
+
+		data = kmap_atomic(page, KM_USER0);
+		sector_sum->sum = ~(u32)0;
+		sector_sum->sum = btrfs_csum_data(root, data, sector_sum->sum,
+						  PAGE_CACHE_SIZE);
+		kunmap_atomic(data, KM_USER0);
+		btrfs_csum_final(sector_sum->sum,
+				 (char *)&sector_sum->sum);
+		sector_sum->offset = page_offset(page);
+		page_cache_release(page);
+
+		sector_sum++;
+		total_bytes += PAGE_CACHE_SIZE;
+		this_sum_bytes += PAGE_CACHE_SIZE;
+		start += PAGE_CACHE_SIZE;
+
+		WARN_ON(len < PAGE_CACHE_SIZE);
+		len -= PAGE_CACHE_SIZE;
+	}
+	btrfs_add_ordered_sum(inode, ordered, sums);
+	btrfs_put_ordered_extent(ordered);
+	return 0;
+}
+
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio)
 {

commit 639cb58675ce9b507eed9c3d6b3335488079b21a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Aug 28 06:15:25 2008 -0400

    Btrfs: Fix variable init during csum creation
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f861bd506928..6dbe88b9d7d4 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -325,6 +325,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	item = btrfs_lookup_csum(trans, root, path, objectid, offset, 1);
 	if (!IS_ERR(item)) {
 		leaf = path->nodes[0];
+		ret = 0;
 		goto found;
 	}
 	ret = PTR_ERR(item);

commit 4d1b5fb4d7075f862848dbff8873e22382abd482
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Aug 20 09:44:52 2008 -0400

    Btrfs: Lookup readpage checksums on bio submission again
    
    This optimization had been removed because I thought it was triggering
    csum errors.  The real cause of the errors was elsewhere, and so
    this optimization is back.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 9454e0a07c89..f861bd506928 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -134,7 +134,6 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-#if 0 /* broken */
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio)
 {
@@ -151,6 +150,8 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
 
 	path = btrfs_alloc_path();
+	if (bio->bi_size > PAGE_CACHE_SIZE * 8)
+		path->reada = 2;
 
 	WARN_ON(bio->bi_vcnt <= 0);
 
@@ -211,7 +212,6 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	btrfs_free_path(path);
 	return 0;
 }
-#endif
 
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio)

commit 53863232ef961778aa414b700ed88a48e8e871e6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 15 15:34:18 2008 -0400

    Btrfs: Lower contention on the csum mutex
    
    This takes the csum mutex deeper in the call chain and releases it
    more often.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 51aba8cee7ce..9454e0a07c89 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -321,6 +321,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	file_key.offset = offset;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
 
+	mutex_lock(&BTRFS_I(inode)->csum_mutex);
 	item = btrfs_lookup_csum(trans, root, path, objectid, offset, 1);
 	if (!IS_ERR(item)) {
 		leaf = path->nodes[0];
@@ -367,7 +368,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	ret = btrfs_search_slot(trans, root, &file_key, path,
 				BTRFS_CRC32_SIZE, 1);
 	if (ret < 0)
-		goto fail;
+		goto fail_unlock;
 	if (ret == 0) {
 		BUG();
 	}
@@ -411,10 +412,10 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      ins_size);
 	if (ret < 0)
-		goto fail;
+		goto fail_unlock;
 	if (ret != 0) {
 		WARN_ON(1);
-		goto fail;
+		goto fail_unlock;
 	}
 csum:
 	leaf = path->nodes[0];
@@ -427,6 +428,8 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	item_end = (struct btrfs_csum_item *)((unsigned char *)item_end +
 				      btrfs_item_size_nr(leaf, path->slots[0]));
 	eb_token = NULL;
+	mutex_unlock(&BTRFS_I(inode)->csum_mutex);
+	cond_resched();
 next_sector:
 
 	if (!eb_token ||
@@ -467,13 +470,18 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		eb_token = NULL;
 	}
 	btrfs_mark_buffer_dirty(path->nodes[0]);
+	cond_resched();
 	if (total_bytes < sums->len) {
 		btrfs_release_path(root, path);
 		goto again;
 	}
-fail:
+out:
 	btrfs_free_path(path);
 	return ret;
+
+fail_unlock:
+	mutex_unlock(&BTRFS_I(inode)->csum_mutex);
+	goto out;
 }
 
 int btrfs_csum_truncate(struct btrfs_trans_handle *trans,

commit 3de9d6b649b4cc60687be92e71cef36d7d4e8f2f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Aug 4 23:17:27 2008 -0400

    btrfs_lookup_bio_sums seems broken, go back to the readpage_io_hook for now
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 70af24aa582b..51aba8cee7ce 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -134,6 +134,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
+#if 0 /* broken */
 int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 			  struct bio *bio)
 {
@@ -200,7 +201,7 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 		diff = diff * BTRFS_CRC32_SIZE;
 
 		read_extent_buffer(path->nodes[0], &sum,
-				   (unsigned long)item + diff,
+				   ((unsigned long)item) + diff,
 				   BTRFS_CRC32_SIZE);
 found:
 		set_state_private(io_tree, offset, sum);
@@ -210,6 +211,7 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	btrfs_free_path(path);
 	return 0;
 }
+#endif
 
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio)

commit 6dab81574346c831ded96ae3ab0e8f9ca72c37ae
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Aug 4 08:35:53 2008 -0400

    Btrfs: Hold csum mutex while reading in sums during readpages
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a5ff19b34b21..70af24aa582b 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -150,7 +150,6 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
 
 	path = btrfs_alloc_path();
-	path->reada = 2;
 
 	WARN_ON(bio->bi_vcnt <= 0);
 
@@ -177,6 +176,7 @@ int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
 				printk("no csum found for inode %lu start "
 				       "%llu\n", inode->i_ino,
 				       (unsigned long long)offset);
+				item = NULL;
 				goto found;
 			}
 			btrfs_item_key_to_cpu(path->nodes[0], &found_key,

commit 61b4944018449003ac5f9757f4d125dce519cf51
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 31 15:42:53 2008 -0400

    Btrfs: Fix streaming read performance with checksumming on
    
    Large streaming reads make for large bios, which means each entry on the
    list async work queues represents a large amount of data.  IO
    congestion throttling on the device was kicking in before the async
    worker threads decided a single thread was busy and needed some help.
    
    The end result was that a streaming read would result in a single CPU
    running at 100% instead of balancing the work off to other CPUs.
    
    This patch also changes the pre-IO checksum lookup done by reads to
    work on a per-bio basis instead of a per-page.  This results in many
    extra btree lookups on large streaming reads.  Doing the checksum lookup
    right before bio submit allows us to reuse searches while processing
    adjacent offsets.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 2311061f070e..a5ff19b34b21 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -134,6 +134,83 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
+int btrfs_lookup_bio_sums(struct btrfs_root *root, struct inode *inode,
+			  struct bio *bio)
+{
+	u32 sum;
+	struct bio_vec *bvec = bio->bi_io_vec;
+	int bio_index = 0;
+	u64 offset;
+	u64 item_start_offset = 0;
+	u64 item_last_offset = 0;
+	u32 diff;
+	int ret;
+	struct btrfs_path *path;
+	struct btrfs_csum_item *item = NULL;
+	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
+
+	path = btrfs_alloc_path();
+	path->reada = 2;
+
+	WARN_ON(bio->bi_vcnt <= 0);
+
+	while(bio_index < bio->bi_vcnt) {
+		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+		ret = btrfs_find_ordered_sum(inode, offset, &sum);
+		if (ret == 0)
+			goto found;
+
+		if (!item || offset < item_start_offset ||
+		    offset >= item_last_offset) {
+			struct btrfs_key found_key;
+			u32 item_size;
+
+			if (item)
+				btrfs_release_path(root, path);
+			item = btrfs_lookup_csum(NULL, root, path,
+						 inode->i_ino, offset, 0);
+			if (IS_ERR(item)) {
+				ret = PTR_ERR(item);
+				if (ret == -ENOENT || ret == -EFBIG)
+					ret = 0;
+				sum = 0;
+				printk("no csum found for inode %lu start "
+				       "%llu\n", inode->i_ino,
+				       (unsigned long long)offset);
+				goto found;
+			}
+			btrfs_item_key_to_cpu(path->nodes[0], &found_key,
+					      path->slots[0]);
+
+			item_start_offset = found_key.offset;
+			item_size = btrfs_item_size_nr(path->nodes[0],
+						       path->slots[0]);
+			item_last_offset = item_start_offset +
+				(item_size / BTRFS_CRC32_SIZE) *
+				root->sectorsize;
+			item = btrfs_item_ptr(path->nodes[0], path->slots[0],
+					      struct btrfs_csum_item);
+		}
+		/*
+		 * this byte range must be able to fit inside
+		 * a single leaf so it will also fit inside a u32
+		 */
+		diff = offset - item_start_offset;
+		diff = diff / root->sectorsize;
+		diff = diff * BTRFS_CRC32_SIZE;
+
+		read_extent_buffer(path->nodes[0], &sum,
+				   (unsigned long)item + diff,
+				   BTRFS_CRC32_SIZE);
+found:
+		set_state_private(io_tree, offset, sum);
+		bio_index++;
+		bvec++;
+	}
+	btrfs_free_path(path);
+	return 0;
+}
+
 int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 		       struct bio *bio)
 {

commit bcc63abbf3e9bf948a1b0129b3e6120ec7d7f698
Author: Yan <zheng.yan@oracle.com>
Date:   Wed Jul 30 16:29:20 2008 -0400

    Btrfs: implement memory reclaim for leaf reference cache
    
    The memory reclaiming issue happens when snapshot exists. In that
    case, some cache entries may not be used during old snapshot dropping,
    so they will remain in the cache until umount.
    
    The patch adds a field to struct btrfs_leaf_ref to record create time. Besides,
    the patch makes all dead roots of a given snapshot linked together in order of
    create time. After a old snapshot was completely dropped, we check the dead
    root list and remove all cache entries created before the oldest dead root in
    the list.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index afe42d00b5a6..2311061f070e 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -422,4 +422,3 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 	BUG_ON(ret);
 	return ret;
 }
-

commit ed98b56a6393c5e150fd5095b9eb7fd7d3cfb041
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 23:06:42 2008 -0400

    Btrfs: Take the csum mutex while reading checksums
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 45127e4797c8..afe42d00b5a6 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -152,7 +152,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	if (!sums)
 		return -ENOMEM;
 
-	sector_sum = &sums->sums;
+	sector_sum = sums->sums;
 	sums->file_offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 	sums->len = bio->bi_size;
 	INIT_LIST_HEAD(&sums->list);
@@ -174,7 +174,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 			sums = kzalloc(btrfs_ordered_sum_size(root, bytes_left),
 				       GFP_NOFS);
 			BUG_ON(!sums);
-			sector_sum = &sums->sums;
+			sector_sum = sums->sums;
 			sums->len = bytes_left;
 			sums->file_offset = offset;
 			ordered = btrfs_lookup_ordered_extent(inode,
@@ -193,12 +193,14 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 				 (char *)&sector_sum->sum);
 		sector_sum->offset = page_offset(bvec->bv_page) +
 			bvec->bv_offset;
+
 		sector_sum++;
 		bio_index++;
 		total_bytes += bvec->bv_len;
 		this_sum_bytes += bvec->bv_len;
 		bvec++;
 	}
+	this_sum_bytes = 0;
 	btrfs_add_ordered_sum(inode, ordered, sums);
 	btrfs_put_ordered_extent(ordered);
 	return 0;
@@ -231,7 +233,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
-	sector_sum = &sums->sums;
+	sector_sum = sums->sums;
 again:
 	next_offset = (u64)-1;
 	found_next = 0;

commit e5a2217ef6ff088d08a27208929a6f9c635d672c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jul 18 20:42:20 2008 -0400

    Fix btrfs_wait_ordered_extent_range to properly wait
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index d9c69e16d368..45127e4797c8 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -161,7 +161,8 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 
 	while(bio_index < bio->bi_vcnt) {
 		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
-		if (offset >= ordered->file_offset + ordered->len) {
+		if (offset >= ordered->file_offset + ordered->len ||
+		    offset < ordered->file_offset) {
 			unsigned long bytes_left;
 			sums->len = this_sum_bytes;
 			this_sum_bytes = 0;

commit 7f3c74fb831fa19bafe087e817c0a5ff3883f1ea
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jul 18 12:01:11 2008 -0400

    Btrfs: Keep extent mappings in ram until pending ordered extents are done
    
    It was possible for stale mappings from disk to be used instead of the
    new pending ordered extent.  This adds a flag to the extent map struct
    to keep it pinned until the pending ordered extent is actually on disk.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index e02f1e5acb0a..d9c69e16d368 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -192,7 +192,6 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 				 (char *)&sector_sum->sum);
 		sector_sum->offset = page_offset(bvec->bv_page) +
 			bvec->bv_offset;
-
 		sector_sum++;
 		bio_index++;
 		total_bytes += bvec->bv_len;
@@ -201,9 +200,6 @@ int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
 	}
 	btrfs_add_ordered_sum(inode, ordered, sums);
 	btrfs_put_ordered_extent(ordered);
-	if (total_bytes != bio->bi_size) {
-printk("warning, total bytes %lu bio size %u\n", total_bytes, bio->bi_size);
-	}
 	return 0;
 }
 
@@ -372,6 +368,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		write_extent_buffer(leaf, &sector_sum->sum,
 				    (unsigned long)item, BTRFS_CRC32_SIZE);
 	}
+
 	total_bytes += root->sectorsize;
 	sector_sum++;
 	if (total_bytes < sums->len) {

commit 3edf7d33f4edb1e4a9bb0a4c0a84d95fb4d22a09
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jul 18 06:17:13 2008 -0400

    Btrfs: Handle data checksumming on bios that span multiple ordered extents
    
    Data checksumming is done right before the bio is sent down the IO stack,
    which means a single bio might span more than one ordered extent.  In
    this case, the checksumming data is split between two ordered extents.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 345caf8ff516..e02f1e5acb0a 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -134,26 +134,53 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-int btrfs_csum_one_bio(struct btrfs_root *root,
-		       struct bio *bio, struct btrfs_ordered_sum **sums_ret)
+int btrfs_csum_one_bio(struct btrfs_root *root, struct inode *inode,
+		       struct bio *bio)
 {
 	struct btrfs_ordered_sum *sums;
 	struct btrfs_sector_sum *sector_sum;
+	struct btrfs_ordered_extent *ordered;
 	char *data;
 	struct bio_vec *bvec = bio->bi_io_vec;
 	int bio_index = 0;
+	unsigned long total_bytes = 0;
+	unsigned long this_sum_bytes = 0;
+	u64 offset;
 
 	WARN_ON(bio->bi_vcnt <= 0);
 	sums = kzalloc(btrfs_ordered_sum_size(root, bio->bi_size), GFP_NOFS);
 	if (!sums)
 		return -ENOMEM;
-	*sums_ret = sums;
+
 	sector_sum = &sums->sums;
-	sums->file_offset = page_offset(bvec->bv_page);
+	sums->file_offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 	sums->len = bio->bi_size;
 	INIT_LIST_HEAD(&sums->list);
+	ordered = btrfs_lookup_ordered_extent(inode, sums->file_offset);
+	BUG_ON(!ordered);
 
 	while(bio_index < bio->bi_vcnt) {
+		offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+		if (offset >= ordered->file_offset + ordered->len) {
+			unsigned long bytes_left;
+			sums->len = this_sum_bytes;
+			this_sum_bytes = 0;
+			btrfs_add_ordered_sum(inode, ordered, sums);
+			btrfs_put_ordered_extent(ordered);
+
+			bytes_left = bio->bi_size - total_bytes;
+
+			sums = kzalloc(btrfs_ordered_sum_size(root, bytes_left),
+				       GFP_NOFS);
+			BUG_ON(!sums);
+			sector_sum = &sums->sums;
+			sums->len = bytes_left;
+			sums->file_offset = offset;
+			ordered = btrfs_lookup_ordered_extent(inode,
+						      sums->file_offset);
+			BUG_ON(!ordered);
+		}
+
 		data = kmap_atomic(bvec->bv_page, KM_USER0);
 		sector_sum->sum = ~(u32)0;
 		sector_sum->sum = btrfs_csum_data(root,
@@ -165,10 +192,18 @@ int btrfs_csum_one_bio(struct btrfs_root *root,
 				 (char *)&sector_sum->sum);
 		sector_sum->offset = page_offset(bvec->bv_page) +
 			bvec->bv_offset;
+
 		sector_sum++;
 		bio_index++;
+		total_bytes += bvec->bv_len;
+		this_sum_bytes += bvec->bv_len;
 		bvec++;
 	}
+	btrfs_add_ordered_sum(inode, ordered, sums);
+	btrfs_put_ordered_extent(ordered);
+	if (total_bytes != bio->bi_size) {
+printk("warning, total bytes %lu bio size %u\n", total_bytes, bio->bi_size);
+	}
 	return 0;
 }
 

commit e6dcd2dc9c489108648e2ed543315dd134d50a9a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:53:50 2008 -0400

    Btrfs: New data=ordered implementation
    
    The old data=ordered code would force commit to wait until
    all the data extents from the transaction were fully on disk.  This
    introduced large latencies into the commit and stalled new writers
    in the transaction for a long time.
    
    The new code changes the way data allocations and extents work:
    
    * When delayed allocation is filled, data extents are reserved, and
      the extent bit EXTENT_ORDERED is set on the entire range of the extent.
      A struct btrfs_ordered_extent is allocated an inserted into a per-inode
      rbtree to track the pending extents.
    
    * As each page is written EXTENT_ORDERED is cleared on the bytes corresponding
      to that page.
    
    * When all of the bytes corresponding to a single struct btrfs_ordered_extent
      are written, The previously reserved extent is inserted into the FS
      btree and into the extent allocation trees.  The checksums for the file
      data are also updated.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f537eb43c2c6..345caf8ff516 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -135,26 +135,37 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 }
 
 int btrfs_csum_one_bio(struct btrfs_root *root,
-		       struct bio *bio, char **sums_ret)
+		       struct bio *bio, struct btrfs_ordered_sum **sums_ret)
 {
-	u32 *sums;
+	struct btrfs_ordered_sum *sums;
+	struct btrfs_sector_sum *sector_sum;
 	char *data;
 	struct bio_vec *bvec = bio->bi_io_vec;
 	int bio_index = 0;
 
-	sums = kmalloc(bio->bi_vcnt * BTRFS_CRC32_SIZE, GFP_NOFS);
+	WARN_ON(bio->bi_vcnt <= 0);
+	sums = kzalloc(btrfs_ordered_sum_size(root, bio->bi_size), GFP_NOFS);
 	if (!sums)
 		return -ENOMEM;
-	*sums_ret = (char *)sums;
+	*sums_ret = sums;
+	sector_sum = &sums->sums;
+	sums->file_offset = page_offset(bvec->bv_page);
+	sums->len = bio->bi_size;
+	INIT_LIST_HEAD(&sums->list);
 
 	while(bio_index < bio->bi_vcnt) {
 		data = kmap_atomic(bvec->bv_page, KM_USER0);
-		*sums = ~(u32)0;
-		*sums = btrfs_csum_data(root, data + bvec->bv_offset,
-					*sums, bvec->bv_len);
+		sector_sum->sum = ~(u32)0;
+		sector_sum->sum = btrfs_csum_data(root,
+						  data + bvec->bv_offset,
+						  sector_sum->sum,
+						  bvec->bv_len);
 		kunmap_atomic(data, KM_USER0);
-		btrfs_csum_final(*sums, (char *)sums);
-		sums++;
+		btrfs_csum_final(sector_sum->sum,
+				 (char *)&sector_sum->sum);
+		sector_sum->offset = page_offset(bvec->bv_page) +
+			bvec->bv_offset;
+		sector_sum++;
 		bio_index++;
 		bvec++;
 	}
@@ -163,7 +174,7 @@ int btrfs_csum_one_bio(struct btrfs_root *root,
 
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, struct inode *inode,
-			   struct bio *bio, char *sums)
+			   struct btrfs_ordered_sum *sums)
 {
 	u64 objectid = inode->i_ino;
 	u64 offset;
@@ -171,17 +182,16 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
 	u64 next_offset;
+	u64 total_bytes = 0;
 	int found_next;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
 	struct btrfs_csum_item *item_end;
 	struct extent_buffer *leaf = NULL;
 	u64 csum_offset;
-	u32 *sums32 = (u32 *)sums;
+	struct btrfs_sector_sum *sector_sum;
 	u32 nritems;
 	u32 ins_size;
-	int bio_index = 0;
-	struct bio_vec *bvec = bio->bi_io_vec;
 	char *eb_map;
 	char *eb_token;
 	unsigned long map_len;
@@ -189,10 +199,11 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
+	sector_sum = &sums->sums;
 again:
 	next_offset = (u64)-1;
 	found_next = 0;
-	offset = page_offset(bvec->bv_page) + bvec->bv_offset;
+	offset = sector_sum->offset;
 	file_key.objectid = objectid;
 	file_key.offset = offset;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
@@ -303,7 +314,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	item_end = (struct btrfs_csum_item *)((unsigned char *)item_end +
 				      btrfs_item_size_nr(leaf, path->slots[0]));
 	eb_token = NULL;
-next_bvec:
+next_sector:
 
 	if (!eb_token ||
 	   (unsigned long)item  + BTRFS_CRC32_SIZE >= map_start + map_len) {
@@ -321,21 +332,20 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	}
 	if (eb_token) {
 		memcpy(eb_token + ((unsigned long)item & (PAGE_CACHE_SIZE - 1)),
-		       sums32, BTRFS_CRC32_SIZE);
+		       &sector_sum->sum, BTRFS_CRC32_SIZE);
 	} else {
-		write_extent_buffer(leaf, sums32, (unsigned long)item,
-				    BTRFS_CRC32_SIZE);
+		write_extent_buffer(leaf, &sector_sum->sum,
+				    (unsigned long)item, BTRFS_CRC32_SIZE);
 	}
-	bio_index++;
-	bvec++;
-	sums32++;
-	if (bio_index < bio->bi_vcnt) {
+	total_bytes += root->sectorsize;
+	sector_sum++;
+	if (total_bytes < sums->len) {
 		item = (struct btrfs_csum_item *)((char *)item +
 						  BTRFS_CRC32_SIZE);
 		if (item < item_end && offset + PAGE_CACHE_SIZE ==
-		    page_offset(bvec->bv_page)) {
-			offset = page_offset(bvec->bv_page);
-			goto next_bvec;
+		    sector_sum->offset) {
+			    offset = sector_sum->offset;
+			goto next_sector;
 		}
 	}
 	if (eb_token) {
@@ -343,7 +353,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		eb_token = NULL;
 	}
 	btrfs_mark_buffer_dirty(path->nodes[0]);
-	if (bio_index < bio->bi_vcnt) {
+	if (total_bytes < sums->len) {
 		btrfs_release_path(root, path);
 		goto again;
 	}

commit f2eb0a241f0e5c135d93243b0236cb1f14c305e0
Author: Sage Weil <sage@newdream.net>
Date:   Fri May 2 14:43:14 2008 -0400

    Btrfs: Clone file data ioctl
    
    Add a new ioctl to clone file data
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 9259aece6ed1..f537eb43c2c6 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -28,10 +28,10 @@
 			       sizeof(struct btrfs_item) * 2) / \
 			       BTRFS_CRC32_SIZE) - 1))
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
-			       struct btrfs_root *root,
-			       u64 objectid, u64 pos,
-			       u64 offset, u64 disk_num_bytes,
-			       u64 num_bytes)
+			     struct btrfs_root *root,
+			     u64 objectid, u64 pos,
+			     u64 disk_offset, u64 disk_num_bytes,
+			     u64 num_bytes, u64 offset)
 {
 	int ret = 0;
 	struct btrfs_file_extent_item *item;
@@ -53,9 +53,9 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	leaf = path->nodes[0];
 	item = btrfs_item_ptr(leaf, path->slots[0],
 			      struct btrfs_file_extent_item);
-	btrfs_set_file_extent_disk_bytenr(leaf, item, offset);
+	btrfs_set_file_extent_disk_bytenr(leaf, item, disk_offset);
 	btrfs_set_file_extent_disk_num_bytes(leaf, item, disk_num_bytes);
-	btrfs_set_file_extent_offset(leaf, item, 0);
+	btrfs_set_file_extent_offset(leaf, item, offset);
 	btrfs_set_file_extent_num_bytes(leaf, item, num_bytes);
 	btrfs_set_file_extent_generation(leaf, item, trans->transid);
 	btrfs_set_file_extent_type(leaf, item, BTRFS_FILE_EXTENT_REG);

commit e015640f9c4fa2417dcc3bbbb3b2b61ad4059ab0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 16 11:15:20 2008 -0400

    Btrfs: Write bio checksumming outside the FS mutex
    
    This significantly improves streaming write performance by allowing
    concurrency in the data checksumming.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 374d0245b29d..9259aece6ed1 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -134,9 +134,36 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
+int btrfs_csum_one_bio(struct btrfs_root *root,
+		       struct bio *bio, char **sums_ret)
+{
+	u32 *sums;
+	char *data;
+	struct bio_vec *bvec = bio->bi_io_vec;
+	int bio_index = 0;
+
+	sums = kmalloc(bio->bi_vcnt * BTRFS_CRC32_SIZE, GFP_NOFS);
+	if (!sums)
+		return -ENOMEM;
+	*sums_ret = (char *)sums;
+
+	while(bio_index < bio->bi_vcnt) {
+		data = kmap_atomic(bvec->bv_page, KM_USER0);
+		*sums = ~(u32)0;
+		*sums = btrfs_csum_data(root, data + bvec->bv_offset,
+					*sums, bvec->bv_len);
+		kunmap_atomic(data, KM_USER0);
+		btrfs_csum_final(*sums, (char *)sums);
+		sums++;
+		bio_index++;
+		bvec++;
+	}
+	return 0;
+}
+
 int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 			   struct btrfs_root *root, struct inode *inode,
-			   struct bio *bio)
+			   struct bio *bio, char *sums)
 {
 	u64 objectid = inode->i_ino;
 	u64 offset;
@@ -150,12 +177,11 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	struct btrfs_csum_item *item_end;
 	struct extent_buffer *leaf = NULL;
 	u64 csum_offset;
-	u32 csum_result;
+	u32 *sums32 = (u32 *)sums;
 	u32 nritems;
 	u32 ins_size;
 	int bio_index = 0;
 	struct bio_vec *bvec = bio->bi_io_vec;
-	char *data;
 	char *eb_map;
 	char *eb_token;
 	unsigned long map_len;
@@ -278,15 +304,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 				      btrfs_item_size_nr(leaf, path->slots[0]));
 	eb_token = NULL;
 next_bvec:
-	data = kmap_atomic(bvec->bv_page, KM_USER0);
-	csum_result = ~(u32)0;
-	csum_result = btrfs_csum_data(root, data + bvec->bv_offset,
-				      csum_result, bvec->bv_len);
-	kunmap_atomic(data, KM_USER0);
-	btrfs_csum_final(csum_result, (char *)&csum_result);
-	if (csum_result == 0) {
-		printk("csum result is 0 for inode %lu offset %Lu\n", inode->i_ino, offset);
-	}
 
 	if (!eb_token ||
 	   (unsigned long)item  + BTRFS_CRC32_SIZE >= map_start + map_len) {
@@ -304,13 +321,14 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	}
 	if (eb_token) {
 		memcpy(eb_token + ((unsigned long)item & (PAGE_CACHE_SIZE - 1)),
-		       &csum_result, BTRFS_CRC32_SIZE);
+		       sums32, BTRFS_CRC32_SIZE);
 	} else {
-		write_extent_buffer(leaf, &csum_result, (unsigned long)item,
+		write_extent_buffer(leaf, sums32, (unsigned long)item,
 				    BTRFS_CRC32_SIZE);
 	}
 	bio_index++;
 	bvec++;
+	sums32++;
 	if (bio_index < bio->bi_vcnt) {
 		item = (struct btrfs_csum_item *)((char *)item +
 						  BTRFS_CRC32_SIZE);

commit eb20978f318ab5e360ef9c1b24b5dea14d0fee6a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Feb 21 09:30:08 2008 -0500

    Btrfs: Use KM_USERN instead of KM_IRQ during data summing
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index e17cce33fe95..374d0245b29d 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -278,11 +278,11 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 				      btrfs_item_size_nr(leaf, path->slots[0]));
 	eb_token = NULL;
 next_bvec:
-	data = kmap_atomic(bvec->bv_page, KM_IRQ0);
+	data = kmap_atomic(bvec->bv_page, KM_USER0);
 	csum_result = ~(u32)0;
 	csum_result = btrfs_csum_data(root, data + bvec->bv_offset,
 				      csum_result, bvec->bv_len);
-	kunmap_atomic(data, KM_IRQ0);
+	kunmap_atomic(data, KM_USER0);
 	btrfs_csum_final(csum_result, (char *)&csum_result);
 	if (csum_result == 0) {
 		printk("csum result is 0 for inode %lu offset %Lu\n", inode->i_ino, offset);
@@ -293,12 +293,12 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		int err;
 
 		if (eb_token)
-			unmap_extent_buffer(leaf, eb_token, KM_IRQ1);
+			unmap_extent_buffer(leaf, eb_token, KM_USER1);
 		eb_token = NULL;
 		err = map_private_extent_buffer(leaf, (unsigned long)item,
 						BTRFS_CRC32_SIZE,
 						&eb_token, &eb_map,
-						&map_start, &map_len, KM_IRQ1);
+						&map_start, &map_len, KM_USER1);
 		if (err)
 			eb_token = NULL;
 	}
@@ -321,7 +321,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		}
 	}
 	if (eb_token) {
-		unmap_extent_buffer(leaf, eb_token, KM_IRQ1);
+		unmap_extent_buffer(leaf, eb_token, KM_USER1);
 		eb_token = NULL;
 	}
 	btrfs_mark_buffer_dirty(path->nodes[0]);

commit 2e1a992e3103624af48f1501aaad4e4d8317f88c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 20 15:44:32 2008 -0500

    Btrfs: Make sure bio pages are adjacent during bulk csumming
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index ee25e50e7c04..e17cce33fe95 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -161,7 +161,6 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	unsigned long map_len;
 	unsigned long map_start;
 
-
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
 again:
@@ -315,8 +314,11 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	if (bio_index < bio->bi_vcnt) {
 		item = (struct btrfs_csum_item *)((char *)item +
 						  BTRFS_CRC32_SIZE);
-		if (item < item_end)
+		if (item < item_end && offset + PAGE_CACHE_SIZE ==
+		    page_offset(bvec->bv_page)) {
+			offset = page_offset(bvec->bv_page);
 			goto next_bvec;
+		}
 	}
 	if (eb_token) {
 		unmap_extent_buffer(leaf, eb_token, KM_IRQ1);

commit 6e92f5e651a34f24ab31ebdf3f113c7d23a36000
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 20 12:07:25 2008 -0500

    Btrfs: While doing checksums on bios, cache the extent_buffer mapping
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 3f0e71b0e5d9..ee25e50e7c04 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -156,6 +156,11 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	int bio_index = 0;
 	struct bio_vec *bvec = bio->bi_io_vec;
 	char *data;
+	char *eb_map;
+	char *eb_token;
+	unsigned long map_len;
+	unsigned long map_start;
+
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
@@ -272,6 +277,7 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 	item_end = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
 	item_end = (struct btrfs_csum_item *)((unsigned char *)item_end +
 				      btrfs_item_size_nr(leaf, path->slots[0]));
+	eb_token = NULL;
 next_bvec:
 	data = kmap_atomic(bvec->bv_page, KM_IRQ0);
 	csum_result = ~(u32)0;
@@ -283,15 +289,39 @@ int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
 		printk("csum result is 0 for inode %lu offset %Lu\n", inode->i_ino, offset);
 	}
 
-	write_extent_buffer(leaf, &csum_result, (unsigned long)item,
-			    BTRFS_CRC32_SIZE);
+	if (!eb_token ||
+	   (unsigned long)item  + BTRFS_CRC32_SIZE >= map_start + map_len) {
+		int err;
+
+		if (eb_token)
+			unmap_extent_buffer(leaf, eb_token, KM_IRQ1);
+		eb_token = NULL;
+		err = map_private_extent_buffer(leaf, (unsigned long)item,
+						BTRFS_CRC32_SIZE,
+						&eb_token, &eb_map,
+						&map_start, &map_len, KM_IRQ1);
+		if (err)
+			eb_token = NULL;
+	}
+	if (eb_token) {
+		memcpy(eb_token + ((unsigned long)item & (PAGE_CACHE_SIZE - 1)),
+		       &csum_result, BTRFS_CRC32_SIZE);
+	} else {
+		write_extent_buffer(leaf, &csum_result, (unsigned long)item,
+				    BTRFS_CRC32_SIZE);
+	}
 	bio_index++;
 	bvec++;
 	if (bio_index < bio->bi_vcnt) {
-		item = (struct btrfs_csum_item *)((char *)item + BTRFS_CRC32_SIZE);
+		item = (struct btrfs_csum_item *)((char *)item +
+						  BTRFS_CRC32_SIZE);
 		if (item < item_end)
 			goto next_bvec;
 	}
+	if (eb_token) {
+		unmap_extent_buffer(leaf, eb_token, KM_IRQ1);
+		eb_token = NULL;
+	}
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 	if (bio_index < bio->bi_vcnt) {
 		btrfs_release_path(root, path);

commit 065631f6dccea07bfad48d8981369f6d9cfd6e2b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 20 12:07:25 2008 -0500

    Btrfs: checksum file data at bio submission time instead of during writepage
    
    When we checkum file data during writepage, the checksumming is done one
    page at a time, making it difficult to do bulk metadata modifications
    to insert checksums for large ranges of the file at once.
    
    This patch changes btrfs to checksum on a per-bio basis instead.  The
    bios are checksummed before they are handed off to the block layer, so
    each bio is contiguous and only has pages from the same inode.
    
    Checksumming on a bio basis allows us to insert and modify the file
    checksum items in large groups.  It also allows the checksumming to
    be done more easily by async worker threads.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 3ebbc058d082..3f0e71b0e5d9 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -16,6 +16,9 @@
  * Boston, MA 021110-1307, USA.
  */
 
+#include <linux/bio.h>
+#include <linux/pagemap.h>
+#include <linux/highmem.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -131,28 +134,35 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root,
-			  struct inode *inode,
-			  u64 objectid, u64 offset,
-			  char *data, size_t len)
+int btrfs_csum_file_blocks(struct btrfs_trans_handle *trans,
+			   struct btrfs_root *root, struct inode *inode,
+			   struct bio *bio)
 {
+	u64 objectid = inode->i_ino;
+	u64 offset;
 	int ret;
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
-	u64 next_offset = (u64)-1;
-	int found_next = 0;
+	u64 next_offset;
+	int found_next;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
+	struct btrfs_csum_item *item_end;
 	struct extent_buffer *leaf = NULL;
 	u64 csum_offset;
-	u32 csum_result = ~(u32)0;
+	u32 csum_result;
 	u32 nritems;
 	u32 ins_size;
+	int bio_index = 0;
+	struct bio_vec *bvec = bio->bi_io_vec;
+	char *data;
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
-
+again:
+	next_offset = (u64)-1;
+	found_next = 0;
+	offset = page_offset(bvec->bv_page) + bvec->bv_offset;
 	file_key.objectid = objectid;
 	file_key.offset = offset;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
@@ -259,7 +269,15 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	item = (struct btrfs_csum_item *)((unsigned char *)item +
 					  csum_offset * BTRFS_CRC32_SIZE);
 found:
-	csum_result = btrfs_csum_data(root, data, csum_result, len);
+	item_end = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
+	item_end = (struct btrfs_csum_item *)((unsigned char *)item_end +
+				      btrfs_item_size_nr(leaf, path->slots[0]));
+next_bvec:
+	data = kmap_atomic(bvec->bv_page, KM_IRQ0);
+	csum_result = ~(u32)0;
+	csum_result = btrfs_csum_data(root, data + bvec->bv_offset,
+				      csum_result, bvec->bv_len);
+	kunmap_atomic(data, KM_IRQ0);
 	btrfs_csum_final(csum_result, (char *)&csum_result);
 	if (csum_result == 0) {
 		printk("csum result is 0 for inode %lu offset %Lu\n", inode->i_ino, offset);
@@ -267,9 +285,19 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 
 	write_extent_buffer(leaf, &csum_result, (unsigned long)item,
 			    BTRFS_CRC32_SIZE);
+	bio_index++;
+	bvec++;
+	if (bio_index < bio->bi_vcnt) {
+		item = (struct btrfs_csum_item *)((char *)item + BTRFS_CRC32_SIZE);
+		if (item < item_end)
+			goto next_bvec;
+	}
 	btrfs_mark_buffer_dirty(path->nodes[0]);
+	if (bio_index < bio->bi_vcnt) {
+		btrfs_release_path(root, path);
+		goto again;
+	}
 fail:
-	btrfs_release_path(root, path);
 	btrfs_free_path(path);
 	return ret;
 }

commit aadfeb6e39ad6bde080cb3ab23f4da57ccb25f4a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 29 09:10:27 2008 -0500

    Btrfs: Add some extra debugging around file data checksum failures
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 614176e52851..3ebbc058d082 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -261,6 +261,10 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 found:
 	csum_result = btrfs_csum_data(root, data, csum_result, len);
 	btrfs_csum_final(csum_result, (char *)&csum_result);
+	if (csum_result == 0) {
+		printk("csum result is 0 for inode %lu offset %Lu\n", inode->i_ino, offset);
+	}
+
 	write_extent_buffer(leaf, &csum_result, (unsigned long)item,
 			    BTRFS_CRC32_SIZE);
 	btrfs_mark_buffer_dirty(path->nodes[0]);

commit 179e29e488cc74f1e9bd67bc45f70b832740e9ec
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 1 11:28:41 2007 -0400

    Btrfs: Fix a number of inline extent problems that Yan Zheng reported.
    
    The fixes do a number of things:
    
    1) Most btrfs_drop_extent callers will try to leave the inline extents in
    place.  It can truncate bytes off the beginning of the inline extent if
    required.
    
    2) writepage can now update the inline extent, allowing mmap writes to
    go directly into the inline extent.
    
    3) btrfs_truncate_in_transaction truncates inline extents
    
    4) extent_map.c fixed to not merge inline extent mappings and hole
    mappings together
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 7eb9a5412e2f..614176e52851 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -291,7 +291,7 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 	new_item_size = blocks * BTRFS_CRC32_SIZE;
 	if (new_item_size >= btrfs_item_size_nr(leaf, slot))
 		return 0;
-	ret = btrfs_truncate_item(trans, root, path, new_item_size);
+	ret = btrfs_truncate_item(trans, root, path, new_item_size, 1);
 	BUG_ON(ret);
 	return ret;
 }

commit b56baf5bedccd3258643b09289f17ceab3ddea52
Author: Yan <yanzheng@21cn.com>
Date:   Mon Oct 29 12:01:05 2007 -0400

    Minor fix for btrfs_csum_file_block.
    
    Execution should goto label 'insert' when 'btrfs_next_leaf' return a
    non-zero value, otherwise the parameter 'slot' for
    'btrfs_item_key_to_cpu' may be out of bounds. The original codes jump
    to  label 'insert' only when 'btrfs_next_leaf' return a negative
    value.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 482a2b615327..7eb9a5412e2f 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -178,13 +178,11 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 		nritems = btrfs_header_nritems(path->nodes[0]);
 		if (path->slots[0] >= nritems - 1) {
 			ret = btrfs_next_leaf(root, path);
-			if (ret == 1) {
+			if (ret == 1)
 				found_next = 1;
-			} else if (ret == 0) {
-				slot = 0;
-			} else {
+			if (ret != 0)
 				goto insert;
-			}
+			slot = 0;
 		}
 		btrfs_item_key_to_cpu(path->nodes[0], &found_key, slot);
 		if (found_key.objectid != objectid ||
@@ -238,7 +236,7 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	csum_offset = 0;
 	if (found_next) {
 		u64 tmp = min((u64)i_size_read(inode), next_offset);
-		tmp -= offset + root->sectorsize - 1;
+		tmp -= offset & ~((u64)root->sectorsize -1);
 		tmp >>= root->fs_info->sb->s_blocksize_bits;
 		tmp = max((u64)1, tmp);
 		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(root));

commit f578d4bd7e141dd03ca7e8695c1cc118c326e69e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Oct 25 15:42:56 2007 -0400

    Btrfs: Optimize csum insertion to create larger items when possible
    
    This reduces the number of calls to btrfs_extend_item and greatly lowers
    the cpu usage while writing large files.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 10a4c7408600..482a2b615327 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -133,17 +133,22 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 
 int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
+			  struct inode *inode,
 			  u64 objectid, u64 offset,
 			  char *data, size_t len)
 {
 	int ret;
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
+	u64 next_offset = (u64)-1;
+	int found_next = 0;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
 	struct extent_buffer *leaf = NULL;
 	u64 csum_offset;
 	u32 csum_result = ~(u32)0;
+	u32 nritems;
+	u32 ins_size;
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
@@ -168,7 +173,27 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			goto insert;
 		}
 	} else {
+		int slot = path->slots[0] + 1;
 		/* we didn't find a csum item, insert one */
+		nritems = btrfs_header_nritems(path->nodes[0]);
+		if (path->slots[0] >= nritems - 1) {
+			ret = btrfs_next_leaf(root, path);
+			if (ret == 1) {
+				found_next = 1;
+			} else if (ret == 0) {
+				slot = 0;
+			} else {
+				goto insert;
+			}
+		}
+		btrfs_item_key_to_cpu(path->nodes[0], &found_key, slot);
+		if (found_key.objectid != objectid ||
+		    found_key.type != BTRFS_CSUM_ITEM_KEY) {
+			found_next = 1;
+			goto insert;
+		}
+		next_offset = found_key.offset;
+		found_next = 1;
 		goto insert;
 	}
 
@@ -211,8 +236,18 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 insert:
 	btrfs_release_path(root, path);
 	csum_offset = 0;
+	if (found_next) {
+		u64 tmp = min((u64)i_size_read(inode), next_offset);
+		tmp -= offset + root->sectorsize - 1;
+		tmp >>= root->fs_info->sb->s_blocksize_bits;
+		tmp = max((u64)1, tmp);
+		tmp = min(tmp, (u64)MAX_CSUM_ITEMS(root));
+		ins_size = BTRFS_CRC32_SIZE * tmp;
+	} else {
+		ins_size = BTRFS_CRC32_SIZE;
+	}
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
-				      BTRFS_CRC32_SIZE);
+				      ins_size);
 	if (ret < 0)
 		goto fail;
 	if (ret != 0) {

commit ff79f8190b6e955ff7a71faf804a3017d526e657
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:22:25 2007 -0400

    Btrfs: Add back file data checksumming
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 9a65e97a4e28..10a4c7408600 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -136,27 +136,27 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  u64 objectid, u64 offset,
 			  char *data, size_t len)
 {
-	return 0;
-#if 0
 	int ret;
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
-	struct extent_buffer *leaf;
+	struct extent_buffer *leaf = NULL;
 	u64 csum_offset;
+	u32 csum_result = ~(u32)0;
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
 
 	file_key.objectid = objectid;
 	file_key.offset = offset;
-	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
 
 	item = btrfs_lookup_csum(trans, root, path, objectid, offset, 1);
-	if (!IS_ERR(item))
+	if (!IS_ERR(item)) {
+		leaf = path->nodes[0];
 		goto found;
+	}
 	ret = PTR_ERR(item);
 	if (ret == -EFBIG) {
 		u32 item_size;
@@ -226,14 +226,15 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	item = (struct btrfs_csum_item *)((unsigned char *)item +
 					  csum_offset * BTRFS_CRC32_SIZE);
 found:
-	/* FIXME!!!!!!!!!!!! */
-	ret = btrfs_csum_data(root, data, len, &item->csum);
+	csum_result = btrfs_csum_data(root, data, csum_result, len);
+	btrfs_csum_final(csum_result, (char *)&csum_result);
+	write_extent_buffer(leaf, &csum_result, (unsigned long)item,
+			    BTRFS_CRC32_SIZE);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
 	btrfs_release_path(root, path);
 	btrfs_free_path(path);
 	return ret;
-#endif
 }
 
 int btrfs_csum_truncate(struct btrfs_trans_handle *trans,

commit db94535db75e67fab12ccbb7f5ee548e33fed891
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:15:53 2007 -0400

    Btrfs: Allow tree blocks larger than the page size
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 226f6d028c3f..9a65e97a4e28 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -27,8 +27,8 @@
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       u64 objectid, u64 pos,
-			       u64 offset, u64 disk_num_blocks,
-			       u64 num_blocks)
+			       u64 offset, u64 disk_num_bytes,
+			       u64 num_bytes)
 {
 	int ret = 0;
 	struct btrfs_file_extent_item *item;
@@ -50,10 +50,10 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	leaf = path->nodes[0];
 	item = btrfs_item_ptr(leaf, path->slots[0],
 			      struct btrfs_file_extent_item);
-	btrfs_set_file_extent_disk_blocknr(leaf, item, offset);
-	btrfs_set_file_extent_disk_num_blocks(leaf, item, disk_num_blocks);
+	btrfs_set_file_extent_disk_bytenr(leaf, item, offset);
+	btrfs_set_file_extent_disk_num_bytes(leaf, item, disk_num_bytes);
 	btrfs_set_file_extent_offset(leaf, item, 0);
-	btrfs_set_file_extent_num_blocks(leaf, item, num_blocks);
+	btrfs_set_file_extent_num_bytes(leaf, item, num_bytes);
 	btrfs_set_file_extent_generation(leaf, item, trans->transid);
 	btrfs_set_file_extent_type(leaf, item, BTRFS_FILE_EXTENT_REG);
 	btrfs_mark_buffer_dirty(leaf);

commit 5f39d397dfbe140a14edecd4e73c34ce23c4f9ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:19 2007 -0400

    Btrfs: Create extent_buffer interface for large blocksizes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index ea4dd4c5fce3..226f6d028c3f 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -34,12 +34,12 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	struct btrfs_file_extent_item *item;
 	struct btrfs_key file_key;
 	struct btrfs_path *path;
+	struct extent_buffer *leaf;
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
 	file_key.objectid = objectid;
 	file_key.offset = pos;
-	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
 
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
@@ -47,15 +47,16 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	if (ret < 0)
 		goto out;
 	BUG_ON(ret);
-	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
+	leaf = path->nodes[0];
+	item = btrfs_item_ptr(leaf, path->slots[0],
 			      struct btrfs_file_extent_item);
-	btrfs_set_file_extent_disk_blocknr(item, offset);
-	btrfs_set_file_extent_disk_num_blocks(item, disk_num_blocks);
-	btrfs_set_file_extent_offset(item, 0);
-	btrfs_set_file_extent_num_blocks(item, num_blocks);
-	btrfs_set_file_extent_generation(item, trans->transid);
-	btrfs_set_file_extent_type(item, BTRFS_FILE_EXTENT_REG);
-	btrfs_mark_buffer_dirty(path->nodes[0]);
+	btrfs_set_file_extent_disk_blocknr(leaf, item, offset);
+	btrfs_set_file_extent_disk_num_blocks(leaf, item, disk_num_blocks);
+	btrfs_set_file_extent_offset(leaf, item, 0);
+	btrfs_set_file_extent_num_blocks(leaf, item, num_blocks);
+	btrfs_set_file_extent_generation(leaf, item, trans->transid);
+	btrfs_set_file_extent_type(leaf, item, BTRFS_FILE_EXTENT_REG);
+	btrfs_mark_buffer_dirty(leaf);
 out:
 	btrfs_free_path(path);
 	return ret;
@@ -71,32 +72,30 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
 	struct btrfs_csum_item *item;
-	struct btrfs_leaf *leaf;
+	struct extent_buffer *leaf;
 	u64 csum_offset = 0;
 	int csums_in_item;
 
 	file_key.objectid = objectid;
 	file_key.offset = offset;
-	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
 	ret = btrfs_search_slot(trans, root, &file_key, path, 0, cow);
 	if (ret < 0)
 		goto fail;
-	leaf = btrfs_buffer_leaf(path->nodes[0]);
+	leaf = path->nodes[0];
 	if (ret > 0) {
 		ret = 1;
 		if (path->slots[0] == 0)
 			goto fail;
 		path->slots[0]--;
-		btrfs_disk_key_to_cpu(&found_key,
-				      &leaf->items[path->slots[0]].key);
+		btrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);
 		if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
 		    found_key.objectid != objectid) {
 			goto fail;
 		}
 		csum_offset = (offset - found_key.offset) >>
 				root->fs_info->sb->s_blocksize_bits;
-		csums_in_item = btrfs_item_size(leaf->items + path->slots[0]);
+		csums_in_item = btrfs_item_size_nr(leaf, path->slots[0]);
 		csums_in_item /= BTRFS_CRC32_SIZE;
 
 		if (csum_offset >= csums_in_item) {
@@ -127,7 +126,6 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 
 	file_key.objectid = objectid;
 	file_key.offset = offset;
-	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
 	ret = btrfs_search_slot(trans, root, &file_key, path, ins_len, cow);
 	return ret;
@@ -138,12 +136,14 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  u64 objectid, u64 offset,
 			  char *data, size_t len)
 {
+	return 0;
+#if 0
 	int ret;
 	struct btrfs_key file_key;
 	struct btrfs_key found_key;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
-	struct btrfs_leaf *leaf;
+	struct extent_buffer *leaf;
 	u64 csum_offset;
 
 	path = btrfs_alloc_path();
@@ -161,8 +161,8 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	if (ret == -EFBIG) {
 		u32 item_size;
 		/* we found one, but it isn't big enough yet */
-		leaf = btrfs_buffer_leaf(path->nodes[0]);
-		item_size = btrfs_item_size(leaf->items + path->slots[0]);
+		leaf = path->nodes[0];
+		item_size = btrfs_item_size_nr(leaf, path->slots[0]);
 		if ((item_size / BTRFS_CRC32_SIZE) >= MAX_CSUM_ITEMS(root)) {
 			/* already at max size, make a new one */
 			goto insert;
@@ -188,8 +188,8 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 		goto insert;
 	}
 	path->slots[0]--;
-	leaf = btrfs_buffer_leaf(path->nodes[0]);
-	btrfs_disk_key_to_cpu(&found_key, &leaf->items[path->slots[0]].key);
+	leaf = path->nodes[0];
+	btrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);
 	csum_offset = (offset - found_key.offset) >>
 			root->fs_info->sb->s_blocksize_bits;
 	if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
@@ -197,10 +197,10 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	    csum_offset >= MAX_CSUM_ITEMS(root)) {
 		goto insert;
 	}
-	if (csum_offset >= btrfs_item_size(leaf->items + path->slots[0]) /
+	if (csum_offset >= btrfs_item_size_nr(leaf, path->slots[0]) /
 	    BTRFS_CRC32_SIZE) {
 		u32 diff = (csum_offset + 1) * BTRFS_CRC32_SIZE;
-		diff = diff - btrfs_item_size(leaf->items + path->slots[0]);
+		diff = diff - btrfs_item_size_nr(leaf, path->slots[0]);
 		if (diff != BTRFS_CRC32_SIZE)
 			goto insert;
 		ret = btrfs_extend_item(trans, root, path, diff);
@@ -220,21 +220,20 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 		goto fail;
 	}
 csum:
-	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
-			      struct btrfs_csum_item);
+	leaf = path->nodes[0];
+	item = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
 	ret = 0;
 	item = (struct btrfs_csum_item *)((unsigned char *)item +
 					  csum_offset * BTRFS_CRC32_SIZE);
 found:
-	btrfs_check_bounds(&item->csum, BTRFS_CRC32_SIZE,
-			   path->nodes[0]->b_data,
-			   root->fs_info->sb->s_blocksize);
+	/* FIXME!!!!!!!!!!!! */
 	ret = btrfs_csum_data(root, data, len, &item->csum);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
 	btrfs_release_path(root, path);
 	btrfs_free_path(path);
 	return ret;
+#endif
 }
 
 int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
@@ -242,21 +241,21 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 			u64 isize)
 {
 	struct btrfs_key key;
-	struct btrfs_leaf *leaf = btrfs_buffer_leaf(path->nodes[0]);
+	struct extent_buffer *leaf = path->nodes[0];
 	int slot = path->slots[0];
 	int ret;
 	u32 new_item_size;
 	u64 new_item_span;
 	u64 blocks;
 
-	btrfs_disk_key_to_cpu(&key, &leaf->items[slot].key);
+	btrfs_item_key_to_cpu(leaf, &key, slot);
 	if (isize <= key.offset)
 		return 0;
 	new_item_span = isize - key.offset;
-	blocks = (new_item_span + root->blocksize - 1) >>
+	blocks = (new_item_span + root->sectorsize - 1) >>
 		root->fs_info->sb->s_blocksize_bits;
 	new_item_size = blocks * BTRFS_CRC32_SIZE;
-	if (new_item_size >= btrfs_item_size(leaf->items + slot))
+	if (new_item_size >= btrfs_item_size_nr(leaf, slot))
 		return 0;
 	ret = btrfs_truncate_item(trans, root, path, new_item_size);
 	BUG_ON(ret);

commit ec6b910fb330f29e169c9f502c3ac209515af8d1
Author: Zach Brown <zach.brown@oracle.com>
Date:   Wed Jul 11 10:00:37 2007 -0400

    Btrfs: trivial include fixups
    
    Almost none of the files including module.h need to do so,
    remove them.
    
    Include sched.h in extent-tree.c to silence a warning about cond_resched()
    being undeclared.
    
    Signed-off-by: Zach Brown <zach.brown@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 68859934ae25..ea4dd4c5fce3 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -16,7 +16,6 @@
  * Boston, MA 021110-1307, USA.
  */
 
-#include <linux/module.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"

commit 54aa1f4dfdacd60a19c4471220b24e581be6f774
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 22 14:16:25 2007 -0400

    Btrfs: Audit callers and return codes to make sure -ENOSPC gets up the stack
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index cf894f09f6c7..68859934ae25 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -45,6 +45,8 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      sizeof(*item));
+	if (ret < 0)
+		goto out;
 	BUG_ON(ret);
 	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_file_extent_item);
@@ -55,10 +57,9 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	btrfs_set_file_extent_generation(item, trans->transid);
 	btrfs_set_file_extent_type(item, BTRFS_FILE_EXTENT_REG);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
-
-	btrfs_release_path(root, path);
+out:
 	btrfs_free_path(path);
-	return 0;
+	return ret;
 }
 
 struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
@@ -213,6 +214,8 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	csum_offset = 0;
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      BTRFS_CRC32_SIZE);
+	if (ret < 0)
+		goto fail;
 	if (ret != 0) {
 		WARN_ON(1);
 		goto fail;
@@ -261,40 +264,3 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-int btrfs_csum_verify_file_block(struct btrfs_root *root,
-				 u64 objectid, u64 offset,
-				 char *data, size_t len)
-{
-	int ret;
-	struct btrfs_key file_key;
-	struct btrfs_path *path;
-	struct btrfs_csum_item *item;
-	char result[BTRFS_CRC32_SIZE];
-
-	path = btrfs_alloc_path();
-	BUG_ON(!path);
-	file_key.objectid = objectid;
-	file_key.offset = offset;
-	file_key.flags = 0;
-	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
-	mutex_lock(&root->fs_info->fs_mutex);
-
-	item = btrfs_lookup_csum(NULL, root, path, objectid, offset, 0);
-	if (IS_ERR(item)) {
-		ret = PTR_ERR(item);
-		/* a csum that isn't present is a preallocated region. */
-		if (ret == -ENOENT || ret == -EFBIG)
-			ret = -ENOENT;
-		goto fail;
-	}
-
-	ret = btrfs_csum_data(root, data, len, result);
-	WARN_ON(ret);
-	if (memcmp(result, &item->csum, BTRFS_CRC32_SIZE))
-		ret = 1;
-fail:
-	btrfs_release_path(root, path);
-	btrfs_free_path(path);
-	mutex_unlock(&root->fs_info->fs_mutex);
-	return ret;
-}

commit 8c2383c3dd2cb5bb39598ce4fa97154bc591020a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jun 18 09:57:58 2007 -0400

    Subject: Rework btrfs_file_write to only allocate while page locks are held
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 1068993ab1c9..cf894f09f6c7 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -228,7 +228,6 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			   path->nodes[0]->b_data,
 			   root->fs_info->sb->s_blocksize);
 	ret = btrfs_csum_data(root, data, len, &item->csum);
-// printk("file %lu offset %llu csum %X\n", objectid, (unsigned long long)offset, *(int *)(&item->csum));
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
 	btrfs_release_path(root, path);

commit 9ebefb180bad4914a31c4e1748ba187a30e1e990
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 15 13:50:00 2007 -0400

    Btrfs: patch queue: page_mkwrite
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 3c140cc1dd05..1068993ab1c9 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -228,6 +228,7 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			   path->nodes[0]->b_data,
 			   root->fs_info->sb->s_blocksize);
 	ret = btrfs_csum_data(root, data, len, &item->csum);
+// printk("file %lu offset %llu csum %X\n", objectid, (unsigned long long)offset, *(int *)(&item->csum));
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
 	btrfs_release_path(root, path);
@@ -298,4 +299,3 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 	mutex_unlock(&root->fs_info->fs_mutex);
 	return ret;
 }
-

commit f1ace244c8c1e16eaa5c8b3b5339849651e31ede
Author: Aneesh <aneesh.kumar@linux.vnet.ibm.com>
Date:   Wed Jun 13 16:18:26 2007 -0400

    btrfs: Code cleanup
    Attaching below is some of the code cleanups that i came across while
    reading the code.
    
    a) alloc_path already calls init_path.
    b) Mention that btrfs_inode is the in memory copy.Ext4 have ext4_inode_info as
    the in memory copy ext4_inode as the disk copy
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 37dd3801a107..3c140cc1dd05 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -38,7 +38,6 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
-	btrfs_init_path(path);
 	file_key.objectid = objectid;
 	file_key.offset = pos;
 	file_key.flags = 0;
@@ -274,7 +273,6 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
-	btrfs_init_path(path);
 	file_key.objectid = objectid;
 	file_key.offset = offset;
 	file_key.flags = 0;

commit 6cbd55707802b98843f953d1ae6d8f5bcd9a76c0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 09:07:21 2007 -0400

    Btrfs: add GPLv2
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index d5a98827e38a..37dd3801a107 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -1,3 +1,21 @@
+/*
+ * Copyright (C) 2007 Oracle.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
 #include <linux/module.h>
 #include "ctree.h"
 #include "disk-io.h"

commit 5af3981c1878b0657b9babd2ef7ec98c2008cf2c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 07:50:13 2007 -0400

    Btrfs: printk fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index fb8c214160c1..d5a98827e38a 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -28,10 +28,6 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      sizeof(*item));
-	if (ret) {
-printk("failed to insert %Lu %Lu ret %d\n", objectid, pos, ret);
-btrfs_print_leaf(root, btrfs_buffer_leaf(path->nodes[0]));
-	}
 	BUG_ON(ret);
 	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_file_extent_item);
@@ -201,7 +197,6 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      BTRFS_CRC32_SIZE);
 	if (ret != 0) {
-		printk("at insert for %Lu %u %Lu ret is %d\n", file_key.objectid, file_key.flags, file_key.offset, ret);
 		WARN_ON(1);
 		goto fail;
 	}

commit 84f54cfa78c81991e087309a9b379f25f1ffdb10
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 07:43:08 2007 -0400

    Btrfs: 64 bit div fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 0782e924ddeb..fb8c214160c1 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -239,7 +239,8 @@ int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
 	if (isize <= key.offset)
 		return 0;
 	new_item_span = isize - key.offset;
-	blocks = (new_item_span + root->blocksize - 1) / root->blocksize;
+	blocks = (new_item_span + root->blocksize - 1) >>
+		root->fs_info->sb->s_blocksize_bits;
 	new_item_size = blocks * BTRFS_CRC32_SIZE;
 	if (new_item_size >= btrfs_item_size(leaf->items + slot))
 		return 0;

commit 1de037a43edf67f3a9f66dd197195b3c08febb16
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 29 15:17:08 2007 -0400

    Btrfs: fixup various fsx failures
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 7990b5742114..0782e924ddeb 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -2,6 +2,7 @@
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
+#include "print-tree.h"
 
 #define MAX_CSUM_ITEMS(r) ((((BTRFS_LEAF_DATA_SIZE(r) - \
 			       sizeof(struct btrfs_item) * 2) / \
@@ -27,6 +28,10 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      sizeof(*item));
+	if (ret) {
+printk("failed to insert %Lu %Lu ret %d\n", objectid, pos, ret);
+btrfs_print_leaf(root, btrfs_buffer_leaf(path->nodes[0]));
+	}
 	BUG_ON(ret);
 	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_file_extent_item);
@@ -218,6 +223,31 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
+int btrfs_csum_truncate(struct btrfs_trans_handle *trans,
+			struct btrfs_root *root, struct btrfs_path *path,
+			u64 isize)
+{
+	struct btrfs_key key;
+	struct btrfs_leaf *leaf = btrfs_buffer_leaf(path->nodes[0]);
+	int slot = path->slots[0];
+	int ret;
+	u32 new_item_size;
+	u64 new_item_span;
+	u64 blocks;
+
+	btrfs_disk_key_to_cpu(&key, &leaf->items[slot].key);
+	if (isize <= key.offset)
+		return 0;
+	new_item_span = isize - key.offset;
+	blocks = (new_item_span + root->blocksize - 1) / root->blocksize;
+	new_item_size = blocks * BTRFS_CRC32_SIZE;
+	if (new_item_size >= btrfs_item_size(leaf->items + slot))
+		return 0;
+	ret = btrfs_truncate_item(trans, root, path, new_item_size);
+	BUG_ON(ret);
+	return ret;
+}
+
 int btrfs_csum_verify_file_block(struct btrfs_root *root,
 				 u64 objectid, u64 offset,
 				 char *data, size_t len)

commit 3a686375629da5d2e2ad019265b66ef113c87455
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 24 13:35:57 2007 -0400

    Btrfs: sparse files!
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index a66709e6d036..7990b5742114 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -9,7 +9,8 @@
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       u64 objectid, u64 pos,
-			       u64 offset, u64 num_blocks)
+			       u64 offset, u64 disk_num_blocks,
+			       u64 num_blocks)
 {
 	int ret = 0;
 	struct btrfs_file_extent_item *item;
@@ -30,7 +31,7 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_file_extent_item);
 	btrfs_set_file_extent_disk_blocknr(item, offset);
-	btrfs_set_file_extent_disk_num_blocks(item, num_blocks);
+	btrfs_set_file_extent_disk_num_blocks(item, disk_num_blocks);
 	btrfs_set_file_extent_offset(item, 0);
 	btrfs_set_file_extent_num_blocks(item, num_blocks);
 	btrfs_set_file_extent_generation(item, trans->transid);
@@ -176,14 +177,14 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
 	    found_key.objectid != objectid ||
 	    csum_offset >= MAX_CSUM_ITEMS(root)) {
-		WARN_ON(1);
 		goto insert;
 	}
 	if (csum_offset >= btrfs_item_size(leaf->items + path->slots[0]) /
 	    BTRFS_CRC32_SIZE) {
 		u32 diff = (csum_offset + 1) * BTRFS_CRC32_SIZE;
 		diff = diff - btrfs_item_size(leaf->items + path->slots[0]);
-		WARN_ON(diff != BTRFS_CRC32_SIZE);
+		if (diff != BTRFS_CRC32_SIZE)
+			goto insert;
 		ret = btrfs_extend_item(trans, root, path, diff);
 		BUG_ON(ret);
 		goto csum;
@@ -241,7 +242,7 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 		ret = PTR_ERR(item);
 		/* a csum that isn't present is a preallocated region. */
 		if (ret == -ENOENT || ret == -EFBIG)
-			ret = 1;
+			ret = -ENOENT;
 		goto fail;
 	}
 

commit 509659cde578d891445afd67d87121dd13e71596
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 10 12:36:17 2007 -0400

    Btrfs: switch to crc32c instead of sha256
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 10e4cf08e9ed..a66709e6d036 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -4,8 +4,8 @@
 #include "transaction.h"
 
 #define MAX_CSUM_ITEMS(r) ((((BTRFS_LEAF_DATA_SIZE(r) - \
-				 sizeof(struct btrfs_item) * 2) / \
-				sizeof(struct btrfs_csum_item)) - 1))
+			       sizeof(struct btrfs_item) * 2) / \
+			       BTRFS_CRC32_SIZE) - 1))
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       u64 objectid, u64 pos,
@@ -78,7 +78,7 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 		csum_offset = (offset - found_key.offset) >>
 				root->fs_info->sb->s_blocksize_bits;
 		csums_in_item = btrfs_item_size(leaf->items + path->slots[0]);
-		csums_in_item /= sizeof(struct btrfs_csum_item);
+		csums_in_item /= BTRFS_CRC32_SIZE;
 
 		if (csum_offset >= csums_in_item) {
 			ret = -EFBIG;
@@ -86,7 +86,8 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 		}
 	}
 	item = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
-	item += csum_offset;
+	item = (struct btrfs_csum_item *)((unsigned char *)item +
+					  csum_offset * BTRFS_CRC32_SIZE);
 	return item;
 fail:
 	if (ret > 0)
@@ -143,8 +144,7 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 		/* we found one, but it isn't big enough yet */
 		leaf = btrfs_buffer_leaf(path->nodes[0]);
 		item_size = btrfs_item_size(leaf->items + path->slots[0]);
-		if ((item_size / sizeof(struct btrfs_csum_item)) >=
-		    MAX_CSUM_ITEMS(root)) {
+		if ((item_size / BTRFS_CRC32_SIZE) >= MAX_CSUM_ITEMS(root)) {
 			/* already at max size, make a new one */
 			goto insert;
 		}
@@ -159,7 +159,7 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	 */
 	btrfs_release_path(root, path);
 	ret = btrfs_search_slot(trans, root, &file_key, path,
-				sizeof(struct btrfs_csum_item), 1);
+				BTRFS_CRC32_SIZE, 1);
 	if (ret < 0)
 		goto fail;
 	if (ret == 0) {
@@ -180,10 +180,10 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 		goto insert;
 	}
 	if (csum_offset >= btrfs_item_size(leaf->items + path->slots[0]) /
-	    sizeof(struct btrfs_csum_item)) {
-		u32 diff = (csum_offset + 1) * sizeof(struct btrfs_csum_item);
+	    BTRFS_CRC32_SIZE) {
+		u32 diff = (csum_offset + 1) * BTRFS_CRC32_SIZE;
 		diff = diff - btrfs_item_size(leaf->items + path->slots[0]);
-		WARN_ON(diff != sizeof(struct btrfs_csum_item));
+		WARN_ON(diff != BTRFS_CRC32_SIZE);
 		ret = btrfs_extend_item(trans, root, path, diff);
 		BUG_ON(ret);
 		goto csum;
@@ -193,7 +193,7 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	btrfs_release_path(root, path);
 	csum_offset = 0;
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
-				      sizeof(struct btrfs_csum_item));
+				      BTRFS_CRC32_SIZE);
 	if (ret != 0) {
 		printk("at insert for %Lu %u %Lu ret is %d\n", file_key.objectid, file_key.flags, file_key.offset, ret);
 		WARN_ON(1);
@@ -203,10 +203,13 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_csum_item);
 	ret = 0;
-	item += csum_offset;
+	item = (struct btrfs_csum_item *)((unsigned char *)item +
+					  csum_offset * BTRFS_CRC32_SIZE);
 found:
-	btrfs_check_bounds(item->csum, BTRFS_CSUM_SIZE, path->nodes[0]->b_data, root->fs_info->sb->s_blocksize);
-	ret = btrfs_csum_data(root, data, len, item->csum);
+	btrfs_check_bounds(&item->csum, BTRFS_CRC32_SIZE,
+			   path->nodes[0]->b_data,
+			   root->fs_info->sb->s_blocksize);
+	ret = btrfs_csum_data(root, data, len, &item->csum);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
 	btrfs_release_path(root, path);
@@ -222,7 +225,7 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 	struct btrfs_key file_key;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
-	char result[BTRFS_CSUM_SIZE];
+	char result[BTRFS_CRC32_SIZE];
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
@@ -244,7 +247,7 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 
 	ret = btrfs_csum_data(root, data, len, result);
 	WARN_ON(ret);
-	if (memcmp(result, item->csum, BTRFS_CSUM_SIZE))
+	if (memcmp(result, &item->csum, BTRFS_CRC32_SIZE))
 		ret = 1;
 fail:
 	btrfs_release_path(root, path);

commit 236454dfffb64a95ee01c50a215153f5de61c475
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 19 13:37:44 2007 -0400

    Btrfs: many file_write fixes, inline data
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 8cc3c1d15412..10e4cf08e9ed 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -34,6 +34,7 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	btrfs_set_file_extent_offset(item, 0);
 	btrfs_set_file_extent_num_blocks(item, num_blocks);
 	btrfs_set_file_extent_generation(item, trans->transid);
+	btrfs_set_file_extent_type(item, BTRFS_FILE_EXTENT_REG);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 
 	btrfs_release_path(root, path);

commit a429e51371eee3c989160c003ee40bc3947c6a76
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 18 16:15:28 2007 -0400

    Btrfs: working file_write, reorganized key flags
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index ff8f3339c684..8cc3c1d15412 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -4,7 +4,7 @@
 #include "transaction.h"
 
 #define MAX_CSUM_ITEMS(r) ((((BTRFS_LEAF_DATA_SIZE(r) - \
-				 sizeof(struct btrfs_item)) / \
+				 sizeof(struct btrfs_item) * 2) / \
 				sizeof(struct btrfs_csum_item)) - 1))
 int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
@@ -19,11 +19,6 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
 	btrfs_init_path(path);
-	/*
-	ret = btrfs_alloc_extent(trans, root, num_blocks, hint_block,
-				 (u64)-1, &ins);
-				 */
-	BUG_ON(ret);
 	file_key.objectid = objectid;
 	file_key.offset = pos;
 	file_key.flags = 0;
@@ -40,6 +35,7 @@ int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 	btrfs_set_file_extent_num_blocks(item, num_blocks);
 	btrfs_set_file_extent_generation(item, trans->transid);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
+
 	btrfs_release_path(root, path);
 	btrfs_free_path(path);
 	return 0;
@@ -57,6 +53,7 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 	struct btrfs_csum_item *item;
 	struct btrfs_leaf *leaf;
 	u64 csum_offset = 0;
+	int csums_in_item;
 
 	file_key.objectid = objectid;
 	file_key.offset = offset;
@@ -79,9 +76,11 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 		}
 		csum_offset = (offset - found_key.offset) >>
 				root->fs_info->sb->s_blocksize_bits;
-		if (csum_offset >=
-		    btrfs_item_size(leaf->items + path->slots[0]) /
-		    sizeof(struct btrfs_csum_item)) {
+		csums_in_item = btrfs_item_size(leaf->items + path->slots[0]);
+		csums_in_item /= sizeof(struct btrfs_csum_item);
+
+		if (csum_offset >= csums_in_item) {
+			ret = -EFBIG;
 			goto fail;
 		}
 	}
@@ -128,16 +127,36 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
-	btrfs_init_path(path);
 
-	item = btrfs_lookup_csum(trans, root, path, objectid, offset, 0);
-	if (!IS_ERR(item))
-		goto found;
-	btrfs_release_path(root, path);
 	file_key.objectid = objectid;
 	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
+
+	item = btrfs_lookup_csum(trans, root, path, objectid, offset, 1);
+	if (!IS_ERR(item))
+		goto found;
+	ret = PTR_ERR(item);
+	if (ret == -EFBIG) {
+		u32 item_size;
+		/* we found one, but it isn't big enough yet */
+		leaf = btrfs_buffer_leaf(path->nodes[0]);
+		item_size = btrfs_item_size(leaf->items + path->slots[0]);
+		if ((item_size / sizeof(struct btrfs_csum_item)) >=
+		    MAX_CSUM_ITEMS(root)) {
+			/* already at max size, make a new one */
+			goto insert;
+		}
+	} else {
+		/* we didn't find a csum item, insert one */
+		goto insert;
+	}
+
+	/*
+	 * at this point, we know the tree has an item, but it isn't big
+	 * enough yet to put our csum in.  Grow it
+	 */
+	btrfs_release_path(root, path);
 	ret = btrfs_search_slot(trans, root, &file_key, path,
 				sizeof(struct btrfs_csum_item), 1);
 	if (ret < 0)
@@ -146,7 +165,6 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 		BUG();
 	}
 	if (path->slots[0] == 0) {
-		btrfs_release_path(root, path);
 		goto insert;
 	}
 	path->slots[0]--;
@@ -157,29 +175,36 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
 	    found_key.objectid != objectid ||
 	    csum_offset >= MAX_CSUM_ITEMS(root)) {
-		btrfs_release_path(root, path);
+		WARN_ON(1);
 		goto insert;
 	}
 	if (csum_offset >= btrfs_item_size(leaf->items + path->slots[0]) /
 	    sizeof(struct btrfs_csum_item)) {
-		ret = btrfs_extend_item(trans, root, path,
-					sizeof(struct btrfs_csum_item));
+		u32 diff = (csum_offset + 1) * sizeof(struct btrfs_csum_item);
+		diff = diff - btrfs_item_size(leaf->items + path->slots[0]);
+		WARN_ON(diff != sizeof(struct btrfs_csum_item));
+		ret = btrfs_extend_item(trans, root, path, diff);
 		BUG_ON(ret);
 		goto csum;
 	}
 
 insert:
+	btrfs_release_path(root, path);
 	csum_offset = 0;
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      sizeof(struct btrfs_csum_item));
-	if (ret != 0 && ret != -EEXIST)
+	if (ret != 0) {
+		printk("at insert for %Lu %u %Lu ret is %d\n", file_key.objectid, file_key.flags, file_key.offset, ret);
+		WARN_ON(1);
 		goto fail;
+	}
 csum:
 	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_csum_item);
 	ret = 0;
 	item += csum_offset;
 found:
+	btrfs_check_bounds(item->csum, BTRFS_CSUM_SIZE, path->nodes[0]->b_data, root->fs_info->sb->s_blocksize);
 	ret = btrfs_csum_data(root, data, len, item->csum);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
@@ -210,6 +235,9 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 	item = btrfs_lookup_csum(NULL, root, path, objectid, offset, 0);
 	if (IS_ERR(item)) {
 		ret = PTR_ERR(item);
+		/* a csum that isn't present is a preallocated region. */
+		if (ret == -ENOENT || ret == -EFBIG)
+			ret = 1;
 		goto fail;
 	}
 

commit 70b2befd0c8a4064715d8b340270650cc9d15af8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 17 15:39:32 2007 -0400

    Btrfs: rework csums and extent item ordering
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f49968ad0a07..ff8f3339c684 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -62,23 +62,19 @@ struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
 	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
-printk("__lookup for %Lu\n", offset);
 	ret = btrfs_search_slot(trans, root, &file_key, path, 0, cow);
 	if (ret < 0)
 		goto fail;
 	leaf = btrfs_buffer_leaf(path->nodes[0]);
 	if (ret > 0) {
 		ret = 1;
-		if (path->slots[0] == 0) {
-printk("fail1\n");
+		if (path->slots[0] == 0)
 			goto fail;
-		}
 		path->slots[0]--;
 		btrfs_disk_key_to_cpu(&found_key,
 				      &leaf->items[path->slots[0]].key);
 		if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
 		    found_key.objectid != objectid) {
-printk("fail2 type %u %Lu %Lu\n", btrfs_key_type(&found_key), found_key.objectid, objectid);
 			goto fail;
 		}
 		csum_offset = (offset - found_key.offset) >>
@@ -86,7 +82,6 @@ printk("fail2 type %u %Lu %Lu\n", btrfs_key_type(&found_key), found_key.objectid
 		if (csum_offset >=
 		    btrfs_item_size(leaf->items + path->slots[0]) /
 		    sizeof(struct btrfs_csum_item)) {
-printk("fail3, csum offset %lu size %u\n", csum_offset, btrfs_item_size(leaf->items + path->slots[0]) / sizeof(struct btrfs_csum_item));
 			goto fail;
 		}
 	}
@@ -109,26 +104,18 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	struct btrfs_key file_key;
 	int ins_len = mod < 0 ? -1 : 0;
 	int cow = mod != 0;
-	struct btrfs_csum_item *csum_item;
 
-	csum_item = btrfs_lookup_csum(trans, root, path, objectid, offset, 0);
-	if (IS_ERR(csum_item))
-		return PTR_ERR(csum_item);
 	file_key.objectid = objectid;
-	file_key.offset = btrfs_csum_extent_offset(csum_item);
+	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
-	btrfs_release_path(root, path);
-printk("lookup file extent searches for %Lu\n", file_key.offset);
 	ret = btrfs_search_slot(trans, root, &file_key, path, ins_len, cow);
-printk("ret is %d\n", ret);
 	return ret;
 }
 
 int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  u64 objectid, u64 offset,
-			  u64 extent_offset,
 			  char *data, size_t len)
 {
 	int ret;
@@ -151,10 +138,8 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
-printk("searching for csum %Lu %Lu\n", objectid, offset);
 	ret = btrfs_search_slot(trans, root, &file_key, path,
 				sizeof(struct btrfs_csum_item), 1);
-printk("ret %d\n", ret);
 	if (ret < 0)
 		goto fail;
 	if (ret == 0) {
@@ -167,15 +152,12 @@ printk("ret %d\n", ret);
 	path->slots[0]--;
 	leaf = btrfs_buffer_leaf(path->nodes[0]);
 	btrfs_disk_key_to_cpu(&found_key, &leaf->items[path->slots[0]].key);
-printk("found key %Lu %Lu %u\n", found_key.objectid, found_key.offset, found_key.flags);
 	csum_offset = (offset - found_key.offset) >>
 			root->fs_info->sb->s_blocksize_bits;
-printk("csum_offset %Lu\n", csum_offset);
 	if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
 	    found_key.objectid != objectid ||
 	    csum_offset >= MAX_CSUM_ITEMS(root)) {
 		btrfs_release_path(root, path);
-printk("insert1\n");
 		goto insert;
 	}
 	if (csum_offset >= btrfs_item_size(leaf->items + path->slots[0]) /
@@ -183,13 +165,11 @@ printk("insert1\n");
 		ret = btrfs_extend_item(trans, root, path,
 					sizeof(struct btrfs_csum_item));
 		BUG_ON(ret);
-printk("item extended\n");
 		goto csum;
 	}
 
 insert:
 	csum_offset = 0;
-printk("inserting item %Lu %Lu %u\n", file_key.objectid, file_key.offset, file_key.flags);
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      sizeof(struct btrfs_csum_item));
 	if (ret != 0 && ret != -EEXIST)
@@ -201,12 +181,10 @@ printk("inserting item %Lu %Lu %u\n", file_key.objectid, file_key.offset, file_k
 	item += csum_offset;
 found:
 	ret = btrfs_csum_data(root, data, len, item->csum);
-	btrfs_set_csum_extent_offset(item, extent_offset);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
 	btrfs_release_path(root, path);
 	btrfs_free_path(path);
-printk("return ret %d\n", ret);
 	return ret;
 }
 

commit b18c6685810af8e6763760711aece31ccc7a8ea8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 17 13:26:50 2007 -0400

    Btrfs: progress on file_write
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 93d42d650820..f49968ad0a07 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -6,13 +6,11 @@
 #define MAX_CSUM_ITEMS(r) ((((BTRFS_LEAF_DATA_SIZE(r) - \
 				 sizeof(struct btrfs_item)) / \
 				sizeof(struct btrfs_csum_item)) - 1))
-int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
+int btrfs_insert_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
-			       u64 objectid, u64 offset,
-			       u64 num_blocks, u64 hint_block,
-			       u64 *result)
+			       u64 objectid, u64 pos,
+			       u64 offset, u64 num_blocks)
 {
-	struct btrfs_key ins;
 	int ret = 0;
 	struct btrfs_file_extent_item *item;
 	struct btrfs_key file_key;
@@ -21,11 +19,13 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
 	btrfs_init_path(path);
+	/*
 	ret = btrfs_alloc_extent(trans, root, num_blocks, hint_block,
 				 (u64)-1, &ins);
+				 */
 	BUG_ON(ret);
 	file_key.objectid = objectid;
-	file_key.offset = offset;
+	file_key.offset = pos;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
 
@@ -34,21 +34,22 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 	BUG_ON(ret);
 	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_file_extent_item);
-	btrfs_set_file_extent_disk_blocknr(item, ins.objectid);
-	btrfs_set_file_extent_disk_num_blocks(item, ins.offset);
+	btrfs_set_file_extent_disk_blocknr(item, offset);
+	btrfs_set_file_extent_disk_num_blocks(item, num_blocks);
 	btrfs_set_file_extent_offset(item, 0);
-	btrfs_set_file_extent_num_blocks(item, ins.offset);
+	btrfs_set_file_extent_num_blocks(item, num_blocks);
 	btrfs_set_file_extent_generation(item, trans->transid);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
-	*result = ins.objectid;
 	btrfs_release_path(root, path);
 	btrfs_free_path(path);
 	return 0;
 }
 
-static struct btrfs_csum_item *__lookup_csum_item(struct btrfs_root *root,
-						  struct btrfs_path *path,
-						  u64 objectid, u64 offset)
+struct btrfs_csum_item *btrfs_lookup_csum(struct btrfs_trans_handle *trans,
+					  struct btrfs_root *root,
+					  struct btrfs_path *path,
+					  u64 objectid, u64 offset,
+					  int cow)
 {
 	int ret;
 	struct btrfs_key file_key;
@@ -61,19 +62,23 @@ static struct btrfs_csum_item *__lookup_csum_item(struct btrfs_root *root,
 	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
-	ret = btrfs_search_slot(NULL, root, &file_key, path, 0, 0);
+printk("__lookup for %Lu\n", offset);
+	ret = btrfs_search_slot(trans, root, &file_key, path, 0, cow);
 	if (ret < 0)
 		goto fail;
 	leaf = btrfs_buffer_leaf(path->nodes[0]);
 	if (ret > 0) {
 		ret = 1;
-		if (path->slots[0] == 0)
+		if (path->slots[0] == 0) {
+printk("fail1\n");
 			goto fail;
+		}
 		path->slots[0]--;
 		btrfs_disk_key_to_cpu(&found_key,
 				      &leaf->items[path->slots[0]].key);
 		if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
 		    found_key.objectid != objectid) {
+printk("fail2 type %u %Lu %Lu\n", btrfs_key_type(&found_key), found_key.objectid, objectid);
 			goto fail;
 		}
 		csum_offset = (offset - found_key.offset) >>
@@ -81,6 +86,7 @@ static struct btrfs_csum_item *__lookup_csum_item(struct btrfs_root *root,
 		if (csum_offset >=
 		    btrfs_item_size(leaf->items + path->slots[0]) /
 		    sizeof(struct btrfs_csum_item)) {
+printk("fail3, csum offset %lu size %u\n", csum_offset, btrfs_item_size(leaf->items + path->slots[0]) / sizeof(struct btrfs_csum_item));
 			goto fail;
 		}
 	}
@@ -89,7 +95,7 @@ static struct btrfs_csum_item *__lookup_csum_item(struct btrfs_root *root,
 	return item;
 fail:
 	if (ret > 0)
-		ret = -EIO;
+		ret = -ENOENT;
 	return ERR_PTR(ret);
 }
 
@@ -105,7 +111,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	int cow = mod != 0;
 	struct btrfs_csum_item *csum_item;
 
-	csum_item = __lookup_csum_item(root, path, objectid, offset);
+	csum_item = btrfs_lookup_csum(trans, root, path, objectid, offset, 0);
 	if (IS_ERR(csum_item))
 		return PTR_ERR(csum_item);
 	file_key.objectid = objectid;
@@ -113,7 +119,9 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
 	btrfs_release_path(root, path);
+printk("lookup file extent searches for %Lu\n", file_key.offset);
 	ret = btrfs_search_slot(trans, root, &file_key, path, ins_len, cow);
+printk("ret is %d\n", ret);
 	return ret;
 }
 
@@ -134,17 +142,23 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
 	btrfs_init_path(path);
+
+	item = btrfs_lookup_csum(trans, root, path, objectid, offset, 0);
+	if (!IS_ERR(item))
+		goto found;
+	btrfs_release_path(root, path);
 	file_key.objectid = objectid;
 	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
+printk("searching for csum %Lu %Lu\n", objectid, offset);
 	ret = btrfs_search_slot(trans, root, &file_key, path,
 				sizeof(struct btrfs_csum_item), 1);
+printk("ret %d\n", ret);
 	if (ret < 0)
 		goto fail;
 	if (ret == 0) {
-		csum_offset = 0;
-		goto csum;
+		BUG();
 	}
 	if (path->slots[0] == 0) {
 		btrfs_release_path(root, path);
@@ -153,12 +167,15 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	path->slots[0]--;
 	leaf = btrfs_buffer_leaf(path->nodes[0]);
 	btrfs_disk_key_to_cpu(&found_key, &leaf->items[path->slots[0]].key);
+printk("found key %Lu %Lu %u\n", found_key.objectid, found_key.offset, found_key.flags);
 	csum_offset = (offset - found_key.offset) >>
 			root->fs_info->sb->s_blocksize_bits;
+printk("csum_offset %Lu\n", csum_offset);
 	if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
 	    found_key.objectid != objectid ||
 	    csum_offset >= MAX_CSUM_ITEMS(root)) {
 		btrfs_release_path(root, path);
+printk("insert1\n");
 		goto insert;
 	}
 	if (csum_offset >= btrfs_item_size(leaf->items + path->slots[0]) /
@@ -166,11 +183,13 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 		ret = btrfs_extend_item(trans, root, path,
 					sizeof(struct btrfs_csum_item));
 		BUG_ON(ret);
+printk("item extended\n");
 		goto csum;
 	}
 
 insert:
 	csum_offset = 0;
+printk("inserting item %Lu %Lu %u\n", file_key.objectid, file_key.offset, file_key.flags);
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      sizeof(struct btrfs_csum_item));
 	if (ret != 0 && ret != -EEXIST)
@@ -180,12 +199,14 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			      struct btrfs_csum_item);
 	ret = 0;
 	item += csum_offset;
+found:
 	ret = btrfs_csum_data(root, data, len, item->csum);
 	btrfs_set_csum_extent_offset(item, extent_offset);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
 	btrfs_release_path(root, path);
 	btrfs_free_path(path);
+printk("return ret %d\n", ret);
 	return ret;
 }
 
@@ -208,7 +229,7 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
 	mutex_lock(&root->fs_info->fs_mutex);
 
-	item = __lookup_csum_item(root, path, objectid, offset);
+	item = btrfs_lookup_csum(NULL, root, path, objectid, offset, 0);
 	if (IS_ERR(item)) {
 		ret = PTR_ERR(item);
 		goto fail;

commit 6567e837df07e43bffc08ac40858af8133a007bf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 16 09:22:45 2007 -0400

    Btrfs: early work to file_write in big extents
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index d9fd7f4d3794..93d42d650820 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -3,6 +3,9 @@
 #include "disk-io.h"
 #include "transaction.h"
 
+#define MAX_CSUM_ITEMS(r) ((((BTRFS_LEAF_DATA_SIZE(r) - \
+				 sizeof(struct btrfs_item)) / \
+				sizeof(struct btrfs_csum_item)) - 1))
 int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *root,
 			       u64 objectid, u64 offset,
@@ -43,6 +46,54 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 	return 0;
 }
 
+static struct btrfs_csum_item *__lookup_csum_item(struct btrfs_root *root,
+						  struct btrfs_path *path,
+						  u64 objectid, u64 offset)
+{
+	int ret;
+	struct btrfs_key file_key;
+	struct btrfs_key found_key;
+	struct btrfs_csum_item *item;
+	struct btrfs_leaf *leaf;
+	u64 csum_offset = 0;
+
+	file_key.objectid = objectid;
+	file_key.offset = offset;
+	file_key.flags = 0;
+	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
+	ret = btrfs_search_slot(NULL, root, &file_key, path, 0, 0);
+	if (ret < 0)
+		goto fail;
+	leaf = btrfs_buffer_leaf(path->nodes[0]);
+	if (ret > 0) {
+		ret = 1;
+		if (path->slots[0] == 0)
+			goto fail;
+		path->slots[0]--;
+		btrfs_disk_key_to_cpu(&found_key,
+				      &leaf->items[path->slots[0]].key);
+		if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
+		    found_key.objectid != objectid) {
+			goto fail;
+		}
+		csum_offset = (offset - found_key.offset) >>
+				root->fs_info->sb->s_blocksize_bits;
+		if (csum_offset >=
+		    btrfs_item_size(leaf->items + path->slots[0]) /
+		    sizeof(struct btrfs_csum_item)) {
+			goto fail;
+		}
+	}
+	item = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_csum_item);
+	item += csum_offset;
+	return item;
+fail:
+	if (ret > 0)
+		ret = -EIO;
+	return ERR_PTR(ret);
+}
+
+
 int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
@@ -52,11 +103,16 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	struct btrfs_key file_key;
 	int ins_len = mod < 0 ? -1 : 0;
 	int cow = mod != 0;
+	struct btrfs_csum_item *csum_item;
 
+	csum_item = __lookup_csum_item(root, path, objectid, offset);
+	if (IS_ERR(csum_item))
+		return PTR_ERR(csum_item);
 	file_key.objectid = objectid;
-	file_key.offset = offset;
+	file_key.offset = btrfs_csum_extent_offset(csum_item);
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
+	btrfs_release_path(root, path);
 	ret = btrfs_search_slot(trans, root, &file_key, path, ins_len, cow);
 	return ret;
 }
@@ -64,12 +120,16 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root,
 			  u64 objectid, u64 offset,
+			  u64 extent_offset,
 			  char *data, size_t len)
 {
 	int ret;
 	struct btrfs_key file_key;
+	struct btrfs_key found_key;
 	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
+	struct btrfs_leaf *leaf;
+	u64 csum_offset;
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
@@ -78,14 +138,50 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
+	ret = btrfs_search_slot(trans, root, &file_key, path,
+				sizeof(struct btrfs_csum_item), 1);
+	if (ret < 0)
+		goto fail;
+	if (ret == 0) {
+		csum_offset = 0;
+		goto csum;
+	}
+	if (path->slots[0] == 0) {
+		btrfs_release_path(root, path);
+		goto insert;
+	}
+	path->slots[0]--;
+	leaf = btrfs_buffer_leaf(path->nodes[0]);
+	btrfs_disk_key_to_cpu(&found_key, &leaf->items[path->slots[0]].key);
+	csum_offset = (offset - found_key.offset) >>
+			root->fs_info->sb->s_blocksize_bits;
+	if (btrfs_key_type(&found_key) != BTRFS_CSUM_ITEM_KEY ||
+	    found_key.objectid != objectid ||
+	    csum_offset >= MAX_CSUM_ITEMS(root)) {
+		btrfs_release_path(root, path);
+		goto insert;
+	}
+	if (csum_offset >= btrfs_item_size(leaf->items + path->slots[0]) /
+	    sizeof(struct btrfs_csum_item)) {
+		ret = btrfs_extend_item(trans, root, path,
+					sizeof(struct btrfs_csum_item));
+		BUG_ON(ret);
+		goto csum;
+	}
+
+insert:
+	csum_offset = 0;
 	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
-				      BTRFS_CSUM_SIZE);
+				      sizeof(struct btrfs_csum_item));
 	if (ret != 0 && ret != -EEXIST)
 		goto fail;
+csum:
 	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_csum_item);
 	ret = 0;
+	item += csum_offset;
 	ret = btrfs_csum_data(root, data, len, item->csum);
+	btrfs_set_csum_extent_offset(item, extent_offset);
 	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
 	btrfs_release_path(root, path);
@@ -111,12 +207,13 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
 	mutex_lock(&root->fs_info->fs_mutex);
-	ret = btrfs_search_slot(NULL, root, &file_key, path, 0, 0);
-	if (ret)
+
+	item = __lookup_csum_item(root, path, objectid, offset);
+	if (IS_ERR(item)) {
+		ret = PTR_ERR(item);
 		goto fail;
-	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
-			      struct btrfs_csum_item);
-	ret = 0;
+	}
+
 	ret = btrfs_csum_data(root, data, len, result);
 	WARN_ON(ret);
 	if (memcmp(result, item->csum, BTRFS_CSUM_SIZE))

commit d0dbc6245cefa36e19dff49c557ccf05e3063e9c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 10 12:36:36 2007 -0400

    Btrfs: drop owner and parentid
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 2c98b620c594..d9fd7f4d3794 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -19,7 +19,7 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 	BUG_ON(!path);
 	btrfs_init_path(path);
 	ret = btrfs_alloc_extent(trans, root, num_blocks, hint_block,
-				 (u64)-1, objectid, &ins);
+				 (u64)-1, &ins);
 	BUG_ON(ret);
 	file_key.objectid = objectid;
 	file_key.offset = offset;

commit 2da566edd8ce32ae2952b863ee634bcc2e7d63c1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 2 15:43:21 2007 -0400

    Btrfs: csum_verify_file_block locking fix
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index e7510ac5559d..2c98b620c594 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -110,6 +110,7 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
+	mutex_lock(&root->fs_info->fs_mutex);
 	ret = btrfs_search_slot(NULL, root, &file_key, path, 0, 0);
 	if (ret)
 		goto fail;
@@ -123,6 +124,7 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 fail:
 	btrfs_release_path(root, path);
 	btrfs_free_path(path);
+	mutex_unlock(&root->fs_info->fs_mutex);
 	return ret;
 }
 

commit 5caf2a002901f0fde475371c4bf1c553b51884af
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 2 11:20:42 2007 -0400

    Btrfs: dynamic allocation of path struct
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index c3992b7b0c60..e7510ac5559d 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -13,9 +13,11 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 	int ret = 0;
 	struct btrfs_file_extent_item *item;
 	struct btrfs_key file_key;
-	struct btrfs_path path;
+	struct btrfs_path *path;
 
-	btrfs_init_path(&path);
+	path = btrfs_alloc_path();
+	BUG_ON(!path);
+	btrfs_init_path(path);
 	ret = btrfs_alloc_extent(trans, root, num_blocks, hint_block,
 				 (u64)-1, objectid, &ins);
 	BUG_ON(ret);
@@ -24,19 +26,20 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
 
-	ret = btrfs_insert_empty_item(trans, root, &path, &file_key,
+	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      sizeof(*item));
 	BUG_ON(ret);
-	item = btrfs_item_ptr(btrfs_buffer_leaf(path.nodes[0]), path.slots[0],
+	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_file_extent_item);
 	btrfs_set_file_extent_disk_blocknr(item, ins.objectid);
 	btrfs_set_file_extent_disk_num_blocks(item, ins.offset);
 	btrfs_set_file_extent_offset(item, 0);
 	btrfs_set_file_extent_num_blocks(item, ins.offset);
 	btrfs_set_file_extent_generation(item, trans->transid);
-	btrfs_mark_buffer_dirty(path.nodes[0]);
+	btrfs_mark_buffer_dirty(path->nodes[0]);
 	*result = ins.objectid;
-	btrfs_release_path(root, &path);
+	btrfs_release_path(root, path);
+	btrfs_free_path(path);
 	return 0;
 }
 
@@ -65,25 +68,28 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 {
 	int ret;
 	struct btrfs_key file_key;
-	struct btrfs_path path;
+	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
 
-	btrfs_init_path(&path);
+	path = btrfs_alloc_path();
+	BUG_ON(!path);
+	btrfs_init_path(path);
 	file_key.objectid = objectid;
 	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
-	ret = btrfs_insert_empty_item(trans, root, &path, &file_key,
+	ret = btrfs_insert_empty_item(trans, root, path, &file_key,
 				      BTRFS_CSUM_SIZE);
 	if (ret != 0 && ret != -EEXIST)
 		goto fail;
-	item = btrfs_item_ptr(btrfs_buffer_leaf(path.nodes[0]), path.slots[0],
+	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_csum_item);
 	ret = 0;
 	ret = btrfs_csum_data(root, data, len, item->csum);
-	btrfs_mark_buffer_dirty(path.nodes[0]);
+	btrfs_mark_buffer_dirty(path->nodes[0]);
 fail:
-	btrfs_release_path(root, &path);
+	btrfs_release_path(root, path);
+	btrfs_free_path(path);
 	return ret;
 }
 
@@ -93,19 +99,21 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 {
 	int ret;
 	struct btrfs_key file_key;
-	struct btrfs_path path;
+	struct btrfs_path *path;
 	struct btrfs_csum_item *item;
 	char result[BTRFS_CSUM_SIZE];
 
-	btrfs_init_path(&path);
+	path = btrfs_alloc_path();
+	BUG_ON(!path);
+	btrfs_init_path(path);
 	file_key.objectid = objectid;
 	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
-	ret = btrfs_search_slot(NULL, root, &file_key, &path, 0, 0);
+	ret = btrfs_search_slot(NULL, root, &file_key, path, 0, 0);
 	if (ret)
 		goto fail;
-	item = btrfs_item_ptr(btrfs_buffer_leaf(path.nodes[0]), path.slots[0],
+	item = btrfs_item_ptr(btrfs_buffer_leaf(path->nodes[0]), path->slots[0],
 			      struct btrfs_csum_item);
 	ret = 0;
 	ret = btrfs_csum_data(root, data, len, result);
@@ -113,7 +121,8 @@ int btrfs_csum_verify_file_block(struct btrfs_root *root,
 	if (memcmp(result, item->csum, BTRFS_CSUM_SIZE))
 		ret = 1;
 fail:
-	btrfs_release_path(root, &path);
+	btrfs_release_path(root, path);
+	btrfs_free_path(path);
 	return ret;
 }
 

commit d6025579531b7ea170ba283b171ff7a6bf7d0e12
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 30 14:27:56 2007 -0400

    Btrfs: corruption hunt continues
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 2d2c23ca7cbf..c3992b7b0c60 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -34,7 +34,7 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 	btrfs_set_file_extent_offset(item, 0);
 	btrfs_set_file_extent_num_blocks(item, ins.offset);
 	btrfs_set_file_extent_generation(item, trans->transid);
-	mark_buffer_dirty(path.nodes[0]);
+	btrfs_mark_buffer_dirty(path.nodes[0]);
 	*result = ins.objectid;
 	btrfs_release_path(root, &path);
 	return 0;
@@ -81,7 +81,7 @@ int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
 			      struct btrfs_csum_item);
 	ret = 0;
 	ret = btrfs_csum_data(root, data, len, item->csum);
-	mark_buffer_dirty(path.nodes[0]);
+	btrfs_mark_buffer_dirty(path.nodes[0]);
 fail:
 	btrfs_release_path(root, &path);
 	return ret;

commit f254e52c1ce550fdaa0d31f5e068f0d67c2485d4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 29 15:15:27 2007 -0400

    Btrfs: verify csums on read
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 5230a44cb19b..2d2c23ca7cbf 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -57,3 +57,63 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	ret = btrfs_search_slot(trans, root, &file_key, path, ins_len, cow);
 	return ret;
 }
+
+int btrfs_csum_file_block(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root,
+			  u64 objectid, u64 offset,
+			  char *data, size_t len)
+{
+	int ret;
+	struct btrfs_key file_key;
+	struct btrfs_path path;
+	struct btrfs_csum_item *item;
+
+	btrfs_init_path(&path);
+	file_key.objectid = objectid;
+	file_key.offset = offset;
+	file_key.flags = 0;
+	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
+	ret = btrfs_insert_empty_item(trans, root, &path, &file_key,
+				      BTRFS_CSUM_SIZE);
+	if (ret != 0 && ret != -EEXIST)
+		goto fail;
+	item = btrfs_item_ptr(btrfs_buffer_leaf(path.nodes[0]), path.slots[0],
+			      struct btrfs_csum_item);
+	ret = 0;
+	ret = btrfs_csum_data(root, data, len, item->csum);
+	mark_buffer_dirty(path.nodes[0]);
+fail:
+	btrfs_release_path(root, &path);
+	return ret;
+}
+
+int btrfs_csum_verify_file_block(struct btrfs_root *root,
+				 u64 objectid, u64 offset,
+				 char *data, size_t len)
+{
+	int ret;
+	struct btrfs_key file_key;
+	struct btrfs_path path;
+	struct btrfs_csum_item *item;
+	char result[BTRFS_CSUM_SIZE];
+
+	btrfs_init_path(&path);
+	file_key.objectid = objectid;
+	file_key.offset = offset;
+	file_key.flags = 0;
+	btrfs_set_key_type(&file_key, BTRFS_CSUM_ITEM_KEY);
+	ret = btrfs_search_slot(NULL, root, &file_key, &path, 0, 0);
+	if (ret)
+		goto fail;
+	item = btrfs_item_ptr(btrfs_buffer_leaf(path.nodes[0]), path.slots[0],
+			      struct btrfs_csum_item);
+	ret = 0;
+	ret = btrfs_csum_data(root, data, len, result);
+	WARN_ON(ret);
+	if (memcmp(result, item->csum, BTRFS_CSUM_SIZE))
+		ret = 1;
+fail:
+	btrfs_release_path(root, &path);
+	return ret;
+}
+

commit 9773a788681db1f5c2701b7433737fdca61a14ba
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 27 11:26:26 2007 -0400

    Btrfs: byte offsets for file keys
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 09de270c5a52..5230a44cb19b 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -26,6 +26,7 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 
 	ret = btrfs_insert_empty_item(trans, root, &path, &file_key,
 				      sizeof(*item));
+	BUG_ON(ret);
 	item = btrfs_item_ptr(btrfs_buffer_leaf(path.nodes[0]), path.slots[0],
 			      struct btrfs_file_extent_item);
 	btrfs_set_file_extent_disk_blocknr(item, ins.objectid);
@@ -42,7 +43,7 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_path *path, u64 objectid,
-			     u64 blocknr, u64 num_blocks, int mod)
+			     u64 offset, int mod)
 {
 	int ret;
 	struct btrfs_key file_key;
@@ -50,7 +51,7 @@ int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
 	int cow = mod != 0;
 
 	file_key.objectid = objectid;
-	file_key.offset = blocknr;
+	file_key.offset = offset;
 	file_key.flags = 0;
 	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
 	ret = btrfs_search_slot(trans, root, &file_key, path, ins_len, cow);

commit 71951f35a6e413f2bfbd41829af8cf10a890aeb6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 27 09:16:29 2007 -0400

    Btrfs: add generation field to file extent
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 4a0367d702b7..09de270c5a52 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -32,6 +32,7 @@ int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
 	btrfs_set_file_extent_disk_num_blocks(item, ins.offset);
 	btrfs_set_file_extent_offset(item, 0);
 	btrfs_set_file_extent_num_blocks(item, ins.offset);
+	btrfs_set_file_extent_generation(item, trans->transid);
 	mark_buffer_dirty(path.nodes[0]);
 	*result = ins.objectid;
 	btrfs_release_path(root, &path);

commit dee26a9f7aab7ffe1193cd1415b23a69426acc9f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 26 16:00:06 2007 -0400

    btrfs_get_block, file read/write
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 8e1e5b4ccfaf..4a0367d702b7 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -1,9 +1,57 @@
 #include <linux/module.h>
 #include "ctree.h"
+#include "disk-io.h"
 #include "transaction.h"
 
-int btrfs_create_file(struct btrfs_trans_handle *trans,
-		      struct btrfs_root *root, u64 dirid, u64 *objectid)
+int btrfs_alloc_file_extent(struct btrfs_trans_handle *trans,
+			       struct btrfs_root *root,
+			       u64 objectid, u64 offset,
+			       u64 num_blocks, u64 hint_block,
+			       u64 *result)
 {
+	struct btrfs_key ins;
+	int ret = 0;
+	struct btrfs_file_extent_item *item;
+	struct btrfs_key file_key;
+	struct btrfs_path path;
+
+	btrfs_init_path(&path);
+	ret = btrfs_alloc_extent(trans, root, num_blocks, hint_block,
+				 (u64)-1, objectid, &ins);
+	BUG_ON(ret);
+	file_key.objectid = objectid;
+	file_key.offset = offset;
+	file_key.flags = 0;
+	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
+
+	ret = btrfs_insert_empty_item(trans, root, &path, &file_key,
+				      sizeof(*item));
+	item = btrfs_item_ptr(btrfs_buffer_leaf(path.nodes[0]), path.slots[0],
+			      struct btrfs_file_extent_item);
+	btrfs_set_file_extent_disk_blocknr(item, ins.objectid);
+	btrfs_set_file_extent_disk_num_blocks(item, ins.offset);
+	btrfs_set_file_extent_offset(item, 0);
+	btrfs_set_file_extent_num_blocks(item, ins.offset);
+	mark_buffer_dirty(path.nodes[0]);
+	*result = ins.objectid;
+	btrfs_release_path(root, &path);
 	return 0;
 }
+
+int btrfs_lookup_file_extent(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root,
+			     struct btrfs_path *path, u64 objectid,
+			     u64 blocknr, u64 num_blocks, int mod)
+{
+	int ret;
+	struct btrfs_key file_key;
+	int ins_len = mod < 0 ? -1 : 0;
+	int cow = mod != 0;
+
+	file_key.objectid = objectid;
+	file_key.offset = blocknr;
+	file_key.flags = 0;
+	btrfs_set_key_type(&file_key, BTRFS_EXTENT_DATA_KEY);
+	ret = btrfs_search_slot(trans, root, &file_key, path, ins_len, cow);
+	return ret;
+}

commit 2e635a278354a1a7951e16cfea4c247d6d0e7c99
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 21 11:12:56 2007 -0400

    Btrfs: initial move to kernel module land
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index 24cfd6d85240..8e1e5b4ccfaf 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -1,9 +1,5 @@
-#include <stdio.h>
-#include <stdlib.h>
-#include "kerncompat.h"
-#include "radix-tree.h"
+#include <linux/module.h>
 #include "ctree.h"
-#include "disk-io.h"
 #include "transaction.h"
 
 int btrfs_create_file(struct btrfs_trans_handle *trans,

commit 9f5fae2fe6dc35b46bf56183f11398451851cb3f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 20 14:38:32 2007 -0400

    Btrfs: Add inode map, and the start of file extent items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
index f5b36c732c5e..24cfd6d85240 100644
--- a/fs/btrfs/file-item.c
+++ b/fs/btrfs/file-item.c
@@ -4,4 +4,10 @@
 #include "radix-tree.h"
 #include "ctree.h"
 #include "disk-io.h"
+#include "transaction.h"
 
+int btrfs_create_file(struct btrfs_trans_handle *trans,
+		      struct btrfs_root *root, u64 dirid, u64 *objectid)
+{
+	return 0;
+}

commit 1e1d27017c5986c1ea81181506042cf9cba3f6ea
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 15 19:03:33 2007 -0400

    Btrfs: add inode item
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/file-item.c b/fs/btrfs/file-item.c
new file mode 100644
index 000000000000..f5b36c732c5e
--- /dev/null
+++ b/fs/btrfs/file-item.c
@@ -0,0 +1,7 @@
+#include <stdio.h>
+#include <stdlib.h>
+#include "kerncompat.h"
+#include "radix-tree.h"
+#include "ctree.h"
+#include "disk-io.h"
+
