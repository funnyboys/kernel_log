commit b272ae22acd2ca688bbf9d94eea4b1da61fdc697
Author: David Sterba <dsterba@suse.com>
Date:   Wed Feb 5 19:09:33 2020 +0100

    btrfs: drop argument tree from btrfs_lock_and_flush_ordered_range
    
    The tree pointer can be safely read from the inode so we can drop the
    redundant argument from btrfs_lock_and_flush_ordered_range.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index a46f319d9ae0..c01c9698250b 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -183,8 +183,7 @@ u64 btrfs_wait_ordered_extents(struct btrfs_root *root, u64 nr,
 			       const u64 range_start, const u64 range_len);
 void btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, u64 nr,
 			      const u64 range_start, const u64 range_len);
-void btrfs_lock_and_flush_ordered_range(struct extent_io_tree *tree,
-					struct btrfs_inode *inode, u64 start,
+void btrfs_lock_and_flush_ordered_range(struct btrfs_inode *inode, u64 start,
 					u64 end,
 					struct extent_state **cached_state);
 int __init ordered_data_init(void);

commit 3f1c64ce04387773d2b0d8ef6a7e573ff80e4436
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 17 09:02:24 2020 -0500

    btrfs: delete the ordered isize update code
    
    Now that we have a safe way to update the isize, remove all of this code
    as it's no longer needed.
    
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 3beb4da4ab41..a46f319d9ae0 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -52,11 +52,6 @@ enum {
 	BTRFS_ORDERED_DIRECT,
 	/* We had an io error when writing this out */
 	BTRFS_ORDERED_IOERR,
-	/*
-	 * indicates whether this ordered extent has done its due diligence in
-	 * updating the isize
-	 */
-	BTRFS_ORDERED_UPDATED_ISIZE,
 	/* Set when we have to truncate an extent */
 	BTRFS_ORDERED_TRUNCATED,
 	/* Regular IO for COW */
@@ -182,8 +177,6 @@ struct btrfs_ordered_extent *btrfs_lookup_ordered_range(
 		struct btrfs_inode *inode,
 		u64 file_offset,
 		u64 len);
-int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
-				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,
 			   u8 *sum, int len);
 u64 btrfs_wait_ordered_extents(struct btrfs_root *root, u64 nr,

commit bffe633e00fb6b904817137fc17a44b42efcd985
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Dec 2 17:34:19 2019 -0800

    btrfs: make btrfs_ordered_extent naming consistent with btrfs_file_extent_item
    
    ordered->start, ordered->len, and ordered->disk_len correspond to
    fi->disk_bytenr, fi->num_bytes, and fi->disk_num_bytes, respectively.
    It's confusing to translate between the two naming schemes. Since a
    btrfs_ordered_extent is basically a pending btrfs_file_extent_item,
    let's make the former use the naming from the latter.
    
    Note that I didn't touch the names in tracepoints just in case there are
    scripts depending on the current naming.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 4eb0319a86d7..3beb4da4ab41 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -67,14 +67,13 @@ struct btrfs_ordered_extent {
 	/* logical offset in the file */
 	u64 file_offset;
 
-	/* disk byte number */
-	u64 start;
-
-	/* ram length of the extent in bytes */
-	u64 len;
-
-	/* extent length on disk */
-	u64 disk_len;
+	/*
+	 * These fields directly correspond to the same fields in
+	 * btrfs_file_extent_item.
+	 */
+	u64 disk_bytenr;
+	u64 num_bytes;
+	u64 disk_num_bytes;
 
 	/* number of bytes that still need writing */
 	u64 bytes_left;
@@ -161,12 +160,15 @@ int btrfs_dec_test_first_ordered_pending(struct inode *inode,
 				   u64 *file_offset, u64 io_size,
 				   int uptodate);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
-			     u64 start, u64 len, u64 disk_len, int type);
+			     u64 disk_bytenr, u64 num_bytes, u64 disk_num_bytes,
+			     int type);
 int btrfs_add_ordered_extent_dio(struct inode *inode, u64 file_offset,
-				 u64 start, u64 len, u64 disk_len, int type);
+				 u64 disk_bytenr, u64 num_bytes,
+				 u64 disk_num_bytes, int type);
 int btrfs_add_ordered_extent_compress(struct inode *inode, u64 file_offset,
-				      u64 start, u64 len, u64 disk_len,
-				      int type, int compress_type);
+				      u64 disk_bytenr, u64 num_bytes,
+				      u64 disk_num_bytes, int type,
+				      int compress_type);
 void btrfs_add_ordered_sum(struct btrfs_ordered_extent *entry,
 			   struct btrfs_ordered_sum *sum);
 struct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,

commit 042528f8d840f42903d91d47e28c0e29da90c2d6
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Nov 14 18:02:43 2019 +0000

    Btrfs: fix block group remaining RO forever after error during device replace
    
    When doing a device replace, while at scrub.c:scrub_enumerate_chunks(), we
    set the block group to RO mode and then wait for any ongoing writes into
    extents of the block group to complete. While doing that wait we overwrite
    the value of the variable 'ret' and can break out of the loop if an error
    happens without turning the block group back into RW mode. So what happens
    is the following:
    
    1) btrfs_inc_block_group_ro() returns 0, meaning it set the block group
       to RO mode (its ->ro field set to 1 or incremented to some value > 1);
    
    2) Then btrfs_wait_ordered_roots() returns a value > 0;
    
    3) Then if either joining or committing the transaction fails, we break
       out of the loop wihtout calling btrfs_dec_block_group_ro(), leaving
       the block group in RO mode forever.
    
    To fix this, just remove the code that waits for ongoing writes to extents
    of the block group, since it's not needed because in the initial setup
    phase of a device replace operation, before starting to find all chunks
    and their extents, we set the target device for replace while holding
    fs_info->dev_replace->rwsem, which ensures that after releasing that
    semaphore, any writes into the source device are made to the target device
    as well (__btrfs_map_block() guarantees that). So while at
    scrub_enumerate_chunks() we only need to worry about finding and copying
    extents (from the source device to the target device) that were written
    before we started the device replace operation.
    
    Fixes: f0e9b7d6401959 ("Btrfs: fix race setting block group readonly during device replace")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 5204171ea962..4eb0319a86d7 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -186,7 +186,7 @@ int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,
 			   u8 *sum, int len);
 u64 btrfs_wait_ordered_extents(struct btrfs_root *root, u64 nr,
 			       const u64 range_start, const u64 range_len);
-u64 btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, u64 nr,
+void btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, u64 nr,
 			      const u64 range_start, const u64 range_len);
 void btrfs_lock_and_flush_ordered_range(struct extent_io_tree *tree,
 					struct btrfs_inode *inode, u64 start,

commit 1e25a2e3ca0dab0ed1030570e95d98af47113eae
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed May 22 10:19:01 2019 +0200

    btrfs: don't assume ordered sums to be 4 bytes
    
    BTRFS has the implicit assumption that a checksum in btrfs_orderd_sums
    is 4 bytes. While this is true for CRC32C, it is not for any other
    checksum.
    
    Change the data type to be a byte array and adjust loop index
    calculation accordingly.
    
    This includes moving the adjustment of 'index' by 'ins_size' in
    btrfs_csum_file_blocks() before dividing 'ins_size' by the checksum
    size, because before this patch the 'sums' member of 'struct
    btrfs_ordered_sum' was 4 Bytes in size and afterwards it is only one
    byte.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 9b68179d580f..5204171ea962 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -23,7 +23,7 @@ struct btrfs_ordered_sum {
 	int len;
 	struct list_head list;
 	/* last field is a variable length array of csums */
-	u32 sums[];
+	u8 sums[];
 };
 
 /*
@@ -183,7 +183,7 @@ struct btrfs_ordered_extent *btrfs_lookup_ordered_range(
 int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,
-			   u32 *sum, int len);
+			   u8 *sum, int len);
 u64 btrfs_wait_ordered_extents(struct btrfs_root *root, u64 nr,
 			       const u64 range_start, const u64 range_len);
 u64 btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, u64 nr,

commit ffa87214c1100c7ea38e85a3cf981d0d47b1c744
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue May 7 10:19:22 2019 +0300

    btrfs: add new helper btrfs_lock_and_flush_ordered_range
    
    There is a certain idiom used in multiple places in btrfs' codebase,
    dealing with flushing an ordered range. Factor this in a separate
    function that can be reused. Future patches will replace the existing
    code with that function.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 4c5991c3de14..9b68179d580f 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -188,6 +188,10 @@ u64 btrfs_wait_ordered_extents(struct btrfs_root *root, u64 nr,
 			       const u64 range_start, const u64 range_len);
 u64 btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, u64 nr,
 			      const u64 range_start, const u64 range_len);
+void btrfs_lock_and_flush_ordered_range(struct extent_io_tree *tree,
+					struct btrfs_inode *inode, u64 start,
+					u64 end,
+					struct extent_state **cached_state);
 int __init ordered_data_init(void);
 void __cold ordered_data_exit(void);
 

commit f9756261c28c0acdaac8a7a8894d3e25d334d5f3
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 16:16:11 2019 +0300

    btrfs: Remove redundant inode argument from btrfs_add_ordered_sum
    
    Ordered csums are keyed off of a btrfs_ordered_extent, which already has
    a reference to the inode. This implies that an explicit inode argument
    is redundant. So remove it.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index fb9a161f0215..4c5991c3de14 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -167,8 +167,7 @@ int btrfs_add_ordered_extent_dio(struct inode *inode, u64 file_offset,
 int btrfs_add_ordered_extent_compress(struct inode *inode, u64 file_offset,
 				      u64 start, u64 len, u64 disk_len,
 				      int type, int compress_type);
-void btrfs_add_ordered_sum(struct inode *inode,
-			   struct btrfs_ordered_extent *entry,
+void btrfs_add_ordered_sum(struct btrfs_ordered_extent *entry,
 			   struct btrfs_ordered_sum *sum);
 struct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,
 							 u64 file_offset);

commit 5b840301ac4b8a8e8d42d0c7edc31dc3e257145d
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 27 15:17:47 2018 +0100

    btrfs: switch BTRFS_ORDERED_* to enums
    
    We can use simple enum for values that are not part of on-disk format:
    ordered extent flags.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index b10e6765d88f..fb9a161f0215 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -37,26 +37,31 @@ struct btrfs_ordered_sum {
  * rbtree, just before waking any waiters.  It is used to indicate the
  * IO is done and any metadata is inserted into the tree.
  */
-#define BTRFS_ORDERED_IO_DONE 0 /* set when all the pages are written */
-
-#define BTRFS_ORDERED_COMPLETE 1 /* set when removed from the tree */
-
-#define BTRFS_ORDERED_NOCOW 2 /* set when we want to write in place */
-
-#define BTRFS_ORDERED_COMPRESSED 3 /* writing a zlib compressed extent */
-
-#define BTRFS_ORDERED_PREALLOC 4 /* set when writing to preallocated extent */
-
-#define BTRFS_ORDERED_DIRECT 5 /* set when we're doing DIO with this extent */
-
-#define BTRFS_ORDERED_IOERR 6 /* We had an io error when writing this out */
-
-#define BTRFS_ORDERED_UPDATED_ISIZE 7 /* indicates whether this ordered extent
-				       * has done its due diligence in updating
-				       * the isize. */
-#define BTRFS_ORDERED_TRUNCATED 8 /* Set when we have to truncate an extent */
-
-#define BTRFS_ORDERED_REGULAR 10 /* Regular IO for COW */
+enum {
+	/* set when all the pages are written */
+	BTRFS_ORDERED_IO_DONE,
+	/* set when removed from the tree */
+	BTRFS_ORDERED_COMPLETE,
+	/* set when we want to write in place */
+	BTRFS_ORDERED_NOCOW,
+	/* writing a zlib compressed extent */
+	BTRFS_ORDERED_COMPRESSED,
+	/* set when writing to preallocated extent */
+	BTRFS_ORDERED_PREALLOC,
+	/* set when we're doing DIO with this extent */
+	BTRFS_ORDERED_DIRECT,
+	/* We had an io error when writing this out */
+	BTRFS_ORDERED_IOERR,
+	/*
+	 * indicates whether this ordered extent has done its due diligence in
+	 * updating the isize
+	 */
+	BTRFS_ORDERED_UPDATED_ISIZE,
+	/* Set when we have to truncate an extent */
+	BTRFS_ORDERED_TRUNCATED,
+	/* Regular IO for COW */
+	BTRFS_ORDERED_REGULAR,
+};
 
 struct btrfs_ordered_extent {
 	/* logical offset in the file */

commit 85dd506c8e022a5c5555ad22decfa0abf93a5d64
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Oct 26 17:15:21 2018 +0100

    Btrfs: remove no longer used stuff for tracking pending ordered extents
    
    Tracking pending ordered extents per transaction was introduced in commit
    50d9aa99bd35 ("Btrfs: make sure logged extents complete in the current
    transaction V3") and later updated in commit 161c3549b45a ("Btrfs: change
    how we wait for pending ordered extents").
    
    However now that on fsync we always wait for ordered extents to complete
    before logging, done in commit 5636cf7d6dc8 ("btrfs: remove the logged
    extents infrastructure"), we no longer need the stuff to track for pending
    ordered extents, which was not completely removed in the mentioned commit.
    So remove the remaining of the pending ordered extents infrastructure.
    
    Reviewed-by: Liu Bo <bo.liu@linux.alibaba.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 02d813aaa261..b10e6765d88f 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -56,8 +56,6 @@ struct btrfs_ordered_sum {
 				       * the isize. */
 #define BTRFS_ORDERED_TRUNCATED 8 /* Set when we have to truncate an extent */
 
-#define BTRFS_ORDERED_PENDING 9 /* We are waiting for this ordered extent to
-				  * complete in the current transaction. */
 #define BTRFS_ORDERED_REGULAR 10 /* Regular IO for COW */
 
 struct btrfs_ordered_extent {

commit ca5788aba3e8153da38cf99ca3ce2294f032fb51
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jul 19 15:27:46 2018 +0200

    btrfs: remove remaing full_sync logic from btrfs_sync_file
    
    The logic to check if the inode is already in the log can now be
    simplified since we always wait for the ordered extents to complete
    before deciding whether the inode needs to be logged. The big comment
    about it can go away too.
    
    CC: Filipe Manana <fdmanana@suse.com>
    Suggested-by: Filipe Manana <fdmanana@suse.com>
    [ code and changelog copied from mail discussion ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index b2d3f6a091f7..02d813aaa261 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -178,9 +178,6 @@ struct btrfs_ordered_extent *btrfs_lookup_ordered_range(
 		struct btrfs_inode *inode,
 		u64 file_offset,
 		u64 len);
-bool btrfs_have_ordered_extents_in_range(struct inode *inode,
-					 u64 file_offset,
-					 u64 len);
 int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,

commit 5636cf7d6dc86f47fd66757dae088e35014da464
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed May 23 11:58:36 2018 -0400

    btrfs: remove the logged extents infrastructure
    
    This is no longer used anywhere, remove all of it.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 3be443fb3001..b2d3f6a091f7 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -54,15 +54,11 @@ struct btrfs_ordered_sum {
 #define BTRFS_ORDERED_UPDATED_ISIZE 7 /* indicates whether this ordered extent
 				       * has done its due diligence in updating
 				       * the isize. */
-#define BTRFS_ORDERED_LOGGED_CSUM 8 /* We've logged the csums on this ordered
-				       ordered extent */
-#define BTRFS_ORDERED_TRUNCATED 9 /* Set when we have to truncate an extent */
+#define BTRFS_ORDERED_TRUNCATED 8 /* Set when we have to truncate an extent */
 
-#define BTRFS_ORDERED_LOGGED 10 /* Set when we've waited on this ordered extent
-				 * in the logging code. */
-#define BTRFS_ORDERED_PENDING 11 /* We are waiting for this ordered extent to
+#define BTRFS_ORDERED_PENDING 9 /* We are waiting for this ordered extent to
 				  * complete in the current transaction. */
-#define BTRFS_ORDERED_REGULAR 12 /* Regular IO for COW */
+#define BTRFS_ORDERED_REGULAR 10 /* Regular IO for COW */
 
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
@@ -193,16 +189,6 @@ u64 btrfs_wait_ordered_extents(struct btrfs_root *root, u64 nr,
 			       const u64 range_start, const u64 range_len);
 u64 btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, u64 nr,
 			      const u64 range_start, const u64 range_len);
-void btrfs_get_logged_extents(struct btrfs_inode *inode,
-			      struct list_head *logged_list,
-			      const loff_t start,
-			      const loff_t end);
-void btrfs_put_logged_extents(struct list_head *logged_list);
-void btrfs_submit_logged_extents(struct list_head *logged_list,
-				 struct btrfs_root *log);
-void btrfs_wait_logged_extents(struct btrfs_trans_handle *trans,
-			       struct btrfs_root *log, u64 transid);
-void btrfs_free_logged_extents(struct btrfs_root *log, u64 transid);
 int __init ordered_data_init(void);
 void __cold ordered_data_exit(void);
 

commit 9888c3402c8567a977de37f61e9dd87792723064
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:16:55 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- headers
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Unify the include protection macros to match the file names.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 4a1672a13ba6..3be443fb3001 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -1,23 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Copyright (C) 2007 Oracle.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
-#ifndef __BTRFS_ORDERED_DATA__
-#define __BTRFS_ORDERED_DATA__
+#ifndef BTRFS_ORDERED_DATA_H
+#define BTRFS_ORDERED_DATA_H
 
 /* one of these per inode */
 struct btrfs_ordered_inode_tree {
@@ -218,4 +205,5 @@ void btrfs_wait_logged_extents(struct btrfs_trans_handle *trans,
 void btrfs_free_logged_extents(struct btrfs_root *log, u64 transid);
 int __init ordered_data_init(void);
 void __cold ordered_data_exit(void);
+
 #endif

commit e67c718b5b9a306bde7e966be7b4ca48fa063d73
Author: David Sterba <dsterba@suse.com>
Date:   Mon Feb 19 17:24:18 2018 +0100

    btrfs: add more __cold annotations
    
    The __cold functions are placed to a special section, as they're
    expected to be called rarely. This could help i-cache prefetches or help
    compiler to decide which branches are more/less likely to be taken
    without any other annotations needed.
    
    Though we can't add more __exit annotations, it's still possible to add
    __cold (that's also added with __exit). That way the following function
    categories are tagged:
    
    - printf wrappers, error messages
    - exit helpers
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index c53e2cfb72d9..4a1672a13ba6 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -217,5 +217,5 @@ void btrfs_wait_logged_extents(struct btrfs_trans_handle *trans,
 			       struct btrfs_root *log, u64 transid);
 void btrfs_free_logged_extents(struct btrfs_root *log, u64 transid);
 int __init ordered_data_init(void);
-void ordered_data_exit(void);
+void __cold ordered_data_exit(void);
 #endif

commit af89e0dc2ce3177d07c4af4028b8a7b88733d07e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Feb 7 11:19:10 2018 +0200

    btrfs: Don't hardcode the csum size in btrfs_ordered_sum_size
    
    Currently the function uses a hardcoded value for the checksum size of
    a sector. This is fine, given that we currently support only a single
    algorithm, whose checksum is 4 bytes == sizeof(u32). Despite not
    having other algorithms, btrfs' design supports using a different
    algorithm whith different space requirements. To future-proof the code
    query the size of the currently used algorithm from the in-memory copy
    of the super block. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Su Yue <suy.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 56c4c0ee6381..c53e2cfb72d9 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -151,7 +151,9 @@ static inline int btrfs_ordered_sum_size(struct btrfs_fs_info *fs_info,
 					 unsigned long bytes)
 {
 	int num_sectors = (int)DIV_ROUND_UP(bytes, fs_info->sectorsize);
-	return sizeof(struct btrfs_ordered_sum) + num_sectors * sizeof(u32);
+	int csum_size = btrfs_super_csum_size(fs_info->super_copy);
+
+	return sizeof(struct btrfs_ordered_sum) + num_sectors * csum_size;
 }
 
 static inline void

commit 6374e57ad8091b9c2db2eecc536c7f0166ce099e
Author: Chris Mason <clm@fb.com>
Date:   Fri Jun 23 09:48:21 2017 -0700

    btrfs: fix integer overflow in calc_reclaim_items_nr
    
    Dave Jones hit a WARN_ON(nr < 0) in btrfs_wait_ordered_roots() with
    v4.12-rc6.  This was because commit 70e7af244 made it possible for
    calc_reclaim_items_nr() to return a negative number.  It's not really a
    bug in that commit, it just didn't go far enough down the stack to find
    all the possible 64->32 bit overflows.
    
    This switches calc_reclaim_items_nr() to return a u64 and changes everyone
    that uses the results of that math to u64 as well.
    
    Reported-by: Dave Jones <davej@codemonkey.org.uk>
    Fixes: 70e7af2 ("Btrfs: fix delalloc accounting leak caused by u32 overflow")
    Signed-off-by: Chris Mason <clm@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index e0c1d5b8d859..56c4c0ee6381 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -200,9 +200,9 @@ int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,
 			   u32 *sum, int len);
-int btrfs_wait_ordered_extents(struct btrfs_root *root, int nr,
+u64 btrfs_wait_ordered_extents(struct btrfs_root *root, u64 nr,
 			       const u64 range_start, const u64 range_len);
-int btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr,
+u64 btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, u64 nr,
 			      const u64 range_start, const u64 range_len);
 void btrfs_get_logged_extents(struct btrfs_inode *inode,
 			      struct list_head *logged_list,

commit e76edab7f059bc1047c1865141e2709d70e74852
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Mar 3 10:55:13 2017 +0200

    btrfs: convert btrfs_ordered_extent.refs from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 195c93b67fe0..e0c1d5b8d859 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -113,7 +113,7 @@ struct btrfs_ordered_extent {
 	int compress_type;
 
 	/* reference count */
-	atomic_t refs;
+	refcount_t refs;
 
 	/* the inode we belong to */
 	struct inode *inode;

commit a776c6fa1feba7a84519170ebdb7f4a4155b89d6
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Mon Feb 20 13:50:49 2017 +0200

    btrfs: Make btrfs_lookup_ordered_range take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index a8cb8efe6fae..195c93b67fe0 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -189,9 +189,10 @@ void btrfs_start_ordered_extent(struct inode *inode,
 int btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
 struct btrfs_ordered_extent *
 btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
-struct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,
-							u64 file_offset,
-							u64 len);
+struct btrfs_ordered_extent *btrfs_lookup_ordered_range(
+		struct btrfs_inode *inode,
+		u64 file_offset,
+		u64 len);
 bool btrfs_have_ordered_extents_in_range(struct inode *inode,
 					 u64 file_offset,
 					 u64 len);

commit 1af4a0aaa5d4bfcd17020f0620017a3057a9fb8d
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Feb 13 15:35:09 2017 -0800

    Btrfs: specify a new ordered extent type for create_io_em
    
    As 0 refers to an existing type BTRFS_ORDERED_IO_DONE, this specifies a
    new type 'REGULAR' for regular IO.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index b02b71d41d83..a8cb8efe6fae 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -75,6 +75,8 @@ struct btrfs_ordered_sum {
 				 * in the logging code. */
 #define BTRFS_ORDERED_PENDING 11 /* We are waiting for this ordered extent to
 				  * complete in the current transaction. */
+#define BTRFS_ORDERED_REGULAR 12 /* Regular IO for COW */
+
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
 	u64 file_offset;

commit 223466370cf6e05f863fbfeda54a3b6c282749c8
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Wed Jan 18 00:31:39 2017 +0200

    btrfs: Make btrfs_get_logged_extents take btrfs_inode
    
    Signed-off-by: Nikolay Borisov <n.borisov.lkml@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 5f2b0ca28705..b02b71d41d83 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -201,7 +201,7 @@ int btrfs_wait_ordered_extents(struct btrfs_root *root, int nr,
 			       const u64 range_start, const u64 range_len);
 int btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr,
 			      const u64 range_start, const u64 range_len);
-void btrfs_get_logged_extents(struct inode *inode,
+void btrfs_get_logged_extents(struct btrfs_inode *inode,
 			      struct list_head *logged_list,
 			      const loff_t start,
 			      const loff_t end);

commit da17066c40472c2d6a1aab7bb0090c3d285531c9
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 09:22:56 2016 -0400

    btrfs: pull node/sector/stripe sizes out of root and into fs_info
    
    We track the node sizes per-root, but they never vary from the values
    in the superblock.  This patch messes with the 80-column style a bit,
    but subsequent patches to factor out root->fs_info into a convenience
    variable fix it up again.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 451507776ff5..5f2b0ca28705 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -145,10 +145,10 @@ struct btrfs_ordered_extent {
  * calculates the total size you need to allocate for an ordered sum
  * structure spanning 'bytes' in the file
  */
-static inline int btrfs_ordered_sum_size(struct btrfs_root *root,
+static inline int btrfs_ordered_sum_size(struct btrfs_fs_info *fs_info,
 					 unsigned long bytes)
 {
-	int num_sectors = (int)DIV_ROUND_UP(bytes, root->sectorsize);
+	int num_sectors = (int)DIV_ROUND_UP(bytes, fs_info->sectorsize);
 	return sizeof(struct btrfs_ordered_sum) + num_sectors * sizeof(u32);
 }
 

commit f0e9b7d6401959816599191d1d9db90b6fd750db
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat May 14 09:12:53 2016 +0100

    Btrfs: fix race setting block group readonly during device replace
    
    When we do a device replace, for each device extent we find from the
    source device, we set the corresponding block group to readonly mode to
    prevent writes into it from happening while we are copying the device
    extent from the source to the target device. However just before we set
    the block group to readonly mode some concurrent task might have already
    allocated an extent from it or decided it could perform a nocow write
    into one of its extents, which can make the device replace process to
    miss copying an extent since it uses the extent tree's commit root to
    search for extents and only once it finishes searching for all extents
    belonging to the block group it does set the left cursor to the logical
    end address of the block group - this is a problem if the respective
    ordered extents finish while we are searching for extents using the
    extent tree's commit root and no transaction commit happens while we
    are iterating the tree, since it's the delayed references created by the
    ordered extents (when they complete) that insert the extent items into
    the extent tree (using the non-commit root of course).
    Example:
    
              CPU 1                                            CPU 2
    
     btrfs_dev_replace_start()
       btrfs_scrub_dev()
         scrub_enumerate_chunks()
           --> finds device extent belonging
               to block group X
    
                                   <transaction N starts>
    
                                                          starts buffered write
                                                          against some inode
    
                                                          writepages is run against
                                                          that inode forcing dellaloc
                                                          to run
    
                                                          btrfs_writepages()
                                                            extent_writepages()
                                                              extent_write_cache_pages()
                                                                __extent_writepage()
                                                                  writepage_delalloc()
                                                                    run_delalloc_range()
                                                                      cow_file_range()
                                                                        btrfs_reserve_extent()
                                                                          --> allocates an extent
                                                                              from block group X
                                                                              (which is not yet
                                                                               in RO mode)
                                                                        btrfs_add_ordered_extent()
                                                                          --> creates ordered extent Y
                                                            flush_epd_write_bio()
                                                              --> bio against the extent from
                                                                  block group X is submitted
    
           btrfs_inc_block_group_ro(bg X)
             --> sets block group X to readonly
    
           scrub_chunk(bg X)
             scrub_stripe(device extent from srcdev)
               --> keeps searching for extent items
                   belonging to the block group using
                   the extent tree's commit root
               --> it never blocks due to
                   fs_info->scrub_pause_req as no
                   one tries to commit transaction N
               --> copies all extents found from the
                   source device into the target device
               --> finishes search loop
    
                                                            bio completes
    
                                                            ordered extent Y completes
                                                            and creates delayed data
                                                            reference which will add an
                                                            extent item to the extent
                                                            tree when run (typically
                                                            at transaction commit time)
    
                                                              --> so the task doing the
                                                                  scrub/device replace
                                                                  at CPU 1 misses this
                                                                  and does not copy this
                                                                  extent into the new/target
                                                                  device
    
           btrfs_dec_block_group_ro(bg X)
             --> turns block group X back to RW mode
    
           dev_replace->cursor_left is set to the
           logical end offset of block group X
    
    So fix this by waiting for all cow and nocow writes after setting a block
    group to readonly mode.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 2049c9be85ee..451507776ff5 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -199,7 +199,7 @@ int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,
 			   u32 *sum, int len);
 int btrfs_wait_ordered_extents(struct btrfs_root *root, int nr,
 			       const u64 range_start, const u64 range_len);
-void btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr,
+int btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr,
 			      const u64 range_start, const u64 range_len);
 void btrfs_get_logged_extents(struct inode *inode,
 			      struct list_head *logged_list,

commit 42f31734eb7658fd01fb186d56312be869450a42
Merge: e73440868fde 0132761017e0
Author: David Sterba <dsterba@suse.com>
Date:   Wed May 25 22:51:03 2016 +0200

    Merge branch 'cleanups-4.7' into for-chris-4.7-20160525

commit 0132761017e012ab4dc8584d679503f2ba26ca86
Author: Nicholas D Steeves <nsteeves@gmail.com>
Date:   Thu May 19 21:18:45 2016 -0400

    btrfs: fix string and comment grammatical issues and typos
    
    Signed-off-by: Nicholas D Steeves <nsteeves@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 23c96059cef2..ae068bbddc0d 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -58,7 +58,7 @@ struct btrfs_ordered_sum {
 
 #define BTRFS_ORDERED_COMPRESSED 3 /* writing a zlib compressed extent */
 
-#define BTRFS_ORDERED_PREALLOC 4 /* set when writing to prealloced extent */
+#define BTRFS_ORDERED_PREALLOC 4 /* set when writing to preallocated extent */
 
 #define BTRFS_ORDERED_DIRECT 5 /* set when we're doing DIO with this extent */
 

commit 578def7c50f236432ba140d35bb7ca4ef0a1b20b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Apr 26 15:36:38 2016 +0100

    Btrfs: don't wait for unrelated IO to finish before relocation
    
    Before the relocation process of a block group starts, it sets the block
    group to readonly mode, then flushes all delalloc writes and then finally
    it waits for all ordered extents to complete. This last step includes
    waiting for ordered extents destinated at extents allocated in other block
    groups, making us waste unecessary time.
    
    So improve this by waiting only for ordered extents that fall into the
    block group's range.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 23c96059cef2..8ef12623d65c 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -197,8 +197,10 @@ int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,
 			   u32 *sum, int len);
-int btrfs_wait_ordered_extents(struct btrfs_root *root, int nr);
-void btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr);
+int btrfs_wait_ordered_extents(struct btrfs_root *root, int nr,
+			       const u64 range_start, const u64 range_len);
+void btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr,
+			      const u64 range_start, const u64 range_len);
 void btrfs_get_logged_extents(struct inode *inode,
 			      struct list_head *logged_list,
 			      const loff_t start,

commit 161c3549b45aeef05451b6822d8aaaf39c7bedce
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Sep 24 16:17:39 2015 -0400

    Btrfs: change how we wait for pending ordered extents
    
    We have a mechanism to make sure we don't lose updates for ordered extents that
    were logged in the transaction that is currently running.  We add the ordered
    extent to a transaction list and then the transaction waits on all the ordered
    extents in that list.  However are substantially large file systems this list
    can be extremely large, and can give us soft lockups, since the ordered extents
    don't remove themselves from the list when they do complete.
    
    To fix this we simply add a counter to the transaction that is incremented any
    time we have a logged extent that needs to be completed in the current
    transaction.  Then when the ordered extent finally completes it decrements the
    per transaction counter and wakes up the transaction if we are the last ones.
    This will eliminate the softlockup.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 7176cc0fe43f..23c96059cef2 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -73,6 +73,8 @@ struct btrfs_ordered_sum {
 
 #define BTRFS_ORDERED_LOGGED 10 /* Set when we've waited on this ordered extent
 				 * in the logging code. */
+#define BTRFS_ORDERED_PENDING 11 /* We are waiting for this ordered extent to
+				  * complete in the current transaction. */
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
 	u64 file_offset;

commit b659ef027792219b590d67a2baf1643a93727d29
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Mar 31 14:16:52 2015 +0100

    Btrfs: avoid syncing log in the fast fsync path when not necessary
    
    Commit 3a8b36f37806 ("Btrfs: fix data loss in the fast fsync path") added
    a performance regression for that causes an unnecessary sync of the log
    trees (fs/subvol and root log trees) when 2 consecutive fsyncs are done
    against a file, without no writes or any metadata updates to the inode in
    between them and if a transaction is committed before the second fsync is
    called.
    
    Huang Ying reported this to lkml (https://lkml.org/lkml/2015/3/18/99)
    after a test sysbench test that measured a -62% decrease of file io
    requests per second for that tests' workload.
    
    The test is:
    
      echo performance > /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
      echo performance > /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
      echo performance > /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
      echo performance > /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
      mkfs -t btrfs /dev/sda2
      mount -t btrfs /dev/sda2 /fs/sda2
      cd /fs/sda2
      for ((i = 0; i < 1024; i++)); do fallocate -l 67108864 testfile.$i; done
      sysbench --test=fileio --max-requests=0 --num-threads=4 --max-time=600 \
        --file-test-mode=rndwr --file-total-size=68719476736 --file-io-mode=sync \
        --file-num=1024 run
    
    A test on kvm guest, running a debug kernel gave me the following results:
    
    Without 3a8b36f378060d:             16.01 reqs/sec
    With 3a8b36f378060d:                 3.39 reqs/sec
    With 3a8b36f378060d and this patch: 16.04 reqs/sec
    
    Reported-by: Huang Ying <ying.huang@intel.com>
    Tested-by: Huang, Ying <ying.huang@intel.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index a82cd7535d3c..7176cc0fe43f 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -188,6 +188,9 @@ btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
 struct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,
 							u64 file_offset,
 							u64 len);
+bool btrfs_have_ordered_extents_in_range(struct inode *inode,
+					 u64 file_offset,
+					 u64 len);
 int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,

commit 0c304304feab8a576ed6ba6ec964255d00d2886e
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon May 25 11:20:22 2015 +0800

    Btrfs: remove csum_bytes_left
    
    After commit 8407f553268a
    ("Btrfs: fix data corruption after fast fsync and writeback error"),
    during wait_ordered_extents(), we wait for ordered extent setting
    BTRFS_ORDERED_IO_DONE or BTRFS_ORDERED_IOERR, at which point we've
    already got checksum information, so we don't need to check
    (csum_bytes_left == 0) in the whole logging path.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index e96cd4ccd805..a82cd7535d3c 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -89,9 +89,6 @@ struct btrfs_ordered_extent {
 	/* number of bytes that still need writing */
 	u64 bytes_left;
 
-	/* number of bytes that still need csumming */
-	u64 csum_bytes_left;
-
 	/*
 	 * the end of the ordered extent which is behind it but
 	 * didn't update disk_i_size. Please see the comment of

commit 0870295b2371673b3563735825ad559409d8cedc
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Nov 13 17:00:35 2014 +0000

    Btrfs: collect only the necessary ordered extents on ranged fsync
    
    Instead of collecting all ordered extents from the inode's ordered tree
    and then wait for all of them to complete, just collect the ones that
    overlap the fsync range.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 0124bffc775f..e96cd4ccd805 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -198,7 +198,9 @@ int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,
 int btrfs_wait_ordered_extents(struct btrfs_root *root, int nr);
 void btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr);
 void btrfs_get_logged_extents(struct inode *inode,
-			      struct list_head *logged_list);
+			      struct list_head *logged_list,
+			      const loff_t start,
+			      const loff_t end);
 void btrfs_put_logged_extents(struct list_head *logged_list);
 void btrfs_submit_logged_extents(struct list_head *logged_list,
 				 struct btrfs_root *log);

commit 50d9aa99bd35c77200e0e3dd7a72274f8304701f
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Nov 21 14:52:38 2014 -0500

    Btrfs: make sure logged extents complete in the current transaction V3
    
    Liu Bo pointed out that my previous fix would lose the generation update in the
    scenario I described.  It is actually much worse than that, we could lose the
    entire extent if we lose power right after the transaction commits.  Consider
    the following
    
    write extent 0-4k
    log extent in log tree
    commit transaction
            < power fail happens here
    ordered extent completes
    
    We would lose the 0-4k extent because it hasn't updated the actual fs tree, and
    the transaction commit will reset the log so it isn't replayed.  If we lose
    power before the transaction commit we are save, otherwise we are not.
    
    Fix this by keeping track of all extents we logged in this transaction.  Then
    when we go to commit the transaction make sure we wait for all of those ordered
    extents to complete before proceeding.  This will make sure that if we lose
    power after the transaction commit we still have our data.  This also fixes the
    problem of the improperly updated extent generation.  Thanks,
    
    cc: stable@vger.kernel.org
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index d81a274d621e..0124bffc775f 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -71,6 +71,8 @@ struct btrfs_ordered_sum {
 				       ordered extent */
 #define BTRFS_ORDERED_TRUNCATED 9 /* Set when we have to truncate an extent */
 
+#define BTRFS_ORDERED_LOGGED 10 /* Set when we've waited on this ordered extent
+				 * in the logging code. */
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
 	u64 file_offset;
@@ -121,6 +123,9 @@ struct btrfs_ordered_extent {
 	/* If we need to wait on this to be done */
 	struct list_head log_list;
 
+	/* If the transaction needs to wait on this ordered extent */
+	struct list_head trans_list;
+
 	/* used to wait for the BTRFS_ORDERED_COMPLETE bit */
 	wait_queue_head_t wait;
 
@@ -197,7 +202,8 @@ void btrfs_get_logged_extents(struct inode *inode,
 void btrfs_put_logged_extents(struct list_head *logged_list);
 void btrfs_submit_logged_extents(struct list_head *logged_list,
 				 struct btrfs_root *log);
-void btrfs_wait_logged_extents(struct btrfs_root *log, u64 transid);
+void btrfs_wait_logged_extents(struct btrfs_trans_handle *trans,
+			       struct btrfs_root *log, u64 transid);
 void btrfs_free_logged_extents(struct btrfs_root *log, u64 transid);
 int __init ordered_data_init(void);
 void ordered_data_exit(void);

commit 8d875f95da43c6a8f18f77869f2ef26e9594fecc
Author: Chris Mason <clm@fb.com>
Date:   Tue Aug 12 10:47:42 2014 -0700

    btrfs: disable strict file flushes for renames and truncates
    
    Truncates and renames are often used to replace old versions of a file
    with new versions.  Applications often expect this to be an atomic
    replacement, even if they haven't done anything to make sure the new
    version is fully on disk.
    
    Btrfs has strict flushing in place to make sure that renaming over an
    old file with a new file will fully flush out the new file before
    allowing the transaction commit with the rename to complete.
    
    This ordering means the commit code needs to be able to lock file pages,
    and there are a few paths in the filesystem where we will try to end a
    transaction with the page lock held.  It's rare, but these things can
    deadlock.
    
    This patch removes the ordered flushes and switches to a best effort
    filemap_flush like ext4 uses. It's not perfect, but it should fix the
    deadlocks.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 246897058efb..d81a274d621e 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -190,11 +190,6 @@ int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,
 			   u32 *sum, int len);
-int btrfs_run_ordered_operations(struct btrfs_trans_handle *trans,
-				 struct btrfs_root *root, int wait);
-void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
-				 struct btrfs_root *root,
-				 struct inode *inode);
 int btrfs_wait_ordered_extents(struct btrfs_root *root, int nr);
 void btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr);
 void btrfs_get_logged_extents(struct inode *inode,

commit d458b0540ebd728b4d6ef47cc5ef0dbfd4dd361a
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:19 2014 +0800

    btrfs: Cleanup the "_struct" suffix in btrfs_workequeue
    
    Since the "_struct" suffix is mainly used for distinguish the differnt
    btrfs_work between the original and the newly created one,
    there is no need using the suffix since all btrfs_workers are changed
    into btrfs_workqueue.
    
    Also this patch fixed some codes whose code style is changed due to the
    too long "_struct" suffix.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 84bb236119fe..246897058efb 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -130,10 +130,10 @@ struct btrfs_ordered_extent {
 	/* a per root list of all the pending ordered extents */
 	struct list_head root_extent_list;
 
-	struct btrfs_work_struct work;
+	struct btrfs_work work;
 
 	struct completion completion;
-	struct btrfs_work_struct flush_work;
+	struct btrfs_work flush_work;
 	struct list_head work_list;
 };
 

commit fccb5d86d8f52161e013025ccf3101d8fab99a32
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:10 2014 +0800

    btrfs: Replace fs_info->endio_* workqueue with btrfs_workqueue.
    
    Replace the fs_info->endio_* workqueues with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index fe9f4dbab09c..84bb236119fe 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -130,7 +130,7 @@ struct btrfs_ordered_extent {
 	/* a per root list of all the pending ordered extents */
 	struct list_head root_extent_list;
 
-	struct btrfs_work work;
+	struct btrfs_work_struct work;
 
 	struct completion completion;
 	struct btrfs_work_struct flush_work;

commit a44903abe9dc23ffa305898368a7a910dbae13c5
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:09 2014 +0800

    btrfs: Replace fs_info->flush_workers with btrfs_workqueue.
    
    Replace the fs_info->submit_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 246897058efb..fe9f4dbab09c 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -133,7 +133,7 @@ struct btrfs_ordered_extent {
 	struct btrfs_work work;
 
 	struct completion completion;
-	struct btrfs_work flush_work;
+	struct btrfs_work_struct flush_work;
 	struct list_head work_list;
 };
 

commit 827463c49f29111efd22148d24c9ca44d648acfa
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 14 20:31:51 2014 +0800

    Btrfs: don't mix the ordered extents of all files together during logging the inodes
    
    There was a problem in the old code:
    If we failed to log the csum, we would free all the ordered extents in the log list
    including those ordered extents that were logged successfully, it would make the
    log committer not to wait for the completion of the ordered extents.
    
    This patch doesn't insert the ordered extents that is about to be logged into
    a global list, instead, we insert them into a local list. If we log the ordered
    extents successfully, we splice them with the global list, or we will throw them
    away, then do full sync. It can also reduce the lock contention and the traverse
    time of list.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 9b0450f7ac20..246897058efb 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -197,7 +197,11 @@ void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				 struct inode *inode);
 int btrfs_wait_ordered_extents(struct btrfs_root *root, int nr);
 void btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr);
-void btrfs_get_logged_extents(struct btrfs_root *log, struct inode *inode);
+void btrfs_get_logged_extents(struct inode *inode,
+			      struct list_head *logged_list);
+void btrfs_put_logged_extents(struct list_head *logged_list);
+void btrfs_submit_logged_extents(struct list_head *logged_list,
+				 struct btrfs_root *log);
 void btrfs_wait_logged_extents(struct btrfs_root *log, u64 transid);
 void btrfs_free_logged_extents(struct btrfs_root *log, u64 transid);
 int __init ordered_data_init(void);

commit b02441999efcc6152b87cd58e7970bb7843f76cf
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Mon Nov 4 23:13:25 2013 +0800

    Btrfs: don't wait for the completion of all the ordered extents
    
    It is very likely that there are lots of ordered extents in the filesytem,
    if we wait for the completion of all of them when we want to reclaim some
    space for the metadata space reservation, we would be blocked for a long
    time. The performance would drop down suddenly for a long time.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 3982db1c1b36..9b0450f7ac20 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -195,8 +195,8 @@ int btrfs_run_ordered_operations(struct btrfs_trans_handle *trans,
 void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct inode *inode);
-void btrfs_wait_ordered_extents(struct btrfs_root *root);
-void btrfs_wait_all_ordered_extents(struct btrfs_fs_info *fs_info);
+int btrfs_wait_ordered_extents(struct btrfs_root *root, int nr);
+void btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, int nr);
 void btrfs_get_logged_extents(struct btrfs_root *log, struct inode *inode);
 void btrfs_wait_logged_extents(struct btrfs_root *log, u64 transid);
 void btrfs_free_logged_extents(struct btrfs_root *log, u64 transid);

commit 0ef8b726075aa6931ddf1c16f5bae043eef184f9
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Oct 25 16:13:35 2013 -0400

    Btrfs: return an error from btrfs_wait_ordered_range
    
    I noticed that if the free space cache has an error writing out it's data it
    won't actually error out, it will just carry on.  This is because it doesn't
    check the return value of btrfs_wait_ordered_range, which didn't actually return
    anything.  So fix this in order to keep us from making free space cache look
    valid when it really isnt.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 0c0b35612d7a..3982db1c1b36 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -180,7 +180,7 @@ struct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,
 							 u64 file_offset);
 void btrfs_start_ordered_extent(struct inode *inode,
 				struct btrfs_ordered_extent *entry, int wait);
-void btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
+int btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
 struct btrfs_ordered_extent *
 btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
 struct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,

commit f0de181c9b48a397c5a2fbe63dcdd2a26a872695
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Sep 17 10:55:51 2013 -0400

    Btrfs: kill delay_iput arg to the wait_ordered functions
    
    This is a left over of how we used to wait for ordered extents, which was to
    grab the inode and then run filemap flush on it.  However if we have an ordered
    extent then we already are holding a ref on the inode, and we just use
    btrfs_start_ordered_extent anyway, so there is no reason to have an extra ref on
    the inode to start work on the ordered extent.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index d9a5aa097b4f..0c0b35612d7a 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -195,9 +195,8 @@ int btrfs_run_ordered_operations(struct btrfs_trans_handle *trans,
 void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct inode *inode);
-void btrfs_wait_ordered_extents(struct btrfs_root *root, int delay_iput);
-void btrfs_wait_all_ordered_extents(struct btrfs_fs_info *fs_info,
-				    int delay_iput);
+void btrfs_wait_ordered_extents(struct btrfs_root *root);
+void btrfs_wait_all_ordered_extents(struct btrfs_fs_info *fs_info);
 void btrfs_get_logged_extents(struct btrfs_root *log, struct inode *inode);
 void btrfs_wait_logged_extents(struct btrfs_root *log, u64 transid);
 void btrfs_free_logged_extents(struct btrfs_root *log, u64 transid);

commit 77cef2ec5484564eca6bd12a2b4a1e88fd766fbc
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Aug 29 13:57:21 2013 -0400

    Btrfs: allow partial ordered extent completion
    
    We currently have this problem where you can truncate pages that have not yet
    been written for an ordered extent.  We do this because the truncate will be
    coming behind to clean us up anyway so what's the harm right?  Well if truncate
    fails for whatever reason we leave an orphan item around for the file to be
    cleaned up later.  But if the user goes and truncates up the file and tries to
    read from the area that had been discarded previously they will get a csum error
    because we never actually wrote that data out.
    
    This patch fixes this by allowing us to either discard the ordered extent
    completely, by which I mean we just free up the space we had allocated and not
    add the file extent, or adjust the length of the file extent we write.  We do
    this by setting the length we truncated down to in the ordered extent, and then
    we set the file extent length and ram bytes to this length.  The total disk
    space stays unchanged since we may be compressed and we can't just chop off the
    disk space, but at least this way the file extent only points to the valid data.
    Then when the file extent is free'd the extent and csums will be freed normally.
    
    This patch is needed for the next series which will give us more graceful
    recovery of failed truncates.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 68844d59ee6f..d9a5aa097b4f 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -69,6 +69,7 @@ struct btrfs_ordered_sum {
 				       * the isize. */
 #define BTRFS_ORDERED_LOGGED_CSUM 8 /* We've logged the csums on this ordered
 				       ordered extent */
+#define BTRFS_ORDERED_TRUNCATED 9 /* Set when we have to truncate an extent */
 
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
@@ -96,6 +97,12 @@ struct btrfs_ordered_extent {
 	 */
 	u64 outstanding_isize;
 
+	/*
+	 * If we get truncated we need to adjust the file extent we enter for
+	 * this ordered extent so that we do not expose stale data.
+	 */
+	u64 truncated_len;
+
 	/* flags (described above) */
 	unsigned long flags;
 

commit f51a4a1826ff810eb9c00cadff8978b028c40756
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Jun 19 10:36:09 2013 +0800

    Btrfs: remove btrfs_sector_sum structure
    
    Using the structure btrfs_sector_sum to keep the checksum value is
    unnecessary, because the extents that btrfs_sector_sum points to are
    continuous, we can find out the expected checksums by btrfs_ordered_sum's
    bytenr and the offset, so we can remove btrfs_sector_sum's bytenr. After
    removing bytenr, there is only one member in the structure, so it makes
    no sense to keep the structure, just remove it, and use a u32 array to
    store the checksum value.
    
    By this change, we don't use the while loop to get the checksums one by
    one. Now, we can get several checksum value at one time, it improved the
    performance by ~74% on my SSD (31MB/s -> 54MB/s).
    
    test command:
     # dd if=/dev/zero of=/mnt/btrfs/file0 bs=1M count=1024 oflag=sync
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index d082d43e00e5..68844d59ee6f 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -26,18 +26,6 @@ struct btrfs_ordered_inode_tree {
 	struct rb_node *last;
 };
 
-/*
- * these are used to collect checksums done just before bios submission.
- * They are attached via a list into the ordered extent, and
- * checksum items are inserted into the tree after all the blocks in
- * the ordered extent are on disk
- */
-struct btrfs_sector_sum {
-	/* bytenr on disk */
-	u64 bytenr;
-	u32 sum;
-};
-
 struct btrfs_ordered_sum {
 	/* bytenr is the start of this extent on disk */
 	u64 bytenr;
@@ -45,10 +33,10 @@ struct btrfs_ordered_sum {
 	/*
 	 * this is the length in bytes covered by the sums array below.
 	 */
-	unsigned long len;
+	int len;
 	struct list_head list;
-	/* last field is a variable length array of btrfs_sector_sums */
-	struct btrfs_sector_sum sums[];
+	/* last field is a variable length array of csums */
+	u32 sums[];
 };
 
 /*
@@ -149,11 +137,8 @@ struct btrfs_ordered_extent {
 static inline int btrfs_ordered_sum_size(struct btrfs_root *root,
 					 unsigned long bytes)
 {
-	unsigned long num_sectors = (bytes + root->sectorsize - 1) /
-		root->sectorsize;
-	num_sectors++;
-	return sizeof(struct btrfs_ordered_sum) +
-		num_sectors * sizeof(struct btrfs_sector_sum);
+	int num_sectors = (int)DIV_ROUND_UP(bytes, root->sectorsize);
+	return sizeof(struct btrfs_ordered_sum) + num_sectors * sizeof(u32);
 }
 
 static inline void

commit 199c2a9c3d1389db7f7a211e64f6809d352ce5f6
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:23 2013 +0000

    Btrfs: introduce per-subvolume ordered extent list
    
    The reason we introduce per-subvolume ordered extent list is the same
    as the per-subvolume delalloc inode list.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 58b0e3b0ebad..d082d43e00e5 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -204,6 +204,8 @@ void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct inode *inode);
 void btrfs_wait_ordered_extents(struct btrfs_root *root, int delay_iput);
+void btrfs_wait_all_ordered_extents(struct btrfs_fs_info *fs_info,
+				    int delay_iput);
 void btrfs_get_logged_extents(struct btrfs_root *log, struct inode *inode);
 void btrfs_wait_logged_extents(struct btrfs_root *log, u64 transid);
 void btrfs_free_logged_extents(struct btrfs_root *log, u64 transid);

commit e4100d987b2437596ebcf11809022b79507f3db1
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Apr 5 07:20:56 2013 +0000

    Btrfs: improve the performance of the csums lookup
    
    It is very likely that there are several blocks in bio, it is very
    inefficient if we get their csums one by one. This patch improves
    this problem by getting the csums in batch.
    
    According to the result of the following test, the execute time of
    __btrfs_lookup_bio_sums() is down by ~28%(300us -> 217us).
    
     # dd if=<mnt>/file of=/dev/null bs=1M count=1024
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 8eadfe406cdd..58b0e3b0ebad 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -196,7 +196,8 @@ struct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,
 							u64 len);
 int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
-int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr, u32 *sum);
+int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,
+			   u32 *sum, int len);
 int btrfs_run_ordered_operations(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root, int wait);
 void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,

commit b2c6b3e0611c58fbeb6b9c0892b6249f7bdfaf6b
Merge: 19f949f52599 272d26d0ad8c
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Feb 20 14:05:45 2013 -0500

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/josef/btrfs-next into for-linus-3.9
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>
    
    Conflicts:
            fs/btrfs/disk-io.c

commit 569e0f358c0c37f6733702d4a5d2c412860f7169
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Feb 13 11:09:14 2013 -0500

    Btrfs: place ordered operations on a per transaction list
    
    Miao made the ordered operations stuff run async, which introduced a
    deadlock where we could get somebody (sync) racing in and committing the
    transaction while a commit was already happening.  The new committer would
    try and flush ordered operations which would hang waiting for the commit to
    finish because it is done asynchronously and no longer inherits the callers
    trans handle.  To fix this we need to make the ordered operations list a per
    transaction list.  We can get new inodes added to the ordered operation list
    by truncating them and then having another process writing to them, so this
    makes it so that anybody trying to add an ordered operation _must_ start a
    transaction in order to add itself to the list, which will keep new inodes
    from getting added to the ordered operations list after we start committing.
    This should fix the deadlock and also keeps us from doing a lot more work
    than we need to during commit.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index d523dbd2314d..267ac99095f6 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -197,7 +197,8 @@ struct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,
 int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr, u32 *sum);
-int btrfs_run_ordered_operations(struct btrfs_root *root, int wait);
+int btrfs_run_ordered_operations(struct btrfs_trans_handle *trans,
+				 struct btrfs_root *root, int wait);
 void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct inode *inode);

commit 2ab28f322f9896782da904f5942f3873432addc8
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Oct 12 15:27:49 2012 -0400

    Btrfs: wait on ordered extents at the last possible moment
    
    Since we don't actually copy the extent information from the source tree in
    the fast case we don't need to wait for ordered io to be completed in order
    to fsync, we just need to wait for the io to be completed.  So when we're
    logging our file just attach all of the ordered extents to the log, and then
    when the log syncs just wait for IO_DONE on the ordered extents and then
    write the super.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index efc7c2930c17..d523dbd2314d 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -79,6 +79,8 @@ struct btrfs_ordered_sum {
 #define BTRFS_ORDERED_UPDATED_ISIZE 7 /* indicates wether this ordered extent
 				       * has done its due diligence in updating
 				       * the isize. */
+#define BTRFS_ORDERED_LOGGED_CSUM 8 /* We've logged the csums on this ordered
+				       ordered extent */
 
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
@@ -96,6 +98,9 @@ struct btrfs_ordered_extent {
 	/* number of bytes that still need writing */
 	u64 bytes_left;
 
+	/* number of bytes that still need csumming */
+	u64 csum_bytes_left;
+
 	/*
 	 * the end of the ordered extent which is behind it but
 	 * didn't update disk_i_size. Please see the comment of
@@ -118,6 +123,9 @@ struct btrfs_ordered_extent {
 	/* list of checksums for insertion when the extent io is done */
 	struct list_head list;
 
+	/* If we need to wait on this to be done */
+	struct list_head log_list;
+
 	/* used to wait for the BTRFS_ORDERED_COMPLETE bit */
 	wait_queue_head_t wait;
 
@@ -194,6 +202,9 @@ void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct inode *inode);
 void btrfs_wait_ordered_extents(struct btrfs_root *root, int delay_iput);
+void btrfs_get_logged_extents(struct btrfs_root *log, struct inode *inode);
+void btrfs_wait_logged_extents(struct btrfs_root *log, u64 transid);
+void btrfs_free_logged_extents(struct btrfs_root *log, u64 transid);
 int __init ordered_data_init(void);
 void ordered_data_exit(void);
 #endif

commit a22180d2666c018f4fef6818074d78bb76ff2bda
Merge: 2d4dce007044 213490b30177
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 18 09:42:05 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs update from Chris Mason:
     "A big set of fixes and features.
    
      In terms of line count, most of the code comes from Stefan, who added
      the ability to replace a single drive in place.  This is different
      from how btrfs normally replaces drives, and is much much much faster.
    
      Josef is plowing through our synchronous write performance.  This pull
      request does not include the DIO_OWN_WAITING patch that was discussed
      on the list, but it has a number of other improvements to cut down our
      latencies and CPU time during fsync/O_DIRECT writes.
    
      Miao Xie has a big series of fixes and is spreading out ordered
      operations over more CPUs.  This improves performance and reduces
      contention.
    
      I've put in fixes for error handling around hash collisions.  These
      are going back to individual stable kernels as I test against them.
    
      Otherwise we have a lot of fixes and cleanups, thanks everyone!
      raid5/6 is being rebased against the device replacement code.  I'll
      have it posted this Friday along with a nice series of benchmarks."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (115 commits)
      Btrfs: fix a bug of per-file nocow
      Btrfs: fix hash overflow handling
      Btrfs: don't take inode delalloc mutex if we're a free space inode
      Btrfs: fix autodefrag and umount lockup
      Btrfs: fix permissions of empty files not affected by umask
      Btrfs: put raid properties into global table
      Btrfs: fix BUG() in scrub when first superblock reading gives EIO
      Btrfs: do not call file_update_time in aio_write
      Btrfs: only unlock and relock if we have to
      Btrfs: use tokens where we can in the tree log
      Btrfs: optimize leaf_space_used
      Btrfs: don't memset new tokens
      Btrfs: only clear dirty on the buffer if it is marked as dirty
      Btrfs: move checks in set_page_dirty under DEBUG
      Btrfs: log changed inodes based on the extent map tree
      Btrfs: add path->really_keep_locks
      Btrfs: do not mark ems as prealloc if we are writing to them
      Btrfs: keep track of the extents original block length
      Btrfs: inline csums if we're fsyncing
      Btrfs: don't bother copying if we're only logging the inode
      ...

commit 9afab8820bb8b55af669b199597d6716e04d1ba8
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Oct 25 09:41:36 2012 +0000

    Btrfs: make ordered extent be flushed by multi-task
    
    Though the process of the ordered extents is a bit different with the delalloc inode
    flush, but we can see it as a subset of the delalloc inode flush, so we also handle
    them by flush workers.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index e8dcec635112..efc7c2930c17 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -128,8 +128,11 @@ struct btrfs_ordered_extent {
 	struct list_head root_extent_list;
 
 	struct btrfs_work work;
-};
 
+	struct completion completion;
+	struct btrfs_work flush_work;
+	struct list_head work_list;
+};
 
 /*
  * calculates the total size you need to allocate for an ordered sum

commit 25287e0a16c0ad068aa89ab01aea6c699b31ec12
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Oct 25 09:31:03 2012 +0000

    Btrfs: make ordered operations be handled by multi-task
    
    The process of the ordered operations is similar to the delalloc inode flush, so
    we handle them by flush workers.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index dd27a0b46a37..e8dcec635112 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -186,7 +186,7 @@ struct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,
 int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr, u32 *sum);
-void btrfs_run_ordered_operations(struct btrfs_root *root, int wait);
+int btrfs_run_ordered_operations(struct btrfs_root *root, int wait);
 void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct inode *inode);

commit 48fc7f7e787dd65ffe88521bce31f4062ba273eb
Author: Adam Buchbinder <adam.buchbinder@gmail.com>
Date:   Wed Sep 19 21:48:00 2012 -0400

    Fix misspellings of "whether" in comments.
    
    "Whether" is misspelled in various comments across the tree; this
    fixes them. No code changes.
    
    Signed-off-by: Adam Buchbinder <adam.buchbinder@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index dd27a0b46a37..853fc7beedfa 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -76,7 +76,7 @@ struct btrfs_ordered_sum {
 
 #define BTRFS_ORDERED_IOERR 6 /* We had an io error when writing this out */
 
-#define BTRFS_ORDERED_UPDATED_ISIZE 7 /* indicates wether this ordered extent
+#define BTRFS_ORDERED_UPDATED_ISIZE 7 /* indicates whether this ordered extent
 				       * has done its due diligence in updating
 				       * the isize. */
 

commit 6bbe3a9c805fcb8cd8d396dafd32078181a7cdd5
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Sep 14 02:58:07 2012 -0600

    Btrfs: kill obsolete arguments in btrfs_wait_ordered_extents
    
    nocow_only is now an obsolete argument.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index d1ddaeff1356..dd27a0b46a37 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -190,8 +190,7 @@ void btrfs_run_ordered_operations(struct btrfs_root *root, int wait);
 void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root,
 				 struct inode *inode);
-void btrfs_wait_ordered_extents(struct btrfs_root *root,
-				int nocow_only, int delay_iput);
+void btrfs_wait_ordered_extents(struct btrfs_root *root, int delay_iput);
 int __init ordered_data_init(void);
 void ordered_data_exit(void);
 #endif

commit 6352b91da1a2108bb8cc5115e8714f90d706f15f
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Sep 6 04:01:51 2012 -0600

    Btrfs: use a slab for ordered extents allocation
    
    The ordered extent allocation is in the fast path of the IO, so use a slab
    to improve the speed of the allocation.
    
     "Size of the struct is 280, so this will fall into the size-512 bucket,
      giving 8 objects per page, while own slab will pack 14 objects into a page.
    
      Another benefit I see is to check for leaked objects when the module is
      removed (and the cache destroy takes place)."
                                                    -- David Sterba
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index c2443a431ca5..d1ddaeff1356 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -192,4 +192,6 @@ void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				 struct inode *inode);
 void btrfs_wait_ordered_extents(struct btrfs_root *root,
 				int nocow_only, int delay_iput);
+int __init ordered_data_init(void);
+void ordered_data_exit(void);
 #endif

commit b9a8cc5bef963b76c5b6c3016b7e91988a3e758b
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Sep 6 04:01:21 2012 -0600

    Btrfs: fix file extent discount problem in the, snapshot
    
    If a snapshot is created while we are writing some data into the file,
    the i_size of the corresponding file in the snapshot will be wrong, it will
    be beyond the end of the last file extent. And btrfsck will report:
      root 256 inode 257 errors 100
    
    Steps to reproduce:
     # mkfs.btrfs <partition>
     # mount <partition> <mnt>
     # cd <mnt>
     # dd if=/dev/zero of=tmpfile bs=4M count=1024 &
     # for ((i=0; i<4; i++))
     > do
     > btrfs sub snap . $i
     > done
    
    This because the algorithm of disk_i_size update is wrong. Though there are
    some ordered extents behind the current one which we use to update disk_i_size,
    it doesn't mean those extents will be dealt with in the same transaction. So
    We shouldn't use the offset of those extents to update disk_i_size. Or we will
    get the wrong i_size in the snapshot.
    
    We fix this problem by recording the max real i_size. If we find there is a
    ordered extent which is in front of the current one and doesn't complete, we
    will record the end of the current one into that ordered extent. Surely, if
    the current extent holds the end of other extent(it must be greater than
    the current one because it is behind the current one), we will record the
    number that the current extent holds. In this way, we can exclude the ordered
    extents that may not be dealth with in the same transaction, and be easy to
    know the real disk_i_size.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index e03c560d2997..c2443a431ca5 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -96,6 +96,13 @@ struct btrfs_ordered_extent {
 	/* number of bytes that still need writing */
 	u64 bytes_left;
 
+	/*
+	 * the end of the ordered extent which is behind it but
+	 * didn't update disk_i_size. Please see the comment of
+	 * btrfs_ordered_update_i_size();
+	 */
+	u64 outstanding_isize;
+
 	/* flags (described above) */
 	unsigned long flags;
 

commit 5fd02043553b02867b29de1ac9fff2ec16b84def
Author: Josef Bacik <josef@redhat.com>
Date:   Wed May 2 14:00:54 2012 -0400

    Btrfs: finish ordered extents in their own thread
    
    We noticed that the ordered extent completion doesn't really rely on having
    a page and that it could be done independantly of ending the writeback on a
    page.  This patch makes us not do the threaded endio stuff for normal
    buffered writes and direct writes so we can end page writeback as soon as
    possible (in irq context) and only start threads to do the ordered work when
    it is actually done.  Compression needs to be reworked some to take
    advantage of this as well, but atm it has to do a find_get_page in its endio
    handler so it must be done in its own thread.  This makes direct writes
    quite a bit faster.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index c355ad4dc1a6..e03c560d2997 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -74,6 +74,12 @@ struct btrfs_ordered_sum {
 
 #define BTRFS_ORDERED_DIRECT 5 /* set when we're doing DIO with this extent */
 
+#define BTRFS_ORDERED_IOERR 6 /* We had an io error when writing this out */
+
+#define BTRFS_ORDERED_UPDATED_ISIZE 7 /* indicates wether this ordered extent
+				       * has done its due diligence in updating
+				       * the isize. */
+
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
 	u64 file_offset;
@@ -113,6 +119,8 @@ struct btrfs_ordered_extent {
 
 	/* a per root list of all the pending ordered extents */
 	struct list_head root_extent_list;
+
+	struct btrfs_work work;
 };
 
 
@@ -143,10 +151,11 @@ void btrfs_remove_ordered_extent(struct inode *inode,
 				struct btrfs_ordered_extent *entry);
 int btrfs_dec_test_ordered_pending(struct inode *inode,
 				   struct btrfs_ordered_extent **cached,
-				   u64 file_offset, u64 io_size);
+				   u64 file_offset, u64 io_size, int uptodate);
 int btrfs_dec_test_first_ordered_pending(struct inode *inode,
 				   struct btrfs_ordered_extent **cached,
-				   u64 *file_offset, u64 io_size);
+				   u64 *file_offset, u64 io_size,
+				   int uptodate);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
 			     u64 start, u64 len, u64 disk_len, int type);
 int btrfs_add_ordered_extent_dio(struct inode *inode, u64 file_offset,

commit 143bede527b054a271053f41bfaca2b57baa9408
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:56:26 2012 +0100

    btrfs: return void in functions without error conditions
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index ff1f69aa1883..c355ad4dc1a6 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -138,8 +138,8 @@ btrfs_ordered_inode_tree_init(struct btrfs_ordered_inode_tree *t)
 	t->last = NULL;
 }
 
-int btrfs_put_ordered_extent(struct btrfs_ordered_extent *entry);
-int btrfs_remove_ordered_extent(struct inode *inode,
+void btrfs_put_ordered_extent(struct btrfs_ordered_extent *entry);
+void btrfs_remove_ordered_extent(struct inode *inode,
 				struct btrfs_ordered_extent *entry);
 int btrfs_dec_test_ordered_pending(struct inode *inode,
 				   struct btrfs_ordered_extent **cached,
@@ -154,14 +154,14 @@ int btrfs_add_ordered_extent_dio(struct inode *inode, u64 file_offset,
 int btrfs_add_ordered_extent_compress(struct inode *inode, u64 file_offset,
 				      u64 start, u64 len, u64 disk_len,
 				      int type, int compress_type);
-int btrfs_add_ordered_sum(struct inode *inode,
-			  struct btrfs_ordered_extent *entry,
-			  struct btrfs_ordered_sum *sum);
+void btrfs_add_ordered_sum(struct inode *inode,
+			   struct btrfs_ordered_extent *entry,
+			   struct btrfs_ordered_sum *sum);
 struct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,
 							 u64 file_offset);
 void btrfs_start_ordered_extent(struct inode *inode,
 				struct btrfs_ordered_extent *entry, int wait);
-int btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
+void btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
 struct btrfs_ordered_extent *
 btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
 struct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,
@@ -170,10 +170,10 @@ struct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,
 int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr, u32 *sum);
-int btrfs_run_ordered_operations(struct btrfs_root *root, int wait);
-int btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root,
-				struct inode *inode);
-int btrfs_wait_ordered_extents(struct btrfs_root *root,
-			       int nocow_only, int delay_iput);
+void btrfs_run_ordered_operations(struct btrfs_root *root, int wait);
+void btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
+				 struct btrfs_root *root,
+				 struct inode *inode);
+void btrfs_wait_ordered_extents(struct btrfs_root *root,
+				int nocow_only, int delay_iput);
 #endif

commit 261507a02ccba9afda919852263b6bc1581ce1ef
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Dec 17 14:21:50 2010 +0800

    btrfs: Allow to add new compression algorithm
    
    Make the code aware of compression type, instead of always assuming
    zlib compression.
    
    Also make the zlib workspace function as common code for all
    compression types.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 61dca83119dd..ff1f69aa1883 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -68,7 +68,7 @@ struct btrfs_ordered_sum {
 
 #define BTRFS_ORDERED_NOCOW 2 /* set when we want to write in place */
 
-#define BTRFS_ORDERED_COMPRESSED 3 /* writing a compressed extent */
+#define BTRFS_ORDERED_COMPRESSED 3 /* writing a zlib compressed extent */
 
 #define BTRFS_ORDERED_PREALLOC 4 /* set when writing to prealloced extent */
 
@@ -93,6 +93,9 @@ struct btrfs_ordered_extent {
 	/* flags (described above) */
 	unsigned long flags;
 
+	/* compression algorithm */
+	int compress_type;
+
 	/* reference count */
 	atomic_t refs;
 
@@ -148,6 +151,9 @@ int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
 			     u64 start, u64 len, u64 disk_len, int type);
 int btrfs_add_ordered_extent_dio(struct inode *inode, u64 file_offset,
 				 u64 start, u64 len, u64 disk_len, int type);
+int btrfs_add_ordered_extent_compress(struct inode *inode, u64 file_offset,
+				      u64 start, u64 len, u64 disk_len,
+				      int type, int compress_type);
 int btrfs_add_ordered_sum(struct inode *inode,
 			  struct btrfs_ordered_extent *entry,
 			  struct btrfs_ordered_sum *sum);

commit 163cf09c2a0ee5cac6285f9347975bd1e97725da
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Nov 28 19:56:33 2010 -0500

    Btrfs: deal with DIO bios that span more than one ordered extent
    
    The new DIO bio splitting code has problems when the bio
    spans more than one ordered extent.  This will happen as the
    generic DIO code merges our get_blocks calls together into
    a bigger single bio.
    
    This fixes things by walking forward in the ordered extent
    code finding all the overlapping ordered extents and completing them
    all at once.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 8ac365492a3f..61dca83119dd 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -141,6 +141,9 @@ int btrfs_remove_ordered_extent(struct inode *inode,
 int btrfs_dec_test_ordered_pending(struct inode *inode,
 				   struct btrfs_ordered_extent **cached,
 				   u64 file_offset, u64 io_size);
+int btrfs_dec_test_first_ordered_pending(struct inode *inode,
+				   struct btrfs_ordered_extent **cached,
+				   u64 *file_offset, u64 io_size);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
 			     u64 start, u64 len, u64 disk_len, int type);
 int btrfs_add_ordered_extent_dio(struct inode *inode, u64 file_offset,

commit 4b46fce23349bfca781a32e2707a18328ca5ae22
Author: Josef Bacik <josef@redhat.com>
Date:   Sun May 23 11:00:55 2010 -0400

    Btrfs: add basic DIO read/write support
    
    This provides basic DIO support for reading and writing.  It does not do the
    work to recover from mismatching checksums, that will come later.  A few design
    changes have been made from Jim's code (sorry Jim!)
    
    1) Use the generic direct-io code.  Jim originally re-wrote all the generic DIO
    code in order to account for all of BTRFS's oddities, but thanks to that work it
    seems like the best bet is to just ignore compression and such and just opt to
    fallback on buffered IO.
    
    2) Fallback on buffered IO for compressed or inline extents.  Jim's code did
    it's own buffering to make dio with compressed extents work.  Now we just
    fallback onto normal buffered IO.
    
    3) Use ordered extents for the writes so that all of the
    
    lock_extent()
    lookup_ordered()
    
    type checks continue to work.
    
    4) Do the lock_extent() lookup_ordered() loop in readpage so we don't race with
    DIO writes.
    
    I've tested this with fsx and everything works great.  This patch depends on my
    dio and filemap.c patches to work.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index c82f76a9f040..8ac365492a3f 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -72,6 +72,8 @@ struct btrfs_ordered_sum {
 
 #define BTRFS_ORDERED_PREALLOC 4 /* set when writing to prealloced extent */
 
+#define BTRFS_ORDERED_DIRECT 5 /* set when we're doing DIO with this extent */
+
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
 	u64 file_offset;
@@ -140,7 +142,9 @@ int btrfs_dec_test_ordered_pending(struct inode *inode,
 				   struct btrfs_ordered_extent **cached,
 				   u64 file_offset, u64 io_size);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
-			     u64 start, u64 len, u64 disk_len, int tyep);
+			     u64 start, u64 len, u64 disk_len, int type);
+int btrfs_add_ordered_extent_dio(struct inode *inode, u64 file_offset,
+				 u64 start, u64 len, u64 disk_len, int type);
 int btrfs_add_ordered_sum(struct inode *inode,
 			  struct btrfs_ordered_extent *entry,
 			  struct btrfs_ordered_sum *sum);
@@ -151,6 +155,9 @@ void btrfs_start_ordered_extent(struct inode *inode,
 int btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
 struct btrfs_ordered_extent *
 btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
+struct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,
+							u64 file_offset,
+							u64 len);
 int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr, u32 *sum);

commit 5a1a3df1f6c86926cfe8657e6f9b4b4c2f467d60
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Feb 2 20:51:14 2010 +0000

    Btrfs: cache ordered extent when completing io
    
    When finishing io we run btrfs_dec_test_ordered_pending, and then immediately
    run btrfs_lookup_ordered_extent, but btrfs_dec_test_ordered_pending does that
    already, so we're searching twice when we don't have to.  This patch lets us
    pass a btrfs_ordered_extent in to btrfs_dec_test_ordered_pending so if we do
    complete io on that ordered extent we can just use the one we found then instead
    of having to do another btrfs_lookup_ordered_extent.  This made my fio job with
    the other patch go from 24 mb/s to 29 mb/s.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index bfbcebbb0adc..c82f76a9f040 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -137,7 +137,8 @@ int btrfs_put_ordered_extent(struct btrfs_ordered_extent *entry);
 int btrfs_remove_ordered_extent(struct inode *inode,
 				struct btrfs_ordered_extent *entry);
 int btrfs_dec_test_ordered_pending(struct inode *inode,
-				       u64 file_offset, u64 io_size);
+				   struct btrfs_ordered_extent **cached,
+				   u64 file_offset, u64 io_size);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
 			     u64 start, u64 len, u64 disk_len, int tyep);
 int btrfs_add_ordered_sum(struct inode *inode,

commit 49958fd7dbb83cd4d65179d025940e01fe1fbacd
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Feb 2 21:48:28 2010 +0000

    Btrfs: change the ordered tree to use a spinlock instead of a mutex
    
    The ordered tree used to need a mutex, but currently all we use it for is to
    protect the rb_tree, and a spin_lock is just fine for that.  Using a spin_lock
    instead makes dbench run a little faster, 58 mb/s instead of 51 mb/s, and have
    less latency, 3445.138 ms instead of 3820.633 ms.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 9116c6d0c5a9..bfbcebbb0adc 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -21,7 +21,7 @@
 
 /* one of these per inode */
 struct btrfs_ordered_inode_tree {
-	struct mutex mutex;
+	spinlock_t lock;
 	struct rb_root tree;
 	struct rb_node *last;
 };
@@ -128,7 +128,7 @@ static inline int btrfs_ordered_sum_size(struct btrfs_root *root,
 static inline void
 btrfs_ordered_inode_tree_init(struct btrfs_ordered_inode_tree *t)
 {
-	mutex_init(&t->mutex);
+	spin_lock_init(&t->lock);
 	t->tree = RB_ROOT;
 	t->last = NULL;
 }

commit 6bef4d317193d3badbbfa3f3c593758ace84a629
Author: Eric Paris <eparis@redhat.com>
Date:   Tue Feb 23 19:43:04 2010 +0000

    Btrfs: use RB_ROOT to intialize rb_trees instead of setting rb_node to NULL
    
    btrfs inialize rb trees in quite a number of places by settin rb_node =
    NULL;  The problem with this is that 17d9ddc72fb8bba0d4f678 in the
    linux-next tree adds a new field to that struct which needs to be NULL for
    the new rbtree library code to work properly.  This patch uses RB_ROOT as
    the intializer so all of the relevant fields will be NULL'd.  Without the
    patch I get a panic.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 1fe1282ef47c..9116c6d0c5a9 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -129,7 +129,7 @@ static inline void
 btrfs_ordered_inode_tree_init(struct btrfs_ordered_inode_tree *t)
 {
 	mutex_init(&t->mutex);
-	t->tree.rb_node = NULL;
+	t->tree = RB_ROOT;
 	t->last = NULL;
 }
 

commit 24bbcf0442ee04660a5a030efdbb6d03f1c275cb
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:36:34 2009 +0000

    Btrfs: Add delayed iput
    
    iput() can trigger new transactions if we are dropping the
    final reference, so calling it in btrfs_commit_transaction
    may end up deadlock. This patch adds delayed iput to avoid
    the issue.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 4fa20398aec1..1fe1282ef47c 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -153,9 +153,10 @@ btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
 int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr, u32 *sum);
-int btrfs_wait_ordered_extents(struct btrfs_root *root, int nocow_only);
 int btrfs_run_ordered_operations(struct btrfs_root *root, int wait);
 int btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root,
 				struct inode *inode);
+int btrfs_wait_ordered_extents(struct btrfs_root *root,
+			       int nocow_only, int delay_iput);
 #endif

commit c216775458a2ee345d9412a2770c2916acfb5d30
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:34:21 2009 +0000

    Btrfs: Fix disk_i_size update corner case
    
    There are some cases file extents are inserted without involving
    ordered struct. In these cases, we update disk_i_size directly,
    without checking pending ordered extent and DELALLOC bit. This
    patch extends btrfs_ordered_update_i_size() to handle these cases.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index f82e87488ca8..4fa20398aec1 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -150,7 +150,7 @@ void btrfs_start_ordered_extent(struct inode *inode,
 int btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
 struct btrfs_ordered_extent *
 btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
-int btrfs_ordered_update_i_size(struct inode *inode,
+int btrfs_ordered_update_i_size(struct inode *inode, u64 offset,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr, u32 *sum);
 int btrfs_wait_ordered_extents(struct btrfs_root *root, int nocow_only);

commit 8aa38c31b7659e338fee4d9af4c3805acbd9806f
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Oct 1 12:58:30 2009 -0400

    Btrfs: remove duplicates of filemap_ helpers
    
    Use filemap_fdatawrite_range and filemap_fdatawait_range instead of
    local copies of the functions.  For filemap_fdatawait_range that
    also means replacing the awkward old wait_on_page_writeback_range
    calling convention with the regular filemap byte offsets.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 993a7ea45c70..f82e87488ca8 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -153,10 +153,6 @@ btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
 int btrfs_ordered_update_i_size(struct inode *inode,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr, u32 *sum);
-int btrfs_wait_on_page_writeback_range(struct address_space *mapping,
-				       pgoff_t start, pgoff_t end);
-int btrfs_fdatawrite_range(struct address_space *mapping, loff_t start,
-			   loff_t end, int sync_mode);
 int btrfs_wait_ordered_extents(struct btrfs_root *root, int nocow_only);
 int btrfs_run_ordered_operations(struct btrfs_root *root, int wait);
 int btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,

commit 8b62b72b26bcd72082c4a69d179dd906bcc22200
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Sep 2 16:53:46 2009 -0400

    Btrfs: Use PagePrivate2 to track pages in the data=ordered code.
    
    Btrfs writes go through delalloc to the data=ordered code.  This
    makes sure that all of the data is on disk before the metadata
    that references it.  The tracking means that we have to make sure
    each page in an extent is fully written before we add that extent into
    the on-disk btree.
    
    This was done in the past by setting the EXTENT_ORDERED bit for the
    range of an extent when it was added to the data=ordered code, and then
    clearing the EXTENT_ORDERED bit in the extent state tree as each page
    finished IO.
    
    One of the reasons we had to do this was because sometimes pages are
    magically dirtied without page_mkwrite being called.  The EXTENT_ORDERED
    bit is checked at writepage time, and if it isn't there, our page become
    dirty without going through the proper path.
    
    These bit operations make for a number of rbtree searches for each page,
    and can cause considerable lock contention.
    
    This commit switches from the EXTENT_ORDERED bit to use PagePrivate2.
    As pages go into the ordered code, PagePrivate2 is set on each one.
    This is a cheap operation because we already have all the pages locked
    and ready to go.
    
    As IO finishes, the PagePrivate2 bit is cleared and the ordered
    accoutning is updated for each page.
    
    At writepage time, if the PagePrivate2 bit is missing, we go into the
    writepage fixup code to handle improperly dirtied pages.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 3d31c8827b01..993a7ea45c70 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -85,6 +85,9 @@ struct btrfs_ordered_extent {
 	/* extent length on disk */
 	u64 disk_len;
 
+	/* number of bytes that still need writing */
+	u64 bytes_left;
+
 	/* flags (described above) */
 	unsigned long flags;
 

commit 5a3f23d515a2ebf0c750db80579ca57b28cbce6d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 31 13:27:11 2009 -0400

    Btrfs: add extra flushing for renames and truncates
    
    Renames and truncates are both common ways to replace old data with new
    data.  The filesystem can make an effort to make sure the new data is
    on disk before actually replacing the old data.
    
    This is especially important for rename, which many application use as
    though it were atomic for both the data and the metadata involved.  The
    current btrfs code will happily replace a file that is fully on disk
    with one that was just created and still has pending IO.
    
    If we crash after transaction commit but before the IO is done, we'll end
    up replacing a good file with a zero length file.  The solution used
    here is to create a list of inodes that need special ordering and force
    them to disk before the commit is done.  This is similar to the
    ext3 style data=ordering, except it is only done on selected files.
    
    Btrfs is able to get away with this because it does not wait on commits
    very often, even for fsync (which use a sub-commit).
    
    For renames, we order the file when it wasn't already
    on disk and when it is replacing an existing file.  Larger files
    are sent to filemap_flush right away (before the transaction handle is
    opened).
    
    For truncates, we order if the file goes from non-zero size down to
    zero size.  This is a little different, because at the time of the
    truncate the file has no dirty bytes to order.  But, we flag the inode
    so that it is added to the ordered list on close (via release method).  We
    also immediately add it to the ordered list of the current transaction
    so that we can try to flush down any writes the application sneaks in
    before commit.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index ab66d5e8d6d6..3d31c8827b01 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -155,4 +155,8 @@ int btrfs_wait_on_page_writeback_range(struct address_space *mapping,
 int btrfs_fdatawrite_range(struct address_space *mapping, loff_t start,
 			   loff_t end, int sync_mode);
 int btrfs_wait_ordered_extents(struct btrfs_root *root, int nocow_only);
+int btrfs_run_ordered_operations(struct btrfs_root *root, int wait);
+int btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root,
+				struct inode *inode);
 #endif

commit d20f7043fa65659136c1a7c3c456eeeb5c6f431f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 8 16:58:54 2008 -0500

    Btrfs: move data checksumming into a dedicated tree
    
    Btrfs stores checksums for each data block.  Until now, they have
    been stored in the subvolume trees, indexed by the inode that is
    referencing the data block.  This means that when we read the inode,
    we've probably read in at least some checksums as well.
    
    But, this has a few problems:
    
    * The checksums are indexed by logical offset in the file.  When
    compression is on, this means we have to do the expensive checksumming
    on the uncompressed data.  It would be faster if we could checksum
    the compressed data instead.
    
    * If we implement encryption, we'll be checksumming the plain text and
    storing that on disk.  This is significantly less secure.
    
    * For either compression or encryption, we have to get the plain text
    back before we can verify the checksum as correct.  This makes the raid
    layer balancing and extent moving much more expensive.
    
    * It makes the front end caching code more complex, as we have touch
    the subvolume and inodes as we cache extents.
    
    * There is potentitally one copy of the checksum in each subvolume
    referencing an extent.
    
    The solution used here is to store the extent checksums in a dedicated
    tree.  This allows us to index the checksums by phyiscal extent
    start and length.  It means:
    
    * The checksum is against the data stored on disk, after any compression
    or encryption is done.
    
    * The checksum is stored in a central location, and can be verified without
    following back references, or reading inodes.
    
    This makes compression significantly faster by reducing the amount of
    data that needs to be checksummed.  It will also allow much faster
    raid management code in general.
    
    The checksums are indexed by a key with a fixed objectid (a magic value
    in ctree.h) and offset set to the starting byte of the extent.  This
    allows us to copy the checksum items into the fsync log tree directly (or
    any other tree), without having to invent a second format for them.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 260bf95dfe0c..ab66d5e8d6d6 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -33,15 +33,17 @@ struct btrfs_ordered_inode_tree {
  * the ordered extent are on disk
  */
 struct btrfs_sector_sum {
-	u64 offset;
+	/* bytenr on disk */
+	u64 bytenr;
 	u32 sum;
 };
 
 struct btrfs_ordered_sum {
-	u64 file_offset;
+	/* bytenr is the start of this extent on disk */
+	u64 bytenr;
+
 	/*
 	 * this is the length in bytes covered by the sums array below.
-	 * But, the sums array may not be contiguous in the file.
 	 */
 	unsigned long len;
 	struct list_head list;
@@ -147,7 +149,7 @@ struct btrfs_ordered_extent *
 btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
 int btrfs_ordered_update_i_size(struct inode *inode,
 				struct btrfs_ordered_extent *ordered);
-int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u32 *sum);
+int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr, u32 *sum);
 int btrfs_wait_on_page_writeback_range(struct address_space *mapping,
 				       pgoff_t start, pgoff_t end);
 int btrfs_fdatawrite_range(struct address_space *mapping, loff_t start,

commit d899e05215178fed903ad0e7fc1cb4d8e0cc0a88
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Oct 30 14:25:28 2008 -0400

    Btrfs: Add fallocate support v2
    This patch updates btrfs-progs for fallocate support.
    
    fallocate is a little different in Btrfs because we need to tell the
    COW system that a given preallocated extent doesn't need to be
    cow'd as long as there are no snapshots of it.  This leverages the
    -o nodatacow checks.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index e6d9bc54c2b1..260bf95dfe0c 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -68,6 +68,8 @@ struct btrfs_ordered_sum {
 
 #define BTRFS_ORDERED_COMPRESSED 3 /* writing a compressed extent */
 
+#define BTRFS_ORDERED_PREALLOC 4 /* set when writing to prealloced extent */
+
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
 	u64 file_offset;
@@ -132,7 +134,7 @@ int btrfs_remove_ordered_extent(struct inode *inode,
 int btrfs_dec_test_ordered_pending(struct inode *inode,
 				       u64 file_offset, u64 io_size);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
-			     u64 start, u64 len, u64 disk_len, int type);
+			     u64 start, u64 len, u64 disk_len, int tyep);
 int btrfs_add_ordered_sum(struct inode *inode,
 			  struct btrfs_ordered_extent *entry,
 			  struct btrfs_ordered_sum *sum);

commit 80ff385665b7fca29fefe358a60ab0d09f9b8e87
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Oct 30 14:20:02 2008 -0400

    Btrfs: update nodatacow code v2
    
    This patch simplifies the nodatacow checker. If all references
    were created after the latest snapshot, then we can avoid COW
    safely. This patch also updates run_delalloc_nocow to do more
    fine-grained checking.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 1ef464145d22..e6d9bc54c2b1 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -132,8 +132,7 @@ int btrfs_remove_ordered_extent(struct inode *inode,
 int btrfs_dec_test_ordered_pending(struct inode *inode,
 				       u64 file_offset, u64 io_size);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
-			     u64 start, u64 len, u64 disk_len, int nocow,
-			     int compressed);
+			     u64 start, u64 len, u64 disk_len, int type);
 int btrfs_add_ordered_sum(struct inode *inode,
 			  struct btrfs_ordered_extent *entry,
 			  struct btrfs_ordered_sum *sum);

commit c8b978188c9a0fd3d535c13debd19d522b726f1f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Oct 29 14:49:59 2008 -0400

    Btrfs: Add zlib compression support
    
    This is a large change for adding compression on reading and writing,
    both for inline and regular extents.  It does some fairly large
    surgery to the writeback paths.
    
    Compression is off by default and enabled by mount -o compress.  Even
    when the -o compress mount option is not used, it is possible to read
    compressed extents off the disk.
    
    If compression for a given set of pages fails to make them smaller, the
    file is flagged to avoid future compression attempts later.
    
    * While finding delalloc extents, the pages are locked before being sent down
    to the delalloc handler.  This allows the delalloc handler to do complex things
    such as cleaning the pages, marking them writeback and starting IO on their
    behalf.
    
    * Inline extents are inserted at delalloc time now.  This allows us to compress
    the data before inserting the inline extent, and it allows us to insert
    an inline extent that spans multiple pages.
    
    * All of the in-memory extent representations (extent_map.c, ordered-data.c etc)
    are changed to record both an in-memory size and an on disk size, as well
    as a flag for compression.
    
    From a disk format point of view, the extent pointers in the file are changed
    to record the on disk size of a given extent and some encoding flags.
    Space in the disk format is allocated for compression encoding, as well
    as encryption and a generic 'other' field.  Neither the encryption or the
    'other' field are currently used.
    
    In order to limit the amount of data read for a single random read in the
    file, the size of a compressed extent is limited to 128k.  This is a
    software only limit, the disk format supports u64 sized compressed extents.
    
    In order to limit the ram consumed while processing extents, the uncompressed
    size of a compressed extent is limited to 256k.  This is a software only limit
    and will be subject to tuning later.
    
    Checksumming is still done on compressed extents, and it is done on the
    uncompressed version of the data.  This way additional encodings can be
    layered on without having to figure out which encoding to checksum.
    
    Compression happens at delalloc time, which is basically singled threaded because
    it is usually done by a single pdflush thread.  This makes it tricky to
    spread the compression load across all the cpus on the box.  We'll have to
    look at parallel pdflush walks of dirty inodes at a later time.
    
    Decompression is hooked into readpages and it does spread across CPUs nicely.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index f50f8870a144..1ef464145d22 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -66,6 +66,8 @@ struct btrfs_ordered_sum {
 
 #define BTRFS_ORDERED_NOCOW 2 /* set when we want to write in place */
 
+#define BTRFS_ORDERED_COMPRESSED 3 /* writing a compressed extent */
+
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
 	u64 file_offset;
@@ -73,9 +75,12 @@ struct btrfs_ordered_extent {
 	/* disk byte number */
 	u64 start;
 
-	/* length of the extent in bytes */
+	/* ram length of the extent in bytes */
 	u64 len;
 
+	/* extent length on disk */
+	u64 disk_len;
+
 	/* flags (described above) */
 	unsigned long flags;
 
@@ -127,7 +132,8 @@ int btrfs_remove_ordered_extent(struct inode *inode,
 int btrfs_dec_test_ordered_pending(struct inode *inode,
 				       u64 file_offset, u64 io_size);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
-			     u64 start, u64 len, int nocow);
+			     u64 start, u64 len, u64 disk_len, int nocow,
+			     int compressed);
 int btrfs_add_ordered_sum(struct inode *inode,
 			  struct btrfs_ordered_extent *entry,
 			  struct btrfs_ordered_sum *sum);

commit cb843a6f513a1a91c54951005e60bd9b95bdf973
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Oct 3 12:30:02 2008 -0400

    Btrfs: O_DIRECT writes via buffered writes + invaldiate
    
    This reworks the btrfs O_DIRECT write code a bit.  It had always fallen
    back to buffered IO and done an invalidate, but needed to be updated
    for the data=ordered code.  The invalidate wasn't actually removing pages
    because they were still inside an ordered extent.
    
    This also combines the O_DIRECT/O_SYNC paths where possible, and kicks
    off IO in the main btrfs_file_write loop to keep the pipe down the the
    disk full as we process long writes.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index fd45519f30a8..f50f8870a144 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -135,7 +135,7 @@ struct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,
 							 u64 file_offset);
 void btrfs_start_ordered_extent(struct inode *inode,
 				struct btrfs_ordered_extent *entry, int wait);
-void btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
+int btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
 struct btrfs_ordered_extent *
 btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
 int btrfs_ordered_update_i_size(struct inode *inode,

commit 7ea394f1192bee1af67ea4762c88ef4b7b0487a8
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Tue Aug 5 13:05:02 2008 -0400

    Btrfs: Fix nodatacow for the new data=ordered mode
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 5efe6b63c74c..fd45519f30a8 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -64,6 +64,8 @@ struct btrfs_ordered_sum {
 
 #define BTRFS_ORDERED_COMPLETE 1 /* set when removed from the tree */
 
+#define BTRFS_ORDERED_NOCOW 2 /* set when we want to write in place */
+
 struct btrfs_ordered_extent {
 	/* logical offset in the file */
 	u64 file_offset;
@@ -125,7 +127,7 @@ int btrfs_remove_ordered_extent(struct inode *inode,
 int btrfs_dec_test_ordered_pending(struct inode *inode,
 				       u64 file_offset, u64 io_size);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
-			     u64 start, u64 len);
+			     u64 start, u64 len, int nocow);
 int btrfs_add_ordered_sum(struct inode *inode,
 			  struct btrfs_ordered_extent *entry,
 			  struct btrfs_ordered_sum *sum);
@@ -143,5 +145,5 @@ int btrfs_wait_on_page_writeback_range(struct address_space *mapping,
 				       pgoff_t start, pgoff_t end);
 int btrfs_fdatawrite_range(struct address_space *mapping, loff_t start,
 			   loff_t end, int sync_mode);
-int btrfs_wait_ordered_extents(struct btrfs_root *root);
+int btrfs_wait_ordered_extents(struct btrfs_root *root, int nocow_only);
 #endif

commit 3eaa2885276fd6dac7b076a793932428b7168e74
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 24 11:57:52 2008 -0400

    Btrfs: Fix the defragmention code and the block relocation code for data=ordered
    
    Before setting an extent to delalloc, the code needs to wait for
    pending ordered extents.
    
    Also, the relocation code needs to wait for ordered IO before scanning
    the block group again.  This is because the extents are not removed
    until the IO for the new extents is finished
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 199cb0b4f1d9..5efe6b63c74c 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -80,6 +80,9 @@ struct btrfs_ordered_extent {
 	/* reference count */
 	atomic_t refs;
 
+	/* the inode we belong to */
+	struct inode *inode;
+
 	/* list of checksums for insertion when the extent io is done */
 	struct list_head list;
 
@@ -88,6 +91,9 @@ struct btrfs_ordered_extent {
 
 	/* our friendly rbtree entry */
 	struct rb_node rb_node;
+
+	/* a per root list of all the pending ordered extents */
+	struct list_head root_extent_list;
 };
 
 
@@ -137,4 +143,5 @@ int btrfs_wait_on_page_writeback_range(struct address_space *mapping,
 				       pgoff_t start, pgoff_t end);
 int btrfs_fdatawrite_range(struct address_space *mapping, loff_t start,
 			   loff_t end, int sync_mode);
+int btrfs_wait_ordered_extents(struct btrfs_root *root);
 #endif

commit 9ba4611a3a7902c6bad70c5c205de5161fcfc17b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jul 23 09:26:26 2008 -0400

    Btrfs: Fix 32 bit compiles by using an unsigned long byte count in the ordered extent
    
    The ordered extents have to fit in memory, so an unsigned long is sufficient.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 36e63f1f79b3..199cb0b4f1d9 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -95,7 +95,8 @@ struct btrfs_ordered_extent {
  * calculates the total size you need to allocate for an ordered sum
  * structure spanning 'bytes' in the file
  */
-static inline int btrfs_ordered_sum_size(struct btrfs_root *root, u64 bytes)
+static inline int btrfs_ordered_sum_size(struct btrfs_root *root,
+					 unsigned long bytes)
 {
 	unsigned long num_sectors = (bytes + root->sectorsize - 1) /
 		root->sectorsize;

commit ed98b56a6393c5e150fd5095b9eb7fd7d3cfb041
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 23:06:42 2008 -0400

    Btrfs: Take the csum mutex while reading checksums
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 8e8e3c0404f3..36e63f1f79b3 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -46,7 +46,7 @@ struct btrfs_ordered_sum {
 	unsigned long len;
 	struct list_head list;
 	/* last field is a variable length array of btrfs_sector_sums */
-	struct btrfs_sector_sum sums;
+	struct btrfs_sector_sum sums[];
 };
 
 /*

commit f421950f86bf96a11fef932e167ab2e70d4c43a0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 11:18:09 2008 -0400

    Btrfs: Fix some data=ordered related data corruptions
    
    Stress testing was showing data checksum errors, most of which were caused
    by a lookup bug in the extent_map tree.  The tree was caching the last
    pointer returned, and searches would check the last pointer first.
    
    But, search callers also expect the search to return the very first
    matching extent in the range, which wasn't always true with the last
    pointer usage.
    
    For now, the code to cache the last return value is just removed.  It is
    easy to fix, but I think lookups are rare enough that it isn't required anymore.
    
    This commit also replaces do_sync_mapping_range with a local copy of the
    related functions.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 1794efd13ca3..8e8e3c0404f3 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -132,4 +132,8 @@ btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
 int btrfs_ordered_update_i_size(struct inode *inode,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u32 *sum);
+int btrfs_wait_on_page_writeback_range(struct address_space *mapping,
+				       pgoff_t start, pgoff_t end);
+int btrfs_fdatawrite_range(struct address_space *mapping, loff_t start,
+			   loff_t end, int sync_mode);
 #endif

commit 3edf7d33f4edb1e4a9bb0a4c0a84d95fb4d22a09
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jul 18 06:17:13 2008 -0400

    Btrfs: Handle data checksumming on bios that span multiple ordered extents
    
    Data checksumming is done right before the bio is sent down the IO stack,
    which means a single bio might span more than one ordered extent.  In
    this case, the checksumming data is split between two ordered extents.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 98f491d1022b..1794efd13ca3 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -39,7 +39,11 @@ struct btrfs_sector_sum {
 
 struct btrfs_ordered_sum {
 	u64 file_offset;
-	u64 len;
+	/*
+	 * this is the length in bytes covered by the sums array below.
+	 * But, the sums array may not be contiguous in the file.
+	 */
+	unsigned long len;
 	struct list_head list;
 	/* last field is a variable length array of btrfs_sector_sums */
 	struct btrfs_sector_sum sums;
@@ -95,6 +99,7 @@ static inline int btrfs_ordered_sum_size(struct btrfs_root *root, u64 bytes)
 {
 	unsigned long num_sectors = (bytes + root->sectorsize - 1) /
 		root->sectorsize;
+	num_sectors++;
 	return sizeof(struct btrfs_ordered_sum) +
 		num_sectors * sizeof(struct btrfs_sector_sum);
 }
@@ -114,7 +119,9 @@ int btrfs_dec_test_ordered_pending(struct inode *inode,
 				       u64 file_offset, u64 io_size);
 int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
 			     u64 start, u64 len);
-int btrfs_add_ordered_sum(struct inode *inode, struct btrfs_ordered_sum *sum);
+int btrfs_add_ordered_sum(struct inode *inode,
+			  struct btrfs_ordered_extent *entry,
+			  struct btrfs_ordered_sum *sum);
 struct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,
 							 u64 file_offset);
 void btrfs_start_ordered_extent(struct inode *inode,

commit eb84ae039e10f1f80443d846ba1350122bbdc753
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 13:53:27 2008 -0400

    Btrfs: Cleanup and comment ordered-data.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 33f0d9e91b11..98f491d1022b 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -19,12 +19,19 @@
 #ifndef __BTRFS_ORDERED_DATA__
 #define __BTRFS_ORDERED_DATA__
 
+/* one of these per inode */
 struct btrfs_ordered_inode_tree {
 	struct mutex mutex;
 	struct rb_root tree;
 	struct rb_node *last;
 };
 
+/*
+ * these are used to collect checksums done just before bios submission.
+ * They are attached via a list into the ordered extent, and
+ * checksum items are inserted into the tree after all the blocks in
+ * the ordered extent are on disk
+ */
 struct btrfs_sector_sum {
 	u64 offset;
 	u32 sum;
@@ -34,27 +41,56 @@ struct btrfs_ordered_sum {
 	u64 file_offset;
 	u64 len;
 	struct list_head list;
+	/* last field is a variable length array of btrfs_sector_sums */
 	struct btrfs_sector_sum sums;
 };
 
-/* bits for the flags field */
+/*
+ * bits for the flags field:
+ *
+ * BTRFS_ORDERED_IO_DONE is set when all of the blocks are written.
+ * It is used to make sure metadata is inserted into the tree only once
+ * per extent.
+ *
+ * BTRFS_ORDERED_COMPLETE is set when the extent is removed from the
+ * rbtree, just before waking any waiters.  It is used to indicate the
+ * IO is done and any metadata is inserted into the tree.
+ */
 #define BTRFS_ORDERED_IO_DONE 0 /* set when all the pages are written */
+
 #define BTRFS_ORDERED_COMPLETE 1 /* set when removed from the tree */
-#define BTRFS_ORDERED_START 2 /* set when tree setup */
 
 struct btrfs_ordered_extent {
+	/* logical offset in the file */
 	u64 file_offset;
+
+	/* disk byte number */
 	u64 start;
+
+	/* length of the extent in bytes */
 	u64 len;
+
+	/* flags (described above) */
 	unsigned long flags;
+
+	/* reference count */
 	atomic_t refs;
+
+	/* list of checksums for insertion when the extent io is done */
 	struct list_head list;
-	struct inode *inode;
+
+	/* used to wait for the BTRFS_ORDERED_COMPLETE bit */
 	wait_queue_head_t wait;
+
+	/* our friendly rbtree entry */
 	struct rb_node rb_node;
 };
 
 
+/*
+ * calculates the total size you need to allocate for an ordered sum
+ * structure spanning 'bytes' in the file
+ */
 static inline int btrfs_ordered_sum_size(struct btrfs_root *root, u64 bytes)
 {
 	unsigned long num_sectors = (bytes + root->sectorsize - 1) /
@@ -81,14 +117,11 @@ int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
 int btrfs_add_ordered_sum(struct inode *inode, struct btrfs_ordered_sum *sum);
 struct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,
 							 u64 file_offset);
-void btrfs_wait_ordered_extent(struct inode *inode,
-			       struct btrfs_ordered_extent *entry);
+void btrfs_start_ordered_extent(struct inode *inode,
+				struct btrfs_ordered_extent *entry, int wait);
 void btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
 struct btrfs_ordered_extent *
 btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
-int btrfs_add_ordered_pending(struct inode *inode,
-			      struct btrfs_ordered_extent *ordered,
-			      u64 start, u64 len);
 int btrfs_ordered_update_i_size(struct inode *inode,
 				struct btrfs_ordered_extent *ordered);
 int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u32 *sum);

commit ba1da2f442ec91a1534afa893f9bef7e33056ace
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:54:15 2008 -0400

    Btrfs: Don't pin pages in ram until the entire ordered extent is on disk.
    
    Checksum items are not inserted until the entire ordered extent is on disk,
    but individual pages might be clean and available for reclaim long before
    the whole extent is on disk.
    
    In order to allow those pages to be freed, we need to be able to search
    the list of ordered extents to find the checksum that is going to be inserted
    in the tree.  This way if the page needs to be read back in before
    the checksums are in the btree, we'll be able to verify the checksum on
    the page.
    
    This commit adds the ability to search the pending ordered extents for
    a given offset in the file, and changes btrfs_releasepage to allow
    ordered pages to be freed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 40e9126ad954..33f0d9e91b11 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -91,4 +91,5 @@ int btrfs_add_ordered_pending(struct inode *inode,
 			      u64 start, u64 len);
 int btrfs_ordered_update_i_size(struct inode *inode,
 				struct btrfs_ordered_extent *ordered);
+int btrfs_find_ordered_sum(struct inode *inode, u64 offset, u32 *sum);
 #endif

commit dbe674a99c8af088faa4c95eddaeb271a3140ab6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:54:05 2008 -0400

    Btrfs: Update on disk i_size only after pending ordered extents are done
    
    This changes the ordered data code to update i_size after the extent
    is on disk.  An on disk i_size is maintained in the in-memory btrfs inode
    structures, and this is updated as extents finish.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 33292c5fe90c..40e9126ad954 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -89,4 +89,6 @@ btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
 int btrfs_add_ordered_pending(struct inode *inode,
 			      struct btrfs_ordered_extent *ordered,
 			      u64 start, u64 len);
+int btrfs_ordered_update_i_size(struct inode *inode,
+				struct btrfs_ordered_extent *ordered);
 #endif

commit e6dcd2dc9c489108648e2ed543315dd134d50a9a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:53:50 2008 -0400

    Btrfs: New data=ordered implementation
    
    The old data=ordered code would force commit to wait until
    all the data extents from the transaction were fully on disk.  This
    introduced large latencies into the commit and stalled new writers
    in the transaction for a long time.
    
    The new code changes the way data allocations and extents work:
    
    * When delayed allocation is filled, data extents are reserved, and
      the extent bit EXTENT_ORDERED is set on the entire range of the extent.
      A struct btrfs_ordered_extent is allocated an inserted into a per-inode
      rbtree to track the pending extents.
    
    * As each page is written EXTENT_ORDERED is cleared on the bytes corresponding
      to that page.
    
    * When all of the bytes corresponding to a single struct btrfs_ordered_extent
      are written, The previously reserved extent is inserted into the FS
      btree and into the extent allocation trees.  The checksums for the file
      data are also updated.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 4fa78736423e..33292c5fe90c 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -20,24 +20,73 @@
 #define __BTRFS_ORDERED_DATA__
 
 struct btrfs_ordered_inode_tree {
-	rwlock_t lock;
+	struct mutex mutex;
 	struct rb_root tree;
+	struct rb_node *last;
 };
 
+struct btrfs_sector_sum {
+	u64 offset;
+	u32 sum;
+};
+
+struct btrfs_ordered_sum {
+	u64 file_offset;
+	u64 len;
+	struct list_head list;
+	struct btrfs_sector_sum sums;
+};
+
+/* bits for the flags field */
+#define BTRFS_ORDERED_IO_DONE 0 /* set when all the pages are written */
+#define BTRFS_ORDERED_COMPLETE 1 /* set when removed from the tree */
+#define BTRFS_ORDERED_START 2 /* set when tree setup */
+
+struct btrfs_ordered_extent {
+	u64 file_offset;
+	u64 start;
+	u64 len;
+	unsigned long flags;
+	atomic_t refs;
+	struct list_head list;
+	struct inode *inode;
+	wait_queue_head_t wait;
+	struct rb_node rb_node;
+};
+
+
+static inline int btrfs_ordered_sum_size(struct btrfs_root *root, u64 bytes)
+{
+	unsigned long num_sectors = (bytes + root->sectorsize - 1) /
+		root->sectorsize;
+	return sizeof(struct btrfs_ordered_sum) +
+		num_sectors * sizeof(struct btrfs_sector_sum);
+}
+
 static inline void
 btrfs_ordered_inode_tree_init(struct btrfs_ordered_inode_tree *t)
 {
-	rwlock_init(&t->lock);
+	mutex_init(&t->mutex);
 	t->tree.rb_node = NULL;
+	t->last = NULL;
 }
 
-int btrfs_add_ordered_inode(struct inode *inode);
-int btrfs_find_del_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
-				       u64 *root_objectid, u64 *objectid,
-				       struct inode **inode);
-int btrfs_find_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
-				       u64 *root_objectid, u64 *objectid,
-				       struct inode **inode);
-void btrfs_del_ordered_inode(struct inode *inode, int force);
-int btrfs_ordered_throttle(struct btrfs_root *root, struct inode *inode);
+int btrfs_put_ordered_extent(struct btrfs_ordered_extent *entry);
+int btrfs_remove_ordered_extent(struct inode *inode,
+				struct btrfs_ordered_extent *entry);
+int btrfs_dec_test_ordered_pending(struct inode *inode,
+				       u64 file_offset, u64 io_size);
+int btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,
+			     u64 start, u64 len);
+int btrfs_add_ordered_sum(struct inode *inode, struct btrfs_ordered_sum *sum);
+struct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,
+							 u64 file_offset);
+void btrfs_wait_ordered_extent(struct inode *inode,
+			       struct btrfs_ordered_extent *entry);
+void btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len);
+struct btrfs_ordered_extent *
+btrfs_lookup_first_ordered_extent(struct inode * inode, u64 file_offset);
+int btrfs_add_ordered_pending(struct inode *inode,
+			      struct btrfs_ordered_extent *ordered,
+			      u64 start, u64 len);
 #endif

commit 594a24eb0e7fa8413f8b443863be4b7c72bfde9f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Fix btrfs_del_ordered_inode to allow forcing the drop during unlinks
    
    This allows us to delete an unlinked inode with dirty pages from the list
    instead of forcing commit to write these out before deleting the inode.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index c515c4b39996..4fa78736423e 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -38,6 +38,6 @@ int btrfs_find_del_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
 int btrfs_find_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
 				       u64 *root_objectid, u64 *objectid,
 				       struct inode **inode);
-void btrfs_del_ordered_inode(struct inode *inode);
+void btrfs_del_ordered_inode(struct inode *inode, int force);
 int btrfs_ordered_throttle(struct btrfs_root *root, struct inode *inode);
 #endif

commit e1b81e6761bd8419146d4bbe0aadd8b2d348a01c
Author: Mingming <cmm@us.ibm.com>
Date:   Tue May 27 10:55:43 2008 -0400

    btrfs delete ordered inode handling fix
    
    Use btrfs_release_file instead of a put_inode call
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 29047e0abaab..c515c4b39996 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -38,6 +38,6 @@ int btrfs_find_del_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
 int btrfs_find_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
 				       u64 *root_objectid, u64 *objectid,
 				       struct inode **inode);
-int btrfs_del_ordered_inode(struct inode *inode);
+void btrfs_del_ordered_inode(struct inode *inode);
 int btrfs_ordered_throttle(struct btrfs_root *root, struct inode *inode);
 #endif

commit 81d7ed29ff6bdec903c36c26b386e16c014993b2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 25 08:51:48 2008 -0400

    Btrfs: Throttle file_write when data=ordered is flushing the inode
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index f25c6771ec64..29047e0abaab 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -39,4 +39,5 @@ int btrfs_find_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
 				       u64 *root_objectid, u64 *objectid,
 				       struct inode **inode);
 int btrfs_del_ordered_inode(struct inode *inode);
+int btrfs_ordered_throttle(struct btrfs_root *root, struct inode *inode);
 #endif

commit 4d5e74bc0aec3f54b7e429d77b7c35de042c507d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jan 16 16:09:22 2008 -0500

    Btrfs: Fix data=ordered vs wait_on_inode deadlock on older kernels
    
    Using ilookup5 during data=ordered writeback could deadlock on I_LOCK.  This
    saves a pointer to the inode instead.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index 26b26212865b..f25c6771ec64 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -33,8 +33,10 @@ btrfs_ordered_inode_tree_init(struct btrfs_ordered_inode_tree *t)
 
 int btrfs_add_ordered_inode(struct inode *inode);
 int btrfs_find_del_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
-				       u64 *root_objectid, u64 *objectid);
+				       u64 *root_objectid, u64 *objectid,
+				       struct inode **inode);
 int btrfs_find_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
-				       u64 *root_objectid, u64 *objectid);
+				       u64 *root_objectid, u64 *objectid,
+				       struct inode **inode);
 int btrfs_del_ordered_inode(struct inode *inode);
 #endif

commit cee36a03e8f7c6e14aefd497d3acf01bcd3ef153
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 15 08:40:48 2008 -0500

    Rework btrfs_drop_inode to avoid scheduling
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
index aaf9eb142719..26b26212865b 100644
--- a/fs/btrfs/ordered-data.h
+++ b/fs/btrfs/ordered-data.h
@@ -36,4 +36,5 @@ int btrfs_find_del_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
 				       u64 *root_objectid, u64 *objectid);
 int btrfs_find_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
 				       u64 *root_objectid, u64 *objectid);
+int btrfs_del_ordered_inode(struct inode *inode);
 #endif

commit dc17ff8f11d129db9e83ab7244769e4eae05e14d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 8 15:46:30 2008 -0500

    Btrfs: Add data=ordered support
    
    This forces file data extents down the disk along with the metadata that
    references them.  The current implementation is fairly simple, and just
    writes out all of the dirty pages in an inode before the commit.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/ordered-data.h b/fs/btrfs/ordered-data.h
new file mode 100644
index 000000000000..aaf9eb142719
--- /dev/null
+++ b/fs/btrfs/ordered-data.h
@@ -0,0 +1,39 @@
+/*
+ * Copyright (C) 2007 Oracle.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
+#ifndef __BTRFS_ORDERED_DATA__
+#define __BTRFS_ORDERED_DATA__
+
+struct btrfs_ordered_inode_tree {
+	rwlock_t lock;
+	struct rb_root tree;
+};
+
+static inline void
+btrfs_ordered_inode_tree_init(struct btrfs_ordered_inode_tree *t)
+{
+	rwlock_init(&t->lock);
+	t->tree.rb_node = NULL;
+}
+
+int btrfs_add_ordered_inode(struct inode *inode);
+int btrfs_find_del_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
+				       u64 *root_objectid, u64 *objectid);
+int btrfs_find_first_ordered_inode(struct btrfs_ordered_inode_tree *tree,
+				       u64 *root_objectid, u64 *objectid);
+#endif
