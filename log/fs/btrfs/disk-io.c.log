commit aa27b32b76d0b1b242d43977da0e5358da1c825f
Merge: 9e4d7696213f 0465337c5599
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 7 14:10:33 2020 -0700

    Merge tag 'for-5.8-rc4-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
    
     - regression fix of a leak in global block reserve accounting
    
     - fix a (hard to hit) race of readahead vs releasepage that could lead
       to crash
    
     - convert all remaining uses of comment fall through annotations to the
       pseudo keyword
    
     - fix crash when mounting a fuzzed image with -o recovery
    
    * tag 'for-5.8-rc4-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      btrfs: reset tree root pointer after error in init_tree_roots
      btrfs: fix reclaim_size counter leak after stealing from global reserve
      btrfs: fix fatal extent_buffer readahead vs releasepage race
      btrfs: convert comments to fallthrough annotations

commit 0465337c5599bbe360cdcff452992a1a6b7ed2d4
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Tue Jun 30 14:53:02 2020 -0400

    btrfs: reset tree root pointer after error in init_tree_roots
    
    Eric reported an issue where mounting -o recovery with a fuzzed fs
    resulted in a kernel panic.  This is because we tried to free the tree
    node, except it was an error from the read.  Fix this by properly
    resetting the tree_root->node == NULL in this case.  The panic was the
    following
    
      BTRFS warning (device loop0): failed to read tree root
      BUG: kernel NULL pointer dereference, address: 000000000000001f
      RIP: 0010:free_extent_buffer+0xe/0x90 [btrfs]
      Call Trace:
       free_root_extent_buffers.part.0+0x11/0x30 [btrfs]
       free_root_pointers+0x1a/0xa2 [btrfs]
       open_ctree+0x1776/0x18a5 [btrfs]
       btrfs_mount_root.cold+0x13/0xfa [btrfs]
       ? selinux_fs_context_parse_param+0x37/0x80
       legacy_get_tree+0x27/0x40
       vfs_get_tree+0x25/0xb0
       fc_mount+0xe/0x30
       vfs_kern_mount.part.0+0x71/0x90
       btrfs_mount+0x147/0x3e0 [btrfs]
       ? cred_has_capability+0x7c/0x120
       ? legacy_get_tree+0x27/0x40
       legacy_get_tree+0x27/0x40
       vfs_get_tree+0x25/0xb0
       do_mount+0x735/0xa40
       __x64_sys_mount+0x8e/0xd0
       do_syscall_64+0x4d/0x90
       entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Nik says: this is problematic only if we fail on the last iteration of
    the loop as this results in init_tree_roots returning err value with
    tree_root->node = -ERR. Subsequently the caller does: fail_tree_roots
    which calls free_root_pointers on the bogus value.
    
    Reported-by: Eric Sandeen <sandeen@redhat.com>
    Fixes: b8522a1e5f42 ("btrfs: Factor out tree roots initialization during mount")
    CC: stable@vger.kernel.org # 5.5+
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add details how the pointer gets dereferenced ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f8ec2d8606fd..3d4bb77680e7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2595,10 +2595,12 @@ static int __cold init_tree_roots(struct btrfs_fs_info *fs_info)
 		    !extent_buffer_uptodate(tree_root->node)) {
 			handle_error = true;
 
-			if (IS_ERR(tree_root->node))
+			if (IS_ERR(tree_root->node)) {
 				ret = PTR_ERR(tree_root->node);
-			else if (!extent_buffer_uptodate(tree_root->node))
+				tree_root->node = NULL;
+			} else if (!extent_buffer_uptodate(tree_root->node)) {
 				ret = -EUCLEAN;
+			}
 
 			btrfs_warn(fs_info, "failed to read tree root");
 			continue;

commit f3cdc8ae116e27d84e1f33c7a2995960cebb73ac
Merge: 8eeae5bae123 2166e5edce9a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 2 19:59:25 2020 -0700

    Merge tag 'for-5.8-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "Highlights:
    
       - speedup dead root detection during orphan cleanup, eg. when there
         are many deleted subvolumes waiting to be cleaned, the trees are
         now looked up in radix tree instead of a O(N^2) search
    
       - snapshot creation with inherited qgroup will mark the qgroup
         inconsistent, requires a rescan
    
       - send will emit file capabilities after chown, this produces a
         stream that does not need postprocessing to set the capabilities
         again
    
       - direct io ported to iomap infrastructure, cleaned up and simplified
         code, notably removing last use of struct buffer_head in btrfs code
    
      Core changes:
    
       - factor out backreference iteration, to be used by ordinary
         backreferences and relocation code
    
       - improved global block reserve utilization
          * better logic to serialize requests
          * increased maximum available for unlink
          * improved handling on large pages (64K)
    
       - direct io cleanups and fixes
          * simplify layering, where cloned bios were unnecessarily created
            for some cases
          * error handling fixes (submit, endio)
          * remove repair worker thread, used to avoid deadlocks during
            repair
    
       - refactored block group reading code, preparatory work for new type
         of block group storage that should improve mount time on large
         filesystems
    
      Cleanups:
    
       - cleaned up (and slightly sped up) set/get helpers for metadata data
         structure members
    
       - root bit REF_COWS got renamed to SHAREABLE to reflect the that the
         blocks of the tree get shared either among subvolumes or with the
         relocation trees
    
      Fixes:
    
       - when subvolume deletion fails due to ENOSPC, the filesystem is not
         turned read-only
    
       - device scan deals with devices from other filesystems that changed
         ownership due to overwrite (mkfs)
    
       - fix a race between scrub and block group removal/allocation
    
       - fix long standing bug of a runaway balance operation, printing the
         same line to the syslog, caused by a stale status bit on a reloc
         tree that prevented progress
    
       - fix corrupt log due to concurrent fsync of inodes with shared
         extents
    
       - fix space underflow for NODATACOW and buffered writes when it for
         some reason needs to fallback to COW mode"
    
    * tag 'for-5.8-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (133 commits)
      btrfs: fix space_info bytes_may_use underflow during space cache writeout
      btrfs: fix space_info bytes_may_use underflow after nocow buffered write
      btrfs: fix wrong file range cleanup after an error filling dealloc range
      btrfs: remove redundant local variable in read_block_for_search
      btrfs: open code key_search
      btrfs: split btrfs_direct_IO to read and write part
      btrfs: remove BTRFS_INODE_READDIO_NEED_LOCK
      fs: remove dio_end_io()
      btrfs: switch to iomap_dio_rw() for dio
      iomap: remove lockdep_assert_held()
      iomap: add a filesystem hook for direct I/O bio submission
      fs: export generic_file_buffered_read()
      btrfs: turn space cache writeout failure messages into debug messages
      btrfs: include error on messages about failure to write space/inode caches
      btrfs: remove useless 'fail_unlock' label from btrfs_csum_file_blocks()
      btrfs: do not ignore error from btrfs_next_leaf() when inserting checksums
      btrfs: make checksum item extension more efficient
      btrfs: fix corrupt log due to concurrent fsync of inodes with shared extents
      btrfs: unexport btrfs_compress_set_level()
      btrfs: simplify iget helpers
      ...

commit d1b89bc0426110138ddc80a6916f359d0174571d
Author: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
Date:   Mon Jun 1 21:47:45 2020 -0700

    btrfs: use attach/detach_page_private
    
    Since the new pair function is introduced, we can call them to clean the
    code in btrfs.
    
    Signed-off-by: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: David Sterba <dsterba@suse.com>
    Cc: Chris Mason <clm@fb.com>
    Cc: Josef Bacik <josef@toxicpanda.com>
    Link: http://lkml.kernel.org/r/20200517214718.468-4-guoqing.jiang@cloud.ionos.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d10c7be10f3b..7278789ff8a7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -980,9 +980,7 @@ static void btree_invalidatepage(struct page *page, unsigned int offset,
 		btrfs_warn(BTRFS_I(page->mapping->host)->root->fs_info,
 			   "page private not zero on page %llu",
 			   (unsigned long long)page_offset(page));
-		ClearPagePrivate(page);
-		set_page_private(page, 0);
-		put_page(page);
+		detach_page_private(page);
 	}
 }
 

commit e289f03ea79bbc6574b78ac25682555423a91cbb
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 18 12:14:50 2020 +0100

    btrfs: fix corrupt log due to concurrent fsync of inodes with shared extents
    
    When we have extents shared amongst different inodes in the same subvolume,
    if we fsync them in parallel we can end up with checksum items in the log
    tree that represent ranges which overlap.
    
    For example, consider we have inodes A and B, both sharing an extent that
    covers the logical range from X to X + 64KiB:
    
    1) Task A starts an fsync on inode A;
    
    2) Task B starts an fsync on inode B;
    
    3) Task A calls btrfs_csum_file_blocks(), and the first search in the
       log tree, through btrfs_lookup_csum(), returns -EFBIG because it
       finds an existing checksum item that covers the range from X - 64KiB
       to X;
    
    4) Task A checks that the checksum item has not reached the maximum
       possible size (MAX_CSUM_ITEMS) and then releases the search path
       before it does another path search for insertion (through a direct
       call to btrfs_search_slot());
    
    5) As soon as task A releases the path and before it does the search
       for insertion, task B calls btrfs_csum_file_blocks() and gets -EFBIG
       too, because there is an existing checksum item that has an end
       offset that matches the start offset (X) of the checksum range we want
       to log;
    
    6) Task B releases the path;
    
    7) Task A does the path search for insertion (through btrfs_search_slot())
       and then verifies that the checksum item that ends at offset X still
       exists and extends its size to insert the checksums for the range from
       X to X + 64KiB;
    
    8) Task A releases the path and returns from btrfs_csum_file_blocks(),
       having inserted the checksums into an existing checksum item that got
       its size extended. At this point we have one checksum item in the log
       tree that covers the logical range from X - 64KiB to X + 64KiB;
    
    9) Task B now does a search for insertion using btrfs_search_slot() too,
       but it finds that the previous checksum item no longer ends at the
       offset X, it now ends at an of offset X + 64KiB, so it leaves that item
       untouched.
    
       Then it releases the path and calls btrfs_insert_empty_item()
       that inserts a checksum item with a key offset corresponding to X and
       a size for inserting a single checksum (4 bytes in case of crc32c).
       Subsequent iterations end up extending this new checksum item so that
       it contains the checksums for the range from X to X + 64KiB.
    
       So after task B returns from btrfs_csum_file_blocks() we end up with
       two checksum items in the log tree that have overlapping ranges, one
       for the range from X - 64KiB to X + 64KiB, and another for the range
       from X to X + 64KiB.
    
    Having checksum items that represent ranges which overlap, regardless of
    being in the log tree or in the chekcsums tree, can lead to problems where
    checksums for a file range end up not being found. This type of problem
    has happened a few times in the past and the following commits fixed them
    and explain in detail why having checksum items with overlapping ranges is
    problematic:
    
      27b9a8122ff71a "Btrfs: fix csum tree corruption, duplicate and outdated checksums"
      b84b8390d6009c "Btrfs: fix file read corruption after extent cloning and fsync"
      40e046acbd2f36 "Btrfs: fix missing data checksums after replaying a log tree"
    
    Since this specific instance of the problem can only happen when logging
    inodes, because it is the only case where concurrent attempts to insert
    checksums for the same range can happen, fix the issue by using an extent
    io tree as a range lock to serialize checksum insertion during inode
    logging.
    
    This issue could often be reproduced by the test case generic/457 from
    fstests. When it happens it produces the following trace:
    
     BTRFS critical (device dm-0): corrupt leaf: root=18446744073709551610 block=30625792 slot=42, csum end range (15020032) goes beyond the start range (15015936) of the next csum item
     BTRFS info (device dm-0): leaf 30625792 gen 7 total ptrs 49 free space 2402 owner 18446744073709551610
     BTRFS info (device dm-0): refs 1 lock (w:0 r:0 bw:0 br:0 sw:0 sr:0) lock_owner 0 current 15884
          item 0 key (18446744073709551606 128 13979648) itemoff 3991 itemsize 4
          item 1 key (18446744073709551606 128 13983744) itemoff 3987 itemsize 4
          item 2 key (18446744073709551606 128 13987840) itemoff 3983 itemsize 4
          item 3 key (18446744073709551606 128 13991936) itemoff 3979 itemsize 4
          item 4 key (18446744073709551606 128 13996032) itemoff 3975 itemsize 4
          item 5 key (18446744073709551606 128 14000128) itemoff 3971 itemsize 4
     (...)
     BTRFS error (device dm-0): block=30625792 write time tree block corruption detected
     ------------[ cut here ]------------
     WARNING: CPU: 1 PID: 15884 at fs/btrfs/disk-io.c:539 btree_csum_one_bio+0x268/0x2d0 [btrfs]
     Modules linked in: btrfs dm_thin_pool ...
     CPU: 1 PID: 15884 Comm: fsx Tainted: G        W         5.6.0-rc7-btrfs-next-58 #1
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.12.0-59-gc9ba5276e321-prebuilt.qemu.org 04/01/2014
     RIP: 0010:btree_csum_one_bio+0x268/0x2d0 [btrfs]
     Code: c7 c7 ...
     RSP: 0018:ffffbb0109e6f8e0 EFLAGS: 00010296
     RAX: 0000000000000000 RBX: ffffe1c0847b6080 RCX: 0000000000000000
     RDX: 0000000000000000 RSI: ffffffffaa963988 RDI: 0000000000000001
     RBP: ffff956a4f4d2000 R08: 0000000000000000 R09: 0000000000000001
     R10: 0000000000000526 R11: 0000000000000000 R12: ffff956a5cd28bb0
     R13: 0000000000000000 R14: ffff956a649c9388 R15: 000000011ed82000
     FS:  00007fb419959e80(0000) GS:ffff956a7aa00000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     CR2: 0000000000fe6d54 CR3: 0000000138696005 CR4: 00000000003606e0
     DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     Call Trace:
      btree_submit_bio_hook+0x67/0xc0 [btrfs]
      submit_one_bio+0x31/0x50 [btrfs]
      btree_write_cache_pages+0x2db/0x4b0 [btrfs]
      ? __filemap_fdatawrite_range+0xb1/0x110
      do_writepages+0x23/0x80
      __filemap_fdatawrite_range+0xd2/0x110
      btrfs_write_marked_extents+0x15e/0x180 [btrfs]
      btrfs_sync_log+0x206/0x10a0 [btrfs]
      ? kmem_cache_free+0x315/0x3b0
      ? btrfs_log_inode+0x1e8/0xf90 [btrfs]
      ? __mutex_unlock_slowpath+0x45/0x2a0
      ? lockref_put_or_lock+0x9/0x30
      ? dput+0x2d/0x580
      ? dput+0xb5/0x580
      ? btrfs_sync_file+0x464/0x4d0 [btrfs]
      btrfs_sync_file+0x464/0x4d0 [btrfs]
      do_fsync+0x38/0x60
      __x64_sys_fsync+0x10/0x20
      do_syscall_64+0x5c/0x280
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
     RIP: 0033:0x7fb41953a6d0
     Code: 48 3d ...
     RSP: 002b:00007ffcc86bd218 EFLAGS: 00000246 ORIG_RAX: 000000000000004a
     RAX: ffffffffffffffda RBX: 000000000000000d RCX: 00007fb41953a6d0
     RDX: 0000000000000009 RSI: 0000000000040000 RDI: 0000000000000003
     RBP: 0000000000040000 R08: 0000000000000001 R09: 0000000000000009
     R10: 0000000000000064 R11: 0000000000000246 R12: 0000556cf4b2c060
     R13: 0000000000000100 R14: 0000000000000000 R15: 0000556cf322b420
     irq event stamp: 0
     hardirqs last  enabled at (0): [<0000000000000000>] 0x0
     hardirqs last disabled at (0): [<ffffffffa96bdedf>] copy_process+0x74f/0x2020
     softirqs last  enabled at (0): [<ffffffffa96bdedf>] copy_process+0x74f/0x2020
     softirqs last disabled at (0): [<0000000000000000>] 0x0
     ---[ end trace d543fc76f5ad7fd8 ]---
    
    In that trace the tree checker detected the overlapping checksum items at
    the time when we triggered writeback for the log tree when syncing the
    log.
    
    Another trace that can happen is due to BUG_ON() when deleting checksum
    items while logging an inode:
    
     BTRFS critical (device dm-0): slot 81 key (18446744073709551606 128 13635584) new key (18446744073709551606 128 13635584)
     BTRFS info (device dm-0): leaf 30949376 gen 7 total ptrs 98 free space 8527 owner 18446744073709551610
     BTRFS info (device dm-0): refs 4 lock (w:1 r:0 bw:0 br:0 sw:1 sr:0) lock_owner 13473 current 13473
      item 0 key (257 1 0) itemoff 16123 itemsize 160
              inode generation 7 size 262144 mode 100600
      item 1 key (257 12 256) itemoff 16103 itemsize 20
      item 2 key (257 108 0) itemoff 16050 itemsize 53
              extent data disk bytenr 13631488 nr 4096
              extent data offset 0 nr 131072 ram 131072
     (...)
     ------------[ cut here ]------------
     kernel BUG at fs/btrfs/ctree.c:3153!
     invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC PTI
     CPU: 1 PID: 13473 Comm: fsx Not tainted 5.6.0-rc7-btrfs-next-58 #1
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.12.0-59-gc9ba5276e321-prebuilt.qemu.org 04/01/2014
     RIP: 0010:btrfs_set_item_key_safe+0x1ea/0x270 [btrfs]
     Code: 0f b6 ...
     RSP: 0018:ffff95e3889179d0 EFLAGS: 00010282
     RAX: 0000000000000000 RBX: 0000000000000051 RCX: 0000000000000000
     RDX: 0000000000000000 RSI: ffffffffb7763988 RDI: 0000000000000001
     RBP: fffffffffffffff6 R08: 0000000000000000 R09: 0000000000000001
     R10: 00000000000009ef R11: 0000000000000000 R12: ffff8912a8ba5a08
     R13: ffff95e388917a06 R14: ffff89138dcf68c8 R15: ffff95e388917ace
     FS:  00007fe587084e80(0000) GS:ffff8913baa00000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     CR2: 00007fe587091000 CR3: 0000000126dac005 CR4: 00000000003606e0
     DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     Call Trace:
      btrfs_del_csums+0x2f4/0x540 [btrfs]
      copy_items+0x4b5/0x560 [btrfs]
      btrfs_log_inode+0x910/0xf90 [btrfs]
      btrfs_log_inode_parent+0x2a0/0xe40 [btrfs]
      ? dget_parent+0x5/0x370
      btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      btrfs_sync_file+0x42b/0x4d0 [btrfs]
      __x64_sys_msync+0x199/0x200
      do_syscall_64+0x5c/0x280
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
     RIP: 0033:0x7fe586c65760
     Code: 00 f7 ...
     RSP: 002b:00007ffe250f98b8 EFLAGS: 00000246 ORIG_RAX: 000000000000001a
     RAX: ffffffffffffffda RBX: 00000000000040e1 RCX: 00007fe586c65760
     RDX: 0000000000000004 RSI: 0000000000006b51 RDI: 00007fe58708b000
     RBP: 0000000000006a70 R08: 0000000000000003 R09: 00007fe58700cb61
     R10: 0000000000000100 R11: 0000000000000246 R12: 00000000000000e1
     R13: 00007fe58708b000 R14: 0000000000006b51 R15: 0000558de021a420
     Modules linked in: dm_log_writes ...
     ---[ end trace c92a7f447a8515f5 ]---
    
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f2f2864f5978..f8ec2d8606fd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1133,9 +1133,12 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	root->log_transid = 0;
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;
-	if (!dummy)
+	if (!dummy) {
 		extent_io_tree_init(fs_info, &root->dirty_log_pages,
 				    IO_TREE_ROOT_DIRTY_LOG_PAGES, NULL);
+		extent_io_tree_init(fs_info, &root->log_csum_range,
+				    IO_TREE_LOG_CSUM_RANGE, NULL);
+	}
 
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));

commit 56e9357a1e8167134388d4c70654795353765c7b
Author: David Sterba <dsterba@suse.com>
Date:   Fri May 15 19:35:55 2020 +0200

    btrfs: simplify root lookup by id
    
    The main function to lookup a root by its id btrfs_get_fs_root takes the
    whole key, while only using the objectid. The value of offset is preset
    to (u64)-1 but not actually used until btrfs_find_root that does the
    actual search.
    
    Switch btrfs_get_fs_root to use only objectid and remove all local
    variables that existed just for the lookup. The actual key for search is
    set up in btrfs_get_fs_root, reusing another key variable.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7b66a8e4ca54..f2f2864f5978 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1534,35 +1534,34 @@ void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
 
 
 struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
-				     struct btrfs_key *location,
-				     bool check_ref)
+				     u64 objectid, bool check_ref)
 {
 	struct btrfs_root *root;
 	struct btrfs_path *path;
 	struct btrfs_key key;
 	int ret;
 
-	if (location->objectid == BTRFS_ROOT_TREE_OBJECTID)
+	if (objectid == BTRFS_ROOT_TREE_OBJECTID)
 		return btrfs_grab_root(fs_info->tree_root);
-	if (location->objectid == BTRFS_EXTENT_TREE_OBJECTID)
+	if (objectid == BTRFS_EXTENT_TREE_OBJECTID)
 		return btrfs_grab_root(fs_info->extent_root);
-	if (location->objectid == BTRFS_CHUNK_TREE_OBJECTID)
+	if (objectid == BTRFS_CHUNK_TREE_OBJECTID)
 		return btrfs_grab_root(fs_info->chunk_root);
-	if (location->objectid == BTRFS_DEV_TREE_OBJECTID)
+	if (objectid == BTRFS_DEV_TREE_OBJECTID)
 		return btrfs_grab_root(fs_info->dev_root);
-	if (location->objectid == BTRFS_CSUM_TREE_OBJECTID)
+	if (objectid == BTRFS_CSUM_TREE_OBJECTID)
 		return btrfs_grab_root(fs_info->csum_root);
-	if (location->objectid == BTRFS_QUOTA_TREE_OBJECTID)
+	if (objectid == BTRFS_QUOTA_TREE_OBJECTID)
 		return btrfs_grab_root(fs_info->quota_root) ?
 			fs_info->quota_root : ERR_PTR(-ENOENT);
-	if (location->objectid == BTRFS_UUID_TREE_OBJECTID)
+	if (objectid == BTRFS_UUID_TREE_OBJECTID)
 		return btrfs_grab_root(fs_info->uuid_root) ?
 			fs_info->uuid_root : ERR_PTR(-ENOENT);
-	if (location->objectid == BTRFS_FREE_SPACE_TREE_OBJECTID)
+	if (objectid == BTRFS_FREE_SPACE_TREE_OBJECTID)
 		return btrfs_grab_root(fs_info->free_space_root) ?
 			fs_info->free_space_root : ERR_PTR(-ENOENT);
 again:
-	root = btrfs_lookup_fs_root(fs_info, location->objectid);
+	root = btrfs_lookup_fs_root(fs_info, objectid);
 	if (root) {
 		if (check_ref && btrfs_root_refs(&root->root_item) == 0) {
 			btrfs_put_root(root);
@@ -1571,7 +1570,10 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 		return root;
 	}
 
-	root = btrfs_read_tree_root(fs_info->tree_root, location);
+	key.objectid = objectid;
+	key.type = BTRFS_ROOT_ITEM_KEY;
+	key.offset = (u64)-1;
+	root = btrfs_read_tree_root(fs_info->tree_root, &key);
 	if (IS_ERR(root))
 		return root;
 
@@ -1591,7 +1593,7 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	}
 	key.objectid = BTRFS_ORPHAN_OBJECTID;
 	key.type = BTRFS_ORPHAN_ITEM_KEY;
-	key.offset = location->objectid;
+	key.offset = objectid;
 
 	ret = btrfs_search_slot(NULL, fs_info->tree_root, &key, path, 0, 0);
 	btrfs_free_path(path);
@@ -2293,8 +2295,8 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info)
 	 * This tree can share blocks with some other fs tree during relocation
 	 * and we need a proper setup by btrfs_get_fs_root
 	 */
-	location.objectid = BTRFS_DATA_RELOC_TREE_OBJECTID;
-	root = btrfs_get_fs_root(tree_root->fs_info, &location, true);
+	root = btrfs_get_fs_root(tree_root->fs_info,
+				 BTRFS_DATA_RELOC_TREE_OBJECTID, true);
 	if (IS_ERR(root)) {
 		ret = PTR_ERR(root);
 		goto out;
@@ -2839,7 +2841,6 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	u64 generation;
 	u64 features;
 	u16 csum_type;
-	struct btrfs_key location;
 	struct btrfs_super_block *disk_super;
 	struct btrfs_fs_info *fs_info = btrfs_sb(sb);
 	struct btrfs_root *tree_root;
@@ -3253,11 +3254,7 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 		}
 	}
 
-	location.objectid = BTRFS_FS_TREE_OBJECTID;
-	location.type = BTRFS_ROOT_ITEM_KEY;
-	location.offset = 0;
-
-	fs_info->fs_root = btrfs_get_fs_root(fs_info, &location, true);
+	fs_info->fs_root = btrfs_get_fs_root(fs_info, BTRFS_FS_TREE_OBJECTID, true);
 	if (IS_ERR(fs_info->fs_root)) {
 		err = PTR_ERR(fs_info->fs_root);
 		btrfs_warn(fs_info, "failed to read fs tree: %d", err);

commit 1dae7e0e58b484eaa43d530f211098fdeeb0f404
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed May 20 14:58:51 2020 +0800

    btrfs: reloc: clear DEAD_RELOC_TREE bit for orphan roots to prevent runaway balance
    
    [BUG]
    There are several reported runaway balance, that balance is flooding the
    log with "found X extents" where the X never changes.
    
    [CAUSE]
    Commit d2311e698578 ("btrfs: relocation: Delay reloc tree deletion after
    merge_reloc_roots") introduced BTRFS_ROOT_DEAD_RELOC_TREE bit to
    indicate that one subvolume has finished its tree blocks swap with its
    reloc tree.
    
    However if balance is canceled or hits ENOSPC halfway, we didn't clear
    the BTRFS_ROOT_DEAD_RELOC_TREE bit, leaving that bit hanging forever
    until unmount.
    
    Any subvolume root with that bit, would cause backref cache to skip this
    tree block, as it has finished its tree block swap.  This would cause
    all tree blocks of that root be ignored by balance, leading to runaway
    balance.
    
    [FIX]
    Fix the problem by also clearing the BTRFS_ROOT_DEAD_RELOC_TREE bit for
    the original subvolume of orphan reloc root.
    
    Add an umount check for the stale bit still set.
    
    Fixes: d2311e698578 ("btrfs: relocation: Delay reloc tree deletion after merge_reloc_roots")
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f1143741f6ba..7b66a8e4ca54 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1994,6 +1994,7 @@ void btrfs_put_root(struct btrfs_root *root)
 
 	if (refcount_dec_and_test(&root->refs)) {
 		WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
+		WARN_ON(test_bit(BTRFS_ROOT_DEAD_RELOC_TREE, &root->state));
 		if (root->anon_dev)
 			free_anon_bdev(root->anon_dev);
 		btrfs_drew_lock_destroy(&root->snapshot_lock);

commit aeb935a455812e0ec15e15801f7a42d887e6c22f
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri May 15 14:01:42 2020 +0800

    btrfs: don't set SHAREABLE flag for data reloc tree
    
    SHAREABLE flag is set for subvolumes because users can create snapshot
    for subvolumes, thus sharing tree blocks of them.
    
    But data reloc tree is not exposed to user space, as it's only an
    internal tree for data relocation, thus it doesn't need the full path
    replacement handling at all.
    
    This patch will make data reloc tree a non-shareable tree, and add
    btrfs_fs_info::data_reloc_root for data reloc tree, so relocation code
    can grab it from fs_info directly.
    
    This would slightly improve tree relocation, as now data reloc tree
    can go through regular COW routine to get relocated, without bothering
    the complex tree reloc tree routine.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 248086cca124..f1143741f6ba 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1417,7 +1417,8 @@ static int btrfs_init_fs_root(struct btrfs_root *root)
 	if (ret)
 		goto fail;
 
-	if (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {
+	if (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID &&
+	    root->root_key.objectid != BTRFS_DATA_RELOC_TREE_OBJECTID) {
 		set_bit(BTRFS_ROOT_SHAREABLE, &root->state);
 		btrfs_check_and_init_root_item(&root->root_item);
 	}
@@ -1523,6 +1524,7 @@ void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
 	btrfs_put_root(fs_info->uuid_root);
 	btrfs_put_root(fs_info->free_space_root);
 	btrfs_put_root(fs_info->fs_root);
+	btrfs_put_root(fs_info->data_reloc_root);
 	btrfs_check_leaked_roots(fs_info);
 	btrfs_extent_buffer_leak_debug_check(fs_info);
 	kfree(fs_info->super_copy);
@@ -1979,6 +1981,7 @@ static void free_root_pointers(struct btrfs_fs_info *info, bool free_chunk_root)
 	free_root_extent_buffers(info->quota_root);
 	free_root_extent_buffers(info->uuid_root);
 	free_root_extent_buffers(info->fs_root);
+	free_root_extent_buffers(info->data_reloc_root);
 	if (free_chunk_root)
 		free_root_extent_buffers(info->chunk_root);
 	free_root_extent_buffers(info->free_space_root);
@@ -2285,6 +2288,19 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info)
 	set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
 	fs_info->csum_root = root;
 
+	/*
+	 * This tree can share blocks with some other fs tree during relocation
+	 * and we need a proper setup by btrfs_get_fs_root
+	 */
+	location.objectid = BTRFS_DATA_RELOC_TREE_OBJECTID;
+	root = btrfs_get_fs_root(tree_root->fs_info, &location, true);
+	if (IS_ERR(root)) {
+		ret = PTR_ERR(root);
+		goto out;
+	}
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
+	fs_info->data_reloc_root = root;
+
 	location.objectid = BTRFS_QUOTA_TREE_OBJECTID;
 	root = btrfs_read_tree_root(tree_root, &location);
 	if (!IS_ERR(root)) {

commit 92a7cc4252231d1641b36c38cf845cfc50308ab0
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri May 15 14:01:40 2020 +0800

    btrfs: rename BTRFS_ROOT_REF_COWS to BTRFS_ROOT_SHAREABLE
    
    The name BTRFS_ROOT_REF_COWS is not very clear about the meaning.
    
    In fact, that bit can only be set to those trees:
    
    - Subvolume roots
    - Data reloc root
    - Reloc roots for above roots
    
    All other trees won't get this bit set.  So just by the result, it is
    obvious that, roots with this bit set can have tree blocks shared with
    other trees.  Either shared by snapshots, or by reloc roots (an special
    snapshot created by relocation).
    
    This patch will rename BTRFS_ROOT_REF_COWS to BTRFS_ROOT_SHAREABLE to
    make it easier to understand, and update all comment mentioning
    "reference counted" to follow the rename.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 714b57553ed6..248086cca124 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1273,12 +1273,13 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	root->root_key.offset = BTRFS_TREE_LOG_OBJECTID;
 
 	/*
-	 * DON'T set REF_COWS for log trees
+	 * DON'T set SHAREABLE bit for log trees.
 	 *
-	 * log trees do not get reference counted because they go away
-	 * before a real commit is actually done.  They do store pointers
-	 * to file data extents, and those reference counts still get
-	 * updated (along with back refs to the log tree).
+	 * Log trees are not exposed to user space thus can't be snapshotted,
+	 * and they go away before a real commit is actually done.
+	 *
+	 * They do store pointers to file data extents, and those reference
+	 * counts still get updated (along with back refs to the log tree).
 	 */
 
 	leaf = btrfs_alloc_tree_block(trans, root, 0, BTRFS_TREE_LOG_OBJECTID,
@@ -1417,7 +1418,7 @@ static int btrfs_init_fs_root(struct btrfs_root *root)
 		goto fail;
 
 	if (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {
-		set_bit(BTRFS_ROOT_REF_COWS, &root->state);
+		set_bit(BTRFS_ROOT_SHAREABLE, &root->state);
 		btrfs_check_and_init_root_item(&root->root_item);
 	}
 

commit fd08001f17c7f0a5b19bf4026bbaace19d8fbdb6
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Apr 30 23:51:59 2020 -0700

    btrfs: use crypto_shash_digest() instead of open coding
    
    Use crypto_shash_digest() instead of crypto_shash_init() +
    crypto_shash_update() + crypto_shash_final().  This is more efficient.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8ad451695d49..714b57553ed6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -358,16 +358,14 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 	SHASH_DESC_ON_STACK(shash, fs_info->csum_shash);
 
 	shash->tfm = fs_info->csum_shash;
-	crypto_shash_init(shash);
 
 	/*
 	 * The super_block structure does not span the whole
 	 * BTRFS_SUPER_INFO_SIZE range, we expect that the unused space is
 	 * filled with zeros and is included in the checksum.
 	 */
-	crypto_shash_update(shash, raw_disk_sb + BTRFS_CSUM_SIZE,
-			    BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
-	crypto_shash_final(shash, result);
+	crypto_shash_digest(shash, raw_disk_sb + BTRFS_CSUM_SIZE,
+			    BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE, result);
 
 	if (memcmp(disk_sb->csum, result, btrfs_super_csum_size(disk_sb)))
 		return 1;
@@ -3504,10 +3502,9 @@ static int write_dev_supers(struct btrfs_device *device,
 
 		btrfs_set_super_bytenr(sb, bytenr);
 
-		crypto_shash_init(shash);
-		crypto_shash_update(shash, (const char *)sb + BTRFS_CSUM_SIZE,
-				    BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
-		crypto_shash_final(shash, sb->csum);
+		crypto_shash_digest(shash, (const char *)sb + BTRFS_CSUM_SIZE,
+				    BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE,
+				    sb->csum);
 
 		page = find_or_create_page(mapping, bytenr >> PAGE_SHIFT,
 					   GFP_NOFS);

commit 5c047a699aa9433ad92136343a9306d985134c24
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Apr 16 14:46:24 2020 -0700

    btrfs: get rid of endio_repair_workers
    
    This was originally added in commit 8b110e393c5a ("Btrfs: implement
    repair function when direct read fails") to avoid a deadlock. In that
    commit, the direct I/O read endio executes on the endio_workers
    workqueue, submits a repair bio, and waits for it to complete. The
    repair bio endio must execute on a different workqueue, otherwise it
    could block on the endio_workers workqueue becoming available, which
    won't happen because the original endio is blocked on the repair bio.
    
    As of the previous commit, the original endio doesn't wait for the
    repair bio, so this separate workqueue is unnecessary.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d10c7be10f3b..8ad451695d49 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -709,9 +709,7 @@ static void end_workqueue_bio(struct bio *bio)
 		else
 			wq = fs_info->endio_write_workers;
 	} else {
-		if (unlikely(end_io_wq->metadata == BTRFS_WQ_ENDIO_DIO_REPAIR))
-			wq = fs_info->endio_repair_workers;
-		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
+		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
 			wq = fs_info->endio_raid56_workers;
 		else if (end_io_wq->metadata)
 			wq = fs_info->endio_meta_workers;
@@ -1942,7 +1940,6 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->workers);
 	btrfs_destroy_workqueue(fs_info->endio_workers);
 	btrfs_destroy_workqueue(fs_info->endio_raid56_workers);
-	btrfs_destroy_workqueue(fs_info->endio_repair_workers);
 	btrfs_destroy_workqueue(fs_info->rmw_workers);
 	btrfs_destroy_workqueue(fs_info->endio_write_workers);
 	btrfs_destroy_workqueue(fs_info->endio_freespace_worker);
@@ -2145,8 +2142,6 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 	fs_info->endio_raid56_workers =
 		btrfs_alloc_workqueue(fs_info, "endio-raid56", flags,
 				      max_active, 4);
-	fs_info->endio_repair_workers =
-		btrfs_alloc_workqueue(fs_info, "endio-repair", flags, 1, 0);
 	fs_info->rmw_workers =
 		btrfs_alloc_workqueue(fs_info, "rmw", flags, max_active, 2);
 	fs_info->endio_write_workers =
@@ -2170,7 +2165,6 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 	      fs_info->flush_workers &&
 	      fs_info->endio_workers && fs_info->endio_meta_workers &&
 	      fs_info->endio_meta_write_workers &&
-	      fs_info->endio_repair_workers &&
 	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
 	      fs_info->caching_workers && fs_info->readahead_workers &&

commit ef67963dac255b293e19815ea3d440567be4626f
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Tue Mar 24 10:47:52 2020 -0400

    btrfs: drop logs when we've aborted a transaction
    
    Dave reported a problem where we were panicing with generic/475 with
    misc-5.7.  This is because we were doing IO after we had stopped all of
    the worker threads, because we do the log tree cleanup on roots at drop
    time.  Cleaning up the log tree will always need to do reads if we
    happened to have evicted the blocks from memory.
    
    Because of this simply add a helper to btrfs_cleanup_transaction() that
    will go through and drop all of the log roots.  This gets run before we
    do the close_ctree() work, and thus we are allowed to do any reads that
    we would need.  I ran this through many iterations of generic/475 with
    constrained memory and I did not see the issue.
    
      general protection fault, probably for non-canonical address 0x6b6b6b6b6b6b6b6b: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC PTI
      CPU: 2 PID: 12359 Comm: umount Tainted: G        W 5.6.0-rc7-btrfs-next-58 #1
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.12.0-59-gc9ba5276e321-prebuilt.qemu.org 04/01/2014
      RIP: 0010:btrfs_queue_work+0x33/0x1c0 [btrfs]
      RSP: 0018:ffff9cfb015937d8 EFLAGS: 00010246
      RAX: 0000000000000000 RBX: ffff8eb5e339ed80 RCX: 0000000000000000
      RDX: 0000000000000001 RSI: ffff8eb5eb33b770 RDI: ffff8eb5e37a0460
      RBP: ffff8eb5eb33b770 R08: 000000000000020c R09: ffffffff9fc09ac0
      R10: 0000000000000007 R11: 0000000000000000 R12: 6b6b6b6b6b6b6b6b
      R13: ffff9cfb00229040 R14: 0000000000000008 R15: ffff8eb5d3868000
      FS:  00007f167ea022c0(0000) GS:ffff8eb5fae00000(0000) knlGS:0000000000000000
      CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      CR2: 00007f167e5e0cb1 CR3: 0000000138c18004 CR4: 00000000003606e0
      DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      Call Trace:
       btrfs_end_bio+0x81/0x130 [btrfs]
       __split_and_process_bio+0xaf/0x4e0 [dm_mod]
       ? percpu_counter_add_batch+0xa3/0x120
       dm_process_bio+0x98/0x290 [dm_mod]
       ? generic_make_request+0xfb/0x410
       dm_make_request+0x4d/0x120 [dm_mod]
       ? generic_make_request+0xfb/0x410
       generic_make_request+0x12a/0x410
       ? submit_bio+0x38/0x160
       submit_bio+0x38/0x160
       ? percpu_counter_add_batch+0xa3/0x120
       btrfs_map_bio+0x289/0x570 [btrfs]
       ? kmem_cache_alloc+0x24d/0x300
       btree_submit_bio_hook+0x79/0xc0 [btrfs]
       submit_one_bio+0x31/0x50 [btrfs]
       read_extent_buffer_pages+0x2fe/0x450 [btrfs]
       btree_read_extent_buffer_pages+0x7e/0x170 [btrfs]
       walk_down_log_tree+0x343/0x690 [btrfs]
       ? walk_log_tree+0x3d/0x380 [btrfs]
       walk_log_tree+0xf7/0x380 [btrfs]
       ? plist_requeue+0xf0/0xf0
       ? delete_node+0x4b/0x230
       free_log_tree+0x4c/0x130 [btrfs]
       ? wait_log_commit+0x140/0x140 [btrfs]
       btrfs_free_log+0x17/0x30 [btrfs]
       btrfs_drop_and_free_fs_root+0xb0/0xd0 [btrfs]
       btrfs_free_fs_roots+0x10c/0x190 [btrfs]
       ? do_raw_spin_unlock+0x49/0xc0
       ? _raw_spin_unlock+0x29/0x40
       ? release_extent_buffer+0x121/0x170 [btrfs]
       close_ctree+0x289/0x2e6 [btrfs]
       generic_shutdown_super+0x6c/0x110
       kill_anon_super+0xe/0x30
       btrfs_kill_super+0x12/0x20 [btrfs]
       deactivate_locked_super+0x3a/0x70
    
    Reported-by: David Sterba <dsterba@suse.com>
    Fixes: 8c38938c7bb096 ("btrfs: move the root freeing stuff into btrfs_put_root")
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a6cb5cbbdb9f..d10c7be10f3b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2036,9 +2036,6 @@ void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
 		for (i = 0; i < ret; i++)
 			btrfs_drop_and_free_fs_root(fs_info, gang[i]);
 	}
-
-	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
-		btrfs_free_log_root_tree(NULL, fs_info);
 }
 
 static void btrfs_init_scrub(struct btrfs_fs_info *fs_info)
@@ -3888,7 +3885,7 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 
 	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state)) {
-		btrfs_free_log(NULL, root);
+		ASSERT(root->log_root == NULL);
 		if (root->reloc_root) {
 			btrfs_put_root(root->reloc_root);
 			root->reloc_root = NULL;
@@ -4211,6 +4208,36 @@ static void btrfs_error_commit_super(struct btrfs_fs_info *fs_info)
 	up_write(&fs_info->cleanup_work_sem);
 }
 
+static void btrfs_drop_all_logs(struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_root *gang[8];
+	u64 root_objectid = 0;
+	int ret;
+
+	spin_lock(&fs_info->fs_roots_radix_lock);
+	while ((ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,
+					     (void **)gang, root_objectid,
+					     ARRAY_SIZE(gang))) != 0) {
+		int i;
+
+		for (i = 0; i < ret; i++)
+			gang[i] = btrfs_grab_root(gang[i]);
+		spin_unlock(&fs_info->fs_roots_radix_lock);
+
+		for (i = 0; i < ret; i++) {
+			if (!gang[i])
+				continue;
+			root_objectid = gang[i]->root_key.objectid;
+			btrfs_free_log(NULL, gang[i]);
+			btrfs_put_root(gang[i]);
+		}
+		root_objectid++;
+		spin_lock(&fs_info->fs_roots_radix_lock);
+	}
+	spin_unlock(&fs_info->fs_roots_radix_lock);
+	btrfs_free_log_root_tree(NULL, fs_info);
+}
+
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root)
 {
 	struct btrfs_ordered_extent *ordered;
@@ -4603,6 +4630,7 @@ static int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_delayed_inodes(fs_info);
 	btrfs_assert_delayed_root_empty(fs_info);
 	btrfs_destroy_all_delalloc_inodes(fs_info);
+	btrfs_drop_all_logs(fs_info);
 	mutex_unlock(&fs_info->transaction_kthread_mutex);
 
 	return 0;

commit c75e839414d3610e6487ae3145199c500d55f7f7
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:47 2020 -0500

    btrfs: kill the subvol_srcu
    
    Now that we have proper root ref counting everywhere we can kill the
    subvol_srcu.
    
    * removal of fs_info::subvol_srcu reduces size of fs_info by 1176 bytes
    
    * the refcount_t used for the references checks for accidental 0->1
      in cases where the root lifetime would not be properly protected
    
    * there's a leak detector for roots to catch unfreed roots at umount
      time
    
    * SRCU served us well over the years but is was not a proper
      synchronization mechanism for some cases
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4d3eba909664..a6cb5cbbdb9f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2757,46 +2757,33 @@ static int init_mount_fs_info(struct btrfs_fs_info *fs_info, struct super_block
 	sb->s_blocksize = BTRFS_BDEV_BLOCKSIZE;
 	sb->s_blocksize_bits = blksize_bits(BTRFS_BDEV_BLOCKSIZE);
 
-	ret = init_srcu_struct(&fs_info->subvol_srcu);
-	if (ret)
-		return ret;
-
 	ret = percpu_counter_init(&fs_info->dio_bytes, 0, GFP_KERNEL);
 	if (ret)
-		goto fail;
+		return ret;
 
 	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0, GFP_KERNEL);
 	if (ret)
-		goto fail;
+		return ret;
 
 	fs_info->dirty_metadata_batch = PAGE_SIZE *
 					(1 + ilog2(nr_cpu_ids));
 
 	ret = percpu_counter_init(&fs_info->delalloc_bytes, 0, GFP_KERNEL);
 	if (ret)
-		goto fail;
+		return ret;
 
 	ret = percpu_counter_init(&fs_info->dev_replace.bio_counter, 0,
 			GFP_KERNEL);
 	if (ret)
-		goto fail;
+		return ret;
 
 	fs_info->delayed_root = kmalloc(sizeof(struct btrfs_delayed_root),
 					GFP_KERNEL);
-	if (!fs_info->delayed_root) {
-		ret = -ENOMEM;
-		goto fail;
-	}
+	if (!fs_info->delayed_root)
+		return -ENOMEM;
 	btrfs_init_delayed_root(fs_info->delayed_root);
 
-	ret = btrfs_alloc_stripe_hash_table(fs_info);
-	if (ret)
-		goto fail;
-
-	return 0;
-fail:
-	cleanup_srcu_struct(&fs_info->subvol_srcu);
-	return ret;
+	return btrfs_alloc_stripe_hash_table(fs_info);
 }
 
 static int btrfs_uuid_rescan_kthread(void *data)
@@ -2870,13 +2857,13 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	fs_info->chunk_root = chunk_root;
 	if (!tree_root || !chunk_root) {
 		err = -ENOMEM;
-		goto fail_srcu;
+		goto fail;
 	}
 
 	fs_info->btree_inode = new_inode(sb);
 	if (!fs_info->btree_inode) {
 		err = -ENOMEM;
-		goto fail_srcu;
+		goto fail;
 	}
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 	btrfs_init_btree_inode(fs_info);
@@ -3398,8 +3385,6 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
 	iput(fs_info->btree_inode);
-fail_srcu:
-	cleanup_srcu_struct(&fs_info->subvol_srcu);
 fail:
 	btrfs_close_devices(fs_info->fs_devices);
 	return err;
@@ -3902,9 +3887,6 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 		drop_ref = true;
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 
-	if (btrfs_root_refs(&root->root_item) == 0)
-		synchronize_srcu(&fs_info->subvol_srcu);
-
 	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state)) {
 		btrfs_free_log(NULL, root);
 		if (root->reloc_root) {
@@ -4116,7 +4098,6 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)
 
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 	btrfs_close_devices(fs_info->fs_devices);
-	cleanup_srcu_struct(&fs_info->subvol_srcu);
 }
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,

commit efc3453494af78180ac00d9dd8391fd52c4a921e
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:46 2020 -0500

    btrfs: make btrfs_cleanup_fs_roots use the radix tree lock
    
    The radix root is primarily protected by the fs_roots_radix_lock, so use
    that to lookup and get a ref on all of our fs roots in
    btrfs_cleanup_fs_roots. The tree reference is taken in the protected
    section as before.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3a6d35e1edb7..4d3eba909664 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3932,15 +3932,14 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 	int i = 0;
 	int err = 0;
 	unsigned int ret = 0;
-	int index;
 
 	while (1) {
-		index = srcu_read_lock(&fs_info->subvol_srcu);
+		spin_lock(&fs_info->fs_roots_radix_lock);
 		ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,
 					     (void **)gang, root_objectid,
 					     ARRAY_SIZE(gang));
 		if (!ret) {
-			srcu_read_unlock(&fs_info->subvol_srcu, index);
+			spin_unlock(&fs_info->fs_roots_radix_lock);
 			break;
 		}
 		root_objectid = gang[ret - 1]->root_key.objectid + 1;
@@ -3954,7 +3953,7 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 			/* grab all the search result for later use */
 			gang[i] = btrfs_grab_root(gang[i]);
 		}
-		srcu_read_unlock(&fs_info->subvol_srcu, index);
+		spin_unlock(&fs_info->fs_roots_radix_lock);
 
 		for (i = 0; i < ret; i++) {
 			if (!gang[i])

commit 4785e24fa5d23b05bc0f579e10aeb44c4a0a2a3d
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:45 2020 -0500

    btrfs: don't take an extra root ref at allocation time
    
    Now that all the users of roots take references for them we can drop the
    extra root ref we've been taking.  Before we had roots at 2 refs for the
    life of the file system, one for the radix tree, and one simply for
    existing.  Now that we have proper ref accounting in all places that use
    roots we can drop this extra ref simply for existing as we no longer
    need it.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 831755a867ce..3a6d35e1edb7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1601,22 +1601,11 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	if (ret == 0)
 		set_bit(BTRFS_ROOT_ORPHAN_ITEM_INSERTED, &root->state);
 
-	/*
-	 * All roots have two refs on them at all times, one for the mounted fs,
-	 * and one for being in the radix tree.  This way we only free the root
-	 * when we are unmounting or deleting the subvolume.  We get one ref
-	 * from __setup_root, one for inserting it into the radix tree, and then
-	 * we have the third for returning it, and the caller will put it when
-	 * it's done with the root.
-	 */
-	btrfs_grab_root(root);
 	ret = btrfs_insert_fs_root(fs_info, root);
 	if (ret) {
 		btrfs_put_root(root);
-		if (ret == -EEXIST) {
-			btrfs_put_root(root);
+		if (ret == -EEXIST)
 			goto again;
-		}
 		goto fail;
 	}
 	return root;
@@ -3904,11 +3893,13 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 				  struct btrfs_root *root)
 {
+	bool drop_ref = false;
+
 	spin_lock(&fs_info->fs_roots_radix_lock);
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
 	if (test_and_clear_bit(BTRFS_ROOT_IN_RADIX, &root->state))
-		btrfs_put_root(root);
+		drop_ref = true;
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 
 	if (btrfs_root_refs(&root->root_item) == 0)
@@ -3930,7 +3921,8 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 		iput(root->ino_cache_inode);
 		root->ino_cache_inode = NULL;
 	}
-	btrfs_put_root(root);
+	if (drop_ref)
+		btrfs_put_root(root);
 }
 
 int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)

commit dc9492c14c758639d7b2468d4ed3c77e785c1a35
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:44 2020 -0500

    btrfs: hold a ref on the root on the dead roots list
    
    At the point we add a root to the dead roots list we have no open inodes
    for that root, so we need to hold a ref on that root to keep it from
    disappearing.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5db76264b07f..831755a867ce 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2035,8 +2035,7 @@ void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
 
 		if (test_bit(BTRFS_ROOT_IN_RADIX, &gang[0]->state))
 			btrfs_drop_and_free_fs_root(fs_info, gang[0]);
-		else
-			btrfs_put_root(gang[0]);
+		btrfs_put_root(gang[0]);
 	}
 
 	while (1) {

commit 5c8fd99fec9d9265ed8fb732120a2ffd2bbab9b8
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:43 2020 -0500

    btrfs: make inodes hold a ref on their roots
    
    If we make sure all the inodes have refs on their root we don't have to
    worry about the root disappearing while we have open inodes.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 242c072d69a7..5db76264b07f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2096,7 +2096,7 @@ static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info)
 
 	BTRFS_I(inode)->io_tree.ops = &btree_extent_io_ops;
 
-	BTRFS_I(inode)->root = fs_info->tree_root;
+	BTRFS_I(inode)->root = btrfs_grab_root(fs_info->tree_root);
 	memset(&BTRFS_I(inode)->location, 0, sizeof(struct btrfs_key));
 	set_bit(BTRFS_INODE_DUMMY, &BTRFS_I(inode)->runtime_flags);
 	btrfs_insert_inode_hash(inode);

commit 8c38938c7bb096313ad00c2bafa82af37636b0ec
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:42 2020 -0500

    btrfs: move the root freeing stuff into btrfs_put_root
    
    There are a few different ways to free roots, either you allocated them
    yourself and you just do
    
    free_extent_buffer(root->node);
    free_extent_buffer(root->commit_node);
    btrfs_put_root(root);
    
    Which is the pattern for log roots.  Or for snapshots/subvolumes that
    are being dropped you simply call btrfs_free_fs_root() which does all
    the cleanup for you.
    
    Unify this all into btrfs_put_root(), so that we don't free up things
    associated with the root until the last reference is dropped.  This
    makes the root freeing code much more significant.
    
    The only caveat is at close_ctree() time we have to free the extent
    buffers for all of our main roots (extent_root, chunk_root, etc) because
    we have to drop the btree_inode and we'll run into issues if we hold
    onto those nodes until ->kill_sb() time.  This will be addressed in the
    future when we kill the btree_inode.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 37418d1d0820..242c072d69a7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1255,11 +1255,8 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	return root;
 
 fail:
-	if (leaf) {
+	if (leaf)
 		btrfs_tree_unlock(leaf);
-		free_extent_buffer(root->commit_root);
-		free_extent_buffer(leaf);
-	}
 	btrfs_put_root(root);
 
 	return ERR_PTR(ret);
@@ -1382,10 +1379,10 @@ struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 				     generation, level, NULL);
 	if (IS_ERR(root->node)) {
 		ret = PTR_ERR(root->node);
+		root->node = NULL;
 		goto find_fail;
 	} else if (!btrfs_buffer_uptodate(root->node, generation, 0)) {
 		ret = -EIO;
-		free_extent_buffer(root->node);
 		goto find_fail;
 	}
 	root->commit_root = btrfs_root_node(root);
@@ -1617,14 +1614,14 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	if (ret) {
 		btrfs_put_root(root);
 		if (ret == -EEXIST) {
-			btrfs_free_fs_root(root);
+			btrfs_put_root(root);
 			goto again;
 		}
 		goto fail;
 	}
 	return root;
 fail:
-	btrfs_free_fs_root(root);
+	btrfs_put_root(root);
 	return ERR_PTR(ret);
 }
 
@@ -1996,11 +1993,35 @@ static void free_root_pointers(struct btrfs_fs_info *info, bool free_chunk_root)
 	free_root_extent_buffers(info->csum_root);
 	free_root_extent_buffers(info->quota_root);
 	free_root_extent_buffers(info->uuid_root);
+	free_root_extent_buffers(info->fs_root);
 	if (free_chunk_root)
 		free_root_extent_buffers(info->chunk_root);
 	free_root_extent_buffers(info->free_space_root);
 }
 
+void btrfs_put_root(struct btrfs_root *root)
+{
+	if (!root)
+		return;
+
+	if (refcount_dec_and_test(&root->refs)) {
+		WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
+		if (root->anon_dev)
+			free_anon_bdev(root->anon_dev);
+		btrfs_drew_lock_destroy(&root->snapshot_lock);
+		free_extent_buffer(root->node);
+		free_extent_buffer(root->commit_root);
+		kfree(root->free_ino_ctl);
+		kfree(root->free_ino_pinned);
+#ifdef CONFIG_BTRFS_DEBUG
+		spin_lock(&root->fs_info->fs_roots_radix_lock);
+		list_del_init(&root->leak_list);
+		spin_unlock(&root->fs_info->fs_roots_radix_lock);
+#endif
+		kfree(root);
+	}
+}
+
 void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
 {
 	int ret;
@@ -2012,13 +2033,10 @@ void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
 				     struct btrfs_root, root_list);
 		list_del(&gang[0]->root_list);
 
-		if (test_bit(BTRFS_ROOT_IN_RADIX, &gang[0]->state)) {
+		if (test_bit(BTRFS_ROOT_IN_RADIX, &gang[0]->state))
 			btrfs_drop_and_free_fs_root(fs_info, gang[0]);
-		} else {
-			free_extent_buffer(gang[0]->node);
-			free_extent_buffer(gang[0]->commit_root);
+		else
 			btrfs_put_root(gang[0]);
-		}
 	}
 
 	while (1) {
@@ -2223,11 +2241,11 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	if (IS_ERR(log_tree_root->node)) {
 		btrfs_warn(fs_info, "failed to read log tree");
 		ret = PTR_ERR(log_tree_root->node);
+		log_tree_root->node = NULL;
 		btrfs_put_root(log_tree_root);
 		return ret;
 	} else if (!extent_buffer_uptodate(log_tree_root->node)) {
 		btrfs_err(fs_info, "failed to read log tree");
-		free_extent_buffer(log_tree_root->node);
 		btrfs_put_root(log_tree_root);
 		return -EIO;
 	}
@@ -2236,7 +2254,6 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	if (ret) {
 		btrfs_handle_fs_error(fs_info, ret,
 				      "Failed to recover log tree");
-		free_extent_buffer(log_tree_root->node);
 		btrfs_put_root(log_tree_root);
 		return ret;
 	}
@@ -3901,8 +3918,6 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state)) {
 		btrfs_free_log(NULL, root);
 		if (root->reloc_root) {
-			free_extent_buffer(root->reloc_root->node);
-			free_extent_buffer(root->reloc_root->commit_root);
 			btrfs_put_root(root->reloc_root);
 			root->reloc_root = NULL;
 		}
@@ -3916,19 +3931,6 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 		iput(root->ino_cache_inode);
 		root->ino_cache_inode = NULL;
 	}
-	btrfs_free_fs_root(root);
-}
-
-void btrfs_free_fs_root(struct btrfs_root *root)
-{
-	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
-	if (root->anon_dev)
-		free_anon_bdev(root->anon_dev);
-	btrfs_drew_lock_destroy(&root->snapshot_lock);
-	free_extent_buffer(root->node);
-	free_extent_buffer(root->commit_root);
-	kfree(root->free_ino_ctl);
-	kfree(root->free_ino_pinned);
 	btrfs_put_root(root);
 }
 
@@ -4093,8 +4095,6 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)
 	btrfs_sysfs_remove_mounted(fs_info);
 	btrfs_sysfs_remove_fsid(fs_info->fs_devices);
 
-	btrfs_free_fs_roots(fs_info);
-
 	btrfs_put_block_group_cache(fs_info);
 
 	/*
@@ -4106,6 +4106,7 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)
 
 	clear_bit(BTRFS_FS_OPEN, &fs_info->flags);
 	free_root_pointers(fs_info, true);
+	btrfs_free_fs_roots(fs_info);
 
 	/*
 	 * We must free the block groups after dropping the fs_roots as we could

commit 0e996e7fcf2e3a7a5d13b0ed5f9cebc551bd94ba
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:41 2020 -0500

    btrfs: move ino_cache_inode dropping out of btrfs_free_fs_root
    
    We are going to make root life be controlled soley by refcounting, and
    inodes will be one of the things that hold a ref on the root.  This
    means we need to handle dropping the ino_cache_inode outside of the root
    freeing logic, so move it into btrfs_drop_and_free_fs_root() so it is
    cleaned up properly on unmount.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 56cad6a51a7d..37418d1d0820 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3912,12 +3912,15 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 		__btrfs_remove_free_space_cache(root->free_ino_pinned);
 	if (root->free_ino_ctl)
 		__btrfs_remove_free_space_cache(root->free_ino_ctl);
+	if (root->ino_cache_inode) {
+		iput(root->ino_cache_inode);
+		root->ino_cache_inode = NULL;
+	}
 	btrfs_free_fs_root(root);
 }
 
 void btrfs_free_fs_root(struct btrfs_root *root)
 {
-	iput(root->ino_cache_inode);
 	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
 	if (root->anon_dev)
 		free_anon_bdev(root->anon_dev);

commit 3fd6372758d91d8ba801e0733b17d082066a04ef
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 16:11:40 2020 -0500

    btrfs: make the extent buffer leak check per fs info
    
    I'm going to make the entire destruction of btrfs_root's controlled by
    their refcount, so it will be helpful to notice if we're leaking their
    eb's on umount.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6b00ddea0b48..56cad6a51a7d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1530,6 +1530,7 @@ void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
 	btrfs_put_root(fs_info->free_space_root);
 	btrfs_put_root(fs_info->fs_root);
 	btrfs_check_leaked_roots(fs_info);
+	btrfs_extent_buffer_leak_debug_check(fs_info);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
 	kvfree(fs_info);
@@ -2656,6 +2657,8 @@ void btrfs_init_fs_info(struct btrfs_fs_info *fs_info)
 	INIT_LIST_HEAD(&fs_info->unused_bgs);
 #ifdef CONFIG_BTRFS_DEBUG
 	INIT_LIST_HEAD(&fs_info->allocated_roots);
+	INIT_LIST_HEAD(&fs_info->allocated_ebs);
+	spin_lock_init(&fs_info->eb_leak_lock);
 #endif
 	extent_map_tree_init(&fs_info->mapping_tree);
 	btrfs_init_block_rsv(&fs_info->global_block_rsv,

commit c67b38925b682bdd3419ff39688991b1dc7cdfb6
Author: David Sterba <dsterba@suse.com>
Date:   Thu Feb 27 21:00:49 2020 +0100

    btrfs: return void from csum_tree_block
    
    Now that csum_tree_block is not returning any errors, we can make
    csum_tree_block return void and simplify callers.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6f63cc476d1f..6b00ddea0b48 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -253,10 +253,8 @@ struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 
 /*
  * Compute the csum of a btree block and store the result to provided buffer.
- *
- * Returns error if the extent buffer cannot be mapped.
  */
-static int csum_tree_block(struct extent_buffer *buf, u8 *result)
+static void csum_tree_block(struct extent_buffer *buf, u8 *result)
 {
 	struct btrfs_fs_info *fs_info = buf->fs_info;
 	const int num_pages = fs_info->nodesize >> PAGE_SHIFT;
@@ -276,8 +274,6 @@ static int csum_tree_block(struct extent_buffer *buf, u8 *result)
 	}
 	memset(result, 0, BTRFS_CSUM_SIZE);
 	crypto_shash_final(shash, result);
-
-	return 0;
 }
 
 /*
@@ -528,8 +524,7 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 				    offsetof(struct btrfs_header, fsid),
 				    BTRFS_FSID_SIZE) == 0);
 
-	if (csum_tree_block(eb, result))
-		return -EINVAL;
+	csum_tree_block(eb, result);
 
 	if (btrfs_header_level(eb))
 		ret = btrfs_check_node(eb);
@@ -640,9 +635,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	btrfs_set_buffer_lockdep_class(btrfs_header_owner(eb),
 				       eb, found_level);
 
-	ret = csum_tree_block(eb, result);
-	if (ret)
-		goto err;
+	csum_tree_block(eb, result);
 
 	if (memcmp_extent_buffer(eb, result, 0, csum_size)) {
 		u32 val;

commit e9be5a303d271faa42b44b606fbe4d7507a7f026
Author: David Sterba <dsterba@suse.com>
Date:   Thu Feb 27 21:00:47 2020 +0100

    btrfs: simplify tree block checksumming loop
    
    Thw whole point of csum_tree_block is to iterate over all extent buffer
    pages and pass it to checksumming functions. The bytes where checksum is
    stored must be skipped, thus map_private_extent_buffer. This complicates
    further offset calculations.
    
    As the first page will be always present, checksum the relevant bytes
    unconditionally and then do a simple iteration over the remaining pages.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 483b54077d01..6f63cc476d1f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -259,38 +259,22 @@ struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 static int csum_tree_block(struct extent_buffer *buf, u8 *result)
 {
 	struct btrfs_fs_info *fs_info = buf->fs_info;
+	const int num_pages = fs_info->nodesize >> PAGE_SHIFT;
 	SHASH_DESC_ON_STACK(shash, fs_info->csum_shash);
-	unsigned long len;
-	unsigned long cur_len;
-	unsigned long offset = BTRFS_CSUM_SIZE;
 	char *kaddr;
-	unsigned long map_start;
-	unsigned long map_len;
-	int err;
+	int i;
 
 	shash->tfm = fs_info->csum_shash;
 	crypto_shash_init(shash);
+	kaddr = page_address(buf->pages[0]);
+	crypto_shash_update(shash, kaddr + BTRFS_CSUM_SIZE,
+			    PAGE_SIZE - BTRFS_CSUM_SIZE);
 
-	len = buf->len - offset;
-
-	while (len > 0) {
-		/*
-		 * Note: we don't need to check for the err == 1 case here, as
-		 * with the given combination of 'start = BTRFS_CSUM_SIZE (32)'
-		 * and 'min_len = 32' and the currently implemented mapping
-		 * algorithm we cannot cross a page boundary.
-		 */
-		err = map_private_extent_buffer(buf, offset, 32,
-					&kaddr, &map_start, &map_len);
-		if (WARN_ON(err))
-			return err;
-		cur_len = min(len, map_len - (offset - map_start));
-		crypto_shash_update(shash, kaddr + offset - map_start, cur_len);
-		len -= cur_len;
-		offset += cur_len;
+	for (i = 1; i < num_pages; i++) {
+		kaddr = page_address(buf->pages[i]);
+		crypto_shash_update(shash, kaddr, PAGE_SIZE);
 	}
 	memset(result, 0, BTRFS_CSUM_SIZE);
-
 	crypto_shash_final(shash, result);
 
 	return 0;

commit f0cc2cd70164efe8f75c5d99560f0f69969c72e4
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Feb 28 13:04:36 2020 +0000

    Btrfs: fix crash during unmount due to race with delayed inode workers
    
    During unmount we can have a job from the delayed inode items work queue
    still running, that can lead to at least two bad things:
    
    1) A crash, because the worker can try to create a transaction just
       after the fs roots were freed;
    
    2) A transaction leak, because the worker can create a transaction
       before the fs roots are freed and just after we committed the last
       transaction and after we stopped the transaction kthread.
    
    A stack trace example of the crash:
    
     [79011.691214] kernel BUG at lib/radix-tree.c:982!
     [79011.692056] invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC PTI
     [79011.693180] CPU: 3 PID: 1394 Comm: kworker/u8:2 Tainted: G        W         5.6.0-rc2-btrfs-next-54 #2
     (...)
     [79011.696789] Workqueue: btrfs-delayed-meta btrfs_work_helper [btrfs]
     [79011.697904] RIP: 0010:radix_tree_tag_set+0xe7/0x170
     (...)
     [79011.702014] RSP: 0018:ffffb3c84a317ca0 EFLAGS: 00010293
     [79011.702949] RAX: 0000000000000000 RBX: 0000000000000000 RCX: 0000000000000000
     [79011.704202] RDX: ffffb3c84a317cb0 RSI: ffffb3c84a317ca8 RDI: ffff8db3931340a0
     [79011.705463] RBP: 0000000000000005 R08: 0000000000000005 R09: ffffffff974629d0
     [79011.706756] R10: ffffb3c84a317bc0 R11: 0000000000000001 R12: ffff8db393134000
     [79011.708010] R13: ffff8db3931340a0 R14: ffff8db393134068 R15: 0000000000000001
     [79011.709270] FS:  0000000000000000(0000) GS:ffff8db3b6a00000(0000) knlGS:0000000000000000
     [79011.710699] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     [79011.711710] CR2: 00007f22c2a0a000 CR3: 0000000232ad4005 CR4: 00000000003606e0
     [79011.712958] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     [79011.714205] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     [79011.715448] Call Trace:
     [79011.715925]  record_root_in_trans+0x72/0xf0 [btrfs]
     [79011.716819]  btrfs_record_root_in_trans+0x4b/0x70 [btrfs]
     [79011.717925]  start_transaction+0xdd/0x5c0 [btrfs]
     [79011.718829]  btrfs_async_run_delayed_root+0x17e/0x2b0 [btrfs]
     [79011.719915]  btrfs_work_helper+0xaa/0x720 [btrfs]
     [79011.720773]  process_one_work+0x26d/0x6a0
     [79011.721497]  worker_thread+0x4f/0x3e0
     [79011.722153]  ? process_one_work+0x6a0/0x6a0
     [79011.722901]  kthread+0x103/0x140
     [79011.723481]  ? kthread_create_worker_on_cpu+0x70/0x70
     [79011.724379]  ret_from_fork+0x3a/0x50
     (...)
    
    The following diagram shows a sequence of steps that lead to the crash
    during ummount of the filesystem:
    
            CPU 1                                             CPU 2                                CPU 3
    
     btrfs_punch_hole()
       btrfs_btree_balance_dirty()
         btrfs_balance_delayed_items()
           --> sees
               fs_info->delayed_root->items
               with value 200, which is greater
               than
               BTRFS_DELAYED_BACKGROUND (128)
               and smaller than
               BTRFS_DELAYED_WRITEBACK (512)
           btrfs_wq_run_delayed_node()
             --> queues a job for
                 fs_info->delayed_workers to run
                 btrfs_async_run_delayed_root()
    
                                                                                                btrfs_async_run_delayed_root()
                                                                                                  --> job queued by CPU 1
    
                                                                                                  --> starts picking and running
                                                                                                      delayed nodes from the
                                                                                                      prepare_list list
    
                                                     close_ctree()
    
                                                       btrfs_delete_unused_bgs()
    
                                                       btrfs_commit_super()
    
                                                         btrfs_join_transaction()
                                                           --> gets transaction N
    
                                                         btrfs_commit_transaction(N)
                                                           --> set transaction state
                                                            to TRANTS_STATE_COMMIT_START
    
                                                                                                 btrfs_first_prepared_delayed_node()
                                                                                                   --> picks delayed node X through
                                                                                                       the prepared_list list
    
                                                           btrfs_run_delayed_items()
    
                                                             btrfs_first_delayed_node()
                                                               --> also picks delayed node X
                                                                   but through the node_list
                                                                   list
    
                                                             __btrfs_commit_inode_delayed_items()
                                                                --> runs all delayed items from
                                                                    this node and drops the
                                                                    node's item count to 0
                                                                    through call to
                                                                    btrfs_release_delayed_inode()
    
                                                             --> finishes running any remaining
                                                                 delayed nodes
    
                                                           --> finishes transaction commit
    
                                                       --> stops cleaner and transaction threads
    
                                                       btrfs_free_fs_roots()
                                                         --> frees all roots and removes them
                                                             from the radix tree
                                                             fs_info->fs_roots_radix
    
                                                                                                 btrfs_join_transaction()
                                                                                                   start_transaction()
                                                                                                     btrfs_record_root_in_trans()
                                                                                                       record_root_in_trans()
                                                                                                         radix_tree_tag_set()
                                                                                                           --> crashes because
                                                                                                               the root is not in
                                                                                                               the radix tree
                                                                                                               anymore
    
    If the worker is able to call btrfs_join_transaction() before the unmount
    task frees the fs roots, we end up leaking a transaction and all its
    resources, since after the call to btrfs_commit_super() and stopping the
    transaction kthread, we don't expect to have any transaction open anymore.
    
    When this situation happens the worker has a delayed node that has no
    more items to run, since the task calling btrfs_run_delayed_items(),
    which is doing a transaction commit, picks the same node and runs all
    its items first.
    
    We can not wait for the worker to complete when running delayed items
    through btrfs_run_delayed_items(), because we call that function in
    several phases of a transaction commit, and that could cause a deadlock
    because the worker calls btrfs_join_transaction() and the task doing the
    transaction commit may have already set the transaction state to
    TRANS_STATE_COMMIT_DOING.
    
    Also it's not possible to get into a situation where only some of the
    items of a delayed node are added to the fs/subvolume tree in the current
    transaction and the remaining ones in the next transaction, because when
    running the items of a delayed inode we lock its mutex, effectively
    waiting for the worker if the worker is running the items of the delayed
    node already.
    
    Since this can only cause issues when unmounting a filesystem, fix it in
    a simple way by waiting for any jobs on the delayed workers queue before
    calling btrfs_commit_supper() at close_ctree(). This works because at this
    point no one can call btrfs_btree_balance_dirty() or
    btrfs_balance_delayed_items(), and if we end up waiting for any worker to
    complete, btrfs_commit_super() will commit the transaction created by the
    worker.
    
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f01f19c76cf5..483b54077d01 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4067,6 +4067,19 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)
 		 */
 		btrfs_delete_unused_bgs(fs_info);
 
+		/*
+		 * There might be existing delayed inode workers still running
+		 * and holding an empty delayed inode item. We must wait for
+		 * them to complete first because they can create a transaction.
+		 * This happens when someone calls btrfs_balance_delayed_items()
+		 * and then a transaction commit runs the same delayed nodes
+		 * before any delayed worker has done something with the nodes.
+		 * We must wait for any worker here and not at transaction
+		 * commit time since that could cause a deadlock.
+		 * This is a very rare case.
+		 */
+		btrfs_flush_workqueue(fs_info->delayed_workers);
+
 		ret = btrfs_commit_super(fs_info);
 		if (ret)
 			btrfs_err(fs_info, "commit super ret %d", ret);

commit 807fc790aa804102df75b6ac0c943a4d205fc4b5
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Mon Feb 24 17:37:51 2020 +0200

    btrfs: switch to use new generic UUID API
    
    There are new types and helpers that are supposed to be used in new code.
    
    As a preparation to get rid of legacy types and API functions do
    the conversion here.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a4493e5dac22..f01f19c76cf5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1223,7 +1223,6 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	struct btrfs_key key;
 	unsigned int nofs_flag;
 	int ret = 0;
-	uuid_le uuid = NULL_UUID_LE;
 
 	/*
 	 * We're holding a transaction handle, so use a NOFS memory allocation
@@ -1262,8 +1261,9 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_root_last_snapshot(&root->root_item, 0);
 	btrfs_set_root_dirid(&root->root_item, 0);
 	if (is_fstree(objectid))
-		uuid_le_gen(&uuid);
-	memcpy(root->root_item.uuid, uuid.b, BTRFS_UUID_SIZE);
+		generate_random_guid(root->root_item.uuid);
+	else
+		export_guid(root->root_item.uuid, &guid_null);
 	root->root_item.drop_level = 0;
 
 	key.objectid = objectid;

commit 15b6e8a83e910c71e98c368e51b581135539efdf
Author: David Sterba <dsterba@suse.com>
Date:   Thu Nov 28 16:15:04 2019 +0100

    btrfs: reduce pointer intdirections in btree_readpage_end_io_hook
    
    All we need to read is checksum size from fs_info superblock, and
    fs_info is provided by extent buffer so we can get rid of the wild
    pointer indirections from page/inode/root.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f109607ff40b..a4493e5dac22 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -604,9 +604,8 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	u64 found_start;
 	int found_level;
 	struct extent_buffer *eb;
-	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
-	struct btrfs_fs_info *fs_info = root->fs_info;
-	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
+	struct btrfs_fs_info *fs_info;
+	u16 csum_size;
 	int ret = 0;
 	u8 result[BTRFS_CSUM_SIZE];
 	int reads_done;
@@ -615,6 +614,8 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 		goto out;
 
 	eb = (struct extent_buffer *)page->private;
+	fs_info = eb->fs_info;
+	csum_size = btrfs_super_csum_size(fs_info->super_copy);
 
 	/* the pending IO might have been the only thing that kept this buffer
 	 * in memory.  Make sure we have a ref for all this other checks

commit b79ce3dddd3f1be7515452adfed633d13e45d806
Author: David Sterba <dsterba@suse.com>
Date:   Thu Nov 28 15:34:28 2019 +0100

    btrfs: adjust delayed refs message level
    
    The message seems to be for debugging and has little value for users.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index abd7a613c8e6..f109607ff40b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4302,7 +4302,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 	spin_lock(&delayed_refs->lock);
 	if (atomic_read(&delayed_refs->num_entries) == 0) {
 		spin_unlock(&delayed_refs->lock);
-		btrfs_info(fs_info, "delayed_refs has NO entry");
+		btrfs_debug(fs_info, "delayed_refs has NO entry");
 		return ret;
 	}
 

commit c4ac75419826c7afc997bbe4da07ad6f963da22f
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:17:13 2019 +0100

    btrfs: open code trivial helper btrfs_header_chunk_tree_uuid
    
    The helper btrfs_header_chunk_tree_uuid follows naming convention of
    other struct accessors but does something compeletly different. As the
    offsetof calculation is clear in the context of extent buffer operations
    we can remove it.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2e482657a1b4..abd7a613c8e6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3106,7 +3106,8 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	chunk_root->commit_root = btrfs_root_node(chunk_root);
 
 	read_extent_buffer(chunk_root->node, fs_info->chunk_tree_uuid,
-	   btrfs_header_chunk_tree_uuid(chunk_root->node), BTRFS_UUID_SIZE);
+			   offsetof(struct btrfs_header, chunk_tree_uuid),
+			   BTRFS_UUID_SIZE);
 
 	ret = btrfs_read_chunk_tree(fs_info);
 	if (ret) {

commit 9a8658e33d8fd45879eebc44178b2a172e76bb47
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:15:57 2019 +0100

    btrfs: open code trivial helper btrfs_header_fsid
    
    The helper btrfs_header_fsid follows naming convention of other struct
    accessors but does something compeletly different. As the offsetof
    calculation is clear in the context of extent buffer operations we can
    remove it.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 06819c41e4f4..2e482657a1b4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -541,7 +541,8 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 		return -EUCLEAN;
 
 	ASSERT(memcmp_extent_buffer(eb, fs_info->fs_devices->metadata_uuid,
-			btrfs_header_fsid(), BTRFS_FSID_SIZE) == 0);
+				    offsetof(struct btrfs_header, fsid),
+				    BTRFS_FSID_SIZE) == 0);
 
 	if (csum_tree_block(eb, result))
 		return -EINVAL;
@@ -571,7 +572,8 @@ static int check_tree_block_fsid(struct extent_buffer *eb)
 	u8 fsid[BTRFS_FSID_SIZE];
 	int ret = 1;
 
-	read_extent_buffer(eb, fsid, btrfs_header_fsid(), BTRFS_FSID_SIZE);
+	read_extent_buffer(eb, fsid, offsetof(struct btrfs_header, fsid),
+			   BTRFS_FSID_SIZE);
 	while (fs_devices) {
 		u8 *metadata_uuid;
 

commit dcc3eb9638c3c927f1597075e851d0a16300a876
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Jan 30 14:59:45 2020 +0200

    btrfs: convert snapshot/nocow exlcusion to drew lock
    
    This patch removes all haphazard code implementing nocow writers
    exclusion from pending snapshot creation and switches to using the drew
    lock to ensure this invariant still holds.
    
    'Readers' are snapshot creators from create_snapshot and 'writers' are
    nocow writers from buffered write path or btrfs_setsize. This locking
    scheme allows for multiple snapshots to happen while any nocow writers
    are blocked, since writes to page cache in the nocow path will make
    snapshots inconsistent.
    
    So for performance reasons we'd like to have the ability to run multiple
    concurrent snapshots and also favors readers in this case. And in case
    there aren't pending snapshots (which will be the majority of the cases)
    we rely on the percpu's writers counter to avoid cacheline contention.
    
    The main gain from using the drew lock is it's now a lot easier to
    reason about the guarantees of the locking scheme and whether there is
    some silent breakage lurking.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 770d469e1d9c..06819c41e4f4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1104,32 +1104,6 @@ void btrfs_clean_tree_block(struct extent_buffer *buf)
 	}
 }
 
-static struct btrfs_subvolume_writers *btrfs_alloc_subvolume_writers(void)
-{
-	struct btrfs_subvolume_writers *writers;
-	int ret;
-
-	writers = kmalloc(sizeof(*writers), GFP_NOFS);
-	if (!writers)
-		return ERR_PTR(-ENOMEM);
-
-	ret = percpu_counter_init(&writers->counter, 0, GFP_NOFS);
-	if (ret < 0) {
-		kfree(writers);
-		return ERR_PTR(ret);
-	}
-
-	init_waitqueue_head(&writers->wait);
-	return writers;
-}
-
-static void
-btrfs_free_subvolume_writers(struct btrfs_subvolume_writers *writers)
-{
-	percpu_counter_destroy(&writers->counter);
-	kfree(writers);
-}
-
 static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 			 u64 objectid)
 {
@@ -1178,7 +1152,6 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	atomic_set(&root->log_writers, 0);
 	atomic_set(&root->log_batch, 0);
 	refcount_set(&root->refs, 1);
-	atomic_set(&root->will_be_snapshotted, 0);
 	atomic_set(&root->snapshot_force_cow, 0);
 	atomic_set(&root->nr_swapfiles, 0);
 	root->log_transid = 0;
@@ -1450,7 +1423,7 @@ struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 static int btrfs_init_fs_root(struct btrfs_root *root)
 {
 	int ret;
-	struct btrfs_subvolume_writers *writers;
+	unsigned int nofs_flag;
 
 	root->free_ino_ctl = kzalloc(sizeof(*root->free_ino_ctl), GFP_NOFS);
 	root->free_ino_pinned = kzalloc(sizeof(*root->free_ino_pinned),
@@ -1460,12 +1433,15 @@ static int btrfs_init_fs_root(struct btrfs_root *root)
 		goto fail;
 	}
 
-	writers = btrfs_alloc_subvolume_writers();
-	if (IS_ERR(writers)) {
-		ret = PTR_ERR(writers);
+	/*
+	 * We might be called under a transaction (e.g. indirect backref
+	 * resolution) which could deadlock if it triggers memory reclaim
+	 */
+	nofs_flag = memalloc_nofs_save();
+	ret = btrfs_drew_lock_init(&root->snapshot_lock);
+	memalloc_nofs_restore(nofs_flag);
+	if (ret)
 		goto fail;
-	}
-	root->subv_writers = writers;
 
 	if (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {
 		set_bit(BTRFS_ROOT_REF_COWS, &root->state);
@@ -3961,8 +3937,7 @@ void btrfs_free_fs_root(struct btrfs_root *root)
 	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
 	if (root->anon_dev)
 		free_anon_bdev(root->anon_dev);
-	if (root->subv_writers)
-		btrfs_free_subvolume_writers(root->subv_writers);
+	btrfs_drew_lock_destroy(&root->snapshot_lock);
 	free_extent_buffer(root->node);
 	free_extent_buffer(root->commit_root);
 	kfree(root->free_ino_ctl);

commit 75ec1db8717a8f0a9d9c8d033e542fdaa7b73898
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 15:22:06 2020 -0500

    btrfs: set update the uuid generation as soon as possible
    
    In my EIO stress testing I noticed I was getting forced to rescan the
    uuid tree pretty often, which was weird.  This is because my error
    injection stuff would sometimes inject an error after log replay but
    before we loaded the UUID tree.  If log replay committed the transaction
    it wouldn't have updated the uuid tree generation, but the tree was
    valid and didn't change, so there's no reason to not update the
    generation here.
    
    Fix this by setting the BTRFS_FS_UPDATE_UUID_TREE_GEN bit immediately
    after reading all the fs roots if the uuid tree generation matches the
    fs generation.  Then any transaction commits that happen during mount
    won't screw up our uuid tree state, forcing us to do needless uuid
    rescans.
    
    Fixes: 70f801754728 ("Btrfs: check UUID tree during mount if required")
    CC: stable@vger.kernel.org # 4.19+
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 864ffc6c81c1..770d469e1d9c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3151,6 +3151,18 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	if (ret)
 		goto fail_tree_roots;
 
+	/*
+	 * If we have a uuid root and we're not being told to rescan we need to
+	 * check the generation here so we can set the
+	 * BTRFS_FS_UPDATE_UUID_TREE_GEN bit.  Otherwise we could commit the
+	 * transaction during a balance or the log replay without updating the
+	 * uuid generation, and then if we crash we would rescan the uuid tree,
+	 * even though it was perfectly fine.
+	 */
+	if (fs_info->uuid_root && !btrfs_test_opt(fs_info, RESCAN_UUID_TREE) &&
+	    fs_info->generation == btrfs_super_uuid_tree_generation(disk_super))
+		set_bit(BTRFS_FS_UPDATE_UUID_TREE_GEN, &fs_info->flags);
+
 	ret = btrfs_verify_dev_extents(fs_info);
 	if (ret) {
 		btrfs_err(fs_info,
@@ -3375,8 +3387,6 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 			close_ctree(fs_info);
 			return ret;
 		}
-	} else {
-		set_bit(BTRFS_FS_UPDATE_UUID_TREE_GEN, &fs_info->flags);
 	}
 	set_bit(BTRFS_FS_OPEN, &fs_info->flags);
 

commit c94bec2c6190a5d13f59c0f36a660be5e2d85644
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Feb 14 15:05:01 2020 -0500

    btrfs: bail out of uuid tree scanning if we're closing
    
    In doing my fsstress+EIO stress testing I started running into issues
    where umount would get stuck forever because the uuid checker was
    chewing through the thousands of subvolumes I had created.
    
    We shouldn't block umount on this, simply bail if we're unmounting the
    fs.  We need to make sure we don't mark the UUID tree as ok, so we only
    set that bit if we made it through the whole rescan operation, but
    otherwise this is completely safe.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 074b77041f89..864ffc6c81c1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2847,7 +2847,9 @@ static int btrfs_uuid_rescan_kthread(void *data)
 	 */
 	ret = btrfs_uuid_tree_iterate(fs_info);
 	if (ret < 0) {
-		btrfs_warn(fs_info, "iterating uuid_tree failed %d", ret);
+		if (ret != -EINTR)
+			btrfs_warn(fs_info, "iterating uuid_tree failed %d",
+				   ret);
 		up(&fs_info->uuid_tree_rescan_sem);
 		return ret;
 	}

commit 97f4dd09dad05943a9c4184ace47258ed09e8e74
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Feb 18 16:56:08 2020 +0200

    btrfs: make btrfs_check_uuid_tree private to disk-io.c
    
    It's used only during filesystem mount as such it can be made private to
    disk-io.c file. Also use the occasion to move btrfs_uuid_rescan_kthread
    as btrfs_check_uuid_tree is its sole caller.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 756bf2ab64cd..074b77041f89 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2835,6 +2835,41 @@ static int init_mount_fs_info(struct btrfs_fs_info *fs_info, struct super_block
 	return ret;
 }
 
+static int btrfs_uuid_rescan_kthread(void *data)
+{
+	struct btrfs_fs_info *fs_info = (struct btrfs_fs_info *)data;
+	int ret;
+
+	/*
+	 * 1st step is to iterate through the existing UUID tree and
+	 * to delete all entries that contain outdated data.
+	 * 2nd step is to add all missing entries to the UUID tree.
+	 */
+	ret = btrfs_uuid_tree_iterate(fs_info);
+	if (ret < 0) {
+		btrfs_warn(fs_info, "iterating uuid_tree failed %d", ret);
+		up(&fs_info->uuid_tree_rescan_sem);
+		return ret;
+	}
+	return btrfs_uuid_scan_kthread(data);
+}
+
+static int btrfs_check_uuid_tree(struct btrfs_fs_info *fs_info)
+{
+	struct task_struct *task;
+
+	down(&fs_info->uuid_tree_rescan_sem);
+	task = kthread_run(btrfs_uuid_rescan_kthread, fs_info, "btrfs-uuid");
+	if (IS_ERR(task)) {
+		/* fs_info->update_uuid_tree_gen remains 0 in all error case */
+		btrfs_warn(fs_info, "failed to start uuid_rescan task");
+		up(&fs_info->uuid_tree_rescan_sem);
+		return PTR_ERR(task);
+	}
+
+	return 0;
+}
+
 int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_devices,
 		      char *options)
 {

commit 314b6dd0eebfa99621202f2be0b5f76e01d849e1
Author: Johannes Thumshirn <johannes.thumshirn@wdc.com>
Date:   Fri Feb 14 00:24:33 2020 +0900

    btrfs: use bios instead of buffer_heads from super block writeout
    
    Similar to the superblock read path, change the write path to using bios
    and pages instead of buffer_heads. This allows us to skip over the
    buffer_head code, for writing the superblock to disk.
    
    This is based on a patch originally authored by Nikolay Borisov.
    
    Co-developed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ac9554d71a46..756bf2ab64cd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -7,7 +7,6 @@
 #include <linux/blkdev.h>
 #include <linux/radix-tree.h>
 #include <linux/writeback.h>
-#include <linux/buffer_head.h>
 #include <linux/workqueue.h>
 #include <linux/kthread.h>
 #include <linux/slab.h>
@@ -3395,25 +3394,34 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 }
 ALLOW_ERROR_INJECTION(open_ctree, ERRNO);
 
-static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
+static void btrfs_end_super_write(struct bio *bio)
 {
-	if (uptodate) {
-		set_buffer_uptodate(bh);
-	} else {
-		struct btrfs_device *device = (struct btrfs_device *)
-			bh->b_private;
-
-		btrfs_warn_rl_in_rcu(device->fs_info,
-				"lost page write due to IO error on %s",
-					  rcu_str_deref(device->name));
-		/* note, we don't set_buffer_write_io_error because we have
-		 * our own ways of dealing with the IO errors
-		 */
-		clear_buffer_uptodate(bh);
-		btrfs_dev_stat_inc_and_print(device, BTRFS_DEV_STAT_WRITE_ERRS);
+	struct btrfs_device *device = bio->bi_private;
+	struct bio_vec *bvec;
+	struct bvec_iter_all iter_all;
+	struct page *page;
+
+	bio_for_each_segment_all(bvec, bio, iter_all) {
+		page = bvec->bv_page;
+
+		if (bio->bi_status) {
+			btrfs_warn_rl_in_rcu(device->fs_info,
+				"lost page write due to IO error on %s (%d)",
+				rcu_str_deref(device->name),
+				blk_status_to_errno(bio->bi_status));
+			ClearPageUptodate(page);
+			SetPageError(page);
+			btrfs_dev_stat_inc_and_print(device,
+						     BTRFS_DEV_STAT_WRITE_ERRS);
+		} else {
+			SetPageUptodate(page);
+		}
+
+		put_page(page);
+		unlock_page(page);
 	}
-	unlock_buffer(bh);
-	put_bh(bh);
+
+	bio_put(bio);
 }
 
 struct btrfs_super_block *btrfs_read_dev_one_super(struct block_device *bdev,
@@ -3473,25 +3481,23 @@ struct btrfs_super_block *btrfs_read_dev_super(struct block_device *bdev)
 
 /*
  * Write superblock @sb to the @device. Do not wait for completion, all the
- * buffer heads we write are pinned.
+ * pages we use for writing are locked.
  *
  * Write @max_mirrors copies of the superblock, where 0 means default that fit
  * the expected device size at commit time. Note that max_mirrors must be
  * same for write and wait phases.
  *
- * Return number of errors when buffer head is not found or submission fails.
+ * Return number of errors when page is not found or submission fails.
  */
 static int write_dev_supers(struct btrfs_device *device,
 			    struct btrfs_super_block *sb, int max_mirrors)
 {
 	struct btrfs_fs_info *fs_info = device->fs_info;
+	struct address_space *mapping = device->bdev->bd_inode->i_mapping;
 	SHASH_DESC_ON_STACK(shash, fs_info->csum_shash);
-	struct buffer_head *bh;
 	int i;
-	int ret;
 	int errors = 0;
 	u64 bytenr;
-	int op_flags;
 
 	if (max_mirrors == 0)
 		max_mirrors = BTRFS_SUPER_MIRROR_MAX;
@@ -3499,6 +3505,10 @@ static int write_dev_supers(struct btrfs_device *device,
 	shash->tfm = fs_info->csum_shash;
 
 	for (i = 0; i < max_mirrors; i++) {
+		struct page *page;
+		struct bio *bio;
+		struct btrfs_super_block *disk_super;
+
 		bytenr = btrfs_sb_offset(i);
 		if (bytenr + BTRFS_SUPER_INFO_SIZE >=
 		    device->commit_total_bytes)
@@ -3511,37 +3521,45 @@ static int write_dev_supers(struct btrfs_device *device,
 				    BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
 		crypto_shash_final(shash, sb->csum);
 
-		/* One reference for us, and we leave it for the caller */
-		bh = __getblk(device->bdev, bytenr / BTRFS_BDEV_BLOCKSIZE,
-			      BTRFS_SUPER_INFO_SIZE);
-		if (!bh) {
+		page = find_or_create_page(mapping, bytenr >> PAGE_SHIFT,
+					   GFP_NOFS);
+		if (!page) {
 			btrfs_err(device->fs_info,
-			    "couldn't get super buffer head for bytenr %llu",
+			    "couldn't get super block page for bytenr %llu",
 			    bytenr);
 			errors++;
 			continue;
 		}
 
-		memcpy(bh->b_data, sb, BTRFS_SUPER_INFO_SIZE);
+		/* Bump the refcount for wait_dev_supers() */
+		get_page(page);
 
-		/* one reference for submit_bh */
-		get_bh(bh);
+		disk_super = page_address(page);
+		memcpy(disk_super, sb, BTRFS_SUPER_INFO_SIZE);
 
-		set_buffer_uptodate(bh);
-		lock_buffer(bh);
-		bh->b_end_io = btrfs_end_buffer_write_sync;
-		bh->b_private = device;
+		/*
+		 * Directly use bios here instead of relying on the page cache
+		 * to do I/O, so we don't lose the ability to do integrity
+		 * checking.
+		 */
+		bio = bio_alloc(GFP_NOFS, 1);
+		bio_set_dev(bio, device->bdev);
+		bio->bi_iter.bi_sector = bytenr >> SECTOR_SHIFT;
+		bio->bi_private = device;
+		bio->bi_end_io = btrfs_end_super_write;
+		__bio_add_page(bio, page, BTRFS_SUPER_INFO_SIZE,
+			       offset_in_page(bytenr));
 
 		/*
-		 * we fua the first super.  The others we allow
-		 * to go down lazy.
+		 * We FUA only the first super block.  The others we allow to
+		 * go down lazy and there's a short window where the on-disk
+		 * copies might still contain the older version.
 		 */
-		op_flags = REQ_SYNC | REQ_META | REQ_PRIO;
+		bio->bi_opf = REQ_OP_WRITE | REQ_SYNC | REQ_META | REQ_PRIO;
 		if (i == 0 && !btrfs_test_opt(device->fs_info, NOBARRIER))
-			op_flags |= REQ_FUA;
-		ret = btrfsic_submit_bh(REQ_OP_WRITE, op_flags, bh);
-		if (ret)
-			errors++;
+			bio->bi_opf |= REQ_FUA;
+
+		btrfsic_submit_bio(bio);
 	}
 	return errors < i ? 0 : -1;
 }
@@ -3550,12 +3568,11 @@ static int write_dev_supers(struct btrfs_device *device,
  * Wait for write completion of superblocks done by write_dev_supers,
  * @max_mirrors same for write and wait phases.
  *
- * Return number of errors when buffer head is not found or not marked up to
+ * Return number of errors when page is not found or not marked up to
  * date.
  */
 static int wait_dev_supers(struct btrfs_device *device, int max_mirrors)
 {
-	struct buffer_head *bh;
 	int i;
 	int errors = 0;
 	bool primary_failed = false;
@@ -3565,32 +3582,34 @@ static int wait_dev_supers(struct btrfs_device *device, int max_mirrors)
 		max_mirrors = BTRFS_SUPER_MIRROR_MAX;
 
 	for (i = 0; i < max_mirrors; i++) {
+		struct page *page;
+
 		bytenr = btrfs_sb_offset(i);
 		if (bytenr + BTRFS_SUPER_INFO_SIZE >=
 		    device->commit_total_bytes)
 			break;
 
-		bh = __find_get_block(device->bdev,
-				      bytenr / BTRFS_BDEV_BLOCKSIZE,
-				      BTRFS_SUPER_INFO_SIZE);
-		if (!bh) {
+		page = find_get_page(device->bdev->bd_inode->i_mapping,
+				     bytenr >> PAGE_SHIFT);
+		if (!page) {
 			errors++;
 			if (i == 0)
 				primary_failed = true;
 			continue;
 		}
-		wait_on_buffer(bh);
-		if (!buffer_uptodate(bh)) {
+		/* Page is submitted locked and unlocked once the IO completes */
+		wait_on_page_locked(page);
+		if (PageError(page)) {
 			errors++;
 			if (i == 0)
 				primary_failed = true;
 		}
 
-		/* drop our reference */
-		brelse(bh);
+		/* Drop our reference */
+		put_page(page);
 
-		/* drop the reference from the writing run */
-		brelse(bh);
+		/* Drop the reference from the writing run */
+		put_page(page);
 	}
 
 	/* log error, force error return */

commit 8f32380d3f2904ad0e98574ae17f2018f6dd277e
Author: Johannes Thumshirn <johannes.thumshirn@wdc.com>
Date:   Fri Feb 14 00:24:32 2020 +0900

    btrfs: use the page cache for super block reading
    
    Super-block reading in BTRFS is done using buffer_heads. Buffer_heads
    have some drawbacks, like not being able to propagate errors from the
    lower layers.
    
    Directly use the page cache for reading the super blocks from disk or
    invalidating an on-disk super block. We have to use the page cache so to
    avoid races between mkfs and udev. See also 6f60cbd3ae44 ("btrfs: access
    superblock via pagecache in scan_one_device").
    
    This patch unwraps the buffer head API and does not change the way the
    super block is actually read.
    
    Signed-off-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e1e111c8b08b..ac9554d71a46 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2846,7 +2846,6 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	u64 features;
 	u16 csum_type;
 	struct btrfs_key location;
-	struct buffer_head *bh;
 	struct btrfs_super_block *disk_super;
 	struct btrfs_fs_info *fs_info = btrfs_sb(sb);
 	struct btrfs_root *tree_root;
@@ -2887,9 +2886,9 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	/*
 	 * Read super block and check the signature bytes only
 	 */
-	bh = btrfs_read_dev_super(fs_devices->latest_bdev);
-	if (IS_ERR(bh)) {
-		err = PTR_ERR(bh);
+	disk_super = btrfs_read_dev_super(fs_devices->latest_bdev);
+	if (IS_ERR(disk_super)) {
+		err = PTR_ERR(disk_super);
 		goto fail_alloc;
 	}
 
@@ -2897,18 +2896,19 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	 * Verify the type first, if that or the the checksum value are
 	 * corrupted, we'll find out
 	 */
-	csum_type = btrfs_super_csum_type((struct btrfs_super_block *)bh->b_data);
+	csum_type = btrfs_super_csum_type(disk_super);
 	if (!btrfs_supported_super_csum(csum_type)) {
 		btrfs_err(fs_info, "unsupported checksum algorithm: %u",
 			  csum_type);
 		err = -EINVAL;
-		brelse(bh);
+		btrfs_release_disk_super(disk_super);
 		goto fail_alloc;
 	}
 
 	ret = btrfs_init_csum_hash(fs_info, csum_type);
 	if (ret) {
 		err = ret;
+		btrfs_release_disk_super(disk_super);
 		goto fail_alloc;
 	}
 
@@ -2916,10 +2916,10 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	 * We want to check superblock checksum, the type is stored inside.
 	 * Pass the whole disk block of size BTRFS_SUPER_INFO_SIZE (4k).
 	 */
-	if (btrfs_check_super_csum(fs_info, bh->b_data)) {
+	if (btrfs_check_super_csum(fs_info, (u8 *)disk_super)) {
 		btrfs_err(fs_info, "superblock checksum mismatch");
 		err = -EINVAL;
-		brelse(bh);
+		btrfs_release_disk_super(disk_super);
 		goto fail_alloc;
 	}
 
@@ -2928,8 +2928,8 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	 * following bytes up to INFO_SIZE, the checksum is calculated from
 	 * the whole block of INFO_SIZE
 	 */
-	memcpy(fs_info->super_copy, bh->b_data, sizeof(*fs_info->super_copy));
-	brelse(bh);
+	memcpy(fs_info->super_copy, disk_super, sizeof(*fs_info->super_copy));
+	btrfs_release_disk_super(disk_super);
 
 	disk_super = fs_info->super_copy;
 
@@ -3416,45 +3416,38 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 	put_bh(bh);
 }
 
-int btrfs_read_dev_one_super(struct block_device *bdev, int copy_num,
-			struct buffer_head **bh_ret)
+struct btrfs_super_block *btrfs_read_dev_one_super(struct block_device *bdev,
+						   int copy_num)
 {
-	struct buffer_head *bh;
 	struct btrfs_super_block *super;
+	struct page *page;
 	u64 bytenr;
+	struct address_space *mapping = bdev->bd_inode->i_mapping;
 
 	bytenr = btrfs_sb_offset(copy_num);
 	if (bytenr + BTRFS_SUPER_INFO_SIZE >= i_size_read(bdev->bd_inode))
-		return -EINVAL;
+		return ERR_PTR(-EINVAL);
 
-	bh = __bread(bdev, bytenr / BTRFS_BDEV_BLOCKSIZE, BTRFS_SUPER_INFO_SIZE);
-	/*
-	 * If we fail to read from the underlying devices, as of now
-	 * the best option we have is to mark it EIO.
-	 */
-	if (!bh)
-		return -EIO;
+	page = read_cache_page_gfp(mapping, bytenr >> PAGE_SHIFT, GFP_NOFS);
+	if (IS_ERR(page))
+		return ERR_CAST(page);
 
-	super = (struct btrfs_super_block *)bh->b_data;
+	super = page_address(page);
 	if (btrfs_super_bytenr(super) != bytenr ||
 		    btrfs_super_magic(super) != BTRFS_MAGIC) {
-		brelse(bh);
-		return -EINVAL;
+		btrfs_release_disk_super(super);
+		return ERR_PTR(-EINVAL);
 	}
 
-	*bh_ret = bh;
-	return 0;
+	return super;
 }
 
 
-struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
+struct btrfs_super_block *btrfs_read_dev_super(struct block_device *bdev)
 {
-	struct buffer_head *bh;
-	struct buffer_head *latest = NULL;
-	struct btrfs_super_block *super;
+	struct btrfs_super_block *super, *latest = NULL;
 	int i;
 	u64 transid = 0;
-	int ret = -EINVAL;
 
 	/* we would like to check all the supers, but that would make
 	 * a btrfs mount succeed after a mkfs from a different FS.
@@ -3462,25 +3455,20 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 	 * later supers, using BTRFS_SUPER_MIRROR_MAX instead
 	 */
 	for (i = 0; i < 1; i++) {
-		ret = btrfs_read_dev_one_super(bdev, i, &bh);
-		if (ret)
+		super = btrfs_read_dev_one_super(bdev, i);
+		if (IS_ERR(super))
 			continue;
 
-		super = (struct btrfs_super_block *)bh->b_data;
-
 		if (!latest || btrfs_super_generation(super) > transid) {
-			brelse(latest);
-			latest = bh;
+			if (latest)
+				btrfs_release_disk_super(super);
+
+			latest = super;
 			transid = btrfs_super_generation(super);
-		} else {
-			brelse(bh);
 		}
 	}
 
-	if (!latest)
-		return ERR_PTR(ret);
-
-	return latest;
+	return super;
 }
 
 /*

commit fe119a6eeb670585e29dbe3932e00ad29ae8f5f9
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 20 16:09:18 2020 +0200

    btrfs: switch to per-transaction pinned extents
    
    This commit flips the switch to start tracking/processing pinned extents
    on a per-transaction basis. It mostly replaces all references from
    btrfs_fs_info::(pinned_extents|freed_extents[]) to
    btrfs_transaction::pinned_extents.
    
    Two notable modifications that warrant explicit mention are changing
    clean_pinned_extents to get a reference to the previously running
    transaction. The other one is removal of call to
    btrfs_destroy_pinned_extent since transactions are going to be cleaned
    in btrfs_cleanup_one_transaction.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 194c98a61095..e1e111c8b08b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2075,10 +2075,8 @@ void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
 			btrfs_drop_and_free_fs_root(fs_info, gang[i]);
 	}
 
-	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state)) {
+	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
 		btrfs_free_log_root_tree(NULL, fs_info);
-		btrfs_destroy_pinned_extent(fs_info, fs_info->pinned_extents);
-	}
 }
 
 static void btrfs_init_scrub(struct btrfs_fs_info *fs_info)
@@ -2749,11 +2747,8 @@ void btrfs_init_fs_info(struct btrfs_fs_info *fs_info)
 	fs_info->block_group_cache_tree = RB_ROOT;
 	fs_info->first_logical_byte = (u64)-1;
 
-	extent_io_tree_init(fs_info, &fs_info->freed_extents[0],
-			    IO_TREE_FS_INFO_FREED_EXTENTS0, NULL);
-	extent_io_tree_init(fs_info, &fs_info->freed_extents[1],
-			    IO_TREE_FS_INFO_FREED_EXTENTS1, NULL);
-	fs_info->pinned_extents = &fs_info->freed_extents[0];
+	extent_io_tree_init(fs_info, &fs_info->excluded_extents,
+			    IO_TREE_FS_EXCLUDED_EXTENTS, NULL);
 	set_bit(BTRFS_FS_BARRIER, &fs_info->flags);
 
 	mutex_init(&fs_info->ordered_operations_mutex);
@@ -4434,16 +4429,12 @@ static int btrfs_destroy_marked_extents(struct btrfs_fs_info *fs_info,
 }
 
 static int btrfs_destroy_pinned_extent(struct btrfs_fs_info *fs_info,
-				       struct extent_io_tree *pinned_extents)
+				       struct extent_io_tree *unpin)
 {
-	struct extent_io_tree *unpin;
 	u64 start;
 	u64 end;
 	int ret;
-	bool loop = true;
 
-	unpin = pinned_extents;
-again:
 	while (1) {
 		struct extent_state *cached_state = NULL;
 
@@ -4468,15 +4459,6 @@ static int btrfs_destroy_pinned_extent(struct btrfs_fs_info *fs_info,
 		cond_resched();
 	}
 
-	if (loop) {
-		if (unpin == &fs_info->freed_extents[0])
-			unpin = &fs_info->freed_extents[1];
-		else
-			unpin = &fs_info->freed_extents[0];
-		loop = false;
-		goto again;
-	}
-
 	return 0;
 }
 
@@ -4567,8 +4549,7 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 
 	btrfs_destroy_marked_extents(fs_info, &cur_trans->dirty_pages,
 				     EXTENT_DIRTY);
-	btrfs_destroy_pinned_extent(fs_info,
-				    fs_info->pinned_extents);
+	btrfs_destroy_pinned_extent(fs_info, &cur_trans->pinned_extents);
 
 	cur_trans->state =TRANS_STATE_COMPLETED;
 	wake_up(&cur_trans->commit_wait);
@@ -4620,7 +4601,6 @@ static int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_all_ordered_extents(fs_info);
 	btrfs_destroy_delayed_inodes(fs_info);
 	btrfs_assert_delayed_root_empty(fs_info);
-	btrfs_destroy_pinned_extent(fs_info, fs_info->pinned_extents);
 	btrfs_destroy_all_delalloc_inodes(fs_info);
 	mutex_unlock(&fs_info->transaction_kthread_mutex);
 

commit f603bb94abbed5b5542cfb514ddfa3c5dda96bcc
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 20 16:09:08 2020 +0200

    btrfs: Perform pinned cleanup directly in btrfs_destroy_delayed_refs
    
    Having btrfs_destroy_delayed_refs call btrfs_pin_extent is problematic
    for making pinned extents tracking per-transaction since
    btrfs_trans_handle cannot be passed to btrfs_pin_extent in this context.
    Additionally delayed refs heads pinned in btrfs_destroy_delayed_refs
    are going to be handled very closely, in btrfs_destroy_pinned_extent.
    
    To enable btrfs_pin_extent to take btrfs_trans_handle simply open code
    it in btrfs_destroy_delayed_refs and call btrfs_error_unpin_extent_range
    on the range. This enables us to do less work in
    btrfs_destroy_pinned_extent and leaves btrfs_pin_extent being called in
    contexts which have a valid btrfs_trans_handle.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 49daf6c946df..194c98a61095 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -42,6 +42,7 @@
 #include "ref-verify.h"
 #include "block-group.h"
 #include "discard.h"
+#include "space-info.h"
 
 #define BTRFS_SUPER_FLAG_SUPP	(BTRFS_HEADER_FLAG_WRITTEN |\
 				 BTRFS_HEADER_FLAG_RELOC |\
@@ -4308,9 +4309,30 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		spin_unlock(&delayed_refs->lock);
 		mutex_unlock(&head->mutex);
 
-		if (pin_bytes)
-			btrfs_pin_extent(fs_info, head->bytenr,
-					 head->num_bytes, 1);
+		if (pin_bytes) {
+			struct btrfs_block_group *cache;
+
+			cache = btrfs_lookup_block_group(fs_info, head->bytenr);
+			BUG_ON(!cache);
+
+			spin_lock(&cache->space_info->lock);
+			spin_lock(&cache->lock);
+			cache->pinned += head->num_bytes;
+			btrfs_space_info_update_bytes_pinned(fs_info,
+				cache->space_info, head->num_bytes);
+			cache->reserved -= head->num_bytes;
+			cache->space_info->bytes_reserved -= head->num_bytes;
+			spin_unlock(&cache->lock);
+			spin_unlock(&cache->space_info->lock);
+			percpu_counter_add_batch(
+				&cache->space_info->total_bytes_pinned,
+				head->num_bytes, BTRFS_TOTAL_BYTES_PINNED_BATCH);
+
+			btrfs_put_block_group(cache);
+
+			btrfs_error_unpin_extent_range(fs_info, head->bytenr,
+				head->bytenr + head->num_bytes - 1);
+		}
 		btrfs_cleanup_ref_head_accounting(fs_info, delayed_refs, head);
 		btrfs_put_delayed_ref_head(head);
 		cond_resched();

commit 71ad38b44eaa758c70c34ca97a5c3848d6b67e03
Author: David Sterba <dsterba@suse.com>
Date:   Wed Feb 5 19:09:35 2020 +0100

    btrfs: sink argument tree to extent_read_full_page
    
    The tree pointer can be safely read from the page's inode, use it and
    drop the redundant argument.
    
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f859a28255dd..49daf6c946df 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -978,9 +978,7 @@ static int btree_writepages(struct address_space *mapping,
 
 static int btree_readpage(struct file *file, struct page *page)
 {
-	struct extent_io_tree *tree;
-	tree = &BTRFS_I(page->mapping->host)->io_tree;
-	return extent_read_full_page(tree, page, btree_get_extent, 0);
+	return extent_read_full_page(page, btree_get_extent, 0);
 }
 
 static int btree_releasepage(struct page *page, gfp_t gfp_flags)

commit 0024652895e3479cd0d372f63b57d9581a0bdd38
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:33:01 2020 -0500

    btrfs: rename btrfs_put_fs_root and btrfs_grab_fs_root
    
    We are now using these for all roots, rename them to btrfs_put_root()
    and btrfs_grab_root();
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c2838a48327f..f859a28255dd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1309,7 +1309,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 		free_extent_buffer(root->commit_root);
 		free_extent_buffer(leaf);
 	}
-	btrfs_put_fs_root(root);
+	btrfs_put_root(root);
 
 	return ERR_PTR(ret);
 }
@@ -1340,7 +1340,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	leaf = btrfs_alloc_tree_block(trans, root, 0, BTRFS_TREE_LOG_OBJECTID,
 			NULL, 0, 0, 0);
 	if (IS_ERR(leaf)) {
-		btrfs_put_fs_root(root);
+		btrfs_put_root(root);
 		return ERR_CAST(leaf);
 	}
 
@@ -1443,7 +1443,7 @@ struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	return root;
 
 find_fail:
-	btrfs_put_fs_root(root);
+	btrfs_put_root(root);
 alloc_fail:
 	root = ERR_PTR(ret);
 	goto out;
@@ -1509,7 +1509,7 @@ static struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
 	root = radix_tree_lookup(&fs_info->fs_roots_radix,
 				 (unsigned long)root_id);
 	if (root)
-		root = btrfs_grab_fs_root(root);
+		root = btrfs_grab_root(root);
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 	return root;
 }
@@ -1528,7 +1528,7 @@ int btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,
 				(unsigned long)root->root_key.objectid,
 				root);
 	if (ret == 0) {
-		btrfs_grab_fs_root(root);
+		btrfs_grab_root(root);
 		set_bit(BTRFS_ROOT_IN_RADIX, &root->state);
 	}
 	spin_unlock(&fs_info->fs_roots_radix_lock);
@@ -1549,8 +1549,8 @@ void btrfs_check_leaked_roots(struct btrfs_fs_info *fs_info)
 			  root->root_key.objectid, root->root_key.offset,
 			  refcount_read(&root->refs));
 		while (refcount_read(&root->refs) > 1)
-			btrfs_put_fs_root(root);
-		btrfs_put_fs_root(root);
+			btrfs_put_root(root);
+		btrfs_put_root(root);
 	}
 #endif
 }
@@ -1566,15 +1566,15 @@ void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
 	btrfs_free_ref_cache(fs_info);
 	kfree(fs_info->balance_ctl);
 	kfree(fs_info->delayed_root);
-	btrfs_put_fs_root(fs_info->extent_root);
-	btrfs_put_fs_root(fs_info->tree_root);
-	btrfs_put_fs_root(fs_info->chunk_root);
-	btrfs_put_fs_root(fs_info->dev_root);
-	btrfs_put_fs_root(fs_info->csum_root);
-	btrfs_put_fs_root(fs_info->quota_root);
-	btrfs_put_fs_root(fs_info->uuid_root);
-	btrfs_put_fs_root(fs_info->free_space_root);
-	btrfs_put_fs_root(fs_info->fs_root);
+	btrfs_put_root(fs_info->extent_root);
+	btrfs_put_root(fs_info->tree_root);
+	btrfs_put_root(fs_info->chunk_root);
+	btrfs_put_root(fs_info->dev_root);
+	btrfs_put_root(fs_info->csum_root);
+	btrfs_put_root(fs_info->quota_root);
+	btrfs_put_root(fs_info->uuid_root);
+	btrfs_put_root(fs_info->free_space_root);
+	btrfs_put_root(fs_info->fs_root);
 	btrfs_check_leaked_roots(fs_info);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
@@ -1592,29 +1592,29 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	int ret;
 
 	if (location->objectid == BTRFS_ROOT_TREE_OBJECTID)
-		return btrfs_grab_fs_root(fs_info->tree_root);
+		return btrfs_grab_root(fs_info->tree_root);
 	if (location->objectid == BTRFS_EXTENT_TREE_OBJECTID)
-		return btrfs_grab_fs_root(fs_info->extent_root);
+		return btrfs_grab_root(fs_info->extent_root);
 	if (location->objectid == BTRFS_CHUNK_TREE_OBJECTID)
-		return btrfs_grab_fs_root(fs_info->chunk_root);
+		return btrfs_grab_root(fs_info->chunk_root);
 	if (location->objectid == BTRFS_DEV_TREE_OBJECTID)
-		return btrfs_grab_fs_root(fs_info->dev_root);
+		return btrfs_grab_root(fs_info->dev_root);
 	if (location->objectid == BTRFS_CSUM_TREE_OBJECTID)
-		return btrfs_grab_fs_root(fs_info->csum_root);
+		return btrfs_grab_root(fs_info->csum_root);
 	if (location->objectid == BTRFS_QUOTA_TREE_OBJECTID)
-		return btrfs_grab_fs_root(fs_info->quota_root) ?
+		return btrfs_grab_root(fs_info->quota_root) ?
 			fs_info->quota_root : ERR_PTR(-ENOENT);
 	if (location->objectid == BTRFS_UUID_TREE_OBJECTID)
-		return btrfs_grab_fs_root(fs_info->uuid_root) ?
+		return btrfs_grab_root(fs_info->uuid_root) ?
 			fs_info->uuid_root : ERR_PTR(-ENOENT);
 	if (location->objectid == BTRFS_FREE_SPACE_TREE_OBJECTID)
-		return btrfs_grab_fs_root(fs_info->free_space_root) ?
+		return btrfs_grab_root(fs_info->free_space_root) ?
 			fs_info->free_space_root : ERR_PTR(-ENOENT);
 again:
 	root = btrfs_lookup_fs_root(fs_info, location->objectid);
 	if (root) {
 		if (check_ref && btrfs_root_refs(&root->root_item) == 0) {
-			btrfs_put_fs_root(root);
+			btrfs_put_root(root);
 			return ERR_PTR(-ENOENT);
 		}
 		return root;
@@ -1657,10 +1657,10 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	 * we have the third for returning it, and the caller will put it when
 	 * it's done with the root.
 	 */
-	btrfs_grab_fs_root(root);
+	btrfs_grab_root(root);
 	ret = btrfs_insert_fs_root(fs_info, root);
 	if (ret) {
-		btrfs_put_fs_root(root);
+		btrfs_put_root(root);
 		if (ret == -EEXIST) {
 			btrfs_free_fs_root(root);
 			goto again;
@@ -2062,7 +2062,7 @@ void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
 		} else {
 			free_extent_buffer(gang[0]->node);
 			free_extent_buffer(gang[0]->commit_root);
-			btrfs_put_fs_root(gang[0]);
+			btrfs_put_root(gang[0]);
 		}
 	}
 
@@ -2270,12 +2270,12 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	if (IS_ERR(log_tree_root->node)) {
 		btrfs_warn(fs_info, "failed to read log tree");
 		ret = PTR_ERR(log_tree_root->node);
-		btrfs_put_fs_root(log_tree_root);
+		btrfs_put_root(log_tree_root);
 		return ret;
 	} else if (!extent_buffer_uptodate(log_tree_root->node)) {
 		btrfs_err(fs_info, "failed to read log tree");
 		free_extent_buffer(log_tree_root->node);
-		btrfs_put_fs_root(log_tree_root);
+		btrfs_put_root(log_tree_root);
 		return -EIO;
 	}
 	/* returns with log_tree_root freed on success */
@@ -2284,7 +2284,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 		btrfs_handle_fs_error(fs_info, ret,
 				      "Failed to recover log tree");
 		free_extent_buffer(log_tree_root->node);
-		btrfs_put_fs_root(log_tree_root);
+		btrfs_put_root(log_tree_root);
 		return ret;
 	}
 
@@ -3884,7 +3884,7 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
 	if (test_and_clear_bit(BTRFS_ROOT_IN_RADIX, &root->state))
-		btrfs_put_fs_root(root);
+		btrfs_put_root(root);
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 
 	if (btrfs_root_refs(&root->root_item) == 0)
@@ -3895,7 +3895,7 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 		if (root->reloc_root) {
 			free_extent_buffer(root->reloc_root->node);
 			free_extent_buffer(root->reloc_root->commit_root);
-			btrfs_put_fs_root(root->reloc_root);
+			btrfs_put_root(root->reloc_root);
 			root->reloc_root = NULL;
 		}
 	}
@@ -3919,7 +3919,7 @@ void btrfs_free_fs_root(struct btrfs_root *root)
 	free_extent_buffer(root->commit_root);
 	kfree(root->free_ino_ctl);
 	kfree(root->free_ino_pinned);
-	btrfs_put_fs_root(root);
+	btrfs_put_root(root);
 }
 
 int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
@@ -3949,7 +3949,7 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 				continue;
 			}
 			/* grab all the search result for later use */
-			gang[i] = btrfs_grab_fs_root(gang[i]);
+			gang[i] = btrfs_grab_root(gang[i]);
 		}
 		srcu_read_unlock(&fs_info->subvol_srcu, index);
 
@@ -3960,7 +3960,7 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 			err = btrfs_orphan_cleanup(gang[i]);
 			if (err)
 				break;
-			btrfs_put_fs_root(gang[i]);
+			btrfs_put_root(gang[i]);
 		}
 		root_objectid++;
 	}
@@ -3968,7 +3968,7 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 	/* release the uncleaned roots due to error */
 	for (; i < ret; i++) {
 		if (gang[i])
-			btrfs_put_fs_root(gang[i]);
+			btrfs_put_root(gang[i]);
 	}
 	return err;
 }
@@ -4368,12 +4368,12 @@ static void btrfs_destroy_all_delalloc_inodes(struct btrfs_fs_info *fs_info)
 	while (!list_empty(&splice)) {
 		root = list_first_entry(&splice, struct btrfs_root,
 					 delalloc_root);
-		root = btrfs_grab_fs_root(root);
+		root = btrfs_grab_root(root);
 		BUG_ON(!root);
 		spin_unlock(&fs_info->delalloc_root_lock);
 
 		btrfs_destroy_delalloc_inodes(root);
-		btrfs_put_fs_root(root);
+		btrfs_put_root(root);
 
 		spin_lock(&fs_info->delalloc_root_lock);
 	}

commit bd647ce385ec110fe7796267b6555873e48e44eb
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:33:00 2020 -0500

    btrfs: add a leak check for roots
    
    Now that we're going to start relying on getting ref counting right for
    roots, add a list to track allocated roots and print out any roots that
    aren't freed up at free_fs_info time.
    
    Hide this behind CONFIG_BTRFS_DEBUG because this will just be used for
    developers to verify they aren't breaking things.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3e4df0c6a663..c2838a48327f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1202,6 +1202,12 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 
 	spin_lock_init(&root->root_item_lock);
 	btrfs_qgroup_init_swapped_blocks(&root->swapped_blocks);
+#ifdef CONFIG_BTRFS_DEBUG
+	INIT_LIST_HEAD(&root->leak_list);
+	spin_lock(&fs_info->fs_roots_radix_lock);
+	list_add_tail(&root->leak_list, &fs_info->allocated_roots);
+	spin_unlock(&fs_info->fs_roots_radix_lock);
+#endif
 }
 
 static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info,
@@ -1531,6 +1537,24 @@ int btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
+void btrfs_check_leaked_roots(struct btrfs_fs_info *fs_info)
+{
+#ifdef CONFIG_BTRFS_DEBUG
+	struct btrfs_root *root;
+
+	while (!list_empty(&fs_info->allocated_roots)) {
+		root = list_first_entry(&fs_info->allocated_roots,
+					struct btrfs_root, leak_list);
+		btrfs_err(fs_info, "leaked root %llu-%llu refcount %d",
+			  root->root_key.objectid, root->root_key.offset,
+			  refcount_read(&root->refs));
+		while (refcount_read(&root->refs) > 1)
+			btrfs_put_fs_root(root);
+		btrfs_put_fs_root(root);
+	}
+#endif
+}
+
 void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
 {
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
@@ -1551,6 +1575,7 @@ void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
 	btrfs_put_fs_root(fs_info->uuid_root);
 	btrfs_put_fs_root(fs_info->free_space_root);
 	btrfs_put_fs_root(fs_info->fs_root);
+	btrfs_check_leaked_roots(fs_info);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
 	kvfree(fs_info);
@@ -2677,6 +2702,9 @@ void btrfs_init_fs_info(struct btrfs_fs_info *fs_info)
 	INIT_LIST_HEAD(&fs_info->space_info);
 	INIT_LIST_HEAD(&fs_info->tree_mod_seq_list);
 	INIT_LIST_HEAD(&fs_info->unused_bgs);
+#ifdef CONFIG_BTRFS_DEBUG
+	INIT_LIST_HEAD(&fs_info->allocated_roots);
+#endif
 	extent_map_tree_init(&fs_info->mapping_tree);
 	btrfs_init_block_rsv(&fs_info->global_block_rsv,
 			     BTRFS_BLOCK_RSV_GLOBAL);

commit 8260edba67a2e6bd5e709d32188e23aa22cb4a38
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:59 2020 -0500

    btrfs: make the init of static elements in fs_info separate
    
    In adding things like eb leak checking and root leak checking there were
    a lot of weird corner cases that come from the fact that
    
      1) We do not init the fs_info until we get to open_ctree time in the
         normal case and
    
      2) The test infrastructure half-init's the fs_info for things that it
         needs.
    
    This makes it really annoying to make changes because you have to add
    init in two different places, have special cases for testing fs_info's
    that may not have certain things initialized, and cases for fs_info's
    that didn't make it to open_ctree and thus are not fully set up.
    
    Fix this by extracting out the non-allocating init of the fs info into
    it's own public function and use that to make sure we're all getting
    consistent views of an allocated fs_info.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0bc6bc2c10f0..3e4df0c6a663 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2649,10 +2649,8 @@ static int __cold init_tree_roots(struct btrfs_fs_info *fs_info)
 	return ret;
 }
 
-static int init_fs_info(struct btrfs_fs_info *fs_info, struct super_block *sb)
+void btrfs_init_fs_info(struct btrfs_fs_info *fs_info)
 {
-	int ret;
-
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);
 	INIT_RADIX_TREE(&fs_info->buffer_radix, GFP_ATOMIC);
 	INIT_LIST_HEAD(&fs_info->trans_list);
@@ -2695,7 +2693,6 @@ static int init_fs_info(struct btrfs_fs_info *fs_info, struct super_block *sb)
 	atomic_set(&fs_info->reada_works_cnt, 0);
 	atomic_set(&fs_info->nr_delayed_iputs, 0);
 	atomic64_set(&fs_info->tree_mod_seq, 0);
-	fs_info->sb = sb;
 	fs_info->max_inline = BTRFS_DEFAULT_MAX_INLINE;
 	fs_info->metadata_ratio = 0;
 	fs_info->defrag_inodes = RB_ROOT;
@@ -2721,9 +2718,6 @@ static int init_fs_info(struct btrfs_fs_info *fs_info, struct super_block *sb)
 	btrfs_init_balance(fs_info);
 	btrfs_init_async_reclaim_work(&fs_info->async_reclaim_work);
 
-	sb->s_blocksize = BTRFS_BDEV_BLOCKSIZE;
-	sb->s_blocksize_bits = blksize_bits(BTRFS_BDEV_BLOCKSIZE);
-
 	spin_lock_init(&fs_info->block_group_cache_lock);
 	fs_info->block_group_cache_tree = RB_ROOT;
 	fs_info->first_logical_byte = (u64)-1;
@@ -2768,6 +2762,15 @@ static int init_fs_info(struct btrfs_fs_info *fs_info, struct super_block *sb)
 	fs_info->swapfile_pins = RB_ROOT;
 
 	fs_info->send_in_progress = 0;
+}
+
+static int init_mount_fs_info(struct btrfs_fs_info *fs_info, struct super_block *sb)
+{
+	int ret;
+
+	fs_info->sb = sb;
+	sb->s_blocksize = BTRFS_BDEV_BLOCKSIZE;
+	sb->s_blocksize_bits = blksize_bits(BTRFS_BDEV_BLOCKSIZE);
 
 	ret = init_srcu_struct(&fs_info->subvol_srcu);
 	if (ret)
@@ -2831,7 +2834,7 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device
 	int clear_free_space_tree = 0;
 	int level;
 
-	ret = init_fs_info(fs_info, sb);
+	ret = init_mount_fs_info(fs_info, sb);
 	if (ret) {
 		err = ret;
 		goto fail;

commit ae18c37ad5a12a73d119dc1d7b30199574a41bf3
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:58 2020 -0500

    btrfs: move fs_info init work into it's own helper function
    
    open_ctree mixes initialization of fs stuff and fs_info stuff, which
    makes it confusing when doing things like adding the root leak
    detection.  Make a separate function that inits all the static
    structures inside of the fs_info needed for the fs to operate, and then
    call that before we start setting up the fs_info to be mounted.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1f2661369738..0bc6bc2c10f0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2649,70 +2649,9 @@ static int __cold init_tree_roots(struct btrfs_fs_info *fs_info)
 	return ret;
 }
 
-int __cold open_ctree(struct super_block *sb,
-	       struct btrfs_fs_devices *fs_devices,
-	       char *options)
+static int init_fs_info(struct btrfs_fs_info *fs_info, struct super_block *sb)
 {
-	u32 sectorsize;
-	u32 nodesize;
-	u32 stripesize;
-	u64 generation;
-	u64 features;
-	u16 csum_type;
-	struct btrfs_key location;
-	struct buffer_head *bh;
-	struct btrfs_super_block *disk_super;
-	struct btrfs_fs_info *fs_info = btrfs_sb(sb);
-	struct btrfs_root *tree_root;
-	struct btrfs_root *chunk_root;
 	int ret;
-	int err = -EINVAL;
-	int clear_free_space_tree = 0;
-	int level;
-
-	tree_root = btrfs_alloc_root(fs_info, BTRFS_ROOT_TREE_OBJECTID,
-				     GFP_KERNEL);
-	fs_info->tree_root = tree_root;
-	chunk_root = btrfs_alloc_root(fs_info, BTRFS_CHUNK_TREE_OBJECTID,
-				      GFP_KERNEL);
-	fs_info->chunk_root = chunk_root;
-	if (!tree_root || !chunk_root) {
-		err = -ENOMEM;
-		goto fail;
-	}
-
-	ret = init_srcu_struct(&fs_info->subvol_srcu);
-	if (ret) {
-		err = ret;
-		goto fail;
-	}
-
-	ret = percpu_counter_init(&fs_info->dio_bytes, 0, GFP_KERNEL);
-	if (ret) {
-		err = ret;
-		goto fail_srcu;
-	}
-
-	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0, GFP_KERNEL);
-	if (ret) {
-		err = ret;
-		goto fail_srcu;
-	}
-	fs_info->dirty_metadata_batch = PAGE_SIZE *
-					(1 + ilog2(nr_cpu_ids));
-
-	ret = percpu_counter_init(&fs_info->delalloc_bytes, 0, GFP_KERNEL);
-	if (ret) {
-		err = ret;
-		goto fail_srcu;
-	}
-
-	ret = percpu_counter_init(&fs_info->dev_replace.bio_counter, 0,
-			GFP_KERNEL);
-	if (ret) {
-		err = ret;
-		goto fail_srcu;
-	}
 
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);
 	INIT_RADIX_TREE(&fs_info->buffer_radix, GFP_ATOMIC);
@@ -2775,21 +2714,6 @@ int __cold open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->ordered_roots);
 	spin_lock_init(&fs_info->ordered_root_lock);
 
-	fs_info->btree_inode = new_inode(sb);
-	if (!fs_info->btree_inode) {
-		err = -ENOMEM;
-		goto fail_srcu;
-	}
-	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
-
-	fs_info->delayed_root = kmalloc(sizeof(struct btrfs_delayed_root),
-					GFP_KERNEL);
-	if (!fs_info->delayed_root) {
-		err = -ENOMEM;
-		goto fail_iput;
-	}
-	btrfs_init_delayed_root(fs_info->delayed_root);
-
 	btrfs_init_scrub(fs_info);
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	fs_info->check_integrity_print_mask = 0;
@@ -2800,8 +2724,6 @@ int __cold open_ctree(struct super_block *sb,
 	sb->s_blocksize = BTRFS_BDEV_BLOCKSIZE;
 	sb->s_blocksize_bits = blksize_bits(BTRFS_BDEV_BLOCKSIZE);
 
-	btrfs_init_btree_inode(fs_info);
-
 	spin_lock_init(&fs_info->block_group_cache_lock);
 	fs_info->block_group_cache_tree = RB_ROOT;
 	fs_info->first_logical_byte = (u64)-1;
@@ -2847,12 +2769,94 @@ int __cold open_ctree(struct super_block *sb,
 
 	fs_info->send_in_progress = 0;
 
+	ret = init_srcu_struct(&fs_info->subvol_srcu);
+	if (ret)
+		return ret;
+
+	ret = percpu_counter_init(&fs_info->dio_bytes, 0, GFP_KERNEL);
+	if (ret)
+		goto fail;
+
+	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0, GFP_KERNEL);
+	if (ret)
+		goto fail;
+
+	fs_info->dirty_metadata_batch = PAGE_SIZE *
+					(1 + ilog2(nr_cpu_ids));
+
+	ret = percpu_counter_init(&fs_info->delalloc_bytes, 0, GFP_KERNEL);
+	if (ret)
+		goto fail;
+
+	ret = percpu_counter_init(&fs_info->dev_replace.bio_counter, 0,
+			GFP_KERNEL);
+	if (ret)
+		goto fail;
+
+	fs_info->delayed_root = kmalloc(sizeof(struct btrfs_delayed_root),
+					GFP_KERNEL);
+	if (!fs_info->delayed_root) {
+		ret = -ENOMEM;
+		goto fail;
+	}
+	btrfs_init_delayed_root(fs_info->delayed_root);
+
 	ret = btrfs_alloc_stripe_hash_table(fs_info);
+	if (ret)
+		goto fail;
+
+	return 0;
+fail:
+	cleanup_srcu_struct(&fs_info->subvol_srcu);
+	return ret;
+}
+
+int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_devices,
+		      char *options)
+{
+	u32 sectorsize;
+	u32 nodesize;
+	u32 stripesize;
+	u64 generation;
+	u64 features;
+	u16 csum_type;
+	struct btrfs_key location;
+	struct buffer_head *bh;
+	struct btrfs_super_block *disk_super;
+	struct btrfs_fs_info *fs_info = btrfs_sb(sb);
+	struct btrfs_root *tree_root;
+	struct btrfs_root *chunk_root;
+	int ret;
+	int err = -EINVAL;
+	int clear_free_space_tree = 0;
+	int level;
+
+	ret = init_fs_info(fs_info, sb);
 	if (ret) {
 		err = ret;
-		goto fail_alloc;
+		goto fail;
 	}
 
+	/* These need to be init'ed before we start creating inodes and such. */
+	tree_root = btrfs_alloc_root(fs_info, BTRFS_ROOT_TREE_OBJECTID,
+				     GFP_KERNEL);
+	fs_info->tree_root = tree_root;
+	chunk_root = btrfs_alloc_root(fs_info, BTRFS_CHUNK_TREE_OBJECTID,
+				      GFP_KERNEL);
+	fs_info->chunk_root = chunk_root;
+	if (!tree_root || !chunk_root) {
+		err = -ENOMEM;
+		goto fail_srcu;
+	}
+
+	fs_info->btree_inode = new_inode(sb);
+	if (!fs_info->btree_inode) {
+		err = -ENOMEM;
+		goto fail_srcu;
+	}
+	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
+	btrfs_init_btree_inode(fs_info);
+
 	invalidate_bdev(fs_devices->latest_bdev);
 
 	/*
@@ -3355,7 +3359,6 @@ int __cold open_ctree(struct super_block *sb,
 	btrfs_stop_all_workers(fs_info);
 	btrfs_free_block_groups(fs_info);
 fail_alloc:
-fail_iput:
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
 	iput(fs_info->btree_inode);

commit 141386e1a5d641d6d89a7794f806a31945ec1e9f
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:57 2020 -0500

    btrfs: free more things in btrfs_free_fs_info
    
    Things like the percpu_counters, the mapping_tree, and the csum hash can
    all be freed at btrfs_free_fs_info time, since the helpers all check if
    the structure has been initialized already.  This significantly cleans
    up the error cases in open_ctree.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a0c67200fb2a..1f2661369738 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -98,6 +98,12 @@ void __cold btrfs_end_io_wq_exit(void)
 	kmem_cache_destroy(btrfs_end_io_wq_cache);
 }
 
+static void btrfs_free_csum_hash(struct btrfs_fs_info *fs_info)
+{
+	if (fs_info->csum_shash)
+		crypto_free_shash(fs_info->csum_shash);
+}
+
 /*
  * async submit bios are used to offload expensive checksumming
  * onto the worker threads.  They checksum file and metadata bios
@@ -1527,6 +1533,13 @@ int btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,
 
 void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
 {
+	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
+	percpu_counter_destroy(&fs_info->delalloc_bytes);
+	percpu_counter_destroy(&fs_info->dio_bytes);
+	percpu_counter_destroy(&fs_info->dev_replace.bio_counter);
+	btrfs_free_csum_hash(fs_info);
+	btrfs_free_stripe_hash_table(fs_info);
+	btrfs_free_ref_cache(fs_info);
 	kfree(fs_info->balance_ctl);
 	kfree(fs_info->delayed_root);
 	btrfs_put_fs_root(fs_info->extent_root);
@@ -2207,11 +2220,6 @@ static int btrfs_init_csum_hash(struct btrfs_fs_info *fs_info, u16 csum_type)
 	return 0;
 }
 
-static void btrfs_free_csum_hash(struct btrfs_fs_info *fs_info)
-{
-	crypto_free_shash(fs_info->csum_shash);
-}
-
 static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 			    struct btrfs_fs_devices *fs_devices)
 {
@@ -2688,7 +2696,7 @@ int __cold open_ctree(struct super_block *sb,
 	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0, GFP_KERNEL);
 	if (ret) {
 		err = ret;
-		goto fail_dio_bytes;
+		goto fail_srcu;
 	}
 	fs_info->dirty_metadata_batch = PAGE_SIZE *
 					(1 + ilog2(nr_cpu_ids));
@@ -2696,14 +2704,14 @@ int __cold open_ctree(struct super_block *sb,
 	ret = percpu_counter_init(&fs_info->delalloc_bytes, 0, GFP_KERNEL);
 	if (ret) {
 		err = ret;
-		goto fail_dirty_metadata_bytes;
+		goto fail_srcu;
 	}
 
 	ret = percpu_counter_init(&fs_info->dev_replace.bio_counter, 0,
 			GFP_KERNEL);
 	if (ret) {
 		err = ret;
-		goto fail_delalloc_bytes;
+		goto fail_srcu;
 	}
 
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);
@@ -2770,7 +2778,7 @@ int __cold open_ctree(struct super_block *sb,
 	fs_info->btree_inode = new_inode(sb);
 	if (!fs_info->btree_inode) {
 		err = -ENOMEM;
-		goto fail_bio_counter;
+		goto fail_srcu;
 	}
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 
@@ -2883,7 +2891,7 @@ int __cold open_ctree(struct super_block *sb,
 		btrfs_err(fs_info, "superblock checksum mismatch");
 		err = -EINVAL;
 		brelse(bh);
-		goto fail_csum;
+		goto fail_alloc;
 	}
 
 	/*
@@ -2920,11 +2928,11 @@ int __cold open_ctree(struct super_block *sb,
 	if (ret) {
 		btrfs_err(fs_info, "superblock contains fatal errors");
 		err = -EINVAL;
-		goto fail_csum;
+		goto fail_alloc;
 	}
 
 	if (!btrfs_super_root(disk_super))
-		goto fail_csum;
+		goto fail_alloc;
 
 	/* check FS state, whether FS is broken. */
 	if (btrfs_super_flags(disk_super) & BTRFS_SUPER_FLAG_ERROR)
@@ -2939,7 +2947,7 @@ int __cold open_ctree(struct super_block *sb,
 	ret = btrfs_parse_options(fs_info, options, sb->s_flags);
 	if (ret) {
 		err = ret;
-		goto fail_csum;
+		goto fail_alloc;
 	}
 
 	features = btrfs_super_incompat_flags(disk_super) &
@@ -2949,7 +2957,7 @@ int __cold open_ctree(struct super_block *sb,
 		    "cannot mount because of unsupported optional features (%llx)",
 		    features);
 		err = -EINVAL;
-		goto fail_csum;
+		goto fail_alloc;
 	}
 
 	features = btrfs_super_incompat_flags(disk_super);
@@ -2993,7 +3001,7 @@ int __cold open_ctree(struct super_block *sb,
 		btrfs_err(fs_info,
 "unequal nodesize/sectorsize (%u != %u) are not allowed for mixed block groups",
 			nodesize, sectorsize);
-		goto fail_csum;
+		goto fail_alloc;
 	}
 
 	/*
@@ -3009,7 +3017,7 @@ int __cold open_ctree(struct super_block *sb,
 	"cannot mount read-write because of unsupported optional features (%llx)",
 		       features);
 		err = -EINVAL;
-		goto fail_csum;
+		goto fail_alloc;
 	}
 
 	ret = btrfs_init_workqueues(fs_info, fs_devices);
@@ -3346,25 +3354,14 @@ int __cold open_ctree(struct super_block *sb,
 fail_sb_buffer:
 	btrfs_stop_all_workers(fs_info);
 	btrfs_free_block_groups(fs_info);
-fail_csum:
-	btrfs_free_csum_hash(fs_info);
 fail_alloc:
 fail_iput:
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
 	iput(fs_info->btree_inode);
-fail_bio_counter:
-	percpu_counter_destroy(&fs_info->dev_replace.bio_counter);
-fail_delalloc_bytes:
-	percpu_counter_destroy(&fs_info->delalloc_bytes);
-fail_dirty_metadata_bytes:
-	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
-fail_dio_bytes:
-	percpu_counter_destroy(&fs_info->dio_bytes);
 fail_srcu:
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 fail:
-	btrfs_free_stripe_hash_table(fs_info);
 	btrfs_close_devices(fs_info->fs_devices);
 	return err;
 }
@@ -4071,16 +4068,7 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)
 
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 	btrfs_close_devices(fs_info->fs_devices);
-
-	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
-	percpu_counter_destroy(&fs_info->delalloc_bytes);
-	percpu_counter_destroy(&fs_info->dio_bytes);
-	percpu_counter_destroy(&fs_info->dev_replace.bio_counter);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
-
-	btrfs_free_csum_hash(fs_info);
-	btrfs_free_stripe_hash_table(fs_info);
-	btrfs_free_ref_cache(fs_info);
 }
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,

commit bc44d7c4b2b179c4b74fba208b9908e2ecbc1b4d
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:56 2020 -0500

    btrfs: push btrfs_grab_fs_root into btrfs_get_fs_root
    
    Now that all callers of btrfs_get_fs_root are subsequently calling
    btrfs_grab_fs_root and handling dropping the ref when they are done
    appropriately, go ahead and push btrfs_grab_fs_root up into
    btrfs_get_fs_root.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5be61619c71b..a0c67200fb2a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1496,6 +1496,8 @@ static struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
 	spin_lock(&fs_info->fs_roots_radix_lock);
 	root = radix_tree_lookup(&fs_info->fs_roots_radix,
 				 (unsigned long)root_id);
+	if (root)
+		root = btrfs_grab_fs_root(root);
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 	return root;
 }
@@ -1552,29 +1554,31 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	int ret;
 
 	if (location->objectid == BTRFS_ROOT_TREE_OBJECTID)
-		return fs_info->tree_root;
+		return btrfs_grab_fs_root(fs_info->tree_root);
 	if (location->objectid == BTRFS_EXTENT_TREE_OBJECTID)
-		return fs_info->extent_root;
+		return btrfs_grab_fs_root(fs_info->extent_root);
 	if (location->objectid == BTRFS_CHUNK_TREE_OBJECTID)
-		return fs_info->chunk_root;
+		return btrfs_grab_fs_root(fs_info->chunk_root);
 	if (location->objectid == BTRFS_DEV_TREE_OBJECTID)
-		return fs_info->dev_root;
+		return btrfs_grab_fs_root(fs_info->dev_root);
 	if (location->objectid == BTRFS_CSUM_TREE_OBJECTID)
-		return fs_info->csum_root;
+		return btrfs_grab_fs_root(fs_info->csum_root);
 	if (location->objectid == BTRFS_QUOTA_TREE_OBJECTID)
-		return fs_info->quota_root ? fs_info->quota_root :
-					     ERR_PTR(-ENOENT);
+		return btrfs_grab_fs_root(fs_info->quota_root) ?
+			fs_info->quota_root : ERR_PTR(-ENOENT);
 	if (location->objectid == BTRFS_UUID_TREE_OBJECTID)
-		return fs_info->uuid_root ? fs_info->uuid_root :
-					    ERR_PTR(-ENOENT);
+		return btrfs_grab_fs_root(fs_info->uuid_root) ?
+			fs_info->uuid_root : ERR_PTR(-ENOENT);
 	if (location->objectid == BTRFS_FREE_SPACE_TREE_OBJECTID)
-		return fs_info->free_space_root ? fs_info->free_space_root :
-						  ERR_PTR(-ENOENT);
+		return btrfs_grab_fs_root(fs_info->free_space_root) ?
+			fs_info->free_space_root : ERR_PTR(-ENOENT);
 again:
 	root = btrfs_lookup_fs_root(fs_info, location->objectid);
 	if (root) {
-		if (check_ref && btrfs_root_refs(&root->root_item) == 0)
+		if (check_ref && btrfs_root_refs(&root->root_item) == 0) {
+			btrfs_put_fs_root(root);
 			return ERR_PTR(-ENOENT);
+		}
 		return root;
 	}
 
@@ -1607,8 +1611,18 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	if (ret == 0)
 		set_bit(BTRFS_ROOT_ORPHAN_ITEM_INSERTED, &root->state);
 
+	/*
+	 * All roots have two refs on them at all times, one for the mounted fs,
+	 * and one for being in the radix tree.  This way we only free the root
+	 * when we are unmounting or deleting the subvolume.  We get one ref
+	 * from __setup_root, one for inserting it into the radix tree, and then
+	 * we have the third for returning it, and the caller will put it when
+	 * it's done with the root.
+	 */
+	btrfs_grab_fs_root(root);
 	ret = btrfs_insert_fs_root(fs_info, root);
 	if (ret) {
+		btrfs_put_fs_root(root);
 		if (ret == -EEXIST) {
 			btrfs_free_fs_root(root);
 			goto again;
@@ -3207,13 +3221,6 @@ int __cold open_ctree(struct super_block *sb,
 		goto fail_qgroup;
 	}
 
-	if (!btrfs_grab_fs_root(fs_info->fs_root)) {
-		fs_info->fs_root = NULL;
-		err = -ENOENT;
-		btrfs_warn(fs_info, "failed to grab a ref on the fs tree");
-		goto fail_qgroup;
-	}
-
 	if (sb_rdonly(sb))
 		return 0;
 

commit 81f096edf0472864879e1e5a7f0fdf87ea90fe75
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:55 2020 -0500

    btrfs: use btrfs_put_fs_root to free roots always
    
    If we are going to track leaked roots we need to free them all the same
    way, so don't kfree() roots directly, use btrfs_put_fs_root.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 76b888728540..5be61619c71b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1297,7 +1297,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 		free_extent_buffer(root->commit_root);
 		free_extent_buffer(leaf);
 	}
-	kfree(root);
+	btrfs_put_fs_root(root);
 
 	return ERR_PTR(ret);
 }
@@ -1328,7 +1328,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	leaf = btrfs_alloc_tree_block(trans, root, 0, BTRFS_TREE_LOG_OBJECTID,
 			NULL, 0, 0, 0);
 	if (IS_ERR(leaf)) {
-		kfree(root);
+		btrfs_put_fs_root(root);
 		return ERR_CAST(leaf);
 	}
 
@@ -1431,7 +1431,7 @@ struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	return root;
 
 find_fail:
-	kfree(root);
+	btrfs_put_fs_root(root);
 alloc_fail:
 	root = ERR_PTR(ret);
 	goto out;
@@ -1527,17 +1527,17 @@ void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
 {
 	kfree(fs_info->balance_ctl);
 	kfree(fs_info->delayed_root);
-	kfree(fs_info->extent_root);
-	kfree(fs_info->tree_root);
-	kfree(fs_info->chunk_root);
-	kfree(fs_info->dev_root);
-	kfree(fs_info->csum_root);
-	kfree(fs_info->quota_root);
-	kfree(fs_info->uuid_root);
-	kfree(fs_info->free_space_root);
+	btrfs_put_fs_root(fs_info->extent_root);
+	btrfs_put_fs_root(fs_info->tree_root);
+	btrfs_put_fs_root(fs_info->chunk_root);
+	btrfs_put_fs_root(fs_info->dev_root);
+	btrfs_put_fs_root(fs_info->csum_root);
+	btrfs_put_fs_root(fs_info->quota_root);
+	btrfs_put_fs_root(fs_info->uuid_root);
+	btrfs_put_fs_root(fs_info->free_space_root);
+	btrfs_put_fs_root(fs_info->fs_root);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
-	btrfs_put_fs_root(fs_info->fs_root);
 	kvfree(fs_info);
 }
 
@@ -2223,12 +2223,12 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	if (IS_ERR(log_tree_root->node)) {
 		btrfs_warn(fs_info, "failed to read log tree");
 		ret = PTR_ERR(log_tree_root->node);
-		kfree(log_tree_root);
+		btrfs_put_fs_root(log_tree_root);
 		return ret;
 	} else if (!extent_buffer_uptodate(log_tree_root->node)) {
 		btrfs_err(fs_info, "failed to read log tree");
 		free_extent_buffer(log_tree_root->node);
-		kfree(log_tree_root);
+		btrfs_put_fs_root(log_tree_root);
 		return -EIO;
 	}
 	/* returns with log_tree_root freed on success */
@@ -2237,7 +2237,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 		btrfs_handle_fs_error(fs_info, ret,
 				      "Failed to recover log tree");
 		free_extent_buffer(log_tree_root->node);
-		kfree(log_tree_root);
+		btrfs_put_fs_root(log_tree_root);
 		return ret;
 	}
 

commit 4c78e9f59632b5e635e51db9b68111288b38ff22
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:54 2020 -0500

    btrfs: hold a ref on the root in open_ctree
    
    We lookup the fs_root and put it in our fs_info directly, we should hold
    a ref on this root for the lifetime of the fs_info.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ce36a4b9c8a3..76b888728540 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1537,6 +1537,7 @@ void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
 	kfree(fs_info->free_space_root);
 	kfree(fs_info->super_copy);
 	kfree(fs_info->super_for_commit);
+	btrfs_put_fs_root(fs_info->fs_root);
 	kvfree(fs_info);
 }
 
@@ -3206,6 +3207,13 @@ int __cold open_ctree(struct super_block *sb,
 		goto fail_qgroup;
 	}
 
+	if (!btrfs_grab_fs_root(fs_info->fs_root)) {
+		fs_info->fs_root = NULL;
+		err = -ENOENT;
+		btrfs_warn(fs_info, "failed to grab a ref on the fs tree");
+		goto fail_qgroup;
+	}
+
 	if (sb_rdonly(sb))
 		return 0;
 

commit 0d4b0463011de06288d8ca80a873a97a7d99a948
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:53 2020 -0500

    btrfs: export and rename free_fs_info
    
    We're going to start freeing roots and doing other complicated things in
    free_fs_info, so we need to move it to disk-io.c and export it in order
    to use things lik btrfs_put_fs_root().
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 43af9f9b8583..ce36a4b9c8a3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1523,6 +1523,24 @@ int btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
+void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)
+{
+	kfree(fs_info->balance_ctl);
+	kfree(fs_info->delayed_root);
+	kfree(fs_info->extent_root);
+	kfree(fs_info->tree_root);
+	kfree(fs_info->chunk_root);
+	kfree(fs_info->dev_root);
+	kfree(fs_info->csum_root);
+	kfree(fs_info->quota_root);
+	kfree(fs_info->uuid_root);
+	kfree(fs_info->free_space_root);
+	kfree(fs_info->super_copy);
+	kfree(fs_info->super_for_commit);
+	kvfree(fs_info);
+}
+
+
 struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 				     struct btrfs_key *location,
 				     bool check_ref)

commit af01d2e53f3343e9f22495e79f07b107374b05a1
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:27 2020 -0500

    btrfs: hold a ref on fs roots while they're in the radix tree
    
    If the root is sitting in the radix tree, we should probably have a ref
    for the radix tree.  Grab a ref on the root when we insert it, and drop
    it when it gets deleted.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 67e7b0ccdea0..43af9f9b8583 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1513,8 +1513,10 @@ int btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,
 	ret = radix_tree_insert(&fs_info->fs_roots_radix,
 				(unsigned long)root->root_key.objectid,
 				root);
-	if (ret == 0)
+	if (ret == 0) {
+		btrfs_grab_fs_root(root);
 		set_bit(BTRFS_ROOT_IN_RADIX, &root->state);
+	}
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 	radix_tree_preload_end();
 
@@ -3817,6 +3819,8 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 	spin_lock(&fs_info->fs_roots_radix_lock);
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
+	if (test_and_clear_bit(BTRFS_ROOT_IN_RADIX, &root->state))
+		btrfs_put_fs_root(root);
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 
 	if (btrfs_root_refs(&root->root_item) == 0)

commit a98db0f304670dfd65375e6d0ea08793c174bf44
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:25 2020 -0500

    btrfs: make the fs root init functions static
    
    Now that the orphan cleanup stuff doesn't use this directly we can just
    make them static.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f0a33e004d91..67e7b0ccdea0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1437,7 +1437,7 @@ struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	goto out;
 }
 
-int btrfs_init_fs_root(struct btrfs_root *root)
+static int btrfs_init_fs_root(struct btrfs_root *root)
 {
 	int ret;
 	struct btrfs_subvolume_writers *writers;
@@ -1488,8 +1488,8 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 	return ret;
 }
 
-struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
-					u64 root_id)
+static struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
+					       u64 root_id)
 {
 	struct btrfs_root *root;
 

commit 3619c94f073e4e96bef4cc15e70adbc36f3cb203
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:24 2020 -0500

    btrfs: open code btrfs_read_fs_root_no_name
    
    All this does is call btrfs_get_fs_root() with check_ref == true.  Just
    use btrfs_get_fs_root() so we don't have a bunch of different helpers
    that do the same thing.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2e92a6bc64c0..f0a33e004d91 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3178,7 +3178,7 @@ int __cold open_ctree(struct super_block *sb,
 	location.type = BTRFS_ROOT_ITEM_KEY;
 	location.offset = 0;
 
-	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
+	fs_info->fs_root = btrfs_get_fs_root(fs_info, &location, true);
 	if (IS_ERR(fs_info->fs_root)) {
 		err = PTR_ERR(fs_info->fs_root);
 		btrfs_warn(fs_info, "failed to read fs tree: %d", err);

commit 83db2aadb3bd3a117918434448e8c0e90229b73b
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:23 2020 -0500

    btrfs: remove btrfs_read_fs_root, not used anymore
    
    All helpers should either be using btrfs_get_fs_root() or
    btrfs_read_tree_root().
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9807167b6208..2e92a6bc64c0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1437,17 +1437,6 @@ struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	goto out;
 }
 
-struct btrfs_root *btrfs_read_fs_root(struct btrfs_root *tree_root,
-				      struct btrfs_key *location)
-{
-	struct btrfs_root *root;
-
-	root = btrfs_read_tree_root(tree_root, location);
-	if (IS_ERR(root))
-		return root;
-	return root;
-}
-
 int btrfs_init_fs_root(struct btrfs_root *root)
 {
 	int ret;
@@ -1568,7 +1557,7 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 		return root;
 	}
 
-	root = btrfs_read_fs_root(fs_info->tree_root, location);
+	root = btrfs_read_tree_root(fs_info->tree_root, location);
 	if (IS_ERR(root))
 		return root;
 

commit 62a2c73ebda3b0163832610c0e91f350a22908bd
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:21 2020 -0500

    btrfs: export and use btrfs_read_tree_root for tree-log
    
    Tree-log uses btrfs_read_fs_root to load its log, but this just calls
    btrfs_read_tree_root.  We don't save the log roots in our root cache, so
    just export this helper and use it in the logging code.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eff6f0e45c3e..9807167b6208 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1384,8 +1384,8 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	return 0;
 }
 
-static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
-					       struct btrfs_key *key)
+struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
+					struct btrfs_key *key)
 {
 	struct btrfs_root *root;
 	struct btrfs_fs_info *fs_info = tree_root->fs_info;

commit f39e457156f919b849eb2c12a7a4452a1f2be15b
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:19 2020 -0500

    btrfs: move fs root init stuff into btrfs_init_fs_root
    
    We have a helper for reading fs roots that just reads the fs root off
    the disk and then sets REF_COWS and init's the inheritable flags.  Move
    this into btrfs_init_fs_root so we can later get rid of this helper and
    consolidate all of the fs root reading into one helper.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f1121d814e87..eff6f0e45c3e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1445,12 +1445,6 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_root *tree_root,
 	root = btrfs_read_tree_root(tree_root, location);
 	if (IS_ERR(root))
 		return root;
-
-	if (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {
-		set_bit(BTRFS_ROOT_REF_COWS, &root->state);
-		btrfs_check_and_init_root_item(&root->root_item);
-	}
-
 	return root;
 }
 
@@ -1474,6 +1468,11 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 	}
 	root->subv_writers = writers;
 
+	if (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {
+		set_bit(BTRFS_ROOT_REF_COWS, &root->state);
+		btrfs_check_and_init_root_item(&root->root_item);
+	}
+
 	btrfs_init_free_ino_ctl(root);
 	spin_lock_init(&root->ino_cache_lock);
 	init_waitqueue_head(&root->ino_cache_wait);

commit 96dfcb46ffca4803627f7ae74085fbb2bae2acc5
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 24 09:32:18 2020 -0500

    btrfs: push __setup_root into btrfs_alloc_root
    
    There's no reason to not init the root at alloc time, and with later
    patches it actually causes problems if we error out mounting the fs
    before the tree_root is init'ed because we expect it to have a valid ref
    count.  Fix this by pushing __setup_root into btrfs_alloc_root.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c6c9a6a8e6c8..f1121d814e87 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1130,6 +1130,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 			 u64 objectid)
 {
 	bool dummy = test_bit(BTRFS_FS_STATE_DUMMY_FS_INFO, &fs_info->fs_state);
+	root->fs_info = fs_info;
 	root->node = NULL;
 	root->commit_root = NULL;
 	root->state = 0;
@@ -1198,11 +1199,11 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 }
 
 static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info,
-		gfp_t flags)
+					   u64 objectid, gfp_t flags)
 {
 	struct btrfs_root *root = kzalloc(sizeof(*root), flags);
 	if (root)
-		root->fs_info = fs_info;
+		__setup_root(root, fs_info, objectid);
 	return root;
 }
 
@@ -1215,12 +1216,11 @@ struct btrfs_root *btrfs_alloc_dummy_root(struct btrfs_fs_info *fs_info)
 	if (!fs_info)
 		return ERR_PTR(-EINVAL);
 
-	root = btrfs_alloc_root(fs_info, GFP_KERNEL);
+	root = btrfs_alloc_root(fs_info, BTRFS_ROOT_TREE_OBJECTID, GFP_KERNEL);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
 	/* We don't use the stripesize in selftest, set it as sectorsize */
-	__setup_root(root, fs_info, BTRFS_ROOT_TREE_OBJECTID);
 	root->alloc_bytenr = 0;
 
 	return root;
@@ -1244,12 +1244,11 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	 * context to avoid deadlock if reclaim happens.
 	 */
 	nofs_flag = memalloc_nofs_save();
-	root = btrfs_alloc_root(fs_info, GFP_KERNEL);
+	root = btrfs_alloc_root(fs_info, objectid, GFP_KERNEL);
 	memalloc_nofs_restore(nofs_flag);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
-	__setup_root(root, fs_info, objectid);
 	root->root_key.objectid = objectid;
 	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
 	root->root_key.offset = 0;
@@ -1309,12 +1308,10 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	struct btrfs_root *root;
 	struct extent_buffer *leaf;
 
-	root = btrfs_alloc_root(fs_info, GFP_NOFS);
+	root = btrfs_alloc_root(fs_info, BTRFS_TREE_LOG_OBJECTID, GFP_NOFS);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
-	__setup_root(root, fs_info, BTRFS_TREE_LOG_OBJECTID);
-
 	root->root_key.objectid = BTRFS_TREE_LOG_OBJECTID;
 	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
 	root->root_key.offset = BTRFS_TREE_LOG_OBJECTID;
@@ -1401,14 +1398,12 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	if (!path)
 		return ERR_PTR(-ENOMEM);
 
-	root = btrfs_alloc_root(fs_info, GFP_NOFS);
+	root = btrfs_alloc_root(fs_info, key->objectid, GFP_NOFS);
 	if (!root) {
 		ret = -ENOMEM;
 		goto alloc_fail;
 	}
 
-	__setup_root(root, fs_info, key->objectid);
-
 	ret = btrfs_find_root(tree_root, key, path,
 			      &root->root_item, &root->root_key);
 	if (ret) {
@@ -2208,12 +2203,11 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 		return -EIO;
 	}
 
-	log_tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
+	log_tree_root = btrfs_alloc_root(fs_info, BTRFS_TREE_LOG_OBJECTID,
+					 GFP_KERNEL);
 	if (!log_tree_root)
 		return -ENOMEM;
 
-	__setup_root(log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
-
 	log_tree_root->node = read_tree_block(fs_info, bytenr,
 					      fs_info->generation + 1,
 					      level, NULL);
@@ -2645,8 +2639,12 @@ int __cold open_ctree(struct super_block *sb,
 	int clear_free_space_tree = 0;
 	int level;
 
-	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
-	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
+	tree_root = btrfs_alloc_root(fs_info, BTRFS_ROOT_TREE_OBJECTID,
+				     GFP_KERNEL);
+	fs_info->tree_root = tree_root;
+	chunk_root = btrfs_alloc_root(fs_info, BTRFS_CHUNK_TREE_OBJECTID,
+				      GFP_KERNEL);
+	fs_info->chunk_root = chunk_root;
 	if (!tree_root || !chunk_root) {
 		err = -ENOMEM;
 		goto fail;
@@ -2824,8 +2822,6 @@ int __cold open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
-	__setup_root(tree_root, fs_info, BTRFS_ROOT_TREE_OBJECTID);
-
 	invalidate_bdev(fs_devices->latest_bdev);
 
 	/*
@@ -3021,8 +3017,6 @@ int __cold open_ctree(struct super_block *sb,
 	generation = btrfs_super_chunk_root_generation(disk_super);
 	level = btrfs_super_chunk_root_level(disk_super);
 
-	__setup_root(chunk_root, fs_info, BTRFS_CHUNK_TREE_OBJECTID);
-
 	chunk_root->node = read_tree_block(fs_info,
 					   btrfs_super_chunk_root(disk_super),
 					   generation, level, NULL);

commit 1e90315149f3fe148e114a5de86f0196d1c21fa5
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Feb 13 10:47:29 2020 -0500

    btrfs: do not check delayed items are empty for single transaction cleanup
    
    btrfs_assert_delayed_root_empty() will check if the delayed root is
    completely empty, but this is a filesystem-wide check.  On cleanup we
    may have allowed other transactions to begin, for whatever reason, and
    thus the delayed root is not empty.
    
    So remove this check from cleanup_one_transation().  This however can
    stay in btrfs_cleanup_transaction(), because it checks only after all of
    the transactions have been properly cleaned up, and thus is valid.
    
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 197352f23534..c6c9a6a8e6c8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4503,7 +4503,6 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	wake_up(&fs_info->transaction_wait);
 
 	btrfs_destroy_delayed_inodes(fs_info);
-	btrfs_assert_delayed_root_empty(fs_info);
 
 	btrfs_destroy_marked_extents(fs_info, &cur_trans->dirty_pages,
 				     EXTENT_DIRTY);

commit 315bf8ef914f31d51d084af950703aa1e09a728c
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Feb 13 10:47:28 2020 -0500

    btrfs: reset fs_root to NULL on error in open_ctree
    
    While running my error injection script I hit a panic when we tried to
    clean up the fs_root when freeing the fs_root.  This is because
    fs_info->fs_root == PTR_ERR(-EIO), which isn't great.  Fix this by
    setting fs_info->fs_root = NULL; if we fail to read the root.
    
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d7fec89974cb..197352f23534 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3200,6 +3200,7 @@ int __cold open_ctree(struct super_block *sb,
 	if (IS_ERR(fs_info->fs_root)) {
 		err = PTR_ERR(fs_info->fs_root);
 		btrfs_warn(fs_info, "failed to read fs tree: %d", err);
+		fs_info->fs_root = NULL;
 		goto fail_qgroup;
 	}
 

commit 81f7eb00ff5bb8326e82503a32809421d14abb8a
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Feb 11 15:25:37 2020 +0800

    btrfs: destroy qgroup extent records on transaction abort
    
    We clean up the delayed references when we abort a transaction but we
    leave the pending qgroup extent records behind, leaking memory.
    
    This patch destroys the extent records when we destroy the delayed refs
    and makes sure ensure they're gone before releasing the transaction.
    
    Fixes: 3368d001ba5d ("btrfs: qgroup: Record possible quota-related extent for qgroup.")
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    [ Rebased to latest upstream, remove to_qgroup() helper, use
      rbtree_postorder_for_each_entry_safe() wrapper ]
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 89422aa8e9d1..d7fec89974cb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4276,6 +4276,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		cond_resched();
 		spin_lock(&delayed_refs->lock);
 	}
+	btrfs_qgroup_destroy_extent_records(trans);
 
 	spin_unlock(&delayed_refs->lock);
 

commit e8294f2f6aa6208ed0923aa6d70cea3be178309a
Author: David Sterba <dsterba@suse.com>
Date:   Wed Feb 5 17:12:16 2020 +0100

    btrfs: print message when tree-log replay starts
    
    There's no logged information about tree-log replay although this is
    something that points to previous unclean unmount. Other filesystems
    report that as well.
    
    Suggested-by: Chris Murphy <lists@colorremedies.com>
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7fa9bb79ad08..89422aa8e9d1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3164,6 +3164,7 @@ int __cold open_ctree(struct super_block *sb,
 	/* do not make disk changes in broken FS or nologreplay is given */
 	if (btrfs_super_log_root(disk_super) != 0 &&
 	    !btrfs_test_opt(fs_info, NOLOGREPLAY)) {
+		btrfs_info(fs_info, "start tree-log replay");
 		ret = btrfs_replay_log(fs_info, fs_devices);
 		if (ret) {
 			err = ret;

commit 7227ff4de55d931bbdc156c8ef0ce4f100c78a5b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Jan 22 12:23:20 2020 +0000

    Btrfs: fix race between adding and putting tree mod seq elements and nodes
    
    There is a race between adding and removing elements to the tree mod log
    list and rbtree that can lead to use-after-free problems.
    
    Consider the following example that explains how/why the problems happens:
    
    1) Task A has mod log element with sequence number 200. It currently is
       the only element in the mod log list;
    
    2) Task A calls btrfs_put_tree_mod_seq() because it no longer needs to
       access the tree mod log. When it enters the function, it initializes
       'min_seq' to (u64)-1. Then it acquires the lock 'tree_mod_seq_lock'
       before checking if there are other elements in the mod seq list.
       Since the list it empty, 'min_seq' remains set to (u64)-1. Then it
       unlocks the lock 'tree_mod_seq_lock';
    
    3) Before task A acquires the lock 'tree_mod_log_lock', task B adds
       itself to the mod seq list through btrfs_get_tree_mod_seq() and gets a
       sequence number of 201;
    
    4) Some other task, name it task C, modifies a btree and because there
       elements in the mod seq list, it adds a tree mod elem to the tree
       mod log rbtree. That node added to the mod log rbtree is assigned
       a sequence number of 202;
    
    5) Task B, which is doing fiemap and resolving indirect back references,
       calls btrfs get_old_root(), with 'time_seq' == 201, which in turn
       calls tree_mod_log_search() - the search returns the mod log node
       from the rbtree with sequence number 202, created by task C;
    
    6) Task A now acquires the lock 'tree_mod_log_lock', starts iterating
       the mod log rbtree and finds the node with sequence number 202. Since
       202 is less than the previously computed 'min_seq', (u64)-1, it
       removes the node and frees it;
    
    7) Task B still has a pointer to the node with sequence number 202, and
       it dereferences the pointer itself and through the call to
       __tree_mod_log_rewind(), resulting in a use-after-free problem.
    
    This issue can be triggered sporadically with the test case generic/561
    from fstests, and it happens more frequently with a higher number of
    duperemove processes. When it happens to me, it either freezes the VM or
    it produces a trace like the following before crashing:
    
      [ 1245.321140] general protection fault: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC PTI
      [ 1245.321200] CPU: 1 PID: 26997 Comm: pool Not tainted 5.5.0-rc6-btrfs-next-52 #1
      [ 1245.321235] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.12.0-0-ga698c8995f-prebuilt.qemu.org 04/01/2014
      [ 1245.321287] RIP: 0010:rb_next+0x16/0x50
      [ 1245.321307] Code: ....
      [ 1245.321372] RSP: 0018:ffffa151c4d039b0 EFLAGS: 00010202
      [ 1245.321388] RAX: 6b6b6b6b6b6b6b6b RBX: ffff8ae221363c80 RCX: 6b6b6b6b6b6b6b6b
      [ 1245.321409] RDX: 0000000000000001 RSI: 0000000000000000 RDI: ffff8ae221363c80
      [ 1245.321439] RBP: ffff8ae20fcc4688 R08: 0000000000000002 R09: 0000000000000000
      [ 1245.321475] R10: ffff8ae20b120910 R11: 00000000243f8bb1 R12: 0000000000000038
      [ 1245.321506] R13: ffff8ae221363c80 R14: 000000000000075f R15: ffff8ae223f762b8
      [ 1245.321539] FS:  00007fdee1ec7700(0000) GS:ffff8ae236c80000(0000) knlGS:0000000000000000
      [ 1245.321591] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [ 1245.321614] CR2: 00007fded4030c48 CR3: 000000021da16003 CR4: 00000000003606e0
      [ 1245.321642] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [ 1245.321668] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [ 1245.321706] Call Trace:
      [ 1245.321798]  __tree_mod_log_rewind+0xbf/0x280 [btrfs]
      [ 1245.321841]  btrfs_search_old_slot+0x105/0xd00 [btrfs]
      [ 1245.321877]  resolve_indirect_refs+0x1eb/0xc60 [btrfs]
      [ 1245.321912]  find_parent_nodes+0x3dc/0x11b0 [btrfs]
      [ 1245.321947]  btrfs_check_shared+0x115/0x1c0 [btrfs]
      [ 1245.321980]  ? extent_fiemap+0x59d/0x6d0 [btrfs]
      [ 1245.322029]  extent_fiemap+0x59d/0x6d0 [btrfs]
      [ 1245.322066]  do_vfs_ioctl+0x45a/0x750
      [ 1245.322081]  ksys_ioctl+0x70/0x80
      [ 1245.322092]  ? trace_hardirqs_off_thunk+0x1a/0x1c
      [ 1245.322113]  __x64_sys_ioctl+0x16/0x20
      [ 1245.322126]  do_syscall_64+0x5c/0x280
      [ 1245.322139]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [ 1245.322155] RIP: 0033:0x7fdee3942dd7
      [ 1245.322177] Code: ....
      [ 1245.322258] RSP: 002b:00007fdee1ec6c88 EFLAGS: 00000246 ORIG_RAX: 0000000000000010
      [ 1245.322294] RAX: ffffffffffffffda RBX: 00007fded40210d8 RCX: 00007fdee3942dd7
      [ 1245.322314] RDX: 00007fded40210d8 RSI: 00000000c020660b RDI: 0000000000000004
      [ 1245.322337] RBP: 0000562aa89e7510 R08: 0000000000000000 R09: 00007fdee1ec6d44
      [ 1245.322369] R10: 0000000000000073 R11: 0000000000000246 R12: 00007fdee1ec6d48
      [ 1245.322390] R13: 00007fdee1ec6d40 R14: 00007fded40210d0 R15: 00007fdee1ec6d50
      [ 1245.322423] Modules linked in: ....
      [ 1245.323443] ---[ end trace 01de1e9ec5dff3cd ]---
    
    Fix this by ensuring that btrfs_put_tree_mod_seq() computes the minimum
    sequence number and iterates the rbtree while holding the lock
    'tree_mod_log_lock' in write mode. Also get rid of the 'tree_mod_seq_lock'
    lock, since it is now redundant.
    
    Fixes: bd989ba359f2ac ("Btrfs: add tree modification log functions")
    Fixes: 097b8a7c9e48e2 ("Btrfs: join tree mod log code with the code holding back delayed refs")
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aea48d6ddc0c..7fa9bb79ad08 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2697,7 +2697,6 @@ int __cold open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->fs_roots_radix_lock);
 	spin_lock_init(&fs_info->delayed_iput_lock);
 	spin_lock_init(&fs_info->defrag_inodes_lock);
-	spin_lock_init(&fs_info->tree_mod_seq_lock);
 	spin_lock_init(&fs_info->super_lock);
 	spin_lock_init(&fs_info->buffer_lock);
 	spin_lock_init(&fs_info->unused_bgs_lock);

commit 4e19443da1941050b346f8fc4c368aa68413bc88
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Tue Jan 21 09:17:06 2020 -0500

    btrfs: free block groups after free'ing fs trees
    
    Sometimes when running generic/475 we would trip the
    WARN_ON(cache->reserved) check when free'ing the block groups on umount.
    This is because sometimes we don't commit the transaction because of IO
    errors and thus do not cleanup the tree logs until at umount time.
    
    These blocks are still reserved until they are cleaned up, but they
    aren't cleaned up until _after_ we do the free block groups work.  Fix
    this by moving the free after free'ing the fs roots, that way all of the
    tree logs are cleaned up and we have a properly cleaned fs.  A bunch of
    loops of generic/475 confirmed this fixes the problem.
    
    CC: stable@vger.kernel.org # 4.9+
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5ce2801f8388..aea48d6ddc0c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4030,11 +4030,18 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	btrfs_stop_all_workers(fs_info);
 
-	btrfs_free_block_groups(fs_info);
-
 	clear_bit(BTRFS_FS_OPEN, &fs_info->flags);
 	free_root_pointers(fs_info, true);
 
+	/*
+	 * We must free the block groups after dropping the fs_roots as we could
+	 * have had an IO error and have left over tree log blocks that aren't
+	 * cleaned up until the fs roots are freed.  This makes the block group
+	 * accounting appear to be wrong because there's pending reserved bytes,
+	 * so make sure we do the block group cleanup afterwards.
+	 */
+	btrfs_free_block_groups(fs_info);
+
 	iput(fs_info->btree_inode);
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY

commit b0643e59cfa609c4b5f246f2b2c33b078f87e9d9
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:14 2019 -0800

    btrfs: add the beginning of async discard, discard workqueue
    
    When discard is enabled, everytime a pinned extent is released back to
    the block_group's free space cache, a discard is issued for the extent.
    This is an overeager approach when it comes to discarding and helping
    the SSD maintain enough free space to prevent severe garbage collection
    situations.
    
    This adds the beginning of async discard. Instead of issuing a discard
    prior to returning it to the free space, it is just marked as untrimmed.
    The block_group is then added to a LRU which then feeds into a workqueue
    to issue discards at a much slower rate. Full discarding of unused block
    groups is still done and will be addressed in a future patch of the
    series.
    
    For now, we don't persist the discard state of extents and bitmaps.
    Therefore, our failure recovery mode will be to consider extents
    untrimmed. This lets us handle failure and unmounting as one in the
    same.
    
    On a number of Facebook webservers, I collected data every minute
    accounting the time we spent in btrfs_finish_extent_commit() (col. 1)
    and in btrfs_commit_transaction() (col. 2). btrfs_finish_extent_commit()
    is where we discard extents synchronously before returning them to the
    free space cache.
    
    discard=sync:
                     p99 total per minute       p99 total per minute
          Drive   |   extent_commit() (ms)  |    commit_trans() (ms)
        ---------------------------------------------------------------
         Drive A  |           434           |          1170
         Drive B  |           880           |          2330
         Drive C  |          2943           |          3920
         Drive D  |          4763           |          5701
    
    discard=async:
                     p99 total per minute       p99 total per minute
          Drive   |   extent_commit() (ms)  |    commit_trans() (ms)
        --------------------------------------------------------------
         Drive A  |           134           |           956
         Drive B  |            64           |          1972
         Drive C  |            59           |          1032
         Drive D  |            62           |          1200
    
    While it's not great that the stats are cumulative over 1m, all of these
    servers are running the same workload and and the delta between the two
    are substantial. We are spending significantly less time in
    btrfs_finish_extent_commit() which is responsible for discarding.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 881aba162e4e..5ce2801f8388 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -41,6 +41,7 @@
 #include "tree-checker.h"
 #include "ref-verify.h"
 #include "block-group.h"
+#include "discard.h"
 
 #define BTRFS_SUPER_FLAG_SUPP	(BTRFS_HEADER_FLAG_WRITTEN |\
 				 BTRFS_HEADER_FLAG_RELOC |\
@@ -1953,6 +1954,8 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->readahead_workers);
 	btrfs_destroy_workqueue(fs_info->flush_workers);
 	btrfs_destroy_workqueue(fs_info->qgroup_rescan_workers);
+	if (fs_info->discard_ctl.discard_workers)
+		destroy_workqueue(fs_info->discard_ctl.discard_workers);
 	/*
 	 * Now that all other work queues are destroyed, we can safely destroy
 	 * the queues used for metadata I/O, since tasks from those other work
@@ -2148,6 +2151,8 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 				      max_active, 2);
 	fs_info->qgroup_rescan_workers =
 		btrfs_alloc_workqueue(fs_info, "qgroup-rescan", flags, 1, 0);
+	fs_info->discard_ctl.discard_workers =
+		alloc_workqueue("btrfs_discard", WQ_UNBOUND | WQ_FREEZABLE, 1);
 
 	if (!(fs_info->workers && fs_info->delalloc_workers &&
 	      fs_info->flush_workers &&
@@ -2158,7 +2163,8 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
 	      fs_info->caching_workers && fs_info->readahead_workers &&
 	      fs_info->fixup_workers && fs_info->delayed_workers &&
-	      fs_info->qgroup_rescan_workers)) {
+	      fs_info->qgroup_rescan_workers &&
+	      fs_info->discard_ctl.discard_workers)) {
 		return -ENOMEM;
 	}
 
@@ -2792,6 +2798,7 @@ int __cold open_ctree(struct super_block *sb,
 
 	btrfs_init_dev_replace_locks(fs_info);
 	btrfs_init_qgroup(fs_info);
+	btrfs_discard_init(fs_info);
 
 	btrfs_init_free_cluster(&fs_info->meta_alloc_cluster);
 	btrfs_init_free_cluster(&fs_info->data_alloc_cluster);
@@ -3255,6 +3262,7 @@ int __cold open_ctree(struct super_block *sb,
 	}
 
 	btrfs_qgroup_rescan_resume(fs_info);
+	btrfs_discard_resume(fs_info);
 
 	if (!fs_info->uuid_root) {
 		btrfs_info(fs_info, "creating UUID tree");
@@ -3971,6 +3979,9 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)
 
 	cancel_work_sync(&fs_info->async_reclaim_work);
 
+	/* Cancel or finish ongoing discard work */
+	btrfs_discard_cleanup(fs_info);
+
 	if (!sb_rdonly(fs_info->sb)) {
 		/*
 		 * The cleaner kthread is stopped, so do one final pass over

commit 39b07b5d7072f8e9fd8cc2f840d3749f86699bbb
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Dec 2 17:34:23 2019 -0800

    btrfs: drop create parameter to btrfs_get_extent()
    
    We only pass this as 1 from __extent_writepage_io(). The parameter
    basically means "pretend I didn't pass in a page". This is silly since
    we can simply not pass in the page. Get rid of the parameter from
    btrfs_get_extent(), and since it's used as a get_extent_t callback,
    remove it from get_extent_t and btree_get_extent(), neither of which
    need it.
    
    While we're here, let's document btrfs_get_extent().
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ab888d89d844..881aba162e4e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -202,8 +202,8 @@ void btrfs_set_buffer_lockdep_class(u64 objectid, struct extent_buffer *eb,
  * that covers the entire device
  */
 struct extent_map *btree_get_extent(struct btrfs_inode *inode,
-		struct page *page, size_t pg_offset, u64 start, u64 len,
-		int create)
+				    struct page *page, size_t pg_offset,
+				    u64 start, u64 len)
 {
 	struct extent_map_tree *em_tree = &inode->extent_tree;
 	struct extent_map *em;

commit bc036bb33524dcb2525d74c336e9694d5d3c0047
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Nov 21 17:33:34 2019 +0800

    btrfs: sysfs, merge btrfs_sysfs_add devices_kobj and fsid
    
    Merge btrfs_sysfs_add_fsid() and btrfs_sysfs_add_devices_kobj() functions
    as these two are small and they are called one after the other.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 65cfd0fd0f83..ab888d89d844 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3089,13 +3089,6 @@ int __cold open_ctree(struct super_block *sb,
 		goto fail_block_groups;
 	}
 
-	ret = btrfs_sysfs_add_devices_kobj(fs_devices);
-	if (ret) {
-		btrfs_err(fs_info, "failed to init sysfs device interface: %d",
-				ret);
-		goto fail_fsdev_sysfs;
-	}
-
 	ret = btrfs_sysfs_add_mounted(fs_info);
 	if (ret) {
 		btrfs_err(fs_info, "failed to init sysfs interface: %d", ret);

commit be2cf92e0a2f64efe0709a2cfe5d9f4852d14b61
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Nov 21 17:33:33 2019 +0800

    btrfs: sysfs, rename btrfs_sysfs_add_device()
    
    btrfs_sysfs_add_device() creates the directory
    /sys/fs/btrfs/UUID/devices but its function name is misleading. Rename
    it to btrfs_sysfs_add_devices_kobj() instead. No functional changes.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 639104326691..65cfd0fd0f83 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3089,7 +3089,7 @@ int __cold open_ctree(struct super_block *sb,
 		goto fail_block_groups;
 	}
 
-	ret = btrfs_sysfs_add_device(fs_devices);
+	ret = btrfs_sysfs_add_devices_kobj(fs_devices);
 	if (ret) {
 		btrfs_err(fs_info, "failed to init sysfs device interface: %d",
 				ret);

commit c6761a9ed329dd41fee09dc2926126768e5ca34c
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Nov 21 17:33:32 2019 +0800

    btrfs: sysfs, btrfs_sysfs_add_fsid() drop unused argument parent
    
    Commit 24bd69cb ("Btrfs: sysfs: add support to add parent for fsid")
    added parent argument in preparation to show the seed fsid under the
    sprout fsid as in the patch [1] in the mailing list.
    
     [1] Btrfs: sysfs: support seed devices in the sysfs layout
    
    But later this idea was superseded by another idea to rename the fsid as
    in the commit f93c39970b1d ("btrfs: factor out sysfs code for updating
    sprout fsid").
    
    So we don't need parent argument anymore.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e0edfdc9c82b..639104326691 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3082,7 +3082,7 @@ int __cold open_ctree(struct super_block *sb,
 
 	btrfs_free_extra_devids(fs_devices, 1);
 
-	ret = btrfs_sysfs_add_fsid(fs_devices, NULL);
+	ret = btrfs_sysfs_add_fsid(fs_devices);
 	if (ret) {
 		btrfs_err(fs_info, "failed to init sysfs fsid interface: %d",
 				ret);

commit a019e9e197eaa68ffe2efeba00d685581b1a5416
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 30 15:40:53 2019 +0200

    btrfs: remove extent_map::bdev
    
    We can now remove the bdev from extent_map. Previous patches made sure
    that bio_set_dev is correctly in all places and that we don't need to
    grab it from latest_bdev or pass it around inside the extent map.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8783d86f487d..e0edfdc9c82b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -205,7 +205,6 @@ struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 		struct page *page, size_t pg_offset, u64 start, u64 len,
 		int create)
 {
-	struct btrfs_fs_info *fs_info = inode->root->fs_info;
 	struct extent_map_tree *em_tree = &inode->extent_tree;
 	struct extent_map *em;
 	int ret;
@@ -213,7 +212,6 @@ struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 	read_lock(&em_tree->lock);
 	em = lookup_extent_mapping(em_tree, start, len);
 	if (em) {
-		em->bdev = fs_info->fs_devices->latest_bdev;
 		read_unlock(&em_tree->lock);
 		goto out;
 	}
@@ -228,7 +226,6 @@ struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 	em->len = (u64)-1;
 	em->block_len = (u64)-1;
 	em->block_start = 0;
-	em->bdev = fs_info->fs_devices->latest_bdev;
 
 	write_lock(&em_tree->lock);
 	ret = add_extent_mapping(em_tree, em, 0);

commit 32da5386d9a4fd5c1155cecf703df104d918954c
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 29 19:20:18 2019 +0100

    btrfs: rename btrfs_block_group_cache
    
    The type name is misleading, a single entry is named 'cache' while this
    normally means a collection of objects. Rename that everywhere. Also the
    identifier was quite long, making function prototypes harder to format.
    
    Suggested-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ddb39f76f71a..8783d86f487d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4409,7 +4409,7 @@ static int btrfs_destroy_pinned_extent(struct btrfs_fs_info *fs_info,
 	return 0;
 }
 
-static void btrfs_cleanup_bg_io(struct btrfs_block_group_cache *cache)
+static void btrfs_cleanup_bg_io(struct btrfs_block_group *cache)
 {
 	struct inode *inode;
 
@@ -4426,12 +4426,12 @@ static void btrfs_cleanup_bg_io(struct btrfs_block_group_cache *cache)
 void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 			     struct btrfs_fs_info *fs_info)
 {
-	struct btrfs_block_group_cache *cache;
+	struct btrfs_block_group *cache;
 
 	spin_lock(&cur_trans->dirty_bgs_lock);
 	while (!list_empty(&cur_trans->dirty_bgs)) {
 		cache = list_first_entry(&cur_trans->dirty_bgs,
-					 struct btrfs_block_group_cache,
+					 struct btrfs_block_group,
 					 dirty_list);
 
 		if (!list_empty(&cache->io_list)) {
@@ -4459,7 +4459,7 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 	 */
 	while (!list_empty(&cur_trans->io_bgs)) {
 		cache = list_first_entry(&cur_trans->io_bgs,
-					 struct btrfs_block_group_cache,
+					 struct btrfs_block_group,
 					 io_list);
 
 		list_del_init(&cache->io_list);

commit 6ef108dd0cda65d3031166222e64cdf71fdd3359
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 15 18:42:24 2019 +0300

    btrfs: Streamline btrfs_fs_info::backup_root_index semantics
    
    The backup_root_index member stores the index at which the backup root
    should be saved upon next transaction commit. However, there is a
    small deviation from this behavior in the form of a check in
    backup_super_roots which checks if current root generation equals to the
    generation of the previous root. This can trigger in the following
    scenario:
    
    slot0: gen-2
    slot1: gen-1
    slot2: gen
    slot3: unused
    
    Now suppose slot3 (which is also the root specified in the super block)
    is corrupted hence init_tree_roots chooses to use the backup root at
    slot2, meaning read_backup_root will read slot2 and assign the
    superblock generation to gen-1. Despite this backup_root_index will
    point at slot3 because its init happens in init_backup_root_slot, long
    before any parsing of the backup roots occur. Then on next transaction
    start, gen-1 will be incremented by 1 making the root's generation
    equal gen. Subsequently, on transaction commit the following check
    triggers:
    
      if (btrfs_backup_tree_root_gen(root_backup) ==
               btrfs_header_generation(info->tree_root->node))
    
    This causes the 'next_backup', which is the index at which the backup is
    going to be written to, to set to last_backup, which will be slot2.
    
    All of this is a very confusing way of expressing the following
    invariant:
    
     Always write a backup root at the index following the last used backup
     root.
    
    This commit streamlines this logic by setting backup_root_index to the
    next index after the one used for mount.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6c44d1781f21..ddb39f76f71a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1815,23 +1815,6 @@ static int find_newest_super_backup(struct btrfs_fs_info *info)
 	return -EINVAL;
 }
 
-/*
- * Initialize backup_root_index with the next available slot, where subsequent
- * transaction commit will store the backup root
- */
-static void init_backup_root_slot(struct btrfs_fs_info *info)
-{
-	int newest_index;
-
-	newest_index = find_newest_super_backup(info);
-	/* if there was garbage in there, just move along */
-	if (newest_index == -EINVAL) {
-		info->backup_root_index = 0;
-	} else {
-		info->backup_root_index = (newest_index + 1) % BTRFS_NUM_BACKUP_ROOTS;
-	}
-}
-
 /*
  * copy all the root pointers into the super backup array.
  * this will bump the backup pointer by one when it is
@@ -1839,22 +1822,8 @@ static void init_backup_root_slot(struct btrfs_fs_info *info)
  */
 static void backup_super_roots(struct btrfs_fs_info *info)
 {
-	int next_backup;
+	const int next_backup = info->backup_root_index;
 	struct btrfs_root_backup *root_backup;
-	int last_backup;
-
-	next_backup = info->backup_root_index;
-	last_backup = (next_backup + BTRFS_NUM_BACKUP_ROOTS - 1) %
-		BTRFS_NUM_BACKUP_ROOTS;
-
-	/*
-	 * just overwrite the last backup if we're at the same generation
-	 * this happens only at umount
-	 */
-	root_backup = info->super_for_commit->super_roots + last_backup;
-	if (btrfs_backup_tree_root_gen(root_backup) ==
-	    btrfs_header_generation(info->tree_root->node))
-		next_backup = last_backup;
 
 	root_backup = info->super_for_commit->super_roots + next_backup;
 
@@ -2558,8 +2527,9 @@ static int btrfs_validate_write_super(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
-int __cold init_tree_roots(struct btrfs_fs_info *fs_info)
+static int __cold init_tree_roots(struct btrfs_fs_info *fs_info)
 {
+	int backup_index = find_newest_super_backup(fs_info);
 	struct btrfs_super_block *sb = fs_info->super_copy;
 	struct btrfs_root *tree_root = fs_info->tree_root;
 	bool handle_error = false;
@@ -2590,6 +2560,7 @@ int __cold init_tree_roots(struct btrfs_fs_info *fs_info)
 			btrfs_set_opt(fs_info->mount_opt, CLEAR_CACHE);
 
 			ret = read_backup_root(fs_info, i);
+			backup_index = ret;
 			if (ret < 0)
 				return ret;
 		}
@@ -2636,6 +2607,14 @@ int __cold init_tree_roots(struct btrfs_fs_info *fs_info)
 		/* All successful */
 		fs_info->generation = generation;
 		fs_info->last_trans_committed = generation;
+
+		/* Always begin writing backup roots after the one being used */
+		if (backup_index < 0) {
+			fs_info->backup_root_index = 0;
+		} else {
+			fs_info->backup_root_index = backup_index + 1;
+			fs_info->backup_root_index %= BTRFS_NUM_BACKUP_ROOTS;
+		}
 		break;
 	}
 
@@ -2929,12 +2908,6 @@ int __cold open_ctree(struct super_block *sb,
 	if (btrfs_super_flags(disk_super) & BTRFS_SUPER_FLAG_ERROR)
 		set_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state);
 
-	/*
-	 * run through our array of backup supers and setup
-	 * our ring pointer to the oldest one
-	 */
-	init_backup_root_slot(fs_info);
-
 	/*
 	 * In the long term, we'll store the compression type in the super
 	 * block, and it'll be used for per file compression control.

commit 4ac039ad75df3f5f5f5b2b7439f094ad5bd9dbbe
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 15 18:42:23 2019 +0300

    btrfs: Rename find_oldest_super_backup to init_backup_root_slot
    
    The old name name was an awful misnomer because it didn't really find
    the oldest super backup per-se but rather its slot. For example if we
    have:
    
    slot0: gen - 2
    slot1: gen - 1
    slot2: gen
    slot3: empty
    
    init_backup_root_slot will return slot3 and not slot0.
    
    The new name is more appropriate since the function doesn't care whether
    there is a valid backup in the returned slot or not.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 99ba3278628c..6c44d1781f21 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1815,13 +1815,11 @@ static int find_newest_super_backup(struct btrfs_fs_info *info)
 	return -EINVAL;
 }
 
-
 /*
- * find the oldest backup so we know where to store new entries
- * in the backup array.  This will set the backup_root_index
- * field in the fs_info struct
+ * Initialize backup_root_index with the next available slot, where subsequent
+ * transaction commit will store the backup root
  */
-static void find_oldest_super_backup(struct btrfs_fs_info *info)
+static void init_backup_root_slot(struct btrfs_fs_info *info)
 {
 	int newest_index;
 
@@ -2935,7 +2933,7 @@ int __cold open_ctree(struct super_block *sb,
 	 * run through our array of backup supers and setup
 	 * our ring pointer to the oldest one
 	 */
-	find_oldest_super_backup(fs_info);
+	init_backup_root_slot(fs_info);
 
 	/*
 	 * In the long term, we'll store the compression type in the super

commit 260eb11bd42b4b5bcd671a1f8cb7d7b9a3e36b8d
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 15 18:42:22 2019 +0300

    btrfs: Remove unused next_root_backup function
    
    This function has been superseded by previous commits and is no longer
    used so just remove it.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b23c9fbc2e89..99ba3278628c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1972,56 +1972,6 @@ static int read_backup_root(struct btrfs_fs_info *fs_info, u8 priority)
 	return backup_index;
 }
 
-/*
- * this copies info out of the root backup array and back into
- * the in-memory super block.  It is meant to help iterate through
- * the array, so you send it the number of backups you've already
- * tried and the last backup index you used.
- *
- * this returns -1 when it has tried all the backups
- */
-static noinline int next_root_backup(struct btrfs_fs_info *info,
-				     struct btrfs_super_block *super,
-				     int *num_backups_tried, int *backup_index)
-{
-	struct btrfs_root_backup *root_backup;
-	int newest = *backup_index;
-
-	if (*num_backups_tried == 0) {
-		newest = find_newest_super_backup(info);
-		if (newest == -1)
-			return -1;
-
-		*backup_index = newest;
-		*num_backups_tried = 1;
-	} else if (*num_backups_tried == BTRFS_NUM_BACKUP_ROOTS) {
-		/* we've tried all the backups, all done */
-		return -1;
-	} else {
-		/* jump to the next oldest backup */
-		newest = (*backup_index + BTRFS_NUM_BACKUP_ROOTS - 1) %
-			BTRFS_NUM_BACKUP_ROOTS;
-		*backup_index = newest;
-		*num_backups_tried += 1;
-	}
-	root_backup = super->super_roots + newest;
-
-	btrfs_set_super_generation(super,
-				   btrfs_backup_tree_root_gen(root_backup));
-	btrfs_set_super_root(super, btrfs_backup_tree_root(root_backup));
-	btrfs_set_super_root_level(super,
-				   btrfs_backup_tree_root_level(root_backup));
-	btrfs_set_super_bytes_used(super, btrfs_backup_bytes_used(root_backup));
-
-	/*
-	 * fixme: the total bytes and num_devices need to match or we should
-	 * need a fsck
-	 */
-	btrfs_set_super_total_bytes(super, btrfs_backup_total_bytes(root_backup));
-	btrfs_set_super_num_devices(super, btrfs_backup_num_devices(root_backup));
-	return 0;
-}
-
 /* helper to cleanup workers */
 static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 {

commit 336a0d8df1d9ec2480dc1790f0d7801c32318d1c
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 15 18:42:21 2019 +0300

    btrfs: Don't use objectid_mutex during mount
    
    Since the filesystem is not well formed and no trees are loaded it's
    pointless holding the objectid_mutex. Just remove its usage.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1b1f051ef33f..b23c9fbc2e89 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2666,17 +2666,18 @@ int __cold init_tree_roots(struct btrfs_fs_info *fs_info)
 		tree_root->commit_root = btrfs_root_node(tree_root);
 		btrfs_set_root_refs(&tree_root->root_item, 1);
 
-		mutex_lock(&tree_root->objectid_mutex);
+		/*
+		 * No need to hold btrfs_root::objectid_mutex since the fs
+		 * hasn't been fully initialised and we are the only user
+		 */
 		ret = btrfs_find_highest_objectid(tree_root,
 						&tree_root->highest_objectid);
 		if (ret < 0) {
-			mutex_unlock(&tree_root->objectid_mutex);
 			handle_error = true;
 			continue;
 		}
 
 		ASSERT(tree_root->highest_objectid <= BTRFS_LAST_FREE_OBJECTID);
-		mutex_unlock(&tree_root->objectid_mutex);
 
 		ret = btrfs_read_roots(fs_info);
 		if (ret < 0) {

commit b8522a1e5f421e003a8d2a8937eb3a095ce33f5d
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 15 18:42:20 2019 +0300

    btrfs: Factor out tree roots initialization during mount
    
    The code responsible for reading and initializing tree roots is
    scattered in open_ctree among 2 labels, emulating a loop. This is rather
    confusing to reason about. Instead, factor the code to a new function,
    init_tree_roots which implements the same logical flow.
    
    There are a couple of notable differences, namely:
    
    * Instead of using next_backup_root it's using the newly introduced
      read_backup_root.
    
    * If read_backup_root returns an error init_tree_roots propagates the
      error and there is no special handling of that case e.g. the code jumps
      straight to 'fail_tree_roots' label. The old code, however, was
      (erroneously) jumping to 'fail_block_groups' label if next_backup_root
      did fail, this was unnecessary since the tree roots init logic doesn't
      modify the state of block groups.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4d061facb416..1b1f051ef33f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2610,6 +2610,89 @@ static int btrfs_validate_write_super(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
+int __cold init_tree_roots(struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_super_block *sb = fs_info->super_copy;
+	struct btrfs_root *tree_root = fs_info->tree_root;
+	bool handle_error = false;
+	int ret = 0;
+	int i;
+
+	for (i = 0; i < BTRFS_NUM_BACKUP_ROOTS; i++) {
+		u64 generation;
+		int level;
+
+		if (handle_error) {
+			if (!IS_ERR(tree_root->node))
+				free_extent_buffer(tree_root->node);
+			tree_root->node = NULL;
+
+			if (!btrfs_test_opt(fs_info, USEBACKUPROOT))
+				break;
+
+			free_root_pointers(fs_info, 0);
+
+			/*
+			 * Don't use the log in recovery mode, it won't be
+			 * valid
+			 */
+			btrfs_set_super_log_root(sb, 0);
+
+			/* We can't trust the free space cache either */
+			btrfs_set_opt(fs_info->mount_opt, CLEAR_CACHE);
+
+			ret = read_backup_root(fs_info, i);
+			if (ret < 0)
+				return ret;
+		}
+		generation = btrfs_super_generation(sb);
+		level = btrfs_super_root_level(sb);
+		tree_root->node = read_tree_block(fs_info, btrfs_super_root(sb),
+						  generation, level, NULL);
+		if (IS_ERR(tree_root->node) ||
+		    !extent_buffer_uptodate(tree_root->node)) {
+			handle_error = true;
+
+			if (IS_ERR(tree_root->node))
+				ret = PTR_ERR(tree_root->node);
+			else if (!extent_buffer_uptodate(tree_root->node))
+				ret = -EUCLEAN;
+
+			btrfs_warn(fs_info, "failed to read tree root");
+			continue;
+		}
+
+		btrfs_set_root_node(&tree_root->root_item, tree_root->node);
+		tree_root->commit_root = btrfs_root_node(tree_root);
+		btrfs_set_root_refs(&tree_root->root_item, 1);
+
+		mutex_lock(&tree_root->objectid_mutex);
+		ret = btrfs_find_highest_objectid(tree_root,
+						&tree_root->highest_objectid);
+		if (ret < 0) {
+			mutex_unlock(&tree_root->objectid_mutex);
+			handle_error = true;
+			continue;
+		}
+
+		ASSERT(tree_root->highest_objectid <= BTRFS_LAST_FREE_OBJECTID);
+		mutex_unlock(&tree_root->objectid_mutex);
+
+		ret = btrfs_read_roots(fs_info);
+		if (ret < 0) {
+			handle_error = true;
+			continue;
+		}
+
+		/* All successful */
+		fs_info->generation = generation;
+		fs_info->last_trans_committed = generation;
+		break;
+	}
+
+	return ret;
+}
+
 int __cold open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2628,8 +2711,6 @@ int __cold open_ctree(struct super_block *sb,
 	struct btrfs_root *chunk_root;
 	int ret;
 	int err = -EINVAL;
-	int num_backups_tried = 0;
-	int backup_index = 0;
 	int clear_free_space_tree = 0;
 	int level;
 
@@ -3051,44 +3132,9 @@ int __cold open_ctree(struct super_block *sb,
 		goto fail_tree_roots;
 	}
 
-retry_root_backup:
-	generation = btrfs_super_generation(disk_super);
-	level = btrfs_super_root_level(disk_super);
-
-	tree_root->node = read_tree_block(fs_info,
-					  btrfs_super_root(disk_super),
-					  generation, level, NULL);
-	if (IS_ERR(tree_root->node) ||
-	    !extent_buffer_uptodate(tree_root->node)) {
-		btrfs_warn(fs_info, "failed to read tree root");
-		if (!IS_ERR(tree_root->node))
-			free_extent_buffer(tree_root->node);
-		tree_root->node = NULL;
-		goto recovery_tree_root;
-	}
-
-	btrfs_set_root_node(&tree_root->root_item, tree_root->node);
-	tree_root->commit_root = btrfs_root_node(tree_root);
-	btrfs_set_root_refs(&tree_root->root_item, 1);
-
-	mutex_lock(&tree_root->objectid_mutex);
-	ret = btrfs_find_highest_objectid(tree_root,
-					&tree_root->highest_objectid);
-	if (ret) {
-		mutex_unlock(&tree_root->objectid_mutex);
-		goto recovery_tree_root;
-	}
-
-	ASSERT(tree_root->highest_objectid <= BTRFS_LAST_FREE_OBJECTID);
-
-	mutex_unlock(&tree_root->objectid_mutex);
-
-	ret = btrfs_read_roots(fs_info);
+	ret = init_tree_roots(fs_info);
 	if (ret)
-		goto recovery_tree_root;
-
-	fs_info->generation = generation;
-	fs_info->last_trans_committed = generation;
+		goto fail_tree_roots;
 
 	ret = btrfs_verify_dev_extents(fs_info);
 	if (ret) {
@@ -3383,24 +3429,6 @@ int __cold open_ctree(struct super_block *sb,
 	btrfs_free_stripe_hash_table(fs_info);
 	btrfs_close_devices(fs_info->fs_devices);
 	return err;
-
-recovery_tree_root:
-	if (!btrfs_test_opt(fs_info, USEBACKUPROOT))
-		goto fail_tree_roots;
-
-	free_root_pointers(fs_info, false);
-
-	/* don't use the log in recovery mode, it won't be valid */
-	btrfs_set_super_log_root(disk_super, 0);
-
-	/* we can't trust the free space cache either */
-	btrfs_set_opt(fs_info->mount_opt, CLEAR_CACHE);
-
-	ret = next_root_backup(fs_info, fs_info->super_copy,
-			       &num_backups_tried, &backup_index);
-	if (ret == -1)
-		goto fail_block_groups;
-	goto retry_root_backup;
 }
 ALLOW_ERROR_INJECTION(open_ctree, ERRNO);
 

commit bd2336b2ac119e65457261528883d9623d41315f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 15 18:42:19 2019 +0300

    btrfs: Add read_backup_root
    
    This function will replace next_root_backup with a much saner/cleaner
    interface.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1834ff4fabee..4d061facb416 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1928,6 +1928,50 @@ static void backup_super_roots(struct btrfs_fs_info *info)
 	       sizeof(*root_backup) * BTRFS_NUM_BACKUP_ROOTS);
 }
 
+/*
+ * read_backup_root - Reads a backup root based on the passed priority. Prio 0
+ * is the newest, prio 1/2/3 are 2nd newest/3rd newest/4th (oldest) backup roots
+ *
+ * fs_info - filesystem whose backup roots need to be read
+ * priority - priority of backup root required
+ *
+ * Returns backup root index on success and -EINVAL otherwise.
+ */
+static int read_backup_root(struct btrfs_fs_info *fs_info, u8 priority)
+{
+	int backup_index = find_newest_super_backup(fs_info);
+	struct btrfs_super_block *super = fs_info->super_copy;
+	struct btrfs_root_backup *root_backup;
+
+	if (priority < BTRFS_NUM_BACKUP_ROOTS && backup_index >= 0) {
+		if (priority == 0)
+			return backup_index;
+
+		backup_index = backup_index + BTRFS_NUM_BACKUP_ROOTS - priority;
+		backup_index %= BTRFS_NUM_BACKUP_ROOTS;
+	} else {
+		return -EINVAL;
+	}
+
+	root_backup = super->super_roots + backup_index;
+
+	btrfs_set_super_generation(super,
+				   btrfs_backup_tree_root_gen(root_backup));
+	btrfs_set_super_root(super, btrfs_backup_tree_root(root_backup));
+	btrfs_set_super_root_level(super,
+				   btrfs_backup_tree_root_level(root_backup));
+	btrfs_set_super_bytes_used(super, btrfs_backup_bytes_used(root_backup));
+
+	/*
+	 * Fixme: the total bytes and num_devices need to match or we should
+	 * need a fsck
+	 */
+	btrfs_set_super_total_bytes(super, btrfs_backup_total_bytes(root_backup));
+	btrfs_set_super_num_devices(super, btrfs_backup_num_devices(root_backup));
+
+	return backup_index;
+}
+
 /*
  * this copies info out of the root backup array and back into
  * the in-memory super block.  It is meant to help iterate through

commit fc2e4c5b3508f4d0ab981be9aa55bfb80bf971d1
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 15 18:42:18 2019 +0300

    btrfs: Remove newest_gen argument from find_oldest_super_backup
    
    It's no longer needed following cleanups around find_newest_backup_root
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9d24bd3de595..1834ff4fabee 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1821,8 +1821,7 @@ static int find_newest_super_backup(struct btrfs_fs_info *info)
  * in the backup array.  This will set the backup_root_index
  * field in the fs_info struct
  */
-static void find_oldest_super_backup(struct btrfs_fs_info *info,
-				     u64 newest_gen)
+static void find_oldest_super_backup(struct btrfs_fs_info *info)
 {
 	int newest_index;
 
@@ -2860,8 +2859,7 @@ int __cold open_ctree(struct super_block *sb,
 	 * run through our array of backup supers and setup
 	 * our ring pointer to the oldest one
 	 */
-	generation = btrfs_super_generation(disk_super);
-	find_oldest_super_backup(fs_info, generation);
+	find_oldest_super_backup(fs_info);
 
 	/*
 	 * In the long term, we'll store the compression type in the super

commit 01f0f9da9dc8b4d60921af92bc9329a1eb2fa8e0
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 15 18:42:17 2019 +0300

    btrfs: Cleanup and simplify find_newest_super_backup
    
    Backup roots are always written in a circular manner. By definition we
    can only ever have 1 backup root whose generation equals to that of the
    superblock. Hence, the 'if' in the for loop will trigger at most once.
    This is sufficient to return the newest backup root.
    
    Furthermore the newest_gen parameter is always set to the generation of
    the superblock. This value can be obtained from the fs_info.
    
    This patch removes the unnecessary code dealing with the wraparound
    case and makes 'newest_gen' a local variable.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7c345c4bc817..9d24bd3de595 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1790,18 +1790,18 @@ static int transaction_kthread(void *arg)
 }
 
 /*
- * this will find the highest generation in the array of
- * root backups.  The index of the highest array is returned,
- * or -1 if we can't find anything.
+ * This will find the highest generation in the array of root backups.  The
+ * index of the highest array is returned, or -EINVAL if we can't find
+ * anything.
  *
  * We check to make sure the array is valid by comparing the
  * generation of the latest  root in the array with the generation
  * in the super block.  If they don't match we pitch it.
  */
-static int find_newest_super_backup(struct btrfs_fs_info *info, u64 newest_gen)
+static int find_newest_super_backup(struct btrfs_fs_info *info)
 {
+	const u64 newest_gen = btrfs_super_generation(info->super_copy);
 	u64 cur;
-	int newest_index = -1;
 	struct btrfs_root_backup *root_backup;
 	int i;
 
@@ -1809,17 +1809,10 @@ static int find_newest_super_backup(struct btrfs_fs_info *info, u64 newest_gen)
 		root_backup = info->super_copy->super_roots + i;
 		cur = btrfs_backup_tree_root_gen(root_backup);
 		if (cur == newest_gen)
-			newest_index = i;
+			return i;
 	}
 
-	/* check to see if we actually wrapped around */
-	if (newest_index == BTRFS_NUM_BACKUP_ROOTS - 1) {
-		root_backup = info->super_copy->super_roots;
-		cur = btrfs_backup_tree_root_gen(root_backup);
-		if (cur == newest_gen)
-			newest_index = 0;
-	}
-	return newest_index;
+	return -EINVAL;
 }
 
 
@@ -1831,11 +1824,11 @@ static int find_newest_super_backup(struct btrfs_fs_info *info, u64 newest_gen)
 static void find_oldest_super_backup(struct btrfs_fs_info *info,
 				     u64 newest_gen)
 {
-	int newest_index = -1;
+	int newest_index;
 
-	newest_index = find_newest_super_backup(info, newest_gen);
+	newest_index = find_newest_super_backup(info);
 	/* if there was garbage in there, just move along */
-	if (newest_index == -1) {
+	if (newest_index == -EINVAL) {
 		info->backup_root_index = 0;
 	} else {
 		info->backup_root_index = (newest_index + 1) % BTRFS_NUM_BACKUP_ROOTS;
@@ -1952,9 +1945,7 @@ static noinline int next_root_backup(struct btrfs_fs_info *info,
 	int newest = *backup_index;
 
 	if (*num_backups_tried == 0) {
-		u64 gen = btrfs_super_generation(super);
-
-		newest = find_newest_super_backup(info, gen);
+		newest = find_newest_super_backup(info);
 		if (newest == -1)
 			return -1;
 

commit 352ae07b599a03b08a2149d9c2ff9c3479591af2
Author: David Sterba <dsterba@suse.com>
Date:   Mon Oct 7 11:11:02 2019 +0200

    btrfs: add blake2b to checksumming algorithms
    
    Add blake2b (with 256 bit digest) to the list of possible checksumming
    algorithms used by BTRFS.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 948ed5ac0794..7c345c4bc817 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -354,6 +354,7 @@ static bool btrfs_supported_super_csum(u16 csum_type)
 	case BTRFS_CSUM_TYPE_CRC32:
 	case BTRFS_CSUM_TYPE_XXHASH:
 	case BTRFS_CSUM_TYPE_SHA256:
+	case BTRFS_CSUM_TYPE_BLAKE2:
 		return true;
 	default:
 		return false;

commit b4e967be431cf37f56cd1993592943007d7ab03b
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 8 18:41:33 2019 +0200

    btrfs: add member for a specific checksum driver
    
    Currently all the checksum algorithms generate a fixed size digest size
    and we use it.  The on-disk format can hold up to BTRFS_CSUM_SIZE bytes
    and BLAKE2b produces digest of 512 bits by default. We can't do that and
    will use the blake2b-256, this needs to be passed to the crypto API.
    
    Separate that from the base algorithm name and add a member to request
    specific driver, in this case with the digest size.
    
    The only place that uses the driver name is the crypto API setup.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 21fab336f8ca..948ed5ac0794 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2219,13 +2219,13 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 static int btrfs_init_csum_hash(struct btrfs_fs_info *fs_info, u16 csum_type)
 {
 	struct crypto_shash *csum_shash;
-	const char *csum_name = btrfs_super_csum_name(csum_type);
+	const char *csum_driver = btrfs_super_csum_driver(csum_type);
 
-	csum_shash = crypto_alloc_shash(csum_name, 0, 0);
+	csum_shash = crypto_alloc_shash(csum_driver, 0, 0);
 
 	if (IS_ERR(csum_shash)) {
 		btrfs_err(fs_info, "error allocating %s hash for checksum",
-			  csum_name);
+			  csum_driver);
 		return PTR_ERR(csum_shash);
 	}
 

commit 3831bf0094abed51e71cbeca8b6edf8b88c2644b
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Oct 7 11:11:02 2019 +0200

    btrfs: add sha256 to checksumming algorithm
    
    Add sha256 to the list of possible checksumming algorithms used by BTRFS.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 82a2fa755b13..21fab336f8ca 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -353,6 +353,7 @@ static bool btrfs_supported_super_csum(u16 csum_type)
 	switch (csum_type) {
 	case BTRFS_CSUM_TYPE_CRC32:
 	case BTRFS_CSUM_TYPE_XXHASH:
+	case BTRFS_CSUM_TYPE_SHA256:
 		return true;
 	default:
 		return false;

commit 3951e7f050ac6a38bbc859fc3cd6093890c31d1c
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Oct 7 11:11:01 2019 +0200

    btrfs: add xxhash64 to checksumming algorithms
    
    Add xxhash64 to the list of possible checksumming algorithms used by
    BTRFS.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5d32deb42993..82a2fa755b13 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -352,6 +352,7 @@ static bool btrfs_supported_super_csum(u16 csum_type)
 {
 	switch (csum_type) {
 	case BTRFS_CSUM_TYPE_CRC32:
+	case BTRFS_CSUM_TYPE_XXHASH:
 		return true;
 	default:
 		return false;

commit 4273eaff9b8d5e141113a5bdf9628c02acf3afe5
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Oct 10 10:39:25 2019 +0800

    btrfs: use bool argument in free_root_pointers()
    
    We don't need int argument bool shall do in free_root_pointers().  And
    rename the argument as it confused two people.
    
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 43e14a17e3f4..5d32deb42993 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2022,7 +2022,7 @@ static void free_root_extent_buffers(struct btrfs_root *root)
 }
 
 /* helper to cleanup tree roots */
-static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
+static void free_root_pointers(struct btrfs_fs_info *info, bool free_chunk_root)
 {
 	free_root_extent_buffers(info->tree_root);
 
@@ -2031,7 +2031,7 @@ static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 	free_root_extent_buffers(info->csum_root);
 	free_root_extent_buffers(info->quota_root);
 	free_root_extent_buffers(info->uuid_root);
-	if (chunk_root)
+	if (free_chunk_root)
 		free_root_extent_buffers(info->chunk_root);
 	free_root_extent_buffers(info->free_space_root);
 }
@@ -3320,7 +3320,7 @@ int __cold open_ctree(struct super_block *sb,
 	btrfs_put_block_group_cache(fs_info);
 
 fail_tree_roots:
-	free_root_pointers(fs_info, 1);
+	free_root_pointers(fs_info, true);
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 
 fail_sb_buffer:
@@ -3352,7 +3352,7 @@ int __cold open_ctree(struct super_block *sb,
 	if (!btrfs_test_opt(fs_info, USEBACKUPROOT))
 		goto fail_tree_roots;
 
-	free_root_pointers(fs_info, 0);
+	free_root_pointers(fs_info, false);
 
 	/* don't use the log in recovery mode, it won't be valid */
 	btrfs_set_super_log_root(disk_super, 0);
@@ -4046,7 +4046,7 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)
 	btrfs_free_block_groups(fs_info);
 
 	clear_bit(BTRFS_FS_OPEN, &fs_info->flags);
-	free_root_pointers(fs_info, 1);
+	free_root_pointers(fs_info, true);
 
 	iput(fs_info->btree_inode);
 

commit 67439dadb03ad9da45bfccb4cdb6ef6b1a7f8da9
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 8 13:28:47 2019 +0200

    btrfs: opencode extent_buffer_get
    
    The helper is trivial and we can understand what the atomic_inc on
    something named refs does.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f54a4782d18c..43e14a17e3f4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -610,7 +610,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	/* the pending IO might have been the only thing that kept this buffer
 	 * in memory.  Make sure we have a ref for all this other checks
 	 */
-	extent_buffer_get(eb);
+	atomic_inc(&eb->refs);
 
 	reads_done = atomic_dec_and_test(&eb->io_pages);
 	if (!reads_done)

commit c06631b0d8a4236fb45667de60880b037863de56
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Oct 4 17:31:33 2019 +0800

    btrfs: Enhance error output for write time tree checker
    
    Unlike read time tree checker errors, write time error can't be
    inspected by "btrfs inspect dump-tree", so we need extra information to
    determine what's going wrong.
    
    The patch will add the following output for write time tree checker
    error:
    
    - The content of the offending tree block
      To help determining if it's a false alert.
    
    - Kernel WARN_ON() for debug build
      This is helpful for us to detect unexpected write time tree checker
      error, especially fstests could catch the dmesg.
      Since the WARN_ON() is only triggered for write time tree checker,
      test cases utilizing dm-error won't trigger this WARN_ON(), thus no
      extra noise.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0bc6e3e9f7c3..f54a4782d18c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -545,9 +545,11 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 		ret = btrfs_check_leaf_full(eb);
 
 	if (ret < 0) {
+		btrfs_print_tree(eb, 0);
 		btrfs_err(fs_info,
 		"block=%llu write time tree block corruption detected",
 			  eb->start);
+		WARN_ON(IS_ENABLED(CONFIG_BTRFS_DEBUG));
 		return ret;
 	}
 	write_extent_buffer(eb, result, 0, csum_size);

commit ec39f7696ccfac85b3eea41eba7d6f747ee4ce8d
Author: Chris Mason <clm@fb.com>
Date:   Wed Jul 10 12:28:17 2019 -0700

    Btrfs: use REQ_CGROUP_PUNT for worker thread submitted bios
    
    Async CRCs and compression submit IO through helper threads, which means
    they have IO priority inversions when cgroup IO controllers are in use.
    
    This flags all of the writes submitted by btrfs helper threads as
    REQ_CGROUP_PUNT.  submit_bio() will punt these to dedicated per-blkcg
    work items to avoid the priority inversion.
    
    For the compression code, we take a reference on the wbc's blkg css and
    pass it down to the async workers.
    
    For the async CRCs, the bio already has the correct css, we just need to
    tell the block layer to use REQ_CGROUP_PUNT.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Modified-and-reviewed-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 18f80b31f05f..0bc6e3e9f7c3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -791,6 +791,12 @@ static void run_one_async_done(struct btrfs_work *work)
 		return;
 	}
 
+	/*
+	 * All of the bios that pass through here are from async helpers.
+	 * Use REQ_CGROUP_PUNT to issue them from the owning cgroup's context.
+	 * This changes nothing when cgroups aren't in use.
+	 */
+	async->bio->bi_opf |= REQ_CGROUP_PUNT;
 	ret = btrfs_map_bio(btrfs_sb(inode->i_sb), async->bio, async->mirror_num);
 	if (ret) {
 		async->bio->bi_status = ret;

commit ba8a9d07954397f0645cf62bcc1ef536e8e7ba24
Author: Chris Mason <clm@fb.com>
Date:   Wed Jul 10 12:28:15 2019 -0700

    Btrfs: delete the entire async bio submission framework
    
    Now that we're not using btrfs_schedule_bio() anymore, delete all the
    code that supported it.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bad83867c519..18f80b31f05f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1989,7 +1989,6 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->rmw_workers);
 	btrfs_destroy_workqueue(fs_info->endio_write_workers);
 	btrfs_destroy_workqueue(fs_info->endio_freespace_worker);
-	btrfs_destroy_workqueue(fs_info->submit_workers);
 	btrfs_destroy_workqueue(fs_info->delayed_workers);
 	btrfs_destroy_workqueue(fs_info->caching_workers);
 	btrfs_destroy_workqueue(fs_info->readahead_workers);
@@ -2154,16 +2153,6 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 	fs_info->caching_workers =
 		btrfs_alloc_workqueue(fs_info, "cache", flags, max_active, 0);
 
-	/*
-	 * a higher idle thresh on the submit workers makes it much more
-	 * likely that bios will be send down in a sane order to the
-	 * devices
-	 */
-	fs_info->submit_workers =
-		btrfs_alloc_workqueue(fs_info, "submit", flags,
-				      min_t(u64, fs_devices->num_devices,
-					    max_active), 64);
-
 	fs_info->fixup_workers =
 		btrfs_alloc_workqueue(fs_info, "fixup", flags, 1, 0);
 
@@ -2202,7 +2191,7 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 		btrfs_alloc_workqueue(fs_info, "qgroup-rescan", flags, 1, 0);
 
 	if (!(fs_info->workers && fs_info->delalloc_workers &&
-	      fs_info->submit_workers && fs_info->flush_workers &&
+	      fs_info->flush_workers &&
 	      fs_info->endio_workers && fs_info->endio_meta_workers &&
 	      fs_info->endio_meta_write_workers &&
 	      fs_info->endio_repair_workers &&

commit 08635bae0b4ceb08fe4c156a11c83baec397d36d
Author: Chris Mason <clm@fb.com>
Date:   Wed Jul 10 12:28:14 2019 -0700

    Btrfs: stop using btrfs_schedule_bio()
    
    btrfs_schedule_bio() hands IO off to a helper thread to do the actual
    submit_bio() call.  This has been used to make sure async crc and
    compression helpers don't get stuck on IO submission.  To maintain good
    performance, over time the IO submission threads duplicated some IO
    scheduler characteristics such as high and low priority IOs and they
    also made some ugly assumptions about request allocation batch sizes.
    
    All of this cost at least one extra context switch during IO submission,
    and doesn't fit well with the modern blkmq IO stack.  So, this commit stops
    using btrfs_schedule_bio().  We may need to adjust the number of async
    helper threads for crcs and compression, but long term it's a better
    path.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 307861d0a040..bad83867c519 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -791,8 +791,7 @@ static void run_one_async_done(struct btrfs_work *work)
 		return;
 	}
 
-	ret = btrfs_map_bio(btrfs_sb(inode->i_sb), async->bio,
-			async->mirror_num, 1);
+	ret = btrfs_map_bio(btrfs_sb(inode->i_sb), async->bio, async->mirror_num);
 	if (ret) {
 		async->bio->bi_status = ret;
 		bio_endio(async->bio);
@@ -892,12 +891,12 @@ static blk_status_t btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 					  BTRFS_WQ_ENDIO_METADATA);
 		if (ret)
 			goto out_w_error;
-		ret = btrfs_map_bio(fs_info, bio, mirror_num, 0);
+		ret = btrfs_map_bio(fs_info, bio, mirror_num);
 	} else if (!async) {
 		ret = btree_csum_one_bio(bio);
 		if (ret)
 			goto out_w_error;
-		ret = btrfs_map_bio(fs_info, bio, mirror_num, 0);
+		ret = btrfs_map_bio(fs_info, bio, mirror_num);
 	} else {
 		/*
 		 * kthread helpers are used to submit writes so that

commit b105e92755b448efd4800e3415dfeae5ad8054e9
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 1 19:57:35 2019 +0200

    btrfs: add __cold attribute to more functions
    
    The attribute can mark functions supposed to be called rarely if at all
    and the text can be moved to sections far from the other code. The
    attribute has been added to several functions already, this patch is
    based on hints given by gcc -Wsuggest-attribute=cold.
    
    The net effect of this patch is decrease of btrfs.ko by 1000-1300,
    depending on the config options.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 00954c99d259..307861d0a040 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2577,7 +2577,7 @@ static int btrfs_validate_write_super(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
-int open_ctree(struct super_block *sb,
+int __cold open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
 {
@@ -3962,7 +3962,7 @@ int btrfs_commit_super(struct btrfs_fs_info *fs_info)
 	return btrfs_commit_transaction(trans);
 }
 
-void close_ctree(struct btrfs_fs_info *fs_info)
+void __cold close_ctree(struct btrfs_fs_info *fs_info)
 {
 	int ret;
 

commit 3296bf562443a8ca35aaad959a76a49e9b412760
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Aug 22 15:25:00 2019 +0800

    btrfs: transaction: Cleanup unused TRANS_STATE_BLOCKED
    
    The state was introduced in commit 4a9d8bdee368 ("Btrfs: make the state
    of the transaction more readable"), then in commit 302167c50b32
    ("btrfs: don't end the transaction for delayed refs in throttle") the
    state is completely removed.
    
    So we can just clean up the state since it's only compared but never
    set.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bae334212ee2..00954c99d259 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1741,7 +1741,7 @@ static int transaction_kthread(void *arg)
 		}
 
 		now = ktime_get_seconds();
-		if (cur->state < TRANS_STATE_BLOCKED &&
+		if (cur->state < TRANS_STATE_COMMIT_START &&
 		    !test_bit(BTRFS_FS_NEED_ASYNC_COMMIT, &fs_info->flags) &&
 		    (now < cur->start_time ||
 		     now - cur->start_time < fs_info->commit_interval)) {

commit a0cac0ec961f0d42828eeef196ac2246a2f07659
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Sep 16 11:30:57 2019 -0700

    btrfs: get rid of unique workqueue helper functions
    
    Commit 9e0af2376434 ("Btrfs: fix task hang under heavy compressed
    write") worked around the issue that a recycled work item could get a
    false dependency on the original work item due to how the workqueue code
    guarantees non-reentrancy. It did so by giving different work functions
    to different types of work.
    
    However, the fixes in the previous few patches are more complete, as
    they prevent a work item from being recycled at all (except for a tiny
    window that the kernel workqueue code handles for us). This obsoletes
    the previous fix, so we don't need the unique helpers for correctness.
    The only other reason to keep them would be so they show up in stack
    traces, but they always seem to be optimized to a tail call, so they
    don't show up anyways. So, let's just get rid of the extra indirection.
    
    While we're here, rename normal_work_helper() to the more informative
    btrfs_work_helper().
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3895c21853cc..bae334212ee2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -706,43 +706,31 @@ static void end_workqueue_bio(struct bio *bio)
 	struct btrfs_end_io_wq *end_io_wq = bio->bi_private;
 	struct btrfs_fs_info *fs_info;
 	struct btrfs_workqueue *wq;
-	btrfs_work_func_t func;
 
 	fs_info = end_io_wq->info;
 	end_io_wq->status = bio->bi_status;
 
 	if (bio_op(bio) == REQ_OP_WRITE) {
-		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_METADATA) {
+		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_METADATA)
 			wq = fs_info->endio_meta_write_workers;
-			func = btrfs_endio_meta_write_helper;
-		} else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_FREE_SPACE) {
+		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_FREE_SPACE)
 			wq = fs_info->endio_freespace_worker;
-			func = btrfs_freespace_write_helper;
-		} else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56) {
+		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
 			wq = fs_info->endio_raid56_workers;
-			func = btrfs_endio_raid56_helper;
-		} else {
+		else
 			wq = fs_info->endio_write_workers;
-			func = btrfs_endio_write_helper;
-		}
 	} else {
-		if (unlikely(end_io_wq->metadata ==
-			     BTRFS_WQ_ENDIO_DIO_REPAIR)) {
+		if (unlikely(end_io_wq->metadata == BTRFS_WQ_ENDIO_DIO_REPAIR))
 			wq = fs_info->endio_repair_workers;
-			func = btrfs_endio_repair_helper;
-		} else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56) {
+		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
 			wq = fs_info->endio_raid56_workers;
-			func = btrfs_endio_raid56_helper;
-		} else if (end_io_wq->metadata) {
+		else if (end_io_wq->metadata)
 			wq = fs_info->endio_meta_workers;
-			func = btrfs_endio_meta_helper;
-		} else {
+		else
 			wq = fs_info->endio_workers;
-			func = btrfs_endio_helper;
-		}
 	}
 
-	btrfs_init_work(&end_io_wq->work, func, end_workqueue_fn, NULL, NULL);
+	btrfs_init_work(&end_io_wq->work, end_workqueue_fn, NULL, NULL);
 	btrfs_queue_work(wq, &end_io_wq->work);
 }
 
@@ -835,8 +823,8 @@ blk_status_t btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct bio *bio,
 	async->mirror_num = mirror_num;
 	async->submit_bio_start = submit_bio_start;
 
-	btrfs_init_work(&async->work, btrfs_worker_helper, run_one_async_start,
-			run_one_async_done, run_one_async_free);
+	btrfs_init_work(&async->work, run_one_async_start, run_one_async_done,
+			run_one_async_free);
 
 	async->bio_offset = bio_offset;
 

commit 9be490f1e15c34193b1aae17da58e14dd9f55a95
Author: Omar Sandoval <osandov@fb.com>
Date:   Mon Sep 16 11:30:54 2019 -0700

    btrfs: don't prematurely free work in end_workqueue_fn()
    
    Currently, end_workqueue_fn() frees the end_io_wq entry (which embeds
    the work item) and then calls bio_endio(). This is another potential
    instance of the bug in "btrfs: don't prematurely free work in
    run_ordered_work()".
    
    In particular, the endio call may depend on other work items. For
    example, btrfs_end_dio_bio() can call btrfs_subio_endio_read() ->
    __btrfs_correct_data_nocsum() -> dio_read_error() ->
    submit_dio_repair_bio(), which submits a bio that is also completed
    through a end_workqueue_fn() work item. However,
    __btrfs_correct_data_nocsum() waits for the newly submitted bio to
    complete, thus it depends on another work item.
    
    This example currently usually works because we use different workqueue
    helper functions for BTRFS_WQ_ENDIO_DATA and BTRFS_WQ_ENDIO_DIO_REPAIR.
    However, it may deadlock with stacked filesystems and is fragile
    overall. The proper fix is to free the work item at the very end of the
    work function, so let's do that.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 402b61bf345c..3895c21853cc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1657,8 +1657,8 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	bio->bi_status = end_io_wq->status;
 	bio->bi_private = end_io_wq->private;
 	bio->bi_end_io = end_io_wq->end_io;
-	kmem_cache_free(btrfs_end_io_wq_cache, end_io_wq);
 	bio_endio(bio);
+	kmem_cache_free(btrfs_end_io_wq_cache, end_io_wq);
 }
 
 static int cleaner_kthread(void *arg)

commit 80ed4548d0711d15ca51be5dee0ff813051cfc90
Author: David Sterba <dsterba@suse.com>
Date:   Sat Oct 12 18:42:10 2019 +0200

    btrfs: don't needlessly create extent-refs kernel thread
    
    The patch 32b593bfcb58 ("Btrfs: remove no longer used function to run
    delayed refs asynchronously") removed the async delayed refs but the
    thread has been created, without any use. Remove it to avoid resource
    consumption.
    
    Fixes: 32b593bfcb58 ("Btrfs: remove no longer used function to run delayed refs asynchronously")
    CC: stable@vger.kernel.org # 5.2+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 044981cf6df9..402b61bf345c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2008,7 +2008,6 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->readahead_workers);
 	btrfs_destroy_workqueue(fs_info->flush_workers);
 	btrfs_destroy_workqueue(fs_info->qgroup_rescan_workers);
-	btrfs_destroy_workqueue(fs_info->extent_workers);
 	/*
 	 * Now that all other work queues are destroyed, we can safely destroy
 	 * the queues used for metadata I/O, since tasks from those other work
@@ -2214,10 +2213,6 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 				      max_active, 2);
 	fs_info->qgroup_rescan_workers =
 		btrfs_alloc_workqueue(fs_info, "qgroup-rescan", flags, 1, 0);
-	fs_info->extent_workers =
-		btrfs_alloc_workqueue(fs_info, "extent-refs", flags,
-				      min_t(u64, fs_devices->num_devices,
-					    max_active), 8);
 
 	if (!(fs_info->workers && fs_info->delalloc_workers &&
 	      fs_info->submit_workers && fs_info->flush_workers &&
@@ -2228,7 +2223,6 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
 	      fs_info->caching_workers && fs_info->readahead_workers &&
 	      fs_info->fixup_workers && fs_info->delayed_workers &&
-	      fs_info->extent_workers &&
 	      fs_info->qgroup_rescan_workers)) {
 		return -ENOMEM;
 	}

commit 62fdaa52a3d00a875da771719b6dc537ca79fce1
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Aug 22 10:14:15 2019 +0800

    btrfs: Detect unbalanced tree with empty leaf before crashing btree operations
    
    [BUG]
    With crafted image, btrfs will panic at btree operations:
    
      kernel BUG at fs/btrfs/ctree.c:3894!
      invalid opcode: 0000 [#1] SMP PTI
      CPU: 0 PID: 1138 Comm: btrfs-transacti Not tainted 5.0.0-rc8+ #9
      RIP: 0010:__push_leaf_left+0x6b6/0x6e0
      RSP: 0018:ffffc0bd4128b990 EFLAGS: 00010246
      RAX: 0000000000000000 RBX: ffffa0a4ab8f0e38 RCX: 0000000000000000
      RDX: ffffa0a280000000 RSI: 0000000000000000 RDI: ffffa0a4b3814000
      RBP: ffffc0bd4128ba38 R08: 0000000000001000 R09: ffffc0bd4128b948
      R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000240
      R13: ffffa0a4b556fb60 R14: ffffa0a4ab8f0af0 R15: ffffa0a4ab8f0af0
      FS: 0000000000000000(0000) GS:ffffa0a4b7a00000(0000) knlGS:0000000000000000
      CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      CR2: 00007f2461c80020 CR3: 000000022b32a006 CR4: 00000000000206f0
      Call Trace:
      ? _cond_resched+0x1a/0x50
      push_leaf_left+0x179/0x190
      btrfs_del_items+0x316/0x470
      btrfs_del_csums+0x215/0x3a0
      __btrfs_free_extent.isra.72+0x5a7/0xbe0
      __btrfs_run_delayed_refs+0x539/0x1120
      btrfs_run_delayed_refs+0xdb/0x1b0
      btrfs_commit_transaction+0x52/0x950
      ? start_transaction+0x94/0x450
      transaction_kthread+0x163/0x190
      kthread+0x105/0x140
      ? btrfs_cleanup_transaction+0x560/0x560
      ? kthread_destroy_worker+0x50/0x50
      ret_from_fork+0x35/0x40
      Modules linked in:
      ---[ end trace c2425e6e89b5558f ]---
    
    [CAUSE]
    The offending csum tree looks like this:
    
      checksum tree key (CSUM_TREE ROOT_ITEM 0)
      node 29741056 level 1 items 14 free 107 generation 19 owner CSUM_TREE
              ...
              key (EXTENT_CSUM EXTENT_CSUM 85975040) block 29630464 gen 17
              key (EXTENT_CSUM EXTENT_CSUM 89911296) block 29642752 gen 17 <<<
              key (EXTENT_CSUM EXTENT_CSUM 92274688) block 29646848 gen 17
              ...
    
      leaf 29630464 items 6 free space 1 generation 17 owner CSUM_TREE
              item 0 key (EXTENT_CSUM EXTENT_CSUM 85975040) itemoff 3987 itemsize 8
                      range start 85975040 end 85983232 length 8192
              ...
      leaf 29642752 items 0 free space 3995 generation 17 owner 0
                          ^ empty leaf            invalid owner ^
    
      leaf 29646848 items 1 free space 602 generation 17 owner CSUM_TREE
              item 0 key (EXTENT_CSUM EXTENT_CSUM 92274688) itemoff 627 itemsize 3368
                      range start 92274688 end 95723520 length 3448832
    
    So we have a corrupted csum tree where one tree leaf is completely
    empty, causing unbalanced btree, thus leading to unexpected btree
    balance error.
    
    [FIX]
    For this particular case, we handle it in two directions to catch it:
    - Check if the tree block is empty through btrfs_verify_level_key()
      So that invalid tree blocks won't be read out through
      btrfs_search_slot() and its variants.
    
    - Check 0 tree owner in tree checker
      NO tree is using 0 as its tree owner, detect it and reject at tree
      block read time.
    
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=202821
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 99dfd889b9f7..044981cf6df9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -417,6 +417,16 @@ int btrfs_verify_level_key(struct extent_buffer *eb, int level,
 	 */
 	if (btrfs_header_generation(eb) > fs_info->last_trans_committed)
 		return 0;
+
+	/* We have @first_key, so this @eb must have at least one item */
+	if (btrfs_header_nritems(eb) == 0) {
+		btrfs_err(fs_info,
+		"invalid tree nritems, bytenr=%llu nritems=0 expect >0",
+			  eb->start);
+		WARN_ON(IS_ENABLED(CONFIG_BTRFS_DEBUG));
+		return -EUCLEAN;
+	}
+
 	if (found_level)
 		btrfs_node_key_to_cpu(eb, &found_key, 0);
 	else

commit 4f84bd7f99fb67475e17e1cdca412e5d14bd3f45
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Aug 21 16:38:15 2019 +0300

    btrfs: Make reada_tree_block_flagged private
    
    This function is used only for the readahead machinery. It makes no
    sense to keep it external to reada.c file. Place it above its sole
    caller and make it static. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 589405eeb80f..99dfd889b9f7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1038,35 +1038,6 @@ void readahead_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr)
 		free_extent_buffer(buf);
 }
 
-int reada_tree_block_flagged(struct btrfs_fs_info *fs_info, u64 bytenr,
-			 int mirror_num, struct extent_buffer **eb)
-{
-	struct extent_buffer *buf = NULL;
-	int ret;
-
-	buf = btrfs_find_create_tree_block(fs_info, bytenr);
-	if (IS_ERR(buf))
-		return 0;
-
-	set_bit(EXTENT_BUFFER_READAHEAD, &buf->bflags);
-
-	ret = read_extent_buffer_pages(buf, WAIT_PAGE_LOCK, mirror_num);
-	if (ret) {
-		free_extent_buffer_stale(buf);
-		return ret;
-	}
-
-	if (test_bit(EXTENT_BUFFER_CORRUPT, &buf->bflags)) {
-		free_extent_buffer_stale(buf);
-		return -EIO;
-	} else if (extent_buffer_uptodate(buf)) {
-		*eb = buf;
-	} else {
-		free_extent_buffer(buf);
-	}
-	return 0;
-}
-
 struct extent_buffer *btrfs_find_create_tree_block(
 						struct btrfs_fs_info *fs_info,
 						u64 bytenr)

commit aac0023c2106952538414254960c51dcf0dc39e9
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:44 2019 -0400

    btrfs: move basic block_group definitions to their own header
    
    This is prep work for moving all of the block group cache code into its
    own file.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor comment updates ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 97beb351a10c..589405eeb80f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -40,6 +40,7 @@
 #include "compression.h"
 #include "tree-checker.h"
 #include "ref-verify.h"
+#include "block-group.h"
 
 #define BTRFS_SUPER_FLAG_SUPP	(BTRFS_HEADER_FLAG_WRITTEN |\
 				 BTRFS_HEADER_FLAG_RELOC |\

commit d7cd4dd907c19c0295829c947d79afa290b6fc24
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Aug 7 11:21:46 2019 +0100

    Btrfs: fix sysfs warning and missing raid sysfs directories
    
    In the 5.3 merge window, commit 7c7e301406d0a9 ("btrfs: sysfs: Replace
    default_attrs in ktypes with groups"), we started using the member
    "defaults_groups" for the kobject type "btrfs_raid_ktype". That leads
    to a series of warnings when running some test cases of fstests, such
    as btrfs/027, btrfs/124 and btrfs/176. The traces produced by those
    warnings are like the following:
    
      [116648.059212] kernfs: can not remove 'total_bytes', no directory
      [116648.060112] WARNING: CPU: 3 PID: 28500 at fs/kernfs/dir.c:1504 kernfs_remove_by_name_ns+0x75/0x80
      (...)
      [116648.066482] CPU: 3 PID: 28500 Comm: umount Tainted: G        W         5.3.0-rc3-btrfs-next-54 #1
      (...)
      [116648.069376] RIP: 0010:kernfs_remove_by_name_ns+0x75/0x80
      (...)
      [116648.072385] RSP: 0018:ffffabfd0090bd08 EFLAGS: 00010282
      [116648.073437] RAX: 0000000000000000 RBX: ffffffffc0c11998 RCX: 0000000000000000
      [116648.074201] RDX: ffff9fff603a7a00 RSI: ffff9fff603978a8 RDI: ffff9fff603978a8
      [116648.074956] RBP: ffffffffc0b9ca2f R08: 0000000000000000 R09: 0000000000000001
      [116648.075708] R10: ffff9ffe1f72e1c0 R11: 0000000000000000 R12: ffffffffc0b94120
      [116648.076434] R13: ffffffffb3d9b4e0 R14: 0000000000000000 R15: dead000000000100
      [116648.077143] FS:  00007f9cdc78a2c0(0000) GS:ffff9fff60380000(0000) knlGS:0000000000000000
      [116648.077852] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [116648.078546] CR2: 00007f9fc4747ab4 CR3: 00000005c7832003 CR4: 00000000003606e0
      [116648.079235] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [116648.079907] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [116648.080585] Call Trace:
      [116648.081262]  remove_files+0x31/0x70
      [116648.081929]  sysfs_remove_group+0x38/0x80
      [116648.082596]  sysfs_remove_groups+0x34/0x70
      [116648.083258]  kobject_del+0x20/0x60
      [116648.083933]  btrfs_free_block_groups+0x405/0x430 [btrfs]
      [116648.084608]  close_ctree+0x19a/0x380 [btrfs]
      [116648.085278]  generic_shutdown_super+0x6c/0x110
      [116648.085951]  kill_anon_super+0xe/0x30
      [116648.086621]  btrfs_kill_super+0x12/0xa0 [btrfs]
      [116648.087289]  deactivate_locked_super+0x3a/0x70
      [116648.087956]  cleanup_mnt+0xb4/0x160
      [116648.088620]  task_work_run+0x7e/0xc0
      [116648.089285]  exit_to_usermode_loop+0xfa/0x100
      [116648.089933]  do_syscall_64+0x1cb/0x220
      [116648.090567]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [116648.091197] RIP: 0033:0x7f9cdc073b37
      (...)
      [116648.100046] ---[ end trace 22e24db328ccadf8 ]---
      [116648.100618] ------------[ cut here ]------------
      [116648.101175] kernfs: can not remove 'used_bytes', no directory
      [116648.101731] WARNING: CPU: 3 PID: 28500 at fs/kernfs/dir.c:1504 kernfs_remove_by_name_ns+0x75/0x80
      (...)
      [116648.105649] CPU: 3 PID: 28500 Comm: umount Tainted: G        W         5.3.0-rc3-btrfs-next-54 #1
      (...)
      [116648.107461] RIP: 0010:kernfs_remove_by_name_ns+0x75/0x80
      (...)
      [116648.109336] RSP: 0018:ffffabfd0090bd08 EFLAGS: 00010282
      [116648.109979] RAX: 0000000000000000 RBX: ffffffffc0c119a0 RCX: 0000000000000000
      [116648.110625] RDX: ffff9fff603a7a00 RSI: ffff9fff603978a8 RDI: ffff9fff603978a8
      [116648.111283] RBP: ffffffffc0b9ca41 R08: 0000000000000000 R09: 0000000000000001
      [116648.111940] R10: ffff9ffe1f72e1c0 R11: 0000000000000000 R12: ffffffffc0b94120
      [116648.112603] R13: ffffffffb3d9b4e0 R14: 0000000000000000 R15: dead000000000100
      [116648.113268] FS:  00007f9cdc78a2c0(0000) GS:ffff9fff60380000(0000) knlGS:0000000000000000
      [116648.113939] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [116648.114607] CR2: 00007f9fc4747ab4 CR3: 00000005c7832003 CR4: 00000000003606e0
      [116648.115286] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [116648.115966] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [116648.116649] Call Trace:
      [116648.117326]  remove_files+0x31/0x70
      [116648.117997]  sysfs_remove_group+0x38/0x80
      [116648.118671]  sysfs_remove_groups+0x34/0x70
      [116648.119342]  kobject_del+0x20/0x60
      [116648.120022]  btrfs_free_block_groups+0x405/0x430 [btrfs]
      [116648.120707]  close_ctree+0x19a/0x380 [btrfs]
      [116648.121396]  generic_shutdown_super+0x6c/0x110
      [116648.122057]  kill_anon_super+0xe/0x30
      [116648.122702]  btrfs_kill_super+0x12/0xa0 [btrfs]
      [116648.123335]  deactivate_locked_super+0x3a/0x70
      [116648.123961]  cleanup_mnt+0xb4/0x160
      [116648.124586]  task_work_run+0x7e/0xc0
      [116648.125210]  exit_to_usermode_loop+0xfa/0x100
      [116648.125830]  do_syscall_64+0x1cb/0x220
      [116648.126463]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [116648.127080] RIP: 0033:0x7f9cdc073b37
      (...)
      [116648.135923] ---[ end trace 22e24db328ccadf9 ]---
    
    These happen because, during the unmount path, we call kobject_del() for
    raid kobjects that are not fully initialized, meaning that we set their
    ktype (as btrfs_raid_ktype) through link_block_group() but we didn't set
    their parent kobject, which is done through btrfs_add_raid_kobjects().
    
    We have this split raid kobject setup since commit 75cb379d263521
    ("btrfs: defer adding raid type kobject until after chunk relocation") in
    order to avoid triggering reclaim during contextes where we can not
    (either we are holding a transaction handle or some lock required by
    the transaction commit path), so that we do the calls to kobject_add(),
    which triggers GFP_KERNEL allocations, through btrfs_add_raid_kobjects()
    in contextes where it is safe to trigger reclaim. That change expected
    that a new raid kobject can only be created either when mounting the
    filesystem or after raid profile conversion through the relocation path.
    However, we can have new raid kobject created in other two cases at least:
    
    1) During device replace (or scrub) after adding a device a to the
       filesystem. The replace procedure (and scrub) do calls to
       btrfs_inc_block_group_ro() which can allocate a new block group
       with a new raid profile (because we now have more devices). This
       can be triggered by test cases btrfs/027 and btrfs/176.
    
    2) During a degraded mount trough any write path. This can be triggered
       by test case btrfs/124.
    
    Fixing this by adding extra calls to btrfs_add_raid_kobjects(), not only
    makes things more complex and fragile, can also introduce deadlocks with
    reclaim the following way:
    
    1) Calling btrfs_add_raid_kobjects() at btrfs_inc_block_group_ro() or
       anywhere in the replace/scrub path will cause a deadlock with reclaim
       because if reclaim happens and a transaction commit is triggered,
       the transaction commit path will block at btrfs_scrub_pause().
    
    2) During degraded mounts it is essentially impossible to figure out where
       to add extra calls to btrfs_add_raid_kobjects(), because allocation of
       a block group with a new raid profile can happen anywhere, which means
       we can't safely figure out which contextes are safe for reclaim, as
       we can either hold a transaction handle or some lock needed by the
       transaction commit path.
    
    So it is too complex and error prone to have this split setup of raid
    kobjects. So fix the issue by consolidating the setup of the kobjects in a
    single place, at link_block_group(), and setup a nofs context there in
    order to prevent reclaim being triggered by the memory allocations done
    through the call chain of kobject_add().
    
    Besides fixing the sysfs warnings during kobject_del(), this also ensures
    the sysfs directories for the new raid profiles end up created and visible
    to users (a bug that existed before the 5.3 commit 7c7e301406d0a9
    ("btrfs: sysfs: Replace default_attrs in ktypes with groups")).
    
    Fixes: 75cb379d263521 ("btrfs: defer adding raid type kobject until after chunk relocation")
    Fixes: 7c7e301406d0a9 ("btrfs: sysfs: Replace default_attrs in ktypes with groups")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5f7ee70b3d1a..97beb351a10c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2683,8 +2683,6 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->delayed_iputs);
 	INIT_LIST_HEAD(&fs_info->delalloc_roots);
 	INIT_LIST_HEAD(&fs_info->caching_block_groups);
-	INIT_LIST_HEAD(&fs_info->pending_raid_kobjs);
-	spin_lock_init(&fs_info->pending_raid_kobjs_lock);
 	spin_lock_init(&fs_info->delalloc_root_lock);
 	spin_lock_init(&fs_info->trans_lock);
 	spin_lock_init(&fs_info->fs_roots_radix_lock);

commit bfcea1c661eddabd7b5fee85dd3399bb16712c5a
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Thu Jul 11 17:23:04 2019 +0200

    btrfs: free checksum hash on in close_ctree
    
    fs_info::csum_hash gets initialized in btrfs_init_csum_hash() which is
    called by open_ctree().
    
    But it only gets freed if open_ctree() fails, not on normal operation.
    
    This leads to a memory leak like the following found by kmemleak:
    unreferenced object 0xffff888132cb8720 (size 96):
    
      comm "mount", pid 450, jiffies 4294912436 (age 17.584s)
      hex dump (first 32 bytes):
        04 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
        00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
      backtrace:
        [<000000000c9643d4>] crypto_create_tfm+0x2d/0xd0
        [<00000000ae577f68>] crypto_alloc_tfm+0x4b/0xb0
        [<000000002b5cdf30>] open_ctree+0xb84/0x2060 [btrfs]
        [<0000000043204297>] btrfs_mount_root+0x552/0x640 [btrfs]
        [<00000000c99b10ea>] legacy_get_tree+0x22/0x40
        [<0000000071a6495f>] vfs_get_tree+0x1f/0xc0
        [<00000000f180080e>] fc_mount+0x9/0x30
        [<000000009e36cebd>] vfs_kern_mount.part.11+0x6a/0x80
        [<0000000004594c05>] btrfs_mount+0x174/0x910 [btrfs]
        [<00000000c99b10ea>] legacy_get_tree+0x22/0x40
        [<0000000071a6495f>] vfs_get_tree+0x1f/0xc0
        [<00000000b86e92c5>] do_mount+0x6b0/0x940
        [<0000000097464494>] ksys_mount+0x7b/0xd0
        [<0000000057213c80>] __x64_sys_mount+0x1c/0x20
        [<00000000cb689b5e>] do_syscall_64+0x43/0x130
        [<000000002194e289>] entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Free fs_info::csum_hash in close_ctree() to avoid the memory leak.
    
    Fixes: 6d97c6e31b55 ("btrfs: add boilerplate code for directly including the crypto framework")
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 41a2bd2e0c56..5f7ee70b3d1a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4106,6 +4106,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	percpu_counter_destroy(&fs_info->dev_replace.bio_counter);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 
+	btrfs_free_csum_hash(fs_info);
 	btrfs_free_stripe_hash_table(fs_info);
 	btrfs_free_ref_cache(fs_info);
 }

commit 9e967495e0e0ae8bb08f52aa71b29affc7075d31
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Apr 22 16:44:09 2019 +0100

    Btrfs: prevent send failures and crashes due to concurrent relocation
    
    Send always operates on read-only trees and always expected that while it
    is in progress, nothing changes in those trees. Due to that expectation
    and the fact that send is a read-only operation, it operates on commit
    roots and does not hold transaction handles. However relocation can COW
    nodes and leafs from read-only trees, which can cause unexpected failures
    and crashes (hitting BUG_ONs). while send using a node/leaf, it gets
    COWed, the transaction used to COW it is committed, a new transaction
    starts, the extent previously used for that node/leaf gets allocated,
    possibly for another tree, and the respective extent buffer' content
    changes while send is still using it. When this happens send normally
    fails with EIO being returned to user space and messages like the
    following are found in dmesg/syslog:
    
      [ 3408.699121] BTRFS error (device sdc): parent transid verify failed on 58703872 wanted 250 found 253
      [ 3441.523123] BTRFS error (device sdc): did not find backref in send_root. inode=63211, offset=0, disk_byte=5222825984 found extent=5222825984
    
    Other times, less often, we hit a BUG_ON() because an extent buffer that
    send is using used to be a node, and while send is still using it, it
    got COWed and got reused as a leaf while send is still using, producing
    the following trace:
    
     [ 3478.466280] ------------[ cut here ]------------
     [ 3478.466282] kernel BUG at fs/btrfs/ctree.c:1806!
     [ 3478.466965] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
     [ 3478.467635] CPU: 0 PID: 2165 Comm: btrfs Not tainted 5.0.0-btrfs-next-46 #1
     [ 3478.468311] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.2-0-gf9626ccb91-prebuilt.qemu-project.org 04/01/2014
     [ 3478.469681] RIP: 0010:read_node_slot+0x122/0x130 [btrfs]
     (...)
     [ 3478.471758] RSP: 0018:ffffa437826bfaa0 EFLAGS: 00010246
     [ 3478.472457] RAX: ffff961416ed7000 RBX: 000000000000003d RCX: 0000000000000002
     [ 3478.473151] RDX: 000000000000003d RSI: ffff96141e387408 RDI: ffff961599b30000
     [ 3478.473837] RBP: ffffa437826bfb8e R08: 0000000000000001 R09: ffffa437826bfb8e
     [ 3478.474515] R10: ffffa437826bfa70 R11: 0000000000000000 R12: ffff9614385c8708
     [ 3478.475186] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     [ 3478.475840] FS:  00007f8e0e9cc8c0(0000) GS:ffff9615b6a00000(0000) knlGS:0000000000000000
     [ 3478.476489] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     [ 3478.477127] CR2: 00007f98b67a056e CR3: 0000000005df6005 CR4: 00000000003606f0
     [ 3478.477762] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     [ 3478.478385] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     [ 3478.479003] Call Trace:
     [ 3478.479600]  ? do_raw_spin_unlock+0x49/0xc0
     [ 3478.480202]  tree_advance+0x173/0x1d0 [btrfs]
     [ 3478.480810]  btrfs_compare_trees+0x30c/0x690 [btrfs]
     [ 3478.481388]  ? process_extent+0x1280/0x1280 [btrfs]
     [ 3478.481954]  btrfs_ioctl_send+0x1037/0x1270 [btrfs]
     [ 3478.482510]  _btrfs_ioctl_send+0x80/0x110 [btrfs]
     [ 3478.483062]  btrfs_ioctl+0x13fe/0x3120 [btrfs]
     [ 3478.483581]  ? rq_clock_task+0x2e/0x60
     [ 3478.484086]  ? wake_up_new_task+0x1f3/0x370
     [ 3478.484582]  ? do_vfs_ioctl+0xa2/0x6f0
     [ 3478.485075]  ? btrfs_ioctl_get_supported_features+0x30/0x30 [btrfs]
     [ 3478.485552]  do_vfs_ioctl+0xa2/0x6f0
     [ 3478.486016]  ? __fget+0x113/0x200
     [ 3478.486467]  ksys_ioctl+0x70/0x80
     [ 3478.486911]  __x64_sys_ioctl+0x16/0x20
     [ 3478.487337]  do_syscall_64+0x60/0x1b0
     [ 3478.487751]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
     [ 3478.488159] RIP: 0033:0x7f8e0d7d4dd7
     (...)
     [ 3478.489349] RSP: 002b:00007ffcf6fb4908 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
     [ 3478.489742] RAX: ffffffffffffffda RBX: 0000000000000105 RCX: 00007f8e0d7d4dd7
     [ 3478.490142] RDX: 00007ffcf6fb4990 RSI: 0000000040489426 RDI: 0000000000000005
     [ 3478.490548] RBP: 0000000000000005 R08: 00007f8e0d6f3700 R09: 00007f8e0d6f3700
     [ 3478.490953] R10: 00007f8e0d6f39d0 R11: 0000000000000202 R12: 0000000000000005
     [ 3478.491343] R13: 00005624e0780020 R14: 0000000000000000 R15: 0000000000000001
     (...)
     [ 3478.493352] ---[ end trace d5f537302be4f8c8 ]---
    
    Another possibility, much less likely to happen, is that send will not
    fail but the contents of the stream it produces may not be correct.
    
    To avoid this, do not allow send and relocation (balance) to run in
    parallel. In the long term the goal is to allow for both to be able to
    run concurrently without any problems, but that will take a significant
    effort in development and testing.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6c7dc24d4031..41a2bd2e0c56 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2809,6 +2809,8 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->swapfile_pins_lock);
 	fs_info->swapfile_pins = RB_ROOT;
 
+	fs_info->send_in_progress = 0;
+
 	ret = btrfs_alloc_stripe_hash_table(fs_info);
 	if (ret) {
 		err = ret;

commit d5178578bcd461cc79118c7a139882350fe505aa
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Jun 3 16:58:57 2019 +0200

    btrfs: directly call into crypto framework for checksumming
    
    Currently btrfs_csum_data() relied on the crc32c() wrapper around the
    crypto framework for calculating the CRCs.
    
    As we have our own crypto_shash structure in the fs_info now, we can
    directly call into the crypto framework without going trough the wrapper.
    
    This way we can even remove the btrfs_csum_data() and btrfs_csum_final()
    wrappers.
    
    The module dependency on crc32c is preserved via MODULE_SOFTDEP("pre:
    crc32c"), which was previously provided by LIBCRC32C config option doing
    the same.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 34222bbe4b48..6c7dc24d4031 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -246,16 +246,6 @@ struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 	return em;
 }
 
-u32 btrfs_csum_data(const char *data, u32 seed, size_t len)
-{
-	return crc32c(seed, data, len);
-}
-
-void btrfs_csum_final(u32 crc, u8 *result)
-{
-	put_unaligned_le32(~crc, result);
-}
-
 /*
  * Compute the csum of a btree block and store the result to provided buffer.
  *
@@ -263,6 +253,8 @@ void btrfs_csum_final(u32 crc, u8 *result)
  */
 static int csum_tree_block(struct extent_buffer *buf, u8 *result)
 {
+	struct btrfs_fs_info *fs_info = buf->fs_info;
+	SHASH_DESC_ON_STACK(shash, fs_info->csum_shash);
 	unsigned long len;
 	unsigned long cur_len;
 	unsigned long offset = BTRFS_CSUM_SIZE;
@@ -270,9 +262,12 @@ static int csum_tree_block(struct extent_buffer *buf, u8 *result)
 	unsigned long map_start;
 	unsigned long map_len;
 	int err;
-	u32 crc = ~(u32)0;
+
+	shash->tfm = fs_info->csum_shash;
+	crypto_shash_init(shash);
 
 	len = buf->len - offset;
+
 	while (len > 0) {
 		/*
 		 * Note: we don't need to check for the err == 1 case here, as
@@ -285,14 +280,13 @@ static int csum_tree_block(struct extent_buffer *buf, u8 *result)
 		if (WARN_ON(err))
 			return err;
 		cur_len = min(len, map_len - (offset - map_start));
-		crc = btrfs_csum_data(kaddr + offset - map_start,
-				      crc, cur_len);
+		crypto_shash_update(shash, kaddr + offset - map_start, cur_len);
 		len -= cur_len;
 		offset += cur_len;
 	}
 	memset(result, 0, BTRFS_CSUM_SIZE);
 
-	btrfs_csum_final(crc, result);
+	crypto_shash_final(shash, result);
 
 	return 0;
 }
@@ -372,17 +366,20 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 {
 	struct btrfs_super_block *disk_sb =
 		(struct btrfs_super_block *)raw_disk_sb;
-	u32 crc = ~(u32)0;
 	char result[BTRFS_CSUM_SIZE];
+	SHASH_DESC_ON_STACK(shash, fs_info->csum_shash);
+
+	shash->tfm = fs_info->csum_shash;
+	crypto_shash_init(shash);
 
 	/*
 	 * The super_block structure does not span the whole
 	 * BTRFS_SUPER_INFO_SIZE range, we expect that the unused space is
 	 * filled with zeros and is included in the checksum.
 	 */
-	crc = btrfs_csum_data(raw_disk_sb + BTRFS_CSUM_SIZE,
-			      crc, BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
-	btrfs_csum_final(crc, result);
+	crypto_shash_update(shash, raw_disk_sb + BTRFS_CSUM_SIZE,
+			    BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
+	crypto_shash_final(shash, result);
 
 	if (memcmp(disk_sb->csum, result, btrfs_super_csum_size(disk_sb)))
 		return 1;
@@ -3512,17 +3509,20 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 static int write_dev_supers(struct btrfs_device *device,
 			    struct btrfs_super_block *sb, int max_mirrors)
 {
+	struct btrfs_fs_info *fs_info = device->fs_info;
+	SHASH_DESC_ON_STACK(shash, fs_info->csum_shash);
 	struct buffer_head *bh;
 	int i;
 	int ret;
 	int errors = 0;
-	u32 crc;
 	u64 bytenr;
 	int op_flags;
 
 	if (max_mirrors == 0)
 		max_mirrors = BTRFS_SUPER_MIRROR_MAX;
 
+	shash->tfm = fs_info->csum_shash;
+
 	for (i = 0; i < max_mirrors; i++) {
 		bytenr = btrfs_sb_offset(i);
 		if (bytenr + BTRFS_SUPER_INFO_SIZE >=
@@ -3531,10 +3531,10 @@ static int write_dev_supers(struct btrfs_device *device,
 
 		btrfs_set_super_bytenr(sb, bytenr);
 
-		crc = ~(u32)0;
-		crc = btrfs_csum_data((const char *)sb + BTRFS_CSUM_SIZE, crc,
-				      BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
-		btrfs_csum_final(crc, sb->csum);
+		crypto_shash_init(shash);
+		crypto_shash_update(shash, (const char *)sb + BTRFS_CSUM_SIZE,
+				    BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
+		crypto_shash_final(shash, sb->csum);
 
 		/* One reference for us, and we leave it for the caller */
 		bh = __getblk(device->bdev, bytenr / BTRFS_BDEV_BLOCKSIZE,

commit 6d97c6e31b553bc9f58b83ac3c4c79c17affbda8
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Jun 3 16:58:56 2019 +0200

    btrfs: add boilerplate code for directly including the crypto framework
    
    Add boilerplate code for directly including the crypto framework.  This
    helps us flipping the switch for new algorithms.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c9ce0b002008..34222bbe4b48 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -19,6 +19,7 @@
 #include <linux/crc32c.h>
 #include <linux/sched/mm.h>
 #include <asm/unaligned.h>
+#include <crypto/hash.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -2256,6 +2257,29 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 	return 0;
 }
 
+static int btrfs_init_csum_hash(struct btrfs_fs_info *fs_info, u16 csum_type)
+{
+	struct crypto_shash *csum_shash;
+	const char *csum_name = btrfs_super_csum_name(csum_type);
+
+	csum_shash = crypto_alloc_shash(csum_name, 0, 0);
+
+	if (IS_ERR(csum_shash)) {
+		btrfs_err(fs_info, "error allocating %s hash for checksum",
+			  csum_name);
+		return PTR_ERR(csum_shash);
+	}
+
+	fs_info->csum_shash = csum_shash;
+
+	return 0;
+}
+
+static void btrfs_free_csum_hash(struct btrfs_fs_info *fs_info)
+{
+	crypto_free_shash(fs_info->csum_shash);
+}
+
 static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 			    struct btrfs_fs_devices *fs_devices)
 {
@@ -2820,6 +2844,12 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
+	ret = btrfs_init_csum_hash(fs_info, csum_type);
+	if (ret) {
+		err = ret;
+		goto fail_alloc;
+	}
+
 	/*
 	 * We want to check superblock checksum, the type is stored inside.
 	 * Pass the whole disk block of size BTRFS_SUPER_INFO_SIZE (4k).
@@ -2828,7 +2858,7 @@ int open_ctree(struct super_block *sb,
 		btrfs_err(fs_info, "superblock checksum mismatch");
 		err = -EINVAL;
 		brelse(bh);
-		goto fail_alloc;
+		goto fail_csum;
 	}
 
 	/*
@@ -2865,11 +2895,11 @@ int open_ctree(struct super_block *sb,
 	if (ret) {
 		btrfs_err(fs_info, "superblock contains fatal errors");
 		err = -EINVAL;
-		goto fail_alloc;
+		goto fail_csum;
 	}
 
 	if (!btrfs_super_root(disk_super))
-		goto fail_alloc;
+		goto fail_csum;
 
 	/* check FS state, whether FS is broken. */
 	if (btrfs_super_flags(disk_super) & BTRFS_SUPER_FLAG_ERROR)
@@ -2891,7 +2921,7 @@ int open_ctree(struct super_block *sb,
 	ret = btrfs_parse_options(fs_info, options, sb->s_flags);
 	if (ret) {
 		err = ret;
-		goto fail_alloc;
+		goto fail_csum;
 	}
 
 	features = btrfs_super_incompat_flags(disk_super) &
@@ -2901,7 +2931,7 @@ int open_ctree(struct super_block *sb,
 		    "cannot mount because of unsupported optional features (%llx)",
 		    features);
 		err = -EINVAL;
-		goto fail_alloc;
+		goto fail_csum;
 	}
 
 	features = btrfs_super_incompat_flags(disk_super);
@@ -2945,7 +2975,7 @@ int open_ctree(struct super_block *sb,
 		btrfs_err(fs_info,
 "unequal nodesize/sectorsize (%u != %u) are not allowed for mixed block groups",
 			nodesize, sectorsize);
-		goto fail_alloc;
+		goto fail_csum;
 	}
 
 	/*
@@ -2961,7 +2991,7 @@ int open_ctree(struct super_block *sb,
 	"cannot mount read-write because of unsupported optional features (%llx)",
 		       features);
 		err = -EINVAL;
-		goto fail_alloc;
+		goto fail_csum;
 	}
 
 	ret = btrfs_init_workqueues(fs_info, fs_devices);
@@ -3339,6 +3369,8 @@ int open_ctree(struct super_block *sb,
 fail_sb_buffer:
 	btrfs_stop_all_workers(fs_info);
 	btrfs_free_block_groups(fs_info);
+fail_csum:
+	btrfs_free_csum_hash(fs_info);
 fail_alloc:
 fail_iput:
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);

commit 51bce6c9b97729835bb55ceb37febd5c8fa962dd
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Jun 3 16:58:55 2019 +0200

    btrfs: Simplify btrfs_check_super_csum() and get rid of size assumptions
    
    Now that we have already checked for a valid checksum type before
    calling btrfs_check_super_csum(), it can be simplified even further.
    
    While at it get rid of the implicit size assumption of the resulting
    checksum as well.
    
    This is a preparation for changing all checksum functionality to use the
    crypto layer later.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ce6dc95effae..c9ce0b002008 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -371,30 +371,20 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 {
 	struct btrfs_super_block *disk_sb =
 		(struct btrfs_super_block *)raw_disk_sb;
-	u16 csum_type = btrfs_super_csum_type(disk_sb);
-
-	if (!btrfs_supported_super_csum(csum_type)) {
-		btrfs_err(fs_info, "unsupported checksum algorithm %u",
-			  csum_type);
-		return 1;
-	}
-
-	if (csum_type == BTRFS_CSUM_TYPE_CRC32) {
-		u32 crc = ~(u32)0;
-		char result[sizeof(crc)];
+	u32 crc = ~(u32)0;
+	char result[BTRFS_CSUM_SIZE];
 
-		/*
-		 * The super_block structure does not span the whole
-		 * BTRFS_SUPER_INFO_SIZE range, we expect that the unused space
-		 * is filled with zeros and is included in the checksum.
-		 */
-		crc = btrfs_csum_data(raw_disk_sb + BTRFS_CSUM_SIZE,
-				crc, BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
-		btrfs_csum_final(crc, result);
+	/*
+	 * The super_block structure does not span the whole
+	 * BTRFS_SUPER_INFO_SIZE range, we expect that the unused space is
+	 * filled with zeros and is included in the checksum.
+	 */
+	crc = btrfs_csum_data(raw_disk_sb + BTRFS_CSUM_SIZE,
+			      crc, BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
+	btrfs_csum_final(crc, result);
 
-		if (memcmp(raw_disk_sb, result, sizeof(result)))
-			return 1;
-	}
+	if (memcmp(disk_sb->csum, result, btrfs_super_csum_size(disk_sb)))
+		return 1;
 
 	return 0;
 }
@@ -2611,6 +2601,7 @@ int open_ctree(struct super_block *sb,
 	u32 stripesize;
 	u64 generation;
 	u64 features;
+	u16 csum_type;
 	struct btrfs_key location;
 	struct buffer_head *bh;
 	struct btrfs_super_block *disk_super;
@@ -2820,11 +2811,10 @@ int open_ctree(struct super_block *sb,
 	 * Verify the type first, if that or the the checksum value are
 	 * corrupted, we'll find out
 	 */
-	if (!btrfs_supported_super_csum(btrfs_super_csum_type(
-				 (struct btrfs_super_block *) bh->b_data))) {
+	csum_type = btrfs_super_csum_type((struct btrfs_super_block *)bh->b_data);
+	if (!btrfs_supported_super_csum(csum_type)) {
 		btrfs_err(fs_info, "unsupported checksum algorithm: %u",
-			  btrfs_super_csum_type((struct btrfs_super_block *)
-						bh->b_data));
+			  csum_type);
 		err = -EINVAL;
 		brelse(bh);
 		goto fail_alloc;

commit 8dc3f22c8ba02c5a5b889406259c50b3eaa61c65
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Jun 3 16:58:54 2019 +0200

    btrfs: check for supported superblock checksum type before checksum validation
    
    Now that we have factorerd out the superblock checksum type validation,
    we can check for supported superblock checksum types before doing the
    actual validation of the superblock read from disk.
    
    This leads the path to further simplifications of
    btrfs_check_super_csum() later on.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add comment ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3f3bb70ca437..ce6dc95effae 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2816,6 +2816,20 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
+	/*
+	 * Verify the type first, if that or the the checksum value are
+	 * corrupted, we'll find out
+	 */
+	if (!btrfs_supported_super_csum(btrfs_super_csum_type(
+				 (struct btrfs_super_block *) bh->b_data))) {
+		btrfs_err(fs_info, "unsupported checksum algorithm: %u",
+			  btrfs_super_csum_type((struct btrfs_super_block *)
+						bh->b_data));
+		err = -EINVAL;
+		brelse(bh);
+		goto fail_alloc;
+	}
+
 	/*
 	 * We want to check superblock checksum, the type is stored inside.
 	 * Pass the whole disk block of size BTRFS_SUPER_INFO_SIZE (4k).

commit e7e16f4882edb5935ff0ba81a0df25ae0b80b549
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Jun 3 16:58:53 2019 +0200

    btrfs: add common checksum type validation
    
    Currently btrfs is only supporting CRC32C as checksumming algorithm. As
    this is about to change provide a function to validate the checksum type
    in the superblock against all possible algorithms.
    
    This makes adding new algorithms easier as there are fewer places to
    adjust when adding new algorithms.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fe14b971440f..3f3bb70ca437 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -352,6 +352,16 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 	return ret;
 }
 
+static bool btrfs_supported_super_csum(u16 csum_type)
+{
+	switch (csum_type) {
+	case BTRFS_CSUM_TYPE_CRC32:
+		return true;
+	default:
+		return false;
+	}
+}
+
 /*
  * Return 0 if the superblock checksum type matches the checksum value of that
  * algorithm. Pass the raw disk superblock data.
@@ -362,7 +372,12 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 	struct btrfs_super_block *disk_sb =
 		(struct btrfs_super_block *)raw_disk_sb;
 	u16 csum_type = btrfs_super_csum_type(disk_sb);
-	int ret = 0;
+
+	if (!btrfs_supported_super_csum(csum_type)) {
+		btrfs_err(fs_info, "unsupported checksum algorithm %u",
+			  csum_type);
+		return 1;
+	}
 
 	if (csum_type == BTRFS_CSUM_TYPE_CRC32) {
 		u32 crc = ~(u32)0;
@@ -378,16 +393,10 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 		btrfs_csum_final(crc, result);
 
 		if (memcmp(raw_disk_sb, result, sizeof(result)))
-			ret = 1;
+			return 1;
 	}
 
-	if (csum_type >= ARRAY_SIZE(btrfs_csum_sizes)) {
-		btrfs_err(fs_info, "unsupported checksum algorithm %u",
-				csum_type);
-		ret = 1;
-	}
-
-	return ret;
+	return 0;
 }
 
 int btrfs_verify_level_key(struct extent_buffer *eb, int level,
@@ -2572,7 +2581,7 @@ static int btrfs_validate_write_super(struct btrfs_fs_info *fs_info,
 	ret = validate_super(fs_info, sb, -1);
 	if (ret < 0)
 		goto out;
-	if (btrfs_super_csum_type(sb) != BTRFS_CSUM_TYPE_CRC32) {
+	if (!btrfs_supported_super_csum(btrfs_super_csum_type(sb))) {
 		ret = -EUCLEAN;
 		btrfs_err(fs_info, "invalid csum type, has %u want %u",
 			  btrfs_super_csum_type(sb), BTRFS_CSUM_TYPE_CRC32);

commit 8c3e3582a4f0dbdaea49cfd71640a626c8bb7134
Author: David Sterba <dsterba@suse.com>
Date:   Fri May 17 11:43:36 2019 +0200

    btrfs: use u8 for raid_array members
    
    The raid_attr table is now 7 * 56 = 392 bytes long, consisting of just
    small numbers so we don't have to use ints. New size is 7 * 32 = 224,
    saving 3 cachelines.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 03e703d70701..fe14b971440f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3704,7 +3704,7 @@ int btrfs_get_num_tolerated_disk_barrier_failures(u64 flags)
 
 	if ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0 ||
 	    (flags & BTRFS_AVAIL_ALLOC_BIT_SINGLE))
-		min_tolerated = min(min_tolerated,
+		min_tolerated = min_t(int, min_tolerated,
 				    btrfs_raid_array[BTRFS_RAID_SINGLE].
 				    tolerated_failures);
 
@@ -3713,7 +3713,7 @@ int btrfs_get_num_tolerated_disk_barrier_failures(u64 flags)
 			continue;
 		if (!(flags & btrfs_raid_array[raid_type].bg_flag))
 			continue;
-		min_tolerated = min(min_tolerated,
+		min_tolerated = min_t(int, min_tolerated,
 				    btrfs_raid_array[raid_type].
 				    tolerated_failures);
 	}

commit c8bf1b67039556884d0532f7b06acd524c90ed87
Author: David Sterba <dsterba@suse.com>
Date:   Fri May 17 11:43:17 2019 +0200

    btrfs: remove mapping tree structures indirection
    
    fs_info::mapping_tree is the physical<->logical mapping tree and uses
    the same underlying structure as extents, but is embedded to another
    structure. There are no other members and this indirection is useless.
    No functional change.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 024c9fadeaeb..03e703d70701 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2684,7 +2684,7 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->space_info);
 	INIT_LIST_HEAD(&fs_info->tree_mod_seq_list);
 	INIT_LIST_HEAD(&fs_info->unused_bgs);
-	btrfs_mapping_init(&fs_info->mapping_tree);
+	extent_map_tree_init(&fs_info->mapping_tree);
 	btrfs_init_block_rsv(&fs_info->global_block_rsv,
 			     BTRFS_BLOCK_RSV_GLOBAL);
 	btrfs_init_block_rsv(&fs_info->trans_block_rsv, BTRFS_BLOCK_RSV_TRANS);

commit 9b4e675a9978800995f83af0ed90e890ca501f31
Author: David Sterba <dsterba@suse.com>
Date:   Thu May 16 13:39:59 2019 +0200

    btrfs: detect fast implementation of crc32c on all architectures
    
    Currently, there's only check for fast crc32c implementation on X86,
    based on the CPU flags. This is used to decide if checksumming should be
    offloaded to worker threads or can be calculated by the caller.
    
    As there are more architectures that implement a faster version of
    crc32c (ARM, SPARC, s390, MIPS, PowerPC), also there are specialized hw
    cards.
    
    The detection is based on driver name, all generic C implementations
    contain 'generic', while the specialized versions do not. Alternatively
    the priority could be used, but this is not currently provided by the
    crypto API.
    
    The flag is set per-filesystem at mount time and used for the offloading
    decisions.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index deb74a8c191a..024c9fadeaeb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -40,10 +40,6 @@
 #include "tree-checker.h"
 #include "ref-verify.h"
 
-#ifdef CONFIG_X86
-#include <asm/cpufeature.h>
-#endif
-
 #define BTRFS_SUPER_FLAG_SUPP	(BTRFS_HEADER_FLAG_WRITTEN |\
 				 BTRFS_HEADER_FLAG_RELOC |\
 				 BTRFS_SUPER_FLAG_ERROR |\
@@ -873,14 +869,13 @@ static blk_status_t btree_submit_bio_start(void *private_data, struct bio *bio,
 	return btree_csum_one_bio(bio);
 }
 
-static int check_async_write(struct btrfs_inode *bi)
+static int check_async_write(struct btrfs_fs_info *fs_info,
+			     struct btrfs_inode *bi)
 {
 	if (atomic_read(&bi->sync_writers))
 		return 0;
-#ifdef CONFIG_X86
-	if (static_cpu_has(X86_FEATURE_XMM4_2))
+	if (test_bit(BTRFS_FS_CSUM_IMPL_FAST, &fs_info->flags))
 		return 0;
-#endif
 	return 1;
 }
 
@@ -889,7 +884,7 @@ static blk_status_t btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 					  unsigned long bio_flags)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
-	int async = check_async_write(BTRFS_I(inode));
+	int async = check_async_write(fs_info, BTRFS_I(inode));
 	blk_status_t ret;
 
 	if (bio_op(bio) != REQ_OP_WRITE) {

commit 67a242223958d628f0ba33283668e3ddd192d057
Merge: 8b35ad6232c4 b8753433fc61
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 18:14:36 2019 -0700

    Merge tag 'for-5.2/block-20190507' of git://git.kernel.dk/linux-block
    
    Pull block updates from Jens Axboe:
     "Nothing major in this series, just fixes and improvements all over the
      map. This contains:
    
       - Series of fixes for sed-opal (David, Jonas)
    
       - Fixes and performance tweaks for BFQ (via Paolo)
    
       - Set of fixes for bcache (via Coly)
    
       - Set of fixes for md (via Song)
    
       - Enabling multi-page for passthrough requests (Ming)
    
       - Queue release fix series (Ming)
    
       - Device notification improvements (Martin)
    
       - Propagate underlying device rotational status in loop (Holger)
    
       - Removal of mtip32xx trim support, which has been disabled for years
         (Christoph)
    
       - Improvement and cleanup of nvme command handling (Christoph)
    
       - Add block SPDX tags (Christoph)
    
       - Cleanup/hardening of bio/bvec iteration (Christoph)
    
       - A few NVMe pull requests (Christoph)
    
       - Removal of CONFIG_LBDAF (Christoph)
    
       - Various little fixes here and there"
    
    * tag 'for-5.2/block-20190507' of git://git.kernel.dk/linux-block: (164 commits)
      block: fix mismerge in bvec_advance
      block: don't drain in-progress dispatch in blk_cleanup_queue()
      blk-mq: move cancel of hctx->run_work into blk_mq_hw_sysfs_release
      blk-mq: always free hctx after request queue is freed
      blk-mq: split blk_mq_alloc_and_init_hctx into two parts
      blk-mq: free hw queue's resource in hctx's release handler
      blk-mq: move cancel of requeue_work into blk_mq_release
      blk-mq: grab .q_usage_counter when queuing request from plug code path
      block: fix function name in comment
      nvmet: protect discovery change log event list iteration
      nvme: mark nvme_core_init and nvme_core_exit static
      nvme: move command size checks to the core
      nvme-fabrics: check more command sizes
      nvme-pci: check more command sizes
      nvme-pci: remove an unneeded variable initialization
      nvme-pci: unquiesce admin queue on shutdown
      nvme-pci: shutdown on timeout during deletion
      nvme-pci: fix psdt field for single segment sgls
      nvme-multipath: don't print ANA group state by default
      nvme-multipath: split bios with the ns_head bio_set before submitting
      ...

commit 2b070cfe582b8e99fec6ada57d2e59e194aae202
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 25 09:03:00 2019 +0200

    block: remove the i argument to bio_for_each_segment_all
    
    We only have two callers that need the integer loop iterator, and they
    can easily maintain it themselves.
    
    Suggested-by: Matthew Wilcox <willy@infradead.org>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Acked-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Acked-by: Coly Li <colyli@suse.de>
    Reviewed-by: Matthew Wilcox <willy@infradead.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6fe9197f6ee4..c333e79408ff 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -832,11 +832,11 @@ static blk_status_t btree_csum_one_bio(struct bio *bio)
 {
 	struct bio_vec *bvec;
 	struct btrfs_root *root;
-	int i, ret = 0;
+	int ret = 0;
 	struct bvec_iter_all iter_all;
 
 	ASSERT(!bio_flagged(bio, BIO_CLONED));
-	bio_for_each_segment_all(bvec, bio, i, iter_all) {
+	bio_for_each_segment_all(bvec, bio, iter_all) {
 		root = BTRFS_I(bvec->bv_page->mapping->host)->root;
 		ret = csum_dirty_buffer(root->fs_info, bvec->bv_page);
 		if (ret)

commit 4297ff84dc24d120753e0425702e8ad9b80ed10f
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Apr 10 15:56:09 2019 -0400

    btrfs: track DIO bytes in flight
    
    When diagnosing a slowdown of generic/224 I noticed we were not doing
    anything when calling into shrink_delalloc().  This is because all
    writes in 224 are O_DIRECT, not delalloc, and thus our delalloc_bytes
    counter is 0, which short circuits most of the work inside of
    shrink_delalloc().  However O_DIRECT writes still consume metadata
    resources and generate ordered extents, which we can still wait on.
    
    Fix this by tracking outstanding DIO write bytes, and use this as well
    as the delalloc bytes counter to decide if we need to lookup and wait on
    any ordered extents.  If we have more DIO writes than delalloc bytes
    we'll go ahead and wait on any ordered extents regardless of our flush
    state as flushing delalloc is likely to not gain us anything.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    [ use dio instead of odirect in identifiers ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eb26b3239827..663efce22d98 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2633,11 +2633,17 @@ int open_ctree(struct super_block *sb,
 		goto fail;
 	}
 
-	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0, GFP_KERNEL);
+	ret = percpu_counter_init(&fs_info->dio_bytes, 0, GFP_KERNEL);
 	if (ret) {
 		err = ret;
 		goto fail_srcu;
 	}
+
+	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0, GFP_KERNEL);
+	if (ret) {
+		err = ret;
+		goto fail_dio_bytes;
+	}
 	fs_info->dirty_metadata_batch = PAGE_SIZE *
 					(1 + ilog2(nr_cpu_ids));
 
@@ -3336,6 +3342,8 @@ int open_ctree(struct super_block *sb,
 	percpu_counter_destroy(&fs_info->delalloc_bytes);
 fail_dirty_metadata_bytes:
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
+fail_dio_bytes:
+	percpu_counter_destroy(&fs_info->dio_bytes);
 fail_srcu:
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 fail:
@@ -4017,6 +4025,10 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 
+	if (percpu_counter_sum(&fs_info->dio_bytes))
+		btrfs_info(fs_info, "at unmount dio bytes count %lld",
+			   percpu_counter_sum(&fs_info->dio_bytes));
+
 	btrfs_sysfs_remove_mounted(fs_info);
 	btrfs_sysfs_remove_fsid(fs_info->fs_devices);
 
@@ -4048,6 +4060,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
 	percpu_counter_destroy(&fs_info->delalloc_bytes);
+	percpu_counter_destroy(&fs_info->dio_bytes);
 	percpu_counter_destroy(&fs_info->dev_replace.bio_counter);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 

commit 50489a5734ec77e0a0613143512de09e2229f852
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 19:46:04 2019 +0300

    btrfs: Remove bio_offset argument from submit_bio_hook
    
    None of the implementers of the submit_bio_hook use the bio_offset
    parameter, simply remove it. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index adc492848619..eb26b3239827 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -885,8 +885,8 @@ static int check_async_write(struct btrfs_inode *bi)
 }
 
 static blk_status_t btree_submit_bio_hook(struct inode *inode, struct bio *bio,
-					  int mirror_num, unsigned long bio_flags,
-					  u64 bio_offset)
+					  int mirror_num,
+					  unsigned long bio_flags)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	int async = check_async_write(BTRFS_I(inode));

commit e68f2ee72181697d574e3049426b9d4fe5b5ec4d
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 17:24:42 2019 +0300

    btrfs: Always pass 0 bio_offset for btree_submit_bio_start
    
    The btree submit hook queues the async csum and forwards the bio_offset
    parameter passed to btree_submit_bio_hook. This is redundant since
    btree_submit_bio_start calls btree_csum_one_bio which doesn't use the
    offset at all. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 62983ff0c3e1..adc492848619 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -913,8 +913,7 @@ static blk_status_t btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 		 * checksumming can happen in parallel across all CPUs
 		 */
 		ret = btrfs_wq_submit_bio(fs_info, bio, mirror_num, 0,
-					  bio_offset, inode,
-					  btree_submit_bio_start);
+					  0, inode, btree_submit_bio_start);
 	}
 
 	if (ret)

commit c2ccfbc62e9f00979fc1a82ab93ff0a4ddd8944a
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 17:24:40 2019 +0300

    btrfs: Remove 'tree' argument from read_extent_buffer_pages
    
    This function always uses the btree inode's io_tree. Stop taking the
    tree as a function argument and instead access it internally from
    read_extent_buffer_pages. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d41511a05f2e..62983ff0c3e1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -465,8 +465,7 @@ static int btree_read_extent_buffer_pages(struct extent_buffer *eb,
 	io_tree = &BTRFS_I(fs_info->btree_inode)->io_tree;
 	while (1) {
 		clear_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
-		ret = read_extent_buffer_pages(io_tree, eb, WAIT_COMPLETE,
-					       mirror_num);
+		ret = read_extent_buffer_pages(eb, WAIT_COMPLETE, mirror_num);
 		if (!ret) {
 			if (verify_parent_transid(io_tree, eb,
 						   parent_transid, 0))
@@ -1034,15 +1033,13 @@ static const struct address_space_operations btree_aops = {
 void readahead_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr)
 {
 	struct extent_buffer *buf = NULL;
-	struct inode *btree_inode = fs_info->btree_inode;
 	int ret;
 
 	buf = btrfs_find_create_tree_block(fs_info, bytenr);
 	if (IS_ERR(buf))
 		return;
 
-	ret = read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf,
-			WAIT_NONE, 0);
+	ret = read_extent_buffer_pages(buf, WAIT_NONE, 0);
 	if (ret < 0)
 		free_extent_buffer_stale(buf);
 	else
@@ -1053,8 +1050,6 @@ int reada_tree_block_flagged(struct btrfs_fs_info *fs_info, u64 bytenr,
 			 int mirror_num, struct extent_buffer **eb)
 {
 	struct extent_buffer *buf = NULL;
-	struct inode *btree_inode = fs_info->btree_inode;
-	struct extent_io_tree *io_tree = &BTRFS_I(btree_inode)->io_tree;
 	int ret;
 
 	buf = btrfs_find_create_tree_block(fs_info, bytenr);
@@ -1063,8 +1058,7 @@ int reada_tree_block_flagged(struct btrfs_fs_info *fs_info, u64 bytenr,
 
 	set_bit(EXTENT_BUFFER_READAHEAD, &buf->bflags);
 
-	ret = read_extent_buffer_pages(io_tree, buf, WAIT_PAGE_LOCK,
-				       mirror_num);
+	ret = read_extent_buffer_pages(buf, WAIT_PAGE_LOCK, mirror_num);
 	if (ret) {
 		free_extent_buffer_stale(buf);
 		return ret;

commit a56b1c7bc83c2c5439e4a5d44f35cea36fbe2c9d
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Apr 10 17:24:39 2019 +0300

    btrfs: Change submit_bio_hook to taking an inode directly
    
    The only possible 'private_data' that is passed to this function is
    actually an inode. Make that explicit by changing the signature of the
    call back. No functional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f5d0517a8563..d41511a05f2e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -885,11 +885,10 @@ static int check_async_write(struct btrfs_inode *bi)
 	return 1;
 }
 
-static blk_status_t btree_submit_bio_hook(void *private_data, struct bio *bio,
+static blk_status_t btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 					  int mirror_num, unsigned long bio_flags,
 					  u64 bio_offset)
 {
-	struct inode *inode = private_data;
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	int async = check_async_write(BTRFS_I(inode));
 	blk_status_t ret;
@@ -915,7 +914,7 @@ static blk_status_t btree_submit_bio_hook(void *private_data, struct bio *bio,
 		 * checksumming can happen in parallel across all CPUs
 		 */
 		ret = btrfs_wq_submit_bio(fs_info, bio, mirror_num, 0,
-					  bio_offset, private_data,
+					  bio_offset, inode,
 					  btree_submit_bio_start);
 	}
 

commit 9b7a2440ae51de73bf80e07b0465b9ed736397bd
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:20:49 2019 +0100

    btrfs: get fs_info from trans in btrfs_create_tree
    
    We can read fs_info from the transaction and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6fc09d24a7f1..f5d0517a8563 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1266,9 +1266,9 @@ struct btrfs_root *btrfs_alloc_dummy_root(struct btrfs_fs_info *fs_info)
 #endif
 
 struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
-				     struct btrfs_fs_info *fs_info,
 				     u64 objectid)
 {
+	struct btrfs_fs_info *fs_info = trans->fs_info;
 	struct extent_buffer *leaf;
 	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct btrfs_root *root;

commit 8d47a0d8f7947422dd359ac8e462687f81a7a137
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Apr 4 11:47:08 2019 +0800

    btrfs: Do mandatory tree block check before submitting bio
    
    There are at least 2 reports about a memory bit flip sneaking into
    on-disk data.
    
    Currently we only have a relaxed check triggered at
    btrfs_mark_buffer_dirty() time, as it's not mandatory and only for
    CONFIG_BTRFS_FS_CHECK_INTEGRITY enabled build, it doesn't help users to
    detect such problem.
    
    This patch will address the hole by triggering comprehensive check on
    tree blocks before writing it back to disk.
    
    The design points are:
    
    - Timing of the check: Tree block write hook
      This timing is chosen to reduce the overhead.
      The comprehensive check should be as expensive as a checksum
      calculation.
      Doing full check at btrfs_mark_buffer_dirty() is too expensive for end
      user.
    
    - Loose empty leaf check
      Originally for an empty leaf, tree-checker will report error if it's
      not a tree root.
    
      The problem for such check at write time is:
      * False alert for tree root created in current transaction
        In that case, the commit root still needs to be written to disk.
        And since current root can differ from commit root, then it will
        cause false alert.
        This happens for log tree.
    
      * False alert for relocated tree block
        Relocated tree block can be written to disk due to memory pressure,
        in that case an empty csum tree root can be written to disk and
        cause false alert, since csum root node hasn't been updated.
    
      Previous patch of removing comprehensive empty leaf owner check has
      paved the way for this patch.
    
    The example error output will be something like:
    
      BTRFS critical (device dm-3): corrupt leaf: root=2 block=1350630375424 slot=68, bad key order, prev (10510212874240 169 0) current (1714119868416 169 0)
      BTRFS error (device dm-3): block=1350630375424 write time tree block corruption detected
      BTRFS: error (device dm-3) in btrfs_commit_transaction:2220: errno=-5 IO failure (Error while writing out transaction)
      BTRFS info (device dm-3): forced readonly
      BTRFS warning (device dm-3): Skipping commit of aborted transaction.
      BTRFS: error (device dm-3) in cleanup_transaction:1839: errno=-5 IO failure
      BTRFS info (device dm-3): delayed_refs has NO entry
    
    Reported-by: Leonard Lausen <leonard@lausen.nl>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 36c44ddadd2d..6fc09d24a7f1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -514,6 +514,7 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 	u8 result[BTRFS_CSUM_SIZE];
 	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 	struct extent_buffer *eb;
+	int ret;
 
 	eb = (struct extent_buffer *)page->private;
 	if (page != eb->pages[0])
@@ -535,7 +536,19 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 	if (csum_tree_block(eb, result))
 		return -EINVAL;
 
+	if (btrfs_header_level(eb))
+		ret = btrfs_check_node(eb);
+	else
+		ret = btrfs_check_leaf_full(eb);
+
+	if (ret < 0) {
+		btrfs_err(fs_info,
+		"block=%llu write time tree block corruption detected",
+			  eb->start);
+		return ret;
+	}
 	write_extent_buffer(eb, result, 0, csum_size);
+
 	return 0;
 }
 

commit 813fd1dcab2d030ce4445f3ecc143a492a62e8b8
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 16:25:00 2019 +0100

    btrfs: get fs_info from eb in btrfs_check_node
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 516812801081..36c44ddadd2d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -657,7 +657,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 		ret = -EIO;
 	}
 
-	if (found_level > 0 && btrfs_check_node(fs_info, eb))
+	if (found_level > 0 && btrfs_check_node(eb))
 		ret = -EIO;
 
 	if (!ret)

commit cfdaad5e5f425b0a42ff1df3893f137b90099f44
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 16:24:18 2019 +0100

    btrfs: get fs_info from eb in btrfs_check_leaf_relaxed
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3c488fc493bd..516812801081 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4101,7 +4101,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	 * So here we should only check item pointers, not item data.
 	 */
 	if (btrfs_header_level(buf) == 0 &&
-	    btrfs_check_leaf_relaxed(fs_info, buf)) {
+	    btrfs_check_leaf_relaxed(buf)) {
 		btrfs_print_leaf(buf);
 		ASSERT(0);
 	}

commit 1c4360ee056b724d3b0e4cb2d0fe4ff6c242b7ca
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 16:23:29 2019 +0100

    btrfs: get fs_info from eb in btrfs_check_leaf_full
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0b2b75a7efbd..3c488fc493bd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -652,7 +652,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	 * that we don't try and read the other copies of this block, just
 	 * return -EIO.
 	 */
-	if (found_level == 0 && btrfs_check_leaf_full(fs_info, eb)) {
+	if (found_level == 0 && btrfs_check_leaf_full(eb)) {
 		set_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 		ret = -EIO;
 	}

commit 1c11b63eff2a67906cb9137bc6b2ee27767f313b
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Mar 27 14:24:12 2019 +0200

    btrfs: replace pending/pinned chunks lists with io tree
    
    The pending chunks list contains chunks that are allocated in the
    current transaction but haven't been created yet. The pinned chunks
    list contains chunks that are being released in the current transaction.
    Both describe chunks that are not reflected on disk as in use but are
    unavailable just the same.
    
    The pending chunks list is anchored by the transaction handle, which
    means that we need to hold a reference to a transaction when working
    with the list.
    
    The way we use them is by iterating over both lists to perform
    comparisons on the stripes they describe for each device. This is
    backwards and requires that we keep a transaction handle open while
    we're trimming.
    
    This patchset adds an extent_io_tree to btrfs_device that maintains
    the allocation state of the device.  Extents are set dirty when
    chunks are first allocated -- when the extent maps are added to the
    mapping tree. They're cleared when last removed -- when the extent
    maps are removed from the mapping tree. This matches the lifespan
    of the pending and pinned chunks list and allows us to do trims
    on unallocated space safely without pinning the transaction for what
    may be a lengthy operation. We can also use this io tree to mark
    which chunks have already been trimmed so we don't repeat the operation.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8c10702a3f83..0b2b75a7efbd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2774,8 +2774,6 @@ int open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->async_submit_wait);
 	init_waitqueue_head(&fs_info->delayed_iputs_wait);
 
-	INIT_LIST_HEAD(&fs_info->pinned_chunks);
-
 	/* Usable values until the real ones are cached from the superblock */
 	fs_info->nodesize = 4096;
 	fs_info->sectorsize = 4096;
@@ -4050,15 +4048,6 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 
 	btrfs_free_stripe_hash_table(fs_info);
 	btrfs_free_ref_cache(fs_info);
-
-	while (!list_empty(&fs_info->pinned_chunks)) {
-		struct extent_map *em;
-
-		em = list_first_entry(&fs_info->pinned_chunks,
-				      struct extent_map, list);
-		list_del_init(&em->list);
-		free_extent_map(em);
-	}
 }
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,

commit 68c94e55e1502868813a3cac2febc021d01edb75
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Feb 12 16:13:14 2019 +0200

    btrfs: Transpose btrfs_close_devices/btrfs_mapping_tree_free in close_ctree
    
    Following the introduction of the alloc_state tree, some of the callees
    of btrfs_mapping_tree_free will have to interact with the btrfs_device
    of the constituent devices. Enable this by moving the code responsible
    for freeing devices after the last user (btrfs_mapping_tree_free).
    Otherwise the kernel could crash due to use-after-free.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index de1dcccc7c9d..8c10702a3f83 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4040,8 +4040,8 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 		btrfsic_unmount(fs_info->fs_devices);
 #endif
 
-	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
+	btrfs_close_devices(fs_info->fs_devices);
 
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
 	percpu_counter_destroy(&fs_info->delalloc_bytes);

commit bbbf7243d62d8be73b7ef60721c127b36b2d523e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Mar 25 14:31:22 2019 +0200

    btrfs: combine device update operations during transaction commit
    
    We currently overload the pending_chunks list to handle updating
    btrfs_device->commit_bytes used.  We don't actually care about the
    extent mapping or even the device mapping for the chunk - we just need
    the device, and we can end up processing it multiple times.  The
    fs_devices->resized_list does more or less the same thing, but with the
    disk size.  They are called consecutively during commit and have more or
    less the same purpose.
    
    We can combine the two lists into a single list that attaches to the
    transaction and contains a list of devices that need updating.  Since we
    always add the device to a list when we change bytes_used or
    disk_total_size, there's no harm in copying both values at once.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0fa65aca56a3..de1dcccc7c9d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4479,10 +4479,17 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 				   struct btrfs_fs_info *fs_info)
 {
+	struct btrfs_device *dev, *tmp;
+
 	btrfs_cleanup_dirty_bgs(cur_trans, fs_info);
 	ASSERT(list_empty(&cur_trans->dirty_bgs));
 	ASSERT(list_empty(&cur_trans->io_bgs));
 
+	list_for_each_entry_safe(dev, tmp, &cur_trans->dev_update_list,
+				 post_commit_list) {
+		list_del_init(&dev->post_commit_list);
+	}
+
 	btrfs_destroy_delayed_refs(cur_trans, fs_info);
 
 	cur_trans->state = TRANS_STATE_COMMIT_START;

commit 90b1377daa9633973d595487d717d43d3c601420
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 27 16:55:26 2019 +0100

    btrfs: qgroup: remove obsolete fs_info members
    
    The commit fcebe4562dec ("Btrfs: rework qgroup accounting") reworked
    qgroups and added some new structures. Another rework of qgroup
    mechanics e69bcee37692 ("btrfs: qgroup: Cleanup the old
    ref_node-oriented mechanism.") stopped using them and left uncleaned.
    
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b4c070936289..0fa65aca56a3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2161,7 +2161,6 @@ static void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)
 	spin_lock_init(&fs_info->qgroup_lock);
 	mutex_init(&fs_info->qgroup_ioctl_lock);
 	fs_info->qgroup_tree = RB_ROOT;
-	fs_info->qgroup_op_tree = RB_ROOT;
 	INIT_LIST_HEAD(&fs_info->dirty_qgroups);
 	fs_info->qgroup_seq = 1;
 	fs_info->qgroup_ulist = NULL;
@@ -2666,7 +2665,6 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->defrag_inodes_lock);
 	spin_lock_init(&fs_info->tree_mod_seq_lock);
 	spin_lock_init(&fs_info->super_lock);
-	spin_lock_init(&fs_info->qgroup_op_lock);
 	spin_lock_init(&fs_info->buffer_lock);
 	spin_lock_init(&fs_info->unused_bgs_lock);
 	rwlock_init(&fs_info->tree_mod_log_lock);
@@ -2693,7 +2691,6 @@ int open_ctree(struct super_block *sb,
 
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->defrag_running, 0);
-	atomic_set(&fs_info->qgroup_op_seq, 0);
 	atomic_set(&fs_info->reada_works_cnt, 0);
 	atomic_set(&fs_info->nr_delayed_iputs, 0);
 	atomic64_set(&fs_info->tree_mod_seq, 0);

commit e064d5e9f0a00041f84d9eabd3d53546e4f8ab74
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 14:58:13 2019 +0100

    btrfs: get fs_info from eb in btrfs_verify_level_key
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f7bfa73c2545..b4c070936289 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -394,10 +394,10 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
-int btrfs_verify_level_key(struct btrfs_fs_info *fs_info,
-			   struct extent_buffer *eb, int level,
+int btrfs_verify_level_key(struct extent_buffer *eb, int level,
 			   struct btrfs_key *first_key, u64 parent_transid)
 {
+	struct btrfs_fs_info *fs_info = eb->fs_info;
 	int found_level;
 	struct btrfs_key found_key;
 	int ret;
@@ -471,7 +471,7 @@ static int btree_read_extent_buffer_pages(struct extent_buffer *eb,
 			if (verify_parent_transid(io_tree, eb,
 						   parent_transid, 0))
 				ret = -EIO;
-			else if (btrfs_verify_level_key(fs_info, eb, level,
+			else if (btrfs_verify_level_key(eb, level,
 						first_key, parent_transid))
 				ret = -EUCLEAN;
 			else

commit 5ab12d1ff83723f724d8631228f2b747aaec0a85
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 14:56:39 2019 +0100

    btrfs: get fs_info from eb in btree_read_extent_buffer_pages
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 64978fc36745..f7bfa73c2545 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -450,11 +450,11 @@ int btrfs_verify_level_key(struct btrfs_fs_info *fs_info,
  * @level:		expected level, mandatory check
  * @first_key:		expected key of first slot, skip check if NULL
  */
-static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
-					  struct extent_buffer *eb,
+static int btree_read_extent_buffer_pages(struct extent_buffer *eb,
 					  u64 parent_transid, int level,
 					  struct btrfs_key *first_key)
 {
+	struct btrfs_fs_info *fs_info = eb->fs_info;
 	struct extent_io_tree *io_tree;
 	int failed = 0;
 	int ret;
@@ -1097,7 +1097,7 @@ struct extent_buffer *read_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr,
 	if (IS_ERR(buf))
 		return buf;
 
-	ret = btree_read_extent_buffer_pages(fs_info, buf, parent_transid,
+	ret = btree_read_extent_buffer_pages(buf, parent_transid,
 					     level, first_key);
 	if (ret) {
 		free_extent_buffer_stale(buf);
@@ -4158,10 +4158,7 @@ void btrfs_btree_balance_dirty_nodelay(struct btrfs_fs_info *fs_info)
 int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid, int level,
 		      struct btrfs_key *first_key)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
-	struct btrfs_fs_info *fs_info = root->fs_info;
-
-	return btree_read_extent_buffer_pages(fs_info, buf, parent_transid,
+	return btree_read_extent_buffer_pages(buf, parent_transid,
 					      level, first_key);
 }
 

commit 6a884d7d527f32b5ea80dc472968a5430ffee9f5
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 14:30:02 2019 +0100

    btrfs: get fs_info from eb in clean_tree_block
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ab7e2c5ba556..64978fc36745 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1107,9 +1107,9 @@ struct extent_buffer *read_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr,
 
 }
 
-void clean_tree_block(struct btrfs_fs_info *fs_info,
-		      struct extent_buffer *buf)
+void btrfs_clean_tree_block(struct extent_buffer *buf)
 {
+	struct btrfs_fs_info *fs_info = buf->fs_info;
 	if (btrfs_header_generation(buf) ==
 	    fs_info->running_transaction->transid) {
 		btrfs_assert_tree_locked(buf);

commit b0c9b3b05dcbe9463550277af223f5d173aec522
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:12:00 2019 +0100

    btrfs: get fs_info from eb in check_tree_block_fsid
    
    We can read fs_info from extent buffer and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9c5b87bc0813..ab7e2c5ba556 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -539,9 +539,9 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 	return 0;
 }
 
-static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
-				 struct extent_buffer *eb)
+static int check_tree_block_fsid(struct extent_buffer *eb)
 {
+	struct btrfs_fs_info *fs_info = eb->fs_info;
 	struct btrfs_fs_devices *fs_devices = fs_info->fs_devices;
 	u8 fsid[BTRFS_FSID_SIZE];
 	int ret = 1;
@@ -611,7 +611,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 		ret = -EIO;
 		goto err;
 	}
-	if (check_tree_block_fsid(fs_info, eb)) {
+	if (check_tree_block_fsid(eb)) {
 		btrfs_err_rl(fs_info, "bad fsid on block %llu",
 			     eb->start);
 		ret = -EIO;

commit 20a1fbf97e11204e099a95167f1851fc54296a00
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 11:23:44 2019 +0100

    btrfs: get fs_info from eb in repair_eb_io_failure
    
    We can read fs_info from extent buffer and can drop it from the
    parameters. As all callsites are updated, add the btrfs_ prefix as the
    function is exported.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b29bb6e1a283..9c5b87bc0813 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -497,7 +497,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 	}
 
 	if (failed && !ret && failed_mirror)
-		repair_eb_io_failure(fs_info, eb, failed_mirror);
+		btrfs_repair_eb_io_failure(eb, failed_mirror);
 
 	return ret;
 }

commit 247462a5aca5154c8542830e3ec4d1fce2733433
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 21 20:21:05 2019 +0100

    btrfs: move tree block wait and write helpers to tree-log
    
    The wrapper names better describe what's happening so they're not
    deleted though they're trivial, but at least moved closer to their place
    of use.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f4ef3a1a321b..b29bb6e1a283 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1078,19 +1078,6 @@ struct extent_buffer *btrfs_find_create_tree_block(
 	return alloc_extent_buffer(fs_info, bytenr);
 }
 
-
-int btrfs_write_tree_block(struct extent_buffer *buf)
-{
-	return filemap_fdatawrite_range(buf->pages[0]->mapping, buf->start,
-					buf->start + buf->len - 1);
-}
-
-void btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
-{
-	filemap_fdatawait_range(buf->pages[0]->mapping,
-			        buf->start, buf->start + buf->len - 1);
-}
-
 /*
  * Read tree block at logical address @bytenr and do variant basic but critical
  * verification.

commit 75391f0d41197e54b61ada92ddeffc28bf028c8c
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Mar 20 14:27:40 2019 +0800

    btrfs: disk-io: Show the timing of corrupted tree block explicitly
    
    Just add one extra line to show when the corruption is detected.
    Currently only read time detection is possible.
    
    The planned distinguish line would be:
    
      read time:
        <detailed report>
        block=XXXXX read time tree block corruption detected
    
      write time:
        <detailed report>
        block=XXXXX write time tree block corruption detected
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fb9c9e0783af..f4ef3a1a321b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -662,6 +662,10 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 
 	if (!ret)
 		set_extent_buffer_uptodate(eb);
+	else
+		btrfs_err(fs_info,
+			  "block=%llu read time tree block corruption detected",
+			  eb->start);
 err:
 	if (reads_done &&
 	    test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))

commit 63489055e4c0dd4d2a04064138906630995456dc
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Mar 20 14:27:39 2019 +0800

    btrfs: Always output error message when key/level verification fails
    
    We have internal report of strange transaction abort due to EUCLEAN
    without any error message.
    
    Since error message inside verify_level_key() is only enabled for
    CONFIG_BTRFS_DEBUG, the error message won't be printed on most builds.
    
    This patch will make the error message mandatory, so when problem
    happens we know what's causing the problem.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 71141ae72cc9..fb9c9e0783af 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -404,12 +404,11 @@ int btrfs_verify_level_key(struct btrfs_fs_info *fs_info,
 
 	found_level = btrfs_header_level(eb);
 	if (found_level != level) {
-#ifdef CONFIG_BTRFS_DEBUG
-		WARN_ON(1);
+		WARN(IS_ENABLED(CONFIG_BTRFS_DEBUG),
+		     KERN_ERR "BTRFS: tree level check failed\n");
 		btrfs_err(fs_info,
 "tree level mismatch detected, bytenr=%llu level expected=%u has=%u",
 			  eb->start, level, found_level);
-#endif
 		return -EIO;
 	}
 
@@ -430,9 +429,9 @@ int btrfs_verify_level_key(struct btrfs_fs_info *fs_info,
 		btrfs_item_key_to_cpu(eb, &found_key, 0);
 	ret = btrfs_comp_cpu_keys(first_key, &found_key);
 
-#ifdef CONFIG_BTRFS_DEBUG
 	if (ret) {
-		WARN_ON(1);
+		WARN(IS_ENABLED(CONFIG_BTRFS_DEBUG),
+		     KERN_ERR "BTRFS: tree first key check failed\n");
 		btrfs_err(fs_info,
 "tree first key mismatch detected, bytenr=%llu parent_transid=%llu key expected=(%llu,%u,%llu) has=(%llu,%u,%llu)",
 			  eb->start, parent_transid, first_key->objectid,
@@ -440,7 +439,6 @@ int btrfs_verify_level_key(struct btrfs_fs_info *fs_info,
 			  found_key.objectid, found_key.type,
 			  found_key.offset);
 	}
-#endif
 	return ret;
 }
 

commit 448de471cd4cab0cedd15770082567a69a784a11
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Mar 12 17:10:40 2019 +0800

    btrfs: Check the first key and level for cached extent buffer
    
    [BUG]
    When reading a file from a fuzzed image, kernel can panic like:
    
      BTRFS warning (device loop0): csum failed root 5 ino 270 off 0 csum 0x98f94189 expected csum 0x00000000 mirror 1
      assertion failed: !memcmp_extent_buffer(b, &disk_key, offsetof(struct btrfs_leaf, items[0].key), sizeof(disk_key)), file: fs/btrfs/ctree.c, line: 2544
      ------------[ cut here ]------------
      kernel BUG at fs/btrfs/ctree.h:3500!
      invalid opcode: 0000 [#1] PREEMPT SMP NOPTI
      RIP: 0010:btrfs_search_slot.cold.24+0x61/0x63 [btrfs]
      Call Trace:
       btrfs_lookup_csum+0x52/0x150 [btrfs]
       __btrfs_lookup_bio_sums+0x209/0x640 [btrfs]
       btrfs_submit_bio_hook+0x103/0x170 [btrfs]
       submit_one_bio+0x59/0x80 [btrfs]
       extent_read_full_page+0x58/0x80 [btrfs]
       generic_file_read_iter+0x2f6/0x9d0
       __vfs_read+0x14d/0x1a0
       vfs_read+0x8d/0x140
       ksys_read+0x52/0xc0
       do_syscall_64+0x60/0x210
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    [CAUSE]
    The fuzzed image has a corrupted leaf whose first key doesn't match its
    parent:
    
      checksum tree key (CSUM_TREE ROOT_ITEM 0)
      node 29741056 level 1 items 14 free 107 generation 19 owner CSUM_TREE
      fs uuid 3381d111-94a3-4ac7-8f39-611bbbdab7e6
      chunk uuid 9af1c3c7-2af5-488b-8553-530bd515f14c
            ...
              key (EXTENT_CSUM EXTENT_CSUM 79691776) block 29761536 gen 19
    
      leaf 29761536 items 1 free space 1726 generation 19 owner CSUM_TREE
      leaf 29761536 flags 0x1(WRITTEN) backref revision 1
      fs uuid 3381d111-94a3-4ac7-8f39-611bbbdab7e6
      chunk uuid 9af1c3c7-2af5-488b-8553-530bd515f14c
              item 0 key (EXTENT_CSUM EXTENT_CSUM 8798638964736) itemoff 1751 itemsize 2244
                      range start 8798638964736 end 8798641262592 length 2297856
    
    When reading the above tree block, we have extent_buffer->refs = 2 in
    the context:
    
    - initial one from __alloc_extent_buffer()
      alloc_extent_buffer()
      |- __alloc_extent_buffer()
         |- atomic_set(&eb->refs, 1)
    
    - one being added to fs_info->buffer_radix
      alloc_extent_buffer()
      |- check_buffer_tree_ref()
         |- atomic_inc(&eb->refs)
    
    So if even we call free_extent_buffer() in read_tree_block or other
    similar situation, we only decrease the refs by 1, it doesn't reach 0
    and won't be freed right now.
    
    The staled eb and its corrupted content will still be kept cached.
    
    Furthermore, we have several extra cases where we either don't do first
    key check or the check is not proper for all callers:
    
    - scrub
      We just don't have first key in this context.
    
    - shared tree block
      One tree block can be shared by several snapshot/subvolume trees.
      In that case, the first key check for one subvolume doesn't apply to
      another.
    
    So for the above reasons, a corrupted extent buffer can sneak into the
    buffer cache.
    
    [FIX]
    Call verify_level_key in read_block_for_search to do another
    verification. For that purpose the function is exported.
    
    Due to above reasons, although we can free corrupted extent buffer from
    cache, we still need the check in read_block_for_search(), for scrub and
    shared tree blocks.
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=202755
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=202757
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=202759
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=202761
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=202767
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=202769
    Reported-by: Yoon Jungyeon <jungyeon@gatech.edu>
    CC: stable@vger.kernel.org # 4.19+
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ea44cf136131..71141ae72cc9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -394,9 +394,9 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
-static int verify_level_key(struct btrfs_fs_info *fs_info,
-			    struct extent_buffer *eb, int level,
-			    struct btrfs_key *first_key, u64 parent_transid)
+int btrfs_verify_level_key(struct btrfs_fs_info *fs_info,
+			   struct extent_buffer *eb, int level,
+			   struct btrfs_key *first_key, u64 parent_transid)
 {
 	int found_level;
 	struct btrfs_key found_key;
@@ -473,8 +473,8 @@ static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 			if (verify_parent_transid(io_tree, eb,
 						   parent_transid, 0))
 				ret = -EIO;
-			else if (verify_level_key(fs_info, eb, level,
-						  first_key, parent_transid))
+			else if (btrfs_verify_level_key(fs_info, eb, level,
+						first_key, parent_transid))
 				ret = -EUCLEAN;
 			else
 				break;

commit 537f38f019fa0b762dbb4c0fc95d7fcce9db8e2d
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Mar 14 09:52:35 2019 +0200

    btrfs: Correctly free extent buffer in case btree_read_extent_buffer_pages fails
    
    If a an eb fails to be read for whatever reason - it's corrupted on disk
    and parent transid/key validations fail or IO for eb pages fail then
    this buffer must be removed from the buffer cache. Currently the code
    calls free_extent_buffer if an error occurs. Unfortunately this doesn't
    achieve the desired behavior since btrfs_find_create_tree_block returns
    with eb->refs == 2.
    
    On the other hand free_extent_buffer will only decrement the refs once
    leaving it added to the buffer cache radix tree.  This enables later
    code to look up the buffer from the cache and utilize it potentially
    leading to a crash.
    
    The correct way to free the buffer is call free_extent_buffer_stale.
    This function will correctly call atomic_dec explicitly for the buffer
    and subsequently call release_extent_buffer which will decrement the
    final reference thus correctly remove the invalid buffer from buffer
    cache. This change affects only newly allocated buffers since they have
    eb->refs == 2.
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=202755
    Reported-by: Jungyeon <jungyeon@gatech.edu>
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 46b368d84aa3..ea44cf136131 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1021,13 +1021,18 @@ void readahead_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr)
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = fs_info->btree_inode;
+	int ret;
 
 	buf = btrfs_find_create_tree_block(fs_info, bytenr);
 	if (IS_ERR(buf))
 		return;
-	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
-				 buf, WAIT_NONE, 0);
-	free_extent_buffer(buf);
+
+	ret = read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf,
+			WAIT_NONE, 0);
+	if (ret < 0)
+		free_extent_buffer_stale(buf);
+	else
+		free_extent_buffer(buf);
 }
 
 int reada_tree_block_flagged(struct btrfs_fs_info *fs_info, u64 bytenr,
@@ -1047,12 +1052,12 @@ int reada_tree_block_flagged(struct btrfs_fs_info *fs_info, u64 bytenr,
 	ret = read_extent_buffer_pages(io_tree, buf, WAIT_PAGE_LOCK,
 				       mirror_num);
 	if (ret) {
-		free_extent_buffer(buf);
+		free_extent_buffer_stale(buf);
 		return ret;
 	}
 
 	if (test_bit(EXTENT_BUFFER_CORRUPT, &buf->bflags)) {
-		free_extent_buffer(buf);
+		free_extent_buffer_stale(buf);
 		return -EIO;
 	} else if (extent_buffer_uptodate(buf)) {
 		*eb = buf;
@@ -1106,7 +1111,7 @@ struct extent_buffer *read_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr,
 	ret = btree_read_extent_buffer_pages(fs_info, buf, parent_transid,
 					     level, first_key);
 	if (ret) {
-		free_extent_buffer(buf);
+		free_extent_buffer_stale(buf);
 		return ERR_PTR(ret);
 	}
 	return buf;

commit 43eb5f2975848743e5b14c5bef20f40d404a7a04
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Mar 1 10:47:59 2019 +0800

    btrfs: Introduce extent_io_tree::owner to distinguish different io_trees
    
    Btrfs has the following different extent_io_trees used:
    
    - fs_info::free_extents[2]
    - btrfs_inode::io_tree - for both normal inodes and the btree inode
    - btrfs_inode::io_failure_tree
    - btrfs_transaction::dirty_pages
    - btrfs_root::dirty_log_pages
    
    If we want to trace changes in those trees, it will be pretty hard to
    distinguish them.
    
    Instead of using hard-to-read pointer address, this patch will introduce
    a new member extent_io_tree::owner to track the owner.
    
    This modification needs all the callers of extent_io_tree_init() to
    accept a new parameter @owner.
    
    This patch provides the basis for later trace events.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 130796639f88..46b368d84aa3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1211,7 +1211,8 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;
 	if (!dummy)
-		extent_io_tree_init(fs_info, &root->dirty_log_pages, NULL);
+		extent_io_tree_init(fs_info, &root->dirty_log_pages,
+				    IO_TREE_ROOT_DIRTY_LOG_PAGES, NULL);
 
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
@@ -2141,7 +2142,8 @@ static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info)
 	inode->i_mapping->a_ops = &btree_aops;
 
 	RB_CLEAR_NODE(&BTRFS_I(inode)->rb_node);
-	extent_io_tree_init(fs_info, &BTRFS_I(inode)->io_tree, inode);
+	extent_io_tree_init(fs_info, &BTRFS_I(inode)->io_tree,
+			    IO_TREE_INODE_IO, inode);
 	BTRFS_I(inode)->io_tree.track_uptodate = false;
 	extent_map_tree_init(&BTRFS_I(inode)->extent_tree);
 
@@ -2751,8 +2753,10 @@ int open_ctree(struct super_block *sb,
 	fs_info->block_group_cache_tree = RB_ROOT;
 	fs_info->first_logical_byte = (u64)-1;
 
-	extent_io_tree_init(fs_info, &fs_info->freed_extents[0], NULL);
-	extent_io_tree_init(fs_info, &fs_info->freed_extents[1], NULL);
+	extent_io_tree_init(fs_info, &fs_info->freed_extents[0],
+			    IO_TREE_FS_INFO_FREED_EXTENTS0, NULL);
+	extent_io_tree_init(fs_info, &fs_info->freed_extents[1],
+			    IO_TREE_FS_INFO_FREED_EXTENTS1, NULL);
 	fs_info->pinned_extents = &fs_info->freed_extents[0];
 	set_bit(BTRFS_FS_BARRIER, &fs_info->flags);
 

commit 7b4397386fbdc606eb053bc2a1cfd985aea59916
Author: David Sterba <dsterba@suse.com>
Date:   Mon Mar 11 15:58:30 2019 +0100

    btrfs: switch extent_io_tree::track_uptodate to bool
    
    This patch is split from the following one "btrfs: Introduce
    extent_io_tree::owner to distinguish different io_trees" from Qu, so the
    different changes are not mixed together.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 26493c2fc237..130796639f88 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2142,7 +2142,7 @@ static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info)
 
 	RB_CLEAR_NODE(&BTRFS_I(inode)->rb_node);
 	extent_io_tree_init(fs_info, &BTRFS_I(inode)->io_tree, inode);
-	BTRFS_I(inode)->io_tree.track_uptodate = 0;
+	BTRFS_I(inode)->io_tree.track_uptodate = false;
 	extent_map_tree_init(&BTRFS_I(inode)->extent_tree);
 
 	BTRFS_I(inode)->io_tree.ops = &btree_extent_io_ops;

commit c258d6e36442eb5d3363f6dbc0e6f2c162bfb66d
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Mar 1 10:47:58 2019 +0800

    btrfs: Introduce fs_info to extent_io_tree
    
    This patch will add a new member fs_info to extent_io_tree.
    
    This provides the basis for later trace events to distinguish the output
    between different btrfs filesystems. While this increases the size of
    the structure, we want to know the source of the trace events and
    passing the fs_info as an argument to all contexts is not possible.
    
    The selftests are now allowed to set it to NULL as they don't use the
    tracepoints.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c4404e1e9cfb..26493c2fc237 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1211,7 +1211,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;
 	if (!dummy)
-		extent_io_tree_init(&root->dirty_log_pages, NULL);
+		extent_io_tree_init(fs_info, &root->dirty_log_pages, NULL);
 
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
@@ -2141,7 +2141,7 @@ static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info)
 	inode->i_mapping->a_ops = &btree_aops;
 
 	RB_CLEAR_NODE(&BTRFS_I(inode)->rb_node);
-	extent_io_tree_init(&BTRFS_I(inode)->io_tree, inode);
+	extent_io_tree_init(fs_info, &BTRFS_I(inode)->io_tree, inode);
 	BTRFS_I(inode)->io_tree.track_uptodate = 0;
 	extent_map_tree_init(&BTRFS_I(inode)->extent_tree);
 
@@ -2751,8 +2751,8 @@ int open_ctree(struct super_block *sb,
 	fs_info->block_group_cache_tree = RB_ROOT;
 	fs_info->first_logical_byte = (u64)-1;
 
-	extent_io_tree_init(&fs_info->freed_extents[0], NULL);
-	extent_io_tree_init(&fs_info->freed_extents[1], NULL);
+	extent_io_tree_init(fs_info, &fs_info->freed_extents[0], NULL);
+	extent_io_tree_init(fs_info, &fs_info->freed_extents[1], NULL);
 	fs_info->pinned_extents = &fs_info->freed_extents[0];
 	set_bit(BTRFS_FS_BARRIER, &fs_info->flags);
 

commit c53839fc3217085c210e1a62022016f199ae7b5a
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Feb 25 14:24:16 2019 +0100

    btrfs: warn if extent buffer mapping crosses a page boundary in csum_tree_block
    
    Since commit d2e174d5d3ee ("btrfs: document extent mapping assumptions in
    checksum") we have a comment in place why map_private_extent_buffer()
    can't return 1 in the csum_tree_block() case.
    
    Make this a bit more explicit and WARN_ON() in case this this assumption
    breaks.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4f11a83304ae..c4404e1e9cfb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -285,7 +285,7 @@ static int csum_tree_block(struct extent_buffer *buf, u8 *result)
 		 */
 		err = map_private_extent_buffer(buf, offset, 32,
 					&kaddr, &map_start, &map_len);
-		if (err)
+		if (WARN_ON(err))
 			return err;
 		cur_len = min(len, map_len - (offset - map_start));
 		crc = btrfs_csum_data(kaddr + offset - map_start,

commit 2996e1f8bcadf0436cc67b63af01523f6cf5d43f
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Feb 25 14:24:15 2019 +0100

    btrfs: factor our read/write stage off csum_tree_block into its callers
    
    Currently csum_tree_block() does two things, first it as it's name
    suggests it calculates the checksum for a tree-block. But it also writes
    this checksum to disk or reads an extent_buffer from disk and compares the
    checksum with the calculated checksum, depending on the verify argument.
    
    Furthermore one of the two callers passes in '1' for the verify argument,
    the other one passes in '0'.
    
    For clarity and less layering violations, factor out the second stage in
    csum_tree_block()'s callers.
    
    Suggested-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6fe9197f6ee4..4f11a83304ae 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -260,15 +260,12 @@ void btrfs_csum_final(u32 crc, u8 *result)
 }
 
 /*
- * compute the csum for a btree block, and either verify it or write it
- * into the csum field of the block.
+ * Compute the csum of a btree block and store the result to provided buffer.
+ *
+ * Returns error if the extent buffer cannot be mapped.
  */
-static int csum_tree_block(struct btrfs_fs_info *fs_info,
-			   struct extent_buffer *buf,
-			   int verify)
+static int csum_tree_block(struct extent_buffer *buf, u8 *result)
 {
-	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
-	char result[BTRFS_CSUM_SIZE];
 	unsigned long len;
 	unsigned long cur_len;
 	unsigned long offset = BTRFS_CSUM_SIZE;
@@ -300,23 +297,6 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 
 	btrfs_csum_final(crc, result);
 
-	if (verify) {
-		if (memcmp_extent_buffer(buf, result, 0, csum_size)) {
-			u32 val;
-			u32 found = 0;
-			memcpy(&found, result, csum_size);
-
-			read_extent_buffer(buf, &val, 0, csum_size);
-			btrfs_warn_rl(fs_info,
-				"%s checksum verify failed on %llu wanted %X found %X level %d",
-				fs_info->sb->s_id, buf->start,
-				val, found, btrfs_header_level(buf));
-			return -EUCLEAN;
-		}
-	} else {
-		write_extent_buffer(buf, result, 0, csum_size);
-	}
-
 	return 0;
 }
 
@@ -533,6 +513,8 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 {
 	u64 start = page_offset(page);
 	u64 found_start;
+	u8 result[BTRFS_CSUM_SIZE];
+	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 	struct extent_buffer *eb;
 
 	eb = (struct extent_buffer *)page->private;
@@ -552,7 +534,11 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 	ASSERT(memcmp_extent_buffer(eb, fs_info->fs_devices->metadata_uuid,
 			btrfs_header_fsid(), BTRFS_FSID_SIZE) == 0);
 
-	return csum_tree_block(fs_info, eb, 0);
+	if (csum_tree_block(eb, result))
+		return -EINVAL;
+
+	write_extent_buffer(eb, result, 0, csum_size);
+	return 0;
 }
 
 static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
@@ -595,7 +581,9 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	struct extent_buffer *eb;
 	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
 	struct btrfs_fs_info *fs_info = root->fs_info;
+	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 	int ret = 0;
+	u8 result[BTRFS_CSUM_SIZE];
 	int reads_done;
 
 	if (!page->private)
@@ -642,10 +630,25 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	btrfs_set_buffer_lockdep_class(btrfs_header_owner(eb),
 				       eb, found_level);
 
-	ret = csum_tree_block(fs_info, eb, 1);
+	ret = csum_tree_block(eb, result);
 	if (ret)
 		goto err;
 
+	if (memcmp_extent_buffer(eb, result, 0, csum_size)) {
+		u32 val;
+		u32 found = 0;
+
+		memcpy(&found, result, csum_size);
+
+		read_extent_buffer(eb, &val, 0, csum_size);
+		btrfs_warn_rl(fs_info,
+		"%s checksum verify failed on %llu wanted %x found %x level %d",
+			      fs_info->sb->s_id, eb->start,
+			      val, found, btrfs_header_level(eb));
+		ret = -EUCLEAN;
+		goto err;
+	}
+
 	/*
 	 * If this is a leaf block and it is corrupt, set the corrupt bit so
 	 * that we don't try and read the other copies of this block, just

commit b5420237ec817b0b5f729a674c81ace0865c3b3b
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Mar 11 23:28:13 2019 -0700

    mm: refactor readahead defines in mm.h
    
    All users of VM_MAX_READAHEAD actually convert it to kbytes and then to
    pages. Define the macro explicitly as (SZ_128K / PAGE_SIZE). This
    simplifies the expression in every filesystem. Also rename the macro to
    VM_READAHEAD_PAGES to properly convey its meaning. Finally remove unused
    VM_MIN_READAHEAD
    
    [akpm@linux-foundation.org: fix fs/io_uring.c, per Stephen]
    Link: http://lkml.kernel.org/r/20181221144053.24318-1-nborisov@suse.com
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Matthew Wilcox <willy@infradead.org>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Eric Van Hensbergen <ericvh@gmail.com>
    Cc: Latchesar Ionkov <lucho@ionkov.net>
    Cc: Dominique Martinet <asmadeus@codewreck.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Chris Mason <clm@fb.com>
    Cc: Josef Bacik <josef@toxicpanda.com>
    Cc: David Sterba <dsterba@suse.com>
    Cc: Miklos Szeredi <miklos@szeredi.hu>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f0cdb53f3e2d..6fe9197f6ee4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2958,7 +2958,7 @@ int open_ctree(struct super_block *sb,
 	sb->s_bdi->congested_fn = btrfs_congested_fn;
 	sb->s_bdi->congested_data = fs_info;
 	sb->s_bdi->capabilities |= BDI_CAP_CGROUP_WRITEBACK;
-	sb->s_bdi->ra_pages = VM_MAX_READAHEAD * SZ_1K / PAGE_SIZE;
+	sb->s_bdi->ra_pages = VM_READAHEAD_PAGES;
 	sb->s_bdi->ra_pages *= btrfs_super_num_devices(disk_super);
 	sb->s_bdi->ra_pages = max(sb->s_bdi->ra_pages, SZ_4M / PAGE_SIZE);
 

commit 80201fe175cbf7f3e372f53eba0a881a702ad926
Merge: 4221b807d1f7 aaeee62c841c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 8 14:12:17 2019 -0800

    Merge tag 'for-5.1/block-20190302' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
     "Not a huge amount of changes in this round, the biggest one is that we
      finally have Mings multi-page bvec support merged. Apart from that,
      this pull request contains:
    
       - Small series that avoids quiescing the queue for sysfs changes that
         match what we currently have (Aleksei)
    
       - Series of bcache fixes (via Coly)
    
       - Series of lightnvm fixes (via Mathias)
    
       - NVMe pull request from Christoph. Nothing major, just SPDX/license
         cleanups, RR mp policy (Hannes), and little fixes (Bart,
         Chaitanya).
    
       - BFQ series (Paolo)
    
       - Save blk-mq cpu -> hw queue mapping, removing a pointer indirection
         for the fast path (Jianchao)
    
       - fops->iopoll() added for async IO polling, this is a feature that
         the upcoming io_uring interface will use (Christoph, me)
    
       - Partition scan loop fixes (Dongli)
    
       - mtip32xx conversion from managed resource API (Christoph)
    
       - cdrom registration race fix (Guenter)
    
       - MD pull from Song, two minor fixes.
    
       - Various documentation fixes (Marcos)
    
       - Multi-page bvec feature. This brings a lot of nice improvements
         with it, like more efficient splitting, larger IOs can be supported
         without growing the bvec table size, and so on. (Ming)
    
       - Various little fixes to core and drivers"
    
    * tag 'for-5.1/block-20190302' of git://git.kernel.dk/linux-block: (117 commits)
      block: fix updating bio's front segment size
      block: Replace function name in string with __func__
      nbd: propagate genlmsg_reply return code
      floppy: remove set but not used variable 'q'
      null_blk: fix checking for REQ_FUA
      block: fix NULL pointer dereference in register_disk
      fs: fix guard_bio_eod to check for real EOD errors
      blk-mq: use HCTX_TYPE_DEFAULT but not 0 to index blk_mq_tag_set->map
      block: optimize bvec iteration in bvec_iter_advance
      block: introduce mp_bvec_for_each_page() for iterating over page
      block: optimize blk_bio_segment_split for single-page bvec
      block: optimize __blk_segment_map_sg() for single-page bvec
      block: introduce bvec_nth_page()
      iomap: wire up the iopoll method
      block: add bio_set_polled() helper
      block: wire up block device iopoll method
      fs: add an iopoll method to struct file_operations
      loop: set GENHD_FL_NO_PART_SCAN after blkdev_reread_part()
      loop: do not print warn message if partition scan is successful
      block: bounce: make sure that bvec table is updated
      ...

commit ff09c4ca5992b839b4e8b411f55aecd75735fc16
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Jan 30 14:45:02 2019 +0800

    btrfs: scrub: convert scrub_workers_refcnt to refcount_t
    
    Use the refcount_t for fs_info::scrub_workers_refcnt instead of int so
    we get the extra checks. All reference changes are still done under
    scrub_lock.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8c0038de73ee..5216e7b3f9ad 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2109,7 +2109,7 @@ static void btrfs_init_scrub(struct btrfs_fs_info *fs_info)
 	atomic_set(&fs_info->scrubs_paused, 0);
 	atomic_set(&fs_info->scrub_cancel_req, 0);
 	init_waitqueue_head(&fs_info->scrub_pause_wait);
-	fs_info->scrub_workers_refcnt = 0;
+	refcount_set(&fs_info->scrub_workers_refcnt, 0);
 }
 
 static void btrfs_init_balance(struct btrfs_fs_info *fs_info)

commit 034f784d7cab9af731ccd41b34e5e9625ef47db7
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Mon Dec 3 11:06:52 2018 -0500

    btrfs: replace cleaner_delayed_iput_mutex with a waitqueue
    
    The throttle path doesn't take cleaner_delayed_iput_mutex, which means
    we could think we're done flushing iputs in the data space reservation
    path when we could have a throttler doing an iput.  There's no real
    reason to serialize the delayed iput flushing, so instead of taking the
    cleaner_delayed_iput_mutex whenever we flush the delayed iputs just
    replace it with an atomic counter and a waitqueue.  This removes the
    short (or long depending on how big the inode is) window where we think
    there are no more pending iputs when there really are some.
    
    The waiting is killable as it could be indirectly called from user
    operations like fallocate or zero-range. Such call sites should handle
    the error but otherwise it's not necessary. Eg. flush_space just needs
    to attempt to make space by waiting on iputs.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    [ add killable comment and changelog parts ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4047867473e1..8c0038de73ee 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1717,9 +1717,7 @@ static int cleaner_kthread(void *arg)
 			goto sleep;
 		}
 
-		mutex_lock(&fs_info->cleaner_delayed_iput_mutex);
 		btrfs_run_delayed_iputs(fs_info);
-		mutex_unlock(&fs_info->cleaner_delayed_iput_mutex);
 
 		again = btrfs_clean_one_deleted_snapshot(root);
 		mutex_unlock(&fs_info->cleaner_mutex);
@@ -2676,7 +2674,6 @@ int open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->delete_unused_bgs_mutex);
 	mutex_init(&fs_info->reloc_mutex);
 	mutex_init(&fs_info->delalloc_root_mutex);
-	mutex_init(&fs_info->cleaner_delayed_iput_mutex);
 	seqlock_init(&fs_info->profiles_lock);
 
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
@@ -2698,6 +2695,7 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->defrag_running, 0);
 	atomic_set(&fs_info->qgroup_op_seq, 0);
 	atomic_set(&fs_info->reada_works_cnt, 0);
+	atomic_set(&fs_info->nr_delayed_iputs, 0);
 	atomic64_set(&fs_info->tree_mod_seq, 0);
 	fs_info->sb = sb;
 	fs_info->max_inline = BTRFS_DEFAULT_MAX_INLINE;
@@ -2775,6 +2773,7 @@ int open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->transaction_wait);
 	init_waitqueue_head(&fs_info->transaction_blocked_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);
+	init_waitqueue_head(&fs_info->delayed_iputs_wait);
 
 	INIT_LIST_HEAD(&fs_info->pinned_chunks);
 

commit 8bead258206f4d4f485ad55bc1e39d23bbfe2fdd
Author: David Sterba <dsterba@suse.com>
Date:   Wed Apr 4 02:03:48 2018 +0200

    btrfs: open code now trivial btrfs_set_lock_blocking
    
    btrfs_set_lock_blocking is now only a simple wrapper around
    btrfs_set_lock_blocking_write. The name does not bring any semantic
    value that could not be inferred from the new function so there's no
    point keeping it.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 74a696d9cd68..4047867473e1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1121,7 +1121,7 @@ void clean_tree_block(struct btrfs_fs_info *fs_info,
 						 -buf->len,
 						 fs_info->dirty_metadata_batch);
 			/* ugh, clear_extent_buffer_dirty needs to lock the page */
-			btrfs_set_lock_blocking(buf);
+			btrfs_set_lock_blocking_write(buf);
 			clear_extent_buffer_dirty(buf);
 		}
 	}

commit 300aa896e1199bcd0dfb61aae86356714e017355
Author: David Sterba <dsterba@suse.com>
Date:   Wed Apr 4 02:00:17 2018 +0200

    btrfs: replace btrfs_set_lock_blocking_rw with appropriate helpers
    
    We can use the right helper where the lock type is a fixed parameter.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3d233608fa0f..74a696d9cd68 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -342,7 +342,7 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 
 	if (need_lock) {
 		btrfs_tree_read_lock(eb);
-		btrfs_set_lock_blocking_rw(eb, BTRFS_READ_LOCK);
+		btrfs_set_lock_blocking_read(eb);
 	}
 
 	lock_extent_bits(io_tree, eb->start, eb->start + eb->len - 1,

commit 370a11b8114bcca3738fe6a5d7ed8babcc212f39
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jan 23 15:15:16 2019 +0800

    btrfs: qgroup: Introduce per-root swapped blocks infrastructure
    
    To allow delayed subtree swap rescan, btrfs needs to record per-root
    information about which tree blocks get swapped.  This patch introduces
    the required infrastructure.
    
    The designed workflow will be:
    
    1) Record the subtree root block that gets swapped.
    
       During subtree swap:
       O = Old tree blocks
       N = New tree blocks
             reloc tree                         subvolume tree X
                Root                               Root
               /    \                             /    \
             NA     OB                          OA      OB
           /  |     |  \                      /  |      |  \
         NC  ND     OE  OF                   OC  OD     OE  OF
    
      In this case, NA and OA are going to be swapped, record (NA, OA) into
      subvolume tree X.
    
    2) After subtree swap.
             reloc tree                         subvolume tree X
                Root                               Root
               /    \                             /    \
             OA     OB                          NA      OB
           /  |     |  \                      /  |      |  \
         OC  OD     OE  OF                   NC  ND     OE  OF
    
    3a) COW happens for OB
        If we are going to COW tree block OB, we check OB's bytenr against
        tree X's swapped_blocks structure.
        If it doesn't fit any, nothing will happen.
    
    3b) COW happens for NA
        Check NA's bytenr against tree X's swapped_blocks, and get a hit.
        Then we do subtree scan on both subtrees OA and NA.
        Resulting 6 tree blocks to be scanned (OA, OC, OD, NA, NC, ND).
    
        Then no matter what we do to subvolume tree X, qgroup numbers will
        still be correct.
        Then NA's record gets removed from X's swapped_blocks.
    
    4)  Transaction commit
        Any record in X's swapped_blocks gets removed, since there is no
        modification to swapped subtrees, no need to trigger heavy qgroup
        subtree rescan for them.
    
    This will introduce 128 bytes overhead for each btrfs_root even qgroup
    is not enabled. This is to reduce memory allocations and potential
    failures.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9e24fdb57453..3d233608fa0f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1220,6 +1220,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	root->anon_dev = 0;
 
 	spin_lock_init(&root->root_item_lock);
+	btrfs_qgroup_init_swapped_blocks(&root->swapped_blocks);
 }
 
 static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info,

commit d2311e69857815ae2f728b48e6730f833a617092
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jan 23 15:15:14 2019 +0800

    btrfs: relocation: Delay reloc tree deletion after merge_reloc_roots
    
    Relocation code will drop btrfs_root::reloc_root as soon as
    merge_reloc_root() finishes.
    
    However later qgroup code will need to access btrfs_root::reloc_root
    after merge_reloc_root() for delayed subtree rescan.
    
    So alter the timming of resetting btrfs_root:::reloc_root, make it
    happens after transaction commit.
    
    With this patch, we will introduce a new btrfs_root::state,
    BTRFS_ROOT_DEAD_RELOC_TREE, to info part of btrfs_root::reloc_tree user
    that although btrfs_root::reloc_tree is still non-NULL, but still it's
    not used any more.
    
    The lifespan of btrfs_root::reloc tree will become:
              Old behavior            |              New
    ------------------------------------------------------------------------
    btrfs_init_reloc_root()      ---  | btrfs_init_reloc_root()      ---
      set reloc_root              |   |   set reloc_root              |
                                  |   |                               |
                                  |   |                               |
    merge_reloc_root()            |   | merge_reloc_root()            |
    |- btrfs_update_reloc_root() ---  | |- btrfs_update_reloc_root() -+-
         clear btrfs_root::reloc_root |      set ROOT_DEAD_RELOC_TREE |
                                      |      record root into dirty   |
                                      |      roots rbtree             |
                                      |                               |
                                      | reloc_block_group() Or        |
                                      | btrfs_recover_relocation()    |
                                      | | After transaction commit    |
                                      | |- clean_dirty_subvols()     ---
                                      |     clear btrfs_root::reloc_root
    
    During ROOT_DEAD_RELOC_TREE set lifespan, the only user of
    btrfs_root::reloc_tree should be qgroup.
    
    Since reloc root needs a longer life-span, this patch will also delay
    btrfs_drop_snapshot() call.
    Now btrfs_drop_snapshot() is called in clean_dirty_subvols().
    
    This patch will increase the size of btrfs_root by 16 bytes.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index de4b7ed02da1..9e24fdb57453 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1176,6 +1176,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	INIT_LIST_HEAD(&root->delalloc_root);
 	INIT_LIST_HEAD(&root->ordered_extents);
 	INIT_LIST_HEAD(&root->ordered_root);
+	INIT_LIST_HEAD(&root->reloc_dirty_list);
 	INIT_LIST_HEAD(&root->logged_list[0]);
 	INIT_LIST_HEAD(&root->logged_list[1]);
 	spin_lock_init(&root->inode_lock);

commit fa781cea3d6a2bd5f6c044cb06c608d7eeb6d787
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Nov 21 14:05:40 2018 -0500

    btrfs: make btrfs_destroy_delayed_refs use btrfs_delete_ref_head
    
    Instead of open coding this stuff use the helper instead.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b723ad9bd1e6..de4b7ed02da1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4264,12 +4264,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		if (head->must_insert_reserved)
 			pin_bytes = true;
 		btrfs_free_delayed_extent_op(head->extent_op);
-		delayed_refs->num_heads--;
-		if (head->processing == 0)
-			delayed_refs->num_heads_ready--;
-		atomic_dec(&delayed_refs->num_entries);
-		rb_erase_cached(&head->href_node, &delayed_refs->href_root);
-		RB_CLEAR_NODE(&head->href_node);
+		btrfs_delete_ref_head(delayed_refs, head);
 		spin_unlock(&head->lock);
 		spin_unlock(&delayed_refs->lock);
 		mutex_unlock(&head->mutex);

commit 3069bd26690a01f1e8280dff9cb019fdf216a4f5
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Nov 21 14:05:39 2018 -0500

    btrfs: make btrfs_destroy_delayed_refs use btrfs_delayed_ref_lock
    
    We have this open coded in btrfs_destroy_delayed_refs, use the helper
    instead.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 888d72dda794..b723ad9bd1e6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4246,16 +4246,9 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 
 		head = rb_entry(node, struct btrfs_delayed_ref_head,
 				href_node);
-		if (!mutex_trylock(&head->mutex)) {
-			refcount_inc(&head->refs);
-			spin_unlock(&delayed_refs->lock);
-
-			mutex_lock(&head->mutex);
-			mutex_unlock(&head->mutex);
-			btrfs_put_delayed_ref_head(head);
-			spin_lock(&delayed_refs->lock);
+		if (btrfs_delayed_ref_lock(delayed_refs, head))
 			continue;
-		}
+
 		spin_lock(&head->lock);
 		while ((n = rb_first_cached(&head->ref_tree)) != NULL) {
 			ref = rb_entry(n, struct btrfs_delayed_ref_node,

commit b89f6d1fcb30a8cbdc18ce00c7d93792076af453
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Dec 13 21:16:45 2018 +0000

    Btrfs: setup a nofs context for memory allocation at btrfs_create_tree()
    
    We are holding a transaction handle when creating a tree, therefore we can
    not allocate the root using GFP_KERNEL, as we could deadlock if reclaim is
    triggered by the allocation, therefore setup a nofs context.
    
    Fixes: 74e4d82757f74 ("btrfs: let callers of btrfs_alloc_root pass gfp flags")
    CC: stable@vger.kernel.org # 4.9+
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6a2a2a951705..888d72dda794 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -17,6 +17,7 @@
 #include <linux/semaphore.h>
 #include <linux/error-injection.h>
 #include <linux/crc32c.h>
+#include <linux/sched/mm.h>
 #include <asm/unaligned.h>
 #include "ctree.h"
 #include "disk-io.h"
@@ -1258,10 +1259,17 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct btrfs_root *root;
 	struct btrfs_key key;
+	unsigned int nofs_flag;
 	int ret = 0;
 	uuid_le uuid = NULL_UUID_LE;
 
+	/*
+	 * We're holding a transaction handle, so use a NOFS memory allocation
+	 * context to avoid deadlock if reclaim happens.
+	 */
+	nofs_flag = memalloc_nofs_save();
 	root = btrfs_alloc_root(fs_info, GFP_KERNEL);
+	memalloc_nofs_restore(nofs_flag);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 

commit 6dc4f100c175dd0511ae8674786e7c9006cdfbfa
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Feb 15 19:13:19 2019 +0800

    block: allow bio_for_each_segment_all() to iterate over multi-page bvec
    
    This patch introduces one extra iterator variable to bio_for_each_segment_all(),
    then we can allow bio_for_each_segment_all() to iterate over multi-page bvec.
    
    Given it is just one mechannical & simple change on all bio_for_each_segment_all()
    users, this patch does tree-wide change in one single patch, so that we can
    avoid to use a temporary helper for this conversion.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6a2a2a951705..ca1b7da6dd1b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -832,9 +832,10 @@ static blk_status_t btree_csum_one_bio(struct bio *bio)
 	struct bio_vec *bvec;
 	struct btrfs_root *root;
 	int i, ret = 0;
+	struct bvec_iter_all iter_all;
 
 	ASSERT(!bio_flagged(bio, BIO_CLONED));
-	bio_for_each_segment_all(bvec, bio, i) {
+	bio_for_each_segment_all(bvec, bio, i, iter_all) {
 		root = BTRFS_I(bvec->bv_page->mapping->host)->root;
 		ret = csum_dirty_buffer(root->fs_info, bvec->bv_page);
 		if (ret)

commit fd340d0f68cc87badfc9efcb226f23a5428826a0
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Jan 11 10:21:02 2019 -0500

    btrfs: wakeup cleaner thread when adding delayed iput
    
    The cleaner thread usually takes care of delayed iputs, with the
    exception of the btrfs_end_transaction_throttle path.  Delaying iputs
    means we are potentially delaying the eviction of an inode and it's
    respective space.  The cleaner thread only gets woken up every 30
    seconds, or when we require space.  If there are a lot of inodes that
    need to be deleted we could induce a serious amount of latency while we
    wait for these inodes to be evicted.  So instead wakeup the cleaner if
    it's not already awake to process any new delayed iputs we add to the
    list.  If we suddenly need space we will less likely be backed up
    behind a bunch of inodes that are waiting to be deleted, and we could
    possibly free space before we need to get into the flushing logic which
    will save us some latency.
    
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 18eefc5b2532..6a2a2a951705 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1682,6 +1682,8 @@ static int cleaner_kthread(void *arg)
 	while (1) {
 		again = 0;
 
+		set_bit(BTRFS_FS_CLEANER_RUNNING, &fs_info->flags);
+
 		/* Make the cleaner go to sleep early. */
 		if (btrfs_need_cleaner_sleep(fs_info))
 			goto sleep;
@@ -1728,6 +1730,7 @@ static int cleaner_kthread(void *arg)
 		 */
 		btrfs_delete_unused_bgs(fs_info);
 sleep:
+		clear_bit(BTRFS_FS_CLEANER_RUNNING, &fs_info->flags);
 		if (kthread_should_park())
 			kthread_parkme();
 		if (kthread_should_stop())

commit 74d5d229b1bf60f93bff244b2dfc0eb21ec32a07
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Nov 21 14:05:45 2018 -0500

    btrfs: wait on ordered extents on abort cleanup
    
    If we flip read-only before we initiate writeback on all dirty pages for
    ordered extents we've created then we'll have ordered extents left over
    on umount, which results in all sorts of bad things happening.  Fix this
    by making sure we wait on ordered extents if we have to do the aborted
    transaction cleanup stuff.
    
    generic/475 can produce this warning:
    
     [ 8531.177332] WARNING: CPU: 2 PID: 11997 at fs/btrfs/disk-io.c:3856 btrfs_free_fs_root+0x95/0xa0 [btrfs]
     [ 8531.183282] CPU: 2 PID: 11997 Comm: umount Tainted: G        W 5.0.0-rc1-default+ #394
     [ 8531.185164] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),BIOS rel-1.11.2-0-gf9626cc-prebuilt.qemu-project.org 04/01/2014
     [ 8531.187851] RIP: 0010:btrfs_free_fs_root+0x95/0xa0 [btrfs]
     [ 8531.193082] RSP: 0018:ffffb1ab86163d98 EFLAGS: 00010286
     [ 8531.194198] RAX: ffff9f3449494d18 RBX: ffff9f34a2695000 RCX:0000000000000000
     [ 8531.195629] RDX: 0000000000000002 RSI: 0000000000000001 RDI:0000000000000000
     [ 8531.197315] RBP: ffff9f344e930000 R08: 0000000000000001 R09:0000000000000000
     [ 8531.199095] R10: 0000000000000000 R11: ffff9f34494d4ff8 R12:ffffb1ab86163dc0
     [ 8531.200870] R13: ffff9f344e9300b0 R14: ffffb1ab86163db8 R15:0000000000000000
     [ 8531.202707] FS:  00007fc68e949fc0(0000) GS:ffff9f34bd800000(0000)knlGS:0000000000000000
     [ 8531.204851] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     [ 8531.205942] CR2: 00007ffde8114dd8 CR3: 000000002dfbd000 CR4:00000000000006e0
     [ 8531.207516] Call Trace:
     [ 8531.208175]  btrfs_free_fs_roots+0xdb/0x170 [btrfs]
     [ 8531.210209]  ? wait_for_completion+0x5b/0x190
     [ 8531.211303]  close_ctree+0x157/0x350 [btrfs]
     [ 8531.212412]  generic_shutdown_super+0x64/0x100
     [ 8531.213485]  kill_anon_super+0x14/0x30
     [ 8531.214430]  btrfs_kill_super+0x12/0xa0 [btrfs]
     [ 8531.215539]  deactivate_locked_super+0x29/0x60
     [ 8531.216633]  cleanup_mnt+0x3b/0x70
     [ 8531.217497]  task_work_run+0x98/0xc0
     [ 8531.218397]  exit_to_usermode_loop+0x83/0x90
     [ 8531.219324]  do_syscall_64+0x15b/0x180
     [ 8531.220192]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
     [ 8531.221286] RIP: 0033:0x7fc68e5e4d07
     [ 8531.225621] RSP: 002b:00007ffde8116608 EFLAGS: 00000246 ORIG_RAX:00000000000000a6
     [ 8531.227512] RAX: 0000000000000000 RBX: 00005580c2175970 RCX:00007fc68e5e4d07
     [ 8531.229098] RDX: 0000000000000001 RSI: 0000000000000000 RDI:00005580c2175b80
     [ 8531.230730] RBP: 0000000000000000 R08: 00005580c2175ba0 R09:00007ffde8114e80
     [ 8531.232269] R10: 0000000000000000 R11: 0000000000000246 R12:00005580c2175b80
     [ 8531.233839] R13: 00007fc68eac61c4 R14: 00005580c2175a68 R15:0000000000000000
    
    Leaving a tree in the rb-tree:
    
    3853 void btrfs_free_fs_root(struct btrfs_root *root)
    3854 {
    3855         iput(root->ino_cache_inode);
    3856         WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
    
    CC: stable@vger.kernel.org
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    [ add stacktrace ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 469a51b4b273..18eefc5b2532 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4201,6 +4201,14 @@ static void btrfs_destroy_all_ordered_extents(struct btrfs_fs_info *fs_info)
 		spin_lock(&fs_info->ordered_root_lock);
 	}
 	spin_unlock(&fs_info->ordered_root_lock);
+
+	/*
+	 * We need this here because if we've been flipped read-only we won't
+	 * get sync() from the umount, so we need to make sure any ordered
+	 * extents that haven't had their dirty pages IO start writeout yet
+	 * actually get run and error out properly.
+	 */
+	btrfs_wait_ordered_roots(fs_info, U64_MAX, 0, (u64)-1);
 }
 
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,

commit 31890da0bfdd24b135a258404b93c58a65510c7a
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Nov 21 14:05:41 2018 -0500

    btrfs: handle delayed ref head accounting cleanup in abort
    
    We weren't doing any of the accounting cleanup when we aborted
    transactions.  Fix this by making cleanup_ref_head_accounting global and
    calling it from the abort code, this fixes the issue where our
    accounting was all wrong after the fs aborts.
    
    The test generic/475 on a 2G VM can trigger the problems eg.:
    
      [ 8502.136957] WARNING: CPU: 0 PID: 11064 at fs/btrfs/extent-tree.c:5986 btrfs_free_block_grou +ps+0x3dc/0x410 [btrfs]
      [ 8502.148372] CPU: 0 PID: 11064 Comm: umount Not tainted 5.0.0-rc1-default+ #394
      [ 8502.150807] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.2-0-gf9626 +cc-prebuilt.qemu-project.org 04/01/2014
      [ 8502.154317] RIP: 0010:btrfs_free_block_groups+0x3dc/0x410 [btrfs]
      [ 8502.160623] RSP: 0018:ffffb1ab84b93de8 EFLAGS: 00010206
      [ 8502.161906] RAX: 0000000001000000 RBX: ffff9f34b1756400 RCX: 0000000000000000
      [ 8502.163448] RDX: 0000000000000002 RSI: 0000000000000001 RDI: ffff9f34b1755400
      [ 8502.164906] RBP: ffff9f34b7e8c000 R08: 0000000000000001 R09: 0000000000000000
      [ 8502.166716] R10: 0000000000000000 R11: 0000000000000001 R12: ffff9f34b7e8c108
      [ 8502.168498] R13: ffff9f34b7e8c158 R14: 0000000000000000 R15: dead000000000100
      [ 8502.170296] FS:  00007fb1cf15ffc0(0000) GS:ffff9f34bd400000(0000) knlGS:0000000000000000
      [ 8502.172439] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [ 8502.173669] CR2: 00007fb1ced507b0 CR3: 000000002f7a6000 CR4: 00000000000006f0
      [ 8502.175094] Call Trace:
      [ 8502.175759]  close_ctree+0x17f/0x350 [btrfs]
      [ 8502.176721]  generic_shutdown_super+0x64/0x100
      [ 8502.177702]  kill_anon_super+0x14/0x30
      [ 8502.178607]  btrfs_kill_super+0x12/0xa0 [btrfs]
      [ 8502.179602]  deactivate_locked_super+0x29/0x60
      [ 8502.180595]  cleanup_mnt+0x3b/0x70
      [ 8502.181406]  task_work_run+0x98/0xc0
      [ 8502.182255]  exit_to_usermode_loop+0x83/0x90
      [ 8502.183113]  do_syscall_64+0x15b/0x180
      [ 8502.183919]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Corresponding to
    
      release_global_block_rsv() {
      ...
      WARN_ON(fs_info->delayed_refs_rsv.reserved > 0);
    
    CC: stable@vger.kernel.org
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    [ add log dump ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8da2f380d3c0..469a51b4b273 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4265,6 +4265,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		if (pin_bytes)
 			btrfs_pin_extent(fs_info, head->bytenr,
 					 head->num_bytes, 1);
+		btrfs_cleanup_ref_head_accounting(fs_info, delayed_refs, head);
 		btrfs_put_delayed_ref_head(head);
 		cond_resched();
 		spin_lock(&delayed_refs->lock);

commit 52042d8e82ff50d40e76a275ac0b97aa663328b0
Author: Andrea Gelmini <andrea.gelmini@gelma.net>
Date:   Wed Nov 28 12:05:13 2018 +0100

    btrfs: Fix typos in comments and strings
    
    The typos accumulate over time so once in a while time they get fixed in
    a large patch.
    
    Signed-off-by: Andrea Gelmini <andrea.gelmini@gelma.net>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2f934a0b2148..8da2f380d3c0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3100,7 +3100,7 @@ int open_ctree(struct super_block *sb,
 
 	if (!sb_rdonly(sb) && !btrfs_check_rw_degradable(fs_info, NULL)) {
 		btrfs_warn(fs_info,
-		"writeable mount is not allowed due to too many missing devices");
+		"writable mount is not allowed due to too many missing devices");
 		goto fail_sysfs;
 	}
 
@@ -4077,7 +4077,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 	/*
 	 * This is a fast path so only do this check if we have sanity tests
-	 * enabled.  Normal people shouldn't be using umapped buffers as dirty
+	 * enabled.  Normal people shouldn't be using unmapped buffers as dirty
 	 * outside of the sanity tests.
 	 */
 	if (unlikely(test_bit(EXTENT_BUFFER_UNMAPPED, &buf->bflags)))

commit ba2c4d4e3bda7d6de2bc616ae6715e0a0725b294
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Dec 3 10:20:33 2018 -0500

    btrfs: introduce delayed_refs_rsv
    
    Traditionally we've had voodoo in btrfs to account for the space that
    delayed refs may take up by having a global_block_rsv.  This works most
    of the time, except when it doesn't.  We've had issues reported and seen
    in production where sometimes the global reserve is exhausted during
    transaction commit before we can run all of our delayed refs, resulting
    in an aborted transaction.  Because of this voodoo we have equally
    dubious flushing semantics around throttling delayed refs which we often
    get wrong.
    
    So instead give them their own block_rsv.  This way we can always know
    exactly how much outstanding space we need for delayed refs.  This
    allows us to make sure we are constantly filling that reservation up
    with space, and allows us to put more precise pressure on the enospc
    system.  Instead of doing math to see if its a good time to throttle,
    the normal enospc code will be invoked if we have a lot of delayed refs
    pending, and they will be run via the normal flushing mechanism.
    
    For now the delayed_refs_rsv will hold the reservations for the delayed
    refs, the block group updates, and deleting csums.  We could have a
    separate rsv for the block group updates, but the csum deletion stuff is
    still handled via the delayed_refs so that will stay there.
    
    Historical background:
    
    The global reserve has grown to cover everything we don't reserve space
    explicitly for, and we've grown a lot of weird ad-hoc heuristics to know
    if we're running short on space and when it's time to force a commit.  A
    failure rate of 20-40 file systems when we run hundreds of thousands of
    them isn't super high, but cleaning up this code will make things less
    ugly and more predictible.
    
    Thus the delayed refs rsv.  We always know how many delayed refs we have
    outstanding, and although running them generates more we can use the
    global reserve for that spill over, which fits better into it's desired
    use than a full blown reservation.  This first approach is to simply
    take how many times we're reserving space for and multiply that by 2 in
    order to save enough space for the delayed refs that could be generated.
    This is a niave approach and will probably evolve, but for now it works.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com> # high-level review
    [ added background notes from the cover letter ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cbb7cf4a993d..2f934a0b2148 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2678,6 +2678,9 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_block_rsv(&fs_info->empty_block_rsv, BTRFS_BLOCK_RSV_EMPTY);
 	btrfs_init_block_rsv(&fs_info->delayed_block_rsv,
 			     BTRFS_BLOCK_RSV_DELOPS);
+	btrfs_init_block_rsv(&fs_info->delayed_refs_rsv,
+			     BTRFS_BLOCK_RSV_DELREFS);
+
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->defrag_running, 0);
 	atomic_set(&fs_info->qgroup_op_seq, 0);
@@ -4446,6 +4449,7 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 
 		spin_unlock(&cur_trans->dirty_bgs_lock);
 		btrfs_put_block_group(cache);
+		btrfs_delayed_refs_rsv_release(fs_info, 1);
 		spin_lock(&cur_trans->dirty_bgs_lock);
 	}
 	spin_unlock(&cur_trans->dirty_bgs_lock);

commit 53176dde0acd8fa49c6c2e6097283acc6241480f
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 5 01:41:06 2018 +0200

    btrfs: dev-replace: remove custom read/write blocking scheme
    
    After the rw semaphore has been added, the custom blocking using
    ::blocking_readers and ::read_lock_wq is redundant.
    
    The blocking logic in __btrfs_map_block is replaced by extending the
    time the semaphore is held, that has the same blocking effect on writes
    as the previous custom scheme that waited until ::blocking_readers was
    zero.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eca66ac52c7a..cbb7cf4a993d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2142,9 +2142,7 @@ static void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)
 {
 	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
 	init_rwsem(&fs_info->dev_replace.rwsem);
-	atomic_set(&fs_info->dev_replace.blocking_readers, 0);
 	init_waitqueue_head(&fs_info->dev_replace.replace_wait);
-	init_waitqueue_head(&fs_info->dev_replace.read_lock_wq);
 }
 
 static void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)

commit 129827e3001fd1e6892a0629b48f9c7c91cbb8b6
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 5 01:29:24 2018 +0200

    btrfs: dev-replace: swich locking to rw semaphore
    
    This is the first part of removing the custom locking and waiting scheme
    used for device replace. It was probably copied from extent buffer
    locking, but there's nothing that would require more than is provided by
    the common locking primitives.
    
    The rw spinlock protects waiting tasks counter in case of incompatible
    locks and the waitqueue. Same as rw semaphore.
    
    This patch only switches the locking primitive, for better
    bisectability.  There should be no functional change other than the
    overhead of the locking and potential sleeping instead of spinning when
    the lock is contended.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 14d355d0cb7a..eca66ac52c7a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2141,7 +2141,7 @@ static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info)
 static void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)
 {
 	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
-	rwlock_init(&fs_info->dev_replace.lock);
+	init_rwsem(&fs_info->dev_replace.rwsem);
 	atomic_set(&fs_info->dev_replace.blocking_readers, 0);
 	init_waitqueue_head(&fs_info->dev_replace.replace_wait);
 	init_waitqueue_head(&fs_info->dev_replace.read_lock_wq);

commit d2e174d5d3eedb3b9dd97167307bf1f01bd2fa5c
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed Nov 28 09:54:56 2018 +0100

    btrfs: document extent mapping assumptions in checksum
    
    Document why map_private_extent_buffer() cannot return '1' (i.e. the map
    spans two pages) for the csum_tree_block() case.
    
    The current algorithm for detecting a page boundary crossing in
    map_private_extent_buffer() will return a '1' *IFF* the extent buffer's
    offset in the page + the offset passed in by csum_tree_block() and the
    minimal length passed in by csum_tree_block() - 1 are bigger than
    PAGE_SIZE.
    
    We always pass BTRFS_CSUM_SIZE (32) as offset and a minimal length of 32
    and the current extent buffer allocator always guarantees page aligned
    extends, so the above condition can't be true.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4bc270ef29b4..14d355d0cb7a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -279,6 +279,12 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 
 	len = buf->len - offset;
 	while (len > 0) {
+		/*
+		 * Note: we don't need to check for the err == 1 case here, as
+		 * with the given combination of 'start = BTRFS_CSUM_SIZE (32)'
+		 * and 'min_len = 32' and the currently implemented mapping
+		 * algorithm we cannot cross a page boundary.
+		 */
 		err = map_private_extent_buffer(buf, offset, 32,
 					&kaddr, &map_start, &map_len);
 		if (err)

commit 78e62c02abb94e49ea739226a70325a6bf7a6603
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Nov 22 10:17:49 2018 +0200

    btrfs: Remove extent_io_ops::readpage_io_failed_hook
    
    For data inodes this hook does nothing but to return -EAGAIN which is
    used to signal to the endio routines that this bio belongs to a data
    inode. If this is the case the actual retrying is handled by
    bio_readpage_error. Alternatively, if this bio belongs to the btree
    inode then btree_io_failed_hook just does some cleanup and doesn't retry
    anything.
    
    This patch simplifies the code flow by eliminating
    readpage_io_failed_hook and instead open-coding btree_io_failed_hook in
    end_bio_extent_readpage. Also eliminate some needless checks since IO is
    always performed on either data inode or btree inode, both of which are
    guaranteed to have their extent_io_tree::ops set.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 19b270368308..4bc270ef29b4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -673,19 +673,6 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	return ret;
 }
 
-static int btree_io_failed_hook(struct page *page, int failed_mirror)
-{
-	struct extent_buffer *eb;
-
-	eb = (struct extent_buffer *)page->private;
-	set_bit(EXTENT_BUFFER_READ_ERR, &eb->bflags);
-	eb->read_mirror = failed_mirror;
-	atomic_dec(&eb->io_pages);
-	if (test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
-		btree_readahead_hook(eb, -EIO);
-	return -EIO;	/* we fixed nothing */
-}
-
 static void end_workqueue_bio(struct bio *bio)
 {
 	struct btrfs_end_io_wq *end_io_wq = bio->bi_private;
@@ -4560,7 +4547,4 @@ static const struct extent_io_ops btree_extent_io_ops = {
 	/* mandatory callbacks */
 	.submit_bio_hook = btree_submit_bio_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
-	.readpage_io_failed_hook = btree_io_failed_hook,
-
-	/* optional callbacks */
 };

commit 06ea01b1eeb10450ee8448f8895dd641c8d37047
Author: David Sterba <dsterba@suse.com>
Date:   Tue Jul 17 22:08:41 2018 +0200

    btrfs: merge btrfs_submit_bio_done to its caller
    
    There's one caller and its code is simple, we can open code it in
    run_one_async_done. The errors are passed through bio.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aac08ae7bc88..19b270368308 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -764,11 +764,22 @@ static void run_one_async_start(struct btrfs_work *work)
 		async->status = ret;
 }
 
+/*
+ * In order to insert checksums into the metadata in large chunks, we wait
+ * until bio submission time.   All the pages in the bio are checksummed and
+ * sums are attached onto the ordered extent record.
+ *
+ * At IO completion time the csums attached on the ordered extent record are
+ * inserted into the tree.
+ */
 static void run_one_async_done(struct btrfs_work *work)
 {
 	struct async_submit_bio *async;
+	struct inode *inode;
+	blk_status_t ret;
 
 	async = container_of(work, struct  async_submit_bio, work);
+	inode = async->private_data;
 
 	/* If an error occurred we just want to clean up the bio and move on */
 	if (async->status) {
@@ -777,7 +788,12 @@ static void run_one_async_done(struct btrfs_work *work)
 		return;
 	}
 
-	btrfs_submit_bio_done(async->private_data, async->bio, async->mirror_num);
+	ret = btrfs_map_bio(btrfs_sb(inode->i_sb), async->bio,
+			async->mirror_num, 1);
+	if (ret) {
+		async->bio->bi_status = ret;
+		bio_endio(async->bio);
+	}
 }
 
 static void run_one_async_free(struct btrfs_work *work)

commit 0e6ec385b55f6001da8c6b1532494241e52c550d
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Nov 16 13:04:44 2018 +0000

    Btrfs: allow clear_extent_dirty() to receive a cached extent state record
    
    We can have a lot freed extents during the life span of transaction, so
    the red black tree that keeps track of the ranges of each freed extent
    (fs_info->freed_extents[]) can get quite big. When finishing a
    transaction commit we find each range, process it (discard the extents,
    unpin them) and then remove it from the red black tree.
    
    We can use an extent state record as a cache when searching for a range,
    so that when we clean the range we can use the cached extent state we
    passed to the search function instead of iterating the red black tree
    again. Doing things as fast as possible when finishing a transaction (in
    state TRANS_STATE_UNBLOCKED) is convenient as it reduces the time we
    block another task that wants to commit the next transaction.
    
    So change clear_extent_dirty() to allow an optional extent state record to
    be passed as an argument, which will be passed down to __clear_extent_bit.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index feb67dfd663d..aac08ae7bc88 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4365,6 +4365,8 @@ static int btrfs_destroy_pinned_extent(struct btrfs_fs_info *fs_info,
 	unpin = pinned_extents;
 again:
 	while (1) {
+		struct extent_state *cached_state = NULL;
+
 		/*
 		 * The btrfs_finish_extent_commit() may get the same range as
 		 * ours between find_first_extent_bit and clear_extent_dirty.
@@ -4373,13 +4375,14 @@ static int btrfs_destroy_pinned_extent(struct btrfs_fs_info *fs_info,
 		 */
 		mutex_lock(&fs_info->unused_bg_unpin_mutex);
 		ret = find_first_extent_bit(unpin, 0, &start, &end,
-					    EXTENT_DIRTY, NULL);
+					    EXTENT_DIRTY, &cached_state);
 		if (ret) {
 			mutex_unlock(&fs_info->unused_bg_unpin_mutex);
 			break;
 		}
 
-		clear_extent_dirty(unpin, start, end);
+		clear_extent_dirty(unpin, start, end, &cached_state);
+		free_extent_state(cached_state);
 		btrfs_error_unpin_extent_range(fs_info, start, end);
 		mutex_unlock(&fs_info->unused_bg_unpin_mutex);
 		cond_resched();

commit fbc6feaec98ac0c6a615bbe9e17c5689a1a84650
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 30 16:43:25 2018 +0200

    btrfs: Add handling for disk split-brain scenario during fsid change
    
    Even though fsid change without rewrite is a very quick operation it's
    still possible to experience a split-brain scenario if power loss occurs
    at the most inconvenient time. This patch handles the case where power
    failure occurs while the first transaction (the one setting
    CHANGING_FSID_V2) flag is being persisted on disk. This can cause the
    btrfs_fs_devices of this filesystem to be created by a device which:
    
     a) has the CHANGING_FSID_V2 flag set but its fsid value is intact
    
     b) or a device which doesn't have CHANGING_FSID_V2 flag set and its
        fsid value is intact
    
    This situation is trivially handled by the current find_fsid code since
    in both cases the devices are going to be treated like ordinary devices.
    Since btrfs is always mounted using the superblock of the latest
    device (the one with highest generation number), meaning it will have
    the CHANGING_FSID_V2 flag set, ensure it's being cleared on mount. On
    the first transaction commit following mount all disks will have it
    cleared.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ed6d4c83c1e7..feb67dfd663d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2799,10 +2799,10 @@ int open_ctree(struct super_block *sb,
 	 * the whole block of INFO_SIZE
 	 */
 	memcpy(fs_info->super_copy, bh->b_data, sizeof(*fs_info->super_copy));
-	memcpy(fs_info->super_for_commit, fs_info->super_copy,
-	       sizeof(*fs_info->super_for_commit));
 	brelse(bh);
 
+	disk_super = fs_info->super_copy;
+
 	ASSERT(!memcmp(fs_info->fs_devices->fsid, fs_info->super_copy->fsid,
 		       BTRFS_FSID_SIZE));
 
@@ -2812,6 +2812,16 @@ int open_ctree(struct super_block *sb,
 				BTRFS_FSID_SIZE));
 	}
 
+	features = btrfs_super_flags(disk_super);
+	if (features & BTRFS_SUPER_FLAG_CHANGING_FSID_V2) {
+		features &= ~BTRFS_SUPER_FLAG_CHANGING_FSID_V2;
+		btrfs_set_super_flags(disk_super, features);
+		btrfs_info(fs_info,
+			"found metadata UUID change in progress flag, clearing");
+	}
+
+	memcpy(fs_info->super_for_commit, fs_info->super_copy,
+	       sizeof(*fs_info->super_for_commit));
 
 	ret = btrfs_validate_mount_super(fs_info);
 	if (ret) {
@@ -2820,7 +2830,6 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
-	disk_super = fs_info->super_copy;
 	if (!btrfs_super_root(disk_super))
 		goto fail_alloc;
 

commit de37aa513105f864d3c21105bf5542d498f21ca2
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 30 16:43:24 2018 +0200

    btrfs: Remove fsid/metadata_fsid fields from btrfs_info
    
    Currently btrfs_fs_info structure contains a copy of the
    fsid/metadata_uuid fields. Same values are also contained in the
    btrfs_fs_devices structure which fs_info has a reference to. Let's
    reduce duplication by removing the fields from fs_info and always refer
    to the ones in fs_devices. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 18bc678ae4e6..ed6d4c83c1e7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -542,7 +542,7 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 	if (WARN_ON(!PageUptodate(page)))
 		return -EUCLEAN;
 
-	ASSERT(memcmp_extent_buffer(eb, fs_info->metadata_fsid,
+	ASSERT(memcmp_extent_buffer(eb, fs_info->fs_devices->metadata_uuid,
 			btrfs_header_fsid(), BTRFS_FSID_SIZE) == 0);
 
 	return csum_tree_block(fs_info, eb, 0);
@@ -2456,11 +2456,11 @@ static int validate_super(struct btrfs_fs_info *fs_info,
 		ret = -EINVAL;
 	}
 
-	if (memcmp(fs_info->metadata_fsid, sb->dev_item.fsid,
+	if (memcmp(fs_info->fs_devices->metadata_uuid, sb->dev_item.fsid,
 		   BTRFS_FSID_SIZE) != 0) {
 		btrfs_err(fs_info,
 			"dev_item UUID does not match metadata fsid: %pU != %pU",
-			fs_info->metadata_fsid, sb->dev_item.fsid);
+			fs_info->fs_devices->metadata_uuid, sb->dev_item.fsid);
 		ret = -EINVAL;
 	}
 
@@ -2803,14 +2803,16 @@ int open_ctree(struct super_block *sb,
 	       sizeof(*fs_info->super_for_commit));
 	brelse(bh);
 
-	memcpy(fs_info->fsid, fs_info->super_copy->fsid, BTRFS_FSID_SIZE);
+	ASSERT(!memcmp(fs_info->fs_devices->fsid, fs_info->super_copy->fsid,
+		       BTRFS_FSID_SIZE));
+
 	if (btrfs_fs_incompat(fs_info, METADATA_UUID)) {
-		memcpy(fs_info->metadata_fsid,
-		       fs_info->super_copy->metadata_uuid, BTRFS_FSID_SIZE);
-	} else {
-		memcpy(fs_info->metadata_fsid, fs_info->fsid, BTRFS_FSID_SIZE);
+		ASSERT(!memcmp(fs_info->fs_devices->metadata_uuid,
+				fs_info->super_copy->metadata_uuid,
+				BTRFS_FSID_SIZE));
 	}
 
+
 	ret = btrfs_validate_mount_super(fs_info);
 	if (ret) {
 		btrfs_err(fs_info, "superblock contains fatal errors");
@@ -2930,7 +2932,7 @@ int open_ctree(struct super_block *sb,
 
 	sb->s_blocksize = sectorsize;
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
-	memcpy(&sb->s_uuid, fs_info->fsid, BTRFS_FSID_SIZE);
+	memcpy(&sb->s_uuid, fs_info->fs_devices->fsid, BTRFS_FSID_SIZE);
 
 	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_sys_array(fs_info);

commit 7239ff4b2be8ec0c3160da7fdd1475785fdb4cb9
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 30 16:43:23 2018 +0200

    btrfs: Introduce support for FSID change without metadata rewrite
    
    This field is going to be used when the user wants to change the UUID
    of the filesystem without having to rewrite all metadata blocks. This
    field adds another level of indirection such that when the FSID is
    changed what really happens is the current UUID (the one with which the
    fs was created) is copied to the 'metadata_uuid' field in the superblock
    as well as a new incompat flag is set METADATA_UUID. When the kernel
    detects this flag is set it knows that the superblock in fact has 2
    UUIDs:
    
    1. Is the UUID which is user-visible, currently known as FSID.
    2. Metadata UUID - this is the UUID which is stamped into all on-disk
       datastructures belonging to this file system.
    
    When the new incompat flag is present device scanning checks whether
    both fsid/metadata_uuid of the scanned device match any of the
    registered filesystems. When the flag is not set then both UUIDs are
    equal and only the FSID is retained on disk, metadata_uuid is set only
    in-memory during mount.
    
    Additionally a new metadata_uuid field is also added to the fs_info
    struct. It's initialised either with the FSID in case METADATA_UUID
    incompat flag is not set or with the metdata_uuid of the superblock
    otherwise.
    
    This commit introduces the new fields as well as the new incompat flag
    and switches all users of the fsid to the new logic.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor updates in comments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c1d127decc8d..18bc678ae4e6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -542,7 +542,7 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 	if (WARN_ON(!PageUptodate(page)))
 		return -EUCLEAN;
 
-	ASSERT(memcmp_extent_buffer(eb, fs_info->fsid,
+	ASSERT(memcmp_extent_buffer(eb, fs_info->metadata_fsid,
 			btrfs_header_fsid(), BTRFS_FSID_SIZE) == 0);
 
 	return csum_tree_block(fs_info, eb, 0);
@@ -557,7 +557,20 @@ static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
 
 	read_extent_buffer(eb, fsid, btrfs_header_fsid(), BTRFS_FSID_SIZE);
 	while (fs_devices) {
-		if (!memcmp(fsid, fs_devices->fsid, BTRFS_FSID_SIZE)) {
+		u8 *metadata_uuid;
+
+		/*
+		 * Checking the incompat flag is only valid for the current
+		 * fs. For seed devices it's forbidden to have their uuid
+		 * changed so reading ->fsid in this case is fine
+		 */
+		if (fs_devices == fs_info->fs_devices &&
+		    btrfs_fs_incompat(fs_info, METADATA_UUID))
+			metadata_uuid = fs_devices->metadata_uuid;
+		else
+			metadata_uuid = fs_devices->fsid;
+
+		if (!memcmp(fsid, metadata_uuid, BTRFS_FSID_SIZE)) {
 			ret = 0;
 			break;
 		}
@@ -2443,10 +2456,11 @@ static int validate_super(struct btrfs_fs_info *fs_info,
 		ret = -EINVAL;
 	}
 
-	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_FSID_SIZE) != 0) {
+	if (memcmp(fs_info->metadata_fsid, sb->dev_item.fsid,
+		   BTRFS_FSID_SIZE) != 0) {
 		btrfs_err(fs_info,
-			   "dev_item UUID does not match fsid: %pU != %pU",
-			   fs_info->fsid, sb->dev_item.fsid);
+			"dev_item UUID does not match metadata fsid: %pU != %pU",
+			fs_info->metadata_fsid, sb->dev_item.fsid);
 		ret = -EINVAL;
 	}
 
@@ -2790,6 +2804,12 @@ int open_ctree(struct super_block *sb,
 	brelse(bh);
 
 	memcpy(fs_info->fsid, fs_info->super_copy->fsid, BTRFS_FSID_SIZE);
+	if (btrfs_fs_incompat(fs_info, METADATA_UUID)) {
+		memcpy(fs_info->metadata_fsid,
+		       fs_info->super_copy->metadata_uuid, BTRFS_FSID_SIZE);
+	} else {
+		memcpy(fs_info->metadata_fsid, fs_info->fsid, BTRFS_FSID_SIZE);
+	}
 
 	ret = btrfs_validate_mount_super(fs_info);
 	if (ret) {
@@ -3728,7 +3748,8 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 		btrfs_set_stack_device_io_width(dev_item, dev->io_width);
 		btrfs_set_stack_device_sector_size(dev_item, dev->sector_size);
 		memcpy(dev_item->uuid, dev->uuid, BTRFS_UUID_SIZE);
-		memcpy(dev_item->fsid, dev->fs_devices->fsid, BTRFS_FSID_SIZE);
+		memcpy(dev_item->fsid, dev->fs_devices->metadata_uuid,
+		       BTRFS_FSID_SIZE);
 
 		flags = btrfs_super_flags(sb);
 		btrfs_set_super_flags(sb, flags | BTRFS_HEADER_FLAG_WRITTEN);

commit eede2bf34f4fa84ce82e36878ccdd0fdc4b1463c
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Nov 3 10:28:12 2016 -0700

    Btrfs: prevent ioctls from interfering with a swap file
    
    A later patch will implement swap file support for Btrfs, but before we
    do that, we need to make sure that the various Btrfs ioctls cannot
    change a swap file.
    
    When a swap file is active, we must make sure that the extents of the
    file are not moved and that they don't become shared. That means that
    the following are not safe:
    
    - chattr +c (enable compression)
    - reflink
    - dedupe
    - snapshot
    - defrag
    
    Don't allow those to happen on an active swap file.
    
    Additionally, balance, resize, device remove, and device replace are
    also unsafe if they affect an active swapfile. Add a red-black tree of
    block groups and devices which contain an active swapfile. Relocation
    checks each block group against this tree and skips it or errors out for
    balance or resize, respectively. Device remove and device replace check
    the tree for the device they will operate on.
    
    Note that we don't have to worry about chattr -C (disable nocow), which
    we ignore for non-empty files, because an active swapfile must be
    non-empty and can't be truncated. We also don't have to worry about
    autodefrag because it's only done on COW files. Truncate and fallocate
    are already taken care of by the generic code. Device add doesn't do
    relocation so it's not an issue, either.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6d776717d8b3..c1d127decc8d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1178,6 +1178,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	refcount_set(&root->refs, 1);
 	atomic_set(&root->will_be_snapshotted, 0);
 	atomic_set(&root->snapshot_force_cow, 0);
+	atomic_set(&root->nr_swapfiles, 0);
 	root->log_transid = 0;
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;
@@ -2745,6 +2746,9 @@ int open_ctree(struct super_block *sb,
 	fs_info->sectorsize = 4096;
 	fs_info->stripesize = 4096;
 
+	spin_lock_init(&fs_info->swapfile_pins_lock);
+	fs_info->swapfile_pins = RB_ROOT;
+
 	ret = btrfs_alloc_stripe_hash_table(fs_info);
 	if (ret) {
 		err = ret;

commit f8397d69daef06d358430d3054662fb597e37c00
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Nov 6 16:40:20 2018 +0200

    btrfs: Always try all copies when reading extent buffers
    
    When a metadata read is served the endio routine btree_readpage_end_io_hook
    is called which eventually runs the tree-checker. If tree-checker fails
    to validate the read eb then it sets EXTENT_BUFFER_CORRUPT flag. This
    leads to btree_read_extent_buffer_pages wrongly assuming that all
    available copies of this extent buffer are wrong and failing prematurely.
    Fix this modify btree_read_extent_buffer_pages to read all copies of
    the data.
    
    This failure was exhibitted in xfstests btrfs/124 which would
    spuriously fail its balance operations. The reason was that when balance
    was run following re-introduction of the missing raid1 disk
    __btrfs_map_block would map the read request to stripe 0, which
    corresponded to devid 2 (the disk which is being removed in the test):
    
        item 2 key (FIRST_CHUNK_TREE CHUNK_ITEM 3553624064) itemoff 15975 itemsize 112
            length 1073741824 owner 2 stripe_len 65536 type DATA|RAID1
            io_align 65536 io_width 65536 sector_size 4096
            num_stripes 2 sub_stripes 1
                    stripe 0 devid 2 offset 2156920832
                    dev_uuid 8466c350-ed0c-4c3b-b17d-6379b445d5c8
                    stripe 1 devid 1 offset 3553624064
                    dev_uuid 1265d8db-5596-477e-af03-df08eb38d2ca
    
    This caused read requests for a checksum item that to be routed to the
    stale disk which triggered the aforementioned logic involving
    EXTENT_BUFFER_CORRUPT flag. This then triggered cascading failures of
    the balance operation.
    
    Fixes: a826d6dcb32d ("Btrfs: check items for correctness as we search")
    CC: stable@vger.kernel.org # 4.4+
    Suggested-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3f0b6d1936e8..6d776717d8b3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -477,9 +477,9 @@ static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 	int mirror_num = 0;
 	int failed_mirror = 0;
 
-	clear_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 	io_tree = &BTRFS_I(fs_info->btree_inode)->io_tree;
 	while (1) {
+		clear_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 		ret = read_extent_buffer_pages(io_tree, eb, WAIT_COMPLETE,
 					       mirror_num);
 		if (!ret) {
@@ -493,15 +493,6 @@ static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 				break;
 		}
 
-		/*
-		 * This buffer's crc is fine, but its contents are corrupted, so
-		 * there is no reason to read the other copies, they won't be
-		 * any less wrong.
-		 */
-		if (test_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags) ||
-		    ret == -EUCLEAN)
-			break;
-
 		num_copies = btrfs_num_copies(fs_info,
 					      eb->start, eb->len);
 		if (num_copies == 1)

commit d6fd0ae25c6495674dc5a41a8d16bc8e0073276d
Author: Omar Sandoval <osandov@fb.com>
Date:   Wed Oct 31 10:06:08 2018 -0700

    Btrfs: fix missing delayed iputs on unmount
    
    There's a race between close_ctree() and cleaner_kthread().
    close_ctree() sets btrfs_fs_closing(), and the cleaner stops when it
    sees it set, but this is racy; the cleaner might have already checked
    the bit and could be cleaning stuff. In particular, if it deletes unused
    block groups, it will create delayed iputs for the free space cache
    inodes. As of "btrfs: don't run delayed_iputs in commit", we're no
    longer running delayed iputs after a commit. Therefore, if the cleaner
    creates more delayed iputs after delayed iputs are run in
    btrfs_commit_super(), we will leak inodes on unmount and get a busy
    inode crash from the VFS.
    
    Fix it by parking the cleaner before we actually close anything. Then,
    any remaining delayed iputs will always be handled in
    btrfs_commit_super(). This also ensures that the commit in close_ctree()
    is really the last commit, so we can get rid of the commit in
    cleaner_kthread().
    
    The fstest/generic/475 followed by 476 can trigger a crash that
    manifests as a slab corruption caused by accessing the freed kthread
    structure by a wake up function. Sample trace:
    
    [ 5657.077612] BUG: unable to handle kernel NULL pointer dereference at 00000000000000cc
    [ 5657.079432] PGD 1c57a067 P4D 1c57a067 PUD da10067 PMD 0
    [ 5657.080661] Oops: 0000 [#1] PREEMPT SMP
    [ 5657.081592] CPU: 1 PID: 5157 Comm: fsstress Tainted: G        W         4.19.0-rc8-default+ #323
    [ 5657.083703] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.2-0-gf9626cc-prebuilt.qemu-project.org 04/01/2014
    [ 5657.086577] RIP: 0010:shrink_page_list+0x2f9/0xe90
    [ 5657.091937] RSP: 0018:ffffb5c745c8f728 EFLAGS: 00010287
    [ 5657.092953] RAX: 0000000000000074 RBX: ffffb5c745c8f830 RCX: 0000000000000000
    [ 5657.094590] RDX: 0000000000000000 RSI: 0000000000000001 RDI: ffff9a8747fdf3d0
    [ 5657.095987] RBP: ffffb5c745c8f9e0 R08: 0000000000000000 R09: 0000000000000000
    [ 5657.097159] R10: ffff9a8747fdf5e8 R11: 0000000000000000 R12: ffffb5c745c8f788
    [ 5657.098513] R13: ffff9a877f6ff2c0 R14: ffff9a877f6ff2c8 R15: dead000000000200
    [ 5657.099689] FS:  00007f948d853b80(0000) GS:ffff9a877d600000(0000) knlGS:0000000000000000
    [ 5657.101032] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 5657.101953] CR2: 00000000000000cc CR3: 00000000684bd000 CR4: 00000000000006e0
    [ 5657.103159] Call Trace:
    [ 5657.103776]  shrink_inactive_list+0x194/0x410
    [ 5657.104671]  shrink_node_memcg.constprop.84+0x39a/0x6a0
    [ 5657.105750]  shrink_node+0x62/0x1c0
    [ 5657.106529]  try_to_free_pages+0x1a4/0x500
    [ 5657.107408]  __alloc_pages_slowpath+0x2c9/0xb20
    [ 5657.108418]  __alloc_pages_nodemask+0x268/0x2b0
    [ 5657.109348]  kmalloc_large_node+0x37/0x90
    [ 5657.110205]  __kmalloc_node+0x236/0x310
    [ 5657.111014]  kvmalloc_node+0x3e/0x70
    
    Fixes: 30928e9baac2 ("btrfs: don't run delayed_iputs in commit")
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add trace ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 00ee5e37e989..3f0b6d1936e8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1664,9 +1664,8 @@ static int cleaner_kthread(void *arg)
 	struct btrfs_root *root = arg;
 	struct btrfs_fs_info *fs_info = root->fs_info;
 	int again;
-	struct btrfs_trans_handle *trans;
 
-	do {
+	while (1) {
 		again = 0;
 
 		/* Make the cleaner go to sleep early. */
@@ -1715,42 +1714,16 @@ static int cleaner_kthread(void *arg)
 		 */
 		btrfs_delete_unused_bgs(fs_info);
 sleep:
+		if (kthread_should_park())
+			kthread_parkme();
+		if (kthread_should_stop())
+			return 0;
 		if (!again) {
 			set_current_state(TASK_INTERRUPTIBLE);
-			if (!kthread_should_stop())
-				schedule();
+			schedule();
 			__set_current_state(TASK_RUNNING);
 		}
-	} while (!kthread_should_stop());
-
-	/*
-	 * Transaction kthread is stopped before us and wakes us up.
-	 * However we might have started a new transaction and COWed some
-	 * tree blocks when deleting unused block groups for example. So
-	 * make sure we commit the transaction we started to have a clean
-	 * shutdown when evicting the btree inode - if it has dirty pages
-	 * when we do the final iput() on it, eviction will trigger a
-	 * writeback for it which will fail with null pointer dereferences
-	 * since work queues and other resources were already released and
-	 * destroyed by the time the iput/eviction/writeback is made.
-	 */
-	trans = btrfs_attach_transaction(root);
-	if (IS_ERR(trans)) {
-		if (PTR_ERR(trans) != -ENOENT)
-			btrfs_err(fs_info,
-				  "cleaner transaction attach returned %ld",
-				  PTR_ERR(trans));
-	} else {
-		int ret;
-
-		ret = btrfs_commit_transaction(trans);
-		if (ret)
-			btrfs_err(fs_info,
-				  "cleaner open transaction commit returned %d",
-				  ret);
 	}
-
-	return 0;
 }
 
 static int transaction_kthread(void *arg)
@@ -3931,6 +3904,13 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	int ret;
 
 	set_bit(BTRFS_FS_CLOSING_START, &fs_info->flags);
+	/*
+	 * We don't want the cleaner to start new transactions, add more delayed
+	 * iputs, etc. while we're closing. We can't use kthread_stop() yet
+	 * because that frees the task_struct, and the transaction kthread might
+	 * still try to wake up the cleaner.
+	 */
+	kthread_park(fs_info->cleaner_kthread);
 
 	/* wait for the qgroup rescan worker to stop */
 	btrfs_qgroup_wait_for_completion(fs_info, false);
@@ -3958,9 +3938,8 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 
 	if (!sb_rdonly(fs_info->sb)) {
 		/*
-		 * If the cleaner thread is stopped and there are
-		 * block groups queued for removal, the deletion will be
-		 * skipped when we quit the cleaner thread.
+		 * The cleaner kthread is stopped, so do one final pass over
+		 * unused block groups.
 		 */
 		btrfs_delete_unused_bgs(fs_info);
 

commit fcd5e74288f7d36991b1f0fb96b8c57079645e38
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Oct 24 20:24:03 2018 +0800

    btrfs: fix pinned underflow after transaction aborted
    
    When running generic/475, we may get the following warning in dmesg:
    
    [ 6902.102154] WARNING: CPU: 3 PID: 18013 at fs/btrfs/extent-tree.c:9776 btrfs_free_block_groups+0x2af/0x3b0 [btrfs]
    [ 6902.109160] CPU: 3 PID: 18013 Comm: umount Tainted: G        W  O      4.19.0-rc8+ #8
    [ 6902.110971] Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 0.0.0 02/06/2015
    [ 6902.112857] RIP: 0010:btrfs_free_block_groups+0x2af/0x3b0 [btrfs]
    [ 6902.118921] RSP: 0018:ffffc9000459bdb0 EFLAGS: 00010286
    [ 6902.120315] RAX: ffff880175050bb0 RBX: ffff8801124a8000 RCX: 0000000000170007
    [ 6902.121969] RDX: 0000000000000002 RSI: 0000000000170007 RDI: ffffffff8125fb74
    [ 6902.123716] RBP: ffff880175055d10 R08: 0000000000000000 R09: 0000000000000000
    [ 6902.125417] R10: 0000000000000000 R11: 0000000000000000 R12: ffff880175055d88
    [ 6902.127129] R13: ffff880175050bb0 R14: 0000000000000000 R15: dead000000000100
    [ 6902.129060] FS:  00007f4507223780(0000) GS:ffff88017ba00000(0000) knlGS:0000000000000000
    [ 6902.130996] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 6902.132558] CR2: 00005623599cac78 CR3: 000000014b700001 CR4: 00000000003606e0
    [ 6902.134270] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 6902.135981] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 6902.137836] Call Trace:
    [ 6902.138939]  close_ctree+0x171/0x330 [btrfs]
    [ 6902.140181]  ? kthread_stop+0x146/0x1f0
    [ 6902.141277]  generic_shutdown_super+0x6c/0x100
    [ 6902.142517]  kill_anon_super+0x14/0x30
    [ 6902.143554]  btrfs_kill_super+0x13/0x100 [btrfs]
    [ 6902.144790]  deactivate_locked_super+0x2f/0x70
    [ 6902.146014]  cleanup_mnt+0x3b/0x70
    [ 6902.147020]  task_work_run+0x9e/0xd0
    [ 6902.148036]  do_syscall_64+0x470/0x600
    [ 6902.149142]  ? trace_hardirqs_off_thunk+0x1a/0x1c
    [ 6902.150375]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [ 6902.151640] RIP: 0033:0x7f45077a6a7b
    [ 6902.157324] RSP: 002b:00007ffd589f3e68 EFLAGS: 00000246 ORIG_RAX: 00000000000000a6
    [ 6902.159187] RAX: 0000000000000000 RBX: 000055e8eec732b0 RCX: 00007f45077a6a7b
    [ 6902.160834] RDX: 0000000000000001 RSI: 0000000000000000 RDI: 000055e8eec73490
    [ 6902.162526] RBP: 0000000000000000 R08: 000055e8eec734b0 R09: 00007ffd589f26c0
    [ 6902.164141] R10: 0000000000000000 R11: 0000000000000246 R12: 000055e8eec73490
    [ 6902.165815] R13: 00007f4507ac61a4 R14: 0000000000000000 R15: 00007ffd589f40d8
    [ 6902.167553] irq event stamp: 0
    [ 6902.168998] hardirqs last  enabled at (0): [<0000000000000000>]           (null)
    [ 6902.170731] hardirqs last disabled at (0): [<ffffffff810cd810>] copy_process.part.55+0x3b0/0x1f00
    [ 6902.172773] softirqs last  enabled at (0): [<ffffffff810cd810>] copy_process.part.55+0x3b0/0x1f00
    [ 6902.174671] softirqs last disabled at (0): [<0000000000000000>]           (null)
    [ 6902.176407] ---[ end trace 463138c2986b275c ]---
    [ 6902.177636] BTRFS info (device dm-3): space_info 4 has 273465344 free, is not full
    [ 6902.179453] BTRFS info (device dm-3): space_info total=276824064, used=4685824, pinned=18446744073708158976, reserved=0, may_use=0, readonly=65536
    
    In the above line there's "pinned=18446744073708158976" which is an
    unsigned u64 value of -1392640, an obvious underflow.
    
    When transaction_kthread is running cleanup_transaction(), another
    fsstress is running btrfs_commit_transaction(). The
    btrfs_finish_extent_commit() may get the same range as
    btrfs_destroy_pinned_extent() got, which causes the pinned underflow.
    
    Fixes: d4b450cd4b33 ("Btrfs: fix race between transaction commit and empty block group removal")
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b0ab41da91d1..00ee5e37e989 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4359,13 +4359,23 @@ static int btrfs_destroy_pinned_extent(struct btrfs_fs_info *fs_info,
 	unpin = pinned_extents;
 again:
 	while (1) {
+		/*
+		 * The btrfs_finish_extent_commit() may get the same range as
+		 * ours between find_first_extent_bit and clear_extent_dirty.
+		 * Hence, hold the unused_bg_unpin_mutex to avoid double unpin
+		 * the same extent range.
+		 */
+		mutex_lock(&fs_info->unused_bg_unpin_mutex);
 		ret = find_first_extent_bit(unpin, 0, &start, &end,
 					    EXTENT_DIRTY, NULL);
-		if (ret)
+		if (ret) {
+			mutex_unlock(&fs_info->unused_bg_unpin_mutex);
 			break;
+		}
 
 		clear_extent_dirty(unpin, start, end);
 		btrfs_error_unpin_extent_range(fs_info, start, end);
+		mutex_unlock(&fs_info->unused_bg_unpin_mutex);
 		cond_resched();
 	}
 

commit e187831e1875b2754a3ba3c683bd277d4a5f7be8
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Sep 28 07:18:03 2018 -0400

    btrfs: assert on non-empty delayed iputs
    
    I ran into an issue where there was some reference being held on an
    inode that I couldn't track.  This assert wasn't triggered, but it at
    least rules out we're doing something stupid.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 27f6a3348f94..b0ab41da91d1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3976,6 +3976,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	kthread_stop(fs_info->transaction_kthread);
 	kthread_stop(fs_info->cleaner_kthread);
 
+	ASSERT(list_empty(&fs_info->delayed_iputs));
 	set_bit(BTRFS_FS_CLOSING_DONE, &fs_info->flags);
 
 	btrfs_free_qgroup_config(fs_info);

commit 7f8d236ae132a8886a0186008c828e21f7460474
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 5 01:04:49 2018 +0200

    btrfs: dev-replace: move replace members out of fs_info
    
    The replace_wait and bio_counter were mistakenly added to fs_info in
    commit c404e0dc2c843b154f ("Btrfs: fix use-after-free in the finishing
    procedure of the device replace"), but they logically belong to
    fs_info::dev_replace. Besides, bio_counter is a very generic name and is
    confusing in bare fs_info context.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 79903243877b..27f6a3348f94 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2156,7 +2156,7 @@ static void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)
 	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
 	rwlock_init(&fs_info->dev_replace.lock);
 	atomic_set(&fs_info->dev_replace.blocking_readers, 0);
-	init_waitqueue_head(&fs_info->replace_wait);
+	init_waitqueue_head(&fs_info->dev_replace.replace_wait);
 	init_waitqueue_head(&fs_info->dev_replace.read_lock_wq);
 }
 
@@ -2646,7 +2646,8 @@ int open_ctree(struct super_block *sb,
 		goto fail_dirty_metadata_bytes;
 	}
 
-	ret = percpu_counter_init(&fs_info->bio_counter, 0, GFP_KERNEL);
+	ret = percpu_counter_init(&fs_info->dev_replace.bio_counter, 0,
+			GFP_KERNEL);
 	if (ret) {
 		err = ret;
 		goto fail_delalloc_bytes;
@@ -3307,7 +3308,7 @@ int open_ctree(struct super_block *sb,
 
 	iput(fs_info->btree_inode);
 fail_bio_counter:
-	percpu_counter_destroy(&fs_info->bio_counter);
+	percpu_counter_destroy(&fs_info->dev_replace.bio_counter);
 fail_delalloc_bytes:
 	percpu_counter_destroy(&fs_info->delalloc_bytes);
 fail_dirty_metadata_bytes:
@@ -4016,7 +4017,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
 	percpu_counter_destroy(&fs_info->delalloc_bytes);
-	percpu_counter_destroy(&fs_info->bio_counter);
+	percpu_counter_destroy(&fs_info->dev_replace.bio_counter);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 
 	btrfs_free_stripe_hash_table(fs_info);

commit 3280f874576d31b03fe19cbcc23585d96feb4ceb
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 24 17:32:29 2018 +0200

    btrfs: remove btrfs_dev_replace::read_locks
    
    This member seems to be copied from the extent_buffer locking scheme and
    is at least used to assert that the read lock/unlock is properly nested.
    In some way. While the _inc/_dec are called inside the read lock
    section, the asserts are both inside and outside, so the ordering is not
    guaranteed and we can see read/inc/dec ordered in any way
    (theoretically).
    
    A missing call of btrfs_dev_replace_clear_lock_blocking could cause
    unexpected read_locks count, so this at least looks like a valid
    assertion, but this will become unnecessary with later updates.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 517484ecad96..79903243877b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2155,7 +2155,6 @@ static void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)
 {
 	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
 	rwlock_init(&fs_info->dev_replace.lock);
-	atomic_set(&fs_info->dev_replace.read_locks, 0);
 	atomic_set(&fs_info->dev_replace.blocking_readers, 0);
 	init_waitqueue_head(&fs_info->replace_wait);
 	init_waitqueue_head(&fs_info->dev_replace.read_lock_wq);

commit e3d039656384288bbe952413d8d404b3035fe7d7
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Thu Aug 23 03:51:50 2018 +0800

    Btrfs: delayed-refs: use rb_first_cached for ref_tree
    
    rb_first_cached() trades an extra pointer "leftmost" for doing the same
    job as rb_first() but in O(1).
    
    Functions manipulating href->ref_tree need to get the first entry, this
    converts href->ref_tree to use rb_first_cached().
    
    For more details about the optimization see patch "Btrfs: delayed-refs:
    use rb_first_cached for href_root".
    
    Tested-by: Holger Hoffsttte <holger@applied-asynchrony.com>
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a21a96786813..517484ecad96 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4221,11 +4221,11 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 			continue;
 		}
 		spin_lock(&head->lock);
-		while ((n = rb_first(&head->ref_tree)) != NULL) {
+		while ((n = rb_first_cached(&head->ref_tree)) != NULL) {
 			ref = rb_entry(n, struct btrfs_delayed_ref_node,
 				       ref_node);
 			ref->in_tree = 0;
-			rb_erase(&ref->ref_node, &head->ref_tree);
+			rb_erase_cached(&ref->ref_node, &head->ref_tree);
 			RB_CLEAR_NODE(&ref->ref_node);
 			if (!list_empty(&ref->add_list))
 				list_del(&ref->add_list);

commit 5c9d028b3b174e5cf3678a7b0c14e21e51665793
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Thu Aug 23 03:51:49 2018 +0800

    Btrfs: delayed-refs: use rb_first_cached for href_root
    
    rb_first_cached() trades an extra pointer "leftmost" for doing the same
    job as rb_first() but in O(1).
    
    Functions manipulating href_root need to get the first entry, this
    converts href_root to use rb_first_cached().
    
    This patch is first in the sequenct of similar updates to other rbtrees
    and this is analysis of the expected behaviour and improvements.
    
    There's a common pattern:
    
    while (node = rb_first) {
            entry = rb_entry(node)
            next = rb_next(node)
            rb_erase(node)
            cleanup(entry)
    }
    
    rb_first needs to traverse the tree up to logN depth, rb_erase can
    completely reshuffle the tree. With the caching we'll skip the traversal
    in rb_first.  That's a cached memory access vs looped pointer
    dereference trade-off that IMHO has a clear winner.
    
    Measurements show there's not much difference in a sample tree with
    10000 nodes: 4.5s / rb_first and 4.8s / rb_first_cached. Real effects of
    caching and pointer chasing are unpredictable though.
    
    Further optimzations can be done to avoid the expensive rb_erase step.
    In some cases it's ok to process the nodes in any order, so the tree can
    be traversed in post-order, not rebalancing the children nodes and just
    calling free. Care must be taken regarding the next node.
    
    Tested-by: Holger Hoffsttte <holger@applied-asynchrony.com>
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog from mail discussions ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3611df2ce5c1..a21a96786813 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4203,7 +4203,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		return ret;
 	}
 
-	while ((node = rb_first(&delayed_refs->href_root)) != NULL) {
+	while ((node = rb_first_cached(&delayed_refs->href_root)) != NULL) {
 		struct btrfs_delayed_ref_head *head;
 		struct rb_node *n;
 		bool pin_bytes = false;
@@ -4239,7 +4239,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		if (head->processing == 0)
 			delayed_refs->num_heads_ready--;
 		atomic_dec(&delayed_refs->num_entries);
-		rb_erase(&head->href_node, &delayed_refs->href_root);
+		rb_erase_cached(&head->href_node, &delayed_refs->href_root);
 		RB_CLEAR_NODE(&head->href_node);
 		spin_unlock(&head->lock);
 		spin_unlock(&delayed_refs->lock);

commit 4fd786e6c3d67b1348e0ad4f450efe9fc9d7a306
Author: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
Date:   Mon Aug 6 14:25:24 2018 +0900

    btrfs: Remove 'objectid' member from struct btrfs_root
    
    There are two members in struct btrfs_root which indicate root's
    objectid: objectid and root_key.objectid.
    
    They are both set to the same value in __setup_root():
    
      static void __setup_root(struct btrfs_root *root,
                               struct btrfs_fs_info *fs_info,
                               u64 objectid)
      {
        ...
        root->objectid = objectid;
        ...
        root->root_key.objectid = objecitd;
        ...
      }
    
    and not changed to other value after initialization.
    
    grep in btrfs directory shows both are used in many places:
      $ grep -rI "root->root_key.objectid" | wc -l
      133
      $ grep -rI "root->objectid" | wc -l
      55
     (4.17, inc. some noise)
    
    It is confusing to have two similar variable names and it seems
    that there is no rule about which should be used in a certain case.
    
    Since ->root_key itself is needed for tree reloc tree, let's remove
    'objecitd' member and unify code to use ->root_key.objectid in all places.
    
    Signed-off-by: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 05dc3c17cb62..3611df2ce5c1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -125,8 +125,8 @@ struct async_submit_bio {
  * Different roots are used for different purposes and may nest inside each
  * other and they require separate keysets.  As lockdep keys should be
  * static, assign keysets according to the purpose of the root as indicated
- * by btrfs_root->objectid.  This ensures that all special purpose roots
- * have separate keysets.
+ * by btrfs_root->root_key.objectid.  This ensures that all special purpose
+ * roots have separate keysets.
  *
  * Lock-nesting across peer nodes is always done with the immediate parent
  * node locked thus preventing deadlock.  As lockdep doesn't know this, use
@@ -1148,7 +1148,6 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	root->state = 0;
 	root->orphan_cleanup_state = 0;
 
-	root->objectid = objectid;
 	root->last_trans = 0;
 	root->highest_objectid = 0;
 	root->nr_delalloc_inodes = 0;

commit 8ecebf4d767e2307a946c8905278d6358eda35c3
Author: Robbie Ko <robbieko@synology.com>
Date:   Mon Aug 6 10:30:30 2018 +0800

    Btrfs: fix unexpected failure of nocow buffered writes after snapshotting when low on space
    
    Commit e9894fd3e3b3 ("Btrfs: fix snapshot vs nocow writting") forced
    nocow writes to fallback to COW, during writeback, when a snapshot is
    created. This resulted in writes made before creating the snapshot to
    unexpectedly fail with ENOSPC during writeback when success (0) was
    returned to user space through the write system call.
    
    The steps leading to this problem are:
    
    1. When it's not possible to allocate data space for a write, the
       buffered write path checks if a NOCOW write is possible.  If it is,
       it will not reserve space and success (0) is returned to user space.
    
    2. Then when a snapshot is created, the root's will_be_snapshotted
       atomic is incremented and writeback is triggered for all inode's that
       belong to the root being snapshotted. Incrementing that atomic forces
       all previous writes to fallback to COW during writeback (running
       delalloc).
    
    3. This results in the writeback for the inodes to fail and therefore
       setting the ENOSPC error in their mappings, so that a subsequent
       fsync on them will report the error to user space. So it's not a
       completely silent data loss (since fsync will report ENOSPC) but it's
       a very unexpected and undesirable behaviour, because if a clean
       shutdown/unmount of the filesystem happens without previous calls to
       fsync, it is expected to have the data present in the files after
       mounting the filesystem again.
    
    So fix this by adding a new atomic named snapshot_force_cow to the
    root structure which prevents this behaviour and works the following way:
    
    1. It is incremented when we start to create a snapshot after triggering
       writeback and before waiting for writeback to finish.
    
    2. This new atomic is now what is used by writeback (running delalloc)
       to decide whether we need to fallback to COW or not. Because we
       incremented this new atomic after triggering writeback in the
       snapshot creation ioctl, we ensure that all buffered writes that
       happened before snapshot creation will succeed and not fallback to
       COW (which would make them fail with ENOSPC).
    
    3. The existing atomic, will_be_snapshotted, is kept because it is used
       to force new buffered writes, that start after we started
       snapshotting, to reserve data space even when NOCOW is possible.
       This makes these writes fail early with ENOSPC when there's no
       available space to allocate, preventing the unexpected behaviour of
       writeback later failing with ENOSPC due to a fallback to COW mode.
    
    Fixes: e9894fd3e3b3 ("Btrfs: fix snapshot vs nocow writting")
    Signed-off-by: Robbie Ko <robbieko@synology.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5124c15705ce..05dc3c17cb62 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1187,6 +1187,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	atomic_set(&root->log_batch, 0);
 	refcount_set(&root->refs, 1);
 	atomic_set(&root->will_be_snapshotted, 0);
+	atomic_set(&root->snapshot_force_cow, 0);
 	root->log_transid = 0;
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;

commit cf90d884b347c50a1e8c1effc4093e497dd68b4b
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Aug 1 10:37:19 2018 +0800

    btrfs: Introduce mount time chunk <-> dev extent mapping check
    
    This patch will introduce chunk <-> dev extent mapping check, to protect
    us against invalid dev extents or chunks.
    
    Since chunk mapping is the fundamental infrastructure of btrfs, extra
    check at mount time could prevent a lot of unexpected behavior (BUG_ON).
    
    Reported-by: Xu Wen <wen.xu@gatech.edu>
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=200403
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=200407
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Su Yue <suy.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6a5a3cd12886..5124c15705ce 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3030,6 +3030,13 @@ int open_ctree(struct super_block *sb,
 	fs_info->generation = generation;
 	fs_info->last_trans_committed = generation;
 
+	ret = btrfs_verify_dev_extents(fs_info);
+	if (ret) {
+		btrfs_err(fs_info,
+			  "failed to verify dev extents against chunks: %d",
+			  ret);
+		goto fail_block_groups;
+	}
 	ret = btrfs_recover_balance(fs_info);
 	if (ret) {
 		btrfs_err(fs_info, "failed to recover balance: %d", ret);

commit 84db5ccf4262894852e0d178d250678945d9b0b8
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jul 20 16:30:25 2018 +0200

    btrfs: merge free_fs_root helpers
    
    The exported helper just calls the static one. There's no obvious reason
    to have them separate eg. for performance reasons where the static one
    could be better optimized in the same unit. There's a slight decrease in
    code size and stack consumption.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c1d287a766c1..6a5a3cd12886 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -52,7 +52,6 @@
 
 static const struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
-static void free_fs_root(struct btrfs_root *root);
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				      struct btrfs_fs_info *fs_info);
@@ -1504,7 +1503,7 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 
 	return 0;
 fail:
-	/* the caller is responsible to call free_fs_root */
+	/* The caller is responsible to call btrfs_free_fs_root */
 	return ret;
 }
 
@@ -1609,14 +1608,14 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	ret = btrfs_insert_fs_root(fs_info, root);
 	if (ret) {
 		if (ret == -EEXIST) {
-			free_fs_root(root);
+			btrfs_free_fs_root(root);
 			goto again;
 		}
 		goto fail;
 	}
 	return root;
 fail:
-	free_fs_root(root);
+	btrfs_free_fs_root(root);
 	return ERR_PTR(ret);
 }
 
@@ -3831,10 +3830,10 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 		__btrfs_remove_free_space_cache(root->free_ino_pinned);
 	if (root->free_ino_ctl)
 		__btrfs_remove_free_space_cache(root->free_ino_ctl);
-	free_fs_root(root);
+	btrfs_free_fs_root(root);
 }
 
-static void free_fs_root(struct btrfs_root *root)
+void btrfs_free_fs_root(struct btrfs_root *root)
 {
 	iput(root->ino_cache_inode);
 	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
@@ -3849,11 +3848,6 @@ static void free_fs_root(struct btrfs_root *root)
 	btrfs_put_fs_root(root);
 }
 
-void btrfs_free_fs_root(struct btrfs_root *root)
-{
-	free_fs_root(root);
-}
-
 int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 {
 	u64 root_objectid = 0;

commit e9539cff04728e31e150b41000b828745fc0c2b3
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jul 20 16:30:20 2018 +0200

    btrfs: dev-replace: remove unused members of btrfs_dev_replace
    
    Lock owner and nesting level have been unused since day 1, probably
    copy&pasted from the extent_buffer locking scheme without much thinking.
    The locking of device replace is simpler and does not need any lock
    nesting.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3830867e0225..c1d287a766c1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2154,8 +2154,6 @@ static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info)
 
 static void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)
 {
-	fs_info->dev_replace.lock_owner = 0;
-	atomic_set(&fs_info->dev_replace.nesting_level, 0);
 	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
 	rwlock_init(&fs_info->dev_replace.lock);
 	atomic_set(&fs_info->dev_replace.read_locks, 0);

commit e17385ca2960177da402d6f4d80bdc5b53c29bc4
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jul 20 16:30:18 2018 +0200

    btrfs: remove unused member btrfs_root::name
    
    Added in 58176a9604c ("Btrfs: Add per-root block accounting and sysfs
    entries") in 2007, the roots had names exported in sysfs. The code
    was commented out in 4df27c4d5cc1dda54ed ("Btrfs: change how subvolumes
    are organized") and cleaned by 182608c8294b5fe9 ("btrfs: remove old
    unused commented out code").
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9b208ccf24fe..3830867e0225 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1154,7 +1154,6 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	root->highest_objectid = 0;
 	root->nr_delalloc_inodes = 0;
 	root->nr_ordered_extents = 0;
-	root->name = NULL;
 	root->inode_tree = RB_ROOT;
 	INIT_RADIX_TREE(&root->delayed_nodes_tree, GFP_ATOMIC);
 	root->block_rsv = NULL;
@@ -3849,7 +3848,6 @@ static void free_fs_root(struct btrfs_root *root)
 	free_extent_buffer(root->commit_root);
 	kfree(root->free_ino_ctl);
 	kfree(root->free_ino_pinned);
-	kfree(root->name);
 	btrfs_put_fs_root(root);
 }
 

commit 5cdc84bfde22dc17b11ee7cb18cebd48f4a09f70
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 20:32:52 2018 +0200

    btrfs: drop extent_io_ops::set_range_writeback callback
    
    The data and metadata callback implementation both use the same
    function. We can remove the call indirection and intermediate helper
    completely.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0c9c029ade72..9b208ccf24fe 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4528,7 +4528,6 @@ static const struct extent_io_ops btree_extent_io_ops = {
 	.submit_bio_hook = btree_submit_bio_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
 	.readpage_io_failed_hook = btree_io_failed_hook,
-	.set_range_writeback = btrfs_set_range_writeback,
 
 	/* optional callbacks */
 };

commit 00032d38eaa89c76de7d9c1ae6de8c48c14edd74
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 19:28:09 2018 +0200

    btrfs: drop extent_io_ops::merge_bio_hook callback
    
    The data and metadata callback implementation both use the same
    function. We can remove the call indirection completely.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 126460214512..0c9c029ade72 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4527,8 +4527,6 @@ static const struct extent_io_ops btree_extent_io_ops = {
 	/* mandatory callbacks */
 	.submit_bio_hook = btree_submit_bio_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
-	/* note we're sharing with inode.c for the merge bio hook */
-	.merge_bio_hook = btrfs_merge_bio_hook,
 	.readpage_io_failed_hook = btree_io_failed_hook,
 	.set_range_writeback = btrfs_set_range_writeback,
 

commit 05912a3c04ebca217507b4323b679c60eda4ac11
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 19:23:45 2018 +0200

    btrfs: drop extent_io_ops::tree_fs_info callback
    
    All implementations of the callback are trivial and do the same and
    there's only one user. Merge everything together.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 03a7ed448f38..126460214512 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4523,12 +4523,6 @@ static int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info)
 	return 0;
 }
 
-static struct btrfs_fs_info *btree_fs_info(void *private_data)
-{
-	struct inode *inode = private_data;
-	return btrfs_sb(inode->i_sb);
-}
-
 static const struct extent_io_ops btree_extent_io_ops = {
 	/* mandatory callbacks */
 	.submit_bio_hook = btree_submit_bio_hook,
@@ -4537,7 +4531,6 @@ static const struct extent_io_ops btree_extent_io_ops = {
 	.merge_bio_hook = btrfs_merge_bio_hook,
 	.readpage_io_failed_hook = btree_io_failed_hook,
 	.set_range_writeback = btrfs_set_range_writeback,
-	.tree_fs_info = btree_fs_info,
 
 	/* optional callbacks */
 };

commit e288c080dddd1fdc3b7e0165cebd7af51a52d016
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 17:36:24 2018 +0200

    btrfs: unify end_io callbacks of async_submit_bio
    
    The end_io callbacks passed to btrfs_wq_submit_bio
    (btrfs_submit_bio_done and btree_submit_bio_done) are effectively the
    same code, there's no point to do the indirection. Export
    btrfs_submit_bio_done and call it directly.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d82df15af89c..03a7ed448f38 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -108,7 +108,6 @@ struct async_submit_bio {
 	void *private_data;
 	struct bio *bio;
 	extent_submit_bio_start_t *submit_bio_start;
-	extent_submit_bio_done_t *submit_bio_done;
 	int mirror_num;
 	/*
 	 * bio_offset is optional, can be used if the pages in the bio
@@ -775,7 +774,7 @@ static void run_one_async_done(struct btrfs_work *work)
 		return;
 	}
 
-	async->submit_bio_done(async->private_data, async->bio, async->mirror_num);
+	btrfs_submit_bio_done(async->private_data, async->bio, async->mirror_num);
 }
 
 static void run_one_async_free(struct btrfs_work *work)
@@ -789,8 +788,7 @@ static void run_one_async_free(struct btrfs_work *work)
 blk_status_t btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset, void *private_data,
-				 extent_submit_bio_start_t *submit_bio_start,
-				 extent_submit_bio_done_t *submit_bio_done)
+				 extent_submit_bio_start_t *submit_bio_start)
 {
 	struct async_submit_bio *async;
 
@@ -802,7 +800,6 @@ blk_status_t btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct bio *bio,
 	async->bio = bio;
 	async->mirror_num = mirror_num;
 	async->submit_bio_start = submit_bio_start;
-	async->submit_bio_done = submit_bio_done;
 
 	btrfs_init_work(&async->work, btrfs_worker_helper, run_one_async_start,
 			run_one_async_done, run_one_async_free);
@@ -845,24 +842,6 @@ static blk_status_t btree_submit_bio_start(void *private_data, struct bio *bio,
 	return btree_csum_one_bio(bio);
 }
 
-static blk_status_t btree_submit_bio_done(void *private_data, struct bio *bio,
-					    int mirror_num)
-{
-	struct inode *inode = private_data;
-	blk_status_t ret;
-
-	/*
-	 * when we're called for a write, we're already in the async
-	 * submission context.  Just jump into btrfs_map_bio
-	 */
-	ret = btrfs_map_bio(btrfs_sb(inode->i_sb), bio, mirror_num, 1);
-	if (ret) {
-		bio->bi_status = ret;
-		bio_endio(bio);
-	}
-	return ret;
-}
-
 static int check_async_write(struct btrfs_inode *bi)
 {
 	if (atomic_read(&bi->sync_writers))
@@ -905,8 +884,7 @@ static blk_status_t btree_submit_bio_hook(void *private_data, struct bio *bio,
 		 */
 		ret = btrfs_wq_submit_bio(fs_info, bio, mirror_num, 0,
 					  bio_offset, private_data,
-					  btree_submit_bio_start,
-					  btree_submit_bio_done);
+					  btree_submit_bio_start);
 	}
 
 	if (ret)

commit d7cbfafc4bc37ed21351cdedbc6f9d979545dbf3
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 17:31:10 2018 +0200

    btrfs: remove unused member async_submit_bio::bio_flags
    
    After splitting the start and end hooks in a758781d4b76c3 ("btrfs:
    separate types for submit_bio_start and submit_bio_done"), some of
    the function arguments were dropped but not removed from the structure.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8033289d2189..d82df15af89c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -110,7 +110,6 @@ struct async_submit_bio {
 	extent_submit_bio_start_t *submit_bio_start;
 	extent_submit_bio_done_t *submit_bio_done;
 	int mirror_num;
-	unsigned long bio_flags;
 	/*
 	 * bio_offset is optional, can be used if the pages in the bio
 	 * can't tell us where in the file the bio should go
@@ -808,7 +807,6 @@ blk_status_t btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct bio *bio,
 	btrfs_init_work(&async->work, btrfs_worker_helper, run_one_async_start,
 			run_one_async_done, run_one_async_free);
 
-	async->bio_flags = bio_flags;
 	async->bio_offset = bio_offset;
 
 	async->status = 0;

commit d7e8555b1dd493c809e56e359974eecabe7d3fde
Author: David Sterba <dsterba@suse.com>
Date:   Wed Jul 18 17:31:19 2018 +0200

    btrfs: remove unused member async_submit_bio::fs_info
    
    Introduced by c6100a4b4e3d1 ("Btrfs: replace tree->mapping with
    tree->private_data") to be used in run_one_async_done where it got
    unused after 736cd52e0c720103 ("Btrfs: remove nr_async_submits and
    async_submit_draining").
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a4b713d03a33..8033289d2189 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -106,7 +106,6 @@ void __cold btrfs_end_io_wq_exit(void)
  */
 struct async_submit_bio {
 	void *private_data;
-	struct btrfs_fs_info *fs_info;
 	struct bio *bio;
 	extent_submit_bio_start_t *submit_bio_start;
 	extent_submit_bio_done_t *submit_bio_done;
@@ -801,7 +800,6 @@ blk_status_t btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct bio *bio,
 		return BLK_STS_RESOURCE;
 
 	async->private_data = private_data;
-	async->fs_info = fs_info;
 	async->bio = bio;
 	async->mirror_num = mirror_num;
 	async->submit_bio_start = submit_bio_start;

commit b0132a3be5daf84116833542717ff5692f51640e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Jun 27 16:38:24 2018 +0300

    btrfs: Rename EXTENT_BUFFER_DUMMY to EXTENT_BUFFER_UNMAPPED
    
    EXTENT_BUFFER_DUMMY is an awful name for this flag. Buffers which have
    this flag set are not in any way dummy. Rather, they are private in the
    sense that are not mapped and linked to the global buffer tree. This
    flag has subtle implications to the way free_extent_buffer works for
    example, as well as controls whether page->mapping->private_lock is held
    during extent_buffer release. Pages for an unmapped buffer cannot be
    under io, nor can they be written by a 3rd party so taking the lock is
    unnecessary.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ EXTENT_BUFFER_UNMAPPED, update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e3858b2fe014..a4b713d03a33 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4089,10 +4089,10 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 	/*
 	 * This is a fast path so only do this check if we have sanity tests
-	 * enabled.  Normal people shouldn't be marking dummy buffers as dirty
+	 * enabled.  Normal people shouldn't be using umapped buffers as dirty
 	 * outside of the sanity tests.
 	 */
-	if (unlikely(test_bit(EXTENT_BUFFER_DUMMY, &buf->bflags)))
+	if (unlikely(test_bit(EXTENT_BUFFER_UNMAPPED, &buf->bflags)))
 		return;
 #endif
 	root = BTRFS_I(buf->pages[0]->mapping->host)->root;

commit d814a49198eafa6163698bdd93961302f3a877a4
Author: Ethan Lien <ethanlien@synology.com>
Date:   Mon Jul 2 15:44:58 2018 +0800

    btrfs: use correct compare function of dirty_metadata_bytes
    
    We use customized, nodesize batch value to update dirty_metadata_bytes.
    We should also use batch version of compare function or we will easily
    goto fast path and get false result from percpu_counter_compare().
    
    Fixes: e2d845211eda ("Btrfs: use percpu counter for dirty metadata count")
    CC: stable@vger.kernel.org # 4.4+
    Signed-off-by: Ethan Lien <ethanlien@synology.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6023eed3e805..e3858b2fe014 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -959,8 +959,9 @@ static int btree_writepages(struct address_space *mapping,
 
 		fs_info = BTRFS_I(mapping->host)->root->fs_info;
 		/* this is a bit racy, but that's ok */
-		ret = percpu_counter_compare(&fs_info->dirty_metadata_bytes,
-					     BTRFS_DIRTY_METADATA_THRESH);
+		ret = __percpu_counter_compare(&fs_info->dirty_metadata_bytes,
+					     BTRFS_DIRTY_METADATA_THRESH,
+					     fs_info->dirty_metadata_batch);
 		if (ret < 0)
 			return 0;
 	}
@@ -4134,8 +4135,9 @@ static void __btrfs_btree_balance_dirty(struct btrfs_fs_info *fs_info,
 	if (flush_delayed)
 		btrfs_balance_delayed_items(fs_info);
 
-	ret = percpu_counter_compare(&fs_info->dirty_metadata_bytes,
-				     BTRFS_DIRTY_METADATA_THRESH);
+	ret = __percpu_counter_compare(&fs_info->dirty_metadata_bytes,
+				     BTRFS_DIRTY_METADATA_THRESH,
+				     fs_info->dirty_metadata_batch);
 	if (ret > 0) {
 		balance_dirty_pages_ratelimited(fs_info->btree_inode->i_mapping);
 	}

commit d7f663fa3ff906247a979c1115bc92cbabfb19ba
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 29 10:56:47 2018 +0200

    btrfs: prune unused includes
    
    Remove includes if none of the interfaces and exports is used in the
    given source file.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e0baf2f3154d..6023eed3e805 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -5,8 +5,6 @@
 
 #include <linux/fs.h>
 #include <linux/blkdev.h>
-#include <linux/scatterlist.h>
-#include <linux/swap.h>
 #include <linux/radix-tree.h>
 #include <linux/writeback.h>
 #include <linux/buffer_head.h>

commit 3ffbd68c48320730ef64ebfb5e639220f1f65483
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 29 10:56:42 2018 +0200

    btrfs: simplify pointer chasing of local fs_info variables
    
    Functions that get btrfs inode can simply reach the fs_info by
    dereferencing the root and this looks a bit more straightforward
    compared to the btrfs_sb(...) indirection.
    
    If the transaction handle is available and not NULL it's used instead.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c77afa9e5d91..e0baf2f3154d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -212,7 +212,7 @@ struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 		struct page *page, size_t pg_offset, u64 start, u64 len,
 		int create)
 {
-	struct btrfs_fs_info *fs_info = btrfs_sb(inode->vfs_inode.i_sb);
+	struct btrfs_fs_info *fs_info = inode->root->fs_info;
 	struct extent_map_tree *em_tree = &inode->extent_tree;
 	struct extent_map *em;
 	int ret;

commit 893bf4b115c713738df05bb557f8fba14f07c077
Author: Su Yue <suy.fnst@cn.fujitsu.com>
Date:   Fri Jun 22 09:52:15 2018 +0800

    btrfs: print more details when checking tree block finds a problem
    
    For easier debugging, print eb->start if level is invalid.  Also make
    clear if bytenr found is not expected.
    
    Signed-off-by: Su Yue <suy.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2de3da7b7bdc..c77afa9e5d91 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -615,8 +615,8 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != eb->start) {
-		btrfs_err_rl(fs_info, "bad tree block start %llu %llu",
-			     found_start, eb->start);
+		btrfs_err_rl(fs_info, "bad tree block start, want %llu have %llu",
+			     eb->start, found_start);
 		ret = -EIO;
 		goto err;
 	}
@@ -628,8 +628,8 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	}
 	found_level = btrfs_header_level(eb);
 	if (found_level >= BTRFS_MAX_LEVEL) {
-		btrfs_err(fs_info, "bad tree block level %d",
-			  (int)btrfs_header_level(eb));
+		btrfs_err(fs_info, "bad tree block level %d on %llu",
+			  (int)btrfs_header_level(eb), eb->start);
 		ret = -EIO;
 		goto err;
 	}

commit afd48513f0019a2048afed0d98904d3fec7e05dd
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Thu Jun 21 18:04:05 2018 +0200

    btrfs: use monotonic time for transaction handling
    
    The transaction times were changed to ktime_get_real_seconds to avoid
    the y2038 overflow, but they still have a minor problem when they go
    backwards or jump due to settimeofday() or leap seconds.
    
    This changes the transaction handling to instead use ktime_get_seconds(),
    which returns a CLOCK_MONOTONIC timestamp that has neither of those
    problems.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6318ac2539d3..2de3da7b7bdc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1805,7 +1805,7 @@ static int transaction_kthread(void *arg)
 			goto sleep;
 		}
 
-		now = ktime_get_real_seconds();
+		now = ktime_get_seconds();
 		if (cur->state < TRANS_STATE_BLOCKED &&
 		    !test_bit(BTRFS_FS_NEED_ASYNC_COMMIT, &fs_info->flags) &&
 		    (now < cur->start_time ||

commit bc877d285ca3dba24c52406946a4a69847cc7422
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jun 18 14:13:19 2018 +0300

    btrfs: Deduplicate extent_buffer init code
    
    When a new extent buffer is allocated there are a few mandatory fields
    which need to be set in order for the buffer to be sane: level,
    generation, bytenr, backref_rev, owner and FSID/UUID. Currently this
    is open coded in the callers of btrfs_alloc_tree_block, meaning it's
    fairly high in the abstraction hierarchy of operations. This patch
    solves this by simply moving this init code in btrfs_init_new_buffer,
    since this is the function which initializes a newly allocated
    extent buffer. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f3224e23d5fa..6318ac2539d3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1292,15 +1292,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 		goto fail;
 	}
 
-	memzero_extent_buffer(leaf, 0, sizeof(struct btrfs_header));
-	btrfs_set_header_bytenr(leaf, leaf->start);
-	btrfs_set_header_generation(leaf, trans->transid);
-	btrfs_set_header_backref_rev(leaf, BTRFS_MIXED_BACKREF_REV);
-	btrfs_set_header_owner(leaf, objectid);
 	root->node = leaf;
-
-	write_extent_buffer_fsid(leaf, fs_info->fsid);
-	write_extent_buffer_chunk_tree_uuid(leaf, fs_info->chunk_tree_uuid);
 	btrfs_mark_buffer_dirty(leaf);
 
 	root->commit_root = btrfs_root_node(root);
@@ -1374,14 +1366,8 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 		return ERR_CAST(leaf);
 	}
 
-	memzero_extent_buffer(leaf, 0, sizeof(struct btrfs_header));
-	btrfs_set_header_bytenr(leaf, leaf->start);
-	btrfs_set_header_generation(leaf, trans->transid);
-	btrfs_set_header_backref_rev(leaf, BTRFS_MIXED_BACKREF_REV);
-	btrfs_set_header_owner(leaf, BTRFS_TREE_LOG_OBJECTID);
 	root->node = leaf;
 
-	write_extent_buffer_fsid(root->node, fs_info->fsid);
 	btrfs_mark_buffer_dirty(root->node);
 	btrfs_tree_unlock(root->node);
 	return root;

commit a944442c2b8a420301e7830f976bab8cc86a2b4d
Author: Allen Pais <allen.lkml@gmail.com>
Date:   Tue Jun 12 17:18:25 2018 +0530

    btrfs: replace get_seconds with new 64bit time API
    
    The get_seconds() function is deprecated as it truncates the timestamp
    to 32 bits. Change it to or ktime_get_real_seconds().
    
    Signed-off-by: Allen Pais <allen.lkml@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 205092dc9390..f3224e23d5fa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1803,7 +1803,7 @@ static int transaction_kthread(void *arg)
 	struct btrfs_trans_handle *trans;
 	struct btrfs_transaction *cur;
 	u64 transid;
-	unsigned long now;
+	time64_t now;
 	unsigned long delay;
 	bool cannot_commit;
 
@@ -1819,7 +1819,7 @@ static int transaction_kthread(void *arg)
 			goto sleep;
 		}
 
-		now = get_seconds();
+		now = ktime_get_real_seconds();
 		if (cur->state < TRANS_STATE_BLOCKED &&
 		    !test_bit(BTRFS_FS_NEED_ASYNC_COMMIT, &fs_info->flags) &&
 		    (now < cur->start_time ||

commit ff76a864cc94d055b4239fb2cd13e8e633dc7aac
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Fri May 18 10:59:35 2018 +0800

    Btrfs: add parent_transid parameter to veirfy_level_key
    
    As verify_level_key() is checked after verify_parent_transid(), i.e.
    
    if (verify_parent_transid())
       ret = -EIO;
    else if (verify_level_key())
       ret = -EUCLEAN;
    
    if parent_transid is 0, verify_parent_transid() skips verifying
    parent_transid and considers eb as valid, and if verify_level_key()
    reports something wrong, we're not going to know if it's caused by
    corrupted metadata or non-checkecd eb (e.g. stale eb).
    
    The stale eb can be from an outdated raid1 mirror after a degraded
    mount, see eg "btrfs: fix reading stale metadata blocks after degraded
    raid1 mounts" (02a3307aa9c20b4f66262) for more details.
    
    @parent_transid is able to tell whether the eb's generation has been
    verified by the caller.
    
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d8d3b73680ef..205092dc9390 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -415,7 +415,7 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 
 static int verify_level_key(struct btrfs_fs_info *fs_info,
 			    struct extent_buffer *eb, int level,
-			    struct btrfs_key *first_key)
+			    struct btrfs_key *first_key, u64 parent_transid)
 {
 	int found_level;
 	struct btrfs_key found_key;
@@ -453,10 +453,11 @@ static int verify_level_key(struct btrfs_fs_info *fs_info,
 	if (ret) {
 		WARN_ON(1);
 		btrfs_err(fs_info,
-"tree first key mismatch detected, bytenr=%llu key expected=(%llu, %u, %llu) has=(%llu, %u, %llu)",
-			  eb->start, first_key->objectid, first_key->type,
-			  first_key->offset, found_key.objectid,
-			  found_key.type, found_key.offset);
+"tree first key mismatch detected, bytenr=%llu parent_transid=%llu key expected=(%llu,%u,%llu) has=(%llu,%u,%llu)",
+			  eb->start, parent_transid, first_key->objectid,
+			  first_key->type, first_key->offset,
+			  found_key.objectid, found_key.type,
+			  found_key.offset);
 	}
 #endif
 	return ret;
@@ -492,7 +493,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 						   parent_transid, 0))
 				ret = -EIO;
 			else if (verify_level_key(fs_info, eb, level,
-						  first_key))
+						  first_key, parent_transid))
 				ret = -EUCLEAN;
 			else
 				break;

commit a575ceeb1338e7eae6d14e223b077b3c6fd3bb6b
Author: Omar Sandoval <osandov@fb.com>
Date:   Fri May 11 13:13:38 2018 -0700

    Btrfs: get rid of unused orphan infrastructure
    
    Now that we don't keep long-standing reservations for orphan items,
    root->orphan_block_rsv isn't used. We can git rid of it, along with:
    
    - root->orphan_lock, which was used to protect root->orphan_block_rsv
    - root->orphan_inodes, which was used as a refcount for root->orphan_block_rsv
    - BTRFS_INODE_ORPHAN_META_RESERVED, which was used to track reservations
      in root->orphan_block_rsv
    - btrfs_orphan_commit_root(), which was the last user of any of these
      and does nothing else
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a16385091572..d8d3b73680ef 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1184,7 +1184,6 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	root->inode_tree = RB_ROOT;
 	INIT_RADIX_TREE(&root->delayed_nodes_tree, GFP_ATOMIC);
 	root->block_rsv = NULL;
-	root->orphan_block_rsv = NULL;
 
 	INIT_LIST_HEAD(&root->dirty_list);
 	INIT_LIST_HEAD(&root->root_list);
@@ -1194,7 +1193,6 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	INIT_LIST_HEAD(&root->ordered_root);
 	INIT_LIST_HEAD(&root->logged_list[0]);
 	INIT_LIST_HEAD(&root->logged_list[1]);
-	spin_lock_init(&root->orphan_lock);
 	spin_lock_init(&root->inode_lock);
 	spin_lock_init(&root->delalloc_lock);
 	spin_lock_init(&root->ordered_extent_lock);
@@ -1215,7 +1213,6 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	atomic_set(&root->log_commit[1], 0);
 	atomic_set(&root->log_writers, 0);
 	atomic_set(&root->log_batch, 0);
-	atomic_set(&root->orphan_inodes, 0);
 	refcount_set(&root->refs, 1);
 	atomic_set(&root->will_be_snapshotted, 0);
 	root->log_transid = 0;
@@ -3884,8 +3881,6 @@ static void free_fs_root(struct btrfs_root *root)
 {
 	iput(root->ino_cache_inode);
 	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
-	btrfs_free_block_rsv(root->fs_info, root->orphan_block_rsv);
-	root->orphan_block_rsv = NULL;
 	if (root->anon_dev)
 		free_anon_bdev(root->anon_dev);
 	if (root->subv_writers)
@@ -3976,7 +3971,6 @@ int btrfs_commit_super(struct btrfs_fs_info *fs_info)
 
 void close_ctree(struct btrfs_fs_info *fs_info)
 {
-	struct btrfs_root *root = fs_info->tree_root;
 	int ret;
 
 	set_bit(BTRFS_FS_CLOSING_START, &fs_info->flags);
@@ -4072,9 +4066,6 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	btrfs_free_stripe_hash_table(fs_info);
 	btrfs_free_ref_cache(fs_info);
 
-	__btrfs_free_block_rsv(root->orphan_block_rsv);
-	root->orphan_block_rsv = NULL;
-
 	while (!list_empty(&fs_info->pinned_chunks)) {
 		struct extent_map *em;
 

commit 75cb857d2618cca810b8bf13ba5b2ceaaf26ba3d
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri May 11 13:35:27 2018 +0800

    btrfs: Do super block verification before writing it to disk
    
    There are already 2 reports about strangely corrupted super blocks,
    where csum still matches but extra garbage gets slipped into super block.
    
    The corruption would looks like:
    ------
    superblock: bytenr=65536, device=/dev/sdc1
    ---------------------------------------------------------
    csum_type               41700 (INVALID)
    csum                    0x3b252d3a [match]
    bytenr                  65536
    flags                   0x1
                            ( WRITTEN )
    magic                   _BHRfS_M [match]
    ...
    incompat_flags          0x5b22400000000169
                            ( MIXED_BACKREF |
                              COMPRESS_LZO |
                              BIG_METADATA |
                              EXTENDED_IREF |
                              SKINNY_METADATA |
                              unknown flag: 0x5b22400000000000 )
    ...
    ------
    Or
    ------
    superblock: bytenr=65536, device=/dev/mapper/x
    ---------------------------------------------------------
    csum_type              35355 (INVALID)
    csum_size              32
    csum                   0xf0dbeddd [match]
    bytenr                 65536
    flags                  0x1
                           ( WRITTEN )
    magic                  _BHRfS_M [match]
    ...
    incompat_flags         0x176d200000000169
                           ( MIXED_BACKREF |
                             COMPRESS_LZO |
                             BIG_METADATA |
                             EXTENDED_IREF |
                             SKINNY_METADATA |
                             unknown flag: 0x176d200000000000 )
    ------
    
    Obviously, csum_type and incompat_flags get some garbage, but its csum
    still matches, which means kernel calculates the csum based on corrupted
    super block memory.
    And after manually fixing these values, the filesystem is completely
    healthy without any problem exposed by btrfs check.
    
    Although the cause is still unknown, at least detect it and prevent further
    corruption.
    
    Both reports have same symptoms, there's an overwrite on offset 192 of
    the superblock, by 4 bytes. The superblock structure is not allocated or
    freed and stays in the memory for the whole filesystem lifetime, so it's
    not a use-after-free kind of error on someone else's leaked page.
    
    As a vague point for the problable cause is mentioning of other system
    freezing related to graphic card drivers.
    
    Reported-by: Ken Swenson <flat@imo.uto.moe>
    Reported-by: Ben Parsons <9parsonsb@gmail.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add brief analysis of the reports ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eff867370036..a16385091572 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2610,6 +2610,41 @@ static int btrfs_validate_mount_super(struct btrfs_fs_info *fs_info)
 	return validate_super(fs_info, fs_info->super_copy, 0);
 }
 
+/*
+ * Validation of super block at write time.
+ * Some checks like bytenr check will be skipped as their values will be
+ * overwritten soon.
+ * Extra checks like csum type and incompat flags will be done here.
+ */
+static int btrfs_validate_write_super(struct btrfs_fs_info *fs_info,
+				      struct btrfs_super_block *sb)
+{
+	int ret;
+
+	ret = validate_super(fs_info, sb, -1);
+	if (ret < 0)
+		goto out;
+	if (btrfs_super_csum_type(sb) != BTRFS_CSUM_TYPE_CRC32) {
+		ret = -EUCLEAN;
+		btrfs_err(fs_info, "invalid csum type, has %u want %u",
+			  btrfs_super_csum_type(sb), BTRFS_CSUM_TYPE_CRC32);
+		goto out;
+	}
+	if (btrfs_super_incompat_flags(sb) & ~BTRFS_FEATURE_INCOMPAT_SUPP) {
+		ret = -EUCLEAN;
+		btrfs_err(fs_info,
+		"invalid incompat flags, has 0x%llx valid mask 0x%llx",
+			  btrfs_super_incompat_flags(sb),
+			  (unsigned long long)BTRFS_FEATURE_INCOMPAT_SUPP);
+		goto out;
+	}
+out:
+	if (ret < 0)
+		btrfs_err(fs_info,
+		"super block corruption detected before writing it to disk");
+	return ret;
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -3770,6 +3805,14 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 		flags = btrfs_super_flags(sb);
 		btrfs_set_super_flags(sb, flags | BTRFS_HEADER_FLAG_WRITTEN);
 
+		ret = btrfs_validate_write_super(fs_info, sb);
+		if (ret < 0) {
+			mutex_unlock(&fs_info->fs_devices->device_list_mutex);
+			btrfs_handle_fs_error(fs_info, -EUCLEAN,
+				"unexpected superblock corruption detected");
+			return -EUCLEAN;
+		}
+
 		ret = write_dev_supers(dev, sb, max_mirrors);
 		if (ret)
 			total_errors++;

commit 069ec957c35e03ba3beb40973379899cfdbf1ee1
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri May 11 13:35:26 2018 +0800

    btrfs: Refactor btrfs_check_super_valid
    
    Refactor btrfs_check_super_valid:
    
    1) Rename it to btrfs_validate_mount_super()
       Now it's more obvious when the function should be called.
    
    2) Extract core check routine into validate_super()
       Later write time check can reuse it, and if needed, we could also
       use validate_super() to check each super block.
    
    3) Add more comments about btrfs_validate_mount_super()
       Mostly about what it doesn't check and when it should be called.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ rename to validate_super ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6dff0028d69a..eff867370036 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2440,9 +2440,19 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info)
 	return ret;
 }
 
-static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)
+/*
+ * Real super block validation
+ * NOTE: super csum type and incompat features will not be checked here.
+ *
+ * @sb:		super block to check
+ * @mirror_num:	the super block number to check its bytenr:
+ * 		0	the primary (1st) sb
+ * 		1, 2	2nd and 3rd backup copy
+ * 	       -1	skip bytenr check
+ */
+static int validate_super(struct btrfs_fs_info *fs_info,
+			    struct btrfs_super_block *sb, int mirror_num)
 {
-	struct btrfs_super_block *sb = fs_info->super_copy;
 	u64 nodesize = btrfs_super_nodesize(sb);
 	u64 sectorsize = btrfs_super_sectorsize(sb);
 	int ret = 0;
@@ -2545,7 +2555,8 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)
 		ret = -EINVAL;
 	}
 
-	if (btrfs_super_bytenr(sb) != BTRFS_SUPER_INFO_OFFSET) {
+	if (mirror_num >= 0 &&
+	    btrfs_super_bytenr(sb) != btrfs_sb_offset(mirror_num)) {
 		btrfs_err(fs_info, "super offset mismatch %llu != %u",
 			  btrfs_super_bytenr(sb), BTRFS_SUPER_INFO_OFFSET);
 		ret = -EINVAL;
@@ -2589,6 +2600,16 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)
 	return ret;
 }
 
+/*
+ * Validation of super block at mount time.
+ * Some checks already done early at mount time, like csum type and incompat
+ * flags will be skipped.
+ */
+static int btrfs_validate_mount_super(struct btrfs_fs_info *fs_info)
+{
+	return validate_super(fs_info, fs_info->super_copy, 0);
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2814,7 +2835,7 @@ int open_ctree(struct super_block *sb,
 
 	memcpy(fs_info->fsid, fs_info->super_copy->fsid, BTRFS_FSID_SIZE);
 
-	ret = btrfs_check_super_valid(fs_info);
+	ret = btrfs_validate_mount_super(fs_info);
 	if (ret) {
 		btrfs_err(fs_info, "superblock contains fatal errors");
 		err = -EINVAL;

commit 21a852b01820bdb543df2728cf2f39ecf565255d
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri May 11 13:35:25 2018 +0800

    btrfs: Move btrfs_check_super_valid() to avoid forward declaration
    
    Move btrfs_check_super_valid() before its single caller to avoid forward
    declaration.
    
    Though such code motion is not recommended as it pollutes git history,
    in this case the following patches would need to add new forward
    declarations for static functions that we want to avoid.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 47dbbe496253..6dff0028d69a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -55,7 +55,6 @@
 static const struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
-static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info);
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				      struct btrfs_fs_info *fs_info);
@@ -2441,6 +2440,155 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info)
 	return ret;
 }
 
+static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_super_block *sb = fs_info->super_copy;
+	u64 nodesize = btrfs_super_nodesize(sb);
+	u64 sectorsize = btrfs_super_sectorsize(sb);
+	int ret = 0;
+
+	if (btrfs_super_magic(sb) != BTRFS_MAGIC) {
+		btrfs_err(fs_info, "no valid FS found");
+		ret = -EINVAL;
+	}
+	if (btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP) {
+		btrfs_err(fs_info, "unrecognized or unsupported super flag: %llu",
+				btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP);
+		ret = -EINVAL;
+	}
+	if (btrfs_super_root_level(sb) >= BTRFS_MAX_LEVEL) {
+		btrfs_err(fs_info, "tree_root level too big: %d >= %d",
+				btrfs_super_root_level(sb), BTRFS_MAX_LEVEL);
+		ret = -EINVAL;
+	}
+	if (btrfs_super_chunk_root_level(sb) >= BTRFS_MAX_LEVEL) {
+		btrfs_err(fs_info, "chunk_root level too big: %d >= %d",
+				btrfs_super_chunk_root_level(sb), BTRFS_MAX_LEVEL);
+		ret = -EINVAL;
+	}
+	if (btrfs_super_log_root_level(sb) >= BTRFS_MAX_LEVEL) {
+		btrfs_err(fs_info, "log_root level too big: %d >= %d",
+				btrfs_super_log_root_level(sb), BTRFS_MAX_LEVEL);
+		ret = -EINVAL;
+	}
+
+	/*
+	 * Check sectorsize and nodesize first, other check will need it.
+	 * Check all possible sectorsize(4K, 8K, 16K, 32K, 64K) here.
+	 */
+	if (!is_power_of_2(sectorsize) || sectorsize < 4096 ||
+	    sectorsize > BTRFS_MAX_METADATA_BLOCKSIZE) {
+		btrfs_err(fs_info, "invalid sectorsize %llu", sectorsize);
+		ret = -EINVAL;
+	}
+	/* Only PAGE SIZE is supported yet */
+	if (sectorsize != PAGE_SIZE) {
+		btrfs_err(fs_info,
+			"sectorsize %llu not supported yet, only support %lu",
+			sectorsize, PAGE_SIZE);
+		ret = -EINVAL;
+	}
+	if (!is_power_of_2(nodesize) || nodesize < sectorsize ||
+	    nodesize > BTRFS_MAX_METADATA_BLOCKSIZE) {
+		btrfs_err(fs_info, "invalid nodesize %llu", nodesize);
+		ret = -EINVAL;
+	}
+	if (nodesize != le32_to_cpu(sb->__unused_leafsize)) {
+		btrfs_err(fs_info, "invalid leafsize %u, should be %llu",
+			  le32_to_cpu(sb->__unused_leafsize), nodesize);
+		ret = -EINVAL;
+	}
+
+	/* Root alignment check */
+	if (!IS_ALIGNED(btrfs_super_root(sb), sectorsize)) {
+		btrfs_warn(fs_info, "tree_root block unaligned: %llu",
+			   btrfs_super_root(sb));
+		ret = -EINVAL;
+	}
+	if (!IS_ALIGNED(btrfs_super_chunk_root(sb), sectorsize)) {
+		btrfs_warn(fs_info, "chunk_root block unaligned: %llu",
+			   btrfs_super_chunk_root(sb));
+		ret = -EINVAL;
+	}
+	if (!IS_ALIGNED(btrfs_super_log_root(sb), sectorsize)) {
+		btrfs_warn(fs_info, "log_root block unaligned: %llu",
+			   btrfs_super_log_root(sb));
+		ret = -EINVAL;
+	}
+
+	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_FSID_SIZE) != 0) {
+		btrfs_err(fs_info,
+			   "dev_item UUID does not match fsid: %pU != %pU",
+			   fs_info->fsid, sb->dev_item.fsid);
+		ret = -EINVAL;
+	}
+
+	/*
+	 * Hint to catch really bogus numbers, bitflips or so, more exact checks are
+	 * done later
+	 */
+	if (btrfs_super_bytes_used(sb) < 6 * btrfs_super_nodesize(sb)) {
+		btrfs_err(fs_info, "bytes_used is too small %llu",
+			  btrfs_super_bytes_used(sb));
+		ret = -EINVAL;
+	}
+	if (!is_power_of_2(btrfs_super_stripesize(sb))) {
+		btrfs_err(fs_info, "invalid stripesize %u",
+			  btrfs_super_stripesize(sb));
+		ret = -EINVAL;
+	}
+	if (btrfs_super_num_devices(sb) > (1UL << 31))
+		btrfs_warn(fs_info, "suspicious number of devices: %llu",
+			   btrfs_super_num_devices(sb));
+	if (btrfs_super_num_devices(sb) == 0) {
+		btrfs_err(fs_info, "number of devices is 0");
+		ret = -EINVAL;
+	}
+
+	if (btrfs_super_bytenr(sb) != BTRFS_SUPER_INFO_OFFSET) {
+		btrfs_err(fs_info, "super offset mismatch %llu != %u",
+			  btrfs_super_bytenr(sb), BTRFS_SUPER_INFO_OFFSET);
+		ret = -EINVAL;
+	}
+
+	/*
+	 * Obvious sys_chunk_array corruptions, it must hold at least one key
+	 * and one chunk
+	 */
+	if (btrfs_super_sys_array_size(sb) > BTRFS_SYSTEM_CHUNK_ARRAY_SIZE) {
+		btrfs_err(fs_info, "system chunk array too big %u > %u",
+			  btrfs_super_sys_array_size(sb),
+			  BTRFS_SYSTEM_CHUNK_ARRAY_SIZE);
+		ret = -EINVAL;
+	}
+	if (btrfs_super_sys_array_size(sb) < sizeof(struct btrfs_disk_key)
+			+ sizeof(struct btrfs_chunk)) {
+		btrfs_err(fs_info, "system chunk array too small %u < %zu",
+			  btrfs_super_sys_array_size(sb),
+			  sizeof(struct btrfs_disk_key)
+			  + sizeof(struct btrfs_chunk));
+		ret = -EINVAL;
+	}
+
+	/*
+	 * The generation is a global counter, we'll trust it more than the others
+	 * but it's still possible that it's the one that's wrong.
+	 */
+	if (btrfs_super_generation(sb) < btrfs_super_chunk_root_generation(sb))
+		btrfs_warn(fs_info,
+			"suspicious: generation < chunk_root_generation: %llu < %llu",
+			btrfs_super_generation(sb),
+			btrfs_super_chunk_root_generation(sb));
+	if (btrfs_super_generation(sb) < btrfs_super_cache_generation(sb)
+	    && btrfs_super_cache_generation(sb) != (u64)-1)
+		btrfs_warn(fs_info,
+			"suspicious: generation < cache_generation: %llu < %llu",
+			btrfs_super_generation(sb),
+			btrfs_super_cache_generation(sb));
+
+	return ret;
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -3973,155 +4121,6 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid, int level,
 					      level, first_key);
 }
 
-static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)
-{
-	struct btrfs_super_block *sb = fs_info->super_copy;
-	u64 nodesize = btrfs_super_nodesize(sb);
-	u64 sectorsize = btrfs_super_sectorsize(sb);
-	int ret = 0;
-
-	if (btrfs_super_magic(sb) != BTRFS_MAGIC) {
-		btrfs_err(fs_info, "no valid FS found");
-		ret = -EINVAL;
-	}
-	if (btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP) {
-		btrfs_err(fs_info, "unrecognized or unsupported super flag: %llu",
-				btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP);
-		ret = -EINVAL;
-	}
-	if (btrfs_super_root_level(sb) >= BTRFS_MAX_LEVEL) {
-		btrfs_err(fs_info, "tree_root level too big: %d >= %d",
-				btrfs_super_root_level(sb), BTRFS_MAX_LEVEL);
-		ret = -EINVAL;
-	}
-	if (btrfs_super_chunk_root_level(sb) >= BTRFS_MAX_LEVEL) {
-		btrfs_err(fs_info, "chunk_root level too big: %d >= %d",
-				btrfs_super_chunk_root_level(sb), BTRFS_MAX_LEVEL);
-		ret = -EINVAL;
-	}
-	if (btrfs_super_log_root_level(sb) >= BTRFS_MAX_LEVEL) {
-		btrfs_err(fs_info, "log_root level too big: %d >= %d",
-				btrfs_super_log_root_level(sb), BTRFS_MAX_LEVEL);
-		ret = -EINVAL;
-	}
-
-	/*
-	 * Check sectorsize and nodesize first, other check will need it.
-	 * Check all possible sectorsize(4K, 8K, 16K, 32K, 64K) here.
-	 */
-	if (!is_power_of_2(sectorsize) || sectorsize < 4096 ||
-	    sectorsize > BTRFS_MAX_METADATA_BLOCKSIZE) {
-		btrfs_err(fs_info, "invalid sectorsize %llu", sectorsize);
-		ret = -EINVAL;
-	}
-	/* Only PAGE SIZE is supported yet */
-	if (sectorsize != PAGE_SIZE) {
-		btrfs_err(fs_info,
-			"sectorsize %llu not supported yet, only support %lu",
-			sectorsize, PAGE_SIZE);
-		ret = -EINVAL;
-	}
-	if (!is_power_of_2(nodesize) || nodesize < sectorsize ||
-	    nodesize > BTRFS_MAX_METADATA_BLOCKSIZE) {
-		btrfs_err(fs_info, "invalid nodesize %llu", nodesize);
-		ret = -EINVAL;
-	}
-	if (nodesize != le32_to_cpu(sb->__unused_leafsize)) {
-		btrfs_err(fs_info, "invalid leafsize %u, should be %llu",
-			  le32_to_cpu(sb->__unused_leafsize), nodesize);
-		ret = -EINVAL;
-	}
-
-	/* Root alignment check */
-	if (!IS_ALIGNED(btrfs_super_root(sb), sectorsize)) {
-		btrfs_warn(fs_info, "tree_root block unaligned: %llu",
-			   btrfs_super_root(sb));
-		ret = -EINVAL;
-	}
-	if (!IS_ALIGNED(btrfs_super_chunk_root(sb), sectorsize)) {
-		btrfs_warn(fs_info, "chunk_root block unaligned: %llu",
-			   btrfs_super_chunk_root(sb));
-		ret = -EINVAL;
-	}
-	if (!IS_ALIGNED(btrfs_super_log_root(sb), sectorsize)) {
-		btrfs_warn(fs_info, "log_root block unaligned: %llu",
-			   btrfs_super_log_root(sb));
-		ret = -EINVAL;
-	}
-
-	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_FSID_SIZE) != 0) {
-		btrfs_err(fs_info,
-			   "dev_item UUID does not match fsid: %pU != %pU",
-			   fs_info->fsid, sb->dev_item.fsid);
-		ret = -EINVAL;
-	}
-
-	/*
-	 * Hint to catch really bogus numbers, bitflips or so, more exact checks are
-	 * done later
-	 */
-	if (btrfs_super_bytes_used(sb) < 6 * btrfs_super_nodesize(sb)) {
-		btrfs_err(fs_info, "bytes_used is too small %llu",
-			  btrfs_super_bytes_used(sb));
-		ret = -EINVAL;
-	}
-	if (!is_power_of_2(btrfs_super_stripesize(sb))) {
-		btrfs_err(fs_info, "invalid stripesize %u",
-			  btrfs_super_stripesize(sb));
-		ret = -EINVAL;
-	}
-	if (btrfs_super_num_devices(sb) > (1UL << 31))
-		btrfs_warn(fs_info, "suspicious number of devices: %llu",
-			   btrfs_super_num_devices(sb));
-	if (btrfs_super_num_devices(sb) == 0) {
-		btrfs_err(fs_info, "number of devices is 0");
-		ret = -EINVAL;
-	}
-
-	if (btrfs_super_bytenr(sb) != BTRFS_SUPER_INFO_OFFSET) {
-		btrfs_err(fs_info, "super offset mismatch %llu != %u",
-			  btrfs_super_bytenr(sb), BTRFS_SUPER_INFO_OFFSET);
-		ret = -EINVAL;
-	}
-
-	/*
-	 * Obvious sys_chunk_array corruptions, it must hold at least one key
-	 * and one chunk
-	 */
-	if (btrfs_super_sys_array_size(sb) > BTRFS_SYSTEM_CHUNK_ARRAY_SIZE) {
-		btrfs_err(fs_info, "system chunk array too big %u > %u",
-			  btrfs_super_sys_array_size(sb),
-			  BTRFS_SYSTEM_CHUNK_ARRAY_SIZE);
-		ret = -EINVAL;
-	}
-	if (btrfs_super_sys_array_size(sb) < sizeof(struct btrfs_disk_key)
-			+ sizeof(struct btrfs_chunk)) {
-		btrfs_err(fs_info, "system chunk array too small %u < %zu",
-			  btrfs_super_sys_array_size(sb),
-			  sizeof(struct btrfs_disk_key)
-			  + sizeof(struct btrfs_chunk));
-		ret = -EINVAL;
-	}
-
-	/*
-	 * The generation is a global counter, we'll trust it more than the others
-	 * but it's still possible that it's the one that's wrong.
-	 */
-	if (btrfs_super_generation(sb) < btrfs_super_chunk_root_generation(sb))
-		btrfs_warn(fs_info,
-			"suspicious: generation < chunk_root_generation: %llu < %llu",
-			btrfs_super_generation(sb),
-			btrfs_super_chunk_root_generation(sb));
-	if (btrfs_super_generation(sb) < btrfs_super_cache_generation(sb)
-	    && btrfs_super_cache_generation(sb) != (u64)-1)
-		btrfs_warn(fs_info,
-			"suspicious: generation < cache_generation: %llu < %llu",
-			btrfs_super_generation(sb),
-			btrfs_super_cache_generation(sb));
-
-	return ret;
-}
-
 static void btrfs_error_commit_super(struct btrfs_fs_info *fs_info)
 {
 	/* cleanup FS via transaction */

commit 41a6e8913cdff6b30ac53a24641259d117c0b101
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Apr 25 19:01:43 2018 +0800

    btrfs: move btrfs_raid_group values to btrfs_raid_attr table
    
    Add a new member struct btrfs_raid_attr::bg_flag so that
    btrfs_raid_array can maintain the bit map flag of the raid type, and
    so we can drop btrfs_raid_group.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7503ff1dd6f0..47dbbe496253 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3521,7 +3521,7 @@ int btrfs_get_num_tolerated_disk_barrier_failures(u64 flags)
 	for (raid_type = 0; raid_type < BTRFS_NR_RAID_TYPES; raid_type++) {
 		if (raid_type == BTRFS_RAID_SINGLE)
 			continue;
-		if (!(flags & btrfs_raid_group[raid_type]))
+		if (!(flags & btrfs_raid_array[raid_type].bg_flag))
 			continue;
 		min_tolerated = min(min_tolerated,
 				    btrfs_raid_array[raid_type].

commit 3009a62f3b18230a000d1a91e9a676036487e834
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 21 01:31:04 2018 +0100

    btrfs: track running balance in a simpler way
    
    Currently fs_info::balance_running is 0 or 1 and does not use the
    semantics of atomics. The pause and cancel check for 0, that can happen
    only after __btrfs_balance exits for whatever reason.
    
    Parallel calls to balance ioctl may enter btrfs_ioctl_balance multiple
    times but will block on the balance_mutex that protects the
    fs_info::flags bit.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 49a990c8493e..7503ff1dd6f0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2164,7 +2164,6 @@ static void btrfs_init_balance(struct btrfs_fs_info *fs_info)
 {
 	spin_lock_init(&fs_info->balance_lock);
 	mutex_init(&fs_info->balance_mutex);
-	atomic_set(&fs_info->balance_running, 0);
 	atomic_set(&fs_info->balance_pause_req, 0);
 	atomic_set(&fs_info->balance_cancel_req, 0);
 	fs_info->balance_ctl = NULL;

commit dccdb07bc996e9c8de80d06813163ca08288bf73
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 21 00:20:05 2018 +0100

    btrfs: kill btrfs_fs_info::volume_mutex
    
    Mutual exclusion of device add/rm and balance was done by the volume
    mutex up to version 3.7. The commit 5ac00addc7ac091109 ("Btrfs: disallow
    mutually exclusive admin operations from user mode") added a bit that
    essentially tracked the same information.
    
    The status bit has an advantage over a mutex that it can be set without
    restrictions of function context, so it started to be used in the
    mount-time resuming of balance or device replace.
    
    But we don't really need to track the same information in two ways.
    
    1) After the previous cleanups, the main ioctl handlers for
       add/del/resize copy the EXCL_OP bit next to the volume mutex, here
       it's clearly safe.
    
    2) Resuming balance during mount or after rw remount will set only the
       EXCL_OP bit and the volume_mutex is held in the kernel thread that
       calls btrfs_balance.
    
    3) Resuming device replace during mount or after rw remount is done
       after balance and is excluded by the EXCL_OP bit. It does not take
       the volume_mutex at all and completely relies on the EXCL_OP bit.
    
    4) The resuming of balance and dev-replace cannot hapen at the same time
       as the ioctls cannot be started in parallel. Nevertheless, a crafted
       image could trigger that and a warning is printed.
    
    5) Balance is normally excluded by EXCL_OP and also uses own mutex to
       protect against concurrent access to its status data. There's some
       trickery to maintain the right lock nesting in case we need to
       reexamine the status in btrfs_ioctl_balance. The volume_mutex is
       removed and the unlock/lock sequence is left in place as we might
       expect other waiters to proceed.
    
    6) Similar to 5, the unlock/lock sequence is kept in
       btrfs_cancel_balance to allow waiters to continue.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c3504b4d281b..49a990c8493e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2601,7 +2601,6 @@ int open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->chunk_mutex);
 	mutex_init(&fs_info->transaction_kthread_mutex);
 	mutex_init(&fs_info->cleaner_mutex);
-	mutex_init(&fs_info->volume_mutex);
 	mutex_init(&fs_info->ro_block_group_mutex);
 	init_rwsem(&fs_info->commit_root_sem);
 	init_rwsem(&fs_info->cleanup_work_sem);

commit fe816d0f1d4c31c4c31d42ca78a87660565fc800
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Fri Apr 27 12:21:53 2018 +0300

    btrfs: Fix delalloc inodes invalidation during transaction abort
    
    When a transaction is aborted btrfs_cleanup_transaction is called to
    cleanup all the various in-flight bits and pieces which migth be
    active. One of those is delalloc inodes - inodes which have dirty
    pages which haven't been persisted yet. Currently the process of
    freeing such delalloc inodes in exceptional circumstances such as
    transaction abort boiled down to calling btrfs_invalidate_inodes whose
    sole job is to invalidate the dentries for all inodes related to a
    root. This is in fact wrong and insufficient since such delalloc inodes
    will likely have pending pages or ordered-extents and will be linked to
    the sb->s_inode_list. This means that unmounting a btrfs instance with
    an aborted transaction could potentially lead inodes/their pages
    visible to the system long after their superblock has been freed. This
    in turn leads to a "use-after-free" situation once page shrink is
    triggered. This situation could be simulated by running generic/019
    which would cause such inodes to be left hanging, followed by
    generic/176 which causes memory pressure and page eviction which lead
    to touching the freed super block instance. This situation is
    additionally detected by the unmount code of VFS with the following
    message:
    
    "VFS: Busy inodes after unmount of Self-destruct in 5 seconds.  Have a nice day..."
    
    Additionally btrfs hits WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
    in free_fs_root for the same reason.
    
    This patch aims to rectify the sitaution by doing the following:
    
    1. Change btrfs_destroy_delalloc_inodes so that it calls
    invalidate_inode_pages2 for every inode on the delalloc list, this
    ensures that all the pages of the inode are released. This function
    boils down to calling btrfs_releasepage. During test I observed cases
    where inodes on the delalloc list were having an i_count of 0, so this
    necessitates using igrab to be sure we are working on a non-freed inode.
    
    2. Since calling btrfs_releasepage might queue delayed iputs move the
    call out to btrfs_cleanup_transaction in btrfs_error_commit_super before
    calling run_delayed_iputs for the last time. This is necessary to ensure
    that delayed iputs are run.
    
    Note: this patch is tagged for 4.14 stable but the fix applies to older
    versions too but needs to be backported manually due to conflicts.
    
    CC: stable@vger.kernel.org # 4.14.x: 2b8773313494: btrfs: Split btrfs_del_delalloc_inode into 2 functions
    CC: stable@vger.kernel.org # 4.14.x
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add comment to igrab ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 60caa68c3618..c3504b4d281b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3818,6 +3818,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	set_bit(BTRFS_FS_CLOSING_DONE, &fs_info->flags);
 
 	btrfs_free_qgroup_config(fs_info);
+	ASSERT(list_empty(&fs_info->delalloc_roots));
 
 	if (percpu_counter_sum(&fs_info->delalloc_bytes)) {
 		btrfs_info(fs_info, "at unmount delalloc count %lld",
@@ -4125,15 +4126,15 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)
 
 static void btrfs_error_commit_super(struct btrfs_fs_info *fs_info)
 {
+	/* cleanup FS via transaction */
+	btrfs_cleanup_transaction(fs_info);
+
 	mutex_lock(&fs_info->cleaner_mutex);
 	btrfs_run_delayed_iputs(fs_info);
 	mutex_unlock(&fs_info->cleaner_mutex);
 
 	down_write(&fs_info->cleanup_work_sem);
 	up_write(&fs_info->cleanup_work_sem);
-
-	/* cleanup FS via transaction */
-	btrfs_cleanup_transaction(fs_info);
 }
 
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root)
@@ -4258,19 +4259,23 @@ static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
 	list_splice_init(&root->delalloc_inodes, &splice);
 
 	while (!list_empty(&splice)) {
+		struct inode *inode = NULL;
 		btrfs_inode = list_first_entry(&splice, struct btrfs_inode,
 					       delalloc_inodes);
-
-		list_del_init(&btrfs_inode->delalloc_inodes);
-		clear_bit(BTRFS_INODE_IN_DELALLOC_LIST,
-			  &btrfs_inode->runtime_flags);
+		__btrfs_del_delalloc_inode(root, btrfs_inode);
 		spin_unlock(&root->delalloc_lock);
 
-		btrfs_invalidate_inodes(btrfs_inode->root);
-
+		/*
+		 * Make sure we get a live inode and that it'll not disappear
+		 * meanwhile.
+		 */
+		inode = igrab(&btrfs_inode->vfs_inode);
+		if (inode) {
+			invalidate_inode_pages2(inode->i_mapping);
+			iput(inode);
+		}
 		spin_lock(&root->delalloc_lock);
 	}
-
 	spin_unlock(&root->delalloc_lock);
 }
 
@@ -4286,7 +4291,6 @@ static void btrfs_destroy_all_delalloc_inodes(struct btrfs_fs_info *fs_info)
 	while (!list_empty(&splice)) {
 		root = list_first_entry(&splice, struct btrfs_root,
 					 delalloc_root);
-		list_del_init(&root->delalloc_root);
 		root = btrfs_grab_fs_root(root);
 		BUG_ON(!root);
 		spin_unlock(&fs_info->delalloc_root_lock);

commit a514d63882c3d2063b21b865447266ebcb18b04c
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Dec 22 16:06:39 2017 +0800

    btrfs: qgroup: Commit transaction in advance to reduce early EDQUOT
    
    Unlike previous method that tries to commit transaction inside
    qgroup_reserve(), this time we will try to commit transaction using
    fs_info->transaction_kthread to avoid nested transaction and no need to
    worry about locking context.
    
    Since it's an asynchronous function call and we won't wait for
    transaction commit, unlike previous method, we must call it before we
    hit the qgroup limit.
    
    So this patch will use the ratio and size of qgroup meta_pertrans
    reservation as indicator to check if we should trigger a transaction
    commit.  (meta_prealloc won't be cleaned in transaction committ, it's
    useless anyway)
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4ac8b1d21baf..60caa68c3618 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1824,6 +1824,7 @@ static int transaction_kthread(void *arg)
 
 		now = get_seconds();
 		if (cur->state < TRANS_STATE_BLOCKED &&
+		    !test_bit(BTRFS_FS_NEED_ASYNC_COMMIT, &fs_info->flags) &&
 		    (now < cur->start_time ||
 		     now - cur->start_time < fs_info->commit_interval)) {
 			spin_unlock(&fs_info->trans_lock);

commit 5d41be6f702f19f72db816c17175caf9dbdcdfa6
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Apr 13 06:32:47 2018 +0800

    btrfs: Only check first key for committed tree blocks
    
    When looping btrfs/074 with many cpus (>= 8), it's possible to trigger
    kernel warning due to first key verification:
    
    [ 4239.523446] WARNING: CPU: 5 PID: 2381 at fs/btrfs/disk-io.c:460 btree_read_extent_buffer_pages+0x1ad/0x210
    [ 4239.523830] Modules linked in:
    [ 4239.524630] RIP: 0010:btree_read_extent_buffer_pages+0x1ad/0x210
    [ 4239.527101] Call Trace:
    [ 4239.527251]  read_tree_block+0x42/0x70
    [ 4239.527434]  read_node_slot+0xd2/0x110
    [ 4239.527632]  push_leaf_right+0xad/0x1b0
    [ 4239.527809]  split_leaf+0x4ea/0x700
    [ 4239.527988]  ? leaf_space_used+0xbc/0xe0
    [ 4239.528192]  ? btrfs_set_lock_blocking_rw+0x99/0xb0
    [ 4239.528416]  btrfs_search_slot+0x8cc/0xa40
    [ 4239.528605]  btrfs_insert_empty_items+0x71/0xc0
    [ 4239.528798]  __btrfs_run_delayed_refs+0xa98/0x1680
    [ 4239.529013]  btrfs_run_delayed_refs+0x10b/0x1b0
    [ 4239.529205]  btrfs_commit_transaction+0x33/0xaf0
    [ 4239.529445]  ? start_transaction+0xa8/0x4f0
    [ 4239.529630]  btrfs_alloc_data_chunk_ondemand+0x1b0/0x4e0
    [ 4239.529833]  btrfs_check_data_free_space+0x54/0xa0
    [ 4239.530045]  btrfs_delalloc_reserve_space+0x25/0x70
    [ 4239.531907]  btrfs_direct_IO+0x233/0x3d0
    [ 4239.532098]  generic_file_direct_write+0xcb/0x170
    [ 4239.532296]  btrfs_file_write_iter+0x2bb/0x5f4
    [ 4239.532491]  aio_write+0xe2/0x180
    [ 4239.532669]  ? lock_acquire+0xac/0x1e0
    [ 4239.532839]  ? __might_fault+0x3e/0x90
    [ 4239.533032]  do_io_submit+0x594/0x860
    [ 4239.533223]  ? do_io_submit+0x594/0x860
    [ 4239.533398]  SyS_io_submit+0x10/0x20
    [ 4239.533560]  ? SyS_io_submit+0x10/0x20
    [ 4239.533729]  do_syscall_64+0x75/0x1d0
    [ 4239.533979]  entry_SYSCALL_64_after_hwframe+0x42/0xb7
    [ 4239.534182] RIP: 0033:0x7f8519741697
    
    The problem here is, at btree_read_extent_buffer_pages() we don't have
    acquired read/write lock on that extent buffer, only basic info like
    level/bytenr is reliable.
    
    So race condition leads to such false alert.
    
    However in current call site, it's impossible to acquire proper lock
    without race window.
    To fix the problem, we only verify first key for committed tree blocks
    (whose generation is no larger than fs_info->last_trans_committed), so
    the content of such tree blocks will not change and there is no need to
    get read/write lock.
    
    Reported-by: Nikolay Borisov <nborisov@suse.com>
    Fixes: 581c1760415c ("btrfs: Validate child tree block's level and first key")
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 74cbc342b29a..4ac8b1d21baf 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -436,6 +436,14 @@ static int verify_level_key(struct btrfs_fs_info *fs_info,
 	if (!first_key)
 		return 0;
 
+	/*
+	 * For live tree block (new tree blocks in current transaction),
+	 * we need proper lock context to avoid race, which is impossible here.
+	 * So we only checks tree blocks which is read from disk, whose
+	 * generation <= fs_info->last_trans_committed.
+	 */
+	if (btrfs_header_generation(eb) > fs_info->last_trans_committed)
+		return 0;
 	if (found_level)
 		btrfs_node_key_to_cpu(eb, &found_key, 0);
 	else

commit c1d7c514f745628eb096c5cbb10737855879ae25
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:23:33 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- sources
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bb38f4098e9c..74cbc342b29a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1,19 +1,6 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 2007 Oracle.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
 #include <linux/fs.h>

commit af7227338135d2f1b1552bf9a6d43e02dcba10b9
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Sat Mar 31 06:11:56 2018 +0800

    Btrfs: clean up resources during umount after trans is aborted
    
    Currently if some fatal errors occur, like all IO get -EIO, resources
    would be cleaned up when
    a) transaction is being committed or
    b) BTRFS_FS_STATE_ERROR is set
    
    However, in some rare cases, resources may be left alone after transaction
    gets aborted and umount may run into some ASSERT(), e.g.
    ASSERT(list_empty(&block_group->dirty_list));
    
    For case a), in btrfs_commit_transaciton(), there're several places at the
    beginning where we just call btrfs_end_transaction() without cleaning up
    resources.  For case b), it is possible that the trans handle doesn't have
    any dirty stuff, then only trans hanlde is marked as aborted while
    BTRFS_FS_STATE_ERROR is not set, so resources remain in memory.
    
    This makes btrfs also check BTRFS_FS_STATE_TRANS_ABORTED to make sure that
    all resources won't stay in memory after umount.
    
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 07b5e6f7df67..bb38f4098e9c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3812,7 +3812,8 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 			btrfs_err(fs_info, "commit super ret %d", ret);
 	}
 
-	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
+	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state) ||
+	    test_bit(BTRFS_FS_STATE_TRANS_ABORTED, &fs_info->fs_state))
 		btrfs_error_commit_super(fs_info);
 
 	kthread_stop(fs_info->transaction_kthread);

commit f50f43539070c6c876bf5435fb23f898f9d81e72
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Thu Mar 29 06:11:45 2018 +0800

    Btrfs: print error messages when failing to read trees
    
    When mount fails to read trees like fs tree, checksum tree, extent
    tree, etc, there is not enough information about where went wrong.
    
    With this, messages like
    
    "BTRFS warning (device sdf): failed to read root (objectid=7): -5"
    
    would help us a bit.
    
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a2f3a0c67a99..07b5e6f7df67 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2383,23 +2383,29 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info)
 	location.offset = 0;
 
 	root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(root))
-		return PTR_ERR(root);
+	if (IS_ERR(root)) {
+		ret = PTR_ERR(root);
+		goto out;
+	}
 	set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
 	fs_info->extent_root = root;
 
 	location.objectid = BTRFS_DEV_TREE_OBJECTID;
 	root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(root))
-		return PTR_ERR(root);
+	if (IS_ERR(root)) {
+		ret = PTR_ERR(root);
+		goto out;
+	}
 	set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
 	fs_info->dev_root = root;
 	btrfs_init_devices_late(fs_info);
 
 	location.objectid = BTRFS_CSUM_TREE_OBJECTID;
 	root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(root))
-		return PTR_ERR(root);
+	if (IS_ERR(root)) {
+		ret = PTR_ERR(root);
+		goto out;
+	}
 	set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
 	fs_info->csum_root = root;
 
@@ -2416,7 +2422,7 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info)
 	if (IS_ERR(root)) {
 		ret = PTR_ERR(root);
 		if (ret != -ENOENT)
-			return ret;
+			goto out;
 	} else {
 		set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
 		fs_info->uuid_root = root;
@@ -2425,13 +2431,19 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info)
 	if (btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
 		location.objectid = BTRFS_FREE_SPACE_TREE_OBJECTID;
 		root = btrfs_read_tree_root(tree_root, &location);
-		if (IS_ERR(root))
-			return PTR_ERR(root);
+		if (IS_ERR(root)) {
+			ret = PTR_ERR(root);
+			goto out;
+		}
 		set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
 		fs_info->free_space_root = root;
 	}
 
 	return 0;
+out:
+	btrfs_warn(fs_info, "failed to read root (objectid=%llu): %d",
+		   location.objectid, ret);
+	return ret;
 }
 
 int open_ctree(struct super_block *sb,
@@ -3004,6 +3016,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
 	if (IS_ERR(fs_info->fs_root)) {
 		err = PTR_ERR(fs_info->fs_root);
+		btrfs_warn(fs_info, "failed to read fs tree: %d", err);
 		goto fail_qgroup;
 	}
 

commit 581c1760415c48cca9349b198bba52dd38750765
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Mar 29 09:08:11 2018 +0800

    btrfs: Validate child tree block's level and first key
    
    We have several reports about node pointer points to incorrect child
    tree blocks, which could have even wrong owner and level but still with
    valid generation and checksum.
    
    Although btrfs check could handle it and print error message like:
    leaf parent key incorrect 60670574592
    
    Kernel doesn't have enough check on this type of corruption correctly.
    At least add such check to read_tree_block() and btrfs_read_buffer(),
    where we need two new parameters @level and @first_key to verify the
    child tree block.
    
    The new @level check is mandatory and all call sites are already
    modified to extract expected level from its call chain.
    
    While @first_key is optional, the following call sites are skipping such
    check:
    1) Root node/leaf
       As ROOT_ITEM doesn't contain the first key, skip @first_key check.
    2) Direct backref
       Only parent bytenr and level is known and we need to resolve the key
       all by ourselves, skip @first_key check.
    
    Another note of this verification is, it needs extra info from nodeptr
    or ROOT_ITEM, so it can't fit into current tree-checker framework, which
    is limited to node/leaf boundary.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 269374261e36..a2f3a0c67a99 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -427,13 +427,59 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
+static int verify_level_key(struct btrfs_fs_info *fs_info,
+			    struct extent_buffer *eb, int level,
+			    struct btrfs_key *first_key)
+{
+	int found_level;
+	struct btrfs_key found_key;
+	int ret;
+
+	found_level = btrfs_header_level(eb);
+	if (found_level != level) {
+#ifdef CONFIG_BTRFS_DEBUG
+		WARN_ON(1);
+		btrfs_err(fs_info,
+"tree level mismatch detected, bytenr=%llu level expected=%u has=%u",
+			  eb->start, level, found_level);
+#endif
+		return -EIO;
+	}
+
+	if (!first_key)
+		return 0;
+
+	if (found_level)
+		btrfs_node_key_to_cpu(eb, &found_key, 0);
+	else
+		btrfs_item_key_to_cpu(eb, &found_key, 0);
+	ret = btrfs_comp_cpu_keys(first_key, &found_key);
+
+#ifdef CONFIG_BTRFS_DEBUG
+	if (ret) {
+		WARN_ON(1);
+		btrfs_err(fs_info,
+"tree first key mismatch detected, bytenr=%llu key expected=(%llu, %u, %llu) has=(%llu, %u, %llu)",
+			  eb->start, first_key->objectid, first_key->type,
+			  first_key->offset, found_key.objectid,
+			  found_key.type, found_key.offset);
+	}
+#endif
+	return ret;
+}
+
 /*
  * helper to read a given tree block, doing retries as required when
  * the checksums don't match and we have alternate mirrors to try.
+ *
+ * @parent_transid:	expected transid, skip check if 0
+ * @level:		expected level, mandatory check
+ * @first_key:		expected key of first slot, skip check if NULL
  */
 static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 					  struct extent_buffer *eb,
-					  u64 parent_transid)
+					  u64 parent_transid, int level,
+					  struct btrfs_key *first_key)
 {
 	struct extent_io_tree *io_tree;
 	int failed = 0;
@@ -448,11 +494,14 @@ static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 		ret = read_extent_buffer_pages(io_tree, eb, WAIT_COMPLETE,
 					       mirror_num);
 		if (!ret) {
-			if (!verify_parent_transid(io_tree, eb,
+			if (verify_parent_transid(io_tree, eb,
 						   parent_transid, 0))
-				break;
-			else
 				ret = -EIO;
+			else if (verify_level_key(fs_info, eb, level,
+						  first_key))
+				ret = -EUCLEAN;
+			else
+				break;
 		}
 
 		/*
@@ -460,7 +509,8 @@ static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 		 * there is no reason to read the other copies, they won't be
 		 * any less wrong.
 		 */
-		if (test_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags))
+		if (test_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags) ||
+		    ret == -EUCLEAN)
 			break;
 
 		num_copies = btrfs_num_copies(fs_info,
@@ -1049,8 +1099,17 @@ void btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
 			        buf->start, buf->start + buf->len - 1);
 }
 
+/*
+ * Read tree block at logical address @bytenr and do variant basic but critical
+ * verification.
+ *
+ * @parent_transid:	expected transid of this tree block, skip check if 0
+ * @level:		expected level, mandatory check
+ * @first_key:		expected key in slot 0, skip check if NULL
+ */
 struct extent_buffer *read_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr,
-				      u64 parent_transid)
+				      u64 parent_transid, int level,
+				      struct btrfs_key *first_key)
 {
 	struct extent_buffer *buf = NULL;
 	int ret;
@@ -1059,7 +1118,8 @@ struct extent_buffer *read_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr,
 	if (IS_ERR(buf))
 		return buf;
 
-	ret = btree_read_extent_buffer_pages(fs_info, buf, parent_transid);
+	ret = btree_read_extent_buffer_pages(fs_info, buf, parent_transid,
+					     level, first_key);
 	if (ret) {
 		free_extent_buffer(buf);
 		return ERR_PTR(ret);
@@ -1388,6 +1448,7 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	struct btrfs_path *path;
 	u64 generation;
 	int ret;
+	int level;
 
 	path = btrfs_alloc_path();
 	if (!path)
@@ -1410,9 +1471,10 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	}
 
 	generation = btrfs_root_generation(&root->root_item);
+	level = btrfs_root_level(&root->root_item);
 	root->node = read_tree_block(fs_info,
 				     btrfs_root_bytenr(&root->root_item),
-				     generation);
+				     generation, level, NULL);
 	if (IS_ERR(root->node)) {
 		ret = PTR_ERR(root->node);
 		goto find_fail;
@@ -2261,6 +2323,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	struct btrfs_root *log_tree_root;
 	struct btrfs_super_block *disk_super = fs_info->super_copy;
 	u64 bytenr = btrfs_super_log_root(disk_super);
+	int level = btrfs_super_log_root_level(disk_super);
 
 	if (fs_devices->rw_devices == 0) {
 		btrfs_warn(fs_info, "log replay required on RO media");
@@ -2274,7 +2337,8 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	__setup_root(log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
 
 	log_tree_root->node = read_tree_block(fs_info, bytenr,
-					      fs_info->generation + 1);
+					      fs_info->generation + 1,
+					      level, NULL);
 	if (IS_ERR(log_tree_root->node)) {
 		btrfs_warn(fs_info, "failed to read log tree");
 		ret = PTR_ERR(log_tree_root->node);
@@ -2390,6 +2454,7 @@ int open_ctree(struct super_block *sb,
 	int num_backups_tried = 0;
 	int backup_index = 0;
 	int clear_free_space_tree = 0;
+	int level;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
@@ -2725,12 +2790,13 @@ int open_ctree(struct super_block *sb,
 	}
 
 	generation = btrfs_super_chunk_root_generation(disk_super);
+	level = btrfs_super_chunk_root_level(disk_super);
 
 	__setup_root(chunk_root, fs_info, BTRFS_CHUNK_TREE_OBJECTID);
 
 	chunk_root->node = read_tree_block(fs_info,
 					   btrfs_super_chunk_root(disk_super),
-					   generation);
+					   generation, level, NULL);
 	if (IS_ERR(chunk_root->node) ||
 	    !extent_buffer_uptodate(chunk_root->node)) {
 		btrfs_err(fs_info, "failed to read chunk root");
@@ -2764,10 +2830,11 @@ int open_ctree(struct super_block *sb,
 
 retry_root_backup:
 	generation = btrfs_super_generation(disk_super);
+	level = btrfs_super_root_level(disk_super);
 
 	tree_root->node = read_tree_block(fs_info,
 					  btrfs_super_root(disk_super),
-					  generation);
+					  generation, level, NULL);
 	if (IS_ERR(tree_root->node) ||
 	    !extent_buffer_uptodate(tree_root->node)) {
 		btrfs_warn(fs_info, "failed to read tree root");
@@ -3887,12 +3954,14 @@ void btrfs_btree_balance_dirty_nodelay(struct btrfs_fs_info *fs_info)
 	__btrfs_btree_balance_dirty(fs_info, 0);
 }
 
-int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
+int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid, int level,
+		      struct btrfs_key *first_key)
 {
 	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
 	struct btrfs_fs_info *fs_info = root->fs_info;
 
-	return btree_read_extent_buffer_pages(fs_info, buf, parent_transid);
+	return btree_read_extent_buffer_pages(fs_info, buf, parent_transid,
+					      level, first_key);
 }
 
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)

commit 8287475a20552af66b32c07704dbdbeeb898ac1f
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Dec 12 15:34:34 2017 +0800

    btrfs: qgroup: Use root::qgroup_meta_rsv_* to record qgroup meta reserved space
    
    For quota disabled->enable case, it's possible that at reservation time
    quota was not enabled so no bytes were really reserved, while at release
    time, quota was enabled so we will try to release some bytes we didn't
    really own.
    
    Such situation can cause metadata reserveation underflow, for both types,
    also less possible for per-trans type since quota enable will commit
    transaction.
    
    To address this, record qgroup meta reserved bytes into
    root::qgroup_meta_rsv_pertrans and ::prealloc.
    So at releasing time we won't free any bytes we didn't reserve.
    
    For DATA, it's already handled by io_tree, so nothing needs to be done
    there.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ad900f821f1e..269374261e36 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1147,6 +1147,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	spin_lock_init(&root->accounting_lock);
 	spin_lock_init(&root->log_extents_lock[0]);
 	spin_lock_init(&root->log_extents_lock[1]);
+	spin_lock_init(&root->qgroup_meta_rsv_lock);
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
 	mutex_init(&root->ordered_extent_mutex);

commit e1211d0e896b71d395fe411d0e0a76f4bc336617
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Dec 12 15:34:30 2017 +0800

    btrfs: qgroup: Don't use root->qgroup_meta_rsv for qgroup
    
    Since qgroup has seperate metadata reservation types now, we can
    completely get rid of the old root->qgroup_meta_rsv, which mostly acts
    as current META_PERTRANS reservation type.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 38b387ae78f8..ad900f821f1e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1163,7 +1163,6 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	atomic_set(&root->orphan_inodes, 0);
 	refcount_set(&root->refs, 1);
 	atomic_set(&root->will_be_snapshotted, 0);
-	atomic64_set(&root->qgroup_meta_rsv, 0);
 	root->log_transid = 0;
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;

commit 75cb379d2635215ad2c67750693f7dc45ad19a5f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Mar 20 15:25:26 2018 -0400

    btrfs: defer adding raid type kobject until after chunk relocation
    
    Any time the first block group of a new type is created, we add a new
    kobject to sysfs to hold the attributes for that type.  Kobject-internal
    allocations always use GFP_KERNEL, making them prone to fs-reclaim races.
    While it appears as if this can occur any time a block group is created,
    the only times the first block group of a new type can be created in
    memory is at mount and when we create the first new block group during
    raid conversion.
    
    This patch adds a new list to track pending kobject additions and then
    handles them after we do chunk relocation.  Between relocating the
    target chunk (or forcing allocation of a new chunk in the case of data)
    and removing the old chunk, we're in a safe place for fs-reclaim to
    occur.  We're holding the volume mutex, which is already held across
    page faults, and the delete_unused_bgs_mutex, which will only stall
    the cleaner thread.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1657d6aa4fa6..38b387ae78f8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2431,6 +2431,8 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->delayed_iputs);
 	INIT_LIST_HEAD(&fs_info->delalloc_roots);
 	INIT_LIST_HEAD(&fs_info->caching_block_groups);
+	INIT_LIST_HEAD(&fs_info->pending_raid_kobjs);
+	spin_lock_init(&fs_info->pending_raid_kobjs_lock);
 	spin_lock_init(&fs_info->delalloc_root_lock);
 	spin_lock_init(&fs_info->trans_lock);
 	spin_lock_init(&fs_info->fs_roots_radix_lock);

commit 8a5a916d9a35e13576d79cc16e24611821b13e34
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Mar 16 14:36:27 2018 -0400

    btrfs: fix lockdep splat in btrfs_alloc_subvolume_writers
    
    While running btrfs/011, I hit the following lockdep splat.
    
    This is the important bit:
       pcpu_alloc+0x1ac/0x5e0
       __percpu_counter_init+0x4e/0xb0
       btrfs_init_fs_root+0x99/0x1c0 [btrfs]
       btrfs_get_fs_root.part.54+0x5b/0x150 [btrfs]
       resolve_indirect_refs+0x130/0x830 [btrfs]
       find_parent_nodes+0x69e/0xff0 [btrfs]
       btrfs_find_all_roots_safe+0xa0/0x110 [btrfs]
       btrfs_find_all_roots+0x50/0x70 [btrfs]
       btrfs_qgroup_prepare_account_extents+0x53/0x90 [btrfs]
       btrfs_commit_transaction+0x3ce/0x9b0 [btrfs]
    
    The percpu_counter_init call in btrfs_alloc_subvolume_writers
    uses GFP_KERNEL, which we can't do during transaction commit.
    
    This switches it to GFP_NOFS.
    
    ========================================================
    WARNING: possible irq lock inversion dependency detected
    4.12.14-kvmsmall #8 Tainted: G        W
    --------------------------------------------------------
    kswapd0/50 just changed the state of lock:
     (&delayed_node->mutex){+.+.-.}, at: [<ffffffffc06994fa>] __btrfs_release_delayed_node+0x3a/0x1f0 [btrfs]
    but this lock took another, RECLAIM_FS-unsafe lock in the past:
     (pcpu_alloc_mutex){+.+.+.}
    
    and interrupts could create inverse lock ordering between them.
    
    other info that might help us debug this:
    Chain exists of:
      &delayed_node->mutex --> &found->groups_sem --> pcpu_alloc_mutex
    
     Possible interrupt unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(pcpu_alloc_mutex);
                                   local_irq_disable();
                                   lock(&delayed_node->mutex);
                                   lock(&found->groups_sem);
      <Interrupt>
        lock(&delayed_node->mutex);
    
     *** DEADLOCK ***
    
    2 locks held by kswapd0/50:
     #0:  (shrinker_rwsem){++++..}, at: [<ffffffff811dc11f>] shrink_slab+0x7f/0x5b0
     #1:  (&type->s_umount_key#30){+++++.}, at: [<ffffffff8126dec6>] trylock_super+0x16/0x50
    
    the shortest dependencies between 2nd lock and 1st lock:
       -> (pcpu_alloc_mutex){+.+.+.} ops: 4904 {
          HARDIRQ-ON-W at:
                              __mutex_lock+0x4e/0x8c0
                              pcpu_alloc+0x1ac/0x5e0
                              alloc_kmem_cache_cpus.isra.70+0x25/0xa0
                              __do_tune_cpucache+0x2c/0x220
                              do_tune_cpucache+0x26/0xc0
                              enable_cpucache+0x6d/0xf0
                              kmem_cache_init_late+0x42/0x75
                              start_kernel+0x343/0x4cb
                              x86_64_start_kernel+0x127/0x134
                              secondary_startup_64+0xa5/0xb0
          SOFTIRQ-ON-W at:
                              __mutex_lock+0x4e/0x8c0
                              pcpu_alloc+0x1ac/0x5e0
                              alloc_kmem_cache_cpus.isra.70+0x25/0xa0
                              __do_tune_cpucache+0x2c/0x220
                              do_tune_cpucache+0x26/0xc0
                              enable_cpucache+0x6d/0xf0
                              kmem_cache_init_late+0x42/0x75
                              start_kernel+0x343/0x4cb
                              x86_64_start_kernel+0x127/0x134
                              secondary_startup_64+0xa5/0xb0
          RECLAIM_FS-ON-W at:
                                 __kmalloc+0x47/0x310
                                 pcpu_extend_area_map+0x2b/0xc0
                                 pcpu_alloc+0x3ec/0x5e0
                                 alloc_kmem_cache_cpus.isra.70+0x25/0xa0
                                 __do_tune_cpucache+0x2c/0x220
                                 do_tune_cpucache+0x26/0xc0
                                 enable_cpucache+0x6d/0xf0
                                 __kmem_cache_create+0x1bf/0x390
                                 create_cache+0xba/0x1b0
                                 kmem_cache_create+0x1f8/0x2b0
                                 ksm_init+0x6f/0x19d
                                 do_one_initcall+0x50/0x1b0
                                 kernel_init_freeable+0x201/0x289
                                 kernel_init+0xa/0x100
                                 ret_from_fork+0x3a/0x50
          INITIAL USE at:
                             __mutex_lock+0x4e/0x8c0
                             pcpu_alloc+0x1ac/0x5e0
                             alloc_kmem_cache_cpus.isra.70+0x25/0xa0
                             setup_cpu_cache+0x2f/0x1f0
                             __kmem_cache_create+0x1bf/0x390
                             create_boot_cache+0x8b/0xb1
                             kmem_cache_init+0xa1/0x19e
                             start_kernel+0x270/0x4cb
                             x86_64_start_kernel+0x127/0x134
                             secondary_startup_64+0xa5/0xb0
        }
        ... key      at: [<ffffffff821d8e70>] pcpu_alloc_mutex+0x70/0xa0
        ... acquired at:
       pcpu_alloc+0x1ac/0x5e0
       __percpu_counter_init+0x4e/0xb0
       btrfs_init_fs_root+0x99/0x1c0 [btrfs]
       btrfs_get_fs_root.part.54+0x5b/0x150 [btrfs]
       resolve_indirect_refs+0x130/0x830 [btrfs]
       find_parent_nodes+0x69e/0xff0 [btrfs]
       btrfs_find_all_roots_safe+0xa0/0x110 [btrfs]
       btrfs_find_all_roots+0x50/0x70 [btrfs]
       btrfs_qgroup_prepare_account_extents+0x53/0x90 [btrfs]
       btrfs_commit_transaction+0x3ce/0x9b0 [btrfs]
       transaction_kthread+0x176/0x1b0 [btrfs]
       kthread+0x102/0x140
       ret_from_fork+0x3a/0x50
    
      -> (&fs_info->commit_root_sem){++++..} ops: 1566382 {
         HARDIRQ-ON-W at:
                            down_write+0x3e/0xa0
                            cache_block_group+0x287/0x420 [btrfs]
                            find_free_extent+0x106c/0x12d0 [btrfs]
                            btrfs_reserve_extent+0xd8/0x170 [btrfs]
                            cow_file_range.isra.66+0x133/0x470 [btrfs]
                            run_delalloc_range+0x121/0x410 [btrfs]
                            writepage_delalloc.isra.50+0xfe/0x180 [btrfs]
                            __extent_writepage+0x19a/0x360 [btrfs]
                            extent_write_cache_pages.constprop.56+0x249/0x3e0 [btrfs]
                            extent_writepages+0x4d/0x60 [btrfs]
                            do_writepages+0x1a/0x70
                            __filemap_fdatawrite_range+0xa7/0xe0
                            btrfs_rename+0x5ee/0xdb0 [btrfs]
                            vfs_rename+0x52a/0x7e0
                            SyS_rename+0x351/0x3b0
                            do_syscall_64+0x79/0x1e0
                            entry_SYSCALL_64_after_hwframe+0x42/0xb7
         HARDIRQ-ON-R at:
                            down_read+0x35/0x90
                            caching_thread+0x57/0x560 [btrfs]
                            normal_work_helper+0x1c0/0x5e0 [btrfs]
                            process_one_work+0x1e0/0x5c0
                            worker_thread+0x44/0x390
                            kthread+0x102/0x140
                            ret_from_fork+0x3a/0x50
         SOFTIRQ-ON-W at:
                            down_write+0x3e/0xa0
                            cache_block_group+0x287/0x420 [btrfs]
                            find_free_extent+0x106c/0x12d0 [btrfs]
                            btrfs_reserve_extent+0xd8/0x170 [btrfs]
                            cow_file_range.isra.66+0x133/0x470 [btrfs]
                            run_delalloc_range+0x121/0x410 [btrfs]
                            writepage_delalloc.isra.50+0xfe/0x180 [btrfs]
                            __extent_writepage+0x19a/0x360 [btrfs]
                            extent_write_cache_pages.constprop.56+0x249/0x3e0 [btrfs]
                            extent_writepages+0x4d/0x60 [btrfs]
                            do_writepages+0x1a/0x70
                            __filemap_fdatawrite_range+0xa7/0xe0
                            btrfs_rename+0x5ee/0xdb0 [btrfs]
                            vfs_rename+0x52a/0x7e0
                            SyS_rename+0x351/0x3b0
                            do_syscall_64+0x79/0x1e0
                            entry_SYSCALL_64_after_hwframe+0x42/0xb7
         SOFTIRQ-ON-R at:
                            down_read+0x35/0x90
                            caching_thread+0x57/0x560 [btrfs]
                            normal_work_helper+0x1c0/0x5e0 [btrfs]
                            process_one_work+0x1e0/0x5c0
                            worker_thread+0x44/0x390
                            kthread+0x102/0x140
                            ret_from_fork+0x3a/0x50
         INITIAL USE at:
                           down_write+0x3e/0xa0
                           cache_block_group+0x287/0x420 [btrfs]
                           find_free_extent+0x106c/0x12d0 [btrfs]
                           btrfs_reserve_extent+0xd8/0x170 [btrfs]
                           cow_file_range.isra.66+0x133/0x470 [btrfs]
                           run_delalloc_range+0x121/0x410 [btrfs]
                           writepage_delalloc.isra.50+0xfe/0x180 [btrfs]
                           __extent_writepage+0x19a/0x360 [btrfs]
                           extent_write_cache_pages.constprop.56+0x249/0x3e0 [btrfs]
                           extent_writepages+0x4d/0x60 [btrfs]
                           do_writepages+0x1a/0x70
                           __filemap_fdatawrite_range+0xa7/0xe0
                           btrfs_rename+0x5ee/0xdb0 [btrfs]
                           vfs_rename+0x52a/0x7e0
                           SyS_rename+0x351/0x3b0
                           do_syscall_64+0x79/0x1e0
                           entry_SYSCALL_64_after_hwframe+0x42/0xb7
       }
       ... key      at: [<ffffffffc0729578>] __key.61970+0x0/0xfffffffffff9aa88 [btrfs]
       ... acquired at:
       cache_block_group+0x287/0x420 [btrfs]
       find_free_extent+0x106c/0x12d0 [btrfs]
       btrfs_reserve_extent+0xd8/0x170 [btrfs]
       btrfs_alloc_tree_block+0x12f/0x4c0 [btrfs]
       btrfs_create_tree+0xbb/0x2a0 [btrfs]
       btrfs_create_uuid_tree+0x37/0x140 [btrfs]
       open_ctree+0x23c0/0x2660 [btrfs]
       btrfs_mount+0xd36/0xf90 [btrfs]
       mount_fs+0x3a/0x160
       vfs_kern_mount+0x66/0x150
       btrfs_mount+0x18c/0xf90 [btrfs]
       mount_fs+0x3a/0x160
       vfs_kern_mount+0x66/0x150
       do_mount+0x1c1/0xcc0
       SyS_mount+0x7e/0xd0
       do_syscall_64+0x79/0x1e0
       entry_SYSCALL_64_after_hwframe+0x42/0xb7
    
     -> (&found->groups_sem){++++..} ops: 2134587 {
        HARDIRQ-ON-W at:
                          down_write+0x3e/0xa0
                          __link_block_group+0x34/0x130 [btrfs]
                          btrfs_read_block_groups+0x33d/0x7b0 [btrfs]
                          open_ctree+0x2054/0x2660 [btrfs]
                          btrfs_mount+0xd36/0xf90 [btrfs]
                          mount_fs+0x3a/0x160
                          vfs_kern_mount+0x66/0x150
                          btrfs_mount+0x18c/0xf90 [btrfs]
                          mount_fs+0x3a/0x160
                          vfs_kern_mount+0x66/0x150
                          do_mount+0x1c1/0xcc0
                          SyS_mount+0x7e/0xd0
                          do_syscall_64+0x79/0x1e0
                          entry_SYSCALL_64_after_hwframe+0x42/0xb7
        HARDIRQ-ON-R at:
                          down_read+0x35/0x90
                          btrfs_calc_num_tolerated_disk_barrier_failures+0x113/0x1f0 [btrfs]
                          open_ctree+0x207b/0x2660 [btrfs]
                          btrfs_mount+0xd36/0xf90 [btrfs]
                          mount_fs+0x3a/0x160
                          vfs_kern_mount+0x66/0x150
                          btrfs_mount+0x18c/0xf90 [btrfs]
                          mount_fs+0x3a/0x160
                          vfs_kern_mount+0x66/0x150
                          do_mount+0x1c1/0xcc0
                          SyS_mount+0x7e/0xd0
                          do_syscall_64+0x79/0x1e0
                          entry_SYSCALL_64_after_hwframe+0x42/0xb7
        SOFTIRQ-ON-W at:
                          down_write+0x3e/0xa0
                          __link_block_group+0x34/0x130 [btrfs]
                          btrfs_read_block_groups+0x33d/0x7b0 [btrfs]
                          open_ctree+0x2054/0x2660 [btrfs]
                          btrfs_mount+0xd36/0xf90 [btrfs]
                          mount_fs+0x3a/0x160
                          vfs_kern_mount+0x66/0x150
                          btrfs_mount+0x18c/0xf90 [btrfs]
                          mount_fs+0x3a/0x160
                          vfs_kern_mount+0x66/0x150
                          do_mount+0x1c1/0xcc0
                          SyS_mount+0x7e/0xd0
                          do_syscall_64+0x79/0x1e0
                          entry_SYSCALL_64_after_hwframe+0x42/0xb7
        SOFTIRQ-ON-R at:
                          down_read+0x35/0x90
                          btrfs_calc_num_tolerated_disk_barrier_failures+0x113/0x1f0 [btrfs]
                          open_ctree+0x207b/0x2660 [btrfs]
                          btrfs_mount+0xd36/0xf90 [btrfs]
                          mount_fs+0x3a/0x160
                          vfs_kern_mount+0x66/0x150
                          btrfs_mount+0x18c/0xf90 [btrfs]
                          mount_fs+0x3a/0x160
                          vfs_kern_mount+0x66/0x150
                          do_mount+0x1c1/0xcc0
                          SyS_mount+0x7e/0xd0
                          do_syscall_64+0x79/0x1e0
                          entry_SYSCALL_64_after_hwframe+0x42/0xb7
        INITIAL USE at:
                         down_write+0x3e/0xa0
                         __link_block_group+0x34/0x130 [btrfs]
                         btrfs_read_block_groups+0x33d/0x7b0 [btrfs]
                         open_ctree+0x2054/0x2660 [btrfs]
                         btrfs_mount+0xd36/0xf90 [btrfs]
                         mount_fs+0x3a/0x160
                         vfs_kern_mount+0x66/0x150
                         btrfs_mount+0x18c/0xf90 [btrfs]
                         mount_fs+0x3a/0x160
                         vfs_kern_mount+0x66/0x150
                         do_mount+0x1c1/0xcc0
                         SyS_mount+0x7e/0xd0
                         do_syscall_64+0x79/0x1e0
                         entry_SYSCALL_64_after_hwframe+0x42/0xb7
      }
      ... key      at: [<ffffffffc0729488>] __key.59101+0x0/0xfffffffffff9ab78 [btrfs]
      ... acquired at:
       find_free_extent+0xcb4/0x12d0 [btrfs]
       btrfs_reserve_extent+0xd8/0x170 [btrfs]
       btrfs_alloc_tree_block+0x12f/0x4c0 [btrfs]
       __btrfs_cow_block+0x110/0x5b0 [btrfs]
       btrfs_cow_block+0xd7/0x290 [btrfs]
       btrfs_search_slot+0x1f6/0x960 [btrfs]
       btrfs_lookup_inode+0x2a/0x90 [btrfs]
       __btrfs_update_delayed_inode+0x65/0x210 [btrfs]
       btrfs_commit_inode_delayed_inode+0x121/0x130 [btrfs]
       btrfs_evict_inode+0x3fe/0x6a0 [btrfs]
       evict+0xc4/0x190
       __dentry_kill+0xbf/0x170
       dput+0x2ae/0x2f0
       SyS_rename+0x2a6/0x3b0
       do_syscall_64+0x79/0x1e0
       entry_SYSCALL_64_after_hwframe+0x42/0xb7
    
    -> (&delayed_node->mutex){+.+.-.} ops: 5580204 {
       HARDIRQ-ON-W at:
                        __mutex_lock+0x4e/0x8c0
                        btrfs_delayed_update_inode+0x46/0x6e0 [btrfs]
                        btrfs_update_inode+0x83/0x110 [btrfs]
                        btrfs_dirty_inode+0x62/0xe0 [btrfs]
                        touch_atime+0x8c/0xb0
                        do_generic_file_read+0x818/0xb10
                        __vfs_read+0xdc/0x150
                        vfs_read+0x8a/0x130
                        SyS_read+0x45/0xa0
                        do_syscall_64+0x79/0x1e0
                        entry_SYSCALL_64_after_hwframe+0x42/0xb7
       SOFTIRQ-ON-W at:
                        __mutex_lock+0x4e/0x8c0
                        btrfs_delayed_update_inode+0x46/0x6e0 [btrfs]
                        btrfs_update_inode+0x83/0x110 [btrfs]
                        btrfs_dirty_inode+0x62/0xe0 [btrfs]
                        touch_atime+0x8c/0xb0
                        do_generic_file_read+0x818/0xb10
                        __vfs_read+0xdc/0x150
                        vfs_read+0x8a/0x130
                        SyS_read+0x45/0xa0
                        do_syscall_64+0x79/0x1e0
                        entry_SYSCALL_64_after_hwframe+0x42/0xb7
       IN-RECLAIM_FS-W at:
                           __mutex_lock+0x4e/0x8c0
                           __btrfs_release_delayed_node+0x3a/0x1f0 [btrfs]
                           btrfs_evict_inode+0x22c/0x6a0 [btrfs]
                           evict+0xc4/0x190
                           dispose_list+0x35/0x50
                           prune_icache_sb+0x42/0x50
                           super_cache_scan+0x139/0x190
                           shrink_slab+0x262/0x5b0
                           shrink_node+0x2eb/0x2f0
                           kswapd+0x2eb/0x890
                           kthread+0x102/0x140
                           ret_from_fork+0x3a/0x50
       INITIAL USE at:
                       __mutex_lock+0x4e/0x8c0
                       btrfs_delayed_update_inode+0x46/0x6e0 [btrfs]
                       btrfs_update_inode+0x83/0x110 [btrfs]
                       btrfs_dirty_inode+0x62/0xe0 [btrfs]
                       touch_atime+0x8c/0xb0
                       do_generic_file_read+0x818/0xb10
                       __vfs_read+0xdc/0x150
                       vfs_read+0x8a/0x130
                       SyS_read+0x45/0xa0
                       do_syscall_64+0x79/0x1e0
                       entry_SYSCALL_64_after_hwframe+0x42/0xb7
     }
     ... key      at: [<ffffffffc072d488>] __key.56935+0x0/0xfffffffffff96b78 [btrfs]
     ... acquired at:
       __lock_acquire+0x264/0x11c0
       lock_acquire+0xbd/0x1e0
       __mutex_lock+0x4e/0x8c0
       __btrfs_release_delayed_node+0x3a/0x1f0 [btrfs]
       btrfs_evict_inode+0x22c/0x6a0 [btrfs]
       evict+0xc4/0x190
       dispose_list+0x35/0x50
       prune_icache_sb+0x42/0x50
       super_cache_scan+0x139/0x190
       shrink_slab+0x262/0x5b0
       shrink_node+0x2eb/0x2f0
       kswapd+0x2eb/0x890
       kthread+0x102/0x140
       ret_from_fork+0x3a/0x50
    
    stack backtrace:
    CPU: 1 PID: 50 Comm: kswapd0 Tainted: G        W        4.12.14-kvmsmall #8 SLE15 (unreleased)
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.0.0-prebuilt.qemu-project.org 04/01/2014
    Call Trace:
     dump_stack+0x78/0xb7
     print_irq_inversion_bug.part.38+0x19f/0x1aa
     check_usage_forwards+0x102/0x120
     ? ret_from_fork+0x3a/0x50
     ? check_usage_backwards+0x110/0x110
     mark_lock+0x16c/0x270
     __lock_acquire+0x264/0x11c0
     ? pagevec_lookup_entries+0x1a/0x30
     ? truncate_inode_pages_range+0x2b3/0x7f0
     lock_acquire+0xbd/0x1e0
     ? __btrfs_release_delayed_node+0x3a/0x1f0 [btrfs]
     __mutex_lock+0x4e/0x8c0
     ? __btrfs_release_delayed_node+0x3a/0x1f0 [btrfs]
     ? __btrfs_release_delayed_node+0x3a/0x1f0 [btrfs]
     ? btrfs_evict_inode+0x1f6/0x6a0 [btrfs]
     __btrfs_release_delayed_node+0x3a/0x1f0 [btrfs]
     btrfs_evict_inode+0x22c/0x6a0 [btrfs]
     evict+0xc4/0x190
     dispose_list+0x35/0x50
     prune_icache_sb+0x42/0x50
     super_cache_scan+0x139/0x190
     shrink_slab+0x262/0x5b0
     shrink_node+0x2eb/0x2f0
     kswapd+0x2eb/0x890
     kthread+0x102/0x140
     ? mem_cgroup_shrink_node+0x2c0/0x2c0
     ? kthread_create_on_node+0x40/0x40
     ret_from_fork+0x3a/0x50
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Liu Bo <bo.liu@linux.alibaba.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 04834cb65272..1657d6aa4fa6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1095,7 +1095,7 @@ static struct btrfs_subvolume_writers *btrfs_alloc_subvolume_writers(void)
 	if (!writers)
 		return ERR_PTR(-ENOMEM);
 
-	ret = percpu_counter_init(&writers->counter, 0, GFP_KERNEL);
+	ret = percpu_counter_init(&writers->counter, 0, GFP_NOFS);
 	if (ret < 0) {
 		kfree(writers);
 		return ERR_PTR(ret);

commit 338dae1ae64f413bc058d0f2e964480add5ddacc
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Mar 15 14:36:26 2018 +0200

    btrfs: remove max_active var from open_ctree
    
    Introduced by 5cdc7ad337fb ("btrfs: Replace fs_info->workers with
    btrfs_workqueue.") but obsoleted by 2a4581983f90 ("btrfs: factor
    btrfs_init_workqueues() out of open_ctree()").
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b203982d66bc..04834cb65272 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2389,7 +2389,6 @@ int open_ctree(struct super_block *sb,
 	int err = -EINVAL;
 	int num_backups_tried = 0;
 	int backup_index = 0;
-	u32 max_active;
 	int clear_free_space_tree = 0;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
@@ -2698,8 +2697,6 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
-	max_active = fs_info->thread_pool_size;
-
 	ret = btrfs_init_workqueues(fs_info, fs_devices);
 	if (ret) {
 		err = ret;

commit 776c4a7ce86f4c95d9fc6307d44a4e9e1a740e40
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Mar 13 10:26:06 2018 +0200

    btrfs: Use sizeof directly instead of a constant variable
    
    The kernel would like to have all stack VLA usage removed[1].
    Unfortunately using an integer constant variable as the size of an
    array is still considered a VLA. Instead let's use directly sizeof(var)
    which removes the VLA usage. Use the occasion to remove csum_size
    altogether and use sizeof() also for the size passed to memcmp
    
    [1]: https://lkml.org/lkml/2018/3/7/621
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 156116655a32..b203982d66bc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -403,8 +403,7 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 
 	if (csum_type == BTRFS_CSUM_TYPE_CRC32) {
 		u32 crc = ~(u32)0;
-		const int csum_size = sizeof(crc);
-		char result[csum_size];
+		char result[sizeof(crc)];
 
 		/*
 		 * The super_block structure does not span the whole
@@ -415,7 +414,7 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
 				crc, BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
 		btrfs_csum_final(crc, result);
 
-		if (memcmp(raw_disk_sb, result, csum_size))
+		if (memcmp(raw_disk_sb, result, sizeof(result)))
 			ret = 1;
 	}
 

commit d0ee39349311ce823c36ece7fa066827ab8eb7af
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 8 14:35:48 2018 +0100

    btrfs: rename submit callbacks and drop double underscores
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7cec8a003838..156116655a32 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -797,7 +797,7 @@ static blk_status_t btree_csum_one_bio(struct bio *bio)
 	return errno_to_blk_status(ret);
 }
 
-static blk_status_t __btree_submit_bio_start(void *private_data, struct bio *bio,
+static blk_status_t btree_submit_bio_start(void *private_data, struct bio *bio,
 					     u64 bio_offset)
 {
 	/*
@@ -807,7 +807,7 @@ static blk_status_t __btree_submit_bio_start(void *private_data, struct bio *bio
 	return btree_csum_one_bio(bio);
 }
 
-static blk_status_t __btree_submit_bio_done(void *private_data, struct bio *bio,
+static blk_status_t btree_submit_bio_done(void *private_data, struct bio *bio,
 					    int mirror_num)
 {
 	struct inode *inode = private_data;
@@ -867,8 +867,8 @@ static blk_status_t btree_submit_bio_hook(void *private_data, struct bio *bio,
 		 */
 		ret = btrfs_wq_submit_bio(fs_info, bio, mirror_num, 0,
 					  bio_offset, private_data,
-					  __btree_submit_bio_start,
-					  __btree_submit_bio_done);
+					  btree_submit_bio_start,
+					  btree_submit_bio_done);
 	}
 
 	if (ret)

commit 6c553435870bf351c594437b4ba8babbdb0bb37e
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 8 13:47:33 2018 +0100

    btrfs: remove unused parameters from extent_submit_bio_done_t
    
    Remove parameters not used by any of the callbacks.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6fe5a959d56b..7cec8a003838 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -735,8 +735,7 @@ static void run_one_async_done(struct btrfs_work *work)
 		return;
 	}
 
-	async->submit_bio_done(async->private_data, async->bio, async->mirror_num,
-			       async->bio_flags, async->bio_offset);
+	async->submit_bio_done(async->private_data, async->bio, async->mirror_num);
 }
 
 static void run_one_async_free(struct btrfs_work *work)
@@ -809,8 +808,7 @@ static blk_status_t __btree_submit_bio_start(void *private_data, struct bio *bio
 }
 
 static blk_status_t __btree_submit_bio_done(void *private_data, struct bio *bio,
-					    int mirror_num, unsigned long bio_flags,
-					    u64 bio_offset)
+					    int mirror_num)
 {
 	struct inode *inode = private_data;
 	blk_status_t ret;

commit d0779291b1e9666aa4aac46ffd8062e3c3b0f2ab
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 8 13:47:33 2018 +0100

    btrfs: remove unused parameters from extent_submit_bio_start_t
    
    Remove parameters not used by any of the callbacks.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ee5d29a0219f..6fe5a959d56b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -717,7 +717,6 @@ static void run_one_async_start(struct btrfs_work *work)
 
 	async = container_of(work, struct  async_submit_bio, work);
 	ret = async->submit_bio_start(async->private_data, async->bio,
-				      async->mirror_num, async->bio_flags,
 				      async->bio_offset);
 	if (ret)
 		async->status = ret;
@@ -800,7 +799,6 @@ static blk_status_t btree_csum_one_bio(struct bio *bio)
 }
 
 static blk_status_t __btree_submit_bio_start(void *private_data, struct bio *bio,
-					     int mirror_num, unsigned long bio_flags,
 					     u64 bio_offset)
 {
 	/*

commit a758781d4b76c38374f155e2f2cf902e13b9e50e
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 23 03:05:23 2017 +0200

    btrfs: separate types for submit_bio_start and submit_bio_done
    
    The callbacks make use of different parameters that are passed to the
    other type unnecessarily. This patch adds separate types for each and
    the unused parameters will be removed.
    
    The type extent_submit_bio_hook_t keeps all parameters and can be used
    where the start/done types are not appropriate.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bbbcbf87ac93..ee5d29a0219f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -124,8 +124,8 @@ struct async_submit_bio {
 	void *private_data;
 	struct btrfs_fs_info *fs_info;
 	struct bio *bio;
-	extent_submit_bio_hook_t *submit_bio_start;
-	extent_submit_bio_hook_t *submit_bio_done;
+	extent_submit_bio_start_t *submit_bio_start;
+	extent_submit_bio_done_t *submit_bio_done;
 	int mirror_num;
 	unsigned long bio_flags;
 	/*
@@ -751,8 +751,8 @@ static void run_one_async_free(struct btrfs_work *work)
 blk_status_t btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset, void *private_data,
-				 extent_submit_bio_hook_t *submit_bio_start,
-				 extent_submit_bio_hook_t *submit_bio_done)
+				 extent_submit_bio_start_t *submit_bio_start,
+				 extent_submit_bio_done_t *submit_bio_done)
 {
 	struct async_submit_bio *async;
 

commit 9b99b11564446600f3a3ce394a841d525b7993e7
Author: Anand Jain <anand.jain@oracle.com>
Date:   Tue Feb 27 12:41:59 2018 +0800

    btrfs: rename btrfs_close_extra_device to btrfs_free_extra_devids
    
    This function btrfs_close_extra_devices() is about freeing
    extra devids which once it may have belonged to this filesystem.
    So rename it and add the comment. The _devid suffix is
    appropriate as this function won't handle devices which are
    outside of the filesytem being mounted.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 798e602c1834..bbbcbf87ac93 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2758,10 +2758,10 @@ int open_ctree(struct super_block *sb,
 	}
 
 	/*
-	 * keep the device that is marked to be the target device for the
-	 * dev_replace procedure
+	 * Keep the devid that is marked to be the target device for the
+	 * device replace procedure
 	 */
-	btrfs_close_extra_devices(fs_devices, 0);
+	btrfs_free_extra_devids(fs_devices, 0);
 
 	if (!fs_devices->latest_bdev) {
 		btrfs_err(fs_info, "failed to read devices");
@@ -2824,7 +2824,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_block_groups;
 	}
 
-	btrfs_close_extra_devices(fs_devices, 1);
+	btrfs_free_extra_devids(fs_devices, 1);
 
 	ret = btrfs_sysfs_add_fsid(fs_devices, NULL);
 	if (ret) {

commit e67c718b5b9a306bde7e966be7b4ca48fa063d73
Author: David Sterba <dsterba@suse.com>
Date:   Mon Feb 19 17:24:18 2018 +0100

    btrfs: add more __cold annotations
    
    The __cold functions are placed to a special section, as they're
    expected to be called rarely. This could help i-cache prefetches or help
    compiler to decide which branches are more/less likely to be taken
    without any other annotations needed.
    
    Though we can't add more __exit annotations, it's still possible to add
    __cold (that's also added with __exit). That way the following function
    categories are tagged:
    
    - printf wrappers, error messages
    - exit helpers
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c10c84640eee..798e602c1834 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -110,7 +110,7 @@ int __init btrfs_end_io_wq_init(void)
 	return 0;
 }
 
-void btrfs_end_io_wq_exit(void)
+void __cold btrfs_end_io_wq_exit(void)
 {
 	kmem_cache_destroy(btrfs_end_io_wq_cache);
 }

commit 9678c54388b6a6b309ff7ee5c8d23fa9eba7c06f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 8 11:45:05 2018 +0200

    btrfs: Remove custom crc32c init code
    
    The custom crc32 init code was introduced in
    14a958e678cd ("Btrfs: fix btrfs boot when compiled as built-in") to
    enable using btrfs as a built-in. However, later as pointed out by
    60efa5eb2e88 ("Btrfs: use late_initcall instead of module_init") this
    wasn't enough and finally btrfs was switched to late_initcall which
    comes after the generic crc32c implementation is initiliased. The
    latter commit superseeded the former. Now that we don't have to
    maintain our own code let's just remove it and switch to using the
    generic implementation.
    
    Despite touching a lot of files the patch is really simple. Here is the gist of
    the changes:
    
    1. Select LIBCRC32C rather than the low-level modules.
    2. s/btrfs_crc32c/crc32c/g
    3. replace hash.h with linux/crc32c.h
    4. Move the btrfs namehash funcs to ctree.h and change the tree accordingly.
    
    I've tested this with btrfs being both a module and a built-in and xfstest
    doesn't complain.
    
    Does seem to fix the longstanding problem of not automatically selectiong
    the crc32c module when btrfs is used. Possibly there is a workaround in
    dracut.
    
    The modinfo confirms that now all the module dependencies are there:
    
    before:
    depends:        zstd_compress,zstd_decompress,raid6_pq,xor,zlib_deflate
    
    after:
    depends:        libcrc32c,zstd_compress,zstd_decompress,raid6_pq,xor,zlib_deflate
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add more info to changelog from mails ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9d2c932b012e..c10c84640eee 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -31,10 +31,10 @@
 #include <linux/uuid.h>
 #include <linux/semaphore.h>
 #include <linux/error-injection.h>
+#include <linux/crc32c.h>
 #include <asm/unaligned.h>
 #include "ctree.h"
 #include "disk-io.h"
-#include "hash.h"
 #include "transaction.h"
 #include "btrfs_inode.h"
 #include "volumes.h"
@@ -270,7 +270,7 @@ struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 
 u32 btrfs_csum_data(const char *data, u32 seed, size_t len)
 {
-	return btrfs_crc32c(seed, data, len);
+	return crc32c(seed, data, len);
 }
 
 void btrfs_csum_final(u32 crc, u8 *result)

commit 2f659546c9048931c2b8e146824a892b74a8e33c
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Jan 25 14:56:18 2018 +0800

    btrfs: tree-checker: Replace root parameter with fs_info
    
    When inspecting the error message with real corruption, the "root=%llu"
    always shows "1" (root tree), instead of the correct owner.
    
    The problem is that we are getting @root from page->mapping->host, which
    points the same btree inode, so we will always get the same root.
    
    This makes the root owner output meaningless, and harder to port
    tree-checker to btrfs-progs.
    
    So get rid of the false and meaningless @root parameter and replace it
    with @fs_info.
    To get the owner, we can only rely on btrfs_header_owner() now.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fa80de56340f..9d2c932b012e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -602,12 +602,12 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	 * that we don't try and read the other copies of this block, just
 	 * return -EIO.
 	 */
-	if (found_level == 0 && btrfs_check_leaf_full(root, eb)) {
+	if (found_level == 0 && btrfs_check_leaf_full(fs_info, eb)) {
 		set_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 		ret = -EIO;
 	}
 
-	if (found_level > 0 && btrfs_check_node(root, eb))
+	if (found_level > 0 && btrfs_check_node(fs_info, eb))
 		ret = -EIO;
 
 	if (!ret)
@@ -3854,7 +3854,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	 * So here we should only check item pointers, not item data.
 	 */
 	if (btrfs_header_level(buf) == 0 &&
-	    btrfs_check_leaf_relaxed(root, buf)) {
+	    btrfs_check_leaf_relaxed(fs_info, buf)) {
 		btrfs_print_leaf(buf);
 		ASSERT(0);
 	}

commit bc5511d0eda1c2534aa3cedb485eae1fc354f2dc
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Jan 23 14:46:53 2018 +0200

    btrfs: Use schedule_timeout_interruptible
    
    Instead of manually fiddling with the state of the task
    (RUNNING->INTERRUPTIBLE->RUNNING) again just use schedule_timeout_interruptible
    which adjusts the task state as needed. No functional changes.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b23961a4af52..fa80de56340f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1800,12 +1800,10 @@ static int transaction_kthread(void *arg)
 		if (unlikely(test_bit(BTRFS_FS_STATE_ERROR,
 				      &fs_info->fs_state)))
 			btrfs_cleanup_transaction(fs_info);
-		set_current_state(TASK_INTERRUPTIBLE);
 		if (!kthread_should_stop() &&
 				(!btrfs_transaction_blocked(fs_info) ||
 				 cannot_commit))
-			schedule_timeout(delay);
-		__set_current_state(TASK_RUNNING);
+			schedule_timeout_interruptible(delay);
 	} while (!kthread_should_stop());
 	return 0;
 }

commit 2afb9653bf56a32ac4955527357428a8c4fdd5b8
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Feb 15 11:36:07 2018 +0800

    btrfs: remove unused function btrfs_async_submit_limit()
    
    Commit [1] removed the need to use btrfs_async_submit_limit(), so
    delete it.
    
    [1]
     commit 736cd52e0c720103f52ab9da47b6cc3af6b083f6
      Btrfs: remove nr_async_submits and async_submit_draining
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 08e33f316a86..b23961a4af52 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -710,14 +710,6 @@ blk_status_t btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 	return 0;
 }
 
-unsigned long btrfs_async_submit_limit(struct btrfs_fs_info *info)
-{
-	unsigned long limit = min_t(unsigned long,
-				    info->thread_pool_size,
-				    info->fs_devices->open_devices);
-	return 256 * limit;
-}
-
 static void run_one_async_start(struct btrfs_work *work)
 {
 	struct async_submit_bio *async;

commit 45ae2c1841c31c90077cf427c09ea0e83e381026
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Feb 8 18:25:18 2018 +0200

    btrfs: Document consistency of transaction->io_bgs list
    
    The reason why io_bgs can be modified without holding any lock is
    non-obvious. Document it and reference that documentation from the
    respective call sites.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dcfdb1f17f1b..08e33f316a86 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4346,6 +4346,10 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 	}
 	spin_unlock(&cur_trans->dirty_bgs_lock);
 
+	/*
+	 * Refer to the definition of io_bgs member for details why it's safe
+	 * to use it without any locking
+	 */
 	while (!list_empty(&cur_trans->io_bgs)) {
 		cache = list_first_entry(&cur_trans->io_bgs,
 					 struct btrfs_block_group_cache,

commit bf6d7d4900c0d0c15dcd1baa1b65e6519bf4abef
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Feb 8 18:25:17 2018 +0200

    btrfs: Remove invalid null checks from btrfs_cleanup_dirty_bgs
    
    list_first_entry is essentially a wrapper over cotnainer_of. The latter
    can never return null even if it's working on inconsistent list since it
    will either crash or return some offset in the wrong struct.
    Additionally, for the dirty_bgs list the iteration is done under
    dirty_bgs_lock which ensures consistency of the list.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 47624407bb94..dcfdb1f17f1b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4327,11 +4327,6 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 		cache = list_first_entry(&cur_trans->dirty_bgs,
 					 struct btrfs_block_group_cache,
 					 dirty_list);
-		if (!cache) {
-			btrfs_err(fs_info, "orphan block group dirty_bgs list");
-			spin_unlock(&cur_trans->dirty_bgs_lock);
-			return;
-		}
 
 		if (!list_empty(&cache->io_list)) {
 			spin_unlock(&cur_trans->dirty_bgs_lock);
@@ -4355,10 +4350,6 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 		cache = list_first_entry(&cur_trans->io_bgs,
 					 struct btrfs_block_group_cache,
 					 io_list);
-		if (!cache) {
-			btrfs_err(fs_info, "orphan block group on io_bgs list");
-			return;
-		}
 
 		list_del_init(&cache->io_list);
 		spin_lock(&cache->lock);

commit f7b885befd05fa4f546cdc3e6c9a3b4a30484cd1
Author: Anand Jain <anand.jain@oracle.com>
Date:   Tue Feb 13 17:50:42 2018 +0800

    btrfs: manage thread_pool mount option as %u
    
    The mount option thread_pool is always unsigned. Manage it that way all
    around.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9f7ed4390b33..47624407bb94 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2183,7 +2183,7 @@ static void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)
 static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 		struct btrfs_fs_devices *fs_devices)
 {
-	int max_active = fs_info->thread_pool_size;
+	u32 max_active = fs_info->thread_pool_size;
 	unsigned int flags = WQ_MEM_RECLAIM | WQ_FREEZABLE | WQ_UNBOUND;
 
 	fs_info->workers =
@@ -2404,7 +2404,7 @@ int open_ctree(struct super_block *sb,
 	int err = -EINVAL;
 	int num_backups_tried = 0;
 	int backup_index = 0;
-	int max_active;
+	u32 max_active;
 	int clear_free_space_tree = 0;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);

commit b6a535faed06c2bdfaf55b00025dfdcb1eadf980
Author: Howard McLauchlan <hmclauchlan@fb.com>
Date:   Fri Feb 2 11:09:01 2018 -0800

    btrfs: print error if primary super block write fails
    
    Presently, failing a primary super block write but succeeding in at
    least one super block write in general will appear to users as if
    nothing important went wrong. However, upon unmounting and re-mounting,
    the file system will be in a rolled back state. This was discovered
    with a BCC program that uses bpf_override_return() to fail super block
    writes.
    
    This patch outputs an error clarifying that the primary super block
    write has failed, so users can expect potentially erroneous behaviour.
    It also forces wait_dev_supers() to return an error to its caller if
    the primary super block write fails.
    
    Signed-off-by: Howard McLauchlan <hmclauchlan@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 21f34ad0d411..9f7ed4390b33 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3290,6 +3290,7 @@ static int wait_dev_supers(struct btrfs_device *device, int max_mirrors)
 	struct buffer_head *bh;
 	int i;
 	int errors = 0;
+	bool primary_failed = false;
 	u64 bytenr;
 
 	if (max_mirrors == 0)
@@ -3306,11 +3307,16 @@ static int wait_dev_supers(struct btrfs_device *device, int max_mirrors)
 				      BTRFS_SUPER_INFO_SIZE);
 		if (!bh) {
 			errors++;
+			if (i == 0)
+				primary_failed = true;
 			continue;
 		}
 		wait_on_buffer(bh);
-		if (!buffer_uptodate(bh))
+		if (!buffer_uptodate(bh)) {
 			errors++;
+			if (i == 0)
+				primary_failed = true;
+		}
 
 		/* drop our reference */
 		brelse(bh);
@@ -3319,6 +3325,13 @@ static int wait_dev_supers(struct btrfs_device *device, int max_mirrors)
 		brelse(bh);
 	}
 
+	/* log error, force error return */
+	if (primary_failed) {
+		btrfs_err(device->fs_info, "error writing primary super block to device %llu",
+			  device->devid);
+		return -1;
+	}
+
 	return errors < i ? 0 : -1;
 }
 

commit b2fe5fa68642860e7de76167c3111623aa0d5de1
Merge: a103950e0dd2 a54667f6728c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 31 14:31:10 2018 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
    
     1) Significantly shrink the core networking routing structures. Result
        of http://vger.kernel.org/~davem/seoul2017_netdev_keynote.pdf
    
     2) Add netdevsim driver for testing various offloads, from Jakub
        Kicinski.
    
     3) Support cross-chip FDB operations in DSA, from Vivien Didelot.
    
     4) Add a 2nd listener hash table for TCP, similar to what was done for
        UDP. From Martin KaFai Lau.
    
     5) Add eBPF based queue selection to tun, from Jason Wang.
    
     6) Lockless qdisc support, from John Fastabend.
    
     7) SCTP stream interleave support, from Xin Long.
    
     8) Smoother TCP receive autotuning, from Eric Dumazet.
    
     9) Lots of erspan tunneling enhancements, from William Tu.
    
    10) Add true function call support to BPF, from Alexei Starovoitov.
    
    11) Add explicit support for GRO HW offloading, from Michael Chan.
    
    12) Support extack generation in more netlink subsystems. From Alexander
        Aring, Quentin Monnet, and Jakub Kicinski.
    
    13) Add 1000BaseX, flow control, and EEE support to mvneta driver. From
        Russell King.
    
    14) Add flow table abstraction to netfilter, from Pablo Neira Ayuso.
    
    15) Many improvements and simplifications to the NFP driver bpf JIT,
        from Jakub Kicinski.
    
    16) Support for ipv6 non-equal cost multipath routing, from Ido
        Schimmel.
    
    17) Add resource abstration to devlink, from Arkadi Sharshevsky.
    
    18) Packet scheduler classifier shared filter block support, from Jiri
        Pirko.
    
    19) Avoid locking in act_csum, from Davide Caratti.
    
    20) devinet_ioctl() simplifications from Al viro.
    
    21) More TCP bpf improvements from Lawrence Brakmo.
    
    22) Add support for onlink ipv6 route flag, similar to ipv4, from David
        Ahern.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1925 commits)
      tls: Add support for encryption using async offload accelerator
      ip6mr: fix stale iterator
      net/sched: kconfig: Remove blank help texts
      openvswitch: meter: Use 64-bit arithmetic instead of 32-bit
      tcp_nv: fix potential integer overflow in tcpnv_acked
      r8169: fix RTL8168EP take too long to complete driver initialization.
      qmi_wwan: Add support for Quectel EP06
      rtnetlink: enable IFLA_IF_NETNSID for RTM_NEWLINK
      ipmr: Fix ptrdiff_t print formatting
      ibmvnic: Wait for device response when changing MAC
      qlcnic: fix deadlock bug
      tcp: release sk_frag.page in tcp_disconnect
      ipv4: Get the address of interface correctly.
      net_sched: gen_estimator: fix lockdep splat
      net: macb: Handle HRESP error
      net/mlx5e: IPoIB, Fix copy-paste bug in flow steering refactoring
      ipv6: addrconf: break critical section in addrconf_verify_rtnl()
      ipv6: change route cache aging logic
      i40e/i40evf: Update DESC_NEEDED value to reflect larger value
      bnxt_en: cleanup DIM work on device shutdown
      ...

commit 6f794e3c5c8f8fdd3b5bb20d9ded894e685b5bbe
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Tue Jan 9 09:05:43 2018 +0800

    btrfs: fail mount when sb flag is not in BTRFS_SUPER_FLAG_SUPP
    
    It appears from the original commit [1] that there isn't any design
    specific reason not to fail the mount instead of just warning. This
    patch will change it to fail.
    
    [1]
     commit 319e4d0661e5323c9f9945f0f8fb5905e5fe74c3
        btrfs: Enhance super validation check
    
    Fixes: 319e4d0661e5323 ("btrfs: Enhance super validation check")
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1916016e9fbb..ed095202942f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3907,9 +3907,11 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)
 		btrfs_err(fs_info, "no valid FS found");
 		ret = -EINVAL;
 	}
-	if (btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP)
-		btrfs_warn(fs_info, "unrecognized super flag: %llu",
+	if (btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP) {
+		btrfs_err(fs_info, "unrecognized or unsupported super flag: %llu",
 				btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP);
+		ret = -EINVAL;
+	}
 	if (btrfs_super_root_level(sb) >= BTRFS_MAX_LEVEL) {
 		btrfs_err(fs_info, "tree_root level too big: %d >= %d",
 				btrfs_super_root_level(sb), BTRFS_MAX_LEVEL);

commit e2731e55884f2138a252b0a3d7b24d57e49c3c59
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Tue Jan 9 09:05:41 2018 +0800

    btrfs: define SUPER_FLAG_METADUMP_V2
    
    btrfs-progs uses super flag bit BTRFS_SUPER_FLAG_METADUMP_V2 (1ULL << 34).
    So just define that in kernel so that we know its been used.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 73ab44159d82..1916016e9fbb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -61,7 +61,8 @@
 				 BTRFS_HEADER_FLAG_RELOC |\
 				 BTRFS_SUPER_FLAG_ERROR |\
 				 BTRFS_SUPER_FLAG_SEEDING |\
-				 BTRFS_SUPER_FLAG_METADUMP)
+				 BTRFS_SUPER_FLAG_METADUMP |\
+				 BTRFS_SUPER_FLAG_METADUMP_V2)
 
 static const struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);

commit 6528b99d3d20795ff947d9b3fd736affe901acef
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Mon Dec 18 17:08:59 2017 +0800

    btrfs: factor btrfs_check_rw_degradable() to check given device
    
    Update btrfs_check_rw_degradable() to check against the given device if
    its lost.
    
    We can use this function to know if the volume is going to be in
    degraded mode OR failed state, when the given device fails.  Which is
    needed when we are handling the device failed state.
    
    A preparatory patch does not affect the flow as such.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    [ enhance comment ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 41d151b9ffd2..73ab44159d82 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2866,7 +2866,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_sysfs;
 	}
 
-	if (!sb_rdonly(sb) && !btrfs_check_rw_degradable(fs_info)) {
+	if (!sb_rdonly(sb) && !btrfs_check_rw_degradable(fs_info, NULL)) {
 		btrfs_warn(fs_info,
 		"writeable mount is not allowed due to too many missing devices");
 		goto fail_sysfs;
@@ -3369,7 +3369,7 @@ static blk_status_t wait_dev_flush(struct btrfs_device *device)
 
 static int check_barrier_error(struct btrfs_fs_info *fs_info)
 {
-	if (!btrfs_check_rw_degradable(fs_info))
+	if (!btrfs_check_rw_degradable(fs_info, NULL))
 		return -EIO;
 	return 0;
 }

commit e43bbe5e16d87b40f3b382b3a43b0142d6d1193d
Author: David Sterba <dsterba@suse.com>
Date:   Tue Dec 12 21:43:52 2017 +0100

    btrfs: sink unlock_extent parameter gfp_flags
    
    All callers pass either GFP_NOFS or GFP_KERNEL now, so we can sink the
    parameter to the function, though we lose some of the slightly better
    semantics of GFP_KERNEL in some places, it's worth cleaning up the
    callchains.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 392d6cde4308..41d151b9ffd2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -381,7 +381,7 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		clear_extent_buffer_uptodate(eb);
 out:
 	unlock_extent_cached(io_tree, eb->start, eb->start + eb->len - 1,
-			     &cached_state, GFP_NOFS);
+			     &cached_state);
 	if (need_lock)
 		btrfs_tree_read_unlock_blocking(eb);
 	return ret;

commit 1c3063b6dbfa03e469a53371fae149a022a41bfd
Author: Anand Jain <anand.jain@oracle.com>
Date:   Mon Dec 4 12:54:56 2017 +0800

    btrfs: cleanup device states define BTRFS_DEV_STATE_FLUSH_SENT
    
    Currently device state is being managed by each individual int
    variable such as struct btrfs_device::is_tgtdev_for_dev_replace.
    Instead of that declare btrfs_device::dev_state
    BTRFS_DEV_STATE_FLUSH_SENT and use the bit operations.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4f7d2a38865c..392d6cde4308 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3348,7 +3348,7 @@ static void write_dev_flush(struct btrfs_device *device)
 	bio->bi_private = &device->flush_wait;
 
 	btrfsic_submit_bio(bio);
-	device->flush_bio_sent = 1;
+	set_bit(BTRFS_DEV_STATE_FLUSH_SENT, &device->dev_state);
 }
 
 /*
@@ -3358,10 +3358,10 @@ static blk_status_t wait_dev_flush(struct btrfs_device *device)
 {
 	struct bio *bio = device->flush_bio;
 
-	if (!device->flush_bio_sent)
+	if (!test_bit(BTRFS_DEV_STATE_FLUSH_SENT, &device->dev_state))
 		return BLK_STS_OK;
 
-	device->flush_bio_sent = 0;
+	clear_bit(BTRFS_DEV_STATE_FLUSH_SENT, &device->dev_state);
 	wait_for_completion_io(&device->flush_wait);
 
 	return bio->bi_status;

commit e6e674bd4d54fe8d47a06914f3b90752785b4882
Author: Anand Jain <anand.jain@oracle.com>
Date:   Mon Dec 4 12:54:54 2017 +0800

    btrfs: cleanup device states define BTRFS_DEV_STATE_MISSING
    
    Currently device state is being managed by each individual int
    variable such as struct btrfs_device::missing. Instead of that
    declare btrfs_device::dev_state BTRFS_DEV_STATE_MISSING and use
    the bit operations.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by : Nikolay Borisov <nborisov@suse.com>
    [ whitespace adjustments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 44573cdda1fd..4f7d2a38865c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3389,7 +3389,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 	/* send down all the barriers */
 	head = &info->fs_devices->devices;
 	list_for_each_entry(dev, head, dev_list) {
-		if (dev->missing)
+		if (test_bit(BTRFS_DEV_STATE_MISSING, &dev->dev_state))
 			continue;
 		if (!dev->bdev)
 			continue;
@@ -3403,7 +3403,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 
 	/* wait for all the barriers */
 	list_for_each_entry(dev, head, dev_list) {
-		if (dev->missing)
+		if (test_bit(BTRFS_DEV_STATE_MISSING, &dev->dev_state))
 			continue;
 		if (!dev->bdev) {
 			errors_wait++;

commit e12c96214d28f9211b4035cf20e76d677ff5611f
Author: Anand Jain <anand.jain@oracle.com>
Date:   Mon Dec 4 12:54:53 2017 +0800

    btrfs: cleanup device states define BTRFS_DEV_STATE_IN_FS_METADATA
    
    Currently device state is being managed by each individual int
    variable such as struct btrfs_device::in_fs_metadata. Instead of
    that declare device state BTRFS_DEV_STATE_IN_FS_METADATA and use
    the bit operations.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    [ whitespace adjustments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 396f8183ee86..44573cdda1fd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3393,7 +3393,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 			continue;
 		if (!dev->bdev)
 			continue;
-		if (!dev->in_fs_metadata ||
+		if (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||
 		    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))
 			continue;
 
@@ -3409,7 +3409,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 			errors_wait++;
 			continue;
 		}
-		if (!dev->in_fs_metadata ||
+		if (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||
 		    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))
 			continue;
 
@@ -3507,7 +3507,7 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 			total_errors++;
 			continue;
 		}
-		if (!dev->in_fs_metadata ||
+		if (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||
 		    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))
 			continue;
 
@@ -3547,7 +3547,7 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 	list_for_each_entry(dev, head, dev_list) {
 		if (!dev->bdev)
 			continue;
-		if (!dev->in_fs_metadata ||
+		if (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||
 		    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))
 			continue;
 

commit ebbede42d47dc77d1c20e7468418826e5efa6b29
Author: Anand Jain <anand.jain@oracle.com>
Date:   Mon Dec 4 12:54:52 2017 +0800

    btrfs: cleanup device states define BTRFS_DEV_STATE_WRITEABLE
    
    Currently device state is being managed by each individual int
    variable such as struct btrfs_device::writeable. Instead of that
    declare device state BTRFS_DEV_STATE_WRITEABLE and use the
    bit operations.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    [ whitespace adjustments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5f9430063c50..396f8183ee86 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3393,7 +3393,8 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 			continue;
 		if (!dev->bdev)
 			continue;
-		if (!dev->in_fs_metadata || !dev->writeable)
+		if (!dev->in_fs_metadata ||
+		    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))
 			continue;
 
 		write_dev_flush(dev);
@@ -3408,7 +3409,8 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 			errors_wait++;
 			continue;
 		}
-		if (!dev->in_fs_metadata || !dev->writeable)
+		if (!dev->in_fs_metadata ||
+		    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))
 			continue;
 
 		ret = wait_dev_flush(dev);
@@ -3505,7 +3507,8 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 			total_errors++;
 			continue;
 		}
-		if (!dev->in_fs_metadata || !dev->writeable)
+		if (!dev->in_fs_metadata ||
+		    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))
 			continue;
 
 		btrfs_set_stack_device_generation(dev_item, 0);
@@ -3544,7 +3547,8 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 	list_for_each_entry(dev, head, dev_list) {
 		if (!dev->bdev)
 			continue;
-		if (!dev->in_fs_metadata || !dev->writeable)
+		if (!dev->in_fs_metadata ||
+		    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))
 			continue;
 
 		ret = wait_dev_supers(dev, max_mirrors);

commit 71a635516ca521931be418827150f782b0a03ae7
Author: David Sterba <dsterba@suse.com>
Date:   Mon Nov 6 19:23:00 2017 +0100

    btrfs: switch to on-stack csum buffer in csum_tree_block
    
    The maximum size of a checksum buffer is known, BTRFS_CSUM_SIZE, and we
    don't have to allocate it dynamically. This code path is not used at all
    as we have only the crc32c and use an on-stack buffer already.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cbf37df05a88..5f9430063c50 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -285,7 +285,7 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 			   int verify)
 {
 	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
-	char *result = NULL;
+	char result[BTRFS_CSUM_SIZE];
 	unsigned long len;
 	unsigned long cur_len;
 	unsigned long offset = BTRFS_CSUM_SIZE;
@@ -294,7 +294,6 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 	unsigned long map_len;
 	int err;
 	u32 crc = ~(u32)0;
-	unsigned long inline_result;
 
 	len = buf->len - offset;
 	while (len > 0) {
@@ -308,13 +307,7 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 		len -= cur_len;
 		offset += cur_len;
 	}
-	if (csum_size > sizeof(inline_result)) {
-		result = kzalloc(csum_size, GFP_NOFS);
-		if (!result)
-			return -ENOMEM;
-	} else {
-		result = (char *)&inline_result;
-	}
+	memset(result, 0, BTRFS_CSUM_SIZE);
 
 	btrfs_csum_final(crc, result);
 
@@ -329,15 +322,12 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 				"%s checksum verify failed on %llu wanted %X found %X level %d",
 				fs_info->sb->s_id, buf->start,
 				val, found, btrfs_header_level(buf));
-			if (result != (char *)&inline_result)
-				kfree(result);
 			return -EUCLEAN;
 		}
 	} else {
 		write_extent_buffer(buf, result, 0, csum_size);
 	}
-	if (result != (char *)&inline_result)
-		kfree(result);
+
 	return 0;
 }
 

commit 6af49dbde9532c95f53d2c45fe9cc0012226c5e7
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 23 04:09:57 2017 +0200

    btrfs: sink get_extent parameter to read_extent_buffer_pages
    
    All callers pass btree_get_extent, which needs to be exported.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 06c593775b82..cbf37df05a88 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -220,7 +220,7 @@ void btrfs_set_buffer_lockdep_class(u64 objectid, struct extent_buffer *eb,
  * extents on the btree inode are pretty simple, there's one extent
  * that covers the entire device
  */
-static struct extent_map *btree_get_extent(struct btrfs_inode *inode,
+struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 		struct page *page, size_t pg_offset, u64 start, u64 len,
 		int create)
 {
@@ -455,7 +455,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 	io_tree = &BTRFS_I(fs_info->btree_inode)->io_tree;
 	while (1) {
 		ret = read_extent_buffer_pages(io_tree, eb, WAIT_COMPLETE,
-					       btree_get_extent, mirror_num);
+					       mirror_num);
 		if (!ret) {
 			if (!verify_parent_transid(io_tree, eb,
 						   parent_transid, 0))
@@ -1012,7 +1012,7 @@ void readahead_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr)
 	if (IS_ERR(buf))
 		return;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
-				 buf, WAIT_NONE, btree_get_extent, 0);
+				 buf, WAIT_NONE, 0);
 	free_extent_buffer(buf);
 }
 
@@ -1031,7 +1031,7 @@ int reada_tree_block_flagged(struct btrfs_fs_info *fs_info, u64 bytenr,
 	set_bit(EXTENT_BUFFER_READAHEAD, &buf->bflags);
 
 	ret = read_extent_buffer_pages(io_tree, buf, WAIT_PAGE_LOCK,
-				       btree_get_extent, mirror_num);
+				       mirror_num);
 	if (ret) {
 		free_extent_buffer(buf);
 		return ret;

commit 1538e6c52e19175a5f4da48eb88e059d5d12d7a0
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 16 00:28:47 2017 +0200

    btrfs: use non-RCU list traversal in write_all_supers callees
    
    We take the fs_devices::device_list_mutex mutex in write_all_supers
    which will prevent any add/del changes to the device list. Therefore we
    don't need to use the RCU variant list_for_each_entry_rcu in any of the
    called functions.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ec9aa34bb6eb..06c593775b82 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3395,9 +3395,10 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 	int errors_wait = 0;
 	blk_status_t ret;
 
+	lockdep_assert_held(&info->fs_devices->device_list_mutex);
 	/* send down all the barriers */
 	head = &info->fs_devices->devices;
-	list_for_each_entry_rcu(dev, head, dev_list) {
+	list_for_each_entry(dev, head, dev_list) {
 		if (dev->missing)
 			continue;
 		if (!dev->bdev)
@@ -3410,7 +3411,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 	}
 
 	/* wait for all the barriers */
-	list_for_each_entry_rcu(dev, head, dev_list) {
+	list_for_each_entry(dev, head, dev_list) {
 		if (dev->missing)
 			continue;
 		if (!dev->bdev) {
@@ -3509,7 +3510,7 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 		}
 	}
 
-	list_for_each_entry_rcu(dev, head, dev_list) {
+	list_for_each_entry(dev, head, dev_list) {
 		if (!dev->bdev) {
 			total_errors++;
 			continue;
@@ -3550,7 +3551,7 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 	}
 
 	total_errors = 0;
-	list_for_each_entry_rcu(dev, head, dev_list) {
+	list_for_each_entry(dev, head, dev_list) {
 		if (!dev->bdev)
 			continue;
 		if (!dev->in_fs_metadata || !dev->writeable)

commit 33d85fda13ea2712bb9c9e687176798583d2359c
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Oct 31 14:08:16 2017 +0800

    btrfs: Don't generate UUID for non-fs tree
    
    btrfs_create_tree() will unconditionally generate UUID for any root.
    So for quota tree and data reloc tree created by kernel, they will have
    unique UUIDs.
    
    However UUID in root item is only referred by UUID tree, which only
    records UUID for fs trees.  This makes unique UUIDs for quota/data reloc
    tree meaningless.
    
    Leave the UUID as zero for non-fs tree, making btrfs-debug-tree output
    less confusing.
    
    Reported-by: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a8ecccfc36de..ec9aa34bb6eb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1243,7 +1243,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	struct btrfs_root *root;
 	struct btrfs_key key;
 	int ret = 0;
-	uuid_le uuid;
+	uuid_le uuid = NULL_UUID_LE;
 
 	root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	if (!root)
@@ -1284,7 +1284,8 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_root_used(&root->root_item, leaf->len);
 	btrfs_set_root_last_snapshot(&root->root_item, 0);
 	btrfs_set_root_dirid(&root->root_item, 0);
-	uuid_le_gen(&uuid);
+	if (is_fstree(objectid))
+		uuid_le_gen(&uuid);
 	memcpy(root->root_item.uuid, uuid.b, BTRFS_UUID_SIZE);
 	root->root_item.drop_level = 0;
 

commit 663faf9f7beeaca4ad0176bb96c776eed9dad0c5
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jan 13 02:55:33 2018 +0900

    error-injection: Add injectable error types
    
    Add injectable error types for each error-injectable function.
    
    One motivation of error injection test is to find software flaws,
    mistakes or mis-handlings of expectable errors. If we find such
    flaws by the test, that is a program bug, so we need to fix it.
    
    But if the tester miss input the error (e.g. just return success
    code without processing anything), it causes unexpected behavior
    even if the caller is correctly programmed to handle any errors.
    That is not what we want to test by error injection.
    
    To clarify what type of errors the caller must expect for each
    injectable function, this introduces injectable error types:
    
     - EI_ETYPE_NULL : means the function will return NULL if it
                        fails. No ERR_PTR, just a NULL.
     - EI_ETYPE_ERRNO : means the function will return -ERRNO
                        if it fails.
     - EI_ETYPE_ERRNO_NULL : means the function will return -ERRNO
                           (ERR_PTR) or NULL.
    
    ALLOW_ERROR_INJECTION() macro is expanded to get one of
    NULL, ERRNO, ERRNO_NULL to record the error type for
    each function. e.g.
    
     ALLOW_ERROR_INJECTION(open_ctree, ERRNO)
    
    This error types are shown in debugfs as below.
    
      ====
      / # cat /sys/kernel/debug/error_injection/list
      open_ctree [btrfs]    ERRNO
      io_ctl_init [btrfs]   ERRNO
      ====
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9798e21ebe9d..83e2349e1362 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3124,7 +3124,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_block_groups;
 	goto retry_root_backup;
 }
-ALLOW_ERROR_INJECTION(open_ctree);
+ALLOW_ERROR_INJECTION(open_ctree, ERRNO);
 
 static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 {

commit 540adea3809f61115d2a1ea4ed6e627613452ba1
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jan 13 02:55:03 2018 +0900

    error-injection: Separate error-injection from kprobe
    
    Since error-injection framework is not limited to be used
    by kprobes, nor bpf. Other kernel subsystems can use it
    freely for checking safeness of error-injection, e.g.
    livepatch, ftrace etc.
    So this separate error-injection framework from kprobes.
    
    Some differences has been made:
    
    - "kprobe" word is removed from any APIs/structures.
    - BPF_ALLOW_ERROR_INJECTION() is renamed to
      ALLOW_ERROR_INJECTION() since it is not limited for BPF too.
    - CONFIG_FUNCTION_ERROR_INJECTION is the config item of this
      feature. It is automatically enabled if the arch supports
      error injection feature for kprobe or ftrace etc.
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5da18ebc9222..9798e21ebe9d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -30,7 +30,7 @@
 #include <linux/ratelimit.h>
 #include <linux/uuid.h>
 #include <linux/semaphore.h>
-#include <linux/bpf.h>
+#include <linux/error-injection.h>
 #include <asm/unaligned.h>
 #include "ctree.h"
 #include "disk-io.h"
@@ -3124,7 +3124,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_block_groups;
 	goto retry_root_backup;
 }
-BPF_ALLOW_ERROR_INJECTION(open_ctree);
+ALLOW_ERROR_INJECTION(open_ctree);
 
 static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 {

commit 59436c9ee18d7faad0cd1875c9d8322668f98611
Merge: c30abd5e40dd 46df3d209db0
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Dec 18 10:51:06 2017 -0500

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next
    
    Daniel Borkmann says:
    
    ====================
    pull-request: bpf-next 2017-12-18
    
    The following pull-request contains BPF updates for your *net-next* tree.
    
    The main changes are:
    
    1) Allow arbitrary function calls from one BPF function to another BPF function.
       As of today when writing BPF programs, __always_inline had to be used in
       the BPF C programs for all functions, unnecessarily causing LLVM to inflate
       code size. Handle this more naturally with support for BPF to BPF calls
       such that this __always_inline restriction can be overcome. As a result,
       it allows for better optimized code and finally enables to introduce core
       BPF libraries in the future that can be reused out of different projects.
       x86 and arm64 JIT support was added as well, from Alexei.
    
    2) Add infrastructure for tagging functions as error injectable and allow for
       BPF to return arbitrary error values when BPF is attached via kprobes on
       those. This way of injecting errors generically eases testing and debugging
       without having to recompile or restart the kernel. Tags for opting-in for
       this facility are added with BPF_ALLOW_ERROR_INJECTION(), from Josef.
    
    3) For BPF offload via nfp JIT, add support for bpf_xdp_adjust_head() helper
       call for XDP programs. First part of this work adds handling of BPF
       capabilities included in the firmware, and the later patches add support
       to the nfp verifier part and JIT as well as some small optimizations,
       from Jakub.
    
    4) The bpftool now also gets support for basic cgroup BPF operations such
       as attaching, detaching and listing current BPF programs. As a requirement
       for the attach part, bpftool can now also load object files through
       'bpftool prog load'. This reuses libbpf which we have in the kernel tree
       as well. bpftool-cgroup man page is added along with it, from Roman.
    
    5) Back then commit e87c6bc3852b ("bpf: permit multiple bpf attachments for
       a single perf event") added support for attaching multiple BPF programs
       to a single perf event. Given they are configured through perf's ioctl()
       interface, the interface has been extended with a PERF_EVENT_IOC_QUERY_BPF
       command in this work in order to return an array of one or multiple BPF
       prog ids that are currently attached, from Yonghong.
    
    6) Various minor fixes and cleanups to the bpftool's Makefile as well
       as a new 'uninstall' and 'doc-uninstall' target for removing bpftool
       itself or prior installed documentation related to it, from Quentin.
    
    7) Add CONFIG_CGROUP_BPF=y to the BPF kernel selftest config file which is
       required for the test_dev_cgroup test case to run, from Naresh.
    
    8) Fix reporting of XDP prog_flags for nfp driver, from Jakub.
    
    9) Fix libbpf's exit code from the Makefile when libelf was not found in
       the system, also from Jakub.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 8556e50994c8a8f5282fea008ae084d6d080648a
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Dec 11 11:36:47 2017 -0500

    btrfs: make open_ctree error injectable
    
    This allows us to do error injection with BPF for open_ctree.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 10a2a579cc7f..02b5f5667754 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -30,6 +30,7 @@
 #include <linux/ratelimit.h>
 #include <linux/uuid.h>
 #include <linux/semaphore.h>
+#include <linux/bpf.h>
 #include <asm/unaligned.h>
 #include "ctree.h"
 #include "disk-io.h"
@@ -3123,6 +3124,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_block_groups;
 	goto retry_root_backup;
 }
+BPF_ALLOW_ERROR_INJECTION(open_ctree);
 
 static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 {

commit 1b9e619c5bc8235cfba3dc4ced2fb0e3554a05d4
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Dec 5 22:54:02 2017 -0800

    Btrfs: disable FUA if mounted with nobarrier
    
    I was seeing disk flushes still happening when I mounted a Btrfs
    filesystem with nobarrier for testing. This is because we use FUA to
    write out the first super block, and on devices without FUA support, the
    block layer translates FUA to a flush. Even on devices supporting true
    FUA, using FUA when we asked for no barriers is surprising.
    
    Fixes: 387125fc722a8ed ("Btrfs: fix barrier flushes")
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 10a2a579cc7f..a8ecccfc36de 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3231,6 +3231,7 @@ static int write_dev_supers(struct btrfs_device *device,
 	int errors = 0;
 	u32 crc;
 	u64 bytenr;
+	int op_flags;
 
 	if (max_mirrors == 0)
 		max_mirrors = BTRFS_SUPER_MIRROR_MAX;
@@ -3273,13 +3274,10 @@ static int write_dev_supers(struct btrfs_device *device,
 		 * we fua the first super.  The others we allow
 		 * to go down lazy.
 		 */
-		if (i == 0) {
-			ret = btrfsic_submit_bh(REQ_OP_WRITE,
-				REQ_SYNC | REQ_FUA | REQ_META | REQ_PRIO, bh);
-		} else {
-			ret = btrfsic_submit_bh(REQ_OP_WRITE,
-				REQ_SYNC | REQ_META | REQ_PRIO, bh);
-		}
+		op_flags = REQ_SYNC | REQ_META | REQ_PRIO;
+		if (i == 0 && !btrfs_test_opt(device->fs_info, NOBARRIER))
+			op_flags |= REQ_FUA;
+		ret = btrfsic_submit_bh(REQ_OP_WRITE, op_flags, bh);
 		if (ret)
 			errors++;
 	}

commit 69fc6cbbac542c349b3d350d10f6e394c253c81d
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Nov 8 08:54:24 2017 +0800

    btrfs: tree-checker: Fix false panic for sanity test
    
    [BUG]
    If we run btrfs with CONFIG_BTRFS_FS_RUN_SANITY_TESTS=y, it will
    instantly cause kernel panic like:
    
    ------
    ...
    assertion failed: 0, file: fs/btrfs/disk-io.c, line: 3853
    ...
    Call Trace:
     btrfs_mark_buffer_dirty+0x187/0x1f0 [btrfs]
     setup_items_for_insert+0x385/0x650 [btrfs]
     __btrfs_drop_extents+0x129a/0x1870 [btrfs]
    ...
    -----
    
    [Cause]
    Btrfs will call btrfs_check_leaf() in btrfs_mark_buffer_dirty() to check
    if the leaf is valid with CONFIG_BTRFS_FS_RUN_SANITY_TESTS=y.
    
    However quite some btrfs_mark_buffer_dirty() callers(*) don't really
    initialize its item data but only initialize its item pointers, leaving
    item data uninitialized.
    
    This makes tree-checker catch uninitialized data as error, causing
    such panic.
    
    *: These callers include but not limited to
    setup_items_for_insert()
    btrfs_split_item()
    btrfs_expand_item()
    
    [Fix]
    Add a new parameter @check_item_data to btrfs_check_leaf().
    With @check_item_data set to false, item data check will be skipped and
    fallback to old btrfs_check_leaf() behavior.
    
    So we can still get early warning if we screw up item pointers, and
    avoid false panic.
    
    Cc: Filipe Manana <fdmanana@gmail.com>
    Reported-by: Lakshmipathi.G <lakshmipathi.g@gmail.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index efce9a2fa9be..10a2a579cc7f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -610,7 +610,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	 * that we don't try and read the other copies of this block, just
 	 * return -EIO.
 	 */
-	if (found_level == 0 && btrfs_check_leaf(root, eb)) {
+	if (found_level == 0 && btrfs_check_leaf_full(root, eb)) {
 		set_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 		ret = -EIO;
 	}
@@ -3848,7 +3848,13 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 					 buf->len,
 					 fs_info->dirty_metadata_batch);
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
-	if (btrfs_header_level(buf) == 0 && btrfs_check_leaf(root, buf)) {
+	/*
+	 * Since btrfs_mark_buffer_dirty() can be called with item pointer set
+	 * but item data not updated.
+	 * So here we should only check item pointers, not item data.
+	 */
+	if (btrfs_header_level(buf) == 0 &&
+	    btrfs_check_leaf_relaxed(root, buf)) {
 		btrfs_print_leaf(buf);
 		ASSERT(0);
 	}

commit 0e0adbcfdc908684317c99a9bf5e13383f03b7ec
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Oct 19 14:16:00 2017 -0400

    btrfs: track refs in a rb_tree instead of a list
    
    If we get a significant amount of delayed refs for a single block (think
    modifying multiple snapshots) we can end up spending an ungodly amount
    of time looping through all of the entries trying to see if they can be
    merged.  This is because we only add them to a list, so we have O(2n)
    for every ref head.  This doesn't make any sense as we likely have refs
    for different roots, and so they cannot be merged.  Tracking in a tree
    will allow us to break as soon as we hit an entry that doesn't match,
    making our worst case O(n).
    
    With this we can also merge entries more easily.  Before we had to hope
    that matching refs were on the ends of our list, but with the tree we
    can search down to exact matches and merge them at insert time.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d1f396f72979..efce9a2fa9be 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4113,7 +4113,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 
 	while ((node = rb_first(&delayed_refs->href_root)) != NULL) {
 		struct btrfs_delayed_ref_head *head;
-		struct btrfs_delayed_ref_node *tmp;
+		struct rb_node *n;
 		bool pin_bytes = false;
 
 		head = rb_entry(node, struct btrfs_delayed_ref_head,
@@ -4129,10 +4129,12 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 			continue;
 		}
 		spin_lock(&head->lock);
-		list_for_each_entry_safe_reverse(ref, tmp, &head->ref_list,
-						 list) {
+		while ((n = rb_first(&head->ref_tree)) != NULL) {
+			ref = rb_entry(n, struct btrfs_delayed_ref_node,
+				       ref_node);
 			ref->in_tree = 0;
-			list_del(&ref->list);
+			rb_erase(&ref->ref_node, &head->ref_tree);
+			RB_CLEAR_NODE(&ref->ref_node);
 			if (!list_empty(&ref->add_list))
 				list_del(&ref->add_list);
 			atomic_dec(&delayed_refs->num_entries);

commit 69fe2d75dd91d0124ad2ab6e9fef07633bd730e0
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Oct 19 14:15:57 2017 -0400

    btrfs: make the delalloc block rsv per inode
    
    The way we handle delalloc metadata reservations has gotten
    progressively more complicated over the years.  There is so much cruft
    and weirdness around keeping the reserved count and outstanding counters
    consistent and handling the error cases that it's impossible to
    understand.
    
    Fix this by making the delalloc block rsv per-inode.  This way we can
    calculate the actual size of the outstanding metadata reservations every
    time we make a change, and then reserve the delta based on that amount.
    This greatly simplifies the code everywhere, and makes the error
    handling in btrfs_delalloc_reserve_metadata far less terrifying.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 484cf8fc952c..d1f396f72979 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2447,14 +2447,6 @@ int open_ctree(struct super_block *sb,
 		goto fail_delalloc_bytes;
 	}
 
-	fs_info->btree_inode = new_inode(sb);
-	if (!fs_info->btree_inode) {
-		err = -ENOMEM;
-		goto fail_bio_counter;
-	}
-
-	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
-
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);
 	INIT_RADIX_TREE(&fs_info->buffer_radix, GFP_ATOMIC);
 	INIT_LIST_HEAD(&fs_info->trans_list);
@@ -2487,8 +2479,6 @@ int open_ctree(struct super_block *sb,
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	btrfs_init_block_rsv(&fs_info->global_block_rsv,
 			     BTRFS_BLOCK_RSV_GLOBAL);
-	btrfs_init_block_rsv(&fs_info->delalloc_block_rsv,
-			     BTRFS_BLOCK_RSV_DELALLOC);
 	btrfs_init_block_rsv(&fs_info->trans_block_rsv, BTRFS_BLOCK_RSV_TRANS);
 	btrfs_init_block_rsv(&fs_info->chunk_block_rsv, BTRFS_BLOCK_RSV_CHUNK);
 	btrfs_init_block_rsv(&fs_info->empty_block_rsv, BTRFS_BLOCK_RSV_EMPTY);
@@ -2517,6 +2507,14 @@ int open_ctree(struct super_block *sb,
 
 	INIT_LIST_HEAD(&fs_info->ordered_roots);
 	spin_lock_init(&fs_info->ordered_root_lock);
+
+	fs_info->btree_inode = new_inode(sb);
+	if (!fs_info->btree_inode) {
+		err = -ENOMEM;
+		goto fail_bio_counter;
+	}
+	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
+
 	fs_info->delayed_root = kmalloc(sizeof(struct btrfs_delayed_root),
 					GFP_KERNEL);
 	if (!fs_info->delayed_root) {

commit d4417e22551377c6e589c15ff2b931610e5230bc
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Oct 16 16:48:40 2017 +0300

    btrfs: Replace opencoded sizes with their symbolic constants
    
    Currently btrfs' code uses a mix of opencoded sizes and defines from sizes.h.
    Let's unifiy the code base to always use the symbolic constants. No functional
    changes
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 69ce738c00d0..484cf8fc952c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2733,7 +2733,7 @@ int open_ctree(struct super_block *sb,
 	sb->s_bdi->congested_fn = btrfs_congested_fn;
 	sb->s_bdi->congested_data = fs_info;
 	sb->s_bdi->capabilities |= BDI_CAP_CGROUP_WRITEBACK;
-	sb->s_bdi->ra_pages = VM_MAX_READAHEAD * 1024 / PAGE_SIZE;
+	sb->s_bdi->ra_pages = VM_MAX_READAHEAD * SZ_1K / PAGE_SIZE;
 	sb->s_bdi->ra_pages *= btrfs_super_num_devices(disk_super);
 	sb->s_bdi->ra_pages = max(sb->s_bdi->ra_pages, SZ_4M / PAGE_SIZE);
 

commit d278850eff3053ef166cf64c16f798dfe36278a2
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Sep 29 15:43:57 2017 -0400

    btrfs: remove delayed_ref_node from ref_head
    
    This is just excessive information in the ref_head, and makes the code
    complicated.  It is a relic from when we had the heads and the refs in
    the same tree, which is no longer the case.  With this removal I've
    cleaned up a bunch of the cruft around this old assumption as well.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f971d5680e6f..69ce738c00d0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4121,12 +4121,12 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		head = rb_entry(node, struct btrfs_delayed_ref_head,
 				href_node);
 		if (!mutex_trylock(&head->mutex)) {
-			refcount_inc(&head->node.refs);
+			refcount_inc(&head->refs);
 			spin_unlock(&delayed_refs->lock);
 
 			mutex_lock(&head->mutex);
 			mutex_unlock(&head->mutex);
-			btrfs_put_delayed_ref(&head->node);
+			btrfs_put_delayed_ref_head(head);
 			spin_lock(&delayed_refs->lock);
 			continue;
 		}
@@ -4147,16 +4147,16 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		if (head->processing == 0)
 			delayed_refs->num_heads_ready--;
 		atomic_dec(&delayed_refs->num_entries);
-		head->node.in_tree = 0;
 		rb_erase(&head->href_node, &delayed_refs->href_root);
+		RB_CLEAR_NODE(&head->href_node);
 		spin_unlock(&head->lock);
 		spin_unlock(&delayed_refs->lock);
 		mutex_unlock(&head->mutex);
 
 		if (pin_bytes)
-			btrfs_pin_extent(fs_info, head->node.bytenr,
-					 head->node.num_bytes, 1);
-		btrfs_put_delayed_ref(&head->node);
+			btrfs_pin_extent(fs_info, head->bytenr,
+					 head->num_bytes, 1);
+		btrfs_put_delayed_ref_head(head);
 		cond_resched();
 		spin_lock(&delayed_refs->lock);
 	}

commit fd708b81d972a0714b02a60eb4792fdbf15868c4
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Sep 29 15:43:50 2017 -0400

    Btrfs: add a extent ref verify tool
    
    We were having corruption issues that were tied back to problems with
    the extent tree.  In order to track them down I built this tool to try
    and find the culprit, which was pretty successful.  If you compile with
    this tool on it will live verify every ref update that the fs makes and
    make sure it is consistent and valid.  I've run this through with
    xfstests and haven't gotten any false positives.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update error messages, add fixup from Dan Carpenter to handle errors
      of read_tree_block ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f3e6e8fa19b0..f971d5680e6f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -51,6 +51,7 @@
 #include "qgroup.h"
 #include "compression.h"
 #include "tree-checker.h"
+#include "ref-verify.h"
 
 #ifdef CONFIG_X86
 #include <asm/cpufeature.h>
@@ -2509,6 +2510,7 @@ int open_ctree(struct super_block *sb,
 	/* readahead state */
 	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_DIRECT_RECLAIM);
 	spin_lock_init(&fs_info->reada_lock);
+	btrfs_init_ref_verify(fs_info);
 
 	fs_info->thread_pool_size = min_t(unsigned long,
 					  num_online_cpus() + 2, 8);
@@ -2920,6 +2922,9 @@ int open_ctree(struct super_block *sb,
 	if (ret)
 		goto fail_trans_kthread;
 
+	if (btrfs_build_ref_tree(fs_info))
+		btrfs_err(fs_info, "couldn't build ref tree");
+
 	/* do not make disk changes in broken FS or nologreplay is given */
 	if (btrfs_super_log_root(disk_super) != 0 &&
 	    !btrfs_test_opt(fs_info, NOLOGREPLAY)) {
@@ -3785,6 +3790,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 
 	btrfs_free_stripe_hash_table(fs_info);
+	btrfs_free_ref_cache(fs_info);
 
 	__btrfs_free_block_rsv(root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;

commit 736cd52e0c720103f52ab9da47b6cc3af6b083f6
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Sep 7 11:22:22 2017 -0600

    Btrfs: remove nr_async_submits and async_submit_draining
    
    Now that we have the combo of flushing twice, which can make sure IO
    have started since the second flush will wait for page lock which
    won't be unlocked unless setting page writeback and queuing ordered
    extents, we don't need %async_submit_draining, %async_delalloc_pages
    and %nr_async_submits to tell whether the IO has actually started.
    
    Moreover, all the flushers in use are followed by functions that wait
    for ordered extents to complete, so %nr_async_submits, which tracks
    whether bio's async submit has made progress, doesn't really make
    sense.
    
    However, %async_delalloc_pages is still required by shrink_delalloc()
    as that function doesn't flush twice in the normal case (just issues a
    writeback with WB_REASON_FS_FREE_SPACE).
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2b18b0c379c1..f3e6e8fa19b0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -740,22 +740,9 @@ static void run_one_async_start(struct btrfs_work *work)
 
 static void run_one_async_done(struct btrfs_work *work)
 {
-	struct btrfs_fs_info *fs_info;
 	struct async_submit_bio *async;
-	int limit;
 
 	async = container_of(work, struct  async_submit_bio, work);
-	fs_info = async->fs_info;
-
-	limit = btrfs_async_submit_limit(fs_info);
-	limit = limit * 2 / 3;
-
-	/*
-	 * atomic_dec_return implies a barrier for waitqueue_active
-	 */
-	if (atomic_dec_return(&fs_info->nr_async_submits) < limit &&
-	    waitqueue_active(&fs_info->async_submit_wait))
-		wake_up(&fs_info->async_submit_wait);
 
 	/* If an error occurred we just want to clean up the bio and move on */
 	if (async->status) {
@@ -803,19 +790,10 @@ blk_status_t btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct bio *bio,
 
 	async->status = 0;
 
-	atomic_inc(&fs_info->nr_async_submits);
-
 	if (op_is_sync(bio->bi_opf))
 		btrfs_set_work_high_priority(&async->work);
 
 	btrfs_queue_work(fs_info->workers, &async->work);
-
-	while (atomic_read(&fs_info->async_submit_draining) &&
-	      atomic_read(&fs_info->nr_async_submits)) {
-		wait_event(fs_info->async_submit_wait,
-			   (atomic_read(&fs_info->nr_async_submits) == 0));
-	}
-
 	return 0;
 }
 
@@ -2515,9 +2493,7 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_block_rsv(&fs_info->empty_block_rsv, BTRFS_BLOCK_RSV_EMPTY);
 	btrfs_init_block_rsv(&fs_info->delayed_block_rsv,
 			     BTRFS_BLOCK_RSV_DELOPS);
-	atomic_set(&fs_info->nr_async_submits, 0);
 	atomic_set(&fs_info->async_delalloc_pages, 0);
-	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->defrag_running, 0);
 	atomic_set(&fs_info->qgroup_op_seq, 0);
 	atomic_set(&fs_info->reada_works_cnt, 0);

commit f851689b5ae3eb8e1b4d397eaf2805ccfd88bf77
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Sep 7 11:22:20 2017 -0600

    Btrfs: remove nr_async_bios
    
    This was intended to congest higher layers to not send bios, but as
    
    1) the congested bit has been taken by writeback
    
    Async bios come from buffered writes and DIO writes.
    
    For DIO writes, we want to submit them ASAP, while for buffered writes,
    writeback uses balance_dirty_pages() to throttle how much dirty pages we
    can have.
    
    2) and no one is waiting for %nr_async_bios down to zero,
    
    Historically, it was introduced along with changes which let
    checksumming workload spread accross different cpus.  And at that time,
    pdflush was used instead of per-bdi flushing, perhaps pdflush did not
    have the necessary information for writeback to do throttling.
    
    We can safely remove them now.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    [ additional explanation from mails, removed unused variable 'limit' ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 09407384e996..2b18b0c379c1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2518,7 +2518,6 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->nr_async_submits, 0);
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);
-	atomic_set(&fs_info->nr_async_bios, 0);
 	atomic_set(&fs_info->defrag_running, 0);
 	atomic_set(&fs_info->qgroup_op_seq, 0);
 	atomic_set(&fs_info->reada_works_cnt, 0);

commit 557ea5dd003d371536f6b4e8f7c8209a2b6fd4e3
Author: Qu Wenruo <quwenruo.btrfs@gmx.com>
Date:   Mon Oct 9 01:51:02 2017 +0000

    btrfs: Move leaf and node validation checker to tree-checker.c
    
    It's no doubt the comprehensive tree block checker will become larger,
    so moving them into their own files is quite reasonable.
    
    Signed-off-by: Qu Wenruo <quwenruo.btrfs@gmx.com>
    [ wording adjustments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c8633f2abdf1..09407384e996 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -50,6 +50,7 @@
 #include "sysfs.h"
 #include "qgroup.h"
 #include "compression.h"
+#include "tree-checker.h"
 
 #ifdef CONFIG_X86
 #include <asm/cpufeature.h>
@@ -543,284 +544,6 @@ static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
-#define CORRUPT(reason, eb, root, slot)					\
-	btrfs_crit(root->fs_info,					\
-		   "corrupt %s, %s: block=%llu, root=%llu, slot=%d",	\
-		   btrfs_header_level(eb) == 0 ? "leaf" : "node",	\
-		   reason, btrfs_header_bytenr(eb), root->objectid, slot)
-
-static int check_extent_data_item(struct btrfs_root *root,
-				  struct extent_buffer *leaf,
-				  struct btrfs_key *key, int slot)
-{
-	struct btrfs_file_extent_item *fi;
-	u32 sectorsize = root->fs_info->sectorsize;
-	u32 item_size = btrfs_item_size_nr(leaf, slot);
-
-	if (!IS_ALIGNED(key->offset, sectorsize)) {
-		CORRUPT("unaligned key offset for file extent",
-			leaf, root, slot);
-		return -EUCLEAN;
-	}
-
-	fi = btrfs_item_ptr(leaf, slot, struct btrfs_file_extent_item);
-
-	if (btrfs_file_extent_type(leaf, fi) > BTRFS_FILE_EXTENT_TYPES) {
-		CORRUPT("invalid file extent type", leaf, root, slot);
-		return -EUCLEAN;
-	}
-
-	/*
-	 * Support for new compression/encrption must introduce incompat flag,
-	 * and must be caught in open_ctree().
-	 */
-	if (btrfs_file_extent_compression(leaf, fi) > BTRFS_COMPRESS_TYPES) {
-		CORRUPT("invalid file extent compression", leaf, root, slot);
-		return -EUCLEAN;
-	}
-	if (btrfs_file_extent_encryption(leaf, fi)) {
-		CORRUPT("invalid file extent encryption", leaf, root, slot);
-		return -EUCLEAN;
-	}
-	if (btrfs_file_extent_type(leaf, fi) == BTRFS_FILE_EXTENT_INLINE) {
-		/* Inline extent must have 0 as key offset */
-		if (key->offset) {
-			CORRUPT("inline extent has non-zero key offset",
-				leaf, root, slot);
-			return -EUCLEAN;
-		}
-
-		/* Compressed inline extent has no on-disk size, skip it */
-		if (btrfs_file_extent_compression(leaf, fi) !=
-		    BTRFS_COMPRESS_NONE)
-			return 0;
-
-		/* Uncompressed inline extent size must match item size */
-		if (item_size != BTRFS_FILE_EXTENT_INLINE_DATA_START +
-		    btrfs_file_extent_ram_bytes(leaf, fi)) {
-			CORRUPT("plaintext inline extent has invalid size",
-				leaf, root, slot);
-			return -EUCLEAN;
-		}
-		return 0;
-	}
-
-	/* Regular or preallocated extent has fixed item size */
-	if (item_size != sizeof(*fi)) {
-		CORRUPT(
-		"regluar or preallocated extent data item size is invalid",
-			leaf, root, slot);
-		return -EUCLEAN;
-	}
-	if (!IS_ALIGNED(btrfs_file_extent_ram_bytes(leaf, fi), sectorsize) ||
-	    !IS_ALIGNED(btrfs_file_extent_disk_bytenr(leaf, fi), sectorsize) ||
-	    !IS_ALIGNED(btrfs_file_extent_disk_num_bytes(leaf, fi), sectorsize) ||
-	    !IS_ALIGNED(btrfs_file_extent_offset(leaf, fi), sectorsize) ||
-	    !IS_ALIGNED(btrfs_file_extent_num_bytes(leaf, fi), sectorsize)) {
-		CORRUPT(
-		"regular or preallocated extent data item has unaligned value",
-			leaf, root, slot);
-		return -EUCLEAN;
-	}
-
-	return 0;
-}
-
-static int check_csum_item(struct btrfs_root *root, struct extent_buffer *leaf,
-			   struct btrfs_key *key, int slot)
-{
-	u32 sectorsize = root->fs_info->sectorsize;
-	u32 csumsize = btrfs_super_csum_size(root->fs_info->super_copy);
-
-	if (key->objectid != BTRFS_EXTENT_CSUM_OBJECTID) {
-		CORRUPT("invalid objectid for csum item", leaf, root, slot);
-		return -EUCLEAN;
-	}
-	if (!IS_ALIGNED(key->offset, sectorsize)) {
-		CORRUPT("unaligned key offset for csum item", leaf, root, slot);
-		return -EUCLEAN;
-	}
-	if (!IS_ALIGNED(btrfs_item_size_nr(leaf, slot), csumsize)) {
-		CORRUPT("unaligned csum item size", leaf, root, slot);
-		return -EUCLEAN;
-	}
-	return 0;
-}
-
-/*
- * Common point to switch the item-specific validation.
- */
-static int check_leaf_item(struct btrfs_root *root,
-			   struct extent_buffer *leaf,
-			   struct btrfs_key *key, int slot)
-{
-	int ret = 0;
-
-	switch (key->type) {
-	case BTRFS_EXTENT_DATA_KEY:
-		ret = check_extent_data_item(root, leaf, key, slot);
-		break;
-	case BTRFS_EXTENT_CSUM_KEY:
-		ret = check_csum_item(root, leaf, key, slot);
-		break;
-	}
-	return ret;
-}
-
-static noinline int check_leaf(struct btrfs_root *root,
-			       struct extent_buffer *leaf)
-{
-	struct btrfs_fs_info *fs_info = root->fs_info;
-	/* No valid key type is 0, so all key should be larger than this key */
-	struct btrfs_key prev_key = {0, 0, 0};
-	struct btrfs_key key;
-	u32 nritems = btrfs_header_nritems(leaf);
-	int slot;
-
-	/*
-	 * Extent buffers from a relocation tree have a owner field that
-	 * corresponds to the subvolume tree they are based on. So just from an
-	 * extent buffer alone we can not find out what is the id of the
-	 * corresponding subvolume tree, so we can not figure out if the extent
-	 * buffer corresponds to the root of the relocation tree or not. So skip
-	 * this check for relocation trees.
-	 */
-	if (nritems == 0 && !btrfs_header_flag(leaf, BTRFS_HEADER_FLAG_RELOC)) {
-		struct btrfs_root *check_root;
-
-		key.objectid = btrfs_header_owner(leaf);
-		key.type = BTRFS_ROOT_ITEM_KEY;
-		key.offset = (u64)-1;
-
-		check_root = btrfs_get_fs_root(fs_info, &key, false);
-		/*
-		 * The only reason we also check NULL here is that during
-		 * open_ctree() some roots has not yet been set up.
-		 */
-		if (!IS_ERR_OR_NULL(check_root)) {
-			struct extent_buffer *eb;
-
-			eb = btrfs_root_node(check_root);
-			/* if leaf is the root, then it's fine */
-			if (leaf != eb) {
-				CORRUPT("non-root leaf's nritems is 0",
-					leaf, check_root, 0);
-				free_extent_buffer(eb);
-				return -EUCLEAN;
-			}
-			free_extent_buffer(eb);
-		}
-		return 0;
-	}
-
-	if (nritems == 0)
-		return 0;
-
-	/*
-	 * Check the following things to make sure this is a good leaf, and
-	 * leaf users won't need to bother with similar sanity checks:
-	 *
-	 * 1) key order
-	 * 2) item offset and size
-	 *    No overlap, no hole, all inside the leaf.
-	 * 3) item content
-	 *    If possible, do comprehensive sanity check.
-	 *    NOTE: All checks must only rely on the item data itself.
-	 */
-	for (slot = 0; slot < nritems; slot++) {
-		u32 item_end_expected;
-		int ret;
-
-		btrfs_item_key_to_cpu(leaf, &key, slot);
-
-		/* Make sure the keys are in the right order */
-		if (btrfs_comp_cpu_keys(&prev_key, &key) >= 0) {
-			CORRUPT("bad key order", leaf, root, slot);
-			return -EUCLEAN;
-		}
-
-		/*
-		 * Make sure the offset and ends are right, remember that the
-		 * item data starts at the end of the leaf and grows towards the
-		 * front.
-		 */
-		if (slot == 0)
-			item_end_expected = BTRFS_LEAF_DATA_SIZE(fs_info);
-		else
-			item_end_expected = btrfs_item_offset_nr(leaf,
-								 slot - 1);
-		if (btrfs_item_end_nr(leaf, slot) != item_end_expected) {
-			CORRUPT("slot offset bad", leaf, root, slot);
-			return -EUCLEAN;
-		}
-
-		/*
-		 * Check to make sure that we don't point outside of the leaf,
-		 * just in case all the items are consistent to each other, but
-		 * all point outside of the leaf.
-		 */
-		if (btrfs_item_end_nr(leaf, slot) >
-		    BTRFS_LEAF_DATA_SIZE(fs_info)) {
-			CORRUPT("slot end outside of leaf", leaf, root, slot);
-			return -EUCLEAN;
-		}
-
-		/* Also check if the item pointer overlaps with btrfs item. */
-		if (btrfs_item_nr_offset(slot) + sizeof(struct btrfs_item) >
-		    btrfs_item_ptr_offset(leaf, slot)) {
-			CORRUPT("slot overlap with its data", leaf, root, slot);
-			return -EUCLEAN;
-		}
-
-		/* Check if the item size and content meet other criteria */
-		ret = check_leaf_item(root, leaf, &key, slot);
-		if (ret < 0)
-			return ret;
-
-		prev_key.objectid = key.objectid;
-		prev_key.type = key.type;
-		prev_key.offset = key.offset;
-	}
-
-	return 0;
-}
-
-static int check_node(struct btrfs_root *root, struct extent_buffer *node)
-{
-	unsigned long nr = btrfs_header_nritems(node);
-	struct btrfs_key key, next_key;
-	int slot;
-	u64 bytenr;
-	int ret = 0;
-
-	if (nr == 0 || nr > BTRFS_NODEPTRS_PER_BLOCK(root->fs_info)) {
-		btrfs_crit(root->fs_info,
-			   "corrupt node: block %llu root %llu nritems %lu",
-			   node->start, root->objectid, nr);
-		return -EIO;
-	}
-
-	for (slot = 0; slot < nr - 1; slot++) {
-		bytenr = btrfs_node_blockptr(node, slot);
-		btrfs_node_key_to_cpu(node, &key, slot);
-		btrfs_node_key_to_cpu(node, &next_key, slot + 1);
-
-		if (!bytenr) {
-			CORRUPT("invalid item slot", node, root, slot);
-			ret = -EIO;
-			goto out;
-		}
-
-		if (btrfs_comp_cpu_keys(&key, &next_key) >= 0) {
-			CORRUPT("bad key order", node, root, slot);
-			ret = -EIO;
-			goto out;
-		}
-	}
-out:
-	return ret;
-}
-
 static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 				      u64 phy_offset, struct page *page,
 				      u64 start, u64 end, int mirror)
@@ -886,12 +609,12 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	 * that we don't try and read the other copies of this block, just
 	 * return -EIO.
 	 */
-	if (found_level == 0 && check_leaf(root, eb)) {
+	if (found_level == 0 && btrfs_check_leaf(root, eb)) {
 		set_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 		ret = -EIO;
 	}
 
-	if (found_level > 0 && check_node(root, eb))
+	if (found_level > 0 && btrfs_check_node(root, eb))
 		ret = -EIO;
 
 	if (!ret)
@@ -4146,7 +3869,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 					 buf->len,
 					 fs_info->dirty_metadata_batch);
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
-	if (btrfs_header_level(buf) == 0 && check_leaf(root, buf)) {
+	if (btrfs_header_level(buf) == 0 && btrfs_check_leaf(root, buf)) {
 		btrfs_print_leaf(buf);
 		ASSERT(0);
 	}

commit 4b865cab96fe2a30ed512cf667b354bd291b3b0a
Author: Qu Wenruo <quwenruo.btrfs@gmx.com>
Date:   Wed Aug 23 16:57:59 2017 +0900

    btrfs: Add checker for EXTENT_CSUM
    
    EXTENT_CSUM checker is a relatively easy one, only needs to check:
    
    1) Objectid
       Fixed to BTRFS_EXTENT_CSUM_OBJECTID
    
    2) Key offset alignment
       Must be aligned to sectorsize
    
    3) Item size alignedment
       Must be aligned to csum size
    
    Signed-off-by: Qu Wenruo <quwenruo.btrfs@gmx.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b863d41f7d0a..c8633f2abdf1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -626,6 +626,27 @@ static int check_extent_data_item(struct btrfs_root *root,
 	return 0;
 }
 
+static int check_csum_item(struct btrfs_root *root, struct extent_buffer *leaf,
+			   struct btrfs_key *key, int slot)
+{
+	u32 sectorsize = root->fs_info->sectorsize;
+	u32 csumsize = btrfs_super_csum_size(root->fs_info->super_copy);
+
+	if (key->objectid != BTRFS_EXTENT_CSUM_OBJECTID) {
+		CORRUPT("invalid objectid for csum item", leaf, root, slot);
+		return -EUCLEAN;
+	}
+	if (!IS_ALIGNED(key->offset, sectorsize)) {
+		CORRUPT("unaligned key offset for csum item", leaf, root, slot);
+		return -EUCLEAN;
+	}
+	if (!IS_ALIGNED(btrfs_item_size_nr(leaf, slot), csumsize)) {
+		CORRUPT("unaligned csum item size", leaf, root, slot);
+		return -EUCLEAN;
+	}
+	return 0;
+}
+
 /*
  * Common point to switch the item-specific validation.
  */
@@ -639,6 +660,9 @@ static int check_leaf_item(struct btrfs_root *root,
 	case BTRFS_EXTENT_DATA_KEY:
 		ret = check_extent_data_item(root, leaf, key, slot);
 		break;
+	case BTRFS_EXTENT_CSUM_KEY:
+		ret = check_csum_item(root, leaf, key, slot);
+		break;
 	}
 	return ret;
 }

commit 40c3c40947324d9f40bf47830c92c59a9bbadf4a
Author: Qu Wenruo <quwenruo.btrfs@gmx.com>
Date:   Wed Aug 23 16:57:58 2017 +0900

    btrfs: Add sanity check for EXTENT_DATA when reading out leaf
    
    Add extra checks for item with EXTENT_DATA type.  This checks the
    following thing:
    
    0) Key offset
       All key offsets must be aligned to sectorsize.
       Inline extent must have 0 for key offset.
    
    1) Item size
       Uncompressed inline file extent size must match item size.
       (Compressed inline file extent has no information about its on-disk size.)
       Regular/preallocated file extent size must be a fixed value.
    
    2) Every member of regular file extent item
       Including alignment for bytenr and offset, possible value for
       compression/encryption/type.
    
    3) Type/compression/encode must be one of the valid values.
    
    This should be the most comprehensive and strict check in the context
    of btrfs_item for EXTENT_DATA.
    
    Signed-off-by: Qu Wenruo <quwenruo.btrfs@gmx.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ switch to BTRFS_FILE_EXTENT_TYPES, similar to what
      BTRFS_COMPRESS_TYPES does ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d1770b3e0385..b863d41f7d0a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -549,6 +549,100 @@ static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
 		   btrfs_header_level(eb) == 0 ? "leaf" : "node",	\
 		   reason, btrfs_header_bytenr(eb), root->objectid, slot)
 
+static int check_extent_data_item(struct btrfs_root *root,
+				  struct extent_buffer *leaf,
+				  struct btrfs_key *key, int slot)
+{
+	struct btrfs_file_extent_item *fi;
+	u32 sectorsize = root->fs_info->sectorsize;
+	u32 item_size = btrfs_item_size_nr(leaf, slot);
+
+	if (!IS_ALIGNED(key->offset, sectorsize)) {
+		CORRUPT("unaligned key offset for file extent",
+			leaf, root, slot);
+		return -EUCLEAN;
+	}
+
+	fi = btrfs_item_ptr(leaf, slot, struct btrfs_file_extent_item);
+
+	if (btrfs_file_extent_type(leaf, fi) > BTRFS_FILE_EXTENT_TYPES) {
+		CORRUPT("invalid file extent type", leaf, root, slot);
+		return -EUCLEAN;
+	}
+
+	/*
+	 * Support for new compression/encrption must introduce incompat flag,
+	 * and must be caught in open_ctree().
+	 */
+	if (btrfs_file_extent_compression(leaf, fi) > BTRFS_COMPRESS_TYPES) {
+		CORRUPT("invalid file extent compression", leaf, root, slot);
+		return -EUCLEAN;
+	}
+	if (btrfs_file_extent_encryption(leaf, fi)) {
+		CORRUPT("invalid file extent encryption", leaf, root, slot);
+		return -EUCLEAN;
+	}
+	if (btrfs_file_extent_type(leaf, fi) == BTRFS_FILE_EXTENT_INLINE) {
+		/* Inline extent must have 0 as key offset */
+		if (key->offset) {
+			CORRUPT("inline extent has non-zero key offset",
+				leaf, root, slot);
+			return -EUCLEAN;
+		}
+
+		/* Compressed inline extent has no on-disk size, skip it */
+		if (btrfs_file_extent_compression(leaf, fi) !=
+		    BTRFS_COMPRESS_NONE)
+			return 0;
+
+		/* Uncompressed inline extent size must match item size */
+		if (item_size != BTRFS_FILE_EXTENT_INLINE_DATA_START +
+		    btrfs_file_extent_ram_bytes(leaf, fi)) {
+			CORRUPT("plaintext inline extent has invalid size",
+				leaf, root, slot);
+			return -EUCLEAN;
+		}
+		return 0;
+	}
+
+	/* Regular or preallocated extent has fixed item size */
+	if (item_size != sizeof(*fi)) {
+		CORRUPT(
+		"regluar or preallocated extent data item size is invalid",
+			leaf, root, slot);
+		return -EUCLEAN;
+	}
+	if (!IS_ALIGNED(btrfs_file_extent_ram_bytes(leaf, fi), sectorsize) ||
+	    !IS_ALIGNED(btrfs_file_extent_disk_bytenr(leaf, fi), sectorsize) ||
+	    !IS_ALIGNED(btrfs_file_extent_disk_num_bytes(leaf, fi), sectorsize) ||
+	    !IS_ALIGNED(btrfs_file_extent_offset(leaf, fi), sectorsize) ||
+	    !IS_ALIGNED(btrfs_file_extent_num_bytes(leaf, fi), sectorsize)) {
+		CORRUPT(
+		"regular or preallocated extent data item has unaligned value",
+			leaf, root, slot);
+		return -EUCLEAN;
+	}
+
+	return 0;
+}
+
+/*
+ * Common point to switch the item-specific validation.
+ */
+static int check_leaf_item(struct btrfs_root *root,
+			   struct extent_buffer *leaf,
+			   struct btrfs_key *key, int slot)
+{
+	int ret = 0;
+
+	switch (key->type) {
+	case BTRFS_EXTENT_DATA_KEY:
+		ret = check_extent_data_item(root, leaf, key, slot);
+		break;
+	}
+	return ret;
+}
+
 static noinline int check_leaf(struct btrfs_root *root,
 			       struct extent_buffer *leaf)
 {
@@ -605,9 +699,13 @@ static noinline int check_leaf(struct btrfs_root *root,
 	 * 1) key order
 	 * 2) item offset and size
 	 *    No overlap, no hole, all inside the leaf.
+	 * 3) item content
+	 *    If possible, do comprehensive sanity check.
+	 *    NOTE: All checks must only rely on the item data itself.
 	 */
 	for (slot = 0; slot < nritems; slot++) {
 		u32 item_end_expected;
+		int ret;
 
 		btrfs_item_key_to_cpu(leaf, &key, slot);
 
@@ -650,6 +748,11 @@ static noinline int check_leaf(struct btrfs_root *root,
 			return -EUCLEAN;
 		}
 
+		/* Check if the item size and content meet other criteria */
+		ret = check_leaf_item(root, leaf, &key, slot);
+		if (ret < 0)
+			return ret;
+
 		prev_key.objectid = key.objectid;
 		prev_key.type = key.type;
 		prev_key.offset = key.offset;

commit 7f43d4affb2a254d421ab20b0cf65ac2569909fb
Author: Qu Wenruo <quwenruo.btrfs@gmx.com>
Date:   Wed Aug 23 16:57:57 2017 +0900

    btrfs: Check if item pointer overlaps with the item itself
    
    Function check_leaf() checks if any item pointer points outside of the
    leaf, but it doesn't check if the pointer overlaps with the item itself.
    
    Normally only the last item may be the victim, but adding such check is
    never a bad idea anyway.
    
    Signed-off-by: Qu Wenruo <quwenruo.btrfs@gmx.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6c97ae1e7288..d1770b3e0385 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -643,6 +643,13 @@ static noinline int check_leaf(struct btrfs_root *root,
 			return -EUCLEAN;
 		}
 
+		/* Also check if the item pointer overlaps with btrfs item. */
+		if (btrfs_item_nr_offset(slot) + sizeof(struct btrfs_item) >
+		    btrfs_item_ptr_offset(leaf, slot)) {
+			CORRUPT("slot overlap with its data", leaf, root, slot);
+			return -EUCLEAN;
+		}
+
 		prev_key.objectid = key.objectid;
 		prev_key.type = key.type;
 		prev_key.offset = key.offset;

commit c3267bbaa9cae09b62960eafe33ad19196803285
Author: Qu Wenruo <quwenruo.btrfs@gmx.com>
Date:   Wed Aug 23 16:57:56 2017 +0900

    btrfs: Refactor check_leaf function for later expansion
    
    Current check_leaf() function does a good job checking key order and
    item offset/size.
    
    However it only checks from slot 0 to the last but one slot, this is
    good but makes later expansion hard.
    
    So this refactoring iterates from slot 0 to the last slot.
    For key comparison, it uses a key with all 0 as initial key, so all
    valid keys should be larger than that.
    
    And for item size/offset checks, it compares current item end with
    previous item offset.
    For slot 0, use leaf end as a special case.
    
    This makes later item/key offset checks and item size checks easier to
    be implemented.
    
    Also, makes check_leaf() to return -EUCLEAN other than -EIO to indicate
    error.
    
    Signed-off-by: Qu Wenruo <quwenruo.btrfs@gmx.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 90310d9e647a..6c97ae1e7288 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -553,8 +553,9 @@ static noinline int check_leaf(struct btrfs_root *root,
 			       struct extent_buffer *leaf)
 {
 	struct btrfs_fs_info *fs_info = root->fs_info;
+	/* No valid key type is 0, so all key should be larger than this key */
+	struct btrfs_key prev_key = {0, 0, 0};
 	struct btrfs_key key;
-	struct btrfs_key leaf_key;
 	u32 nritems = btrfs_header_nritems(leaf);
 	int slot;
 
@@ -587,7 +588,7 @@ static noinline int check_leaf(struct btrfs_root *root,
 				CORRUPT("non-root leaf's nritems is 0",
 					leaf, check_root, 0);
 				free_extent_buffer(eb);
-				return -EIO;
+				return -EUCLEAN;
 			}
 			free_extent_buffer(eb);
 		}
@@ -597,28 +598,23 @@ static noinline int check_leaf(struct btrfs_root *root,
 	if (nritems == 0)
 		return 0;
 
-	/* Check the 0 item */
-	if (btrfs_item_offset_nr(leaf, 0) + btrfs_item_size_nr(leaf, 0) !=
-	    BTRFS_LEAF_DATA_SIZE(fs_info)) {
-		CORRUPT("invalid item offset size pair", leaf, root, 0);
-		return -EIO;
-	}
-
 	/*
-	 * Check to make sure each items keys are in the correct order and their
-	 * offsets make sense.  We only have to loop through nritems-1 because
-	 * we check the current slot against the next slot, which verifies the
-	 * next slot's offset+size makes sense and that the current's slot
-	 * offset is correct.
+	 * Check the following things to make sure this is a good leaf, and
+	 * leaf users won't need to bother with similar sanity checks:
+	 *
+	 * 1) key order
+	 * 2) item offset and size
+	 *    No overlap, no hole, all inside the leaf.
 	 */
-	for (slot = 0; slot < nritems - 1; slot++) {
-		btrfs_item_key_to_cpu(leaf, &leaf_key, slot);
-		btrfs_item_key_to_cpu(leaf, &key, slot + 1);
+	for (slot = 0; slot < nritems; slot++) {
+		u32 item_end_expected;
+
+		btrfs_item_key_to_cpu(leaf, &key, slot);
 
 		/* Make sure the keys are in the right order */
-		if (btrfs_comp_cpu_keys(&leaf_key, &key) >= 0) {
+		if (btrfs_comp_cpu_keys(&prev_key, &key) >= 0) {
 			CORRUPT("bad key order", leaf, root, slot);
-			return -EIO;
+			return -EUCLEAN;
 		}
 
 		/*
@@ -626,10 +622,14 @@ static noinline int check_leaf(struct btrfs_root *root,
 		 * item data starts at the end of the leaf and grows towards the
 		 * front.
 		 */
-		if (btrfs_item_offset_nr(leaf, slot) !=
-			btrfs_item_end_nr(leaf, slot + 1)) {
+		if (slot == 0)
+			item_end_expected = BTRFS_LEAF_DATA_SIZE(fs_info);
+		else
+			item_end_expected = btrfs_item_offset_nr(leaf,
+								 slot - 1);
+		if (btrfs_item_end_nr(leaf, slot) != item_end_expected) {
 			CORRUPT("slot offset bad", leaf, root, slot);
-			return -EIO;
+			return -EUCLEAN;
 		}
 
 		/*
@@ -640,8 +640,12 @@ static noinline int check_leaf(struct btrfs_root *root,
 		if (btrfs_item_end_nr(leaf, slot) >
 		    BTRFS_LEAF_DATA_SIZE(fs_info)) {
 			CORRUPT("slot end outside of leaf", leaf, root, slot);
-			return -EIO;
+			return -EUCLEAN;
 		}
+
+		prev_key.objectid = key.objectid;
+		prev_key.type = key.type;
+		prev_key.offset = key.offset;
 	}
 
 	return 0;

commit 18fdc67900c5bfd1eeb41cfa50ea6f2eb7266f73
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Sep 13 12:18:22 2017 -0600

    Btrfs: remove bio_flags which indicates a meta block of log-tree
    
    Since both committing transaction and writing log-tree are doing
    plugging on metadata IO, we can unify to use %sync_writers to benefit
    both cases, instead of checking bio_flags while writing meta blocks of
    log-tree.
    
    We can remove this bio_flags because in order to write dirty blocks,
    log tree also uses btrfs_write_marked_extents(), inside which we
    have enabled %sync_writers, therefore, every write goes in a
    synchronous way, so does checksuming.
    
    Please also note that, bio_flags is applied per-context while
    %sync_writers is applied per-inode, so this might incur some overhead, ie.
    
    1) while log tree is flushing its dirty blocks via
       btrfs_write_marked_extents(), in which %sync_writers is increased
       by one.
    
    2) in the meantime, some writeback operations may happen upon btrfs's
       metadata inode, so these writes go synchronously, too.
    
    However, AFAICS, the overhead is not a big one while the win is that
    we unify the two places that needs synchronous way and remove a
    special hack/flag.
    
    This removes the bio_flags related stuff for writing log-tree.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 23442747363e..90310d9e647a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1005,12 +1005,10 @@ static blk_status_t __btree_submit_bio_done(void *private_data, struct bio *bio,
 	return ret;
 }
 
-static int check_async_write(struct btrfs_inode *bi, unsigned long bio_flags)
+static int check_async_write(struct btrfs_inode *bi)
 {
 	if (atomic_read(&bi->sync_writers))
 		return 0;
-	if (bio_flags & EXTENT_BIO_TREE_LOG)
-		return 0;
 #ifdef CONFIG_X86
 	if (static_cpu_has(X86_FEATURE_XMM4_2))
 		return 0;
@@ -1024,7 +1022,7 @@ static blk_status_t btree_submit_bio_hook(void *private_data, struct bio *bio,
 {
 	struct inode *inode = private_data;
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
-	int async = check_async_write(BTRFS_I(inode), bio_flags);
+	int async = check_async_write(BTRFS_I(inode));
 	blk_status_t ret;
 
 	if (bio_op(bio) != REQ_OP_WRITE) {

commit 6300463b14c1c2665674eb8f15843e5bb7a7ff84
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Aug 21 15:49:59 2017 -0600

    Btrfs: make plug in writing meta blocks really work
    
    We have started plug in btrfs_write_and_wait_marked_extents() but the
    generated IOs actually go to device's schedule IO list where the work
    is doing in another task, thus the started plug doesn't make any
    sense.
    
    And since we wait for IOs immediately after writing meta blocks, it's
    the same case as writing log tree, doing sync submit can merge more
    IOs.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0a98567f8cfc..23442747363e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1005,8 +1005,10 @@ static blk_status_t __btree_submit_bio_done(void *private_data, struct bio *bio,
 	return ret;
 }
 
-static int check_async_write(unsigned long bio_flags)
+static int check_async_write(struct btrfs_inode *bi, unsigned long bio_flags)
 {
+	if (atomic_read(&bi->sync_writers))
+		return 0;
 	if (bio_flags & EXTENT_BIO_TREE_LOG)
 		return 0;
 #ifdef CONFIG_X86
@@ -1022,7 +1024,7 @@ static blk_status_t btree_submit_bio_hook(void *private_data, struct bio *bio,
 {
 	struct inode *inode = private_data;
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
-	int async = check_async_write(bio_flags);
+	int async = check_async_write(BTRFS_I(inode), bio_flags);
 	blk_status_t ret;
 
 	if (bio_op(bio) != REQ_OP_WRITE) {

commit ee87cf5ed9fe8e41d057f5f5c7f49c18b6d3f94c
Author: Anand Jain <anand.jain@oracle.com>
Date:   Tue Aug 1 18:35:08 2017 +0800

    btrfs: copy fsid to super_block s_uuid
    
    We didn't copy fsid to struct super_block.s_uuid so Overlay disables
    index feature with btrfs as the lower FS.
    
    kernel: overlayfs: fs on '/lower' does not support file handles, falling back to index=off.
    
    Fix this by publishing the fsid through struct super_block.s_uuid.
    
    [ dsterba: I think that setting s_uuid is the last missing bit. Overlay
      needs the file handle encoding support from the lower filesystem, which
      is supported. Filling the whole filesystem id is correct, the subvolume
      id is encoded in the file handle buffer from inside btrfs_encode_fh. ]
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dfdab849037b..0a98567f8cfc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2901,6 +2901,7 @@ int open_ctree(struct super_block *sb,
 
 	sb->s_blocksize = sectorsize;
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
+	memcpy(&sb->s_uuid, fs_info->fsid, BTRFS_FSID_SIZE);
 
 	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_sys_array(fs_info);

commit 5ba88cd6e9a658be0cdcaf4fc0438b7d63d32bf6
Merge: 7b5ef82336e7 8c6c592831a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 29 12:57:35 2017 -0700

    Merge branch 'for-4.14-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "We've collected a bunch of isolated fixes, for crashes, user-visible
      behaviour or missing bits from other subsystem cleanups from the past.
    
      The overall number is not small but I was not able to make it
      significantly smaller. Most of the patches are supposed to go to
      stable"
    
    * 'for-4.14-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      btrfs: log csums for all modified extents
      Btrfs: fix unexpected result when dio reading corrupted blocks
      btrfs: Report error on removing qgroup if del_qgroup_item fails
      Btrfs: skip checksum when reading compressed data if some IO have failed
      Btrfs: fix kernel oops while reading compressed data
      Btrfs: use btrfs_op instead of bio_op in __btrfs_map_block
      Btrfs: do not backup tree roots when fsync
      btrfs: remove BTRFS_FS_QUOTA_DISABLING flag
      btrfs: propagate error to btrfs_cmp_data_prepare caller
      btrfs: prevent to set invalid default subvolid
      Btrfs: send: fix error number for unknown inode types
      btrfs: fix NULL pointer dereference from free_reloc_roots()
      btrfs: finish ordered extent cleaning if no progress is found
      btrfs: clear ordered flag on cleaning up ordered extents
      Btrfs: fix incorrect {node,sector}size endianness from BTRFS_IOC_FS_INFO
      Btrfs: do not reset bio->bi_ops while writing bio
      Btrfs: use the new helper wbc_to_write_flags

commit fed3b381145e2e7c66b0b3f640851e1633ebd07f
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Sep 13 12:25:21 2017 -0600

    Btrfs: do not backup tree roots when fsync
    
    It doesn't make sense to backup tree roots when doing fsync, since
    during fsync those tree roots have not been consistent on disk.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Qu Wenruo <quwenruo.btrfs@gmx.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 27d458640536..0f2271815eb6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3641,7 +3641,14 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 	u64 flags;
 
 	do_barriers = !btrfs_test_opt(fs_info, NOBARRIER);
-	backup_super_roots(fs_info);
+
+	/*
+	 * max_mirrors == 0 indicates we're from commit_transaction,
+	 * not from fsync where the tree roots in fs_info have not
+	 * been consistent on disk.
+	 */
+	if (max_mirrors == 0)
+		backup_super_roots(fs_info);
 
 	sb = fs_info->super_for_commit;
 	dev_item = &sb->dev_item;

commit 0f0d12728e56c94d3289c6831243b6faeae8a19d
Merge: 581bfce969cb e462ec50cb5f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 14 18:54:01 2017 -0700

    Merge branch 'work.mount' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull mount flag updates from Al Viro:
     "Another chunk of fmount preparations from dhowells; only trivial
      conflicts for that part. It separates MS_... bits (very grotty
      mount(2) ABI) from the struct super_block ->s_flags (kernel-internal,
      only a small subset of MS_... stuff).
    
      This does *not* convert the filesystems to new constants; only the
      infrastructure is done here. The next step in that series is where the
      conflicts would be; that's the conversion of filesystems. It's purely
      mechanical and it's better done after the merge, so if you could run
      something like
    
            list=$(for i in MS_RDONLY MS_NOSUID MS_NODEV MS_NOEXEC MS_SYNCHRONOUS MS_MANDLOCK MS_DIRSYNC MS_NOATIME MS_NODIRATIME MS_SILENT MS_POSIXACL MS_KERNMOUNT MS_I_VERSION MS_LAZYTIME; do git grep -l $i fs drivers/staging/lustre drivers/mtd ipc mm include/linux; done|sort|uniq|grep -v '^fs/namespace.c$')
    
            sed -i -e 's/\<MS_RDONLY\>/SB_RDONLY/g' \
                    -e 's/\<MS_NOSUID\>/SB_NOSUID/g' \
                    -e 's/\<MS_NODEV\>/SB_NODEV/g' \
                    -e 's/\<MS_NOEXEC\>/SB_NOEXEC/g' \
                    -e 's/\<MS_SYNCHRONOUS\>/SB_SYNCHRONOUS/g' \
                    -e 's/\<MS_MANDLOCK\>/SB_MANDLOCK/g' \
                    -e 's/\<MS_DIRSYNC\>/SB_DIRSYNC/g' \
                    -e 's/\<MS_NOATIME\>/SB_NOATIME/g' \
                    -e 's/\<MS_NODIRATIME\>/SB_NODIRATIME/g' \
                    -e 's/\<MS_SILENT\>/SB_SILENT/g' \
                    -e 's/\<MS_POSIXACL\>/SB_POSIXACL/g' \
                    -e 's/\<MS_KERNMOUNT\>/SB_KERNMOUNT/g' \
                    -e 's/\<MS_I_VERSION\>/SB_I_VERSION/g' \
                    -e 's/\<MS_LAZYTIME\>/SB_LAZYTIME/g' \
                    $list
    
      and commit it with something along the lines of 'convert filesystems
      away from use of MS_... constants' as commit message, it would save a
      quite a bit of headache next cycle"
    
    * 'work.mount' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      VFS: Differentiate mount flags (MS_*) from internal superblock flags
      VFS: Convert sb->s_flags & MS_RDONLY to sb_rdonly(sb)
      vfs: Add sb_rdonly(sb) to query the MS_RDONLY flag on s_flags

commit e7cdb60fd28b252f1c15a0e50f79a01906124915
Merge: a2bc8dea9e96 87bf54bb43dd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 14 17:30:49 2017 -0700

    Merge branch 'zstd-minimal' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull zstd support from Chris Mason:
     "Nick Terrell's patch series to add zstd support to the kernel has been
      floating around for a while. After talking with Dave Sterba, Herbert
      and Phillip, we decided to send the whole thing in as one pull
      request.
    
      zstd is a big win in speed over zlib and in compression ratio over
      lzo, and the compression team here at FB has gotten great results
      using it in production. Nick will continue to update the kernel side
      with new improvements from the open source zstd userland code.
    
      Nick has a number of benchmarks for the main zstd code in his lib/zstd
      commit:
    
          I ran the benchmarks on a Ubuntu 14.04 VM with 2 cores and 4 GiB
          of RAM. The VM is running on a MacBook Pro with a 3.1 GHz Intel
          Core i7 processor, 16 GB of RAM, and a SSD. I benchmarked using
          `silesia.tar` [3], which is 211,988,480 B large. Run the following
          commands for the benchmark:
    
            sudo modprobe zstd_compress_test
            sudo mknod zstd_compress_test c 245 0
            sudo cp silesia.tar zstd_compress_test
    
          The time is reported by the time of the userland `cp`.
          The MB/s is computed with
    
            1,536,217,008 B / time(buffer size, hash)
    
          which includes the time to copy from userland.
          The Adjusted MB/s is computed with
    
            1,536,217,088 B / (time(buffer size, hash) - time(buffer size, none)).
    
          The memory reported is the amount of memory the compressor
          requests.
    
            | Method   | Size (B) | Time (s) | Ratio | MB/s    | Adj MB/s | Mem (MB) |
            |----------|----------|----------|-------|---------|----------|----------|
            | none     | 11988480 |    0.100 |     1 | 2119.88 |        - |        - |
            | zstd -1  | 73645762 |    1.044 | 2.878 |  203.05 |   224.56 |     1.23 |
            | zstd -3  | 66988878 |    1.761 | 3.165 |  120.38 |   127.63 |     2.47 |
            | zstd -5  | 65001259 |    2.563 | 3.261 |   82.71 |    86.07 |     2.86 |
            | zstd -10 | 60165346 |   13.242 | 3.523 |   16.01 |    16.13 |    13.22 |
            | zstd -15 | 58009756 |   47.601 | 3.654 |    4.45 |     4.46 |    21.61 |
            | zstd -19 | 54014593 |  102.835 | 3.925 |    2.06 |     2.06 |    60.15 |
            | zlib -1  | 77260026 |    2.895 | 2.744 |   73.23 |    75.85 |     0.27 |
            | zlib -3  | 72972206 |    4.116 | 2.905 |   51.50 |    52.79 |     0.27 |
            | zlib -6  | 68190360 |    9.633 | 3.109 |   22.01 |    22.24 |     0.27 |
            | zlib -9  | 67613382 |   22.554 | 3.135 |    9.40 |     9.44 |     0.27 |
    
          I benchmarked zstd decompression using the same method on the same
          machine. The benchmark file is located in the upstream zstd repo
          under `contrib/linux-kernel/zstd_decompress_test.c` [4]. The
          memory reported is the amount of memory required to decompress
          data compressed with the given compression level. If you know the
          maximum size of your input, you can reduce the memory usage of
          decompression irrespective of the compression level.
    
            | Method   | Time (s) | MB/s    | Adjusted MB/s | Memory (MB) |
            |----------|----------|---------|---------------|-------------|
            | none     |    0.025 | 8479.54 |             - |           - |
            | zstd -1  |    0.358 |  592.15 |        636.60 |        0.84 |
            | zstd -3  |    0.396 |  535.32 |        571.40 |        1.46 |
            | zstd -5  |    0.396 |  535.32 |        571.40 |        1.46 |
            | zstd -10 |    0.374 |  566.81 |        607.42 |        2.51 |
            | zstd -15 |    0.379 |  559.34 |        598.84 |        4.61 |
            | zstd -19 |    0.412 |  514.54 |        547.77 |        8.80 |
            | zlib -1  |    0.940 |  225.52 |        231.68 |        0.04 |
            | zlib -3  |    0.883 |  240.08 |        247.07 |        0.04 |
            | zlib -6  |    0.844 |  251.17 |        258.84 |        0.04 |
            | zlib -9  |    0.837 |  253.27 |        287.64 |        0.04 |
    
      I ran a long series of tests and benchmarks on the btrfs side and the
      gains are very similar to the core benchmarks Nick ran"
    
    * 'zstd-minimal' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      squashfs: Add zstd support
      btrfs: Add zstd support
      lib: Add zstd modules
      lib: Add xxhash module

commit 66ba772ee3119849fcdd8ac9766c6c25ede4a982
Merge: 126e76ffbf78 db95c876c568
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Sep 9 13:27:51 2017 -0700

    Merge branch 'for-4.14' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "The changes range through all types: cleanups, core chagnes, sanity
      checks, fixes, other user visible changes, detailed list below:
    
       - deprecated: user transaction ioctl
    
       - mount option ssd does not change allocation alignments
    
       - degraded read-write mount is allowed if all the raid profile
         constraints are met, now based on more accurate check
    
       - defrag: do not reset compression afterwards; the NOCOMPRESS flag
         can be now overriden by defrag
    
       - prep work for better extent reference tracking (related to the
         qgroup slowness with balance)
    
       - prep work for compression heuristics
    
       - memory allocation reductions (may help latencies on a loaded
         system)
    
       - better accounting for io waiting states
    
       - error handling improvements (removed BUGs)
    
       - added more sanity checks for shared refs
    
       - fix readdir vs pagefault deadlock under some circumstances
    
       - fix for 'no-hole' mode, certain combination of compressed and
         inline extents
    
       - send: fix emission of invalid clone operations
    
       - fixup file mode if setting acls fail
    
       - more fixes from fuzzing
    
       - oher cleanups"
    
    * 'for-4.14' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (104 commits)
      btrfs: submit superblock io with REQ_META and REQ_PRIO
      btrfs: remove unnecessary memory barrier in btrfs_direct_IO
      btrfs: remove superfluous chunk_tree argument from btrfs_alloc_dev_extent
      btrfs: Remove chunk_objectid parameter of btrfs_alloc_dev_extent
      btrfs: pass fs_info to btrfs_del_root instead of tree_root
      Btrfs: add one more sanity check for shared ref type
      Btrfs: remove BUG_ON in __add_tree_block
      Btrfs: remove BUG() in add_data_reference
      Btrfs: remove BUG() in print_extent_item
      Btrfs: remove BUG() in btrfs_extent_inline_ref_size
      Btrfs: convert to use btrfs_get_extent_inline_ref_type
      Btrfs: add a helper to retrive extent inline ref type
      btrfs: scrub: simplify scrub worker initialization
      btrfs: scrub: clean up division in scrub_find_csum
      btrfs: scrub: clean up division in __scrub_mark_bitmap
      btrfs: scrub: use bool for flush_all_writes
      btrfs: preserve i_mode if __btrfs_set_acl() fails
      btrfs: Remove extraneous chunk_objectid variable
      btrfs: Remove chunk_objectid argument from btrfs_make_block_group
      btrfs: Remove extra parentheses from condition in copy_items()
      ...

commit a0725ab0c7536076d5477264420ef420ebb64501
Merge: 3ee31b89d9b1 ef13ecbc134d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 7 11:59:42 2017 -0700

    Merge branch 'for-4.14/block' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
     "This is the first pull request for 4.14, containing most of the code
      changes. It's a quiet series this round, which I think we needed after
      the churn of the last few series. This contains:
    
       - Fix for a registration race in loop, from Anton Volkov.
    
       - Overflow complaint fix from Arnd for DAC960.
    
       - Series of drbd changes from the usual suspects.
    
       - Conversion of the stec/skd driver to blk-mq. From Bart.
    
       - A few BFQ improvements/fixes from Paolo.
    
       - CFQ improvement from Ritesh, allowing idling for group idle.
    
       - A few fixes found by Dan's smatch, courtesy of Dan.
    
       - A warning fixup for a race between changing the IO scheduler and
         device remova. From David Jeffery.
    
       - A few nbd fixes from Josef.
    
       - Support for cgroup info in blktrace, from Shaohua.
    
       - Also from Shaohua, new features in the null_blk driver to allow it
         to actually hold data, among other things.
    
       - Various corner cases and error handling fixes from Weiping Zhang.
    
       - Improvements to the IO stats tracking for blk-mq from me. Can
         drastically improve performance for fast devices and/or big
         machines.
    
       - Series from Christoph removing bi_bdev as being needed for IO
         submission, in preparation for nvme multipathing code.
    
       - Series from Bart, including various cleanups and fixes for switch
         fall through case complaints"
    
    * 'for-4.14/block' of git://git.kernel.dk/linux-block: (162 commits)
      kernfs: checking for IS_ERR() instead of NULL
      drbd: remove BIOSET_NEED_RESCUER flag from drbd_{md_,}io_bio_set
      drbd: Fix allyesconfig build, fix recent commit
      drbd: switch from kmalloc() to kmalloc_array()
      drbd: abort drbd_start_resync if there is no connection
      drbd: move global variables to drbd namespace and make some static
      drbd: rename "usermode_helper" to "drbd_usermode_helper"
      drbd: fix race between handshake and admin disconnect/down
      drbd: fix potential deadlock when trying to detach during handshake
      drbd: A single dot should be put into a sequence.
      drbd: fix rmmod cleanup, remove _all_ debugfs entries
      drbd: Use setup_timer() instead of init_timer() to simplify the code.
      drbd: fix potential get_ldev/put_ldev refcount imbalance during attach
      drbd: new disk-option disable-write-same
      drbd: Fix resource role for newly created resources in events2
      drbd: mark symbols static where possible
      drbd: Send P_NEG_ACK upon write error in protocol != C
      drbd: add explicit plugging when submitting batches
      drbd: change list_for_each_safe to while(list_first_entry_or_null)
      drbd: introduce drbd_recv_header_maybe_unplug
      ...

commit 58efbc9f5463308c43d812fd0748a4dee44c8a16
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Aug 22 23:45:59 2017 -0700

    Btrfs: fix blk_status_t/errno confusion
    
    This fixes several instances of blk_status_t and bare errno ints being
    mixed up, some of which are real bugs.
    
    In the normal case, 0 matches BLK_STS_OK, so we don't observe any
    effects of the missing conversion, but in case of errors or passes
    through the repair/retry paths, the errors get mixed up.
    
    The changes were identified using 'sparse', we don't have reports of the
    buggy behaviour.
    
    Fixes: 4e4cbee93d56 ("block: switch bios to blk_status_t")
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 080e2ebb8aa0..f45b61fe9a9a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3516,7 +3516,7 @@ static blk_status_t wait_dev_flush(struct btrfs_device *device)
 	struct bio *bio = device->flush_bio;
 
 	if (!device->flush_bio_sent)
-		return 0;
+		return BLK_STS_OK;
 
 	device->flush_bio_sent = 0;
 	wait_for_completion_io(&device->flush_wait);
@@ -3563,7 +3563,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 			continue;
 
 		write_dev_flush(dev);
-		dev->last_flush_error = 0;
+		dev->last_flush_error = BLK_STS_OK;
 	}
 
 	/* wait for all the barriers */

commit 74d46992e0d9dee7f1f376de0d56d31614c8a17a
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 23 19:10:32 2017 +0200

    block: replace bi_bdev with a gendisk pointer and partitions index
    
    This way we don't need a block_device structure to submit I/O.  The
    block_device has different life time rules from the gendisk and
    request_queue and is usually only available when the block device node
    is open.  Other callers need to explicitly create one (e.g. the lightnvm
    passthrough code, or the new nvme multipathing code).
    
    For the actual I/O path all that we need is the gendisk, which exists
    once per block device.  But given that the block layer also does
    partition remapping we additionally need a partition index, which is
    used for said remapping in generic_make_request.
    
    Note that all the block drivers generally want request_queue or
    sometimes the gendisk, so this removes a layer of indirection all
    over the stack.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 080e2ebb8aa0..0640c27e63e9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3499,7 +3499,7 @@ static void write_dev_flush(struct btrfs_device *device)
 
 	bio_reset(bio);
 	bio->bi_end_io = btrfs_end_empty_barrier;
-	bio->bi_bdev = device->bdev;
+	bio_set_dev(bio, device->bdev);
 	bio->bi_opf = REQ_OP_WRITE | REQ_SYNC | REQ_PREFLUSH;
 	init_completion(&device->flush_wait);
 	bio->bi_private = &device->flush_wait;

commit db95c876c568cef951fbbd4c0118cb5386e4bb99
Author: David Sterba <dsterba@suse.com>
Date:   Fri Aug 18 18:16:25 2017 +0200

    btrfs: submit superblock io with REQ_META and REQ_PRIO
    
    The superblock is also metadata of the filesystem so the relevant IO
    should be tagged as such. We also tag it as high priority, as it's the
    last block committed for metadata from a given transaction. Any delays
    would effectively block the whole transaction, also blocking any other
    operation holding the device_list_mutex.
    
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 90b967ae46d0..27d458640536 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3433,9 +3433,10 @@ static int write_dev_supers(struct btrfs_device *device,
 		 */
 		if (i == 0) {
 			ret = btrfsic_submit_bh(REQ_OP_WRITE,
-						REQ_SYNC | REQ_FUA, bh);
+				REQ_SYNC | REQ_FUA | REQ_META | REQ_PRIO, bh);
 		} else {
-			ret = btrfsic_submit_bh(REQ_OP_WRITE, REQ_SYNC, bh);
+			ret = btrfsic_submit_bh(REQ_OP_WRITE,
+				REQ_SYNC | REQ_META | REQ_PRIO, bh);
 		}
 		if (ret)
 			errors++;

commit 583b723151794e2ff1691f1510b4e43710293875
Author: Hans van Kranenburg <hans.van.kranenburg@mendix.com>
Date:   Fri Jul 28 08:31:28 2017 +0200

    btrfs: Do not use data_alloc_cluster in ssd mode
    
        This patch provides a band aid to improve the 'out of the box'
    behaviour of btrfs for disks that are detected as being an ssd.  In a
    general purpose mixed workload scenario, the current ssd mode causes
    overallocation of available raw disk space for data, while leaving
    behind increasing amounts of unused fragmented free space. This
    situation leads to early ENOSPC problems which are harming user
    experience and adoption of btrfs as a general purpose filesystem.
    
    This patch modifies the data extent allocation behaviour of the ssd mode
    to make it behave identical to nossd mode.  The metadata behaviour and
    additional ssd_spread option stay untouched so far.
    
    Recommendations for future development are to reconsider the current
    oversimplified nossd / ssd distinction and the broken detection
    mechanism based on the rotational attribute in sysfs and provide
    experienced users with a more flexible way to choose allocator behaviour
    for data and metadata, optimized for certain use cases, while keeping
    sane 'out of the box' default settings.  The internals of the current
    btrfs code have more potential than what currently gets exposed to the
    user to choose from.
    
        The SSD story...
    
        In the first year of btrfs development, around early 2008, btrfs
    gained a mount option which enables specific functionality for
    filesystems on solid state devices. The first occurance of this
    functionality is in commit e18e4809, labeled "Add mount -o ssd, which
    includes optimizations for seek free storage".
    
    The effect on allocating free space for doing (data) writes is to
    'cluster' writes together, writing them out in contiguous space, as
    opposed to a 'tetris' way of putting all separate writes into any free
    space fragment that fits (which is what the -o nossd behaviour does).
    
    A somewhat simplified explanation of what happens is that, when for
    example, the 'cluster' size is set to 2MiB, when we do some writes, the
    data allocator will search for a free space block that is 2MiB big, and
    put the writes in there. The ssd mode itself might allow a 2MiB cluster
    to be composed of multiple free space extents with some existing data in
    between, while the additional ssd_spread mount option kills off this
    option and requires fully free space.
    
    The idea behind this is (commit 536ac8ae): "The [...] clusters make it
    more likely a given IO will completely overwrite the ssd block, so it
    doesn't have to do an internal rwm cycle."; ssd block meaning nand erase
    block. So, effectively this means applying a "locality based algorithm"
    and trying to outsmart the actual ssd.
    
    Since then, various changes have been made to the involved code, but the
    basic idea is still present, and gets activated whenever the ssd mount
    option is active. This also happens by default, when the rotational flag
    as seen at /sys/block/<device>/queue/rotational is set to 0.
    
        However, there's a number of problems with this approach.
    
        First, what the optimization is trying to do is outsmart the ssd by
    assuming there is a relation between the physical address space of the
    block device as seen by btrfs and the actual physical storage of the
    ssd, and then adjusting data placement. However, since the introduction
    of the Flash Translation Layer (FTL) which is a part of the internal
    controller of an ssd, these attempts are futile. The use of good quality
    FTL in consumer ssd products might have been limited in 2008, but this
    situation has changed drastically soon after that time. Today, even the
    flash memory in your automatic cat feeding machine or your grandma's
    wheelchair has a full featured one.
    
    Second, the behaviour as described above results in the filesystem being
    filled up with badly fragmented free space extents because of relatively
    small pieces of space that are freed up by deletes, but not selected
    again as part of a 'cluster'. Since the algorithm prefers allocating a
    new chunk over going back to tetris mode, the end result is a filesystem
    in which all raw space is allocated, but which is composed of
    underutilized chunks with a 'shotgun blast' pattern of fragmented free
    space. Usually, the next problematic thing that happens is the
    filesystem wanting to allocate new space for metadata, which causes the
    filesystem to fail in spectacular ways.
    
    Third, the default mount options you get for an ssd ('ssd' mode enabled,
    'discard' not enabled), in combination with spreading out writes over
    the full address space and ignoring freed up space leads to worst case
    behaviour in providing information to the ssd itself, since it will
    never learn that all the free space left behind is actually free.  There
    are two ways to let an ssd know previously written data does not have to
    be preserved, which are sending explicit signals using discard or
    fstrim, or by simply overwriting the space with new data.  The worst
    case behaviour is the btrfs ssd_spread mount option in combination with
    not having discard enabled. It has a side effect of minimizing the reuse
    of free space previously written in.
    
    Fourth, the rotational flag in /sys/ does not reliably indicate if the
    device is a locally attached ssd. For example, iSCSI or NBD displays as
    non-rotational, while a loop device on an ssd shows up as rotational.
    
    The combination of the second and third problem effectively means that
    despite all the good intentions, the btrfs ssd mode reliably causes the
    ssd hardware and the filesystem structures and performance to be choked
    to death. The clickbait version of the title of this story would have
    been "Btrfs ssd optimizations considered harmful for ssds".
    
    The current nossd 'tetris' mode (even still without discard) allows a
    pattern of overwriting much more previously used space, causing many
    more implicit discards to happen because of the overwrite information
    the ssd gets. The actual location in the physical address space, as seen
    from the point of view of btrfs is irrelevant, because the actual writes
    to the low level flash are reordered anyway thanks to the FTL.
    
        Changes made in the code
    
    1. Make ssd mode data allocation identical to tetris mode, like nossd.
    2. Adjust and clean up filesystem mount messages so that we can easily
    identify if a kernel has this patch applied or not, when providing
    support to end users. Also, make better use of the *_and_info helpers to
    only trigger messages on actual state changes.
    
        Backporting notes
    
    Notes for whoever wants to backport this patch to their 4.9 LTS kernel:
    * First apply commit 951e7966 "btrfs: drop the nossd flag when
      remounting with -o ssd", or fixup the differences manually.
    * The rest of the conflicts are because of the fs_info refactoring. So,
      for example, instead of using fs_info, it's root->fs_info in
      extent-tree.c
    
    Signed-off-by: Hans van Kranenburg <hans.van.kranenburg@mendix.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 195634098f21..90b967ae46d0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3053,11 +3053,9 @@ int open_ctree(struct super_block *sb,
 	if (IS_ERR(fs_info->transaction_kthread))
 		goto fail_cleaner;
 
-	if (!btrfs_test_opt(fs_info, SSD) &&
-	    !btrfs_test_opt(fs_info, NOSSD) &&
+	if (!btrfs_test_opt(fs_info, NOSSD) &&
 	    !fs_info->fs_devices->rotating) {
-		btrfs_info(fs_info, "detected SSD devices, enabling SSD mode");
-		btrfs_set_opt(fs_info->mount_opt, SSD);
+		btrfs_set_and_info(fs_info, SSD, "enabling ssd optimizations");
 	}
 
 	/*

commit 43a0111103af2d358f6d2d671d8429ba169e53bb
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Fri Aug 18 16:38:07 2017 +0800

    btrfs: use btrfsic_submit_bio instead of submit_bio in write_dev_flush
    
    Although this bio has no data attached, it will reach this condition
    (bio->bi_opf & REQ_PREFLUSH) and then update the flush_gen of dev_state
    in __btrfsic_submit_bio. So we should still submit it through integrity
    checker. Otherwise, the integrity checker will throw the following warning
    when I mount a newly created btrfs filesystem.
    
    [10264.755497] btrfs: attempt to write superblock which references block M @29523968 (sdb1/1111654400/0) which is not flushed out of disk's write cache (block flush_gen=1, dev->flush_gen=0)!
    [10264.755498] btrfs: attempt to write superblock which references block M @29523968 (sdb1/37912576/0) which is not flushed out of disk's write cache (block flush_gen=1, dev->flush_gen=0)!
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3715478fffed..195634098f21 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3517,7 +3517,7 @@ static void write_dev_flush(struct btrfs_device *device)
 	init_completion(&device->flush_wait);
 	bio->bi_private = &device->flush_wait;
 
-	submit_bio(bio);
+	btrfsic_submit_bio(bio);
 	device->flush_bio_sent = 1;
 }
 

commit 44880fdc91bc4f6730e37f2cb6025b35c70b312d
Author: Anand Jain <anand.jain@oracle.com>
Date:   Sat Jul 29 17:50:09 2017 +0800

    btrfs: use appropriate define for the fsid
    
    Though BTRFS_FSID_SIZE and BTRFS_UUID_SIZE are of the same size, we
    should use the matching constant for the fsid buffer.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c2d3699a70bd..3715478fffed 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -529,7 +529,7 @@ static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
 				 struct extent_buffer *eb)
 {
 	struct btrfs_fs_devices *fs_devices = fs_info->fs_devices;
-	u8 fsid[BTRFS_UUID_SIZE];
+	u8 fsid[BTRFS_FSID_SIZE];
 	int ret = 1;
 
 	read_extent_buffer(eb, fsid, btrfs_header_fsid(), BTRFS_FSID_SIZE);
@@ -3681,7 +3681,7 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 		btrfs_set_stack_device_io_width(dev_item, dev->io_width);
 		btrfs_set_stack_device_sector_size(dev_item, dev->sector_size);
 		memcpy(dev_item->uuid, dev->uuid, BTRFS_UUID_SIZE);
-		memcpy(dev_item->fsid, dev->fs_devices->fsid, BTRFS_UUID_SIZE);
+		memcpy(dev_item->fsid, dev->fs_devices->fsid, BTRFS_FSID_SIZE);
 
 		flags = btrfs_super_flags(sb);
 		btrfs_set_super_flags(sb, flags | BTRFS_HEADER_FLAG_WRITTEN);
@@ -4120,7 +4120,7 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)
 		ret = -EINVAL;
 	}
 
-	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_UUID_SIZE) != 0) {
+	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_FSID_SIZE) != 0) {
 		btrfs_err(fs_info,
 			   "dev_item UUID does not match fsid: %pU != %pU",
 			   fs_info->fsid, sb->dev_item.fsid);

commit 4958aa6821c7c4e9682806bc4fea92250d020829
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 22 03:59:40 2017 +0200

    btrfs: drop chunk locks at the end of close_ctree
    
    The pinned chunks might be left over so we clean them but at this point
    of close_ctree, there's noone to race with, the locking can be removed.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 57a857142cda..c2d3699a70bd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3944,7 +3944,6 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	__btrfs_free_block_rsv(root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;
 
-	mutex_lock(&fs_info->chunk_mutex);
 	while (!list_empty(&fs_info->pinned_chunks)) {
 		struct extent_map *em;
 
@@ -3953,7 +3952,6 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 		list_del_init(&em->list);
 		free_extent_map(em);
 	}
-	mutex_unlock(&fs_info->chunk_mutex);
 }
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,

commit ea14b57fd1954fa3193e025224bbbeab7415c490
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 22 02:19:11 2017 +0200

    btrfs: fix spelling of snapshotting
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9b1f4ef54438..57a857142cda 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1343,7 +1343,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	atomic_set(&root->log_batch, 0);
 	atomic_set(&root->orphan_inodes, 0);
 	refcount_set(&root->refs, 1);
-	atomic_set(&root->will_be_snapshoted, 0);
+	atomic_set(&root->will_be_snapshotted, 0);
 	atomic64_set(&root->qgroup_meta_rsv, 0);
 	root->log_transid = 0;
 	root->log_transid_committed = -1;

commit 9f6d251033bc5bd0115c23fae8b6aac5f6263c2c
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 16 01:48:05 2017 +0200

    btrfs: use named constant for bdev blocksize
    
    Superblock is read and written using buffer heads, we need to set the
    bdev blocksize. The magic constant has been hardcoded in several places,
    so replace it with a named constant.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b72711ad7121..9b1f4ef54438 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2694,8 +2694,8 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_balance(fs_info);
 	btrfs_init_async_reclaim_work(&fs_info->async_reclaim_work);
 
-	sb->s_blocksize = 4096;
-	sb->s_blocksize_bits = blksize_bits(4096);
+	sb->s_blocksize = BTRFS_BDEV_BLOCKSIZE;
+	sb->s_blocksize_bits = blksize_bits(BTRFS_BDEV_BLOCKSIZE);
 
 	btrfs_init_btree_inode(fs_info);
 
@@ -3316,7 +3316,7 @@ int btrfs_read_dev_one_super(struct block_device *bdev, int copy_num,
 	if (bytenr + BTRFS_SUPER_INFO_SIZE >= i_size_read(bdev->bd_inode))
 		return -EINVAL;
 
-	bh = __bread(bdev, bytenr / 4096, BTRFS_SUPER_INFO_SIZE);
+	bh = __bread(bdev, bytenr / BTRFS_BDEV_BLOCKSIZE, BTRFS_SUPER_INFO_SIZE);
 	/*
 	 * If we fail to read from the underlying devices, as of now
 	 * the best option we have is to mark it EIO.
@@ -3409,7 +3409,7 @@ static int write_dev_supers(struct btrfs_device *device,
 		btrfs_csum_final(crc, sb->csum);
 
 		/* One reference for us, and we leave it for the caller */
-		bh = __getblk(device->bdev, bytenr / 4096,
+		bh = __getblk(device->bdev, bytenr / BTRFS_BDEV_BLOCKSIZE,
 			      BTRFS_SUPER_INFO_SIZE);
 		if (!bh) {
 			btrfs_err(device->fs_info,
@@ -3468,7 +3468,8 @@ static int wait_dev_supers(struct btrfs_device *device, int max_mirrors)
 		    device->commit_total_bytes)
 			break;
 
-		bh = __find_get_block(device->bdev, bytenr / 4096,
+		bh = __find_get_block(device->bdev,
+				      bytenr / BTRFS_BDEV_BLOCKSIZE,
 				      BTRFS_SUPER_INFO_SIZE);
 		if (!bh) {
 			errors++;

commit abbb3b8ebfec577390873d33076d56bc6e758939
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 16 00:50:33 2017 +0200

    btrfs: split write_dev_supers to two functions
    
    There are two independent parts, one that writes the superblocks and
    another that waits for completion. No functional changes, but cleanups,
    reformatting and comment updates.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a42ae7676759..b72711ad7121 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3373,19 +3373,17 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 }
 
 /*
- * this should be called twice, once with wait == 0 and
- * once with wait == 1.  When wait == 0 is done, all the buffer heads
- * we write are pinned.
+ * Write superblock @sb to the @device. Do not wait for completion, all the
+ * buffer heads we write are pinned.
  *
- * They are released when wait == 1 is done.
- * max_mirrors must be the same for both runs, and it indicates how
- * many supers on this one device should be written.
+ * Write @max_mirrors copies of the superblock, where 0 means default that fit
+ * the expected device size at commit time. Note that max_mirrors must be
+ * same for write and wait phases.
  *
- * max_mirrors == 0 means to write them all.
+ * Return number of errors when buffer head is not found or submission fails.
  */
 static int write_dev_supers(struct btrfs_device *device,
-			    struct btrfs_super_block *sb,
-			    int wait, int max_mirrors)
+			    struct btrfs_super_block *sb, int max_mirrors)
 {
 	struct buffer_head *bh;
 	int i;
@@ -3403,57 +3401,33 @@ static int write_dev_supers(struct btrfs_device *device,
 		    device->commit_total_bytes)
 			break;
 
-		if (wait) {
-			bh = __find_get_block(device->bdev, bytenr / 4096,
-					      BTRFS_SUPER_INFO_SIZE);
-			if (!bh) {
-				errors++;
-				continue;
-			}
-			wait_on_buffer(bh);
-			if (!buffer_uptodate(bh))
-				errors++;
+		btrfs_set_super_bytenr(sb, bytenr);
 
-			/* drop our reference */
-			brelse(bh);
+		crc = ~(u32)0;
+		crc = btrfs_csum_data((const char *)sb + BTRFS_CSUM_SIZE, crc,
+				      BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
+		btrfs_csum_final(crc, sb->csum);
 
-			/* drop the reference from the wait == 0 run */
-			brelse(bh);
+		/* One reference for us, and we leave it for the caller */
+		bh = __getblk(device->bdev, bytenr / 4096,
+			      BTRFS_SUPER_INFO_SIZE);
+		if (!bh) {
+			btrfs_err(device->fs_info,
+			    "couldn't get super buffer head for bytenr %llu",
+			    bytenr);
+			errors++;
 			continue;
-		} else {
-			btrfs_set_super_bytenr(sb, bytenr);
-
-			crc = ~(u32)0;
-			crc = btrfs_csum_data((const char *)sb +
-					      BTRFS_CSUM_SIZE, crc,
-					      BTRFS_SUPER_INFO_SIZE -
-					      BTRFS_CSUM_SIZE);
-			btrfs_csum_final(crc, sb->csum);
-
-			/*
-			 * one reference for us, and we leave it for the
-			 * caller
-			 */
-			bh = __getblk(device->bdev, bytenr / 4096,
-				      BTRFS_SUPER_INFO_SIZE);
-			if (!bh) {
-				btrfs_err(device->fs_info,
-				    "couldn't get super buffer head for bytenr %llu",
-				    bytenr);
-				errors++;
-				continue;
-			}
+		}
 
-			memcpy(bh->b_data, sb, BTRFS_SUPER_INFO_SIZE);
+		memcpy(bh->b_data, sb, BTRFS_SUPER_INFO_SIZE);
 
-			/* one reference for submit_bh */
-			get_bh(bh);
+		/* one reference for submit_bh */
+		get_bh(bh);
 
-			set_buffer_uptodate(bh);
-			lock_buffer(bh);
-			bh->b_end_io = btrfs_end_buffer_write_sync;
-			bh->b_private = device;
-		}
+		set_buffer_uptodate(bh);
+		lock_buffer(bh);
+		bh->b_end_io = btrfs_end_buffer_write_sync;
+		bh->b_private = device;
 
 		/*
 		 * we fua the first super.  The others we allow
@@ -3471,6 +3445,49 @@ static int write_dev_supers(struct btrfs_device *device,
 	return errors < i ? 0 : -1;
 }
 
+/*
+ * Wait for write completion of superblocks done by write_dev_supers,
+ * @max_mirrors same for write and wait phases.
+ *
+ * Return number of errors when buffer head is not found or not marked up to
+ * date.
+ */
+static int wait_dev_supers(struct btrfs_device *device, int max_mirrors)
+{
+	struct buffer_head *bh;
+	int i;
+	int errors = 0;
+	u64 bytenr;
+
+	if (max_mirrors == 0)
+		max_mirrors = BTRFS_SUPER_MIRROR_MAX;
+
+	for (i = 0; i < max_mirrors; i++) {
+		bytenr = btrfs_sb_offset(i);
+		if (bytenr + BTRFS_SUPER_INFO_SIZE >=
+		    device->commit_total_bytes)
+			break;
+
+		bh = __find_get_block(device->bdev, bytenr / 4096,
+				      BTRFS_SUPER_INFO_SIZE);
+		if (!bh) {
+			errors++;
+			continue;
+		}
+		wait_on_buffer(bh);
+		if (!buffer_uptodate(bh))
+			errors++;
+
+		/* drop our reference */
+		brelse(bh);
+
+		/* drop the reference from the writing run */
+		brelse(bh);
+	}
+
+	return errors < i ? 0 : -1;
+}
+
 /*
  * endio for the write_dev_flush, this will wake anyone waiting
  * for the barrier when it is done
@@ -3668,7 +3685,7 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 		flags = btrfs_super_flags(sb);
 		btrfs_set_super_flags(sb, flags | BTRFS_HEADER_FLAG_WRITTEN);
 
-		ret = write_dev_supers(dev, sb, 0, max_mirrors);
+		ret = write_dev_supers(dev, sb, max_mirrors);
 		if (ret)
 			total_errors++;
 	}
@@ -3691,7 +3708,7 @@ int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 		if (!dev->in_fs_metadata || !dev->writeable)
 			continue;
 
-		ret = write_dev_supers(dev, sb, 1, max_mirrors);
+		ret = wait_dev_supers(dev, max_mirrors);
 		if (ret)
 			total_errors++;
 	}

commit a4f78750ef1882e59bb4f947e216cf61ef2d67d2
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 29 18:37:49 2017 +0200

    btrfs: get fs_info from eb in btrfs_print_leaf, remove argument
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2f366044d891..a42ae7676759 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3984,7 +3984,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 					 fs_info->dirty_metadata_batch);
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_header_level(buf) == 0 && check_leaf(root, buf)) {
-		btrfs_print_leaf(fs_info, buf);
+		btrfs_print_leaf(buf);
 		ASSERT(0);
 	}
 #endif

commit bc3cce2378b9eeb420873b17664493e68fd07e8c
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Thu Mar 9 09:34:41 2017 +0800

    btrfs: Cleanup num_tolerated_disk_barrier_failures
    
    As we use per-chunk degradable check, the global
    num_tolerated_disk_barrier_failures is of no use.
    
    We can now remove it.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 552098e1b65b..2f366044d891 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3611,60 +3611,6 @@ int btrfs_get_num_tolerated_disk_barrier_failures(u64 flags)
 	return min_tolerated;
 }
 
-int btrfs_calc_num_tolerated_disk_barrier_failures(
-	struct btrfs_fs_info *fs_info)
-{
-	struct btrfs_ioctl_space_info space;
-	struct btrfs_space_info *sinfo;
-	u64 types[] = {BTRFS_BLOCK_GROUP_DATA,
-		       BTRFS_BLOCK_GROUP_SYSTEM,
-		       BTRFS_BLOCK_GROUP_METADATA,
-		       BTRFS_BLOCK_GROUP_DATA | BTRFS_BLOCK_GROUP_METADATA};
-	int i;
-	int c;
-	int num_tolerated_disk_barrier_failures =
-		(int)fs_info->fs_devices->num_devices;
-
-	for (i = 0; i < ARRAY_SIZE(types); i++) {
-		struct btrfs_space_info *tmp;
-
-		sinfo = NULL;
-		rcu_read_lock();
-		list_for_each_entry_rcu(tmp, &fs_info->space_info, list) {
-			if (tmp->flags == types[i]) {
-				sinfo = tmp;
-				break;
-			}
-		}
-		rcu_read_unlock();
-
-		if (!sinfo)
-			continue;
-
-		down_read(&sinfo->groups_sem);
-		for (c = 0; c < BTRFS_NR_RAID_TYPES; c++) {
-			u64 flags;
-
-			if (list_empty(&sinfo->block_groups[c]))
-				continue;
-
-			btrfs_get_block_group_info(&sinfo->block_groups[c],
-						   &space);
-			if (space.total_bytes == 0 || space.used_bytes == 0)
-				continue;
-			flags = space.flags;
-
-			num_tolerated_disk_barrier_failures = min(
-				num_tolerated_disk_barrier_failures,
-				btrfs_get_num_tolerated_disk_barrier_failures(
-					flags));
-		}
-		up_read(&sinfo->groups_sem);
-	}
-
-	return num_tolerated_disk_barrier_failures;
-}
-
 int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 {
 	struct list_head *head;

commit d10b82fe29cf3730ab7c1a487f0f62f10af5d301
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Jun 27 17:28:40 2017 +0800

    btrfs: Allow barrier_all_devices to do chunk level device check
    
    The last user of num_tolerated_disk_barrier_failures is
    barrier_all_devices().
    But it can be easily changed to the new per-chunk degradable check
    framework.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 78fc7f5ab773..552098e1b65b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3519,20 +3519,10 @@ static blk_status_t wait_dev_flush(struct btrfs_device *device)
 	return bio->bi_status;
 }
 
-static int check_barrier_error(struct btrfs_fs_devices *fsdevs)
+static int check_barrier_error(struct btrfs_fs_info *fs_info)
 {
-	int dev_flush_error = 0;
-	struct btrfs_device *dev;
-
-	list_for_each_entry_rcu(dev, &fsdevs->devices, dev_list) {
-		if (!dev->bdev || dev->last_flush_error)
-			dev_flush_error++;
-	}
-
-	if (dev_flush_error >
-	    fsdevs->fs_info->num_tolerated_disk_barrier_failures)
+	if (!btrfs_check_rw_degradable(fs_info))
 		return -EIO;
-
 	return 0;
 }
 
@@ -3587,7 +3577,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 		 * to arrive at the volume status. So error checking
 		 * is being pushed to a separate loop.
 		 */
-		return check_barrier_error(info->fs_devices);
+		return check_barrier_error(info);
 	}
 	return 0;
 }

commit 4330e183c9537df20952d4a9ee142c536fb8ae54
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Thu Mar 9 09:34:37 2017 +0800

    btrfs: Do chunk level check for degraded rw mount
    
    Now use the btrfs_check_rw_degradable() to check if we can mount in the
    degraded mode.
    
    With this patch, we can mount in the following case:
     # mkfs.btrfs -f -m raid1 -d single /dev/sdb /dev/sdc
     # wipefs -a /dev/sdc
     # mount /dev/sdb /mnt/btrfs -o degraded
     As the single data chunk is only on sdb, so it's OK to mount as
     degraded, as missing one device is OK for RAID1.
    
    But still fail in the following case as expected:
     # mkfs.btrfs -f -m raid1 -d single /dev/sdb /dev/sdc
     # wipefs -a /dev/sdb
     # mount /dev/sdc /mnt/btrfs -o degraded
     As the data chunk is only in sdb, so it's not OK to mount it as
     degraded.
    
    Reported-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Reported-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 080e2ebb8aa0..78fc7f5ab773 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3035,15 +3035,10 @@ int open_ctree(struct super_block *sb,
 		btrfs_err(fs_info, "failed to read block groups: %d", ret);
 		goto fail_sysfs;
 	}
-	fs_info->num_tolerated_disk_barrier_failures =
-		btrfs_calc_num_tolerated_disk_barrier_failures(fs_info);
-	if (fs_info->fs_devices->missing_devices >
-	     fs_info->num_tolerated_disk_barrier_failures &&
-	    !(sb->s_flags & MS_RDONLY)) {
+
+	if (!(sb->s_flags & MS_RDONLY) && !btrfs_check_rw_degradable(fs_info)) {
 		btrfs_warn(fs_info,
-"missing devices (%llu) exceeds the limit (%d), writeable mount is not allowed",
-			fs_info->fs_devices->missing_devices,
-			fs_info->num_tolerated_disk_barrier_failures);
+		"writeable mount is not allowed due to too many missing devices");
 		goto fail_sysfs;
 	}
 

commit 5c1aab1dd5445ed8bdcdbb575abc1b0d7ee5b2e7
Author: Nick Terrell <terrelln@fb.com>
Date:   Wed Aug 9 19:39:02 2017 -0700

    btrfs: Add zstd support
    
    Add zstd compression and decompression support to BtrFS. zstd at its
    fastest level compresses almost as well as zlib, while offering much
    faster compression and decompression, approaching lzo speeds.
    
    I benchmarked btrfs with zstd compression against no compression, lzo
    compression, and zlib compression. I benchmarked two scenarios. Copying
    a set of files to btrfs, and then reading the files. Copying a tarball
    to btrfs, extracting it to btrfs, and then reading the extracted files.
    After every operation, I call `sync` and include the sync time.
    Between every pair of operations I unmount and remount the filesystem
    to avoid caching. The benchmark files can be found in the upstream
    zstd source repository under
    `contrib/linux-kernel/{btrfs-benchmark.sh,btrfs-extract-benchmark.sh}`
    [1] [2].
    
    I ran the benchmarks on a Ubuntu 14.04 VM with 2 cores and 4 GiB of RAM.
    The VM is running on a MacBook Pro with a 3.1 GHz Intel Core i7 processor,
    16 GB of RAM, and a SSD.
    
    The first compression benchmark is copying 10 copies of the unzipped
    Silesia corpus [3] into a BtrFS filesystem mounted with
    `-o compress-force=Method`. The decompression benchmark times how long
    it takes to `tar` all 10 copies into `/dev/null`. The compression ratio is
    measured by comparing the output of `df` and `du`. See the benchmark file
    [1] for details. I benchmarked multiple zstd compression levels, although
    the patch uses zstd level 1.
    
    | Method  | Ratio | Compression MB/s | Decompression speed |
    |---------|-------|------------------|---------------------|
    | None    |  0.99 |              504 |                 686 |
    | lzo     |  1.66 |              398 |                 442 |
    | zlib    |  2.58 |               65 |                 241 |
    | zstd 1  |  2.57 |              260 |                 383 |
    | zstd 3  |  2.71 |              174 |                 408 |
    | zstd 6  |  2.87 |               70 |                 398 |
    | zstd 9  |  2.92 |               43 |                 406 |
    | zstd 12 |  2.93 |               21 |                 408 |
    | zstd 15 |  3.01 |               11 |                 354 |
    
    The next benchmark first copies `linux-4.11.6.tar` [4] to btrfs. Then it
    measures the compression ratio, extracts the tar, and deletes the tar.
    Then it measures the compression ratio again, and `tar`s the extracted
    files into `/dev/null`. See the benchmark file [2] for details.
    
    | Method | Tar Ratio | Extract Ratio | Copy (s) | Extract (s)| Read (s) |
    |--------|-----------|---------------|----------|------------|----------|
    | None   |      0.97 |          0.78 |    0.981 |      5.501 |    8.807 |
    | lzo    |      2.06 |          1.38 |    1.631 |      8.458 |    8.585 |
    | zlib   |      3.40 |          1.86 |    7.750 |     21.544 |   11.744 |
    | zstd 1 |      3.57 |          1.85 |    2.579 |     11.479 |    9.389 |
    
    [1] https://github.com/facebook/zstd/blob/dev/contrib/linux-kernel/btrfs-benchmark.sh
    [2] https://github.com/facebook/zstd/blob/dev/contrib/linux-kernel/btrfs-extract-benchmark.sh
    [3] http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia
    [4] https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.11.6.tar.xz
    
    zstd source repository: https://github.com/facebook/zstd
    
    Signed-off-by: Nick Terrell <terrelln@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 080e2ebb8aa0..04632f4de933 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2828,6 +2828,8 @@ int open_ctree(struct super_block *sb,
 	features |= BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF;
 	if (fs_info->compress_type == BTRFS_COMPRESS_LZO)
 		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;
+	else if (fs_info->compress_type == BTRFS_COMPRESS_ZSTD)
+		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_ZSTD;
 
 	if (features & BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA)
 		btrfs_info(fs_info, "has skinny extents");

commit bc98a42c1f7d0f886c0c1b75a92a004976a46d9f
Author: David Howells <dhowells@redhat.com>
Date:   Mon Jul 17 08:45:34 2017 +0100

    VFS: Convert sb->s_flags & MS_RDONLY to sb_rdonly(sb)
    
    Firstly by applying the following with coccinelle's spatch:
    
            @@ expression SB; @@
            -SB->s_flags & MS_RDONLY
            +sb_rdonly(SB)
    
    to effect the conversion to sb_rdonly(sb), then by applying:
    
            @@ expression A, SB; @@
            (
            -(!sb_rdonly(SB)) && A
            +!sb_rdonly(SB) && A
            |
            -A != (sb_rdonly(SB))
            +A != sb_rdonly(SB)
            |
            -A == (sb_rdonly(SB))
            +A == sb_rdonly(SB)
            |
            -!(sb_rdonly(SB))
            +!sb_rdonly(SB)
            |
            -A && (sb_rdonly(SB))
            +A && sb_rdonly(SB)
            |
            -A || (sb_rdonly(SB))
            +A || sb_rdonly(SB)
            |
            -(sb_rdonly(SB)) != A
            +sb_rdonly(SB) != A
            |
            -(sb_rdonly(SB)) == A
            +sb_rdonly(SB) == A
            |
            -(sb_rdonly(SB)) && A
            +sb_rdonly(SB) && A
            |
            -(sb_rdonly(SB)) || A
            +sb_rdonly(SB) || A
            )
    
            @@ expression A, B, SB; @@
            (
            -(sb_rdonly(SB)) ? 1 : 0
            +sb_rdonly(SB)
            |
            -(sb_rdonly(SB)) ? A : B
            +sb_rdonly(SB) ? A : B
            )
    
    to remove left over excess bracketage and finally by applying:
    
            @@ expression A, SB; @@
            (
            -(A & MS_RDONLY) != sb_rdonly(SB)
            +(bool)(A & MS_RDONLY) != sb_rdonly(SB)
            |
            -(A & MS_RDONLY) == sb_rdonly(SB)
            +(bool)(A & MS_RDONLY) == sb_rdonly(SB)
            )
    
    to make comparisons against the result of sb_rdonly() (which is a bool)
    work correctly.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 080e2ebb8aa0..4a9b40f604fa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2478,7 +2478,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 		return ret;
 	}
 
-	if (fs_info->sb->s_flags & MS_RDONLY) {
+	if (sb_rdonly(fs_info->sb)) {
 		ret = btrfs_commit_super(fs_info);
 		if (ret)
 			return ret;
@@ -2874,7 +2874,7 @@ int open_ctree(struct super_block *sb,
 
 	features = btrfs_super_compat_ro_flags(disk_super) &
 		~BTRFS_FEATURE_COMPAT_RO_SUPP;
-	if (!(sb->s_flags & MS_RDONLY) && features) {
+	if (!sb_rdonly(sb) && features) {
 		btrfs_err(fs_info,
 	"cannot mount read-write because of unsupported optional features (%llx)",
 		       features);
@@ -3039,7 +3039,7 @@ int open_ctree(struct super_block *sb,
 		btrfs_calc_num_tolerated_disk_barrier_failures(fs_info);
 	if (fs_info->fs_devices->missing_devices >
 	     fs_info->num_tolerated_disk_barrier_failures &&
-	    !(sb->s_flags & MS_RDONLY)) {
+	    !sb_rdonly(sb)) {
 		btrfs_warn(fs_info,
 "missing devices (%llu) exceeds the limit (%d), writeable mount is not allowed",
 			fs_info->fs_devices->missing_devices,
@@ -3102,7 +3102,7 @@ int open_ctree(struct super_block *sb,
 	if (ret)
 		goto fail_qgroup;
 
-	if (!(sb->s_flags & MS_RDONLY)) {
+	if (!sb_rdonly(sb)) {
 		ret = btrfs_cleanup_fs_roots(fs_info);
 		if (ret)
 			goto fail_qgroup;
@@ -3128,7 +3128,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_qgroup;
 	}
 
-	if (sb->s_flags & MS_RDONLY)
+	if (sb_rdonly(sb))
 		return 0;
 
 	if (btrfs_test_opt(fs_info, CLEAR_CACHE) &&
@@ -3928,7 +3928,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 
 	cancel_work_sync(&fs_info->async_reclaim_work);
 
-	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
+	if (!sb_rdonly(fs_info->sb)) {
 		/*
 		 * If the cleaner thread is stopped and there are
 		 * block groups queued for removal, the deletion will be

commit bc243704fb3c97f3631994bbe543782a09482afb
Merge: 0ffff118b16b c3cfb6563075
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 14 22:55:52 2017 -0700

    Merge branch 'for-4.13-part2' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs fixes from David Sterba:
     "We've identified and fixed a silent corruption (introduced by code in
      the first pull), a fixup after the blk_status_t merge and two fixes to
      incremental send that Filipe has been hunting for some time"
    
    * 'for-4.13-part2' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:
      Btrfs: fix unexpected return value of bio_readpage_error
      btrfs: btrfs_create_repair_bio never fails, skip error handling
      btrfs: cloned bios must not be iterated by bio_for_each_segment_all
      Btrfs: fix write corruption due to bio cloning on raid5/6
      Btrfs: incremental send, fix invalid memory access
      Btrfs: incremental send, fix invalid path for link commands

commit c09abff87f90c81d74b6483837a665f97448a475
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jul 13 18:10:07 2017 +0200

    btrfs: cloned bios must not be iterated by bio_for_each_segment_all
    
    We've started using cloned bios more in 4.13, there are some specifics
    regarding the iteration.  Filipe found [1] that the raid56 iterated a
    cloned bio using bio_for_each_segment_all, which is incorrect. The
    cloned bios have wrong bi_vcnt and this could lead to silent
    corruptions.  This patch adds assertions to all remaining
    bio_for_each_segment_all cases.
    
    [1] https://patchwork.kernel.org/patch/9838535/
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b6758892874f..075beedb4352 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -964,6 +964,7 @@ static int btree_csum_one_bio(struct bio *bio)
 	struct btrfs_root *root;
 	int i, ret = 0;
 
+	ASSERT(!bio_flagged(bio, BIO_CLONED));
 	bio_for_each_segment_all(bvec, bio, i) {
 		root = BTRFS_I(bvec->bv_page->mapping->host)->root;
 		ret = csum_dirty_buffer(root->fs_info, bvec->bv_page);

commit a4c20b9a574b9720acf6c647eaff5e7e1e688086
Merge: 9b51f04424e1 e3efe3db932b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 6 08:59:41 2017 -0700

    Merge branch 'for-4.13' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu
    
    Pull percpu updates from Tejun Heo:
     "These are the percpu changes for the v4.13-rc1 merge window. There are
      a couple visibility related changes - tracepoints and allocator stats
      through debugfs, along with __ro_after_init markings and a cosmetic
      rename in percpu_counter.
    
      Please note that the simple O(#elements_in_the_chunk) area allocator
      used by percpu allocator is again showing scalability issues,
      primarily with bpf allocating and freeing large number of counters.
      Dennis is working on the replacement allocator and the percpu
      allocator will be seeing increased churns in the coming cycles"
    
    * 'for-4.13' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu:
      percpu: fix static checker warnings in pcpu_destroy_chunk
      percpu: fix early calls for spinlock in pcpu_stats
      percpu: resolve err may not be initialized in pcpu_alloc
      percpu_counter: Rename __percpu_counter_add to percpu_counter_add_batch
      percpu: add tracepoint support for percpu memory
      percpu: expose statistics about percpu memory via debugfs
      percpu: migrate percpu data structures to internal header
      percpu: add missing lockdep_assert_held to func pcpu_free_area
      mark most percpu globals as __ro_after_init

commit 8c27cb3566762613a23c080e3db7d0501af9a787
Merge: 7114f51fcb97 848c23b78faf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 5 16:41:23 2017 -0700

    Merge branch 'for-4.13-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux
    
    Pull btrfs updates from David Sterba:
     "The core updates improve error handling (mostly related to bios), with
      the usual incremental work on the GFP_NOFS (mis)use removal,
      refactoring or cleanups. Except the two top patches, all have been in
      for-next for an extensive amount of time.
    
      User visible changes:
    
       - statx support
    
       - quota override tunable
    
       - improved compression thresholds
    
       - obsoleted mount option alloc_start
    
      Core updates:
    
       - bio-related updates:
           - faster bio cloning
           - no allocation failures
           - preallocated flush bios
    
       - more kvzalloc use, memalloc_nofs protections, GFP_NOFS updates
    
       - prep work for btree_inode removal
    
       - dir-item validation
    
       - qgoup fixes and updates
    
       - cleanups:
           - removed unused struct members, unused code, refactoring
           - argument refactoring (fs_info/root, caller -> callee sink)
           - SEARCH_TREE ioctl docs"
    
    * 'for-4.13-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux: (115 commits)
      btrfs: Remove false alert when fiemap range is smaller than on-disk extent
      btrfs: Don't clear SGID when inheriting ACLs
      btrfs: fix integer overflow in calc_reclaim_items_nr
      btrfs: scrub: fix target device intialization while setting up scrub context
      btrfs: qgroup: Fix qgroup reserved space underflow by only freeing reserved ranges
      btrfs: qgroup: Introduce extent changeset for qgroup reserve functions
      btrfs: qgroup: Fix qgroup reserved space underflow caused by buffered write and quotas being enabled
      btrfs: qgroup: Return actually freed bytes for qgroup release or free data
      btrfs: qgroup: Cleanup btrfs_qgroup_prepare_account_extents function
      btrfs: qgroup: Add quick exit for non-fs extents
      Btrfs: rework delayed ref total_bytes_pinned accounting
      Btrfs: return old and new total ref mods when adding delayed refs
      Btrfs: always account pinned bytes when dropping a tree block ref
      Btrfs: update total_bytes_pinned when pinning down extents
      Btrfs: make BUG_ON() in add_pinned_bytes() an ASSERT()
      Btrfs: make add_pinned_bytes() take an s64 num_bytes instead of u64
      btrfs: fix validation of XATTR_ITEM dir items
      btrfs: Verify dir_item in iterate_object_props
      btrfs: Check name_len before in btrfs_del_root_ref
      btrfs: Check name_len before reading btrfs_get_name
      ...

commit 66b4993e95c17e0ee30f0d72f0d6e00e5c035a98
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 15 16:20:43 2017 +0200

    btrfs: move dev stats accounting out of wait_dev_flush
    
    We should really just wait in wait_dev_flush and let the caller decide
    what to do with the error value.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 917e29167580..b6758892874f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3512,7 +3512,6 @@ static void write_dev_flush(struct btrfs_device *device)
  */
 static int wait_dev_flush(struct btrfs_device *device)
 {
-	int ret = 0;
 	struct bio *bio = device->flush_bio;
 
 	if (!device->flush_bio_sent)
@@ -3521,13 +3520,7 @@ static int wait_dev_flush(struct btrfs_device *device)
 	device->flush_bio_sent = 0;
 	wait_for_completion_io(&device->flush_wait);
 
-	if (bio->bi_error) {
-		ret = bio->bi_error;
-		btrfs_dev_stat_inc_and_print(device,
-				BTRFS_DEV_STAT_FLUSH_ERRS);
-	}
-
-	return ret;
+	return bio->bi_error;
 }
 
 static int check_barrier_error(struct btrfs_fs_devices *fsdevs)
@@ -3586,6 +3579,8 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 		ret = wait_dev_flush(dev);
 		if (ret) {
 			dev->last_flush_error = ret;
+			btrfs_dev_stat_inc_and_print(dev,
+					BTRFS_DEV_STAT_FLUSH_ERRS);
 			errors_wait++;
 		}
 	}

commit 2980d5745fa0beeaab4c22e25bea4faa54f7d9f7
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 15 16:04:26 2017 +0200

    btrfs: account as waiting for IO, while waiting fot the flush bio completion
    
    Similar to what submit_bio_wait does, we should account for IO while
    waiting for a bio completion. This has marginal visible effects, flush
    bio is short-lived.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bfcbab3a7607..917e29167580 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3519,7 +3519,7 @@ static int wait_dev_flush(struct btrfs_device *device)
 		return 0;
 
 	device->flush_bio_sent = 0;
-	wait_for_completion(&device->flush_wait);
+	wait_for_completion_io(&device->flush_wait);
 
 	if (bio->bi_error) {
 		ret = bio->bi_error;

commit e0ae999414238aa9c0a116844813982effb68a02
Author: David Sterba <dsterba@suse.com>
Date:   Tue Jun 6 17:06:06 2017 +0200

    btrfs: preallocate device flush bio
    
    For devices that support flushing, we allocate a bio, submit, wait for
    it and then free it. The bio allocation does not fail so ENOMEM is not a
    problem but we still may unnecessarily stress the allocation subsystem.
    
    Instead, we can allocate the bio at the same time we allocate the device
    and reuse it each time we need to flush the barriers. The bio is reset
    before each use. Reference counting is simplified to just device
    allocation (get) and freeing (put).
    
    The bio used to be submitted through the integrity checker which will
    find out that bio has no data attached and call submit_bio.
    
    Status of the bio in flight needs to be tracked separately in case the
    device caches get switched off between write and wait.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2ac0a35f4450..bfcbab3a7607 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3481,9 +3481,7 @@ static int write_dev_supers(struct btrfs_device *device,
  */
 static void btrfs_end_empty_barrier(struct bio *bio)
 {
-	if (bio->bi_private)
-		complete(bio->bi_private);
-	bio_put(bio);
+	complete(bio->bi_private);
 }
 
 /*
@@ -3493,26 +3491,20 @@ static void btrfs_end_empty_barrier(struct bio *bio)
 static void write_dev_flush(struct btrfs_device *device)
 {
 	struct request_queue *q = bdev_get_queue(device->bdev);
-	struct bio *bio;
+	struct bio *bio = device->flush_bio;
 
 	if (!test_bit(QUEUE_FLAG_WC, &q->queue_flags))
 		return;
 
-	/*
-	 * one reference for us, and we leave it for the
-	 * caller
-	 */
-	device->flush_bio = NULL;
-	bio = btrfs_io_bio_alloc(0);
+	bio_reset(bio);
 	bio->bi_end_io = btrfs_end_empty_barrier;
 	bio->bi_bdev = device->bdev;
 	bio->bi_opf = REQ_OP_WRITE | REQ_SYNC | REQ_PREFLUSH;
 	init_completion(&device->flush_wait);
 	bio->bi_private = &device->flush_wait;
-	device->flush_bio = bio;
 
-	bio_get(bio);
-	btrfsic_submit_bio(bio);
+	submit_bio(bio);
+	device->flush_bio_sent = 1;
 }
 
 /*
@@ -3523,9 +3515,10 @@ static int wait_dev_flush(struct btrfs_device *device)
 	int ret = 0;
 	struct bio *bio = device->flush_bio;
 
-	if (!bio)
+	if (!device->flush_bio_sent)
 		return 0;
 
+	device->flush_bio_sent = 0;
 	wait_for_completion(&device->flush_wait);
 
 	if (bio->bi_error) {
@@ -3534,10 +3527,6 @@ static int wait_dev_flush(struct btrfs_device *device)
 				BTRFS_DEV_STAT_FLUSH_ERRS);
 	}
 
-	/* drop the reference from the wait == 0 run */
-	bio_put(bio);
-	device->flush_bio = NULL;
-
 	return ret;
 }
 

commit 104b4e5139fe384431ac11c3b8a6cf4a529edf4a
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Jun 20 21:01:20 2017 +0300

    percpu_counter: Rename __percpu_counter_add to percpu_counter_add_batch
    
    Currently, percpu_counter_add is a wrapper around __percpu_counter_add
    which is preempt safe due to explicit calls to preempt_disable.  Given
    how __ prefix is used in percpu related interfaces, the naming
    unfortunately creates the false sense that __percpu_counter_add is
    less safe than percpu_counter_add.  In terms of context-safety,
    they're equivalent.  The only difference is that the __ version takes
    a batch parameter.
    
    Make this a bit more explicit by just renaming __percpu_counter_add to
    percpu_counter_add_batch.
    
    This patch doesn't cause any functional changes.
    
    tj: Minor updates to patch description for clarity.  Cosmetic
        indentation updates.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Chris Mason <clm@fb.com>
    Cc: Josef Bacik <jbacik@fb.com>
    Cc: David Sterba <dsterba@suse.com>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Jan Kara <jack@suse.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: linux-mm@kvack.org
    Cc: "David S. Miller" <davem@davemloft.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 061c1d1f774f..eb5c95569300 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1255,9 +1255,9 @@ void clean_tree_block(struct btrfs_fs_info *fs_info,
 		btrfs_assert_tree_locked(buf);
 
 		if (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &buf->bflags)) {
-			__percpu_counter_add(&fs_info->dirty_metadata_bytes,
-					     -buf->len,
-					     fs_info->dirty_metadata_batch);
+			percpu_counter_add_batch(&fs_info->dirty_metadata_bytes,
+						 -buf->len,
+						 fs_info->dirty_metadata_batch);
 			/* ugh, clear_extent_buffer_dirty needs to lock the page */
 			btrfs_set_lock_blocking(buf);
 			clear_extent_buffer_dirty(buf);
@@ -4046,9 +4046,9 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 			buf->start, transid, fs_info->generation);
 	was_dirty = set_extent_buffer_dirty(buf);
 	if (!was_dirty)
-		__percpu_counter_add(&fs_info->dirty_metadata_bytes,
-				     buf->len,
-				     fs_info->dirty_metadata_batch);
+		percpu_counter_add_batch(&fs_info->dirty_metadata_bytes,
+					 buf->len,
+					 fs_info->dirty_metadata_batch);
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_header_level(buf) == 0 && check_leaf(root, buf)) {
 		btrfs_print_leaf(fs_info, buf);

commit fac03c8daeb581e2bc38e5a8c0c6a42cf87cf1c3
Author: David Sterba <dsterba@suse.com>
Date:   Thu Jun 15 19:10:03 2017 +0200

    btrfs: move fs_info::fs_frozen to the flags
    
    We can keep the state among the other fs_info flags, there's no reason
    why fs_frozen would need to be separate.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2b00ebff13f8..2ac0a35f4450 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2661,7 +2661,6 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->qgroup_op_seq, 0);
 	atomic_set(&fs_info->reada_works_cnt, 0);
 	atomic64_set(&fs_info->tree_mod_seq, 0);
-	fs_info->fs_frozen = 0;
 	fs_info->sb = sb;
 	fs_info->max_inline = BTRFS_DEFAULT_MAX_INLINE;
 	fs_info->metadata_ratio = 0;

commit 4fc6441aac75893b4f32415f693d001f290d7d5b
Author: Anand Jain <anand.jain@oracle.com>
Date:   Tue Jun 13 17:05:41 2017 +0800

    btrfs: wait part of the write_dev_flush() can be separated out
    
    Submit and wait parts of write_dev_flush() can be split into two
    separate functions for better readability.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 528eef955060..2b00ebff13f8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3488,37 +3488,16 @@ static void btrfs_end_empty_barrier(struct bio *bio)
 }
 
 /*
- * trigger flushes for one the devices.  If you pass wait == 0, the flushes are
- * sent down.  With wait == 1, it waits for the previous flush.
- *
- * any device where the flush fails with eopnotsupp are flagged as not-barrier
- * capable
+ * Submit a flush request to the device if it supports it. Error handling is
+ * done in the waiting counterpart.
  */
-static int write_dev_flush(struct btrfs_device *device, int wait)
+static void write_dev_flush(struct btrfs_device *device)
 {
 	struct request_queue *q = bdev_get_queue(device->bdev);
 	struct bio *bio;
-	int ret = 0;
 
 	if (!test_bit(QUEUE_FLAG_WC, &q->queue_flags))
-		return 0;
-
-	if (wait) {
-		bio = device->flush_bio;
-		wait_for_completion(&device->flush_wait);
-
-		if (bio->bi_error) {
-			ret = bio->bi_error;
-			btrfs_dev_stat_inc_and_print(device,
-				BTRFS_DEV_STAT_FLUSH_ERRS);
-		}
-
-		/* drop the reference from the wait == 0 run */
-		bio_put(bio);
-		device->flush_bio = NULL;
-
-		return ret;
-	}
+		return;
 
 	/*
 	 * one reference for us, and we leave it for the
@@ -3535,8 +3514,32 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 	bio_get(bio);
 	btrfsic_submit_bio(bio);
+}
 
-	return 0;
+/*
+ * If the flush bio has been submitted by write_dev_flush, wait for it.
+ */
+static int wait_dev_flush(struct btrfs_device *device)
+{
+	int ret = 0;
+	struct bio *bio = device->flush_bio;
+
+	if (!bio)
+		return 0;
+
+	wait_for_completion(&device->flush_wait);
+
+	if (bio->bi_error) {
+		ret = bio->bi_error;
+		btrfs_dev_stat_inc_and_print(device,
+				BTRFS_DEV_STAT_FLUSH_ERRS);
+	}
+
+	/* drop the reference from the wait == 0 run */
+	bio_put(bio);
+	device->flush_bio = NULL;
+
+	return ret;
 }
 
 static int check_barrier_error(struct btrfs_fs_devices *fsdevs)
@@ -3577,7 +3580,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 		if (!dev->in_fs_metadata || !dev->writeable)
 			continue;
 
-		write_dev_flush(dev, 0);
+		write_dev_flush(dev);
 		dev->last_flush_error = 0;
 	}
 
@@ -3592,7 +3595,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 		if (!dev->in_fs_metadata || !dev->writeable)
 			continue;
 
-		ret = write_dev_flush(dev, 1);
+		ret = wait_dev_flush(dev);
 		if (ret) {
 			dev->last_flush_error = ret;
 			errors_wait++;

commit cea7c8bf77209ba11350e9c6f541064c820a174c
Author: Anand Jain <anand.jain@oracle.com>
Date:   Tue Jun 13 17:05:40 2017 +0800

    btrfs: remove redundant null bdev counting during flush submission
    
    There is no extra benefit to count null bdev during the submit loop,
    as these null devices will be anyway checked during command
    completion device loop just after the submit loop. We are holding the
    device_list_mutex, the device->bdev status won't change in between.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1e90469cc0d2..528eef955060 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3564,7 +3564,6 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 {
 	struct list_head *head;
 	struct btrfs_device *dev;
-	int errors_send = 0;
 	int errors_wait = 0;
 	int ret;
 
@@ -3573,10 +3572,8 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 	list_for_each_entry_rcu(dev, head, dev_list) {
 		if (dev->missing)
 			continue;
-		if (!dev->bdev) {
-			errors_send++;
+		if (!dev->bdev)
 			continue;
-		}
 		if (!dev->in_fs_metadata || !dev->writeable)
 			continue;
 
@@ -3602,7 +3599,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 		}
 	}
 
-	if (errors_send || errors_wait) {
+	if (errors_wait) {
 		/*
 		 * At some point we need the status of all disks
 		 * to arrive at the volume status. So error checking

commit 12b9bf0b942ecca695fe709ea754091918d88b01
Author: Anand Jain <anand.jain@oracle.com>
Date:   Tue Jun 13 17:32:29 2017 +0800

    btrfs: write_dev_flush does not return ENOMEM anymore
    
    Since commit "btrfs: btrfs_io_bio_alloc never fails, skip error handling"
    write_dev_flush will not return ENOMEM in the sending part. We do not
    need to check for it in the callers.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ updated changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8b57c280e5cd..1e90469cc0d2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3505,13 +3505,6 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 	if (wait) {
 		bio = device->flush_bio;
-		if (!bio)
-			/*
-			 * This means the alloc has failed with ENOMEM, however
-			 * here we return 0, as its not a device error.
-			 */
-			return 0;
-
 		wait_for_completion(&device->flush_wait);
 
 		if (bio->bi_error) {
@@ -3548,25 +3541,16 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 static int check_barrier_error(struct btrfs_fs_devices *fsdevs)
 {
-	int submit_flush_error = 0;
 	int dev_flush_error = 0;
 	struct btrfs_device *dev;
-	int tolerance;
 
 	list_for_each_entry_rcu(dev, &fsdevs->devices, dev_list) {
-		if (!dev->bdev) {
-			submit_flush_error++;
-			dev_flush_error++;
-			continue;
-		}
-		if (dev->last_flush_error == -ENOMEM)
-			submit_flush_error++;
-		if (dev->last_flush_error && dev->last_flush_error != -ENOMEM)
+		if (!dev->bdev || dev->last_flush_error)
 			dev_flush_error++;
 	}
 
-	tolerance = fsdevs->fs_info->num_tolerated_disk_barrier_failures;
-	if (submit_flush_error > tolerance || dev_flush_error > tolerance)
+	if (dev_flush_error >
+	    fsdevs->fs_info->num_tolerated_disk_barrier_failures)
 		return -EIO;
 
 	return 0;
@@ -3596,10 +3580,8 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 		if (!dev->in_fs_metadata || !dev->writeable)
 			continue;
 
-		ret = write_dev_flush(dev, 0);
-		if (ret)
-			errors_send++;
-		dev->last_flush_error = ret;
+		write_dev_flush(dev, 0);
+		dev->last_flush_error = 0;
 	}
 
 	/* wait for all the barriers */
@@ -3620,16 +3602,6 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 		}
 	}
 
-	/*
-	 * Try hard in case of flush. Lets say, in RAID1 we have
-	 * the following situation
-	 *  dev1: EIO dev2: ENOMEM
-	 * this is not a fatal error as we hope to recover from
-	 * ENOMEM in the next attempt to flush.
-	 * But the following is considered as fatal
-	 *  dev1: ENOMEM dev2: ENOMEM
-	 *  dev1: bdev == NULL dev2: ENOMEM
-	 */
 	if (errors_send || errors_wait) {
 		/*
 		 * At some point we need the status of all disks

commit c5e4c3d7503453832444475641988ffa02b88b6d
Author: David Sterba <dsterba@suse.com>
Date:   Mon Jun 12 17:29:41 2017 +0200

    btrfs: sink gfp parameter to btrfs_io_bio_alloc
    
    We can hardcode GFP_NOFS to btrfs_io_bio_alloc, although it means we
    change it back from GFP_KERNEL in scrub. I'd rather save a few stack
    bytes from not passing the gfp flags in the remaining, more imporatant,
    contexts and the bio allocating API now looks more consistent.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9f2ffe2c6afb..8b57c280e5cd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3532,7 +3532,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 	 * caller
 	 */
 	device->flush_bio = NULL;
-	bio = btrfs_io_bio_alloc(GFP_NOFS, 0);
+	bio = btrfs_io_bio_alloc(0);
 	bio->bi_end_io = btrfs_end_empty_barrier;
 	bio->bi_bdev = device->bdev;
 	bio->bi_opf = REQ_OP_WRITE | REQ_SYNC | REQ_PREFLUSH;

commit e4f56903863c793bc1d181f7f0b6244ea5753338
Author: David Sterba <dsterba@suse.com>
Date:   Fri Jun 2 17:38:30 2017 +0200

    btrfs: btrfs_io_bio_alloc never fails, skip error handling
    
    Update direct callers of btrfs_io_bio_alloc that do error handling, that
    we can now remove.
    
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cb79bce3a972..9f2ffe2c6afb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3533,9 +3533,6 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 	 */
 	device->flush_bio = NULL;
 	bio = btrfs_io_bio_alloc(GFP_NOFS, 0);
-	if (!bio)
-		return -ENOMEM;
-
 	bio->bi_end_io = btrfs_end_empty_barrier;
 	bio->bi_bdev = device->bdev;
 	bio->bi_opf = REQ_OP_WRITE | REQ_SYNC | REQ_PREFLUSH;

commit 4b5faeac4688174fd523f2a22b7d70d5a96842fb
Author: David Sterba <dsterba@suse.com>
Date:   Tue Mar 28 12:06:05 2017 +0200

    btrfs: use generic slab for for btrfs_transaction
    
    Observing the number of slab objects of btrfs_transaction, there's just
    one active on an almost quiescent filesystem, and the number of objects
    goes to about ten when sync is in progress. Then the nubmer goes down to
    1.  This matches the expectations of the transaction lifetime.
    
    For such use the separate slab cache is not justified, as we do not
    reuse objects frequently. For the shortlived transaction, the generic
    slab (size 512) should be ok. We can optimistically expect that the 512
    slabs are not all used (fragmentation) and there are free slots to take
    when we do the allocation, compared to potentially allocating a whole new
    page for the separate slab.
    
    We'll lose the stats about the object use, which could be added later if
    we really need them.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cdc28ad7f1ed..cb79bce3a972 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4624,11 +4624,6 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 
 	cur_trans->state =TRANS_STATE_COMPLETED;
 	wake_up(&cur_trans->commit_wait);
-
-	/*
-	memset(cur_trans, 0, sizeof(*cur_trans));
-	kmem_cache_free(btrfs_transaction_cachep, cur_trans);
-	*/
 }
 
 static int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info)

commit 3189ff778630d9ce8a9f2fda9f8ae4510cceb154
Author: Jeff Layton <jlayton@redhat.com>
Date:   Thu May 25 06:39:52 2017 -0400

    btrfs: btrfs_wait_tree_block_writeback can be void return
    
    Nothing checks its return value.
    
    Is it safe to skip checking return value of btrfs_wait_tree_block_writeback?
    
    Liu Bo: I think yes, it's used in walk_log_tree which is called in two
    places, free_log_tree and log replay.  For free_log_tree, it waits for
    any running writeback of the extent buffer under freeing to finish in
    case we need to access the eb pointer from page->private, and it's OK to
    not check the return value, while for log replay, it's doesn't wait
    because wc->wait is not set. So neither cares about the writeback error.
    
    Signed-off-by: Jeff Layton <jlayton@redhat.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    [ added more explanation to changelog, from Liu Bo ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bfeb5c12e3ff..cdc28ad7f1ed 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1223,10 +1223,10 @@ int btrfs_write_tree_block(struct extent_buffer *buf)
 					buf->start + buf->len - 1);
 }
 
-int btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
+void btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
 {
-	return filemap_fdatawait_range(buf->pages[0]->mapping,
-				       buf->start, buf->start + buf->len - 1);
+	filemap_fdatawait_range(buf->pages[0]->mapping,
+			        buf->start, buf->start + buf->len - 1);
 }
 
 struct extent_buffer *read_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr,

commit c9fed2bb61c4050ff01c4337e880a546fde5677d
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 13 19:11:04 2017 +0200

    btrfs: remove unused member list from btrfs_end_io_wq
    
    The end io work queue items have been tracked by the work queues since
    "Btrfs: Add async worker threads for pre and post IO checksumming"
    (8b7128429235d9bd72cfd5e) (2008).
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f896fa1dc070..bfeb5c12e3ff 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -89,7 +89,6 @@ struct btrfs_end_io_wq {
 	struct btrfs_fs_info *info;
 	int error;
 	enum btrfs_wq_endio_type metadata;
-	struct list_head list;
 	struct btrfs_work work;
 };
 

commit b297c9f68f4ac61c259dbe529ceb74910f25e281
Author: David Sterba <dsterba@suse.com>
Date:   Thu Apr 13 19:11:04 2017 +0200

    btrfs: remove unused member list from async_submit_bio
    
    The list used to track checksums in the early version (2.6.29), but I
    was able not pinpoint the commit that stopped using it. Everything
    apparently works without it for a long time.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d8ad30fdeee6..f896fa1dc070 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -121,7 +121,6 @@ struct async_submit_bio {
 	void *private_data;
 	struct btrfs_fs_info *fs_info;
 	struct bio *bio;
-	struct list_head list;
 	extent_submit_bio_hook_t *submit_bio_start;
 	extent_submit_bio_hook_t *submit_bio_done;
 	int mirror_num;

commit c6100a4b4e3d1650deafda45e49571b83270c714
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri May 5 11:57:13 2017 -0400

    Btrfs: replace tree->mapping with tree->private_data
    
    For extent_io tree's we have carried the address_mapping of the inode
    around in the io tree in order to pull the inode back out for calling
    into various tree ops hooks.  This works fine when everything that has
    an extent_io_tree has an inode.  But we are going to remove the
    btree_inode, so we need to change this.  Instead just have a generic
    void * for private data that we can initialize with, and have all the
    tree ops use that instead.  This had a lot of cascading changes but
    should be relatively straightforward.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ minor reordering of the callback prototypes ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9b8df5aaf76e..d8ad30fdeee6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -118,7 +118,8 @@ void btrfs_end_io_wq_exit(void)
  * just before they are sent down the IO stack.
  */
 struct async_submit_bio {
-	struct inode *inode;
+	void *private_data;
+	struct btrfs_fs_info *fs_info;
 	struct bio *bio;
 	struct list_head list;
 	extent_submit_bio_hook_t *submit_bio_start;
@@ -871,7 +872,7 @@ static void run_one_async_start(struct btrfs_work *work)
 	int ret;
 
 	async = container_of(work, struct  async_submit_bio, work);
-	ret = async->submit_bio_start(async->inode, async->bio,
+	ret = async->submit_bio_start(async->private_data, async->bio,
 				      async->mirror_num, async->bio_flags,
 				      async->bio_offset);
 	if (ret)
@@ -885,7 +886,7 @@ static void run_one_async_done(struct btrfs_work *work)
 	int limit;
 
 	async = container_of(work, struct  async_submit_bio, work);
-	fs_info = BTRFS_I(async->inode)->root->fs_info;
+	fs_info = async->fs_info;
 
 	limit = btrfs_async_submit_limit(fs_info);
 	limit = limit * 2 / 3;
@@ -904,7 +905,7 @@ static void run_one_async_done(struct btrfs_work *work)
 		return;
 	}
 
-	async->submit_bio_done(async->inode, async->bio, async->mirror_num,
+	async->submit_bio_done(async->private_data, async->bio, async->mirror_num,
 			       async->bio_flags, async->bio_offset);
 }
 
@@ -916,10 +917,9 @@ static void run_one_async_free(struct btrfs_work *work)
 	kfree(async);
 }
 
-int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
-			struct bio *bio, int mirror_num,
-			unsigned long bio_flags,
-			u64 bio_offset,
+int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct bio *bio,
+			int mirror_num, unsigned long bio_flags,
+			u64 bio_offset, void *private_data,
 			extent_submit_bio_hook_t *submit_bio_start,
 			extent_submit_bio_hook_t *submit_bio_done)
 {
@@ -929,7 +929,8 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	if (!async)
 		return -ENOMEM;
 
-	async->inode = inode;
+	async->private_data = private_data;
+	async->fs_info = fs_info;
 	async->bio = bio;
 	async->mirror_num = mirror_num;
 	async->submit_bio_start = submit_bio_start;
@@ -975,7 +976,7 @@ static int btree_csum_one_bio(struct bio *bio)
 	return ret;
 }
 
-static int __btree_submit_bio_start(struct inode *inode, struct bio *bio,
+static int __btree_submit_bio_start(void *private_data, struct bio *bio,
 				    int mirror_num, unsigned long bio_flags,
 				    u64 bio_offset)
 {
@@ -986,10 +987,11 @@ static int __btree_submit_bio_start(struct inode *inode, struct bio *bio,
 	return btree_csum_one_bio(bio);
 }
 
-static int __btree_submit_bio_done(struct inode *inode, struct bio *bio,
+static int __btree_submit_bio_done(void *private_data, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset)
 {
+	struct inode *inode = private_data;
 	int ret;
 
 	/*
@@ -1015,10 +1017,11 @@ static int check_async_write(unsigned long bio_flags)
 	return 1;
 }
 
-static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
+static int btree_submit_bio_hook(void *private_data, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset)
 {
+	struct inode *inode = private_data;
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	int async = check_async_write(bio_flags);
 	int ret;
@@ -1043,8 +1046,8 @@ static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 		 * kthread helpers are used to submit writes so that
 		 * checksumming can happen in parallel across all CPUs
 		 */
-		ret = btrfs_wq_submit_bio(fs_info, inode, bio, mirror_num, 0,
-					  bio_offset,
+		ret = btrfs_wq_submit_bio(fs_info, bio, mirror_num, 0,
+					  bio_offset, private_data,
 					  __btree_submit_bio_start,
 					  __btree_submit_bio_done);
 	}
@@ -1347,8 +1350,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;
 	if (!dummy)
-		extent_io_tree_init(&root->dirty_log_pages,
-				     fs_info->btree_inode->i_mapping);
+		extent_io_tree_init(&root->dirty_log_pages, NULL);
 
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
@@ -2309,7 +2311,7 @@ static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info)
 	inode->i_mapping->a_ops = &btree_aops;
 
 	RB_CLEAR_NODE(&BTRFS_I(inode)->rb_node);
-	extent_io_tree_init(&BTRFS_I(inode)->io_tree, inode->i_mapping);
+	extent_io_tree_init(&BTRFS_I(inode)->io_tree, inode);
 	BTRFS_I(inode)->io_tree.track_uptodate = 0;
 	extent_map_tree_init(&BTRFS_I(inode)->extent_tree);
 
@@ -2703,10 +2705,8 @@ int open_ctree(struct super_block *sb,
 	fs_info->block_group_cache_tree = RB_ROOT;
 	fs_info->first_logical_byte = (u64)-1;
 
-	extent_io_tree_init(&fs_info->freed_extents[0],
-			     fs_info->btree_inode->i_mapping);
-	extent_io_tree_init(&fs_info->freed_extents[1],
-			     fs_info->btree_inode->i_mapping);
+	extent_io_tree_init(&fs_info->freed_extents[0], NULL);
+	extent_io_tree_init(&fs_info->freed_extents[1], NULL);
 	fs_info->pinned_extents = &fs_info->freed_extents[0];
 	set_bit(BTRFS_FS_BARRIER, &fs_info->flags);
 
@@ -4686,6 +4686,12 @@ static int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info)
 	return 0;
 }
 
+static struct btrfs_fs_info *btree_fs_info(void *private_data)
+{
+	struct inode *inode = private_data;
+	return btrfs_sb(inode->i_sb);
+}
+
 static const struct extent_io_ops btree_extent_io_ops = {
 	/* mandatory callbacks */
 	.submit_bio_hook = btree_submit_bio_hook,
@@ -4693,6 +4699,8 @@ static const struct extent_io_ops btree_extent_io_ops = {
 	/* note we're sharing with inode.c for the merge bio hook */
 	.merge_bio_hook = btrfs_merge_bio_hook,
 	.readpage_io_failed_hook = btree_io_failed_hook,
+	.set_range_writeback = btrfs_set_range_writeback,
+	.tree_fs_info = btree_fs_info,
 
 	/* optional callbacks */
 };

commit a5ed45f8224f2c7e4ad5a9673cb50e8e3128bd88
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu May 11 09:17:46 2017 +0300

    btrfs: Convert fs_info->free_chunk_space to atomic64_t
    
    The ->free_chunk_space variable is used to track the unallocated space
    and access to it is protected by a spinlock, which is not used for
    anything else.  Make the code a bit self-explanatory by switching the
    variable to an atomic64_t type and kill the spinlock.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    [ not a performance critical code, use of atomic type is ok ]
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bafdd2fe8f88..9b8df5aaf76e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2626,7 +2626,6 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->fs_roots_radix_lock);
 	spin_lock_init(&fs_info->delayed_iput_lock);
 	spin_lock_init(&fs_info->defrag_inodes_lock);
-	spin_lock_init(&fs_info->free_chunk_lock);
 	spin_lock_init(&fs_info->tree_mod_seq_lock);
 	spin_lock_init(&fs_info->super_lock);
 	spin_lock_init(&fs_info->qgroup_op_lock);
@@ -2667,7 +2666,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->max_inline = BTRFS_DEFAULT_MAX_INLINE;
 	fs_info->metadata_ratio = 0;
 	fs_info->defrag_inodes = RB_ROOT;
-	fs_info->free_chunk_space = 0;
+	atomic64_set(&fs_info->free_chunk_space, 0);
 	fs_info->tree_mod_log = RB_ROOT;
 	fs_info->commit_interval = BTRFS_DEFAULT_COMMIT_INTERVAL;
 	fs_info->avg_delayed_ref_runtime = NSEC_PER_SEC >> 6; /* div by 64 */

commit 401b41e5a85a635fd9888ba8969c5006a5dbd399
Author: Anand Jain <anand.jain@oracle.com>
Date:   Sat May 6 07:17:54 2017 +0800

    btrfs: add framework to handle device flush error as a volume
    
    This adds comments to the flush error handling part of the code, and
    hopes to maintain the same logic with a framework which can be used to
    handle the errors at the volume level.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5f678dcb20e6..bafdd2fe8f88 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3509,6 +3509,10 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 	if (wait) {
 		bio = device->flush_bio;
 		if (!bio)
+			/*
+			 * This means the alloc has failed with ENOMEM, however
+			 * here we return 0, as its not a device error.
+			 */
 			return 0;
 
 		wait_for_completion(&device->flush_wait);
@@ -3548,6 +3552,32 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 	return 0;
 }
 
+static int check_barrier_error(struct btrfs_fs_devices *fsdevs)
+{
+	int submit_flush_error = 0;
+	int dev_flush_error = 0;
+	struct btrfs_device *dev;
+	int tolerance;
+
+	list_for_each_entry_rcu(dev, &fsdevs->devices, dev_list) {
+		if (!dev->bdev) {
+			submit_flush_error++;
+			dev_flush_error++;
+			continue;
+		}
+		if (dev->last_flush_error == -ENOMEM)
+			submit_flush_error++;
+		if (dev->last_flush_error && dev->last_flush_error != -ENOMEM)
+			dev_flush_error++;
+	}
+
+	tolerance = fsdevs->fs_info->num_tolerated_disk_barrier_failures;
+	if (submit_flush_error > tolerance || dev_flush_error > tolerance)
+		return -EIO;
+
+	return 0;
+}
+
 /*
  * send an empty flush down to each device in parallel,
  * then wait for them
@@ -3575,6 +3605,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 		ret = write_dev_flush(dev, 0);
 		if (ret)
 			errors_send++;
+		dev->last_flush_error = ret;
 	}
 
 	/* wait for all the barriers */
@@ -3589,12 +3620,30 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 			continue;
 
 		ret = write_dev_flush(dev, 1);
-		if (ret)
+		if (ret) {
+			dev->last_flush_error = ret;
 			errors_wait++;
+		}
+	}
+
+	/*
+	 * Try hard in case of flush. Lets say, in RAID1 we have
+	 * the following situation
+	 *  dev1: EIO dev2: ENOMEM
+	 * this is not a fatal error as we hope to recover from
+	 * ENOMEM in the next attempt to flush.
+	 * But the following is considered as fatal
+	 *  dev1: ENOMEM dev2: ENOMEM
+	 *  dev1: bdev == NULL dev2: ENOMEM
+	 */
+	if (errors_send || errors_wait) {
+		/*
+		 * At some point we need the status of all disks
+		 * to arrive at the volume status. So error checking
+		 * is being pushed to a separate loop.
+		 */
+		return check_barrier_error(info->fs_devices);
 	}
-	if (errors_send > info->num_tolerated_disk_barrier_failures ||
-	    errors_wait > info->num_tolerated_disk_barrier_failures)
-		return -EIO;
 	return 0;
 }
 

commit 8f66439eec46d652255b9351abebb540ee5b2fd9
Merge: 22ec656bcc3f 32c1431eea48
Author: Jens Axboe <axboe@kernel.dk>
Date:   Mon Jun 12 08:30:13 2017 -0600

    Merge tag 'v4.12-rc5' into for-4.13/block
    
    We've already got a few conflicts and upcoming work depends on some of the
    changes that have gone into mainline as regression fixes for this series.
    
    Pull in 4.12-rc5 to resolve these conflicts and make it easier on down stream
    trees to continue working on 4.13 changes.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 66cea28a947739343ba3f804641de5cdf388cffa
Merge: ac1a14a239bb 70e7af244f24
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jun 10 11:06:05 2017 -0700

    Merge branch 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "Some fixes that Dave Sterba collected.
    
      We've been hitting an early enospc problem on production machines that
      Omar tracked down to an old int->u64 mistake. I waited a bit on this
      pull to make sure it was really the problem from production, but it's
      on ~2100 hosts now and I think we're good.
    
      Omar also noticed a commit in the queue would make new early ENOSPC
      problems. I pulled that out for now, which is why the top three
      commits are younger than the rest.
    
      Otherwise these are all fixes, some explaining very old bugs that
      we've been poking at for a while"
    
    * 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix delalloc accounting leak caused by u32 overflow
      Btrfs: clear EXTENT_DEFRAG bits in finish_ordered_io
      btrfs: tree-log.c: Wrong printk information about namelen
      btrfs: fix race with relocation recovery and fs_root setup
      btrfs: fix memory leak in update_space_info failure path
      btrfs: use correct types for page indices in btrfs_page_exists_in_range
      btrfs: fix incorrect error return ret being passed to mapping_set_error
      btrfs: Make flush bios explicitely sync
      btrfs: fiemap: Cache and merge fiemap extent before submit it to user

commit 4e4cbee93d56137ebff722be022cae5f70ef84fb
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:06 2017 +0200

    block: switch bios to blk_status_t
    
    Replace bi_error with a new bi_status to allow for a clear conversion.
    Note that device mapper overloaded bi_error with a private value, which
    we'll have to keep arround at least for now and thus propagate to a
    proper blk_status_t value.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8685d67185d0..46accc75ad5a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -87,7 +87,7 @@ struct btrfs_end_io_wq {
 	bio_end_io_t *end_io;
 	void *private;
 	struct btrfs_fs_info *info;
-	int error;
+	blk_status_t status;
 	enum btrfs_wq_endio_type metadata;
 	struct list_head list;
 	struct btrfs_work work;
@@ -131,7 +131,7 @@ struct async_submit_bio {
 	 */
 	u64 bio_offset;
 	struct btrfs_work work;
-	int error;
+	blk_status_t status;
 };
 
 /*
@@ -799,7 +799,7 @@ static void end_workqueue_bio(struct bio *bio)
 	btrfs_work_func_t func;
 
 	fs_info = end_io_wq->info;
-	end_io_wq->error = bio->bi_error;
+	end_io_wq->status = bio->bi_status;
 
 	if (bio_op(bio) == REQ_OP_WRITE) {
 		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_METADATA) {
@@ -836,19 +836,19 @@ static void end_workqueue_bio(struct bio *bio)
 	btrfs_queue_work(wq, &end_io_wq->work);
 }
 
-int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
+blk_status_t btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 			enum btrfs_wq_endio_type metadata)
 {
 	struct btrfs_end_io_wq *end_io_wq;
 
 	end_io_wq = kmem_cache_alloc(btrfs_end_io_wq_cache, GFP_NOFS);
 	if (!end_io_wq)
-		return -ENOMEM;
+		return BLK_STS_RESOURCE;
 
 	end_io_wq->private = bio->bi_private;
 	end_io_wq->end_io = bio->bi_end_io;
 	end_io_wq->info = info;
-	end_io_wq->error = 0;
+	end_io_wq->status = 0;
 	end_io_wq->bio = bio;
 	end_io_wq->metadata = metadata;
 
@@ -868,14 +868,14 @@ unsigned long btrfs_async_submit_limit(struct btrfs_fs_info *info)
 static void run_one_async_start(struct btrfs_work *work)
 {
 	struct async_submit_bio *async;
-	int ret;
+	blk_status_t ret;
 
 	async = container_of(work, struct  async_submit_bio, work);
 	ret = async->submit_bio_start(async->inode, async->bio,
 				      async->mirror_num, async->bio_flags,
 				      async->bio_offset);
 	if (ret)
-		async->error = ret;
+		async->status = ret;
 }
 
 static void run_one_async_done(struct btrfs_work *work)
@@ -898,8 +898,8 @@ static void run_one_async_done(struct btrfs_work *work)
 		wake_up(&fs_info->async_submit_wait);
 
 	/* If an error occurred we just want to clean up the bio and move on */
-	if (async->error) {
-		async->bio->bi_error = async->error;
+	if (async->status) {
+		async->bio->bi_status = async->status;
 		bio_endio(async->bio);
 		return;
 	}
@@ -916,18 +916,17 @@ static void run_one_async_free(struct btrfs_work *work)
 	kfree(async);
 }
 
-int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
-			struct bio *bio, int mirror_num,
-			unsigned long bio_flags,
-			u64 bio_offset,
-			extent_submit_bio_hook_t *submit_bio_start,
-			extent_submit_bio_hook_t *submit_bio_done)
+blk_status_t btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info,
+		struct inode *inode, struct bio *bio, int mirror_num,
+		unsigned long bio_flags, u64 bio_offset,
+		extent_submit_bio_hook_t *submit_bio_start,
+		extent_submit_bio_hook_t *submit_bio_done)
 {
 	struct async_submit_bio *async;
 
 	async = kmalloc(sizeof(*async), GFP_NOFS);
 	if (!async)
-		return -ENOMEM;
+		return BLK_STS_RESOURCE;
 
 	async->inode = inode;
 	async->bio = bio;
@@ -941,7 +940,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->bio_flags = bio_flags;
 	async->bio_offset = bio_offset;
 
-	async->error = 0;
+	async->status = 0;
 
 	atomic_inc(&fs_info->nr_async_submits);
 
@@ -959,7 +958,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	return 0;
 }
 
-static int btree_csum_one_bio(struct bio *bio)
+static blk_status_t btree_csum_one_bio(struct bio *bio)
 {
 	struct bio_vec *bvec;
 	struct btrfs_root *root;
@@ -972,12 +971,12 @@ static int btree_csum_one_bio(struct bio *bio)
 			break;
 	}
 
-	return ret;
+	return errno_to_blk_status(ret);
 }
 
-static int __btree_submit_bio_start(struct inode *inode, struct bio *bio,
-				    int mirror_num, unsigned long bio_flags,
-				    u64 bio_offset)
+static blk_status_t __btree_submit_bio_start(struct inode *inode,
+		struct bio *bio, int mirror_num, unsigned long bio_flags,
+		u64 bio_offset)
 {
 	/*
 	 * when we're called for a write, we're already in the async
@@ -986,11 +985,11 @@ static int __btree_submit_bio_start(struct inode *inode, struct bio *bio,
 	return btree_csum_one_bio(bio);
 }
 
-static int __btree_submit_bio_done(struct inode *inode, struct bio *bio,
-				 int mirror_num, unsigned long bio_flags,
-				 u64 bio_offset)
+static blk_status_t __btree_submit_bio_done(struct inode *inode,
+		struct bio *bio, int mirror_num, unsigned long bio_flags,
+		u64 bio_offset)
 {
-	int ret;
+	blk_status_t ret;
 
 	/*
 	 * when we're called for a write, we're already in the async
@@ -998,7 +997,7 @@ static int __btree_submit_bio_done(struct inode *inode, struct bio *bio,
 	 */
 	ret = btrfs_map_bio(btrfs_sb(inode->i_sb), bio, mirror_num, 1);
 	if (ret) {
-		bio->bi_error = ret;
+		bio->bi_status = ret;
 		bio_endio(bio);
 	}
 	return ret;
@@ -1015,13 +1014,13 @@ static int check_async_write(unsigned long bio_flags)
 	return 1;
 }
 
-static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
+static blk_status_t btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	int async = check_async_write(bio_flags);
-	int ret;
+	blk_status_t ret;
 
 	if (bio_op(bio) != REQ_OP_WRITE) {
 		/*
@@ -1054,7 +1053,7 @@ static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 	return 0;
 
 out_w_error:
-	bio->bi_error = ret;
+	bio->bi_status = ret;
 	bio_endio(bio);
 	return ret;
 }
@@ -1820,7 +1819,7 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	end_io_wq = container_of(work, struct btrfs_end_io_wq, work);
 	bio = end_io_wq->bio;
 
-	bio->bi_error = end_io_wq->error;
+	bio->bi_status = end_io_wq->status;
 	bio->bi_private = end_io_wq->private;
 	bio->bi_end_io = end_io_wq->end_io;
 	kmem_cache_free(btrfs_end_io_wq_cache, end_io_wq);
@@ -3495,11 +3494,11 @@ static void btrfs_end_empty_barrier(struct bio *bio)
  * any device where the flush fails with eopnotsupp are flagged as not-barrier
  * capable
  */
-static int write_dev_flush(struct btrfs_device *device, int wait)
+static blk_status_t write_dev_flush(struct btrfs_device *device, int wait)
 {
 	struct request_queue *q = bdev_get_queue(device->bdev);
 	struct bio *bio;
-	int ret = 0;
+	blk_status_t ret = 0;
 
 	if (!test_bit(QUEUE_FLAG_WC, &q->queue_flags))
 		return 0;
@@ -3511,8 +3510,8 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 		wait_for_completion(&device->flush_wait);
 
-		if (bio->bi_error) {
-			ret = bio->bi_error;
+		if (bio->bi_status) {
+			ret = bio->bi_status;
 			btrfs_dev_stat_inc_and_print(device,
 				BTRFS_DEV_STAT_FLUSH_ERRS);
 		}
@@ -3531,7 +3530,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 	device->flush_bio = NULL;
 	bio = btrfs_io_bio_alloc(GFP_NOFS, 0);
 	if (!bio)
-		return -ENOMEM;
+		return BLK_STS_RESOURCE;
 
 	bio->bi_end_io = btrfs_end_empty_barrier;
 	bio->bi_bdev = device->bdev;
@@ -3556,7 +3555,7 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 	struct btrfs_device *dev;
 	int errors_send = 0;
 	int errors_wait = 0;
-	int ret;
+	blk_status_t ret;
 
 	/* send down all the barriers */
 	head = &info->fs_devices->devices;

commit 8d91012528b3c95c159e6b6779e367421df9cbb5
Author: Jan Kara <jack@suse.cz>
Date:   Tue May 2 17:03:50 2017 +0200

    btrfs: Make flush bios explicitely sync
    
    Commit b685d3d65ac7 "block: treat REQ_FUA and REQ_PREFLUSH as
    synchronous" removed REQ_SYNC flag from WRITE_{FUA|PREFLUSH|...}
    definitions.  generic_make_request_checks() however strips REQ_FUA and
    REQ_PREFLUSH flags from a bio when the storage doesn't report volatile
    write cache and thus write effectively becomes asynchronous which can
    lead to performance regressions
    
    Fix the problem by making sure all bios which are synchronous are
    properly marked with REQ_SYNC.
    
    CC: David Sterba <dsterba@suse.com>
    CC: linux-btrfs@vger.kernel.org
    Fixes: b685d3d65ac791406e0dfd8779cc9b3707fea5a3
    Signed-off-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 683194242deb..b3579d11fb26 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3488,10 +3488,12 @@ static int write_dev_supers(struct btrfs_device *device,
 		 * we fua the first super.  The others we allow
 		 * to go down lazy.
 		 */
-		if (i == 0)
-			ret = btrfsic_submit_bh(REQ_OP_WRITE, REQ_FUA, bh);
-		else
+		if (i == 0) {
+			ret = btrfsic_submit_bh(REQ_OP_WRITE,
+						REQ_SYNC | REQ_FUA, bh);
+		} else {
 			ret = btrfsic_submit_bh(REQ_OP_WRITE, REQ_SYNC, bh);
+		}
 		if (ret)
 			errors++;
 	}
@@ -3556,7 +3558,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 	bio->bi_end_io = btrfs_end_empty_barrier;
 	bio->bi_bdev = device->bdev;
-	bio->bi_opf = REQ_OP_WRITE | REQ_PREFLUSH;
+	bio->bi_opf = REQ_OP_WRITE | REQ_SYNC | REQ_PREFLUSH;
 	init_completion(&device->flush_wait);
 	bio->bi_private = &device->flush_wait;
 	device->flush_bio = bio;

commit 1176032cb12bb89ad558a3e57e82f2f25b817eff
Merge: 56868a460b83 9bcaaea7418d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 10 08:33:17 2017 -0700

    Merge branch 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This has fixes and cleanups Dave Sterba collected for the merge
      window.
    
      The biggest functional fixes are between btrfs raid5/6 and scrub, and
      raid5/6 and device replacement. Some of our pending qgroup fixes are
      included as well while I bash on the rest in testing.
    
      We also have the usual set of cleanups, including one that makes
      __btrfs_map_block() much more maintainable, and conversions from
      atomic_t to refcount_t"
    
    * 'for-linus-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (71 commits)
      btrfs: fix the gfp_mask for the reada_zones radix tree
      Btrfs: fix reported number of inode blocks
      Btrfs: send, fix file hole not being preserved due to inline extent
      Btrfs: fix extent map leak during fallocate error path
      Btrfs: fix incorrect space accounting after failure to insert inline extent
      Btrfs: fix invalid attempt to free reserved space on failure to cow range
      btrfs: Handle delalloc error correctly to avoid ordered extent hang
      btrfs: Fix metadata underflow caused by btrfs_reloc_clone_csum error
      btrfs: check if the device is flush capable
      btrfs: delete unused member nobarriers
      btrfs: scrub: Fix RAID56 recovery race condition
      btrfs: scrub: Introduce full stripe lock for RAID56
      btrfs: Use ktime_get_real_ts for root ctime
      Btrfs: handle only applicable errors returned by btrfs_get_extent
      btrfs: qgroup: Fix qgroup corruption caused by inode_cache mount option
      btrfs: use q which is already obtained from bdev_get_queue
      Btrfs: switch to div64_u64 if with a u64 divisor
      Btrfs: update scrub_parity to use u64 stripe_len
      Btrfs: enable repair during read for raid56 profile
      btrfs: use clear_page where appropriate
      ...

commit 9bcaaea7418d09691f1ffab5c49aacafe3eef9d0
Author: Chris Mason <clm@fb.com>
Date:   Thu May 4 16:08:08 2017 -0700

    btrfs: fix the gfp_mask for the reada_zones radix tree
    
    Commits cc8385b59e17 and 7ef70b4d9987a7 added preallocation for the
    reada radix trees and also switched them over to GFP_KERNEL for the
    default gfp mask.
    
    Since we're doing radix tree insertions under spinlocks, we need
    to make sure the mask doesn't allow sleeping.  This fix keeps
    the radix preallocation but switches back to the original gfp_mask.
    
    Reported-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ba7bd65693a3..683194242deb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2693,7 +2693,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->commit_interval = BTRFS_DEFAULT_COMMIT_INTERVAL;
 	fs_info->avg_delayed_ref_runtime = NSEC_PER_SEC >> 6; /* div by 64 */
 	/* readahead state */
-	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_KERNEL);
+	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_DIRECT_RECLAIM);
 	spin_lock_init(&fs_info->reada_lock);
 
 	fs_info->thread_pool_size = min_t(unsigned long,

commit 694752922b12bd318aa80191bd9d8c3dcfb39055
Merge: a351e9b9fc24 9438b3e080be
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 1 10:39:57 2017 -0700

    Merge branch 'for-4.12/block' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
    
     - Add BFQ IO scheduler under the new blk-mq scheduling framework. BFQ
       was initially a fork of CFQ, but subsequently changed to implement
       fairness based on B-WF2Q+, a modified variant of WF2Q. BFQ is meant
       to be used on desktop type single drives, providing good fairness.
       From Paolo.
    
     - Add Kyber IO scheduler. This is a full multiqueue aware scheduler,
       using a scalable token based algorithm that throttles IO based on
       live completion IO stats, similary to blk-wbt. From Omar.
    
     - A series from Jan, moving users to separately allocated backing
       devices. This continues the work of separating backing device life
       times, solving various problems with hot removal.
    
     - A series of updates for lightnvm, mostly from Javier. Includes a
       'pblk' target that exposes an open channel SSD as a physical block
       device.
    
     - A series of fixes and improvements for nbd from Josef.
    
     - A series from Omar, removing queue sharing between devices on mostly
       legacy drivers. This helps us clean up other bits, if we know that a
       queue only has a single device backing. This has been overdue for
       more than a decade.
    
     - Fixes for the blk-stats, and improvements to unify the stats and user
       windows. This both improves blk-wbt, and enables other users to
       register a need to receive IO stats for a device. From Omar.
    
     - blk-throttle improvements from Shaohua. This provides a scalable
       framework for implementing scalable priotization - particularly for
       blk-mq, but applicable to any type of block device. The interface is
       marked experimental for now.
    
     - Bucketized IO stats for IO polling from Stephen Bates. This improves
       efficiency of polled workloads in the presence of mixed block size
       IO.
    
     - A few fixes for opal, from Scott.
    
     - A few pulls for NVMe, including a lot of fixes for NVMe-over-fabrics.
       From a variety of folks, mostly Sagi and James Smart.
    
     - A series from Bart, improving our exposed info and capabilities from
       the blk-mq debugfs support.
    
     - A series from Christoph, cleaning up how handle WRITE_ZEROES.
    
     - A series from Christoph, cleaning up the block layer handling of how
       we track errors in a request. On top of being a nice cleanup, it also
       shrinks the size of struct request a bit.
    
     - Removal of mg_disk and hd (sorry Linus) by Christoph. The former was
       never used by platforms, and the latter has outlived it's usefulness.
    
     - Various little bug fixes and cleanups from a wide variety of folks.
    
    * 'for-4.12/block' of git://git.kernel.dk/linux-block: (329 commits)
      block: hide badblocks attribute by default
      blk-mq: unify hctx delay_work and run_work
      block: add kblock_mod_delayed_work_on()
      blk-mq: unify hctx delayed_run_work and run_work
      nbd: fix use after free on module unload
      MAINTAINERS: bfq: Add Paolo as maintainer for the BFQ I/O scheduler
      blk-mq-sched: alloate reserved tags out of normal pool
      mtip32xx: use runtime tag to initialize command header
      scsi: Implement blk_mq_ops.show_rq()
      blk-mq: Add blk_mq_ops.show_rq()
      blk-mq: Show operation, cmd_flags and rq_flags names
      blk-mq: Make blk_flags_show() callers append a newline character
      blk-mq: Move the "state" debugfs attribute one level down
      blk-mq: Unregister debugfs attributes earlier
      blk-mq: Only unregister hctxs for which registration succeeded
      blk-mq-debugfs: Rename functions for registering and unregistering the mq directory
      blk-mq: Let blk_mq_debugfs_register() look up the queue name
      blk-mq: Register <dev>/queue/mq after having registered <dev>/queue
      ide-pm: always pass 0 error to ide_complete_rq in ide_do_devset
      ide-pm: always pass 0 error to __blk_end_request_all
      ..

commit 9e11ceee23f25b6bb03de97ad1b729784f09538c
Author: Jan Kara <jack@suse.cz>
Date:   Wed Apr 12 12:24:32 2017 +0200

    btrfs: Convert to separately allocated bdi
    
    Allocate struct backing_dev_info separately instead of embedding it
    inside superblock. This unifies handling of bdi among users.
    
    CC: Chris Mason <clm@fb.com>
    CC: Josef Bacik <jbacik@fb.com>
    CC: David Sterba <dsterba@suse.com>
    CC: linux-btrfs@vger.kernel.org
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 08b74daf35d0..a7d8c342f604 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1808,21 +1808,6 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	return ret;
 }
 
-static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
-{
-	int err;
-
-	err = bdi_setup_and_register(bdi, "btrfs");
-	if (err)
-		return err;
-
-	bdi->ra_pages = VM_MAX_READAHEAD * 1024 / PAGE_SIZE;
-	bdi->congested_fn	= btrfs_congested_fn;
-	bdi->congested_data	= info;
-	bdi->capabilities |= BDI_CAP_CGROUP_WRITEBACK;
-	return 0;
-}
-
 /*
  * called by the kthread helper functions to finally call the bio end_io
  * functions.  This is where read checksum verification actually happens
@@ -2601,16 +2586,10 @@ int open_ctree(struct super_block *sb,
 		goto fail;
 	}
 
-	ret = setup_bdi(fs_info, &fs_info->bdi);
-	if (ret) {
-		err = ret;
-		goto fail_srcu;
-	}
-
 	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0, GFP_KERNEL);
 	if (ret) {
 		err = ret;
-		goto fail_bdi;
+		goto fail_srcu;
 	}
 	fs_info->dirty_metadata_batch = PAGE_SIZE *
 					(1 + ilog2(nr_cpu_ids));
@@ -2718,7 +2697,6 @@ int open_ctree(struct super_block *sb,
 
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
-	sb->s_bdi = &fs_info->bdi;
 
 	btrfs_init_btree_inode(fs_info);
 
@@ -2915,9 +2893,12 @@ int open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 
-	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
-	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
-				    SZ_4M / PAGE_SIZE);
+	sb->s_bdi->congested_fn = btrfs_congested_fn;
+	sb->s_bdi->congested_data = fs_info;
+	sb->s_bdi->capabilities |= BDI_CAP_CGROUP_WRITEBACK;
+	sb->s_bdi->ra_pages = VM_MAX_READAHEAD * 1024 / PAGE_SIZE;
+	sb->s_bdi->ra_pages *= btrfs_super_num_devices(disk_super);
+	sb->s_bdi->ra_pages = max(sb->s_bdi->ra_pages, SZ_4M / PAGE_SIZE);
 
 	sb->s_blocksize = sectorsize;
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
@@ -3285,8 +3266,6 @@ int open_ctree(struct super_block *sb,
 	percpu_counter_destroy(&fs_info->delalloc_bytes);
 fail_dirty_metadata_bytes:
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
-fail_bdi:
-	bdi_destroy(&fs_info->bdi);
 fail_srcu:
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 fail:
@@ -4007,7 +3986,6 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
 	percpu_counter_destroy(&fs_info->delalloc_bytes);
 	percpu_counter_destroy(&fs_info->bio_counter);
-	bdi_destroy(&fs_info->bdi);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 
 	btrfs_free_stripe_hash_table(fs_info);

commit c2a9c7ab475bc3aaf06521a39ac65bc48c8cad4f
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Apr 6 11:22:53 2017 +0800

    btrfs: check if the device is flush capable
    
    The block layer call chain from submit_bio will check if the write cache
    is enabled for the given queue before submitting the flush. This will
    add a code to fail fast if its not.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ updated changelog to reflect current code stat, blkdev_issue_flush is
      not used yet ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e070e463ad8b..ba7bd65693a3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3518,9 +3518,13 @@ static void btrfs_end_empty_barrier(struct bio *bio)
  */
 static int write_dev_flush(struct btrfs_device *device, int wait)
 {
+	struct request_queue *q = bdev_get_queue(device->bdev);
 	struct bio *bio;
 	int ret = 0;
 
+	if (!test_bit(QUEUE_FLAG_WC, &q->queue_flags))
+		return 0;
+
 	if (wait) {
 		bio = device->flush_bio;
 		if (!bio)

commit 13e88e1560d6014838e2dd9f8b9cf8ec9a8d86e6
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Apr 6 11:22:52 2017 +0800

    btrfs: delete unused member nobarriers
    
    The last consumer of nobarriers is removed by the commit [1] and sync
    won't fail with EOPNOTSUPP anymore. Thus, now when write cache is write
    through it just return success without actually transpiring such a
    request to the block device/lun.
    
    [1]
    commit b25de9d6da49b1a8760a89672283128aa8c78345
    block: remove BIO_EOPNOTSUPP
    
    And, as the device/lun write cache state may change dynamically saving
    such as state won't help either. So deleting the member nobarriers.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a9314fe494c9..e070e463ad8b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3521,9 +3521,6 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 	struct bio *bio;
 	int ret = 0;
 
-	if (device->nobarriers)
-		return 0;
-
 	if (wait) {
 		bio = device->flush_bio;
 		if (!bio)

commit d48d71aa9977473b6515bb48933617a06cdc7be9
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 2 19:43:30 2017 +0100

    btrfs: remove redundant parameter from btree_readahead_hook
    
    We can read fs_info from eb.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 12eba54877c2..a9314fe494c9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -762,7 +762,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 err:
 	if (reads_done &&
 	    test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
-		btree_readahead_hook(fs_info, eb, ret);
+		btree_readahead_hook(eb, ret);
 
 	if (ret) {
 		/*
@@ -787,7 +787,7 @@ static int btree_io_failed_hook(struct page *page, int failed_mirror)
 	eb->read_mirror = failed_mirror;
 	atomic_dec(&eb->io_pages);
 	if (test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
-		btree_readahead_hook(eb->fs_info, eb, -EIO);
+		btree_readahead_hook(eb, -EIO);
 	return -EIO;	/* we fixed nothing */
 }
 

commit 7ef70b4d9987a78d39c4e40a02093493333e5408
Author: David Sterba <dsterba@suse.com>
Date:   Thu Mar 2 18:54:52 2017 +0100

    btrfs: preallocate radix tree node for global readahead tree
    
    We can preallocate the node so insertion does not have to do that under
    the lock. The GFP flags for the global radix tree are initialized to
     GFP_NOFS & ~__GFP_DIRECT_RECLAIM
    but we can use GFP_KERNEL, because readahead is optional and not on any
    critical writeout path.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bd415e1dd114..12eba54877c2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2693,7 +2693,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->commit_interval = BTRFS_DEFAULT_COMMIT_INTERVAL;
 	fs_info->avg_delayed_ref_runtime = NSEC_PER_SEC >> 6; /* div by 64 */
 	/* readahead state */
-	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_DIRECT_RECLAIM);
+	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_KERNEL);
 	spin_lock_init(&fs_info->reada_lock);
 
 	fs_info->thread_pool_size = min_t(unsigned long,

commit 0700cea7c8b387c8c6bc4de79b197baa0b3fc4a3
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Mar 3 10:55:18 2017 +0200

    btrfs: convert btrfs_root.refs from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3748bc54a6ab..bd415e1dd114 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1340,7 +1340,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	atomic_set(&root->log_writers, 0);
 	atomic_set(&root->log_batch, 0);
 	atomic_set(&root->orphan_inodes, 0);
-	atomic_set(&root->refs, 1);
+	refcount_set(&root->refs, 1);
 	atomic_set(&root->will_be_snapshoted, 0);
 	atomic64_set(&root->qgroup_meta_rsv, 0);
 	root->log_transid = 0;

commit 6df8cdf5bda221f268ac23940bce589ad176993d
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Mar 3 10:55:15 2017 +0200

    btrfs: convert btrfs_delayed_ref_node.refs from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e4aa64c263f9..3748bc54a6ab 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4343,7 +4343,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		head = rb_entry(node, struct btrfs_delayed_ref_head,
 				href_node);
 		if (!mutex_trylock(&head->mutex)) {
-			atomic_inc(&head->node.refs);
+			refcount_inc(&head->node.refs);
 			spin_unlock(&delayed_refs->lock);
 
 			mutex_lock(&head->mutex);

commit 9b64f57ddf8673d29fafb3405d4aa1e93f5a4cd7
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Mar 3 10:55:11 2017 +0200

    btrfs: convert btrfs_transaction.use_count from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eb1ee7b6f532..e4aa64c263f9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4615,7 +4615,7 @@ static int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info)
 		t = list_first_entry(&fs_info->trans_list,
 				     struct btrfs_transaction, list);
 		if (t->state >= TRANS_STATE_COMMIT_START) {
-			atomic_inc(&t->use_count);
+			refcount_inc(&t->use_count);
 			spin_unlock(&fs_info->trans_lock);
 			btrfs_wait_for_commit(fs_info, t->transid);
 			btrfs_put_transaction(t);

commit fe8e12b5032536d37751c47e1c0446f17e974e5c
Merge: f9799ad21b5e 41a75a6eb2bf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 31 17:58:48 2017 -0700

    Merge branch 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "We have three small fixes queued up in my for-linus-4.11 branch"
    
    * 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix an integer overflow check
      btrfs: Change qgroup_meta_rsv to 64bit
      Btrfs: bring back repair during read

commit ce0dcee626c482183b42d45b6ea43198c7223fc7
Author: Goldwyn Rodrigues <rgoldwyn@suse.com>
Date:   Tue Mar 14 05:25:09 2017 -0500

    btrfs: Change qgroup_meta_rsv to 64bit
    
    Using an int value is causing qg->reserved to become negative and
    exclusive -EDQUOT to be reached prematurely.
    
    This affects exclusive qgroups only.
    
    TEST CASE:
    
    DEVICE=/dev/vdb
    MOUNTPOINT=/mnt
    SUBVOL=$MOUNTPOINT/tmp
    
    umount $SUBVOL
    umount $MOUNTPOINT
    
    mkfs.btrfs -f $DEVICE
    mount /dev/vdb $MOUNTPOINT
    btrfs quota enable $MOUNTPOINT
    btrfs subvol create $SUBVOL
    umount $MOUNTPOINT
    mount /dev/vdb $MOUNTPOINT
    mount -o subvol=tmp $DEVICE $SUBVOL
    btrfs qgroup limit -e 3G $SUBVOL
    
    btrfs quota rescan /mnt -w
    
    for i in `seq 1 44000`; do
      dd if=/dev/zero of=/mnt/tmp/test_$i bs=10k count=1
      if [[ $? > 0 ]]; then
         btrfs qgroup show -pcref $SUBVOL
         exit 1
      fi
    done
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    [ add reproducer to changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 73fdc6bdaea9..982c56f79515 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1342,7 +1342,7 @@ static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 	atomic_set(&root->orphan_inodes, 0);
 	atomic_set(&root->refs, 1);
 	atomic_set(&root->will_be_snapshoted, 0);
-	atomic_set(&root->qgroup_meta_rsv, 0);
+	atomic64_set(&root->qgroup_meta_rsv, 0);
 	root->log_transid = 0;
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;

commit bbe08c0a43e2c5ee3a00de68c0e867a08a9aa990
Merge: 94e877d0fb43 e9f467d028cd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 2 16:03:00 2017 -0800

    Merge branch 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull more btrfs updates from Chris Mason:
     "Btrfs round two.
    
      These are mostly a continuation of Dave Sterba's collection of
      cleanups, but Filipe also has some bug fixes and performance
      improvements"
    
    * 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (69 commits)
      btrfs: add dummy callback for readpage_io_failed and drop checks
      btrfs: drop checks for mandatory extent_io_ops callbacks
      btrfs: document existence of extent_io ops callbacks
      btrfs: let writepage_end_io_hook return void
      btrfs: do proper error handling in btrfs_insert_xattr_item
      btrfs: handle allocation error in update_dev_stat_item
      btrfs: remove BUG_ON from __tree_mod_log_insert
      btrfs: derive maximum output size in the compression implementation
      btrfs: use predefined limits for calculating maximum number of pages for compression
      btrfs: export compression buffer limits in a header
      btrfs: merge nr_pages input and output parameter in compress_pages
      btrfs: merge length input and output parameter in compress_pages
      btrfs: constify name of subvolume in creation helpers
      btrfs: constify buffers used by compression helpers
      btrfs: constify input buffer of btrfs_csum_data
      btrfs: constify device path passed to relevant helpers
      btrfs: make btrfs_inode_resume_unlocked_dio take btrfs_inode
      btrfs: make btrfs_inode_block_unlocked_dio take btrfs_inode
      btrfs: Make btrfs_add_nondir take btrfs_inode
      btrfs: Make btrfs_add_link take btrfs_inode
      ...

commit e9f467d028cd7d8bee2a4d6c4fb806caf8cd580b
Merge: ef6ebf324216 20a7db8ab3f2
Author: Chris Mason <clm@fb.com>
Date:   Tue Feb 28 14:35:09 2017 -0800

    Merge branch 'for-chris-4.11-part2' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.11

commit 20a7db8ab3f2057a518448b1728d504ffadef65e
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 17 16:24:29 2017 +0100

    btrfs: add dummy callback for readpage_io_failed and drop checks
    
    Make extent_io_ops::readpage_io_failed_hook callback mandatory and
    define a dummy function for btrfs_extent_io_ops. As the failed IO
    callback is not performance critical, the branch vs extra trade off does
    not hurt.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 60d4f1b210d7..cad47ece2fdf 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4658,7 +4658,7 @@ static const struct extent_io_ops btree_extent_io_ops = {
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
 	/* note we're sharing with inode.c for the merge bio hook */
 	.merge_bio_hook = btrfs_merge_bio_hook,
+	.readpage_io_failed_hook = btree_io_failed_hook,
 
 	/* optional callbacks */
-	.readpage_io_failed_hook = btree_io_failed_hook,
 };

commit 4d53dddbec671bcb64a936a3d2b7bf1ce2252ed0
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 17 15:27:44 2017 +0100

    btrfs: document existence of extent_io ops callbacks
    
    Some of the callbacks defined in btree_extent_io_ops and
    btrfs_extent_io_ops do always exist so we don't need to check the
    existence before each call. This patch just reorders the definition and
    documents which are mandatory/optional.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 67d663ab658a..60d4f1b210d7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4653,9 +4653,12 @@ static int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info)
 }
 
 static const struct extent_io_ops btree_extent_io_ops = {
-	.readpage_end_io_hook = btree_readpage_end_io_hook,
-	.readpage_io_failed_hook = btree_io_failed_hook,
+	/* mandatory callbacks */
 	.submit_bio_hook = btree_submit_bio_hook,
+	.readpage_end_io_hook = btree_readpage_end_io_hook,
 	/* note we're sharing with inode.c for the merge bio hook */
 	.merge_bio_hook = btrfs_merge_bio_hook,
+
+	/* optional callbacks */
+	.readpage_io_failed_hook = btree_io_failed_hook,
 };

commit 9ed573674ae607bc616c804657bfaf5b6ea5889d
Author: David Sterba <dsterba@suse.com>
Date:   Tue Feb 14 18:03:49 2017 +0100

    btrfs: constify input buffer of btrfs_csum_data
    
    The function does not modify the input buffer, also update a typecast in
    one caller.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a53ff3bff8eb..67d663ab658a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -265,7 +265,7 @@ static struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 	return em;
 }
 
-u32 btrfs_csum_data(char *data, u32 seed, size_t len)
+u32 btrfs_csum_data(const char *data, u32 seed, size_t len)
 {
 	return btrfs_crc32c(seed, data, len);
 }
@@ -3448,7 +3448,7 @@ static int write_dev_supers(struct btrfs_device *device,
 			btrfs_set_super_bytenr(sb, bytenr);
 
 			crc = ~(u32)0;
-			crc = btrfs_csum_data((char *)sb +
+			crc = btrfs_csum_data((const char *)sb +
 					      BTRFS_CSUM_SIZE, crc,
 					      BTRFS_SUPER_INFO_SIZE -
 					      BTRFS_CSUM_SIZE);

commit fc4f21b1d8d023cf0a2b1b050ae18e15dbe7068e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 20 13:51:06 2017 +0200

    btrfs: Make get_extent_t take btrfs_inode
    
    In addition to changing the signature, this patch also switches
    all the functions which are used as an argument to also take btrfs_inode.
    Namely those are: btrfs_get_extent and btrfs_get_extent_filemap.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2b06f557c176..a53ff3bff8eb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -219,12 +219,12 @@ void btrfs_set_buffer_lockdep_class(u64 objectid, struct extent_buffer *eb,
  * extents on the btree inode are pretty simple, there's one extent
  * that covers the entire device
  */
-static struct extent_map *btree_get_extent(struct inode *inode,
+static struct extent_map *btree_get_extent(struct btrfs_inode *inode,
 		struct page *page, size_t pg_offset, u64 start, u64 len,
 		int create)
 {
-	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
-	struct extent_map_tree *em_tree = &BTRFS_I(inode)->extent_tree;
+	struct btrfs_fs_info *fs_info = btrfs_sb(inode->vfs_inode.i_sb);
+	struct extent_map_tree *em_tree = &inode->extent_tree;
 	struct extent_map *em;
 	int ret;
 

commit 9003ed1fed2a3fe2774a6b67dcbe1ab31d7f8ec3
Merge: 94eae8034002 6288d6eabc75
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 25 14:53:58 2017 -0800

    Merge branch 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This has a series of fixes and cleanups that Dave Sterba has been
      collecting.
    
      There is a pretty big variety here, cleaning up internal APIs and
      fixing corner cases"
    
    * 'for-linus-4.11' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (124 commits)
      Btrfs: use the correct type when creating cow dio extent
      Btrfs: fix deadlock between dedup on same file and starting writeback
      btrfs: use btrfs_debug instead of pr_debug in transaction abort
      btrfs: btrfs_truncate_free_space_cache always allocates path
      btrfs: free-space-cache, clean up unnecessary root arguments
      btrfs: convert btrfs_inc_block_group_ro to accept fs_info
      btrfs: flush_space always takes fs_info->fs_root
      btrfs: pass fs_info to (more) routines that are only called with extent_root
      btrfs: qgroup: Move half of the qgroup accounting time out of commit trans
      btrfs: remove unused parameter from adjust_slots_upwards
      btrfs: remove unused parameters from __btrfs_write_out_cache
      btrfs: remove unused parameter from cleanup_write_cache_enospc
      btrfs: remove unused parameter from __add_inode_ref
      btrfs: remove unused parameter from clone_copy_inline_extent
      btrfs: remove unused parameters from btrfs_cmp_data
      btrfs: remove unused parameter from __add_inline_refs
      btrfs: remove unused parameters from scrub_setup_wr_ctx
      btrfs: remove unused parameter from create_snapshot
      btrfs: remove unused parameter from init_first_rw_device
      btrfs: remove unused parameter from __btrfs_alloc_chunk
      ...

commit a9b9477db2937934e469db800317ec3ef7e81b51
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Feb 4 17:12:00 2017 +0000

    Btrfs: fix use-after-free due to wrong order of destroying work queues
    
    Before we destroy all work queues (and wait for their tasks to complete)
    we were destroying the work queues used for metadata I/O operations, which
    can result in a use-after-free problem because most tasks from all work
    queues do metadata I/O operations. For example, the tasks from the caching
    workers work queue (fs_info->caching_workers), which is destroyed only
    after the work queue used for metadata reads (fs_info->endio_meta_workers)
    is destroyed, do metadata reads, which result in attempts to queue tasks
    into the later work queue, triggering a use-after-free with a trace like
    the following:
    
    [23114.613543] general protection fault: 0000 [#1] PREEMPT SMP
    [23114.614442] Modules linked in: dm_thin_pool dm_persistent_data dm_bio_prison dm_bufio libcrc32c btrfs xor raid6_pq dm_flakey dm_mod crc32c_generic
    acpi_cpufreq tpm_tis tpm_tis_core tpm ppdev parport_pc parport i2c_piix4 processor sg evdev i2c_core psmouse pcspkr serio_raw button loop autofs4 ext4 crc16
    jbd2 mbcache sr_mod cdrom sd_mod ata_generic virtio_scsi ata_piix virtio_pci libata virtio_ring virtio e1000 scsi_mod floppy [last unloaded: scsi_debug]
    [23114.616932] CPU: 9 PID: 4537 Comm: kworker/u32:8 Not tainted 4.9.0-rc7-btrfs-next-36+ #1
    [23114.616932] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.1-0-gb3ef39f-prebuilt.qemu-project.org 04/01/2014
    [23114.616932] Workqueue: btrfs-cache btrfs_cache_helper [btrfs]
    [23114.616932] task: ffff880221d45780 task.stack: ffffc9000bc50000
    [23114.616932] RIP: 0010:[<ffffffffa037c1bf>]  [<ffffffffa037c1bf>] btrfs_queue_work+0x2c/0x190 [btrfs]
    [23114.616932] RSP: 0018:ffff88023f443d60  EFLAGS: 00010246
    [23114.616932] RAX: 0000000000000000 RBX: 6b6b6b6b6b6b6b6b RCX: 0000000000000102
    [23114.616932] RDX: ffffffffa0419000 RSI: ffff88011df534f0 RDI: ffff880101f01c00
    [23114.616932] RBP: ffff88023f443d80 R08: 00000000000f7000 R09: 000000000000ffff
    [23114.616932] R10: ffff88023f443d48 R11: 0000000000001000 R12: ffff88011df534f0
    [23114.616932] R13: ffff880135963868 R14: 0000000000001000 R15: 0000000000001000
    [23114.616932] FS:  0000000000000000(0000) GS:ffff88023f440000(0000) knlGS:0000000000000000
    [23114.616932] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [23114.616932] CR2: 00007f0fb9f8e520 CR3: 0000000001a0b000 CR4: 00000000000006e0
    [23114.616932] Stack:
    [23114.616932]  ffff880101f01c00 ffff88011df534f0 ffff880135963868 0000000000001000
    [23114.616932]  ffff88023f443da0 ffffffffa03470af ffff880149b37200 ffff880135963868
    [23114.616932]  ffff88023f443db8 ffffffff8125293c ffff880149b37200 ffff88023f443de0
    [23114.616932] Call Trace:
    [23114.616932]  <IRQ> [23114.616932]  [<ffffffffa03470af>] end_workqueue_bio+0xd5/0xda [btrfs]
    [23114.616932]  [<ffffffff8125293c>] bio_endio+0x54/0x57
    [23114.616932]  [<ffffffffa0377929>] btrfs_end_bio+0xf7/0x106 [btrfs]
    [23114.616932]  [<ffffffff8125293c>] bio_endio+0x54/0x57
    [23114.616932]  [<ffffffff8125955f>] blk_update_request+0x21a/0x30f
    [23114.616932]  [<ffffffffa0022316>] scsi_end_request+0x31/0x182 [scsi_mod]
    [23114.616932]  [<ffffffffa00235fc>] scsi_io_completion+0x1ce/0x4c8 [scsi_mod]
    [23114.616932]  [<ffffffffa001ba9d>] scsi_finish_command+0x104/0x10d [scsi_mod]
    [23114.616932]  [<ffffffffa002311f>] scsi_softirq_done+0x101/0x10a [scsi_mod]
    [23114.616932]  [<ffffffff8125fbd9>] blk_done_softirq+0x82/0x8d
    [23114.616932]  [<ffffffff814c8a4b>] __do_softirq+0x1ab/0x412
    [23114.616932]  [<ffffffff8105b01d>] irq_exit+0x49/0x99
    [23114.616932]  [<ffffffff81035135>] smp_call_function_single_interrupt+0x24/0x26
    [23114.616932]  [<ffffffff814c7ec9>] call_function_single_interrupt+0x89/0x90
    [23114.616932]  <EOI> [23114.616932]  [<ffffffffa0023262>] ? scsi_request_fn+0x13a/0x2a1 [scsi_mod]
    [23114.616932]  [<ffffffff814c5966>] ? _raw_spin_unlock_irq+0x2c/0x4a
    [23114.616932]  [<ffffffff814c596c>] ? _raw_spin_unlock_irq+0x32/0x4a
    [23114.616932]  [<ffffffff814c5966>] ? _raw_spin_unlock_irq+0x2c/0x4a
    [23114.616932]  [<ffffffffa0023262>] scsi_request_fn+0x13a/0x2a1 [scsi_mod]
    [23114.616932]  [<ffffffff8125590e>] __blk_run_queue_uncond+0x22/0x2b
    [23114.616932]  [<ffffffff81255930>] __blk_run_queue+0x19/0x1b
    [23114.616932]  [<ffffffff8125ab01>] blk_queue_bio+0x268/0x282
    [23114.616932]  [<ffffffff81258f44>] generic_make_request+0xbd/0x160
    [23114.616932]  [<ffffffff812590e7>] submit_bio+0x100/0x11d
    [23114.616932]  [<ffffffff81298603>] ? __this_cpu_preempt_check+0x13/0x15
    [23114.616932]  [<ffffffff812a1805>] ? __percpu_counter_add+0x8e/0xa7
    [23114.616932]  [<ffffffffa03bfd47>] btrfsic_submit_bio+0x1a/0x1d [btrfs]
    [23114.616932]  [<ffffffffa0377db2>] btrfs_map_bio+0x1f4/0x26d [btrfs]
    [23114.616932]  [<ffffffffa0348a33>] btree_submit_bio_hook+0x74/0xbf [btrfs]
    [23114.616932]  [<ffffffffa03489bf>] ? btrfs_wq_submit_bio+0x160/0x160 [btrfs]
    [23114.616932]  [<ffffffffa03697a9>] submit_one_bio+0x6b/0x89 [btrfs]
    [23114.616932]  [<ffffffffa036f5be>] read_extent_buffer_pages+0x170/0x1ec [btrfs]
    [23114.616932]  [<ffffffffa03471fa>] ? free_root_pointers+0x64/0x64 [btrfs]
    [23114.616932]  [<ffffffffa0348adf>] readahead_tree_block+0x3f/0x4c [btrfs]
    [23114.616932]  [<ffffffffa032e115>] read_block_for_search.isra.20+0x1ce/0x23d [btrfs]
    [23114.616932]  [<ffffffffa032fab8>] btrfs_search_slot+0x65f/0x774 [btrfs]
    [23114.616932]  [<ffffffffa036eff1>] ? free_extent_buffer+0x73/0x7e [btrfs]
    [23114.616932]  [<ffffffffa0331ba4>] btrfs_next_old_leaf+0xa1/0x33c [btrfs]
    [23114.616932]  [<ffffffffa0331e4f>] btrfs_next_leaf+0x10/0x12 [btrfs]
    [23114.616932]  [<ffffffffa0336aa6>] caching_thread+0x22d/0x416 [btrfs]
    [23114.616932]  [<ffffffffa037bce9>] btrfs_scrubparity_helper+0x187/0x3b6 [btrfs]
    [23114.616932]  [<ffffffffa037c036>] btrfs_cache_helper+0xe/0x10 [btrfs]
    [23114.616932]  [<ffffffff8106cf96>] process_one_work+0x273/0x4e4
    [23114.616932]  [<ffffffff8106d6db>] worker_thread+0x1eb/0x2ca
    [23114.616932]  [<ffffffff8106d4f0>] ? rescuer_thread+0x2b6/0x2b6
    [23114.616932]  [<ffffffff81072a81>] kthread+0xd5/0xdd
    [23114.616932]  [<ffffffff810729ac>] ? __kthread_unpark+0x5a/0x5a
    [23114.616932]  [<ffffffff814c6257>] ret_from_fork+0x27/0x40
    [23114.616932] Code: 1f 44 00 00 55 48 89 e5 41 56 41 55 41 54 53 49 89 f4 48 8b 46 70 a8 04 74 09 48 8b 5f 08 48 85 db 75 03 48 8b 1f 49 89 5c 24 68 <83> 7b
    64 ff 74 04 f0 ff 43 58 49 83 7c 24 08 00 74 2c 4c 8d 6b
    [23114.616932] RIP  [<ffffffffa037c1bf>] btrfs_queue_work+0x2c/0x190 [btrfs]
    [23114.616932]  RSP <ffff88023f443d60>
    [23114.689493] ---[ end trace 6e48b6bc707ca34b ]---
    [23114.690166] Kernel panic - not syncing: Fatal exception in interrupt
    [23114.691283] Kernel Offset: disabled
    [23114.691918] ---[ end Kernel panic - not syncing: Fatal exception in interrupt
    
    The following diagram shows the sequence of operations that lead to the
    use-after-free problem from the above trace:
    
            CPU 1                               CPU 2                                     CPU 3
    
                                           caching_thread()
     close_ctree()
       btrfs_stop_all_workers()
         btrfs_destroy_workqueue(
          fs_info->endio_meta_workers)
    
                                             btrfs_search_slot()
                                              read_block_for_search()
                                               readahead_tree_block()
                                                read_extent_buffer_pages()
                                                 submit_one_bio()
                                                  btree_submit_bio_hook()
                                                   btrfs_bio_wq_end_io()
                                                    --> sets the bio's
                                                        bi_end_io callback
                                                        to end_workqueue_bio()
                                                   --> bio is submitted
                                                                                      bio completes
                                                                                      and its bi_end_io callback
                                                                                      is invoked
                                                                                       --> end_workqueue_bio()
                                                                                           --> attempts to queue
                                                                                               a task on fs_info->endio_meta_workers
    
         btrfs_destroy_workqueue(
          fs_info->caching_workers)
    
    So fix this by destroying the queues used for metadata I/O tasks only
    after destroying all the other queues.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d0e61d58b121..32a9ec11888d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2205,11 +2205,9 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->delalloc_workers);
 	btrfs_destroy_workqueue(fs_info->workers);
 	btrfs_destroy_workqueue(fs_info->endio_workers);
-	btrfs_destroy_workqueue(fs_info->endio_meta_workers);
 	btrfs_destroy_workqueue(fs_info->endio_raid56_workers);
 	btrfs_destroy_workqueue(fs_info->endio_repair_workers);
 	btrfs_destroy_workqueue(fs_info->rmw_workers);
-	btrfs_destroy_workqueue(fs_info->endio_meta_write_workers);
 	btrfs_destroy_workqueue(fs_info->endio_write_workers);
 	btrfs_destroy_workqueue(fs_info->endio_freespace_worker);
 	btrfs_destroy_workqueue(fs_info->submit_workers);
@@ -2219,6 +2217,13 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->flush_workers);
 	btrfs_destroy_workqueue(fs_info->qgroup_rescan_workers);
 	btrfs_destroy_workqueue(fs_info->extent_workers);
+	/*
+	 * Now that all other work queues are destroyed, we can safely destroy
+	 * the queues used for metadata I/O, since tasks from those other work
+	 * queues can do metadata I/O operations.
+	 */
+	btrfs_destroy_workqueue(fs_info->endio_meta_workers);
+	btrfs_destroy_workqueue(fs_info->endio_meta_write_workers);
 }
 
 static void free_root_extent_buffers(struct btrfs_root *root)

commit 5cdd7db6c5c9d33dc66ecdd81aa8020276c7d140
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 1 22:39:50 2017 +0000

    Btrfs: fix assertion failure when freeing block groups at close_ctree()
    
    At close_ctree() we free the block groups and then only after we wait for
    any running worker kthreads to finish and shutdown the workqueues. This
    behaviour is racy and it triggers an assertion failure when freeing block
    groups because while we are doing it we can have for example a block group
    caching kthread running, and in that case the block group's reference
    count can still be greater than 1 by the time we assert its reference count
    is 1, leading to an assertion failure:
    
    [19041.198004] assertion failed: atomic_read(&block_group->count) == 1, file: fs/btrfs/extent-tree.c, line: 9799
    [19041.200584] ------------[ cut here ]------------
    [19041.201692] kernel BUG at fs/btrfs/ctree.h:3418!
    [19041.202830] invalid opcode: 0000 [#1] PREEMPT SMP
    [19041.203929] Modules linked in: btrfs xor raid6_pq dm_flakey dm_mod crc32c_generic ppdev sg psmouse acpi_cpufreq pcspkr parport_pc evdev tpm_tis parport tpm_tis_core i2c_piix4 i2c_core tpm serio_raw processor button loop autofs4 ext4 crc16 jbd2 mbcache sr_mod cdrom sd_mod ata_generic virtio_scsi ata_piix virtio_pci libata virtio_ring virtio e1000 scsi_mod floppy [last unloaded: btrfs]
    [19041.208082] CPU: 6 PID: 29051 Comm: umount Not tainted 4.9.0-rc7-btrfs-next-36+ #1
    [19041.208082] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.1-0-gb3ef39f-prebuilt.qemu-project.org 04/01/2014
    [19041.208082] task: ffff88015f028980 task.stack: ffffc9000ad34000
    [19041.208082] RIP: 0010:[<ffffffffa03e319e>]  [<ffffffffa03e319e>] assfail.constprop.41+0x1c/0x1e [btrfs]
    [19041.208082] RSP: 0018:ffffc9000ad37d60  EFLAGS: 00010286
    [19041.208082] RAX: 0000000000000061 RBX: ffff88015ecb4000 RCX: 0000000000000001
    [19041.208082] RDX: ffff88023f392fb8 RSI: ffffffff817ef7ba RDI: 00000000ffffffff
    [19041.208082] RBP: ffffc9000ad37d60 R08: 0000000000000001 R09: 0000000000000000
    [19041.208082] R10: ffffc9000ad37cb0 R11: ffffffff82f2b66d R12: ffff88023431d170
    [19041.208082] R13: ffff88015ecb40c0 R14: ffff88023431d000 R15: ffff88015ecb4100
    [19041.208082] FS:  00007f44f3d42840(0000) GS:ffff88023f380000(0000) knlGS:0000000000000000
    [19041.208082] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [19041.208082] CR2: 00007f65d623b000 CR3: 00000002166f2000 CR4: 00000000000006e0
    [19041.208082] Stack:
    [19041.208082]  ffffc9000ad37d98 ffffffffa035989f ffff88015ecb4000 ffff88015ecb5630
    [19041.208082]  ffff88014f6be000 0000000000000000 00007ffcf0ba6a10 ffffc9000ad37df8
    [19041.208082]  ffffffffa0368cd4 ffff88014e9658e0 ffffc9000ad37e08 ffffffff811a634d
    [19041.208082] Call Trace:
    [19041.208082]  [<ffffffffa035989f>] btrfs_free_block_groups+0x17f/0x392 [btrfs]
    [19041.208082]  [<ffffffffa0368cd4>] close_ctree+0x1c5/0x2e1 [btrfs]
    [19041.208082]  [<ffffffff811a634d>] ? evict_inodes+0x132/0x141
    [19041.208082]  [<ffffffffa034356d>] btrfs_put_super+0x15/0x17 [btrfs]
    [19041.208082]  [<ffffffff8118fc32>] generic_shutdown_super+0x6a/0xeb
    [19041.208082]  [<ffffffff8119004f>] kill_anon_super+0x12/0x1c
    [19041.208082]  [<ffffffffa0343370>] btrfs_kill_super+0x16/0x21 [btrfs]
    [19041.208082]  [<ffffffff8118fad1>] deactivate_locked_super+0x3b/0x68
    [19041.208082]  [<ffffffff8118fb34>] deactivate_super+0x36/0x39
    [19041.208082]  [<ffffffff811a9946>] cleanup_mnt+0x58/0x76
    [19041.208082]  [<ffffffff811a99a2>] __cleanup_mnt+0x12/0x14
    [19041.208082]  [<ffffffff81071573>] task_work_run+0x6f/0x95
    [19041.208082]  [<ffffffff81001897>] prepare_exit_to_usermode+0xa3/0xc1
    [19041.208082]  [<ffffffff81001a23>] syscall_return_slowpath+0x16e/0x1d2
    [19041.208082]  [<ffffffff814c607d>] entry_SYSCALL_64_fastpath+0xab/0xad
    [19041.208082] Code: c7 ae a0 3e a0 48 89 e5 e8 4e 74 d4 e0 0f 0b 55 89 f1 48 c7 c2 0b a4 3e a0 48 89 fe 48 c7 c7 a4 a6 3e a0 48 89 e5 e8 30 74 d4 e0 <0f> 0b 55 31 d2 48 89 e5 e8 d5 b9 f7 ff 5d c3 48 63 f6 55 31 c9
    [19041.208082] RIP  [<ffffffffa03e319e>] assfail.constprop.41+0x1c/0x1e [btrfs]
    [19041.208082]  RSP <ffffc9000ad37d60>
    [19041.279264] ---[ end trace 23330586f16f064d ]---
    
    This started happening as of kernel 4.8, since commit f3bca8028bd9
    ("Btrfs: add ASSERT for block group's memory leak") introduced these
    assertions.
    
    So fix this by freeing the block groups only after waiting for all
    worker kthreads to complete and shutdown the workqueues.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2b06f557c176..d0e61d58b121 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3261,7 +3261,6 @@ int open_ctree(struct super_block *sb,
 
 fail_block_groups:
 	btrfs_put_block_group_cache(fs_info);
-	btrfs_free_block_groups(fs_info);
 
 fail_tree_roots:
 	free_root_pointers(fs_info, 1);
@@ -3269,6 +3268,7 @@ int open_ctree(struct super_block *sb,
 
 fail_sb_buffer:
 	btrfs_stop_all_workers(fs_info);
+	btrfs_free_block_groups(fs_info);
 fail_alloc:
 fail_iput:
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
@@ -3977,8 +3977,6 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 
 	btrfs_put_block_group_cache(fs_info);
 
-	btrfs_free_block_groups(fs_info);
-
 	/*
 	 * we must make sure there is not any read request to
 	 * submit after we stopping all workers.
@@ -3986,6 +3984,8 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	btrfs_stop_all_workers(fs_info);
 
+	btrfs_free_block_groups(fs_info);
+
 	clear_bit(BTRFS_FS_OPEN, &fs_info->flags);
 	free_root_pointers(fs_info, 1);
 

commit 3d3a126a81f152a5abfe19916a5099d2bbd38f9d
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 10 19:23:20 2017 +0100

    btrfs: remove unused parameter from btrfs_check_super_valid
    
    None of the checks need to know the ro/rw status as they're all not
    changing the superblock. Moreover, we can access the sb flags directly
    if we'd need to decide by the ro/rw status.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 441a62cd0351..2b06f557c176 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -64,8 +64,7 @@
 static const struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
-static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
-				    int read_only);
+static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info);
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				      struct btrfs_fs_info *fs_info);
@@ -2801,7 +2800,7 @@ int open_ctree(struct super_block *sb,
 
 	memcpy(fs_info->fsid, fs_info->super_copy->fsid, BTRFS_FSID_SIZE);
 
-	ret = btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
+	ret = btrfs_check_super_valid(fs_info);
 	if (ret) {
 		btrfs_err(fs_info, "superblock contains fatal errors");
 		err = -EINVAL;
@@ -4115,8 +4114,7 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 	return btree_read_extent_buffer_pages(fs_info, buf, parent_transid);
 }
 
-static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
-			      int read_only)
+static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info)
 {
 	struct btrfs_super_block *sb = fs_info->super_copy;
 	u64 nodesize = btrfs_super_nodesize(sb);

commit eece6a9cf69140fe1886f14d9a96add4f9929d78
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 10 19:04:32 2017 +0100

    btrfs: merge two superblock writing helpers
    
    write_all_supers and write_ctree_super are almost equal, the parameter
    'trans' is unused so we can drop it and have just one helper.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 43e71457c193..441a62cd0351 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3695,7 +3695,7 @@ int btrfs_calc_num_tolerated_disk_barrier_failures(
 	return num_tolerated_disk_barrier_failures;
 }
 
-static int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
+int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 {
 	struct list_head *head;
 	struct btrfs_device *dev;
@@ -3789,12 +3789,6 @@ static int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 	return 0;
 }
 
-int write_ctree_super(struct btrfs_trans_handle *trans,
-		      struct btrfs_fs_info *fs_info, int max_mirrors)
-{
-	return write_all_supers(fs_info, max_mirrors);
-}
-
 /* Drop a fs root from the radix tree and free it. */
 void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 				  struct btrfs_root *root)

commit b75f50624394fff4f0e6521fda673317d5b79309
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 10 18:52:06 2017 +0100

    btrfs: remove unused parameter from write_dev_supers
    
    The barriers are handled by the caller.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 48846d215e97..43e71457c193 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3410,7 +3410,7 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
  */
 static int write_dev_supers(struct btrfs_device *device,
 			    struct btrfs_super_block *sb,
-			    int do_barriers, int wait, int max_mirrors)
+			    int wait, int max_mirrors)
 {
 	struct buffer_head *bh;
 	int i;
@@ -3752,7 +3752,7 @@ static int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 		flags = btrfs_super_flags(sb);
 		btrfs_set_super_flags(sb, flags | BTRFS_HEADER_FLAG_WRITTEN);
 
-		ret = write_dev_supers(dev, sb, do_barriers, 0, max_mirrors);
+		ret = write_dev_supers(dev, sb, 0, max_mirrors);
 		if (ret)
 			total_errors++;
 	}
@@ -3775,7 +3775,7 @@ static int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 		if (!dev->in_fs_metadata || !dev->writeable)
 			continue;
 
-		ret = write_dev_supers(dev, sb, do_barriers, 1, max_mirrors);
+		ret = write_dev_supers(dev, sb, 1, max_mirrors);
 		if (ret)
 			total_errors++;
 	}

commit 7c302b49dd757b03d12bec772e1d1f462684c991
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 10 18:47:57 2017 +0100

    btrfs: remove unused parameter from clean_tree_block
    
    Added but never needed.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 89cd597883fd..48846d215e97 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1248,8 +1248,7 @@ struct extent_buffer *read_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr,
 
 }
 
-void clean_tree_block(struct btrfs_trans_handle *trans,
-		      struct btrfs_fs_info *fs_info,
+void clean_tree_block(struct btrfs_fs_info *fs_info,
 		      struct extent_buffer *buf)
 {
 	if (btrfs_header_generation(buf) ==

commit e27f62652b89d0701d87112339f286ebf24ffc8c
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 10 18:46:09 2017 +0100

    btrfs: remove unused parameter from check_async_write
    
    Added but never used.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 18004169552c..89cd597883fd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1005,7 +1005,7 @@ static int __btree_submit_bio_done(struct inode *inode, struct bio *bio,
 	return ret;
 }
 
-static int check_async_write(struct inode *inode, unsigned long bio_flags)
+static int check_async_write(unsigned long bio_flags)
 {
 	if (bio_flags & EXTENT_BIO_TREE_LOG)
 		return 0;
@@ -1021,7 +1021,7 @@ static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 				 u64 bio_offset)
 {
 	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
-	int async = check_async_write(inode, bio_flags);
+	int async = check_async_write(bio_flags);
 	int ret;
 
 	if (bio_op(bio) != REQ_OP_WRITE) {

commit efa7c9f97e3ef624e9a398bf69c15f58eea9f0e8
Author: Jan Kara <jack@suse.cz>
Date:   Thu Feb 2 15:56:53 2017 +0100

    block: Get rid of blk_get_backing_dev_info()
    
    blk_get_backing_dev_info() is now a simple dereference. Remove that
    function and simplify some code around that.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 18004169552c..37a31b12bb0c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1800,7 +1800,7 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	list_for_each_entry_rcu(device, &info->fs_devices->devices, dev_list) {
 		if (!device->bdev)
 			continue;
-		bdi = blk_get_backing_dev_info(device->bdev);
+		bdi = device->bdev->bd_bdi;
 		if (bdi_congested(bdi, bdi_bits)) {
 			ret = 1;
 			break;

commit 087a76d390cbb8c0d21ea0cb3672ab4a7bb76362
Merge: 759b2656b259 2939e1a86f75
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 16 10:53:01 2016 -0800

    Merge branch 'for-linus-4.10' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "Jeff Mahoney and Dave Sterba have a really nice set of cleanups in
      here, and Christoph pitched in corrections/improvements to make btrfs
      use proper helpers for bio walking instead of doing it by hand.
    
      There are some key fixes as well, including some long standing bugs
      that took forever to track down in btrfs_drop_extents and during
      balance"
    
    * 'for-linus-4.10' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (77 commits)
      btrfs: limit async_work allocation and worker func duration
      Revert "Btrfs: adjust len of writes if following a preallocated extent"
      Btrfs: don't WARN() in btrfs_transaction_abort() for IO errors
      btrfs: opencode chunk locking, remove helpers
      btrfs: remove root parameter from transaction commit/end routines
      btrfs: split btrfs_wait_marked_extents into normal and tree log functions
      btrfs: take an fs_info directly when the root is not used otherwise
      btrfs: simplify btrfs_wait_cache_io prototype
      btrfs: convert extent-tree tracepoints to use fs_info
      btrfs: root->fs_info cleanup, access fs_info->delayed_root directly
      btrfs: root->fs_info cleanup, add fs_info convenience variables
      btrfs: root->fs_info cleanup, update_block_group{,flags}
      btrfs: root->fs_info cleanup, lock/unlock_chunks
      btrfs: root->fs_info cleanup, btrfs_calc_{trans,trunc}_metadata_size
      btrfs: pull node/sector/stripe sizes out of root and into fs_info
      btrfs: root->fs_info cleanup, io_ctl_init
      btrfs: root->fs_info cleanup, use fs_info->dev_root everywhere
      btrfs: struct reada_control.root -> reada_control.fs_info
      btrfs: struct btrfsic_state->root should be an fs_info
      btrfs: alloc_reserved_file_extent trace point should use extent_root
      ...

commit 5f52a2c512a55500349aa261e469d099ede0f256
Merge: 7c4c71ac8a72 2a7bf53f577e
Author: Chris Mason <clm@fb.com>
Date:   Tue Dec 13 09:14:42 2016 -0800

    Merge branch 'for-chris-4.10' of git://git.kernel.org/pub/scm/linux/kernel/git/fdmanana/linux into for-linus-4.10
    
    Patches queued up by Filipe:
    
    The most important change is still the fix for the extent tree
    corruption that happens due to balance when qgroups are enabled (a
    regression introduced in 4.7 by a fix for a regression from the last
    qgroups rework). This has been hitting SLE and openSUSE users and QA
    very badly, where transactions keep getting aborted when running
    delayed references leaving the root filesystem in RO mode and nearly
    unusable.  There are fixes here that allow us to run xfstests again
    with the integrity checker enabled, which has been impossible since 4.8
    (apparently I'm the only one running xfstests with the integrity
    checker enabled, which is useful to validate dirtied leafs, like
    checking if there are keys out of order, etc).  The rest are just some
    trivial fixes, most of them tagged for stable, and two cleanups.
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 34441361c4f52a5f6e41d8de8e5debbeb415dbf0
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 4 19:34:27 2016 +0200

    btrfs: opencode chunk locking, remove helpers
    
    The helpers are trivial and we don't use them consistently.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 196f1aafcea9..848d5e1c0585 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4003,7 +4003,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	__btrfs_free_block_rsv(root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;
 
-	lock_chunks(fs_info);
+	mutex_lock(&fs_info->chunk_mutex);
 	while (!list_empty(&fs_info->pinned_chunks)) {
 		struct extent_map *em;
 
@@ -4012,7 +4012,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 		list_del_init(&em->list);
 		free_extent_map(em);
 	}
-	unlock_chunks(fs_info);
+	mutex_unlock(&fs_info->chunk_mutex);
 }
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,

commit 3a45bb207ee2c5548ebf6f5fcc7d249e141f15e8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Sep 9 21:39:03 2016 -0400

    btrfs: remove root parameter from transaction commit/end routines
    
    Now we only use the root parameter to print the root objectid in
    a tracepoint.  We can use the root parameter from the transaction
    handle for that.  It's also used to join the transaction with
    async commits, so we remove the comment that it's just for checking.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3ce36b526ebe..196f1aafcea9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1913,7 +1913,7 @@ static int cleaner_kthread(void *arg)
 	} else {
 		int ret;
 
-		ret = btrfs_commit_transaction(trans, root);
+		ret = btrfs_commit_transaction(trans);
 		if (ret)
 			btrfs_err(fs_info,
 				  "cleaner open transaction commit returned %d",
@@ -1965,9 +1965,9 @@ static int transaction_kthread(void *arg)
 			goto sleep;
 		}
 		if (transid == trans->transid) {
-			btrfs_commit_transaction(trans, root);
+			btrfs_commit_transaction(trans);
 		} else {
-			btrfs_end_transaction(trans, root);
+			btrfs_end_transaction(trans);
 		}
 sleep:
 		wake_up_process(fs_info->cleaner_kthread);
@@ -3901,7 +3901,7 @@ int btrfs_commit_super(struct btrfs_fs_info *fs_info)
 	trans = btrfs_join_transaction(root);
 	if (IS_ERR(trans))
 		return PTR_ERR(trans);
-	return btrfs_commit_transaction(trans, root);
+	return btrfs_commit_transaction(trans);
 }
 
 void close_ctree(struct btrfs_fs_info *fs_info)

commit 2ff7e61e0d30ff166a2ae94575526bffe11fd1a8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:24 2016 -0400

    btrfs: take an fs_info directly when the root is not used otherwise
    
    There are loads of functions in btrfs that accept a root parameter
    but only use it to obtain an fs_info pointer.  Let's convert those to
    just accept an fs_info pointer directly.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5f7d283933b4..3ce36b526ebe 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -68,15 +68,15 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 				    int read_only);
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
-				      struct btrfs_root *root);
+				      struct btrfs_fs_info *fs_info);
 static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root);
-static int btrfs_destroy_marked_extents(struct btrfs_root *root,
+static int btrfs_destroy_marked_extents(struct btrfs_fs_info *fs_info,
 					struct extent_io_tree *dirty_pages,
 					int mark);
-static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
+static int btrfs_destroy_pinned_extent(struct btrfs_fs_info *fs_info,
 				       struct extent_io_tree *pinned_extents);
-static int btrfs_cleanup_transaction(struct btrfs_root *root);
-static void btrfs_error_commit_super(struct btrfs_root *root);
+static int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info);
+static void btrfs_error_commit_super(struct btrfs_fs_info *fs_info);
 
 /*
  * btrfs_end_io_wq structs are used to do processing in task context when an IO
@@ -440,11 +440,10 @@ static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
  * helper to read a given tree block, doing retries as required when
  * the checksums don't match and we have alternate mirrors to try.
  */
-static int btree_read_extent_buffer_pages(struct btrfs_root *root,
+static int btree_read_extent_buffer_pages(struct btrfs_fs_info *fs_info,
 					  struct extent_buffer *eb,
 					  u64 parent_transid)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct extent_io_tree *io_tree;
 	int failed = 0;
 	int ret;
@@ -492,7 +491,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 	}
 
 	if (failed && !ret && failed_mirror)
-		repair_eb_io_failure(root, eb, failed_mirror);
+		repair_eb_io_failure(fs_info, eb, failed_mirror);
 
 	return ret;
 }
@@ -983,7 +982,7 @@ static int __btree_submit_bio_done(struct inode *inode, struct bio *bio,
 	 * when we're called for a write, we're already in the async
 	 * submission context.  Just jump into btrfs_map_bio
 	 */
-	ret = btrfs_map_bio(BTRFS_I(inode)->root, bio, mirror_num, 1);
+	ret = btrfs_map_bio(btrfs_sb(inode->i_sb), bio, mirror_num, 1);
 	if (ret) {
 		bio->bi_error = ret;
 		bio_endio(bio);
@@ -1019,12 +1018,12 @@ static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 					  BTRFS_WQ_ENDIO_METADATA);
 		if (ret)
 			goto out_w_error;
-		ret = btrfs_map_bio(BTRFS_I(inode)->root, bio, mirror_num, 0);
+		ret = btrfs_map_bio(fs_info, bio, mirror_num, 0);
 	} else if (!async) {
 		ret = btree_csum_one_bio(bio);
 		if (ret)
 			goto out_w_error;
-		ret = btrfs_map_bio(BTRFS_I(inode)->root, bio, mirror_num, 0);
+		ret = btrfs_map_bio(fs_info, bio, mirror_num, 0);
 	} else {
 		/*
 		 * kthread helpers are used to submit writes so that
@@ -1148,12 +1147,12 @@ static const struct address_space_operations btree_aops = {
 	.set_page_dirty = btree_set_page_dirty,
 };
 
-void readahead_tree_block(struct btrfs_root *root, u64 bytenr)
+void readahead_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr)
 {
 	struct extent_buffer *buf = NULL;
-	struct inode *btree_inode = root->fs_info->btree_inode;
+	struct inode *btree_inode = fs_info->btree_inode;
 
-	buf = btrfs_find_create_tree_block(root, bytenr);
+	buf = btrfs_find_create_tree_block(fs_info, bytenr);
 	if (IS_ERR(buf))
 		return;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
@@ -1161,15 +1160,15 @@ void readahead_tree_block(struct btrfs_root *root, u64 bytenr)
 	free_extent_buffer(buf);
 }
 
-int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr,
+int reada_tree_block_flagged(struct btrfs_fs_info *fs_info, u64 bytenr,
 			 int mirror_num, struct extent_buffer **eb)
 {
 	struct extent_buffer *buf = NULL;
-	struct inode *btree_inode = root->fs_info->btree_inode;
+	struct inode *btree_inode = fs_info->btree_inode;
 	struct extent_io_tree *io_tree = &BTRFS_I(btree_inode)->io_tree;
 	int ret;
 
-	buf = btrfs_find_create_tree_block(root, bytenr);
+	buf = btrfs_find_create_tree_block(fs_info, bytenr);
 	if (IS_ERR(buf))
 		return 0;
 
@@ -1193,11 +1192,10 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr,
 	return 0;
 }
 
-struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
-						 u64 bytenr)
+struct extent_buffer *btrfs_find_create_tree_block(
+						struct btrfs_fs_info *fs_info,
+						u64 bytenr)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
-
 	if (btrfs_is_testing(fs_info))
 		return alloc_test_extent_buffer(fs_info, bytenr);
 	return alloc_extent_buffer(fs_info, bytenr);
@@ -1216,17 +1214,17 @@ int btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
 				       buf->start, buf->start + buf->len - 1);
 }
 
-struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
+struct extent_buffer *read_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr,
 				      u64 parent_transid)
 {
 	struct extent_buffer *buf = NULL;
 	int ret;
 
-	buf = btrfs_find_create_tree_block(root, bytenr);
+	buf = btrfs_find_create_tree_block(fs_info, bytenr);
 	if (IS_ERR(buf))
 		return buf;
 
-	ret = btree_read_extent_buffer_pages(root, buf, parent_transid);
+	ret = btree_read_extent_buffer_pages(fs_info, buf, parent_transid);
 	if (ret) {
 		free_extent_buffer(buf);
 		return ERR_PTR(ret);
@@ -1578,7 +1576,8 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	}
 
 	generation = btrfs_root_generation(&root->root_item);
-	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
+	root->node = read_tree_block(fs_info,
+				     btrfs_root_bytenr(&root->root_item),
 				     generation);
 	if (IS_ERR(root->node)) {
 		ret = PTR_ERR(root->node);
@@ -1841,7 +1840,7 @@ static int cleaner_kthread(void *arg)
 		again = 0;
 
 		/* Make the cleaner go to sleep early. */
-		if (btrfs_need_cleaner_sleep(root))
+		if (btrfs_need_cleaner_sleep(fs_info))
 			goto sleep;
 
 		/*
@@ -1858,13 +1857,13 @@ static int cleaner_kthread(void *arg)
 		 * Avoid the problem that we change the status of the fs
 		 * during the above check and trylock.
 		 */
-		if (btrfs_need_cleaner_sleep(root)) {
+		if (btrfs_need_cleaner_sleep(fs_info)) {
 			mutex_unlock(&fs_info->cleaner_mutex);
 			goto sleep;
 		}
 
 		mutex_lock(&fs_info->cleaner_delayed_iput_mutex);
-		btrfs_run_delayed_iputs(root);
+		btrfs_run_delayed_iputs(fs_info);
 		mutex_unlock(&fs_info->cleaner_delayed_iput_mutex);
 
 		again = btrfs_clean_one_deleted_snapshot(root);
@@ -1976,7 +1975,7 @@ static int transaction_kthread(void *arg)
 
 		if (unlikely(test_bit(BTRFS_FS_STATE_ERROR,
 				      &fs_info->fs_state)))
-			btrfs_cleanup_transaction(root);
+			btrfs_cleanup_transaction(fs_info);
 		set_current_state(TASK_INTERRUPTIBLE);
 		if (!kthread_should_stop() &&
 				(!btrfs_transaction_blocked(fs_info) ||
@@ -2266,8 +2265,7 @@ void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
 
 	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state)) {
 		btrfs_free_log_root_tree(NULL, fs_info);
-		btrfs_destroy_pinned_extent(fs_info->tree_root,
-					    fs_info->pinned_extents);
+		btrfs_destroy_pinned_extent(fs_info, fs_info->pinned_extents);
 	}
 }
 
@@ -2295,30 +2293,29 @@ static void btrfs_init_balance(struct btrfs_fs_info *fs_info)
 
 static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info)
 {
-	fs_info->btree_inode->i_ino = BTRFS_BTREE_INODE_OBJECTID;
-	set_nlink(fs_info->btree_inode, 1);
+	struct inode *inode = fs_info->btree_inode;
+
+	inode->i_ino = BTRFS_BTREE_INODE_OBJECTID;
+	set_nlink(inode, 1);
 	/*
 	 * we set the i_size on the btree inode to the max possible int.
 	 * the real end of the address space is determined by all of
 	 * the devices in the system
 	 */
-	fs_info->btree_inode->i_size = OFFSET_MAX;
-	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
+	inode->i_size = OFFSET_MAX;
+	inode->i_mapping->a_ops = &btree_aops;
 
-	RB_CLEAR_NODE(&BTRFS_I(fs_info->btree_inode)->rb_node);
-	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,
-			     fs_info->btree_inode->i_mapping);
-	BTRFS_I(fs_info->btree_inode)->io_tree.track_uptodate = 0;
-	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree);
+	RB_CLEAR_NODE(&BTRFS_I(inode)->rb_node);
+	extent_io_tree_init(&BTRFS_I(inode)->io_tree, inode->i_mapping);
+	BTRFS_I(inode)->io_tree.track_uptodate = 0;
+	extent_map_tree_init(&BTRFS_I(inode)->extent_tree);
 
-	BTRFS_I(fs_info->btree_inode)->io_tree.ops = &btree_extent_io_ops;
+	BTRFS_I(inode)->io_tree.ops = &btree_extent_io_ops;
 
-	BTRFS_I(fs_info->btree_inode)->root = fs_info->tree_root;
-	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
-	       sizeof(struct btrfs_key));
-	set_bit(BTRFS_INODE_DUMMY,
-		&BTRFS_I(fs_info->btree_inode)->runtime_flags);
-	btrfs_insert_inode_hash(fs_info->btree_inode);
+	BTRFS_I(inode)->root = fs_info->tree_root;
+	memset(&BTRFS_I(inode)->location, 0, sizeof(struct btrfs_key));
+	set_bit(BTRFS_INODE_DUMMY, &BTRFS_I(inode)->runtime_flags);
+	btrfs_insert_inode_hash(inode);
 }
 
 static void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)
@@ -2439,7 +2436,6 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 			    struct btrfs_fs_devices *fs_devices)
 {
 	int ret;
-	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct btrfs_root *log_tree_root;
 	struct btrfs_super_block *disk_super = fs_info->super_copy;
 	u64 bytenr = btrfs_super_log_root(disk_super);
@@ -2455,8 +2451,8 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 
 	__setup_root(log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
 
-	log_tree_root->node = read_tree_block(tree_root, bytenr,
-			fs_info->generation + 1);
+	log_tree_root->node = read_tree_block(fs_info, bytenr,
+					      fs_info->generation + 1);
 	if (IS_ERR(log_tree_root->node)) {
 		btrfs_warn(fs_info, "failed to read log tree");
 		ret = PTR_ERR(log_tree_root->node);
@@ -2819,7 +2815,7 @@ int open_ctree(struct super_block *sb,
 	 */
 	fs_info->compress_type = BTRFS_COMPRESS_ZLIB;
 
-	ret = btrfs_parse_options(tree_root, options, sb->s_flags);
+	ret = btrfs_parse_options(fs_info, options, sb->s_flags);
 	if (ret) {
 		err = ret;
 		goto fail_alloc;
@@ -2920,7 +2916,7 @@ int open_ctree(struct super_block *sb,
 
 	__setup_root(chunk_root, fs_info, BTRFS_CHUNK_TREE_OBJECTID);
 
-	chunk_root->node = read_tree_block(chunk_root,
+	chunk_root->node = read_tree_block(fs_info,
 					   btrfs_super_chunk_root(disk_super),
 					   generation);
 	if (IS_ERR(chunk_root->node) ||
@@ -2957,7 +2953,7 @@ int open_ctree(struct super_block *sb,
 retry_root_backup:
 	generation = btrfs_super_generation(disk_super);
 
-	tree_root->node = read_tree_block(tree_root,
+	tree_root->node = read_tree_block(fs_info,
 					  btrfs_super_root(disk_super),
 					  generation);
 	if (IS_ERR(tree_root->node) ||
@@ -3081,7 +3077,7 @@ int open_ctree(struct super_block *sb,
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_test_opt(fs_info, CHECK_INTEGRITY)) {
-		ret = btrfsic_mount(tree_root, fs_devices,
+		ret = btrfsic_mount(fs_info, fs_devices,
 				    btrfs_test_opt(fs_info,
 					CHECK_INTEGRITY_INCLUDING_EXTENT_DATA) ?
 				    1 : 0,
@@ -3233,7 +3229,7 @@ int open_ctree(struct super_block *sb,
 	btrfs_free_qgroup_config(fs_info);
 fail_trans_kthread:
 	kthread_stop(fs_info->transaction_kthread);
-	btrfs_cleanup_transaction(fs_info->tree_root);
+	btrfs_cleanup_transaction(fs_info);
 	btrfs_free_fs_roots(fs_info);
 fail_cleaner:
 	kthread_stop(fs_info->cleaner_kthread);
@@ -3685,9 +3681,8 @@ int btrfs_calc_num_tolerated_disk_barrier_failures(
 	return num_tolerated_disk_barrier_failures;
 }
 
-static int write_all_supers(struct btrfs_root *root, int max_mirrors)
+static int write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct list_head *head;
 	struct btrfs_device *dev;
 	struct btrfs_super_block *sb;
@@ -3781,9 +3776,9 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 }
 
 int write_ctree_super(struct btrfs_trans_handle *trans,
-		      struct btrfs_root *root, int max_mirrors)
+		      struct btrfs_fs_info *fs_info, int max_mirrors)
 {
-	return write_all_supers(root, max_mirrors);
+	return write_all_supers(fs_info, max_mirrors);
 }
 
 /* Drop a fs root from the radix tree and free it. */
@@ -3819,7 +3814,7 @@ static void free_fs_root(struct btrfs_root *root)
 {
 	iput(root->ino_cache_inode);
 	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
-	btrfs_free_block_rsv(root, root->orphan_block_rsv);
+	btrfs_free_block_rsv(root->fs_info, root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;
 	if (root->anon_dev)
 		free_anon_bdev(root->anon_dev);
@@ -3895,7 +3890,7 @@ int btrfs_commit_super(struct btrfs_fs_info *fs_info)
 	struct btrfs_trans_handle *trans;
 
 	mutex_lock(&fs_info->cleaner_mutex);
-	btrfs_run_delayed_iputs(root);
+	btrfs_run_delayed_iputs(fs_info);
 	mutex_unlock(&fs_info->cleaner_mutex);
 	wake_up_process(fs_info->cleaner_kthread);
 
@@ -3954,7 +3949,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	}
 
 	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
-		btrfs_error_commit_super(root);
+		btrfs_error_commit_super(fs_info);
 
 	kthread_stop(fs_info->transaction_kthread);
 	kthread_stop(fs_info->cleaner_kthread);
@@ -3991,7 +3986,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_test_opt(fs_info, CHECK_INTEGRITY))
-		btrfsic_unmount(root, fs_info->fs_devices);
+		btrfsic_unmount(fs_info->fs_devices);
 #endif
 
 	btrfs_close_devices(fs_info->fs_devices);
@@ -4066,16 +4061,15 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 				     fs_info->dirty_metadata_batch);
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_header_level(buf) == 0 && check_leaf(root, buf)) {
-		btrfs_print_leaf(root, buf);
+		btrfs_print_leaf(fs_info, buf);
 		ASSERT(0);
 	}
 #endif
 }
 
-static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
+static void __btrfs_btree_balance_dirty(struct btrfs_fs_info *fs_info,
 					int flush_delayed)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	/*
 	 * looks as though older kernels can get into trouble with
 	 * this code, they end up stuck in balance_dirty_pages forever
@@ -4086,7 +4080,7 @@ static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
 		return;
 
 	if (flush_delayed)
-		btrfs_balance_delayed_items(root);
+		btrfs_balance_delayed_items(fs_info);
 
 	ret = percpu_counter_compare(&fs_info->dirty_metadata_bytes,
 				     BTRFS_DIRTY_METADATA_THRESH);
@@ -4095,20 +4089,22 @@ static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
 	}
 }
 
-void btrfs_btree_balance_dirty(struct btrfs_root *root)
+void btrfs_btree_balance_dirty(struct btrfs_fs_info *fs_info)
 {
-	__btrfs_btree_balance_dirty(root, 1);
+	__btrfs_btree_balance_dirty(fs_info, 1);
 }
 
-void btrfs_btree_balance_dirty_nodelay(struct btrfs_root *root)
+void btrfs_btree_balance_dirty_nodelay(struct btrfs_fs_info *fs_info)
 {
-	__btrfs_btree_balance_dirty(root, 0);
+	__btrfs_btree_balance_dirty(fs_info, 0);
 }
 
 int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 {
 	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
-	return btree_read_extent_buffer_pages(root, buf, parent_transid);
+	struct btrfs_fs_info *fs_info = root->fs_info;
+
+	return btree_read_extent_buffer_pages(fs_info, buf, parent_transid);
 }
 
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
@@ -4259,19 +4255,17 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
-static void btrfs_error_commit_super(struct btrfs_root *root)
+static void btrfs_error_commit_super(struct btrfs_fs_info *fs_info)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
-
 	mutex_lock(&fs_info->cleaner_mutex);
-	btrfs_run_delayed_iputs(root);
+	btrfs_run_delayed_iputs(fs_info);
 	mutex_unlock(&fs_info->cleaner_mutex);
 
 	down_write(&fs_info->cleanup_work_sem);
 	up_write(&fs_info->cleanup_work_sem);
 
 	/* cleanup FS via transaction */
-	btrfs_cleanup_transaction(root);
+	btrfs_cleanup_transaction(fs_info);
 }
 
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root)
@@ -4314,9 +4308,8 @@ static void btrfs_destroy_all_ordered_extents(struct btrfs_fs_info *fs_info)
 }
 
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
-				      struct btrfs_root *root)
+				      struct btrfs_fs_info *fs_info)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct rb_node *node;
 	struct btrfs_delayed_ref_root *delayed_refs;
 	struct btrfs_delayed_ref_node *ref;
@@ -4372,7 +4365,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		mutex_unlock(&head->mutex);
 
 		if (pin_bytes)
-			btrfs_pin_extent(root, head->node.bytenr,
+			btrfs_pin_extent(fs_info, head->node.bytenr,
 					 head->node.num_bytes, 1);
 		btrfs_put_delayed_ref(&head->node);
 		cond_resched();
@@ -4436,11 +4429,10 @@ static void btrfs_destroy_all_delalloc_inodes(struct btrfs_fs_info *fs_info)
 	spin_unlock(&fs_info->delalloc_root_lock);
 }
 
-static int btrfs_destroy_marked_extents(struct btrfs_root *root,
+static int btrfs_destroy_marked_extents(struct btrfs_fs_info *fs_info,
 					struct extent_io_tree *dirty_pages,
 					int mark)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	int ret;
 	struct extent_buffer *eb;
 	u64 start = 0;
@@ -4470,10 +4462,9 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 	return ret;
 }
 
-static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
+static int btrfs_destroy_pinned_extent(struct btrfs_fs_info *fs_info,
 				       struct extent_io_tree *pinned_extents)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct extent_io_tree *unpin;
 	u64 start;
 	u64 end;
@@ -4489,7 +4480,7 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 			break;
 
 		clear_extent_dirty(unpin, start, end);
-		btrfs_error_unpin_extent_range(root, start, end);
+		btrfs_error_unpin_extent_range(fs_info, start, end);
 		cond_resched();
 	}
 
@@ -4520,9 +4511,8 @@ static void btrfs_cleanup_bg_io(struct btrfs_block_group_cache *cache)
 }
 
 void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
-			     struct btrfs_root *root)
+			     struct btrfs_fs_info *fs_info)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_block_group_cache *cache;
 
 	spin_lock(&cur_trans->dirty_bgs_lock);
@@ -4572,14 +4562,13 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 }
 
 void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
-				   struct btrfs_root *root)
+				   struct btrfs_fs_info *fs_info)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
-	btrfs_cleanup_dirty_bgs(cur_trans, root);
+	btrfs_cleanup_dirty_bgs(cur_trans, fs_info);
 	ASSERT(list_empty(&cur_trans->dirty_bgs));
 	ASSERT(list_empty(&cur_trans->io_bgs));
 
-	btrfs_destroy_delayed_refs(cur_trans, root);
+	btrfs_destroy_delayed_refs(cur_trans, fs_info);
 
 	cur_trans->state = TRANS_STATE_COMMIT_START;
 	wake_up(&fs_info->transaction_blocked_wait);
@@ -4590,9 +4579,9 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	btrfs_destroy_delayed_inodes(fs_info);
 	btrfs_assert_delayed_root_empty(fs_info);
 
-	btrfs_destroy_marked_extents(root, &cur_trans->dirty_pages,
+	btrfs_destroy_marked_extents(fs_info, &cur_trans->dirty_pages,
 				     EXTENT_DIRTY);
-	btrfs_destroy_pinned_extent(root,
+	btrfs_destroy_pinned_extent(fs_info,
 				    fs_info->pinned_extents);
 
 	cur_trans->state =TRANS_STATE_COMPLETED;
@@ -4604,9 +4593,8 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	*/
 }
 
-static int btrfs_cleanup_transaction(struct btrfs_root *root)
+static int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_transaction *t;
 
 	mutex_lock(&fs_info->transaction_kthread_mutex);
@@ -4618,7 +4606,7 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 		if (t->state >= TRANS_STATE_COMMIT_START) {
 			atomic_inc(&t->use_count);
 			spin_unlock(&fs_info->trans_lock);
-			btrfs_wait_for_commit(root, t->transid);
+			btrfs_wait_for_commit(fs_info, t->transid);
 			btrfs_put_transaction(t);
 			spin_lock(&fs_info->trans_lock);
 			continue;
@@ -4635,7 +4623,7 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 		} else {
 			spin_unlock(&fs_info->trans_lock);
 		}
-		btrfs_cleanup_one_transaction(t, root);
+		btrfs_cleanup_one_transaction(t, fs_info);
 
 		spin_lock(&fs_info->trans_lock);
 		if (t == fs_info->running_transaction)
@@ -4644,14 +4632,14 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 		spin_unlock(&fs_info->trans_lock);
 
 		btrfs_put_transaction(t);
-		trace_btrfs_transaction_commit(root);
+		trace_btrfs_transaction_commit(fs_info->tree_root);
 		spin_lock(&fs_info->trans_lock);
 	}
 	spin_unlock(&fs_info->trans_lock);
 	btrfs_destroy_all_ordered_extents(fs_info);
 	btrfs_destroy_delayed_inodes(fs_info);
 	btrfs_assert_delayed_root_empty(fs_info);
-	btrfs_destroy_pinned_extent(root, fs_info->pinned_extents);
+	btrfs_destroy_pinned_extent(fs_info, fs_info->pinned_extents);
 	btrfs_destroy_all_delalloc_inodes(fs_info);
 	mutex_unlock(&fs_info->transaction_kthread_mutex);
 

commit ccdf9b305a49875d49dbaec6f8d2440abb0b1994
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:23 2016 -0400

    btrfs: root->fs_info cleanup, access fs_info->delayed_root directly
    
    This results in btrfs_assert_delayed_root_empty and
    btrfs_destroy_delayed_inode taking an fs_info instead of a root.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 02ba794d171e..5f7d283933b4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4587,8 +4587,8 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	cur_trans->state = TRANS_STATE_UNBLOCKED;
 	wake_up(&fs_info->transaction_wait);
 
-	btrfs_destroy_delayed_inodes(root);
-	btrfs_assert_delayed_root_empty(root);
+	btrfs_destroy_delayed_inodes(fs_info);
+	btrfs_assert_delayed_root_empty(fs_info);
 
 	btrfs_destroy_marked_extents(root, &cur_trans->dirty_pages,
 				     EXTENT_DIRTY);
@@ -4649,8 +4649,8 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 	}
 	spin_unlock(&fs_info->trans_lock);
 	btrfs_destroy_all_ordered_extents(fs_info);
-	btrfs_destroy_delayed_inodes(root);
-	btrfs_assert_delayed_root_empty(root);
+	btrfs_destroy_delayed_inodes(fs_info);
+	btrfs_assert_delayed_root_empty(fs_info);
 	btrfs_destroy_pinned_extent(root, fs_info->pinned_extents);
 	btrfs_destroy_all_delalloc_inodes(fs_info);
 	mutex_unlock(&fs_info->transaction_kthread_mutex);

commit 0b246afa62b0cf5b09d078121f543135f28492ad
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:23 2016 -0400

    btrfs: root->fs_info cleanup, add fs_info convenience variables
    
    In routines where someptr->fs_info is referenced multiple times, we
    introduce a convenience variable.  This makes the code considerably
    more readable.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5abf3afa6ea5..02ba794d171e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -224,6 +224,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 		struct page *page, size_t pg_offset, u64 start, u64 len,
 		int create)
 {
+	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	struct extent_map_tree *em_tree = &BTRFS_I(inode)->extent_tree;
 	struct extent_map *em;
 	int ret;
@@ -231,8 +232,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 	read_lock(&em_tree->lock);
 	em = lookup_extent_mapping(em_tree, start, len);
 	if (em) {
-		em->bdev =
-			BTRFS_I(inode)->root->fs_info->fs_devices->latest_bdev;
+		em->bdev = fs_info->fs_devices->latest_bdev;
 		read_unlock(&em_tree->lock);
 		goto out;
 	}
@@ -247,7 +247,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 	em->len = (u64)-1;
 	em->block_len = (u64)-1;
 	em->block_start = 0;
-	em->bdev = BTRFS_I(inode)->root->fs_info->fs_devices->latest_bdev;
+	em->bdev = fs_info->fs_devices->latest_bdev;
 
 	write_lock(&em_tree->lock);
 	ret = add_extent_mapping(em_tree, em, 0);
@@ -444,6 +444,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 					  struct extent_buffer *eb,
 					  u64 parent_transid)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct extent_io_tree *io_tree;
 	int failed = 0;
 	int ret;
@@ -452,7 +453,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 	int failed_mirror = 0;
 
 	clear_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
-	io_tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
+	io_tree = &BTRFS_I(fs_info->btree_inode)->io_tree;
 	while (1) {
 		ret = read_extent_buffer_pages(io_tree, eb, WAIT_COMPLETE,
 					       btree_get_extent, mirror_num);
@@ -472,7 +473,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		if (test_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags))
 			break;
 
-		num_copies = btrfs_num_copies(root->fs_info,
+		num_copies = btrfs_num_copies(fs_info,
 					      eb->start, eb->len);
 		if (num_copies == 1)
 			break;
@@ -545,15 +546,16 @@ static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
-#define CORRUPT(reason, eb, root, slot)				\
-	btrfs_crit(root->fs_info, "corrupt %s, %s: block=%llu,"	\
-		   " root=%llu, slot=%d",			\
-		   btrfs_header_level(eb) == 0 ? "leaf" : "node",\
+#define CORRUPT(reason, eb, root, slot)					\
+	btrfs_crit(root->fs_info,					\
+		   "corrupt %s, %s: block=%llu, root=%llu, slot=%d",	\
+		   btrfs_header_level(eb) == 0 ? "leaf" : "node",	\
 		   reason, btrfs_header_bytenr(eb), root->objectid, slot)
 
 static noinline int check_leaf(struct btrfs_root *root,
 			       struct extent_buffer *leaf)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_key key;
 	struct btrfs_key leaf_key;
 	u32 nritems = btrfs_header_nritems(leaf);
@@ -566,7 +568,7 @@ static noinline int check_leaf(struct btrfs_root *root,
 		key.type = BTRFS_ROOT_ITEM_KEY;
 		key.offset = (u64)-1;
 
-		check_root = btrfs_get_fs_root(root->fs_info, &key, false);
+		check_root = btrfs_get_fs_root(fs_info, &key, false);
 		/*
 		 * The only reason we also check NULL here is that during
 		 * open_ctree() some roots has not yet been set up.
@@ -585,7 +587,7 @@ static noinline int check_leaf(struct btrfs_root *root,
 
 	/* Check the 0 item */
 	if (btrfs_item_offset_nr(leaf, 0) + btrfs_item_size_nr(leaf, 0) !=
-	    BTRFS_LEAF_DATA_SIZE(root->fs_info)) {
+	    BTRFS_LEAF_DATA_SIZE(fs_info)) {
 		CORRUPT("invalid item offset size pair", leaf, root, 0);
 		return -EIO;
 	}
@@ -624,7 +626,7 @@ static noinline int check_leaf(struct btrfs_root *root,
 		 * all point outside of the leaf.
 		 */
 		if (btrfs_item_end_nr(leaf, slot) >
-		    BTRFS_LEAF_DATA_SIZE(root->fs_info)) {
+		    BTRFS_LEAF_DATA_SIZE(fs_info)) {
 			CORRUPT("slot end outside of leaf", leaf, root, slot);
 			return -EIO;
 		}
@@ -1004,6 +1006,7 @@ static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset)
 {
+	struct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);
 	int async = check_async_write(inode, bio_flags);
 	int ret;
 
@@ -1012,8 +1015,8 @@ static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 		 * called for a read, do the setup so that checksum validation
 		 * can happen in the async kernel threads
 		 */
-		ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info,
-					  bio, BTRFS_WQ_ENDIO_METADATA);
+		ret = btrfs_bio_wq_end_io(fs_info, bio,
+					  BTRFS_WQ_ENDIO_METADATA);
 		if (ret)
 			goto out_w_error;
 		ret = btrfs_map_bio(BTRFS_I(inode)->root, bio, mirror_num, 0);
@@ -1027,8 +1030,7 @@ static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 		 * kthread helpers are used to submit writes so that
 		 * checksumming can happen in parallel across all CPUs
 		 */
-		ret = btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
-					  inode, bio, mirror_num, 0,
+		ret = btrfs_wq_submit_bio(fs_info, inode, bio, mirror_num, 0,
 					  bio_offset,
 					  __btree_submit_bio_start,
 					  __btree_submit_bio_done);
@@ -1194,9 +1196,11 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr,
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 bytenr)
 {
-	if (btrfs_is_testing(root->fs_info))
-		return alloc_test_extent_buffer(root->fs_info, bytenr);
-	return alloc_extent_buffer(root->fs_info, bytenr);
+	struct btrfs_fs_info *fs_info = root->fs_info;
+
+	if (btrfs_is_testing(fs_info))
+		return alloc_test_extent_buffer(fs_info, bytenr);
+	return alloc_extent_buffer(fs_info, bytenr);
 }
 
 
@@ -1493,7 +1497,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_header_owner(leaf, BTRFS_TREE_LOG_OBJECTID);
 	root->node = leaf;
 
-	write_extent_buffer_fsid(root->node, root->fs_info->fsid);
+	write_extent_buffer_fsid(root->node, fs_info->fsid);
 	btrfs_mark_buffer_dirty(root->node);
 	btrfs_tree_unlock(root->node);
 	return root;
@@ -1515,10 +1519,11 @@ int btrfs_init_log_root_tree(struct btrfs_trans_handle *trans,
 int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 		       struct btrfs_root *root)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_root *log_root;
 	struct btrfs_inode_item *inode_item;
 
-	log_root = alloc_log_tree(trans, root->fs_info);
+	log_root = alloc_log_tree(trans, fs_info);
 	if (IS_ERR(log_root))
 		return PTR_ERR(log_root);
 
@@ -1530,7 +1535,7 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_stack_inode_size(inode_item, 3);
 	btrfs_set_stack_inode_nlink(inode_item, 1);
 	btrfs_set_stack_inode_nbytes(inode_item,
-				     root->fs_info->nodesize);
+				     fs_info->nodesize);
 	btrfs_set_stack_inode_mode(inode_item, S_IFDIR | 0755);
 
 	btrfs_set_root_node(&log_root->root_item, log_root->node);
@@ -1828,6 +1833,7 @@ static void end_workqueue_fn(struct btrfs_work *work)
 static int cleaner_kthread(void *arg)
 {
 	struct btrfs_root *root = arg;
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	int again;
 	struct btrfs_trans_handle *trans;
 
@@ -1842,10 +1848,10 @@ static int cleaner_kthread(void *arg)
 		 * Do not do anything if we might cause open_ctree() to block
 		 * before we have finished mounting the filesystem.
 		 */
-		if (!test_bit(BTRFS_FS_OPEN, &root->fs_info->flags))
+		if (!test_bit(BTRFS_FS_OPEN, &fs_info->flags))
 			goto sleep;
 
-		if (!mutex_trylock(&root->fs_info->cleaner_mutex))
+		if (!mutex_trylock(&fs_info->cleaner_mutex))
 			goto sleep;
 
 		/*
@@ -1853,22 +1859,22 @@ static int cleaner_kthread(void *arg)
 		 * during the above check and trylock.
 		 */
 		if (btrfs_need_cleaner_sleep(root)) {
-			mutex_unlock(&root->fs_info->cleaner_mutex);
+			mutex_unlock(&fs_info->cleaner_mutex);
 			goto sleep;
 		}
 
-		mutex_lock(&root->fs_info->cleaner_delayed_iput_mutex);
+		mutex_lock(&fs_info->cleaner_delayed_iput_mutex);
 		btrfs_run_delayed_iputs(root);
-		mutex_unlock(&root->fs_info->cleaner_delayed_iput_mutex);
+		mutex_unlock(&fs_info->cleaner_delayed_iput_mutex);
 
 		again = btrfs_clean_one_deleted_snapshot(root);
-		mutex_unlock(&root->fs_info->cleaner_mutex);
+		mutex_unlock(&fs_info->cleaner_mutex);
 
 		/*
 		 * The defragger has dealt with the R/O remount and umount,
 		 * needn't do anything special here.
 		 */
-		btrfs_run_defrag_inodes(root->fs_info);
+		btrfs_run_defrag_inodes(fs_info);
 
 		/*
 		 * Acquires fs_info->delete_unused_bgs_mutex to avoid racing
@@ -1878,7 +1884,7 @@ static int cleaner_kthread(void *arg)
 		 * can't hold, nor need to, fs_info->cleaner_mutex when deleting
 		 * unused block groups.
 		 */
-		btrfs_delete_unused_bgs(root->fs_info);
+		btrfs_delete_unused_bgs(fs_info);
 sleep:
 		if (!again) {
 			set_current_state(TASK_INTERRUPTIBLE);
@@ -1902,7 +1908,7 @@ static int cleaner_kthread(void *arg)
 	trans = btrfs_attach_transaction(root);
 	if (IS_ERR(trans)) {
 		if (PTR_ERR(trans) != -ENOENT)
-			btrfs_err(root->fs_info,
+			btrfs_err(fs_info,
 				  "cleaner transaction attach returned %ld",
 				  PTR_ERR(trans));
 	} else {
@@ -1910,7 +1916,7 @@ static int cleaner_kthread(void *arg)
 
 		ret = btrfs_commit_transaction(trans, root);
 		if (ret)
-			btrfs_err(root->fs_info,
+			btrfs_err(fs_info,
 				  "cleaner open transaction commit returned %d",
 				  ret);
 	}
@@ -1921,6 +1927,7 @@ static int cleaner_kthread(void *arg)
 static int transaction_kthread(void *arg)
 {
 	struct btrfs_root *root = arg;
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_trans_handle *trans;
 	struct btrfs_transaction *cur;
 	u64 transid;
@@ -1930,26 +1937,26 @@ static int transaction_kthread(void *arg)
 
 	do {
 		cannot_commit = false;
-		delay = HZ * root->fs_info->commit_interval;
-		mutex_lock(&root->fs_info->transaction_kthread_mutex);
+		delay = HZ * fs_info->commit_interval;
+		mutex_lock(&fs_info->transaction_kthread_mutex);
 
-		spin_lock(&root->fs_info->trans_lock);
-		cur = root->fs_info->running_transaction;
+		spin_lock(&fs_info->trans_lock);
+		cur = fs_info->running_transaction;
 		if (!cur) {
-			spin_unlock(&root->fs_info->trans_lock);
+			spin_unlock(&fs_info->trans_lock);
 			goto sleep;
 		}
 
 		now = get_seconds();
 		if (cur->state < TRANS_STATE_BLOCKED &&
 		    (now < cur->start_time ||
-		     now - cur->start_time < root->fs_info->commit_interval)) {
-			spin_unlock(&root->fs_info->trans_lock);
+		     now - cur->start_time < fs_info->commit_interval)) {
+			spin_unlock(&fs_info->trans_lock);
 			delay = HZ * 5;
 			goto sleep;
 		}
 		transid = cur->transid;
-		spin_unlock(&root->fs_info->trans_lock);
+		spin_unlock(&fs_info->trans_lock);
 
 		/* If the file system is aborted, this will always fail. */
 		trans = btrfs_attach_transaction(root);
@@ -1964,15 +1971,15 @@ static int transaction_kthread(void *arg)
 			btrfs_end_transaction(trans, root);
 		}
 sleep:
-		wake_up_process(root->fs_info->cleaner_kthread);
-		mutex_unlock(&root->fs_info->transaction_kthread_mutex);
+		wake_up_process(fs_info->cleaner_kthread);
+		mutex_unlock(&fs_info->transaction_kthread_mutex);
 
 		if (unlikely(test_bit(BTRFS_FS_STATE_ERROR,
-				      &root->fs_info->fs_state)))
+				      &fs_info->fs_state)))
 			btrfs_cleanup_transaction(root);
 		set_current_state(TASK_INTERRUPTIBLE);
 		if (!kthread_should_stop() &&
-				(!btrfs_transaction_blocked(root->fs_info) ||
+				(!btrfs_transaction_blocked(fs_info) ||
 				 cannot_commit))
 			schedule_timeout(delay);
 		__set_current_state(TASK_RUNNING);
@@ -2464,8 +2471,8 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	/* returns with log_tree_root freed on success */
 	ret = btrfs_recover_log_trees(log_tree_root);
 	if (ret) {
-		btrfs_handle_fs_error(tree_root->fs_info, ret,
-			    "Failed to recover log tree");
+		btrfs_handle_fs_error(fs_info, ret,
+				      "Failed to recover log tree");
 		free_extent_buffer(log_tree_root->node);
 		kfree(log_tree_root);
 		return ret;
@@ -2830,7 +2837,7 @@ int open_ctree(struct super_block *sb,
 
 	features = btrfs_super_incompat_flags(disk_super);
 	features |= BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF;
-	if (tree_root->fs_info->compress_type == BTRFS_COMPRESS_LZO)
+	if (fs_info->compress_type == BTRFS_COMPRESS_LZO)
 		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;
 
 	if (features & BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA)
@@ -3059,8 +3066,8 @@ int open_ctree(struct super_block *sb,
 	if (IS_ERR(fs_info->transaction_kthread))
 		goto fail_cleaner;
 
-	if (!btrfs_test_opt(tree_root->fs_info, SSD) &&
-	    !btrfs_test_opt(tree_root->fs_info, NOSSD) &&
+	if (!btrfs_test_opt(fs_info, SSD) &&
+	    !btrfs_test_opt(fs_info, NOSSD) &&
 	    !fs_info->fs_devices->rotating) {
 		btrfs_info(fs_info, "detected SSD devices, enabling SSD mode");
 		btrfs_set_opt(fs_info->mount_opt, SSD);
@@ -3073,9 +3080,9 @@ int open_ctree(struct super_block *sb,
 	btrfs_apply_pending_changes(fs_info);
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
-	if (btrfs_test_opt(tree_root->fs_info, CHECK_INTEGRITY)) {
+	if (btrfs_test_opt(fs_info, CHECK_INTEGRITY)) {
 		ret = btrfsic_mount(tree_root, fs_devices,
-				    btrfs_test_opt(tree_root->fs_info,
+				    btrfs_test_opt(fs_info,
 					CHECK_INTEGRITY_INCLUDING_EXTENT_DATA) ?
 				    1 : 0,
 				    fs_info->check_integrity_print_mask);
@@ -3091,7 +3098,7 @@ int open_ctree(struct super_block *sb,
 
 	/* do not make disk changes in broken FS or nologreplay is given */
 	if (btrfs_super_log_root(disk_super) != 0 &&
-	    !btrfs_test_opt(tree_root->fs_info, NOLOGREPLAY)) {
+	    !btrfs_test_opt(fs_info, NOLOGREPLAY)) {
 		ret = btrfs_replay_log(fs_info, fs_devices);
 		if (ret) {
 			err = ret;
@@ -3152,7 +3159,7 @@ int open_ctree(struct super_block *sb,
 		}
 	}
 
-	if (btrfs_test_opt(tree_root->fs_info, FREE_SPACE_TREE) &&
+	if (btrfs_test_opt(fs_info, FREE_SPACE_TREE) &&
 	    !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
 		btrfs_info(fs_info, "creating free space tree");
 		ret = btrfs_create_free_space_tree(fs_info);
@@ -3198,7 +3205,7 @@ int open_ctree(struct super_block *sb,
 			close_ctree(fs_info);
 			return ret;
 		}
-	} else if (btrfs_test_opt(tree_root->fs_info, RESCAN_UUID_TREE) ||
+	} else if (btrfs_test_opt(fs_info, RESCAN_UUID_TREE) ||
 		   fs_info->generation !=
 				btrfs_super_uuid_tree_generation(disk_super)) {
 		btrfs_info(fs_info, "checking UUID tree");
@@ -3274,7 +3281,7 @@ int open_ctree(struct super_block *sb,
 	return err;
 
 recovery_tree_root:
-	if (!btrfs_test_opt(tree_root->fs_info, USEBACKUPROOT))
+	if (!btrfs_test_opt(fs_info, USEBACKUPROOT))
 		goto fail_tree_roots;
 
 	free_root_pointers(fs_info, 0);
@@ -3680,6 +3687,7 @@ int btrfs_calc_num_tolerated_disk_barrier_failures(
 
 static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct list_head *head;
 	struct btrfs_device *dev;
 	struct btrfs_super_block *sb;
@@ -3690,23 +3698,23 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	int total_errors = 0;
 	u64 flags;
 
-	do_barriers = !btrfs_test_opt(root->fs_info, NOBARRIER);
-	backup_super_roots(root->fs_info);
+	do_barriers = !btrfs_test_opt(fs_info, NOBARRIER);
+	backup_super_roots(fs_info);
 
-	sb = root->fs_info->super_for_commit;
+	sb = fs_info->super_for_commit;
 	dev_item = &sb->dev_item;
 
-	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
-	head = &root->fs_info->fs_devices->devices;
-	max_errors = btrfs_super_num_devices(root->fs_info->super_copy) - 1;
+	mutex_lock(&fs_info->fs_devices->device_list_mutex);
+	head = &fs_info->fs_devices->devices;
+	max_errors = btrfs_super_num_devices(fs_info->super_copy) - 1;
 
 	if (do_barriers) {
-		ret = barrier_all_devices(root->fs_info);
+		ret = barrier_all_devices(fs_info);
 		if (ret) {
 			mutex_unlock(
-				&root->fs_info->fs_devices->device_list_mutex);
-			btrfs_handle_fs_error(root->fs_info, ret,
-				    "errors while submitting device barriers.");
+				&fs_info->fs_devices->device_list_mutex);
+			btrfs_handle_fs_error(fs_info, ret,
+					      "errors while submitting device barriers.");
 			return ret;
 		}
 	}
@@ -3740,13 +3748,14 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 			total_errors++;
 	}
 	if (total_errors > max_errors) {
-		btrfs_err(root->fs_info, "%d errors while writing supers",
-		       total_errors);
-		mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
+		btrfs_err(fs_info, "%d errors while writing supers",
+			  total_errors);
+		mutex_unlock(&fs_info->fs_devices->device_list_mutex);
 
 		/* FUA is masked off if unsupported and can't be the reason */
-		btrfs_handle_fs_error(root->fs_info, -EIO,
-			    "%d errors while writing supers", total_errors);
+		btrfs_handle_fs_error(fs_info, -EIO,
+				      "%d errors while writing supers",
+				      total_errors);
 		return -EIO;
 	}
 
@@ -3761,10 +3770,11 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		if (ret)
 			total_errors++;
 	}
-	mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
+	mutex_unlock(&fs_info->fs_devices->device_list_mutex);
 	if (total_errors > max_errors) {
-		btrfs_handle_fs_error(root->fs_info, -EIO,
-			    "%d errors while writing supers", total_errors);
+		btrfs_handle_fs_error(fs_info, -EIO,
+				      "%d errors while writing supers",
+				      total_errors);
 		return -EIO;
 	}
 	return 0;
@@ -3884,14 +3894,14 @@ int btrfs_commit_super(struct btrfs_fs_info *fs_info)
 	struct btrfs_root *root = fs_info->tree_root;
 	struct btrfs_trans_handle *trans;
 
-	mutex_lock(&root->fs_info->cleaner_mutex);
+	mutex_lock(&fs_info->cleaner_mutex);
 	btrfs_run_delayed_iputs(root);
-	mutex_unlock(&root->fs_info->cleaner_mutex);
-	wake_up_process(root->fs_info->cleaner_kthread);
+	mutex_unlock(&fs_info->cleaner_mutex);
+	wake_up_process(fs_info->cleaner_kthread);
 
 	/* wait until ongoing cleanup work done */
-	down_write(&root->fs_info->cleanup_work_sem);
-	up_write(&root->fs_info->cleanup_work_sem);
+	down_write(&fs_info->cleanup_work_sem);
+	up_write(&fs_info->cleanup_work_sem);
 
 	trans = btrfs_join_transaction(root);
 	if (IS_ERR(trans))
@@ -3936,7 +3946,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 		 * block groups queued for removal, the deletion will be
 		 * skipped when we quit the cleaner thread.
 		 */
-		btrfs_delete_unused_bgs(root->fs_info);
+		btrfs_delete_unused_bgs(fs_info);
 
 		ret = btrfs_commit_super(fs_info);
 		if (ret)
@@ -3980,7 +3990,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	iput(fs_info->btree_inode);
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
-	if (btrfs_test_opt(root->fs_info, CHECK_INTEGRITY))
+	if (btrfs_test_opt(fs_info, CHECK_INTEGRITY))
 		btrfsic_unmount(root, fs_info->fs_devices);
 #endif
 
@@ -3998,7 +4008,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	__btrfs_free_block_rsv(root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;
 
-	lock_chunks(root->fs_info);
+	lock_chunks(fs_info);
 	while (!list_empty(&fs_info->pinned_chunks)) {
 		struct extent_map *em;
 
@@ -4007,7 +4017,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 		list_del_init(&em->list);
 		free_extent_map(em);
 	}
-	unlock_chunks(root->fs_info);
+	unlock_chunks(fs_info);
 }
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,
@@ -4029,6 +4039,7 @@ int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,
 
 void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 {
+	struct btrfs_fs_info *fs_info;
 	struct btrfs_root *root;
 	u64 transid = btrfs_header_generation(buf);
 	int was_dirty;
@@ -4043,15 +4054,16 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 		return;
 #endif
 	root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	fs_info = root->fs_info;
 	btrfs_assert_tree_locked(buf);
-	if (transid != root->fs_info->generation)
+	if (transid != fs_info->generation)
 		WARN(1, KERN_CRIT "btrfs transid mismatch buffer %llu, found %llu running %llu\n",
-			buf->start, transid, root->fs_info->generation);
+			buf->start, transid, fs_info->generation);
 	was_dirty = set_extent_buffer_dirty(buf);
 	if (!was_dirty)
-		__percpu_counter_add(&root->fs_info->dirty_metadata_bytes,
+		__percpu_counter_add(&fs_info->dirty_metadata_bytes,
 				     buf->len,
-				     root->fs_info->dirty_metadata_batch);
+				     fs_info->dirty_metadata_batch);
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_header_level(buf) == 0 && check_leaf(root, buf)) {
 		btrfs_print_leaf(root, buf);
@@ -4063,6 +4075,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
 					int flush_delayed)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	/*
 	 * looks as though older kernels can get into trouble with
 	 * this code, they end up stuck in balance_dirty_pages forever
@@ -4075,11 +4088,10 @@ static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
 	if (flush_delayed)
 		btrfs_balance_delayed_items(root);
 
-	ret = percpu_counter_compare(&root->fs_info->dirty_metadata_bytes,
+	ret = percpu_counter_compare(&fs_info->dirty_metadata_bytes,
 				     BTRFS_DIRTY_METADATA_THRESH);
 	if (ret > 0) {
-		balance_dirty_pages_ratelimited(
-				   root->fs_info->btree_inode->i_mapping);
+		balance_dirty_pages_ratelimited(fs_info->btree_inode->i_mapping);
 	}
 }
 
@@ -4249,12 +4261,14 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 
 static void btrfs_error_commit_super(struct btrfs_root *root)
 {
-	mutex_lock(&root->fs_info->cleaner_mutex);
+	struct btrfs_fs_info *fs_info = root->fs_info;
+
+	mutex_lock(&fs_info->cleaner_mutex);
 	btrfs_run_delayed_iputs(root);
-	mutex_unlock(&root->fs_info->cleaner_mutex);
+	mutex_unlock(&fs_info->cleaner_mutex);
 
-	down_write(&root->fs_info->cleanup_work_sem);
-	up_write(&root->fs_info->cleanup_work_sem);
+	down_write(&fs_info->cleanup_work_sem);
+	up_write(&fs_info->cleanup_work_sem);
 
 	/* cleanup FS via transaction */
 	btrfs_cleanup_transaction(root);
@@ -4302,6 +4316,7 @@ static void btrfs_destroy_all_ordered_extents(struct btrfs_fs_info *fs_info)
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				      struct btrfs_root *root)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct rb_node *node;
 	struct btrfs_delayed_ref_root *delayed_refs;
 	struct btrfs_delayed_ref_node *ref;
@@ -4312,7 +4327,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 	spin_lock(&delayed_refs->lock);
 	if (atomic_read(&delayed_refs->num_entries) == 0) {
 		spin_unlock(&delayed_refs->lock);
-		btrfs_info(root->fs_info, "delayed_refs has NO entry");
+		btrfs_info(fs_info, "delayed_refs has NO entry");
 		return ret;
 	}
 
@@ -4425,6 +4440,7 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 					struct extent_io_tree *dirty_pages,
 					int mark)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	int ret;
 	struct extent_buffer *eb;
 	u64 start = 0;
@@ -4438,8 +4454,8 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 
 		clear_extent_bits(dirty_pages, start, end, mark);
 		while (start <= end) {
-			eb = find_extent_buffer(root->fs_info, start);
-			start += root->fs_info->nodesize;
+			eb = find_extent_buffer(fs_info, start);
+			start += fs_info->nodesize;
 			if (!eb)
 				continue;
 			wait_on_extent_buffer_writeback(eb);
@@ -4457,6 +4473,7 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 				       struct extent_io_tree *pinned_extents)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct extent_io_tree *unpin;
 	u64 start;
 	u64 end;
@@ -4477,10 +4494,10 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 	}
 
 	if (loop) {
-		if (unpin == &root->fs_info->freed_extents[0])
-			unpin = &root->fs_info->freed_extents[1];
+		if (unpin == &fs_info->freed_extents[0])
+			unpin = &fs_info->freed_extents[1];
 		else
-			unpin = &root->fs_info->freed_extents[0];
+			unpin = &fs_info->freed_extents[0];
 		loop = false;
 		goto again;
 	}
@@ -4505,6 +4522,7 @@ static void btrfs_cleanup_bg_io(struct btrfs_block_group_cache *cache)
 void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 			     struct btrfs_root *root)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_block_group_cache *cache;
 
 	spin_lock(&cur_trans->dirty_bgs_lock);
@@ -4513,8 +4531,7 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 					 struct btrfs_block_group_cache,
 					 dirty_list);
 		if (!cache) {
-			btrfs_err(root->fs_info,
-				  "orphan block group dirty_bgs list");
+			btrfs_err(fs_info, "orphan block group dirty_bgs list");
 			spin_unlock(&cur_trans->dirty_bgs_lock);
 			return;
 		}
@@ -4542,8 +4559,7 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 					 struct btrfs_block_group_cache,
 					 io_list);
 		if (!cache) {
-			btrfs_err(root->fs_info,
-				  "orphan block group on io_bgs list");
+			btrfs_err(fs_info, "orphan block group on io_bgs list");
 			return;
 		}
 
@@ -4558,6 +4574,7 @@ void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
 void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 				   struct btrfs_root *root)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	btrfs_cleanup_dirty_bgs(cur_trans, root);
 	ASSERT(list_empty(&cur_trans->dirty_bgs));
 	ASSERT(list_empty(&cur_trans->io_bgs));
@@ -4565,10 +4582,10 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	btrfs_destroy_delayed_refs(cur_trans, root);
 
 	cur_trans->state = TRANS_STATE_COMMIT_START;
-	wake_up(&root->fs_info->transaction_blocked_wait);
+	wake_up(&fs_info->transaction_blocked_wait);
 
 	cur_trans->state = TRANS_STATE_UNBLOCKED;
-	wake_up(&root->fs_info->transaction_wait);
+	wake_up(&fs_info->transaction_wait);
 
 	btrfs_destroy_delayed_inodes(root);
 	btrfs_assert_delayed_root_empty(root);
@@ -4576,7 +4593,7 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	btrfs_destroy_marked_extents(root, &cur_trans->dirty_pages,
 				     EXTENT_DIRTY);
 	btrfs_destroy_pinned_extent(root,
-				    root->fs_info->pinned_extents);
+				    fs_info->pinned_extents);
 
 	cur_trans->state =TRANS_STATE_COMPLETED;
 	wake_up(&cur_trans->commit_wait);
@@ -4589,25 +4606,26 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 
 static int btrfs_cleanup_transaction(struct btrfs_root *root)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_transaction *t;
 
-	mutex_lock(&root->fs_info->transaction_kthread_mutex);
+	mutex_lock(&fs_info->transaction_kthread_mutex);
 
-	spin_lock(&root->fs_info->trans_lock);
-	while (!list_empty(&root->fs_info->trans_list)) {
-		t = list_first_entry(&root->fs_info->trans_list,
+	spin_lock(&fs_info->trans_lock);
+	while (!list_empty(&fs_info->trans_list)) {
+		t = list_first_entry(&fs_info->trans_list,
 				     struct btrfs_transaction, list);
 		if (t->state >= TRANS_STATE_COMMIT_START) {
 			atomic_inc(&t->use_count);
-			spin_unlock(&root->fs_info->trans_lock);
+			spin_unlock(&fs_info->trans_lock);
 			btrfs_wait_for_commit(root, t->transid);
 			btrfs_put_transaction(t);
-			spin_lock(&root->fs_info->trans_lock);
+			spin_lock(&fs_info->trans_lock);
 			continue;
 		}
-		if (t == root->fs_info->running_transaction) {
+		if (t == fs_info->running_transaction) {
 			t->state = TRANS_STATE_COMMIT_DOING;
-			spin_unlock(&root->fs_info->trans_lock);
+			spin_unlock(&fs_info->trans_lock);
 			/*
 			 * We wait for 0 num_writers since we don't hold a trans
 			 * handle open currently for this transaction.
@@ -4615,27 +4633,27 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 			wait_event(t->writer_wait,
 				   atomic_read(&t->num_writers) == 0);
 		} else {
-			spin_unlock(&root->fs_info->trans_lock);
+			spin_unlock(&fs_info->trans_lock);
 		}
 		btrfs_cleanup_one_transaction(t, root);
 
-		spin_lock(&root->fs_info->trans_lock);
-		if (t == root->fs_info->running_transaction)
-			root->fs_info->running_transaction = NULL;
+		spin_lock(&fs_info->trans_lock);
+		if (t == fs_info->running_transaction)
+			fs_info->running_transaction = NULL;
 		list_del_init(&t->list);
-		spin_unlock(&root->fs_info->trans_lock);
+		spin_unlock(&fs_info->trans_lock);
 
 		btrfs_put_transaction(t);
 		trace_btrfs_transaction_commit(root);
-		spin_lock(&root->fs_info->trans_lock);
+		spin_lock(&fs_info->trans_lock);
 	}
-	spin_unlock(&root->fs_info->trans_lock);
-	btrfs_destroy_all_ordered_extents(root->fs_info);
+	spin_unlock(&fs_info->trans_lock);
+	btrfs_destroy_all_ordered_extents(fs_info);
 	btrfs_destroy_delayed_inodes(root);
 	btrfs_assert_delayed_root_empty(root);
-	btrfs_destroy_pinned_extent(root, root->fs_info->pinned_extents);
-	btrfs_destroy_all_delalloc_inodes(root->fs_info);
-	mutex_unlock(&root->fs_info->transaction_kthread_mutex);
+	btrfs_destroy_pinned_extent(root, fs_info->pinned_extents);
+	btrfs_destroy_all_delalloc_inodes(fs_info);
+	mutex_unlock(&fs_info->transaction_kthread_mutex);
 
 	return 0;
 }

commit 3796d335356acccd03282547d852f41e48063766
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Jun 16 11:30:29 2016 -0400

    btrfs: root->fs_info cleanup, lock/unlock_chunks
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3d4fb99d9e4f..5abf3afa6ea5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3998,7 +3998,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 	__btrfs_free_block_rsv(root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;
 
-	lock_chunks(root);
+	lock_chunks(root->fs_info);
 	while (!list_empty(&fs_info->pinned_chunks)) {
 		struct extent_map *em;
 
@@ -4007,7 +4007,7 @@ void close_ctree(struct btrfs_fs_info *fs_info)
 		list_del_init(&em->list);
 		free_extent_map(em);
 	}
-	unlock_chunks(root);
+	unlock_chunks(root->fs_info);
 }
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,

commit da17066c40472c2d6a1aab7bb0090c3d285531c9
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 15 09:22:56 2016 -0400

    btrfs: pull node/sector/stripe sizes out of root and into fs_info
    
    We track the node sizes per-root, but they never vary from the values
    in the superblock.  This patch messes with the 80-column style a bit,
    but subsequent patches to factor out root->fs_info into a convenience
    variable fix it up again.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 83848314e12f..3d4fb99d9e4f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -585,7 +585,7 @@ static noinline int check_leaf(struct btrfs_root *root,
 
 	/* Check the 0 item */
 	if (btrfs_item_offset_nr(leaf, 0) + btrfs_item_size_nr(leaf, 0) !=
-	    BTRFS_LEAF_DATA_SIZE(root)) {
+	    BTRFS_LEAF_DATA_SIZE(root->fs_info)) {
 		CORRUPT("invalid item offset size pair", leaf, root, 0);
 		return -EIO;
 	}
@@ -624,7 +624,7 @@ static noinline int check_leaf(struct btrfs_root *root,
 		 * all point outside of the leaf.
 		 */
 		if (btrfs_item_end_nr(leaf, slot) >
-		    BTRFS_LEAF_DATA_SIZE(root)) {
+		    BTRFS_LEAF_DATA_SIZE(root->fs_info)) {
 			CORRUPT("slot end outside of leaf", leaf, root, slot);
 			return -EIO;
 		}
@@ -641,7 +641,7 @@ static int check_node(struct btrfs_root *root, struct extent_buffer *node)
 	u64 bytenr;
 	int ret = 0;
 
-	if (nr == 0 || nr > BTRFS_NODEPTRS_PER_BLOCK(root)) {
+	if (nr == 0 || nr > BTRFS_NODEPTRS_PER_BLOCK(root->fs_info)) {
 		btrfs_crit(root->fs_info,
 			   "corrupt node: block %llu root %llu nritems %lu",
 			   node->start, root->objectid, nr);
@@ -1195,8 +1195,7 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 bytenr)
 {
 	if (btrfs_is_testing(root->fs_info))
-		return alloc_test_extent_buffer(root->fs_info, bytenr,
-				root->nodesize);
+		return alloc_test_extent_buffer(root->fs_info, bytenr);
 	return alloc_extent_buffer(root->fs_info, bytenr);
 }
 
@@ -1277,16 +1276,12 @@ btrfs_free_subvolume_writers(struct btrfs_subvolume_writers *writers)
 	kfree(writers);
 }
 
-static void __setup_root(u32 nodesize, u32 sectorsize, u32 stripesize,
-			 struct btrfs_root *root, struct btrfs_fs_info *fs_info,
+static void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 			 u64 objectid)
 {
 	bool dummy = test_bit(BTRFS_FS_STATE_DUMMY_FS_INFO, &fs_info->fs_state);
 	root->node = NULL;
 	root->commit_root = NULL;
-	root->sectorsize = sectorsize;
-	root->nodesize = nodesize;
-	root->stripesize = stripesize;
 	root->state = 0;
 	root->orphan_cleanup_state = 0;
 
@@ -1364,8 +1359,7 @@ static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info,
 
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 /* Should only be used by the testing infrastructure */
-struct btrfs_root *btrfs_alloc_dummy_root(struct btrfs_fs_info *fs_info,
-					  u32 sectorsize, u32 nodesize)
+struct btrfs_root *btrfs_alloc_dummy_root(struct btrfs_fs_info *fs_info)
 {
 	struct btrfs_root *root;
 
@@ -1375,9 +1369,9 @@ struct btrfs_root *btrfs_alloc_dummy_root(struct btrfs_fs_info *fs_info,
 	root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
+
 	/* We don't use the stripesize in selftest, set it as sectorsize */
-	__setup_root(nodesize, sectorsize, sectorsize, root, fs_info,
-			BTRFS_ROOT_TREE_OBJECTID);
+	__setup_root(root, fs_info, BTRFS_ROOT_TREE_OBJECTID);
 	root->alloc_bytenr = 0;
 
 	return root;
@@ -1399,8 +1393,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
-	__setup_root(tree_root->nodesize, tree_root->sectorsize,
-		tree_root->stripesize, root, fs_info, objectid);
+	__setup_root(root, fs_info, objectid);
 	root->root_key.objectid = objectid;
 	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
 	root->root_key.offset = 0;
@@ -1465,16 +1458,13 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info)
 {
 	struct btrfs_root *root;
-	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct extent_buffer *leaf;
 
 	root = btrfs_alloc_root(fs_info, GFP_NOFS);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
-	__setup_root(tree_root->nodesize, tree_root->sectorsize,
-		     tree_root->stripesize, root, fs_info,
-		     BTRFS_TREE_LOG_OBJECTID);
+	__setup_root(root, fs_info, BTRFS_TREE_LOG_OBJECTID);
 
 	root->root_key.objectid = BTRFS_TREE_LOG_OBJECTID;
 	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
@@ -1539,7 +1529,8 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_stack_inode_generation(inode_item, 1);
 	btrfs_set_stack_inode_size(inode_item, 3);
 	btrfs_set_stack_inode_nlink(inode_item, 1);
-	btrfs_set_stack_inode_nbytes(inode_item, root->nodesize);
+	btrfs_set_stack_inode_nbytes(inode_item,
+				     root->fs_info->nodesize);
 	btrfs_set_stack_inode_mode(inode_item, S_IFDIR | 0755);
 
 	btrfs_set_root_node(&log_root->root_item, log_root->node);
@@ -1571,8 +1562,7 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 		goto alloc_fail;
 	}
 
-	__setup_root(tree_root->nodesize, tree_root->sectorsize,
-		tree_root->stripesize, root, fs_info, key->objectid);
+	__setup_root(root, fs_info, key->objectid);
 
 	ret = btrfs_find_root(tree_root, key, path,
 			      &root->root_item, &root->root_key);
@@ -2456,9 +2446,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	if (!log_tree_root)
 		return -ENOMEM;
 
-	__setup_root(tree_root->nodesize, tree_root->sectorsize,
-			tree_root->stripesize, log_tree_root, fs_info,
-			BTRFS_TREE_LOG_OBJECTID);
+	__setup_root(log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
 
 	log_tree_root->node = read_tree_block(tree_root, bytenr,
 			fs_info->generation + 1);
@@ -2749,14 +2737,18 @@ int open_ctree(struct super_block *sb,
 
 	INIT_LIST_HEAD(&fs_info->pinned_chunks);
 
+	/* Usable values until the real ones are cached from the superblock */
+	fs_info->nodesize = 4096;
+	fs_info->sectorsize = 4096;
+	fs_info->stripesize = 4096;
+
 	ret = btrfs_alloc_stripe_hash_table(fs_info);
 	if (ret) {
 		err = ret;
 		goto fail_alloc;
 	}
 
-	__setup_root(4096, 4096, 4096, tree_root,
-		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
+	__setup_root(tree_root, fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
 	invalidate_bdev(fs_devices->latest_bdev);
 
@@ -2861,6 +2853,11 @@ int open_ctree(struct super_block *sb,
 	fs_info->dirty_metadata_batch = nodesize * (1 + ilog2(nr_cpu_ids));
 	fs_info->delalloc_batch = sectorsize * 512 * (1 + ilog2(nr_cpu_ids));
 
+	/* Cache block sizes */
+	fs_info->nodesize = nodesize;
+	fs_info->sectorsize = sectorsize;
+	fs_info->stripesize = stripesize;
+
 	/*
 	 * mixed block groups end up with duplicate but slightly offset
 	 * extent buffers for the same range.  It leads to corruptions
@@ -2901,10 +2898,6 @@ int open_ctree(struct super_block *sb,
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
 				    SZ_4M / PAGE_SIZE);
 
-	tree_root->nodesize = nodesize;
-	tree_root->sectorsize = sectorsize;
-	tree_root->stripesize = stripesize;
-
 	sb->s_blocksize = sectorsize;
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
 
@@ -2918,8 +2911,7 @@ int open_ctree(struct super_block *sb,
 
 	generation = btrfs_super_chunk_root_generation(disk_super);
 
-	__setup_root(nodesize, sectorsize, stripesize, chunk_root,
-		     fs_info, BTRFS_CHUNK_TREE_OBJECTID);
+	__setup_root(chunk_root, fs_info, BTRFS_CHUNK_TREE_OBJECTID);
 
 	chunk_root->node = read_tree_block(chunk_root,
 					   btrfs_super_chunk_root(disk_super),
@@ -4447,7 +4439,7 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 		clear_extent_bits(dirty_pages, start, end, mark);
 		while (start <= end) {
 			eb = find_extent_buffer(root->fs_info, start);
-			start += root->nodesize;
+			start += root->fs_info->nodesize;
 			if (!eb)
 				continue;
 			wait_on_extent_buffer_writeback(eb);

commit fb456252d3d9c05dfad09b603868e1ef9097a220
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:56 2016 -0400

    btrfs: root->fs_info cleanup, use fs_info->dev_root everywhere
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1db5f0304c6b..83848314e12f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3308,7 +3308,7 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 		struct btrfs_device *device = (struct btrfs_device *)
 			bh->b_private;
 
-		btrfs_warn_rl_in_rcu(device->dev_root->fs_info,
+		btrfs_warn_rl_in_rcu(device->fs_info,
 				"lost page write due to IO error on %s",
 					  rcu_str_deref(device->name));
 		/* note, we don't set_buffer_write_io_error because we have
@@ -3453,7 +3453,7 @@ static int write_dev_supers(struct btrfs_device *device,
 			bh = __getblk(device->bdev, bytenr / 4096,
 				      BTRFS_SUPER_INFO_SIZE);
 			if (!bh) {
-				btrfs_err(device->dev_root->fs_info,
+				btrfs_err(device->fs_info,
 				    "couldn't get super buffer head for bytenr %llu",
 				    bytenr);
 				errors++;

commit 6bccf3ab1e1f0913268bfcd1c09cadb1f4f2857d
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jun 21 21:16:51 2016 -0400

    btrfs: call functions that always use the same root with fs_info instead
    
    There are many functions that are always called with the same root
    argument.  Rather than passing the same root every time, we can
    pass an fs_info pointer instead and have the function get the root
    pointer itself.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 92c2aea5118b..1db5f0304c6b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2296,8 +2296,7 @@ static void btrfs_init_balance(struct btrfs_fs_info *fs_info)
 	init_waitqueue_head(&fs_info->balance_wait_q);
 }
 
-static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info,
-				   struct btrfs_root *tree_root)
+static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info)
 {
 	fs_info->btree_inode->i_ino = BTRFS_BTREE_INODE_OBJECTID;
 	set_nlink(fs_info->btree_inode, 1);
@@ -2317,7 +2316,7 @@ static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info,
 
 	BTRFS_I(fs_info->btree_inode)->io_tree.ops = &btree_extent_io_ops;
 
-	BTRFS_I(fs_info->btree_inode)->root = tree_root;
+	BTRFS_I(fs_info->btree_inode)->root = fs_info->tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));
 	set_bit(BTRFS_INODE_DUMMY,
@@ -2485,7 +2484,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	}
 
 	if (fs_info->sb->s_flags & MS_RDONLY) {
-		ret = btrfs_commit_super(tree_root);
+		ret = btrfs_commit_super(fs_info);
 		if (ret)
 			return ret;
 	}
@@ -2493,13 +2492,15 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	return 0;
 }
 
-static int btrfs_read_roots(struct btrfs_fs_info *fs_info,
-			    struct btrfs_root *tree_root)
+static int btrfs_read_roots(struct btrfs_fs_info *fs_info)
 {
+	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct btrfs_root *root;
 	struct btrfs_key location;
 	int ret;
 
+	BUG_ON(!fs_info->tree_root);
+
 	location.objectid = BTRFS_EXTENT_TREE_OBJECTID;
 	location.type = BTRFS_ROOT_ITEM_KEY;
 	location.offset = 0;
@@ -2710,7 +2711,7 @@ int open_ctree(struct super_block *sb,
 	sb->s_blocksize_bits = blksize_bits(4096);
 	sb->s_bdi = &fs_info->bdi;
 
-	btrfs_init_btree_inode(fs_info, tree_root);
+	btrfs_init_btree_inode(fs_info);
 
 	spin_lock_init(&fs_info->block_group_cache_lock);
 	fs_info->block_group_cache_tree = RB_ROOT;
@@ -2908,7 +2909,7 @@ int open_ctree(struct super_block *sb,
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
 
 	mutex_lock(&fs_info->chunk_mutex);
-	ret = btrfs_read_sys_array(tree_root);
+	ret = btrfs_read_sys_array(fs_info);
 	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
 		btrfs_err(fs_info, "failed to read the system array: %d", ret);
@@ -2985,7 +2986,7 @@ int open_ctree(struct super_block *sb,
 
 	mutex_unlock(&tree_root->objectid_mutex);
 
-	ret = btrfs_read_roots(fs_info, tree_root);
+	ret = btrfs_read_roots(fs_info);
 	if (ret)
 		goto recovery_tree_root;
 
@@ -3106,7 +3107,7 @@ int open_ctree(struct super_block *sb,
 		}
 	}
 
-	ret = btrfs_find_orphan_roots(tree_root);
+	ret = btrfs_find_orphan_roots(fs_info);
 	if (ret)
 		goto fail_qgroup;
 
@@ -3154,7 +3155,7 @@ int open_ctree(struct super_block *sb,
 		if (ret) {
 			btrfs_warn(fs_info,
 				   "failed to clear free space tree: %d", ret);
-			close_ctree(tree_root);
+			close_ctree(fs_info);
 			return ret;
 		}
 	}
@@ -3166,7 +3167,7 @@ int open_ctree(struct super_block *sb,
 		if (ret) {
 			btrfs_warn(fs_info,
 				"failed to create free space tree: %d", ret);
-			close_ctree(tree_root);
+			close_ctree(fs_info);
 			return ret;
 		}
 	}
@@ -3175,7 +3176,7 @@ int open_ctree(struct super_block *sb,
 	if ((ret = btrfs_orphan_cleanup(fs_info->fs_root)) ||
 	    (ret = btrfs_orphan_cleanup(fs_info->tree_root))) {
 		up_read(&fs_info->cleanup_work_sem);
-		close_ctree(tree_root);
+		close_ctree(fs_info);
 		return ret;
 	}
 	up_read(&fs_info->cleanup_work_sem);
@@ -3183,14 +3184,14 @@ int open_ctree(struct super_block *sb,
 	ret = btrfs_resume_balance_async(fs_info);
 	if (ret) {
 		btrfs_warn(fs_info, "failed to resume balance: %d", ret);
-		close_ctree(tree_root);
+		close_ctree(fs_info);
 		return ret;
 	}
 
 	ret = btrfs_resume_dev_replace_async(fs_info);
 	if (ret) {
 		btrfs_warn(fs_info, "failed to resume device replace: %d", ret);
-		close_ctree(tree_root);
+		close_ctree(fs_info);
 		return ret;
 	}
 
@@ -3202,7 +3203,7 @@ int open_ctree(struct super_block *sb,
 		if (ret) {
 			btrfs_warn(fs_info,
 				"failed to create the UUID tree: %d", ret);
-			close_ctree(tree_root);
+			close_ctree(fs_info);
 			return ret;
 		}
 	} else if (btrfs_test_opt(tree_root->fs_info, RESCAN_UUID_TREE) ||
@@ -3213,7 +3214,7 @@ int open_ctree(struct super_block *sb,
 		if (ret) {
 			btrfs_warn(fs_info,
 				"failed to check the UUID tree: %d", ret);
-			close_ctree(tree_root);
+			close_ctree(fs_info);
 			return ret;
 		}
 	} else {
@@ -3886,8 +3887,9 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 	return err;
 }
 
-int btrfs_commit_super(struct btrfs_root *root)
+int btrfs_commit_super(struct btrfs_fs_info *fs_info)
 {
+	struct btrfs_root *root = fs_info->tree_root;
 	struct btrfs_trans_handle *trans;
 
 	mutex_lock(&root->fs_info->cleaner_mutex);
@@ -3905,9 +3907,9 @@ int btrfs_commit_super(struct btrfs_root *root)
 	return btrfs_commit_transaction(trans, root);
 }
 
-void close_ctree(struct btrfs_root *root)
+void close_ctree(struct btrfs_fs_info *fs_info)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
+	struct btrfs_root *root = fs_info->tree_root;
 	int ret;
 
 	set_bit(BTRFS_FS_CLOSING_START, &fs_info->flags);
@@ -3944,7 +3946,7 @@ void close_ctree(struct btrfs_root *root)
 		 */
 		btrfs_delete_unused_bgs(root->fs_info);
 
-		ret = btrfs_commit_super(root);
+		ret = btrfs_commit_super(fs_info);
 		if (ret)
 			btrfs_err(fs_info, "commit super ret %d", ret);
 	}

commit 5b4aacefb8fbfc996e68b9b083d30f8bc0972449
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jun 21 10:40:19 2016 -0400

    btrfs: call functions that overwrite their root parameter with fs_info
    
    There are 11 functions that accept a root parameter and immediately
    overwrite it.  We can pass those an fs_info pointer instead.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 811662cce977..92c2aea5118b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2937,7 +2937,7 @@ int open_ctree(struct super_block *sb,
 	read_extent_buffer(chunk_root->node, fs_info->chunk_tree_uuid,
 	   btrfs_header_chunk_tree_uuid(chunk_root->node), BTRFS_UUID_SIZE);
 
-	ret = btrfs_read_chunk_tree(chunk_root);
+	ret = btrfs_read_chunk_tree(fs_info);
 	if (ret) {
 		btrfs_err(fs_info, "failed to read chunk tree: %d", ret);
 		goto fail_tree_roots;
@@ -3038,7 +3038,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_sysfs;
 	}
 
-	ret = btrfs_read_block_groups(fs_info->extent_root);
+	ret = btrfs_read_block_groups(fs_info);
 	if (ret) {
 		btrfs_err(fs_info, "failed to read block groups: %d", ret);
 		goto fail_sysfs;

commit 1d57ee941692d0cc928526e21a1557b2ae3e11db
Author: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
Date:   Wed Oct 26 18:07:33 2016 +0800

    btrfs: improve delayed refs iterations
    
    This issue was found when I tried to delete a heavily reflinked file,
    when deleting such files, other transaction operation will not have a
    chance to make progress, for example, start_transaction() will blocked
    in wait_current_trans(root) for long time, sometimes it even triggers
    soft lockups, and the time taken to delete such heavily reflinked file
    is also very large, often hundreds of seconds. Using perf top, it reports
    that:
    
    PerfTop:    7416 irqs/sec  kernel:99.8%  exact:  0.0% [4000Hz cpu-clock],  (all, 4 CPUs)
    ---------------------------------------------------------------------------------------
        84.37%  [btrfs]             [k] __btrfs_run_delayed_refs.constprop.80
        11.02%  [kernel]            [k] delay_tsc
         0.79%  [kernel]            [k] _raw_spin_unlock_irq
         0.78%  [kernel]            [k] _raw_spin_unlock_irqrestore
         0.45%  [kernel]            [k] do_raw_spin_lock
         0.18%  [kernel]            [k] __slab_alloc
    It seems __btrfs_run_delayed_refs() took most cpu time, after some debug
    work, I found it's select_delayed_ref() causing this issue, for a delayed
    head, in our case, it'll be full of BTRFS_DROP_DELAYED_REF nodes, but
    select_delayed_ref() will firstly try to iterate node list to find
    BTRFS_ADD_DELAYED_REF nodes, obviously it's a disaster in this case, and
    waste much time.
    
    To fix this issue, we introduce a new ref_add_list in struct btrfs_delayed_ref_head,
    then in select_delayed_ref(), if this list is not empty, we can directly use
    nodes in this list. With this patch, it just took about 10~15 seconds to
    delte the same file. Now using perf top, it reports that:
    
    PerfTop:    2734 irqs/sec  kernel:99.5%  exact:  0.0% [4000Hz cpu-clock],  (all, 4 CPUs)
    ----------------------------------------------------------------------------------------
    
        20.74%  [kernel]          [k] _raw_spin_unlock_irqrestore
        16.33%  [kernel]          [k] __slab_alloc
         5.41%  [kernel]          [k] lock_acquired
         4.42%  [kernel]          [k] lock_acquire
         4.05%  [kernel]          [k] lock_release
         3.37%  [kernel]          [k] _raw_spin_unlock_irq
    
    For normal files, this patch also gives help, at least we do not need to
    iterate whole list to found BTRFS_ADD_DELAYED_REF nodes.
    
    Signed-off-by: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Tested-by: Holger Hoffsttte <holger@applied-asynchrony.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8677d29efade..811662cce977 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4344,6 +4344,8 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 						 list) {
 			ref->in_tree = 0;
 			list_del(&ref->list);
+			if (!list_empty(&ref->add_list))
+				list_del(&ref->add_list);
 			atomic_dec(&delayed_refs->num_entries);
 			btrfs_put_delayed_ref(ref);
 		}

commit 0b5e3dafb60229dd7225e81023af5d2ddfb6a4b7
Author: Domagoj Tran <domagoj.trsan@gmail.com>
Date:   Thu Oct 27 08:52:33 2016 +0100

    btrfs: change btrfs_csum_final result param type to u8
    
    csum member of struct btrfs_super_block has array type of u8. It makes
    sense that function btrfs_csum_final should be also declared to accept
    u8 *. I changed the declaration of method void btrfs_csum_final(u32 crc,
    char *result); to void btrfs_csum_final(u32 crc, u8 *result);
    
    Signed-off-by: Domagoj Tran <domagoj.trsan@gmail.com>
    [ changed cast to u8 at several call sites ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5d1da78f044b..8677d29efade 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -271,7 +271,7 @@ u32 btrfs_csum_data(char *data, u32 seed, size_t len)
 	return btrfs_crc32c(seed, data, len);
 }
 
-void btrfs_csum_final(u32 crc, char *result)
+void btrfs_csum_final(u32 crc, u8 *result)
 {
 	put_unaligned_le32(~crc, result);
 }

commit b159fa2808b1b53d784807a48ad95fa809be10b0
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 18:09:03 2016 +0100

    btrfs: remove constant parameter to memset_extent_buffer and rename it
    
    The only memset we do is to 0, so sink the parameter to the function and
    simplify all calls. Rename the function to reflect the behaviour.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 21f8e597fe97..5d1da78f044b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1412,7 +1412,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 		goto fail;
 	}
 
-	memset_extent_buffer(leaf, 0, 0, sizeof(struct btrfs_header));
+	memzero_extent_buffer(leaf, 0, sizeof(struct btrfs_header));
 	btrfs_set_header_bytenr(leaf, leaf->start);
 	btrfs_set_header_generation(leaf, trans->transid);
 	btrfs_set_header_backref_rev(leaf, BTRFS_MIXED_BACKREF_REV);
@@ -1496,7 +1496,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 		return ERR_CAST(leaf);
 	}
 
-	memset_extent_buffer(leaf, 0, 0, sizeof(struct btrfs_header));
+	memzero_extent_buffer(leaf, 0, sizeof(struct btrfs_header));
 	btrfs_set_header_bytenr(leaf, leaf->start);
 	btrfs_set_header_generation(leaf, trans->transid);
 	btrfs_set_header_backref_rev(leaf, BTRFS_MIXED_BACKREF_REV);

commit d24ee97b96db46123f766041d2ec0ca81491bd31
Author: David Sterba <dsterba@suse.com>
Date:   Wed Nov 9 17:44:25 2016 +0100

    btrfs: use new helpers to set uuids in eb
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 686d05acfdb7..21f8e597fe97 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1419,11 +1419,8 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_header_owner(leaf, objectid);
 	root->node = leaf;
 
-	write_extent_buffer(leaf, fs_info->fsid, btrfs_header_fsid(),
-			    BTRFS_FSID_SIZE);
-	write_extent_buffer(leaf, fs_info->chunk_tree_uuid,
-			    btrfs_header_chunk_tree_uuid(leaf),
-			    BTRFS_UUID_SIZE);
+	write_extent_buffer_fsid(leaf, fs_info->fsid);
+	write_extent_buffer_chunk_tree_uuid(leaf, fs_info->chunk_tree_uuid);
 	btrfs_mark_buffer_dirty(leaf);
 
 	root->commit_root = btrfs_root_node(root);
@@ -1506,8 +1503,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_header_owner(leaf, BTRFS_TREE_LOG_OBJECTID);
 	root->node = leaf;
 
-	write_extent_buffer(root->node, root->fs_info->fsid,
-			    btrfs_header_fsid(), BTRFS_FSID_SIZE);
+	write_extent_buffer_fsid(root->node, root->fs_info->fsid);
 	btrfs_mark_buffer_dirty(root->node);
 	btrfs_tree_unlock(root->node);
 	return root;

commit 62d1f9fe97dd25ca5e850bd7e140d4c9d4b9c7c7
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 23:21:05 2016 +0100

    btrfs: remove trivial helper btrfs_find_tree_block
    
    During the time, the function has been shrunk to the point that it just
    calls find_extent_buffer, just passing the parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9c4ef833ba0b..686d05acfdb7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1191,12 +1191,6 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr,
 	return 0;
 }
 
-struct extent_buffer *btrfs_find_tree_block(struct btrfs_fs_info *fs_info,
-					    u64 bytenr)
-{
-	return find_extent_buffer(fs_info, bytenr);
-}
-
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 bytenr)
 {
@@ -4452,7 +4446,7 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 
 		clear_extent_bits(dirty_pages, start, end, mark);
 		while (start <= end) {
-			eb = btrfs_find_tree_block(root->fs_info, start);
+			eb = find_extent_buffer(root->fs_info, start);
 			start += root->nodesize;
 			if (!eb)
 				continue;

commit fc2e901f26859a87b7cd5c49015552805b7a00e0
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 8 13:50:03 2016 +0100

    btrfs: reada, sink start parameter to btree_readahead_hook
    
    Originally, the eb and start were passed separately in case eb is NULL.
    Since the readahead has been refactored in 4.6, this is not true anymore
    and we can get rid of the parameter.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3a57f99d96aa..9c4ef833ba0b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -747,7 +747,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 err:
 	if (reads_done &&
 	    test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
-		btree_readahead_hook(fs_info, eb, eb->start, ret);
+		btree_readahead_hook(fs_info, eb, ret);
 
 	if (ret) {
 		/*
@@ -772,7 +772,7 @@ static int btree_io_failed_hook(struct page *page, int failed_mirror)
 	eb->read_mirror = failed_mirror;
 	atomic_dec(&eb->io_pages);
 	if (test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
-		btree_readahead_hook(eb->fs_info, eb, eb->start, -EIO);
+		btree_readahead_hook(eb->fs_info, eb, -EIO);
 	return -EIO;	/* we fixed nothing */
 }
 

commit f177d73949bf758542ca15a1c1945bd2e802cc65
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Nov 23 16:21:18 2016 +0000

    Btrfs: fix emptiness check for dirtied extent buffers at check_leaf()
    
    We can not simply use the owner field from an extent buffer's header to
    get the id of the respective tree when the extent buffer is from a
    relocation tree. When we create the root for a relocation tree we leave
    (on purpose) the owner field with the same value as the subvolume's tree
    root (we do this at ctree.c:btrfs_copy_root()). So we must ignore extent
    buffers from relocation trees, which have the BTRFS_HEADER_FLAG_RELOC
    flag set, because otherwise we will always consider the extent buffer
    as not being the root of the tree (the root of original subvolume tree
    is always different from the root of the respective relocation tree).
    
    This lead to assertion failures when running with the integrity checker
    enabled (CONFIG_BTRFS_FS_CHECK_INTEGRITY=y) such as the following:
    
    [  643.393409] BTRFS critical (device sdg): corrupt leaf, non-root leaf's nritems is 0: block=38506496, root=260, slot=0
    [  643.397609] BTRFS info (device sdg): leaf 38506496 total ptrs 0 free space 3995
    [  643.407075] assertion failed: 0, file: fs/btrfs/disk-io.c, line: 4078
    [  643.408425] ------------[ cut here ]------------
    [  643.409112] kernel BUG at fs/btrfs/ctree.h:3419!
    [  643.409773] invalid opcode: 0000 [#1] PREEMPT SMP
    [  643.410447] Modules linked in: dm_flakey dm_mod crc32c_generic btrfs xor raid6_pq ppdev psmouse acpi_cpufreq parport_pc evdev parport tpm_tis tpm_tis_core pcspkr serio_raw i2c_piix4 sg tpm i2c_core button processor loop autofs4 ext4 crc16 jbd2 mbcache sr_mod cdrom sd_mod ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring scsi_mod virtio e1000 floppy
    [  643.414356] CPU: 11 PID: 32726 Comm: btrfs Not tainted 4.8.0-rc8-btrfs-next-35+ #1
    [  643.414356] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.1-0-gb3ef39f-prebuilt.qemu-project.org 04/01/2014
    [  643.414356] task: ffff880145e95b00 task.stack: ffff88014826c000
    [  643.414356] RIP: 0010:[<ffffffffa0352759>]  [<ffffffffa0352759>] assfail.constprop.41+0x1c/0x1e [btrfs]
    [  643.414356] RSP: 0018:ffff88014826fa28  EFLAGS: 00010292
    [  643.414356] RAX: 0000000000000039 RBX: ffff88014e2d7c38 RCX: 0000000000000001
    [  643.414356] RDX: ffff88023f4d2f58 RSI: ffffffff81806c63 RDI: 00000000ffffffff
    [  643.414356] RBP: ffff88014826fa28 R08: 0000000000000001 R09: 0000000000000000
    [  643.414356] R10: ffff88014826f918 R11: ffffffff82f3c5ed R12: ffff880172910000
    [  643.414356] R13: ffff880233992230 R14: ffff8801a68a3310 R15: fffffffffffffff8
    [  643.414356] FS:  00007f9ca305e8c0(0000) GS:ffff88023f4c0000(0000) knlGS:0000000000000000
    [  643.414356] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  643.414356] CR2: 00007f9ca3071000 CR3: 000000015d01b000 CR4: 00000000000006e0
    [  643.414356] Stack:
    [  643.414356]  ffff88014826fa50 ffffffffa02d655a 000000000000000a ffff88014e2d7c38
    [  643.414356]  0000000000000000 ffff88014826faa8 ffffffffa02b72f3 ffff88014826fab8
    [  643.414356]  00ffffffa03228e4 0000000000000000 0000000000000000 ffff8801bbd4e000
    [  643.414356] Call Trace:
    [  643.414356]  [<ffffffffa02d655a>] btrfs_mark_buffer_dirty+0xdf/0xe5 [btrfs]
    [  643.414356]  [<ffffffffa02b72f3>] btrfs_copy_root+0x18a/0x1d1 [btrfs]
    [  643.414356]  [<ffffffffa0322921>] create_reloc_root+0x72/0x1ba [btrfs]
    [  643.414356]  [<ffffffffa03267c2>] btrfs_init_reloc_root+0x7b/0xa7 [btrfs]
    [  643.414356]  [<ffffffffa02d9e44>] record_root_in_trans+0xdf/0xed [btrfs]
    [  643.414356]  [<ffffffffa02db04e>] btrfs_record_root_in_trans+0x50/0x6a [btrfs]
    [  643.414356]  [<ffffffffa030ad2b>] create_subvol+0x472/0x773 [btrfs]
    [  643.414356]  [<ffffffffa030b406>] btrfs_mksubvol+0x3da/0x463 [btrfs]
    [  643.414356]  [<ffffffffa030b406>] ? btrfs_mksubvol+0x3da/0x463 [btrfs]
    [  643.414356]  [<ffffffff810781ac>] ? preempt_count_add+0x65/0x68
    [  643.414356]  [<ffffffff811a6e97>] ? __mnt_want_write+0x62/0x77
    [  643.414356]  [<ffffffffa030b55d>] btrfs_ioctl_snap_create_transid+0xce/0x187 [btrfs]
    [  643.414356]  [<ffffffffa030b67d>] btrfs_ioctl_snap_create+0x67/0x81 [btrfs]
    [  643.414356]  [<ffffffffa030ecfd>] btrfs_ioctl+0x508/0x20dd [btrfs]
    [  643.414356]  [<ffffffff81293e39>] ? __this_cpu_preempt_check+0x13/0x15
    [  643.414356]  [<ffffffff81155eca>] ? handle_mm_fault+0x976/0x9ab
    [  643.414356]  [<ffffffff81091300>] ? arch_local_irq_save+0x9/0xc
    [  643.414356]  [<ffffffff8119a2b0>] vfs_ioctl+0x18/0x34
    [  643.414356]  [<ffffffff8119a8e8>] do_vfs_ioctl+0x581/0x600
    [  643.414356]  [<ffffffff814b9552>] ? entry_SYSCALL_64_fastpath+0x5/0xa8
    [  643.414356]  [<ffffffff81093fe9>] ? trace_hardirqs_on_caller+0x17b/0x197
    [  643.414356]  [<ffffffff8119a9be>] SyS_ioctl+0x57/0x79
    [  643.414356]  [<ffffffff814b9565>] entry_SYSCALL_64_fastpath+0x18/0xa8
    [  643.414356]  [<ffffffff81091b08>] ? trace_hardirqs_off_caller+0x3f/0xaa
    [  643.414356] Code: 89 83 88 00 00 00 31 c0 5b 41 5c 41 5d 5d c3 55 89 f1 48 c7 c2 98 bc 35 a0 48 89 fe 48 c7 c7 05 be 35 a0 48 89 e5 e8 13 46 dd e0 <0f> 0b 55 89 f1 48 c7 c2 9f d3 35 a0 48 89 fe 48 c7 c7 7a d5 35
    [  643.414356] RIP  [<ffffffffa0352759>] assfail.constprop.41+0x1c/0x1e [btrfs]
    [  643.414356]  RSP <ffff88014826fa28>
    [  643.468267] ---[ end trace 6a1b3fb1a9d7d6e3 ]---
    
    This can be easily reproduced by running xfstests with the integrity
    checker enabled.
    
    Fixes: 1ba98d086fe3 (Btrfs: detect corruption when non-root leaf has zero item)
    Cc: stable@vger.kernel.org  # 4.8+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c4e673a94426..1cd325765aaa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -559,7 +559,15 @@ static noinline int check_leaf(struct btrfs_root *root,
 	u32 nritems = btrfs_header_nritems(leaf);
 	int slot;
 
-	if (nritems == 0) {
+	/*
+	 * Extent buffers from a relocation tree have a owner field that
+	 * corresponds to the subvolume tree they are based on. So just from an
+	 * extent buffer alone we can not find out what is the id of the
+	 * corresponding subvolume tree, so we can not figure out if the extent
+	 * buffer corresponds to the root of the relocation tree or not. So skip
+	 * this check for relocation trees.
+	 */
+	if (nritems == 0 && !btrfs_header_flag(leaf, BTRFS_HEADER_FLAG_RELOC)) {
 		struct btrfs_root *check_root;
 
 		key.objectid = btrfs_header_owner(leaf);
@@ -587,6 +595,9 @@ static noinline int check_leaf(struct btrfs_root *root,
 		return 0;
 	}
 
+	if (nritems == 0)
+		return 0;
+
 	/* Check the 0 item */
 	if (btrfs_item_offset_nr(leaf, 0) + btrfs_item_size_nr(leaf, 0) !=
 	    BTRFS_LEAF_DATA_SIZE(root)) {

commit ef85b25e982b5bba1530b936e283ef129f02ab9d
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Sep 2 12:35:34 2016 -0700

    Btrfs: fix BUG_ON in btrfs_mark_buffer_dirty
    
    This can only happen with CONFIG_BTRFS_FS_CHECK_INTEGRITY=y.
    
    Commit 1ba98d0 ("Btrfs: detect corruption when non-root leaf has zero item")
    assumes that a leaf is its root when leaf->bytenr == btrfs_root_bytenr(root),
    however, we should not use btrfs_root_bytenr(root) since it's mainly got
    updated during committing transaction.  So the check can fail when doing
    COW on this leaf while it is a root.
    
    This changes to use "if (leaf == btrfs_root_node(root))" instead, just like
    how we check whether leaf is a root in __btrfs_cow_block().
    
    Fixes: 1ba98d086fe3 (Btrfs: detect corruption when non-root leaf has zero item)
    Cc: stable@vger.kernel.org  # 4.8+
    Reported-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3a57f99d96aa..c4e673a94426 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -572,13 +572,17 @@ static noinline int check_leaf(struct btrfs_root *root,
 		 * open_ctree() some roots has not yet been set up.
 		 */
 		if (!IS_ERR_OR_NULL(check_root)) {
+			struct extent_buffer *eb;
+
+			eb = btrfs_root_node(check_root);
 			/* if leaf is the root, then it's fine */
-			if (leaf->start !=
-			    btrfs_root_bytenr(&check_root->root_item)) {
+			if (leaf != eb) {
 				CORRUPT("non-root leaf's nritems is 0",
-					leaf, root, 0);
+					leaf, check_root, 0);
+				free_extent_buffer(eb);
 				return -EIO;
 			}
+			free_extent_buffer(eb);
 		}
 		return 0;
 	}

commit 70fd76140a6cb63262bd47b68d57b42e889c10ee
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 1 07:40:10 2016 -0600

    block,fs: use REQ_* flags directly
    
    Remove the WRITE_* and READ_SYNC wrappers, and just use the flags
    directly.  Where applicable this also drops usage of the
    bio_set_op_attrs wrapper.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c8454a8e35f2..fe10afd51e02 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3485,9 +3485,9 @@ static int write_dev_supers(struct btrfs_device *device,
 		 * to go down lazy.
 		 */
 		if (i == 0)
-			ret = btrfsic_submit_bh(REQ_OP_WRITE, WRITE_FUA, bh);
+			ret = btrfsic_submit_bh(REQ_OP_WRITE, REQ_FUA, bh);
 		else
-			ret = btrfsic_submit_bh(REQ_OP_WRITE, WRITE_SYNC, bh);
+			ret = btrfsic_submit_bh(REQ_OP_WRITE, REQ_SYNC, bh);
 		if (ret)
 			errors++;
 	}
@@ -3551,7 +3551,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 	bio->bi_end_io = btrfs_end_empty_barrier;
 	bio->bi_bdev = device->bdev;
-	bio_set_op_attrs(bio, REQ_OP_WRITE, WRITE_FLUSH);
+	bio->bi_opf = REQ_OP_WRITE | REQ_PREFLUSH;
 	init_completion(&device->flush_wait);
 	bio->bi_private = &device->flush_wait;
 	device->flush_bio = bio;

commit 67f055c798c72c49ee0c844eae0cd6e9c83b1b16
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 1 07:40:06 2016 -0600

    btrfs: use op_is_sync to check for synchronous requests
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3a57f99d96aa..c8454a8e35f2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -930,7 +930,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 
 	atomic_inc(&fs_info->nr_async_submits);
 
-	if (bio->bi_opf & REQ_SYNC)
+	if (op_is_sync(bio->bi_opf))
 		btrfs_set_work_high_priority(&async->work);
 
 	btrfs_queue_work(fs_info->workers, &async->work);

commit d9ed71e5457c8c5bf1dc706e06468eab9e2aa87e
Merge: 19c4d2f99478 0e6757859efe
Author: Chris Mason <clm@fb.com>
Date:   Wed Oct 12 13:16:00 2016 -0700

    Merge branch 'fst-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.9
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 6675df311db87aa2107a04ef97e19420953cbace
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Sep 22 17:24:22 2016 -0700

    Btrfs: catch invalid free space trees
    
    There are two separate issues that can lead to corrupted free space
    trees.
    
    1. The free space tree bitmaps had an endianness issue on big-endian
       systems which is fixed by an earlier patch in this series.
    2. btrfs-progs before v4.7.3 modified filesystems without updating the
       free space tree.
    
    To catch both of these issues at once, we need to force the free space
    tree to be rebuilt. To do so, add a FREE_SPACE_TREE_VALID compat_ro bit.
    If the bit isn't set, we know that it was either produced by a broken
    big-endian kernel or may have been corrupted by btrfs-progs.
    
    This also provides us with a way to add rudimentary read-write support
    for the free space tree to btrfs-progs: it can just clear this bit and
    have the kernel rebuild the free space tree.
    
    Cc: stable@vger.kernel.org # 4.5+
    Tested-by: Holger Hoffsttte <holger@applied-asynchrony.com>
    Tested-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c0bfc6ce5f06..3dede6d53bad 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2566,6 +2566,7 @@ int open_ctree(struct super_block *sb,
 	int num_backups_tried = 0;
 	int backup_index = 0;
 	int max_active;
+	int clear_free_space_tree = 0;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
@@ -3131,6 +3132,14 @@ int open_ctree(struct super_block *sb,
 
 	if (btrfs_test_opt(fs_info, CLEAR_CACHE) &&
 	    btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
+		clear_free_space_tree = 1;
+	} else if (btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE) &&
+		   !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE_VALID)) {
+		btrfs_warn(fs_info, "free space tree is invalid");
+		clear_free_space_tree = 1;
+	}
+
+	if (clear_free_space_tree) {
 		btrfs_info(fs_info, "clearing free space tree");
 		ret = btrfs_clear_free_space_tree(fs_info);
 		if (ret) {

commit f8d468a15c22b954b379aa0c74914d5068448fb1
Author: Omar Sandoval <osandov@fb.com>
Date:   Thu Sep 22 17:24:21 2016 -0700

    Btrfs: fix mount -o clear_cache,space_cache=v2
    
    We moved the code for creating the free space tree the first time that
    it's enabled, but didn't move the clearing code along with it. This
    breaks my (undocumented) intention that `mount -o
    clear_cache,space_cache=v2` would clear the free space tree and then
    recreate it.
    
    Fixes: 511711af91f2 ("btrfs: don't run delayed references while we are creating the free space tree")
    Cc: stable@vger.kernel.org # 4.5+
    Tested-by: Holger Hoffsttte <holger@applied-asynchrony.com>
    Tested-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 54bc8c7c6bcd..c0bfc6ce5f06 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3129,6 +3129,18 @@ int open_ctree(struct super_block *sb,
 	if (sb->s_flags & MS_RDONLY)
 		return 0;
 
+	if (btrfs_test_opt(fs_info, CLEAR_CACHE) &&
+	    btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
+		btrfs_info(fs_info, "clearing free space tree");
+		ret = btrfs_clear_free_space_tree(fs_info);
+		if (ret) {
+			btrfs_warn(fs_info,
+				   "failed to clear free space tree: %d", ret);
+			close_ctree(tree_root);
+			return ret;
+		}
+	}
+
 	if (btrfs_test_opt(tree_root->fs_info, FREE_SPACE_TREE) &&
 	    !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
 		btrfs_info(fs_info, "creating free space tree");
@@ -3166,18 +3178,6 @@ int open_ctree(struct super_block *sb,
 
 	btrfs_qgroup_rescan_resume(fs_info);
 
-	if (btrfs_test_opt(tree_root->fs_info, CLEAR_CACHE) &&
-	    btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
-		btrfs_info(fs_info, "clearing free space tree");
-		ret = btrfs_clear_free_space_tree(fs_info);
-		if (ret) {
-			btrfs_warn(fs_info,
-				"failed to clear free space tree: %d", ret);
-			close_ctree(tree_root);
-			return ret;
-		}
-	}
-
 	if (!fs_info->uuid_root) {
 		btrfs_info(fs_info, "creating UUID tree");
 		ret = btrfs_create_uuid_tree(fs_info);

commit ab8d0fc48dba09e0a2b8b0dbfe144d4de9eb874f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:02 2016 -0400

    btrfs: convert pr_* to btrfs_* where possible
    
    For many printks, we want to know which file system issued the message.
    
    This patch converts most pr_* calls to use the btrfs_* versions instead.
    In some cases, this means adding plumbing to allow call sites access to
    an fs_info pointer.
    
    fs/btrfs/check-integrity.c is left alone for another day.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index df8c8f291831..e720d3e6ec20 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -401,7 +401,8 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
  * Return 0 if the superblock checksum type matches the checksum value of that
  * algorithm. Pass the raw disk superblock data.
  */
-static int btrfs_check_super_csum(char *raw_disk_sb)
+static int btrfs_check_super_csum(struct btrfs_fs_info *fs_info,
+				  char *raw_disk_sb)
 {
 	struct btrfs_super_block *disk_sb =
 		(struct btrfs_super_block *)raw_disk_sb;
@@ -427,7 +428,7 @@ static int btrfs_check_super_csum(char *raw_disk_sb)
 	}
 
 	if (csum_type >= ARRAY_SIZE(btrfs_csum_sizes)) {
-		pr_err("BTRFS: unsupported checksum algorithm %u\n",
+		btrfs_err(fs_info, "unsupported checksum algorithm %u",
 				csum_type);
 		ret = 1;
 	}
@@ -2780,7 +2781,7 @@ int open_ctree(struct super_block *sb,
 	 * We want to check superblock checksum, the type is stored inside.
 	 * Pass the whole disk block of size BTRFS_SUPER_INFO_SIZE (4k).
 	 */
-	if (btrfs_check_super_csum(bh->b_data)) {
+	if (btrfs_check_super_csum(fs_info, bh->b_data)) {
 		btrfs_err(fs_info, "superblock checksum mismatch");
 		err = -EINVAL;
 		brelse(bh);
@@ -3624,7 +3625,7 @@ int btrfs_get_num_tolerated_disk_barrier_failures(u64 flags)
 	}
 
 	if (min_tolerated == INT_MAX) {
-		pr_warn("BTRFS: unknown raid flag: %llu\n", flags);
+		pr_warn("BTRFS: unknown raid flag: %llu", flags);
 		min_tolerated = 0;
 	}
 
@@ -4114,24 +4115,24 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	int ret = 0;
 
 	if (btrfs_super_magic(sb) != BTRFS_MAGIC) {
-		pr_err("BTRFS: no valid FS found\n");
+		btrfs_err(fs_info, "no valid FS found");
 		ret = -EINVAL;
 	}
 	if (btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP)
-		pr_warn("BTRFS: unrecognized super flag: %llu\n",
+		btrfs_warn(fs_info, "unrecognized super flag: %llu",
 				btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP);
 	if (btrfs_super_root_level(sb) >= BTRFS_MAX_LEVEL) {
-		pr_err("BTRFS: tree_root level too big: %d >= %d\n",
+		btrfs_err(fs_info, "tree_root level too big: %d >= %d",
 				btrfs_super_root_level(sb), BTRFS_MAX_LEVEL);
 		ret = -EINVAL;
 	}
 	if (btrfs_super_chunk_root_level(sb) >= BTRFS_MAX_LEVEL) {
-		pr_err("BTRFS: chunk_root level too big: %d >= %d\n",
+		btrfs_err(fs_info, "chunk_root level too big: %d >= %d",
 				btrfs_super_chunk_root_level(sb), BTRFS_MAX_LEVEL);
 		ret = -EINVAL;
 	}
 	if (btrfs_super_log_root_level(sb) >= BTRFS_MAX_LEVEL) {
-		pr_err("BTRFS: log_root level too big: %d >= %d\n",
+		btrfs_err(fs_info, "log_root level too big: %d >= %d",
 				btrfs_super_log_root_level(sb), BTRFS_MAX_LEVEL);
 		ret = -EINVAL;
 	}
@@ -4142,47 +4143,48 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 */
 	if (!is_power_of_2(sectorsize) || sectorsize < 4096 ||
 	    sectorsize > BTRFS_MAX_METADATA_BLOCKSIZE) {
-		pr_err("BTRFS: invalid sectorsize %llu\n", sectorsize);
+		btrfs_err(fs_info, "invalid sectorsize %llu", sectorsize);
 		ret = -EINVAL;
 	}
 	/* Only PAGE SIZE is supported yet */
 	if (sectorsize != PAGE_SIZE) {
-		pr_err("BTRFS: sectorsize %llu not supported yet, only support %lu\n",
-				sectorsize, PAGE_SIZE);
+		btrfs_err(fs_info,
+			"sectorsize %llu not supported yet, only support %lu",
+			sectorsize, PAGE_SIZE);
 		ret = -EINVAL;
 	}
 	if (!is_power_of_2(nodesize) || nodesize < sectorsize ||
 	    nodesize > BTRFS_MAX_METADATA_BLOCKSIZE) {
-		pr_err("BTRFS: invalid nodesize %llu\n", nodesize);
+		btrfs_err(fs_info, "invalid nodesize %llu", nodesize);
 		ret = -EINVAL;
 	}
 	if (nodesize != le32_to_cpu(sb->__unused_leafsize)) {
-		pr_err("BTRFS: invalid leafsize %u, should be %llu\n",
-				le32_to_cpu(sb->__unused_leafsize),
-				nodesize);
+		btrfs_err(fs_info, "invalid leafsize %u, should be %llu",
+			  le32_to_cpu(sb->__unused_leafsize), nodesize);
 		ret = -EINVAL;
 	}
 
 	/* Root alignment check */
 	if (!IS_ALIGNED(btrfs_super_root(sb), sectorsize)) {
-		pr_warn("BTRFS: tree_root block unaligned: %llu\n",
-				btrfs_super_root(sb));
+		btrfs_warn(fs_info, "tree_root block unaligned: %llu",
+			   btrfs_super_root(sb));
 		ret = -EINVAL;
 	}
 	if (!IS_ALIGNED(btrfs_super_chunk_root(sb), sectorsize)) {
-		pr_warn("BTRFS: chunk_root block unaligned: %llu\n",
-				btrfs_super_chunk_root(sb));
+		btrfs_warn(fs_info, "chunk_root block unaligned: %llu",
+			   btrfs_super_chunk_root(sb));
 		ret = -EINVAL;
 	}
 	if (!IS_ALIGNED(btrfs_super_log_root(sb), sectorsize)) {
-		pr_warn("BTRFS: log_root block unaligned: %llu\n",
-				btrfs_super_log_root(sb));
+		btrfs_warn(fs_info, "log_root block unaligned: %llu",
+			   btrfs_super_log_root(sb));
 		ret = -EINVAL;
 	}
 
 	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_UUID_SIZE) != 0) {
-		pr_err("BTRFS: dev_item UUID does not match fsid: %pU != %pU\n",
-				fs_info->fsid, sb->dev_item.fsid);
+		btrfs_err(fs_info,
+			   "dev_item UUID does not match fsid: %pU != %pU",
+			   fs_info->fsid, sb->dev_item.fsid);
 		ret = -EINVAL;
 	}
 
@@ -4192,25 +4194,25 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 */
 	if (btrfs_super_bytes_used(sb) < 6 * btrfs_super_nodesize(sb)) {
 		btrfs_err(fs_info, "bytes_used is too small %llu",
-		       btrfs_super_bytes_used(sb));
+			  btrfs_super_bytes_used(sb));
 		ret = -EINVAL;
 	}
 	if (!is_power_of_2(btrfs_super_stripesize(sb))) {
 		btrfs_err(fs_info, "invalid stripesize %u",
-		       btrfs_super_stripesize(sb));
+			  btrfs_super_stripesize(sb));
 		ret = -EINVAL;
 	}
 	if (btrfs_super_num_devices(sb) > (1UL << 31))
-		pr_warn("BTRFS: suspicious number of devices: %llu\n",
-				btrfs_super_num_devices(sb));
+		btrfs_warn(fs_info, "suspicious number of devices: %llu",
+			   btrfs_super_num_devices(sb));
 	if (btrfs_super_num_devices(sb) == 0) {
-		pr_err("BTRFS: number of devices is 0\n");
+		btrfs_err(fs_info, "number of devices is 0");
 		ret = -EINVAL;
 	}
 
 	if (btrfs_super_bytenr(sb) != BTRFS_SUPER_INFO_OFFSET) {
-		pr_err("BTRFS: super offset mismatch %llu != %u\n",
-				btrfs_super_bytenr(sb), BTRFS_SUPER_INFO_OFFSET);
+		btrfs_err(fs_info, "super offset mismatch %llu != %u",
+			  btrfs_super_bytenr(sb), BTRFS_SUPER_INFO_OFFSET);
 		ret = -EINVAL;
 	}
 
@@ -4219,17 +4221,17 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 * and one chunk
 	 */
 	if (btrfs_super_sys_array_size(sb) > BTRFS_SYSTEM_CHUNK_ARRAY_SIZE) {
-		pr_err("BTRFS: system chunk array too big %u > %u\n",
-				btrfs_super_sys_array_size(sb),
-				BTRFS_SYSTEM_CHUNK_ARRAY_SIZE);
+		btrfs_err(fs_info, "system chunk array too big %u > %u",
+			  btrfs_super_sys_array_size(sb),
+			  BTRFS_SYSTEM_CHUNK_ARRAY_SIZE);
 		ret = -EINVAL;
 	}
 	if (btrfs_super_sys_array_size(sb) < sizeof(struct btrfs_disk_key)
 			+ sizeof(struct btrfs_chunk)) {
-		pr_err("BTRFS: system chunk array too small %u < %zu\n",
-				btrfs_super_sys_array_size(sb),
-				sizeof(struct btrfs_disk_key)
-				+ sizeof(struct btrfs_chunk));
+		btrfs_err(fs_info, "system chunk array too small %u < %zu",
+			  btrfs_super_sys_array_size(sb),
+			  sizeof(struct btrfs_disk_key)
+			  + sizeof(struct btrfs_chunk));
 		ret = -EINVAL;
 	}
 
@@ -4238,12 +4240,16 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 * but it's still possible that it's the one that's wrong.
 	 */
 	if (btrfs_super_generation(sb) < btrfs_super_chunk_root_generation(sb))
-		pr_warn("BTRFS: suspicious: generation < chunk_root_generation: %llu < %llu\n",
-			btrfs_super_generation(sb), btrfs_super_chunk_root_generation(sb));
+		btrfs_warn(fs_info,
+			"suspicious: generation < chunk_root_generation: %llu < %llu",
+			btrfs_super_generation(sb),
+			btrfs_super_chunk_root_generation(sb));
 	if (btrfs_super_generation(sb) < btrfs_super_cache_generation(sb)
 	    && btrfs_super_cache_generation(sb) != (u64)-1)
-		pr_warn("BTRFS: suspicious: generation < cache_generation: %llu < %llu\n",
-			btrfs_super_generation(sb), btrfs_super_cache_generation(sb));
+		btrfs_warn(fs_info,
+			"suspicious: generation < cache_generation: %llu < %llu",
+			btrfs_super_generation(sb),
+			btrfs_super_cache_generation(sb));
 
 	return ret;
 }

commit 62e855771dacf7c4d6daf9741642a965e7066d31
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:01 2016 -0400

    btrfs: convert printk(KERN_* to use pr_* calls
    
    This patch converts printk(KERN_* style messages to use the pr_* versions.
    
    One side effect is that anything that was KERN_DEBUG is now automatically
    a dynamic debug message.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9e91b8b238f7..df8c8f291831 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -427,7 +427,7 @@ static int btrfs_check_super_csum(char *raw_disk_sb)
 	}
 
 	if (csum_type >= ARRAY_SIZE(btrfs_csum_sizes)) {
-		printk(KERN_ERR "BTRFS: unsupported checksum algorithm %u\n",
+		pr_err("BTRFS: unsupported checksum algorithm %u\n",
 				csum_type);
 		ret = 1;
 	}
@@ -4114,24 +4114,24 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	int ret = 0;
 
 	if (btrfs_super_magic(sb) != BTRFS_MAGIC) {
-		printk(KERN_ERR "BTRFS: no valid FS found\n");
+		pr_err("BTRFS: no valid FS found\n");
 		ret = -EINVAL;
 	}
 	if (btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP)
-		printk(KERN_WARNING "BTRFS: unrecognized super flag: %llu\n",
+		pr_warn("BTRFS: unrecognized super flag: %llu\n",
 				btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP);
 	if (btrfs_super_root_level(sb) >= BTRFS_MAX_LEVEL) {
-		printk(KERN_ERR "BTRFS: tree_root level too big: %d >= %d\n",
+		pr_err("BTRFS: tree_root level too big: %d >= %d\n",
 				btrfs_super_root_level(sb), BTRFS_MAX_LEVEL);
 		ret = -EINVAL;
 	}
 	if (btrfs_super_chunk_root_level(sb) >= BTRFS_MAX_LEVEL) {
-		printk(KERN_ERR "BTRFS: chunk_root level too big: %d >= %d\n",
+		pr_err("BTRFS: chunk_root level too big: %d >= %d\n",
 				btrfs_super_chunk_root_level(sb), BTRFS_MAX_LEVEL);
 		ret = -EINVAL;
 	}
 	if (btrfs_super_log_root_level(sb) >= BTRFS_MAX_LEVEL) {
-		printk(KERN_ERR "BTRFS: log_root level too big: %d >= %d\n",
+		pr_err("BTRFS: log_root level too big: %d >= %d\n",
 				btrfs_super_log_root_level(sb), BTRFS_MAX_LEVEL);
 		ret = -EINVAL;
 	}
@@ -4142,22 +4142,22 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 */
 	if (!is_power_of_2(sectorsize) || sectorsize < 4096 ||
 	    sectorsize > BTRFS_MAX_METADATA_BLOCKSIZE) {
-		printk(KERN_ERR "BTRFS: invalid sectorsize %llu\n", sectorsize);
+		pr_err("BTRFS: invalid sectorsize %llu\n", sectorsize);
 		ret = -EINVAL;
 	}
 	/* Only PAGE SIZE is supported yet */
 	if (sectorsize != PAGE_SIZE) {
-		printk(KERN_ERR "BTRFS: sectorsize %llu not supported yet, only support %lu\n",
+		pr_err("BTRFS: sectorsize %llu not supported yet, only support %lu\n",
 				sectorsize, PAGE_SIZE);
 		ret = -EINVAL;
 	}
 	if (!is_power_of_2(nodesize) || nodesize < sectorsize ||
 	    nodesize > BTRFS_MAX_METADATA_BLOCKSIZE) {
-		printk(KERN_ERR "BTRFS: invalid nodesize %llu\n", nodesize);
+		pr_err("BTRFS: invalid nodesize %llu\n", nodesize);
 		ret = -EINVAL;
 	}
 	if (nodesize != le32_to_cpu(sb->__unused_leafsize)) {
-		printk(KERN_ERR "BTRFS: invalid leafsize %u, should be %llu\n",
+		pr_err("BTRFS: invalid leafsize %u, should be %llu\n",
 				le32_to_cpu(sb->__unused_leafsize),
 				nodesize);
 		ret = -EINVAL;
@@ -4165,23 +4165,23 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 
 	/* Root alignment check */
 	if (!IS_ALIGNED(btrfs_super_root(sb), sectorsize)) {
-		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
+		pr_warn("BTRFS: tree_root block unaligned: %llu\n",
 				btrfs_super_root(sb));
 		ret = -EINVAL;
 	}
 	if (!IS_ALIGNED(btrfs_super_chunk_root(sb), sectorsize)) {
-		printk(KERN_WARNING "BTRFS: chunk_root block unaligned: %llu\n",
+		pr_warn("BTRFS: chunk_root block unaligned: %llu\n",
 				btrfs_super_chunk_root(sb));
 		ret = -EINVAL;
 	}
 	if (!IS_ALIGNED(btrfs_super_log_root(sb), sectorsize)) {
-		printk(KERN_WARNING "BTRFS: log_root block unaligned: %llu\n",
+		pr_warn("BTRFS: log_root block unaligned: %llu\n",
 				btrfs_super_log_root(sb));
 		ret = -EINVAL;
 	}
 
 	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_UUID_SIZE) != 0) {
-		printk(KERN_ERR "BTRFS: dev_item UUID does not match fsid: %pU != %pU\n",
+		pr_err("BTRFS: dev_item UUID does not match fsid: %pU != %pU\n",
 				fs_info->fsid, sb->dev_item.fsid);
 		ret = -EINVAL;
 	}
@@ -4201,15 +4201,15 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 		ret = -EINVAL;
 	}
 	if (btrfs_super_num_devices(sb) > (1UL << 31))
-		printk(KERN_WARNING "BTRFS: suspicious number of devices: %llu\n",
+		pr_warn("BTRFS: suspicious number of devices: %llu\n",
 				btrfs_super_num_devices(sb));
 	if (btrfs_super_num_devices(sb) == 0) {
-		printk(KERN_ERR "BTRFS: number of devices is 0\n");
+		pr_err("BTRFS: number of devices is 0\n");
 		ret = -EINVAL;
 	}
 
 	if (btrfs_super_bytenr(sb) != BTRFS_SUPER_INFO_OFFSET) {
-		printk(KERN_ERR "BTRFS: super offset mismatch %llu != %u\n",
+		pr_err("BTRFS: super offset mismatch %llu != %u\n",
 				btrfs_super_bytenr(sb), BTRFS_SUPER_INFO_OFFSET);
 		ret = -EINVAL;
 	}
@@ -4219,14 +4219,14 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 * and one chunk
 	 */
 	if (btrfs_super_sys_array_size(sb) > BTRFS_SYSTEM_CHUNK_ARRAY_SIZE) {
-		printk(KERN_ERR "BTRFS: system chunk array too big %u > %u\n",
+		pr_err("BTRFS: system chunk array too big %u > %u\n",
 				btrfs_super_sys_array_size(sb),
 				BTRFS_SYSTEM_CHUNK_ARRAY_SIZE);
 		ret = -EINVAL;
 	}
 	if (btrfs_super_sys_array_size(sb) < sizeof(struct btrfs_disk_key)
 			+ sizeof(struct btrfs_chunk)) {
-		printk(KERN_ERR "BTRFS: system chunk array too small %u < %zu\n",
+		pr_err("BTRFS: system chunk array too small %u < %zu\n",
 				btrfs_super_sys_array_size(sb),
 				sizeof(struct btrfs_disk_key)
 				+ sizeof(struct btrfs_chunk));
@@ -4238,13 +4238,11 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 * but it's still possible that it's the one that's wrong.
 	 */
 	if (btrfs_super_generation(sb) < btrfs_super_chunk_root_generation(sb))
-		printk(KERN_WARNING
-			"BTRFS: suspicious: generation < chunk_root_generation: %llu < %llu\n",
+		pr_warn("BTRFS: suspicious: generation < chunk_root_generation: %llu < %llu\n",
 			btrfs_super_generation(sb), btrfs_super_chunk_root_generation(sb));
 	if (btrfs_super_generation(sb) < btrfs_super_cache_generation(sb)
 	    && btrfs_super_cache_generation(sb) != (u64)-1)
-		printk(KERN_WARNING
-			"BTRFS: suspicious: generation < cache_generation: %llu < %llu\n",
+		pr_warn("BTRFS: suspicious: generation < cache_generation: %llu < %llu\n",
 			btrfs_super_generation(sb), btrfs_super_cache_generation(sb));
 
 	return ret;

commit 5d163e0e68ce743e1e919ddd3264c96ac02e9026
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:00 2016 -0400

    btrfs: unsplit printed strings
    
    CodingStyle chapter 2:
    "[...] never break user-visible strings such as printk messages,
    because that breaks the ability to grep for them."
    
    This patch unsplits user-visible strings.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 92dd26eef7ab..9e91b8b238f7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -326,8 +326,7 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 
 			read_extent_buffer(buf, &val, 0, csum_size);
 			btrfs_warn_rl(fs_info,
-				"%s checksum verify failed on %llu wanted %X found %X "
-				"level %d",
+				"%s checksum verify failed on %llu wanted %X found %X level %d",
 				fs_info->sb->s_id, buf->start,
 				val, found, btrfs_header_level(buf));
 			if (result != (char *)&inline_result)
@@ -4052,8 +4051,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	root = BTRFS_I(buf->pages[0]->mapping->host)->root;
 	btrfs_assert_tree_locked(buf);
 	if (transid != root->fs_info->generation)
-		WARN(1, KERN_CRIT "btrfs transid mismatch buffer %llu, "
-		       "found %llu running %llu\n",
+		WARN(1, KERN_CRIT "btrfs transid mismatch buffer %llu, found %llu running %llu\n",
 			buf->start, transid, root->fs_info->generation);
 	was_dirty = set_extent_buffer_dirty(buf);
 	if (!was_dirty)

commit 6b722c1747d533ac6d4df110dc8233db46918b65
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Sep 14 17:23:24 2016 -0700

    Btrfs: improve check_node to avoid reading corrupted nodes
    
    We need to check items in a node to make sure that we're reading
    a valid one, otherwise we could get various crashes while processing
    delayed_refs.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e4c2428cee85..92dd26eef7ab 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -546,9 +546,10 @@ static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
 }
 
 #define CORRUPT(reason, eb, root, slot)				\
-	btrfs_crit(root->fs_info, "corrupt leaf, %s: block=%llu,"	\
-		   "root=%llu, slot=%d", reason,			\
-	       btrfs_header_bytenr(eb),	root->objectid, slot)
+	btrfs_crit(root->fs_info, "corrupt %s, %s: block=%llu,"	\
+		   " root=%llu, slot=%d",			\
+		   btrfs_header_level(eb) == 0 ? "leaf" : "node",\
+		   reason, btrfs_header_bytenr(eb), root->objectid, slot)
 
 static noinline int check_leaf(struct btrfs_root *root,
 			       struct extent_buffer *leaf)
@@ -635,6 +636,10 @@ static noinline int check_leaf(struct btrfs_root *root,
 static int check_node(struct btrfs_root *root, struct extent_buffer *node)
 {
 	unsigned long nr = btrfs_header_nritems(node);
+	struct btrfs_key key, next_key;
+	int slot;
+	u64 bytenr;
+	int ret = 0;
 
 	if (nr == 0 || nr > BTRFS_NODEPTRS_PER_BLOCK(root)) {
 		btrfs_crit(root->fs_info,
@@ -642,7 +647,26 @@ static int check_node(struct btrfs_root *root, struct extent_buffer *node)
 			   node->start, root->objectid, nr);
 		return -EIO;
 	}
-	return 0;
+
+	for (slot = 0; slot < nr - 1; slot++) {
+		bytenr = btrfs_node_blockptr(node, slot);
+		btrfs_node_key_to_cpu(node, &key, slot);
+		btrfs_node_key_to_cpu(node, &next_key, slot + 1);
+
+		if (!bytenr) {
+			CORRUPT("invalid item slot", node, root, slot);
+			ret = -EIO;
+			goto out;
+		}
+
+		if (btrfs_comp_cpu_keys(&key, &next_key) >= 0) {
+			CORRUPT("bad key order", node, root, slot);
+			ret = -EIO;
+			goto out;
+		}
+	}
+out:
+	return ret;
 }
 
 static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,

commit 8436ea91a1c4fd8ed57ff0c0ca482ee3dbe744c7
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Sep 2 15:40:03 2016 -0400

    Btrfs: kill the start argument to read_extent_buffer_pages
    
    Nobody uses this, it makes no sense to do partial reads of extent buffers.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f92bfa8ffd41..e4c2428cee85 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -442,7 +442,7 @@ static int btrfs_check_super_csum(char *raw_disk_sb)
  */
 static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 					  struct extent_buffer *eb,
-					  u64 start, u64 parent_transid)
+					  u64 parent_transid)
 {
 	struct extent_io_tree *io_tree;
 	int failed = 0;
@@ -454,8 +454,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 	clear_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 	io_tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 	while (1) {
-		ret = read_extent_buffer_pages(io_tree, eb, start,
-					       WAIT_COMPLETE,
+		ret = read_extent_buffer_pages(io_tree, eb, WAIT_COMPLETE,
 					       btree_get_extent, mirror_num);
 		if (!ret) {
 			if (!verify_parent_transid(io_tree, eb,
@@ -1132,7 +1131,7 @@ void readahead_tree_block(struct btrfs_root *root, u64 bytenr)
 	if (IS_ERR(buf))
 		return;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
-				 buf, 0, WAIT_NONE, btree_get_extent, 0);
+				 buf, WAIT_NONE, btree_get_extent, 0);
 	free_extent_buffer(buf);
 }
 
@@ -1150,7 +1149,7 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr,
 
 	set_bit(EXTENT_BUFFER_READAHEAD, &buf->bflags);
 
-	ret = read_extent_buffer_pages(io_tree, buf, 0, WAIT_PAGE_LOCK,
+	ret = read_extent_buffer_pages(io_tree, buf, WAIT_PAGE_LOCK,
 				       btree_get_extent, mirror_num);
 	if (ret) {
 		free_extent_buffer(buf);
@@ -1206,7 +1205,7 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 	if (IS_ERR(buf))
 		return buf;
 
-	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
+	ret = btree_read_extent_buffer_pages(root, buf, parent_transid);
 	if (ret) {
 		free_extent_buffer(buf);
 		return ERR_PTR(ret);
@@ -4081,7 +4080,7 @@ void btrfs_btree_balance_dirty_nodelay(struct btrfs_root *root)
 int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 {
 	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
-	return btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
+	return btree_read_extent_buffer_pages(root, buf, parent_transid);
 }
 
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,

commit afcdd129e05a9210a5d19d4aa6e0afa475fc49e2
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Sep 2 15:40:02 2016 -0400

    Btrfs: add a flags field to btrfs_fs_info
    
    We have a lot of random ints in btrfs_fs_info that can be put into flags.  This
    is mostly equivalent with the exception of how we deal with quota going on or
    off, now instead we set a flag when we are turning it on or off and deal with
    that appropriately, rather than just having a pending state that the current
    quota_enabled gets set to.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 754de24f17af..f92bfa8ffd41 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1839,7 +1839,7 @@ static int cleaner_kthread(void *arg)
 		 * Do not do anything if we might cause open_ctree() to block
 		 * before we have finished mounting the filesystem.
 		 */
-		if (!root->fs_info->open)
+		if (!test_bit(BTRFS_FS_OPEN, &root->fs_info->flags))
 			goto sleep;
 
 		if (!mutex_trylock(&root->fs_info->cleaner_mutex))
@@ -2332,8 +2332,6 @@ static void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)
 	fs_info->qgroup_op_tree = RB_ROOT;
 	INIT_LIST_HEAD(&fs_info->dirty_qgroups);
 	fs_info->qgroup_seq = 1;
-	fs_info->quota_enabled = 0;
-	fs_info->pending_quota_state = 0;
 	fs_info->qgroup_ulist = NULL;
 	fs_info->qgroup_rescan_running = false;
 	mutex_init(&fs_info->qgroup_rescan_lock);
@@ -2518,8 +2516,7 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info,
 	root = btrfs_read_tree_root(tree_root, &location);
 	if (!IS_ERR(root)) {
 		set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
-		fs_info->quota_enabled = 1;
-		fs_info->pending_quota_state = 1;
+		set_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags);
 		fs_info->quota_root = root;
 	}
 
@@ -2710,8 +2707,7 @@ int open_ctree(struct super_block *sb,
 	extent_io_tree_init(&fs_info->freed_extents[1],
 			     fs_info->btree_inode->i_mapping);
 	fs_info->pinned_extents = &fs_info->freed_extents[0];
-	fs_info->do_barriers = 1;
-
+	set_bit(BTRFS_FS_BARRIER, &fs_info->flags);
 
 	mutex_init(&fs_info->ordered_operations_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
@@ -3199,10 +3195,9 @@ int open_ctree(struct super_block *sb,
 			return ret;
 		}
 	} else {
-		fs_info->update_uuid_tree_gen = 1;
+		set_bit(BTRFS_FS_UPDATE_UUID_TREE_GEN, &fs_info->flags);
 	}
-
-	fs_info->open = 1;
+	set_bit(BTRFS_FS_OPEN, &fs_info->flags);
 
 	/*
 	 * backuproot only affect mount behavior, and if open_ctree succeeded,
@@ -3893,8 +3888,7 @@ void close_ctree(struct btrfs_root *root)
 	struct btrfs_fs_info *fs_info = root->fs_info;
 	int ret;
 
-	fs_info->closing = 1;
-	smp_mb();
+	set_bit(BTRFS_FS_CLOSING_START, &fs_info->flags);
 
 	/* wait for the qgroup rescan worker to stop */
 	btrfs_qgroup_wait_for_completion(fs_info, false);
@@ -3939,8 +3933,7 @@ void close_ctree(struct btrfs_root *root)
 	kthread_stop(fs_info->transaction_kthread);
 	kthread_stop(fs_info->cleaner_kthread);
 
-	fs_info->closing = 2;
-	smp_mb();
+	set_bit(BTRFS_FS_CLOSING_DONE, &fs_info->flags);
 
 	btrfs_free_qgroup_config(fs_info);
 
@@ -3965,7 +3958,7 @@ void close_ctree(struct btrfs_root *root)
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	btrfs_stop_all_workers(fs_info);
 
-	fs_info->open = 0;
+	clear_bit(BTRFS_FS_OPEN, &fs_info->flags);
 	free_root_pointers(fs_info, 1);
 
 	iput(fs_info->btree_inode);

commit c79a175175d5a908a7c4d923d44f36808f56536e
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Jul 20 17:44:12 2016 -0700

    Btrfs: fix memory leak of block group cache
    
    While processing delayed refs, we may update block group's statistics
    and attach it to cur_trans->dirty_bgs, and later writing dirty block
    groups will process the list, which happens during
    btrfs_commit_transaction().
    
    For whatever reason, the transaction is aborted and dirty_bgs
    is not processed in cleanup_transaction(), we end up with memory leak
    of these dirty block group cache.
    
    Since btrfs_start_dirty_block_groups() doesn't make it go to the commit
    critical section, this also adds the cleanup work inside it.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 54bc8c7c6bcd..754de24f17af 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4475,9 +4475,80 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 	return 0;
 }
 
+static void btrfs_cleanup_bg_io(struct btrfs_block_group_cache *cache)
+{
+	struct inode *inode;
+
+	inode = cache->io_ctl.inode;
+	if (inode) {
+		invalidate_inode_pages2(inode->i_mapping);
+		BTRFS_I(inode)->generation = 0;
+		cache->io_ctl.inode = NULL;
+		iput(inode);
+	}
+	btrfs_put_block_group(cache);
+}
+
+void btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,
+			     struct btrfs_root *root)
+{
+	struct btrfs_block_group_cache *cache;
+
+	spin_lock(&cur_trans->dirty_bgs_lock);
+	while (!list_empty(&cur_trans->dirty_bgs)) {
+		cache = list_first_entry(&cur_trans->dirty_bgs,
+					 struct btrfs_block_group_cache,
+					 dirty_list);
+		if (!cache) {
+			btrfs_err(root->fs_info,
+				  "orphan block group dirty_bgs list");
+			spin_unlock(&cur_trans->dirty_bgs_lock);
+			return;
+		}
+
+		if (!list_empty(&cache->io_list)) {
+			spin_unlock(&cur_trans->dirty_bgs_lock);
+			list_del_init(&cache->io_list);
+			btrfs_cleanup_bg_io(cache);
+			spin_lock(&cur_trans->dirty_bgs_lock);
+		}
+
+		list_del_init(&cache->dirty_list);
+		spin_lock(&cache->lock);
+		cache->disk_cache_state = BTRFS_DC_ERROR;
+		spin_unlock(&cache->lock);
+
+		spin_unlock(&cur_trans->dirty_bgs_lock);
+		btrfs_put_block_group(cache);
+		spin_lock(&cur_trans->dirty_bgs_lock);
+	}
+	spin_unlock(&cur_trans->dirty_bgs_lock);
+
+	while (!list_empty(&cur_trans->io_bgs)) {
+		cache = list_first_entry(&cur_trans->io_bgs,
+					 struct btrfs_block_group_cache,
+					 io_list);
+		if (!cache) {
+			btrfs_err(root->fs_info,
+				  "orphan block group on io_bgs list");
+			return;
+		}
+
+		list_del_init(&cache->io_list);
+		spin_lock(&cache->lock);
+		cache->disk_cache_state = BTRFS_DC_ERROR;
+		spin_unlock(&cache->lock);
+		btrfs_cleanup_bg_io(cache);
+	}
+}
+
 void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 				   struct btrfs_root *root)
 {
+	btrfs_cleanup_dirty_bgs(cur_trans, root);
+	ASSERT(list_empty(&cur_trans->dirty_bgs));
+	ASSERT(list_empty(&cur_trans->io_bgs));
+
 	btrfs_destroy_delayed_refs(cur_trans, root);
 
 	cur_trans->state = TRANS_STATE_COMMIT_START;

commit 28687b935e93a9041a485b9ecdcab0e335f8eda5
Merge: 370f6017295d 28a235931b56
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 26 20:22:01 2016 -0700

    Merge branch 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "We've queued up a few different fixes in here.  These range from
      enospc corners to fsync and quota fixes, and a few targeted at error
      handling for corrupt metadata/fuzzing"
    
    * 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix lockdep warning on deadlock against an inode's log mutex
      Btrfs: detect corruption when non-root leaf has zero item
      Btrfs: check btree node's nritems
      btrfs: don't create or leak aliased root while cleaning up orphans
      Btrfs: fix em leak in find_first_block_group
      btrfs: do not background blkdev_put()
      Btrfs: clarify do_chunk_alloc()'s return value
      btrfs: fix fsfreeze hang caused by delayed iputs deal
      btrfs: update btrfs_space_info's bytes_may_use timely
      btrfs: divide btrfs_update_reserved_bytes() into two functions
      btrfs: use correct offset for reloc_inode in prealloc_file_extent_cluster()
      btrfs: qgroup: Fix qgroup incorrectness caused by log replay
      btrfs: relocation: Fix leaking qgroups numbers on data extents
      btrfs: qgroup: Refactor btrfs_qgroup_insert_dirty_extent()
      btrfs: waiting on qgroup rescan should not always be interruptible
      btrfs: properly track when rescan worker is running
      btrfs: flush_space: treat return value of do_chunk_alloc properly
      Btrfs: add ASSERT for block group's memory leak
      btrfs: backref: Fix soft lockup in __merge_refs function
      Btrfs: fix memory leak of reloc_root

commit 1ba98d086fe3a14d6a31f2f66dbab70c45d00f63
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Tue Aug 23 15:22:58 2016 -0700

    Btrfs: detect corruption when non-root leaf has zero item
    
    Right now we treat leaf which has zero item as a valid one
    because we could have an empty tree, that is, a root that is
    also a leaf without any item, however, in the same case but
    when the leaf is not a root, we can end up with hitting the
    BUG_ON(1) in btrfs_extend_item() called by
    setup_inline_extent_backref().
    
    This makes us check the situation as a corruption if leaf is
    not its own root.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 474209f50844..70e76ad11fbf 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -560,8 +560,29 @@ static noinline int check_leaf(struct btrfs_root *root,
 	u32 nritems = btrfs_header_nritems(leaf);
 	int slot;
 
-	if (nritems == 0)
+	if (nritems == 0) {
+		struct btrfs_root *check_root;
+
+		key.objectid = btrfs_header_owner(leaf);
+		key.type = BTRFS_ROOT_ITEM_KEY;
+		key.offset = (u64)-1;
+
+		check_root = btrfs_get_fs_root(root->fs_info, &key, false);
+		/*
+		 * The only reason we also check NULL here is that during
+		 * open_ctree() some roots has not yet been set up.
+		 */
+		if (!IS_ERR_OR_NULL(check_root)) {
+			/* if leaf is the root, then it's fine */
+			if (leaf->start !=
+			    btrfs_root_bytenr(&check_root->root_item)) {
+				CORRUPT("non-root leaf's nritems is 0",
+					leaf, root, 0);
+				return -EIO;
+			}
+		}
 		return 0;
+	}
 
 	/* Check the 0 item */
 	if (btrfs_item_offset_nr(leaf, 0) + btrfs_item_size_nr(leaf, 0) !=

commit 053ab70f0604224c7893b43f9d9d5efa283580d6
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Tue Aug 23 17:37:45 2016 -0700

    Btrfs: check btree node's nritems
    
    When btree node (level = 1) has nritems which equals to zero,
    we can end up with panic due to insert_ptr()'s
    
    BUG_ON(slot > nritems);
    
    where slot is 1 and nritems is 0, as copy_for_split() calls
    insert_ptr(.., path->slots[1] + 1, ...);
    
    A invalid value results in the whole mess, this adds the check
    for btree's node nritems so that we stop reading block when
    when something is wrong.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index edda47162752..474209f50844 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -613,6 +613,19 @@ static noinline int check_leaf(struct btrfs_root *root,
 	return 0;
 }
 
+static int check_node(struct btrfs_root *root, struct extent_buffer *node)
+{
+	unsigned long nr = btrfs_header_nritems(node);
+
+	if (nr == 0 || nr > BTRFS_NODEPTRS_PER_BLOCK(root)) {
+		btrfs_crit(root->fs_info,
+			   "corrupt node: block %llu root %llu nritems %lu",
+			   node->start, root->objectid, nr);
+		return -EIO;
+	}
+	return 0;
+}
+
 static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 				      u64 phy_offset, struct page *page,
 				      u64 start, u64 end, int mirror)
@@ -683,6 +696,9 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 		ret = -EIO;
 	}
 
+	if (found_level > 0 && check_node(root, eb))
+		ret = -EIO;
+
 	if (!ret)
 		set_extent_buffer_uptodate(eb);
 err:

commit 35bbb97fc898aeb874cb7c8b746f091caa359994
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Aug 17 21:58:33 2016 -0400

    btrfs: don't create or leak aliased root while cleaning up orphans
    
    commit 909c3a22da3 (Btrfs: fix loading of orphan roots leading to BUG_ON)
    avoids the BUG_ON but can add an aliased root to the dead_roots list or
    leak the root.
    
    Since we've already been loading roots into the radix tree, we should
    use it before looking the root up on disk.
    
    Cc: <stable@vger.kernel.org> # 4.5
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 17062223fac3..edda47162752 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1624,8 +1624,8 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 	return ret;
 }
 
-static struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
-					       u64 root_id)
+struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
+					u64 root_id)
 {
 	struct btrfs_root *root;
 

commit 9e7cc91a6d18a4973c6d2cc104871439c9e94f3d
Author: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
Date:   Mon Aug 1 13:28:08 2016 +0800

    btrfs: fix fsfreeze hang caused by delayed iputs deal
    
    When running fstests generic/068, sometimes we got below deadlock:
      xfs_io          D ffff8800331dbb20     0  6697   6693 0x00000080
      ffff8800331dbb20 ffff88007acfc140 ffff880034d895c0 ffff8800331dc000
      ffff880032d243e8 fffffffeffffffff ffff880032d24400 0000000000000001
      ffff8800331dbb38 ffffffff816a9045 ffff880034d895c0 ffff8800331dbba8
      Call Trace:
      [<ffffffff816a9045>] schedule+0x35/0x80
      [<ffffffff816abab2>] rwsem_down_read_failed+0xf2/0x140
      [<ffffffff8118f5e1>] ? __filemap_fdatawrite_range+0xd1/0x100
      [<ffffffff8134f978>] call_rwsem_down_read_failed+0x18/0x30
      [<ffffffffa06631fc>] ? btrfs_alloc_block_rsv+0x2c/0xb0 [btrfs]
      [<ffffffff810d32b5>] percpu_down_read+0x35/0x50
      [<ffffffff81217dfc>] __sb_start_write+0x2c/0x40
      [<ffffffffa067f5d5>] start_transaction+0x2a5/0x4d0 [btrfs]
      [<ffffffffa067f857>] btrfs_join_transaction+0x17/0x20 [btrfs]
      [<ffffffffa068ba34>] btrfs_evict_inode+0x3c4/0x5d0 [btrfs]
      [<ffffffff81230a1a>] evict+0xba/0x1a0
      [<ffffffff812316b6>] iput+0x196/0x200
      [<ffffffffa06851d0>] btrfs_run_delayed_iputs+0x70/0xc0 [btrfs]
      [<ffffffffa067f1d8>] btrfs_commit_transaction+0x928/0xa80 [btrfs]
      [<ffffffffa0646df0>] btrfs_freeze+0x30/0x40 [btrfs]
      [<ffffffff81218040>] freeze_super+0xf0/0x190
      [<ffffffff81229275>] do_vfs_ioctl+0x4a5/0x5c0
      [<ffffffff81003176>] ? do_audit_syscall_entry+0x66/0x70
      [<ffffffff810038cf>] ? syscall_trace_enter_phase1+0x11f/0x140
      [<ffffffff81229409>] SyS_ioctl+0x79/0x90
      [<ffffffff81003c12>] do_syscall_64+0x62/0x110
      [<ffffffff816acbe1>] entry_SYSCALL64_slow_path+0x25/0x25
    
    >From this warning, freeze_super() already holds SB_FREEZE_FS, but
    btrfs_freeze() will call btrfs_commit_transaction() again, if
    btrfs_commit_transaction() finds that it has delayed iputs to handle,
    it'll start_transaction(), which will try to get SB_FREEZE_FS lock
    again, then deadlock occurs.
    
    The root cause is that in btrfs, sync_filesystem(sb) does not make
    sure all metadata is updated. There still maybe some codes adding
    delayed iputs, see below sample race window:
    
             CPU1                                  |         CPU2
    |-> freeze_super()                             |
        |-> sync_filesystem(sb);                   |
        |                                          |-> cleaner_kthread()
        |                                          |   |-> btrfs_delete_unused_bgs()
        |                                          |       |-> btrfs_remove_chunk()
        |                                          |           |-> btrfs_remove_block_group()
        |                                          |               |-> btrfs_add_delayed_iput()
        |                                          |
        |-> sb->s_writers.frozen = SB_FREEZE_FS;   |
        |-> sb_wait_write(sb, SB_FREEZE_FS);       |
        |   acquire SB_FREEZE_FS lock.             |
        |                                          |
        |-> btrfs_freeze()                         |
            |-> btrfs_commit_transaction()         |
                |-> btrfs_run_delayed_iputs()      |
                |   will handle delayed iputs,     |
                |   that means start_transaction() |
                |   will be called, which will try |
                |   to get SB_FREEZE_FS lock.      |
    
    To fix this issue, introduce a "int fs_frozen" to record internally whether
    fs has been frozen. If fs has been frozen, we can not handle delayed iputs.
    
    Signed-off-by: Wang Xiaoguang <wangxg.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ add comment to btrfs_freeze ]
    Signed-off-by: David Sterba <dsterba@suse.com>
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7857f64e1cae..17062223fac3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2631,6 +2631,7 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->qgroup_op_seq, 0);
 	atomic_set(&fs_info->reada_works_cnt, 0);
 	atomic64_set(&fs_info->tree_mod_seq, 0);
+	fs_info->fs_frozen = 0;
 	fs_info->sb = sb;
 	fs_info->max_inline = BTRFS_DEFAULT_MAX_INLINE;
 	fs_info->metadata_ratio = 0;

commit d06f23d6a947c9abae41dc46be69a56baf36f436
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Aug 8 22:08:06 2016 -0400

    btrfs: waiting on qgroup rescan should not always be interruptible
    
    We wait on qgroup rescan completion in three places: file system
    shutdown, the quota disable ioctl, and the rescan wait ioctl.  If the
    user sends a signal while we're waiting, we continue happily along.  This
    is expected behavior for the rescan wait ioctl.  It's racy in the shutdown
    path but mostly works due to other unrelated synchronization points.
    In the quota disable path, it Oopses the kernel pretty much immediately.
    
    Cc: <stable@vger.kernel.org> # v4.4+
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f5b2a7fb4575..7857f64e1cae 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3864,7 +3864,7 @@ void close_ctree(struct btrfs_root *root)
 	smp_mb();
 
 	/* wait for the qgroup rescan worker to stop */
-	btrfs_qgroup_wait_for_completion(fs_info);
+	btrfs_qgroup_wait_for_completion(fs_info, false);
 
 	/* wait for the uuid_scan task to finish */
 	down(&fs_info->uuid_tree_rescan_sem);

commit d2c609b834d62f1e91f1635a27dca29f7806d3d6
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Aug 15 12:10:33 2016 -0400

    btrfs: properly track when rescan worker is running
    
    The qgroup_flags field is overloaded such that it reflects the on-disk
    status of qgroups and the runtime state.  The BTRFS_QGROUP_STATUS_FLAG_RESCAN
    flag is used to indicate that a rescan operation is in progress, but if
    the file system is unmounted while a rescan is running, the rescan
    operation is paused.  If the file system is then mounted read-only,
    the flag will still be present but the rescan operation will not have
    been resumed.  When we go to umount, btrfs_qgroup_wait_for_completion
    will see the flag and interpret it to mean that the rescan worker is
    still running and will wait for a completion that will never come.
    
    This patch uses a separate flag to indicate when the worker is
    running.  The locking and state surrounding the qgroup rescan worker
    needs a lot of attention beyond this patch but this is enough to
    avoid a hung umount.
    
    Cc: <stable@vger.kernel.org> # v4.4+
    Signed-off-by; Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4a34c9fcc1a7..f5b2a7fb4575 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2304,6 +2304,7 @@ static void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)
 	fs_info->quota_enabled = 0;
 	fs_info->pending_quota_state = 0;
 	fs_info->qgroup_ulist = NULL;
+	fs_info->qgroup_rescan_running = false;
 	mutex_init(&fs_info->qgroup_rescan_lock);
 }
 

commit 1c1ea4f781db9f754842b9c31d1eff400d17cddc
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Tue Jul 19 15:36:05 2016 -0700

    Btrfs: fix memory leak of reloc_root
    
    When some critical errors occur and FS would be flipped into RO,
    if we have an on-going balance, we can end up with a memory leak
    of root->reloc_root since btrfs_drop_snapshots() bails out
    without freeing reloc_root at the very early start.
    
    However, we're not able to free reloc_root in btrfs_drop_snapshots()
    because its caller, merge_reloc_roots(), still needs to access it to
    cleanup reloc_root's rbtree.
    
    This makes us free reloc_root when we're going to free fs/file roots.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ff2362dca91a..4a34c9fcc1a7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3744,8 +3744,15 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 	if (btrfs_root_refs(&root->root_item) == 0)
 		synchronize_srcu(&fs_info->subvol_srcu);
 
-	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
+	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state)) {
 		btrfs_free_log(NULL, root);
+		if (root->reloc_root) {
+			free_extent_buffer(root->reloc_root->node);
+			free_extent_buffer(root->reloc_root->commit_root);
+			btrfs_put_fs_root(root->reloc_root);
+			root->reloc_root = NULL;
+		}
+	}
 
 	if (root->free_ino_pinned)
 		__btrfs_remove_free_space_cache(root->free_ino_pinned);

commit 1eff9d322a444245c67515edb52bc0eb68374aa8
Author: Jens Axboe <axboe@fb.com>
Date:   Fri Aug 5 15:35:16 2016 -0600

    block: rename bio bi_rw to bi_opf
    
    Since commit 63a4cc24867d, bio->bi_rw contains flags in the lower
    portion and the op code in the higher portions. This means that
    old code that relies on manually setting bi_rw is most likely
    going to be broken. Instead of letting that brokeness linger,
    rename the member, to force old and out-of-tree code to break
    at compile time instead of at runtime.
    
    No intended functional changes in this commit.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 87dad552e39a..59febfb8d04a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -870,7 +870,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 
 	atomic_inc(&fs_info->nr_async_submits);
 
-	if (bio->bi_rw & REQ_SYNC)
+	if (bio->bi_opf & REQ_SYNC)
 		btrfs_set_work_high_priority(&async->work);
 
 	btrfs_queue_work(fs_info->workers, &async->work);

commit d58b0d980f0b1c27204da0e05537b606da45a07f
Merge: 3a303258ef40 42049bf60db4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 4 19:56:16 2016 -0400

    Merge branch 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull more btrfs updates from Chris Mason:
     "This is part two of my btrfs pull, which is some cleanups and a batch
      of fixes.
    
      Most of the code here is from Jeff Mahoney, making the pointers we
      pass around internally more consistent and less confusing overall.  I
      noticed a small problem right before I sent this out yesterday, so I
      fixed it up and re-tested overnight"
    
    * 'for-linus-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (40 commits)
      Btrfs: fix __MAX_CSUM_ITEMS
      btrfs: btrfs_abort_transaction, drop root parameter
      btrfs: add btrfs_trans_handle->fs_info pointer
      btrfs: btrfs_relocate_chunk pass extent_root to btrfs_end_transaction
      btrfs: convert nodesize macros to static inlines
      btrfs: introduce BTRFS_MAX_ITEM_SIZE
      btrfs: cleanup, remove prototype for btrfs_find_root_ref
      btrfs: copy_to_sk drop unused root parameter
      btrfs: simpilify btrfs_subvol_inherit_props
      btrfs: tests, use BTRFS_FS_STATE_DUMMY_FS_INFO instead of dummy root
      btrfs: tests, require fs_info for root
      btrfs: tests, move initialization into tests/
      btrfs: btrfs_test_opt and friends should take a btrfs_fs_info
      btrfs: prefix fsid to all trace events
      btrfs: plumb fs_info into btrfs_work
      btrfs: remove obsolete part of comment in statfs
      btrfs: hide test-only member under ifdef
      btrfs: Ratelimit "no csum found" info message
      btrfs: Add ratelimit to btrfs printing
      Btrfs: fix unexpected balance crash due to BUG_ON
      ...

commit d05d7f40791ccbb6e543cc5dd6a6aa08fc71d635
Merge: 75a442efb1ca 17007f3994cd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 26 15:03:07 2016 -0700

    Merge branch 'for-4.8/core' of git://git.kernel.dk/linux-block
    
    Pull core block updates from Jens Axboe:
    
       - the big change is the cleanup from Mike Christie, cleaning up our
         uses of command types and modified flags.  This is what will throw
         some merge conflicts
    
       - regression fix for the above for btrfs, from Vincent
    
       - following up to the above, better packing of struct request from
         Christoph
    
       - a 2038 fix for blktrace from Arnd
    
       - a few trivial/spelling fixes from Bart Van Assche
    
       - a front merge check fix from Damien, which could cause issues on
         SMR drives
    
       - Atari partition fix from Gabriel
    
       - convert cfq to highres timers, since jiffies isn't granular enough
         for some devices these days.  From Jan and Jeff
    
       - CFQ priority boost fix idle classes, from me
    
       - cleanup series from Ming, improving our bio/bvec iteration
    
       - a direct issue fix for blk-mq from Omar
    
       - fix for plug merging not involving the IO scheduler, like we do for
         other types of merges.  From Tahsin
    
       - expose DAX type internally and through sysfs.  From Toshi and Yigal
    
    * 'for-4.8/core' of git://git.kernel.dk/linux-block: (76 commits)
      block: Fix front merge check
      block: do not merge requests without consulting with io scheduler
      block: Fix spelling in a source code comment
      block: expose QUEUE_FLAG_DAX in sysfs
      block: add QUEUE_FLAG_DAX for devices to advertise their DAX support
      Btrfs: fix comparison in __btrfs_map_block()
      block: atari: Return early for unsupported sector size
      Doc: block: Fix a typo in queue-sysfs.txt
      cfq-iosched: Charge at least 1 jiffie instead of 1 ns
      cfq-iosched: Fix regression in bonnie++ rewrite performance
      cfq-iosched: Convert slice_resid from u64 to s64
      block: Convert fifo_time from ulong to u64
      blktrace: avoid using timespec
      block/blk-cgroup.c: Declare local symbols static
      block/bio-integrity.c: Add #include "blk.h"
      block/partition-generic.c: Remove a set-but-not-used variable
      block: bio: kill BIO_MAX_SIZE
      cfq-iosched: temporarily boost queue priority for idle classes
      block: drbd: avoid to use BIO_MAX_SIZE
      block: bio: remove BIO_MAX_SECTORS
      ...

commit f5ee5c9ac56cd328fcc915582f81226affebd81c
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jun 21 09:52:41 2016 -0400

    btrfs: tests, use BTRFS_FS_STATE_DUMMY_FS_INFO instead of dummy root
    
    Now that we have a dummy fs_info associated with each test that
    uses a root, we don't need the DUMMY_ROOT bit anymore.  This lets
    us make choices without needing an actual root like in e.g.
    btrfs_find_create_tree_block.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8e838b1cc806..ff2362dca91a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1146,7 +1146,7 @@ struct extent_buffer *btrfs_find_tree_block(struct btrfs_fs_info *fs_info,
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 bytenr)
 {
-	if (btrfs_test_is_dummy_root(root))
+	if (btrfs_is_testing(root->fs_info))
 		return alloc_test_extent_buffer(root->fs_info, bytenr,
 				root->nodesize);
 	return alloc_extent_buffer(root->fs_info, bytenr);
@@ -1330,7 +1330,6 @@ struct btrfs_root *btrfs_alloc_dummy_root(struct btrfs_fs_info *fs_info,
 	/* We don't use the stripesize in selftest, set it as sectorsize */
 	__setup_root(nodesize, sectorsize, sectorsize, root, fs_info,
 			BTRFS_ROOT_TREE_OBJECTID);
-	set_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state);
 	root->alloc_bytenr = 0;
 
 	return root;

commit 7c0260ee098db7a05fd68812b2e21ce2e19dfcf0
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Jun 20 14:14:09 2016 -0400

    btrfs: tests, require fs_info for root
    
    This allows the upcoming patchset to push nodesize and sectorsize into
    fs_info.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 802a3113854f..8e838b1cc806 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1233,6 +1233,7 @@ static void __setup_root(u32 nodesize, u32 sectorsize, u32 stripesize,
 			 struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 			 u64 objectid)
 {
+	bool dummy = test_bit(BTRFS_FS_STATE_DUMMY_FS_INFO, &fs_info->fs_state);
 	root->node = NULL;
 	root->commit_root = NULL;
 	root->sectorsize = sectorsize;
@@ -1287,14 +1288,14 @@ static void __setup_root(u32 nodesize, u32 sectorsize, u32 stripesize,
 	root->log_transid = 0;
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;
-	if (fs_info)
+	if (!dummy)
 		extent_io_tree_init(&root->dirty_log_pages,
 				     fs_info->btree_inode->i_mapping);
 
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
-	if (fs_info)
+	if (!dummy)
 		root->defrag_trans_start = fs_info->generation;
 	else
 		root->defrag_trans_start = 0;
@@ -1315,15 +1316,19 @@ static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info,
 
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 /* Should only be used by the testing infrastructure */
-struct btrfs_root *btrfs_alloc_dummy_root(u32 sectorsize, u32 nodesize)
+struct btrfs_root *btrfs_alloc_dummy_root(struct btrfs_fs_info *fs_info,
+					  u32 sectorsize, u32 nodesize)
 {
 	struct btrfs_root *root;
 
-	root = btrfs_alloc_root(NULL, GFP_KERNEL);
+	if (!fs_info)
+		return ERR_PTR(-EINVAL);
+
+	root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 	/* We don't use the stripesize in selftest, set it as sectorsize */
-	__setup_root(nodesize, sectorsize, sectorsize, root, NULL,
+	__setup_root(nodesize, sectorsize, sectorsize, root, fs_info,
 			BTRFS_ROOT_TREE_OBJECTID);
 	set_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state);
 	root->alloc_bytenr = 0;

commit 3cdde2240d4533ff71fbb8dc9c32d5d57d3cdeed
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Jun 9 21:38:35 2016 -0400

    btrfs: btrfs_test_opt and friends should take a btrfs_fs_info
    
    btrfs_test_opt and friends only use the root pointer to access
    the fs_info.  Let's pass the fs_info directly in preparation to
    eliminate similar patterns all over btrfs.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cb6d13c39bee..802a3113854f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3019,8 +3019,8 @@ int open_ctree(struct super_block *sb,
 	if (IS_ERR(fs_info->transaction_kthread))
 		goto fail_cleaner;
 
-	if (!btrfs_test_opt(tree_root, SSD) &&
-	    !btrfs_test_opt(tree_root, NOSSD) &&
+	if (!btrfs_test_opt(tree_root->fs_info, SSD) &&
+	    !btrfs_test_opt(tree_root->fs_info, NOSSD) &&
 	    !fs_info->fs_devices->rotating) {
 		btrfs_info(fs_info, "detected SSD devices, enabling SSD mode");
 		btrfs_set_opt(fs_info->mount_opt, SSD);
@@ -3033,9 +3033,9 @@ int open_ctree(struct super_block *sb,
 	btrfs_apply_pending_changes(fs_info);
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
-	if (btrfs_test_opt(tree_root, CHECK_INTEGRITY)) {
+	if (btrfs_test_opt(tree_root->fs_info, CHECK_INTEGRITY)) {
 		ret = btrfsic_mount(tree_root, fs_devices,
-				    btrfs_test_opt(tree_root,
+				    btrfs_test_opt(tree_root->fs_info,
 					CHECK_INTEGRITY_INCLUDING_EXTENT_DATA) ?
 				    1 : 0,
 				    fs_info->check_integrity_print_mask);
@@ -3051,7 +3051,7 @@ int open_ctree(struct super_block *sb,
 
 	/* do not make disk changes in broken FS or nologreplay is given */
 	if (btrfs_super_log_root(disk_super) != 0 &&
-	    !btrfs_test_opt(tree_root, NOLOGREPLAY)) {
+	    !btrfs_test_opt(tree_root->fs_info, NOLOGREPLAY)) {
 		ret = btrfs_replay_log(fs_info, fs_devices);
 		if (ret) {
 			err = ret;
@@ -3092,7 +3092,7 @@ int open_ctree(struct super_block *sb,
 	if (sb->s_flags & MS_RDONLY)
 		return 0;
 
-	if (btrfs_test_opt(tree_root, FREE_SPACE_TREE) &&
+	if (btrfs_test_opt(tree_root->fs_info, FREE_SPACE_TREE) &&
 	    !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
 		btrfs_info(fs_info, "creating free space tree");
 		ret = btrfs_create_free_space_tree(fs_info);
@@ -3129,7 +3129,7 @@ int open_ctree(struct super_block *sb,
 
 	btrfs_qgroup_rescan_resume(fs_info);
 
-	if (btrfs_test_opt(tree_root, CLEAR_CACHE) &&
+	if (btrfs_test_opt(tree_root->fs_info, CLEAR_CACHE) &&
 	    btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
 		btrfs_info(fs_info, "clearing free space tree");
 		ret = btrfs_clear_free_space_tree(fs_info);
@@ -3150,7 +3150,7 @@ int open_ctree(struct super_block *sb,
 			close_ctree(tree_root);
 			return ret;
 		}
-	} else if (btrfs_test_opt(tree_root, RESCAN_UUID_TREE) ||
+	} else if (btrfs_test_opt(tree_root->fs_info, RESCAN_UUID_TREE) ||
 		   fs_info->generation !=
 				btrfs_super_uuid_tree_generation(disk_super)) {
 		btrfs_info(fs_info, "checking UUID tree");
@@ -3227,7 +3227,7 @@ int open_ctree(struct super_block *sb,
 	return err;
 
 recovery_tree_root:
-	if (!btrfs_test_opt(tree_root, USEBACKUPROOT))
+	if (!btrfs_test_opt(tree_root->fs_info, USEBACKUPROOT))
 		goto fail_tree_roots;
 
 	free_root_pointers(fs_info, 0);
@@ -3642,7 +3642,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	int total_errors = 0;
 	u64 flags;
 
-	do_barriers = !btrfs_test_opt(root, NOBARRIER);
+	do_barriers = !btrfs_test_opt(root->fs_info, NOBARRIER);
 	backup_super_roots(root->fs_info);
 
 	sb = root->fs_info->super_for_commit;
@@ -3926,7 +3926,7 @@ void close_ctree(struct btrfs_root *root)
 	iput(fs_info->btree_inode);
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
-	if (btrfs_test_opt(root, CHECK_INTEGRITY))
+	if (btrfs_test_opt(root->fs_info, CHECK_INTEGRITY))
 		btrfsic_unmount(root, fs_info->fs_devices);
 #endif
 

commit cb001095ca705dcd95f57fe98867e38a4889916d
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Jun 9 16:22:11 2016 -0400

    btrfs: plumb fs_info into btrfs_work
    
    In order to provide an fsid for trace events, we'll need a btrfs_fs_info
    pointer.  The most lightweight way to do that for btrfs_work structures
    is to associate it with the __btrfs_workqueue structure.  Each queued
    btrfs_work structure has a workqueue associated with it, so that's
    a natural fit.  It's a privately defined structures, so we add accessors
    to retrieve the fs_info pointer.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 49565626321e..cb6d13c39bee 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2310,17 +2310,19 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 	unsigned int flags = WQ_MEM_RECLAIM | WQ_FREEZABLE | WQ_UNBOUND;
 
 	fs_info->workers =
-		btrfs_alloc_workqueue("worker", flags | WQ_HIGHPRI,
-				      max_active, 16);
+		btrfs_alloc_workqueue(fs_info, "worker",
+				      flags | WQ_HIGHPRI, max_active, 16);
 
 	fs_info->delalloc_workers =
-		btrfs_alloc_workqueue("delalloc", flags, max_active, 2);
+		btrfs_alloc_workqueue(fs_info, "delalloc",
+				      flags, max_active, 2);
 
 	fs_info->flush_workers =
-		btrfs_alloc_workqueue("flush_delalloc", flags, max_active, 0);
+		btrfs_alloc_workqueue(fs_info, "flush_delalloc",
+				      flags, max_active, 0);
 
 	fs_info->caching_workers =
-		btrfs_alloc_workqueue("cache", flags, max_active, 0);
+		btrfs_alloc_workqueue(fs_info, "cache", flags, max_active, 0);
 
 	/*
 	 * a higher idle thresh on the submit workers makes it much more
@@ -2328,41 +2330,48 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 	 * devices
 	 */
 	fs_info->submit_workers =
-		btrfs_alloc_workqueue("submit", flags,
+		btrfs_alloc_workqueue(fs_info, "submit", flags,
 				      min_t(u64, fs_devices->num_devices,
 					    max_active), 64);
 
 	fs_info->fixup_workers =
-		btrfs_alloc_workqueue("fixup", flags, 1, 0);
+		btrfs_alloc_workqueue(fs_info, "fixup", flags, 1, 0);
 
 	/*
 	 * endios are largely parallel and should have a very
 	 * low idle thresh
 	 */
 	fs_info->endio_workers =
-		btrfs_alloc_workqueue("endio", flags, max_active, 4);
+		btrfs_alloc_workqueue(fs_info, "endio", flags, max_active, 4);
 	fs_info->endio_meta_workers =
-		btrfs_alloc_workqueue("endio-meta", flags, max_active, 4);
+		btrfs_alloc_workqueue(fs_info, "endio-meta", flags,
+				      max_active, 4);
 	fs_info->endio_meta_write_workers =
-		btrfs_alloc_workqueue("endio-meta-write", flags, max_active, 2);
+		btrfs_alloc_workqueue(fs_info, "endio-meta-write", flags,
+				      max_active, 2);
 	fs_info->endio_raid56_workers =
-		btrfs_alloc_workqueue("endio-raid56", flags, max_active, 4);
+		btrfs_alloc_workqueue(fs_info, "endio-raid56", flags,
+				      max_active, 4);
 	fs_info->endio_repair_workers =
-		btrfs_alloc_workqueue("endio-repair", flags, 1, 0);
+		btrfs_alloc_workqueue(fs_info, "endio-repair", flags, 1, 0);
 	fs_info->rmw_workers =
-		btrfs_alloc_workqueue("rmw", flags, max_active, 2);
+		btrfs_alloc_workqueue(fs_info, "rmw", flags, max_active, 2);
 	fs_info->endio_write_workers =
-		btrfs_alloc_workqueue("endio-write", flags, max_active, 2);
+		btrfs_alloc_workqueue(fs_info, "endio-write", flags,
+				      max_active, 2);
 	fs_info->endio_freespace_worker =
-		btrfs_alloc_workqueue("freespace-write", flags, max_active, 0);
+		btrfs_alloc_workqueue(fs_info, "freespace-write", flags,
+				      max_active, 0);
 	fs_info->delayed_workers =
-		btrfs_alloc_workqueue("delayed-meta", flags, max_active, 0);
+		btrfs_alloc_workqueue(fs_info, "delayed-meta", flags,
+				      max_active, 0);
 	fs_info->readahead_workers =
-		btrfs_alloc_workqueue("readahead", flags, max_active, 2);
+		btrfs_alloc_workqueue(fs_info, "readahead", flags,
+				      max_active, 2);
 	fs_info->qgroup_rescan_workers =
-		btrfs_alloc_workqueue("qgroup-rescan", flags, 1, 0);
+		btrfs_alloc_workqueue(fs_info, "qgroup-rescan", flags, 1, 0);
 	fs_info->extent_workers =
-		btrfs_alloc_workqueue("extent-refs", flags,
+		btrfs_alloc_workqueue(fs_info, "extent-refs", flags,
 				      min_t(u64, fs_devices->num_devices,
 					    max_active), 8);
 

commit fba4b697710eb2a4bee456b9d39e9239c66f8bee
Author: Nikolay Borisov <n.borisov.lkml@gmail.com>
Date:   Thu Jun 23 21:17:08 2016 +0300

    btrfs: Fix slab accounting flags
    
    BTRFS is using a variety of slab caches to satisfy internal needs.
    Those slab caches are always allocated with the SLAB_RECLAIM_ACCOUNT,
    meaning allocations from the caches are going to be accounted as
    SReclaimable. At the same time btrfs is not registering any shrinkers
    whatsoever, thus preventing memory from the slabs to be shrunk. This
    means those caches are not in fact reclaimable.
    
    To fix this remove the SLAB_RECLAIM_ACCOUNT on all caches apart from the
    inode cache, since this one is being freed by the generic VFS super_block
    shrinker. Also set the transaction related caches as SLAB_TEMPORARY,
    to better document the lifetime of the objects (it just translates
    to SLAB_RECLAIM_ACCOUNT).
    
    Signed-off-by: Nikolay Borisov <n.borisov.lkml@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6c88c63f3be7..49565626321e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -101,7 +101,7 @@ int __init btrfs_end_io_wq_init(void)
 	btrfs_end_io_wq_cache = kmem_cache_create("btrfs_end_io_wq",
 					sizeof(struct btrfs_end_io_wq),
 					0,
-					SLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD,
+					SLAB_MEM_SPREAD,
 					NULL);
 	if (!btrfs_end_io_wq_cache)
 		return -ENOMEM;

commit 876d2cf141b42f9be70a383502a324b64b23f33a
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Tue Jun 28 13:44:38 2016 -0700

    Btrfs: fix double free of fs root
    
    I got this warning while mounting a btrfs image,
    
    [ 3020.509606] ------------[ cut here ]------------
    [ 3020.510107] WARNING: CPU: 3 PID: 5581 at lib/idr.c:1051 ida_remove+0xca/0x190
    [ 3020.510853] ida_remove called for id=42 which is not allocated.
    [ 3020.511466] Modules linked in:
    [ 3020.511802] CPU: 3 PID: 5581 Comm: mount Not tainted 4.7.0-rc5+ #274
    [ 3020.512438] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.8.2-20150714_191134- 04/01/2014
    [ 3020.513385]  0000000000000286 0000000021295d86 ffff88006c66b8f0 ffffffff8182ba5a
    [ 3020.514153]  0000000000000000 0000000000000009 ffff88006c66b930 ffffffff810e0ed7
    [ 3020.514928]  0000041b00000000 ffffffff8289a8c0 ffff88007f437880 0000000000000000
    [ 3020.515717] Call Trace:
    [ 3020.515965]  [<ffffffff8182ba5a>] dump_stack+0xc9/0x13f
    [ 3020.516487]  [<ffffffff810e0ed7>] __warn+0x147/0x160
    [ 3020.517005]  [<ffffffff810e0f4f>] warn_slowpath_fmt+0x5f/0x80
    [ 3020.517572]  [<ffffffff8182e6ca>] ida_remove+0xca/0x190
    [ 3020.518075]  [<ffffffff813a2bcc>] free_anon_bdev+0x2c/0x60
    [ 3020.518609]  [<ffffffff81657a9f>] free_fs_root+0x13f/0x160
    [ 3020.519138]  [<ffffffff8165c679>] btrfs_get_fs_root+0x379/0x3d0
    [ 3020.519710]  [<ffffffff81e6e975>] ? __mutex_unlock_slowpath+0x155/0x2c0
    [ 3020.520366]  [<ffffffff816615b1>] open_ctree+0x2e91/0x3200
    [ 3020.520965]  [<ffffffff8161ede2>] btrfs_mount+0x1322/0x15b0
    [ 3020.521536]  [<ffffffff81e60e74>] ? kmemleak_alloc_percpu+0x44/0x170
    [ 3020.522167]  [<ffffffff8115f5e1>] ? lockdep_init_map+0x61/0x210
    [ 3020.522780]  [<ffffffff813a4f59>] mount_fs+0x49/0x2c0
    [ 3020.523305]  [<ffffffff813d840c>] vfs_kern_mount+0xac/0x1b0
    [ 3020.523872]  [<ffffffff8161dee1>] btrfs_mount+0x421/0x15b0
    [ 3020.524402]  [<ffffffff81e60e74>] ? kmemleak_alloc_percpu+0x44/0x170
    [ 3020.525045]  [<ffffffff8115f5e1>] ? lockdep_init_map+0x61/0x210
    [ 3020.525657]  [<ffffffff8115f5e1>] ? lockdep_init_map+0x61/0x210
    [ 3020.526289]  [<ffffffff813a4f59>] mount_fs+0x49/0x2c0
    [ 3020.526803]  [<ffffffff813d840c>] vfs_kern_mount+0xac/0x1b0
    [ 3020.527365]  [<ffffffff813dc27a>] do_mount+0x41a/0x1770
    [ 3020.527899]  [<ffffffff812e800d>] ? strndup_user+0x6d/0xc0
    [ 3020.528447]  [<ffffffff812e7f68>] ? memdup_user+0x78/0xb0
    [ 3020.528987]  [<ffffffff813ddad0>] SyS_mount+0x150/0x160
    [ 3020.529493]  [<ffffffff81e72b7c>] entry_SYSCALL_64_fastpath+0x1f/0xbd
    
    It turns out that we free fs root twice, btrfs_init_fs_root() calls
    free_anon_bdev(root->anon_dev) and later then btrfs_get_fs_root() cals
    free_fs_root which does another free_anon_bdev() and it ends up with the
    above warning.
    
    Instead of reset root->anon_dev to 0 after free_anon_bdev(), we can let
    btrfs_init_fs_root() return directly since its callers have already done
    the free job by calling free_fs_root().
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 60ce1190307b..6c88c63f3be7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1600,14 +1600,14 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 
 	ret = get_anon_bdev(&root->anon_dev);
 	if (ret)
-		goto free_writers;
+		goto fail;
 
 	mutex_lock(&root->objectid_mutex);
 	ret = btrfs_find_highest_objectid(root,
 					&root->highest_objectid);
 	if (ret) {
 		mutex_unlock(&root->objectid_mutex);
-		goto free_root_dev;
+		goto fail;
 	}
 
 	ASSERT(root->highest_objectid <= BTRFS_LAST_FREE_OBJECTID);
@@ -1615,14 +1615,8 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 	mutex_unlock(&root->objectid_mutex);
 
 	return 0;
-
-free_root_dev:
-	free_anon_bdev(root->anon_dev);
-free_writers:
-	btrfs_free_subvolume_writers(root->subv_writers);
 fail:
-	kfree(root->free_ino_ctl);
-	kfree(root->free_ino_pinned);
+	/* the caller is responsible to call free_fs_root */
 	return ret;
 }
 

commit b7f67055d2df9b8f68f02e49d256ee3973999bd2
Author: Chandan Rajendra <chandan@linux.vnet.ibm.com>
Date:   Thu Jun 23 15:16:44 2016 +0530

    Btrfs: Force stripesize to the value of sectorsize
    
    Btrfs code currently assumes stripesize to be same as
    sectorsize. However Btrfs-progs (until commit
    df05c7ed455f519e6e15e46196392e4757257305) has been setting
    btrfs_super_block->stripesize to a value of 4096.
    
    This commit makes sure that the value of btrfs_super_block->stripesize
    is a power of 2. Later, it unconditionally sets btrfs_root->stripesize
    to sectorsize.
    
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 54cca7a1572b..60ce1190307b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2806,7 +2806,7 @@ int open_ctree(struct super_block *sb,
 
 	nodesize = btrfs_super_nodesize(disk_super);
 	sectorsize = btrfs_super_sectorsize(disk_super);
-	stripesize = btrfs_super_stripesize(disk_super);
+	stripesize = sectorsize;
 	fs_info->dirty_metadata_batch = nodesize * (1 + ilog2(nr_cpu_ids));
 	fs_info->delalloc_batch = sectorsize * 512 * (1 + ilog2(nr_cpu_ids));
 
@@ -4133,9 +4133,7 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 		       btrfs_super_bytes_used(sb));
 		ret = -EINVAL;
 	}
-	if (!is_power_of_2(btrfs_super_stripesize(sb)) ||
-		((btrfs_super_stripesize(sb) != sectorsize) &&
-			(btrfs_super_stripesize(sb) != 4096))) {
+	if (!is_power_of_2(btrfs_super_stripesize(sb))) {
 		btrfs_err(fs_info, "invalid stripesize %u",
 		       btrfs_super_stripesize(sb));
 		ret = -EINVAL;

commit dd5c93111dc9d26e038ac437f7a403d617e82c62
Author: Chandan Rajendra <chandan@linux.vnet.ibm.com>
Date:   Thu Jun 16 22:07:58 2016 +0530

    Btrfs: btrfs_check_super_valid: Allow 4096 as stripesize
    
    Older btrfs-progs/mkfs.btrfs sets 4096 as the stripesize. Hence
    restricting stripesize to be equal to sectorsize would cause super block
    validation to return an error on architectures where PAGE_SIZE is not
    equal to 4096.
    
    Hence as a workaround, this commit allows stripesize to be set to 4096
    bytes.
    
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 789f5f233940..54cca7a1572b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4134,7 +4134,8 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 		ret = -EINVAL;
 	}
 	if (!is_power_of_2(btrfs_super_stripesize(sb)) ||
-	    btrfs_super_stripesize(sb) != sectorsize) {
+		((btrfs_super_stripesize(sb) != sectorsize) &&
+			(btrfs_super_stripesize(sb) != 4096))) {
 		btrfs_err(fs_info, "invalid stripesize %u",
 		       btrfs_super_stripesize(sb));
 		ret = -EINVAL;

commit 90c711ab380d633bf85249bd5d819edb601feda7
Author: Zygo Blaxell <ce3g8jdj@umail.furryterror.org>
Date:   Sun Jun 12 23:39:58 2016 -0400

    btrfs: avoid blocking open_ctree from cleaner_kthread
    
    This fixes a problem introduced in commit 2f3165ecf103599f82bf0ea254039db335fb5005
    "btrfs: don't force mounts to wait for cleaner_kthread to delete one or more subvolumes".
    
    open_ctree eventually calls btrfs_replay_log which in turn calls
    btrfs_commit_super which tries to lock the cleaner_mutex, causing a
    recursive mutex deadlock during mount.
    
    Instead of playing whack-a-mole trying to keep up with all the
    functions that may want to lock cleaner_mutex, put all the cleaner_mutex
    lockers back where they were, and attack the problem more directly:
    keep cleaner_kthread asleep until the filesystem is mounted.
    
    When filesystems are mounted read-only and later remounted read-write,
    open_ctree did not set fs_info->open and neither does anything else.
    Set this flag in btrfs_remount so that neither btrfs_delete_unused_bgs
    nor cleaner_kthread get confused by the common case of "/" filesystem
    read-only mount followed by read-write remount.
    
    Signed-off-by: Zygo Blaxell <ce3g8jdj@umail.furryterror.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7b5d5e8efde6..789f5f233940 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1806,6 +1806,13 @@ static int cleaner_kthread(void *arg)
 		if (btrfs_need_cleaner_sleep(root))
 			goto sleep;
 
+		/*
+		 * Do not do anything if we might cause open_ctree() to block
+		 * before we have finished mounting the filesystem.
+		 */
+		if (!root->fs_info->open)
+			goto sleep;
+
 		if (!mutex_trylock(&root->fs_info->cleaner_mutex))
 			goto sleep;
 
@@ -2520,7 +2527,6 @@ int open_ctree(struct super_block *sb,
 	int num_backups_tried = 0;
 	int backup_index = 0;
 	int max_active;
-	bool cleaner_mutex_locked = false;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
@@ -2999,13 +3005,6 @@ int open_ctree(struct super_block *sb,
 		goto fail_sysfs;
 	}
 
-	/*
-	 * Hold the cleaner_mutex thread here so that we don't block
-	 * for a long time on btrfs_recover_relocation.  cleaner_kthread
-	 * will wait for us to finish mounting the filesystem.
-	 */
-	mutex_lock(&fs_info->cleaner_mutex);
-	cleaner_mutex_locked = true;
 	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
 					       "btrfs-cleaner");
 	if (IS_ERR(fs_info->cleaner_kthread))
@@ -3065,8 +3064,10 @@ int open_ctree(struct super_block *sb,
 		ret = btrfs_cleanup_fs_roots(fs_info);
 		if (ret)
 			goto fail_qgroup;
-		/* We locked cleaner_mutex before creating cleaner_kthread. */
+
+		mutex_lock(&fs_info->cleaner_mutex);
 		ret = btrfs_recover_relocation(tree_root);
+		mutex_unlock(&fs_info->cleaner_mutex);
 		if (ret < 0) {
 			btrfs_warn(fs_info, "failed to recover relocation: %d",
 					ret);
@@ -3074,8 +3075,6 @@ int open_ctree(struct super_block *sb,
 			goto fail_qgroup;
 		}
 	}
-	mutex_unlock(&fs_info->cleaner_mutex);
-	cleaner_mutex_locked = false;
 
 	location.objectid = BTRFS_FS_TREE_OBJECTID;
 	location.type = BTRFS_ROOT_ITEM_KEY;
@@ -3189,10 +3188,6 @@ int open_ctree(struct super_block *sb,
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
 
 fail_sysfs:
-	if (cleaner_mutex_locked) {
-		mutex_unlock(&fs_info->cleaner_mutex);
-		cleaner_mutex_locked = false;
-	}
 	btrfs_sysfs_remove_mounted(fs_info);
 
 fail_fsdev_sysfs:

commit c871b0f2fd27e7f9097d507f47de5270f88003b9
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Jun 6 12:01:23 2016 -0700

    Btrfs: check if extent buffer is aligned to sectorsize
    
    Thanks to fuzz testing, we can pass an invalid bytenr to extent buffer
    via alloc_extent_buffer().  An unaligned eb can have more pages than it
    should have, which ends up extent buffer's leak or some corrupted content
    in extent buffer.
    
    This adds a warning to let us quickly know what was happening.
    
    Now that alloc_extent_buffer() no more returns NULL, this changes its
    caller and callers of its caller to match with the new error
    handling.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1142127f6e5e..7b5d5e8efde6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1098,7 +1098,7 @@ void readahead_tree_block(struct btrfs_root *root, u64 bytenr)
 	struct inode *btree_inode = root->fs_info->btree_inode;
 
 	buf = btrfs_find_create_tree_block(root, bytenr);
-	if (!buf)
+	if (IS_ERR(buf))
 		return;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
 				 buf, 0, WAIT_NONE, btree_get_extent, 0);
@@ -1114,7 +1114,7 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr,
 	int ret;
 
 	buf = btrfs_find_create_tree_block(root, bytenr);
-	if (!buf)
+	if (IS_ERR(buf))
 		return 0;
 
 	set_bit(EXTENT_BUFFER_READAHEAD, &buf->bflags);
@@ -1172,8 +1172,8 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 	int ret;
 
 	buf = btrfs_find_create_tree_block(root, bytenr);
-	if (!buf)
-		return ERR_PTR(-ENOMEM);
+	if (IS_ERR(buf))
+		return buf;
 
 	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 	if (ret) {

commit 719da39a61173c849f70656ed1a302e4b6deaa5b
Merge: 4c52990080e3 5f9e1059d934
Author: Chris Mason <clm@fb.com>
Date:   Wed Jun 8 14:36:12 2016 -0700

    Merge branch 'misc-fixes-4.7' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.7

commit 81a75f6781deb7a3b5274b4c683e327e5cb5b883
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:54 2016 -0500

    btrfs: use bio fields for op and flags
    
    The bio REQ_OP and bi_rw rq_flag_bits are now always setup, so there is
    no need to pass around the rq_flag_bits bits too. btrfs users should
    should access the bio insead.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 93278c2f6af2..e80ef6eb17e6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -124,7 +124,6 @@ struct async_submit_bio {
 	struct list_head list;
 	extent_submit_bio_hook_t *submit_bio_start;
 	extent_submit_bio_hook_t *submit_bio_done;
-	int rw;
 	int mirror_num;
 	unsigned long bio_flags;
 	/*
@@ -797,7 +796,7 @@ static void run_one_async_start(struct btrfs_work *work)
 	int ret;
 
 	async = container_of(work, struct  async_submit_bio, work);
-	ret = async->submit_bio_start(async->inode, async->rw, async->bio,
+	ret = async->submit_bio_start(async->inode, async->bio,
 				      async->mirror_num, async->bio_flags,
 				      async->bio_offset);
 	if (ret)
@@ -830,9 +829,8 @@ static void run_one_async_done(struct btrfs_work *work)
 		return;
 	}
 
-	async->submit_bio_done(async->inode, async->rw, async->bio,
-			       async->mirror_num, async->bio_flags,
-			       async->bio_offset);
+	async->submit_bio_done(async->inode, async->bio, async->mirror_num,
+			       async->bio_flags, async->bio_offset);
 }
 
 static void run_one_async_free(struct btrfs_work *work)
@@ -844,7 +842,7 @@ static void run_one_async_free(struct btrfs_work *work)
 }
 
 int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
-			int rw, struct bio *bio, int mirror_num,
+			struct bio *bio, int mirror_num,
 			unsigned long bio_flags,
 			u64 bio_offset,
 			extent_submit_bio_hook_t *submit_bio_start,
@@ -857,7 +855,6 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 		return -ENOMEM;
 
 	async->inode = inode;
-	async->rw = rw;
 	async->bio = bio;
 	async->mirror_num = mirror_num;
 	async->submit_bio_start = submit_bio_start;
@@ -903,9 +900,8 @@ static int btree_csum_one_bio(struct bio *bio)
 	return ret;
 }
 
-static int __btree_submit_bio_start(struct inode *inode, int rw,
-				    struct bio *bio, int mirror_num,
-				    unsigned long bio_flags,
+static int __btree_submit_bio_start(struct inode *inode, struct bio *bio,
+				    int mirror_num, unsigned long bio_flags,
 				    u64 bio_offset)
 {
 	/*
@@ -915,7 +911,7 @@ static int __btree_submit_bio_start(struct inode *inode, int rw,
 	return btree_csum_one_bio(bio);
 }
 
-static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
+static int __btree_submit_bio_done(struct inode *inode, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset)
 {
@@ -925,7 +921,7 @@ static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
 	 * when we're called for a write, we're already in the async
 	 * submission context.  Just jump into btrfs_map_bio
 	 */
-	ret = btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num, 1);
+	ret = btrfs_map_bio(BTRFS_I(inode)->root, bio, mirror_num, 1);
 	if (ret) {
 		bio->bi_error = ret;
 		bio_endio(bio);
@@ -944,7 +940,7 @@ static int check_async_write(struct inode *inode, unsigned long bio_flags)
 	return 1;
 }
 
-static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
+static int btree_submit_bio_hook(struct inode *inode, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset)
 {
@@ -960,21 +956,19 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 					  bio, BTRFS_WQ_ENDIO_METADATA);
 		if (ret)
 			goto out_w_error;
-		ret = btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
-				    mirror_num, 0);
+		ret = btrfs_map_bio(BTRFS_I(inode)->root, bio, mirror_num, 0);
 	} else if (!async) {
 		ret = btree_csum_one_bio(bio);
 		if (ret)
 			goto out_w_error;
-		ret = btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
-				    mirror_num, 0);
+		ret = btrfs_map_bio(BTRFS_I(inode)->root, bio, mirror_num, 0);
 	} else {
 		/*
 		 * kthread helpers are used to submit writes so that
 		 * checksumming can happen in parallel across all CPUs
 		 */
 		ret = btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
-					  inode, rw, bio, mirror_num, 0,
+					  inode, bio, mirror_num, 0,
 					  bio_offset,
 					  __btree_submit_bio_start,
 					  __btree_submit_bio_done);

commit 37226b2111b0ef7903ceedb8597e2203d7d6dc09
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:52 2016 -0500

    btrfs: use bio op accessors
    
    This should be the easier cases to convert btrfs to
    bio_set_op_attrs/bio_op.
    They are mostly just cut and replace type of changes.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 11033ce82f8a..93278c2f6af2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -727,7 +727,7 @@ static void end_workqueue_bio(struct bio *bio)
 	fs_info = end_io_wq->info;
 	end_io_wq->error = bio->bi_error;
 
-	if (bio->bi_rw & REQ_WRITE) {
+	if (bio_op(bio) == REQ_OP_WRITE) {
 		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_METADATA) {
 			wq = fs_info->endio_meta_write_workers;
 			func = btrfs_endio_meta_write_helper;
@@ -873,7 +873,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 
 	atomic_inc(&fs_info->nr_async_submits);
 
-	if (rw & REQ_SYNC)
+	if (bio->bi_rw & REQ_SYNC)
 		btrfs_set_work_high_priority(&async->work);
 
 	btrfs_queue_work(fs_info->workers, &async->work);
@@ -951,7 +951,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 	int async = check_async_write(inode, bio_flags);
 	int ret;
 
-	if (!(rw & REQ_WRITE)) {
+	if (bio_op(bio) != REQ_OP_WRITE) {
 		/*
 		 * called for a read, do the setup so that checksum validation
 		 * can happen in the async kernel threads
@@ -3486,7 +3486,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 	bio->bi_end_io = btrfs_end_empty_barrier;
 	bio->bi_bdev = device->bdev;
-	bio->bi_rw = WRITE_FLUSH;
+	bio_set_op_attrs(bio, REQ_OP_WRITE, WRITE_FLUSH);
 	init_completion(&device->flush_wait);
 	bio->bi_private = &device->flush_wait;
 	device->flush_bio = bio;

commit 2a222ca992c35aee1e83af428f3dd26a3f5d5d94
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:43 2016 -0500

    fs: have submit_bh users pass in op and flags separately
    
    This has submit_bh users pass in the operation and flags separately,
    so submit_bh_wbc can setup the bio op and bi_rw flags on the bio that
    is submitted.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3666558a2375..11033ce82f8a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3420,9 +3420,9 @@ static int write_dev_supers(struct btrfs_device *device,
 		 * to go down lazy.
 		 */
 		if (i == 0)
-			ret = btrfsic_submit_bh(WRITE_FUA, bh);
+			ret = btrfsic_submit_bh(REQ_OP_WRITE, WRITE_FUA, bh);
 		else
-			ret = btrfsic_submit_bh(WRITE_SYNC, bh);
+			ret = btrfsic_submit_bh(REQ_OP_WRITE, WRITE_SYNC, bh);
 		if (ret)
 			errors++;
 	}

commit 4e49ea4a3d276365bf7396c9b77b4d1d5923835a
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:41 2016 -0500

    block/fs/drivers: remove rw argument from submit_bio
    
    This has callers of submit_bio/submit_bio_wait set the bio->bi_rw
    instead of passing it in. This makes that use the same as
    generic_make_request and how we set the other bio fields.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    
    Fixed up fs/ext4/crypto.c
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6628fca9f4ed..3666558a2375 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3486,12 +3486,13 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 	bio->bi_end_io = btrfs_end_empty_barrier;
 	bio->bi_bdev = device->bdev;
+	bio->bi_rw = WRITE_FLUSH;
 	init_completion(&device->flush_wait);
 	bio->bi_private = &device->flush_wait;
 	device->flush_bio = bio;
 
 	bio_get(bio);
-	btrfsic_submit_bio(WRITE_FLUSH, bio);
+	btrfsic_submit_bio(bio);
 
 	return 0;
 }

commit ef9f2db365c31433e52b0c5863793273bb632666
Author: Feifei Xu <xufeifei@linux.vnet.ibm.com>
Date:   Wed Jun 1 19:18:28 2016 +0800

    Btrfs: self-tests: Use macros instead of constants and add missing newline
    
    This commit replaces numerical constants with appropriate
    preprocessor macros.
    
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Feifei Xu <xufeifei@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 06ef433552b3..c3764ddb2a46 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1323,7 +1323,8 @@ struct btrfs_root *btrfs_alloc_dummy_root(u32 sectorsize, u32 nodesize)
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 	/* We don't use the stripesize in selftest, set it as sectorsize */
-	__setup_root(nodesize, sectorsize, sectorsize, root, NULL, 1);
+	__setup_root(nodesize, sectorsize, sectorsize, root, NULL,
+			BTRFS_ROOT_TREE_OBJECTID);
 	set_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state);
 	root->alloc_bytenr = 0;
 

commit 99e3ecfcb9f4ca35192d20a5bea158b81f600062
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Jun 3 12:05:14 2016 -0700

    Btrfs: add more validation checks for superblock
    
    This adds validation checks for super_total_bytes, super_bytes_used and
    super_stripesize, super_num_devices.
    
    Reported-by: Vegard Nossum <vegard.nossum@oracle.com>
    Reported-by: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6628fca9f4ed..2bd5f5e975cc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4130,6 +4130,17 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 * Hint to catch really bogus numbers, bitflips or so, more exact checks are
 	 * done later
 	 */
+	if (btrfs_super_bytes_used(sb) < 6 * btrfs_super_nodesize(sb)) {
+		btrfs_err(fs_info, "bytes_used is too small %llu",
+		       btrfs_super_bytes_used(sb));
+		ret = -EINVAL;
+	}
+	if (!is_power_of_2(btrfs_super_stripesize(sb)) ||
+	    btrfs_super_stripesize(sb) != sectorsize) {
+		btrfs_err(fs_info, "invalid stripesize %u",
+		       btrfs_super_stripesize(sb));
+		ret = -EINVAL;
+	}
 	if (btrfs_super_num_devices(sb) > (1UL << 31))
 		printk(KERN_WARNING "BTRFS: suspicious number of devices: %llu\n",
 				btrfs_super_num_devices(sb));

commit b9ef22dedde08ab1b4ccd5f53344984c4dcb89f4
Author: Feifei Xu <xufeifei@linux.vnet.ibm.com>
Date:   Wed Jun 1 19:18:25 2016 +0800

    Btrfs: self-tests: Support non-4k page size
    
    self-tests code assumes 4k as the sectorsize and nodesize. This commit
    fix hardcoded 4K. Enables the self-tests code to be executed on non-4k
    page sized systems (e.g. ppc64).
    
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Feifei Xu <xufeifei@linux.vnet.ibm.com>
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6628fca9f4ed..06ef433552b3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1147,7 +1147,8 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 bytenr)
 {
 	if (btrfs_test_is_dummy_root(root))
-		return alloc_test_extent_buffer(root->fs_info, bytenr);
+		return alloc_test_extent_buffer(root->fs_info, bytenr,
+				root->nodesize);
 	return alloc_extent_buffer(root->fs_info, bytenr);
 }
 
@@ -1314,14 +1315,15 @@ static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info,
 
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 /* Should only be used by the testing infrastructure */
-struct btrfs_root *btrfs_alloc_dummy_root(void)
+struct btrfs_root *btrfs_alloc_dummy_root(u32 sectorsize, u32 nodesize)
 {
 	struct btrfs_root *root;
 
 	root = btrfs_alloc_root(NULL, GFP_KERNEL);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
-	__setup_root(4096, 4096, 4096, root, NULL, 1);
+	/* We don't use the stripesize in selftest, set it as sectorsize */
+	__setup_root(nodesize, sectorsize, sectorsize, root, NULL, 1);
 	set_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state);
 	root->alloc_bytenr = 0;
 

commit 42f31734eb7658fd01fb186d56312be869450a42
Merge: e73440868fde 0132761017e0
Author: David Sterba <dsterba@suse.com>
Date:   Wed May 25 22:51:03 2016 +0200

    Merge branch 'cleanups-4.7' into for-chris-4.7-20160525

commit 0132761017e012ab4dc8584d679503f2ba26ca86
Author: Nicholas D Steeves <nsteeves@gmail.com>
Date:   Thu May 19 21:18:45 2016 -0400

    btrfs: fix string and comment grammatical issues and typos
    
    Signed-off-by: Nicholas D Steeves <nsteeves@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 263823f28ba4..aacc707ef952 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -384,7 +384,7 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 	/*
 	 * Things reading via commit roots that don't have normal protection,
 	 * like send, can have a really old block in cache that may point at a
-	 * block that has been free'd and re-allocated.  So don't clear uptodate
+	 * block that has been freed and re-allocated.  So don't clear uptodate
 	 * if we find an eb that is under IO (dirty/writeback) because we could
 	 * end up reading in the stale data and then writing it back out and
 	 * making everybody very sad.
@@ -418,7 +418,7 @@ static int btrfs_check_super_csum(char *raw_disk_sb)
 		/*
 		 * The super_block structure does not span the whole
 		 * BTRFS_SUPER_INFO_SIZE range, we expect that the unused space
-		 * is filled with zeros and is included in the checkum.
+		 * is filled with zeros and is included in the checksum.
 		 */
 		crc = btrfs_csum_data(raw_disk_sb + BTRFS_CSUM_SIZE,
 				crc, BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
@@ -600,7 +600,7 @@ static noinline int check_leaf(struct btrfs_root *root,
 
 		/*
 		 * Check to make sure that we don't point outside of the leaf,
-		 * just incase all the items are consistent to eachother, but
+		 * just in case all the items are consistent to each other, but
 		 * all point outside of the leaf.
 		 */
 		if (btrfs_item_end_nr(leaf, slot) >
@@ -3017,7 +3017,7 @@ int open_ctree(struct super_block *sb,
 	}
 
 	/*
-	 * Mount does not set all options immediatelly, we can do it now and do
+	 * Mount does not set all options immediately, we can do it now and do
 	 * not have to wait for transaction commit
 	 */
 	btrfs_apply_pending_changes(fs_info);
@@ -3245,7 +3245,7 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 		btrfs_warn_rl_in_rcu(device->dev_root->fs_info,
 				"lost page write due to IO error on %s",
 					  rcu_str_deref(device->name));
-		/* note, we dont' set_buffer_write_io_error because we have
+		/* note, we don't set_buffer_write_io_error because we have
 		 * our own ways of dealing with the IO errors
 		 */
 		clear_buffer_uptodate(bh);

commit 5ef64a3e757c94b2f2fc61465ef9603aaacaecff
Merge: 73d32ce21e17 e1860a772482
Author: David Sterba <dsterba@suse.com>
Date:   Mon May 16 15:46:24 2016 +0200

    Merge branch 'cleanups-4.7' into for-chris-4.7-20160516

commit e1860a7724828a341037b010b3f4ff58bad53f95
Author: David Sterba <dsterba@suse.com>
Date:   Mon May 9 14:11:38 2016 +0200

    btrfs: GFP_NOFS does not GFP_HIGHMEM
    
    Masking HIGHMEM out of NOFS does not make sense.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 123fab55b5a4..4931d3856aa3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1640,7 +1640,7 @@ int btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,
 {
 	int ret;
 
-	ret = radix_tree_preload(GFP_NOFS & ~__GFP_HIGHMEM);
+	ret = radix_tree_preload(GFP_NOFS);
 	if (ret)
 		return ret;
 

commit 05135f597adcb94dc34fa87b82e68eb55e00f0eb
Author: David Sterba <dsterba@suse.com>
Date:   Mon May 9 11:32:39 2016 +0200

    btrfs: switch to common message helpers in open_ctree, adjust messages
    
    Currently we lack the identification of the filesystem in most if not
    all mount messages, done via printk/pr_* functions. We can use the
    btrfs_* helpers in open_ctree, as the fs_info <-> sb link is established
    at the beginning of the function.
    
    The messages have been updated at the same time to be more consistent:
    
    * dropped sb->s_id, as it's not available via btrfs_*
    * added %d for return code where appropriate
    * wording changed
    * %Lx replaced by %llx
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aeb090583b78..123fab55b5a4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2713,7 +2713,7 @@ int open_ctree(struct super_block *sb,
 	 * Pass the whole disk block of size BTRFS_SUPER_INFO_SIZE (4k).
 	 */
 	if (btrfs_check_super_csum(bh->b_data)) {
-		printk(KERN_ERR "BTRFS: superblock checksum mismatch\n");
+		btrfs_err(fs_info, "superblock checksum mismatch");
 		err = -EINVAL;
 		brelse(bh);
 		goto fail_alloc;
@@ -2733,7 +2733,7 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
 	if (ret) {
-		printk(KERN_ERR "BTRFS: superblock contains fatal errors\n");
+		btrfs_err(fs_info, "superblock contains fatal errors");
 		err = -EINVAL;
 		goto fail_alloc;
 	}
@@ -2768,9 +2768,9 @@ int open_ctree(struct super_block *sb,
 	features = btrfs_super_incompat_flags(disk_super) &
 		~BTRFS_FEATURE_INCOMPAT_SUPP;
 	if (features) {
-		printk(KERN_ERR "BTRFS: couldn't mount because of "
-		       "unsupported optional features (%Lx).\n",
-		       features);
+		btrfs_err(fs_info,
+		    "cannot mount because of unsupported optional features (%llx)",
+		    features);
 		err = -EINVAL;
 		goto fail_alloc;
 	}
@@ -2781,7 +2781,7 @@ int open_ctree(struct super_block *sb,
 		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;
 
 	if (features & BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA)
-		printk(KERN_INFO "BTRFS: has skinny extents\n");
+		btrfs_info(fs_info, "has skinny extents");
 
 	/*
 	 * flag our filesystem as having big metadata blocks if
@@ -2789,7 +2789,8 @@ int open_ctree(struct super_block *sb,
 	 */
 	if (btrfs_super_nodesize(disk_super) > PAGE_SIZE) {
 		if (!(features & BTRFS_FEATURE_INCOMPAT_BIG_METADATA))
-			printk(KERN_INFO "BTRFS: flagging fs with big metadata feature\n");
+			btrfs_info(fs_info,
+				"flagging fs with big metadata feature");
 		features |= BTRFS_FEATURE_INCOMPAT_BIG_METADATA;
 	}
 
@@ -2805,9 +2806,9 @@ int open_ctree(struct super_block *sb,
 	 */
 	if ((features & BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS) &&
 	    (sectorsize != nodesize)) {
-		printk(KERN_ERR "BTRFS: unequal leaf/node/sector sizes "
-				"are not allowed for mixed block groups on %s\n",
-				sb->s_id);
+		btrfs_err(fs_info,
+"unequal nodesize/sectorsize (%u != %u) are not allowed for mixed block groups",
+			nodesize, sectorsize);
 		goto fail_alloc;
 	}
 
@@ -2820,8 +2821,8 @@ int open_ctree(struct super_block *sb,
 	features = btrfs_super_compat_ro_flags(disk_super) &
 		~BTRFS_FEATURE_COMPAT_RO_SUPP;
 	if (!(sb->s_flags & MS_RDONLY) && features) {
-		printk(KERN_ERR "BTRFS: couldn't mount RDWR because of "
-		       "unsupported option features (%Lx).\n",
+		btrfs_err(fs_info,
+	"cannot mount read-write because of unsupported optional features (%llx)",
 		       features);
 		err = -EINVAL;
 		goto fail_alloc;
@@ -2850,8 +2851,7 @@ int open_ctree(struct super_block *sb,
 	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
-		printk(KERN_ERR "BTRFS: failed to read the system "
-		       "array on %s\n", sb->s_id);
+		btrfs_err(fs_info, "failed to read the system array: %d", ret);
 		goto fail_sb_buffer;
 	}
 
@@ -2865,8 +2865,7 @@ int open_ctree(struct super_block *sb,
 					   generation);
 	if (IS_ERR(chunk_root->node) ||
 	    !extent_buffer_uptodate(chunk_root->node)) {
-		printk(KERN_ERR "BTRFS: failed to read chunk root on %s\n",
-		       sb->s_id);
+		btrfs_err(fs_info, "failed to read chunk root");
 		if (!IS_ERR(chunk_root->node))
 			free_extent_buffer(chunk_root->node);
 		chunk_root->node = NULL;
@@ -2880,8 +2879,7 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_read_chunk_tree(chunk_root);
 	if (ret) {
-		printk(KERN_ERR "BTRFS: failed to read chunk tree on %s\n",
-		       sb->s_id);
+		btrfs_err(fs_info, "failed to read chunk tree: %d", ret);
 		goto fail_tree_roots;
 	}
 
@@ -2892,8 +2890,7 @@ int open_ctree(struct super_block *sb,
 	btrfs_close_extra_devices(fs_devices, 0);
 
 	if (!fs_devices->latest_bdev) {
-		printk(KERN_ERR "BTRFS: failed to read devices on %s\n",
-		       sb->s_id);
+		btrfs_err(fs_info, "failed to read devices");
 		goto fail_tree_roots;
 	}
 
@@ -2905,8 +2902,7 @@ int open_ctree(struct super_block *sb,
 					  generation);
 	if (IS_ERR(tree_root->node) ||
 	    !extent_buffer_uptodate(tree_root->node)) {
-		printk(KERN_WARNING "BTRFS: failed to read tree root on %s\n",
-		       sb->s_id);
+		btrfs_warn(fs_info, "failed to read tree root");
 		if (!IS_ERR(tree_root->node))
 			free_extent_buffer(tree_root->node);
 		tree_root->node = NULL;
@@ -2938,20 +2934,19 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_recover_balance(fs_info);
 	if (ret) {
-		printk(KERN_ERR "BTRFS: failed to recover balance\n");
+		btrfs_err(fs_info, "failed to recover balance: %d", ret);
 		goto fail_block_groups;
 	}
 
 	ret = btrfs_init_dev_stats(fs_info);
 	if (ret) {
-		printk(KERN_ERR "BTRFS: failed to init dev_stats: %d\n",
-		       ret);
+		btrfs_err(fs_info, "failed to init dev_stats: %d", ret);
 		goto fail_block_groups;
 	}
 
 	ret = btrfs_init_dev_replace(fs_info);
 	if (ret) {
-		pr_err("BTRFS: failed to init dev_replace: %d\n", ret);
+		btrfs_err(fs_info, "failed to init dev_replace: %d", ret);
 		goto fail_block_groups;
 	}
 
@@ -2959,31 +2954,33 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_sysfs_add_fsid(fs_devices, NULL);
 	if (ret) {
-		pr_err("BTRFS: failed to init sysfs fsid interface: %d\n", ret);
+		btrfs_err(fs_info, "failed to init sysfs fsid interface: %d",
+				ret);
 		goto fail_block_groups;
 	}
 
 	ret = btrfs_sysfs_add_device(fs_devices);
 	if (ret) {
-		pr_err("BTRFS: failed to init sysfs device interface: %d\n", ret);
+		btrfs_err(fs_info, "failed to init sysfs device interface: %d",
+				ret);
 		goto fail_fsdev_sysfs;
 	}
 
 	ret = btrfs_sysfs_add_mounted(fs_info);
 	if (ret) {
-		pr_err("BTRFS: failed to init sysfs interface: %d\n", ret);
+		btrfs_err(fs_info, "failed to init sysfs interface: %d", ret);
 		goto fail_fsdev_sysfs;
 	}
 
 	ret = btrfs_init_space_info(fs_info);
 	if (ret) {
-		printk(KERN_ERR "BTRFS: Failed to initial space info: %d\n", ret);
+		btrfs_err(fs_info, "failed to initialize space info: %d", ret);
 		goto fail_sysfs;
 	}
 
 	ret = btrfs_read_block_groups(fs_info->extent_root);
 	if (ret) {
-		printk(KERN_ERR "BTRFS: Failed to read block groups: %d\n", ret);
+		btrfs_err(fs_info, "failed to read block groups: %d", ret);
 		goto fail_sysfs;
 	}
 	fs_info->num_tolerated_disk_barrier_failures =
@@ -2991,7 +2988,8 @@ int open_ctree(struct super_block *sb,
 	if (fs_info->fs_devices->missing_devices >
 	     fs_info->num_tolerated_disk_barrier_failures &&
 	    !(sb->s_flags & MS_RDONLY)) {
-		pr_warn("BTRFS: missing devices(%llu) exceeds the limit(%d), writeable mount is not allowed\n",
+		btrfs_warn(fs_info,
+"missing devices (%llu) exceeds the limit (%d), writeable mount is not allowed",
 			fs_info->fs_devices->missing_devices,
 			fs_info->num_tolerated_disk_barrier_failures);
 		goto fail_sysfs;
@@ -3011,8 +3009,7 @@ int open_ctree(struct super_block *sb,
 	if (!btrfs_test_opt(tree_root, SSD) &&
 	    !btrfs_test_opt(tree_root, NOSSD) &&
 	    !fs_info->fs_devices->rotating) {
-		printk(KERN_INFO "BTRFS: detected SSD devices, enabling SSD "
-		       "mode\n");
+		btrfs_info(fs_info, "detected SSD devices, enabling SSD mode");
 		btrfs_set_opt(fs_info->mount_opt, SSD);
 	}
 
@@ -3030,8 +3027,9 @@ int open_ctree(struct super_block *sb,
 				    1 : 0,
 				    fs_info->check_integrity_print_mask);
 		if (ret)
-			printk(KERN_WARNING "BTRFS: failed to initialize"
-			       " integrity check module %s\n", sb->s_id);
+			btrfs_warn(fs_info,
+				"failed to initialize integrity check module: %d",
+				ret);
 	}
 #endif
 	ret = btrfs_read_qgroup_config(fs_info);
@@ -3061,8 +3059,8 @@ int open_ctree(struct super_block *sb,
 		ret = btrfs_recover_relocation(tree_root);
 		mutex_unlock(&fs_info->cleaner_mutex);
 		if (ret < 0) {
-			printk(KERN_WARNING
-			       "BTRFS: failed to recover relocation\n");
+			btrfs_warn(fs_info, "failed to recover relocation: %d",
+					ret);
 			err = -EINVAL;
 			goto fail_qgroup;
 		}
@@ -3083,11 +3081,11 @@ int open_ctree(struct super_block *sb,
 
 	if (btrfs_test_opt(tree_root, FREE_SPACE_TREE) &&
 	    !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
-		pr_info("BTRFS: creating free space tree\n");
+		btrfs_info(fs_info, "creating free space tree");
 		ret = btrfs_create_free_space_tree(fs_info);
 		if (ret) {
-			pr_warn("BTRFS: failed to create free space tree %d\n",
-				ret);
+			btrfs_warn(fs_info,
+				"failed to create free space tree: %d", ret);
 			close_ctree(tree_root);
 			return ret;
 		}
@@ -3104,14 +3102,14 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_resume_balance_async(fs_info);
 	if (ret) {
-		printk(KERN_WARNING "BTRFS: failed to resume balance\n");
+		btrfs_warn(fs_info, "failed to resume balance: %d", ret);
 		close_ctree(tree_root);
 		return ret;
 	}
 
 	ret = btrfs_resume_dev_replace_async(fs_info);
 	if (ret) {
-		pr_warn("BTRFS: failed to resume dev_replace\n");
+		btrfs_warn(fs_info, "failed to resume device replace: %d", ret);
 		close_ctree(tree_root);
 		return ret;
 	}
@@ -3120,33 +3118,33 @@ int open_ctree(struct super_block *sb,
 
 	if (btrfs_test_opt(tree_root, CLEAR_CACHE) &&
 	    btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
-		pr_info("BTRFS: clearing free space tree\n");
+		btrfs_info(fs_info, "clearing free space tree");
 		ret = btrfs_clear_free_space_tree(fs_info);
 		if (ret) {
-			pr_warn("BTRFS: failed to clear free space tree %d\n",
-				ret);
+			btrfs_warn(fs_info,
+				"failed to clear free space tree: %d", ret);
 			close_ctree(tree_root);
 			return ret;
 		}
 	}
 
 	if (!fs_info->uuid_root) {
-		pr_info("BTRFS: creating UUID tree\n");
+		btrfs_info(fs_info, "creating UUID tree");
 		ret = btrfs_create_uuid_tree(fs_info);
 		if (ret) {
-			pr_warn("BTRFS: failed to create the UUID tree %d\n",
-				ret);
+			btrfs_warn(fs_info,
+				"failed to create the UUID tree: %d", ret);
 			close_ctree(tree_root);
 			return ret;
 		}
 	} else if (btrfs_test_opt(tree_root, RESCAN_UUID_TREE) ||
 		   fs_info->generation !=
 				btrfs_super_uuid_tree_generation(disk_super)) {
-		pr_info("BTRFS: checking UUID tree\n");
+		btrfs_info(fs_info, "checking UUID tree");
 		ret = btrfs_check_uuid_tree(fs_info);
 		if (ret) {
-			pr_warn("BTRFS: failed to check the UUID tree %d\n",
-				ret);
+			btrfs_warn(fs_info,
+				"failed to check the UUID tree: %d", ret);
 			close_ctree(tree_root);
 			return ret;
 		}

commit 2f3165ecf103599f82bf0ea254039db335fb5005
Author: Zygo Blaxell <ce3g8jdj@umail.furryterror.org>
Date:   Thu May 5 00:23:49 2016 -0400

    btrfs: don't force mounts to wait for cleaner_kthread to delete one or more subvolumes
    
    During a mount, we start the cleaner kthread first because the transaction
    kthread wants to wake up the cleaner kthread.  We start the transaction
    kthread next because everything in btrfs wants transactions.  We do reloc
    recovery in the thread that was doing the original mount call once the
    transaction kthread is running.  This means that the cleaner kthread
    could already be running when reloc recovery happens (e.g. if a snapshot
    delete was started before a crash).
    
    Relocation does not play well with the cleaner kthread, so a mutex was
    added in commit 5f3164813b90f7dbcb5c3ab9006906222ce471b7 "Btrfs: fix
    race between balance recovery and root deletion" to prevent both from
    being active at the same time.
    
    If the cleaner kthread is already holding the mutex by the time we get
    to btrfs_recover_relocation, the mount will be blocked until at least
    one deleted subvolume is cleaned (possibly more if the mount process
    doesn't get the lock right away).  During this time (which could be an
    arbitrarily long time on a large/slow filesystem), the mount process is
    stuck and the filesystem is unnecessarily inaccessible.
    
    Fix this by locking cleaner_mutex before we start cleaner_kthread, and
    unlocking the mutex after mount no longer requires it.  This ensures
    that the mounting process will not be blocked by the cleaner kthread.
    The cleaner kthread is already prepared for mutex contention and will
    just go to sleep until the mutex is available.
    
    Signed-off-by: Zygo Blaxell <ce3g8jdj@umail.furryterror.org>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4e47849d7427..070c1dad42bd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2517,6 +2517,7 @@ int open_ctree(struct super_block *sb,
 	int num_backups_tried = 0;
 	int backup_index = 0;
 	int max_active;
+	bool cleaner_mutex_locked = false;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
@@ -2997,6 +2998,13 @@ int open_ctree(struct super_block *sb,
 		goto fail_sysfs;
 	}
 
+	/*
+	 * Hold the cleaner_mutex thread here so that we don't block
+	 * for a long time on btrfs_recover_relocation.  cleaner_kthread
+	 * will wait for us to finish mounting the filesystem.
+	 */
+	mutex_lock(&fs_info->cleaner_mutex);
+	cleaner_mutex_locked = true;
 	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
 					       "btrfs-cleaner");
 	if (IS_ERR(fs_info->cleaner_kthread))
@@ -3056,10 +3064,8 @@ int open_ctree(struct super_block *sb,
 		ret = btrfs_cleanup_fs_roots(fs_info);
 		if (ret)
 			goto fail_qgroup;
-
-		mutex_lock(&fs_info->cleaner_mutex);
+		/* We locked cleaner_mutex before creating cleaner_kthread. */
 		ret = btrfs_recover_relocation(tree_root);
-		mutex_unlock(&fs_info->cleaner_mutex);
 		if (ret < 0) {
 			printk(KERN_WARNING
 			       "BTRFS: failed to recover relocation\n");
@@ -3067,6 +3073,8 @@ int open_ctree(struct super_block *sb,
 			goto fail_qgroup;
 		}
 	}
+	mutex_unlock(&fs_info->cleaner_mutex);
+	cleaner_mutex_locked = false;
 
 	location.objectid = BTRFS_FS_TREE_OBJECTID;
 	location.type = BTRFS_ROOT_ITEM_KEY;
@@ -3180,6 +3188,10 @@ int open_ctree(struct super_block *sb,
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
 
 fail_sysfs:
+	if (cleaner_mutex_locked) {
+		mutex_unlock(&fs_info->cleaner_mutex);
+		cleaner_mutex_locked = false;
+	}
 	btrfs_sysfs_remove_mounted(fs_info);
 
 fail_fsdev_sysfs:

commit af6f8f604d44e05f98ed45a69830547ed133adf8
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to clear_extent_dirty
    
    Callers pass GFP_NOFS. No need to pass the flags around.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3bc88b4b0032..263823f28ba4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4392,7 +4392,7 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 		if (ret)
 			break;
 
-		clear_extent_dirty(unpin, start, end, GFP_NOFS);
+		clear_extent_dirty(unpin, start, end);
 		btrfs_error_unpin_extent_range(root, start, end);
 		cond_resched();
 	}

commit 91166212e0ffbb4db50aa8a238548e967008b33d
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 26 23:54:39 2016 +0200

    btrfs: sink gfp parameter to clear_extent_bits
    
    Callers pass GFP_NOFS and GFP_KERNEL. No need to pass the flags around.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4e47849d7427..3bc88b4b0032 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4357,7 +4357,7 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 		if (ret)
 			break;
 
-		clear_extent_bits(dirty_pages, start, end, mark, GFP_NOFS);
+		clear_extent_bits(dirty_pages, start, end, mark);
 		while (start <= end) {
 			eb = btrfs_find_tree_block(root->fs_info, start);
 			start += root->nodesize;

commit 34d9700702f4042ce10d68a092ab7f79575e7a3b
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Mar 16 16:43:06 2016 +0800

    btrfs: rename btrfs_std_error to btrfs_handle_fs_error
    
    btrfs_std_error() handles errors, puts FS into readonly mode
    (as of now). So its good idea to rename it to btrfs_handle_fs_error().
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ edit changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4e47849d7427..aeb090583b78 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2417,7 +2417,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	/* returns with log_tree_root freed on success */
 	ret = btrfs_recover_log_trees(log_tree_root);
 	if (ret) {
-		btrfs_std_error(tree_root->fs_info, ret,
+		btrfs_handle_fs_error(tree_root->fs_info, ret,
 			    "Failed to recover log tree");
 		free_extent_buffer(log_tree_root->node);
 		kfree(log_tree_root);
@@ -3646,7 +3646,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		if (ret) {
 			mutex_unlock(
 				&root->fs_info->fs_devices->device_list_mutex);
-			btrfs_std_error(root->fs_info, ret,
+			btrfs_handle_fs_error(root->fs_info, ret,
 				    "errors while submitting device barriers.");
 			return ret;
 		}
@@ -3686,7 +3686,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
 
 		/* FUA is masked off if unsupported and can't be the reason */
-		btrfs_std_error(root->fs_info, -EIO,
+		btrfs_handle_fs_error(root->fs_info, -EIO,
 			    "%d errors while writing supers", total_errors);
 		return -EIO;
 	}
@@ -3704,7 +3704,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	}
 	mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
 	if (total_errors > max_errors) {
-		btrfs_std_error(root->fs_info, -EIO,
+		btrfs_handle_fs_error(root->fs_info, -EIO,
 			    "%d errors while writing supers", total_errors);
 		return -EIO;
 	}

commit 4a2d057e4fc4f9ebd32351837c14c10a0773b956
Merge: 9735a22799b9 1fa64f198b9f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 4 10:50:24 2016 -0700

    Merge branch 'PAGE_CACHE_SIZE-removal'
    
    Merge PAGE_CACHE_SIZE removal patches from Kirill Shutemov:
     "PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
      ago with promise that one day it will be possible to implement page
      cache with bigger chunks than PAGE_SIZE.
    
      This promise never materialized.  And unlikely will.
    
      Let's stop pretending that pages in page cache are special.  They are
      not.
    
      The first patch with most changes has been done with coccinelle.  The
      second is manual fixups on top.
    
      The third patch removes macros definition"
    
    [ I was planning to apply this just before rc2, but then I spaced out,
      so here it is right _after_ rc2 instead.
    
      As Kirill suggested as a possibility, I could have decided to only
      merge the first two patches, and leave the old interfaces for
      compatibility, but I'd rather get it all done and any out-of-tree
      modules and patches can trivially do the converstion while still also
      working with older kernels, so there is little reason to try to
      maintain the redundant legacy model.    - Linus ]
    
    * PAGE_CACHE_SIZE-removal:
      mm: drop PAGE_CACHE_* and page_cache_{get,release} definition
      mm, fs: remove remaining PAGE_CACHE_* and page_cache_{get,release} usage
      mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4b02591b0301..942af3d2885f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1055,7 +1055,7 @@ static void btree_invalidatepage(struct page *page, unsigned int offset,
 			   (unsigned long long)page_offset(page));
 		ClearPagePrivate(page);
 		set_page_private(page, 0);
-		page_cache_release(page);
+		put_page(page);
 	}
 }
 
@@ -1757,7 +1757,7 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 	if (err)
 		return err;
 
-	bdi->ra_pages = VM_MAX_READAHEAD * 1024 / PAGE_CACHE_SIZE;
+	bdi->ra_pages = VM_MAX_READAHEAD * 1024 / PAGE_SIZE;
 	bdi->congested_fn	= btrfs_congested_fn;
 	bdi->congested_data	= info;
 	bdi->capabilities |= BDI_CAP_CGROUP_WRITEBACK;
@@ -2537,7 +2537,7 @@ int open_ctree(struct super_block *sb,
 		err = ret;
 		goto fail_bdi;
 	}
-	fs_info->dirty_metadata_batch = PAGE_CACHE_SIZE *
+	fs_info->dirty_metadata_batch = PAGE_SIZE *
 					(1 + ilog2(nr_cpu_ids));
 
 	ret = percpu_counter_init(&fs_info->delalloc_bytes, 0, GFP_KERNEL);
@@ -2782,7 +2782,7 @@ int open_ctree(struct super_block *sb,
 	 * flag our filesystem as having big metadata blocks if
 	 * they are bigger than the page size
 	 */
-	if (btrfs_super_nodesize(disk_super) > PAGE_CACHE_SIZE) {
+	if (btrfs_super_nodesize(disk_super) > PAGE_SIZE) {
 		if (!(features & BTRFS_FEATURE_INCOMPAT_BIG_METADATA))
 			printk(KERN_INFO "BTRFS: flagging fs with big metadata feature\n");
 		features |= BTRFS_FEATURE_INCOMPAT_BIG_METADATA;
@@ -2832,7 +2832,7 @@ int open_ctree(struct super_block *sb,
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
-				    SZ_4M / PAGE_CACHE_SIZE);
+				    SZ_4M / PAGE_SIZE);
 
 	tree_root->nodesize = nodesize;
 	tree_root->sectorsize = sectorsize;
@@ -4071,9 +4071,9 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 		ret = -EINVAL;
 	}
 	/* Only PAGE SIZE is supported yet */
-	if (sectorsize != PAGE_CACHE_SIZE) {
+	if (sectorsize != PAGE_SIZE) {
 		printk(KERN_ERR "BTRFS: sectorsize %llu not supported yet, only support %lu\n",
-				sectorsize, PAGE_CACHE_SIZE);
+				sectorsize, PAGE_SIZE);
 		ret = -EINVAL;
 	}
 	if (!is_power_of_2(nodesize) || nodesize < sectorsize ||

commit 82d2a348bb9a1e265fe1c62e39341128ec014ed9
Merge: 22fed39775c6 232cad8413a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 1 18:08:34 2016 -0500

    Merge branch 'for-linus-4.6' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "This has a few fixes Dave Sterba had queued up.  These are all pretty
      small, but since they were tested I decided against waiting for more"
    
    * 'for-linus-4.6' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      btrfs: transaction_kthread() is not freezable
      btrfs: cleaner_kthread() doesn't need explicit freeze
      btrfs: do not write corrupted metadata blocks to disk
      btrfs: csum_tree_block: return proper errno value

commit 232cad8413a0bfbd25f11cc19fd13dfd85e1d8ad
Merge: 389f239c5342 ce63f891e1a8
Author: Chris Mason <clm@fb.com>
Date:   Thu Mar 24 17:36:13 2016 -0700

    Merge branch 'misc-4.6' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.6

commit ce63f891e1a87ae79c4325dad5f512e8d6a8a78e
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Tue Mar 15 11:28:59 2016 +0100

    btrfs: transaction_kthread() is not freezable
    
    transaction_kthread() is calling try_to_freeze(), but that's just an
    expeinsive no-op given the fact that the thread is not marked freezable.
    
    After removing this, disk-io.c is now independent on freezer API.
    
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ff36a33ee9ca..81966676a26b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -25,7 +25,6 @@
 #include <linux/buffer_head.h>
 #include <linux/workqueue.h>
 #include <linux/kthread.h>
-#include <linux/freezer.h>
 #include <linux/slab.h>
 #include <linux/migrate.h>
 #include <linux/ratelimit.h>
@@ -1928,14 +1927,12 @@ static int transaction_kthread(void *arg)
 		if (unlikely(test_bit(BTRFS_FS_STATE_ERROR,
 				      &root->fs_info->fs_state)))
 			btrfs_cleanup_transaction(root);
-		if (!try_to_freeze()) {
-			set_current_state(TASK_INTERRUPTIBLE);
-			if (!kthread_should_stop() &&
-			    (!btrfs_transaction_blocked(root->fs_info) ||
-			     cannot_commit))
-				schedule_timeout(delay);
-			__set_current_state(TASK_RUNNING);
-		}
+		set_current_state(TASK_INTERRUPTIBLE);
+		if (!kthread_should_stop() &&
+				(!btrfs_transaction_blocked(root->fs_info) ||
+				 cannot_commit))
+			schedule_timeout(delay);
+		__set_current_state(TASK_RUNNING);
 	} while (!kthread_should_stop());
 	return 0;
 }

commit 838fe1887765f4cc679febea60d87d2a06bd300e
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Tue Mar 15 11:28:54 2016 +0100

    btrfs: cleaner_kthread() doesn't need explicit freeze
    
    cleaner_kthread() is not marked freezable, and therefore calling
    try_to_freeze() in its context is a pointless no-op.
    
    In addition to that, as has been clearly demonstrated by 80ad623edd2d
    ("Revert "btrfs: clear PF_NOFREEZE in cleaner_kthread()"), it's perfectly
    valid / legal for cleaner_kthread() to stay scheduled out in an arbitrary
    place during suspend (in that particular example that was waiting for
    reading of extent pages), so there is no need to leave any traces of
    freezer in this kthread.
    
    Fixes: 80ad623edd2d ("Revert "btrfs: clear PF_NOFREEZE in cleaner_kthread()")
    Fixes: 696249132158 ("btrfs: clear PF_NOFREEZE in cleaner_kthread()")
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8579b35bb160..ff36a33ee9ca 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1838,7 +1838,7 @@ static int cleaner_kthread(void *arg)
 		 */
 		btrfs_delete_unused_bgs(root->fs_info);
 sleep:
-		if (!try_to_freeze() && !again) {
+		if (!again) {
 			set_current_state(TASK_INTERRUPTIBLE);
 			if (!kthread_should_stop())
 				schedule();

commit 0f805531daa2ebfb5706422dc2ead1cff9e53e65
Author: Alex Lyakas <alex.bolshoy@gmail.com>
Date:   Thu Mar 10 13:10:15 2016 +0200

    btrfs: do not write corrupted metadata blocks to disk
    
    csum_dirty_buffer was issuing a warning in case the extent buffer
    did not look alright, but was still returning success.
    Let's return error in this case, and also add an additional sanity
    check on the extent buffer header.
    The caller up the chain may BUG_ON on this, for example flush_epd_write_bio will,
    but it is better than to have a silent metadata corruption on disk.
    
    Signed-off-by: Alex Lyakas <alex@zadarastorage.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9cafae5c2061..8579b35bb160 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -512,9 +512,20 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 	eb = (struct extent_buffer *)page->private;
 	if (page != eb->pages[0])
 		return 0;
+
 	found_start = btrfs_header_bytenr(eb);
-	if (WARN_ON(found_start != start || !PageUptodate(page)))
-		return 0;
+	/*
+	 * Please do not consolidate these warnings into a single if.
+	 * It is useful to know what went wrong.
+	 */
+	if (WARN_ON(found_start != start))
+		return -EUCLEAN;
+	if (WARN_ON(!PageUptodate(page)))
+		return -EUCLEAN;
+
+	ASSERT(memcmp_extent_buffer(eb, fs_info->fsid,
+			btrfs_header_fsid(), BTRFS_FSID_SIZE) == 0);
+
 	return csum_tree_block(fs_info, eb, 0);
 }
 

commit 8bd98f0e6bf792e8fa7c3fed709321ad42ba8d2e
Author: Alex Lyakas <alex.bolshoy@gmail.com>
Date:   Thu Mar 10 13:09:46 2016 +0200

    btrfs: csum_tree_block: return proper errno value
    
    Signed-off-by: Alex Lyakas <alex@zadarastorage.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a998ef15ec6d..9cafae5c2061 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -302,7 +302,7 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 		err = map_private_extent_buffer(buf, offset, 32,
 					&kaddr, &map_start, &map_len);
 		if (err)
-			return 1;
+			return err;
 		cur_len = min(len, map_len - (offset - map_start));
 		crc = btrfs_csum_data(kaddr + offset - map_start,
 				      crc, cur_len);
@@ -312,7 +312,7 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 	if (csum_size > sizeof(inline_result)) {
 		result = kzalloc(csum_size, GFP_NOFS);
 		if (!result)
-			return 1;
+			return -ENOMEM;
 	} else {
 		result = (char *)&inline_result;
 	}
@@ -333,7 +333,7 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 				val, found, btrfs_header_level(buf));
 			if (result != (char *)&inline_result)
 				kfree(result);
-			return 1;
+			return -EUCLEAN;
 		}
 	} else {
 		write_extent_buffer(buf, result, 0, csum_size);
@@ -515,8 +515,7 @@ static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 	found_start = btrfs_header_bytenr(eb);
 	if (WARN_ON(found_start != start || !PageUptodate(page)))
 		return 0;
-	csum_tree_block(fs_info, eb, 0);
-	return 0;
+	return csum_tree_block(fs_info, eb, 0);
 }
 
 static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
@@ -660,10 +659,8 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 				       eb, found_level);
 
 	ret = csum_tree_block(fs_info, eb, 1);
-	if (ret) {
-		ret = -EIO;
+	if (ret)
 		goto err;
-	}
 
 	/*
 	 * If this is a leaf block and it is corrupt, set the corrupt bit so

commit 968f3e374faf41e5e6049399eb7302777a09a1e8
Merge: e531cdf50a8a 389f239c5342
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 21 18:12:42 2016 -0700

    Merge branch 'for-linus-4.6' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "We have a good sized cleanup of our internal read ahead code, and the
      first series of commits from Chandan to enable PAGE_SIZE > sectorsize
    
      Otherwise, it's a normal series of cleanups and fixes, with many
      thanks to Dave Sterba for doing most of the patch wrangling this time"
    
    * 'for-linus-4.6' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (82 commits)
      btrfs: make sure we stay inside the bvec during __btrfs_lookup_bio_sums
      btrfs: Fix misspellings in comments.
      btrfs: Print Warning only if ENOSPC_DEBUG is enabled
      btrfs: scrub: silence an uninitialized variable warning
      btrfs: move btrfs_compression_type to compression.h
      btrfs: rename btrfs_print_info to btrfs_print_mod_info
      Btrfs: Show a warning message if one of objectid reaches its highest value
      Documentation: btrfs: remove usage specific information
      btrfs: use kbasename in btrfsic_mount
      Btrfs: do not collect ordered extents when logging that inode exists
      Btrfs: fix race when checking if we can skip fsync'ing an inode
      Btrfs: fix listxattrs not listing all xattrs packed in the same item
      Btrfs: fix deadlock between direct IO reads and buffered writes
      Btrfs: fix extent_same allowing destination offset beyond i_size
      Btrfs: fix file loss on log replay after renaming a file and fsync
      Btrfs: fix unreplayable log after snapshot delete + parent dir fsync
      Btrfs: fix lockdep deadlock warning due to dev_replace
      btrfs: drop unused argument in btrfs_ioctl_get_supported_features
      btrfs: add GET_SUPPORTED_FEATURES to the control device ioctls
      btrfs: change max_inline default to 2048
      ...

commit bb7ab3b92e46da06b580c6f83abe7894dc449cca
Author: Adam Buchbinder <adam.buchbinder@gmail.com>
Date:   Fri Mar 4 11:23:12 2016 -0800

    btrfs: Fix misspellings in comments.
    
    Signed-off-by: Adam Buchbinder <adam.buchbinder@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 53525a54608b..c95e3ce9f22e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -816,7 +816,7 @@ static void run_one_async_done(struct btrfs_work *work)
 	    waitqueue_active(&fs_info->async_submit_wait))
 		wake_up(&fs_info->async_submit_wait);
 
-	/* If an error occured we just want to clean up the bio and move on */
+	/* If an error occurred we just want to clean up the bio and move on */
 	if (async->error) {
 		async->bio->bi_error = async->error;
 		bio_endio(async->bio);

commit ebb8765b2ded869b75bf5154b048119eb52571f7
Author: Anand Jain <anand.jain@oracle.com>
Date:   Thu Mar 10 17:26:59 2016 +0800

    btrfs: move btrfs_compression_type to compression.h
    
    So that its better organized.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a998ef15ec6d..53525a54608b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -50,6 +50,7 @@
 #include "raid56.h"
 #include "sysfs.h"
 #include "qgroup.h"
+#include "compression.h"
 
 #ifdef CONFIG_X86
 #include <asm/cpufeature.h>

commit f004fae0cfeb96d33240eb5471f14cb6fbbd4eea
Merge: 675d276b322b f827ba9a641b
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:33 2016 +0100

    Merge branch 'cleanups-4.6' into for-chris-4.6

commit 675d276b322b45e7bf7c616a2847bdc425745b99
Merge: e9ddd77a31e6 73beece9ca07
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:32 2016 +0100

    Merge branch 'foreign/liubo/replace-lockup' into for-chris-4.6

commit ff7db6e05a93a23eb43c7d20dc2027bcc939b6a8
Merge: 23c1a966f252 7aff8cf4a6d6
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:30 2016 +0100

    Merge branch 'foreign/zhaolei/reada' into for-chris-4.6

commit 23c1a966f2525e71f895bf349a5ae9e5d7bdd67f
Merge: 67d605fec1d4 fed8f166ebf3
Author: David Sterba <dsterba@suse.com>
Date:   Fri Feb 26 15:38:30 2016 +0100

    Merge branch 'foreign/qu/norecovery-v7' into for-chris-4.6

commit 73beece9ca07c003e0e4f4825b12be167334d4ad
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Jul 17 16:49:19 2015 +0800

    Btrfs: fix lockdep deadlock warning due to dev_replace
    
    Xfstests btrfs/011 complains about a deadlock warning,
    
    [ 1226.649039] =========================================================
    [ 1226.649039] [ INFO: possible irq lock inversion dependency detected ]
    [ 1226.649039] 4.1.0+ #270 Not tainted
    [ 1226.649039] ---------------------------------------------------------
    [ 1226.652955] kswapd0/46 just changed the state of lock:
    [ 1226.652955]  (&delayed_node->mutex){+.+.-.}, at: [<ffffffff81458735>] __btrfs_release_delayed_node+0x45/0x1d0
    [ 1226.652955] but this lock took another, RECLAIM_FS-unsafe lock in the past:
    [ 1226.652955]  (&fs_info->dev_replace.lock){+.+.+.}
    
    and interrupts could create inverse lock ordering between them.
    
    [ 1226.652955]
    other info that might help us debug this:
    [ 1226.652955] Chain exists of:
      &delayed_node->mutex --> &found->groups_sem --> &fs_info->dev_replace.lock
    
    [ 1226.652955]  Possible interrupt unsafe locking scenario:
    
    [ 1226.652955]        CPU0                    CPU1
    [ 1226.652955]        ----                    ----
    [ 1226.652955]   lock(&fs_info->dev_replace.lock);
    [ 1226.652955]                                local_irq_disable();
    [ 1226.652955]                                lock(&delayed_node->mutex);
    [ 1226.652955]                                lock(&found->groups_sem);
    [ 1226.652955]   <Interrupt>
    [ 1226.652955]     lock(&delayed_node->mutex);
    [ 1226.652955]
     *** DEADLOCK ***
    
    Commit 084b6e7c7607 ("btrfs: Fix a lockdep warning when running xfstest.") tried
    to fix a similar one that has the exactly same warning, but with that, we still
    run to this.
    
    The above lock chain comes from
    btrfs_commit_transaction
      ->btrfs_run_delayed_items
        ...
        ->__btrfs_update_delayed_inode
          ...
          ->__btrfs_cow_block
             ...
             ->find_free_extent
                ->cache_block_group
                  ->load_free_space_cache
                    ->btrfs_readpages
                      ->submit_one_bio
                        ...
                        ->__btrfs_map_block
                          ->btrfs_dev_replace_lock
    
    However, with high memory pressure, tasks which hold dev_replace.lock can
    be interrupted by kswapd and then kswapd is intended to release memory occupied
    by superblock, inodes and dentries, where we may call evict_inode, and it comes
    to
    
    [ 1226.652955]  [<ffffffff81458735>] __btrfs_release_delayed_node+0x45/0x1d0
    [ 1226.652955]  [<ffffffff81459e74>] btrfs_remove_delayed_node+0x24/0x30
    [ 1226.652955]  [<ffffffff8140c5fe>] btrfs_evict_inode+0x34e/0x700
    
    delayed_node->mutex may be acquired in __btrfs_release_delayed_node(), and it leads
    to a ABBA deadlock.
    
    To fix this, we can use "blocking rwlock" used in the case of extent_buffer, but
    things are simpler here since we only needs read's spinlock to blocking lock.
    
    With this, btrfs/011 no more produces warnings in dmesg.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4545e2e2ad45..81d0f39c2266 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2272,9 +2272,11 @@ static void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)
 	fs_info->dev_replace.lock_owner = 0;
 	atomic_set(&fs_info->dev_replace.nesting_level, 0);
 	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
-	mutex_init(&fs_info->dev_replace.lock_management_lock);
-	mutex_init(&fs_info->dev_replace.lock);
+	rwlock_init(&fs_info->dev_replace.lock);
+	atomic_set(&fs_info->dev_replace.read_locks, 0);
+	atomic_set(&fs_info->dev_replace.blocking_readers, 0);
 	init_waitqueue_head(&fs_info->replace_wait);
+	init_waitqueue_head(&fs_info->dev_replace.read_lock_wq);
 }
 
 static void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)

commit 5598e9005a4076d6700bbd89d0cdbe5b2922a846
Author: Kinglong Mee <kinglongmee@gmail.com>
Date:   Fri Jan 29 21:36:35 2016 +0800

    btrfs: drop null testing before destroy functions
    
    Cleanup.
    
    kmem_cache_destroy has support NULL argument checking,
    so drop the double null testing before calling it.
    
    Signed-off-by: Kinglong Mee <kinglongmee@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4545e2e2ad45..19f8e5bd7dfb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -110,8 +110,7 @@ int __init btrfs_end_io_wq_init(void)
 
 void btrfs_end_io_wq_exit(void)
 {
-	if (btrfs_end_io_wq_cache)
-		kmem_cache_destroy(btrfs_end_io_wq_cache);
+	kmem_cache_destroy(btrfs_end_io_wq_cache);
 }
 
 /*

commit 2fefd5583f8b86171c898f90cadac7c09ccf9d73
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Jan 7 18:38:48 2016 +0800

    btrfs: reada: limit max works count
    
    Reada creates 2 works for each level of tree recursively.
    
    In case of a tree having many levels, the number of created works
    is 2^level_of_tree.
    Actually we don't need so many works in parallel, this patch limits
    max works to BTRFS_MAX_MIRRORS * 2.
    
    The per-fs works_counter will be also used for btrfs_reada_wait() to
    check is there are background workers.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 498156ede32c..5e3ec1fc0ac3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2603,6 +2603,7 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->nr_async_bios, 0);
 	atomic_set(&fs_info->defrag_running, 0);
 	atomic_set(&fs_info->qgroup_op_seq, 0);
+	atomic_set(&fs_info->reada_works_cnt, 0);
 	atomic64_set(&fs_info->tree_mod_seq, 0);
 	fs_info->sb = sb;
 	fs_info->max_inline = BTRFS_DEFAULT_MAX_INLINE;

commit 02873e432518f84ad8f15d8911e79659ea38085f
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Dec 31 22:46:45 2015 +0800

    btrfs: reada: Use fs_info instead of root in __readahead_hook's argument
    
    What __readahead_hook() need exactly is fs_info, no need to convert
    fs_info to root in caller and convert back in __readahead_hook()
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4545e2e2ad45..498156ede32c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -612,6 +612,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	int found_level;
 	struct extent_buffer *eb;
 	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
+	struct btrfs_fs_info *fs_info = root->fs_info;
 	int ret = 0;
 	int reads_done;
 
@@ -637,21 +638,21 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != eb->start) {
-		btrfs_err_rl(eb->fs_info, "bad tree block start %llu %llu",
-			       found_start, eb->start);
+		btrfs_err_rl(fs_info, "bad tree block start %llu %llu",
+			     found_start, eb->start);
 		ret = -EIO;
 		goto err;
 	}
-	if (check_tree_block_fsid(root->fs_info, eb)) {
-		btrfs_err_rl(eb->fs_info, "bad fsid on block %llu",
-			       eb->start);
+	if (check_tree_block_fsid(fs_info, eb)) {
+		btrfs_err_rl(fs_info, "bad fsid on block %llu",
+			     eb->start);
 		ret = -EIO;
 		goto err;
 	}
 	found_level = btrfs_header_level(eb);
 	if (found_level >= BTRFS_MAX_LEVEL) {
-		btrfs_err(root->fs_info, "bad tree block level %d",
-			   (int)btrfs_header_level(eb));
+		btrfs_err(fs_info, "bad tree block level %d",
+			  (int)btrfs_header_level(eb));
 		ret = -EIO;
 		goto err;
 	}
@@ -659,7 +660,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	btrfs_set_buffer_lockdep_class(btrfs_header_owner(eb),
 				       eb, found_level);
 
-	ret = csum_tree_block(root->fs_info, eb, 1);
+	ret = csum_tree_block(fs_info, eb, 1);
 	if (ret) {
 		ret = -EIO;
 		goto err;
@@ -680,7 +681,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 err:
 	if (reads_done &&
 	    test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
-		btree_readahead_hook(root, eb, eb->start, ret);
+		btree_readahead_hook(fs_info, eb, eb->start, ret);
 
 	if (ret) {
 		/*
@@ -699,14 +700,13 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 static int btree_io_failed_hook(struct page *page, int failed_mirror)
 {
 	struct extent_buffer *eb;
-	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
 
 	eb = (struct extent_buffer *)page->private;
 	set_bit(EXTENT_BUFFER_READ_ERR, &eb->bflags);
 	eb->read_mirror = failed_mirror;
 	atomic_dec(&eb->io_pages);
 	if (test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
-		btree_readahead_hook(root, eb, eb->start, -EIO);
+		btree_readahead_hook(eb->fs_info, eb, eb->start, -EIO);
 	return -EIO;	/* we fixed nothing */
 }
 

commit 3a2f2ac9b96f9a9f5538396a212d3b9fb543bfc5
Merge: 4e79e182b419 f4eafd8bcd52
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Feb 18 09:28:03 2016 +0100

    Merge branch 'x86/urgent' into x86/asm, to pick up fixes
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 96da09192cda57a356467bd7c91a3641a2e78490
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Jan 19 10:23:03 2016 +0800

    btrfs: Introduce new mount option to disable tree log replay
    
    Introduce a new mount option "nologreplay" to co-operate with "ro" mount
    option to get real readonly mount, like "norecovery" in ext* and xfs.
    
    Since the new parse_options() need to check new flags at remount time,
    so add a new parameter for parse_options().
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Tested-by: Austin S. Hemmelgarn <ahferroin7@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c0363626c5da..18541dc4ec0b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2750,7 +2750,7 @@ int open_ctree(struct super_block *sb,
 	 */
 	fs_info->compress_type = BTRFS_COMPRESS_ZLIB;
 
-	ret = btrfs_parse_options(tree_root, options);
+	ret = btrfs_parse_options(tree_root, options, sb->s_flags);
 	if (ret) {
 		err = ret;
 		goto fail_alloc;
@@ -3029,8 +3029,9 @@ int open_ctree(struct super_block *sb,
 	if (ret)
 		goto fail_trans_kthread;
 
-	/* do not make disk changes in broken FS */
-	if (btrfs_super_log_root(disk_super) != 0) {
+	/* do not make disk changes in broken FS or nologreplay is given */
+	if (btrfs_super_log_root(disk_super) != 0 &&
+	    !btrfs_test_opt(tree_root, NOLOGREPLAY)) {
 		ret = btrfs_replay_log(fs_info, fs_devices);
 		if (ret) {
 			err = ret;

commit 8dcddfa048de637c8bbfa20ffd22757aeab7c604
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Jan 19 10:23:02 2016 +0800

    btrfs: Introduce new mount option usebackuproot to replace recovery
    
    Current "recovery" mount option will only try to use backup root.
    However the word "recovery" is too generic and may be confusing for some
    users.
    
    Here introduce a new and more specific mount option, "usebackuproot" to
    replace "recovery" mount option.
    "Recovery" will be kept for compatibility reason, but will be
    deprecated.
    
    Also, since "usebackuproot" will only affect mount behavior and after
    open_ctree() it has nothing to do with the filesystem, so clear the flag
    after mount succeeded.
    
    This provides the basis for later unified "norecovery" mount option.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    [ dropped usebackuproot from show_mount, added note about 'recovery' to
      docs ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4545e2e2ad45..c0363626c5da 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3146,6 +3146,12 @@ int open_ctree(struct super_block *sb,
 
 	fs_info->open = 1;
 
+	/*
+	 * backuproot only affect mount behavior, and if open_ctree succeeded,
+	 * no need to keep the flag
+	 */
+	btrfs_clear_opt(fs_info->mount_opt, USEBACKUPROOT);
+
 	return 0;
 
 fail_qgroup:
@@ -3200,7 +3206,7 @@ int open_ctree(struct super_block *sb,
 	return err;
 
 recovery_tree_root:
-	if (!btrfs_test_opt(tree_root, RECOVERY))
+	if (!btrfs_test_opt(tree_root, USEBACKUPROOT))
 		goto fail_tree_roots;
 
 	free_root_pointers(fs_info, 0);

commit 74e4d82757f7479bab6b854783f84a5b9f2df78f
Author: David Sterba <dsterba@suse.com>
Date:   Thu Feb 11 11:01:55 2016 +0100

    btrfs: let callers of btrfs_alloc_root pass gfp flags
    
    We don't need to use GFP_NOFS in all contexts, eg. during mount or for
    dummy root tree, but we might for the the log tree creation.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4545e2e2ad45..40690e90beee 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1296,9 +1296,10 @@ static void __setup_root(u32 nodesize, u32 sectorsize, u32 stripesize,
 	spin_lock_init(&root->root_item_lock);
 }
 
-static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info)
+static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info,
+		gfp_t flags)
 {
-	struct btrfs_root *root = kzalloc(sizeof(*root), GFP_NOFS);
+	struct btrfs_root *root = kzalloc(sizeof(*root), flags);
 	if (root)
 		root->fs_info = fs_info;
 	return root;
@@ -1310,7 +1311,7 @@ struct btrfs_root *btrfs_alloc_dummy_root(void)
 {
 	struct btrfs_root *root;
 
-	root = btrfs_alloc_root(NULL);
+	root = btrfs_alloc_root(NULL, GFP_KERNEL);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 	__setup_root(4096, 4096, 4096, root, NULL, 1);
@@ -1332,7 +1333,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	int ret = 0;
 	uuid_le uuid;
 
-	root = btrfs_alloc_root(fs_info);
+	root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
@@ -1408,7 +1409,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct extent_buffer *leaf;
 
-	root = btrfs_alloc_root(fs_info);
+	root = btrfs_alloc_root(fs_info, GFP_NOFS);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
@@ -1506,7 +1507,7 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	if (!path)
 		return ERR_PTR(-ENOMEM);
 
-	root = btrfs_alloc_root(fs_info);
+	root = btrfs_alloc_root(fs_info, GFP_NOFS);
 	if (!root) {
 		ret = -ENOMEM;
 		goto alloc_fail;
@@ -2385,7 +2386,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 		return -EIO;
 	}
 
-	log_tree_root = btrfs_alloc_root(fs_info);
+	log_tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	if (!log_tree_root)
 		return -ENOMEM;
 
@@ -2510,8 +2511,8 @@ int open_ctree(struct super_block *sb,
 	int backup_index = 0;
 	int max_active;
 
-	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info);
-	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info);
+	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
+	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info, GFP_KERNEL);
 	if (!tree_root || !chunk_root) {
 		err = -ENOMEM;
 		goto fail;
@@ -2622,7 +2623,7 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->ordered_roots);
 	spin_lock_init(&fs_info->ordered_root_lock);
 	fs_info->delayed_root = kmalloc(sizeof(struct btrfs_delayed_root),
-					GFP_NOFS);
+					GFP_KERNEL);
 	if (!fs_info->delayed_root) {
 		err = -ENOMEM;
 		goto fail_iput;

commit bc696ca05f5a8927329ec276a892341e006b00ba
Author: Borislav Petkov <bp@suse.de>
Date:   Tue Jan 26 22:12:05 2016 +0100

    x86/cpufeature: Replace the old static_cpu_has() with safe variant
    
    So the old one didn't work properly before alternatives had run.
    And it was supposed to provide an optimized JMP because the
    assumption was that the offset it is jumping to is within a
    signed byte and thus a two-byte JMP.
    
    So I did an x86_64 allyesconfig build and dumped all possible
    sites where static_cpu_has() was used. The optimization amounted
    to all in all 12(!) places where static_cpu_has() had generated
    a 2-byte JMP. Which has saved us a whopping 36 bytes!
    
    This clearly is not worth the trouble so we can remove it. The
    only place where the optimization might count - in __switch_to()
    - we will handle differently. But that's not subject of this
    patch.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1453842730-28463-6-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dd08e29f5117..d9286497924f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -930,7 +930,7 @@ static int check_async_write(struct inode *inode, unsigned long bio_flags)
 	if (bio_flags & EXTENT_BIO_TREE_LOG)
 		return 0;
 #ifdef CONFIG_X86
-	if (static_cpu_has_safe(X86_FEATURE_XMM4_2))
+	if (static_cpu_has(X86_FEATURE_XMM4_2))
 		return 0;
 #endif
 	return 1;

commit d3f71ae711cebdeaff12989761f48bd4230e83d5
Merge: 46552e68acf7 e410e34fad91
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 29 15:46:49 2016 -0800

    Merge branch 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "Dave had a small collection of fixes to the new free space tree code,
      one of which was keeping our sysfs files more up to date with feature
      bits as different things get enabled (lzo, raid5/6, etc).
    
      I should have kept the sysfs stuff for rc3, since we always manage to
      trip over something.  This time it was GFP_KERNEL from somewhere that
      is NOFS only.  Instead of rebasing it out I've put a revert in, and
      we'll fix it properly for rc3.
    
      Otherwise, Filipe fixed a btrfs DIO race and Qu Wenruo fixed up a
      use-after-free in our tracepoints that Dave Jones reported"
    
    * 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Revert "btrfs: synchronize incompat feature bits with sysfs files"
      btrfs: don't use GFP_HIGHMEM for free-space-tree bitmap kzalloc
      btrfs: sysfs: check initialization state before updating features
      Revert "btrfs: clear PF_NOFREEZE in cleaner_kthread()"
      btrfs: async-thread: Fix a use-after-free error for trace
      Btrfs: fix race between fsync and lockless direct IO writes
      btrfs: add free space tree to the cow-only list
      btrfs: add free space tree to lockdep classes
      btrfs: tweak free space tree bitmap allocation
      btrfs: tests: switch to GFP_KERNEL
      btrfs: synchronize incompat feature bits with sysfs files
      btrfs: sysfs: introduce helper for syncing bits with sysfs files
      btrfs: sysfs: add free-space-tree bit attribute
      btrfs: sysfs: fix typo in compat_ro attribute definition

commit d32a4e34348869a273a01139112a13fc6870f003
Merge: bf6092066f80 3e4c5efbb3ac
Author: Chris Mason <clm@fb.com>
Date:   Wed Jan 27 05:48:23 2016 -0800

    Merge branch 'dev/fst-followup' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.5

commit 80ad623edd2d0ccb47d85357ee31c97e6c684e82
Author: David Sterba <dsterba@suse.com>
Date:   Mon Jan 25 11:02:06 2016 +0100

    Revert "btrfs: clear PF_NOFREEZE in cleaner_kthread()"
    
    This reverts commit 696249132158014d594896df3a81390616069c5c. The
    cleaner thread can block freezing when there's a snapshot cleaning in
    progress and the other threads get suspended first. From the logs
    provided by Martin we're waiting for reading extent pages:
    
    kernel: PM: Syncing filesystems ... done.
    kernel: Freezing user space processes ... (elapsed 0.015 seconds) done.
    kernel: Freezing remaining freezable tasks ...
    kernel: Freezing of tasks failed after 20.003 seconds (1 tasks refusing to freeze, wq_busy=0):
    kernel: btrfs-cleaner   D ffff88033dd13bc0     0   152      2 0x00000000
    kernel: ffff88032ebc2e00 ffff88032e750000 ffff88032e74fa50 7fffffffffffffff
    kernel: ffffffff814a58df 0000000000000002 ffffea000934d580 ffffffff814a5451
    kernel: 7fffffffffffffff ffffffff814a6e8f 0000000000000000 0000000000000020
    kernel: Call Trace:
    kernel: [<ffffffff814a58df>] ? bit_wait+0x2c/0x2c
    kernel: [<ffffffff814a5451>] ? schedule+0x6f/0x7c
    kernel: [<ffffffff814a6e8f>] ? schedule_timeout+0x2f/0xd8
    kernel: [<ffffffff81076f94>] ? timekeeping_get_ns+0xa/0x2e
    kernel: [<ffffffff81077603>] ? ktime_get+0x36/0x44
    kernel: [<ffffffff814a4f6c>] ? io_schedule_timeout+0x94/0xf2
    kernel: [<ffffffff814a4f6c>] ? io_schedule_timeout+0x94/0xf2
    kernel: [<ffffffff814a590b>] ? bit_wait_io+0x2c/0x30
    kernel: [<ffffffff814a5694>] ? __wait_on_bit+0x41/0x73
    kernel: [<ffffffff8109eba8>] ? wait_on_page_bit+0x6d/0x72
    kernel: [<ffffffff8105d718>] ? autoremove_wake_function+0x2a/0x2a
    kernel: [<ffffffff811a02d7>] ? read_extent_buffer_pages+0x1bd/0x203
    kernel: [<ffffffff8117d9e9>] ? free_root_pointers+0x4c/0x4c
    kernel: [<ffffffff8117e831>] ? btree_read_extent_buffer_pages.constprop.57+0x5a/0xe9
    kernel: [<ffffffff8117f4f3>] ? read_tree_block+0x2d/0x45
    kernel: [<ffffffff8116782a>] ? read_block_for_search.isra.34+0x22a/0x26b
    kernel: [<ffffffff811656c3>] ? btrfs_set_path_blocking+0x1e/0x4a
    kernel: [<ffffffff8116919b>] ? btrfs_search_slot+0x648/0x736
    kernel: [<ffffffff81170559>] ? btrfs_lookup_extent_info+0xb7/0x2c7
    kernel: [<ffffffff81170ee5>] ? walk_down_proc+0x9c/0x1ae
    kernel: [<ffffffff81171c9d>] ? walk_down_tree+0x40/0xa4
    kernel: [<ffffffff8117375f>] ? btrfs_drop_snapshot+0x2da/0x664
    kernel: [<ffffffff8104ff21>] ? finish_task_switch+0x126/0x167
    kernel: [<ffffffff811850f8>] ? btrfs_clean_one_deleted_snapshot+0xa6/0xb0
    kernel: [<ffffffff8117eaba>] ? cleaner_kthread+0x13e/0x17b
    kernel: [<ffffffff8117e97c>] ? btrfs_item_end+0x33/0x33
    kernel: [<ffffffff8104d256>] ? kthread+0x95/0x9d
    kernel: [<ffffffff8104d1c1>] ? kthread_parkme+0x16/0x16
    kernel: [<ffffffff814a7b5f>] ? ret_from_fork+0x3f/0x70
    kernel: [<ffffffff8104d1c1>] ? kthread_parkme+0x16/0x16
    
    As this affects a released kernel (4.4) we need a minimal fix for
    stable kernels.
    
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=108361
    Reported-by: Martin Ziegler <ziegler@uni-freiburg.de>
    CC: stable@vger.kernel.org # 4.4
    CC: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 26ef14152093..404e894c33d9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1787,7 +1787,6 @@ static int cleaner_kthread(void *arg)
 	int again;
 	struct btrfs_trans_handle *trans;
 
-	set_freezable();
 	do {
 		again = 0;
 

commit 6b20e0ad2e39b77b7d4a48cc06c4de39768c7bb8
Author: David Sterba <dsterba@suse.com>
Date:   Mon Jan 25 16:30:22 2016 +0100

    btrfs: add free space tree to lockdep classes
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c67c129fe99a..ca78bf2ed287 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -176,6 +176,7 @@ static struct btrfs_lockdep_keyset {
 	{ .id = BTRFS_TREE_RELOC_OBJECTID,	.name_stem = "treloc"	},
 	{ .id = BTRFS_DATA_RELOC_TREE_OBJECTID,	.name_stem = "dreloc"	},
 	{ .id = BTRFS_UUID_TREE_OBJECTID,	.name_stem = "uuid"	},
+	{ .id = BTRFS_FREE_SPACE_TREE_OBJECTID,	.name_stem = "free-space" },
 	{ .id = 0,				.name_stem = "tree"	},
 };
 

commit 2101ae42899a14fe7caa73114e2161e778328661
Merge: 391f2a16b74b a6111d11b8b5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 22 11:49:21 2016 -0800

    Merge branch 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull more btrfs updates from Chris Mason:
     "These are mostly fixes that we've been testing, but also we grabbed
      and tested a few small cleanups that had been on the list for a while.
    
      Zhao Lei's patchset also fixes some early ENOSPC buglets"
    
    * 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (21 commits)
      btrfs: raid56: Use raid_write_end_io for scrub
      btrfs: Remove unnecessary ClearPageUptodate for raid56
      btrfs: use rbio->nr_pages to reduce calculation
      btrfs: Use unified stripe_page's index calculation
      btrfs: Fix calculation of rbio->dbitmap's size calculation
      btrfs: Fix no_space in write and rm loop
      btrfs: merge functions for wait snapshot creation
      btrfs: delete unused argument in btrfs_copy_from_user
      btrfs: Use direct way to determine raid56 write/recover mode
      btrfs: Small cleanup for get index_srcdev loop
      btrfs: Enhance chunk validation check
      btrfs: Enhance super validation check
      Btrfs: fix deadlock running delayed iputs at transaction commit time
      Btrfs: fix typo in log message when starting a balance
      btrfs: remove duplicate const specifier
      btrfs: initialize the seq counter in struct btrfs_device
      Btrfs: clean up an error code in btrfs_init_space_info()
      btrfs: fix iterator with update error in backref.c
      Btrfs: fix output of compression message in btrfs_parse_options()
      Btrfs: Initialize btrfs_root->highest_objectid when loading tree root and subvolume roots
      ...

commit 319e4d0661e5323c9f9945f0f8fb5905e5fe74c3
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Dec 15 09:14:36 2015 +0800

    btrfs: Enhance super validation check
    
    Enhance btrfs_check_super_valid() function by the following points:
    1) Restrict sector/node size check
       Not the old max/min valid check, but also check if it's a power of 2.
       So some bogus number like 12K node size won't pass now.
    
    2) Super flag check
       For now, there is still some inconsistency between kernel and
       btrfs-progs super flags.
       And considering btrfs-progs may add new flags for super block, this
       check will only output warning.
    
    3) Better root alignment check
       Now root bytenr is checked against sector size.
    
    4) Move some check into btrfs_check_super_valid().
       Like node size vs leaf size check, and PAGESIZE vs sectorsize check.
       And magic number check.
    
    Reported-by: Vegard Nossum <vegard.nossum@oracle.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index be03f93ca257..26ef14152093 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -55,6 +55,12 @@
 #include <asm/cpufeature.h>
 #endif
 
+#define BTRFS_SUPER_FLAG_SUPP	(BTRFS_HEADER_FLAG_WRITTEN |\
+				 BTRFS_HEADER_FLAG_RELOC |\
+				 BTRFS_SUPER_FLAG_ERROR |\
+				 BTRFS_SUPER_FLAG_SEEDING |\
+				 BTRFS_SUPER_FLAG_METADUMP)
+
 static const struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
@@ -2760,26 +2766,6 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
-	/*
-	 * Leafsize and nodesize were always equal, this is only a sanity check.
-	 */
-	if (le32_to_cpu(disk_super->__unused_leafsize) !=
-	    btrfs_super_nodesize(disk_super)) {
-		printk(KERN_ERR "BTRFS: couldn't mount because metadata "
-		       "blocksizes don't match.  node %d leaf %d\n",
-		       btrfs_super_nodesize(disk_super),
-		       le32_to_cpu(disk_super->__unused_leafsize));
-		err = -EINVAL;
-		goto fail_alloc;
-	}
-	if (btrfs_super_nodesize(disk_super) > BTRFS_MAX_METADATA_BLOCKSIZE) {
-		printk(KERN_ERR "BTRFS: couldn't mount because metadata "
-		       "blocksize (%d) was too large\n",
-		       btrfs_super_nodesize(disk_super));
-		err = -EINVAL;
-		goto fail_alloc;
-	}
-
 	features = btrfs_super_incompat_flags(disk_super);
 	features |= BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF;
 	if (tree_root->fs_info->compress_type == BTRFS_COMPRESS_LZO)
@@ -2851,17 +2837,6 @@ int open_ctree(struct super_block *sb,
 	sb->s_blocksize = sectorsize;
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
 
-	if (btrfs_super_magic(disk_super) != BTRFS_MAGIC) {
-		printk(KERN_ERR "BTRFS: valid FS not found on %s\n", sb->s_id);
-		goto fail_sb_buffer;
-	}
-
-	if (sectorsize != PAGE_SIZE) {
-		printk(KERN_ERR "BTRFS: incompatible sector size (%lu) "
-		       "found on %s\n", (unsigned long)sectorsize, sb->s_id);
-		goto fail_sb_buffer;
-	}
-
 	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);
@@ -4048,8 +4023,17 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 			      int read_only)
 {
 	struct btrfs_super_block *sb = fs_info->super_copy;
+	u64 nodesize = btrfs_super_nodesize(sb);
+	u64 sectorsize = btrfs_super_sectorsize(sb);
 	int ret = 0;
 
+	if (btrfs_super_magic(sb) != BTRFS_MAGIC) {
+		printk(KERN_ERR "BTRFS: no valid FS found\n");
+		ret = -EINVAL;
+	}
+	if (btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP)
+		printk(KERN_WARNING "BTRFS: unrecognized super flag: %llu\n",
+				btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP);
 	if (btrfs_super_root_level(sb) >= BTRFS_MAX_LEVEL) {
 		printk(KERN_ERR "BTRFS: tree_root level too big: %d >= %d\n",
 				btrfs_super_root_level(sb), BTRFS_MAX_LEVEL);
@@ -4067,31 +4051,46 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	}
 
 	/*
-	 * The common minimum, we don't know if we can trust the nodesize/sectorsize
-	 * items yet, they'll be verified later. Issue just a warning.
+	 * Check sectorsize and nodesize first, other check will need it.
+	 * Check all possible sectorsize(4K, 8K, 16K, 32K, 64K) here.
 	 */
-	if (!IS_ALIGNED(btrfs_super_root(sb), 4096))
+	if (!is_power_of_2(sectorsize) || sectorsize < 4096 ||
+	    sectorsize > BTRFS_MAX_METADATA_BLOCKSIZE) {
+		printk(KERN_ERR "BTRFS: invalid sectorsize %llu\n", sectorsize);
+		ret = -EINVAL;
+	}
+	/* Only PAGE SIZE is supported yet */
+	if (sectorsize != PAGE_CACHE_SIZE) {
+		printk(KERN_ERR "BTRFS: sectorsize %llu not supported yet, only support %lu\n",
+				sectorsize, PAGE_CACHE_SIZE);
+		ret = -EINVAL;
+	}
+	if (!is_power_of_2(nodesize) || nodesize < sectorsize ||
+	    nodesize > BTRFS_MAX_METADATA_BLOCKSIZE) {
+		printk(KERN_ERR "BTRFS: invalid nodesize %llu\n", nodesize);
+		ret = -EINVAL;
+	}
+	if (nodesize != le32_to_cpu(sb->__unused_leafsize)) {
+		printk(KERN_ERR "BTRFS: invalid leafsize %u, should be %llu\n",
+				le32_to_cpu(sb->__unused_leafsize),
+				nodesize);
+		ret = -EINVAL;
+	}
+
+	/* Root alignment check */
+	if (!IS_ALIGNED(btrfs_super_root(sb), sectorsize)) {
 		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
 				btrfs_super_root(sb));
-	if (!IS_ALIGNED(btrfs_super_chunk_root(sb), 4096))
+		ret = -EINVAL;
+	}
+	if (!IS_ALIGNED(btrfs_super_chunk_root(sb), sectorsize)) {
 		printk(KERN_WARNING "BTRFS: chunk_root block unaligned: %llu\n",
 				btrfs_super_chunk_root(sb));
-	if (!IS_ALIGNED(btrfs_super_log_root(sb), 4096))
-		printk(KERN_WARNING "BTRFS: log_root block unaligned: %llu\n",
-				btrfs_super_log_root(sb));
-
-	/*
-	 * Check the lower bound, the alignment and other constraints are
-	 * checked later.
-	 */
-	if (btrfs_super_nodesize(sb) < 4096) {
-		printk(KERN_ERR "BTRFS: nodesize too small: %u < 4096\n",
-				btrfs_super_nodesize(sb));
 		ret = -EINVAL;
 	}
-	if (btrfs_super_sectorsize(sb) < 4096) {
-		printk(KERN_ERR "BTRFS: sectorsize too small: %u < 4096\n",
-				btrfs_super_sectorsize(sb));
+	if (!IS_ALIGNED(btrfs_super_log_root(sb), sectorsize)) {
+		printk(KERN_WARNING "BTRFS: log_root block unaligned: %llu\n",
+				btrfs_super_log_root(sb));
 		ret = -EINVAL;
 	}
 

commit c2d6cb1636d235257086f939a8194ef0bf93af6e
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Jan 15 11:05:12 2016 +0000

    Btrfs: fix deadlock running delayed iputs at transaction commit time
    
    While running a stress test I ran into a deadlock when running the delayed
    iputs at transaction time, which produced the following report and trace:
    
    [  886.399989] =============================================
    [  886.400871] [ INFO: possible recursive locking detected ]
    [  886.401663] 4.4.0-rc6-btrfs-next-18+ #1 Not tainted
    [  886.402384] ---------------------------------------------
    [  886.403182] fio/8277 is trying to acquire lock:
    [  886.403568]  (&fs_info->delayed_iput_sem){++++..}, at: [<ffffffffa0538823>] btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.403568]
    [  886.403568] but task is already holding lock:
    [  886.403568]  (&fs_info->delayed_iput_sem){++++..}, at: [<ffffffffa0538823>] btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.403568]
    [  886.403568] other info that might help us debug this:
    [  886.403568]  Possible unsafe locking scenario:
    [  886.403568]
    [  886.403568]        CPU0
    [  886.403568]        ----
    [  886.403568]   lock(&fs_info->delayed_iput_sem);
    [  886.403568]   lock(&fs_info->delayed_iput_sem);
    [  886.403568]
    [  886.403568]  *** DEADLOCK ***
    [  886.403568]
    [  886.403568]  May be due to missing lock nesting notation
    [  886.403568]
    [  886.403568] 3 locks held by fio/8277:
    [  886.403568]  #0:  (sb_writers#11){.+.+.+}, at: [<ffffffff81174c4c>] __sb_start_write+0x5f/0xb0
    [  886.403568]  #1:  (&sb->s_type->i_mutex_key#15){+.+.+.}, at: [<ffffffffa054620d>] btrfs_file_write_iter+0x73/0x408 [btrfs]
    [  886.403568]  #2:  (&fs_info->delayed_iput_sem){++++..}, at: [<ffffffffa0538823>] btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.403568]
    [  886.403568] stack backtrace:
    [  886.403568] CPU: 6 PID: 8277 Comm: fio Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [  886.403568] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [  886.403568]  0000000000000000 ffff88009f80f770 ffffffff8125d4fd ffffffff82af1fc0
    [  886.403568]  ffff88009f80f830 ffffffff8108e5f9 0000000200000000 ffff88009fd92290
    [  886.403568]  0000000000000000 ffffffff82af1fc0 ffffffff829cfb01 00042b216d008804
    [  886.403568] Call Trace:
    [  886.403568]  [<ffffffff8125d4fd>] dump_stack+0x4e/0x79
    [  886.403568]  [<ffffffff8108e5f9>] __lock_acquire+0xd42/0xf0b
    [  886.403568]  [<ffffffff810c22db>] ? __module_address+0xdf/0x108
    [  886.403568]  [<ffffffff8108eb77>] lock_acquire+0x10d/0x194
    [  886.403568]  [<ffffffff8108eb77>] ? lock_acquire+0x10d/0x194
    [  886.403568]  [<ffffffffa0538823>] ? btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.489542]  [<ffffffff8148556b>] down_read+0x3e/0x4d
    [  886.489542]  [<ffffffffa0538823>] ? btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.489542]  [<ffffffffa0538823>] btrfs_run_delayed_iputs+0x36/0xbf [btrfs]
    [  886.489542]  [<ffffffffa0533953>] btrfs_commit_transaction+0x8f5/0x96e [btrfs]
    [  886.489542]  [<ffffffffa0521d7a>] flush_space+0x435/0x44a [btrfs]
    [  886.489542]  [<ffffffffa052218b>] ? reserve_metadata_bytes+0x26a/0x384 [btrfs]
    [  886.489542]  [<ffffffffa05221ae>] reserve_metadata_bytes+0x28d/0x384 [btrfs]
    [  886.489542]  [<ffffffffa052256c>] ? btrfs_block_rsv_refill+0x58/0x96 [btrfs]
    [  886.489542]  [<ffffffffa0522584>] btrfs_block_rsv_refill+0x70/0x96 [btrfs]
    [  886.489542]  [<ffffffffa053d747>] btrfs_evict_inode+0x394/0x55a [btrfs]
    [  886.489542]  [<ffffffff81188e31>] evict+0xa7/0x15c
    [  886.489542]  [<ffffffff81189878>] iput+0x1d3/0x266
    [  886.489542]  [<ffffffffa053887c>] btrfs_run_delayed_iputs+0x8f/0xbf [btrfs]
    [  886.489542]  [<ffffffffa0533953>] btrfs_commit_transaction+0x8f5/0x96e [btrfs]
    [  886.489542]  [<ffffffff81085096>] ? signal_pending_state+0x31/0x31
    [  886.489542]  [<ffffffffa0521191>] btrfs_alloc_data_chunk_ondemand+0x1d7/0x288 [btrfs]
    [  886.489542]  [<ffffffffa0521282>] btrfs_check_data_free_space+0x40/0x59 [btrfs]
    [  886.489542]  [<ffffffffa05228f5>] btrfs_delalloc_reserve_space+0x1e/0x4e [btrfs]
    [  886.489542]  [<ffffffffa053620a>] btrfs_direct_IO+0x10c/0x27e [btrfs]
    [  886.489542]  [<ffffffff8111d9a1>] generic_file_direct_write+0xb3/0x128
    [  886.489542]  [<ffffffffa05463c3>] btrfs_file_write_iter+0x229/0x408 [btrfs]
    [  886.489542]  [<ffffffff8108ae38>] ? __lock_is_held+0x38/0x50
    [  886.489542]  [<ffffffff8117279e>] __vfs_write+0x7c/0xa5
    [  886.489542]  [<ffffffff81172cda>] vfs_write+0xa0/0xe4
    [  886.489542]  [<ffffffff811734cc>] SyS_write+0x50/0x7e
    [  886.489542]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [ 1081.852335] INFO: task fio:8244 blocked for more than 120 seconds.
    [ 1081.854348]       Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [ 1081.857560] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [ 1081.863227] fio        D ffff880213f9bb28     0  8244   8240 0x00000000
    [ 1081.868719]  ffff880213f9bb28 00ffffff810fc6b0 ffffffff0000000a ffff88023ed55240
    [ 1081.872499]  ffff880206b5d400 ffff880213f9c000 ffff88020a4d5318 ffff880206b5d400
    [ 1081.876834]  ffffffff00000001 ffff880206b5d400 ffff880213f9bb40 ffffffff81482ba4
    [ 1081.880782] Call Trace:
    [ 1081.881793]  [<ffffffff81482ba4>] schedule+0x7f/0x97
    [ 1081.883340]  [<ffffffff81485eb5>] rwsem_down_write_failed+0x2d5/0x325
    [ 1081.895525]  [<ffffffff8108d48d>] ? trace_hardirqs_on_caller+0x16/0x1ab
    [ 1081.897419]  [<ffffffff81269723>] call_rwsem_down_write_failed+0x13/0x20
    [ 1081.899251]  [<ffffffff81269723>] ? call_rwsem_down_write_failed+0x13/0x20
    [ 1081.901063]  [<ffffffff81089fae>] ? __down_write_nested.isra.0+0x1f/0x21
    [ 1081.902365]  [<ffffffff814855bd>] down_write+0x43/0x57
    [ 1081.903846]  [<ffffffffa05211b0>] ? btrfs_alloc_data_chunk_ondemand+0x1f6/0x288 [btrfs]
    [ 1081.906078]  [<ffffffffa05211b0>] btrfs_alloc_data_chunk_ondemand+0x1f6/0x288 [btrfs]
    [ 1081.908846]  [<ffffffff8108d461>] ? mark_held_locks+0x56/0x6c
    [ 1081.910409]  [<ffffffffa0521282>] btrfs_check_data_free_space+0x40/0x59 [btrfs]
    [ 1081.912482]  [<ffffffffa05228f5>] btrfs_delalloc_reserve_space+0x1e/0x4e [btrfs]
    [ 1081.914597]  [<ffffffffa053620a>] btrfs_direct_IO+0x10c/0x27e [btrfs]
    [ 1081.919037]  [<ffffffff8111d9a1>] generic_file_direct_write+0xb3/0x128
    [ 1081.920754]  [<ffffffffa05463c3>] btrfs_file_write_iter+0x229/0x408 [btrfs]
    [ 1081.922496]  [<ffffffff8108ae38>] ? __lock_is_held+0x38/0x50
    [ 1081.923922]  [<ffffffff8117279e>] __vfs_write+0x7c/0xa5
    [ 1081.925275]  [<ffffffff81172cda>] vfs_write+0xa0/0xe4
    [ 1081.926584]  [<ffffffff811734cc>] SyS_write+0x50/0x7e
    [ 1081.927968]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [ 1081.985293] INFO: lockdep is turned off.
    [ 1081.986132] INFO: task fio:8249 blocked for more than 120 seconds.
    [ 1081.987434]       Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [ 1081.988534] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [ 1081.990147] fio        D ffff880218febbb8     0  8249   8240 0x00000000
    [ 1081.991626]  ffff880218febbb8 00ffffff81486b8e ffff88020000000b ffff88023ed75240
    [ 1081.993258]  ffff8802120a9a00 ffff880218fec000 ffff88020a4d5318 ffff8802120a9a00
    [ 1081.994850]  ffffffff00000001 ffff8802120a9a00 ffff880218febbd0 ffffffff81482ba4
    [ 1081.996485] Call Trace:
    [ 1081.997037]  [<ffffffff81482ba4>] schedule+0x7f/0x97
    [ 1081.998017]  [<ffffffff81485eb5>] rwsem_down_write_failed+0x2d5/0x325
    [ 1081.999241]  [<ffffffff810852a5>] ? finish_wait+0x6d/0x76
    [ 1082.000306]  [<ffffffff81269723>] call_rwsem_down_write_failed+0x13/0x20
    [ 1082.001533]  [<ffffffff81269723>] ? call_rwsem_down_write_failed+0x13/0x20
    [ 1082.002776]  [<ffffffff81089fae>] ? __down_write_nested.isra.0+0x1f/0x21
    [ 1082.003995]  [<ffffffff814855bd>] down_write+0x43/0x57
    [ 1082.005000]  [<ffffffffa05211b0>] ? btrfs_alloc_data_chunk_ondemand+0x1f6/0x288 [btrfs]
    [ 1082.007403]  [<ffffffffa05211b0>] btrfs_alloc_data_chunk_ondemand+0x1f6/0x288 [btrfs]
    [ 1082.008988]  [<ffffffffa0545064>] btrfs_fallocate+0x7c1/0xc2f [btrfs]
    [ 1082.010193]  [<ffffffff8108a1ba>] ? percpu_down_read+0x4e/0x77
    [ 1082.011280]  [<ffffffff81174c4c>] ? __sb_start_write+0x5f/0xb0
    [ 1082.012265]  [<ffffffff81174c4c>] ? __sb_start_write+0x5f/0xb0
    [ 1082.013021]  [<ffffffff811712e4>] vfs_fallocate+0x170/0x1ff
    [ 1082.013738]  [<ffffffff81181ebb>] ioctl_preallocate+0x89/0x9b
    [ 1082.014778]  [<ffffffff811822d7>] do_vfs_ioctl+0x40a/0x4ea
    [ 1082.015778]  [<ffffffff81176ea7>] ? SYSC_newfstat+0x25/0x2e
    [ 1082.016806]  [<ffffffff8118b4de>] ? __fget_light+0x4d/0x71
    [ 1082.017789]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [ 1082.018706]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    
    This happens because we can recursively acquire the semaphore
    fs_info->delayed_iput_sem when attempting to allocate space to satisfy
    a file write request as shown in the first trace above - when committing
    a transaction we acquire (down_read) the semaphore before running the
    delayed iputs, and when running a delayed iput() we can end up calling
    an inode's eviction handler, which in turn commits another transaction
    and attempts to acquire (down_read) again the semaphore to run more
    delayed iput operations.
    This results in a deadlock because if a task acquires multiple times a
    semaphore it should invoke down_read_nested() with a different lockdep
    class for each level of recursion.
    
    Fix this by simplifying the implementation and use a mutex instead that
    is acquired by the cleaner kthread before it runs the delayed iputs
    instead of always acquiring a semaphore before delayed references are
    run from anywhere.
    
    Fixes: d7c151717a1e (btrfs: Fix NO_SPACE bug caused by delayed-iput)
    Cc: stable@vger.kernel.org   # 4.1+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 64f02c3d0dd0..be03f93ca257 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1801,7 +1801,10 @@ static int cleaner_kthread(void *arg)
 			goto sleep;
 		}
 
+		mutex_lock(&root->fs_info->cleaner_delayed_iput_mutex);
 		btrfs_run_delayed_iputs(root);
+		mutex_unlock(&root->fs_info->cleaner_delayed_iput_mutex);
+
 		again = btrfs_clean_one_deleted_snapshot(root);
 		mutex_unlock(&root->fs_info->cleaner_mutex);
 
@@ -2571,8 +2574,8 @@ int open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->delete_unused_bgs_mutex);
 	mutex_init(&fs_info->reloc_mutex);
 	mutex_init(&fs_info->delalloc_root_mutex);
+	mutex_init(&fs_info->cleaner_delayed_iput_mutex);
 	seqlock_init(&fs_info->profiles_lock);
-	init_rwsem(&fs_info->delayed_iput_sem);
 
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
 	INIT_LIST_HEAD(&fs_info->space_info);

commit 326f784281fbbdcd91bb401b2a3e32132c0f5c72
Merge: acc308556c81 546bed631203
Author: Chris Mason <clm@fb.com>
Date:   Tue Jan 19 18:21:30 2016 -0800

    Merge branch 'misc-for-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.5

commit c1a198d9235b9e7d6942027374e44f78ebdcb455
Merge: 48f58ba9cbff 988f1f576d4f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 18 12:44:40 2016 -0800

    Merge branch 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This has our usual assortment of fixes and cleanups, but the biggest
      change included is Omar Sandoval's free space tree.  It's not the
      default yet, mounting -o space_cache=v2 enables it and sets a readonly
      compat bit.  The tree can actually be deleted and regenerated if there
      are any problems, but it has held up really well in testing so far.
    
      For very large filesystems (30T+) our existing free space caching code
      can end up taking a huge amount of time during commits.  The new tree
      based code is faster and less work overall to update as the commit
      progresses.
    
      Omar worked on this during the summer and we'll hammer on it in
      production here at FB over the next few months"
    
    * 'for-linus-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (73 commits)
      Btrfs: fix fitrim discarding device area reserved for boot loader's use
      Btrfs: Check metadata redundancy on balance
      btrfs: statfs: report zero available if metadata are exhausted
      btrfs: preallocate path for snapshot creation at ioctl time
      btrfs: allocate root item at snapshot ioctl time
      btrfs: do an allocation earlier during snapshot creation
      btrfs: use smaller type for btrfs_path locks
      btrfs: use smaller type for btrfs_path lowest_level
      btrfs: use smaller type for btrfs_path reada
      btrfs: cleanup, use enum values for btrfs_path reada
      btrfs: constify static arrays
      btrfs: constify remaining structs with function pointers
      btrfs tests: replace whole ops structure for free space tests
      btrfs: use list_for_each_entry* in backref.c
      btrfs: use list_for_each_entry_safe in free-space-cache.c
      btrfs: use list_for_each_entry* in check-integrity.c
      Btrfs: use linux/sizes.h to represent constants
      btrfs: cleanup, remove stray return statements
      btrfs: zero out delayed node upon allocation
      btrfs: pass proper enum type to start_transaction()
      ...

commit f32e48e925964c4f8ab917850788a87e1cef3bad
Author: Chandan Rajendra <chandan@linux.vnet.ibm.com>
Date:   Thu Jan 7 18:56:59 2016 +0530

    Btrfs: Initialize btrfs_root->highest_objectid when loading tree root and subvolume roots
    
    The following call trace is seen when btrfs/031 test is executed in a loop,
    
    [  158.661848] ------------[ cut here ]------------
    [  158.662634] WARNING: CPU: 2 PID: 890 at /home/chandan/repos/linux/fs/btrfs/ioctl.c:558 create_subvol+0x3d1/0x6ea()
    [  158.664102] BTRFS: Transaction aborted (error -2)
    [  158.664774] Modules linked in:
    [  158.665266] CPU: 2 PID: 890 Comm: btrfs Not tainted 4.4.0-rc6-g511711a #2
    [  158.666251] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
    [  158.667392]  ffffffff81c0a6b0 ffff8806c7c4f8e8 ffffffff81431fc8 ffff8806c7c4f930
    [  158.668515]  ffff8806c7c4f920 ffffffff81051aa1 ffff880c85aff000 ffff8800bb44d000
    [  158.669647]  ffff8808863b5c98 0000000000000000 00000000fffffffe ffff8806c7c4f980
    [  158.670769] Call Trace:
    [  158.671153]  [<ffffffff81431fc8>] dump_stack+0x44/0x5c
    [  158.671884]  [<ffffffff81051aa1>] warn_slowpath_common+0x81/0xc0
    [  158.672769]  [<ffffffff81051b27>] warn_slowpath_fmt+0x47/0x50
    [  158.673620]  [<ffffffff813bc98d>] create_subvol+0x3d1/0x6ea
    [  158.674440]  [<ffffffff813777c9>] btrfs_mksubvol.isra.30+0x369/0x520
    [  158.675376]  [<ffffffff8108a4aa>] ? percpu_down_read+0x1a/0x50
    [  158.676235]  [<ffffffff81377a81>] btrfs_ioctl_snap_create_transid+0x101/0x180
    [  158.677268]  [<ffffffff81377b52>] btrfs_ioctl_snap_create+0x52/0x70
    [  158.678183]  [<ffffffff8137afb4>] btrfs_ioctl+0x474/0x2f90
    [  158.678975]  [<ffffffff81144b8e>] ? vma_merge+0xee/0x300
    [  158.679751]  [<ffffffff8115be31>] ? alloc_pages_vma+0x91/0x170
    [  158.680599]  [<ffffffff81123f62>] ? lru_cache_add_active_or_unevictable+0x22/0x70
    [  158.681686]  [<ffffffff813d99cf>] ? selinux_file_ioctl+0xff/0x1d0
    [  158.682581]  [<ffffffff8117b791>] do_vfs_ioctl+0x2c1/0x490
    [  158.683399]  [<ffffffff813d3cde>] ? security_file_ioctl+0x3e/0x60
    [  158.684297]  [<ffffffff8117b9d4>] SyS_ioctl+0x74/0x80
    [  158.685051]  [<ffffffff819b2bd7>] entry_SYSCALL_64_fastpath+0x12/0x6a
    [  158.685958] ---[ end trace 4b63312de5a2cb76 ]---
    [  158.686647] BTRFS: error (device loop0) in create_subvol:558: errno=-2 No such entry
    [  158.709508] BTRFS info (device loop0): forced readonly
    [  158.737113] BTRFS info (device loop0): disk space caching is enabled
    [  158.738096] BTRFS error (device loop0): Remounting read-write after error is not allowed
    [  158.851303] BTRFS error (device loop0): cleaner transaction attach returned -30
    
    This occurs because,
    
    Mount filesystem
    Create subvol with ID 257
    Unmount filesystem
    Mount filesystem
    Delete subvol with ID 257
      btrfs_drop_snapshot()
        Add root corresponding to subvol 257 into
        btrfs_transaction->dropped_roots list
    Create new subvol (i.e. create_subvol())
      257 is returned as the next free objectid
      btrfs_read_fs_root_no_name()
        Finds the btrfs_root instance corresponding to the old subvol with ID 257
        in btrfs_fs_info->fs_roots_radix.
        Returns error since btrfs_root_item->refs has the value of 0.
    
    To fix the issue the commit initializes tree root's and subvolume root's
    highest_objectid when loading the roots from disk.
    
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 216f97765b56..868736dbe6ee 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1582,8 +1582,23 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 	ret = get_anon_bdev(&root->anon_dev);
 	if (ret)
 		goto free_writers;
+
+	mutex_lock(&root->objectid_mutex);
+	ret = btrfs_find_highest_objectid(root,
+					&root->highest_objectid);
+	if (ret) {
+		mutex_unlock(&root->objectid_mutex);
+		goto free_root_dev;
+	}
+
+	ASSERT(root->highest_objectid <= BTRFS_LAST_FREE_OBJECTID);
+
+	mutex_unlock(&root->objectid_mutex);
+
 	return 0;
 
+free_root_dev:
+	free_anon_bdev(root->anon_dev);
 free_writers:
 	btrfs_free_subvolume_writers(root->subv_writers);
 fail:
@@ -2901,6 +2916,18 @@ int open_ctree(struct super_block *sb,
 	tree_root->commit_root = btrfs_root_node(tree_root);
 	btrfs_set_root_refs(&tree_root->root_item, 1);
 
+	mutex_lock(&tree_root->objectid_mutex);
+	ret = btrfs_find_highest_objectid(tree_root,
+					&tree_root->highest_objectid);
+	if (ret) {
+		mutex_unlock(&tree_root->objectid_mutex);
+		goto recovery_tree_root;
+	}
+
+	ASSERT(tree_root->highest_objectid <= BTRFS_LAST_FREE_OBJECTID);
+
+	mutex_unlock(&tree_root->objectid_mutex);
+
 	ret = btrfs_read_roots(fs_info, tree_root);
 	if (ret)
 		goto recovery_tree_root;

commit b28cf57246d5b797ba725bb033110c247f2c301f
Merge: a3058101c17d a7ca42256d9f
Author: Chris Mason <clm@fb.com>
Date:   Mon Jan 11 06:08:37 2016 -0800

    Merge branch 'misc-cleanups-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.5
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit a3058101c17d2825f34a0ab5c37d93ead0f4d9dc
Merge: 511711af91f2 ee592d077161
Author: Chris Mason <clm@fb.com>
Date:   Mon Jan 11 05:59:32 2016 -0800

    Merge branch 'misc-for-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.5

commit ee22184b53c823f6956314c2815d4068e3820737
Author: Byongho Lee <bhlee.kernel@gmail.com>
Date:   Tue Dec 15 01:42:10 2015 +0900

    Btrfs: use linux/sizes.h to represent constants
    
    We use many constants to represent size and offset value.  And to make
    code readable we use '256 * 1024 * 1024' instead of '268435456' to
    represent '256MB'.  However we can make far more readable with 'SZ_256MB'
    which is defined in the 'linux/sizes.h'.
    
    So this patch replaces 'xxx * 1024 * 1024' kind of expression with
    single 'SZ_xxxMB' if 'xxx' is a power of 2 then 'xxx * SZ_1M' if 'xxx' is
    not a power of 2. And I haven't touched to '4096' & '8192' because it's
    more intuitive than 'SZ_4KB' & 'SZ_8KB'.
    
    Signed-off-by: Byongho Lee <bhlee.kernel@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c76f6ea3edd6..e8eebe77ec39 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2809,7 +2809,7 @@ int open_ctree(struct super_block *sb,
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
-				    4 * 1024 * 1024 / PAGE_CACHE_SIZE);
+				    SZ_4M / PAGE_CACHE_SIZE);
 
 	tree_root->nodesize = nodesize;
 	tree_root->sectorsize = sectorsize;

commit 7928d672ffb06085d06fe3c27a93549d37e53ab3
Author: David Sterba <dsterba@suse.com>
Date:   Mon Nov 30 11:02:31 2015 +0100

    btrfs: cleanup, remove stray return statements
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 974be09e7556..c76f6ea3edd6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3962,7 +3962,6 @@ static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
 		balance_dirty_pages_ratelimited(
 				   root->fs_info->btree_inode->i_mapping);
 	}
-	return;
 }
 
 void btrfs_btree_balance_dirty(struct btrfs_root *root)

commit b2acdddfad13c38a1e8b927d83c3cf321f63601a
Author: Anand Jain <anand.jain@oracle.com>
Date:   Wed Oct 7 17:23:23 2015 +0800

    Btrfs: add missing brelse when superblock checksum fails
    
    Looks like oversight, call brelse() when checksum fails. Further down the
    code, in the non error path, we do call brelse() and so we don't see
    brelse() in the goto error paths.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 974be09e7556..216f97765b56 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2668,6 +2668,7 @@ int open_ctree(struct super_block *sb,
 	if (btrfs_check_super_csum(bh->b_data)) {
 		printk(KERN_ERR "BTRFS: superblock checksum mismatch\n");
 		err = -EINVAL;
+		brelse(bh);
 		goto fail_alloc;
 	}
 

commit 511711af91f21d80b27f18b569352d6896562828
Author: Chris Mason <clm@fb.com>
Date:   Wed Dec 30 07:52:35 2015 -0800

    btrfs: don't run delayed references while we are creating the free space tree
    
    This is a short term solution to make sure btrfs_run_delayed_refs()
    doesn't change the extent tree while we are scanning it to create the
    free space tree.
    
    Longer term we need to synchronize scanning the block groups one by one,
    similar to what happens during a balance.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 823c1ce87e2e..dc6b73a95342 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3065,6 +3065,18 @@ int open_ctree(struct super_block *sb,
 	if (sb->s_flags & MS_RDONLY)
 		return 0;
 
+	if (btrfs_test_opt(tree_root, FREE_SPACE_TREE) &&
+	    !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
+		pr_info("BTRFS: creating free space tree\n");
+		ret = btrfs_create_free_space_tree(fs_info);
+		if (ret) {
+			pr_warn("BTRFS: failed to create free space tree %d\n",
+				ret);
+			close_ctree(tree_root);
+			return ret;
+		}
+	}
+
 	down_read(&fs_info->cleanup_work_sem);
 	if ((ret = btrfs_orphan_cleanup(fs_info->fs_root)) ||
 	    (ret = btrfs_orphan_cleanup(fs_info->tree_root))) {
@@ -3102,18 +3114,6 @@ int open_ctree(struct super_block *sb,
 		}
 	}
 
-	if (btrfs_test_opt(tree_root, FREE_SPACE_TREE) &&
-	    !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
-		pr_info("BTRFS: creating free space tree\n");
-		ret = btrfs_create_free_space_tree(fs_info);
-		if (ret) {
-			pr_warn("BTRFS: failed to create free space tree %d\n",
-				ret);
-			close_ctree(tree_root);
-			return ret;
-		}
-	}
-
 	if (!fs_info->uuid_root) {
 		pr_info("BTRFS: creating UUID tree\n");
 		ret = btrfs_create_uuid_tree(fs_info);

commit f0f76413d332d74446d0ee9535a29a900c4f63e4
Merge: a53fe2576955 f7d3d2f99eea
Author: Chris Mason <clm@fb.com>
Date:   Wed Dec 23 13:29:09 2015 -0800

    Merge branch 'freespace-4.5' into for-linus-4.5

commit bb9d687618695e8291f1e6209eb3211d231f97bb
Merge: 13d5d15d6301 cd716d8fea12
Author: Chris Mason <clm@fb.com>
Date:   Wed Dec 23 13:17:42 2015 -0800

    Merge branch 'dev/simplify-set-bit' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.5
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 362f924b64ba0f4be2ee0cb697690c33d40be721
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Dec 7 10:39:41 2015 +0100

    x86/cpufeature: Remove unused and seldomly used cpu_has_xx macros
    
    Those are stupid and code should use static_cpu_has_safe() or
    boot_cpu_has() instead. Kill the least used and unused ones.
    
    The remaining ones need more careful inspection before a conversion can
    happen. On the TODO.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: http://lkml.kernel.org/r/1449481182-27541-4-git-send-email-bp@alien8.de
    Cc: David Sterba <dsterba@suse.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Matt Mackall <mpm@selenic.com>
    Cc: Chris Mason <clm@fb.com>
    Cc: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 974be09e7556..42a378a4eefb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -923,7 +923,7 @@ static int check_async_write(struct inode *inode, unsigned long bio_flags)
 	if (bio_flags & EXTENT_BIO_TREE_LOG)
 		return 0;
 #ifdef CONFIG_X86
-	if (cpu_has_xmm4_2)
+	if (static_cpu_has_safe(X86_FEATURE_XMM4_2))
 		return 0;
 #endif
 	return 1;

commit f7d3d2f99eeaa9f5c111965b1516972f4fc5e449
Merge: 9f9499ae8e64 70f6d82ec73c
Author: Chris Mason <clm@fb.com>
Date:   Fri Dec 18 11:11:10 2015 -0800

    Merge branch 'freespace-tree' into for-linus-4.5
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 70f6d82ec73c3ae2d3adc6853c5bebcd73610097
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Sep 29 20:50:38 2015 -0700

    Btrfs: add free space tree mount option
    
    Now we can finally hook up everything so we can actually use free space
    tree. The free space tree is enabled by passing the space_cache=v2 mount
    option. On the first mount with the this option set, the free space tree
    will be created and the FREE_SPACE_TREE read-only compat bit will be
    set. Any time the filesystem is mounted from then on, we must use the
    free space tree. The clear_cache option will also clear the free space
    tree.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1e60d00d4ea7..af7ac28380c2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -42,6 +42,7 @@
 #include "locking.h"
 #include "tree-log.h"
 #include "free-space-cache.h"
+#include "free-space-tree.h"
 #include "inode-map.h"
 #include "check-integrity.h"
 #include "rcu-string.h"
@@ -1647,6 +1648,9 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	if (location->objectid == BTRFS_UUID_TREE_OBJECTID)
 		return fs_info->uuid_root ? fs_info->uuid_root :
 					    ERR_PTR(-ENOENT);
+	if (location->objectid == BTRFS_FREE_SPACE_TREE_OBJECTID)
+		return fs_info->free_space_root ? fs_info->free_space_root :
+						  ERR_PTR(-ENOENT);
 again:
 	root = btrfs_lookup_fs_root(fs_info, location->objectid);
 	if (root) {
@@ -2144,6 +2148,7 @@ static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 	free_root_extent_buffers(info->uuid_root);
 	if (chunk_root)
 		free_root_extent_buffers(info->chunk_root);
+	free_root_extent_buffers(info->free_space_root);
 }
 
 void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
@@ -2445,6 +2450,15 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info,
 		fs_info->uuid_root = root;
 	}
 
+	if (btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
+		location.objectid = BTRFS_FREE_SPACE_TREE_OBJECTID;
+		root = btrfs_read_tree_root(tree_root, &location);
+		if (IS_ERR(root))
+			return PTR_ERR(root);
+		set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
+		fs_info->free_space_root = root;
+	}
+
 	return 0;
 }
 
@@ -3073,6 +3087,30 @@ int open_ctree(struct super_block *sb,
 
 	btrfs_qgroup_rescan_resume(fs_info);
 
+	if (btrfs_test_opt(tree_root, CLEAR_CACHE) &&
+	    btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
+		pr_info("BTRFS: clearing free space tree\n");
+		ret = btrfs_clear_free_space_tree(fs_info);
+		if (ret) {
+			pr_warn("BTRFS: failed to clear free space tree %d\n",
+				ret);
+			close_ctree(tree_root);
+			return ret;
+		}
+	}
+
+	if (btrfs_test_opt(tree_root, FREE_SPACE_TREE) &&
+	    !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {
+		pr_info("BTRFS: creating free space tree\n");
+		ret = btrfs_create_free_space_tree(fs_info);
+		if (ret) {
+			pr_warn("BTRFS: failed to create free space tree %d\n",
+				ret);
+			close_ctree(tree_root);
+			return ret;
+		}
+	}
+
 	if (!fs_info->uuid_root) {
 		pr_info("BTRFS: creating UUID tree\n");
 		ret = btrfs_create_uuid_tree(fs_info);

commit 4db8c528cdccb44f8ca237ca3c695d6c164fa70f
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 13:06:46 2015 +0100

    btrfs: remove a trivial helper btrfs_set_buffer_uptodate
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 974be09e7556..166ad0821ec2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3902,11 +3902,6 @@ int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,
 	return !ret;
 }
 
-int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
-{
-	return set_extent_buffer_uptodate(buf);
-}
-
 void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 {
 	struct btrfs_root *root;

commit ff13db41f184f8222aca0cb653347ccdd48a057a
Author: David Sterba <dsterba@suse.com>
Date:   Thu Dec 3 14:30:40 2015 +0100

    btrfs: drop unused parameter from lock_extent_bits
    
    We've always passed 0. Stack usage will slightly decrease.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 974be09e7556..68ceed712df2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -362,7 +362,7 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 	}
 
 	lock_extent_bits(io_tree, eb->start, eb->start + eb->len - 1,
-			 0, &cached_state);
+			 &cached_state);
 	if (extent_buffer_uptodate(eb) &&
 	    btrfs_header_generation(eb) == parent_transid) {
 		ret = 0;

commit e75cdf9898132f521df98a3ce1c280a2f85d360a
Merge: ca4ba96e02e9 d5f2e33b92b1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 13 16:30:29 2015 -0800

    Merge branch 'for-linus-4.4' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes and cleanups from Chris Mason:
     "Some of this got cherry-picked from a github repo this week, but I
      verified the patches.
    
      We have three small scrub cleanups and a collection of fixes"
    
    * 'for-linus-4.4' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      btrfs: Use fs_info directly in btrfs_delete_unused_bgs
      btrfs: Fix lost-data-profile caused by balance bg
      btrfs: Fix lost-data-profile caused by auto removing bg
      btrfs: Remove len argument from scrub_find_csum
      btrfs: Reduce unnecessary arguments in scrub_recheck_block
      btrfs: Use scrub_checksum_data and scrub_checksum_tree_block for scrub_recheck_block_checksum
      btrfs: Reset sblock->xxx_error stats before calling scrub_recheck_block_checksum
      btrfs: scrub: setup all fields for sblock_to_check
      btrfs: scrub: set error stats when tree block spanning stripes
      Btrfs: fix race when listing an inode's xattrs
      Btrfs: fix race leading to BUG_ON when running delalloc for nodatacow
      Btrfs: fix race leading to incorrect item deletion when dropping extents
      Btrfs: fix sleeping inside atomic context in qgroup rescan worker
      Btrfs: fix race waiting for qgroup rescan worker
      btrfs: qgroup: exit the rescan worker during umount
      Btrfs: fix extent accounting for partial direct IO writes

commit ad804a0b2a769a0eed29015c53fe395449c09d13
Merge: ab9f2faf8f40 5f2a2d5d423d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Nov 7 14:32:45 2015 -0800

    Merge branch 'akpm' (patches from Andrew)
    
    Merge second patch-bomb from Andrew Morton:
    
     - most of the rest of MM
    
     - procfs
    
     - lib/ updates
    
     - printk updates
    
     - bitops infrastructure tweaks
    
     - checkpatch updates
    
     - nilfs2 update
    
     - signals
    
     - various other misc bits: coredump, seqfile, kexec, pidns, zlib, ipc,
       dma-debug, dma-mapping, ...
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (102 commits)
      ipc,msg: drop dst nil validation in copy_msg
      include/linux/zutil.h: fix usage example of zlib_adler32()
      panic: release stale console lock to always get the logbuf printed out
      dma-debug: check nents in dma_sync_sg*
      dma-mapping: tidy up dma_parms default handling
      pidns: fix set/getpriority and ioprio_set/get in PRIO_USER mode
      kexec: use file name as the output message prefix
      fs, seqfile: always allow oom killer
      seq_file: reuse string_escape_str()
      fs/seq_file: use seq_* helpers in seq_hex_dump()
      coredump: change zap_threads() and zap_process() to use for_each_thread()
      coredump: ensure all coredumping tasks have SIGNAL_GROUP_COREDUMP
      signal: remove jffs2_garbage_collect_thread()->allow_signal(SIGCONT)
      signal: introduce kernel_signal_stop() to fix jffs2_garbage_collect_thread()
      signal: turn dequeue_signal_lock() into kernel_dequeue_signal()
      signals: kill block_all_signals() and unblock_all_signals()
      nilfs2: fix gcc uninitialized-variable warnings in powerpc build
      nilfs2: fix gcc unused-but-set-variable warnings
      MAINTAINERS: nilfs2: add header file for tracing
      nilfs2: add tracepoints for analyzing reading and writing metadata files
      ...

commit d0164adc89f6bb374d304ffcc375c6d2652fe67d
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Fri Nov 6 16:28:21 2015 -0800

    mm, page_alloc: distinguish between being unable to sleep, unwilling to sleep and avoiding waking kswapd
    
    __GFP_WAIT has been used to identify atomic context in callers that hold
    spinlocks or are in interrupts.  They are expected to be high priority and
    have access one of two watermarks lower than "min" which can be referred
    to as the "atomic reserve".  __GFP_HIGH users get access to the first
    lower watermark and can be called the "high priority reserve".
    
    Over time, callers had a requirement to not block when fallback options
    were available.  Some have abused __GFP_WAIT leading to a situation where
    an optimisitic allocation with a fallback option can access atomic
    reserves.
    
    This patch uses __GFP_ATOMIC to identify callers that are truely atomic,
    cannot sleep and have no alternative.  High priority users continue to use
    __GFP_HIGH.  __GFP_DIRECT_RECLAIM identifies callers that can sleep and
    are willing to enter direct reclaim.  __GFP_KSWAPD_RECLAIM to identify
    callers that want to wake kswapd for background reclaim.  __GFP_WAIT is
    redefined as a caller that is willing to enter direct reclaim and wake
    kswapd for background reclaim.
    
    This patch then converts a number of sites
    
    o __GFP_ATOMIC is used by callers that are high priority and have memory
      pools for those requests. GFP_ATOMIC uses this flag.
    
    o Callers that have a limited mempool to guarantee forward progress clear
      __GFP_DIRECT_RECLAIM but keep __GFP_KSWAPD_RECLAIM. bio allocations fall
      into this category where kswapd will still be woken but atomic reserves
      are not used as there is a one-entry mempool to guarantee progress.
    
    o Callers that are checking if they are non-blocking should use the
      helper gfpflags_allow_blocking() where possible. This is because
      checking for __GFP_WAIT as was done historically now can trigger false
      positives. Some exceptions like dm-crypt.c exist where the code intent
      is clearer if __GFP_DIRECT_RECLAIM is used instead of the helper due to
      flag manipulations.
    
    o Callers that built their own GFP flags instead of starting with GFP_KERNEL
      and friends now also need to specify __GFP_KSWAPD_RECLAIM.
    
    The first key hazard to watch out for is callers that removed __GFP_WAIT
    and was depending on access to atomic reserves for inconspicuous reasons.
    In some cases it may be appropriate for them to use __GFP_HIGH.
    
    The second key hazard is callers that assembled their own combination of
    GFP flags instead of starting with something like GFP_KERNEL.  They may
    now wish to specify __GFP_KSWAPD_RECLAIM.  It's almost certainly harmless
    if it's missed in most cases as other activity will wake kswapd.
    
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Vitaly Wool <vitalywool@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1e60d00d4ea7..c339d561e596 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2572,7 +2572,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->commit_interval = BTRFS_DEFAULT_COMMIT_INTERVAL;
 	fs_info->avg_delayed_ref_runtime = NSEC_PER_SEC >> 6; /* div by 64 */
 	/* readahead state */
-	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_WAIT);
+	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_DIRECT_RECLAIM);
 	spin_lock_init(&fs_info->reada_lock);
 
 	fs_info->thread_pool_size = min_t(unsigned long,

commit 7343dd61fd1b57c40cc06a5b5b5386df7f73c3ac
Author: Justin Maggard <jmaggard10@gmail.com>
Date:   Wed Nov 4 15:56:16 2015 -0800

    btrfs: qgroup: exit the rescan worker during umount
    
    I was hitting a consistent NULL pointer dereference during shutdown that
    showed the trace running through end_workqueue_bio().  I traced it back to
    the endio_meta_workers workqueue being poked after it had already been
    destroyed.
    
    Eventually I found that the root cause was a qgroup rescan that was still
    in progress while we were stopping all the btrfs workers.
    
    Currently we explicitly pause balance and scrub operations in
    close_ctree(), but we do nothing to stop the qgroup rescan.  We should
    probably be doing the same for qgroup rescan, but that's a much larger
    change.  This small change is good enough to allow me to unmount without
    crashing.
    
    Signed-off-by: Justin Maggard <jmaggard@netgear.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2d4667594681..1eb08393bff0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3780,6 +3780,9 @@ void close_ctree(struct btrfs_root *root)
 	fs_info->closing = 1;
 	smp_mb();
 
+	/* wait for the qgroup rescan worker to stop */
+	btrfs_qgroup_wait_for_completion(fs_info);
+
 	/* wait for the uuid_scan task to finish */
 	down(&fs_info->uuid_tree_rescan_sem);
 	/* avoid complains from lockdep et al., set sem back to initial state */

commit 696249132158014d594896df3a81390616069c5c
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Mon Oct 26 15:06:19 2015 +0900

    btrfs: clear PF_NOFREEZE in cleaner_kthread()
    
    cleaner_kthread() kthread calls try_to_freeze() at the beginning of every
    cleanup attempt. This operation can't ever succeed though, as the kthread
    hasn't marked itself as freezable.
    
    Before (hopefully eventually) kthread freezing gets converted to fileystem
    freezing, we'd rather mark cleaner_kthread() freezable (as my
    understanding is that it can generate filesystem I/O during suspend).
    
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 86a11a902fcf..2d4667594681 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1762,6 +1762,7 @@ static int cleaner_kthread(void *arg)
 	int again;
 	struct btrfs_trans_handle *trans;
 
+	set_freezable();
 	do {
 		again = 0;
 

commit a9e6d153563d2ed69c6cd7fb4fa5ce4ca7c712eb
Merge: 56fa9d0762ed 0584f718ed1f
Author: Chris Mason <clm@fb.com>
Date:   Wed Oct 21 19:00:38 2015 -0700

    Merge branch 'allocator-fixes' into for-linus-4.4
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 161c3549b45aeef05451b6822d8aaaf39c7bedce
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Sep 24 16:17:39 2015 -0400

    Btrfs: change how we wait for pending ordered extents
    
    We have a mechanism to make sure we don't lose updates for ordered extents that
    were logged in the transaction that is currently running.  We add the ordered
    extent to a transaction list and then the transaction waits on all the ordered
    extents in that list.  However are substantially large file systems this list
    can be extremely large, and can give us soft lockups, since the ordered extents
    don't remove themselves from the list when they do complete.
    
    To fix this we simply add a counter to the transaction that is incremented any
    time we have a logged extent that needs to be completed in the current
    transaction.  Then when the ordered extent finally completes it decrements the
    per transaction counter and wakes up the transaction if we are the last ones.
    This will eliminate the softlockup.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bcbb596d9695..dceabb13ddc4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4326,25 +4326,6 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 	return 0;
 }
 
-static void btrfs_free_pending_ordered(struct btrfs_transaction *cur_trans,
-				       struct btrfs_fs_info *fs_info)
-{
-	struct btrfs_ordered_extent *ordered;
-
-	spin_lock(&fs_info->trans_lock);
-	while (!list_empty(&cur_trans->pending_ordered)) {
-		ordered = list_first_entry(&cur_trans->pending_ordered,
-					   struct btrfs_ordered_extent,
-					   trans_list);
-		list_del_init(&ordered->trans_list);
-		spin_unlock(&fs_info->trans_lock);
-
-		btrfs_put_ordered_extent(ordered);
-		spin_lock(&fs_info->trans_lock);
-	}
-	spin_unlock(&fs_info->trans_lock);
-}
-
 void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 				   struct btrfs_root *root)
 {
@@ -4356,7 +4337,6 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	cur_trans->state = TRANS_STATE_UNBLOCKED;
 	wake_up(&root->fs_info->transaction_wait);
 
-	btrfs_free_pending_ordered(cur_trans, root->fs_info);
 	btrfs_destroy_delayed_inodes(root);
 	btrfs_assert_delayed_root_empty(root);
 

commit 55eeaf0578038c40baaf3cf9408c23e42cd2a2b8
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 8 17:08:38 2015 +0800

    btrfs: qgroup: Introduce new functions to reserve/free metadata
    
    Introduce new functions btrfs_qgroup_reserve/free_meta() to reserve/free
    metadata reserved space.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bcbb596d9695..0e0544e0e20b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1267,6 +1267,7 @@ static void __setup_root(u32 nodesize, u32 sectorsize, u32 stripesize,
 	atomic_set(&root->orphan_inodes, 0);
 	atomic_set(&root->refs, 1);
 	atomic_set(&root->will_be_snapshoted, 0);
+	atomic_set(&root->qgroup_meta_rsv, 0);
 	root->log_transid = 0;
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;

commit a0d58e48db58801a0e764e9b9c87e1782d390fcb
Merge: 6db4a7335dd7 ddd664f4478a
Author: Chris Mason <clm@fb.com>
Date:   Wed Oct 21 18:21:40 2015 -0700

    Merge branch 'cleanups/for-4.4' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.4

commit 8789f4fe608922f484369382a8e507ca12df7f4e
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Tue Sep 15 21:08:07 2015 +0800

    btrfs: use btrfs_raid_array for btrfs_get_num_tolerated_disk_barrier_failures()
    
    btrfs_raid_array[] is used to define all raid attributes, use it
    to get tolerated_failures in btrfs_get_num_tolerated_disk_barrier_failures(),
    instead of complex condition in function.
    
    It can make code simple and auto-support other possible raid-type in
    future.
    
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1e60d00d4ea7..322fd6ded723 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3449,22 +3449,31 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 
 int btrfs_get_num_tolerated_disk_barrier_failures(u64 flags)
 {
-	if ((flags & (BTRFS_BLOCK_GROUP_DUP |
-		      BTRFS_BLOCK_GROUP_RAID0 |
-		      BTRFS_AVAIL_ALLOC_BIT_SINGLE)) ||
-	    ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0))
-		return 0;
+	int raid_type;
+	int min_tolerated = INT_MAX;
 
-	if (flags & (BTRFS_BLOCK_GROUP_RAID1 |
-		     BTRFS_BLOCK_GROUP_RAID5 |
-		     BTRFS_BLOCK_GROUP_RAID10))
-		return 1;
+	if ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0 ||
+	    (flags & BTRFS_AVAIL_ALLOC_BIT_SINGLE))
+		min_tolerated = min(min_tolerated,
+				    btrfs_raid_array[BTRFS_RAID_SINGLE].
+				    tolerated_failures);
 
-	if (flags & BTRFS_BLOCK_GROUP_RAID6)
-		return 2;
+	for (raid_type = 0; raid_type < BTRFS_NR_RAID_TYPES; raid_type++) {
+		if (raid_type == BTRFS_RAID_SINGLE)
+			continue;
+		if (!(flags & btrfs_raid_group[raid_type]))
+			continue;
+		min_tolerated = min(min_tolerated,
+				    btrfs_raid_array[raid_type].
+				    tolerated_failures);
+	}
 
-	pr_warn("BTRFS: unknown raid type: %llu\n", flags);
-	return 0;
+	if (min_tolerated == INT_MAX) {
+		pr_warn("BTRFS: unknown raid flag: %llu\n", flags);
+		min_tolerated = 0;
+	}
+
+	return min_tolerated;
 }
 
 int btrfs_calc_num_tolerated_disk_barrier_failures(

commit 6db4a7335dd701a0e20275440ee057d3db2a7ae3
Merge: 62fb50ab7c90 ee8639545807
Author: Chris Mason <clm@fb.com>
Date:   Mon Oct 12 16:24:40 2015 -0700

    Merge branch 'fix/waitqueue-barriers' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.4

commit 62fb50ab7c903357c92cef2f7677235b92ac575f
Merge: 640926ffdda7 73416dab235e
Author: Chris Mason <clm@fb.com>
Date:   Mon Oct 12 16:24:15 2015 -0700

    Merge branch 'anand/sysfs-updates-v4.3-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.4
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 640926ffdda7e817965d3bfb5bbbc51598ccf49b
Merge: 25cb62b76430 f14d104dbdb5
Author: Chris Mason <clm@fb.com>
Date:   Mon Oct 12 16:22:26 2015 -0700

    Merge branch 'cleanup/messages' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.4

commit ee86395458072760d62e66aad10a5e9e8902b8cf
Author: David Sterba <dsterba@suse.com>
Date:   Mon Feb 16 19:41:40 2015 +0100

    btrfs: comment the rest of implicit barriers before waitqueue_active
    
    There are atomic operations that imply the barrier for waitqueue_active
    mixed in an if-condition.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 295795aebe0b..379526ffd84d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -802,6 +802,9 @@ static void run_one_async_done(struct btrfs_work *work)
 	limit = btrfs_async_submit_limit(fs_info);
 	limit = limit * 2 / 3;
 
+	/*
+	 * atomic_dec_return implies a barrier for waitqueue_active
+	 */
 	if (atomic_dec_return(&fs_info->nr_async_submits) < limit &&
 	    waitqueue_active(&fs_info->async_submit_wait))
 		wake_up(&fs_info->async_submit_wait);

commit 175d58cfed70f132b8d4df39e19267ad6094bd16
Merge: 38aa0a59a666 7d35199e15b8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 9 16:39:35 2015 -0700

    Merge branch 'for-linus-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "These are small and assorted.  Neil's is the oldest, I dropped the
      ball thinking he was going to send it in"
    
    * 'for-linus-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: support NFSv2 export
      Btrfs: open_ctree: Fix possible memory leak
      Btrfs: fix deadlock when finalizing block group creation
      Btrfs: update fix for read corruption of compressed and shared extents
      Btrfs: send, fix corner case for reference overwrite detection

commit f14d104dbdb5044dac9acd0e983ffb60f706c746
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 8 11:37:06 2015 +0200

    btrfs: switch more printks to our helpers
    
    Convert the simple cases, not all functions provide a way to reach the
    fs_info. Also skipped debugging messages (print-tree, integrity
    checker and pr_debug) and messages that are printed from possibly
    unfinished mount.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 72553cd9ed14..5bc94d2d5699 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2347,8 +2347,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	u64 bytenr = btrfs_super_log_root(disk_super);
 
 	if (fs_devices->rw_devices == 0) {
-		printk(KERN_WARNING "BTRFS: log replay required "
-		       "on RO media\n");
+		btrfs_warn(fs_info, "log replay required on RO media");
 		return -EIO;
 	}
 
@@ -2363,12 +2362,12 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	log_tree_root->node = read_tree_block(tree_root, bytenr,
 			fs_info->generation + 1);
 	if (IS_ERR(log_tree_root->node)) {
-		printk(KERN_ERR "BTRFS: failed to read log tree\n");
+		btrfs_warn(fs_info, "failed to read log tree");
 		ret = PTR_ERR(log_tree_root->node);
 		kfree(log_tree_root);
 		return ret;
 	} else if (!extent_buffer_uptodate(log_tree_root->node)) {
-		printk(KERN_ERR "BTRFS: failed to read log tree\n");
+		btrfs_err(fs_info, "failed to read log tree");
 		free_extent_buffer(log_tree_root->node);
 		kfree(log_tree_root);
 		return -EIO;
@@ -3294,8 +3293,9 @@ static int write_dev_supers(struct btrfs_device *device,
 			bh = __getblk(device->bdev, bytenr / 4096,
 				      BTRFS_SUPER_INFO_SIZE);
 			if (!bh) {
-				printk(KERN_ERR "BTRFS: couldn't get super "
-				       "buffer head for bytenr %Lu\n", bytenr);
+				btrfs_err(device->dev_root->fs_info,
+				    "couldn't get super buffer head for bytenr %llu",
+				    bytenr);
 				errors++;
 				continue;
 			}

commit 9464732266862f6044e4708dca6c4b2a83dd937b
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 8 11:01:36 2015 +0200

    btrfs: switch message printers to ratelimited variants
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ba41faf623ce..72553cd9ed14 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -319,9 +319,9 @@ static int csum_tree_block(struct btrfs_fs_info *fs_info,
 			memcpy(&found, result, csum_size);
 
 			read_extent_buffer(buf, &val, 0, csum_size);
-			printk_ratelimited(KERN_WARNING
-				"BTRFS: %s checksum verify failed on %llu wanted %X found %X "
-				"level %d\n",
+			btrfs_warn_rl(fs_info,
+				"%s checksum verify failed on %llu wanted %X found %X "
+				"level %d",
 				fs_info->sb->s_id, buf->start,
 				val, found, btrfs_header_level(buf));
 			if (result != (char *)&inline_result)
@@ -368,9 +368,9 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		ret = 0;
 		goto out;
 	}
-	printk_ratelimited(KERN_ERR
-	    "BTRFS (device %s): parent transid verify failed on %llu wanted %llu found %llu\n",
-			eb->fs_info->sb->s_id, eb->start,
+	btrfs_err_rl(eb->fs_info,
+		"parent transid verify failed on %llu wanted %llu found %llu",
+			eb->start,
 			parent_transid, btrfs_header_generation(eb));
 	ret = 1;
 
@@ -629,15 +629,14 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != eb->start) {
-		printk_ratelimited(KERN_ERR "BTRFS (device %s): bad tree block start "
-			       "%llu %llu\n",
-			       eb->fs_info->sb->s_id, found_start, eb->start);
+		btrfs_err_rl(eb->fs_info, "bad tree block start %llu %llu",
+			       found_start, eb->start);
 		ret = -EIO;
 		goto err;
 	}
 	if (check_tree_block_fsid(root->fs_info, eb)) {
-		printk_ratelimited(KERN_ERR "BTRFS (device %s): bad fsid on block %llu\n",
-			       eb->fs_info->sb->s_id, eb->start);
+		btrfs_err_rl(eb->fs_info, "bad fsid on block %llu",
+			       eb->start);
 		ret = -EIO;
 		goto err;
 	}

commit b14af3b46f214c5e927dacf58a994fa3c4cb20dc
Author: David Sterba <dsterba@suse.com>
Date:   Thu Oct 8 10:43:10 2015 +0200

    btrfs: switch message printers to ratelimited _in_rcu variants
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 295795aebe0b..ba41faf623ce 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3175,8 +3175,8 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 		struct btrfs_device *device = (struct btrfs_device *)
 			bh->b_private;
 
-		printk_ratelimited_in_rcu(KERN_WARNING "BTRFS: lost page write due to "
-					  "I/O error on %s\n",
+		btrfs_warn_rl_in_rcu(device->dev_root->fs_info,
+				"lost page write due to IO error on %s",
 					  rcu_str_deref(device->name));
 		/* note, we dont' set_buffer_write_io_error because we have
 		 * our own ways of dealing with the IO errors

commit e5fffbac4a49270e4976d71a0e054c0cf3ef4f8e
Author: chandan <chandan@linux.vnet.ibm.com>
Date:   Mon Oct 5 22:14:25 2015 +0530

    Btrfs: open_ctree: Fix possible memory leak
    
    After reading one of chunk or tree root tree's root node from disk, if the
    root node does not have EXTENT_BUFFER_UPTODATE flag set, we fail to release
    the memory used by the root node. Fix this.
    
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aa59871885da..807f6854acaa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2842,6 +2842,8 @@ int open_ctree(struct super_block *sb,
 	    !extent_buffer_uptodate(chunk_root->node)) {
 		printk(KERN_ERR "BTRFS: failed to read chunk root on %s\n",
 		       sb->s_id);
+		if (!IS_ERR(chunk_root->node))
+			free_extent_buffer(chunk_root->node);
 		chunk_root->node = NULL;
 		goto fail_tree_roots;
 	}
@@ -2880,6 +2882,8 @@ int open_ctree(struct super_block *sb,
 	    !extent_buffer_uptodate(tree_root->node)) {
 		printk(KERN_WARNING "BTRFS: failed to read tree root on %s\n",
 		       sb->s_id);
+		if (!IS_ERR(tree_root->node))
+			free_extent_buffer(tree_root->node);
 		tree_root->node = NULL;
 		goto recovery_tree_root;
 	}

commit 29c36d72535deb3d8961b3fb4b6a565190a6c63b
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Aug 14 18:32:58 2015 +0800

    Btrfs: add btrfs_read_dev_one_super() to read one specific SB
    
    This uses a chunk of code from btrfs_read_dev_super() and creates
    a function called btrfs_read_dev_one_super() so that next patch
    can use it for scratch superblock.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    [renamed bufhead to bh]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0f8e33f2bcea..c7c739f420b5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3188,6 +3188,37 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 	put_bh(bh);
 }
 
+int btrfs_read_dev_one_super(struct block_device *bdev, int copy_num,
+			struct buffer_head **bh_ret)
+{
+	struct buffer_head *bh;
+	struct btrfs_super_block *super;
+	u64 bytenr;
+
+	bytenr = btrfs_sb_offset(copy_num);
+	if (bytenr + BTRFS_SUPER_INFO_SIZE >= i_size_read(bdev->bd_inode))
+		return -EINVAL;
+
+	bh = __bread(bdev, bytenr / 4096, BTRFS_SUPER_INFO_SIZE);
+	/*
+	 * If we fail to read from the underlying devices, as of now
+	 * the best option we have is to mark it EIO.
+	 */
+	if (!bh)
+		return -EIO;
+
+	super = (struct btrfs_super_block *)bh->b_data;
+	if (btrfs_super_bytenr(super) != bytenr ||
+		    btrfs_super_magic(super) != BTRFS_MAGIC) {
+		brelse(bh);
+		return -EINVAL;
+	}
+
+	*bh_ret = bh;
+	return 0;
+}
+
+
 struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 {
 	struct buffer_head *bh;
@@ -3195,7 +3226,6 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 	struct btrfs_super_block *super;
 	int i;
 	u64 transid = 0;
-	u64 bytenr;
 	int ret = -EINVAL;
 
 	/* we would like to check all the supers, but that would make
@@ -3204,28 +3234,11 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 	 * later supers, using BTRFS_SUPER_MIRROR_MAX instead
 	 */
 	for (i = 0; i < 1; i++) {
-		bytenr = btrfs_sb_offset(i);
-		if (bytenr + BTRFS_SUPER_INFO_SIZE >=
-					i_size_read(bdev->bd_inode))
-			break;
-		bh = __bread(bdev, bytenr / 4096,
-					BTRFS_SUPER_INFO_SIZE);
-		/*
-		 * If we fail to read from the underlying devices, as of now
-		 * the best option we have is to mark it EIO.
-		 */
-		if (!bh) {
-			ret = -EIO;
+		ret = btrfs_read_dev_one_super(bdev, i, &bh);
+		if (ret)
 			continue;
-		}
 
 		super = (struct btrfs_super_block *)bh->b_data;
-		if (btrfs_super_bytenr(super) != bytenr ||
-		    btrfs_super_magic(super) != BTRFS_MAGIC) {
-			brelse(bh);
-			ret = -EINVAL;
-			continue;
-		}
 
 		if (!latest || btrfs_super_generation(super) > transid) {
 			brelse(latest);

commit a4553fefb59cb0336f543fa567170b47e90142a9
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Sep 25 14:43:01 2015 +0800

    Btrfs: consolidate btrfs_error() to btrfs_std_error()
    
    btrfs_error() and btrfs_std_error() does the same thing
    and calls _btrfs_std_error(), so consolidate them together.
    And the main motivation is that btrfs_error() is closely
    named with btrfs_err(), one handles error action the other
    is to log the error, so don't closely name them.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Suggested-by: David Sterba <dsterba@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 357d9f9c9968..0f8e33f2bcea 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2377,7 +2377,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	/* returns with log_tree_root freed on success */
 	ret = btrfs_recover_log_trees(log_tree_root);
 	if (ret) {
-		btrfs_error(tree_root->fs_info, ret,
+		btrfs_std_error(tree_root->fs_info, ret,
 			    "Failed to recover log tree");
 		free_extent_buffer(log_tree_root->node);
 		kfree(log_tree_root);
@@ -3556,7 +3556,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		if (ret) {
 			mutex_unlock(
 				&root->fs_info->fs_devices->device_list_mutex);
-			btrfs_error(root->fs_info, ret,
+			btrfs_std_error(root->fs_info, ret,
 				    "errors while submitting device barriers.");
 			return ret;
 		}
@@ -3596,7 +3596,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
 
 		/* FUA is masked off if unsupported and can't be the reason */
-		btrfs_error(root->fs_info, -EIO,
+		btrfs_std_error(root->fs_info, -EIO,
 			    "%d errors while writing supers", total_errors);
 		return -EIO;
 	}
@@ -3614,7 +3614,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	}
 	mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
 	if (total_errors > max_errors) {
-		btrfs_error(root->fs_info, -EIO,
+		btrfs_std_error(root->fs_info, -EIO,
 			    "%d errors while writing supers", total_errors);
 		return -EIO;
 	}

commit 92fc03fbdcbe2523be3f7e6b8e95fee9563a10d2
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Aug 14 18:32:51 2015 +0800

    Btrfs: SB read failure should return EIO for __bread failure
    
    This will return EIO when __bread() fails to read SB,
    instead of EINVAL.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 76734732eca6..357d9f9c9968 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2653,8 +2653,8 @@ int open_ctree(struct super_block *sb,
 	 * Read super block and check the signature bytes only
 	 */
 	bh = btrfs_read_dev_super(fs_devices->latest_bdev);
-	if (!bh) {
-		err = -EINVAL;
+	if (IS_ERR(bh)) {
+		err = PTR_ERR(bh);
 		goto fail_alloc;
 	}
 
@@ -3196,6 +3196,7 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 	int i;
 	u64 transid = 0;
 	u64 bytenr;
+	int ret = -EINVAL;
 
 	/* we would like to check all the supers, but that would make
 	 * a btrfs mount succeed after a mkfs from a different FS.
@@ -3209,13 +3210,20 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 			break;
 		bh = __bread(bdev, bytenr / 4096,
 					BTRFS_SUPER_INFO_SIZE);
-		if (!bh)
+		/*
+		 * If we fail to read from the underlying devices, as of now
+		 * the best option we have is to mark it EIO.
+		 */
+		if (!bh) {
+			ret = -EIO;
 			continue;
+		}
 
 		super = (struct btrfs_super_block *)bh->b_data;
 		if (btrfs_super_bytenr(super) != bytenr ||
 		    btrfs_super_magic(super) != BTRFS_MAGIC) {
 			brelse(bh);
+			ret = -EINVAL;
 			continue;
 		}
 
@@ -3227,6 +3235,10 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 			brelse(bh);
 		}
 	}
+
+	if (!latest)
+		return ERR_PTR(ret);
+
 	return latest;
 }
 

commit 6618a59bfc0a0490f2a51df37c67878e23285670
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Aug 14 18:32:47 2015 +0800

    Btrfs: rename btrfs_sysfs_remove_one to btrfs_sysfs_remove_mounted
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4622d38fa56e..76734732eca6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3113,7 +3113,7 @@ int open_ctree(struct super_block *sb,
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
 
 fail_sysfs:
-	btrfs_sysfs_remove_one(fs_info);
+	btrfs_sysfs_remove_mounted(fs_info);
 
 fail_fsdev_sysfs:
 	btrfs_sysfs_remove_fsid(fs_info->fs_devices);
@@ -3788,7 +3788,7 @@ void close_ctree(struct btrfs_root *root)
 		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 
-	btrfs_sysfs_remove_one(fs_info);
+	btrfs_sysfs_remove_mounted(fs_info);
 	btrfs_sysfs_remove_fsid(fs_info->fs_devices);
 
 	btrfs_free_fs_roots(fs_info);

commit 96f3136e51580ed68a2952341c8b9e2d7f853472
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Aug 14 18:32:46 2015 +0800

    Btrfs: rename btrfs_sysfs_add_one to btrfs_sysfs_add_mounted
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 295795aebe0b..4622d38fa56e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2933,7 +2933,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_fsdev_sysfs;
 	}
 
-	ret = btrfs_sysfs_add_one(fs_info);
+	ret = btrfs_sysfs_add_mounted(fs_info);
 	if (ret) {
 		pr_err("BTRFS: failed to init sysfs interface: %d\n", ret);
 		goto fail_fsdev_sysfs;

commit 03e8f644868f147e021e8660346890e731c2e435
Merge: 101688f534fd 2b9dbef272b6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 25 12:08:41 2015 -0700

    Merge branch 'for-linus-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "This is an assorted set I've been queuing up:
    
      Jeff Mahoney tracked down a tricky one where we ended up starting IO
      on the wrong mapping for special files in btrfs_evict_inode.  A few
      people reported this one on the list.
    
      Filipe found (and provided a test for) a difficult bug in reading
      compressed extents, and Josef fixed up some quota record keeping with
      snapshot deletion.  Chandan killed off an accounting bug during DIO
      that lead to WARN_ONs as we freed inodes"
    
    * 'for-linus-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: keep dropped roots in cache until transaction commit
      Btrfs: Direct I/O: Fix space accounting
      btrfs: skip waiting on ordered range for special files
      Btrfs: fix read corruption of compressed and shared extents
      Btrfs: remove unnecessary locking of cleaner_mutex to avoid deadlock
      Btrfs: don't initialize a space info as full to prevent ENOSPC

commit e91eb6204fb826116453e43d4f5cf0f666bf46fe
Merge: e013f74b60bb 527afb4493c2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 11 12:38:25 2015 -0700

    Merge branch 'for-linus-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs cleanups and fixes from Chris Mason:
     "These are small cleanups, and also some fixes for our async worker
      thread initialization.
    
      I was having some trouble testing these, but it ended up being a
      combination of changing around my test servers and a shiny new
      schedule while atomic from the new start/finish_plug in
      writeback_sb_inodes().
    
      That one only hits on btrfs raid5/6 or MD raid10, and if I wasn't
      changing a bunch of things in my test setup at once it would have been
      really clear.  Fix for writeback_sb_inodes() on the way as well"
    
    * 'for-linus-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: cleanup: remove unnecessary check before btrfs_free_path is called
      btrfs: async_thread: Fix workqueue 'max_active' value when initializing
      btrfs: Add raid56 support for updating  num_tolerated_disk_barrier_failures in btrfs_balance
      btrfs: Cleanup for btrfs_calc_num_tolerated_disk_barrier_failures
      btrfs: Remove noused chunk_tree and chunk_objectid from scrub_enumerate_chunks and scrub_chunk
      btrfs: Update out-of-date "skip parity stripe" comment

commit 85e0a0f21a14bfd9145422a6a627c3df47101bd8
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Sep 10 10:36:06 2015 +0100

    Btrfs: remove unnecessary locking of cleaner_mutex to avoid deadlock
    
    After commmit e44163e17796 ("btrfs: explictly delete unused block groups
    in close_ctree and ro-remount"), added in the 4.3 merge window, we have
    calls to btrfs_delete_unused_bgs() while holding the cleaner_mutex.
    This can cause a deadlock with a concurrent block group relocation (when
    a filesystem balance or shrink operation is in progress for example)
    because btrfs_delete_unused_bgs() locks delete_unused_bgs_mutex and the
    relocation path locks first delete_unused_bgs_mutex and then it locks
    cleaner_mutex, resulting in a classic ABBA deadlock:
    
             CPU 0                                        CPU 1
    
    lock fs_info->cleaner_mutex
    
                                               __btrfs_balance() || btrfs_shrink_device()
                                                 lock fs_info->delete_unused_bgs_mutex
                                                 btrfs_relocate_chunk()
                                                   btrfs_relocate_block_group()
                                                     lock fs_info->cleaner_mutex
    btrfs_delete_unused_bgs()
      lock fs_info->delete_unused_bgs_mutex
    
    Fix this by not taking the cleaner_mutex before calling
    btrfs_delete_unused_bgs() because it's no longer needed after
    commit 67c5e7d464bc ("Btrfs: fix race between balance and unused block
    group deletion"). The mutex fs_info->delete_unused_bgs_mutex, the
    spinlock fs_info->unused_bgs_lock and a block group's spinlock are
    enough to get correct serialization between tasks running relocation
    and unused block group deletion (as well as between multiple tasks
    concurrently calling btrfs_delete_unused_bgs()).
    
    This issue was discussed (in the mailing list) during the review of
    the patch titled "btrfs: explictly delete unused block groups in
    close_ctree and ro-remount" and it was agreed that acquiring the
    cleaner mutex had to be dropped after the patch titled
    "Btrfs: fix race between balance and unused block group deletion"
    got merged (both patches were submitted at about the same time, but
    one landed in kernel 4.2 and the other in the 4.3 merge window).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0b658d0230f0..aa59871885da 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3762,9 +3762,7 @@ void close_ctree(struct btrfs_root *root)
 		 * block groups queued for removal, the deletion will be
 		 * skipped when we quit the cleaner thread.
 		 */
-		mutex_lock(&root->fs_info->cleaner_mutex);
 		btrfs_delete_unused_bgs(root->fs_info);
-		mutex_unlock(&root->fs_info->cleaner_mutex);
 
 		ret = btrfs_commit_super(root);
 		if (ret)

commit 22365979ab15f8500254cb90037b0b4c17554739
Merge: 6c0f568e84a3 3a9508b0221d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Sep 5 15:14:43 2015 -0700

    Merge branch 'for-linus-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This has Jeff Mahoney's long standing trim patch that fixes corners
      where trims were missing.  Omar has some raid5/6 fixes, especially for
      using scrub and device replace when devices are missing.
    
      Zhao Lie continues cleaning and fixing things, this series fixes some
      really hard to hit corners in xfstests.  I had to pull it last merge
      window due to some deadlocks, but those are now resolved.
    
      I added support for Tejun's new blkio controllers.  It seems to work
      well for single devices, we'll expand to multi-device as well"
    
    * 'for-linus-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (47 commits)
      btrfs: fix compile when block cgroups are not enabled
      Btrfs: fix file read corruption after extent cloning and fsync
      Btrfs: check if previous transaction aborted to avoid fs corruption
      btrfs: use __GFP_NOFAIL in alloc_btrfs_bio
      btrfs: Prevent from early transaction abort
      btrfs: Remove unused arguments in tree-log.c
      btrfs: Remove useless condition in start_log_trans()
      Btrfs: add support for blkio controllers
      Btrfs: remove unused mutex from struct 'btrfs_fs_info'
      Btrfs: fix parity scrub of RAID 5/6 with missing device
      Btrfs: fix device replace of a missing RAID 5/6 device
      Btrfs: add RAID 5/6 BTRFS_RBIO_REBUILD_MISSING operation
      Btrfs: count devices correctly in readahead during RAID 5/6 replace
      Btrfs: remove misleading handling of missing device scrub
      btrfs: fix clone / extent-same deadlocks
      Btrfs: fix defrag to merge tail file extent
      Btrfs: fix warning in backref walking
      btrfs: Add WARN_ON() for double lock in btrfs_tree_lock()
      btrfs: Remove root argument in extent_data_ref_count()
      btrfs: Fix wrong comment of btrfs_alloc_tree_block()
      ...

commit 1081230b748de8f03f37f80c53dfa89feda9b8de
Merge: df910390e2db 2ca495ac27d2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 2 13:10:25 2015 -0700

    Merge branch 'for-4.3/core' of git://git.kernel.dk/linux-block
    
    Pull core block updates from Jens Axboe:
     "This first core part of the block IO changes contains:
    
       - Cleanup of the bio IO error signaling from Christoph.  We used to
         rely on the uptodate bit and passing around of an error, now we
         store the error in the bio itself.
    
       - Improvement of the above from myself, by shrinking the bio size
         down again to fit in two cachelines on x86-64.
    
       - Revert of the max_hw_sectors cap removal from a revision again,
         from Jeff Moyer.  This caused performance regressions in various
         tests.  Reinstate the limit, bump it to a more reasonable size
         instead.
    
       - Make /sys/block/<dev>/queue/discard_max_bytes writeable, by me.
         Most devices have huge trim limits, which can cause nasty latencies
         when deleting files.  Enable the admin to configure the size down.
         We will look into having a more sane default instead of UINT_MAX
         sectors.
    
       - Improvement of the SGP gaps logic from Keith Busch.
    
       - Enable the block core to handle arbitrarily sized bios, which
         enables a nice simplification of bio_add_page() (which is an IO hot
         path).  From Kent.
    
       - Improvements to the partition io stats accounting, making it
         faster.  From Ming Lei.
    
       - Also from Ming Lei, a basic fixup for overflow of the sysfs pending
         file in blk-mq, as well as a fix for a blk-mq timeout race
         condition.
    
       - Ming Lin has been carrying Kents above mentioned patches forward
         for a while, and testing them.  Ming also did a few fixes around
         that.
    
       - Sasha Levin found and fixed a use-after-free problem introduced by
         the bio->bi_error changes from Christoph.
    
       - Small blk cgroup cleanup from Viresh Kumar"
    
    * 'for-4.3/core' of git://git.kernel.dk/linux-block: (26 commits)
      blk: Fix bio_io_vec index when checking bvec gaps
      block: Replace SG_GAPS with new queue limits mask
      block: bump BLK_DEF_MAX_SECTORS to 2560
      Revert "block: remove artifical max_hw_sectors cap"
      blk-mq: fix race between timeout and freeing request
      blk-mq: fix buffer overflow when reading sysfs file of 'pending'
      Documentation: update notes in biovecs about arbitrarily sized bios
      block: remove bio_get_nr_vecs()
      fs: use helper bio_add_page() instead of open coding on bi_io_vec
      block: kill merge_bvec_fn() completely
      md/raid5: get rid of bio_fits_rdev()
      md/raid5: split bio for chunk_aligned_read
      block: remove split code in blkdev_issue_{discard,write_same}
      btrfs: remove bio splitting and merge_bvec_fn() calls
      bcache: remove driver private bio splitting code
      block: simplify bio_add_page()
      block: make generic_make_request handle arbitrarily sized bios
      blk-cgroup: Drop unlikely before IS_ERR(_OR_NULL)
      block: don't access bio->bi_error after bio_put()
      block: shrink struct bio down to 2 cache lines again
      ...

commit 943c6e9925d90dc80207322b5799d95fb90ffec0
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Wed Aug 19 15:54:15 2015 +0800

    btrfs: Add raid56 support for updating
     num_tolerated_disk_barrier_failures in btrfs_balance
    
    Code for updating fs_info->num_tolerated_disk_barrier_failures in
    btrfs_balance() lacks raid56 support.
    
    Reason:
     Above code was wroten in 2012-08-01, together with
     btrfs_calc_num_tolerated_disk_barrier_failures()'s first version.
    
     Then, btrfs_calc_num_tolerated_disk_barrier_failures() got updated
     later to support raid56, but code in btrfs_balance() was not
     updated together.
    
    Fix:
     Merge above similar code to a common function:
     btrfs_get_num_tolerated_disk_barrier_failures()
     and make it support both case.
    
     It can fix this bug with a bonus of cleanup, and make these code
     never in above no-sync state from now on.
    
    Suggested-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 51192d94c90c..0b658d0230f0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3440,6 +3440,26 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 	return 0;
 }
 
+int btrfs_get_num_tolerated_disk_barrier_failures(u64 flags)
+{
+	if ((flags & (BTRFS_BLOCK_GROUP_DUP |
+		      BTRFS_BLOCK_GROUP_RAID0 |
+		      BTRFS_AVAIL_ALLOC_BIT_SINGLE)) ||
+	    ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0))
+		return 0;
+
+	if (flags & (BTRFS_BLOCK_GROUP_RAID1 |
+		     BTRFS_BLOCK_GROUP_RAID5 |
+		     BTRFS_BLOCK_GROUP_RAID10))
+		return 1;
+
+	if (flags & BTRFS_BLOCK_GROUP_RAID6)
+		return 2;
+
+	pr_warn("BTRFS: unknown raid type: %llu\n", flags);
+	return 0;
+}
+
 int btrfs_calc_num_tolerated_disk_barrier_failures(
 	struct btrfs_fs_info *fs_info)
 {
@@ -3482,28 +3502,11 @@ int btrfs_calc_num_tolerated_disk_barrier_failures(
 			if (space.total_bytes == 0 || space.used_bytes == 0)
 				continue;
 			flags = space.flags;
-			/*
-			 * return
-			 * 0: if dup, single or RAID0 is configured for
-			 *    any of metadata, system or data, else
-			 * 1: if RAID5 is configured, or if RAID1 or
-			 *    RAID10 is configured and only two mirrors
-			 *    are used, else
-			 * 2: if RAID6 is configured
-			 */
-			if (num_tolerated_disk_barrier_failures > 0 &&
-			    ((flags & (BTRFS_BLOCK_GROUP_DUP |
-				       BTRFS_BLOCK_GROUP_RAID0)) ||
-			     ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0)))
-				num_tolerated_disk_barrier_failures = 0;
-			else if (num_tolerated_disk_barrier_failures > 1 &&
-				 (flags & (BTRFS_BLOCK_GROUP_RAID1 |
-					   BTRFS_BLOCK_GROUP_RAID5 |
-					   BTRFS_BLOCK_GROUP_RAID10)))
-				num_tolerated_disk_barrier_failures = 1;
-			else if (num_tolerated_disk_barrier_failures > 2 &&
-				 (flags & BTRFS_BLOCK_GROUP_RAID6))
-				num_tolerated_disk_barrier_failures = 2;
+
+			num_tolerated_disk_barrier_failures = min(
+				num_tolerated_disk_barrier_failures,
+				btrfs_get_num_tolerated_disk_barrier_failures(
+					flags));
 		}
 		up_read(&sinfo->groups_sem);
 	}

commit 2c4580454fffbf184fdb9292aa19ab1ffc224add
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Jul 16 15:00:46 2015 +0800

    btrfs: Cleanup for btrfs_calc_num_tolerated_disk_barrier_failures
    
    1: Use ARRAY_SIZE(types) to replace a static-value variant:
       int num_types = 4;
    
    2: Use 'continue' on condition to reduce one level tab
       if (!XXX) {
           code;
           ...
       }
       ->
       if (XXX)
           continue;
       code;
       ...
    
    3: Put setting 'num_tolerated_disk_barrier_failures = 2' to
       (num_tolerated_disk_barrier_failures > 2) condition to make
       make logic neat.
       if (num_tolerated_disk_barrier_failures > 0 && XXX)
           num_tolerated_disk_barrier_failures = 0;
       else if (num_tolerated_disk_barrier_failures > 1) {
           if (XXX)
               num_tolerated_disk_barrier_failures = 1;
           else if (XXX)
               num_tolerated_disk_barrier_failures = 2;
       ->
       if (num_tolerated_disk_barrier_failures > 0 && XXX)
           num_tolerated_disk_barrier_failures = 0;
       if (num_tolerated_disk_barrier_failures > 1 && XXX)
           num_tolerated_disk_barrier_failures = ;
       if (num_tolerated_disk_barrier_failures > 2 && XXX)
           num_tolerated_disk_barrier_failures = 2;
    
    4: Remove comment of:
       num_mirrors - 1: if RAID1 or RAID10 is configured and more
       than 2 mirrors are used.
       which is not fit with code.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cc15514b4a76..51192d94c90c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3449,13 +3449,12 @@ int btrfs_calc_num_tolerated_disk_barrier_failures(
 		       BTRFS_BLOCK_GROUP_SYSTEM,
 		       BTRFS_BLOCK_GROUP_METADATA,
 		       BTRFS_BLOCK_GROUP_DATA | BTRFS_BLOCK_GROUP_METADATA};
-	int num_types = 4;
 	int i;
 	int c;
 	int num_tolerated_disk_barrier_failures =
 		(int)fs_info->fs_devices->num_devices;
 
-	for (i = 0; i < num_types; i++) {
+	for (i = 0; i < ARRAY_SIZE(types); i++) {
 		struct btrfs_space_info *tmp;
 
 		sinfo = NULL;
@@ -3473,44 +3472,38 @@ int btrfs_calc_num_tolerated_disk_barrier_failures(
 
 		down_read(&sinfo->groups_sem);
 		for (c = 0; c < BTRFS_NR_RAID_TYPES; c++) {
-			if (!list_empty(&sinfo->block_groups[c])) {
-				u64 flags;
-
-				btrfs_get_block_group_info(
-					&sinfo->block_groups[c], &space);
-				if (space.total_bytes == 0 ||
-				    space.used_bytes == 0)
-					continue;
-				flags = space.flags;
-				/*
-				 * return
-				 * 0: if dup, single or RAID0 is configured for
-				 *    any of metadata, system or data, else
-				 * 1: if RAID5 is configured, or if RAID1 or
-				 *    RAID10 is configured and only two mirrors
-				 *    are used, else
-				 * 2: if RAID6 is configured, else
-				 * num_mirrors - 1: if RAID1 or RAID10 is
-				 *                  configured and more than
-				 *                  2 mirrors are used.
-				 */
-				if (num_tolerated_disk_barrier_failures > 0 &&
-				    ((flags & (BTRFS_BLOCK_GROUP_DUP |
-					       BTRFS_BLOCK_GROUP_RAID0)) ||
-				     ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK)
-				      == 0)))
-					num_tolerated_disk_barrier_failures = 0;
-				else if (num_tolerated_disk_barrier_failures > 1) {
-					if (flags & (BTRFS_BLOCK_GROUP_RAID1 |
-					    BTRFS_BLOCK_GROUP_RAID5 |
-					    BTRFS_BLOCK_GROUP_RAID10)) {
-						num_tolerated_disk_barrier_failures = 1;
-					} else if (flags &
-						   BTRFS_BLOCK_GROUP_RAID6) {
-						num_tolerated_disk_barrier_failures = 2;
-					}
-				}
-			}
+			u64 flags;
+
+			if (list_empty(&sinfo->block_groups[c]))
+				continue;
+
+			btrfs_get_block_group_info(&sinfo->block_groups[c],
+						   &space);
+			if (space.total_bytes == 0 || space.used_bytes == 0)
+				continue;
+			flags = space.flags;
+			/*
+			 * return
+			 * 0: if dup, single or RAID0 is configured for
+			 *    any of metadata, system or data, else
+			 * 1: if RAID5 is configured, or if RAID1 or
+			 *    RAID10 is configured and only two mirrors
+			 *    are used, else
+			 * 2: if RAID6 is configured
+			 */
+			if (num_tolerated_disk_barrier_failures > 0 &&
+			    ((flags & (BTRFS_BLOCK_GROUP_DUP |
+				       BTRFS_BLOCK_GROUP_RAID0)) ||
+			     ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0)))
+				num_tolerated_disk_barrier_failures = 0;
+			else if (num_tolerated_disk_barrier_failures > 1 &&
+				 (flags & (BTRFS_BLOCK_GROUP_RAID1 |
+					   BTRFS_BLOCK_GROUP_RAID5 |
+					   BTRFS_BLOCK_GROUP_RAID10)))
+				num_tolerated_disk_barrier_failures = 1;
+			else if (num_tolerated_disk_barrier_failures > 2 &&
+				 (flags & BTRFS_BLOCK_GROUP_RAID6))
+				num_tolerated_disk_barrier_failures = 2;
 		}
 		up_read(&sinfo->groups_sem);
 	}

commit 46cd28555ffaa40162290dba203daad0ff6f7abd
Merge: da2f0f74cf7d e33e17ee1098
Author: Chris Mason <clm@fb.com>
Date:   Sun Aug 9 07:35:33 2015 -0700

    Merge branch 'jeffm-discard-4.3' into for-linus-4.3

commit da2f0f74cf7d074e5a8918c8efdf6aba4a989b4a
Author: Chris Mason <clm@fb.com>
Date:   Thu Jul 2 13:57:22 2015 -0700

    Btrfs: add support for blkio controllers
    
    This attaches accounting information to bios as we submit them so the
    new blkio controllers can throttle on btrfs filesystems.
    
    Not much is required, we're just associating bios with blkcgs during clone,
    calling wbc_init_bio()/wbc_account_io() during writepages submission,
    and attaching the bios to the current context during direct IO.
    
    Finally if we are splitting bios during btrfs_map_bio, this attaches
    accounting information to the split.
    
    The end result is able to throttle nicely on single disk filesystems.  A
    little more work is required for multi-device filesystems.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f7536bcf7cee..230546b45474 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1724,6 +1724,7 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 	bdi->ra_pages = VM_MAX_READAHEAD * 1024 / PAGE_CACHE_SIZE;
 	bdi->congested_fn	= btrfs_congested_fn;
 	bdi->congested_data	= info;
+	bdi->capabilities |= BDI_CAP_CGROUP_WRITEBACK;
 	return 0;
 }
 

commit a4027a20c57a2c8779e17a61425737634bb7163d
Author: Byongho Lee <bhlee.kernel@gmail.com>
Date:   Fri Jul 10 13:10:26 2015 +0900

    Btrfs: remove unused mutex from struct 'btrfs_fs_info'
    
    The code using 'ordered_extent_flush_mutex' mutex has removed by below
    commit.
     - 8d875f95da43c6a8f18f77869f2ef26e9594fecc
       btrfs: disable strict file flushes for renames and truncates
    But the mutex still lives in struct 'btrfs_fs_info'.
    
    So, this patch removes the mutex from struct 'btrfs_fs_info' and its
    initialization code.
    
    Signed-off-by: Byongho Lee <bhlee.kernel@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e49ae5ea9040..f7536bcf7cee 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2608,7 +2608,6 @@ int open_ctree(struct super_block *sb,
 
 
 	mutex_init(&fs_info->ordered_operations_mutex);
-	mutex_init(&fs_info->ordered_extent_flush_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
 	mutex_init(&fs_info->chunk_mutex);
 	mutex_init(&fs_info->transaction_kthread_mutex);

commit 78fa177029802f7f10953d357067171f39a79b81
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Mon Jul 20 17:54:50 2015 +0800

    btrfs: Show detail information when mount failed on missing devices
    
    When mount failed because missing device, we can see following
    dmesg:
     [ 1060.267743] BTRFS: too many missing devices, writeable mount is not allowed
     [ 1060.273158] BTRFS: open_ctree failed
    
    This patch add missing_device_number and tolerated_missing_device_number
    to above output, to let user know what really happened, and helps
    bug-report and debug.
    
    dmesg after patch:
     [  127.050367] BTRFS: missing devices(1) exceeds the limit(0), writeable mount is not allowed
     [  127.056099] BTRFS: open_ctree failed
    
    Changelog v1->v2:
    1: Changed to more clear description, suggested-by:
       Anand Jain <anand.jain@oracle.com>
    
    Suggested-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Reviewed-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f556c3732c2c..e49ae5ea9040 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2950,8 +2950,9 @@ int open_ctree(struct super_block *sb,
 	if (fs_info->fs_devices->missing_devices >
 	     fs_info->num_tolerated_disk_barrier_failures &&
 	    !(sb->s_flags & MS_RDONLY)) {
-		printk(KERN_WARNING "BTRFS: "
-			"too many missing devices, writeable mount is not allowed\n");
+		pr_warn("BTRFS: missing devices(%llu) exceeds the limit(%d), writeable mount is not allowed\n",
+			fs_info->fs_devices->missing_devices,
+			fs_info->num_tolerated_disk_barrier_failures);
 		goto fail_sysfs;
 	}
 

commit acea568fa9eaeffbf949d15b2f7c9c346e16aae3
Merge: c6fd4fc70830 00d80e342c0f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 31 17:05:37 2015 -0700

    Merge branch 'for-linus-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "Filipe fixed up a hard to trigger ENOSPC regression from our merge
      window pull, and we have a few other smaller fixes"
    
    * 'for-linus-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix quick exhaustion of the system array in the superblock
      btrfs: its btrfs_err() instead of btrfs_error()
      btrfs: Avoid NULL pointer dereference of free_extent_buffer when read_tree_block() fail
      btrfs: Fix lockdep warning of btrfs_run_delayed_iputs()

commit e44163e177960ee60e32a73bffdd53c3a5827406
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Jun 15 09:41:18 2015 -0400

    btrfs: explictly delete unused block groups in close_ctree and ro-remount
    
    The cleaner thread may already be sleeping by the time we enter
    close_ctree.  If that's the case, we'll skip removing any unused
    block groups queued for removal, even during a normal umount.
    They'll be cleaned up automatically at next mount, but users
    expect a umount to be a clean synchronization point, especially
    when used on thin-provisioned storage with -odiscard.  We also
    explicitly remove unused block groups in the ro-remount path
    for the same reason.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Tested-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 84cbbb2d562e..053109ba26b7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3767,6 +3767,15 @@ void close_ctree(struct btrfs_root *root)
 	cancel_work_sync(&fs_info->async_reclaim_work);
 
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
+		/*
+		 * If the cleaner thread is stopped and there are
+		 * block groups queued for removal, the deletion will be
+		 * skipped when we quit the cleaner thread.
+		 */
+		mutex_lock(&root->fs_info->cleaner_mutex);
+		btrfs_delete_unused_bgs(root->fs_info);
+		mutex_unlock(&root->fs_info->cleaner_mutex);
+
 		ret = btrfs_commit_super(root);
 		if (ret)
 			btrfs_err(fs_info, "commit super ret %d", ret);

commit 4246a0b63bd8f56a1469b12eafeb875b1041a451
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jul 20 15:29:37 2015 +0200

    block: add a bi_error field to struct bio
    
    Currently we have two different ways to signal an I/O error on a BIO:
    
     (1) by clearing the BIO_UPTODATE flag
     (2) by returning a Linux errno value to the bi_end_io callback
    
    The first one has the drawback of only communicating a single possible
    error (-EIO), and the second one has the drawback of not beeing persistent
    when bios are queued up, and are not passed along from child to parent
    bio in the ever more popular chaining scenario.  Having both mechanisms
    available has the additional drawback of utterly confusing driver authors
    and introducing bugs where various I/O submitters only deal with one of
    them, and the others have to add boilerplate code to deal with both kinds
    of error returns.
    
    So add a new bi_error field to store an errno value directly in struct
    bio and remove the existing mechanisms to clean all this up.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a9aadb2ad525..a8c0de888a9d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -703,7 +703,7 @@ static int btree_io_failed_hook(struct page *page, int failed_mirror)
 	return -EIO;	/* we fixed nothing */
 }
 
-static void end_workqueue_bio(struct bio *bio, int err)
+static void end_workqueue_bio(struct bio *bio)
 {
 	struct btrfs_end_io_wq *end_io_wq = bio->bi_private;
 	struct btrfs_fs_info *fs_info;
@@ -711,7 +711,7 @@ static void end_workqueue_bio(struct bio *bio, int err)
 	btrfs_work_func_t func;
 
 	fs_info = end_io_wq->info;
-	end_io_wq->error = err;
+	end_io_wq->error = bio->bi_error;
 
 	if (bio->bi_rw & REQ_WRITE) {
 		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_METADATA) {
@@ -808,7 +808,8 @@ static void run_one_async_done(struct btrfs_work *work)
 
 	/* If an error occured we just want to clean up the bio and move on */
 	if (async->error) {
-		bio_endio(async->bio, async->error);
+		async->bio->bi_error = async->error;
+		bio_endio(async->bio);
 		return;
 	}
 
@@ -908,8 +909,10 @@ static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
 	 * submission context.  Just jump into btrfs_map_bio
 	 */
 	ret = btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num, 1);
-	if (ret)
-		bio_endio(bio, ret);
+	if (ret) {
+		bio->bi_error = ret;
+		bio_endio(bio);
+	}
 	return ret;
 }
 
@@ -960,10 +963,13 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 					  __btree_submit_bio_done);
 	}
 
-	if (ret) {
+	if (ret)
+		goto out_w_error;
+	return 0;
+
 out_w_error:
-		bio_endio(bio, ret);
-	}
+	bio->bi_error = ret;
+	bio_endio(bio);
 	return ret;
 }
 
@@ -1735,16 +1741,15 @@ static void end_workqueue_fn(struct btrfs_work *work)
 {
 	struct bio *bio;
 	struct btrfs_end_io_wq *end_io_wq;
-	int error;
 
 	end_io_wq = container_of(work, struct btrfs_end_io_wq, work);
 	bio = end_io_wq->bio;
 
-	error = end_io_wq->error;
+	bio->bi_error = end_io_wq->error;
 	bio->bi_private = end_io_wq->private;
 	bio->bi_end_io = end_io_wq->end_io;
 	kmem_cache_free(btrfs_end_io_wq_cache, end_io_wq);
-	bio_endio(bio, error);
+	bio_endio(bio);
 }
 
 static int cleaner_kthread(void *arg)
@@ -3323,10 +3328,8 @@ static int write_dev_supers(struct btrfs_device *device,
  * endio for the write_dev_flush, this will wake anyone waiting
  * for the barrier when it is done
  */
-static void btrfs_end_empty_barrier(struct bio *bio, int err)
+static void btrfs_end_empty_barrier(struct bio *bio)
 {
-	if (err)
-		clear_bit(BIO_UPTODATE, &bio->bi_flags);
 	if (bio->bi_private)
 		complete(bio->bi_private);
 	bio_put(bio);
@@ -3354,8 +3357,8 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 		wait_for_completion(&device->flush_wait);
 
-		if (!bio_flagged(bio, BIO_UPTODATE)) {
-			ret = -EIO;
+		if (bio->bi_error) {
+			ret = bio->bi_error;
 			btrfs_dev_stat_inc_and_print(device,
 				BTRFS_DEV_STAT_FLUSH_ERRS);
 		}

commit 95ab1f64908795a2edd6b847eca94a0c63a44be4
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Wed Jul 15 21:02:09 2015 +0800

    btrfs: Avoid NULL pointer dereference of free_extent_buffer when read_tree_block() fail
    
    When read_tree_block() failed, we can see following dmesg:
     [  134.371389] BUG: unable to handle kernel NULL pointer dereference at 0000000000000063
     [  134.372236] IP: [<ffffffff813a4a51>] free_extent_buffer+0x21/0x90
     [  134.372236] PGD 0
     [  134.372236] Oops: 0000 [#1] SMP
     [  134.372236] Modules linked in:
     [  134.372236] CPU: 0 PID: 2289 Comm: mount Not tainted 4.2.0-rc1_HEAD_c65b99f046843d2455aa231747b5a07a999a9f3d_+ #115
     [  134.372236] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5.1-0-g8936dbb-20141113_115728-nilsson.home.kraxel.org 04/01/2014
     [  134.372236] task: ffff88003b6e1a00 ti: ffff880011e60000 task.ti: ffff880011e60000
     [  134.372236] RIP: 0010:[<ffffffff813a4a51>]  [<ffffffff813a4a51>] free_extent_buffer+0x21/0x90
     ...
     [  134.372236] Call Trace:
     [  134.372236]  [<ffffffff81379aa1>] free_root_extent_buffers+0x91/0xb0
     [  134.372236]  [<ffffffff81379c3d>] free_root_pointers+0x17d/0x190
     [  134.372236]  [<ffffffff813801b0>] open_ctree+0x1ca0/0x25b0
     [  134.372236]  [<ffffffff8144d017>] ? disk_name+0x97/0xb0
     [  134.372236]  [<ffffffff813558aa>] btrfs_mount+0x8fa/0xab0
     ...
    
    Reason:
     read_tree_block() changed to return error number on fail,
     and this value(not NULL) is set to tree_root->node, then subsequent
     code will run to:
      free_root_pointers()
      ->free_root_extent_buffers()
      ->free_extent_buffer()
      ->atomic_read((extent_buffer *)(-E_XXX)->refs);
     and trigger above error.
    
    Fix:
     Set tree_root->node to NULL on fail to make error_handle code
     happy.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e5aad7f535aa..84cbbb2d562e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2842,6 +2842,7 @@ int open_ctree(struct super_block *sb,
 	    !extent_buffer_uptodate(chunk_root->node)) {
 		printk(KERN_ERR "BTRFS: failed to read chunk root on %s\n",
 		       sb->s_id);
+		chunk_root->node = NULL;
 		goto fail_tree_roots;
 	}
 	btrfs_set_root_node(&chunk_root->root_item, chunk_root->node);
@@ -2879,7 +2880,7 @@ int open_ctree(struct super_block *sb,
 	    !extent_buffer_uptodate(tree_root->node)) {
 		printk(KERN_WARNING "BTRFS: failed to read tree root on %s\n",
 		       sb->s_id);
-
+		tree_root->node = NULL;
 		goto recovery_tree_root;
 	}
 

commit 31b7a57c9eb3d90c87b6c2b855720ec709d2f6be
Merge: 84e3e9d04d5b 9689457b5b0a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 11 10:26:34 2015 -0700

    Merge branch 'for-linus-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "This is an assortment of fixes.  Most of the commits are from Filipe
      (fsync, the inode allocation cache and a few others).  Mark kicked in
      a series fixing corners in the extent sharing ioctls, and everyone
      else fixed up on assorted other problems"
    
    * 'for-linus-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix wrong check for btrfs_force_chunk_alloc()
      Btrfs: fix warning of bytes_may_use
      Btrfs: fix hang when failing to submit bio of directIO
      Btrfs: fix a comment in inode.c:evict_inode_truncate_pages()
      Btrfs: fix memory corruption on failure to submit bio for direct IO
      btrfs: don't update mtime/ctime on deduped inodes
      btrfs: allow dedupe of same inode
      btrfs: fix deadlock with extent-same and readpage
      btrfs: pass unaligned length to btrfs_cmp_data()
      Btrfs: fix fsync after truncate when no_holes feature is enabled
      Btrfs: fix fsync xattr loss in the fast fsync path
      Btrfs: fix fsync data loss after append write
      Btrfs: fix crash on close_ctree() if cleaner starts new transaction
      Btrfs: fix race between caching kthread and returning inode to inode cache
      Btrfs: use kmem_cache_free when freeing entry in inode cache
      Btrfs: fix race between balance and unused block group deletion
      btrfs: add error handling for scrub_workers_get()
      btrfs: cleanup noused initialization of dev in btrfs_end_bio()
      btrfs: qgroup: allow user to clear the limitation on qgroup

commit 043cd04950431f206f784d1ed9b3fcc5993045f2
Merge: 43baed34bc6b 5a5003df98d5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 30 20:07:45 2015 -0700

    Merge branch 'for-linus-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "Outside of our usual batch of fixes, this integrates the subvolume
      quota updates that Qu Wenruo from Fujitsu has been working on for a
      few releases now.  He gets an extra gold star for making btrfs smaller
      this time, and fixing a number of quota corners in the process.
    
      Dave Sterba tested and integrated Anand Jain's sysfs improvements.
      Outside of exporting a symbol (ack'd by Greg) these are all internal
      to btrfs and it's mostly cleanups and fixes.  Anand also attached some
      of our sysfs objects to our internal device management structs instead
      of an object off the super block.  It will make device management
      easier overall and it's a better fit for how the sysfs files are used.
      None of the existing sysfs files are moved around.
    
      Thanks for all the fixes everyone"
    
    * 'for-linus-4.2' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (87 commits)
      btrfs: delayed-ref: double free in btrfs_add_delayed_tree_ref()
      Btrfs: Check if kobject is initialized before put
      lib: export symbol kobject_move()
      Btrfs: sysfs: add support to show replacing target in the sysfs
      Btrfs: free the stale device
      Btrfs: use received_uuid of parent during send
      Btrfs: fix use-after-free in btrfs_replay_log
      btrfs: wait for delayed iputs on no space
      btrfs: qgroup: Make snapshot accounting work with new extent-oriented qgroup.
      btrfs: qgroup: Add the ability to skip given qgroup for old/new_roots.
      btrfs: ulist: Add ulist_del() function.
      btrfs: qgroup: Cleanup the old ref_node-oriented mechanism.
      btrfs: qgroup: Switch self test to extent-oriented qgroup mechanism.
      btrfs: qgroup: Switch to new extent-oriented qgroup mechanism.
      btrfs: qgroup: Switch rescan to new mechanism.
      btrfs: qgroup: Add new qgroup calculation function btrfs_qgroup_account_extents().
      btrfs: backref: Add special time_seq == (u64)-1 case for btrfs_find_all_roots().
      btrfs: qgroup: Add new function to record old_roots.
      btrfs: qgroup: Record possible quota-related extent for qgroup.
      btrfs: qgroup: Add function qgroup_update_counters().
      ...

commit da288d280d16f4d7e4ada331cb33d381b408b10c
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Jun 13 06:55:31 2015 +0100

    Btrfs: fix crash on close_ctree() if cleaner starts new transaction
    
    Often when running fstests btrfs/079 I was running into the following
    trace during umount on one of my qemu/kvm test vms:
    
    [ 8245.682441] WARNING: CPU: 8 PID: 25064 at fs/btrfs/extent-tree.c:138 btrfs_put_block_group+0x51/0x69 [btrfs]()
    [ 8245.685039] Modules linked in: btrfs dm_flakey dm_mod crc32c_generic xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd grace fscache sunrpc loop fuse parport_pc i2c_piix4 acpi_cpufreq processor psmouse i2c_core thermal_sys parport evdev serio_raw button pcspkr microcode ext4 crc16 jbd2 mbcache sg sr_mod cdrom sd_mod ata_generic virtio_scsi ata_piix libata floppy virtio_pci virtio_ring scsi_mod virtio e1000 [last unloaded: btrfs]
    [ 8245.693860] CPU: 8 PID: 25064 Comm: umount Tainted: G        W       4.1.0-rc5-btrfs-next-10+ #1
    [ 8245.695081] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.1-0-g4adadbd-20150316_085822-nilsson.home.kraxel.org 04/01/2014
    [ 8245.697583]  0000000000000009 ffff88020d047ce8 ffffffff8145eec7 ffffffff81095dce
    [ 8245.699234]  0000000000000000 ffff88020d047d28 ffffffff8104b399 0000000000000028
    [ 8245.700995]  ffffffffa04db07b ffff8801c6036c00 ffff8801c6036d68 ffff880202eb40b0
    [ 8245.702510] Call Trace:
    [ 8245.703006]  [<ffffffff8145eec7>] dump_stack+0x4f/0x7b
    [ 8245.705393]  [<ffffffff81095dce>] ? console_unlock+0x356/0x3a2
    [ 8245.706569]  [<ffffffff8104b399>] warn_slowpath_common+0xa1/0xbb
    [ 8245.707747]  [<ffffffffa04db07b>] ? btrfs_put_block_group+0x51/0x69 [btrfs]
    [ 8245.709101]  [<ffffffff8104b456>] warn_slowpath_null+0x1a/0x1c
    [ 8245.710274]  [<ffffffffa04db07b>] btrfs_put_block_group+0x51/0x69 [btrfs]
    [ 8245.711823]  [<ffffffffa04e3473>] btrfs_free_block_groups+0x145/0x322 [btrfs]
    [ 8245.713251]  [<ffffffffa04ef31a>] close_ctree+0x1ef/0x325 [btrfs]
    [ 8245.714448]  [<ffffffff8117d26e>] ? evict_inodes+0xdc/0xeb
    [ 8245.715539]  [<ffffffffa04cb3ad>] btrfs_put_super+0x19/0x1b [btrfs]
    [ 8245.716835]  [<ffffffff81167607>] generic_shutdown_super+0x73/0xef
    [ 8245.718015]  [<ffffffff81167a3a>] kill_anon_super+0x13/0x1e
    [ 8245.719101]  [<ffffffffa04cb1b6>] btrfs_kill_super+0x17/0x23 [btrfs]
    [ 8245.720316]  [<ffffffff81167544>] deactivate_locked_super+0x3b/0x68
    [ 8245.721517]  [<ffffffff81167dd6>] deactivate_super+0x3f/0x43
    [ 8245.722581]  [<ffffffff8117fbb9>] cleanup_mnt+0x59/0x78
    [ 8245.723538]  [<ffffffff8117fc18>] __cleanup_mnt+0x12/0x14
    [ 8245.724572]  [<ffffffff81065371>] task_work_run+0x8f/0xbc
    [ 8245.725598]  [<ffffffff810028fb>] do_notify_resume+0x45/0x53
    [ 8245.726892]  [<ffffffff814651ac>] int_signal+0x12/0x17
    [ 8245.737887] ---[ end trace a01d038397e99b92 ]---
    [ 8245.769363] general protection fault: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
    [ 8245.770737] Modules linked in: btrfs dm_flakey dm_mod crc32c_generic xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd grace fscache sunrpc loop fuse parport_pc i2c_piix4 acpi_cpufreq processor psmouse i2c_core thermal_sys parport evdev serio_raw button pcspkr microcode ext4 crc16 jbd2 mbcache sg sr_mod cdrom sd_mod ata_generic virtio_scsi ata_piix libata floppy virtio_pci virtio_ring scsi_mod virtio e1000 [last unloaded: btrfs]
    [ 8245.772641] CPU: 2 PID: 25064 Comm: umount Tainted: G        W       4.1.0-rc5-btrfs-next-10+ #1
    [ 8245.772641] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.1-0-g4adadbd-20150316_085822-nilsson.home.kraxel.org 04/01/2014
    [ 8245.772641] task: ffff880013005810 ti: ffff88020d044000 task.ti: ffff88020d044000
    [ 8245.772641] RIP: 0010:[<ffffffffa051c8e6>]  [<ffffffffa051c8e6>] btrfs_queue_work+0x2c/0x14d [btrfs]
    [ 8245.772641] RSP: 0018:ffff88020d0478b8  EFLAGS: 00010202
    [ 8245.772641] RAX: 0000000000000004 RBX: 6b6b6b6b6b6b6b6b RCX: ffffffffa0581488
    [ 8245.772641] RDX: 0000000000000000 RSI: ffff880194b7bf48 RDI: ffff880144b6a7a0
    [ 8245.772641] RBP: ffff88020d0478d8 R08: 0000000000000000 R09: 000000000000ffff
    [ 8245.772641] R10: 0000000000000004 R11: 0000000000000005 R12: ffff880194b7bf48
    [ 8245.772641] R13: ffff880194b7bf48 R14: 0000000000000410 R15: 0000000000000000
    [ 8245.772641] FS:  00007f991e77d840(0000) GS:ffff88023e280000(0000) knlGS:0000000000000000
    [ 8245.772641] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [ 8245.772641] CR2: 00007fbbd325ee68 CR3: 000000021de8e000 CR4: 00000000000006e0
    [ 8245.772641] Stack:
    [ 8245.772641]  ffff880194b7bf00 ffff880202eb4000 ffff880194b7bf48 0000000000000410
    [ 8245.772641]  ffff88020d047958 ffffffffa04ec6d5 ffff8801629b2ee8 0000000082987570
    [ 8245.772641]  0000000000a5813f 0000000000000001 ffff880013006100 0000000000000002
    [ 8245.772641] Call Trace:
    [ 8245.772641]  [<ffffffffa04ec6d5>] btrfs_wq_submit_bio+0xe1/0x17b [btrfs]
    [ 8245.772641]  [<ffffffff81086bff>] ? check_irq_usage+0x76/0x87
    [ 8245.772641]  [<ffffffffa04ec825>] btree_submit_bio_hook+0xb6/0xd9 [btrfs]
    [ 8245.772641]  [<ffffffffa04ebb7c>] ? btree_csum_one_bio+0xad/0xad [btrfs]
    [ 8245.772641]  [<ffffffffa04eb1a6>] ? btree_io_failed_hook+0x5e/0x5e [btrfs]
    [ 8245.772641]  [<ffffffffa050a6e7>] submit_one_bio+0x8c/0xc7 [btrfs]
    [ 8245.772641]  [<ffffffffa050d75b>] submit_extent_page.isra.18+0x9d/0x186 [btrfs]
    [ 8245.772641]  [<ffffffffa050d95b>] write_one_eb+0x117/0x1ae [btrfs]
    [ 8245.772641]  [<ffffffffa050a79b>] ? end_extent_buffer_writeback+0x21/0x21 [btrfs]
    [ 8245.772641]  [<ffffffffa0510510>] btree_write_cache_pages+0x2ab/0x385 [btrfs]
    [ 8245.772641]  [<ffffffffa04eb2b8>] btree_writepages+0x23/0x5c [btrfs]
    [ 8245.772641]  [<ffffffff8111c661>] do_writepages+0x23/0x2c
    [ 8245.772641]  [<ffffffff81189cd4>] __writeback_single_inode+0xda/0x5bd
    [ 8245.772641]  [<ffffffff8118aa60>] ? writeback_single_inode+0x2b/0x173
    [ 8245.772641]  [<ffffffff8118aafd>] writeback_single_inode+0xc8/0x173
    [ 8245.772641]  [<ffffffff8118ac95>] write_inode_now+0x8a/0x95
    [ 8245.772641]  [<ffffffff81247bf0>] ? _atomic_dec_and_lock+0x30/0x4e
    [ 8245.772641]  [<ffffffff8117cc5e>] iput+0x17d/0x26a
    [ 8245.772641]  [<ffffffffa04ef355>] close_ctree+0x22a/0x325 [btrfs]
    [ 8245.772641]  [<ffffffff8117d26e>] ? evict_inodes+0xdc/0xeb
    [ 8245.772641]  [<ffffffffa04cb3ad>] btrfs_put_super+0x19/0x1b [btrfs]
    [ 8245.772641]  [<ffffffff81167607>] generic_shutdown_super+0x73/0xef
    [ 8245.772641]  [<ffffffff81167a3a>] kill_anon_super+0x13/0x1e
    [ 8245.772641]  [<ffffffffa04cb1b6>] btrfs_kill_super+0x17/0x23 [btrfs]
    [ 8245.772641]  [<ffffffff81167544>] deactivate_locked_super+0x3b/0x68
    [ 8245.772641]  [<ffffffff81167dd6>] deactivate_super+0x3f/0x43
    [ 8245.772641]  [<ffffffff8117fbb9>] cleanup_mnt+0x59/0x78
    [ 8245.772641]  [<ffffffff8117fc18>] __cleanup_mnt+0x12/0x14
    [ 8245.772641]  [<ffffffff81065371>] task_work_run+0x8f/0xbc
    [ 8245.772641]  [<ffffffff810028fb>] do_notify_resume+0x45/0x53
    [ 8245.772641]  [<ffffffff814651ac>] int_signal+0x12/0x17
    [ 8245.772641] Code: 1f 44 00 00 55 48 89 e5 41 56 41 55 41 54 53 49 89 f4 48 8b 46 70 a8 04 74 09 48 8b 5f 08 48 85 db 75 03 48 8b 1f 49 89 5c 24 68 <83> 7b 5c ff 74 04 f0 ff 43 50 49 83 7c 24 08 00 74 2c 4c 8d 6b
    [ 8245.772641] RIP  [<ffffffffa051c8e6>] btrfs_queue_work+0x2c/0x14d [btrfs]
    [ 8245.772641]  RSP <ffff88020d0478b8>
    [ 8245.845040] ---[ end trace a01d038397e99b93 ]---
    
    For logical reasons such as the phase of the moon, this happened more
    often with "-o inode_cache" than without any mount options.
    
    After some debugging it turned out to be simple to understand what was
    happening:
    
    1) close_ctree() is called;
    
    2) It then stops the transaction kthread, which commits the current
       transaction;
    
    3) It asks the cleaner kthread to stop, which is currently running
       btrfs_delete_unused_bgs();
    
    4) btrfs_delete_unused_bgs() finds an unused block group, starts a new
       transaction, deletes the block group, which implies COWing some
       tree nodes and leafs and dirtying their respective pages, and then
       finally it ends the transaction it started, without committing it;
    
    5) The cleaner kthread stops;
    
    6) close_ctree() releases (from memory) the block group objects, which
       produces the warning in the trace pasted above;
    
    7) Then it invalidates all pages of the btree inode, by calling
       invalidate_inode_pages2(), which waits for any pages under writeback,
       and releases any non-dirty pages;
    
    8) All work queues are destroyed (waiting first for their current tasks
       to finish execution);
    
    9) A final iput() is called against the btree inode;
    
    10) This iput triggers a writeback of the btree inode because it still
        has dirty pages;
    
    11) This starts the whole chain of callbacks for the btree inode until
        it eventually reaches btrfs_wq_submit_bio() where it leads to a
        NULL pointer dereference because the work queues were already
        destroyed.
    
    Fix this by making the cleaner commit any transaction that it started
    after the transaction kthread was stopped.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b59deb2c63f4..e5aad7f535aa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1751,6 +1751,7 @@ static int cleaner_kthread(void *arg)
 {
 	struct btrfs_root *root = arg;
 	int again;
+	struct btrfs_trans_handle *trans;
 
 	do {
 		again = 0;
@@ -1798,6 +1799,34 @@ static int cleaner_kthread(void *arg)
 			__set_current_state(TASK_RUNNING);
 		}
 	} while (!kthread_should_stop());
+
+	/*
+	 * Transaction kthread is stopped before us and wakes us up.
+	 * However we might have started a new transaction and COWed some
+	 * tree blocks when deleting unused block groups for example. So
+	 * make sure we commit the transaction we started to have a clean
+	 * shutdown when evicting the btree inode - if it has dirty pages
+	 * when we do the final iput() on it, eviction will trigger a
+	 * writeback for it which will fail with null pointer dereferences
+	 * since work queues and other resources were already released and
+	 * destroyed by the time the iput/eviction/writeback is made.
+	 */
+	trans = btrfs_attach_transaction(root);
+	if (IS_ERR(trans)) {
+		if (PTR_ERR(trans) != -ENOENT)
+			btrfs_err(root->fs_info,
+				  "cleaner transaction attach returned %ld",
+				  PTR_ERR(trans));
+	} else {
+		int ret;
+
+		ret = btrfs_commit_transaction(trans, root);
+		if (ret)
+			btrfs_err(root->fs_info,
+				  "cleaner open transaction commit returned %d",
+				  ret);
+	}
+
 	return 0;
 }
 

commit 67c5e7d464bc466471b05e027abe8a6b29687ebd
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jun 11 00:58:53 2015 +0100

    Btrfs: fix race between balance and unused block group deletion
    
    We have a race between deleting an unused block group and balancing the
    same block group that leads to an assertion failure/BUG(), producing the
    following trace:
    
    [181631.208236] BTRFS: assertion failed: 0, file: fs/btrfs/volumes.c, line: 2622
    [181631.220591] ------------[ cut here ]------------
    [181631.222959] kernel BUG at fs/btrfs/ctree.h:4062!
    [181631.223932] invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
    [181631.224566] Modules linked in: btrfs dm_flakey dm_mod crc32c_generic xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd grace fscache sunrpc loop fuse acpi_cpufreq parpor$
    [181631.224566] CPU: 8 PID: 17451 Comm: btrfs Tainted: G        W       4.1.0-rc5-btrfs-next-10+ #1
    [181631.224566] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.1-0-g4adadbd-20150316_085822-nilsson.home.kraxel.org 04/01/2014
    [181631.224566] task: ffff880127e09590 ti: ffff8800b5824000 task.ti: ffff8800b5824000
    [181631.224566] RIP: 0010:[<ffffffffa03f19f6>]  [<ffffffffa03f19f6>] assfail.constprop.50+0x1e/0x20 [btrfs]
    [181631.224566] RSP: 0018:ffff8800b5827ae8  EFLAGS: 00010246
    [181631.224566] RAX: 0000000000000040 RBX: ffff8800109fc218 RCX: ffffffff81095dce
    [181631.224566] RDX: 0000000000005124 RSI: ffffffff81464819 RDI: 00000000ffffffff
    [181631.224566] RBP: ffff8800b5827ae8 R08: 0000000000000001 R09: 0000000000000000
    [181631.224566] R10: 0000000000000000 R11: 0000000000000000 R12: ffff8800109fc200
    [181631.224566] R13: ffff880020095000 R14: ffff8800b1a13f38 R15: ffff880020095000
    [181631.224566] FS:  00007f70ca0b0c80(0000) GS:ffff88013ec00000(0000) knlGS:0000000000000000
    [181631.224566] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [181631.224566] CR2: 00007f2872ab6e68 CR3: 00000000a717c000 CR4: 00000000000006e0
    [181631.224566] Stack:
    [181631.224566]  ffff8800b5827ba8 ffffffffa03f3916 ffff8800b5827b38 ffffffffa03d080e
    [181631.224566]  ffffffffa03d1423 ffff880020095000 ffff88001233c000 0000000000000001
    [181631.224566]  ffff880020095000 ffff8800b1a13f38 0000000a69c00000 0000000000000000
    [181631.224566] Call Trace:
    [181631.224566]  [<ffffffffa03f3916>] btrfs_remove_chunk+0xa4/0x6bb [btrfs]
    [181631.224566]  [<ffffffffa03d080e>] ? join_transaction.isra.8+0xb9/0x3ba [btrfs]
    [181631.224566]  [<ffffffffa03d1423>] ? wait_current_trans.isra.13+0x22/0xfc [btrfs]
    [181631.224566]  [<ffffffffa03f3fbc>] btrfs_relocate_chunk.isra.29+0x8f/0xa7 [btrfs]
    [181631.224566]  [<ffffffffa03f54df>] btrfs_balance+0xaa4/0xc52 [btrfs]
    [181631.224566]  [<ffffffffa03fd388>] btrfs_ioctl_balance+0x23f/0x2b0 [btrfs]
    [181631.224566]  [<ffffffff810872f9>] ? trace_hardirqs_on+0xd/0xf
    [181631.224566]  [<ffffffffa04019a3>] btrfs_ioctl+0xfe2/0x2220 [btrfs]
    [181631.224566]  [<ffffffff812603ed>] ? __this_cpu_preempt_check+0x13/0x15
    [181631.224566]  [<ffffffff81084669>] ? arch_local_irq_save+0x9/0xc
    [181631.224566]  [<ffffffff81138def>] ? handle_mm_fault+0x834/0xcd2
    [181631.224566]  [<ffffffff81138def>] ? handle_mm_fault+0x834/0xcd2
    [181631.224566]  [<ffffffff8103e48c>] ? __do_page_fault+0x211/0x424
    [181631.224566]  [<ffffffff811755e6>] do_vfs_ioctl+0x3c6/0x479
    (...)
    
    The sequence of steps leading to this are:
    
               CPU 0                                         CPU 1
    
      btrfs_balance()
        btrfs_relocate_chunk()
    
          btrfs_relocate_block_group(bg X)
            btrfs_lookup_block_group(bg X)
    
                                                   cleaner_kthread
                                                      locks fs_info->cleaner_mutex
    
                                                      btrfs_delete_unused_bgs()
                                                        finds bg X, which became
                                                        unused in the previous
                                                        transaction
    
                                                        checks bg X ->ro == 0,
                                                        so it proceeds
            sets bg X ->ro to 1
            (btrfs_set_block_group_ro(bg X))
    
            blocks on fs_info->cleaner_mutex
                                                        btrfs_remove_chunk(bg X)
                                                      unlocks fs_info->cleaner_mutex
    
            acquires fs_info->cleaner_mutex
            relocate_block_group()
              --> does nothing, no extents found in
                  the extent tree from bg X
            unlocks fs_info->cleaner_mutex
    
          btrfs_relocate_block_group(bg X) returns
    
        btrfs_remove_chunk(bg X)
           extent map not found
              --> ASSERT(0)
    
    Fix this by using a new mutex to make sure these 2 operations, block
    group relocation and removal, are serialized.
    
    This issue is reproducible by running fstests generic/038 (which stresses
    chunk allocation and automatic removal of unused block groups) together
    with the following balance loop:
    
        while true; do btrfs balance start -dusage=0 <mountpoint> ; done
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b977fc8d8201..b59deb2c63f4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1772,7 +1772,6 @@ static int cleaner_kthread(void *arg)
 		}
 
 		btrfs_run_delayed_iputs(root);
-		btrfs_delete_unused_bgs(root->fs_info);
 		again = btrfs_clean_one_deleted_snapshot(root);
 		mutex_unlock(&root->fs_info->cleaner_mutex);
 
@@ -1781,6 +1780,16 @@ static int cleaner_kthread(void *arg)
 		 * needn't do anything special here.
 		 */
 		btrfs_run_defrag_inodes(root->fs_info);
+
+		/*
+		 * Acquires fs_info->delete_unused_bgs_mutex to avoid racing
+		 * with relocation (btrfs_relocate_chunk) and relocation
+		 * acquires fs_info->cleaner_mutex (btrfs_relocate_block_group)
+		 * after acquiring fs_info->delete_unused_bgs_mutex. So we
+		 * can't hold, nor need to, fs_info->cleaner_mutex when deleting
+		 * unused block groups.
+		 */
+		btrfs_delete_unused_bgs(root->fs_info);
 sleep:
 		if (!try_to_freeze() && !again) {
 			set_current_state(TASK_INTERRUPTIBLE);
@@ -2492,6 +2501,7 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->unused_bgs_lock);
 	rwlock_init(&fs_info->tree_mod_log_lock);
 	mutex_init(&fs_info->unused_bg_unpin_mutex);
+	mutex_init(&fs_info->delete_unused_bgs_mutex);
 	mutex_init(&fs_info->reloc_mutex);
 	mutex_init(&fs_info->delalloc_root_mutex);
 	seqlock_init(&fs_info->profiles_lock);

commit c40b7b064f6159df3a080595a498613d08206e59
Merge: 37b8d27de5d0 f90fc5472882
Author: Chris Mason <clm@fb.com>
Date:   Tue Jun 23 05:34:39 2015 -0700

    Merge branch 'sysfs-fsdevices-4.2-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into anand

commit 0eeff2362b829b5e80f8b69f86b60b8094bc742d
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Jun 11 14:16:44 2015 +0800

    Btrfs: fix use-after-free in btrfs_replay_log
    
    @log_root_tree should not be referenced after kfree.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Reported-by: Julia Lawall <julia.lawall@lip6.fr>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 695363ae1c28..b7fa3bac2cff 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2321,8 +2321,9 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 			fs_info->generation + 1);
 	if (IS_ERR(log_tree_root->node)) {
 		printk(KERN_ERR "BTRFS: failed to read log tree\n");
+		ret = PTR_ERR(log_tree_root->node);
 		kfree(log_tree_root);
-		return PTR_ERR(log_tree_root->node);
+		return ret;
 	} else if (!extent_buffer_uptodate(log_tree_root->node)) {
 		printk(KERN_ERR "BTRFS: failed to read log tree\n");
 		free_extent_buffer(log_tree_root->node);

commit c6fc24549960f26910cd0c6e4b5f48f2f306b11d
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Mar 30 17:03:00 2015 +0800

    btrfs: delayed-ref: Use list to replace the ref_root in ref_head.
    
    This patch replace the rbtree used in ref_head to list.
    This has the following advantage:
    1) Easier merge logic.
    With the new list implement, we only need to care merging the tail
    ref_node with the new ref_node.
    And this can be done quite easy at insert time, no need to do a
    indicated merge at run_delayed_refs().
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7f8377871283..695363ae1c28 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4062,6 +4062,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 
 	while ((node = rb_first(&delayed_refs->href_root)) != NULL) {
 		struct btrfs_delayed_ref_head *head;
+		struct btrfs_delayed_ref_node *tmp;
 		bool pin_bytes = false;
 
 		head = rb_entry(node, struct btrfs_delayed_ref_head,
@@ -4077,11 +4078,10 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 			continue;
 		}
 		spin_lock(&head->lock);
-		while ((node = rb_first(&head->ref_root)) != NULL) {
-			ref = rb_entry(node, struct btrfs_delayed_ref_node,
-				       rb_node);
+		list_for_each_entry_safe_reverse(ref, tmp, &head->ref_list,
+						 list) {
 			ref->in_tree = 0;
-			rb_erase(&ref->rb_node, &head->ref_root);
+			list_del(&ref->list);
 			atomic_dec(&delayed_refs->num_entries);
 			btrfs_put_delayed_ref(ref);
 		}

commit 64c043de466d5746e7ca306dab9d418cd871cefc
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon May 25 17:30:15 2015 +0800

    Btrfs: fix up read_tree_block to return proper error
    
    The return value of read_tree_block() can confuse callers as it always
    returns NULL for either -ENOMEM or -EIO, so it's likely that callers
    parse it to a wrong error, for instance, in btrfs_read_tree_root().
    
    This fixes the above issue.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2ef9a4b72d06..7f8377871283 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1149,12 +1149,12 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 
 	buf = btrfs_find_create_tree_block(root, bytenr);
 	if (!buf)
-		return NULL;
+		return ERR_PTR(-ENOMEM);
 
 	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 	if (ret) {
 		free_extent_buffer(buf);
-		return NULL;
+		return ERR_PTR(ret);
 	}
 	return buf;
 
@@ -1509,20 +1509,19 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	generation = btrfs_root_generation(&root->root_item);
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     generation);
-	if (!root->node) {
-		ret = -ENOMEM;
+	if (IS_ERR(root->node)) {
+		ret = PTR_ERR(root->node);
 		goto find_fail;
 	} else if (!btrfs_buffer_uptodate(root->node, generation, 0)) {
 		ret = -EIO;
-		goto read_fail;
+		free_extent_buffer(root->node);
+		goto find_fail;
 	}
 	root->commit_root = btrfs_root_node(root);
 out:
 	btrfs_free_path(path);
 	return root;
 
-read_fail:
-	free_extent_buffer(root->node);
 find_fail:
 	kfree(root);
 alloc_fail:
@@ -2320,8 +2319,11 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 
 	log_tree_root->node = read_tree_block(tree_root, bytenr,
 			fs_info->generation + 1);
-	if (!log_tree_root->node ||
-	    !extent_buffer_uptodate(log_tree_root->node)) {
+	if (IS_ERR(log_tree_root->node)) {
+		printk(KERN_ERR "BTRFS: failed to read log tree\n");
+		kfree(log_tree_root);
+		return PTR_ERR(log_tree_root->node);
+	} else if (!extent_buffer_uptodate(log_tree_root->node)) {
 		printk(KERN_ERR "BTRFS: failed to read log tree\n");
 		free_extent_buffer(log_tree_root->node);
 		kfree(log_tree_root);
@@ -2797,8 +2799,8 @@ int open_ctree(struct super_block *sb,
 	chunk_root->node = read_tree_block(chunk_root,
 					   btrfs_super_chunk_root(disk_super),
 					   generation);
-	if (!chunk_root->node ||
-	    !test_bit(EXTENT_BUFFER_UPTODATE, &chunk_root->node->bflags)) {
+	if (IS_ERR(chunk_root->node) ||
+	    !extent_buffer_uptodate(chunk_root->node)) {
 		printk(KERN_ERR "BTRFS: failed to read chunk root on %s\n",
 		       sb->s_id);
 		goto fail_tree_roots;
@@ -2834,8 +2836,8 @@ int open_ctree(struct super_block *sb,
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super),
 					  generation);
-	if (!tree_root->node ||
-	    !test_bit(EXTENT_BUFFER_UPTODATE, &tree_root->node->bflags)) {
+	if (IS_ERR(tree_root->node) ||
+	    !extent_buffer_uptodate(tree_root->node)) {
 		printk(KERN_WARNING "BTRFS: failed to read tree root on %s\n",
 		       sb->s_id);
 

commit b7c35e81adcd593daca2160b5ba0ec62f71a9303
Author: Anand Jain <anand.jain@oracle.com>
Date:   Tue Mar 10 06:38:38 2015 +0800

    Btrfs: sysfs: separate kobject and attribute creation
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c42503cf3462..d29a2515f1e8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2873,10 +2873,22 @@ int open_ctree(struct super_block *sb,
 
 	btrfs_close_extra_devices(fs_devices, 1);
 
+	ret = btrfs_sysfs_add_fsid(fs_devices, NULL);
+	if (ret) {
+		pr_err("BTRFS: failed to init sysfs fsid interface: %d\n", ret);
+		goto fail_block_groups;
+	}
+
+	ret = btrfs_sysfs_add_device(fs_devices);
+	if (ret) {
+		pr_err("BTRFS: failed to init sysfs device interface: %d\n", ret);
+		goto fail_fsdev_sysfs;
+	}
+
 	ret = btrfs_sysfs_add_one(fs_info);
 	if (ret) {
 		pr_err("BTRFS: failed to init sysfs interface: %d\n", ret);
-		goto fail_block_groups;
+		goto fail_fsdev_sysfs;
 	}
 
 	ret = btrfs_init_space_info(fs_info);
@@ -3054,6 +3066,9 @@ int open_ctree(struct super_block *sb,
 fail_sysfs:
 	btrfs_sysfs_remove_one(fs_info);
 
+fail_fsdev_sysfs:
+	btrfs_sysfs_remove_fsid(fs_info->fs_devices);
+
 fail_block_groups:
 	btrfs_put_block_group_cache(fs_info);
 	btrfs_free_block_groups(fs_info);
@@ -3731,6 +3746,7 @@ void close_ctree(struct btrfs_root *root)
 	}
 
 	btrfs_sysfs_remove_one(fs_info);
+	btrfs_sysfs_remove_fsid(fs_info->fs_devices);
 
 	btrfs_free_fs_roots(fs_info);
 

commit 4e51f005a22a2c7795351b975437b0cee0acce3e
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Tue Mar 10 06:38:20 2015 +0800

    Btrfs: sysfs: fix, fs_info kobject_unregister has init_completion() twice
    
    kobject_unregister is to handle the release of the kobject,
    its completion init is being called in btrfs_sysfs_add_one(),
    so we don't have to do the same in the open_ctree() again.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2ef9a4b72d06..c42503cf3462 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2494,7 +2494,6 @@ int open_ctree(struct super_block *sb,
 	seqlock_init(&fs_info->profiles_lock);
 	init_rwsem(&fs_info->delayed_iput_sem);
 
-	init_completion(&fs_info->kobj_unregister);
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
 	INIT_LIST_HEAD(&fs_info->space_info);
 	INIT_LIST_HEAD(&fs_info->tree_mod_seq_list);

commit 326e1dbb57368087a36607aaebe9795b8d5453e5
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Fri May 22 09:14:03 2015 -0400

    block: remove management of bi_remaining when restoring original bi_end_io
    
    Commit c4cf5261 ("bio: skip atomic inc/dec of ->bi_remaining for
    non-chains") regressed all existing callers that followed this pattern:
     1) saving a bio's original bi_end_io
     2) wiring up an intermediate bi_end_io
     3) restoring the original bi_end_io from intermediate bi_end_io
     4) calling bio_endio() to execute the restored original bi_end_io
    
    The regression was due to BIO_CHAIN only ever getting set if
    bio_inc_remaining() is called.  For the above pattern it isn't set until
    step 3 above (step 2 would've needed to establish BIO_CHAIN).  As such
    the first bio_endio(), in step 2 above, never decremented __bi_remaining
    before calling the intermediate bi_end_io -- leaving __bi_remaining with
    the value 1 instead of 0.  When bio_inc_remaining() occurred during step
    3 it brought it to a value of 2.  When the second bio_endio() was
    called, in step 4 above, it should've called the original bi_end_io but
    it didn't because there was an extra reference that wasn't dropped (due
    to atomic operations being optimized away since BIO_CHAIN wasn't set
    upfront).
    
    Fix this issue by removing the __bi_remaining management complexity for
    all callers that use the above pattern -- bio_chain() is the only
    interface that _needs_ to be concerned with __bi_remaining.  For the
    above pattern callers just expect the bi_end_io they set to get called!
    Remove bio_endio_nodec() and also remove all bio_inc_remaining() calls
    that aren't associated with the bio_chain() interface.
    
    Also, the bio_inc_remaining() interface has been moved local to bio.c.
    
    Fixes: c4cf5261 ("bio: skip atomic inc/dec of ->bi_remaining for non-chains")
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e08a926fe12c..0bccf18dc1dc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1745,7 +1745,7 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	bio->bi_private = end_io_wq->private;
 	bio->bi_end_io = end_io_wq->end_io;
 	kmem_cache_free(btrfs_end_io_wq_cache, end_io_wq);
-	bio_endio_nodec(bio, error);
+	bio_endio(bio, error);
 }
 
 static int cleaner_kthread(void *arg)

commit b25de9d6da49b1a8760a89672283128aa8c78345
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Apr 24 21:41:01 2015 +0200

    block: remove BIO_EOPNOTSUPP
    
    Since the big barrier rewrite/removal in 2007 we never fail FLUSH or
    FUA requests, which means we can remove the magic BIO_EOPNOTSUPP flag
    to help propagating those to the buffer_head layer.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2ef9a4b72d06..e08a926fe12c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3269,11 +3269,8 @@ static int write_dev_supers(struct btrfs_device *device,
  */
 static void btrfs_end_empty_barrier(struct bio *bio, int err)
 {
-	if (err) {
-		if (err == -EOPNOTSUPP)
-			set_bit(BIO_EOPNOTSUPP, &bio->bi_flags);
+	if (err)
 		clear_bit(BIO_UPTODATE, &bio->bi_flags);
-	}
 	if (bio->bi_private)
 		complete(bio->bi_private);
 	bio_put(bio);
@@ -3301,11 +3298,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 
 		wait_for_completion(&device->flush_wait);
 
-		if (bio_flagged(bio, BIO_EOPNOTSUPP)) {
-			printk_in_rcu("BTRFS: disabling barriers on dev %s\n",
-				      rcu_str_deref(device->name));
-			device->nobarriers = 1;
-		} else if (!bio_flagged(bio, BIO_UPTODATE)) {
+		if (!bio_flagged(bio, BIO_UPTODATE)) {
 			ret = -EIO;
 			btrfs_dev_stat_inc_and_print(device,
 				BTRFS_DEV_STAT_FLUSH_ERRS);

commit d7c151717a1efe289aec29fb9f94485f64262c0b
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Feb 26 10:49:20 2015 +0800

    btrfs: Fix NO_SPACE bug caused by delayed-iput
    
    Steps to reproduce:
      while true; do
        dd if=/dev/zero of=/btrfs_dir/file count=[fs_size * 75%]
        rm /btrfs_dir/file
        sync
      done
    
      And we'll see dd failed because btrfs return NO_SPACE.
    
    Reason:
      Normally, btrfs_commit_transaction() call btrfs_run_delayed_iputs()
      in end to free fs space for next write, but sometimes it hadn't
      done work on time, because btrfs-cleaner thread get delayed-iputs
      from list before, but do iput() after next write.
    
      This is log:
      [ 2569.050776] comm=btrfs-cleaner func=btrfs_evict_inode() begin
    
      [ 2569.084280] comm=sync func=btrfs_commit_transaction() call btrfs_run_delayed_iputs()
      [ 2569.085418] comm=sync func=btrfs_commit_transaction() done btrfs_run_delayed_iputs()
      [ 2569.087554] comm=sync func=btrfs_commit_transaction() end
    
      [ 2569.191081] comm=dd begin
      [ 2569.790112] comm=dd func=__btrfs_buffered_write() ret=-28
    
      [ 2569.847479] comm=btrfs-cleaner func=add_pinned_bytes() 0 + 32677888 = 32677888
      [ 2569.849530] comm=btrfs-cleaner func=add_pinned_bytes() 32677888 + 23834624 = 56512512
      ...
      [ 2569.903893] comm=btrfs-cleaner func=add_pinned_bytes() 943976448 + 21762048 = 965738496
      [ 2569.908270] comm=btrfs-cleaner func=btrfs_evict_inode() end
    
    Fix:
      Make btrfs_commit_transaction() wait current running btrfs-cleaner's
      delayed-iputs() done in end.
    
    Test:
      Use script similar to above(more complex),
      before patch:
        7 failed in 100 * 20 loop.
      after patch:
        0 failed in 100 * 20 loop.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 62cd3b63190d..2ef9a4b72d06 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2487,11 +2487,12 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->qgroup_op_lock);
 	spin_lock_init(&fs_info->buffer_lock);
 	spin_lock_init(&fs_info->unused_bgs_lock);
-	mutex_init(&fs_info->unused_bg_unpin_mutex);
 	rwlock_init(&fs_info->tree_mod_log_lock);
+	mutex_init(&fs_info->unused_bg_unpin_mutex);
 	mutex_init(&fs_info->reloc_mutex);
 	mutex_init(&fs_info->delalloc_root_mutex);
 	seqlock_init(&fs_info->profiles_lock);
+	init_rwsem(&fs_info->delayed_iput_sem);
 
 	init_completion(&fs_info->kobj_unregister);
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);

commit cdfb080e1853660952db5e5332727e59427856df
Author: Chris Mason <clm@fb.com>
Date:   Mon Apr 6 18:17:00 2015 -0700

    Btrfs: fix use after free when close_ctree frees the orphan_rsv
    
    Near the end of close_ctree, we're calling btrfs_free_block_rsv
    to free up the orphan rsv.  The problem is this call updates the
    space_info, which has already been freed.
    
    This adds a new __ function that directly calls kfree instead of trying
    to update the space infos.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b5e3d5f6400a..62cd3b63190d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3766,7 +3766,7 @@ void close_ctree(struct btrfs_root *root)
 
 	btrfs_free_stripe_hash_table(fs_info);
 
-	btrfs_free_block_rsv(root, root->orphan_block_rsv);
+	__btrfs_free_block_rsv(root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;
 
 	lock_chunks(root);

commit 1bbc621ef28462456131c035eaeb5567a1a2a2fe
Author: Chris Mason <clm@fb.com>
Date:   Mon Apr 6 12:46:08 2015 -0700

    Btrfs: allow block group cache writeout outside critical section in commit
    
    We loop through all of the dirty block groups during commit and write
    the free space cache.  In order to make sure the cache is currect, we do
    this while no other writers are allowed in the commit.
    
    If a large number of block groups are dirty, this can introduce long
    stalls during the final stages of the commit, which can block new procs
    trying to change the filesystem.
    
    This commit changes the block group cache writeout to take appropriate
    locks and allow it to run earlier in the commit.  We'll still have to
    redo some of the block groups, but it means we can get most of the work
    out of the way without blocking the entire FS.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 568cc4e3d80e..b5e3d5f6400a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2572,6 +2572,7 @@ int open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->transaction_kthread_mutex);
 	mutex_init(&fs_info->cleaner_mutex);
 	mutex_init(&fs_info->volume_mutex);
+	mutex_init(&fs_info->ro_block_group_mutex);
 	init_rwsem(&fs_info->commit_root_sem);
 	init_rwsem(&fs_info->cleanup_work_sem);
 	init_rwsem(&fs_info->subvol_sem);

commit e56a951e01bf55f49533c47ad2ce61dbd613a3f3
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Tue Mar 17 14:34:16 2015 +0800

    Btrfs: Remove the check for old-style mkfs
    
    This was used to make sure that a fresh btrfs from an older mkfs.btrfs,
    but it also allows us to mount a buggy btrfs if this btrfs has the right
    superblock head part but has something wrong with chunk tree part[1], and
    after that we can hit BUG_ON()s set in the code to prevent something
    impossible.
    
    Since David has released "Btrfs progs v3.19-rc2", just remove the check,
    if anyone who wants to make a fresh btrfs, please use the latest one.
    
    [1]: http://www.spinics.net/lists/linux-btrfs/msg42358.html
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Omar Sandoval <osandov@osandov.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 23c49ab2de4c..568cc4e3d80e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -419,12 +419,6 @@ static int btrfs_check_super_csum(char *raw_disk_sb)
 
 		if (memcmp(raw_disk_sb, result, csum_size))
 			ret = 1;
-
-		if (ret && btrfs_super_generation(disk_sb) < 10) {
-			printk(KERN_WARNING
-				"BTRFS: super block crcs don't match, older mkfs detected\n");
-			ret = 0;
-		}
 	}
 
 	if (csum_type >= ARRAY_SIZE(btrfs_csum_sizes)) {

commit fc4c3c872f44bf425963feba57eb9c3f8ac2d7eb
Merge: 9deed229fa8a a4f3d2c4efe2
Author: Chris Mason <clm@fb.com>
Date:   Wed Mar 25 10:52:48 2015 -0700

    Merge branch 'cleanups-post-3.19' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.1
    
    Signed-off-by: Chris Mason <clm@fb.com>
    
    Conflicts:
            fs/btrfs/disk-io.c

commit 9deed229fa8a83bb5cd713b2d2a8e5c022a4b45b
Merge: bc465aa9d045 258ece02126a
Author: Chris Mason <clm@fb.com>
Date:   Wed Mar 25 10:43:16 2015 -0700

    Merge branch 'cleanups-for-4.1-v2' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus-4.1

commit 521d474631310e8aafef7953a8a7f7d1efd42da6
Merge: 0d122f7430ed e1cbbfa5f5aa
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 21 10:53:37 2015 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "Most of these are fixing extent reservation accounting, or corners
      with tree writeback during commit.
    
      Josef's set does add a test, which isn't strictly a fix, but it'll
      keep us from making this same mistake again"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix outstanding_extents accounting in DIO
      Btrfs: add sanity test for outstanding_extents accounting
      Btrfs: just free dummy extent buffers
      Btrfs: account merges/splits properly
      Btrfs: prepare block group cache before writing
      Btrfs: fix ASSERT(list_empty(&cur_trans->dirty_bgs_list)
      Btrfs: account for the correct number of extents for delalloc reservations
      Btrfs: fix merge delalloc logic
      Btrfs: fix comp_oper to get right order
      Btrfs: catch transaction abortion after waiting for it
      btrfs: fix sizeof format specifier in btrfs_check_super_valid()

commit d22071293f17eedc96df25093d8e99d09cd76463
Author: Fabian Frederick <fabf@skynet.be>
Date:   Sat Feb 14 13:10:22 2015 +0100

    btrfs: fix sizeof format specifier in btrfs_check_super_valid()
    
    This patch fixes mips compilation warning:
    
    fs/btrfs/disk-io.c: In function 'btrfs_check_super_valid':
    fs/btrfs/disk-io.c:3927:21: warning: format '%lu' expects argument
    of type 'long unsigned int', but argument 3 has type 'unsigned int' [-Wformat]
    
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 41b320e235d7..1577b91940dd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3923,7 +3923,7 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	}
 	if (btrfs_super_sys_array_size(sb) < sizeof(struct btrfs_disk_key)
 			+ sizeof(struct btrfs_chunk)) {
-		printk(KERN_ERR "BTRFS: system chunk array too small %u < %lu\n",
+		printk(KERN_ERR "BTRFS: system chunk array too small %u < %zu\n",
 				btrfs_super_sys_array_size(sb),
 				sizeof(struct btrfs_disk_key)
 				+ sizeof(struct btrfs_chunk));

commit 31e818fe7375d60de9953051f7bd1615cebc3681
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Feb 20 18:00:26 2015 +0100

    btrfs: cleanup, use kmalloc_array/kcalloc array helpers
    
    Convert kmalloc(nr * size, ..) to kmalloc_array that does additional
    overflow checks, the zeroing variant is kcalloc.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 73b152138221..14e4a3e0f9b2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -302,7 +302,7 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 		offset += cur_len;
 	}
 	if (csum_size > sizeof(inline_result)) {
-		result = kzalloc(csum_size * sizeof(char), GFP_NOFS);
+		result = kzalloc(csum_size, GFP_NOFS);
 		if (!result)
 			return 1;
 	} else {

commit f8c269d7223f6b63cc5936eb191bc3b170d24342
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Jan 16 17:21:12 2015 +0100

    btrfs: cleanup 64bit/32bit divs, compile time constants
    
    Switch to div_u64 if the divisor is a numeric constant or sum of
    sizeof()s. We can remove a few instances of do_div that has the hidden
    semtantics of changing the 1st argument.
    
    Small power-of-two divisors are converted to bitshifts, large values are
    kept intact for clarity.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 41b320e235d7..73b152138221 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2277,7 +2277,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->free_chunk_space = 0;
 	fs_info->tree_mod_log = RB_ROOT;
 	fs_info->commit_interval = BTRFS_DEFAULT_COMMIT_INTERVAL;
-	fs_info->avg_delayed_ref_runtime = div64_u64(NSEC_PER_SEC, 64);
+	fs_info->avg_delayed_ref_runtime = NSEC_PER_SEC >> 6; /* div by 64 */
 	/* readahead state */
 	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_WAIT);
 	spin_lock_init(&fs_info->reada_lock);

commit 2b9fb532d4168e8974fe49709e2c4c8d5352a64c
Merge: 4533f6e27a36 a742994aa2e2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 19 14:36:00 2015 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This pull is mostly cleanups and fixes:
    
       - The raid5/6 cleanups from Zhao Lei fixup some long standing warts
         in the code and add improvements on top of the scrubbing support
         from 3.19.
    
       - Josef has round one of our ENOSPC fixes coming from large btrfs
         clusters here at FB.
    
       - Dave Sterba continues a long series of cleanups (thanks Dave), and
         Filipe continues hammering on corner cases in fsync and others
    
      This all was held up a little trying to track down a use-after-free in
      btrfs raid5/6.  It's not clear yet if this is just made easier to
      trigger with this pull or if its a new bug from the raid5/6 cleanups.
      Dave Sterba is the only one to trigger it so far, but he has a
      consistent way to reproduce, so we'll get it nailed shortly"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (68 commits)
      Btrfs: don't remove extents and xattrs when logging new names
      Btrfs: fix fsync data loss after adding hard link to inode
      Btrfs: fix BUG_ON in btrfs_orphan_add() when delete unused block group
      Btrfs: account for large extents with enospc
      Btrfs: don't set and clear delalloc for O_DIRECT writes
      Btrfs: only adjust outstanding_extents when we do a short write
      btrfs: Fix out-of-space bug
      Btrfs: scrub, fix sleep in atomic context
      Btrfs: fix scheduler warning when syncing log
      Btrfs: Remove unnecessary placeholder in btrfs_err_code
      btrfs: cleanup init for list in free-space-cache
      btrfs: delete chunk allocation attemp when setting block group ro
      btrfs: clear bio reference after submit_one_bio()
      Btrfs: fix scrub race leading to use-after-free
      Btrfs: add missing cleanup on sysfs init failure
      Btrfs: fix race between transaction commit and empty block group removal
      btrfs: add more checks to btrfs_read_sys_array
      btrfs: cleanup, rename a few variables in btrfs_read_sys_array
      btrfs: add checks for sys_chunk_array sizes
      btrfs: more superblock checks, lower bounds on devices and sectorsize/nodesize
      ...

commit a4f3d2c4efe2628329249b64fd5799468e025b9d
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Feb 16 18:44:34 2015 +0100

    btrfs: cleanup, reduce temporary variables in btrfs_read_roots
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 29cb50b4981e..f770e8b5cb86 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2357,11 +2357,7 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 static int btrfs_read_roots(struct btrfs_fs_info *fs_info,
 			    struct btrfs_root *tree_root)
 {
-	struct btrfs_root *extent_root;
-	struct btrfs_root *dev_root;
-	struct btrfs_root *csum_root;
-	struct btrfs_root *quota_root;
-	struct btrfs_root *uuid_root;
+	struct btrfs_root *root;
 	struct btrfs_key location;
 	int ret;
 
@@ -2369,45 +2365,45 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info,
 	location.type = BTRFS_ROOT_ITEM_KEY;
 	location.offset = 0;
 
-	extent_root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(extent_root))
-		return PTR_ERR(extent_root);
-	set_bit(BTRFS_ROOT_TRACK_DIRTY, &extent_root->state);
-	fs_info->extent_root = extent_root;
+	root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(root))
+		return PTR_ERR(root);
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
+	fs_info->extent_root = root;
 
 	location.objectid = BTRFS_DEV_TREE_OBJECTID;
-	dev_root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(dev_root))
-		return PTR_ERR(dev_root);
-	set_bit(BTRFS_ROOT_TRACK_DIRTY, &dev_root->state);
-	fs_info->dev_root = dev_root;
+	root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(root))
+		return PTR_ERR(root);
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
+	fs_info->dev_root = root;
 	btrfs_init_devices_late(fs_info);
 
 	location.objectid = BTRFS_CSUM_TREE_OBJECTID;
-	csum_root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(csum_root))
-		return PTR_ERR(csum_root);
-	set_bit(BTRFS_ROOT_TRACK_DIRTY, &csum_root->state);
-	fs_info->csum_root = csum_root;
+	root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(root))
+		return PTR_ERR(root);
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
+	fs_info->csum_root = root;
 
 	location.objectid = BTRFS_QUOTA_TREE_OBJECTID;
-	quota_root = btrfs_read_tree_root(tree_root, &location);
-	if (!IS_ERR(quota_root)) {
-		set_bit(BTRFS_ROOT_TRACK_DIRTY, &quota_root->state);
+	root = btrfs_read_tree_root(tree_root, &location);
+	if (!IS_ERR(root)) {
+		set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
 		fs_info->quota_enabled = 1;
 		fs_info->pending_quota_state = 1;
-		fs_info->quota_root = quota_root;
+		fs_info->quota_root = root;
 	}
 
 	location.objectid = BTRFS_UUID_TREE_OBJECTID;
-	uuid_root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(uuid_root)) {
-		ret = PTR_ERR(uuid_root);
+	root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(root)) {
+		ret = PTR_ERR(root);
 		if (ret != -ENOENT)
 			return ret;
 	} else {
-		set_bit(BTRFS_ROOT_TRACK_DIRTY, &uuid_root->state);
-		fs_info->uuid_root = uuid_root;
+		set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
+		fs_info->uuid_root = root;
 	}
 
 	return 0;

commit 6f0110581911623df08bf4b65fdef4548ebcda0a
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Feb 16 18:34:01 2015 +0100

    btrfs: use correct type for workqueue flags
    
    Through all the local wrappers to alloc_workqueue, __alloc_workqueue_key
    takes an unsigned int.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c7546d6512cc..29cb50b4981e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2227,7 +2227,7 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 		struct btrfs_fs_devices *fs_devices)
 {
 	int max_active = fs_info->thread_pool_size;
-	int flags = WQ_MEM_RECLAIM | WQ_FREEZABLE | WQ_UNBOUND;
+	unsigned int flags = WQ_MEM_RECLAIM | WQ_FREEZABLE | WQ_UNBOUND;
 
 	fs_info->workers =
 		btrfs_alloc_workqueue("worker", flags | WQ_HIGHPRI,

commit 4bbcaa648d23470f04285c52a27d87c8fe906203
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Fri Aug 1 18:12:45 2014 -0500

    btrfs: factor btrfs_read_roots() out of open_ctree()
    
    Also, remove the two local variables create_uuid_tree
    and check_uuid_tree; we can use the existence of
    the uuid root and/or the RESCAN_UUID_TREE flag to
    determine what action to take.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 954f0658dd0e..c7546d6512cc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2354,6 +2354,65 @@ static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
 	return 0;
 }
 
+static int btrfs_read_roots(struct btrfs_fs_info *fs_info,
+			    struct btrfs_root *tree_root)
+{
+	struct btrfs_root *extent_root;
+	struct btrfs_root *dev_root;
+	struct btrfs_root *csum_root;
+	struct btrfs_root *quota_root;
+	struct btrfs_root *uuid_root;
+	struct btrfs_key location;
+	int ret;
+
+	location.objectid = BTRFS_EXTENT_TREE_OBJECTID;
+	location.type = BTRFS_ROOT_ITEM_KEY;
+	location.offset = 0;
+
+	extent_root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(extent_root))
+		return PTR_ERR(extent_root);
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &extent_root->state);
+	fs_info->extent_root = extent_root;
+
+	location.objectid = BTRFS_DEV_TREE_OBJECTID;
+	dev_root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(dev_root))
+		return PTR_ERR(dev_root);
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &dev_root->state);
+	fs_info->dev_root = dev_root;
+	btrfs_init_devices_late(fs_info);
+
+	location.objectid = BTRFS_CSUM_TREE_OBJECTID;
+	csum_root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(csum_root))
+		return PTR_ERR(csum_root);
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &csum_root->state);
+	fs_info->csum_root = csum_root;
+
+	location.objectid = BTRFS_QUOTA_TREE_OBJECTID;
+	quota_root = btrfs_read_tree_root(tree_root, &location);
+	if (!IS_ERR(quota_root)) {
+		set_bit(BTRFS_ROOT_TRACK_DIRTY, &quota_root->state);
+		fs_info->quota_enabled = 1;
+		fs_info->pending_quota_state = 1;
+		fs_info->quota_root = quota_root;
+	}
+
+	location.objectid = BTRFS_UUID_TREE_OBJECTID;
+	uuid_root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(uuid_root)) {
+		ret = PTR_ERR(uuid_root);
+		if (ret != -ENOENT)
+			return ret;
+	} else {
+		set_bit(BTRFS_ROOT_TRACK_DIRTY, &uuid_root->state);
+		fs_info->uuid_root = uuid_root;
+	}
+
+	return 0;
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2368,19 +2427,12 @@ int open_ctree(struct super_block *sb,
 	struct btrfs_super_block *disk_super;
 	struct btrfs_fs_info *fs_info = btrfs_sb(sb);
 	struct btrfs_root *tree_root;
-	struct btrfs_root *extent_root;
-	struct btrfs_root *csum_root;
 	struct btrfs_root *chunk_root;
-	struct btrfs_root *dev_root;
-	struct btrfs_root *quota_root;
-	struct btrfs_root *uuid_root;
 	int ret;
 	int err = -EINVAL;
 	int num_backups_tried = 0;
 	int backup_index = 0;
 	int max_active;
-	bool create_uuid_tree;
-	bool check_uuid_tree;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info);
@@ -2804,61 +2856,9 @@ int open_ctree(struct super_block *sb,
 	tree_root->commit_root = btrfs_root_node(tree_root);
 	btrfs_set_root_refs(&tree_root->root_item, 1);
 
-	location.objectid = BTRFS_EXTENT_TREE_OBJECTID;
-	location.type = BTRFS_ROOT_ITEM_KEY;
-	location.offset = 0;
-
-	extent_root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(extent_root)) {
-		ret = PTR_ERR(extent_root);
-		goto recovery_tree_root;
-	}
-	set_bit(BTRFS_ROOT_TRACK_DIRTY, &extent_root->state);
-	fs_info->extent_root = extent_root;
-
-	location.objectid = BTRFS_DEV_TREE_OBJECTID;
-	dev_root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(dev_root)) {
-		ret = PTR_ERR(dev_root);
-		goto recovery_tree_root;
-	}
-	set_bit(BTRFS_ROOT_TRACK_DIRTY, &dev_root->state);
-	fs_info->dev_root = dev_root;
-	btrfs_init_devices_late(fs_info);
-
-	location.objectid = BTRFS_CSUM_TREE_OBJECTID;
-	csum_root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(csum_root)) {
-		ret = PTR_ERR(csum_root);
+	ret = btrfs_read_roots(fs_info, tree_root);
+	if (ret)
 		goto recovery_tree_root;
-	}
-	set_bit(BTRFS_ROOT_TRACK_DIRTY, &csum_root->state);
-	fs_info->csum_root = csum_root;
-
-	location.objectid = BTRFS_QUOTA_TREE_OBJECTID;
-	quota_root = btrfs_read_tree_root(tree_root, &location);
-	if (!IS_ERR(quota_root)) {
-		set_bit(BTRFS_ROOT_TRACK_DIRTY, &quota_root->state);
-		fs_info->quota_enabled = 1;
-		fs_info->pending_quota_state = 1;
-		fs_info->quota_root = quota_root;
-	}
-
-	location.objectid = BTRFS_UUID_TREE_OBJECTID;
-	uuid_root = btrfs_read_tree_root(tree_root, &location);
-	if (IS_ERR(uuid_root)) {
-		ret = PTR_ERR(uuid_root);
-		if (ret != -ENOENT)
-			goto recovery_tree_root;
-		create_uuid_tree = true;
-		check_uuid_tree = false;
-	} else {
-		set_bit(BTRFS_ROOT_TRACK_DIRTY, &uuid_root->state);
-		fs_info->uuid_root = uuid_root;
-		create_uuid_tree = false;
-		check_uuid_tree =
-		    generation != btrfs_super_uuid_tree_generation(disk_super);
-	}
 
 	fs_info->generation = generation;
 	fs_info->last_trans_committed = generation;
@@ -2896,7 +2896,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_sysfs;
 	}
 
-	ret = btrfs_read_block_groups(extent_root);
+	ret = btrfs_read_block_groups(fs_info->extent_root);
 	if (ret) {
 		printk(KERN_ERR "BTRFS: Failed to read block groups: %d\n", ret);
 		goto fail_sysfs;
@@ -3019,7 +3019,7 @@ int open_ctree(struct super_block *sb,
 
 	btrfs_qgroup_rescan_resume(fs_info);
 
-	if (create_uuid_tree) {
+	if (!fs_info->uuid_root) {
 		pr_info("BTRFS: creating UUID tree\n");
 		ret = btrfs_create_uuid_tree(fs_info);
 		if (ret) {
@@ -3028,8 +3028,9 @@ int open_ctree(struct super_block *sb,
 			close_ctree(tree_root);
 			return ret;
 		}
-	} else if (check_uuid_tree ||
-		   btrfs_test_opt(tree_root, RESCAN_UUID_TREE)) {
+	} else if (btrfs_test_opt(tree_root, RESCAN_UUID_TREE) ||
+		   fs_info->generation !=
+				btrfs_super_uuid_tree_generation(disk_super)) {
 		pr_info("BTRFS: checking UUID tree\n");
 		ret = btrfs_check_uuid_tree(fs_info);
 		if (ret) {

commit 63443bf54a746fada8ef2829148a29f28f07f7af
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Fri Aug 1 18:12:46 2014 -0500

    btrfs: factor btrfs_replay_log() out of open_ctree()
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9ecd19d98f89..954f0658dd0e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2303,6 +2303,57 @@ static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
 	return 0;
 }
 
+static int btrfs_replay_log(struct btrfs_fs_info *fs_info,
+			    struct btrfs_fs_devices *fs_devices)
+{
+	int ret;
+	struct btrfs_root *tree_root = fs_info->tree_root;
+	struct btrfs_root *log_tree_root;
+	struct btrfs_super_block *disk_super = fs_info->super_copy;
+	u64 bytenr = btrfs_super_log_root(disk_super);
+
+	if (fs_devices->rw_devices == 0) {
+		printk(KERN_WARNING "BTRFS: log replay required "
+		       "on RO media\n");
+		return -EIO;
+	}
+
+	log_tree_root = btrfs_alloc_root(fs_info);
+	if (!log_tree_root)
+		return -ENOMEM;
+
+	__setup_root(tree_root->nodesize, tree_root->sectorsize,
+			tree_root->stripesize, log_tree_root, fs_info,
+			BTRFS_TREE_LOG_OBJECTID);
+
+	log_tree_root->node = read_tree_block(tree_root, bytenr,
+			fs_info->generation + 1);
+	if (!log_tree_root->node ||
+	    !extent_buffer_uptodate(log_tree_root->node)) {
+		printk(KERN_ERR "BTRFS: failed to read log tree\n");
+		free_extent_buffer(log_tree_root->node);
+		kfree(log_tree_root);
+		return -EIO;
+	}
+	/* returns with log_tree_root freed on success */
+	ret = btrfs_recover_log_trees(log_tree_root);
+	if (ret) {
+		btrfs_error(tree_root->fs_info, ret,
+			    "Failed to recover log tree");
+		free_extent_buffer(log_tree_root->node);
+		kfree(log_tree_root);
+		return ret;
+	}
+
+	if (fs_info->sb->s_flags & MS_RDONLY) {
+		ret = btrfs_commit_super(tree_root);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2323,7 +2374,6 @@ int open_ctree(struct super_block *sb,
 	struct btrfs_root *dev_root;
 	struct btrfs_root *quota_root;
 	struct btrfs_root *uuid_root;
-	struct btrfs_root *log_tree_root;
 	int ret;
 	int err = -EINVAL;
 	int num_backups_tried = 0;
@@ -2904,48 +2954,11 @@ int open_ctree(struct super_block *sb,
 
 	/* do not make disk changes in broken FS */
 	if (btrfs_super_log_root(disk_super) != 0) {
-		u64 bytenr = btrfs_super_log_root(disk_super);
-
-		if (fs_devices->rw_devices == 0) {
-			printk(KERN_WARNING "BTRFS: log replay required "
-			       "on RO media\n");
-			err = -EIO;
-			goto fail_qgroup;
-		}
-
-		log_tree_root = btrfs_alloc_root(fs_info);
-		if (!log_tree_root) {
-			err = -ENOMEM;
-			goto fail_qgroup;
-		}
-
-		__setup_root(nodesize, sectorsize, stripesize,
-			     log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
-
-		log_tree_root->node = read_tree_block(tree_root, bytenr,
-						      generation + 1);
-		if (!log_tree_root->node ||
-		    !extent_buffer_uptodate(log_tree_root->node)) {
-			printk(KERN_ERR "BTRFS: failed to read log tree\n");
-			free_extent_buffer(log_tree_root->node);
-			kfree(log_tree_root);
-			goto fail_qgroup;
-		}
-		/* returns with log_tree_root freed on success */
-		ret = btrfs_recover_log_trees(log_tree_root);
+		ret = btrfs_replay_log(fs_info, fs_devices);
 		if (ret) {
-			btrfs_error(tree_root->fs_info, ret,
-				    "Failed to recover log tree");
-			free_extent_buffer(log_tree_root->node);
-			kfree(log_tree_root);
+			err = ret;
 			goto fail_qgroup;
 		}
-
-		if (sb->s_flags & MS_RDONLY) {
-			ret = btrfs_commit_super(tree_root);
-			if (ret)
-				goto fail_qgroup;
-		}
 	}
 
 	ret = btrfs_find_orphan_roots(tree_root);

commit 2a4581983f90d829d9aeaa4cb881031950f54937
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Mon Feb 16 16:29:26 2015 +0100

    btrfs: factor btrfs_init_workqueues() out of open_ctree()
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    [renamed to btrfs_init_workqueues]
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1d8db0bb0d4f..9ecd19d98f89 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2223,6 +2223,86 @@ static void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)
 	mutex_init(&fs_info->qgroup_rescan_lock);
 }
 
+static int btrfs_init_workqueues(struct btrfs_fs_info *fs_info,
+		struct btrfs_fs_devices *fs_devices)
+{
+	int max_active = fs_info->thread_pool_size;
+	int flags = WQ_MEM_RECLAIM | WQ_FREEZABLE | WQ_UNBOUND;
+
+	fs_info->workers =
+		btrfs_alloc_workqueue("worker", flags | WQ_HIGHPRI,
+				      max_active, 16);
+
+	fs_info->delalloc_workers =
+		btrfs_alloc_workqueue("delalloc", flags, max_active, 2);
+
+	fs_info->flush_workers =
+		btrfs_alloc_workqueue("flush_delalloc", flags, max_active, 0);
+
+	fs_info->caching_workers =
+		btrfs_alloc_workqueue("cache", flags, max_active, 0);
+
+	/*
+	 * a higher idle thresh on the submit workers makes it much more
+	 * likely that bios will be send down in a sane order to the
+	 * devices
+	 */
+	fs_info->submit_workers =
+		btrfs_alloc_workqueue("submit", flags,
+				      min_t(u64, fs_devices->num_devices,
+					    max_active), 64);
+
+	fs_info->fixup_workers =
+		btrfs_alloc_workqueue("fixup", flags, 1, 0);
+
+	/*
+	 * endios are largely parallel and should have a very
+	 * low idle thresh
+	 */
+	fs_info->endio_workers =
+		btrfs_alloc_workqueue("endio", flags, max_active, 4);
+	fs_info->endio_meta_workers =
+		btrfs_alloc_workqueue("endio-meta", flags, max_active, 4);
+	fs_info->endio_meta_write_workers =
+		btrfs_alloc_workqueue("endio-meta-write", flags, max_active, 2);
+	fs_info->endio_raid56_workers =
+		btrfs_alloc_workqueue("endio-raid56", flags, max_active, 4);
+	fs_info->endio_repair_workers =
+		btrfs_alloc_workqueue("endio-repair", flags, 1, 0);
+	fs_info->rmw_workers =
+		btrfs_alloc_workqueue("rmw", flags, max_active, 2);
+	fs_info->endio_write_workers =
+		btrfs_alloc_workqueue("endio-write", flags, max_active, 2);
+	fs_info->endio_freespace_worker =
+		btrfs_alloc_workqueue("freespace-write", flags, max_active, 0);
+	fs_info->delayed_workers =
+		btrfs_alloc_workqueue("delayed-meta", flags, max_active, 0);
+	fs_info->readahead_workers =
+		btrfs_alloc_workqueue("readahead", flags, max_active, 2);
+	fs_info->qgroup_rescan_workers =
+		btrfs_alloc_workqueue("qgroup-rescan", flags, 1, 0);
+	fs_info->extent_workers =
+		btrfs_alloc_workqueue("extent-refs", flags,
+				      min_t(u64, fs_devices->num_devices,
+					    max_active), 8);
+
+	if (!(fs_info->workers && fs_info->delalloc_workers &&
+	      fs_info->submit_workers && fs_info->flush_workers &&
+	      fs_info->endio_workers && fs_info->endio_meta_workers &&
+	      fs_info->endio_meta_write_workers &&
+	      fs_info->endio_repair_workers &&
+	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
+	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
+	      fs_info->caching_workers && fs_info->readahead_workers &&
+	      fs_info->fixup_workers && fs_info->delayed_workers &&
+	      fs_info->extent_workers &&
+	      fs_info->qgroup_rescan_workers)) {
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2249,7 +2329,6 @@ int open_ctree(struct super_block *sb,
 	int num_backups_tried = 0;
 	int backup_index = 0;
 	int max_active;
-	int flags = WQ_MEM_RECLAIM | WQ_FREEZABLE | WQ_UNBOUND;
 	bool create_uuid_tree;
 	bool check_uuid_tree;
 
@@ -2581,75 +2660,9 @@ int open_ctree(struct super_block *sb,
 
 	max_active = fs_info->thread_pool_size;
 
-	fs_info->workers =
-		btrfs_alloc_workqueue("worker", flags | WQ_HIGHPRI,
-				      max_active, 16);
-
-	fs_info->delalloc_workers =
-		btrfs_alloc_workqueue("delalloc", flags, max_active, 2);
-
-	fs_info->flush_workers =
-		btrfs_alloc_workqueue("flush_delalloc", flags, max_active, 0);
-
-	fs_info->caching_workers =
-		btrfs_alloc_workqueue("cache", flags, max_active, 0);
-
-	/*
-	 * a higher idle thresh on the submit workers makes it much more
-	 * likely that bios will be send down in a sane order to the
-	 * devices
-	 */
-	fs_info->submit_workers =
-		btrfs_alloc_workqueue("submit", flags,
-				      min_t(u64, fs_devices->num_devices,
-					    max_active), 64);
-
-	fs_info->fixup_workers =
-		btrfs_alloc_workqueue("fixup", flags, 1, 0);
-
-	/*
-	 * endios are largely parallel and should have a very
-	 * low idle thresh
-	 */
-	fs_info->endio_workers =
-		btrfs_alloc_workqueue("endio", flags, max_active, 4);
-	fs_info->endio_meta_workers =
-		btrfs_alloc_workqueue("endio-meta", flags, max_active, 4);
-	fs_info->endio_meta_write_workers =
-		btrfs_alloc_workqueue("endio-meta-write", flags, max_active, 2);
-	fs_info->endio_raid56_workers =
-		btrfs_alloc_workqueue("endio-raid56", flags, max_active, 4);
-	fs_info->endio_repair_workers =
-		btrfs_alloc_workqueue("endio-repair", flags, 1, 0);
-	fs_info->rmw_workers =
-		btrfs_alloc_workqueue("rmw", flags, max_active, 2);
-	fs_info->endio_write_workers =
-		btrfs_alloc_workqueue("endio-write", flags, max_active, 2);
-	fs_info->endio_freespace_worker =
-		btrfs_alloc_workqueue("freespace-write", flags, max_active, 0);
-	fs_info->delayed_workers =
-		btrfs_alloc_workqueue("delayed-meta", flags, max_active, 0);
-	fs_info->readahead_workers =
-		btrfs_alloc_workqueue("readahead", flags, max_active, 2);
-	fs_info->qgroup_rescan_workers =
-		btrfs_alloc_workqueue("qgroup-rescan", flags, 1, 0);
-	fs_info->extent_workers =
-		btrfs_alloc_workqueue("extent-refs", flags,
-				      min_t(u64, fs_devices->num_devices,
-					    max_active), 8);
-
-	if (!(fs_info->workers && fs_info->delalloc_workers &&
-	      fs_info->submit_workers && fs_info->flush_workers &&
-	      fs_info->endio_workers && fs_info->endio_meta_workers &&
-	      fs_info->endio_meta_write_workers &&
-	      fs_info->endio_repair_workers &&
-	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
-	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
-	      fs_info->caching_workers && fs_info->readahead_workers &&
-	      fs_info->fixup_workers && fs_info->delayed_workers &&
-	      fs_info->extent_workers &&
-	      fs_info->qgroup_rescan_workers)) {
-		err = -ENOMEM;
+	ret = btrfs_init_workqueues(fs_info, fs_devices);
+	if (ret) {
+		err = ret;
 		goto fail_sb_buffer;
 	}
 

commit f9e92e40b517bfe94d9e961ff484ab885348f322
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Fri Aug 1 18:12:42 2014 -0500

    btrfs: factor btrfs_init_qgroup() out of open_ctree()
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    [renamed to btrfs_init_qgroup]
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2b905a76a45e..1d8db0bb0d4f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2209,6 +2209,20 @@ static void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)
 	init_waitqueue_head(&fs_info->replace_wait);
 }
 
+static void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)
+{
+	spin_lock_init(&fs_info->qgroup_lock);
+	mutex_init(&fs_info->qgroup_ioctl_lock);
+	fs_info->qgroup_tree = RB_ROOT;
+	fs_info->qgroup_op_tree = RB_ROOT;
+	INIT_LIST_HEAD(&fs_info->dirty_qgroups);
+	fs_info->qgroup_seq = 1;
+	fs_info->quota_enabled = 0;
+	fs_info->pending_quota_state = 0;
+	fs_info->qgroup_ulist = NULL;
+	mutex_init(&fs_info->qgroup_rescan_lock);
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2395,17 +2409,7 @@ int open_ctree(struct super_block *sb,
 	sema_init(&fs_info->uuid_tree_rescan_sem, 1);
 
 	btrfs_init_dev_replace_locks(fs_info);
-
-	spin_lock_init(&fs_info->qgroup_lock);
-	mutex_init(&fs_info->qgroup_ioctl_lock);
-	fs_info->qgroup_tree = RB_ROOT;
-	fs_info->qgroup_op_tree = RB_ROOT;
-	INIT_LIST_HEAD(&fs_info->dirty_qgroups);
-	fs_info->qgroup_seq = 1;
-	fs_info->quota_enabled = 0;
-	fs_info->pending_quota_state = 0;
-	fs_info->qgroup_ulist = NULL;
-	mutex_init(&fs_info->qgroup_rescan_lock);
+	btrfs_init_qgroup(fs_info);
 
 	btrfs_init_free_cluster(&fs_info->meta_alloc_cluster);
 	btrfs_init_free_cluster(&fs_info->data_alloc_cluster);

commit ad6183680c0845ff8052a919b97c71b4fec8f33a
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Fri Aug 1 18:12:41 2014 -0500

    btrfs: factor btrfs_init_dev_replace_locks() out of open_ctree()
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    [renamed to btrfs_init_dev_replace_locks]
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6a64e666de05..2b905a76a45e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2199,6 +2199,16 @@ static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info,
 	btrfs_insert_inode_hash(fs_info->btree_inode);
 }
 
+static void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)
+{
+	fs_info->dev_replace.lock_owner = 0;
+	atomic_set(&fs_info->dev_replace.nesting_level, 0);
+	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
+	mutex_init(&fs_info->dev_replace.lock_management_lock);
+	mutex_init(&fs_info->dev_replace.lock);
+	init_waitqueue_head(&fs_info->replace_wait);
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2348,7 +2358,6 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_delayed_root(fs_info->delayed_root);
 
 	btrfs_init_scrub(fs_info);
-	init_waitqueue_head(&fs_info->replace_wait);
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	fs_info->check_integrity_print_mask = 0;
 #endif
@@ -2384,11 +2393,8 @@ int open_ctree(struct super_block *sb,
 	init_rwsem(&fs_info->cleanup_work_sem);
 	init_rwsem(&fs_info->subvol_sem);
 	sema_init(&fs_info->uuid_tree_rescan_sem, 1);
-	fs_info->dev_replace.lock_owner = 0;
-	atomic_set(&fs_info->dev_replace.nesting_level, 0);
-	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
-	mutex_init(&fs_info->dev_replace.lock_management_lock);
-	mutex_init(&fs_info->dev_replace.lock);
+
+	btrfs_init_dev_replace_locks(fs_info);
 
 	spin_lock_init(&fs_info->qgroup_lock);
 	mutex_init(&fs_info->qgroup_ioctl_lock);

commit f37938e0e22f90740cfbfe74ecd9aad5e8369b9d
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Fri Aug 1 18:12:40 2014 -0500

    btrfs: factor btrfs_init_btree_inode() out of open_ctree()
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    [renamed to btrfs_init_btree_inode]
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b95b033b2494..6a64e666de05 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2169,6 +2169,36 @@ static void btrfs_init_balance(struct btrfs_fs_info *fs_info)
 	init_waitqueue_head(&fs_info->balance_wait_q);
 }
 
+static void btrfs_init_btree_inode(struct btrfs_fs_info *fs_info,
+				   struct btrfs_root *tree_root)
+{
+	fs_info->btree_inode->i_ino = BTRFS_BTREE_INODE_OBJECTID;
+	set_nlink(fs_info->btree_inode, 1);
+	/*
+	 * we set the i_size on the btree inode to the max possible int.
+	 * the real end of the address space is determined by all of
+	 * the devices in the system
+	 */
+	fs_info->btree_inode->i_size = OFFSET_MAX;
+	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
+	fs_info->btree_inode->i_mapping->backing_dev_info = &fs_info->bdi;
+
+	RB_CLEAR_NODE(&BTRFS_I(fs_info->btree_inode)->rb_node);
+	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,
+			     fs_info->btree_inode->i_mapping);
+	BTRFS_I(fs_info->btree_inode)->io_tree.track_uptodate = 0;
+	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree);
+
+	BTRFS_I(fs_info->btree_inode)->io_tree.ops = &btree_extent_io_ops;
+
+	BTRFS_I(fs_info->btree_inode)->root = tree_root;
+	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
+	       sizeof(struct btrfs_key));
+	set_bit(BTRFS_INODE_DUMMY,
+		&BTRFS_I(fs_info->btree_inode)->runtime_flags);
+	btrfs_insert_inode_hash(fs_info->btree_inode);
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2329,31 +2359,7 @@ int open_ctree(struct super_block *sb,
 	sb->s_blocksize_bits = blksize_bits(4096);
 	sb->s_bdi = &fs_info->bdi;
 
-	fs_info->btree_inode->i_ino = BTRFS_BTREE_INODE_OBJECTID;
-	set_nlink(fs_info->btree_inode, 1);
-	/*
-	 * we set the i_size on the btree inode to the max possible int.
-	 * the real end of the address space is determined by all of
-	 * the devices in the system
-	 */
-	fs_info->btree_inode->i_size = OFFSET_MAX;
-	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
-	fs_info->btree_inode->i_mapping->backing_dev_info = &fs_info->bdi;
-
-	RB_CLEAR_NODE(&BTRFS_I(fs_info->btree_inode)->rb_node);
-	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,
-			     fs_info->btree_inode->i_mapping);
-	BTRFS_I(fs_info->btree_inode)->io_tree.track_uptodate = 0;
-	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree);
-
-	BTRFS_I(fs_info->btree_inode)->io_tree.ops = &btree_extent_io_ops;
-
-	BTRFS_I(fs_info->btree_inode)->root = tree_root;
-	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
-	       sizeof(struct btrfs_key));
-	set_bit(BTRFS_INODE_DUMMY,
-		&BTRFS_I(fs_info->btree_inode)->runtime_flags);
-	btrfs_insert_inode_hash(fs_info->btree_inode);
+	btrfs_init_btree_inode(fs_info, tree_root);
 
 	spin_lock_init(&fs_info->block_group_cache_lock);
 	fs_info->block_group_cache_tree = RB_ROOT;

commit 779a65a495b76aee7fae500ac7ae360dc8fd81ff
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Fri Aug 1 18:12:39 2014 -0500

    btrfs: factor btrfs_init_balance() out of open_ctree()
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    [renamed to btrfs_init_balance]
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2936a3958f3c..b95b033b2494 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2158,6 +2158,17 @@ static void btrfs_init_scrub(struct btrfs_fs_info *fs_info)
 	fs_info->scrub_workers_refcnt = 0;
 }
 
+static void btrfs_init_balance(struct btrfs_fs_info *fs_info)
+{
+	spin_lock_init(&fs_info->balance_lock);
+	mutex_init(&fs_info->balance_mutex);
+	atomic_set(&fs_info->balance_running, 0);
+	atomic_set(&fs_info->balance_pause_req, 0);
+	atomic_set(&fs_info->balance_cancel_req, 0);
+	fs_info->balance_ctl = NULL;
+	init_waitqueue_head(&fs_info->balance_wait_q);
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2311,14 +2322,7 @@ int open_ctree(struct super_block *sb,
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	fs_info->check_integrity_print_mask = 0;
 #endif
-
-	spin_lock_init(&fs_info->balance_lock);
-	mutex_init(&fs_info->balance_mutex);
-	atomic_set(&fs_info->balance_running, 0);
-	atomic_set(&fs_info->balance_pause_req, 0);
-	atomic_set(&fs_info->balance_cancel_req, 0);
-	fs_info->balance_ctl = NULL;
-	init_waitqueue_head(&fs_info->balance_wait_q);
+	btrfs_init_balance(fs_info);
 	btrfs_init_async_reclaim_work(&fs_info->async_reclaim_work);
 
 	sb->s_blocksize = 4096;

commit 638aa7ed4667f63ec45b264d1b6e259a79638733
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Fri Aug 1 18:12:38 2014 -0500

    btrfs: factor btrfs_init_scrub() out of open_ctree()
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    [renamed to btrfs_init_scrub]
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6f37d9fc5d28..2936a3958f3c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2147,6 +2147,17 @@ void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
 	}
 }
 
+static void btrfs_init_scrub(struct btrfs_fs_info *fs_info)
+{
+	mutex_init(&fs_info->scrub_lock);
+	atomic_set(&fs_info->scrubs_running, 0);
+	atomic_set(&fs_info->scrub_pause_req, 0);
+	atomic_set(&fs_info->scrubs_paused, 0);
+	atomic_set(&fs_info->scrub_cancel_req, 0);
+	init_waitqueue_head(&fs_info->scrub_pause_wait);
+	fs_info->scrub_workers_refcnt = 0;
+}
+
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
 	       char *options)
@@ -2295,14 +2306,8 @@ int open_ctree(struct super_block *sb,
 	}
 	btrfs_init_delayed_root(fs_info->delayed_root);
 
-	mutex_init(&fs_info->scrub_lock);
-	atomic_set(&fs_info->scrubs_running, 0);
-	atomic_set(&fs_info->scrub_pause_req, 0);
-	atomic_set(&fs_info->scrubs_paused, 0);
-	atomic_set(&fs_info->scrub_cancel_req, 0);
+	btrfs_init_scrub(fs_info);
 	init_waitqueue_head(&fs_info->replace_wait);
-	init_waitqueue_head(&fs_info->scrub_pause_wait);
-	fs_info->scrub_workers_refcnt = 0;
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	fs_info->check_integrity_print_mask = 0;
 #endif

commit 04892340777484351473f1756e6f870500c00a48
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Fri Aug 1 18:12:36 2014 -0500

    btrfs: consistently use fs_info in close_ctree()
    
    close_ctree() has a local fs_info var for convienience;
    use it consistently.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d91f08994d3c..6f37d9fc5d28 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3670,7 +3670,7 @@ void close_ctree(struct btrfs_root *root)
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_commit_super(root);
 		if (ret)
-			btrfs_err(root->fs_info, "commit super ret %d", ret);
+			btrfs_err(fs_info, "commit super ret %d", ret);
 	}
 
 	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
@@ -3682,10 +3682,10 @@ void close_ctree(struct btrfs_root *root)
 	fs_info->closing = 2;
 	smp_mb();
 
-	btrfs_free_qgroup_config(root->fs_info);
+	btrfs_free_qgroup_config(fs_info);
 
 	if (percpu_counter_sum(&fs_info->delalloc_bytes)) {
-		btrfs_info(root->fs_info, "at unmount delalloc count %lld",
+		btrfs_info(fs_info, "at unmount delalloc count %lld",
 		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 

commit 9eaed21ef94b5da30eaf1b2503df1d41c2025175
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Fri Aug 1 18:12:35 2014 -0500

    btrfs: remove unused fs_info arg from btrfs_close_extra_devices()
    
    The commit:
    8dabb74 Btrfs: change core code of btrfs to support the
            device replace operations
    added the fs_info argument, but never used it -
    just remove it again.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6911aa4caa0d..d91f08994d3c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2690,7 +2690,7 @@ int open_ctree(struct super_block *sb,
 	 * keep the device that is marked to be the target device for the
 	 * dev_replace procedure
 	 */
-	btrfs_close_extra_devices(fs_info, fs_devices, 0);
+	btrfs_close_extra_devices(fs_devices, 0);
 
 	if (!fs_devices->latest_bdev) {
 		printk(KERN_ERR "BTRFS: failed to read devices on %s\n",
@@ -2794,7 +2794,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_block_groups;
 	}
 
-	btrfs_close_extra_devices(fs_info, fs_devices, 1);
+	btrfs_close_extra_devices(fs_devices, 1);
 
 	ret = btrfs_sysfs_add_one(fs_info);
 	if (ret) {

commit 41d6b13ea7b459cd51d4446c9b264128a52db993
Author: Fabian Frederick <fabf@skynet.be>
Date:   Sat Feb 14 13:10:22 2015 +0100

    btrfs: fix sizeof format specifier in btrfs_check_super_valid()
    
    This patch fixes mips compilation warning:
    
    fs/btrfs/disk-io.c: In function 'btrfs_check_super_valid':
    fs/btrfs/disk-io.c:3927:21: warning: format '%lu' expects argument
    of type 'long unsigned int', but argument 3 has type 'unsigned int' [-Wformat]
    
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 83671f847c7c..6911aa4caa0d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3923,7 +3923,7 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	}
 	if (btrfs_super_sys_array_size(sb) < sizeof(struct btrfs_disk_key)
 			+ sizeof(struct btrfs_chunk)) {
-		printk(KERN_ERR "BTRFS: system chunk array too small %u < %lu\n",
+		printk(KERN_ERR "BTRFS: system chunk array too small %u < %zu\n",
 				btrfs_super_sys_array_size(sb),
 				sizeof(struct btrfs_disk_key)
 				+ sizeof(struct btrfs_chunk));

commit e8c9f18603f7ce2beca233401e228de730f121fa
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Jan 2 18:23:10 2015 +0100

    btrfs: constify structs with op functions or static definitions
    
    There are some op tables that can be easily made const, similarly the
    sysfs feature and raid tables. This is motivated by PaX CONSTIFY plugin.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ed5dcfe52f91..83671f847c7c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -54,7 +54,7 @@
 #include <asm/cpufeature.h>
 #endif
 
-static struct extent_io_ops btree_extent_io_ops;
+static const struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
@@ -4287,7 +4287,7 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 	return 0;
 }
 
-static struct extent_io_ops btree_extent_io_ops = {
+static const struct extent_io_ops btree_extent_io_ops = {
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
 	.readpage_io_failed_hook = btree_io_failed_hook,
 	.submit_bio_hook = btree_submit_bio_hook,

commit 01d58472a887cba61da7b4e6dc251b5170b57e2e
Author: Daniel Dressler <danieru.dressler@gmail.com>
Date:   Fri Nov 21 17:15:07 2014 +0900

    Btrfs: disk-io: replace root args iff only fs_info used
    
    This is the 3rd independent patch of a larger project to cleanup btrfs's
    internal usage of btrfs_root. Many functions take btrfs_root only to
    grab the fs_info struct.
    
    By requiring a root these functions cause programmer overhead. That
    these functions can accept any valid root is not obvious until
    inspection.
    
    This patch reduces the specificity of such functions to accept the
    fs_info directly.
    
    These patches can be applied independently and thus are not being
    submitted as a patch series. There should be about 26 patches by the
    project's completion. Each patch will cleanup between 1 and 34 functions
    apiece.  Each patch covers a single file's functions.
    
    This patch affects the following function(s):
      1) csum_tree_block
      2) csum_dirty_buffer
      3) check_tree_block_fsid
      4) btrfs_find_tree_block
      5) clean_tree_block
    
    Signed-off-by: Daniel Dressler <danieru.dressler@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 41b320e235d7..ed5dcfe52f91 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -274,10 +274,11 @@ void btrfs_csum_final(u32 crc, char *result)
  * compute the csum for a btree block, and either verify it or write it
  * into the csum field of the block.
  */
-static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
+static int csum_tree_block(struct btrfs_fs_info *fs_info,
+			   struct extent_buffer *buf,
 			   int verify)
 {
-	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(fs_info->super_copy);
 	char *result = NULL;
 	unsigned long len;
 	unsigned long cur_len;
@@ -321,7 +322,7 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			printk_ratelimited(KERN_WARNING
 				"BTRFS: %s checksum verify failed on %llu wanted %X found %X "
 				"level %d\n",
-				root->fs_info->sb->s_id, buf->start,
+				fs_info->sb->s_id, buf->start,
 				val, found, btrfs_header_level(buf));
 			if (result != (char *)&inline_result)
 				kfree(result);
@@ -501,7 +502,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
  * we only fill in the checksum field in the first page of a multi-page block
  */
 
-static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
+static int csum_dirty_buffer(struct btrfs_fs_info *fs_info, struct page *page)
 {
 	u64 start = page_offset(page);
 	u64 found_start;
@@ -513,14 +514,14 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	found_start = btrfs_header_bytenr(eb);
 	if (WARN_ON(found_start != start || !PageUptodate(page)))
 		return 0;
-	csum_tree_block(root, eb, 0);
+	csum_tree_block(fs_info, eb, 0);
 	return 0;
 }
 
-static int check_tree_block_fsid(struct btrfs_root *root,
+static int check_tree_block_fsid(struct btrfs_fs_info *fs_info,
 				 struct extent_buffer *eb)
 {
-	struct btrfs_fs_devices *fs_devices = root->fs_info->fs_devices;
+	struct btrfs_fs_devices *fs_devices = fs_info->fs_devices;
 	u8 fsid[BTRFS_UUID_SIZE];
 	int ret = 1;
 
@@ -640,7 +641,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 		ret = -EIO;
 		goto err;
 	}
-	if (check_tree_block_fsid(root, eb)) {
+	if (check_tree_block_fsid(root->fs_info, eb)) {
 		printk_ratelimited(KERN_ERR "BTRFS (device %s): bad fsid on block %llu\n",
 			       eb->fs_info->sb->s_id, eb->start);
 		ret = -EIO;
@@ -657,7 +658,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	btrfs_set_buffer_lockdep_class(btrfs_header_owner(eb),
 				       eb, found_level);
 
-	ret = csum_tree_block(root, eb, 1);
+	ret = csum_tree_block(root->fs_info, eb, 1);
 	if (ret) {
 		ret = -EIO;
 		goto err;
@@ -882,7 +883,7 @@ static int btree_csum_one_bio(struct bio *bio)
 
 	bio_for_each_segment_all(bvec, bio, i) {
 		root = BTRFS_I(bvec->bv_page->mapping->host)->root;
-		ret = csum_dirty_buffer(root, bvec->bv_page);
+		ret = csum_dirty_buffer(root->fs_info, bvec->bv_page);
 		if (ret)
 			break;
 	}
@@ -1119,10 +1120,10 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr,
 	return 0;
 }
 
-struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
+struct extent_buffer *btrfs_find_tree_block(struct btrfs_fs_info *fs_info,
 					    u64 bytenr)
 {
-	return find_extent_buffer(root->fs_info, bytenr);
+	return find_extent_buffer(fs_info, bytenr);
 }
 
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
@@ -1165,11 +1166,10 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 
 }
 
-void clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+void clean_tree_block(struct btrfs_trans_handle *trans,
+		      struct btrfs_fs_info *fs_info,
 		      struct extent_buffer *buf)
 {
-	struct btrfs_fs_info *fs_info = root->fs_info;
-
 	if (btrfs_header_generation(buf) ==
 	    fs_info->running_transaction->transid) {
 		btrfs_assert_tree_locked(buf);
@@ -4136,7 +4136,7 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 
 		clear_extent_bits(dirty_pages, start, end, mark, GFP_NOFS);
 		while (start <= end) {
-			eb = btrfs_find_tree_block(root, start);
+			eb = btrfs_find_tree_block(root->fs_info, start);
 			start += root->nodesize;
 			if (!eb)
 				continue;

commit d4b450cd4b33ce7c572e7fdccf33b59c4cdf361c
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jan 29 19:18:25 2015 +0000

    Btrfs: fix race between transaction commit and empty block group removal
    
    Committing a transaction can race with automatic removal of empty block
    groups (cleaner kthread), leading to a BUG_ON() in the transaction
    commit code while running btrfs_finish_extent_commit(). The following
    sequence diagram shows how it can happen:
    
               CPU 1                                       CPU 2
    
    btrfs_commit_transaction()
      fs_info->running_transaction = NULL
      btrfs_finish_extent_commit()
        find_first_extent_bit()
          -> found range for block group X
             in fs_info->freed_extents[]
    
                                                   btrfs_delete_unused_bgs()
                                                     -> found block group X
    
                                                     Removed block group X's range
                                                     from fs_info->freed_extents[]
    
                                                     btrfs_remove_chunk()
                                                        btrfs_remove_block_group(bg X)
    
        unpin_extent_range(bg X range)
           btrfs_lookup_block_group(bg X)
              -> returns NULL
                -> BUG_ON()
    
    The trace that results from the BUG_ON() is:
    
    [48665.187808] ------------[ cut here ]------------
    [48665.188032] kernel BUG at fs/btrfs/extent-tree.c:5675!
    [48665.188032] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC
    [48665.188032] Modules linked in: dm_flakey dm_mod crc32c_generic btrfs xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd grace fscache sunrpc loop parport_pc evdev microcode
    [48665.197388] CPU: 2 PID: 31211 Comm: kworker/u32:16 Tainted: G        W      3.19.0-rc5-btrfs-next-4+ #1
    [48665.197388] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    [48665.197388] Workqueue: events_unbound btrfs_async_reclaim_metadata_space [btrfs]
    [48665.197388] task: ffff880222011810 ti: ffff8801b56a4000 task.ti: ffff8801b56a4000
    [48665.197388] RIP: 0010:[<ffffffffa0350d05>]  [<ffffffffa0350d05>] unpin_extent_range+0x6a/0x1ba [btrfs]
    [48665.197388] RSP: 0018:ffff8801b56a7b88  EFLAGS: 00010246
    [48665.197388] RAX: 0000000000000000 RBX: ffff8802143a6000 RCX: ffff8802220120c8
    [48665.197388] RDX: 0000000000000001 RSI: 0000000000000001 RDI: ffff8800a3c140b0
    [48665.197388] RBP: ffff8801b56a7bd8 R08: 0000000000000003 R09: 0000000000000000
    [48665.197388] R10: 0000000000000000 R11: 000000000000bbac R12: 0000000012e8e000
    [48665.197388] R13: ffff8800a3c14000 R14: 0000000000000000 R15: 0000000000000000
    [48665.197388] FS:  0000000000000000(0000) GS:ffff88023ec40000(0000) knlGS:0000000000000000
    [48665.197388] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [48665.197388] CR2: 00007f065e42f270 CR3: 0000000206f70000 CR4: 00000000000006e0
    [48665.197388] Stack:
    [48665.197388]  ffff8801b56a7bd8 0000000012ea0000 01ff8800a3c14138 0000000012e9ffff
    [48665.197388]  ffff880141df3dd8 ffff8802143a6000 ffff8800a3c14138 ffff880141df3df0
    [48665.197388]  ffff880141df3dd8 0000000000000000 ffff8801b56a7c08 ffffffffa0354227
    [48665.197388] Call Trace:
    [48665.197388]  [<ffffffffa0354227>] btrfs_finish_extent_commit+0xb0/0xd9 [btrfs]
    [48665.197388]  [<ffffffffa0366b4b>] btrfs_commit_transaction+0x791/0x92c [btrfs]
    [48665.197388]  [<ffffffffa0352432>] flush_space+0x43d/0x452 [btrfs]
    [48665.197388]  [<ffffffff814295c3>] ? _raw_spin_unlock+0x28/0x33
    [48665.197388]  [<ffffffffa035255f>] btrfs_async_reclaim_metadata_space+0x118/0x164 [btrfs]
    [48665.197388]  [<ffffffff81059917>] ? process_one_work+0x14b/0x3ab
    [48665.197388]  [<ffffffff810599ac>] process_one_work+0x1e0/0x3ab
    [48665.197388]  [<ffffffff81079fa9>] ? trace_hardirqs_off+0xd/0xf
    [48665.197388]  [<ffffffff8105a55b>] worker_thread+0x210/0x2d0
    [48665.197388]  [<ffffffff8105a34b>] ? rescuer_thread+0x2c3/0x2c3
    [48665.197388]  [<ffffffff8105e5c0>] kthread+0xef/0xf7
    [48665.197388]  [<ffffffff81429682>] ? _raw_spin_unlock_irq+0x2d/0x39
    [48665.197388]  [<ffffffff8105e4d1>] ? __kthread_parkme+0xad/0xad
    [48665.197388]  [<ffffffff81429dec>] ret_from_fork+0x7c/0xb0
    [48665.197388]  [<ffffffff8105e4d1>] ? __kthread_parkme+0xad/0xad
    [48665.197388] Code: 85 f6 74 14 49 8b 06 49 03 46 09 49 39 c4 72 1d 4c 89 f7 e8 83 ec ff ff 4c 89 e6 4c 89 ef e8 1e f1 ff ff 48 85 c0 49 89 c6 75 02 <0f> 0b 49 8b 1e 49 03 5e 09 48 8b
    [48665.197388] RIP  [<ffffffffa0350d05>] unpin_extent_range+0x6a/0x1ba [btrfs]
    [48665.197388]  RSP <ffff8801b56a7b88>
    [48665.272246] ---[ end trace b9c6ab9957521376 ]---
    
    Fix this by ensuring that unpining the block group's range in
    btrfs_finish_extent_commit() is done in a synchronized fashion
    with removing the block group's range from freed_extents[]
    in btrfs_delete_unused_bgs()
    
    This race got introduced with the change:
    
        Btrfs: remove empty block groups automatically
        commit 47ab2a6c689913db23ccae38349714edf8365e0a
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 263d1471d01a..41b320e235d7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2242,6 +2242,7 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->qgroup_op_lock);
 	spin_lock_init(&fs_info->buffer_lock);
 	spin_lock_init(&fs_info->unused_bgs_lock);
+	mutex_init(&fs_info->unused_bg_unpin_mutex);
 	rwlock_init(&fs_info->tree_mod_log_lock);
 	mutex_init(&fs_info->reloc_mutex);
 	mutex_init(&fs_info->delalloc_root_mutex);

commit ce7fca5f57ed0fcd7e7b3d7b1a3e1791f8e56fa3
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Oct 31 18:42:05 2014 +0100

    btrfs: add checks for sys_chunk_array sizes
    
    Verify that possible minimum and maximum size is set, validity of
    contents is checked in btrfs_read_sys_array.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 11171362bd33..263d1471d01a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3910,6 +3910,25 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 		ret = -EINVAL;
 	}
 
+	/*
+	 * Obvious sys_chunk_array corruptions, it must hold at least one key
+	 * and one chunk
+	 */
+	if (btrfs_super_sys_array_size(sb) > BTRFS_SYSTEM_CHUNK_ARRAY_SIZE) {
+		printk(KERN_ERR "BTRFS: system chunk array too big %u > %u\n",
+				btrfs_super_sys_array_size(sb),
+				BTRFS_SYSTEM_CHUNK_ARRAY_SIZE);
+		ret = -EINVAL;
+	}
+	if (btrfs_super_sys_array_size(sb) < sizeof(struct btrfs_disk_key)
+			+ sizeof(struct btrfs_chunk)) {
+		printk(KERN_ERR "BTRFS: system chunk array too small %u < %lu\n",
+				btrfs_super_sys_array_size(sb),
+				sizeof(struct btrfs_disk_key)
+				+ sizeof(struct btrfs_chunk));
+		ret = -EINVAL;
+	}
+
 	/*
 	 * The generation is a global counter, we'll trust it more than the others
 	 * but it's still possible that it's the one that's wrong.

commit 75d6ad382bb91f363452119d34238e156589ca2d
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Oct 31 17:18:08 2014 +0100

    btrfs: more superblock checks, lower bounds on devices and sectorsize/nodesize
    
    I received a few crafted images from Jiri, all got through the recently
    added superblock checks. The lower bounds checks for num_devices and
    sector/node -sizes were missing and caused a crash during mount.
    
    Tools for symbolic code execution were used to prepare the images
    contents.
    
    Reported-by: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 612d46eece62..11171362bd33 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3871,6 +3871,21 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 		printk(KERN_WARNING "BTRFS: log_root block unaligned: %llu\n",
 				btrfs_super_log_root(sb));
 
+	/*
+	 * Check the lower bound, the alignment and other constraints are
+	 * checked later.
+	 */
+	if (btrfs_super_nodesize(sb) < 4096) {
+		printk(KERN_ERR "BTRFS: nodesize too small: %u < 4096\n",
+				btrfs_super_nodesize(sb));
+		ret = -EINVAL;
+	}
+	if (btrfs_super_sectorsize(sb) < 4096) {
+		printk(KERN_ERR "BTRFS: sectorsize too small: %u < 4096\n",
+				btrfs_super_sectorsize(sb));
+		ret = -EINVAL;
+	}
+
 	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_UUID_SIZE) != 0) {
 		printk(KERN_ERR "BTRFS: dev_item UUID does not match fsid: %pU != %pU\n",
 				fs_info->fsid, sb->dev_item.fsid);
@@ -3884,6 +3899,10 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	if (btrfs_super_num_devices(sb) > (1UL << 31))
 		printk(KERN_WARNING "BTRFS: suspicious number of devices: %llu\n",
 				btrfs_super_num_devices(sb));
+	if (btrfs_super_num_devices(sb) == 0) {
+		printk(KERN_ERR "BTRFS: number of devices is 0\n");
+		ret = -EINVAL;
+	}
 
 	if (btrfs_super_bytenr(sb) != BTRFS_SUPER_INFO_OFFSET) {
 		printk(KERN_ERR "BTRFS: super offset mismatch %llu != %u\n",

commit 78f55e5e1fa9f684705325667d455a957f43ad66
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Tue Jan 13 00:55:10 2015 +0800

    Btrfs: fix unused members in struct btrfs_root
    
    There isn't any real use of following members of struct btrfs_root
    so delete them.
    
    struct kobject root_kobj;
    struct completion kobj_unregister;
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0696a103751e..612d46eece62 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1275,12 +1275,10 @@ static void __setup_root(u32 nodesize, u32 sectorsize, u32 stripesize,
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
-	memset(&root->root_kobj, 0, sizeof(root->root_kobj));
 	if (fs_info)
 		root->defrag_trans_start = fs_info->generation;
 	else
 		root->defrag_trans_start = 0;
-	init_completion(&root->kobj_unregister);
 	root->root_key.objectid = objectid;
 	root->anon_dev = 0;
 

commit 5efa0490cc94aee06cd8d282683e22a8ce0a0026
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Dec 19 18:38:47 2014 +0100

    btrfs: set proper message level for skinny metadata
    
    This has been confusing people for too long, the message is really just
    informative.
    
    CC: <stable@vger.kernel.org> # 3.10+
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 20da68206fba..0696a103751e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2509,7 +2509,7 @@ int open_ctree(struct super_block *sb,
 		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;
 
 	if (features & BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA)
-		printk(KERN_ERR "BTRFS: has skinny extents\n");
+		printk(KERN_INFO "BTRFS: has skinny extents\n");
 
 	/*
 	 * flag our filesystem as having big metadata blocks if

commit f0954c66377b1610a512fd05f4d33afa54441c3b
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Dec 19 18:38:44 2014 +0100

    btrfs: update message levels after checksum errors
    
    The errors are worth noting and might get missed with INFO level.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7ff24cbcf656..20da68206fba 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -318,7 +318,7 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			memcpy(&found, result, csum_size);
 
 			read_extent_buffer(buf, &val, 0, csum_size);
-			printk_ratelimited(KERN_INFO
+			printk_ratelimited(KERN_WARNING
 				"BTRFS: %s checksum verify failed on %llu wanted %X found %X "
 				"level %d\n",
 				root->fs_info->sb->s_id, buf->start,

commit aa8ee31209d644a3f4716cb0c43aba7889fbef31
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Dec 19 18:38:41 2014 +0100

    btrfs: update message levels during failed mount
    
    All error conditions from open_ctree shall be ERR. Warning would
    suggest that something's wrong and we can continue.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2a3e2252ddbf..7ff24cbcf656 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2533,7 +2533,7 @@ int open_ctree(struct super_block *sb,
 	 */
 	if ((features & BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS) &&
 	    (sectorsize != nodesize)) {
-		printk(KERN_WARNING "BTRFS: unequal leaf/node/sector sizes "
+		printk(KERN_ERR "BTRFS: unequal leaf/node/sector sizes "
 				"are not allowed for mixed block groups on %s\n",
 				sb->s_id);
 		goto fail_alloc;
@@ -2641,12 +2641,12 @@ int open_ctree(struct super_block *sb,
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
 
 	if (btrfs_super_magic(disk_super) != BTRFS_MAGIC) {
-		printk(KERN_INFO "BTRFS: valid FS not found on %s\n", sb->s_id);
+		printk(KERN_ERR "BTRFS: valid FS not found on %s\n", sb->s_id);
 		goto fail_sb_buffer;
 	}
 
 	if (sectorsize != PAGE_SIZE) {
-		printk(KERN_WARNING "BTRFS: Incompatible sector size(%lu) "
+		printk(KERN_ERR "BTRFS: incompatible sector size (%lu) "
 		       "found on %s\n", (unsigned long)sectorsize, sb->s_id);
 		goto fail_sb_buffer;
 	}
@@ -2655,7 +2655,7 @@ int open_ctree(struct super_block *sb,
 	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
-		printk(KERN_WARNING "BTRFS: failed to read the system "
+		printk(KERN_ERR "BTRFS: failed to read the system "
 		       "array on %s\n", sb->s_id);
 		goto fail_sb_buffer;
 	}
@@ -2670,7 +2670,7 @@ int open_ctree(struct super_block *sb,
 					   generation);
 	if (!chunk_root->node ||
 	    !test_bit(EXTENT_BUFFER_UPTODATE, &chunk_root->node->bflags)) {
-		printk(KERN_WARNING "BTRFS: failed to read chunk root on %s\n",
+		printk(KERN_ERR "BTRFS: failed to read chunk root on %s\n",
 		       sb->s_id);
 		goto fail_tree_roots;
 	}
@@ -2682,7 +2682,7 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_read_chunk_tree(chunk_root);
 	if (ret) {
-		printk(KERN_WARNING "BTRFS: failed to read chunk tree on %s\n",
+		printk(KERN_ERR "BTRFS: failed to read chunk tree on %s\n",
 		       sb->s_id);
 		goto fail_tree_roots;
 	}
@@ -2694,7 +2694,7 @@ int open_ctree(struct super_block *sb,
 	btrfs_close_extra_devices(fs_info, fs_devices, 0);
 
 	if (!fs_devices->latest_bdev) {
-		printk(KERN_CRIT "BTRFS: failed to read devices on %s\n",
+		printk(KERN_ERR "BTRFS: failed to read devices on %s\n",
 		       sb->s_id);
 		goto fail_tree_roots;
 	}
@@ -2778,7 +2778,7 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_recover_balance(fs_info);
 	if (ret) {
-		printk(KERN_WARNING "BTRFS: failed to recover balance\n");
+		printk(KERN_ERR "BTRFS: failed to recover balance\n");
 		goto fail_block_groups;
 	}
 

commit 68b663d13ceba777ee6e250154f0e3ab28bd1181
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Dec 19 18:38:37 2014 +0100

    btrfs: update message levels for errors
    
    Several messages that point to some internal problem, level INFO is
    wrong here.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 65384de10375..2a3e2252ddbf 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -367,7 +367,8 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		ret = 0;
 		goto out;
 	}
-	printk_ratelimited(KERN_INFO "BTRFS (device %s): parent transid verify failed on %llu wanted %llu found %llu\n",
+	printk_ratelimited(KERN_ERR
+	    "BTRFS (device %s): parent transid verify failed on %llu wanted %llu found %llu\n",
 			eb->fs_info->sb->s_id, eb->start,
 			parent_transid, btrfs_header_generation(eb));
 	ret = 1;
@@ -633,21 +634,21 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != eb->start) {
-		printk_ratelimited(KERN_INFO "BTRFS (device %s): bad tree block start "
+		printk_ratelimited(KERN_ERR "BTRFS (device %s): bad tree block start "
 			       "%llu %llu\n",
 			       eb->fs_info->sb->s_id, found_start, eb->start);
 		ret = -EIO;
 		goto err;
 	}
 	if (check_tree_block_fsid(root, eb)) {
-		printk_ratelimited(KERN_INFO "BTRFS (device %s): bad fsid on block %llu\n",
+		printk_ratelimited(KERN_ERR "BTRFS (device %s): bad fsid on block %llu\n",
 			       eb->fs_info->sb->s_id, eb->start);
 		ret = -EIO;
 		goto err;
 	}
 	found_level = btrfs_header_level(eb);
 	if (found_level >= BTRFS_MAX_LEVEL) {
-		btrfs_info(root->fs_info, "bad tree block level %d",
+		btrfs_err(root->fs_info, "bad tree block level %d",
 			   (int)btrfs_header_level(eb));
 		ret = -EIO;
 		goto err;

commit 57bbddd7fbf468336940d18a4c68a8678163acb0
Merge: d3541834884f ce3e69847e3e
Author: Chris Mason <clm@fb.com>
Date:   Wed Jan 21 17:49:35 2015 -0800

    Merge branch 'cleanup/blocksize-diet-part2' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus

commit df0ce26cb4ee8bc233d50213b97213532aff0a3c
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 14 10:42:41 2015 +0100

    fs: remove default_backing_dev_info
    
    Now that default_backing_dev_info is not used for writeback purposes we can
    git rid of it easily:
    
     - instead of using it's name for tracing unregistered bdi we just use
       "unknown"
     - btrfs and ceph can just assign the default read ahead window themselves
       like several other filesystems already do.
     - we can assign noop_backing_dev_info as the default one in alloc_super.
       All filesystems already either assigned their own or
       noop_backing_dev_info.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1ec872e3a926..1afb18226da8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1719,7 +1719,7 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 	if (err)
 		return err;
 
-	bdi->ra_pages	= default_backing_dev_info.ra_pages;
+	bdi->ra_pages = VM_MAX_READAHEAD * 1024 / PAGE_CACHE_SIZE;
 	bdi->congested_fn	= btrfs_congested_fn;
 	bdi->congested_data	= info;
 	return 0;

commit b83ae6d421435c6204150300f1c25bfbd39cd62b
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 14 10:42:37 2015 +0100

    fs: remove mapping->backing_dev_info
    
    Now that we never use the backing_dev_info pointer in struct address_space
    we can simply remove it and save 4 to 8 bytes in every inode.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Reviewed-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index afc4092989cd..1ec872e3a926 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2318,7 +2318,6 @@ int open_ctree(struct super_block *sb,
 	 */
 	fs_info->btree_inode->i_size = OFFSET_MAX;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
-	fs_info->btree_inode->i_mapping->backing_dev_info = &fs_info->bdi;
 
 	RB_CLEAR_NODE(&BTRFS_I(fs_info->btree_inode)->rb_node);
 	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,

commit b4caecd48005fbed3949dde6c1cb233142fd69e9
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 14 10:42:32 2015 +0100

    fs: introduce f_op->mmap_capabilities for nommu mmap support
    
    Since "BDI: Provide backing device capability information [try #3]" the
    backing_dev_info structure also provides flags for the kind of mmap
    operation available in a nommu environment, which is entirely unrelated
    to it's original purpose.
    
    Introduce a new nommu-only file operation to provide this information to
    the nommu mmap code instead.  Splitting this from the backing_dev_info
    structure allows to remove lots of backing_dev_info instance that aren't
    otherwise needed, and entirely gets rid of the concept of providing a
    backing_dev_info for a character device.  It also removes the need for
    the mtd_inodefs filesystem.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Tejun Heo <tj@kernel.org>
    Acked-by: Brian Norris <computersforpeace@gmail.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8c63419a7f70..afc4092989cd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1715,8 +1715,7 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 {
 	int err;
 
-	bdi->capabilities = BDI_CAP_MAP_COPY;
-	err = bdi_setup_and_register(bdi, "btrfs", BDI_CAP_MAP_COPY);
+	err = bdi_setup_and_register(bdi, "btrfs");
 	if (err)
 		return err;
 

commit 1d4c08e0a60be356134d0c466744d0d4e16ebab0
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Jan 2 19:36:14 2015 +0100

    btrfs: expand btrfs_find_item if found_key is NULL
    
    If the found_key is NULL, then btrfs_find_item becomes a verbose wrapper
    for simple btrfs_search_slot.
    
    After we've removed all such callers, passing a NULL key is not valid
    anymore.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6182e5493d0f..8d486603e8a3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1631,6 +1631,7 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 {
 	struct btrfs_root *root;
 	struct btrfs_path *path;
+	struct btrfs_key key;
 	int ret;
 
 	if (location->objectid == BTRFS_ROOT_TREE_OBJECTID)
@@ -1675,8 +1676,11 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 		ret = -ENOMEM;
 		goto fail;
 	}
-	ret = btrfs_find_item(fs_info->tree_root, path, BTRFS_ORPHAN_OBJECTID,
-			location->objectid, BTRFS_ORPHAN_ITEM_KEY, NULL);
+	key.objectid = BTRFS_ORPHAN_OBJECTID;
+	key.type = BTRFS_ORPHAN_ITEM_KEY;
+	key.offset = location->objectid;
+
+	ret = btrfs_search_slot(NULL, fs_info->tree_root, &key, path, 0, 0);
 	btrfs_free_path(path);
 	if (ret < 0)
 		goto fail;

commit 381cf6587f8a8a8e981bc0c1aaaa8859b51dc756
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Jan 2 18:45:16 2015 +0100

    btrfs: fix leak of path in btrfs_find_item
    
    If btrfs_find_item is called with NULL path it allocates one locally but
    does not free it. Affected paths are inserting an orphan item for a file
    and for a subvol root.
    
    Move the path allocation to the callers.
    
    CC: <stable@vger.kernel.org> # 3.14+
    Fixes: 3f870c289900 ("btrfs: expand btrfs_find_item() to include find_orphan_item functionality")
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8c63419a7f70..6182e5493d0f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1630,6 +1630,7 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 				     bool check_ref)
 {
 	struct btrfs_root *root;
+	struct btrfs_path *path;
 	int ret;
 
 	if (location->objectid == BTRFS_ROOT_TREE_OBJECTID)
@@ -1669,8 +1670,14 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	if (ret)
 		goto fail;
 
-	ret = btrfs_find_item(fs_info->tree_root, NULL, BTRFS_ORPHAN_OBJECTID,
+	path = btrfs_alloc_path();
+	if (!path) {
+		ret = -ENOMEM;
+		goto fail;
+	}
+	ret = btrfs_find_item(fs_info->tree_root, path, BTRFS_ORPHAN_OBJECTID,
 			location->objectid, BTRFS_ORPHAN_ITEM_KEY, NULL);
+	btrfs_free_path(path);
 	if (ret < 0)
 		goto fail;
 	if (ret == 0)

commit ce3e69847e3ec79a38421bfd3d6f554d5e481231
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 03:00:04 2014 +0200

    btrfs: sink parameter len to alloc_extent_buffer
    
    Because we're using globally known nodesize. Do the same for the sanity
    test function variant.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 548cb540e516..9c204533fd22 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1128,9 +1128,8 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 bytenr)
 {
 	if (btrfs_test_is_dummy_root(root))
-		return alloc_test_extent_buffer(root->fs_info, bytenr,
-						root->nodesize);
-	return alloc_extent_buffer(root->fs_info, bytenr, root->nodesize);
+		return alloc_test_extent_buffer(root->fs_info, bytenr);
+	return alloc_extent_buffer(root->fs_info, bytenr);
 }
 
 

commit a83fffb75d09cd3d44167b7fb9c1ab9e2269445f
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 02:39:54 2014 +0200

    btrfs: sink blocksize parameter to btrfs_find_create_tree_block
    
    Finally it's clear that the requested blocksize is always equal to
    nodesize, with one exception, the superblock.
    
    Superblock has fixed size regardless of the metadata block size, but
    uses the same helpers to initialize sys array/chunk tree and to work
    with the chunk items. So it pretends to be an extent_buffer for a
    moment, btrfs_read_sys_array is full of special cases, we're adding one
    more.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8123b03b1f9d..548cb540e516 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1078,7 +1078,7 @@ void readahead_tree_block(struct btrfs_root *root, u64 bytenr)
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 
-	buf = btrfs_find_create_tree_block(root, bytenr, root->nodesize);
+	buf = btrfs_find_create_tree_block(root, bytenr);
 	if (!buf)
 		return;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
@@ -1094,7 +1094,7 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr,
 	struct extent_io_tree *io_tree = &BTRFS_I(btree_inode)->io_tree;
 	int ret;
 
-	buf = btrfs_find_create_tree_block(root, bytenr, root->nodesize);
+	buf = btrfs_find_create_tree_block(root, bytenr);
 	if (!buf)
 		return 0;
 
@@ -1125,12 +1125,12 @@ struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 }
 
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
-						 u64 bytenr, u32 blocksize)
+						 u64 bytenr)
 {
 	if (btrfs_test_is_dummy_root(root))
 		return alloc_test_extent_buffer(root->fs_info, bytenr,
-						blocksize);
-	return alloc_extent_buffer(root->fs_info, bytenr, blocksize);
+						root->nodesize);
+	return alloc_extent_buffer(root->fs_info, bytenr, root->nodesize);
 }
 
 
@@ -1152,7 +1152,7 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 	struct extent_buffer *buf = NULL;
 	int ret;
 
-	buf = btrfs_find_create_tree_block(root, bytenr, root->nodesize);
+	buf = btrfs_find_create_tree_block(root, bytenr);
 	if (!buf)
 		return NULL;
 

commit c0dcaa4d7b66b788b315c418bda3cca75c5938dc
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 02:24:21 2014 +0200

    btrfs: sink blocksize parameter to reada_tree_block_flagged
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index be9d7c612489..8123b03b1f9d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1086,7 +1086,7 @@ void readahead_tree_block(struct btrfs_root *root, u64 bytenr)
 	free_extent_buffer(buf);
 }
 
-int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr, u32 blocksize,
+int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr,
 			 int mirror_num, struct extent_buffer **eb)
 {
 	struct extent_buffer *buf = NULL;
@@ -1094,7 +1094,7 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr, u32 blocksize,
 	struct extent_io_tree *io_tree = &BTRFS_I(btree_inode)->io_tree;
 	int ret;
 
-	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
+	buf = btrfs_find_create_tree_block(root, bytenr, root->nodesize);
 	if (!buf)
 		return 0;
 

commit d3e46fea1b1e8ba97a8c9dd8f54b97d086cd25aa
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 02:04:19 2014 +0200

    btrfs: sink blocksize parameter to readahead_tree_block
    
    All callers pass nodesize.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 30965120772b..be9d7c612489 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1073,12 +1073,12 @@ static const struct address_space_operations btree_aops = {
 	.set_page_dirty = btree_set_page_dirty,
 };
 
-void readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
+void readahead_tree_block(struct btrfs_root *root, u64 bytenr)
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 
-	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
+	buf = btrfs_find_create_tree_block(root, bytenr, root->nodesize);
 	if (!buf)
 		return;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,

commit 678886bdc6378c1cbd5072da2c5a3035000214e3
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sun Dec 7 21:31:47 2014 +0000

    Btrfs: fix fs corruption on transaction abort if device supports discard
    
    When we abort a transaction we iterate over all the ranges marked as dirty
    in fs_info->freed_extents[0] and fs_info->freed_extents[1], clear them
    from those trees, add them back (unpin) to the free space caches and, if
    the fs was mounted with "-o discard", perform a discard on those regions.
    Also, after adding the regions to the free space caches, a fitrim ioctl call
    can see those ranges in a block group's free space cache and perform a discard
    on the ranges, so the same issue can happen without "-o discard" as well.
    
    This causes corruption, affecting one or multiple btree nodes (in the worst
    case leaving the fs unmountable) because some of those ranges (the ones in
    the fs_info->pinned_extents tree) correspond to btree nodes/leafs that are
    referred by the last committed super block - breaking the rule that anything
    that was committed by a transaction is untouched until the next transaction
    commits successfully.
    
    I ran into this while running in a loop (for several hours) the fstest that
    I recently submitted:
    
      [PATCH] fstests: add btrfs test to stress chunk allocation/removal and fstrim
    
    The corruption always happened when a transaction aborted and then fsck complained
    like this:
    
       _check_btrfs_filesystem: filesystem on /dev/sdc is inconsistent
       *** fsck.btrfs output ***
       Check tree block failed, want=94945280, have=0
       Check tree block failed, want=94945280, have=0
       Check tree block failed, want=94945280, have=0
       Check tree block failed, want=94945280, have=0
       Check tree block failed, want=94945280, have=0
       read block failed check_tree_block
       Couldn't open file system
    
    In this case 94945280 corresponded to the root of a tree.
    Using frace what I observed was the following sequence of steps happened:
    
       1) transaction N started, fs_info->pinned_extents pointed to
          fs_info->freed_extents[0];
    
       2) node/eb 94945280 is created;
    
       3) eb is persisted to disk;
    
       4) transaction N commit starts, fs_info->pinned_extents now points to
          fs_info->freed_extents[1], and transaction N completes;
    
       5) transaction N + 1 starts;
    
       6) eb is COWed, and btrfs_free_tree_block() called for this eb;
    
       7) eb range (94945280 to 94945280 + 16Kb) is added to
          fs_info->pinned_extents (fs_info->freed_extents[1]);
    
       8) Something goes wrong in transaction N + 1, like hitting ENOSPC
          for example, and the transaction is aborted, turning the fs into
          readonly mode. The stack trace I got for example:
    
          [112065.253935]  [<ffffffff8140c7b6>] dump_stack+0x4d/0x66
          [112065.254271]  [<ffffffff81042984>] warn_slowpath_common+0x7f/0x98
          [112065.254567]  [<ffffffffa0325990>] ? __btrfs_abort_transaction+0x50/0x10b [btrfs]
          [112065.261674]  [<ffffffff810429e5>] warn_slowpath_fmt+0x48/0x50
          [112065.261922]  [<ffffffffa032949e>] ? btrfs_free_path+0x26/0x29 [btrfs]
          [112065.262211]  [<ffffffffa0325990>] __btrfs_abort_transaction+0x50/0x10b [btrfs]
          [112065.262545]  [<ffffffffa036b1d6>] btrfs_remove_chunk+0x537/0x58b [btrfs]
          [112065.262771]  [<ffffffffa033840f>] btrfs_delete_unused_bgs+0x1de/0x21b [btrfs]
          [112065.263105]  [<ffffffffa0343106>] cleaner_kthread+0x100/0x12f [btrfs]
          (...)
          [112065.264493] ---[ end trace dd7903a975a31a08 ]---
          [112065.264673] BTRFS: error (device sdc) in btrfs_remove_chunk:2625: errno=-28 No space left
          [112065.264997] BTRFS info (device sdc): forced readonly
    
       9) The clear kthread sees that the BTRFS_FS_STATE_ERROR bit is set in
          fs_info->fs_state and calls btrfs_cleanup_transaction(), which in
          turn calls btrfs_destroy_pinned_extent();
    
       10) Then btrfs_destroy_pinned_extent() iterates over all the ranges
           marked as dirty in fs_info->freed_extents[], and for each one
           it calls discard, if the fs was mounted with "-o discard", and
           adds the range to the free space cache of the respective block
           group;
    
       11) btrfs_trim_block_group(), invoked from the fitrim ioctl code path,
           sees the free space entries and performs a discard;
    
       12) After an umount and mount (or fsck), our eb's location on disk was full
           of zeroes, and it should have been untouched, because it was marked as
           dirty in the fs_info->pinned_extents tree, and therefore used by the
           trees that the last committed superblock points to.
    
    Fix this by not performing a discard and not adding the ranges to the free space
    caches - it's useless from this point since the fs is now in readonly mode and
    we won't write free space caches to disk anymore (otherwise we would leak space)
    nor any new superblock. By not adding the ranges to the free space caches, it
    prevents other code paths from allocating that space and write to it as well,
    therefore being safer and simpler.
    
    This isn't a new problem, as it's been present since 2011 (git commit
    acce952b0263825da32cf10489413dec78053347).
    
    Cc: stable@vger.kernel.org  # any kernel released after 2011-01-06
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 30965120772b..8c63419a7f70 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4121,12 +4121,6 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 		if (ret)
 			break;
 
-		/* opt_discard */
-		if (btrfs_test_opt(root, DISCARD))
-			ret = btrfs_error_discard_extent(root, start,
-							 end + 1 - start,
-							 NULL);
-
 		clear_extent_dirty(unpin, start, end, GFP_NOFS);
 		btrfs_error_unpin_extent_range(root, start, end);
 		cond_resched();

commit 04216820fe83d5e27322065ba989de27dbfc104d
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Nov 27 21:14:15 2014 +0000

    Btrfs: fix race between fs trimming and block group remove/allocation
    
    Our fs trim operation, which is completely transactionless (doesn't start
    or joins an existing transaction) consists of visiting all block groups
    and then for each one to iterate its free space entries and perform a
    discard operation against the space range represented by the free space
    entries. However before performing a discard, the corresponding free space
    entry is removed from the free space rbtree, and when the discard completes
    it is added back to the free space rbtree.
    
    If a block group remove operation happens while the discard is ongoing (or
    before it starts and after a free space entry is hidden), we end up not
    waiting for the discard to complete, remove the extent map that maps
    logical address to physical addresses and the corresponding chunk metadata
    from the the chunk and device trees. After that and before the discard
    completes, the current running transaction can finish and a new one start,
    allowing for new block groups that map to the same physical addresses to
    be allocated and written to.
    
    So fix this by keeping the extent map in memory until the discard completes
    so that the same physical addresses aren't reused before it completes.
    
    If the physical locations that are under a discard operation end up being
    used for a new metadata block group for example, and dirty metadata extents
    are written before the discard finishes (the VM might call writepages() of
    our btree inode's i_mapping for example, or an fsync log commit happens) we
    end up overwriting metadata with zeroes, which leads to errors from fsck
    like the following:
    
            checking extents
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            read block failed check_tree_block
            owner ref check failed [833912832 16384]
            Errors found in extent allocation tree or chunk allocation
            checking free space cache
            checking fs roots
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            Check tree block failed, want=833912832, have=0
            read block failed check_tree_block
            root 5 root dir 256 error
            root 5 inode 260 errors 2001, no inode item, link count wrong
                    unresolved ref dir 256 index 0 namelen 8 name foobar_3 filetype 1 errors 6, no dir index, no inode ref
            root 5 inode 262 errors 2001, no inode item, link count wrong
                    unresolved ref dir 256 index 0 namelen 8 name foobar_5 filetype 1 errors 6, no dir index, no inode ref
            root 5 inode 263 errors 2001, no inode item, link count wrong
            (...)
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1e3e414c8501..30965120772b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2384,6 +2384,8 @@ int open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->transaction_blocked_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);
 
+	INIT_LIST_HEAD(&fs_info->pinned_chunks);
+
 	ret = btrfs_alloc_stripe_hash_table(fs_info);
 	if (ret) {
 		err = ret;
@@ -3715,6 +3717,17 @@ void close_ctree(struct btrfs_root *root)
 
 	btrfs_free_block_rsv(root, root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;
+
+	lock_chunks(root);
+	while (!list_empty(&fs_info->pinned_chunks)) {
+		struct extent_map *em;
+
+		em = list_first_entry(&fs_info->pinned_chunks,
+				      struct extent_map, list);
+		list_del_init(&em->list);
+		free_extent_map(em);
+	}
+	unlock_chunks(root);
 }
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,

commit ad27c0dab76a7abc8809ec41ae59cf67de5ea906
Merge: b38ef71cb102 a6f69dc8018d
Author: Chris Mason <clm@fb.com>
Date:   Tue Nov 25 05:45:30 2014 -0800

    Merge branch 'dev/pending-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus

commit 50d9aa99bd35c77200e0e3dd7a72274f8304701f
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Nov 21 14:52:38 2014 -0500

    Btrfs: make sure logged extents complete in the current transaction V3
    
    Liu Bo pointed out that my previous fix would lose the generation update in the
    scenario I described.  It is actually much worse than that, we could lose the
    entire extent if we lose power right after the transaction commits.  Consider
    the following
    
    write extent 0-4k
    log extent in log tree
    commit transaction
            < power fail happens here
    ordered extent completes
    
    We would lose the 0-4k extent because it hasn't updated the actual fs tree, and
    the transaction commit will reset the log so it isn't replayed.  If we lose
    power before the transaction commit we are save, otherwise we are not.
    
    Fix this by keeping track of all extents we logged in this transaction.  Then
    when we go to commit the transaction make sure we wait for all of those ordered
    extents to complete before proceeding.  This will make sure that if we lose
    power after the transaction commit we still have our data.  This also fixes the
    problem of the improperly updated extent generation.  Thanks,
    
    cc: stable@vger.kernel.org
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7af9a1978a2f..6efaee8d7739 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4129,6 +4129,25 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 	return 0;
 }
 
+static void btrfs_free_pending_ordered(struct btrfs_transaction *cur_trans,
+				       struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_ordered_extent *ordered;
+
+	spin_lock(&fs_info->trans_lock);
+	while (!list_empty(&cur_trans->pending_ordered)) {
+		ordered = list_first_entry(&cur_trans->pending_ordered,
+					   struct btrfs_ordered_extent,
+					   trans_list);
+		list_del_init(&ordered->trans_list);
+		spin_unlock(&fs_info->trans_lock);
+
+		btrfs_put_ordered_extent(ordered);
+		spin_lock(&fs_info->trans_lock);
+	}
+	spin_unlock(&fs_info->trans_lock);
+}
+
 void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 				   struct btrfs_root *root)
 {
@@ -4140,6 +4159,7 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	cur_trans->state = TRANS_STATE_UNBLOCKED;
 	wake_up(&root->fs_info->transaction_wait);
 
+	btrfs_free_pending_ordered(cur_trans, root->fs_info);
 	btrfs_destroy_delayed_inodes(root);
 	btrfs_assert_delayed_root_empty(root);
 

commit cd743fac42bbc2e6125ee14aaa8741601f92fe9a
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Oct 31 19:40:14 2014 +0100

    btrfs: fix typos in btrfs_check_super_valid
    
    Copy&paste errors in some messages and add few more missing macro
    accessors.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1bf9f897065d..7af9a1978a2f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3839,12 +3839,12 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 */
 	if (!IS_ALIGNED(btrfs_super_root(sb), 4096))
 		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
-				sb->root);
+				btrfs_super_root(sb));
 	if (!IS_ALIGNED(btrfs_super_chunk_root(sb), 4096))
-		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
-				sb->chunk_root);
+		printk(KERN_WARNING "BTRFS: chunk_root block unaligned: %llu\n",
+				btrfs_super_chunk_root(sb));
 	if (!IS_ALIGNED(btrfs_super_log_root(sb), 4096))
-		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
+		printk(KERN_WARNING "BTRFS: log_root block unaligned: %llu\n",
 				btrfs_super_log_root(sb));
 
 	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_UUID_SIZE) != 0) {

commit 7e1876aca815029d5c3023a66a91e249eca3e533
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Feb 5 15:26:17 2014 +0100

    btrfs: switch inode_cache option handling to pending changes
    
    The pending mount option(s) now share namespace and bits with the normal
    options, and the existing one for (inode_cache) is unset unconditionally
    at each transaction commit.
    
    Introduce a separate namespace for pending changes and enhance the
    descriptions of the intended change to use separate bits for each
    action.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fd80c0d98421..6b406e3f3abe 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2830,10 +2830,6 @@ int open_ctree(struct super_block *sb,
 		btrfs_set_opt(fs_info->mount_opt, SSD);
 	}
 
-	/* Set the real inode map cache flag */
-	if (btrfs_test_opt(tree_root, CHANGE_INODE_CACHE))
-		btrfs_set_opt(tree_root->fs_info->mount_opt, INODE_MAP_CACHE);
-
 	/*
 	 * Mount does not set all options immediatelly, we can do it now and do
 	 * not have to wait for transaction commit

commit 572d9ab7845ea0e043ec34cd733a75228130ad03
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Feb 5 15:26:17 2014 +0100

    btrfs: add support for processing pending changes
    
    There are some actions that modify global filesystem state but cannot be
    performed at the time of request, but later at the transaction commit
    time when the filesystem is in a known state.
    
    For example enabling new incompat features on-the-fly or issuing
    transaction commit from unsafe contexts (sysfs handlers).
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1bf9f897065d..fd80c0d98421 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2834,6 +2834,12 @@ int open_ctree(struct super_block *sb,
 	if (btrfs_test_opt(tree_root, CHANGE_INODE_CACHE))
 		btrfs_set_opt(tree_root->fs_info->mount_opt, INODE_MAP_CACHE);
 
+	/*
+	 * Mount does not set all options immediatelly, we can do it now and do
+	 * not have to wait for transaction commit
+	 */
+	btrfs_apply_pending_changes(fs_info);
+
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_test_opt(tree_root, CHECK_INTEGRITY)) {
 		ret = btrfsic_mount(tree_root, fs_devices,

commit 4f4274af7009890f0d4724909bf9038193955489
Merge: 9f935675d41a d05a2b4cd970
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Nov 1 10:41:26 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "Filipe is nailing down some problems with our skinny extent variation,
      and Dave's patch fixes endian problems in the new super block checks"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix race that makes btrfs_lookup_extent_info miss skinny extent items
      Btrfs: properly clean up btrfs_end_io_wq_cache
      Btrfs: fix invalid leaf slot access in btrfs_lookup_extent()
      btrfs: use macro accessors in superblock validation checks

commit 21e7626b12f25770e2975bc7c7b2e1d5b1d58a57
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Oct 27 13:52:21 2014 +0100

    btrfs: use macro accessors in superblock validation checks
    
    The initial patch c926093ec516f5d316 (btrfs: add more superblock checks)
    did not properly use the macro accessors that wrap endianness and the
    code would not work correctly on big endian machines.
    
    Reported-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2409718e3f20..1ae1661ba14c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3817,19 +3817,19 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	struct btrfs_super_block *sb = fs_info->super_copy;
 	int ret = 0;
 
-	if (sb->root_level > BTRFS_MAX_LEVEL) {
-		printk(KERN_ERR "BTRFS: tree_root level too big: %d > %d\n",
-				sb->root_level, BTRFS_MAX_LEVEL);
+	if (btrfs_super_root_level(sb) >= BTRFS_MAX_LEVEL) {
+		printk(KERN_ERR "BTRFS: tree_root level too big: %d >= %d\n",
+				btrfs_super_root_level(sb), BTRFS_MAX_LEVEL);
 		ret = -EINVAL;
 	}
-	if (sb->chunk_root_level > BTRFS_MAX_LEVEL) {
-		printk(KERN_ERR "BTRFS: chunk_root level too big: %d > %d\n",
-				sb->chunk_root_level, BTRFS_MAX_LEVEL);
+	if (btrfs_super_chunk_root_level(sb) >= BTRFS_MAX_LEVEL) {
+		printk(KERN_ERR "BTRFS: chunk_root level too big: %d >= %d\n",
+				btrfs_super_chunk_root_level(sb), BTRFS_MAX_LEVEL);
 		ret = -EINVAL;
 	}
-	if (sb->log_root_level > BTRFS_MAX_LEVEL) {
-		printk(KERN_ERR "BTRFS: log_root level too big: %d > %d\n",
-				sb->log_root_level, BTRFS_MAX_LEVEL);
+	if (btrfs_super_log_root_level(sb) >= BTRFS_MAX_LEVEL) {
+		printk(KERN_ERR "BTRFS: log_root level too big: %d >= %d\n",
+				btrfs_super_log_root_level(sb), BTRFS_MAX_LEVEL);
 		ret = -EINVAL;
 	}
 
@@ -3837,15 +3837,15 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 * The common minimum, we don't know if we can trust the nodesize/sectorsize
 	 * items yet, they'll be verified later. Issue just a warning.
 	 */
-	if (!IS_ALIGNED(sb->root, 4096))
+	if (!IS_ALIGNED(btrfs_super_root(sb), 4096))
 		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
 				sb->root);
-	if (!IS_ALIGNED(sb->chunk_root, 4096))
+	if (!IS_ALIGNED(btrfs_super_chunk_root(sb), 4096))
 		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
 				sb->chunk_root);
-	if (!IS_ALIGNED(sb->log_root, 4096))
+	if (!IS_ALIGNED(btrfs_super_log_root(sb), 4096))
 		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
-				sb->log_root);
+				btrfs_super_log_root(sb));
 
 	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_UUID_SIZE) != 0) {
 		printk(KERN_ERR "BTRFS: dev_item UUID does not match fsid: %pU != %pU\n",
@@ -3857,13 +3857,13 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 * Hint to catch really bogus numbers, bitflips or so, more exact checks are
 	 * done later
 	 */
-	if (sb->num_devices > (1UL << 31))
+	if (btrfs_super_num_devices(sb) > (1UL << 31))
 		printk(KERN_WARNING "BTRFS: suspicious number of devices: %llu\n",
-				sb->num_devices);
+				btrfs_super_num_devices(sb));
 
-	if (sb->bytenr != BTRFS_SUPER_INFO_OFFSET) {
+	if (btrfs_super_bytenr(sb) != BTRFS_SUPER_INFO_OFFSET) {
 		printk(KERN_ERR "BTRFS: super offset mismatch %llu != %u\n",
-				sb->bytenr, BTRFS_SUPER_INFO_OFFSET);
+				btrfs_super_bytenr(sb), BTRFS_SUPER_INFO_OFFSET);
 		ret = -EINVAL;
 	}
 
@@ -3871,14 +3871,15 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	 * The generation is a global counter, we'll trust it more than the others
 	 * but it's still possible that it's the one that's wrong.
 	 */
-	if (sb->generation < sb->chunk_root_generation)
+	if (btrfs_super_generation(sb) < btrfs_super_chunk_root_generation(sb))
 		printk(KERN_WARNING
 			"BTRFS: suspicious: generation < chunk_root_generation: %llu < %llu\n",
-			sb->generation, sb->chunk_root_generation);
-	if (sb->generation < sb->cache_generation && sb->cache_generation != (u64)-1)
+			btrfs_super_generation(sb), btrfs_super_chunk_root_generation(sb));
+	if (btrfs_super_generation(sb) < btrfs_super_cache_generation(sb)
+	    && btrfs_super_cache_generation(sb) != (u64)-1)
 		printk(KERN_WARNING
 			"BTRFS: suspicious: generation < cache_generation: %llu < %llu\n",
-			sb->generation, sb->cache_generation);
+			btrfs_super_generation(sb), btrfs_super_cache_generation(sb));
 
 	return ret;
 }

commit d3dc366bbaf07c125561e90d6da4bb147741101a
Merge: 511c41d9e666 e19a8a0ad2d2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Oct 18 11:53:51 2014 -0700

    Merge branch 'for-3.18/core' of git://git.kernel.dk/linux-block
    
    Pull core block layer changes from Jens Axboe:
     "This is the core block IO pull request for 3.18.  Apart from the new
      and improved flush machinery for blk-mq, this is all mostly bug fixes
      and cleanups.
    
       - blk-mq timeout updates and fixes from Christoph.
    
       - Removal of REQ_END, also from Christoph.  We pass it through the
         ->queue_rq() hook for blk-mq instead, freeing up one of the request
         bits.  The space was overly tight on 32-bit, so Martin also killed
         REQ_KERNEL since it's no longer used.
    
       - blk integrity updates and fixes from Martin and Gu Zheng.
    
       - Update to the flush machinery for blk-mq from Ming Lei.  Now we
         have a per hardware context flush request, which both cleans up the
         code should scale better for flush intensive workloads on blk-mq.
    
       - Improve the error printing, from Rob Elliott.
    
       - Backing device improvements and cleanups from Tejun.
    
       - Fixup of a misplaced rq_complete() tracepoint from Hannes.
    
       - Make blk_get_request() return error pointers, fixing up issues
         where we NULL deref when a device goes bad or missing.  From Joe
         Lawrence.
    
       - Prep work for drastically reducing the memory consumption of dm
         devices from Junichi Nomura.  This allows creating clone bio sets
         without preallocating a lot of memory.
    
       - Fix a blk-mq hang on certain combinations of queue depths and
         hardware queues from me.
    
       - Limit memory consumption for blk-mq devices for crash dump
         scenarios and drivers that use crazy high depths (certain SCSI
         shared tag setups).  We now just use a single queue and limited
         depth for that"
    
    * 'for-3.18/core' of git://git.kernel.dk/linux-block: (58 commits)
      block: Remove REQ_KERNEL
      blk-mq: allocate cpumask on the home node
      bio-integrity: remove the needless fail handle of bip_slab creating
      block: include func name in __get_request prints
      block: make blk_update_request print prefix match ratelimited prefix
      blk-merge: don't compute bi_phys_segments from bi_vcnt for cloned bio
      block: fix alignment_offset math that assumes io_min is a power-of-2
      blk-mq: Make bt_clear_tag() easier to read
      blk-mq: fix potential hang if rolling wakeup depth is too high
      block: add bioset_create_nobvec()
      block: use bio_clone_fast() in blk_rq_prep_clone()
      block: misplaced rq_complete tracepoint
      sd: Honor block layer integrity handling flags
      block: Replace strnicmp with strncasecmp
      block: Add T10 Protection Information functions
      block: Don't merge requests if integrity flags differ
      block: Integrity checksum flag
      block: Relocate bio integrity flags
      block: Add a disk flag to block integrity profile
      block: Add prefix to block integrity profile flags
      ...

commit 90d0c376f5ee1927327b267faf15bf970476f09e
Merge: ac0c49396d5e a43bb39b5c71
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Oct 11 08:03:52 2014 -0400

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "The largest set of changes here come from Miao Xie.  He's cleaning up
      and improving read recovery/repair for raid, and has a number of
      related fixes.
    
      I've merged another set of fsync fixes from Filipe, and he's also
      improved the way we handle metadata write errors to make sure we force
      the FS readonly if things go wrong.
    
      Otherwise we have a collection of fixes and cleanups.  Dave Sterba
      gets a cookie for removing the most lines (thanks Dave)"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (139 commits)
      btrfs: Fix compile error when CONFIG_SECURITY is not set.
      Btrfs: fix compiles when CONFIG_BTRFS_FS_RUN_SANITY_TESTS is off
      btrfs: Make btrfs handle security mount options internally to avoid losing security label.
      Btrfs: send, don't delay dir move if there's a new parent inode
      btrfs: add more superblock checks
      Btrfs: fix race in WAIT_SYNC ioctl
      Btrfs: be aware of btree inode write errors to avoid fs corruption
      Btrfs: remove redundant btrfs_verify_qgroup_counts declaration.
      btrfs: fix shadow warning on cmp
      Btrfs: fix compilation errors under DEBUG
      Btrfs: fix crash of btrfs_release_extent_buffer_page
      Btrfs: add missing end_page_writeback on submit_extent_page failure
      btrfs: Fix the wrong condition judgment about subset extent map
      Btrfs: fix build_backref_tree issue with multiple shared blocks
      Btrfs: cleanup error handling in build_backref_tree
      btrfs: move checks for DUMMY_ROOT into a helper
      btrfs: new define for the inline extent data start
      btrfs: kill extent_buffer_page helper
      btrfs: drop constant param from btrfs_release_extent_buffer_page
      btrfs: hide typecast to definition of BTRFS_SEND_TRANS_STUB
      ...

commit 27b19cc8864e206c4203041892b0f706f044a0f1
Merge: bbf65cf0b5b6 4d75f8a9c87b
Author: Chris Mason <clm@fb.com>
Date:   Sat Oct 4 09:57:14 2014 -0700

    Merge branch 'cleanup/blocksize-diet-part1' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus

commit bbf65cf0b5b67843ca094df01019222b85af2183
Merge: bf8e8ca6fd4a fccb84c94a97
Author: Chris Mason <clm@fb.com>
Date:   Sat Oct 4 09:56:45 2014 -0700

    Merge branch 'cleanup/misc-for-3.18' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus
    
    Signed-off-by: Chris Mason <clm@fb.com>
    
    Conflicts:
            fs/btrfs/extent_io.c

commit c926093ec516f5d316ecdf8c1be11f577ac71b85
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Sep 30 19:16:47 2014 +0200

    btrfs: add more superblock checks
    
    Populate btrfs_check_super_valid() with checks that try to verify
    consistency of superblock by additional conditions that may arise from
    corrupted devices or bitflips. Some of tests are only hints and issue
    warnings instead of failing the mount, basically when the checks are
    derived from the data found in the superblock.
    
    Tested on a broken image provided by Qu.
    
    Reported-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 09b3c8a0c790..fc8dfaa27967 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3817,10 +3817,73 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 			      int read_only)
 {
+	struct btrfs_super_block *sb = fs_info->super_copy;
+	int ret = 0;
+
+	if (sb->root_level > BTRFS_MAX_LEVEL) {
+		printk(KERN_ERR "BTRFS: tree_root level too big: %d > %d\n",
+				sb->root_level, BTRFS_MAX_LEVEL);
+		ret = -EINVAL;
+	}
+	if (sb->chunk_root_level > BTRFS_MAX_LEVEL) {
+		printk(KERN_ERR "BTRFS: chunk_root level too big: %d > %d\n",
+				sb->chunk_root_level, BTRFS_MAX_LEVEL);
+		ret = -EINVAL;
+	}
+	if (sb->log_root_level > BTRFS_MAX_LEVEL) {
+		printk(KERN_ERR "BTRFS: log_root level too big: %d > %d\n",
+				sb->log_root_level, BTRFS_MAX_LEVEL);
+		ret = -EINVAL;
+	}
+
 	/*
-	 * Placeholder for checks
+	 * The common minimum, we don't know if we can trust the nodesize/sectorsize
+	 * items yet, they'll be verified later. Issue just a warning.
 	 */
-	return 0;
+	if (!IS_ALIGNED(sb->root, 4096))
+		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
+				sb->root);
+	if (!IS_ALIGNED(sb->chunk_root, 4096))
+		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
+				sb->chunk_root);
+	if (!IS_ALIGNED(sb->log_root, 4096))
+		printk(KERN_WARNING "BTRFS: tree_root block unaligned: %llu\n",
+				sb->log_root);
+
+	if (memcmp(fs_info->fsid, sb->dev_item.fsid, BTRFS_UUID_SIZE) != 0) {
+		printk(KERN_ERR "BTRFS: dev_item UUID does not match fsid: %pU != %pU\n",
+				fs_info->fsid, sb->dev_item.fsid);
+		ret = -EINVAL;
+	}
+
+	/*
+	 * Hint to catch really bogus numbers, bitflips or so, more exact checks are
+	 * done later
+	 */
+	if (sb->num_devices > (1UL << 31))
+		printk(KERN_WARNING "BTRFS: suspicious number of devices: %llu\n",
+				sb->num_devices);
+
+	if (sb->bytenr != BTRFS_SUPER_INFO_OFFSET) {
+		printk(KERN_ERR "BTRFS: super offset mismatch %llu != %u\n",
+				sb->bytenr, BTRFS_SUPER_INFO_OFFSET);
+		ret = -EINVAL;
+	}
+
+	/*
+	 * The generation is a global counter, we'll trust it more than the others
+	 * but it's still possible that it's the one that's wrong.
+	 */
+	if (sb->generation < sb->chunk_root_generation)
+		printk(KERN_WARNING
+			"BTRFS: suspicious: generation < chunk_root_generation: %llu < %llu\n",
+			sb->generation, sb->chunk_root_generation);
+	if (sb->generation < sb->cache_generation && sb->cache_generation != (u64)-1)
+		printk(KERN_WARNING
+			"BTRFS: suspicious: generation < cache_generation: %llu < %llu\n",
+			sb->generation, sb->cache_generation);
+
+	return ret;
 }
 
 static void btrfs_error_commit_super(struct btrfs_root *root)

commit 656f30dba7ab8179c9a2e04293b0c7b383fa9ce9
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Sep 26 12:25:56 2014 +0100

    Btrfs: be aware of btree inode write errors to avoid fs corruption
    
    While we have a transaction ongoing, the VM might decide at any time
    to call btree_inode->i_mapping->a_ops->writepages(), which will start
    writeback of dirty pages belonging to btree nodes/leafs. This call
    might return an error or the writeback might finish with an error
    before we attempt to commit the running transaction. If this happens,
    we might have no way of knowing that such error happened when we are
    committing the transaction - because the pages might no longer be
    marked dirty nor tagged for writeback (if a subsequent modification
    to the extent buffer didn't happen before the transaction commit) which
    makes filemap_fdata[write|wait]_range unable to find such pages (even
    if they're marked with SetPageError).
    So if this happens we must abort the transaction, otherwise we commit
    a super block with btree roots that point to btree nodes/leafs whose
    content on disk is invalid - either garbage or the content of some
    node/leaf from a past generation that got cowed or deleted and is no
    longer valid (for this later case we end up getting error messages like
    "parent transid verify failed on 10826481664 wanted 25748 found 29562"
    when reading btree nodes/leafs from disk).
    
    Note that setting and checking AS_EIO/AS_ENOSPC in the btree inode's
    i_mapping would not be enough because we need to distinguish between
    log tree extents (not fatal) vs non-log tree extents (fatal) and
    because the next call to filemap_fdatawait_range() will catch and clear
    such errors in the mapping - and that call might be from a log sync and
    not from a transaction commit, which means we would not know about the
    error at transaction commit time. Also, checking for the eb flag
    EXTENT_BUFFER_IOERR at transaction commit time isn't done and would
    not be completely reliable, as the eb might be removed from memory and
    read back when trying to get it, which clears that flag right before
    reading the eb's pages from disk, making us not know about the previous
    write error.
    
    Using the new 3 flags for the btree inode also makes us achieve the
    goal of AS_EIO/AS_ENOSPC when writepages() returns success, started
    writeback for all dirty pages and before filemap_fdatawait_range() is
    called, the writeback for all dirty pages had already finished with
    errors - because we were not using AS_EIO/AS_ENOSPC,
    filemap_fdatawait_range() would return success, as it could not know
    that writeback errors happened (the pages were no longer tagged for
    writeback).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4780e6623c7b..09b3c8a0c790 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -607,7 +607,7 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 		goto err;
 
 	eb->read_mirror = mirror;
-	if (test_bit(EXTENT_BUFFER_IOERR, &eb->bflags)) {
+	if (test_bit(EXTENT_BUFFER_READ_ERR, &eb->bflags)) {
 		ret = -EIO;
 		goto err;
 	}
@@ -680,7 +680,7 @@ static int btree_io_failed_hook(struct page *page, int failed_mirror)
 	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
 
 	eb = (struct extent_buffer *)page->private;
-	set_bit(EXTENT_BUFFER_IOERR, &eb->bflags);
+	set_bit(EXTENT_BUFFER_READ_ERR, &eb->bflags);
 	eb->read_mirror = failed_mirror;
 	atomic_dec(&eb->io_pages);
 	if (test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))

commit fccb84c94a9755f48668e43d0a44d6ecc750900f
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Sep 29 23:53:21 2014 +0200

    btrfs: move checks for DUMMY_ROOT into a helper
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0abf4b0a9010..14117f85b545 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1130,11 +1130,9 @@ struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 bytenr, u32 blocksize)
 {
-#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-	if (unlikely(test_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state)))
+	if (btrfs_test_is_dummy_root(root))
 		return alloc_test_extent_buffer(root->fs_info, bytenr,
 						blocksize);
-#endif
 	return alloc_extent_buffer(root->fs_info, bytenr, blocksize);
 }
 

commit 2755a0de64693501741fb3603cd8ca928b0b7e81
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Jul 31 00:43:18 2014 +0200

    btrfs: hide typecast to definition of BTRFS_SEND_TRANS_STUB
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2f075ef20050..0abf4b0a9010 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -347,8 +347,7 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 {
 	struct extent_state *cached_state = NULL;
 	int ret;
-	bool need_lock = (current->journal_info ==
-			  (void *)BTRFS_SEND_TRANS_STUB);
+	bool need_lock = (current->journal_info == BTRFS_SEND_TRANS_STUB);
 
 	if (!parent_transid || btrfs_header_generation(eb) == parent_transid)
 		return 0;

commit 97eb6b69d1e856cb5e1cf2c3d94afab643e93128
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Jul 30 00:55:42 2014 +0200

    btrfs: use slab for end_io_wq structures
    
    The structure is frequently reused.  Rename it according to the slab
    name.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d7cb58ed2946..2f075ef20050 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -72,11 +72,11 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root);
 static void btrfs_error_commit_super(struct btrfs_root *root);
 
 /*
- * end_io_wq structs are used to do processing in task context when an IO is
- * complete.  This is used during reads to verify checksums, and it is used
+ * btrfs_end_io_wq structs are used to do processing in task context when an IO
+ * is complete.  This is used during reads to verify checksums, and it is used
  * by writes to insert metadata for new file extents after IO is complete.
  */
-struct end_io_wq {
+struct btrfs_end_io_wq {
 	struct bio *bio;
 	bio_end_io_t *end_io;
 	void *private;
@@ -87,6 +87,26 @@ struct end_io_wq {
 	struct btrfs_work work;
 };
 
+static struct kmem_cache *btrfs_end_io_wq_cache;
+
+int __init btrfs_end_io_wq_init(void)
+{
+	btrfs_end_io_wq_cache = kmem_cache_create("btrfs_end_io_wq",
+					sizeof(struct btrfs_end_io_wq),
+					0,
+					SLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD,
+					NULL);
+	if (!btrfs_end_io_wq_cache)
+		return -ENOMEM;
+	return 0;
+}
+
+void btrfs_end_io_wq_exit(void)
+{
+	if (btrfs_end_io_wq_cache)
+		kmem_cache_destroy(btrfs_end_io_wq_cache);
+}
+
 /*
  * async submit bios are used to offload expensive checksumming
  * onto the worker threads.  They checksum file and metadata bios
@@ -690,7 +710,7 @@ static int btree_io_failed_hook(struct page *page, int failed_mirror)
 
 static void end_workqueue_bio(struct bio *bio, int err)
 {
-	struct end_io_wq *end_io_wq = bio->bi_private;
+	struct btrfs_end_io_wq *end_io_wq = bio->bi_private;
 	struct btrfs_fs_info *fs_info;
 	struct btrfs_workqueue *wq;
 	btrfs_work_func_t func;
@@ -736,9 +756,9 @@ static void end_workqueue_bio(struct bio *bio, int err)
 int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 			enum btrfs_wq_endio_type metadata)
 {
-	struct end_io_wq *end_io_wq;
+	struct btrfs_end_io_wq *end_io_wq;
 
-	end_io_wq = kmalloc(sizeof(*end_io_wq), GFP_NOFS);
+	end_io_wq = kmem_cache_alloc(btrfs_end_io_wq_cache, GFP_NOFS);
 	if (!end_io_wq)
 		return -ENOMEM;
 
@@ -1723,16 +1743,16 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 static void end_workqueue_fn(struct btrfs_work *work)
 {
 	struct bio *bio;
-	struct end_io_wq *end_io_wq;
+	struct btrfs_end_io_wq *end_io_wq;
 	int error;
 
-	end_io_wq = container_of(work, struct end_io_wq, work);
+	end_io_wq = container_of(work, struct btrfs_end_io_wq, work);
 	bio = end_io_wq->bio;
 
 	error = end_io_wq->error;
 	bio->bi_private = end_io_wq->private;
 	bio->bi_end_io = end_io_wq->end_io;
-	kfree(end_io_wq);
+	kmem_cache_free(btrfs_end_io_wq_cache, end_io_wq);
 	bio_endio_nodec(bio, error);
 }
 

commit bfebd8b5441755f228ad02273682d675d3335123
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Jul 30 00:25:45 2014 +0200

    btrfs: use enum for wq endio metadata type
    
    The enum exists but is not consistently used.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9b2a741370b7..d7cb58ed2946 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -82,7 +82,7 @@ struct end_io_wq {
 	void *private;
 	struct btrfs_fs_info *info;
 	int error;
-	int metadata;
+	enum btrfs_wq_endio_type metadata;
 	struct list_head list;
 	struct btrfs_work work;
 };
@@ -733,16 +733,8 @@ static void end_workqueue_bio(struct bio *bio, int err)
 	btrfs_queue_work(wq, &end_io_wq->work);
 }
 
-/*
- * For the metadata arg you want
- *
- * 0 - if data
- * 1 - if normal metadta
- * 2 - if writing to the free space cache area
- * 3 - raid parity work
- */
 int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
-			int metadata)
+			enum btrfs_wq_endio_type metadata)
 {
 	struct end_io_wq *end_io_wq;
 
@@ -930,7 +922,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 		 * can happen in the async kernel threads
 		 */
 		ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info,
-					  bio, 1);
+					  bio, BTRFS_WQ_ENDIO_METADATA);
 		if (ret)
 			goto out_w_error;
 		ret = btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,

commit 95ac567af212db3293af3897ccb521efdf1dd7ff
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Thu Aug 8 22:45:48 2013 +0100

    Btrfs: set default max_inline to 8KiB instead of 8MiB
    
    8MiB is way too large and likely set by mistake. This is not
    a significant issue as in practice the max amount of data
    added to an inline extent is also limited by the page cache
    and btree leaf sizes.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4780e6623c7b..9b2a741370b7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2260,7 +2260,7 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->qgroup_op_seq, 0);
 	atomic64_set(&fs_info->tree_mod_seq, 0);
 	fs_info->sb = sb;
-	fs_info->max_inline = 8192 * 1024;
+	fs_info->max_inline = BTRFS_DEFAULT_MAX_INLINE;
 	fs_info->metadata_ratio = 0;
 	fs_info->defrag_inodes = RB_ROOT;
 	fs_info->free_chunk_space = 0;

commit 4d75f8a9c87b843c8ded15b82b8d137b9724cccc
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 01:54:12 2014 +0200

    btrfs: remove blocksize from btrfs_alloc_free_block and rename
    
    Rename to btrfs_alloc_tree_block as it fits to the alloc/find/free +
    _tree_block family. The parameter blocksize was set to the metadata
    block size, directly or indirectly.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e0293d2fbb3a..2e5d460d4e0c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1324,8 +1324,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
 	root->root_key.offset = 0;
 
-	leaf = btrfs_alloc_free_block(trans, root, root->nodesize,
-				      0, objectid, NULL, 0, 0, 0);
+	leaf = btrfs_alloc_tree_block(trans, root, 0, objectid, NULL, 0, 0, 0);
 	if (IS_ERR(leaf)) {
 		ret = PTR_ERR(leaf);
 		leaf = NULL;
@@ -1412,9 +1411,8 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	 * updated (along with back refs to the log tree).
 	 */
 
-	leaf = btrfs_alloc_free_block(trans, root, root->nodesize, 0,
-				      BTRFS_TREE_LOG_OBJECTID, NULL,
-				      0, 0, 0);
+	leaf = btrfs_alloc_tree_block(trans, root, 0, BTRFS_TREE_LOG_OBJECTID,
+			NULL, 0, 0, 0);
 	if (IS_ERR(leaf)) {
 		kfree(root);
 		return ERR_CAST(leaf);

commit 0308af4465897c889e32754ef37bb465a1b2b872
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 01:43:40 2014 +0200

    btrfs: remove unused parameter blocksize from btrfs_find_tree_block
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 03c0973568ef..e0293d2fbb3a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1108,7 +1108,7 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr, u32 blocksize,
 }
 
 struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
-					    u64 bytenr, u32 blocksize)
+					    u64 bytenr)
 {
 	return find_extent_buffer(root->fs_info, bytenr);
 }
@@ -4002,8 +4002,7 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 
 		clear_extent_bits(dirty_pages, start, end, mark, GFP_NOFS);
 		while (start <= end) {
-			eb = btrfs_find_tree_block(root, start,
-						   root->nodesize);
+			eb = btrfs_find_tree_block(root, start);
 			start += root->nodesize;
 			if (!eb)
 				continue;

commit ce86cd59179279a6fe673d2a105d24fb7e70aef3
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 01:07:32 2014 +0200

    btrfs: remove parameter blocksize from read_tree_block
    
    We know the tree block size, no need to pass it around.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 332f63518156..03c0973568ef 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1138,12 +1138,12 @@ int btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
 }
 
 struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
-				      u32 blocksize, u64 parent_transid)
+				      u64 parent_transid)
 {
 	struct extent_buffer *buf = NULL;
 	int ret;
 
-	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
+	buf = btrfs_find_create_tree_block(root, bytenr, root->nodesize);
 	if (!buf)
 		return NULL;
 
@@ -1484,7 +1484,6 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	struct btrfs_fs_info *fs_info = tree_root->fs_info;
 	struct btrfs_path *path;
 	u64 generation;
-	u32 blocksize;
 	int ret;
 
 	path = btrfs_alloc_path();
@@ -1509,9 +1508,8 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	}
 
 	generation = btrfs_root_generation(&root->root_item);
-	blocksize = root->nodesize;
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
-				     blocksize, generation);
+				     generation);
 	if (!root->node) {
 		ret = -ENOMEM;
 		goto find_fail;
@@ -2139,7 +2137,6 @@ int open_ctree(struct super_block *sb,
 {
 	u32 sectorsize;
 	u32 nodesize;
-	u32 blocksize;
 	u32 stripesize;
 	u64 generation;
 	u64 features;
@@ -2643,7 +2640,6 @@ int open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 
-	blocksize = tree_root->nodesize;
 	generation = btrfs_super_chunk_root_generation(disk_super);
 
 	__setup_root(nodesize, sectorsize, stripesize, chunk_root,
@@ -2651,7 +2647,7 @@ int open_ctree(struct super_block *sb,
 
 	chunk_root->node = read_tree_block(chunk_root,
 					   btrfs_super_chunk_root(disk_super),
-					   blocksize, generation);
+					   generation);
 	if (!chunk_root->node ||
 	    !test_bit(EXTENT_BUFFER_UPTODATE, &chunk_root->node->bflags)) {
 		printk(KERN_WARNING "BTRFS: failed to read chunk root on %s\n",
@@ -2684,12 +2680,11 @@ int open_ctree(struct super_block *sb,
 	}
 
 retry_root_backup:
-	blocksize = tree_root->nodesize;
 	generation = btrfs_super_generation(disk_super);
 
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super),
-					  blocksize, generation);
+					  generation);
 	if (!tree_root->node ||
 	    !test_bit(EXTENT_BUFFER_UPTODATE, &tree_root->node->bflags)) {
 		printk(KERN_WARNING "BTRFS: failed to read tree root on %s\n",
@@ -2858,7 +2853,6 @@ int open_ctree(struct super_block *sb,
 			err = -EIO;
 			goto fail_qgroup;
 		}
-		blocksize = tree_root->nodesize;
 
 		log_tree_root = btrfs_alloc_root(fs_info);
 		if (!log_tree_root) {
@@ -2870,7 +2864,6 @@ int open_ctree(struct super_block *sb,
 			     log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
 
 		log_tree_root->node = read_tree_block(tree_root, bytenr,
-						      blocksize,
 						      generation + 1);
 		if (!log_tree_root->node ||
 		    !extent_buffer_uptodate(log_tree_root->node)) {

commit 6197d86eabb844c1a9c99956d4e6b0f8eb548ad3
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 00:49:36 2014 +0200

    btrfs: return void from readahead_tree_block
    
    Errors in readahead are not fatal and ignored elsewhere in the code.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ff83748d39da..332f63518156 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1062,19 +1062,17 @@ static const struct address_space_operations btree_aops = {
 	.set_page_dirty = btree_set_page_dirty,
 };
 
-int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
+void readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	int ret = 0;
 
 	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
 	if (!buf)
-		return 0;
+		return;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
 				 buf, 0, WAIT_NONE, btree_get_extent, 0);
 	free_extent_buffer(buf);
-	return ret;
 }
 
 int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr, u32 blocksize,

commit 58dc4ce4325108b35425ffd30e6acfad9644d49d
Author: David Sterba <dsterba@suse.cz>
Date:   Sun Jun 15 00:29:04 2014 +0200

    btrfs: remove unused parameter from readahead_tree_block
    
    The parent_transid parameter has been unused since its introduction in
    ca7a79ad8dbe2466 ("Pass down the expected generation number when reading
    tree blocks").  In reada_tree_block, it was even wrongly set to leafsize.
    Transid check is done in the proper read and readahead ignores errors.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4780e6623c7b..ff83748d39da 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1062,8 +1062,7 @@ static const struct address_space_operations btree_aops = {
 	.set_page_dirty = btree_set_page_dirty,
 };
 
-int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize,
-			 u64 parent_transid)
+int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;

commit d06efebf0c37d438fcf07057be00dd40fcfce08d
Merge: bb2e226b3bef 0a30288da1ae
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Sep 24 13:00:21 2014 -0400

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/axboe/linux-block into for-3.18
    
    This is to receive 0a30288da1ae ("blk-mq, percpu_ref: implement a
    kludge for SCSI blk-mq stall during probe") which implements
    __percpu_ref_kill_expedited() to work around SCSI blk-mq stall.  The
    commit reverted and patches to implement proper fix will be added.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Kent Overstreet <kmo@daterainc.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Christoph Hellwig <hch@lst.de>

commit 47ab2a6c689913db23ccae38349714edf8365e0a
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Sep 18 11:20:02 2014 -0400

    Btrfs: remove empty block groups automatically
    
    One problem that has plagued us is that a user will use up all of his space with
    data, remove a bunch of that data, and then try to create a bunch of small files
    and run out of space.  This happens because all the chunks were allocated for
    data since the metadata requirements were so low.  But now there's a bunch of
    empty data block groups and not enough metadata space to do anything.  This
    patch solves this problem by automatically deleting empty block groups.  If we
    notice the used count go down to 0 when deleting or on mount notice that a block
    group has a used count of 0 then we will queue it to be deleted.
    
    When the cleaner thread runs we will double check to make sure the block group
    is still empty and then we will delete it.  This patch has the side effect of no
    longer having a bunch of BUG_ON()'s in the chunk delete code, which will be
    helpful for both this and relocate.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 48794f951427..4780e6623c7b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1769,6 +1769,7 @@ static int cleaner_kthread(void *arg)
 		}
 
 		btrfs_run_delayed_iputs(root);
+		btrfs_delete_unused_bgs(root->fs_info);
 		again = btrfs_clean_one_deleted_snapshot(root);
 		mutex_unlock(&root->fs_info->cleaner_mutex);
 
@@ -2230,6 +2231,7 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->super_lock);
 	spin_lock_init(&fs_info->qgroup_op_lock);
 	spin_lock_init(&fs_info->buffer_lock);
+	spin_lock_init(&fs_info->unused_bgs_lock);
 	rwlock_init(&fs_info->tree_mod_log_lock);
 	mutex_init(&fs_info->reloc_mutex);
 	mutex_init(&fs_info->delalloc_root_mutex);
@@ -2239,6 +2241,7 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
 	INIT_LIST_HEAD(&fs_info->space_info);
 	INIT_LIST_HEAD(&fs_info->tree_mod_seq_list);
+	INIT_LIST_HEAD(&fs_info->unused_bgs);
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	btrfs_init_block_rsv(&fs_info->global_block_rsv,
 			     BTRFS_BLOCK_RSV_GLOBAL);
@@ -2977,6 +2980,8 @@ int open_ctree(struct super_block *sb,
 		fs_info->update_uuid_tree_gen = 1;
 	}
 
+	fs_info->open = 1;
+
 	return 0;
 
 fail_qgroup:
@@ -3688,6 +3693,7 @@ void close_ctree(struct btrfs_root *root)
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	btrfs_stop_all_workers(fs_info);
 
+	fs_info->open = 0;
 	free_root_pointers(fs_info, 1);
 
 	iput(fs_info->btree_inode);

commit 8b110e393c5a6e72d50fcdf9fa7ed8b647cfdfc9
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 12 18:44:03 2014 +0800

    Btrfs: implement repair function when direct read fails
    
    This patch implement data repair function when direct read fails.
    
    The detail of the implementation is:
    - When we find the data is not right, we try to read the data from the other
      mirror.
    - When the io on the mirror ends, we will insert the endio work into the
      dedicated btrfs workqueue, not common read endio workqueue, because the
      original endio work is still blocked in the btrfs endio workqueue, if we
      insert the endio work of the io on the mirror into that workqueue, deadlock
      would happen.
    - After we get right data, we write it back to the corrupted mirror.
    - And if the data on the new mirror is still corrupted, we will try next
      mirror until we read right data or all the mirrors are traversed.
    - After the above work, we set the uptodate flag according to the result.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a224fb9b34a3..48794f951427 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -713,7 +713,11 @@ static void end_workqueue_bio(struct bio *bio, int err)
 			func = btrfs_endio_write_helper;
 		}
 	} else {
-		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56) {
+		if (unlikely(end_io_wq->metadata ==
+			     BTRFS_WQ_ENDIO_DIO_REPAIR)) {
+			wq = fs_info->endio_repair_workers;
+			func = btrfs_endio_repair_helper;
+		} else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56) {
 			wq = fs_info->endio_raid56_workers;
 			func = btrfs_endio_raid56_helper;
 		} else if (end_io_wq->metadata) {
@@ -741,6 +745,7 @@ int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 			int metadata)
 {
 	struct end_io_wq *end_io_wq;
+
 	end_io_wq = kmalloc(sizeof(*end_io_wq), GFP_NOFS);
 	if (!end_io_wq)
 		return -ENOMEM;
@@ -2055,6 +2060,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->endio_workers);
 	btrfs_destroy_workqueue(fs_info->endio_meta_workers);
 	btrfs_destroy_workqueue(fs_info->endio_raid56_workers);
+	btrfs_destroy_workqueue(fs_info->endio_repair_workers);
 	btrfs_destroy_workqueue(fs_info->rmw_workers);
 	btrfs_destroy_workqueue(fs_info->endio_meta_write_workers);
 	btrfs_destroy_workqueue(fs_info->endio_write_workers);
@@ -2572,6 +2578,8 @@ int open_ctree(struct super_block *sb,
 		btrfs_alloc_workqueue("endio-meta-write", flags, max_active, 2);
 	fs_info->endio_raid56_workers =
 		btrfs_alloc_workqueue("endio-raid56", flags, max_active, 4);
+	fs_info->endio_repair_workers =
+		btrfs_alloc_workqueue("endio-repair", flags, 1, 0);
 	fs_info->rmw_workers =
 		btrfs_alloc_workqueue("rmw", flags, max_active, 2);
 	fs_info->endio_write_workers =
@@ -2593,6 +2601,7 @@ int open_ctree(struct super_block *sb,
 	      fs_info->submit_workers && fs_info->flush_workers &&
 	      fs_info->endio_workers && fs_info->endio_meta_workers &&
 	      fs_info->endio_meta_write_workers &&
+	      fs_info->endio_repair_workers &&
 	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
 	      fs_info->caching_workers && fs_info->readahead_workers &&

commit ce7213c70c37e3a66bc0b50c45edcbfea505f62f
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Sep 3 21:35:34 2014 +0800

    Btrfs: fix wrong device bytes_used in the super block
    
    device->bytes_used will be changed when allocating a new chunk, and
    disk_total_size will be changed if resizing is successful.
    Meanwhile, the on-disk super blocks of the previous transaction
    might not be updated. Considering the consistency of the metadata
    in the previous transaction, We should use the size in the previous
    transaction to check if the super block is beyond the boundary
    of the device.
    
    Though it is not big problem because we don't use it now, but anyway
    it is better that we make it be consistent with the common metadata,
    maybe we will use it in the future.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0cd18b725554..a224fb9b34a3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3446,7 +3446,8 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		btrfs_set_stack_device_id(dev_item, dev->devid);
 		btrfs_set_stack_device_total_bytes(dev_item,
 						   dev->commit_total_bytes);
-		btrfs_set_stack_device_bytes_used(dev_item, dev->bytes_used);
+		btrfs_set_stack_device_bytes_used(dev_item,
+						  dev->commit_bytes_used);
 		btrfs_set_stack_device_io_align(dev_item, dev->io_align);
 		btrfs_set_stack_device_io_width(dev_item, dev->io_width);
 		btrfs_set_stack_device_sector_size(dev_item, dev->sector_size);

commit 935e5cc935bcbf9b3d0dd59fed7dbc0f2ebca6bc
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Sep 3 21:35:33 2014 +0800

    Btrfs: fix wrong disk size when writing super blocks
    
    total_size will be changed when resizing a device, and disk_total_size
    will be changed if resizing is successful. Meanwhile, the on-disk super
    blocks of the previous transaction might not be updated. Considering
    the consistency of the metadata in the previous transaction, We should
    use the size in the previous transaction to check if the super block is
    beyond the boundary of the device. Fix it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dbd792754b27..0cd18b725554 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3127,7 +3127,8 @@ static int write_dev_supers(struct btrfs_device *device,
 
 	for (i = 0; i < max_mirrors; i++) {
 		bytenr = btrfs_sb_offset(i);
-		if (bytenr + BTRFS_SUPER_INFO_SIZE >= device->total_bytes)
+		if (bytenr + BTRFS_SUPER_INFO_SIZE >=
+		    device->commit_total_bytes)
 			break;
 
 		if (wait) {
@@ -3444,7 +3445,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		btrfs_set_stack_device_type(dev_item, dev->type);
 		btrfs_set_stack_device_id(dev_item, dev->devid);
 		btrfs_set_stack_device_total_bytes(dev_item,
-						   dev->disk_total_bytes);
+						   dev->commit_total_bytes);
 		btrfs_set_stack_device_bytes_used(dev_item, dev->bytes_used);
 		btrfs_set_stack_device_io_align(dev_item, dev->io_align);
 		btrfs_set_stack_device_io_width(dev_item, dev->io_width);

commit 82f70d62f7923cc43128e75ae85366f137055b76
Author: Li RongQing <roy.qing.li@gmail.com>
Date:   Mon Sep 8 20:41:09 2014 +0800

    btrfs: remove the wrong comments
    
    This comments became wrong after c3c532[bdi: add helper function for
    doing init and register of a bdi for a file system], so remove them.
    
    Signed-off-by: Li RongQing <roy.qing.li@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 38b295553544..dbd792754b27 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1704,10 +1704,6 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	return ret;
 }
 
-/*
- * If this fails, caller must call bdi_destroy() to get rid of the
- * bdi again.
- */
 static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 {
 	int err;

commit 56094eecd32cbb80d098eee5a7cbd60f39f4b764
Author: Andrey Utkin <andrey.krieger.utkin@gmail.com>
Date:   Sat Aug 9 14:51:15 2014 +0300

    btrfs: Drop stray check of fixup_workers creation
    
    The issue was introduced in a79b7d4b3e8118f265dcb4bdf9a572c392f02708,
    adding allocation of extent_workers, so this stray check is surely not
    meant to be a check of something else.
    
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=82021
    Reported-by: Maks Naumov <maksqwe1@ukr.net>
    Signed-off-by: Andrey Utkin <andrey.krieger.utkin@gmail.com>
    Reviewed-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d14847d05f31..38b295553544 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2601,7 +2601,7 @@ int open_ctree(struct super_block *sb,
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
 	      fs_info->caching_workers && fs_info->readahead_workers &&
 	      fs_info->fixup_workers && fs_info->delayed_workers &&
-	      fs_info->fixup_workers && fs_info->extent_workers &&
+	      fs_info->extent_workers &&
 	      fs_info->qgroup_rescan_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;

commit 29549aec76bd6f1fc8e1723ed5396d65073d6521
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Fri Jul 4 17:59:06 2014 +0800

    Btrfs: print btrfs specific info for some fatal error cases
    
    Marc argued that if there are several btrfs filesystems mounted,
    while users even don't know which filesystem hit the corrupted
    errors something like generation verification failure.
    
    Since @extent_buffer structure has a member @fs_info, let's output
    btrfs device info.
    
    Reported-by: Marc MERLIN <marc@merlins.org>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 508bbee320f6..d14847d05f31 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -348,9 +348,9 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		ret = 0;
 		goto out;
 	}
-	printk_ratelimited("parent transid verify failed on %llu wanted %llu "
-		       "found %llu\n",
-		       eb->start, parent_transid, btrfs_header_generation(eb));
+	printk_ratelimited(KERN_INFO "BTRFS (device %s): parent transid verify failed on %llu wanted %llu found %llu\n",
+			eb->fs_info->sb->s_id, eb->start,
+			parent_transid, btrfs_header_generation(eb));
 	ret = 1;
 
 	/*
@@ -614,15 +614,15 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != eb->start) {
-		printk_ratelimited(KERN_INFO "BTRFS: bad tree block start "
+		printk_ratelimited(KERN_INFO "BTRFS (device %s): bad tree block start "
 			       "%llu %llu\n",
-			       found_start, eb->start);
+			       eb->fs_info->sb->s_id, found_start, eb->start);
 		ret = -EIO;
 		goto err;
 	}
 	if (check_tree_block_fsid(root, eb)) {
-		printk_ratelimited(KERN_INFO "BTRFS: bad fsid on block %llu\n",
-			       eb->start);
+		printk_ratelimited(KERN_INFO "BTRFS (device %s): bad fsid on block %llu\n",
+			       eb->fs_info->sb->s_id, eb->start);
 		ret = -EIO;
 		goto err;
 	}

commit 707e8a071528385a87b63a72a37c2322e463c7b8
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Jun 4 19:22:26 2014 +0200

    btrfs: use nodesize everywhere, kill leafsize
    
    The nodesize and leafsize were never of different values. Unify the
    usage and make nodesize the one. Cleanup the redundant checks and
    helpers.
    
    Shaves a few bytes from .text:
    
      text    data     bss     dec     hex filename
    852418   24560   23112  900090   dbbfa btrfs.ko.before
    851074   24584   23112  898770   db6d2 btrfs.ko.after
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ec32bead96a1..508bbee320f6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1200,16 +1200,14 @@ btrfs_free_subvolume_writers(struct btrfs_subvolume_writers *writers)
 	kfree(writers);
 }
 
-static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
-			 u32 stripesize, struct btrfs_root *root,
-			 struct btrfs_fs_info *fs_info,
+static void __setup_root(u32 nodesize, u32 sectorsize, u32 stripesize,
+			 struct btrfs_root *root, struct btrfs_fs_info *fs_info,
 			 u64 objectid)
 {
 	root->node = NULL;
 	root->commit_root = NULL;
 	root->sectorsize = sectorsize;
 	root->nodesize = nodesize;
-	root->leafsize = leafsize;
 	root->stripesize = stripesize;
 	root->state = 0;
 	root->orphan_cleanup_state = 0;
@@ -1295,7 +1293,7 @@ struct btrfs_root *btrfs_alloc_dummy_root(void)
 	root = btrfs_alloc_root(NULL);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
-	__setup_root(4096, 4096, 4096, 4096, root, NULL, 1);
+	__setup_root(4096, 4096, 4096, root, NULL, 1);
 	set_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state);
 	root->alloc_bytenr = 0;
 
@@ -1318,14 +1316,13 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
-	__setup_root(tree_root->nodesize, tree_root->leafsize,
-		     tree_root->sectorsize, tree_root->stripesize,
-		     root, fs_info, objectid);
+	__setup_root(tree_root->nodesize, tree_root->sectorsize,
+		tree_root->stripesize, root, fs_info, objectid);
 	root->root_key.objectid = objectid;
 	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
 	root->root_key.offset = 0;
 
-	leaf = btrfs_alloc_free_block(trans, root, root->leafsize,
+	leaf = btrfs_alloc_free_block(trans, root, root->nodesize,
 				      0, objectid, NULL, 0, 0, 0);
 	if (IS_ERR(leaf)) {
 		ret = PTR_ERR(leaf);
@@ -1396,9 +1393,9 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
-	__setup_root(tree_root->nodesize, tree_root->leafsize,
-		     tree_root->sectorsize, tree_root->stripesize,
-		     root, fs_info, BTRFS_TREE_LOG_OBJECTID);
+	__setup_root(tree_root->nodesize, tree_root->sectorsize,
+		     tree_root->stripesize, root, fs_info,
+		     BTRFS_TREE_LOG_OBJECTID);
 
 	root->root_key.objectid = BTRFS_TREE_LOG_OBJECTID;
 	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
@@ -1413,7 +1410,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	 * updated (along with back refs to the log tree).
 	 */
 
-	leaf = btrfs_alloc_free_block(trans, root, root->leafsize, 0,
+	leaf = btrfs_alloc_free_block(trans, root, root->nodesize, 0,
 				      BTRFS_TREE_LOG_OBJECTID, NULL,
 				      0, 0, 0);
 	if (IS_ERR(leaf)) {
@@ -1465,7 +1462,7 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_stack_inode_generation(inode_item, 1);
 	btrfs_set_stack_inode_size(inode_item, 3);
 	btrfs_set_stack_inode_nlink(inode_item, 1);
-	btrfs_set_stack_inode_nbytes(inode_item, root->leafsize);
+	btrfs_set_stack_inode_nbytes(inode_item, root->nodesize);
 	btrfs_set_stack_inode_mode(inode_item, S_IFDIR | 0755);
 
 	btrfs_set_root_node(&log_root->root_item, log_root->node);
@@ -1498,9 +1495,8 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 		goto alloc_fail;
 	}
 
-	__setup_root(tree_root->nodesize, tree_root->leafsize,
-		     tree_root->sectorsize, tree_root->stripesize,
-		     root, fs_info, key->objectid);
+	__setup_root(tree_root->nodesize, tree_root->sectorsize,
+		tree_root->stripesize, root, fs_info, key->objectid);
 
 	ret = btrfs_find_root(tree_root, key, path,
 			      &root->root_item, &root->root_key);
@@ -1511,7 +1507,7 @@ static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
 	}
 
 	generation = btrfs_root_generation(&root->root_item);
-	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
+	blocksize = root->nodesize;
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
 	if (!root->node) {
@@ -2143,7 +2139,6 @@ int open_ctree(struct super_block *sb,
 {
 	u32 sectorsize;
 	u32 nodesize;
-	u32 leafsize;
 	u32 blocksize;
 	u32 stripesize;
 	u64 generation;
@@ -2389,7 +2384,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
-	__setup_root(4096, 4096, 4096, 4096, tree_root,
+	__setup_root(4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
 	invalidate_bdev(fs_devices->latest_bdev);
@@ -2469,19 +2464,22 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
-	if (btrfs_super_leafsize(disk_super) !=
+	/*
+	 * Leafsize and nodesize were always equal, this is only a sanity check.
+	 */
+	if (le32_to_cpu(disk_super->__unused_leafsize) !=
 	    btrfs_super_nodesize(disk_super)) {
 		printk(KERN_ERR "BTRFS: couldn't mount because metadata "
 		       "blocksizes don't match.  node %d leaf %d\n",
 		       btrfs_super_nodesize(disk_super),
-		       btrfs_super_leafsize(disk_super));
+		       le32_to_cpu(disk_super->__unused_leafsize));
 		err = -EINVAL;
 		goto fail_alloc;
 	}
-	if (btrfs_super_leafsize(disk_super) > BTRFS_MAX_METADATA_BLOCKSIZE) {
+	if (btrfs_super_nodesize(disk_super) > BTRFS_MAX_METADATA_BLOCKSIZE) {
 		printk(KERN_ERR "BTRFS: couldn't mount because metadata "
 		       "blocksize (%d) was too large\n",
-		       btrfs_super_leafsize(disk_super));
+		       btrfs_super_nodesize(disk_super));
 		err = -EINVAL;
 		goto fail_alloc;
 	}
@@ -2498,17 +2496,16 @@ int open_ctree(struct super_block *sb,
 	 * flag our filesystem as having big metadata blocks if
 	 * they are bigger than the page size
 	 */
-	if (btrfs_super_leafsize(disk_super) > PAGE_CACHE_SIZE) {
+	if (btrfs_super_nodesize(disk_super) > PAGE_CACHE_SIZE) {
 		if (!(features & BTRFS_FEATURE_INCOMPAT_BIG_METADATA))
 			printk(KERN_INFO "BTRFS: flagging fs with big metadata feature\n");
 		features |= BTRFS_FEATURE_INCOMPAT_BIG_METADATA;
 	}
 
 	nodesize = btrfs_super_nodesize(disk_super);
-	leafsize = btrfs_super_leafsize(disk_super);
 	sectorsize = btrfs_super_sectorsize(disk_super);
 	stripesize = btrfs_super_stripesize(disk_super);
-	fs_info->dirty_metadata_batch = leafsize * (1 + ilog2(nr_cpu_ids));
+	fs_info->dirty_metadata_batch = nodesize * (1 + ilog2(nr_cpu_ids));
 	fs_info->delalloc_batch = sectorsize * 512 * (1 + ilog2(nr_cpu_ids));
 
 	/*
@@ -2516,7 +2513,7 @@ int open_ctree(struct super_block *sb,
 	 * extent buffers for the same range.  It leads to corruptions
 	 */
 	if ((features & BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS) &&
-	    (sectorsize != leafsize)) {
+	    (sectorsize != nodesize)) {
 		printk(KERN_WARNING "BTRFS: unequal leaf/node/sector sizes "
 				"are not allowed for mixed block groups on %s\n",
 				sb->s_id);
@@ -2615,7 +2612,6 @@ int open_ctree(struct super_block *sb,
 				    4 * 1024 * 1024 / PAGE_CACHE_SIZE);
 
 	tree_root->nodesize = nodesize;
-	tree_root->leafsize = leafsize;
 	tree_root->sectorsize = sectorsize;
 	tree_root->stripesize = stripesize;
 
@@ -2642,12 +2638,11 @@ int open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 
-	blocksize = btrfs_level_size(tree_root,
-				     btrfs_super_chunk_root_level(disk_super));
+	blocksize = tree_root->nodesize;
 	generation = btrfs_super_chunk_root_generation(disk_super);
 
-	__setup_root(nodesize, leafsize, sectorsize, stripesize,
-		     chunk_root, fs_info, BTRFS_CHUNK_TREE_OBJECTID);
+	__setup_root(nodesize, sectorsize, stripesize, chunk_root,
+		     fs_info, BTRFS_CHUNK_TREE_OBJECTID);
 
 	chunk_root->node = read_tree_block(chunk_root,
 					   btrfs_super_chunk_root(disk_super),
@@ -2684,8 +2679,7 @@ int open_ctree(struct super_block *sb,
 	}
 
 retry_root_backup:
-	blocksize = btrfs_level_size(tree_root,
-				     btrfs_super_root_level(disk_super));
+	blocksize = tree_root->nodesize;
 	generation = btrfs_super_generation(disk_super);
 
 	tree_root->node = read_tree_block(tree_root,
@@ -2859,9 +2853,7 @@ int open_ctree(struct super_block *sb,
 			err = -EIO;
 			goto fail_qgroup;
 		}
-		blocksize =
-		     btrfs_level_size(tree_root,
-				      btrfs_super_log_root_level(disk_super));
+		blocksize = tree_root->nodesize;
 
 		log_tree_root = btrfs_alloc_root(fs_info);
 		if (!log_tree_root) {
@@ -2869,7 +2861,7 @@ int open_ctree(struct super_block *sb,
 			goto fail_qgroup;
 		}
 
-		__setup_root(nodesize, leafsize, sectorsize, stripesize,
+		__setup_root(nodesize, sectorsize, stripesize,
 			     log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
 
 		log_tree_root->node = read_tree_block(tree_root, bytenr,
@@ -4008,8 +4000,8 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 		clear_extent_bits(dirty_pages, start, end, mark, GFP_NOFS);
 		while (start <= end) {
 			eb = btrfs_find_tree_block(root, start,
-						   root->leafsize);
-			start += root->leafsize;
+						   root->nodesize);
+			start += root->nodesize;
 			if (!eb)
 				continue;
 			wait_on_extent_buffer_writeback(eb);

commit 3abdbd780e9d75f0648b8a502c3789857b1e92ce
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Jun 4 18:10:45 2014 +0200

    btrfs: make close_ctree return void
    
    There's no user of the return value and we can get rid of the comment in
    put_super.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 354cc3f232bb..ec32bead96a1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3623,7 +3623,7 @@ int btrfs_commit_super(struct btrfs_root *root)
 	return btrfs_commit_transaction(trans, root);
 }
 
-int close_ctree(struct btrfs_root *root)
+void close_ctree(struct btrfs_root *root)
 {
 	struct btrfs_fs_info *fs_info = root->fs_info;
 	int ret;
@@ -3711,8 +3711,6 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_free_block_rsv(root, root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;
-
-	return 0;
 }
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,

commit 57cdc8db21bf9cfa6b2e45310d56e74e263e8609
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Feb 5 02:37:48 2014 +0100

    btrfs: cleanup ino cache members of btrfs_root
    
    The naming is confusing, generic yet used for a specific cache. Add a
    prefix 'ino_' or rename appropriately.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a1d36e62179c..354cc3f232bb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1573,8 +1573,8 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 	root->subv_writers = writers;
 
 	btrfs_init_free_ino_ctl(root);
-	spin_lock_init(&root->cache_lock);
-	init_waitqueue_head(&root->cache_wait);
+	spin_lock_init(&root->ino_cache_lock);
+	init_waitqueue_head(&root->ino_cache_wait);
 
 	ret = get_anon_bdev(&root->anon_dev);
 	if (ret)
@@ -3532,7 +3532,7 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 
 static void free_fs_root(struct btrfs_root *root)
 {
-	iput(root->cache_inode);
+	iput(root->ino_cache_inode);
 	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
 	btrfs_free_block_rsv(root, root->orphan_block_rsv);
 	root->orphan_block_rsv = NULL;

commit b207892b061da7608878e273ae22ba9bf9be264b
Merge: 018a17bdc865 a516440542af
Author: Jens Axboe <axboe@fb.com>
Date:   Thu Sep 11 09:31:18 2014 -0600

    Merge branch 'for-linus' into for-3.18/core
    
    A bit of churn on the for-linus side that would be nice to have
    in the core bits for 3.18, so pull it in to catch us up and make
    forward progress easier.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>
    
    Conflicts:
            block/scsi_ioctl.c

commit ff9ea323816dc1c8ac7144afd4eab3ac97704430
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Sep 8 08:03:56 2014 +0900

    block, bdi: an active gendisk always has a request_queue associated with it
    
    bdev_get_queue() returns the request_queue associated with the
    specified block_device.  blk_get_backing_dev_info() makes use of
    bdev_get_queue() to determine the associated bdi given a block_device.
    
    All the callers of bdev_get_queue() including
    blk_get_backing_dev_info() assume that bdev_get_queue() may return
    NULL and implement NULL handling; however, bdev_get_queue() requires
    the passed in block_device is opened and attached to its gendisk.
    Because an active gendisk always has a valid request_queue associated
    with it, bdev_get_queue() can never return NULL and neither can
    blk_get_backing_dev_info().
    
    Make it clear that neither of the two functions can return NULL and
    remove NULL handling from all the callers.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Chris Mason <clm@fb.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d0ed9e664f7d..39ff591ae1b4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1694,7 +1694,7 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 		if (!device->bdev)
 			continue;
 		bdi = blk_get_backing_dev_info(device->bdev);
-		if (bdi && bdi_congested(bdi, bdi_bits)) {
+		if (bdi_congested(bdi, bdi_bits)) {
 			ret = 1;
 			break;
 		}

commit 908c7f1949cb7cc6e92ba8f18f2998e87e265b8e
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Sep 8 09:51:29 2014 +0900

    percpu_counter: add @gfp to percpu_counter_init()
    
    Percpu allocator now supports allocation mask.  Add @gfp to
    percpu_counter_init() so that !GFP_KERNEL allocation masks can be used
    with percpu_counters too.
    
    We could have left percpu_counter_init() alone and added
    percpu_counter_init_gfp(); however, the number of users isn't that
    high and introducing _gfp variants to all percpu data structures would
    be quite ugly, so let's just do the conversion.  This is the one with
    the most users.  Other percpu data structures are a lot easier to
    convert.
    
    This patch doesn't make any functional difference.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Jan Kara <jack@suse.cz>
    Acked-by: "David S. Miller" <davem@davemloft.net>
    Cc: x86@kernel.org
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 08e65e9cf2aa..61dae01788d7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1180,7 +1180,7 @@ static struct btrfs_subvolume_writers *btrfs_alloc_subvolume_writers(void)
 	if (!writers)
 		return ERR_PTR(-ENOMEM);
 
-	ret = percpu_counter_init(&writers->counter, 0);
+	ret = percpu_counter_init(&writers->counter, 0, GFP_KERNEL);
 	if (ret < 0) {
 		kfree(writers);
 		return ERR_PTR(ret);
@@ -2185,7 +2185,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_srcu;
 	}
 
-	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0);
+	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0, GFP_KERNEL);
 	if (ret) {
 		err = ret;
 		goto fail_bdi;
@@ -2193,13 +2193,13 @@ int open_ctree(struct super_block *sb,
 	fs_info->dirty_metadata_batch = PAGE_CACHE_SIZE *
 					(1 + ilog2(nr_cpu_ids));
 
-	ret = percpu_counter_init(&fs_info->delalloc_bytes, 0);
+	ret = percpu_counter_init(&fs_info->delalloc_bytes, 0, GFP_KERNEL);
 	if (ret) {
 		err = ret;
 		goto fail_dirty_metadata_bytes;
 	}
 
-	ret = percpu_counter_init(&fs_info->bio_counter, 0);
+	ret = percpu_counter_init(&fs_info->bio_counter, 0, GFP_KERNEL);
 	if (ret) {
 		err = ret;
 		goto fail_delalloc_bytes;

commit 9e0af23764344f7f1b68e4eefbe7dc865018b63d
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Aug 15 23:36:53 2014 +0800

    Btrfs: fix task hang under heavy compressed write
    
    This has been reported and discussed for a long time, and this hang occurs in
    both 3.15 and 3.16.
    
    Btrfs now migrates to use kernel workqueue, but it introduces this hang problem.
    
    Btrfs has a kind of work queued as an ordered way, which means that its
    ordered_func() must be processed in the way of FIFO, so it usually looks like --
    
    normal_work_helper(arg)
        work = container_of(arg, struct btrfs_work, normal_work);
    
        work->func() <---- (we name it work X)
        for ordered_work in wq->ordered_list
                ordered_work->ordered_func()
                ordered_work->ordered_free()
    
    The hang is a rare case, first when we find free space, we get an uncached block
    group, then we go to read its free space cache inode for free space information,
    so it will
    
    file a readahead request
        btrfs_readpages()
             for page that is not in page cache
                    __do_readpage()
                         submit_extent_page()
                               btrfs_submit_bio_hook()
                                     btrfs_bio_wq_end_io()
                                     submit_bio()
                                     end_workqueue_bio() <--(ret by the 1st endio)
                                          queue a work(named work Y) for the 2nd
                                          also the real endio()
    
    So the hang occurs when work Y's work_struct and work X's work_struct happens
    to share the same address.
    
    A bit more explanation,
    
    A,B,C -- struct btrfs_work
    arg   -- struct work_struct
    
    kthread:
    worker_thread()
        pick up a work_struct from @worklist
        process_one_work(arg)
            worker->current_work = arg;  <-- arg is A->normal_work
            worker->current_func(arg)
                    normal_work_helper(arg)
                         A = container_of(arg, struct btrfs_work, normal_work);
    
                         A->func()
                         A->ordered_func()
                         A->ordered_free()  <-- A gets freed
    
                         B->ordered_func()
                              submit_compressed_extents()
                                  find_free_extent()
                                      load_free_space_inode()
                                          ...   <-- (the above readhead stack)
                                          end_workqueue_bio()
                                               btrfs_queue_work(work C)
                         B->ordered_free()
    
    As if work A has a high priority in wq->ordered_list and there are more ordered
    works queued after it, such as B->ordered_func(), its memory could have been
    freed before normal_work_helper() returns, which means that kernel workqueue
    code worker_thread() still has worker->current_work pointer to be work
    A->normal_work's, ie. arg's address.
    
    Meanwhile, work C is allocated after work A is freed, work C->normal_work
    and work A->normal_work are likely to share the same address(I confirmed this
    with ftrace output, so I'm not just guessing, it's rare though).
    
    When another kthread picks up work C->normal_work to process, and finds our
    kthread is processing it(see find_worker_executing_work()), it'll think
    work C as a collision and skip then, which ends up nobody processing work C.
    
    So the situation is that our kthread is waiting forever on work C.
    
    Besides, there're other cases that can lead to deadlock, but the real problem
    is that all btrfs workqueue shares one work->func, -- normal_work_helper,
    so this makes each workqueue to have its own helper function, but only a
    wraper pf normal_work_helper.
    
    With this patch, I no long hit the above hang.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c99a414813c1..a1d36e62179c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -39,7 +39,6 @@
 #include "btrfs_inode.h"
 #include "volumes.h"
 #include "print-tree.h"
-#include "async-thread.h"
 #include "locking.h"
 #include "tree-log.h"
 #include "free-space-cache.h"
@@ -693,35 +692,41 @@ static void end_workqueue_bio(struct bio *bio, int err)
 {
 	struct end_io_wq *end_io_wq = bio->bi_private;
 	struct btrfs_fs_info *fs_info;
+	struct btrfs_workqueue *wq;
+	btrfs_work_func_t func;
 
 	fs_info = end_io_wq->info;
 	end_io_wq->error = err;
-	btrfs_init_work(&end_io_wq->work, end_workqueue_fn, NULL, NULL);
 
 	if (bio->bi_rw & REQ_WRITE) {
-		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_METADATA)
-			btrfs_queue_work(fs_info->endio_meta_write_workers,
-					 &end_io_wq->work);
-		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_FREE_SPACE)
-			btrfs_queue_work(fs_info->endio_freespace_worker,
-					 &end_io_wq->work);
-		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
-			btrfs_queue_work(fs_info->endio_raid56_workers,
-					 &end_io_wq->work);
-		else
-			btrfs_queue_work(fs_info->endio_write_workers,
-					 &end_io_wq->work);
+		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_METADATA) {
+			wq = fs_info->endio_meta_write_workers;
+			func = btrfs_endio_meta_write_helper;
+		} else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_FREE_SPACE) {
+			wq = fs_info->endio_freespace_worker;
+			func = btrfs_freespace_write_helper;
+		} else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56) {
+			wq = fs_info->endio_raid56_workers;
+			func = btrfs_endio_raid56_helper;
+		} else {
+			wq = fs_info->endio_write_workers;
+			func = btrfs_endio_write_helper;
+		}
 	} else {
-		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
-			btrfs_queue_work(fs_info->endio_raid56_workers,
-					 &end_io_wq->work);
-		else if (end_io_wq->metadata)
-			btrfs_queue_work(fs_info->endio_meta_workers,
-					 &end_io_wq->work);
-		else
-			btrfs_queue_work(fs_info->endio_workers,
-					 &end_io_wq->work);
+		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56) {
+			wq = fs_info->endio_raid56_workers;
+			func = btrfs_endio_raid56_helper;
+		} else if (end_io_wq->metadata) {
+			wq = fs_info->endio_meta_workers;
+			func = btrfs_endio_meta_helper;
+		} else {
+			wq = fs_info->endio_workers;
+			func = btrfs_endio_helper;
+		}
 	}
+
+	btrfs_init_work(&end_io_wq->work, func, end_workqueue_fn, NULL, NULL);
+	btrfs_queue_work(wq, &end_io_wq->work);
 }
 
 /*
@@ -828,7 +833,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->submit_bio_start = submit_bio_start;
 	async->submit_bio_done = submit_bio_done;
 
-	btrfs_init_work(&async->work, run_one_async_start,
+	btrfs_init_work(&async->work, btrfs_worker_helper, run_one_async_start,
 			run_one_async_done, run_one_async_free);
 
 	async->bio_flags = bio_flags;

commit 7df69d3e94d6de537fd1afb574c760d8dc83ab60
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jul 24 11:37:13 2014 +0800

    Btrfs: Fix wrong device size when we are resizing the device
    
    total_bytes of device is just a in-memory variant which is used to record
    the size of the device, and it might be changed before we resize a device,
    if the resize operation fails, it will be fallbacked. But some code used it
    to update on-disk metadata of the device, it would cause the problem that
    on-disk metadata of the devices was not consistent. We should use the other
    variant named disk_total_bytes to update the on-disk metadata of device,
    because that variant is updated only when the resize operation is successful.
    Fix it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d0ed9e664f7d..c99a414813c1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3450,7 +3450,8 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		btrfs_set_stack_device_generation(dev_item, 0);
 		btrfs_set_stack_device_type(dev_item, dev->type);
 		btrfs_set_stack_device_id(dev_item, dev->devid);
-		btrfs_set_stack_device_total_bytes(dev_item, dev->total_bytes);
+		btrfs_set_stack_device_total_bytes(dev_item,
+						   dev->disk_total_bytes);
 		btrfs_set_stack_device_bytes_used(dev_item, dev->bytes_used);
 		btrfs_set_stack_device_io_align(dev_item, dev->io_align);
 		btrfs_set_stack_device_io_width(dev_item, dev->io_width);

commit 8d875f95da43c6a8f18f77869f2ef26e9594fecc
Author: Chris Mason <clm@fb.com>
Date:   Tue Aug 12 10:47:42 2014 -0700

    btrfs: disable strict file flushes for renames and truncates
    
    Truncates and renames are often used to replace old versions of a file
    with new versions.  Applications often expect this to be an atomic
    replacement, even if they haven't done anything to make sure the new
    version is fully on disk.
    
    Btrfs has strict flushing in place to make sure that renaming over an
    old file with a new file will fully flush out the new file before
    allowing the transaction commit with the rename to complete.
    
    This ordering means the commit code needs to be able to lock file pages,
    and there are a few paths in the filesystem where we will try to end a
    transaction with the page lock held.  It's rare, but these things can
    deadlock.
    
    This patch removes the ordered flushes and switches to a best effort
    filemap_flush like ext4 uses. It's not perfect, but it should fix the
    deadlocks.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 08e65e9cf2aa..d0ed9e664f7d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -60,8 +60,6 @@ static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 				    int read_only);
-static void btrfs_destroy_ordered_operations(struct btrfs_transaction *t,
-					     struct btrfs_root *root);
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				      struct btrfs_root *root);
@@ -3829,34 +3827,6 @@ static void btrfs_error_commit_super(struct btrfs_root *root)
 	btrfs_cleanup_transaction(root);
 }
 
-static void btrfs_destroy_ordered_operations(struct btrfs_transaction *t,
-					     struct btrfs_root *root)
-{
-	struct btrfs_inode *btrfs_inode;
-	struct list_head splice;
-
-	INIT_LIST_HEAD(&splice);
-
-	mutex_lock(&root->fs_info->ordered_operations_mutex);
-	spin_lock(&root->fs_info->ordered_root_lock);
-
-	list_splice_init(&t->ordered_operations, &splice);
-	while (!list_empty(&splice)) {
-		btrfs_inode = list_entry(splice.next, struct btrfs_inode,
-					 ordered_operations);
-
-		list_del_init(&btrfs_inode->ordered_operations);
-		spin_unlock(&root->fs_info->ordered_root_lock);
-
-		btrfs_invalidate_inodes(btrfs_inode->root);
-
-		spin_lock(&root->fs_info->ordered_root_lock);
-	}
-
-	spin_unlock(&root->fs_info->ordered_root_lock);
-	mutex_unlock(&root->fs_info->ordered_operations_mutex);
-}
-
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root)
 {
 	struct btrfs_ordered_extent *ordered;
@@ -4093,8 +4063,6 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 				   struct btrfs_root *root)
 {
-	btrfs_destroy_ordered_operations(cur_trans, root);
-
 	btrfs_destroy_delayed_refs(cur_trans, root);
 
 	cur_trans->state = TRANS_STATE_COMMIT_START;

commit 5f3164813b90f7dbcb5c3ab9006906222ce471b7
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Thu Jun 26 11:08:16 2014 +0800

    Btrfs: fix race between balance recovery and root deletion
    
    Balance recovery is called when RW mounting or remounting from
    RO to RW, it is called to finish roots merging.
    
    When doing balance recovery, relocation root's corresponding
    fs root(whose root refs is 0) might be destroyed by cleaner
    thread, this will make btrfs fail to mount.
    
    Fix this problem by holding @cleaner_mutex when doing balance
    recovery.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f00165de6fbf..08e65e9cf2aa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2905,7 +2905,9 @@ int open_ctree(struct super_block *sb,
 		if (ret)
 			goto fail_qgroup;
 
+		mutex_lock(&fs_info->cleaner_mutex);
 		ret = btrfs_recover_relocation(tree_root);
+		mutex_unlock(&fs_info->cleaner_mutex);
 		if (ret < 0) {
 			printk(KERN_WARNING
 			       "BTRFS: failed to recover relocation\n");

commit 472b909ff6f4884d235ef7b9d3847fad5efafbff
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed Jun 25 13:45:41 2014 -0700

    btrfs: only unlock block in verify_parent_transid if we locked it
    
    This is a regression from my patch a26e8c9f75b0bfd8cccc9e8f110737b136eb5994, we
    need to only unlock the block if we were the one who locked it.  Otherwise this
    will trip BUG_ON()'s in locking.c  Thanks,
    
    cc: stable@vger.kernel.org
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8bb4aa19898f..f00165de6fbf 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -369,7 +369,8 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 out:
 	unlock_extent_cached(io_tree, eb->start, eb->start + eb->len - 1,
 			     &cached_state, GFP_NOFS);
-	btrfs_tree_read_unlock_blocking(eb);
+	if (need_lock)
+		btrfs_tree_read_unlock_blocking(eb);
 	return ret;
 }
 

commit a79b7d4b3e8118f265dcb4bdf9a572c392f02708
Author: Chris Mason <clm@fb.com>
Date:   Thu May 22 16:18:52 2014 -0700

    Btrfs: async delayed refs
    
    Delayed extent operations are triggered during transaction commits.
    The goal is to queue up a healthly batch of changes to the extent
    allocation tree and run through them in bulk.
    
    This farms them off to async helper threads.  The goal is to have the
    bulk of the delayed operations being done in the background, but this is
    also important to limit our stack footprint.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0c0fa78ef452..8bb4aa19898f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2069,6 +2069,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->readahead_workers);
 	btrfs_destroy_workqueue(fs_info->flush_workers);
 	btrfs_destroy_workqueue(fs_info->qgroup_rescan_workers);
+	btrfs_destroy_workqueue(fs_info->extent_workers);
 }
 
 static void free_root_extent_buffers(struct btrfs_root *root)
@@ -2586,6 +2587,10 @@ int open_ctree(struct super_block *sb,
 		btrfs_alloc_workqueue("readahead", flags, max_active, 2);
 	fs_info->qgroup_rescan_workers =
 		btrfs_alloc_workqueue("qgroup-rescan", flags, 1, 0);
+	fs_info->extent_workers =
+		btrfs_alloc_workqueue("extent-refs", flags,
+				      min_t(u64, fs_devices->num_devices,
+					    max_active), 8);
 
 	if (!(fs_info->workers && fs_info->delalloc_workers &&
 	      fs_info->submit_workers && fs_info->flush_workers &&
@@ -2595,6 +2600,7 @@ int open_ctree(struct super_block *sb,
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
 	      fs_info->caching_workers && fs_info->readahead_workers &&
 	      fs_info->fixup_workers && fs_info->delayed_workers &&
+	      fs_info->fixup_workers && fs_info->extent_workers &&
 	      fs_info->qgroup_rescan_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;

commit faa2dbf004e89e8f7ccd28fbe6f07c308417b8ae
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed May 7 17:06:09 2014 -0400

    Btrfs: add sanity tests for new qgroup accounting code
    
    This exercises the various parts of the new qgroup accounting code.  We do some
    basic stuff and do some things with the shared refs to make sure all that code
    works.  I had to add a bunch of infrastructure because I needed to be able to
    insert items into a fake tree without having to do all the hard work myself,
    hopefully this will be usefull in the future.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 77f92a32e230..0c0fa78ef452 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1110,6 +1110,11 @@ struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 bytenr, u32 blocksize)
 {
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+	if (unlikely(test_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state)))
+		return alloc_test_extent_buffer(root->fs_info, bytenr,
+						blocksize);
+#endif
 	return alloc_extent_buffer(root->fs_info, bytenr, blocksize);
 }
 
@@ -1288,6 +1293,7 @@ struct btrfs_root *btrfs_alloc_dummy_root(void)
 		return ERR_PTR(-ENOMEM);
 	__setup_root(4096, 4096, 4096, 4096, root, NULL, 1);
 	set_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state);
+	root->alloc_bytenr = 0;
 
 	return root;
 }
@@ -2089,7 +2095,7 @@ static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 		free_root_extent_buffers(info->chunk_root);
 }
 
-static void del_fs_roots(struct btrfs_fs_info *fs_info)
+void btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)
 {
 	int ret;
 	struct btrfs_root *gang[8];
@@ -2969,7 +2975,7 @@ int open_ctree(struct super_block *sb,
 fail_trans_kthread:
 	kthread_stop(fs_info->transaction_kthread);
 	btrfs_cleanup_transaction(fs_info->tree_root);
-	del_fs_roots(fs_info);
+	btrfs_free_fs_roots(fs_info);
 fail_cleaner:
 	kthread_stop(fs_info->cleaner_kthread);
 
@@ -3504,8 +3510,10 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
 		btrfs_free_log(NULL, root);
 
-	__btrfs_remove_free_space_cache(root->free_ino_pinned);
-	__btrfs_remove_free_space_cache(root->free_ino_ctl);
+	if (root->free_ino_pinned)
+		__btrfs_remove_free_space_cache(root->free_ino_pinned);
+	if (root->free_ino_ctl)
+		__btrfs_remove_free_space_cache(root->free_ino_ctl);
 	free_fs_root(root);
 }
 
@@ -3655,7 +3663,7 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_sysfs_remove_one(fs_info);
 
-	del_fs_roots(fs_info);
+	btrfs_free_fs_roots(fs_info);
 
 	btrfs_put_block_group_cache(fs_info);
 

commit fcebe4562dec83b3f8d3088d77584727b09130b2
Author: Josef Bacik <jbacik@fb.com>
Date:   Tue May 13 17:30:47 2014 -0700

    Btrfs: rework qgroup accounting
    
    Currently qgroups account for space by intercepting delayed ref updates to fs
    trees.  It does this by adding sequence numbers to delayed ref updates so that
    it can figure out how the tree looked before the update so we can adjust the
    counters properly.  The problem with this is that it does not allow delayed refs
    to be merged, so if you say are defragging an extent with 5k snapshots pointing
    to it we will thrash the delayed ref lock because we need to go back and
    manually merge these things together.  Instead we want to process quota changes
    when we know they are going to happen, like when we first allocate an extent, we
    free a reference for an extent, we add new references etc.  This patch
    accomplishes this by only adding qgroup operations for real ref changes.  We
    only modify the sequence number when we need to lookup roots for bytenrs, this
    reduces the amount of churn on the sequence number and allows us to merge
    delayed refs as we add them most of the time.  This patch encompasses a bunch of
    architectural changes
    
    1) qgroup ref operations: instead of tracking qgroup operations through the
    delayed refs we simply add new ref operations whenever we notice that we need to
    when we've modified the refs themselves.
    
    2) tree mod seq:  we no longer have this separation of major/minor counters.
    this makes the sequence number stuff much more sane and we can remove some
    locking that was needed to protect the counter.
    
    3) delayed ref seq: we now read the tree mod seq number and use that as our
    sequence.  This means each new delayed ref doesn't have it's own unique sequence
    number, rather whenever we go to lookup backrefs we inc the sequence number so
    we can make sure to keep any new operations from screwing up our world view at
    that given point.  This allows us to merge delayed refs during runtime.
    
    With all of these changes the delayed ref stuff is a little saner and the qgroup
    accounting stuff no longer goes negative in some cases like it was before.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e54f0cd5cdf6..77f92a32e230 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -49,6 +49,7 @@
 #include "dev-replace.h"
 #include "raid56.h"
 #include "sysfs.h"
+#include "qgroup.h"
 
 #ifdef CONFIG_X86
 #include <asm/cpufeature.h>
@@ -2219,6 +2220,7 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->free_chunk_lock);
 	spin_lock_init(&fs_info->tree_mod_seq_lock);
 	spin_lock_init(&fs_info->super_lock);
+	spin_lock_init(&fs_info->qgroup_op_lock);
 	spin_lock_init(&fs_info->buffer_lock);
 	rwlock_init(&fs_info->tree_mod_log_lock);
 	mutex_init(&fs_info->reloc_mutex);
@@ -2244,6 +2246,7 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
 	atomic_set(&fs_info->defrag_running, 0);
+	atomic_set(&fs_info->qgroup_op_seq, 0);
 	atomic64_set(&fs_info->tree_mod_seq, 0);
 	fs_info->sb = sb;
 	fs_info->max_inline = 8192 * 1024;
@@ -2353,6 +2356,7 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->qgroup_lock);
 	mutex_init(&fs_info->qgroup_ioctl_lock);
 	fs_info->qgroup_tree = RB_ROOT;
+	fs_info->qgroup_op_tree = RB_ROOT;
 	INIT_LIST_HEAD(&fs_info->dirty_qgroups);
 	fs_info->qgroup_seq = 1;
 	fs_info->quota_enabled = 0;

commit 1f21ef0a34c37de0daf66fce7141b23b88630f29
Author: Filipe Manana <fdmanana@gmail.com>
Date:   Wed Apr 9 15:37:06 2014 +0100

    Btrfs: check if items are ordered when a leaf is marked dirty
    
    To ease finding bugs during development related to modifying btree leaves
    in such a way that it makes its items not sorted by key anymore. Since this
    is an expensive check, it's only enabled if CONFIG_BTRFS_FS_CHECK_INTEGRITY
    is set, which isn't meant to be enabled for regular users.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f4e708239c09..e54f0cd5cdf6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3738,6 +3738,12 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 		__percpu_counter_add(&root->fs_info->dirty_metadata_bytes,
 				     buf->len,
 				     root->fs_info->dirty_metadata_batch);
+#ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
+	if (btrfs_header_level(buf) == 0 && check_leaf(root, buf)) {
+		btrfs_print_leaf(root, buf);
+		ASSERT(0);
+	}
+#endif
 }
 
 static void __btrfs_btree_balance_dirty(struct btrfs_root *root,

commit de348ee022175401e77d7662b7ca6e231a94e3fd
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Wed Apr 9 19:23:22 2014 +0800

    Btrfs: make sure there are not any read requests before stopping workers
    
    In close_ctree(), after we have stopped all workers,there maybe still
    some read requests(for example readahead) to submit and this *maybe* trigger
    an oops that user reported before:
    
    kernel BUG at fs/btrfs/async-thread.c:619!
    
    By hacking codes, i can reproduce this problem with one cpu available.
    We fix this potential problem by invalidating all btree inode pages before
    stopping all workers.
    
    Thanks to Miao for pointing out this problem.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d3bd34e434f6..f4e708239c09 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3657,6 +3657,11 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_free_block_groups(fs_info);
 
+	/*
+	 * we must make sure there is not any read request to
+	 * submit after we stopping all workers.
+	 */
+	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	btrfs_stop_all_workers(fs_info);
 
 	free_root_pointers(fs_info, 1);

commit 59885b39303edc0b3284f324a1ca42cb6e7742d0
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Wed Apr 9 09:18:04 2014 +0900

    Btrfs: fix possible memory leak in btrfs_create_tree()
    
    In btrfs_create_tree(), if btrfs_insert_root() fails, we should
    free root->commit_root.
    
    Reported-by: Alex Lyakas <alex@zadarastorage.com>
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cf8427a7a615..d3bd34e434f6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1366,6 +1366,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 fail:
 	if (leaf) {
 		btrfs_tree_unlock(leaf);
+		free_extent_buffer(root->commit_root);
 		free_extent_buffer(leaf);
 	}
 	kfree(root);

commit 27cdeb7096b86f05ad018a24cdb63acdf0850a5d
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Apr 2 19:51:05 2014 +0800

    Btrfs: use bitfield instead of integer data type for the some variants in btrfs_root
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 85f514483bd1..cf8427a7a615 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1201,10 +1201,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->nodesize = nodesize;
 	root->leafsize = leafsize;
 	root->stripesize = stripesize;
-	root->ref_cows = 0;
-	root->track_dirty = 0;
-	root->in_radix = 0;
-	root->orphan_item_inserted = 0;
+	root->state = 0;
 	root->orphan_cleanup_state = 0;
 
 	root->objectid = objectid;
@@ -1265,7 +1262,6 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	else
 		root->defrag_trans_start = 0;
 	init_completion(&root->kobj_unregister);
-	root->defrag_running = 0;
 	root->root_key.objectid = objectid;
 	root->anon_dev = 0;
 
@@ -1290,7 +1286,7 @@ struct btrfs_root *btrfs_alloc_dummy_root(void)
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 	__setup_root(4096, 4096, 4096, 4096, root, NULL, 1);
-	root->dummy_root = 1;
+	set_bit(BTRFS_ROOT_DUMMY_ROOT, &root->state);
 
 	return root;
 }
@@ -1341,8 +1337,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	btrfs_mark_buffer_dirty(leaf);
 
 	root->commit_root = btrfs_root_node(root);
-	root->track_dirty = 1;
-
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
 
 	root->root_item.flags = 0;
 	root->root_item.byte_limit = 0;
@@ -1396,13 +1391,15 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	root->root_key.objectid = BTRFS_TREE_LOG_OBJECTID;
 	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
 	root->root_key.offset = BTRFS_TREE_LOG_OBJECTID;
+
 	/*
+	 * DON'T set REF_COWS for log trees
+	 *
 	 * log trees do not get reference counted because they go away
 	 * before a real commit is actually done.  They do store pointers
 	 * to file data extents, and those reference counts still get
 	 * updated (along with back refs to the log tree).
 	 */
-	root->ref_cows = 0;
 
 	leaf = btrfs_alloc_free_block(trans, root, root->leafsize, 0,
 				      BTRFS_TREE_LOG_OBJECTID, NULL,
@@ -1536,7 +1533,7 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_root *tree_root,
 		return root;
 
 	if (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {
-		root->ref_cows = 1;
+		set_bit(BTRFS_ROOT_REF_COWS, &root->state);
 		btrfs_check_and_init_root_item(&root->root_item);
 	}
 
@@ -1606,7 +1603,7 @@ int btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,
 				(unsigned long)root->root_key.objectid,
 				root);
 	if (ret == 0)
-		root->in_radix = 1;
+		set_bit(BTRFS_ROOT_IN_RADIX, &root->state);
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 	radix_tree_preload_end();
 
@@ -1662,7 +1659,7 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	if (ret < 0)
 		goto fail;
 	if (ret == 0)
-		root->orphan_item_inserted = 1;
+		set_bit(BTRFS_ROOT_ORPHAN_ITEM_INSERTED, &root->state);
 
 	ret = btrfs_insert_fs_root(fs_info, root);
 	if (ret) {
@@ -2101,7 +2098,7 @@ static void del_fs_roots(struct btrfs_fs_info *fs_info)
 				     struct btrfs_root, root_list);
 		list_del(&gang[0]->root_list);
 
-		if (gang[0]->in_radix) {
+		if (test_bit(BTRFS_ROOT_IN_RADIX, &gang[0]->state)) {
 			btrfs_drop_and_free_fs_root(fs_info, gang[0]);
 		} else {
 			free_extent_buffer(gang[0]->node);
@@ -2694,7 +2691,7 @@ int open_ctree(struct super_block *sb,
 		ret = PTR_ERR(extent_root);
 		goto recovery_tree_root;
 	}
-	extent_root->track_dirty = 1;
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &extent_root->state);
 	fs_info->extent_root = extent_root;
 
 	location.objectid = BTRFS_DEV_TREE_OBJECTID;
@@ -2703,7 +2700,7 @@ int open_ctree(struct super_block *sb,
 		ret = PTR_ERR(dev_root);
 		goto recovery_tree_root;
 	}
-	dev_root->track_dirty = 1;
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &dev_root->state);
 	fs_info->dev_root = dev_root;
 	btrfs_init_devices_late(fs_info);
 
@@ -2713,13 +2710,13 @@ int open_ctree(struct super_block *sb,
 		ret = PTR_ERR(csum_root);
 		goto recovery_tree_root;
 	}
-	csum_root->track_dirty = 1;
+	set_bit(BTRFS_ROOT_TRACK_DIRTY, &csum_root->state);
 	fs_info->csum_root = csum_root;
 
 	location.objectid = BTRFS_QUOTA_TREE_OBJECTID;
 	quota_root = btrfs_read_tree_root(tree_root, &location);
 	if (!IS_ERR(quota_root)) {
-		quota_root->track_dirty = 1;
+		set_bit(BTRFS_ROOT_TRACK_DIRTY, &quota_root->state);
 		fs_info->quota_enabled = 1;
 		fs_info->pending_quota_state = 1;
 		fs_info->quota_root = quota_root;
@@ -2734,7 +2731,7 @@ int open_ctree(struct super_block *sb,
 		create_uuid_tree = true;
 		check_uuid_tree = false;
 	} else {
-		uuid_root->track_dirty = 1;
+		set_bit(BTRFS_ROOT_TRACK_DIRTY, &uuid_root->state);
 		fs_info->uuid_root = uuid_root;
 		create_uuid_tree = false;
 		check_uuid_tree =

commit 65d33fd7a6e4aaf9cd6577555d0b3c18fbefe415
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Apr 22 17:13:51 2014 +0800

    btrfs: Add check to avoid cleanup roots already in fs_info->dead_roots.
    
    Current btrfs_orphan_cleanup will also cleanup roots which is already in
    fs_info->dead_roots without protection.
    This will have conditional race with fs_info->cleaner_kthread.
    
    This patch will use refs in root->root_item to detect roots in
    dead_roots and avoid conflicts.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4b1f16dd9ce3..85f514483bd1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3534,28 +3534,51 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 {
 	u64 root_objectid = 0;
 	struct btrfs_root *gang[8];
-	int i;
-	int ret;
+	int i = 0;
+	int err = 0;
+	unsigned int ret = 0;
+	int index;
 
 	while (1) {
+		index = srcu_read_lock(&fs_info->subvol_srcu);
 		ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,
 					     (void **)gang, root_objectid,
 					     ARRAY_SIZE(gang));
-		if (!ret)
+		if (!ret) {
+			srcu_read_unlock(&fs_info->subvol_srcu, index);
 			break;
-
+		}
 		root_objectid = gang[ret - 1]->root_key.objectid + 1;
+
 		for (i = 0; i < ret; i++) {
-			int err;
+			/* Avoid to grab roots in dead_roots */
+			if (btrfs_root_refs(&gang[i]->root_item) == 0) {
+				gang[i] = NULL;
+				continue;
+			}
+			/* grab all the search result for later use */
+			gang[i] = btrfs_grab_fs_root(gang[i]);
+		}
+		srcu_read_unlock(&fs_info->subvol_srcu, index);
 
+		for (i = 0; i < ret; i++) {
+			if (!gang[i])
+				continue;
 			root_objectid = gang[i]->root_key.objectid;
 			err = btrfs_orphan_cleanup(gang[i]);
 			if (err)
-				return err;
+				break;
+			btrfs_put_fs_root(gang[i]);
 		}
 		root_objectid++;
 	}
-	return 0;
+
+	/* release the uncleaned roots due to error */
+	for (; i < ret; i++) {
+		if (gang[i])
+			btrfs_put_fs_root(gang[i]);
+	}
+	return err;
 }
 
 int btrfs_commit_super(struct btrfs_root *root)

commit 21c7e75654b77b53a4436bf28496aac11536b6ba
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue May 13 17:29:04 2014 -0700

    Btrfs: reclaim the reserved metadata space at background
    
    Before applying this patch, the task had to reclaim the metadata space
    by itself if the metadata space was not enough. And When the task started
    the space reclamation, all the other tasks which wanted to reserve the
    metadata space were blocked. At some cases, they would be blocked for
    a long time, it made the performance fluctuate wildly.
    
    So we introduce the background metadata space reclamation, when the space
    is about to be exhausted, we insert a reclaim work into the workqueue, the
    worker of the workqueue helps us to reclaim the reserved space at the
    background. By this way, the tasks needn't reclaim the space by themselves at
    most cases, and even if the tasks have to reclaim the space or are blocked
    for the space reclamation, they will get enough space more quickly.
    
    Here is my test result(Tested by compilebench):
     Memory:        2GB
     CPU:           2Cores * 1CPU
     Partition:     40GB(SSD)
    
    Test command:
     # compilebench -D <mnt> -m
    
    Without this patch:
     intial create total runs 30 avg 54.36 MB/s (user 0.52s sys 2.44s)
     compile total runs 30 avg 123.72 MB/s (user 0.13s sys 1.17s)
     read compiled tree total runs 3 avg 81.15 MB/s (user 0.74s sys 4.89s)
     delete compiled tree total runs 30 avg 5.32 seconds (user 0.35s sys 4.37s)
    
    With this patch:
     intial create total runs 30 avg 59.80 MB/s (user 0.52s sys 2.53s)
     compile total runs 30 avg 151.44 MB/s (user 0.13s sys 1.11s)
     read compiled tree total runs 3 avg 83.25 MB/s (user 0.76s sys 4.91s)
     delete compiled tree total runs 30 avg 5.29 seconds (user 0.34s sys 4.34s)
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 983314932af3..4b1f16dd9ce3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2291,6 +2291,7 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->balance_cancel_req, 0);
 	fs_info->balance_ctl = NULL;
 	init_waitqueue_head(&fs_info->balance_wait_q);
+	btrfs_init_async_reclaim_work(&fs_info->async_reclaim_work);
 
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
@@ -3603,6 +3604,8 @@ int close_ctree(struct btrfs_root *root)
 	/* clear out the rbtree of defraggable inodes */
 	btrfs_cleanup_defrag_inodes(fs_info);
 
+	cancel_work_sync(&fs_info->async_reclaim_work);
+
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_commit_super(root);
 		if (ret)

commit 33c0022f0e687b0161a9bb84a5671df932551e3a
Merge: 2b9d1c050d29 cfd4a535b68f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Apr 27 13:26:28 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: limit the path size in send to PATH_MAX
      Btrfs: correctly set profile flags on seqlock retry
      Btrfs: use correct key when repeating search for extent item
      Btrfs: fix inode caching vs tree log
      Btrfs: fix possible memory leaks in open_ctree()
      Btrfs: avoid triggering bug_on() when we fail to start inode caching task
      Btrfs: move btrfs_{set,clear}_and_info() to ctree.h
      btrfs: replace error code from btrfs_drop_extents
      btrfs: Change the hole range to a more accurate value.
      btrfs: fix use-after-free in mount_subvol()

commit 28c16cbbc32781224309e50cc99c684f2498bc59
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Wed Apr 23 19:33:35 2014 +0800

    Btrfs: fix possible memory leaks in open_ctree()
    
    Fix possible memory leaks in the following error handling paths:
    
    read_tree_block()
    btrfs_recover_log_trees
    btrfs_commit_super()
    btrfs_find_orphan_roots()
    btrfs_cleanup_fs_roots()
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6d1ac7d46f81..0e4fb4a5c7f0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2864,7 +2864,7 @@ int open_ctree(struct super_block *sb,
 			printk(KERN_ERR "BTRFS: failed to read log tree\n");
 			free_extent_buffer(log_tree_root->node);
 			kfree(log_tree_root);
-			goto fail_trans_kthread;
+			goto fail_qgroup;
 		}
 		/* returns with log_tree_root freed on success */
 		ret = btrfs_recover_log_trees(log_tree_root);
@@ -2873,24 +2873,24 @@ int open_ctree(struct super_block *sb,
 				    "Failed to recover log tree");
 			free_extent_buffer(log_tree_root->node);
 			kfree(log_tree_root);
-			goto fail_trans_kthread;
+			goto fail_qgroup;
 		}
 
 		if (sb->s_flags & MS_RDONLY) {
 			ret = btrfs_commit_super(tree_root);
 			if (ret)
-				goto fail_trans_kthread;
+				goto fail_qgroup;
 		}
 	}
 
 	ret = btrfs_find_orphan_roots(tree_root);
 	if (ret)
-		goto fail_trans_kthread;
+		goto fail_qgroup;
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_cleanup_fs_roots(fs_info);
 		if (ret)
-			goto fail_trans_kthread;
+			goto fail_qgroup;
 
 		ret = btrfs_recover_relocation(tree_root);
 		if (ret < 0) {

commit 3123bca71993c2346a458875488863772c1d5dc4
Merge: 582076ab1677 e4fbaee29272
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 11 14:16:53 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull second set of btrfs updates from Chris Mason:
     "The most important changes here are from Josef, fixing a btrfs
      regression in 3.14 that can cause corruptions in the extent allocation
      tree when snapshots are in use.
    
      Josef also fixed some deadlocks in send/recv and other assorted races
      when balance is running"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (23 commits)
      Btrfs: fix compile warnings on on avr32 platform
      btrfs: allow mounting btrfs subvolumes with different ro/rw options
      btrfs: export global block reserve size as space_info
      btrfs: fix crash in remount(thread_pool=) case
      Btrfs: abort the transaction when we don't find our extent ref
      Btrfs: fix EINVAL checks in btrfs_clone
      Btrfs: fix unlock in __start_delalloc_inodes()
      Btrfs: scrub raid56 stripes in the right way
      Btrfs: don't compress for a small write
      Btrfs: more efficient io tree navigation on wait_extent_bit
      Btrfs: send, build path string only once in send_hole
      btrfs: filter invalid arg for btrfs resize
      Btrfs: send, fix data corruption due to incorrect hole detection
      Btrfs: kmalloc() doesn't return an ERR_PTR
      Btrfs: fix snapshot vs nocow writting
      btrfs: Change the expanding write sequence to fix snapshot related bug.
      btrfs: make device scan less noisy
      btrfs: fix lockdep warning with reclaim lock inversion
      Btrfs: hold the commit_root_sem when getting the commit root during send
      Btrfs: remove transaction from send
      ...

commit 9e351cc862b098d8ec8f8022d110932490794925
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Mar 13 15:42:13 2014 -0400

    Btrfs: remove transaction from send
    
    Lets try this again.  We can deadlock the box if we send on a box and try to
    write onto the same fs with the app that is trying to listen to the send pipe.
    This is because the writer could get stuck waiting for a transaction commit
    which is being blocked by the send.  So fix this by making sure looking at the
    commit roots is always going to be consistent.  We do this by keeping track of
    which roots need to have their commit roots swapped during commit, and then
    taking the commit_root_sem and swapping them all at once.  Then make sure we
    take a read lock on the commit_root_sem in cases where we search the commit root
    to make sure we're always looking at a consistent view of the commit roots.
    Previously we had problems with this because we would swap a fs tree commit root
    and then swap the extent tree commit root independently which would cause the
    backref walking code to screw up sometimes.  With this patch we no longer
    deadlock and pass all the weird send/receive corner cases.  Thanks,
    
    Reportedy-by: Hugo Mills <hugo@carfax.org.uk>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 98fe70193397..6d1ac7d46f81 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1567,7 +1567,6 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 	root->subv_writers = writers;
 
 	btrfs_init_free_ino_ctl(root);
-	mutex_init(&root->fs_commit_mutex);
 	spin_lock_init(&root->cache_lock);
 	init_waitqueue_head(&root->cache_wait);
 
@@ -2345,7 +2344,7 @@ int open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->transaction_kthread_mutex);
 	mutex_init(&fs_info->cleaner_mutex);
 	mutex_init(&fs_info->volume_mutex);
-	init_rwsem(&fs_info->extent_commit_sem);
+	init_rwsem(&fs_info->commit_root_sem);
 	init_rwsem(&fs_info->cleanup_work_sem);
 	init_rwsem(&fs_info->subvol_sem);
 	sema_init(&fs_info->uuid_tree_rescan_sem, 1);

commit a26e8c9f75b0bfd8cccc9e8f110737b136eb5994
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Mar 28 17:07:27 2014 -0400

    Btrfs: don't clear uptodate if the eb is under IO
    
    So I have an awful exercise script that will run snapshot, balance and
    send/receive in parallel.  This sometimes would crash spectacularly and when it
    came back up the fs would be completely hosed.  Turns out this is because of a
    bad interaction of balance and send/receive.  Send will hold onto its entire
    path for the whole send, but its blocks could get relocated out from underneath
    it, and because it doesn't old tree locks theres nothing to keep this from
    happening.  So it will go to read in a slot with an old transid, and we could
    have re-allocated this block for something else and it could have a completely
    different transid.  But because we think it is invalid we clear uptodate and
    re-read in the block.  If we do this before we actually write out the new block
    we could write back stale data to the fs, and boom we're screwed.
    
    Now we definitely need to fix this disconnect between send and balance, but we
    really really need to not allow ourselves to accidently read in stale data over
    new data.  So make sure we check if the extent buffer is not under io before
    clearing uptodate, this will kick back EIO to the caller instead of reading in
    stale data and keep us from corrupting the fs.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d9698fda2d12..98fe70193397 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -329,6 +329,8 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 {
 	struct extent_state *cached_state = NULL;
 	int ret;
+	bool need_lock = (current->journal_info ==
+			  (void *)BTRFS_SEND_TRANS_STUB);
 
 	if (!parent_transid || btrfs_header_generation(eb) == parent_transid)
 		return 0;
@@ -336,6 +338,11 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 	if (atomic)
 		return -EAGAIN;
 
+	if (need_lock) {
+		btrfs_tree_read_lock(eb);
+		btrfs_set_lock_blocking_rw(eb, BTRFS_READ_LOCK);
+	}
+
 	lock_extent_bits(io_tree, eb->start, eb->start + eb->len - 1,
 			 0, &cached_state);
 	if (extent_buffer_uptodate(eb) &&
@@ -347,10 +354,21 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		       "found %llu\n",
 		       eb->start, parent_transid, btrfs_header_generation(eb));
 	ret = 1;
-	clear_extent_buffer_uptodate(eb);
+
+	/*
+	 * Things reading via commit roots that don't have normal protection,
+	 * like send, can have a really old block in cache that may point at a
+	 * block that has been free'd and re-allocated.  So don't clear uptodate
+	 * if we find an eb that is under IO (dirty/writeback) because we could
+	 * end up reading in the stale data and then writing it back out and
+	 * making everybody very sad.
+	 */
+	if (!extent_buffer_under_io(eb))
+		clear_extent_buffer_uptodate(eb);
 out:
 	unlock_extent_cached(io_tree, eb->start, eb->start + eb->len - 1,
 			     &cached_state, GFP_NOFS);
+	btrfs_tree_read_unlock_blocking(eb);
 	return ret;
 }
 

commit 53c566625fb872e7826a237f0f5c21458028e94a
Merge: 34917f971390 00fdf13a2e9f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 4 15:31:36 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs changes from Chris Mason:
     "This is a pretty long stream of bug fixes and performance fixes.
    
      Qu Wenruo has replaced the btrfs async threads with regular kernel
      workqueues.  We'll keep an eye out for performance differences, but
      it's nice to be using more generic code for this.
    
      We still have some corruption fixes and other patches coming in for
      the merge window, but this batch is tested and ready to go"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (108 commits)
      Btrfs: fix a crash of clone with inline extents's split
      btrfs: fix uninit variable warning
      Btrfs: take into account total references when doing backref lookup
      Btrfs: part 2, fix incremental send's decision to delay a dir move/rename
      Btrfs: fix incremental send's decision to delay a dir move/rename
      Btrfs: remove unnecessary inode generation lookup in send
      Btrfs: fix race when updating existing ref head
      btrfs: Add trace for btrfs_workqueue alloc/destroy
      Btrfs: less fs tree lock contention when using autodefrag
      Btrfs: return EPERM when deleting a default subvolume
      Btrfs: add missing kfree in btrfs_destroy_workqueue
      Btrfs: cache extent states in defrag code path
      Btrfs: fix deadlock with nested trans handles
      Btrfs: fix possible empty list access when flushing the delalloc inodes
      Btrfs: split the global ordered extents mutex
      Btrfs: don't flush all delalloc inodes when we doesn't get s_umount lock
      Btrfs: reclaim delalloc metadata more aggressively
      Btrfs: remove unnecessary lock in may_commit_transaction()
      Btrfs: remove the unnecessary flush when preparing the pages
      Btrfs: just do dirty page flush for the inode with compression before direct IO
      ...

commit 573bfb72f7608eb7097d2dd036a714a6ab20cffe
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Mar 6 13:55:03 2014 +0800

    Btrfs: fix possible empty list access when flushing the delalloc inodes
    
    We didn't have a lock to protect the access to the delalloc inodes list, that is
    we might access a empty delalloc inodes list if someone start flushing delalloc
    inodes because the delalloc inodes were moved into a other list temporarily.
    Fix it by wrapping the access with a lock.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 237b5b5a2200..d9698fda2d12 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1221,6 +1221,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
 	mutex_init(&root->ordered_extent_mutex);
+	mutex_init(&root->delalloc_mutex);
 	init_waitqueue_head(&root->log_writer_wait);
 	init_waitqueue_head(&root->log_commit_wait[0]);
 	init_waitqueue_head(&root->log_commit_wait[1]);
@@ -2209,6 +2210,7 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->buffer_lock);
 	rwlock_init(&fs_info->tree_mod_log_lock);
 	mutex_init(&fs_info->reloc_mutex);
+	mutex_init(&fs_info->delalloc_root_mutex);
 	seqlock_init(&fs_info->profiles_lock);
 
 	init_completion(&fs_info->kobj_unregister);

commit 31f3d255c677073f83daa1e0671bbf2157bf8edc
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Mar 6 13:55:02 2014 +0800

    Btrfs: split the global ordered extents mutex
    
    When we create a snapshot, we just need wait the ordered extents in
    the source fs/file root, but because we use the global mutex to protect
    this ordered extents list of the source fs/file root to avoid accessing
    a empty list, if someone got the mutex to access the ordered extents list
    of the other fs/file root, we had to wait.
    
    This patch splits the above global mutex, now every fs/file root has
    its own mutex to protect its own list.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7d09ca48c347..237b5b5a2200 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1220,6 +1220,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	spin_lock_init(&root->log_extents_lock[1]);
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
+	mutex_init(&root->ordered_extent_mutex);
 	init_waitqueue_head(&root->log_writer_wait);
 	init_waitqueue_head(&root->log_commit_wait[0]);
 	init_waitqueue_head(&root->log_commit_wait[1]);

commit 8257b2dc3c1a1057b84a589827354abdc4c767fd
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Mar 6 13:38:19 2014 +0800

    Btrfs: introduce btrfs_{start, end}_nocow_write() for each subvolume
    
    If the snapshot creation happened after the nocow write but before the dirty
    data flush, we would fail to flush the dirty data because of no space.
    
    So we must keep track of when those nocow write operations start and when they
    end, if there are nocow writers, the snapshot creators must wait. In order
    to implement this function, I introduce btrfs_{start, end}_nocow_write(),
    which is similar to mnt_{want,drop}_write().
    
    These two functions are only used for nocow file write operations.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f7d84d955764..7d09ca48c347 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1149,6 +1149,32 @@ void clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 	}
 }
 
+static struct btrfs_subvolume_writers *btrfs_alloc_subvolume_writers(void)
+{
+	struct btrfs_subvolume_writers *writers;
+	int ret;
+
+	writers = kmalloc(sizeof(*writers), GFP_NOFS);
+	if (!writers)
+		return ERR_PTR(-ENOMEM);
+
+	ret = percpu_counter_init(&writers->counter, 0);
+	if (ret < 0) {
+		kfree(writers);
+		return ERR_PTR(ret);
+	}
+
+	init_waitqueue_head(&writers->wait);
+	return writers;
+}
+
+static void
+btrfs_free_subvolume_writers(struct btrfs_subvolume_writers *writers)
+{
+	percpu_counter_destroy(&writers->counter);
+	kfree(writers);
+}
+
 static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 			 u32 stripesize, struct btrfs_root *root,
 			 struct btrfs_fs_info *fs_info,
@@ -1205,6 +1231,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	atomic_set(&root->log_batch, 0);
 	atomic_set(&root->orphan_inodes, 0);
 	atomic_set(&root->refs, 1);
+	atomic_set(&root->will_be_snapshoted, 0);
 	root->log_transid = 0;
 	root->log_transid_committed = -1;
 	root->last_log_commit = 0;
@@ -1502,6 +1529,7 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_root *tree_root,
 int btrfs_init_fs_root(struct btrfs_root *root)
 {
 	int ret;
+	struct btrfs_subvolume_writers *writers;
 
 	root->free_ino_ctl = kzalloc(sizeof(*root->free_ino_ctl), GFP_NOFS);
 	root->free_ino_pinned = kzalloc(sizeof(*root->free_ino_pinned),
@@ -1511,6 +1539,13 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 		goto fail;
 	}
 
+	writers = btrfs_alloc_subvolume_writers();
+	if (IS_ERR(writers)) {
+		ret = PTR_ERR(writers);
+		goto fail;
+	}
+	root->subv_writers = writers;
+
 	btrfs_init_free_ino_ctl(root);
 	mutex_init(&root->fs_commit_mutex);
 	spin_lock_init(&root->cache_lock);
@@ -1518,8 +1553,11 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 
 	ret = get_anon_bdev(&root->anon_dev);
 	if (ret)
-		goto fail;
+		goto free_writers;
 	return 0;
+
+free_writers:
+	btrfs_free_subvolume_writers(root->subv_writers);
 fail:
 	kfree(root->free_ino_ctl);
 	kfree(root->free_ino_pinned);
@@ -3459,6 +3497,8 @@ static void free_fs_root(struct btrfs_root *root)
 	root->orphan_block_rsv = NULL;
 	if (root->anon_dev)
 		free_anon_bdev(root->anon_dev);
+	if (root->subv_writers)
+		btrfs_free_subvolume_writers(root->subv_writers);
 	free_extent_buffer(root->node);
 	free_extent_buffer(root->commit_root);
 	kfree(root->free_ino_ctl);

commit d458b0540ebd728b4d6ef47cc5ef0dbfd4dd361a
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:19 2014 +0800

    btrfs: Cleanup the "_struct" suffix in btrfs_workequeue
    
    Since the "_struct" suffix is mainly used for distinguish the differnt
    btrfs_work between the original and the newly created one,
    there is no need using the suffix since all btrfs_workers are changed
    into btrfs_workqueue.
    
    Also this patch fixed some codes whose code style is changed due to the
    too long "_struct" suffix.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c80d9507171c..f7d84d955764 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -55,7 +55,7 @@
 #endif
 
 static struct extent_io_ops btree_extent_io_ops;
-static void end_workqueue_fn(struct btrfs_work_struct *work);
+static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 				    int read_only);
@@ -86,7 +86,7 @@ struct end_io_wq {
 	int error;
 	int metadata;
 	struct list_head list;
-	struct btrfs_work_struct work;
+	struct btrfs_work work;
 };
 
 /*
@@ -108,7 +108,7 @@ struct async_submit_bio {
 	 * can't tell us where in the file the bio should go
 	 */
 	u64 bio_offset;
-	struct btrfs_work_struct work;
+	struct btrfs_work work;
 	int error;
 };
 
@@ -742,7 +742,7 @@ unsigned long btrfs_async_submit_limit(struct btrfs_fs_info *info)
 	return 256 * limit;
 }
 
-static void run_one_async_start(struct btrfs_work_struct *work)
+static void run_one_async_start(struct btrfs_work *work)
 {
 	struct async_submit_bio *async;
 	int ret;
@@ -755,7 +755,7 @@ static void run_one_async_start(struct btrfs_work_struct *work)
 		async->error = ret;
 }
 
-static void run_one_async_done(struct btrfs_work_struct *work)
+static void run_one_async_done(struct btrfs_work *work)
 {
 	struct btrfs_fs_info *fs_info;
 	struct async_submit_bio *async;
@@ -782,7 +782,7 @@ static void run_one_async_done(struct btrfs_work_struct *work)
 			       async->bio_offset);
 }
 
-static void run_one_async_free(struct btrfs_work_struct *work)
+static void run_one_async_free(struct btrfs_work *work)
 {
 	struct async_submit_bio *async;
 
@@ -1668,7 +1668,7 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
  * called by the kthread helper functions to finally call the bio end_io
  * functions.  This is where read checksum verification actually happens
  */
-static void end_workqueue_fn(struct btrfs_work_struct *work)
+static void end_workqueue_fn(struct btrfs_work *work)
 {
 	struct bio *bio;
 	struct end_io_wq *end_io_wq;

commit a046e9c88b0f46677923864295eac7c92cd962cb
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:18 2014 +0800

    btrfs: Cleanup the old btrfs_worker.
    
    Since all the btrfs_worker is replaced with the newly created
    btrfs_workqueue, the old codes can be easily remove.
    
    Signed-off-by: Quwenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9aaf9c309b54..c80d9507171c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1994,7 +1994,6 @@ static noinline int next_root_backup(struct btrfs_fs_info *info,
 /* helper to cleanup workers */
 static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 {
-	btrfs_stop_workers(&fs_info->generic_worker);
 	btrfs_destroy_workqueue(fs_info->fixup_workers);
 	btrfs_destroy_workqueue(fs_info->delalloc_workers);
 	btrfs_destroy_workqueue(fs_info->workers);
@@ -2472,8 +2471,6 @@ int open_ctree(struct super_block *sb,
 	}
 
 	max_active = fs_info->thread_pool_size;
-	btrfs_init_workers(&fs_info->generic_worker,
-			   "genwork", 1, NULL);
 
 	fs_info->workers =
 		btrfs_alloc_workqueue("worker", flags | WQ_HIGHPRI,
@@ -2526,15 +2523,6 @@ int open_ctree(struct super_block *sb,
 	fs_info->qgroup_rescan_workers =
 		btrfs_alloc_workqueue("qgroup-rescan", flags, 1, 0);
 
-	/*
-	 * btrfs_start_workers can really only fail because of ENOMEM so just
-	 * return -ENOMEM if any of these fail.
-	 */
-	ret = btrfs_start_workers(&fs_info->generic_worker);
-	if (ret) {
-		err = -ENOMEM;
-		goto fail_sb_buffer;
-	}
 	if (!(fs_info->workers && fs_info->delalloc_workers &&
 	      fs_info->submit_workers && fs_info->flush_workers &&
 	      fs_info->endio_workers && fs_info->endio_meta_workers &&

commit fc97fab0ea59fb923cbe91b7d208ffc6f1d8a95c
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:16 2014 +0800

    btrfs: Replace fs_info->qgroup_rescan_worker workqueue with btrfs_workqueue.
    
    Replace the fs_info->qgroup_rescan_worker with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f5da1fd23ee9..9aaf9c309b54 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2010,7 +2010,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->caching_workers);
 	btrfs_destroy_workqueue(fs_info->readahead_workers);
 	btrfs_destroy_workqueue(fs_info->flush_workers);
-	btrfs_stop_workers(&fs_info->qgroup_rescan_workers);
+	btrfs_destroy_workqueue(fs_info->qgroup_rescan_workers);
 }
 
 static void free_root_extent_buffers(struct btrfs_root *root)
@@ -2523,15 +2523,14 @@ int open_ctree(struct super_block *sb,
 		btrfs_alloc_workqueue("delayed-meta", flags, max_active, 0);
 	fs_info->readahead_workers =
 		btrfs_alloc_workqueue("readahead", flags, max_active, 2);
-	btrfs_init_workers(&fs_info->qgroup_rescan_workers, "qgroup-rescan", 1,
-			   &fs_info->generic_worker);
+	fs_info->qgroup_rescan_workers =
+		btrfs_alloc_workqueue("qgroup-rescan", flags, 1, 0);
 
 	/*
 	 * btrfs_start_workers can really only fail because of ENOMEM so just
 	 * return -ENOMEM if any of these fail.
 	 */
 	ret = btrfs_start_workers(&fs_info->generic_worker);
-	ret |= btrfs_start_workers(&fs_info->qgroup_rescan_workers);
 	if (ret) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
@@ -2543,7 +2542,8 @@ int open_ctree(struct super_block *sb,
 	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
 	      fs_info->caching_workers && fs_info->readahead_workers &&
-	      fs_info->fixup_workers && fs_info->delayed_workers)) {
+	      fs_info->fixup_workers && fs_info->delayed_workers &&
+	      fs_info->qgroup_rescan_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit 5b3bc44e2e69d42edf40ca3785040d233ca949f4
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:15 2014 +0800

    btrfs: Replace fs_info->delayed_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->delayed_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 392cd3baefe4..f5da1fd23ee9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2006,7 +2006,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->endio_write_workers);
 	btrfs_destroy_workqueue(fs_info->endio_freespace_worker);
 	btrfs_destroy_workqueue(fs_info->submit_workers);
-	btrfs_stop_workers(&fs_info->delayed_workers);
+	btrfs_destroy_workqueue(fs_info->delayed_workers);
 	btrfs_destroy_workqueue(fs_info->caching_workers);
 	btrfs_destroy_workqueue(fs_info->readahead_workers);
 	btrfs_destroy_workqueue(fs_info->flush_workers);
@@ -2519,9 +2519,8 @@ int open_ctree(struct super_block *sb,
 		btrfs_alloc_workqueue("endio-write", flags, max_active, 2);
 	fs_info->endio_freespace_worker =
 		btrfs_alloc_workqueue("freespace-write", flags, max_active, 0);
-	btrfs_init_workers(&fs_info->delayed_workers, "delayed-meta",
-			   fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
+	fs_info->delayed_workers =
+		btrfs_alloc_workqueue("delayed-meta", flags, max_active, 0);
 	fs_info->readahead_workers =
 		btrfs_alloc_workqueue("readahead", flags, max_active, 2);
 	btrfs_init_workers(&fs_info->qgroup_rescan_workers, "qgroup-rescan", 1,
@@ -2532,7 +2531,6 @@ int open_ctree(struct super_block *sb,
 	 * return -ENOMEM if any of these fail.
 	 */
 	ret = btrfs_start_workers(&fs_info->generic_worker);
-	ret |= btrfs_start_workers(&fs_info->delayed_workers);
 	ret |= btrfs_start_workers(&fs_info->qgroup_rescan_workers);
 	if (ret) {
 		err = -ENOMEM;
@@ -2545,7 +2543,7 @@ int open_ctree(struct super_block *sb,
 	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
 	      fs_info->caching_workers && fs_info->readahead_workers &&
-	      fs_info->fixup_workers)) {
+	      fs_info->fixup_workers && fs_info->delayed_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit dc6e320998fb907e4c19032d545d461bfe5040d1
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:14 2014 +0800

    btrfs: Replace fs_info->fixup_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->fixup_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c0b003bb66cd..392cd3baefe4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1995,7 +1995,7 @@ static noinline int next_root_backup(struct btrfs_fs_info *info,
 static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 {
 	btrfs_stop_workers(&fs_info->generic_worker);
-	btrfs_stop_workers(&fs_info->fixup_workers);
+	btrfs_destroy_workqueue(fs_info->fixup_workers);
 	btrfs_destroy_workqueue(fs_info->delalloc_workers);
 	btrfs_destroy_workqueue(fs_info->workers);
 	btrfs_destroy_workqueue(fs_info->endio_workers);
@@ -2498,8 +2498,8 @@ int open_ctree(struct super_block *sb,
 				      min_t(u64, fs_devices->num_devices,
 					    max_active), 64);
 
-	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1,
-			   &fs_info->generic_worker);
+	fs_info->fixup_workers =
+		btrfs_alloc_workqueue("fixup", flags, 1, 0);
 
 	/*
 	 * endios are largely parallel and should have a very
@@ -2532,7 +2532,6 @@ int open_ctree(struct super_block *sb,
 	 * return -ENOMEM if any of these fail.
 	 */
 	ret = btrfs_start_workers(&fs_info->generic_worker);
-	ret |= btrfs_start_workers(&fs_info->fixup_workers);
 	ret |= btrfs_start_workers(&fs_info->delayed_workers);
 	ret |= btrfs_start_workers(&fs_info->qgroup_rescan_workers);
 	if (ret) {
@@ -2545,7 +2544,8 @@ int open_ctree(struct super_block *sb,
 	      fs_info->endio_meta_write_workers &&
 	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
-	      fs_info->caching_workers && fs_info->readahead_workers)) {
+	      fs_info->caching_workers && fs_info->readahead_workers &&
+	      fs_info->fixup_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit 736cfa15e89a654436d4149c109bf1ae09fc67cf
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:13 2014 +0800

    btrfs: Replace fs_info->readahead_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->readahead_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9c14e3bd078c..c0b003bb66cd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2008,7 +2008,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->submit_workers);
 	btrfs_stop_workers(&fs_info->delayed_workers);
 	btrfs_destroy_workqueue(fs_info->caching_workers);
-	btrfs_stop_workers(&fs_info->readahead_workers);
+	btrfs_destroy_workqueue(fs_info->readahead_workers);
 	btrfs_destroy_workqueue(fs_info->flush_workers);
 	btrfs_stop_workers(&fs_info->qgroup_rescan_workers);
 }
@@ -2522,14 +2522,11 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->delayed_workers, "delayed-meta",
 			   fs_info->thread_pool_size,
 			   &fs_info->generic_worker);
-	btrfs_init_workers(&fs_info->readahead_workers, "readahead",
-			   fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
+	fs_info->readahead_workers =
+		btrfs_alloc_workqueue("readahead", flags, max_active, 2);
 	btrfs_init_workers(&fs_info->qgroup_rescan_workers, "qgroup-rescan", 1,
 			   &fs_info->generic_worker);
 
-	fs_info->readahead_workers.idle_thresh = 2;
-
 	/*
 	 * btrfs_start_workers can really only fail because of ENOMEM so just
 	 * return -ENOMEM if any of these fail.
@@ -2537,7 +2534,6 @@ int open_ctree(struct super_block *sb,
 	ret = btrfs_start_workers(&fs_info->generic_worker);
 	ret |= btrfs_start_workers(&fs_info->fixup_workers);
 	ret |= btrfs_start_workers(&fs_info->delayed_workers);
-	ret |= btrfs_start_workers(&fs_info->readahead_workers);
 	ret |= btrfs_start_workers(&fs_info->qgroup_rescan_workers);
 	if (ret) {
 		err = -ENOMEM;
@@ -2549,7 +2545,7 @@ int open_ctree(struct super_block *sb,
 	      fs_info->endio_meta_write_workers &&
 	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
 	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
-	      fs_info->caching_workers)) {
+	      fs_info->caching_workers && fs_info->readahead_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit e66f0bb14465371d4c86fa70cff2acc331efa1fb
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:12 2014 +0800

    btrfs: Replace fs_info->cache_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->cache_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5f12806e96e8..9c14e3bd078c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2007,7 +2007,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->endio_freespace_worker);
 	btrfs_destroy_workqueue(fs_info->submit_workers);
 	btrfs_stop_workers(&fs_info->delayed_workers);
-	btrfs_stop_workers(&fs_info->caching_workers);
+	btrfs_destroy_workqueue(fs_info->caching_workers);
 	btrfs_stop_workers(&fs_info->readahead_workers);
 	btrfs_destroy_workqueue(fs_info->flush_workers);
 	btrfs_stop_workers(&fs_info->qgroup_rescan_workers);
@@ -2485,8 +2485,8 @@ int open_ctree(struct super_block *sb,
 	fs_info->flush_workers =
 		btrfs_alloc_workqueue("flush_delalloc", flags, max_active, 0);
 
-	btrfs_init_workers(&fs_info->caching_workers, "cache",
-			   fs_info->thread_pool_size, NULL);
+	fs_info->caching_workers =
+		btrfs_alloc_workqueue("cache", flags, max_active, 0);
 
 	/*
 	 * a higher idle thresh on the submit workers makes it much more
@@ -2537,7 +2537,6 @@ int open_ctree(struct super_block *sb,
 	ret = btrfs_start_workers(&fs_info->generic_worker);
 	ret |= btrfs_start_workers(&fs_info->fixup_workers);
 	ret |= btrfs_start_workers(&fs_info->delayed_workers);
-	ret |= btrfs_start_workers(&fs_info->caching_workers);
 	ret |= btrfs_start_workers(&fs_info->readahead_workers);
 	ret |= btrfs_start_workers(&fs_info->qgroup_rescan_workers);
 	if (ret) {
@@ -2549,7 +2548,8 @@ int open_ctree(struct super_block *sb,
 	      fs_info->endio_workers && fs_info->endio_meta_workers &&
 	      fs_info->endio_meta_write_workers &&
 	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
-	      fs_info->endio_freespace_worker && fs_info->rmw_workers)) {
+	      fs_info->endio_freespace_worker && fs_info->rmw_workers &&
+	      fs_info->caching_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit d05a33ac265c62d4be35788dd978b2665033f077
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:11 2014 +0800

    btrfs: Replace fs_info->rmw_workers workqueue with btrfs_workqueue.
    
    Replace the fs_info->rmw_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8ce0214e3bac..5f12806e96e8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2001,7 +2001,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_destroy_workqueue(fs_info->endio_workers);
 	btrfs_destroy_workqueue(fs_info->endio_meta_workers);
 	btrfs_destroy_workqueue(fs_info->endio_raid56_workers);
-	btrfs_stop_workers(&fs_info->rmw_workers);
+	btrfs_destroy_workqueue(fs_info->rmw_workers);
 	btrfs_destroy_workqueue(fs_info->endio_meta_write_workers);
 	btrfs_destroy_workqueue(fs_info->endio_write_workers);
 	btrfs_destroy_workqueue(fs_info->endio_freespace_worker);
@@ -2513,9 +2513,8 @@ int open_ctree(struct super_block *sb,
 		btrfs_alloc_workqueue("endio-meta-write", flags, max_active, 2);
 	fs_info->endio_raid56_workers =
 		btrfs_alloc_workqueue("endio-raid56", flags, max_active, 4);
-	btrfs_init_workers(&fs_info->rmw_workers,
-			   "rmw", fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
+	fs_info->rmw_workers =
+		btrfs_alloc_workqueue("rmw", flags, max_active, 2);
 	fs_info->endio_write_workers =
 		btrfs_alloc_workqueue("endio-write", flags, max_active, 2);
 	fs_info->endio_freespace_worker =
@@ -2529,8 +2528,6 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->qgroup_rescan_workers, "qgroup-rescan", 1,
 			   &fs_info->generic_worker);
 
-	fs_info->rmw_workers.idle_thresh = 2;
-
 	fs_info->readahead_workers.idle_thresh = 2;
 
 	/*
@@ -2539,7 +2536,6 @@ int open_ctree(struct super_block *sb,
 	 */
 	ret = btrfs_start_workers(&fs_info->generic_worker);
 	ret |= btrfs_start_workers(&fs_info->fixup_workers);
-	ret |= btrfs_start_workers(&fs_info->rmw_workers);
 	ret |= btrfs_start_workers(&fs_info->delayed_workers);
 	ret |= btrfs_start_workers(&fs_info->caching_workers);
 	ret |= btrfs_start_workers(&fs_info->readahead_workers);
@@ -2553,7 +2549,7 @@ int open_ctree(struct super_block *sb,
 	      fs_info->endio_workers && fs_info->endio_meta_workers &&
 	      fs_info->endio_meta_write_workers &&
 	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
-	      fs_info->endio_freespace_worker)) {
+	      fs_info->endio_freespace_worker && fs_info->rmw_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit fccb5d86d8f52161e013025ccf3101d8fab99a32
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:10 2014 +0800

    btrfs: Replace fs_info->endio_* workqueue with btrfs_workqueue.
    
    Replace the fs_info->endio_* workqueues with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5b82b0b31ec8..8ce0214e3bac 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -55,7 +55,7 @@
 #endif
 
 static struct extent_io_ops btree_extent_io_ops;
-static void end_workqueue_fn(struct btrfs_work *work);
+static void end_workqueue_fn(struct btrfs_work_struct *work);
 static void free_fs_root(struct btrfs_root *root);
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 				    int read_only);
@@ -86,7 +86,7 @@ struct end_io_wq {
 	int error;
 	int metadata;
 	struct list_head list;
-	struct btrfs_work work;
+	struct btrfs_work_struct work;
 };
 
 /*
@@ -678,32 +678,31 @@ static void end_workqueue_bio(struct bio *bio, int err)
 
 	fs_info = end_io_wq->info;
 	end_io_wq->error = err;
-	end_io_wq->work.func = end_workqueue_fn;
-	end_io_wq->work.flags = 0;
+	btrfs_init_work(&end_io_wq->work, end_workqueue_fn, NULL, NULL);
 
 	if (bio->bi_rw & REQ_WRITE) {
 		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_METADATA)
-			btrfs_queue_worker(&fs_info->endio_meta_write_workers,
-					   &end_io_wq->work);
+			btrfs_queue_work(fs_info->endio_meta_write_workers,
+					 &end_io_wq->work);
 		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_FREE_SPACE)
-			btrfs_queue_worker(&fs_info->endio_freespace_worker,
-					   &end_io_wq->work);
+			btrfs_queue_work(fs_info->endio_freespace_worker,
+					 &end_io_wq->work);
 		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
-			btrfs_queue_worker(&fs_info->endio_raid56_workers,
-					   &end_io_wq->work);
+			btrfs_queue_work(fs_info->endio_raid56_workers,
+					 &end_io_wq->work);
 		else
-			btrfs_queue_worker(&fs_info->endio_write_workers,
-					   &end_io_wq->work);
+			btrfs_queue_work(fs_info->endio_write_workers,
+					 &end_io_wq->work);
 	} else {
 		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
-			btrfs_queue_worker(&fs_info->endio_raid56_workers,
-					   &end_io_wq->work);
+			btrfs_queue_work(fs_info->endio_raid56_workers,
+					 &end_io_wq->work);
 		else if (end_io_wq->metadata)
-			btrfs_queue_worker(&fs_info->endio_meta_workers,
-					   &end_io_wq->work);
+			btrfs_queue_work(fs_info->endio_meta_workers,
+					 &end_io_wq->work);
 		else
-			btrfs_queue_worker(&fs_info->endio_workers,
-					   &end_io_wq->work);
+			btrfs_queue_work(fs_info->endio_workers,
+					 &end_io_wq->work);
 	}
 }
 
@@ -1669,7 +1668,7 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
  * called by the kthread helper functions to finally call the bio end_io
  * functions.  This is where read checksum verification actually happens
  */
-static void end_workqueue_fn(struct btrfs_work *work)
+static void end_workqueue_fn(struct btrfs_work_struct *work)
 {
 	struct bio *bio;
 	struct end_io_wq *end_io_wq;
@@ -1999,13 +1998,13 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_destroy_workqueue(fs_info->delalloc_workers);
 	btrfs_destroy_workqueue(fs_info->workers);
-	btrfs_stop_workers(&fs_info->endio_workers);
-	btrfs_stop_workers(&fs_info->endio_meta_workers);
-	btrfs_stop_workers(&fs_info->endio_raid56_workers);
+	btrfs_destroy_workqueue(fs_info->endio_workers);
+	btrfs_destroy_workqueue(fs_info->endio_meta_workers);
+	btrfs_destroy_workqueue(fs_info->endio_raid56_workers);
 	btrfs_stop_workers(&fs_info->rmw_workers);
-	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
-	btrfs_stop_workers(&fs_info->endio_write_workers);
-	btrfs_stop_workers(&fs_info->endio_freespace_worker);
+	btrfs_destroy_workqueue(fs_info->endio_meta_write_workers);
+	btrfs_destroy_workqueue(fs_info->endio_write_workers);
+	btrfs_destroy_workqueue(fs_info->endio_freespace_worker);
 	btrfs_destroy_workqueue(fs_info->submit_workers);
 	btrfs_stop_workers(&fs_info->delayed_workers);
 	btrfs_stop_workers(&fs_info->caching_workers);
@@ -2501,26 +2500,26 @@ int open_ctree(struct super_block *sb,
 
 	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1,
 			   &fs_info->generic_worker);
-	btrfs_init_workers(&fs_info->endio_workers, "endio",
-			   fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
-	btrfs_init_workers(&fs_info->endio_meta_workers, "endio-meta",
-			   fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
-	btrfs_init_workers(&fs_info->endio_meta_write_workers,
-			   "endio-meta-write", fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
-	btrfs_init_workers(&fs_info->endio_raid56_workers,
-			   "endio-raid56", fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
+
+	/*
+	 * endios are largely parallel and should have a very
+	 * low idle thresh
+	 */
+	fs_info->endio_workers =
+		btrfs_alloc_workqueue("endio", flags, max_active, 4);
+	fs_info->endio_meta_workers =
+		btrfs_alloc_workqueue("endio-meta", flags, max_active, 4);
+	fs_info->endio_meta_write_workers =
+		btrfs_alloc_workqueue("endio-meta-write", flags, max_active, 2);
+	fs_info->endio_raid56_workers =
+		btrfs_alloc_workqueue("endio-raid56", flags, max_active, 4);
 	btrfs_init_workers(&fs_info->rmw_workers,
 			   "rmw", fs_info->thread_pool_size,
 			   &fs_info->generic_worker);
-	btrfs_init_workers(&fs_info->endio_write_workers, "endio-write",
-			   fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
-	btrfs_init_workers(&fs_info->endio_freespace_worker, "freespace-write",
-			   1, &fs_info->generic_worker);
+	fs_info->endio_write_workers =
+		btrfs_alloc_workqueue("endio-write", flags, max_active, 2);
+	fs_info->endio_freespace_worker =
+		btrfs_alloc_workqueue("freespace-write", flags, max_active, 0);
 	btrfs_init_workers(&fs_info->delayed_workers, "delayed-meta",
 			   fs_info->thread_pool_size,
 			   &fs_info->generic_worker);
@@ -2530,17 +2529,8 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->qgroup_rescan_workers, "qgroup-rescan", 1,
 			   &fs_info->generic_worker);
 
-	/*
-	 * endios are largely parallel and should have a very
-	 * low idle thresh
-	 */
-	fs_info->endio_workers.idle_thresh = 4;
-	fs_info->endio_meta_workers.idle_thresh = 4;
-	fs_info->endio_raid56_workers.idle_thresh = 4;
 	fs_info->rmw_workers.idle_thresh = 2;
 
-	fs_info->endio_write_workers.idle_thresh = 2;
-	fs_info->endio_meta_write_workers.idle_thresh = 2;
 	fs_info->readahead_workers.idle_thresh = 2;
 
 	/*
@@ -2549,13 +2539,7 @@ int open_ctree(struct super_block *sb,
 	 */
 	ret = btrfs_start_workers(&fs_info->generic_worker);
 	ret |= btrfs_start_workers(&fs_info->fixup_workers);
-	ret |= btrfs_start_workers(&fs_info->endio_workers);
-	ret |= btrfs_start_workers(&fs_info->endio_meta_workers);
 	ret |= btrfs_start_workers(&fs_info->rmw_workers);
-	ret |= btrfs_start_workers(&fs_info->endio_raid56_workers);
-	ret |= btrfs_start_workers(&fs_info->endio_meta_write_workers);
-	ret |= btrfs_start_workers(&fs_info->endio_write_workers);
-	ret |= btrfs_start_workers(&fs_info->endio_freespace_worker);
 	ret |= btrfs_start_workers(&fs_info->delayed_workers);
 	ret |= btrfs_start_workers(&fs_info->caching_workers);
 	ret |= btrfs_start_workers(&fs_info->readahead_workers);
@@ -2565,7 +2549,11 @@ int open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 	if (!(fs_info->workers && fs_info->delalloc_workers &&
-	      fs_info->submit_workers && fs_info->flush_workers)) {
+	      fs_info->submit_workers && fs_info->flush_workers &&
+	      fs_info->endio_workers && fs_info->endio_meta_workers &&
+	      fs_info->endio_meta_write_workers &&
+	      fs_info->endio_write_workers && fs_info->endio_raid56_workers &&
+	      fs_info->endio_freespace_worker)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit a44903abe9dc23ffa305898368a7a910dbae13c5
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:09 2014 +0800

    btrfs: Replace fs_info->flush_workers with btrfs_workqueue.
    
    Replace the fs_info->submit_workers with the newly created
    btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 420328bacf49..5b82b0b31ec8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2010,7 +2010,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_stop_workers(&fs_info->delayed_workers);
 	btrfs_stop_workers(&fs_info->caching_workers);
 	btrfs_stop_workers(&fs_info->readahead_workers);
-	btrfs_stop_workers(&fs_info->flush_workers);
+	btrfs_destroy_workqueue(fs_info->flush_workers);
 	btrfs_stop_workers(&fs_info->qgroup_rescan_workers);
 }
 
@@ -2483,9 +2483,8 @@ int open_ctree(struct super_block *sb,
 	fs_info->delalloc_workers =
 		btrfs_alloc_workqueue("delalloc", flags, max_active, 2);
 
-	btrfs_init_workers(&fs_info->flush_workers, "flush_delalloc",
-			   fs_info->thread_pool_size, NULL);
-
+	fs_info->flush_workers =
+		btrfs_alloc_workqueue("flush_delalloc", flags, max_active, 0);
 
 	btrfs_init_workers(&fs_info->caching_workers, "cache",
 			   fs_info->thread_pool_size, NULL);
@@ -2560,14 +2559,13 @@ int open_ctree(struct super_block *sb,
 	ret |= btrfs_start_workers(&fs_info->delayed_workers);
 	ret |= btrfs_start_workers(&fs_info->caching_workers);
 	ret |= btrfs_start_workers(&fs_info->readahead_workers);
-	ret |= btrfs_start_workers(&fs_info->flush_workers);
 	ret |= btrfs_start_workers(&fs_info->qgroup_rescan_workers);
 	if (ret) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}
 	if (!(fs_info->workers && fs_info->delalloc_workers &&
-	      fs_info->submit_workers)) {
+	      fs_info->submit_workers && fs_info->flush_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit a8c93d4ef6f6727764a61a2ee1c1878a755637c5
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:08 2014 +0800

    btrfs: Replace fs_info->submit_workers with btrfs_workqueue.
    
    Much like the fs_info->workers, replace the fs_info->submit_workers
    use the same btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7eeb45f649bf..420328bacf49 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2006,7 +2006,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->endio_freespace_worker);
-	btrfs_stop_workers(&fs_info->submit_workers);
+	btrfs_destroy_workqueue(fs_info->submit_workers);
 	btrfs_stop_workers(&fs_info->delayed_workers);
 	btrfs_stop_workers(&fs_info->caching_workers);
 	btrfs_stop_workers(&fs_info->readahead_workers);
@@ -2486,18 +2486,19 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->flush_workers, "flush_delalloc",
 			   fs_info->thread_pool_size, NULL);
 
-	btrfs_init_workers(&fs_info->submit_workers, "submit",
-			   min_t(u64, fs_devices->num_devices,
-			   fs_info->thread_pool_size), NULL);
 
 	btrfs_init_workers(&fs_info->caching_workers, "cache",
 			   fs_info->thread_pool_size, NULL);
 
-	/* a higher idle thresh on the submit workers makes it much more
+	/*
+	 * a higher idle thresh on the submit workers makes it much more
 	 * likely that bios will be send down in a sane order to the
 	 * devices
 	 */
-	fs_info->submit_workers.idle_thresh = 64;
+	fs_info->submit_workers =
+		btrfs_alloc_workqueue("submit", flags,
+				      min_t(u64, fs_devices->num_devices,
+					    max_active), 64);
 
 	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1,
 			   &fs_info->generic_worker);
@@ -2548,7 +2549,6 @@ int open_ctree(struct super_block *sb,
 	 * return -ENOMEM if any of these fail.
 	 */
 	ret = btrfs_start_workers(&fs_info->generic_worker);
-	ret |= btrfs_start_workers(&fs_info->submit_workers);
 	ret |= btrfs_start_workers(&fs_info->fixup_workers);
 	ret |= btrfs_start_workers(&fs_info->endio_workers);
 	ret |= btrfs_start_workers(&fs_info->endio_meta_workers);
@@ -2566,7 +2566,8 @@ int open_ctree(struct super_block *sb,
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}
-	if (!(fs_info->workers && fs_info->delalloc_workers)) {
+	if (!(fs_info->workers && fs_info->delalloc_workers &&
+	      fs_info->submit_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit afe3d24267926eb78ba863016bdd65cfe718aef5
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:07 2014 +0800

    btrfs: Replace fs_info->delalloc_workers with btrfs_workqueue
    
    Much like the fs_info->workers, replace the fs_info->delalloc_workers
    use the same btrfs_workqueue.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index faafa5153fbd..7eeb45f649bf 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1997,7 +1997,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 {
 	btrfs_stop_workers(&fs_info->generic_worker);
 	btrfs_stop_workers(&fs_info->fixup_workers);
-	btrfs_stop_workers(&fs_info->delalloc_workers);
+	btrfs_destroy_workqueue(fs_info->delalloc_workers);
 	btrfs_destroy_workqueue(fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_workers);
@@ -2480,8 +2480,8 @@ int open_ctree(struct super_block *sb,
 		btrfs_alloc_workqueue("worker", flags | WQ_HIGHPRI,
 				      max_active, 16);
 
-	btrfs_init_workers(&fs_info->delalloc_workers, "delalloc",
-			   fs_info->thread_pool_size, NULL);
+	fs_info->delalloc_workers =
+		btrfs_alloc_workqueue("delalloc", flags, max_active, 2);
 
 	btrfs_init_workers(&fs_info->flush_workers, "flush_delalloc",
 			   fs_info->thread_pool_size, NULL);
@@ -2499,9 +2499,6 @@ int open_ctree(struct super_block *sb,
 	 */
 	fs_info->submit_workers.idle_thresh = 64;
 
-	fs_info->delalloc_workers.idle_thresh = 2;
-	fs_info->delalloc_workers.ordered = 1;
-
 	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1,
 			   &fs_info->generic_worker);
 	btrfs_init_workers(&fs_info->endio_workers, "endio",
@@ -2552,7 +2549,6 @@ int open_ctree(struct super_block *sb,
 	 */
 	ret = btrfs_start_workers(&fs_info->generic_worker);
 	ret |= btrfs_start_workers(&fs_info->submit_workers);
-	ret |= btrfs_start_workers(&fs_info->delalloc_workers);
 	ret |= btrfs_start_workers(&fs_info->fixup_workers);
 	ret |= btrfs_start_workers(&fs_info->endio_workers);
 	ret |= btrfs_start_workers(&fs_info->endio_meta_workers);
@@ -2570,7 +2566,7 @@ int open_ctree(struct super_block *sb,
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}
-	if (!(fs_info->workers)) {
+	if (!(fs_info->workers && fs_info->delalloc_workers)) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}

commit 5cdc7ad337fb08f630ac3538fb10e4a75de2572d
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Feb 28 10:46:06 2014 +0800

    btrfs: Replace fs_info->workers with btrfs_workqueue.
    
    Use the newly created btrfs_workqueue_struct to replace the original
    fs_info->workers
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Tested-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dd52146035b3..faafa5153fbd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -108,7 +108,7 @@ struct async_submit_bio {
 	 * can't tell us where in the file the bio should go
 	 */
 	u64 bio_offset;
-	struct btrfs_work work;
+	struct btrfs_work_struct work;
 	int error;
 };
 
@@ -738,12 +738,12 @@ int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 unsigned long btrfs_async_submit_limit(struct btrfs_fs_info *info)
 {
 	unsigned long limit = min_t(unsigned long,
-				    info->workers.max_workers,
+				    info->thread_pool_size,
 				    info->fs_devices->open_devices);
 	return 256 * limit;
 }
 
-static void run_one_async_start(struct btrfs_work *work)
+static void run_one_async_start(struct btrfs_work_struct *work)
 {
 	struct async_submit_bio *async;
 	int ret;
@@ -756,7 +756,7 @@ static void run_one_async_start(struct btrfs_work *work)
 		async->error = ret;
 }
 
-static void run_one_async_done(struct btrfs_work *work)
+static void run_one_async_done(struct btrfs_work_struct *work)
 {
 	struct btrfs_fs_info *fs_info;
 	struct async_submit_bio *async;
@@ -783,7 +783,7 @@ static void run_one_async_done(struct btrfs_work *work)
 			       async->bio_offset);
 }
 
-static void run_one_async_free(struct btrfs_work *work)
+static void run_one_async_free(struct btrfs_work_struct *work)
 {
 	struct async_submit_bio *async;
 
@@ -811,11 +811,9 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->submit_bio_start = submit_bio_start;
 	async->submit_bio_done = submit_bio_done;
 
-	async->work.func = run_one_async_start;
-	async->work.ordered_func = run_one_async_done;
-	async->work.ordered_free = run_one_async_free;
+	btrfs_init_work(&async->work, run_one_async_start,
+			run_one_async_done, run_one_async_free);
 
-	async->work.flags = 0;
 	async->bio_flags = bio_flags;
 	async->bio_offset = bio_offset;
 
@@ -824,9 +822,9 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	atomic_inc(&fs_info->nr_async_submits);
 
 	if (rw & REQ_SYNC)
-		btrfs_set_work_high_prio(&async->work);
+		btrfs_set_work_high_priority(&async->work);
 
-	btrfs_queue_worker(&fs_info->workers, &async->work);
+	btrfs_queue_work(fs_info->workers, &async->work);
 
 	while (atomic_read(&fs_info->async_submit_draining) &&
 	      atomic_read(&fs_info->nr_async_submits)) {
@@ -2000,7 +1998,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_stop_workers(&fs_info->generic_worker);
 	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->delalloc_workers);
-	btrfs_stop_workers(&fs_info->workers);
+	btrfs_destroy_workqueue(fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_workers);
 	btrfs_stop_workers(&fs_info->endio_raid56_workers);
@@ -2104,6 +2102,8 @@ int open_ctree(struct super_block *sb,
 	int err = -EINVAL;
 	int num_backups_tried = 0;
 	int backup_index = 0;
+	int max_active;
+	int flags = WQ_MEM_RECLAIM | WQ_FREEZABLE | WQ_UNBOUND;
 	bool create_uuid_tree;
 	bool check_uuid_tree;
 
@@ -2472,12 +2472,13 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
+	max_active = fs_info->thread_pool_size;
 	btrfs_init_workers(&fs_info->generic_worker,
 			   "genwork", 1, NULL);
 
-	btrfs_init_workers(&fs_info->workers, "worker",
-			   fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
+	fs_info->workers =
+		btrfs_alloc_workqueue("worker", flags | WQ_HIGHPRI,
+				      max_active, 16);
 
 	btrfs_init_workers(&fs_info->delalloc_workers, "delalloc",
 			   fs_info->thread_pool_size, NULL);
@@ -2498,9 +2499,6 @@ int open_ctree(struct super_block *sb,
 	 */
 	fs_info->submit_workers.idle_thresh = 64;
 
-	fs_info->workers.idle_thresh = 16;
-	fs_info->workers.ordered = 1;
-
 	fs_info->delalloc_workers.idle_thresh = 2;
 	fs_info->delalloc_workers.ordered = 1;
 
@@ -2552,8 +2550,7 @@ int open_ctree(struct super_block *sb,
 	 * btrfs_start_workers can really only fail because of ENOMEM so just
 	 * return -ENOMEM if any of these fail.
 	 */
-	ret = btrfs_start_workers(&fs_info->workers);
-	ret |= btrfs_start_workers(&fs_info->generic_worker);
+	ret = btrfs_start_workers(&fs_info->generic_worker);
 	ret |= btrfs_start_workers(&fs_info->submit_workers);
 	ret |= btrfs_start_workers(&fs_info->delalloc_workers);
 	ret |= btrfs_start_workers(&fs_info->fixup_workers);
@@ -2573,6 +2570,10 @@ int open_ctree(struct super_block *sb,
 		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}
+	if (!(fs_info->workers)) {
+		err = -ENOMEM;
+		goto fail_sb_buffer;
+	}
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,

commit d1433debe7f4346cf9fc0dafc71c3137d2a97bc4
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Feb 20 18:08:59 2014 +0800

    Btrfs: just wait or commit our own log sub-transaction
    
    We might commit the log sub-transaction which didn't contain the metadata we
    logged. It was because we didn't record the log transid and just select
    the current log sub-transaction to commit, but the right one might be
    committed by the other task already. Actually, we needn't do anything
    and it is safe that we go back directly in this case.
    
    This patch improves the log sync by the above idea. We record the transid
    of the log sub-transaction in which we log the metadata, and the transid
    of the log sub-transaction we have committed. If the committed transid
    is >= the transid we record when logging the metadata, we just go back.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 44f52d280b7d..dd52146035b3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1209,6 +1209,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	atomic_set(&root->orphan_inodes, 0);
 	atomic_set(&root->refs, 1);
 	root->log_transid = 0;
+	root->log_transid_committed = -1;
 	root->last_log_commit = 0;
 	if (fs_info)
 		extent_io_tree_init(&root->dirty_log_pages,
@@ -1422,6 +1423,7 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	WARN_ON(root->log_root);
 	root->log_root = log_root;
 	root->log_transid = 0;
+	root->log_transid_committed = -1;
 	root->last_log_commit = 0;
 	return 0;
 }

commit 8b050d350c7846462a21e9e054c9154ede9b43cf
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Feb 20 18:08:58 2014 +0800

    Btrfs: fix skipped error handle when log sync failed
    
    It is possible that many tasks sync the log tree at the same time, but
    only one task can do the sync work, the others will wait for it. But those
    wait tasks didn't get the result of the log sync, and returned 0 when they
    ended the wait. It caused those tasks skipped the error handle, and the
    serious problem was they told the users the file sync succeeded but in
    fact they failed.
    
    This patch fixes this problem by introducing a log context structure,
    we insert it into the a global list. When the sync fails, we will set
    the error number of every log context in the list, then the waiting tasks
    get the error number of the log context and handle the error if need.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cc1b4237dc62..44f52d280b7d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1200,6 +1200,8 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	init_waitqueue_head(&root->log_writer_wait);
 	init_waitqueue_head(&root->log_commit_wait[0]);
 	init_waitqueue_head(&root->log_commit_wait[1]);
+	INIT_LIST_HEAD(&root->log_ctxs[0]);
+	INIT_LIST_HEAD(&root->log_ctxs[1]);
 	atomic_set(&root->log_commit[0], 0);
 	atomic_set(&root->log_commit[1], 0);
 	atomic_set(&root->log_writers, 0);

commit 2a85d9cac160bb5b845985a60007cc8348d77def
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Feb 10 17:07:16 2014 +0800

    Btrfs: fix possible deadlock in btrfs_cleanup_transaction
    
    [13654.480669] ======================================================
    [13654.480905] [ INFO: possible circular locking dependency detected ]
    [13654.481003] 3.12.0+ #4 Tainted: G        W  O
    [13654.481060] -------------------------------------------------------
    [13654.481060] btrfs-transacti/9347 is trying to acquire lock:
    [13654.481060]  (&(&root->ordered_extent_lock)->rlock){+.+...}, at: [<ffffffffa02d30a1>] btrfs_cleanup_transaction+0x271/0x570 [btrfs]
    [13654.481060] but task is already holding lock:
    [13654.481060]  (&(&fs_info->ordered_root_lock)->rlock){+.+...}, at: [<ffffffffa02d3015>] btrfs_cleanup_transaction+0x1e5/0x570 [btrfs]
    [13654.481060] which lock already depends on the new lock.
    
    [13654.481060] the existing dependency chain (in reverse order) is:
    [13654.481060] -> #1 (&(&fs_info->ordered_root_lock)->rlock){+.+...}:
    [13654.481060]        [<ffffffff810c4103>] lock_acquire+0x93/0x130
    [13654.481060]        [<ffffffff81689991>] _raw_spin_lock+0x41/0x50
    [13654.481060]        [<ffffffffa02f011b>] __btrfs_add_ordered_extent+0x39b/0x450 [btrfs]
    [13654.481060]        [<ffffffffa02f0202>] btrfs_add_ordered_extent+0x32/0x40 [btrfs]
    [13654.481060]        [<ffffffffa02df6aa>] run_delalloc_nocow+0x78a/0x9d0 [btrfs]
    [13654.481060]        [<ffffffffa02dfc0d>] run_delalloc_range+0x31d/0x390 [btrfs]
    [13654.481060]        [<ffffffffa02f7c00>] __extent_writepage+0x310/0x780 [btrfs]
    [13654.481060]        [<ffffffffa02f830a>] extent_write_cache_pages.isra.29.constprop.48+0x29a/0x410 [btrfs]
    [13654.481060]        [<ffffffffa02f879d>] extent_writepages+0x4d/0x70 [btrfs]
    [13654.481060]        [<ffffffffa02d9f68>] btrfs_writepages+0x28/0x30 [btrfs]
    [13654.481060]        [<ffffffff8114be91>] do_writepages+0x21/0x50
    [13654.481060]        [<ffffffff81140d49>] __filemap_fdatawrite_range+0x59/0x60
    [13654.481060]        [<ffffffff81140e13>] filemap_fdatawrite_range+0x13/0x20
    [13654.481060]        [<ffffffffa02f1db9>] btrfs_wait_ordered_range+0x49/0x140 [btrfs]
    [13654.481060]        [<ffffffffa0318fe2>] __btrfs_write_out_cache+0x682/0x8b0 [btrfs]
    [13654.481060]        [<ffffffffa031952d>] btrfs_write_out_cache+0x8d/0xe0 [btrfs]
    [13654.481060]        [<ffffffffa02c7083>] btrfs_write_dirty_block_groups+0x593/0x680 [btrfs]
    [13654.481060]        [<ffffffffa0345307>] commit_cowonly_roots+0x14b/0x20d [btrfs]
    [13654.481060]        [<ffffffffa02d7c1a>] btrfs_commit_transaction+0x43a/0x9d0 [btrfs]
    [13654.481060]        [<ffffffffa030061a>] btrfs_create_uuid_tree+0x5a/0x100 [btrfs]
    [13654.481060]        [<ffffffffa02d5a8a>] open_ctree+0x21da/0x2210 [btrfs]
    [13654.481060]        [<ffffffffa02ab6fe>] btrfs_mount+0x68e/0x870 [btrfs]
    [13654.481060]        [<ffffffff811b2409>] mount_fs+0x39/0x1b0
    [13654.481060]        [<ffffffff811cd653>] vfs_kern_mount+0x63/0xf0
    [13654.481060]        [<ffffffff811cfcce>] do_mount+0x23e/0xa90
    [13654.481060]        [<ffffffff811d05a3>] SyS_mount+0x83/0xc0
    [13654.481060]        [<ffffffff81692b52>] system_call_fastpath+0x16/0x1b
    [13654.481060] -> #0 (&(&root->ordered_extent_lock)->rlock){+.+...}:
    [13654.481060]        [<ffffffff810c340a>] __lock_acquire+0x150a/0x1a70
    [13654.481060]        [<ffffffff810c4103>] lock_acquire+0x93/0x130
    [13654.481060]        [<ffffffff81689991>] _raw_spin_lock+0x41/0x50
    [13654.481060]        [<ffffffffa02d30a1>] btrfs_cleanup_transaction+0x271/0x570 [btrfs]
    [13654.481060]        [<ffffffffa02d35ce>] transaction_kthread+0x22e/0x270 [btrfs]
    [13654.481060]        [<ffffffff81079efa>] kthread+0xea/0xf0
    [13654.481060]        [<ffffffff81692aac>] ret_from_fork+0x7c/0xb0
    [13654.481060] other info that might help us debug this:
    
    [13654.481060]  Possible unsafe locking scenario:
    
    [13654.481060]        CPU0                    CPU1
    [13654.481060]        ----                    ----
    [13654.481060]   lock(&(&fs_info->ordered_root_lock)->rlock);
    [13654.481060]                           lock(&(&root->ordered_extent_lock)->rlock);
    [13654.481060]                           lock(&(&fs_info->ordered_root_lock)->rlock);
    [13654.481060]   lock(&(&root->ordered_extent_lock)->rlock);
    [13654.481060]
     *** DEADLOCK ***
    [...]
    
    ======================================================
    
    btrfs_destroy_all_ordered_extents()
    gets &fs_info->ordered_root_lock __BEFORE__ acquiring &root->ordered_extent_lock,
    while btrfs_[add,remove]_ordered_extent()
    acquires &fs_info->ordered_root_lock __AFTER__ getting &root->ordered_extent_lock.
    
    This patch fixes the above problem.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 74c9be89fc0c..cc1b4237dc62 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3808,9 +3808,11 @@ static void btrfs_destroy_all_ordered_extents(struct btrfs_fs_info *fs_info)
 		list_move_tail(&root->ordered_root,
 			       &fs_info->ordered_roots);
 
+		spin_unlock(&fs_info->ordered_root_lock);
 		btrfs_destroy_ordered_extents(root);
 
-		cond_resched_lock(&fs_info->ordered_root_lock);
+		cond_resched();
+		spin_lock(&fs_info->ordered_root_lock);
 	}
 	spin_unlock(&fs_info->ordered_root_lock);
 }

commit f88ba6a2a44ee98e8d59654463dc157bb6d13c43
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Wed Feb 5 16:34:38 2014 +0900

    Btrfs: skip submitting barrier for missing device
    
    I got an error on v3.13:
     BTRFS error (device sdf1) in write_all_supers:3378: errno=-5 IO failure (errors while submitting device barriers.)
    
    how to reproduce:
      > mkfs.btrfs -f -d raid1 /dev/sdf1 /dev/sdf2
      > wipefs -a /dev/sdf2
      > mount -o degraded /dev/sdf1 /mnt
      > btrfs balance start -f -sconvert=single -mconvert=single -dconvert=single /mnt
    
    The reason of the error is that barrier_all_devices() failed to submit
    barrier to the missing device.  However it is clear that we cannot do
    anything on missing device, and also it is not necessary to care chunks
    on the missing device.
    
    This patch stops sending/waiting barrier if device is missing.
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0cafacb07b43..74c9be89fc0c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3256,6 +3256,8 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 	/* send down all the barriers */
 	head = &info->fs_devices->devices;
 	list_for_each_entry_rcu(dev, head, dev_list) {
+		if (dev->missing)
+			continue;
 		if (!dev->bdev) {
 			errors_send++;
 			continue;
@@ -3270,6 +3272,8 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 
 	/* wait for all the barriers */
 	list_for_each_entry_rcu(dev, head, dev_list) {
+		if (dev->missing)
+			continue;
 		if (!dev->bdev) {
 			errors_wait++;
 			continue;

commit c404e0dc2c843b154f9a36c3aec10d0a715d88eb
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jan 30 16:46:55 2014 +0800

    Btrfs: fix use-after-free in the finishing procedure of the device replace
    
    During device replace test, we hit a null pointer deference (It was very easy
    to reproduce it by running xfstests' btrfs/011 on the devices with the virtio
    scsi driver). There were two bugs that caused this problem:
    - We might allocate new chunks on the replaced device after we updated
      the mapping tree. And we forgot to replace the source device in those
      mapping of the new chunks.
    - We might get the mapping information which including the source device
      before the mapping information update. And then submit the bio which was
      based on that mapping information after we freed the source device.
    
    For the first bug, we can fix it by doing mapping tree update and source
    device remove in the same context of the chunk mutex. The chunk mutex is
    used to protect the allocable device list, the above method can avoid
    the new chunk allocation, and after we remove the source device, all
    the new chunks will be allocated on the new device. So it can fix
    the first bug.
    
    For the second bug, we need make sure all flighting bios are finished and
    no new bios are produced during we are removing the source device. To fix
    this problem, we introduced a global @bio_counter, we not only inc/dec
    @bio_counter outsize of map_blocks, but also inc it before submitting bio
    and dec @bio_counter when ending bios.
    
    Since Raid56 is a little different and device replace dosen't support raid56
    yet, it is not addressed in the patch and I add comments to make sure we will
    fix it in the future.
    
    Reported-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fcf367581073..0cafacb07b43 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2136,10 +2136,16 @@ int open_ctree(struct super_block *sb,
 		goto fail_dirty_metadata_bytes;
 	}
 
+	ret = percpu_counter_init(&fs_info->bio_counter, 0);
+	if (ret) {
+		err = ret;
+		goto fail_delalloc_bytes;
+	}
+
 	fs_info->btree_inode = new_inode(sb);
 	if (!fs_info->btree_inode) {
 		err = -ENOMEM;
-		goto fail_delalloc_bytes;
+		goto fail_bio_counter;
 	}
 
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
@@ -2214,6 +2220,7 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->scrub_pause_req, 0);
 	atomic_set(&fs_info->scrubs_paused, 0);
 	atomic_set(&fs_info->scrub_cancel_req, 0);
+	init_waitqueue_head(&fs_info->replace_wait);
 	init_waitqueue_head(&fs_info->scrub_pause_wait);
 	fs_info->scrub_workers_refcnt = 0;
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
@@ -2966,6 +2973,8 @@ int open_ctree(struct super_block *sb,
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
 	iput(fs_info->btree_inode);
+fail_bio_counter:
+	percpu_counter_destroy(&fs_info->bio_counter);
 fail_delalloc_bytes:
 	percpu_counter_destroy(&fs_info->delalloc_bytes);
 fail_dirty_metadata_bytes:
@@ -3613,6 +3622,7 @@ int close_ctree(struct btrfs_root *root)
 
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
 	percpu_counter_destroy(&fs_info->delalloc_bytes);
+	percpu_counter_destroy(&fs_info->bio_counter);
 	bdi_destroy(&fs_info->bdi);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 

commit 3962dfbe22a8d65e4162354cc859440293d85524
Merge: 4302a8750d6f 93de4ba86480
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Feb 16 11:05:27 2014 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "We have a small collection of fixes in my for-linus branch.
    
      The big thing that stands out is a revert of a new ioctl.  Users
      haven't shipped yet in btrfs-progs, and Dave Sterba found a better way
      to export the information"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: use right clone root offset for compressed extents
      btrfs: fix null pointer deference at btrfs_sysfs_add_one+0x105
      Btrfs: unset DCACHE_DISCONNECTED when mounting default subvol
      Btrfs: fix max_inline mount option
      Btrfs: fix a lockdep warning when cleaning up aborted transaction
      Revert "btrfs: add ioctl to export size of global metadata reservation"

commit a9d2d4adb6a87e515912a7033b227acbd9c8835e
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Sat Feb 8 15:33:08 2014 +0800

    Btrfs: fix a lockdep warning when cleaning up aborted transaction
    
    Given now we have 2 spinlock for management of delayed refs,
    CONFIG_DEBUG_SPINLOCK=y helped me find this,
    
    [ 4723.413809] BUG: spinlock wrong CPU on CPU#1, btrfs-transacti/2258
    [ 4723.414882]  lock: 0xffff880048377670, .magic: dead4ead, .owner: btrfs-transacti/2258, .owner_cpu: 2
    [ 4723.417146] CPU: 1 PID: 2258 Comm: btrfs-transacti Tainted: G        W  O 3.12.0+ #4
    [ 4723.421321] Call Trace:
    [ 4723.421872]  [<ffffffff81680fe7>] dump_stack+0x54/0x74
    [ 4723.422753]  [<ffffffff81681093>] spin_dump+0x8c/0x91
    [ 4723.424979]  [<ffffffff816810b9>] spin_bug+0x21/0x26
    [ 4723.425846]  [<ffffffff81323956>] do_raw_spin_unlock+0x66/0x90
    [ 4723.434424]  [<ffffffff81689bf7>] _raw_spin_unlock+0x27/0x40
    [ 4723.438747]  [<ffffffffa015da9e>] btrfs_cleanup_one_transaction+0x35e/0x710 [btrfs]
    [ 4723.443321]  [<ffffffffa015df54>] btrfs_cleanup_transaction+0x104/0x570 [btrfs]
    [ 4723.444692]  [<ffffffff810c1b5d>] ? trace_hardirqs_on_caller+0xfd/0x1c0
    [ 4723.450336]  [<ffffffff810c1c2d>] ? trace_hardirqs_on+0xd/0x10
    [ 4723.451332]  [<ffffffffa015e5ee>] transaction_kthread+0x22e/0x270 [btrfs]
    [ 4723.452543]  [<ffffffffa015e3c0>] ? btrfs_cleanup_transaction+0x570/0x570 [btrfs]
    [ 4723.457833]  [<ffffffff81079efa>] kthread+0xea/0xf0
    [ 4723.458990]  [<ffffffff81079e10>] ? kthread_create_on_node+0x140/0x140
    [ 4723.460133]  [<ffffffff81692aac>] ret_from_fork+0x7c/0xb0
    [ 4723.460865]  [<ffffffff81079e10>] ? kthread_create_on_node+0x140/0x140
    [ 4723.496521] ------------[ cut here ]------------
    
    ----------------------------------------------------------------------
    
    The reason is that we get to call cond_resched_lock(&head_ref->lock) while
    still holding @delayed_refs->lock.
    
    So it's different with __btrfs_run_delayed_refs(), where we do drop-acquire
    dance before and after actually processing delayed refs.
    
    Here we don't drop the lock, others are not able to add new delayed refs to
    head_ref, so cond_resched_lock(&head_ref->lock) is not necessary here.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3903bd3f8d2b..fcf367581073 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3842,7 +3842,6 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 			rb_erase(&ref->rb_node, &head->ref_root);
 			atomic_dec(&delayed_refs->num_entries);
 			btrfs_put_delayed_ref(ref);
-			cond_resched_lock(&head->lock);
 		}
 		if (head->must_insert_reserved)
 			pin_bytes = true;

commit 878a876b2e10888afe53766dcca33f723ae20edc
Merge: d7512f79fd6c 60efa5eb2e88
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 4 12:26:56 2014 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "Filipe is fixing compile and boot problems with our crc32c rework, and
      Josef has disabled snapshot aware defrag for now.
    
      As the number of snapshots increases, we're hitting OOM.  For the
      short term we're disabling things until a bigger fix is ready"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: use late_initcall instead of module_init
      Btrfs: use btrfs_crc32c everywhere instead of libcrc32c
      Btrfs: disable snapshot aware defrag for now

commit 0b947aff1599afbbd2ec07ada87b05af0f94cf10
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Wed Jan 29 21:06:04 2014 +0000

    Btrfs: use btrfs_crc32c everywhere instead of libcrc32c
    
    After the commit titled "Btrfs: fix btrfs boot when compiled as built-in",
    LIBCRC32C requirement was removed from btrfs' Kconfig. This made it not
    possible to build a kernel with btrfs enabled (either as module or built-in)
    if libcrc32c is not enabled as well. So just replace all uses of libcrc32c
    with the equivalent function in btrfs hash.h - btrfs_crc32c.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7619147da382..3903bd3f8d2b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -26,7 +26,6 @@
 #include <linux/workqueue.h>
 #include <linux/kthread.h>
 #include <linux/freezer.h>
-#include <linux/crc32c.h>
 #include <linux/slab.h>
 #include <linux/migrate.h>
 #include <linux/ratelimit.h>
@@ -35,6 +34,7 @@
 #include <asm/unaligned.h>
 #include "ctree.h"
 #include "disk-io.h"
+#include "hash.h"
 #include "transaction.h"
 #include "btrfs_inode.h"
 #include "volumes.h"
@@ -244,7 +244,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 
 u32 btrfs_csum_data(char *data, u32 seed, size_t len)
 {
-	return crc32c(seed, data, len);
+	return btrfs_crc32c(seed, data, len);
 }
 
 void btrfs_csum_final(u32 crc, char *result)

commit e7651b819e90da924991d727d3c007200a18670d
Merge: 060e8e3b6f8f cf93da7bcf45
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 30 20:08:20 2014 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This is a pretty big pull, and most of these changes have been
      floating in btrfs-next for a long time.  Filipe's properties work is a
      cool building block for inheriting attributes like compression down on
      a per inode basis.
    
      Jeff Mahoney kicked in code to export filesystem info into sysfs.
    
      Otherwise, lots of performance improvements, cleanups and bug fixes.
    
      Looks like there are still a few other small pending incrementals, but
      I wanted to get the bulk of this in first"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (149 commits)
      Btrfs: fix spin_unlock in check_ref_cleanup
      Btrfs: setup inode location during btrfs_init_inode_locked
      Btrfs: don't use ram_bytes for uncompressed inline items
      Btrfs: fix btrfs_search_slot_for_read backwards iteration
      Btrfs: do not export ulist functions
      Btrfs: rework ulist with list+rb_tree
      Btrfs: fix memory leaks on walking backrefs failure
      Btrfs: fix send file hole detection leading to data corruption
      Btrfs: add a reschedule point in btrfs_find_all_roots()
      Btrfs: make send's file extent item search more efficient
      Btrfs: fix to catch all errors when resolving indirect ref
      Btrfs: fix protection between walking backrefs and root deletion
      btrfs: fix warning while merging two adjacent extents
      Btrfs: fix infinite path build loops in incremental send
      btrfs: undo sysfs when open_ctree() fails
      Btrfs: fix snprintf usage by send's gen_unique_name
      btrfs: fix defrag 32-bit integer overflow
      btrfs: sysfs: list the NO_HOLES feature
      btrfs: sysfs: don't show reserved incompat feature
      btrfs: call permission checks earlier in ioctls and return EPERM
      ...

commit 2365dd3ca02bbb6d3412404482e1d85752549953
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Wed Jan 22 11:15:51 2014 +0800

    btrfs: undo sysfs when open_ctree() fails
    
    reproducer:
    mkfs.btrfs -f /dev/sdb &&\
    mount /dev/sdb /btrfs &&\
    btrfs dev add -f /dev/sdc /btrfs &&\
    umount /btrfs &&\
    wipefs -a /dev/sdc &&\
    mount -o degraded /dev/sdb /btrfs
    //above mount fails so try with RO
    mount -o degraded,ro /dev/sdb /btrfs
    
    ------
    sysfs: cannot create duplicate filename '/fs/btrfs/3f48c79e-5ed0-4e87-b189-86e749e503f4'
    ::
    
    dump_stack+0x49/0x5e
    warn_slowpath_common+0x87/0xb0
    warn_slowpath_fmt+0x41/0x50
    strlcat+0x69/0x80
    sysfs_warn_dup+0x87/0xa0
    sysfs_add_one+0x40/0x50
    create_dir+0x76/0xc0
    sysfs_create_dir_ns+0x7a/0xc0
    kobject_add_internal+0xad/0x220
    kobject_add_varg+0x38/0x60
    kobject_init_and_add+0x53/0x70
    mutex_lock+0x11/0x40
    __free_pages+0x25/0x30
    free_pages+0x41/0x50
    selinux_sb_copy_data+0x14e/0x1e0
    mount_fs+0x3e/0x1a0
    vfs_kern_mount+0x71/0x120
    do_mount+0x3f7/0x980
    SyS_mount+0x8b/0xe0
    system_call_fastpath+0x16/0x1b
    ------
    
    further 'modprobe -r btrfs' fails as well
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 47c2bc21caad..7619147da382 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2745,13 +2745,13 @@ int open_ctree(struct super_block *sb,
 	ret = btrfs_init_space_info(fs_info);
 	if (ret) {
 		printk(KERN_ERR "BTRFS: Failed to initial space info: %d\n", ret);
-		goto fail_block_groups;
+		goto fail_sysfs;
 	}
 
 	ret = btrfs_read_block_groups(extent_root);
 	if (ret) {
 		printk(KERN_ERR "BTRFS: Failed to read block groups: %d\n", ret);
-		goto fail_block_groups;
+		goto fail_sysfs;
 	}
 	fs_info->num_tolerated_disk_barrier_failures =
 		btrfs_calc_num_tolerated_disk_barrier_failures(fs_info);
@@ -2760,13 +2760,13 @@ int open_ctree(struct super_block *sb,
 	    !(sb->s_flags & MS_RDONLY)) {
 		printk(KERN_WARNING "BTRFS: "
 			"too many missing devices, writeable mount is not allowed\n");
-		goto fail_block_groups;
+		goto fail_sysfs;
 	}
 
 	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
 					       "btrfs-cleaner");
 	if (IS_ERR(fs_info->cleaner_kthread))
-		goto fail_block_groups;
+		goto fail_sysfs;
 
 	fs_info->transaction_kthread = kthread_run(transaction_kthread,
 						   tree_root,
@@ -2948,6 +2948,9 @@ int open_ctree(struct super_block *sb,
 	 */
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
 
+fail_sysfs:
+	btrfs_sysfs_remove_one(fs_info);
+
 fail_block_groups:
 	btrfs_put_block_group_cache(fs_info);
 	btrfs_free_block_groups(fs_info);

commit 1a4319cc3c495d5b6b8e41f4d4c73b950d54c2be
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Jan 13 19:53:53 2014 +0800

    Btrfs: fix extent state leak on transaction abortion
    
    When transaction is aborted, we fail to commit transaction, instead we do
    cleanup work.  After that when we umount btrfs, we get to free fs roots' log
    trees respectively, but that happens after we unpin extents, so those extents
    pinned by freeing log trees will remain in memory and lead to the leak.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4f142c986544..47c2bc21caad 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2065,6 +2065,12 @@ static void del_fs_roots(struct btrfs_fs_info *fs_info)
 		for (i = 0; i < ret; i++)
 			btrfs_drop_and_free_fs_root(fs_info, gang[i]);
 	}
+
+	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state)) {
+		btrfs_free_log_root_tree(NULL, fs_info);
+		btrfs_destroy_pinned_extent(fs_info->tree_root,
+					    fs_info->pinned_extents);
+	}
 }
 
 int open_ctree(struct super_block *sb,
@@ -3455,10 +3461,8 @@ void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
 	if (btrfs_root_refs(&root->root_item) == 0)
 		synchronize_srcu(&fs_info->subvol_srcu);
 
-	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state)) {
+	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
 		btrfs_free_log(NULL, root);
-		btrfs_free_log_root_tree(NULL, fs_info);
-	}
 
 	__btrfs_remove_free_space_cache(root->free_ino_pinned);
 	__btrfs_remove_free_space_cache(root->free_ino_ctl);
@@ -3569,8 +3573,6 @@ int close_ctree(struct btrfs_root *root)
 	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
 		btrfs_error_commit_super(root);
 
-	btrfs_put_block_group_cache(fs_info);
-
 	kthread_stop(fs_info->transaction_kthread);
 	kthread_stop(fs_info->cleaner_kthread);
 
@@ -3588,6 +3590,8 @@ int close_ctree(struct btrfs_root *root)
 
 	del_fs_roots(fs_info);
 
+	btrfs_put_block_group_cache(fs_info);
+
 	btrfs_free_block_groups(fs_info);
 
 	btrfs_stop_all_workers(fs_info);

commit 3818aea275423236db38a2d2d0a4951bc6da2e01
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Jan 13 13:36:06 2014 +0800

    btrfs: Add noinode_cache mount option
    
    Add noinode_cache mount option for btrfs.
    
    Since inode map cache involves all the btrfs_find_free_ino/return_ino
    things and if just trigger the mount_opt,
    an inode number get from inode map cache will not returned to inode map
    cache.
    
    To keep the find and return inode both in the same behavior,
    a new bit in mount_opt, CHANGE_INODE_CACHE, is introduced for this idea.
    CHANGE_INODE_CACHE is set/cleared in remounting, and the original
    INODE_MAP_CACHE is set/cleared according to CHANGE_INODE_CACHE after a
    success transaction.
    Since find/return inode is all done between btrfs_start_transaction and
    btrfs_commit_transaction, this will keep consistent behavior.
    
    Also noinode_cache mount option will not stop the caching_kthread.
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f0e7bbe14823..4f142c986544 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2776,6 +2776,10 @@ int open_ctree(struct super_block *sb,
 		btrfs_set_opt(fs_info->mount_opt, SSD);
 	}
 
+	/* Set the real inode map cache flag */
+	if (btrfs_test_opt(tree_root, CHANGE_INODE_CACHE))
+		btrfs_set_opt(tree_root->fs_info->mount_opt, INODE_MAP_CACHE);
+
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_test_opt(tree_root, CHECK_INTEGRITY)) {
 		ret = btrfsic_mount(tree_root, fs_devices,

commit 0a2b2a844af616addc87cac3cc18dcaba2a9d0fb
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Jan 23 10:54:11 2014 -0500

    Btrfs: throttle delayed refs better
    
    On one of our gluster clusters we noticed some pretty big lag spikes.  This
    turned out to be because our transaction commit was taking like 3 minutes to
    complete.  This is because we have like 30 gigs of metadata, so our global
    reserve would end up being the max which is like 512 mb.  So our throttling code
    would allow a ridiculous amount of delayed refs to build up and then they'd all
    get run at transaction commit time, and for a cold mounted file system that
    could take up to 3 minutes to run.  So fix the throttling to be based on both
    the size of the global reserve and how long it takes us to run delayed refs.
    This patch tracks the time it takes to run delayed refs and then only allows 1
    seconds worth of outstanding delayed refs at a time.  This way it will auto-tune
    itself from cold cache up to when everything is in memory and it no longer has
    to go to disk.  This makes our transaction commits take much less time to run.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ed23127a4b02..f0e7bbe14823 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2185,7 +2185,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->free_chunk_space = 0;
 	fs_info->tree_mod_log = RB_ROOT;
 	fs_info->commit_interval = BTRFS_DEFAULT_COMMIT_INTERVAL;
-
+	fs_info->avg_delayed_ref_runtime = div64_u64(NSEC_PER_SEC, 64);
 	/* readahead state */
 	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_WAIT);
 	spin_lock_init(&fs_info->reada_lock);

commit d7df2c796d7eedd72a334dc89c65e1fec8171431
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Jan 23 09:21:38 2014 -0500

    Btrfs: attach delayed ref updates to delayed ref heads
    
    Currently we have two rb-trees, one for delayed ref heads and one for all of the
    delayed refs, including the delayed ref heads.  When we process the delayed refs
    we have to hold onto the delayed ref lock for all of the selecting and merging
    and such, which results in quite a bit of lock contention.  This was solved by
    having a waitqueue and only one flusher at a time, however this hurts if we get
    a lot of delayed refs queued up.
    
    So instead just have an rb tree for the delayed ref heads, and then attach the
    delayed ref updates to an rb tree that is per delayed ref head.  Then we only
    need to take the delayed ref lock when adding new delayed refs and when
    selecting a delayed ref head to process, all the rest of the time we deal with a
    per delayed ref head lock which will be much less contentious.
    
    The locking rules for this get a little more complicated since we have to lock
    up to 3 things to properly process delayed refs, but I will address that problem
    later.  For now this passes all of xfstests and my overnight stress tests.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9850a51a3f19..ed23127a4b02 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3801,58 +3801,55 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 	delayed_refs = &trans->delayed_refs;
 
 	spin_lock(&delayed_refs->lock);
-	if (delayed_refs->num_entries == 0) {
+	if (atomic_read(&delayed_refs->num_entries) == 0) {
 		spin_unlock(&delayed_refs->lock);
 		btrfs_info(root->fs_info, "delayed_refs has NO entry");
 		return ret;
 	}
 
-	while ((node = rb_first(&delayed_refs->root)) != NULL) {
-		struct btrfs_delayed_ref_head *head = NULL;
+	while ((node = rb_first(&delayed_refs->href_root)) != NULL) {
+		struct btrfs_delayed_ref_head *head;
 		bool pin_bytes = false;
 
-		ref = rb_entry(node, struct btrfs_delayed_ref_node, rb_node);
-		atomic_set(&ref->refs, 1);
-		if (btrfs_delayed_ref_is_head(ref)) {
+		head = rb_entry(node, struct btrfs_delayed_ref_head,
+				href_node);
+		if (!mutex_trylock(&head->mutex)) {
+			atomic_inc(&head->node.refs);
+			spin_unlock(&delayed_refs->lock);
 
-			head = btrfs_delayed_node_to_head(ref);
-			if (!mutex_trylock(&head->mutex)) {
-				atomic_inc(&ref->refs);
-				spin_unlock(&delayed_refs->lock);
-
-				/* Need to wait for the delayed ref to run */
-				mutex_lock(&head->mutex);
-				mutex_unlock(&head->mutex);
-				btrfs_put_delayed_ref(ref);
-
-				spin_lock(&delayed_refs->lock);
-				continue;
-			}
-
-			if (head->must_insert_reserved)
-				pin_bytes = true;
-			btrfs_free_delayed_extent_op(head->extent_op);
-			delayed_refs->num_heads--;
-			if (list_empty(&head->cluster))
-				delayed_refs->num_heads_ready--;
-			list_del_init(&head->cluster);
-		}
-
-		ref->in_tree = 0;
-		rb_erase(&ref->rb_node, &delayed_refs->root);
-		if (head)
-			rb_erase(&head->href_node, &delayed_refs->href_root);
-
-		delayed_refs->num_entries--;
-		spin_unlock(&delayed_refs->lock);
-		if (head) {
-			if (pin_bytes)
-				btrfs_pin_extent(root, ref->bytenr,
-						 ref->num_bytes, 1);
+			mutex_lock(&head->mutex);
 			mutex_unlock(&head->mutex);
+			btrfs_put_delayed_ref(&head->node);
+			spin_lock(&delayed_refs->lock);
+			continue;
+		}
+		spin_lock(&head->lock);
+		while ((node = rb_first(&head->ref_root)) != NULL) {
+			ref = rb_entry(node, struct btrfs_delayed_ref_node,
+				       rb_node);
+			ref->in_tree = 0;
+			rb_erase(&ref->rb_node, &head->ref_root);
+			atomic_dec(&delayed_refs->num_entries);
+			btrfs_put_delayed_ref(ref);
+			cond_resched_lock(&head->lock);
 		}
-		btrfs_put_delayed_ref(ref);
+		if (head->must_insert_reserved)
+			pin_bytes = true;
+		btrfs_free_delayed_extent_op(head->extent_op);
+		delayed_refs->num_heads--;
+		if (head->processing == 0)
+			delayed_refs->num_heads_ready--;
+		atomic_dec(&delayed_refs->num_entries);
+		head->node.in_tree = 0;
+		rb_erase(&head->href_node, &delayed_refs->href_root);
+		spin_unlock(&head->lock);
+		spin_unlock(&delayed_refs->lock);
+		mutex_unlock(&head->mutex);
 
+		if (pin_bytes)
+			btrfs_pin_extent(root, head->node.bytenr,
+					 head->node.num_bytes, 1);
+		btrfs_put_delayed_ref(&head->node);
 		cond_resched();
 		spin_lock(&delayed_refs->lock);
 	}

commit e8117c26b24098496b6011aabe84e43e0189a506
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Fri Jan 3 18:22:57 2014 +0800

    Btrfs: only fua the first superblock when writting supers
    
    We only intent to fua the first superblock in every device from
    comments, fix it.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0400a26fc8c5..9850a51a3f19 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3133,7 +3133,10 @@ static int write_dev_supers(struct btrfs_device *device,
 		 * we fua the first super.  The others we allow
 		 * to go down lazy.
 		 */
-		ret = btrfsic_submit_bh(WRITE_FUA, bh);
+		if (i == 0)
+			ret = btrfsic_submit_bh(WRITE_FUA, bh);
+		else
+			ret = btrfsic_submit_bh(WRITE_SYNC, bh);
 		if (ret)
 			errors++;
 	}

commit efe120a067c8674a8ae21b194f0e68f098b61ee2
Author: Frank Holton <fholton@gmail.com>
Date:   Fri Dec 20 11:37:06 2013 -0500

    Btrfs: convert printk to btrfs_ and fix BTRFS prefix
    
    Convert all applicable cases of printk and pr_* to the btrfs_* macros.
    
    Fix all uses of the BTRFS prefix.
    
    Signed-off-by: Frank Holton <fholton@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4a1871cf797b..0400a26fc8c5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -300,11 +300,11 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			memcpy(&found, result, csum_size);
 
 			read_extent_buffer(buf, &val, 0, csum_size);
-			printk_ratelimited(KERN_INFO "btrfs: %s checksum verify "
-				       "failed on %llu wanted %X found %X "
-				       "level %d\n",
-				       root->fs_info->sb->s_id, buf->start,
-				       val, found, btrfs_header_level(buf));
+			printk_ratelimited(KERN_INFO
+				"BTRFS: %s checksum verify failed on %llu wanted %X found %X "
+				"level %d\n",
+				root->fs_info->sb->s_id, buf->start,
+				val, found, btrfs_header_level(buf));
 			if (result != (char *)&inline_result)
 				kfree(result);
 			return 1;
@@ -383,13 +383,14 @@ static int btrfs_check_super_csum(char *raw_disk_sb)
 			ret = 1;
 
 		if (ret && btrfs_super_generation(disk_sb) < 10) {
-			printk(KERN_WARNING "btrfs: super block crcs don't match, older mkfs detected\n");
+			printk(KERN_WARNING
+				"BTRFS: super block crcs don't match, older mkfs detected\n");
 			ret = 0;
 		}
 	}
 
 	if (csum_type >= ARRAY_SIZE(btrfs_csum_sizes)) {
-		printk(KERN_ERR "btrfs: unsupported checksum algorithm %u\n",
+		printk(KERN_ERR "BTRFS: unsupported checksum algorithm %u\n",
 				csum_type);
 		ret = 1;
 	}
@@ -498,8 +499,8 @@ static int check_tree_block_fsid(struct btrfs_root *root,
 }
 
 #define CORRUPT(reason, eb, root, slot)				\
-	printk(KERN_CRIT "btrfs: corrupt leaf, %s: block=%llu,"	\
-	       "root=%llu, slot=%d\n", reason,			\
+	btrfs_crit(root->fs_info, "corrupt leaf, %s: block=%llu,"	\
+		   "root=%llu, slot=%d", reason,			\
 	       btrfs_header_bytenr(eb),	root->objectid, slot)
 
 static noinline int check_leaf(struct btrfs_root *root,
@@ -596,21 +597,21 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != eb->start) {
-		printk_ratelimited(KERN_INFO "btrfs bad tree block start "
+		printk_ratelimited(KERN_INFO "BTRFS: bad tree block start "
 			       "%llu %llu\n",
 			       found_start, eb->start);
 		ret = -EIO;
 		goto err;
 	}
 	if (check_tree_block_fsid(root, eb)) {
-		printk_ratelimited(KERN_INFO "btrfs bad fsid on block %llu\n",
+		printk_ratelimited(KERN_INFO "BTRFS: bad fsid on block %llu\n",
 			       eb->start);
 		ret = -EIO;
 		goto err;
 	}
 	found_level = btrfs_header_level(eb);
 	if (found_level >= BTRFS_MAX_LEVEL) {
-		btrfs_info(root->fs_info, "bad tree block level %d\n",
+		btrfs_info(root->fs_info, "bad tree block level %d",
 			   (int)btrfs_header_level(eb));
 		ret = -EIO;
 		goto err;
@@ -1004,8 +1005,9 @@ static void btree_invalidatepage(struct page *page, unsigned int offset,
 	extent_invalidatepage(tree, page, offset);
 	btree_releasepage(page, GFP_NOFS);
 	if (PagePrivate(page)) {
-		printk(KERN_WARNING "btrfs warning page private not zero "
-		       "on page %llu\n", (unsigned long long)page_offset(page));
+		btrfs_warn(BTRFS_I(page->mapping->host)->root->fs_info,
+			   "page private not zero on page %llu",
+			   (unsigned long long)page_offset(page));
 		ClearPagePrivate(page);
 		set_page_private(page, 0);
 		page_cache_release(page);
@@ -2322,7 +2324,7 @@ int open_ctree(struct super_block *sb,
 	 * Pass the whole disk block of size BTRFS_SUPER_INFO_SIZE (4k).
 	 */
 	if (btrfs_check_super_csum(bh->b_data)) {
-		printk(KERN_ERR "btrfs: superblock checksum mismatch\n");
+		printk(KERN_ERR "BTRFS: superblock checksum mismatch\n");
 		err = -EINVAL;
 		goto fail_alloc;
 	}
@@ -2341,7 +2343,7 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
 	if (ret) {
-		printk(KERN_ERR "btrfs: superblock contains fatal errors\n");
+		printk(KERN_ERR "BTRFS: superblock contains fatal errors\n");
 		err = -EINVAL;
 		goto fail_alloc;
 	}
@@ -2406,7 +2408,7 @@ int open_ctree(struct super_block *sb,
 		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;
 
 	if (features & BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA)
-		printk(KERN_ERR "btrfs: has skinny extents\n");
+		printk(KERN_ERR "BTRFS: has skinny extents\n");
 
 	/*
 	 * flag our filesystem as having big metadata blocks if
@@ -2414,7 +2416,7 @@ int open_ctree(struct super_block *sb,
 	 */
 	if (btrfs_super_leafsize(disk_super) > PAGE_CACHE_SIZE) {
 		if (!(features & BTRFS_FEATURE_INCOMPAT_BIG_METADATA))
-			printk(KERN_INFO "btrfs flagging fs with big metadata feature\n");
+			printk(KERN_INFO "BTRFS: flagging fs with big metadata feature\n");
 		features |= BTRFS_FEATURE_INCOMPAT_BIG_METADATA;
 	}
 
@@ -2431,7 +2433,7 @@ int open_ctree(struct super_block *sb,
 	 */
 	if ((features & BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS) &&
 	    (sectorsize != leafsize)) {
-		printk(KERN_WARNING "btrfs: unequal leaf/node/sector sizes "
+		printk(KERN_WARNING "BTRFS: unequal leaf/node/sector sizes "
 				"are not allowed for mixed block groups on %s\n",
 				sb->s_id);
 		goto fail_alloc;
@@ -2568,12 +2570,12 @@ int open_ctree(struct super_block *sb,
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
 
 	if (btrfs_super_magic(disk_super) != BTRFS_MAGIC) {
-		printk(KERN_INFO "btrfs: valid FS not found on %s\n", sb->s_id);
+		printk(KERN_INFO "BTRFS: valid FS not found on %s\n", sb->s_id);
 		goto fail_sb_buffer;
 	}
 
 	if (sectorsize != PAGE_SIZE) {
-		printk(KERN_WARNING "btrfs: Incompatible sector size(%lu) "
+		printk(KERN_WARNING "BTRFS: Incompatible sector size(%lu) "
 		       "found on %s\n", (unsigned long)sectorsize, sb->s_id);
 		goto fail_sb_buffer;
 	}
@@ -2582,7 +2584,7 @@ int open_ctree(struct super_block *sb,
 	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
-		printk(KERN_WARNING "btrfs: failed to read the system "
+		printk(KERN_WARNING "BTRFS: failed to read the system "
 		       "array on %s\n", sb->s_id);
 		goto fail_sb_buffer;
 	}
@@ -2599,7 +2601,7 @@ int open_ctree(struct super_block *sb,
 					   blocksize, generation);
 	if (!chunk_root->node ||
 	    !test_bit(EXTENT_BUFFER_UPTODATE, &chunk_root->node->bflags)) {
-		printk(KERN_WARNING "btrfs: failed to read chunk root on %s\n",
+		printk(KERN_WARNING "BTRFS: failed to read chunk root on %s\n",
 		       sb->s_id);
 		goto fail_tree_roots;
 	}
@@ -2611,7 +2613,7 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_read_chunk_tree(chunk_root);
 	if (ret) {
-		printk(KERN_WARNING "btrfs: failed to read chunk tree on %s\n",
+		printk(KERN_WARNING "BTRFS: failed to read chunk tree on %s\n",
 		       sb->s_id);
 		goto fail_tree_roots;
 	}
@@ -2623,7 +2625,7 @@ int open_ctree(struct super_block *sb,
 	btrfs_close_extra_devices(fs_info, fs_devices, 0);
 
 	if (!fs_devices->latest_bdev) {
-		printk(KERN_CRIT "btrfs: failed to read devices on %s\n",
+		printk(KERN_CRIT "BTRFS: failed to read devices on %s\n",
 		       sb->s_id);
 		goto fail_tree_roots;
 	}
@@ -2638,7 +2640,7 @@ int open_ctree(struct super_block *sb,
 					  blocksize, generation);
 	if (!tree_root->node ||
 	    !test_bit(EXTENT_BUFFER_UPTODATE, &tree_root->node->bflags)) {
-		printk(KERN_WARNING "btrfs: failed to read tree root on %s\n",
+		printk(KERN_WARNING "BTRFS: failed to read tree root on %s\n",
 		       sb->s_id);
 
 		goto recovery_tree_root;
@@ -2709,20 +2711,20 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_recover_balance(fs_info);
 	if (ret) {
-		printk(KERN_WARNING "btrfs: failed to recover balance\n");
+		printk(KERN_WARNING "BTRFS: failed to recover balance\n");
 		goto fail_block_groups;
 	}
 
 	ret = btrfs_init_dev_stats(fs_info);
 	if (ret) {
-		printk(KERN_ERR "btrfs: failed to init dev_stats: %d\n",
+		printk(KERN_ERR "BTRFS: failed to init dev_stats: %d\n",
 		       ret);
 		goto fail_block_groups;
 	}
 
 	ret = btrfs_init_dev_replace(fs_info);
 	if (ret) {
-		pr_err("btrfs: failed to init dev_replace: %d\n", ret);
+		pr_err("BTRFS: failed to init dev_replace: %d\n", ret);
 		goto fail_block_groups;
 	}
 
@@ -2730,19 +2732,19 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_sysfs_add_one(fs_info);
 	if (ret) {
-		pr_err("btrfs: failed to init sysfs interface: %d\n", ret);
+		pr_err("BTRFS: failed to init sysfs interface: %d\n", ret);
 		goto fail_block_groups;
 	}
 
 	ret = btrfs_init_space_info(fs_info);
 	if (ret) {
-		printk(KERN_ERR "Failed to initial space info: %d\n", ret);
+		printk(KERN_ERR "BTRFS: Failed to initial space info: %d\n", ret);
 		goto fail_block_groups;
 	}
 
 	ret = btrfs_read_block_groups(extent_root);
 	if (ret) {
-		printk(KERN_ERR "Failed to read block groups: %d\n", ret);
+		printk(KERN_ERR "BTRFS: Failed to read block groups: %d\n", ret);
 		goto fail_block_groups;
 	}
 	fs_info->num_tolerated_disk_barrier_failures =
@@ -2750,8 +2752,8 @@ int open_ctree(struct super_block *sb,
 	if (fs_info->fs_devices->missing_devices >
 	     fs_info->num_tolerated_disk_barrier_failures &&
 	    !(sb->s_flags & MS_RDONLY)) {
-		printk(KERN_WARNING
-		       "Btrfs: too many missing devices, writeable mount is not allowed\n");
+		printk(KERN_WARNING "BTRFS: "
+			"too many missing devices, writeable mount is not allowed\n");
 		goto fail_block_groups;
 	}
 
@@ -2769,7 +2771,7 @@ int open_ctree(struct super_block *sb,
 	if (!btrfs_test_opt(tree_root, SSD) &&
 	    !btrfs_test_opt(tree_root, NOSSD) &&
 	    !fs_info->fs_devices->rotating) {
-		printk(KERN_INFO "Btrfs detected SSD devices, enabling SSD "
+		printk(KERN_INFO "BTRFS: detected SSD devices, enabling SSD "
 		       "mode\n");
 		btrfs_set_opt(fs_info->mount_opt, SSD);
 	}
@@ -2782,7 +2784,7 @@ int open_ctree(struct super_block *sb,
 				    1 : 0,
 				    fs_info->check_integrity_print_mask);
 		if (ret)
-			printk(KERN_WARNING "btrfs: failed to initialize"
+			printk(KERN_WARNING "BTRFS: failed to initialize"
 			       " integrity check module %s\n", sb->s_id);
 	}
 #endif
@@ -2795,7 +2797,7 @@ int open_ctree(struct super_block *sb,
 		u64 bytenr = btrfs_super_log_root(disk_super);
 
 		if (fs_devices->rw_devices == 0) {
-			printk(KERN_WARNING "Btrfs log replay required "
+			printk(KERN_WARNING "BTRFS: log replay required "
 			       "on RO media\n");
 			err = -EIO;
 			goto fail_qgroup;
@@ -2818,7 +2820,7 @@ int open_ctree(struct super_block *sb,
 						      generation + 1);
 		if (!log_tree_root->node ||
 		    !extent_buffer_uptodate(log_tree_root->node)) {
-			printk(KERN_ERR "btrfs: failed to read log tree\n");
+			printk(KERN_ERR "BTRFS: failed to read log tree\n");
 			free_extent_buffer(log_tree_root->node);
 			kfree(log_tree_root);
 			goto fail_trans_kthread;
@@ -2852,7 +2854,7 @@ int open_ctree(struct super_block *sb,
 		ret = btrfs_recover_relocation(tree_root);
 		if (ret < 0) {
 			printk(KERN_WARNING
-			       "btrfs: failed to recover relocation\n");
+			       "BTRFS: failed to recover relocation\n");
 			err = -EINVAL;
 			goto fail_qgroup;
 		}
@@ -2882,14 +2884,14 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_resume_balance_async(fs_info);
 	if (ret) {
-		printk(KERN_WARNING "btrfs: failed to resume balance\n");
+		printk(KERN_WARNING "BTRFS: failed to resume balance\n");
 		close_ctree(tree_root);
 		return ret;
 	}
 
 	ret = btrfs_resume_dev_replace_async(fs_info);
 	if (ret) {
-		pr_warn("btrfs: failed to resume dev_replace\n");
+		pr_warn("BTRFS: failed to resume dev_replace\n");
 		close_ctree(tree_root);
 		return ret;
 	}
@@ -2897,20 +2899,20 @@ int open_ctree(struct super_block *sb,
 	btrfs_qgroup_rescan_resume(fs_info);
 
 	if (create_uuid_tree) {
-		pr_info("btrfs: creating UUID tree\n");
+		pr_info("BTRFS: creating UUID tree\n");
 		ret = btrfs_create_uuid_tree(fs_info);
 		if (ret) {
-			pr_warn("btrfs: failed to create the UUID tree %d\n",
+			pr_warn("BTRFS: failed to create the UUID tree %d\n",
 				ret);
 			close_ctree(tree_root);
 			return ret;
 		}
 	} else if (check_uuid_tree ||
 		   btrfs_test_opt(tree_root, RESCAN_UUID_TREE)) {
-		pr_info("btrfs: checking UUID tree\n");
+		pr_info("BTRFS: checking UUID tree\n");
 		ret = btrfs_check_uuid_tree(fs_info);
 		if (ret) {
-			pr_warn("btrfs: failed to check the UUID tree %d\n",
+			pr_warn("BTRFS: failed to check the UUID tree %d\n",
 				ret);
 			close_ctree(tree_root);
 			return ret;
@@ -2991,7 +2993,7 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 		struct btrfs_device *device = (struct btrfs_device *)
 			bh->b_private;
 
-		printk_ratelimited_in_rcu(KERN_WARNING "lost page write due to "
+		printk_ratelimited_in_rcu(KERN_WARNING "BTRFS: lost page write due to "
 					  "I/O error on %s\n",
 					  rcu_str_deref(device->name));
 		/* note, we dont' set_buffer_write_io_error because we have
@@ -3110,7 +3112,7 @@ static int write_dev_supers(struct btrfs_device *device,
 			bh = __getblk(device->bdev, bytenr / 4096,
 				      BTRFS_SUPER_INFO_SIZE);
 			if (!bh) {
-				printk(KERN_ERR "btrfs: couldn't get super "
+				printk(KERN_ERR "BTRFS: couldn't get super "
 				       "buffer head for bytenr %Lu\n", bytenr);
 				errors++;
 				continue;
@@ -3177,7 +3179,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 		wait_for_completion(&device->flush_wait);
 
 		if (bio_flagged(bio, BIO_EOPNOTSUPP)) {
-			printk_in_rcu("btrfs: disabling barriers on dev %s\n",
+			printk_in_rcu("BTRFS: disabling barriers on dev %s\n",
 				      rcu_str_deref(device->name));
 			device->nobarriers = 1;
 		} else if (!bio_flagged(bio, BIO_UPTODATE)) {
@@ -3398,7 +3400,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 			total_errors++;
 	}
 	if (total_errors > max_errors) {
-		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
+		btrfs_err(root->fs_info, "%d errors while writing supers",
 		       total_errors);
 		mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
 
@@ -3554,7 +3556,7 @@ int close_ctree(struct btrfs_root *root)
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_commit_super(root);
 		if (ret)
-			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
+			btrfs_err(root->fs_info, "commit super ret %d", ret);
 	}
 
 	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
@@ -3571,7 +3573,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_free_qgroup_config(root->fs_info);
 
 	if (percpu_counter_sum(&fs_info->delalloc_bytes)) {
-		printk(KERN_INFO "btrfs: at unmount delalloc count %lld\n",
+		btrfs_info(root->fs_info, "at unmount delalloc count %lld",
 		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 
@@ -3798,7 +3800,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 	spin_lock(&delayed_refs->lock);
 	if (delayed_refs->num_entries == 0) {
 		spin_unlock(&delayed_refs->lock);
-		printk(KERN_INFO "delayed_refs has NO entry\n");
+		btrfs_info(root->fs_info, "delayed_refs has NO entry");
 		return ret;
 	}
 

commit f28491e0a6c46d99cbbef0f8ef7e314afa2359c8
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Dec 16 13:24:27 2013 -0500

    Btrfs: move the extent buffer radix tree into the fs_info
    
    I need to create a fake tree to test qgroups and I don't want to have to setup a
    fake btree_inode.  The fact is we only use the radix tree for the fs_info, so
    everybody else who allocates an extent_io_tree is just wasting the space anyway.
    This patch moves the radix tree and its lock into btrfs_fs_info so there is less
    stuff I have to fake to do qgroup sanity tests.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4ecee0a009cb..4a1871cf797b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1089,21 +1089,13 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr, u32 blocksize,
 struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize)
 {
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	struct extent_buffer *eb;
-	eb = find_extent_buffer(&BTRFS_I(btree_inode)->io_tree, bytenr);
-	return eb;
+	return find_extent_buffer(root->fs_info, bytenr);
 }
 
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 bytenr, u32 blocksize)
 {
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	struct extent_buffer *eb;
-
-	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
-				 bytenr, blocksize);
-	return eb;
+	return alloc_extent_buffer(root->fs_info, bytenr, blocksize);
 }
 
 
@@ -2145,6 +2137,7 @@ int open_ctree(struct super_block *sb,
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);
+	INIT_RADIX_TREE(&fs_info->buffer_radix, GFP_ATOMIC);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->delayed_iputs);
@@ -2158,6 +2151,7 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->free_chunk_lock);
 	spin_lock_init(&fs_info->tree_mod_seq_lock);
 	spin_lock_init(&fs_info->super_lock);
+	spin_lock_init(&fs_info->buffer_lock);
 	rwlock_init(&fs_info->tree_mod_log_lock);
 	mutex_init(&fs_info->reloc_mutex);
 	seqlock_init(&fs_info->profiles_lock);

commit 3f870c28990015a1fd6c67807efcdb02a75b35e1
Author: Kelley Nielsen <kelleynnn@gmail.com>
Date:   Mon Nov 4 19:37:39 2013 -0800

    btrfs: expand btrfs_find_item() to include find_orphan_item functionality
    
    This is the third step in bootstrapping the btrfs_find_item interface.
    The function find_orphan_item(), in orphan.c, is similar to the two
    functions already replaced by the new interface. It uses two parameters,
    which are already present in the interface, and is nearly identical to
    the function brought in in the previous patch.
    
    Replace the two calls to find_orphan_item() with calls to
    btrfs_find_item(), with the defined objectid and type that was used
    internally by find_orphan_item(), a null path, and a null key. Add a
    test for a null path to btrfs_find_item, and if it passes, allocate and
    free the path. Finally, remove find_orphan_item().
    
    Signed-off-by: Kelley Nielsen <kelleynnn@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d84667379f01..4ecee0a009cb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1608,7 +1608,8 @@ struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
 	if (ret)
 		goto fail;
 
-	ret = btrfs_find_orphan_item(fs_info->tree_root, location->objectid);
+	ret = btrfs_find_item(fs_info->tree_root, NULL, BTRFS_ORPHAN_OBJECTID,
+			location->objectid, BTRFS_ORPHAN_ITEM_KEY, NULL);
 	if (ret < 0)
 		goto fail;
 	if (ret == 0)

commit 71db2a7751b6c4befad06e66a26d7f2b8dd3c1b9
Author: Valentina Giusti <valentina.giusti@microon.de>
Date:   Mon Nov 4 22:34:23 2013 +0100

    btrfs: remove unused variables from disk-io.c
    
    Remove unused variables:
    * tree from csum_dirty_buffer,
    * tree from btree_readpage_end_io_hook,
    * tree from btree_writepages,
    * bytenr from btrfs_create_tree,
    * fs_info from end_workqueue_fn.
    
    Signed-off-by: Valentina Giusti <valentina.giusti@microon.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 81f3433fe4fd..d84667379f01 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -465,13 +465,10 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 
 static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 {
-	struct extent_io_tree *tree;
 	u64 start = page_offset(page);
 	u64 found_start;
 	struct extent_buffer *eb;
 
-	tree = &BTRFS_I(page->mapping->host)->io_tree;
-
 	eb = (struct extent_buffer *)page->private;
 	if (page != eb->pages[0])
 		return 0;
@@ -570,7 +567,6 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 				      u64 phy_offset, struct page *page,
 				      u64 start, u64 end, int mirror)
 {
-	struct extent_io_tree *tree;
 	u64 found_start;
 	int found_level;
 	struct extent_buffer *eb;
@@ -581,7 +577,6 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	if (!page->private)
 		goto out;
 
-	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	eb = (struct extent_buffer *)page->private;
 
 	/* the pending IO might have been the only thing that kept this buffer
@@ -968,11 +963,9 @@ static int btree_migratepage(struct address_space *mapping,
 static int btree_writepages(struct address_space *mapping,
 			    struct writeback_control *wbc)
 {
-	struct extent_io_tree *tree;
 	struct btrfs_fs_info *fs_info;
 	int ret;
 
-	tree = &BTRFS_I(mapping->host)->io_tree;
 	if (wbc->sync_mode == WB_SYNC_NONE) {
 
 		if (wbc->for_kupdate)
@@ -1274,7 +1267,6 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	struct btrfs_root *root;
 	struct btrfs_key key;
 	int ret = 0;
-	u64 bytenr;
 	uuid_le uuid;
 
 	root = btrfs_alloc_root(fs_info);
@@ -1296,7 +1288,6 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 		goto fail;
 	}
 
-	bytenr = leaf->start;
 	memset_extent_buffer(leaf, 0, 0, sizeof(struct btrfs_header));
 	btrfs_set_header_bytenr(leaf, leaf->start);
 	btrfs_set_header_generation(leaf, trans->transid);
@@ -1685,12 +1676,10 @@ static void end_workqueue_fn(struct btrfs_work *work)
 {
 	struct bio *bio;
 	struct end_io_wq *end_io_wq;
-	struct btrfs_fs_info *fs_info;
 	int error;
 
 	end_io_wq = container_of(work, struct end_io_wq, work);
 	bio = end_io_wq->bio;
-	fs_info = end_io_wq->info;
 
 	error = end_io_wq->error;
 	bio->bi_private = end_io_wq->private;

commit 5ac1d209f11271fbfad0fa31ba56ec64c142d9ea
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Nov 1 13:06:58 2013 -0400

    btrfs: publish per-super attributes in sysfs
    
    This patch adds per-super attributes to sysfs.
    
    It doesn't publish any attributes yet, but does the proper lifetime
    handling as well as the basic infrastructure to add new attributes.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 435ef132b800..81f3433fe4fd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -48,6 +48,7 @@
 #include "rcu-string.h"
 #include "dev-replace.h"
 #include "raid56.h"
+#include "sysfs.h"
 
 #ifdef CONFIG_X86
 #include <asm/cpufeature.h>
@@ -2743,6 +2744,12 @@ int open_ctree(struct super_block *sb,
 
 	btrfs_close_extra_devices(fs_info, fs_devices, 1);
 
+	ret = btrfs_sysfs_add_one(fs_info);
+	if (ret) {
+		pr_err("btrfs: failed to init sysfs interface: %d\n", ret);
+		goto fail_block_groups;
+	}
+
 	ret = btrfs_init_space_info(fs_info);
 	if (ret) {
 		printk(KERN_ERR "Failed to initial space info: %d\n", ret);
@@ -3584,6 +3591,8 @@ int close_ctree(struct btrfs_root *root)
 		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 
+	btrfs_sysfs_remove_one(fs_info);
+
 	del_fs_roots(fs_info);
 
 	btrfs_free_block_groups(fs_info);

commit c46effa601f869f3d20a7386a745d9c002838eb8
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Oct 14 12:59:45 2013 +0800

    Btrfs: introduce a head ref rbtree
    
    The way how we process delayed refs is
    1) get a bunch of head refs,
    2) pick up one head ref,
    3) go one node back for any delayed ref updates.
    
    The head ref is also linked in the same rbtree as the delayed ref is,
    so in 1) stage, we have to walk one by one including not only head refs, but
    delayed refs.
    
    When we have a great number of delayed refs pending to process,
    this'll cost time a lot.
    
    Here we introduce a head ref specific rbtree, it only has head refs, so troubles
    go away.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8072cfa8a3b1..435ef132b800 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3842,6 +3842,9 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 
 		ref->in_tree = 0;
 		rb_erase(&ref->rb_node, &delayed_refs->root);
+		if (head)
+			rb_erase(&head->href_node, &delayed_refs->href_root);
+
 		delayed_refs->num_entries--;
 		spin_unlock(&delayed_refs->lock);
 		if (head) {

commit bc1e79acc13d70c5bb1b2a47bf0a580e6ae81fb6
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Tue Dec 3 13:24:08 2013 -0800

    block: fixup for generic bio chaining
    
    btrfs bits got lost in the rebase
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>
    Cc: Chris Mason <clm@fb.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5a10c61adafc..e71039ea66cf 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1692,7 +1692,7 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	bio->bi_private = end_io_wq->private;
 	bio->bi_end_io = end_io_wq->end_io;
 	kfree(end_io_wq);
-	bio_endio(bio, error);
+	bio_endio_nodec(bio, error);
 }
 
 static int cleaner_kthread(void *arg)

commit 2c30c71bd653afcbed7f6754e8fe3d16e0e708a1
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Thu Nov 7 12:20:26 2013 -0800

    block: Convert various code to bio_for_each_segment()
    
    With immutable biovecs we don't want code accessing bi_io_vec directly -
    the uses this patch changes weren't incorrect since they all own the
    bio, but it makes the code harder to audit for no good reason - also,
    this will help with multipage bvecs later.
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Chris Mason <chris.mason@fusionio.com>
    Cc: Jaegeuk Kim <jaegeuk.kim@samsung.com>
    Cc: Joern Engel <joern@logfs.org>
    Cc: Prasad Joshi <prasadjoshi.linux@gmail.com>
    Cc: Trond Myklebust <Trond.Myklebust@netapp.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8072cfa8a3b1..5a10c61adafc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -842,20 +842,17 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 
 static int btree_csum_one_bio(struct bio *bio)
 {
-	struct bio_vec *bvec = bio->bi_io_vec;
-	int bio_index = 0;
+	struct bio_vec *bvec;
 	struct btrfs_root *root;
-	int ret = 0;
+	int i, ret = 0;
 
-	WARN_ON(bio->bi_vcnt <= 0);
-	while (bio_index < bio->bi_vcnt) {
+	bio_for_each_segment_all(bvec, bio, i) {
 		root = BTRFS_I(bvec->bv_page->mapping->host)->root;
 		ret = csum_dirty_buffer(root, bvec->bv_page);
 		if (ret)
 			break;
-		bio_index++;
-		bvec++;
 	}
+
 	return ret;
 }
 

commit d52c1bcc647ca41ee563bc38d8231e5f3816112c
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Tue Nov 5 11:45:53 2013 +0800

    Btrfs: avoid heavy operations in btrfs_commit_super
    
    The 'git blame' history shows that, the old transaction commit code has to do
    twice to ensure roots are updated and we have to flush metadata and super block
    manually, however, right now all of these can be handled well inside
    the transaction commit code without extra efforts.
    
    And the error handling part remains same with the current code, -- 'return to
    caller once we get error'.
    
    This saves us a transaction commit and a flush of super block, which are both
    heavy operations according to ftrace output analysis.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4c4ed0bb3da1..8072cfa8a3b1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3517,7 +3517,6 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 int btrfs_commit_super(struct btrfs_root *root)
 {
 	struct btrfs_trans_handle *trans;
-	int ret;
 
 	mutex_lock(&root->fs_info->cleaner_mutex);
 	btrfs_run_delayed_iputs(root);
@@ -3531,25 +3530,7 @@ int btrfs_commit_super(struct btrfs_root *root)
 	trans = btrfs_join_transaction(root);
 	if (IS_ERR(trans))
 		return PTR_ERR(trans);
-	ret = btrfs_commit_transaction(trans, root);
-	if (ret)
-		return ret;
-	/* run commit again to drop the original snapshot */
-	trans = btrfs_join_transaction(root);
-	if (IS_ERR(trans))
-		return PTR_ERR(trans);
-	ret = btrfs_commit_transaction(trans, root);
-	if (ret)
-		return ret;
-	ret = btrfs_write_and_wait_transaction(NULL, root);
-	if (ret) {
-		btrfs_error(root->fs_info, ret,
-			    "Failed to sync btree inode to disk.");
-		return ret;
-	}
-
-	ret = write_ctree_super(NULL, root, 0);
-	return ret;
+	return btrfs_commit_transaction(trans, root);
 }
 
 int close_ctree(struct btrfs_root *root)

commit f570e757b54ca6eceabc9b19a6342f14e836c196
Author: Rashika <rashika.kheria@gmail.com>
Date:   Thu Oct 31 16:50:42 2013 +0530

    btrfs: Remove useless variable in write_ctree_super()
    
    The function write_ctree_super() in disk-io.c uses variable ret to return
    the result of function write_all_supers(). Since, this variable serves
    no purpose, hence the patch removes it and returns the call of the
    called function.
    
    Reviewed-by: Zach Brown <zab@redhat.com>
    Signed-off-by: Rashika Kheria <rashika.kheria@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 77fa2d99252f..4c4ed0bb3da1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3440,10 +3440,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 int write_ctree_super(struct btrfs_trans_handle *trans,
 		      struct btrfs_root *root, int max_mirrors)
 {
-	int ret;
-
-	ret = write_all_supers(root, max_mirrors);
-	return ret;
+	return write_all_supers(root, max_mirrors);
 }
 
 /* Drop a fs root from the radix tree and free it. */

commit fae7f21cece9a4c181a8d8131870c7247e153f65
Author: Dulshani Gunawardhana <dulshani.gunawardhana89@gmail.com>
Date:   Thu Oct 31 10:30:08 2013 +0530

    btrfs: Use WARN_ON()'s return value in place of WARN_ON(1)
    
    Use WARN_ON()'s return value in place of WARN_ON(1) for cleaner source
    code that outputs a more descriptive warnings. Also fix the styling
    warning of redundant braces that came up as a result of this fix.
    
    Signed-off-by: Dulshani Gunawardhana <dulshani.gunawardhana89@gmail.com>
    Reviewed-by: Zach Brown <zab@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 22443fac9408..77fa2d99252f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -475,14 +475,8 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	if (page != eb->pages[0])
 		return 0;
 	found_start = btrfs_header_bytenr(eb);
-	if (found_start != start) {
-		WARN_ON(1);
+	if (WARN_ON(found_start != start || !PageUptodate(page)))
 		return 0;
-	}
-	if (!PageUptodate(page)) {
-		WARN_ON(1);
-		return 0;
-	}
 	csum_tree_block(root, eb, 0);
 	return 0;
 }

commit 2e9f5954978cd5b0c26e6eeb9fd4ccbdce0f5ecc
Author: Rashika <rashika.kheria@gmail.com>
Date:   Thu Oct 31 02:45:20 2013 +0530

    btrfs: Add helper function for free_root_pointers()
    
    The function free_root_pointers() in disk-io.h contains redundant code.
    Therefore, this patch adds a helper function free_root_extent_buffers()
    to free_root_pointers() to eliminate redundancy.
    
    Reviewed-by: Zach Brown <zab@redhat.com>
    Signed-off-by: Rashika Kheria <rashika.kheria@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a3ad3a27944d..22443fac9408 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2033,50 +2033,28 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_stop_workers(&fs_info->qgroup_rescan_workers);
 }
 
+static void free_root_extent_buffers(struct btrfs_root *root)
+{
+	if (root) {
+		free_extent_buffer(root->node);
+		free_extent_buffer(root->commit_root);
+		root->node = NULL;
+		root->commit_root = NULL;
+	}
+}
+
 /* helper to cleanup tree roots */
 static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 {
-	free_extent_buffer(info->tree_root->node);
-	free_extent_buffer(info->tree_root->commit_root);
-	info->tree_root->node = NULL;
-	info->tree_root->commit_root = NULL;
-
-	if (info->dev_root) {
-		free_extent_buffer(info->dev_root->node);
-		free_extent_buffer(info->dev_root->commit_root);
-		info->dev_root->node = NULL;
-		info->dev_root->commit_root = NULL;
-	}
-	if (info->extent_root) {
-		free_extent_buffer(info->extent_root->node);
-		free_extent_buffer(info->extent_root->commit_root);
-		info->extent_root->node = NULL;
-		info->extent_root->commit_root = NULL;
-	}
-	if (info->csum_root) {
-		free_extent_buffer(info->csum_root->node);
-		free_extent_buffer(info->csum_root->commit_root);
-		info->csum_root->node = NULL;
-		info->csum_root->commit_root = NULL;
-	}
-	if (info->quota_root) {
-		free_extent_buffer(info->quota_root->node);
-		free_extent_buffer(info->quota_root->commit_root);
-		info->quota_root->node = NULL;
-		info->quota_root->commit_root = NULL;
-	}
-	if (info->uuid_root) {
-		free_extent_buffer(info->uuid_root->node);
-		free_extent_buffer(info->uuid_root->commit_root);
-		info->uuid_root->node = NULL;
-		info->uuid_root->commit_root = NULL;
-	}
-	if (chunk_root) {
-		free_extent_buffer(info->chunk_root->node);
-		free_extent_buffer(info->chunk_root->commit_root);
-		info->chunk_root->node = NULL;
-		info->chunk_root->commit_root = NULL;
-	}
+	free_root_extent_buffers(info->tree_root);
+
+	free_root_extent_buffers(info->dev_root);
+	free_root_extent_buffers(info->extent_root);
+	free_root_extent_buffers(info->csum_root);
+	free_root_extent_buffers(info->quota_root);
+	free_root_extent_buffers(info->uuid_root);
+	if (chunk_root)
+		free_root_extent_buffers(info->chunk_root);
 }
 
 static void del_fs_roots(struct btrfs_fs_info *fs_info)

commit 9b011adfe14977fcda977234609d43ca52463a3d
Author: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
Date:   Fri Oct 25 19:12:02 2013 +0800

    Btrfs: remove scrub_super_lock holding in btrfs_sync_log()
    
    Originally, we introduced scrub_super_lock to synchronize
    tree log code with scrubbing super.
    
    However we can replace scrub_super_lock with device_list_mutex,
    because writing super will hold this mutex, this will reduce an extra
    lock holding when writing supers in sync log code.
    
    Signed-off-by: Wang Shilong <wangsl.fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 62c4aba221bb..a3ad3a27944d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2250,7 +2250,6 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->scrubs_paused, 0);
 	atomic_set(&fs_info->scrub_cancel_req, 0);
 	init_waitqueue_head(&fs_info->scrub_pause_wait);
-	init_rwsem(&fs_info->scrub_super_lock);
 	fs_info->scrub_workers_refcnt = 0;
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	fs_info->check_integrity_print_mask = 0;

commit 8b558c5f097b636209b654f4d7775ac96054d6e3
Author: Zach Brown <zab@redhat.com>
Date:   Wed Oct 16 12:10:34 2013 -0700

    btrfs: remove fs/btrfs/compat.h
    
    fs/btrfs/compat.h only contained trivial macro wrappers of drop_nlink()
    and inc_nlink().  This doesn't belong in mainline.
    
    Signed-off-by: Zach Brown <zab@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ebc784aba3f5..62c4aba221bb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -33,7 +33,6 @@
 #include <linux/uuid.h>
 #include <linux/semaphore.h>
 #include <asm/unaligned.h>
-#include "compat.h"
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"

commit 452c75c3d2187089f6e846710e6ea7883bf30f8a
Author: Chandra Seetharaman <sekharan@us.ibm.com>
Date:   Mon Oct 7 10:45:25 2013 -0500

    Btrfs: Simplify the logic in alloc_extent_buffer() for existing extent buffer case
    
    alloc_extent_buffer() uses radix_tree_lookup() when radix_tree_insert()
    fails with EEXIST. That part of the code is very similar to the code in
    find_extent_buffer(). This patch replaces radix_tree_lookup() and
    surrounding code in alloc_extent_buffer() with find_extent_buffer().
    
    Note that radix_tree_lookup() does not need to be protected by
    tree->buffer_lock. It is protected by eb->refs.
    
    While at it, this patch
      - changes the other usage of radix_tree_lookup() in alloc_extent_buffer()
        with find_extent_buffer() to reduce redundancy.
      - removes the unused argument 'len' to find_extent_buffer().
    
    Signed-Off-by: Chandra Seetharaman <sekharan@us.ibm.com>
    Reviewed-by: Zach Brown <zab@redhat.com>
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b0ea9f4bbc70..ebc784aba3f5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1104,8 +1104,7 @@ struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	struct extent_buffer *eb;
-	eb = find_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
-				bytenr, blocksize);
+	eb = find_extent_buffer(&BTRFS_I(btree_inode)->io_tree, bytenr);
 	return eb;
 }
 

commit 96192499c27e8b58d71f4370f29ca86d4ca915d7
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Oct 16 13:53:28 2013 -0400

    Btrfs: stop all workers after we free block groups
    
    Stefan was hitting a panic in the async worker stuff because we had outstanding
    read bios while we were stopping the worker threads.  You could reproduce this
    easily if you mount -o nospace_cache and ran generic/273.  This is because the
    caching thread stuff is still going and we were stopping all the worker threads.
    We need to stop the workers after this work is done, and the free block groups
    code will wait for all the caching threads to stop first so we don't run into
    this problem.  With this patch we no longer panic.  Thanks,
    
    Cc: stable@vger.kernel.org
    Reported-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 419968e3eaa0..b0ea9f4bbc70 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3637,12 +3637,12 @@ int close_ctree(struct btrfs_root *root)
 		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 
-	btrfs_stop_all_workers(fs_info);
-
 	del_fs_roots(fs_info);
 
 	btrfs_free_block_groups(fs_info);
 
+	btrfs_stop_all_workers(fs_info);
+
 	free_root_pointers(fs_info, 1);
 
 	iput(fs_info->btree_inode);

commit 2b1360da35877cd969ed83884d8989ba778254d0
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Oct 7 15:14:44 2013 -0400

    Btrfs: free up block groups after everything
    
    If we abort a transaction we will do the tree log cleanup at unmount, but this
    happens after we free up the block groups.  This makes all the leak detection
    warnings go off because we think we've leaked space but in reality we just
    haven't cleaned it up yet.  So instead do the block group cleanup stuff after
    free'ing the fs roots so we don't get these warnings.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fdc75ab09483..419968e3eaa0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3637,12 +3637,12 @@ int close_ctree(struct btrfs_root *root)
 		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 
-	btrfs_free_block_groups(fs_info);
-
 	btrfs_stop_all_workers(fs_info);
 
 	del_fs_roots(fs_info);
 
+	btrfs_free_block_groups(fs_info);
+
 	free_root_pointers(fs_info, 1);
 
 	iput(fs_info->btree_inode);

commit eb58bb371a04d3bbab44ec0c5672ce69487bac1e
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Oct 7 10:45:07 2013 -0400

    Btrfs: do not free the dirty bytes from the trans block rsv on cleanup
    
    The transactions should be cleaning up their reservations on failure, this just
    causes us to have warnings on unmount because we go negative by free'ing
    reservations that have already been free'ed.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d205bddc7776..fdc75ab09483 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4046,8 +4046,6 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	btrfs_destroy_ordered_operations(cur_trans, root);
 
 	btrfs_destroy_delayed_refs(cur_trans, root);
-	btrfs_block_rsv_release(root, &root->fs_info->trans_block_rsv,
-				cur_trans->dirty_pages.dirty_bytes);
 
 	cur_trans->state = TRANS_STATE_COMMIT_START;
 	wake_up(&root->fs_info->transaction_blocked_wait);

commit 778ba82b1796e75e719a52679ae431371ca73988
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Sun Oct 6 22:22:33 2013 +0100

    Btrfs: improve inode hash function/inode lookup
    
    Currently the hash value used for adding an inode to the VFS's inode
    hash table consists of the plain inode number, which is a 64 bits
    integer. This results in hash table buckets (hlist_head lists) with
    too many elements for at least 2 important scenarios:
    
    1) When we have many subvolumes. Each subvolume has its own btree
       where its files and directories are added to, and each has its
       own objectid (inode number) namespace. This means that if we have
       N subvolumes, and all have inode number X associated to a file or
       directory, the corresponding inodes all map to the same hash table
       entry, resulting in a bucket (hlist_head list) with N elements;
    
    2) On 32 bits machines. Th VFS hash values are unsigned longs, which
       are 32 bits wide on 32 bits machines, and the inode (objectid)
       numbers are 64 bits unsigned integers. We simply cast the inode
       numbers to hash values, which means that for all inodes with the
       same 32 bits lower half, the same hash bucket is used for all of
       them. For example, all inodes with a number (objectid) between
       0x0000_0000_ffff_ffff and 0xffff_ffff_ffff_ffff will end up in
       the same hash table bucket.
    
    This change ensures the inode's hash value depends both on the
    objectid (inode number) and its subvolume's (btree root) objectid.
    For 32 bits machines, this change gives better entropy by making
    the hash value depend on both the upper and lower 32 bits of the
    64 bits hash previously computed.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ade6c0e79616..d205bddc7776 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2294,7 +2294,7 @@ int open_ctree(struct super_block *sb,
 	       sizeof(struct btrfs_key));
 	set_bit(BTRFS_INODE_DUMMY,
 		&BTRFS_I(fs_info->btree_inode)->runtime_flags);
-	insert_inode_hash(fs_info->btree_inode);
+	btrfs_insert_inode_hash(fs_info->btree_inode);
 
 	spin_lock_init(&fs_info->block_group_cache_lock);
 	fs_info->block_group_cache_tree = RB_ROOT;

commit 0a4e558609dd4df30a58a07d9eb14c5ddc2c1241
Author: Ross Kirk <ross.kirk@gmail.com>
Date:   Tue Sep 24 10:12:38 2013 +0100

    btrfs: remove unused parameter from btrfs_header_fsid
    
    Remove unused parameter, 'eb'. Unused since introduction in
    5f39d397dfbe140a14edecd4e73c34ce23c4f9ee
    
    Updated to be rebased against current upstream and correct diff supplied this time!
    
    Signed-off-by: Ross Kirk <ross.kirk@gmail.com>
    Reviewed-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b131d716d5a5..ade6c0e79616 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -495,7 +495,7 @@ static int check_tree_block_fsid(struct btrfs_root *root,
 	u8 fsid[BTRFS_UUID_SIZE];
 	int ret = 1;
 
-	read_extent_buffer(eb, fsid, btrfs_header_fsid(eb), BTRFS_FSID_SIZE);
+	read_extent_buffer(eb, fsid, btrfs_header_fsid(), BTRFS_FSID_SIZE);
 	while (fs_devices) {
 		if (!memcmp(fsid, fs_devices->fsid, BTRFS_FSID_SIZE)) {
 			ret = 0;
@@ -1311,7 +1311,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_header_owner(leaf, objectid);
 	root->node = leaf;
 
-	write_extent_buffer(leaf, fs_info->fsid, btrfs_header_fsid(leaf),
+	write_extent_buffer(leaf, fs_info->fsid, btrfs_header_fsid(),
 			    BTRFS_FSID_SIZE);
 	write_extent_buffer(leaf, fs_info->chunk_tree_uuid,
 			    btrfs_header_chunk_tree_uuid(leaf),
@@ -1398,7 +1398,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	root->node = leaf;
 
 	write_extent_buffer(root->node, root->fs_info->fsid,
-			    btrfs_header_fsid(root->node), BTRFS_FSID_SIZE);
+			    btrfs_header_fsid(), BTRFS_FSID_SIZE);
 	btrfs_mark_buffer_dirty(root->node);
 	btrfs_tree_unlock(root->node);
 	return root;

commit 724e2315db3d59a8201d4a87c7c7a873e60e1ce0
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Sep 30 11:36:38 2013 -0400

    Btrfs: fix two use-after-free bugs with transaction cleanup
    
    I was noticing the slab redzone stuff going off every once and a while during
    transaction aborts.  This was caused by two things
    
    1) We would walk the pending snapshots and set their error to -ECANCELED.  We
    don't need to do this, the snapshot stuff waits for a transaction commit and if
    there is a problem we just free our pending snapshot object and exit.  Doing
    this was causing us to touch the pending snapshot object after the thing had
    already been freed.
    
    2) We were freeing the transaction manually with wanton disregard for it's
    use_count reference counter.  To fix this I cleaned up the transaction freeing
    loop to either wait for the transaction commit to finish if it was in the middle
    of that (since it will be cleaned and freed up there) or to do the cleanup
    oursevles.
    
    I also moved the global "kill all things dirty everywhere" stuff outside of the
    transaction cleanup loop since that only needs to be done once.  With this patch
    I'm no longer seeing slab corruption because of use after frees.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 01a26e2eb310..b131d716d5a5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -64,7 +64,6 @@ static void btrfs_destroy_ordered_operations(struct btrfs_transaction *t,
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				      struct btrfs_root *root);
-static void btrfs_evict_pending_snapshots(struct btrfs_transaction *t);
 static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root);
 static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 					struct extent_io_tree *dirty_pages,
@@ -3915,24 +3914,6 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 	return ret;
 }
 
-static void btrfs_evict_pending_snapshots(struct btrfs_transaction *t)
-{
-	struct btrfs_pending_snapshot *snapshot;
-	struct list_head splice;
-
-	INIT_LIST_HEAD(&splice);
-
-	list_splice_init(&t->pending_snapshots, &splice);
-
-	while (!list_empty(&splice)) {
-		snapshot = list_entry(splice.next,
-				      struct btrfs_pending_snapshot,
-				      list);
-		snapshot->error = -ECANCELED;
-		list_del_init(&snapshot->list);
-	}
-}
-
 static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
 {
 	struct btrfs_inode *btrfs_inode;
@@ -4062,6 +4043,8 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 				   struct btrfs_root *root)
 {
+	btrfs_destroy_ordered_operations(cur_trans, root);
+
 	btrfs_destroy_delayed_refs(cur_trans, root);
 	btrfs_block_rsv_release(root, &root->fs_info->trans_block_rsv,
 				cur_trans->dirty_pages.dirty_bytes);
@@ -4069,8 +4052,6 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	cur_trans->state = TRANS_STATE_COMMIT_START;
 	wake_up(&root->fs_info->transaction_blocked_wait);
 
-	btrfs_evict_pending_snapshots(cur_trans);
-
 	cur_trans->state = TRANS_STATE_UNBLOCKED;
 	wake_up(&root->fs_info->transaction_wait);
 
@@ -4094,63 +4075,51 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 static int btrfs_cleanup_transaction(struct btrfs_root *root)
 {
 	struct btrfs_transaction *t;
-	LIST_HEAD(list);
 
 	mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
 	spin_lock(&root->fs_info->trans_lock);
-	list_splice_init(&root->fs_info->trans_list, &list);
-	root->fs_info->running_transaction = NULL;
-	spin_unlock(&root->fs_info->trans_lock);
-
-	while (!list_empty(&list)) {
-		t = list_entry(list.next, struct btrfs_transaction, list);
-
-		btrfs_destroy_ordered_operations(t, root);
-
-		btrfs_destroy_all_ordered_extents(root->fs_info);
-
-		btrfs_destroy_delayed_refs(t, root);
-
-		/*
-		 *  FIXME: cleanup wait for commit
-		 *  We needn't acquire the lock here, because we are during
-		 *  the umount, there is no other task which will change it.
-		 */
-		t->state = TRANS_STATE_COMMIT_START;
-		smp_mb();
-		if (waitqueue_active(&root->fs_info->transaction_blocked_wait))
-			wake_up(&root->fs_info->transaction_blocked_wait);
-
-		btrfs_evict_pending_snapshots(t);
-
-		t->state = TRANS_STATE_UNBLOCKED;
-		smp_mb();
-		if (waitqueue_active(&root->fs_info->transaction_wait))
-			wake_up(&root->fs_info->transaction_wait);
-
-		btrfs_destroy_delayed_inodes(root);
-		btrfs_assert_delayed_root_empty(root);
-
-		btrfs_destroy_all_delalloc_inodes(root->fs_info);
-
-		btrfs_destroy_marked_extents(root, &t->dirty_pages,
-					     EXTENT_DIRTY);
-
-		btrfs_destroy_pinned_extent(root,
-					    root->fs_info->pinned_extents);
-
-		t->state = TRANS_STATE_COMPLETED;
-		smp_mb();
-		if (waitqueue_active(&t->commit_wait))
-			wake_up(&t->commit_wait);
+	while (!list_empty(&root->fs_info->trans_list)) {
+		t = list_first_entry(&root->fs_info->trans_list,
+				     struct btrfs_transaction, list);
+		if (t->state >= TRANS_STATE_COMMIT_START) {
+			atomic_inc(&t->use_count);
+			spin_unlock(&root->fs_info->trans_lock);
+			btrfs_wait_for_commit(root, t->transid);
+			btrfs_put_transaction(t);
+			spin_lock(&root->fs_info->trans_lock);
+			continue;
+		}
+		if (t == root->fs_info->running_transaction) {
+			t->state = TRANS_STATE_COMMIT_DOING;
+			spin_unlock(&root->fs_info->trans_lock);
+			/*
+			 * We wait for 0 num_writers since we don't hold a trans
+			 * handle open currently for this transaction.
+			 */
+			wait_event(t->writer_wait,
+				   atomic_read(&t->num_writers) == 0);
+		} else {
+			spin_unlock(&root->fs_info->trans_lock);
+		}
+		btrfs_cleanup_one_transaction(t, root);
 
-		atomic_set(&t->use_count, 0);
+		spin_lock(&root->fs_info->trans_lock);
+		if (t == root->fs_info->running_transaction)
+			root->fs_info->running_transaction = NULL;
 		list_del_init(&t->list);
-		memset(t, 0, sizeof(*t));
-		kmem_cache_free(btrfs_transaction_cachep, t);
-	}
+		spin_unlock(&root->fs_info->trans_lock);
 
+		btrfs_put_transaction(t);
+		trace_btrfs_transaction_commit(root);
+		spin_lock(&root->fs_info->trans_lock);
+	}
+	spin_unlock(&root->fs_info->trans_lock);
+	btrfs_destroy_all_ordered_extents(root->fs_info);
+	btrfs_destroy_delayed_inodes(root);
+	btrfs_assert_delayed_root_empty(root);
+	btrfs_destroy_pinned_extent(root, root->fs_info->pinned_extents);
+	btrfs_destroy_all_delalloc_inodes(root->fs_info);
 	mutex_unlock(&root->fs_info->transaction_kthread_mutex);
 
 	return 0;

commit 1de2cfde93c20a0357ff1dffed901598470facf3
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Sep 27 16:36:02 2013 -0400

    Btrfs: don't delete ordered roots from list during cleanup
    
    During transaction cleanup after an abort we are just removing roots from the
    ordered roots list which is incorrect.  We have a BUG_ON() to make sure that the
    root is still part of the ordered roots list when we put our ordered extent
    which we were tripping in this case.  So do like we do everywhere else and just
    move it to the tail of the ordered roots list and allow the normal cleanup to
    take care of stuff.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 113cd43530ba..01a26e2eb310 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3836,7 +3836,8 @@ static void btrfs_destroy_all_ordered_extents(struct btrfs_fs_info *fs_info)
 	while (!list_empty(&splice)) {
 		root = list_first_entry(&splice, struct btrfs_root,
 					ordered_root);
-		list_del_init(&root->ordered_root);
+		list_move_tail(&root->ordered_root,
+			       &fs_info->ordered_roots);
 
 		btrfs_destroy_ordered_extents(root);
 

commit 4e121c06adf53aae478ebce3035116595d063413
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Sep 27 16:32:39 2013 -0400

    Btrfs: cleanup transaction on abort
    
    If we abort not during a transaction commit we won't clean up anything until we
    unmount.  Unfortunately if we abort in the middle of writing out an ordered
    extent we won't clean it up and if somebody is waiting on that ordered extent
    they will wait forever.  To fix this just make the transaction kthread call the
    cleanup transaction stuff if it notices theres an error, and make
    btrfs_end_transaction wake up the transaction kthread if there is an error.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index db2095486a4f..113cd43530ba 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1800,6 +1800,9 @@ static int transaction_kthread(void *arg)
 		wake_up_process(root->fs_info->cleaner_kthread);
 		mutex_unlock(&root->fs_info->transaction_kthread_mutex);
 
+		if (unlikely(test_bit(BTRFS_FS_STATE_ERROR,
+				      &root->fs_info->fs_state)))
+			btrfs_cleanup_transaction(root);
 		if (!try_to_freeze()) {
 			set_current_state(TASK_INTERRUPTIBLE);
 			if (!kthread_should_stop() &&

commit 06ea65a398a2501e94beee3a425d07e1846ff25a
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Sep 19 16:07:01 2013 -0400

    Btrfs: add a sanity test for btrfs_split_item
    
    While looking at somebodys corruption I became completely convinced that
    btrfs_split_item was broken, so I wrote this test to verify that it was working
    as it was supposed to.  Thankfully it appears to be working as intended, so just
    add this test to make sure nobody breaks it in the future.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f724397b396b..db2095486a4f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1229,14 +1229,18 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	atomic_set(&root->refs, 1);
 	root->log_transid = 0;
 	root->last_log_commit = 0;
-	extent_io_tree_init(&root->dirty_log_pages,
-			     fs_info->btree_inode->i_mapping);
+	if (fs_info)
+		extent_io_tree_init(&root->dirty_log_pages,
+				     fs_info->btree_inode->i_mapping);
 
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
 	memset(&root->root_kobj, 0, sizeof(root->root_kobj));
-	root->defrag_trans_start = fs_info->generation;
+	if (fs_info)
+		root->defrag_trans_start = fs_info->generation;
+	else
+		root->defrag_trans_start = 0;
 	init_completion(&root->kobj_unregister);
 	root->defrag_running = 0;
 	root->root_key.objectid = objectid;
@@ -1253,6 +1257,22 @@ static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info)
 	return root;
 }
 
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+/* Should only be used by the testing infrastructure */
+struct btrfs_root *btrfs_alloc_dummy_root(void)
+{
+	struct btrfs_root *root;
+
+	root = btrfs_alloc_root(NULL);
+	if (!root)
+		return ERR_PTR(-ENOMEM);
+	__setup_root(4096, 4096, 4096, 4096, root, NULL, 1);
+	root->dummy_root = 1;
+
+	return root;
+}
+#endif
+
 struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 				     struct btrfs_fs_info *fs_info,
 				     u64 objectid)
@@ -3670,10 +3690,20 @@ int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
 
 void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root;
 	u64 transid = btrfs_header_generation(buf);
 	int was_dirty;
 
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+	/*
+	 * This is a fast path so only do this check if we have sanity tests
+	 * enabled.  Normal people shouldn't be marking dummy buffers as dirty
+	 * outside of the sanity tests.
+	 */
+	if (unlikely(test_bit(EXTENT_BUFFER_DUMMY, &buf->bflags)))
+		return;
+#endif
+	root = BTRFS_I(buf->pages[0]->mapping->host)->root;
 	btrfs_assert_tree_locked(buf);
 	if (transid != root->fs_info->generation)
 		WARN(1, KERN_CRIT "btrfs transid mismatch buffer %llu, "

commit 69e9c6c6dc87587d8846e447febedefe037c14f8
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Sep 5 16:58:43 2013 +0200

    Btrfs: eliminate the exceptional root_tree refs=0
    
    The fact that btrfs_root_refs() returned 0 for the tree_root caused
    bugs in the past, therefore it is set to 1 with this patch and
    (hopefully) all affected code is adapted to this change.
    
    I verified this change by temporarily adding WARN_ON() checks
    everywhere where btrfs_root_refs() is used, checking whether the
    logic of the code is changed by btrfs_root_refs() returning 1
    instead of 0 for root->root_key.objectid == BTRFS_ROOT_TREE_OBJECTID.
    With these added checks, I ran the xfstests './check -g auto'.
    
    The two roots chunk_root and log_root_tree that are only referenced
    by the superblock and the log_roots below the log_root_tree still
    have btrfs_root_refs() == 0, only the tree_root is changed.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 62176ad89846..f724397b396b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2670,6 +2670,7 @@ int open_ctree(struct super_block *sb,
 
 	btrfs_set_root_node(&tree_root->root_item, tree_root->node);
 	tree_root->commit_root = btrfs_root_node(tree_root);
+	btrfs_set_root_refs(&tree_root->root_item, 1);
 
 	location.objectid = BTRFS_EXTENT_TREE_OBJECTID;
 	location.type = BTRFS_ROOT_ITEM_KEY;

commit c00869f1ae6a8fa49802d5e60d843b7051a112ec
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Sep 25 21:47:44 2013 +0800

    Btrfs: fix oops caused by the space balance and dead roots
    
    When doing space balance and subvolume destroy at the same time, we met
    the following oops:
    
    kernel BUG at fs/btrfs/relocation.c:2247!
    RIP: 0010: [<ffffffffa04cec16>] prepare_to_merge+0x154/0x1f0 [btrfs]
    Call Trace:
     [<ffffffffa04b5ab7>] relocate_block_group+0x466/0x4e6 [btrfs]
     [<ffffffffa04b5c7a>] btrfs_relocate_block_group+0x143/0x275 [btrfs]
     [<ffffffffa0495c56>] btrfs_relocate_chunk.isra.27+0x5c/0x5a2 [btrfs]
     [<ffffffffa0459871>] ? btrfs_item_key_to_cpu+0x15/0x31 [btrfs]
     [<ffffffffa048b46a>] ? btrfs_get_token_64+0x7e/0xcd [btrfs]
     [<ffffffffa04a3467>] ? btrfs_tree_read_unlock_blocking+0xb2/0xb7 [btrfs]
     [<ffffffffa049907d>] btrfs_balance+0x9c7/0xb6f [btrfs]
     [<ffffffffa049ef84>] btrfs_ioctl_balance+0x234/0x2ac [btrfs]
     [<ffffffffa04a1e8e>] btrfs_ioctl+0xd87/0x1ef9 [btrfs]
     [<ffffffff81122f53>] ? path_openat+0x234/0x4db
     [<ffffffff813c3b78>] ? __do_page_fault+0x31d/0x391
     [<ffffffff810f8ab6>] ? vma_link+0x74/0x94
     [<ffffffff811250f5>] vfs_ioctl+0x1d/0x39
     [<ffffffff811258c8>] do_vfs_ioctl+0x32d/0x3e2
     [<ffffffff811259d4>] SyS_ioctl+0x57/0x83
     [<ffffffff813c3bfa>] ? do_page_fault+0xe/0x10
     [<ffffffff813c73c2>] system_call_fastpath+0x16/0x1b
    
    It is because we returned the error number if the reference of the root was 0
    when doing space relocation. It was not right here, because though the root
    was dead(refs == 0), but the space it held still need be relocated, or we
    could not remove the block group. So in this case, we should return the root
    no matter it is dead or not.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4ae17ed13b32..62176ad89846 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1561,8 +1561,9 @@ int btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,
 	return ret;
 }
 
-struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
-					      struct btrfs_key *location)
+struct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,
+				     struct btrfs_key *location,
+				     bool check_ref)
 {
 	struct btrfs_root *root;
 	int ret;
@@ -1586,7 +1587,7 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 again:
 	root = btrfs_lookup_fs_root(fs_info, location->objectid);
 	if (root) {
-		if (btrfs_root_refs(&root->root_item) == 0)
+		if (check_ref && btrfs_root_refs(&root->root_item) == 0)
 			return ERR_PTR(-ENOENT);
 		return root;
 	}
@@ -1595,7 +1596,7 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	if (IS_ERR(root))
 		return root;
 
-	if (btrfs_root_refs(&root->root_item) == 0) {
+	if (check_ref && btrfs_root_refs(&root->root_item) == 0) {
 		ret = -ENOENT;
 		goto fail;
 	}

commit a724b4369097897db45d61108c0e976912e586c7
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Sep 11 09:59:22 2013 +0200

    Btrfs: add the missing mutex unlock in write_all_supers()
    
    The BUG() was replaced by btrfs_error() and return -EIO with the
    patch "get rid of one BUG() in write_all_supers()", but the missing
    mutex_unlock() was overlooked.
    
    The 0-DAY kernel build service from Intel reported the missing
    unlock which was found by the coccinelle tool:
    
        fs/btrfs/disk-io.c:3422:2-8: preceding lock on line 3374
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 72cf08b2be85..4ae17ed13b32 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3416,6 +3416,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	if (total_errors > max_errors) {
 		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
 		       total_errors);
+		mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
 
 		/* FUA is masked off if unsupported and can't be the reason */
 		btrfs_error(root->fs_info, -EIO,

commit 13fd8da98f79317d26277360d510caa1edf9bab3
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Sep 3 18:28:57 2013 +0200

    btrfs: add lockdep and tracing annotations for uuid tree
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4cbb00af92ff..72cf08b2be85 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -157,6 +157,7 @@ static struct btrfs_lockdep_keyset {
 	{ .id = BTRFS_TREE_LOG_OBJECTID,	.name_stem = "log"	},
 	{ .id = BTRFS_TREE_RELOC_OBJECTID,	.name_stem = "treloc"	},
 	{ .id = BTRFS_DATA_RELOC_TREE_OBJECTID,	.name_stem = "dreloc"	},
+	{ .id = BTRFS_UUID_TREE_OBJECTID,	.name_stem = "uuid"	},
 	{ .id = 0,				.name_stem = "tree"	},
 };
 

commit 45d5fd14d22304c9a40d5aae75ec610f5d1cbb53
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Aug 29 16:51:22 2013 -0400

    Btrfs: don't use an async starter for most of our workers
    
    We only need an async starter if we can't make a GFP_NOFS allocation in our
    current path.  This is the case for the endio stuff since it happens in IRQ
    context, but things like the caching thread workers and the delalloc flushers we
    can easily make this allocation and start threads right away.  Also change the
    worker count for the caching thread pool.  Traditionally we limited this to 2
    since we took read locks while caching, but nowadays we do this lockless so
    there's no reason to limit the number of caching threads.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 21d1d066758e..4cbb00af92ff 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2483,20 +2483,17 @@ int open_ctree(struct super_block *sb,
 			   &fs_info->generic_worker);
 
 	btrfs_init_workers(&fs_info->delalloc_workers, "delalloc",
-			   fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
+			   fs_info->thread_pool_size, NULL);
 
 	btrfs_init_workers(&fs_info->flush_workers, "flush_delalloc",
-			   fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
+			   fs_info->thread_pool_size, NULL);
 
 	btrfs_init_workers(&fs_info->submit_workers, "submit",
 			   min_t(u64, fs_devices->num_devices,
-			   fs_info->thread_pool_size),
-			   &fs_info->generic_worker);
+			   fs_info->thread_pool_size), NULL);
 
 	btrfs_init_workers(&fs_info->caching_workers, "cache",
-			   2, &fs_info->generic_worker);
+			   fs_info->thread_pool_size, NULL);
 
 	/* a higher idle thresh on the submit workers makes it much more
 	 * likely that bios will be send down in a sane order to the

commit 48475471728f060bfd2e686f592ef208d3ba8b7d
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri Aug 23 10:34:42 2013 +0200

    Btrfs: fix for patch "cleanup: don't check the same thing twice"
    
    Mitch Harder noticed that the patch 3c64a1a mentioned in the subject
    line was causing a kernel BUG() on snapshot deletion.
    
    The patch was wrong. It did not handle cached roots correctly. The
    check for root_refs == 0 was removed everywhere where
    btrfs_read_fs_root_no_name() had been used to retrieve the root,
    because this check was already dealt with in
    btrfs_read_fs_root_no_name(). But in the case when the root was
    found in the cache, there was no such check.
    
    This patch adds the missing check in the case where the root is
    found in the cache.
    
    Reported-by: Mitch Harder <mitch.harder@sabayonlinux.org>
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Reviewed-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0f75a01f69e2..21d1d066758e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1584,8 +1584,11 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 					    ERR_PTR(-ENOENT);
 again:
 	root = btrfs_lookup_fs_root(fs_info, location->objectid);
-	if (root)
+	if (root) {
+		if (btrfs_root_refs(&root->root_item) == 0)
+			return ERR_PTR(-ENOENT);
 		return root;
+	}
 
 	root = btrfs_read_fs_root(fs_info->tree_root, location);
 	if (IS_ERR(root))

commit 9d565ba4330db102127f19d159609df5c3a375d8
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri Aug 9 17:08:40 2013 +0200

    Btrfs: get rid of one BUG() in write_all_supers()
    
    The second round uses btrfs_error() and return -EIO, the first round
    can handle write errors the same way.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6d642e487229..0f75a01f69e2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3416,8 +3416,10 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
 		       total_errors);
 
-		/* This shouldn't happen. FUA is masked off if unsupported */
-		BUG();
+		/* FUA is masked off if unsupported and can't be the reason */
+		btrfs_error(root->fs_info, -EIO,
+			    "%d errors while writing supers", total_errors);
+		return -EIO;
 	}
 
 	total_errors = 0;

commit d73068018419c5999f594a52998621947dc1f7d0
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Fri Aug 9 15:41:36 2013 +0100

    Btrfs: fix race between removing a dev and writing sbs
    
    This change fixes an issue when removing a device and writing
    all super blocks run simultaneously. Here's the steps necessary
    for the issue to happen:
    
    1) disk-io.c:write_all_supers() gets a number of N devices from the
       super_copy, so it will not panic if it fails to write super blocks
       for N - 1 devices;
    
    2) Then it tries to acquire the device_list_mutex, but blocks because
       volumes.c:btrfs_rm_device() got it first;
    
    3) btrfs_rm_device() removes the device from the list, then unlocks the
       mutex and after the unlock it updates the number of devices in
       super_copy to N - 1.
    
    4) write_all_supers() finally acquires the mutex, iterates over all the
       devices in the list and gets N - 1 errors, that is, it failed to write
       super blocks to all the devices;
    
    5) Because write_all_supers() thinks there are a total of N devices, it
       considers N - 1 errors to be ok, and therefore won't panic.
    
    So this change just makes sure that write_all_supers() reads the number
    of devices from super_copy after it acquires the device_list_mutex.
    Conversely, it changes btrfs_rm_device() to update the number of devices
    in super_copy before it releases the device list mutex.
    
    The code path to add a new device (volumes.c:btrfs_init_new_device),
    already has the right behaviour: it updates the number of devices in
    super_copy while holding the device_list_mutex.
    
    The only code path that doesn't lock the device list mutex
    before updating the number of devices in the super copy is
    disk-io.c:next_root_backup(), called by open_ctree() during
    mount time where concurrency issues can't happen.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 940bc486a0f8..6d642e487229 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3365,7 +3365,6 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	int total_errors = 0;
 	u64 flags;
 
-	max_errors = btrfs_super_num_devices(root->fs_info->super_copy) - 1;
 	do_barriers = !btrfs_test_opt(root, NOBARRIER);
 	backup_super_roots(root->fs_info);
 
@@ -3374,6 +3373,7 @@ static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 
 	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
 	head = &root->fs_info->fs_devices->devices;
+	max_errors = btrfs_super_num_devices(root->fs_info->super_copy) - 1;
 
 	if (do_barriers) {
 		ret = barrier_all_devices(root->fs_info);

commit b308bc2f05a86e728bd035e21a4974acd05f4d1e
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:15 2013 +0200

    Btrfs: Make btrfs_header_chunk_tree_uuid() return unsigned long
    
    Internally, btrfs_header_chunk_tree_uuid() calculates an unsigned long, but
    casts it to a pointer, while all callers cast it to unsigned long again.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d67a2ddb3ce6..940bc486a0f8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1294,7 +1294,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	write_extent_buffer(leaf, fs_info->fsid, btrfs_header_fsid(leaf),
 			    BTRFS_FSID_SIZE);
 	write_extent_buffer(leaf, fs_info->chunk_tree_uuid,
-			    (unsigned long)btrfs_header_chunk_tree_uuid(leaf),
+			    btrfs_header_chunk_tree_uuid(leaf),
 			    BTRFS_UUID_SIZE);
 	btrfs_mark_buffer_dirty(leaf);
 
@@ -2629,8 +2629,7 @@ int open_ctree(struct super_block *sb,
 	chunk_root->commit_root = btrfs_root_node(chunk_root);
 
 	read_extent_buffer(chunk_root->node, fs_info->chunk_tree_uuid,
-	   (unsigned long)btrfs_header_chunk_tree_uuid(chunk_root->node),
-	   BTRFS_UUID_SIZE);
+	   btrfs_header_chunk_tree_uuid(chunk_root->node), BTRFS_UUID_SIZE);
 
 	ret = btrfs_read_chunk_tree(chunk_root);
 	if (ret) {

commit fba6aa75654394fccf2530041e9451414c28084f
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:14 2013 +0200

    Btrfs: Make btrfs_header_fsid() return unsigned long
    
    Internally, btrfs_header_fsid() calculates an unsigned long, but casts
    it to a pointer, while all callers cast it to unsigned long again.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5003466b00d2..d67a2ddb3ce6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -495,8 +495,7 @@ static int check_tree_block_fsid(struct btrfs_root *root,
 	u8 fsid[BTRFS_UUID_SIZE];
 	int ret = 1;
 
-	read_extent_buffer(eb, fsid, (unsigned long)btrfs_header_fsid(eb),
-			   BTRFS_FSID_SIZE);
+	read_extent_buffer(eb, fsid, btrfs_header_fsid(eb), BTRFS_FSID_SIZE);
 	while (fs_devices) {
 		if (!memcmp(fsid, fs_devices->fsid, BTRFS_FSID_SIZE)) {
 			ret = 0;
@@ -1292,8 +1291,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_header_owner(leaf, objectid);
 	root->node = leaf;
 
-	write_extent_buffer(leaf, fs_info->fsid,
-			    (unsigned long)btrfs_header_fsid(leaf),
+	write_extent_buffer(leaf, fs_info->fsid, btrfs_header_fsid(leaf),
 			    BTRFS_FSID_SIZE);
 	write_extent_buffer(leaf, fs_info->chunk_tree_uuid,
 			    (unsigned long)btrfs_header_chunk_tree_uuid(leaf),
@@ -1380,8 +1378,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	root->node = leaf;
 
 	write_extent_buffer(root->node, root->fs_info->fsid,
-			    (unsigned long)btrfs_header_fsid(root->node),
-			    BTRFS_FSID_SIZE);
+			    btrfs_header_fsid(root->node), BTRFS_FSID_SIZE);
 	btrfs_mark_buffer_dirty(root->node);
 	btrfs_tree_unlock(root->node);
 	return root;

commit c1c9ff7c94e83fae89a742df74db51156869bad5
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Aug 20 13:20:07 2013 +0200

    Btrfs: Remove superfluous casts from u64 to unsigned long long
    
    u64 is "unsigned long long" on all architectures now, so there's no need to
    cast it when formatting it using the "ll" length modifier.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c60372de6647..5003466b00d2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -303,9 +303,8 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			printk_ratelimited(KERN_INFO "btrfs: %s checksum verify "
 				       "failed on %llu wanted %X found %X "
 				       "level %d\n",
-				       root->fs_info->sb->s_id,
-				       (unsigned long long)buf->start, val, found,
-				       btrfs_header_level(buf));
+				       root->fs_info->sb->s_id, buf->start,
+				       val, found, btrfs_header_level(buf));
 			if (result != (char *)&inline_result)
 				kfree(result);
 			return 1;
@@ -346,9 +345,7 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 	}
 	printk_ratelimited("parent transid verify failed on %llu wanted %llu "
 		       "found %llu\n",
-		       (unsigned long long)eb->start,
-		       (unsigned long long)parent_transid,
-		       (unsigned long long)btrfs_header_generation(eb));
+		       eb->start, parent_transid, btrfs_header_generation(eb));
 	ret = 1;
 	clear_extent_buffer_uptodate(eb);
 out:
@@ -513,8 +510,7 @@ static int check_tree_block_fsid(struct btrfs_root *root,
 #define CORRUPT(reason, eb, root, slot)				\
 	printk(KERN_CRIT "btrfs: corrupt leaf, %s: block=%llu,"	\
 	       "root=%llu, slot=%d\n", reason,			\
-	       (unsigned long long)btrfs_header_bytenr(eb),	\
-	       (unsigned long long)root->objectid, slot)
+	       btrfs_header_bytenr(eb),	root->objectid, slot)
 
 static noinline int check_leaf(struct btrfs_root *root,
 			       struct extent_buffer *leaf)
@@ -614,14 +610,13 @@ static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
 	if (found_start != eb->start) {
 		printk_ratelimited(KERN_INFO "btrfs bad tree block start "
 			       "%llu %llu\n",
-			       (unsigned long long)found_start,
-			       (unsigned long long)eb->start);
+			       found_start, eb->start);
 		ret = -EIO;
 		goto err;
 	}
 	if (check_tree_block_fsid(root, eb)) {
 		printk_ratelimited(KERN_INFO "btrfs bad fsid on block %llu\n",
-			       (unsigned long long)eb->start);
+			       eb->start);
 		ret = -EIO;
 		goto err;
 	}
@@ -2405,7 +2400,7 @@ int open_ctree(struct super_block *sb,
 	if (features) {
 		printk(KERN_ERR "BTRFS: couldn't mount because of "
 		       "unsupported optional features (%Lx).\n",
-		       (unsigned long long)features);
+		       features);
 		err = -EINVAL;
 		goto fail_alloc;
 	}
@@ -2475,7 +2470,7 @@ int open_ctree(struct super_block *sb,
 	if (!(sb->s_flags & MS_RDONLY) && features) {
 		printk(KERN_ERR "BTRFS: couldn't mount RDWR because of "
 		       "unsupported option features (%Lx).\n",
-		       (unsigned long long)features);
+		       features);
 		err = -EINVAL;
 		goto fail_alloc;
 	}
@@ -3681,9 +3676,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	if (transid != root->fs_info->generation)
 		WARN(1, KERN_CRIT "btrfs transid mismatch buffer %llu, "
 		       "found %llu running %llu\n",
-			(unsigned long long)buf->start,
-			(unsigned long long)transid,
-			(unsigned long long)root->fs_info->generation);
+			buf->start, transid, root->fs_info->generation);
 	was_dirty = set_extent_buffer_dirty(buf);
 	if (!was_dirty)
 		__percpu_counter_add(&root->fs_info->dirty_metadata_bytes,

commit 1cb048f596cc7b4405d695d65ca70098a7ab9065
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Tue Aug 20 00:52:51 2013 +0100

    Btrfs: fix memory leak of orphan block rsv
    
    This issue is simple to reproduce and observe if kmemleak is enabled.
    Two simple ways to reproduce it:
    
    ** 1
    
    $ mkfs.btrfs -f /dev/loop0
    $ mount /dev/loop0 /mnt/btrfs
    $ btrfs balance start /mnt/btrfs
    $ umount /mnt/btrfs
    
    ** 2
    
    $ mkfs.btrfs -f /dev/loop0
    $ mount /dev/loop0 /mnt/btrfs
    $ touch /mnt/btrfs/foobar
    $ rm -f /mnt/btrfs/foobar
    $ umount /mnt/btrfs
    
    After a while, kmemleak reports the leak:
    
    $ cat /sys/kernel/debug/kmemleak
    unreferenced object 0xffff880402b13e00 (size 128):
      comm "btrfs", pid 19621, jiffies 4341648183 (age 70057.844s)
      hex dump (first 32 bytes):
        00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
        00 fc c6 b1 04 88 ff ff 04 00 04 00 ad 4e ad de  .............N..
      backtrace:
        [<ffffffff817275a6>] kmemleak_alloc+0x26/0x50
        [<ffffffff8117832b>] kmem_cache_alloc_trace+0xeb/0x1d0
        [<ffffffffa04db499>] btrfs_alloc_block_rsv+0x39/0x70 [btrfs]
        [<ffffffffa04f8bad>] btrfs_orphan_add+0x13d/0x1b0 [btrfs]
        [<ffffffffa04e2b13>] btrfs_remove_block_group+0x143/0x500 [btrfs]
        [<ffffffffa0518158>] btrfs_relocate_chunk.isra.63+0x618/0x790 [btrfs]
        [<ffffffffa051bc27>] btrfs_balance+0x8f7/0xe90 [btrfs]
        [<ffffffffa05240a0>] btrfs_ioctl_balance+0x250/0x550 [btrfs]
        [<ffffffffa05269ca>] btrfs_ioctl+0xdfa/0x25f0 [btrfs]
        [<ffffffff8119c936>] do_vfs_ioctl+0x96/0x570
        [<ffffffff8119cea1>] SyS_ioctl+0x91/0xb0
        [<ffffffff81750242>] system_call_fastpath+0x16/0x1b
        [<ffffffffffffffff>] 0xffffffffffffffff
    
    This affects btrfs-next, revision be8e3cd00d7293dd177e3f8a4a1645ce09ca3acb
    (Btrfs: separate out tests into their own directory).
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 00914a62abec..c60372de6647 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3484,6 +3484,8 @@ static void free_fs_root(struct btrfs_root *root)
 {
 	iput(root->cache_inode);
 	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
+	btrfs_free_block_rsv(root, root->orphan_block_rsv);
+	root->orphan_block_rsv = NULL;
 	if (root->anon_dev)
 		free_anon_bdev(root->anon_dev);
 	free_extent_buffer(root->node);
@@ -3641,6 +3643,9 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_free_stripe_hash_table(fs_info);
 
+	btrfs_free_block_rsv(root, root->orphan_block_rsv);
+	root->orphan_block_rsv = NULL;
+
 	return 0;
 }
 

commit f420ee1e923b931eeef5e2928791e84b1197cab3
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:24 2013 +0200

    Btrfs: add mount option to force UUID tree checking
    
    This should never be needed, but since all functions are there
    to check and rebuild the UUID tree, a mount option is added that
    allows to force this check and rebuild procedure.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e7ef82ad0d26..00914a62abec 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2929,7 +2929,8 @@ int open_ctree(struct super_block *sb,
 			close_ctree(tree_root);
 			return ret;
 		}
-	} else if (check_uuid_tree) {
+	} else if (check_uuid_tree ||
+		   btrfs_test_opt(tree_root, RESCAN_UUID_TREE)) {
 		pr_info("btrfs: checking UUID tree\n");
 		ret = btrfs_check_uuid_tree(fs_info);
 		if (ret) {

commit 70f801754728017ebc909d603c69255dc1e6f06f
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:23 2013 +0200

    Btrfs: check UUID tree during mount if required
    
    If the filesystem was mounted with an old kernel that was not
    aware of the UUID tree, this is detected by looking at the
    uuid_tree_generation field of the superblock (similar to how
    the free space cache is doing it). If a mismatch is detected
    at mount time, a thread is started that does two things:
    1. Iterate through the UUID tree, check each entry, delete those
       entries that are not valid anymore (i.e., the subvol does not
       exist anymore or the value changed).
    2. Iterate through the root tree, for each found subvolume, add
       the UUID tree entries for the subvolume (if they are not
       already there).
    
    This mechanism is also used to handle and repair errors that
    happened during the initial creation and filling of the tree.
    The update of the uuid_tree_generation field (which indicates
    that the state of the UUID tree is up to date) is blocked until
    all create and repair operations are successfully completed.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fa49e900216a..e7ef82ad0d26 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2120,7 +2120,8 @@ int open_ctree(struct super_block *sb,
 	int err = -EINVAL;
 	int num_backups_tried = 0;
 	int backup_index = 0;
-	bool create_uuid_tree = false;
+	bool create_uuid_tree;
+	bool check_uuid_tree;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info);
@@ -2724,9 +2725,13 @@ int open_ctree(struct super_block *sb,
 		if (ret != -ENOENT)
 			goto recovery_tree_root;
 		create_uuid_tree = true;
+		check_uuid_tree = false;
 	} else {
 		uuid_root->track_dirty = 1;
 		fs_info->uuid_root = uuid_root;
+		create_uuid_tree = false;
+		check_uuid_tree =
+		    generation != btrfs_super_uuid_tree_generation(disk_super);
 	}
 
 	fs_info->generation = generation;
@@ -2924,6 +2929,17 @@ int open_ctree(struct super_block *sb,
 			close_ctree(tree_root);
 			return ret;
 		}
+	} else if (check_uuid_tree) {
+		pr_info("btrfs: checking UUID tree\n");
+		ret = btrfs_check_uuid_tree(fs_info);
+		if (ret) {
+			pr_warn("btrfs: failed to check the UUID tree %d\n",
+				ret);
+			close_ctree(tree_root);
+			return ret;
+		}
+	} else {
+		fs_info->update_uuid_tree_gen = 1;
 	}
 
 	return 0;

commit 803b2f54fb4faf6d76fca43e59bcc555d9713cd4
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:21 2013 +0200

    Btrfs: fill UUID tree initially
    
    When the UUID tree is initially created, a task is spawned that
    walks through the root tree. For each found subvolume root_item,
    the uuid and received_uuid entries in the UUID tree are added.
    This is such a quick operation so that in case somebody wants
    to unmount the filesystem while the task is still running, the
    unmount is delayed until the UUID tree building task is finished.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 80bd63738c6d..fa49e900216a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -31,6 +31,7 @@
 #include <linux/migrate.h>
 #include <linux/ratelimit.h>
 #include <linux/uuid.h>
+#include <linux/semaphore.h>
 #include <asm/unaligned.h>
 #include "compat.h"
 #include "ctree.h"
@@ -2297,6 +2298,7 @@ int open_ctree(struct super_block *sb,
 	init_rwsem(&fs_info->extent_commit_sem);
 	init_rwsem(&fs_info->cleanup_work_sem);
 	init_rwsem(&fs_info->subvol_sem);
+	sema_init(&fs_info->uuid_tree_rescan_sem, 1);
 	fs_info->dev_replace.lock_owner = 0;
 	atomic_set(&fs_info->dev_replace.nesting_level, 0);
 	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
@@ -3554,6 +3556,11 @@ int close_ctree(struct btrfs_root *root)
 	fs_info->closing = 1;
 	smp_mb();
 
+	/* wait for the uuid_scan task to finish */
+	down(&fs_info->uuid_tree_rescan_sem);
+	/* avoid complains from lockdep et al., set sem back to initial state */
+	up(&fs_info->uuid_tree_rescan_sem);
+
 	/* pause restriper - we want to resume on mount */
 	btrfs_pause_balance(fs_info);
 

commit f7a81ea4cc6bdb51d8267d2f3ff485f0b4070074
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Thu Aug 15 17:11:19 2013 +0200

    Btrfs: create UUID tree if required
    
    This tree is not created by mkfs.btrfs. Therefore when a filesystem
    is mounted writable and the UUID tree does not exist, this tree is
    created if required. The tree is also added to the fs_info structure
    and initialized, but this commit does not yet read or write UUID tree
    elements.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f96a237bb40a..80bd63738c6d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1586,6 +1586,9 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	if (location->objectid == BTRFS_QUOTA_TREE_OBJECTID)
 		return fs_info->quota_root ? fs_info->quota_root :
 					     ERR_PTR(-ENOENT);
+	if (location->objectid == BTRFS_UUID_TREE_OBJECTID)
+		return fs_info->uuid_root ? fs_info->uuid_root :
+					    ERR_PTR(-ENOENT);
 again:
 	root = btrfs_lookup_fs_root(fs_info, location->objectid);
 	if (root)
@@ -2044,6 +2047,12 @@ static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 		info->quota_root->node = NULL;
 		info->quota_root->commit_root = NULL;
 	}
+	if (info->uuid_root) {
+		free_extent_buffer(info->uuid_root->node);
+		free_extent_buffer(info->uuid_root->commit_root);
+		info->uuid_root->node = NULL;
+		info->uuid_root->commit_root = NULL;
+	}
 	if (chunk_root) {
 		free_extent_buffer(info->chunk_root->node);
 		free_extent_buffer(info->chunk_root->commit_root);
@@ -2104,11 +2113,13 @@ int open_ctree(struct super_block *sb,
 	struct btrfs_root *chunk_root;
 	struct btrfs_root *dev_root;
 	struct btrfs_root *quota_root;
+	struct btrfs_root *uuid_root;
 	struct btrfs_root *log_tree_root;
 	int ret;
 	int err = -EINVAL;
 	int num_backups_tried = 0;
 	int backup_index = 0;
+	bool create_uuid_tree = false;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info);
@@ -2704,6 +2715,18 @@ int open_ctree(struct super_block *sb,
 		fs_info->quota_root = quota_root;
 	}
 
+	location.objectid = BTRFS_UUID_TREE_OBJECTID;
+	uuid_root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(uuid_root)) {
+		ret = PTR_ERR(uuid_root);
+		if (ret != -ENOENT)
+			goto recovery_tree_root;
+		create_uuid_tree = true;
+	} else {
+		uuid_root->track_dirty = 1;
+		fs_info->uuid_root = uuid_root;
+	}
+
 	fs_info->generation = generation;
 	fs_info->last_trans_committed = generation;
 
@@ -2890,6 +2913,17 @@ int open_ctree(struct super_block *sb,
 
 	btrfs_qgroup_rescan_resume(fs_info);
 
+	if (create_uuid_tree) {
+		pr_info("btrfs: creating UUID tree\n");
+		ret = btrfs_create_uuid_tree(fs_info);
+		if (ret) {
+			pr_warn("btrfs: failed to create the UUID tree %d\n",
+				ret);
+			close_ctree(tree_root);
+			return ret;
+		}
+	}
+
 	return 0;
 
 fail_qgroup:

commit 171170c1c5625cab9687ecf6714e09e0c8a6ed3c
Author: Sergei Trofimovich <slyfox@gentoo.org>
Date:   Wed Aug 14 23:27:46 2013 +0300

    btrfs: mark some local function as 'static'
    
    Cc: Josef Bacik <jbacik@fusionio.com>
    Cc: Chris Mason <chris.mason@fusionio.com>
    Signed-off-by: Sergei Trofimovich <slyfox@gentoo.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 77a9d46b5cdb..f96a237bb40a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1534,8 +1534,8 @@ int btrfs_init_fs_root(struct btrfs_root *root)
 	return ret;
 }
 
-struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
-					u64 root_id)
+static struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
+					       u64 root_id)
 {
 	struct btrfs_root *root;
 

commit 35a3621beb3e2face3e7954eaee20a8fa0043fac
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Aug 14 18:12:25 2013 +0200

    Btrfs: get rid of sparse warnings
    
    make C=2 fs/btrfs/ CF=-D__CHECK_ENDIAN__
    
    I tried to filter out the warnings for which patches have already
    been sent to the mailing list, pending for inclusion in btrfs-next.
    
    All these changes should be obviously safe.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 68391ecf2c59..77a9d46b5cdb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1433,8 +1433,8 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	return 0;
 }
 
-struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
-					struct btrfs_key *key)
+static struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
+					       struct btrfs_key *key)
 {
 	struct btrfs_root *root;
 	struct btrfs_fs_info *fs_info = tree_root->fs_info;
@@ -3754,8 +3754,8 @@ static void btrfs_destroy_all_ordered_extents(struct btrfs_fs_info *fs_info)
 	spin_unlock(&fs_info->ordered_root_lock);
 }
 
-int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
-			       struct btrfs_root *root)
+static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
+				      struct btrfs_root *root)
 {
 	struct rb_node *node;
 	struct btrfs_delayed_ref_root *delayed_refs;

commit 9ffba8cda917c0158857426f0e74b64d0206aaa9
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Aug 14 11:33:56 2013 -0400

    Btrfs: fix heavy delalloc related deadlock
    
    I added a patch where we started taking the ordered operations mutex when we
    waited on ordered extents.  We need this because we splice the list and process
    it, so if a flusher came in during this scenario it would think the list was
    empty and we'd usually get an early ENOSPC.  The problem with this is that this
    lock is used in transaction committing.  So we end up with something like this
    
    Transaction commit
            -> wait on writers
    
    Delalloc flusher
            -> run_ordered_operations (holds mutex)
                    ->wait for filemap-flush to do its thing
    
    flush task
            -> cow_file_range
                    ->wait on btrfs_join_transaction because we're commiting
    
    some other task
            -> commit_transaction because we notice trans->transaction->flush is set
                    -> run_ordered_operations (hang on mutex)
    
    We need to disentangle the ordered operations flushing from the delalloc
    flushing, since they are separate things.  This solves the deadlock issue I was
    seeing.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 572e21eb644c..68391ecf2c59 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2277,6 +2277,7 @@ int open_ctree(struct super_block *sb,
 
 
 	mutex_init(&fs_info->ordered_operations_mutex);
+	mutex_init(&fs_info->ordered_extent_flush_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
 	mutex_init(&fs_info->chunk_mutex);
 	mutex_init(&fs_info->transaction_kthread_mutex);

commit 8b87dc17fbc7443bf4c6c096279c35e89fb51326
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Aug 1 18:14:52 2013 +0200

    btrfs: add mount option to set commit interval
    
    I'ts hardcoded to 30 seconds which is fine for most users. Higher values
    defer data being synced to permanent storage with obvious consequences
    when the system crashes. The upper bound is not forced, but a warning is
    printed if it's more than 300 seconds (5 minutes).
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2a378abb03fb..572e21eb644c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1742,7 +1742,7 @@ static int transaction_kthread(void *arg)
 
 	do {
 		cannot_commit = false;
-		delay = HZ * 30;
+		delay = HZ * root->fs_info->commit_interval;
 		mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
 		spin_lock(&root->fs_info->trans_lock);
@@ -1754,7 +1754,8 @@ static int transaction_kthread(void *arg)
 
 		now = get_seconds();
 		if (cur->state < TRANS_STATE_BLOCKED &&
-		    (now < cur->start_time || now - cur->start_time < 30)) {
+		    (now < cur->start_time ||
+		     now - cur->start_time < root->fs_info->commit_interval)) {
 			spin_unlock(&root->fs_info->trans_lock);
 			delay = HZ * 5;
 			goto sleep;
@@ -2194,6 +2195,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->defrag_inodes = RB_ROOT;
 	fs_info->free_chunk_space = 0;
 	fs_info->tree_mod_log = RB_ROOT;
+	fs_info->commit_interval = BTRFS_DEFAULT_COMMIT_INTERVAL;
 
 	/* readahead state */
 	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_WAIT);

commit 0f0fe8f710f29dbd4b2c915fc1c36962e4957b3b
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Wed Jul 31 00:39:56 2013 +0100

    Btrfs: add missing error handling to read_tree_block
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 13564354c927..2a378abb03fb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1149,6 +1149,10 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 		return NULL;
 
 	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
+	if (ret) {
+		free_extent_buffer(buf);
+		return NULL;
+	}
 	return buf;
 
 }

commit 8068a47e2a77ecae27cfd0298e8732756f565ed1
Author: Anand Jain <Anand.Jain@oracle.com>
Date:   Fri Jul 26 01:29:35 2013 +0800

    btrfs: use BTRFS_SUPER_INFO_SIZE macro at btrfs_read_dev_super()
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8e2eee67c3a8..13564354c927 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2984,9 +2984,11 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 	 */
 	for (i = 0; i < 1; i++) {
 		bytenr = btrfs_sb_offset(i);
-		if (bytenr + 4096 >= i_size_read(bdev->bd_inode))
+		if (bytenr + BTRFS_SUPER_INFO_SIZE >=
+					i_size_read(bdev->bd_inode))
 			break;
-		bh = __bread(bdev, bytenr / 4096, 4096);
+		bh = __bread(bdev, bytenr / 4096,
+					BTRFS_SUPER_INFO_SIZE);
 		if (!bh)
 			continue;
 

commit facc8a2247340a9735fe8cc123c5da2102f5ef1b
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jul 25 19:22:34 2013 +0800

    Btrfs: don't cache the csum value into the extent state tree
    
    Before applying this patch, we cached the csum value into the extent state
    tree when reading some data from the disk, this operation increased the lock
    contention of the state tree.
    
    Now, we just store the csum value into the bio structure or other unshared
    structure, so we can reduce the lock contention.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 56fcf8439f42..8e2eee67c3a8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -576,8 +576,9 @@ static noinline int check_leaf(struct btrfs_root *root,
 	return 0;
 }
 
-static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
-			       struct extent_state *state, int mirror)
+static int btree_readpage_end_io_hook(struct btrfs_io_bio *io_bio,
+				      u64 phy_offset, struct page *page,
+				      u64 start, u64 end, int mirror)
 {
 	struct extent_io_tree *tree;
 	u64 found_start;

commit 3cae210fa529d69cb25c2a3c491f29dab687b245
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Jul 16 11:19:18 2013 +0800

    btrfs: Cleanup for using BTRFS_SETGET_STACK instead of raw convert
    
    Some codes still use the cpu_to_lexx instead of the
    BTRFS_SETGET_STACK_FUNCS declared in ctree.h.
    
    Also added some BTRFS_SETGET_STACK_FUNCS for btrfs_header btrfs_timespec
    and other structures.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Miao Xie <miaoxie@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6b092a1c4e37..56fcf8439f42 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1413,11 +1413,11 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	log_root->root_key.offset = root->root_key.objectid;
 
 	inode_item = &log_root->root_item.inode;
-	inode_item->generation = cpu_to_le64(1);
-	inode_item->size = cpu_to_le64(3);
-	inode_item->nlink = cpu_to_le32(1);
-	inode_item->nbytes = cpu_to_le64(root->leafsize);
-	inode_item->mode = cpu_to_le32(S_IFDIR | 0755);
+	btrfs_set_stack_inode_generation(inode_item, 1);
+	btrfs_set_stack_inode_size(inode_item, 3);
+	btrfs_set_stack_inode_nlink(inode_item, 1);
+	btrfs_set_stack_inode_nbytes(inode_item, root->leafsize);
+	btrfs_set_stack_inode_mode(inode_item, S_IFDIR | 0755);
 
 	btrfs_set_root_node(&log_root->root_item, log_root->node);
 
@@ -2575,7 +2575,7 @@ int open_ctree(struct super_block *sb,
 	sb->s_blocksize = sectorsize;
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
 
-	if (disk_super->magic != cpu_to_le64(BTRFS_MAGIC)) {
+	if (btrfs_super_magic(disk_super) != BTRFS_MAGIC) {
 		printk(KERN_INFO "btrfs: valid FS not found on %s\n", sb->s_id);
 		goto fail_sb_buffer;
 	}
@@ -2991,7 +2991,7 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 
 		super = (struct btrfs_super_block *)bh->b_data;
 		if (btrfs_super_bytenr(super) != bytenr ||
-		    super->magic != cpu_to_le64(BTRFS_MAGIC)) {
+		    btrfs_super_magic(super) != BTRFS_MAGIC) {
 			brelse(bh);
 			continue;
 		}

commit e3a0dd98e1ddfd135b7ef889fcc0269e8c2ca445
Merge: da89bd213fe7 0e267c44c3a4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 9 12:33:09 2013 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs update from Chris Mason:
     "These are the usual mixture of bugs, cleanups and performance fixes.
      Miao has some really nice tuning of our crc code as well as our
      transaction commits.
    
      Josef is peeling off more and more problems related to early enospc,
      and has a number of important bug fixes in here too"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (81 commits)
      Btrfs: wait ordered range before doing direct io
      Btrfs: only do the tree_mod_log_free_eb if this is our last ref
      Btrfs: hold the tree mod lock in __tree_mod_log_rewind
      Btrfs: make backref walking code handle skinny metadata
      Btrfs: fix crash regarding to ulist_add_merge
      Btrfs: fix several potential problems in copy_nocow_pages_for_inode
      Btrfs: cleanup the code of copy_nocow_pages_for_inode()
      Btrfs: fix oops when recovering the file data by scrub function
      Btrfs: make the chunk allocator completely tree lockless
      Btrfs: cleanup orphaned root orphan item
      Btrfs: fix wrong mirror number tuning
      Btrfs: cleanup redundant code in btrfs_submit_direct()
      Btrfs: remove btrfs_sector_sum structure
      Btrfs: check if we can nocow if we don't have data space
      Btrfs: stop using try_to_writeback_inodes_sb_nr to flush delalloc
      Btrfs: use a percpu to keep track of possibly pinned bytes
      Btrfs: check for actual acls rather than just xattrs when caching no acl
      Btrfs: move btrfs_truncate_page to btrfs_cont_expand instead of btrfs_truncate
      Btrfs: optimize reada_for_balance
      Btrfs: optimize read_block_for_search
      ...

commit 9e239bb93914e1c832d54161c7f8f398d0c914ab
Merge: 63580e51bb3e 6ae06ff51eab
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 2 09:39:34 2013 -0700

    Merge tag 'ext4_for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4
    
    Pull ext4 update from Ted Ts'o:
     "Lots of bug fixes, cleanups and optimizations.  In the bug fixes
      category, of note is a fix for on-line resizing file systems where the
      block size is smaller than the page size (i.e., file systems 1k blocks
      on x86, or more interestingly file systems with 4k blocks on Power or
      ia64 systems.)
    
      In the cleanup category, the ext4's punch hole implementation was
      significantly improved by Lukas Czerner, and now supports bigalloc
      file systems.  In addition, Jan Kara significantly cleaned up the
      write submission code path.  We also improved error checking and added
      a few sanity checks.
    
      In the optimizations category, two major optimizations deserve
      mention.  The first is that ext4_writepages() is now used for
      nodelalloc and ext3 compatibility mode.  This allows writes to be
      submitted much more efficiently as a single bio request, instead of
      being sent as individual 4k writes into the block layer (which then
      relied on the elevator code to coalesce the requests in the block
      queue).  Secondly, the extent cache shrink mechanism, which was
      introduce in 3.9, no longer has a scalability bottleneck caused by the
      i_es_lru spinlock.  Other optimizations include some changes to reduce
      CPU usage and to avoid issuing empty commits unnecessarily."
    
    * tag 'ext4_for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4: (86 commits)
      ext4: optimize starting extent in ext4_ext_rm_leaf()
      jbd2: invalidate handle if jbd2_journal_restart() fails
      ext4: translate flag bits to strings in tracepoints
      ext4: fix up error handling for mpage_map_and_submit_extent()
      jbd2: fix theoretical race in jbd2__journal_restart
      ext4: only zero partial blocks in ext4_zero_partial_blocks()
      ext4: check error return from ext4_write_inline_data_end()
      ext4: delete unnecessary C statements
      ext3,ext4: don't mess with dir_file->f_pos in htree_dirblock_to_tree()
      jbd2: move superblock checksum calculation to jbd2_write_superblock()
      ext4: pass inode pointer instead of file pointer to punch hole
      ext4: improve free space calculation for inline_data
      ext4: reduce object size when !CONFIG_PRINTK
      ext4: improve extent cache shrink mechanism to avoid to burn CPU time
      ext4: implement error handling of ext4_mb_new_preallocation()
      ext4: fix corruption when online resizing a fs with 1K block size
      ext4: delete unused variables
      ext4: return FIEMAP_EXTENT_UNKNOWN for delalloc extents
      jbd2: remove debug dependency on debug_fs and update Kconfig help text
      jbd2: use a single printk for jbd_debug()
      ...

commit e78417d1921c538ea195537c7bea1b31a6a55961
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Jun 3 16:42:36 2013 -0400

    Btrfs: do not pin while under spin lock
    
    When testing a corrupted fs I noticed I was getting sleep while atomic errors
    when the transaction aborted.  This is because btrfs_pin_extent may need to
    allocate memory and we are calling this under the spin lock.  Fix this by moving
    it out and doing the pin after dropping the spin lock but before dropping the
    mutex, the same way it works when delayed refs run normally.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9b7020197c71..3c2886ca7d8c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3762,6 +3762,7 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 
 	while ((node = rb_first(&delayed_refs->root)) != NULL) {
 		struct btrfs_delayed_ref_head *head = NULL;
+		bool pin_bytes = false;
 
 		ref = rb_entry(node, struct btrfs_delayed_ref_node, rb_node);
 		atomic_set(&ref->refs, 1);
@@ -3782,8 +3783,7 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 			}
 
 			if (head->must_insert_reserved)
-				btrfs_pin_extent(root, ref->bytenr,
-						 ref->num_bytes, 1);
+				pin_bytes = true;
 			btrfs_free_delayed_extent_op(head->extent_op);
 			delayed_refs->num_heads--;
 			if (list_empty(&head->cluster))
@@ -3794,9 +3794,13 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		ref->in_tree = 0;
 		rb_erase(&ref->rb_node, &delayed_refs->root);
 		delayed_refs->num_entries--;
-		if (head)
-			mutex_unlock(&head->mutex);
 		spin_unlock(&delayed_refs->lock);
+		if (head) {
+			if (pin_bytes)
+				btrfs_pin_extent(root, ref->bytenr,
+						 ref->num_bytes, 1);
+			mutex_unlock(&head->mutex);
+		}
 		btrfs_put_delayed_ref(ref);
 
 		cond_resched();

commit b382a324b60f4923e9fc8e11f023e4f493c51318
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Tue May 28 15:47:24 2013 +0000

    Btrfs: fix qgroup rescan resume on mount
    
    When called during mount, we cannot start the rescan worker thread until
    open_ctree is done. This commit restuctures the qgroup rescan internals to
    enable a clean deferral of the rescan resume operation.
    
    First of all, the struct qgroup_rescan is removed, saving us a malloc and
    some initialization synchronizations problems. Its only element (the worker
    struct) now lives within fs_info just as the rest of the rescan code.
    
    Then setting up a rescan worker is split into several reusable stages.
    Currently we have three different rescan startup scenarios:
            (A) rescan ioctl
            (B) rescan resume by mount
            (C) rescan by quota enable
    
    Each case needs its own combination of the four following steps:
            (1) set the progress [A, C: zero; B: state of umount]
            (2) commit the transaction [A]
            (3) set the counters [A, C: zero; B: state of umount]
            (4) start worker [A, B, C]
    
    qgroup_rescan_init does step (1). There's no extra function added to commit
    a transaction, we've got that already. qgroup_rescan_zero_tracking does
    step (3). Step (4) is nothing more than a call to the generic
    btrfs_queue_worker.
    
    We also get rid of a double check for the rescan progress during
    btrfs_qgroup_account_ref, which is no longer required due to having step 2
    from the list above.
    
    As a side effect, this commit prepares to move the rescan start code from
    btrfs_run_qgroups (which is run during commit) to a less time critical
    section.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b9eaa0f21144..9b7020197c71 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2879,6 +2879,8 @@ int open_ctree(struct super_block *sb,
 		return ret;
 	}
 
+	btrfs_qgroup_rescan_resume(fs_info);
+
 	return 0;
 
 fail_qgroup:

commit 4a9d8bdee368de78ace8b36da4eb2186afea162d
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri May 17 03:53:43 2013 +0000

    Btrfs: make the state of the transaction more readable
    
    We used 3 variants to track the state of the transaction, it was complex
    and wasted the memory space. Besides that, it was hard to understand that
    which types of the transaction handles should be blocked in each transaction
    state, so the developers often made mistakes.
    
    This patch improved the above problem. In this patch, we define 6 states
    for the transaction,
      enum btrfs_trans_state {
            TRANS_STATE_RUNNING             = 0,
            TRANS_STATE_BLOCKED             = 1,
            TRANS_STATE_COMMIT_START        = 2,
            TRANS_STATE_COMMIT_DOING        = 3,
            TRANS_STATE_UNBLOCKED           = 4,
            TRANS_STATE_COMPLETED           = 5,
            TRANS_STATE_MAX                 = 6,
      }
    and just use 1 variant to track those state.
    
    In order to make the blocked handle types for each state more clear,
    we introduce a array:
      unsigned int btrfs_blocked_trans_types[TRANS_STATE_MAX] = {
            [TRANS_STATE_RUNNING]           = 0U,
            [TRANS_STATE_BLOCKED]           = (__TRANS_USERSPACE |
                                               __TRANS_START),
            [TRANS_STATE_COMMIT_START]      = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH),
            [TRANS_STATE_COMMIT_DOING]      = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH |
                                               __TRANS_JOIN),
            [TRANS_STATE_UNBLOCKED]         = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH |
                                               __TRANS_JOIN |
                                               __TRANS_JOIN_NOLOCK),
            [TRANS_STATE_COMPLETED]         = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH |
                                               __TRANS_JOIN |
                                               __TRANS_JOIN_NOLOCK),
      }
    it is very intuitionistic.
    
    Besides that, because we remove ->in_commit in transaction structure, so
    the lock ->commit_lock which was used to protect it is unnecessary, remove
    ->commit_lock.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 885245f5acdc..b9eaa0f21144 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1747,7 +1747,7 @@ static int transaction_kthread(void *arg)
 		}
 
 		now = get_seconds();
-		if (!cur->blocked &&
+		if (cur->state < TRANS_STATE_BLOCKED &&
 		    (now < cur->start_time || now - cur->start_time < 30)) {
 			spin_unlock(&root->fs_info->trans_lock);
 			delay = HZ * 5;
@@ -2186,7 +2186,6 @@ int open_ctree(struct super_block *sb,
 	fs_info->max_inline = 8192 * 1024;
 	fs_info->metadata_ratio = 0;
 	fs_info->defrag_inodes = RB_ROOT;
-	fs_info->trans_no_join = 0;
 	fs_info->free_chunk_space = 0;
 	fs_info->tree_mod_log = RB_ROOT;
 
@@ -3958,19 +3957,14 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	btrfs_block_rsv_release(root, &root->fs_info->trans_block_rsv,
 				cur_trans->dirty_pages.dirty_bytes);
 
-	/* FIXME: cleanup wait for commit */
-	cur_trans->in_commit = 1;
-	cur_trans->blocked = 1;
+	cur_trans->state = TRANS_STATE_COMMIT_START;
 	wake_up(&root->fs_info->transaction_blocked_wait);
 
 	btrfs_evict_pending_snapshots(cur_trans);
 
-	cur_trans->blocked = 0;
+	cur_trans->state = TRANS_STATE_UNBLOCKED;
 	wake_up(&root->fs_info->transaction_wait);
 
-	cur_trans->commit_done = 1;
-	wake_up(&cur_trans->commit_wait);
-
 	btrfs_destroy_delayed_inodes(root);
 	btrfs_assert_delayed_root_empty(root);
 
@@ -3979,6 +3973,9 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	btrfs_destroy_pinned_extent(root,
 				    root->fs_info->pinned_extents);
 
+	cur_trans->state =TRANS_STATE_COMPLETED;
+	wake_up(&cur_trans->commit_wait);
+
 	/*
 	memset(cur_trans, 0, sizeof(*cur_trans));
 	kmem_cache_free(btrfs_transaction_cachep, cur_trans);
@@ -4006,25 +4003,23 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 
 		btrfs_destroy_delayed_refs(t, root);
 
-		/* FIXME: cleanup wait for commit */
-		t->in_commit = 1;
-		t->blocked = 1;
+		/*
+		 *  FIXME: cleanup wait for commit
+		 *  We needn't acquire the lock here, because we are during
+		 *  the umount, there is no other task which will change it.
+		 */
+		t->state = TRANS_STATE_COMMIT_START;
 		smp_mb();
 		if (waitqueue_active(&root->fs_info->transaction_blocked_wait))
 			wake_up(&root->fs_info->transaction_blocked_wait);
 
 		btrfs_evict_pending_snapshots(t);
 
-		t->blocked = 0;
+		t->state = TRANS_STATE_UNBLOCKED;
 		smp_mb();
 		if (waitqueue_active(&root->fs_info->transaction_wait))
 			wake_up(&root->fs_info->transaction_wait);
 
-		t->commit_done = 1;
-		smp_mb();
-		if (waitqueue_active(&t->commit_wait))
-			wake_up(&t->commit_wait);
-
 		btrfs_destroy_delayed_inodes(root);
 		btrfs_assert_delayed_root_empty(root);
 
@@ -4036,6 +4031,11 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 		btrfs_destroy_pinned_extent(root,
 					    root->fs_info->pinned_extents);
 
+		t->state = TRANS_STATE_COMPLETED;
+		smp_mb();
+		if (waitqueue_active(&t->commit_wait))
+			wake_up(&t->commit_wait);
+
 		atomic_set(&t->use_count, 0);
 		list_del_init(&t->list);
 		memset(t, 0, sizeof(*t));

commit ac6738792fe4478df2da9c1f41e3540e9ef79604
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:25 2013 +0000

    Btrfs: cleanup unnecessary assignment when cleaning up all the residual transaction
    
    When we umount a fs with serious errors, we will invoke btrfs_cleanup_transactions()
    to clean up the residual transaction. At this time, It is impossible to start a new
    transaction, so we needn't assign trans_no_join to 1, and also needn't clear running
    transaction every time we destroy a residual transaction.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0f873872d1f8..885245f5acdc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3994,7 +3994,7 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 
 	spin_lock(&root->fs_info->trans_lock);
 	list_splice_init(&root->fs_info->trans_list, &list);
-	root->fs_info->trans_no_join = 1;
+	root->fs_info->running_transaction = NULL;
 	spin_unlock(&root->fs_info->trans_lock);
 
 	while (!list_empty(&list)) {
@@ -4030,10 +4030,6 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 
 		btrfs_destroy_all_delalloc_inodes(root->fs_info);
 
-		spin_lock(&root->fs_info->trans_lock);
-		root->fs_info->running_transaction = NULL;
-		spin_unlock(&root->fs_info->trans_lock);
-
 		btrfs_destroy_marked_extents(root, &t->dirty_pages,
 					     EXTENT_DIRTY);
 
@@ -4046,9 +4042,6 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 		kmem_cache_free(btrfs_transaction_cachep, t);
 	}
 
-	spin_lock(&root->fs_info->trans_lock);
-	root->fs_info->trans_no_join = 0;
-	spin_unlock(&root->fs_info->trans_lock);
 	mutex_unlock(&root->fs_info->transaction_kthread_mutex);
 
 	return 0;

commit 199c2a9c3d1389db7f7a211e64f6809d352ce5f6
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:23 2013 +0000

    Btrfs: introduce per-subvolume ordered extent list
    
    The reason we introduce per-subvolume ordered extent list is the same
    as the per-subvolume delalloc inode list.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2748c7ccdd51..0f873872d1f8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1192,6 +1192,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->last_trans = 0;
 	root->highest_objectid = 0;
 	root->nr_delalloc_inodes = 0;
+	root->nr_ordered_extents = 0;
 	root->name = NULL;
 	root->inode_tree = RB_ROOT;
 	INIT_RADIX_TREE(&root->delayed_nodes_tree, GFP_ATOMIC);
@@ -1202,11 +1203,14 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	INIT_LIST_HEAD(&root->root_list);
 	INIT_LIST_HEAD(&root->delalloc_inodes);
 	INIT_LIST_HEAD(&root->delalloc_root);
+	INIT_LIST_HEAD(&root->ordered_extents);
+	INIT_LIST_HEAD(&root->ordered_root);
 	INIT_LIST_HEAD(&root->logged_list[0]);
 	INIT_LIST_HEAD(&root->logged_list[1]);
 	spin_lock_init(&root->orphan_lock);
 	spin_lock_init(&root->inode_lock);
 	spin_lock_init(&root->delalloc_lock);
+	spin_lock_init(&root->ordered_extent_lock);
 	spin_lock_init(&root->accounting_lock);
 	spin_lock_init(&root->log_extents_lock[0]);
 	spin_lock_init(&root->log_extents_lock[1]);
@@ -2193,8 +2197,8 @@ int open_ctree(struct super_block *sb,
 	fs_info->thread_pool_size = min_t(unsigned long,
 					  num_online_cpus() + 2, 8);
 
-	INIT_LIST_HEAD(&fs_info->ordered_extents);
-	spin_lock_init(&fs_info->ordered_extent_lock);
+	INIT_LIST_HEAD(&fs_info->ordered_roots);
+	spin_lock_init(&fs_info->ordered_root_lock);
 	fs_info->delayed_root = kmalloc(sizeof(struct btrfs_delayed_root),
 					GFP_NOFS);
 	if (!fs_info->delayed_root) {
@@ -3683,7 +3687,7 @@ static void btrfs_destroy_ordered_operations(struct btrfs_transaction *t,
 	INIT_LIST_HEAD(&splice);
 
 	mutex_lock(&root->fs_info->ordered_operations_mutex);
-	spin_lock(&root->fs_info->ordered_extent_lock);
+	spin_lock(&root->fs_info->ordered_root_lock);
 
 	list_splice_init(&t->ordered_operations, &splice);
 	while (!list_empty(&splice)) {
@@ -3691,14 +3695,14 @@ static void btrfs_destroy_ordered_operations(struct btrfs_transaction *t,
 					 ordered_operations);
 
 		list_del_init(&btrfs_inode->ordered_operations);
-		spin_unlock(&root->fs_info->ordered_extent_lock);
+		spin_unlock(&root->fs_info->ordered_root_lock);
 
 		btrfs_invalidate_inodes(btrfs_inode->root);
 
-		spin_lock(&root->fs_info->ordered_extent_lock);
+		spin_lock(&root->fs_info->ordered_root_lock);
 	}
 
-	spin_unlock(&root->fs_info->ordered_extent_lock);
+	spin_unlock(&root->fs_info->ordered_root_lock);
 	mutex_unlock(&root->fs_info->ordered_operations_mutex);
 }
 
@@ -3706,15 +3710,36 @@ static void btrfs_destroy_ordered_extents(struct btrfs_root *root)
 {
 	struct btrfs_ordered_extent *ordered;
 
-	spin_lock(&root->fs_info->ordered_extent_lock);
+	spin_lock(&root->ordered_extent_lock);
 	/*
 	 * This will just short circuit the ordered completion stuff which will
 	 * make sure the ordered extent gets properly cleaned up.
 	 */
-	list_for_each_entry(ordered, &root->fs_info->ordered_extents,
+	list_for_each_entry(ordered, &root->ordered_extents,
 			    root_extent_list)
 		set_bit(BTRFS_ORDERED_IOERR, &ordered->flags);
-	spin_unlock(&root->fs_info->ordered_extent_lock);
+	spin_unlock(&root->ordered_extent_lock);
+}
+
+static void btrfs_destroy_all_ordered_extents(struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_root *root;
+	struct list_head splice;
+
+	INIT_LIST_HEAD(&splice);
+
+	spin_lock(&fs_info->ordered_root_lock);
+	list_splice_init(&fs_info->ordered_roots, &splice);
+	while (!list_empty(&splice)) {
+		root = list_first_entry(&splice, struct btrfs_root,
+					ordered_root);
+		list_del_init(&root->ordered_root);
+
+		btrfs_destroy_ordered_extents(root);
+
+		cond_resched_lock(&fs_info->ordered_root_lock);
+	}
+	spin_unlock(&fs_info->ordered_root_lock);
 }
 
 int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
@@ -3977,7 +4002,7 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 
 		btrfs_destroy_ordered_operations(t, root);
 
-		btrfs_destroy_ordered_extents(root);
+		btrfs_destroy_all_ordered_extents(root->fs_info);
 
 		btrfs_destroy_delayed_refs(t, root);
 

commit eb73c1b7cea7d533288ef5297a0ea0e159db85b0
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:22 2013 +0000

    Btrfs: introduce per-subvolume delalloc inode list
    
    When we create a snapshot, we need flush all delalloc inodes in the
    fs, just flushing the inodes in the source tree is OK. So we introduce
    per-subvolume delalloc inode list.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 90b643e07f3c..2748c7ccdd51 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1191,6 +1191,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->objectid = objectid;
 	root->last_trans = 0;
 	root->highest_objectid = 0;
+	root->nr_delalloc_inodes = 0;
 	root->name = NULL;
 	root->inode_tree = RB_ROOT;
 	INIT_RADIX_TREE(&root->delayed_nodes_tree, GFP_ATOMIC);
@@ -1199,10 +1200,13 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 
 	INIT_LIST_HEAD(&root->dirty_list);
 	INIT_LIST_HEAD(&root->root_list);
+	INIT_LIST_HEAD(&root->delalloc_inodes);
+	INIT_LIST_HEAD(&root->delalloc_root);
 	INIT_LIST_HEAD(&root->logged_list[0]);
 	INIT_LIST_HEAD(&root->logged_list[1]);
 	spin_lock_init(&root->orphan_lock);
 	spin_lock_init(&root->inode_lock);
+	spin_lock_init(&root->delalloc_lock);
 	spin_lock_init(&root->accounting_lock);
 	spin_lock_init(&root->log_extents_lock[0]);
 	spin_lock_init(&root->log_extents_lock[1]);
@@ -2140,9 +2144,9 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->delayed_iputs);
-	INIT_LIST_HEAD(&fs_info->delalloc_inodes);
+	INIT_LIST_HEAD(&fs_info->delalloc_roots);
 	INIT_LIST_HEAD(&fs_info->caching_block_groups);
-	spin_lock_init(&fs_info->delalloc_lock);
+	spin_lock_init(&fs_info->delalloc_root_lock);
 	spin_lock_init(&fs_info->trans_lock);
 	spin_lock_init(&fs_info->fs_roots_radix_lock);
 	spin_lock_init(&fs_info->delayed_iput_lock);
@@ -3803,24 +3807,49 @@ static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
 
 	INIT_LIST_HEAD(&splice);
 
-	spin_lock(&root->fs_info->delalloc_lock);
-	list_splice_init(&root->fs_info->delalloc_inodes, &splice);
+	spin_lock(&root->delalloc_lock);
+	list_splice_init(&root->delalloc_inodes, &splice);
 
 	while (!list_empty(&splice)) {
-		btrfs_inode = list_entry(splice.next, struct btrfs_inode,
-				    delalloc_inodes);
+		btrfs_inode = list_first_entry(&splice, struct btrfs_inode,
+					       delalloc_inodes);
 
 		list_del_init(&btrfs_inode->delalloc_inodes);
 		clear_bit(BTRFS_INODE_IN_DELALLOC_LIST,
 			  &btrfs_inode->runtime_flags);
-		spin_unlock(&root->fs_info->delalloc_lock);
+		spin_unlock(&root->delalloc_lock);
 
 		btrfs_invalidate_inodes(btrfs_inode->root);
 
-		spin_lock(&root->fs_info->delalloc_lock);
+		spin_lock(&root->delalloc_lock);
 	}
 
-	spin_unlock(&root->fs_info->delalloc_lock);
+	spin_unlock(&root->delalloc_lock);
+}
+
+static void btrfs_destroy_all_delalloc_inodes(struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_root *root;
+	struct list_head splice;
+
+	INIT_LIST_HEAD(&splice);
+
+	spin_lock(&fs_info->delalloc_root_lock);
+	list_splice_init(&fs_info->delalloc_roots, &splice);
+	while (!list_empty(&splice)) {
+		root = list_first_entry(&splice, struct btrfs_root,
+					 delalloc_root);
+		list_del_init(&root->delalloc_root);
+		root = btrfs_grab_fs_root(root);
+		BUG_ON(!root);
+		spin_unlock(&fs_info->delalloc_root_lock);
+
+		btrfs_destroy_delalloc_inodes(root);
+		btrfs_put_fs_root(root);
+
+		spin_lock(&fs_info->delalloc_root_lock);
+	}
+	spin_unlock(&fs_info->delalloc_root_lock);
 }
 
 static int btrfs_destroy_marked_extents(struct btrfs_root *root,
@@ -3974,7 +4003,7 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 		btrfs_destroy_delayed_inodes(root);
 		btrfs_assert_delayed_root_empty(root);
 
-		btrfs_destroy_delalloc_inodes(root);
+		btrfs_destroy_all_delalloc_inodes(root->fs_info);
 
 		spin_lock(&root->fs_info->trans_lock);
 		root->fs_info->running_transaction = NULL;

commit b0feb9d96e71a88d7eec56f41b8f23e92af889b0
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:20 2013 +0000

    Btrfs: introduce grab/put functions for the root of the fs/file tree
    
    The grab/put funtions will be used in the next patch, which need grab
    the root object and ensure it is not freed. We use reference counter
    instead of the srcu lock is to aovid blocking the memory reclaim task,
    which invokes synchronize_srcu().
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c65a5aac1e45..90b643e07f3c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1216,6 +1216,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	atomic_set(&root->log_writers, 0);
 	atomic_set(&root->log_batch, 0);
 	atomic_set(&root->orphan_inodes, 0);
+	atomic_set(&root->refs, 1);
 	root->log_transid = 0;
 	root->last_log_commit = 0;
 	extent_io_tree_init(&root->dirty_log_pages,
@@ -2052,7 +2053,7 @@ static void del_fs_roots(struct btrfs_fs_info *fs_info)
 		} else {
 			free_extent_buffer(gang[0]->node);
 			free_extent_buffer(gang[0]->commit_root);
-			kfree(gang[0]);
+			btrfs_put_fs_root(gang[0]);
 		}
 	}
 
@@ -3417,7 +3418,7 @@ static void free_fs_root(struct btrfs_root *root)
 	kfree(root->free_ino_ctl);
 	kfree(root->free_ino_pinned);
 	kfree(root->name);
-	kfree(root);
+	btrfs_put_fs_root(root);
 }
 
 void btrfs_free_fs_root(struct btrfs_root *root)

commit cb517eabba4f109810dba2e5f37b0dcf22103065
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:19 2013 +0000

    Btrfs: cleanup the similar code of the fs root read
    
    There are several functions whose code is similar, such as
      btrfs_find_last_root()
      btrfs_read_fs_root_no_radix()
    
    Besides that, some functions are invoked twice, it is unnecessary,
    for example, we are sure that all roots which is found in
      btrfs_find_orphan_roots()
    have their orphan items, so it is unnecessary to check the orphan
    item again.
    
    So cleanup it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8dbd908a3a97..c65a5aac1e45 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1234,39 +1234,6 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	spin_lock_init(&root->root_item_lock);
 }
 
-static int __must_check find_and_setup_root(struct btrfs_root *tree_root,
-					    struct btrfs_fs_info *fs_info,
-					    u64 objectid,
-					    struct btrfs_root *root)
-{
-	int ret;
-	u32 blocksize;
-	u64 generation;
-
-	__setup_root(tree_root->nodesize, tree_root->leafsize,
-		     tree_root->sectorsize, tree_root->stripesize,
-		     root, fs_info, objectid);
-	ret = btrfs_find_last_root(tree_root, objectid,
-				   &root->root_item, &root->root_key);
-	if (ret > 0)
-		return -ENOENT;
-	else if (ret < 0)
-		return ret;
-
-	generation = btrfs_root_generation(&root->root_item);
-	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
-	root->commit_root = NULL;
-	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
-				     blocksize, generation);
-	if (!root->node || !btrfs_buffer_uptodate(root->node, generation, 0)) {
-		free_extent_buffer(root->node);
-		root->node = NULL;
-		return -EIO;
-	}
-	root->commit_root = btrfs_root_node(root);
-	return 0;
-}
-
 static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info)
 {
 	struct btrfs_root *root = kzalloc(sizeof(*root), GFP_NOFS);
@@ -1451,70 +1418,73 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	return 0;
 }
 
-struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
-					       struct btrfs_key *location)
+struct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,
+					struct btrfs_key *key)
 {
 	struct btrfs_root *root;
 	struct btrfs_fs_info *fs_info = tree_root->fs_info;
 	struct btrfs_path *path;
-	struct extent_buffer *l;
 	u64 generation;
 	u32 blocksize;
-	int ret = 0;
-	int slot;
+	int ret;
 
-	root = btrfs_alloc_root(fs_info);
-	if (!root)
+	path = btrfs_alloc_path();
+	if (!path)
 		return ERR_PTR(-ENOMEM);
-	if (location->offset == (u64)-1) {
-		ret = find_and_setup_root(tree_root, fs_info,
-					  location->objectid, root);
-		if (ret) {
-			kfree(root);
-			return ERR_PTR(ret);
-		}
-		goto out;
+
+	root = btrfs_alloc_root(fs_info);
+	if (!root) {
+		ret = -ENOMEM;
+		goto alloc_fail;
 	}
 
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
 		     tree_root->sectorsize, tree_root->stripesize,
-		     root, fs_info, location->objectid);
+		     root, fs_info, key->objectid);
 
-	path = btrfs_alloc_path();
-	if (!path) {
-		kfree(root);
-		return ERR_PTR(-ENOMEM);
-	}
-	ret = btrfs_search_slot(NULL, tree_root, location, path, 0, 0);
-	if (ret == 0) {
-		l = path->nodes[0];
-		slot = path->slots[0];
-		btrfs_read_root_item(l, slot, &root->root_item);
-		memcpy(&root->root_key, location, sizeof(*location));
-	}
-	btrfs_free_path(path);
+	ret = btrfs_find_root(tree_root, key, path,
+			      &root->root_item, &root->root_key);
 	if (ret) {
-		kfree(root);
 		if (ret > 0)
 			ret = -ENOENT;
-		return ERR_PTR(ret);
+		goto find_fail;
 	}
 
 	generation = btrfs_root_generation(&root->root_item);
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
-	if (!root->node || !extent_buffer_uptodate(root->node)) {
-		ret = (!root->node) ? -ENOMEM : -EIO;
-
-		free_extent_buffer(root->node);
-		kfree(root);
-		return ERR_PTR(ret);
+	if (!root->node) {
+		ret = -ENOMEM;
+		goto find_fail;
+	} else if (!btrfs_buffer_uptodate(root->node, generation, 0)) {
+		ret = -EIO;
+		goto read_fail;
 	}
-
 	root->commit_root = btrfs_root_node(root);
 out:
-	if (location->objectid != BTRFS_TREE_LOG_OBJECTID) {
+	btrfs_free_path(path);
+	return root;
+
+read_fail:
+	free_extent_buffer(root->node);
+find_fail:
+	kfree(root);
+alloc_fail:
+	root = ERR_PTR(ret);
+	goto out;
+}
+
+struct btrfs_root *btrfs_read_fs_root(struct btrfs_root *tree_root,
+				      struct btrfs_key *location)
+{
+	struct btrfs_root *root;
+
+	root = btrfs_read_tree_root(tree_root, location);
+	if (IS_ERR(root))
+		return root;
+
+	if (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {
 		root->ref_cows = 1;
 		btrfs_check_and_init_root_item(&root->root_item);
 	}
@@ -1522,6 +1492,66 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	return root;
 }
 
+int btrfs_init_fs_root(struct btrfs_root *root)
+{
+	int ret;
+
+	root->free_ino_ctl = kzalloc(sizeof(*root->free_ino_ctl), GFP_NOFS);
+	root->free_ino_pinned = kzalloc(sizeof(*root->free_ino_pinned),
+					GFP_NOFS);
+	if (!root->free_ino_pinned || !root->free_ino_ctl) {
+		ret = -ENOMEM;
+		goto fail;
+	}
+
+	btrfs_init_free_ino_ctl(root);
+	mutex_init(&root->fs_commit_mutex);
+	spin_lock_init(&root->cache_lock);
+	init_waitqueue_head(&root->cache_wait);
+
+	ret = get_anon_bdev(&root->anon_dev);
+	if (ret)
+		goto fail;
+	return 0;
+fail:
+	kfree(root->free_ino_ctl);
+	kfree(root->free_ino_pinned);
+	return ret;
+}
+
+struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
+					u64 root_id)
+{
+	struct btrfs_root *root;
+
+	spin_lock(&fs_info->fs_roots_radix_lock);
+	root = radix_tree_lookup(&fs_info->fs_roots_radix,
+				 (unsigned long)root_id);
+	spin_unlock(&fs_info->fs_roots_radix_lock);
+	return root;
+}
+
+int btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,
+			 struct btrfs_root *root)
+{
+	int ret;
+
+	ret = radix_tree_preload(GFP_NOFS & ~__GFP_HIGHMEM);
+	if (ret)
+		return ret;
+
+	spin_lock(&fs_info->fs_roots_radix_lock);
+	ret = radix_tree_insert(&fs_info->fs_roots_radix,
+				(unsigned long)root->root_key.objectid,
+				root);
+	if (ret == 0)
+		root->in_radix = 1;
+	spin_unlock(&fs_info->fs_roots_radix_lock);
+	radix_tree_preload_end();
+
+	return ret;
+}
+
 struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 					      struct btrfs_key *location)
 {
@@ -1542,58 +1572,30 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 		return fs_info->quota_root ? fs_info->quota_root :
 					     ERR_PTR(-ENOENT);
 again:
-	spin_lock(&fs_info->fs_roots_radix_lock);
-	root = radix_tree_lookup(&fs_info->fs_roots_radix,
-				 (unsigned long)location->objectid);
-	spin_unlock(&fs_info->fs_roots_radix_lock);
+	root = btrfs_lookup_fs_root(fs_info, location->objectid);
 	if (root)
 		return root;
 
-	root = btrfs_read_fs_root_no_radix(fs_info->tree_root, location);
+	root = btrfs_read_fs_root(fs_info->tree_root, location);
 	if (IS_ERR(root))
 		return root;
 
-	root->free_ino_ctl = kzalloc(sizeof(*root->free_ino_ctl), GFP_NOFS);
-	root->free_ino_pinned = kzalloc(sizeof(*root->free_ino_pinned),
-					GFP_NOFS);
-	if (!root->free_ino_pinned || !root->free_ino_ctl) {
-		ret = -ENOMEM;
+	if (btrfs_root_refs(&root->root_item) == 0) {
+		ret = -ENOENT;
 		goto fail;
 	}
 
-	btrfs_init_free_ino_ctl(root);
-	mutex_init(&root->fs_commit_mutex);
-	spin_lock_init(&root->cache_lock);
-	init_waitqueue_head(&root->cache_wait);
-
-	ret = get_anon_bdev(&root->anon_dev);
+	ret = btrfs_init_fs_root(root);
 	if (ret)
 		goto fail;
 
-	if (btrfs_root_refs(&root->root_item) == 0) {
-		ret = -ENOENT;
-		goto fail;
-	}
-
 	ret = btrfs_find_orphan_item(fs_info->tree_root, location->objectid);
 	if (ret < 0)
 		goto fail;
 	if (ret == 0)
 		root->orphan_item_inserted = 1;
 
-	ret = radix_tree_preload(GFP_NOFS & ~__GFP_HIGHMEM);
-	if (ret)
-		goto fail;
-
-	spin_lock(&fs_info->fs_roots_radix_lock);
-	ret = radix_tree_insert(&fs_info->fs_roots_radix,
-				(unsigned long)root->root_key.objectid,
-				root);
-	if (ret == 0)
-		root->in_radix = 1;
-
-	spin_unlock(&fs_info->fs_roots_radix_lock);
-	radix_tree_preload_end();
+	ret = btrfs_insert_fs_root(fs_info, root);
 	if (ret) {
 		if (ret == -EEXIST) {
 			free_fs_root(root);
@@ -1601,10 +1603,6 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 		}
 		goto fail;
 	}
-
-	ret = btrfs_find_dead_roots(fs_info->tree_root,
-				    root->root_key.objectid);
-	WARN_ON(ret);
 	return root;
 fail:
 	free_fs_root(root);
@@ -2050,7 +2048,7 @@ static void del_fs_roots(struct btrfs_fs_info *fs_info)
 		list_del(&gang[0]->root_list);
 
 		if (gang[0]->in_radix) {
-			btrfs_free_fs_root(fs_info, gang[0]);
+			btrfs_drop_and_free_fs_root(fs_info, gang[0]);
 		} else {
 			free_extent_buffer(gang[0]->node);
 			free_extent_buffer(gang[0]->commit_root);
@@ -2065,7 +2063,7 @@ static void del_fs_roots(struct btrfs_fs_info *fs_info)
 		if (!ret)
 			break;
 		for (i = 0; i < ret; i++)
-			btrfs_free_fs_root(fs_info, gang[i]);
+			btrfs_drop_and_free_fs_root(fs_info, gang[i]);
 	}
 }
 
@@ -2097,14 +2095,8 @@ int open_ctree(struct super_block *sb,
 	int backup_index = 0;
 
 	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info);
-	extent_root = fs_info->extent_root = btrfs_alloc_root(fs_info);
-	csum_root = fs_info->csum_root = btrfs_alloc_root(fs_info);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info);
-	dev_root = fs_info->dev_root = btrfs_alloc_root(fs_info);
-	quota_root = fs_info->quota_root = btrfs_alloc_root(fs_info);
-
-	if (!tree_root || !extent_root || !csum_root ||
-	    !chunk_root || !dev_root || !quota_root) {
+	if (!tree_root || !chunk_root) {
 		err = -ENOMEM;
 		goto fail;
 	}
@@ -2655,33 +2647,44 @@ int open_ctree(struct super_block *sb,
 	btrfs_set_root_node(&tree_root->root_item, tree_root->node);
 	tree_root->commit_root = btrfs_root_node(tree_root);
 
-	ret = find_and_setup_root(tree_root, fs_info,
-				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
-	if (ret)
+	location.objectid = BTRFS_EXTENT_TREE_OBJECTID;
+	location.type = BTRFS_ROOT_ITEM_KEY;
+	location.offset = 0;
+
+	extent_root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(extent_root)) {
+		ret = PTR_ERR(extent_root);
 		goto recovery_tree_root;
+	}
 	extent_root->track_dirty = 1;
+	fs_info->extent_root = extent_root;
 
-	ret = find_and_setup_root(tree_root, fs_info,
-				  BTRFS_DEV_TREE_OBJECTID, dev_root);
-	if (ret)
+	location.objectid = BTRFS_DEV_TREE_OBJECTID;
+	dev_root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(dev_root)) {
+		ret = PTR_ERR(dev_root);
 		goto recovery_tree_root;
+	}
 	dev_root->track_dirty = 1;
+	fs_info->dev_root = dev_root;
+	btrfs_init_devices_late(fs_info);
 
-	ret = find_and_setup_root(tree_root, fs_info,
-				  BTRFS_CSUM_TREE_OBJECTID, csum_root);
-	if (ret)
+	location.objectid = BTRFS_CSUM_TREE_OBJECTID;
+	csum_root = btrfs_read_tree_root(tree_root, &location);
+	if (IS_ERR(csum_root)) {
+		ret = PTR_ERR(csum_root);
 		goto recovery_tree_root;
+	}
 	csum_root->track_dirty = 1;
+	fs_info->csum_root = csum_root;
 
-	ret = find_and_setup_root(tree_root, fs_info,
-				  BTRFS_QUOTA_TREE_OBJECTID, quota_root);
-	if (ret) {
-		kfree(quota_root);
-		quota_root = fs_info->quota_root = NULL;
-	} else {
+	location.objectid = BTRFS_QUOTA_TREE_OBJECTID;
+	quota_root = btrfs_read_tree_root(tree_root, &location);
+	if (!IS_ERR(quota_root)) {
 		quota_root->track_dirty = 1;
 		fs_info->quota_enabled = 1;
 		fs_info->pending_quota_state = 1;
+		fs_info->quota_root = quota_root;
 	}
 
 	fs_info->generation = generation;
@@ -2834,7 +2837,7 @@ int open_ctree(struct super_block *sb,
 
 	location.objectid = BTRFS_FS_TREE_OBJECTID;
 	location.type = BTRFS_ROOT_ITEM_KEY;
-	location.offset = (u64)-1;
+	location.offset = 0;
 
 	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
 	if (IS_ERR(fs_info->fs_root)) {
@@ -3381,7 +3384,9 @@ int write_ctree_super(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-void btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
+/* Drop a fs root from the radix tree and free it. */
+void btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,
+				  struct btrfs_root *root)
 {
 	spin_lock(&fs_info->fs_roots_radix_lock);
 	radix_tree_delete(&fs_info->fs_roots_radix,
@@ -3415,6 +3420,11 @@ static void free_fs_root(struct btrfs_root *root)
 	kfree(root);
 }
 
+void btrfs_free_fs_root(struct btrfs_root *root)
+{
+	free_fs_root(root);
+}
+
 int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 {
 	u64 root_objectid = 0;

commit babbf170c781f24095336c82ebf18ad272ddb773
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue May 14 10:20:43 2013 +0000

    Btrfs: make the snap/subv deletion end more early when the fs is R/O
    
    The snapshot/subvolume deletion might spend lots of time, it would make
    the remount task wait for a long time. This patch improve this problem,
    we will break the deletion if the fs is remounted to be R/O. It will make
    the users happy.
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5b9b4eb36e5d..8dbd908a3a97 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1673,17 +1673,6 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	bio_endio(bio, error);
 }
 
-/*
- * If we remount the fs to be R/O or umount the fs, the cleaner needn't do
- * anything except sleeping. This function is used to check the status of
- * the fs.
- */
-static inline int need_cleaner_sleep(struct btrfs_root *root)
-{
-	return (root->fs_info->sb->s_flags & MS_RDONLY ||
-		btrfs_fs_closing(root->fs_info));
-}
-
 static int cleaner_kthread(void *arg)
 {
 	struct btrfs_root *root = arg;
@@ -1693,7 +1682,7 @@ static int cleaner_kthread(void *arg)
 		again = 0;
 
 		/* Make the cleaner go to sleep early. */
-		if (need_cleaner_sleep(root))
+		if (btrfs_need_cleaner_sleep(root))
 			goto sleep;
 
 		if (!mutex_trylock(&root->fs_info->cleaner_mutex))
@@ -1703,7 +1692,7 @@ static int cleaner_kthread(void *arg)
 		 * Avoid the problem that we change the status of the fs
 		 * during the above check and trylock.
 		 */
-		if (need_cleaner_sleep(root)) {
+		if (btrfs_need_cleaner_sleep(root)) {
 			mutex_unlock(&root->fs_info->cleaner_mutex);
 			goto sleep;
 		}

commit dc7f370c05dd024697d4d6c68f91fd04fe8fad1e
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue May 14 10:20:42 2013 +0000

    Btrfs: move the R/O check out of btrfs_clean_one_deleted_snapshot()
    
    If the fs is remounted to be R/O, it is unnecessary to call
    btrfs_clean_one_deleted_snapshot(), so move the R/O check out of
    this function. And besides that, it can make the check logic in the
    caller more clear.
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 06f2c011db03..5b9b4eb36e5d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1699,6 +1699,15 @@ static int cleaner_kthread(void *arg)
 		if (!mutex_trylock(&root->fs_info->cleaner_mutex))
 			goto sleep;
 
+		/*
+		 * Avoid the problem that we change the status of the fs
+		 * during the above check and trylock.
+		 */
+		if (need_cleaner_sleep(root)) {
+			mutex_unlock(&root->fs_info->cleaner_mutex);
+			goto sleep;
+		}
+
 		btrfs_run_delayed_iputs(root);
 		again = btrfs_clean_one_deleted_snapshot(root);
 		mutex_unlock(&root->fs_info->cleaner_mutex);

commit 05323cd13503937e71d5c6ef2debf69e51a9634f
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue May 14 10:20:41 2013 +0000

    Btrfs: make the cleaner complete early when the fs is going to be umounted
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7a54b8e7d124..06f2c011db03 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1674,12 +1674,14 @@ static void end_workqueue_fn(struct btrfs_work *work)
 }
 
 /*
- * If we remount the fs to be R/O, the cleaner needn't do anything except
- * sleeping. This function is used to check the status of the fs.
+ * If we remount the fs to be R/O or umount the fs, the cleaner needn't do
+ * anything except sleeping. This function is used to check the status of
+ * the fs.
  */
 static inline int need_cleaner_sleep(struct btrfs_root *root)
 {
-	return root->fs_info->sb->s_flags & MS_RDONLY;
+	return (root->fs_info->sb->s_flags & MS_RDONLY ||
+		btrfs_fs_closing(root->fs_info));
 }
 
 static int cleaner_kthread(void *arg)
@@ -1702,8 +1704,8 @@ static int cleaner_kthread(void *arg)
 		mutex_unlock(&root->fs_info->cleaner_mutex);
 
 		/*
-		 * The defragger has dealt with the R/O remount, needn't
-		 * do anything special here.
+		 * The defragger has dealt with the R/O remount and umount,
+		 * needn't do anything special here.
 		 */
 		btrfs_run_defrag_inodes(root->fs_info);
 sleep:

commit d027824564c5fcee19109530b87c94c9908e910a
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue May 14 10:20:40 2013 +0000

    Btrfs: remove unnecessary ->s_umount in cleaner_kthread()
    
    In order to avoid the R/O remount, we acquired ->s_umount lock during
    we deleted the dead snapshots and subvolumes. But it is unnecessary,
    because we have cleaner_mutex.
    
    We use cleaner_mutex to protect the process of the dead snapshots/subvolumes
    deletion. And when we remount the fs to be R/O, we also acquire this mutex to
    do cleanup after we change the status of the fs. That is this lock can serialize
    the above operations, the cleaner can be aware of the status of the fs, and if
    the cleaner is deleting the dead snapshots/subvolumes, the remount task will
    wait for it. So it is safe to remove ->s_umount in cleaner_kthread().
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bc2ea9b53048..7a54b8e7d124 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1673,24 +1673,40 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	bio_endio(bio, error);
 }
 
+/*
+ * If we remount the fs to be R/O, the cleaner needn't do anything except
+ * sleeping. This function is used to check the status of the fs.
+ */
+static inline int need_cleaner_sleep(struct btrfs_root *root)
+{
+	return root->fs_info->sb->s_flags & MS_RDONLY;
+}
+
 static int cleaner_kthread(void *arg)
 {
 	struct btrfs_root *root = arg;
+	int again;
 
 	do {
-		int again = 0;
-
-		if (!(root->fs_info->sb->s_flags & MS_RDONLY) &&
-		    down_read_trylock(&root->fs_info->sb->s_umount)) {
-			if (mutex_trylock(&root->fs_info->cleaner_mutex)) {
-				btrfs_run_delayed_iputs(root);
-				again = btrfs_clean_one_deleted_snapshot(root);
-				mutex_unlock(&root->fs_info->cleaner_mutex);
-			}
-			btrfs_run_defrag_inodes(root->fs_info);
-			up_read(&root->fs_info->sb->s_umount);
-		}
+		again = 0;
 
+		/* Make the cleaner go to sleep early. */
+		if (need_cleaner_sleep(root))
+			goto sleep;
+
+		if (!mutex_trylock(&root->fs_info->cleaner_mutex))
+			goto sleep;
+
+		btrfs_run_delayed_iputs(root);
+		again = btrfs_clean_one_deleted_snapshot(root);
+		mutex_unlock(&root->fs_info->cleaner_mutex);
+
+		/*
+		 * The defragger has dealt with the R/O remount, needn't
+		 * do anything special here.
+		 */
+		btrfs_run_defrag_inodes(root->fs_info);
+sleep:
 		if (!try_to_freeze() && !again) {
 			set_current_state(TASK_INTERRUPTIBLE);
 			if (!kthread_should_stop())

commit b1b195969fe6d936f8c8bb63abf7efd2cc4cd5cf
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon May 13 14:42:57 2013 +0000

    Btrfs: cleanup, btrfs_read_fs_root_no_name() doesn't return NULL
    
    No need to check for NULL in send.c and disk-io.c.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index df5169b7aad1..bc2ea9b53048 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2821,8 +2821,6 @@ int open_ctree(struct super_block *sb,
 	location.offset = (u64)-1;
 
 	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
-	if (!fs_info->fs_root)
-		goto fail_qgroup;
 	if (IS_ERR(fs_info->fs_root)) {
 		err = PTR_ERR(fs_info->fs_root);
 		goto fail_qgroup;

commit 1e8f915868c59be4d6e49d9aff928454a5d5d569
Author: Wang Shilong <wangsl-fnst@cn.fujitsu.com>
Date:   Mon May 6 11:03:27 2013 +0000

    Btrfs: introduce qgroup_ulist to avoid frequently allocating/freeing ulist
    
    When doing qgroup accounting, we call ulist_alloc()/ulist_free() every time
    when we want to walk qgroup tree.
    
    By introducing 'qgroup_ulist', we only need to call ulist_alloc()/ulist_free()
    once. This reduce some sys time to allocate memory, see the measurements below
    
    fsstress -p 4 -n 10000 -d $dir
    
    With this patch:
    
    real    0m50.153s
    user    0m0.081s
    sys     0m6.294s
    
    real    0m51.113s
    user    0m0.092s
    sys     0m6.220s
    
    real    0m52.610s
    user    0m0.096s
    sys     0m6.125s        avg 6.213
    -----------------------------------------------------
    Without the patch:
    
    real    0m54.825s
    user    0m0.061s
    sys     0m10.665s
    
    real    1m6.401s
    user    0m0.089s
    sys     0m11.218s
    
    real    1m13.768s
    user    0m0.087s
    sys     0m10.665s       avg 10.849
    
    we can see the sys time reduce ~43%.
    
    Signed-off-by: Wang Shilong <wangsl-fnst@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aecf788ed81e..df5169b7aad1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2274,6 +2274,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->qgroup_seq = 1;
 	fs_info->quota_enabled = 0;
 	fs_info->pending_quota_state = 0;
+	fs_info->qgroup_ulist = NULL;
 	mutex_init(&fs_info->qgroup_rescan_lock);
 
 	btrfs_init_free_cluster(&fs_info->meta_alloc_cluster);

commit 15b0a89d71ae2573ed1c3b168f08320527eed34e
Author: Henrik Nordvik <henrikno@gmail.com>
Date:   Mon Apr 29 18:09:23 2013 +0000

    Btrfs: fix check on same raid type flag twice
    
    Code checked for raid 5 flag in two else-if branches, so code would never be reached. Probably a copy-paste bug.
    
    Signed-off-by: Henrik Nordvik <henrikno@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b8b60b660c8f..aecf788ed81e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3258,7 +3258,7 @@ int btrfs_calc_num_tolerated_disk_barrier_failures(
 					    BTRFS_BLOCK_GROUP_RAID10)) {
 						num_tolerated_disk_barrier_failures = 1;
 					} else if (flags &
-						   BTRFS_BLOCK_GROUP_RAID5) {
+						   BTRFS_BLOCK_GROUP_RAID6) {
 						num_tolerated_disk_barrier_failures = 2;
 					}
 				}

commit 13e6c37b989859e70b0d73d3f2cb0aa022159b17
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu May 30 16:55:44 2013 -0400

    Btrfs: stop all workers before cleaning up roots
    
    Dave reported a panic because the extent_root->commit_root was NULL in the
    caching kthread.  That is because we just unset it in free_root_pointers, which
    is not the correct thing to do, we have to either wait for the caching kthread
    to complete or hold the extent_commit_sem lock so we know the thread has exited.
    This patch makes the kthreads all stop first and then we do our cleanup.  This
    should fix the race.  Thanks,
    
    Reported-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7c66c2314c14..b8b60b660c8f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3514,13 +3514,13 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_free_block_groups(fs_info);
 
-	free_root_pointers(fs_info, 1);
+	btrfs_stop_all_workers(fs_info);
 
 	del_fs_roots(fs_info);
 
-	iput(fs_info->btree_inode);
+	free_root_pointers(fs_info, 1);
 
-	btrfs_stop_all_workers(fs_info);
+	iput(fs_info->btree_inode);
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_test_opt(root, CHECK_INTEGRITY))

commit 2932505abe7c56477315a3d93ffb3c27c5182e9d
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Sun May 26 13:50:27 2013 +0000

    Btrfs: fix use-after-free bug during umount
    
    Commit be283b2e674a09457d4563729015adb637ce7cc1
    (    Btrfs: use helper to cleanup tree roots) introduced the following bug,
    
     BUG: unable to handle kernel NULL pointer dereference at 0000000000000034
     IP: [<ffffffffa039368c>] extent_buffer_get+0x4/0xa [btrfs]
    [...]
     Pid: 2463, comm: btrfs-cache-1 Tainted: G           O 3.9.0+ #4 innotek GmbH VirtualBox/VirtualBox
     RIP: 0010:[<ffffffffa039368c>]  [<ffffffffa039368c>] extent_buffer_get+0x4/0xa [btrfs]
     Process btrfs-cache-1 (pid: 2463, threadinfo ffff880112d60000, task ffff880117679730)
    [...]
     Call Trace:
      [<ffffffffa0398a99>] btrfs_search_slot+0x104/0x64d [btrfs]
      [<ffffffffa039aea4>] btrfs_next_old_leaf+0xa7/0x334 [btrfs]
      [<ffffffffa039b141>] btrfs_next_leaf+0x10/0x12 [btrfs]
      [<ffffffffa039ea13>] caching_thread+0x1a3/0x2e0 [btrfs]
      [<ffffffffa03d8811>] worker_loop+0x14b/0x48e [btrfs]
      [<ffffffffa03d86c6>] ? btrfs_queue_worker+0x25c/0x25c [btrfs]
      [<ffffffff81068d3d>] kthread+0x8d/0x95
      [<ffffffff81068cb0>] ? kthread_freezable_should_stop+0x43/0x43
      [<ffffffff8151e5ac>] ret_from_fork+0x7c/0xb0
      [<ffffffff81068cb0>] ? kthread_freezable_should_stop+0x43/0x43
    RIP  [<ffffffffa039368c>] extent_buffer_get+0x4/0xa [btrfs]
    
    We've free'ed commit_root before actually getting to free block groups where
    caching thread needs valid extent_root->commit_root.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bdaa092d6296..7c66c2314c14 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3512,10 +3512,10 @@ int close_ctree(struct btrfs_root *root)
 		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 
-	free_root_pointers(fs_info, 1);
-
 	btrfs_free_block_groups(fs_info);
 
+	free_root_pointers(fs_info, 1);
+
 	del_fs_roots(fs_info);
 
 	iput(fs_info->btree_inode);

commit 7b5ff90ed081787ec0765ceb4fe5ccf5677493a6
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Jun 6 10:29:40 2013 -0400

    Btrfs: don't delete fs_roots until after we cleanup the transaction
    
    We get a use after free if we had a transaction to cleanup since there could be
    delayed inodes which refer to their respective fs_root.  Thanks
    
    Reported-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e7b3cb5286a5..bdaa092d6296 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2859,8 +2859,8 @@ int open_ctree(struct super_block *sb,
 	btrfs_free_qgroup_config(fs_info);
 fail_trans_kthread:
 	kthread_stop(fs_info->transaction_kthread);
-	del_fs_roots(fs_info);
 	btrfs_cleanup_transaction(fs_info->tree_root);
+	del_fs_roots(fs_info);
 fail_cleaner:
 	kthread_stop(fs_info->cleaner_kthread);
 

commit d47992f86b307985b3215bcf141d56d1849d71df
Author: Lukas Czerner <lczerner@redhat.com>
Date:   Tue May 21 23:17:23 2013 -0400

    mm: change invalidatepage prototype to accept length
    
    Currently there is no way to truncate partial page where the end
    truncate point is not at the end of the page. This is because it was not
    needed and the functionality was enough for file system truncate
    operation to work properly. However more file systems now support punch
    hole feature and it can benefit from mm supporting truncating page just
    up to the certain point.
    
    Specifically, with this functionality truncate_inode_pages_range() can
    be changed so it supports truncating partial page at the end of the
    range (currently it will BUG_ON() if 'end' is not at the end of the
    page).
    
    This commit changes the invalidatepage() address space operation
    prototype to accept range to be invalidated and update all the instances
    for it.
    
    We also change the block_invalidatepage() in the same way and actually
    make a use of the new length argument implementing range invalidation.
    
    Actual file system implementations will follow except the file systems
    where the changes are really simple and should not change the behaviour
    in any way .Implementation for truncate_page_range() which will be able
    to accept page unaligned ranges will follow as well.
    
    Signed-off-by: Lukas Czerner <lczerner@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Hugh Dickins <hughd@google.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e7b3cb5286a5..40c7bc300075 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1013,7 +1013,8 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	return try_release_extent_buffer(page);
 }
 
-static void btree_invalidatepage(struct page *page, unsigned long offset)
+static void btree_invalidatepage(struct page *page, unsigned int offset,
+				 unsigned int length)
 {
 	struct extent_io_tree *tree;
 	tree = &BTRFS_I(page->mapping->host)->io_tree;

commit c5cb6a0573bef87e098ee3cd946115ebe60a910e
Merge: 9be3395bcd4a 655b09fe540b
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Fri May 17 21:53:17 2013 -0400

    Merge branch 'for-chris' of git://git.kernel.org/pub/scm/linux/kernel/git/josef/btrfs-next

commit 9be3395bcd4ad4af76476ac38152b4cafa6b6159
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Fri May 17 18:30:14 2013 -0400

    Btrfs: use a btrfs bioset instead of abusing bio internals
    
    Btrfs has been pointer tagging bi_private and using bi_bdev
    to store the stripe index and mirror number of failed IOs.
    
    As bios bubble back up through the call chain, we use these
    to decide if and how to retry our IOs.  They are also used
    to count IO failures on a per device basis.
    
    Recently a bio tracepoint was added lead to crashes because
    we were abusing bi_bdev.
    
    This commit adds a btrfs bioset, and creates explicit fields
    for the mirror number and stripe index.  The plan is to
    extend this structure for all of the fields currently in
    struct btrfs_bio, which will mean one less kmalloc in
    our IO path.
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>
    Reported-by: Tejun Heo <tj@kernel.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4e9ebe1f1827..ca0ea9928210 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3128,7 +3128,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 	 * caller
 	 */
 	device->flush_bio = NULL;
-	bio = bio_alloc(GFP_NOFS, 0);
+	bio = btrfs_io_bio_alloc(GFP_NOFS, 0);
 	if (!bio)
 		return -ENOMEM;
 

commit 655b09fe540b73edeaabfb4c2d700be51a1f8bce
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri May 17 14:06:51 2013 -0400

    Btrfs: make sure roots are assigned before freeing their nodes
    
    If we fail to load the chunk tree we'll call free_root_pointers, except we may
    not have assigned the roots for the dev_root/extent_root/csum_root yet, so we
    could NULL pointer deref at this point.  Just add checks to make sure these
    roots are set to keep us from panicing.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1b03f8393a69..4bdb0528688a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1987,30 +1987,33 @@ static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 {
 	free_extent_buffer(info->tree_root->node);
 	free_extent_buffer(info->tree_root->commit_root);
-	free_extent_buffer(info->dev_root->node);
-	free_extent_buffer(info->dev_root->commit_root);
-	free_extent_buffer(info->extent_root->node);
-	free_extent_buffer(info->extent_root->commit_root);
-	free_extent_buffer(info->csum_root->node);
-	free_extent_buffer(info->csum_root->commit_root);
-	if (info->quota_root) {
-		free_extent_buffer(info->quota_root->node);
-		free_extent_buffer(info->quota_root->commit_root);
-	}
-
 	info->tree_root->node = NULL;
 	info->tree_root->commit_root = NULL;
-	info->dev_root->node = NULL;
-	info->dev_root->commit_root = NULL;
-	info->extent_root->node = NULL;
-	info->extent_root->commit_root = NULL;
-	info->csum_root->node = NULL;
-	info->csum_root->commit_root = NULL;
+
+	if (info->dev_root) {
+		free_extent_buffer(info->dev_root->node);
+		free_extent_buffer(info->dev_root->commit_root);
+		info->dev_root->node = NULL;
+		info->dev_root->commit_root = NULL;
+	}
+	if (info->extent_root) {
+		free_extent_buffer(info->extent_root->node);
+		free_extent_buffer(info->extent_root->commit_root);
+		info->extent_root->node = NULL;
+		info->extent_root->commit_root = NULL;
+	}
+	if (info->csum_root) {
+		free_extent_buffer(info->csum_root->node);
+		free_extent_buffer(info->csum_root->commit_root);
+		info->csum_root->node = NULL;
+		info->csum_root->commit_root = NULL;
+	}
 	if (info->quota_root) {
+		free_extent_buffer(info->quota_root->node);
+		free_extent_buffer(info->quota_root->commit_root);
 		info->quota_root->node = NULL;
 		info->quota_root->commit_root = NULL;
 	}
-
 	if (chunk_root) {
 		free_extent_buffer(info->chunk_root->node);
 		free_extent_buffer(info->chunk_root->commit_root);

commit b216cbfb52c08300c203abf06ea9519d15d10045
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:21 2013 +0000

    Btrfs: don't invoke btrfs_invalidate_inodes() in the spin lock context
    
    btrfs_invalidate_inodes() may sleep, so we should not invoke it in the
    spin lock context. Fix it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9b9f28664b4f..1b03f8393a69 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3658,8 +3658,11 @@ static void btrfs_destroy_ordered_operations(struct btrfs_transaction *t,
 					 ordered_operations);
 
 		list_del_init(&btrfs_inode->ordered_operations);
+		spin_unlock(&root->fs_info->ordered_extent_lock);
 
 		btrfs_invalidate_inodes(btrfs_inode->root);
+
+		spin_lock(&root->fs_info->ordered_extent_lock);
 	}
 
 	spin_unlock(&root->fs_info->ordered_extent_lock);
@@ -3781,8 +3784,11 @@ static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
 		list_del_init(&btrfs_inode->delalloc_inodes);
 		clear_bit(BTRFS_INODE_IN_DELALLOC_LIST,
 			  &btrfs_inode->runtime_flags);
+		spin_unlock(&root->fs_info->delalloc_lock);
 
 		btrfs_invalidate_inodes(btrfs_inode->root);
+
+		spin_lock(&root->fs_info->delalloc_lock);
 	}
 
 	spin_unlock(&root->fs_info->delalloc_lock);

commit 314297c2a3fbcbda992507f70cd04cc82084e434
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:18 2013 +0000

    Btrfs: remove BUG_ON() in btrfs_read_fs_tree_no_radix()
    
    We have checked if ->node is NULL or not, so it is unnecessary to
    use BUG_ON() to check again. Remove it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e8b29da30154..9b9f28664b4f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1513,7 +1513,6 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	}
 
 	root->commit_root = btrfs_root_node(root);
-	BUG_ON(!root->node); /* -ENOMEM */
 out:
 	if (location->objectid != BTRFS_TREE_LOG_OBJECTID) {
 		root->ref_cows = 1;

commit 69a85bd87cc81bcbd36730d4a1214c12fdb8a548
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed May 8 13:30:11 2013 -0400

    Btrfs: don't null pointer deref on abort
    
    I'm sorry, theres no excuse for this sort of work.  We need to use
    root->leafsize since eb may be NULL.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 72b17276c255..e8b29da30154 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3808,7 +3808,7 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 		while (start <= end) {
 			eb = btrfs_find_tree_block(root, start,
 						   root->leafsize);
-			start += eb->len;
+			start += root->leafsize;
 			if (!eb)
 				continue;
 			wait_on_extent_buffer_writeback(eb);

commit 60b62978bc5e903cd487de34972fb30f76c74a2e
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Apr 30 17:29:29 2013 +0000

    btrfs: annotate quota tree for lockdep
    
    Quota tree has been missing from lockdep annotations, though no warning
    has been seen in the wild.
    
    There's currently one entry that does not belong there,
    BTRFS_ORPHAN_OBJECTID.  No such tree exists, it's probably a copy &
    paste mistake, the id is defined among tree ids.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4e9ebe1f1827..72b17276c255 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -152,7 +152,7 @@ static struct btrfs_lockdep_keyset {
 	{ .id = BTRFS_DEV_TREE_OBJECTID,	.name_stem = "dev"	},
 	{ .id = BTRFS_FS_TREE_OBJECTID,		.name_stem = "fs"	},
 	{ .id = BTRFS_CSUM_TREE_OBJECTID,	.name_stem = "csum"	},
-	{ .id = BTRFS_ORPHAN_OBJECTID,		.name_stem = "orphan"	},
+	{ .id = BTRFS_QUOTA_TREE_OBJECTID,	.name_stem = "quota"	},
 	{ .id = BTRFS_TREE_LOG_OBJECTID,	.name_stem = "log"	},
 	{ .id = BTRFS_TREE_RELOC_OBJECTID,	.name_stem = "treloc"	},
 	{ .id = BTRFS_DATA_RELOC_TREE_OBJECTID,	.name_stem = "dreloc"	},

commit 667e7d94a1683661cff5fe9a0fa0d7f8fdd2c007
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Tue May 7 11:00:13 2013 -0400

    Btrfs: allow superblock mismatch from older mkfs
    
    We've added new checks to make sure the super block crc is correct
    during mount.  A fresh filesystem from an older mkfs won't have the
    crc set.  This adds a warning when it finds a newly created filesystem
    but doesn't fail the mount.
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bc423f7eddce..4e9ebe1f1827 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -383,6 +383,11 @@ static int btrfs_check_super_csum(char *raw_disk_sb)
 
 		if (memcmp(raw_disk_sb, result, csum_size))
 			ret = 1;
+
+		if (ret && btrfs_super_generation(disk_sb) < 10) {
+			printk(KERN_WARNING "btrfs: super block crcs don't match, older mkfs detected\n");
+			ret = 0;
+		}
 	}
 
 	if (csum_type >= ARRAY_SIZE(btrfs_csum_sizes)) {

commit 1104a8855109a4051d74977f819a13b4516aa11e
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Mar 6 15:57:46 2013 +0100

    btrfs: enhance superblock checks
    
    The superblock checksum is not verified upon mount. <awkward silence>
    
    Add that check and also reorder existing checks to a more logical
    order.
    
    Current mkfs.btrfs does not calculate the correct checksum of
    super_block and thus a freshly created filesytem will fail to mount when
    this patch is applied.
    
    First transaction commit calculates correct superblock checksum and
    saves it to disk.
    
    Reproducer:
    $ mfks.btrfs /dev/sda
    $ mount /dev/sda /mnt
    $ btrfs scrub start /mnt
    $ sleep 5
    $ btrfs scrub status /mnt
    ... super:2 ...
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2bc1ecf5e840..bc423f7eddce 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -356,6 +356,44 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 	return ret;
 }
 
+/*
+ * Return 0 if the superblock checksum type matches the checksum value of that
+ * algorithm. Pass the raw disk superblock data.
+ */
+static int btrfs_check_super_csum(char *raw_disk_sb)
+{
+	struct btrfs_super_block *disk_sb =
+		(struct btrfs_super_block *)raw_disk_sb;
+	u16 csum_type = btrfs_super_csum_type(disk_sb);
+	int ret = 0;
+
+	if (csum_type == BTRFS_CSUM_TYPE_CRC32) {
+		u32 crc = ~(u32)0;
+		const int csum_size = sizeof(crc);
+		char result[csum_size];
+
+		/*
+		 * The super_block structure does not span the whole
+		 * BTRFS_SUPER_INFO_SIZE range, we expect that the unused space
+		 * is filled with zeros and is included in the checkum.
+		 */
+		crc = btrfs_csum_data(raw_disk_sb + BTRFS_CSUM_SIZE,
+				crc, BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
+		btrfs_csum_final(crc, result);
+
+		if (memcmp(raw_disk_sb, result, csum_size))
+			ret = 1;
+	}
+
+	if (csum_type >= ARRAY_SIZE(btrfs_csum_sizes)) {
+		printk(KERN_ERR "btrfs: unsupported checksum algorithm %u\n",
+				csum_type);
+		ret = 1;
+	}
+
+	return ret;
+}
+
 /*
  * helper to read a given tree block, doing retries as required when
  * the checksums don't match and we have alternate mirrors to try.
@@ -2249,12 +2287,31 @@ int open_ctree(struct super_block *sb,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
 	invalidate_bdev(fs_devices->latest_bdev);
+
+	/*
+	 * Read super block and check the signature bytes only
+	 */
 	bh = btrfs_read_dev_super(fs_devices->latest_bdev);
 	if (!bh) {
 		err = -EINVAL;
 		goto fail_alloc;
 	}
 
+	/*
+	 * We want to check superblock checksum, the type is stored inside.
+	 * Pass the whole disk block of size BTRFS_SUPER_INFO_SIZE (4k).
+	 */
+	if (btrfs_check_super_csum(bh->b_data)) {
+		printk(KERN_ERR "btrfs: superblock checksum mismatch\n");
+		err = -EINVAL;
+		goto fail_alloc;
+	}
+
+	/*
+	 * super_copy is zeroed at allocation time and we never touch the
+	 * following bytes up to INFO_SIZE, the checksum is calculated from
+	 * the whole block of INFO_SIZE
+	 */
 	memcpy(fs_info->super_copy, bh->b_data, sizeof(*fs_info->super_copy));
 	memcpy(fs_info->super_for_commit, fs_info->super_copy,
 	       sizeof(*fs_info->super_for_commit));
@@ -2262,6 +2319,13 @@ int open_ctree(struct super_block *sb,
 
 	memcpy(fs_info->fsid, fs_info->super_copy->fsid, BTRFS_FSID_SIZE);
 
+	ret = btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
+	if (ret) {
+		printk(KERN_ERR "btrfs: superblock contains fatal errors\n");
+		err = -EINVAL;
+		goto fail_alloc;
+	}
+
 	disk_super = fs_info->super_copy;
 	if (!btrfs_super_root(disk_super))
 		goto fail_alloc;
@@ -2270,13 +2334,6 @@ int open_ctree(struct super_block *sb,
 	if (btrfs_super_flags(disk_super) & BTRFS_SUPER_FLAG_ERROR)
 		set_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state);
 
-	ret = btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
-	if (ret) {
-		printk(KERN_ERR "btrfs: superblock contains fatal errors\n");
-		err = ret;
-		goto fail_alloc;
-	}
-
 	/*
 	 * run through our array of backup supers and setup
 	 * our ring pointer to the oldest one
@@ -3561,14 +3618,9 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 			      int read_only)
 {
-	if (btrfs_super_csum_type(fs_info->super_copy) >= ARRAY_SIZE(btrfs_csum_sizes)) {
-		printk(KERN_ERR "btrfs: unsupported checksum algorithm\n");
-		return -EINVAL;
-	}
-
-	if (read_only)
-		return 0;
-
+	/*
+	 * Placeholder for checks
+	 */
 	return 0;
 }
 

commit f7a52a40cabea38b99b5053bc4f7cf45f4997603
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Apr 26 14:56:29 2013 +0000

    btrfs: remove unused gfp mask parameter from release_extent_buffer callchain
    
    It's unused since 0b32f4bbb423f02ac.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ac132d9637bb..2bc1ecf5e840 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -966,14 +966,8 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 {
 	if (PageWriteback(page) || PageDirty(page))
 		return 0;
-	/*
-	 * We need to mask out eg. __GFP_HIGHMEM and __GFP_DMA32 as we're doing
-	 * slab allocation from alloc_extent_state down the callchain where
-	 * it'd hit a BUG_ON as those flags are not allowed.
-	 */
-	gfp_flags &= ~GFP_SLAB_BUG_MASK;
 
-	return try_release_extent_buffer(page, gfp_flags);
+	return try_release_extent_buffer(page);
 }
 
 static void btree_invalidatepage(struct page *page, unsigned long offset)

commit 48a3b6366f6913683563d934eb16fea67dead9c1
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Apr 25 20:41:01 2013 +0000

    btrfs: make static code static & remove dead code
    
    Big patch, but all it does is add statics to functions which
    are in fact static, then remove the associated dead-code fallout.
    
    removed functions:
    
    btrfs_iref_to_path()
    __btrfs_lookup_delayed_deletion_item()
    __btrfs_search_delayed_insertion_item()
    __btrfs_search_delayed_deletion_item()
    find_eb_for_page()
    btrfs_find_block_group()
    range_straddles_pages()
    extent_range_uptodate()
    btrfs_file_extent_length()
    btrfs_scrub_cancel_devid()
    btrfs_start_transaction_lflush()
    
    btrfs_print_tree() is left because it is used for debugging.
    btrfs_start_transaction_lflush() and btrfs_reada_detach() are
    left for symmetry.
    
    ulist.c functions are left, another patch will take care of those.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f651a37c7e0a..ac132d9637bb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -70,6 +70,8 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 					int mark);
 static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 				       struct extent_io_tree *pinned_extents);
+static int btrfs_cleanup_transaction(struct btrfs_root *root);
+static void btrfs_error_commit_super(struct btrfs_root *root);
 
 /*
  * end_io_wq structs are used to do processing in task context when an IO is
@@ -531,41 +533,6 @@ static noinline int check_leaf(struct btrfs_root *root,
 	return 0;
 }
 
-struct extent_buffer *find_eb_for_page(struct extent_io_tree *tree,
-				       struct page *page, int max_walk)
-{
-	struct extent_buffer *eb;
-	u64 start = page_offset(page);
-	u64 target = start;
-	u64 min_start;
-
-	if (start < max_walk)
-		min_start = 0;
-	else
-		min_start = start - max_walk;
-
-	while (start >= min_start) {
-		eb = find_extent_buffer(tree, start, 0);
-		if (eb) {
-			/*
-			 * we found an extent buffer and it contains our page
-			 * horray!
-			 */
-			if (eb->start <= target &&
-			    eb->start + eb->len > target)
-				return eb;
-
-			/* we found an extent buffer that wasn't for us */
-			free_extent_buffer(eb);
-			return NULL;
-		}
-		if (start == 0)
-			break;
-		start -= PAGE_CACHE_SIZE;
-	}
-	return NULL;
-}
-
 static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 			       struct extent_state *state, int mirror)
 {
@@ -3245,7 +3212,7 @@ int btrfs_calc_num_tolerated_disk_barrier_failures(
 	return num_tolerated_disk_barrier_failures;
 }
 
-int write_all_supers(struct btrfs_root *root, int max_mirrors)
+static int write_all_supers(struct btrfs_root *root, int max_mirrors)
 {
 	struct list_head *head;
 	struct btrfs_device *dev;
@@ -3611,7 +3578,7 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	return 0;
 }
 
-void btrfs_error_commit_super(struct btrfs_root *root)
+static void btrfs_error_commit_super(struct btrfs_root *root)
 {
 	mutex_lock(&root->fs_info->cleaner_mutex);
 	btrfs_run_delayed_iputs(root);
@@ -3879,7 +3846,7 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	*/
 }
 
-int btrfs_cleanup_transaction(struct btrfs_root *root)
+static int btrfs_cleanup_transaction(struct btrfs_root *root)
 {
 	struct btrfs_transaction *t;
 	LIST_HEAD(list);

commit 634554dc0acfc8753c05e432b2fdb34b0be89c78
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Apr 29 10:05:57 2013 -0400

    Btrfs: deal with errors in write_dev_supers
    
    If you try to mount -o loop a restored file system it will panic if the file
    ends up being smaller than the original disk.  This is because we go to try and
    get a block for a super that may be past the EOF which makes __getblk return
    NULL for a buffer head when we aren't expecting it to.  Fix this by dealing with
    this case and just jacking up the errors count.  With this patch we no longer
    panic when mounting a restored file system loopback.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d96305e5cc93..f651a37c7e0a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2986,7 +2986,10 @@ static int write_dev_supers(struct btrfs_device *device,
 		if (wait) {
 			bh = __find_get_block(device->bdev, bytenr / 4096,
 					      BTRFS_SUPER_INFO_SIZE);
-			BUG_ON(!bh);
+			if (!bh) {
+				errors++;
+				continue;
+			}
 			wait_on_buffer(bh);
 			if (!buffer_uptodate(bh))
 				errors++;
@@ -3013,6 +3016,13 @@ static int write_dev_supers(struct btrfs_device *device,
 			 */
 			bh = __getblk(device->bdev, bytenr / 4096,
 				      BTRFS_SUPER_INFO_SIZE);
+			if (!bh) {
+				printk(KERN_ERR "btrfs: couldn't get super "
+				       "buffer head for bytenr %Lu\n", bytenr);
+				errors++;
+				continue;
+			}
+
 			memcpy(bh->b_data, sb, BTRFS_SUPER_INFO_SIZE);
 
 			/* one reference for submit_bh */

commit 2f2320360b0c35b86938bfc561124474f0dac6e4
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Thu Apr 25 16:04:51 2013 +0000

    Btrfs: rescan for qgroups
    
    If qgroup tracking is out of sync, a rescan operation can be started. It
    iterates the complete extent tree and recalculates all qgroup tracking data.
    This is an expensive operation and should not be used unless required.
    
    A filesystem under rescan can still be umounted. The rescan continues on the
    next mount.  Status information is provided with a separate ioctl while a
    rescan operation is in progress.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 92c44ed78de1..d96305e5cc93 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1976,6 +1976,7 @@ static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
 	btrfs_stop_workers(&fs_info->caching_workers);
 	btrfs_stop_workers(&fs_info->readahead_workers);
 	btrfs_stop_workers(&fs_info->flush_workers);
+	btrfs_stop_workers(&fs_info->qgroup_rescan_workers);
 }
 
 /* helper to cleanup tree roots */
@@ -2267,6 +2268,7 @@ int open_ctree(struct super_block *sb,
 	fs_info->qgroup_seq = 1;
 	fs_info->quota_enabled = 0;
 	fs_info->pending_quota_state = 0;
+	mutex_init(&fs_info->qgroup_rescan_lock);
 
 	btrfs_init_free_cluster(&fs_info->meta_alloc_cluster);
 	btrfs_init_free_cluster(&fs_info->data_alloc_cluster);
@@ -2476,6 +2478,8 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->readahead_workers, "readahead",
 			   fs_info->thread_pool_size,
 			   &fs_info->generic_worker);
+	btrfs_init_workers(&fs_info->qgroup_rescan_workers, "qgroup-rescan", 1,
+			   &fs_info->generic_worker);
 
 	/*
 	 * endios are largely parallel and should have a very
@@ -2510,6 +2514,7 @@ int open_ctree(struct super_block *sb,
 	ret |= btrfs_start_workers(&fs_info->caching_workers);
 	ret |= btrfs_start_workers(&fs_info->readahead_workers);
 	ret |= btrfs_start_workers(&fs_info->flush_workers);
+	ret |= btrfs_start_workers(&fs_info->qgroup_rescan_workers);
 	if (ret) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;

commit fc36ed7e0b13955ba66fc56dc5067e67ac105150
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed Apr 24 16:57:33 2013 +0000

    Btrfs: separate sequence numbers for delayed ref tracking and tree mod log
    
    Sequence numbers for delayed refs have been introduced in the first version
    of the qgroup patch set. To solve the problem of find_all_roots on a busy
    file system, the tree mod log was introduced. The sequence numbers for that
    were simply shared between those two users.
    
    However, at one point in qgroup's quota accounting, there's a statement
    accessing the previous sequence number, that's still just doing (seq - 1)
    just as it would have to in the very first version.
    
    To satisfy that requirement, this patch makes the sequence number counter 64
    bit and splits it into a major part (used for qgroup sequence number
    counting) and a minor part (incremented for each tree modification in the
    log). This enables us to go exactly one major step backwards, as required
    for qgroups, while still incrementing the sequence counter for tree mod log
    insertions to keep track of their order. Keeping them in a single variable
    means there's no need to change all the code dealing with comparisons of two
    sequence numbers.
    
    The sequence number is reset to 0 on commit (not new in this patch), which
    ensures we won't overflow the two 32 bit counters.
    
    Without this fix, the qgroup tracking can occasionally go wrong and WARN_ONs
    from the tree mod log code may happen.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e4488b57a7ae..92c44ed78de1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2157,7 +2157,7 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
 	atomic_set(&fs_info->defrag_running, 0);
-	atomic_set(&fs_info->tree_mod_seq, 0);
+	atomic64_set(&fs_info->tree_mod_seq, 0);
 	fs_info->sb = sb;
 	fs_info->max_inline = 8192 * 1024;
 	fs_info->metadata_ratio = 0;

commit 6463fe58ea60cbcc3e799937dd0877466fc7b8d5
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri Apr 19 15:08:05 2013 +0000

    Btrfs: set UUID in root_item for created trees
    
    It is a rare exception that a new tree is created, like the qgroups
    tree. So far these new trees have an all-zero UUID in their root
    items. All trees that mkfs.btrfs has created get an UUID during the
    first mount when btrfs_read_root_item() rewrites the root_item to
    the v2 structure style. These UUID are never used so far, but
    anyway, since it is better to have it uniform for all trees, this
    commit adds some lines that generate and write an UUID for newly
    created trees.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a03a96650548..e4488b57a7ae 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -30,6 +30,7 @@
 #include <linux/slab.h>
 #include <linux/migrate.h>
 #include <linux/ratelimit.h>
+#include <linux/uuid.h>
 #include <asm/unaligned.h>
 #include "compat.h"
 #include "ctree.h"
@@ -1280,6 +1281,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	struct btrfs_key key;
 	int ret = 0;
 	u64 bytenr;
+	uuid_le uuid;
 
 	root = btrfs_alloc_root(fs_info);
 	if (!root)
@@ -1329,6 +1331,8 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 	btrfs_set_root_used(&root->root_item, leaf->len);
 	btrfs_set_root_last_snapshot(&root->root_item, 0);
 	btrfs_set_root_dirid(&root->root_item, 0);
+	uuid_le_gen(&uuid);
+	memcpy(root->root_item.uuid, uuid.b, BTRFS_UUID_SIZE);
 	root->root_item.drop_level = 0;
 
 	key.objectid = objectid;

commit 5fbf83c10c323cbee61483a06ea61883e3c83e6b
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri Apr 19 15:08:04 2013 +0000

    Btrfs: delete unused parameter to btrfs_read_root_item()
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 84c4fa503ef5..a03a96650548 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1481,7 +1481,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	if (ret == 0) {
 		l = path->nodes[0];
 		slot = path->slots[0];
-		btrfs_read_root_item(tree_root, l, slot, &root->root_item);
+		btrfs_read_root_item(l, slot, &root->root_item);
 		memcpy(&root->root_key, location, sizeof(*location));
 	}
 	btrfs_free_path(path);

commit 54067ae95e1547123fe6ffcf80842e234effd53b
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Apr 25 13:44:38 2013 -0400

    Btrfs: various abort cleanups
    
    I have a broken file system that when it aborts leaves all sorts of accounting
    things wrong and gives you lots of WARN_ON()'s other than the abort.  This is
    because we're not cleaning up various parts of the file system when we abort.
    The first chunks are specific to mount failures, we weren't cleaning up the
    block group cached inodes and we weren't cleaning up any transactions that had
    been aborted, which leaves a bunch of things laying around.
    
    The second half of this are related to the cleanup parts.  First we don't need
    to release space for the dirty pages from the trans_block_rsv, that's all
    handled by the trans handles so this is just plain wrong.  The other thing is we
    need to pin down extents that were set ->must_insert_reserved for delayed refs.
    This isn't so much for the pinning but more for the cleaning up the
    cache->reserved counter since we are no longer going to use those reserved
    bytes.  With this patch I no longer see a bunch of WARN_ON()'s when I try to
    mount this broken file system, just the initial one from the abort.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aff571cb6e04..84c4fa503ef5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2826,6 +2826,7 @@ int open_ctree(struct super_block *sb,
 fail_trans_kthread:
 	kthread_stop(fs_info->transaction_kthread);
 	del_fs_roots(fs_info);
+	btrfs_cleanup_transaction(fs_info->tree_root);
 fail_cleaner:
 	kthread_stop(fs_info->cleaner_kthread);
 
@@ -2836,6 +2837,7 @@ int open_ctree(struct super_block *sb,
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
 
 fail_block_groups:
+	btrfs_put_block_group_cache(fs_info);
 	btrfs_free_block_groups(fs_info);
 
 fail_tree_roots:
@@ -3681,6 +3683,9 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				continue;
 			}
 
+			if (head->must_insert_reserved)
+				btrfs_pin_extent(root, ref->bytenr,
+						 ref->num_bytes, 1);
 			btrfs_free_delayed_extent_op(head->extent_op);
 			delayed_refs->num_heads--;
 			if (list_empty(&head->cluster))
@@ -3876,10 +3881,6 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 
 		btrfs_destroy_delayed_refs(t, root);
 
-		btrfs_block_rsv_release(root,
-					&root->fs_info->trans_block_rsv,
-					t->dirty_pages.dirty_bytes);
-
 		/* FIXME: cleanup wait for commit */
 		t->in_commit = 1;
 		t->blocked = 1;

commit fd8b2b611580929ab1aa01e3942dce20f9e95732
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Apr 24 16:41:19 2013 -0400

    Btrfs: cleanup destroy_marked_extents
    
    We can just look up the extent_buffers for the range and free stuff that way.
    This makes the cleanup a bit cleaner and we can make sure to evict the
    extent_buffers pretty quickly by marking them as stale.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b20f1121efae..aff571cb6e04 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3752,13 +3752,9 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 					int mark)
 {
 	int ret;
-	struct page *page;
-	struct inode *btree_inode = root->fs_info->btree_inode;
 	struct extent_buffer *eb;
 	u64 start = 0;
 	u64 end;
-	u64 offset;
-	unsigned long index;
 
 	while (1) {
 		ret = find_first_extent_bit(dirty_pages, start, &start, &end,
@@ -3768,35 +3764,17 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 
 		clear_extent_bits(dirty_pages, start, end, mark, GFP_NOFS);
 		while (start <= end) {
-			index = start >> PAGE_CACHE_SHIFT;
-			start = (u64)(index + 1) << PAGE_CACHE_SHIFT;
-			page = find_get_page(btree_inode->i_mapping, index);
-			if (!page)
+			eb = btrfs_find_tree_block(root, start,
+						   root->leafsize);
+			start += eb->len;
+			if (!eb)
 				continue;
-			offset = page_offset(page);
-
-			spin_lock(&dirty_pages->buffer_lock);
-			eb = radix_tree_lookup(
-			     &(&BTRFS_I(page->mapping->host)->io_tree)->buffer,
-					       offset >> PAGE_CACHE_SHIFT);
-			spin_unlock(&dirty_pages->buffer_lock);
-			if (eb)
-				ret = test_and_clear_bit(EXTENT_BUFFER_DIRTY,
-							 &eb->bflags);
-			lock_page(page);
-
-			wait_on_page_writeback(page);
-			if (PageDirty(page)) {
-				clear_page_dirty_for_io(page);
-				spin_lock_irq(&page->mapping->tree_lock);
-				radix_tree_tag_clear(&page->mapping->page_tree,
-							page_index(page),
-							PAGECACHE_TAG_DIRTY);
-				spin_unlock_irq(&page->mapping->tree_lock);
-			}
+			wait_on_extent_buffer_writeback(eb);
 
-			unlock_page(page);
-			page_cache_release(page);
+			if (test_and_clear_bit(EXTENT_BUFFER_DIRTY,
+					       &eb->bflags))
+				clear_extent_buffer_dirty(eb);
+			free_extent_buffer_stale(eb);
 		}
 	}
 

commit 171f6537abb1929ab9072ed084872273300ca175
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Apr 24 16:35:41 2013 -0400

    Btrfs: cleanup fs roots if we fail to mount
    
    We can run the tree logging recovery or the orphan cleanup on mount, so we'll
    end up looking up a random fs tree in the meantime.  So we need to clean this up
    so we don't leave extent buffers hanging around on the cache.  With this patch
    we no longer leak extent buffers on failure to mount.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index deb6e3d07281..b20f1121efae 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2011,6 +2011,36 @@ static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 	}
 }
 
+static void del_fs_roots(struct btrfs_fs_info *fs_info)
+{
+	int ret;
+	struct btrfs_root *gang[8];
+	int i;
+
+	while (!list_empty(&fs_info->dead_roots)) {
+		gang[0] = list_entry(fs_info->dead_roots.next,
+				     struct btrfs_root, root_list);
+		list_del(&gang[0]->root_list);
+
+		if (gang[0]->in_radix) {
+			btrfs_free_fs_root(fs_info, gang[0]);
+		} else {
+			free_extent_buffer(gang[0]->node);
+			free_extent_buffer(gang[0]->commit_root);
+			kfree(gang[0]);
+		}
+	}
+
+	while (1) {
+		ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,
+					     (void **)gang, 0,
+					     ARRAY_SIZE(gang));
+		if (!ret)
+			break;
+		for (i = 0; i < ret; i++)
+			btrfs_free_fs_root(fs_info, gang[i]);
+	}
+}
 
 int open_ctree(struct super_block *sb,
 	       struct btrfs_fs_devices *fs_devices,
@@ -2795,6 +2825,7 @@ int open_ctree(struct super_block *sb,
 	btrfs_free_qgroup_config(fs_info);
 fail_trans_kthread:
 	kthread_stop(fs_info->transaction_kthread);
+	del_fs_roots(fs_info);
 fail_cleaner:
 	kthread_stop(fs_info->cleaner_kthread);
 
@@ -3323,37 +3354,6 @@ static void free_fs_root(struct btrfs_root *root)
 	kfree(root);
 }
 
-static void del_fs_roots(struct btrfs_fs_info *fs_info)
-{
-	int ret;
-	struct btrfs_root *gang[8];
-	int i;
-
-	while (!list_empty(&fs_info->dead_roots)) {
-		gang[0] = list_entry(fs_info->dead_roots.next,
-				     struct btrfs_root, root_list);
-		list_del(&gang[0]->root_list);
-
-		if (gang[0]->in_radix) {
-			btrfs_free_fs_root(fs_info, gang[0]);
-		} else {
-			free_extent_buffer(gang[0]->node);
-			free_extent_buffer(gang[0]->commit_root);
-			kfree(gang[0]);
-		}
-	}
-
-	while (1) {
-		ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,
-					     (void **)gang, 0,
-					     ARRAY_SIZE(gang));
-		if (!ret)
-			break;
-		for (i = 0; i < ret; i++)
-			btrfs_free_fs_root(fs_info, gang[i]);
-	}
-}
-
 int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 {
 	u64 root_objectid = 0;

commit 416bc6580bb01ddf67befaaeb94f087b392e7f47
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Apr 23 14:17:42 2013 -0400

    Btrfs: fix all callers of read_tree_block
    
    We kept leaking extent buffers when mounting a broken file system and it turns
    out it's because not everybody uses read_tree_block properly.  You need to check
    and make sure the extent_buffer is uptodate before you use it.  This patch fixes
    everybody who calls read_tree_block directly to make sure they check that it is
    uptodate and free it and return an error if it is not.  With this we no longer
    leak EB's when things go horribly wrong.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c7d8fb0dbff6..deb6e3d07281 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1496,6 +1496,14 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
+	if (!root->node || !extent_buffer_uptodate(root->node)) {
+		ret = (!root->node) ? -ENOMEM : -EIO;
+
+		free_extent_buffer(root->node);
+		kfree(root);
+		return ERR_PTR(ret);
+	}
+
 	root->commit_root = btrfs_root_node(root);
 	BUG_ON(!root->node); /* -ENOMEM */
 out:
@@ -2515,8 +2523,8 @@ int open_ctree(struct super_block *sb,
 	chunk_root->node = read_tree_block(chunk_root,
 					   btrfs_super_chunk_root(disk_super),
 					   blocksize, generation);
-	BUG_ON(!chunk_root->node); /* -ENOMEM */
-	if (!test_bit(EXTENT_BUFFER_UPTODATE, &chunk_root->node->bflags)) {
+	if (!chunk_root->node ||
+	    !test_bit(EXTENT_BUFFER_UPTODATE, &chunk_root->node->bflags)) {
 		printk(KERN_WARNING "btrfs: failed to read chunk root on %s\n",
 		       sb->s_id);
 		goto fail_tree_roots;
@@ -2701,6 +2709,13 @@ int open_ctree(struct super_block *sb,
 		log_tree_root->node = read_tree_block(tree_root, bytenr,
 						      blocksize,
 						      generation + 1);
+		if (!log_tree_root->node ||
+		    !extent_buffer_uptodate(log_tree_root->node)) {
+			printk(KERN_ERR "btrfs: failed to read log tree\n");
+			free_extent_buffer(log_tree_root->node);
+			kfree(log_tree_root);
+			goto fail_trans_kthread;
+		}
 		/* returns with log_tree_root freed on success */
 		ret = btrfs_recover_log_trees(log_tree_root);
 		if (ret) {

commit 1c24c3ce6a8022ab225f44160bfddc92a5a6e435
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Apr 23 11:30:14 2013 -0400

    Btrfs: add tree block level sanity check
    
    With a users corrupted fs I was getting weird behavior and panics and it turns
    out it was because one of his tree blocks had a bogus header level.  So add this
    to the sanity checks in the endio handler for tree blocks.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bb6cdbda4f56..c7d8fb0dbff6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -613,6 +613,12 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		goto err;
 	}
 	found_level = btrfs_header_level(eb);
+	if (found_level >= BTRFS_MAX_LEVEL) {
+		btrfs_info(root->fs_info, "bad tree block level %d\n",
+			   (int)btrfs_header_level(eb));
+		ret = -EIO;
+		goto err;
+	}
 
 	btrfs_set_buffer_lockdep_class(btrfs_header_owner(eb),
 				       eb, found_level);

commit 79fb65a1f6d97febc232e1e4e56019b0c9208541
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Sat Apr 20 10:18:27 2013 -0400

    Btrfs: don't call readahead hook until we have read the entire eb
    
    Martin Steigerwald reported a BUG_ON() where we were given a bogus bytenr to
    map.  Turns out he is using > PAGESIZE leafsizes.  The readahead stuff is called
    every time we do a completion, but we may not have finished reading in all the
    pages, so the bytenr we read off the node could be completely bogus.  Fix this
    by only calling the readahead hook once all pages have been read in.  Thanks,
    
    Reported-by: Martin Steigerwald <Martin@lichtvoll.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aab7d89f3ff0..bb6cdbda4f56 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -636,10 +636,9 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	if (!ret)
 		set_extent_buffer_uptodate(eb);
 err:
-	if (test_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags)) {
-		clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags);
+	if (reads_done &&
+	    test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
 		btree_readahead_hook(root, eb, eb->start, ret);
-	}
 
 	if (ret) {
 		/*

commit b8d7f3ac10a865ca727f9373a796ef8537e3a474
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Apr 17 10:17:05 2013 -0400

    Btrfs: don't force pages under writeback to finish when aborting
    
    Dave reported a BUG_ON() that happened in end_page_writeback() after an abort.
    This happened because we unconditionally call end_page_writeback() in the endio
    case, which is right.  However when we abort the transaction we will call
    end_page_writeback() on any writeback pages we find, which is wrong.  We need to
    lock the page and wait on page writeback to complete if it is.  There is nothing
    unsafe about this since we are discarding the transaction anyway.  Thanks,
    
    Reported-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8a7a366267ec..aab7d89f3ff0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3763,10 +3763,9 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 			if (eb)
 				ret = test_and_clear_bit(EXTENT_BUFFER_DIRTY,
 							 &eb->bflags);
-			if (PageWriteback(page))
-				end_page_writeback(page);
-
 			lock_page(page);
+
+			wait_on_page_writeback(page);
 			if (PageDirty(page)) {
 				clear_page_dirty_for_io(page);
 				spin_lock_irq(&page->mapping->tree_lock);

commit ceda08642459e31673d24d7968d864390d2ce5fa
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Apr 11 10:30:16 2013 +0000

    Btrfs: use a lock to protect incompat/compat flag of the super block
    
    The following case will make the incompat/compat flag of the super block
    be recovered.
     Task1                                  |Task2
     flags = btrfs_super_incompat_flags();  |
                                            |flags = btrfs_super_incompat_flags();
     flags |= new_flag1;                    |
                                            |flags |= new_flag2;
     btrfs_set_super_incompat_flags(flags); |
                                            |btrfs_set_super_incompat_flags(flags);
    the new_flag1 is recovered.
    
    In order to avoid this problem, we introduce a lock named super_lock into
    the btrfs_fs_info structure. If we want to update incompat/compat flags
    of the super block, we must hold it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9f83e5b870d2..8a7a366267ec 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2086,6 +2086,7 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->defrag_inodes_lock);
 	spin_lock_init(&fs_info->free_chunk_lock);
 	spin_lock_init(&fs_info->tree_mod_seq_lock);
+	spin_lock_init(&fs_info->super_lock);
 	rwlock_init(&fs_info->tree_mod_log_lock);
 	mutex_init(&fs_info->reloc_mutex);
 	seqlock_init(&fs_info->profiles_lock);
@@ -2349,6 +2350,10 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
+	/*
+	 * Needn't use the lock because there is no other task which will
+	 * update the flag.
+	 */
 	btrfs_set_super_incompat_flags(disk_super, features);
 
 	features = btrfs_super_compat_ro_flags(disk_super) &

commit f2f6ed3d54648ec19dcdeec30f66843cf7a38487
Author: Wang Shilong <wangsl-fnst@cn.fujitsu.com>
Date:   Sun Apr 7 10:50:16 2013 +0000

    Btrfs: introduce a mutex lock for btrfs quota operations
    
    The original code has one spin_lock 'qgroup_lock' to protect quota
    configurations in memory. If we want to add a BTRFS_QGROUP_INFO_KEY,
    it will be added to Btree firstly, and then update configurations in
    memory,however, a race condition may happen between these operations.
    For example:
            ->add_qgroup_info_item()
                    ->add_qgroup_rb()
    
    For the above case, del_qgroup_info_item() may happen just before
    add_qgroup_rb().
    
    What's worse, when we want to add a qgroup relation:
            ->add_qgroup_relation_item()
                    ->add_qgroup_relations()
    
    We don't have any checks whether 'src' and 'dst' exist before
    add_qgroup_relation_item(), a race condition can also happen for
    the above case.
    
    To avoid race condition and have all the necessary checks, we introduce
    a mutex lock 'qgroup_ioctl_lock', and we make all the user change operations
    protected by the mutex lock.
    
    Signed-off-by: Wang Shilong <wangsl-fnst@cn.fujitsu.com>
    Reviewed-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 70e6b0c32db2..9f83e5b870d2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2213,6 +2213,7 @@ int open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->dev_replace.lock);
 
 	spin_lock_init(&fs_info->qgroup_lock);
+	mutex_init(&fs_info->qgroup_ioctl_lock);
 	fs_info->qgroup_tree = RB_ROOT;
 	INIT_LIST_HEAD(&fs_info->dirty_qgroups);
 	fs_info->qgroup_seq = 1;

commit 09a2a8f96e3009273bed1833b3f210e2c68728a5
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Apr 5 16:51:15 2013 -0400

    Btrfs: fix bad extent logging
    
    A user sent me a btrfs-image of a file system that was panicing on mount during
    the log recovery.  I had originally thought these problems were from a bug in
    the free space cache code, but that was just a symptom of the problem.  The
    problem is if your application does something like this
    
    [prealloc][prealloc][prealloc]
    
    the internal extent maps will merge those all together into one extent map, even
    though on disk they are 3 separate extents.  So if you go to write into one of
    these ranges the extent map will be right since we use the physical extent when
    doing the write, but when we log the extents they will use the wrong sizes for
    the remainder prealloc space.  If this doesn't happen to trip up the free space
    cache (which it won't in a lot of cases) then you will get bogus entries in your
    extent tree which will screw stuff up later.  The data and such will still work,
    but everything else is broken.  This patch fixes this by not allowing extents
    that are on the modified list to be merged.  This has the side effect that we
    are no longer adding everything to the modified list all the time, which means
    we now have to call btrfs_drop_extents every time we log an extent into the
    tree.  So this allows me to drop all this speciality code I was using to get
    around calling btrfs_drop_extents.  With this patch the testcase I've created no
    longer creates a bogus file system after replaying the log.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b8ed1d4fe509..70e6b0c32db2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -222,7 +222,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 	em->bdev = BTRFS_I(inode)->root->fs_info->fs_devices->latest_bdev;
 
 	write_lock(&em_tree->lock);
-	ret = add_extent_mapping(em_tree, em);
+	ret = add_extent_mapping(em_tree, em, 0);
 	if (ret == -EEXIST) {
 		free_extent_map(em);
 		em = lookup_extent_mapping(em_tree, start, len);

commit 9d1a2a3ad59f7ae810bf04a5a05995bf2d79300c
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Mar 12 15:13:28 2013 +0000

    btrfs: clean snapshots one by one
    
    Each time pick one dead root from the list and let the caller know if
    it's needed to continue. This should improve responsiveness during
    umount and balance which at some point waits for cleaning all currently
    queued dead roots.
    
    A new dead root is added to the end of the list, so the snapshots
    disappear in the order of deletion.
    
    The snapshot cleaning work is now done only from the cleaner thread and the
    others wake it if needed.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 898263f56d96..b8ed1d4fe509 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1658,15 +1658,20 @@ static int cleaner_kthread(void *arg)
 	struct btrfs_root *root = arg;
 
 	do {
+		int again = 0;
+
 		if (!(root->fs_info->sb->s_flags & MS_RDONLY) &&
-		    mutex_trylock(&root->fs_info->cleaner_mutex)) {
-			btrfs_run_delayed_iputs(root);
-			btrfs_clean_old_snapshots(root);
-			mutex_unlock(&root->fs_info->cleaner_mutex);
+		    down_read_trylock(&root->fs_info->sb->s_umount)) {
+			if (mutex_trylock(&root->fs_info->cleaner_mutex)) {
+				btrfs_run_delayed_iputs(root);
+				again = btrfs_clean_one_deleted_snapshot(root);
+				mutex_unlock(&root->fs_info->cleaner_mutex);
+			}
 			btrfs_run_defrag_inodes(root->fs_info);
+			up_read(&root->fs_info->sb->s_umount);
 		}
 
-		if (!try_to_freeze()) {
+		if (!try_to_freeze() && !again) {
 			set_current_state(TASK_INTERRUPTIBLE);
 			if (!kthread_should_stop())
 				schedule();
@@ -3358,8 +3363,8 @@ int btrfs_commit_super(struct btrfs_root *root)
 
 	mutex_lock(&root->fs_info->cleaner_mutex);
 	btrfs_run_delayed_iputs(root);
-	btrfs_clean_old_snapshots(root);
 	mutex_unlock(&root->fs_info->cleaner_mutex);
+	wake_up_process(root->fs_info->cleaner_kthread);
 
 	/* wait until ongoing cleanup work done */
 	down_write(&root->fs_info->cleanup_work_sem);

commit 7abadb6431a057f1e3cf8d395acb8766b947ac85
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Sun Mar 17 02:10:31 2013 +0000

    Btrfs: share stop worker code
    
    Share the exactly same code of stopping workers.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f47754a2fee4..898263f56d96 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1935,6 +1935,27 @@ static noinline int next_root_backup(struct btrfs_fs_info *info,
 	return 0;
 }
 
+/* helper to cleanup workers */
+static void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)
+{
+	btrfs_stop_workers(&fs_info->generic_worker);
+	btrfs_stop_workers(&fs_info->fixup_workers);
+	btrfs_stop_workers(&fs_info->delalloc_workers);
+	btrfs_stop_workers(&fs_info->workers);
+	btrfs_stop_workers(&fs_info->endio_workers);
+	btrfs_stop_workers(&fs_info->endio_meta_workers);
+	btrfs_stop_workers(&fs_info->endio_raid56_workers);
+	btrfs_stop_workers(&fs_info->rmw_workers);
+	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
+	btrfs_stop_workers(&fs_info->endio_write_workers);
+	btrfs_stop_workers(&fs_info->endio_freespace_worker);
+	btrfs_stop_workers(&fs_info->submit_workers);
+	btrfs_stop_workers(&fs_info->delayed_workers);
+	btrfs_stop_workers(&fs_info->caching_workers);
+	btrfs_stop_workers(&fs_info->readahead_workers);
+	btrfs_stop_workers(&fs_info->flush_workers);
+}
+
 /* helper to cleanup tree roots */
 static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 {
@@ -2760,22 +2781,7 @@ int open_ctree(struct super_block *sb,
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 
 fail_sb_buffer:
-	btrfs_stop_workers(&fs_info->generic_worker);
-	btrfs_stop_workers(&fs_info->readahead_workers);
-	btrfs_stop_workers(&fs_info->fixup_workers);
-	btrfs_stop_workers(&fs_info->delalloc_workers);
-	btrfs_stop_workers(&fs_info->workers);
-	btrfs_stop_workers(&fs_info->endio_workers);
-	btrfs_stop_workers(&fs_info->endio_meta_workers);
-	btrfs_stop_workers(&fs_info->endio_raid56_workers);
-	btrfs_stop_workers(&fs_info->rmw_workers);
-	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
-	btrfs_stop_workers(&fs_info->endio_write_workers);
-	btrfs_stop_workers(&fs_info->endio_freespace_worker);
-	btrfs_stop_workers(&fs_info->submit_workers);
-	btrfs_stop_workers(&fs_info->delayed_workers);
-	btrfs_stop_workers(&fs_info->caching_workers);
-	btrfs_stop_workers(&fs_info->flush_workers);
+	btrfs_stop_all_workers(fs_info);
 fail_alloc:
 fail_iput:
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
@@ -3437,22 +3443,7 @@ int close_ctree(struct btrfs_root *root)
 
 	iput(fs_info->btree_inode);
 
-	btrfs_stop_workers(&fs_info->generic_worker);
-	btrfs_stop_workers(&fs_info->fixup_workers);
-	btrfs_stop_workers(&fs_info->delalloc_workers);
-	btrfs_stop_workers(&fs_info->workers);
-	btrfs_stop_workers(&fs_info->endio_workers);
-	btrfs_stop_workers(&fs_info->endio_meta_workers);
-	btrfs_stop_workers(&fs_info->endio_raid56_workers);
-	btrfs_stop_workers(&fs_info->rmw_workers);
-	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
-	btrfs_stop_workers(&fs_info->endio_write_workers);
-	btrfs_stop_workers(&fs_info->endio_freespace_worker);
-	btrfs_stop_workers(&fs_info->submit_workers);
-	btrfs_stop_workers(&fs_info->delayed_workers);
-	btrfs_stop_workers(&fs_info->caching_workers);
-	btrfs_stop_workers(&fs_info->readahead_workers);
-	btrfs_stop_workers(&fs_info->flush_workers);
+	btrfs_stop_all_workers(fs_info);
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_test_opt(root, CHECK_INTEGRITY))

commit 3173a18f70554fe7880bb2d85c7da566e364eb3c
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Mar 7 14:22:04 2013 -0500

    Btrfs: add a incompatible format change for smaller metadata extent refs
    
    We currently store the first key of the tree block inside the reference for the
    tree block in the extent tree.  This takes up quite a bit of space.  Make a new
    key type for metadata which holds the level as the offset and completely removes
    storing the btrfs_tree_block_info inside the extent ref.  This reduces the size
    from 51 bytes to 33 bytes per extent reference for each tree block.  In practice
    this results in a 30-35% decrease in the size of our extent tree, which means we
    COW less and can keep more of the extent tree in memory which makes our heavy
    metadata operations go much faster.  This is not an automatic format change, you
    must enable it at mkfs time or with btrfstune.  This patch deals with having
    metadata stored as either the old format or the new format so it is easy to
    convert.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e0665488e512..f47754a2fee4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2290,6 +2290,9 @@ int open_ctree(struct super_block *sb,
 	if (tree_root->fs_info->compress_type == BTRFS_COMPRESS_LZO)
 		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;
 
+	if (features & BTRFS_FEATURE_INCOMPAT_SKINNY_METADATA)
+		printk(KERN_ERR "btrfs: has skinny extents\n");
+
 	/*
 	 * flag our filesystem as having big metadata blocks if
 	 * they are bigger than the page size

commit be283b2e674a09457d4563729015adb637ce7cc1
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Mar 14 14:58:05 2013 +0000

    Btrfs: use helper to cleanup tree roots
    
    free_root_pointers() has been introduced to cleanup all of tree roots,
    so just use it instead.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7bb28691ed98..e0665488e512 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3426,20 +3426,7 @@ int close_ctree(struct btrfs_root *root)
 		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 
-	free_extent_buffer(fs_info->extent_root->node);
-	free_extent_buffer(fs_info->extent_root->commit_root);
-	free_extent_buffer(fs_info->tree_root->node);
-	free_extent_buffer(fs_info->tree_root->commit_root);
-	free_extent_buffer(fs_info->chunk_root->node);
-	free_extent_buffer(fs_info->chunk_root->commit_root);
-	free_extent_buffer(fs_info->dev_root->node);
-	free_extent_buffer(fs_info->dev_root->commit_root);
-	free_extent_buffer(fs_info->csum_root->node);
-	free_extent_buffer(fs_info->csum_root->commit_root);
-	if (fs_info->quota_root) {
-		free_extent_buffer(fs_info->quota_root->node);
-		free_extent_buffer(fs_info->quota_root->commit_root);
-	}
+	free_root_pointers(fs_info, 1);
 
 	btrfs_free_block_groups(fs_info);
 

commit b0496686ba0da69cfd2433ef55fb2d1dc7465084
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Mar 14 14:57:45 2013 +0000

    Btrfs: cleanup unused arguments of btrfs_csum_data
    
    Argument 'root' is no more used in btrfs_csum_data().
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6d19a0a554aa..7bb28691ed98 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -238,7 +238,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 	return em;
 }
 
-u32 btrfs_csum_data(struct btrfs_root *root, char *data, u32 seed, size_t len)
+u32 btrfs_csum_data(char *data, u32 seed, size_t len)
 {
 	return crc32c(seed, data, len);
 }
@@ -274,7 +274,7 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 		if (err)
 			return 1;
 		cur_len = min(len, map_len - (offset - map_start));
-		crc = btrfs_csum_data(root, kaddr + offset - map_start,
+		crc = btrfs_csum_data(kaddr + offset - map_start,
 				      crc, cur_len);
 		len -= cur_len;
 		offset += cur_len;
@@ -2919,7 +2919,7 @@ static int write_dev_supers(struct btrfs_device *device,
 			btrfs_set_super_bytenr(sb, bytenr);
 
 			crc = ~(u32)0;
-			crc = btrfs_csum_data(NULL, (char *)sb +
+			crc = btrfs_csum_data((char *)sb +
 					      BTRFS_CSUM_SIZE, crc,
 					      BTRFS_SUPER_INFO_SIZE -
 					      BTRFS_CSUM_SIZE);

commit 1dd05682b3ef6e70409e130bfd83e91770801589
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Thu Mar 21 04:32:32 2013 +0000

    Btrfs: fix memory leak in btrfs_create_tree()
    
    We should free leaf and root before returning from the error
    handling code.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 127b23e8323b..6d19a0a554aa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1291,6 +1291,7 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 				      0, objectid, NULL, 0, 0, 0);
 	if (IS_ERR(leaf)) {
 		ret = PTR_ERR(leaf);
+		leaf = NULL;
 		goto fail;
 	}
 
@@ -1334,11 +1335,16 @@ struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
 
 	btrfs_tree_unlock(leaf);
 
+	return root;
+
 fail:
-	if (ret)
-		return ERR_PTR(ret);
+	if (leaf) {
+		btrfs_tree_unlock(leaf);
+		free_extent_buffer(leaf);
+	}
+	kfree(root);
 
-	return root;
+	return ERR_PTR(ret);
 }
 
 static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,

commit d763448286377b8a0e3f179372e9e292bef3c337
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Mon Mar 11 09:20:00 2013 +0000

    Btrfs: update to use fs_state bit
    
    Now that we use bit operation to check fs_state, update
    btrfs_free_fs_root()'s checker, otherwise we get back to
    memory leak case.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7d84651e850b..127b23e8323b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3253,7 +3253,7 @@ void btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 	if (btrfs_root_refs(&root->root_item) == 0)
 		synchronize_srcu(&fs_info->subvol_srcu);
 
-	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR) {
+	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state)) {
 		btrfs_free_log(NULL, root);
 		btrfs_free_log_root_tree(NULL, fs_info);
 	}

commit aec8030a8745221c8658f2033b22c98528897b13
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Mon Mar 4 09:44:29 2013 +0000

    Btrfs: fix wrong handle at error path of create_snapshot() when the commit fails
    
    There are several bugs at error path of create_snapshot() when the
    transaction commitment failed.
    - access the freed transaction handler. At the end of the
      transaction commitment, the transaction handler was freed, so we
      should not access it after the transaction commitment.
    - we were not aware of the error which happened during the snapshot
      creation if we submitted a async transaction commitment.
    - pending snapshot access vs pending snapshot free. when something
      wrong happened after we submitted a async transaction commitment,
      the transaction committer would cleanup the pending snapshots and
      free them. But the snapshot creators were not aware of it, they
      would access the freed pending snapshots.
    
    This patch fixes the above problems by:
    - remove the dangerous code that accessed the freed handler
    - assign ->error if the error happens during the snapshot creation
    - the transaction committer doesn't free the pending snapshots,
      just assigns the error number and evicts them before we unblock
      the transaction.
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 02369a3c162e..7d84651e850b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -62,7 +62,7 @@ static void btrfs_destroy_ordered_operations(struct btrfs_transaction *t,
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				      struct btrfs_root *root);
-static void btrfs_destroy_pending_snapshots(struct btrfs_transaction *t);
+static void btrfs_evict_pending_snapshots(struct btrfs_transaction *t);
 static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root);
 static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 					struct extent_io_tree *dirty_pages,
@@ -3687,7 +3687,7 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 	return ret;
 }
 
-static void btrfs_destroy_pending_snapshots(struct btrfs_transaction *t)
+static void btrfs_evict_pending_snapshots(struct btrfs_transaction *t)
 {
 	struct btrfs_pending_snapshot *snapshot;
 	struct list_head splice;
@@ -3700,10 +3700,8 @@ static void btrfs_destroy_pending_snapshots(struct btrfs_transaction *t)
 		snapshot = list_entry(splice.next,
 				      struct btrfs_pending_snapshot,
 				      list);
-
+		snapshot->error = -ECANCELED;
 		list_del_init(&snapshot->list);
-
-		kfree(snapshot);
 	}
 }
 
@@ -3840,6 +3838,8 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	cur_trans->blocked = 1;
 	wake_up(&root->fs_info->transaction_blocked_wait);
 
+	btrfs_evict_pending_snapshots(cur_trans);
+
 	cur_trans->blocked = 0;
 	wake_up(&root->fs_info->transaction_wait);
 
@@ -3849,8 +3849,6 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	btrfs_destroy_delayed_inodes(root);
 	btrfs_assert_delayed_root_empty(root);
 
-	btrfs_destroy_pending_snapshots(cur_trans);
-
 	btrfs_destroy_marked_extents(root, &cur_trans->dirty_pages,
 				     EXTENT_DIRTY);
 	btrfs_destroy_pinned_extent(root,
@@ -3894,6 +3892,8 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 		if (waitqueue_active(&root->fs_info->transaction_blocked_wait))
 			wake_up(&root->fs_info->transaction_blocked_wait);
 
+		btrfs_evict_pending_snapshots(t);
+
 		t->blocked = 0;
 		smp_mb();
 		if (waitqueue_active(&root->fs_info->transaction_wait))
@@ -3907,8 +3907,6 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 		btrfs_destroy_delayed_inodes(root);
 		btrfs_assert_delayed_root_empty(root);
 
-		btrfs_destroy_pending_snapshots(t);
-
 		btrfs_destroy_delalloc_inodes(root);
 
 		spin_lock(&root->fs_info->trans_lock);

commit 83c8266acc1d19debbf353a16aabbd892ef99462
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Mar 1 15:03:00 2013 +0000

    btrfs: try harder to allocate raid56 stripe cache
    
    The stripe hash table is large, starting with allocation order 4 and can go as
    high as order 7 in case lock debugging is turned on and structure padding
    happens.
    
    Observed mount failure:
    
    mount: page allocation failure: order:7, mode:0x200050
    Pid: 8234, comm: mount Tainted: G        W    3.8.0-default+ #267
    Call Trace:
     [<ffffffff81114353>] warn_alloc_failed+0xf3/0x140
     [<ffffffff811171d2>] ? __alloc_pages_direct_compact+0x92/0x250
     [<ffffffff81117ac3>] __alloc_pages_nodemask+0x733/0x9d0
     [<ffffffff81152878>] ? cache_alloc_refill+0x3f8/0x840
     [<ffffffff811528bc>] cache_alloc_refill+0x43c/0x840
     [<ffffffff811302eb>] ? is_kernel_percpu_address+0x4b/0x90
     [<ffffffffa00a00ac>] ? btrfs_alloc_stripe_hash_table+0x5c/0x130 [btrfs]
     [<ffffffff811531d7>] kmem_cache_alloc_trace+0x247/0x270
     [<ffffffffa00a00ac>] btrfs_alloc_stripe_hash_table+0x5c/0x130 [btrfs]
     [<ffffffffa003133f>] open_ctree+0xb2f/0x1f90 [btrfs]
     [<ffffffff81397289>] ? string+0x49/0xe0
     [<ffffffff813987b3>] ? vsnprintf+0x443/0x5d0
     [<ffffffffa0007cb6>] btrfs_mount+0x526/0x600 [btrfs]
     [<ffffffff8115127c>] ? cache_alloc_debugcheck_after+0x4c/0x200
     [<ffffffff81162b90>] mount_fs+0x20/0xe0
     [<ffffffff8117db26>] vfs_kern_mount+0x76/0x120
     [<ffffffff811801b6>] do_mount+0x386/0x980
     [<ffffffff8112a5cb>] ? strndup_user+0x5b/0x80
     [<ffffffff81180840>] sys_mount+0x90/0xe0
     [<ffffffff81962e99>] system_call_fastpath+0x16/0x1b
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5031e6dd5938..02369a3c162e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2197,7 +2197,7 @@ int open_ctree(struct super_block *sb,
 
 	ret = btrfs_alloc_stripe_hash_table(fs_info);
 	if (ret) {
-		err = -ENOMEM;
+		err = ret;
 		goto fail_alloc;
 	}
 

commit 3321719ed67440bba1b0c5ae19c30d640263ccc8
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Feb 27 13:28:24 2013 +0000

    Btrfs: fix memory leak of log roots
    
    When we abort a transaction while fsyncing, we'll skip freeing log roots
    part of committing a transaction, which leads to memory leak.
    
    This adds a 'free log roots' in putting super when no more users hold
    references on log roots, so it's safe and clean.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eb7c14308521..5031e6dd5938 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3253,6 +3253,11 @@ void btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 	if (btrfs_root_refs(&root->root_item) == 0)
 		synchronize_srcu(&fs_info->subvol_srcu);
 
+	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR) {
+		btrfs_free_log(NULL, root);
+		btrfs_free_log_root_tree(NULL, fs_info);
+	}
+
 	__btrfs_remove_free_space_cache(root->free_ino_pinned);
 	__btrfs_remove_free_space_cache(root->free_ino_ctl);
 	free_fs_root(root);

commit e942f883bc6651d50be139477baf6fb0eed3d5bb
Merge: b2c6b3e0611c 0e4e02636611
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Feb 20 14:06:05 2013 -0500

    Merge branch 'raid56-experimental' into for-linus-3.9
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>
    
    Conflicts:
            fs/btrfs/ctree.h
            fs/btrfs/extent-tree.c
            fs/btrfs/inode.c
            fs/btrfs/volumes.c

commit b2c6b3e0611c58fbeb6b9c0892b6249f7bdfaf6b
Merge: 19f949f52599 272d26d0ad8c
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Feb 20 14:05:45 2013 -0500

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/josef/btrfs-next into for-linus-3.9
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>
    
    Conflicts:
            fs/btrfs/disk-io.c

commit cdb4c5748cb3ac533889a6b0b95aa10651e68785
Author: Zach Brown <zab@redhat.com>
Date:   Wed Feb 20 00:55:13 2013 +0000

    btrfs: define BTRFS_MAGIC as a u64 value
    
    super.magic is an le64 but it's treated as an unterminated string when
    compared against BTRFS_MAGIC which is defined as a string.  Instead
    define BTRFS_MAGIC as a normal hex value and use endian helpers to
    compare it to the super's magic.
    
    I tested this by mounting an fs made before the change and made sure
    that it didn't introduce sparse errors.  This matches a similar cleanup
    that is pending in btrfs-progs.  David Sterba pointed out that we should
    fix the kernel side as well :).
    
    Signed-off-by: Zach Brown <zab@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e511d9f78c19..39ff34a62a24 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2407,8 +2407,7 @@ int open_ctree(struct super_block *sb,
 	sb->s_blocksize = sectorsize;
 	sb->s_blocksize_bits = blksize_bits(sectorsize);
 
-	if (strncmp((char *)(&disk_super->magic), BTRFS_MAGIC,
-		    sizeof(disk_super->magic))) {
+	if (disk_super->magic != cpu_to_le64(BTRFS_MAGIC)) {
 		printk(KERN_INFO "btrfs: valid FS not found on %s\n", sb->s_id);
 		goto fail_sb_buffer;
 	}
@@ -2815,8 +2814,7 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 
 		super = (struct btrfs_super_block *)bh->b_data;
 		if (btrfs_super_bytenr(super) != bytenr ||
-		    strncmp((char *)(&super->magic), BTRFS_MAGIC,
-			    sizeof(super->magic))) {
+		    super->magic != cpu_to_le64(BTRFS_MAGIC)) {
 			brelse(bh);
 			continue;
 		}

commit 569e0f358c0c37f6733702d4a5d2c412860f7169
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Feb 13 11:09:14 2013 -0500

    Btrfs: place ordered operations on a per transaction list
    
    Miao made the ordered operations stuff run async, which introduced a
    deadlock where we could get somebody (sync) racing in and committing the
    transaction while a commit was already happening.  The new committer would
    try and flush ordered operations which would hang waiting for the commit to
    finish because it is done asynchronously and no longer inherits the callers
    trans handle.  To fix this we need to make the ordered operations list a per
    transaction list.  We can get new inodes added to the ordered operation list
    by truncating them and then having another process writing to them, so this
    makes it so that anybody trying to add an ordered operation _must_ start a
    transaction in order to add itself to the list, which will keep new inodes
    from getting added to the ordered operations list after we start committing.
    This should fix the deadlock and also keeps us from doing a lot more work
    than we need to during commit.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9fcce54ecde4..e511d9f78c19 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -56,7 +56,8 @@ static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 				    int read_only);
-static void btrfs_destroy_ordered_operations(struct btrfs_root *root);
+static void btrfs_destroy_ordered_operations(struct btrfs_transaction *t,
+					     struct btrfs_root *root);
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				      struct btrfs_root *root);
@@ -2029,7 +2030,6 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->delayed_iputs);
 	INIT_LIST_HEAD(&fs_info->delalloc_inodes);
-	INIT_LIST_HEAD(&fs_info->ordered_operations);
 	INIT_LIST_HEAD(&fs_info->caching_block_groups);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->trans_lock);
@@ -3538,7 +3538,8 @@ void btrfs_error_commit_super(struct btrfs_root *root)
 	btrfs_cleanup_transaction(root);
 }
 
-static void btrfs_destroy_ordered_operations(struct btrfs_root *root)
+static void btrfs_destroy_ordered_operations(struct btrfs_transaction *t,
+					     struct btrfs_root *root)
 {
 	struct btrfs_inode *btrfs_inode;
 	struct list_head splice;
@@ -3548,7 +3549,7 @@ static void btrfs_destroy_ordered_operations(struct btrfs_root *root)
 	mutex_lock(&root->fs_info->ordered_operations_mutex);
 	spin_lock(&root->fs_info->ordered_extent_lock);
 
-	list_splice_init(&root->fs_info->ordered_operations, &splice);
+	list_splice_init(&t->ordered_operations, &splice);
 	while (!list_empty(&splice)) {
 		btrfs_inode = list_entry(splice.next, struct btrfs_inode,
 					 ordered_operations);
@@ -3829,7 +3830,7 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 	while (!list_empty(&list)) {
 		t = list_entry(list.next, struct btrfs_transaction, list);
 
-		btrfs_destroy_ordered_operations(root);
+		btrfs_destroy_ordered_operations(t, root);
 
 		btrfs_destroy_ordered_extents(root);
 

commit 2b8195bb5717729e4e94ab4ad73a543feaafb0a2
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Feb 7 06:01:35 2013 +0000

    Btrfs: fix the race between bio and btrfs_stop_workers
    
    open_ctree() need read the metadata to initialize the global information
    of btrfs. But it may fail after it submit some bio, and then it will jump
    to the error path. Unfortunately, it doesn't check if there are some bios
    in flight, and just stop all the worker threads. As a result, when the
    submitted bios end, they can not find any worker thread which can deal with
    subsequent work, then oops happen.
    
    kernel BUG at fs/btrfs/async-thread.c:605!
    
    Fix this problem by invoking invalidate_inode_pages2() before we stop the
    worker threads. This function will wait until the bio end because it need
    lock the pages which are going to be invalidated, and if a page is under
    disk read IO, it must be locked. invalidate_inode_pages2() need wait until
    end bio handler to unlocked it.
    
    Reported-and-Tested-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 259d7891d10c..9fcce54ecde4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2711,13 +2711,13 @@ int open_ctree(struct super_block *sb,
 	 * kthreads
 	 */
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
-	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 
 fail_block_groups:
 	btrfs_free_block_groups(fs_info);
 
 fail_tree_roots:
 	free_root_pointers(fs_info, 1);
+	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 
 fail_sb_buffer:
 	btrfs_stop_workers(&fs_info->generic_worker);
@@ -2738,7 +2738,6 @@ int open_ctree(struct super_block *sb,
 fail_iput:
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
-	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
 fail_delalloc_bytes:
 	percpu_counter_destroy(&fs_info->delalloc_bytes);

commit 779880ef35b60ac82eed1dcaec6db5b34a170df8
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Jan 31 14:30:08 2013 -0500

    Btrfs: fix how we discard outstanding ordered extents on abort
    
    When we abort we've been just free'ing up all the ordered extents and
    hoping for the best.  This results in lots of warnings from various places,
    warnings from btrfs_destroy_inode() because it's ENOSPC accounting isn't
    fixed.  It will also screw up lots of pages who have been set private but
    never get cleared because the ordered extents are never allowed to be
    submitted.  This patch fixes those warnings.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8140cb01951f..259d7891d10c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3565,35 +3565,16 @@ static void btrfs_destroy_ordered_operations(struct btrfs_root *root)
 
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root)
 {
-	struct list_head splice;
 	struct btrfs_ordered_extent *ordered;
-	struct inode *inode;
-
-	INIT_LIST_HEAD(&splice);
 
 	spin_lock(&root->fs_info->ordered_extent_lock);
-
-	list_splice_init(&root->fs_info->ordered_extents, &splice);
-	while (!list_empty(&splice)) {
-		ordered = list_entry(splice.next, struct btrfs_ordered_extent,
-				     root_extent_list);
-
-		list_del_init(&ordered->root_extent_list);
-		atomic_inc(&ordered->refs);
-
-		/* the inode may be getting freed (in sys_unlink path). */
-		inode = igrab(ordered->inode);
-
-		spin_unlock(&root->fs_info->ordered_extent_lock);
-		if (inode)
-			iput(inode);
-
-		atomic_set(&ordered->refs, 1);
-		btrfs_put_ordered_extent(ordered);
-
-		spin_lock(&root->fs_info->ordered_extent_lock);
-	}
-
+	/*
+	 * This will just short circuit the ordered completion stuff which will
+	 * make sure the ordered extent gets properly cleaned up.
+	 */
+	list_for_each_entry(ordered, &root->fs_info->ordered_extents,
+			    root_extent_list)
+		set_bit(BTRFS_ORDERED_IOERR, &ordered->flags);
 	spin_unlock(&root->fs_info->ordered_extent_lock);
 }
 

commit eb12db690c7eb0f6593ba5792f5861409e88bc03
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Jan 30 16:03:59 2013 -0500

    Btrfs: fix freeing delayed ref head while still holding its mutex
    
    I hit this error when reproducing a bug that would end in a transaction
    abort.  We take the delayed ref head's mutex to keep anybody from processing
    it while we're destroying it, but we fail to drop the mutex before we carry
    on and free the damned thing.  Fix this by doing the remove logic for the
    head ourselves and unlock the mutex, that way we can avoid use after free's
    or hung tasks waiting on that mutex to come back so they know the delayed
    ref completed.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bd48bf21118e..8140cb01951f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3615,11 +3615,11 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 	}
 
 	while ((node = rb_first(&delayed_refs->root)) != NULL) {
-		ref = rb_entry(node, struct btrfs_delayed_ref_node, rb_node);
+		struct btrfs_delayed_ref_head *head = NULL;
 
+		ref = rb_entry(node, struct btrfs_delayed_ref_node, rb_node);
 		atomic_set(&ref->refs, 1);
 		if (btrfs_delayed_ref_is_head(ref)) {
-			struct btrfs_delayed_ref_head *head;
 
 			head = btrfs_delayed_node_to_head(ref);
 			if (!mutex_trylock(&head->mutex)) {
@@ -3641,10 +3641,12 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				delayed_refs->num_heads_ready--;
 			list_del_init(&head->cluster);
 		}
+
 		ref->in_tree = 0;
 		rb_erase(&ref->rb_node, &delayed_refs->root);
 		delayed_refs->num_entries--;
-
+		if (head)
+			mutex_unlock(&head->mutex);
 		spin_unlock(&delayed_refs->lock);
 		btrfs_put_delayed_ref(ref);
 

commit d1d3cd27a32b819a0b0e2b9b6b5f9e80890f9821
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Jan 31 00:54:53 2013 +0000

    btrfs: list_entry can't return NULL
    
    No need to test the result, we can't get a
    null pointer from list_entry()
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8e58a1f90546..bd48bf21118e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3846,8 +3846,6 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 
 	while (!list_empty(&list)) {
 		t = list_entry(list.next, struct btrfs_transaction, list);
-		if (!t)
-			break;
 
 		btrfs_destroy_ordered_operations(root);
 

commit 87533c475187c1420794a2e164bc67a7974f1327
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:14:48 2013 +0000

    Btrfs: use bit operation for ->fs_state
    
    There is no lock to protect fs_info->fs_state, it will introduce
    some problems, such as the value may be covered by the other task
    when several tasks modify it. For example:
            Task0 - CPU0            Task1 - CPU1
            mov %fs_state rax
            or $0x1 rax
                                    mov %fs_state rax
                                    or $0x2 rax
            mov rax %fs_state
                                    mov rax %fs_state
    The expected value is 3, but in fact, it is 2.
    
    Though this problem doesn't happen now (because there is only one
    flag currently), the code is error prone, if we add other flags,
    the above problem will happen to a certainty.
    
    Now we use bit operation for it to fix the above problem.
    In this way, we can make the code more robust and be easy to
    add new flags.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 00b6742fdde7..8e58a1f90546 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2201,7 +2201,8 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 
 	/* check FS state, whether FS is broken. */
-	fs_info->fs_state |= btrfs_super_flags(disk_super);
+	if (btrfs_super_flags(disk_super) & BTRFS_SUPER_FLAG_ERROR)
+		set_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state);
 
 	ret = btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
 	if (ret) {
@@ -3359,7 +3360,7 @@ int close_ctree(struct btrfs_root *root)
 			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
 	}
 
-	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR)
+	if (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))
 		btrfs_error_commit_super(root);
 
 	btrfs_put_block_group_cache(fs_info);

commit de98ced9e743656d108de41841797def0f5cb951
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:13:12 2013 +0000

    Btrfs: use seqlock to protect fs_info->avail_{data, metadata, system}_alloc_bits
    
    There is no lock to protect
      fs_info->avail_{data, metadata, system}_alloc_bits,
    it may introduce some problem, such as the wrong profile
    information, so we add a seqlock to protect them.
    
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 11f6dbcb1191..00b6742fdde7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2040,6 +2040,7 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->tree_mod_seq_lock);
 	rwlock_init(&fs_info->tree_mod_log_lock);
 	mutex_init(&fs_info->reloc_mutex);
+	seqlock_init(&fs_info->profiles_lock);
 
 	init_completion(&fs_info->kobj_unregister);
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);

commit df0af1a57f72c74d53a9377c60ff20095afab97d
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:11:59 2013 +0000

    Btrfs: use the inode own lock to protect its delalloc_bytes
    
    We need not use a global lock to protect the delalloc_bytes of the
    inode, just use its own lock. In this way, we can reduce the lock
    contention and ->delalloc_lock will just protect delalloc inode
    list.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2c9498aefe86..11f6dbcb1191 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3690,6 +3690,8 @@ static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
 				    delalloc_inodes);
 
 		list_del_init(&btrfs_inode->delalloc_inodes);
+		clear_bit(BTRFS_INODE_IN_DELALLOC_LIST,
+			  &btrfs_inode->runtime_flags);
 
 		btrfs_invalidate_inodes(btrfs_inode->root);
 	}

commit 963d678b0f7649300e3a67f2513ca9d830c6e303
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:10:51 2013 +0000

    Btrfs: use percpu counter for fs_info->delalloc_bytes
    
    fs_info->delalloc_bytes is accessed very frequently, so use percpu
    counter instead of the u64 variant for it to reduce the lock
    contention.
    
    This patch also fixed the problem that we access the variant
    without the lock protection.At worst, we would not flush the
    delalloc inodes, and just return ENOSPC error when we still have
    some free space in the fs.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 34ace168eebc..2c9498aefe86 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2010,10 +2010,16 @@ int open_ctree(struct super_block *sb,
 	fs_info->dirty_metadata_batch = PAGE_CACHE_SIZE *
 					(1 + ilog2(nr_cpu_ids));
 
+	ret = percpu_counter_init(&fs_info->delalloc_bytes, 0);
+	if (ret) {
+		err = ret;
+		goto fail_dirty_metadata_bytes;
+	}
+
 	fs_info->btree_inode = new_inode(sb);
 	if (!fs_info->btree_inode) {
 		err = -ENOMEM;
-		goto fail_dirty_metadata_bytes;
+		goto fail_delalloc_bytes;
 	}
 
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
@@ -2269,6 +2275,7 @@ int open_ctree(struct super_block *sb,
 	sectorsize = btrfs_super_sectorsize(disk_super);
 	stripesize = btrfs_super_stripesize(disk_super);
 	fs_info->dirty_metadata_batch = leafsize * (1 + ilog2(nr_cpu_ids));
+	fs_info->delalloc_batch = sectorsize * 512 * (1 + ilog2(nr_cpu_ids));
 
 	/*
 	 * mixed block groups end up with duplicate but slightly offset
@@ -2731,6 +2738,8 @@ int open_ctree(struct super_block *sb,
 
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
+fail_delalloc_bytes:
+	percpu_counter_destroy(&fs_info->delalloc_bytes);
 fail_dirty_metadata_bytes:
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
 fail_bdi:
@@ -3362,9 +3371,9 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_free_qgroup_config(root->fs_info);
 
-	if (fs_info->delalloc_bytes) {
-		printk(KERN_INFO "btrfs: at unmount delalloc count %llu\n",
-		       (unsigned long long)fs_info->delalloc_bytes);
+	if (percpu_counter_sum(&fs_info->delalloc_bytes)) {
+		printk(KERN_INFO "btrfs: at unmount delalloc count %lld\n",
+		       percpu_counter_sum(&fs_info->delalloc_bytes));
 	}
 
 	free_extent_buffer(fs_info->extent_root->node);
@@ -3412,6 +3421,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
 	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
+	percpu_counter_destroy(&fs_info->delalloc_bytes);
 	bdi_destroy(&fs_info->bdi);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 

commit e2d845211eda9cf296e8edf6724b3d541f4fbfd5
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Jan 29 10:09:20 2013 +0000

    Btrfs: use percpu counter for dirty metadata count
    
    ->dirty_metadata_bytes is accessed very frequently, so use percpu
    counter instead of the u64 variant to reduce the contention of
    the lock.
    
    This patch also fixed the problem that we access it without
    lock protection in __btrfs_btree_balance_dirty(), which may
    cause we skip the dirty pages flush.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 04f98e3ffd90..34ace168eebc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -946,18 +946,20 @@ static int btree_writepages(struct address_space *mapping,
 			    struct writeback_control *wbc)
 {
 	struct extent_io_tree *tree;
+	struct btrfs_fs_info *fs_info;
+	int ret;
+
 	tree = &BTRFS_I(mapping->host)->io_tree;
 	if (wbc->sync_mode == WB_SYNC_NONE) {
-		struct btrfs_root *root = BTRFS_I(mapping->host)->root;
-		u64 num_dirty;
-		unsigned long thresh = 32 * 1024 * 1024;
 
 		if (wbc->for_kupdate)
 			return 0;
 
+		fs_info = BTRFS_I(mapping->host)->root->fs_info;
 		/* this is a bit racy, but that's ok */
-		num_dirty = root->fs_info->dirty_metadata_bytes;
-		if (num_dirty < thresh)
+		ret = percpu_counter_compare(&fs_info->dirty_metadata_bytes,
+					     BTRFS_DIRTY_METADATA_THRESH);
+		if (ret < 0)
 			return 0;
 	}
 	return btree_write_cache_pages(mapping, wbc);
@@ -1125,24 +1127,16 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 void clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		      struct extent_buffer *buf)
 {
+	struct btrfs_fs_info *fs_info = root->fs_info;
+
 	if (btrfs_header_generation(buf) ==
-	    root->fs_info->running_transaction->transid) {
+	    fs_info->running_transaction->transid) {
 		btrfs_assert_tree_locked(buf);
 
 		if (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &buf->bflags)) {
-			spin_lock(&root->fs_info->delalloc_lock);
-			if (root->fs_info->dirty_metadata_bytes >= buf->len)
-				root->fs_info->dirty_metadata_bytes -= buf->len;
-			else {
-				spin_unlock(&root->fs_info->delalloc_lock);
-				btrfs_panic(root->fs_info, -EOVERFLOW,
-					  "Can't clear %lu bytes from "
-					  " dirty_mdatadata_bytes (%llu)",
-					  buf->len,
-					  root->fs_info->dirty_metadata_bytes);
-			}
-			spin_unlock(&root->fs_info->delalloc_lock);
-
+			__percpu_counter_add(&fs_info->dirty_metadata_bytes,
+					     -buf->len,
+					     fs_info->dirty_metadata_batch);
 			/* ugh, clear_extent_buffer_dirty needs to lock the page */
 			btrfs_set_lock_blocking(buf);
 			clear_extent_buffer_dirty(buf);
@@ -2008,10 +2002,18 @@ int open_ctree(struct super_block *sb,
 		goto fail_srcu;
 	}
 
+	ret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0);
+	if (ret) {
+		err = ret;
+		goto fail_bdi;
+	}
+	fs_info->dirty_metadata_batch = PAGE_CACHE_SIZE *
+					(1 + ilog2(nr_cpu_ids));
+
 	fs_info->btree_inode = new_inode(sb);
 	if (!fs_info->btree_inode) {
 		err = -ENOMEM;
-		goto fail_bdi;
+		goto fail_dirty_metadata_bytes;
 	}
 
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
@@ -2266,6 +2268,7 @@ int open_ctree(struct super_block *sb,
 	leafsize = btrfs_super_leafsize(disk_super);
 	sectorsize = btrfs_super_sectorsize(disk_super);
 	stripesize = btrfs_super_stripesize(disk_super);
+	fs_info->dirty_metadata_batch = leafsize * (1 + ilog2(nr_cpu_ids));
 
 	/*
 	 * mixed block groups end up with duplicate but slightly offset
@@ -2728,6 +2731,8 @@ int open_ctree(struct super_block *sb,
 
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
+fail_dirty_metadata_bytes:
+	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
 fail_bdi:
 	bdi_destroy(&fs_info->bdi);
 fail_srcu:
@@ -3406,6 +3411,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
+	percpu_counter_destroy(&fs_info->dirty_metadata_bytes);
 	bdi_destroy(&fs_info->bdi);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 
@@ -3448,11 +3454,10 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 			(unsigned long long)transid,
 			(unsigned long long)root->fs_info->generation);
 	was_dirty = set_extent_buffer_dirty(buf);
-	if (!was_dirty) {
-		spin_lock(&root->fs_info->delalloc_lock);
-		root->fs_info->dirty_metadata_bytes += buf->len;
-		spin_unlock(&root->fs_info->delalloc_lock);
-	}
+	if (!was_dirty)
+		__percpu_counter_add(&root->fs_info->dirty_metadata_bytes,
+				     buf->len,
+				     root->fs_info->dirty_metadata_batch);
 }
 
 static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
@@ -3462,8 +3467,7 @@ static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
 	 * looks as though older kernels can get into trouble with
 	 * this code, they end up stuck in balance_dirty_pages forever
 	 */
-	u64 num_dirty;
-	unsigned long thresh = 32 * 1024 * 1024;
+	int ret;
 
 	if (current->flags & PF_MEMALLOC)
 		return;
@@ -3471,9 +3475,9 @@ static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
 	if (flush_delayed)
 		btrfs_balance_delayed_items(root);
 
-	num_dirty = root->fs_info->dirty_metadata_bytes;
-
-	if (num_dirty > thresh) {
+	ret = percpu_counter_compare(&root->fs_info->dirty_metadata_bytes,
+				     BTRFS_DIRTY_METADATA_THRESH);
+	if (ret > 0) {
 		balance_dirty_pages_ratelimited_nr(
 				   root->fs_info->btree_inode->i_mapping, 1);
 	}

commit a1897fddd28daf6b23d05a30dc2a18836f77f8e3
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Thu Dec 27 09:01:23 2012 +0000

    Btrfs: record first logical byte in memory
    
    This'd save us a rbtree search which may become expensive in large filesystem.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1db8a9938829..04f98e3ffd90 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2130,6 +2130,7 @@ int open_ctree(struct super_block *sb,
 
 	spin_lock_init(&fs_info->block_group_cache_lock);
 	fs_info->block_group_cache_tree = RB_ROOT;
+	fs_info->first_logical_byte = (u64)-1;
 
 	extent_io_tree_init(&fs_info->freed_extents[0],
 			     fs_info->btree_inode->i_mapping);

commit 2ab28f322f9896782da904f5942f3873432addc8
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Oct 12 15:27:49 2012 -0400

    Btrfs: wait on ordered extents at the last possible moment
    
    Since we don't actually copy the extent information from the source tree in
    the fast case we don't need to wait for ordered io to be completed in order
    to fsync, we just need to wait for the io to be completed.  So when we're
    logging our file just attach all of the ordered extents to the log, and then
    when the log syncs just wait for IO_DONE on the ordered extents and then
    write the super.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a762f9137610..1db8a9938829 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1178,9 +1178,13 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 
 	INIT_LIST_HEAD(&root->dirty_list);
 	INIT_LIST_HEAD(&root->root_list);
+	INIT_LIST_HEAD(&root->logged_list[0]);
+	INIT_LIST_HEAD(&root->logged_list[1]);
 	spin_lock_init(&root->orphan_lock);
 	spin_lock_init(&root->inode_lock);
 	spin_lock_init(&root->accounting_lock);
+	spin_lock_init(&root->log_extents_lock[0]);
+	spin_lock_init(&root->log_extents_lock[1]);
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
 	init_waitqueue_head(&root->log_writer_wait);

commit 4eee4fa4f8ab8c2b2623c22be4c3cb91d525aa57
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Dec 21 09:17:45 2012 +0000

    Btrfs: use wrapper page_offset
    
    Use wrapper page_offset to get byte-offset into filesystem object for page.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4438aac4947f..a762f9137610 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -420,7 +420,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 {
 	struct extent_io_tree *tree;
-	u64 start = (u64)page->index << PAGE_CACHE_SHIFT;
+	u64 start = page_offset(page);
 	u64 found_start;
 	struct extent_buffer *eb;
 

commit 78a6184a3ff9041280ee56273c01e5679a831b39
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Nov 21 02:21:28 2012 +0000

    Btrfs: use slabs for delayed reference allocation
    
    The delayed reference allocation is in the fast path of the IO, so use slabs
    to improve the speed of the allocation.
    
    And besides that, it can do check for leaked objects when the module is removed.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 65f03670a952..4438aac4947f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3614,7 +3614,7 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				continue;
 			}
 
-			kfree(head->extent_op);
+			btrfs_free_delayed_extent_op(head->extent_op);
 			delayed_refs->num_heads--;
 			if (list_empty(&head->cluster))
 				delayed_refs->num_heads_ready--;

commit 53b381b3abeb86f12787a6c40fee9b2f71edc23b
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Tue Jan 29 18:40:14 2013 -0500

    Btrfs: RAID5 and RAID6
    
    This builds on David Woodhouse's original Btrfs raid5/6 implementation.
    The code has changed quite a bit, blame Chris Mason for any bugs.
    
    Read/modify/write is done after the higher levels of the filesystem have
    prepared a given bio.  This means the higher layers are not responsible
    for building full stripes, and they don't need to query for the topology
    of the extents that may get allocated during delayed allocation runs.
    It also means different files can easily share the same stripe.
    
    But, it does expose us to incorrect parity if we crash or lose power
    while doing a read/modify/write cycle.  This will be addressed in a
    later commit.
    
    Scrub is unable to repair crc errors on raid5/6 chunks.
    
    Discard does not work on raid5/6 (yet)
    
    The stripe size is fixed at 64KiB per disk.  This will be tunable
    in a later commit.
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 65f03670a952..e9fa7b4d18e3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -46,6 +46,7 @@
 #include "check-integrity.h"
 #include "rcu-string.h"
 #include "dev-replace.h"
+#include "raid56.h"
 
 #ifdef CONFIG_X86
 #include <asm/cpufeature.h>
@@ -639,8 +640,15 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		btree_readahead_hook(root, eb, eb->start, ret);
 	}
 
-	if (ret)
+	if (ret) {
+		/*
+		 * our io error hook is going to dec the io pages
+		 * again, we have to make sure it has something
+		 * to decrement
+		 */
+		atomic_inc(&eb->io_pages);
 		clear_extent_buffer_uptodate(eb);
+	}
 	free_extent_buffer(eb);
 out:
 	return ret;
@@ -654,6 +662,7 @@ static int btree_io_failed_hook(struct page *page, int failed_mirror)
 	eb = (struct extent_buffer *)page->private;
 	set_bit(EXTENT_BUFFER_IOERR, &eb->bflags);
 	eb->read_mirror = failed_mirror;
+	atomic_dec(&eb->io_pages);
 	if (test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
 		btree_readahead_hook(root, eb, eb->start, -EIO);
 	return -EIO;	/* we fixed nothing */
@@ -670,17 +679,23 @@ static void end_workqueue_bio(struct bio *bio, int err)
 	end_io_wq->work.flags = 0;
 
 	if (bio->bi_rw & REQ_WRITE) {
-		if (end_io_wq->metadata == 1)
+		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_METADATA)
 			btrfs_queue_worker(&fs_info->endio_meta_write_workers,
 					   &end_io_wq->work);
-		else if (end_io_wq->metadata == 2)
+		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_FREE_SPACE)
 			btrfs_queue_worker(&fs_info->endio_freespace_worker,
 					   &end_io_wq->work);
+		else if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
+			btrfs_queue_worker(&fs_info->endio_raid56_workers,
+					   &end_io_wq->work);
 		else
 			btrfs_queue_worker(&fs_info->endio_write_workers,
 					   &end_io_wq->work);
 	} else {
-		if (end_io_wq->metadata)
+		if (end_io_wq->metadata == BTRFS_WQ_ENDIO_RAID56)
+			btrfs_queue_worker(&fs_info->endio_raid56_workers,
+					   &end_io_wq->work);
+		else if (end_io_wq->metadata)
 			btrfs_queue_worker(&fs_info->endio_meta_workers,
 					   &end_io_wq->work);
 		else
@@ -695,6 +710,7 @@ static void end_workqueue_bio(struct bio *bio, int err)
  * 0 - if data
  * 1 - if normal metadta
  * 2 - if writing to the free space cache area
+ * 3 - raid parity work
  */
 int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 			int metadata)
@@ -2165,6 +2181,12 @@ int open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->transaction_blocked_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);
 
+	ret = btrfs_alloc_stripe_hash_table(fs_info);
+	if (ret) {
+		err = -ENOMEM;
+		goto fail_alloc;
+	}
+
 	__setup_root(4096, 4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
@@ -2332,6 +2354,12 @@ int open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->endio_meta_write_workers,
 			   "endio-meta-write", fs_info->thread_pool_size,
 			   &fs_info->generic_worker);
+	btrfs_init_workers(&fs_info->endio_raid56_workers,
+			   "endio-raid56", fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
+	btrfs_init_workers(&fs_info->rmw_workers,
+			   "rmw", fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 	btrfs_init_workers(&fs_info->endio_write_workers, "endio-write",
 			   fs_info->thread_pool_size,
 			   &fs_info->generic_worker);
@@ -2350,6 +2378,8 @@ int open_ctree(struct super_block *sb,
 	 */
 	fs_info->endio_workers.idle_thresh = 4;
 	fs_info->endio_meta_workers.idle_thresh = 4;
+	fs_info->endio_raid56_workers.idle_thresh = 4;
+	fs_info->rmw_workers.idle_thresh = 2;
 
 	fs_info->endio_write_workers.idle_thresh = 2;
 	fs_info->endio_meta_write_workers.idle_thresh = 2;
@@ -2366,6 +2396,8 @@ int open_ctree(struct super_block *sb,
 	ret |= btrfs_start_workers(&fs_info->fixup_workers);
 	ret |= btrfs_start_workers(&fs_info->endio_workers);
 	ret |= btrfs_start_workers(&fs_info->endio_meta_workers);
+	ret |= btrfs_start_workers(&fs_info->rmw_workers);
+	ret |= btrfs_start_workers(&fs_info->endio_raid56_workers);
 	ret |= btrfs_start_workers(&fs_info->endio_meta_write_workers);
 	ret |= btrfs_start_workers(&fs_info->endio_write_workers);
 	ret |= btrfs_start_workers(&fs_info->endio_freespace_worker);
@@ -2710,6 +2742,8 @@ int open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_workers);
+	btrfs_stop_workers(&fs_info->endio_raid56_workers);
+	btrfs_stop_workers(&fs_info->rmw_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->endio_freespace_worker);
@@ -2728,6 +2762,7 @@ int open_ctree(struct super_block *sb,
 fail_srcu:
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 fail:
+	btrfs_free_stripe_hash_table(fs_info);
 	btrfs_close_devices(fs_info->fs_devices);
 	return err;
 
@@ -3076,11 +3111,16 @@ int btrfs_calc_num_tolerated_disk_barrier_failures(
 				     ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK)
 				      == 0)))
 					num_tolerated_disk_barrier_failures = 0;
-				else if (num_tolerated_disk_barrier_failures > 1
-					 &&
-					 (flags & (BTRFS_BLOCK_GROUP_RAID1 |
-						   BTRFS_BLOCK_GROUP_RAID10)))
-					num_tolerated_disk_barrier_failures = 1;
+				else if (num_tolerated_disk_barrier_failures > 1) {
+					if (flags & (BTRFS_BLOCK_GROUP_RAID1 |
+					    BTRFS_BLOCK_GROUP_RAID5 |
+					    BTRFS_BLOCK_GROUP_RAID10)) {
+						num_tolerated_disk_barrier_failures = 1;
+					} else if (flags &
+						   BTRFS_BLOCK_GROUP_RAID5) {
+						num_tolerated_disk_barrier_failures = 2;
+					}
+				}
 			}
 		}
 		up_read(&sinfo->groups_sem);
@@ -3384,6 +3424,8 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_workers);
+	btrfs_stop_workers(&fs_info->endio_raid56_workers);
+	btrfs_stop_workers(&fs_info->rmw_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->endio_freespace_worker);
@@ -3404,6 +3446,8 @@ int close_ctree(struct btrfs_root *root)
 	bdi_destroy(&fs_info->bdi);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 
+	btrfs_free_stripe_hash_table(fs_info);
+
 	return 0;
 }
 

commit a22180d2666c018f4fef6818074d78bb76ff2bda
Merge: 2d4dce007044 213490b30177
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 18 09:42:05 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs update from Chris Mason:
     "A big set of fixes and features.
    
      In terms of line count, most of the code comes from Stefan, who added
      the ability to replace a single drive in place.  This is different
      from how btrfs normally replaces drives, and is much much much faster.
    
      Josef is plowing through our synchronous write performance.  This pull
      request does not include the DIO_OWN_WAITING patch that was discussed
      on the list, but it has a number of other improvements to cut down our
      latencies and CPU time during fsync/O_DIRECT writes.
    
      Miao Xie has a big series of fixes and is spreading out ordered
      operations over more CPUs.  This improves performance and reduces
      contention.
    
      I've put in fixes for error handling around hash collisions.  These
      are going back to individual stable kernels as I test against them.
    
      Otherwise we have a lot of fixes and cleanups, thanks everyone!
      raid5/6 is being rebased against the device replacement code.  I'll
      have it posted this Friday along with a nice series of benchmarks."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (115 commits)
      Btrfs: fix a bug of per-file nocow
      Btrfs: fix hash overflow handling
      Btrfs: don't take inode delalloc mutex if we're a free space inode
      Btrfs: fix autodefrag and umount lockup
      Btrfs: fix permissions of empty files not affected by umask
      Btrfs: put raid properties into global table
      Btrfs: fix BUG() in scrub when first superblock reading gives EIO
      Btrfs: do not call file_update_time in aio_write
      Btrfs: only unlock and relock if we have to
      Btrfs: use tokens where we can in the tree log
      Btrfs: optimize leaf_space_used
      Btrfs: don't memset new tokens
      Btrfs: only clear dirty on the buffer if it is marked as dirty
      Btrfs: move checks in set_page_dirty under DEBUG
      Btrfs: log changed inodes based on the extent map tree
      Btrfs: add path->really_keep_locks
      Btrfs: do not mark ems as prealloc if we are writing to them
      Btrfs: keep track of the extents original block length
      Btrfs: inline csums if we're fsyncing
      Btrfs: don't bother copying if we're only logging the inode
      ...

commit ed7b63eb8afd0bb8d978a23184d70c105b54aa26
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Oct 15 13:33:54 2012 -0400

    Btrfs: only clear dirty on the buffer if it is marked as dirty
    
    No reason to set the path blocking or loop through all of the pages if the
    extent buffer isn't actually marked dirty.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b8f7f04a6407..65f03670a952 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1142,11 +1142,11 @@ void clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 					  root->fs_info->dirty_metadata_bytes);
 			}
 			spin_unlock(&root->fs_info->delalloc_lock);
-		}
 
-		/* ugh, clear_extent_buffer_dirty needs to lock the page */
-		btrfs_set_lock_blocking(buf);
-		clear_extent_buffer_dirty(buf);
+			/* ugh, clear_extent_buffer_dirty needs to lock the page */
+			btrfs_set_lock_blocking(buf);
+			clear_extent_buffer_dirty(buf);
+		}
 	}
 }
 

commit bb146eb265091f472ada52a3419d41e9b0ff1f7d
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Oct 15 13:30:43 2012 -0400

    Btrfs: move checks in set_page_dirty under DEBUG
    
    This is a high traffic function, let's try and do as little as possible
    during normal operations shall we?
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index faf182691b40..b8f7f04a6407 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1001,6 +1001,7 @@ static void btree_invalidatepage(struct page *page, unsigned long offset)
 
 static int btree_set_page_dirty(struct page *page)
 {
+#ifdef DEBUG
 	struct extent_buffer *eb;
 
 	BUG_ON(!PagePrivate(page));
@@ -1009,6 +1010,7 @@ static int btree_set_page_dirty(struct page *page)
 	BUG_ON(!test_bit(EXTENT_BUFFER_DIRTY, &eb->bflags));
 	BUG_ON(!atomic_read(&eb->refs));
 	btrfs_assert_tree_locked(eb);
+#endif
 	return __set_page_dirty_nobuffers(page);
 }
 

commit 5f3ab90a72f98adbf00c50ac2d4d2b47cf4a9685
Author: Anand Jain <anand.jain@oracle.com>
Date:   Fri Dec 7 09:28:54 2012 +0000

    Btrfs: rename root_times_lock to root_item_lock
    
    Originally root_times_lock was introduced as part of send/receive
    code however newly developed patch to label the subvol reused
    the same lock, so renaming it for a meaningful name.
    
    Signed-off-by: Anand Jain <anand.jain@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3229531af8c3..faf182691b40 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1204,7 +1204,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->root_key.objectid = objectid;
 	root->anon_dev = 0;
 
-	spin_lock_init(&root->root_times_lock);
+	spin_lock_init(&root->root_item_lock);
 }
 
 static int __must_check find_and_setup_root(struct btrfs_root *tree_root,

commit 26176e7c2aa923327becdc25b5aca2cb907ac932
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Mon Nov 26 09:26:20 2012 +0000

    Btrfs: restructure btrfs_run_defrag_inodes()
    
    This patch restructure btrfs_run_defrag_inodes() and make the code of the auto
    defragment more readable.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 76b82506bf92..3229531af8c3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3329,7 +3329,7 @@ int close_ctree(struct btrfs_root *root)
 		   (atomic_read(&fs_info->defrag_running) == 0));
 
 	/* clear out the rbtree of defraggable inodes */
-	btrfs_run_defrag_inodes(fs_info);
+	btrfs_cleanup_defrag_inodes(fs_info);
 
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_commit_super(root);

commit 8dabb7420f014ab0f9f04afae8ae046c0f48b270
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Nov 6 13:15:27 2012 +0100

    Btrfs: change core code of btrfs to support the device replace operations
    
    This commit contains all the essential changes to the core code
    of Btrfs for support of the device replace procedure.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0e410478ad27..76b82506bf92 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -45,6 +45,7 @@
 #include "inode-map.h"
 #include "check-integrity.h"
 #include "rcu-string.h"
+#include "dev-replace.h"
 
 #ifdef CONFIG_X86
 #include <asm/cpufeature.h>
@@ -2438,7 +2439,11 @@ int open_ctree(struct super_block *sb,
 		goto fail_tree_roots;
 	}
 
-	btrfs_close_extra_devices(fs_devices);
+	/*
+	 * keep the device that is marked to be the target device for the
+	 * dev_replace procedure
+	 */
+	btrfs_close_extra_devices(fs_info, fs_devices, 0);
 
 	if (!fs_devices->latest_bdev) {
 		printk(KERN_CRIT "btrfs: failed to read devices on %s\n",
@@ -2510,6 +2515,14 @@ int open_ctree(struct super_block *sb,
 		goto fail_block_groups;
 	}
 
+	ret = btrfs_init_dev_replace(fs_info);
+	if (ret) {
+		pr_err("btrfs: failed to init dev_replace: %d\n", ret);
+		goto fail_block_groups;
+	}
+
+	btrfs_close_extra_devices(fs_info, fs_devices, 1);
+
 	ret = btrfs_init_space_info(fs_info);
 	if (ret) {
 		printk(KERN_ERR "Failed to initial space info: %d\n", ret);
@@ -2658,6 +2671,13 @@ int open_ctree(struct super_block *sb,
 		return ret;
 	}
 
+	ret = btrfs_resume_dev_replace_async(fs_info);
+	if (ret) {
+		pr_warn("btrfs: failed to resume dev_replace\n");
+		close_ctree(tree_root);
+		return ret;
+	}
+
 	return 0;
 
 fail_qgroup:
@@ -3300,6 +3320,8 @@ int close_ctree(struct btrfs_root *root)
 	/* pause restriper - we want to resume on mount */
 	btrfs_pause_balance(fs_info);
 
+	btrfs_dev_replace_suspend_for_unmount(fs_info);
+
 	btrfs_scrub_cancel(fs_info);
 
 	/* wait for any defraggers to finish */

commit 618919236ba54361e93106f4951d233a7ade63cd
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 18:51:52 2012 +0100

    Btrfs: handle errors from btrfs_map_bio() everywhere
    
    With the addition of the device replace procedure, it is possible
    for btrfs_map_bio(READ) to report an error. This happens when the
    specific mirror is requested which is located on the target disk,
    and the copy operation has not yet copied this block. Hence the
    block cannot be read and this error state is indicated by
    returning EIO.
    Some background information follows now. A new mirror is added
    while the device replace procedure is running.
    btrfs_get_num_copies() returns one more, and
    btrfs_map_bio(GET_READ_MIRROR) adds one more mirror if a disk
    location is involved that was already handled by the device
    replace copy operation. The assigned mirror num is the highest
    mirror number, e.g. the value 3 in case of RAID1.
    If btrfs_map_bio() is invoked with mirror_num == 0 (i.e., select
    any mirror), the copy on the target drive is never selected
    because that disk shall be able to perform the write requests as
    quickly as possible. The parallel execution of read requests would
    only slow down the disk copy procedure. Second case is that
    btrfs_map_bio() is called with mirror_num > 0. This is done from
    the repair code only. In this case, the highest mirror num is
    assigned to the target disk, since it is used last. And when this
    mirror is not available because the copy procedure has not yet
    handled this area, an error is returned. Everywhere in the code
    the handling of such errors is added now.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9d1b71060813..0e410478ad27 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -852,11 +852,16 @@ static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset)
 {
+	int ret;
+
 	/*
 	 * when we're called for a write, we're already in the async
 	 * submission context.  Just jump into btrfs_map_bio
 	 */
-	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num, 1);
+	ret = btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num, 1);
+	if (ret)
+		bio_endio(bio, ret);
+	return ret;
 }
 
 static int check_async_write(struct inode *inode, unsigned long bio_flags)
@@ -878,7 +883,6 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 	int ret;
 
 	if (!(rw & REQ_WRITE)) {
-
 		/*
 		 * called for a read, do the setup so that checksum validation
 		 * can happen in the async kernel threads
@@ -886,26 +890,32 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 		ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info,
 					  bio, 1);
 		if (ret)
-			return ret;
-		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
-				     mirror_num, 0);
+			goto out_w_error;
+		ret = btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
+				    mirror_num, 0);
 	} else if (!async) {
 		ret = btree_csum_one_bio(bio);
 		if (ret)
-			return ret;
-		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
-				     mirror_num, 0);
+			goto out_w_error;
+		ret = btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
+				    mirror_num, 0);
+	} else {
+		/*
+		 * kthread helpers are used to submit writes so that
+		 * checksumming can happen in parallel across all CPUs
+		 */
+		ret = btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
+					  inode, rw, bio, mirror_num, 0,
+					  bio_offset,
+					  __btree_submit_bio_start,
+					  __btree_submit_bio_done);
 	}
 
-	/*
-	 * kthread helpers are used to submit writes so that checksumming
-	 * can happen in parallel across all CPUs
-	 */
-	return btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
-				   inode, rw, bio, mirror_num, 0,
-				   bio_offset,
-				   __btree_submit_bio_start,
-				   __btree_submit_bio_done);
+	if (ret) {
+out_w_error:
+		bio_endio(bio, ret);
+	}
+	return ret;
 }
 
 #ifdef CONFIG_MIGRATION

commit e922e087a35c437acef3bc88ce31e59c699c38bd
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 17:26:40 2012 +0100

    Btrfs: enhance btrfs structures for device replace support
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 42a8024e935f..9d1b71060813 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2131,6 +2131,11 @@ int open_ctree(struct super_block *sb,
 	init_rwsem(&fs_info->extent_commit_sem);
 	init_rwsem(&fs_info->cleanup_work_sem);
 	init_rwsem(&fs_info->subvol_sem);
+	fs_info->dev_replace.lock_owner = 0;
+	atomic_set(&fs_info->dev_replace.nesting_level, 0);
+	mutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);
+	mutex_init(&fs_info->dev_replace.lock_management_lock);
+	mutex_init(&fs_info->dev_replace.lock);
 
 	spin_lock_init(&fs_info->qgroup_lock);
 	fs_info->qgroup_tree = RB_ROOT;

commit aa1b8cd409f05e1489ec77ff219eff6ed4b801b8
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 17:03:39 2012 +0100

    Btrfs: pass fs_info instead of root
    
    A small number of functions that are used in a device replace
    procedure when the operation is resumed at mount time are unable
    to pass the same root pointer that would be used in the regular
    (ioctl) context. And since the root pointer is not required, only
    the fs_info is, the root pointer argument is replaced with the
    fs_info pointer argument.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ba2b931fd8f6..42a8024e935f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3283,9 +3283,9 @@ int close_ctree(struct btrfs_root *root)
 	smp_mb();
 
 	/* pause restriper - we want to resume on mount */
-	btrfs_pause_balance(root->fs_info);
+	btrfs_pause_balance(fs_info);
 
-	btrfs_scrub_cancel(root);
+	btrfs_scrub_cancel(fs_info);
 
 	/* wait for any defraggers to finish */
 	wait_event(fs_info->transaction_wait,

commit 5d9640517d92d05843711ea982cbeff42d7ed32d
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Mon Nov 5 14:59:07 2012 +0100

    Btrfs: Pass fs_info to btrfs_num_copies() instead of mapping_tree
    
    This is required for the device replace procedure in a later step.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ff5d259ac275..ba2b931fd8f6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -387,7 +387,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		if (test_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags))
 			break;
 
-		num_copies = btrfs_num_copies(&root->fs_info->mapping_tree,
+		num_copies = btrfs_num_copies(root->fs_info,
 					      eb->start, eb->len);
 		if (num_copies == 1)
 			break;

commit b53d3f5db2b79637acadc06a330db6c2c60863f5
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Nov 14 14:34:34 2012 +0000

    Btrfs: cleanup for btrfs_btree_balance_dirty
    
    - 'nr' is no more used.
    - btrfs_btree_balance_dirty() and __btrfs_btree_balance_dirty() can share
      a bunch of code.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 07a2162cdd65..ff5d259ac275 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3411,7 +3411,8 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	}
 }
 
-void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
+static void __btrfs_btree_balance_dirty(struct btrfs_root *root,
+					int flush_delayed)
 {
 	/*
 	 * looks as though older kernels can get into trouble with
@@ -3423,7 +3424,8 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	if (current->flags & PF_MEMALLOC)
 		return;
 
-	btrfs_balance_delayed_items(root);
+	if (flush_delayed)
+		btrfs_balance_delayed_items(root);
 
 	num_dirty = root->fs_info->dirty_metadata_bytes;
 
@@ -3434,25 +3436,14 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	return;
 }
 
-void __btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
+void btrfs_btree_balance_dirty(struct btrfs_root *root)
 {
-	/*
-	 * looks as though older kernels can get into trouble with
-	 * this code, they end up stuck in balance_dirty_pages forever
-	 */
-	u64 num_dirty;
-	unsigned long thresh = 32 * 1024 * 1024;
-
-	if (current->flags & PF_MEMALLOC)
-		return;
-
-	num_dirty = root->fs_info->dirty_metadata_bytes;
+	__btrfs_btree_balance_dirty(root, 1);
+}
 
-	if (num_dirty > thresh) {
-		balance_dirty_pages_ratelimited_nr(
-				   root->fs_info->btree_inode->i_mapping, 1);
-	}
-	return;
+void btrfs_btree_balance_dirty_nodelay(struct btrfs_root *root)
+{
+	__btrfs_btree_balance_dirty(root, 0);
 }
 
 int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)

commit 31b1a2bd758f439fc945b3ac5899d890cb7e2dc6
Author: Julia Lawall <Julia.Lawall@lip6.fr>
Date:   Sat Nov 3 10:58:34 2012 +0000

    fs/btrfs: use WARN
    
    Use WARN rather than printk followed by WARN_ON(1), for conciseness.
    
    A simplified version of the semantic patch that makes this transformation
    is as follows: (http://coccinelle.lip6.fr/)
    
    // <smpl>
    @@
    expression list es;
    @@
    
    -printk(
    +WARN(1,
      es);
    -WARN_ON(1);
    // </smpl>
    
    Signed-off-by: Julia Lawall <Julia.Lawall@lip6.fr>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 064315990f8a..07a2162cdd65 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3397,14 +3397,12 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	int was_dirty;
 
 	btrfs_assert_tree_locked(buf);
-	if (transid != root->fs_info->generation) {
-		printk(KERN_CRIT "btrfs transid mismatch buffer %llu, "
+	if (transid != root->fs_info->generation)
+		WARN(1, KERN_CRIT "btrfs transid mismatch buffer %llu, "
 		       "found %llu running %llu\n",
 			(unsigned long long)buf->start,
 			(unsigned long long)transid,
 			(unsigned long long)root->fs_info->generation);
-		WARN_ON(1);
-	}
 	was_dirty = set_extent_buffer_dirty(buf);
 	if (!was_dirty) {
 		spin_lock(&root->fs_info->delalloc_lock);

commit 292fd7fc39aa06668f3a8db546714e727120cb3e
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Oct 30 17:16:16 2012 +0000

    Btrfs: don't allow degraded mount if too many devices are missing
    
    The current behavior is to allow mounting or remounting a filesystem
    writeable in degraded mode if at least one writeable device is
    present.
    The next failed write access to a missing device which is above
    the tolerance of the configured level of redundancy results in an
    read-only enforcement. Even without this, the next time
    barrier_all_devices() is called and more devices are missing than
    tolerable, the switch to read-only mode takes place.
    
    In order to behave predictably and to provide proper feedback to
    the user at mount time, this patch compares the number of missing
    devices with the number of devices that are tolerated to be missing
    according to the configured RAID level. If more devices are missing
    than tolerated, e.g. if two devices are missing in case of RAID1,
    only a read-only mount and remount is allowed.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bd70c2852ba0..064315990f8a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2508,6 +2508,13 @@ int open_ctree(struct super_block *sb,
 	}
 	fs_info->num_tolerated_disk_barrier_failures =
 		btrfs_calc_num_tolerated_disk_barrier_failures(fs_info);
+	if (fs_info->fs_devices->missing_devices >
+	     fs_info->num_tolerated_disk_barrier_failures &&
+	    !(sb->s_flags & MS_RDONLY)) {
+		printk(KERN_WARNING
+		       "Btrfs: too many missing devices, writeable mount is not allowed\n");
+		goto fail_block_groups;
+	}
 
 	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
 					       "btrfs-cleaner");

commit d0e1d66b5aa1ec9f556f951aa9a114cc192cd01c
Author: Namjae Jeon <linkinjeon@gmail.com>
Date:   Tue Dec 11 16:00:21 2012 -0800

    writeback: remove nr_pages_dirtied arg from balance_dirty_pages_ratelimited_nr()
    
    There is no reason to pass the nr_pages_dirtied argument, because
    nr_pages_dirtied value from the caller is unused in
    balance_dirty_pages_ratelimited_nr().
    
    Signed-off-by: Namjae Jeon <linkinjeon@gmail.com>
    Signed-off-by: Vivek Trivedi <vtrivedi018@gmail.com>
    Cc: Wu Fengguang <fengguang.wu@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7cda51995c1e..22a0439e5a86 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3416,8 +3416,8 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	num_dirty = root->fs_info->dirty_metadata_bytes;
 
 	if (num_dirty > thresh) {
-		balance_dirty_pages_ratelimited_nr(
-				   root->fs_info->btree_inode->i_mapping, 1);
+		balance_dirty_pages_ratelimited(
+				   root->fs_info->btree_inode->i_mapping);
 	}
 	return;
 }
@@ -3437,8 +3437,8 @@ void __btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	num_dirty = root->fs_info->dirty_metadata_bytes;
 
 	if (num_dirty > thresh) {
-		balance_dirty_pages_ratelimited_nr(
-				   root->fs_info->btree_inode->i_mapping, 1);
+		balance_dirty_pages_ratelimited(
+				   root->fs_info->btree_inode->i_mapping);
 	}
 	return;
 }

commit 8ccf6f19b67f7e0921063cc309f4672a6afcb528
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Oct 25 09:28:04 2012 +0000

    Btrfs: make delalloc inodes be flushed by multi-task
    
    This patch introduce a new worker pool named "flush_workers", and if we
    want to force all the inode with pending delalloc to the disks, we can
    queue those inodes into the work queue of the worker pool, in this way,
    those inodes will be flushed by multi-task.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7cda51995c1e..bd70c2852ba0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2279,6 +2279,10 @@ int open_ctree(struct super_block *sb,
 			   fs_info->thread_pool_size,
 			   &fs_info->generic_worker);
 
+	btrfs_init_workers(&fs_info->flush_workers, "flush_delalloc",
+			   fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
+
 	btrfs_init_workers(&fs_info->submit_workers, "submit",
 			   min_t(u64, fs_devices->num_devices,
 			   fs_info->thread_pool_size),
@@ -2350,6 +2354,7 @@ int open_ctree(struct super_block *sb,
 	ret |= btrfs_start_workers(&fs_info->delayed_workers);
 	ret |= btrfs_start_workers(&fs_info->caching_workers);
 	ret |= btrfs_start_workers(&fs_info->readahead_workers);
+	ret |= btrfs_start_workers(&fs_info->flush_workers);
 	if (ret) {
 		err = -ENOMEM;
 		goto fail_sb_buffer;
@@ -2667,6 +2672,7 @@ int open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->submit_workers);
 	btrfs_stop_workers(&fs_info->delayed_workers);
 	btrfs_stop_workers(&fs_info->caching_workers);
+	btrfs_stop_workers(&fs_info->flush_workers);
 fail_alloc:
 fail_iput:
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
@@ -3339,6 +3345,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->delayed_workers);
 	btrfs_stop_workers(&fs_info->caching_workers);
 	btrfs_stop_workers(&fs_info->readahead_workers);
+	btrfs_stop_workers(&fs_info->flush_workers);
 
 #ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
 	if (btrfs_test_opt(root, CHECK_INTEGRITY))

commit 1037a5affc266fdfe08b2dd415d309ab2778ce6a
Author: Wang Sheng-Hui <shhuiw@gmail.com>
Date:   Mon Oct 8 07:26:15 2012 -0600

    Btrfs: remove repeated eb->pages check in, disk-io.c/csum_dirty_buffer
    
    In csum_dirty_buffer, we first get eb from page->private.
    Then we check if the page is the first page of eb. Later
    we check it again. Remove the repeated check here.
    
    Signed-off-by: Wang Sheng-Hui <shhuiw@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 835523687707..7cda51995c1e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -433,10 +433,6 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 		WARN_ON(1);
 		return 0;
 	}
-	if (eb->pages[0] != page) {
-		WARN_ON(1);
-		return 0;
-	}
 	if (!PageUptodate(page)) {
 		WARN_ON(1);
 		return 0;

commit 5af3e8cce8b7ba0a2819e18c9146c8c0b452d479
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Aug 1 18:56:49 2012 +0200

    Btrfs: make filesystem read-only when submitting barrier fails
    
    So far the return code of barrier_all_devices() is ignored, which
    means that errors are ignored. The result can be a corrupt
    filesystem which is not consistent.
    This commit adds code to evaluate the return code of
    barrier_all_devices(). The normal btrfs_error() mechanism is used to
    switch the filesystem into read-only mode when errors are detected.
    
    In order to decide whether barrier_all_devices() should return
    error or success, the number of disks that are allowed to fail the
    barrier submission is calculated. This calculation accounts for the
    worst RAID level of metadata, system and data. If single, dup or
    RAID0 is in use, a single disk error is already considered to be
    fatal. Otherwise a single disk error is tolerated.
    
    The calculation of the number of disks that are tolerated to fail
    the barrier operation is performed when the filesystem gets mounted,
    when a balance operation is started and finished, and when devices
    are added or removed.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c69995556f61..835523687707 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2505,6 +2505,8 @@ int open_ctree(struct super_block *sb,
 		printk(KERN_ERR "Failed to read block groups: %d\n", ret);
 		goto fail_block_groups;
 	}
+	fs_info->num_tolerated_disk_barrier_failures =
+		btrfs_calc_num_tolerated_disk_barrier_failures(fs_info);
 
 	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
 					       "btrfs-cleaner");
@@ -2888,12 +2890,10 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 			printk_in_rcu("btrfs: disabling barriers on dev %s\n",
 				      rcu_str_deref(device->name));
 			device->nobarriers = 1;
-		}
-		if (!bio_flagged(bio, BIO_UPTODATE)) {
+		} else if (!bio_flagged(bio, BIO_UPTODATE)) {
 			ret = -EIO;
-			if (!bio_flagged(bio, BIO_EOPNOTSUPP))
-				btrfs_dev_stat_inc_and_print(device,
-					BTRFS_DEV_STAT_FLUSH_ERRS);
+			btrfs_dev_stat_inc_and_print(device,
+				BTRFS_DEV_STAT_FLUSH_ERRS);
 		}
 
 		/* drop the reference from the wait == 0 run */
@@ -2932,14 +2932,15 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 {
 	struct list_head *head;
 	struct btrfs_device *dev;
-	int errors = 0;
+	int errors_send = 0;
+	int errors_wait = 0;
 	int ret;
 
 	/* send down all the barriers */
 	head = &info->fs_devices->devices;
 	list_for_each_entry_rcu(dev, head, dev_list) {
 		if (!dev->bdev) {
-			errors++;
+			errors_send++;
 			continue;
 		}
 		if (!dev->in_fs_metadata || !dev->writeable)
@@ -2947,13 +2948,13 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 
 		ret = write_dev_flush(dev, 0);
 		if (ret)
-			errors++;
+			errors_send++;
 	}
 
 	/* wait for all the barriers */
 	list_for_each_entry_rcu(dev, head, dev_list) {
 		if (!dev->bdev) {
-			errors++;
+			errors_wait++;
 			continue;
 		}
 		if (!dev->in_fs_metadata || !dev->writeable)
@@ -2961,13 +2962,87 @@ static int barrier_all_devices(struct btrfs_fs_info *info)
 
 		ret = write_dev_flush(dev, 1);
 		if (ret)
-			errors++;
+			errors_wait++;
 	}
-	if (errors)
+	if (errors_send > info->num_tolerated_disk_barrier_failures ||
+	    errors_wait > info->num_tolerated_disk_barrier_failures)
 		return -EIO;
 	return 0;
 }
 
+int btrfs_calc_num_tolerated_disk_barrier_failures(
+	struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_ioctl_space_info space;
+	struct btrfs_space_info *sinfo;
+	u64 types[] = {BTRFS_BLOCK_GROUP_DATA,
+		       BTRFS_BLOCK_GROUP_SYSTEM,
+		       BTRFS_BLOCK_GROUP_METADATA,
+		       BTRFS_BLOCK_GROUP_DATA | BTRFS_BLOCK_GROUP_METADATA};
+	int num_types = 4;
+	int i;
+	int c;
+	int num_tolerated_disk_barrier_failures =
+		(int)fs_info->fs_devices->num_devices;
+
+	for (i = 0; i < num_types; i++) {
+		struct btrfs_space_info *tmp;
+
+		sinfo = NULL;
+		rcu_read_lock();
+		list_for_each_entry_rcu(tmp, &fs_info->space_info, list) {
+			if (tmp->flags == types[i]) {
+				sinfo = tmp;
+				break;
+			}
+		}
+		rcu_read_unlock();
+
+		if (!sinfo)
+			continue;
+
+		down_read(&sinfo->groups_sem);
+		for (c = 0; c < BTRFS_NR_RAID_TYPES; c++) {
+			if (!list_empty(&sinfo->block_groups[c])) {
+				u64 flags;
+
+				btrfs_get_block_group_info(
+					&sinfo->block_groups[c], &space);
+				if (space.total_bytes == 0 ||
+				    space.used_bytes == 0)
+					continue;
+				flags = space.flags;
+				/*
+				 * return
+				 * 0: if dup, single or RAID0 is configured for
+				 *    any of metadata, system or data, else
+				 * 1: if RAID5 is configured, or if RAID1 or
+				 *    RAID10 is configured and only two mirrors
+				 *    are used, else
+				 * 2: if RAID6 is configured, else
+				 * num_mirrors - 1: if RAID1 or RAID10 is
+				 *                  configured and more than
+				 *                  2 mirrors are used.
+				 */
+				if (num_tolerated_disk_barrier_failures > 0 &&
+				    ((flags & (BTRFS_BLOCK_GROUP_DUP |
+					       BTRFS_BLOCK_GROUP_RAID0)) ||
+				     ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK)
+				      == 0)))
+					num_tolerated_disk_barrier_failures = 0;
+				else if (num_tolerated_disk_barrier_failures > 1
+					 &&
+					 (flags & (BTRFS_BLOCK_GROUP_RAID1 |
+						   BTRFS_BLOCK_GROUP_RAID10)))
+					num_tolerated_disk_barrier_failures = 1;
+			}
+		}
+		up_read(&sinfo->groups_sem);
+	}
+
+	return num_tolerated_disk_barrier_failures;
+}
+
 int write_all_supers(struct btrfs_root *root, int max_mirrors)
 {
 	struct list_head *head;
@@ -2990,8 +3065,16 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
 	head = &root->fs_info->fs_devices->devices;
 
-	if (do_barriers)
-		barrier_all_devices(root->fs_info);
+	if (do_barriers) {
+		ret = barrier_all_devices(root->fs_info);
+		if (ret) {
+			mutex_unlock(
+				&root->fs_info->fs_devices->device_list_mutex);
+			btrfs_error(root->fs_info, ret,
+				    "errors while submitting device barriers.");
+			return ret;
+		}
+	}
 
 	list_for_each_entry_rcu(dev, head, dev_list) {
 		if (!dev->bdev) {

commit e6138876ad8327250d77291b3262fee356267211
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Sep 27 17:07:30 2012 -0400

    Btrfs: cache extent state when writing out dirty metadata pages
    
    Everytime we write out dirty pages we search for an offset in the tree,
    convert the bits in the state, and then when we wait we search for the
    offset again and clear the bits.  So for every dirty range in the io tree we
    are doing 4 rb searches, which is suboptimal.  With this patch we are only
    doing 2 searches for every cycle (modulo weird things happening).  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aa02eab8c40b..c69995556f61 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3572,7 +3572,7 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 
 	while (1) {
 		ret = find_first_extent_bit(dirty_pages, start, &start, &end,
-					    mark);
+					    mark, NULL);
 		if (ret)
 			break;
 
@@ -3627,7 +3627,7 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 again:
 	while (1) {
 		ret = find_first_extent_bit(unpin, 0, &start, &end,
-					    EXTENT_DIRTY);
+					    EXTENT_DIRTY, NULL);
 		if (ret)
 			break;
 

commit de0022b9da616b95ea5b41eab32da825b0b5150f
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Sep 25 14:25:58 2012 -0400

    Btrfs: do not async metadata csumming in certain situations
    
    There are a coule scenarios where farming metadata csumming off to an async
    thread doesn't help.  The first is if our processor supports crc32c, in
    which case the csumming will be fast and so the overhead of the async model
    is not worth the cost.  The other case is for our tree log.  We will be
    making that stuff dirty and writing it out and waiting for it immediately.
    Even with software crc32c this gives me a ~15% increase in speed with O_SYNC
    workloads.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dcaf55695e6f..aa02eab8c40b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -46,6 +46,10 @@
 #include "check-integrity.h"
 #include "rcu-string.h"
 
+#ifdef CONFIG_X86
+#include <asm/cpufeature.h>
+#endif
+
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
@@ -859,10 +863,22 @@ static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
 	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num, 1);
 }
 
+static int check_async_write(struct inode *inode, unsigned long bio_flags)
+{
+	if (bio_flags & EXTENT_BIO_TREE_LOG)
+		return 0;
+#ifdef CONFIG_X86
+	if (cpu_has_xmm4_2)
+		return 0;
+#endif
+	return 1;
+}
+
 static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags,
 				 u64 bio_offset)
 {
+	int async = check_async_write(inode, bio_flags);
 	int ret;
 
 	if (!(rw & REQ_WRITE)) {
@@ -877,6 +893,12 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 			return ret;
 		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
 				     mirror_num, 0);
+	} else if (!async) {
+		ret = btree_csum_one_bio(bio);
+		if (ret)
+			return ret;
+		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
+				     mirror_num, 0);
 	}
 
 	/*

commit 354aa0fb6d5b97b262e056f7ad7bfc88d7ce0004
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Sep 20 01:54:00 2012 -0600

    Btrfs: fix orphan transaction on the freezed filesystem
    
    With the following debug patch:
    
     static int btrfs_freeze(struct super_block *sb)
     {
    +       struct btrfs_fs_info *fs_info = btrfs_sb(sb);
    +       struct btrfs_transaction *trans;
    +
    +       spin_lock(&fs_info->trans_lock);
    +       trans = fs_info->running_transaction;
    +       if (trans) {
    +               printk("Transid %llu, use_count %d, num_writer %d\n",
    +                       trans->transid, atomic_read(&trans->use_count),
    +                       atomic_read(&trans->num_writers));
    +       }
    +       spin_unlock(&fs_info->trans_lock);
            return 0;
     }
    
    I found there was a orphan transaction after the freeze operation was done.
    
    It is because the transaction may not be committed when the transaction handle
    end even though it is the last handle of the current transaction. This design
    avoid committing the transaction frequently, but also introduce the above
    problem.
    
    So I add btrfs_attach_transaction() which can catch the current transaction
    and commit it. If there is no transaction, it will return ENOENT, and do not
    anything.
    
    This function also can be used to instead of btrfs_join_transaction_freeze()
    because it don't increase the writer counter and don't start a new transaction,
    so it also can fix the deadlock between sync and freeze.
    
    Besides that, it is used to instead of btrfs_join_transaction() in
    transaction_kthread(), because if there is no transaction, the transaction
    kthread needn't anything.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2c18a4eb4d5a..dcaf55695e6f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1657,9 +1657,10 @@ static int transaction_kthread(void *arg)
 		spin_unlock(&root->fs_info->trans_lock);
 
 		/* If the file system is aborted, this will always fail. */
-		trans = btrfs_join_transaction(root);
+		trans = btrfs_attach_transaction(root);
 		if (IS_ERR(trans)) {
-			cannot_commit = true;
+			if (PTR_ERR(trans) != -ENOENT)
+				cannot_commit = true;
 			goto sleep;
 		}
 		if (transid == trans->transid) {

commit 892951a92ebf8b390815b24f9418f297a5081898
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Sep 14 13:51:53 2012 -0400

    Btrfs: remove unused write cache pages hook
    
    The btree inode has it's own write cache pages so we can remove this write
    cache pages hook as it's not used.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5d3f813e13a0..2c18a4eb4d5a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3347,52 +3347,6 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 	return btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 }
 
-int btree_lock_page_hook(struct page *page, void *data,
-				void (*flush_fn)(void *))
-{
-	struct inode *inode = page->mapping->host;
-	struct btrfs_root *root = BTRFS_I(inode)->root;
-	struct extent_buffer *eb;
-
-	/*
-	 * We culled this eb but the page is still hanging out on the mapping,
-	 * carry on.
-	 */
-	if (!PagePrivate(page))
-		goto out;
-
-	eb = (struct extent_buffer *)page->private;
-	if (!eb) {
-		WARN_ON(1);
-		goto out;
-	}
-	if (page != eb->pages[0])
-		goto out;
-
-	if (!btrfs_try_tree_write_lock(eb)) {
-		flush_fn(data);
-		btrfs_tree_lock(eb);
-	}
-	btrfs_set_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN);
-
-	if (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &eb->bflags)) {
-		spin_lock(&root->fs_info->delalloc_lock);
-		if (root->fs_info->dirty_metadata_bytes >= eb->len)
-			root->fs_info->dirty_metadata_bytes -= eb->len;
-		else
-			WARN_ON(1);
-		spin_unlock(&root->fs_info->delalloc_lock);
-	}
-
-	btrfs_tree_unlock(eb);
-out:
-	if (!trylock_page(page)) {
-		flush_fn(data);
-		lock_page(page);
-	}
-	return 0;
-}
-
 static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 			      int read_only)
 {
@@ -3787,7 +3741,6 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 }
 
 static struct extent_io_ops btree_extent_io_ops = {
-	.write_cache_pages_lock_hook = btree_lock_page_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
 	.readpage_io_failed_hook = btree_io_failed_hook,
 	.submit_bio_hook = btree_submit_bio_hook,

commit 2e90cf858fd2639eae2fb3f2173f7633cb15bf38
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Fri Sep 14 02:58:06 2012 -0600

    Btrfs: cleanup fs_info->hashers
    
    fs_info->hashers is now an obsolete one.
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8d633e3e3919..5d3f813e13a0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1984,7 +1984,6 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->delayed_iputs);
-	INIT_LIST_HEAD(&fs_info->hashers);
 	INIT_LIST_HEAD(&fs_info->delalloc_inodes);
 	INIT_LIST_HEAD(&fs_info->ordered_operations);
 	INIT_LIST_HEAD(&fs_info->caching_block_groups);

commit b4f359ab065b9c6c132124557d23e90e2e8504be
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Thu Sep 13 03:32:54 2012 -0600

    Btrfs: remove unnecessary code in btree_get_extent()
    
    Unnecessary lookup_extent_mapping() is removed because an error is
    returned to the caller.
    This patch was made based on the advice from Stefan Behrens, thanks.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8db87bc53d27..8d633e3e3919 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -217,16 +217,10 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 	write_lock(&em_tree->lock);
 	ret = add_extent_mapping(em_tree, em);
 	if (ret == -EEXIST) {
-		u64 failed_start = em->start;
-		u64 failed_len = em->len;
-
 		free_extent_map(em);
 		em = lookup_extent_mapping(em_tree, start, len);
-		if (!em) {
-			lookup_extent_mapping(em_tree, failed_start,
-					      failed_len);
+		if (!em)
 			em = ERR_PTR(-EIO);
-		}
 	} else if (ret) {
 		free_extent_map(em);
 		em = ERR_PTR(ret);

commit 0433f20d436fd040013e5a419a2e3d732d618a41
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Thu Sep 13 03:32:32 2012 -0600

    Btrfs: cleanup of error processing in btree_get_extent()
    
    This patch simplifies a little complex error processing in
    btree_get_extent().
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8054f7ccf46a..8db87bc53d27 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -222,21 +222,17 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 
 		free_extent_map(em);
 		em = lookup_extent_mapping(em_tree, start, len);
-		if (em) {
-			ret = 0;
-		} else {
-			em = lookup_extent_mapping(em_tree, failed_start,
-						   failed_len);
-			ret = -EIO;
+		if (!em) {
+			lookup_extent_mapping(em_tree, failed_start,
+					      failed_len);
+			em = ERR_PTR(-EIO);
 		}
 	} else if (ret) {
 		free_extent_map(em);
-		em = NULL;
+		em = ERR_PTR(ret);
 	}
 	write_unlock(&em_tree->lock);
 
-	if (ret)
-		em = ERR_PTR(ret);
 out:
 	return em;
 }

commit 0647d6bd16c03c928a22d1b90c4c8684c5908f08
Author: liubo <liubo2009@cn.fujitsu.com>
Date:   Fri Sep 7 20:01:26 2012 -0600

    Btrfs: cleanup for unused ref cache stuff
    
    As ref cache has been removed from btrfs, there is no user on
    its lock and its check.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 34717ac2416a..8054f7ccf46a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2000,7 +2000,6 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->caching_block_groups);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->trans_lock);
-	spin_lock_init(&fs_info->ref_cache_lock);
 	spin_lock_init(&fs_info->fs_roots_radix_lock);
 	spin_lock_init(&fs_info->delayed_iput_lock);
 	spin_lock_init(&fs_info->defrag_inodes_lock);
@@ -3214,10 +3213,6 @@ int close_ctree(struct btrfs_root *root)
 		printk(KERN_INFO "btrfs: at unmount delalloc count %llu\n",
 		       (unsigned long long)fs_info->delalloc_bytes);
 	}
-	if (fs_info->total_ref_cache_size) {
-		printk(KERN_INFO "btrfs: at umount reference cache size %llu\n",
-		       (unsigned long long)fs_info->total_ref_cache_size);
-	}
 
 	free_extent_buffer(fs_info->extent_root->node);
 	free_extent_buffer(fs_info->extent_root->commit_root);

commit 2ecb79239bcd04c9d410f4cdce16adb6840b19da
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Sep 6 04:04:27 2012 -0600

    Btrfs: fix unprotected ->log_batch
    
    We forget to protect ->log_batch when syncing a file, this patch fix
    this problem by atomic operation. And ->log_batch is used to check
    if there are parallel sync operations or not, so it is unnecessary to
    reset it to 0 after the sync operation of the current log tree complete.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0dcfb998229e..34717ac2416a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1168,8 +1168,8 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	atomic_set(&root->log_commit[0], 0);
 	atomic_set(&root->log_commit[1], 0);
 	atomic_set(&root->log_writers, 0);
+	atomic_set(&root->log_batch, 0);
 	atomic_set(&root->orphan_inodes, 0);
-	root->log_batch = 0;
 	root->log_transid = 0;
 	root->last_log_commit = 0;
 	extent_io_tree_init(&root->dirty_log_pages,

commit 66d8f3dd1c87813d7f1cf8b774cb03e9b8d7e87e
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Sep 6 04:02:28 2012 -0600

    Btrfs: add a new "type" field into the block reservation structure
    
    Sometimes we need choose the method of the reservation according to the type
    of the block reservation, such as the reservation for the delayed inode update.
    Now we identify the type just by comparing the address of the reservation
    variants, it is very ugly if it is a temporary one because we need compare it
    with all the common reservation variants. So we add a new "type" field to keep
    the type the reservation variants.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 22e98e04c2ea..0dcfb998229e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2014,12 +2014,15 @@ int open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->space_info);
 	INIT_LIST_HEAD(&fs_info->tree_mod_seq_list);
 	btrfs_mapping_init(&fs_info->mapping_tree);
-	btrfs_init_block_rsv(&fs_info->global_block_rsv);
-	btrfs_init_block_rsv(&fs_info->delalloc_block_rsv);
-	btrfs_init_block_rsv(&fs_info->trans_block_rsv);
-	btrfs_init_block_rsv(&fs_info->chunk_block_rsv);
-	btrfs_init_block_rsv(&fs_info->empty_block_rsv);
-	btrfs_init_block_rsv(&fs_info->delayed_block_rsv);
+	btrfs_init_block_rsv(&fs_info->global_block_rsv,
+			     BTRFS_BLOCK_RSV_GLOBAL);
+	btrfs_init_block_rsv(&fs_info->delalloc_block_rsv,
+			     BTRFS_BLOCK_RSV_DELALLOC);
+	btrfs_init_block_rsv(&fs_info->trans_block_rsv, BTRFS_BLOCK_RSV_TRANS);
+	btrfs_init_block_rsv(&fs_info->chunk_block_rsv, BTRFS_BLOCK_RSV_CHUNK);
+	btrfs_init_block_rsv(&fs_info->empty_block_rsv, BTRFS_BLOCK_RSV_EMPTY);
+	btrfs_init_block_rsv(&fs_info->delayed_block_rsv,
+			     BTRFS_BLOCK_RSV_DELOPS);
 	atomic_set(&fs_info->nr_async_submits, 0);
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);

commit 318e15101993c0fdc3f23f24ac61fc7769d27e68
Merge: a7ccbcf33070 256dd1bb3750
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 29 11:36:22 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "I've split out the big send/receive update from my last pull request
      and now have just the fixes in my for-linus branch.  The send/recv
      branch will wander over to linux-next shortly though.
    
      The largest patches in this pull are Josef's patches to fix DIO
      locking problems and his patch to fix a crash during balance.  They
      are both well tested.
    
      The rest are smaller fixes that we've had queued.  The last rc came
      out while I was hacking new and exciting ways to recover from a
      misplaced rm -rf on my dev box, so these missed rc3."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (25 commits)
      Btrfs: fix that repair code is spuriously executed for transid failures
      Btrfs: fix ordered extent leak when failing to start a transaction
      Btrfs: fix a dio write regression
      Btrfs: fix deadlock with freeze and sync V2
      Btrfs: revert checksum error statistic which can cause a BUG()
      Btrfs: remove superblock writing after fatal error
      Btrfs: allow delayed refs to be merged
      Btrfs: fix enospc problems when deleting a subvol
      Btrfs: fix wrong mtime and ctime when creating snapshots
      Btrfs: fix race in run_clustered_refs
      Btrfs: don't run __tree_mod_log_free_eb on leaves
      Btrfs: increase the size of the free space cache
      Btrfs: barrier before waitqueue_active
      Btrfs: fix deadlock in wait_for_more_refs
      btrfs: fix second lock in btrfs_delete_delayed_items()
      Btrfs: don't allocate a seperate csums array for direct reads
      Btrfs: do not strdup non existent strings
      Btrfs: do not use missing devices when showing devname
      Btrfs: fix that error value is changed by mistake
      Btrfs: lock extents as we map them in DIO
      ...

commit 256dd1bb3750ac5ad49b40887c1691788dc44b33
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri Aug 10 08:58:21 2012 -0600

    Btrfs: fix that repair code is spuriously executed for transid failures
    
    If verify_parent_transid() fails for all mirrors, the current code
    calls repair_io_failure() anyway which means:
    - that the disk block is rewritten without repairing anything and
    - that a kernel log message is printed which misleadingly claims
      that a read error was corrected.
    
    This is an example:
    parent transid verify failed on 615015833600 wanted 110423 found 110424
    parent transid verify failed on 615015833600 wanted 110423 found 110424
    btrfs read error corrected: ino 1 off 615015833600 (dev /dev/...)
    
    It is wrong to ignore the results from verify_parent_transid() and to
    call repair_eb_io_failure() when the verification of the transids failed.
    This commit fixes the issue.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3c4c4397f470..29c69e60d3b0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -377,9 +377,13 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		ret = read_extent_buffer_pages(io_tree, eb, start,
 					       WAIT_COMPLETE,
 					       btree_get_extent, mirror_num);
-		if (!ret && !verify_parent_transid(io_tree, eb,
+		if (!ret) {
+			if (!verify_parent_transid(io_tree, eb,
 						   parent_transid, 0))
-			break;
+				break;
+			else
+				ret = -EIO;
+		}
 
 		/*
 		 * This buffer's crc is fine, but its contents are corrupted, so

commit 68ce9682a4bb95d6be5529cb57214bf2a1b7d20e
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Aug 1 05:45:52 2012 -0600

    Btrfs: remove superblock writing after fatal error
    
    With commit acce952b0, btrfs was changed to flag the filesystem with
    BTRFS_SUPER_FLAG_ERROR and switch to read-only mode after a fatal
    error happened like a write I/O errors of all mirrors.
    In such situations, on unmount, the superblock is written in
    btrfs_error_commit_super(). This is done with the intention to be able
    to evaluate the error flag on the next mount. A warning is printed
    in this case during the next mount and the log tree is ignored.
    
    The issue is that it is possible that the superblock points to a root
    that was not written (due to write I/O errors).
    The result is that the filesystem cannot be mounted. btrfsck also does
    not start and all the other btrfs-progs tools fail to start as well.
    However, mount -o recovery is working well and does the right things
    to recover the filesystem (i.e., don't use the log root, clear the
    free space cache and use the next mountable root that is stored in the
    root backup array).
    
    This patch removes the writing of the superblock when
    BTRFS_SUPER_FLAG_ERROR is set, and removes the handling of the error
    flag in the mount function.
    
    These lines can be used to reproduce the issue (using /dev/sdm):
    SCRATCH_DEV=/dev/sdm
    SCRATCH_MNT=/mnt
    echo 0 25165824 linear $SCRATCH_DEV 0 | dmsetup create foo
    ls -alLF /dev/mapper/foo
    mkfs.btrfs /dev/mapper/foo
    mount /dev/mapper/foo $SCRATCH_MNT
    echo bar > $SCRATCH_MNT/foo
    sync
    echo 0 25165824 error | dmsetup reload foo
    dmsetup resume foo
    ls -alF $SCRATCH_MNT
    touch $SCRATCH_MNT/1
    ls -alF $SCRATCH_MNT
    sleep 35
    echo 0 25165824 linear $SCRATCH_DEV 0 | dmsetup reload foo
    dmsetup resume foo
    sleep 1
    umount $SCRATCH_MNT
    btrfsck /dev/mapper/foo
    dmsetup remove foo
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dd86a5d88428..3c4c4397f470 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2527,8 +2527,7 @@ int open_ctree(struct super_block *sb,
 		goto fail_trans_kthread;
 
 	/* do not make disk changes in broken FS */
-	if (btrfs_super_log_root(disk_super) != 0 &&
-	    !(fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR)) {
+	if (btrfs_super_log_root(disk_super) != 0) {
 		u64 bytenr = btrfs_super_log_root(disk_super);
 
 		if (fs_devices->rw_devices == 0) {
@@ -3188,30 +3187,14 @@ int close_ctree(struct btrfs_root *root)
 	/* clear out the rbtree of defraggable inodes */
 	btrfs_run_defrag_inodes(fs_info);
 
-	/*
-	 * Here come 2 situations when btrfs is broken to flip readonly:
-	 *
-	 * 1. when btrfs flips readonly somewhere else before
-	 * btrfs_commit_super, sb->s_flags has MS_RDONLY flag,
-	 * and btrfs will skip to write sb directly to keep
-	 * ERROR state on disk.
-	 *
-	 * 2. when btrfs flips readonly just in btrfs_commit_super,
-	 * and in such case, btrfs cannot write sb via btrfs_commit_super,
-	 * and since fs_state has been set BTRFS_SUPER_FLAG_ERROR flag,
-	 * btrfs will cleanup all FS resources first and write sb then.
-	 */
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_commit_super(root);
 		if (ret)
 			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
 	}
 
-	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR) {
-		ret = btrfs_error_commit_super(root);
-		if (ret)
-			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
-	}
+	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR)
+		btrfs_error_commit_super(root);
 
 	btrfs_put_block_group_cache(fs_info);
 
@@ -3433,18 +3416,11 @@ static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 	if (read_only)
 		return 0;
 
-	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR) {
-		printk(KERN_WARNING "warning: mount fs with errors, "
-		       "running btrfsck is recommended\n");
-	}
-
 	return 0;
 }
 
-int btrfs_error_commit_super(struct btrfs_root *root)
+void btrfs_error_commit_super(struct btrfs_root *root)
 {
-	int ret;
-
 	mutex_lock(&root->fs_info->cleaner_mutex);
 	btrfs_run_delayed_iputs(root);
 	mutex_unlock(&root->fs_info->cleaner_mutex);
@@ -3454,10 +3430,6 @@ int btrfs_error_commit_super(struct btrfs_root *root)
 
 	/* cleanup FS via transaction */
 	btrfs_cleanup_transaction(root);
-
-	ret = write_ctree_super(NULL, root, 0);
-
-	return ret;
 }
 
 static void btrfs_destroy_ordered_operations(struct btrfs_root *root)

commit 66657b318e0e443ada229fccd40c8be86cfebdbf
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Aug 1 15:36:24 2012 -0400

    Btrfs: barrier before waitqueue_active
    
    We need a barrir before calling waitqueue_active otherwise we will miss
    wakeups.  So in places that do atomic_dec(); then atomic_read() use
    atomic_dec_return() which imply a memory barrier (see memory-barriers.txt)
    and then add an explicit memory barrier everywhere else that need them.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a7ad8fc8dc53..dd86a5d88428 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -754,9 +754,7 @@ static void run_one_async_done(struct btrfs_work *work)
 	limit = btrfs_async_submit_limit(fs_info);
 	limit = limit * 2 / 3;
 
-	atomic_dec(&fs_info->nr_async_submits);
-
-	if (atomic_read(&fs_info->nr_async_submits) < limit &&
+	if (atomic_dec_return(&fs_info->nr_async_submits) < limit &&
 	    waitqueue_active(&fs_info->async_submit_wait))
 		wake_up(&fs_info->async_submit_wait);
 
@@ -3783,14 +3781,17 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 		/* FIXME: cleanup wait for commit */
 		t->in_commit = 1;
 		t->blocked = 1;
+		smp_mb();
 		if (waitqueue_active(&root->fs_info->transaction_blocked_wait))
 			wake_up(&root->fs_info->transaction_blocked_wait);
 
 		t->blocked = 0;
+		smp_mb();
 		if (waitqueue_active(&root->fs_info->transaction_wait))
 			wake_up(&root->fs_info->transaction_wait);
 
 		t->commit_done = 1;
+		smp_mb();
 		if (waitqueue_active(&t->commit_wait))
 			wake_up(&t->commit_wait);
 

commit 1fa11e265fa2562fb713171b6a58e72bb7afd276
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon Aug 6 14:18:51 2012 -0600

    Btrfs: fix deadlock in wait_for_more_refs
    
    Commit a168650c introduced a waiting mechanism to prevent busy waiting in
    btrfs_run_delayed_refs. This can deadlock with btrfs_run_ordered_operations,
    where a tree_mod_seq is held while waiting for the io to complete, while
    the end_io calls btrfs_run_delayed_refs.
    This whole mechanism is unnecessary. If not enough runnable refs are
    available to satisfy count, just return as count is more like a guideline
    than a strict requirement.
    In case we have to run all refs, commit transaction makes sure that no
    other threads are working in the transaction anymore, so we just assert
    here that no refs are blocked.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 502b20c56e84..a7ad8fc8dc53 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2035,8 +2035,6 @@ int open_ctree(struct super_block *sb,
 	fs_info->free_chunk_space = 0;
 	fs_info->tree_mod_log = RB_ROOT;
 
-	init_waitqueue_head(&fs_info->tree_mod_seq_wait);
-
 	/* readahead state */
 	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_WAIT);
 	spin_lock_init(&fs_info->reada_lock);

commit a0e881b7c189fa2bd76c024dbff91e79511c971d
Merge: eff0d13f3823 dbc6e0222d79
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 1 10:26:23 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull second vfs pile from Al Viro:
     "The stuff in there: fsfreeze deadlock fixes by Jan (essentially, the
      deadlock reproduced by xfstests 068), symlink and hardlink restriction
      patches, plus assorted cleanups and fixes.
    
      Note that another fsfreeze deadlock (emergency thaw one) is *not*
      dealt with - the series by Fernando conflicts a lot with Jan's, breaks
      userland ABI (FIFREEZE semantics gets changed) and trades the deadlock
      for massive vfsmount leak; this is going to be handled next cycle.
      There probably will be another pull request, but that stuff won't be
      in it."
    
    Fix up trivial conflicts due to unrelated changes next to each other in
    drivers/{staging/gdm72xx/usb_boot.c, usb/gadget/storage_common.c}
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (54 commits)
      delousing target_core_file a bit
      Documentation: Correct s_umount state for freeze_fs/unfreeze_fs
      fs: Remove old freezing mechanism
      ext2: Implement freezing
      btrfs: Convert to new freezing mechanism
      nilfs2: Convert to new freezing mechanism
      ntfs: Convert to new freezing mechanism
      fuse: Convert to new freezing mechanism
      gfs2: Convert to new freezing mechanism
      ocfs2: Convert to new freezing mechanism
      xfs: Convert to new freezing code
      ext4: Convert to new freezing mechanism
      fs: Protect write paths by sb_start_write - sb_end_write
      fs: Skip atime update on frozen filesystem
      fs: Add freezing handling to mnt_want_write() / mnt_drop_write()
      fs: Improve filesystem freezing handling
      switch the protection of percpu_counter list to spinlock
      nfsd: Push mnt_want_write() outside of i_mutex
      btrfs: Push mnt_want_write() outside of i_mutex
      fat: Push mnt_want_write() outside of i_mutex
      ...

commit b2b5ef5c8e89f19b68c174bf246f3ca212dbf0bc
Author: Jan Kara <jack@suse.cz>
Date:   Tue Jun 12 16:20:45 2012 +0200

    btrfs: Convert to new freezing mechanism
    
    We convert btrfs_file_aio_write() to use new freeze check.  We also add proper
    freeze protection to btrfs_page_mkwrite(). We also add freeze protection to
    the transaction mechanism to avoid starting transactions on frozen filesystem.
    At minimum this is necessary to stop iput() of unlinked file to change frozen
    filesystem during truncation.
    
    Checks in cleaner_kthread() and transaction_kthread() can be safely removed
    since btrfs_freeze() will lock the mutexes and thus block the threads (and they
    shouldn't have anything to do anyway).
    
    CC: linux-btrfs@vger.kernel.org
    CC: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2936ca49b3b4..20c49b16b759 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1533,8 +1533,6 @@ static int cleaner_kthread(void *arg)
 	struct btrfs_root *root = arg;
 
 	do {
-		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
-
 		if (!(root->fs_info->sb->s_flags & MS_RDONLY) &&
 		    mutex_trylock(&root->fs_info->cleaner_mutex)) {
 			btrfs_run_delayed_iputs(root);
@@ -1566,7 +1564,6 @@ static int transaction_kthread(void *arg)
 	do {
 		cannot_commit = false;
 		delay = HZ * 30;
-		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
 		mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
 		spin_lock(&root->fs_info->trans_lock);

commit 533574c6bc30cf526cc1c41bde050c854a945efb
Author: Joe Perches <joe@perches.com>
Date:   Mon Jul 30 14:40:13 2012 -0700

    btrfs: use printk_get_level and printk_skip_level, add __printf, fix fallout
    
    Use the generic printk_get_level() to search a message for a kern_level.
    
    Add __printf to verify format and arguments.  Fix a few messages that
    had mismatches in format and arguments.  Add #ifdef CONFIG_PRINTK blocks
    to shrink the object size a bit when not using printk.
    
    [akpm@linux-foundation.org: whitespace tweak]
    Signed-off-by: Joe Perches <joe@perches.com>
    Cc: Kay Sievers <kay.sievers@vrfy.org>
    Cc: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 502b20c56e84..fadeba6a5db9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1114,7 +1114,7 @@ void clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 				spin_unlock(&root->fs_info->delalloc_lock);
 				btrfs_panic(root->fs_info, -EOVERFLOW,
 					  "Can't clear %lu bytes from "
-					  " dirty_mdatadata_bytes (%lu)",
+					  " dirty_mdatadata_bytes (%llu)",
 					  buf->len,
 					  root->fs_info->dirty_metadata_bytes);
 			}

commit 113c1cb530e10bcada93d88ffaa6b521aae2d251
Merge: cd1cfc49153b 31db9f7c23fb
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Jul 25 19:17:39 2012 -0400

    Merge branch 'send-v2' of git://github.com/ablock84/linux-btrfs into for-linus
    
    This is the kernel portion of btrfs send/receive
    
    Conflicts:
            fs/btrfs/Makefile
            fs/btrfs/backref.h
            fs/btrfs/ctree.c
            fs/btrfs/ioctl.c
            fs/btrfs/ioctl.h
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

commit 8ea05e3a4262b9e6871c349fa3486bcfc72ffd1a
Author: Alexander Block <ablock84@googlemail.com>
Date:   Wed Jul 25 17:35:53 2012 +0200

    Btrfs: introduce subvol uuids and times
    
    This patch introduces uuids for subvolumes. Each
    subvolume has it's own uuid. In case it was snapshotted,
    it also contains parent_uuid. In case it was received,
    it also contains received_uuid.
    
    It also introduces subvolume ctime/otime/stime/rtime. The
    first two are comparable to the times found in inodes. otime
    is the origin/creation time and ctime is the change time.
    stime/rtime are only valid on received subvolumes.
    stime is the time of the subvolume when it was
    sent. rtime is the time of the subvolume when it was
    received.
    
    Additionally to the times, we have a transid for each
    time. They are updated at the same place as the times.
    
    btrfs receive uses stransid and rtransid to find out
    if a received subvolume changed in the meantime.
    
    If an older kernel mounts a filesystem with the
    extented fields, all fields become invalid. The next
    mount with a new kernel will detect this and reset the
    fields.
    
    Signed-off-by: Alexander Block <ablock84@googlemail.com>
    Reviewed-by: David Sterba <dave@jikos.cz>
    Reviewed-by: Arne Jansen <sensille@gmx.net>
    Reviewed-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Reviewed-by: Alex Lyakas <alex.bolshoy.btrfs@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2936ca49b3b4..c39eb71fae31 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1182,6 +1182,8 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->defrag_running = 0;
 	root->root_key.objectid = objectid;
 	root->anon_dev = 0;
+
+	spin_lock_init(&root->root_times_lock);
 }
 
 static int __must_check find_and_setup_root(struct btrfs_root *tree_root,
@@ -1326,6 +1328,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	u64 generation;
 	u32 blocksize;
 	int ret = 0;
+	int slot;
 
 	root = btrfs_alloc_root(fs_info);
 	if (!root)
@@ -1352,9 +1355,8 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	ret = btrfs_search_slot(NULL, tree_root, location, path, 0, 0);
 	if (ret == 0) {
 		l = path->nodes[0];
-		read_extent_buffer(l, &root->root_item,
-				btrfs_item_ptr_offset(l, path->slots[0]),
-				sizeof(root->root_item));
+		slot = path->slots[0];
+		btrfs_read_root_item(tree_root, l, slot, &root->root_item);
 		memcpy(&root->root_key, location, sizeof(*location));
 	}
 	btrfs_free_path(path);

commit b478b2baa37ac99fc04a30809c780dd5dfd43595
Merge: 67c9684f48ea 6f72c7e20dba
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Jul 25 16:11:38 2012 -0400

    Merge branch 'qgroup' of git://git.jan-o-sch.net/btrfs-unstable into for-linus
    
    Conflicts:
            fs/btrfs/ioctl.c
            fs/btrfs/ioctl.h
            fs/btrfs/transaction.c
            fs/btrfs/transaction.h
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

commit c0901581ad077004145c9ee80e843fba71c100b8
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Tue Jul 10 07:30:17 2012 -0600

    Btrfs: avoid I/O repair BUG() from btree_read_extent_buffer_pages()
    
    From btree_read_extent_buffer_pages(), currently repair_io_failure()
    can be called with mirror_num being zero when submit_one_bio() returned
    an error before. This used to cause a BUG_ON(!mirror_num) in
    repair_io_failure() and indeed this is not a case that needs the I/O
    repair code to rewrite disk blocks.
    This commit prevents calling repair_io_failure() in this case and thus
    avoids the BUG_ON() and malfunction.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dd6676b446f6..1a4a2a975926 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -407,7 +407,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 			break;
 	}
 
-	if (failed && !ret)
+	if (failed && !ret && failed_mirror)
 		repair_eb_io_failure(root, eb, failed_mirror);
 
 	return ret;

commit 44c44af2f4a6dc1595f1711cf307bd01062fd129
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Fri Jun 22 12:14:13 2012 -0600

    Btrfs: do not ignore errors from btrfs_cleanup_fs_roots() when mounting
    
    There used to be a BUG_ON(ret) there before EH patch (79787eaa) went in.
    Bail out with EINVAL.
    
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fd216d9369fa..dd6676b446f6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2466,8 +2466,8 @@ int open_ctree(struct super_block *sb,
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_cleanup_fs_roots(fs_info);
-		if (ret) {
-			}
+		if (ret)
+			goto fail_trans_kthread;
 
 		ret = btrfs_recover_relocation(tree_root);
 		if (ret < 0) {

commit fed425c742cb1262ce90a41f2d3d211bac099533
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Fri Jun 22 12:13:01 2012 -0600

    Btrfs: do not return EINVAL instead of ENOMEM from open_ctree()
    
    When bailing from open_ctree() err is returned, not ret.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2936ca49b3b4..fd216d9369fa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2244,7 +2244,7 @@ int open_ctree(struct super_block *sb,
 	ret |= btrfs_start_workers(&fs_info->caching_workers);
 	ret |= btrfs_start_workers(&fs_info->readahead_workers);
 	if (ret) {
-		ret = -ENOMEM;
+		err = -ENOMEM;
 		goto fail_sb_buffer;
 	}
 

commit bcef60f249034f69e89e544461cbfecb68975595
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 15:23:30 2011 +0200

    Btrfs: quota tree support and startup
    
    Init the quota tree along with the others on open_ctree
    and close_ctree. Add the quota tree to the list of well
    known trees in btrfs_read_fs_root_no_name.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eca054974425..87d9391c0576 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1472,6 +1472,9 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 		return fs_info->dev_root;
 	if (location->objectid == BTRFS_CSUM_TREE_OBJECTID)
 		return fs_info->csum_root;
+	if (location->objectid == BTRFS_QUOTA_TREE_OBJECTID)
+		return fs_info->quota_root ? fs_info->quota_root :
+					     ERR_PTR(-ENOENT);
 again:
 	spin_lock(&fs_info->fs_roots_radix_lock);
 	root = radix_tree_lookup(&fs_info->fs_roots_radix,
@@ -1899,6 +1902,10 @@ static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 	free_extent_buffer(info->extent_root->commit_root);
 	free_extent_buffer(info->csum_root->node);
 	free_extent_buffer(info->csum_root->commit_root);
+	if (info->quota_root) {
+		free_extent_buffer(info->quota_root->node);
+		free_extent_buffer(info->quota_root->commit_root);
+	}
 
 	info->tree_root->node = NULL;
 	info->tree_root->commit_root = NULL;
@@ -1908,6 +1915,10 @@ static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 	info->extent_root->commit_root = NULL;
 	info->csum_root->node = NULL;
 	info->csum_root->commit_root = NULL;
+	if (info->quota_root) {
+		info->quota_root->node = NULL;
+		info->quota_root->commit_root = NULL;
+	}
 
 	if (chunk_root) {
 		free_extent_buffer(info->chunk_root->node);
@@ -1938,6 +1949,7 @@ int open_ctree(struct super_block *sb,
 	struct btrfs_root *csum_root;
 	struct btrfs_root *chunk_root;
 	struct btrfs_root *dev_root;
+	struct btrfs_root *quota_root;
 	struct btrfs_root *log_tree_root;
 	int ret;
 	int err = -EINVAL;
@@ -1949,9 +1961,10 @@ int open_ctree(struct super_block *sb,
 	csum_root = fs_info->csum_root = btrfs_alloc_root(fs_info);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info);
 	dev_root = fs_info->dev_root = btrfs_alloc_root(fs_info);
+	quota_root = fs_info->quota_root = btrfs_alloc_root(fs_info);
 
 	if (!tree_root || !extent_root || !csum_root ||
-	    !chunk_root || !dev_root) {
+	    !chunk_root || !dev_root || !quota_root) {
 		err = -ENOMEM;
 		goto fail;
 	}
@@ -2441,6 +2454,17 @@ int open_ctree(struct super_block *sb,
 		goto recovery_tree_root;
 	csum_root->track_dirty = 1;
 
+	ret = find_and_setup_root(tree_root, fs_info,
+				  BTRFS_QUOTA_TREE_OBJECTID, quota_root);
+	if (ret) {
+		kfree(quota_root);
+		quota_root = fs_info->quota_root = NULL;
+	} else {
+		quota_root->track_dirty = 1;
+		fs_info->quota_enabled = 1;
+		fs_info->pending_quota_state = 1;
+	}
+
 	fs_info->generation = generation;
 	fs_info->last_trans_committed = generation;
 
@@ -2500,6 +2524,9 @@ int open_ctree(struct super_block *sb,
 			       " integrity check module %s\n", sb->s_id);
 	}
 #endif
+	ret = btrfs_read_qgroup_config(fs_info);
+	if (ret)
+		goto fail_trans_kthread;
 
 	/* do not make disk changes in broken FS */
 	if (btrfs_super_log_root(disk_super) != 0 &&
@@ -2510,7 +2537,7 @@ int open_ctree(struct super_block *sb,
 			printk(KERN_WARNING "Btrfs log replay required "
 			       "on RO media\n");
 			err = -EIO;
-			goto fail_trans_kthread;
+			goto fail_qgroup;
 		}
 		blocksize =
 		     btrfs_level_size(tree_root,
@@ -2519,7 +2546,7 @@ int open_ctree(struct super_block *sb,
 		log_tree_root = btrfs_alloc_root(fs_info);
 		if (!log_tree_root) {
 			err = -ENOMEM;
-			goto fail_trans_kthread;
+			goto fail_qgroup;
 		}
 
 		__setup_root(nodesize, leafsize, sectorsize, stripesize,
@@ -2559,7 +2586,7 @@ int open_ctree(struct super_block *sb,
 			printk(KERN_WARNING
 			       "btrfs: failed to recover relocation\n");
 			err = -EINVAL;
-			goto fail_trans_kthread;
+			goto fail_qgroup;
 		}
 	}
 
@@ -2569,10 +2596,10 @@ int open_ctree(struct super_block *sb,
 
 	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
 	if (!fs_info->fs_root)
-		goto fail_trans_kthread;
+		goto fail_qgroup;
 	if (IS_ERR(fs_info->fs_root)) {
 		err = PTR_ERR(fs_info->fs_root);
-		goto fail_trans_kthread;
+		goto fail_qgroup;
 	}
 
 	if (sb->s_flags & MS_RDONLY)
@@ -2596,6 +2623,8 @@ int open_ctree(struct super_block *sb,
 
 	return 0;
 
+fail_qgroup:
+	btrfs_free_qgroup_config(fs_info);
 fail_trans_kthread:
 	kthread_stop(fs_info->transaction_kthread);
 fail_cleaner:
@@ -3194,6 +3223,8 @@ int close_ctree(struct btrfs_root *root)
 	fs_info->closing = 2;
 	smp_mb();
 
+	btrfs_free_qgroup_config(root->fs_info);
+
 	if (fs_info->delalloc_bytes) {
 		printk(KERN_INFO "btrfs: at unmount delalloc count %llu\n",
 		       (unsigned long long)fs_info->delalloc_bytes);
@@ -3213,6 +3244,10 @@ int close_ctree(struct btrfs_root *root)
 	free_extent_buffer(fs_info->dev_root->commit_root);
 	free_extent_buffer(fs_info->csum_root->node);
 	free_extent_buffer(fs_info->csum_root->commit_root);
+	if (fs_info->quota_root) {
+		free_extent_buffer(fs_info->quota_root->node);
+		free_extent_buffer(fs_info->quota_root->commit_root);
+	}
 
 	btrfs_free_block_groups(fs_info);
 

commit 416ac51da90e98daaac17e1f359a6c5591f7f5bd
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 12:56:09 2011 +0200

    Btrfs: qgroup state and initialization
    
    Add state to fs_info.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6fc243eccffa..eca054974425 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2110,6 +2110,13 @@ int open_ctree(struct super_block *sb,
 	init_rwsem(&fs_info->cleanup_work_sem);
 	init_rwsem(&fs_info->subvol_sem);
 
+	spin_lock_init(&fs_info->qgroup_lock);
+	fs_info->qgroup_tree = RB_ROOT;
+	INIT_LIST_HEAD(&fs_info->dirty_qgroups);
+	fs_info->qgroup_seq = 1;
+	fs_info->quota_enabled = 0;
+	fs_info->pending_quota_state = 0;
+
 	btrfs_init_free_cluster(&fs_info->meta_alloc_cluster);
 	btrfs_init_free_cluster(&fs_info->data_alloc_cluster);
 

commit 20897f5c86b9d2b77baea1d48eda7fa4ac217279
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 12:44:20 2011 +0200

    Btrfs: added helper to create new trees
    
    This creates a brand new tree. Will be used to create
    the quota tree.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 19a39e10d6f5..6fc243eccffa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1225,6 +1225,82 @@ static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info)
 	return root;
 }
 
+struct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,
+				     struct btrfs_fs_info *fs_info,
+				     u64 objectid)
+{
+	struct extent_buffer *leaf;
+	struct btrfs_root *tree_root = fs_info->tree_root;
+	struct btrfs_root *root;
+	struct btrfs_key key;
+	int ret = 0;
+	u64 bytenr;
+
+	root = btrfs_alloc_root(fs_info);
+	if (!root)
+		return ERR_PTR(-ENOMEM);
+
+	__setup_root(tree_root->nodesize, tree_root->leafsize,
+		     tree_root->sectorsize, tree_root->stripesize,
+		     root, fs_info, objectid);
+	root->root_key.objectid = objectid;
+	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
+	root->root_key.offset = 0;
+
+	leaf = btrfs_alloc_free_block(trans, root, root->leafsize,
+				      0, objectid, NULL, 0, 0, 0);
+	if (IS_ERR(leaf)) {
+		ret = PTR_ERR(leaf);
+		goto fail;
+	}
+
+	bytenr = leaf->start;
+	memset_extent_buffer(leaf, 0, 0, sizeof(struct btrfs_header));
+	btrfs_set_header_bytenr(leaf, leaf->start);
+	btrfs_set_header_generation(leaf, trans->transid);
+	btrfs_set_header_backref_rev(leaf, BTRFS_MIXED_BACKREF_REV);
+	btrfs_set_header_owner(leaf, objectid);
+	root->node = leaf;
+
+	write_extent_buffer(leaf, fs_info->fsid,
+			    (unsigned long)btrfs_header_fsid(leaf),
+			    BTRFS_FSID_SIZE);
+	write_extent_buffer(leaf, fs_info->chunk_tree_uuid,
+			    (unsigned long)btrfs_header_chunk_tree_uuid(leaf),
+			    BTRFS_UUID_SIZE);
+	btrfs_mark_buffer_dirty(leaf);
+
+	root->commit_root = btrfs_root_node(root);
+	root->track_dirty = 1;
+
+
+	root->root_item.flags = 0;
+	root->root_item.byte_limit = 0;
+	btrfs_set_root_bytenr(&root->root_item, leaf->start);
+	btrfs_set_root_generation(&root->root_item, trans->transid);
+	btrfs_set_root_level(&root->root_item, 0);
+	btrfs_set_root_refs(&root->root_item, 1);
+	btrfs_set_root_used(&root->root_item, leaf->len);
+	btrfs_set_root_last_snapshot(&root->root_item, 0);
+	btrfs_set_root_dirid(&root->root_item, 0);
+	root->root_item.drop_level = 0;
+
+	key.objectid = objectid;
+	key.type = BTRFS_ROOT_ITEM_KEY;
+	key.offset = 0;
+	ret = btrfs_insert_root(trans, tree_root, &key, &root->root_item);
+	if (ret)
+		goto fail;
+
+	btrfs_tree_unlock(leaf);
+
+fail:
+	if (ret)
+		return ERR_PTR(ret);
+
+	return root;
+}
+
 static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info)
 {
@@ -3260,7 +3336,7 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 	return btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 }
 
-static int btree_lock_page_hook(struct page *page, void *data,
+int btree_lock_page_hook(struct page *page, void *data,
 				void (*flush_fn)(void *))
 {
 	struct inode *inode = page->mapping->host;

commit 097b8a7c9e48e2cb50fd0eb9315791921beaf484
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Thu Jun 21 11:08:04 2012 +0200

    Btrfs: join tree mod log code with the code holding back delayed refs
    
    We've got two mechanisms both required for reliable backref resolving (tree
    mod log and holding back delayed refs). You cannot make use of one without
    the other. So instead of requiring the user of this mechanism to setup both
    correctly, we join them into a single interface.
    
    Additionally, we stop inserting non-blockers into fs_info->tree_mod_seq_list
    as we did before, which was of no value.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8cc47103a32e..19a39e10d6f5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1944,6 +1944,8 @@ int open_ctree(struct super_block *sb,
 	fs_info->free_chunk_space = 0;
 	fs_info->tree_mod_log = RB_ROOT;
 
+	init_waitqueue_head(&fs_info->tree_mod_seq_wait);
+
 	/* readahead state */
 	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_WAIT);
 	spin_lock_init(&fs_info->reada_lock);

commit 5eecb9cc9029aef3c308fc94149c4a3065d40d9a
Merge: 62ad64498a2e b6305567e7d3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 5 13:06:25 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "I held off on my rc5 pull because I hit an oops during log recovery
      after a crash.  I wanted to make sure it wasn't a regression because
      we have some logging fixes in here.
    
      It turns out that a commit during the merge window just made it much
      more likely to trigger directory logging instead of full commits,
      which exposed an old bug.
    
      The new backref walking code got some additional fixes.  This should
      be the final set of them.
    
      Josef fixed up a corner where our O_DIRECT writes and buffered reads
      could expose old file contents (not stale, just not the most recent).
      He and Liu Bo fixed crashes during tree log recover as well.
    
      Ilya fixed errors while we resume disk balancing operations on
      readonly mounts."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: run delayed directory updates during log replay
      Btrfs: hold a ref on the inode during writepages
      Btrfs: fix tree log remove space corner case
      Btrfs: fix wrong check during log recovery
      Btrfs: use _IOR for BTRFS_IOC_SUBVOL_GETFLAGS
      Btrfs: resume balance on rw (re)mounts properly
      Btrfs: restore restriper state on all mounts
      Btrfs: fix dio write vs buffered read race
      Btrfs: don't count I/O statistic read errors for missing devices
      Btrfs: resolve tree mod log locking issue in btrfs_next_leaf
      Btrfs: fix tree mod log rewind of ADD operations
      Btrfs: leave critical region in btrfs_find_all_roots as soon as possible
      Btrfs: always put insert_ptr modifications into the tree mod log
      Btrfs: fix tree mod log for root replacements at leaf level
      Btrfs: support root level changes in __resolve_indirect_ref
      Btrfs: avoid waiting for delayed refs when we must not

commit 2b6ba629b5aac51e7099efbb43e2b403213aa7fb
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Fri Jun 22 12:24:13 2012 -0600

    Btrfs: resume balance on rw (re)mounts properly
    
    This introduces btrfs_resume_balance_async(), which, given that
    restriper state was recovered earlier by btrfs_recover_balance(),
    resumes balance in btrfs-balance kthread.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3a7961ba161e..8cc47103a32e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2490,17 +2490,23 @@ int open_ctree(struct super_block *sb,
 		goto fail_trans_kthread;
 	}
 
-	if (!(sb->s_flags & MS_RDONLY)) {
-		down_read(&fs_info->cleanup_work_sem);
-		err = btrfs_orphan_cleanup(fs_info->fs_root);
-		if (!err)
-			err = btrfs_orphan_cleanup(fs_info->tree_root);
+	if (sb->s_flags & MS_RDONLY)
+		return 0;
+
+	down_read(&fs_info->cleanup_work_sem);
+	if ((ret = btrfs_orphan_cleanup(fs_info->fs_root)) ||
+	    (ret = btrfs_orphan_cleanup(fs_info->tree_root))) {
 		up_read(&fs_info->cleanup_work_sem);
+		close_ctree(tree_root);
+		return ret;
+	}
+	up_read(&fs_info->cleanup_work_sem);
 
-		if (err) {
-			close_ctree(tree_root);
-			return err;
-		}
+	ret = btrfs_resume_balance_async(fs_info);
+	if (ret) {
+		printk(KERN_WARNING "btrfs: failed to resume balance\n");
+		close_ctree(tree_root);
+		return ret;
 	}
 
 	return 0;

commit 68310a5e42f93c2242ec1836c3b18d531e0065e2
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Fri Jun 22 12:24:12 2012 -0600

    Btrfs: restore restriper state on all mounts
    
    Fix a bug that triggered asserts in btrfs_balance() in both normal and
    resume modes -- restriper state was not properly restored on read-only
    mounts.  This factors out resuming code from btrfs_restore_balance(),
    which is now also called earlier in the mount sequence to avoid the
    problem of some early writes getting the old profile.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7d7bc8eace86..3a7961ba161e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2354,12 +2354,17 @@ int open_ctree(struct super_block *sb,
 				  BTRFS_CSUM_TREE_OBJECTID, csum_root);
 	if (ret)
 		goto recovery_tree_root;
-
 	csum_root->track_dirty = 1;
 
 	fs_info->generation = generation;
 	fs_info->last_trans_committed = generation;
 
+	ret = btrfs_recover_balance(fs_info);
+	if (ret) {
+		printk(KERN_WARNING "btrfs: failed to recover balance\n");
+		goto fail_block_groups;
+	}
+
 	ret = btrfs_init_dev_stats(fs_info);
 	if (ret) {
 		printk(KERN_ERR "btrfs: failed to init dev_stats: %d\n",
@@ -2492,9 +2497,6 @@ int open_ctree(struct super_block *sb,
 			err = btrfs_orphan_cleanup(fs_info->tree_root);
 		up_read(&fs_info->cleanup_work_sem);
 
-		if (!err)
-			err = btrfs_recover_balance(fs_info->tree_root);
-
 		if (err) {
 			close_ctree(tree_root);
 			return err;

commit 8874e812feb4926f4a51a82c4fca75c7daa05fc5
Merge: 7b8377862bd8 cb77fcd88569
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 21 13:41:07 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs fixes from Chris Mason:
     "This is a small pull with btrfs fixes.  The biggest of the bunch is
      another fix for the new backref walking code.
    
      We're still hammering out one btrfs dio vs buffered reads problem, but
      that one will have to wait for the next rc."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: delay iput with async extents
      Btrfs: add a missing spin_lock
      Btrfs: don't assume to be on the correct extent in add_all_parents
      Btrfs: introduce btrfs_next_old_item

commit e18fca734278784bd6591de63ca148cc27344ca9
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jun 18 07:23:18 2012 -0600

    Btrfs: add a missing spin_lock
    
    When fixing up the locking in the delayed ref destruction work I accidently
    broke the locking myself ;(.  Add back a spin_lock that should be there and
    we are now all set.  Thanks,
    Btrfs: add a missing spin_lock
    
    When fixing up the locking in the delayed ref destruction work I accidently
    broke the locking myself ;(.  Add back a spin_lock that should be there and
    we are now all set.  Thanks,
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e22c5bbf0223..7d7bc8eace86 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3426,6 +3426,7 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				mutex_unlock(&head->mutex);
 				btrfs_put_delayed_ref(ref);
 
+				spin_lock(&delayed_refs->lock);
 				continue;
 			}
 

commit 718f58ad61810b7d4a6c9178185495f762e90807
Merge: 424d54d2dca0 9c106405ddf8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 15 16:04:37 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs update from Chris Mason:
     "The dates look like I had to rebase this morning because there was a
      compiler warning for a printk arg that I had missed earlier.
    
      These are all fixes, including one to prevent using stale pointers for
      device names, and lots of fixes around transaction abort cleanups
      (Josef, Liu Bo).
    
      Jan Schmidt also sent in a number of fixes for the new reference
      number tracking code.
    
      Liu Bo beat me to updating the MAINTAINERS file.  Since he thought to
      also fix the git url, I kept his commit."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (24 commits)
      Btrfs: update MAINTAINERS info for BTRFS FILE SYSTEM
      Btrfs: destroy the items of the delayed inodes in error handling routine
      Btrfs: make sure that we've made everything in pinned tree clean
      Btrfs: avoid memory leak of extent state in error handling routine
      Btrfs: do not resize a seeding device
      Btrfs: fix missing inherited flag in rename
      Btrfs: fix incompat flags setting
      Btrfs: fix defrag regression
      Btrfs: call filemap_fdatawrite twice for compression
      Btrfs: keep inode pinned when compressing writes
      Btrfs: implement ->show_devname
      Btrfs: use rcu to protect device->name
      Btrfs: unlock everything properly in the error case for nocow
      Btrfs: fix btrfs_destroy_marked_extents
      Btrfs: abort the transaction if the commit fails
      Btrfs: wake up transaction waiters when aborting a transaction
      Btrfs: fix locking in btrfs_destroy_delayed_refs
      Btrfs: pass locked_page into extent_clear_unlock_delalloc if theres an error
      Btrfs: fix race in tree mod log addition
      Btrfs: add btrfs_next_old_leaf
      ...

commit 67cde3448d951b55088a6ea3bb1aee0160068fb9
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Jun 14 02:23:22 2012 -0600

    Btrfs: destroy the items of the delayed inodes in error handling routine
    
    the items of the delayed inodes were forgotten to be freed, this patch
    fixes it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ffdd76bf05d4..e22c5bbf0223 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3608,6 +3608,9 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	cur_trans->commit_done = 1;
 	wake_up(&cur_trans->commit_wait);
 
+	btrfs_destroy_delayed_inodes(root);
+	btrfs_assert_delayed_root_empty(root);
+
 	btrfs_destroy_pending_snapshots(cur_trans);
 
 	btrfs_destroy_marked_extents(root, &cur_trans->dirty_pages,
@@ -3662,6 +3665,9 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 		if (waitqueue_active(&t->commit_wait))
 			wake_up(&t->commit_wait);
 
+		btrfs_destroy_delayed_inodes(root);
+		btrfs_assert_delayed_root_empty(root);
+
 		btrfs_destroy_pending_snapshots(t);
 
 		btrfs_destroy_delalloc_inodes(root);

commit ed0eaa14981e87a1e185b61e4ef621c440e3930c
Author: Liu Bo <liubo2009@cn.fujitsu.com>
Date:   Thu Jun 14 02:23:21 2012 -0600

    Btrfs: make sure that we've made everything in pinned tree clean
    
    Since we have two trees for recording pinned extents, we need to go through
    both of them to make sure that we've done everything clean.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 63a36232788b..ffdd76bf05d4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3557,8 +3557,10 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 	u64 start;
 	u64 end;
 	int ret;
+	bool loop = true;
 
 	unpin = pinned_extents;
+again:
 	while (1) {
 		ret = find_first_extent_bit(unpin, 0, &start, &end,
 					    EXTENT_DIRTY);
@@ -3576,6 +3578,15 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 		cond_resched();
 	}
 
+	if (loop) {
+		if (unpin == &root->fs_info->freed_extents[0])
+			unpin = &root->fs_info->freed_extents[1];
+		else
+			unpin = &root->fs_info->freed_extents[0];
+		loop = false;
+		goto again;
+	}
+
 	return 0;
 }
 

commit 6e841e32b159e298debbb2cb0e9158e894fcaf05
Author: Liu Bo <liubo2009@cn.fujitsu.com>
Date:   Thu Jun 14 02:23:20 2012 -0600

    Btrfs: avoid memory leak of extent state in error handling routine
    
    We've forgotten to clear extent states in pinned tree, which will results in
    space counter mismatch and memory leak:
    
    WARNING: at fs/btrfs/extent-tree.c:7537 btrfs_free_block_groups+0x1f3/0x2e0 [btrfs]()
    ...
    space_info 2 has 8380416 free, is not full
    space_info total=12582912, used=4096, pinned=4096, reserved=0, may_use=0, readonly=4194304
    btrfs state leak: start 29364224 end 29376511 state 1 in tree ffff880075f20090 refs 1
    ...
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9a569aef72ea..63a36232788b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3601,6 +3601,8 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 
 	btrfs_destroy_marked_extents(root, &cur_trans->dirty_pages,
 				     EXTENT_DIRTY);
+	btrfs_destroy_pinned_extent(root,
+				    root->fs_info->pinned_extents);
 
 	/*
 	memset(cur_trans, 0, sizeof(*cur_trans));

commit 69e380d176e73653e09ce2cf3a5dc09682a69229
Author: Li Zefan <lizefan@huawei.com>
Date:   Mon Jun 11 17:10:51 2012 +0800

    Btrfs: fix incompat flags setting
    
    It's a bug, but it happens to work, as BTRFS_COMPRESS_LZO == 2, which
    has only one bit set.
    
    Signed-off-by: Li Zefan <lizefan@huawei.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1c9664b16cd1..9a569aef72ea 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2119,7 +2119,7 @@ int open_ctree(struct super_block *sb,
 
 	features = btrfs_super_incompat_flags(disk_super);
 	features |= BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF;
-	if (tree_root->fs_info->compress_type & BTRFS_COMPRESS_LZO)
+	if (tree_root->fs_info->compress_type == BTRFS_COMPRESS_LZO)
 		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;
 
 	/*

commit 606686eeac4550d2212bf3d621a810407ef5e9bf
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jun 4 14:03:51 2012 -0400

    Btrfs: use rcu to protect device->name
    
    Al pointed out that we can just toss out the old name on a device and add a
    new one arbitrarily, so anybody who uses device->name in printk could
    possibly use free'd memory.  Instead of adding locking around all of this he
    suggested doing it with RCU, so I've introduced a struct rcu_string that
    does just that and have gone through and protected all accesses to
    device->name that aren't under the uuid_mutex with rcu_read_lock().  This
    protects us and I will use it for dealing with removing the device that we
    used to mount the file system in a later patch.  Thanks,
    
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5a3bf323e2bd..1c9664b16cd1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -44,6 +44,7 @@
 #include "free-space-cache.h"
 #include "inode-map.h"
 #include "check-integrity.h"
+#include "rcu-string.h"
 
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
@@ -2575,8 +2576,9 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 		struct btrfs_device *device = (struct btrfs_device *)
 			bh->b_private;
 
-		printk_ratelimited(KERN_WARNING "lost page write due to "
-				   "I/O error on %s\n", device->name);
+		printk_ratelimited_in_rcu(KERN_WARNING "lost page write due to "
+					  "I/O error on %s\n",
+					  rcu_str_deref(device->name));
 		/* note, we dont' set_buffer_write_io_error because we have
 		 * our own ways of dealing with the IO errors
 		 */
@@ -2749,8 +2751,8 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 		wait_for_completion(&device->flush_wait);
 
 		if (bio_flagged(bio, BIO_EOPNOTSUPP)) {
-			printk("btrfs: disabling barriers on dev %s\n",
-			       device->name);
+			printk_in_rcu("btrfs: disabling barriers on dev %s\n",
+				      rcu_str_deref(device->name));
 			device->nobarriers = 1;
 		}
 		if (!bio_flagged(bio, BIO_UPTODATE)) {

commit ee670f0af35871edb492db5ba406cef36d1b7c21
Author: Josef Bacik <josef@redhat.com>
Date:   Thu May 31 15:54:30 2012 -0400

    Btrfs: fix btrfs_destroy_marked_extents
    
    So we're forcing the eb's to have their ref count set to 1 so invalidatepage
    works but this breaks lots of things, for example root nodes, and is just
    plain wrong, we don't need to just evict all of this stuff.  Also drop the
    invalidatepage altogether and add a page_cache_release().  With this patch
    we no longer hang when trying to access the root nodes after an aborted
    transaction and we no longer leak memory.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 19b4db70dcb1..5a3bf323e2bd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3524,11 +3524,9 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 			     &(&BTRFS_I(page->mapping->host)->io_tree)->buffer,
 					       offset >> PAGE_CACHE_SHIFT);
 			spin_unlock(&dirty_pages->buffer_lock);
-			if (eb) {
+			if (eb)
 				ret = test_and_clear_bit(EXTENT_BUFFER_DIRTY,
 							 &eb->bflags);
-				atomic_set(&eb->refs, 1);
-			}
 			if (PageWriteback(page))
 				end_page_writeback(page);
 
@@ -3542,8 +3540,8 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 				spin_unlock_irq(&page->mapping->tree_lock);
 			}
 
-			page->mapping->a_ops->invalidatepage(page, 0);
 			unlock_page(page);
+			page_cache_release(page);
 		}
 	}
 

commit d7096fc3ef8360f30f228344bc564d4f97d8a158
Author: Josef Bacik <josef@redhat.com>
Date:   Thu May 31 15:49:57 2012 -0400

    Btrfs: wake up transaction waiters when aborting a transaction
    
    I was getting lots of hung tasks and a NULL pointer dereference because we
    are not cleaning up the transaction properly when it aborts.  First we need
    to reset the running_transaction to NULL so we don't get a bad dereference
    for any start_transaction callers after this.  Also we cannot rely on
    waitqueue_active() since it's just a list_empty(), so just call wake_up()
    directly since that will do the barrier for us and such.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c79ddc756081..19b4db70dcb1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3589,16 +3589,13 @@ void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
 	/* FIXME: cleanup wait for commit */
 	cur_trans->in_commit = 1;
 	cur_trans->blocked = 1;
-	if (waitqueue_active(&root->fs_info->transaction_blocked_wait))
-		wake_up(&root->fs_info->transaction_blocked_wait);
+	wake_up(&root->fs_info->transaction_blocked_wait);
 
 	cur_trans->blocked = 0;
-	if (waitqueue_active(&root->fs_info->transaction_wait))
-		wake_up(&root->fs_info->transaction_wait);
+	wake_up(&root->fs_info->transaction_wait);
 
 	cur_trans->commit_done = 1;
-	if (waitqueue_active(&cur_trans->commit_wait))
-		wake_up(&cur_trans->commit_wait);
+	wake_up(&cur_trans->commit_wait);
 
 	btrfs_destroy_pending_snapshots(cur_trans);
 

commit b939d1ab76b4aa816343cdbd8b44ce9929a3b9ef
Author: Josef Bacik <josef@redhat.com>
Date:   Thu May 31 11:06:33 2012 -0400

    Btrfs: fix locking in btrfs_destroy_delayed_refs
    
    The transaction abort stuff was throwing warnings from the list debugging
    code because we do a list_del_init outside of the delayed_refs spin lock.
    The delayed refs locking makes baby Jesus cry so it's not hard to get wrong,
    but we need to take the ref head mutex to make sure it's not being processed
    currently, and so if it is we need to drop the spin lock and then take and
    drop the mutex and do the search again.  If we can take the mutex then we
    can safely remove the head from the list and carry on.  Now when the
    transaction aborts I don't get the list debugging warnings.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b99d5127ba18..c79ddc756081 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3400,7 +3400,6 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 
 	delayed_refs = &trans->delayed_refs;
 
-again:
 	spin_lock(&delayed_refs->lock);
 	if (delayed_refs->num_entries == 0) {
 		spin_unlock(&delayed_refs->lock);
@@ -3408,31 +3407,36 @@ int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 		return ret;
 	}
 
-	node = rb_first(&delayed_refs->root);
-	while (node) {
+	while ((node = rb_first(&delayed_refs->root)) != NULL) {
 		ref = rb_entry(node, struct btrfs_delayed_ref_node, rb_node);
-		node = rb_next(node);
-
-		ref->in_tree = 0;
-		rb_erase(&ref->rb_node, &delayed_refs->root);
-		delayed_refs->num_entries--;
 
 		atomic_set(&ref->refs, 1);
 		if (btrfs_delayed_ref_is_head(ref)) {
 			struct btrfs_delayed_ref_head *head;
 
 			head = btrfs_delayed_node_to_head(ref);
-			spin_unlock(&delayed_refs->lock);
-			mutex_lock(&head->mutex);
+			if (!mutex_trylock(&head->mutex)) {
+				atomic_inc(&ref->refs);
+				spin_unlock(&delayed_refs->lock);
+
+				/* Need to wait for the delayed ref to run */
+				mutex_lock(&head->mutex);
+				mutex_unlock(&head->mutex);
+				btrfs_put_delayed_ref(ref);
+
+				continue;
+			}
+
 			kfree(head->extent_op);
 			delayed_refs->num_heads--;
 			if (list_empty(&head->cluster))
 				delayed_refs->num_heads_ready--;
 			list_del_init(&head->cluster);
-			mutex_unlock(&head->mutex);
-			btrfs_put_delayed_ref(ref);
-			goto again;
 		}
+		ref->in_tree = 0;
+		rb_erase(&ref->rb_node, &delayed_refs->root);
+		delayed_refs->num_entries--;
+
 		spin_unlock(&delayed_refs->lock);
 		btrfs_put_delayed_ref(ref);
 

commit 51eab603f5c86dd1eae4c525df3e7f7eeab401d6
Merge: 419f43194950 1e20932a2357
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 1 08:37:31 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Pull btrfs updates from Chris Mason:
     "This includes a fairly large change from Josef around data writeback
      completion.  Before, the writeback wasn't completed until the metadata
      insertions for the extent were done, and this made for fairly large
      latency spikes on the last page of each ordered extent.
    
      We already had a separate mechanism for tracking pending metadata
      insertions, so Josef just needed to tweak things a little to end
      writeback earlier on the page.  Overall it makes us much friendly to
      memory reclaim and lowers latencies quite a lot for synchronous IO.
    
      Jan Schmidt has finished some background work required to track btree
      blocks as they go through changes in ownership.  It's the missing
      piece he needed for both btrfs send/receive and subvolume quotas.
      Neither of those are ready yet, but the new tracking code is included
      here.  Most of the time, the new code is off.  It is only used by
      scrub and other backref walkers.
    
      Stefan Behrens has added io failure tracking.  This includes counters
      for which drives are causing the most trouble so the admin (or an
      automated tool) can choose to kick them out.  We're tracking IO
      errors, crc errors, and generation checks we do on each metadata
      block.
    
      RAID5/6 did miss the cut this time because I'm having trouble with
      corruptions.  I'll nail it down next week and post as a beta testing
      before 3.6"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (58 commits)
      Btrfs: fix tree mod log rewinded level and rewinding of moved keys
      Btrfs: fix tree mod log del_ptr
      Btrfs: add tree_mod_dont_log helper
      Btrfs: add missing spin_lock for insertion into tree mod log
      Btrfs: add inodes before dropping the extent lock in find_all_leafs
      Btrfs: use delayed ref sequence numbers for all fs-tree updates
      Btrfs: fix false positive in check-integrity on unmount
      Btrfs: fix runtime warning in check-integrity check data mode
      Btrfs: set ioprio of scrub readahead to idle
      Btrfs: fix return code in drop_objectid_items
      Btrfs: check to see if the inode is in the log before fsyncing
      Btrfs: return value of btrfs_read_buffer is checked correctly
      Btrfs: read device stats on mount, write modified ones during commit
      Btrfs: add ioctl to get and reset the device stats
      Btrfs: add device counters for detected IO and checksum errors
      btrfs: Drop unused function btrfs_abort_devices()
      Btrfs: fix the same inode id problem when doing auto defragment
      Btrfs: fall back to non-inline if we don't have enough space
      Btrfs: fix how we deal with the orphan block rsv
      Btrfs: convert the inode bit field to use the actual bit operations
      ...

commit 1e20932a23578bb1ec59107843574e259b96193f
Merge: cfc442b69696 c31931088fd6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 31 16:50:28 2012 -0400

    Merge branch 'for-chris' of git://git.jan-o-sch.net/btrfs-unstable into for-linus
    
    Conflicts:
            fs/btrfs/ulist.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 733f4fbbc1083aa343da739f46ee839705d6cfe3
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri May 25 16:06:10 2012 +0200

    Btrfs: read device stats on mount, write modified ones during commit
    
    The device statistics are written into the device tree with each
    transaction commit. Only modified statistics are written.
    When a filesystem is mounted, the device statistics for each involved
    device are read from the device tree and used to initialize the
    counters.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 46d474e74aa4..b0d49e21b0b1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2354,6 +2354,13 @@ int open_ctree(struct super_block *sb,
 	fs_info->generation = generation;
 	fs_info->last_trans_committed = generation;
 
+	ret = btrfs_init_dev_stats(fs_info);
+	if (ret) {
+		printk(KERN_ERR "btrfs: failed to init dev_stats: %d\n",
+		       ret);
+		goto fail_block_groups;
+	}
+
 	ret = btrfs_init_space_info(fs_info);
 	if (ret) {
 		printk(KERN_ERR "Failed to initial space info: %d\n", ret);

commit 442a4f6308e694e0fa6025708bd5e4e424bbf51c
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Fri May 25 16:06:08 2012 +0200

    Btrfs: add device counters for detected IO and checksum errors
    
    The goal is to detect when drives start to get an increased error rate,
    when drives should be replaced soon. Therefore statistic counters are
    added that count IO errors (read, write and flush). Additionally, the
    software detected errors like checksum errors and corrupted blocks are
    counted.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0f788c059063..46d474e74aa4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2557,18 +2557,19 @@ int open_ctree(struct super_block *sb,
 
 static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 {
-	char b[BDEVNAME_SIZE];
-
 	if (uptodate) {
 		set_buffer_uptodate(bh);
 	} else {
+		struct btrfs_device *device = (struct btrfs_device *)
+			bh->b_private;
+
 		printk_ratelimited(KERN_WARNING "lost page write due to "
-					"I/O error on %s\n",
-				       bdevname(bh->b_bdev, b));
+				   "I/O error on %s\n", device->name);
 		/* note, we dont' set_buffer_write_io_error because we have
 		 * our own ways of dealing with the IO errors
 		 */
 		clear_buffer_uptodate(bh);
+		btrfs_dev_stat_inc_and_print(device, BTRFS_DEV_STAT_WRITE_ERRS);
 	}
 	unlock_buffer(bh);
 	put_bh(bh);
@@ -2683,6 +2684,7 @@ static int write_dev_supers(struct btrfs_device *device,
 			set_buffer_uptodate(bh);
 			lock_buffer(bh);
 			bh->b_end_io = btrfs_end_buffer_write_sync;
+			bh->b_private = device;
 		}
 
 		/*
@@ -2741,6 +2743,9 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 		}
 		if (!bio_flagged(bio, BIO_UPTODATE)) {
 			ret = -EIO;
+			if (!bio_flagged(bio, BIO_EOPNOTSUPP))
+				btrfs_dev_stat_inc_and_print(device,
+					BTRFS_DEV_STAT_FLUSH_ERRS);
 		}
 
 		/* drop the reference from the wait == 0 run */

commit d07eb9117050c9ed3f78296ebcc06128b52693be
Author: Asias He <asias@redhat.com>
Date:   Fri May 25 11:10:21 2012 +0800

    btrfs: Drop unused function btrfs_abort_devices()
    
    1) This function is not used anywhere.
    
    2) Using the blk_abort_queue() to abort the queue seems not correct.
    blk_abort_queue() is used for timeout handling (block/blk-timeout.c).
    
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: linux-btrfs@vger.kernel.org
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Asias He <asias@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 297e5a8ed93c..0f788c059063 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2903,19 +2903,6 @@ int write_ctree_super(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-/* Kill all outstanding I/O */
-void btrfs_abort_devices(struct btrfs_root *root)
-{
-	struct list_head *head;
-	struct btrfs_device *dev;
-	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
-	head = &root->fs_info->fs_devices->devices;
-	list_for_each_entry_rcu(dev, head, dev_list) {
-		blk_abort_queue(dev->bdev->bd_disk->queue);
-	}
-	mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
-}
-
 void btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 {
 	spin_lock(&fs_info->fs_roots_radix_lock);

commit 8a35d95ff4680a456d3ce47df9638f33d4f54f20
Author: Josef Bacik <josef@redhat.com>
Date:   Wed May 23 14:26:42 2012 -0400

    Btrfs: fix how we deal with the orphan block rsv
    
    Ceph was hitting this race where we would remove an inode from the per-root
    orphan list before we would release the space we had reserved for the inode.
    We actually don't need a list or anything, we just need to make sure the
    root doesn't try to free up the orphan reserve until after the inodes have
    released their reservations.  So use an atomic counter instead of a list on
    the root and only decrement the counter after we've released our
    reservation.  I've tested this as well as several others and we no longer
    see the warnings that you would see while running ceph.  Thanks,
    Btrfs: fix how we deal with the orphan block rsv
    
    Ceph was hitting this race where we would remove an inode from the per-root
    orphan list before we would release the space we had reserved for the inode.
    We actually don't need a list or anything, we just need to make sure the
    root doesn't try to free up the orphan reserve until after the inodes have
    released their reservations.  So use an atomic counter instead of a list on
    the root and only decrement the counter after we've released our
    reservation.  I've tested this as well as several others and we no longer
    see the warnings that you would see while running ceph.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0cf8ef2b5b1a..297e5a8ed93c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1153,7 +1153,6 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->orphan_block_rsv = NULL;
 
 	INIT_LIST_HEAD(&root->dirty_list);
-	INIT_LIST_HEAD(&root->orphan_list);
 	INIT_LIST_HEAD(&root->root_list);
 	spin_lock_init(&root->orphan_lock);
 	spin_lock_init(&root->inode_lock);
@@ -1166,6 +1165,7 @@ static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	atomic_set(&root->log_commit[0], 0);
 	atomic_set(&root->log_commit[1], 0);
 	atomic_set(&root->log_writers, 0);
+	atomic_set(&root->orphan_inodes, 0);
 	root->log_batch = 0;
 	root->log_transid = 0;
 	root->last_log_commit = 0;

commit 72ac3c0d7921f943d92d1ef42a549fb52e56817d
Author: Josef Bacik <josef@redhat.com>
Date:   Wed May 23 14:13:11 2012 -0400

    Btrfs: convert the inode bit field to use the actual bit operations
    
    Miao pointed this out while I was working on an orphan problem that messing
    with a bitfield where different ranges are protected by different locks
    doesn't work out right.  Turns out we've been doing this forever where we
    have different parts of the bit field protected by either no lock at all or
    different locks which could cause all sorts of weird problems including the
    issue I was hitting.  So instead make a runtime_flags thing that we use the
    normal bit operations on that are all atomic so we can keep having our
    no/different locking for the different flags and then make force_compress
    it's own thing so it can be treated normally.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 19f5b450f405..0cf8ef2b5b1a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2001,7 +2001,8 @@ int open_ctree(struct super_block *sb,
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));
-	BTRFS_I(fs_info->btree_inode)->dummy_inode = 1;
+	set_bit(BTRFS_INODE_DUMMY,
+		&BTRFS_I(fs_info->btree_inode)->runtime_flags);
 	insert_inode_hash(fs_info->btree_inode);
 
 	spin_lock_init(&fs_info->block_group_cache_lock);

commit 5fd02043553b02867b29de1ac9fff2ec16b84def
Author: Josef Bacik <josef@redhat.com>
Date:   Wed May 2 14:00:54 2012 -0400

    Btrfs: finish ordered extents in their own thread
    
    We noticed that the ordered extent completion doesn't really rely on having
    a page and that it could be done independantly of ending the writeback on a
    page.  This patch makes us not do the threaded endio stuff for normal
    buffered writes and direct writes so we can end page writeback as soon as
    possible (in irq context) and only start threads to do the ordered work when
    it is actually done.  Compression needs to be reworked some to take
    advantage of this as well, but atm it has to do a find_get_page in its endio
    handler so it must be done in its own thread.  This makes direct writes
    quite a bit faster.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a7ffc88a7dbe..19f5b450f405 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3671,17 +3671,6 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 	return 0;
 }
 
-static int btree_writepage_io_failed_hook(struct bio *bio, struct page *page,
-					  u64 start, u64 end,
-					  struct extent_state *state)
-{
-	struct super_block *sb = page->mapping->host->i_sb;
-	struct btrfs_fs_info *fs_info = btrfs_sb(sb);
-	btrfs_error(fs_info, -EIO,
-		    "Error occured while writing out btree at %llu", start);
-	return -EIO;
-}
-
 static struct extent_io_ops btree_extent_io_ops = {
 	.write_cache_pages_lock_hook = btree_lock_page_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
@@ -3689,5 +3678,4 @@ static struct extent_io_ops btree_extent_io_ops = {
 	.submit_bio_hook = btree_submit_bio_hook,
 	/* note we're sharing with inode.c for the merge bio hook */
 	.merge_bio_hook = btrfs_merge_bio_hook,
-	.writepage_io_failed_hook = btree_writepage_io_failed_hook,
 };

commit f29021b29a85701c08afadfd51d87163fb078059
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed May 16 17:55:38 2012 +0200

    Btrfs: add tree mod log to fs_info
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f43307492518..f51ad8477f18 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1914,11 +1914,14 @@ int open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->delayed_iput_lock);
 	spin_lock_init(&fs_info->defrag_inodes_lock);
 	spin_lock_init(&fs_info->free_chunk_lock);
+	spin_lock_init(&fs_info->tree_mod_seq_lock);
+	rwlock_init(&fs_info->tree_mod_log_lock);
 	mutex_init(&fs_info->reloc_mutex);
 
 	init_completion(&fs_info->kobj_unregister);
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
 	INIT_LIST_HEAD(&fs_info->space_info);
+	INIT_LIST_HEAD(&fs_info->tree_mod_seq_list);
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	btrfs_init_block_rsv(&fs_info->global_block_rsv);
 	btrfs_init_block_rsv(&fs_info->delalloc_block_rsv);
@@ -1931,12 +1934,14 @@ int open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
 	atomic_set(&fs_info->defrag_running, 0);
+	atomic_set(&fs_info->tree_mod_seq, 0);
 	fs_info->sb = sb;
 	fs_info->max_inline = 8192 * 1024;
 	fs_info->metadata_ratio = 0;
 	fs_info->defrag_inodes = RB_ROOT;
 	fs_info->trans_no_join = 0;
 	fs_info->free_chunk_space = 0;
+	fs_info->tree_mod_log = RB_ROOT;
 
 	/* readahead state */
 	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_WAIT);

commit 5581a51a59a1f5f51ac3d4bacafb738d35e0350b
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Wed May 16 17:04:52 2012 +0200

    Btrfs: don't set for_cow parameter for tree block functions
    
    Three callers of btrfs_free_tree_block or btrfs_alloc_tree_block passed
    parameter for_cow = 1. In fact, these two functions should never mark
    their tree modification operations as for_cow, because they can change
    the number of blocks referenced by a tree.
    
    Hence, we remove the extra for_cow parameter from these functions and
    make them pass a zero down.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a7ffc88a7dbe..f43307492518 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1252,7 +1252,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 
 	leaf = btrfs_alloc_free_block(trans, root, root->leafsize, 0,
 				      BTRFS_TREE_LOG_OBJECTID, NULL,
-				      0, 0, 0, 0);
+				      0, 0, 0);
 	if (IS_ERR(leaf)) {
 		kfree(root);
 		return ERR_CAST(leaf);

commit e8650a08232e75274304b812ff04cfce9af9671c
Merge: 3c2c4b73aa79 f70d4a95edc7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 22 19:22:50 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial
    
    Pull trivial updates from Jiri Kosina:
     "As usual, it's mostly typo fixes, redundant code elimination and some
      documentation updates."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial: (57 commits)
      edac, mips: don't change code that has been removed in edac/mips tree
      xtensa: Change mail addresses of Hannes Weiner and Oskar Schirmer
      lib: Change mail address of Oskar Schirmer
      net: Change mail address of Oskar Schirmer
      arm/m68k: Change mail address of Sebastian Hess
      i2c: Change mail address of Oskar Schirmer
      net: Fix tcp_build_and_update_options comment in struct tcp_sock
      atomic64_32.h: fix parameter naming mismatch
      Kconfig: replace "--- help ---" with "---help---"
      c2port: fix bogus Kconfig "default no"
      edac: Fix spelling errors.
      qla1280: Remove redundant NULL check before release_firmware() call
      remoteproc: remove redundant NULL check before release_firmware()
      qla2xxx: Remove redundant NULL check before release_firmware() call.
      aic94xx: Get rid of redundant NULL check before release_firmware() call
      tehuti: delete redundant NULL check before release_firmware()
      qlogic: get rid of a redundant test for NULL before call to release_firmware()
      bna: remove redundant NULL test before release_firmware()
      tg3: remove redundant NULL test before release_firmware() call
      typhoon: get rid of redundant conditional before all to release_firmware()
      ...

commit b9fab919b748c7b39c19ff236ed6c5682c266dde
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun May 6 07:23:47 2012 -0400

    Btrfs: avoid sleeping in verify_parent_transid while atomic
    
    verify_parent_transid needs to lock the extent range to make
    sure no IO is underway, and so it can safely clear the
    uptodate bits if our checks fail.
    
    But, a few callers are using it with spinlocks held.  Most
    of the time, the generation numbers are going to match, and
    we don't want to switch to a blocking lock just for the error
    case.  This adds an atomic flag to verify_parent_transid,
    and changes it to return EAGAIN if it needs to block to
    properly verifiy things.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d0c969beaad4..a7ffc88a7dbe 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -323,7 +323,8 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
  * in the wrong place.
  */
 static int verify_parent_transid(struct extent_io_tree *io_tree,
-				 struct extent_buffer *eb, u64 parent_transid)
+				 struct extent_buffer *eb, u64 parent_transid,
+				 int atomic)
 {
 	struct extent_state *cached_state = NULL;
 	int ret;
@@ -331,6 +332,9 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 	if (!parent_transid || btrfs_header_generation(eb) == parent_transid)
 		return 0;
 
+	if (atomic)
+		return -EAGAIN;
+
 	lock_extent_bits(io_tree, eb->start, eb->start + eb->len - 1,
 			 0, &cached_state);
 	if (extent_buffer_uptodate(eb) &&
@@ -372,7 +376,8 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		ret = read_extent_buffer_pages(io_tree, eb, start,
 					       WAIT_COMPLETE,
 					       btree_get_extent, mirror_num);
-		if (!ret && !verify_parent_transid(io_tree, eb, parent_transid))
+		if (!ret && !verify_parent_transid(io_tree, eb,
+						   parent_transid, 0))
 			break;
 
 		/*
@@ -1202,7 +1207,7 @@ static int __must_check find_and_setup_root(struct btrfs_root *tree_root,
 	root->commit_root = NULL;
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
-	if (!root->node || !btrfs_buffer_uptodate(root->node, generation)) {
+	if (!root->node || !btrfs_buffer_uptodate(root->node, generation, 0)) {
 		free_extent_buffer(root->node);
 		root->node = NULL;
 		return -EIO;
@@ -3143,7 +3148,8 @@ int close_ctree(struct btrfs_root *root)
 	return 0;
 }
 
-int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid)
+int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid,
+			  int atomic)
 {
 	int ret;
 	struct inode *btree_inode = buf->pages[0]->mapping->host;
@@ -3153,7 +3159,9 @@ int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid)
 		return ret;
 
 	ret = verify_parent_transid(&BTRFS_I(btree_inode)->io_tree, buf,
-				    parent_transid);
+				    parent_transid, atomic);
+	if (ret == -EAGAIN)
+		return ret;
 	return !ret;
 }
 

commit 5cf1ab56133ad7b712673c071b439d4a555a2d1e
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Apr 16 09:42:26 2012 -0400

    Btrfs: always store the mirror we read the eb from
    
    A user reported a panic where we were trying to fix a bad mirror but the
    mirror number we were giving was 0, which is invalid.  This is because we
    don't do the transid verification until after the read, so as far as the
    read code is concerned the read was a success.  So instead store the mirror
    we read from so that if there is some failure post read we know which mirror
    to try next and which mirror needs to be fixed if we find a good copy of the
    block.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b9866f27ebd7..d0c969beaad4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -383,17 +383,16 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		if (test_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags))
 			break;
 
-		if (!failed_mirror) {
-			failed = 1;
-			printk(KERN_ERR "failed mirror was %d\n", eb->failed_mirror);
-			failed_mirror = eb->failed_mirror;
-		}
-
 		num_copies = btrfs_num_copies(&root->fs_info->mapping_tree,
 					      eb->start, eb->len);
 		if (num_copies == 1)
 			break;
 
+		if (!failed_mirror) {
+			failed = 1;
+			failed_mirror = eb->read_mirror;
+		}
+
 		mirror_num++;
 		if (mirror_num == failed_mirror)
 			mirror_num++;
@@ -564,7 +563,7 @@ struct extent_buffer *find_eb_for_page(struct extent_io_tree *tree,
 }
 
 static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
-			       struct extent_state *state)
+			       struct extent_state *state, int mirror)
 {
 	struct extent_io_tree *tree;
 	u64 found_start;
@@ -589,6 +588,7 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	if (!reads_done)
 		goto err;
 
+	eb->read_mirror = mirror;
 	if (test_bit(EXTENT_BUFFER_IOERR, &eb->bflags)) {
 		ret = -EIO;
 		goto err;
@@ -652,7 +652,7 @@ static int btree_io_failed_hook(struct page *page, int failed_mirror)
 
 	eb = (struct extent_buffer *)page->private;
 	set_bit(EXTENT_BUFFER_IOERR, &eb->bflags);
-	eb->failed_mirror = failed_mirror;
+	eb->read_mirror = failed_mirror;
 	if (test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
 		btree_readahead_hook(root, eb, eb->start, -EIO);
 	return -EIO;	/* we fixed nothing */

commit 8d082fb727ac11930ea20bf1612e334ea7c2b697
Author: Liu Bo <liubo2009@cn.fujitsu.com>
Date:   Tue Apr 3 09:56:53 2012 +0800

    Btrfs: do not mount when we have a sectorsize unequal to PAGE_SIZE
    
    Our code is not ready to cope with a sectorsize that's not equal to PAGE_SIZE.
    It will lead to hanging-on while writing something.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 20196f411206..b9866f27ebd7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2254,9 +2254,9 @@ int open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 
-	if (sectorsize < PAGE_SIZE) {
-		printk(KERN_WARNING "btrfs: Incompatible sector size "
-		       "found on %s\n", sb->s_id);
+	if (sectorsize != PAGE_SIZE) {
+		printk(KERN_WARNING "btrfs: Incompatible sector size(%lu) "
+		       "found on %s\n", (unsigned long)sectorsize, sb->s_id);
 		goto fail_sb_buffer;
 	}
 

commit e75d660672ddd11704b7f0fdb8ff21968587b266
Merge: 61282f379271 0034102808e0
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Sun Apr 8 21:48:52 2012 +0200

    Merge branch 'master' into for-next
    
    Merge with latest Linus' tree, as I have incoming patches
    that fix code that is newer than current HEAD of for-next.
    
    Conflicts:
            drivers/net/ethernet/realtek/r8169.c

commit 9c017abc50f00e80aee6a705a9207fa818a48dda
Author: Jesper Juhl <jj@chaosbits.net>
Date:   Mon Feb 27 00:04:56 2012 +0100

    btrfs: assignment in write_dev_flush() doesn't need two semi-colons
    
    One is enough.
    
    Signed-off-by: Jesper Juhl <jj@chaosbits.net>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 811d9f918b1c..d24a841a8722 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2732,7 +2732,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 	 * one reference for us, and we leave it for the
 	 * caller
 	 */
-	device->flush_bio = NULL;;
+	device->flush_bio = NULL;
 	bio = bio_alloc(GFP_NOFS, 0);
 	if (!bio)
 		return -ENOMEM;

commit bc3f116fec194f1d7329b160c266fe16b9266a1e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 29 17:02:47 2012 -0400

    Btrfs: update the checks for mixed block groups with big metadata blocks
    
    Dave Sterba had put in patches to look for mixed data/metadata groups
    with metadata bigger than 4KB.  But these ended up in the wrong place
    and it wasn't testing the feature flag correctly.
    
    This updates the tests to make sure our sizes are matching
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fd43f6b2f438..20196f411206 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2120,6 +2120,23 @@ int open_ctree(struct super_block *sb,
 		features |= BTRFS_FEATURE_INCOMPAT_BIG_METADATA;
 	}
 
+	nodesize = btrfs_super_nodesize(disk_super);
+	leafsize = btrfs_super_leafsize(disk_super);
+	sectorsize = btrfs_super_sectorsize(disk_super);
+	stripesize = btrfs_super_stripesize(disk_super);
+
+	/*
+	 * mixed block groups end up with duplicate but slightly offset
+	 * extent buffers for the same range.  It leads to corruptions
+	 */
+	if ((features & BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS) &&
+	    (sectorsize != leafsize)) {
+		printk(KERN_WARNING "btrfs: unequal leaf/node/sector sizes "
+				"are not allowed for mixed block groups on %s\n",
+				sb->s_id);
+		goto fail_alloc;
+	}
+
 	btrfs_set_super_incompat_flags(disk_super, features);
 
 	features = btrfs_super_compat_ro_flags(disk_super) &
@@ -2223,10 +2240,6 @@ int open_ctree(struct super_block *sb,
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
 				    4 * 1024 * 1024 / PAGE_CACHE_SIZE);
 
-	nodesize = btrfs_super_nodesize(disk_super);
-	leafsize = btrfs_super_leafsize(disk_super);
-	sectorsize = btrfs_super_sectorsize(disk_super);
-	stripesize = btrfs_super_stripesize(disk_super);
 	tree_root->nodesize = nodesize;
 	tree_root->leafsize = leafsize;
 	tree_root->sectorsize = sectorsize;
@@ -2247,14 +2260,6 @@ int open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 
-	if ((features & BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS) &&
-			(leafsize != nodesize || sectorsize != nodesize)) {
-		printk(KERN_WARNING "btrfs: unequal leaf/node/sector sizes "
-				"are not allowed for mixed block groups on %s\n",
-				sb->s_id);
-		goto fail_sb_buffer;
-	}
-
 	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);

commit 3c4bb26b213e618473e486776483a5bad15ba6da
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 27 18:56:56 2012 -0400

    Btrfs: flush out and clean up any block device pages during mount
    
    Btrfs puts the filesystem metadata into its own address space, and
    somehow the block device address space isn't getting onto disk properly
    before a mount.  The end result is that a loop of mkfs and mounting the
    filesystem will sometimes find stale or incorrect data.
    
    This commit should fix it by sprinkling fdatawrites and invalidate_bdev
    calls around.  This is a short term measure to make sure it is fixed.
    The block devices really should be flushed and cleaned up higher in the
    stack.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7b55eee15a51..fd43f6b2f438 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2031,6 +2031,7 @@ int open_ctree(struct super_block *sb,
 	__setup_root(4096, 4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
+	invalidate_bdev(fs_devices->latest_bdev);
 	bh = btrfs_read_dev_super(fs_devices->latest_bdev);
 	if (!bh) {
 		err = -EINVAL;

commit 1d4284bd6e8d7dd1d5521a6747bdb6dc1caf0225
Merge: b5d67f64f9bc 65139ed99234
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 28 20:31:37 2012 -0400

    Merge branch 'error-handling' into for-linus
    
    Conflicts:
            fs/btrfs/ctree.c
            fs/btrfs/disk-io.c
            fs/btrfs/extent-tree.c
            fs/btrfs/extent_io.c
            fs/btrfs/extent_io.h
            fs/btrfs/inode.c
            fs/btrfs/scrub.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 65139ed99234d8505948cdb7a835452eb5c191f9
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Feb 17 12:26:09 2012 +0100

    btrfs: disallow unequal data/metadata blocksize for mixed block groups
    
    With support for bigger metadata blocks, we must avoid mounting a
    filesystem with different block size for mixed block groups, this causes
    corruption (found by xfstests/083).
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 38c2ee1ca0d5..fe087847c8e7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2302,6 +2302,14 @@ int open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 
+	if ((features & BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS) &&
+			(leafsize != nodesize || sectorsize != nodesize)) {
+		printk(KERN_WARNING "btrfs: unequal leaf/node/sector sizes "
+				"are not allowed for mixed block groups on %s\n",
+				sb->s_id);
+		goto fail_sb_buffer;
+	}
+
 	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);

commit fcd1f065daca593badb7f99d473639cf3b551795
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Mar 6 00:06:18 2012 +0100

    Btrfs: enhance superblock sanity checks
    
    Validate checksum algorithm during mount and prevent BUG_ON later in
    btrfs_super_csum_size.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 438993e3d832..38c2ee1ca0d5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -48,7 +48,7 @@
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
-static void btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
+static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 				    int read_only);
 static void btrfs_destroy_ordered_operations(struct btrfs_root *root);
 static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
@@ -2135,7 +2135,12 @@ int open_ctree(struct super_block *sb,
 	/* check FS state, whether FS is broken. */
 	fs_info->fs_state |= btrfs_super_flags(disk_super);
 
-	btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
+	ret = btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
+	if (ret) {
+		printk(KERN_ERR "btrfs: superblock contains fatal errors\n");
+		err = ret;
+		goto fail_alloc;
+	}
 
 	/*
 	 * run through our array of backup supers and setup
@@ -3324,15 +3329,23 @@ static int btree_lock_page_hook(struct page *page, void *data,
 	return 0;
 }
 
-static void btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
+static int btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 			      int read_only)
 {
+	if (btrfs_super_csum_type(fs_info->super_copy) >= ARRAY_SIZE(btrfs_csum_sizes)) {
+		printk(KERN_ERR "btrfs: unsupported checksum algorithm\n");
+		return -EINVAL;
+	}
+
 	if (read_only)
-		return;
+		return 0;
 
-	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR)
+	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR) {
 		printk(KERN_WARNING "warning: mount fs with errors, "
 		       "running btrfsck is recommended\n");
+	}
+
+	return 0;
 }
 
 int btrfs_error_commit_super(struct btrfs_root *root)

commit ea466794084f55d8fcc100711cf17923bf57e962
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Mar 26 21:57:36 2012 -0400

    Btrfs: deal with read errors on extent buffers differently
    
    Since we need to read and write extent buffers in their entirety we can't use
    the normal bio_readpage_error stuff since it only works on a per page basis.  So
    instead make it so that if we see an io error in endio we just mark the eb as
    having an IO error and then in btree_read_extent_buffer_pages we will manually
    try other mirrors and then overwrite the bad mirror if we find a good copy.
    This works with larger than page size blocks.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 53c5ea702799..6107b6958413 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -360,9 +360,11 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 					  u64 start, u64 parent_transid)
 {
 	struct extent_io_tree *io_tree;
+	int failed = 0;
 	int ret;
 	int num_copies = 0;
 	int mirror_num = 0;
+	int failed_mirror = 0;
 
 	clear_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 	io_tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
@@ -371,7 +373,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 					       WAIT_COMPLETE,
 					       btree_get_extent, mirror_num);
 		if (!ret && !verify_parent_transid(io_tree, eb, parent_transid))
-			return ret;
+			break;
 
 		/*
 		 * This buffer's crc is fine, but its contents are corrupted, so
@@ -379,18 +381,31 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		 * any less wrong.
 		 */
 		if (test_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags))
-			return ret;
+			break;
+
+		if (!failed_mirror) {
+			failed = 1;
+			printk(KERN_ERR "failed mirror was %d\n", eb->failed_mirror);
+			failed_mirror = eb->failed_mirror;
+		}
 
 		num_copies = btrfs_num_copies(&root->fs_info->mapping_tree,
 					      eb->start, eb->len);
 		if (num_copies == 1)
-			return ret;
+			break;
 
 		mirror_num++;
+		if (mirror_num == failed_mirror)
+			mirror_num++;
+
 		if (mirror_num > num_copies)
-			return ret;
+			break;
 	}
-	return -EIO;
+
+	if (failed && !ret)
+		repair_eb_io_failure(root, eb, failed_mirror);
+
+	return ret;
 }
 
 /*
@@ -575,6 +590,11 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	if (!reads_done)
 		goto err;
 
+	if (test_bit(EXTENT_BUFFER_IOERR, &eb->bflags)) {
+		ret = -EIO;
+		goto err;
+	}
+
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != eb->start) {
 		printk_ratelimited(KERN_INFO "btrfs bad tree block start "
@@ -626,21 +646,16 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	return ret;
 }
 
-static int btree_io_failed_hook(struct bio *failed_bio,
-			 struct page *page, u64 start, u64 end,
-			 int mirror_num, struct extent_state *state)
+static int btree_io_failed_hook(struct page *page, int failed_mirror)
 {
 	struct extent_buffer *eb;
 	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
 
 	eb = (struct extent_buffer *)page->private;
-	if (page != eb->pages[0])
-		return -EIO;
-
-	if (test_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags)) {
-		clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags);
+	set_bit(EXTENT_BUFFER_IOERR, &eb->bflags);
+	eb->failed_mirror = failed_mirror;
+	if (test_and_clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags))
 		btree_readahead_hook(root, eb, eb->start, -EIO);
-	}
 	return -EIO;	/* we fixed nothing */
 }
 

commit f3f266ab1bfe4770375d24fa8e72a03278e9450a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 23 10:22:46 2012 -0400

    Btrfs: don't use threaded IO completion helpers for metadata writes
    
    The metadata write IO completion code is now simple enough that we
    don't need the threaded helpers anymore.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c54aec87e89d..53c5ea702799 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -840,15 +840,15 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 {
 	int ret;
 
-	ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info,
-					  bio, 1);
-	BUG_ON(ret);
-
 	if (!(rw & REQ_WRITE)) {
+
 		/*
 		 * called for a read, do the setup so that checksum validation
 		 * can happen in the async kernel threads
 		 */
+		ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info,
+					  bio, 1);
+		BUG_ON(ret);
 		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
 				     mirror_num, 0);
 	}

commit 0b32f4bbb423f02acee6d43cd442f5f0775db7e0
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Mar 13 09:38:00 2012 -0400

    Btrfs: ensure an entire eb is written at once
    
    This patch simplifies how we track our extent buffers.  Previously we could exit
    writepages with only having written half of an extent buffer, which meant we had
    to track the state of the pages and the state of the extent buffers differently.
    Now we only read in entire extent buffers and write out entire extent buffers,
    this allows us to simply set bits in our bflags to indicate the state of the eb
    and we no longer have to do things like track uptodate with our iotree.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0ba055e03eb8..c54aec87e89d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -333,7 +333,7 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 
 	lock_extent_bits(io_tree, eb->start, eb->start + eb->len - 1,
 			 0, &cached_state, GFP_NOFS);
-	if (extent_buffer_uptodate(io_tree, eb, cached_state) &&
+	if (extent_buffer_uptodate(eb) &&
 	    btrfs_header_generation(eb) == parent_transid) {
 		ret = 0;
 		goto out;
@@ -344,7 +344,7 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		       (unsigned long long)parent_transid,
 		       (unsigned long long)btrfs_header_generation(eb));
 	ret = 1;
-	clear_extent_buffer_uptodate(io_tree, eb, &cached_state);
+	clear_extent_buffer_uptodate(eb);
 out:
 	unlock_extent_cached(io_tree, eb->start, eb->start + eb->len - 1,
 			     &cached_state, GFP_NOFS);
@@ -566,7 +566,12 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	eb = (struct extent_buffer *)page->private;
 
-	reads_done = atomic_dec_and_test(&eb->pages_reading);
+	/* the pending IO might have been the only thing that kept this buffer
+	 * in memory.  Make sure we have a ref for all this other checks
+	 */
+	extent_buffer_get(eb);
+
+	reads_done = atomic_dec_and_test(&eb->io_pages);
 	if (!reads_done)
 		goto err;
 
@@ -606,14 +611,17 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		ret = -EIO;
 	}
 
+	if (!ret)
+		set_extent_buffer_uptodate(eb);
 err:
 	if (test_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags)) {
 		clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags);
 		btree_readahead_hook(root, eb, eb->start, ret);
 	}
 
-	if (ret && eb)
-		clear_extent_buffer_uptodate(tree, eb, NULL);
+	if (ret)
+		clear_extent_buffer_uptodate(eb);
+	free_extent_buffer(eb);
 out:
 	return ret;
 }
@@ -878,20 +886,6 @@ static int btree_migratepage(struct address_space *mapping,
 }
 #endif
 
-static int btree_writepage(struct page *page, struct writeback_control *wbc)
-{
-	struct extent_io_tree *tree;
-	tree = &BTRFS_I(page->mapping->host)->io_tree;
-
-	if (!(current->flags & PF_MEMALLOC)) {
-		return extent_write_full_page(tree, page,
-					      btree_get_extent, wbc);
-	}
-
-	redirty_page_for_writepage(wbc, page);
-	unlock_page(page);
-	return 0;
-}
 
 static int btree_writepages(struct address_space *mapping,
 			    struct writeback_control *wbc)
@@ -911,7 +905,7 @@ static int btree_writepages(struct address_space *mapping,
 		if (num_dirty < thresh)
 			return 0;
 	}
-	return extent_writepages(tree, mapping, btree_get_extent, wbc);
+	return btree_write_cache_pages(mapping, wbc);
 }
 
 static int btree_readpage(struct file *file, struct page *page)
@@ -950,15 +944,28 @@ static void btree_invalidatepage(struct page *page, unsigned long offset)
 	}
 }
 
+static int btree_set_page_dirty(struct page *page)
+{
+	struct extent_buffer *eb;
+
+	BUG_ON(!PagePrivate(page));
+	eb = (struct extent_buffer *)page->private;
+	BUG_ON(!eb);
+	BUG_ON(!test_bit(EXTENT_BUFFER_DIRTY, &eb->bflags));
+	BUG_ON(!atomic_read(&eb->refs));
+	btrfs_assert_tree_locked(eb);
+	return __set_page_dirty_nobuffers(page);
+}
+
 static const struct address_space_operations btree_aops = {
 	.readpage	= btree_readpage,
-	.writepage	= btree_writepage,
 	.writepages	= btree_writepages,
 	.releasepage	= btree_releasepage,
 	.invalidatepage = btree_invalidatepage,
 #ifdef CONFIG_MIGRATION
 	.migratepage	= btree_migratepage,
 #endif
+	.set_page_dirty = btree_set_page_dirty,
 };
 
 int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize,
@@ -1001,7 +1008,7 @@ int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr, u32 blocksize,
 	if (test_bit(EXTENT_BUFFER_CORRUPT, &buf->bflags)) {
 		free_extent_buffer(buf);
 		return -EIO;
-	} else if (extent_buffer_uptodate(io_tree, buf, NULL)) {
+	} else if (extent_buffer_uptodate(buf)) {
 		*eb = buf;
 	} else {
 		free_extent_buffer(buf);
@@ -1054,9 +1061,6 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 		return NULL;
 
 	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
-
-	if (ret == 0)
-		set_bit(EXTENT_BUFFER_UPTODATE, &buf->bflags);
 	return buf;
 
 }
@@ -1064,7 +1068,6 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		     struct extent_buffer *buf)
 {
-	struct inode *btree_inode = root->fs_info->btree_inode;
 	if (btrfs_header_generation(buf) ==
 	    root->fs_info->running_transaction->transid) {
 		btrfs_assert_tree_locked(buf);
@@ -1080,8 +1083,7 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 
 		/* ugh, clear_extent_buffer_dirty needs to lock the page */
 		btrfs_set_lock_blocking(buf);
-		clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree,
-					  buf);
+		clear_extent_buffer_dirty(buf);
 	}
 	return 0;
 }
@@ -1948,6 +1950,7 @@ int open_ctree(struct super_block *sb,
 	RB_CLEAR_NODE(&BTRFS_I(fs_info->btree_inode)->rb_node);
 	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,
 			     fs_info->btree_inode->i_mapping);
+	BTRFS_I(fs_info->btree_inode)->io_tree.track_uptodate = 0;
 	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree);
 
 	BTRFS_I(fs_info->btree_inode)->io_tree.ops = &btree_extent_io_ops;
@@ -3058,8 +3061,7 @@ int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid)
 	int ret;
 	struct inode *btree_inode = buf->pages[0]->mapping->host;
 
-	ret = extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree, buf,
-				     NULL);
+	ret = extent_buffer_uptodate(buf);
 	if (!ret)
 		return ret;
 
@@ -3070,16 +3072,13 @@ int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid)
 
 int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->pages[0]->mapping->host;
-	return set_extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree,
-					  buf);
+	return set_extent_buffer_uptodate(buf);
 }
 
 void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
 	u64 transid = btrfs_header_generation(buf);
-	struct inode *btree_inode = root->fs_info->btree_inode;
 	int was_dirty;
 
 	btrfs_assert_tree_locked(buf);
@@ -3091,8 +3090,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 			(unsigned long long)root->fs_info->generation);
 		WARN_ON(1);
 	}
-	was_dirty = set_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree,
-					    buf);
+	was_dirty = set_extent_buffer_dirty(buf);
 	if (!was_dirty) {
 		spin_lock(&root->fs_info->delalloc_lock);
 		root->fs_info->dirty_metadata_bytes += buf->len;
@@ -3147,11 +3145,7 @@ void __btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 {
 	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
-	int ret;
-	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
-	if (ret == 0)
-		set_bit(EXTENT_BUFFER_UPTODATE, &buf->bflags);
-	return ret;
+	return btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 }
 
 static int btree_lock_page_hook(struct page *page, void *data,

commit 3083ee2e18b701122a3b841db83448543a87a583
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Mar 9 16:01:49 2012 -0500

    Btrfs: introduce free_extent_buffer_stale
    
    Because btrfs cow's we can end up with extent buffers that are no longer
    necessary just sitting around in memory.  So instead of evicting these pages, we
    could end up evicting things we actually care about.  Thus we have
    free_extent_buffer_stale for use when we are freeing tree blocks.  This will
    make it so that the ref for the eb being in the radix tree is dropped as soon as
    possible and then is freed when the refcount hits 0 instead of waiting to be
    released by releasepage.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bc88649cffb7..0ba055e03eb8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -923,16 +923,8 @@ static int btree_readpage(struct file *file, struct page *page)
 
 static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 {
-	struct extent_map_tree *map;
-	struct extent_io_tree *tree;
-	int ret;
-
 	if (PageWriteback(page) || PageDirty(page))
 		return 0;
-
-	tree = &BTRFS_I(page->mapping->host)->io_tree;
-	map = &BTRFS_I(page->mapping->host)->extent_tree;
-
 	/*
 	 * We need to mask out eg. __GFP_HIGHMEM and __GFP_DMA32 as we're doing
 	 * slab allocation from alloc_extent_state down the callchain where
@@ -940,11 +932,7 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	 */
 	gfp_flags &= ~GFP_SLAB_BUG_MASK;
 
-	ret = try_release_extent_state(map, tree, page, gfp_flags);
-	if (!ret)
-		return 0;
-
-	return try_release_extent_buffer(tree, page);
+	return try_release_extent_buffer(page, gfp_flags);
 }
 
 static void btree_invalidatepage(struct page *page, unsigned long offset)

commit 4f2de97acee6532b36dd6e995b858343771ad126
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Mar 7 16:20:05 2012 -0500

    Btrfs: set page->private to the eb
    
    We spend a lot of time looking up extent buffers from pages when we could just
    store the pointer to the eb the page is associated with in page->private.  This
    patch does just that, and it makes things a little simpler and reduces a bit of
    CPU overhead involved with doing metadata IO.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 68fc93e18db8..bc88649cffb7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -403,39 +403,28 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	struct extent_io_tree *tree;
 	u64 start = (u64)page->index << PAGE_CACHE_SHIFT;
 	u64 found_start;
-	unsigned long len;
 	struct extent_buffer *eb;
 
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 
-	if (page->private == EXTENT_PAGE_PRIVATE)
-		goto out;
-	if (!page->private) {
-		WARN_ON(1);
-		goto out;
-	}
-	len = page->private >> 2;
-	WARN_ON(len == 0);
-
-	eb = find_extent_buffer(tree, start, len);
+	eb = (struct extent_buffer *)page->private;
+	if (page != eb->pages[0])
+		return 0;
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
 		WARN_ON(1);
-		goto err;
+		return 0;
 	}
 	if (eb->pages[0] != page) {
 		WARN_ON(1);
-		goto err;
+		return 0;
 	}
 	if (!PageUptodate(page)) {
 		WARN_ON(1);
-		goto err;
+		return 0;
 	}
 	csum_tree_block(root, eb, 0);
-err:
-	free_extent_buffer(eb);
-out:
 	return 0;
 }
 
@@ -566,7 +555,6 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	struct extent_io_tree *tree;
 	u64 found_start;
 	int found_level;
-	unsigned long len;
 	struct extent_buffer *eb;
 	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
 	int ret = 0;
@@ -576,13 +564,8 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		goto out;
 
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
-	len = page->private >> 2;
+	eb = (struct extent_buffer *)page->private;
 
-	eb = find_eb_for_page(tree, page, max(root->leafsize, root->nodesize));
-	if (!eb) {
-		ret = -EIO;
-		goto out;
-	}
 	reads_done = atomic_dec_and_test(&eb->pages_reading);
 	if (!reads_done)
 		goto err;
@@ -631,7 +614,6 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 
 	if (ret && eb)
 		clear_extent_buffer_uptodate(tree, eb, NULL);
-	free_extent_buffer(eb);
 out:
 	return ret;
 }
@@ -640,31 +622,17 @@ static int btree_io_failed_hook(struct bio *failed_bio,
 			 struct page *page, u64 start, u64 end,
 			 int mirror_num, struct extent_state *state)
 {
-	struct extent_io_tree *tree;
-	unsigned long len;
 	struct extent_buffer *eb;
 	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
 
-	tree = &BTRFS_I(page->mapping->host)->io_tree;
-	if (page->private == EXTENT_PAGE_PRIVATE)
-		goto out;
-	if (!page->private)
-		goto out;
-
-	len = page->private >> 2;
-	WARN_ON(len == 0);
-
-	eb = alloc_extent_buffer(tree, start, len);
-	if (eb == NULL)
-		goto out;
+	eb = (struct extent_buffer *)page->private;
+	if (page != eb->pages[0])
+		return -EIO;
 
 	if (test_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags)) {
 		clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags);
 		btree_readahead_hook(root, eb, eb->start, -EIO);
 	}
-	free_extent_buffer(eb);
-
-out:
 	return -EIO;	/* we fixed nothing */
 }
 
@@ -955,10 +923,8 @@ static int btree_readpage(struct file *file, struct page *page)
 
 static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 {
-	struct extent_io_tree *tree;
 	struct extent_map_tree *map;
-	struct extent_buffer *eb;
-	struct btrfs_root *root;
+	struct extent_io_tree *tree;
 	int ret;
 
 	if (PageWriteback(page) || PageDirty(page))
@@ -967,13 +933,6 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
 
-	root = BTRFS_I(page->mapping->host)->root;
-	if (page->private == EXTENT_PAGE_PRIVATE) {
-		eb = find_eb_for_page(tree, page, max(root->leafsize, root->nodesize));
-		free_extent_buffer(eb);
-		if (eb)
-			return 0;
-	}
 	/*
 	 * We need to mask out eg. __GFP_HIGHMEM and __GFP_DMA32 as we're doing
 	 * slab allocation from alloc_extent_state down the callchain where
@@ -985,14 +944,7 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	if (!ret)
 		return 0;
 
-	ret = try_release_extent_buffer(tree, page);
-	if (ret == 1) {
-		ClearPagePrivate(page);
-		set_page_private(page, 0);
-		page_cache_release(page);
-	}
-
-	return ret;
+	return try_release_extent_buffer(tree, page);
 }
 
 static void btree_invalidatepage(struct page *page, unsigned long offset)
@@ -3219,17 +3171,21 @@ static int btree_lock_page_hook(struct page *page, void *data,
 {
 	struct inode *inode = page->mapping->host;
 	struct btrfs_root *root = BTRFS_I(inode)->root;
-	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
 	struct extent_buffer *eb;
-	unsigned long len;
-	u64 bytenr = page_offset(page);
 
-	if (page->private == EXTENT_PAGE_PRIVATE)
+	/*
+	 * We culled this eb but the page is still hanging out on the mapping,
+	 * carry on.
+	 */
+	if (!PagePrivate(page))
 		goto out;
 
-	len = page->private >> 2;
-	eb = find_extent_buffer(io_tree, bytenr, len);
-	if (!eb)
+	eb = (struct extent_buffer *)page->private;
+	if (!eb) {
+		WARN_ON(1);
+		goto out;
+	}
+	if (page != eb->pages[0])
 		goto out;
 
 	if (!btrfs_try_tree_write_lock(eb)) {
@@ -3248,7 +3204,6 @@ static int btree_lock_page_hook(struct page *page, void *data,
 	}
 
 	btrfs_tree_unlock(eb);
-	free_extent_buffer(eb);
 out:
 	if (!trylock_page(page)) {
 		flush_fn(data);

commit 727011e07cbdf87772fcc1999cccd15cc915eb62
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 6 13:21:20 2010 -0400

    Btrfs: allow metadata blocks larger than the page size
    
    A few years ago the btrfs code to support blocks lager than
    the page size was disabled to fix a few corner cases in the
    page cache handling.  This fixes the code to properly support
    large metadata blocks again.
    
    Since current kernels will crash early and often with larger
    metadata blocks, this adds an incompat bit so that older kernels
    can't mount it.
    
    This also does away with different blocksizes for nodes and leaves.
    You get a single block size for all tree blocks.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 534266fe505f..68fc93e18db8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -370,8 +370,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		ret = read_extent_buffer_pages(io_tree, eb, start,
 					       WAIT_COMPLETE,
 					       btree_get_extent, mirror_num);
-		if (!ret &&
-		    !verify_parent_transid(io_tree, eb, parent_transid))
+		if (!ret && !verify_parent_transid(io_tree, eb, parent_transid))
 			return ret;
 
 		/*
@@ -406,14 +405,11 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	u64 found_start;
 	unsigned long len;
 	struct extent_buffer *eb;
-	int ret;
 
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 
-	if (page->private == EXTENT_PAGE_PRIVATE) {
-		WARN_ON(1);
+	if (page->private == EXTENT_PAGE_PRIVATE)
 		goto out;
-	}
 	if (!page->private) {
 		WARN_ON(1);
 		goto out;
@@ -421,22 +417,14 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	len = page->private >> 2;
 	WARN_ON(len == 0);
 
-	eb = alloc_extent_buffer(tree, start, len, page);
-	if (eb == NULL) {
-		WARN_ON(1);
-		goto out;
-	}
-	ret = btree_read_extent_buffer_pages(root, eb, start + PAGE_CACHE_SIZE,
-					     btrfs_header_generation(eb));
-	BUG_ON(ret);
-	WARN_ON(!btrfs_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN));
+	eb = find_extent_buffer(tree, start, len);
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
 		WARN_ON(1);
 		goto err;
 	}
-	if (eb->first_page != page) {
+	if (eb->pages[0] != page) {
 		WARN_ON(1);
 		goto err;
 	}
@@ -537,6 +525,41 @@ static noinline int check_leaf(struct btrfs_root *root,
 	return 0;
 }
 
+struct extent_buffer *find_eb_for_page(struct extent_io_tree *tree,
+				       struct page *page, int max_walk)
+{
+	struct extent_buffer *eb;
+	u64 start = page_offset(page);
+	u64 target = start;
+	u64 min_start;
+
+	if (start < max_walk)
+		min_start = 0;
+	else
+		min_start = start - max_walk;
+
+	while (start >= min_start) {
+		eb = find_extent_buffer(tree, start, 0);
+		if (eb) {
+			/*
+			 * we found an extent buffer and it contains our page
+			 * horray!
+			 */
+			if (eb->start <= target &&
+			    eb->start + eb->len > target)
+				return eb;
+
+			/* we found an extent buffer that wasn't for us */
+			free_extent_buffer(eb);
+			return NULL;
+		}
+		if (start == 0)
+			break;
+		start -= PAGE_CACHE_SIZE;
+	}
+	return NULL;
+}
+
 static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 			       struct extent_state *state)
 {
@@ -547,24 +570,25 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	struct extent_buffer *eb;
 	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
 	int ret = 0;
+	int reads_done;
 
-	tree = &BTRFS_I(page->mapping->host)->io_tree;
-	if (page->private == EXTENT_PAGE_PRIVATE)
-		goto out;
 	if (!page->private)
 		goto out;
 
+	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	len = page->private >> 2;
-	WARN_ON(len == 0);
 
-	eb = alloc_extent_buffer(tree, start, len, page);
-	if (eb == NULL) {
+	eb = find_eb_for_page(tree, page, max(root->leafsize, root->nodesize));
+	if (!eb) {
 		ret = -EIO;
 		goto out;
 	}
+	reads_done = atomic_dec_and_test(&eb->pages_reading);
+	if (!reads_done)
+		goto err;
 
 	found_start = btrfs_header_bytenr(eb);
-	if (found_start != start) {
+	if (found_start != eb->start) {
 		printk_ratelimited(KERN_INFO "btrfs bad tree block start "
 			       "%llu %llu\n",
 			       (unsigned long long)found_start,
@@ -572,13 +596,6 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		ret = -EIO;
 		goto err;
 	}
-	if (eb->first_page != page) {
-		printk(KERN_INFO "btrfs bad first page %lu %lu\n",
-		       eb->first_page->index, page->index);
-		WARN_ON(1);
-		ret = -EIO;
-		goto err;
-	}
 	if (check_tree_block_fsid(root, eb)) {
 		printk_ratelimited(KERN_INFO "btrfs bad fsid on block %llu\n",
 			       (unsigned long long)eb->start);
@@ -606,14 +623,14 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		ret = -EIO;
 	}
 
-	end = min_t(u64, eb->len, PAGE_CACHE_SIZE);
-	end = eb->start + end - 1;
 err:
 	if (test_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags)) {
 		clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags);
 		btree_readahead_hook(root, eb, eb->start, ret);
 	}
 
+	if (ret && eb)
+		clear_extent_buffer_uptodate(tree, eb, NULL);
 	free_extent_buffer(eb);
 out:
 	return ret;
@@ -637,7 +654,7 @@ static int btree_io_failed_hook(struct bio *failed_bio,
 	len = page->private >> 2;
 	WARN_ON(len == 0);
 
-	eb = alloc_extent_buffer(tree, start, len, page);
+	eb = alloc_extent_buffer(tree, start, len);
 	if (eb == NULL)
 		goto out;
 
@@ -896,28 +913,14 @@ static int btree_migratepage(struct address_space *mapping,
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct extent_io_tree *tree;
-	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
-	struct extent_buffer *eb;
-	int was_dirty;
-
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
+
 	if (!(current->flags & PF_MEMALLOC)) {
 		return extent_write_full_page(tree, page,
 					      btree_get_extent, wbc);
 	}
 
 	redirty_page_for_writepage(wbc, page);
-	eb = btrfs_find_tree_block(root, page_offset(page), PAGE_CACHE_SIZE);
-	WARN_ON(!eb);
-
-	was_dirty = test_and_set_bit(EXTENT_BUFFER_DIRTY, &eb->bflags);
-	if (!was_dirty) {
-		spin_lock(&root->fs_info->delalloc_lock);
-		root->fs_info->dirty_metadata_bytes += PAGE_CACHE_SIZE;
-		spin_unlock(&root->fs_info->delalloc_lock);
-	}
-	free_extent_buffer(eb);
-
 	unlock_page(page);
 	return 0;
 }
@@ -954,6 +957,8 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 {
 	struct extent_io_tree *tree;
 	struct extent_map_tree *map;
+	struct extent_buffer *eb;
+	struct btrfs_root *root;
 	int ret;
 
 	if (PageWriteback(page) || PageDirty(page))
@@ -962,6 +967,13 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
 
+	root = BTRFS_I(page->mapping->host)->root;
+	if (page->private == EXTENT_PAGE_PRIVATE) {
+		eb = find_eb_for_page(tree, page, max(root->leafsize, root->nodesize));
+		free_extent_buffer(eb);
+		if (eb)
+			return 0;
+	}
 	/*
 	 * We need to mask out eg. __GFP_HIGHMEM and __GFP_DMA32 as we're doing
 	 * slab allocation from alloc_extent_state down the callchain where
@@ -1074,20 +1086,20 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 	struct extent_buffer *eb;
 
 	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
-				 bytenr, blocksize, NULL);
+				 bytenr, blocksize);
 	return eb;
 }
 
 
 int btrfs_write_tree_block(struct extent_buffer *buf)
 {
-	return filemap_fdatawrite_range(buf->first_page->mapping, buf->start,
+	return filemap_fdatawrite_range(buf->pages[0]->mapping, buf->start,
 					buf->start + buf->len - 1);
 }
 
 int btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
 {
-	return filemap_fdatawait_range(buf->first_page->mapping,
+	return filemap_fdatawait_range(buf->pages[0]->mapping,
 				       buf->start, buf->start + buf->len - 1);
 }
 
@@ -1513,41 +1525,6 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 	return 0;
 }
 
-static int bio_ready_for_csum(struct bio *bio)
-{
-	u64 length = 0;
-	u64 buf_len = 0;
-	u64 start = 0;
-	struct page *page;
-	struct extent_io_tree *io_tree = NULL;
-	struct bio_vec *bvec;
-	int i;
-	int ret;
-
-	bio_for_each_segment(bvec, bio, i) {
-		page = bvec->bv_page;
-		if (page->private == EXTENT_PAGE_PRIVATE) {
-			length += bvec->bv_len;
-			continue;
-		}
-		if (!page->private) {
-			length += bvec->bv_len;
-			continue;
-		}
-		length = bvec->bv_len;
-		buf_len = page->private >> 2;
-		start = page_offset(page) + bvec->bv_offset;
-		io_tree = &BTRFS_I(page->mapping->host)->io_tree;
-	}
-	/* are we fully contained in this bio? */
-	if (buf_len <= length)
-		return 1;
-
-	ret = extent_range_uptodate(io_tree, start + length,
-				    start + buf_len - 1);
-	return ret;
-}
-
 /*
  * called by the kthread helper functions to finally call the bio end_io
  * functions.  This is where read checksum verification actually happens
@@ -1563,17 +1540,6 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	bio = end_io_wq->bio;
 	fs_info = end_io_wq->info;
 
-	/* metadata bio reads are special because the whole tree block must
-	 * be checksummed at once.  This makes sure the entire block is in
-	 * ram and up to date before trying to verify things.  For
-	 * blocksize <= pagesize, it is basically a noop
-	 */
-	if (!(bio->bi_rw & REQ_WRITE) && end_io_wq->metadata &&
-	    !bio_ready_for_csum(bio)) {
-		btrfs_queue_worker(&fs_info->endio_meta_workers,
-				   &end_io_wq->work);
-		return;
-	}
 	error = end_io_wq->error;
 	bio->bi_private = end_io_wq->private;
 	bio->bi_end_io = end_io_wq->end_io;
@@ -2135,10 +2101,38 @@ int open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
+	if (btrfs_super_leafsize(disk_super) !=
+	    btrfs_super_nodesize(disk_super)) {
+		printk(KERN_ERR "BTRFS: couldn't mount because metadata "
+		       "blocksizes don't match.  node %d leaf %d\n",
+		       btrfs_super_nodesize(disk_super),
+		       btrfs_super_leafsize(disk_super));
+		err = -EINVAL;
+		goto fail_alloc;
+	}
+	if (btrfs_super_leafsize(disk_super) > BTRFS_MAX_METADATA_BLOCKSIZE) {
+		printk(KERN_ERR "BTRFS: couldn't mount because metadata "
+		       "blocksize (%d) was too large\n",
+		       btrfs_super_leafsize(disk_super));
+		err = -EINVAL;
+		goto fail_alloc;
+	}
+
 	features = btrfs_super_incompat_flags(disk_super);
 	features |= BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF;
 	if (tree_root->fs_info->compress_type & BTRFS_COMPRESS_LZO)
 		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;
+
+	/*
+	 * flag our filesystem as having big metadata blocks if
+	 * they are bigger than the page size
+	 */
+	if (btrfs_super_leafsize(disk_super) > PAGE_CACHE_SIZE) {
+		if (!(features & BTRFS_FEATURE_INCOMPAT_BIG_METADATA))
+			printk(KERN_INFO "btrfs flagging fs with big metadata feature\n");
+		features |= BTRFS_FEATURE_INCOMPAT_BIG_METADATA;
+	}
+
 	btrfs_set_super_incompat_flags(disk_super, features);
 
 	features = btrfs_super_compat_ro_flags(disk_super) &
@@ -3122,7 +3116,7 @@ int close_ctree(struct btrfs_root *root)
 int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid)
 {
 	int ret;
-	struct inode *btree_inode = buf->first_page->mapping->host;
+	struct inode *btree_inode = buf->pages[0]->mapping->host;
 
 	ret = extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree, buf,
 				     NULL);
@@ -3136,14 +3130,14 @@ int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid)
 
 int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->first_page->mapping->host;
+	struct inode *btree_inode = buf->pages[0]->mapping->host;
 	return set_extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree,
 					  buf);
 }
 
 void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
 	u64 transid = btrfs_header_generation(buf);
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	int was_dirty;
@@ -3212,7 +3206,7 @@ void __btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 
 int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 {
-	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
 	int ret;
 	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 	if (ret == 0)

commit 914b20070b413ca10f832c45a58b2894990f065f
Author: Jan Kara <jack@suse.cz>
Date:   Mon Mar 12 16:05:50 2012 +0100

    btrfs: Fix busyloop in transaction_kthread()
    
    When a filesystem got aborted due do error, transaction_kthread() will
    busyloop.  Fix it by going to sleep in that case as well. Maybe we should
    just stop transaction_kthread() when filesystem is aborted but that would be
    more complex.
    
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 16a0cada26c2..438993e3d832 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1640,8 +1640,10 @@ static int transaction_kthread(void *arg)
 	u64 transid;
 	unsigned long now;
 	unsigned long delay;
+	bool cannot_commit;
 
 	do {
+		cannot_commit = false;
 		delay = HZ * 30;
 		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
 		mutex_lock(&root->fs_info->transaction_kthread_mutex);
@@ -1665,8 +1667,10 @@ static int transaction_kthread(void *arg)
 
 		/* If the file system is aborted, this will always fail. */
 		trans = btrfs_join_transaction(root);
-		if (IS_ERR(trans))
+		if (IS_ERR(trans)) {
+			cannot_commit = true;
 			goto sleep;
+		}
 		if (transid == trans->transid) {
 			btrfs_commit_transaction(trans, root);
 		} else {
@@ -1679,7 +1683,8 @@ static int transaction_kthread(void *arg)
 		if (!try_to_freeze()) {
 			set_current_state(TASK_INTERRUPTIBLE);
 			if (!kthread_should_stop() &&
-			    !btrfs_transaction_blocked(root->fs_info))
+			    (!btrfs_transaction_blocked(root->fs_info) ||
+			     cannot_commit))
 				schedule_timeout(delay);
 			__set_current_state(TASK_RUNNING);
 		}

commit 79787eaab46121d4713ed03c8fc63b9ec3eaec76
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 12 16:03:00 2012 +0100

    btrfs: replace many BUG_ONs with proper error handling
    
     btrfs currently handles most errors with BUG_ON. This patch is a work-in-
     progress but aims to handle most errors other than internal logic
     errors and ENOMEM more gracefully.
    
     This iteration prevents most crashes but can run into lockups with
     the page lock on occasion when the timing "works out."
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6297a030ac50..16a0cada26c2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -98,6 +98,7 @@ struct async_submit_bio {
 	 */
 	u64 bio_offset;
 	struct btrfs_work work;
+	int error;
 };
 
 /*
@@ -405,7 +406,7 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	u64 found_start;
 	unsigned long len;
 	struct extent_buffer *eb;
-	int ret;
+	int ret = -EIO;
 
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 
@@ -423,13 +424,20 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	eb = alloc_extent_buffer(tree, start, len, page);
 	if (eb == NULL) {
 		WARN_ON(1);
+		ret = -ENOMEM;
 		goto out;
 	}
 	ret = btree_read_extent_buffer_pages(root, eb, start + PAGE_CACHE_SIZE,
 					     btrfs_header_generation(eb));
-	BUG_ON(ret);
+	if (ret) {
+		btrfs_printk(root->fs_info, KERN_WARNING
+			     "Failed to checksum dirty buffer @ %llu[%lu]\n",
+			      start, len);
+		goto err;
+	}
 	WARN_ON(!btrfs_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN));
 
+	ret = -EIO;
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
 		WARN_ON(1);
@@ -444,10 +452,11 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 		goto err;
 	}
 	csum_tree_block(root, eb, 0);
+	ret = 0;
 err:
 	free_extent_buffer(eb);
 out:
-	return 0;
+	return ret;
 }
 
 static int check_tree_block_fsid(struct btrfs_root *root,
@@ -718,11 +727,14 @@ unsigned long btrfs_async_submit_limit(struct btrfs_fs_info *info)
 static void run_one_async_start(struct btrfs_work *work)
 {
 	struct async_submit_bio *async;
+	int ret;
 
 	async = container_of(work, struct  async_submit_bio, work);
-	async->submit_bio_start(async->inode, async->rw, async->bio,
-			       async->mirror_num, async->bio_flags,
-			       async->bio_offset);
+	ret = async->submit_bio_start(async->inode, async->rw, async->bio,
+				      async->mirror_num, async->bio_flags,
+				      async->bio_offset);
+	if (ret)
+		async->error = ret;
 }
 
 static void run_one_async_done(struct btrfs_work *work)
@@ -743,6 +755,12 @@ static void run_one_async_done(struct btrfs_work *work)
 	    waitqueue_active(&fs_info->async_submit_wait))
 		wake_up(&fs_info->async_submit_wait);
 
+	/* If an error occured we just want to clean up the bio and move on */
+	if (async->error) {
+		bio_endio(async->bio, async->error);
+		return;
+	}
+
 	async->submit_bio_done(async->inode, async->rw, async->bio,
 			       async->mirror_num, async->bio_flags,
 			       async->bio_offset);
@@ -784,6 +802,8 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->bio_flags = bio_flags;
 	async->bio_offset = bio_offset;
 
+	async->error = 0;
+
 	atomic_inc(&fs_info->nr_async_submits);
 
 	if (rw & REQ_SYNC)
@@ -805,15 +825,18 @@ static int btree_csum_one_bio(struct bio *bio)
 	struct bio_vec *bvec = bio->bi_io_vec;
 	int bio_index = 0;
 	struct btrfs_root *root;
+	int ret = 0;
 
 	WARN_ON(bio->bi_vcnt <= 0);
 	while (bio_index < bio->bi_vcnt) {
 		root = BTRFS_I(bvec->bv_page->mapping->host)->root;
-		csum_dirty_buffer(root, bvec->bv_page);
+		ret = csum_dirty_buffer(root, bvec->bv_page);
+		if (ret)
+			break;
 		bio_index++;
 		bvec++;
 	}
-	return 0;
+	return ret;
 }
 
 static int __btree_submit_bio_start(struct inode *inode, int rw,
@@ -825,8 +848,7 @@ static int __btree_submit_bio_start(struct inode *inode, int rw,
 	 * when we're called for a write, we're already in the async
 	 * submission context.  Just jump into btrfs_map_bio
 	 */
-	btree_csum_one_bio(bio);
-	return 0;
+	return btree_csum_one_bio(bio);
 }
 
 static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
@@ -1381,7 +1403,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
 	root->commit_root = btrfs_root_node(root);
-	BUG_ON(!root->node);
+	BUG_ON(!root->node); /* -ENOMEM */
 out:
 	if (location->objectid != BTRFS_TREE_LOG_OBJECTID) {
 		root->ref_cows = 1;
@@ -1618,7 +1640,6 @@ static int transaction_kthread(void *arg)
 	u64 transid;
 	unsigned long now;
 	unsigned long delay;
-	int ret;
 
 	do {
 		delay = HZ * 30;
@@ -1642,11 +1663,12 @@ static int transaction_kthread(void *arg)
 		transid = cur->transid;
 		spin_unlock(&root->fs_info->trans_lock);
 
+		/* If the file system is aborted, this will always fail. */
 		trans = btrfs_join_transaction(root);
-		BUG_ON(IS_ERR(trans));
+		if (IS_ERR(trans))
+			goto sleep;
 		if (transid == trans->transid) {
-			ret = btrfs_commit_transaction(trans, root);
-			BUG_ON(ret);
+			btrfs_commit_transaction(trans, root);
 		} else {
 			btrfs_end_transaction(trans, root);
 		}
@@ -2289,7 +2311,7 @@ int open_ctree(struct super_block *sb,
 	chunk_root->node = read_tree_block(chunk_root,
 					   btrfs_super_chunk_root(disk_super),
 					   blocksize, generation);
-	BUG_ON(!chunk_root->node);
+	BUG_ON(!chunk_root->node); /* -ENOMEM */
 	if (!test_bit(EXTENT_BUFFER_UPTODATE, &chunk_root->node->bflags)) {
 		printk(KERN_WARNING "btrfs: failed to read chunk root on %s\n",
 		       sb->s_id);
@@ -2429,21 +2451,31 @@ int open_ctree(struct super_block *sb,
 		log_tree_root->node = read_tree_block(tree_root, bytenr,
 						      blocksize,
 						      generation + 1);
+		/* returns with log_tree_root freed on success */
 		ret = btrfs_recover_log_trees(log_tree_root);
-		BUG_ON(ret);
+		if (ret) {
+			btrfs_error(tree_root->fs_info, ret,
+				    "Failed to recover log tree");
+			free_extent_buffer(log_tree_root->node);
+			kfree(log_tree_root);
+			goto fail_trans_kthread;
+		}
 
 		if (sb->s_flags & MS_RDONLY) {
-			ret =  btrfs_commit_super(tree_root);
-			BUG_ON(ret);
+			ret = btrfs_commit_super(tree_root);
+			if (ret)
+				goto fail_trans_kthread;
 		}
 	}
 
 	ret = btrfs_find_orphan_roots(tree_root);
-	BUG_ON(ret);
+	if (ret)
+		goto fail_trans_kthread;
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_cleanup_fs_roots(fs_info);
-		BUG_ON(ret);
+		if (ret) {
+			}
 
 		ret = btrfs_recover_relocation(tree_root);
 		if (ret < 0) {
@@ -2863,6 +2895,8 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	if (total_errors > max_errors) {
 		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
 		       total_errors);
+
+		/* This shouldn't happen. FUA is masked off if unsupported */
 		BUG();
 	}
 
@@ -2879,9 +2913,9 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	}
 	mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
 	if (total_errors > max_errors) {
-		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
-		       total_errors);
-		BUG();
+		btrfs_error(root->fs_info, -EIO,
+			    "%d errors while writing supers", total_errors);
+		return -EIO;
 	}
 	return 0;
 }
@@ -3014,14 +3048,21 @@ int btrfs_commit_super(struct btrfs_root *root)
 	if (IS_ERR(trans))
 		return PTR_ERR(trans);
 	ret = btrfs_commit_transaction(trans, root);
-	BUG_ON(ret);
+	if (ret)
+		return ret;
 	/* run commit again to drop the original snapshot */
 	trans = btrfs_join_transaction(root);
 	if (IS_ERR(trans))
 		return PTR_ERR(trans);
-	btrfs_commit_transaction(trans, root);
+	ret = btrfs_commit_transaction(trans, root);
+	if (ret)
+		return ret;
 	ret = btrfs_write_and_wait_transaction(NULL, root);
-	BUG_ON(ret);
+	if (ret) {
+		btrfs_error(root->fs_info, ret,
+			    "Failed to sync btree inode to disk.");
+		return ret;
+	}
 
 	ret = write_ctree_super(NULL, root, 0);
 	return ret;
@@ -3366,8 +3407,8 @@ static void btrfs_destroy_ordered_extents(struct btrfs_root *root)
 	spin_unlock(&root->fs_info->ordered_extent_lock);
 }
 
-static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
-				      struct btrfs_root *root)
+int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
+			       struct btrfs_root *root)
 {
 	struct rb_node *node;
 	struct btrfs_delayed_ref_root *delayed_refs;
@@ -3376,6 +3417,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 
 	delayed_refs = &trans->delayed_refs;
 
+again:
 	spin_lock(&delayed_refs->lock);
 	if (delayed_refs->num_entries == 0) {
 		spin_unlock(&delayed_refs->lock);
@@ -3397,6 +3439,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 			struct btrfs_delayed_ref_head *head;
 
 			head = btrfs_delayed_node_to_head(ref);
+			spin_unlock(&delayed_refs->lock);
 			mutex_lock(&head->mutex);
 			kfree(head->extent_op);
 			delayed_refs->num_heads--;
@@ -3404,8 +3447,9 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				delayed_refs->num_heads_ready--;
 			list_del_init(&head->cluster);
 			mutex_unlock(&head->mutex);
+			btrfs_put_delayed_ref(ref);
+			goto again;
 		}
-
 		spin_unlock(&delayed_refs->lock);
 		btrfs_put_delayed_ref(ref);
 
@@ -3649,6 +3693,17 @@ int btrfs_cleanup_transaction(struct btrfs_root *root)
 	return 0;
 }
 
+static int btree_writepage_io_failed_hook(struct bio *bio, struct page *page,
+					  u64 start, u64 end,
+					  struct extent_state *state)
+{
+	struct super_block *sb = page->mapping->host->i_sb;
+	struct btrfs_fs_info *fs_info = btrfs_sb(sb);
+	btrfs_error(fs_info, -EIO,
+		    "Error occured while writing out btree at %llu", start);
+	return -EIO;
+}
+
 static struct extent_io_ops btree_extent_io_ops = {
 	.write_cache_pages_lock_hook = btree_lock_page_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
@@ -3656,4 +3711,5 @@ static struct extent_io_ops btree_extent_io_ops = {
 	.submit_bio_hook = btree_submit_bio_hook,
 	/* note we're sharing with inode.c for the merge bio hook */
 	.merge_bio_hook = btrfs_merge_bio_hook,
+	.writepage_io_failed_hook = btree_writepage_io_failed_hook,
 };

commit 49b25e0540904be0bf558b84475c69d72e4de66e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 17:24:58 2012 +0100

    btrfs: enhance transaction abort infrastructure
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 69ef456b32fa..6297a030ac50 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -61,7 +61,6 @@ static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 					int mark);
 static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 				       struct extent_io_tree *pinned_extents);
-static int btrfs_cleanup_transaction(struct btrfs_root *root);
 
 /*
  * end_io_wq structs are used to do processing in task context when an IO is
@@ -2896,6 +2895,19 @@ int write_ctree_super(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
+/* Kill all outstanding I/O */
+void btrfs_abort_devices(struct btrfs_root *root)
+{
+	struct list_head *head;
+	struct btrfs_device *dev;
+	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
+	head = &root->fs_info->fs_devices->devices;
+	list_for_each_entry_rcu(dev, head, dev_list) {
+		blk_abort_queue(dev->bdev->bd_disk->queue);
+	}
+	mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
+}
+
 void btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 {
 	spin_lock(&fs_info->fs_roots_radix_lock);
@@ -3536,13 +3548,43 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 	return 0;
 }
 
-static int btrfs_cleanup_transaction(struct btrfs_root *root)
+void btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,
+				   struct btrfs_root *root)
+{
+	btrfs_destroy_delayed_refs(cur_trans, root);
+	btrfs_block_rsv_release(root, &root->fs_info->trans_block_rsv,
+				cur_trans->dirty_pages.dirty_bytes);
+
+	/* FIXME: cleanup wait for commit */
+	cur_trans->in_commit = 1;
+	cur_trans->blocked = 1;
+	if (waitqueue_active(&root->fs_info->transaction_blocked_wait))
+		wake_up(&root->fs_info->transaction_blocked_wait);
+
+	cur_trans->blocked = 0;
+	if (waitqueue_active(&root->fs_info->transaction_wait))
+		wake_up(&root->fs_info->transaction_wait);
+
+	cur_trans->commit_done = 1;
+	if (waitqueue_active(&cur_trans->commit_wait))
+		wake_up(&cur_trans->commit_wait);
+
+	btrfs_destroy_pending_snapshots(cur_trans);
+
+	btrfs_destroy_marked_extents(root, &cur_trans->dirty_pages,
+				     EXTENT_DIRTY);
+
+	/*
+	memset(cur_trans, 0, sizeof(*cur_trans));
+	kmem_cache_free(btrfs_transaction_cachep, cur_trans);
+	*/
+}
+
+int btrfs_cleanup_transaction(struct btrfs_root *root)
 {
 	struct btrfs_transaction *t;
 	LIST_HEAD(list);
 
-	WARN_ON(1);
-
 	mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
 	spin_lock(&root->fs_info->trans_lock);

commit d0082371cf086e0ba2bbd0367b2c9920532df24f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:57:19 2012 +0100

    btrfs: drop gfp_t from lock_extent
    
     lock_extent and unlock_extent are always called with GFP_NOFS, drop the
     argument and use GFP_NOFS consistently.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 73ccadce90bc..69ef456b32fa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -332,7 +332,7 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		return 0;
 
 	lock_extent_bits(io_tree, eb->start, eb->start + eb->len - 1,
-			 0, &cached_state, GFP_NOFS);
+			 0, &cached_state);
 	if (extent_buffer_uptodate(io_tree, eb, cached_state) &&
 	    btrfs_header_generation(eb) == parent_transid) {
 		ret = 0;

commit 143bede527b054a271053f41bfaca2b57baa9408
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:56:26 2012 +0100

    btrfs: return void in functions without error conditions
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2e4428bd60ec..73ccadce90bc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -50,12 +50,12 @@ static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
 static void btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
 				    int read_only);
-static int btrfs_destroy_ordered_operations(struct btrfs_root *root);
-static int btrfs_destroy_ordered_extents(struct btrfs_root *root);
+static void btrfs_destroy_ordered_operations(struct btrfs_root *root);
+static void btrfs_destroy_ordered_extents(struct btrfs_root *root);
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 				      struct btrfs_root *root);
-static int btrfs_destroy_pending_snapshots(struct btrfs_transaction *t);
-static int btrfs_destroy_delalloc_inodes(struct btrfs_root *root);
+static void btrfs_destroy_pending_snapshots(struct btrfs_transaction *t);
+static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root);
 static int btrfs_destroy_marked_extents(struct btrfs_root *root,
 					struct extent_io_tree *dirty_pages,
 					int mark);
@@ -1139,10 +1139,10 @@ void clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 	}
 }
 
-static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
-			u32 stripesize, struct btrfs_root *root,
-			struct btrfs_fs_info *fs_info,
-			u64 objectid)
+static void __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
+			 u32 stripesize, struct btrfs_root *root,
+			 struct btrfs_fs_info *fs_info,
+			 u64 objectid)
 {
 	root->node = NULL;
 	root->commit_root = NULL;
@@ -1194,7 +1194,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->defrag_running = 0;
 	root->root_key.objectid = objectid;
 	root->anon_dev = 0;
-	return 0;
 }
 
 static int __must_check find_and_setup_root(struct btrfs_root *tree_root,
@@ -2897,7 +2896,7 @@ int write_ctree_super(struct btrfs_trans_handle *trans,
 	return ret;
 }
 
-int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
+void btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 {
 	spin_lock(&fs_info->fs_roots_radix_lock);
 	radix_tree_delete(&fs_info->fs_roots_radix,
@@ -2910,7 +2909,6 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 	__btrfs_remove_free_space_cache(root->free_ino_pinned);
 	__btrfs_remove_free_space_cache(root->free_ino_ctl);
 	free_fs_root(root);
-	return 0;
 }
 
 static void free_fs_root(struct btrfs_root *root)
@@ -2927,7 +2925,7 @@ static void free_fs_root(struct btrfs_root *root)
 	kfree(root);
 }
 
-static int del_fs_roots(struct btrfs_fs_info *fs_info)
+static void del_fs_roots(struct btrfs_fs_info *fs_info)
 {
 	int ret;
 	struct btrfs_root *gang[8];
@@ -2956,7 +2954,6 @@ static int del_fs_roots(struct btrfs_fs_info *fs_info)
 		for (i = 0; i < ret; i++)
 			btrfs_free_fs_root(fs_info, gang[i]);
 	}
-	return 0;
 }
 
 int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
@@ -3299,7 +3296,7 @@ int btrfs_error_commit_super(struct btrfs_root *root)
 	return ret;
 }
 
-static int btrfs_destroy_ordered_operations(struct btrfs_root *root)
+static void btrfs_destroy_ordered_operations(struct btrfs_root *root)
 {
 	struct btrfs_inode *btrfs_inode;
 	struct list_head splice;
@@ -3321,11 +3318,9 @@ static int btrfs_destroy_ordered_operations(struct btrfs_root *root)
 
 	spin_unlock(&root->fs_info->ordered_extent_lock);
 	mutex_unlock(&root->fs_info->ordered_operations_mutex);
-
-	return 0;
 }
 
-static int btrfs_destroy_ordered_extents(struct btrfs_root *root)
+static void btrfs_destroy_ordered_extents(struct btrfs_root *root)
 {
 	struct list_head splice;
 	struct btrfs_ordered_extent *ordered;
@@ -3357,8 +3352,6 @@ static int btrfs_destroy_ordered_extents(struct btrfs_root *root)
 	}
 
 	spin_unlock(&root->fs_info->ordered_extent_lock);
-
-	return 0;
 }
 
 static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
@@ -3413,7 +3406,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 	return ret;
 }
 
-static int btrfs_destroy_pending_snapshots(struct btrfs_transaction *t)
+static void btrfs_destroy_pending_snapshots(struct btrfs_transaction *t)
 {
 	struct btrfs_pending_snapshot *snapshot;
 	struct list_head splice;
@@ -3431,11 +3424,9 @@ static int btrfs_destroy_pending_snapshots(struct btrfs_transaction *t)
 
 		kfree(snapshot);
 	}
-
-	return 0;
 }
 
-static int btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
+static void btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
 {
 	struct btrfs_inode *btrfs_inode;
 	struct list_head splice;
@@ -3455,8 +3446,6 @@ static int btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
 	}
 
 	spin_unlock(&root->fs_info->delalloc_lock);
-
-	return 0;
 }
 
 static int btrfs_destroy_marked_extents(struct btrfs_root *root,

commit 355808c296c6923db6705f43639969a80b16d15d
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Oct 3 23:23:14 2011 -0400

    btrfs: ->submit_bio_hook error push-up
    
    This pushes failures from the submit_bio_hook callbacks,
    btrfs_submit_bio_hook and btree_submit_bio_hook into the callers, including
    callers of submit_one_bio where it catches the failures with BUG_ON.
    
    It also pushes up through the ->readpage_io_failed_hook to
    end_bio_extent_writepage where the error is already caught with BUG_ON.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 155c4e35e536..2e4428bd60ec 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -847,9 +847,9 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 {
 	int ret;
 
-	ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info,
-					  bio, 1);
-	BUG_ON(ret);
+	ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info, bio, 1);
+	if (ret)
+		return ret;
 
 	if (!(rw & REQ_WRITE)) {
 		/*

commit 200a5c17677e1ee8b78382046f3748c9f5816281
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Oct 3 23:22:43 2011 -0400

    btrfs: find_and_setup_root error push-up
    
    find_and_setup_root BUGs when it encounters an error from
    btrfs_find_last_root, which can occur if a path can't be allocated.
    
    This patch pushes it up to its callers where it is already handled.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d52ec1155204..155c4e35e536 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1197,10 +1197,10 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	return 0;
 }
 
-static int find_and_setup_root(struct btrfs_root *tree_root,
-			       struct btrfs_fs_info *fs_info,
-			       u64 objectid,
-			       struct btrfs_root *root)
+static int __must_check find_and_setup_root(struct btrfs_root *tree_root,
+					    struct btrfs_fs_info *fs_info,
+					    u64 objectid,
+					    struct btrfs_root *root)
 {
 	int ret;
 	u32 blocksize;
@@ -1213,7 +1213,8 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 				   &root->root_item, &root->root_key);
 	if (ret > 0)
 		return -ENOENT;
-	BUG_ON(ret);
+	else if (ret < 0)
+		return ret;
 
 	generation = btrfs_root_generation(&root->root_item);
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));

commit d5c13f927fe77b11a67f79559808c68b26474c77
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 14:56:27 2012 +0100

    btrfs: clean_tree_block should panic on observed memory corruption and return void
    
     The only error condition in clean_tree_block is an accounting bug.
     Returning without modifying dirty_metadata_bytes and as if the cleaning
     as been performed may cause problems later so it should panic instead.
    
     It should probably be a BUG_ON but we have btrfs_panic now.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 534266fe505f..d52ec1155204 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1109,8 +1109,8 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 
 }
 
-int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		     struct extent_buffer *buf)
+void clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		      struct extent_buffer *buf)
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	if (btrfs_header_generation(buf) ==
@@ -1121,8 +1121,14 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 			spin_lock(&root->fs_info->delalloc_lock);
 			if (root->fs_info->dirty_metadata_bytes >= buf->len)
 				root->fs_info->dirty_metadata_bytes -= buf->len;
-			else
-				WARN_ON(1);
+			else {
+				spin_unlock(&root->fs_info->delalloc_lock);
+				btrfs_panic(root->fs_info, -EOVERFLOW,
+					  "Can't clear %lu bytes from "
+					  " dirty_mdatadata_bytes (%lu)",
+					  buf->len,
+					  root->fs_info->dirty_metadata_bytes);
+			}
 			spin_unlock(&root->fs_info->delalloc_lock);
 		}
 
@@ -1131,7 +1137,6 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree,
 					  buf);
 	}
-	return 0;
 }
 
 static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,

commit 855a85f704026d5fe7de94fb1b765fe03404507f
Merge: ee3253241a92 e77266e4c4be
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 24 09:02:53 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    Quoth Chris:
     "This is later than I wanted because I got backed up running through
      btrfs bugs from the Oracle QA teams.  But they are all bug fixes that
      we've queued and tested since rc1.
    
      Nothing in particular stands out, this just reflects bug fixing and QA
      done in parallel by all the btrfs developers.  The most user visible
      of these is:
    
        Btrfs: clear the extent uptodate bits during parent transid failures
    
      Because that helps deal with out of date drives (say an iscsi disk
      that has gone away and come back).  The old code wasn't always
      properly retrying the other mirror for this type of failure."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (24 commits)
      Btrfs: fix compiler warnings on 32 bit systems
      Btrfs: increase the global block reserve estimates
      Btrfs: clear the extent uptodate bits during parent transid failures
      Btrfs: add extra sanity checks on the path names in btrfs_mksubvol
      Btrfs: make sure we update latest_bdev
      Btrfs: improve error handling for btrfs_insert_dir_item callers
      Btrfs: be less strict on finding next node in clear_extent_bit
      Btrfs: fix a bug on overcommit stuff
      Btrfs: kick out redundant stuff in convert_extent_bit
      Btrfs: skip states when they does not contain bits to clear
      Btrfs: check return value of lookup_extent_mapping() correctly
      Btrfs: fix deadlock on page lock when doing auto-defragment
      Btrfs: fix return value check of extent_io_ops
      btrfs: honor umask when creating subvol root
      btrfs: silence warning in raid array setup
      btrfs: fix structs where bitfields and spinlock/atomic share 8B word
      btrfs: delalloc for page dirtied out-of-band in fixup worker
      Btrfs: fix memory leak in load_free_space_cache()
      btrfs: don't check DUP chunks twice
      Btrfs: fix trim 0 bytes after a device delete
      ...

commit a6b0d5c8dbfd428717fc4db4c36757783f391c7b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Feb 20 20:53:43 2012 -0500

    Btrfs: make sure we update latest_bdev
    
    When we are setting up the mount, we close all the
    devices that were not actually part of the metadata we found.
    
    But, we don't make sure that one of those devices wasn't
    fs_devices->latest_bdev, which means we can do a use after free
    on the one we closed.
    
    This updates latest_bdev as it goes.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 58d0678dfcba..b801d29f3f10 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2305,6 +2305,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	btrfs_close_extra_devices(fs_devices);
 
+	if (!fs_devices->latest_bdev) {
+		printk(KERN_CRIT "btrfs: failed to read devices on %s\n",
+		       sb->s_id);
+		goto fail_tree_roots;
+	}
+
 retry_root_backup:
 	blocksize = btrfs_level_size(tree_root,
 				     btrfs_super_root_level(disk_super));

commit 941b2ddf71987ef369389517a7e215dd505fe01e
Author: Keith Mannthey <kmannth@us.ibm.com>
Date:   Tue Nov 29 17:44:12 2011 -0800

    btrfs: Sector Size check during Mount
    
    Gracefully fail when trying to mount a BTRFS file system that has a
    sectorsize smaller than PAGE_SIZE.
    
    On PPC it is possible to build a FS while using a 4k PAGE_SIZE kernel
    then boot into a 64K PAGE_SIZE kernel.  Presently open_ctree fails in an
    endless loop and hangs the machine in this situation.
    
    My debugging has show this Sector size < Page size to be a non trivial
    situation and a graceful exit from the situation would be nice for the
    time being.
    
    Signed-off-by: Keith Mannthey <kmannth@us.ibm.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4c867112b4c8..58d0678dfcba 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2258,6 +2258,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 
+	if (sectorsize < PAGE_SIZE) {
+		printk(KERN_WARNING "btrfs: Incompatible sector size "
+		       "found on %s\n", sb->s_id);
+		goto fail_sb_buffer;
+	}
+
 	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);

commit 67d2433ee7aa631bc3ab14c2af6bbc1d44d13a00
Merge: 1c36ab1a318a 9998eb703490
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 28 17:00:19 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: fix reservations in btrfs_page_mkwrite
      Btrfs: advance window_start if we're using a bitmap
      btrfs: mask out gfp flags in releasepage
      Btrfs: fix enospc error caused by wrong checks of the chunk
      Btrfs: do not defrag a file partially
      Btrfs: fix warning for 32-bit build of fs/btrfs/check-integrity.c
      Btrfs: use cluster->window_start when allocating from a cluster bitmap
      Btrfs: Check for NULL page in extent_range_uptodate
      btrfs: Fix busyloops in transaction waiting code
      Btrfs: make sure a bitmap has enough bytes
      Btrfs: fix uninit warning in backref.c

commit 0c4e538bccc106872d31b1514570b4dac95fb7f2
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Jan 26 15:01:12 2012 -0500

    btrfs: mask out gfp flags in releasepage
    
    btree_releasepage is a callback and can be passed unknown gfp flags and then
    they may end up in kmem_cache_alloc called from alloc_extent_state, slab
    allocator will BUG_ON when there is HIGHMEM or DMA32 flag set.
    
    This may happen when btrfs is mounted from a loop device, which masks out
    __GFP_IO flag. The check in try_release_extent_state
    
    3399                 if ((mask & GFP_NOFS) == GFP_NOFS)
    3400                         mask = GFP_NOFS;
    
    will not work and passes unfiltered flags further resulting in crash at
    mm/slab.c:2963
    
     [<000000000024ae4c>] cache_alloc_refill+0x3b4/0x5c8
     [<000000000024c810>] kmem_cache_alloc+0x204/0x294
     [<00000000001fd3c2>] mempool_alloc+0x52/0x170
     [<000003c000ced0b0>] alloc_extent_state+0x40/0xd4 [btrfs]
     [<000003c000cee5ae>] __clear_extent_bit+0x38a/0x4cc [btrfs]
     [<000003c000cee78c>] try_release_extent_state+0x9c/0xd4 [btrfs]
     [<000003c000cc4c66>] btree_releasepage+0x7e/0xd0 [btrfs]
     [<0000000000210d84>] shrink_page_list+0x6a0/0x724
     [<0000000000211394>] shrink_inactive_list+0x230/0x578
     [<0000000000211bb8>] shrink_list+0x6c/0x120
     [<0000000000211e4e>] shrink_zone+0x1e2/0x228
     [<0000000000211f24>] shrink_zones+0x90/0x254
     [<0000000000213410>] do_try_to_free_pages+0xac/0x420
     [<0000000000213ae0>] try_to_free_pages+0x13c/0x1b0
     [<0000000000204e6c>] __alloc_pages_nodemask+0x5b4/0x9a8
     [<00000000001fb04a>] grab_cache_page_write_begin+0x7e/0xe8
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index da4457f84d78..4c867112b4c8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -961,6 +961,13 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
 
+	/*
+	 * We need to mask out eg. __GFP_HIGHMEM and __GFP_DMA32 as we're doing
+	 * slab allocation from alloc_extent_state down the callchain where
+	 * it'd hit a BUG_ON as those flags are not allowed.
+	 */
+	gfp_flags &= ~GFP_SLAB_BUG_MASK;
+
 	ret = try_release_extent_state(map, tree, page, gfp_flags);
 	if (!ret)
 		return 0;

commit d65773b22b749252b2805dcf96bdeb951a9481d8
Merge: f9156c7288e2 f84a8bd60e3e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 17 15:52:51 2012 -0800

    Merge branch 'btrfs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    * 'btrfs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      btrfs: take allocation of ->tree_root into open_ctree()
      btrfs: let ->s_fs_info point to fs_info, not root...
      btrfs: consolidate failure exits in btrfs_mount() a bit
      btrfs: make free_fs_info() call ->kill_sb() unconditional
      btrfs: merge free_fs_info() calls on fill_super failures
      btrfs: kill pointless reassignment of ->s_fs_info in btrfs_fill_super()
      btrfs: make open_ctree() return int
      btrfs: sanitizing ->fs_info, part 5
      btrfs: sanitizing ->fs_info, part 4
      btrfs: sanitizing ->fs_info, part 3
      btrfs: sanitizing ->fs_info, part 2
      btrfs: sanitizing ->fs_info, part 1
      btrfs: fix a deadlock in btrfs_scan_one_device()
      btrfs: fix mount/umount race
      btrfs: get ->kill_sb() of its own
      btrfs: preparation to fixing mount/umount race

commit f9156c7288e2d11501ded4d7fe6d9a3a41ee4057
Merge: 67175b855bfd 96bdc7dc61fb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 17 15:49:54 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (62 commits)
      Btrfs: use larger system chunks
      Btrfs: add a delalloc mutex to inodes for delalloc reservations
      Btrfs: space leak tracepoints
      Btrfs: protect orphan block rsv with spin_lock
      Btrfs: add allocator tracepoints
      Btrfs: don't call btrfs_throttle in file write
      Btrfs: release space on error in page_mkwrite
      Btrfs: fix btrfsck error 400 when truncating a compressed
      Btrfs: do not use btrfs_end_transaction_throttle everywhere
      Btrfs: add balance progress reporting
      Btrfs: allow for resuming restriper after it was paused
      Btrfs: allow for canceling restriper
      Btrfs: allow for pausing restriper
      Btrfs: add skip_balance mount option
      Btrfs: recover balance on mount
      Btrfs: save balance parameters to disk
      Btrfs: soft profile changing mode (aka soft convert)
      Btrfs: implement online profile changing
      Btrfs: do not reduce profile in do_chunk_alloc()
      Btrfs: virtual address space subset filter
      ...
    
    Fix up trivial conflict in fs/btrfs/ioctl.c due to the use of the new
    mnt_drop_write_file() helper.

commit c126dea771be1b3c370c0ffc4a09e6a82d492a49
Merge: 9785dbdf265d 21adbd5cbb53
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 16 15:27:58 2012 -0500

    Merge branch 'integrity-check-patch-v2' of git://btrfs.giantdisaster.de/git/btrfs into integration
    
    Conflicts:
            fs/btrfs/ctree.h
            fs/btrfs/super.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 9785dbdf265ddc47d5c88267d89a97648c0dc14b
Merge: d756bd2d9339 6bf7e080d5bc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 16 15:26:31 2012 -0500

    Merge branch 'for-chris' of git://git.jan-o-sch.net/btrfs-unstable into integration

commit d756bd2d9339447c29bde950910586df8f8941ec
Merge: 27263e28321d b367e47fb3a7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 16 15:26:17 2012 -0500

    Merge branch 'for-chris' of git://repo.or.cz/linux-btrfs-devel into integration
    
    Conflicts:
            fs/btrfs/volumes.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 27263e28321db438bc43dc0c0be432ce91526224
Merge: 64e05503ab5c 19a39dce3b9b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 16 15:26:02 2012 -0500

    Merge branch 'restriper' of git://github.com/idryomov/btrfs-unstable into integration

commit a7e99c691af553fc15ac46a51f130b7c59a65f76
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:49 2012 +0200

    Btrfs: allow for canceling restriper
    
    Implement an ioctl for canceling restriper.  Currently we wait until
    relocation of the current block group is finished, in future this can be
    done by triggering a commit.  Balance item is deleted and no memory
    about the interrupted balance is kept.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8ce837407800..c23b82d8ec08 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2006,6 +2006,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->balance_mutex);
 	atomic_set(&fs_info->balance_running, 0);
 	atomic_set(&fs_info->balance_pause_req, 0);
+	atomic_set(&fs_info->balance_cancel_req, 0);
 	fs_info->balance_ctl = NULL;
 	init_waitqueue_head(&fs_info->balance_wait_q);
 

commit 837d5b6e46d1a4af5b6cc8f2fe83cb5de79a2961
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:49 2012 +0200

    Btrfs: allow for pausing restriper
    
    Implement an ioctl for pausing restriper.  This pauses the relocation,
    but balance is still considered to be "in progress": balance item is
    not deleted, other volume operations cannot be started, etc.  If paused
    in the middle of profile changing operation we will continue making
    allocations with the target profile.
    
    Add a hook to close_ctree() to pause restriper and free its data
    structures on unmount.  (It's safe to unmount when restriper is in
    "paused" state, we will resume with the same parameters on the next
    mount)
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eb7a11ac5b73..8ce837407800 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2004,7 +2004,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	spin_lock_init(&fs_info->balance_lock);
 	mutex_init(&fs_info->balance_mutex);
+	atomic_set(&fs_info->balance_running, 0);
+	atomic_set(&fs_info->balance_pause_req, 0);
 	fs_info->balance_ctl = NULL;
+	init_waitqueue_head(&fs_info->balance_wait_q);
 
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
@@ -2980,6 +2983,9 @@ int close_ctree(struct btrfs_root *root)
 	fs_info->closing = 1;
 	smp_mb();
 
+	/* pause restriper - we want to resume on mount */
+	btrfs_pause_balance(root->fs_info);
+
 	btrfs_scrub_cancel(root);
 
 	/* wait for any defraggers to finish */

commit 596410151ed71819b9e8a8018c6c9992796b256d
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:48 2012 +0200

    Btrfs: recover balance on mount
    
    On mount, if balance item is found, resume balance in a separate
    kernel thread.
    
    Try to be smart to continue roughly where previous balance (or convert)
    was interrupted.  For chunk types that were being converted to some
    profile we turn on soft convert, in case of a simple balance we turn on
    usage filter and relocate only less-than-90%-full chunks of that type.
    These are just heuristics but they help quite a bit, and can be improved
    in future.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 190a1b24c902..eb7a11ac5b73 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2427,6 +2427,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		if (!err)
 			err = btrfs_orphan_cleanup(fs_info->tree_root);
 		up_read(&fs_info->cleanup_work_sem);
+
+		if (!err)
+			err = btrfs_recover_balance(fs_info->tree_root);
+
 		if (err) {
 			close_ctree(tree_root);
 			return ERR_PTR(err);

commit c9e9f97bdfb64d06e9520f8e4f37674ac21cc9bc
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:47 2012 +0200

    Btrfs: add basic restriper infrastructure
    
    Add basic restriper infrastructure: extended balancing ioctl and all
    related ioctl data structures, add data structure for tracking
    restriper's state to fs_info, etc.  The semantics of the old balancing
    ioctl are fully preserved.
    
    Explicitly disallow any volume operations when balance is in progress.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ce9d0fb3627d..190a1b24c902 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2002,6 +2002,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	init_rwsem(&fs_info->scrub_super_lock);
 	fs_info->scrub_workers_refcnt = 0;
 
+	spin_lock_init(&fs_info->balance_lock);
+	mutex_init(&fs_info->balance_mutex);
+	fs_info->balance_ctl = NULL;
+
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
 	sb->s_bdi = &fs_info->bdi;

commit 6fef8df1dcb9b586268caff66df1d71ce8610132
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Jan 16 22:04:47 2012 +0200

    Btrfs: get rid of *_alloc_profile fields
    
    {data,metadata,system}_alloc_profile fields have been unused for a long
    time now.  Get rid of them.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3f9d5551e582..ce9d0fb3627d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2321,9 +2321,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	fs_info->generation = generation;
 	fs_info->last_trans_committed = generation;
-	fs_info->data_alloc_profile = (u64)-1;
-	fs_info->metadata_alloc_profile = (u64)-1;
-	fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
 
 	ret = btrfs_init_space_info(fs_info);
 	if (ret) {

commit a6bc32b899223a877f595ef9ddc1e89ead5072b8
Author: Mel Gorman <mgorman@suse.de>
Date:   Thu Jan 12 17:19:43 2012 -0800

    mm: compaction: introduce sync-light migration for use by compaction
    
    This patch adds a lightweight sync migrate operation MIGRATE_SYNC_LIGHT
    mode that avoids writing back pages to backing storage.  Async compaction
    maps to MIGRATE_ASYNC while sync compaction maps to MIGRATE_SYNC_LIGHT.
    For other migrate_pages users such as memory hotplug, MIGRATE_SYNC is
    used.
    
    This avoids sync compaction stalling for an excessive length of time,
    particularly when copying files to a USB stick where there might be a
    large number of dirty pages backed by a filesystem that does not support
    ->writepages.
    
    [aarcange@redhat.com: This patch is heavily based on Andrea's work]
    [akpm@linux-foundation.org: fix fs/nfs/write.c build]
    [akpm@linux-foundation.org: fix fs/btrfs/disk-io.c build]
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Minchan Kim <minchan.kim@gmail.com>
    Cc: Dave Jones <davej@redhat.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Andy Isaacson <adi@hexapodia.org>
    Cc: Nai Xia <nai.xia@gmail.com>
    Cc: Johannes Weiner <jweiner@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1375494c8cb6..d8525662ca7a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -872,7 +872,8 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 
 #ifdef CONFIG_MIGRATION
 static int btree_migratepage(struct address_space *mapping,
-			struct page *newpage, struct page *page, bool sync)
+			struct page *newpage, struct page *page,
+			enum migrate_mode mode)
 {
 	/*
 	 * we can't safely write a btree page from here,
@@ -887,7 +888,7 @@ static int btree_migratepage(struct address_space *mapping,
 	if (page_has_private(page) &&
 	    !try_to_release_page(page, GFP_KERNEL))
 		return -EAGAIN;
-	return migrate_page(mapping, newpage, page, sync);
+	return migrate_page(mapping, newpage, page, mode);
 }
 #endif
 

commit b969c4ab9f182a6e1b2a0848be349f99714947b0
Author: Mel Gorman <mgorman@suse.de>
Date:   Thu Jan 12 17:19:34 2012 -0800

    mm: compaction: determine if dirty pages can be migrated without blocking within ->migratepage
    
    Asynchronous compaction is used when allocating transparent hugepages to
    avoid blocking for long periods of time.  Due to reports of stalling,
    there was a debate on disabling synchronous compaction but this severely
    impacted allocation success rates.  Part of the reason was that many dirty
    pages are skipped in asynchronous compaction by the following check;
    
            if (PageDirty(page) && !sync &&
                    mapping->a_ops->migratepage != migrate_page)
                            rc = -EBUSY;
    
    This skips over all mapping aops using buffer_migrate_page() even though
    it is possible to migrate some of these pages without blocking.  This
    patch updates the ->migratepage callback with a "sync" parameter.  It is
    the responsibility of the callback to fail gracefully if migration would
    block.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Minchan Kim <minchan.kim@gmail.com>
    Cc: Dave Jones <davej@redhat.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Andy Isaacson <adi@hexapodia.org>
    Cc: Nai Xia <nai.xia@gmail.com>
    Cc: Johannes Weiner <jweiner@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f99a099a7747..1375494c8cb6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -872,7 +872,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 
 #ifdef CONFIG_MIGRATION
 static int btree_migratepage(struct address_space *mapping,
-			struct page *newpage, struct page *page)
+			struct page *newpage, struct page *page, bool sync)
 {
 	/*
 	 * we can't safely write a btree page from here,
@@ -887,7 +887,7 @@ static int btree_migratepage(struct address_space *mapping,
 	if (page_has_private(page) &&
 	    !try_to_release_page(page, GFP_KERNEL))
 		return -EAGAIN;
-	return migrate_page(mapping, newpage, page);
+	return migrate_page(mapping, newpage, page, sync);
 }
 #endif
 

commit b367e47fb3a70f5d24ebd6faf7d42436d485fb2d
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Dec 7 11:38:24 2011 +0800

    Btrfs: fix possible deadlock when opening a seed device
    
    The correct lock order is uuid_mutex -> volume_mutex -> chunk_mutex,
    but when we mount a filesystem which has backing seed devices, we have
    this lock chain:
    
        open_ctree()
            lock(chunk_mutex);
            read_chunk_tree();
                read_one_dev();
                    open_seed_devices();
                        lock(uuid_mutex);
    
    and then we hit a lockdep splat.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3f9d5551e582..858ab347413e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2270,9 +2270,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	   (unsigned long)btrfs_header_chunk_tree_uuid(chunk_root->node),
 	   BTRFS_UUID_SIZE);
 
-	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_chunk_tree(chunk_root);
-	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
 		printk(KERN_WARNING "btrfs: failed to read chunk tree on %s\n",
 		       sb->s_id);

commit f84a8bd60e3ee49eacc9ba824babf149ba3dad7e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 15:57:57 2011 -0500

    btrfs: take allocation of ->tree_root into open_ctree()
    
    now that we don't need it for sget() anymore...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f7d8b9ba519b..dd71be875939 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1215,7 +1215,7 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 	return 0;
 }
 
-struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info)
+static struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info)
 {
 	struct btrfs_root *root = kzalloc(sizeof(*root), GFP_NOFS);
 	if (root)
@@ -1895,7 +1895,7 @@ int open_ctree(struct super_block *sb,
 	struct buffer_head *bh;
 	struct btrfs_super_block *disk_super;
 	struct btrfs_fs_info *fs_info = btrfs_sb(sb);
-	struct btrfs_root *tree_root = fs_info->tree_root;
+	struct btrfs_root *tree_root;
 	struct btrfs_root *extent_root;
 	struct btrfs_root *csum_root;
 	struct btrfs_root *chunk_root;
@@ -1906,12 +1906,14 @@ int open_ctree(struct super_block *sb,
 	int num_backups_tried = 0;
 	int backup_index = 0;
 
+	tree_root = fs_info->tree_root = btrfs_alloc_root(fs_info);
 	extent_root = fs_info->extent_root = btrfs_alloc_root(fs_info);
 	csum_root = fs_info->csum_root = btrfs_alloc_root(fs_info);
 	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info);
 	dev_root = fs_info->dev_root = btrfs_alloc_root(fs_info);
 
-	if (!extent_root || !csum_root || !chunk_root || !dev_root) {
+	if (!tree_root || !extent_root || !csum_root ||
+	    !chunk_root || !dev_root) {
 		err = -ENOMEM;
 		goto fail;
 	}

commit 815745cf3e46681241ad8025602ffbf2a452d514
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 15:40:49 2011 -0500

    btrfs: let ->s_fs_info point to fs_info, not root...
    
    the latter can be obtained from the former (by looking as ->tree_root)
    just as cheaply as we currently are doing the other way round.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b6d11eb4e430..f7d8b9ba519b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1894,8 +1894,8 @@ int open_ctree(struct super_block *sb,
 	struct btrfs_key location;
 	struct buffer_head *bh;
 	struct btrfs_super_block *disk_super;
-	struct btrfs_root *tree_root = btrfs_sb(sb);
-	struct btrfs_fs_info *fs_info = tree_root->fs_info;
+	struct btrfs_fs_info *fs_info = btrfs_sb(sb);
+	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct btrfs_root *extent_root;
 	struct btrfs_root *csum_root;
 	struct btrfs_root *chunk_root;

commit be7e0950def403e90b5295ff2192c39967bf2aec
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 01:40:05 2011 -0500

    btrfs: merge free_fs_info() calls on fill_super failures
    
    ... all the way up into btrfs_mount().
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 78247522c693..b6d11eb4e430 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2427,7 +2427,6 @@ int open_ctree(struct super_block *sb,
 		up_read(&fs_info->cleanup_work_sem);
 		if (err) {
 			close_ctree(tree_root);
-			free_fs_info(fs_info);
 			return err;
 		}
 	}
@@ -2478,7 +2477,6 @@ int open_ctree(struct super_block *sb,
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 fail:
 	btrfs_close_devices(fs_info->fs_devices);
-	free_fs_info(fs_info);
 	return err;
 
 recovery_tree_root:

commit ad2b2c802be2d3e8ed8364fef5ffaddabe448219
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 01:10:02 2011 -0500

    btrfs: make open_ctree() return int
    
    It returns either ERR_PTR(-ve) or sb->s_fs_info.  The latter can
    be found by caller just as well, TYVM, no need to return it.  Just
    return -ve or 0...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9308c7f13c17..78247522c693 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1880,9 +1880,9 @@ static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
 }
 
 
-struct btrfs_root *open_ctree(struct super_block *sb,
-			      struct btrfs_fs_devices *fs_devices,
-			      char *options)
+int open_ctree(struct super_block *sb,
+	       struct btrfs_fs_devices *fs_devices,
+	       char *options)
 {
 	u32 sectorsize;
 	u32 nodesize;
@@ -2428,11 +2428,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		if (err) {
 			close_ctree(tree_root);
 			free_fs_info(fs_info);
-			return ERR_PTR(err);
+			return err;
 		}
 	}
 
-	return tree_root;
+	return 0;
 
 fail_trans_kthread:
 	kthread_stop(fs_info->transaction_kthread);
@@ -2479,7 +2479,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail:
 	btrfs_close_devices(fs_info->fs_devices);
 	free_fs_info(fs_info);
-	return ERR_PTR(err);
+	return err;
 
 recovery_tree_root:
 	if (!btrfs_test_opt(tree_root, RECOVERY))

commit e3029d9fd426c8f582210ba35551ae5506218345
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 00:56:18 2011 -0500

    btrfs: sanitizing ->fs_info, part 5
    
    close_ctree() uses a weird mix of accesses to root->fs_info and
    its value at the beginning of function stored in local variable.
    Since ->fs_info *never* changes, let's just use the local variable
    to avoid confusion.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ee846ce58846..9308c7f13c17 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2982,7 +2982,7 @@ int close_ctree(struct btrfs_root *root)
 		   (atomic_read(&fs_info->defrag_running) == 0));
 
 	/* clear out the rbtree of defraggable inodes */
-	btrfs_run_defrag_inodes(root->fs_info);
+	btrfs_run_defrag_inodes(fs_info);
 
 	/*
 	 * Here come 2 situations when btrfs is broken to flip readonly:
@@ -3011,8 +3011,8 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_put_block_group_cache(fs_info);
 
-	kthread_stop(root->fs_info->transaction_kthread);
-	kthread_stop(root->fs_info->cleaner_kthread);
+	kthread_stop(fs_info->transaction_kthread);
+	kthread_stop(fs_info->cleaner_kthread);
 
 	fs_info->closing = 2;
 	smp_mb();
@@ -3030,14 +3030,14 @@ int close_ctree(struct btrfs_root *root)
 	free_extent_buffer(fs_info->extent_root->commit_root);
 	free_extent_buffer(fs_info->tree_root->node);
 	free_extent_buffer(fs_info->tree_root->commit_root);
-	free_extent_buffer(root->fs_info->chunk_root->node);
-	free_extent_buffer(root->fs_info->chunk_root->commit_root);
-	free_extent_buffer(root->fs_info->dev_root->node);
-	free_extent_buffer(root->fs_info->dev_root->commit_root);
-	free_extent_buffer(root->fs_info->csum_root->node);
-	free_extent_buffer(root->fs_info->csum_root->commit_root);
-
-	btrfs_free_block_groups(root->fs_info);
+	free_extent_buffer(fs_info->chunk_root->node);
+	free_extent_buffer(fs_info->chunk_root->commit_root);
+	free_extent_buffer(fs_info->dev_root->node);
+	free_extent_buffer(fs_info->dev_root->commit_root);
+	free_extent_buffer(fs_info->csum_root->node);
+	free_extent_buffer(fs_info->csum_root->commit_root);
+
+	btrfs_free_block_groups(fs_info);
 
 	del_fs_roots(fs_info);
 

commit 6f07e42ee6fcc252a210781d7262f4051e9fd8f6
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 00:46:16 2011 -0500

    btrfs: sanitizing ->fs_info, part 4
    
    A new helper: btrfs_alloc_root(fs_info); allocates btrfs_root
    and sets ->fs_info.  All places allocating the suckers converted
    to it.  At that point we *never* reassign ->fs_info of btrfs_root;
    it's set before anyone sees the address of newly allocated
    struct btrfs_root and never assigned anywhere else.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 06480fcf0fb3..ee846ce58846 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1215,6 +1215,14 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 	return 0;
 }
 
+struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_root *root = kzalloc(sizeof(*root), GFP_NOFS);
+	if (root)
+		root->fs_info = fs_info;
+	return root;
+}
+
 static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info)
 {
@@ -1222,11 +1230,10 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct extent_buffer *leaf;
 
-	root = kzalloc(sizeof(*root), GFP_NOFS);
+	root = btrfs_alloc_root(fs_info);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
-	root->fs_info = fs_info;
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
 		     tree_root->sectorsize, tree_root->stripesize,
 		     root, fs_info, BTRFS_TREE_LOG_OBJECTID);
@@ -1317,10 +1324,9 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	u32 blocksize;
 	int ret = 0;
 
-	root = kzalloc(sizeof(*root), GFP_NOFS);
+	root = btrfs_alloc_root(fs_info);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
-	root->fs_info = fs_info;
 	if (location->offset == (u64)-1) {
 		ret = find_and_setup_root(tree_root, fs_info,
 					  location->objectid, root);
@@ -1900,23 +1906,15 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	int num_backups_tried = 0;
 	int backup_index = 0;
 
-	extent_root = fs_info->extent_root =
-		kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
-	csum_root = fs_info->csum_root =
-		kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
-	chunk_root = fs_info->chunk_root =
-		kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
-	dev_root = fs_info->dev_root =
-		kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
+	extent_root = fs_info->extent_root = btrfs_alloc_root(fs_info);
+	csum_root = fs_info->csum_root = btrfs_alloc_root(fs_info);
+	chunk_root = fs_info->chunk_root = btrfs_alloc_root(fs_info);
+	dev_root = fs_info->dev_root = btrfs_alloc_root(fs_info);
 
 	if (!extent_root || !csum_root || !chunk_root || !dev_root) {
 		err = -ENOMEM;
 		goto fail;
 	}
-	chunk_root->fs_info = fs_info;
-	extent_root->fs_info = fs_info;
-	dev_root->fs_info = fs_info;
-	csum_root->fs_info = fs_info;
 
 	ret = init_srcu_struct(&fs_info->subvol_srcu);
 	if (ret) {
@@ -2372,13 +2370,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		     btrfs_level_size(tree_root,
 				      btrfs_super_log_root_level(disk_super));
 
-		log_tree_root = kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
+		log_tree_root = btrfs_alloc_root(fs_info);
 		if (!log_tree_root) {
 			err = -ENOMEM;
 			goto fail_trans_kthread;
 		}
 
-		log_tree_root->fs_info = fs_info;
 		__setup_root(nodesize, leafsize, sectorsize, stripesize,
 			     log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
 

commit 38a77db49ad8f78369dcdfb693b8e5a818a60104
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 00:38:54 2011 -0500

    btrfs: sanitizing ->fs_info, part 3
    
    move assignments to ->fs_info in open_ctree() up, to the place
    just after the original allocations.  Assignment for tree_root
    becomes a no-op - we'd obtained fs_info from tree_root->fs_info
    in the first place.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b8dae517f80c..06480fcf0fb3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1320,8 +1320,8 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	root = kzalloc(sizeof(*root), GFP_NOFS);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
+	root->fs_info = fs_info;
 	if (location->offset == (u64)-1) {
-		root->fs_info = fs_info;
 		ret = find_and_setup_root(tree_root, fs_info,
 					  location->objectid, root);
 		if (ret) {
@@ -1331,7 +1331,6 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 		goto out;
 	}
 
-	root->fs_info = fs_info;
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
 		     tree_root->sectorsize, tree_root->stripesize,
 		     root, fs_info, location->objectid);
@@ -1914,6 +1913,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		err = -ENOMEM;
 		goto fail;
 	}
+	chunk_root->fs_info = fs_info;
+	extent_root->fs_info = fs_info;
+	dev_root->fs_info = fs_info;
+	csum_root->fs_info = fs_info;
 
 	ret = init_srcu_struct(&fs_info->subvol_srcu);
 	if (ret) {
@@ -2057,7 +2060,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->transaction_blocked_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);
 
-	tree_root->fs_info = fs_info;
 	__setup_root(4096, 4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
@@ -2250,7 +2252,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 				     btrfs_super_chunk_root_level(disk_super));
 	generation = btrfs_super_chunk_root_generation(disk_super);
 
-	chunk_root->fs_info = fs_info;
 	__setup_root(nodesize, leafsize, sectorsize, stripesize,
 		     chunk_root, fs_info, BTRFS_CHUNK_TREE_OBJECTID);
 
@@ -2300,21 +2301,18 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_set_root_node(&tree_root->root_item, tree_root->node);
 	tree_root->commit_root = btrfs_root_node(tree_root);
 
-	extent_root->fs_info = fs_info;
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
 	if (ret)
 		goto recovery_tree_root;
 	extent_root->track_dirty = 1;
 
-	dev_root->fs_info = fs_info;
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_DEV_TREE_OBJECTID, dev_root);
 	if (ret)
 		goto recovery_tree_root;
 	dev_root->track_dirty = 1;
 
-	csum_root->fs_info = fs_info;
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_CSUM_TREE_OBJECTID, csum_root);
 	if (ret)

commit 1233f546ec29ac32424327baf6ae5df81e3d9eae
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 00:34:00 2011 -0500

    btrfs: sanitizing ->fs_info, part 2
    
    lift assignment to callers of find_and_setup_root()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 04eba10af825..b8dae517f80c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1192,7 +1192,6 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 	u32 blocksize;
 	u64 generation;
 
-	root->fs_info = fs_info;
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
 		     tree_root->sectorsize, tree_root->stripesize,
 		     root, fs_info, objectid);
@@ -1322,6 +1321,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 	if (location->offset == (u64)-1) {
+		root->fs_info = fs_info;
 		ret = find_and_setup_root(tree_root, fs_info,
 					  location->objectid, root);
 		if (ret) {
@@ -2300,18 +2300,21 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_set_root_node(&tree_root->root_item, tree_root->node);
 	tree_root->commit_root = btrfs_root_node(tree_root);
 
+	extent_root->fs_info = fs_info;
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
 	if (ret)
 		goto recovery_tree_root;
 	extent_root->track_dirty = 1;
 
+	dev_root->fs_info = fs_info;
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_DEV_TREE_OBJECTID, dev_root);
 	if (ret)
 		goto recovery_tree_root;
 	dev_root->track_dirty = 1;
 
+	csum_root->fs_info = fs_info;
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_CSUM_TREE_OBJECTID, csum_root);
 	if (ret)

commit 2eb34cd368b3e5cef960ae9d9971a037cd6fa9d3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 00:32:06 2011 -0500

    btrfs: sanitizing ->fs_info, part 1
    
    take assignment of ->fs_info to callers of __setup_root()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dcb5d949b543..04eba10af825 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1142,7 +1142,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->orphan_item_inserted = 0;
 	root->orphan_cleanup_state = 0;
 
-	root->fs_info = fs_info;
 	root->objectid = objectid;
 	root->last_trans = 0;
 	root->highest_objectid = 0;
@@ -1193,6 +1192,7 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 	u32 blocksize;
 	u64 generation;
 
+	root->fs_info = fs_info;
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
 		     tree_root->sectorsize, tree_root->stripesize,
 		     root, fs_info, objectid);
@@ -1227,6 +1227,7 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 
+	root->fs_info = fs_info;
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
 		     tree_root->sectorsize, tree_root->stripesize,
 		     root, fs_info, BTRFS_TREE_LOG_OBJECTID);
@@ -1330,6 +1331,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 		goto out;
 	}
 
+	root->fs_info = fs_info;
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
 		     tree_root->sectorsize, tree_root->stripesize,
 		     root, fs_info, location->objectid);
@@ -2055,6 +2057,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->transaction_blocked_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);
 
+	tree_root->fs_info = fs_info;
 	__setup_root(4096, 4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
@@ -2247,6 +2250,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 				     btrfs_super_chunk_root_level(disk_super));
 	generation = btrfs_super_chunk_root_generation(disk_super);
 
+	chunk_root->fs_info = fs_info;
 	__setup_root(nodesize, leafsize, sectorsize, stripesize,
 		     chunk_root, fs_info, BTRFS_CHUNK_TREE_OBJECTID);
 
@@ -2373,6 +2377,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			goto fail_trans_kthread;
 		}
 
+		log_tree_root->fs_info = fs_info;
 		__setup_root(nodesize, leafsize, sectorsize, stripesize,
 			     log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
 

commit 98c7089c769048f941bd5c5285287f8fc301f8b1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 17 01:00:31 2011 -0500

    btrfs: preparation to fixing mount/umount race
    
    We need fs_info and root to live until the moment when the victim
    superblock leaves the list, so we need to postpone free_fs_info()
    until after ->put_super().  The call is buried in close_ctree(),
    though, so we need to lift it into the callers (including
    btrfs_put_super()) first.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f99a099a7747..dcb5d949b543 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2424,6 +2424,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		up_read(&fs_info->cleanup_work_sem);
 		if (err) {
 			close_ctree(tree_root);
+			free_fs_info(fs_info);
 			return ERR_PTR(err);
 		}
 	}
@@ -3059,8 +3060,6 @@ int close_ctree(struct btrfs_root *root)
 	bdi_destroy(&fs_info->bdi);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 
-	free_fs_info(fs_info);
-
 	return 0;
 }
 

commit 66d7e7f09f77456fe68683247d77721032a00ee5
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon Sep 12 15:26:38 2011 +0200

    Btrfs: mark delayed refs as for cow
    
    Add a for_cow parameter to add_delayed_*_ref and pass the appropriate value
    from every call site. The for_cow parameter will later on be used to
    determine if a ref will change anything with respect to qgroups.
    
    Delayed refs coming from relocation are always counted as for_cow, as they
    don't change subvol quota.
    
    Also pass in the fs_info for later use.
    
    btrfs_find_all_roots() will use this as an optimization, as changes that are
    for_cow will not change anything with respect to which root points to a
    certain leaf. Thus, we don't need to add the current sequence number to
    those delayed refs.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 94abc25392f6..6f8cd17c9a9f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1243,7 +1243,8 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	root->ref_cows = 0;
 
 	leaf = btrfs_alloc_free_block(trans, root, root->leafsize, 0,
-				      BTRFS_TREE_LOG_OBJECTID, NULL, 0, 0, 0);
+				      BTRFS_TREE_LOG_OBJECTID, NULL,
+				      0, 0, 0, 0);
 	if (IS_ERR(leaf)) {
 		kfree(root);
 		return ERR_CAST(leaf);

commit b00f4dc5ff022cb9cbaffd376d9454d7fa1e496f
Merge: 1eac8111e076 b9e26dfdad5a
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Dec 21 21:59:45 2011 +0100

    Merge branch 'master' into pm-sleep
    
    * master: (848 commits)
      SELinux: Fix RCU deref check warning in sel_netport_insert()
      binary_sysctl(): fix memory leak
      mm/vmalloc.c: remove static declaration of va from __get_vm_area_node
      ipmi_watchdog: restore settings when BMC reset
      oom: fix integer overflow of points in oom_badness
      memcg: keep root group unchanged if creation fails
      nilfs2: potential integer overflow in nilfs_ioctl_clean_segments()
      nilfs2: unbreak compat ioctl
      cpusets: stall when updating mems_allowed for mempolicy or disjoint nodemask
      evm: prevent racing during tfm allocation
      evm: key must be set once during initialization
      mmc: vub300: fix type of firmware_rom_wait_states module parameter
      Revert "mmc: enable runtime PM by default"
      mmc: sdhci: remove "state" argument from sdhci_suspend_host
      x86, dumpstack: Fix code bytes breakage due to missing KERN_CONT
      IB/qib: Correct sense on freectxts increment and decrement
      RDMA/cma: Verify private data length
      cgroups: fix a css_set not found bug in cgroup_attach_proc
      oprofile: Fix uninitialized memory access when writing to writing to oprofilefs
      Revert "xen/pv-on-hvm kexec: add xs_reset_watches to shutdown watches from old kernel"
      ...
    
    Conflicts:
            kernel/cgroup_freezer.c

commit 21adbd5cbb5344a3fca6bb7ddb2ab6cb03c44546
Author: Stefan Behrens <sbehrens@giantdisaster.de>
Date:   Wed Nov 9 13:44:05 2011 +0100

    Btrfs: integrate integrity check module into btrfs
    
    This is the last part of the patch series. It modifies the btrfs
    code to use the integrity check module if configured to do so
    with the define BTRFS_FS_CHECK_INTEGRITY. If this define is not set,
    the only effective change is that code is added that handles the
    mount option to activate the integrity check. If the mount option is
    set and the define BTRFS_FS_CHECK_INTEGRITY is not set, that code
    complains in the log and the mount fails with EINVAL.
    
    Add the mount option to activate the usage of the integrity check
    code.
    Add invocation of btrfs integrity check code init and cleanup
    function on mount and umount, respectively.
    Add hook to call btrfs integrity check code version of
    submit_bh/submit_bio.
    
    Signed-off-by: Stefan Behrens <sbehrens@giantdisaster.de>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3f9d5551e582..f363c6d9c3de 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -43,6 +43,7 @@
 #include "tree-log.h"
 #include "free-space-cache.h"
 #include "inode-map.h"
+#include "check-integrity.h"
 
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
@@ -2001,6 +2002,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->scrub_pause_wait);
 	init_rwsem(&fs_info->scrub_super_lock);
 	fs_info->scrub_workers_refcnt = 0;
+#ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
+	fs_info->check_integrity_print_mask = 0;
+#endif
 
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
@@ -2356,6 +2360,19 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		btrfs_set_opt(fs_info->mount_opt, SSD);
 	}
 
+#ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
+	if (btrfs_test_opt(tree_root, CHECK_INTEGRITY)) {
+		ret = btrfsic_mount(tree_root, fs_devices,
+				    btrfs_test_opt(tree_root,
+					CHECK_INTEGRITY_INCLUDING_EXTENT_DATA) ?
+				    1 : 0,
+				    fs_info->check_integrity_print_mask);
+		if (ret)
+			printk(KERN_WARNING "btrfs: failed to initialize"
+			       " integrity check module %s\n", sb->s_id);
+	}
+#endif
+
 	/* do not make disk changes in broken FS */
 	if (btrfs_super_log_root(disk_super) != 0 &&
 	    !(fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR)) {
@@ -2634,7 +2651,7 @@ static int write_dev_supers(struct btrfs_device *device,
 		 * we fua the first super.  The others we allow
 		 * to go down lazy.
 		 */
-		ret = submit_bh(WRITE_FUA, bh);
+		ret = btrfsic_submit_bh(WRITE_FUA, bh);
 		if (ret)
 			errors++;
 	}
@@ -2711,7 +2728,7 @@ static int write_dev_flush(struct btrfs_device *device, int wait)
 	device->flush_bio = bio;
 
 	bio_get(bio);
-	submit_bio(WRITE_FLUSH, bio);
+	btrfsic_submit_bio(WRITE_FLUSH, bio);
 
 	return 0;
 }
@@ -3057,6 +3074,11 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->caching_workers);
 	btrfs_stop_workers(&fs_info->readahead_workers);
 
+#ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY
+	if (btrfs_test_opt(root, CHECK_INTEGRITY))
+		btrfsic_unmount(root, fs_info->fs_devices);
+#endif
+
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 

commit c9a7fe9672612c0b595633d2945f52257ad92b20
Merge: 2cfab8d74ebf d85c8a6f1bc0 142349f541d0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 16 12:15:50 2011 -0800

    Merge branches 'for-linus' and 'for-linus-3.2' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: unplug every once and a while
      Btrfs: deal with NULL srv_rsv in the delalloc inode reservation code
      Btrfs: only set cache_generation if we setup the block group
      Btrfs: don't panic if orphan item already exists
      Btrfs: fix leaked space in truncate
      Btrfs: fix how we do delalloc reservations and how we free reservations on error
      Btrfs: deal with enospc from dirtying inodes properly
      Btrfs: fix num_workers_starting bug and other bugs in async thread
      BTRFS: Establish i_ops before calling d_instantiate
      Btrfs: add a cond_resched() into the worker loop
      Btrfs: fix ctime update of on-disk inode
      btrfs: keep orphans for subvolume deletion
      Btrfs: fix inaccurate available space on raid0 profile
      Btrfs: fix wrong disk space information of the files
      Btrfs: fix wrong i_size when truncating a file to a larger size
      Btrfs: fix btrfs_end_bio to deal with write errors to a single mirror
    
    * 'for-linus-3.2' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      btrfs: lower the dirty balance poll interval

commit 0dc3b84a73267f47a75468f924f5d58a840e3152
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Nov 18 14:37:27 2011 -0500

    Btrfs: fix num_workers_starting bug and other bugs in async thread
    
    Al pointed out we have some random problems with the way we account for
    num_workers_starting in the async thread stuff.  First of all we need to make
    sure to decrement num_workers_starting if we fail to start the worker, so make
    __btrfs_start_workers do this.  Also fix __btrfs_start_workers so that it
    doesn't call btrfs_stop_workers(), there is no point in stopping everybody if we
    failed to create a worker.  Also check_pending_worker_creates needs to call
    __btrfs_start_work in it's work function since it already increments
    num_workers_starting.
    
    People only start one worker at a time, so get rid of the num_workers argument
    everywhere, and make btrfs_queue_worker a void since it will always succeed.
    Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 94abc25392f6..3f9d5551e582 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2194,19 +2194,27 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->endio_meta_write_workers.idle_thresh = 2;
 	fs_info->readahead_workers.idle_thresh = 2;
 
-	btrfs_start_workers(&fs_info->workers, 1);
-	btrfs_start_workers(&fs_info->generic_worker, 1);
-	btrfs_start_workers(&fs_info->submit_workers, 1);
-	btrfs_start_workers(&fs_info->delalloc_workers, 1);
-	btrfs_start_workers(&fs_info->fixup_workers, 1);
-	btrfs_start_workers(&fs_info->endio_workers, 1);
-	btrfs_start_workers(&fs_info->endio_meta_workers, 1);
-	btrfs_start_workers(&fs_info->endio_meta_write_workers, 1);
-	btrfs_start_workers(&fs_info->endio_write_workers, 1);
-	btrfs_start_workers(&fs_info->endio_freespace_worker, 1);
-	btrfs_start_workers(&fs_info->delayed_workers, 1);
-	btrfs_start_workers(&fs_info->caching_workers, 1);
-	btrfs_start_workers(&fs_info->readahead_workers, 1);
+	/*
+	 * btrfs_start_workers can really only fail because of ENOMEM so just
+	 * return -ENOMEM if any of these fail.
+	 */
+	ret = btrfs_start_workers(&fs_info->workers);
+	ret |= btrfs_start_workers(&fs_info->generic_worker);
+	ret |= btrfs_start_workers(&fs_info->submit_workers);
+	ret |= btrfs_start_workers(&fs_info->delalloc_workers);
+	ret |= btrfs_start_workers(&fs_info->fixup_workers);
+	ret |= btrfs_start_workers(&fs_info->endio_workers);
+	ret |= btrfs_start_workers(&fs_info->endio_meta_workers);
+	ret |= btrfs_start_workers(&fs_info->endio_meta_write_workers);
+	ret |= btrfs_start_workers(&fs_info->endio_write_workers);
+	ret |= btrfs_start_workers(&fs_info->endio_freespace_worker);
+	ret |= btrfs_start_workers(&fs_info->delayed_workers);
+	ret |= btrfs_start_workers(&fs_info->caching_workers);
+	ret |= btrfs_start_workers(&fs_info->readahead_workers);
+	if (ret) {
+		ret = -ENOMEM;
+		goto fail_sb_buffer;
+	}
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,

commit 986b11c3ee9e0eace25fe74a502205f7fe8c179b
Merge: bb58dd5d1ffa 24b7ead3fb0b
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Nov 23 21:09:02 2011 +0100

    Merge branch 'pm-freezer' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/misc into pm-freezer
    
    * 'pm-freezer' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/misc: (24 commits)
      freezer: fix wait_event_freezable/__thaw_task races
      freezer: kill unused set_freezable_with_signal()
      dmatest: don't use set_freezable_with_signal()
      usb_storage: don't use set_freezable_with_signal()
      freezer: remove unused @sig_only from freeze_task()
      freezer: use lock_task_sighand() in fake_signal_wake_up()
      freezer: restructure __refrigerator()
      freezer: fix set_freezable[_with_signal]() race
      freezer: remove should_send_signal() and update frozen()
      freezer: remove now unused TIF_FREEZE
      freezer: make freezing() test freeze conditions in effect instead of TIF_FREEZE
      cgroup_freezer: prepare for removal of TIF_FREEZE
      freezer: clean up freeze_processes() failure path
      freezer: kill PF_FREEZING
      freezer: test freezable conditions while holding freezer_lock
      freezer: make freezing indicate freeze condition in effect
      freezer: use dedicated lock instead of task_lock() + memory barrier
      freezer: don't distinguish nosig tasks on thaw
      freezer: remove racy clear_freeze_flag() and set PF_NOFREEZE on dead tasks
      freezer: rename thaw_process() to __thaw_task() and simplify the implementation
      ...

commit af36d15f58a3560617f1497ae011c3192049e40e
Merge: 8ba8ed54de4d 24a70313969f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 22 08:53:40 2011 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      Btrfs: remove free-space-cache.c WARN during log replay
      Btrfs: sectorsize align offsets in fiemap
      Btrfs: clear pages dirty for io and set them extent mapped
      Btrfs: wait on caching if we're loading the free space cache
      Btrfs: prefix resize related printks with btrfs:
      btrfs: fix stat blocks accounting
      Btrfs: avoid unnecessary bitmap search for cluster setup
      Btrfs: fix to search one more bitmap for cluster setup
      btrfs: mirror_num should be int, not u64
      btrfs: Fix up 32/64-bit compatibility for new ioctls
      Btrfs: fix barrier flushes
      Btrfs: fix tree corruption after multi-thread snapshots and inode_cache flush

commit a0acae0e886d44bd5ce6d2f173c1ace0fcf0d9f6
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 21 12:32:22 2011 -0800

    freezer: unexport refrigerator() and update try_to_freeze() slightly
    
    There is no reason to export two functions for entering the
    refrigerator.  Calling refrigerator() instead of try_to_freeze()
    doesn't save anything noticeable or removes any race condition.
    
    * Rename refrigerator() to __refrigerator() and make it return bool
      indicating whether it scheduled out for freezing.
    
    * Update try_to_freeze() to return bool and relay the return value of
      __refrigerator() if freezing().
    
    * Convert all refrigerator() users to try_to_freeze().
    
    * Update documentation accordingly.
    
    * While at it, add might_sleep() to try_to_freeze().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Samuel Ortiz <samuel@sortiz.org>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Jan Kara <jack@suse.cz>
    Cc: KONISHI Ryusuke <konishi.ryusuke@lab.ntt.co.jp>
    Cc: Christoph Hellwig <hch@infradead.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 62afe5c5694e..622654fe051f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1579,9 +1579,7 @@ static int cleaner_kthread(void *arg)
 			btrfs_run_defrag_inodes(root->fs_info);
 		}
 
-		if (freezing(current)) {
-			refrigerator();
-		} else {
+		if (!try_to_freeze()) {
 			set_current_state(TASK_INTERRUPTIBLE);
 			if (!kthread_should_stop())
 				schedule();
@@ -1635,9 +1633,7 @@ static int transaction_kthread(void *arg)
 		wake_up_process(root->fs_info->cleaner_kthread);
 		mutex_unlock(&root->fs_info->transaction_kthread_mutex);
 
-		if (freezing(current)) {
-			refrigerator();
-		} else {
+		if (!try_to_freeze()) {
 			set_current_state(TASK_INTERRUPTIBLE);
 			if (!kthread_should_stop() &&
 			    !btrfs_transaction_blocked(root->fs_info))

commit 32240a913d9f3a5aad42175d7696590ea1bfdb08
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Sun Nov 20 07:33:38 2011 -0500

    btrfs: mirror_num should be int, not u64
    
    My previous patch introduced some u64 for failed_mirror variables, this one
    makes it consistent again.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 48d30138237f..94abc25392f6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -620,7 +620,7 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 
 static int btree_io_failed_hook(struct bio *failed_bio,
 			 struct page *page, u64 start, u64 end,
-			 u64 mirror_num, struct extent_state *state)
+			 int mirror_num, struct extent_state *state)
 {
 	struct extent_io_tree *tree;
 	unsigned long len;

commit 387125fc722a8ed432066b85a552917343bdafca
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Nov 18 15:07:51 2011 -0500

    Btrfs: fix barrier flushes
    
    When btrfs is writing the super blocks, it send barrier flushes to make
    sure writeback caching drives get all the metadata on disk in the
    right order.
    
    But, we have two bugs in the way these are sent down.  When doing
    full commits (not via the tree log), we are sending the barrier down
    before the last super when it should be going down before the first.
    
    In multi-device setups, we should be waiting for the barriers to
    complete on all devices before writing any of the supers.
    
    Both of these bugs can cause corruptions on power failures.  We fix it
    with some new code to send down empty barriers to all devices before
    writing the first super.
    
    Alexandre Oliva found the multi-device bug.  Arne Jansen did the async
    barrier loop.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>
    Reported-by: Alexandre Oliva <oliva@lsd.ic.unicamp.br>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b6a5c0dd0dd8..48d30138237f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2573,22 +2573,10 @@ static int write_dev_supers(struct btrfs_device *device,
 	int errors = 0;
 	u32 crc;
 	u64 bytenr;
-	int last_barrier = 0;
 
 	if (max_mirrors == 0)
 		max_mirrors = BTRFS_SUPER_MIRROR_MAX;
 
-	/* make sure only the last submit_bh does a barrier */
-	if (do_barriers) {
-		for (i = 0; i < max_mirrors; i++) {
-			bytenr = btrfs_sb_offset(i);
-			if (bytenr + BTRFS_SUPER_INFO_SIZE >=
-			    device->total_bytes)
-				break;
-			last_barrier = i;
-		}
-	}
-
 	for (i = 0; i < max_mirrors; i++) {
 		bytenr = btrfs_sb_offset(i);
 		if (bytenr + BTRFS_SUPER_INFO_SIZE >= device->total_bytes)
@@ -2634,17 +2622,136 @@ static int write_dev_supers(struct btrfs_device *device,
 			bh->b_end_io = btrfs_end_buffer_write_sync;
 		}
 
-		if (i == last_barrier && do_barriers)
-			ret = submit_bh(WRITE_FLUSH_FUA, bh);
-		else
-			ret = submit_bh(WRITE_SYNC, bh);
-
+		/*
+		 * we fua the first super.  The others we allow
+		 * to go down lazy.
+		 */
+		ret = submit_bh(WRITE_FUA, bh);
 		if (ret)
 			errors++;
 	}
 	return errors < i ? 0 : -1;
 }
 
+/*
+ * endio for the write_dev_flush, this will wake anyone waiting
+ * for the barrier when it is done
+ */
+static void btrfs_end_empty_barrier(struct bio *bio, int err)
+{
+	if (err) {
+		if (err == -EOPNOTSUPP)
+			set_bit(BIO_EOPNOTSUPP, &bio->bi_flags);
+		clear_bit(BIO_UPTODATE, &bio->bi_flags);
+	}
+	if (bio->bi_private)
+		complete(bio->bi_private);
+	bio_put(bio);
+}
+
+/*
+ * trigger flushes for one the devices.  If you pass wait == 0, the flushes are
+ * sent down.  With wait == 1, it waits for the previous flush.
+ *
+ * any device where the flush fails with eopnotsupp are flagged as not-barrier
+ * capable
+ */
+static int write_dev_flush(struct btrfs_device *device, int wait)
+{
+	struct bio *bio;
+	int ret = 0;
+
+	if (device->nobarriers)
+		return 0;
+
+	if (wait) {
+		bio = device->flush_bio;
+		if (!bio)
+			return 0;
+
+		wait_for_completion(&device->flush_wait);
+
+		if (bio_flagged(bio, BIO_EOPNOTSUPP)) {
+			printk("btrfs: disabling barriers on dev %s\n",
+			       device->name);
+			device->nobarriers = 1;
+		}
+		if (!bio_flagged(bio, BIO_UPTODATE)) {
+			ret = -EIO;
+		}
+
+		/* drop the reference from the wait == 0 run */
+		bio_put(bio);
+		device->flush_bio = NULL;
+
+		return ret;
+	}
+
+	/*
+	 * one reference for us, and we leave it for the
+	 * caller
+	 */
+	device->flush_bio = NULL;;
+	bio = bio_alloc(GFP_NOFS, 0);
+	if (!bio)
+		return -ENOMEM;
+
+	bio->bi_end_io = btrfs_end_empty_barrier;
+	bio->bi_bdev = device->bdev;
+	init_completion(&device->flush_wait);
+	bio->bi_private = &device->flush_wait;
+	device->flush_bio = bio;
+
+	bio_get(bio);
+	submit_bio(WRITE_FLUSH, bio);
+
+	return 0;
+}
+
+/*
+ * send an empty flush down to each device in parallel,
+ * then wait for them
+ */
+static int barrier_all_devices(struct btrfs_fs_info *info)
+{
+	struct list_head *head;
+	struct btrfs_device *dev;
+	int errors = 0;
+	int ret;
+
+	/* send down all the barriers */
+	head = &info->fs_devices->devices;
+	list_for_each_entry_rcu(dev, head, dev_list) {
+		if (!dev->bdev) {
+			errors++;
+			continue;
+		}
+		if (!dev->in_fs_metadata || !dev->writeable)
+			continue;
+
+		ret = write_dev_flush(dev, 0);
+		if (ret)
+			errors++;
+	}
+
+	/* wait for all the barriers */
+	list_for_each_entry_rcu(dev, head, dev_list) {
+		if (!dev->bdev) {
+			errors++;
+			continue;
+		}
+		if (!dev->in_fs_metadata || !dev->writeable)
+			continue;
+
+		ret = write_dev_flush(dev, 1);
+		if (ret)
+			errors++;
+	}
+	if (errors)
+		return -EIO;
+	return 0;
+}
+
 int write_all_supers(struct btrfs_root *root, int max_mirrors)
 {
 	struct list_head *head;
@@ -2666,6 +2773,10 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 
 	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
 	head = &root->fs_info->fs_devices->devices;
+
+	if (do_barriers)
+		barrier_all_devices(root->fs_info);
+
 	list_for_each_entry_rcu(dev, head, dev_list) {
 		if (!dev->bdev) {
 			total_errors++;

commit c1f4246716392ec8693c23cffb969bd73c1b0910
Merge: fe10e6f4b24e 8965593e41dd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 11 23:47:06 2011 -0200

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs:
      btrfs: rename the option to nospace_cache
      Btrfs: handle bio_add_page failure gracefully in scrub
      Btrfs: fix deadlock caused by the race between relocation
      Btrfs: only map pages if we know we need them when reading the space cache
      Btrfs: fix orphan backref nodes
      Btrfs: Abstract similar code for btrfs_block_rsv_add{, _noflush}
      Btrfs: fix unreleased path in btrfs_orphan_cleanup()
      Btrfs: fix no reserved space for writing out inode cache
      Btrfs: fix nocow when deleting the item
      Btrfs: tweak the delayed inode reservations again
      Btrfs: rework error handling in btrfs_mount()
      Btrfs: close devices on all error paths in open_ctree()
      Btrfs: avoid null dereference and leaks when bailing from open_ctree()
      Btrfs: fix subvol_name leak on error in btrfs_mount()
      Btrfs: fix memory leak in btrfs_parse_early_options()
      Btrfs: fix our reservations for updating an inode when completing io
      Btrfs: fix oops on NULL trans handle in btrfs_truncate
      btrfs: fix double-free 'tree_root' in 'btrfs_mount()'

commit 586e46e2813c589d26258a599580421fb6fb576b
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Wed Nov 9 13:26:37 2011 +0200

    Btrfs: close devices on all error paths in open_ctree()
    
    Fix a bug introduced by 7e662854 where we would leave devices busy on
    certain error paths in open_ctree().  fs_info is guaranteed to be
    non-NULL now so it's safe to dereference it on all error paths.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 91db90b526c2..b6a5c0dd0dd8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2460,21 +2460,20 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->caching_workers);
 fail_alloc:
 fail_iput:
+	btrfs_mapping_tree_free(&fs_info->mapping_tree);
+
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
-
-	btrfs_close_devices(fs_info->fs_devices);
-	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 fail_bdi:
 	bdi_destroy(&fs_info->bdi);
 fail_srcu:
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 fail:
+	btrfs_close_devices(fs_info->fs_devices);
 	free_fs_info(fs_info);
 	return ERR_PTR(err);
 
 recovery_tree_root:
-
 	if (!btrfs_test_opt(tree_root, RECOVERY))
 		goto fail_tree_roots;
 

commit 4d34b2789538befa45a68a191dc12e0886a69f7d
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Wed Nov 9 00:08:15 2011 +0200

    Btrfs: avoid null dereference and leaks when bailing from open_ctree()
    
    Fix bugs introduced by 6c41761f.  Firstly, after failing to allocate any
    of the tree roots (first 'goto fail' in open_ctree()) we would
    dereference a NULL fs_info pointer in free_fs_info().  Secondly, after
    failures from init_srcu_struct(), setup_bdi() and new_inode() we would
    leak all earlier allocated roots: fs_info fields haven't been
    initialized yet so free_fs_info() is rendered useless.
    
    Fix this by initializing fs_info pointer and fs_info fields before any
    allocations happen.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e53a5bb85670..91db90b526c2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1890,31 +1890,32 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	u64 features;
 	struct btrfs_key location;
 	struct buffer_head *bh;
-	struct btrfs_root *extent_root = kzalloc(sizeof(struct btrfs_root),
-						 GFP_NOFS);
-	struct btrfs_root *csum_root = kzalloc(sizeof(struct btrfs_root),
-						 GFP_NOFS);
+	struct btrfs_super_block *disk_super;
 	struct btrfs_root *tree_root = btrfs_sb(sb);
-	struct btrfs_fs_info *fs_info = NULL;
-	struct btrfs_root *chunk_root = kzalloc(sizeof(struct btrfs_root),
-						GFP_NOFS);
-	struct btrfs_root *dev_root = kzalloc(sizeof(struct btrfs_root),
-					      GFP_NOFS);
+	struct btrfs_fs_info *fs_info = tree_root->fs_info;
+	struct btrfs_root *extent_root;
+	struct btrfs_root *csum_root;
+	struct btrfs_root *chunk_root;
+	struct btrfs_root *dev_root;
 	struct btrfs_root *log_tree_root;
-
 	int ret;
 	int err = -EINVAL;
 	int num_backups_tried = 0;
 	int backup_index = 0;
 
-	struct btrfs_super_block *disk_super;
+	extent_root = fs_info->extent_root =
+		kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
+	csum_root = fs_info->csum_root =
+		kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
+	chunk_root = fs_info->chunk_root =
+		kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
+	dev_root = fs_info->dev_root =
+		kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
 
-	if (!extent_root || !tree_root || !tree_root->fs_info ||
-	    !chunk_root || !dev_root || !csum_root) {
+	if (!extent_root || !csum_root || !chunk_root || !dev_root) {
 		err = -ENOMEM;
 		goto fail;
 	}
-	fs_info = tree_root->fs_info;
 
 	ret = init_srcu_struct(&fs_info->subvol_srcu);
 	if (ret) {
@@ -1954,12 +1955,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->reloc_mutex);
 
 	init_completion(&fs_info->kobj_unregister);
-	fs_info->tree_root = tree_root;
-	fs_info->extent_root = extent_root;
-	fs_info->csum_root = csum_root;
-	fs_info->chunk_root = chunk_root;
-	fs_info->dev_root = dev_root;
-	fs_info->fs_devices = fs_devices;
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
 	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);

commit 6a6662ced4153f6dbcfc40d7225c3cc45416039c
Merge: 32aaeffbd4a7 7c7e82a77fe3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Nov 6 20:03:41 2011 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs: (114 commits)
      Btrfs: check for a null fs root when writing to the backup root log
      Btrfs: fix race during transaction joins
      Btrfs: fix a potential btrfs_bio leak on scrub fixups
      Btrfs: rename btrfs_bio multi -> bbio for consistency
      Btrfs: stop leaking btrfs_bios on readahead
      Btrfs: stop the readahead threads on failed mount
      Btrfs: fix extent_buffer leak in the metadata IO error handling
      Btrfs: fix the new inspection ioctls for 32 bit compat
      Btrfs: fix delayed insertion reservation
      Btrfs: ClearPageError during writepage and clean_tree_block
      Btrfs: be smarter about committing the transaction in reserve_metadata_bytes
      Btrfs: make a delayed_block_rsv for the delayed item insertion
      Btrfs: add a log of past tree roots
      btrfs: separate superblock items out of fs_info
      Btrfs: use the global reserve when truncating the free space cache inode
      Btrfs: release metadata from global reserve if we have to fallback for unlink
      Btrfs: make sure to flush queued bios if write_cache_pages waits
      Btrfs: fix extent pinning bugs in the tree log
      Btrfs: make sure btrfs_remove_free_space doesn't leak EAGAIN
      Btrfs: don't wait as long for more batches during SSD log commit
      ...

commit 7c7e82a77fe3d89ae50824aa7c897454675eb4c4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Nov 6 18:50:56 2011 -0500

    Btrfs: check for a null fs root when writing to the backup root log
    
    During log replay, can commit the transaction before the fs_root
    pointers are setup, so we have to make sure they are not null before
    trying to use them.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e532892431f4..e53a5bb85670 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1754,11 +1754,18 @@ static void backup_super_roots(struct btrfs_fs_info *info)
 	btrfs_set_backup_extent_root_level(root_backup,
 			       btrfs_header_level(info->extent_root->node));
 
-	btrfs_set_backup_fs_root(root_backup, info->fs_root->node->start);
-	btrfs_set_backup_fs_root_gen(root_backup,
+	/*
+	 * we might commit during log recovery, which happens before we set
+	 * the fs_root.  Make sure it is valid before we fill it in.
+	 */
+	if (info->fs_root && info->fs_root->node) {
+		btrfs_set_backup_fs_root(root_backup,
+					 info->fs_root->node->start);
+		btrfs_set_backup_fs_root_gen(root_backup,
 			       btrfs_header_generation(info->fs_root->node));
-	btrfs_set_backup_fs_root_level(root_backup,
+		btrfs_set_backup_fs_root_level(root_backup,
 			       btrfs_header_level(info->fs_root->node));
+	}
 
 	btrfs_set_backup_dev_root(root_backup, info->dev_root->node->start);
 	btrfs_set_backup_dev_root_gen(root_backup,

commit 306c8b68c82dfe6b7c9e5b61985760ad5d089205
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 3 15:21:39 2011 -0400

    Btrfs: stop the readahead threads on failed mount
    
    If we don't stop them, they linger around corrupting
    memory by using pointers to freed things.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 40a62b980087..e532892431f4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2444,6 +2444,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 fail_sb_buffer:
 	btrfs_stop_workers(&fs_info->generic_worker);
+	btrfs_stop_workers(&fs_info->readahead_workers);
 	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->delalloc_workers);
 	btrfs_stop_workers(&fs_info->workers);

commit c674e04e1cd6049715e7b9446790f4b441e547c0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 3 22:23:13 2011 -0400

    Btrfs: fix extent_buffer leak in the metadata IO error handling
    
    The scrub readahead branch brought in a new error handling hook,
    but it was leaking extent_buffer references.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0eb1f0951251..40a62b980087 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -644,6 +644,7 @@ static int btree_io_failed_hook(struct bio *failed_bio,
 		clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags);
 		btree_readahead_hook(root, eb, eb->start, -EIO);
 	}
+	free_extent_buffer(eb);
 
 out:
 	return -EIO;	/* we fixed nothing */

commit 806468f8bf76a3cb2b626dd282946a6c9c0a50f0
Merge: 531f4b1ae5e0 5da6fcbc4eb5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Nov 6 03:07:10 2011 -0500

    Merge git://git.jan-o-sch.net/btrfs-unstable into integration
    
    Conflicts:
            fs/btrfs/Makefile
            fs/btrfs/extent_io.c
            fs/btrfs/extent_io.h
            fs/btrfs/scrub.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 531f4b1ae5e0fc8c9b3f03838218e5ea178f80d3
Merge: c06a0e120a4e 7a26285eea8e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Nov 6 03:05:08 2011 -0500

    Merge branch 'for-chris' of git://github.com/sensille/linux into integration
    
    Conflicts:
            fs/btrfs/ctree.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 6d668dda0caec537fbf28c4d91e6d18181af3cff
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Nov 3 22:54:25 2011 -0400

    Btrfs: make a delayed_block_rsv for the delayed item insertion
    
    I've been hitting warnings in use_block_rsv when running the delayed insertion
    stuff.  It's because we will readjust global block rsv based on what is in use,
    which means we could end up discarding reservations that are for the delayed
    insertion stuff.  So instead create a seperate block rsv for the delayed
    insertion stuff.  This will also make it easier to debug problems with the
    delayed insertion reservations since we will know that only the delayed
    insertion code touches this block_rsv.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a61f8a6cf219..23b6776477b7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1891,6 +1891,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_init_block_rsv(&fs_info->trans_block_rsv);
 	btrfs_init_block_rsv(&fs_info->chunk_block_rsv);
 	btrfs_init_block_rsv(&fs_info->empty_block_rsv);
+	btrfs_init_block_rsv(&fs_info->delayed_block_rsv);
 	atomic_set(&fs_info->nr_async_submits, 0);
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);

commit af31f5e5b84b5bf2bcec464153a5130b170b2770
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 3 15:17:42 2011 -0400

    Btrfs: add a log of past tree roots
    
    This takes some of the free space in the btrfs super block
    to record information about most of the roots in the last four
    commits.
    
    It also adds a -o recovery to use the root history log when
    we're not able to read the tree of tree roots, the extent
    tree root, the device tree root or the csum root.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 761717c98278..a61f8a6cf219 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1134,10 +1134,12 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 
 	generation = btrfs_root_generation(&root->root_item);
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
+	root->commit_root = NULL;
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
 	if (!root->node || !btrfs_buffer_uptodate(root->node, generation)) {
 		free_extent_buffer(root->node);
+		root->node = NULL;
 		return -EIO;
 	}
 	root->commit_root = btrfs_root_node(root);
@@ -1576,6 +1578,228 @@ static int transaction_kthread(void *arg)
 	return 0;
 }
 
+/*
+ * this will find the highest generation in the array of
+ * root backups.  The index of the highest array is returned,
+ * or -1 if we can't find anything.
+ *
+ * We check to make sure the array is valid by comparing the
+ * generation of the latest  root in the array with the generation
+ * in the super block.  If they don't match we pitch it.
+ */
+static int find_newest_super_backup(struct btrfs_fs_info *info, u64 newest_gen)
+{
+	u64 cur;
+	int newest_index = -1;
+	struct btrfs_root_backup *root_backup;
+	int i;
+
+	for (i = 0; i < BTRFS_NUM_BACKUP_ROOTS; i++) {
+		root_backup = info->super_copy->super_roots + i;
+		cur = btrfs_backup_tree_root_gen(root_backup);
+		if (cur == newest_gen)
+			newest_index = i;
+	}
+
+	/* check to see if we actually wrapped around */
+	if (newest_index == BTRFS_NUM_BACKUP_ROOTS - 1) {
+		root_backup = info->super_copy->super_roots;
+		cur = btrfs_backup_tree_root_gen(root_backup);
+		if (cur == newest_gen)
+			newest_index = 0;
+	}
+	return newest_index;
+}
+
+
+/*
+ * find the oldest backup so we know where to store new entries
+ * in the backup array.  This will set the backup_root_index
+ * field in the fs_info struct
+ */
+static void find_oldest_super_backup(struct btrfs_fs_info *info,
+				     u64 newest_gen)
+{
+	int newest_index = -1;
+
+	newest_index = find_newest_super_backup(info, newest_gen);
+	/* if there was garbage in there, just move along */
+	if (newest_index == -1) {
+		info->backup_root_index = 0;
+	} else {
+		info->backup_root_index = (newest_index + 1) % BTRFS_NUM_BACKUP_ROOTS;
+	}
+}
+
+/*
+ * copy all the root pointers into the super backup array.
+ * this will bump the backup pointer by one when it is
+ * done
+ */
+static void backup_super_roots(struct btrfs_fs_info *info)
+{
+	int next_backup;
+	struct btrfs_root_backup *root_backup;
+	int last_backup;
+
+	next_backup = info->backup_root_index;
+	last_backup = (next_backup + BTRFS_NUM_BACKUP_ROOTS - 1) %
+		BTRFS_NUM_BACKUP_ROOTS;
+
+	/*
+	 * just overwrite the last backup if we're at the same generation
+	 * this happens only at umount
+	 */
+	root_backup = info->super_for_commit->super_roots + last_backup;
+	if (btrfs_backup_tree_root_gen(root_backup) ==
+	    btrfs_header_generation(info->tree_root->node))
+		next_backup = last_backup;
+
+	root_backup = info->super_for_commit->super_roots + next_backup;
+
+	/*
+	 * make sure all of our padding and empty slots get zero filled
+	 * regardless of which ones we use today
+	 */
+	memset(root_backup, 0, sizeof(*root_backup));
+
+	info->backup_root_index = (next_backup + 1) % BTRFS_NUM_BACKUP_ROOTS;
+
+	btrfs_set_backup_tree_root(root_backup, info->tree_root->node->start);
+	btrfs_set_backup_tree_root_gen(root_backup,
+			       btrfs_header_generation(info->tree_root->node));
+
+	btrfs_set_backup_tree_root_level(root_backup,
+			       btrfs_header_level(info->tree_root->node));
+
+	btrfs_set_backup_chunk_root(root_backup, info->chunk_root->node->start);
+	btrfs_set_backup_chunk_root_gen(root_backup,
+			       btrfs_header_generation(info->chunk_root->node));
+	btrfs_set_backup_chunk_root_level(root_backup,
+			       btrfs_header_level(info->chunk_root->node));
+
+	btrfs_set_backup_extent_root(root_backup, info->extent_root->node->start);
+	btrfs_set_backup_extent_root_gen(root_backup,
+			       btrfs_header_generation(info->extent_root->node));
+	btrfs_set_backup_extent_root_level(root_backup,
+			       btrfs_header_level(info->extent_root->node));
+
+	btrfs_set_backup_fs_root(root_backup, info->fs_root->node->start);
+	btrfs_set_backup_fs_root_gen(root_backup,
+			       btrfs_header_generation(info->fs_root->node));
+	btrfs_set_backup_fs_root_level(root_backup,
+			       btrfs_header_level(info->fs_root->node));
+
+	btrfs_set_backup_dev_root(root_backup, info->dev_root->node->start);
+	btrfs_set_backup_dev_root_gen(root_backup,
+			       btrfs_header_generation(info->dev_root->node));
+	btrfs_set_backup_dev_root_level(root_backup,
+				       btrfs_header_level(info->dev_root->node));
+
+	btrfs_set_backup_csum_root(root_backup, info->csum_root->node->start);
+	btrfs_set_backup_csum_root_gen(root_backup,
+			       btrfs_header_generation(info->csum_root->node));
+	btrfs_set_backup_csum_root_level(root_backup,
+			       btrfs_header_level(info->csum_root->node));
+
+	btrfs_set_backup_total_bytes(root_backup,
+			     btrfs_super_total_bytes(info->super_copy));
+	btrfs_set_backup_bytes_used(root_backup,
+			     btrfs_super_bytes_used(info->super_copy));
+	btrfs_set_backup_num_devices(root_backup,
+			     btrfs_super_num_devices(info->super_copy));
+
+	/*
+	 * if we don't copy this out to the super_copy, it won't get remembered
+	 * for the next commit
+	 */
+	memcpy(&info->super_copy->super_roots,
+	       &info->super_for_commit->super_roots,
+	       sizeof(*root_backup) * BTRFS_NUM_BACKUP_ROOTS);
+}
+
+/*
+ * this copies info out of the root backup array and back into
+ * the in-memory super block.  It is meant to help iterate through
+ * the array, so you send it the number of backups you've already
+ * tried and the last backup index you used.
+ *
+ * this returns -1 when it has tried all the backups
+ */
+static noinline int next_root_backup(struct btrfs_fs_info *info,
+				     struct btrfs_super_block *super,
+				     int *num_backups_tried, int *backup_index)
+{
+	struct btrfs_root_backup *root_backup;
+	int newest = *backup_index;
+
+	if (*num_backups_tried == 0) {
+		u64 gen = btrfs_super_generation(super);
+
+		newest = find_newest_super_backup(info, gen);
+		if (newest == -1)
+			return -1;
+
+		*backup_index = newest;
+		*num_backups_tried = 1;
+	} else if (*num_backups_tried == BTRFS_NUM_BACKUP_ROOTS) {
+		/* we've tried all the backups, all done */
+		return -1;
+	} else {
+		/* jump to the next oldest backup */
+		newest = (*backup_index + BTRFS_NUM_BACKUP_ROOTS - 1) %
+			BTRFS_NUM_BACKUP_ROOTS;
+		*backup_index = newest;
+		*num_backups_tried += 1;
+	}
+	root_backup = super->super_roots + newest;
+
+	btrfs_set_super_generation(super,
+				   btrfs_backup_tree_root_gen(root_backup));
+	btrfs_set_super_root(super, btrfs_backup_tree_root(root_backup));
+	btrfs_set_super_root_level(super,
+				   btrfs_backup_tree_root_level(root_backup));
+	btrfs_set_super_bytes_used(super, btrfs_backup_bytes_used(root_backup));
+
+	/*
+	 * fixme: the total bytes and num_devices need to match or we should
+	 * need a fsck
+	 */
+	btrfs_set_super_total_bytes(super, btrfs_backup_total_bytes(root_backup));
+	btrfs_set_super_num_devices(super, btrfs_backup_num_devices(root_backup));
+	return 0;
+}
+
+/* helper to cleanup tree roots */
+static void free_root_pointers(struct btrfs_fs_info *info, int chunk_root)
+{
+	free_extent_buffer(info->tree_root->node);
+	free_extent_buffer(info->tree_root->commit_root);
+	free_extent_buffer(info->dev_root->node);
+	free_extent_buffer(info->dev_root->commit_root);
+	free_extent_buffer(info->extent_root->node);
+	free_extent_buffer(info->extent_root->commit_root);
+	free_extent_buffer(info->csum_root->node);
+	free_extent_buffer(info->csum_root->commit_root);
+
+	info->tree_root->node = NULL;
+	info->tree_root->commit_root = NULL;
+	info->dev_root->node = NULL;
+	info->dev_root->commit_root = NULL;
+	info->extent_root->node = NULL;
+	info->extent_root->commit_root = NULL;
+	info->csum_root->node = NULL;
+	info->csum_root->commit_root = NULL;
+
+	if (chunk_root) {
+		free_extent_buffer(info->chunk_root->node);
+		free_extent_buffer(info->chunk_root->commit_root);
+		info->chunk_root->node = NULL;
+		info->chunk_root->commit_root = NULL;
+	}
+}
+
+
 struct btrfs_root *open_ctree(struct super_block *sb,
 			      struct btrfs_fs_devices *fs_devices,
 			      char *options)
@@ -1603,6 +1827,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	int ret;
 	int err = -EINVAL;
+	int num_backups_tried = 0;
+	int backup_index = 0;
 
 	struct btrfs_super_block *disk_super;
 
@@ -1781,6 +2007,13 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
 
+	/*
+	 * run through our array of backup supers and setup
+	 * our ring pointer to the oldest one
+	 */
+	generation = btrfs_super_generation(disk_super);
+	find_oldest_super_backup(fs_info, generation);
+
 	/*
 	 * In the long term, we'll store the compression type in the super
 	 * block, and it'll be used for per file compression control.
@@ -1938,7 +2171,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!test_bit(EXTENT_BUFFER_UPTODATE, &chunk_root->node->bflags)) {
 		printk(KERN_WARNING "btrfs: failed to read chunk root on %s\n",
 		       sb->s_id);
-		goto fail_chunk_root;
+		goto fail_tree_roots;
 	}
 	btrfs_set_root_node(&chunk_root->root_item, chunk_root->node);
 	chunk_root->commit_root = btrfs_root_node(chunk_root);
@@ -1953,11 +2186,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (ret) {
 		printk(KERN_WARNING "btrfs: failed to read chunk tree on %s\n",
 		       sb->s_id);
-		goto fail_chunk_root;
+		goto fail_tree_roots;
 	}
 
 	btrfs_close_extra_devices(fs_devices);
 
+retry_root_backup:
 	blocksize = btrfs_level_size(tree_root,
 				     btrfs_super_root_level(disk_super));
 	generation = btrfs_super_generation(disk_super);
@@ -1965,32 +2199,33 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super),
 					  blocksize, generation);
-	if (!tree_root->node)
-		goto fail_chunk_root;
-	if (!test_bit(EXTENT_BUFFER_UPTODATE, &tree_root->node->bflags)) {
+	if (!tree_root->node ||
+	    !test_bit(EXTENT_BUFFER_UPTODATE, &tree_root->node->bflags)) {
 		printk(KERN_WARNING "btrfs: failed to read tree root on %s\n",
 		       sb->s_id);
-		goto fail_tree_root;
+
+		goto recovery_tree_root;
 	}
+
 	btrfs_set_root_node(&tree_root->root_item, tree_root->node);
 	tree_root->commit_root = btrfs_root_node(tree_root);
 
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
 	if (ret)
-		goto fail_tree_root;
+		goto recovery_tree_root;
 	extent_root->track_dirty = 1;
 
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_DEV_TREE_OBJECTID, dev_root);
 	if (ret)
-		goto fail_extent_root;
+		goto recovery_tree_root;
 	dev_root->track_dirty = 1;
 
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_CSUM_TREE_OBJECTID, csum_root);
 	if (ret)
-		goto fail_dev_root;
+		goto recovery_tree_root;
 
 	csum_root->track_dirty = 1;
 
@@ -2123,20 +2358,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 fail_block_groups:
 	btrfs_free_block_groups(fs_info);
-	free_extent_buffer(csum_root->node);
-	free_extent_buffer(csum_root->commit_root);
-fail_dev_root:
-	free_extent_buffer(dev_root->node);
-	free_extent_buffer(dev_root->commit_root);
-fail_extent_root:
-	free_extent_buffer(extent_root->node);
-	free_extent_buffer(extent_root->commit_root);
-fail_tree_root:
-	free_extent_buffer(tree_root->node);
-	free_extent_buffer(tree_root->commit_root);
-fail_chunk_root:
-	free_extent_buffer(chunk_root->node);
-	free_extent_buffer(chunk_root->commit_root);
+
+fail_tree_roots:
+	free_root_pointers(fs_info, 1);
+
 fail_sb_buffer:
 	btrfs_stop_workers(&fs_info->generic_worker);
 	btrfs_stop_workers(&fs_info->fixup_workers);
@@ -2164,6 +2389,25 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail:
 	free_fs_info(fs_info);
 	return ERR_PTR(err);
+
+recovery_tree_root:
+
+	if (!btrfs_test_opt(tree_root, RECOVERY))
+		goto fail_tree_roots;
+
+	free_root_pointers(fs_info, 0);
+
+	/* don't use the log in recovery mode, it won't be valid */
+	btrfs_set_super_log_root(disk_super, 0);
+
+	/* we can't trust the free space cache either */
+	btrfs_set_opt(fs_info->mount_opt, CLEAR_CACHE);
+
+	ret = next_root_backup(fs_info, fs_info->super_copy,
+			       &num_backups_tried, &backup_index);
+	if (ret == -1)
+		goto fail_block_groups;
+	goto retry_root_backup;
 }
 
 static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
@@ -2333,6 +2577,7 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 
 	max_errors = btrfs_super_num_devices(root->fs_info->super_copy) - 1;
 	do_barriers = !btrfs_test_opt(root, NOBARRIER);
+	backup_super_roots(root->fs_info);
 
 	sb = root->fs_info->super_for_commit;
 	dev_item = &sb->dev_item;

commit 6c41761fc6efe1503103a1afe03a6635c0b5d4ec
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Apr 13 15:41:04 2011 +0200

    btrfs: separate superblock items out of fs_info
    
    fs_info has now ~9kb, more than fits into one page. This will cause
    mount failure when memory is too fragmented. Top space consumers are
    super block structures super_copy and super_for_commit, ~2.8kb each.
    Allocate them dynamically. fs_info will be ~3.5kb. (measured on x86_64)
    
    Add a wrapper for freeing fs_info and all of it's dynamically allocated
    members.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6f58911ece0d..761717c98278 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -256,8 +256,7 @@ void btrfs_csum_final(u32 crc, char *result)
 static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			   int verify)
 {
-	u16 csum_size =
-		btrfs_super_csum_size(&root->fs_info->super_copy);
+	u16 csum_size = btrfs_super_csum_size(root->fs_info->super_copy);
 	char *result = NULL;
 	unsigned long len;
 	unsigned long cur_len;
@@ -1766,14 +1765,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_alloc;
 	}
 
-	memcpy(&fs_info->super_copy, bh->b_data, sizeof(fs_info->super_copy));
-	memcpy(&fs_info->super_for_commit, &fs_info->super_copy,
-	       sizeof(fs_info->super_for_commit));
+	memcpy(fs_info->super_copy, bh->b_data, sizeof(*fs_info->super_copy));
+	memcpy(fs_info->super_for_commit, fs_info->super_copy,
+	       sizeof(*fs_info->super_for_commit));
 	brelse(bh);
 
-	memcpy(fs_info->fsid, fs_info->super_copy.fsid, BTRFS_FSID_SIZE);
+	memcpy(fs_info->fsid, fs_info->super_copy->fsid, BTRFS_FSID_SIZE);
 
-	disk_super = &fs_info->super_copy;
+	disk_super = fs_info->super_copy;
 	if (!btrfs_super_root(disk_super))
 		goto fail_alloc;
 
@@ -2152,7 +2151,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->delayed_workers);
 	btrfs_stop_workers(&fs_info->caching_workers);
 fail_alloc:
-	kfree(fs_info->delayed_root);
 fail_iput:
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
@@ -2164,12 +2162,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail_srcu:
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 fail:
-	kfree(extent_root);
-	kfree(tree_root);
-	kfree(fs_info);
-	kfree(chunk_root);
-	kfree(dev_root);
-	kfree(csum_root);
+	free_fs_info(fs_info);
 	return ERR_PTR(err);
 }
 
@@ -2338,10 +2331,10 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	int total_errors = 0;
 	u64 flags;
 
-	max_errors = btrfs_super_num_devices(&root->fs_info->super_copy) - 1;
+	max_errors = btrfs_super_num_devices(root->fs_info->super_copy) - 1;
 	do_barriers = !btrfs_test_opt(root, NOBARRIER);
 
-	sb = &root->fs_info->super_for_commit;
+	sb = root->fs_info->super_for_commit;
 	dev_item = &sb->dev_item;
 
 	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
@@ -2603,7 +2596,6 @@ int close_ctree(struct btrfs_root *root)
 	del_fs_roots(fs_info);
 
 	iput(fs_info->btree_inode);
-	kfree(fs_info->delayed_root);
 
 	btrfs_stop_workers(&fs_info->generic_worker);
 	btrfs_stop_workers(&fs_info->fixup_workers);
@@ -2624,12 +2616,7 @@ int close_ctree(struct btrfs_root *root)
 	bdi_destroy(&fs_info->bdi);
 	cleanup_srcu_struct(&fs_info->subvol_srcu);
 
-	kfree(fs_info->extent_root);
-	kfree(fs_info->tree_root);
-	kfree(fs_info->chunk_root);
-	kfree(fs_info->dev_root);
-	kfree(fs_info->csum_root);
-	kfree(fs_info);
+	free_fs_info(fs_info);
 
 	return 0;
 }

commit 01d658f2ca3c85c1ffb20b306e30d16197000ce7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 1 10:08:06 2011 -0400

    Btrfs: make sure to flush queued bios if write_cache_pages waits
    
    write_cache_pages tries to build up a large bio to stuff down the pipe.
    But if it needs to wait for a page lock, it needs to make sure and send
    down any pending writes so we don't deadlock with anyone who has the
    page lock and is waiting for writeback of things inside the bio.
    
    Dave Sterba triggered this as a deadlock between the autodefrag code and
    the extent write_cache_pages
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 51372a521167..6f58911ece0d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2735,7 +2735,8 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 	return ret;
 }
 
-int btree_lock_page_hook(struct page *page)
+static int btree_lock_page_hook(struct page *page, void *data,
+				void (*flush_fn)(void *))
 {
 	struct inode *inode = page->mapping->host;
 	struct btrfs_root *root = BTRFS_I(inode)->root;
@@ -2752,7 +2753,10 @@ int btree_lock_page_hook(struct page *page)
 	if (!eb)
 		goto out;
 
-	btrfs_tree_lock(eb);
+	if (!btrfs_try_tree_write_lock(eb)) {
+		flush_fn(data);
+		btrfs_tree_lock(eb);
+	}
 	btrfs_set_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN);
 
 	if (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &eb->bflags)) {
@@ -2767,7 +2771,10 @@ int btree_lock_page_hook(struct page *page)
 	btrfs_tree_unlock(eb);
 	free_extent_buffer(eb);
 out:
-	lock_page(page);
+	if (!trylock_page(page)) {
+		flush_fn(data);
+		lock_page(page);
+	}
 	return 0;
 }
 

commit bfe8684869601dacfcb2cd69ef8cfd9045f62170
Author: Miklos Szeredi <mszeredi@suse.cz>
Date:   Fri Oct 28 14:13:29 2011 +0200

    filesystems: add set_nlink()
    
    Replace remaining direct i_nlink updates with a new set_nlink()
    updater function.
    
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    Tested-by: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 07b3ac662e19..07ea91879a91 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1705,7 +1705,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	sb->s_bdi = &fs_info->bdi;
 
 	fs_info->btree_inode->i_ino = BTRFS_BTREE_INODE_OBJECTID;
-	fs_info->btree_inode->i_nlink = 1;
+	set_nlink(fs_info->btree_inode, 1);
 	/*
 	 * we set the i_size on the btree inode to the max possible int.
 	 * the real end of the address space is determined by all of

commit 2bf64758fd6290797a5ce97d4b9c698a4ed1cbad
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Sep 26 17:12:22 2011 -0400

    Btrfs: allow us to overcommit our enospc reservations
    
    One of the things that kills us is the fact that our ENOSPC reservations are
    horribly over the top in most normal cases.  There isn't too much that can be
    done about this because when we are completely full we really need them to work
    like this so we don't under reserve.  However if there is plenty of unallocated
    chunks on the disk we can use that to gauge how much we can overcommit.  So this
    patch adds chunk free space accounting so we always know how much unallocated
    space we have.  Then if we fail to make a reservation within our allocated
    space, check to see if we can overcommit.  In the normal flushing case (like
    with delalloc metadata reservations) we'll take the free space and divide it by
    2 if our metadata profile is setup for DUP or any of those, and then divide it
    by 8 to make sure we don't overcommit too much.  Then if we're in a non-flushing
    case (we really need this reservation now!) we only limit ourselves to half of
    the free space.  This makes this fio test
    
    [torrent]
    filename=torrent-test
    rw=randwrite
    size=4g
    ioengine=sync
    directory=/mnt/btrfs-test
    
    go from taking around 45 minutes to 10 seconds on my freshly formatted 3 TiB
    file system.  This doesn't seem to break my other enospc tests, but could really
    use some more testing as this is a super scary change.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4965a0179b31..51372a521167 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1648,6 +1648,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->fs_roots_radix_lock);
 	spin_lock_init(&fs_info->delayed_iput_lock);
 	spin_lock_init(&fs_info->defrag_inodes_lock);
+	spin_lock_init(&fs_info->free_chunk_lock);
 	mutex_init(&fs_info->reloc_mutex);
 
 	init_completion(&fs_info->kobj_unregister);
@@ -1675,6 +1676,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->metadata_ratio = 0;
 	fs_info->defrag_inodes = RB_ROOT;
 	fs_info->trans_no_join = 0;
+	fs_info->free_chunk_space = 0;
 
 	fs_info->thread_pool_size = min_t(unsigned long,
 					  num_online_cpus() + 2, 8);

commit 300e4f8a56f263797568c95b71c949f9f02e4534
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Aug 29 14:06:00 2011 -0400

    Btrfs: put the block group cache after we commit the super
    
    In moving some enospc stuff around I noticed that when we unmount we are often
    evicting the free space cache inodes before we do our last commit.  This isn't
    bad, but it makes us constantly have to re-read the inodes back.  So instead
    don't evict the cache until after we do our last commit, this will make things a
    little less crappy and makes a future enospc change work properly.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0b5643a68d57..4965a0179b31 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2543,8 +2543,6 @@ int close_ctree(struct btrfs_root *root)
 	/* clear out the rbtree of defraggable inodes */
 	btrfs_run_defrag_inodes(root->fs_info);
 
-	btrfs_put_block_group_cache(fs_info);
-
 	/*
 	 * Here come 2 situations when btrfs is broken to flip readonly:
 	 *
@@ -2570,6 +2568,8 @@ int close_ctree(struct btrfs_root *root)
 			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
 	}
 
+	btrfs_put_block_group_cache(fs_info);
+
 	kthread_stop(root->fs_info->transaction_kthread);
 	kthread_stop(root->fs_info->cleaner_kthread);
 

commit 37be25bcb6d731914e126f8de59c4367f0d66b80
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Aug 5 10:25:38 2011 -0400

    Btrfs: kill the durable block rsv stuff
    
    This is confusing code and isn't used by anything anymore, so delete it.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 07b3ac662e19..0b5643a68d57 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1665,8 +1665,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_init_block_rsv(&fs_info->trans_block_rsv);
 	btrfs_init_block_rsv(&fs_info->chunk_block_rsv);
 	btrfs_init_block_rsv(&fs_info->empty_block_rsv);
-	INIT_LIST_HEAD(&fs_info->durable_block_rsv_list);
-	mutex_init(&fs_info->durable_block_rsv_mutex);
 	atomic_set(&fs_info->nr_async_submits, 0);
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);

commit 4bb31e928d1a47f5bd046ecb176b8eff7c589fc0
Author: Arne Jansen <sensille@gmx.net>
Date:   Fri Jun 10 13:55:54 2011 +0200

    btrfs: hooks for readahead
    
    This adds the hooks needed for readahead. In the readpage_end_io_hook,
    the extent state is checked for the EXTENT_READAHEAD flag. Only in this
    case the readahead hook is called, to keep the impact on non-ra as low
    as possible.
    Additionally, a hook for a failed IO is added, otherwise readahead would
    wait indefinitely for the extent to finish.
    
    Changes for v2:
     - eliminate race condition
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fd28c40e9ec3..2151828aa142 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -609,11 +609,47 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	end = min_t(u64, eb->len, PAGE_CACHE_SIZE);
 	end = eb->start + end - 1;
 err:
+	if (test_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags)) {
+		clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags);
+		btree_readahead_hook(root, eb, eb->start, ret);
+	}
+
 	free_extent_buffer(eb);
 out:
 	return ret;
 }
 
+static int btree_io_failed_hook(struct bio *failed_bio,
+			 struct page *page, u64 start, u64 end,
+			 struct extent_state *state)
+{
+	struct extent_io_tree *tree;
+	unsigned long len;
+	struct extent_buffer *eb;
+	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
+
+	tree = &BTRFS_I(page->mapping->host)->io_tree;
+	if (page->private == EXTENT_PAGE_PRIVATE)
+		goto out;
+	if (!page->private)
+		goto out;
+
+	len = page->private >> 2;
+	WARN_ON(len == 0);
+
+	eb = alloc_extent_buffer(tree, start, len, page);
+	if (eb == NULL)
+		goto out;
+
+	if (test_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags)) {
+		clear_bit(EXTENT_BUFFER_READAHEAD, &eb->bflags);
+		btree_readahead_hook(root, eb, eb->start, -EIO);
+	}
+
+out:
+	return -EIO;	/* we fixed nothing */
+}
+
 static void end_workqueue_bio(struct bio *bio, int err)
 {
 	struct end_io_wq *end_io_wq = bio->bi_private;
@@ -3166,6 +3202,7 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 static struct extent_io_ops btree_extent_io_ops = {
 	.write_cache_pages_lock_hook = btree_lock_page_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
+	.readpage_io_failed_hook = btree_io_failed_hook,
 	.submit_bio_hook = btree_submit_bio_hook,
 	/* note we're sharing with inode.c for the merge bio hook */
 	.merge_bio_hook = btrfs_merge_bio_hook,

commit 90519d66abbccc251d14719ac76f191f70826e40
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon May 23 14:30:00 2011 +0200

    btrfs: state information for readahead
    
    Add state information for readahead to btrfs_fs_info and btrfs_device
    
    Changes v2:
     - don't wait in radix_trees
     - add own set of workers for readahead
    
    Reviewed-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1220d04072c8..fd28c40e9ec3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1711,6 +1711,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->defrag_inodes = RB_ROOT;
 	fs_info->trans_no_join = 0;
 
+	/* readahead state */
+	INIT_RADIX_TREE(&fs_info->reada_tree, GFP_NOFS & ~__GFP_WAIT);
+	spin_lock_init(&fs_info->reada_lock);
+
 	fs_info->thread_pool_size = min_t(unsigned long,
 					  num_online_cpus() + 2, 8);
 
@@ -1903,6 +1907,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->delayed_workers, "delayed-meta",
 			   fs_info->thread_pool_size,
 			   &fs_info->generic_worker);
+	btrfs_init_workers(&fs_info->readahead_workers, "readahead",
+			   fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 
 	/*
 	 * endios are largely parallel and should have a very
@@ -1913,6 +1920,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	fs_info->endio_write_workers.idle_thresh = 2;
 	fs_info->endio_meta_write_workers.idle_thresh = 2;
+	fs_info->readahead_workers.idle_thresh = 2;
 
 	btrfs_start_workers(&fs_info->workers, 1);
 	btrfs_start_workers(&fs_info->generic_worker, 1);
@@ -1926,6 +1934,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->endio_freespace_worker, 1);
 	btrfs_start_workers(&fs_info->delayed_workers, 1);
 	btrfs_start_workers(&fs_info->caching_workers, 1);
+	btrfs_start_workers(&fs_info->readahead_workers, 1);
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
@@ -2650,6 +2659,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->submit_workers);
 	btrfs_stop_workers(&fs_info->delayed_workers);
 	btrfs_stop_workers(&fs_info->caching_workers);
+	btrfs_stop_workers(&fs_info->readahead_workers);
 
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);

commit ab0fff03055d2d1b01a7581badeba18db9c4f55c
Author: Arne Jansen <sensille@gmx.net>
Date:   Mon May 23 14:25:41 2011 +0200

    btrfs: add READAHEAD extent buffer flag
    
    Add a READAHEAD extent buffer flag.
    Add a function to trigger a read with this flag set.
    
    Changes v2:
     - use extent buffer flags instead of extent state flags
    
    Changes v5:
     - adapt to changed read_extent_buffer_pages interface
     - don't return eb from reada_tree_block_flagged if it has CORRUPT flag set
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e6170e142cad..1220d04072c8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -980,6 +980,38 @@ int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize,
 	return ret;
 }
 
+int reada_tree_block_flagged(struct btrfs_root *root, u64 bytenr, u32 blocksize,
+			 int mirror_num, struct extent_buffer **eb)
+{
+	struct extent_buffer *buf = NULL;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	struct extent_io_tree *io_tree = &BTRFS_I(btree_inode)->io_tree;
+	int ret;
+
+	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
+	if (!buf)
+		return 0;
+
+	set_bit(EXTENT_BUFFER_READAHEAD, &buf->bflags);
+
+	ret = read_extent_buffer_pages(io_tree, buf, 0, WAIT_PAGE_LOCK,
+				       btree_get_extent, mirror_num);
+	if (ret) {
+		free_extent_buffer(buf);
+		return ret;
+	}
+
+	if (test_bit(EXTENT_BUFFER_CORRUPT, &buf->bflags)) {
+		free_extent_buffer(buf);
+		return -EIO;
+	} else if (extent_buffer_uptodate(io_tree, buf, NULL)) {
+		*eb = buf;
+	} else {
+		free_extent_buffer(buf);
+	}
+	return 0;
+}
+
 struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize)
 {

commit bb82ab88dfdb12948af58989c75bfe904bc1b09d
Author: Arne Jansen <sensille@gmx.net>
Date:   Fri Jun 10 14:06:53 2011 +0200

    btrfs: add an extra wait mode to read_extent_buffer_pages
    
    read_extent_buffer_pages currently has two modes, either trigger a read
    without waiting for anything, or wait for the I/O to finish. The former
    also bails when it's unable to lock the page. This patch now adds an
    additional parameter to allow it to block on page lock, but don't wait
    for completion.
    
    Changes v5:
     - merge the 2 wait parameters into one and define WAIT_NONE, WAIT_COMPLETE and
       WAIT_PAGE_LOCK
    
    Change v6:
     - fix bug introduced in v5
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 07b3ac662e19..e6170e142cad 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -367,7 +367,8 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 	clear_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 	io_tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 	while (1) {
-		ret = read_extent_buffer_pages(io_tree, eb, start, 1,
+		ret = read_extent_buffer_pages(io_tree, eb, start,
+					       WAIT_COMPLETE,
 					       btree_get_extent, mirror_num);
 		if (!ret &&
 		    !verify_parent_transid(io_tree, eb, parent_transid))
@@ -974,7 +975,7 @@ int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize,
 	if (!buf)
 		return 0;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
-				 buf, 0, 0, btree_get_extent, 0);
+				 buf, 0, WAIT_NONE, btree_get_extent, 0);
 	free_extent_buffer(buf);
 	return ret;
 }

commit 8ddc7d9cd0a00062247c732b96386ec2462bdbc7
Author: Jan Schmidt <list.btrfs@jan-o-sch.net>
Date:   Mon Jun 13 20:02:58 2011 +0200

    btrfs: add mirror_num to extent_read_full_page
    
    Currently, extent_read_full_page always assumes we are trying to read mirror
    0, which generally is the best we can do. To add flexibility, pass it as a
    parameter. This will be needed by scrub fixup code.
    
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 07b3ac662e19..dc0343802535 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -908,7 +908,7 @@ static int btree_readpage(struct file *file, struct page *page)
 {
 	struct extent_io_tree *tree;
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
-	return extent_read_full_page(tree, page, btree_get_extent);
+	return extent_read_full_page(tree, page, btree_get_extent, 0);
 }
 
 static int btree_releasepage(struct page *page, gfp_t gfp_flags)

commit 22712200e175e0df5c7f9edfe6c6bf5c94c23b83
Merge: 597a67e0ba75 ff95acb6733d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 27 16:43:52 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: make sure reserve_metadata_bytes doesn't leak out strange errors
      Btrfs: use the commit_root for reading free_space_inode crcs
      Btrfs: reduce extent_state lock contention for metadata
      Btrfs: remove lockdep magic from btrfs_next_leaf
      Btrfs: make a lockdep class for each root
      Btrfs: switch the btrfs tree locks to reader/writer
      Btrfs: fix deadlock when throttling transactions
      Btrfs: stop using highmem for extent_buffers
      Btrfs: fix BUG_ON() caused by ENOSPC when relocating space
      Btrfs: tag pages for writeback in sync
      Btrfs: fix enospc problems with delalloc
      Btrfs: don't flush delalloc arbitrarily
      Btrfs: use find_or_create_page instead of grab_cache_page
      Btrfs: use a worker thread to do caching
      Btrfs: fix how we merge extent states and deal with cached states
      Btrfs: use the normal checksumming infrastructure for free space cache
      Btrfs: serialize flushers in reserve_metadata_bytes
      Btrfs: do transaction space reservation before joining the transaction
      Btrfs: try to only do one btrfs_search_slot in do_setxattr

commit 85d4e461117b40eb10722f774566b19bd5e77879
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 26 16:11:19 2011 -0400

    Btrfs: make a lockdep class for each root
    
    This patch was originally from Tejun Heo.  lockdep complains about the btrfs
    locking because we sometimes take btree locks from two different trees at the
    same time.  The current classes are based only on level in the btree, which
    isn't enough information for lockdep to figure out if the lock is safe.
    
    This patch makes a class for each type of tree, and lumps all the FS trees that
    actually have files and directories into the same class.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 97f22ff8326f..94ecac33cf2d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -100,38 +100,83 @@ struct async_submit_bio {
 	struct btrfs_work work;
 };
 
-/* These are used to set the lockdep class on the extent buffer locks.
- * The class is set by the readpage_end_io_hook after the buffer has
- * passed csum validation but before the pages are unlocked.
+/*
+ * Lockdep class keys for extent_buffer->lock's in this root.  For a given
+ * eb, the lockdep key is determined by the btrfs_root it belongs to and
+ * the level the eb occupies in the tree.
+ *
+ * Different roots are used for different purposes and may nest inside each
+ * other and they require separate keysets.  As lockdep keys should be
+ * static, assign keysets according to the purpose of the root as indicated
+ * by btrfs_root->objectid.  This ensures that all special purpose roots
+ * have separate keysets.
  *
- * The lockdep class is also set by btrfs_init_new_buffer on freshly
- * allocated blocks.
+ * Lock-nesting across peer nodes is always done with the immediate parent
+ * node locked thus preventing deadlock.  As lockdep doesn't know this, use
+ * subclass to avoid triggering lockdep warning in such cases.
  *
- * The class is based on the level in the tree block, which allows lockdep
- * to know that lower nodes nest inside the locks of higher nodes.
+ * The key is set by the readpage_end_io_hook after the buffer has passed
+ * csum validation but before the pages are unlocked.  It is also set by
+ * btrfs_init_new_buffer on freshly allocated blocks.
  *
- * We also add a check to make sure the highest level of the tree is
- * the same as our lockdep setup here.  If BTRFS_MAX_LEVEL changes, this
- * code needs update as well.
+ * We also add a check to make sure the highest level of the tree is the
+ * same as our lockdep setup here.  If BTRFS_MAX_LEVEL changes, this code
+ * needs update as well.
  */
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 # if BTRFS_MAX_LEVEL != 8
 #  error
 # endif
-static struct lock_class_key btrfs_eb_class[BTRFS_MAX_LEVEL + 1];
-static const char *btrfs_eb_name[BTRFS_MAX_LEVEL + 1] = {
-	/* leaf */
-	"btrfs-extent-00",
-	"btrfs-extent-01",
-	"btrfs-extent-02",
-	"btrfs-extent-03",
-	"btrfs-extent-04",
-	"btrfs-extent-05",
-	"btrfs-extent-06",
-	"btrfs-extent-07",
-	/* highest possible level */
-	"btrfs-extent-08",
+
+static struct btrfs_lockdep_keyset {
+	u64			id;		/* root objectid */
+	const char		*name_stem;	/* lock name stem */
+	char			names[BTRFS_MAX_LEVEL + 1][20];
+	struct lock_class_key	keys[BTRFS_MAX_LEVEL + 1];
+} btrfs_lockdep_keysets[] = {
+	{ .id = BTRFS_ROOT_TREE_OBJECTID,	.name_stem = "root"	},
+	{ .id = BTRFS_EXTENT_TREE_OBJECTID,	.name_stem = "extent"	},
+	{ .id = BTRFS_CHUNK_TREE_OBJECTID,	.name_stem = "chunk"	},
+	{ .id = BTRFS_DEV_TREE_OBJECTID,	.name_stem = "dev"	},
+	{ .id = BTRFS_FS_TREE_OBJECTID,		.name_stem = "fs"	},
+	{ .id = BTRFS_CSUM_TREE_OBJECTID,	.name_stem = "csum"	},
+	{ .id = BTRFS_ORPHAN_OBJECTID,		.name_stem = "orphan"	},
+	{ .id = BTRFS_TREE_LOG_OBJECTID,	.name_stem = "log"	},
+	{ .id = BTRFS_TREE_RELOC_OBJECTID,	.name_stem = "treloc"	},
+	{ .id = BTRFS_DATA_RELOC_TREE_OBJECTID,	.name_stem = "dreloc"	},
+	{ .id = 0,				.name_stem = "tree"	},
 };
+
+void __init btrfs_init_lockdep(void)
+{
+	int i, j;
+
+	/* initialize lockdep class names */
+	for (i = 0; i < ARRAY_SIZE(btrfs_lockdep_keysets); i++) {
+		struct btrfs_lockdep_keyset *ks = &btrfs_lockdep_keysets[i];
+
+		for (j = 0; j < ARRAY_SIZE(ks->names); j++)
+			snprintf(ks->names[j], sizeof(ks->names[j]),
+				 "btrfs-%s-%02d", ks->name_stem, j);
+	}
+}
+
+void btrfs_set_buffer_lockdep_class(u64 objectid, struct extent_buffer *eb,
+				    int level)
+{
+	struct btrfs_lockdep_keyset *ks;
+
+	BUG_ON(level >= ARRAY_SIZE(ks->keys));
+
+	/* find the matching keyset, id 0 is the default entry */
+	for (ks = btrfs_lockdep_keysets; ks->id; ks++)
+		if (ks->id == objectid)
+			break;
+
+	lockdep_set_class_and_name(&eb->lock,
+				   &ks->keys[level], ks->names[level]);
+}
+
 #endif
 
 /*
@@ -491,15 +536,6 @@ static noinline int check_leaf(struct btrfs_root *root,
 	return 0;
 }
 
-#ifdef CONFIG_DEBUG_LOCK_ALLOC
-void btrfs_set_buffer_lockdep_class(struct extent_buffer *eb, int level)
-{
-	lockdep_set_class_and_name(&eb->lock,
-			   &btrfs_eb_class[level],
-			   btrfs_eb_name[level]);
-}
-#endif
-
 static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 			       struct extent_state *state)
 {
@@ -550,7 +586,8 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	}
 	found_level = btrfs_header_level(eb);
 
-	btrfs_set_buffer_lockdep_class(eb, found_level);
+	btrfs_set_buffer_lockdep_class(btrfs_header_owner(eb),
+				       eb, found_level);
 
 	ret = csum_tree_block(root, eb, 1);
 	if (ret) {

commit a65917156e345946dbde3d7effd28124c6d6a8c2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 19 12:04:14 2011 -0400

    Btrfs: stop using highmem for extent_buffers
    
    The extent_buffers have a very complex interface where
    we use HIGHMEM for metadata and try to cache a kmap mapping
    to access the memory.
    
    The next commit adds reader/writer locks, and concurrent use
    of this kmap cache would make it even more complex.
    
    This commit drops the ability to use HIGHMEM with extent buffers,
    and rips out all of the related code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 234a08404fc2..97f22ff8326f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -217,7 +217,6 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	unsigned long len;
 	unsigned long cur_len;
 	unsigned long offset = BTRFS_CSUM_SIZE;
-	char *map_token = NULL;
 	char *kaddr;
 	unsigned long map_start;
 	unsigned long map_len;
@@ -228,8 +227,7 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	len = buf->len - offset;
 	while (len > 0) {
 		err = map_private_extent_buffer(buf, offset, 32,
-					&map_token, &kaddr,
-					&map_start, &map_len, KM_USER0);
+					&kaddr, &map_start, &map_len);
 		if (err)
 			return 1;
 		cur_len = min(len, map_len - (offset - map_start));
@@ -237,7 +235,6 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 				      crc, cur_len);
 		len -= cur_len;
 		offset += cur_len;
-		unmap_extent_buffer(buf, map_token, KM_USER0);
 	}
 	if (csum_size > sizeof(inline_result)) {
 		result = kzalloc(csum_size * sizeof(char), GFP_NOFS);
@@ -1603,7 +1600,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_bdi;
 	}
 
-	fs_info->btree_inode->i_mapping->flags &= ~__GFP_FS;
+	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);
 	INIT_LIST_HEAD(&fs_info->trans_list);

commit bab39bf998133510f2dad08158006197ec0dabea
Author: Josef Bacik <josef@redhat.com>
Date:   Thu Jun 30 14:42:28 2011 -0400

    Btrfs: use a worker thread to do caching
    
    A user reported a deadlock when copying a bunch of files.  This is because they
    were low on memory and kthreadd got hung up trying to migrate pages for an
    allocation when starting the caching kthread.  The page was locked by the person
    starting the caching kthread.  To fix this we just need to use the async thread
    stuff so that the threads are already created and we don't have to worry about
    deadlocks.  Thanks,
    
    Reported-by: Roman Mamedov <rm@romanrm.ru>
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1ac8db5dc0a3..234a08404fc2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1807,6 +1807,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			   fs_info->thread_pool_size),
 			   &fs_info->generic_worker);
 
+	btrfs_init_workers(&fs_info->caching_workers, "cache",
+			   2, &fs_info->generic_worker);
+
 	/* a higher idle thresh on the submit workers makes it much more
 	 * likely that bios will be send down in a sane order to the
 	 * devices
@@ -1860,6 +1863,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->endio_write_workers, 1);
 	btrfs_start_workers(&fs_info->endio_freespace_worker, 1);
 	btrfs_start_workers(&fs_info->delayed_workers, 1);
+	btrfs_start_workers(&fs_info->caching_workers, 1);
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
@@ -2117,6 +2121,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->endio_freespace_worker);
 	btrfs_stop_workers(&fs_info->submit_workers);
 	btrfs_stop_workers(&fs_info->delayed_workers);
+	btrfs_stop_workers(&fs_info->caching_workers);
 fail_alloc:
 	kfree(fs_info->delayed_root);
 fail_iput:
@@ -2584,6 +2589,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->endio_freespace_worker);
 	btrfs_stop_workers(&fs_info->submit_workers);
 	btrfs_stop_workers(&fs_info->delayed_workers);
+	btrfs_stop_workers(&fs_info->caching_workers);
 
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);

commit 0ee5dc676a5f8fadede608c7281dfedb1ae714ea
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Jul 7 15:44:25 2011 -0400

    btrfs: kill magical embedded struct superblock
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1ac8db5dc0a3..b231ae13b269 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1077,12 +1077,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	init_completion(&root->kobj_unregister);
 	root->defrag_running = 0;
 	root->root_key.objectid = objectid;
-	root->anon_super.s_root = NULL;
-	root->anon_super.s_dev = 0;
-	INIT_LIST_HEAD(&root->anon_super.s_list);
-	INIT_LIST_HEAD(&root->anon_super.s_instances);
-	init_rwsem(&root->anon_super.s_umount);
-
+	root->anon_dev = 0;
 	return 0;
 }
 
@@ -1311,7 +1306,7 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	spin_lock_init(&root->cache_lock);
 	init_waitqueue_head(&root->cache_wait);
 
-	ret = set_anon_super(&root->anon_super, NULL);
+	ret = get_anon_bdev(&root->anon_dev);
 	if (ret)
 		goto fail;
 
@@ -2393,10 +2388,8 @@ static void free_fs_root(struct btrfs_root *root)
 {
 	iput(root->cache_inode);
 	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
-	if (root->anon_super.s_dev) {
-		down_write(&root->anon_super.s_umount);
-		kill_anon_super(&root->anon_super);
-	}
+	if (root->anon_dev)
+		free_anon_bdev(root->anon_dev);
 	free_extent_buffer(root->node);
 	free_extent_buffer(root->commit_root);
 	kfree(root->free_ino_ctl);

commit 35a30d7ce54e087d8025a725d4e5a2fdee723a9f
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Jun 13 15:18:23 2011 +0000

    btrfs: fix uninitialized return value
    
    When allocation fails in btrfs_read_fs_root_no_name, ret is not set
    although it is returned, holding a garbage value.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c25ef5a0ccd6..1ac8db5dc0a3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1299,12 +1299,12 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 		return root;
 
 	root->free_ino_ctl = kzalloc(sizeof(*root->free_ino_ctl), GFP_NOFS);
-	if (!root->free_ino_ctl)
-		goto fail;
 	root->free_ino_pinned = kzalloc(sizeof(*root->free_ino_pinned),
 					GFP_NOFS);
-	if (!root->free_ino_pinned)
+	if (!root->free_ino_pinned || !root->free_ino_ctl) {
+		ret = -ENOMEM;
 		goto fail;
+	}
 
 	btrfs_init_free_ino_ctl(root);
 	mutex_init(&root->fs_commit_mutex);

commit 9fe6a50fb764f508dd2de47a66e62e51388791fb
Author: Maarten Lankhorst <m.b.lankhorst@gmail.com>
Date:   Thu Jun 16 09:04:57 2011 +0000

    btrfs: Remove unused sysfs code
    
    Removes code no longer used. The sysfs file itself is kept, because the
    btrfs developers expressed interest in putting new entries to sysfs.
    
    Signed-off-by: Maarten Lankhorst <m.b.lankhorst@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0b2b4b759136..c25ef5a0ccd6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1044,7 +1044,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->last_trans = 0;
 	root->highest_objectid = 0;
 	root->name = NULL;
-	root->in_sysfs = 0;
 	root->inode_tree = RB_ROOT;
 	INIT_RADIX_TREE(&root->delayed_nodes_tree, GFP_ATOMIC);
 	root->block_rsv = NULL;

commit 7585717f304f5ed005cc4ad933a69aab3efbd136
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jun 13 20:00:16 2011 -0400

    Btrfs: fix relocation races
    
    The recent commit to get rid of our trans_mutex introduced
    some races with block group relocation.  The problem is that relocation
    needs to do some record keeping about each root, and it was relying
    on the transaction mutex to coordinate things in subtle ways.
    
    This fix adds a mutex just for the relocation code and makes sure
    it doesn't have a big impact on normal operations.  The race is
    really fixed in btrfs_record_root_in_trans, which is where we
    step back and wait for the relocation code to finish accounting
    setup.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 20c111b3fa0d..0b2b4b759136 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1620,6 +1620,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->fs_roots_radix_lock);
 	spin_lock_init(&fs_info->delayed_iput_lock);
 	spin_lock_init(&fs_info->defrag_inodes_lock);
+	mutex_init(&fs_info->reloc_mutex);
 
 	init_completion(&fs_info->kobj_unregister);
 	fs_info->tree_root = tree_root;

commit ac08aedfa5d3de0dcb3825b598d16c2e57991f54
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jun 13 11:28:50 2011 -0400

    Btrfs: check the return value from set_anon_super
    
    Al Viro noticed we weren't checking for set_anon_super failures.  This
    adds the required checks.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9f68c6898653..20c111b3fa0d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1312,7 +1312,9 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	spin_lock_init(&root->cache_lock);
 	init_waitqueue_head(&root->cache_wait);
 
-	set_anon_super(&root->anon_super, NULL);
+	ret = set_anon_super(&root->anon_super, NULL);
+	if (ret)
+		goto fail;
 
 	if (btrfs_root_refs(&root->root_item) == 0) {
 		ret = -ENOENT;

commit 0e735872fb4b157a2fc94d4443f367e9aeb533a6
Merge: 5be76758f35e 6eef3125886d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 10 18:58:08 2011 -0400

    Merge branch 'for-chris' of git://git.kernel.org/pub/scm/linux/kernel/git/arne/btrfs-unstable-arne into for-linus

commit 5be76758f35ec6578e5b9b150aa513ac26bd9c54
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Jun 9 10:02:51 2011 +0000

    btrfs: fix unlocked access of delalloc_inodes
    
    list_splice_init will make delalloc_inodes empty, but without a spinlock
    around, this may produce corrupted list head, accessed in many placess,
    The race window is very tight and nobody seems to have hit it so far.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a203d363184d..33b744a5ac03 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2911,9 +2911,8 @@ static int btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
 
 	INIT_LIST_HEAD(&splice);
 
-	list_splice_init(&root->fs_info->delalloc_inodes, &splice);
-
 	spin_lock(&root->fs_info->delalloc_lock);
+	list_splice_init(&root->fs_info->delalloc_inodes, &splice);
 
 	while (!list_empty(&splice)) {
 		btrfs_inode = list_entry(splice.next, struct btrfs_inode,

commit 632dd772fcbde2ba37c0e8983bd38ef4a1eac906
Author: Arne Jansen <sensille@gmx.net>
Date:   Fri Jun 10 12:07:07 2011 +0200

    btrfs: reinitialize scrub workers
    
    Scrub starts the workers each time a scrub starts and stops them after it
    finished. This patch adds an initialization for the workers before each
    start, otherwise the workers behave strangely.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a203d363184d..7bbbfebe47e4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1668,8 +1668,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->scrub_pause_wait);
 	init_rwsem(&fs_info->scrub_super_lock);
 	fs_info->scrub_workers_refcnt = 0;
-	btrfs_init_workers(&fs_info->scrub_workers, "scrub",
-			   fs_info->thread_pool_size, &fs_info->generic_worker);
 
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);

commit ff5714cca971848963b87d6b477c16ca8abbaa54
Merge: 174ba50915b0 d90c732122a1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat May 28 07:00:39 2011 -0400

    Merge branch 'for-chris' of
    git://git.kernel.org/pub/scm/linux/kernel/git/josef/btrfs-work into for-linus
    
    Conflicts:
            fs/btrfs/disk-io.c
            fs/btrfs/extent-tree.c
            fs/btrfs/free-space-cache.c
            fs/btrfs/inode.c
            fs/btrfs/transaction.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 174ba50915b08dcfd07c8b5fb795b46a165fa09a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri May 27 10:03:58 2011 -0400

    Btrfs: use the device_list_mutex during write_dev_supers
    
    write_dev_supers was changed to use RCU to protect the list of
    devices, but it was then sleeping while it actually wrote the supers.
    This fixes it to just use the mutex, since we really don't any
    concurrency in write_dev_supers anyway.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b2588a552658..98b6a71decba 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2310,7 +2310,7 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	sb = &root->fs_info->super_for_commit;
 	dev_item = &sb->dev_item;
 
-	rcu_read_lock();
+	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
 	head = &root->fs_info->fs_devices->devices;
 	list_for_each_entry_rcu(dev, head, dev_list) {
 		if (!dev->bdev) {
@@ -2355,7 +2355,7 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		if (ret)
 			total_errors++;
 	}
-	rcu_read_unlock();
+	mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
 	if (total_errors > max_errors) {
 		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
 		       total_errors);

commit 4cb5300bc839b8a943eb19c9f27f25470e22d0ca
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 24 15:35:30 2011 -0400

    Btrfs: add mount -o auto_defrag
    
    This will detect small random writes into files and
    queue the up for an auto defrag process.  It isn't well suited to
    database workloads yet, but works for smaller files such as rpm, sqlite
    or bdb databases.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 16d335b342a2..b2588a552658 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1475,6 +1475,7 @@ static int cleaner_kthread(void *arg)
 			btrfs_run_delayed_iputs(root);
 			btrfs_clean_old_snapshots(root);
 			mutex_unlock(&root->fs_info->cleaner_mutex);
+			btrfs_run_defrag_inodes(root->fs_info);
 		}
 
 		if (freezing(current)) {
@@ -1616,6 +1617,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->ref_cache_lock);
 	spin_lock_init(&fs_info->fs_roots_radix_lock);
 	spin_lock_init(&fs_info->delayed_iput_lock);
+	spin_lock_init(&fs_info->defrag_inodes_lock);
 
 	init_completion(&fs_info->kobj_unregister);
 	fs_info->tree_root = tree_root;
@@ -1638,9 +1640,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
+	atomic_set(&fs_info->defrag_running, 0);
 	fs_info->sb = sb;
 	fs_info->max_inline = 8192 * 1024;
 	fs_info->metadata_ratio = 0;
+	fs_info->defrag_inodes = RB_ROOT;
 
 	fs_info->thread_pool_size = min_t(unsigned long,
 					  num_online_cpus() + 2, 8);
@@ -2501,6 +2505,14 @@ int close_ctree(struct btrfs_root *root)
 	smp_mb();
 
 	btrfs_scrub_cancel(root);
+
+	/* wait for any defraggers to finish */
+	wait_event(fs_info->transaction_wait,
+		   (atomic_read(&fs_info->defrag_running) == 0));
+
+	/* clear out the rbtree of defraggable inodes */
+	btrfs_run_defrag_inodes(root->fs_info);
+
 	btrfs_put_block_group_cache(fs_info);
 
 	/*

commit d6c0cb379c5198487e4ac124728cbb2346d63b1f
Merge: 8e531cdfeb75 1f78160ce1b1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 23 14:37:47 2011 -0400

    Merge branch 'cleanups_and_fixes' into inode_numbers
    
    Conflicts:
            fs/btrfs/tree-log.c
            fs/btrfs/volumes.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 1f78160ce1b1b8e657e2248118c4d91f881763f0
Author: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
Date:   Wed Apr 20 10:09:16 2011 +0000

    Btrfs: using rcu lock in the reader side of devices list
    
    fs_devices->devices is only updated on remove and add device paths, so we can
    use rcu to protect it in the reader side
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4e53a4fc467f..deba3d9c8853 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1410,8 +1410,8 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	struct btrfs_device *device;
 	struct backing_dev_info *bdi;
 
-	mutex_lock(&info->fs_devices->device_list_mutex);
-	list_for_each_entry(device, &info->fs_devices->devices, dev_list) {
+	rcu_read_lock();
+	list_for_each_entry_rcu(device, &info->fs_devices->devices, dev_list) {
 		if (!device->bdev)
 			continue;
 		bdi = blk_get_backing_dev_info(device->bdev);
@@ -1420,7 +1420,7 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 			break;
 		}
 	}
-	mutex_unlock(&info->fs_devices->device_list_mutex);
+	rcu_read_unlock();
 	return ret;
 }
 
@@ -2332,9 +2332,9 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	sb = &root->fs_info->super_for_commit;
 	dev_item = &sb->dev_item;
 
-	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
+	rcu_read_lock();
 	head = &root->fs_info->fs_devices->devices;
-	list_for_each_entry(dev, head, dev_list) {
+	list_for_each_entry_rcu(dev, head, dev_list) {
 		if (!dev->bdev) {
 			total_errors++;
 			continue;
@@ -2367,7 +2367,7 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	}
 
 	total_errors = 0;
-	list_for_each_entry(dev, head, dev_list) {
+	list_for_each_entry_rcu(dev, head, dev_list) {
 		if (!dev->bdev)
 			continue;
 		if (!dev->in_fs_metadata || !dev->writeable)
@@ -2377,7 +2377,7 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		if (ret)
 			total_errors++;
 	}
-	mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
+	rcu_read_unlock();
 	if (total_errors > max_errors) {
 		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
 		       total_errors);

commit c9513edb0079f97749c2ac00c887a22c4ba44792
Author: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
Date:   Wed Apr 20 10:07:30 2011 +0000

    Btrfs: fix the race between reading and updating devices
    
    On btrfs_congested_fn and __unplug_io_fn paths, we should hold
    device_list_mutex to avoid remove/add device path to
    update fs_devices->devices
    
    On __btrfs_close_devices and btrfs_prepare_sprout paths, the devices in
    fs_devices->devices or fs_devices->devices is updated, so we should hold
    the mutex to avoid the reader side to reach them
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 64b289690f9d..4e53a4fc467f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1410,6 +1410,7 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	struct btrfs_device *device;
 	struct backing_dev_info *bdi;
 
+	mutex_lock(&info->fs_devices->device_list_mutex);
 	list_for_each_entry(device, &info->fs_devices->devices, dev_list) {
 		if (!device->bdev)
 			continue;
@@ -1419,6 +1420,7 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 			break;
 		}
 	}
+	mutex_unlock(&info->fs_devices->device_list_mutex);
 	return ret;
 }
 

commit 0956c798ef8dbe0fc215870eb68bd2d8e789f86a
Author: Andi Kleen <ak@linux.intel.com>
Date:   Wed May 18 00:11:22 2011 +0000

    BTRFS: Remove unused node_lock
    
    240f62c8756 replaced the node_lock with rcu_read_lock, but forgot
    to remove the actual lock in the data structure. Remove it here.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 228cf36ece83..64b289690f9d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1064,7 +1064,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	INIT_LIST_HEAD(&root->dirty_list);
 	INIT_LIST_HEAD(&root->orphan_list);
 	INIT_LIST_HEAD(&root->root_list);
-	spin_lock_init(&root->node_lock);
 	spin_lock_init(&root->orphan_lock);
 	spin_lock_init(&root->inode_lock);
 	spin_lock_init(&root->accounting_lock);

commit a4abeea41adfa3c143c289045f4625dfaeba2212
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Apr 11 17:25:13 2011 -0400

    Btrfs: kill trans_mutex
    
    We use trans_mutex for lots of things, here's a basic list
    
    1) To serialize trans_handles joining the currently running transaction
    2) To make sure that no new trans handles are started while we are committing
    3) To protect the dead_roots list and the transaction lists
    
    Really the serializing trans_handles joining is not too hard, and can really get
    bogged down in acquiring a reference to the transaction.  So replace the
    trans_mutex with a trans_lock spinlock and use it to do the following
    
    1) Protect fs_info->running_transaction.  All trans handles have to do is check
    this, and then take a reference of the transaction and keep on going.
    2) Protect the fs_info->trans_list.  This doesn't get used too much, basically
    it just holds the current transactions, which will usually just be the currently
    committing transaction and the currently running transaction at most.
    3) Protect the dead roots list.  This is only ever processed by splicing the
    list so this is relatively simple.
    4) Protect the fs_info->reloc_ctl stuff.  This is very lightweight and was using
    the trans_mutex before, so this is a pretty straightforward change.
    5) Protect fs_info->no_trans_join.  Because we don't hold the trans_lock over
    the entirety of the commit we need to have a way to block new people from
    creating a new transaction while we're doing our work.  So we set no_trans_join
    and in join_transaction we test to see if that is set, and if it is we do a
    wait_on_commit.
    6) Make the transaction use count atomic so we don't need to take locks to
    modify it when we're dropping references.
    7) Add a commit_lock to the transaction to make sure multiple people trying to
    commit the same transaction don't race and commit at the same time.
    8) Make open_ioctl_trans an atomic so we don't have to take any locks for ioctl
    trans.
    
    I have tested this with xfstests, but obviously it is a pretty hairy change so
    lots of testing is greatly appreciated.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9d6c9e332ca3..93ef254ec432 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1551,22 +1551,22 @@ static int transaction_kthread(void *arg)
 		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
 		mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
-		spin_lock(&root->fs_info->new_trans_lock);
+		spin_lock(&root->fs_info->trans_lock);
 		cur = root->fs_info->running_transaction;
 		if (!cur) {
-			spin_unlock(&root->fs_info->new_trans_lock);
+			spin_unlock(&root->fs_info->trans_lock);
 			goto sleep;
 		}
 
 		now = get_seconds();
 		if (!cur->blocked &&
 		    (now < cur->start_time || now - cur->start_time < 30)) {
-			spin_unlock(&root->fs_info->new_trans_lock);
+			spin_unlock(&root->fs_info->trans_lock);
 			delay = HZ * 5;
 			goto sleep;
 		}
 		transid = cur->transid;
-		spin_unlock(&root->fs_info->new_trans_lock);
+		spin_unlock(&root->fs_info->trans_lock);
 
 		trans = btrfs_join_transaction(root);
 		BUG_ON(IS_ERR(trans));
@@ -1658,7 +1658,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->ordered_operations);
 	INIT_LIST_HEAD(&fs_info->caching_block_groups);
 	spin_lock_init(&fs_info->delalloc_lock);
-	spin_lock_init(&fs_info->new_trans_lock);
+	spin_lock_init(&fs_info->trans_lock);
 	spin_lock_init(&fs_info->ref_cache_lock);
 	spin_lock_init(&fs_info->fs_roots_radix_lock);
 	spin_lock_init(&fs_info->delayed_iput_lock);
@@ -1687,6 +1687,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->sb = sb;
 	fs_info->max_inline = 8192 * 1024;
 	fs_info->metadata_ratio = 0;
+	fs_info->trans_no_join = 0;
 
 	fs_info->thread_pool_size = min_t(unsigned long,
 					  num_online_cpus() + 2, 8);
@@ -1735,7 +1736,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->do_barriers = 1;
 
 
-	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->ordered_operations_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
 	mutex_init(&fs_info->chunk_mutex);
@@ -3006,10 +3006,13 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 
 	WARN_ON(1);
 
-	mutex_lock(&root->fs_info->trans_mutex);
 	mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
+	spin_lock(&root->fs_info->trans_lock);
 	list_splice_init(&root->fs_info->trans_list, &list);
+	root->fs_info->trans_no_join = 1;
+	spin_unlock(&root->fs_info->trans_lock);
+
 	while (!list_empty(&list)) {
 		t = list_entry(list.next, struct btrfs_transaction, list);
 		if (!t)
@@ -3034,23 +3037,18 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 		t->blocked = 0;
 		if (waitqueue_active(&root->fs_info->transaction_wait))
 			wake_up(&root->fs_info->transaction_wait);
-		mutex_unlock(&root->fs_info->trans_mutex);
 
-		mutex_lock(&root->fs_info->trans_mutex);
 		t->commit_done = 1;
 		if (waitqueue_active(&t->commit_wait))
 			wake_up(&t->commit_wait);
-		mutex_unlock(&root->fs_info->trans_mutex);
-
-		mutex_lock(&root->fs_info->trans_mutex);
 
 		btrfs_destroy_pending_snapshots(t);
 
 		btrfs_destroy_delalloc_inodes(root);
 
-		spin_lock(&root->fs_info->new_trans_lock);
+		spin_lock(&root->fs_info->trans_lock);
 		root->fs_info->running_transaction = NULL;
-		spin_unlock(&root->fs_info->new_trans_lock);
+		spin_unlock(&root->fs_info->trans_lock);
 
 		btrfs_destroy_marked_extents(root, &t->dirty_pages,
 					     EXTENT_DIRTY);
@@ -3064,8 +3062,10 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 		kmem_cache_free(btrfs_transaction_cachep, t);
 	}
 
+	spin_lock(&root->fs_info->trans_lock);
+	root->fs_info->trans_no_join = 0;
+	spin_unlock(&root->fs_info->trans_lock);
 	mutex_unlock(&root->fs_info->transaction_kthread_mutex);
-	mutex_unlock(&root->fs_info->trans_mutex);
 
 	return 0;
 }

commit 7a7eaa40a39bde4eefc91aadeb1ce3dc4e6a1252
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Apr 13 12:54:33 2011 -0400

    Btrfs: take away the num_items argument from btrfs_join_transaction
    
    I keep forgetting that btrfs_join_transaction() just ignores the num_items
    argument, which leads me to sending pointless patches and looking stupid :).  So
    just kill the num_items argument from btrfs_join_transaction and
    btrfs_start_ioctl_transaction, since neither of them use it.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 228cf36ece83..9d6c9e332ca3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1568,7 +1568,7 @@ static int transaction_kthread(void *arg)
 		transid = cur->transid;
 		spin_unlock(&root->fs_info->new_trans_lock);
 
-		trans = btrfs_join_transaction(root, 1);
+		trans = btrfs_join_transaction(root);
 		BUG_ON(IS_ERR(trans));
 		if (transid == trans->transid) {
 			ret = btrfs_commit_transaction(trans, root);
@@ -2495,13 +2495,13 @@ int btrfs_commit_super(struct btrfs_root *root)
 	down_write(&root->fs_info->cleanup_work_sem);
 	up_write(&root->fs_info->cleanup_work_sem);
 
-	trans = btrfs_join_transaction(root, 1);
+	trans = btrfs_join_transaction(root);
 	if (IS_ERR(trans))
 		return PTR_ERR(trans);
 	ret = btrfs_commit_transaction(trans, root);
 	BUG_ON(ret);
 	/* run commit again to drop the original snapshot */
-	trans = btrfs_join_transaction(root, 1);
+	trans = btrfs_join_transaction(root);
 	if (IS_ERR(trans))
 		return PTR_ERR(trans);
 	btrfs_commit_transaction(trans, root);

commit 712673339a0d085358fd1cd3a6477cc7979bb69f
Merge: aa2dfb372a2a 8628764e1a5e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 23 06:30:52 2011 -0400

    Merge branch 'for-chris' of git://git.kernel.org/pub/scm/linux/kernel/git/arne/btrfs-unstable-arne into inode_numbers
    
    Conflicts:
            fs/btrfs/Makefile
            fs/btrfs/ctree.h
            fs/btrfs/volumes.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 945d8962ceee6bb273365d0bdf42f763225b290f
Merge: 0d0ca30f1809 4ea028859bbd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun May 22 12:33:42 2011 -0400

    Merge branch 'cleanups' of git://repo.or.cz/linux-2.6/btrfs-unstable into inode_numbers
    
    Conflicts:
            fs/btrfs/extent-tree.c
            fs/btrfs/free-space-cache.c
            fs/btrfs/inode.c
            fs/btrfs/tree-log.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit dcc6d073225b6b732a52477c91bd4edc9b4d5502
Merge: 0965537308ac 16cdcec736cd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun May 22 07:07:01 2011 -0400

    Merge branch 'delayed_inode' into inode_numbers
    
    Conflicts:
            fs/btrfs/inode.c
            fs/btrfs/ioctl.c
            fs/btrfs/transaction.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 16cdcec736cd214350cdb591bf1091f8beedefa0
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Apr 22 18:12:22 2011 +0800

    btrfs: implement delayed inode items operation
    
    Changelog V5 -> V6:
    - Fix oom when the memory load is high, by storing the delayed nodes into the
      root's radix tree, and letting btrfs inodes go.
    
    Changelog V4 -> V5:
    - Fix the race on adding the delayed node to the inode, which is spotted by
      Chris Mason.
    - Merge Chris Mason's incremental patch into this patch.
    - Fix deadlock between readdir() and memory fault, which is reported by
      Itaru Kitayama.
    
    Changelog V3 -> V4:
    - Fix nested lock, which is reported by Itaru Kitayama, by updating space cache
      inode in time.
    
    Changelog V2 -> V3:
    - Fix the race between the delayed worker and the task which does delayed items
      balance, which is reported by Tsutomu Itoh.
    - Modify the patch address David Sterba's comment.
    - Fix the bug of the cpu recursion spinlock, reported by Chris Mason
    
    Changelog V1 -> V2:
    - break up the global rb-tree, use a list to manage the delayed nodes,
      which is created for every directory and file, and used to manage the
      delayed directory name index items and the delayed inode item.
    - introduce a worker to deal with the delayed nodes.
    
    Compare with Ext3/4, the performance of file creation and deletion on btrfs
    is very poor. the reason is that btrfs must do a lot of b+ tree insertions,
    such as inode item, directory name item, directory name index and so on.
    
    If we can do some delayed b+ tree insertion or deletion, we can improve the
    performance, so we made this patch which implemented delayed directory name
    index insertion/deletion and delayed inode update.
    
    Implementation:
    - introduce a delayed root object into the filesystem, that use two lists to
      manage the delayed nodes which are created for every file/directory.
      One is used to manage all the delayed nodes that have delayed items. And the
      other is used to manage the delayed nodes which is waiting to be dealt with
      by the work thread.
    - Every delayed node has two rb-tree, one is used to manage the directory name
      index which is going to be inserted into b+ tree, and the other is used to
      manage the directory name index which is going to be deleted from b+ tree.
    - introduce a worker to deal with the delayed operation. This worker is used
      to deal with the works of the delayed directory name index items insertion
      and deletion and the delayed inode update.
      When the delayed items is beyond the lower limit, we create works for some
      delayed nodes and insert them into the work queue of the worker, and then
      go back.
      When the delayed items is beyond the upper bound, we create works for all
      the delayed nodes that haven't been dealt with, and insert them into the work
      queue of the worker, and then wait for that the untreated items is below some
      threshold value.
    - When we want to insert a directory name index into b+ tree, we just add the
      information into the delayed inserting rb-tree.
      And then we check the number of the delayed items and do delayed items
      balance. (The balance policy is above.)
    - When we want to delete a directory name index from the b+ tree, we search it
      in the inserting rb-tree at first. If we look it up, just drop it. If not,
      add the key of it into the delayed deleting rb-tree.
      Similar to the delayed inserting rb-tree, we also check the number of the
      delayed items and do delayed items balance.
      (The same to inserting manipulation)
    - When we want to update the metadata of some inode, we cached the data of the
      inode into the delayed node. the worker will flush it into the b+ tree after
      dealing with the delayed insertion and deletion.
    - We will move the delayed node to the tail of the list after we access the
      delayed node, By this way, we can cache more delayed items and merge more
      inode updates.
    - If we want to commit transaction, we will deal with all the delayed node.
    - the delayed node will be freed when we free the btrfs inode.
    - Before we log the inode items, we commit all the directory name index items
      and the delayed inode update.
    
    I did a quick test by the benchmark tool[1] and found we can improve the
    performance of file creation by ~15%, and file deletion by ~20%.
    
    Before applying this patch:
    Create files:
            Total files: 50000
            Total time: 1.096108
            Average time: 0.000022
    Delete files:
            Total files: 50000
            Total time: 1.510403
            Average time: 0.000030
    
    After applying this patch:
    Create files:
            Total files: 50000
            Total time: 0.932899
            Average time: 0.000019
    Delete files:
            Total files: 50000
            Total time: 1.215732
            Average time: 0.000024
    
    [1] http://marc.info/?l=linux-btrfs&m=128212635122920&q=p3
    
    Many thanks for Kitayama-san's help!
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Reviewed-by: David Sterba <dave@jikos.cz>
    Tested-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Tested-by: Itaru Kitayama <kitayama@cl.bb4u.ne.jp>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 228cf36ece83..22c3c9586049 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1058,6 +1058,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->name = NULL;
 	root->in_sysfs = 0;
 	root->inode_tree = RB_ROOT;
+	INIT_RADIX_TREE(&root->delayed_nodes_tree, GFP_ATOMIC);
 	root->block_rsv = NULL;
 	root->orphan_block_rsv = NULL;
 
@@ -1693,6 +1694,13 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	INIT_LIST_HEAD(&fs_info->ordered_extents);
 	spin_lock_init(&fs_info->ordered_extent_lock);
+	fs_info->delayed_root = kmalloc(sizeof(struct btrfs_delayed_root),
+					GFP_NOFS);
+	if (!fs_info->delayed_root) {
+		err = -ENOMEM;
+		goto fail_iput;
+	}
+	btrfs_init_delayed_root(fs_info->delayed_root);
 
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
@@ -1760,7 +1768,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	bh = btrfs_read_dev_super(fs_devices->latest_bdev);
 	if (!bh) {
 		err = -EINVAL;
-		goto fail_iput;
+		goto fail_alloc;
 	}
 
 	memcpy(&fs_info->super_copy, bh->b_data, sizeof(fs_info->super_copy));
@@ -1772,7 +1780,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	disk_super = &fs_info->super_copy;
 	if (!btrfs_super_root(disk_super))
-		goto fail_iput;
+		goto fail_alloc;
 
 	/* check FS state, whether FS is broken. */
 	fs_info->fs_state |= btrfs_super_flags(disk_super);
@@ -1788,7 +1796,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	ret = btrfs_parse_options(tree_root, options);
 	if (ret) {
 		err = ret;
-		goto fail_iput;
+		goto fail_alloc;
 	}
 
 	features = btrfs_super_incompat_flags(disk_super) &
@@ -1798,7 +1806,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		       "unsupported optional features (%Lx).\n",
 		       (unsigned long long)features);
 		err = -EINVAL;
-		goto fail_iput;
+		goto fail_alloc;
 	}
 
 	features = btrfs_super_incompat_flags(disk_super);
@@ -1814,7 +1822,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		       "unsupported option features (%Lx).\n",
 		       (unsigned long long)features);
 		err = -EINVAL;
-		goto fail_iput;
+		goto fail_alloc;
 	}
 
 	btrfs_init_workers(&fs_info->generic_worker,
@@ -1861,6 +1869,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			   &fs_info->generic_worker);
 	btrfs_init_workers(&fs_info->endio_freespace_worker, "freespace-write",
 			   1, &fs_info->generic_worker);
+	btrfs_init_workers(&fs_info->delayed_workers, "delayed-meta",
+			   fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 
 	/*
 	 * endios are largely parallel and should have a very
@@ -1882,6 +1893,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->endio_meta_write_workers, 1);
 	btrfs_start_workers(&fs_info->endio_write_workers, 1);
 	btrfs_start_workers(&fs_info->endio_freespace_worker, 1);
+	btrfs_start_workers(&fs_info->delayed_workers, 1);
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
@@ -2138,6 +2150,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->endio_freespace_worker);
 	btrfs_stop_workers(&fs_info->submit_workers);
+	btrfs_stop_workers(&fs_info->delayed_workers);
+fail_alloc:
+	kfree(fs_info->delayed_root);
 fail_iput:
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
@@ -2578,6 +2593,7 @@ int close_ctree(struct btrfs_root *root)
 	del_fs_roots(fs_info);
 
 	iput(fs_info->btree_inode);
+	kfree(fs_info->delayed_root);
 
 	btrfs_stop_workers(&fs_info->generic_worker);
 	btrfs_stop_workers(&fs_info->fixup_workers);
@@ -2589,6 +2605,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->endio_freespace_worker);
 	btrfs_stop_workers(&fs_info->submit_workers);
+	btrfs_stop_workers(&fs_info->delayed_workers);
 
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
@@ -2662,6 +2679,29 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	u64 num_dirty;
 	unsigned long thresh = 32 * 1024 * 1024;
 
+	if (current->flags & PF_MEMALLOC)
+		return;
+
+	btrfs_balance_delayed_items(root);
+
+	num_dirty = root->fs_info->dirty_metadata_bytes;
+
+	if (num_dirty > thresh) {
+		balance_dirty_pages_ratelimited_nr(
+				   root->fs_info->btree_inode->i_mapping, 1);
+	}
+	return;
+}
+
+void __btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
+{
+	/*
+	 * looks as though older kernels can get into trouble with
+	 * this code, they end up stuck in balance_dirty_pages forever
+	 */
+	u64 num_dirty;
+	unsigned long thresh = 32 * 1024 * 1024;
+
 	if (current->flags & PF_MEMALLOC)
 		return;
 

commit 0965537308ac3b267ea16e731bd73870a51c53b8
Merge: 61c4f2c81c61 82d5902d9c68
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat May 21 09:27:38 2011 -0400

    Merge branch 'ino-alloc' of git://repo.or.cz/linux-btrfs-devel into inode_numbers
    
    Conflicts:
            fs/btrfs/free-space-cache.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 7a36ddec1003a4e84e79f28ee714a142ed6bc529
Author: David Sterba <dsterba@suse.cz>
Date:   Fri May 6 15:33:15 2011 +0200

    btrfs: use printk_ratelimited instead of printk_ratelimit
    
    As per printk_ratelimit comment, it should not be used.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index de7b4770ab17..cb9d1b8bfe74 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -29,6 +29,7 @@
 #include <linux/crc32c.h>
 #include <linux/slab.h>
 #include <linux/migrate.h>
+#include <linux/ratelimit.h>
 #include <asm/unaligned.h>
 #include "compat.h"
 #include "ctree.h"
@@ -254,14 +255,12 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			memcpy(&found, result, csum_size);
 
 			read_extent_buffer(buf, &val, 0, csum_size);
-			if (printk_ratelimit()) {
-				printk(KERN_INFO "btrfs: %s checksum verify "
+			printk_ratelimited(KERN_INFO "btrfs: %s checksum verify "
 				       "failed on %llu wanted %X found %X "
 				       "level %d\n",
 				       root->fs_info->sb->s_id,
 				       (unsigned long long)buf->start, val, found,
 				       btrfs_header_level(buf));
-			}
 			if (result != (char *)&inline_result)
 				kfree(result);
 			return 1;
@@ -296,13 +295,11 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		ret = 0;
 		goto out;
 	}
-	if (printk_ratelimit()) {
-		printk("parent transid verify failed on %llu wanted %llu "
+	printk_ratelimited("parent transid verify failed on %llu wanted %llu "
 		       "found %llu\n",
 		       (unsigned long long)eb->start,
 		       (unsigned long long)parent_transid,
 		       (unsigned long long)btrfs_header_generation(eb));
-	}
 	ret = 1;
 	clear_extent_buffer_uptodate(io_tree, eb, &cached_state);
 out:
@@ -533,12 +530,10 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
-		if (printk_ratelimit()) {
-			printk(KERN_INFO "btrfs bad tree block start "
+		printk_ratelimited(KERN_INFO "btrfs bad tree block start "
 			       "%llu %llu\n",
 			       (unsigned long long)found_start,
 			       (unsigned long long)eb->start);
-		}
 		ret = -EIO;
 		goto err;
 	}
@@ -550,10 +545,8 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		goto err;
 	}
 	if (check_tree_block_fsid(root, eb)) {
-		if (printk_ratelimit()) {
-			printk(KERN_INFO "btrfs bad fsid on block %llu\n",
+		printk_ratelimited(KERN_INFO "btrfs bad fsid on block %llu\n",
 			       (unsigned long long)eb->start);
-		}
 		ret = -EIO;
 		goto err;
 	}
@@ -2108,11 +2101,9 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 	if (uptodate) {
 		set_buffer_uptodate(bh);
 	} else {
-		if (printk_ratelimit()) {
-			printk(KERN_WARNING "lost page write due to "
+		printk_ratelimited(KERN_WARNING "lost page write due to "
 					"I/O error on %s\n",
 				       bdevname(bh->b_bdev, b));
-		}
 		/* note, we dont' set_buffer_write_io_error because we have
 		 * our own ways of dealing with the IO errors
 		 */

commit a2de733c78fa7af51ba9670482fa7d392aa67c57
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Mar 8 14:14:00 2011 +0100

    btrfs: scrub
    
    This adds an initial implementation for scrub. It works quite
    straightforward. The usermode issues an ioctl for each device in the
    fs. For each device, it enumerates the allocated device chunks. For
    each chunk, the contained extents are enumerated and the data checksums
    fetched. The extents are read sequentially and the checksums verified.
    If an error occurs (checksum or EIO), a good copy is searched for. If
    one is found, the bad copy will be rewritten.
    All enumerations happen from the commit roots. During a transaction
    commit, the scrubs get paused and afterwards continue from the new
    roots.
    
    This commit is based on the series originally posted to linux-btrfs
    with some improvements that resulted from comments from David Sterba,
    Ilya Dryomov and Jan Schmidt.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fe5aec9b3924..e48e8095c61f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1773,6 +1773,17 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->ordered_extents);
 	spin_lock_init(&fs_info->ordered_extent_lock);
 
+	mutex_init(&fs_info->scrub_lock);
+	atomic_set(&fs_info->scrubs_running, 0);
+	atomic_set(&fs_info->scrub_pause_req, 0);
+	atomic_set(&fs_info->scrubs_paused, 0);
+	atomic_set(&fs_info->scrub_cancel_req, 0);
+	init_waitqueue_head(&fs_info->scrub_pause_wait);
+	init_rwsem(&fs_info->scrub_super_lock);
+	fs_info->scrub_workers_refcnt = 0;
+	btrfs_init_workers(&fs_info->scrub_workers, "scrub",
+			   fs_info->thread_pool_size, &fs_info->generic_worker);
+
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
 	sb->s_bdi = &fs_info->bdi;
@@ -2599,6 +2610,7 @@ int close_ctree(struct btrfs_root *root)
 	fs_info->closing = 1;
 	smp_mb();
 
+	btrfs_scrub_cancel(root);
 	btrfs_put_block_group_cache(fs_info);
 
 	/*

commit 182608c8294b5fe90d7bbd4b026c82bf0a24b736
Author: David Sterba <dsterba@suse.cz>
Date:   Thu May 5 13:13:16 2011 +0200

    btrfs: remove old unused commented out code
    
    Remove code which has been #if0-ed out for a very long time and does not
    seem to be related to current codebase anymore.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fa287c551ffc..de7b4770ab17 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1348,35 +1348,6 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	return ERR_PTR(ret);
 }
 
-#if 0
-	struct btrfs_root *root;
-	int ret;
-
-	root = btrfs_read_fs_root_no_name(fs_info, location);
-	if (!root)
-		return NULL;
-
-	if (root->in_sysfs)
-		return root;
-
-	ret = btrfs_set_root_name(root, name, namelen);
-	if (ret) {
-		free_extent_buffer(root->node);
-		kfree(root);
-		return ERR_PTR(ret);
-	}
-
-	ret = btrfs_sysfs_add_root(root);
-	if (ret) {
-		free_extent_buffer(root->node);
-		kfree(root->name);
-		kfree(root);
-		return ERR_PTR(ret);
-	}
-	root->in_sysfs = 1;
-	return root;
-#endif
-
 static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 {
 	struct btrfs_fs_info *info = (struct btrfs_fs_info *)congested_data;

commit f2a97a9dbd86eb1ef956bdf20e05c507b32beb96
Author: David Sterba <dsterba@suse.cz>
Date:   Thu May 5 12:44:41 2011 +0200

    btrfs: remove all unused functions
    
    Remove static and global declarations and/or definitions. Reduces size
    of btrfs.ko by ~3.4kB.
    
      text    data     bss     dec     hex filename
    402081    7464     200  409745   64091 btrfs.ko.base
    398620    7144     200  405964   631cc btrfs.ko.remove-all
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4084959b36fd..fa287c551ffc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -650,12 +650,6 @@ unsigned long btrfs_async_submit_limit(struct btrfs_fs_info *info)
 	return 256 * limit;
 }
 
-int btrfs_congested_async(struct btrfs_fs_info *info, int iodone)
-{
-	return atomic_read(&info->nr_async_bios) >
-		btrfs_async_submit_limit(info);
-}
-
 static void run_one_async_start(struct btrfs_work *work)
 {
 	struct async_submit_bio *async;
@@ -1283,21 +1277,6 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	return root;
 }
 
-struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
-					u64 root_objectid)
-{
-	struct btrfs_root *root;
-
-	if (root_objectid == BTRFS_ROOT_TREE_OBJECTID)
-		return fs_info->tree_root;
-	if (root_objectid == BTRFS_EXTENT_TREE_OBJECTID)
-		return fs_info->extent_root;
-
-	root = radix_tree_lookup(&fs_info->fs_roots_radix,
-				 (unsigned long)root_objectid);
-	return root;
-}
-
 struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 					      struct btrfs_key *location)
 {
@@ -1369,11 +1348,6 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	return ERR_PTR(ret);
 }
 
-struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
-				      struct btrfs_key *location,
-				      const char *name, int namelen)
-{
-	return btrfs_read_fs_root_no_name(fs_info, location);
 #if 0
 	struct btrfs_root *root;
 	int ret;
@@ -1402,7 +1376,6 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 	root->in_sysfs = 1;
 	return root;
 #endif
-}
 
 static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 {

commit ba14419264684b290f0d0b7f48d26eafb11fc0c6
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Apr 21 01:12:06 2011 +0200

    btrfs: drop gfp parameter from alloc_extent_buffer
    
    pass GFP_NOFS directly to kmem_cache_alloc
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1c0752e99066..4084959b36fd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -380,7 +380,7 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	len = page->private >> 2;
 	WARN_ON(len == 0);
 
-	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
+	eb = alloc_extent_buffer(tree, start, len, page);
 	if (eb == NULL) {
 		WARN_ON(1);
 		goto out;
@@ -525,7 +525,7 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	len = page->private >> 2;
 	WARN_ON(len == 0);
 
-	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
+	eb = alloc_extent_buffer(tree, start, len, page);
 	if (eb == NULL) {
 		ret = -EIO;
 		goto out;
@@ -974,7 +974,7 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 	struct extent_buffer *eb;
 
 	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
-				 bytenr, blocksize, NULL, GFP_NOFS);
+				 bytenr, blocksize, NULL);
 	return eb;
 }
 

commit f09d1f60e6aa82fb4cfaa525e21f6287fc1516f4
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Apr 21 01:08:01 2011 +0200

    btrfs: drop gfp parameter from find_extent_buffer
    
    pass GFP_NOFS directly to kmem_cache_alloc
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e1e55679d061..1c0752e99066 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -963,7 +963,7 @@ struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	struct extent_buffer *eb;
 	eb = find_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
-				bytenr, blocksize, GFP_NOFS);
+				bytenr, blocksize);
 	return eb;
 }
 
@@ -2696,7 +2696,7 @@ int btree_lock_page_hook(struct page *page)
 		goto out;
 
 	len = page->private >> 2;
-	eb = find_extent_buffer(io_tree, bytenr, len, GFP_NOFS);
+	eb = find_extent_buffer(io_tree, bytenr, len);
 	if (!eb)
 		goto out;
 

commit 172ddd60a662c4d8bf2809462866ddddd6431ea5
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Apr 21 00:48:27 2011 +0200

    btrfs: drop gfp parameter from alloc_extent_map
    
    pass GFP_NOFS directly to kmem_cache_alloc
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f2ee584b8efd..e1e55679d061 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -154,7 +154,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 	}
 	read_unlock(&em_tree->lock);
 
-	em = alloc_extent_map(GFP_NOFS);
+	em = alloc_extent_map();
 	if (!em) {
 		em = ERR_PTR(-ENOMEM);
 		goto out;

commit a8067e022ab54fde8953880a64572c3acca644dc
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Apr 21 00:34:43 2011 +0200

    btrfs: drop unused parameter from extent_map_tree_init
    
    the GFP flags are not stored anywhere and all allocations are done via
    alloc_extent_map(GFP_NOFS).
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3ce80f71e98a..f2ee584b8efd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1713,8 +1713,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	RB_CLEAR_NODE(&BTRFS_I(fs_info->btree_inode)->rb_node);
 	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,
 			     fs_info->btree_inode->i_mapping);
-	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree,
-			     GFP_NOFS);
+	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree);
 
 	BTRFS_I(fs_info->btree_inode)->io_tree.ops = &btree_extent_io_ops;
 

commit f993c883ad8e111fb9e9ae603540acbe94f7246c
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Apr 20 23:35:57 2011 +0200

    btrfs: drop unused argument from extent_io_tree_init
    
    all callers pass GFP_NOFS, but the GFP mask argument is not used in the
    function; GFP_ATOMIC is passed to radix tree initialization and it's the
    only correct one, since we're using the preload/insert mechanism of
    radix tree.
    Let's drop the gfp mask from btrfs function, this will not change
    behaviour.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 25e4b8f1d0ef..3ce80f71e98a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1080,7 +1080,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->log_transid = 0;
 	root->last_log_commit = 0;
 	extent_io_tree_init(&root->dirty_log_pages,
-			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+			     fs_info->btree_inode->i_mapping);
 
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
@@ -1712,8 +1712,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	RB_CLEAR_NODE(&BTRFS_I(fs_info->btree_inode)->rb_node);
 	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,
-			     fs_info->btree_inode->i_mapping,
-			     GFP_NOFS);
+			     fs_info->btree_inode->i_mapping);
 	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree,
 			     GFP_NOFS);
 
@@ -1729,9 +1728,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->block_group_cache_tree = RB_ROOT;
 
 	extent_io_tree_init(&fs_info->freed_extents[0],
-			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+			     fs_info->btree_inode->i_mapping);
 	extent_io_tree_init(&fs_info->freed_extents[1],
-			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+			     fs_info->btree_inode->i_mapping);
 	fs_info->pinned_extents = &fs_info->freed_extents[0];
 	fs_info->do_barriers = 1;
 

commit 4891aca2dac612a2f21a3278d9906ade13b55788
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Apr 19 16:45:00 2011 +0200

    btrfs: fix dereference before check
    
    The superblock's ->s_fs_info is properly set in btrfs_fill_super, after
    a call to open_ctree, which derefereces it before check. Although
    tree_root is set via btrfs_set_super, let's be defensive and leave the
    check in place.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 990afa8656a2..25e4b8f1d0ef 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1611,7 +1611,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	struct btrfs_root *csum_root = kzalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
 	struct btrfs_root *tree_root = btrfs_sb(sb);
-	struct btrfs_fs_info *fs_info = tree_root->fs_info;
+	struct btrfs_fs_info *fs_info = NULL;
 	struct btrfs_root *chunk_root = kzalloc(sizeof(struct btrfs_root),
 						GFP_NOFS);
 	struct btrfs_root *dev_root = kzalloc(sizeof(struct btrfs_root),
@@ -1623,11 +1623,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	struct btrfs_super_block *disk_super;
 
-	if (!extent_root || !tree_root || !fs_info ||
+	if (!extent_root || !tree_root || !tree_root->fs_info ||
 	    !chunk_root || !dev_root || !csum_root) {
 		err = -ENOMEM;
 		goto fail;
 	}
+	fs_info = tree_root->fs_info;
 
 	ret = init_srcu_struct(&fs_info->subvol_srcu);
 	if (ret) {

commit 306e16ce13c0f3d4fc071b45803b5b83c2606011
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Apr 19 14:29:38 2011 +0200

    btrfs: rename variables clashing with global function names
    
    reported by gcc -Wshadow:
    page_index, page_offset, new_inode, dev_name
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 228cf36ece83..990afa8656a2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -137,7 +137,7 @@ static const char *btrfs_eb_name[BTRFS_MAX_LEVEL + 1] = {
  * that covers the entire device
  */
 static struct extent_map *btree_get_extent(struct inode *inode,
-		struct page *page, size_t page_offset, u64 start, u64 len,
+		struct page *page, size_t pg_offset, u64 start, u64 len,
 		int create)
 {
 	struct extent_map_tree *em_tree = &BTRFS_I(inode)->extent_tree;

commit 019793b7554b18818624e9cf7a2ee8ba8cf6bda0
Merge: cb49f5778795 7cf96da3ec7c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 26 08:26:58 2011 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: cleanup error handling in inode.c
      Btrfs: put the right bio if we have an error
      Btrfs: free bitmaps properly when evicting the cache
      Btrfs: Free free_space item properly in btrfs_trim_block_group()
      btrfs: add missing spin_unlock to a rare exit path
      Btrfs: check return value of kmalloc()
      btrfs: fix wrong allocating flag when reading page
      Btrfs: fix missing mutex_unlock in btrfs_del_dir_entries_in_log()

commit cfece4db110dacfd6b4b87b912c59e77e6846fc0
Author: David Sterba <dsterba@suse.cz>
Date:   Mon Apr 25 19:43:52 2011 -0400

    btrfs: add missing spin_unlock to a rare exit path
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ef6865c17cd6..fe5aec9b3924 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2903,6 +2903,7 @@ static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
 
 	spin_lock(&delayed_refs->lock);
 	if (delayed_refs->num_entries == 0) {
+		spin_unlock(&delayed_refs->lock);
 		printk(KERN_INFO "delayed_refs has NO entry\n");
 		return ret;
 	}

commit 82d5902d9c681be37ffa9d70482907f9f0b7ec1f
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Apr 20 10:33:24 2011 +0800

    Btrfs: Support reading/writing on disk free ino cache
    
    This is similar to block group caching.
    
    We dedicate a special inode in fs tree to save free ino cache.
    
    At the very first time we create/delete a file after mount, the free ino
    cache will be loaded from disk into memory. When the fs tree is commited,
    the cache will be written back to disk.
    
    To keep compatibility, we check the root generation against the generation
    of the special inode when loading the cache, so the loading will fail
    if the btrfs filesystem was mounted in an older kernel before.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d02683b1ee16..4f12c30a5470 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2505,6 +2505,7 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 
 static void free_fs_root(struct btrfs_root *root)
 {
+	iput(root->cache_inode);
 	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
 	if (root->anon_super.s_dev) {
 		down_write(&root->anon_super.s_umount);

commit 581bb050941b4f220f84d3e5ed6dace3d42dd382
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Apr 20 10:06:11 2011 +0800

    Btrfs: Cache free inode numbers in memory
    
    Currently btrfs stores the highest objectid of the fs tree, and it always
    returns (highest+1) inode number when we create a file, so inode numbers
    won't be reclaimed when we delete files, so we'll run out of inode numbers
    as we keep create/delete files in 32bits machines.
    
    This fixes it, and it works similarly to how we cache free space in block
    cgroups.
    
    We start a kernel thread to read the file tree. By scanning inode items,
    we know which chunks of inode numbers are free, and we cache them in
    an rb-tree.
    
    Because we are searching the commit root, we have to carefully handle the
    cross-transaction case.
    
    The rb-tree is a hybrid extent+bitmap tree, so if we have too many small
    chunks of inode numbers, we'll use bitmaps. Initially we allow 16K ram
    of extents, and a bitmap will be used if we exceed this threshold. The
    extents threshold is adjusted in runtime.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ef6865c17cd6..d02683b1ee16 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -41,6 +41,7 @@
 #include "locking.h"
 #include "tree-log.h"
 #include "free-space-cache.h"
+#include "inode-map.h"
 
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
@@ -1327,6 +1328,19 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	if (IS_ERR(root))
 		return root;
 
+	root->free_ino_ctl = kzalloc(sizeof(*root->free_ino_ctl), GFP_NOFS);
+	if (!root->free_ino_ctl)
+		goto fail;
+	root->free_ino_pinned = kzalloc(sizeof(*root->free_ino_pinned),
+					GFP_NOFS);
+	if (!root->free_ino_pinned)
+		goto fail;
+
+	btrfs_init_free_ino_ctl(root);
+	mutex_init(&root->fs_commit_mutex);
+	spin_lock_init(&root->cache_lock);
+	init_waitqueue_head(&root->cache_wait);
+
 	set_anon_super(&root->anon_super, NULL);
 
 	if (btrfs_root_refs(&root->root_item) == 0) {
@@ -2483,6 +2497,8 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 	if (btrfs_root_refs(&root->root_item) == 0)
 		synchronize_srcu(&fs_info->subvol_srcu);
 
+	__btrfs_remove_free_space_cache(root->free_ino_pinned);
+	__btrfs_remove_free_space_cache(root->free_ino_ctl);
 	free_fs_root(root);
 	return 0;
 }
@@ -2496,6 +2512,8 @@ static void free_fs_root(struct btrfs_root *root)
 	}
 	free_extent_buffer(root->node);
 	free_extent_buffer(root->commit_root);
+	kfree(root->free_ino_ctl);
+	kfree(root->free_ino_pinned);
 	kfree(root->name);
 	kfree(root);
 }

commit adff377bb1010ec65aada1f94ef2be7c7805c711
Merge: d8bdc59f215e f65647c29b14
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 18 12:24:05 2011 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (24 commits)
      Btrfs: fix free space cache leak
      Btrfs: avoid taking the chunk_mutex in do_chunk_alloc
      Btrfs end_bio_extent_readpage should look for locked bits
      Btrfs: don't force chunk allocation in find_free_extent
      Btrfs: Check validity before setting an acl
      Btrfs: Fix incorrect inode nlink in btrfs_link()
      Btrfs: Check if btrfs_next_leaf() returns error in btrfs_real_readdir()
      Btrfs: Check if btrfs_next_leaf() returns error in btrfs_listxattr()
      Btrfs: make uncache_state unconditional
      btrfs: using cached extent_state in set/unlock combinations
      Btrfs: avoid taking the trans_mutex in btrfs_end_transaction
      Btrfs: fix subvolume mount by name problem when default mount subvolume is set
      fix user annotation in ioctl.c
      Btrfs: check for duplicate iov_base's when doing dio reads
      btrfs: properly handle overlapping areas in memmove_extent_buffer
      Btrfs: fix memory leaks in btrfs_new_inode()
      Btrfs: check for duplicate iov_base's when doing dio reads
      Btrfs: reuse the extent_map we found when calling btrfs_get_extent
      Btrfs: do not use async submit for small DIO io's
      Btrfs: don't split dio bios if we don't have to
      ...

commit 13c5a93e7005d7dae0b6d070d25203593e692d13
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Apr 11 15:45:29 2011 -0400

    Btrfs: avoid taking the trans_mutex in btrfs_end_transaction
    
    I've been working on making our O_DIRECT latency not suck and I noticed we were
    taking the trans_mutex in btrfs_end_transaction.  So to do this we convert
    num_writers and use_count to atomic_t's and just decrement them in
    btrfs_end_transaction.  Instead of deleting the transaction from the trans list
    in put_transaction we do that in btrfs_commit_transaction() since that's the
    only time it actually needs to be removed from the list.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a272bfd74ea0..ef6865c17cd6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3136,7 +3136,7 @@ static int btrfs_cleanup_transaction(struct btrfs_root *root)
 		btrfs_destroy_pinned_extent(root,
 					    root->fs_info->pinned_extents);
 
-		t->use_count = 0;
+		atomic_set(&t->use_count, 0);
 		list_del_init(&t->list);
 		memset(t, 0, sizeof(*t));
 		kmem_cache_free(btrfs_transaction_cachep, t);

commit 884b8267d5f13bdcdc7e675ecbd0dbb0257689bb
Merge: d14f5b810b49 c9ddec74aa95
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 5 12:29:25 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: don't warn in btrfs_add_orphan
      Btrfs: fix free space cache when there are pinned extents and clusters V2
      Btrfs: Fix uninitialized root flags for subvolumes
      btrfs: clear __GFP_FS flag in the space cache inode
      Btrfs: fix memory leak in start_transaction()
      Btrfs: fix memory leak in btrfs_ioctl_start_sync()
      Btrfs: fix subvol_sem leak in btrfs_rename()
      Btrfs: Fix oops for defrag with compression turned on
      Btrfs: fix /proc/mounts info.
      Btrfs: fix compiler warning in file.c

commit 08fe4db170b4193603d9d31f40ebaf652d07ac9c
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Mon Mar 28 02:01:25 2011 +0000

    Btrfs: Fix uninitialized root flags for subvolumes
    
    root_item->flags and root_item->byte_limit are not initialized when
    a subvolume is created. This bug is not revealed until we added
    readonly snapshot support - now you mount a btrfs filesystem and you
    may find the subvolumes in it are readonly.
    
    To work around this problem, we steal a bit from root_item->inode_item->flags,
    and use it to indicate if those fields have been properly initialized.
    When we read a tree root from disk, we check if the bit is set, and if
    not we'll set the flag and initialize the two fields of the root item.
    
    Reported-by: Andreas Philipp <philipp.andreas@gmail.com>
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Tested-by: Andreas Philipp <philipp.andreas@gmail.com>
    cc: stable@kernel.org
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5cf3aa7b125c..a272bfd74ea0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1276,8 +1276,10 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	root->commit_root = btrfs_root_node(root);
 	BUG_ON(!root->node);
 out:
-	if (location->objectid != BTRFS_TREE_LOG_OBJECTID)
+	if (location->objectid != BTRFS_TREE_LOG_OBJECTID) {
 		root->ref_cows = 1;
+		btrfs_check_and_init_root_item(&root->root_item);
+	}
 
 	return root;
 }

commit 212a17ab878305600e607f637d2d8a49d9f7ef25
Merge: baaca1a61497 d9d04879321a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 28 15:31:05 2011 -0700

    Merge branch 'for-linus-unmerged' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus-unmerged' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (45 commits)
      Btrfs: fix __btrfs_map_block on 32 bit machines
      btrfs: fix possible deadlock by clearing __GFP_FS flag
      btrfs: check link counter overflow in link(2)
      btrfs: don't mess with i_nlink of unlocked inode in rename()
      Btrfs: check return value of btrfs_alloc_path()
      Btrfs: fix OOPS of empty filesystem after balance
      Btrfs: fix memory leak of empty filesystem after balance
      Btrfs: fix return value of setflags ioctl
      Btrfs: fix uncheck memory allocations
      btrfs: make inode ref log recovery faster
      Btrfs: add btrfs_trim_fs() to handle FITRIM
      Btrfs: adjust btrfs_discard_extent() return errors and trimmed bytes
      Btrfs: make btrfs_map_block() return entire free extent for each device of RAID0/1/10/DUP
      Btrfs: make update_reserved_bytes() public
      btrfs: return EXDEV when linking from different subvolumes
      Btrfs: Per file/directory controls for COW and compression
      Btrfs: add datacow flag in inode flag
      btrfs: use GFP_NOFS instead of GFP_KERNEL
      Btrfs: check return value of read_tree_block()
      btrfs: properly access unaligned checksum buffer
      ...
    
    Fix up trivial conflicts in fs/btrfs/volumes.c due to plug removal in
    the block layer.

commit 1561deda687eef0e95065f1268d680ddc5976ee7
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Sun Mar 27 16:07:36 2011 +0800

    btrfs: fix possible deadlock by clearing __GFP_FS flag
    
    Using the GFP_HIGHUSER_MOVABLE flag to allocate the metadata's page may cause
    deadlock.
      Task1
      open()
        ...
        btrfs_search_slot()
          ...
          btrfs_cow_block()
            ...
            alloc_page()
              wait for reclaiming
                                            shrink_slab()
                                              ...
                                              shrink_icache_memory()
                                                ...
                                                btrfs_evict_inode()
                                                  ...
                                                  btrfs_search_slot()
    
    If the path is locked by task1, the deadlock happens.
    
    So the btree's page cache is different with the file's page cache, it can not
    allocate pages by GFP_HIGHUSER_MOVABLE flag, we must clear __GFP_FS flag in
    GFP_HIGHUSER_MOVABLE flag.
    
    Reported-by: Itaru Kitayama <kitayama@cl.bb4u.ne.jp>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b3fc8475870f..5cf3aa7b125c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1724,6 +1724,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_bdi;
 	}
 
+	fs_info->btree_inode->i_mapping->flags &= ~__GFP_FS;
+
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);

commit c59021f846881a957ac5afe456d0f59d6a517b61
Author: liubo <liubo2009@cn.fujitsu.com>
Date:   Mon Mar 7 02:13:14 2011 +0000

    Btrfs: fix OOPS of empty filesystem after balance
    
    btrfs will remove unused block groups after balance.
    When a empty filesystem is balanced, the block group with tag "DATA" may be
    dropped, and after umount and mount again, it will not find "DATA" space_info
    and lead to OOPS.
    So we initial the necessary space_infos(DATA, SYSTEM, METADATA) to avoid OOPS.
    
    Reported-by: Daniel J Blueman <daniel.blueman@gmail.com>
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8ecc5419d8b6..b3fc8475870f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2065,6 +2065,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->metadata_alloc_profile = (u64)-1;
 	fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
 
+	ret = btrfs_init_space_info(fs_info);
+	if (ret) {
+		printk(KERN_ERR "Failed to initial space info: %d\n", ret);
+		goto fail_block_groups;
+	}
+
 	ret = btrfs_read_block_groups(extent_root);
 	if (ret) {
 		printk(KERN_ERR "Failed to read block groups: %d\n", ret);

commit 5378e60734f5b7bfe1b43dc191aaf6131c1befe7
Author: Li Dongyang <lidongyang@novell.com>
Date:   Thu Mar 24 10:24:27 2011 +0000

    Btrfs: adjust btrfs_discard_extent() return errors and trimmed bytes
    
    Callers of btrfs_discard_extent() should check if we are mounted with -o discard,
    as we want to make fitrim to work even the fs is not mounted with -o discard.
    Also we should use REQ_DISCARD to map the free extent to get a full mapping,
    last we only return errors if
    1. the error is not a EOPNOTSUPP
    2. no device supports discard
    
    Signed-off-by: Li Dongyang <lidongyang@novell.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 125639ddaffe..8ecc5419d8b6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3054,7 +3054,10 @@ static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
 			break;
 
 		/* opt_discard */
-		ret = btrfs_error_discard_extent(root, start, end + 1 - start);
+		if (btrfs_test_opt(root, DISCARD))
+			ret = btrfs_error_discard_extent(root, start,
+							 end + 1 - start,
+							 NULL);
 
 		clear_extent_dirty(unpin, start, end, GFP_NOFS);
 		btrfs_error_unpin_extent_range(root, start, end);

commit 75e7cb7fe0c391561bd3af36515be3f3c64a04c6
Author: Liu Bo <liubo2009@cn.fujitsu.com>
Date:   Tue Mar 22 10:12:20 2011 +0000

    Btrfs: Per file/directory controls for COW and compression
    
    Data compression and data cow are controlled across the entire FS by mount
    options right now.  ioctls are needed to set this on a per file or per
    directory basis.  This has been proposed previously, but VFS developers
    wanted us to use generic ioctls rather than btrfs-specific ones.
    
    According to Chris's comment, there should be just one true compression
    method(probably LZO) stored in the super.  However, before this, we would
    wait for that one method is stable enough to be adopted into the super.
    So I list it as a long term goal, and just store it in ram today.
    
    After applying this patch, we can use the generic "FS_IOC_SETFLAGS" ioctl to
    control file and directory's datacow and compression attribute.
    
    NOTE:
     - The compression type is selected by such rules:
       If we mount btrfs with compress options, ie, zlib/lzo, the type is it.
       Otherwise, we'll use the default compress type (zlib today).
    
    v1->v2:
    - rebase to the latest btrfs.
    v2->v3:
    - fix a problem, i.e. when a file is set NOCOW via mount option, then this NOCOW
      will be screwed by inheritance from parent directory.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2bdb124333ab..125639ddaffe 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1854,6 +1854,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
 
+	/*
+	 * In the long term, we'll store the compression type in the super
+	 * block, and it'll be used for per file compression control.
+	 */
+	fs_info->compress_type = BTRFS_COMPRESS_ZLIB;
+
 	ret = btrfs_parse_options(tree_root, options);
 	if (ret) {
 		err = ret;

commit 7e75bf3ff3a716d7b21d8fb43bf823115801c1e9
Author: David Sterba <dave@jikos.cz>
Date:   Fri Mar 18 22:56:43 2011 +0000

    btrfs: properly access unaligned checksum buffer
    
    On Fri, Mar 18, 2011 at 11:56:53AM -0400, Chris Mason wrote:
    > Thanks for fielding this one.  Does put_unaligned_le32 optimize away on
    > platforms with efficient access?  It would be great if we didn't need
    > the #ifdef.
    
    (quicktest: assembly output is same for put_unaligned_le32 and direct
    assignment on my x86_64)
    I was originally following examples in
    Documentation/unaligned-memory-access.txt. From other code it seems to me that
    the define CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS is intended for larger
    portions of code. Macros/wrappers for {put,get}_unaligned* are chosen via
    arch/<arch>/include/asm/unaligned.h accordingly, therefore it's safe to use
    put_unaligned_le32 without the ifdef.
    
    dave
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 00cbb41af660..2bdb124333ab 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -29,6 +29,7 @@
 #include <linux/crc32c.h>
 #include <linux/slab.h>
 #include <linux/migrate.h>
+#include <asm/unaligned.h>
 #include "compat.h"
 #include "ctree.h"
 #include "disk-io.h"
@@ -198,7 +199,7 @@ u32 btrfs_csum_data(struct btrfs_root *root, char *data, u32 seed, size_t len)
 
 void btrfs_csum_final(u32 crc, char *result)
 {
-	*(__le32 *)result = ~cpu_to_le32(crc);
+	put_unaligned_le32(~crc, result);
 }
 
 /*

commit db5b493ac78e46c7b6bad22cd25d8041564cd8ea
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Wed Mar 23 08:14:16 2011 +0000

    Btrfs: cleanup some BUG_ON()
    
    This patch changes some BUG_ON() to the error return.
    (but, most callers still use BUG_ON())
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9f31e110b481..00cbb41af660 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1248,7 +1248,10 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 		     root, fs_info, location->objectid);
 
 	path = btrfs_alloc_path();
-	BUG_ON(!path);
+	if (!path) {
+		kfree(root);
+		return ERR_PTR(-ENOMEM);
+	}
 	ret = btrfs_search_slot(NULL, tree_root, location, path, 0, 0);
 	if (ret == 0) {
 		l = path->nodes[0];

commit 6c5103890057b1bb781b26b7aae38d33e4c517d8
Merge: 3dab04e6978e 9d2e157d970a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 24 10:16:26 2011 -0700

    Merge branch 'for-2.6.39/core' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-2.6.39/core' of git://git.kernel.dk/linux-2.6-block: (65 commits)
      Documentation/iostats.txt: bit-size reference etc.
      cfq-iosched: removing unnecessary think time checking
      cfq-iosched: Don't clear queue stats when preempt.
      blk-throttle: Reset group slice when limits are changed
      blk-cgroup: Only give unaccounted_time under debug
      cfq-iosched: Don't set active queue in preempt
      block: fix non-atomic access to genhd inflight structures
      block: attempt to merge with existing requests on plug flush
      block: NULL dereference on error path in __blkdev_get()
      cfq-iosched: Don't update group weights when on service tree
      fs: assign sb->s_bdi to default_backing_dev_info if the bdi is going away
      block: Require subsystems to explicitly allocate bio_set integrity mempool
      jbd2: finish conversion from WRITE_SYNC_PLUG to WRITE_SYNC and explicit plugging
      jbd: finish conversion from WRITE_SYNC_PLUG to WRITE_SYNC and explicit plugging
      fs: make fsync_buffers_list() plug
      mm: make generic_writepages() use plugging
      blk-cgroup: Add unaccounted time to timeslice_used.
      block: fixup plugging stubs for !CONFIG_BLOCK
      block: remove obsolete comments for blkdev_issue_zeroout.
      blktrace: Use rq->cmd_flags directly in blk_add_trace_rq.
      ...
    
    Fix up conflicts in fs/{aio.c,super.c}

commit e16b396ce314b2bcdfe6c173fe075bf8e3432368
Merge: 7fd23a24717a e6e8dd5055a9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 18 10:37:40 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial: (47 commits)
      doc: CONFIG_UNEVICTABLE_LRU doesn't exist anymore
      Update cpuset info & webiste for cgroups
      dcdbas: force SMI to happen when expected
      arch/arm/Kconfig: remove one to many l's in the word.
      asm-generic/user.h: Fix spelling in comment
      drm: fix printk typo 'sracth'
      Remove one to many n's in a word
      Documentation/filesystems/romfs.txt: fixing link to genromfs
      drivers:scsi Change printk typo initate -> initiate
      serial, pch uart: Remove duplicate inclusion of linux/pci.h header
      fs/eventpoll.c: fix spelling
      mm: Fix out-of-date comments which refers non-existent functions
      drm: Fix printk typo 'failled'
      coh901318.c: Change initate to initiate.
      mbox-db5500.c Change initate to initiate.
      edac: correct i82975x error-info reported
      edac: correct i82975x mci initialisation
      edac: correct commented info
      fs: update comments to point correct document
      target: remove duplicate include of target/target_core_device.h from drivers/target/target_core_hba.c
      ...
    
    Trivial conflict in fs/eventpoll.c (spelling vs addition)

commit a826d6dcb32d811b4c81df57a5ef1367516586b0
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Mar 16 13:42:43 2011 -0400

    Btrfs: check items for correctness as we search
    
    Currently if we have corrupted items things will blow up in spectacular ways.
    So as we read in blocks and they are leaves, check the entire leaf to make sure
    all of the items are correct and point to valid parts in the leaf for the item
    data the are responsible for.  If the item is corrupt we will kick back EIO and
    not read any of the copies since they are likely to not be correct either.  This
    will catch generic corruptions, it will be up to the individual callers of
    btrfs_search_slot to make sure their items are right.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 495b1ac45f8c..9f31e110b481 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -323,6 +323,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 	int num_copies = 0;
 	int mirror_num = 0;
 
+	clear_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
 	io_tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 	while (1) {
 		ret = read_extent_buffer_pages(io_tree, eb, start, 1,
@@ -331,6 +332,14 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		    !verify_parent_transid(io_tree, eb, parent_transid))
 			return ret;
 
+		/*
+		 * This buffer's crc is fine, but its contents are corrupted, so
+		 * there is no reason to read the other copies, they won't be
+		 * any less wrong.
+		 */
+		if (test_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags))
+			return ret;
+
 		num_copies = btrfs_num_copies(&root->fs_info->mapping_tree,
 					      eb->start, eb->len);
 		if (num_copies == 1)
@@ -419,6 +428,73 @@ static int check_tree_block_fsid(struct btrfs_root *root,
 	return ret;
 }
 
+#define CORRUPT(reason, eb, root, slot)				\
+	printk(KERN_CRIT "btrfs: corrupt leaf, %s: block=%llu,"	\
+	       "root=%llu, slot=%d\n", reason,			\
+	       (unsigned long long)btrfs_header_bytenr(eb),	\
+	       (unsigned long long)root->objectid, slot)
+
+static noinline int check_leaf(struct btrfs_root *root,
+			       struct extent_buffer *leaf)
+{
+	struct btrfs_key key;
+	struct btrfs_key leaf_key;
+	u32 nritems = btrfs_header_nritems(leaf);
+	int slot;
+
+	if (nritems == 0)
+		return 0;
+
+	/* Check the 0 item */
+	if (btrfs_item_offset_nr(leaf, 0) + btrfs_item_size_nr(leaf, 0) !=
+	    BTRFS_LEAF_DATA_SIZE(root)) {
+		CORRUPT("invalid item offset size pair", leaf, root, 0);
+		return -EIO;
+	}
+
+	/*
+	 * Check to make sure each items keys are in the correct order and their
+	 * offsets make sense.  We only have to loop through nritems-1 because
+	 * we check the current slot against the next slot, which verifies the
+	 * next slot's offset+size makes sense and that the current's slot
+	 * offset is correct.
+	 */
+	for (slot = 0; slot < nritems - 1; slot++) {
+		btrfs_item_key_to_cpu(leaf, &leaf_key, slot);
+		btrfs_item_key_to_cpu(leaf, &key, slot + 1);
+
+		/* Make sure the keys are in the right order */
+		if (btrfs_comp_cpu_keys(&leaf_key, &key) >= 0) {
+			CORRUPT("bad key order", leaf, root, slot);
+			return -EIO;
+		}
+
+		/*
+		 * Make sure the offset and ends are right, remember that the
+		 * item data starts at the end of the leaf and grows towards the
+		 * front.
+		 */
+		if (btrfs_item_offset_nr(leaf, slot) !=
+			btrfs_item_end_nr(leaf, slot + 1)) {
+			CORRUPT("slot offset bad", leaf, root, slot);
+			return -EIO;
+		}
+
+		/*
+		 * Check to make sure that we don't point outside of the leaf,
+		 * just incase all the items are consistent to eachother, but
+		 * all point outside of the leaf.
+		 */
+		if (btrfs_item_end_nr(leaf, slot) >
+		    BTRFS_LEAF_DATA_SIZE(root)) {
+			CORRUPT("slot end outside of leaf", leaf, root, slot);
+			return -EIO;
+		}
+	}
+
+	return 0;
+}
+
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 void btrfs_set_buffer_lockdep_class(struct extent_buffer *eb, int level)
 {
@@ -485,8 +561,20 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	btrfs_set_buffer_lockdep_class(eb, found_level);
 
 	ret = csum_tree_block(root, eb, 1);
-	if (ret)
+	if (ret) {
 		ret = -EIO;
+		goto err;
+	}
+
+	/*
+	 * If this is a leaf block and it is corrupt, set the corrupt bit so
+	 * that we don't try and read the other copies of this block, just
+	 * return -EIO.
+	 */
+	if (found_level == 0 && check_leaf(root, eb)) {
+		set_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);
+		ret = -EIO;
+	}
 
 	end = min_t(u64, eb->len, PAGE_CACHE_SIZE);
 	end = eb->start + end - 1;

commit 66b4ffd110f9b48b8d8c1319ee446b53b8d073bf
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jan 31 16:22:42 2011 -0500

    Btrfs: handle errors in btrfs_orphan_cleanup
    
    If we cannot truncate an inode for some reason we will never delete the orphan
    item associated with that inode, which means that we will loop forever in
    btrfs_orphan_cleanup.  Instead of doing this just return error so we fail to
    mount.  It sucks, but hey it's better than hanging.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e1aa8d607bc7..495b1ac45f8c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2058,9 +2058,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		down_read(&fs_info->cleanup_work_sem);
-		btrfs_orphan_cleanup(fs_info->fs_root);
-		btrfs_orphan_cleanup(fs_info->tree_root);
+		err = btrfs_orphan_cleanup(fs_info->fs_root);
+		if (!err)
+			err = btrfs_orphan_cleanup(fs_info->tree_root);
 		up_read(&fs_info->cleanup_work_sem);
+		if (err) {
+			close_ctree(tree_root);
+			return ERR_PTR(err);
+		}
 	}
 
 	return tree_root;
@@ -2435,8 +2440,12 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 
 		root_objectid = gang[ret - 1]->root_key.objectid + 1;
 		for (i = 0; i < ret; i++) {
+			int err;
+
 			root_objectid = gang[i]->root_key.objectid;
-			btrfs_orphan_cleanup(gang[i]);
+			err = btrfs_orphan_cleanup(gang[i]);
+			if (err)
+				return err;
 		}
 		root_objectid++;
 	}

commit 7eaceaccab5f40bbfda044629a6298616aeaed50
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Thu Mar 10 08:52:07 2011 +0100

    block: remove per-queue plugging
    
    Code has been converted over to the new explicit on-stack plugging,
    and delay users have been converted to use the new API for that.
    So lets kill off the old plugging along with aops->sync_page().
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e1aa8d607bc7..ada1f6bd0a57 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -847,7 +847,6 @@ static const struct address_space_operations btree_aops = {
 	.writepages	= btree_writepages,
 	.releasepage	= btree_releasepage,
 	.invalidatepage = btree_invalidatepage,
-	.sync_page	= block_sync_page,
 #ifdef CONFIG_MIGRATION
 	.migratepage	= btree_migratepage,
 #endif
@@ -1330,82 +1329,6 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	return ret;
 }
 
-/*
- * this unplugs every device on the box, and it is only used when page
- * is null
- */
-static void __unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
-{
-	struct btrfs_device *device;
-	struct btrfs_fs_info *info;
-
-	info = (struct btrfs_fs_info *)bdi->unplug_io_data;
-	list_for_each_entry(device, &info->fs_devices->devices, dev_list) {
-		if (!device->bdev)
-			continue;
-
-		bdi = blk_get_backing_dev_info(device->bdev);
-		if (bdi->unplug_io_fn)
-			bdi->unplug_io_fn(bdi, page);
-	}
-}
-
-static void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
-{
-	struct inode *inode;
-	struct extent_map_tree *em_tree;
-	struct extent_map *em;
-	struct address_space *mapping;
-	u64 offset;
-
-	/* the generic O_DIRECT read code does this */
-	if (1 || !page) {
-		__unplug_io_fn(bdi, page);
-		return;
-	}
-
-	/*
-	 * page->mapping may change at any time.  Get a consistent copy
-	 * and use that for everything below
-	 */
-	smp_mb();
-	mapping = page->mapping;
-	if (!mapping)
-		return;
-
-	inode = mapping->host;
-
-	/*
-	 * don't do the expensive searching for a small number of
-	 * devices
-	 */
-	if (BTRFS_I(inode)->root->fs_info->fs_devices->open_devices <= 2) {
-		__unplug_io_fn(bdi, page);
-		return;
-	}
-
-	offset = page_offset(page);
-
-	em_tree = &BTRFS_I(inode)->extent_tree;
-	read_lock(&em_tree->lock);
-	em = lookup_extent_mapping(em_tree, offset, PAGE_CACHE_SIZE);
-	read_unlock(&em_tree->lock);
-	if (!em) {
-		__unplug_io_fn(bdi, page);
-		return;
-	}
-
-	if (em->block_start >= EXTENT_MAP_LAST_BYTE) {
-		free_extent_map(em);
-		__unplug_io_fn(bdi, page);
-		return;
-	}
-	offset = offset - em->start;
-	btrfs_unplug_page(&BTRFS_I(inode)->root->fs_info->mapping_tree,
-			  em->block_start + offset, page);
-	free_extent_map(em);
-}
-
 /*
  * If this fails, caller must call bdi_destroy() to get rid of the
  * bdi again.
@@ -1420,8 +1343,6 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 		return err;
 
 	bdi->ra_pages	= default_backing_dev_info.ra_pages;
-	bdi->unplug_io_fn	= btrfs_unplug_io_fn;
-	bdi->unplug_io_data	= info;
 	bdi->congested_fn	= btrfs_congested_fn;
 	bdi->congested_data	= info;
 	return 0;

commit ae0e47f02aaedbfdd5e4bec73f79b714d758223d
Author: Justin P. Mattock <justinmattock@gmail.com>
Date:   Tue Mar 1 15:06:02 2011 +0100

    Remove one to many n's in a word
    
    Signed-off-by: Justin P. Mattock <justinmattock@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fdce8799b98d..7b658d2107b4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2489,7 +2489,7 @@ int close_ctree(struct btrfs_root *root)
 	 * ERROR state on disk.
 	 *
 	 * 2. when btrfs flips readonly just in btrfs_commit_super,
-	 * and in such case, btrfs cannnot write sb via btrfs_commit_super,
+	 * and in such case, btrfs cannot write sb via btrfs_commit_super,
 	 * and since fs_state has been set BTRFS_SUPER_FLAG_ERROR flag,
 	 * btrfs will cleanup all FS resources first and write sb then.
 	 */

commit 007a14af2649c9ac77f38cd23469518ffb8b355a
Merge: 261cd298a8c3 c26a920373a9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 15 08:00:35 2011 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: check return value of alloc_extent_map()
      Btrfs - Fix memory leak in btrfs_init_new_device()
      btrfs: prevent heap corruption in btrfs_ioctl_space_info()
      Btrfs: Fix balance panic
      Btrfs: don't release pages when we can't clear the uptodate bits
      Btrfs: fix page->private races

commit eb14ab8ed24a0405fd056068b28c33a1cd846024
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Feb 10 12:35:00 2011 -0500

    Btrfs: fix page->private races
    
    There is a race where btrfs_releasepage can drop the
    page->private contents just as alloc_extent_buffer is setting
    up pages for metadata.  Because of how the Btrfs page flags work,
    this results in us skipping the crc on the page during IO.
    
    This patch sovles the race by waiting until after the extent buffer
    is inserted into the radix tree before it sets page private.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b36eeef19194..3e1ea3e0477e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -359,10 +359,14 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 
-	if (page->private == EXTENT_PAGE_PRIVATE)
+	if (page->private == EXTENT_PAGE_PRIVATE) {
+		WARN_ON(1);
 		goto out;
-	if (!page->private)
+	}
+	if (!page->private) {
+		WARN_ON(1);
 		goto out;
+	}
 	len = page->private >> 2;
 	WARN_ON(len == 0);
 

commit cb5520f02c010e3cb974b9ac06f30aafa2eebc38
Merge: eee4da2cef8e 3a90983dbdcb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Feb 7 14:06:18 2011 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (33 commits)
      Btrfs: Fix page count calculation
      btrfs: Drop __exit attribute on btrfs_exit_compress
      btrfs: cleanup error handling in btrfs_unlink_inode()
      Btrfs: exclude super blocks when we read in block groups
      Btrfs: make sure search_bitmap finds something in remove_from_bitmap
      btrfs: fix return value check of btrfs_start_transaction()
      btrfs: checking NULL or not in some functions
      Btrfs: avoid uninit variable warnings in ordered-data.c
      Btrfs: catch errors from btrfs_sync_log
      Btrfs: make shrink_delalloc a little friendlier
      Btrfs: handle no memory properly in prepare_pages
      Btrfs: do error checking in btrfs_del_csums
      Btrfs: use the global block reserve if we cannot reserve space
      Btrfs: do not release more reserved bytes to the global_block_rsv than we need
      Btrfs: fix check_path_shared so it returns the right value
      btrfs: check return value of btrfs_start_ioctl_transaction() properly
      btrfs: fix return value check of btrfs_join_transaction()
      fs/btrfs/inode.c: Add missing IS_ERR test
      btrfs: fix missing break in switch phrase
      btrfs: fix several uncheck memory allocations
      ...

commit 3612b49598c303cfb22a4b609427f829828e2427
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Tue Jan 25 02:51:38 2011 +0000

    btrfs: fix return value check of btrfs_join_transaction()
    
    The error check of btrfs_join_transaction()/btrfs_join_transaction_nolock()
    is added, and the mistake of the error check in several places is
    corrected.
    
    For more stable Btrfs, I think that we should reduce BUG_ON().
    But, I think that long time is necessary for this.
    So, I propose this patch as a short-term solution.
    
    With this patch:
     - To more stable Btrfs, the part that should be corrected is clarified.
     - The panic isn't done by the NULL pointer reference etc. (even if
       BUG_ON() is increased temporarily)
     - The error code is returned in the place where the error can be easily
       returned.
    
    As a long-term plan:
     - BUG_ON() is reduced by using the forced-readonly framework, etc.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2887b8be6fdd..b36eeef19194 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1550,6 +1550,7 @@ static int transaction_kthread(void *arg)
 		spin_unlock(&root->fs_info->new_trans_lock);
 
 		trans = btrfs_join_transaction(root, 1);
+		BUG_ON(IS_ERR(trans));
 		if (transid == trans->transid) {
 			ret = btrfs_commit_transaction(trans, root);
 			BUG_ON(ret);
@@ -2464,10 +2465,14 @@ int btrfs_commit_super(struct btrfs_root *root)
 	up_write(&root->fs_info->cleanup_work_sem);
 
 	trans = btrfs_join_transaction(root, 1);
+	if (IS_ERR(trans))
+		return PTR_ERR(trans);
 	ret = btrfs_commit_transaction(trans, root);
 	BUG_ON(ret);
 	/* run commit again to drop the original snapshot */
 	trans = btrfs_join_transaction(root, 1);
+	if (IS_ERR(trans))
+		return PTR_ERR(trans);
 	btrfs_commit_transaction(trans, root);
 	ret = btrfs_write_and_wait_transaction(NULL, root);
 	BUG_ON(ret);

commit eab49bec41136460b12ac0fbeceeb88386d538c7
Merge: acce952b0263 4d728ec7aefd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jan 28 16:24:59 2011 -0500

    Merge branch 'bug-fixes' of git://repo.or.cz/linux-btrfs-devel into btrfs-38

commit 83a4d54840c88a4a45c49670f044b8c7ddeaa8c7
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Mon Dec 27 16:19:53 2010 +0800

    Btrfs: Fix memory leak at umount
    
    fs_info, which is allocated in open_ctree(), should be freed
    in close_ctree().
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a5d2249e6da5..089871e5cd5a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2513,6 +2513,8 @@ int close_ctree(struct btrfs_root *root)
 	kfree(fs_info->chunk_root);
 	kfree(fs_info->dev_root);
 	kfree(fs_info->csum_root);
+	kfree(fs_info);
+
 	return 0;
 }
 

commit eee2a817df7c5a6e569f353f8be78cc1b3604bb6
Merge: 83896fb5e515 acce952b0263
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 17 14:43:43 2011 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (25 commits)
      Btrfs: forced readonly mounts on errors
      btrfs: Require CAP_SYS_ADMIN for filesystem rebalance
      Btrfs: don't warn if we get ENOSPC in btrfs_block_rsv_check
      btrfs: Fix memory leak in btrfs_read_fs_root_no_radix()
      btrfs: check NULL or not
      btrfs: Don't pass NULL ptr to func that may deref it.
      btrfs: mount failure return value fix
      btrfs: Mem leak in btrfs_get_acl()
      btrfs: fix wrong free space information of btrfs
      btrfs: make the chunk allocator utilize the devices better
      btrfs: restructure find_free_dev_extent()
      btrfs: fix wrong calculation of stripe size
      btrfs: try to reclaim some space when chunk allocation fails
      btrfs: fix wrong data space statistics
      fs/btrfs: Fix build of ctree
      Btrfs: fix off by one while setting block groups readonly
      Btrfs: Add BTRFS_IOC_SUBVOL_GETFLAGS/SETFLAGS ioctls
      Btrfs: Add readonly snapshots support
      Btrfs: Refactor btrfs_ioctl_snap_create()
      btrfs: Extract duplicate decompress code
      ...

commit acce952b0263825da32cf10489413dec78053347
Author: liubo <liubo2009@cn.fujitsu.com>
Date:   Thu Jan 6 19:30:25 2011 +0800

    Btrfs: forced readonly mounts on errors
    
    This patch comes from "Forced readonly mounts on errors" ideas.
    
    As we know, this is the first step in being more fault tolerant of disk
    corruptions instead of just using BUG() statements.
    
    The major content:
    - add a framework for generating errors that should result in filesystems
      going readonly.
    - keep FS state in disk super block.
    - make sure that all of resource will be freed and released at umount time.
    - make sure that fter FS is forced readonly on error, there will be no more
      disk change before FS is corrected. For this, we should stop write operation.
    
    After this patch is applied, the conversion from BUG() to such a framework can
    happen incrementally.
    
    Signed-off-by: Liu Bo <liubo2009@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9b1dd4138072..1a3af9e8e0c4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -44,6 +44,20 @@
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
+static void btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
+				    int read_only);
+static int btrfs_destroy_ordered_operations(struct btrfs_root *root);
+static int btrfs_destroy_ordered_extents(struct btrfs_root *root);
+static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
+				      struct btrfs_root *root);
+static int btrfs_destroy_pending_snapshots(struct btrfs_transaction *t);
+static int btrfs_destroy_delalloc_inodes(struct btrfs_root *root);
+static int btrfs_destroy_marked_extents(struct btrfs_root *root,
+					struct extent_io_tree *dirty_pages,
+					int mark);
+static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
+				       struct extent_io_tree *pinned_extents);
+static int btrfs_cleanup_transaction(struct btrfs_root *root);
 
 /*
  * end_io_wq structs are used to do processing in task context when an IO is
@@ -1738,6 +1752,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!btrfs_super_root(disk_super))
 		goto fail_iput;
 
+	/* check FS state, whether FS is broken. */
+	fs_info->fs_state |= btrfs_super_flags(disk_super);
+
+	btrfs_check_super_valid(fs_info, sb->s_flags & MS_RDONLY);
+
 	ret = btrfs_parse_options(tree_root, options);
 	if (ret) {
 		err = ret;
@@ -1968,7 +1987,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		btrfs_set_opt(fs_info->mount_opt, SSD);
 	}
 
-	if (btrfs_super_log_root(disk_super) != 0) {
+	/* do not make disk changes in broken FS */
+	if (btrfs_super_log_root(disk_super) != 0 &&
+	    !(fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR)) {
 		u64 bytenr = btrfs_super_log_root(disk_super);
 
 		if (fs_devices->rw_devices == 0) {
@@ -2464,8 +2485,28 @@ int close_ctree(struct btrfs_root *root)
 	smp_mb();
 
 	btrfs_put_block_group_cache(fs_info);
+
+	/*
+	 * Here come 2 situations when btrfs is broken to flip readonly:
+	 *
+	 * 1. when btrfs flips readonly somewhere else before
+	 * btrfs_commit_super, sb->s_flags has MS_RDONLY flag,
+	 * and btrfs will skip to write sb directly to keep
+	 * ERROR state on disk.
+	 *
+	 * 2. when btrfs flips readonly just in btrfs_commit_super,
+	 * and in such case, btrfs cannnot write sb via btrfs_commit_super,
+	 * and since fs_state has been set BTRFS_SUPER_FLAG_ERROR flag,
+	 * btrfs will cleanup all FS resources first and write sb then.
+	 */
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
-		ret =  btrfs_commit_super(root);
+		ret = btrfs_commit_super(root);
+		if (ret)
+			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
+	}
+
+	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR) {
+		ret = btrfs_error_commit_super(root);
 		if (ret)
 			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
 	}
@@ -2641,6 +2682,352 @@ int btree_lock_page_hook(struct page *page)
 	return 0;
 }
 
+static void btrfs_check_super_valid(struct btrfs_fs_info *fs_info,
+			      int read_only)
+{
+	if (read_only)
+		return;
+
+	if (fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR)
+		printk(KERN_WARNING "warning: mount fs with errors, "
+		       "running btrfsck is recommended\n");
+}
+
+int btrfs_error_commit_super(struct btrfs_root *root)
+{
+	int ret;
+
+	mutex_lock(&root->fs_info->cleaner_mutex);
+	btrfs_run_delayed_iputs(root);
+	mutex_unlock(&root->fs_info->cleaner_mutex);
+
+	down_write(&root->fs_info->cleanup_work_sem);
+	up_write(&root->fs_info->cleanup_work_sem);
+
+	/* cleanup FS via transaction */
+	btrfs_cleanup_transaction(root);
+
+	ret = write_ctree_super(NULL, root, 0);
+
+	return ret;
+}
+
+static int btrfs_destroy_ordered_operations(struct btrfs_root *root)
+{
+	struct btrfs_inode *btrfs_inode;
+	struct list_head splice;
+
+	INIT_LIST_HEAD(&splice);
+
+	mutex_lock(&root->fs_info->ordered_operations_mutex);
+	spin_lock(&root->fs_info->ordered_extent_lock);
+
+	list_splice_init(&root->fs_info->ordered_operations, &splice);
+	while (!list_empty(&splice)) {
+		btrfs_inode = list_entry(splice.next, struct btrfs_inode,
+					 ordered_operations);
+
+		list_del_init(&btrfs_inode->ordered_operations);
+
+		btrfs_invalidate_inodes(btrfs_inode->root);
+	}
+
+	spin_unlock(&root->fs_info->ordered_extent_lock);
+	mutex_unlock(&root->fs_info->ordered_operations_mutex);
+
+	return 0;
+}
+
+static int btrfs_destroy_ordered_extents(struct btrfs_root *root)
+{
+	struct list_head splice;
+	struct btrfs_ordered_extent *ordered;
+	struct inode *inode;
+
+	INIT_LIST_HEAD(&splice);
+
+	spin_lock(&root->fs_info->ordered_extent_lock);
+
+	list_splice_init(&root->fs_info->ordered_extents, &splice);
+	while (!list_empty(&splice)) {
+		ordered = list_entry(splice.next, struct btrfs_ordered_extent,
+				     root_extent_list);
+
+		list_del_init(&ordered->root_extent_list);
+		atomic_inc(&ordered->refs);
+
+		/* the inode may be getting freed (in sys_unlink path). */
+		inode = igrab(ordered->inode);
+
+		spin_unlock(&root->fs_info->ordered_extent_lock);
+		if (inode)
+			iput(inode);
+
+		atomic_set(&ordered->refs, 1);
+		btrfs_put_ordered_extent(ordered);
+
+		spin_lock(&root->fs_info->ordered_extent_lock);
+	}
+
+	spin_unlock(&root->fs_info->ordered_extent_lock);
+
+	return 0;
+}
+
+static int btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,
+				      struct btrfs_root *root)
+{
+	struct rb_node *node;
+	struct btrfs_delayed_ref_root *delayed_refs;
+	struct btrfs_delayed_ref_node *ref;
+	int ret = 0;
+
+	delayed_refs = &trans->delayed_refs;
+
+	spin_lock(&delayed_refs->lock);
+	if (delayed_refs->num_entries == 0) {
+		printk(KERN_INFO "delayed_refs has NO entry\n");
+		return ret;
+	}
+
+	node = rb_first(&delayed_refs->root);
+	while (node) {
+		ref = rb_entry(node, struct btrfs_delayed_ref_node, rb_node);
+		node = rb_next(node);
+
+		ref->in_tree = 0;
+		rb_erase(&ref->rb_node, &delayed_refs->root);
+		delayed_refs->num_entries--;
+
+		atomic_set(&ref->refs, 1);
+		if (btrfs_delayed_ref_is_head(ref)) {
+			struct btrfs_delayed_ref_head *head;
+
+			head = btrfs_delayed_node_to_head(ref);
+			mutex_lock(&head->mutex);
+			kfree(head->extent_op);
+			delayed_refs->num_heads--;
+			if (list_empty(&head->cluster))
+				delayed_refs->num_heads_ready--;
+			list_del_init(&head->cluster);
+			mutex_unlock(&head->mutex);
+		}
+
+		spin_unlock(&delayed_refs->lock);
+		btrfs_put_delayed_ref(ref);
+
+		cond_resched();
+		spin_lock(&delayed_refs->lock);
+	}
+
+	spin_unlock(&delayed_refs->lock);
+
+	return ret;
+}
+
+static int btrfs_destroy_pending_snapshots(struct btrfs_transaction *t)
+{
+	struct btrfs_pending_snapshot *snapshot;
+	struct list_head splice;
+
+	INIT_LIST_HEAD(&splice);
+
+	list_splice_init(&t->pending_snapshots, &splice);
+
+	while (!list_empty(&splice)) {
+		snapshot = list_entry(splice.next,
+				      struct btrfs_pending_snapshot,
+				      list);
+
+		list_del_init(&snapshot->list);
+
+		kfree(snapshot);
+	}
+
+	return 0;
+}
+
+static int btrfs_destroy_delalloc_inodes(struct btrfs_root *root)
+{
+	struct btrfs_inode *btrfs_inode;
+	struct list_head splice;
+
+	INIT_LIST_HEAD(&splice);
+
+	list_splice_init(&root->fs_info->delalloc_inodes, &splice);
+
+	spin_lock(&root->fs_info->delalloc_lock);
+
+	while (!list_empty(&splice)) {
+		btrfs_inode = list_entry(splice.next, struct btrfs_inode,
+				    delalloc_inodes);
+
+		list_del_init(&btrfs_inode->delalloc_inodes);
+
+		btrfs_invalidate_inodes(btrfs_inode->root);
+	}
+
+	spin_unlock(&root->fs_info->delalloc_lock);
+
+	return 0;
+}
+
+static int btrfs_destroy_marked_extents(struct btrfs_root *root,
+					struct extent_io_tree *dirty_pages,
+					int mark)
+{
+	int ret;
+	struct page *page;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	struct extent_buffer *eb;
+	u64 start = 0;
+	u64 end;
+	u64 offset;
+	unsigned long index;
+
+	while (1) {
+		ret = find_first_extent_bit(dirty_pages, start, &start, &end,
+					    mark);
+		if (ret)
+			break;
+
+		clear_extent_bits(dirty_pages, start, end, mark, GFP_NOFS);
+		while (start <= end) {
+			index = start >> PAGE_CACHE_SHIFT;
+			start = (u64)(index + 1) << PAGE_CACHE_SHIFT;
+			page = find_get_page(btree_inode->i_mapping, index);
+			if (!page)
+				continue;
+			offset = page_offset(page);
+
+			spin_lock(&dirty_pages->buffer_lock);
+			eb = radix_tree_lookup(
+			     &(&BTRFS_I(page->mapping->host)->io_tree)->buffer,
+					       offset >> PAGE_CACHE_SHIFT);
+			spin_unlock(&dirty_pages->buffer_lock);
+			if (eb) {
+				ret = test_and_clear_bit(EXTENT_BUFFER_DIRTY,
+							 &eb->bflags);
+				atomic_set(&eb->refs, 1);
+			}
+			if (PageWriteback(page))
+				end_page_writeback(page);
+
+			lock_page(page);
+			if (PageDirty(page)) {
+				clear_page_dirty_for_io(page);
+				spin_lock_irq(&page->mapping->tree_lock);
+				radix_tree_tag_clear(&page->mapping->page_tree,
+							page_index(page),
+							PAGECACHE_TAG_DIRTY);
+				spin_unlock_irq(&page->mapping->tree_lock);
+			}
+
+			page->mapping->a_ops->invalidatepage(page, 0);
+			unlock_page(page);
+		}
+	}
+
+	return ret;
+}
+
+static int btrfs_destroy_pinned_extent(struct btrfs_root *root,
+				       struct extent_io_tree *pinned_extents)
+{
+	struct extent_io_tree *unpin;
+	u64 start;
+	u64 end;
+	int ret;
+
+	unpin = pinned_extents;
+	while (1) {
+		ret = find_first_extent_bit(unpin, 0, &start, &end,
+					    EXTENT_DIRTY);
+		if (ret)
+			break;
+
+		/* opt_discard */
+		ret = btrfs_error_discard_extent(root, start, end + 1 - start);
+
+		clear_extent_dirty(unpin, start, end, GFP_NOFS);
+		btrfs_error_unpin_extent_range(root, start, end);
+		cond_resched();
+	}
+
+	return 0;
+}
+
+static int btrfs_cleanup_transaction(struct btrfs_root *root)
+{
+	struct btrfs_transaction *t;
+	LIST_HEAD(list);
+
+	WARN_ON(1);
+
+	mutex_lock(&root->fs_info->trans_mutex);
+	mutex_lock(&root->fs_info->transaction_kthread_mutex);
+
+	list_splice_init(&root->fs_info->trans_list, &list);
+	while (!list_empty(&list)) {
+		t = list_entry(list.next, struct btrfs_transaction, list);
+		if (!t)
+			break;
+
+		btrfs_destroy_ordered_operations(root);
+
+		btrfs_destroy_ordered_extents(root);
+
+		btrfs_destroy_delayed_refs(t, root);
+
+		btrfs_block_rsv_release(root,
+					&root->fs_info->trans_block_rsv,
+					t->dirty_pages.dirty_bytes);
+
+		/* FIXME: cleanup wait for commit */
+		t->in_commit = 1;
+		t->blocked = 1;
+		if (waitqueue_active(&root->fs_info->transaction_blocked_wait))
+			wake_up(&root->fs_info->transaction_blocked_wait);
+
+		t->blocked = 0;
+		if (waitqueue_active(&root->fs_info->transaction_wait))
+			wake_up(&root->fs_info->transaction_wait);
+		mutex_unlock(&root->fs_info->trans_mutex);
+
+		mutex_lock(&root->fs_info->trans_mutex);
+		t->commit_done = 1;
+		if (waitqueue_active(&t->commit_wait))
+			wake_up(&t->commit_wait);
+		mutex_unlock(&root->fs_info->trans_mutex);
+
+		mutex_lock(&root->fs_info->trans_mutex);
+
+		btrfs_destroy_pending_snapshots(t);
+
+		btrfs_destroy_delalloc_inodes(root);
+
+		spin_lock(&root->fs_info->new_trans_lock);
+		root->fs_info->running_transaction = NULL;
+		spin_unlock(&root->fs_info->new_trans_lock);
+
+		btrfs_destroy_marked_extents(root, &t->dirty_pages,
+					     EXTENT_DIRTY);
+
+		btrfs_destroy_pinned_extent(root,
+					    root->fs_info->pinned_extents);
+
+		t->use_count = 0;
+		list_del_init(&t->list);
+		memset(t, 0, sizeof(*t));
+		kmem_cache_free(btrfs_transaction_cachep, t);
+	}
+
+	mutex_unlock(&root->fs_info->transaction_kthread_mutex);
+	mutex_unlock(&root->fs_info->trans_mutex);
+
+	return 0;
+}
+
 static struct extent_io_ops btree_extent_io_ops = {
 	.write_cache_pages_lock_hook = btree_lock_page_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,

commit 5e540f7715b8cd83b8e60beaaa525b125cc122de
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Mon Dec 27 06:53:10 2010 +0000

    btrfs: Fix memory leak in btrfs_read_fs_root_no_radix()
    
    In btrfs_read_fs_root_no_radix(), 'root' is not freed if
    btrfs_search_slot() returns error.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a0c37b2ee9ed..9b1dd4138072 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1153,6 +1153,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	}
 	btrfs_free_path(path);
 	if (ret) {
+		kfree(root);
 		if (ret > 0)
 			ret = -ENOENT;
 		return ERR_PTR(ret);

commit 91ca338d776e0cefb255bf2979b6448febd880f5
Author: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
Date:   Wed Jan 5 02:32:22 2011 +0000

    btrfs: check NULL or not
    
    Should check if functions returns NULL or not.
    
    Signed-off-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f9efb68fc2e3..a0c37b2ee9ed 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -353,6 +353,10 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	WARN_ON(len == 0);
 
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
+	if (eb == NULL) {
+		WARN_ON(1);
+		goto out;
+	}
 	ret = btree_read_extent_buffer_pages(root, eb, start + PAGE_CACHE_SIZE,
 					     btrfs_header_generation(eb));
 	BUG_ON(ret);
@@ -427,6 +431,10 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	WARN_ON(len == 0);
 
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
+	if (eb == NULL) {
+		ret = -EIO;
+		goto out;
+	}
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {

commit 20b450773d17e325190c158e10bfdb25dc21d2d6
Author: Dave Young <hidave.darkstar@gmail.com>
Date:   Sat Jan 8 10:09:13 2011 +0000

    btrfs: mount failure return value fix
    
    I happened to pass swap partition as root partition in cmdline,
    then kernel panic and tell me about "Cannot open root device".
    It is not correct, in fact it is a fs type mismatch instead of 'no device'.
    
    Eventually I found btrfs mounting failed with -EIO, it should be -EINVAL.
    The logic in init/do_mounts.c:
            for (p = fs_names; *p; p += strlen(p)+1) {
                    int err = do_mount_root(name, p, flags, root_mount_data);
                    switch (err) {
                            case 0:
                                    goto out;
                            case -EACCES:
                                    flags |= MS_RDONLY;
                                    goto retry;
                            case -EINVAL:
                                    continue;
                    }
                    print "Cannot open root device"
                    panic
            }
    SO fs type after btrfs will have no chance to mount
    
    Here fix the return value as -EINVAL
    
    Signed-off-by: Dave Young <hidave.darkstar@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f88eb2ce7919..f9efb68fc2e3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1713,8 +1713,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
 	bh = btrfs_read_dev_super(fs_devices->latest_bdev);
-	if (!bh)
+	if (!bh) {
+		err = -EINVAL;
 		goto fail_iput;
+	}
 
 	memcpy(&fs_info->super_copy, bh->b_data, sizeof(fs_info->super_copy));
 	memcpy(&fs_info->super_for_commit, &fs_info->super_copy,

commit a6fa6fae40ec336c7df6155255ae64ebef43a8bc
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Mon Oct 25 15:12:26 2010 +0800

    btrfs: Add lzo compression support
    
    Lzo is a much faster compression algorithm than gzib, so would allow
    more users to enable transparent compression, and some users can
    choose from compression ratio and speed for different applications
    
    Usage:
    
     # mount -t btrfs -o compress[=<zlib,lzo>] dev /mnt
    or
     # mount -t btrfs -o compress-force[=<zlib,lzo>] dev /mnt
    
    "-o compress" without argument is still allowed for compatability.
    
    Compatibility:
    
    If we mount a filesystem with lzo compression, it will not be able be
    mounted in old kernels. One reason is, otherwise btrfs will directly
    dump compressed data, which sits in inline extent, to user.
    
    Performance:
    
    The test copied a linux source tarball (~400M) from an ext4 partition
    to the btrfs partition, and then extracted it.
    
    (time in second)
               lzo        zlib        nocompress
    copy:      10.6       21.7        14.9
    extract:   70.1       94.4        66.6
    
    (data size in MB)
               lzo        zlib        nocompress
    copy:      185.87     108.69      394.49
    extract:   193.80     132.36      381.21
    
    Changelog:
    
    v1 -> v2:
    - Select LZO_COMPRESS and LZO_DECOMPRESS in btrfs Kconfig.
    - Add incompability flag.
    - Fix error handling in compress code.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a5d2249e6da5..f88eb2ce7919 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1744,10 +1744,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	}
 
 	features = btrfs_super_incompat_flags(disk_super);
-	if (!(features & BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF)) {
-		features |= BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF;
-		btrfs_set_super_incompat_flags(disk_super, features);
-	}
+	features |= BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF;
+	if (tree_root->fs_info->compress_type & BTRFS_COMPRESS_LZO)
+		features |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;
+	btrfs_set_super_incompat_flags(disk_super, features);
 
 	features = btrfs_super_compat_ro_flags(disk_super) &
 		~BTRFS_FEATURE_COMPAT_RO_SUPP;

commit e13cf63f2bbd38721af557f0205da994ea068427
Merge: 073f21ae1319 83a50de97fe9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 14 11:08:13 2010 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: prevent RAID level downgrades when space is low
      Btrfs: account for missing devices in RAID allocation profiles
      Btrfs: EIO when we fail to read tree roots
      Btrfs: fix compiler warnings
      Btrfs: Make async snapshot ioctl more generic
      Btrfs: pwrite blocked when writing from the mmaped buffer of the same page
      Btrfs: Fix a crash when mounting a subvolume
      Btrfs: fix sync subvol/snapshot creation
      Btrfs: Fix page leak in compressed writeback path
      Btrfs: do not BUG if we fail to remove the orphan item for dead snapshots
      Btrfs: fixup return code for btrfs_del_orphan_item
      Btrfs: do not do fast caching if we are allocating blocks for tree_root
      Btrfs: deal with space cache errors better
      Btrfs: fix use after free in O_DIRECT

commit 68433b73b104bff388aac376631d32abbbd872b0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 13 14:47:58 2010 -0500

    Btrfs: EIO when we fail to read tree roots
    
    If we just get a plain IO error when we read tree roots, the code
    wasn't properly sending that error up the chain.  This allowed mounts to
    continue when they should failed, and allowed operations
    on partially setup root structs.  The end result was usually oopsen
    on spinlocks that hadn't been spun up correctly.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b803c2667673..a5d2249e6da5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1007,7 +1007,10 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
-	BUG_ON(!root->node);
+	if (!root->node || !btrfs_buffer_uptodate(root->node, generation)) {
+		free_extent_buffer(root->node);
+		return -EIO;
+	}
 	root->commit_root = btrfs_root_node(root);
 	return 0;
 }

commit 3dd1462e82bcab7625cec129952f26dae7a8b742
Author: Jan Beulich <jbeulich@novell.com>
Date:   Tue Dec 7 14:54:09 2010 +0000

    Btrfs: fix compiler warnings
    
    ... regarding an unused function when !MIGRATION, and regarding a
    printk() format string vs argument mismatch.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 33b6d459494c..b803c2667673 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -696,6 +696,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 				   __btree_submit_bio_done);
 }
 
+#ifdef CONFIG_MIGRATION
 static int btree_migratepage(struct address_space *mapping,
 			struct page *newpage, struct page *page)
 {
@@ -712,12 +713,9 @@ static int btree_migratepage(struct address_space *mapping,
 	if (page_has_private(page) &&
 	    !try_to_release_page(page, GFP_KERNEL))
 		return -EAGAIN;
-#ifdef CONFIG_MIGRATION
 	return migrate_page(mapping, newpage, page);
-#else
-	return -ENOSYS;
-#endif
 }
+#endif
 
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {

commit aa3fc52546b847f590d86a093afd863ff9081628
Merge: 555bdaefd52c 5a92bc88cef2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 29 14:11:08 2010 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (24 commits)
      Btrfs: don't use migrate page without CONFIG_MIGRATION
      Btrfs: deal with DIO bios that span more than one ordered extent
      Btrfs: setup blank root and fs_info for mount time
      Btrfs: fix fiemap
      Btrfs - fix race between btrfs_get_sb() and umount
      Btrfs: update inode ctime when using links
      Btrfs: make sure new inode size is ok in fallocate
      Btrfs: fix typo in fallocate to make it honor actual size
      Btrfs: avoid NULL pointer deref in try_release_extent_buffer
      Btrfs: make btrfs_add_nondir take parent inode as an argument
      Btrfs: hold i_mutex when calling btrfs_log_dentry_safe
      Btrfs: use dget_parent where we can UPDATED
      Btrfs: fix more ESTALE problems with NFS
      Btrfs: handle NFS lookups properly
      btrfs: make 1-bit signed fileds unsigned
      btrfs: Show device attr correctly for symlinks
      btrfs: Set file size correctly in file clone
      btrfs: Check if dest_offset is block-size aligned before cloning file
      Btrfs: handle the space_cache option properly
      btrfs: Fix early enospc because 'unused' calculated with wrong sign.
      ...

commit 5a92bc88cef279261d3f138e25850c122df67045
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 29 09:49:11 2010 -0500

    Btrfs: don't use migrate page without CONFIG_MIGRATION
    
    Fixes compile error
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 57c9d8eeb7dc..33b6d459494c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -712,8 +712,11 @@ static int btree_migratepage(struct address_space *mapping,
 	if (page_has_private(page) &&
 	    !try_to_release_page(page, GFP_KERNEL))
 		return -EAGAIN;
-
+#ifdef CONFIG_MIGRATION
 	return migrate_page(mapping, newpage, page);
+#else
+	return -ENOSYS;
+#endif
 }
 
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
@@ -821,7 +824,9 @@ static const struct address_space_operations btree_aops = {
 	.releasepage	= btree_releasepage,
 	.invalidatepage = btree_invalidatepage,
 	.sync_page	= block_sync_page,
+#ifdef CONFIG_MIGRATION
 	.migratepage	= btree_migratepage,
+#endif
 };
 
 int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize,

commit 450ba0ea06b6ed3612d27f2b7127a9de4160f285
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Nov 19 14:59:15 2010 -0500

    Btrfs: setup blank root and fs_info for mount time
    
    There is a problem with how we use sget, it searches through the list of supers
    attached to the fs_type looking for a super with the same fs_devices as what
    we're trying to mount.  This depends on sb->s_fs_info being filled, but we don't
    fill that in until we get to btrfs_fill_super, so we could hit supers on the
    fs_type super list that have a null s_fs_info.  In order to fix that we need to
    go ahead and setup a blank root with a blank fs_info to hold fs_devices, that
    way our test will work out right and then we can set s_fs_info in
    btrfs_set_super, and then open_ctree will simply use our pre-allocated root and
    fs_info when setting everything up.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a67b98d58c2a..57c9d8eeb7dc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1561,10 +1561,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 						 GFP_NOFS);
 	struct btrfs_root *csum_root = kzalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
-	struct btrfs_root *tree_root = kzalloc(sizeof(struct btrfs_root),
-					       GFP_NOFS);
-	struct btrfs_fs_info *fs_info = kzalloc(sizeof(*fs_info),
-						GFP_NOFS);
+	struct btrfs_root *tree_root = btrfs_sb(sb);
+	struct btrfs_fs_info *fs_info = tree_root->fs_info;
 	struct btrfs_root *chunk_root = kzalloc(sizeof(struct btrfs_root),
 						GFP_NOFS);
 	struct btrfs_root *dev_root = kzalloc(sizeof(struct btrfs_root),

commit 784b4e29a26617589edd290dd2919735e190c06e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun Nov 21 22:20:49 2010 -0500

    Btrfs: add migrate page for metadata inode
    
    Migrate page will directly call the btrfs btree writepage function,
    which isn't actually allowed.
    
    Our writepage assumes that you have locked the extent_buffer and
    flagged the block as written.  Without doing these steps, we can
    corrupt metadata blocks.
    
    A later commit will remove the btree writepage function since
    it is really only safely used internally by btrfs.  We
    use writepages for everything else.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b40dfe48017b..a67b98d58c2a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -28,6 +28,7 @@
 #include <linux/freezer.h>
 #include <linux/crc32c.h>
 #include <linux/slab.h>
+#include <linux/migrate.h>
 #include "compat.h"
 #include "ctree.h"
 #include "disk-io.h"
@@ -355,6 +356,8 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	ret = btree_read_extent_buffer_pages(root, eb, start + PAGE_CACHE_SIZE,
 					     btrfs_header_generation(eb));
 	BUG_ON(ret);
+	WARN_ON(!btrfs_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN));
+
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
 		WARN_ON(1);
@@ -693,6 +696,26 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 				   __btree_submit_bio_done);
 }
 
+static int btree_migratepage(struct address_space *mapping,
+			struct page *newpage, struct page *page)
+{
+	/*
+	 * we can't safely write a btree page from here,
+	 * we haven't done the locking hook
+	 */
+	if (PageDirty(page))
+		return -EAGAIN;
+	/*
+	 * Buffers may be managed in a filesystem specific way.
+	 * We must have no buffers or drop them.
+	 */
+	if (page_has_private(page) &&
+	    !try_to_release_page(page, GFP_KERNEL))
+		return -EAGAIN;
+
+	return migrate_page(mapping, newpage, page);
+}
+
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct extent_io_tree *tree;
@@ -707,8 +730,7 @@ static int btree_writepage(struct page *page, struct writeback_control *wbc)
 	}
 
 	redirty_page_for_writepage(wbc, page);
-	eb = btrfs_find_tree_block(root, page_offset(page),
-				      PAGE_CACHE_SIZE);
+	eb = btrfs_find_tree_block(root, page_offset(page), PAGE_CACHE_SIZE);
 	WARN_ON(!eb);
 
 	was_dirty = test_and_set_bit(EXTENT_BUFFER_DIRTY, &eb->bflags);
@@ -799,6 +821,7 @@ static const struct address_space_operations btree_aops = {
 	.releasepage	= btree_releasepage,
 	.invalidatepage = btree_invalidatepage,
 	.sync_page	= block_sync_page,
+	.migratepage	= btree_migratepage,
 };
 
 int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize,

commit 925d169f5b86fe57e2f5264ea574cce9a89b719d
Merge: cdf01dd5443d 6418c96107a2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Oct 30 09:05:48 2010 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (39 commits)
      Btrfs: deal with errors from updating the tree log
      Btrfs: allow subvol deletion by unprivileged user with -o user_subvol_rm_allowed
      Btrfs: make SNAP_DESTROY async
      Btrfs: add SNAP_CREATE_ASYNC ioctl
      Btrfs: add START_SYNC, WAIT_SYNC ioctls
      Btrfs: async transaction commit
      Btrfs: fix deadlock in btrfs_commit_transaction
      Btrfs: fix lockdep warning on clone ioctl
      Btrfs: fix clone ioctl where range is adjacent to extent
      Btrfs: fix delalloc checks in clone ioctl
      Btrfs: drop unused variable in block_alloc_rsv
      Btrfs: cleanup warnings from gcc 4.6 (nonbugs)
      Btrfs: Fix variables set but not read (bugs found by gcc 4.6)
      Btrfs: Use ERR_CAST helpers
      Btrfs: use memdup_user helpers
      Btrfs: fix raid code for removing missing drives
      Btrfs: Switch the extent buffer rbtree into a radix tree
      Btrfs: restructure try_release_extent_buffer()
      Btrfs: use the flusher threads for delalloc throttling
      Btrfs: tune the chunk allocation to 5% of the FS as metadata
      ...
    
    Fix up trivial conflicts in fs/btrfs/super.c and fs/fs-writeback.c, and
    remove use of INIT_RCU_HEAD in fs/btrfs/extent_io.c (that init macro was
    useless and removed in commit 5e8067adfdba: "rcu head remove init")

commit bb9c12c945cbd1b0eaa1589546dde772ccabeeba
Author: Sage Weil <sage@newdream.net>
Date:   Fri Oct 29 15:37:34 2010 -0400

    Btrfs: async transaction commit
    
    Add support for an async transaction commit that is ordered such that any
    subsequent operations will join the following transaction, but does not
    wait until the current commit is fully on disk.  This avoids much of the
    latency associated with the btrfs_commit_transaction for callers concerned
    with serialization and not safety.
    
    The wait_for_unblock flag controls whether we wait for the 'middle' portion
    of commit_transaction to complete, which is necessary if the caller expects
    some of the modifications contained in the commit to be available (this is
    the case for subvol/snapshot creation).
    
    Signed-off-by: Sage Weil <sage@newdream.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e163424c7fce..b40dfe48017b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1679,6 +1679,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	init_waitqueue_head(&fs_info->transaction_throttle);
 	init_waitqueue_head(&fs_info->transaction_wait);
+	init_waitqueue_head(&fs_info->transaction_blocked_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);
 
 	__setup_root(4096, 4096, 4096, 4096, tree_root,

commit 559af8211433b8c0b20e6c43c61409cb9c9c2996
Author: Andi Kleen <andi@firstfloor.org>
Date:   Fri Oct 29 15:14:37 2010 -0400

    Btrfs: cleanup warnings from gcc 4.6 (nonbugs)
    
    These are all the cases where a variable is set, but not read which are
    not bugs as far as I can see, but simply leftovers.
    
    Still needs more review.
    
    Found by gcc 4.6's new warnings
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 77e5dabfd45a..e163424c7fce 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -338,7 +338,6 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	struct extent_io_tree *tree;
 	u64 start = (u64)page->index << PAGE_CACHE_SHIFT;
 	u64 found_start;
-	int found_level;
 	unsigned long len;
 	struct extent_buffer *eb;
 	int ret;
@@ -369,8 +368,6 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 		WARN_ON(1);
 		goto err;
 	}
-	found_level = btrfs_header_level(eb);
-
 	csum_tree_block(root, eb, 0);
 err:
 	free_extent_buffer(eb);
@@ -543,11 +540,9 @@ int btrfs_congested_async(struct btrfs_fs_info *info, int iodone)
 
 static void run_one_async_start(struct btrfs_work *work)
 {
-	struct btrfs_fs_info *fs_info;
 	struct async_submit_bio *async;
 
 	async = container_of(work, struct  async_submit_bio, work);
-	fs_info = BTRFS_I(async->inode)->root->fs_info;
 	async->submit_bio_start(async->inode, async->rw, async->bio,
 			       async->mirror_num, async->bio_flags,
 			       async->bio_offset);
@@ -860,12 +855,8 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 				      u32 blocksize, u64 parent_transid)
 {
 	struct extent_buffer *buf = NULL;
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	struct extent_io_tree *io_tree;
 	int ret;
 
-	io_tree = &BTRFS_I(btree_inode)->io_tree;
-
 	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
 	if (!buf)
 		return NULL;
@@ -1387,7 +1378,6 @@ static int bio_ready_for_csum(struct bio *bio)
 	u64 start = 0;
 	struct page *page;
 	struct extent_io_tree *io_tree = NULL;
-	struct btrfs_fs_info *info = NULL;
 	struct bio_vec *bvec;
 	int i;
 	int ret;
@@ -1406,7 +1396,6 @@ static int bio_ready_for_csum(struct bio *bio)
 		buf_len = page->private >> 2;
 		start = page_offset(page) + bvec->bv_offset;
 		io_tree = &BTRFS_I(page->mapping->host)->io_tree;
-		info = BTRFS_I(page->mapping->host)->root->fs_info;
 	}
 	/* are we fully contained in this bio? */
 	if (buf_len <= length)

commit 0cb59c9953171e9adf6da8142a5c85ceb77bb60d
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Jul 2 12:14:14 2010 -0400

    Btrfs: write out free space cache
    
    This is a simple bit, just dump the free space cache out to our preallocated
    inode when we're writing out dirty block groups.  There are a bunch of changes
    in inode.c in order to account for special cases.  Mostly when we're doing the
    writeout we're holding trans_mutex, so we need to use the nolock transacation
    functions.  Also we can't do asynchronous completions since the async thread
    could be blocked on already completed IO waiting for the transaction lock.  This
    has been tested with xfstests and btrfs filesystem balance, as well as my ENOSPC
    tests.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 45cf64fc1e3e..77e5dabfd45a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -481,9 +481,12 @@ static void end_workqueue_bio(struct bio *bio, int err)
 	end_io_wq->work.flags = 0;
 
 	if (bio->bi_rw & REQ_WRITE) {
-		if (end_io_wq->metadata)
+		if (end_io_wq->metadata == 1)
 			btrfs_queue_worker(&fs_info->endio_meta_write_workers,
 					   &end_io_wq->work);
+		else if (end_io_wq->metadata == 2)
+			btrfs_queue_worker(&fs_info->endio_freespace_worker,
+					   &end_io_wq->work);
 		else
 			btrfs_queue_worker(&fs_info->endio_write_workers,
 					   &end_io_wq->work);
@@ -497,6 +500,13 @@ static void end_workqueue_bio(struct bio *bio, int err)
 	}
 }
 
+/*
+ * For the metadata arg you want
+ *
+ * 0 - if data
+ * 1 - if normal metadta
+ * 2 - if writing to the free space cache area
+ */
 int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 			int metadata)
 {
@@ -1774,6 +1784,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->endio_write_workers, "endio-write",
 			   fs_info->thread_pool_size,
 			   &fs_info->generic_worker);
+	btrfs_init_workers(&fs_info->endio_freespace_worker, "freespace-write",
+			   1, &fs_info->generic_worker);
 
 	/*
 	 * endios are largely parallel and should have a very
@@ -1794,6 +1806,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->endio_meta_workers, 1);
 	btrfs_start_workers(&fs_info->endio_meta_write_workers, 1);
 	btrfs_start_workers(&fs_info->endio_write_workers, 1);
+	btrfs_start_workers(&fs_info->endio_freespace_worker, 1);
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
@@ -2035,6 +2048,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->endio_meta_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
+	btrfs_stop_workers(&fs_info->endio_freespace_worker);
 	btrfs_stop_workers(&fs_info->submit_workers);
 fail_iput:
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
@@ -2468,6 +2482,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->endio_meta_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
+	btrfs_stop_workers(&fs_info->endio_freespace_worker);
 	btrfs_stop_workers(&fs_info->submit_workers);
 
 	btrfs_close_devices(fs_info->fs_devices);

commit 0af3d00bad38d3bb9912a60928ad0669f17bdb76
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jun 21 14:48:16 2010 -0400

    Btrfs: create special free space cache inode
    
    In order to save free space cache, we need an inode to hold the data, and we
    need a special item to point at the right inode for the right block group.  So
    first, create a special item that will point to the right inode, and the number
    of extent entries we will have and the number of bitmaps we will have.  We
    truncate and pre-allocate space everytime to make sure it's uptodate.
    
    This feature will be turned on as soon as you mount with -o space_cache, however
    it is safe to boot into old kernels, they will just generate the cache the old
    fashion way.  When you boot back into a newer kernel we will notice that we
    modified and not the cache and automatically discard the cache.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 64f10082f048..45cf64fc1e3e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1685,7 +1685,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	__setup_root(4096, 4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
-
 	bh = btrfs_read_dev_super(fs_devices->latest_bdev);
 	if (!bh)
 		goto fail_iput;
@@ -1993,6 +1992,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!(sb->s_flags & MS_RDONLY)) {
 		down_read(&fs_info->cleanup_work_sem);
 		btrfs_orphan_cleanup(fs_info->fs_root);
+		btrfs_orphan_cleanup(fs_info->tree_root);
 		up_read(&fs_info->cleanup_work_sem);
 	}
 
@@ -2421,6 +2421,7 @@ int close_ctree(struct btrfs_root *root)
 	fs_info->closing = 1;
 	smp_mb();
 
+	btrfs_put_block_group_cache(fs_info);
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
 		ret =  btrfs_commit_super(root);
 		if (ret)

commit c3b9a62c8f932f32a733d6b628f61f3f28345727
Author: Christoph Hellwig <hch@infradead.org>
Date:   Wed Aug 18 05:29:12 2010 -0400

    btrfs: replace barriers with explicit flush / FUA usage
    
    Switch to the WRITE_FLUSH_FUA flag for log writes, remove the EOPNOTSUPP
    detection for barriers and stop setting the barrier flag for discards.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 64f10082f048..5e789f4a3ed0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2063,7 +2063,7 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 	if (uptodate) {
 		set_buffer_uptodate(bh);
 	} else {
-		if (!buffer_eopnotsupp(bh) && printk_ratelimit()) {
+		if (printk_ratelimit()) {
 			printk(KERN_WARNING "lost page write due to "
 					"I/O error on %s\n",
 				       bdevname(bh->b_bdev, b));
@@ -2200,21 +2200,10 @@ static int write_dev_supers(struct btrfs_device *device,
 			bh->b_end_io = btrfs_end_buffer_write_sync;
 		}
 
-		if (i == last_barrier && do_barriers && device->barriers) {
-			ret = submit_bh(WRITE_BARRIER, bh);
-			if (ret == -EOPNOTSUPP) {
-				printk("btrfs: disabling barriers on dev %s\n",
-				       device->name);
-				set_buffer_uptodate(bh);
-				device->barriers = 0;
-				/* one reference for submit_bh */
-				get_bh(bh);
-				lock_buffer(bh);
-				ret = submit_bh(WRITE_SYNC, bh);
-			}
-		} else {
+		if (i == last_barrier && do_barriers)
+			ret = submit_bh(WRITE_FLUSH_FUA, bh);
+		else
 			ret = submit_bh(WRITE_SYNC, bh);
-		}
 
 		if (ret)
 			errors++;

commit 7b6d91daee5cac6402186ff224c3af39d79f4a0e
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Aug 7 18:20:39 2010 +0200

    block: unify flags for struct bio and struct request
    
    Remove the current bio flags and reuse the request flags for the bio, too.
    This allows to more easily trace the type of I/O from the filesystem
    down to the block driver.  There were two flags in the bio that were
    missing in the requests:  BIO_RW_UNPLUG and BIO_RW_AHEAD.  Also I've
    renamed two request flags that had a superflous RW in them.
    
    Note that the flags are in bio.h despite having the REQ_ name - as
    blkdev.h includes bio.h that is the only way to go for now.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 34f7c375567e..64f10082f048 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -480,7 +480,7 @@ static void end_workqueue_bio(struct bio *bio, int err)
 	end_io_wq->work.func = end_workqueue_fn;
 	end_io_wq->work.flags = 0;
 
-	if (bio->bi_rw & (1 << BIO_RW)) {
+	if (bio->bi_rw & REQ_WRITE) {
 		if (end_io_wq->metadata)
 			btrfs_queue_worker(&fs_info->endio_meta_write_workers,
 					   &end_io_wq->work);
@@ -604,7 +604,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 
 	atomic_inc(&fs_info->nr_async_submits);
 
-	if (rw & (1 << BIO_RW_SYNCIO))
+	if (rw & REQ_SYNC)
 		btrfs_set_work_high_prio(&async->work);
 
 	btrfs_queue_worker(&fs_info->workers, &async->work);
@@ -668,7 +668,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 					  bio, 1);
 	BUG_ON(ret);
 
-	if (!(rw & (1 << BIO_RW))) {
+	if (!(rw & REQ_WRITE)) {
 		/*
 		 * called for a read, do the setup so that checksum validation
 		 * can happen in the async kernel threads
@@ -1427,7 +1427,7 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	 * ram and up to date before trying to verify things.  For
 	 * blocksize <= pagesize, it is basically a noop
 	 */
-	if (!(bio->bi_rw & (1 << BIO_RW)) && end_io_wq->metadata &&
+	if (!(bio->bi_rw & REQ_WRITE) && end_io_wq->metadata &&
 	    !bio_ready_for_csum(bio)) {
 		btrfs_queue_worker(&fs_info->endio_meta_workers,
 				   &end_io_wq->work);

commit 3140c9a34b44cd4013baae8704fdb34a93a44475
Author: Dan Carpenter <error27@gmail.com>
Date:   Sat May 29 09:44:10 2010 +0000

    Btrfs: btrfs_read_fs_root_no_name() returns ERR_PTRs
    
    btrfs_read_fs_root_no_name() returns ERR_PTRs on error so I added a
    check for that.  It's not clear to me if it can also return NULL
    pointers or not so I left the original NULL pointer check as is.
    
    Signed-off-by: Dan Carpenter <error27@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 73895baf6e07..34f7c375567e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1985,6 +1985,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
 	if (!fs_info->fs_root)
 		goto fail_trans_kthread;
+	if (IS_ERR(fs_info->fs_root)) {
+		err = PTR_ERR(fs_info->fs_root);
+		goto fail_trans_kthread;
+	}
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		down_read(&fs_info->cleanup_work_sem);

commit 676e4c86391936795c82ccd11ca9671ee6307936
Author: Dan Carpenter <error27@gmail.com>
Date:   Sat May 29 09:43:07 2010 +0000

    Btrfs: handle kzalloc() failure in open_ctree()
    
    Unwind and return -ENOMEM if the allocation fails here.
    
    Signed-off-by: Dan Carpenter <error27@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f3b287c22caf..73895baf6e07 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1941,8 +1941,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		     btrfs_level_size(tree_root,
 				      btrfs_super_log_root_level(disk_super));
 
-		log_tree_root = kzalloc(sizeof(struct btrfs_root),
-						      GFP_NOFS);
+		log_tree_root = kzalloc(sizeof(struct btrfs_root), GFP_NOFS);
+		if (!log_tree_root) {
+			err = -ENOMEM;
+			goto fail_trans_kthread;
+		}
 
 		__setup_root(nodesize, leafsize, sectorsize, stripesize,
 			     log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);

commit eaf25d933e64c2bf3c79b83e8820404f36fdfc52
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 25 09:48:28 2010 -0400

    Btrfs: use async helpers for DIO write checksumming
    
    The async helper threads offload crc work onto all the
    CPUs, and make streaming writes much faster.  This
    changes the O_DIRECT write code to use them.  The only
    small complication was that we need to pass in the
    logical offset in the file for each bio, because we can't
    find it in the bio's pages.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a8772b5a9cb5..f3b287c22caf 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -74,6 +74,11 @@ struct async_submit_bio {
 	int rw;
 	int mirror_num;
 	unsigned long bio_flags;
+	/*
+	 * bio_offset is optional, can be used if the pages in the bio
+	 * can't tell us where in the file the bio should go
+	 */
+	u64 bio_offset;
 	struct btrfs_work work;
 };
 
@@ -534,7 +539,8 @@ static void run_one_async_start(struct btrfs_work *work)
 	async = container_of(work, struct  async_submit_bio, work);
 	fs_info = BTRFS_I(async->inode)->root->fs_info;
 	async->submit_bio_start(async->inode, async->rw, async->bio,
-			       async->mirror_num, async->bio_flags);
+			       async->mirror_num, async->bio_flags,
+			       async->bio_offset);
 }
 
 static void run_one_async_done(struct btrfs_work *work)
@@ -556,7 +562,8 @@ static void run_one_async_done(struct btrfs_work *work)
 		wake_up(&fs_info->async_submit_wait);
 
 	async->submit_bio_done(async->inode, async->rw, async->bio,
-			       async->mirror_num, async->bio_flags);
+			       async->mirror_num, async->bio_flags,
+			       async->bio_offset);
 }
 
 static void run_one_async_free(struct btrfs_work *work)
@@ -570,6 +577,7 @@ static void run_one_async_free(struct btrfs_work *work)
 int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			int rw, struct bio *bio, int mirror_num,
 			unsigned long bio_flags,
+			u64 bio_offset,
 			extent_submit_bio_hook_t *submit_bio_start,
 			extent_submit_bio_hook_t *submit_bio_done)
 {
@@ -592,6 +600,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 
 	async->work.flags = 0;
 	async->bio_flags = bio_flags;
+	async->bio_offset = bio_offset;
 
 	atomic_inc(&fs_info->nr_async_submits);
 
@@ -627,7 +636,8 @@ static int btree_csum_one_bio(struct bio *bio)
 
 static int __btree_submit_bio_start(struct inode *inode, int rw,
 				    struct bio *bio, int mirror_num,
-				    unsigned long bio_flags)
+				    unsigned long bio_flags,
+				    u64 bio_offset)
 {
 	/*
 	 * when we're called for a write, we're already in the async
@@ -638,7 +648,8 @@ static int __btree_submit_bio_start(struct inode *inode, int rw,
 }
 
 static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
-				 int mirror_num, unsigned long bio_flags)
+				 int mirror_num, unsigned long bio_flags,
+				 u64 bio_offset)
 {
 	/*
 	 * when we're called for a write, we're already in the async
@@ -648,7 +659,8 @@ static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
 }
 
 static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
-				 int mirror_num, unsigned long bio_flags)
+				 int mirror_num, unsigned long bio_flags,
+				 u64 bio_offset)
 {
 	int ret;
 
@@ -671,6 +683,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 	 */
 	return btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
 				   inode, rw, bio, mirror_num, 0,
+				   bio_offset,
 				   __btree_submit_bio_start,
 				   __btree_submit_bio_done);
 }

commit 4a500fd178c89b96fa166a2d9e7855df33429841
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:59 2010 -0400

    Btrfs: Metadata ENOSPC handling for tree log
    
    Previous patches make the allocater return -ENOSPC if there is no
    unreserved free metadata space. This patch updates tree log code
    and various other places to propagate/handle the ENOSPC error.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 82955b73a962..a8772b5a9cb5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -972,42 +972,6 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 	return 0;
 }
 
-int btrfs_free_log_root_tree(struct btrfs_trans_handle *trans,
-			     struct btrfs_fs_info *fs_info)
-{
-	struct extent_buffer *eb;
-	struct btrfs_root *log_root_tree = fs_info->log_root_tree;
-	u64 start = 0;
-	u64 end = 0;
-	int ret;
-
-	if (!log_root_tree)
-		return 0;
-
-	while (1) {
-		ret = find_first_extent_bit(&log_root_tree->dirty_log_pages,
-				0, &start, &end, EXTENT_DIRTY | EXTENT_NEW);
-		if (ret)
-			break;
-
-		clear_extent_bits(&log_root_tree->dirty_log_pages, start, end,
-				  EXTENT_DIRTY | EXTENT_NEW, GFP_NOFS);
-	}
-	eb = fs_info->log_root_tree->node;
-
-	WARN_ON(btrfs_header_level(eb) != 0);
-	WARN_ON(btrfs_header_nritems(eb) != 0);
-
-	ret = btrfs_free_reserved_extent(fs_info->tree_root,
-				eb->start, eb->len);
-	BUG_ON(ret);
-
-	free_extent_buffer(eb);
-	kfree(fs_info->log_root_tree);
-	fs_info->log_root_tree = NULL;
-	return 0;
-}
-
 static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info)
 {

commit d68fc57b7e3245cfacf2e3b47acfed1946a11786
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:58 2010 -0400

    Btrfs: Metadata reservation for orphan inodes
    
    reserve metadata space for handling orphan inodes
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 309d8c08a640..82955b73a962 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -894,7 +894,8 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->ref_cows = 0;
 	root->track_dirty = 0;
 	root->in_radix = 0;
-	root->clean_orphans = 0;
+	root->orphan_item_inserted = 0;
+	root->orphan_cleanup_state = 0;
 
 	root->fs_info = fs_info;
 	root->objectid = objectid;
@@ -904,12 +905,13 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->in_sysfs = 0;
 	root->inode_tree = RB_ROOT;
 	root->block_rsv = NULL;
+	root->orphan_block_rsv = NULL;
 
 	INIT_LIST_HEAD(&root->dirty_list);
 	INIT_LIST_HEAD(&root->orphan_list);
 	INIT_LIST_HEAD(&root->root_list);
 	spin_lock_init(&root->node_lock);
-	spin_lock_init(&root->list_lock);
+	spin_lock_init(&root->orphan_lock);
 	spin_lock_init(&root->inode_lock);
 	spin_lock_init(&root->accounting_lock);
 	mutex_init(&root->objectid_mutex);
@@ -1193,19 +1195,23 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	if (root)
 		return root;
 
-	ret = btrfs_find_orphan_item(fs_info->tree_root, location->objectid);
-	if (ret == 0)
-		ret = -ENOENT;
-	if (ret < 0)
-		return ERR_PTR(ret);
-
 	root = btrfs_read_fs_root_no_radix(fs_info->tree_root, location);
 	if (IS_ERR(root))
 		return root;
 
-	WARN_ON(btrfs_root_refs(&root->root_item) == 0);
 	set_anon_super(&root->anon_super, NULL);
 
+	if (btrfs_root_refs(&root->root_item) == 0) {
+		ret = -ENOENT;
+		goto fail;
+	}
+
+	ret = btrfs_find_orphan_item(fs_info->tree_root, location->objectid);
+	if (ret < 0)
+		goto fail;
+	if (ret == 0)
+		root->orphan_item_inserted = 1;
+
 	ret = radix_tree_preload(GFP_NOFS & ~__GFP_HIGHMEM);
 	if (ret)
 		goto fail;
@@ -1214,10 +1220,9 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	ret = radix_tree_insert(&fs_info->fs_roots_radix,
 				(unsigned long)root->root_key.objectid,
 				root);
-	if (ret == 0) {
+	if (ret == 0)
 		root->in_radix = 1;
-		root->clean_orphans = 1;
-	}
+
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 	radix_tree_preload_end();
 	if (ret) {
@@ -1981,6 +1986,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	BUG_ON(ret);
 
 	if (!(sb->s_flags & MS_RDONLY)) {
+		ret = btrfs_cleanup_fs_roots(fs_info);
+		BUG_ON(ret);
+
 		ret = btrfs_recover_relocation(tree_root);
 		if (ret < 0) {
 			printk(KERN_WARNING

commit 8929ecfa50f266163832eeacfbc3642ed5eb83b6
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:58 2010 -0400

    Btrfs: Introduce global metadata reservation
    
    Reserve metadata space for extent tree, checksum tree and root tree
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 054b4475c757..309d8c08a640 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1463,10 +1463,6 @@ static int cleaner_kthread(void *arg)
 	struct btrfs_root *root = arg;
 
 	do {
-		smp_mb();
-		if (root->fs_info->closing)
-			break;
-
 		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
 
 		if (!(root->fs_info->sb->s_flags & MS_RDONLY) &&
@@ -1479,11 +1475,9 @@ static int cleaner_kthread(void *arg)
 		if (freezing(current)) {
 			refrigerator();
 		} else {
-			smp_mb();
-			if (root->fs_info->closing)
-				break;
 			set_current_state(TASK_INTERRUPTIBLE);
-			schedule();
+			if (!kthread_should_stop())
+				schedule();
 			__set_current_state(TASK_RUNNING);
 		}
 	} while (!kthread_should_stop());
@@ -1495,36 +1489,40 @@ static int transaction_kthread(void *arg)
 	struct btrfs_root *root = arg;
 	struct btrfs_trans_handle *trans;
 	struct btrfs_transaction *cur;
+	u64 transid;
 	unsigned long now;
 	unsigned long delay;
 	int ret;
 
 	do {
-		smp_mb();
-		if (root->fs_info->closing)
-			break;
-
 		delay = HZ * 30;
 		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
 		mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
-		mutex_lock(&root->fs_info->trans_mutex);
+		spin_lock(&root->fs_info->new_trans_lock);
 		cur = root->fs_info->running_transaction;
 		if (!cur) {
-			mutex_unlock(&root->fs_info->trans_mutex);
+			spin_unlock(&root->fs_info->new_trans_lock);
 			goto sleep;
 		}
 
 		now = get_seconds();
-		if (now < cur->start_time || now - cur->start_time < 30) {
-			mutex_unlock(&root->fs_info->trans_mutex);
+		if (!cur->blocked &&
+		    (now < cur->start_time || now - cur->start_time < 30)) {
+			spin_unlock(&root->fs_info->new_trans_lock);
 			delay = HZ * 5;
 			goto sleep;
 		}
-		mutex_unlock(&root->fs_info->trans_mutex);
-		trans = btrfs_join_transaction(root, 1);
-		ret = btrfs_commit_transaction(trans, root);
+		transid = cur->transid;
+		spin_unlock(&root->fs_info->new_trans_lock);
 
+		trans = btrfs_join_transaction(root, 1);
+		if (transid == trans->transid) {
+			ret = btrfs_commit_transaction(trans, root);
+			BUG_ON(ret);
+		} else {
+			btrfs_end_transaction(trans, root);
+		}
 sleep:
 		wake_up_process(root->fs_info->cleaner_kthread);
 		mutex_unlock(&root->fs_info->transaction_kthread_mutex);
@@ -1532,10 +1530,10 @@ static int transaction_kthread(void *arg)
 		if (freezing(current)) {
 			refrigerator();
 		} else {
-			if (root->fs_info->closing)
-				break;
 			set_current_state(TASK_INTERRUPTIBLE);
-			schedule_timeout(delay);
+			if (!kthread_should_stop() &&
+			    !btrfs_transaction_blocked(root->fs_info))
+				schedule_timeout(delay);
 			__set_current_state(TASK_RUNNING);
 		}
 	} while (!kthread_should_stop());
@@ -1917,17 +1915,18 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	csum_root->track_dirty = 1;
 
+	fs_info->generation = generation;
+	fs_info->last_trans_committed = generation;
+	fs_info->data_alloc_profile = (u64)-1;
+	fs_info->metadata_alloc_profile = (u64)-1;
+	fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
+
 	ret = btrfs_read_block_groups(extent_root);
 	if (ret) {
 		printk(KERN_ERR "Failed to read block groups: %d\n", ret);
 		goto fail_block_groups;
 	}
 
-	fs_info->generation = generation;
-	fs_info->last_trans_committed = generation;
-	fs_info->data_alloc_profile = (u64)-1;
-	fs_info->metadata_alloc_profile = (u64)-1;
-	fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
 	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
 					       "btrfs-cleaner");
 	if (IS_ERR(fs_info->cleaner_kthread))
@@ -2430,15 +2429,15 @@ int close_ctree(struct btrfs_root *root)
 	fs_info->closing = 1;
 	smp_mb();
 
-	kthread_stop(root->fs_info->transaction_kthread);
-	kthread_stop(root->fs_info->cleaner_kthread);
-
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
 		ret =  btrfs_commit_super(root);
 		if (ret)
 			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
 	}
 
+	kthread_stop(root->fs_info->transaction_kthread);
+	kthread_stop(root->fs_info->cleaner_kthread);
+
 	fs_info->closing = 2;
 	smp_mb();
 

commit a22285a6a32390195235171b89d157ed1a1fe932
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:48:46 2010 -0400

    Btrfs: Integrate metadata reservation with start_transaction
    
    Besides simplify the code, this change makes sure all metadata
    reservation for normal metadata operations are released after
    committing transaction.
    
    Changes since V1:
    
    Add code that check if unlink and rmdir will free space.
    
    Add ENOSPC handling for clone ioctl.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 574594cf6b51..054b4475c757 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1522,7 +1522,7 @@ static int transaction_kthread(void *arg)
 			goto sleep;
 		}
 		mutex_unlock(&root->fs_info->trans_mutex);
-		trans = btrfs_start_transaction(root, 1);
+		trans = btrfs_join_transaction(root, 1);
 		ret = btrfs_commit_transaction(trans, root);
 
 sleep:
@@ -2409,11 +2409,11 @@ int btrfs_commit_super(struct btrfs_root *root)
 	down_write(&root->fs_info->cleanup_work_sem);
 	up_write(&root->fs_info->cleanup_work_sem);
 
-	trans = btrfs_start_transaction(root, 1);
+	trans = btrfs_join_transaction(root, 1);
 	ret = btrfs_commit_transaction(trans, root);
 	BUG_ON(ret);
 	/* run commit again to drop the original snapshot */
-	trans = btrfs_start_transaction(root, 1);
+	trans = btrfs_join_transaction(root, 1);
 	btrfs_commit_transaction(trans, root);
 	ret = btrfs_write_and_wait_transaction(NULL, root);
 	BUG_ON(ret);

commit f0486c68e4bd9a06a5904d3eeb3a0d73a83befb8
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:46:25 2010 -0400

    Btrfs: Introduce contexts for metadata reservation
    
    Introducing metadata reseravtion contexts has two major advantages.
    First, it makes metadata reseravtion more traceable. Second, it can
    reclaim freed space and re-add them to the itself after transaction
    committed.
    
    Besides add btrfs_block_rsv structure and related helper functions,
    This patch contains following changes:
    
    Move code that decides if freed tree block should be pinned into
    btrfs_free_tree_block().
    
    Make space accounting more accurate, mainly for handling read only
    block groups.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 05f26acfd070..574594cf6b51 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -903,6 +903,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->name = NULL;
 	root->in_sysfs = 0;
 	root->inode_tree = RB_ROOT;
+	root->block_rsv = NULL;
 
 	INIT_LIST_HEAD(&root->dirty_list);
 	INIT_LIST_HEAD(&root->orphan_list);
@@ -910,6 +911,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	spin_lock_init(&root->node_lock);
 	spin_lock_init(&root->list_lock);
 	spin_lock_init(&root->inode_lock);
+	spin_lock_init(&root->accounting_lock);
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
 	init_waitqueue_head(&root->log_writer_wait);
@@ -1620,6 +1622,13 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
 	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);
+	btrfs_init_block_rsv(&fs_info->global_block_rsv);
+	btrfs_init_block_rsv(&fs_info->delalloc_block_rsv);
+	btrfs_init_block_rsv(&fs_info->trans_block_rsv);
+	btrfs_init_block_rsv(&fs_info->chunk_block_rsv);
+	btrfs_init_block_rsv(&fs_info->empty_block_rsv);
+	INIT_LIST_HEAD(&fs_info->durable_block_rsv_list);
+	mutex_init(&fs_info->durable_block_rsv_mutex);
 	atomic_set(&fs_info->nr_async_submits, 0);
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);

commit 5da9d01b66458b180a6bee0e637a1d0a3effc622
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:46:25 2010 -0400

    Btrfs: Shrink delay allocated space in a synchronized
    
    Shrink delayed allocation space in a synchronized manner is more
    controllable than flushing all delay allocated space in an async
    thread.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index feca04197d02..05f26acfd070 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1759,9 +1759,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			   min_t(u64, fs_devices->num_devices,
 			   fs_info->thread_pool_size),
 			   &fs_info->generic_worker);
-	btrfs_init_workers(&fs_info->enospc_workers, "enospc",
-			   fs_info->thread_pool_size,
-			   &fs_info->generic_worker);
 
 	/* a higher idle thresh on the submit workers makes it much more
 	 * likely that bios will be send down in a sane order to the
@@ -1809,7 +1806,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->endio_meta_workers, 1);
 	btrfs_start_workers(&fs_info->endio_meta_write_workers, 1);
 	btrfs_start_workers(&fs_info->endio_write_workers, 1);
-	btrfs_start_workers(&fs_info->enospc_workers, 1);
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
@@ -2040,7 +2036,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
-	btrfs_stop_workers(&fs_info->enospc_workers);
 fail_iput:
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
@@ -2473,7 +2468,6 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
-	btrfs_stop_workers(&fs_info->enospc_workers);
 
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);

commit e6d086d83cf7f102d48c006f58172a69ec0c15a4
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Mon Apr 26 10:27:54 2010 +0200

    btrfs: convert to using bdi_setup_and_register()
    
    It's now a provided helper, so get rid of the internal setup
    and btrfs atomic_t bdi enumerator.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e7b8f2c89ccb..feca04197d02 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -44,8 +44,6 @@ static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 static void free_fs_root(struct btrfs_root *root);
 
-static atomic_t btrfs_bdi_num = ATOMIC_INIT(0);
-
 /*
  * end_io_wq structs are used to do processing in task context when an IO is
  * complete.  This is used during reads to verify checksums, and it is used
@@ -1375,19 +1373,11 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 {
 	int err;
 
-	bdi->name = "btrfs";
 	bdi->capabilities = BDI_CAP_MAP_COPY;
-	err = bdi_init(bdi);
+	err = bdi_setup_and_register(bdi, "btrfs", BDI_CAP_MAP_COPY);
 	if (err)
 		return err;
 
-	err = bdi_register(bdi, NULL, "btrfs-%d",
-				atomic_inc_return(&btrfs_bdi_num));
-	if (err) {
-		bdi_destroy(bdi);
-		return err;
-	}
-
 	bdi->ra_pages	= default_backing_dev_info.ra_pages;
 	bdi->unplug_io_fn	= btrfs_unplug_io_fn;
 	bdi->unplug_io_data	= info;

commit 795d580baec0d5386b83a8b557df47c20810e86b
Merge: 449cedf099b2 109f6aef5fc4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 5 13:21:15 2010 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: add check for changed leaves in setup_leaf_for_split
      Btrfs: create snapshot references in same commit as snapshot
      Btrfs: fix small race with delalloc flushing waitqueue's
      Btrfs: use add_to_page_cache_lru, use __page_cache_alloc
      Btrfs: fix chunk allocate size calculation
      Btrfs: kill max_extent mount option
      Btrfs: fail to mount if we have problems reading the block groups
      Btrfs: check btrfs_get_extent return for IS_ERR()
      Btrfs: handle kmalloc() failure in inode lookup ioctl
      Btrfs: dereferencing freed memory
      Btrfs: Simplify num_stripes's calculation logical for __btrfs_alloc_chunk()
      Btrfs: Add error handle for btrfs_search_slot() in btrfs_read_chunk_tree()
      Btrfs: Remove unnecessary finish_wait() in wait_current_trans()
      Btrfs: add NULL check for do_walk_down()
      Btrfs: remove duplicate include in ioctl.c
    
    Fix trivial conflict in fs/btrfs/compression.c due to slab.h include
    cleanups.

commit 287a0ab91d25ca982f895a76402e5893b47ed7a6
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Mar 19 18:07:23 2010 +0000

    Btrfs: kill max_extent mount option
    
    As Yan pointed out, theres not much reason for all this complicated math to
    account for file extents being split up into max_extent chunks, since they are
    likely to all end up in the same leaf anyway.  Since there isn't much reason to
    use max_extent, just remove the option altogether so we have one less thing we
    need to test.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5ae1c0fcfce0..6632e5c4c8bb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1634,7 +1634,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
 	fs_info->sb = sb;
-	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
 	fs_info->metadata_ratio = 0;
 

commit 1b1d1f6625e517a08640ddb4b8f8a0e025243fe3
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Mar 19 20:49:55 2010 +0000

    Btrfs: fail to mount if we have problems reading the block groups
    
    We don't actually check the return value of btrfs_read_block_groups, so we can
    possibly succeed to mount, but then fail to say read the superblock xattr for
    selinux which will cause the vfs code to deactivate the super.
    
    This is a problem because in find_free_extent we just assume that we
    will find the right space_info for the allocation we want.  But if we
    failed to read the block groups, we won't have setup any space_info's,
    and we'll hit a NULL pointer deref in find_free_extent.
    
    This patch fixes that problem by checking the return value of
    btrfs_read_block_groups, and failing out properly.  I've also added a
    check in find_free_extent so if for some reason we don't find an
    appropriate space_info, we just return -ENOSPC.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 11d0ad30e203..5ae1c0fcfce0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1922,7 +1922,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	csum_root->track_dirty = 1;
 
-	btrfs_read_block_groups(extent_root);
+	ret = btrfs_read_block_groups(extent_root);
+	if (ret) {
+		printk(KERN_ERR "Failed to read block groups: %d\n", ret);
+		goto fail_block_groups;
+	}
 
 	fs_info->generation = generation;
 	fs_info->last_trans_committed = generation;
@@ -1932,7 +1936,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
 					       "btrfs-cleaner");
 	if (IS_ERR(fs_info->cleaner_kthread))
-		goto fail_csum_root;
+		goto fail_block_groups;
 
 	fs_info->transaction_kthread = kthread_run(transaction_kthread,
 						   tree_root,
@@ -2020,7 +2024,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 
-fail_csum_root:
+fail_block_groups:
+	btrfs_free_block_groups(fs_info);
 	free_extent_buffer(csum_root->node);
 	free_extent_buffer(csum_root->commit_root);
 fail_dev_root:

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 11d0ad30e203..e57ded75d910 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -27,6 +27,7 @@
 #include <linux/kthread.h>
 #include <linux/freezer.h>
 #include <linux/crc32c.h>
+#include <linux/slab.h>
 #include "compat.h"
 #include "ctree.h"
 #include "disk-io.h"

commit 2ac55d41b5d6bf49e76bc85db5431240617e2f8f
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Feb 3 19:33:23 2010 +0000

    Btrfs: cache the extent state everywhere we possibly can V2
    
    This patch just goes through and fixes everybody that does
    
    lock_extent()
    blah
    unlock_extent()
    
    to use
    
    lock_extent_bits()
    blah
    unlock_extent_cached()
    
    and pass around a extent_state so we only have to do the searches once per
    function.  This gives me about a 3 mb/s boots on my random write test.  I have
    not converted some things, like the relocation and ioctl's, since they aren't
    heavily used and the relocation stuff is in the middle of being re-written.  I
    also changed the clear_extent_bit() to only unset the cached state if we are
    clearing EXTENT_LOCKED and related stuff, so we can do things like this
    
    lock_extent_bits()
    clear delalloc bits
    unlock_extent_cached()
    
    without losing our cached state.  I tested this thoroughly and turned on
    LEAK_DEBUG to make sure we weren't leaking extent states, everything worked out
    fine.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0427183e3e05..11d0ad30e203 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -263,13 +263,15 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 static int verify_parent_transid(struct extent_io_tree *io_tree,
 				 struct extent_buffer *eb, u64 parent_transid)
 {
+	struct extent_state *cached_state = NULL;
 	int ret;
 
 	if (!parent_transid || btrfs_header_generation(eb) == parent_transid)
 		return 0;
 
-	lock_extent(io_tree, eb->start, eb->start + eb->len - 1, GFP_NOFS);
-	if (extent_buffer_uptodate(io_tree, eb) &&
+	lock_extent_bits(io_tree, eb->start, eb->start + eb->len - 1,
+			 0, &cached_state, GFP_NOFS);
+	if (extent_buffer_uptodate(io_tree, eb, cached_state) &&
 	    btrfs_header_generation(eb) == parent_transid) {
 		ret = 0;
 		goto out;
@@ -282,10 +284,10 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		       (unsigned long long)btrfs_header_generation(eb));
 	}
 	ret = 1;
-	clear_extent_buffer_uptodate(io_tree, eb);
+	clear_extent_buffer_uptodate(io_tree, eb, &cached_state);
 out:
-	unlock_extent(io_tree, eb->start, eb->start + eb->len - 1,
-		      GFP_NOFS);
+	unlock_extent_cached(io_tree, eb->start, eb->start + eb->len - 1,
+			     &cached_state, GFP_NOFS);
 	return ret;
 }
 
@@ -2497,7 +2499,8 @@ int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid)
 	int ret;
 	struct inode *btree_inode = buf->first_page->mapping->host;
 
-	ret = extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree, buf);
+	ret = extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree, buf,
+				     NULL);
 	if (!ret)
 		return ret;
 

commit 6bef4d317193d3badbbfa3f3c593758ace84a629
Author: Eric Paris <eparis@redhat.com>
Date:   Tue Feb 23 19:43:04 2010 +0000

    Btrfs: use RB_ROOT to intialize rb_trees instead of setting rb_node to NULL
    
    btrfs inialize rb trees in quite a number of places by settin rb_node =
    NULL;  The problem with this is that 17d9ddc72fb8bba0d4f678 in the
    linux-next tree adds a new field to that struct which needs to be NULL for
    the new rbtree library code to work properly.  This patch uses RB_ROOT as
    the intializer so all of the relevant fields will be NULL'd.  Without the
    patch I get a panic.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2b59201b955c..0427183e3e05 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -901,7 +901,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->highest_objectid = 0;
 	root->name = NULL;
 	root->in_sysfs = 0;
-	root->inode_tree.rb_node = NULL;
+	root->inode_tree = RB_ROOT;
 
 	INIT_LIST_HEAD(&root->dirty_list);
 	INIT_LIST_HEAD(&root->orphan_list);
@@ -1673,7 +1673,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	insert_inode_hash(fs_info->btree_inode);
 
 	spin_lock_init(&fs_info->block_group_cache_lock);
-	fs_info->block_group_cache_tree.rb_node = NULL;
+	fs_info->block_group_cache_tree = RB_ROOT;
 
 	extent_io_tree_init(&fs_info->freed_extents[0],
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);

commit d7ce5843bb28ada6845ab2ae8510ba3f12d33154
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Feb 2 08:46:44 2010 +0000

    Btrfs: remove BUG_ON() due to mounting bad filesystem
    
    Mounting a bad filesystem caused a BUG_ON(). The following is steps to
    reproduce it.
     # mkfs.btrfs /dev/sda2
     # mount /dev/sda2 /mnt
     # mkfs.btrfs /dev/sda1 /dev/sda2
     (the program says that /dev/sda2 was mounted, and then exits. )
     # umount /mnt
     # mount /dev/sda1 /mnt
    
    At the third step, mkfs.btrfs exited in the way of make filesystem. So the
    initialization of the filesystem didn't finish. So the filesystem was bad, and
    it caused BUG_ON() when mounting it. But BUG_ON() should be called by the wrong
    code, not user's operation, so I think it is a bug of btrfs.
    
    This patch fixes it.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 87b25543d7d1..2b59201b955c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1982,7 +1982,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_recover_relocation(tree_root);
-		BUG_ON(ret);
+		if (ret < 0) {
+			printk(KERN_WARNING
+			       "btrfs: failed to recover relocation\n");
+			err = -EINVAL;
+			goto fail_trans_kthread;
+		}
 	}
 
 	location.objectid = BTRFS_FS_TREE_OBJECTID;

commit e3acc2a6850efff647f1c5458524eb3a8bcba20a
Author: Josef Bacik <josef@redhat.com>
Date:   Tue Jan 26 14:30:53 2010 +0000

    Btrfs: run orphan cleanup on default fs root
    
    This patch revert's commit
    
    6c090a11e1c403b727a6a8eff0b97d5fb9e95cb5
    
    Since it introduces this problem where we can run orphan cleanup on a
    volume that can have orphan entries re-added.  Instead of my original
    fix, Yan Zheng pointed out that we can just revert my original fix and
    then run the orphan cleanup in open_ctree after we look up the fs_root.
    I have tested this with all the tests that gave me problems and this
    patch fixes both problems.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 009e3bd18f23..87b25543d7d1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1993,6 +1993,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!fs_info->fs_root)
 		goto fail_trans_kthread;
 
+	if (!(sb->s_flags & MS_RDONLY)) {
+		down_read(&fs_info->cleanup_work_sem);
+		btrfs_orphan_cleanup(fs_info->fs_root);
+		up_read(&fs_info->cleanup_work_sem);
+	}
+
 	return tree_root;
 
 fail_trans_kthread:

commit 24bbcf0442ee04660a5a030efdbb6d03f1c275cb
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:36:34 2009 +0000

    Btrfs: Add delayed iput
    
    iput() can trigger new transactions if we are dropping the
    final reference, so calling it in btrfs_commit_transaction
    may end up deadlock. This patch adds delayed iput to avoid
    the issue.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c1e59e33f020..009e3bd18f23 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1476,6 +1476,7 @@ static int cleaner_kthread(void *arg)
 
 		if (!(root->fs_info->sb->s_flags & MS_RDONLY) &&
 		    mutex_trylock(&root->fs_info->cleaner_mutex)) {
+			btrfs_run_delayed_iputs(root);
 			btrfs_clean_old_snapshots(root);
 			mutex_unlock(&root->fs_info->cleaner_mutex);
 		}
@@ -1605,6 +1606,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
+	INIT_LIST_HEAD(&fs_info->delayed_iputs);
 	INIT_LIST_HEAD(&fs_info->hashers);
 	INIT_LIST_HEAD(&fs_info->delalloc_inodes);
 	INIT_LIST_HEAD(&fs_info->ordered_operations);
@@ -1613,6 +1615,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->new_trans_lock);
 	spin_lock_init(&fs_info->ref_cache_lock);
 	spin_lock_init(&fs_info->fs_roots_radix_lock);
+	spin_lock_init(&fs_info->delayed_iput_lock);
 
 	init_completion(&fs_info->kobj_unregister);
 	fs_info->tree_root = tree_root;
@@ -2386,6 +2389,7 @@ int btrfs_commit_super(struct btrfs_root *root)
 	int ret;
 
 	mutex_lock(&root->fs_info->cleaner_mutex);
+	btrfs_run_delayed_iputs(root);
 	btrfs_clean_old_snapshots(root);
 	mutex_unlock(&root->fs_info->cleaner_mutex);
 

commit c71bf099abddf3e0fdc27f251ba76fca1461d49a
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:34:40 2009 +0000

    Btrfs: Avoid orphan inodes cleanup while replaying log
    
    We do log replay in a single transaction, so it's not good to do unbound
    operations. This patch cleans up orphan inodes cleanup after replaying
    the log. It also avoids doing other unbound operations such as truncating
    a file during replaying log. These unbound operations are postponed to
    the orphan inode cleanup stage.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 101940fab9b3..c1e59e33f020 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -892,6 +892,8 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->stripesize = stripesize;
 	root->ref_cows = 0;
 	root->track_dirty = 0;
+	root->in_radix = 0;
+	root->clean_orphans = 0;
 
 	root->fs_info = fs_info;
 	root->objectid = objectid;
@@ -928,7 +930,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->defrag_trans_start = fs_info->generation;
 	init_completion(&root->kobj_unregister);
 	root->defrag_running = 0;
-	root->defrag_level = 0;
 	root->root_key.objectid = objectid;
 	root->anon_super.s_root = NULL;
 	root->anon_super.s_dev = 0;
@@ -1210,8 +1211,10 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	ret = radix_tree_insert(&fs_info->fs_roots_radix,
 				(unsigned long)root->root_key.objectid,
 				root);
-	if (ret == 0)
+	if (ret == 0) {
 		root->in_radix = 1;
+		root->clean_orphans = 1;
+	}
 	spin_unlock(&fs_info->fs_roots_radix_lock);
 	radix_tree_preload_end();
 	if (ret) {
@@ -1225,10 +1228,6 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	ret = btrfs_find_dead_roots(fs_info->tree_root,
 				    root->root_key.objectid);
 	WARN_ON(ret);
-
-	if (!(fs_info->sb->s_flags & MS_RDONLY))
-		btrfs_orphan_cleanup(root);
-
 	return root;
 fail:
 	free_fs_root(root);
@@ -1689,6 +1688,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->cleaner_mutex);
 	mutex_init(&fs_info->volume_mutex);
 	init_rwsem(&fs_info->extent_commit_sem);
+	init_rwsem(&fs_info->cleanup_work_sem);
 	init_rwsem(&fs_info->subvol_sem);
 
 	btrfs_init_free_cluster(&fs_info->meta_alloc_cluster);
@@ -2388,6 +2388,11 @@ int btrfs_commit_super(struct btrfs_root *root)
 	mutex_lock(&root->fs_info->cleaner_mutex);
 	btrfs_clean_old_snapshots(root);
 	mutex_unlock(&root->fs_info->cleaner_mutex);
+
+	/* wait until ongoing cleanup work done */
+	down_write(&root->fs_info->cleanup_work_sem);
+	up_write(&root->fs_info->cleanup_work_sem);
+
 	trans = btrfs_start_transaction(root, 1);
 	ret = btrfs_commit_transaction(trans, root);
 	BUG_ON(ret);

commit 8cef4e160d74920ad1725f58c89fd75ec4c4ac38
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:33:26 2009 +0000

    Btrfs: Avoid superfluous tree-log writeout
    
    We allow two log transactions at a time, but use same flag
    to mark dirty tree-log btree blocks. So we may flush dirty
    blocks belonging to newer log transaction when committing a
    log transaction. This patch fixes the issue by using two
    flags to mark dirty tree-log btree blocks.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 02b6afbd7450..101940fab9b3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -980,12 +980,12 @@ int btrfs_free_log_root_tree(struct btrfs_trans_handle *trans,
 
 	while (1) {
 		ret = find_first_extent_bit(&log_root_tree->dirty_log_pages,
-				    0, &start, &end, EXTENT_DIRTY);
+				0, &start, &end, EXTENT_DIRTY | EXTENT_NEW);
 		if (ret)
 			break;
 
-		clear_extent_dirty(&log_root_tree->dirty_log_pages,
-				   start, end, GFP_NOFS);
+		clear_extent_bits(&log_root_tree->dirty_log_pages, start, end,
+				  EXTENT_DIRTY | EXTENT_NEW, GFP_NOFS);
 	}
 	eb = fs_info->log_root_tree->node;
 

commit dcbeb0bec5f2695c3ff53f174efb8e03c209f3f3
Merge: 2b650df2cea9 444528b3e614
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 15 15:06:37 2009 -0700

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: always pin metadata in discard mode
      Btrfs: enable discard support
      Btrfs: add -o discard option
      Btrfs: properly wait log writers during log sync
      Btrfs: fix possible ENOSPC problems with truncate
      Btrfs: fix btrfs acl #ifdef checks
      Btrfs: streamline tree-log btree block writeout
      Btrfs: avoid tree log commit when there are no changes
      Btrfs: only write one super copy during fsync

commit 257c62e1bce03e5b9f3f069fd52ad73a56de71fd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Oct 13 13:21:08 2009 -0400

    Btrfs: avoid tree log commit when there are no changes
    
    rpm has a habit of running fdatasync when the file hasn't
    changed.  We already detect if a file hasn't been changed
    in the current transaction but it might have been sent to
    the tree-log in this transaction and not changed since
    the last call to fsync.
    
    In this case, we want to avoid a tree log sync, which includes
    a number of synchronous writes and barriers.  This commit
    extends the existing tracking of the last transaction to change
    a file to also track the last sub-transaction.
    
    The end result is that rpm -ivh and -Uvh are roughly twice as fast,
    and on par with ext3.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ac8927bdc33d..d4132aad9ea1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -919,6 +919,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	atomic_set(&root->log_writers, 0);
 	root->log_batch = 0;
 	root->log_transid = 0;
+	root->last_log_commit = 0;
 	extent_io_tree_init(&root->dirty_log_pages,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 
@@ -1089,6 +1090,7 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	WARN_ON(root->log_root);
 	root->log_root = log_root;
 	root->log_transid = 0;
+	root->last_log_commit = 0;
 	return 0;
 }
 

commit 474a503d4bf77ae0cbe484dd0842a2648c0b1c28
Merge: d43c36dc6b35 ac6889cbb254
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Oct 11 11:23:13 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: fix file clone ioctl for bookend extents
      Btrfs: fix uninit compiler warning in cow_file_range_nocow
      Btrfs: constify dentry_operations
      Btrfs: optimize back reference update during btrfs_drop_snapshot
      Btrfs: remove negative dentry when deleting subvolumne
      Btrfs: optimize fsync for the single writer case
      Btrfs: async delalloc flushing under space pressure
      Btrfs: release delalloc reservations on extent item insertion
      Btrfs: delay clearing EXTENT_DELALLOC for compressed extents
      Btrfs: cleanup extent_clear_unlock_delalloc flags
      Btrfs: fix possible softlockup in the allocator
      Btrfs: fix deadlock on async thread startup

commit e3ccfa989752c083ceb23c823a84f7ce3a081e61
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Oct 7 20:44:34 2009 -0400

    Btrfs: async delalloc flushing under space pressure
    
    This patch moves the delalloc flushing that occurs when we are under space
    pressure off to a async thread pool.  This helps since we only free up
    metadata space when we actually insert the extent item, which means it takes
    quite a while for space to be free'ed up if we wait on all ordered extents.
    However, if space is freed up due to inline extents being inserted, we can
    wake people who are waiting up early, and they can finish their work.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9903f042765d..ac8927bdc33d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1762,6 +1762,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			   min_t(u64, fs_devices->num_devices,
 			   fs_info->thread_pool_size),
 			   &fs_info->generic_worker);
+	btrfs_init_workers(&fs_info->enospc_workers, "enospc",
+			   fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 
 	/* a higher idle thresh on the submit workers makes it much more
 	 * likely that bios will be send down in a sane order to the
@@ -1809,6 +1812,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->endio_meta_workers, 1);
 	btrfs_start_workers(&fs_info->endio_meta_write_workers, 1);
 	btrfs_start_workers(&fs_info->endio_write_workers, 1);
+	btrfs_start_workers(&fs_info->enospc_workers, 1);
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
@@ -2023,6 +2027,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
+	btrfs_stop_workers(&fs_info->enospc_workers);
 fail_iput:
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
@@ -2449,6 +2454,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
+	btrfs_stop_workers(&fs_info->enospc_workers);
 
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);

commit 61d92c328c16419fc96dc50dd16f8b8c695409ec
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Oct 2 19:11:56 2009 -0400

    Btrfs: fix deadlock on async thread startup
    
    The btrfs async worker threads are used for a wide variety of things,
    including processing bio end_io functions.  This means that when
    the endio threads aren't running, the rest of the FS isn't
    able to do the final processing required to clear PageWriteback.
    
    The endio threads also try to exit as they become idle and
    start more as the work piles up.  The problem is that starting more
    threads means kthreadd may need to allocate ram, and that allocation
    may wait until the global number of writeback pages on the system is
    below a certain limit.
    
    The result of that throttling is that end IO threads wait on
    kthreadd, who is waiting on IO to end, which will never happen.
    
    This commit fixes the deadlock by handing off thread startup to a
    dedicated thread.  It also fixes a bug where the on-demand thread
    creation was creating far too many threads because it didn't take into
    account threads being started by other procs.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 69dce50aabd2..9903f042765d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1746,21 +1746,22 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		err = -EINVAL;
 		goto fail_iput;
 	}
-printk("thread pool is %d\n", fs_info->thread_pool_size);
-	/*
-	 * we need to start all the end_io workers up front because the
-	 * queue work function gets called at interrupt time, and so it
-	 * cannot dynamically grow.
-	 */
+
+	btrfs_init_workers(&fs_info->generic_worker,
+			   "genwork", 1, NULL);
+
 	btrfs_init_workers(&fs_info->workers, "worker",
-			   fs_info->thread_pool_size);
+			   fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 
 	btrfs_init_workers(&fs_info->delalloc_workers, "delalloc",
-			   fs_info->thread_pool_size);
+			   fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 
 	btrfs_init_workers(&fs_info->submit_workers, "submit",
 			   min_t(u64, fs_devices->num_devices,
-			   fs_info->thread_pool_size));
+			   fs_info->thread_pool_size),
+			   &fs_info->generic_worker);
 
 	/* a higher idle thresh on the submit workers makes it much more
 	 * likely that bios will be send down in a sane order to the
@@ -1774,15 +1775,20 @@ printk("thread pool is %d\n", fs_info->thread_pool_size);
 	fs_info->delalloc_workers.idle_thresh = 2;
 	fs_info->delalloc_workers.ordered = 1;
 
-	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1);
+	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1,
+			   &fs_info->generic_worker);
 	btrfs_init_workers(&fs_info->endio_workers, "endio",
-			   fs_info->thread_pool_size);
+			   fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 	btrfs_init_workers(&fs_info->endio_meta_workers, "endio-meta",
-			   fs_info->thread_pool_size);
+			   fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 	btrfs_init_workers(&fs_info->endio_meta_write_workers,
-			   "endio-meta-write", fs_info->thread_pool_size);
+			   "endio-meta-write", fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 	btrfs_init_workers(&fs_info->endio_write_workers, "endio-write",
-			   fs_info->thread_pool_size);
+			   fs_info->thread_pool_size,
+			   &fs_info->generic_worker);
 
 	/*
 	 * endios are largely parallel and should have a very
@@ -1794,12 +1800,8 @@ printk("thread pool is %d\n", fs_info->thread_pool_size);
 	fs_info->endio_write_workers.idle_thresh = 2;
 	fs_info->endio_meta_write_workers.idle_thresh = 2;
 
-	fs_info->endio_workers.atomic_worker_start = 1;
-	fs_info->endio_meta_workers.atomic_worker_start = 1;
-	fs_info->endio_write_workers.atomic_worker_start = 1;
-	fs_info->endio_meta_write_workers.atomic_worker_start = 1;
-
 	btrfs_start_workers(&fs_info->workers, 1);
+	btrfs_start_workers(&fs_info->generic_worker, 1);
 	btrfs_start_workers(&fs_info->submit_workers, 1);
 	btrfs_start_workers(&fs_info->delalloc_workers, 1);
 	btrfs_start_workers(&fs_info->fixup_workers, 1);
@@ -2012,6 +2014,7 @@ printk("thread pool is %d\n", fs_info->thread_pool_size);
 	free_extent_buffer(chunk_root->node);
 	free_extent_buffer(chunk_root->commit_root);
 fail_sb_buffer:
+	btrfs_stop_workers(&fs_info->generic_worker);
 	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->delalloc_workers);
 	btrfs_stop_workers(&fs_info->workers);
@@ -2437,6 +2440,7 @@ int close_ctree(struct btrfs_root *root)
 
 	iput(fs_info->btree_inode);
 
+	btrfs_stop_workers(&fs_info->generic_worker);
 	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->delalloc_workers);
 	btrfs_stop_workers(&fs_info->workers);

commit 8aa38c31b7659e338fee4d9af4c3805acbd9806f
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Oct 1 12:58:30 2009 -0400

    Btrfs: remove duplicates of filemap_ helpers
    
    Use filemap_fdatawrite_range and filemap_fdatawait_range instead of
    local copies of the functions.  For filemap_fdatawait_range that
    also means replacing the awkward old wait_on_page_writeback_range
    calling convention with the regular filemap byte offsets.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d20dc05208fe..af0435f79fa6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -822,16 +822,14 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 
 int btrfs_write_tree_block(struct extent_buffer *buf)
 {
-	return btrfs_fdatawrite_range(buf->first_page->mapping, buf->start,
-				      buf->start + buf->len - 1, WB_SYNC_ALL);
+	return filemap_fdatawrite_range(buf->first_page->mapping, buf->start,
+					buf->start + buf->len - 1);
 }
 
 int btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
 {
-	return btrfs_wait_on_page_writeback_range(buf->first_page->mapping,
-				  buf->start >> PAGE_CACHE_SHIFT,
-				  (buf->start + buf->len - 1) >>
-				   PAGE_CACHE_SHIFT);
+	return filemap_fdatawait_range(buf->first_page->mapping,
+				       buf->start, buf->start + buf->len - 1);
 }
 
 struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,

commit 25472b880c69c0daa485c4f80a6550437ed1149f
Merge: 17d857be649a ab93dbecfba7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Oct 1 12:58:13 2009 -0400

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable into for-linus

commit 35d62a942db5ae03104929fe7397835b572c4bc4
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Sep 30 16:47:08 2009 -0400

    Btrfs: fix arguments to btrfs_wait_on_page_writeback_range
    
    wait_on_page_writeback_range/btrfs_wait_on_page_writeback_range takes
    a pagecache offset, not a byte offset into the file.  Shift the arguments
    around to wait for the correct range
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ece8d1e26b5e..69dce50aabd2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -829,7 +829,9 @@ int btrfs_write_tree_block(struct extent_buffer *buf)
 int btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
 {
 	return btrfs_wait_on_page_writeback_range(buf->first_page->mapping,
-				  buf->start, buf->start + buf->len - 1);
+				  buf->start >> PAGE_CACHE_SHIFT,
+				  (buf->start + buf->len - 1) >>
+				   PAGE_CACHE_SHIFT);
 }
 
 struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,

commit 9ed74f2dba6ebf9f30b80554290bfc73cc3ef083
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Sep 11 16:12:44 2009 -0400

    Btrfs: proper -ENOSPC handling
    
    At the start of a transaction we do a btrfs_reserve_metadata_space() and
    specify how many items we plan on modifying.  Then once we've done our
    modifications and such, just call btrfs_unreserve_metadata_space() for
    the same number of items we reserved.
    
    For keeping track of metadata needed for data I've had to add an extent_io op
    for when we merge extents.  This lets us track space properly when we are doing
    sequential writes, so we don't end up reserving way more metadata space than
    what we need.
    
    The only place where the metadata space accounting is not done is in the
    relocation code.  This is because Yan is going to be reworking that code in the
    near future, so running btrfs-vol -b could still possibly result in a ENOSPC
    related panic.  This patch also turns off the metadata_ratio stuff in order to
    allow users to more efficiently use their disk space.
    
    This patch makes it so we track how much metadata we need for an inode's
    delayed allocation extents by tracking how many extents are currently
    waiting for allocation.  It introduces two new callbacks for the
    extent_io tree's, merge_extent_hook and split_extent_hook.  These help
    us keep track of when we merge delalloc extents together and split them
    up.  Reservations are handled prior to any actually dirty'ing occurs,
    and then we unreserve after we dirty.
    
    btrfs_unreserve_metadata_for_delalloc() will make the appropriate
    unreservations as needed based on the number of reservations we
    currently have and the number of extents we currently have.  Doing the
    reservation outside of doing any of the actual dirty'ing lets us do
    things like filemap_flush() the inode to try and force delalloc to
    happen, or as a last resort actually start allocation on all delalloc
    inodes in the fs.  This has survived dbench, fs_mark and an fsx torture
    test.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f1e905f7e701..ece8d1e26b5e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1629,7 +1629,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->sb = sb;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
-	fs_info->metadata_ratio = 8;
+	fs_info->metadata_ratio = 0;
 
 	fs_info->thread_pool_size = min_t(unsigned long,
 					  num_online_cpus() + 2, 8);

commit 54bcf382daf08c1396edb8b81e650b58930ccaef
Merge: 94a8d5caba74 c65ddb52dc41
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Sep 24 10:00:58 2009 -0400

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable into for-linus
    
    Conflicts:
            fs/btrfs/super.c

commit c65ddb52dc412c9b67681b1aa16cd1bac8434e24
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Sep 24 09:24:43 2009 -0400

    Btrfs: hash the btree inode during  fill_super
    
    The snapshot deletion  patches dropped this line, but the inode
    needs to be hashed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a0d41e713f3c..f1e905f7e701 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1664,6 +1664,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));
 	BTRFS_I(fs_info->btree_inode)->dummy_inode = 1;
+	insert_inode_hash(fs_info->btree_inode);
 
 	spin_lock_init(&fs_info->block_group_cache_lock);
 	fs_info->block_group_cache_tree.rb_node = NULL;

commit 7f09410bbc4306f592cfb43812389ea1c7905a20
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Mon Sep 21 17:01:10 2009 -0700

    const: mark remaining address_space_operations const
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8b8192790011..6c4173146bb7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -772,7 +772,7 @@ static void btree_invalidatepage(struct page *page, unsigned long offset)
 	}
 }
 
-static struct address_space_operations btree_aops = {
+static const struct address_space_operations btree_aops = {
 	.readpage	= btree_readpage,
 	.writepage	= btree_writepage,
 	.writepages	= btree_writepages,

commit 76dda93c6ae2c1dc3e6cde34569d6aca26b0c918
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Mon Sep 21 16:00:26 2009 -0400

    Btrfs: add snapshot/subvolume destroy ioctl
    
    This patch adds snapshot/subvolume destroy ioctl.  A subvolume that isn't being
    used and doesn't contains links to other subvolumes can be destroyed.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a4f531047c4a..a0d41e713f3c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1378,8 +1378,10 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 
 	err = bdi_register(bdi, NULL, "btrfs-%d",
 				atomic_inc_return(&btrfs_bdi_num));
-	if (err)
+	if (err) {
+		bdi_destroy(bdi);
 		return err;
+	}
 
 	bdi->ra_pages	= default_backing_dev_info.ra_pages;
 	bdi->unplug_io_fn	= btrfs_unplug_io_fn;
@@ -1469,9 +1471,12 @@ static int cleaner_kthread(void *arg)
 			break;
 
 		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
-		mutex_lock(&root->fs_info->cleaner_mutex);
-		btrfs_clean_old_snapshots(root);
-		mutex_unlock(&root->fs_info->cleaner_mutex);
+
+		if (!(root->fs_info->sb->s_flags & MS_RDONLY) &&
+		    mutex_trylock(&root->fs_info->cleaner_mutex)) {
+			btrfs_clean_old_snapshots(root);
+			mutex_unlock(&root->fs_info->cleaner_mutex);
+		}
 
 		if (freezing(current)) {
 			refrigerator();
@@ -1576,7 +1581,26 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		err = -ENOMEM;
 		goto fail;
 	}
-	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
+
+	ret = init_srcu_struct(&fs_info->subvol_srcu);
+	if (ret) {
+		err = ret;
+		goto fail;
+	}
+
+	ret = setup_bdi(fs_info, &fs_info->bdi);
+	if (ret) {
+		err = ret;
+		goto fail_srcu;
+	}
+
+	fs_info->btree_inode = new_inode(sb);
+	if (!fs_info->btree_inode) {
+		err = -ENOMEM;
+		goto fail_bdi;
+	}
+
+	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->hashers);
@@ -1586,6 +1610,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);
 	spin_lock_init(&fs_info->ref_cache_lock);
+	spin_lock_init(&fs_info->fs_roots_radix_lock);
 
 	init_completion(&fs_info->kobj_unregister);
 	fs_info->tree_root = tree_root;
@@ -1604,11 +1629,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->sb = sb;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
-	if (setup_bdi(fs_info, &fs_info->bdi))
-		goto fail_bdi;
-	fs_info->btree_inode = new_inode(sb);
-	fs_info->btree_inode->i_ino = 1;
-	fs_info->btree_inode->i_nlink = 1;
 	fs_info->metadata_ratio = 8;
 
 	fs_info->thread_pool_size = min_t(unsigned long,
@@ -1620,6 +1640,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
 
+	fs_info->btree_inode->i_ino = BTRFS_BTREE_INODE_OBJECTID;
+	fs_info->btree_inode->i_nlink = 1;
 	/*
 	 * we set the i_size on the btree inode to the max possible int.
 	 * the real end of the address space is determined by all of
@@ -1638,6 +1660,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	BTRFS_I(fs_info->btree_inode)->io_tree.ops = &btree_extent_io_ops;
 
+	BTRFS_I(fs_info->btree_inode)->root = tree_root;
+	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
+	       sizeof(struct btrfs_key));
+	BTRFS_I(fs_info->btree_inode)->dummy_inode = 1;
+
 	spin_lock_init(&fs_info->block_group_cache_lock);
 	fs_info->block_group_cache_tree.rb_node = NULL;
 
@@ -1648,21 +1675,16 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->pinned_extents = &fs_info->freed_extents[0];
 	fs_info->do_barriers = 1;
 
-	BTRFS_I(fs_info->btree_inode)->root = tree_root;
-	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
-	       sizeof(struct btrfs_key));
-	insert_inode_hash(fs_info->btree_inode);
 
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->ordered_operations_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
-	mutex_init(&fs_info->drop_mutex);
 	mutex_init(&fs_info->chunk_mutex);
 	mutex_init(&fs_info->transaction_kthread_mutex);
 	mutex_init(&fs_info->cleaner_mutex);
 	mutex_init(&fs_info->volume_mutex);
-	mutex_init(&fs_info->tree_reloc_mutex);
 	init_rwsem(&fs_info->extent_commit_sem);
+	init_rwsem(&fs_info->subvol_sem);
 
 	btrfs_init_free_cluster(&fs_info->meta_alloc_cluster);
 	btrfs_init_free_cluster(&fs_info->data_alloc_cluster);
@@ -1941,6 +1963,9 @@ printk("thread pool is %d\n", fs_info->thread_pool_size);
 		}
 	}
 
+	ret = btrfs_find_orphan_roots(tree_root);
+	BUG_ON(ret);
+
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_recover_relocation(tree_root);
 		BUG_ON(ret);
@@ -2000,6 +2025,8 @@ printk("thread pool is %d\n", fs_info->thread_pool_size);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 fail_bdi:
 	bdi_destroy(&fs_info->bdi);
+fail_srcu:
+	cleanup_srcu_struct(&fs_info->subvol_srcu);
 fail:
 	kfree(extent_root);
 	kfree(tree_root);
@@ -2263,6 +2290,10 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
 	spin_unlock(&fs_info->fs_roots_radix_lock);
+
+	if (btrfs_root_refs(&root->root_item) == 0)
+		synchronize_srcu(&fs_info->subvol_srcu);
+
 	free_fs_root(root);
 	return 0;
 }
@@ -2286,6 +2317,20 @@ static int del_fs_roots(struct btrfs_fs_info *fs_info)
 	struct btrfs_root *gang[8];
 	int i;
 
+	while (!list_empty(&fs_info->dead_roots)) {
+		gang[0] = list_entry(fs_info->dead_roots.next,
+				     struct btrfs_root, root_list);
+		list_del(&gang[0]->root_list);
+
+		if (gang[0]->in_radix) {
+			btrfs_free_fs_root(fs_info, gang[0]);
+		} else {
+			free_extent_buffer(gang[0]->node);
+			free_extent_buffer(gang[0]->commit_root);
+			kfree(gang[0]);
+		}
+	}
+
 	while (1) {
 		ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,
 					     (void **)gang, 0,
@@ -2315,9 +2360,6 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 		root_objectid = gang[ret - 1]->root_key.objectid + 1;
 		for (i = 0; i < ret; i++) {
 			root_objectid = gang[i]->root_key.objectid;
-			ret = btrfs_find_dead_roots(fs_info->tree_root,
-						    root_objectid);
-			BUG_ON(ret);
 			btrfs_orphan_cleanup(gang[i]);
 		}
 		root_objectid++;
@@ -2405,6 +2447,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
 	bdi_destroy(&fs_info->bdi);
+	cleanup_srcu_struct(&fs_info->subvol_srcu);
 
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);

commit 4df27c4d5cc1dda54ed7d0a8389347f2df359cf9
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Mon Sep 21 15:56:00 2009 -0400

    Btrfs: change how subvolumes are organized
    
    btrfs allows subvolumes and snapshots anywhere in the directory tree.
    If we snapshot a subvolume that contains a link to other subvolume
    called subvolA, subvolA can be accessed through both the original
    subvolume and the snapshot. This is similar to creating hard link to
    directory, and has the very similar problems.
    
    The aim of this patch is enforcing there is only one access point to
    each subvolume. Only the first directory entry (the one added when
    the subvolume/snapshot was created) is treated as valid access point.
    The first directory entry is distinguished by checking root forward
    reference. If the corresponding root forward reference is missing,
    we know the entry is not the first one.
    
    This patch also adds snapshot/subvolume rename support, the code
    allows rename subvolume link across subvolumes.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 790f4b61a3d7..a4f531047c4a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -41,6 +41,7 @@
 
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
+static void free_fs_root(struct btrfs_root *root);
 
 static atomic_t btrfs_bdi_num = ATOMIC_INIT(0);
 
@@ -951,14 +952,16 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 		     root, fs_info, objectid);
 	ret = btrfs_find_last_root(tree_root, objectid,
 				   &root->root_item, &root->root_key);
+	if (ret > 0)
+		return -ENOENT;
 	BUG_ON(ret);
 
 	generation = btrfs_root_generation(&root->root_item);
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
-	root->commit_root = btrfs_root_node(root);
 	BUG_ON(!root->node);
+	root->commit_root = btrfs_root_node(root);
 	return 0;
 }
 
@@ -1176,39 +1179,66 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 		return fs_info->dev_root;
 	if (location->objectid == BTRFS_CSUM_TREE_OBJECTID)
 		return fs_info->csum_root;
-
+again:
+	spin_lock(&fs_info->fs_roots_radix_lock);
 	root = radix_tree_lookup(&fs_info->fs_roots_radix,
 				 (unsigned long)location->objectid);
+	spin_unlock(&fs_info->fs_roots_radix_lock);
 	if (root)
 		return root;
 
+	ret = btrfs_find_orphan_item(fs_info->tree_root, location->objectid);
+	if (ret == 0)
+		ret = -ENOENT;
+	if (ret < 0)
+		return ERR_PTR(ret);
+
 	root = btrfs_read_fs_root_no_radix(fs_info->tree_root, location);
 	if (IS_ERR(root))
 		return root;
 
+	WARN_ON(btrfs_root_refs(&root->root_item) == 0);
 	set_anon_super(&root->anon_super, NULL);
 
+	ret = radix_tree_preload(GFP_NOFS & ~__GFP_HIGHMEM);
+	if (ret)
+		goto fail;
+
+	spin_lock(&fs_info->fs_roots_radix_lock);
 	ret = radix_tree_insert(&fs_info->fs_roots_radix,
 				(unsigned long)root->root_key.objectid,
 				root);
+	if (ret == 0)
+		root->in_radix = 1;
+	spin_unlock(&fs_info->fs_roots_radix_lock);
+	radix_tree_preload_end();
 	if (ret) {
-		free_extent_buffer(root->node);
-		kfree(root);
-		return ERR_PTR(ret);
+		if (ret == -EEXIST) {
+			free_fs_root(root);
+			goto again;
+		}
+		goto fail;
 	}
-	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
-		ret = btrfs_find_dead_roots(fs_info->tree_root,
-					    root->root_key.objectid);
-		BUG_ON(ret);
+
+	ret = btrfs_find_dead_roots(fs_info->tree_root,
+				    root->root_key.objectid);
+	WARN_ON(ret);
+
+	if (!(fs_info->sb->s_flags & MS_RDONLY))
 		btrfs_orphan_cleanup(root);
-	}
+
 	return root;
+fail:
+	free_fs_root(root);
+	return ERR_PTR(ret);
 }
 
 struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 				      struct btrfs_key *location,
 				      const char *name, int namelen)
 {
+	return btrfs_read_fs_root_no_name(fs_info, location);
+#if 0
 	struct btrfs_root *root;
 	int ret;
 
@@ -1225,7 +1255,7 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
-#if 0
+
 	ret = btrfs_sysfs_add_root(root);
 	if (ret) {
 		free_extent_buffer(root->node);
@@ -1233,9 +1263,9 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
-#endif
 	root->in_sysfs = 1;
 	return root;
+#endif
 }
 
 static int btrfs_congested_fn(void *congested_data, int bdi_bits)
@@ -2229,20 +2259,25 @@ int write_ctree_super(struct btrfs_trans_handle *trans,
 
 int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 {
-	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
+	spin_lock(&fs_info->fs_roots_radix_lock);
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
+	spin_unlock(&fs_info->fs_roots_radix_lock);
+	free_fs_root(root);
+	return 0;
+}
+
+static void free_fs_root(struct btrfs_root *root)
+{
+	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
 	if (root->anon_super.s_dev) {
 		down_write(&root->anon_super.s_umount);
 		kill_anon_super(&root->anon_super);
 	}
-	if (root->node)
-		free_extent_buffer(root->node);
-	if (root->commit_root)
-		free_extent_buffer(root->commit_root);
+	free_extent_buffer(root->node);
+	free_extent_buffer(root->commit_root);
 	kfree(root->name);
 	kfree(root);
-	return 0;
 }
 
 static int del_fs_roots(struct btrfs_fs_info *fs_info)

commit 13a8a7c8c47e542b3cdb45bec3f431f96af79361
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Mon Sep 21 15:56:00 2009 -0400

    Btrfs: do not reuse objectid of deleted snapshot/subvol
    
    The new back reference format does not allow reusing objectid of
    deleted snapshot/subvol. So we use ++highest_objectid to allocate
    objectid for new snapshot/subvol.
    
    Now we use ++highest_objectid to allocate objectid for both new inode
    and new snapshot/subvolume, so this patch removes 'find hole' code in
    btrfs_find_free_objectid.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 16dae122dda4..790f4b61a3d7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -895,8 +895,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->fs_info = fs_info;
 	root->objectid = objectid;
 	root->last_trans = 0;
-	root->highest_inode = 0;
-	root->last_inode_alloc = 0;
+	root->highest_objectid = 0;
 	root->name = NULL;
 	root->in_sysfs = 0;
 	root->inode_tree.rb_node = NULL;
@@ -1095,7 +1094,6 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	struct btrfs_fs_info *fs_info = tree_root->fs_info;
 	struct btrfs_path *path;
 	struct extent_buffer *l;
-	u64 highest_inode;
 	u64 generation;
 	u32 blocksize;
 	int ret = 0;
@@ -1110,7 +1108,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 			kfree(root);
 			return ERR_PTR(ret);
 		}
-		goto insert;
+		goto out;
 	}
 
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
@@ -1120,39 +1118,30 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
 	ret = btrfs_search_slot(NULL, tree_root, location, path, 0, 0);
-	if (ret != 0) {
-		if (ret > 0)
-			ret = -ENOENT;
-		goto out;
+	if (ret == 0) {
+		l = path->nodes[0];
+		read_extent_buffer(l, &root->root_item,
+				btrfs_item_ptr_offset(l, path->slots[0]),
+				sizeof(root->root_item));
+		memcpy(&root->root_key, location, sizeof(*location));
 	}
-	l = path->nodes[0];
-	read_extent_buffer(l, &root->root_item,
-	       btrfs_item_ptr_offset(l, path->slots[0]),
-	       sizeof(root->root_item));
-	memcpy(&root->root_key, location, sizeof(*location));
-	ret = 0;
-out:
-	btrfs_release_path(root, path);
 	btrfs_free_path(path);
 	if (ret) {
-		kfree(root);
+		if (ret > 0)
+			ret = -ENOENT;
 		return ERR_PTR(ret);
 	}
+
 	generation = btrfs_root_generation(&root->root_item);
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
 	root->commit_root = btrfs_root_node(root);
 	BUG_ON(!root->node);
-insert:
-	if (location->objectid != BTRFS_TREE_LOG_OBJECTID) {
+out:
+	if (location->objectid != BTRFS_TREE_LOG_OBJECTID)
 		root->ref_cows = 1;
-		ret = btrfs_find_highest_inode(root, &highest_inode);
-		if (ret == 0) {
-			root->highest_inode = highest_inode;
-			root->last_inode_alloc = highest_inode;
-		}
-	}
+
 	return root;
 }
 

commit 11833d66be94b514652466802100378046c16b72
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Fri Sep 11 16:11:19 2009 -0400

    Btrfs: improve async block group caching
    
    This patch gets rid of two limitations of async block group caching.
    The old code delays handling pinned extents when block group is in
    caching. To allocate logged file extents, the old code need wait
    until block group is fully cached. To get rid of the limitations,
    This patch introduces a data structure to track the progress of
    caching. Base on the caching progress, we know which extents should
    be added to the free space cache when handling the pinned extents.
    The logged file extents are also handled in a similar way.
    
    This patch also changes how pinned extents are tracked. The old
    code uses one tree to track pinned extents, and copy the pinned
    extents tree at transaction commit time. This patch makes it use
    two trees to track pinned extents. One tree for extents that are
    pinned in the running transaction, one tree for extents that can
    be unpinned. At transaction commit time, we swap the two trees.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 253da7e01ab3..16dae122dda4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1563,6 +1563,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->hashers);
 	INIT_LIST_HEAD(&fs_info->delalloc_inodes);
 	INIT_LIST_HEAD(&fs_info->ordered_operations);
+	INIT_LIST_HEAD(&fs_info->caching_block_groups);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);
 	spin_lock_init(&fs_info->ref_cache_lock);
@@ -1621,8 +1622,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->block_group_cache_lock);
 	fs_info->block_group_cache_tree.rb_node = NULL;
 
-	extent_io_tree_init(&fs_info->pinned_extents,
+	extent_io_tree_init(&fs_info->freed_extents[0],
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+	extent_io_tree_init(&fs_info->freed_extents[1],
+			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+	fs_info->pinned_extents = &fs_info->freed_extents[0];
 	fs_info->do_barriers = 1;
 
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
@@ -2359,7 +2363,6 @@ int close_ctree(struct btrfs_root *root)
 	free_extent_buffer(root->fs_info->csum_root->commit_root);
 
 	btrfs_free_block_groups(root->fs_info);
-	btrfs_free_pinned_extents(root->fs_info);
 
 	del_fs_roots(fs_info);
 

commit 32a88aa1b6dfb901cec64e1898cac78d0f25028a
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Wed Sep 16 15:02:33 2009 +0200

    fs: Assign bdi in super_block
    
    We do this automatically in get_sb_bdev() from the set_bdev_super()
    callback. Filesystems that have their own private backing_dev_info
    must assign that in ->fill_super().
    
    Note that ->s_bdi assignment is required for proper writeback!
    
    Acked-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 15831d5c7367..8b8192790011 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1600,6 +1600,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
+	sb->s_bdi = &fs_info->bdi;
 
 	/*
 	 * we set the i_size on the btree inode to the max possible int.

commit 83ebade34bc1a90d0c3f77b87b940f336d075fda
Merge: 74fca6a42863 93c82d575055
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 11 19:07:25 2009 -0400

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable

commit 890871be854b5f5e43e7ba2475f706209906cc24
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Sep 2 16:24:52 2009 -0400

    Btrfs: switch extent_map to a rw lock
    
    There are two main users of the extent_map tree.  The
    first is regular file inodes, where it is evenly spread
    between readers and writers.
    
    The second is the chunk allocation tree, which maps blocks from
    logical addresses to phyiscal ones, and it is 99.99% reads.
    
    The mapping tree is a point of lock contention during heavy IO
    workloads, so this commit switches things to a rw lock.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 20cefc6f22c4..b6cfdd9164e2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -121,15 +121,15 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 	struct extent_map *em;
 	int ret;
 
-	spin_lock(&em_tree->lock);
+	read_lock(&em_tree->lock);
 	em = lookup_extent_mapping(em_tree, start, len);
 	if (em) {
 		em->bdev =
 			BTRFS_I(inode)->root->fs_info->fs_devices->latest_bdev;
-		spin_unlock(&em_tree->lock);
+		read_unlock(&em_tree->lock);
 		goto out;
 	}
-	spin_unlock(&em_tree->lock);
+	read_unlock(&em_tree->lock);
 
 	em = alloc_extent_map(GFP_NOFS);
 	if (!em) {
@@ -142,7 +142,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 	em->block_start = 0;
 	em->bdev = BTRFS_I(inode)->root->fs_info->fs_devices->latest_bdev;
 
-	spin_lock(&em_tree->lock);
+	write_lock(&em_tree->lock);
 	ret = add_extent_mapping(em_tree, em);
 	if (ret == -EEXIST) {
 		u64 failed_start = em->start;
@@ -161,7 +161,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 		free_extent_map(em);
 		em = NULL;
 	}
-	spin_unlock(&em_tree->lock);
+	write_unlock(&em_tree->lock);
 
 	if (ret)
 		em = ERR_PTR(ret);
@@ -1323,9 +1323,9 @@ static void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 	offset = page_offset(page);
 
 	em_tree = &BTRFS_I(inode)->extent_tree;
-	spin_lock(&em_tree->lock);
+	read_lock(&em_tree->lock);
 	em = lookup_extent_mapping(em_tree, offset, PAGE_CACHE_SIZE);
-	spin_unlock(&em_tree->lock);
+	read_unlock(&em_tree->lock);
 	if (!em) {
 		__unplug_io_fn(bdi, page);
 		return;

commit 9042846bc7ae69cc3288d85af6bad16208d93a95
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Aug 4 16:56:34 2009 -0400

    Btrfs: Allow worker threads to exit when idle
    
    The Btrfs worker threads don't currently die off after they have
    been idle for a while, leading to a lot of threads sitting around
    doing nothing for each mount.
    
    Also, they are unable to start atomically (from end_io hanlders).
    
    This commit reworks the worker threads so they can be started
    from end_io handlers (just setting a flag that asks for a thread
    to be added at a later date) and so they can exit if they
    have been idle for a long time.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3cf4cfa575c8..20cefc6f22c4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1682,7 +1682,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		err = -EINVAL;
 		goto fail_iput;
 	}
-
+printk("thread pool is %d\n", fs_info->thread_pool_size);
 	/*
 	 * we need to start all the end_io workers up front because the
 	 * queue work function gets called at interrupt time, and so it
@@ -1727,20 +1727,22 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->endio_workers.idle_thresh = 4;
 	fs_info->endio_meta_workers.idle_thresh = 4;
 
-	fs_info->endio_write_workers.idle_thresh = 64;
-	fs_info->endio_meta_write_workers.idle_thresh = 64;
+	fs_info->endio_write_workers.idle_thresh = 2;
+	fs_info->endio_meta_write_workers.idle_thresh = 2;
+
+	fs_info->endio_workers.atomic_worker_start = 1;
+	fs_info->endio_meta_workers.atomic_worker_start = 1;
+	fs_info->endio_write_workers.atomic_worker_start = 1;
+	fs_info->endio_meta_write_workers.atomic_worker_start = 1;
 
 	btrfs_start_workers(&fs_info->workers, 1);
 	btrfs_start_workers(&fs_info->submit_workers, 1);
 	btrfs_start_workers(&fs_info->delalloc_workers, 1);
 	btrfs_start_workers(&fs_info->fixup_workers, 1);
-	btrfs_start_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
-	btrfs_start_workers(&fs_info->endio_meta_workers,
-			    fs_info->thread_pool_size);
-	btrfs_start_workers(&fs_info->endio_meta_write_workers,
-			    fs_info->thread_pool_size);
-	btrfs_start_workers(&fs_info->endio_write_workers,
-			    fs_info->thread_pool_size);
+	btrfs_start_workers(&fs_info->endio_workers, 1);
+	btrfs_start_workers(&fs_info->endio_meta_workers, 1);
+	btrfs_start_workers(&fs_info->endio_meta_write_workers, 1);
+	btrfs_start_workers(&fs_info->endio_write_workers, 1);
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,

commit d993831fa7ffeb89e994f046f93eeb09ec91df08
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri Jun 12 14:45:52 2009 +0200

    writeback: add name to backing_dev_info
    
    This enables us to track who does what and print info. Its main use
    is catching dirty inodes on the default_backing_dev_info, so we can
    fix that up.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e83be2e4602c..15831d5c7367 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1352,6 +1352,7 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 {
 	int err;
 
+	bdi->name = "btrfs";
 	bdi->capabilities = BDI_CAP_MAP_COPY;
 	err = bdi_init(bdi);
 	if (err)

commit ec6a8679fa8ce977c8b7f86238455b494699de74
Merge: db06816cb9ce f36f3042eae2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 30 16:46:48 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: be more polite in the async caching threads
      Btrfs: preserve commit_root for async caching

commit 276e680d192a67d222fcea51af37b056feffb665
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Jul 30 09:40:40 2009 -0400

    Btrfs: preserve commit_root for async caching
    
    The async block group caching code uses the commit_root pointer
    to get a stable version of the extent allocation tree for scanning.
    This copy of the tree root isn't going to change and it significantly
    reduces the complexity of the scanning code.
    
    During a commit, we have a loop where we update the extent allocation
    tree root.  We need to loop because updating the root pointer in
    the tree of tree roots may allocate blocks which may change the
    extent allocation tree.
    
    Right now the commit_root pointer is changed inside this loop.  It
    is more correct to change the commit_root pointer only after all the
    looping is done.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3a9b88759880..3cf4cfa575c8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -907,7 +907,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	spin_lock_init(&root->inode_lock);
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
-	init_rwsem(&root->commit_root_sem);
 	init_waitqueue_head(&root->log_writer_wait);
 	init_waitqueue_head(&root->log_commit_wait[0]);
 	init_waitqueue_head(&root->log_commit_wait[1]);
@@ -1624,6 +1623,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->cleaner_mutex);
 	mutex_init(&fs_info->volume_mutex);
 	mutex_init(&fs_info->tree_reloc_mutex);
+	init_rwsem(&fs_info->extent_commit_sem);
 
 	btrfs_init_free_cluster(&fs_info->meta_alloc_cluster);
 	btrfs_init_free_cluster(&fs_info->data_alloc_cluster);

commit 655c5d8fc110a9d4f90cc831bd009936f3e8df28
Merge: ce4adcc6e532 f25784b35f59
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 28 14:27:06 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable: (22 commits)
      Btrfs: Fix async caching interaction with unmount
      Btrfs: change how we unpin extents
      Btrfs: Correct redundant test in add_inode_ref
      Btrfs: find smallest available device extent during chunk allocation
      Btrfs: clear all space_info->full after removing a block group
      Btrfs: make flushoncommit mount option correctly wait on ordered_extents
      Btrfs: Avoid delayed reference update looping
      Btrfs: Fix ordering of key field checks in btrfs_previous_item
      Btrfs: find_free_dev_extent doesn't handle holes at the start of the device
      Btrfs: Remove code duplication in comp_keys
      Btrfs: async block group caching
      Btrfs: use hybrid extents+bitmap rb tree for free space
      Btrfs: Fix crash on read failures at mount
      Btrfs: remove of redundant btrfs_header_level
      Btrfs: adjust NULL test
      Btrfs: Remove broken sanity check from btrfs_rmap_block()
      Btrfs: convert nested spin_lock_irqsave to spin_lock
      Btrfs: make sure all dirty blocks are written at commit time
      Btrfs: fix locking issue in btrfs_find_next_key
      Btrfs: fix double increment of path->slots[0] in btrfs_next_leaf
      ...

commit f25784b35f590c81d5fb8245a8cd45e1afb6f1b2
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Tue Jul 28 08:41:57 2009 -0400

    Btrfs: Fix async caching interaction with unmount
    
    - don't stop the caching thread until btrfs_commit_super return.
    
    - if caching is interrupted by umount, set last to (u64)-1.
      otherwise the un-scanned range of block group will be considered
      as free extent.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c658397c7473..3a9b88759880 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2317,6 +2317,9 @@ int close_ctree(struct btrfs_root *root)
 			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
 	}
 
+	fs_info->closing = 2;
+	smp_mb();
+
 	if (fs_info->delalloc_bytes) {
 		printk(KERN_INFO "btrfs: at unmount delalloc count %llu\n",
 		       (unsigned long long)fs_info->delalloc_bytes);

commit 68b38550ddbea13d296184bf69edff387618b1d3
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jul 27 13:57:01 2009 -0400

    Btrfs: change how we unpin extents
    
    We are racy with async block caching and unpinning extents.  This patch makes
    things much less complicated by only unpinning the extent if the block group is
    cached.  We check the block_group->cached var under the block_group->lock spin
    lock.  If it is set to BTRFS_CACHE_FINISHED then we update the pinned counters,
    and unpin the extent and add the free space back.  If it is not set to this, we
    start the caching of the block group so the next time we unpin extents we can
    unpin the extent.  This keeps us from racing with the async caching threads,
    lets us kill the fs wide async thread counter, and keeps us from having to set
    DELALLOC bits for every extent we hit if there are caching kthreads going.
    
    One thing that needed to be changed was btrfs_free_super_mirror_extents.  Now
    instead of just looking for LOCKED extents, we also look for DIRTY extents,
    since we could have left some extents pinned in the previous transaction that
    will never get freed now that we are unmounting, which would cause us to leak
    memory.  So btrfs_free_super_mirror_extents has been changed to
    btrfs_free_pinned_extents, and it will clear the extents locked for the super
    mirror, and any remaining pinned extents that may be present.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ec2c915f7f4a..c658397c7473 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1567,7 +1567,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
-	atomic_set(&fs_info->async_caching_threads, 0);
 	fs_info->sb = sb;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
@@ -2339,7 +2338,7 @@ int close_ctree(struct btrfs_root *root)
 	free_extent_buffer(root->fs_info->csum_root->commit_root);
 
 	btrfs_free_block_groups(root->fs_info);
-	btrfs_free_super_mirror_extents(root->fs_info);
+	btrfs_free_pinned_extents(root->fs_info);
 
 	del_fs_roots(fs_info);
 

commit 817d52f8dba26d0295c26035531c30ce5f1e3c3e
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jul 13 21:29:25 2009 -0400

    Btrfs: async block group caching
    
    This patch moves the caching of the block group off to a kthread in order to
    allow people to allocate sooner.  Instead of blocking up behind the caching
    mutex, we instead kick of the caching kthread, and then attempt to make an
    allocation.  If we cannot, we wait on the block groups caching waitqueue, which
    the caching kthread will wake the waiting threads up everytime it finds 2 meg
    worth of space, and then again when its finished caching.  This is how I tested
    the speedup from this
    
    mkfs the disk
    mount the disk
    fill the disk up with fs_mark
    unmount the disk
    mount the disk
    time touch /mnt/foo
    
    Without my changes this took 11 seconds on my box, with these changes it now
    takes 1 second.
    
    Another change thats been put in place is we lock the super mirror's in the
    pinned extent map in order to keep us from adding that stuff as free space when
    caching the block group.  This doesn't really change anything else as far as the
    pinned extent map is concerned, since for actual pinned extents we use
    EXTENT_DIRTY, but it does mean that when we unmount we have to go in and unlock
    those extents to keep from leaking memory.
    
    I've also added a check where when we are reading block groups from disk, if the
    amount of space used == the size of the block group, we go ahead and mark the
    block group as cached.  This drastically reduces the amount of time it takes to
    cache the block groups.  Using the same test as above, except doing a dd to a
    file and then unmounting, it used to take 33 seconds to umount, now it takes 3
    seconds.
    
    This version uses the commit_root in the caching kthread, and then keeps track
    of how many async caching threads are running at any given time so if one of the
    async threads is still running as we cross transactions we can wait until its
    finished before handling the pinned extents.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 55d9d188e693..ec2c915f7f4a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -907,6 +907,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	spin_lock_init(&root->inode_lock);
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
+	init_rwsem(&root->commit_root_sem);
 	init_waitqueue_head(&root->log_writer_wait);
 	init_waitqueue_head(&root->log_commit_wait[0]);
 	init_waitqueue_head(&root->log_commit_wait[1]);
@@ -1566,6 +1567,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
+	atomic_set(&fs_info->async_caching_threads, 0);
 	fs_info->sb = sb;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
@@ -2337,6 +2339,7 @@ int close_ctree(struct btrfs_root *root)
 	free_extent_buffer(root->fs_info->csum_root->commit_root);
 
 	btrfs_free_block_groups(root->fs_info);
+	btrfs_free_super_mirror_extents(root->fs_info);
 
 	del_fs_roots(fs_info);
 

commit 83121942b28daffc9526b14b7843d8cdbd3db641
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Wed Jul 22 16:52:13 2009 -0400

    Btrfs: Fix crash on read failures at mount
    
    If the tree roots hit read errors during mount, btrfs is not properly
    erroring out.  We need to check the uptodate bits after
    reading in the tree root node.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0d50d49d990a..55d9d188e693 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1783,6 +1783,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 					   btrfs_super_chunk_root(disk_super),
 					   blocksize, generation);
 	BUG_ON(!chunk_root->node);
+	if (!test_bit(EXTENT_BUFFER_UPTODATE, &chunk_root->node->bflags)) {
+		printk(KERN_WARNING "btrfs: failed to read chunk root on %s\n",
+		       sb->s_id);
+		goto fail_chunk_root;
+	}
 	btrfs_set_root_node(&chunk_root->root_item, chunk_root->node);
 	chunk_root->commit_root = btrfs_root_node(chunk_root);
 
@@ -1810,6 +1815,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 					  blocksize, generation);
 	if (!tree_root->node)
 		goto fail_chunk_root;
+	if (!test_bit(EXTENT_BUFFER_UPTODATE, &tree_root->node->bflags)) {
+		printk(KERN_WARNING "btrfs: failed to read tree root on %s\n",
+		       sb->s_id);
+		goto fail_tree_root;
+	}
 	btrfs_set_root_node(&tree_root->root_item, tree_root->node);
 	tree_root->commit_root = btrfs_root_node(tree_root);
 

commit ad081f1430515d0b727eba99ec435a526c61a599
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri Jun 12 14:43:40 2009 +0200

    btrfs: properly register fs backing device
    
    btrfs assigns this bdi to all inodes on that file system, so make
    sure it's registered. This isn't really important now, but will be
    when we put dirty inodes there. Even now, we miss the stats when the
    bdi isn't visible.
    
    Also fixes failure to check bdi_init() return value, and bad inherit of
    ->capabilities flags from the default bdi.
    
    Acked-by: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0d50d49d990a..d28d29c95f7c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -42,6 +42,8 @@
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 
+static atomic_t btrfs_bdi_num = ATOMIC_INIT(0);
+
 /*
  * end_io_wq structs are used to do processing in task context when an IO is
  * complete.  This is used during reads to verify checksums, and it is used
@@ -1342,12 +1344,25 @@ static void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 	free_extent_map(em);
 }
 
+/*
+ * If this fails, caller must call bdi_destroy() to get rid of the
+ * bdi again.
+ */
 static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 {
-	bdi_init(bdi);
+	int err;
+
+	bdi->capabilities = BDI_CAP_MAP_COPY;
+	err = bdi_init(bdi);
+	if (err)
+		return err;
+
+	err = bdi_register(bdi, NULL, "btrfs-%d",
+				atomic_inc_return(&btrfs_bdi_num));
+	if (err)
+		return err;
+
 	bdi->ra_pages	= default_backing_dev_info.ra_pages;
-	bdi->state		= 0;
-	bdi->capabilities	= default_backing_dev_info.capabilities;
 	bdi->unplug_io_fn	= btrfs_unplug_io_fn;
 	bdi->unplug_io_data	= info;
 	bdi->congested_fn	= btrfs_congested_fn;
@@ -1569,7 +1584,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->sb = sb;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
-	setup_bdi(fs_info, &fs_info->bdi);
+	if (setup_bdi(fs_info, &fs_info->bdi))
+		goto fail_bdi;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;
@@ -1946,8 +1962,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
+fail_bdi:
 	bdi_destroy(&fs_info->bdi);
-
 fail:
 	kfree(extent_root);
 	kfree(tree_root);

commit 4eedeb75e7f15ffdb12d1ad559b565e7505bdbaf
Author: Hisashi Hifumi <hifumi.hisashi@oss.ntt.co.jp>
Date:   Wed Jun 10 15:28:55 2009 -0400

    Btrfs: pin buffers during write_dev_supers
    
    write_dev_supers is called in sequence.  First is it called with wait == 0,
    which starts IO on all of the super blocks for a given device.  Then it is
    called with wait == 1 to make sure they all reach the disk.
    
    It doesn't currently pin the buffers between the two calls, and it also
    assumes the buffers won't go away between the two calls, leading to
    an oops if the VM manages to free the buffers in the middle of the sync.
    
    This fixes that assumption and updates the code to return an error if things
    are not up to date when the wait == 1 run is done.
    
    Signed-off-by: Hisashi Hifumi <hifumi.hisashi@oss.ntt.co.jp>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b7ddc77fa568..0d50d49d990a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2020,6 +2020,17 @@ struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
 	return latest;
 }
 
+/*
+ * this should be called twice, once with wait == 0 and
+ * once with wait == 1.  When wait == 0 is done, all the buffer heads
+ * we write are pinned.
+ *
+ * They are released when wait == 1 is done.
+ * max_mirrors must be the same for both runs, and it indicates how
+ * many supers on this one device should be written.
+ *
+ * max_mirrors == 0 means to write them all.
+ */
 static int write_dev_supers(struct btrfs_device *device,
 			    struct btrfs_super_block *sb,
 			    int do_barriers, int wait, int max_mirrors)
@@ -2055,12 +2066,16 @@ static int write_dev_supers(struct btrfs_device *device,
 			bh = __find_get_block(device->bdev, bytenr / 4096,
 					      BTRFS_SUPER_INFO_SIZE);
 			BUG_ON(!bh);
-			brelse(bh);
 			wait_on_buffer(bh);
-			if (buffer_uptodate(bh)) {
-				brelse(bh);
-				continue;
-			}
+			if (!buffer_uptodate(bh))
+				errors++;
+
+			/* drop our reference */
+			brelse(bh);
+
+			/* drop the reference from the wait == 0 run */
+			brelse(bh);
+			continue;
 		} else {
 			btrfs_set_super_bytenr(sb, bytenr);
 
@@ -2071,12 +2086,18 @@ static int write_dev_supers(struct btrfs_device *device,
 					      BTRFS_CSUM_SIZE);
 			btrfs_csum_final(crc, sb->csum);
 
+			/*
+			 * one reference for us, and we leave it for the
+			 * caller
+			 */
 			bh = __getblk(device->bdev, bytenr / 4096,
 				      BTRFS_SUPER_INFO_SIZE);
 			memcpy(bh->b_data, sb, BTRFS_SUPER_INFO_SIZE);
 
-			set_buffer_uptodate(bh);
+			/* one reference for submit_bh */
 			get_bh(bh);
+
+			set_buffer_uptodate(bh);
 			lock_buffer(bh);
 			bh->b_end_io = btrfs_end_buffer_write_sync;
 		}
@@ -2088,6 +2109,7 @@ static int write_dev_supers(struct btrfs_device *device,
 				       device->name);
 				set_buffer_uptodate(bh);
 				device->barriers = 0;
+				/* one reference for submit_bh */
 				get_bh(bh);
 				lock_buffer(bh);
 				ret = submit_bh(WRITE_SYNC, bh);
@@ -2096,15 +2118,8 @@ static int write_dev_supers(struct btrfs_device *device,
 			ret = submit_bh(WRITE_SYNC, bh);
 		}
 
-		if (!ret && wait) {
-			wait_on_buffer(bh);
-			if (!buffer_uptodate(bh))
-				errors++;
-		} else if (ret) {
+		if (ret)
 			errors++;
-		}
-		if (wait)
-			brelse(bh);
 	}
 	return errors < i ? 0 : -1;
 }

commit e5e9a5206a171b2c467e494aebcdcf70c47289bc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 10 15:17:02 2009 -0400

    Btrfs: avoid races between super writeout and device list updates
    
    On multi-device filesystems, btrfs writes supers to all of the devices
    before considering a sync complete.  There wasn't any additional
    locking between super writeout and the device list management code
    because device management was done inside a transaction and
    super writeout only happened  with no transation writers running.
    
    With the btrfs fsync log and other async transaction updates, this
    has been racey for some time.  This adds a mutex to protect
    the device list.  The existing volume mutex could not be reused due to
    transaction lock ordering requirements.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6c54c210dfd0..b7ddc77fa568 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2111,7 +2111,7 @@ static int write_dev_supers(struct btrfs_device *device,
 
 int write_all_supers(struct btrfs_root *root, int max_mirrors)
 {
-	struct list_head *head = &root->fs_info->fs_devices->devices;
+	struct list_head *head;
 	struct btrfs_device *dev;
 	struct btrfs_super_block *sb;
 	struct btrfs_dev_item *dev_item;
@@ -2126,6 +2126,9 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 
 	sb = &root->fs_info->super_for_commit;
 	dev_item = &sb->dev_item;
+
+	mutex_lock(&root->fs_info->fs_devices->device_list_mutex);
+	head = &root->fs_info->fs_devices->devices;
 	list_for_each_entry(dev, head, dev_list) {
 		if (!dev->bdev) {
 			total_errors++;
@@ -2169,6 +2172,7 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 		if (ret)
 			total_errors++;
 	}
+	mutex_unlock(&root->fs_info->fs_devices->device_list_mutex);
 	if (total_errors > max_errors) {
 		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
 		       total_errors);

commit 163e783e6a8b1e8bcb4c9084d438091386b589df
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Sun Apr 19 13:02:41 2009 +0100

    Btrfs: remove crc32c.h and use libcrc32c directly.
    
    There's no need to preserve this abstraction; it used to let us use
    hardware crc32c support directly, but libcrc32c is already doing that for us
    through the crypto API -- so we're already using the Intel crc32c
    acceleration where appropriate.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f4dfbb7ab496..6c54c210dfd0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -26,8 +26,8 @@
 #include <linux/workqueue.h>
 #include <linux/kthread.h>
 #include <linux/freezer.h>
+#include <linux/crc32c.h>
 #include "compat.h"
-#include "crc32c.h"
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -171,7 +171,7 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 
 u32 btrfs_csum_data(struct btrfs_root *root, char *data, u32 seed, size_t len)
 {
-	return btrfs_crc32c(seed, data, len);
+	return crc32c(seed, data, len);
 }
 
 void btrfs_csum_final(u32 crc, char *result)

commit c289811cc096c57ff35550ee8132793a4f9b5b59
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 10 09:51:32 2009 -0400

    Btrfs: autodetect SSD devices
    
    During mount, btrfs will check the queue nonrot flag
    for all the devices found in the FS.  If they are all
    non-rotating, SSD mode is enabled by default.
    
    If the FS was mounted with -o nossd, the non-rotating
    flag is ignored.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e572cf478a5d..f4dfbb7ab496 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1850,6 +1850,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (IS_ERR(fs_info->transaction_kthread))
 		goto fail_cleaner;
 
+	if (!btrfs_test_opt(tree_root, SSD) &&
+	    !btrfs_test_opt(tree_root, NOSSD) &&
+	    !fs_info->fs_devices->rotating) {
+		printk(KERN_INFO "Btrfs detected SSD devices, enabling SSD "
+		       "mode\n");
+		btrfs_set_opt(fs_info->mount_opt, SSD);
+	}
+
 	if (btrfs_super_log_root(disk_super) != 0) {
 		u64 bytenr = btrfs_super_log_root(disk_super);
 
@@ -1893,6 +1901,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
 	if (!fs_info->fs_root)
 		goto fail_trans_kthread;
+
 	return tree_root;
 
 fail_trans_kthread:

commit 585ad2c3797dcaa643aeba75b9f072778adf3490
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 18 10:41:58 2009 -0400

    Btrfs: fix metadata dirty throttling limits
    
    Once a metadata block has been written, it must be recowed, so the
    btrfs dirty balancing call has a check to make sure a fair amount of metadata
    was actually dirty before it started writing it back to disk.
    
    A previous commit had changed the dirty tracking for metadata without
    updating the btrfs dirty balancing checks.  This commit switches it
    to use the correct counter.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7f5c6e3e9992..e572cf478a5d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2378,17 +2378,14 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	 * looks as though older kernels can get into trouble with
 	 * this code, they end up stuck in balance_dirty_pages forever
 	 */
-	struct extent_io_tree *tree;
 	u64 num_dirty;
-	u64 start = 0;
 	unsigned long thresh = 32 * 1024 * 1024;
-	tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 
 	if (current->flags & PF_MEMALLOC)
 		return;
 
-	num_dirty = count_range_bits(tree, &start, (u64)-1,
-				     thresh, EXTENT_DIRTY);
+	num_dirty = root->fs_info->dirty_metadata_bytes;
+
 	if (num_dirty > thresh) {
 		balance_dirty_pages_ratelimited_nr(
 				   root->fs_info->btree_inode->i_mapping, 1);

commit 5d4f98a28c7d334091c1b7744f48a1acdd2a4ae0
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Jun 10 10:45:14 2009 -0400

    Btrfs: Mixed back reference  (FORWARD ROLLING FORMAT CHANGE)
    
    This commit introduces a new kind of back reference for btrfs metadata.
    Once a filesystem has been mounted with this commit, IT WILL NO LONGER
    BE MOUNTABLE BY OLDER KERNELS.
    
    When a tree block in subvolume tree is cow'd, the reference counts of all
    extents it points to are increased by one.  At transaction commit time,
    the old root of the subvolume is recorded in a "dead root" data structure,
    and the btree it points to is later walked, dropping reference counts
    and freeing any blocks where the reference count goes to 0.
    
    The increments done during cow and decrements done after commit cancel out,
    and the walk is a very expensive way to go about freeing the blocks that
    are no longer referenced by the new btree root.  This commit reduces the
    transaction overhead by avoiding the need for dead root records.
    
    When a non-shared tree block is cow'd, we free the old block at once, and the
    new block inherits old block's references. When a tree block with reference
    count > 1 is cow'd, we increase the reference counts of all extents
    the new block points to by one, and decrease the old block's reference count by
    one.
    
    This dead tree avoidance code removes the need to modify the reference
    counts of lower level extents when a non-shared tree block is cow'd.
    But we still need to update back ref for all pointers in the block.
    This is because the location of the block is recorded in the back ref
    item.
    
    We can solve this by introducing a new type of back ref. The new
    back ref provides information about pointer's key, level and in which
    tree the pointer lives. This information allow us to find the pointer
    by searching the tree. The shortcoming of the new back ref is that it
    only works for pointers in tree blocks referenced by their owner trees.
    
    This is mostly a problem for snapshots, where resolving one of these
    fuzzy back references would be O(number_of_snapshots) and quite slow.
    The solution used here is to use the fuzzy back references in the common
    case where a given tree block is only referenced by one root,
    and use the full back references when multiple roots have a reference
    on a given block.
    
    This commit adds per subvolume red-black tree to keep trace of cached
    inodes. The red-black tree helps the balancing code to find cached
    inodes whose inode numbers within a given range.
    
    This commit improves the balancing code by introducing several data
    structures to keep the state of balancing. The most important one
    is the back ref cache. It caches how the upper level tree blocks are
    referenced. This greatly reduce the overhead of checking back ref.
    
    The improved balancing code scales significantly better with a large
    number of snapshots.
    
    This is a very large commit and was written in a number of
    pieces.  But, they depend heavily on the disk format change and were
    squashed together to make sure git bisect didn't end up in a
    bad state wrt space balancing or the format change.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4b0ea0b80c23..7f5c6e3e9992 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -36,7 +36,6 @@
 #include "print-tree.h"
 #include "async-thread.h"
 #include "locking.h"
-#include "ref-cache.h"
 #include "tree-log.h"
 #include "free-space-cache.h"
 
@@ -884,7 +883,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 {
 	root->node = NULL;
 	root->commit_root = NULL;
-	root->ref_tree = NULL;
 	root->sectorsize = sectorsize;
 	root->nodesize = nodesize;
 	root->leafsize = leafsize;
@@ -899,12 +897,14 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->last_inode_alloc = 0;
 	root->name = NULL;
 	root->in_sysfs = 0;
+	root->inode_tree.rb_node = NULL;
 
 	INIT_LIST_HEAD(&root->dirty_list);
 	INIT_LIST_HEAD(&root->orphan_list);
-	INIT_LIST_HEAD(&root->dead_list);
+	INIT_LIST_HEAD(&root->root_list);
 	spin_lock_init(&root->node_lock);
 	spin_lock_init(&root->list_lock);
+	spin_lock_init(&root->inode_lock);
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
 	init_waitqueue_head(&root->log_writer_wait);
@@ -918,9 +918,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	extent_io_tree_init(&root->dirty_log_pages,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 
-	btrfs_leaf_ref_tree_init(&root->ref_tree_struct);
-	root->ref_tree = &root->ref_tree_struct;
-
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
@@ -959,6 +956,7 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
+	root->commit_root = btrfs_root_node(root);
 	BUG_ON(!root->node);
 	return 0;
 }
@@ -1025,20 +1023,19 @@ static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
 	 */
 	root->ref_cows = 0;
 
-	leaf = btrfs_alloc_free_block(trans, root, root->leafsize,
-				      0, BTRFS_TREE_LOG_OBJECTID,
-				      trans->transid, 0, 0, 0);
+	leaf = btrfs_alloc_free_block(trans, root, root->leafsize, 0,
+				      BTRFS_TREE_LOG_OBJECTID, NULL, 0, 0, 0);
 	if (IS_ERR(leaf)) {
 		kfree(root);
 		return ERR_CAST(leaf);
 	}
 
+	memset_extent_buffer(leaf, 0, 0, sizeof(struct btrfs_header));
+	btrfs_set_header_bytenr(leaf, leaf->start);
+	btrfs_set_header_generation(leaf, trans->transid);
+	btrfs_set_header_backref_rev(leaf, BTRFS_MIXED_BACKREF_REV);
+	btrfs_set_header_owner(leaf, BTRFS_TREE_LOG_OBJECTID);
 	root->node = leaf;
-	btrfs_set_header_nritems(root->node, 0);
-	btrfs_set_header_level(root->node, 0);
-	btrfs_set_header_bytenr(root->node, root->node->start);
-	btrfs_set_header_generation(root->node, trans->transid);
-	btrfs_set_header_owner(root->node, BTRFS_TREE_LOG_OBJECTID);
 
 	write_extent_buffer(root->node, root->fs_info->fsid,
 			    (unsigned long)btrfs_header_fsid(root->node),
@@ -1081,8 +1078,7 @@ int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
 	inode_item->nbytes = cpu_to_le64(root->leafsize);
 	inode_item->mode = cpu_to_le32(S_IFDIR | 0755);
 
-	btrfs_set_root_bytenr(&log_root->root_item, log_root->node->start);
-	btrfs_set_root_generation(&log_root->root_item, trans->transid);
+	btrfs_set_root_node(&log_root->root_item, log_root->node);
 
 	WARN_ON(root->log_root);
 	root->log_root = log_root;
@@ -1144,6 +1140,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
 				     blocksize, generation);
+	root->commit_root = btrfs_root_node(root);
 	BUG_ON(!root->node);
 insert:
 	if (location->objectid != BTRFS_TREE_LOG_OBJECTID) {
@@ -1210,7 +1207,7 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	}
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
 		ret = btrfs_find_dead_roots(fs_info->tree_root,
-					    root->root_key.objectid, root);
+					    root->root_key.objectid);
 		BUG_ON(ret);
 		btrfs_orphan_cleanup(root);
 	}
@@ -1569,8 +1566,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
-	atomic_set(&fs_info->throttles, 0);
-	atomic_set(&fs_info->throttle_gen, 0);
 	fs_info->sb = sb;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
@@ -1598,6 +1593,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
 	fs_info->btree_inode->i_mapping->backing_dev_info = &fs_info->bdi;
 
+	RB_CLEAR_NODE(&BTRFS_I(fs_info->btree_inode)->rb_node);
 	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,
 			     fs_info->btree_inode->i_mapping,
 			     GFP_NOFS);
@@ -1613,10 +1609,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 
-	INIT_LIST_HEAD(&fs_info->dead_reloc_roots);
-	btrfs_leaf_ref_tree_init(&fs_info->reloc_ref_tree);
-	btrfs_leaf_ref_tree_init(&fs_info->shared_ref_tree);
-
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));
@@ -1674,6 +1666,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_iput;
 	}
 
+	features = btrfs_super_incompat_flags(disk_super);
+	if (!(features & BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF)) {
+		features |= BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF;
+		btrfs_set_super_incompat_flags(disk_super, features);
+	}
+
 	features = btrfs_super_compat_ro_flags(disk_super) &
 		~BTRFS_FEATURE_COMPAT_RO_SUPP;
 	if (!(sb->s_flags & MS_RDONLY) && features) {
@@ -1771,7 +1769,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (ret) {
 		printk(KERN_WARNING "btrfs: failed to read the system "
 		       "array on %s\n", sb->s_id);
-		goto fail_sys_array;
+		goto fail_sb_buffer;
 	}
 
 	blocksize = btrfs_level_size(tree_root,
@@ -1785,6 +1783,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 					   btrfs_super_chunk_root(disk_super),
 					   blocksize, generation);
 	BUG_ON(!chunk_root->node);
+	btrfs_set_root_node(&chunk_root->root_item, chunk_root->node);
+	chunk_root->commit_root = btrfs_root_node(chunk_root);
 
 	read_extent_buffer(chunk_root->node, fs_info->chunk_tree_uuid,
 	   (unsigned long)btrfs_header_chunk_tree_uuid(chunk_root->node),
@@ -1810,7 +1810,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 					  blocksize, generation);
 	if (!tree_root->node)
 		goto fail_chunk_root;
-
+	btrfs_set_root_node(&tree_root->root_item, tree_root->node);
+	tree_root->commit_root = btrfs_root_node(tree_root);
 
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
@@ -1820,14 +1821,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_DEV_TREE_OBJECTID, dev_root);
-	dev_root->track_dirty = 1;
 	if (ret)
 		goto fail_extent_root;
+	dev_root->track_dirty = 1;
 
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_CSUM_TREE_OBJECTID, csum_root);
 	if (ret)
-		goto fail_extent_root;
+		goto fail_dev_root;
 
 	csum_root->track_dirty = 1;
 
@@ -1881,7 +1882,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	}
 
 	if (!(sb->s_flags & MS_RDONLY)) {
-		ret = btrfs_cleanup_reloc_trees(tree_root);
+		ret = btrfs_recover_relocation(tree_root);
 		BUG_ON(ret);
 	}
 
@@ -1908,14 +1909,19 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 fail_csum_root:
 	free_extent_buffer(csum_root->node);
+	free_extent_buffer(csum_root->commit_root);
+fail_dev_root:
+	free_extent_buffer(dev_root->node);
+	free_extent_buffer(dev_root->commit_root);
 fail_extent_root:
 	free_extent_buffer(extent_root->node);
+	free_extent_buffer(extent_root->commit_root);
 fail_tree_root:
 	free_extent_buffer(tree_root->node);
+	free_extent_buffer(tree_root->commit_root);
 fail_chunk_root:
 	free_extent_buffer(chunk_root->node);
-fail_sys_array:
-	free_extent_buffer(dev_root->node);
+	free_extent_buffer(chunk_root->commit_root);
 fail_sb_buffer:
 	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->delalloc_workers);
@@ -2173,6 +2179,7 @@ int write_ctree_super(struct btrfs_trans_handle *trans,
 
 int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 {
+	WARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
 	if (root->anon_super.s_dev) {
@@ -2219,10 +2226,12 @@ int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 					     ARRAY_SIZE(gang));
 		if (!ret)
 			break;
+
+		root_objectid = gang[ret - 1]->root_key.objectid + 1;
 		for (i = 0; i < ret; i++) {
 			root_objectid = gang[i]->root_key.objectid;
 			ret = btrfs_find_dead_roots(fs_info->tree_root,
-						    root_objectid, gang[i]);
+						    root_objectid);
 			BUG_ON(ret);
 			btrfs_orphan_cleanup(gang[i]);
 		}
@@ -2278,20 +2287,16 @@ int close_ctree(struct btrfs_root *root)
 		       (unsigned long long)fs_info->total_ref_cache_size);
 	}
 
-	if (fs_info->extent_root->node)
-		free_extent_buffer(fs_info->extent_root->node);
-
-	if (fs_info->tree_root->node)
-		free_extent_buffer(fs_info->tree_root->node);
-
-	if (root->fs_info->chunk_root->node)
-		free_extent_buffer(root->fs_info->chunk_root->node);
-
-	if (root->fs_info->dev_root->node)
-		free_extent_buffer(root->fs_info->dev_root->node);
-
-	if (root->fs_info->csum_root->node)
-		free_extent_buffer(root->fs_info->csum_root->node);
+	free_extent_buffer(fs_info->extent_root->node);
+	free_extent_buffer(fs_info->extent_root->commit_root);
+	free_extent_buffer(fs_info->tree_root->node);
+	free_extent_buffer(fs_info->tree_root->commit_root);
+	free_extent_buffer(root->fs_info->chunk_root->node);
+	free_extent_buffer(root->fs_info->chunk_root->commit_root);
+	free_extent_buffer(root->fs_info->dev_root->node);
+	free_extent_buffer(root->fs_info->dev_root->commit_root);
+	free_extent_buffer(root->fs_info->csum_root->node);
+	free_extent_buffer(root->fs_info->csum_root->commit_root);
 
 	btrfs_free_block_groups(root->fs_info);
 

commit cc7b0c9b701a079016183f3546b4d720194b367f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 14 13:31:21 2009 -0400

    Btrfs: remove some WARN_ONs in the IO failure path
    
    These debugging WARN_ONs make too much console noise during regular
    IO failures.  An IO failure will still generate a number of messages
    as we verify checksums etc, but these two are not needed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0ff16d3331da..4b0ea0b80c23 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -848,8 +848,6 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 
 	if (ret == 0)
 		set_bit(EXTENT_BUFFER_UPTODATE, &buf->bflags);
-	else
-		WARN_ON(1);
 	return buf;
 
 }

commit 21380931eb4da4e29ac663d0221581282cbba208
Author: Joel Becker <joel.becker@oracle.com>
Date:   Tue Apr 21 12:38:29 2009 -0700

    Btrfs: Fix a bunch of printk() warnings.
    
    Just happened to notice a bunch of %llu vs u64 warnings.  Here's a patch
    to cast them all.
    
    Signed-off-by: Joel Becker <joel.becker@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aa0c259b9c28..0ff16d3331da 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1671,7 +1671,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (features) {
 		printk(KERN_ERR "BTRFS: couldn't mount because of "
 		       "unsupported optional features (%Lx).\n",
-		       features);
+		       (unsigned long long)features);
 		err = -EINVAL;
 		goto fail_iput;
 	}
@@ -1681,7 +1681,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!(sb->s_flags & MS_RDONLY) && features) {
 		printk(KERN_ERR "BTRFS: couldn't mount RDWR because of "
 		       "unsupported option features (%Lx).\n",
-		       features);
+		       (unsigned long long)features);
 		err = -EINVAL;
 		goto fail_iput;
 	}
@@ -2273,7 +2273,7 @@ int close_ctree(struct btrfs_root *root)
 
 	if (fs_info->delalloc_bytes) {
 		printk(KERN_INFO "btrfs: at unmount delalloc count %llu\n",
-		       fs_info->delalloc_bytes);
+		       (unsigned long long)fs_info->delalloc_bytes);
 	}
 	if (fs_info->total_ref_cache_size) {
 		printk(KERN_INFO "btrfs: at umount reference cache size %llu\n",

commit 193f284d4985db0370a8a1bbdfb20df548cf9ffb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 27 07:29:05 2009 -0400

    Btrfs: ratelimit IO error printks
    
    Btrfs has printks for various IO errors, including bad checksums and
    mismatches between what we expect the block headers to contain and what
    we actually find on the disk.
    
    Longer term we need a real reporting mechanism for this, but for now
    printk is going to have to do.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 77f9a3b824be..aa0c259b9c28 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -232,10 +232,14 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			memcpy(&found, result, csum_size);
 
 			read_extent_buffer(buf, &val, 0, csum_size);
-			printk(KERN_INFO "btrfs: %s checksum verify failed "
-			       "on %llu wanted %X found %X level %d\n",
-			       root->fs_info->sb->s_id,
-			       buf->start, val, found, btrfs_header_level(buf));
+			if (printk_ratelimit()) {
+				printk(KERN_INFO "btrfs: %s checksum verify "
+				       "failed on %llu wanted %X found %X "
+				       "level %d\n",
+				       root->fs_info->sb->s_id,
+				       (unsigned long long)buf->start, val, found,
+				       btrfs_header_level(buf));
+			}
 			if (result != (char *)&inline_result)
 				kfree(result);
 			return 1;
@@ -268,10 +272,13 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 		ret = 0;
 		goto out;
 	}
-	printk("parent transid verify failed on %llu wanted %llu found %llu\n",
-	       (unsigned long long)eb->start,
-	       (unsigned long long)parent_transid,
-	       (unsigned long long)btrfs_header_generation(eb));
+	if (printk_ratelimit()) {
+		printk("parent transid verify failed on %llu wanted %llu "
+		       "found %llu\n",
+		       (unsigned long long)eb->start,
+		       (unsigned long long)parent_transid,
+		       (unsigned long long)btrfs_header_generation(eb));
+	}
 	ret = 1;
 	clear_extent_buffer_uptodate(io_tree, eb);
 out:
@@ -415,9 +422,12 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
-		printk(KERN_INFO "btrfs bad tree block start %llu %llu\n",
-		       (unsigned long long)found_start,
-		       (unsigned long long)eb->start);
+		if (printk_ratelimit()) {
+			printk(KERN_INFO "btrfs bad tree block start "
+			       "%llu %llu\n",
+			       (unsigned long long)found_start,
+			       (unsigned long long)eb->start);
+		}
 		ret = -EIO;
 		goto err;
 	}
@@ -429,8 +439,10 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		goto err;
 	}
 	if (check_tree_block_fsid(root, eb)) {
-		printk(KERN_INFO "btrfs bad fsid on block %llu\n",
-		       (unsigned long long)eb->start);
+		if (printk_ratelimit()) {
+			printk(KERN_INFO "btrfs bad fsid on block %llu\n",
+			       (unsigned long long)eb->start);
+		}
 		ret = -EIO;
 		goto err;
 	}

commit b7967db75a38df4891b22efe1b0969b9357eb946
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 27 07:29:04 2009 -0400

    Btrfs: remove #if 0 code
    
    Btrfs had some old code sitting around under #if 0, this drops it.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 44c94d808e2b..77f9a3b824be 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -584,18 +584,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 		btrfs_set_work_high_prio(&async->work);
 
 	btrfs_queue_worker(&fs_info->workers, &async->work);
-#if 0
-	int limit = btrfs_async_submit_limit(fs_info);
-	if (atomic_read(&fs_info->nr_async_submits) > limit) {
-		wait_event_timeout(fs_info->async_submit_wait,
-			   (atomic_read(&fs_info->nr_async_submits) < limit),
-			   HZ/10);
 
-		wait_event_timeout(fs_info->async_submit_wait,
-			   (atomic_read(&fs_info->nr_async_bios) < limit),
-			   HZ/10);
-	}
-#endif
 	while (atomic_read(&fs_info->async_submit_draining) &&
 	      atomic_read(&fs_info->nr_async_submits)) {
 		wait_event(fs_info->async_submit_wait,
@@ -770,27 +759,6 @@ static void btree_invalidatepage(struct page *page, unsigned long offset)
 	}
 }
 
-#if 0
-static int btree_writepage(struct page *page, struct writeback_control *wbc)
-{
-	struct buffer_head *bh;
-	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
-	struct buffer_head *head;
-	if (!page_has_buffers(page)) {
-		create_empty_buffers(page, root->fs_info->sb->s_blocksize,
-					(1 << BH_Dirty)|(1 << BH_Uptodate));
-	}
-	head = page_buffers(page);
-	bh = head;
-	do {
-		if (buffer_dirty(bh))
-			csum_tree_block(root, bh, 0);
-		bh = bh->b_this_page;
-	} while (bh != head);
-	return block_write_full_page(page, btree_get_block, wbc);
-}
-#endif
-
 static struct address_space_operations btree_aops = {
 	.readpage	= btree_readpage,
 	.writepage	= btree_writepage,
@@ -1278,11 +1246,7 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	int ret = 0;
 	struct btrfs_device *device;
 	struct backing_dev_info *bdi;
-#if 0
-	if ((bdi_bits & (1 << BDI_write_congested)) &&
-	    btrfs_congested_async(info, 0))
-		return 1;
-#endif
+
 	list_for_each_entry(device, &info->fs_devices->devices, dev_list) {
 		if (!device->bdev)
 			continue;
@@ -2334,16 +2298,6 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
 
-#if 0
-	while (!list_empty(&fs_info->hashers)) {
-		struct btrfs_hasher *hasher;
-		hasher = list_entry(fs_info->hashers.next, struct btrfs_hasher,
-				    hashers);
-		list_del(&hasher->hashers);
-		crypto_free_hash(&fs_info->hash_tfm);
-		kfree(hasher);
-	}
-#endif
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 

commit 97e728d4353f38c87bf0804cdfd79a9b13fc2c3e
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Apr 21 17:40:57 2009 -0400

    Btrfs: try to keep a healthy ratio of metadata vs data block groups
    
    This patch makes the chunk allocator keep a good ratio of metadata vs data
    block groups.  By default for every 8 data block groups, we'll allocate 1
    metadata chunk, or about 12% of the disk will be allocated for metadata.  This
    can be changed by specifying the metadata_ratio mount option.
    
    This is simply the number of data block groups that have to be allocated to
    force a metadata chunk allocation.  By making sure we allocate metadata chunks
    more often, we are less likely to get into situations where the whole disk
    has been allocated as data block groups.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a6b83744b05d..44c94d808e2b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1604,6 +1604,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;
+	fs_info->metadata_ratio = 8;
 
 	fs_info->thread_pool_size = min_t(unsigned long,
 					  num_online_cpus() + 2, 8);

commit d313d7a31a752c88f7288692bd98e66d0789779b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 20 15:50:09 2009 -0400

    Btrfs: add a priority queue to the async thread helpers
    
    Btrfs is using WRITE_SYNC_PLUG to send down synchronous IOs with a
    higher priority.  But, the checksumming helper threads prevent it
    from being fully effective.
    
    There are two problems.  First, a big queue of pending checksumming
    will delay the synchronous IO behind other lower priority writes.  Second,
    the checksumming uses an ordered async work queue.  The ordering makes sure
    that IOs are sent to the block layer in the same order they are sent
    to the checksumming threads.  Usually this gives us less seeky IO.
    
    But, when we start mixing IO priorities, the lower priority IO can delay
    the higher priority IO.
    
    This patch solves both problems by adding a high priority list to the async
    helper threads, and a new btrfs_set_work_high_prio(), which is used
    to make put a new async work item onto the higher priority list.
    
    The ordering is still done on high priority IO, but all of the high
    priority bios are ordered separately from the low priority bios.  This
    ordering is purely an IO optimization, it is not involved in data
    or metadata integrity.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fec18b43c2c3..a6b83744b05d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -579,6 +579,10 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->bio_flags = bio_flags;
 
 	atomic_inc(&fs_info->nr_async_submits);
+
+	if (rw & (1 << BIO_RW_SYNCIO))
+		btrfs_set_work_high_prio(&async->work);
+
 	btrfs_queue_worker(&fs_info->workers, &async->work);
 #if 0
 	int limit = btrfs_async_submit_limit(fs_info);
@@ -656,6 +660,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
 				     mirror_num, 0);
 	}
+
 	/*
 	 * kthread helpers are used to submit writes so that checksumming
 	 * can happen in parallel across all CPUs

commit ffbd517d5a8c8e93ddd11046434fb029f3df73aa
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 20 15:50:09 2009 -0400

    Btrfs: use WRITE_SYNC for synchronous writes
    
    Part of reducing fsync/O_SYNC/O_DIRECT latencies is using WRITE_SYNC for
    writes we plan on waiting on in the near future.  This patch
    mirrors recent changes in other filesystems and the generic code to
    use WRITE_SYNC when WB_SYNC_ALL is passed and to use WRITE_SYNC for
    other latency critical writes.
    
    Btrfs uses async worker threads for checksumming before the write is done,
    and then again to actually submit the bios.  The bio submission code just
    runs a per-device list of bios that need to be sent down the pipe.
    
    This list is split into low priority and high priority lists so the
    WRITE_SYNC IO happens first.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 92caa8035f36..fec18b43c2c3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2095,10 +2095,10 @@ static int write_dev_supers(struct btrfs_device *device,
 				device->barriers = 0;
 				get_bh(bh);
 				lock_buffer(bh);
-				ret = submit_bh(WRITE, bh);
+				ret = submit_bh(WRITE_SYNC, bh);
 			}
 		} else {
-			ret = submit_bh(WRITE, bh);
+			ret = submit_bh(WRITE_SYNC, bh);
 		}
 
 		if (!ret && wait) {

commit b983471794e568fd71fa767da77a62ba517c3e63
Merge: 5a3ae2760578 c293498be698
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 3 15:14:44 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: BUG to BUG_ON changes
      Btrfs: remove dead code
      Btrfs: remove dead code
      Btrfs: fix typos in comments
      Btrfs: remove unused ftrace include
      Btrfs: fix __ucmpdi2 compile bug on 32 bit builds
      Btrfs: free inode struct when btrfs_new_inode fails
      Btrfs: fix race in worker_loop
      Btrfs: add flushoncommit mount option
      Btrfs: notreelog mount option
      Btrfs: introduce btrfs_show_options
      Btrfs: rework allocation clustering
      Btrfs: Optimize locking in btrfs_next_leaf()
      Btrfs: break up btrfs_search_slot into smaller pieces
      Btrfs: kill the pinned_mutex
      Btrfs: kill the block group alloc mutex
      Btrfs: clean up find_free_extent
      Btrfs: free space cache cleanups
      Btrfs: unplug in the async bio submission threads
      Btrfs: keep processing bios for a given bdev if our proc is batching

commit 3e7ad38d20ad113158d1b4c9de0f51c04f50d4f7
Author: Dan Carpenter <error27@gmail.com>
Date:   Thu Apr 2 16:46:06 2009 -0400

    Btrfs: remove dead code
    
    Remove an unneeded return statement and conditional
    
    Signed-off-by: Dan Carpenter <error27@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e68ef7b456b0..a850c3ac196d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1413,8 +1413,6 @@ static int bio_ready_for_csum(struct bio *bio)
 
 	ret = extent_range_uptodate(io_tree, start + length,
 				    start + buf_len - 1);
-	if (ret == 1)
-		return ret;
 	return ret;
 }
 

commit fa9c0d795f7b57c76560b7fac703f5d341210e28
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 3 09:47:43 2009 -0400

    Btrfs: rework allocation clustering
    
    Because btrfs is copy-on-write, we end up picking new locations for
    blocks very often.  This makes it fairly difficult to maintain perfect
    read patterns over time, but we can at least do some optimizations
    for writes.
    
    This is done today by remembering the last place we allocated and
    trying to find a free space hole big enough to hold more than just one
    allocation.  The end result is that we tend to write sequentially to
    the drive.
    
    This happens all the time for metadata and it happens for data
    when mounted -o ssd.  But, the way we record it is fairly racey
    and it tends to fragment the free space over time because we are trying
    to allocate fairly large areas at once.
    
    This commit gets rid of the races by adding a free space cluster object
    with dedicated locking to make sure that only one process at a time
    is out replacing the cluster.
    
    The free space fragmentation is somewhat solved by allowing a cluster
    to be comprised of smaller free space extents.  This part definitely
    adds some CPU time to the cluster allocations, but it allows the allocator
    to consume the small holes left behind by cow.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ea59ebfa505d..e68ef7b456b0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -38,6 +38,7 @@
 #include "locking.h"
 #include "ref-cache.h"
 #include "tree-log.h"
+#include "free-space-cache.h"
 
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
@@ -1652,6 +1653,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->cleaner_mutex);
 	mutex_init(&fs_info->volume_mutex);
 	mutex_init(&fs_info->tree_reloc_mutex);
+
+	btrfs_init_free_cluster(&fs_info->meta_alloc_cluster);
+	btrfs_init_free_cluster(&fs_info->data_alloc_cluster);
+
 	init_waitqueue_head(&fs_info->transaction_throttle);
 	init_waitqueue_head(&fs_info->transaction_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);

commit 04018de5d41e6490840de9399e029fd30e78576f
Author: Josef Bacik <jbacik@redhat.com>
Date:   Fri Apr 3 10:14:18 2009 -0400

    Btrfs: kill the pinned_mutex
    
    This patch removes the pinned_mutex.  The extent io map has an internal tree
    lock that protects the tree itself, and since we only copy the extent io map
    when we are committing the transaction we don't need it there.  We also don't
    need it when caching the block group since searching through the tree is also
    protected by the internal map spin lock.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1747dfd18654..ea59ebfa505d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1647,7 +1647,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->ordered_operations_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
 	mutex_init(&fs_info->drop_mutex);
-	mutex_init(&fs_info->pinned_mutex);
 	mutex_init(&fs_info->chunk_mutex);
 	mutex_init(&fs_info->transaction_kthread_mutex);
 	mutex_init(&fs_info->cleaner_mutex);

commit c226fd659fa7b6a7b038df5ae6856a68514bacde
Merge: c09bca786ff9 d57e62b89796
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 1 10:20:44 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/mason/btrfs-unstable:
      Btrfs: try to free metadata pages when we free btree blocks
      Btrfs: add extra flushing for renames and truncates
      Btrfs: make sure btrfs_update_delayed_ref doesn't increase ref_mod
      Btrfs: optimize fsyncs on old files
      Btrfs: tree logging unlink/rename fixes
      Btrfs: Make sure i_nlink doesn't hit zero too soon during log replay
      Btrfs: limit balancing work while flushing delayed refs
      Btrfs: readahead checksums during btrfs_finish_ordered_io
      Btrfs: leave btree locks spinning more often
      Btrfs: Only let very young transactions grow during commit
      Btrfs: Check for a blocking lock before taking the spin
      Btrfs: reduce stack in cow_file_range
      Btrfs: reduce stalls during transaction commit
      Btrfs: process the delayed reference queue in clusters
      Btrfs: try to cleanup delayed refs while freeing extents
      Btrfs: reduce stack usage in some crucial tree balancing functions
      Btrfs: do extent allocation and reference count updates in the background
      Btrfs: don't preallocate metadata blocks during btrfs_search_slot

commit 5a3f23d515a2ebf0c750db80579ca57b28cbce6d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 31 13:27:11 2009 -0400

    Btrfs: add extra flushing for renames and truncates
    
    Renames and truncates are both common ways to replace old data with new
    data.  The filesystem can make an effort to make sure the new data is
    on disk before actually replacing the old data.
    
    This is especially important for rename, which many application use as
    though it were atomic for both the data and the metadata involved.  The
    current btrfs code will happily replace a file that is fully on disk
    with one that was just created and still has pending IO.
    
    If we crash after transaction commit but before the IO is done, we'll end
    up replacing a good file with a zero length file.  The solution used
    here is to create a list of inodes that need special ordering and force
    them to disk before the commit is done.  This is similar to the
    ext3 style data=ordering, except it is only done on selected files.
    
    Btrfs is able to get away with this because it does not wait on commits
    very often, even for fsync (which use a sub-commit).
    
    For renames, we order the file when it wasn't already
    on disk and when it is replacing an existing file.  Larger files
    are sent to filemap_flush right away (before the transaction handle is
    opened).
    
    For truncates, we order if the file goes from non-zero size down to
    zero size.  This is a little different, because at the time of the
    truncate the file has no dirty bytes to order.  But, we flag the inode
    so that it is added to the ordered list on close (via release method).  We
    also immediately add it to the ordered list of the current transaction
    so that we can try to flush down any writes the application sneaks in
    before commit.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9244cd7313d4..1747dfd18654 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1572,6 +1572,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->hashers);
 	INIT_LIST_HEAD(&fs_info->delalloc_inodes);
+	INIT_LIST_HEAD(&fs_info->ordered_operations);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);
 	spin_lock_init(&fs_info->ref_cache_lock);
@@ -1643,6 +1644,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	insert_inode_hash(fs_info->btree_inode);
 
 	mutex_init(&fs_info->trans_mutex);
+	mutex_init(&fs_info->ordered_operations_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
 	mutex_init(&fs_info->drop_mutex);
 	mutex_init(&fs_info->pinned_mutex);

commit 6933c02e9cc47c2df3c016621a013ec79fb4203f
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Mar 17 09:36:37 2009 +0100

    btrfs: get rid of current_is_pdflush() in btrfs_btree_balance_dirty
    
    Chris says it's safe to kill.
    
    Acked-by: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3e18175248e0..6ec80c0fc869 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -2385,7 +2385,7 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	unsigned long thresh = 32 * 1024 * 1024;
 	tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 
-	if (current_is_pdflush() || current->flags & PF_MEMALLOC)
+	if (current->flags & PF_MEMALLOC)
 		return;
 
 	num_dirty = count_range_bits(tree, &start, (u64)-1,

commit b9473439d3e84d9fc1a0a83faca69cc1b7566341
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 11:00:37 2009 -0400

    Btrfs: leave btree locks spinning more often
    
    btrfs_mark_buffer dirty would set dirty bits in the extent_io tree
    for the buffers it was dirtying.  This may require a kmalloc and it
    was not atomic.  So, anyone who called btrfs_mark_buffer_dirty had to
    set any btree locks they were holding to blocking first.
    
    This commit changes dirty tracking for extent buffers to just use a flag
    in the extent buffer.  Now that we have one and only one extent buffer
    per page, this can be safely done without losing dirty bits along the way.
    
    This also introduces a path->leave_spinning flag that callers of
    btrfs_search_slot can use to indicate they will properly deal with a
    path returned where all the locks are spinning instead of blocking.
    
    Many of the btree search callers now expect spinning paths,
    resulting in better btree concurrency overall.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1f1d89b18818..9244cd7313d4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -668,14 +668,31 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct extent_io_tree *tree;
+	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
+	struct extent_buffer *eb;
+	int was_dirty;
+
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
+	if (!(current->flags & PF_MEMALLOC)) {
+		return extent_write_full_page(tree, page,
+					      btree_get_extent, wbc);
+	}
 
-	if (current->flags & PF_MEMALLOC) {
-		redirty_page_for_writepage(wbc, page);
-		unlock_page(page);
-		return 0;
+	redirty_page_for_writepage(wbc, page);
+	eb = btrfs_find_tree_block(root, page_offset(page),
+				      PAGE_CACHE_SIZE);
+	WARN_ON(!eb);
+
+	was_dirty = test_and_set_bit(EXTENT_BUFFER_DIRTY, &eb->bflags);
+	if (!was_dirty) {
+		spin_lock(&root->fs_info->delalloc_lock);
+		root->fs_info->dirty_metadata_bytes += PAGE_CACHE_SIZE;
+		spin_unlock(&root->fs_info->delalloc_lock);
 	}
-	return extent_write_full_page(tree, page, btree_get_extent, wbc);
+	free_extent_buffer(eb);
+
+	unlock_page(page);
+	return 0;
 }
 
 static int btree_writepages(struct address_space *mapping,
@@ -684,15 +701,15 @@ static int btree_writepages(struct address_space *mapping,
 	struct extent_io_tree *tree;
 	tree = &BTRFS_I(mapping->host)->io_tree;
 	if (wbc->sync_mode == WB_SYNC_NONE) {
+		struct btrfs_root *root = BTRFS_I(mapping->host)->root;
 		u64 num_dirty;
-		u64 start = 0;
 		unsigned long thresh = 32 * 1024 * 1024;
 
 		if (wbc->for_kupdate)
 			return 0;
 
-		num_dirty = count_range_bits(tree, &start, (u64)-1,
-					     thresh, EXTENT_DIRTY);
+		/* this is a bit racy, but that's ok */
+		num_dirty = root->fs_info->dirty_metadata_bytes;
 		if (num_dirty < thresh)
 			return 0;
 	}
@@ -859,9 +876,17 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 	    root->fs_info->running_transaction->transid) {
 		btrfs_assert_tree_locked(buf);
 
-		/* ugh, clear_extent_buffer_dirty can be expensive */
-		btrfs_set_lock_blocking(buf);
+		if (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &buf->bflags)) {
+			spin_lock(&root->fs_info->delalloc_lock);
+			if (root->fs_info->dirty_metadata_bytes >= buf->len)
+				root->fs_info->dirty_metadata_bytes -= buf->len;
+			else
+				WARN_ON(1);
+			spin_unlock(&root->fs_info->delalloc_lock);
+		}
 
+		/* ugh, clear_extent_buffer_dirty needs to lock the page */
+		btrfs_set_lock_blocking(buf);
 		clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree,
 					  buf);
 	}
@@ -2348,8 +2373,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	u64 transid = btrfs_header_generation(buf);
 	struct inode *btree_inode = root->fs_info->btree_inode;
-
-	btrfs_set_lock_blocking(buf);
+	int was_dirty;
 
 	btrfs_assert_tree_locked(buf);
 	if (transid != root->fs_info->generation) {
@@ -2360,7 +2384,13 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 			(unsigned long long)root->fs_info->generation);
 		WARN_ON(1);
 	}
-	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree, buf);
+	was_dirty = set_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree,
+					    buf);
+	if (!was_dirty) {
+		spin_lock(&root->fs_info->delalloc_lock);
+		root->fs_info->dirty_metadata_bytes += buf->len;
+		spin_unlock(&root->fs_info->delalloc_lock);
+	}
 }
 
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
@@ -2400,6 +2430,7 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 int btree_lock_page_hook(struct page *page)
 {
 	struct inode *inode = page->mapping->host;
+	struct btrfs_root *root = BTRFS_I(inode)->root;
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
 	struct extent_buffer *eb;
 	unsigned long len;
@@ -2415,6 +2446,16 @@ int btree_lock_page_hook(struct page *page)
 
 	btrfs_tree_lock(eb);
 	btrfs_set_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN);
+
+	if (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &eb->bflags)) {
+		spin_lock(&root->fs_info->delalloc_lock);
+		if (root->fs_info->dirty_metadata_bytes >= eb->len)
+			root->fs_info->dirty_metadata_bytes -= eb->len;
+		else
+			WARN_ON(1);
+		spin_unlock(&root->fs_info->delalloc_lock);
+	}
+
 	btrfs_tree_unlock(eb);
 	free_extent_buffer(eb);
 out:

commit c3e69d58e86c3917ae4e9e31b4acf490a7cafe60
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 10:17:05 2009 -0400

    Btrfs: process the delayed reference queue in clusters
    
    The delayed reference queue maintains pending operations that need to
    be done to the extent allocation tree.  These are processed by
    finding records in the tree that are not currently being processed one at
    a time.
    
    This is slow because it uses lots of time searching through the rbtree
    and because it creates lock contention on the extent allocation tree
    when lots of different procs are running delayed refs at the same time.
    
    This commit changes things to grab a cluster of refs for processing,
    using a cursor into the rbtree as the starting point of the next search.
    This way we walk smoothly through the rbtree.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4f43e227a297..1f1d89b18818 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1458,7 +1458,6 @@ static int transaction_kthread(void *arg)
 	struct btrfs_root *root = arg;
 	struct btrfs_trans_handle *trans;
 	struct btrfs_transaction *cur;
-	struct btrfs_fs_info *info = root->fs_info;
 	unsigned long now;
 	unsigned long delay;
 	int ret;
@@ -1481,24 +1480,8 @@ static int transaction_kthread(void *arg)
 
 		now = get_seconds();
 		if (now < cur->start_time || now - cur->start_time < 30) {
-			unsigned long num_delayed;
-			num_delayed = cur->delayed_refs.num_entries;
 			mutex_unlock(&root->fs_info->trans_mutex);
 			delay = HZ * 5;
-
-			/*
-			 * we may have been woken up early to start
-			 * processing the delayed extent ref updates
-			 * If so, run some of them and then loop around again
-			 * to see if we need to force a commit
-			 */
-			if (num_delayed > 64) {
-				mutex_unlock(&info->transaction_kthread_mutex);
-				trans = btrfs_start_transaction(root, 1);
-				btrfs_run_delayed_refs(trans, root, 256);
-				btrfs_end_transaction(trans, root);
-				continue;
-			}
 			goto sleep;
 		}
 		mutex_unlock(&root->fs_info->trans_mutex);

commit 56bec294dea971335d4466b30f2d959f28f6e36d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 10:10:06 2009 -0400

    Btrfs: do extent allocation and reference count updates in the background
    
    The extent allocation tree maintains a reference count and full
    back reference information for every extent allocated in the
    filesystem.  For subvolume and snapshot trees, every time
    a block goes through COW, the new copy of the block adds a reference
    on every block it points to.
    
    If a btree node points to 150 leaves, then the COW code needs to go
    and add backrefs on 150 different extents, which might be spread all
    over the extent allocation tree.
    
    These updates currently happen during btrfs_cow_block, and most COWs
    happen during btrfs_search_slot.  btrfs_search_slot has locks held
    on both the parent and the node we are COWing, and so we really want
    to avoid IO during the COW if we can.
    
    This commit adds an rbtree of pending reference count updates and extent
    allocations.  The tree is ordered by byte number of the extent and byte number
    of the parent for the back reference.  The tree allows us to:
    
    1) Modify back references in something close to disk order, reducing seeks
    2) Significantly reduce the number of modifications made as block pointers
    are balanced around
    3) Do all of the extent insertion and back reference modifications outside
    of the performance critical btrfs_search_slot code.
    
    #3 has the added benefit of greatly reducing the btrfs stack footprint.
    The extent allocation tree modifications are done without the deep
    (and somewhat recursive) call chains used in the past.
    
    These delayed back reference updates must be done before the transaction
    commits, and so the rbtree is tied to the transaction.  Throttling is
    implemented to help keep the queue of backrefs at a reasonable size.
    
    Since there was a similar mechanism in place for the extent tree
    extents, that is removed and replaced by the delayed reference tree.
    
    Yan Zheng <yan.zheng@oracle.com> helped review and fixup this code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3e18175248e0..4f43e227a297 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1458,6 +1458,7 @@ static int transaction_kthread(void *arg)
 	struct btrfs_root *root = arg;
 	struct btrfs_trans_handle *trans;
 	struct btrfs_transaction *cur;
+	struct btrfs_fs_info *info = root->fs_info;
 	unsigned long now;
 	unsigned long delay;
 	int ret;
@@ -1471,12 +1472,6 @@ static int transaction_kthread(void *arg)
 		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
 		mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
-		if (root->fs_info->total_ref_cache_size > 20 * 1024 * 1024) {
-			printk(KERN_INFO "btrfs: total reference cache "
-			       "size %llu\n",
-			       root->fs_info->total_ref_cache_size);
-		}
-
 		mutex_lock(&root->fs_info->trans_mutex);
 		cur = root->fs_info->running_transaction;
 		if (!cur) {
@@ -1486,13 +1481,30 @@ static int transaction_kthread(void *arg)
 
 		now = get_seconds();
 		if (now < cur->start_time || now - cur->start_time < 30) {
+			unsigned long num_delayed;
+			num_delayed = cur->delayed_refs.num_entries;
 			mutex_unlock(&root->fs_info->trans_mutex);
 			delay = HZ * 5;
+
+			/*
+			 * we may have been woken up early to start
+			 * processing the delayed extent ref updates
+			 * If so, run some of them and then loop around again
+			 * to see if we need to force a commit
+			 */
+			if (num_delayed > 64) {
+				mutex_unlock(&info->transaction_kthread_mutex);
+				trans = btrfs_start_transaction(root, 1);
+				btrfs_run_delayed_refs(trans, root, 256);
+				btrfs_end_transaction(trans, root);
+				continue;
+			}
 			goto sleep;
 		}
 		mutex_unlock(&root->fs_info->trans_mutex);
 		trans = btrfs_start_transaction(root, 1);
 		ret = btrfs_commit_transaction(trans, root);
+
 sleep:
 		wake_up_process(root->fs_info->cleaner_kthread);
 		mutex_unlock(&root->fs_info->transaction_kthread_mutex);
@@ -1611,10 +1623,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	extent_io_tree_init(&fs_info->pinned_extents,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
-	extent_io_tree_init(&fs_info->pending_del,
-			     fs_info->btree_inode->i_mapping, GFP_NOFS);
-	extent_io_tree_init(&fs_info->extent_ins,
-			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 
 	INIT_LIST_HEAD(&fs_info->dead_reloc_roots);
@@ -1629,7 +1637,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
 	mutex_init(&fs_info->drop_mutex);
-	mutex_init(&fs_info->extent_ins_mutex);
 	mutex_init(&fs_info->pinned_mutex);
 	mutex_init(&fs_info->chunk_mutex);
 	mutex_init(&fs_info->transaction_kthread_mutex);

commit b9447ef80bd301b932ac4d85c9622e929de5fd62
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 9 11:45:38 2009 -0400

    Btrfs: fix spinlock assertions on UP systems
    
    btrfs_tree_locked was being used to make sure a given extent_buffer was
    properly locked in a few places.  But, it wasn't correct for UP compiled
    kernels.
    
    This switches it to using assert_spin_locked instead, and renames it to
    btrfs_assert_tree_locked to better reflect how it was really being used.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index adda739a0215..3e18175248e0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -857,7 +857,7 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	if (btrfs_header_generation(buf) ==
 	    root->fs_info->running_transaction->transid) {
-		WARN_ON(!btrfs_tree_locked(buf));
+		btrfs_assert_tree_locked(buf);
 
 		/* ugh, clear_extent_buffer_dirty can be expensive */
 		btrfs_set_lock_blocking(buf);
@@ -2361,7 +2361,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 
 	btrfs_set_lock_blocking(buf);
 
-	WARN_ON(!btrfs_tree_locked(buf));
+	btrfs_assert_tree_locked(buf);
 	if (transid != root->fs_info->generation) {
 		printk(KERN_CRIT "btrfs transid mismatch buffer %llu, "
 		       "found %llu running %llu\n",

commit 4008c04a07c73ec3cb1be4c1391d2159a8f75d6d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Feb 12 14:09:45 2009 -0500

    Btrfs: make a lockdep class for the extent buffer locks
    
    Btrfs is currently using spin_lock_nested with a nested value based
    on the tree depth of the block.  But, this doesn't quite work because
    the max tree depth is bigger than what spin_lock_nested can deal with,
    and because locks are sometimes taken before the level field is filled in.
    
    The solution here is to use lockdep_set_class_and_name instead, and to
    set the class before unlocking the pages when the block is read from the
    disk and just after init of a freshly allocated tree block.
    
    btrfs_clear_path_blocking is also changed to take the locks in the proper
    order, and it also makes sure all the locks currently held are properly
    set to blocking before it tries to retake the spinlocks.  Otherwise, lockdep
    gets upset about bad lock orderin.
    
    The lockdep magic cam from Peter Zijlstra <peterz@infradead.org>
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5aebddd71193..adda739a0215 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -75,6 +75,40 @@ struct async_submit_bio {
 	struct btrfs_work work;
 };
 
+/* These are used to set the lockdep class on the extent buffer locks.
+ * The class is set by the readpage_end_io_hook after the buffer has
+ * passed csum validation but before the pages are unlocked.
+ *
+ * The lockdep class is also set by btrfs_init_new_buffer on freshly
+ * allocated blocks.
+ *
+ * The class is based on the level in the tree block, which allows lockdep
+ * to know that lower nodes nest inside the locks of higher nodes.
+ *
+ * We also add a check to make sure the highest level of the tree is
+ * the same as our lockdep setup here.  If BTRFS_MAX_LEVEL changes, this
+ * code needs update as well.
+ */
+#ifdef CONFIG_DEBUG_LOCK_ALLOC
+# if BTRFS_MAX_LEVEL != 8
+#  error
+# endif
+static struct lock_class_key btrfs_eb_class[BTRFS_MAX_LEVEL + 1];
+static const char *btrfs_eb_name[BTRFS_MAX_LEVEL + 1] = {
+	/* leaf */
+	"btrfs-extent-00",
+	"btrfs-extent-01",
+	"btrfs-extent-02",
+	"btrfs-extent-03",
+	"btrfs-extent-04",
+	"btrfs-extent-05",
+	"btrfs-extent-06",
+	"btrfs-extent-07",
+	/* highest possible level */
+	"btrfs-extent-08",
+};
+#endif
+
 /*
  * extents on the btree inode are pretty simple, there's one extent
  * that covers the entire device
@@ -347,6 +381,15 @@ static int check_tree_block_fsid(struct btrfs_root *root,
 	return ret;
 }
 
+#ifdef CONFIG_DEBUG_LOCK_ALLOC
+void btrfs_set_buffer_lockdep_class(struct extent_buffer *eb, int level)
+{
+	lockdep_set_class_and_name(&eb->lock,
+			   &btrfs_eb_class[level],
+			   btrfs_eb_name[level]);
+}
+#endif
+
 static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 			       struct extent_state *state)
 {
@@ -392,6 +435,8 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	}
 	found_level = btrfs_header_level(eb);
 
+	btrfs_set_buffer_lockdep_class(eb, found_level);
+
 	ret = csum_tree_block(root, eb, 1);
 	if (ret)
 		ret = -EIO;
@@ -1777,7 +1822,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_DEV_TREE_OBJECTID, dev_root);
 	dev_root->track_dirty = 1;
-
 	if (ret)
 		goto fail_extent_root;
 

commit b4ce94de9b4d64e8ab3cf155d13653c666e22b9b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 4 09:25:08 2009 -0500

    Btrfs: Change btree locking to use explicit blocking points
    
    Most of the btrfs metadata operations can be protected by a spinlock,
    but some operations still need to schedule.
    
    So far, btrfs has been using a mutex along with a trylock loop,
    most of the time it is able to avoid going for the full mutex, so
    the trylock loop is a big performance gain.
    
    This commit is step one for getting rid of the blocking locks entirely.
    btrfs_tree_lock takes a spinlock, and the code explicitly switches
    to a blocking lock when it starts an operation that can schedule.
    
    We'll be able get rid of the blocking locks in smaller pieces over time.
    Tracing allows us to find the most common cause of blocking, so we
    can start with the hot spots first.
    
    The basic idea is:
    
    btrfs_tree_lock() returns with the spin lock held
    
    btrfs_set_lock_blocking() sets the EXTENT_BUFFER_BLOCKING bit in
    the extent buffer flags, and then drops the spin lock.  The buffer is
    still considered locked by all of the btrfs code.
    
    If btrfs_tree_lock gets the spinlock but finds the blocking bit set, it drops
    the spin lock and waits on a wait queue for the blocking bit to go away.
    
    Much of the code that needs to set the blocking bit finishes without actually
    blocking a good percentage of the time.  So, an adaptive spin is still
    used against the blocking bit to avoid very high context switch rates.
    
    btrfs_clear_lock_blocking() clears the blocking bit and returns
    with the spinlock held again.
    
    btrfs_tree_unlock() can be called on either blocking or spinning locks,
    it does the right thing based on the blocking bit.
    
    ctree.c has a helper function to set/clear all the locked buffers in a
    path as blocking.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 549271607c17..5aebddd71193 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -799,7 +799,7 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 
 	if (ret == 0)
-		buf->flags |= EXTENT_UPTODATE;
+		set_bit(EXTENT_BUFFER_UPTODATE, &buf->bflags);
 	else
 		WARN_ON(1);
 	return buf;
@@ -813,6 +813,10 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 	if (btrfs_header_generation(buf) ==
 	    root->fs_info->running_transaction->transid) {
 		WARN_ON(!btrfs_tree_locked(buf));
+
+		/* ugh, clear_extent_buffer_dirty can be expensive */
+		btrfs_set_lock_blocking(buf);
+
 		clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree,
 					  buf);
 	}
@@ -2311,6 +2315,8 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	u64 transid = btrfs_header_generation(buf);
 	struct inode *btree_inode = root->fs_info->btree_inode;
 
+	btrfs_set_lock_blocking(buf);
+
 	WARN_ON(!btrfs_tree_locked(buf));
 	if (transid != root->fs_info->generation) {
 		printk(KERN_CRIT "btrfs transid mismatch buffer %llu, "
@@ -2353,7 +2359,7 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 	int ret;
 	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 	if (ret == 0)
-		buf->flags |= EXTENT_UPTODATE;
+		set_bit(EXTENT_BUFFER_UPTODATE, &buf->bflags);
 	return ret;
 }
 

commit c487685d7c18a8481900755aa5c56a7a74193101
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 4 09:24:25 2009 -0500

    Btrfs: hash_lock is no longer needed
    
    Before metadata is written to disk, it is updated to reflect that writeout
    has begun.  Once this update is done, the block must be cow'd before it
    can be modified again.
    
    This update was originally synchronized by using a per-fs spinlock.  Today
    the buffers for the metadata blocks are locked before writeout begins,
    and everyone that tests the flag has the buffer locked as well.
    
    So, the per-fs spinlock (called hash_lock for no good reason) is no
    longer required.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9c3810047976..549271607c17 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1503,7 +1503,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->hashers);
 	INIT_LIST_HEAD(&fs_info->delalloc_inodes);
-	spin_lock_init(&fs_info->hash_lock);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);
 	spin_lock_init(&fs_info->ref_cache_lock);
@@ -2361,7 +2360,6 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 int btree_lock_page_hook(struct page *page)
 {
 	struct inode *inode = page->mapping->host;
-	struct btrfs_root *root = BTRFS_I(inode)->root;
 	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
 	struct extent_buffer *eb;
 	unsigned long len;
@@ -2376,9 +2374,7 @@ int btree_lock_page_hook(struct page *page)
 		goto out;
 
 	btrfs_tree_lock(eb);
-	spin_lock(&root->fs_info->hash_lock);
 	btrfs_set_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN);
-	spin_unlock(&root->fs_info->hash_lock);
 	btrfs_tree_unlock(eb);
 	free_extent_buffer(eb);
 out:

commit b51912c91fcf7581cc7b4550f1bb96422809d9ed
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 4 09:23:24 2009 -0500

    Btrfs: async threads should try harder to find work
    
    Tracing shows the delay between when an async thread goes to sleep
    and when more work is added is often very short.  This commit adds
    a little bit of delay and extra checking to the code right before
    we schedule out.
    
    It allows more work to be added to the worker
    without requiring notifications from other procs.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7feac5a475e9..9c3810047976 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1679,6 +1679,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 * low idle thresh
 	 */
 	fs_info->endio_workers.idle_thresh = 4;
+	fs_info->endio_meta_workers.idle_thresh = 4;
+
 	fs_info->endio_write_workers.idle_thresh = 64;
 	fs_info->endio_meta_write_workers.idle_thresh = 64;
 

commit 7237f1833601dcc435a64176c2c347ec4bd959f9
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Jan 21 12:54:03 2009 -0500

    Btrfs: fix tree logs parallel sync
    
    To improve performance, btrfs_sync_log merges tree log sync
    requests. But it wrongly merges sync requests for different
    tree logs. If multiple tree logs are synced at the same time,
    only one of them actually gets synced.
    
    This patch has following changes to fix the bug:
    
    Move most tree log related fields in btrfs_fs_info to
    btrfs_root. This allows merging sync requests separately
    for each tree log.
    
    Don't insert root item into the log root tree immediately
    after log tree is allocated. Root item for log tree is
    inserted when log tree get synced for the first time. This
    allows syncing the log root tree without first syncing all
    log trees.
    
    At tree-log sync, btrfs_sync_log first sync the log tree;
    then updates corresponding root item in the log root tree;
    sync the log root tree; then update the super block.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3cf17257f89d..7feac5a475e9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -849,6 +849,14 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	spin_lock_init(&root->list_lock);
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
+	init_waitqueue_head(&root->log_writer_wait);
+	init_waitqueue_head(&root->log_commit_wait[0]);
+	init_waitqueue_head(&root->log_commit_wait[1]);
+	atomic_set(&root->log_commit[0], 0);
+	atomic_set(&root->log_commit[1], 0);
+	atomic_set(&root->log_writers, 0);
+	root->log_batch = 0;
+	root->log_transid = 0;
 	extent_io_tree_init(&root->dirty_log_pages,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 
@@ -933,15 +941,16 @@ int btrfs_free_log_root_tree(struct btrfs_trans_handle *trans,
 	return 0;
 }
 
-int btrfs_init_log_root_tree(struct btrfs_trans_handle *trans,
-			     struct btrfs_fs_info *fs_info)
+static struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,
+					 struct btrfs_fs_info *fs_info)
 {
 	struct btrfs_root *root;
 	struct btrfs_root *tree_root = fs_info->tree_root;
+	struct extent_buffer *leaf;
 
 	root = kzalloc(sizeof(*root), GFP_NOFS);
 	if (!root)
-		return -ENOMEM;
+		return ERR_PTR(-ENOMEM);
 
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
 		     tree_root->sectorsize, tree_root->stripesize,
@@ -950,12 +959,23 @@ int btrfs_init_log_root_tree(struct btrfs_trans_handle *trans,
 	root->root_key.objectid = BTRFS_TREE_LOG_OBJECTID;
 	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
 	root->root_key.offset = BTRFS_TREE_LOG_OBJECTID;
+	/*
+	 * log trees do not get reference counted because they go away
+	 * before a real commit is actually done.  They do store pointers
+	 * to file data extents, and those reference counts still get
+	 * updated (along with back refs to the log tree).
+	 */
 	root->ref_cows = 0;
 
-	root->node = btrfs_alloc_free_block(trans, root, root->leafsize,
-					    0, BTRFS_TREE_LOG_OBJECTID,
-					    trans->transid, 0, 0, 0);
+	leaf = btrfs_alloc_free_block(trans, root, root->leafsize,
+				      0, BTRFS_TREE_LOG_OBJECTID,
+				      trans->transid, 0, 0, 0);
+	if (IS_ERR(leaf)) {
+		kfree(root);
+		return ERR_CAST(leaf);
+	}
 
+	root->node = leaf;
 	btrfs_set_header_nritems(root->node, 0);
 	btrfs_set_header_level(root->node, 0);
 	btrfs_set_header_bytenr(root->node, root->node->start);
@@ -967,7 +987,48 @@ int btrfs_init_log_root_tree(struct btrfs_trans_handle *trans,
 			    BTRFS_FSID_SIZE);
 	btrfs_mark_buffer_dirty(root->node);
 	btrfs_tree_unlock(root->node);
-	fs_info->log_root_tree = root;
+	return root;
+}
+
+int btrfs_init_log_root_tree(struct btrfs_trans_handle *trans,
+			     struct btrfs_fs_info *fs_info)
+{
+	struct btrfs_root *log_root;
+
+	log_root = alloc_log_tree(trans, fs_info);
+	if (IS_ERR(log_root))
+		return PTR_ERR(log_root);
+	WARN_ON(fs_info->log_root_tree);
+	fs_info->log_root_tree = log_root;
+	return 0;
+}
+
+int btrfs_add_log_tree(struct btrfs_trans_handle *trans,
+		       struct btrfs_root *root)
+{
+	struct btrfs_root *log_root;
+	struct btrfs_inode_item *inode_item;
+
+	log_root = alloc_log_tree(trans, root->fs_info);
+	if (IS_ERR(log_root))
+		return PTR_ERR(log_root);
+
+	log_root->last_trans = trans->transid;
+	log_root->root_key.offset = root->root_key.objectid;
+
+	inode_item = &log_root->root_item.inode;
+	inode_item->generation = cpu_to_le64(1);
+	inode_item->size = cpu_to_le64(3);
+	inode_item->nlink = cpu_to_le32(1);
+	inode_item->nbytes = cpu_to_le64(root->leafsize);
+	inode_item->mode = cpu_to_le32(S_IFDIR | 0755);
+
+	btrfs_set_root_bytenr(&log_root->root_item, log_root->node->start);
+	btrfs_set_root_generation(&log_root->root_item, trans->transid);
+
+	WARN_ON(root->log_root);
+	root->log_root = log_root;
+	root->log_transid = 0;
 	return 0;
 }
 
@@ -1530,10 +1591,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->transaction_throttle);
 	init_waitqueue_head(&fs_info->transaction_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);
-	init_waitqueue_head(&fs_info->tree_log_wait);
-	atomic_set(&fs_info->tree_log_commit, 0);
-	atomic_set(&fs_info->tree_log_writers, 0);
-	fs_info->tree_log_transid = 0;
 
 	__setup_root(4096, 4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);

commit 7e6628544abad773222d8b177f738ac2db1859de
Author: Qinghuang Feng <qhfeng.kernel@gmail.com>
Date:   Wed Jan 21 10:49:16 2009 -0500

    Btrfs: open_ctree() error handling can oops on fs_info
    
    a bug in open_ctree:
    
    struct btrfs_root *open_ctree(..)
    {
    ....
            if (!extent_root || !tree_root || !fs_info ||
                !chunk_root || !dev_root || !csum_root) {
                    err = -ENOMEM;
                    goto fail;
    //When code flow goes to "fail", fs_info may be NULL or uninitialized.
            }
    ....
    
    fail:
            btrfs_close_devices(fs_info->fs_devices);// !
            btrfs_mapping_tree_free(&fs_info->mapping_tree);// !
    
            kfree(extent_root);
            kfree(tree_root);
            bdi_destroy(&fs_info->bdi);// !
    ...
    )
    
    Signed-off-by: Qinghuang Feng <qhfeng.kernel@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 26a18779e84b..3cf17257f89d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1823,13 +1823,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail_iput:
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
-fail:
+
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
+	bdi_destroy(&fs_info->bdi);
 
+fail:
 	kfree(extent_root);
 	kfree(tree_root);
-	bdi_destroy(&fs_info->bdi);
 	kfree(fs_info);
 	kfree(chunk_root);
 	kfree(dev_root);

commit c6e308713a47527f88a277ee95b7c5d1db80f77b
Author: Qinghuang Feng <qhfeng.kernel@gmail.com>
Date:   Wed Jan 21 10:59:08 2009 -0500

    Btrfs: simplify iteration codes
    
    Merge list_for_each* and list_entry to list_for_each_entry*
    
    Signed-off-by: Qinghuang Feng <qhfeng.kernel@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0d8ccd625ba2..26a18779e84b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1135,7 +1135,6 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 {
 	struct btrfs_fs_info *info = (struct btrfs_fs_info *)congested_data;
 	int ret = 0;
-	struct list_head *cur;
 	struct btrfs_device *device;
 	struct backing_dev_info *bdi;
 #if 0
@@ -1143,8 +1142,7 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	    btrfs_congested_async(info, 0))
 		return 1;
 #endif
-	list_for_each(cur, &info->fs_devices->devices) {
-		device = list_entry(cur, struct btrfs_device, dev_list);
+	list_for_each_entry(device, &info->fs_devices->devices, dev_list) {
 		if (!device->bdev)
 			continue;
 		bdi = blk_get_backing_dev_info(device->bdev);
@@ -1162,13 +1160,11 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
  */
 static void __unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 {
-	struct list_head *cur;
 	struct btrfs_device *device;
 	struct btrfs_fs_info *info;
 
 	info = (struct btrfs_fs_info *)bdi->unplug_io_data;
-	list_for_each(cur, &info->fs_devices->devices) {
-		device = list_entry(cur, struct btrfs_device, dev_list);
+	list_for_each_entry(device, &info->fs_devices->devices, dev_list) {
 		if (!device->bdev)
 			continue;
 
@@ -1994,7 +1990,6 @@ static int write_dev_supers(struct btrfs_device *device,
 
 int write_all_supers(struct btrfs_root *root, int max_mirrors)
 {
-	struct list_head *cur;
 	struct list_head *head = &root->fs_info->fs_devices->devices;
 	struct btrfs_device *dev;
 	struct btrfs_super_block *sb;
@@ -2010,8 +2005,7 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 
 	sb = &root->fs_info->super_for_commit;
 	dev_item = &sb->dev_item;
-	list_for_each(cur, head) {
-		dev = list_entry(cur, struct btrfs_device, dev_list);
+	list_for_each_entry(dev, head, dev_list) {
 		if (!dev->bdev) {
 			total_errors++;
 			continue;
@@ -2044,8 +2038,7 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 	}
 
 	total_errors = 0;
-	list_for_each(cur, head) {
-		dev = list_entry(cur, struct btrfs_device, dev_list);
+	list_for_each_entry(dev, head, dev_list) {
 		if (!dev->bdev)
 			continue;
 		if (!dev->in_fs_metadata || !dev->writeable)

commit 57506d50ed6db7b0e7ddc9845e86e81f140983d5
Author: Qinghuang Feng <qhfeng.kernel@gmail.com>
Date:   Wed Jan 21 10:49:16 2009 -0500

    Btrfs: check return value for kthread_run() correctly
    
    kthread_run() returns the kthread or ERR_PTR(-ENOMEM), not NULL.
    
    Signed-off-by: Qinghuang Feng <qhfeng.kernel@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 37e12f620392..0d8ccd625ba2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1739,13 +1739,13 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
 	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
 					       "btrfs-cleaner");
-	if (!fs_info->cleaner_kthread)
+	if (IS_ERR(fs_info->cleaner_kthread))
 		goto fail_csum_root;
 
 	fs_info->transaction_kthread = kthread_run(transaction_kthread,
 						   tree_root,
 						   "btrfs-transaction");
-	if (!fs_info->transaction_kthread)
+	if (IS_ERR(fs_info->transaction_kthread))
 		goto fail_cleaner;
 
 	if (btrfs_super_log_root(disk_super) != 0) {

commit 7eaebe7d503c3ef240ac7b3efc5433fe647c0298
Author: Huang Weiyi <weiyi.huang@gmail.com>
Date:   Wed Jan 21 10:49:16 2009 -0500

    Btrfs: removed unused #include <version.h>'s
    
    Removed unused #include <version.h>'s in btrfs
    
    Signed-off-by: Huang Weiyi <weiyi.huang@gmail.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 81a313874ae5..37e12f620392 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -16,7 +16,6 @@
  * Boston, MA 021110-1307, USA.
  */
 
-#include <linux/version.h>
 #include <linux/fs.h>
 #include <linux/blkdev.h>
 #include <linux/scatterlist.h>

commit d397712bcc6a759a560fd247e6053ecae091f958
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 5 21:25:51 2009 -0500

    Btrfs: Fix checkpatch.pl warnings
    
    There were many, most are fixed now.  struct-funcs.c generates some warnings
    but these are bogus.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dae25e78a6b7..81a313874ae5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -23,7 +23,7 @@
 #include <linux/swap.h>
 #include <linux/radix-tree.h>
 #include <linux/writeback.h>
-#include <linux/buffer_head.h> // for block_sync_page
+#include <linux/buffer_head.h>
 #include <linux/workqueue.h>
 #include <linux/kthread.h>
 #include <linux/freezer.h>
@@ -40,19 +40,6 @@
 #include "ref-cache.h"
 #include "tree-log.h"
 
-#if 0
-static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
-{
-	if (extent_buffer_blocknr(buf) != btrfs_header_blocknr(buf)) {
-		printk(KERN_CRIT "buf blocknr(buf) is %llu, header is %llu\n",
-		       (unsigned long long)extent_buffer_blocknr(buf),
-		       (unsigned long long)btrfs_header_blocknr(buf));
-		return 1;
-	}
-	return 0;
-}
-#endif
-
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 
@@ -128,23 +115,13 @@ static struct extent_map *btree_get_extent(struct inode *inode,
 		u64 failed_start = em->start;
 		u64 failed_len = em->len;
 
-		printk("failed to insert %Lu %Lu -> %Lu into tree\n",
-		       em->start, em->len, em->block_start);
 		free_extent_map(em);
 		em = lookup_extent_mapping(em_tree, start, len);
 		if (em) {
-			printk("after failing, found %Lu %Lu %Lu\n",
-			       em->start, em->len, em->block_start);
 			ret = 0;
 		} else {
 			em = lookup_extent_mapping(em_tree, failed_start,
 						   failed_len);
-			if (em) {
-				printk("double failure lookup gives us "
-				       "%Lu %Lu -> %Lu\n", em->start,
-				       em->len, em->block_start);
-				free_extent_map(em);
-			}
 			ret = -EIO;
 		}
 	} else if (ret) {
@@ -191,15 +168,12 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	unsigned long inline_result;
 
 	len = buf->len - offset;
-	while(len > 0) {
+	while (len > 0) {
 		err = map_private_extent_buffer(buf, offset, 32,
 					&map_token, &kaddr,
 					&map_start, &map_len, KM_USER0);
-		if (err) {
-			printk("failed to map extent buffer! %lu\n",
-			       offset);
+		if (err)
 			return 1;
-		}
 		cur_len = min(len, map_len - (offset - map_start));
 		crc = btrfs_csum_data(root, kaddr + offset - map_start,
 				      crc, cur_len);
@@ -218,15 +192,14 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	btrfs_csum_final(crc, result);
 
 	if (verify) {
-		/* FIXME, this is not good */
 		if (memcmp_extent_buffer(buf, result, 0, csum_size)) {
 			u32 val;
 			u32 found = 0;
 			memcpy(&found, result, csum_size);
 
 			read_extent_buffer(buf, &val, 0, csum_size);
-			printk("btrfs: %s checksum verify failed on %llu "
-			       "wanted %X found %X level %d\n",
+			printk(KERN_INFO "btrfs: %s checksum verify failed "
+			       "on %llu wanted %X found %X level %d\n",
 			       root->fs_info->sb->s_id,
 			       buf->start, val, found, btrfs_header_level(buf));
 			if (result != (char *)&inline_result)
@@ -293,7 +266,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		if (!ret &&
 		    !verify_parent_transid(io_tree, eb, parent_transid))
 			return ret;
-printk("read extent buffer pages failed with ret %d mirror no %d\n", ret, mirror_num);
+
 		num_copies = btrfs_num_copies(&root->fs_info->mapping_tree,
 					      eb->start, eb->len);
 		if (num_copies == 1)
@@ -307,9 +280,10 @@ printk("read extent buffer pages failed with ret %d mirror no %d\n", ret, mirror
 }
 
 /*
- * checksum a dirty tree block before IO.  This has extra checks to make
- * sure we only fill in the checksum field in the first page of a multi-page block
+ * checksum a dirty tree block before IO.  This has extra checks to make sure
+ * we only fill in the checksum field in the first page of a multi-page block
  */
+
 static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 {
 	struct extent_io_tree *tree;
@@ -327,28 +301,22 @@ static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	if (!page->private)
 		goto out;
 	len = page->private >> 2;
-	if (len == 0) {
-		WARN_ON(1);
-	}
+	WARN_ON(len == 0);
+
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
 	ret = btree_read_extent_buffer_pages(root, eb, start + PAGE_CACHE_SIZE,
 					     btrfs_header_generation(eb));
 	BUG_ON(ret);
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
-		printk("warning: eb start incorrect %Lu buffer %Lu len %lu\n",
-		       start, found_start, len);
 		WARN_ON(1);
 		goto err;
 	}
 	if (eb->first_page != page) {
-		printk("bad first page %lu %lu\n", eb->first_page->index,
-		       page->index);
 		WARN_ON(1);
 		goto err;
 	}
 	if (!PageUptodate(page)) {
-		printk("csum not up to date page %lu\n", page->index);
 		WARN_ON(1);
 		goto err;
 	}
@@ -396,29 +364,30 @@ static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		goto out;
 	if (!page->private)
 		goto out;
+
 	len = page->private >> 2;
-	if (len == 0) {
-		WARN_ON(1);
-	}
+	WARN_ON(len == 0);
+
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
-		printk("bad tree block start %llu %llu\n",
+		printk(KERN_INFO "btrfs bad tree block start %llu %llu\n",
 		       (unsigned long long)found_start,
 		       (unsigned long long)eb->start);
 		ret = -EIO;
 		goto err;
 	}
 	if (eb->first_page != page) {
-		printk("bad first page %lu %lu\n", eb->first_page->index,
-		       page->index);
+		printk(KERN_INFO "btrfs bad first page %lu %lu\n",
+		       eb->first_page->index, page->index);
 		WARN_ON(1);
 		ret = -EIO;
 		goto err;
 	}
 	if (check_tree_block_fsid(root, eb)) {
-		printk("bad fsid on block %Lu\n", eb->start);
+		printk(KERN_INFO "btrfs bad fsid on block %llu\n",
+		       (unsigned long long)eb->start);
 		ret = -EIO;
 		goto err;
 	}
@@ -578,7 +547,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			   HZ/10);
 	}
 #endif
-	while(atomic_read(&fs_info->async_submit_draining) &&
+	while (atomic_read(&fs_info->async_submit_draining) &&
 	      atomic_read(&fs_info->nr_async_submits)) {
 		wait_event(fs_info->async_submit_wait,
 			   (atomic_read(&fs_info->nr_async_submits) == 0));
@@ -594,7 +563,7 @@ static int btree_csum_one_bio(struct bio *bio)
 	struct btrfs_root *root;
 
 	WARN_ON(bio->bi_vcnt <= 0);
-	while(bio_index < bio->bi_vcnt) {
+	while (bio_index < bio->bi_vcnt) {
 		root = BTRFS_I(bvec->bv_page->mapping->host)->root;
 		csum_dirty_buffer(root, bvec->bv_page);
 		bio_index++;
@@ -680,9 +649,8 @@ static int btree_writepages(struct address_space *mapping,
 
 		num_dirty = count_range_bits(tree, &start, (u64)-1,
 					     thresh, EXTENT_DIRTY);
-		if (num_dirty < thresh) {
+		if (num_dirty < thresh)
 			return 0;
-		}
 	}
 	return extent_writepages(tree, mapping, btree_get_extent, wbc);
 }
@@ -701,15 +669,14 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	int ret;
 
 	if (PageWriteback(page) || PageDirty(page))
-	    return 0;
+		return 0;
 
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
 
 	ret = try_release_extent_state(map, tree, page, gfp_flags);
-	if (!ret) {
+	if (!ret)
 		return 0;
-	}
 
 	ret = try_release_extent_buffer(tree, page);
 	if (ret == 1) {
@@ -728,8 +695,8 @@ static void btree_invalidatepage(struct page *page, unsigned long offset)
 	extent_invalidatepage(tree, page, offset);
 	btree_releasepage(page, GFP_NOFS);
 	if (PagePrivate(page)) {
-		printk("warning page private not zero on page %Lu\n",
-		       page_offset(page));
+		printk(KERN_WARNING "btrfs warning page private not zero "
+		       "on page %llu\n", (unsigned long long)page_offset(page));
 		ClearPagePrivate(page);
 		set_page_private(page, 0);
 		page_cache_release(page);
@@ -813,7 +780,7 @@ int btrfs_write_tree_block(struct extent_buffer *buf)
 int btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
 {
 	return btrfs_wait_on_page_writeback_range(buf->first_page->mapping,
-				  buf->start, buf->start + buf->len -1);
+				  buf->start, buf->start + buf->len - 1);
 }
 
 struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
@@ -832,11 +799,10 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 
 	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 
-	if (ret == 0) {
+	if (ret == 0)
 		buf->flags |= EXTENT_UPTODATE;
-	} else {
+	else
 		WARN_ON(1);
-	}
 	return buf;
 
 }
@@ -944,7 +910,7 @@ int btrfs_free_log_root_tree(struct btrfs_trans_handle *trans,
 	if (!log_root_tree)
 		return 0;
 
-	while(1) {
+	while (1) {
 		ret = find_first_extent_bit(&log_root_tree->dirty_log_pages,
 				    0, &start, &end, EXTENT_DIRTY);
 		if (ret)
@@ -1165,24 +1131,6 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 	root->in_sysfs = 1;
 	return root;
 }
-#if 0
-static int add_hasher(struct btrfs_fs_info *info, char *type) {
-	struct btrfs_hasher *hasher;
-
-	hasher = kmalloc(sizeof(*hasher), GFP_NOFS);
-	if (!hasher)
-		return -ENOMEM;
-	hasher->hash_tfm = crypto_alloc_hash(type, 0, CRYPTO_ALG_ASYNC);
-	if (!hasher->hash_tfm) {
-		kfree(hasher);
-		return -EINVAL;
-	}
-	spin_lock(&info->hash_lock);
-	list_add(&hasher->list, &info->hashers);
-	spin_unlock(&info->hash_lock);
-	return 0;
-}
-#endif
 
 static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 {
@@ -1226,9 +1174,8 @@ static void __unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 			continue;
 
 		bdi = blk_get_backing_dev_info(device->bdev);
-		if (bdi->unplug_io_fn) {
+		if (bdi->unplug_io_fn)
 			bdi->unplug_io_fn(bdi, page);
-		}
 	}
 }
 
@@ -1420,8 +1367,9 @@ static int transaction_kthread(void *arg)
 		mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
 		if (root->fs_info->total_ref_cache_size > 20 * 1024 * 1024) {
-			printk("btrfs: total reference cache size %Lu\n",
-				root->fs_info->total_ref_cache_size);
+			printk(KERN_INFO "btrfs: total reference cache "
+			       "size %llu\n",
+			       root->fs_info->total_ref_cache_size);
 		}
 
 		mutex_lock(&root->fs_info->trans_mutex);
@@ -1592,14 +1540,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	atomic_set(&fs_info->tree_log_writers, 0);
 	fs_info->tree_log_transid = 0;
 
-#if 0
-	ret = add_hasher(fs_info, "crc32c");
-	if (ret) {
-		printk("btrfs: failed hash setup, modprobe cryptomgr?\n");
-		err = -ENOMEM;
-		goto fail_iput;
-	}
-#endif
 	__setup_root(4096, 4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
@@ -1720,7 +1660,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	if (strncmp((char *)(&disk_super->magic), BTRFS_MAGIC,
 		    sizeof(disk_super->magic))) {
-		printk("btrfs: valid FS not found on %s\n", sb->s_id);
+		printk(KERN_INFO "btrfs: valid FS not found on %s\n", sb->s_id);
 		goto fail_sb_buffer;
 	}
 
@@ -1728,8 +1668,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
-		printk("btrfs: failed to read the system array on %s\n",
-		       sb->s_id);
+		printk(KERN_WARNING "btrfs: failed to read the system "
+		       "array on %s\n", sb->s_id);
 		goto fail_sys_array;
 	}
 
@@ -1746,14 +1686,15 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	BUG_ON(!chunk_root->node);
 
 	read_extent_buffer(chunk_root->node, fs_info->chunk_tree_uuid,
-	         (unsigned long)btrfs_header_chunk_tree_uuid(chunk_root->node),
-		 BTRFS_UUID_SIZE);
+	   (unsigned long)btrfs_header_chunk_tree_uuid(chunk_root->node),
+	   BTRFS_UUID_SIZE);
 
 	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_chunk_tree(chunk_root);
 	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
-		printk("btrfs: failed to read chunk tree on %s\n", sb->s_id);
+		printk(KERN_WARNING "btrfs: failed to read chunk tree on %s\n",
+		       sb->s_id);
 		goto fail_chunk_root;
 	}
 
@@ -1812,7 +1753,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		u64 bytenr = btrfs_super_log_root(disk_super);
 
 		if (fs_devices->rw_devices == 0) {
-			printk("Btrfs log replay required on RO media\n");
+			printk(KERN_WARNING "Btrfs log replay required "
+			       "on RO media\n");
 			err = -EIO;
 			goto fail_trans_kthread;
 		}
@@ -2097,7 +2039,8 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 			total_errors++;
 	}
 	if (total_errors > max_errors) {
-		printk("btrfs: %d errors while writing supers\n", total_errors);
+		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
+		       total_errors);
 		BUG();
 	}
 
@@ -2114,7 +2057,8 @@ int write_all_supers(struct btrfs_root *root, int max_mirrors)
 			total_errors++;
 	}
 	if (total_errors > max_errors) {
-		printk("btrfs: %d errors while writing supers\n", total_errors);
+		printk(KERN_ERR "btrfs: %d errors while writing supers\n",
+		       total_errors);
 		BUG();
 	}
 	return 0;
@@ -2137,16 +2081,11 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 		down_write(&root->anon_super.s_umount);
 		kill_anon_super(&root->anon_super);
 	}
-#if 0
-	if (root->in_sysfs)
-		btrfs_sysfs_del_root(root);
-#endif
 	if (root->node)
 		free_extent_buffer(root->node);
 	if (root->commit_root)
 		free_extent_buffer(root->commit_root);
-	if (root->name)
-		kfree(root->name);
+	kfree(root->name);
 	kfree(root);
 	return 0;
 }
@@ -2157,7 +2096,7 @@ static int del_fs_roots(struct btrfs_fs_info *fs_info)
 	struct btrfs_root *gang[8];
 	int i;
 
-	while(1) {
+	while (1) {
 		ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,
 					     (void **)gang, 0,
 					     ARRAY_SIZE(gang));
@@ -2228,18 +2167,17 @@ int close_ctree(struct btrfs_root *root)
 
 	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
 		ret =  btrfs_commit_super(root);
-		if (ret) {
-			printk("btrfs: commit super returns %d\n", ret);
-		}
+		if (ret)
+			printk(KERN_ERR "btrfs: commit super ret %d\n", ret);
 	}
 
 	if (fs_info->delalloc_bytes) {
-		printk("btrfs: at unmount delalloc count %Lu\n",
+		printk(KERN_INFO "btrfs: at unmount delalloc count %llu\n",
 		       fs_info->delalloc_bytes);
 	}
 	if (fs_info->total_ref_cache_size) {
-		printk("btrfs: at umount reference cache size %Lu\n",
-			fs_info->total_ref_cache_size);
+		printk(KERN_INFO "btrfs: at umount reference cache size %llu\n",
+		       (unsigned long long)fs_info->total_ref_cache_size);
 	}
 
 	if (fs_info->extent_root->node)
@@ -2248,13 +2186,13 @@ int close_ctree(struct btrfs_root *root)
 	if (fs_info->tree_root->node)
 		free_extent_buffer(fs_info->tree_root->node);
 
-	if (root->fs_info->chunk_root->node);
+	if (root->fs_info->chunk_root->node)
 		free_extent_buffer(root->fs_info->chunk_root->node);
 
-	if (root->fs_info->dev_root->node);
+	if (root->fs_info->dev_root->node)
 		free_extent_buffer(root->fs_info->dev_root->node);
 
-	if (root->fs_info->csum_root->node);
+	if (root->fs_info->csum_root->node)
 		free_extent_buffer(root->fs_info->csum_root->node);
 
 	btrfs_free_block_groups(root->fs_info);
@@ -2273,7 +2211,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->submit_workers);
 
 #if 0
-	while(!list_empty(&fs_info->hashers)) {
+	while (!list_empty(&fs_info->hashers)) {
 		struct btrfs_hasher *hasher;
 		hasher = list_entry(fs_info->hashers.next, struct btrfs_hasher,
 				    hashers);
@@ -2324,9 +2262,11 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 
 	WARN_ON(!btrfs_tree_locked(buf));
 	if (transid != root->fs_info->generation) {
-		printk(KERN_CRIT "transid mismatch buffer %llu, found %Lu running %Lu\n",
+		printk(KERN_CRIT "btrfs transid mismatch buffer %llu, "
+		       "found %llu running %llu\n",
 			(unsigned long long)buf->start,
-			transid, root->fs_info->generation);
+			(unsigned long long)transid,
+			(unsigned long long)root->fs_info->generation);
 		WARN_ON(1);
 	}
 	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree, buf);
@@ -2361,9 +2301,8 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	int ret;
 	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
-	if (ret == 0) {
+	if (ret == 0)
 		buf->flags |= EXTENT_UPTODATE;
-	}
 	return ret;
 }
 

commit 2d69a0f88459fae35df3ddef4934a2dad67e2765
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Mon Jan 5 15:43:42 2009 -0500

    Btrfs: avoid potential super block corruption
    
    The data in fs_info->super_for_commit are zeros before the
    first transaction commit. If tree log sync and system crash
    both occur before the first transaction commit, super block
    will get corrupted.
    
    This fixes it by properly filling in the super_for_commit field at
    open time.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 40a540f31161..dae25e78a6b7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1609,6 +1609,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_iput;
 
 	memcpy(&fs_info->super_copy, bh->b_data, sizeof(fs_info->super_copy));
+	memcpy(&fs_info->super_for_commit, &fs_info->super_copy,
+	       sizeof(fs_info->super_for_commit));
 	brelse(bh);
 
 	memcpy(fs_info->fsid, fs_info->super_copy.fsid, BTRFS_FSID_SIZE);
@@ -1790,7 +1792,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	btrfs_read_block_groups(extent_root);
 
-	fs_info->generation = generation + 1;
+	fs_info->generation = generation;
 	fs_info->last_trans_committed = generation;
 	fs_info->data_alloc_profile = (u64)-1;
 	fs_info->metadata_alloc_profile = (u64)-1;

commit b34b086c1c1d934c5314d46ba25ccfa9acc471ae
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Dec 19 15:43:22 2008 -0500

    Btrfs: Fix compile warning around num_online_cpus() in a min statement
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 04f8d7080b17..40a540f31161 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1528,7 +1528,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;
 
-	fs_info->thread_pool_size = min(num_online_cpus() + 2, 8);
+	fs_info->thread_pool_size = min_t(unsigned long,
+					  num_online_cpus() + 2, 8);
 
 	INIT_LIST_HEAD(&fs_info->ordered_extents);
 	spin_lock_init(&fs_info->ordered_extent_lock);

commit cad321ad529400c6ab24c501a67c3be720a0744c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Dec 17 14:51:42 2008 -0500

    Btrfs: shift all end_io work to thread pools
    
    bio_end_io for reads without checksumming on and btree writes were
    happening without using async thread pools.  This means the extent_io.c
    code had to use spin_lock_irq and friends on the rb tree locks for
    extent state.
    
    There were some irq safe vs unsafe lock inversions between the delallock
    lock and the extent state locks.  This patch gets rid of them by moving
    all end_io code into the thread pools.
    
    To avoid contention and deadlocks between the data end_io processing and the
    metadata end_io processing yet another thread pool is added to finish
    off metadata writes.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 541a8279ac71..04f8d7080b17 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -447,8 +447,12 @@ static void end_workqueue_bio(struct bio *bio, int err)
 	end_io_wq->work.flags = 0;
 
 	if (bio->bi_rw & (1 << BIO_RW)) {
-		btrfs_queue_worker(&fs_info->endio_write_workers,
-				   &end_io_wq->work);
+		if (end_io_wq->metadata)
+			btrfs_queue_worker(&fs_info->endio_meta_write_workers,
+					   &end_io_wq->work);
+		else
+			btrfs_queue_worker(&fs_info->endio_write_workers,
+					   &end_io_wq->work);
 	} else {
 		if (end_io_wq->metadata)
 			btrfs_queue_worker(&fs_info->endio_meta_workers,
@@ -624,23 +628,24 @@ static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
 static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 				 int mirror_num, unsigned long bio_flags)
 {
-	/*
-	 * kthread helpers are used to submit writes so that checksumming
-	 * can happen in parallel across all CPUs
-	 */
+	int ret;
+
+	ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info,
+					  bio, 1);
+	BUG_ON(ret);
+
 	if (!(rw & (1 << BIO_RW))) {
-		int ret;
 		/*
 		 * called for a read, do the setup so that checksum validation
 		 * can happen in the async kernel threads
 		 */
-		ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info,
-					  bio, 1);
-		BUG_ON(ret);
-
 		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
 				     mirror_num, 0);
 	}
+	/*
+	 * kthread helpers are used to submit writes so that checksumming
+	 * can happen in parallel across all CPUs
+	 */
 	return btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
 				   inode, rw, bio, mirror_num, 0,
 				   __btree_submit_bio_start,
@@ -1350,12 +1355,13 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	bio = end_io_wq->bio;
 	fs_info = end_io_wq->info;
 
-	/* metadata bios are special because the whole tree block must
+	/* metadata bio reads are special because the whole tree block must
 	 * be checksummed at once.  This makes sure the entire block is in
 	 * ram and up to date before trying to verify things.  For
 	 * blocksize <= pagesize, it is basically a noop
 	 */
-	if (end_io_wq->metadata && !bio_ready_for_csum(bio)) {
+	if (!(bio->bi_rw & (1 << BIO_RW)) && end_io_wq->metadata &&
+	    !bio_ready_for_csum(bio)) {
 		btrfs_queue_worker(&fs_info->endio_meta_workers,
 				   &end_io_wq->work);
 		return;
@@ -1668,6 +1674,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			   fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->endio_meta_workers, "endio-meta",
 			   fs_info->thread_pool_size);
+	btrfs_init_workers(&fs_info->endio_meta_write_workers,
+			   "endio-meta-write", fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->endio_write_workers, "endio-write",
 			   fs_info->thread_pool_size);
 
@@ -1677,6 +1685,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 */
 	fs_info->endio_workers.idle_thresh = 4;
 	fs_info->endio_write_workers.idle_thresh = 64;
+	fs_info->endio_meta_write_workers.idle_thresh = 64;
 
 	btrfs_start_workers(&fs_info->workers, 1);
 	btrfs_start_workers(&fs_info->submit_workers, 1);
@@ -1685,6 +1694,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
 	btrfs_start_workers(&fs_info->endio_meta_workers,
 			    fs_info->thread_pool_size);
+	btrfs_start_workers(&fs_info->endio_meta_write_workers,
+			    fs_info->thread_pool_size);
 	btrfs_start_workers(&fs_info->endio_write_workers,
 			    fs_info->thread_pool_size);
 
@@ -1866,6 +1877,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_workers);
+	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
 fail_iput:
@@ -2253,6 +2265,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_meta_workers);
+	btrfs_stop_workers(&fs_info->endio_meta_write_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
 

commit e4404d6e8da678d852b7f767f665f8edf76c9e9f
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Fri Dec 12 10:03:26 2008 -0500

    Btrfs: shared seed device
    
    This patch makes seed device possible to be shared by
    multiple mounted file systems. The sharing is achieved
    by cloning seed device's btrfs_fs_devices structure.
    Thanks you,
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6f042de1ac43..541a8279ac71 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1711,7 +1711,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	}
 
 	mutex_lock(&fs_info->chunk_mutex);
-	ret = btrfs_read_sys_array(tree_root, btrfs_super_bytenr(disk_super));
+	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
 		printk("btrfs: failed to read the system array on %s\n",

commit 0403e47ee26f26e960ee9038552bc89df4a1fb3d
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Dec 10 20:32:51 2008 -0500

    Btrfs: Add checking of csum tree in balancing code
    
    This updates the space balancing code for the
    new checksum format.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c72f4f3b912c..6f042de1ac43 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1097,6 +1097,8 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 		return fs_info->chunk_root;
 	if (location->objectid == BTRFS_DEV_TREE_OBJECTID)
 		return fs_info->dev_root;
+	if (location->objectid == BTRFS_CSUM_TREE_OBJECTID)
+		return fs_info->csum_root;
 
 	root = radix_tree_lookup(&fs_info->fs_roots_radix,
 				 (unsigned long)location->objectid);

commit a512bbf855ff0af474257475f2e6da7acd854f52
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Mon Dec 8 16:46:26 2008 -0500

    Btrfs: superblock duplication
    
    This patch implements superblock duplication. Superblocks
    are stored at offset 16K, 64M and 256G on every devices.
    Spaces used by superblocks are preserved by the allocator,
    which uses a reverse mapping function to find the logical
    addresses that correspond to superblocks. Thank you,
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 61dc3b2c834b..c72f4f3b912c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1595,8 +1595,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
 
-	bh = __bread(fs_devices->latest_bdev,
-		     BTRFS_SUPER_INFO_OFFSET / 4096, 4096);
+	bh = btrfs_read_dev_super(fs_devices->latest_bdev);
 	if (!bh)
 		goto fail_iput;
 
@@ -1710,7 +1709,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	}
 
 	mutex_lock(&fs_info->chunk_mutex);
-	ret = btrfs_read_sys_array(tree_root);
+	ret = btrfs_read_sys_array(tree_root, btrfs_super_bytenr(disk_super));
 	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
 		printk("btrfs: failed to read the system array on %s\n",
@@ -1905,19 +1904,147 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 	put_bh(bh);
 }
 
-static int write_all_supers(struct btrfs_root *root)
+struct buffer_head *btrfs_read_dev_super(struct block_device *bdev)
+{
+	struct buffer_head *bh;
+	struct buffer_head *latest = NULL;
+	struct btrfs_super_block *super;
+	int i;
+	u64 transid = 0;
+	u64 bytenr;
+
+	/* we would like to check all the supers, but that would make
+	 * a btrfs mount succeed after a mkfs from a different FS.
+	 * So, we need to add a special mount option to scan for
+	 * later supers, using BTRFS_SUPER_MIRROR_MAX instead
+	 */
+	for (i = 0; i < 1; i++) {
+		bytenr = btrfs_sb_offset(i);
+		if (bytenr + 4096 >= i_size_read(bdev->bd_inode))
+			break;
+		bh = __bread(bdev, bytenr / 4096, 4096);
+		if (!bh)
+			continue;
+
+		super = (struct btrfs_super_block *)bh->b_data;
+		if (btrfs_super_bytenr(super) != bytenr ||
+		    strncmp((char *)(&super->magic), BTRFS_MAGIC,
+			    sizeof(super->magic))) {
+			brelse(bh);
+			continue;
+		}
+
+		if (!latest || btrfs_super_generation(super) > transid) {
+			brelse(latest);
+			latest = bh;
+			transid = btrfs_super_generation(super);
+		} else {
+			brelse(bh);
+		}
+	}
+	return latest;
+}
+
+static int write_dev_supers(struct btrfs_device *device,
+			    struct btrfs_super_block *sb,
+			    int do_barriers, int wait, int max_mirrors)
+{
+	struct buffer_head *bh;
+	int i;
+	int ret;
+	int errors = 0;
+	u32 crc;
+	u64 bytenr;
+	int last_barrier = 0;
+
+	if (max_mirrors == 0)
+		max_mirrors = BTRFS_SUPER_MIRROR_MAX;
+
+	/* make sure only the last submit_bh does a barrier */
+	if (do_barriers) {
+		for (i = 0; i < max_mirrors; i++) {
+			bytenr = btrfs_sb_offset(i);
+			if (bytenr + BTRFS_SUPER_INFO_SIZE >=
+			    device->total_bytes)
+				break;
+			last_barrier = i;
+		}
+	}
+
+	for (i = 0; i < max_mirrors; i++) {
+		bytenr = btrfs_sb_offset(i);
+		if (bytenr + BTRFS_SUPER_INFO_SIZE >= device->total_bytes)
+			break;
+
+		if (wait) {
+			bh = __find_get_block(device->bdev, bytenr / 4096,
+					      BTRFS_SUPER_INFO_SIZE);
+			BUG_ON(!bh);
+			brelse(bh);
+			wait_on_buffer(bh);
+			if (buffer_uptodate(bh)) {
+				brelse(bh);
+				continue;
+			}
+		} else {
+			btrfs_set_super_bytenr(sb, bytenr);
+
+			crc = ~(u32)0;
+			crc = btrfs_csum_data(NULL, (char *)sb +
+					      BTRFS_CSUM_SIZE, crc,
+					      BTRFS_SUPER_INFO_SIZE -
+					      BTRFS_CSUM_SIZE);
+			btrfs_csum_final(crc, sb->csum);
+
+			bh = __getblk(device->bdev, bytenr / 4096,
+				      BTRFS_SUPER_INFO_SIZE);
+			memcpy(bh->b_data, sb, BTRFS_SUPER_INFO_SIZE);
+
+			set_buffer_uptodate(bh);
+			get_bh(bh);
+			lock_buffer(bh);
+			bh->b_end_io = btrfs_end_buffer_write_sync;
+		}
+
+		if (i == last_barrier && do_barriers && device->barriers) {
+			ret = submit_bh(WRITE_BARRIER, bh);
+			if (ret == -EOPNOTSUPP) {
+				printk("btrfs: disabling barriers on dev %s\n",
+				       device->name);
+				set_buffer_uptodate(bh);
+				device->barriers = 0;
+				get_bh(bh);
+				lock_buffer(bh);
+				ret = submit_bh(WRITE, bh);
+			}
+		} else {
+			ret = submit_bh(WRITE, bh);
+		}
+
+		if (!ret && wait) {
+			wait_on_buffer(bh);
+			if (!buffer_uptodate(bh))
+				errors++;
+		} else if (ret) {
+			errors++;
+		}
+		if (wait)
+			brelse(bh);
+	}
+	return errors < i ? 0 : -1;
+}
+
+int write_all_supers(struct btrfs_root *root, int max_mirrors)
 {
 	struct list_head *cur;
 	struct list_head *head = &root->fs_info->fs_devices->devices;
 	struct btrfs_device *dev;
 	struct btrfs_super_block *sb;
 	struct btrfs_dev_item *dev_item;
-	struct buffer_head *bh;
 	int ret;
 	int do_barriers;
 	int max_errors;
 	int total_errors = 0;
-	u32 crc;
 	u64 flags;
 
 	max_errors = btrfs_super_num_devices(&root->fs_info->super_copy) - 1;
@@ -1944,40 +2071,11 @@ static int write_all_supers(struct btrfs_root *root)
 		btrfs_set_stack_device_sector_size(dev_item, dev->sector_size);
 		memcpy(dev_item->uuid, dev->uuid, BTRFS_UUID_SIZE);
 		memcpy(dev_item->fsid, dev->fs_devices->fsid, BTRFS_UUID_SIZE);
+
 		flags = btrfs_super_flags(sb);
 		btrfs_set_super_flags(sb, flags | BTRFS_HEADER_FLAG_WRITTEN);
 
-
-		crc = ~(u32)0;
-		crc = btrfs_csum_data(root, (char *)sb + BTRFS_CSUM_SIZE, crc,
-				      BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
-		btrfs_csum_final(crc, sb->csum);
-
-		bh = __getblk(dev->bdev, BTRFS_SUPER_INFO_OFFSET / 4096,
-			      BTRFS_SUPER_INFO_SIZE);
-
-		memcpy(bh->b_data, sb, BTRFS_SUPER_INFO_SIZE);
-		dev->pending_io = bh;
-
-		get_bh(bh);
-		set_buffer_uptodate(bh);
-		lock_buffer(bh);
-		bh->b_end_io = btrfs_end_buffer_write_sync;
-
-		if (do_barriers && dev->barriers) {
-			ret = submit_bh(WRITE_BARRIER, bh);
-			if (ret == -EOPNOTSUPP) {
-				printk("btrfs: disabling barriers on dev %s\n",
-				       dev->name);
-				set_buffer_uptodate(bh);
-				dev->barriers = 0;
-				get_bh(bh);
-				lock_buffer(bh);
-				ret = submit_bh(WRITE, bh);
-			}
-		} else {
-			ret = submit_bh(WRITE, bh);
-		}
+		ret = write_dev_supers(dev, sb, do_barriers, 0, max_mirrors);
 		if (ret)
 			total_errors++;
 	}
@@ -1985,8 +2083,8 @@ static int write_all_supers(struct btrfs_root *root)
 		printk("btrfs: %d errors while writing supers\n", total_errors);
 		BUG();
 	}
-	total_errors = 0;
 
+	total_errors = 0;
 	list_for_each(cur, head) {
 		dev = list_entry(cur, struct btrfs_device, dev_list);
 		if (!dev->bdev)
@@ -1994,29 +2092,9 @@ static int write_all_supers(struct btrfs_root *root)
 		if (!dev->in_fs_metadata || !dev->writeable)
 			continue;
 
-		BUG_ON(!dev->pending_io);
-		bh = dev->pending_io;
-		wait_on_buffer(bh);
-		if (!buffer_uptodate(dev->pending_io)) {
-			if (do_barriers && dev->barriers) {
-				printk("btrfs: disabling barriers on dev %s\n",
-				       dev->name);
-				set_buffer_uptodate(bh);
-				get_bh(bh);
-				lock_buffer(bh);
-				dev->barriers = 0;
-				ret = submit_bh(WRITE, bh);
-				BUG_ON(ret);
-				wait_on_buffer(bh);
-				if (!buffer_uptodate(bh))
-					total_errors++;
-			} else {
-				total_errors++;
-			}
-
-		}
-		dev->pending_io = NULL;
-		brelse(bh);
+		ret = write_dev_supers(dev, sb, do_barriers, 1, max_mirrors);
+		if (ret)
+			total_errors++;
 	}
 	if (total_errors > max_errors) {
 		printk("btrfs: %d errors while writing supers\n", total_errors);
@@ -2025,12 +2103,12 @@ static int write_all_supers(struct btrfs_root *root)
 	return 0;
 }
 
-int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root)
+int write_ctree_super(struct btrfs_trans_handle *trans,
+		      struct btrfs_root *root, int max_mirrors)
 {
 	int ret;
 
-	ret = write_all_supers(root);
+	ret = write_all_supers(root, max_mirrors);
 	return ret;
 }
 
@@ -2116,7 +2194,7 @@ int btrfs_commit_super(struct btrfs_root *root)
 	ret = btrfs_write_and_wait_transaction(NULL, root);
 	BUG_ON(ret);
 
-	ret = write_ctree_super(NULL, root);
+	ret = write_ctree_super(NULL, root, 0);
 	return ret;
 }
 

commit d20f7043fa65659136c1a7c3c456eeeb5c6f431f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 8 16:58:54 2008 -0500

    Btrfs: move data checksumming into a dedicated tree
    
    Btrfs stores checksums for each data block.  Until now, they have
    been stored in the subvolume trees, indexed by the inode that is
    referencing the data block.  This means that when we read the inode,
    we've probably read in at least some checksums as well.
    
    But, this has a few problems:
    
    * The checksums are indexed by logical offset in the file.  When
    compression is on, this means we have to do the expensive checksumming
    on the uncompressed data.  It would be faster if we could checksum
    the compressed data instead.
    
    * If we implement encryption, we'll be checksumming the plain text and
    storing that on disk.  This is significantly less secure.
    
    * For either compression or encryption, we have to get the plain text
    back before we can verify the checksum as correct.  This makes the raid
    layer balancing and extent moving much more expensive.
    
    * It makes the front end caching code more complex, as we have touch
    the subvolume and inodes as we cache extents.
    
    * There is potentitally one copy of the checksum in each subvolume
    referencing an extent.
    
    The solution used here is to store the extent checksums in a dedicated
    tree.  This allows us to index the checksums by phyiscal extent
    start and length.  It means:
    
    * The checksum is against the data stored on disk, after any compression
    or encryption is done.
    
    * The checksum is stored in a central location, and can be verified without
    following back references, or reading inodes.
    
    This makes compression significantly faster by reducing the amount of
    data that needs to be checksummed.  It will also allow much faster
    raid management code in general.
    
    The checksums are indexed by a key with a fixed objectid (a magic value
    in ctree.h) and offset set to the starting byte of the extent.  This
    allows us to copy the checksum items into the fsync log tree directly (or
    any other tree), without having to invent a second format for them.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3eb7c2576fe5..61dc3b2c834b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -445,11 +445,18 @@ static void end_workqueue_bio(struct bio *bio, int err)
 	end_io_wq->error = err;
 	end_io_wq->work.func = end_workqueue_fn;
 	end_io_wq->work.flags = 0;
-	if (bio->bi_rw & (1 << BIO_RW))
+
+	if (bio->bi_rw & (1 << BIO_RW)) {
 		btrfs_queue_worker(&fs_info->endio_write_workers,
 				   &end_io_wq->work);
-	else
-		btrfs_queue_worker(&fs_info->endio_workers, &end_io_wq->work);
+	} else {
+		if (end_io_wq->metadata)
+			btrfs_queue_worker(&fs_info->endio_meta_workers,
+					   &end_io_wq->work);
+		else
+			btrfs_queue_worker(&fs_info->endio_workers,
+					   &end_io_wq->work);
+	}
 }
 
 int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
@@ -1208,6 +1215,9 @@ static void __unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 	info = (struct btrfs_fs_info *)bdi->unplug_io_data;
 	list_for_each(cur, &info->fs_devices->devices) {
 		device = list_entry(cur, struct btrfs_device, dev_list);
+		if (!device->bdev)
+			continue;
+
 		bdi = blk_get_backing_dev_info(device->bdev);
 		if (bdi->unplug_io_fn) {
 			bdi->unplug_io_fn(bdi, page);
@@ -1344,7 +1354,7 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	 * blocksize <= pagesize, it is basically a noop
 	 */
 	if (end_io_wq->metadata && !bio_ready_for_csum(bio)) {
-		btrfs_queue_worker(&fs_info->endio_workers,
+		btrfs_queue_worker(&fs_info->endio_meta_workers,
 				   &end_io_wq->work);
 		return;
 	}
@@ -1454,6 +1464,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	struct buffer_head *bh;
 	struct btrfs_root *extent_root = kzalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
+	struct btrfs_root *csum_root = kzalloc(sizeof(struct btrfs_root),
+						 GFP_NOFS);
 	struct btrfs_root *tree_root = kzalloc(sizeof(struct btrfs_root),
 					       GFP_NOFS);
 	struct btrfs_fs_info *fs_info = kzalloc(sizeof(*fs_info),
@@ -1470,7 +1482,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	struct btrfs_super_block *disk_super;
 
 	if (!extent_root || !tree_root || !fs_info ||
-	    !chunk_root || !dev_root) {
+	    !chunk_root || !dev_root || !csum_root) {
 		err = -ENOMEM;
 		goto fail;
 	}
@@ -1487,6 +1499,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	init_completion(&fs_info->kobj_unregister);
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
+	fs_info->csum_root = csum_root;
 	fs_info->chunk_root = chunk_root;
 	fs_info->dev_root = dev_root;
 	fs_info->fs_devices = fs_devices;
@@ -1652,6 +1665,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1);
 	btrfs_init_workers(&fs_info->endio_workers, "endio",
 			   fs_info->thread_pool_size);
+	btrfs_init_workers(&fs_info->endio_meta_workers, "endio-meta",
+			   fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->endio_write_workers, "endio-write",
 			   fs_info->thread_pool_size);
 
@@ -1667,6 +1682,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->delalloc_workers, 1);
 	btrfs_start_workers(&fs_info->fixup_workers, 1);
 	btrfs_start_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
+	btrfs_start_workers(&fs_info->endio_meta_workers,
+			    fs_info->thread_pool_size);
 	btrfs_start_workers(&fs_info->endio_write_workers,
 			    fs_info->thread_pool_size);
 
@@ -1751,6 +1768,13 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (ret)
 		goto fail_extent_root;
 
+	ret = find_and_setup_root(tree_root, fs_info,
+				  BTRFS_CSUM_TREE_OBJECTID, csum_root);
+	if (ret)
+		goto fail_extent_root;
+
+	csum_root->track_dirty = 1;
+
 	btrfs_read_block_groups(extent_root);
 
 	fs_info->generation = generation + 1;
@@ -1761,7 +1785,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
 					       "btrfs-cleaner");
 	if (!fs_info->cleaner_kthread)
-		goto fail_extent_root;
+		goto fail_csum_root;
 
 	fs_info->transaction_kthread = kthread_run(transaction_kthread,
 						   tree_root,
@@ -1825,6 +1849,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 
+fail_csum_root:
+	free_extent_buffer(csum_root->node);
 fail_extent_root:
 	free_extent_buffer(extent_root->node);
 fail_tree_root:
@@ -1838,6 +1864,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->delalloc_workers);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
+	btrfs_stop_workers(&fs_info->endio_meta_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
 fail_iput:
@@ -1853,6 +1880,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	kfree(fs_info);
 	kfree(chunk_root);
 	kfree(dev_root);
+	kfree(csum_root);
 	return ERR_PTR(err);
 }
 
@@ -2131,6 +2159,9 @@ int close_ctree(struct btrfs_root *root)
 	if (root->fs_info->dev_root->node);
 		free_extent_buffer(root->fs_info->dev_root->node);
 
+	if (root->fs_info->csum_root->node);
+		free_extent_buffer(root->fs_info->csum_root->node);
+
 	btrfs_free_block_groups(root->fs_info);
 
 	del_fs_roots(fs_info);
@@ -2141,6 +2172,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->delalloc_workers);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
+	btrfs_stop_workers(&fs_info->endio_meta_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
 
@@ -2163,6 +2195,7 @@ int close_ctree(struct btrfs_root *root)
 	kfree(fs_info->tree_root);
 	kfree(fs_info->chunk_root);
 	kfree(fs_info->dev_root);
+	kfree(fs_info->csum_root);
 	return 0;
 }
 

commit 607d432da0542e84ddcd358adfddac6f68500e3d
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Dec 2 07:17:45 2008 -0500

    Btrfs: add support for multiple csum algorithms
    
    This patch gives us the space we will need in order to have different csum
    algorithims at some point in the future.  We save the csum algorithim type
    in the superblock, and use those instead of define's.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dfd5ba05ce45..3eb7c2576fe5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -176,7 +176,9 @@ void btrfs_csum_final(u32 crc, char *result)
 static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			   int verify)
 {
-	char result[BTRFS_CRC32_SIZE];
+	u16 csum_size =
+		btrfs_super_csum_size(&root->fs_info->super_copy);
+	char *result = NULL;
 	unsigned long len;
 	unsigned long cur_len;
 	unsigned long offset = BTRFS_CSUM_SIZE;
@@ -186,6 +188,7 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	unsigned long map_len;
 	int err;
 	u32 crc = ~(u32)0;
+	unsigned long inline_result;
 
 	len = buf->len - offset;
 	while(len > 0) {
@@ -204,25 +207,37 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 		offset += cur_len;
 		unmap_extent_buffer(buf, map_token, KM_USER0);
 	}
+	if (csum_size > sizeof(inline_result)) {
+		result = kzalloc(csum_size * sizeof(char), GFP_NOFS);
+		if (!result)
+			return 1;
+	} else {
+		result = (char *)&inline_result;
+	}
+
 	btrfs_csum_final(crc, result);
 
 	if (verify) {
 		/* FIXME, this is not good */
-		if (memcmp_extent_buffer(buf, result, 0, BTRFS_CRC32_SIZE)) {
+		if (memcmp_extent_buffer(buf, result, 0, csum_size)) {
 			u32 val;
 			u32 found = 0;
-			memcpy(&found, result, BTRFS_CRC32_SIZE);
+			memcpy(&found, result, csum_size);
 
-			read_extent_buffer(buf, &val, 0, BTRFS_CRC32_SIZE);
+			read_extent_buffer(buf, &val, 0, csum_size);
 			printk("btrfs: %s checksum verify failed on %llu "
 			       "wanted %X found %X level %d\n",
 			       root->fs_info->sb->s_id,
 			       buf->start, val, found, btrfs_header_level(buf));
+			if (result != (char *)&inline_result)
+				kfree(result);
 			return 1;
 		}
 	} else {
-		write_extent_buffer(buf, result, 0, BTRFS_CRC32_SIZE);
+		write_extent_buffer(buf, result, 0, csum_size);
 	}
+	if (result != (char *)&inline_result)
+		kfree(result);
 	return 0;
 }
 

commit c6e2bac1a52ffc36dd10769b594dfa3994e95f77
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Dec 2 06:36:10 2008 -0500

    Btrfs: fix panic on error during mount
    
    This needs to be applied on top of my previous patches, but is needed for more
    than just my new stuff.  We're going to the wrong label when we have an error,
    we try to stop the workers, but they are started below all of this code.  This
    fixes it so we go to the right error label and not panic when we fail one of
    these cases.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6ae9bdf98b68..dfd5ba05ce45 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1579,12 +1579,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	disk_super = &fs_info->super_copy;
 	if (!btrfs_super_root(disk_super))
-		goto fail_sb_buffer;
+		goto fail_iput;
 
 	ret = btrfs_parse_options(tree_root, options);
 	if (ret) {
 		err = ret;
-		goto fail_sb_buffer;
+		goto fail_iput;
 	}
 
 	features = btrfs_super_incompat_flags(disk_super) &
@@ -1594,7 +1594,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		       "unsupported optional features (%Lx).\n",
 		       features);
 		err = -EINVAL;
-		goto fail_sb_buffer;
+		goto fail_iput;
 	}
 
 	features = btrfs_super_compat_ro_flags(disk_super) &
@@ -1604,7 +1604,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		       "unsupported option features (%Lx).\n",
 		       features);
 		err = -EINVAL;
-		goto fail_sb_buffer;
+		goto fail_iput;
 	}
 
 	/*

commit f2b636e80d8206dd4012de6e973c2367259a7d22
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Dec 2 06:36:08 2008 -0500

    Btrfs: add support for compat flags to btrfs
    
    This adds the necessary disk format for handling compatibility flags
    in the future to handle disk format changes.  We have a compat_flags,
    compat_ro_flags and incompat_flags set for the super block.  Compat
    flags will be to hold the features that are compatible with older
    versions of btrfs, compat_ro flags have features that are compatible
    with older versions of btrfs if the fs is mounted read only, and
    incompat_flags has features that are incompatible with older versions
    of btrfs.  This also axes the compat_flags field for the inode and
    just makes the flags field a 64bit field, and changes the root item
    flags field to 64bit.
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2464c099db57..6ae9bdf98b68 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1434,6 +1434,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	u32 blocksize;
 	u32 stripesize;
 	u64 generation;
+	u64 features;
 	struct btrfs_key location;
 	struct buffer_head *bh;
 	struct btrfs_root *extent_root = kzalloc(sizeof(struct btrfs_root),
@@ -1586,6 +1587,26 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 
+	features = btrfs_super_incompat_flags(disk_super) &
+		~BTRFS_FEATURE_INCOMPAT_SUPP;
+	if (features) {
+		printk(KERN_ERR "BTRFS: couldn't mount because of "
+		       "unsupported optional features (%Lx).\n",
+		       features);
+		err = -EINVAL;
+		goto fail_sb_buffer;
+	}
+
+	features = btrfs_super_compat_ro_flags(disk_super) &
+		~BTRFS_FEATURE_COMPAT_RO_SUPP;
+	if (!(sb->s_flags & MS_RDONLY) && features) {
+		printk(KERN_ERR "BTRFS: couldn't mount RDWR because of "
+		       "unsupported option features (%Lx).\n",
+		       features);
+		err = -EINVAL;
+		goto fail_sb_buffer;
+	}
+
 	/*
 	 * we need to start all the end_io workers up front because the
 	 * queue work function gets called at interrupt time, and so it

commit 6e430f94e508fee1aefd1dfec88da3c24ce64433
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Dec 2 06:36:09 2008 -0500

    Btrfs: fix shadowed variable declarations
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8a2bcc7024fe..2464c099db57 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1734,7 +1734,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_cleaner;
 
 	if (btrfs_super_log_root(disk_super) != 0) {
-		u32 blocksize;
 		u64 bytenr = btrfs_super_log_root(disk_super);
 
 		if (fs_devices->rw_devices == 0) {

commit b2950863c61bc24cf0f63bc05947d9d50663c4c0
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Dec 2 09:54:17 2008 -0500

    Btrfs: make things static and include the right headers
    
    Shut up various sparse warnings about symbols that should be either
    static or have their declarations in scope.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fb04665e5005..8a2bcc7024fe 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -93,9 +93,9 @@ struct async_submit_bio {
  * extents on the btree inode are pretty simple, there's one extent
  * that covers the entire device
  */
-struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
-				    size_t page_offset, u64 start, u64 len,
-				    int create)
+static struct extent_map *btree_get_extent(struct inode *inode,
+		struct page *page, size_t page_offset, u64 start, u64 len,
+		int create)
 {
 	struct extent_map_tree *em_tree = &BTRFS_I(inode)->extent_tree;
 	struct extent_map *em;
@@ -295,7 +295,7 @@ printk("read extent buffer pages failed with ret %d mirror no %d\n", ret, mirror
  * checksum a dirty tree block before IO.  This has extra checks to make
  * sure we only fill in the checksum field in the first page of a multi-page block
  */
-int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
+static int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 {
 	struct extent_io_tree *tree;
 	u64 start = (u64)page->index << PAGE_CACHE_SHIFT;
@@ -365,7 +365,7 @@ static int check_tree_block_fsid(struct btrfs_root *root,
 	return ret;
 }
 
-int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
+static int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 			       struct extent_state *state)
 {
 	struct extent_io_tree *tree;
@@ -660,7 +660,7 @@ static int btree_writepages(struct address_space *mapping,
 	return extent_writepages(tree, mapping, btree_get_extent, wbc);
 }
 
-int btree_readpage(struct file *file, struct page *page)
+static int btree_readpage(struct file *file, struct page *page)
 {
 	struct extent_io_tree *tree;
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
@@ -1200,7 +1200,7 @@ static void __unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 	}
 }
 
-void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
+static void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 {
 	struct inode *inode;
 	struct extent_map_tree *em_tree;
@@ -1842,7 +1842,7 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 	put_bh(bh);
 }
 
-int write_all_supers(struct btrfs_root *root)
+static int write_all_supers(struct btrfs_root *root)
 {
 	struct list_head *cur;
 	struct list_head *head = &root->fs_info->fs_devices->devices;

commit e556ce2c9d2163aea122e91a1512c9a110fece5d
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 20 10:25:19 2008 -0500

    Btrfs: Drop dirty roots created by log replay immediately when
    
    The log replay produces dirty roots. These dirty roots
    should be dropped immediately if the fs is mounted as
    ro. Otherwise they can be added to the dirty root list
    again when remounting the fs as rw. Thank you,
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 981652233f70..fb04665e5005 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1757,6 +1757,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 						      generation + 1);
 		ret = btrfs_recover_log_trees(log_tree_root);
 		BUG_ON(ret);
+
+		if (sb->s_flags & MS_RDONLY) {
+			ret =  btrfs_commit_super(tree_root);
+			BUG_ON(ret);
+		}
 	}
 
 	if (!(sb->s_flags & MS_RDONLY)) {

commit 4b4e25f2a6ddb070bab7f7dd2bd2926fb8db9e04
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 20 10:22:27 2008 -0500

    Btrfs: compat code fixes
    
    The btrfs git kernel trees is used to build a standalone tree for
    compiling against older kernels.  This commit makes the standalone tree
    work with 2.6.27
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c8dcb47b6d7d..981652233f70 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -26,7 +26,8 @@
 #include <linux/buffer_head.h> // for block_sync_page
 #include <linux/workqueue.h>
 #include <linux/kthread.h>
-# include <linux/freezer.h>
+#include <linux/freezer.h>
+#include "compat.h"
 #include "crc32c.h"
 #include "ctree.h"
 #include "disk-io.h"

commit 7c2ca4682a2b401cb0c43f96b05eced25eb83eec
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Nov 19 15:13:35 2008 -0500

    Btrfs: Do fsync log replay when mount -o ro, except when on readonly media
    
    fsync log replay can change the filesystem, so it cannot be delayed until
    mount -o rw,remount, and it can't be forgotten entirely.  So, this patch
    changes btrfs to do with reiserfs, ext3 and xfs do, which is to do the
    log replay even when mounted readonly.
    
    On a readonly device if log replay is required, the mount is aborted.
    
    Getting all of this right had required fixing up some of the error
    handling in open_ctree.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8d03e4a3c4e9..c8dcb47b6d7d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -518,7 +518,6 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			extent_submit_bio_hook_t *submit_bio_done)
 {
 	struct async_submit_bio *async;
-	int limit = btrfs_async_submit_limit(fs_info);
 
 	async = kmalloc(sizeof(*async), GFP_NOFS);
 	if (!async)
@@ -541,6 +540,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	atomic_inc(&fs_info->nr_async_submits);
 	btrfs_queue_worker(&fs_info->workers, &async->work);
 #if 0
+	int limit = btrfs_async_submit_limit(fs_info);
 	if (atomic_read(&fs_info->nr_async_submits) > limit) {
 		wait_event_timeout(fs_info->async_submit_wait,
 			   (atomic_read(&fs_info->nr_async_submits) < limit),
@@ -1732,13 +1732,15 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!fs_info->transaction_kthread)
 		goto fail_cleaner;
 
-	if (sb->s_flags & MS_RDONLY)
-		goto read_fs_root;
-
 	if (btrfs_super_log_root(disk_super) != 0) {
 		u32 blocksize;
 		u64 bytenr = btrfs_super_log_root(disk_super);
 
+		if (fs_devices->rw_devices == 0) {
+			printk("Btrfs log replay required on RO media\n");
+			err = -EIO;
+			goto fail_trans_kthread;
+		}
 		blocksize =
 		     btrfs_level_size(tree_root,
 				      btrfs_super_log_root_level(disk_super));
@@ -1756,21 +1758,32 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		BUG_ON(ret);
 	}
 
-	ret = btrfs_cleanup_reloc_trees(tree_root);
-	BUG_ON(ret);
+	if (!(sb->s_flags & MS_RDONLY)) {
+		ret = btrfs_cleanup_reloc_trees(tree_root);
+		BUG_ON(ret);
+	}
 
-read_fs_root:
 	location.objectid = BTRFS_FS_TREE_OBJECTID;
 	location.type = BTRFS_ROOT_ITEM_KEY;
 	location.offset = (u64)-1;
 
 	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
 	if (!fs_info->fs_root)
-		goto fail_cleaner;
+		goto fail_trans_kthread;
 	return tree_root;
 
+fail_trans_kthread:
+	kthread_stop(fs_info->transaction_kthread);
 fail_cleaner:
 	kthread_stop(fs_info->cleaner_kthread);
+
+	/*
+	 * make sure we're done with the btree inode before we stop our
+	 * kthreads
+	 */
+	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
+	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
+
 fail_extent_root:
 	free_extent_buffer(extent_root->node);
 fail_tree_root:
@@ -1778,6 +1791,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail_chunk_root:
 	free_extent_buffer(chunk_root->node);
 fail_sys_array:
+	free_extent_buffer(dev_root->node);
 fail_sb_buffer:
 	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->delalloc_workers);
@@ -1786,6 +1800,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
 fail_iput:
+	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	iput(fs_info->btree_inode);
 fail:
 	btrfs_close_devices(fs_info->fs_devices);

commit d2c3f4f695edac4d75c1b3eb01a1d16072de63bb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Nov 19 12:44:22 2008 -0500

    Btrfs: Avoid writeback stalls
    
    While building large bios in writepages, btrfs may end up waiting
    for other page writeback to finish if WB_SYNC_ALL is used.
    
    While it is waiting, the bio it is building has a number of pages with the
    writeback bit set and they aren't getting to the disk any time soon.  This
    lowers the latencies of writeback in general by sending down the bio being
    built before waiting for other pages.
    
    The bio submission code tries to limit the total number of async bios in
    flight by waiting when we're over a certain number of async bios.  But,
    the waits are happening while writepages is building bios, and this can easily
    lead to stalls and other problems for people calling wait_on_page_writeback.
    
    The current fix is to let the congestion tests take care of waiting.
    
    sync() and others make sure to drain the current async requests to make
    sure that everything that was pending when the sync was started really get
    to disk.  The code would drain pending requests both before and after
    submitting a new request.
    
    But, if one of the requests is waiting for page writeback to finish,
    the draining waits might block that page writeback.  This changes the
    draining code to only wait after submitting the bio being processed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0e8d31274c92..8d03e4a3c4e9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -538,15 +538,9 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->work.flags = 0;
 	async->bio_flags = bio_flags;
 
-	while(atomic_read(&fs_info->async_submit_draining) &&
-	      atomic_read(&fs_info->nr_async_submits)) {
-		wait_event(fs_info->async_submit_wait,
-			   (atomic_read(&fs_info->nr_async_submits) == 0));
-	}
-
 	atomic_inc(&fs_info->nr_async_submits);
 	btrfs_queue_worker(&fs_info->workers, &async->work);
-
+#if 0
 	if (atomic_read(&fs_info->nr_async_submits) > limit) {
 		wait_event_timeout(fs_info->async_submit_wait,
 			   (atomic_read(&fs_info->nr_async_submits) < limit),
@@ -556,7 +550,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			   (atomic_read(&fs_info->nr_async_bios) < limit),
 			   HZ/10);
 	}
-
+#endif
 	while(atomic_read(&fs_info->async_submit_draining) &&
 	      atomic_read(&fs_info->nr_async_submits)) {
 		wait_event(fs_info->async_submit_wait,
@@ -1765,11 +1759,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	ret = btrfs_cleanup_reloc_trees(tree_root);
 	BUG_ON(ret);
 
+read_fs_root:
 	location.objectid = BTRFS_FS_TREE_OBJECTID;
 	location.type = BTRFS_ROOT_ITEM_KEY;
 	location.offset = (u64)-1;
 
-read_fs_root:
 	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
 	if (!fs_info->fs_root)
 		goto fail_cleaner;

commit 9f0ba5bd91d42706ba78f97ec638c6a821db1c5e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 18 10:31:22 2008 -0500

    Btrfs: unplug all devices in the unplug call back
    
    For larger multi-device filesystems, there was logic to limit the
    number of devices unplugged to just the page that was sent to our sync_page
    function.
    
    But, the code wasn't always unplugging the right device.  Since this was
    just an optimization, disable it for now.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e18250a6fd2d..0e8d31274c92 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1214,7 +1214,7 @@ void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 	u64 offset;
 
 	/* the generic O_DIRECT read code does this */
-	if (!page) {
+	if (1 || !page) {
 		__unplug_io_fn(bdi, page);
 		return;
 	}

commit ea9e8b11bd1252dcbc23afefcf1a52ec6aa3c113
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 17 21:14:24 2008 -0500

    Btrfs: prevent loops in the directory tree when creating snapshots
    
    For a directory tree:
    
    /mnt/subvolA/subvolB
    
    btrfsctl -s /mnt/subvolA/subvolB /mnt
    
    Will create a directory loop with subvolA under subvolB.  This
    commit uses the forward refs for each subvol and snapshot to error out
    before creating the loop.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8d7866b733d6..e18250a6fd2d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1129,7 +1129,7 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
-
+#if 0
 	ret = btrfs_sysfs_add_root(root);
 	if (ret) {
 		free_extent_buffer(root->node);
@@ -1137,6 +1137,7 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
+#endif
 	root->in_sysfs = 1;
 	return root;
 }
@@ -1963,8 +1964,10 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 		down_write(&root->anon_super.s_umount);
 		kill_anon_super(&root->anon_super);
 	}
+#if 0
 	if (root->in_sysfs)
 		btrfs_sysfs_del_root(root);
+#endif
 	if (root->node)
 		free_extent_buffer(root->node);
 	if (root->commit_root)

commit 3394e1607eaf870ebba37d303fbd590a4c569908
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 17 20:42:26 2008 -0500

    Btrfs: Give each subvol and snapshot their own anonymous devid
    
    Each subvolume has its own private inode number space, and so we need
    to fill in different device numbers for each subvolume to avoid confusing
    applications.
    
    This commit puts a struct super_block into struct btrfs_root so it can
    call set_anon_super() and get a different device number generated for
    each root.
    
    btrfs_rename is changed to prevent renames across subvols.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0a5350573f61..8d7866b733d6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -877,6 +877,12 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->defrag_running = 0;
 	root->defrag_level = 0;
 	root->root_key.objectid = objectid;
+	root->anon_super.s_root = NULL;
+	root->anon_super.s_dev = 0;
+	INIT_LIST_HEAD(&root->anon_super.s_list);
+	INIT_LIST_HEAD(&root->anon_super.s_instances);
+	init_rwsem(&root->anon_super.s_umount);
+
 	return 0;
 }
 
@@ -1083,6 +1089,9 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	root = btrfs_read_fs_root_no_radix(fs_info->tree_root, location);
 	if (IS_ERR(root))
 		return root;
+
+	set_anon_super(&root->anon_super, NULL);
+
 	ret = radix_tree_insert(&fs_info->fs_roots_radix,
 				(unsigned long)root->root_key.objectid,
 				root);
@@ -1950,6 +1959,10 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 {
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
+	if (root->anon_super.s_dev) {
+		down_write(&root->anon_super.s_umount);
+		kill_anon_super(&root->anon_super);
+	}
 	if (root->in_sysfs)
 		btrfs_sysfs_del_root(root);
 	if (root->node)

commit 3de4586c5278a28107030c336956381f69ff7a9d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 17 21:02:50 2008 -0500

    Btrfs: Allow subvolumes and snapshots anywhere in the directory tree
    
    Before, all snapshots and subvolumes lived in a single flat directory.  This
    was awkward and confusing because the single flat directory was only writable
    with the ioctls.
    
    This commit changes the ioctls to create subvols and snapshots at any
    point in the directory tree.  This requires making separate ioctls for
    snapshot and subvol creation instead of a combining them into one.
    
    The subvol ioctl does:
    
    btrfsctl -S subvol_name parent_dir
    
    After the ioctl is done subvol_name lives inside parent_dir.
    
    The snapshot ioctl does:
    
    btrfsctl -s path_for_snapshot root_to_snapshot
    
    path_for_snapshot can be an absolute or relative path.  btrfsctl breaks it up
    into directory and basename components.
    
    root_to_snapshot can be any file or directory in the FS.  The snapshot
    is taken of the entire root where that file lives.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 82833e5d84b6..0a5350573f61 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -838,7 +838,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 			u64 objectid)
 {
 	root->node = NULL;
-	root->inode = NULL;
 	root->commit_root = NULL;
 	root->ref_tree = NULL;
 	root->sectorsize = sectorsize;
@@ -1430,6 +1429,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	u32 blocksize;
 	u32 stripesize;
 	u64 generation;
+	struct btrfs_key location;
 	struct buffer_head *bh;
 	struct btrfs_root *extent_root = kzalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
@@ -1729,7 +1729,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_cleaner;
 
 	if (sb->s_flags & MS_RDONLY)
-		return tree_root;
+		goto read_fs_root;
 
 	if (btrfs_super_log_root(disk_super) != 0) {
 		u32 blocksize;
@@ -1755,6 +1755,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	ret = btrfs_cleanup_reloc_trees(tree_root);
 	BUG_ON(ret);
 
+	location.objectid = BTRFS_FS_TREE_OBJECTID;
+	location.type = BTRFS_ROOT_ITEM_KEY;
+	location.offset = (u64)-1;
+
+read_fs_root:
+	fs_info->fs_root = btrfs_read_fs_root_no_name(fs_info, &location);
+	if (!fs_info->fs_root)
+		goto fail_cleaner;
 	return tree_root;
 
 fail_cleaner:
@@ -1944,8 +1952,6 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 			  (unsigned long)root->root_key.objectid);
 	if (root->in_sysfs)
 		btrfs_sysfs_del_root(root);
-	if (root->inode)
-		iput(root->inode);
 	if (root->node)
 		free_extent_buffer(root->node);
 	if (root->commit_root)

commit 2b82032c34ec40515d3c45c36cd1961f37977de8
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Mon Nov 17 21:11:30 2008 -0500

    Btrfs: Seed device support
    
    Seed device is a special btrfs with SEEDING super flag
    set and can only be mounted in read-only mode. Seed
    devices allow people to create new btrfs on top of it.
    
    The new FS contains the same contents as the seed device,
    but it can be mounted in read-write mode.
    
    This patch does the following:
    
    1) split code in btrfs_alloc_chunk into two parts. The first part does makes
    the newly allocated chunk usable, but does not do any operation that modifies
    the chunk tree. The second part does the the chunk tree modifications. This
    division is for the bootstrap step of adding storage to the seed device.
    
    2) Update device management code to handle seed device.
    The basic idea is: For an FS grown from seed devices, its
    seed devices are put into a list. Seed devices are
    opened on demand at mounting time. If any seed device is
    missing or has been changed, btrfs kernel module will
    refuse to mount the FS.
    
    3) make btrfs_find_block_group not return NULL when all
    block groups are read-only.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c599f0ee997a..82833e5d84b6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -345,6 +345,25 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	return 0;
 }
 
+static int check_tree_block_fsid(struct btrfs_root *root,
+				 struct extent_buffer *eb)
+{
+	struct btrfs_fs_devices *fs_devices = root->fs_info->fs_devices;
+	u8 fsid[BTRFS_UUID_SIZE];
+	int ret = 1;
+
+	read_extent_buffer(eb, fsid, (unsigned long)btrfs_header_fsid(eb),
+			   BTRFS_FSID_SIZE);
+	while (fs_devices) {
+		if (!memcmp(fsid, fs_devices->fsid, BTRFS_FSID_SIZE)) {
+			ret = 0;
+			break;
+		}
+		fs_devices = fs_devices->seed;
+	}
+	return ret;
+}
+
 int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 			       struct extent_state *state)
 {
@@ -382,9 +401,7 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		ret = -EIO;
 		goto err;
 	}
-	if (memcmp_extent_buffer(eb, root->fs_info->fsid,
-				 (unsigned long)btrfs_header_fsid(eb),
-				 BTRFS_FSID_SIZE)) {
+	if (check_tree_block_fsid(root, eb)) {
 		printk("bad fsid on block %Lu\n", eb->start);
 		ret = -EIO;
 		goto err;
@@ -1558,9 +1575,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!btrfs_super_root(disk_super))
 		goto fail_sb_buffer;
 
-	err = btrfs_parse_options(tree_root, options);
-	if (err)
+	ret = btrfs_parse_options(tree_root, options);
+	if (ret) {
+		err = ret;
 		goto fail_sb_buffer;
+	}
 
 	/*
 	 * we need to start all the end_io workers up front because the
@@ -1610,18 +1629,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->endio_write_workers,
 			    fs_info->thread_pool_size);
 
-	err = -EINVAL;
-	if (btrfs_super_num_devices(disk_super) > fs_devices->open_devices) {
-		printk("Btrfs: wanted %llu devices, but found %llu\n",
-		       (unsigned long long)btrfs_super_num_devices(disk_super),
-		       (unsigned long long)fs_devices->open_devices);
-		if (btrfs_test_opt(tree_root, DEGRADED))
-			printk("continuing in degraded mode\n");
-		else {
-			goto fail_sb_buffer;
-		}
-	}
-
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
 				    4 * 1024 * 1024 / PAGE_CACHE_SIZE);
@@ -1672,7 +1679,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_chunk_tree(chunk_root);
 	mutex_unlock(&fs_info->chunk_mutex);
-	BUG_ON(ret);
+	if (ret) {
+		printk("btrfs: failed to read chunk tree on %s\n", sb->s_id);
+		goto fail_chunk_root;
+	}
 
 	btrfs_close_extra_devices(fs_devices);
 
@@ -1684,7 +1694,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 					  btrfs_super_root(disk_super),
 					  blocksize, generation);
 	if (!tree_root->node)
-		goto fail_sb_buffer;
+		goto fail_chunk_root;
 
 
 	ret = find_and_setup_root(tree_root, fs_info,
@@ -1753,6 +1763,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	free_extent_buffer(extent_root->node);
 fail_tree_root:
 	free_extent_buffer(tree_root->node);
+fail_chunk_root:
+	free_extent_buffer(chunk_root->node);
 fail_sys_array:
 fail_sb_buffer:
 	btrfs_stop_workers(&fs_info->fixup_workers);
@@ -1823,9 +1835,10 @@ int write_all_supers(struct btrfs_root *root)
 			total_errors++;
 			continue;
 		}
-		if (!dev->in_fs_metadata)
+		if (!dev->in_fs_metadata || !dev->writeable)
 			continue;
 
+		btrfs_set_stack_device_generation(dev_item, 0);
 		btrfs_set_stack_device_type(dev_item, dev->type);
 		btrfs_set_stack_device_id(dev_item, dev->devid);
 		btrfs_set_stack_device_total_bytes(dev_item, dev->total_bytes);
@@ -1834,6 +1847,7 @@ int write_all_supers(struct btrfs_root *root)
 		btrfs_set_stack_device_io_width(dev_item, dev->io_width);
 		btrfs_set_stack_device_sector_size(dev_item, dev->sector_size);
 		memcpy(dev_item->uuid, dev->uuid, BTRFS_UUID_SIZE);
+		memcpy(dev_item->fsid, dev->fs_devices->fsid, BTRFS_UUID_SIZE);
 		flags = btrfs_super_flags(sb);
 		btrfs_set_super_flags(sb, flags | BTRFS_HEADER_FLAG_WRITTEN);
 
@@ -1881,7 +1895,7 @@ int write_all_supers(struct btrfs_root *root)
 		dev = list_entry(cur, struct btrfs_device, dev_list);
 		if (!dev->bdev)
 			continue;
-		if (!dev->in_fs_metadata)
+		if (!dev->in_fs_metadata || !dev->writeable)
 			continue;
 
 		BUG_ON(!dev->pending_io);

commit c146afad2c7fea6a366d4945c1bab9b03880f526
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Nov 12 14:34:12 2008 -0500

    Btrfs: mount ro and remount support
    
    This patch adds mount ro and remount support. The main
    changes in patch are: adding btrfs_remount and related
    helper function; splitting the transaction related code
    out of close_ctree into btrfs_commit_super; updating
    allocator to properly handle read only block group.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3b0e974a9e9c..c599f0ee997a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1075,10 +1075,12 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
-	ret = btrfs_find_dead_roots(fs_info->tree_root,
-				    root->root_key.objectid, root);
-	BUG_ON(ret);
-
+	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
+		ret = btrfs_find_dead_roots(fs_info->tree_root,
+					    root->root_key.objectid, root);
+		BUG_ON(ret);
+		btrfs_orphan_cleanup(root);
+	}
 	return root;
 }
 
@@ -1700,7 +1702,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	btrfs_read_block_groups(extent_root);
 
-	fs_info->generation = btrfs_super_generation(disk_super) + 1;
+	fs_info->generation = generation + 1;
+	fs_info->last_trans_committed = generation;
 	fs_info->data_alloc_profile = (u64)-1;
 	fs_info->metadata_alloc_profile = (u64)-1;
 	fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
@@ -1715,6 +1718,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!fs_info->transaction_kthread)
 		goto fail_cleaner;
 
+	if (sb->s_flags & MS_RDONLY)
+		return tree_root;
+
 	if (btrfs_super_log_root(disk_super) != 0) {
 		u32 blocksize;
 		u64 bytenr = btrfs_super_log_root(disk_super);
@@ -1735,7 +1741,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		ret = btrfs_recover_log_trees(log_tree_root);
 		BUG_ON(ret);
 	}
-	fs_info->last_trans_committed = btrfs_super_generation(disk_super);
 
 	ret = btrfs_cleanup_reloc_trees(tree_root);
 	BUG_ON(ret);
@@ -1955,28 +1960,69 @@ static int del_fs_roots(struct btrfs_fs_info *fs_info)
 	return 0;
 }
 
-int close_ctree(struct btrfs_root *root)
+int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)
 {
+	u64 root_objectid = 0;
+	struct btrfs_root *gang[8];
+	int i;
 	int ret;
-	struct btrfs_trans_handle *trans;
-	struct btrfs_fs_info *fs_info = root->fs_info;
 
-	fs_info->closing = 1;
-	smp_mb();
+	while (1) {
+		ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,
+					     (void **)gang, root_objectid,
+					     ARRAY_SIZE(gang));
+		if (!ret)
+			break;
+		for (i = 0; i < ret; i++) {
+			root_objectid = gang[i]->root_key.objectid;
+			ret = btrfs_find_dead_roots(fs_info->tree_root,
+						    root_objectid, gang[i]);
+			BUG_ON(ret);
+			btrfs_orphan_cleanup(gang[i]);
+		}
+		root_objectid++;
+	}
+	return 0;
+}
 
-	kthread_stop(root->fs_info->transaction_kthread);
-	kthread_stop(root->fs_info->cleaner_kthread);
+int btrfs_commit_super(struct btrfs_root *root)
+{
+	struct btrfs_trans_handle *trans;
+	int ret;
 
+	mutex_lock(&root->fs_info->cleaner_mutex);
 	btrfs_clean_old_snapshots(root);
+	mutex_unlock(&root->fs_info->cleaner_mutex);
 	trans = btrfs_start_transaction(root, 1);
 	ret = btrfs_commit_transaction(trans, root);
-	/* run commit again to  drop the original snapshot */
+	BUG_ON(ret);
+	/* run commit again to drop the original snapshot */
 	trans = btrfs_start_transaction(root, 1);
 	btrfs_commit_transaction(trans, root);
 	ret = btrfs_write_and_wait_transaction(NULL, root);
 	BUG_ON(ret);
 
-	write_ctree_super(NULL, root);
+	ret = write_ctree_super(NULL, root);
+	return ret;
+}
+
+int close_ctree(struct btrfs_root *root)
+{
+	struct btrfs_fs_info *fs_info = root->fs_info;
+	int ret;
+
+	fs_info->closing = 1;
+	smp_mb();
+
+	kthread_stop(root->fs_info->transaction_kthread);
+	kthread_stop(root->fs_info->cleaner_kthread);
+
+	if (!(fs_info->sb->s_flags & MS_RDONLY)) {
+		ret =  btrfs_commit_super(root);
+		if (ret) {
+			printk("btrfs: commit super returns %d\n", ret);
+		}
+	}
 
 	if (fs_info->delalloc_bytes) {
 		printk("btrfs: at unmount delalloc count %Lu\n",
@@ -2000,12 +2046,10 @@ int close_ctree(struct btrfs_root *root)
 		free_extent_buffer(root->fs_info->dev_root->node);
 
 	btrfs_free_block_groups(root->fs_info);
-	fs_info->closing = 2;
-	del_fs_roots(fs_info);
 
-	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
+	del_fs_roots(fs_info);
 
-	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
+	iput(fs_info->btree_inode);
 
 	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->delalloc_workers);
@@ -2014,7 +2058,6 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
 
-	iput(fs_info->btree_inode);
 #if 0
 	while(!list_empty(&fs_info->hashers)) {
 		struct btrfs_hasher *hasher;

commit 6f3577bdc768e6dae3c4d419e89b5a904f470728
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 13 09:59:36 2008 -0500

    Btrfs: Improve metadata read latencies
    
    This fixes latency problems on metadata reads by making sure they
    don't go through the async submit queue, and by tuning down the amount
    of readahead done during btree searches.
    
    Also, the btrfs bdi congestion function is tuned to ignore the
    number of pending async bios and checksums pending.  There is additional
    code that throttles new async bios now and the congestion function
    doesn't need to worry about it anymore.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1bb54d69fbb2..3b0e974a9e9c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -605,7 +605,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 		BUG_ON(ret);
 
 		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
-				     mirror_num, 1);
+				     mirror_num, 0);
 	}
 	return btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
 				   inode, rw, bio, mirror_num, 0,
@@ -1139,11 +1139,11 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	struct list_head *cur;
 	struct btrfs_device *device;
 	struct backing_dev_info *bdi;
-
+#if 0
 	if ((bdi_bits & (1 << BDI_write_congested)) &&
 	    btrfs_congested_async(info, 0))
 		return 1;
-
+#endif
 	list_for_each(cur, &info->fs_devices->devices) {
 		device = list_entry(cur, struct btrfs_device, dev_list);
 		if (!device->bdev)

commit 240d5d482b69415b92ffce4b8dfca10799c9890b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 10 13:08:31 2008 -0500

    Btrfs: tune btrfs unplug functions for a small number of devices
    
    When btrfs unplugs, it tries to find the correct device to unplug
    via search through the extent_map tree.  This avoids unplugging
    a device that doesn't need it, but is a waste of time for filesystems
    with a small number of devices.
    
    This patch checks the total number of devices before doing the
    search.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8efc123d222b..1bb54d69fbb2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1201,6 +1201,16 @@ void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 		return;
 
 	inode = mapping->host;
+
+	/*
+	 * don't do the expensive searching for a small number of
+	 * devices
+	 */
+	if (BTRFS_I(inode)->root->fs_info->fs_devices->open_devices <= 2) {
+		__unplug_io_fn(bdi, page);
+		return;
+	}
+
 	offset = page_offset(page);
 
 	em_tree = &BTRFS_I(inode)->extent_tree;

commit 771ed689d2cd53439e28e095bc38fbe40a71429e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 6 22:02:51 2008 -0500

    Btrfs: Optimize compressed writeback and reads
    
    When reading compressed extents, try to put pages into the page cache
    for any pages covered by the compressed extent that readpages didn't already
    preload.
    
    Add an async work queue to handle transformations at delayed allocation processing
    time.  Right now this is just compression.  The workflow is:
    
    1) Find offsets in the file marked for delayed allocation
    2) Lock the pages
    3) Lock the state bits
    4) Call the async delalloc code
    
    The async delalloc code clears the state lock bits and delalloc bits.  It is
    important this happens before the range goes into the work queue because
    otherwise it might deadlock with other work queue items that try to lock
    those extent bits.
    
    The file pages are compressed, and if the compression doesn't work the
    pages are written back directly.
    
    An ordered work queue is used to make sure the inodes are written in the same
    order that pdflush or writepages sent them down.
    
    This changes extent_write_cache_pages to let the writepage function
    update the wbc nr_written count.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e0a28f705a64..8efc123d222b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -539,6 +539,13 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			   (atomic_read(&fs_info->nr_async_bios) < limit),
 			   HZ/10);
 	}
+
+	while(atomic_read(&fs_info->async_submit_draining) &&
+	      atomic_read(&fs_info->nr_async_submits)) {
+		wait_event(fs_info->async_submit_wait,
+			   (atomic_read(&fs_info->nr_async_submits) == 0));
+	}
+
 	return 0;
 }
 
@@ -1437,6 +1444,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	atomic_set(&fs_info->nr_async_submits, 0);
+	atomic_set(&fs_info->async_delalloc_pages, 0);
 	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
 	atomic_set(&fs_info->throttles, 0);
@@ -1550,6 +1558,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->workers, "worker",
 			   fs_info->thread_pool_size);
 
+	btrfs_init_workers(&fs_info->delalloc_workers, "delalloc",
+			   fs_info->thread_pool_size);
+
 	btrfs_init_workers(&fs_info->submit_workers, "submit",
 			   min_t(u64, fs_devices->num_devices,
 			   fs_info->thread_pool_size));
@@ -1560,15 +1571,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 */
 	fs_info->submit_workers.idle_thresh = 64;
 
-	/* fs_info->workers is responsible for checksumming file data
-	 * blocks and metadata.  Using a larger idle thresh allows each
-	 * worker thread to operate on things in roughly the order they
-	 * were sent by the writeback daemons, improving overall locality
-	 * of the IO going down the pipe.
-	 */
-	fs_info->workers.idle_thresh = 8;
+	fs_info->workers.idle_thresh = 16;
 	fs_info->workers.ordered = 1;
 
+	fs_info->delalloc_workers.idle_thresh = 2;
+	fs_info->delalloc_workers.ordered = 1;
+
 	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1);
 	btrfs_init_workers(&fs_info->endio_workers, "endio",
 			   fs_info->thread_pool_size);
@@ -1584,6 +1592,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	btrfs_start_workers(&fs_info->workers, 1);
 	btrfs_start_workers(&fs_info->submit_workers, 1);
+	btrfs_start_workers(&fs_info->delalloc_workers, 1);
 	btrfs_start_workers(&fs_info->fixup_workers, 1);
 	btrfs_start_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
 	btrfs_start_workers(&fs_info->endio_write_workers,
@@ -1732,6 +1741,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail_sys_array:
 fail_sb_buffer:
 	btrfs_stop_workers(&fs_info->fixup_workers);
+	btrfs_stop_workers(&fs_info->delalloc_workers);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
@@ -1988,6 +1998,7 @@ int close_ctree(struct btrfs_root *root)
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 
 	btrfs_stop_workers(&fs_info->fixup_workers);
+	btrfs_stop_workers(&fs_info->delalloc_workers);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
@@ -2062,7 +2073,7 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	struct extent_io_tree *tree;
 	u64 num_dirty;
 	u64 start = 0;
-	unsigned long thresh = 96 * 1024 * 1024;
+	unsigned long thresh = 32 * 1024 * 1024;
 	tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 
 	if (current_is_pdflush() || current->flags & PF_MEMALLOC)

commit 4a69a41009c4ac691f7d9c289f5f37fabeddce46
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Nov 6 22:03:00 2008 -0500

    Btrfs: Add ordered async work queues
    
    Btrfs uses kernel threads to create async work queues for cpu intensive
    operations such as checksumming and decompression.  These work well,
    but they make it difficult to keep IO order intact.
    
    A single writepages call from pdflush or fsync will turn into a number
    of bios, and each bio is checksummed in parallel.  Once the checksum is
    computed, the bio is sent down to the disk, and since we don't control
    the order in which the parallel operations happen, they might go down to
    the disk in almost any order.
    
    The code deals with this somewhat by having deep work queues for a single
    kernel thread, making it very likely that a single thread will process all
    the bios for a single inode.
    
    This patch introduces an explicitly ordered work queue.  As work structs
    are placed into the queue they are put onto the tail of a list.  They have
    three callbacks:
    
    ->func (cpu intensive processing here)
    ->ordered_func (order sensitive processing here)
    ->ordered_free (free the work struct, all processing is done)
    
    The work struct has three callbacks.  The func callback does the cpu intensive
    work, and when it completes the work struct is marked as done.
    
    Every time a work struct completes, the list is checked to see if the head
    is marked as done.  If so the ordered_func callback is used to do the
    order sensitive processing and the ordered_free callback is used to do
    any cleanup.  Then we loop back and check the head of the list again.
    
    This patch also changes the checksumming code to use the ordered workqueues.
    One a 4 drive array, it increases streaming writes from 280MB/s to 350MB/s.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 94b4e50f6b2c..e0a28f705a64 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -80,7 +80,8 @@ struct async_submit_bio {
 	struct inode *inode;
 	struct bio *bio;
 	struct list_head list;
-	extent_submit_bio_hook_t *submit_bio_hook;
+	extent_submit_bio_hook_t *submit_bio_start;
+	extent_submit_bio_hook_t *submit_bio_done;
 	int rw;
 	int mirror_num;
 	unsigned long bio_flags;
@@ -452,7 +453,18 @@ int btrfs_congested_async(struct btrfs_fs_info *info, int iodone)
 		btrfs_async_submit_limit(info);
 }
 
-static void run_one_async_submit(struct btrfs_work *work)
+static void run_one_async_start(struct btrfs_work *work)
+{
+	struct btrfs_fs_info *fs_info;
+	struct async_submit_bio *async;
+
+	async = container_of(work, struct  async_submit_bio, work);
+	fs_info = BTRFS_I(async->inode)->root->fs_info;
+	async->submit_bio_start(async->inode, async->rw, async->bio,
+			       async->mirror_num, async->bio_flags);
+}
+
+static void run_one_async_done(struct btrfs_work *work)
 {
 	struct btrfs_fs_info *fs_info;
 	struct async_submit_bio *async;
@@ -470,15 +482,23 @@ static void run_one_async_submit(struct btrfs_work *work)
 	    waitqueue_active(&fs_info->async_submit_wait))
 		wake_up(&fs_info->async_submit_wait);
 
-	async->submit_bio_hook(async->inode, async->rw, async->bio,
+	async->submit_bio_done(async->inode, async->rw, async->bio,
 			       async->mirror_num, async->bio_flags);
+}
+
+static void run_one_async_free(struct btrfs_work *work)
+{
+	struct async_submit_bio *async;
+
+	async = container_of(work, struct  async_submit_bio, work);
 	kfree(async);
 }
 
 int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			int rw, struct bio *bio, int mirror_num,
 			unsigned long bio_flags,
-			extent_submit_bio_hook_t *submit_bio_hook)
+			extent_submit_bio_hook_t *submit_bio_start,
+			extent_submit_bio_hook_t *submit_bio_done)
 {
 	struct async_submit_bio *async;
 	int limit = btrfs_async_submit_limit(fs_info);
@@ -491,8 +511,13 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->rw = rw;
 	async->bio = bio;
 	async->mirror_num = mirror_num;
-	async->submit_bio_hook = submit_bio_hook;
-	async->work.func = run_one_async_submit;
+	async->submit_bio_start = submit_bio_start;
+	async->submit_bio_done = submit_bio_done;
+
+	async->work.func = run_one_async_start;
+	async->work.ordered_func = run_one_async_done;
+	async->work.ordered_free = run_one_async_free;
+
 	async->work.flags = 0;
 	async->bio_flags = bio_flags;
 
@@ -533,29 +558,25 @@ static int btree_csum_one_bio(struct bio *bio)
 	return 0;
 }
 
-static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
-				 int mirror_num, unsigned long bio_flags)
+static int __btree_submit_bio_start(struct inode *inode, int rw,
+				    struct bio *bio, int mirror_num,
+				    unsigned long bio_flags)
 {
-	struct btrfs_root *root = BTRFS_I(inode)->root;
-	int ret;
-
 	/*
 	 * when we're called for a write, we're already in the async
 	 * submission context.  Just jump into btrfs_map_bio
 	 */
-	if (rw & (1 << BIO_RW)) {
-		btree_csum_one_bio(bio);
-		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
-				     mirror_num, 1);
-	}
+	btree_csum_one_bio(bio);
+	return 0;
+}
 
+static int __btree_submit_bio_done(struct inode *inode, int rw, struct bio *bio,
+				 int mirror_num, unsigned long bio_flags)
+{
 	/*
-	 * called for a read, do the setup so that checksum validation
-	 * can happen in the async kernel threads
+	 * when we're called for a write, we're already in the async
+	 * submission context.  Just jump into btrfs_map_bio
 	 */
-	ret = btrfs_bio_wq_end_io(root->fs_info, bio, 1);
-	BUG_ON(ret);
-
 	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num, 1);
 }
 
@@ -567,11 +588,22 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 	 * can happen in parallel across all CPUs
 	 */
 	if (!(rw & (1 << BIO_RW))) {
-		return __btree_submit_bio_hook(inode, rw, bio, mirror_num, 0);
+		int ret;
+		/*
+		 * called for a read, do the setup so that checksum validation
+		 * can happen in the async kernel threads
+		 */
+		ret = btrfs_bio_wq_end_io(BTRFS_I(inode)->root->fs_info,
+					  bio, 1);
+		BUG_ON(ret);
+
+		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
+				     mirror_num, 1);
 	}
 	return btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
 				   inode, rw, bio, mirror_num, 0,
-				   __btree_submit_bio_hook);
+				   __btree_submit_bio_start,
+				   __btree_submit_bio_done);
 }
 
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
@@ -1534,7 +1566,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 * were sent by the writeback daemons, improving overall locality
 	 * of the IO going down the pipe.
 	 */
-	fs_info->workers.idle_thresh = 128;
+	fs_info->workers.idle_thresh = 8;
+	fs_info->workers.ordered = 1;
 
 	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1);
 	btrfs_init_workers(&fs_info->endio_workers, "endio",

commit 84234f3a1f7c532e4afeba03cc8e7e4a8a5277ea
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Oct 29 14:49:05 2008 -0400

    Btrfs: Add root tree pointer transaction ids
    
    This patch adds transaction IDs to root tree pointers.
    Transaction IDs in tree pointers are compared with the
    generation numbers in block headers when reading root
    blocks of trees. This can detect some types of IO errors.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d1137d7ea8d4..94b4e50f6b2c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -832,6 +832,7 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 {
 	int ret;
 	u32 blocksize;
+	u64 generation;
 
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
 		     tree_root->sectorsize, tree_root->stripesize,
@@ -840,9 +841,10 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 				   &root->root_item, &root->root_key);
 	BUG_ON(ret);
 
+	generation = btrfs_root_generation(&root->root_item);
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
-				     blocksize, 0);
+				     blocksize, generation);
 	BUG_ON(!root->node);
 	return 0;
 }
@@ -929,6 +931,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 	struct btrfs_path *path;
 	struct extent_buffer *l;
 	u64 highest_inode;
+	u64 generation;
 	u32 blocksize;
 	int ret = 0;
 
@@ -970,9 +973,10 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
+	generation = btrfs_root_generation(&root->root_item);
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
-				     blocksize, 0);
+				     blocksize, generation);
 	BUG_ON(!root->node);
 insert:
 	if (location->objectid != BTRFS_TREE_LOG_OBJECTID) {
@@ -1357,6 +1361,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	u32 leafsize;
 	u32 blocksize;
 	u32 stripesize;
+	u64 generation;
 	struct buffer_head *bh;
 	struct btrfs_root *extent_root = kzalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
@@ -1596,13 +1601,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	blocksize = btrfs_level_size(tree_root,
 				     btrfs_super_chunk_root_level(disk_super));
+	generation = btrfs_super_chunk_root_generation(disk_super);
 
 	__setup_root(nodesize, leafsize, sectorsize, stripesize,
 		     chunk_root, fs_info, BTRFS_CHUNK_TREE_OBJECTID);
 
 	chunk_root->node = read_tree_block(chunk_root,
 					   btrfs_super_chunk_root(disk_super),
-					   blocksize, 0);
+					   blocksize, generation);
 	BUG_ON(!chunk_root->node);
 
 	read_extent_buffer(chunk_root->node, fs_info->chunk_tree_uuid,
@@ -1618,11 +1624,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	blocksize = btrfs_level_size(tree_root,
 				     btrfs_super_root_level(disk_super));
-
+	generation = btrfs_super_generation(disk_super);
 
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super),
-					  blocksize, 0);
+					  blocksize, generation);
 	if (!tree_root->node)
 		goto fail_sb_buffer;
 
@@ -1672,15 +1678,16 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			     log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
 
 		log_tree_root->node = read_tree_block(tree_root, bytenr,
-						      blocksize, 0);
+						      blocksize,
+						      generation + 1);
 		ret = btrfs_recover_log_trees(log_tree_root);
 		BUG_ON(ret);
 	}
+	fs_info->last_trans_committed = btrfs_super_generation(disk_super);
 
 	ret = btrfs_cleanup_reloc_trees(tree_root);
 	BUG_ON(ret);
 
-	fs_info->last_trans_committed = btrfs_super_generation(disk_super);
 	return tree_root;
 
 fail_cleaner:

commit 2517920135b0d29e70453e5b03d70d7b94207df3
Author: Josef Bacik <jbacik@redhat.com>
Date:   Wed Oct 29 14:49:05 2008 -0400

    Btrfs: nuke fs wide allocation mutex V2
    
    This patch removes the giant fs_info->alloc_mutex and replaces it with a bunch
    of little locks.
    
    There is now a pinned_mutex, which is used when messing with the pinned_extents
    extent io tree, and the extent_ins_mutex which is used with the pending_del and
    extent_ins extent io trees.
    
    The locking for the extent tree stuff was inspired by a patch that Yan Zheng
    wrote to fix a race condition, I cleaned it up some and changed the locking
    around a little bit, but the idea remains the same.  Basically instead of
    holding the extent_ins_mutex throughout the processing of an extent on the
    extent_ins or pending_del trees, we just hold it while we're searching and when
    we clear the bits on those trees, and lock the extent for the duration of the
    operations on the extent.
    
    Also to keep from getting hung up waiting to lock an extent, I've added a
    try_lock_extent so if we cannot lock the extent, move on to the next one in the
    tree and we'll come back to that one.  I have tested this heavily and it does
    not appear to break anything.  This has to be applied on top of my
    find_free_extent redo patch.
    
    I tested this patch on top of Yan's space reblancing code and it worked fine.
    The only thing that has changed since the last version is I pulled out all my
    debugging stuff, apparently I forgot to run guilt refresh before I sent the
    last patch out.  Thank you,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 796256440dfa..d1137d7ea8d4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1460,7 +1460,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
 	mutex_init(&fs_info->drop_mutex);
-	mutex_init(&fs_info->alloc_mutex);
+	mutex_init(&fs_info->extent_ins_mutex);
+	mutex_init(&fs_info->pinned_mutex);
 	mutex_init(&fs_info->chunk_mutex);
 	mutex_init(&fs_info->transaction_kthread_mutex);
 	mutex_init(&fs_info->cleaner_mutex);

commit f82d02d9d8222183b7945e893111a6d1bf67ae4a
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Oct 29 14:49:05 2008 -0400

    Btrfs: Improve space balancing code
    
    This patch improves the space balancing code to keep more sharing
    of tree blocks. The only case that breaks sharing of tree blocks is
    data extents get fragmented during balancing. The main changes in
    this patch are:
    
    Add a 'drop sub-tree' function. This solves the problem in old code
    that BTRFS_HEADER_FLAG_WRITTEN check breaks sharing of tree block.
    
    Remove relocation mapping tree. Relocation mappings are stored in
    struct btrfs_ref_path and updated dynamically during walking up/down
    the reference path. This reduces CPU usage and simplifies code.
    
    This patch also fixes a bug. Root items for reloc trees should be
    updated in btrfs_free_reloc_root.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dc95f636a11b..796256440dfa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1448,8 +1448,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 
-	extent_io_tree_init(&fs_info->reloc_mapping_tree,
-			    fs_info->btree_inode->i_mapping, GFP_NOFS);
 	INIT_LIST_HEAD(&fs_info->dead_reloc_roots);
 	btrfs_leaf_ref_tree_init(&fs_info->reloc_ref_tree);
 	btrfs_leaf_ref_tree_init(&fs_info->shared_ref_tree);

commit c8b978188c9a0fd3d535c13debd19d522b726f1f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Oct 29 14:49:59 2008 -0400

    Btrfs: Add zlib compression support
    
    This is a large change for adding compression on reading and writing,
    both for inline and regular extents.  It does some fairly large
    surgery to the writeback paths.
    
    Compression is off by default and enabled by mount -o compress.  Even
    when the -o compress mount option is not used, it is possible to read
    compressed extents off the disk.
    
    If compression for a given set of pages fails to make them smaller, the
    file is flagged to avoid future compression attempts later.
    
    * While finding delalloc extents, the pages are locked before being sent down
    to the delalloc handler.  This allows the delalloc handler to do complex things
    such as cleaning the pages, marking them writeback and starting IO on their
    behalf.
    
    * Inline extents are inserted at delalloc time now.  This allows us to compress
    the data before inserting the inline extent, and it allows us to insert
    an inline extent that spans multiple pages.
    
    * All of the in-memory extent representations (extent_map.c, ordered-data.c etc)
    are changed to record both an in-memory size and an on disk size, as well
    as a flag for compression.
    
    From a disk format point of view, the extent pointers in the file are changed
    to record the on disk size of a given extent and some encoding flags.
    Space in the disk format is allocated for compression encoding, as well
    as encryption and a generic 'other' field.  Neither the encryption or the
    'other' field are currently used.
    
    In order to limit the amount of data read for a single random read in the
    file, the size of a compressed extent is limited to 128k.  This is a
    software only limit, the disk format supports u64 sized compressed extents.
    
    In order to limit the ram consumed while processing extents, the uncompressed
    size of a compressed extent is limited to 256k.  This is a software only limit
    and will be subject to tuning later.
    
    Checksumming is still done on compressed extents, and it is done on the
    uncompressed version of the data.  This way additional encodings can be
    layered on without having to figure out which encoding to checksum.
    
    Compression happens at delalloc time, which is basically singled threaded because
    it is usually done by a single pdflush thread.  This makes it tricky to
    spread the compression load across all the cpus on the box.  We'll have to
    look at parallel pdflush walks of dirty inodes at a later time.
    
    Decompression is hooked into readpages and it does spread across CPUs nicely.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0be044bb6194..dc95f636a11b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -83,6 +83,7 @@ struct async_submit_bio {
 	extent_submit_bio_hook_t *submit_bio_hook;
 	int rw;
 	int mirror_num;
+	unsigned long bio_flags;
 	struct btrfs_work work;
 };
 
@@ -115,6 +116,7 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 	}
 	em->start = 0;
 	em->len = (u64)-1;
+	em->block_len = (u64)-1;
 	em->block_start = 0;
 	em->bdev = BTRFS_I(inode)->root->fs_info->fs_devices->latest_bdev;
 
@@ -469,12 +471,13 @@ static void run_one_async_submit(struct btrfs_work *work)
 		wake_up(&fs_info->async_submit_wait);
 
 	async->submit_bio_hook(async->inode, async->rw, async->bio,
-			       async->mirror_num);
+			       async->mirror_num, async->bio_flags);
 	kfree(async);
 }
 
 int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			int rw, struct bio *bio, int mirror_num,
+			unsigned long bio_flags,
 			extent_submit_bio_hook_t *submit_bio_hook)
 {
 	struct async_submit_bio *async;
@@ -491,6 +494,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->submit_bio_hook = submit_bio_hook;
 	async->work.func = run_one_async_submit;
 	async->work.flags = 0;
+	async->bio_flags = bio_flags;
 
 	while(atomic_read(&fs_info->async_submit_draining) &&
 	      atomic_read(&fs_info->nr_async_submits)) {
@@ -530,7 +534,7 @@ static int btree_csum_one_bio(struct bio *bio)
 }
 
 static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
-				 int mirror_num)
+				 int mirror_num, unsigned long bio_flags)
 {
 	struct btrfs_root *root = BTRFS_I(inode)->root;
 	int ret;
@@ -556,17 +560,17 @@ static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 }
 
 static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
-				 int mirror_num)
+				 int mirror_num, unsigned long bio_flags)
 {
 	/*
 	 * kthread helpers are used to submit writes so that checksumming
 	 * can happen in parallel across all CPUs
 	 */
 	if (!(rw & (1 << BIO_RW))) {
-		return __btree_submit_bio_hook(inode, rw, bio, mirror_num);
+		return __btree_submit_bio_hook(inode, rw, bio, mirror_num, 0);
 	}
 	return btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
-				   inode, rw, bio, mirror_num,
+				   inode, rw, bio, mirror_num, 0,
 				   __btree_submit_bio_hook);
 }
 
@@ -1407,6 +1411,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;
+
 	fs_info->thread_pool_size = min(num_online_cpus() + 2, 8);
 
 	INIT_LIST_HEAD(&fs_info->ordered_extents);
@@ -1508,6 +1513,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 */
 	btrfs_init_workers(&fs_info->workers, "worker",
 			   fs_info->thread_pool_size);
+
 	btrfs_init_workers(&fs_info->submit_workers, "submit",
 			   min_t(u64, fs_devices->num_devices,
 			   fs_info->thread_pool_size));
@@ -1559,6 +1565,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	}
 
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
+	fs_info->bdi.ra_pages = max(fs_info->bdi.ra_pages,
+				    4 * 1024 * 1024 / PAGE_CACHE_SIZE);
 
 	nodesize = btrfs_super_nodesize(disk_super);
 	leafsize = btrfs_super_leafsize(disk_super);

commit 83afeac42c5680b0b70d64fb8c4724cf05483fc2
Author: Jim Meyering <meyering@redhat.com>
Date:   Wed Oct 1 19:09:51 2008 -0400

    Btrfs: disk-io.c (open_ctree): avoid leaks upon allocation failure
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 41b7d24d07e2..0be044bb6194 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1699,6 +1699,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	kfree(tree_root);
 	bdi_destroy(&fs_info->bdi);
 	kfree(fs_info);
+	kfree(chunk_root);
+	kfree(dev_root);
 	return ERR_PTR(err);
 }
 

commit 0463bb4e8d2f717a9bf3be6cc12c0aec51cc261d
Author: Jim Meyering <meyering@redhat.com>
Date:   Wed Oct 1 19:09:04 2008 -0400

    Btrfs: disk-io.c (open_ctree): Don't deref. NULL upon failed kzalloc
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5ee10d3136f5..41b7d24d07e2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1371,7 +1371,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	struct btrfs_super_block *disk_super;
 
-	if (!extent_root || !tree_root || !fs_info) {
+	if (!extent_root || !tree_root || !fs_info ||
+	    !chunk_root || !dev_root) {
 		err = -ENOMEM;
 		goto fail;
 	}

commit d352ac68148b69937d39ca5d48bcc4478e118dbf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 29 15:18:18 2008 -0400

    Btrfs: add and improve comments
    
    This improves the comments at the top of many functions.  It didn't
    dive into the guts of functions because I was trying to
    avoid merging problems with the new allocator and back reference work.
    
    extent-tree.c and volumes.c were both skipped, and there is definitely
    more work todo in cleaning and commenting the code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 45b4f7285275..5ee10d3136f5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -55,6 +55,11 @@ static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
 static struct extent_io_ops btree_extent_io_ops;
 static void end_workqueue_fn(struct btrfs_work *work);
 
+/*
+ * end_io_wq structs are used to do processing in task context when an IO is
+ * complete.  This is used during reads to verify checksums, and it is used
+ * by writes to insert metadata for new file extents after IO is complete.
+ */
 struct end_io_wq {
 	struct bio *bio;
 	bio_end_io_t *end_io;
@@ -66,6 +71,11 @@ struct end_io_wq {
 	struct btrfs_work work;
 };
 
+/*
+ * async submit bios are used to offload expensive checksumming
+ * onto the worker threads.  They checksum file and metadata bios
+ * just before they are sent down the IO stack.
+ */
 struct async_submit_bio {
 	struct inode *inode;
 	struct bio *bio;
@@ -76,6 +86,10 @@ struct async_submit_bio {
 	struct btrfs_work work;
 };
 
+/*
+ * extents on the btree inode are pretty simple, there's one extent
+ * that covers the entire device
+ */
 struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 				    size_t page_offset, u64 start, u64 len,
 				    int create)
@@ -151,6 +165,10 @@ void btrfs_csum_final(u32 crc, char *result)
 	*(__le32 *)result = ~cpu_to_le32(crc);
 }
 
+/*
+ * compute the csum for a btree block, and either verify it or write it
+ * into the csum field of the block.
+ */
 static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			   int verify)
 {
@@ -204,6 +222,12 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	return 0;
 }
 
+/*
+ * we can't consider a given block up to date unless the transid of the
+ * block matches the transid in the parent node's pointer.  This is how we
+ * detect blocks that either didn't get written at all or got written
+ * in the wrong place.
+ */
 static int verify_parent_transid(struct extent_io_tree *io_tree,
 				 struct extent_buffer *eb, u64 parent_transid)
 {
@@ -228,9 +252,12 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 	unlock_extent(io_tree, eb->start, eb->start + eb->len - 1,
 		      GFP_NOFS);
 	return ret;
-
 }
 
+/*
+ * helper to read a given tree block, doing retries as required when
+ * the checksums don't match and we have alternate mirrors to try.
+ */
 static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 					  struct extent_buffer *eb,
 					  u64 start, u64 parent_transid)
@@ -260,6 +287,10 @@ printk("read extent buffer pages failed with ret %d mirror no %d\n", ret, mirror
 	return -EIO;
 }
 
+/*
+ * checksum a dirty tree block before IO.  This has extra checks to make
+ * sure we only fill in the checksum field in the first page of a multi-page block
+ */
 int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 {
 	struct extent_io_tree *tree;

commit 8c8bee1d7ca47fc75b6bd24a8085c525a2394c02
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 29 11:19:10 2008 -0400

    Btrfs: Wait for IO on the block device inodes of newly added devices
    
    btrfs-vol -a /dev/xxx will zero the first and last two MB of the device.
    The kernel code needs to wait for this IO to finish before it adds
    the device.
    
    btrfs metadata IO does not happen through the block device inode.  A
    separate address space is used, allowing the zero filled buffer heads in
    the block device inode to be written to disk after FS metadata starts
    going down to the disk via the btrfs metadata inode.
    
    The end result is zero filled metadata blocks after adding new devices
    into the filesystem.
    
    The fix is a simple filemap_write_and_wait on the block device inode
    before actually inserting it into the pool of available devices.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 45bc3132b054..45b4f7285275 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -460,6 +460,13 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->submit_bio_hook = submit_bio_hook;
 	async->work.func = run_one_async_submit;
 	async->work.flags = 0;
+
+	while(atomic_read(&fs_info->async_submit_draining) &&
+	      atomic_read(&fs_info->nr_async_submits)) {
+		wait_event(fs_info->async_submit_wait,
+			   (atomic_read(&fs_info->nr_async_submits) == 0));
+	}
+
 	atomic_inc(&fs_info->nr_async_submits);
 	btrfs_queue_worker(&fs_info->workers, &async->work);
 
@@ -495,11 +502,8 @@ static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 				 int mirror_num)
 {
 	struct btrfs_root *root = BTRFS_I(inode)->root;
-	u64 offset;
 	int ret;
 
-	offset = bio->bi_sector << 9;
-
 	/*
 	 * when we're called for a write, we're already in the async
 	 * submission context.  Just jump into btrfs_map_bio
@@ -1360,6 +1364,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	atomic_set(&fs_info->nr_async_submits, 0);
+	atomic_set(&fs_info->async_submit_draining, 0);
 	atomic_set(&fs_info->nr_async_bios, 0);
 	atomic_set(&fs_info->throttles, 0);
 	atomic_set(&fs_info->throttle_gen, 0);

commit 1a40e23b95da45051ee4d74374c58ae87a14051c
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Fri Sep 26 10:09:34 2008 -0400

    Btrfs: update space balancing code
    
    This patch updates the space balancing code to utilize the new
    backref format.  Before, btrfs-vol -b would break any COW links
    on data blocks or metadata.  This was slow and caused the amount
    of space used to explode if a large number of snapshots were present.
    
    The new code can keeps the sharing of all data extents and
    most of the tree blocks.
    
    To maintain the sharing of data extents, the space balance code uses
    a seperate inode hold data extent pointers, then updates the references
    to point to the new location.
    
    To maintain the sharing of tree blocks, the space balance code uses
    reloc trees to relocate tree blocks in reference counted roots.
    There is one reloc tree for each subvol, and all reloc trees share
    same root key objectid. Reloc trees are snapshots of the latest
    committed roots of subvols (root->commit_root).
    
    To relocate a tree block referenced by a subvol, there are two steps.
    COW the block through subvol's reloc tree, then update block pointer in
    the subvol to point to the new block. Since all reloc trees share
    same root key objectid, doing special handing for tree blocks
    owned by them is easy. Once a tree block has been COWed in one
    reloc tree, we can use the resulting new block directly when the
    same block is required to COW again through other reloc trees.
    In this way, relocated tree blocks are shared between reloc trees,
    so they are also shared between subvols.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8969fee23318..45bc3132b054 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1406,6 +1406,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 
+	extent_io_tree_init(&fs_info->reloc_mapping_tree,
+			    fs_info->btree_inode->i_mapping, GFP_NOFS);
+	INIT_LIST_HEAD(&fs_info->dead_reloc_roots);
+	btrfs_leaf_ref_tree_init(&fs_info->reloc_ref_tree);
 	btrfs_leaf_ref_tree_init(&fs_info->shared_ref_tree);
 
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
@@ -1421,6 +1425,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->transaction_kthread_mutex);
 	mutex_init(&fs_info->cleaner_mutex);
 	mutex_init(&fs_info->volume_mutex);
+	mutex_init(&fs_info->tree_reloc_mutex);
 	init_waitqueue_head(&fs_info->transaction_throttle);
 	init_waitqueue_head(&fs_info->transaction_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);
@@ -1627,6 +1632,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		ret = btrfs_recover_log_trees(log_tree_root);
 		BUG_ON(ret);
 	}
+
+	ret = btrfs_cleanup_reloc_trees(tree_root);
+	BUG_ON(ret);
+
 	fs_info->last_trans_committed = btrfs_super_generation(disk_super);
 	return tree_root;
 

commit e465768938f95388723b0fd3c50a0ae48173edb9
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Fri Sep 26 10:04:53 2008 -0400

    Btrfs: Add shared reference cache
    
    Btrfs has a cache of reference counts in leaves, allowing it to
    avoid reading tree leaves while deleting snapshots.  To reduce
    contention with multiple subvolumes, this cache is private to each
    subvolume.
    
    This patch adds shared reference cache support. The new space
    balancing code plays with multiple subvols at the same time, So
    the old per-subvol reference cache is not well suited.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 71e81f3a765b..8969fee23318 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1406,6 +1406,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 
+	btrfs_leaf_ref_tree_init(&fs_info->shared_ref_tree);
+
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));

commit 24ab9cd85c11bccacbd0cce7f8e1aebd4930404c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Sep 24 14:51:30 2008 -0400

    Btrfs: Raise thresholds for metadata writeback
    
    Btrfs metadata writeback is fairly expensive.  Once a tree block is written
    it must be cowed before it can be changed again.  The btree writepages
    code has a threshold based on a count of dirty btree bytes which is
    updated as IO is sent out.
    
    This changes btree_writepages to skip the writeout if there are less
    than 32MB of dirty bytes from the btrees, improving performance
    across many workloads.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dffb8dabd533..71e81f3a765b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -556,7 +556,7 @@ static int btree_writepages(struct address_space *mapping,
 	if (wbc->sync_mode == WB_SYNC_NONE) {
 		u64 num_dirty;
 		u64 start = 0;
-		unsigned long thresh = 8 * 1024 * 1024;
+		unsigned long thresh = 32 * 1024 * 1024;
 
 		if (wbc->for_kupdate)
 			return 0;
@@ -690,7 +690,7 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 int btrfs_write_tree_block(struct extent_buffer *buf)
 {
 	return btrfs_fdatawrite_range(buf->first_page->mapping, buf->start,
-				      buf->start + buf->len - 1, WB_SYNC_NONE);
+				      buf->start + buf->len - 1, WB_SYNC_ALL);
 }
 
 int btrfs_wait_tree_block_writeback(struct extent_buffer *buf)

commit 2b1f55b0f0d0d1a66470ef4ea2696cd5dd741a12
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Sep 24 11:48:04 2008 -0400

    Remove Btrfs compat code for older kernels
    
    Btrfs had compatibility code for kernels back to 2.6.18.  These have
    been removed, and will be maintained in a separate backport
    git tree from now on.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d35ca6a3f513..dffb8dabd533 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -26,11 +26,7 @@
 #include <linux/buffer_head.h> // for block_sync_page
 #include <linux/workqueue.h>
 #include <linux/kthread.h>
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,20)
 # include <linux/freezer.h>
-#else
-# include <linux/sched.h>
-#endif
 #include "crc32c.h"
 #include "ctree.h"
 #include "disk-io.h"
@@ -373,21 +369,11 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	return ret;
 }
 
-#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)
 static void end_workqueue_bio(struct bio *bio, int err)
-#else
-static int end_workqueue_bio(struct bio *bio,
-				   unsigned int bytes_done, int err)
-#endif
 {
 	struct end_io_wq *end_io_wq = bio->bi_private;
 	struct btrfs_fs_info *fs_info;
 
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
-	if (bio->bi_size)
-		return 1;
-#endif
-
 	fs_info = end_io_wq->info;
 	end_io_wq->error = err;
 	end_io_wq->work.func = end_workqueue_fn;
@@ -397,10 +383,6 @@ static int end_workqueue_bio(struct bio *bio,
 				   &end_io_wq->work);
 	else
 		btrfs_queue_worker(&fs_info->endio_workers, &end_io_wq->work);
-
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
-	return 0;
-#endif
 }
 
 int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
@@ -1161,9 +1143,7 @@ void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 
 static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 {
-#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)
 	bdi_init(bdi);
-#endif
 	bdi->ra_pages	= default_backing_dev_info.ra_pages;
 	bdi->state		= 0;
 	bdi->capabilities	= default_backing_dev_info.capabilities;
@@ -1242,11 +1222,7 @@ static void end_workqueue_fn(struct btrfs_work *work)
 	bio->bi_private = end_io_wq->private;
 	bio->bi_end_io = end_io_wq->end_io;
 	kfree(end_io_wq);
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
-	bio_endio(bio, bio->bi_size, error);
-#else
 	bio_endio(bio, error);
-#endif
 }
 
 static int cleaner_kthread(void *arg)
@@ -1673,9 +1649,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	kfree(extent_root);
 	kfree(tree_root);
-#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)
 	bdi_destroy(&fs_info->bdi);
-#endif
 	kfree(fs_info);
 	return ERR_PTR(err);
 }
@@ -1936,9 +1910,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
-#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)
 	bdi_destroy(&fs_info->bdi);
-#endif
 
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);

commit 31840ae1a6b433ca0e6a8d341756ff478bbf959e
Author: Zheng Yan <zheng.yan@oracle.com>
Date:   Tue Sep 23 13:14:14 2008 -0400

    Btrfs: Full back reference support
    
    This patch makes the back reference system to explicit record the
    location of parent node for all types of extents. The location of
    parent node is placed into the offset field of backref key. Every
    time a tree block is balanced, the back references for the affected
    lower level extents are updated.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 25be96946a2f..d35ca6a3f513 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -882,8 +882,8 @@ int btrfs_init_log_root_tree(struct btrfs_trans_handle *trans,
 	root->ref_cows = 0;
 
 	root->node = btrfs_alloc_free_block(trans, root, root->leafsize,
-					    BTRFS_TREE_LOG_OBJECTID,
-					    0, 0, 0, 0, 0);
+					    0, BTRFS_TREE_LOG_OBJECTID,
+					    trans->transid, 0, 0, 0);
 
 	btrfs_set_header_nritems(root->node, 0);
 	btrfs_set_header_level(root->node, 0);

commit ce3ed71a58094544da1e1dc4723f1f553bb5b2d5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Sep 23 13:14:12 2008 -0400

    Btrfs: Checksum tree blocks in the background
    
    Tree blocks were using async bio submission, but the sum was still
    being done directly during writepage.  This moves the checksumming
    into the worker thread.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 535bd0fe1a71..25be96946a2f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -315,14 +315,6 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	return 0;
 }
 
-static int btree_writepage_io_hook(struct page *page, u64 start, u64 end)
-{
-	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
-
-	csum_dirty_buffer(root, page);
-	return 0;
-}
-
 int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 			       struct extent_state *state)
 {
@@ -501,6 +493,22 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	return 0;
 }
 
+static int btree_csum_one_bio(struct bio *bio)
+{
+	struct bio_vec *bvec = bio->bi_io_vec;
+	int bio_index = 0;
+	struct btrfs_root *root;
+
+	WARN_ON(bio->bi_vcnt <= 0);
+	while(bio_index < bio->bi_vcnt) {
+		root = BTRFS_I(bvec->bv_page->mapping->host)->root;
+		csum_dirty_buffer(root, bvec->bv_page);
+		bio_index++;
+		bvec++;
+	}
+	return 0;
+}
+
 static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 				 int mirror_num)
 {
@@ -515,6 +523,7 @@ static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 	 * submission context.  Just jump into btrfs_map_bio
 	 */
 	if (rw & (1 << BIO_RW)) {
+		btree_csum_one_bio(bio);
 		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
 				     mirror_num, 1);
 	}
@@ -2040,7 +2049,6 @@ int btree_lock_page_hook(struct page *page)
 
 static struct extent_io_ops btree_extent_io_ops = {
 	.write_cache_pages_lock_hook = btree_lock_page_hook,
-	.writepage_io_hook = btree_writepage_io_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
 	.submit_bio_hook = btree_submit_bio_hook,
 	/* note we're sharing with inode.c for the merge bio hook */

commit 0f9dd46cda36b8de3b9f48bc42bd09d20b9c3b52
Author: Josef Bacik <jbacik@redhat.com>
Date:   Tue Sep 23 13:14:11 2008 -0400

    Btrfs: free space accounting redo
    
    1) replace the per fs_info extent_io_tree that tracked free space with two
    rb-trees per block group to track free space areas via offset and size.  The
    reason to do this is because most allocations come with a hint byte where to
    start, so we can usually find a chunk of free space at that hint byte to satisfy
    the allocation and get good space packing.  If we cannot find free space at or
    after the given offset we fall back on looking for a chunk of the given size as
    close to that given offset as possible.  When we fall back on the size search we
    also try to find a slot as close to the size we want as possible, to avoid
    breaking small chunks off of huge areas if possible.
    
    2) remove the extent_io_tree that tracked the block group cache from fs_info and
    replaced it with an rb-tree thats tracks block group cache via offset.  also
    added a per space_info list that tracks the block group cache for the particular
    space so we can lookup related block groups easily.
    
    3) cleaned up the allocation code to make it a little easier to read and a
    little less complicated.  Basically there are 3 steps, first look from our
    provided hint.  If we couldn't find from that given hint, start back at our
    original search start and look for space from there.  If that fails try to
    allocate space if we can and start looking again.  If not we're screwed and need
    to start over again.
    
    4) small fixes.  there were some issues in volumes.c where we wouldn't allocate
    the rest of the disk.  fixed cow_file_range to actually pass the alloc_hint,
    which has helped a good bit in making the fs_mark test I run have semi-normal
    results as we run out of space.  Generally with data allocations we don't track
    where we last allocated from, so everytime we did a data allocation we'd search
    through every block group that we have looking for free space.  Now searching a
    block group with no free space isn't terribly time consuming, it was causing a
    slight degradation as we got more data block groups.  The alloc_hint has fixed
    this slight degredation and made things semi-normal.
    
    There is still one nagging problem I'm working on where we will get ENOSPC when
    there is definitely plenty of space.  This only happens with metadata
    allocations, and only when we are almost full.  So you generally hit the 85%
    mark first, but sometimes you'll hit the BUG before you hit the 85% wall.  I'm
    still tracking it down, but until then this seems to be pretty stable and make a
    significant performance gain.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f6f7821d43a5..535bd0fe1a71 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1410,10 +1410,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	BTRFS_I(fs_info->btree_inode)->io_tree.ops = &btree_extent_io_ops;
 
-	extent_io_tree_init(&fs_info->free_space_cache,
-			     fs_info->btree_inode->i_mapping, GFP_NOFS);
-	extent_io_tree_init(&fs_info->block_group_cache,
-			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+	spin_lock_init(&fs_info->block_group_cache_lock);
+	fs_info->block_group_cache_tree.rb_node = NULL;
+
 	extent_io_tree_init(&fs_info->pinned_extents,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	extent_io_tree_init(&fs_info->pending_del,

commit 23a07867b78ee0f33b01466e52bb608c336b26ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 12 08:57:47 2008 -0400

    Btrfs: Fix mismerge in block header checks
    
    I had incorrectly disabled the check for the block number being correct
    in the header block.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 57fbf107e59f..f6f7821d43a5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -346,7 +346,7 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
 
 	found_start = btrfs_header_bytenr(eb);
-	if (0 && found_start != start) {
+	if (found_start != start) {
 		printk("bad tree block start %llu %llu\n",
 		       (unsigned long long)found_start,
 		       (unsigned long long)eb->start);

commit d0c803c4049c5ca322d4795d8b74f28768603e0e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Sep 11 16:17:57 2008 -0400

    Btrfs: Record dirty pages tree-log pages in an extent_io tree
    
    This is the same way the transaction code makes sure that all the
    other tree blocks are safely on disk.  There's an extent_io tree
    for each root, and any blocks allocated to the tree logs are
    recorded in that tree.
    
    At tree-log sync, the extent_io tree is walked to flush down the
    dirty pages and wait for them.
    
    The main benefit is less time spent walking the tree log and skipping
    clean pages, and getting sequential IO down to the drive.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5edb7f885799..57fbf107e59f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -777,6 +777,8 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	spin_lock_init(&root->list_lock);
 	mutex_init(&root->objectid_mutex);
 	mutex_init(&root->log_mutex);
+	extent_io_tree_init(&root->dirty_log_pages,
+			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 
 	btrfs_leaf_ref_tree_init(&root->ref_tree_struct);
 	root->ref_tree = &root->ref_tree_struct;
@@ -819,11 +821,23 @@ int btrfs_free_log_root_tree(struct btrfs_trans_handle *trans,
 			     struct btrfs_fs_info *fs_info)
 {
 	struct extent_buffer *eb;
+	struct btrfs_root *log_root_tree = fs_info->log_root_tree;
+	u64 start = 0;
+	u64 end = 0;
 	int ret;
 
-	if (!fs_info->log_root_tree)
+	if (!log_root_tree)
 		return 0;
 
+	while(1) {
+		ret = find_first_extent_bit(&log_root_tree->dirty_log_pages,
+				    0, &start, &end, EXTENT_DIRTY);
+		if (ret)
+			break;
+
+		clear_extent_dirty(&log_root_tree->dirty_log_pages,
+				   start, end, GFP_NOFS);
+	}
 	eb = fs_info->log_root_tree->node;
 
 	WARN_ON(btrfs_header_level(eb) != 0);
@@ -1412,7 +1426,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));
 	insert_inode_hash(fs_info->btree_inode);
-	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->tree_log_mutex);

commit d00aff00139b40f2e9c60299d76aac29d72e48ba
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Sep 11 15:54:42 2008 -0400

    Btrfs: Optimize tree log block allocations
    
    Since tree log blocks get freed every transaction, they never really
    need to be written to disk.  This skips the step where we update
    metadata to record they were allocated.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7c06eb4ecfdd..5edb7f885799 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -829,9 +829,8 @@ int btrfs_free_log_root_tree(struct btrfs_trans_handle *trans,
 	WARN_ON(btrfs_header_level(eb) != 0);
 	WARN_ON(btrfs_header_nritems(eb) != 0);
 
-	ret = btrfs_free_extent(trans, fs_info->tree_root,
-				eb->start, eb->len,
-				BTRFS_TREE_LOG_OBJECTID, 0, 0, 0, 1);
+	ret = btrfs_free_reserved_extent(fs_info->tree_root,
+				eb->start, eb->len);
 	BUG_ON(ret);
 
 	free_extent_buffer(eb);

commit 3a5f1d458ad1610a06e38f0be2fbc6ac215439c0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Sep 11 15:53:37 2008 -0400

    Btrfs: Optimize btree walking while logging inodes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ecb74b720262..7c06eb4ecfdd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1497,7 +1497,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 * low idle thresh
 	 */
 	fs_info->endio_workers.idle_thresh = 4;
-	fs_info->endio_write_workers.idle_thresh = 4;
+	fs_info->endio_write_workers.idle_thresh = 64;
 
 	btrfs_start_workers(&fs_info->workers, 1);
 	btrfs_start_workers(&fs_info->submit_workers, 1);

commit 98509cfc5a6857bddcfe4b19a9539726655ec9bd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Sep 11 15:51:43 2008 -0400

    Btrfs: Fix releasepage to properly keep dirty and writeback pages
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 42bf99168056..ecb74b720262 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -346,7 +346,7 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
 
 	found_start = btrfs_header_bytenr(eb);
-	if (found_start != start) {
+	if (0 && found_start != start) {
 		printk("bad tree block start %llu %llu\n",
 		       (unsigned long long)found_start,
 		       (unsigned long long)eb->start);
@@ -592,6 +592,9 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	struct extent_map_tree *map;
 	int ret;
 
+	if (PageWriteback(page) || PageDirty(page))
+	    return 0;
+
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
 

commit 4bef084857ab8fe71cf49eae349c25e440a49150
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 8 11:18:08 2008 -0400

    Btrfs: Tree logging fixes
    
    * Pin down data blocks to prevent them from being reallocated like so:
    
    trans 1: allocate file extent
    trans 2: free file extent
    trans 3: free file extent during old snapshot deletion
    trans 3: allocate file extent to new file
    trans 3: fsync new file
    
    Before the tree logging code, this was legal because the fsync
    would commit the transation that did the final data extent free
    and the transaction that allocated the extent to the new file
    at the same time.
    
    With the tree logging code, the tree log subtransaction can commit
    before the transaction that freed the extent.  If we crash,
    we're left with two different files using the extent.
    
    * Don't wait in start_transaction if log replay is going on.  This
    avoids deadlocks from iput while we're cleaning up link counts in the
    replay code.
    
    * Don't deadlock in replay_one_name by trying to read an inode off
    the disk while holding paths for the directory
    
    * Hold the buffer lock while we mark a buffer as written.  This
    closes a race where someone is changing a buffer while we write it.
    They are supposed to mark it dirty again after they change it, but
    this violates the cow rules.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a4373db5967a..42bf99168056 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -307,9 +307,7 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 		goto err;
 	}
 	found_level = btrfs_header_level(eb);
-	spin_lock(&root->fs_info->hash_lock);
-	btrfs_set_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN);
-	spin_unlock(&root->fs_info->hash_lock);
+
 	csum_tree_block(root, eb, 0);
 err:
 	free_extent_buffer(eb);
@@ -1998,7 +1996,36 @@ int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 	return ret;
 }
 
+int btree_lock_page_hook(struct page *page)
+{
+	struct inode *inode = page->mapping->host;
+	struct btrfs_root *root = BTRFS_I(inode)->root;
+	struct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;
+	struct extent_buffer *eb;
+	unsigned long len;
+	u64 bytenr = page_offset(page);
+
+	if (page->private == EXTENT_PAGE_PRIVATE)
+		goto out;
+
+	len = page->private >> 2;
+	eb = find_extent_buffer(io_tree, bytenr, len, GFP_NOFS);
+	if (!eb)
+		goto out;
+
+	btrfs_tree_lock(eb);
+	spin_lock(&root->fs_info->hash_lock);
+	btrfs_set_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN);
+	spin_unlock(&root->fs_info->hash_lock);
+	btrfs_tree_unlock(eb);
+	free_extent_buffer(eb);
+out:
+	lock_page(page);
+	return 0;
+}
+
 static struct extent_io_ops btree_extent_io_ops = {
+	.write_cache_pages_lock_hook = btree_lock_page_hook,
 	.writepage_io_hook = btree_writepage_io_hook,
 	.readpage_end_io_hook = btree_readpage_end_io_hook,
 	.submit_bio_hook = btree_submit_bio_hook,

commit e02119d5a7b4396c5a872582fddc8bd6d305a70a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 5 16:13:11 2008 -0400

    Btrfs: Add a write ahead tree log to optimize synchronous operations
    
    File syncs and directory syncs are optimized by copying their
    items into a special (copy-on-write) log tree.  There is one log tree per
    subvolume and the btrfs super block points to a tree of log tree roots.
    
    After a crash, items are copied out of the log tree and back into the
    subvolume.  See tree-log.c for all the details.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8e7a938bfbc7..a4373db5967a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -41,6 +41,7 @@
 #include "async-thread.h"
 #include "locking.h"
 #include "ref-cache.h"
+#include "tree-log.h"
 
 #if 0
 static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
@@ -694,6 +695,18 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 }
 
 
+int btrfs_write_tree_block(struct extent_buffer *buf)
+{
+	return btrfs_fdatawrite_range(buf->first_page->mapping, buf->start,
+				      buf->start + buf->len - 1, WB_SYNC_NONE);
+}
+
+int btrfs_wait_tree_block_writeback(struct extent_buffer *buf)
+{
+	return btrfs_wait_on_page_writeback_range(buf->first_page->mapping,
+				  buf->start, buf->start + buf->len -1);
+}
+
 struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 				      u32 blocksize, u64 parent_transid)
 {
@@ -732,15 +745,6 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 	return 0;
 }
 
-int wait_on_tree_block_writeback(struct btrfs_root *root,
-				 struct extent_buffer *buf)
-{
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	wait_on_extent_buffer_writeback(&BTRFS_I(btree_inode)->io_tree,
-					buf);
-	return 0;
-}
-
 static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 			u32 stripesize, struct btrfs_root *root,
 			struct btrfs_fs_info *fs_info,
@@ -771,6 +775,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	spin_lock_init(&root->node_lock);
 	spin_lock_init(&root->list_lock);
 	mutex_init(&root->objectid_mutex);
+	mutex_init(&root->log_mutex);
 
 	btrfs_leaf_ref_tree_init(&root->ref_tree_struct);
 	root->ref_tree = &root->ref_tree_struct;
@@ -809,11 +814,74 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 	return 0;
 }
 
-struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
-					       struct btrfs_key *location)
+int btrfs_free_log_root_tree(struct btrfs_trans_handle *trans,
+			     struct btrfs_fs_info *fs_info)
+{
+	struct extent_buffer *eb;
+	int ret;
+
+	if (!fs_info->log_root_tree)
+		return 0;
+
+	eb = fs_info->log_root_tree->node;
+
+	WARN_ON(btrfs_header_level(eb) != 0);
+	WARN_ON(btrfs_header_nritems(eb) != 0);
+
+	ret = btrfs_free_extent(trans, fs_info->tree_root,
+				eb->start, eb->len,
+				BTRFS_TREE_LOG_OBJECTID, 0, 0, 0, 1);
+	BUG_ON(ret);
+
+	free_extent_buffer(eb);
+	kfree(fs_info->log_root_tree);
+	fs_info->log_root_tree = NULL;
+	return 0;
+}
+
+int btrfs_init_log_root_tree(struct btrfs_trans_handle *trans,
+			     struct btrfs_fs_info *fs_info)
 {
 	struct btrfs_root *root;
 	struct btrfs_root *tree_root = fs_info->tree_root;
+
+	root = kzalloc(sizeof(*root), GFP_NOFS);
+	if (!root)
+		return -ENOMEM;
+
+	__setup_root(tree_root->nodesize, tree_root->leafsize,
+		     tree_root->sectorsize, tree_root->stripesize,
+		     root, fs_info, BTRFS_TREE_LOG_OBJECTID);
+
+	root->root_key.objectid = BTRFS_TREE_LOG_OBJECTID;
+	root->root_key.type = BTRFS_ROOT_ITEM_KEY;
+	root->root_key.offset = BTRFS_TREE_LOG_OBJECTID;
+	root->ref_cows = 0;
+
+	root->node = btrfs_alloc_free_block(trans, root, root->leafsize,
+					    BTRFS_TREE_LOG_OBJECTID,
+					    0, 0, 0, 0, 0);
+
+	btrfs_set_header_nritems(root->node, 0);
+	btrfs_set_header_level(root->node, 0);
+	btrfs_set_header_bytenr(root->node, root->node->start);
+	btrfs_set_header_generation(root->node, trans->transid);
+	btrfs_set_header_owner(root->node, BTRFS_TREE_LOG_OBJECTID);
+
+	write_extent_buffer(root->node, root->fs_info->fsid,
+			    (unsigned long)btrfs_header_fsid(root->node),
+			    BTRFS_FSID_SIZE);
+	btrfs_mark_buffer_dirty(root->node);
+	btrfs_tree_unlock(root->node);
+	fs_info->log_root_tree = root;
+	return 0;
+}
+
+struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_root *tree_root,
+					       struct btrfs_key *location)
+{
+	struct btrfs_root *root;
+	struct btrfs_fs_info *fs_info = tree_root->fs_info;
 	struct btrfs_path *path;
 	struct extent_buffer *l;
 	u64 highest_inode;
@@ -863,11 +931,13 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 				     blocksize, 0);
 	BUG_ON(!root->node);
 insert:
-	root->ref_cows = 1;
-	ret = btrfs_find_highest_inode(root, &highest_inode);
-	if (ret == 0) {
-		root->highest_inode = highest_inode;
-		root->last_inode_alloc = highest_inode;
+	if (location->objectid != BTRFS_TREE_LOG_OBJECTID) {
+		root->ref_cows = 1;
+		ret = btrfs_find_highest_inode(root, &highest_inode);
+		if (ret == 0) {
+			root->highest_inode = highest_inode;
+			root->last_inode_alloc = highest_inode;
+		}
 	}
 	return root;
 }
@@ -907,7 +977,7 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 	if (root)
 		return root;
 
-	root = btrfs_read_fs_root_no_radix(fs_info, location);
+	root = btrfs_read_fs_root_no_radix(fs_info->tree_root, location);
 	if (IS_ERR(root))
 		return root;
 	ret = radix_tree_insert(&fs_info->fs_roots_radix,
@@ -1250,16 +1320,18 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	u32 blocksize;
 	u32 stripesize;
 	struct buffer_head *bh;
-	struct btrfs_root *extent_root = kmalloc(sizeof(struct btrfs_root),
+	struct btrfs_root *extent_root = kzalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
-	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
+	struct btrfs_root *tree_root = kzalloc(sizeof(struct btrfs_root),
 					       GFP_NOFS);
 	struct btrfs_fs_info *fs_info = kzalloc(sizeof(*fs_info),
 						GFP_NOFS);
-	struct btrfs_root *chunk_root = kmalloc(sizeof(struct btrfs_root),
+	struct btrfs_root *chunk_root = kzalloc(sizeof(struct btrfs_root),
 						GFP_NOFS);
-	struct btrfs_root *dev_root = kmalloc(sizeof(struct btrfs_root),
+	struct btrfs_root *dev_root = kzalloc(sizeof(struct btrfs_root),
 					      GFP_NOFS);
+	struct btrfs_root *log_tree_root;
+
 	int ret;
 	int err = -EINVAL;
 
@@ -1343,6 +1415,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 
 	mutex_init(&fs_info->trans_mutex);
+	mutex_init(&fs_info->tree_log_mutex);
 	mutex_init(&fs_info->drop_mutex);
 	mutex_init(&fs_info->alloc_mutex);
 	mutex_init(&fs_info->chunk_mutex);
@@ -1352,6 +1425,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	init_waitqueue_head(&fs_info->transaction_throttle);
 	init_waitqueue_head(&fs_info->transaction_wait);
 	init_waitqueue_head(&fs_info->async_submit_wait);
+	init_waitqueue_head(&fs_info->tree_log_wait);
+	atomic_set(&fs_info->tree_log_commit, 0);
+	atomic_set(&fs_info->tree_log_writers, 0);
+	fs_info->tree_log_transid = 0;
 
 #if 0
 	ret = add_hasher(fs_info, "crc32c");
@@ -1532,7 +1609,26 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!fs_info->transaction_kthread)
 		goto fail_cleaner;
 
+	if (btrfs_super_log_root(disk_super) != 0) {
+		u32 blocksize;
+		u64 bytenr = btrfs_super_log_root(disk_super);
+
+		blocksize =
+		     btrfs_level_size(tree_root,
+				      btrfs_super_log_root_level(disk_super));
 
+		log_tree_root = kzalloc(sizeof(struct btrfs_root),
+						      GFP_NOFS);
+
+		__setup_root(nodesize, leafsize, sectorsize, stripesize,
+			     log_tree_root, fs_info, BTRFS_TREE_LOG_OBJECTID);
+
+		log_tree_root->node = read_tree_block(tree_root, bytenr,
+						      blocksize, 0);
+		ret = btrfs_recover_log_trees(log_tree_root);
+		BUG_ON(ret);
+	}
+	fs_info->last_trans_committed = btrfs_super_generation(disk_super);
 	return tree_root;
 
 fail_cleaner:

commit a1b32a5932cfac7c38b442582285f3da2a09dfd8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 5 16:09:51 2008 -0400

    Btrfs: Add debugging checks to track down corrupted metadata
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6a218f792e59..8e7a938bfbc7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -250,7 +250,7 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 		if (!ret &&
 		    !verify_parent_transid(io_tree, eb, parent_transid))
 			return ret;
-
+printk("read extent buffer pages failed with ret %d mirror no %d\n", ret, mirror_num);
 		num_copies = btrfs_num_copies(&root->fs_info->mapping_tree,
 					      eb->start, eb->len);
 		if (num_copies == 1)
@@ -348,6 +348,9 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
+		printk("bad tree block start %llu %llu\n",
+		       (unsigned long long)found_start,
+		       (unsigned long long)eb->start);
 		ret = -EIO;
 		goto err;
 	}
@@ -709,6 +712,8 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 
 	if (ret == 0) {
 		buf->flags |= EXTENT_UPTODATE;
+	} else {
+		WARN_ON(1);
 	}
 	return buf;
 

commit 9473f16c75606fe6b2e5000525fe9766114505f3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Aug 28 06:15:24 2008 -0400

    Btrfs: Throttle for async bio submits higher up the chain
    
    The current code waits for the count of async bio submits to get below
    a given threshold if it is too high right after adding the latest bio
    to the work queue.  This isn't optimal because the caller may have
    sequential adjacent bios pending they are waiting to send down the pipe.
    
    This changeset requires the caller to wait on the async bio count,
    and changes the async checksumming submits to wait for async bios any
    time they self throttle.
    
    The end result is much higher sequential throughput.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bbba14b629d2..6a218f792e59 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -487,9 +487,15 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	atomic_inc(&fs_info->nr_async_submits);
 	btrfs_queue_worker(&fs_info->workers, &async->work);
 
-	wait_event_timeout(fs_info->async_submit_wait,
+	if (atomic_read(&fs_info->nr_async_submits) > limit) {
+		wait_event_timeout(fs_info->async_submit_wait,
 			   (atomic_read(&fs_info->nr_async_submits) < limit),
 			   HZ/10);
+
+		wait_event_timeout(fs_info->async_submit_wait,
+			   (atomic_read(&fs_info->nr_async_bios) < limit),
+			   HZ/10);
+	}
 	return 0;
 }
 

commit b64a2851ba25b3410a87d3d1b751155612105c8e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Aug 20 13:39:41 2008 -0400

    Btrfs: Wait for async bio submissions to make some progress at queue time
    
    Before, the btrfs bdi congestion function was used to test for too many
    async bios.  This keeps that check to throttle pdflush, but also
    adds a check while queuing bios.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 92e14dd9bddb..bbba14b629d2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -429,7 +429,7 @@ int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 	return 0;
 }
 
-static unsigned long async_submit_limit(struct btrfs_fs_info *info)
+unsigned long btrfs_async_submit_limit(struct btrfs_fs_info *info)
 {
 	unsigned long limit = min_t(unsigned long,
 				    info->workers.max_workers,
@@ -439,7 +439,8 @@ static unsigned long async_submit_limit(struct btrfs_fs_info *info)
 
 int btrfs_congested_async(struct btrfs_fs_info *info, int iodone)
 {
-	return atomic_read(&info->nr_async_bios) > async_submit_limit(info);
+	return atomic_read(&info->nr_async_bios) >
+		btrfs_async_submit_limit(info);
 }
 
 static void run_one_async_submit(struct btrfs_work *work)
@@ -451,12 +452,13 @@ static void run_one_async_submit(struct btrfs_work *work)
 	async = container_of(work, struct  async_submit_bio, work);
 	fs_info = BTRFS_I(async->inode)->root->fs_info;
 
-	limit = async_submit_limit(fs_info);
+	limit = btrfs_async_submit_limit(fs_info);
 	limit = limit * 2 / 3;
 
 	atomic_dec(&fs_info->nr_async_submits);
 
-	if (atomic_read(&fs_info->nr_async_submits) < limit)
+	if (atomic_read(&fs_info->nr_async_submits) < limit &&
+	    waitqueue_active(&fs_info->async_submit_wait))
 		wake_up(&fs_info->async_submit_wait);
 
 	async->submit_bio_hook(async->inode, async->rw, async->bio,
@@ -469,7 +471,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			extent_submit_bio_hook_t *submit_bio_hook)
 {
 	struct async_submit_bio *async;
-	int limit = async_submit_limit(fs_info);
+	int limit = btrfs_async_submit_limit(fs_info);
 
 	async = kmalloc(sizeof(*async), GFP_NOFS);
 	if (!async)
@@ -1863,10 +1865,10 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	struct extent_io_tree *tree;
 	u64 num_dirty;
 	u64 start = 0;
-	unsigned long thresh = 12 * 1024 * 1024;
+	unsigned long thresh = 96 * 1024 * 1024;
 	tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 
-	if (current_is_pdflush())
+	if (current_is_pdflush() || current->flags & PF_MEMALLOC)
 		return;
 
 	num_dirty = count_range_bits(tree, &start, (u64)-1,

commit 53863232ef961778aa414b700ed88a48e8e871e6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 15 15:34:18 2008 -0400

    Btrfs: Lower contention on the csum mutex
    
    This takes the csum mutex deeper in the call chain and releases it
    more often.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1aed1f4616b6..92e14dd9bddb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1386,7 +1386,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 * devices
 	 */
 	fs_info->submit_workers.idle_thresh = 64;
-	fs_info->workers.idle_thresh = 32;
+
+	/* fs_info->workers is responsible for checksumming file data
+	 * blocks and metadata.  Using a larger idle thresh allows each
+	 * worker thread to operate on things in roughly the order they
+	 * were sent by the writeback daemons, improving overall locality
+	 * of the IO going down the pipe.
+	 */
+	fs_info->workers.idle_thresh = 128;
 
 	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1);
 	btrfs_init_workers(&fs_info->endio_workers, "endio",

commit 4854ddd0ed0a687fc2d7c45a529c406232e31e7b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 15 15:34:17 2008 -0400

    Btrfs: Wait for kernel threads to make progress during async submission
    
    Before this change, btrfs would use a bdi congestion function to make
    sure there weren't too many pending async checksum work items.
    
    This change makes the process creating async work items wait instead,
    leading to fewer congestion returns from the bdi.  This improves
    pdflush background_writeout scanning.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1bf210dadef6..1aed1f4616b6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -429,31 +429,36 @@ int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 	return 0;
 }
 
-int btrfs_congested_async(struct btrfs_fs_info *info, int iodone)
+static unsigned long async_submit_limit(struct btrfs_fs_info *info)
 {
-	int limit = 256 * info->fs_devices->open_devices;
-
-	if (iodone)
-		limit = (limit * 3) / 2;
-	if (atomic_read(&info->nr_async_submits) > limit)
-		return 1;
+	unsigned long limit = min_t(unsigned long,
+				    info->workers.max_workers,
+				    info->fs_devices->open_devices);
+	return 256 * limit;
+}
 
-	return atomic_read(&info->nr_async_bios) > limit;
+int btrfs_congested_async(struct btrfs_fs_info *info, int iodone)
+{
+	return atomic_read(&info->nr_async_bios) > async_submit_limit(info);
 }
 
 static void run_one_async_submit(struct btrfs_work *work)
 {
 	struct btrfs_fs_info *fs_info;
 	struct async_submit_bio *async;
+	int limit;
 
 	async = container_of(work, struct  async_submit_bio, work);
 	fs_info = BTRFS_I(async->inode)->root->fs_info;
+
+	limit = async_submit_limit(fs_info);
+	limit = limit * 2 / 3;
+
 	atomic_dec(&fs_info->nr_async_submits);
 
-	if ((async->bio->bi_rw & (1 << BIO_RW)) &&
-	    !btrfs_congested_async(fs_info, 1)) {
-		clear_bdi_congested(&fs_info->bdi, WRITE);
-	}
+	if (atomic_read(&fs_info->nr_async_submits) < limit)
+		wake_up(&fs_info->async_submit_wait);
+
 	async->submit_bio_hook(async->inode, async->rw, async->bio,
 			       async->mirror_num);
 	kfree(async);
@@ -464,6 +469,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			extent_submit_bio_hook_t *submit_bio_hook)
 {
 	struct async_submit_bio *async;
+	int limit = async_submit_limit(fs_info);
 
 	async = kmalloc(sizeof(*async), GFP_NOFS);
 	if (!async)
@@ -478,6 +484,10 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->work.flags = 0;
 	atomic_inc(&fs_info->nr_async_submits);
 	btrfs_queue_worker(&fs_info->workers, &async->work);
+
+	wait_event_timeout(fs_info->async_submit_wait,
+			   (atomic_read(&fs_info->nr_async_submits) < limit),
+			   HZ/10);
 	return 0;
 }
 
@@ -545,16 +555,11 @@ static int btree_writepages(struct address_space *mapping,
 	if (wbc->sync_mode == WB_SYNC_NONE) {
 		u64 num_dirty;
 		u64 start = 0;
-		unsigned long thresh = 96 * 1024 * 1024;
+		unsigned long thresh = 8 * 1024 * 1024;
 
 		if (wbc->for_kupdate)
 			return 0;
 
-		if (current_is_pdflush()) {
-			thresh = 96 * 1024 * 1024;
-		} else {
-			thresh = 8 * 1024 * 1024;
-		}
 		num_dirty = count_range_bits(tree, &start, (u64)-1,
 					     thresh, EXTENT_DIRTY);
 		if (num_dirty < thresh) {
@@ -1333,6 +1338,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->volume_mutex);
 	init_waitqueue_head(&fs_info->transaction_throttle);
 	init_waitqueue_head(&fs_info->transaction_wait);
+	init_waitqueue_head(&fs_info->async_submit_wait);
 
 #if 0
 	ret = add_hasher(fs_info, "crc32c");
@@ -1380,6 +1386,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 * devices
 	 */
 	fs_info->submit_workers.idle_thresh = 64;
+	fs_info->workers.idle_thresh = 32;
 
 	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1);
 	btrfs_init_workers(&fs_info->endio_workers, "endio",
@@ -1849,7 +1856,7 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	struct extent_io_tree *tree;
 	u64 num_dirty;
 	u64 start = 0;
-	unsigned long thresh = 2 * 1024 * 1024;
+	unsigned long thresh = 12 * 1024 * 1024;
 	tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 
 	if (current_is_pdflush())

commit 5443be45f5cb57d02fd895a0bcaf7e7d9890b1df
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 15 15:34:16 2008 -0400

    Btrfs: Give all the worker threads descriptive names
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9601b13c7d7a..1bf210dadef6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -492,11 +492,11 @@ static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 
 	/*
 	 * when we're called for a write, we're already in the async
-	 * submission context.  Just jump ingo btrfs_map_bio
+	 * submission context.  Just jump into btrfs_map_bio
 	 */
 	if (rw & (1 << BIO_RW)) {
 		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
-				     mirror_num, 0);
+				     mirror_num, 1);
 	}
 
 	/*
@@ -528,6 +528,12 @@ static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct extent_io_tree *tree;
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
+
+	if (current->flags & PF_MEMALLOC) {
+		redirty_page_for_writepage(wbc, page);
+		unlock_page(page);
+		return 0;
+	}
 	return extent_write_full_page(tree, page, btree_get_extent, wbc);
 }
 
@@ -1363,8 +1369,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 * queue work function gets called at interrupt time, and so it
 	 * cannot dynamically grow.
 	 */
-	btrfs_init_workers(&fs_info->workers, fs_info->thread_pool_size);
-	btrfs_init_workers(&fs_info->submit_workers,
+	btrfs_init_workers(&fs_info->workers, "worker",
+			   fs_info->thread_pool_size);
+	btrfs_init_workers(&fs_info->submit_workers, "submit",
 			   min_t(u64, fs_devices->num_devices,
 			   fs_info->thread_pool_size));
 
@@ -1374,9 +1381,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 */
 	fs_info->submit_workers.idle_thresh = 64;
 
-	btrfs_init_workers(&fs_info->fixup_workers, 1);
-	btrfs_init_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
-	btrfs_init_workers(&fs_info->endio_write_workers,
+	btrfs_init_workers(&fs_info->fixup_workers, "fixup", 1);
+	btrfs_init_workers(&fs_info->endio_workers, "endio",
+			   fs_info->thread_pool_size);
+	btrfs_init_workers(&fs_info->endio_write_workers, "endio-write",
 			   fs_info->thread_pool_size);
 
 	/*

commit 777e6bd706ee40897545463871de5b456fbc46dc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 15 15:34:15 2008 -0400

    Btrfs: Transaction commit: don't use filemap_fdatawait
    
    After writing out all the remaining btree blocks in the transaction,
    the commit code would use filemap_fdatawait to make sure it was all
    on disk.  This means it would wait for blocks written by other procs
    as well.
    
    The new code walks the list of blocks for this transaction again
    and waits only for those required by this transaction.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9902d29abd06..9601b13c7d7a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -429,7 +429,7 @@ int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 	return 0;
 }
 
-static int congested_async(struct btrfs_fs_info *info, int iodone)
+int btrfs_congested_async(struct btrfs_fs_info *info, int iodone)
 {
 	int limit = 256 * info->fs_devices->open_devices;
 
@@ -438,9 +438,6 @@ static int congested_async(struct btrfs_fs_info *info, int iodone)
 	if (atomic_read(&info->nr_async_submits) > limit)
 		return 1;
 
-	limit = 8192 * info->fs_devices->open_devices;
-	if (iodone)
-		limit = (limit * 3) / 2;
 	return atomic_read(&info->nr_async_bios) > limit;
 }
 
@@ -454,7 +451,7 @@ static void run_one_async_submit(struct btrfs_work *work)
 	atomic_dec(&fs_info->nr_async_submits);
 
 	if ((async->bio->bi_rw & (1 << BIO_RW)) &&
-	    !congested_async(fs_info, 1)) {
+	    !btrfs_congested_async(fs_info, 1)) {
 		clear_bdi_congested(&fs_info->bdi, WRITE);
 	}
 	async->submit_bio_hook(async->inode, async->rw, async->bio,
@@ -963,7 +960,7 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	struct backing_dev_info *bdi;
 
 	if ((bdi_bits & (1 << BDI_write_congested)) &&
-	    congested_async(info, 0))
+	    btrfs_congested_async(info, 0))
 		return 1;
 
 	list_for_each(cur, &info->fs_devices->devices) {
@@ -1844,7 +1841,7 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	struct extent_io_tree *tree;
 	u64 num_dirty;
 	u64 start = 0;
-	unsigned long thresh = 16 * 1024 * 1024;
+	unsigned long thresh = 2 * 1024 * 1024;
 	tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 
 	if (current_is_pdflush())

commit 0986fe9eac24fd186927c3b87af51d62f8ab92cd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 15 15:34:15 2008 -0400

    Btrfs: Count async bios separately from async checksum work items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 99bd9f9b9eed..9902d29abd06 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -429,6 +429,21 @@ int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 	return 0;
 }
 
+static int congested_async(struct btrfs_fs_info *info, int iodone)
+{
+	int limit = 256 * info->fs_devices->open_devices;
+
+	if (iodone)
+		limit = (limit * 3) / 2;
+	if (atomic_read(&info->nr_async_submits) > limit)
+		return 1;
+
+	limit = 8192 * info->fs_devices->open_devices;
+	if (iodone)
+		limit = (limit * 3) / 2;
+	return atomic_read(&info->nr_async_bios) > limit;
+}
+
 static void run_one_async_submit(struct btrfs_work *work)
 {
 	struct btrfs_fs_info *fs_info;
@@ -437,6 +452,11 @@ static void run_one_async_submit(struct btrfs_work *work)
 	async = container_of(work, struct  async_submit_bio, work);
 	fs_info = BTRFS_I(async->inode)->root->fs_info;
 	atomic_dec(&fs_info->nr_async_submits);
+
+	if ((async->bio->bi_rw & (1 << BIO_RW)) &&
+	    !congested_async(fs_info, 1)) {
+		clear_bdi_congested(&fs_info->bdi, WRITE);
+	}
 	async->submit_bio_hook(async->inode, async->rw, async->bio,
 			       async->mirror_num);
 	kfree(async);
@@ -938,15 +958,13 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 {
 	struct btrfs_fs_info *info = (struct btrfs_fs_info *)congested_data;
 	int ret = 0;
-	int limit = 256 * info->fs_devices->open_devices;
 	struct list_head *cur;
 	struct btrfs_device *device;
 	struct backing_dev_info *bdi;
 
 	if ((bdi_bits & (1 << BDI_write_congested)) &&
-	    atomic_read(&info->nr_async_submits) > limit) {
+	    congested_async(info, 0))
 		return 1;
-	}
 
 	list_for_each(cur, &info->fs_devices->devices) {
 		device = list_entry(cur, struct btrfs_device, dev_list);
@@ -1250,6 +1268,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	atomic_set(&fs_info->nr_async_submits, 0);
+	atomic_set(&fs_info->nr_async_bios, 0);
 	atomic_set(&fs_info->throttles, 0);
 	atomic_set(&fs_info->throttle_gen, 0);
 	fs_info->sb = sb;

commit b720d209524fccdd33a499351f2ca880b8c0ffb4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 15 15:34:14 2008 -0400

    Btrfs: Limit the number of async bio submission kthreads to the number of devices
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 56c54a41dbbb..99bd9f9b9eed 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1348,7 +1348,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 * cannot dynamically grow.
 	 */
 	btrfs_init_workers(&fs_info->workers, fs_info->thread_pool_size);
-	btrfs_init_workers(&fs_info->submit_workers, fs_info->thread_pool_size);
+	btrfs_init_workers(&fs_info->submit_workers,
+			   min_t(u64, fs_devices->num_devices,
+			   fs_info->thread_pool_size));
 
 	/* a higher idle thresh on the submit workers makes it much more
 	 * likely that bios will be send down in a sane order to the

commit 4ca8b41e3fe76cc5774fbcc6cba64259d69e0f96
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Aug 5 13:30:48 2008 -0400

    Btrfs: Avoid calling into the FS for the final iput on fake root inodes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 76543683f3b9..56c54a41dbbb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1739,6 +1739,7 @@ int close_ctree(struct btrfs_root *root)
 		free_extent_buffer(root->fs_info->dev_root->node);
 
 	btrfs_free_block_groups(root->fs_info);
+	fs_info->closing = 2;
 	del_fs_roots(fs_info);
 
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);

commit ea8c281947950fac5f78818b767821d696c9512a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Aug 4 23:17:27 2008 -0400

    Btrfs: Maintain a list of inodes that are delalloc and a way to wait on them
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index da9dda4338a3..76543683f3b9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1234,6 +1234,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->hashers);
+	INIT_LIST_HEAD(&fs_info->delalloc_inodes);
 	spin_lock_init(&fs_info->hash_lock);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);

commit 2dd3e67b1eaec8504da7e12b8afee77323a49f38
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Aug 4 08:20:15 2008 -0400

    Btrfs: More throttle tuning
    
    * Make walk_down_tree wake up throttled tasks more often
    * Make walk_down_tree call cond_resched during long loops
    * As the size of the ref cache grows, wait longer in throttle
    * Get rid of the reada code in walk_down_tree, the leaves don't get
      read anymore, thanks to the ref cache.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d2d1cc87e8ad..da9dda4338a3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -188,13 +188,6 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	btrfs_csum_final(crc, result);
 
 	if (verify) {
-		int from_this_trans = 0;
-
-		if (root->fs_info->running_transaction &&
-		    btrfs_header_generation(buf) ==
-		    root->fs_info->running_transaction->transid)
-			from_this_trans = 1;
-
 		/* FIXME, this is not good */
 		if (memcmp_extent_buffer(buf, result, 0, BTRFS_CRC32_SIZE)) {
 			u32 val;
@@ -203,11 +196,9 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 
 			read_extent_buffer(buf, &val, 0, BTRFS_CRC32_SIZE);
 			printk("btrfs: %s checksum verify failed on %llu "
-			       "wanted %X found %X from_this_trans %d "
-			       "level %d\n",
+			       "wanted %X found %X level %d\n",
 			       root->fs_info->sb->s_id,
-			       buf->start, val, found, from_this_trans,
-			       btrfs_header_level(buf));
+			       buf->start, val, found, btrfs_header_level(buf));
 			return 1;
 		}
 	} else {

commit 61b4944018449003ac5f9757f4d125dce519cf51
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 31 15:42:53 2008 -0400

    Btrfs: Fix streaming read performance with checksumming on
    
    Large streaming reads make for large bios, which means each entry on the
    list async work queues represents a large amount of data.  IO
    congestion throttling on the device was kicking in before the async
    worker threads decided a single thread was busy and needed some help.
    
    The end result was that a streaming read would result in a single CPU
    running at 100% instead of balancing the work off to other CPUs.
    
    This patch also changes the pre-IO checksum lookup done by reads to
    work on a per-bio basis instead of a per-page.  This results in many
    extra btree lookups on large streaming reads.  Doing the checksum lookup
    right before bio submit allows us to reuse searches while processing
    adjacent offsets.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e826730d750f..d2d1cc87e8ad 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1357,10 +1357,25 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 */
 	btrfs_init_workers(&fs_info->workers, fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->submit_workers, fs_info->thread_pool_size);
+
+	/* a higher idle thresh on the submit workers makes it much more
+	 * likely that bios will be send down in a sane order to the
+	 * devices
+	 */
+	fs_info->submit_workers.idle_thresh = 64;
+
 	btrfs_init_workers(&fs_info->fixup_workers, 1);
 	btrfs_init_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->endio_write_workers,
 			   fs_info->thread_pool_size);
+
+	/*
+	 * endios are largely parallel and should have a very
+	 * low idle thresh
+	 */
+	fs_info->endio_workers.idle_thresh = 4;
+	fs_info->endio_write_workers.idle_thresh = 4;
+
 	btrfs_start_workers(&fs_info->workers, 1);
 	btrfs_start_workers(&fs_info->submit_workers, 1);
 	btrfs_start_workers(&fs_info->fixup_workers, 1);

commit bcc63abbf3e9bf948a1b0129b3e6120ec7d7f698
Author: Yan <zheng.yan@oracle.com>
Date:   Wed Jul 30 16:29:20 2008 -0400

    Btrfs: implement memory reclaim for leaf reference cache
    
    The memory reclaiming issue happens when snapshot exists. In that
    case, some cache entries may not be used during old snapshot dropping,
    so they will remain in the cache until umount.
    
    The patch adds a field to struct btrfs_leaf_ref to record create time. Besides,
    the patch makes all dead roots of a given snapshot linked together in order of
    create time. After a old snapshot was completely dropped, we check the dead
    root list and remove all cache entries created before the oldest dead root in
    the list.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ec1ba8ddb35f..e826730d750f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -735,8 +735,9 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 
 	INIT_LIST_HEAD(&root->dirty_list);
 	INIT_LIST_HEAD(&root->orphan_list);
+	INIT_LIST_HEAD(&root->dead_list);
 	spin_lock_init(&root->node_lock);
-	spin_lock_init(&root->orphan_lock);
+	spin_lock_init(&root->list_lock);
 	mutex_init(&root->objectid_mutex);
 
 	btrfs_leaf_ref_tree_init(&root->ref_tree_struct);
@@ -1717,7 +1718,7 @@ int close_ctree(struct btrfs_root *root)
 		printk("btrfs: at umount reference cache size %Lu\n",
 			fs_info->total_ref_cache_size);
 	}
-	
+
 	if (fs_info->extent_root->node)
 		free_extent_buffer(fs_info->extent_root->node);
 

commit 33958dc6d38fb4ca7e62273855fcb2db7e616263
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jul 30 10:29:12 2008 -0400

    Btrfs: Fix verify_parent_transid
    
    It was incorrectly clearing the up to date flag on the buffer even
    when the buffer properly verified.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 27ffa9b7ddc8..ec1ba8ddb35f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -235,8 +235,8 @@ static int verify_parent_transid(struct extent_io_tree *io_tree,
 	       (unsigned long long)parent_transid,
 	       (unsigned long long)btrfs_header_generation(eb));
 	ret = 1;
-out:
 	clear_extent_buffer_uptodate(io_tree, eb);
+out:
 	unlock_extent(io_tree, eb->start, eb->start + eb->len - 1,
 		      GFP_NOFS);
 	return ret;

commit ab78c84de1ce4db1b2a2cef361625ad80abbab3f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 29 16:15:18 2008 -0400

    Btrfs: Throttle operations if the reference cache gets too large
    
    A large reference cache is directly related to a lot of work pending
    for the cleaner thread.  This throttles back new operations based on
    the size of the reference cache so the cleaner thread will be able to keep
    up.
    
    Overall, this actually makes the FS faster because the cleaner thread will
    be more likely to find things in cache.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eccdf13a95ac..27ffa9b7ddc8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1171,8 +1171,10 @@ static int transaction_kthread(void *arg)
 		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
 		mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
-		printk("btrfs: total reference cache size %Lu\n",
-			root->fs_info->total_ref_cache_size);
+		if (root->fs_info->total_ref_cache_size > 20 * 1024 * 1024) {
+			printk("btrfs: total reference cache size %Lu\n",
+				root->fs_info->total_ref_cache_size);
+		}
 
 		mutex_lock(&root->fs_info->trans_mutex);
 		cur = root->fs_info->running_transaction;
@@ -1256,6 +1258,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	atomic_set(&fs_info->nr_async_submits, 0);
 	atomic_set(&fs_info->throttles, 0);
+	atomic_set(&fs_info->throttle_gen, 0);
 	fs_info->sb = sb;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;

commit 017e5369eb353559d68a11d4a718faa634533821
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jul 28 15:32:51 2008 -0400

    Btrfs: Leaf reference cache update
    
    This changes the reference cache to make a single cache per root
    instead of one cache per transaction, and to key by the byte number
    of the disk block instead of the keys inside.
    
    This makes it much less likely to have cache misses if a snapshot
    or something has an extra reference on a higher node or a leaf while
    the first transaction that added the leaf into the cache is dropping.
    
    Some throttling is added to functions that free blocks heavily so they
    wait for old transactions to drop.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4f0e1d06c384..eccdf13a95ac 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -40,6 +40,7 @@
 #include "print-tree.h"
 #include "async-thread.h"
 #include "locking.h"
+#include "ref-cache.h"
 
 #if 0
 static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
@@ -737,6 +738,10 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	spin_lock_init(&root->node_lock);
 	spin_lock_init(&root->orphan_lock);
 	mutex_init(&root->objectid_mutex);
+
+	btrfs_leaf_ref_tree_init(&root->ref_tree_struct);
+	root->ref_tree = &root->ref_tree_struct;
+
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
@@ -1176,9 +1181,6 @@ static int transaction_kthread(void *arg)
 			goto sleep;
 		}
 
-		printk("btrfs: running reference cache size %Lu\n",
-			root->fs_info->running_ref_cache_size);
-
 		now = get_seconds();
 		if (now < cur->start_time || now - cur->start_time < 30) {
 			mutex_unlock(&root->fs_info->trans_mutex);

commit 31153d81284934601d08110ac7698fd9a535e4c0
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Mon Jul 28 15:32:19 2008 -0400

    Btrfs: Add a leaf reference cache
    
    Much of the IO done while dropping snapshots is done looking up
    leaves in the filesystem trees to see if they point to any extents and
    to drop the references on any extents found.
    
    This creates a cache so that IO isn't required.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d60923967347..4f0e1d06c384 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -716,6 +716,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->node = NULL;
 	root->inode = NULL;
 	root->commit_root = NULL;
+	root->ref_tree = NULL;
 	root->sectorsize = sectorsize;
 	root->nodesize = nodesize;
 	root->leafsize = leafsize;
@@ -1165,12 +1166,19 @@ static int transaction_kthread(void *arg)
 		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
 		mutex_lock(&root->fs_info->transaction_kthread_mutex);
 
+		printk("btrfs: total reference cache size %Lu\n",
+			root->fs_info->total_ref_cache_size);
+
 		mutex_lock(&root->fs_info->trans_mutex);
 		cur = root->fs_info->running_transaction;
 		if (!cur) {
 			mutex_unlock(&root->fs_info->trans_mutex);
 			goto sleep;
 		}
+
+		printk("btrfs: running reference cache size %Lu\n",
+			root->fs_info->running_ref_cache_size);
+
 		now = get_seconds();
 		if (now < cur->start_time || now - cur->start_time < 30) {
 			mutex_unlock(&root->fs_info->trans_mutex);
@@ -1233,6 +1241,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->hash_lock);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);
+	spin_lock_init(&fs_info->ref_cache_lock);
 
 	init_completion(&fs_info->kobj_unregister);
 	fs_info->tree_root = tree_root;
@@ -1699,6 +1708,11 @@ int close_ctree(struct btrfs_root *root)
 		printk("btrfs: at unmount delalloc count %Lu\n",
 		       fs_info->delalloc_bytes);
 	}
+	if (fs_info->total_ref_cache_size) {
+		printk("btrfs: at umount reference cache size %Lu\n",
+			fs_info->total_ref_cache_size);
+	}
+	
 	if (fs_info->extent_root->node)
 		free_extent_buffer(fs_info->extent_root->node);
 

commit 7b1287662304c3cb05cb38f5e3e2d69f386e8f10
Author: Josef Bacik <jbacik@redhat.com>
Date:   Thu Jul 24 12:17:14 2008 -0400

    Btrfs: Create orphan inode records to prevent lost files after a crash
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ec01062eb41d..d60923967347 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -732,7 +732,9 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->in_sysfs = 0;
 
 	INIT_LIST_HEAD(&root->dirty_list);
+	INIT_LIST_HEAD(&root->orphan_list);
 	spin_lock_init(&root->node_lock);
+	spin_lock_init(&root->orphan_lock);
 	mutex_init(&root->objectid_mutex);
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));

commit 3eaa2885276fd6dac7b076a793932428b7168e74
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 24 11:57:52 2008 -0400

    Btrfs: Fix the defragmention code and the block relocation code for data=ordered
    
    Before setting an extent to delalloc, the code needs to wait for
    pending ordered extents.
    
    Also, the relocation code needs to wait for ordered IO before scanning
    the block group again.  This is because the extents are not removed
    until the IO for the new extents is finished
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7ce3f83c5dd6..ec01062eb41d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1252,6 +1252,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode->i_nlink = 1;
 	fs_info->thread_pool_size = min(num_online_cpus() + 2, 8);
 
+	INIT_LIST_HEAD(&fs_info->ordered_extents);
+	spin_lock_init(&fs_info->ordered_extent_lock);
+
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
 

commit 89642229a582a5c2b6d2ed8ec16986387d9a9047
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 24 09:41:53 2008 -0400

    Btrfs: Search data ordered extents first for checksums on read
    
    Checksum items are not inserted into the tree until all of the io from a
    given extent is complete.  This means one dirty page from an extent may
    be written, freed, and then read again before the entire extent is on disk
    and the checksum item is inserted.
    
    The checksums themselves are stored in the ordered extent so they can
    be inserted in bulk when IO is complete.  On read, if a checksum item isn't
    found, the ordered extents were being searched for a checksum record.
    
    This all worked most of the time, but the checksum insertion code tries
    to reduce the number of tree operations by pre-inserting checksum items
    based on i_size and a few other factors.  This means the read code might
    find a checksum item that hasn't yet really been filled in.
    
    This commit changes things to check the ordered extents first and only
    dive into the btree if nothing was found.  This removes the need for
    extra locking and is more reliable.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 86e84a8579e3..7ce3f83c5dd6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1011,9 +1011,16 @@ void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 	spin_lock(&em_tree->lock);
 	em = lookup_extent_mapping(em_tree, offset, PAGE_CACHE_SIZE);
 	spin_unlock(&em_tree->lock);
-	if (!em)
+	if (!em) {
+		__unplug_io_fn(bdi, page);
 		return;
+	}
 
+	if (em->block_start >= EXTENT_MAP_LAST_BYTE) {
+		free_extent_map(em);
+		__unplug_io_fn(bdi, page);
+		return;
+	}
 	offset = offset - em->start;
 	btrfs_unplug_page(&BTRFS_I(inode)->root->fs_info->mapping_tree,
 			  em->block_start + offset, page);

commit 6af118ce51b52ceda357c671550c79628b9c4a65
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 22 11:18:07 2008 -0400

    Btrfs: Index extent buffers in an rbtree
    
    Before, extent buffers were a temporary object, meant to map a number of pages
    at once and collect operations on them.
    
    But, a few extra fields have crept in, and they are also the best place to
    store a per-tree block lock field as well.  This commit puts the extent
    buffers into an rbtree, and ensures a single extent buffer for each
    tree block.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 99bb385c2982..86e84a8579e3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -381,7 +381,6 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 
 	end = min_t(u64, eb->len, PAGE_CACHE_SIZE);
 	end = eb->start + end - 1;
-	release_extent_buffer_tail_pages(eb);
 err:
 	free_extent_buffer(eb);
 out:
@@ -563,21 +562,21 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	struct extent_map_tree *map;
 	int ret;
 
-	if (page_count(page) > 3) {
-		/* once for page->private, once for the caller, once
-		 * once for the page cache
-		 */
-		return 0;
-	}
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
+
 	ret = try_release_extent_state(map, tree, page, gfp_flags);
+	if (!ret) {
+		return 0;
+	}
+
+	ret = try_release_extent_buffer(tree, page);
 	if (ret == 1) {
-		invalidate_extent_lru(tree, page_offset(page), PAGE_CACHE_SIZE);
 		ClearPagePrivate(page);
 		set_page_private(page, 0);
 		page_cache_release(page);
 	}
+
 	return ret;
 }
 
@@ -588,7 +587,8 @@ static void btree_invalidatepage(struct page *page, unsigned long offset)
 	extent_invalidatepage(tree, page, offset);
 	btree_releasepage(page, GFP_NOFS);
 	if (PagePrivate(page)) {
-		invalidate_extent_lru(tree, page_offset(page), PAGE_CACHE_SIZE);
+		printk("warning page private not zero on page %Lu\n",
+		       page_offset(page));
 		ClearPagePrivate(page);
 		set_page_private(page, 0);
 		page_cache_release(page);
@@ -1456,7 +1456,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	free_extent_buffer(tree_root->node);
 fail_sys_array:
 fail_sb_buffer:
-	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
@@ -1705,13 +1704,6 @@ int close_ctree(struct btrfs_root *root)
 
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
 
-	extent_io_tree_empty_lru(&fs_info->free_space_cache);
-	extent_io_tree_empty_lru(&fs_info->block_group_cache);
-	extent_io_tree_empty_lru(&fs_info->pinned_extents);
-	extent_io_tree_empty_lru(&fs_info->pending_del);
-	extent_io_tree_empty_lru(&fs_info->extent_ins);
-	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
-
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 
 	btrfs_stop_workers(&fs_info->fixup_workers);

commit f9295749388f82c8d2f485e99c72cd7c7876a99b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:54:14 2008 -0400

    btrfs_start_transaction: wait for commits in progress to finish
    
    btrfs_commit_transaction has to loop waiting for any writers in the
    transaction to finish before it can proceed.  btrfs_start_transaction
    should be polite and not join a transaction that is in the process
    of being finished off.
    
    There are a few places that can't wait, basically the ones doing IO that
    might be needed to finish the transaction.  For them, btrfs_join_transaction
    is added.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 66466d125c05..99bb385c2982 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1291,6 +1291,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->cleaner_mutex);
 	mutex_init(&fs_info->volume_mutex);
 	init_waitqueue_head(&fs_info->transaction_throttle);
+	init_waitqueue_head(&fs_info->transaction_wait);
 
 #if 0
 	ret = add_hasher(fs_info, "crc32c");

commit 247e743cbe6e655768c3679f84821e03c1577902
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:53:51 2008 -0400

    Btrfs: Use async helpers to deal with pages that have been improperly dirtied
    
    Higher layers sometimes call set_page_dirty without asking the filesystem
    to help.  This causes many problems for the data=ordered and cow code.
    This commit detects pages that haven't been properly setup for IO and
    kicks off an async helper to deal with them.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4a5ebafb935a..66466d125c05 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1329,11 +1329,13 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 */
 	btrfs_init_workers(&fs_info->workers, fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->submit_workers, fs_info->thread_pool_size);
+	btrfs_init_workers(&fs_info->fixup_workers, 1);
 	btrfs_init_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->endio_write_workers,
 			   fs_info->thread_pool_size);
 	btrfs_start_workers(&fs_info->workers, 1);
 	btrfs_start_workers(&fs_info->submit_workers, 1);
+	btrfs_start_workers(&fs_info->fixup_workers, 1);
 	btrfs_start_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
 	btrfs_start_workers(&fs_info->endio_write_workers,
 			    fs_info->thread_pool_size);
@@ -1454,6 +1456,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail_sys_array:
 fail_sb_buffer:
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
+	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);
@@ -1710,6 +1713,7 @@ int close_ctree(struct btrfs_root *root)
 
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 
+	btrfs_stop_workers(&fs_info->fixup_workers);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
 	btrfs_stop_workers(&fs_info->endio_write_workers);

commit e6dcd2dc9c489108648e2ed543315dd134d50a9a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:53:50 2008 -0400

    Btrfs: New data=ordered implementation
    
    The old data=ordered code would force commit to wait until
    all the data extents from the transaction were fully on disk.  This
    introduced large latencies into the commit and stalled new writers
    in the transaction for a long time.
    
    The new code changes the way data allocations and extents work:
    
    * When delayed allocation is filled, data extents are reserved, and
      the extent bit EXTENT_ORDERED is set on the entire range of the extent.
      A struct btrfs_ordered_extent is allocated an inserted into a per-inode
      rbtree to track the pending extents.
    
    * As each page is written EXTENT_ORDERED is cleared on the bytes corresponding
      to that page.
    
    * When all of the bytes corresponding to a single struct btrfs_ordered_extent
      are written, The previously reserved extent is inserted into the FS
      btree and into the extent allocation trees.  The checksums for the file
      data are also updated.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b01b3f4f92a9..4a5ebafb935a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -407,7 +407,11 @@ static int end_workqueue_bio(struct bio *bio,
 	end_io_wq->error = err;
 	end_io_wq->work.func = end_workqueue_fn;
 	end_io_wq->work.flags = 0;
-	btrfs_queue_worker(&fs_info->endio_workers, &end_io_wq->work);
+	if (bio->bi_rw & (1 << BIO_RW))
+		btrfs_queue_worker(&fs_info->endio_write_workers,
+				   &end_io_wq->work);
+	else
+		btrfs_queue_worker(&fs_info->endio_workers, &end_io_wq->work);
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
 	return 0;
@@ -1286,6 +1290,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->transaction_kthread_mutex);
 	mutex_init(&fs_info->cleaner_mutex);
 	mutex_init(&fs_info->volume_mutex);
+	init_waitqueue_head(&fs_info->transaction_throttle);
 
 #if 0
 	ret = add_hasher(fs_info, "crc32c");
@@ -1325,9 +1330,13 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_init_workers(&fs_info->workers, fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->submit_workers, fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
+	btrfs_init_workers(&fs_info->endio_write_workers,
+			   fs_info->thread_pool_size);
 	btrfs_start_workers(&fs_info->workers, 1);
 	btrfs_start_workers(&fs_info->submit_workers, 1);
 	btrfs_start_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
+	btrfs_start_workers(&fs_info->endio_write_workers,
+			    fs_info->thread_pool_size);
 
 	err = -EINVAL;
 	if (btrfs_super_num_devices(disk_super) > fs_devices->open_devices) {
@@ -1447,6 +1456,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
+	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
 fail_iput:
 	iput(fs_info->btree_inode);
@@ -1702,6 +1712,7 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
+	btrfs_stop_workers(&fs_info->endio_write_workers);
 	btrfs_stop_workers(&fs_info->submit_workers);
 
 	iput(fs_info->btree_inode);

commit 77a41afb7d0dd0f27b6f2f1a5bc701929c7034de
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 8 14:32:12 2008 -0400

    Btrfs: Drop some verbose printks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8f4c40033e92..b01b3f4f92a9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1117,9 +1117,7 @@ static int cleaner_kthread(void *arg)
 
 		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
 		mutex_lock(&root->fs_info->cleaner_mutex);
-printk("cleaner awake\n");
 		btrfs_clean_old_snapshots(root);
-printk("cleaner done\n");
 		mutex_unlock(&root->fs_info->cleaner_mutex);
 
 		if (freezing(current)) {

commit 7d9eb12c8739e7dc80c78c6b3596f912ecd8f941
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 8 14:19:17 2008 -0400

    Btrfs: Add locking around volume management (device add/remove/balance)
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4cdc0b6a2672..8f4c40033e92 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1287,6 +1287,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->chunk_mutex);
 	mutex_init(&fs_info->transaction_kthread_mutex);
 	mutex_init(&fs_info->cleaner_mutex);
+	mutex_init(&fs_info->volume_mutex);
 
 #if 0
 	ret = add_hasher(fs_info, "crc32c");

commit 3f157a2fd2ad731e1ed9964fecdc5f459f04a4a4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Online btree defragmentation fixes
    
    The btree defragger wasn't making forward progress because the new key wasn't
    being saved by the btrfs_search_forward function.
    
    This also disables the automatic btree defrag, it wasn't scaling well to
    huge filesystems.  The auto-defrag needs to be done differently.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 31ca9f89388d..4cdc0b6a2672 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -295,7 +295,6 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	ret = btree_read_extent_buffer_pages(root, eb, start + PAGE_CACHE_SIZE,
 					     btrfs_header_generation(eb));
 	BUG_ON(ret);
-	btrfs_clear_buffer_defrag(eb);
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
 		printk("warning: eb start incorrect %Lu buffer %Lu len %lu\n",
@@ -355,7 +354,6 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	}
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
 
-	btrfs_clear_buffer_defrag(eb);
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
 		ret = -EIO;
@@ -736,6 +734,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
 	memset(&root->root_kobj, 0, sizeof(root->root_kobj));
+	root->defrag_trans_start = fs_info->generation;
 	init_completion(&root->kobj_unregister);
 	root->defrag_running = 0;
 	root->defrag_level = 0;
@@ -1168,7 +1167,6 @@ static int transaction_kthread(void *arg)
 			goto sleep;
 		}
 		mutex_unlock(&root->fs_info->trans_mutex);
-		btrfs_defrag_dirty_roots(root->fs_info);
 		trans = btrfs_start_transaction(root, 1);
 		ret = btrfs_commit_transaction(trans, root);
 sleep:
@@ -1434,12 +1432,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 						   tree_root,
 						   "btrfs-transaction");
 	if (!fs_info->transaction_kthread)
-		goto fail_trans_kthread;
+		goto fail_cleaner;
 
 
 	return tree_root;
 
-fail_trans_kthread:
+fail_cleaner:
 	kthread_stop(fs_info->cleaner_kthread);
 fail_extent_root:
 	free_extent_buffer(extent_root->node);
@@ -1662,7 +1660,6 @@ int close_ctree(struct btrfs_root *root)
 	kthread_stop(root->fs_info->transaction_kthread);
 	kthread_stop(root->fs_info->cleaner_kthread);
 
-	btrfs_defrag_dirty_roots(root->fs_info);
 	btrfs_clean_old_snapshots(root);
 	trans = btrfs_start_transaction(root, 1);
 	ret = btrfs_commit_transaction(trans, root);
@@ -1794,58 +1791,6 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	return;
 }
 
-void btrfs_set_buffer_defrag(struct extent_buffer *buf)
-{
-	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	set_extent_bits(&BTRFS_I(btree_inode)->io_tree, buf->start,
-			buf->start + buf->len - 1, EXTENT_DEFRAG, GFP_NOFS);
-}
-
-void btrfs_set_buffer_defrag_done(struct extent_buffer *buf)
-{
-	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	set_extent_bits(&BTRFS_I(btree_inode)->io_tree, buf->start,
-			buf->start + buf->len - 1, EXTENT_DEFRAG_DONE,
-			GFP_NOFS);
-}
-
-int btrfs_buffer_defrag(struct extent_buffer *buf)
-{
-	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	return test_range_bit(&BTRFS_I(btree_inode)->io_tree,
-		     buf->start, buf->start + buf->len - 1, EXTENT_DEFRAG, 0);
-}
-
-int btrfs_buffer_defrag_done(struct extent_buffer *buf)
-{
-	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	return test_range_bit(&BTRFS_I(btree_inode)->io_tree,
-		     buf->start, buf->start + buf->len - 1,
-		     EXTENT_DEFRAG_DONE, 0);
-}
-
-int btrfs_clear_buffer_defrag_done(struct extent_buffer *buf)
-{
-	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	return clear_extent_bits(&BTRFS_I(btree_inode)->io_tree,
-		     buf->start, buf->start + buf->len - 1,
-		     EXTENT_DEFRAG_DONE, GFP_NOFS);
-}
-
-int btrfs_clear_buffer_defrag(struct extent_buffer *buf)
-{
-	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	return clear_extent_bits(&BTRFS_I(btree_inode)->io_tree,
-		     buf->start, buf->start + buf->len - 1,
-		     EXTENT_DEFRAG, GFP_NOFS);
-}
-
 int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;

commit a74a4b97b61beede185b4b3ad359d7d378b0d312
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Replace the transaction work queue with kthreads
    
    This creates one kthread for commits and one kthread for
    deleting old snapshots.  All the work queues are removed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 52569b57692d..31ca9f89388d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -16,6 +16,7 @@
  * Boston, MA 021110-1307, USA.
  */
 
+#include <linux/version.h>
 #include <linux/fs.h>
 #include <linux/blkdev.h>
 #include <linux/scatterlist.h>
@@ -24,6 +25,12 @@
 #include <linux/writeback.h>
 #include <linux/buffer_head.h> // for block_sync_page
 #include <linux/workqueue.h>
+#include <linux/kthread.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,20)
+# include <linux/freezer.h>
+#else
+# include <linux/sched.h>
+#endif
 #include "crc32c.h"
 #include "ctree.h"
 #include "disk-io.h"
@@ -1100,6 +1107,87 @@ static void end_workqueue_fn(struct btrfs_work *work)
 #endif
 }
 
+static int cleaner_kthread(void *arg)
+{
+	struct btrfs_root *root = arg;
+
+	do {
+		smp_mb();
+		if (root->fs_info->closing)
+			break;
+
+		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
+		mutex_lock(&root->fs_info->cleaner_mutex);
+printk("cleaner awake\n");
+		btrfs_clean_old_snapshots(root);
+printk("cleaner done\n");
+		mutex_unlock(&root->fs_info->cleaner_mutex);
+
+		if (freezing(current)) {
+			refrigerator();
+		} else {
+			smp_mb();
+			if (root->fs_info->closing)
+				break;
+			set_current_state(TASK_INTERRUPTIBLE);
+			schedule();
+			__set_current_state(TASK_RUNNING);
+		}
+	} while (!kthread_should_stop());
+	return 0;
+}
+
+static int transaction_kthread(void *arg)
+{
+	struct btrfs_root *root = arg;
+	struct btrfs_trans_handle *trans;
+	struct btrfs_transaction *cur;
+	unsigned long now;
+	unsigned long delay;
+	int ret;
+
+	do {
+		smp_mb();
+		if (root->fs_info->closing)
+			break;
+
+		delay = HZ * 30;
+		vfs_check_frozen(root->fs_info->sb, SB_FREEZE_WRITE);
+		mutex_lock(&root->fs_info->transaction_kthread_mutex);
+
+		mutex_lock(&root->fs_info->trans_mutex);
+		cur = root->fs_info->running_transaction;
+		if (!cur) {
+			mutex_unlock(&root->fs_info->trans_mutex);
+			goto sleep;
+		}
+		now = get_seconds();
+		if (now < cur->start_time || now - cur->start_time < 30) {
+			mutex_unlock(&root->fs_info->trans_mutex);
+			delay = HZ * 5;
+			goto sleep;
+		}
+		mutex_unlock(&root->fs_info->trans_mutex);
+		btrfs_defrag_dirty_roots(root->fs_info);
+		trans = btrfs_start_transaction(root, 1);
+		ret = btrfs_commit_transaction(trans, root);
+sleep:
+		wake_up_process(root->fs_info->cleaner_kthread);
+		mutex_unlock(&root->fs_info->transaction_kthread_mutex);
+
+		if (freezing(current)) {
+			refrigerator();
+		} else {
+			if (root->fs_info->closing)
+				break;
+			set_current_state(TASK_INTERRUPTIBLE);
+			schedule_timeout(delay);
+			__set_current_state(TASK_RUNNING);
+		}
+	} while (!kthread_should_stop());
+	return 0;
+}
+
 struct btrfs_root *open_ctree(struct super_block *sb,
 			      struct btrfs_fs_devices *fs_devices,
 			      char *options)
@@ -1189,11 +1277,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);
-#else
-	INIT_DELAYED_WORK(&fs_info->trans_work, btrfs_transaction_cleaner);
-#endif
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));
@@ -1204,6 +1287,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->drop_mutex);
 	mutex_init(&fs_info->alloc_mutex);
 	mutex_init(&fs_info->chunk_mutex);
+	mutex_init(&fs_info->transaction_kthread_mutex);
+	mutex_init(&fs_info->cleaner_mutex);
 
 #if 0
 	ret = add_hasher(fs_info, "crc32c");
@@ -1247,7 +1332,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_start_workers(&fs_info->submit_workers, 1);
 	btrfs_start_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
 
-
 	err = -EINVAL;
 	if (btrfs_super_num_devices(disk_super) > fs_devices->open_devices) {
 		printk("Btrfs: wanted %llu devices, but found %llu\n",
@@ -1341,9 +1425,22 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->data_alloc_profile = (u64)-1;
 	fs_info->metadata_alloc_profile = (u64)-1;
 	fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
+	fs_info->cleaner_kthread = kthread_run(cleaner_kthread, tree_root,
+					       "btrfs-cleaner");
+	if (!fs_info->cleaner_kthread)
+		goto fail_extent_root;
+
+	fs_info->transaction_kthread = kthread_run(transaction_kthread,
+						   tree_root,
+						   "btrfs-transaction");
+	if (!fs_info->transaction_kthread)
+		goto fail_trans_kthread;
+
 
 	return tree_root;
 
+fail_trans_kthread:
+	kthread_stop(fs_info->cleaner_kthread);
 fail_extent_root:
 	free_extent_buffer(extent_root->node);
 fail_tree_root:
@@ -1562,8 +1659,11 @@ int close_ctree(struct btrfs_root *root)
 	fs_info->closing = 1;
 	smp_mb();
 
-	btrfs_transaction_flush_work(root);
+	kthread_stop(root->fs_info->transaction_kthread);
+	kthread_stop(root->fs_info->cleaner_kthread);
+
 	btrfs_defrag_dirty_roots(root->fs_info);
+	btrfs_clean_old_snapshots(root);
 	trans = btrfs_start_transaction(root, 1);
 	ret = btrfs_commit_transaction(trans, root);
 	/* run commit again to  drop the original snapshot */
@@ -1574,8 +1674,6 @@ int close_ctree(struct btrfs_root *root)
 
 	write_ctree_super(NULL, root);
 
-	btrfs_transaction_flush_work(root);
-
 	if (fs_info->delalloc_bytes) {
 		printk("btrfs: at unmount delalloc count %Lu\n",
 		       fs_info->delalloc_bytes);

commit 89ce8a63d0c761fbb02089850605360f389477d8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Add btrfs_end_transaction_throttle to force writers to wait for pending commits
    
    The existing throttle mechanism was often not sufficient to prevent
    new writers from coming in and making a given transaction run forever.
    This adds an explicit wait at the end of most operations so they will
    allow the current transaction to close.
    
    There is no wait inside file_write, inode updates, or cow filling, all which
    have different deadlock possibilities.
    
    This is a temporary measure until better asynchronous commit support is
    added.  This code leads to stalls as it waits for data=ordered
    writeback, and it really needs to be fixed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3cc480b83819..52569b57692d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1672,24 +1672,6 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree, buf);
 }
 
-void btrfs_throttle(struct btrfs_root *root)
-{
-#if 0
-	struct backing_dev_info *bdi;
-
-	bdi = &root->fs_info->bdi;
-	if (atomic_read(&root->fs_info->throttles) &&
-	    bdi_write_congested(bdi)) {
-#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,18)
-		congestion_wait(WRITE, HZ/20);
-#else
-		blk_congestion_wait(WRITE, HZ/20);
-#endif
-
-	}
-#endif
-}
-
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 {
 	/*

commit 333db94cdde9e6dfdedab9290d04d812f83e0922
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Btrfs: Fix snapshot deletion to release the alloc_mutex much more often.
    
    This lowers the impact of snapshot deletion on the rest of the FS.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ffc363d2fb24..3cc480b83819 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1674,6 +1674,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 
 void btrfs_throttle(struct btrfs_root *root)
 {
+#if 0
 	struct backing_dev_info *bdi;
 
 	bdi = &root->fs_info->bdi;
@@ -1686,6 +1687,7 @@ void btrfs_throttle(struct btrfs_root *root)
 #endif
 
 	}
+#endif
 }
 
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)

commit 051e1b9f748ae673b7325d3fc049bb838606cffa
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Drop locks in btrfs_search_slot when reading a tree block.
    
    One lock per btree block can make for significant congestion if everyone
    has to wait for IO at the high levels of the btree.  This drops
    locks held by a path when doing reads during a tree search.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f638803549e0..ffc363d2fb24 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1684,6 +1684,7 @@ void btrfs_throttle(struct btrfs_root *root)
 #else
 		blk_congestion_wait(WRITE, HZ/20);
 #endif
+
 	}
 }
 

commit a213501153fd66e2359e091b1612841305ba6551
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Btrfs: Replace the big fs_mutex with a collection of other locks
    
    Extent alloctions are still protected by a large alloc_mutex.
    Objectid allocations are covered by a objectid mutex
    Other btree operations are protected by a lock on individual btree nodes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fe40bdd984ff..f638803549e0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -724,6 +724,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 
 	INIT_LIST_HEAD(&root->dirty_list);
 	spin_lock_init(&root->node_lock);
+	mutex_init(&root->objectid_mutex);
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
@@ -1146,6 +1147,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	atomic_set(&fs_info->nr_async_submits, 0);
+	atomic_set(&fs_info->throttles, 0);
 	fs_info->sb = sb;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
@@ -1199,7 +1201,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 
 	mutex_init(&fs_info->trans_mutex);
-	mutex_init(&fs_info->fs_mutex);
+	mutex_init(&fs_info->drop_mutex);
 	mutex_init(&fs_info->alloc_mutex);
 	mutex_init(&fs_info->chunk_mutex);
 
@@ -1278,8 +1280,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		goto fail_sb_buffer;
 	}
 
-	mutex_lock(&fs_info->fs_mutex);
-
 	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_sys_array(tree_root);
 	mutex_unlock(&fs_info->chunk_mutex);
@@ -1342,7 +1342,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->metadata_alloc_profile = (u64)-1;
 	fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
 
-	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
 
 fail_extent_root:
@@ -1350,7 +1349,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail_tree_root:
 	free_extent_buffer(tree_root->node);
 fail_sys_array:
-	mutex_unlock(&fs_info->fs_mutex);
 fail_sb_buffer:
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 	btrfs_stop_workers(&fs_info->workers);
@@ -1562,8 +1560,9 @@ int close_ctree(struct btrfs_root *root)
 	struct btrfs_fs_info *fs_info = root->fs_info;
 
 	fs_info->closing = 1;
+	smp_mb();
+
 	btrfs_transaction_flush_work(root);
-	mutex_lock(&fs_info->fs_mutex);
 	btrfs_defrag_dirty_roots(root->fs_info);
 	trans = btrfs_start_transaction(root, 1);
 	ret = btrfs_commit_transaction(trans, root);
@@ -1574,7 +1573,6 @@ int close_ctree(struct btrfs_root *root)
 	BUG_ON(ret);
 
 	write_ctree_super(NULL, root);
-	mutex_unlock(&fs_info->fs_mutex);
 
 	btrfs_transaction_flush_work(root);
 
@@ -1679,7 +1677,8 @@ void btrfs_throttle(struct btrfs_root *root)
 	struct backing_dev_info *bdi;
 
 	bdi = &root->fs_info->bdi;
-	if (root->fs_info->throttles && bdi_write_congested(bdi)) {
+	if (atomic_read(&root->fs_info->throttles) &&
+	    bdi_write_congested(bdi)) {
 #if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,18)
 		congestion_wait(WRITE, HZ/20);
 #else

commit 925baeddc5b0764a53f2214a1253251bab0e0324
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:30 2008 -0400

    Btrfs: Start btree concurrency work.
    
    The allocation trees and the chunk trees are serialized via their own
    dedicated mutexes.  This means allocation location is still not very
    fine grained.
    
    The main FS btree is protected by locks on each block in the btree.  Locks
    are taken top / down, and as processing finishes on a given level of the
    tree, the lock is released after locking the lower level.
    
    The end result of a search is now a path where only the lowest level
    is locked.  Releasing or freeing the path drops any locks held.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e5c758e306d5..fe40bdd984ff 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -32,6 +32,7 @@
 #include "volumes.h"
 #include "print-tree.h"
 #include "async-thread.h"
+#include "locking.h"
 
 #if 0
 static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
@@ -681,9 +682,11 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	if (btrfs_header_generation(buf) ==
-	    root->fs_info->running_transaction->transid)
+	    root->fs_info->running_transaction->transid) {
+		WARN_ON(!btrfs_tree_locked(buf));
 		clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree,
 					  buf);
+	}
 	return 0;
 }
 
@@ -720,6 +723,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->in_sysfs = 0;
 
 	INIT_LIST_HEAD(&root->dirty_list);
+	spin_lock_init(&root->node_lock);
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
@@ -1196,6 +1200,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
+	mutex_init(&fs_info->alloc_mutex);
+	mutex_init(&fs_info->chunk_mutex);
 
 #if 0
 	ret = add_hasher(fs_info, "crc32c");
@@ -1274,7 +1280,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	mutex_lock(&fs_info->fs_mutex);
 
+	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_sys_array(tree_root);
+	mutex_unlock(&fs_info->chunk_mutex);
 	if (ret) {
 		printk("btrfs: failed to read the system array on %s\n",
 		       sb->s_id);
@@ -1296,7 +1304,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	         (unsigned long)btrfs_header_chunk_tree_uuid(chunk_root->node),
 		 BTRFS_UUID_SIZE);
 
+	mutex_lock(&fs_info->chunk_mutex);
 	ret = btrfs_read_chunk_tree(chunk_root);
+	mutex_unlock(&fs_info->chunk_mutex);
 	BUG_ON(ret);
 
 	btrfs_close_extra_devices(fs_devices);
@@ -1654,6 +1664,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	u64 transid = btrfs_header_generation(buf);
 	struct inode *btree_inode = root->fs_info->btree_inode;
 
+	WARN_ON(!btrfs_tree_locked(buf));
 	if (transid != root->fs_info->generation) {
 		printk(KERN_CRIT "transid mismatch buffer %llu, found %Lu running %Lu\n",
 			(unsigned long long)buf->start,

commit 1cc127b5d1b71453091859301de4a7dd6ee96fa8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jun 12 14:46:17 2008 -0400

    Btrfs: Add a thread pool just for submit_bio
    
    If a bio submission is after a lock holder waiting for the bio
    on the work queue, it is possible to deadlock.  Move the bios
    into their own pool.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c6a710a668cb..e5c758e306d5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1233,8 +1233,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	 * cannot dynamically grow.
 	 */
 	btrfs_init_workers(&fs_info->workers, fs_info->thread_pool_size);
+	btrfs_init_workers(&fs_info->submit_workers, fs_info->thread_pool_size);
 	btrfs_init_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
 	btrfs_start_workers(&fs_info->workers, 1);
+	btrfs_start_workers(&fs_info->submit_workers, 1);
 	btrfs_start_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
 
 
@@ -1343,6 +1345,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
+	btrfs_stop_workers(&fs_info->submit_workers);
 fail_iput:
 	iput(fs_info->btree_inode);
 fail:
@@ -1597,6 +1600,7 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
+	btrfs_stop_workers(&fs_info->submit_workers);
 
 	iput(fs_info->btree_inode);
 #if 0

commit 4543df7ecc8ae4928c1e51d6e7dc188d650abee4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 11 21:47:56 2008 -0400

    Btrfs: Add a mount option to control worker thread pool size
    
    mount -o thread_pool_size changes the default, which is
    min(num_cpus + 2, 8).  Larger thread pools would make more sense on
    very large disk arrays.
    
    This mount option controls the max size of each thread pool.  There
    are multiple thread pools, so the total worker count will be larger
    than the mount option.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 98ff4fbcb386..c6a710a668cb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1117,6 +1117,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 					      GFP_NOFS);
 	int ret;
 	int err = -EINVAL;
+
 	struct btrfs_super_block *disk_super;
 
 	if (!extent_root || !tree_root || !fs_info) {
@@ -1148,6 +1149,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;
+	fs_info->thread_pool_size = min(num_online_cpus() + 2, 8);
 
 	sb->s_blocksize = 4096;
 	sb->s_blocksize_bits = blksize_bits(4096);
@@ -1195,19 +1197,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
 
-	/* we need to start all the end_io workers up front because the
-	 * queue work function gets called at interrupt time.  The endio
-	 * workers don't normally start IO, so some number of them <= the
-	 * number of cpus is fine.  They handle checksumming after a read.
-	 *
-	 * The other worker threads do start IO, so the max is larger than
-	 * the number of CPUs.  FIXME, tune this for huge machines
-	 */
-	btrfs_init_workers(&fs_info->workers, num_online_cpus() * 2);
-	btrfs_init_workers(&fs_info->endio_workers, num_online_cpus());
-	btrfs_start_workers(&fs_info->workers, 1);
-	btrfs_start_workers(&fs_info->endio_workers, num_online_cpus());
-
 #if 0
 	ret = add_hasher(fs_info, "crc32c");
 	if (ret) {
@@ -1238,6 +1227,17 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (err)
 		goto fail_sb_buffer;
 
+	/*
+	 * we need to start all the end_io workers up front because the
+	 * queue work function gets called at interrupt time, and so it
+	 * cannot dynamically grow.
+	 */
+	btrfs_init_workers(&fs_info->workers, fs_info->thread_pool_size);
+	btrfs_init_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
+	btrfs_start_workers(&fs_info->workers, 1);
+	btrfs_start_workers(&fs_info->endio_workers, fs_info->thread_pool_size);
+
+
 	err = -EINVAL;
 	if (btrfs_super_num_devices(disk_super) > fs_devices->open_devices) {
 		printk("Btrfs: wanted %llu devices, but found %llu\n",
@@ -1341,10 +1341,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_unlock(&fs_info->fs_mutex);
 fail_sb_buffer:
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
-fail_iput:
-	iput(fs_info->btree_inode);
 	btrfs_stop_workers(&fs_info->workers);
 	btrfs_stop_workers(&fs_info->endio_workers);
+fail_iput:
+	iput(fs_info->btree_inode);
 fail:
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);

commit 8b7128429235d9bd72cfd5ed20c77c4f3118f744
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 11 16:50:36 2008 -0400

    Btrfs: Add async worker threads for pre and post IO checksumming
    
    Btrfs has been using workqueues to spread the checksumming load across
    other CPUs in the system.  But, workqueues only schedule work on the
    same CPU that queued the work, giving them a limited benefit for systems with
    higher CPU counts.
    
    This code adds a generic facility to schedule work with pools of kthreads,
    and changes the bio submission code to queue bios up.  The queueing is
    important to make sure large numbers of procs on the system don't
    turn streaming workloads into random workloads by sending IO down
    concurrently.
    
    The end result of all of this is much higher performance (and CPU usage) when
    doing checksumming on large machines.  Two worker pools are created,
    one for writes and one for endio processing.  The two could deadlock if
    we tried to service both from a single pool.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b9a53646ceb2..98ff4fbcb386 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -31,6 +31,7 @@
 #include "btrfs_inode.h"
 #include "volumes.h"
 #include "print-tree.h"
+#include "async-thread.h"
 
 #if 0
 static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
@@ -46,8 +47,7 @@ static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
 #endif
 
 static struct extent_io_ops btree_extent_io_ops;
-static struct workqueue_struct *end_io_workqueue;
-static struct workqueue_struct *async_submit_workqueue;
+static void end_workqueue_fn(struct btrfs_work *work);
 
 struct end_io_wq {
 	struct bio *bio;
@@ -57,6 +57,7 @@ struct end_io_wq {
 	int error;
 	int metadata;
 	struct list_head list;
+	struct btrfs_work work;
 };
 
 struct async_submit_bio {
@@ -66,6 +67,7 @@ struct async_submit_bio {
 	extent_submit_bio_hook_t *submit_bio_hook;
 	int rw;
 	int mirror_num;
+	struct btrfs_work work;
 };
 
 struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
@@ -389,7 +391,6 @@ static int end_workqueue_bio(struct bio *bio,
 {
 	struct end_io_wq *end_io_wq = bio->bi_private;
 	struct btrfs_fs_info *fs_info;
-	unsigned long flags;
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
 	if (bio->bi_size)
@@ -397,11 +398,10 @@ static int end_workqueue_bio(struct bio *bio,
 #endif
 
 	fs_info = end_io_wq->info;
-	spin_lock_irqsave(&fs_info->end_io_work_lock, flags);
 	end_io_wq->error = err;
-	list_add_tail(&end_io_wq->list, &fs_info->end_io_work_list);
-	spin_unlock_irqrestore(&fs_info->end_io_work_lock, flags);
-	queue_work(end_io_workqueue, &fs_info->end_io_work);
+	end_io_wq->work.func = end_workqueue_fn;
+	end_io_wq->work.flags = 0;
+	btrfs_queue_worker(&fs_info->endio_workers, &end_io_wq->work);
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
 	return 0;
@@ -428,6 +428,19 @@ int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 	return 0;
 }
 
+static void run_one_async_submit(struct btrfs_work *work)
+{
+	struct btrfs_fs_info *fs_info;
+	struct async_submit_bio *async;
+
+	async = container_of(work, struct  async_submit_bio, work);
+	fs_info = BTRFS_I(async->inode)->root->fs_info;
+	atomic_dec(&fs_info->nr_async_submits);
+	async->submit_bio_hook(async->inode, async->rw, async->bio,
+			       async->mirror_num);
+	kfree(async);
+}
+
 int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 			int rw, struct bio *bio, int mirror_num,
 			extent_submit_bio_hook_t *submit_bio_hook)
@@ -443,13 +456,10 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 	async->bio = bio;
 	async->mirror_num = mirror_num;
 	async->submit_bio_hook = submit_bio_hook;
-
-	spin_lock(&fs_info->async_submit_work_lock);
-	list_add_tail(&async->list, &fs_info->async_submit_work_list);
+	async->work.func = run_one_async_submit;
+	async->work.flags = 0;
 	atomic_inc(&fs_info->nr_async_submits);
-	spin_unlock(&fs_info->async_submit_work_lock);
-
-	queue_work(async_submit_workqueue, &fs_info->async_submit_work);
+	btrfs_queue_worker(&fs_info->workers, &async->work);
 	return 0;
 }
 
@@ -462,19 +472,32 @@ static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 
 	offset = bio->bi_sector << 9;
 
+	/*
+	 * when we're called for a write, we're already in the async
+	 * submission context.  Just jump ingo btrfs_map_bio
+	 */
 	if (rw & (1 << BIO_RW)) {
-		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num);
+		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio,
+				     mirror_num, 0);
 	}
 
+	/*
+	 * called for a read, do the setup so that checksum validation
+	 * can happen in the async kernel threads
+	 */
 	ret = btrfs_bio_wq_end_io(root->fs_info, bio, 1);
 	BUG_ON(ret);
 
-	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num);
+	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num, 1);
 }
 
 static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 				 int mirror_num)
 {
+	/*
+	 * kthread helpers are used to submit writes so that checksumming
+	 * can happen in parallel across all CPUs
+	 */
 	if (!(rw & (1 << BIO_RW))) {
 		return __btree_submit_bio_hook(inode, rw, bio, mirror_num);
 	}
@@ -1036,95 +1059,40 @@ static int bio_ready_for_csum(struct bio *bio)
 	return ret;
 }
 
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-static void btrfs_end_io_csum(void *p)
-#else
-static void btrfs_end_io_csum(struct work_struct *work)
-#endif
+/*
+ * called by the kthread helper functions to finally call the bio end_io
+ * functions.  This is where read checksum verification actually happens
+ */
+static void end_workqueue_fn(struct btrfs_work *work)
 {
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-	struct btrfs_fs_info *fs_info = p;
-#else
-	struct btrfs_fs_info *fs_info = container_of(work,
-						     struct btrfs_fs_info,
-						     end_io_work);
-#endif
-	unsigned long flags;
-	struct end_io_wq *end_io_wq;
 	struct bio *bio;
-	struct list_head *next;
+	struct end_io_wq *end_io_wq;
+	struct btrfs_fs_info *fs_info;
 	int error;
-	int was_empty;
 
-	while(1) {
-		spin_lock_irqsave(&fs_info->end_io_work_lock, flags);
-		if (list_empty(&fs_info->end_io_work_list)) {
-			spin_unlock_irqrestore(&fs_info->end_io_work_lock,
-					       flags);
-			return;
-		}
-		next = fs_info->end_io_work_list.next;
-		list_del(next);
-		spin_unlock_irqrestore(&fs_info->end_io_work_lock, flags);
-
-		end_io_wq = list_entry(next, struct end_io_wq, list);
-
-		bio = end_io_wq->bio;
-		if (end_io_wq->metadata && !bio_ready_for_csum(bio)) {
-			spin_lock_irqsave(&fs_info->end_io_work_lock, flags);
-			was_empty = list_empty(&fs_info->end_io_work_list);
-			list_add_tail(&end_io_wq->list,
-				      &fs_info->end_io_work_list);
-			spin_unlock_irqrestore(&fs_info->end_io_work_lock,
-					       flags);
-			if (was_empty)
-				return;
-			continue;
-		}
-		error = end_io_wq->error;
-		bio->bi_private = end_io_wq->private;
-		bio->bi_end_io = end_io_wq->end_io;
-		kfree(end_io_wq);
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
-		bio_endio(bio, bio->bi_size, error);
-#else
-		bio_endio(bio, error);
-#endif
-	}
-}
+	end_io_wq = container_of(work, struct end_io_wq, work);
+	bio = end_io_wq->bio;
+	fs_info = end_io_wq->info;
 
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-static void btrfs_async_submit_work(void *p)
-#else
-static void btrfs_async_submit_work(struct work_struct *work)
-#endif
-{
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-	struct btrfs_fs_info *fs_info = p;
+	/* metadata bios are special because the whole tree block must
+	 * be checksummed at once.  This makes sure the entire block is in
+	 * ram and up to date before trying to verify things.  For
+	 * blocksize <= pagesize, it is basically a noop
+	 */
+	if (end_io_wq->metadata && !bio_ready_for_csum(bio)) {
+		btrfs_queue_worker(&fs_info->endio_workers,
+				   &end_io_wq->work);
+		return;
+	}
+	error = end_io_wq->error;
+	bio->bi_private = end_io_wq->private;
+	bio->bi_end_io = end_io_wq->end_io;
+	kfree(end_io_wq);
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
+	bio_endio(bio, bio->bi_size, error);
 #else
-	struct btrfs_fs_info *fs_info = container_of(work,
-						     struct btrfs_fs_info,
-						     async_submit_work);
+	bio_endio(bio, error);
 #endif
-	struct async_submit_bio *async;
-	struct list_head *next;
-
-	while(1) {
-		spin_lock(&fs_info->async_submit_work_lock);
-		if (list_empty(&fs_info->async_submit_work_list)) {
-			spin_unlock(&fs_info->async_submit_work_lock);
-			return;
-		}
-		next = fs_info->async_submit_work_list.next;
-		list_del(next);
-		atomic_dec(&fs_info->nr_async_submits);
-		spin_unlock(&fs_info->async_submit_work_lock);
-
-		async = list_entry(next, struct async_submit_bio, list);
-		async->submit_bio_hook(async->inode, async->rw, async->bio,
-				       async->mirror_num);
-		kfree(async);
-	}
 }
 
 struct btrfs_root *open_ctree(struct super_block *sb,
@@ -1155,19 +1123,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		err = -ENOMEM;
 		goto fail;
 	}
-	end_io_workqueue = create_workqueue("btrfs-end-io");
-	BUG_ON(!end_io_workqueue);
-	async_submit_workqueue = create_workqueue("btrfs-async-submit");
-
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->hashers);
-	INIT_LIST_HEAD(&fs_info->end_io_work_list);
-	INIT_LIST_HEAD(&fs_info->async_submit_work_list);
 	spin_lock_init(&fs_info->hash_lock);
-	spin_lock_init(&fs_info->end_io_work_lock);
-	spin_lock_init(&fs_info->async_submit_work_lock);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);
 
@@ -1222,13 +1182,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->do_barriers = 1;
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-	INIT_WORK(&fs_info->end_io_work, btrfs_end_io_csum, fs_info);
-	INIT_WORK(&fs_info->async_submit_work, btrfs_async_submit_work,
-		  fs_info);
 	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);
 #else
-	INIT_WORK(&fs_info->end_io_work, btrfs_end_io_csum);
-	INIT_WORK(&fs_info->async_submit_work, btrfs_async_submit_work);
 	INIT_DELAYED_WORK(&fs_info->trans_work, btrfs_transaction_cleaner);
 #endif
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
@@ -1240,6 +1195,19 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
 
+	/* we need to start all the end_io workers up front because the
+	 * queue work function gets called at interrupt time.  The endio
+	 * workers don't normally start IO, so some number of them <= the
+	 * number of cpus is fine.  They handle checksumming after a read.
+	 *
+	 * The other worker threads do start IO, so the max is larger than
+	 * the number of CPUs.  FIXME, tune this for huge machines
+	 */
+	btrfs_init_workers(&fs_info->workers, num_online_cpus() * 2);
+	btrfs_init_workers(&fs_info->endio_workers, num_online_cpus());
+	btrfs_start_workers(&fs_info->workers, 1);
+	btrfs_start_workers(&fs_info->endio_workers, num_online_cpus());
+
 #if 0
 	ret = add_hasher(fs_info, "crc32c");
 	if (ret) {
@@ -1375,6 +1343,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 fail_iput:
 	iput(fs_info->btree_inode);
+	btrfs_stop_workers(&fs_info->workers);
+	btrfs_stop_workers(&fs_info->endio_workers);
 fail:
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
@@ -1623,16 +1593,10 @@ int close_ctree(struct btrfs_root *root)
 	extent_io_tree_empty_lru(&fs_info->extent_ins);
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 
-	flush_workqueue(async_submit_workqueue);
-	flush_workqueue(end_io_workqueue);
-
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 
-	flush_workqueue(async_submit_workqueue);
-	destroy_workqueue(async_submit_workqueue);
-
-	flush_workqueue(end_io_workqueue);
-	destroy_workqueue(end_io_workqueue);
+	btrfs_stop_workers(&fs_info->workers);
+	btrfs_stop_workers(&fs_info->endio_workers);
 
 	iput(fs_info->btree_inode);
 #if 0

commit edf24abe51493ccda384644d487fe2f796ac21c8
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jun 10 10:40:29 2008 -0400

    btrfs: sanity mount option parsing and early mount code
    
    Also adds lots of comments to describe what's going on here.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3805e7eab82d..b9a53646ceb2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1266,8 +1266,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!btrfs_super_root(disk_super))
 		goto fail_sb_buffer;
 
-	btrfs_parse_options(options, tree_root, NULL);
+	err = btrfs_parse_options(tree_root, options);
+	if (err)
+		goto fail_sb_buffer;
 
+	err = -EINVAL;
 	if (btrfs_super_num_devices(disk_super) > fs_devices->open_devices) {
 		printk("Btrfs: wanted %llu devices, but found %llu\n",
 		       (unsigned long long)btrfs_super_num_devices(disk_super),

commit 51ebc0d3d5cd1a2728068499a8fc1bdb0a581ab5
Author: Jan Engelhardt <jengelh@medozas.de>
Date:   Mon Jun 9 22:19:40 2008 -0400

    Btrfs: bdi_init and bdi_destroy come with 2.6.23
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 016c0c0226ed..3805e7eab82d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -984,7 +984,7 @@ void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 
 static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 {
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)
 	bdi_init(bdi);
 #endif
 	bdi->ra_pages	= default_backing_dev_info.ra_pages;
@@ -1378,7 +1378,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	kfree(extent_root);
 	kfree(tree_root);
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)
 	bdi_destroy(&fs_info->bdi);
 #endif
 	kfree(fs_info);
@@ -1645,7 +1645,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)
 	bdi_destroy(&fs_info->bdi);
 #endif
 

commit da496f2acf61153e0d4d42ded6a53f3367939db0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 27 10:52:17 2008 -0400

    Btrfs: Always use the async submission queue for checksummed writes
    
    This avoids IO stalls and poorly ordered IO from inline writers mixing in
    with the async submission queue
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d8a256d3c83a..016c0c0226ed 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -434,13 +434,6 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 {
 	struct async_submit_bio *async;
 
-	/*
-	 * inline writerback should stay inline, only hop to the async
-	 * queue if we're pdflush
-	 */
-	if (!current_is_pdflush())
-		return submit_bio_hook(inode, rw, bio, mirror_num);
-
 	async = kmalloc(sizeof(*async), GFP_NOFS);
 	if (!async)
 		return -ENOMEM;

commit 1c8cfcc1590d378c82ec75888f71e87fd26551e3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri May 16 13:06:51 2008 -0400

    Btrfs: Enable btree balancing on old kernels again
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 373374340e9b..d8a256d3c83a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1719,7 +1719,6 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	 * looks as though older kernels can get into trouble with
 	 * this code, they end up stuck in balance_dirty_pages forever
 	 */
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
 	struct extent_io_tree *tree;
 	u64 num_dirty;
 	u64 start = 0;
@@ -1735,9 +1734,7 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 		balance_dirty_pages_ratelimited_nr(
 				   root->fs_info->btree_inode->i_mapping, 1);
 	}
-#else
 	return;
-#endif
 }
 
 void btrfs_set_buffer_defrag(struct extent_buffer *buf)

commit cb03c743c6486e4efb8be6bdf7bf23177826d156
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 15 16:15:45 2008 -0400

    Btrfs: Change the congestion functions to meter the number of async submits as well
    
    The async submit workqueue was absorbing too many requests, leading to long
    stalls where the async submitters were stalling.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 264f297260f8..373374340e9b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -453,6 +453,7 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 
 	spin_lock(&fs_info->async_submit_work_lock);
 	list_add_tail(&async->list, &fs_info->async_submit_work_list);
+	atomic_inc(&fs_info->nr_async_submits);
 	spin_unlock(&fs_info->async_submit_work_lock);
 
 	queue_work(async_submit_workqueue, &fs_info->async_submit_work);
@@ -906,10 +907,16 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 {
 	struct btrfs_fs_info *info = (struct btrfs_fs_info *)congested_data;
 	int ret = 0;
+	int limit = 256 * info->fs_devices->open_devices;
 	struct list_head *cur;
 	struct btrfs_device *device;
 	struct backing_dev_info *bdi;
 
+	if ((bdi_bits & (1 << BDI_write_congested)) &&
+	    atomic_read(&info->nr_async_submits) > limit) {
+		return 1;
+	}
+
 	list_for_each(cur, &info->fs_devices->devices) {
 		device = list_entry(cur, struct btrfs_device, dev_list);
 		if (!device->bdev)
@@ -1117,6 +1124,7 @@ static void btrfs_async_submit_work(struct work_struct *work)
 		}
 		next = fs_info->async_submit_work_list.next;
 		list_del(next);
+		atomic_dec(&fs_info->nr_async_submits);
 		spin_unlock(&fs_info->async_submit_work_lock);
 
 		async = list_entry(next, struct async_submit_bio, list);
@@ -1179,6 +1187,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
 	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);
+	atomic_set(&fs_info->nr_async_submits, 0);
 	fs_info->sb = sb;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;

commit a0af469b58944f6e8c5c8ecbebb42997baf0cb9e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 13 16:03:06 2008 -0400

    Fix btrfs_open_devices to deal with changes since the scan ioctls
    
    Devices can change after the scan ioctls are done, and btrfs_open_devices
    needs to be able to verify them as they are opened and used by the FS.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 38b0d9ecda6a..264f297260f8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1266,10 +1266,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	btrfs_parse_options(options, tree_root, NULL);
 
-	if (btrfs_super_num_devices(disk_super) > fs_devices->num_devices) {
+	if (btrfs_super_num_devices(disk_super) > fs_devices->open_devices) {
 		printk("Btrfs: wanted %llu devices, but found %llu\n",
 		       (unsigned long long)btrfs_super_num_devices(disk_super),
-		       (unsigned long long)fs_devices->num_devices);
+		       (unsigned long long)fs_devices->open_devices);
 		if (btrfs_test_opt(tree_root, DEGRADED))
 			printk("continuing in degraded mode\n");
 		else {

commit dfe25020689bb2d318782d2c9c7141203583fc70
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 13 13:46:40 2008 -0400

    Btrfs: Add mount -o degraded to allow mounts to continue with missing devices
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 574b1245964e..38b0d9ecda6a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -614,21 +614,6 @@ int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize,
 	return ret;
 }
 
-static int close_all_devices(struct btrfs_fs_info *fs_info)
-{
-	struct list_head *list;
-	struct list_head *next;
-	struct btrfs_device *device;
-
-	list = &fs_info->fs_devices->devices;
-	list_for_each(next, list) {
-		device = list_entry(next, struct btrfs_device, dev_list);
-		close_bdev_excl(device->bdev);
-		device->bdev = NULL;
-	}
-	return 0;
-}
-
 struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize)
 {
@@ -927,6 +912,8 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 
 	list_for_each(cur, &info->fs_devices->devices) {
 		device = list_entry(cur, struct btrfs_device, dev_list);
+		if (!device->bdev)
+			continue;
 		bdi = blk_get_backing_dev_info(device->bdev);
 		if (bdi && bdi_congested(bdi, bdi_bits)) {
 			ret = 1;
@@ -1140,7 +1127,8 @@ static void btrfs_async_submit_work(struct work_struct *work)
 }
 
 struct btrfs_root *open_ctree(struct super_block *sb,
-			      struct btrfs_fs_devices *fs_devices)
+			      struct btrfs_fs_devices *fs_devices,
+			      char *options)
 {
 	u32 sectorsize;
 	u32 nodesize;
@@ -1276,12 +1264,19 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	if (!btrfs_super_root(disk_super))
 		goto fail_sb_buffer;
 
-	if (btrfs_super_num_devices(disk_super) != fs_devices->num_devices) {
+	btrfs_parse_options(options, tree_root, NULL);
+
+	if (btrfs_super_num_devices(disk_super) > fs_devices->num_devices) {
 		printk("Btrfs: wanted %llu devices, but found %llu\n",
 		       (unsigned long long)btrfs_super_num_devices(disk_super),
 		       (unsigned long long)fs_devices->num_devices);
-		goto fail_sb_buffer;
+		if (btrfs_test_opt(tree_root, DEGRADED))
+			printk("continuing in degraded mode\n");
+		else {
+			goto fail_sb_buffer;
+		}
 	}
+
 	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
 
 	nodesize = btrfs_super_nodesize(disk_super);
@@ -1329,6 +1324,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	ret = btrfs_read_chunk_tree(chunk_root);
 	BUG_ON(ret);
 
+	btrfs_close_extra_devices(fs_devices);
+
 	blocksize = btrfs_level_size(tree_root,
 				     btrfs_super_root_level(disk_super));
 
@@ -1374,7 +1371,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail_iput:
 	iput(fs_info->btree_inode);
 fail:
-	close_all_devices(fs_info);
+	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
 	kfree(extent_root);
@@ -1429,6 +1426,13 @@ int write_all_supers(struct btrfs_root *root)
 	dev_item = &sb->dev_item;
 	list_for_each(cur, head) {
 		dev = list_entry(cur, struct btrfs_device, dev_list);
+		if (!dev->bdev) {
+			total_errors++;
+			continue;
+		}
+		if (!dev->in_fs_metadata)
+			continue;
+
 		btrfs_set_stack_device_type(dev_item, dev->type);
 		btrfs_set_stack_device_id(dev_item, dev->devid);
 		btrfs_set_stack_device_total_bytes(dev_item, dev->total_bytes);
@@ -1482,6 +1486,11 @@ int write_all_supers(struct btrfs_root *root)
 
 	list_for_each(cur, head) {
 		dev = list_entry(cur, struct btrfs_device, dev_list);
+		if (!dev->bdev)
+			continue;
+		if (!dev->in_fs_metadata)
+			continue;
+
 		BUG_ON(!dev->pending_io);
 		bh = dev->pending_io;
 		wait_on_buffer(bh);
@@ -1631,7 +1640,7 @@ int close_ctree(struct btrfs_root *root)
 		kfree(hasher);
 	}
 #endif
-	close_all_devices(fs_info);
+	btrfs_close_devices(fs_info->fs_devices);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)

commit 1259ab75c62462b8ffad90067b5e1f6312786a18
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 12 13:39:03 2008 -0400

    Btrfs: Handle write errors on raid1 and raid10
    
    When duplicate copies exist, writes are allowed to fail to one of those
    copies.  This changeset includes a few changes that allow the FS to
    continue even when some IOs fail.
    
    It also adds verification of the parent generation number for btree blocks.
    This generation is stored in the pointer to a block, and it ensures
    that missed writes to are detected.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index edee7a44f861..574b1245964e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -205,6 +205,33 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	return 0;
 }
 
+static int verify_parent_transid(struct extent_io_tree *io_tree,
+				 struct extent_buffer *eb, u64 parent_transid)
+{
+	int ret;
+
+	if (!parent_transid || btrfs_header_generation(eb) == parent_transid)
+		return 0;
+
+	lock_extent(io_tree, eb->start, eb->start + eb->len - 1, GFP_NOFS);
+	if (extent_buffer_uptodate(io_tree, eb) &&
+	    btrfs_header_generation(eb) == parent_transid) {
+		ret = 0;
+		goto out;
+	}
+	printk("parent transid verify failed on %llu wanted %llu found %llu\n",
+	       (unsigned long long)eb->start,
+	       (unsigned long long)parent_transid,
+	       (unsigned long long)btrfs_header_generation(eb));
+	ret = 1;
+out:
+	clear_extent_buffer_uptodate(io_tree, eb);
+	unlock_extent(io_tree, eb->start, eb->start + eb->len - 1,
+		      GFP_NOFS);
+	return ret;
+
+}
+
 static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 					  struct extent_buffer *eb,
 					  u64 start, u64 parent_transid)
@@ -218,7 +245,8 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 	while (1) {
 		ret = read_extent_buffer_pages(io_tree, eb, start, 1,
 					       btree_get_extent, mirror_num);
-		if (!ret)
+		if (!ret &&
+		    !verify_parent_transid(io_tree, eb, parent_transid))
 			return ret;
 
 		num_copies = btrfs_num_copies(&root->fs_info->mapping_tree,
@@ -330,6 +358,13 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		ret = -EIO;
 		goto err;
 	}
+	if (memcmp_extent_buffer(eb, root->fs_info->fsid,
+				 (unsigned long)btrfs_header_fsid(eb),
+				 BTRFS_FSID_SIZE)) {
+		printk("bad fsid on block %Lu\n", eb->start);
+		ret = -EIO;
+		goto err;
+	}
 	found_level = btrfs_header_level(eb);
 
 	ret = csum_tree_block(root, eb, 1);
@@ -1363,7 +1398,9 @@ static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
 					"I/O error on %s\n",
 				       bdevname(bh->b_bdev, b));
 		}
-		set_buffer_write_io_error(bh);
+		/* note, we dont' set_buffer_write_io_error because we have
+		 * our own ways of dealing with the IO errors
+		 */
 		clear_buffer_uptodate(bh);
 	}
 	unlock_buffer(bh);
@@ -1459,7 +1496,8 @@ int write_all_supers(struct btrfs_root *root)
 				ret = submit_bh(WRITE, bh);
 				BUG_ON(ret);
 				wait_on_buffer(bh);
-				BUG_ON(!buffer_uptodate(bh));
+				if (!buffer_uptodate(bh))
+					total_errors++;
 			} else {
 				total_errors++;
 			}
@@ -1607,10 +1645,18 @@ int close_ctree(struct btrfs_root *root)
 	return 0;
 }
 
-int btrfs_buffer_uptodate(struct extent_buffer *buf)
+int btrfs_buffer_uptodate(struct extent_buffer *buf, u64 parent_transid)
 {
+	int ret;
 	struct inode *btree_inode = buf->first_page->mapping->host;
-	return extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree, buf);
+
+	ret = extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree, buf);
+	if (!ret)
+		return ret;
+
+	ret = verify_parent_transid(&BTRFS_I(btree_inode)->io_tree, buf,
+				    parent_transid);
+	return !ret;
 }
 
 int btrfs_set_buffer_uptodate(struct extent_buffer *buf)

commit ca7a79ad8dbe24669a8ced01f9fc0126b872745d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 12 12:59:19 2008 -0400

    Btrfs: Pass down the expected generation number when reading tree blocks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c3083165b172..edee7a44f861 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -207,7 +207,7 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 
 static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 					  struct extent_buffer *eb,
-					  u64 start)
+					  u64 start, u64 parent_transid)
 {
 	struct extent_io_tree *io_tree;
 	int ret;
@@ -254,7 +254,8 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 		WARN_ON(1);
 	}
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
-	ret = btree_read_extent_buffer_pages(root, eb, start + PAGE_CACHE_SIZE);
+	ret = btree_read_extent_buffer_pages(root, eb, start + PAGE_CACHE_SIZE,
+					     btrfs_header_generation(eb));
 	BUG_ON(ret);
 	btrfs_clear_buffer_defrag(eb);
 	found_start = btrfs_header_bytenr(eb);
@@ -562,7 +563,8 @@ static struct address_space_operations btree_aops = {
 	.sync_page	= block_sync_page,
 };
 
-int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
+int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize,
+			 u64 parent_transid)
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
@@ -592,12 +594,6 @@ static int close_all_devices(struct btrfs_fs_info *fs_info)
 	return 0;
 }
 
-int btrfs_verify_block_csum(struct btrfs_root *root,
-			    struct extent_buffer *buf)
-{
-	return btrfs_buffer_uptodate(buf);
-}
-
 struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize)
 {
@@ -621,7 +617,7 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 
 
 struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
-				      u32 blocksize)
+				      u32 blocksize, u64 parent_transid)
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
@@ -634,7 +630,7 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 	if (!buf)
 		return NULL;
 
-	ret = btree_read_extent_buffer_pages(root, buf, 0);
+	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 
 	if (ret == 0) {
 		buf->flags |= EXTENT_UPTODATE;
@@ -715,7 +711,7 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
-				     blocksize);
+				     blocksize, 0);
 	BUG_ON(!root->node);
 	return 0;
 }
@@ -771,7 +767,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 	}
 	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
 	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
-				     blocksize);
+				     blocksize, 0);
 	BUG_ON(!root->node);
 insert:
 	root->ref_cows = 1;
@@ -1288,7 +1284,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	chunk_root->node = read_tree_block(chunk_root,
 					   btrfs_super_chunk_root(disk_super),
-					   blocksize);
+					   blocksize, 0);
 	BUG_ON(!chunk_root->node);
 
 	read_extent_buffer(chunk_root->node, fs_info->chunk_tree_uuid,
@@ -1304,7 +1300,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super),
-					  blocksize);
+					  blocksize, 0);
 	if (!tree_root->node)
 		goto fail_sb_buffer;
 
@@ -1732,11 +1728,11 @@ int btrfs_clear_buffer_defrag(struct extent_buffer *buf)
 		     EXTENT_DEFRAG, GFP_NOFS);
 }
 
-int btrfs_read_buffer(struct extent_buffer *buf)
+int btrfs_read_buffer(struct extent_buffer *buf, u64 parent_transid)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	int ret;
-	ret = btree_read_extent_buffer_pages(root, buf, 0);
+	ret = btree_read_extent_buffer_pages(root, buf, 0, parent_transid);
 	if (ret == 0) {
 		buf->flags |= EXTENT_UPTODATE;
 	}

commit 188de649c51f03df3f8a601aea0110a3870815c2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri May 9 11:52:25 2008 -0400

    Btrfs: Don't do btree balance_dirty_pages on old kernels, it stalls forever
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9d5424ad01a3..c3083165b172 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1655,6 +1655,11 @@ void btrfs_throttle(struct btrfs_root *root)
 
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 {
+	/*
+	 * looks as though older kernels can get into trouble with
+	 * this code, they end up stuck in balance_dirty_pages forever
+	 */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
 	struct extent_io_tree *tree;
 	u64 num_dirty;
 	u64 start = 0;
@@ -1670,6 +1675,9 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 		balance_dirty_pages_ratelimited_nr(
 				   root->fs_info->btree_inode->i_mapping, 1);
 	}
+#else
+	return;
+#endif
 }
 
 void btrfs_set_buffer_defrag(struct extent_buffer *buf)

commit a061fc8da7b990faa41ca503e66faef3ecdeead0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed May 7 11:43:44 2008 -0400

    Btrfs: Add support for online device removal
    
    This required a few structural changes to the code that manages bdev pointers:
    
    The VFS super block now gets an anon-bdev instead of a pointer to the
    lowest bdev.  This allows us to avoid swapping the super block bdev pointer
    around at run time.
    
    The code to read in the super block no longer goes through the extent
    buffer interface.  Things got ugly keeping the mapping constant.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fabc31b334b6..9d5424ad01a3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -78,9 +78,13 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 
 	spin_lock(&em_tree->lock);
 	em = lookup_extent_mapping(em_tree, start, len);
-	spin_unlock(&em_tree->lock);
-	if (em)
+	if (em) {
+		em->bdev =
+			BTRFS_I(inode)->root->fs_info->fs_devices->latest_bdev;
+		spin_unlock(&em_tree->lock);
 		goto out;
+	}
+	spin_unlock(&em_tree->lock);
 
 	em = alloc_extent_map(GFP_NOFS);
 	if (!em) {
@@ -90,7 +94,7 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 	em->start = 0;
 	em->len = (u64)-1;
 	em->block_start = 0;
-	em->bdev = inode->i_sb->s_bdev;
+	em->bdev = BTRFS_I(inode)->root->fs_info->fs_devices->latest_bdev;
 
 	spin_lock(&em_tree->lock);
 	ret = add_extent_mapping(em_tree, em);
@@ -435,11 +439,6 @@ static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 	ret = btrfs_bio_wq_end_io(root->fs_info, bio, 1);
 	BUG_ON(ret);
 
-	if (offset == BTRFS_SUPER_INFO_OFFSET) {
-		bio->bi_bdev = root->fs_info->fs_devices->latest_bdev;
-		submit_bio(rw, bio);
-		return 0;
-	}
 	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num);
 }
 
@@ -587,8 +586,7 @@ static int close_all_devices(struct btrfs_fs_info *fs_info)
 	list = &fs_info->fs_devices->devices;
 	list_for_each(next, list) {
 		device = list_entry(next, struct btrfs_device, dev_list);
-		if (device->bdev && device->bdev != fs_info->sb->s_bdev)
-			close_bdev_excl(device->bdev);
+		close_bdev_excl(device->bdev);
 		device->bdev = NULL;
 	}
 	return 0;
@@ -1118,6 +1116,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	u32 leafsize;
 	u32 blocksize;
 	u32 stripesize;
+	struct buffer_head *bh;
 	struct btrfs_root *extent_root = kmalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
 	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
@@ -1153,7 +1152,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->new_trans_lock);
 
 	init_completion(&fs_info->kobj_unregister);
-	sb_set_blocksize(sb, BTRFS_SUPER_INFO_SIZE);
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
 	fs_info->chunk_root = chunk_root;
@@ -1170,6 +1168,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;
 
+	sb->s_blocksize = 4096;
+	sb->s_blocksize_bits = blksize_bits(4096);
+
 	/*
 	 * we set the i_size on the btree inode to the max possible int.
 	 * the real end of the address space is determined by all of
@@ -1229,19 +1230,16 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	__setup_root(4096, 4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
-	fs_info->sb_buffer = read_tree_block(tree_root,
-					     BTRFS_SUPER_INFO_OFFSET,
-					     4096);
 
-	if (!fs_info->sb_buffer)
+	bh = __bread(fs_devices->latest_bdev,
+		     BTRFS_SUPER_INFO_OFFSET / 4096, 4096);
+	if (!bh)
 		goto fail_iput;
 
-	read_extent_buffer(fs_info->sb_buffer, &fs_info->super_copy, 0,
-			   sizeof(fs_info->super_copy));
+	memcpy(&fs_info->super_copy, bh->b_data, sizeof(fs_info->super_copy));
+	brelse(bh);
 
-	read_extent_buffer(fs_info->sb_buffer, fs_info->fsid,
-			   (unsigned long)btrfs_super_fsid(fs_info->sb_buffer),
-			   BTRFS_FSID_SIZE);
+	memcpy(fs_info->fsid, fs_info->super_copy.fsid, BTRFS_FSID_SIZE);
 
 	disk_super = &fs_info->super_copy;
 	if (!btrfs_super_root(disk_super))
@@ -1263,7 +1261,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	tree_root->leafsize = leafsize;
 	tree_root->sectorsize = sectorsize;
 	tree_root->stripesize = stripesize;
-	sb_set_blocksize(sb, sectorsize);
+
+	sb->s_blocksize = sectorsize;
+	sb->s_blocksize_bits = blksize_bits(sectorsize);
 
 	if (strncmp((char *)(&disk_super->magic), BTRFS_MAGIC,
 		    sizeof(disk_super->magic))) {
@@ -1339,7 +1339,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail_sys_array:
 	mutex_unlock(&fs_info->fs_mutex);
 fail_sb_buffer:
-	free_extent_buffer(fs_info->sb_buffer);
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 fail_iput:
 	iput(fs_info->btree_inode);
@@ -1380,41 +1379,44 @@ int write_all_supers(struct btrfs_root *root)
 	struct list_head *cur;
 	struct list_head *head = &root->fs_info->fs_devices->devices;
 	struct btrfs_device *dev;
-	struct extent_buffer *sb;
+	struct btrfs_super_block *sb;
 	struct btrfs_dev_item *dev_item;
 	struct buffer_head *bh;
 	int ret;
 	int do_barriers;
 	int max_errors;
 	int total_errors = 0;
+	u32 crc;
+	u64 flags;
 
 	max_errors = btrfs_super_num_devices(&root->fs_info->super_copy) - 1;
 	do_barriers = !btrfs_test_opt(root, NOBARRIER);
 
-	sb = root->fs_info->sb_buffer;
-	dev_item = (struct btrfs_dev_item *)offsetof(struct btrfs_super_block,
-						      dev_item);
+	sb = &root->fs_info->super_for_commit;
+	dev_item = &sb->dev_item;
 	list_for_each(cur, head) {
 		dev = list_entry(cur, struct btrfs_device, dev_list);
-		btrfs_set_device_type(sb, dev_item, dev->type);
-		btrfs_set_device_id(sb, dev_item, dev->devid);
-		btrfs_set_device_total_bytes(sb, dev_item, dev->total_bytes);
-		btrfs_set_device_bytes_used(sb, dev_item, dev->bytes_used);
-		btrfs_set_device_io_align(sb, dev_item, dev->io_align);
-		btrfs_set_device_io_width(sb, dev_item, dev->io_width);
-		btrfs_set_device_sector_size(sb, dev_item, dev->sector_size);
-		write_extent_buffer(sb, dev->uuid,
-				    (unsigned long)btrfs_device_uuid(dev_item),
-				    BTRFS_UUID_SIZE);
-
-		btrfs_set_header_flag(sb, BTRFS_HEADER_FLAG_WRITTEN);
-		csum_tree_block(root, sb, 0);
-
-		bh = __getblk(dev->bdev, BTRFS_SUPER_INFO_OFFSET /
-			      root->fs_info->sb->s_blocksize,
+		btrfs_set_stack_device_type(dev_item, dev->type);
+		btrfs_set_stack_device_id(dev_item, dev->devid);
+		btrfs_set_stack_device_total_bytes(dev_item, dev->total_bytes);
+		btrfs_set_stack_device_bytes_used(dev_item, dev->bytes_used);
+		btrfs_set_stack_device_io_align(dev_item, dev->io_align);
+		btrfs_set_stack_device_io_width(dev_item, dev->io_width);
+		btrfs_set_stack_device_sector_size(dev_item, dev->sector_size);
+		memcpy(dev_item->uuid, dev->uuid, BTRFS_UUID_SIZE);
+		flags = btrfs_super_flags(sb);
+		btrfs_set_super_flags(sb, flags | BTRFS_HEADER_FLAG_WRITTEN);
+
+
+		crc = ~(u32)0;
+		crc = btrfs_csum_data(root, (char *)sb + BTRFS_CSUM_SIZE, crc,
+				      BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE);
+		btrfs_csum_final(crc, sb->csum);
+
+		bh = __getblk(dev->bdev, BTRFS_SUPER_INFO_OFFSET / 4096,
 			      BTRFS_SUPER_INFO_SIZE);
 
-		read_extent_buffer(sb, bh->b_data, 0, BTRFS_SUPER_INFO_SIZE);
+		memcpy(bh->b_data, sb, BTRFS_SUPER_INFO_SIZE);
 		dev->pending_io = bh;
 
 		get_bh(bh);
@@ -1483,15 +1485,6 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 	int ret;
 
 	ret = write_all_supers(root);
-#if 0
-	if (!btrfs_test_opt(root, NOBARRIER))
-		blkdev_issue_flush(sb->s_bdev, NULL);
-	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree, super);
-	ret = sync_page_range_nolock(btree_inode, btree_inode->i_mapping,
-				     super->start, super->len);
-	if (!btrfs_test_opt(root, NOBARRIER))
-		blkdev_issue_flush(sb->s_bdev, NULL);
-#endif
 	return ret;
 }
 
@@ -1570,8 +1563,6 @@ int close_ctree(struct btrfs_root *root)
 	if (root->fs_info->dev_root->node);
 		free_extent_buffer(root->fs_info->dev_root->node);
 
-	free_extent_buffer(fs_info->sb_buffer);
-
 	btrfs_free_block_groups(root->fs_info);
 	del_fs_roots(fs_info);
 
@@ -1652,7 +1643,7 @@ void btrfs_throttle(struct btrfs_root *root)
 {
 	struct backing_dev_info *bdi;
 
-	bdi = root->fs_info->sb->s_bdev->bd_inode->i_mapping->backing_dev_info;
+	bdi = &root->fs_info->bdi;
 	if (root->fs_info->throttles && bdi_write_congested(bdi)) {
 #if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,18)
 		congestion_wait(WRITE, HZ/20);

commit d6bfde8765668c8687de72f7a40f52acdf4f2f19
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 30 13:59:35 2008 -0400

    Btrfs: Fixes for 2.6.18 enterprise kernels
    
    2.6.18 seems to get caught in an infinite loop when
    cancel_rearming_delayed_workqueue is called more than once, so this switches
    to cancel_delayed_work, which is arguably more correct.
    
    Also, balance_dirty_pages can run into problems with 2.6.18 based kernels
    because it doesn't have the per-bdi dirty limits.  This avoids calling
    balance_dirty_pages on the btree inode unless there is actually something
    to balance, which is a good optimization in general.
    
    Finally there's a compile fix for ordered-data.h
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e35e70165b53..fabc31b334b6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1548,6 +1548,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_commit_transaction(trans, root);
 	ret = btrfs_write_and_wait_transaction(NULL, root);
 	BUG_ON(ret);
+
 	write_ctree_super(NULL, root);
 	mutex_unlock(&fs_info->fs_mutex);
 
@@ -1583,17 +1584,17 @@ int close_ctree(struct btrfs_root *root)
 	extent_io_tree_empty_lru(&fs_info->extent_ins);
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 
-	flush_workqueue(end_io_workqueue);
 	flush_workqueue(async_submit_workqueue);
+	flush_workqueue(end_io_workqueue);
 
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 
-	flush_workqueue(end_io_workqueue);
-	destroy_workqueue(end_io_workqueue);
-
 	flush_workqueue(async_submit_workqueue);
 	destroy_workqueue(async_submit_workqueue);
 
+	flush_workqueue(end_io_workqueue);
+	destroy_workqueue(end_io_workqueue);
+
 	iput(fs_info->btree_inode);
 #if 0
 	while(!list_empty(&fs_info->hashers)) {
@@ -1663,8 +1664,21 @@ void btrfs_throttle(struct btrfs_root *root)
 
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 {
-	balance_dirty_pages_ratelimited_nr(
+	struct extent_io_tree *tree;
+	u64 num_dirty;
+	u64 start = 0;
+	unsigned long thresh = 16 * 1024 * 1024;
+	tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
+
+	if (current_is_pdflush())
+		return;
+
+	num_dirty = count_range_bits(tree, &start, (u64)-1,
+				     thresh, EXTENT_DIRTY);
+	if (num_dirty > thresh) {
+		balance_dirty_pages_ratelimited_nr(
 				   root->fs_info->btree_inode->i_mapping, 1);
+	}
 }
 
 void btrfs_set_buffer_defrag(struct extent_buffer *buf)

commit a236aed14ccb0661611d4416f6b573d892bdc60a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 29 09:38:00 2008 -0400

    Btrfs: Deal with failed writes in mirrored configurations
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1c7d84aff864..e35e70165b53 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1385,7 +1385,10 @@ int write_all_supers(struct btrfs_root *root)
 	struct buffer_head *bh;
 	int ret;
 	int do_barriers;
+	int max_errors;
+	int total_errors = 0;
 
+	max_errors = btrfs_super_num_devices(&root->fs_info->super_copy) - 1;
 	do_barriers = !btrfs_test_opt(root, NOBARRIER);
 
 	sb = root->fs_info->sb_buffer;
@@ -1433,8 +1436,14 @@ int write_all_supers(struct btrfs_root *root)
 		} else {
 			ret = submit_bh(WRITE, bh);
 		}
-		BUG_ON(ret);
+		if (ret)
+			total_errors++;
 	}
+	if (total_errors > max_errors) {
+		printk("btrfs: %d errors while writing supers\n", total_errors);
+		BUG();
+	}
+	total_errors = 0;
 
 	list_for_each(cur, head) {
 		dev = list_entry(cur, struct btrfs_device, dev_list);
@@ -1454,13 +1463,17 @@ int write_all_supers(struct btrfs_root *root)
 				wait_on_buffer(bh);
 				BUG_ON(!buffer_uptodate(bh));
 			} else {
-				BUG();
+				total_errors++;
 			}
 
 		}
 		dev->pending_io = NULL;
 		brelse(bh);
 	}
+	if (total_errors > max_errors) {
+		printk("btrfs: %d errors while writing supers\n", total_errors);
+		BUG();
+	}
 	return 0;
 }
 

commit 4235298e4fc3c1a09f659cfe2fd285024eeb2241
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 28 16:40:52 2008 -0400

    Btrfs: Drop some verbose printks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a9ce491d279b..1c7d84aff864 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -214,25 +214,18 @@ static int btree_read_extent_buffer_pages(struct btrfs_root *root,
 	while (1) {
 		ret = read_extent_buffer_pages(io_tree, eb, start, 1,
 					       btree_get_extent, mirror_num);
-		if (!ret) {
-			if (mirror_num)
-printk("good read %Lu mirror %d total %d\n", eb->start, mirror_num, num_copies);
+		if (!ret)
 			return ret;
-		}
+
 		num_copies = btrfs_num_copies(&root->fs_info->mapping_tree,
 					      eb->start, eb->len);
-printk("failed to read %Lu mirror %d total %d\n", eb->start, mirror_num, num_copies);
-		if (num_copies == 1) {
-printk("reading %Lu failed only one copy\n", eb->start);
+		if (num_copies == 1)
 			return ret;
-		}
+
 		mirror_num++;
-		if (mirror_num > num_copies) {
-printk("bailing at mirror %d of %d\n", mirror_num, num_copies);
+		if (mirror_num > num_copies)
 			return ret;
-		}
 	}
-printk("read extent buffer page last\n");
 	return -EIO;
 }
 
@@ -322,7 +315,6 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	btrfs_clear_buffer_defrag(eb);
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
-printk("bad start on %Lu found %Lu\n", eb->start, found_start);
 		ret = -EIO;
 		goto err;
 	}

commit 8f18cf13396caae5a3d7ae91201cfb15181a9642
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 25 16:53:30 2008 -0400

    Btrfs: Make the resizer work based on shrinking and growing devices
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 71838264ca6b..a9ce491d279b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -818,6 +818,10 @@ struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 		return fs_info->tree_root;
 	if (location->objectid == BTRFS_EXTENT_TREE_OBJECTID)
 		return fs_info->extent_root;
+	if (location->objectid == BTRFS_CHUNK_TREE_OBJECTID)
+		return fs_info->chunk_root;
+	if (location->objectid == BTRFS_DEV_TREE_OBJECTID)
+		return fs_info->dev_root;
 
 	root = radix_tree_lookup(&fs_info->fs_roots_radix,
 				 (unsigned long)location->objectid);

commit 84eed90fac1b927a2657ff3bb7a0f18b9cb688f7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 25 09:04:37 2008 -0400

    Btrfs: Add failure handling for read_sys_array
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1281c393c7e6..71838264ca6b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1278,7 +1278,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	mutex_lock(&fs_info->fs_mutex);
 
 	ret = btrfs_read_sys_array(tree_root);
-	BUG_ON(ret);
+	if (ret) {
+		printk("btrfs: failed to read the system array on %s\n",
+		       sb->s_id);
+		goto fail_sys_array;
+	}
 
 	blocksize = btrfs_level_size(tree_root,
 				     btrfs_super_chunk_root_level(disk_super));
@@ -1335,8 +1339,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 fail_extent_root:
 	free_extent_buffer(extent_root->node);
 fail_tree_root:
-	mutex_unlock(&fs_info->fs_mutex);
 	free_extent_buffer(tree_root->node);
+fail_sys_array:
+	mutex_unlock(&fs_info->fs_mutex);
 fail_sb_buffer:
 	free_extent_buffer(fs_info->sb_buffer);
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
@@ -1344,6 +1349,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	iput(fs_info->btree_inode);
 fail:
 	close_all_devices(fs_info);
+	btrfs_mapping_tree_free(&fs_info->mapping_tree);
+
 	kfree(extent_root);
 	kfree(tree_root);
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)

commit bcbfce8abd5f8d3f84eab60a9df1ec147f81c34f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 22 13:26:47 2008 -0400

    Btrfs: Fix the unplug_io_fn to grab a consistent copy of page->mapping
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 19c258d2c7e2..1281c393c7e6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -936,14 +936,25 @@ void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 	struct inode *inode;
 	struct extent_map_tree *em_tree;
 	struct extent_map *em;
+	struct address_space *mapping;
 	u64 offset;
 
+	/* the generic O_DIRECT read code does this */
 	if (!page) {
 		__unplug_io_fn(bdi, page);
 		return;
 	}
 
-	inode = page->mapping->host;
+	/*
+	 * page->mapping may change at any time.  Get a consistent copy
+	 * and use that for everything below
+	 */
+	smp_mb();
+	mapping = page->mapping;
+	if (!mapping)
+		return;
+
+	inode = mapping->host;
 	offset = page_offset(page);
 
 	em_tree = &BTRFS_I(inode)->extent_tree;

commit 38b669880df44cba24ab1b01715b87318d469217
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 22 09:22:11 2008 -0400

    Deal with page == NULL in the btrfs_unplug_io_fn
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7f5aca35494d..19c258d2c7e2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -911,12 +911,40 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 	return ret;
 }
 
+/*
+ * this unplugs every device on the box, and it is only used when page
+ * is null
+ */
+static void __unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
+{
+	struct list_head *cur;
+	struct btrfs_device *device;
+	struct btrfs_fs_info *info;
+
+	info = (struct btrfs_fs_info *)bdi->unplug_io_data;
+	list_for_each(cur, &info->fs_devices->devices) {
+		device = list_entry(cur, struct btrfs_device, dev_list);
+		bdi = blk_get_backing_dev_info(device->bdev);
+		if (bdi->unplug_io_fn) {
+			bdi->unplug_io_fn(bdi, page);
+		}
+	}
+}
+
 void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 {
-	struct inode *inode = page->mapping->host;
+	struct inode *inode;
 	struct extent_map_tree *em_tree;
 	struct extent_map *em;
-	u64 offset = page_offset(page);
+	u64 offset;
+
+	if (!page) {
+		__unplug_io_fn(bdi, page);
+		return;
+	}
+
+	inode = page->mapping->host;
+	offset = page_offset(page);
 
 	em_tree = &BTRFS_I(inode)->extent_tree;
 	spin_lock(&em_tree->lock);

commit f2d8d74d7874f8f81222363cd6459a365796e35a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 21 10:03:05 2008 -0400

    Btrfs: Make an unplug function that doesn't unplug every spindle
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c829612c797e..7f5aca35494d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -913,18 +913,22 @@ static int btrfs_congested_fn(void *congested_data, int bdi_bits)
 
 void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 {
-	struct list_head *cur;
-	struct btrfs_device *device;
-	struct btrfs_fs_info *info;
+	struct inode *inode = page->mapping->host;
+	struct extent_map_tree *em_tree;
+	struct extent_map *em;
+	u64 offset = page_offset(page);
 
-	info = (struct btrfs_fs_info *)bdi->unplug_io_data;
-	list_for_each(cur, &info->fs_devices->devices) {
-		device = list_entry(cur, struct btrfs_device, dev_list);
-		bdi = blk_get_backing_dev_info(device->bdev);
-		if (bdi->unplug_io_fn) {
-			bdi->unplug_io_fn(bdi, page);
-		}
-	}
+	em_tree = &BTRFS_I(inode)->extent_tree;
+	spin_lock(&em_tree->lock);
+	em = lookup_extent_mapping(em_tree, offset, PAGE_CACHE_SIZE);
+	spin_unlock(&em_tree->lock);
+	if (!em)
+		return;
+
+	offset = offset - em->start;
+	btrfs_unplug_page(&BTRFS_I(inode)->root->fs_info->mapping_tree,
+			  em->block_start + offset, page);
+	free_extent_map(em);
 }
 
 static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)

commit 4ef64eae288a3644d1f8b748eb075426701e96d1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 21 08:52:50 2008 -0400

    Btrfs: Remove debugging statements from the invalidatepage calls
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 46188ee16623..c829612c797e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -534,7 +534,7 @@ static void btree_invalidatepage(struct page *page, unsigned long offset)
 	extent_invalidatepage(tree, page, offset);
 	btree_releasepage(page, GFP_NOFS);
 	if (PagePrivate(page)) {
-		printk("2invalidate page cleaning up after releasepage\n");
+		invalidate_extent_lru(tree, page_offset(page), PAGE_CACHE_SIZE);
 		ClearPagePrivate(page);
 		set_page_private(page, 0);
 		page_cache_release(page);

commit 4575c9cceeca2f51c50536850e15e1dc5187f3d9
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 18 16:13:31 2008 -0400

    Btrfs: Scale the bdi ra_pages by the number of devices in the FS
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b479cdfe3ee8..46188ee16623 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -932,7 +932,7 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
 	bdi_init(bdi);
 #endif
-	bdi->ra_pages	= default_backing_dev_info.ra_pages * 4;
+	bdi->ra_pages	= default_backing_dev_info.ra_pages;
 	bdi->state		= 0;
 	bdi->capabilities	= default_backing_dev_info.capabilities;
 	bdi->unplug_io_fn	= btrfs_unplug_io_fn;
@@ -1214,6 +1214,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		       (unsigned long long)fs_devices->num_devices);
 		goto fail_sb_buffer;
 	}
+	fs_info->bdi.ra_pages *= btrfs_super_num_devices(disk_super);
+
 	nodesize = btrfs_super_nodesize(disk_super);
 	leafsize = btrfs_super_leafsize(disk_super);
 	sectorsize = btrfs_super_sectorsize(disk_super);

commit 9ad6b7bc2e00ba02f915cffd5b6bcd6564bb2c75
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 18 16:11:30 2008 -0400

    Force page->private removal in btrfs_invalidatepage
    
    btrfs_invalidatepage is not allowed to leave pages around on the lru.
    Any such pages will trigger an oops later on because the VM will see
    page->private and assume it is a buffer head.
    
    This also forces extra flushes of the async work queues before
    dropping all the pages on the btree inode during unmount.  Left over
    items on the work queues are one possible cause of busy state ranges
    during truncate_inode_pages.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9d648f2f41a5..b479cdfe3ee8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -533,6 +533,12 @@ static void btree_invalidatepage(struct page *page, unsigned long offset)
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	extent_invalidatepage(tree, page, offset);
 	btree_releasepage(page, GFP_NOFS);
+	if (PagePrivate(page)) {
+		printk("2invalidate page cleaning up after releasepage\n");
+		ClearPagePrivate(page);
+		set_page_private(page, 0);
+		page_cache_release(page);
+	}
 }
 
 #if 0
@@ -1484,6 +1490,8 @@ int close_ctree(struct btrfs_root *root)
 	write_ctree_super(NULL, root);
 	mutex_unlock(&fs_info->fs_mutex);
 
+	btrfs_transaction_flush_work(root);
+
 	if (fs_info->delalloc_bytes) {
 		printk("btrfs: at unmount delalloc count %Lu\n",
 		       fs_info->delalloc_bytes);
@@ -1514,7 +1522,11 @@ int close_ctree(struct btrfs_root *root)
 	extent_io_tree_empty_lru(&fs_info->extent_ins);
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 
+	flush_workqueue(end_io_workqueue);
+	flush_workqueue(async_submit_workqueue);
+
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
+
 	flush_workqueue(end_io_workqueue);
 	destroy_workqueue(end_io_workqueue);
 

commit 0afbaf8c8216a0de64b55c2d455de2b6c9dde5eb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 18 14:17:20 2008 -0400

    Btrfs: Set the btree inode i_size to OFFSET_MAX
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2de2b00afebc..9d648f2f41a5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -88,19 +88,35 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 		goto out;
 	}
 	em->start = 0;
-	em->len = i_size_read(inode);
+	em->len = (u64)-1;
 	em->block_start = 0;
 	em->bdev = inode->i_sb->s_bdev;
 
 	spin_lock(&em_tree->lock);
 	ret = add_extent_mapping(em_tree, em);
 	if (ret == -EEXIST) {
+		u64 failed_start = em->start;
+		u64 failed_len = em->len;
+
+		printk("failed to insert %Lu %Lu -> %Lu into tree\n",
+		       em->start, em->len, em->block_start);
 		free_extent_map(em);
 		em = lookup_extent_mapping(em_tree, start, len);
-		if (em)
+		if (em) {
+			printk("after failing, found %Lu %Lu %Lu\n",
+			       em->start, em->len, em->block_start);
 			ret = 0;
-		else
+		} else {
+			em = lookup_extent_mapping(em_tree, failed_start,
+						   failed_len);
+			if (em) {
+				printk("double failure lookup gives us "
+				       "%Lu %Lu -> %Lu\n", em->start,
+				       em->len, em->block_start);
+				free_extent_map(em);
+			}
 			ret = -EIO;
+		}
 	} else if (ret) {
 		free_extent_map(em);
 		em = NULL;
@@ -1108,7 +1124,13 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;
-	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
+
+	/*
+	 * we set the i_size on the btree inode to the max possible int.
+	 * the real end of the address space is determined by all of
+	 * the devices in the system
+	 */
+	fs_info->btree_inode->i_size = OFFSET_MAX;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
 	fs_info->btree_inode->i_mapping->backing_dev_info = &fs_info->bdi;
 
@@ -1196,9 +1218,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	tree_root->stripesize = stripesize;
 	sb_set_blocksize(sb, sectorsize);
 
-	i_size_write(fs_info->btree_inode,
-		     btrfs_super_total_bytes(disk_super));
-
 	if (strncmp((char *)(&disk_super->magic), BTRFS_MAGIC,
 		    sizeof(disk_super->magic))) {
 		printk("btrfs: valid FS not found on %s\n", sb->s_id);

commit 7b13b7b119c932a5eca486db4113f4c1fe3b97a8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 18 10:29:50 2008 -0400

    Btrfs: Don't drop extent_map cache during releasepage on the btree inode
    
    The btree inode should only have a single extent_map in the cache,
    it doesn't make sense to ever drop it.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 76ee7a4ae00c..2de2b00afebc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -76,13 +76,12 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 	struct extent_map *em;
 	int ret;
 
-again:
 	spin_lock(&em_tree->lock);
 	em = lookup_extent_mapping(em_tree, start, len);
 	spin_unlock(&em_tree->lock);
-	if (em) {
+	if (em)
 		goto out;
-	}
+
 	em = alloc_extent_map(GFP_NOFS);
 	if (!em) {
 		em = ERR_PTR(-ENOMEM);
@@ -95,15 +94,21 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 
 	spin_lock(&em_tree->lock);
 	ret = add_extent_mapping(em_tree, em);
-	spin_unlock(&em_tree->lock);
-
 	if (ret == -EEXIST) {
 		free_extent_map(em);
-		em = NULL;
-		goto again;
+		em = lookup_extent_mapping(em_tree, start, len);
+		if (em)
+			ret = 0;
+		else
+			ret = -EIO;
 	} else if (ret) {
-		em = ERR_PTR(ret);
+		free_extent_map(em);
+		em = NULL;
 	}
+	spin_unlock(&em_tree->lock);
+
+	if (ret)
+		em = ERR_PTR(ret);
 out:
 	return em;
 }
@@ -496,7 +501,7 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	}
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
-	ret = try_release_extent_mapping(map, tree, page, gfp_flags);
+	ret = try_release_extent_state(map, tree, page, gfp_flags);
 	if (ret == 1) {
 		invalidate_extent_lru(tree, page_offset(page), PAGE_CACHE_SIZE);
 		ClearPagePrivate(page);

commit 7b859fe7cd383fa5e7e379884a748680d0af7bcc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 16 13:06:16 2008 -0400

    Btrfs: Only do async bio submission for pdflush
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9e41ea93ebce..76ee7a4ae00c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -381,6 +381,13 @@ int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
 {
 	struct async_submit_bio *async;
 
+	/*
+	 * inline writerback should stay inline, only hop to the async
+	 * queue if we're pdflush
+	 */
+	if (!current_is_pdflush())
+		return submit_bio_hook(inode, rw, bio, mirror_num);
+
 	async = kmalloc(sizeof(*async), GFP_NOFS);
 	if (!async)
 		return -ENOMEM;

commit 44b8bd7edda4f63de180d0f7325c9fb704b3806b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 16 11:14:51 2008 -0400

    Btrfs: Create a work queue for bio writes
    
    This allows checksumming to happen in parallel among many cpus, and
    keeps us from bogging down pdflush with the checksumming code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 79c284c87286..9e41ea93ebce 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -47,6 +47,7 @@ static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
 
 static struct extent_io_ops btree_extent_io_ops;
 static struct workqueue_struct *end_io_workqueue;
+static struct workqueue_struct *async_submit_workqueue;
 
 struct end_io_wq {
 	struct bio *bio;
@@ -58,6 +59,15 @@ struct end_io_wq {
 	struct list_head list;
 };
 
+struct async_submit_bio {
+	struct inode *inode;
+	struct bio *bio;
+	struct list_head list;
+	extent_submit_bio_hook_t *submit_bio_hook;
+	int rw;
+	int mirror_num;
+};
+
 struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 				    size_t page_offset, u64 start, u64 len,
 				    int create)
@@ -365,7 +375,31 @@ int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 	return 0;
 }
 
-static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
+int btrfs_wq_submit_bio(struct btrfs_fs_info *fs_info, struct inode *inode,
+			int rw, struct bio *bio, int mirror_num,
+			extent_submit_bio_hook_t *submit_bio_hook)
+{
+	struct async_submit_bio *async;
+
+	async = kmalloc(sizeof(*async), GFP_NOFS);
+	if (!async)
+		return -ENOMEM;
+
+	async->inode = inode;
+	async->rw = rw;
+	async->bio = bio;
+	async->mirror_num = mirror_num;
+	async->submit_bio_hook = submit_bio_hook;
+
+	spin_lock(&fs_info->async_submit_work_lock);
+	list_add_tail(&async->list, &fs_info->async_submit_work_list);
+	spin_unlock(&fs_info->async_submit_work_lock);
+
+	queue_work(async_submit_workqueue, &fs_info->async_submit_work);
+	return 0;
+}
+
+static int __btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 				 int mirror_num)
 {
 	struct btrfs_root *root = BTRFS_I(inode)->root;
@@ -389,6 +423,17 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num);
 }
 
+static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
+				 int mirror_num)
+{
+	if (!(rw & (1 << BIO_RW))) {
+		return __btree_submit_bio_hook(inode, rw, bio, mirror_num);
+	}
+	return btrfs_wq_submit_bio(BTRFS_I(inode)->root->fs_info,
+				   inode, rw, bio, mirror_num,
+				   __btree_submit_bio_hook);
+}
+
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct extent_io_tree *tree;
@@ -903,9 +948,9 @@ static int bio_ready_for_csum(struct bio *bio)
 }
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-void btrfs_end_io_csum(void *p)
+static void btrfs_end_io_csum(void *p)
 #else
-void btrfs_end_io_csum(struct work_struct *work)
+static void btrfs_end_io_csum(struct work_struct *work)
 #endif
 {
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
@@ -959,6 +1004,39 @@ void btrfs_end_io_csum(struct work_struct *work)
 	}
 }
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+static void btrfs_async_submit_work(void *p)
+#else
+static void btrfs_async_submit_work(struct work_struct *work)
+#endif
+{
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+	struct btrfs_fs_info *fs_info = p;
+#else
+	struct btrfs_fs_info *fs_info = container_of(work,
+						     struct btrfs_fs_info,
+						     async_submit_work);
+#endif
+	struct async_submit_bio *async;
+	struct list_head *next;
+
+	while(1) {
+		spin_lock(&fs_info->async_submit_work_lock);
+		if (list_empty(&fs_info->async_submit_work_list)) {
+			spin_unlock(&fs_info->async_submit_work_lock);
+			return;
+		}
+		next = fs_info->async_submit_work_list.next;
+		list_del(next);
+		spin_unlock(&fs_info->async_submit_work_lock);
+
+		async = list_entry(next, struct async_submit_bio, list);
+		async->submit_bio_hook(async->inode, async->rw, async->bio,
+				       async->mirror_num);
+		kfree(async);
+	}
+}
+
 struct btrfs_root *open_ctree(struct super_block *sb,
 			      struct btrfs_fs_devices *fs_devices)
 {
@@ -987,14 +1065,17 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	}
 	end_io_workqueue = create_workqueue("btrfs-end-io");
 	BUG_ON(!end_io_workqueue);
+	async_submit_workqueue = create_workqueue("btrfs-async-submit");
 
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->hashers);
 	INIT_LIST_HEAD(&fs_info->end_io_work_list);
+	INIT_LIST_HEAD(&fs_info->async_submit_work_list);
 	spin_lock_init(&fs_info->hash_lock);
 	spin_lock_init(&fs_info->end_io_work_lock);
+	spin_lock_init(&fs_info->async_submit_work_lock);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);
 
@@ -1041,9 +1122,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	INIT_WORK(&fs_info->end_io_work, btrfs_end_io_csum, fs_info);
+	INIT_WORK(&fs_info->async_submit_work, btrfs_async_submit_work,
+		  fs_info);
 	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);
 #else
 	INIT_WORK(&fs_info->end_io_work, btrfs_end_io_csum);
+	INIT_WORK(&fs_info->async_submit_work, btrfs_async_submit_work);
 	INIT_DELAYED_WORK(&fs_info->trans_work, btrfs_transaction_cleaner);
 #endif
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
@@ -1403,6 +1487,9 @@ int close_ctree(struct btrfs_root *root)
 	flush_workqueue(end_io_workqueue);
 	destroy_workqueue(end_io_workqueue);
 
+	flush_workqueue(async_submit_workqueue);
+	destroy_workqueue(async_submit_workqueue);
+
 	iput(fs_info->btree_inode);
 #if 0
 	while(!list_empty(&fs_info->hashers)) {

commit e17cade25ff8074101d653557a78df09c16ca276
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 15 15:41:47 2008 -0400

    Btrfs: Add chunk uuids and update multi-device back references
    
    Block headers now store the chunk tree uuid
    
    Chunk items records the device uuid for each stripes
    
    Device extent items record better back refs to the chunk tree
    
    Block groups record better back refs to the chunk tree
    
    The chunk tree format has also changed.  The objectid of BTRFS_CHUNK_ITEM_KEY
    used to be the logical offset of the chunk.  Now it is a chunk tree id,
    with the logical offset being stored in the offset field of the key.
    
    This allows a single chunk tree to record multiple logical address spaces,
    upping the number of bytes indexed by a chunk tree from 2^64 to
    2^128.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9c94dddde704..79c284c87286 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1125,6 +1125,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 					   blocksize);
 	BUG_ON(!chunk_root->node);
 
+	read_extent_buffer(chunk_root->node, fs_info->chunk_tree_uuid,
+	         (unsigned long)btrfs_header_chunk_tree_uuid(chunk_root->node),
+		 BTRFS_UUID_SIZE);
+
 	ret = btrfs_read_chunk_tree(chunk_root);
 	BUG_ON(ret);
 
@@ -1229,7 +1233,7 @@ int write_all_supers(struct btrfs_root *root)
 		btrfs_set_device_sector_size(sb, dev_item, dev->sector_size);
 		write_extent_buffer(sb, dev->uuid,
 				    (unsigned long)btrfs_device_uuid(dev_item),
-				    BTRFS_DEV_UUID_SIZE);
+				    BTRFS_UUID_SIZE);
 
 		btrfs_set_header_flag(sb, BTRFS_HEADER_FLAG_WRITTEN);
 		csum_tree_block(root, sb, 0);

commit b248a4152956cbae1b23f4c70ef5b51d6ea2ecfb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 14 09:48:18 2008 -0400

    Btrfs: A few updates for 2.6.18 and versions older than 2.6.25
    
    This includes fixing a missing spinlock init call that caused oops on mount
    for most kernels other than 2.6.25.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aebe8c21ec80..9c94dddde704 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -850,7 +850,9 @@ void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 
 static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
 	bdi_init(bdi);
+#endif
 	bdi->ra_pages	= default_backing_dev_info.ra_pages * 4;
 	bdi->state		= 0;
 	bdi->capabilities	= default_backing_dev_info.capabilities;
@@ -950,7 +952,7 @@ void btrfs_end_io_csum(struct work_struct *work)
 		bio->bi_end_io = end_io_wq->end_io;
 		kfree(end_io_wq);
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
-		bio_endio(bio, bio->bi_size, err);
+		bio_endio(bio, bio->bi_size, error);
 #else
 		bio_endio(bio, error);
 #endif
@@ -1037,10 +1039,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 
-	INIT_WORK(&fs_info->end_io_work, btrfs_end_io_csum);
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+	INIT_WORK(&fs_info->end_io_work, btrfs_end_io_csum, fs_info);
 	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);
 #else
+	INIT_WORK(&fs_info->end_io_work, btrfs_end_io_csum);
 	INIT_DELAYED_WORK(&fs_info->trans_work, btrfs_transaction_cleaner);
 #endif
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
@@ -1173,7 +1176,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	close_all_devices(fs_info);
 	kfree(extent_root);
 	kfree(tree_root);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
 	bdi_destroy(&fs_info->bdi);
+#endif
 	kfree(fs_info);
 	return ERR_PTR(err);
 }
@@ -1407,7 +1412,10 @@ int close_ctree(struct btrfs_root *root)
 #endif
 	close_all_devices(fs_info);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,23)
 	bdi_destroy(&fs_info->bdi);
+#endif
 
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);

commit 73f61b2a6459df982cb4faf0e5cf5ac8b153aaff
Author: Miguel <miguel.filipe@gmail.com>
Date:   Fri Apr 11 15:50:59 2008 -0400

    Btrfs: bio_endio support for linux 2.6.23 and older.
    
    bio_endio() changed prototype on linux 2.6.24, support older kernels
    using the older prototype.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0bfcc31d94d7..aebe8c21ec80 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -949,11 +949,14 @@ void btrfs_end_io_csum(struct work_struct *work)
 		bio->bi_private = end_io_wq->private;
 		bio->bi_end_io = end_io_wq->end_io;
 		kfree(end_io_wq);
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
+		bio_endio(bio, bio->bi_size, err);
+#else
 		bio_endio(bio, error);
+#endif
 	}
 }
 
-
 struct btrfs_root *open_ctree(struct super_block *sb,
 			      struct btrfs_fs_devices *fs_devices)
 {

commit a5eb62e345fc1818d0d8b6181463200a9e8dfe39
Author: Miguel <miguel.filipe@gmail.com>
Date:   Fri Apr 11 15:45:51 2008 -0400

    Btrfs: Endianess bug fix for v0.13 with kernels
    
    Fix for a endianess BUG when using btrfs v0.13 with kernels older than 2.6.23
    
    Problem:
    
    Has of v0.13, btrfs-progs is using crc32c.c equivalent to the one found on
    linux-2.6.23/lib/libcrc32c.c Since crc32c_le() changed in linux-2.6.23, when
    running btrfs v0.13 with older kernels we have a missmatch between the versions
    of crc32c_le() from btrfs-progs and libcrc32c in the kernel.  This missmatch
    causes a bug when using btrfs on big endian machines.
    
    Solution:
    btrfs_crc32c() macro that when compiling for kernels older than 2.6.23, does
    endianess conversion to parameters and return value of crc32c().
    This endianess conversion nullifies the differences in implementation
    of crc32c_le().
    If kernel 2.6.23 or better, it calls crc32c().
    
    Signed-off-by: Miguel Sousa Filipe <miguel.filipe@gmail.com>
    ---
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e22960e23501..0bfcc31d94d7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -18,13 +18,13 @@
 
 #include <linux/fs.h>
 #include <linux/blkdev.h>
-#include <linux/crc32c.h>
 #include <linux/scatterlist.h>
 #include <linux/swap.h>
 #include <linux/radix-tree.h>
 #include <linux/writeback.h>
 #include <linux/buffer_head.h> // for block_sync_page
 #include <linux/workqueue.h>
+#include "crc32c.h"
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -100,7 +100,7 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 
 u32 btrfs_csum_data(struct btrfs_root *root, char *data, u32 seed, size_t len)
 {
-	return crc32c(seed, data, len);
+	return btrfs_crc32c(seed, data, len);
 }
 
 void btrfs_csum_final(u32 crc, char *result)

commit 3dd39914bc0737d055c780d29c20a1d117819cdb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 11 10:51:07 2008 -0400

    Btrfs: Add extra checks to avoid removing extent_state from pages we can't free
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cf1de75f088a..e22960e23501 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -436,6 +436,12 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	struct extent_map_tree *map;
 	int ret;
 
+	if (page_count(page) > 3) {
+		/* once for page->private, once for the caller, once
+		 * once for the page cache
+		 */
+		return 0;
+	}
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
 	ret = try_release_extent_mapping(map, tree, page, gfp_flags);

commit f29844623de29a12358d7fba35d0959465b64adf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 10 16:19:33 2008 -0400

    Btrfs: Write out all super blocks on commit, and bring back proper barrier support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 59bdf0474be3..cf1de75f088a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -382,7 +382,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
 	BUG_ON(ret);
 
 	if (offset == BTRFS_SUPER_INFO_OFFSET) {
-		bio->bi_bdev = root->fs_info->sb->s_bdev;
+		bio->bi_bdev = root->fs_info->fs_devices->latest_bdev;
 		submit_bio(rw, bio);
 		return 0;
 	}
@@ -988,7 +988,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->new_trans_lock);
 
 	init_completion(&fs_info->kobj_unregister);
-	sb_set_blocksize(sb, 4096);
+	sb_set_blocksize(sb, BTRFS_SUPER_INFO_SIZE);
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
 	fs_info->chunk_root = chunk_root;
@@ -1169,14 +1169,121 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	return ERR_PTR(err);
 }
 
+static void btrfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
+{
+	char b[BDEVNAME_SIZE];
+
+	if (uptodate) {
+		set_buffer_uptodate(bh);
+	} else {
+		if (!buffer_eopnotsupp(bh) && printk_ratelimit()) {
+			printk(KERN_WARNING "lost page write due to "
+					"I/O error on %s\n",
+				       bdevname(bh->b_bdev, b));
+		}
+		set_buffer_write_io_error(bh);
+		clear_buffer_uptodate(bh);
+	}
+	unlock_buffer(bh);
+	put_bh(bh);
+}
+
+int write_all_supers(struct btrfs_root *root)
+{
+	struct list_head *cur;
+	struct list_head *head = &root->fs_info->fs_devices->devices;
+	struct btrfs_device *dev;
+	struct extent_buffer *sb;
+	struct btrfs_dev_item *dev_item;
+	struct buffer_head *bh;
+	int ret;
+	int do_barriers;
+
+	do_barriers = !btrfs_test_opt(root, NOBARRIER);
+
+	sb = root->fs_info->sb_buffer;
+	dev_item = (struct btrfs_dev_item *)offsetof(struct btrfs_super_block,
+						      dev_item);
+	list_for_each(cur, head) {
+		dev = list_entry(cur, struct btrfs_device, dev_list);
+		btrfs_set_device_type(sb, dev_item, dev->type);
+		btrfs_set_device_id(sb, dev_item, dev->devid);
+		btrfs_set_device_total_bytes(sb, dev_item, dev->total_bytes);
+		btrfs_set_device_bytes_used(sb, dev_item, dev->bytes_used);
+		btrfs_set_device_io_align(sb, dev_item, dev->io_align);
+		btrfs_set_device_io_width(sb, dev_item, dev->io_width);
+		btrfs_set_device_sector_size(sb, dev_item, dev->sector_size);
+		write_extent_buffer(sb, dev->uuid,
+				    (unsigned long)btrfs_device_uuid(dev_item),
+				    BTRFS_DEV_UUID_SIZE);
+
+		btrfs_set_header_flag(sb, BTRFS_HEADER_FLAG_WRITTEN);
+		csum_tree_block(root, sb, 0);
+
+		bh = __getblk(dev->bdev, BTRFS_SUPER_INFO_OFFSET /
+			      root->fs_info->sb->s_blocksize,
+			      BTRFS_SUPER_INFO_SIZE);
+
+		read_extent_buffer(sb, bh->b_data, 0, BTRFS_SUPER_INFO_SIZE);
+		dev->pending_io = bh;
+
+		get_bh(bh);
+		set_buffer_uptodate(bh);
+		lock_buffer(bh);
+		bh->b_end_io = btrfs_end_buffer_write_sync;
+
+		if (do_barriers && dev->barriers) {
+			ret = submit_bh(WRITE_BARRIER, bh);
+			if (ret == -EOPNOTSUPP) {
+				printk("btrfs: disabling barriers on dev %s\n",
+				       dev->name);
+				set_buffer_uptodate(bh);
+				dev->barriers = 0;
+				get_bh(bh);
+				lock_buffer(bh);
+				ret = submit_bh(WRITE, bh);
+			}
+		} else {
+			ret = submit_bh(WRITE, bh);
+		}
+		BUG_ON(ret);
+	}
+
+	list_for_each(cur, head) {
+		dev = list_entry(cur, struct btrfs_device, dev_list);
+		BUG_ON(!dev->pending_io);
+		bh = dev->pending_io;
+		wait_on_buffer(bh);
+		if (!buffer_uptodate(dev->pending_io)) {
+			if (do_barriers && dev->barriers) {
+				printk("btrfs: disabling barriers on dev %s\n",
+				       dev->name);
+				set_buffer_uptodate(bh);
+				get_bh(bh);
+				lock_buffer(bh);
+				dev->barriers = 0;
+				ret = submit_bh(WRITE, bh);
+				BUG_ON(ret);
+				wait_on_buffer(bh);
+				BUG_ON(!buffer_uptodate(bh));
+			} else {
+				BUG();
+			}
+
+		}
+		dev->pending_io = NULL;
+		brelse(bh);
+	}
+	return 0;
+}
+
 int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root)
 {
 	int ret;
-	struct extent_buffer *super = root->fs_info->sb_buffer;
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	struct super_block *sb = root->fs_info->sb;
 
+	ret = write_all_supers(root);
+#if 0
 	if (!btrfs_test_opt(root, NOBARRIER))
 		blkdev_issue_flush(sb->s_bdev, NULL);
 	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree, super);
@@ -1184,6 +1291,7 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 				     super->start, super->len);
 	if (!btrfs_test_opt(root, NOBARRIER))
 		blkdev_issue_flush(sb->s_bdev, NULL);
+#endif
 	return ret;
 }
 

commit f188591e987e21b6f7f8864c66a02858b95b530e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 9 16:28:12 2008 -0400

    Btrfs: Retry metadata reads in the face of checksum failures
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 94ff87d0eae4..59bdf0474be3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -156,7 +156,6 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			memcpy(&found, result, BTRFS_CRC32_SIZE);
 
 			read_extent_buffer(buf, &val, 0, BTRFS_CRC32_SIZE);
-			WARN_ON(1);
 			printk("btrfs: %s checksum verify failed on %llu "
 			       "wanted %X found %X from_this_trans %d "
 			       "level %d\n",
@@ -171,6 +170,40 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	return 0;
 }
 
+static int btree_read_extent_buffer_pages(struct btrfs_root *root,
+					  struct extent_buffer *eb,
+					  u64 start)
+{
+	struct extent_io_tree *io_tree;
+	int ret;
+	int num_copies = 0;
+	int mirror_num = 0;
+
+	io_tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
+	while (1) {
+		ret = read_extent_buffer_pages(io_tree, eb, start, 1,
+					       btree_get_extent, mirror_num);
+		if (!ret) {
+			if (mirror_num)
+printk("good read %Lu mirror %d total %d\n", eb->start, mirror_num, num_copies);
+			return ret;
+		}
+		num_copies = btrfs_num_copies(&root->fs_info->mapping_tree,
+					      eb->start, eb->len);
+printk("failed to read %Lu mirror %d total %d\n", eb->start, mirror_num, num_copies);
+		if (num_copies == 1) {
+printk("reading %Lu failed only one copy\n", eb->start);
+			return ret;
+		}
+		mirror_num++;
+		if (mirror_num > num_copies) {
+printk("bailing at mirror %d of %d\n", mirror_num, num_copies);
+			return ret;
+		}
+	}
+printk("read extent buffer page last\n");
+	return -EIO;
+}
 
 int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 {
@@ -180,6 +213,8 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	int found_level;
 	unsigned long len;
 	struct extent_buffer *eb;
+	int ret;
+
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 
 	if (page->private == EXTENT_PAGE_PRIVATE)
@@ -191,8 +226,8 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 		WARN_ON(1);
 	}
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
-	read_extent_buffer_pages(tree, eb, start + PAGE_CACHE_SIZE, 1,
-				 btree_get_extent);
+	ret = btree_read_extent_buffer_pages(root, eb, start + PAGE_CACHE_SIZE);
+	BUG_ON(ret);
 	btrfs_clear_buffer_defrag(eb);
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
@@ -240,7 +275,7 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 	unsigned long len;
 	struct extent_buffer *eb;
 	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
-	int ret;
+	int ret = 0;
 
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	if (page->private == EXTENT_PAGE_PRIVATE)
@@ -252,25 +287,26 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 		WARN_ON(1);
 	}
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
-	read_extent_buffer_pages(tree, eb, start + PAGE_CACHE_SIZE, 1,
-				 btree_get_extent);
+
 	btrfs_clear_buffer_defrag(eb);
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
-		printk("warning: eb start incorrect %Lu buffer %Lu len %lu\n",
-		       start, found_start, len);
-		WARN_ON(1);
+printk("bad start on %Lu found %Lu\n", eb->start, found_start);
+		ret = -EIO;
 		goto err;
 	}
 	if (eb->first_page != page) {
 		printk("bad first page %lu %lu\n", eb->first_page->index,
 		       page->index);
 		WARN_ON(1);
+		ret = -EIO;
 		goto err;
 	}
 	found_level = btrfs_header_level(eb);
 
 	ret = csum_tree_block(root, eb, 1);
+	if (ret)
+		ret = -EIO;
 
 	end = min_t(u64, eb->len, PAGE_CACHE_SIZE);
 	end = eb->start + end - 1;
@@ -278,7 +314,7 @@ int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
 err:
 	free_extent_buffer(eb);
 out:
-	return 0;
+	return ret;
 }
 
 #if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)
@@ -329,7 +365,8 @@ int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
 	return 0;
 }
 
-static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio)
+static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio,
+				 int mirror_num)
 {
 	struct btrfs_root *root = BTRFS_I(inode)->root;
 	u64 offset;
@@ -338,7 +375,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio)
 	offset = bio->bi_sector << 9;
 
 	if (rw & (1 << BIO_RW)) {
-		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio);
+		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num);
 	}
 
 	ret = btrfs_bio_wq_end_io(root->fs_info, bio, 1);
@@ -349,7 +386,7 @@ static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio)
 		submit_bio(rw, bio);
 		return 0;
 	}
-	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio);
+	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio, mirror_num);
 }
 
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
@@ -459,7 +496,7 @@ int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
 	if (!buf)
 		return 0;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
-				 buf, 0, 0, btree_get_extent);
+				 buf, 0, 0, btree_get_extent, 0);
 	free_extent_buffer(buf);
 	return ret;
 }
@@ -522,8 +559,7 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 	if (!buf)
 		return NULL;
 
-	ret = read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf, 0,
-				       1, btree_get_extent);
+	ret = btree_read_extent_buffer_pages(root, buf, 0);
 
 	if (ret == 0) {
 		buf->flags |= EXTENT_UPTODATE;
@@ -1366,10 +1402,8 @@ int btrfs_clear_buffer_defrag(struct extent_buffer *buf)
 int btrfs_read_buffer(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
-	struct inode *btree_inode = root->fs_info->btree_inode;
 	int ret;
-	ret = read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
-					buf, 0, 1, btree_get_extent);
+	ret = btree_read_extent_buffer_pages(root, buf, 0);
 	if (ret == 0) {
 		buf->flags |= EXTENT_UPTODATE;
 	}

commit 22c599485b1fdd95e4476a4752596a6cf6c6629a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 9 16:28:12 2008 -0400

    Btrfs: Handle data block end_io through the async work queue
    
    Before it was done by the bio end_io routine, the work queue code is able
    to scale much better with faster IO subsystems.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 82109204788c..94ff87d0eae4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -54,6 +54,7 @@ struct end_io_wq {
 	void *private;
 	struct btrfs_fs_info *info;
 	int error;
+	int metadata;
 	struct list_head list;
 };
 
@@ -308,29 +309,40 @@ static int end_workqueue_bio(struct bio *bio,
 #endif
 }
 
-static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio)
+int btrfs_bio_wq_end_io(struct btrfs_fs_info *info, struct bio *bio,
+			int metadata)
 {
-	struct btrfs_root *root = BTRFS_I(inode)->root;
 	struct end_io_wq *end_io_wq;
-	u64 offset;
-	offset = bio->bi_sector << 9;
-
-	if (rw & (1 << BIO_RW)) {
-		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio);
-	}
-
 	end_io_wq = kmalloc(sizeof(*end_io_wq), GFP_NOFS);
 	if (!end_io_wq)
 		return -ENOMEM;
 
 	end_io_wq->private = bio->bi_private;
 	end_io_wq->end_io = bio->bi_end_io;
-	end_io_wq->info = root->fs_info;
+	end_io_wq->info = info;
 	end_io_wq->error = 0;
 	end_io_wq->bio = bio;
+	end_io_wq->metadata = metadata;
 
 	bio->bi_private = end_io_wq;
 	bio->bi_end_io = end_workqueue_bio;
+	return 0;
+}
+
+static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio)
+{
+	struct btrfs_root *root = BTRFS_I(inode)->root;
+	u64 offset;
+	int ret;
+
+	offset = bio->bi_sector << 9;
+
+	if (rw & (1 << BIO_RW)) {
+		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio);
+	}
+
+	ret = btrfs_bio_wq_end_io(root->fs_info, bio, 1);
+	BUG_ON(ret);
 
 	if (offset == BTRFS_SUPER_INFO_OFFSET) {
 		bio->bi_bdev = root->fs_info->sb->s_bdev;
@@ -880,7 +892,7 @@ void btrfs_end_io_csum(struct work_struct *work)
 		end_io_wq = list_entry(next, struct end_io_wq, list);
 
 		bio = end_io_wq->bio;
-		if (!bio_ready_for_csum(bio)) {
+		if (end_io_wq->metadata && !bio_ready_for_csum(bio)) {
 			spin_lock_irqsave(&fs_info->end_io_work_lock, flags);
 			was_empty = list_empty(&fs_info->end_io_work_list);
 			list_add_tail(&end_io_wq->list,

commit ce9adaa5a792c2099a83246265eb4055bc38b6b8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 9 16:28:12 2008 -0400

    Btrfs: Do metadata checksums for reads via a workqueue
    
    Before, metadata checksumming was done by the callers of read_tree_block,
    which would set EXTENT_CSUM bits in the extent tree to show that a given
    range of pages was already checksummed and didn't need to be verified
    again.
    
    But, those bits could go away via try_to_releasepage, and the end
    result was bogus checksum failures on pages that never left the cache.
    
    The new code validates checksums when the page is read.  It is a little
    tricky because metadata blocks can span pages and a single read may
    end up going via multiple bios.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e444b99e02da..82109204788c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -24,6 +24,7 @@
 #include <linux/radix-tree.h>
 #include <linux/writeback.h>
 #include <linux/buffer_head.h> // for block_sync_page
+#include <linux/workqueue.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -45,6 +46,16 @@ static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
 #endif
 
 static struct extent_io_ops btree_extent_io_ops;
+static struct workqueue_struct *end_io_workqueue;
+
+struct end_io_wq {
+	struct bio *bio;
+	bio_end_io_t *end_io;
+	void *private;
+	struct btrfs_fs_info *info;
+	int error;
+	struct list_head list;
+};
 
 struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 				    size_t page_offset, u64 start, u64 len,
@@ -219,11 +230,108 @@ static int btree_writepage_io_hook(struct page *page, u64 start, u64 end)
 	return 0;
 }
 
+int btree_readpage_end_io_hook(struct page *page, u64 start, u64 end,
+			       struct extent_state *state)
+{
+	struct extent_io_tree *tree;
+	u64 found_start;
+	int found_level;
+	unsigned long len;
+	struct extent_buffer *eb;
+	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
+	int ret;
+
+	tree = &BTRFS_I(page->mapping->host)->io_tree;
+	if (page->private == EXTENT_PAGE_PRIVATE)
+		goto out;
+	if (!page->private)
+		goto out;
+	len = page->private >> 2;
+	if (len == 0) {
+		WARN_ON(1);
+	}
+	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
+	read_extent_buffer_pages(tree, eb, start + PAGE_CACHE_SIZE, 1,
+				 btree_get_extent);
+	btrfs_clear_buffer_defrag(eb);
+	found_start = btrfs_header_bytenr(eb);
+	if (found_start != start) {
+		printk("warning: eb start incorrect %Lu buffer %Lu len %lu\n",
+		       start, found_start, len);
+		WARN_ON(1);
+		goto err;
+	}
+	if (eb->first_page != page) {
+		printk("bad first page %lu %lu\n", eb->first_page->index,
+		       page->index);
+		WARN_ON(1);
+		goto err;
+	}
+	found_level = btrfs_header_level(eb);
+
+	ret = csum_tree_block(root, eb, 1);
+
+	end = min_t(u64, eb->len, PAGE_CACHE_SIZE);
+	end = eb->start + end - 1;
+	release_extent_buffer_tail_pages(eb);
+err:
+	free_extent_buffer(eb);
+out:
+	return 0;
+}
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)
+static void end_workqueue_bio(struct bio *bio, int err)
+#else
+static int end_workqueue_bio(struct bio *bio,
+				   unsigned int bytes_done, int err)
+#endif
+{
+	struct end_io_wq *end_io_wq = bio->bi_private;
+	struct btrfs_fs_info *fs_info;
+	unsigned long flags;
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
+	if (bio->bi_size)
+		return 1;
+#endif
+
+	fs_info = end_io_wq->info;
+	spin_lock_irqsave(&fs_info->end_io_work_lock, flags);
+	end_io_wq->error = err;
+	list_add_tail(&end_io_wq->list, &fs_info->end_io_work_list);
+	spin_unlock_irqrestore(&fs_info->end_io_work_lock, flags);
+	queue_work(end_io_workqueue, &fs_info->end_io_work);
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
+	return 0;
+#endif
+}
+
 static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio)
 {
 	struct btrfs_root *root = BTRFS_I(inode)->root;
+	struct end_io_wq *end_io_wq;
 	u64 offset;
 	offset = bio->bi_sector << 9;
+
+	if (rw & (1 << BIO_RW)) {
+		return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio);
+	}
+
+	end_io_wq = kmalloc(sizeof(*end_io_wq), GFP_NOFS);
+	if (!end_io_wq)
+		return -ENOMEM;
+
+	end_io_wq->private = bio->bi_private;
+	end_io_wq->end_io = bio->bi_end_io;
+	end_io_wq->info = root->fs_info;
+	end_io_wq->error = 0;
+	end_io_wq->bio = bio;
+
+	bio->bi_private = end_io_wq;
+	bio->bi_end_io = end_workqueue_bio;
+
 	if (offset == BTRFS_SUPER_INFO_OFFSET) {
 		bio->bi_bdev = root->fs_info->sb->s_bdev;
 		submit_bio(rw, bio);
@@ -363,36 +471,7 @@ static int close_all_devices(struct btrfs_fs_info *fs_info)
 int btrfs_verify_block_csum(struct btrfs_root *root,
 			    struct extent_buffer *buf)
 {
-	struct extent_io_tree *io_tree;
-	u64 end;
-	int ret;
-
-	io_tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
-	if (buf->flags & EXTENT_CSUM)
-		return 0;
-
-	end = min_t(u64, buf->len, PAGE_CACHE_SIZE);
-	end = buf->start + end - 1;
-	if (test_range_bit(io_tree, buf->start, end, EXTENT_CSUM, 1)) {
-		buf->flags |= EXTENT_CSUM;
-		return 0;
-	}
-	lock_extent(io_tree, buf->start, end, GFP_NOFS);
-
-	if (test_range_bit(io_tree, buf->start, end, EXTENT_CSUM, 1)) {
-		buf->flags |= EXTENT_CSUM;
-		ret = 0;
-		goto out_unlock;
-	}
-WARN_ON(buf->flags & EXTENT_CSUM);
-
-	ret = csum_tree_block(root, buf, 1);
-	set_extent_bits(io_tree, buf->start, end, EXTENT_CSUM, GFP_NOFS);
-	buf->flags |= EXTENT_CSUM;
-
-out_unlock:
-	unlock_extent(io_tree, buf->start, end, GFP_NOFS);
-	return ret;
+	return btrfs_buffer_uptodate(buf);
 }
 
 struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
@@ -430,11 +509,15 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
 	if (!buf)
 		return NULL;
-	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf, 0, 1,
-				 btree_get_extent);
 
-	ret = btrfs_verify_block_csum(root, buf);
+	ret = read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf, 0,
+				       1, btree_get_extent);
+
+	if (ret == 0) {
+		buf->flags |= EXTENT_UPTODATE;
+	}
 	return buf;
+
 }
 
 int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
@@ -724,6 +807,99 @@ static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 	return 0;
 }
 
+static int bio_ready_for_csum(struct bio *bio)
+{
+	u64 length = 0;
+	u64 buf_len = 0;
+	u64 start = 0;
+	struct page *page;
+	struct extent_io_tree *io_tree = NULL;
+	struct btrfs_fs_info *info = NULL;
+	struct bio_vec *bvec;
+	int i;
+	int ret;
+
+	bio_for_each_segment(bvec, bio, i) {
+		page = bvec->bv_page;
+		if (page->private == EXTENT_PAGE_PRIVATE) {
+			length += bvec->bv_len;
+			continue;
+		}
+		if (!page->private) {
+			length += bvec->bv_len;
+			continue;
+		}
+		length = bvec->bv_len;
+		buf_len = page->private >> 2;
+		start = page_offset(page) + bvec->bv_offset;
+		io_tree = &BTRFS_I(page->mapping->host)->io_tree;
+		info = BTRFS_I(page->mapping->host)->root->fs_info;
+	}
+	/* are we fully contained in this bio? */
+	if (buf_len <= length)
+		return 1;
+
+	ret = extent_range_uptodate(io_tree, start + length,
+				    start + buf_len - 1);
+	if (ret == 1)
+		return ret;
+	return ret;
+}
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+void btrfs_end_io_csum(void *p)
+#else
+void btrfs_end_io_csum(struct work_struct *work)
+#endif
+{
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+	struct btrfs_fs_info *fs_info = p;
+#else
+	struct btrfs_fs_info *fs_info = container_of(work,
+						     struct btrfs_fs_info,
+						     end_io_work);
+#endif
+	unsigned long flags;
+	struct end_io_wq *end_io_wq;
+	struct bio *bio;
+	struct list_head *next;
+	int error;
+	int was_empty;
+
+	while(1) {
+		spin_lock_irqsave(&fs_info->end_io_work_lock, flags);
+		if (list_empty(&fs_info->end_io_work_list)) {
+			spin_unlock_irqrestore(&fs_info->end_io_work_lock,
+					       flags);
+			return;
+		}
+		next = fs_info->end_io_work_list.next;
+		list_del(next);
+		spin_unlock_irqrestore(&fs_info->end_io_work_lock, flags);
+
+		end_io_wq = list_entry(next, struct end_io_wq, list);
+
+		bio = end_io_wq->bio;
+		if (!bio_ready_for_csum(bio)) {
+			spin_lock_irqsave(&fs_info->end_io_work_lock, flags);
+			was_empty = list_empty(&fs_info->end_io_work_list);
+			list_add_tail(&end_io_wq->list,
+				      &fs_info->end_io_work_list);
+			spin_unlock_irqrestore(&fs_info->end_io_work_lock,
+					       flags);
+			if (was_empty)
+				return;
+			continue;
+		}
+		error = end_io_wq->error;
+		bio->bi_private = end_io_wq->private;
+		bio->bi_end_io = end_io_wq->end_io;
+		kfree(end_io_wq);
+		bio_endio(bio, error);
+	}
+}
+
+
 struct btrfs_root *open_ctree(struct super_block *sb,
 			      struct btrfs_fs_devices *fs_devices)
 {
@@ -750,11 +926,16 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 		err = -ENOMEM;
 		goto fail;
 	}
+	end_io_workqueue = create_workqueue("btrfs-end-io");
+	BUG_ON(!end_io_workqueue);
+
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->hashers);
+	INIT_LIST_HEAD(&fs_info->end_io_work_list);
 	spin_lock_init(&fs_info->hash_lock);
+	spin_lock_init(&fs_info->end_io_work_lock);
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);
 
@@ -799,6 +980,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 
+	INIT_WORK(&fs_info->end_io_work, btrfs_end_io_csum);
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);
 #else
@@ -1044,6 +1226,8 @@ int close_ctree(struct btrfs_root *root)
 	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
+	flush_workqueue(end_io_workqueue);
+	destroy_workqueue(end_io_workqueue);
 
 	iput(fs_info->btree_inode);
 #if 0
@@ -1171,12 +1355,18 @@ int btrfs_read_buffer(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	return read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
+	int ret;
+	ret = read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
 					buf, 0, 1, btree_get_extent);
+	if (ret == 0) {
+		buf->flags |= EXTENT_UPTODATE;
+	}
+	return ret;
 }
 
 static struct extent_io_ops btree_extent_io_ops = {
 	.writepage_io_hook = btree_writepage_io_hook,
+	.readpage_end_io_hook = btree_readpage_end_io_hook,
 	.submit_bio_hook = btree_submit_bio_hook,
 	/* note we're sharing with inode.c for the merge bio hook */
 	.merge_bio_hook = btrfs_merge_bio_hook,

commit 728131d8e40c2a47c59ca91a806299c4708029f9
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 9 16:28:12 2008 -0400

    Btrfs: Add additional debugging for metadata checksum failures
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bc5bd5abb28a..e444b99e02da 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -283,6 +283,7 @@ static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
 	ret = try_release_extent_mapping(map, tree, page, gfp_flags);
 	if (ret == 1) {
+		invalidate_extent_lru(tree, page_offset(page), PAGE_CACHE_SIZE);
 		ClearPagePrivate(page);
 		set_page_private(page, 0);
 		page_cache_release(page);
@@ -376,7 +377,6 @@ int btrfs_verify_block_csum(struct btrfs_root *root,
 		buf->flags |= EXTENT_CSUM;
 		return 0;
 	}
-
 	lock_extent(io_tree, buf->start, end, GFP_NOFS);
 
 	if (test_range_bit(io_tree, buf->start, end, EXTENT_CSUM, 1)) {
@@ -384,6 +384,7 @@ int btrfs_verify_block_csum(struct btrfs_root *root,
 		ret = 0;
 		goto out_unlock;
 	}
+WARN_ON(buf->flags & EXTENT_CSUM);
 
 	ret = csum_tree_block(root, buf, 1);
 	set_extent_bits(io_tree, buf->start, end, EXTENT_CSUM, GFP_NOFS);

commit d18a2c447524751137a12cc8ccaf9d1e0b7fa1b3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 4 15:40:00 2008 -0400

    Btrfs: Fix allocation profile init
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 42522232fde4..bc5bd5abb28a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -912,13 +912,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_read_block_groups(extent_root);
 
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
-	if (btrfs_super_num_devices(disk_super) > 0) {
-		fs_info->data_alloc_profile = BTRFS_BLOCK_GROUP_RAID0 |
-			BTRFS_BLOCK_GROUP_RAID1;
-		fs_info->metadata_alloc_profile = BTRFS_BLOCK_GROUP_RAID1 |
-			BTRFS_BLOCK_GROUP_DUP;
-		fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
-	}
+	fs_info->data_alloc_profile = (u64)-1;
+	fs_info->metadata_alloc_profile = (u64)-1;
+	fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
+
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
 

commit 611f0e00a27fe0e5a571194a12443ecdc99a43ef
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 3 16:29:03 2008 -0400

    Btrfs: Add support for duplicate blocks on a single spindle
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ff75ad586767..42522232fde4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -913,9 +913,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
 	if (btrfs_super_num_devices(disk_super) > 0) {
-		fs_info->data_alloc_profile = BTRFS_BLOCK_GROUP_RAID0;
-		fs_info->metadata_alloc_profile = BTRFS_BLOCK_GROUP_RAID1;
-		fs_info->system_alloc_profile = BTRFS_BLOCK_GROUP_RAID0;
+		fs_info->data_alloc_profile = BTRFS_BLOCK_GROUP_RAID0 |
+			BTRFS_BLOCK_GROUP_RAID1;
+		fs_info->metadata_alloc_profile = BTRFS_BLOCK_GROUP_RAID1 |
+			BTRFS_BLOCK_GROUP_DUP;
+		fs_info->system_alloc_profile = fs_info->metadata_alloc_profile;
 	}
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;

commit 8790d502e4401a4a3a4175b83a3a47e8d595c771
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 3 16:29:03 2008 -0400

    Btrfs: Add support for mirroring across drives
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e40fb318ad99..ff75ad586767 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -735,7 +735,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 						 GFP_NOFS);
 	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
 					       GFP_NOFS);
-	struct btrfs_fs_info *fs_info = kmalloc(sizeof(*fs_info),
+	struct btrfs_fs_info *fs_info = kzalloc(sizeof(*fs_info),
 						GFP_NOFS);
 	struct btrfs_root *chunk_root = kmalloc(sizeof(struct btrfs_root),
 						GFP_NOFS);
@@ -744,6 +744,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	int ret;
 	int err = -EINVAL;
 	struct btrfs_super_block *disk_super;
+
 	if (!extent_root || !tree_root || !fs_info) {
 		err = -ENOMEM;
 		goto fail;
@@ -756,11 +757,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	spin_lock_init(&fs_info->delalloc_lock);
 	spin_lock_init(&fs_info->new_trans_lock);
 
-	memset(&fs_info->super_kobj, 0, sizeof(fs_info->super_kobj));
 	init_completion(&fs_info->kobj_unregister);
 	sb_set_blocksize(sb, 4096);
-	fs_info->running_transaction = NULL;
-	fs_info->last_trans_committed = 0;
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
 	fs_info->chunk_root = chunk_root;
@@ -770,11 +768,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	fs_info->sb = sb;
-	fs_info->throttles = 0;
-	fs_info->mount_opt = 0;
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
-	fs_info->delalloc_bytes = 0;
 	setup_bdi(fs_info, &fs_info->bdi);
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
@@ -802,12 +797,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	extent_io_tree_init(&fs_info->extent_ins,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
-	fs_info->closing = 0;
-	fs_info->total_pinned = 0;
-	fs_info->last_alloc = 0;
-	fs_info->last_data_alloc = 0;
-	fs_info->extra_alloc_bits = 0;
-	fs_info->extra_data_alloc_bits = 0;
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);
@@ -923,6 +912,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	btrfs_read_block_groups(extent_root);
 
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
+	if (btrfs_super_num_devices(disk_super) > 0) {
+		fs_info->data_alloc_profile = BTRFS_BLOCK_GROUP_RAID0;
+		fs_info->metadata_alloc_profile = BTRFS_BLOCK_GROUP_RAID1;
+		fs_info->system_alloc_profile = BTRFS_BLOCK_GROUP_RAID0;
+	}
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
 

commit 0999df54f850fe1aba29b10d5c869493af107478
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 1 13:48:14 2008 -0400

    Btrfs: Verify checksums on tree blocks found without read_tree_block
    
    Checksums were only verified by btrfs_read_tree_block, which meant the
    functions to probe the page cache for blocks were not validating checksums.
    Normally this is fine because the buffers will only be in cache if they
    have already been validated.
    
    But, there is a window while the buffer is being read from disk where
    it could be up to date in the cache but not yet verified.  This patch
    makes sure all buffers go through checksum verification before they
    are used.
    
    This is safer, and it prevents modification of buffers before they go
    through the csum code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5547607681f4..e40fb318ad99 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -46,27 +46,6 @@ static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
 
 static struct extent_io_ops btree_extent_io_ops;
 
-struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
-					    u64 bytenr, u32 blocksize)
-{
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	struct extent_buffer *eb;
-	eb = find_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
-				bytenr, blocksize, GFP_NOFS);
-	return eb;
-}
-
-struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
-						 u64 bytenr, u32 blocksize)
-{
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	struct extent_buffer *eb;
-
-	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
-				 bytenr, blocksize, NULL, GFP_NOFS);
-	return eb;
-}
-
 struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 				    size_t page_offset, u64 start, u64 len,
 				    int create)
@@ -380,36 +359,29 @@ static int close_all_devices(struct btrfs_fs_info *fs_info)
 	return 0;
 }
 
-struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
-				      u32 blocksize)
+int btrfs_verify_block_csum(struct btrfs_root *root,
+			    struct extent_buffer *buf)
 {
-	struct extent_buffer *buf = NULL;
-	struct inode *btree_inode = root->fs_info->btree_inode;
 	struct extent_io_tree *io_tree;
 	u64 end;
 	int ret;
 
-	io_tree = &BTRFS_I(btree_inode)->io_tree;
-
-	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
-	if (!buf)
-		return NULL;
-	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf, 0, 1,
-				 btree_get_extent);
-
+	io_tree = &BTRFS_I(root->fs_info->btree_inode)->io_tree;
 	if (buf->flags & EXTENT_CSUM)
-		return buf;
+		return 0;
 
-	end = buf->start + PAGE_CACHE_SIZE - 1;
+	end = min_t(u64, buf->len, PAGE_CACHE_SIZE);
+	end = buf->start + end - 1;
 	if (test_range_bit(io_tree, buf->start, end, EXTENT_CSUM, 1)) {
 		buf->flags |= EXTENT_CSUM;
-		return buf;
+		return 0;
 	}
 
 	lock_extent(io_tree, buf->start, end, GFP_NOFS);
 
 	if (test_range_bit(io_tree, buf->start, end, EXTENT_CSUM, 1)) {
 		buf->flags |= EXTENT_CSUM;
+		ret = 0;
 		goto out_unlock;
 	}
 
@@ -419,6 +391,48 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 
 out_unlock:
 	unlock_extent(io_tree, buf->start, end, GFP_NOFS);
+	return ret;
+}
+
+struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
+					    u64 bytenr, u32 blocksize)
+{
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	struct extent_buffer *eb;
+	eb = find_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
+				bytenr, blocksize, GFP_NOFS);
+	return eb;
+}
+
+struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
+						 u64 bytenr, u32 blocksize)
+{
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	struct extent_buffer *eb;
+
+	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
+				 bytenr, blocksize, NULL, GFP_NOFS);
+	return eb;
+}
+
+
+struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
+				      u32 blocksize)
+{
+	struct extent_buffer *buf = NULL;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	struct extent_io_tree *io_tree;
+	int ret;
+
+	io_tree = &BTRFS_I(btree_inode)->io_tree;
+
+	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
+	if (!buf)
+		return NULL;
+	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf, 0, 1,
+				 btree_get_extent);
+
+	ret = btrfs_verify_block_csum(root, buf);
 	return buf;
 }
 

commit e58ca0203d32869a01540a293df40ddc480dc378
Author: Yan <yanzheng@21cn.com>
Date:   Tue Apr 1 11:21:34 2008 -0400

    Fix btrfs_fill_super to return -EINVAL when no FS found
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 709e33d08bb5..5547607681f4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -728,9 +728,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	struct btrfs_root *dev_root = kmalloc(sizeof(struct btrfs_root),
 					      GFP_NOFS);
 	int ret;
-	int err = -EIO;
+	int err = -EINVAL;
 	struct btrfs_super_block *disk_super;
-
 	if (!extent_root || !tree_root || !fs_info) {
 		err = -ENOMEM;
 		goto fail;

commit 63b10fc4874a014e22bc4c64e3d92b71180661fe
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 1 11:21:32 2008 -0400

    Reorder the flags field in struct btrfs_header and record a flag on writeout
    
    This allows detection of blocks that have already been written in the
    running transaction so they can be recowed instead of modified again.
    It is step one in trusting the transid field of the block pointers.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1c5e097a4df2..709e33d08bb5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -159,17 +159,19 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			from_this_trans = 1;
 
 		/* FIXME, this is not good */
-		if (from_this_trans == 0 &&
-		    memcmp_extent_buffer(buf, result, 0, BTRFS_CRC32_SIZE)) {
+		if (memcmp_extent_buffer(buf, result, 0, BTRFS_CRC32_SIZE)) {
 			u32 val;
 			u32 found = 0;
 			memcpy(&found, result, BTRFS_CRC32_SIZE);
 
 			read_extent_buffer(buf, &val, 0, BTRFS_CRC32_SIZE);
+			WARN_ON(1);
 			printk("btrfs: %s checksum verify failed on %llu "
-			       "wanted %X found %X from_this_trans %d\n",
+			       "wanted %X found %X from_this_trans %d "
+			       "level %d\n",
 			       root->fs_info->sb->s_id,
-			       buf->start, val, found, from_this_trans);
+			       buf->start, val, found, from_this_trans,
+			       btrfs_header_level(buf));
 			return 1;
 		}
 	} else {
@@ -220,6 +222,9 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 		goto err;
 	}
 	found_level = btrfs_header_level(eb);
+	spin_lock(&root->fs_info->hash_lock);
+	btrfs_set_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN);
+	spin_unlock(&root->fs_info->hash_lock);
 	csum_tree_block(root, eb, 0);
 err:
 	free_extent_buffer(eb);

commit 2d2ae547979854d10b75d557b3abdb3eb7511bbc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 26 16:24:23 2008 -0400

    Btrfs: Add leak debugging for extent_buffer and extent_state
    
    This also fixes one leak around the super block when failing to mount the
    FS.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 134b722587ec..1c5e097a4df2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -915,12 +915,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	free_extent_buffer(tree_root->node);
 fail_sb_buffer:
 	free_extent_buffer(fs_info->sb_buffer);
+	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 fail_iput:
 	iput(fs_info->btree_inode);
 fail:
 	close_all_devices(fs_info);
 	kfree(extent_root);
 	kfree(tree_root);
+	bdi_destroy(&fs_info->bdi);
 	kfree(fs_info);
 	return ERR_PTR(err);
 }

commit 83041add611056e830e29fda913029e37e857239
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 26 12:02:55 2008 -0400

    Btrfs: Use a higher default ra pages
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6a70e4916ab4..134b722587ec 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -694,7 +694,7 @@ void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
 static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
 {
 	bdi_init(bdi);
-	bdi->ra_pages	= default_backing_dev_info.ra_pages;
+	bdi->ra_pages	= default_backing_dev_info.ra_pages * 4;
 	bdi->state		= 0;
 	bdi->capabilities	= default_backing_dev_info.capabilities;
 	bdi->unplug_io_fn	= btrfs_unplug_io_fn;

commit 04160088141a6be06d5cb9e53e34076b51803ffc
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 26 10:28:07 2008 -0400

    Create a btrfs backing dev info
    
    This allows intelligent versions of unplug and congestion functions
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d8474796dea2..6a70e4916ab4 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -655,6 +655,55 @@ static int add_hasher(struct btrfs_fs_info *info, char *type) {
 	return 0;
 }
 #endif
+
+static int btrfs_congested_fn(void *congested_data, int bdi_bits)
+{
+	struct btrfs_fs_info *info = (struct btrfs_fs_info *)congested_data;
+	int ret = 0;
+	struct list_head *cur;
+	struct btrfs_device *device;
+	struct backing_dev_info *bdi;
+
+	list_for_each(cur, &info->fs_devices->devices) {
+		device = list_entry(cur, struct btrfs_device, dev_list);
+		bdi = blk_get_backing_dev_info(device->bdev);
+		if (bdi && bdi_congested(bdi, bdi_bits)) {
+			ret = 1;
+			break;
+		}
+	}
+	return ret;
+}
+
+void btrfs_unplug_io_fn(struct backing_dev_info *bdi, struct page *page)
+{
+	struct list_head *cur;
+	struct btrfs_device *device;
+	struct btrfs_fs_info *info;
+
+	info = (struct btrfs_fs_info *)bdi->unplug_io_data;
+	list_for_each(cur, &info->fs_devices->devices) {
+		device = list_entry(cur, struct btrfs_device, dev_list);
+		bdi = blk_get_backing_dev_info(device->bdev);
+		if (bdi->unplug_io_fn) {
+			bdi->unplug_io_fn(bdi, page);
+		}
+	}
+}
+
+static int setup_bdi(struct btrfs_fs_info *info, struct backing_dev_info *bdi)
+{
+	bdi_init(bdi);
+	bdi->ra_pages	= default_backing_dev_info.ra_pages;
+	bdi->state		= 0;
+	bdi->capabilities	= default_backing_dev_info.capabilities;
+	bdi->unplug_io_fn	= btrfs_unplug_io_fn;
+	bdi->unplug_io_data	= info;
+	bdi->congested_fn	= btrfs_congested_fn;
+	bdi->congested_data	= info;
+	return 0;
+}
+
 struct btrfs_root *open_ctree(struct super_block *sb,
 			      struct btrfs_fs_devices *fs_devices)
 {
@@ -708,11 +757,14 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->max_extent = (u64)-1;
 	fs_info->max_inline = 8192 * 1024;
 	fs_info->delalloc_bytes = 0;
+	setup_bdi(fs_info, &fs_info->bdi);
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
+	fs_info->btree_inode->i_mapping->backing_dev_info = &fs_info->bdi;
+
 	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,
 			     fs_info->btree_inode->i_mapping,
 			     GFP_NOFS);
@@ -992,6 +1044,7 @@ int close_ctree(struct btrfs_root *root)
 #endif
 	close_all_devices(fs_info);
 	btrfs_mapping_tree_free(&fs_info->mapping_tree);
+	bdi_destroy(&fs_info->bdi);
 
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);

commit 593060d756e0c2382d59cf00d5f3b9e3a336c408
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 25 16:50:33 2008 -0400

    Btrfs: Implement raid0 when multiple devices are present
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f971a29e4f20..d8474796dea2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -736,6 +736,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->total_pinned = 0;
 	fs_info->last_alloc = 0;
 	fs_info->last_data_alloc = 0;
+	fs_info->extra_alloc_bits = 0;
+	fs_info->extra_data_alloc_bits = 0;
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);

commit 8a4b83cc8bd75fca29ac68615896d9e92820e7c2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:02:07 2008 -0400

    Btrfs: Add support for device scanning and detection ioctls
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4890151cd68d..f971a29e4f20 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -365,12 +365,12 @@ static int close_all_devices(struct btrfs_fs_info *fs_info)
 	struct list_head *next;
 	struct btrfs_device *device;
 
-	list = &fs_info->devices;
-	while(!list_empty(list)) {
-		next = list->next;
-		list_del(next);
+	list = &fs_info->fs_devices->devices;
+	list_for_each(next, list) {
 		device = list_entry(next, struct btrfs_device, dev_list);
-		kfree(device);
+		if (device->bdev && device->bdev != fs_info->sb->s_bdev)
+			close_bdev_excl(device->bdev);
+		device->bdev = NULL;
 	}
 	return 0;
 }
@@ -655,7 +655,8 @@ static int add_hasher(struct btrfs_fs_info *info, char *type) {
 	return 0;
 }
 #endif
-struct btrfs_root *open_ctree(struct super_block *sb)
+struct btrfs_root *open_ctree(struct super_block *sb,
+			      struct btrfs_fs_devices *fs_devices)
 {
 	u32 sectorsize;
 	u32 nodesize;
@@ -697,8 +698,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->extent_root = extent_root;
 	fs_info->chunk_root = chunk_root;
 	fs_info->dev_root = dev_root;
+	fs_info->fs_devices = fs_devices;
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
-	INIT_LIST_HEAD(&fs_info->devices);
 	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);
 	fs_info->sb = sb;
@@ -779,6 +780,12 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	if (!btrfs_super_root(disk_super))
 		goto fail_sb_buffer;
 
+	if (btrfs_super_num_devices(disk_super) != fs_devices->num_devices) {
+		printk("Btrfs: wanted %llu devices, but found %llu\n",
+		       (unsigned long long)btrfs_super_num_devices(disk_super),
+		       (unsigned long long)fs_devices->num_devices);
+		goto fail_sb_buffer;
+	}
 	nodesize = btrfs_super_nodesize(disk_super);
 	leafsize = btrfs_super_leafsize(disk_super);
 	sectorsize = btrfs_super_sectorsize(disk_super);
@@ -799,8 +806,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	}
 
 	mutex_lock(&fs_info->fs_mutex);
-	ret = btrfs_read_super_device(tree_root, fs_info->sb_buffer);
-	BUG_ON(ret);
 
 	ret = btrfs_read_sys_array(tree_root);
 	BUG_ON(ret);
@@ -859,6 +864,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 fail_iput:
 	iput(fs_info->btree_inode);
 fail:
+	close_all_devices(fs_info);
 	kfree(extent_root);
 	kfree(tree_root);
 	kfree(fs_info);

commit 239b14b32dc39232ebf9cce29ff77c4c564355fd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:02:07 2008 -0400

    Btrfs: Bring back mount -o ssd optimizations
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 26185d46712c..4890151cd68d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1103,4 +1103,6 @@ int btrfs_read_buffer(struct extent_buffer *buf)
 static struct extent_io_ops btree_extent_io_ops = {
 	.writepage_io_hook = btree_writepage_io_hook,
 	.submit_bio_hook = btree_submit_bio_hook,
+	/* note we're sharing with inode.c for the merge bio hook */
+	.merge_bio_hook = btrfs_merge_bio_hook,
 };

commit 0d81ba5dbedef0c3970d6aa318aa84920943e6e3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:02:07 2008 -0400

    Btrfs: Move device information into the super block so it can be scanned
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2a239ae49f78..26185d46712c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -370,7 +370,6 @@ static int close_all_devices(struct btrfs_fs_info *fs_info)
 		next = list->next;
 		list_del(next);
 		device = list_entry(next, struct btrfs_device, dev_list);
-		kfree(device->name);
 		kfree(device);
 	}
 	return 0;
@@ -800,6 +799,9 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	}
 
 	mutex_lock(&fs_info->fs_mutex);
+	ret = btrfs_read_super_device(tree_root, fs_info->sb_buffer);
+	BUG_ON(ret);
+
 	ret = btrfs_read_sys_array(tree_root);
 	BUG_ON(ret);
 

commit 6324fbf334f4586325057197da7752f4ffa409d3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:01:59 2008 -0400

    Btrfs: Dynamic chunk and block group allocation
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8e37fa120cc8..2a239ae49f78 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -700,8 +700,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->dev_root = dev_root;
 	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
 	INIT_LIST_HEAD(&fs_info->devices);
+	INIT_LIST_HEAD(&fs_info->space_info);
 	btrfs_mapping_init(&fs_info->mapping_tree);
-	fs_info->last_device = &fs_info->devices;
 	fs_info->sb = sb;
 	fs_info->throttles = 0;
 	fs_info->mount_opt = 0;

commit 0b86a832a1f38abec695864ec2eaedc9d2383f1b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 24 15:01:56 2008 -0400

    Btrfs: Add support for multiple devices per filesystem
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 88e21bdbc478..8e37fa120cc8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -28,6 +28,7 @@
 #include "disk-io.h"
 #include "transaction.h"
 #include "btrfs_inode.h"
+#include "volumes.h"
 #include "print-tree.h"
 
 #if 0
@@ -234,6 +235,19 @@ static int btree_writepage_io_hook(struct page *page, u64 start, u64 end)
 	return 0;
 }
 
+static int btree_submit_bio_hook(struct inode *inode, int rw, struct bio *bio)
+{
+	struct btrfs_root *root = BTRFS_I(inode)->root;
+	u64 offset;
+	offset = bio->bi_sector << 9;
+	if (offset == BTRFS_SUPER_INFO_OFFSET) {
+		bio->bi_bdev = root->fs_info->sb->s_bdev;
+		submit_bio(rw, bio);
+		return 0;
+	}
+	return btrfs_map_bio(BTRFS_I(inode)->root, rw, bio);
+}
+
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct extent_io_tree *tree;
@@ -345,6 +359,23 @@ int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
 	return ret;
 }
 
+static int close_all_devices(struct btrfs_fs_info *fs_info)
+{
+	struct list_head *list;
+	struct list_head *next;
+	struct btrfs_device *device;
+
+	list = &fs_info->devices;
+	while(!list_empty(list)) {
+		next = list->next;
+		list_del(next);
+		device = list_entry(next, struct btrfs_device, dev_list);
+		kfree(device->name);
+		kfree(device);
+	}
+	return 0;
+}
+
 struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 				      u32 blocksize)
 {
@@ -420,6 +451,8 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->leafsize = leafsize;
 	root->stripesize = stripesize;
 	root->ref_cows = 0;
+	root->track_dirty = 0;
+
 	root->fs_info = fs_info;
 	root->objectid = objectid;
 	root->last_trans = 0;
@@ -427,6 +460,8 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->last_inode_alloc = 0;
 	root->name = NULL;
 	root->in_sysfs = 0;
+
+	INIT_LIST_HEAD(&root->dirty_list);
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
@@ -634,6 +669,10 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 					       GFP_NOFS);
 	struct btrfs_fs_info *fs_info = kmalloc(sizeof(*fs_info),
 						GFP_NOFS);
+	struct btrfs_root *chunk_root = kmalloc(sizeof(struct btrfs_root),
+						GFP_NOFS);
+	struct btrfs_root *dev_root = kmalloc(sizeof(struct btrfs_root),
+					      GFP_NOFS);
 	int ret;
 	int err = -EIO;
 	struct btrfs_super_block *disk_super;
@@ -657,6 +696,12 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->last_trans_committed = 0;
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
+	fs_info->chunk_root = chunk_root;
+	fs_info->dev_root = dev_root;
+	INIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);
+	INIT_LIST_HEAD(&fs_info->devices);
+	btrfs_mapping_init(&fs_info->mapping_tree);
+	fs_info->last_device = &fs_info->devices;
 	fs_info->sb = sb;
 	fs_info->throttles = 0;
 	fs_info->mount_opt = 0;
@@ -714,12 +759,12 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 		goto fail_iput;
 	}
 #endif
-	__setup_root(512, 512, 512, 512, tree_root,
+	__setup_root(4096, 4096, 4096, 4096, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
 	fs_info->sb_buffer = read_tree_block(tree_root,
 					     BTRFS_SUPER_INFO_OFFSET,
-					     512);
+					     4096);
 
 	if (!fs_info->sb_buffer)
 		goto fail_iput;
@@ -730,6 +775,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	read_extent_buffer(fs_info->sb_buffer, fs_info->fsid,
 			   (unsigned long)btrfs_super_fsid(fs_info->sb_buffer),
 			   BTRFS_FSID_SIZE);
+
 	disk_super = &fs_info->super_copy;
 	if (!btrfs_super_root(disk_super))
 		goto fail_sb_buffer;
@@ -753,23 +799,47 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 		goto fail_sb_buffer;
 	}
 
+	mutex_lock(&fs_info->fs_mutex);
+	ret = btrfs_read_sys_array(tree_root);
+	BUG_ON(ret);
+
+	blocksize = btrfs_level_size(tree_root,
+				     btrfs_super_chunk_root_level(disk_super));
+
+	__setup_root(nodesize, leafsize, sectorsize, stripesize,
+		     chunk_root, fs_info, BTRFS_CHUNK_TREE_OBJECTID);
+
+	chunk_root->node = read_tree_block(chunk_root,
+					   btrfs_super_chunk_root(disk_super),
+					   blocksize);
+	BUG_ON(!chunk_root->node);
+
+	ret = btrfs_read_chunk_tree(chunk_root);
+	BUG_ON(ret);
+
 	blocksize = btrfs_level_size(tree_root,
 				     btrfs_super_root_level(disk_super));
 
+
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super),
 					  blocksize);
 	if (!tree_root->node)
 		goto fail_sb_buffer;
 
-	mutex_lock(&fs_info->fs_mutex);
 
 	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
-	if (ret) {
-		mutex_unlock(&fs_info->fs_mutex);
+	if (ret)
 		goto fail_tree_root;
-	}
+	extent_root->track_dirty = 1;
+
+	ret = find_and_setup_root(tree_root, fs_info,
+				  BTRFS_DEV_TREE_OBJECTID, dev_root);
+	dev_root->track_dirty = 1;
+
+	if (ret)
+		goto fail_extent_root;
 
 	btrfs_read_block_groups(extent_root);
 
@@ -777,7 +847,10 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
 
+fail_extent_root:
+	free_extent_buffer(extent_root->node);
 fail_tree_root:
+	mutex_unlock(&fs_info->fs_mutex);
 	free_extent_buffer(tree_root->node);
 fail_sb_buffer:
 	free_extent_buffer(fs_info->sb_buffer);
@@ -874,6 +947,12 @@ int close_ctree(struct btrfs_root *root)
 	if (fs_info->tree_root->node)
 		free_extent_buffer(fs_info->tree_root->node);
 
+	if (root->fs_info->chunk_root->node);
+		free_extent_buffer(root->fs_info->chunk_root->node);
+
+	if (root->fs_info->dev_root->node);
+		free_extent_buffer(root->fs_info->dev_root->node);
+
 	free_extent_buffer(fs_info->sb_buffer);
 
 	btrfs_free_block_groups(root->fs_info);
@@ -901,8 +980,13 @@ int close_ctree(struct btrfs_root *root)
 		kfree(hasher);
 	}
 #endif
+	close_all_devices(fs_info);
+	btrfs_mapping_tree_free(&fs_info->mapping_tree);
+
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);
+	kfree(fs_info->chunk_root);
+	kfree(fs_info->dev_root);
 	return 0;
 }
 
@@ -1016,4 +1100,5 @@ int btrfs_read_buffer(struct extent_buffer *buf)
 
 static struct extent_io_ops btree_extent_io_ops = {
 	.writepage_io_hook = btree_writepage_io_hook,
+	.submit_bio_hook = btree_submit_bio_hook,
 };

commit d7fc640e6fed46932f7c74e14f9b58b8637c66cf
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Feb 18 12:12:38 2008 -0500

    Btrfs: Allocator improvements
    
    Reduce CPU time searching for free blocks by optimizing find_first_extent_bit
    
    Fix find_free_extent to make better use of the last_alloc hint.  Before it
    was often finding blocks just before the hint.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6f0825b617d1..88e21bdbc478 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -951,7 +951,7 @@ void btrfs_throttle(struct btrfs_root *root)
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 {
 	balance_dirty_pages_ratelimited_nr(
-			root->fs_info->btree_inode->i_mapping, 1);
+				   root->fs_info->btree_inode->i_mapping, 1);
 }
 
 void btrfs_set_buffer_defrag(struct extent_buffer *buf)

commit a86c12c73d982c545a37a8ecdd66528ab260b770
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Feb 7 10:50:54 2008 -0500

    Btrfs: Create larger bios for btree blocks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index dda8ad6c0077..6f0825b617d1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -197,7 +197,8 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 		WARN_ON(1);
 	}
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
-	read_extent_buffer_pages(tree, eb, start + PAGE_CACHE_SIZE, 1);
+	read_extent_buffer_pages(tree, eb, start + PAGE_CACHE_SIZE, 1,
+				 btree_get_extent);
 	btrfs_clear_buffer_defrag(eb);
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
@@ -339,7 +340,7 @@ int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
 	if (!buf)
 		return 0;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
-				 buf, 0, 0);
+				 buf, 0, 0, btree_get_extent);
 	free_extent_buffer(buf);
 	return ret;
 }
@@ -358,7 +359,8 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
 	if (!buf)
 		return NULL;
-	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf, 0, 1);
+	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf, 0, 1,
+				 btree_get_extent);
 
 	if (buf->flags & EXTENT_CSUM)
 		return buf;
@@ -1009,7 +1011,7 @@ int btrfs_read_buffer(struct extent_buffer *buf)
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
-					buf, 0, 1);
+					buf, 0, 1, btree_get_extent);
 }
 
 static struct extent_io_ops btree_extent_io_ops = {

commit 4529ba495c6fd0d79247784d0df55ae6512fa883
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 31 16:45:07 2008 -0500

    Btrfs: Add data block hints to SSD mode too
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ad72e2192015..dda8ad6c0077 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -688,6 +688,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->closing = 0;
 	fs_info->total_pinned = 0;
 	fs_info->last_alloc = 0;
+	fs_info->last_data_alloc = 0;
 
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);

commit b0c68f8bed058d9f2023b067b16ed06a8c439544
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 31 11:05:37 2008 -0500

    Btrfs: Enable delalloc accounting
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6647b90ef745..ad72e2192015 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -861,6 +861,10 @@ int close_ctree(struct btrfs_root *root)
 	write_ctree_super(NULL, root);
 	mutex_unlock(&fs_info->fs_mutex);
 
+	if (fs_info->delalloc_bytes) {
+		printk("btrfs: at unmount delalloc count %Lu\n",
+		       fs_info->delalloc_bytes);
+	}
 	if (fs_info->extent_root->node)
 		free_extent_buffer(fs_info->extent_root->node);
 

commit 6f568d35a045dbb8a13fe71bfc32e85e39a986cb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 29 16:03:38 2008 -0500

    Btrfs: mount -o max_inline=size to control the maximum inline extent size
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e29a0716f6a9..6647b90ef745 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -659,6 +659,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->throttles = 0;
 	fs_info->mount_opt = 0;
 	fs_info->max_extent = (u64)-1;
+	fs_info->max_inline = 8192 * 1024;
 	fs_info->delalloc_bytes = 0;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;

commit 70dec8079d78691e476cc6c7cede40656078ad30
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 29 09:59:12 2008 -0500

    Btrfs: extent_io and extent_state optimizations
    
    The end_bio routines are changed to take a pointer to the extent state
    struct, and the state tree is walked in order to set/clear appropriate
    bits as IO completes.  This greatly reduces the number of rbtree searches
    done by the end_bio handlers, and reduces lock contention.
    
    The extent_io releasepage function is changed to avoid expensive searches
    for locked state.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4c4ebea0b2a9..e29a0716f6a9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -274,7 +274,7 @@ int btree_readpage(struct file *file, struct page *page)
 	return extent_read_full_page(tree, page, btree_get_extent);
 }
 
-static int btree_releasepage(struct page *page, gfp_t unused_gfp_flags)
+static int btree_releasepage(struct page *page, gfp_t gfp_flags)
 {
 	struct extent_io_tree *tree;
 	struct extent_map_tree *map;
@@ -282,7 +282,7 @@ static int btree_releasepage(struct page *page, gfp_t unused_gfp_flags)
 
 	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	map = &BTRFS_I(page->mapping->host)->extent_tree;
-	ret = try_release_extent_mapping(map, tree, page);
+	ret = try_release_extent_mapping(map, tree, page, gfp_flags);
 	if (ret == 1) {
 		ClearPagePrivate(page);
 		set_page_private(page, 0);

commit d1310b2e0cd98eb1348553e69b73827b436dca7b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 24 16:13:08 2008 -0500

    Btrfs: Split the extent_map code into two parts
    
    There is now extent_map for mapping offsets in the file to disk and
    extent_io for state tracking, IO submission and extent_bufers.
    
    The new extent_map code shifts from [start,end] pairs to [start,len], and
    pushes the locking out into the caller.  This allows a few performance
    optimizations and is easier to use.
    
    A number of extent_map usage bugs were fixed, mostly with failing
    to remove extent_map entries when changing the file.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5d1f9bca2712..4c4ebea0b2a9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -43,14 +43,14 @@ static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
 }
 #endif
 
-static struct extent_map_ops btree_extent_map_ops;
+static struct extent_io_ops btree_extent_io_ops;
 
 struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize)
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	struct extent_buffer *eb;
-	eb = find_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
+	eb = find_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
 				bytenr, blocksize, GFP_NOFS);
 	return eb;
 }
@@ -61,13 +61,13 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	struct extent_buffer *eb;
 
-	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
+	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->io_tree,
 				 bytenr, blocksize, NULL, GFP_NOFS);
 	return eb;
 }
 
 struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
-				    size_t page_offset, u64 start, u64 end,
+				    size_t page_offset, u64 start, u64 len,
 				    int create)
 {
 	struct extent_map_tree *em_tree = &BTRFS_I(inode)->extent_tree;
@@ -75,7 +75,9 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 	int ret;
 
 again:
-	em = lookup_extent_mapping(em_tree, start, end);
+	spin_lock(&em_tree->lock);
+	em = lookup_extent_mapping(em_tree, start, len);
+	spin_unlock(&em_tree->lock);
 	if (em) {
 		goto out;
 	}
@@ -85,11 +87,14 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 		goto out;
 	}
 	em->start = 0;
-	em->end = (i_size_read(inode) & ~((u64)PAGE_CACHE_SIZE -1)) - 1;
+	em->len = i_size_read(inode);
 	em->block_start = 0;
-	em->block_end = em->end;
 	em->bdev = inode->i_sb->s_bdev;
+
+	spin_lock(&em_tree->lock);
 	ret = add_extent_mapping(em_tree, em);
+	spin_unlock(&em_tree->lock);
+
 	if (ret == -EEXIST) {
 		free_extent_map(em);
 		em = NULL;
@@ -175,13 +180,13 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 
 int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 {
-	struct extent_map_tree *tree;
+	struct extent_io_tree *tree;
 	u64 start = (u64)page->index << PAGE_CACHE_SHIFT;
 	u64 found_start;
 	int found_level;
 	unsigned long len;
 	struct extent_buffer *eb;
-	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+	tree = &BTRFS_I(page->mapping->host)->io_tree;
 
 	if (page->private == EXTENT_PAGE_PRIVATE)
 		goto out;
@@ -230,16 +235,16 @@ static int btree_writepage_io_hook(struct page *page, u64 start, u64 end)
 
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
-	struct extent_map_tree *tree;
-	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+	struct extent_io_tree *tree;
+	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	return extent_write_full_page(tree, page, btree_get_extent, wbc);
 }
 
 static int btree_writepages(struct address_space *mapping,
 			    struct writeback_control *wbc)
 {
-	struct extent_map_tree *tree;
-	tree = &BTRFS_I(mapping->host)->extent_tree;
+	struct extent_io_tree *tree;
+	tree = &BTRFS_I(mapping->host)->io_tree;
 	if (wbc->sync_mode == WB_SYNC_NONE) {
 		u64 num_dirty;
 		u64 start = 0;
@@ -264,18 +269,20 @@ static int btree_writepages(struct address_space *mapping,
 
 int btree_readpage(struct file *file, struct page *page)
 {
-	struct extent_map_tree *tree;
-	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+	struct extent_io_tree *tree;
+	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	return extent_read_full_page(tree, page, btree_get_extent);
 }
 
 static int btree_releasepage(struct page *page, gfp_t unused_gfp_flags)
 {
-	struct extent_map_tree *tree;
+	struct extent_io_tree *tree;
+	struct extent_map_tree *map;
 	int ret;
 
-	tree = &BTRFS_I(page->mapping->host)->extent_tree;
-	ret = try_release_extent_mapping(tree, page);
+	tree = &BTRFS_I(page->mapping->host)->io_tree;
+	map = &BTRFS_I(page->mapping->host)->extent_tree;
+	ret = try_release_extent_mapping(map, tree, page);
 	if (ret == 1) {
 		ClearPagePrivate(page);
 		set_page_private(page, 0);
@@ -286,8 +293,8 @@ static int btree_releasepage(struct page *page, gfp_t unused_gfp_flags)
 
 static void btree_invalidatepage(struct page *page, unsigned long offset)
 {
-	struct extent_map_tree *tree;
-	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+	struct extent_io_tree *tree;
+	tree = &BTRFS_I(page->mapping->host)->io_tree;
 	extent_invalidatepage(tree, page, offset);
 	btree_releasepage(page, GFP_NOFS);
 }
@@ -331,7 +338,7 @@ int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
 	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
 	if (!buf)
 		return 0;
-	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
+	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
 				 buf, 0, 0);
 	free_extent_buffer(buf);
 	return ret;
@@ -342,40 +349,39 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	struct extent_map_tree *extent_tree;
+	struct extent_io_tree *io_tree;
 	u64 end;
 	int ret;
 
-	extent_tree = &BTRFS_I(btree_inode)->extent_tree;
+	io_tree = &BTRFS_I(btree_inode)->io_tree;
 
 	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
 	if (!buf)
 		return NULL;
-	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
-				 buf, 0, 1);
+	read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree, buf, 0, 1);
 
 	if (buf->flags & EXTENT_CSUM)
 		return buf;
 
 	end = buf->start + PAGE_CACHE_SIZE - 1;
-	if (test_range_bit(extent_tree, buf->start, end, EXTENT_CSUM, 1)) {
+	if (test_range_bit(io_tree, buf->start, end, EXTENT_CSUM, 1)) {
 		buf->flags |= EXTENT_CSUM;
 		return buf;
 	}
 
-	lock_extent(extent_tree, buf->start, end, GFP_NOFS);
+	lock_extent(io_tree, buf->start, end, GFP_NOFS);
 
-	if (test_range_bit(extent_tree, buf->start, end, EXTENT_CSUM, 1)) {
+	if (test_range_bit(io_tree, buf->start, end, EXTENT_CSUM, 1)) {
 		buf->flags |= EXTENT_CSUM;
 		goto out_unlock;
 	}
 
 	ret = csum_tree_block(root, buf, 1);
-	set_extent_bits(extent_tree, buf->start, end, EXTENT_CSUM, GFP_NOFS);
+	set_extent_bits(io_tree, buf->start, end, EXTENT_CSUM, GFP_NOFS);
 	buf->flags |= EXTENT_CSUM;
 
 out_unlock:
-	unlock_extent(extent_tree, buf->start, end, GFP_NOFS);
+	unlock_extent(io_tree, buf->start, end, GFP_NOFS);
 	return buf;
 }
 
@@ -385,7 +391,7 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	if (btrfs_header_generation(buf) ==
 	    root->fs_info->running_transaction->transid)
-		clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree,
+		clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree,
 					  buf);
 	return 0;
 }
@@ -394,7 +400,7 @@ int wait_on_tree_block_writeback(struct btrfs_root *root,
 				 struct extent_buffer *buf)
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	wait_on_extent_buffer_writeback(&BTRFS_I(btree_inode)->extent_tree,
+	wait_on_extent_buffer_writeback(&BTRFS_I(btree_inode)->io_tree,
 					buf);
 	return 0;
 }
@@ -659,20 +665,23 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->btree_inode->i_nlink = 1;
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
-	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree,
+	extent_io_tree_init(&BTRFS_I(fs_info->btree_inode)->io_tree,
 			     fs_info->btree_inode->i_mapping,
 			     GFP_NOFS);
-	BTRFS_I(fs_info->btree_inode)->extent_tree.ops = &btree_extent_map_ops;
+	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree,
+			     GFP_NOFS);
+
+	BTRFS_I(fs_info->btree_inode)->io_tree.ops = &btree_extent_io_ops;
 
-	extent_map_tree_init(&fs_info->free_space_cache,
+	extent_io_tree_init(&fs_info->free_space_cache,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
-	extent_map_tree_init(&fs_info->block_group_cache,
+	extent_io_tree_init(&fs_info->block_group_cache,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
-	extent_map_tree_init(&fs_info->pinned_extents,
+	extent_io_tree_init(&fs_info->pinned_extents,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
-	extent_map_tree_init(&fs_info->pending_del,
+	extent_io_tree_init(&fs_info->pending_del,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
-	extent_map_tree_init(&fs_info->extent_ins,
+	extent_io_tree_init(&fs_info->extent_ins,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 	fs_info->closing = 0;
@@ -787,7 +796,7 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 
 	if (!btrfs_test_opt(root, NOBARRIER))
 		blkdev_issue_flush(sb->s_bdev, NULL);
-	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, super);
+	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree, super);
 	ret = sync_page_range_nolock(btree_inode, btree_inode->i_mapping,
 				     super->start, super->len);
 	if (!btrfs_test_opt(root, NOBARRIER))
@@ -864,12 +873,12 @@ int close_ctree(struct btrfs_root *root)
 
 	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
 
-	extent_map_tree_empty_lru(&fs_info->free_space_cache);
-	extent_map_tree_empty_lru(&fs_info->block_group_cache);
-	extent_map_tree_empty_lru(&fs_info->pinned_extents);
-	extent_map_tree_empty_lru(&fs_info->pending_del);
-	extent_map_tree_empty_lru(&fs_info->extent_ins);
-	extent_map_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->extent_tree);
+	extent_io_tree_empty_lru(&fs_info->free_space_cache);
+	extent_io_tree_empty_lru(&fs_info->block_group_cache);
+	extent_io_tree_empty_lru(&fs_info->pinned_extents);
+	extent_io_tree_empty_lru(&fs_info->pending_del);
+	extent_io_tree_empty_lru(&fs_info->extent_ins);
+	extent_io_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->io_tree);
 
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 
@@ -892,13 +901,13 @@ int close_ctree(struct btrfs_root *root)
 int btrfs_buffer_uptodate(struct extent_buffer *buf)
 {
 	struct inode *btree_inode = buf->first_page->mapping->host;
-	return extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree, buf);
+	return extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree, buf);
 }
 
 int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
 {
 	struct inode *btree_inode = buf->first_page->mapping->host;
-	return set_extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree,
+	return set_extent_buffer_uptodate(&BTRFS_I(btree_inode)->io_tree,
 					  buf);
 }
 
@@ -914,7 +923,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 			transid, root->fs_info->generation);
 		WARN_ON(1);
 	}
-	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, buf);
+	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->io_tree, buf);
 }
 
 void btrfs_throttle(struct btrfs_root *root)
@@ -941,7 +950,7 @@ void btrfs_set_buffer_defrag(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	set_extent_bits(&BTRFS_I(btree_inode)->extent_tree, buf->start,
+	set_extent_bits(&BTRFS_I(btree_inode)->io_tree, buf->start,
 			buf->start + buf->len - 1, EXTENT_DEFRAG, GFP_NOFS);
 }
 
@@ -949,7 +958,7 @@ void btrfs_set_buffer_defrag_done(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	set_extent_bits(&BTRFS_I(btree_inode)->extent_tree, buf->start,
+	set_extent_bits(&BTRFS_I(btree_inode)->io_tree, buf->start,
 			buf->start + buf->len - 1, EXTENT_DEFRAG_DONE,
 			GFP_NOFS);
 }
@@ -958,7 +967,7 @@ int btrfs_buffer_defrag(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	return test_range_bit(&BTRFS_I(btree_inode)->extent_tree,
+	return test_range_bit(&BTRFS_I(btree_inode)->io_tree,
 		     buf->start, buf->start + buf->len - 1, EXTENT_DEFRAG, 0);
 }
 
@@ -966,7 +975,7 @@ int btrfs_buffer_defrag_done(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	return test_range_bit(&BTRFS_I(btree_inode)->extent_tree,
+	return test_range_bit(&BTRFS_I(btree_inode)->io_tree,
 		     buf->start, buf->start + buf->len - 1,
 		     EXTENT_DEFRAG_DONE, 0);
 }
@@ -975,7 +984,7 @@ int btrfs_clear_buffer_defrag_done(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	return clear_extent_bits(&BTRFS_I(btree_inode)->extent_tree,
+	return clear_extent_bits(&BTRFS_I(btree_inode)->io_tree,
 		     buf->start, buf->start + buf->len - 1,
 		     EXTENT_DEFRAG_DONE, GFP_NOFS);
 }
@@ -984,7 +993,7 @@ int btrfs_clear_buffer_defrag(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	return clear_extent_bits(&BTRFS_I(btree_inode)->extent_tree,
+	return clear_extent_bits(&BTRFS_I(btree_inode)->io_tree,
 		     buf->start, buf->start + buf->len - 1,
 		     EXTENT_DEFRAG, GFP_NOFS);
 }
@@ -993,10 +1002,10 @@ int btrfs_read_buffer(struct extent_buffer *buf)
 {
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	return read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
+	return read_extent_buffer_pages(&BTRFS_I(btree_inode)->io_tree,
 					buf, 0, 1);
 }
 
-static struct extent_map_ops btree_extent_map_ops = {
+static struct extent_io_ops btree_extent_io_ops = {
 	.writepage_io_hook = btree_writepage_io_hook,
 };

commit e18e4809b10e6c9efb5fe10c1ddcb4ebb690d517
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jan 18 10:54:22 2008 -0500

    Btrfs: Add mount -o ssd, which includes optimizations for seek free storage
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 731a534f81f5..5d1f9bca2712 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -193,6 +193,7 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	}
 	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
 	read_extent_buffer_pages(tree, eb, start + PAGE_CACHE_SIZE, 1);
+	btrfs_clear_buffer_defrag(eb);
 	found_start = btrfs_header_bytenr(eb);
 	if (found_start != start) {
 		printk("warning: eb start incorrect %Lu buffer %Lu len %lu\n",
@@ -676,6 +677,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->do_barriers = 1;
 	fs_info->closing = 0;
 	fs_info->total_pinned = 0;
+	fs_info->last_alloc = 0;
+
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
 	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);
 #else

commit 04005cc7a1feef94237204566ccac38571af7991
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 17 12:01:41 2008 -0500

    Btrfs: Use blk_congestion_wait on older kernels
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index cd29922d4073..731a534f81f5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -919,8 +919,13 @@ void btrfs_throttle(struct btrfs_root *root)
 	struct backing_dev_info *bdi;
 
 	bdi = root->fs_info->sb->s_bdev->bd_inode->i_mapping->backing_dev_info;
-	if (root->fs_info->throttles && bdi_write_congested(bdi))
+	if (root->fs_info->throttles && bdi_write_congested(bdi)) {
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,18)
 		congestion_wait(WRITE, HZ/20);
+#else
+		blk_congestion_wait(WRITE, HZ/20);
+#endif
+	}
 }
 
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)

commit cee36a03e8f7c6e14aefd497d3acf01bcd3ef153
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 15 08:40:48 2008 -0500

    Rework btrfs_drop_inode to avoid scheduling
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 87daed632f37..cd29922d4073 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -639,6 +639,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	INIT_LIST_HEAD(&fs_info->hashers);
 	spin_lock_init(&fs_info->hash_lock);
 	spin_lock_init(&fs_info->delalloc_lock);
+	spin_lock_init(&fs_info->new_trans_lock);
 
 	memset(&fs_info->super_kobj, 0, sizeof(fs_info->super_kobj));
 	init_completion(&fs_info->kobj_unregister);

commit b99aa6cb548ae9461c5dc0e38f88ebc618ea68d7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 14 14:41:16 2008 -0500

    Btrfs: Only delete roots from sysfs when they were added to sysfs
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0338f8fd382d..87daed632f37 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -795,7 +795,8 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 {
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
-	btrfs_sysfs_del_root(root);
+	if (root->in_sysfs)
+		btrfs_sysfs_del_root(root);
 	if (root->inode)
 		iput(root->inode);
 	if (root->node)

commit 55c69072d6bd5be170a85467f64a20963cddf490
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jan 9 15:55:33 2008 -0500

    Btrfs: Fix extent_buffer usage when nodesize != leafsize
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a481b970608c..0338f8fd382d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -197,9 +197,23 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	if (found_start != start) {
 		printk("warning: eb start incorrect %Lu buffer %Lu len %lu\n",
 		       start, found_start, len);
+		WARN_ON(1);
+		goto err;
+	}
+	if (eb->first_page != page) {
+		printk("bad first page %lu %lu\n", eb->first_page->index,
+		       page->index);
+		WARN_ON(1);
+		goto err;
+	}
+	if (!PageUptodate(page)) {
+		printk("csum not up to date page %lu\n", page->index);
+		WARN_ON(1);
+		goto err;
 	}
 	found_level = btrfs_header_level(eb);
 	csum_tree_block(root, eb, 0);
+err:
 	free_extent_buffer(eb);
 out:
 	return 0;
@@ -368,7 +382,10 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		     struct extent_buffer *buf)
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, buf);
+	if (btrfs_header_generation(buf) ==
+	    root->fs_info->running_transaction->transid)
+		clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree,
+					  buf);
 	return 0;
 }
 
@@ -897,8 +914,11 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 
 void btrfs_throttle(struct btrfs_root *root)
 {
-	if (root->fs_info->throttles)
-		congestion_wait(WRITE, HZ/10);
+	struct backing_dev_info *bdi;
+
+	bdi = root->fs_info->sb->s_bdev->bd_inode->i_mapping->backing_dev_info;
+	if (root->fs_info->throttles && bdi_write_congested(bdi))
+		congestion_wait(WRITE, HZ/20);
 }
 
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)

commit 21ad10cf3e9c1ef42e725e5c3a593c49f779a16b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jan 9 09:23:21 2008 -0500

    Btrfs: Add flush barriers on commit
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e0940a39ff07..a481b970608c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -762,10 +762,15 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 	int ret;
 	struct extent_buffer *super = root->fs_info->sb_buffer;
 	struct inode *btree_inode = root->fs_info->btree_inode;
+	struct super_block *sb = root->fs_info->sb;
 
+	if (!btrfs_test_opt(root, NOBARRIER))
+		blkdev_issue_flush(sb->s_bdev, NULL);
 	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, super);
 	ret = sync_page_range_nolock(btree_inode, btree_inode->i_mapping,
 				     super->start, super->len);
+	if (!btrfs_test_opt(root, NOBARRIER))
+		blkdev_issue_flush(sb->s_bdev, NULL);
 	return ret;
 }
 

commit e2008b61401ecb467a8ce1788fcd2116ae1cfbc1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 8 15:46:30 2008 -0500

    Btrfs: Add some simple throttling to wait for data=ordered and snapshot deletion
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 34cf1f1f47be..e0940a39ff07 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -631,6 +631,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
 	fs_info->sb = sb;
+	fs_info->throttles = 0;
 	fs_info->mount_opt = 0;
 	fs_info->max_extent = (u64)-1;
 	fs_info->delalloc_bytes = 0;
@@ -889,6 +890,12 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, buf);
 }
 
+void btrfs_throttle(struct btrfs_root *root)
+{
+	if (root->fs_info->throttles)
+		congestion_wait(WRITE, HZ/10);
+}
+
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 {
 	balance_dirty_pages_ratelimited_nr(

commit dc17ff8f11d129db9e83ab7244769e4eae05e14d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 8 15:46:30 2008 -0500

    Btrfs: Add data=ordered support
    
    This forces file data extents down the disk along with the metadata that
    references them.  The current implementation is fairly simple, and just
    writes out all of the dirty pages in an inode before the commit.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a6170ff19e7f..34cf1f1f47be 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -406,7 +406,6 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
 	memset(&root->root_kobj, 0, sizeof(root->root_kobj));
 	init_completion(&root->kobj_unregister);
-	init_rwsem(&root->snap_sem);
 	root->defrag_running = 0;
 	root->defrag_level = 0;
 	root->root_key.objectid = objectid;
@@ -498,6 +497,21 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 	return root;
 }
 
+struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,
+					u64 root_objectid)
+{
+	struct btrfs_root *root;
+
+	if (root_objectid == BTRFS_ROOT_TREE_OBJECTID)
+		return fs_info->tree_root;
+	if (root_objectid == BTRFS_EXTENT_TREE_OBJECTID)
+		return fs_info->extent_root;
+
+	root = radix_tree_lookup(&fs_info->fs_roots_radix,
+				 (unsigned long)root_objectid);
+	return root;
+}
+
 struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
 					      struct btrfs_key *location)
 {

commit e4204dedbbaa3a614605cb83cc0ac5161af6b4e6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 8 15:46:27 2008 -0500

    Btrfs: Change tree block csum tagging to avoid false error messages
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 67d9fd728868..a6170ff19e7f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -145,10 +145,25 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 	btrfs_csum_final(crc, result);
 
 	if (verify) {
-		if (memcmp_extent_buffer(buf, result, 0, BTRFS_CRC32_SIZE)) {
-			printk("btrfs: %s checksum verify failed on %llu\n",
+		int from_this_trans = 0;
+
+		if (root->fs_info->running_transaction &&
+		    btrfs_header_generation(buf) ==
+		    root->fs_info->running_transaction->transid)
+			from_this_trans = 1;
+
+		/* FIXME, this is not good */
+		if (from_this_trans == 0 &&
+		    memcmp_extent_buffer(buf, result, 0, BTRFS_CRC32_SIZE)) {
+			u32 val;
+			u32 found = 0;
+			memcpy(&found, result, BTRFS_CRC32_SIZE);
+
+			read_extent_buffer(buf, &val, 0, BTRFS_CRC32_SIZE);
+			printk("btrfs: %s checksum verify failed on %llu "
+			       "wanted %X found %X from_this_trans %d\n",
 			       root->fs_info->sb->s_id,
-			       buf->start);
+			       buf->start, val, found, from_this_trans);
 			return 1;
 		}
 	} else {
@@ -313,6 +328,7 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	struct extent_map_tree *extent_tree;
+	u64 end;
 	int ret;
 
 	extent_tree = &BTRFS_I(btree_inode)->extent_tree;
@@ -322,19 +338,29 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 		return NULL;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
 				 buf, 0, 1);
-	if (buf->flags & EXTENT_CSUM) {
+
+	if (buf->flags & EXTENT_CSUM)
 		return buf;
-	}
-	if (test_range_bit(extent_tree, buf->start, buf->start + buf->len - 1,
-			   EXTENT_CSUM, 1)) {
+
+	end = buf->start + PAGE_CACHE_SIZE - 1;
+	if (test_range_bit(extent_tree, buf->start, end, EXTENT_CSUM, 1)) {
 		buf->flags |= EXTENT_CSUM;
 		return buf;
 	}
+
+	lock_extent(extent_tree, buf->start, end, GFP_NOFS);
+
+	if (test_range_bit(extent_tree, buf->start, end, EXTENT_CSUM, 1)) {
+		buf->flags |= EXTENT_CSUM;
+		goto out_unlock;
+	}
+
 	ret = csum_tree_block(root, buf, 1);
-	set_extent_bits(extent_tree, buf->start,
-			buf->start + buf->len - 1,
-			EXTENT_CSUM, GFP_NOFS);
+	set_extent_bits(extent_tree, buf->start, end, EXTENT_CSUM, GFP_NOFS);
 	buf->flags |= EXTENT_CSUM;
+
+out_unlock:
+	unlock_extent(extent_tree, buf->start, end, GFP_NOFS);
 	return buf;
 }
 

commit 4313b3994d719fcdeb7e661473019ca3d62e829b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 3 09:08:48 2008 -0500

    Btrfs: Reduce stack usage in the resizer, fix 32 bit compiles
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index de026d9d9b2b..67d9fd728868 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -374,6 +374,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->highest_inode = 0;
 	root->last_inode_alloc = 0;
 	root->name = NULL;
+	root->in_sysfs = 0;
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
@@ -516,6 +517,9 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 	if (!root)
 		return NULL;
 
+	if (root->in_sysfs)
+		return root;
+
 	ret = btrfs_set_root_name(root, name, namelen);
 	if (ret) {
 		free_extent_buffer(root->node);
@@ -530,6 +534,7 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
+	root->in_sysfs = 1;
 	return root;
 }
 #if 0

commit edbd8d4efe4ddaf29a175ae504e2c9a05a96ebee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Dec 21 16:27:24 2007 -0500

    Btrfs: Support for online FS resize (grow and shrink)
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eebb4fb65c61..de026d9d9b2b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -471,13 +471,17 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 	return root;
 }
 
-struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
-				      struct btrfs_key *location,
-				      const char *name, int namelen)
+struct btrfs_root *btrfs_read_fs_root_no_name(struct btrfs_fs_info *fs_info,
+					      struct btrfs_key *location)
 {
 	struct btrfs_root *root;
 	int ret;
 
+	if (location->objectid == BTRFS_ROOT_TREE_OBJECTID)
+		return fs_info->tree_root;
+	if (location->objectid == BTRFS_EXTENT_TREE_OBJECTID)
+		return fs_info->extent_root;
+
 	root = radix_tree_lookup(&fs_info->fs_roots_radix,
 				 (unsigned long)location->objectid);
 	if (root)
@@ -494,6 +498,23 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
+	ret = btrfs_find_dead_roots(fs_info->tree_root,
+				    root->root_key.objectid, root);
+	BUG_ON(ret);
+
+	return root;
+}
+
+struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
+				      struct btrfs_key *location,
+				      const char *name, int namelen)
+{
+	struct btrfs_root *root;
+	int ret;
+
+	root = btrfs_read_fs_root_no_name(fs_info, location);
+	if (!root)
+		return NULL;
 
 	ret = btrfs_set_root_name(root, name, namelen);
 	if (ret) {
@@ -509,11 +530,6 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
-
-	ret = btrfs_find_dead_roots(fs_info->tree_root,
-				    root->root_key.objectid, root);
-	BUG_ON(ret);
-
 	return root;
 }
 #if 0

commit 1832a6d5ee3b1af61001cadba9e10da9e91af4a4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Dec 21 16:27:21 2007 -0500

    Btrfs: Implement basic support for -ENOSPC
    
    This is intended to prevent accidentally filling the drive.  A determined
    user can still make things oops.
    
    It includes some accounting of the current bytes under delayed allocation,
    but this will change as things get optimized
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ebb2db624fdd..eebb4fb65c61 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -223,7 +223,8 @@ static int btree_writepages(struct address_space *mapping,
 		} else {
 			thresh = 8 * 1024 * 1024;
 		}
-		num_dirty = count_range_bits(tree, &start, thresh, EXTENT_DIRTY);
+		num_dirty = count_range_bits(tree, &start, (u64)-1,
+					     thresh, EXTENT_DIRTY);
 		if (num_dirty < thresh) {
 			return 0;
 		}
@@ -559,6 +560,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	INIT_LIST_HEAD(&fs_info->hashers);
 	spin_lock_init(&fs_info->hash_lock);
+	spin_lock_init(&fs_info->delalloc_lock);
 
 	memset(&fs_info->super_kobj, 0, sizeof(fs_info->super_kobj));
 	init_completion(&fs_info->kobj_unregister);
@@ -570,6 +572,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->sb = sb;
 	fs_info->mount_opt = 0;
 	fs_info->max_extent = (u64)-1;
+	fs_info->delalloc_bytes = 0;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;

commit 6da6abae027e2dbc59bca5f4168b0760f25068c7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 18 16:15:09 2007 -0500

    Btrfs: Back port to 2.6.18-el kernels
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7213012c27d5..ebb2db624fdd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -593,8 +593,11 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->do_barriers = 1;
 	fs_info->closing = 0;
 	fs_info->total_pinned = 0;
-
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+	INIT_WORK(&fs_info->trans_work, btrfs_transaction_cleaner, fs_info);
+#else
 	INIT_DELAYED_WORK(&fs_info->trans_work, btrfs_transaction_cleaner);
+#endif
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));

commit c59f8951d48c5eb000926935f3ab063d8181d1ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 17 20:14:04 2007 -0500

    Btrfs: Add mount option to enforce a max extent size
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 278564178993..7213012c27d5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -569,6 +569,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->extent_root = extent_root;
 	fs_info->sb = sb;
 	fs_info->mount_opt = 0;
+	fs_info->max_extent = (u64)-1;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;

commit d10c5f31c79c6a703974ae29d0a05781b828fe30
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Dec 17 20:14:04 2007 -0500

    Btrfs: Fix extent_map and extent_state leaks by flushing lrus on FS unmount
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4338b00c2a25..278564178993 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -765,8 +765,18 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_free_block_groups(root->fs_info);
 	del_fs_roots(fs_info);
+
+	filemap_write_and_wait(fs_info->btree_inode->i_mapping);
+
+	extent_map_tree_empty_lru(&fs_info->free_space_cache);
+	extent_map_tree_empty_lru(&fs_info->block_group_cache);
+	extent_map_tree_empty_lru(&fs_info->pinned_extents);
+	extent_map_tree_empty_lru(&fs_info->pending_del);
+	extent_map_tree_empty_lru(&fs_info->extent_ins);
 	extent_map_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->extent_tree);
+
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
+
 	iput(fs_info->btree_inode);
 #if 0
 	while(!list_empty(&fs_info->hashers)) {

commit b6cda9bcb4df7544c67fc3548a53bc1607d59f46
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Dec 14 15:30:32 2007 -0500

    Btrfs: Add mount -o nodatasum to turn of file data checksumming
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 60a30da6af00..4338b00c2a25 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -568,6 +568,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
 	fs_info->sb = sb;
+	fs_info->mount_opt = 0;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;

commit d8d5f3e16d1ae4fe9b93312e083f2c04a95520f0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 11 12:42:00 2007 -0500

    Btrfs: Add lowest key information to back refs for extent tree blocks as well.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0ac21e3aac87..60a30da6af00 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -210,7 +210,7 @@ static int btree_writepages(struct address_space *mapping,
 {
 	struct extent_map_tree *tree;
 	tree = &BTRFS_I(mapping->host)->extent_tree;
-	if (0 && wbc->sync_mode == WB_SYNC_NONE) {
+	if (wbc->sync_mode == WB_SYNC_NONE) {
 		u64 num_dirty;
 		u64 start = 0;
 		unsigned long thresh = 96 * 1024 * 1024;

commit 7bb86316c3961d1bc401ef184fd996f999556c7f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 11 09:25:06 2007 -0500

    Btrfs: Add back pointers from extents to the btree or file referencing them
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 60a30da6af00..0ac21e3aac87 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -210,7 +210,7 @@ static int btree_writepages(struct address_space *mapping,
 {
 	struct extent_map_tree *tree;
 	tree = &BTRFS_I(mapping->host)->extent_tree;
-	if (wbc->sync_mode == WB_SYNC_NONE) {
+	if (0 && wbc->sync_mode == WB_SYNC_NONE) {
 		u64 num_dirty;
 		u64 start = 0;
 		unsigned long thresh = 96 * 1024 * 1024;

commit 87ee04eb0f2f0c63314cef4a76bd1adac748425e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Nov 30 11:30:34 2007 -0500

    Btrfs: Add simple stripe size parameter
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index eef4ab56b9ca..60a30da6af00 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -355,7 +355,7 @@ int wait_on_tree_block_writeback(struct btrfs_root *root,
 }
 
 static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
-			struct btrfs_root *root,
+			u32 stripesize, struct btrfs_root *root,
 			struct btrfs_fs_info *fs_info,
 			u64 objectid)
 {
@@ -365,6 +365,7 @@ static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 	root->sectorsize = sectorsize;
 	root->nodesize = nodesize;
 	root->leafsize = leafsize;
+	root->stripesize = stripesize;
 	root->ref_cows = 0;
 	root->fs_info = fs_info;
 	root->objectid = objectid;
@@ -393,7 +394,8 @@ static int find_and_setup_root(struct btrfs_root *tree_root,
 	u32 blocksize;
 
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
-		     tree_root->sectorsize, root, fs_info, objectid);
+		     tree_root->sectorsize, tree_root->stripesize,
+		     root, fs_info, objectid);
 	ret = btrfs_find_last_root(tree_root, objectid,
 				   &root->root_item, &root->root_key);
 	BUG_ON(ret);
@@ -430,8 +432,8 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 	}
 
 	__setup_root(tree_root->nodesize, tree_root->leafsize,
-		     tree_root->sectorsize, root, fs_info,
-		     location->objectid);
+		     tree_root->sectorsize, tree_root->stripesize,
+		     root, fs_info, location->objectid);
 
 	path = btrfs_alloc_path();
 	BUG_ON(!path);
@@ -537,6 +539,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	u32 nodesize;
 	u32 leafsize;
 	u32 blocksize;
+	u32 stripesize;
 	struct btrfs_root *extent_root = kmalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
 	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
@@ -607,7 +610,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 		goto fail_iput;
 	}
 #endif
-	__setup_root(512, 512, 512, tree_root,
+	__setup_root(512, 512, 512, 512, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
 	fs_info->sb_buffer = read_tree_block(tree_root,
@@ -630,9 +633,11 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	nodesize = btrfs_super_nodesize(disk_super);
 	leafsize = btrfs_super_leafsize(disk_super);
 	sectorsize = btrfs_super_sectorsize(disk_super);
+	stripesize = btrfs_super_stripesize(disk_super);
 	tree_root->nodesize = nodesize;
 	tree_root->leafsize = leafsize;
 	tree_root->sectorsize = sectorsize;
+	tree_root->stripesize = stripesize;
 	sb_set_blocksize(sb, sectorsize);
 
 	i_size_write(fs_info->btree_inode,

commit ca6646264b7dab662d84435441164bb2a8e8885a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 27 11:16:35 2007 -0500

    Btrfs: Add efficient dirty accounting to the extent_map tree
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index de0552532d23..eef4ab56b9ca 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -210,7 +210,7 @@ static int btree_writepages(struct address_space *mapping,
 {
 	struct extent_map_tree *tree;
 	tree = &BTRFS_I(mapping->host)->extent_tree;
-	if (wbc->sync_mode == WB_SYNC_NONE && current_is_pdflush()) {
+	if (wbc->sync_mode == WB_SYNC_NONE) {
 		u64 num_dirty;
 		u64 start = 0;
 		unsigned long thresh = 96 * 1024 * 1024;
@@ -218,6 +218,11 @@ static int btree_writepages(struct address_space *mapping,
 		if (wbc->for_kupdate)
 			return 0;
 
+		if (current_is_pdflush()) {
+			thresh = 96 * 1024 * 1024;
+		} else {
+			thresh = 8 * 1024 * 1024;
+		}
 		num_dirty = count_range_bits(tree, &start, thresh, EXTENT_DIRTY);
 		if (num_dirty < thresh) {
 			return 0;

commit 448d640b668dae3928591e83f2bf4ca9f4c06e52
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Nov 27 07:52:01 2007 -0800

    Btrfs: Fine tune the btree writeback exclusion some more
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8a74f9027d65..de0552532d23 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -214,6 +214,10 @@ static int btree_writepages(struct address_space *mapping,
 		u64 num_dirty;
 		u64 start = 0;
 		unsigned long thresh = 96 * 1024 * 1024;
+
+		if (wbc->for_kupdate)
+			return 0;
+
 		num_dirty = count_range_bits(tree, &start, thresh, EXTENT_DIRTY);
 		if (num_dirty < thresh) {
 			return 0;

commit 8790bad7fb5ac4929dcd52c5dd8d6b81f8c05be8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 26 19:47:05 2007 -0500

    Btrfs: Only limit btree writeback for pdflush
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 28e9ef8a3253..8a74f9027d65 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -210,7 +210,7 @@ static int btree_writepages(struct address_space *mapping,
 {
 	struct extent_map_tree *tree;
 	tree = &BTRFS_I(mapping->host)->extent_tree;
-	if (wbc->sync_mode == WB_SYNC_NONE) {
+	if (wbc->sync_mode == WB_SYNC_NONE && current_is_pdflush()) {
 		u64 num_dirty;
 		u64 start = 0;
 		unsigned long thresh = 96 * 1024 * 1024;

commit 793955bca66c99defdffc857ae6eb7e8431d6bbe
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 26 16:34:41 2007 -0800

    Btrfs: Limit btree writeback to prevent seeks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3e16cca72b49..28e9ef8a3253 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -210,6 +210,15 @@ static int btree_writepages(struct address_space *mapping,
 {
 	struct extent_map_tree *tree;
 	tree = &BTRFS_I(mapping->host)->extent_tree;
+	if (wbc->sync_mode == WB_SYNC_NONE) {
+		u64 num_dirty;
+		u64 start = 0;
+		unsigned long thresh = 96 * 1024 * 1024;
+		num_dirty = count_range_bits(tree, &start, thresh, EXTENT_DIRTY);
+		if (num_dirty < thresh) {
+			return 0;
+		}
+	}
 	return extent_writepages(tree, mapping, btree_get_extent, wbc);
 }
 

commit 324ae4df00fdc1a6a179bf584d8addf027bb75fb
Author: Yan <yanzheng@21cn.com>
Date:   Fri Nov 16 14:57:08 2007 -0500

    Btrfs: Add block group pinned accounting back
    
    This patch adds a helper function 'update_pinned_extents' to
    extent-tree.c. The usage of the helper function is similar to
    'update_block_group',  the last parameter of the function indicates
    pin vs unpin.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6c8533fba7c9..3e16cca72b49 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -569,6 +569,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 	fs_info->closing = 0;
+	fs_info->total_pinned = 0;
 
 	INIT_DELAYED_WORK(&fs_info->trans_work, btrfs_transaction_cleaner);
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;

commit 0da5468f4724a59e745d938395beffe830c424ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Nov 7 21:08:01 2007 -0500

    Btrfs: Use writepages for the metadata too
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8935eec31ee2..6c8533fba7c9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -43,6 +43,8 @@ static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
 }
 #endif
 
+static struct extent_map_ops btree_extent_map_ops;
+
 struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 					    u64 bytenr, u32 blocksize)
 {
@@ -188,15 +190,29 @@ int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 	return 0;
 }
 
-static int btree_writepage(struct page *page, struct writeback_control *wbc)
+static int btree_writepage_io_hook(struct page *page, u64 start, u64 end)
 {
-	struct extent_map_tree *tree;
 	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
-	tree = &BTRFS_I(page->mapping->host)->extent_tree;
 
 	csum_dirty_buffer(root, page);
+	return 0;
+}
+
+static int btree_writepage(struct page *page, struct writeback_control *wbc)
+{
+	struct extent_map_tree *tree;
+	tree = &BTRFS_I(page->mapping->host)->extent_tree;
 	return extent_write_full_page(tree, page, btree_get_extent, wbc);
 }
+
+static int btree_writepages(struct address_space *mapping,
+			    struct writeback_control *wbc)
+{
+	struct extent_map_tree *tree;
+	tree = &BTRFS_I(mapping->host)->extent_tree;
+	return extent_writepages(tree, mapping, btree_get_extent, wbc);
+}
+
 int btree_readpage(struct file *file, struct page *page)
 {
 	struct extent_map_tree *tree;
@@ -251,6 +267,7 @@ static int btree_writepage(struct page *page, struct writeback_control *wbc)
 static struct address_space_operations btree_aops = {
 	.readpage	= btree_readpage,
 	.writepage	= btree_writepage,
+	.writepages	= btree_writepages,
 	.releasepage	= btree_releasepage,
 	.invalidatepage = btree_invalidatepage,
 	.sync_page	= block_sync_page,
@@ -538,6 +555,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree,
 			     fs_info->btree_inode->i_mapping,
 			     GFP_NOFS);
+	BTRFS_I(fs_info->btree_inode)->extent_tree.ops = &btree_extent_map_ops;
+
 	extent_map_tree_init(&fs_info->free_space_cache,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	extent_map_tree_init(&fs_info->block_group_cache,
@@ -832,3 +851,7 @@ int btrfs_read_buffer(struct extent_buffer *buf)
 	return read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
 					buf, 0, 1);
 }
+
+static struct extent_map_ops btree_extent_map_ops = {
+	.writepage_io_hook = btree_writepage_io_hook,
+};

commit 35ebb934bd7fcc7ca991b155b7980c3c4ff9f1a5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Oct 30 16:56:53 2007 -0400

    Btrfs: Fix PAGE_CACHE_SHIFT shifts on 32 bit machines
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5a7e60d7f443..8935eec31ee2 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -159,7 +159,7 @@ static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
 {
 	struct extent_map_tree *tree;
-	u64 start = page->index << PAGE_CACHE_SHIFT;
+	u64 start = (u64)page->index << PAGE_CACHE_SHIFT;
 	u64 found_start;
 	int found_level;
 	unsigned long len;

commit 44b36eb20bb60d7da1375c1fb45784740a4dc358
Author: Yan Zheng <yanzheng@21cn.com>
Date:   Fri Oct 19 09:22:56 2007 -0400

    Btrfs: Properly setup root key while reading the root
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5accced2858a..5a7e60d7f443 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -410,6 +410,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 	read_extent_buffer(l, &root->root_item,
 	       btrfs_item_ptr_offset(l, path->slots[0]),
 	       sizeof(root->root_item));
+	memcpy(&root->root_key, location, sizeof(*location));
 	ret = 0;
 out:
 	btrfs_release_path(root, path);

commit ff79f8190b6e955ff7a71faf804a3017d526e657
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:22:25 2007 -0400

    Btrfs: Add back file data checksumming
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3878772fcffd..5accced2858a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -594,6 +594,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	tree_root->nodesize = nodesize;
 	tree_root->leafsize = leafsize;
 	tree_root->sectorsize = sectorsize;
+	sb_set_blocksize(sb, sectorsize);
 
 	i_size_write(fs_info->btree_inode,
 		     btrfs_super_total_bytes(disk_super));

commit 304fced668079ce222200d5742657d34cc44af09
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:21:17 2007 -0400

    Btrfs: balance_dirty_pages_ratelimited is causing problems, use nr == 1 always
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1176e5420c56..3878772fcffd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -768,7 +768,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 {
 	balance_dirty_pages_ratelimited_nr(
-			root->fs_info->btree_inode->i_mapping, nr);
+			root->fs_info->btree_inode->i_mapping, 1);
 }
 
 void btrfs_set_buffer_defrag(struct extent_buffer *buf)

commit 19c00ddcc31ad4bdfb86b57085e06d6135b9b1d7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:19:22 2007 -0400

    Btrfs: Add back metadata checksumming
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 16f0260fca66..1176e5420c56 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -60,7 +60,7 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 	struct extent_buffer *eb;
 
 	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
-				 bytenr, blocksize, GFP_NOFS);
+				 bytenr, blocksize, NULL, GFP_NOFS);
 	return eb;
 }
 
@@ -99,10 +99,102 @@ struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
 	return em;
 }
 
+u32 btrfs_csum_data(struct btrfs_root *root, char *data, u32 seed, size_t len)
+{
+	return crc32c(seed, data, len);
+}
+
+void btrfs_csum_final(u32 crc, char *result)
+{
+	*(__le32 *)result = ~cpu_to_le32(crc);
+}
+
+static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
+			   int verify)
+{
+	char result[BTRFS_CRC32_SIZE];
+	unsigned long len;
+	unsigned long cur_len;
+	unsigned long offset = BTRFS_CSUM_SIZE;
+	char *map_token = NULL;
+	char *kaddr;
+	unsigned long map_start;
+	unsigned long map_len;
+	int err;
+	u32 crc = ~(u32)0;
+
+	len = buf->len - offset;
+	while(len > 0) {
+		err = map_private_extent_buffer(buf, offset, 32,
+					&map_token, &kaddr,
+					&map_start, &map_len, KM_USER0);
+		if (err) {
+			printk("failed to map extent buffer! %lu\n",
+			       offset);
+			return 1;
+		}
+		cur_len = min(len, map_len - (offset - map_start));
+		crc = btrfs_csum_data(root, kaddr + offset - map_start,
+				      crc, cur_len);
+		len -= cur_len;
+		offset += cur_len;
+		unmap_extent_buffer(buf, map_token, KM_USER0);
+	}
+	btrfs_csum_final(crc, result);
+
+	if (verify) {
+		if (memcmp_extent_buffer(buf, result, 0, BTRFS_CRC32_SIZE)) {
+			printk("btrfs: %s checksum verify failed on %llu\n",
+			       root->fs_info->sb->s_id,
+			       buf->start);
+			return 1;
+		}
+	} else {
+		write_extent_buffer(buf, result, 0, BTRFS_CRC32_SIZE);
+	}
+	return 0;
+}
+
+
+int csum_dirty_buffer(struct btrfs_root *root, struct page *page)
+{
+	struct extent_map_tree *tree;
+	u64 start = page->index << PAGE_CACHE_SHIFT;
+	u64 found_start;
+	int found_level;
+	unsigned long len;
+	struct extent_buffer *eb;
+	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+
+	if (page->private == EXTENT_PAGE_PRIVATE)
+		goto out;
+	if (!page->private)
+		goto out;
+	len = page->private >> 2;
+	if (len == 0) {
+		WARN_ON(1);
+	}
+	eb = alloc_extent_buffer(tree, start, len, page, GFP_NOFS);
+	read_extent_buffer_pages(tree, eb, start + PAGE_CACHE_SIZE, 1);
+	found_start = btrfs_header_bytenr(eb);
+	if (found_start != start) {
+		printk("warning: eb start incorrect %Lu buffer %Lu len %lu\n",
+		       start, found_start, len);
+	}
+	found_level = btrfs_header_level(eb);
+	csum_tree_block(root, eb, 0);
+	free_extent_buffer(eb);
+out:
+	return 0;
+}
+
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct extent_map_tree *tree;
+	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
 	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+
+	csum_dirty_buffer(root, page);
 	return extent_write_full_page(tree, page, btree_get_extent, wbc);
 }
 int btree_readpage(struct file *file, struct page *page)
@@ -117,7 +209,6 @@ static int btree_releasepage(struct page *page, gfp_t unused_gfp_flags)
 	struct extent_map_tree *tree;
 	int ret;
 
-	BUG_ON(page->private != 1);
 	tree = &BTRFS_I(page->mapping->host)->extent_tree;
 	ret = try_release_extent_mapping(tree, page);
 	if (ret == 1) {
@@ -136,46 +227,6 @@ static void btree_invalidatepage(struct page *page, unsigned long offset)
 	btree_releasepage(page, GFP_NOFS);
 }
 
-int btrfs_csum_data(struct btrfs_root * root, char *data, size_t len,
-		    char *result)
-{
-	return 0;
-#if 0
-	u32 crc;
-	crc = crc32c(0, data, len);
-	memcpy(result, &crc, BTRFS_CRC32_SIZE);
-	return 0;
-#endif
-}
-
-#if 0
-static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
-			   int verify)
-{
-	return 0;
-	char result[BTRFS_CRC32_SIZE];
-	int ret;
-	struct btrfs_node *node;
-
-	ret = btrfs_csum_data(root, bh->b_data + BTRFS_CSUM_SIZE,
-			      bh->b_size - BTRFS_CSUM_SIZE, result);
-	if (ret)
-		return ret;
-	if (verify) {
-		if (memcmp(bh->b_data, result, BTRFS_CRC32_SIZE)) {
-			printk("btrfs: %s checksum verify failed on %llu\n",
-			       root->fs_info->sb->s_id,
-			       (unsigned long long)bh_blocknr(bh));
-			return 1;
-		}
-	} else {
-		node = btrfs_buffer_node(bh);
-		memcpy(node->header.csum, result, BTRFS_CRC32_SIZE);
-	}
-	return 0;
-}
-#endif
-
 #if 0
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
@@ -215,7 +266,7 @@ int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
 	if (!buf)
 		return 0;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
-				 buf, 0);
+				 buf, 0, 0);
 	free_extent_buffer(buf);
 	return ret;
 }
@@ -225,12 +276,29 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
+	struct extent_map_tree *extent_tree;
+	int ret;
+
+	extent_tree = &BTRFS_I(btree_inode)->extent_tree;
 
 	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
 	if (!buf)
 		return NULL;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
-				 buf, 1);
+				 buf, 0, 1);
+	if (buf->flags & EXTENT_CSUM) {
+		return buf;
+	}
+	if (test_range_bit(extent_tree, buf->start, buf->start + buf->len - 1,
+			   EXTENT_CSUM, 1)) {
+		buf->flags |= EXTENT_CSUM;
+		return buf;
+	}
+	ret = csum_tree_block(root, buf, 1);
+	set_extent_bits(extent_tree, buf->start,
+			buf->start + buf->len - 1,
+			EXTENT_CSUM, GFP_NOFS);
+	buf->flags |= EXTENT_CSUM;
 	return buf;
 }
 
@@ -251,13 +319,6 @@ int wait_on_tree_block_writeback(struct btrfs_root *root,
 	return 0;
 }
 
-int set_tree_block_dirty(struct btrfs_root *root, struct extent_buffer *buf)
-{
-	struct inode *btree_inode = root->fs_info->btree_inode;
-	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, buf);
-	return 0;
-}
-
 static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 			struct btrfs_root *root,
 			struct btrfs_fs_info *fs_info,
@@ -416,7 +477,24 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 
 	return root;
 }
-
+#if 0
+static int add_hasher(struct btrfs_fs_info *info, char *type) {
+	struct btrfs_hasher *hasher;
+
+	hasher = kmalloc(sizeof(*hasher), GFP_NOFS);
+	if (!hasher)
+		return -ENOMEM;
+	hasher->hash_tfm = crypto_alloc_hash(type, 0, CRYPTO_ALG_ASYNC);
+	if (!hasher->hash_tfm) {
+		kfree(hasher);
+		return -EINVAL;
+	}
+	spin_lock(&info->hash_lock);
+	list_add(&hasher->list, &info->hashers);
+	spin_unlock(&info->hash_lock);
+	return 0;
+}
+#endif
 struct btrfs_root *open_ctree(struct super_block *sb)
 {
 	u32 sectorsize;
@@ -440,6 +518,9 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
+	INIT_LIST_HEAD(&fs_info->hashers);
+	spin_lock_init(&fs_info->hash_lock);
+
 	memset(&fs_info->super_kobj, 0, sizeof(fs_info->super_kobj));
 	init_completion(&fs_info->kobj_unregister);
 	sb_set_blocksize(sb, 4096);
@@ -479,6 +560,14 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
 
+#if 0
+	ret = add_hasher(fs_info, "crc32c");
+	if (ret) {
+		printk("btrfs: failed hash setup, modprobe cryptomgr?\n");
+		err = -ENOMEM;
+		goto fail_iput;
+	}
+#endif
 	__setup_root(512, 512, 512, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
@@ -509,25 +598,21 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	i_size_write(fs_info->btree_inode,
 		     btrfs_super_total_bytes(disk_super));
 
-
 	if (strncmp((char *)(&disk_super->magic), BTRFS_MAGIC,
 		    sizeof(disk_super->magic))) {
 		printk("btrfs: valid FS not found on %s\n", sb->s_id);
 		goto fail_sb_buffer;
 	}
+
 	blocksize = btrfs_level_size(tree_root,
 				     btrfs_super_root_level(disk_super));
+
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super),
 					  blocksize);
 	if (!tree_root->node)
 		goto fail_sb_buffer;
 
-#if 0
-	btrfs_print_leaf(tree_root, tree_root->node);
-	err = -EIO;
-	goto fail_tree_root;
-#endif
 	mutex_lock(&fs_info->fs_mutex);
 
 	ret = find_and_setup_root(tree_root, fs_info,
@@ -634,9 +719,19 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_free_block_groups(root->fs_info);
 	del_fs_roots(fs_info);
-	extent_map_tree_cleanup(&BTRFS_I(fs_info->btree_inode)->extent_tree);
+	extent_map_tree_empty_lru(&BTRFS_I(fs_info->btree_inode)->extent_tree);
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 	iput(fs_info->btree_inode);
+#if 0
+	while(!list_empty(&fs_info->hashers)) {
+		struct btrfs_hasher *hasher;
+		hasher = list_entry(fs_info->hashers.next, struct btrfs_hasher,
+				    hashers);
+		list_del(&hasher->hashers);
+		crypto_free_hash(&fs_info->hash_tfm);
+		kfree(hasher);
+	}
+#endif
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);
 	return 0;
@@ -733,5 +828,5 @@ int btrfs_read_buffer(struct extent_buffer *buf)
 	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
-					buf, 1);
+					buf, 0, 1);
 }

commit 810191ff3087e8143b41a944fcf4fd8c693f00e3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:18:55 2007 -0400

    Btrfs: extent_map optimizations to cut down on CPU usage
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fd7e6c182b9d..16f0260fca66 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -644,20 +644,20 @@ int close_ctree(struct btrfs_root *root)
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->last_page->mapping->host;
+	struct inode *btree_inode = buf->first_page->mapping->host;
 	return extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree, buf);
 }
 
 int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->last_page->mapping->host;
+	struct inode *btree_inode = buf->first_page->mapping->host;
 	return set_extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree,
 					  buf);
 }
 
 void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	u64 transid = btrfs_header_generation(buf);
 	struct inode *btree_inode = root->fs_info->btree_inode;
 
@@ -678,7 +678,7 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 
 void btrfs_set_buffer_defrag(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	set_extent_bits(&BTRFS_I(btree_inode)->extent_tree, buf->start,
 			buf->start + buf->len - 1, EXTENT_DEFRAG, GFP_NOFS);
@@ -686,7 +686,7 @@ void btrfs_set_buffer_defrag(struct extent_buffer *buf)
 
 void btrfs_set_buffer_defrag_done(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	set_extent_bits(&BTRFS_I(btree_inode)->extent_tree, buf->start,
 			buf->start + buf->len - 1, EXTENT_DEFRAG_DONE,
@@ -695,7 +695,7 @@ void btrfs_set_buffer_defrag_done(struct extent_buffer *buf)
 
 int btrfs_buffer_defrag(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return test_range_bit(&BTRFS_I(btree_inode)->extent_tree,
 		     buf->start, buf->start + buf->len - 1, EXTENT_DEFRAG, 0);
@@ -703,7 +703,7 @@ int btrfs_buffer_defrag(struct extent_buffer *buf)
 
 int btrfs_buffer_defrag_done(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return test_range_bit(&BTRFS_I(btree_inode)->extent_tree,
 		     buf->start, buf->start + buf->len - 1,
@@ -712,7 +712,7 @@ int btrfs_buffer_defrag_done(struct extent_buffer *buf)
 
 int btrfs_clear_buffer_defrag_done(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return clear_extent_bits(&BTRFS_I(btree_inode)->extent_tree,
 		     buf->start, buf->start + buf->len - 1,
@@ -721,7 +721,7 @@ int btrfs_clear_buffer_defrag_done(struct extent_buffer *buf)
 
 int btrfs_clear_buffer_defrag(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return clear_extent_bits(&BTRFS_I(btree_inode)->extent_tree,
 		     buf->start, buf->start + buf->len - 1,
@@ -730,7 +730,7 @@ int btrfs_clear_buffer_defrag(struct extent_buffer *buf)
 
 int btrfs_read_buffer(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
 					buf, 1);

commit 4dc119046d0d8501afa4346472917fb05586ad9c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:18:14 2007 -0400

    Btrfs: Add an extent buffer LRU to reduce radix tree hits
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8e606e6658aa..fd7e6c182b9d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -50,8 +50,6 @@ struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 	struct extent_buffer *eb;
 	eb = find_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
 				bytenr, blocksize, GFP_NOFS);
-	if (eb)
-		eb->alloc_addr = (unsigned long)__builtin_return_address(0);
 	return eb;
 }
 
@@ -63,7 +61,6 @@ struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 
 	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
 				 bytenr, blocksize, GFP_NOFS);
-	eb->alloc_addr = (unsigned long)__builtin_return_address(0);
 	return eb;
 }
 
@@ -234,7 +231,6 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
 		return NULL;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
 				 buf, 1);
-	buf->alloc_addr = (unsigned long)__builtin_return_address(0);
 	return buf;
 }
 
@@ -638,6 +634,7 @@ int close_ctree(struct btrfs_root *root)
 
 	btrfs_free_block_groups(root->fs_info);
 	del_fs_roots(fs_info);
+	extent_map_tree_cleanup(&BTRFS_I(fs_info->btree_inode)->extent_tree);
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 	iput(fs_info->btree_inode);
 	kfree(fs_info->extent_root);
@@ -647,20 +644,20 @@ int close_ctree(struct btrfs_root *root)
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->pages[0]->mapping->host;
+	struct inode *btree_inode = buf->last_page->mapping->host;
 	return extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree, buf);
 }
 
 int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->pages[0]->mapping->host;
+	struct inode *btree_inode = buf->last_page->mapping->host;
 	return set_extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree,
 					  buf);
 }
 
 void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
 	u64 transid = btrfs_header_generation(buf);
 	struct inode *btree_inode = root->fs_info->btree_inode;
 
@@ -681,7 +678,7 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 
 void btrfs_set_buffer_defrag(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	set_extent_bits(&BTRFS_I(btree_inode)->extent_tree, buf->start,
 			buf->start + buf->len - 1, EXTENT_DEFRAG, GFP_NOFS);
@@ -689,7 +686,7 @@ void btrfs_set_buffer_defrag(struct extent_buffer *buf)
 
 void btrfs_set_buffer_defrag_done(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	set_extent_bits(&BTRFS_I(btree_inode)->extent_tree, buf->start,
 			buf->start + buf->len - 1, EXTENT_DEFRAG_DONE,
@@ -698,7 +695,7 @@ void btrfs_set_buffer_defrag_done(struct extent_buffer *buf)
 
 int btrfs_buffer_defrag(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return test_range_bit(&BTRFS_I(btree_inode)->extent_tree,
 		     buf->start, buf->start + buf->len - 1, EXTENT_DEFRAG, 0);
@@ -706,7 +703,7 @@ int btrfs_buffer_defrag(struct extent_buffer *buf)
 
 int btrfs_buffer_defrag_done(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return test_range_bit(&BTRFS_I(btree_inode)->extent_tree,
 		     buf->start, buf->start + buf->len - 1,
@@ -715,7 +712,7 @@ int btrfs_buffer_defrag_done(struct extent_buffer *buf)
 
 int btrfs_clear_buffer_defrag_done(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return clear_extent_bits(&BTRFS_I(btree_inode)->extent_tree,
 		     buf->start, buf->start + buf->len - 1,
@@ -724,7 +721,7 @@ int btrfs_clear_buffer_defrag_done(struct extent_buffer *buf)
 
 int btrfs_clear_buffer_defrag(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return clear_extent_bits(&BTRFS_I(btree_inode)->extent_tree,
 		     buf->start, buf->start + buf->len - 1,
@@ -733,7 +730,7 @@ int btrfs_clear_buffer_defrag(struct extent_buffer *buf)
 
 int btrfs_read_buffer(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->last_page->mapping->host)->root;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	return read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
 					buf, 1);

commit 6b80053d02be41886344b5007d04e345311ec0b5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:17:34 2007 -0400

    Btrfs: Add back the online defragging code
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0636f79672e9..8e606e6658aa 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -678,3 +678,63 @@ void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 	balance_dirty_pages_ratelimited_nr(
 			root->fs_info->btree_inode->i_mapping, nr);
 }
+
+void btrfs_set_buffer_defrag(struct extent_buffer *buf)
+{
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	set_extent_bits(&BTRFS_I(btree_inode)->extent_tree, buf->start,
+			buf->start + buf->len - 1, EXTENT_DEFRAG, GFP_NOFS);
+}
+
+void btrfs_set_buffer_defrag_done(struct extent_buffer *buf)
+{
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	set_extent_bits(&BTRFS_I(btree_inode)->extent_tree, buf->start,
+			buf->start + buf->len - 1, EXTENT_DEFRAG_DONE,
+			GFP_NOFS);
+}
+
+int btrfs_buffer_defrag(struct extent_buffer *buf)
+{
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	return test_range_bit(&BTRFS_I(btree_inode)->extent_tree,
+		     buf->start, buf->start + buf->len - 1, EXTENT_DEFRAG, 0);
+}
+
+int btrfs_buffer_defrag_done(struct extent_buffer *buf)
+{
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	return test_range_bit(&BTRFS_I(btree_inode)->extent_tree,
+		     buf->start, buf->start + buf->len - 1,
+		     EXTENT_DEFRAG_DONE, 0);
+}
+
+int btrfs_clear_buffer_defrag_done(struct extent_buffer *buf)
+{
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	return clear_extent_bits(&BTRFS_I(btree_inode)->extent_tree,
+		     buf->start, buf->start + buf->len - 1,
+		     EXTENT_DEFRAG_DONE, GFP_NOFS);
+}
+
+int btrfs_clear_buffer_defrag(struct extent_buffer *buf)
+{
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	return clear_extent_bits(&BTRFS_I(btree_inode)->extent_tree,
+		     buf->start, buf->start + buf->len - 1,
+		     EXTENT_DEFRAG, GFP_NOFS);
+}
+
+int btrfs_read_buffer(struct extent_buffer *buf)
+{
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	return read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
+					buf, 1);
+}

commit 09e71a326341f40111400c88aaf0498ef622824b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:17:04 2007 -0400

    Btrfs: Use an array of pages in the extent buffers to reduce the cost of find_get_page
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index fad9298c6962..0636f79672e9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -647,20 +647,20 @@ int close_ctree(struct btrfs_root *root)
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->first_page->mapping->host;
+	struct inode *btree_inode = buf->pages[0]->mapping->host;
 	return extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree, buf);
 }
 
 int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->first_page->mapping->host;
+	struct inode *btree_inode = buf->pages[0]->mapping->host;
 	return set_extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree,
 					  buf);
 }
 
 void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
 	u64 transid = btrfs_header_generation(buf);
 	struct inode *btree_inode = root->fs_info->btree_inode;
 

commit db94535db75e67fab12ccbb7f5ee548e33fed891
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:15:53 2007 -0400

    Btrfs: Allow tree blocks larger than the page size
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2b86a1d779b7..fad9298c6962 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -28,6 +28,7 @@
 #include "disk-io.h"
 #include "transaction.h"
 #include "btrfs_inode.h"
+#include "print-tree.h"
 
 #if 0
 static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
@@ -43,26 +44,25 @@ static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
 #endif
 
 struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
-					    u64 blocknr)
+					    u64 bytenr, u32 blocksize)
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	struct extent_buffer *eb;
 	eb = find_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
-				   blocknr * root->sectorsize,
-				   root->sectorsize, GFP_NOFS);
+				bytenr, blocksize, GFP_NOFS);
 	if (eb)
 		eb->alloc_addr = (unsigned long)__builtin_return_address(0);
 	return eb;
 }
 
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
-						 u64 blocknr)
+						 u64 bytenr, u32 blocksize)
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	struct extent_buffer *eb;
+
 	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
-				   blocknr * root->sectorsize,
-				   root->sectorsize, GFP_NOFS);
+				 bytenr, blocksize, GFP_NOFS);
 	eb->alloc_addr = (unsigned long)__builtin_return_address(0);
 	return eb;
 }
@@ -208,13 +208,13 @@ static struct address_space_operations btree_aops = {
 	.sync_page	= block_sync_page,
 };
 
-int readahead_tree_block(struct btrfs_root *root, u64 blocknr)
+int readahead_tree_block(struct btrfs_root *root, u64 bytenr, u32 blocksize)
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 	int ret = 0;
 
-	buf = btrfs_find_create_tree_block(root, blocknr);
+	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
 	if (!buf)
 		return 0;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
@@ -223,12 +223,13 @@ int readahead_tree_block(struct btrfs_root *root, u64 blocknr)
 	return ret;
 }
 
-struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 blocknr)
+struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 bytenr,
+				      u32 blocksize)
 {
 	struct extent_buffer *buf = NULL;
 	struct inode *btree_inode = root->fs_info->btree_inode;
 
-	buf = btrfs_find_create_tree_block(root, blocknr);
+	buf = btrfs_find_create_tree_block(root, bytenr, blocksize);
 	if (!buf)
 		return NULL;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
@@ -261,7 +262,7 @@ int set_tree_block_dirty(struct btrfs_root *root, struct extent_buffer *buf)
 	return 0;
 }
 
-static int __setup_root(int blocksize,
+static int __setup_root(u32 nodesize, u32 leafsize, u32 sectorsize,
 			struct btrfs_root *root,
 			struct btrfs_fs_info *fs_info,
 			u64 objectid)
@@ -269,9 +270,9 @@ static int __setup_root(int blocksize,
 	root->node = NULL;
 	root->inode = NULL;
 	root->commit_root = NULL;
-	root->sectorsize = blocksize;
-	root->nodesize = blocksize;
-	root->leafsize = blocksize;
+	root->sectorsize = sectorsize;
+	root->nodesize = nodesize;
+	root->leafsize = leafsize;
 	root->ref_cows = 0;
 	root->fs_info = fs_info;
 	root->objectid = objectid;
@@ -291,21 +292,23 @@ static int __setup_root(int blocksize,
 	return 0;
 }
 
-static int find_and_setup_root(int blocksize,
-			       struct btrfs_root *tree_root,
+static int find_and_setup_root(struct btrfs_root *tree_root,
 			       struct btrfs_fs_info *fs_info,
 			       u64 objectid,
 			       struct btrfs_root *root)
 {
 	int ret;
+	u32 blocksize;
 
-	__setup_root(blocksize, root, fs_info, objectid);
+	__setup_root(tree_root->nodesize, tree_root->leafsize,
+		     tree_root->sectorsize, root, fs_info, objectid);
 	ret = btrfs_find_last_root(tree_root, objectid,
 				   &root->root_item, &root->root_key);
 	BUG_ON(ret);
 
-	root->node = read_tree_block(root,
-				     btrfs_root_blocknr(&root->root_item));
+	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
+	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
+				     blocksize);
 	BUG_ON(!root->node);
 	return 0;
 }
@@ -318,14 +321,14 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 	struct btrfs_path *path;
 	struct extent_buffer *l;
 	u64 highest_inode;
+	u32 blocksize;
 	int ret = 0;
 
 	root = kzalloc(sizeof(*root), GFP_NOFS);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 	if (location->offset == (u64)-1) {
-		ret = find_and_setup_root(fs_info->sb->s_blocksize,
-					  fs_info->tree_root, fs_info,
+		ret = find_and_setup_root(tree_root, fs_info,
 					  location->objectid, root);
 		if (ret) {
 			kfree(root);
@@ -334,7 +337,8 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 		goto insert;
 	}
 
-	__setup_root(fs_info->sb->s_blocksize, root, fs_info,
+	__setup_root(tree_root->nodesize, tree_root->leafsize,
+		     tree_root->sectorsize, root, fs_info,
 		     location->objectid);
 
 	path = btrfs_alloc_path();
@@ -357,8 +361,9 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
-	root->node = read_tree_block(root,
-				     btrfs_root_blocknr(&root->root_item));
+	blocksize = btrfs_level_size(root, btrfs_root_level(&root->root_item));
+	root->node = read_tree_block(root, btrfs_root_bytenr(&root->root_item),
+				     blocksize);
 	BUG_ON(!root->node);
 insert:
 	root->ref_cows = 1;
@@ -418,6 +423,10 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 
 struct btrfs_root *open_ctree(struct super_block *sb)
 {
+	u32 sectorsize;
+	u32 nodesize;
+	u32 leafsize;
+	u32 blocksize;
 	struct btrfs_root *extent_root = kmalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
 	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
@@ -474,12 +483,12 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
 
-	__setup_root(sb->s_blocksize, tree_root,
+	__setup_root(512, 512, 512, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
 	fs_info->sb_buffer = read_tree_block(tree_root,
-					     BTRFS_SUPER_INFO_OFFSET /
-					     sb->s_blocksize);
+					     BTRFS_SUPER_INFO_OFFSET,
+					     512);
 
 	if (!fs_info->sb_buffer)
 		goto fail_iput;
@@ -494,9 +503,15 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	if (!btrfs_super_root(disk_super))
 		goto fail_sb_buffer;
 
+	nodesize = btrfs_super_nodesize(disk_super);
+	leafsize = btrfs_super_leafsize(disk_super);
+	sectorsize = btrfs_super_sectorsize(disk_super);
+	tree_root->nodesize = nodesize;
+	tree_root->leafsize = leafsize;
+	tree_root->sectorsize = sectorsize;
+
 	i_size_write(fs_info->btree_inode,
-		     btrfs_super_total_blocks(disk_super) <<
-		     fs_info->btree_inode->i_blkbits);
+		     btrfs_super_total_bytes(disk_super));
 
 
 	if (strncmp((char *)(&disk_super->magic), BTRFS_MAGIC,
@@ -504,13 +519,22 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 		printk("btrfs: valid FS not found on %s\n", sb->s_id);
 		goto fail_sb_buffer;
 	}
+	blocksize = btrfs_level_size(tree_root,
+				     btrfs_super_root_level(disk_super));
 	tree_root->node = read_tree_block(tree_root,
-					  btrfs_super_root(disk_super));
+					  btrfs_super_root(disk_super),
+					  blocksize);
 	if (!tree_root->node)
 		goto fail_sb_buffer;
 
+#if 0
+	btrfs_print_leaf(tree_root, tree_root->node);
+	err = -EIO;
+	goto fail_tree_root;
+#endif
 	mutex_lock(&fs_info->fs_mutex);
-	ret = find_and_setup_root(sb->s_blocksize, tree_root, fs_info,
+
+	ret = find_and_setup_root(tree_root, fs_info,
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
 	if (ret) {
 		mutex_unlock(&fs_info->fs_mutex);
@@ -611,11 +635,11 @@ int close_ctree(struct btrfs_root *root)
 		free_extent_buffer(fs_info->tree_root->node);
 
 	free_extent_buffer(fs_info->sb_buffer);
-	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
-	iput(fs_info->btree_inode);
 
 	btrfs_free_block_groups(root->fs_info);
 	del_fs_roots(fs_info);
+	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
+	iput(fs_info->btree_inode);
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);
 	return 0;
@@ -642,7 +666,7 @@ void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 
 	if (transid != root->fs_info->generation) {
 		printk(KERN_CRIT "transid mismatch buffer %llu, found %Lu running %Lu\n",
-			(unsigned long long)extent_buffer_blocknr(buf),
+			(unsigned long long)buf->start,
 			transid, root->fs_info->generation);
 		WARN_ON(1);
 	}

commit 1a5bc167f6707542b79a55452075525620ed43f5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:15:26 2007 -0400

    Btrfs: Change the remaining radix trees used by extent-tree.c to extent_map trees
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index aac7c82b0dce..2b86a1d779b7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -432,9 +432,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 		err = -ENOMEM;
 		goto fail;
 	}
-	init_bit_radix(&fs_info->pinned_radix);
-	init_bit_radix(&fs_info->pending_del_radix);
-	init_bit_radix(&fs_info->extent_ins_radix);
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
@@ -458,6 +455,12 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	extent_map_tree_init(&fs_info->block_group_cache,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+	extent_map_tree_init(&fs_info->pinned_extents,
+			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+	extent_map_tree_init(&fs_info->pending_del,
+			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+	extent_map_tree_init(&fs_info->extent_ins,
+			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 	fs_info->closing = 0;
 

commit 96b5179d0d9b6368c203856f2ad6e8e12a8b2a2c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:15:19 2007 -0400

    Btrfs: Stop using radix trees for the block group cache
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 09f4e694624d..aac7c82b0dce 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -436,8 +436,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	init_bit_radix(&fs_info->pending_del_radix);
 	init_bit_radix(&fs_info->extent_ins_radix);
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
-	INIT_RADIX_TREE(&fs_info->block_group_radix, GFP_KERNEL);
-	INIT_RADIX_TREE(&fs_info->block_group_data_radix, GFP_KERNEL);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	memset(&fs_info->super_kobj, 0, sizeof(fs_info->super_kobj));
@@ -458,6 +456,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 			     GFP_NOFS);
 	extent_map_tree_init(&fs_info->free_space_cache,
 			     fs_info->btree_inode->i_mapping, GFP_NOFS);
+	extent_map_tree_init(&fs_info->block_group_cache,
+			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 	fs_info->closing = 0;
 

commit f510cfecfc98759d75283823cfccf0cc0d59a4c6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:48 2007 -0400

    Btrfs: Fix extent_buffer and extent_state leaks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8242933a1d8b..09f4e694624d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -46,18 +46,25 @@ struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
 					    u64 blocknr)
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	return find_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
+	struct extent_buffer *eb;
+	eb = find_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
 				   blocknr * root->sectorsize,
 				   root->sectorsize, GFP_NOFS);
+	if (eb)
+		eb->alloc_addr = (unsigned long)__builtin_return_address(0);
+	return eb;
 }
 
 struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 blocknr)
 {
 	struct inode *btree_inode = root->fs_info->btree_inode;
-	return alloc_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
+	struct extent_buffer *eb;
+	eb = alloc_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
 				   blocknr * root->sectorsize,
 				   root->sectorsize, GFP_NOFS);
+	eb->alloc_addr = (unsigned long)__builtin_return_address(0);
+	return eb;
 }
 
 struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
@@ -226,6 +233,7 @@ struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 blocknr)
 		return NULL;
 	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
 				 buf, 1);
+	buf->alloc_addr = (unsigned long)__builtin_return_address(0);
 	return buf;
 }
 
@@ -426,7 +434,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	}
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
-	init_bit_radix(&fs_info->extent_map_radix);
 	init_bit_radix(&fs_info->extent_ins_radix);
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_RADIX_TREE(&fs_info->block_group_radix, GFP_KERNEL);
@@ -449,6 +456,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree,
 			     fs_info->btree_inode->i_mapping,
 			     GFP_NOFS);
+	extent_map_tree_init(&fs_info->free_space_cache,
+			     fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->do_barriers = 1;
 	fs_info->closing = 0;
 
@@ -594,8 +603,10 @@ int close_ctree(struct btrfs_root *root)
 
 	if (fs_info->extent_root->node)
 		free_extent_buffer(fs_info->extent_root->node);
+
 	if (fs_info->tree_root->node)
 		free_extent_buffer(fs_info->tree_root->node);
+
 	free_extent_buffer(fs_info->sb_buffer);
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 	iput(fs_info->btree_inode);

commit 6d36dcd48f1e4e7446d603a3df9638bd314a182d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:37 2007 -0400

    Btrfs: Avoid memcpy where possible in extent_buffers
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0c1f90cbedb0..8242933a1d8b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -609,20 +609,20 @@ int close_ctree(struct btrfs_root *root)
 
 int btrfs_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->pages[0]->mapping->host;
+	struct inode *btree_inode = buf->first_page->mapping->host;
 	return extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree, buf);
 }
 
 int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct inode *btree_inode = buf->pages[0]->mapping->host;
+	struct inode *btree_inode = buf->first_page->mapping->host;
 	return set_extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree,
 					  buf);
 }
 
 void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	struct btrfs_root *root = BTRFS_I(buf->first_page->mapping->host)->root;
 	u64 transid = btrfs_header_generation(buf);
 	struct inode *btree_inode = root->fs_info->btree_inode;
 

commit 5f39d397dfbe140a14edecd4e73c34ce23c4f9ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:19 2007 -0400

    Btrfs: Create extent_buffer interface for large blocksizes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ef6d76f2ec20..0c1f90cbedb0 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -23,138 +23,132 @@
 #include <linux/swap.h>
 #include <linux/radix-tree.h>
 #include <linux/writeback.h>
+#include <linux/buffer_head.h> // for block_sync_page
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
 #include "btrfs_inode.h"
 
-u64 bh_blocknr(struct buffer_head *bh)
+#if 0
+static int check_tree_block(struct btrfs_root *root, struct extent_buffer *buf)
 {
-	return bh->b_blocknr;
-}
-
-static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
-{
-	struct btrfs_node *node = btrfs_buffer_node(buf);
-	if (bh_blocknr(buf) != btrfs_header_blocknr(&node->header)) {
-		printk(KERN_CRIT "bh_blocknr(buf) is %llu, header is %llu\n",
-		       (unsigned long long)bh_blocknr(buf),
-		       (unsigned long long)btrfs_header_blocknr(&node->header));
+	if (extent_buffer_blocknr(buf) != btrfs_header_blocknr(buf)) {
+		printk(KERN_CRIT "buf blocknr(buf) is %llu, header is %llu\n",
+		       (unsigned long long)extent_buffer_blocknr(buf),
+		       (unsigned long long)btrfs_header_blocknr(buf));
 		return 1;
 	}
 	return 0;
 }
+#endif
 
-struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
+struct extent_buffer *btrfs_find_tree_block(struct btrfs_root *root,
+					    u64 blocknr)
 {
-	struct address_space *mapping = root->fs_info->btree_inode->i_mapping;
-	int blockbits = root->fs_info->sb->s_blocksize_bits;
-	unsigned long index = blocknr >> (PAGE_CACHE_SHIFT - blockbits);
-	struct page *page;
-	struct buffer_head *bh;
-	struct buffer_head *head;
-	struct buffer_head *ret = NULL;
-
-
-	page = find_lock_page(mapping, index);
-	if (!page)
-		return NULL;
-
-	if (!page_has_buffers(page))
-		goto out_unlock;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	return find_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
+				   blocknr * root->sectorsize,
+				   root->sectorsize, GFP_NOFS);
+}
 
-	head = page_buffers(page);
-	bh = head;
-	do {
-		if (buffer_mapped(bh) && bh_blocknr(bh) == blocknr) {
-			ret = bh;
-			get_bh(bh);
-			goto out_unlock;
-		}
-		bh = bh->b_this_page;
-	} while (bh != head);
-out_unlock:
-	unlock_page(page);
-	page_cache_release(page);
-	return ret;
+struct extent_buffer *btrfs_find_create_tree_block(struct btrfs_root *root,
+						 u64 blocknr)
+{
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	return alloc_extent_buffer(&BTRFS_I(btree_inode)->extent_tree,
+				   blocknr * root->sectorsize,
+				   root->sectorsize, GFP_NOFS);
 }
 
-int btrfs_map_bh_to_logical(struct btrfs_root *root, struct buffer_head *bh,
-			     u64 logical)
+struct extent_map *btree_get_extent(struct inode *inode, struct page *page,
+				    size_t page_offset, u64 start, u64 end,
+				    int create)
 {
-	if (logical == 0) {
-		bh->b_bdev = NULL;
-		bh->b_blocknr = 0;
-		set_buffer_mapped(bh);
-	} else {
-		map_bh(bh, root->fs_info->sb, logical);
+	struct extent_map_tree *em_tree = &BTRFS_I(inode)->extent_tree;
+	struct extent_map *em;
+	int ret;
+
+again:
+	em = lookup_extent_mapping(em_tree, start, end);
+	if (em) {
+		goto out;
 	}
-	return 0;
+	em = alloc_extent_map(GFP_NOFS);
+	if (!em) {
+		em = ERR_PTR(-ENOMEM);
+		goto out;
+	}
+	em->start = 0;
+	em->end = (i_size_read(inode) & ~((u64)PAGE_CACHE_SIZE -1)) - 1;
+	em->block_start = 0;
+	em->block_end = em->end;
+	em->bdev = inode->i_sb->s_bdev;
+	ret = add_extent_mapping(em_tree, em);
+	if (ret == -EEXIST) {
+		free_extent_map(em);
+		em = NULL;
+		goto again;
+	} else if (ret) {
+		em = ERR_PTR(ret);
+	}
+out:
+	return em;
 }
 
-struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
-						 u64 blocknr)
+static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
-	struct address_space *mapping = root->fs_info->btree_inode->i_mapping;
-	int blockbits = root->fs_info->sb->s_blocksize_bits;
-	unsigned long index = blocknr >> (PAGE_CACHE_SHIFT - blockbits);
-	struct page *page;
-	struct buffer_head *bh;
-	struct buffer_head *head;
-	struct buffer_head *ret = NULL;
-	int err;
-	u64 first_block = index << (PAGE_CACHE_SHIFT - blockbits);
+	struct extent_map_tree *tree;
+	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+	return extent_write_full_page(tree, page, btree_get_extent, wbc);
+}
+int btree_readpage(struct file *file, struct page *page)
+{
+	struct extent_map_tree *tree;
+	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+	return extent_read_full_page(tree, page, btree_get_extent);
+}
 
-	page = find_or_create_page(mapping, index, GFP_NOFS);
-	if (!page)
-		return NULL;
+static int btree_releasepage(struct page *page, gfp_t unused_gfp_flags)
+{
+	struct extent_map_tree *tree;
+	int ret;
 
-	if (!page_has_buffers(page))
-		create_empty_buffers(page, root->fs_info->sb->s_blocksize, 0);
-	head = page_buffers(page);
-	bh = head;
-	do {
-		if (!buffer_mapped(bh)) {
-			err = btrfs_map_bh_to_logical(root, bh, first_block);
-			BUG_ON(err);
-		}
-		if (bh_blocknr(bh) == blocknr) {
-			ret = bh;
-			get_bh(bh);
-			goto out_unlock;
-		}
-		bh = bh->b_this_page;
-		first_block++;
-	} while (bh != head);
-out_unlock:
-	unlock_page(page);
-	if (ret)
-		touch_buffer(ret);
-	page_cache_release(page);
+	BUG_ON(page->private != 1);
+	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+	ret = try_release_extent_mapping(tree, page);
+	if (ret == 1) {
+		ClearPagePrivate(page);
+		set_page_private(page, 0);
+		page_cache_release(page);
+	}
 	return ret;
 }
 
-static int btree_get_block(struct inode *inode, sector_t iblock,
-			   struct buffer_head *bh, int create)
+static void btree_invalidatepage(struct page *page, unsigned long offset)
 {
-	int err;
-	struct btrfs_root *root = BTRFS_I(bh->b_page->mapping->host)->root;
-	err = btrfs_map_bh_to_logical(root, bh, iblock);
-	return err;
+	struct extent_map_tree *tree;
+	tree = &BTRFS_I(page->mapping->host)->extent_tree;
+	extent_invalidatepage(tree, page, offset);
+	btree_releasepage(page, GFP_NOFS);
 }
 
 int btrfs_csum_data(struct btrfs_root * root, char *data, size_t len,
 		    char *result)
 {
+	return 0;
+#if 0
 	u32 crc;
 	crc = crc32c(0, data, len);
 	memcpy(result, &crc, BTRFS_CRC32_SIZE);
 	return 0;
+#endif
 }
 
-static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
+#if 0
+static int csum_tree_block(struct btrfs_root *root, struct extent_buffer *buf,
 			   int verify)
 {
+	return 0;
 	char result[BTRFS_CRC32_SIZE];
 	int ret;
 	struct btrfs_node *node;
@@ -176,7 +170,9 @@ static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 	}
 	return 0;
 }
+#endif
 
+#if 0
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct buffer_head *bh;
@@ -195,87 +191,65 @@ static int btree_writepage(struct page *page, struct writeback_control *wbc)
 	} while (bh != head);
 	return block_write_full_page(page, btree_get_block, wbc);
 }
-
-static int btree_readpage(struct file * file, struct page * page)
-{
-	return block_read_full_page(page, btree_get_block);
-}
+#endif
 
 static struct address_space_operations btree_aops = {
 	.readpage	= btree_readpage,
 	.writepage	= btree_writepage,
+	.releasepage	= btree_releasepage,
+	.invalidatepage = btree_invalidatepage,
 	.sync_page	= block_sync_page,
 };
 
 int readahead_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	struct buffer_head *bh = NULL;
+	struct extent_buffer *buf = NULL;
+	struct inode *btree_inode = root->fs_info->btree_inode;
 	int ret = 0;
 
-	bh = btrfs_find_create_tree_block(root, blocknr);
-	if (!bh)
+	buf = btrfs_find_create_tree_block(root, blocknr);
+	if (!buf)
 		return 0;
-	if (buffer_uptodate(bh)) {
-		ret = 1;
-		goto done;
-	}
-	if (test_set_buffer_locked(bh)) {
-		ret = 1;
-		goto done;
-	}
-	if (!buffer_uptodate(bh)) {
-		get_bh(bh);
-		bh->b_end_io = end_buffer_read_sync;
-		submit_bh(READ, bh);
-	} else {
-		unlock_buffer(bh);
-		ret = 1;
-	}
-done:
-	brelse(bh);
+	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
+				 buf, 0);
+	free_extent_buffer(buf);
 	return ret;
 }
 
-struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
+struct extent_buffer *read_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	struct buffer_head *bh = NULL;
-
-	bh = btrfs_find_create_tree_block(root, blocknr);
-	if (!bh)
-		return bh;
-	if (buffer_uptodate(bh))
-		goto uptodate;
-	lock_buffer(bh);
-	if (!buffer_uptodate(bh)) {
-		get_bh(bh);
-		bh->b_end_io = end_buffer_read_sync;
-		submit_bh(READ, bh);
-		wait_on_buffer(bh);
-		if (!buffer_uptodate(bh))
-			goto fail;
-	} else {
-		unlock_buffer(bh);
-	}
-uptodate:
-	if (!buffer_checked(bh)) {
-		csum_tree_block(root, bh, 1);
-		set_buffer_checked(bh);
-	}
-	if (check_tree_block(root, bh))
-		goto fail;
-	return bh;
-fail:
-	brelse(bh);
-	return NULL;
+	struct extent_buffer *buf = NULL;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+
+	buf = btrfs_find_create_tree_block(root, blocknr);
+	if (!buf)
+		return NULL;
+	read_extent_buffer_pages(&BTRFS_I(btree_inode)->extent_tree,
+				 buf, 1);
+	return buf;
 }
 
 int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		     struct buffer_head *buf)
+		     struct extent_buffer *buf)
 {
-	WARN_ON(atomic_read(&buf->b_count) == 0);
-	lock_buffer(buf);
-	clear_buffer_dirty(buf);
-	unlock_buffer(buf);
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	clear_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, buf);
+	return 0;
+}
+
+int wait_on_tree_block_writeback(struct btrfs_root *root,
+				 struct extent_buffer *buf)
+{
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	wait_on_extent_buffer_writeback(&BTRFS_I(btree_inode)->extent_tree,
+					buf);
+	return 0;
+}
+
+int set_tree_block_dirty(struct btrfs_root *root, struct extent_buffer *buf)
+{
+	struct inode *btree_inode = root->fs_info->btree_inode;
+	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, buf);
 	return 0;
 }
 
@@ -287,7 +261,9 @@ static int __setup_root(int blocksize,
 	root->node = NULL;
 	root->inode = NULL;
 	root->commit_root = NULL;
-	root->blocksize = blocksize;
+	root->sectorsize = blocksize;
+	root->nodesize = blocksize;
+	root->leafsize = blocksize;
 	root->ref_cows = 0;
 	root->fs_info = fs_info;
 	root->objectid = objectid;
@@ -332,7 +308,7 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 	struct btrfs_root *root;
 	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct btrfs_path *path;
-	struct btrfs_leaf *l;
+	struct extent_buffer *l;
 	u64 highest_inode;
 	int ret = 0;
 
@@ -361,11 +337,10 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 			ret = -ENOENT;
 		goto out;
 	}
-	l = btrfs_buffer_leaf(path->nodes[0]);
-	memcpy(&root->root_item,
-	       btrfs_item_ptr(l, path->slots[0], struct btrfs_root_item),
+	l = path->nodes[0];
+	read_extent_buffer(l, &root->root_item,
+	       btrfs_item_ptr_offset(l, path->slots[0]),
 	       sizeof(root->root_item));
-	memcpy(&root->root_key, location, sizeof(*location));
 	ret = 0;
 out:
 	btrfs_release_path(root, path);
@@ -406,21 +381,21 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 				(unsigned long)root->root_key.objectid,
 				root);
 	if (ret) {
-		brelse(root->node);
+		free_extent_buffer(root->node);
 		kfree(root);
 		return ERR_PTR(ret);
 	}
 
 	ret = btrfs_set_root_name(root, name, namelen);
 	if (ret) {
-		brelse(root->node);
+		free_extent_buffer(root->node);
 		kfree(root);
 		return ERR_PTR(ret);
 	}
 
 	ret = btrfs_sysfs_add_root(root);
 	if (ret) {
-		brelse(root->node);
+		free_extent_buffer(root->node);
 		kfree(root->name);
 		kfree(root);
 		return ERR_PTR(ret);
@@ -471,6 +446,9 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->btree_inode->i_nlink = 1;
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
+	extent_map_tree_init(&BTRFS_I(fs_info->btree_inode)->extent_tree,
+			     fs_info->btree_inode->i_mapping,
+			     GFP_NOFS);
 	fs_info->do_barriers = 1;
 	fs_info->closing = 0;
 
@@ -493,10 +471,14 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 
 	if (!fs_info->sb_buffer)
 		goto fail_iput;
-	disk_super = (struct btrfs_super_block *)fs_info->sb_buffer->b_data;
-	fs_info->disk_super = disk_super;
-	memcpy(&fs_info->super_copy, disk_super, sizeof(fs_info->super_copy));
 
+	read_extent_buffer(fs_info->sb_buffer, &fs_info->super_copy, 0,
+			   sizeof(fs_info->super_copy));
+
+	read_extent_buffer(fs_info->sb_buffer, fs_info->fsid,
+			   (unsigned long)btrfs_super_fsid(fs_info->sb_buffer),
+			   BTRFS_FSID_SIZE);
+	disk_super = &fs_info->super_copy;
 	if (!btrfs_super_root(disk_super))
 		goto fail_sb_buffer;
 
@@ -530,9 +512,9 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	return tree_root;
 
 fail_tree_root:
-	btrfs_block_release(tree_root, tree_root->node);
+	free_extent_buffer(tree_root->node);
 fail_sb_buffer:
-	btrfs_block_release(tree_root, fs_info->sb_buffer);
+	free_extent_buffer(fs_info->sb_buffer);
 fail_iput:
 	iput(fs_info->btree_inode);
 fail:
@@ -546,31 +528,13 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root)
 {
 	int ret;
-	struct buffer_head *bh = root->fs_info->sb_buffer;
-
-	lock_buffer(bh);
-	WARN_ON(atomic_read(&bh->b_count) < 1);
-	clear_buffer_dirty(bh);
-	csum_tree_block(root, bh, 0);
-	bh->b_end_io = end_buffer_write_sync;
-	get_bh(bh);
-	if (root->fs_info->do_barriers)
-		ret = submit_bh(WRITE_BARRIER, bh);
-	else
-		ret = submit_bh(WRITE, bh);
-	if (ret == -EOPNOTSUPP) {
-		get_bh(bh);
-		lock_buffer(bh);
-		set_buffer_uptodate(bh);
-		root->fs_info->do_barriers = 0;
-		ret = submit_bh(WRITE, bh);
-	}
-	wait_on_buffer(bh);
-	if (!buffer_uptodate(bh)) {
-		WARN_ON(1);
-		return -EIO;
-	}
-	return 0;
+	struct extent_buffer *super = root->fs_info->sb_buffer;
+	struct inode *btree_inode = root->fs_info->btree_inode;
+
+	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, super);
+	ret = sync_page_range_nolock(btree_inode, btree_inode->i_mapping,
+				     super->start, super->len);
+	return ret;
 }
 
 int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
@@ -581,9 +545,9 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 	if (root->inode)
 		iput(root->inode);
 	if (root->node)
-		brelse(root->node);
+		free_extent_buffer(root->node);
 	if (root->commit_root)
-		brelse(root->commit_root);
+		free_extent_buffer(root->commit_root);
 	if (root->name)
 		kfree(root->name);
 	kfree(root);
@@ -629,12 +593,10 @@ int close_ctree(struct btrfs_root *root)
 	mutex_unlock(&fs_info->fs_mutex);
 
 	if (fs_info->extent_root->node)
-		btrfs_block_release(fs_info->extent_root,
-				    fs_info->extent_root->node);
+		free_extent_buffer(fs_info->extent_root->node);
 	if (fs_info->tree_root->node)
-		btrfs_block_release(fs_info->tree_root,
-				    fs_info->tree_root->node);
-	btrfs_block_release(root, fs_info->sb_buffer);
+		free_extent_buffer(fs_info->tree_root->node);
+	free_extent_buffer(fs_info->sb_buffer);
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 	iput(fs_info->btree_inode);
 
@@ -645,25 +607,32 @@ int close_ctree(struct btrfs_root *root)
 	return 0;
 }
 
-void btrfs_mark_buffer_dirty(struct buffer_head *bh)
+int btrfs_buffer_uptodate(struct extent_buffer *buf)
+{
+	struct inode *btree_inode = buf->pages[0]->mapping->host;
+	return extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree, buf);
+}
+
+int btrfs_set_buffer_uptodate(struct extent_buffer *buf)
 {
-	struct btrfs_root *root = BTRFS_I(bh->b_page->mapping->host)->root;
-	u64 transid = btrfs_header_generation(btrfs_buffer_header(bh));
+	struct inode *btree_inode = buf->pages[0]->mapping->host;
+	return set_extent_buffer_uptodate(&BTRFS_I(btree_inode)->extent_tree,
+					  buf);
+}
 
-	WARN_ON(!atomic_read(&bh->b_count));
+void btrfs_mark_buffer_dirty(struct extent_buffer *buf)
+{
+	struct btrfs_root *root = BTRFS_I(buf->pages[0]->mapping->host)->root;
+	u64 transid = btrfs_header_generation(buf);
+	struct inode *btree_inode = root->fs_info->btree_inode;
 
 	if (transid != root->fs_info->generation) {
 		printk(KERN_CRIT "transid mismatch buffer %llu, found %Lu running %Lu\n",
-			(unsigned long long)bh->b_blocknr,
+			(unsigned long long)extent_buffer_blocknr(buf),
 			transid, root->fs_info->generation);
 		WARN_ON(1);
 	}
-	mark_buffer_dirty(bh);
-}
-
-void btrfs_block_release(struct btrfs_root *root, struct buffer_head *buf)
-{
-	brelse(buf);
+	set_extent_buffer_dirty(&BTRFS_I(btree_inode)->extent_tree, buf);
 }
 
 void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)

commit d3c2fdcf7b79079f60ac64e61d886964d4647910
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 17 10:58:06 2007 -0400

    Btrfs: Use balance_dirty_pages_nr on btree blocks
    
    btrfs_btree_balance_dirty is changed to pass the number of pages dirtied
    for more accurate dirty throttling.  This lets the VM make better decisions
    about when to force some writeback.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4296839eea1a..ef6d76f2ec20 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -666,7 +666,8 @@ void btrfs_block_release(struct btrfs_root *root, struct buffer_head *buf)
 	brelse(buf);
 }
 
-void btrfs_btree_balance_dirty(struct btrfs_root *root)
+void btrfs_btree_balance_dirty(struct btrfs_root *root, unsigned long nr)
 {
-	balance_dirty_pages_ratelimited(root->fs_info->btree_inode->i_mapping);
+	balance_dirty_pages_ratelimited_nr(
+			root->fs_info->btree_inode->i_mapping, nr);
 }

commit 5ce14bbcdd1b5d9233d26a1e89faf3a26c820c58
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Sep 11 11:15:39 2007 -0400

    Btrfs: Find and remove dead roots the first time a root is loaded.
    
    Dead roots are trees left over after a crash, and they were either in the
    process of being removed or were waiting to be removed when the box crashed.
    Before, a search of the entire tree of root pointers was done on mount
    looking for dead roots.  Now, the search is done the first time we load
    a root.
    
    This makes mount faster when there are a large number of snapshots, and it
    enables the block accounting code to properly update the block counts on
    the latest root as old versions of the root are reaped after a crash.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6c953a0e0aa3..4296839eea1a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -426,6 +426,10 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		return ERR_PTR(ret);
 	}
 
+	ret = btrfs_find_dead_roots(fs_info->tree_root,
+				    root->root_key.objectid, root);
+	BUG_ON(ret);
+
 	return root;
 }
 
@@ -522,11 +526,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	btrfs_read_block_groups(extent_root);
 
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
-	ret = btrfs_find_dead_roots(tree_root);
-	if (ret) {
-		mutex_unlock(&fs_info->fs_mutex);
-		goto fail_tree_root;
-	}
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
 

commit 011410bd859a481a335d7db1fb559542c5663fd5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Sep 10 19:58:36 2007 -0400

    Btrfs: Add more synchronization before creating a snapshot
    
    File data checksums are only done during writepage, so we have to make sure
    all pages are written when the snapshot is taken.  This also adds some
    locking so that new writes don't race in and add new dirty pages.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c25ef0a68f18..6c953a0e0aa3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -300,6 +300,7 @@ static int __setup_root(int blocksize,
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
 	memset(&root->root_kobj, 0, sizeof(root->root_kobj));
 	init_completion(&root->kobj_unregister);
+	init_rwsem(&root->snap_sem);
 	root->defrag_running = 0;
 	root->defrag_level = 0;
 	root->root_key.objectid = objectid;

commit 58176a9604c5db1784d2c979aea472b3be40b6f0
Author: Josef Bacik <jbacik@redhat.com>
Date:   Wed Aug 29 15:47:34 2007 -0400

    Btrfs: Add per-root block accounting and sysfs entries
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b2f79878d51a..c25ef0a68f18 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -294,9 +294,12 @@ static int __setup_root(int blocksize,
 	root->last_trans = 0;
 	root->highest_inode = 0;
 	root->last_inode_alloc = 0;
+	root->name = NULL;
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
+	memset(&root->root_kobj, 0, sizeof(root->root_kobj));
+	init_completion(&root->kobj_unregister);
 	root->defrag_running = 0;
 	root->defrag_level = 0;
 	root->root_key.objectid = objectid;
@@ -384,7 +387,8 @@ struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
 }
 
 struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
-				      struct btrfs_key *location)
+				      struct btrfs_key *location,
+				      const char *name, int namelen)
 {
 	struct btrfs_root *root;
 	int ret;
@@ -405,6 +409,22 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
+
+	ret = btrfs_set_root_name(root, name, namelen);
+	if (ret) {
+		brelse(root->node);
+		kfree(root);
+		return ERR_PTR(ret);
+	}
+
+	ret = btrfs_sysfs_add_root(root);
+	if (ret) {
+		brelse(root->node);
+		kfree(root->name);
+		kfree(root);
+		return ERR_PTR(ret);
+	}
+
 	return root;
 }
 
@@ -433,6 +453,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	INIT_RADIX_TREE(&fs_info->block_group_data_radix, GFP_KERNEL);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	INIT_LIST_HEAD(&fs_info->dead_roots);
+	memset(&fs_info->super_kobj, 0, sizeof(fs_info->super_kobj));
+	init_completion(&fs_info->kobj_unregister);
 	sb_set_blocksize(sb, 4096);
 	fs_info->running_transaction = NULL;
 	fs_info->last_trans_committed = 0;
@@ -500,8 +522,10 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
 	ret = btrfs_find_dead_roots(tree_root);
-	if (ret)
+	if (ret) {
+		mutex_unlock(&fs_info->fs_mutex);
 		goto fail_tree_root;
+	}
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
 
@@ -553,12 +577,15 @@ int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 {
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
+	btrfs_sysfs_del_root(root);
 	if (root->inode)
 		iput(root->inode);
 	if (root->node)
 		brelse(root->node);
 	if (root->commit_root)
 		brelse(root->commit_root);
+	if (root->name)
+		kfree(root->name);
 	kfree(root);
 	return 0;
 }

commit 15ee9bc7ed171248d1405df5854da5fa91bfdc39
Author: Josef Bacik <jwhiter@redhat.com>
Date:   Fri Aug 10 16:22:09 2007 -0400

    Btrfs: delay commits during fsync to allow more writers
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 192211274ce5..b2f79878d51a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -435,6 +435,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	INIT_LIST_HEAD(&fs_info->dead_roots);
 	sb_set_blocksize(sb, 4096);
 	fs_info->running_transaction = NULL;
+	fs_info->last_trans_committed = 0;
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
 	fs_info->sb = sb;

commit 26b8003f10569a9155b7539ef5a7379ee0c6b050
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Aug 8 20:17:12 2007 -0400

    Btrfs: Replace extent tree preallocation code with some bit radix magic.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c948416fea3a..192211274ce5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -427,6 +427,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
 	init_bit_radix(&fs_info->extent_map_radix);
+	init_bit_radix(&fs_info->extent_ins_radix);
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_RADIX_TREE(&fs_info->block_group_radix, GFP_KERNEL);
 	INIT_RADIX_TREE(&fs_info->block_group_data_radix, GFP_KERNEL);
@@ -443,8 +444,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
 	fs_info->do_barriers = 1;
-	fs_info->extent_tree_insert_nr = 0;
-	fs_info->extent_tree_prealloc_nr = 0;
 	fs_info->closing = 0;
 
 	INIT_DELAYED_WORK(&fs_info->trans_work, btrfs_transaction_cleaner);

commit 6702ed490ca0bb44e17131818a5a18b773957c5a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Aug 7 16:15:09 2007 -0400

    Btrfs: Add run time btree defrag, and an ioctl to force btree defrag
    
    This adds two types of btree defrag, a run time form that tries to
    defrag recently allocated blocks in the btree when they are still in ram,
    and an ioctl that forces defrag of all btree blocks.
    
    File data blocks are not defragged yet, but this can make a huge difference
    in sequential btree reads.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 60db85bc4ba8..c948416fea3a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -273,7 +273,9 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		     struct buffer_head *buf)
 {
 	WARN_ON(atomic_read(&buf->b_count) == 0);
+	lock_buffer(buf);
 	clear_buffer_dirty(buf);
+	unlock_buffer(buf);
 	return 0;
 }
 
@@ -294,6 +296,9 @@ static int __setup_root(int blocksize,
 	root->last_inode_alloc = 0;
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
+	memset(&root->defrag_progress, 0, sizeof(root->defrag_progress));
+	root->defrag_running = 0;
+	root->defrag_level = 0;
 	root->root_key.objectid = objectid;
 	return 0;
 }
@@ -585,6 +590,7 @@ int close_ctree(struct btrfs_root *root)
 	fs_info->closing = 1;
 	btrfs_transaction_flush_work(root);
 	mutex_lock(&fs_info->fs_mutex);
+	btrfs_defrag_dirty_roots(root->fs_info);
 	trans = btrfs_start_transaction(root, 1);
 	ret = btrfs_commit_transaction(trans, root);
 	/* run commit again to  drop the original snapshot */
@@ -616,7 +622,9 @@ void btrfs_mark_buffer_dirty(struct buffer_head *bh)
 {
 	struct btrfs_root *root = BTRFS_I(bh->b_page->mapping->host)->root;
 	u64 transid = btrfs_header_generation(btrfs_buffer_header(bh));
+
 	WARN_ON(!atomic_read(&bh->b_count));
+
 	if (transid != root->fs_info->generation) {
 		printk(KERN_CRIT "transid mismatch buffer %llu, found %Lu running %Lu\n",
 			(unsigned long long)bh->b_blocknr,

commit ec6b910fb330f29e169c9f502c3ac209515af8d1
Author: Zach Brown <zach.brown@oracle.com>
Date:   Wed Jul 11 10:00:37 2007 -0400

    Btrfs: trivial include fixups
    
    Almost none of the files including module.h need to do so,
    remove them.
    
    Include sched.h in extent-tree.c to silence a warning about cond_resched()
    being undeclared.
    
    Signed-off-by: Zach Brown <zach.brown@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d1bf5bc1bc14..60db85bc4ba8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -16,7 +16,6 @@
  * Boston, MA 021110-1307, USA.
  */
 
-#include <linux/module.h>
 #include <linux/fs.h>
 #include <linux/blkdev.h>
 #include <linux/crc32c.h>

commit ccd467d60e81b48cdbecae93532b66bcdedca91d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jun 28 15:57:36 2007 -0400

    Btrfs: crash recovery fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7081729d5b16..d1bf5bc1bc14 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -270,14 +270,6 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 	return NULL;
 }
 
-int dirty_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		     struct buffer_head *buf)
-{
-	WARN_ON(atomic_read(&buf->b_count) == 0);
-	mark_buffer_dirty(buf);
-	return 0;
-}
-
 int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		     struct buffer_head *buf)
 {
@@ -621,6 +613,20 @@ int close_ctree(struct btrfs_root *root)
 	return 0;
 }
 
+void btrfs_mark_buffer_dirty(struct buffer_head *bh)
+{
+	struct btrfs_root *root = BTRFS_I(bh->b_page->mapping->host)->root;
+	u64 transid = btrfs_header_generation(btrfs_buffer_header(bh));
+	WARN_ON(!atomic_read(&bh->b_count));
+	if (transid != root->fs_info->generation) {
+		printk(KERN_CRIT "transid mismatch buffer %llu, found %Lu running %Lu\n",
+			(unsigned long long)bh->b_blocknr,
+			transid, root->fs_info->generation);
+		WARN_ON(1);
+	}
+	mark_buffer_dirty(bh);
+}
+
 void btrfs_block_release(struct btrfs_root *root, struct buffer_head *buf)
 {
 	brelse(buf);

commit 4b52dff6d371b9b93bc99f64c32831ea9a8ec3ac
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 26 10:06:50 2007 -0400

    Btrfs: Fix super block updates during transaction commit
    
    The super block written during commit was not consistent with the state of
    the trees.  This change adds an in-memory copy of the super so that we can
    make sure to write out consistent data during a commit.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index d7615e1578cc..7081729d5b16 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -471,6 +471,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	if (!fs_info->sb_buffer)
 		goto fail_iput;
 	disk_super = (struct btrfs_super_block *)fs_info->sb_buffer->b_data;
+	fs_info->disk_super = disk_super;
+	memcpy(&fs_info->super_copy, disk_super, sizeof(fs_info->super_copy));
 
 	if (!btrfs_super_root(disk_super))
 		goto fail_sb_buffer;
@@ -479,7 +481,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 		     btrfs_super_total_blocks(disk_super) <<
 		     fs_info->btree_inode->i_blkbits);
 
-	fs_info->disk_super = disk_super;
 
 	if (strncmp((char *)(&disk_super->magic), BTRFS_MAGIC,
 		    sizeof(disk_super->magic))) {
@@ -527,8 +528,6 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 	int ret;
 	struct buffer_head *bh = root->fs_info->sb_buffer;
 
-	btrfs_set_super_root(root->fs_info->disk_super,
-			     bh_blocknr(root->fs_info->tree_root->node));
 	lock_buffer(bh);
 	WARN_ON(atomic_read(&bh->b_count) < 1);
 	clear_buffer_dirty(bh);

commit 5eda7b5e9b0bed864dd18284c7df9b3c8207dad7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 22 14:16:25 2007 -0400

    Btrfs: Add the ability to find and remove dead roots after a crash.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 865a284aa06c..d7615e1578cc 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -326,8 +326,8 @@ static int find_and_setup_root(int blocksize,
 	return 0;
 }
 
-struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
-				      struct btrfs_key *location)
+struct btrfs_root *btrfs_read_fs_root_no_radix(struct btrfs_fs_info *fs_info,
+					       struct btrfs_key *location)
 {
 	struct btrfs_root *root;
 	struct btrfs_root *tree_root = fs_info->tree_root;
@@ -336,11 +336,7 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 	u64 highest_inode;
 	int ret = 0;
 
-	root = radix_tree_lookup(&fs_info->fs_roots_radix,
-				 (unsigned long)location->objectid);
-	if (root)
-		return root;
-	root = kmalloc(sizeof(*root), GFP_NOFS);
+	root = kzalloc(sizeof(*root), GFP_NOFS);
 	if (!root)
 		return ERR_PTR(-ENOMEM);
 	if (location->offset == (u64)-1) {
@@ -383,6 +379,28 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 	BUG_ON(!root->node);
 insert:
 	root->ref_cows = 1;
+	ret = btrfs_find_highest_inode(root, &highest_inode);
+	if (ret == 0) {
+		root->highest_inode = highest_inode;
+		root->last_inode_alloc = highest_inode;
+	}
+	return root;
+}
+
+struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
+				      struct btrfs_key *location)
+{
+	struct btrfs_root *root;
+	int ret;
+
+	root = radix_tree_lookup(&fs_info->fs_roots_radix,
+				 (unsigned long)location->objectid);
+	if (root)
+		return root;
+
+	root = btrfs_read_fs_root_no_radix(fs_info, location);
+	if (IS_ERR(root))
+		return root;
 	ret = radix_tree_insert(&fs_info->fs_roots_radix,
 				(unsigned long)root->root_key.objectid,
 				root);
@@ -391,11 +409,6 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 		kfree(root);
 		return ERR_PTR(ret);
 	}
-	ret = btrfs_find_highest_inode(root, &highest_inode);
-	if (ret == 0) {
-		root->highest_inode = highest_inode;
-		root->last_inode_alloc = highest_inode;
-	}
 	return root;
 }
 
@@ -489,6 +502,9 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	btrfs_read_block_groups(extent_root);
 
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
+	ret = btrfs_find_dead_roots(tree_root);
+	if (ret)
+		goto fail_tree_root;
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
 
@@ -538,7 +554,7 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 	return 0;
 }
 
-static int free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
+int btrfs_free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 {
 	radix_tree_delete(&fs_info->fs_roots_radix,
 			  (unsigned long)root->root_key.objectid);
@@ -565,7 +581,7 @@ static int del_fs_roots(struct btrfs_fs_info *fs_info)
 		if (!ret)
 			break;
 		for (i = 0; i < ret; i++)
-			free_fs_root(fs_info, gang[i]);
+			btrfs_free_fs_root(fs_info, gang[i]);
 	}
 	return 0;
 }

commit 54aa1f4dfdacd60a19c4471220b24e581be6f774
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 22 14:16:25 2007 -0400

    Btrfs: Audit callers and return codes to make sure -ENOSPC gets up the stack
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3712e946f9c8..865a284aa06c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -580,7 +580,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_transaction_flush_work(root);
 	mutex_lock(&fs_info->fs_mutex);
 	trans = btrfs_start_transaction(root, 1);
-	btrfs_commit_transaction(trans, root);
+	ret = btrfs_commit_transaction(trans, root);
 	/* run commit again to  drop the original snapshot */
 	trans = btrfs_start_transaction(root, 1);
 	btrfs_commit_transaction(trans, root);

commit 11bd143fc8243cf48c934dc1c4479a5aacf58ce3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 22 14:16:24 2007 -0400

    Btrfs: Switch to libcrc32c to avoid problems with cryptomgr on highmem machines
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 15cc9ec92308..3712e946f9c8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -19,7 +19,7 @@
 #include <linux/module.h>
 #include <linux/fs.h>
 #include <linux/blkdev.h>
-#include <linux/crypto.h>
+#include <linux/crc32c.h>
 #include <linux/scatterlist.h>
 #include <linux/swap.h>
 #include <linux/radix-tree.h>
@@ -147,22 +147,12 @@ static int btree_get_block(struct inode *inode, sector_t iblock,
 int btrfs_csum_data(struct btrfs_root * root, char *data, size_t len,
 		    char *result)
 {
-	struct scatterlist sg;
-	struct crypto_hash *tfm = root->fs_info->hash_tfm;
-	struct hash_desc desc;
-	int ret;
-
-	desc.tfm = tfm;
-	desc.flags = 0;
-	sg_init_one(&sg, data, len);
-	spin_lock_irq(&root->fs_info->hash_lock);
-	ret = crypto_hash_digest(&desc, &sg, 1, result);
-	spin_unlock_irq(&root->fs_info->hash_lock);
-	if (ret) {
-		printk("digest failed\n");
-	}
-	return ret;
+	u32 crc;
+	crc = crc32c(0, data, len);
+	memcpy(result, &crc, BTRFS_CRC32_SIZE);
+	return 0;
 }
+
 static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 			   int verify)
 {
@@ -454,14 +444,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	       sizeof(struct btrfs_key));
 	insert_inode_hash(fs_info->btree_inode);
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
-	fs_info->hash_tfm = crypto_alloc_hash("crc32c", 0, CRYPTO_ALG_ASYNC);
-	spin_lock_init(&fs_info->hash_lock);
 
-	if (!fs_info->hash_tfm || IS_ERR(fs_info->hash_tfm)) {
-		printk("btrfs: failed hash setup, modprobe cryptomgr?\n");
-		err = -ENOMEM;
-		goto fail_iput;
-	}
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
 
@@ -613,7 +596,6 @@ int close_ctree(struct btrfs_root *root)
 		btrfs_block_release(fs_info->tree_root,
 				    fs_info->tree_root->node);
 	btrfs_block_release(root, fs_info->sb_buffer);
-	crypto_free_hash(fs_info->hash_tfm);
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 	iput(fs_info->btree_inode);
 

commit 8c2383c3dd2cb5bb39598ce4fa97154bc591020a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jun 18 09:57:58 2007 -0400

    Subject: Rework btrfs_file_write to only allocate while page locks are held
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 602b63dc76c3..15cc9ec92308 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -541,6 +541,8 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 	else
 		ret = submit_bh(WRITE, bh);
 	if (ret == -EOPNOTSUPP) {
+		get_bh(bh);
+		lock_buffer(bh);
 		set_buffer_uptodate(bh);
 		root->fs_info->do_barriers = 0;
 		ret = submit_bh(WRITE, bh);

commit 9ebefb180bad4914a31c4e1748ba187a30e1e990
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 15 13:50:00 2007 -0400

    Btrfs: patch queue: page_mkwrite
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b0ebba6f2e46..602b63dc76c3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -155,9 +155,9 @@ int btrfs_csum_data(struct btrfs_root * root, char *data, size_t len,
 	desc.tfm = tfm;
 	desc.flags = 0;
 	sg_init_one(&sg, data, len);
-	spin_lock(&root->fs_info->hash_lock);
+	spin_lock_irq(&root->fs_info->hash_lock);
 	ret = crypto_hash_digest(&desc, &sg, 1, result);
-	spin_unlock(&root->fs_info->hash_lock);
+	spin_unlock_irq(&root->fs_info->hash_lock);
 	if (ret) {
 		printk("digest failed\n");
 	}

commit 340887809d92a4dd6c71caa97d658cef32c098c3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 11:36:58 2007 -0400

    Btrfs: i386 fixes from axboe
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8c68a64c0ceb..b0ebba6f2e46 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -106,7 +106,7 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 	int err;
 	u64 first_block = index << (PAGE_CACHE_SHIFT - blockbits);
 
-	page = grab_cache_page(mapping, index);
+	page = find_or_create_page(mapping, index, GFP_NOFS);
 	if (!page)
 		return NULL;
 

commit 6cbd55707802b98843f953d1ae6d8f5bcd9a76c0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 09:07:21 2007 -0400

    Btrfs: add GPLv2
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 878101172546..8c68a64c0ceb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1,3 +1,21 @@
+/*
+ * Copyright (C) 2007 Oracle.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
 #include <linux/module.h>
 #include <linux/fs.h>
 #include <linux/blkdev.h>

commit 5af3981c1878b0657b9babd2ef7ec98c2008cf2c
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 07:50:13 2007 -0400

    Btrfs: printk fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 96bf3ef3a798..878101172546 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -20,8 +20,9 @@ static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 {
 	struct btrfs_node *node = btrfs_buffer_node(buf);
 	if (bh_blocknr(buf) != btrfs_header_blocknr(&node->header)) {
-		printk(KERN_CRIT "bh_blocknr(buf) is %Lu, header is %Lu\n",
-		       bh_blocknr(buf), btrfs_header_blocknr(&node->header));
+		printk(KERN_CRIT "bh_blocknr(buf) is %llu, header is %llu\n",
+		       (unsigned long long)bh_blocknr(buf),
+		       (unsigned long long)btrfs_header_blocknr(&node->header));
 		return 1;
 	}
 	return 0;
@@ -157,8 +158,9 @@ static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 		return ret;
 	if (verify) {
 		if (memcmp(bh->b_data, result, BTRFS_CRC32_SIZE)) {
-			printk("checksum verify failed on %Lu\n",
-			       bh_blocknr(bh));
+			printk("btrfs: %s checksum verify failed on %llu\n",
+			       root->fs_info->sb->s_id,
+			       (unsigned long long)bh_blocknr(bh));
 			return 1;
 		}
 	} else {

commit 39279cc3d2704cfbf9c35dcb5bdd392159ae4625
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 06:35:45 2007 -0400

    Btrfs: split up super.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8a88404525e8..96bf3ef3a798 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -22,7 +22,7 @@ static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 	if (bh_blocknr(buf) != btrfs_header_blocknr(&node->header)) {
 		printk(KERN_CRIT "bh_blocknr(buf) is %Lu, header is %Lu\n",
 		       bh_blocknr(buf), btrfs_header_blocknr(&node->header));
-		BUG();
+		return 1;
 	}
 	return 0;
 }
@@ -253,7 +253,7 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 		set_buffer_checked(bh);
 	}
 	if (check_tree_block(root, bh))
-		BUG();
+		goto fail;
 	return bh;
 fail:
 	brelse(bh);
@@ -398,8 +398,13 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	struct btrfs_fs_info *fs_info = kmalloc(sizeof(*fs_info),
 						GFP_NOFS);
 	int ret;
+	int err = -EIO;
 	struct btrfs_super_block *disk_super;
 
+	if (!extent_root || !tree_root || !fs_info) {
+		err = -ENOMEM;
+		goto fail;
+	}
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
 	init_bit_radix(&fs_info->extent_map_radix);
@@ -431,9 +436,11 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->hash_tfm = crypto_alloc_hash("crc32c", 0, CRYPTO_ALG_ASYNC);
 	spin_lock_init(&fs_info->hash_lock);
+
 	if (!fs_info->hash_tfm || IS_ERR(fs_info->hash_tfm)) {
-		printk("failed to allocate digest hash\n");
-		return NULL;
+		printk("btrfs: failed hash setup, modprobe cryptomgr?\n");
+		err = -ENOMEM;
+		goto fail_iput;
 	}
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
@@ -446,30 +453,53 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 					     sb->s_blocksize);
 
 	if (!fs_info->sb_buffer)
-		return NULL;
+		goto fail_iput;
 	disk_super = (struct btrfs_super_block *)fs_info->sb_buffer->b_data;
+
 	if (!btrfs_super_root(disk_super))
-		return NULL;
+		goto fail_sb_buffer;
 
 	i_size_write(fs_info->btree_inode,
 		     btrfs_super_total_blocks(disk_super) <<
 		     fs_info->btree_inode->i_blkbits);
 
 	fs_info->disk_super = disk_super;
+
+	if (strncmp((char *)(&disk_super->magic), BTRFS_MAGIC,
+		    sizeof(disk_super->magic))) {
+		printk("btrfs: valid FS not found on %s\n", sb->s_id);
+		goto fail_sb_buffer;
+	}
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super));
-	BUG_ON(!tree_root->node);
+	if (!tree_root->node)
+		goto fail_sb_buffer;
 
 	mutex_lock(&fs_info->fs_mutex);
 	ret = find_and_setup_root(sb->s_blocksize, tree_root, fs_info,
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
-	BUG_ON(ret);
+	if (ret) {
+		mutex_unlock(&fs_info->fs_mutex);
+		goto fail_tree_root;
+	}
 
 	btrfs_read_block_groups(extent_root);
 
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
+
+fail_tree_root:
+	btrfs_block_release(tree_root, tree_root->node);
+fail_sb_buffer:
+	btrfs_block_release(tree_root, fs_info->sb_buffer);
+fail_iput:
+	iput(fs_info->btree_inode);
+fail:
+	kfree(extent_root);
+	kfree(tree_root);
+	kfree(fs_info);
+	return ERR_PTR(err);
 }
 
 int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root

commit 0cf6c620176a294bdf1bedddc492f6ae857e0019
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat Jun 9 09:22:25 2007 -0400

    Btrfs: remove device tree
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 751069c0e9f5..8a88404525e8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -11,47 +11,9 @@
 #include "transaction.h"
 #include "btrfs_inode.h"
 
-struct dev_lookup {
-	u64 block_start;
-	u64 num_blocks;
-	u64 device_id;
-	struct block_device *bdev;
-};
-
-int btrfs_insert_dev_radix(struct btrfs_root *root,
-			   struct block_device *bdev,
-			   u64 device_id,
-			   u64 block_start,
-			   u64 num_blocks)
-{
-	struct dev_lookup *lookup;
-	int ret;
-
-	lookup = kmalloc(sizeof(*lookup), GFP_NOFS);
-	if (!lookup)
-		return -ENOMEM;
-	lookup->block_start = block_start;
-	lookup->num_blocks = num_blocks;
-	lookup->bdev = bdev;
-	lookup->device_id = device_id;
-
-	ret = radix_tree_insert(&root->fs_info->dev_radix, block_start +
-				num_blocks - 1, lookup);
-	return ret;
-}
-
 u64 bh_blocknr(struct buffer_head *bh)
 {
-	int blkbits = bh->b_page->mapping->host->i_blkbits;
-	u64 blocknr = bh->b_page->index << (PAGE_CACHE_SHIFT - blkbits);
-	unsigned long offset;
-
-	if (PageHighMem(bh->b_page))
-		offset = (unsigned long)bh->b_data;
-	else
-		offset = bh->b_data - (char *)page_address(bh->b_page);
-	blocknr += offset >> (PAGE_CACHE_SHIFT - blkbits);
-	return blocknr;
+	return bh->b_blocknr;
 }
 
 static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
@@ -102,32 +64,14 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 int btrfs_map_bh_to_logical(struct btrfs_root *root, struct buffer_head *bh,
 			     u64 logical)
 {
-	struct dev_lookup *lookup[2];
-
-	int ret;
-
 	if (logical == 0) {
 		bh->b_bdev = NULL;
 		bh->b_blocknr = 0;
 		set_buffer_mapped(bh);
-		return 0;
-	}
-	root = root->fs_info->dev_root;
-	ret = radix_tree_gang_lookup(&root->fs_info->dev_radix,
-				     (void **)lookup,
-				     (unsigned long)logical,
-				     ARRAY_SIZE(lookup));
-	if (ret == 0 || lookup[0]->block_start > logical ||
-	    lookup[0]->block_start + lookup[0]->num_blocks <= logical) {
-		ret = -ENOENT;
-		goto out;
+	} else {
+		map_bh(bh, root->fs_info->sb, logical);
 	}
-	bh->b_bdev = lookup[0]->bdev;
-	bh->b_blocknr = logical - lookup[0]->block_start;
-	set_buffer_mapped(bh);
-	ret = 0;
-out:
-	return ret;
+	return 0;
 }
 
 struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
@@ -382,24 +326,18 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 	u64 highest_inode;
 	int ret = 0;
 
-printk("read_fs_root looking for %Lu %Lu %u\n", location->objectid, location->offset, location->flags);
 	root = radix_tree_lookup(&fs_info->fs_roots_radix,
 				 (unsigned long)location->objectid);
-	if (root) {
-printk("found %p in cache\n", root);
+	if (root)
 		return root;
-	}
 	root = kmalloc(sizeof(*root), GFP_NOFS);
-	if (!root) {
-printk("failed1\n");
+	if (!root)
 		return ERR_PTR(-ENOMEM);
-	}
 	if (location->offset == (u64)-1) {
 		ret = find_and_setup_root(fs_info->sb->s_blocksize,
 					  fs_info->tree_root, fs_info,
 					  location->objectid, root);
 		if (ret) {
-printk("failed2\n");
 			kfree(root);
 			return ERR_PTR(ret);
 		}
@@ -413,7 +351,6 @@ printk("failed2\n");
 	BUG_ON(!path);
 	ret = btrfs_search_slot(NULL, tree_root, location, path, 0, 0);
 	if (ret != 0) {
-printk("internal search_slot gives us %d\n", ret);
 		if (ret > 0)
 			ret = -ENOENT;
 		goto out;
@@ -435,13 +372,11 @@ printk("internal search_slot gives us %d\n", ret);
 				     btrfs_root_blocknr(&root->root_item));
 	BUG_ON(!root->node);
 insert:
-printk("inserting %p\n", root);
 	root->ref_cows = 1;
 	ret = radix_tree_insert(&fs_info->fs_roots_radix,
 				(unsigned long)root->root_key.objectid,
 				root);
 	if (ret) {
-printk("radix_tree_insert gives us %d\n", ret);
 		brelse(root->node);
 		kfree(root);
 		return ERR_PTR(ret);
@@ -450,116 +385,25 @@ printk("radix_tree_insert gives us %d\n", ret);
 	if (ret == 0) {
 		root->highest_inode = highest_inode;
 		root->last_inode_alloc = highest_inode;
-printk("highest inode is %Lu\n", highest_inode);
 	}
-printk("all worked\n");
 	return root;
 }
 
-static int btrfs_open_disk(struct btrfs_root *root, u64 device_id,
-			   u64 block_start, u64 num_blocks,
-			   char *filename, int name_len)
-{
-	char *null_filename;
-	struct block_device *bdev;
-	int ret;
-
-	null_filename = kmalloc(name_len + 1, GFP_NOFS);
-	if (!null_filename)
-		return -ENOMEM;
-	memcpy(null_filename, filename, name_len);
-	null_filename[name_len] = '\0';
-
-	bdev = open_bdev_excl(null_filename, O_RDWR, root->fs_info->sb);
-	if (IS_ERR(bdev)) {
-		ret = PTR_ERR(bdev);
-		goto out;
-	}
-	set_blocksize(bdev, root->fs_info->sb->s_blocksize);
-	ret = btrfs_insert_dev_radix(root, bdev, device_id,
-				     block_start, num_blocks);
-	BUG_ON(ret);
-	ret = 0;
-out:
-	kfree(null_filename);
-	return ret;
-}
-
-static int read_device_info(struct btrfs_root *root)
-{
-	struct btrfs_path *path;
-	int ret;
-	struct btrfs_key key;
-	struct btrfs_leaf *leaf;
-	struct btrfs_device_item *dev_item;
-	int nritems;
-	int slot;
-
-	root = root->fs_info->dev_root;
-
-	path = btrfs_alloc_path();
-	if (!path)
-		return -ENOMEM;
-	key.objectid = 0;
-	key.offset = 0;
-	key.flags = 0;
-	btrfs_set_key_type(&key, BTRFS_DEV_ITEM_KEY);
-
-	mutex_lock(&root->fs_info->fs_mutex);
-	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
-	leaf = btrfs_buffer_leaf(path->nodes[0]);
-	nritems = btrfs_header_nritems(&leaf->header);
-	while(1) {
-		slot = path->slots[0];
-		if (slot >= nritems) {
-			ret = btrfs_next_leaf(root, path);
-			if (ret)
-				break;
-			leaf = btrfs_buffer_leaf(path->nodes[0]);
-			nritems = btrfs_header_nritems(&leaf->header);
-			slot = path->slots[0];
-		}
-		btrfs_disk_key_to_cpu(&key, &leaf->items[slot].key);
-		if (btrfs_key_type(&key) != BTRFS_DEV_ITEM_KEY) {
-			path->slots[0]++;
-			continue;
-		}
-		dev_item = btrfs_item_ptr(leaf, slot, struct btrfs_device_item);
-printk("found key %Lu %Lu\n", key.objectid, key.offset);
-		if (btrfs_device_id(dev_item) !=
-		    btrfs_super_device_id(root->fs_info->disk_super)) {
-			ret = btrfs_open_disk(root, btrfs_device_id(dev_item),
-					      key.objectid, key.offset,
-					      (char *)(dev_item + 1),
-					      btrfs_device_pathlen(dev_item));
-			BUG_ON(ret);
-		}
-		path->slots[0]++;
-	}
-	btrfs_free_path(path);
-	mutex_unlock(&root->fs_info->fs_mutex);
-	return 0;
-}
-
 struct btrfs_root *open_ctree(struct super_block *sb)
 {
 	struct btrfs_root *extent_root = kmalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
-	struct btrfs_root *dev_root = kmalloc(sizeof(struct btrfs_root),
-						 GFP_NOFS);
 	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
 					       GFP_NOFS);
 	struct btrfs_fs_info *fs_info = kmalloc(sizeof(*fs_info),
 						GFP_NOFS);
 	int ret;
 	struct btrfs_super_block *disk_super;
-	struct dev_lookup *dev_lookup;
 
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
 	init_bit_radix(&fs_info->extent_map_radix);
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
-	INIT_RADIX_TREE(&fs_info->dev_radix, GFP_NOFS);
 	INIT_RADIX_TREE(&fs_info->block_group_radix, GFP_KERNEL);
 	INIT_RADIX_TREE(&fs_info->block_group_data_radix, GFP_KERNEL);
 	INIT_LIST_HEAD(&fs_info->trans_list);
@@ -568,7 +412,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->running_transaction = NULL;
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
-	fs_info->dev_root = dev_root;
 	fs_info->sb = sb;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
@@ -595,19 +438,9 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
 
-	__setup_root(sb->s_blocksize, dev_root,
-		     fs_info, BTRFS_DEV_TREE_OBJECTID);
-
 	__setup_root(sb->s_blocksize, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 
-	dev_lookup = kmalloc(sizeof(*dev_lookup), GFP_NOFS);
-	dev_lookup->block_start = 0;
-	dev_lookup->num_blocks = (u32)-2;
-	dev_lookup->bdev = sb->s_bdev;
-	dev_lookup->device_id = 0;
-	ret = radix_tree_insert(&fs_info->dev_radix, (u32)-2, dev_lookup);
-	BUG_ON(ret);
 	fs_info->sb_buffer = read_tree_block(tree_root,
 					     BTRFS_SUPER_INFO_OFFSET /
 					     sb->s_blocksize);
@@ -622,24 +455,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 		     btrfs_super_total_blocks(disk_super) <<
 		     fs_info->btree_inode->i_blkbits);
 
-	radix_tree_delete(&fs_info->dev_radix, (u32)-2);
-	dev_lookup->block_start = btrfs_super_device_block_start(disk_super);
-	dev_lookup->num_blocks = btrfs_super_device_num_blocks(disk_super);
-	dev_lookup->device_id = btrfs_super_device_id(disk_super);
-
-	ret = radix_tree_insert(&fs_info->dev_radix,
-				dev_lookup->block_start +
-				dev_lookup->num_blocks - 1, dev_lookup);
-	BUG_ON(ret);
-
 	fs_info->disk_super = disk_super;
-
-	dev_root->node = read_tree_block(tree_root,
-					  btrfs_super_device_root(disk_super));
-
-	ret = read_device_info(dev_root);
-	BUG_ON(ret);
-
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super));
 	BUG_ON(!tree_root->node);
@@ -719,30 +535,6 @@ static int del_fs_roots(struct btrfs_fs_info *fs_info)
 	return 0;
 }
 
-static int free_dev_radix(struct btrfs_fs_info *fs_info)
-{
-	struct dev_lookup *lookup[8];
-	struct block_device *super_bdev = fs_info->sb->s_bdev;
-	int ret;
-	int i;
-	while(1) {
-		ret = radix_tree_gang_lookup(&fs_info->dev_radix,
-					     (void **)lookup, 0,
-					     ARRAY_SIZE(lookup));
-		if (!ret)
-			break;
-		for (i = 0; i < ret; i++) {
-			if (lookup[i]->bdev != super_bdev)
-				close_bdev_excl(lookup[i]->bdev);
-			radix_tree_delete(&fs_info->dev_radix,
-					  lookup[i]->block_start +
-					  lookup[i]->num_blocks - 1);
-			kfree(lookup[i]);
-		}
-	}
-	return 0;
-}
-
 int close_ctree(struct btrfs_root *root)
 {
 	int ret;
@@ -765,9 +557,6 @@ int close_ctree(struct btrfs_root *root)
 	if (fs_info->extent_root->node)
 		btrfs_block_release(fs_info->extent_root,
 				    fs_info->extent_root->node);
-	if (fs_info->dev_root->node)
-		btrfs_block_release(fs_info->dev_root,
-				    fs_info->dev_root->node);
 	if (fs_info->tree_root->node)
 		btrfs_block_release(fs_info->tree_root,
 				    fs_info->tree_root->node);
@@ -776,7 +565,6 @@ int close_ctree(struct btrfs_root *root)
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 	iput(fs_info->btree_inode);
 
-	free_dev_radix(fs_info);
 	btrfs_free_block_groups(root->fs_info);
 	del_fs_roots(fs_info);
 	kfree(fs_info->extent_root);

commit facda1e787d43191a3368c322f682054991c41b8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 8 18:11:48 2007 -0400

    Btrfs: get forced transaction commits via workqueue
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 048282f06afb..751069c0e9f5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -563,6 +563,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	INIT_RADIX_TREE(&fs_info->block_group_radix, GFP_KERNEL);
 	INIT_RADIX_TREE(&fs_info->block_group_data_radix, GFP_KERNEL);
 	INIT_LIST_HEAD(&fs_info->trans_list);
+	INIT_LIST_HEAD(&fs_info->dead_roots);
 	sb_set_blocksize(sb, 4096);
 	fs_info->running_transaction = NULL;
 	fs_info->tree_root = tree_root;
@@ -577,6 +578,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->do_barriers = 1;
 	fs_info->extent_tree_insert_nr = 0;
 	fs_info->extent_tree_prealloc_nr = 0;
+	fs_info->closing = 0;
+
 	INIT_DELAYED_WORK(&fs_info->trans_work, btrfs_transaction_cleaner);
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
@@ -746,6 +749,7 @@ int close_ctree(struct btrfs_root *root)
 	struct btrfs_trans_handle *trans;
 	struct btrfs_fs_info *fs_info = root->fs_info;
 
+	fs_info->closing = 1;
 	btrfs_transaction_flush_work(root);
 	mutex_lock(&fs_info->fs_mutex);
 	trans = btrfs_start_transaction(root, 1);

commit 08607c1b182b3b8b54d7141a0c012cda17d201e6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 8 15:33:54 2007 -0400

    Btrfs: add compat ioctl
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3da057f78bc8..048282f06afb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -577,6 +577,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->do_barriers = 1;
 	fs_info->extent_tree_insert_nr = 0;
 	fs_info->extent_tree_prealloc_nr = 0;
+	INIT_DELAYED_WORK(&fs_info->trans_work, btrfs_transaction_cleaner);
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));
@@ -648,7 +649,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	btrfs_read_block_groups(extent_root);
 
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
-	memset(&fs_info->kobj, 0, sizeof(fs_info->kobj));
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
 }
@@ -746,6 +746,7 @@ int close_ctree(struct btrfs_root *root)
 	struct btrfs_trans_handle *trans;
 	struct btrfs_fs_info *fs_info = root->fs_info;
 
+	btrfs_transaction_flush_work(root);
 	mutex_lock(&fs_info->fs_mutex);
 	trans = btrfs_start_transaction(root, 1);
 	btrfs_commit_transaction(trans, root);
@@ -776,7 +777,6 @@ int close_ctree(struct btrfs_root *root)
 	del_fs_roots(fs_info);
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);
-	kobject_unregister(&fs_info->kobj);
 	return 0;
 }
 

commit f9f3c6b666f717510b67036c314ec915b9059eaa
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon May 21 14:05:12 2007 -0400

    Btrfs: 2.6.21-git fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 4c0262b57664..3da057f78bc8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -649,9 +649,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
 	memset(&fs_info->kobj, 0, sizeof(fs_info->kobj));
-	kobj_set_kset_s(fs_info, btrfs_subsys);
-	kobject_set_name(&fs_info->kobj, "%s", sb->s_id);
-	kobject_register(&fs_info->kobj);
 	mutex_unlock(&fs_info->fs_mutex);
 	return tree_root;
 }

commit de428b63b16f9c74a24228a517713e8c65f79475
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri May 18 13:28:27 2007 -0400

    Btrfs: allocator optimizations, truncate readahead
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 678456d1e2f9..4c0262b57664 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -257,24 +257,30 @@ static struct address_space_operations btree_aops = {
 int readahead_tree_block(struct btrfs_root *root, u64 blocknr)
 {
 	struct buffer_head *bh = NULL;
+	int ret = 0;
 
 	bh = btrfs_find_create_tree_block(root, blocknr);
 	if (!bh)
 		return 0;
-	if (buffer_uptodate(bh))
+	if (buffer_uptodate(bh)) {
+		ret = 1;
 		goto done;
-	if (test_set_buffer_locked(bh))
+	}
+	if (test_set_buffer_locked(bh)) {
+		ret = 1;
 		goto done;
+	}
 	if (!buffer_uptodate(bh)) {
 		get_bh(bh);
 		bh->b_end_io = end_buffer_read_sync;
 		submit_bh(READ, bh);
 	} else {
 		unlock_buffer(bh);
+		ret = 1;
 	}
 done:
 	brelse(bh);
-	return 0;
+	return ret;
 }
 
 struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)

commit 509659cde578d891445afd67d87121dd13e71596
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu May 10 12:36:17 2007 -0400

    Btrfs: switch to crc32c instead of sha256
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2dbf422a2b9a..678456d1e2f9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -196,14 +196,14 @@ int btrfs_csum_data(struct btrfs_root * root, char *data, size_t len,
 	ret = crypto_hash_digest(&desc, &sg, 1, result);
 	spin_unlock(&root->fs_info->hash_lock);
 	if (ret) {
-		printk("sha256 digest failed\n");
+		printk("digest failed\n");
 	}
 	return ret;
 }
 static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 			   int verify)
 {
-	char result[BTRFS_CSUM_SIZE];
+	char result[BTRFS_CRC32_SIZE];
 	int ret;
 	struct btrfs_node *node;
 
@@ -212,14 +212,14 @@ static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 	if (ret)
 		return ret;
 	if (verify) {
-		if (memcmp(bh->b_data, result, BTRFS_CSUM_SIZE)) {
+		if (memcmp(bh->b_data, result, BTRFS_CRC32_SIZE)) {
 			printk("checksum verify failed on %Lu\n",
 			       bh_blocknr(bh));
 			return 1;
 		}
 	} else {
 		node = btrfs_buffer_node(bh);
-		memcpy(node->header.csum, result, BTRFS_CSUM_SIZE);
+		memcpy(node->header.csum, result, BTRFS_CRC32_SIZE);
 	}
 	return 0;
 }
@@ -576,10 +576,10 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	       sizeof(struct btrfs_key));
 	insert_inode_hash(fs_info->btree_inode);
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
-	fs_info->hash_tfm = crypto_alloc_hash("sha256", 0, CRYPTO_ALG_ASYNC);
+	fs_info->hash_tfm = crypto_alloc_hash("crc32c", 0, CRYPTO_ALG_ASYNC);
 	spin_lock_init(&fs_info->hash_lock);
 	if (!fs_info->hash_tfm || IS_ERR(fs_info->hash_tfm)) {
-		printk("failed to allocate sha256 hash\n");
+		printk("failed to allocate digest hash\n");
 		return NULL;
 	}
 	mutex_init(&fs_info->trans_mutex);

commit e37c9e6921207cf503634b06bee37ecb7904408d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed May 9 20:13:14 2007 -0400

    Btrfs: many allocator fixes, pretty solid
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7930458c227e..2dbf422a2b9a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -551,6 +551,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
+	init_bit_radix(&fs_info->extent_map_radix);
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_RADIX_TREE(&fs_info->dev_radix, GFP_NOFS);
 	INIT_RADIX_TREE(&fs_info->block_group_radix, GFP_KERNEL);

commit be74417553f4b2ee46be2088007a674ef2f02330
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun May 6 10:15:01 2007 -0400

    Btrfs: more allocator enhancements
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5828a104dfef..7930458c227e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -554,6 +554,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_RADIX_TREE(&fs_info->dev_radix, GFP_NOFS);
 	INIT_RADIX_TREE(&fs_info->block_group_radix, GFP_KERNEL);
+	INIT_RADIX_TREE(&fs_info->block_group_data_radix, GFP_KERNEL);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	sb_set_blocksize(sb, 4096);
 	fs_info->running_transaction = NULL;
@@ -582,7 +583,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	}
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
-	fs_info->block_group_cache = NULL;
 
 	__setup_root(sb->s_blocksize, dev_root,
 		     fs_info, BTRFS_DEV_TREE_OBJECTID);

commit 35b7e476107e3d54f03384e0f2fa3dfd68933353
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed May 2 15:53:43 2007 -0400

    Btrfs: fix page cache memory leak
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 354524adf984..5828a104dfef 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -5,7 +5,7 @@
 #include <linux/scatterlist.h>
 #include <linux/swap.h>
 #include <linux/radix-tree.h>
-#include <linux/file.h>
+#include <linux/writeback.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -694,7 +694,7 @@ static int free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
 	return 0;
 }
 
-int del_fs_roots(struct btrfs_fs_info *fs_info)
+static int del_fs_roots(struct btrfs_fs_info *fs_info)
 {
 	int ret;
 	struct btrfs_root *gang[8];
@@ -781,3 +781,7 @@ void btrfs_block_release(struct btrfs_root *root, struct buffer_head *buf)
 	brelse(buf);
 }
 
+void btrfs_btree_balance_dirty(struct btrfs_root *root)
+{
+	balance_dirty_pages_ratelimited(root->fs_info->btree_inode->i_mapping);
+}

commit 090d18753c7fb73f7d846c3a89a50cd35136d144
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue May 1 08:53:32 2007 -0400

    Btrfs: directory readahead
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e1b6e13a5ae8..354524adf984 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -5,6 +5,7 @@
 #include <linux/scatterlist.h>
 #include <linux/swap.h>
 #include <linux/radix-tree.h>
+#include <linux/file.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -253,6 +254,29 @@ static struct address_space_operations btree_aops = {
 	.sync_page	= block_sync_page,
 };
 
+int readahead_tree_block(struct btrfs_root *root, u64 blocknr)
+{
+	struct buffer_head *bh = NULL;
+
+	bh = btrfs_find_create_tree_block(root, blocknr);
+	if (!bh)
+		return 0;
+	if (buffer_uptodate(bh))
+		goto done;
+	if (test_set_buffer_locked(bh))
+		goto done;
+	if (!buffer_uptodate(bh)) {
+		get_bh(bh);
+		bh->b_end_io = end_buffer_read_sync;
+		submit_bh(READ, bh);
+	} else {
+		unlock_buffer(bh);
+	}
+done:
+	brelse(bh);
+	return 0;
+}
+
 struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 {
 	struct buffer_head *bh = NULL;
@@ -270,11 +294,14 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 		wait_on_buffer(bh);
 		if (!buffer_uptodate(bh))
 			goto fail;
-		csum_tree_block(root, bh, 1);
 	} else {
 		unlock_buffer(bh);
 	}
 uptodate:
+	if (!buffer_checked(bh)) {
+		csum_tree_block(root, bh, 1);
+		set_buffer_checked(bh);
+	}
 	if (check_tree_block(root, bh))
 		BUG();
 	return bh;

commit 28b8bb9e001aa1c4abdd10a8e36972658237fe43
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 27 11:42:05 2007 -0400

    Btrfs: allocator tweaks
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2489ffa5fb38..e1b6e13a5ae8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -94,9 +94,6 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 	} while (bh != head);
 out_unlock:
 	unlock_page(page);
-	if (ret) {
-		touch_buffer(ret);
-	}
 	page_cache_release(page);
 	return ret;
 }

commit cd1bc4653dc37f6390f4d6df4f987044c64f700b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 27 10:08:34 2007 -0400

    Btrfs: more block allocator work
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1c27eb645510..2489ffa5fb38 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -558,7 +558,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	}
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
-	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
+	fs_info->block_group_cache = NULL;
 
 	__setup_root(sb->s_blocksize, dev_root,
 		     fs_info, BTRFS_DEV_TREE_OBJECTID);

commit 9078a3e1e4e489dddc636c7bb8780349d4298743
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 26 16:46:15 2007 -0400

    Btrfs: start of block group code
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 956727f015a5..1c27eb645510 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -529,6 +529,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	init_bit_radix(&fs_info->pending_del_radix);
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_RADIX_TREE(&fs_info->dev_radix, GFP_NOFS);
+	INIT_RADIX_TREE(&fs_info->block_group_radix, GFP_KERNEL);
 	INIT_LIST_HEAD(&fs_info->trans_list);
 	sb_set_blocksize(sb, 4096);
 	fs_info->running_transaction = NULL;
@@ -613,6 +614,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
 	BUG_ON(ret);
 
+	btrfs_read_block_groups(extent_root);
+
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
 	memset(&fs_info->kobj, 0, sizeof(fs_info->kobj));
 	kobj_set_kset_s(fs_info, btrfs_subsys);
@@ -741,6 +744,7 @@ int close_ctree(struct btrfs_root *root)
 	iput(fs_info->btree_inode);
 
 	free_dev_radix(fs_info);
+	btrfs_free_block_groups(root->fs_info);
 	del_fs_roots(fs_info);
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);

commit f2458e1d8c90958ed3631654cb7fd5ab01478505
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 25 15:52:25 2007 -0400

    Btrfs: change around extent-tree prealloc
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7aff6bb55d91..956727f015a5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -542,6 +542,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
 	fs_info->do_barriers = 1;
+	fs_info->extent_tree_insert_nr = 0;
+	fs_info->extent_tree_prealloc_nr = 0;
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));
@@ -555,7 +557,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	}
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
-	memset(&fs_info->current_insert, 0, sizeof(fs_info->current_insert));
 	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
 
 	__setup_root(sb->s_blocksize, dev_root,

commit 4d775673091d43b39fa9d086071009f98dec289e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 20 20:23:12 2007 -0400

    Btrfs: add owner and type fields to the extents aand block headers
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 13046295bf7a..7aff6bb55d91 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -319,6 +319,7 @@ static int __setup_root(int blocksize,
 	root->last_inode_alloc = 0;
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
+	root->root_key.objectid = objectid;
 	return 0;
 }
 

commit e66f709b157ee8557166c14b67c01bae978ac32e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 20 13:16:02 2007 -0400

    Btrfs: write barriers on commit, balance level before split
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b666c3571aee..13046295bf7a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -540,6 +540,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->btree_inode->i_nlink = 1;
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
+	fs_info->do_barriers = 1;
 	BTRFS_I(fs_info->btree_inode)->root = tree_root;
 	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
 	       sizeof(struct btrfs_key));
@@ -622,6 +623,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root)
 {
+	int ret;
 	struct buffer_head *bh = root->fs_info->sb_buffer;
 
 	btrfs_set_super_root(root->fs_info->disk_super,
@@ -632,7 +634,15 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 	csum_tree_block(root, bh, 0);
 	bh->b_end_io = end_buffer_write_sync;
 	get_bh(bh);
-	submit_bh(WRITE, bh);
+	if (root->fs_info->do_barriers)
+		ret = submit_bh(WRITE_BARRIER, bh);
+	else
+		ret = submit_bh(WRITE, bh);
+	if (ret == -EOPNOTSUPP) {
+		set_buffer_uptodate(bh);
+		root->fs_info->do_barriers = 0;
+		ret = submit_bh(WRITE, bh);
+	}
 	wait_on_buffer(bh);
 	if (!buffer_uptodate(bh)) {
 		WARN_ON(1);

commit 8fd17795b2261ecb1bad2a6df09ef14c4957a3fb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 19 21:01:03 2007 -0400

    Btrfs: early fsync support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 11e17a2f736b..b666c3571aee 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -528,6 +528,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	init_bit_radix(&fs_info->pending_del_radix);
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	INIT_RADIX_TREE(&fs_info->dev_radix, GFP_NOFS);
+	INIT_LIST_HEAD(&fs_info->trans_list);
 	sb_set_blocksize(sb, 4096);
 	fs_info->running_transaction = NULL;
 	fs_info->tree_root = tree_root;

commit 236454dfffb64a95ee01c50a215153f5de61c475
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 19 13:37:44 2007 -0400

    Btrfs: many file_write fixes, inline data
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a2a3f529cada..11e17a2f736b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -108,6 +108,12 @@ int btrfs_map_bh_to_logical(struct btrfs_root *root, struct buffer_head *bh,
 
 	int ret;
 
+	if (logical == 0) {
+		bh->b_bdev = NULL;
+		bh->b_blocknr = 0;
+		set_buffer_mapped(bh);
+		return 0;
+	}
 	root = root->fs_info->dev_root;
 	ret = radix_tree_gang_lookup(&root->fs_info->dev_radix,
 				     (void **)lookup,

commit 70b2befd0c8a4064715d8b340270650cc9d15af8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 17 15:39:32 2007 -0400

    Btrfs: rework csums and extent item ordering
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 06b969c14625..a2a3f529cada 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -24,7 +24,6 @@ int btrfs_insert_dev_radix(struct btrfs_root *root,
 			   u64 num_blocks)
 {
 	struct dev_lookup *lookup;
-	char b[BDEVNAME_SIZE];
 	int ret;
 
 	lookup = kmalloc(sizeof(*lookup), GFP_NOFS);
@@ -34,7 +33,6 @@ int btrfs_insert_dev_radix(struct btrfs_root *root,
 	lookup->num_blocks = num_blocks;
 	lookup->bdev = bdev;
 	lookup->device_id = device_id;
-printk("inserting %s into dev radix %Lu %Lu\n", bdevname(bdev, b), block_start, num_blocks);
 
 	ret = radix_tree_insert(&root->fs_info->dev_radix, block_start +
 				num_blocks - 1, lookup);

commit b4100d64241fed93a3f821ddf59d11ab4443a3ba
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 12 12:14:00 2007 -0400

    Btrfs: add a device id to device items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3ba4df20c913..06b969c14625 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -13,11 +13,13 @@
 struct dev_lookup {
 	u64 block_start;
 	u64 num_blocks;
+	u64 device_id;
 	struct block_device *bdev;
 };
 
 int btrfs_insert_dev_radix(struct btrfs_root *root,
 			   struct block_device *bdev,
+			   u64 device_id,
 			   u64 block_start,
 			   u64 num_blocks)
 {
@@ -31,6 +33,7 @@ int btrfs_insert_dev_radix(struct btrfs_root *root,
 	lookup->block_start = block_start;
 	lookup->num_blocks = num_blocks;
 	lookup->bdev = bdev;
+	lookup->device_id = device_id;
 printk("inserting %s into dev radix %Lu %Lu\n", bdevname(bdev, b), block_start, num_blocks);
 
 	ret = radix_tree_insert(&root->fs_info->dev_radix, block_start +
@@ -418,17 +421,14 @@ printk("all worked\n");
 	return root;
 }
 
-int btrfs_open_disk(struct btrfs_root *root, u64 block_start, u64 num_blocks,
-		    char *filename, int name_len)
+static int btrfs_open_disk(struct btrfs_root *root, u64 device_id,
+			   u64 block_start, u64 num_blocks,
+			   char *filename, int name_len)
 {
 	char *null_filename;
 	struct block_device *bdev;
 	int ret;
 
-	if (block_start == 0) {
-printk("skipping disk with block_start == 0\n");
-return 0;
-	}
 	null_filename = kmalloc(name_len + 1, GFP_NOFS);
 	if (!null_filename)
 		return -ENOMEM;
@@ -441,7 +441,8 @@ return 0;
 		goto out;
 	}
 	set_blocksize(bdev, root->fs_info->sb->s_blocksize);
-	ret = btrfs_insert_dev_radix(root, bdev, block_start, num_blocks);
+	ret = btrfs_insert_dev_radix(root, bdev, device_id,
+				     block_start, num_blocks);
 	BUG_ON(ret);
 	ret = 0;
 out:
@@ -490,10 +491,14 @@ static int read_device_info(struct btrfs_root *root)
 		}
 		dev_item = btrfs_item_ptr(leaf, slot, struct btrfs_device_item);
 printk("found key %Lu %Lu\n", key.objectid, key.offset);
-		ret = btrfs_open_disk(root, key.objectid, key.offset,
-				      (char *)(dev_item + 1),
-				      btrfs_device_pathlen(dev_item));
-		BUG_ON(ret);
+		if (btrfs_device_id(dev_item) !=
+		    btrfs_super_device_id(root->fs_info->disk_super)) {
+			ret = btrfs_open_disk(root, btrfs_device_id(dev_item),
+					      key.objectid, key.offset,
+					      (char *)(dev_item + 1),
+					      btrfs_device_pathlen(dev_item));
+			BUG_ON(ret);
+		}
 		path->slots[0]++;
 	}
 	btrfs_free_path(path);
@@ -556,6 +561,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	dev_lookup->block_start = 0;
 	dev_lookup->num_blocks = (u32)-2;
 	dev_lookup->bdev = sb->s_bdev;
+	dev_lookup->device_id = 0;
 	ret = radix_tree_insert(&fs_info->dev_radix, (u32)-2, dev_lookup);
 	BUG_ON(ret);
 	fs_info->sb_buffer = read_tree_block(tree_root,
@@ -575,6 +581,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	radix_tree_delete(&fs_info->dev_radix, (u32)-2);
 	dev_lookup->block_start = btrfs_super_device_block_start(disk_super);
 	dev_lookup->num_blocks = btrfs_super_device_num_blocks(disk_super);
+	dev_lookup->device_id = btrfs_super_device_id(disk_super);
+
 	ret = radix_tree_insert(&fs_info->dev_radix,
 				dev_lookup->block_start +
 				dev_lookup->num_blocks - 1, dev_lookup);
@@ -659,6 +667,7 @@ int del_fs_roots(struct btrfs_fs_info *fs_info)
 	}
 	return 0;
 }
+
 static int free_dev_radix(struct btrfs_fs_info *fs_info)
 {
 	struct dev_lookup *lookup[8];

commit 8352d8a473ac84bf7a1c69690b626946d744ca58
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 12 10:43:05 2007 -0400

    Btrfs: add disk ioctl, mostly working
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c872a7e67abd..3ba4df20c913 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -16,6 +16,28 @@ struct dev_lookup {
 	struct block_device *bdev;
 };
 
+int btrfs_insert_dev_radix(struct btrfs_root *root,
+			   struct block_device *bdev,
+			   u64 block_start,
+			   u64 num_blocks)
+{
+	struct dev_lookup *lookup;
+	char b[BDEVNAME_SIZE];
+	int ret;
+
+	lookup = kmalloc(sizeof(*lookup), GFP_NOFS);
+	if (!lookup)
+		return -ENOMEM;
+	lookup->block_start = block_start;
+	lookup->num_blocks = num_blocks;
+	lookup->bdev = bdev;
+printk("inserting %s into dev radix %Lu %Lu\n", bdevname(bdev, b), block_start, num_blocks);
+
+	ret = radix_tree_insert(&root->fs_info->dev_radix, block_start +
+				num_blocks - 1, lookup);
+	return ret;
+}
+
 u64 bh_blocknr(struct buffer_head *bh)
 {
 	int blkbits = bh->b_page->mapping->host->i_blkbits;
@@ -34,6 +56,8 @@ static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 {
 	struct btrfs_node *node = btrfs_buffer_node(buf);
 	if (bh_blocknr(buf) != btrfs_header_blocknr(&node->header)) {
+		printk(KERN_CRIT "bh_blocknr(buf) is %Lu, header is %Lu\n",
+		       bh_blocknr(buf), btrfs_header_blocknr(&node->header));
 		BUG();
 	}
 	return 0;
@@ -76,11 +100,10 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 	return ret;
 }
 
-static int map_bh_to_logical(struct btrfs_root *root, struct buffer_head *bh,
+int btrfs_map_bh_to_logical(struct btrfs_root *root, struct buffer_head *bh,
 			     u64 logical)
 {
 	struct dev_lookup *lookup[2];
-	char b[BDEVNAME_SIZE];
 
 	int ret;
 
@@ -96,7 +119,6 @@ static int map_bh_to_logical(struct btrfs_root *root, struct buffer_head *bh,
 	}
 	bh->b_bdev = lookup[0]->bdev;
 	bh->b_blocknr = logical - lookup[0]->block_start;
-printk("logical mapping %Lu to %lu bdev  %s\n", logical, bh->b_blocknr, bdevname(bh->b_bdev, b));
 	set_buffer_mapped(bh);
 	ret = 0;
 out:
@@ -126,7 +148,7 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 	bh = head;
 	do {
 		if (!buffer_mapped(bh)) {
-			err = map_bh_to_logical(root, bh, first_block);
+			err = btrfs_map_bh_to_logical(root, bh, first_block);
 			BUG_ON(err);
 		}
 		if (bh_blocknr(bh) == blocknr) {
@@ -150,7 +172,7 @@ static int btree_get_block(struct inode *inode, sector_t iblock,
 {
 	int err;
 	struct btrfs_root *root = BTRFS_I(bh->b_page->mapping->host)->root;
-	err = map_bh_to_logical(root, bh, iblock);
+	err = btrfs_map_bh_to_logical(root, bh, iblock);
 	return err;
 }
 
@@ -396,6 +418,89 @@ printk("all worked\n");
 	return root;
 }
 
+int btrfs_open_disk(struct btrfs_root *root, u64 block_start, u64 num_blocks,
+		    char *filename, int name_len)
+{
+	char *null_filename;
+	struct block_device *bdev;
+	int ret;
+
+	if (block_start == 0) {
+printk("skipping disk with block_start == 0\n");
+return 0;
+	}
+	null_filename = kmalloc(name_len + 1, GFP_NOFS);
+	if (!null_filename)
+		return -ENOMEM;
+	memcpy(null_filename, filename, name_len);
+	null_filename[name_len] = '\0';
+
+	bdev = open_bdev_excl(null_filename, O_RDWR, root->fs_info->sb);
+	if (IS_ERR(bdev)) {
+		ret = PTR_ERR(bdev);
+		goto out;
+	}
+	set_blocksize(bdev, root->fs_info->sb->s_blocksize);
+	ret = btrfs_insert_dev_radix(root, bdev, block_start, num_blocks);
+	BUG_ON(ret);
+	ret = 0;
+out:
+	kfree(null_filename);
+	return ret;
+}
+
+static int read_device_info(struct btrfs_root *root)
+{
+	struct btrfs_path *path;
+	int ret;
+	struct btrfs_key key;
+	struct btrfs_leaf *leaf;
+	struct btrfs_device_item *dev_item;
+	int nritems;
+	int slot;
+
+	root = root->fs_info->dev_root;
+
+	path = btrfs_alloc_path();
+	if (!path)
+		return -ENOMEM;
+	key.objectid = 0;
+	key.offset = 0;
+	key.flags = 0;
+	btrfs_set_key_type(&key, BTRFS_DEV_ITEM_KEY);
+
+	mutex_lock(&root->fs_info->fs_mutex);
+	ret = btrfs_search_slot(NULL, root, &key, path, 0, 0);
+	leaf = btrfs_buffer_leaf(path->nodes[0]);
+	nritems = btrfs_header_nritems(&leaf->header);
+	while(1) {
+		slot = path->slots[0];
+		if (slot >= nritems) {
+			ret = btrfs_next_leaf(root, path);
+			if (ret)
+				break;
+			leaf = btrfs_buffer_leaf(path->nodes[0]);
+			nritems = btrfs_header_nritems(&leaf->header);
+			slot = path->slots[0];
+		}
+		btrfs_disk_key_to_cpu(&key, &leaf->items[slot].key);
+		if (btrfs_key_type(&key) != BTRFS_DEV_ITEM_KEY) {
+			path->slots[0]++;
+			continue;
+		}
+		dev_item = btrfs_item_ptr(leaf, slot, struct btrfs_device_item);
+printk("found key %Lu %Lu\n", key.objectid, key.offset);
+		ret = btrfs_open_disk(root, key.objectid, key.offset,
+				      (char *)(dev_item + 1),
+				      btrfs_device_pathlen(dev_item));
+		BUG_ON(ret);
+		path->slots[0]++;
+	}
+	btrfs_free_path(path);
+	mutex_unlock(&root->fs_info->fs_mutex);
+	return 0;
+}
+
 struct btrfs_root *open_ctree(struct super_block *sb)
 {
 	struct btrfs_root *extent_root = kmalloc(sizeof(struct btrfs_root),
@@ -463,17 +568,26 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	if (!btrfs_super_root(disk_super))
 		return NULL;
 
+	i_size_write(fs_info->btree_inode,
+		     btrfs_super_total_blocks(disk_super) <<
+		     fs_info->btree_inode->i_blkbits);
+
 	radix_tree_delete(&fs_info->dev_radix, (u32)-2);
 	dev_lookup->block_start = btrfs_super_device_block_start(disk_super);
 	dev_lookup->num_blocks = btrfs_super_device_num_blocks(disk_super);
 	ret = radix_tree_insert(&fs_info->dev_radix,
 				dev_lookup->block_start +
-				dev_lookup->num_blocks, dev_lookup);
+				dev_lookup->num_blocks - 1, dev_lookup);
 	BUG_ON(ret);
 
 	fs_info->disk_super = disk_super;
+
 	dev_root->node = read_tree_block(tree_root,
 					  btrfs_super_device_root(disk_super));
+
+	ret = read_device_info(dev_root);
+	BUG_ON(ret);
+
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super));
 	BUG_ON(!tree_root->node);
@@ -562,7 +676,7 @@ static int free_dev_radix(struct btrfs_fs_info *fs_info)
 				close_bdev_excl(lookup[i]->bdev);
 			radix_tree_delete(&fs_info->dev_radix,
 					  lookup[i]->block_start +
-					  lookup[i]->num_blocks);
+					  lookup[i]->num_blocks - 1);
 			kfree(lookup[i]);
 		}
 	}

commit 7eccb903a817e890c947ba4bc90c6a9af9b4219a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 11 15:53:25 2007 -0400

    Btrfs: create a logical->phsyical block number mapping scheme
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e09233262af6..c872a7e67abd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -10,10 +10,30 @@
 #include "transaction.h"
 #include "btrfs_inode.h"
 
+struct dev_lookup {
+	u64 block_start;
+	u64 num_blocks;
+	struct block_device *bdev;
+};
+
+u64 bh_blocknr(struct buffer_head *bh)
+{
+	int blkbits = bh->b_page->mapping->host->i_blkbits;
+	u64 blocknr = bh->b_page->index << (PAGE_CACHE_SHIFT - blkbits);
+	unsigned long offset;
+
+	if (PageHighMem(bh->b_page))
+		offset = (unsigned long)bh->b_data;
+	else
+		offset = bh->b_data - (char *)page_address(bh->b_page);
+	blocknr += offset >> (PAGE_CACHE_SHIFT - blkbits);
+	return blocknr;
+}
+
 static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 {
 	struct btrfs_node *node = btrfs_buffer_node(buf);
-	if (buf->b_blocknr != btrfs_header_blocknr(&node->header)) {
+	if (bh_blocknr(buf) != btrfs_header_blocknr(&node->header)) {
 		BUG();
 	}
 	return 0;
@@ -40,7 +60,7 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 	head = page_buffers(page);
 	bh = head;
 	do {
-		if (buffer_mapped(bh) && bh->b_blocknr == blocknr) {
+		if (buffer_mapped(bh) && bh_blocknr(bh) == blocknr) {
 			ret = bh;
 			get_bh(bh);
 			goto out_unlock;
@@ -56,6 +76,33 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 	return ret;
 }
 
+static int map_bh_to_logical(struct btrfs_root *root, struct buffer_head *bh,
+			     u64 logical)
+{
+	struct dev_lookup *lookup[2];
+	char b[BDEVNAME_SIZE];
+
+	int ret;
+
+	root = root->fs_info->dev_root;
+	ret = radix_tree_gang_lookup(&root->fs_info->dev_radix,
+				     (void **)lookup,
+				     (unsigned long)logical,
+				     ARRAY_SIZE(lookup));
+	if (ret == 0 || lookup[0]->block_start > logical ||
+	    lookup[0]->block_start + lookup[0]->num_blocks <= logical) {
+		ret = -ENOENT;
+		goto out;
+	}
+	bh->b_bdev = lookup[0]->bdev;
+	bh->b_blocknr = logical - lookup[0]->block_start;
+printk("logical mapping %Lu to %lu bdev  %s\n", logical, bh->b_blocknr, bdevname(bh->b_bdev, b));
+	set_buffer_mapped(bh);
+	ret = 0;
+out:
+	return ret;
+}
+
 struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 blocknr)
 {
@@ -66,6 +113,7 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 	struct buffer_head *bh;
 	struct buffer_head *head;
 	struct buffer_head *ret = NULL;
+	int err;
 	u64 first_block = index << (PAGE_CACHE_SHIFT - blockbits);
 
 	page = grab_cache_page(mapping, index);
@@ -78,11 +126,10 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 	bh = head;
 	do {
 		if (!buffer_mapped(bh)) {
-			bh->b_bdev = root->fs_info->sb->s_bdev;
-			bh->b_blocknr = first_block;
-			set_buffer_mapped(bh);
+			err = map_bh_to_logical(root, bh, first_block);
+			BUG_ON(err);
 		}
-		if (bh->b_blocknr == blocknr) {
+		if (bh_blocknr(bh) == blocknr) {
 			ret = bh;
 			get_bh(bh);
 			goto out_unlock;
@@ -98,38 +145,13 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 	return ret;
 }
 
-static sector_t max_block(struct block_device *bdev)
-{
-	sector_t retval = ~((sector_t)0);
-	loff_t sz = i_size_read(bdev->bd_inode);
-
-	if (sz) {
-		unsigned int size = block_size(bdev);
-		unsigned int sizebits = blksize_bits(size);
-		retval = (sz >> sizebits);
-	}
-	return retval;
-}
-
 static int btree_get_block(struct inode *inode, sector_t iblock,
 			   struct buffer_head *bh, int create)
 {
-	if (iblock >= max_block(inode->i_sb->s_bdev)) {
-		if (create)
-			return -EIO;
-
-		/*
-		 * for reads, we're just trying to fill a partial page.
-		 * return a hole, they will have to call get_block again
-		 * before they can fill it, and they will get -EIO at that
-		 * time
-		 */
-		return 0;
-	}
-	bh->b_bdev = inode->i_sb->s_bdev;
-	bh->b_blocknr = iblock;
-	set_buffer_mapped(bh);
-	return 0;
+	int err;
+	struct btrfs_root *root = BTRFS_I(bh->b_page->mapping->host)->root;
+	err = map_bh_to_logical(root, bh, iblock);
+	return err;
 }
 
 int btrfs_csum_data(struct btrfs_root * root, char *data, size_t len,
@@ -164,8 +186,8 @@ static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 		return ret;
 	if (verify) {
 		if (memcmp(bh->b_data, result, BTRFS_CSUM_SIZE)) {
-			printk("checksum verify failed on %lu\n",
-			       bh->b_blocknr);
+			printk("checksum verify failed on %Lu\n",
+			       bh_blocknr(bh));
 			return 1;
 		}
 	} else {
@@ -386,10 +408,12 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 						GFP_NOFS);
 	int ret;
 	struct btrfs_super_block *disk_super;
+	struct dev_lookup *dev_lookup;
 
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
 	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
+	INIT_RADIX_TREE(&fs_info->dev_radix, GFP_NOFS);
 	sb_set_blocksize(sb, 4096);
 	fs_info->running_transaction = NULL;
 	fs_info->tree_root = tree_root;
@@ -422,6 +446,13 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 
 	__setup_root(sb->s_blocksize, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
+
+	dev_lookup = kmalloc(sizeof(*dev_lookup), GFP_NOFS);
+	dev_lookup->block_start = 0;
+	dev_lookup->num_blocks = (u32)-2;
+	dev_lookup->bdev = sb->s_bdev;
+	ret = radix_tree_insert(&fs_info->dev_radix, (u32)-2, dev_lookup);
+	BUG_ON(ret);
 	fs_info->sb_buffer = read_tree_block(tree_root,
 					     BTRFS_SUPER_INFO_OFFSET /
 					     sb->s_blocksize);
@@ -432,6 +463,14 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	if (!btrfs_super_root(disk_super))
 		return NULL;
 
+	radix_tree_delete(&fs_info->dev_radix, (u32)-2);
+	dev_lookup->block_start = btrfs_super_device_block_start(disk_super);
+	dev_lookup->num_blocks = btrfs_super_device_num_blocks(disk_super);
+	ret = radix_tree_insert(&fs_info->dev_radix,
+				dev_lookup->block_start +
+				dev_lookup->num_blocks, dev_lookup);
+	BUG_ON(ret);
+
 	fs_info->disk_super = disk_super;
 	dev_root->node = read_tree_block(tree_root,
 					  btrfs_super_device_root(disk_super));
@@ -459,7 +498,7 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 	struct buffer_head *bh = root->fs_info->sb_buffer;
 
 	btrfs_set_super_root(root->fs_info->disk_super,
-			     root->fs_info->tree_root->node->b_blocknr);
+			     bh_blocknr(root->fs_info->tree_root->node));
 	lock_buffer(bh);
 	WARN_ON(atomic_read(&bh->b_count) < 1);
 	clear_buffer_dirty(bh);
@@ -506,6 +545,29 @@ int del_fs_roots(struct btrfs_fs_info *fs_info)
 	}
 	return 0;
 }
+static int free_dev_radix(struct btrfs_fs_info *fs_info)
+{
+	struct dev_lookup *lookup[8];
+	struct block_device *super_bdev = fs_info->sb->s_bdev;
+	int ret;
+	int i;
+	while(1) {
+		ret = radix_tree_gang_lookup(&fs_info->dev_radix,
+					     (void **)lookup, 0,
+					     ARRAY_SIZE(lookup));
+		if (!ret)
+			break;
+		for (i = 0; i < ret; i++) {
+			if (lookup[i]->bdev != super_bdev)
+				close_bdev_excl(lookup[i]->bdev);
+			radix_tree_delete(&fs_info->dev_radix,
+					  lookup[i]->block_start +
+					  lookup[i]->num_blocks);
+			kfree(lookup[i]);
+		}
+	}
+	return 0;
+}
 
 int close_ctree(struct btrfs_root *root)
 {
@@ -537,6 +599,8 @@ int close_ctree(struct btrfs_root *root)
 	crypto_free_hash(fs_info->hash_tfm);
 	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
 	iput(fs_info->btree_inode);
+
+	free_dev_radix(fs_info);
 	del_fs_roots(fs_info);
 	kfree(fs_info->extent_root);
 	kfree(fs_info->tree_root);

commit 0bd93ba022f5c1ddb4e5b722b02f3c4a4a8865ad
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 11 13:57:44 2007 -0400

    Btrfs: early support for multiple devices
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index ff69162829b3..e09233262af6 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -378,6 +378,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 {
 	struct btrfs_root *extent_root = kmalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
+	struct btrfs_root *dev_root = kmalloc(sizeof(struct btrfs_root),
+						 GFP_NOFS);
 	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
 					       GFP_NOFS);
 	struct btrfs_fs_info *fs_info = kmalloc(sizeof(*fs_info),
@@ -392,6 +394,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->running_transaction = NULL;
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
+	fs_info->dev_root = dev_root;
 	fs_info->sb = sb;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
@@ -414,6 +417,9 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	memset(&fs_info->current_insert, 0, sizeof(fs_info->current_insert));
 	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
 
+	__setup_root(sb->s_blocksize, dev_root,
+		     fs_info, BTRFS_DEV_TREE_OBJECTID);
+
 	__setup_root(sb->s_blocksize, tree_root,
 		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
 	fs_info->sb_buffer = read_tree_block(tree_root,
@@ -427,6 +433,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 		return NULL;
 
 	fs_info->disk_super = disk_super;
+	dev_root->node = read_tree_block(tree_root,
+					  btrfs_super_device_root(disk_super));
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super));
 	BUG_ON(!tree_root->node);
@@ -519,6 +527,9 @@ int close_ctree(struct btrfs_root *root)
 	if (fs_info->extent_root->node)
 		btrfs_block_release(fs_info->extent_root,
 				    fs_info->extent_root->node);
+	if (fs_info->dev_root->node)
+		btrfs_block_release(fs_info->dev_root,
+				    fs_info->dev_root->node);
 	if (fs_info->tree_root->node)
 		btrfs_block_release(fs_info->tree_root,
 				    fs_info->tree_root->node);

commit 2619ba1f0ff9540a9d84683310a1e350b5efde3d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 10 16:58:11 2007 -0400

    Btrfs: subvolumes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 760fdc9a7664..ff69162829b3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -301,6 +301,12 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 	int ret = 0;
 
 printk("read_fs_root looking for %Lu %Lu %u\n", location->objectid, location->offset, location->flags);
+	root = radix_tree_lookup(&fs_info->fs_roots_radix,
+				 (unsigned long)location->objectid);
+	if (root) {
+printk("found %p in cache\n", root);
+		return root;
+	}
 	root = kmalloc(sizeof(*root), GFP_NOFS);
 	if (!root) {
 printk("failed1\n");
@@ -349,7 +355,8 @@ printk("internal search_slot gives us %d\n", ret);
 insert:
 printk("inserting %p\n", root);
 	root->ref_cows = 1;
-	ret = radix_tree_insert(&fs_info->fs_roots_radix, (unsigned long)root,
+	ret = radix_tree_insert(&fs_info->fs_roots_radix,
+				(unsigned long)root->root_key.objectid,
 				root);
 	if (ret) {
 printk("radix_tree_insert gives us %d\n", ret);
@@ -460,6 +467,20 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 	return 0;
 }
 
+static int free_fs_root(struct btrfs_fs_info *fs_info, struct btrfs_root *root)
+{
+	radix_tree_delete(&fs_info->fs_roots_radix,
+			  (unsigned long)root->root_key.objectid);
+	if (root->inode)
+		iput(root->inode);
+	if (root->node)
+		brelse(root->node);
+	if (root->commit_root)
+		brelse(root->commit_root);
+	kfree(root);
+	return 0;
+}
+
 int del_fs_roots(struct btrfs_fs_info *fs_info)
 {
 	int ret;
@@ -472,19 +493,8 @@ int del_fs_roots(struct btrfs_fs_info *fs_info)
 					     ARRAY_SIZE(gang));
 		if (!ret)
 			break;
-		for (i = 0; i < ret; i++) {
-			radix_tree_delete(&fs_info->fs_roots_radix,
-					  (unsigned long)gang[i]);
-			if (gang[i]->inode)
-				iput(gang[i]->inode);
-			else
-				printk("no inode for root %p\n", gang[i]);
-			if (gang[i]->node)
-				brelse(gang[i]->node);
-			if (gang[i]->commit_root)
-				brelse(gang[i]->commit_root);
-			kfree(gang[i]);
-		}
+		for (i = 0; i < ret; i++)
+			free_fs_root(fs_info, gang[i]);
 	}
 	return 0;
 }

commit 1b05da2ee6217e7d55460d04335813fec25be4ca
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 10 12:13:09 2007 -0400

    Btrfs: drop the inode map tree
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6b097ede80b1..760fdc9a7664 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -264,6 +264,8 @@ static int __setup_root(int blocksize,
 	root->fs_info = fs_info;
 	root->objectid = objectid;
 	root->last_trans = 0;
+	root->highest_inode = 0;
+	root->last_inode_alloc = 0;
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	return 0;
@@ -295,6 +297,7 @@ struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
 	struct btrfs_root *tree_root = fs_info->tree_root;
 	struct btrfs_path *path;
 	struct btrfs_leaf *l;
+	u64 highest_inode;
 	int ret = 0;
 
 printk("read_fs_root looking for %Lu %Lu %u\n", location->objectid, location->offset, location->flags);
@@ -354,6 +357,12 @@ printk("radix_tree_insert gives us %d\n", ret);
 		kfree(root);
 		return ERR_PTR(ret);
 	}
+	ret = btrfs_find_highest_inode(root, &highest_inode);
+	if (ret == 0) {
+		root->highest_inode = highest_inode;
+		root->last_inode_alloc = highest_inode;
+printk("highest inode is %Lu\n", highest_inode);
+	}
 printk("all worked\n");
 	return root;
 }
@@ -364,8 +373,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 						 GFP_NOFS);
 	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
 					       GFP_NOFS);
-	struct btrfs_root *inode_root = kmalloc(sizeof(struct btrfs_root),
-						GFP_NOFS);
 	struct btrfs_fs_info *fs_info = kmalloc(sizeof(*fs_info),
 						GFP_NOFS);
 	int ret;
@@ -378,9 +385,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->running_transaction = NULL;
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
-	fs_info->inode_root = inode_root;
-	fs_info->last_inode_alloc = 0;
-	fs_info->highest_inode = 0;
 	fs_info->sb = sb;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
@@ -425,14 +429,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
 	BUG_ON(ret);
 
-	ret = find_and_setup_root(sb->s_blocksize, tree_root, fs_info,
-				  BTRFS_INODE_MAP_OBJECTID, inode_root);
-	BUG_ON(ret);
-
 	fs_info->generation = btrfs_super_generation(disk_super) + 1;
-	ret = btrfs_find_highest_inode(tree_root, &fs_info->last_inode_alloc);
-	if (ret == 0)
-		fs_info->highest_inode = fs_info->last_inode_alloc;
 	memset(&fs_info->kobj, 0, sizeof(fs_info->kobj));
 	kobj_set_kset_s(fs_info, btrfs_subsys);
 	kobject_set_name(&fs_info->kobj, "%s", sb->s_id);
@@ -512,9 +509,6 @@ int close_ctree(struct btrfs_root *root)
 	if (fs_info->extent_root->node)
 		btrfs_block_release(fs_info->extent_root,
 				    fs_info->extent_root->node);
-	if (fs_info->inode_root->node)
-		btrfs_block_release(fs_info->inode_root,
-				    fs_info->inode_root->node);
 	if (fs_info->tree_root->node)
 		btrfs_block_release(fs_info->tree_root,
 				    fs_info->tree_root->node);
@@ -524,7 +518,6 @@ int close_ctree(struct btrfs_root *root)
 	iput(fs_info->btree_inode);
 	del_fs_roots(fs_info);
 	kfree(fs_info->extent_root);
-	kfree(fs_info->inode_root);
 	kfree(fs_info->tree_root);
 	kobject_unregister(&fs_info->kobj);
 	return 0;

commit c5739bba5260a59cebd20a51a55080592c8d3b07
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 10 09:27:04 2007 -0400

    Btrfs: snapshot progress
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b557bdd1e26a..6b097ede80b1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -16,10 +16,6 @@ static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 	if (buf->b_blocknr != btrfs_header_blocknr(&node->header)) {
 		BUG();
 	}
-	if (root->node && btrfs_header_parentid(&node->header) !=
-	    btrfs_header_parentid(btrfs_buffer_header(root->node))) {
-		BUG();
-	}
 	return 0;
 }
 

commit 0f7d52f4431c530b4f39c524448c688bb7754de5
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 9 10:42:37 2007 -0400

    Btrfs: groundwork for subvolume and snapshot roots
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b9301a5e4608..b557bdd1e26a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -4,9 +4,11 @@
 #include <linux/crypto.h>
 #include <linux/scatterlist.h>
 #include <linux/swap.h>
+#include <linux/radix-tree.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
+#include "btrfs_inode.h"
 
 static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 {
@@ -180,7 +182,7 @@ static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct buffer_head *bh;
-	struct btrfs_root *root = btrfs_sb(page->mapping->host->i_sb);
+	struct btrfs_root *root = BTRFS_I(page->mapping->host)->root;
 	struct buffer_head *head;
 	if (!page_has_buffers(page)) {
 		create_empty_buffers(page, root->fs_info->sb->s_blocksize,
@@ -259,10 +261,13 @@ static int __setup_root(int blocksize,
 			u64 objectid)
 {
 	root->node = NULL;
+	root->inode = NULL;
 	root->commit_root = NULL;
 	root->blocksize = blocksize;
 	root->ref_cows = 0;
 	root->fs_info = fs_info;
+	root->objectid = objectid;
+	root->last_trans = 0;
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	return 0;
@@ -287,10 +292,78 @@ static int find_and_setup_root(int blocksize,
 	return 0;
 }
 
+struct btrfs_root *btrfs_read_fs_root(struct btrfs_fs_info *fs_info,
+				      struct btrfs_key *location)
+{
+	struct btrfs_root *root;
+	struct btrfs_root *tree_root = fs_info->tree_root;
+	struct btrfs_path *path;
+	struct btrfs_leaf *l;
+	int ret = 0;
+
+printk("read_fs_root looking for %Lu %Lu %u\n", location->objectid, location->offset, location->flags);
+	root = kmalloc(sizeof(*root), GFP_NOFS);
+	if (!root) {
+printk("failed1\n");
+		return ERR_PTR(-ENOMEM);
+	}
+	if (location->offset == (u64)-1) {
+		ret = find_and_setup_root(fs_info->sb->s_blocksize,
+					  fs_info->tree_root, fs_info,
+					  location->objectid, root);
+		if (ret) {
+printk("failed2\n");
+			kfree(root);
+			return ERR_PTR(ret);
+		}
+		goto insert;
+	}
+
+	__setup_root(fs_info->sb->s_blocksize, root, fs_info,
+		     location->objectid);
+
+	path = btrfs_alloc_path();
+	BUG_ON(!path);
+	ret = btrfs_search_slot(NULL, tree_root, location, path, 0, 0);
+	if (ret != 0) {
+printk("internal search_slot gives us %d\n", ret);
+		if (ret > 0)
+			ret = -ENOENT;
+		goto out;
+	}
+	l = btrfs_buffer_leaf(path->nodes[0]);
+	memcpy(&root->root_item,
+	       btrfs_item_ptr(l, path->slots[0], struct btrfs_root_item),
+	       sizeof(root->root_item));
+	memcpy(&root->root_key, location, sizeof(*location));
+	ret = 0;
+out:
+	btrfs_release_path(root, path);
+	btrfs_free_path(path);
+	if (ret) {
+		kfree(root);
+		return ERR_PTR(ret);
+	}
+	root->node = read_tree_block(root,
+				     btrfs_root_blocknr(&root->root_item));
+	BUG_ON(!root->node);
+insert:
+printk("inserting %p\n", root);
+	root->ref_cows = 1;
+	ret = radix_tree_insert(&fs_info->fs_roots_radix, (unsigned long)root,
+				root);
+	if (ret) {
+printk("radix_tree_insert gives us %d\n", ret);
+		brelse(root->node);
+		kfree(root);
+		return ERR_PTR(ret);
+	}
+printk("all worked\n");
+	return root;
+}
+
 struct btrfs_root *open_ctree(struct super_block *sb)
 {
-	struct btrfs_root *root = kmalloc(sizeof(struct btrfs_root),
-					  GFP_NOFS);
 	struct btrfs_root *extent_root = kmalloc(sizeof(struct btrfs_root),
 						 GFP_NOFS);
 	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
@@ -304,9 +377,9 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
+	INIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_NOFS);
 	sb_set_blocksize(sb, 4096);
 	fs_info->running_transaction = NULL;
-	fs_info->fs_root = root;
 	fs_info->tree_root = tree_root;
 	fs_info->extent_root = extent_root;
 	fs_info->inode_root = inode_root;
@@ -318,6 +391,9 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->btree_inode->i_nlink = 1;
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
+	BTRFS_I(fs_info->btree_inode)->root = tree_root;
+	memset(&BTRFS_I(fs_info->btree_inode)->location, 0,
+	       sizeof(struct btrfs_key));
 	insert_inode_hash(fs_info->btree_inode);
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->hash_tfm = crypto_alloc_hash("sha256", 0, CRYPTO_ALG_ASYNC);
@@ -337,13 +413,12 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 					     BTRFS_SUPER_INFO_OFFSET /
 					     sb->s_blocksize);
 
-	if (!fs_info->sb_buffer) {
+	if (!fs_info->sb_buffer)
 		return NULL;
-	}
 	disk_super = (struct btrfs_super_block *)fs_info->sb_buffer->b_data;
-	if (!btrfs_super_root(disk_super)) {
+	if (!btrfs_super_root(disk_super))
 		return NULL;
-	}
+
 	fs_info->disk_super = disk_super;
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super));
@@ -358,14 +433,8 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 				  BTRFS_INODE_MAP_OBJECTID, inode_root);
 	BUG_ON(ret);
 
-	ret = find_and_setup_root(sb->s_blocksize, tree_root, fs_info,
-				  BTRFS_FS_TREE_OBJECTID, root);
-	BUG_ON(ret);
-	root->commit_root = root->node;
-	get_bh(root->node);
-	root->ref_cows = 1;
-	root->fs_info->generation = root->root_key.offset + 1;
-	ret = btrfs_find_highest_inode(root, &root->fs_info->last_inode_alloc);
+	fs_info->generation = btrfs_super_generation(disk_super) + 1;
+	ret = btrfs_find_highest_inode(tree_root, &fs_info->last_inode_alloc);
 	if (ret == 0)
 		fs_info->highest_inode = fs_info->last_inode_alloc;
 	memset(&fs_info->kobj, 0, sizeof(fs_info->kobj));
@@ -373,7 +442,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	kobject_set_name(&fs_info->kobj, "%s", sb->s_id);
 	kobject_register(&fs_info->kobj);
 	mutex_unlock(&fs_info->fs_mutex);
-	return root;
+	return tree_root;
 }
 
 int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
@@ -398,12 +467,42 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 	return 0;
 }
 
+int del_fs_roots(struct btrfs_fs_info *fs_info)
+{
+	int ret;
+	struct btrfs_root *gang[8];
+	int i;
+
+	while(1) {
+		ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,
+					     (void **)gang, 0,
+					     ARRAY_SIZE(gang));
+		if (!ret)
+			break;
+		for (i = 0; i < ret; i++) {
+			radix_tree_delete(&fs_info->fs_roots_radix,
+					  (unsigned long)gang[i]);
+			if (gang[i]->inode)
+				iput(gang[i]->inode);
+			else
+				printk("no inode for root %p\n", gang[i]);
+			if (gang[i]->node)
+				brelse(gang[i]->node);
+			if (gang[i]->commit_root)
+				brelse(gang[i]->commit_root);
+			kfree(gang[i]);
+		}
+	}
+	return 0;
+}
+
 int close_ctree(struct btrfs_root *root)
 {
 	int ret;
 	struct btrfs_trans_handle *trans;
+	struct btrfs_fs_info *fs_info = root->fs_info;
 
-	mutex_lock(&root->fs_info->fs_mutex);
+	mutex_lock(&fs_info->fs_mutex);
 	trans = btrfs_start_transaction(root, 1);
 	btrfs_commit_transaction(trans, root);
 	/* run commit again to  drop the original snapshot */
@@ -412,29 +511,26 @@ int close_ctree(struct btrfs_root *root)
 	ret = btrfs_write_and_wait_transaction(NULL, root);
 	BUG_ON(ret);
 	write_ctree_super(NULL, root);
-	mutex_unlock(&root->fs_info->fs_mutex);
-
-	if (root->node)
-		btrfs_block_release(root, root->node);
-	if (root->fs_info->extent_root->node)
-		btrfs_block_release(root->fs_info->extent_root,
-				    root->fs_info->extent_root->node);
-	if (root->fs_info->inode_root->node)
-		btrfs_block_release(root->fs_info->inode_root,
-				    root->fs_info->inode_root->node);
-	if (root->fs_info->tree_root->node)
-		btrfs_block_release(root->fs_info->tree_root,
-				    root->fs_info->tree_root->node);
-	btrfs_block_release(root, root->commit_root);
-	btrfs_block_release(root, root->fs_info->sb_buffer);
-	crypto_free_hash(root->fs_info->hash_tfm);
-	truncate_inode_pages(root->fs_info->btree_inode->i_mapping, 0);
-	iput(root->fs_info->btree_inode);
-	kfree(root->fs_info->extent_root);
-	kfree(root->fs_info->inode_root);
-	kfree(root->fs_info->tree_root);
-	kobject_unregister(&root->fs_info->kobj);
-	kfree(root);
+	mutex_unlock(&fs_info->fs_mutex);
+
+	if (fs_info->extent_root->node)
+		btrfs_block_release(fs_info->extent_root,
+				    fs_info->extent_root->node);
+	if (fs_info->inode_root->node)
+		btrfs_block_release(fs_info->inode_root,
+				    fs_info->inode_root->node);
+	if (fs_info->tree_root->node)
+		btrfs_block_release(fs_info->tree_root,
+				    fs_info->tree_root->node);
+	btrfs_block_release(root, fs_info->sb_buffer);
+	crypto_free_hash(fs_info->hash_tfm);
+	truncate_inode_pages(fs_info->btree_inode->i_mapping, 0);
+	iput(fs_info->btree_inode);
+	del_fs_roots(fs_info);
+	kfree(fs_info->extent_root);
+	kfree(fs_info->inode_root);
+	kfree(fs_info->tree_root);
+	kobject_unregister(&fs_info->kobj);
 	return 0;
 }
 

commit d6e4a428eb8f92bbb3537ccabadfb1195efb432b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 6 15:37:36 2007 -0400

    Btrfs: start of support for many FS volumes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 5230554380d1..b9301a5e4608 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -338,7 +338,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 					     sb->s_blocksize);
 
 	if (!fs_info->sb_buffer) {
-printk("failed2\n");
 		return NULL;
 	}
 	disk_super = (struct btrfs_super_block *)fs_info->sb_buffer->b_data;
@@ -369,6 +368,10 @@ printk("failed2\n");
 	ret = btrfs_find_highest_inode(root, &root->fs_info->last_inode_alloc);
 	if (ret == 0)
 		fs_info->highest_inode = fs_info->last_inode_alloc;
+	memset(&fs_info->kobj, 0, sizeof(fs_info->kobj));
+	kobj_set_kset_s(fs_info, btrfs_subsys);
+	kobject_set_name(&fs_info->kobj, "%s", sb->s_id);
+	kobject_register(&fs_info->kobj);
 	mutex_unlock(&fs_info->fs_mutex);
 	return root;
 }
@@ -430,7 +433,7 @@ int close_ctree(struct btrfs_root *root)
 	kfree(root->fs_info->extent_root);
 	kfree(root->fs_info->inode_root);
 	kfree(root->fs_info->tree_root);
-	kfree(root->fs_info);
+	kobject_unregister(&root->fs_info->kobj);
 	kfree(root);
 	return 0;
 }

commit 5be6f7f174146d91039a27ebb2f1b4ac599172b3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 5 13:35:25 2007 -0400

    Btrfs: dirindex optimizations
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index de9ee3aa0aad..5230554380d1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -311,6 +311,7 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->extent_root = extent_root;
 	fs_info->inode_root = inode_root;
 	fs_info->last_inode_alloc = 0;
+	fs_info->highest_inode = 0;
 	fs_info->sb = sb;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
@@ -360,12 +361,15 @@ printk("failed2\n");
 
 	ret = find_and_setup_root(sb->s_blocksize, tree_root, fs_info,
 				  BTRFS_FS_TREE_OBJECTID, root);
-	mutex_unlock(&fs_info->fs_mutex);
 	BUG_ON(ret);
 	root->commit_root = root->node;
 	get_bh(root->node);
 	root->ref_cows = 1;
 	root->fs_info->generation = root->root_key.offset + 1;
+	ret = btrfs_find_highest_inode(root, &root->fs_info->last_inode_alloc);
+	if (ret == 0)
+		fs_info->highest_inode = fs_info->last_inode_alloc;
+	mutex_unlock(&fs_info->fs_mutex);
 	return root;
 }
 

commit b1a4d96509a78ad234d94e0b914b289c60d2969d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Apr 4 15:27:52 2007 -0400

    Btrfs: tweak the inode-map and free extent search starts on cold mount
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 055cd45e802e..de9ee3aa0aad 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -311,7 +311,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->extent_root = extent_root;
 	fs_info->inode_root = inode_root;
 	fs_info->last_inode_alloc = 0;
-	fs_info->last_inode_alloc_dirid = 0;
 	fs_info->sb = sb;
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;

commit 9d64272cd3be2aae71f89f7ababbee90a7587b33
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Apr 3 11:43:19 2007 -0400

    Btrfs: don't wait on uptodate buffers on read
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 39b117a57a54..055cd45e802e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -214,6 +214,8 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 	bh = btrfs_find_create_tree_block(root, blocknr);
 	if (!bh)
 		return bh;
+	if (buffer_uptodate(bh))
+		goto uptodate;
 	lock_buffer(bh);
 	if (!buffer_uptodate(bh)) {
 		get_bh(bh);
@@ -226,6 +228,7 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 	} else {
 		unlock_buffer(bh);
 	}
+uptodate:
 	if (check_tree_block(root, bh))
 		BUG();
 	return bh;

commit 2da566edd8ce32ae2952b863ee634bcc2e7d63c1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 2 15:43:21 2007 -0400

    Btrfs: csum_verify_file_block locking fix
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a227e94b9e88..39b117a57a54 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -160,7 +160,6 @@ static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 	int ret;
 	struct btrfs_node *node;
 
-	return 0;
 	ret = btrfs_csum_data(root, bh->b_data + BTRFS_CSUM_SIZE,
 			      bh->b_size - BTRFS_CSUM_SIZE, result);
 	if (ret)

commit 7cfcc17e7f2334a0503331264c1340de4e564c85
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 2 14:53:59 2007 -0400

    Btrfs: corruptions fixed
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2dbd55084a4e..a227e94b9e88 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -23,8 +23,6 @@ static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 
 struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	return sb_find_get_block(root->fs_info->sb, blocknr);
-#if 0
 	struct address_space *mapping = root->fs_info->btree_inode->i_mapping;
 	int blockbits = root->fs_info->sb->s_blocksize_bits;
 	unsigned long index = blocknr >> (PAGE_CACHE_SHIFT - blockbits);
@@ -58,14 +56,11 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 	}
 	page_cache_release(page);
 	return ret;
-#endif
 }
 
 struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 blocknr)
 {
-	return sb_getblk(root->fs_info->sb, blocknr);
-#if 0
 	struct address_space *mapping = root->fs_info->btree_inode->i_mapping;
 	int blockbits = root->fs_info->sb->s_blocksize_bits;
 	unsigned long index = blocknr >> (PAGE_CACHE_SHIFT - blockbits);
@@ -103,7 +98,6 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 		touch_buffer(ret);
 	page_cache_release(page);
 	return ret;
-#endif
 }
 
 static sector_t max_block(struct block_device *bdev)
@@ -186,7 +180,6 @@ static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
-#if 0
 	struct buffer_head *bh;
 	struct btrfs_root *root = btrfs_sb(page->mapping->host->i_sb);
 	struct buffer_head *head;
@@ -201,7 +194,6 @@ static int btree_writepage(struct page *page, struct writeback_control *wbc)
 			csum_tree_block(root, bh, 0);
 		bh = bh->b_this_page;
 	} while (bh != head);
-#endif
 	return block_write_full_page(page, btree_get_block, wbc);
 }
 
@@ -218,8 +210,6 @@ static struct address_space_operations btree_aops = {
 
 struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	return sb_bread(root->fs_info->sb, blocknr);
-#if 0
 	struct buffer_head *bh = NULL;
 
 	bh = btrfs_find_create_tree_block(root, blocknr);
@@ -243,8 +233,6 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 fail:
 	brelse(bh);
 	return NULL;
-
-#endif
 }
 
 int dirty_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
@@ -323,8 +311,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->last_inode_alloc = 0;
 	fs_info->last_inode_alloc_dirid = 0;
 	fs_info->sb = sb;
-	fs_info->btree_inode = NULL;
-#if 0
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_nlink = 1;
@@ -332,7 +318,6 @@ struct btrfs_root *open_ctree(struct super_block *sb)
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
 	insert_inode_hash(fs_info->btree_inode);
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
-#endif
 	fs_info->hash_tfm = crypto_alloc_hash("sha256", 0, CRYPTO_ALG_ASYNC);
 	spin_lock_init(&fs_info->hash_lock);
 	if (!fs_info->hash_tfm || IS_ERR(fs_info->hash_tfm)) {
@@ -435,8 +420,8 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_block_release(root, root->commit_root);
 	btrfs_block_release(root, root->fs_info->sb_buffer);
 	crypto_free_hash(root->fs_info->hash_tfm);
-	// truncate_inode_pages(root->fs_info->btree_inode->i_mapping, 0);
-	// iput(root->fs_info->btree_inode);
+	truncate_inode_pages(root->fs_info->btree_inode->i_mapping, 0);
+	iput(root->fs_info->btree_inode);
 	kfree(root->fs_info->extent_root);
 	kfree(root->fs_info->inode_root);
 	kfree(root->fs_info->tree_root);
@@ -447,6 +432,6 @@ int close_ctree(struct btrfs_root *root)
 
 void btrfs_block_release(struct btrfs_root *root, struct buffer_head *buf)
 {
-	// brelse(buf);
+	brelse(buf);
 }
 

commit 2c90e5d658424bc71b111eb5a972240d5d06fe86
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 2 10:50:19 2007 -0400

    Btrfs: still corruption hunting
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bb133104e2e9..2dbd55084a4e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -8,18 +8,6 @@
 #include "disk-io.h"
 #include "transaction.h"
 
-#define PATTERN 0xDEADBEEFUL
-static inline void check_pattern(struct buffer_head *buf)
-{
-	if (buf->b_private != (void *)PATTERN)
-		WARN_ON(1);
-}
-
-static inline void set_pattern(struct buffer_head *buf)
-{
-	buf->b_private = (void *)PATTERN;
-}
-
 static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 {
 	struct btrfs_node *node = btrfs_buffer_node(buf);
@@ -35,6 +23,8 @@ static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 
 struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 {
+	return sb_find_get_block(root->fs_info->sb, blocknr);
+#if 0
 	struct address_space *mapping = root->fs_info->btree_inode->i_mapping;
 	int blockbits = root->fs_info->sb->s_blocksize_bits;
 	unsigned long index = blocknr >> (PAGE_CACHE_SHIFT - blockbits);
@@ -43,6 +33,7 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 	struct buffer_head *head;
 	struct buffer_head *ret = NULL;
 
+
 	page = find_lock_page(mapping, index);
 	if (!page)
 		return NULL;
@@ -64,15 +55,17 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 	unlock_page(page);
 	if (ret) {
 		touch_buffer(ret);
-		check_pattern(ret);
 	}
 	page_cache_release(page);
 	return ret;
+#endif
 }
 
 struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 						 u64 blocknr)
 {
+	return sb_getblk(root->fs_info->sb, blocknr);
+#if 0
 	struct address_space *mapping = root->fs_info->btree_inode->i_mapping;
 	int blockbits = root->fs_info->sb->s_blocksize_bits;
 	unsigned long index = blocknr >> (PAGE_CACHE_SHIFT - blockbits);
@@ -95,7 +88,6 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 			bh->b_bdev = root->fs_info->sb->s_bdev;
 			bh->b_blocknr = first_block;
 			set_buffer_mapped(bh);
-			set_pattern(bh);
 		}
 		if (bh->b_blocknr == blocknr) {
 			ret = bh;
@@ -111,6 +103,7 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 		touch_buffer(ret);
 	page_cache_release(page);
 	return ret;
+#endif
 }
 
 static sector_t max_block(struct block_device *bdev)
@@ -225,6 +218,8 @@ static struct address_space_operations btree_aops = {
 
 struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 {
+	return sb_bread(root->fs_info->sb, blocknr);
+#if 0
 	struct buffer_head *bh = NULL;
 
 	bh = btrfs_find_create_tree_block(root, blocknr);
@@ -239,7 +234,6 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 		if (!buffer_uptodate(bh))
 			goto fail;
 		csum_tree_block(root, bh, 1);
-		set_pattern(bh);
 	} else {
 		unlock_buffer(bh);
 	}
@@ -250,6 +244,7 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 	brelse(bh);
 	return NULL;
 
+#endif
 }
 
 int dirty_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
@@ -268,14 +263,14 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 	return 0;
 }
 
-static int __setup_root(struct btrfs_super_block *super,
+static int __setup_root(int blocksize,
 			struct btrfs_root *root,
 			struct btrfs_fs_info *fs_info,
 			u64 objectid)
 {
 	root->node = NULL;
 	root->commit_root = NULL;
-	root->blocksize = btrfs_super_blocksize(super);
+	root->blocksize = blocksize;
 	root->ref_cows = 0;
 	root->fs_info = fs_info;
 	memset(&root->root_key, 0, sizeof(root->root_key));
@@ -283,7 +278,7 @@ static int __setup_root(struct btrfs_super_block *super,
 	return 0;
 }
 
-static int find_and_setup_root(struct btrfs_super_block *super,
+static int find_and_setup_root(int blocksize,
 			       struct btrfs_root *tree_root,
 			       struct btrfs_fs_info *fs_info,
 			       u64 objectid,
@@ -291,7 +286,7 @@ static int find_and_setup_root(struct btrfs_super_block *super,
 {
 	int ret;
 
-	__setup_root(super, root, fs_info, objectid);
+	__setup_root(blocksize, root, fs_info, objectid);
 	ret = btrfs_find_last_root(tree_root, objectid,
 				   &root->root_item, &root->root_key);
 	BUG_ON(ret);
@@ -302,9 +297,7 @@ static int find_and_setup_root(struct btrfs_super_block *super,
 	return 0;
 }
 
-struct btrfs_root *open_ctree(struct super_block *sb,
-			      struct buffer_head *sb_buffer,
-			      struct btrfs_super_block *disk_super)
+struct btrfs_root *open_ctree(struct super_block *sb)
 {
 	struct btrfs_root *root = kmalloc(sizeof(struct btrfs_root),
 					  GFP_NOFS);
@@ -317,13 +310,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	struct btrfs_fs_info *fs_info = kmalloc(sizeof(*fs_info),
 						GFP_NOFS);
 	int ret;
+	struct btrfs_super_block *disk_super;
 
-	if (!btrfs_super_root(disk_super)) {
-		return NULL;
-	}
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
-	sb_set_blocksize(sb, sb_buffer->b_size);
+	sb_set_blocksize(sb, 4096);
 	fs_info->running_transaction = NULL;
 	fs_info->fs_root = root;
 	fs_info->tree_root = tree_root;
@@ -331,55 +322,59 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->inode_root = inode_root;
 	fs_info->last_inode_alloc = 0;
 	fs_info->last_inode_alloc_dirid = 0;
-	fs_info->disk_super = disk_super;
 	fs_info->sb = sb;
+	fs_info->btree_inode = NULL;
+#if 0
 	fs_info->btree_inode = new_inode(sb);
 	fs_info->btree_inode->i_ino = 1;
+	fs_info->btree_inode->i_nlink = 1;
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
 	insert_inode_hash(fs_info->btree_inode);
-
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
+#endif
 	fs_info->hash_tfm = crypto_alloc_hash("sha256", 0, CRYPTO_ALG_ASYNC);
 	spin_lock_init(&fs_info->hash_lock);
-
 	if (!fs_info->hash_tfm || IS_ERR(fs_info->hash_tfm)) {
 		printk("failed to allocate sha256 hash\n");
 		return NULL;
 	}
-
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
 	memset(&fs_info->current_insert, 0, sizeof(fs_info->current_insert));
 	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
 
-	__setup_root(disk_super, tree_root, fs_info, BTRFS_ROOT_TREE_OBJECTID);
-
-	fs_info->sb_buffer = read_tree_block(tree_root, sb_buffer->b_blocknr);
+	__setup_root(sb->s_blocksize, tree_root,
+		     fs_info, BTRFS_ROOT_TREE_OBJECTID);
+	fs_info->sb_buffer = read_tree_block(tree_root,
+					     BTRFS_SUPER_INFO_OFFSET /
+					     sb->s_blocksize);
 
 	if (!fs_info->sb_buffer) {
 printk("failed2\n");
 		return NULL;
 	}
-	brelse(sb_buffer);
-	sb_buffer = NULL;
 	disk_super = (struct btrfs_super_block *)fs_info->sb_buffer->b_data;
+	if (!btrfs_super_root(disk_super)) {
+		return NULL;
+	}
 	fs_info->disk_super = disk_super;
-
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super));
 	BUG_ON(!tree_root->node);
 
-	ret = find_and_setup_root(disk_super, tree_root, fs_info,
+	mutex_lock(&fs_info->fs_mutex);
+	ret = find_and_setup_root(sb->s_blocksize, tree_root, fs_info,
 				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
 	BUG_ON(ret);
 
-	ret = find_and_setup_root(disk_super, tree_root, fs_info,
+	ret = find_and_setup_root(sb->s_blocksize, tree_root, fs_info,
 				  BTRFS_INODE_MAP_OBJECTID, inode_root);
 	BUG_ON(ret);
 
-	ret = find_and_setup_root(disk_super, tree_root, fs_info,
+	ret = find_and_setup_root(sb->s_blocksize, tree_root, fs_info,
 				  BTRFS_FS_TREE_OBJECTID, root);
+	mutex_unlock(&fs_info->fs_mutex);
 	BUG_ON(ret);
 	root->commit_root = root->node;
 	get_bh(root->node);
@@ -392,9 +387,11 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root)
 {
 	struct buffer_head *bh = root->fs_info->sb_buffer;
+
 	btrfs_set_super_root(root->fs_info->disk_super,
 			     root->fs_info->tree_root->node->b_blocknr);
 	lock_buffer(bh);
+	WARN_ON(atomic_read(&bh->b_count) < 1);
 	clear_buffer_dirty(bh);
 	csum_tree_block(root, bh, 0);
 	bh->b_end_io = end_buffer_write_sync;
@@ -413,6 +410,7 @@ int close_ctree(struct btrfs_root *root)
 	int ret;
 	struct btrfs_trans_handle *trans;
 
+	mutex_lock(&root->fs_info->fs_mutex);
 	trans = btrfs_start_transaction(root, 1);
 	btrfs_commit_transaction(trans, root);
 	/* run commit again to  drop the original snapshot */
@@ -421,6 +419,7 @@ int close_ctree(struct btrfs_root *root)
 	ret = btrfs_write_and_wait_transaction(NULL, root);
 	BUG_ON(ret);
 	write_ctree_super(NULL, root);
+	mutex_unlock(&root->fs_info->fs_mutex);
 
 	if (root->node)
 		btrfs_block_release(root, root->node);
@@ -436,8 +435,8 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_block_release(root, root->commit_root);
 	btrfs_block_release(root, root->fs_info->sb_buffer);
 	crypto_free_hash(root->fs_info->hash_tfm);
-	truncate_inode_pages(root->fs_info->btree_inode->i_mapping, 0);
-	iput(root->fs_info->btree_inode);
+	// truncate_inode_pages(root->fs_info->btree_inode->i_mapping, 0);
+	// iput(root->fs_info->btree_inode);
 	kfree(root->fs_info->extent_root);
 	kfree(root->fs_info->inode_root);
 	kfree(root->fs_info->tree_root);
@@ -448,7 +447,6 @@ int close_ctree(struct btrfs_root *root)
 
 void btrfs_block_release(struct btrfs_root *root, struct buffer_head *buf)
 {
-	check_pattern(buf);
-	brelse(buf);
+	// brelse(buf);
 }
 

commit d6025579531b7ea170ba283b171ff7a6bf7d0e12
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 30 14:27:56 2007 -0400

    Btrfs: corruption hunt continues
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 6c010463b9db..bb133104e2e9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -8,6 +8,17 @@
 #include "disk-io.h"
 #include "transaction.h"
 
+#define PATTERN 0xDEADBEEFUL
+static inline void check_pattern(struct buffer_head *buf)
+{
+	if (buf->b_private != (void *)PATTERN)
+		WARN_ON(1);
+}
+
+static inline void set_pattern(struct buffer_head *buf)
+{
+	buf->b_private = (void *)PATTERN;
+}
 
 static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 {
@@ -51,8 +62,10 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 	} while (bh != head);
 out_unlock:
 	unlock_page(page);
-	if (ret)
+	if (ret) {
 		touch_buffer(ret);
+		check_pattern(ret);
+	}
 	page_cache_release(page);
 	return ret;
 }
@@ -82,6 +95,7 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 			bh->b_bdev = root->fs_info->sb->s_bdev;
 			bh->b_blocknr = first_block;
 			set_buffer_mapped(bh);
+			set_pattern(bh);
 		}
 		if (bh->b_blocknr == blocknr) {
 			ret = bh;
@@ -225,6 +239,7 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 		if (!buffer_uptodate(bh))
 			goto fail;
 		csum_tree_block(root, bh, 1);
+		set_pattern(bh);
 	} else {
 		unlock_buffer(bh);
 	}
@@ -240,6 +255,7 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 int dirty_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		     struct buffer_head *buf)
 {
+	WARN_ON(atomic_read(&buf->b_count) == 0);
 	mark_buffer_dirty(buf);
 	return 0;
 }
@@ -247,6 +263,7 @@ int dirty_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 		     struct buffer_head *buf)
 {
+	WARN_ON(atomic_read(&buf->b_count) == 0);
 	clear_buffer_dirty(buf);
 	return 0;
 }
@@ -431,6 +448,7 @@ int close_ctree(struct btrfs_root *root)
 
 void btrfs_block_release(struct btrfs_root *root, struct buffer_head *buf)
 {
+	check_pattern(buf);
 	brelse(buf);
 }
 

commit 22b0ebda6c63a1ad66b6a9e806bd226a4a03a049
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 30 08:47:31 2007 -0400

    Btrfs: hunting slab corruption
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f5db2b936502..6c010463b9db 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3,6 +3,7 @@
 #include <linux/blkdev.h>
 #include <linux/crypto.h>
 #include <linux/scatterlist.h>
+#include <linux/swap.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -50,6 +51,8 @@ struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
 	} while (bh != head);
 out_unlock:
 	unlock_page(page);
+	if (ret)
+		touch_buffer(ret);
 	page_cache_release(page);
 	return ret;
 }
@@ -65,6 +68,7 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 	struct buffer_head *head;
 	struct buffer_head *ret = NULL;
 	u64 first_block = index << (PAGE_CACHE_SHIFT - blockbits);
+
 	page = grab_cache_page(mapping, index);
 	if (!page)
 		return NULL;
@@ -89,6 +93,8 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 	} while (bh != head);
 out_unlock:
 	unlock_page(page);
+	if (ret)
+		touch_buffer(ret);
 	page_cache_release(page);
 	return ret;
 }
@@ -139,7 +145,7 @@ int btrfs_csum_data(struct btrfs_root * root, char *data, size_t len,
 	desc.flags = 0;
 	sg_init_one(&sg, data, len);
 	spin_lock(&root->fs_info->hash_lock);
-	ret = crypto_hash_digest(&desc, &sg, len, result);
+	ret = crypto_hash_digest(&desc, &sg, 1, result);
 	spin_unlock(&root->fs_info->hash_lock);
 	if (ret) {
 		printk("sha256 digest failed\n");
@@ -153,6 +159,7 @@ static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 	int ret;
 	struct btrfs_node *node;
 
+	return 0;
 	ret = btrfs_csum_data(root, bh->b_data + BTRFS_CSUM_SIZE,
 			      bh->b_size - BTRFS_CSUM_SIZE, result);
 	if (ret)
@@ -165,17 +172,17 @@ static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
 		}
 	} else {
 		node = btrfs_buffer_node(bh);
-		memcpy(&node->header.csum, result, BTRFS_CSUM_SIZE);
+		memcpy(node->header.csum, result, BTRFS_CSUM_SIZE);
 	}
 	return 0;
 }
 
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
+#if 0
 	struct buffer_head *bh;
 	struct btrfs_root *root = btrfs_sb(page->mapping->host->i_sb);
 	struct buffer_head *head;
-
 	if (!page_has_buffers(page)) {
 		create_empty_buffers(page, root->fs_info->sb->s_blocksize,
 					(1 << BH_Dirty)|(1 << BH_Uptodate));
@@ -187,6 +194,7 @@ static int btree_writepage(struct page *page, struct writeback_control *wbc)
 			csum_tree_block(root, bh, 0);
 		bh = bh->b_this_page;
 	} while (bh != head);
+#endif
 	return block_write_full_page(page, btree_get_block, wbc);
 }
 
@@ -312,6 +320,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode->i_ino = 1;
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
+	insert_inode_hash(fs_info->btree_inode);
+
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->hash_tfm = crypto_alloc_hash("sha256", 0, CRYPTO_ALG_ASYNC);
 	spin_lock_init(&fs_info->hash_lock);

commit f254e52c1ce550fdaa0d31f5e068f0d67c2485d4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 29 15:15:27 2007 -0400

    Btrfs: verify csums on read
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f2c1dd40c087..f5db2b936502 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -127,31 +127,46 @@ static int btree_get_block(struct inode *inode, sector_t iblock,
 	return 0;
 }
 
-static int csum_tree_block(struct btrfs_root * root, struct buffer_head *bh,
-			    int verify)
+int btrfs_csum_data(struct btrfs_root * root, char *data, size_t len,
+		    char *result)
 {
-	struct btrfs_node *node = btrfs_buffer_node(bh);
 	struct scatterlist sg;
 	struct crypto_hash *tfm = root->fs_info->hash_tfm;
 	struct hash_desc desc;
 	int ret;
-	char result[32];
 
 	desc.tfm = tfm;
 	desc.flags = 0;
-	sg_init_one(&sg, bh->b_data + 32, bh->b_size - 32);
+	sg_init_one(&sg, data, len);
 	spin_lock(&root->fs_info->hash_lock);
-	ret = crypto_hash_digest(&desc, &sg, bh->b_size - 32, result);
+	ret = crypto_hash_digest(&desc, &sg, len, result);
 	spin_unlock(&root->fs_info->hash_lock);
 	if (ret) {
 		printk("sha256 digest failed\n");
 	}
+	return ret;
+}
+static int csum_tree_block(struct btrfs_root *root, struct buffer_head *bh,
+			   int verify)
+{
+	char result[BTRFS_CSUM_SIZE];
+	int ret;
+	struct btrfs_node *node;
+
+	ret = btrfs_csum_data(root, bh->b_data + BTRFS_CSUM_SIZE,
+			      bh->b_size - BTRFS_CSUM_SIZE, result);
+	if (ret)
+		return ret;
 	if (verify) {
-		if (memcmp(node->header.csum, result, sizeof(result)))
-			printk("csum verify failed on %Lu\n", bh->b_blocknr);
-		return -EINVAL;
-	} else
-		memcpy(node->header.csum, result, sizeof(node->header.csum));
+		if (memcmp(bh->b_data, result, BTRFS_CSUM_SIZE)) {
+			printk("checksum verify failed on %lu\n",
+			       bh->b_blocknr);
+			return 1;
+		}
+	} else {
+		node = btrfs_buffer_node(bh);
+		memcpy(&node->header.csum, result, BTRFS_CSUM_SIZE);
+	}
 	return 0;
 }
 

commit 30ae8467483d7ab023b5e728bf7d74a575c78023
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 29 09:59:15 2007 -0400

    Btrfs: btree address space fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2afb7922b062..f2c1dd40c087 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -69,7 +69,6 @@ struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
 	if (!page)
 		return NULL;
 
-	wait_on_page_writeback(page);
 	if (!page_has_buffers(page))
 		create_empty_buffers(page, root->fs_info->sb->s_blocksize, 0);
 	head = page_buffers(page);
@@ -300,11 +299,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
 	fs_info->hash_tfm = crypto_alloc_hash("sha256", 0, CRYPTO_ALG_ASYNC);
-	if (!fs_info->hash_tfm) {
+	spin_lock_init(&fs_info->hash_lock);
+
+	if (!fs_info->hash_tfm || IS_ERR(fs_info->hash_tfm)) {
 		printk("failed to allocate sha256 hash\n");
 		return NULL;
 	}
-	spin_lock_init(&fs_info->hash_lock);
 
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
@@ -394,6 +394,7 @@ int close_ctree(struct btrfs_root *root)
 	btrfs_block_release(root, root->commit_root);
 	btrfs_block_release(root, root->fs_info->sb_buffer);
 	crypto_free_hash(root->fs_info->hash_tfm);
+	truncate_inode_pages(root->fs_info->btree_inode->i_mapping, 0);
 	iput(root->fs_info->btree_inode);
 	kfree(root->fs_info->extent_root);
 	kfree(root->fs_info->inode_root);

commit 87cbda5c1f54aba67b1e318a4a4824c9e9f16324
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 28 19:44:27 2007 -0400

    Btrfs: sha256 csums on metadata
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 970103f2cacd..2afb7922b062 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1,6 +1,8 @@
 #include <linux/module.h>
 #include <linux/fs.h>
 #include <linux/blkdev.h>
+#include <linux/crypto.h>
+#include <linux/scatterlist.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
@@ -126,8 +128,51 @@ static int btree_get_block(struct inode *inode, sector_t iblock,
 	return 0;
 }
 
+static int csum_tree_block(struct btrfs_root * root, struct buffer_head *bh,
+			    int verify)
+{
+	struct btrfs_node *node = btrfs_buffer_node(bh);
+	struct scatterlist sg;
+	struct crypto_hash *tfm = root->fs_info->hash_tfm;
+	struct hash_desc desc;
+	int ret;
+	char result[32];
+
+	desc.tfm = tfm;
+	desc.flags = 0;
+	sg_init_one(&sg, bh->b_data + 32, bh->b_size - 32);
+	spin_lock(&root->fs_info->hash_lock);
+	ret = crypto_hash_digest(&desc, &sg, bh->b_size - 32, result);
+	spin_unlock(&root->fs_info->hash_lock);
+	if (ret) {
+		printk("sha256 digest failed\n");
+	}
+	if (verify) {
+		if (memcmp(node->header.csum, result, sizeof(result)))
+			printk("csum verify failed on %Lu\n", bh->b_blocknr);
+		return -EINVAL;
+	} else
+		memcpy(node->header.csum, result, sizeof(node->header.csum));
+	return 0;
+}
+
 static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
+	struct buffer_head *bh;
+	struct btrfs_root *root = btrfs_sb(page->mapping->host->i_sb);
+	struct buffer_head *head;
+
+	if (!page_has_buffers(page)) {
+		create_empty_buffers(page, root->fs_info->sb->s_blocksize,
+					(1 << BH_Dirty)|(1 << BH_Uptodate));
+	}
+	head = page_buffers(page);
+	bh = head;
+	do {
+		if (buffer_dirty(bh))
+			csum_tree_block(root, bh, 0);
+		bh = bh->b_this_page;
+	} while (bh != head);
 	return block_write_full_page(page, btree_get_block, wbc);
 }
 
@@ -157,6 +202,7 @@ struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 		wait_on_buffer(bh);
 		if (!buffer_uptodate(bh))
 			goto fail;
+		csum_tree_block(root, bh, 1);
 	} else {
 		unlock_buffer(bh);
 	}
@@ -233,8 +279,9 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 						GFP_NOFS);
 	int ret;
 
-	if (!btrfs_super_root(disk_super))
+	if (!btrfs_super_root(disk_super)) {
 		return NULL;
+	}
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
 	sb_set_blocksize(sb, sb_buffer->b_size);
@@ -252,6 +299,12 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
 	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
 	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
+	fs_info->hash_tfm = crypto_alloc_hash("sha256", 0, CRYPTO_ALG_ASYNC);
+	if (!fs_info->hash_tfm) {
+		printk("failed to allocate sha256 hash\n");
+		return NULL;
+	}
+	spin_lock_init(&fs_info->hash_lock);
 
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
@@ -262,9 +315,10 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 
 	fs_info->sb_buffer = read_tree_block(tree_root, sb_buffer->b_blocknr);
 
-	if (!fs_info->sb_buffer)
+	if (!fs_info->sb_buffer) {
+printk("failed2\n");
 		return NULL;
-
+	}
 	brelse(sb_buffer);
 	sb_buffer = NULL;
 	disk_super = (struct btrfs_super_block *)fs_info->sb_buffer->b_data;
@@ -300,6 +354,7 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 			     root->fs_info->tree_root->node->b_blocknr);
 	lock_buffer(bh);
 	clear_buffer_dirty(bh);
+	csum_tree_block(root, bh, 0);
 	bh->b_end_io = end_buffer_write_sync;
 	get_bh(bh);
 	submit_bh(WRITE, bh);
@@ -338,6 +393,7 @@ int close_ctree(struct btrfs_root *root)
 				    root->fs_info->tree_root->node);
 	btrfs_block_release(root, root->commit_root);
 	btrfs_block_release(root, root->fs_info->sb_buffer);
+	crypto_free_hash(root->fs_info->hash_tfm);
 	iput(root->fs_info->btree_inode);
 	kfree(root->fs_info->extent_root);
 	kfree(root->fs_info->inode_root);

commit d98237b3ede7ab98892f7fa62201a13694c526e2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 28 13:57:48 2007 -0400

    Btrfs: use a btree inode instead of sb_getblk
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 758a62aba063..970103f2cacd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1,14 +1,17 @@
 #include <linux/module.h>
 #include <linux/fs.h>
+#include <linux/blkdev.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
 
+
 static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 {
 	struct btrfs_node *node = btrfs_buffer_node(buf);
-	if (buf->b_blocknr != btrfs_header_blocknr(&node->header))
+	if (buf->b_blocknr != btrfs_header_blocknr(&node->header)) {
 		BUG();
+	}
 	if (root->node && btrfs_header_parentid(&node->header) !=
 	    btrfs_header_parentid(btrfs_buffer_header(root->node))) {
 		BUG();
@@ -16,25 +19,154 @@ static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 	return 0;
 }
 
-struct buffer_head *alloc_tree_block(struct btrfs_root *root, u64 blocknr)
+struct buffer_head *btrfs_find_tree_block(struct btrfs_root *root, u64 blocknr)
+{
+	struct address_space *mapping = root->fs_info->btree_inode->i_mapping;
+	int blockbits = root->fs_info->sb->s_blocksize_bits;
+	unsigned long index = blocknr >> (PAGE_CACHE_SHIFT - blockbits);
+	struct page *page;
+	struct buffer_head *bh;
+	struct buffer_head *head;
+	struct buffer_head *ret = NULL;
+
+	page = find_lock_page(mapping, index);
+	if (!page)
+		return NULL;
+
+	if (!page_has_buffers(page))
+		goto out_unlock;
+
+	head = page_buffers(page);
+	bh = head;
+	do {
+		if (buffer_mapped(bh) && bh->b_blocknr == blocknr) {
+			ret = bh;
+			get_bh(bh);
+			goto out_unlock;
+		}
+		bh = bh->b_this_page;
+	} while (bh != head);
+out_unlock:
+	unlock_page(page);
+	page_cache_release(page);
+	return ret;
+}
+
+struct buffer_head *btrfs_find_create_tree_block(struct btrfs_root *root,
+						 u64 blocknr)
+{
+	struct address_space *mapping = root->fs_info->btree_inode->i_mapping;
+	int blockbits = root->fs_info->sb->s_blocksize_bits;
+	unsigned long index = blocknr >> (PAGE_CACHE_SHIFT - blockbits);
+	struct page *page;
+	struct buffer_head *bh;
+	struct buffer_head *head;
+	struct buffer_head *ret = NULL;
+	u64 first_block = index << (PAGE_CACHE_SHIFT - blockbits);
+	page = grab_cache_page(mapping, index);
+	if (!page)
+		return NULL;
+
+	wait_on_page_writeback(page);
+	if (!page_has_buffers(page))
+		create_empty_buffers(page, root->fs_info->sb->s_blocksize, 0);
+	head = page_buffers(page);
+	bh = head;
+	do {
+		if (!buffer_mapped(bh)) {
+			bh->b_bdev = root->fs_info->sb->s_bdev;
+			bh->b_blocknr = first_block;
+			set_buffer_mapped(bh);
+		}
+		if (bh->b_blocknr == blocknr) {
+			ret = bh;
+			get_bh(bh);
+			goto out_unlock;
+		}
+		bh = bh->b_this_page;
+		first_block++;
+	} while (bh != head);
+out_unlock:
+	unlock_page(page);
+	page_cache_release(page);
+	return ret;
+}
+
+static sector_t max_block(struct block_device *bdev)
+{
+	sector_t retval = ~((sector_t)0);
+	loff_t sz = i_size_read(bdev->bd_inode);
+
+	if (sz) {
+		unsigned int size = block_size(bdev);
+		unsigned int sizebits = blksize_bits(size);
+		retval = (sz >> sizebits);
+	}
+	return retval;
+}
+
+static int btree_get_block(struct inode *inode, sector_t iblock,
+			   struct buffer_head *bh, int create)
+{
+	if (iblock >= max_block(inode->i_sb->s_bdev)) {
+		if (create)
+			return -EIO;
+
+		/*
+		 * for reads, we're just trying to fill a partial page.
+		 * return a hole, they will have to call get_block again
+		 * before they can fill it, and they will get -EIO at that
+		 * time
+		 */
+		return 0;
+	}
+	bh->b_bdev = inode->i_sb->s_bdev;
+	bh->b_blocknr = iblock;
+	set_buffer_mapped(bh);
+	return 0;
+}
+
+static int btree_writepage(struct page *page, struct writeback_control *wbc)
 {
-	return sb_getblk(root->fs_info->sb, blocknr);
+	return block_write_full_page(page, btree_get_block, wbc);
 }
 
-struct buffer_head *find_tree_block(struct btrfs_root *root, u64 blocknr)
+static int btree_readpage(struct file * file, struct page * page)
 {
-	return sb_getblk(root->fs_info->sb, blocknr);
+	return block_read_full_page(page, btree_get_block);
 }
 
+static struct address_space_operations btree_aops = {
+	.readpage	= btree_readpage,
+	.writepage	= btree_writepage,
+	.sync_page	= block_sync_page,
+};
+
 struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	struct buffer_head *buf = sb_bread(root->fs_info->sb, blocknr);
+	struct buffer_head *bh = NULL;
 
-	if (!buf)
-		return buf;
-	if (check_tree_block(root, buf))
+	bh = btrfs_find_create_tree_block(root, blocknr);
+	if (!bh)
+		return bh;
+	lock_buffer(bh);
+	if (!buffer_uptodate(bh)) {
+		get_bh(bh);
+		bh->b_end_io = end_buffer_read_sync;
+		submit_bh(READ, bh);
+		wait_on_buffer(bh);
+		if (!buffer_uptodate(bh))
+			goto fail;
+	} else {
+		unlock_buffer(bh);
+	}
+	if (check_tree_block(root, bh))
 		BUG();
-	return buf;
+	return bh;
+fail:
+	brelse(bh);
+	return NULL;
+
 }
 
 int dirty_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
@@ -101,11 +233,11 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 						GFP_NOFS);
 	int ret;
 
-	/* FIXME: don't be stupid */
 	if (!btrfs_super_root(disk_super))
 		return NULL;
 	init_bit_radix(&fs_info->pinned_radix);
 	init_bit_radix(&fs_info->pending_del_radix);
+	sb_set_blocksize(sb, sb_buffer->b_size);
 	fs_info->running_transaction = NULL;
 	fs_info->fs_root = root;
 	fs_info->tree_root = tree_root;
@@ -114,14 +246,30 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->last_inode_alloc = 0;
 	fs_info->last_inode_alloc_dirid = 0;
 	fs_info->disk_super = disk_super;
-	fs_info->sb_buffer = sb_buffer;
 	fs_info->sb = sb;
+	fs_info->btree_inode = new_inode(sb);
+	fs_info->btree_inode->i_ino = 1;
+	fs_info->btree_inode->i_size = sb->s_bdev->bd_inode->i_size;
+	fs_info->btree_inode->i_mapping->a_ops = &btree_aops;
+	mapping_set_gfp_mask(fs_info->btree_inode->i_mapping, GFP_NOFS);
+
 	mutex_init(&fs_info->trans_mutex);
 	mutex_init(&fs_info->fs_mutex);
 	memset(&fs_info->current_insert, 0, sizeof(fs_info->current_insert));
 	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
 
 	__setup_root(disk_super, tree_root, fs_info, BTRFS_ROOT_TREE_OBJECTID);
+
+	fs_info->sb_buffer = read_tree_block(tree_root, sb_buffer->b_blocknr);
+
+	if (!fs_info->sb_buffer)
+		return NULL;
+
+	brelse(sb_buffer);
+	sb_buffer = NULL;
+	disk_super = (struct btrfs_super_block *)fs_info->sb_buffer->b_data;
+	fs_info->disk_super = disk_super;
+
 	tree_root->node = read_tree_block(tree_root,
 					  btrfs_super_root(disk_super));
 	BUG_ON(!tree_root->node);
@@ -137,7 +285,6 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	ret = find_and_setup_root(disk_super, tree_root, fs_info,
 				  BTRFS_FS_TREE_OBJECTID, root);
 	BUG_ON(ret);
-
 	root->commit_root = root->node;
 	get_bh(root->node);
 	root->ref_cows = 1;
@@ -191,6 +338,7 @@ int close_ctree(struct btrfs_root *root)
 				    root->fs_info->tree_root->node);
 	btrfs_block_release(root, root->commit_root);
 	btrfs_block_release(root, root->fs_info->sb_buffer);
+	iput(root->fs_info->btree_inode);
 	kfree(root->fs_info->extent_root);
 	kfree(root->fs_info->inode_root);
 	kfree(root->fs_info->tree_root);

commit 8ef97622caa2d5f78d1dc58ab918e2fbfa9b357a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 26 10:15:30 2007 -0400

    Btrfs: add a radix back bit tree
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index e32ddff55b0e..758a62aba063 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -104,7 +104,8 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	/* FIXME: don't be stupid */
 	if (!btrfs_super_root(disk_super))
 		return NULL;
-	INIT_RADIX_TREE(&fs_info->pinned_radix, GFP_KERNEL);
+	init_bit_radix(&fs_info->pinned_radix);
+	init_bit_radix(&fs_info->pending_del_radix);
 	fs_info->running_transaction = NULL;
 	fs_info->fs_root = root;
 	fs_info->tree_root = tree_root;

commit d561c025ee3a0aee53a225bedce0ee35fe12f335
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 23 19:47:49 2007 -0400

    Btrfs: very minimal locking
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3dea757d4cbb..e32ddff55b0e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -116,6 +116,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->sb_buffer = sb_buffer;
 	fs_info->sb = sb;
 	mutex_init(&fs_info->trans_mutex);
+	mutex_init(&fs_info->fs_mutex);
 	memset(&fs_info->current_insert, 0, sizeof(fs_info->current_insert));
 	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
 

commit 7f5c15160e1436a53d01f9190db11c2a3a4d788a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 23 15:56:19 2007 -0400

    Add generation number to btrfs_header, readdir fixes, hash collision fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2f1eb4ae4e1d..3dea757d4cbb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -11,11 +11,7 @@ static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 		BUG();
 	if (root->node && btrfs_header_parentid(&node->header) !=
 	    btrfs_header_parentid(btrfs_buffer_header(root->node))) {
-		printk("block %Lu parentids don't match buf %Lu, root %Lu\n",
-		       buf->b_blocknr,
-		       btrfs_header_parentid(&node->header),
-		       btrfs_header_parentid(btrfs_buffer_header(root->node)));
-		WARN_ON(1);
+		BUG();
 	}
 	return 0;
 }

commit df2ce34c8801af8e00c7f82435fcb1e4b45a2759
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 23 11:00:45 2007 -0400

    Btrfs: properly set new buffers for new blocks up to date
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8e1dcda0839c..2f1eb4ae4e1d 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -10,8 +10,13 @@ static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 	if (buf->b_blocknr != btrfs_header_blocknr(&node->header))
 		BUG();
 	if (root->node && btrfs_header_parentid(&node->header) !=
-	    btrfs_header_parentid(btrfs_buffer_header(root->node)))
-		BUG();
+	    btrfs_header_parentid(btrfs_buffer_header(root->node))) {
+		printk("block %Lu parentids don't match buf %Lu, root %Lu\n",
+		       buf->b_blocknr,
+		       btrfs_header_parentid(&node->header),
+		       btrfs_header_parentid(btrfs_buffer_header(root->node)));
+		WARN_ON(1);
+	}
 	return 0;
 }
 

commit d571976292839cec05a2820b08f7629b145ed157
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 23 10:01:08 2007 -0400

    btrfs_create, btrfs_write_super, btrfs_sync_fs
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 9cacca0c525c..8e1dcda0839c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -145,19 +145,20 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root)
 {
-	return 0;
-#if 0
-	int ret;
-	btrfs_set_super_root(s, root->fs_info->tree_root->node->b_blocknr);
-
-	ret = pwrite(root->fs_info->fp, s, sizeof(*s),
-		     BTRFS_SUPER_INFO_OFFSET);
-	if (ret != sizeof(*s)) {
-		fprintf(stderr, "failed to write new super block err %d\n", ret);
-		return ret;
+	struct buffer_head *bh = root->fs_info->sb_buffer;
+	btrfs_set_super_root(root->fs_info->disk_super,
+			     root->fs_info->tree_root->node->b_blocknr);
+	lock_buffer(bh);
+	clear_buffer_dirty(bh);
+	bh->b_end_io = end_buffer_write_sync;
+	get_bh(bh);
+	submit_bh(WRITE, bh);
+	wait_on_buffer(bh);
+	if (!buffer_uptodate(bh)) {
+		WARN_ON(1);
+		return -EIO;
 	}
 	return 0;
-#endif
 }
 
 int close_ctree(struct btrfs_root *root)

commit 79154b1b5bcf87903db7ff16a30b360b78d6fe4f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 22 15:59:16 2007 -0400

    Btrfs: transaction rework
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index df2061a735cd..9cacca0c525c 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -50,89 +50,6 @@ int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 	return 0;
 }
 
-int write_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		     struct buffer_head *buf)
-{
-	mark_buffer_dirty(buf);
-	return 0;
-}
-
-static int __commit_transaction(struct btrfs_trans_handle *trans, struct
-				btrfs_root *root)
-{
-	filemap_write_and_wait(root->fs_info->sb->s_bdev->bd_inode->i_mapping);
-	return 0;
-}
-
-static int commit_tree_roots(struct btrfs_trans_handle *trans,
-			     struct btrfs_fs_info *fs_info)
-{
-	int ret;
-	u64 old_extent_block;
-	struct btrfs_root *tree_root = fs_info->tree_root;
-	struct btrfs_root *extent_root = fs_info->extent_root;
-	struct btrfs_root *inode_root = fs_info->inode_root;
-
-	btrfs_set_root_blocknr(&inode_root->root_item,
-			       inode_root->node->b_blocknr);
-	ret = btrfs_update_root(trans, tree_root,
-				&inode_root->root_key,
-				&inode_root->root_item);
-	BUG_ON(ret);
-	while(1) {
-		old_extent_block = btrfs_root_blocknr(&extent_root->root_item);
-		if (old_extent_block == extent_root->node->b_blocknr)
-			break;
-		btrfs_set_root_blocknr(&extent_root->root_item,
-				       extent_root->node->b_blocknr);
-		ret = btrfs_update_root(trans, tree_root,
-					&extent_root->root_key,
-					&extent_root->root_item);
-		BUG_ON(ret);
-	}
-	return 0;
-}
-
-int btrfs_commit_transaction(struct btrfs_trans_handle *trans, struct
-			     btrfs_root *root, struct btrfs_super_block *s)
-{
-	int ret = 0;
-	struct buffer_head *snap = root->commit_root;
-	struct btrfs_key snap_key;
-
-	if (root->commit_root == root->node)
-		return 0;
-
-	memcpy(&snap_key, &root->root_key, sizeof(snap_key));
-	root->root_key.offset++;
-
-	btrfs_set_root_blocknr(&root->root_item, root->node->b_blocknr);
-	ret = btrfs_insert_root(trans, root->fs_info->tree_root,
-				&root->root_key, &root->root_item);
-	BUG_ON(ret);
-
-	ret = commit_tree_roots(trans, root->fs_info);
-	BUG_ON(ret);
-
-	ret = __commit_transaction(trans, root);
-	BUG_ON(ret);
-
-	write_ctree_super(trans, root, s);
-	btrfs_finish_extent_commit(trans, root->fs_info->extent_root);
-	btrfs_finish_extent_commit(trans, root->fs_info->tree_root);
-
-	root->commit_root = root->node;
-	get_bh(root->node);
-	ret = btrfs_drop_snapshot(trans, root, snap);
-	BUG_ON(ret);
-
-	ret = btrfs_del_root(trans, root->fs_info->tree_root, &snap_key);
-	BUG_ON(ret);
-	root->fs_info->generation = root->root_key.offset + 1;
-
-	return ret;
-}
-
 static int __setup_root(struct btrfs_super_block *super,
 			struct btrfs_root *root,
 			struct btrfs_fs_info *fs_info,
@@ -197,6 +114,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 	fs_info->disk_super = disk_super;
 	fs_info->sb_buffer = sb_buffer;
 	fs_info->sb = sb;
+	mutex_init(&fs_info->trans_mutex);
 	memset(&fs_info->current_insert, 0, sizeof(fs_info->current_insert));
 	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
 
@@ -225,7 +143,7 @@ struct btrfs_root *open_ctree(struct super_block *sb,
 }
 
 int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
-		      *root, struct btrfs_super_block *s)
+		      *root)
 {
 	return 0;
 #if 0
@@ -242,34 +160,19 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 #endif
 }
 
-static int drop_cache(struct btrfs_root *root)
-{
-	return 0;
-#if 0
-	while(!list_empty(&root->fs_info->cache)) {
-		struct buffer_head *b = list_entry(root->fs_info->cache.next,
-						    struct buffer_head,
-						    cache);
-		list_del_init(&b->cache);
-		btrfs_block_release(root, b);
-	}
-	return 0;
-#endif
-}
-
 int close_ctree(struct btrfs_root *root)
 {
 	int ret;
 	struct btrfs_trans_handle *trans;
 
-	trans = root->fs_info->running_transaction;
-	btrfs_commit_transaction(trans, root, root->fs_info->disk_super);
-	ret = commit_tree_roots(trans, root->fs_info);
-	BUG_ON(ret);
-	ret = __commit_transaction(trans, root);
+	trans = btrfs_start_transaction(root, 1);
+	btrfs_commit_transaction(trans, root);
+	/* run commit again to  drop the original snapshot */
+	trans = btrfs_start_transaction(root, 1);
+	btrfs_commit_transaction(trans, root);
+	ret = btrfs_write_and_wait_transaction(NULL, root);
 	BUG_ON(ret);
-	write_ctree_super(trans, root, root->fs_info->disk_super);
-	drop_cache(root);
+	write_ctree_super(NULL, root);
 
 	if (root->node)
 		btrfs_block_release(root, root->node);

commit e20d96d64f9cf9288ffecc9ad4714e91c3b97ca8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 22 12:13:20 2007 -0400

    Mountable btrfs, with readdir
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 05637f9fd7c7..df2061a735cd 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1,165 +1,67 @@
-#define _XOPEN_SOURCE 500
-#include <stdio.h>
-#include <stdlib.h>
-#include <sys/types.h>
-#include <sys/stat.h>
-#include <fcntl.h>
-#include <unistd.h>
-#include "kerncompat.h"
-#include "radix-tree.h"
+#include <linux/module.h>
+#include <linux/fs.h>
 #include "ctree.h"
 #include "disk-io.h"
 #include "transaction.h"
 
-static int allocated_blocks = 0;
-int cache_max = 10000;
-
-static int check_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
+static int check_tree_block(struct btrfs_root *root, struct buffer_head *buf)
 {
-	if (buf->blocknr != btrfs_header_blocknr(&buf->node.header))
+	struct btrfs_node *node = btrfs_buffer_node(buf);
+	if (buf->b_blocknr != btrfs_header_blocknr(&node->header))
 		BUG();
-	if (root->node && btrfs_header_parentid(&buf->node.header) !=
-	    btrfs_header_parentid(&root->node->node.header))
+	if (root->node && btrfs_header_parentid(&node->header) !=
+	    btrfs_header_parentid(btrfs_buffer_header(root->node)))
 		BUG();
 	return 0;
 }
 
-static int free_some_buffers(struct btrfs_root *root)
+struct buffer_head *alloc_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	struct list_head *node, *next;
-	struct btrfs_buffer *b;
-	if (root->fs_info->cache_size < cache_max)
-		return 0;
-	list_for_each_safe(node, next, &root->fs_info->cache) {
-		b = list_entry(node, struct btrfs_buffer, cache);
-		if (b->count == 1) {
-			BUG_ON(!list_empty(&b->dirty));
-			list_del_init(&b->cache);
-			btrfs_block_release(root, b);
-			if (root->fs_info->cache_size < cache_max)
-				break;
-		}
-	}
-	return 0;
+	return sb_getblk(root->fs_info->sb, blocknr);
 }
 
-struct btrfs_buffer *alloc_tree_block(struct btrfs_root *root, u64 blocknr)
+struct buffer_head *find_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	struct btrfs_buffer *buf;
-	int ret;
-
-	buf = malloc(sizeof(struct btrfs_buffer) + root->blocksize);
-	if (!buf)
-		return buf;
-	allocated_blocks++;
-	buf->blocknr = blocknr;
-	buf->count = 2;
-	INIT_LIST_HEAD(&buf->dirty);
-	free_some_buffers(root);
-	radix_tree_preload(GFP_KERNEL);
-	ret = radix_tree_insert(&root->fs_info->cache_radix, blocknr, buf);
-	radix_tree_preload_end();
-	list_add_tail(&buf->cache, &root->fs_info->cache);
-	root->fs_info->cache_size++;
-	if (ret) {
-		free(buf);
-		return NULL;
-	}
-	return buf;
+	return sb_getblk(root->fs_info->sb, blocknr);
 }
 
-struct btrfs_buffer *find_tree_block(struct btrfs_root *root, u64 blocknr)
+struct buffer_head *read_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	struct btrfs_buffer *buf;
-	buf = radix_tree_lookup(&root->fs_info->cache_radix, blocknr);
-	if (buf) {
-		buf->count++;
-	} else {
-		buf = alloc_tree_block(root, blocknr);
-		if (!buf) {
-			BUG();
-			return NULL;
-		}
-	}
-	return buf;
-}
-
-struct btrfs_buffer *read_tree_block(struct btrfs_root *root, u64 blocknr)
-{
-	loff_t offset = blocknr * root->blocksize;
-	struct btrfs_buffer *buf;
-	int ret;
+	struct buffer_head *buf = sb_bread(root->fs_info->sb, blocknr);
 
-	buf = radix_tree_lookup(&root->fs_info->cache_radix, blocknr);
-	if (buf) {
-		buf->count++;
-	} else {
-		buf = alloc_tree_block(root, blocknr);
-		if (!buf)
-			return NULL;
-		ret = pread(root->fs_info->fp, &buf->node, root->blocksize,
-			    offset);
-		if (ret != root->blocksize) {
-			free(buf);
-			return NULL;
-		}
-	}
+	if (!buf)
+		return buf;
 	if (check_tree_block(root, buf))
 		BUG();
 	return buf;
 }
 
 int dirty_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		     struct btrfs_buffer *buf)
+		     struct buffer_head *buf)
 {
-	if (!list_empty(&buf->dirty))
-		return 0;
-	list_add_tail(&buf->dirty, &root->fs_info->trans);
-	buf->count++;
+	mark_buffer_dirty(buf);
 	return 0;
 }
 
 int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		     struct btrfs_buffer *buf)
+		     struct buffer_head *buf)
 {
-	if (!list_empty(&buf->dirty)) {
-		list_del_init(&buf->dirty);
-		btrfs_block_release(root, buf);
-	}
+	clear_buffer_dirty(buf);
 	return 0;
 }
 
 int write_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
-		     struct btrfs_buffer *buf)
+		     struct buffer_head *buf)
 {
-	u64 blocknr = buf->blocknr;
-	loff_t offset = blocknr * root->blocksize;
-	int ret;
-
-	if (buf->blocknr != btrfs_header_blocknr(&buf->node.header))
-		BUG();
-	ret = pwrite(root->fs_info->fp, &buf->node, root->blocksize, offset);
-	if (ret != root->blocksize)
-		return ret;
+	mark_buffer_dirty(buf);
 	return 0;
 }
 
 static int __commit_transaction(struct btrfs_trans_handle *trans, struct
 				btrfs_root *root)
 {
-	struct btrfs_buffer *b;
-	int ret = 0;
-	int wret;
-	while(!list_empty(&root->fs_info->trans)) {
-		b = list_entry(root->fs_info->trans.next, struct btrfs_buffer,
-			       dirty);
-		list_del_init(&b->dirty);
-		wret = write_tree_block(trans, root, b);
-		if (wret)
-			ret = wret;
-		btrfs_block_release(root, b);
-	}
-	return ret;
+	filemap_write_and_wait(root->fs_info->sb->s_bdev->bd_inode->i_mapping);
+	return 0;
 }
 
 static int commit_tree_roots(struct btrfs_trans_handle *trans,
@@ -172,17 +74,17 @@ static int commit_tree_roots(struct btrfs_trans_handle *trans,
 	struct btrfs_root *inode_root = fs_info->inode_root;
 
 	btrfs_set_root_blocknr(&inode_root->root_item,
-			       inode_root->node->blocknr);
+			       inode_root->node->b_blocknr);
 	ret = btrfs_update_root(trans, tree_root,
 				&inode_root->root_key,
 				&inode_root->root_item);
 	BUG_ON(ret);
 	while(1) {
 		old_extent_block = btrfs_root_blocknr(&extent_root->root_item);
-		if (old_extent_block == extent_root->node->blocknr)
+		if (old_extent_block == extent_root->node->b_blocknr)
 			break;
 		btrfs_set_root_blocknr(&extent_root->root_item,
-				       extent_root->node->blocknr);
+				       extent_root->node->b_blocknr);
 		ret = btrfs_update_root(trans, tree_root,
 					&extent_root->root_key,
 					&extent_root->root_item);
@@ -195,7 +97,7 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans, struct
 			     btrfs_root *root, struct btrfs_super_block *s)
 {
 	int ret = 0;
-	struct btrfs_buffer *snap = root->commit_root;
+	struct buffer_head *snap = root->commit_root;
 	struct btrfs_key snap_key;
 
 	if (root->commit_root == root->node)
@@ -204,7 +106,7 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans, struct
 	memcpy(&snap_key, &root->root_key, sizeof(snap_key));
 	root->root_key.offset++;
 
-	btrfs_set_root_blocknr(&root->root_item, root->node->blocknr);
+	btrfs_set_root_blocknr(&root->root_item, root->node->b_blocknr);
 	ret = btrfs_insert_root(trans, root->fs_info->tree_root,
 				&root->root_key, &root->root_item);
 	BUG_ON(ret);
@@ -220,7 +122,7 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans, struct
 	btrfs_finish_extent_commit(trans, root->fs_info->tree_root);
 
 	root->commit_root = root->node;
-	root->node->count++;
+	get_bh(root->node);
 	ret = btrfs_drop_snapshot(trans, root, snap);
 	BUG_ON(ret);
 
@@ -234,7 +136,7 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans, struct
 static int __setup_root(struct btrfs_super_block *super,
 			struct btrfs_root *root,
 			struct btrfs_fs_info *fs_info,
-			u64 objectid, int fp)
+			u64 objectid)
 {
 	root->node = NULL;
 	root->commit_root = NULL;
@@ -250,11 +152,11 @@ static int find_and_setup_root(struct btrfs_super_block *super,
 			       struct btrfs_root *tree_root,
 			       struct btrfs_fs_info *fs_info,
 			       u64 objectid,
-			       struct btrfs_root *root, int fp)
+			       struct btrfs_root *root)
 {
 	int ret;
 
-	__setup_root(super, root, fs_info, objectid, fp);
+	__setup_root(super, root, fs_info, objectid);
 	ret = btrfs_find_last_root(tree_root, objectid,
 				   &root->root_item, &root->root_key);
 	BUG_ON(ret);
@@ -265,32 +167,26 @@ static int find_and_setup_root(struct btrfs_super_block *super,
 	return 0;
 }
 
-struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
+struct btrfs_root *open_ctree(struct super_block *sb,
+			      struct buffer_head *sb_buffer,
+			      struct btrfs_super_block *disk_super)
 {
-	int fp;
-
-	fp = open(filename, O_CREAT | O_RDWR, 0600);
-	if (fp < 0) {
-		return NULL;
-	}
-	return open_ctree_fd(fp, super);
-}
-
-struct btrfs_root *open_ctree_fd(int fp, struct btrfs_super_block *super)
-{
-	struct btrfs_root *root = malloc(sizeof(struct btrfs_root));
-	struct btrfs_root *extent_root = malloc(sizeof(struct btrfs_root));
-	struct btrfs_root *tree_root = malloc(sizeof(struct btrfs_root));
-	struct btrfs_root *inode_root = malloc(sizeof(struct btrfs_root));
-	struct btrfs_fs_info *fs_info = malloc(sizeof(*fs_info));
+	struct btrfs_root *root = kmalloc(sizeof(struct btrfs_root),
+					  GFP_NOFS);
+	struct btrfs_root *extent_root = kmalloc(sizeof(struct btrfs_root),
+						 GFP_NOFS);
+	struct btrfs_root *tree_root = kmalloc(sizeof(struct btrfs_root),
+					       GFP_NOFS);
+	struct btrfs_root *inode_root = kmalloc(sizeof(struct btrfs_root),
+						GFP_NOFS);
+	struct btrfs_fs_info *fs_info = kmalloc(sizeof(*fs_info),
+						GFP_NOFS);
 	int ret;
 
-	INIT_RADIX_TREE(&fs_info->cache_radix, GFP_KERNEL);
+	/* FIXME: don't be stupid */
+	if (!btrfs_super_root(disk_super))
+		return NULL;
 	INIT_RADIX_TREE(&fs_info->pinned_radix, GFP_KERNEL);
-	INIT_LIST_HEAD(&fs_info->trans);
-	INIT_LIST_HEAD(&fs_info->cache);
-	fs_info->cache_size = 0;
-	fs_info->fp = fp;
 	fs_info->running_transaction = NULL;
 	fs_info->fs_root = root;
 	fs_info->tree_root = tree_root;
@@ -298,36 +194,31 @@ struct btrfs_root *open_ctree_fd(int fp, struct btrfs_super_block *super)
 	fs_info->inode_root = inode_root;
 	fs_info->last_inode_alloc = 0;
 	fs_info->last_inode_alloc_dirid = 0;
-	fs_info->disk_super = super;
+	fs_info->disk_super = disk_super;
+	fs_info->sb_buffer = sb_buffer;
+	fs_info->sb = sb;
 	memset(&fs_info->current_insert, 0, sizeof(fs_info->current_insert));
 	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
 
-	ret = pread(fp, super, sizeof(struct btrfs_super_block),
-		     BTRFS_SUPER_INFO_OFFSET);
-	if (ret == 0 || btrfs_super_root(super) == 0) {
-		BUG();
-		return NULL;
-	}
-	BUG_ON(ret < 0);
-
-	__setup_root(super, tree_root, fs_info, BTRFS_ROOT_TREE_OBJECTID, fp);
-	tree_root->node = read_tree_block(tree_root, btrfs_super_root(super));
+	__setup_root(disk_super, tree_root, fs_info, BTRFS_ROOT_TREE_OBJECTID);
+	tree_root->node = read_tree_block(tree_root,
+					  btrfs_super_root(disk_super));
 	BUG_ON(!tree_root->node);
 
-	ret = find_and_setup_root(super, tree_root, fs_info,
-				  BTRFS_EXTENT_TREE_OBJECTID, extent_root, fp);
+	ret = find_and_setup_root(disk_super, tree_root, fs_info,
+				  BTRFS_EXTENT_TREE_OBJECTID, extent_root);
 	BUG_ON(ret);
 
-	ret = find_and_setup_root(super, tree_root, fs_info,
-				  BTRFS_INODE_MAP_OBJECTID, inode_root, fp);
+	ret = find_and_setup_root(disk_super, tree_root, fs_info,
+				  BTRFS_INODE_MAP_OBJECTID, inode_root);
 	BUG_ON(ret);
 
-	ret = find_and_setup_root(super, tree_root, fs_info,
-				  BTRFS_FS_TREE_OBJECTID, root, fp);
+	ret = find_and_setup_root(disk_super, tree_root, fs_info,
+				  BTRFS_FS_TREE_OBJECTID, root);
 	BUG_ON(ret);
 
 	root->commit_root = root->node;
-	root->node->count++;
+	get_bh(root->node);
 	root->ref_cows = 1;
 	root->fs_info->generation = root->root_key.offset + 1;
 	return root;
@@ -336,8 +227,11 @@ struct btrfs_root *open_ctree_fd(int fp, struct btrfs_super_block *super)
 int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_super_block *s)
 {
+	return 0;
+#if 0
 	int ret;
-	btrfs_set_super_root(s, root->fs_info->tree_root->node->blocknr);
+	btrfs_set_super_root(s, root->fs_info->tree_root->node->b_blocknr);
+
 	ret = pwrite(root->fs_info->fp, s, sizeof(*s),
 		     BTRFS_SUPER_INFO_OFFSET);
 	if (ret != sizeof(*s)) {
@@ -345,35 +239,38 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 		return ret;
 	}
 	return 0;
+#endif
 }
 
 static int drop_cache(struct btrfs_root *root)
 {
+	return 0;
+#if 0
 	while(!list_empty(&root->fs_info->cache)) {
-		struct btrfs_buffer *b = list_entry(root->fs_info->cache.next,
-						    struct btrfs_buffer,
+		struct buffer_head *b = list_entry(root->fs_info->cache.next,
+						    struct buffer_head,
 						    cache);
 		list_del_init(&b->cache);
 		btrfs_block_release(root, b);
 	}
 	return 0;
+#endif
 }
-int close_ctree(struct btrfs_root *root, struct btrfs_super_block *s)
+
+int close_ctree(struct btrfs_root *root)
 {
 	int ret;
 	struct btrfs_trans_handle *trans;
 
 	trans = root->fs_info->running_transaction;
-	btrfs_commit_transaction(trans, root, s);
+	btrfs_commit_transaction(trans, root, root->fs_info->disk_super);
 	ret = commit_tree_roots(trans, root->fs_info);
 	BUG_ON(ret);
 	ret = __commit_transaction(trans, root);
 	BUG_ON(ret);
-	write_ctree_super(trans, root, s);
+	write_ctree_super(trans, root, root->fs_info->disk_super);
 	drop_cache(root);
-	BUG_ON(!list_empty(&root->fs_info->trans));
 
-	close(root->fs_info->fp);
 	if (root->node)
 		btrfs_block_release(root, root->node);
 	if (root->fs_info->extent_root->node)
@@ -386,29 +283,17 @@ int close_ctree(struct btrfs_root *root, struct btrfs_super_block *s)
 		btrfs_block_release(root->fs_info->tree_root,
 				    root->fs_info->tree_root->node);
 	btrfs_block_release(root, root->commit_root);
-	free(root);
-	printf("on close %d blocks are allocated\n", allocated_blocks);
+	btrfs_block_release(root, root->fs_info->sb_buffer);
+	kfree(root->fs_info->extent_root);
+	kfree(root->fs_info->inode_root);
+	kfree(root->fs_info->tree_root);
+	kfree(root->fs_info);
+	kfree(root);
 	return 0;
 }
 
-void btrfs_block_release(struct btrfs_root *root, struct btrfs_buffer *buf)
+void btrfs_block_release(struct btrfs_root *root, struct buffer_head *buf)
 {
-	buf->count--;
-	if (buf->count < 0)
-		BUG();
-	if (buf->count == 0) {
-		BUG_ON(!list_empty(&buf->cache));
-		BUG_ON(!list_empty(&buf->dirty));
-		if (!radix_tree_lookup(&root->fs_info->cache_radix,
-				       buf->blocknr))
-			BUG();
-		radix_tree_delete(&root->fs_info->cache_radix, buf->blocknr);
-		memset(buf, 0, sizeof(*buf));
-		free(buf);
-		BUG_ON(allocated_blocks == 0);
-		allocated_blocks--;
-		BUG_ON(root->fs_info->cache_size == 0);
-		root->fs_info->cache_size--;
-	}
+	brelse(buf);
 }
 

commit 2e635a278354a1a7951e16cfea4c247d6d0e7c99
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 21 11:12:56 2007 -0400

    Btrfs: initial move to kernel module land
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0322c55162cb..05637f9fd7c7 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -266,20 +266,25 @@ static int find_and_setup_root(struct btrfs_super_block *super,
 }
 
 struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
+{
+	int fp;
+
+	fp = open(filename, O_CREAT | O_RDWR, 0600);
+	if (fp < 0) {
+		return NULL;
+	}
+	return open_ctree_fd(fp, super);
+}
+
+struct btrfs_root *open_ctree_fd(int fp, struct btrfs_super_block *super)
 {
 	struct btrfs_root *root = malloc(sizeof(struct btrfs_root));
 	struct btrfs_root *extent_root = malloc(sizeof(struct btrfs_root));
 	struct btrfs_root *tree_root = malloc(sizeof(struct btrfs_root));
 	struct btrfs_root *inode_root = malloc(sizeof(struct btrfs_root));
 	struct btrfs_fs_info *fs_info = malloc(sizeof(*fs_info));
-	int fp;
 	int ret;
 
-	fp = open(filename, O_CREAT | O_RDWR, 0600);
-	if (fp < 0) {
-		free(root);
-		return NULL;
-	}
 	INIT_RADIX_TREE(&fs_info->cache_radix, GFP_KERNEL);
 	INIT_RADIX_TREE(&fs_info->pinned_radix, GFP_KERNEL);
 	INIT_LIST_HEAD(&fs_info->trans);

commit 1261ec42b3d3a3ad878bd172144940e3ac710749
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 20 20:35:03 2007 -0400

    Btrfs: Better block record keeping, real mkfs
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index bacaa38ea82e..0322c55162cb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -293,20 +293,15 @@ struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 	fs_info->inode_root = inode_root;
 	fs_info->last_inode_alloc = 0;
 	fs_info->last_inode_alloc_dirid = 0;
+	fs_info->disk_super = super;
 	memset(&fs_info->current_insert, 0, sizeof(fs_info->current_insert));
 	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
 
 	ret = pread(fp, super, sizeof(struct btrfs_super_block),
 		     BTRFS_SUPER_INFO_OFFSET);
 	if (ret == 0 || btrfs_super_root(super) == 0) {
-		printf("making new FS!\n");
-		ret = mkfs(fp, 0, 1024);
-		if (ret)
-			return NULL;
-		ret = pread(fp, super, sizeof(struct btrfs_super_block),
-			     BTRFS_SUPER_INFO_OFFSET);
-		if (ret != sizeof(struct btrfs_super_block))
-			return NULL;
+		BUG();
+		return NULL;
 	}
 	BUG_ON(ret < 0);
 

commit 293ffd5fd340428276fbbd24ce7b98bf6728466b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 20 15:57:25 2007 -0400

    Btrfs: change dir-test to insert inode_items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 1849a99690c8..bacaa38ea82e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -226,6 +226,7 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans, struct
 
 	ret = btrfs_del_root(trans, root->fs_info->tree_root, &snap_key);
 	BUG_ON(ret);
+	root->fs_info->generation = root->root_key.offset + 1;
 
 	return ret;
 }
@@ -328,6 +329,7 @@ struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 	root->commit_root = root->node;
 	root->node->count++;
 	root->ref_cows = 1;
+	root->fs_info->generation = root->root_key.offset + 1;
 	return root;
 }
 

commit 9f5fae2fe6dc35b46bf56183f11398451851cb3f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 20 14:38:32 2007 -0400

    Btrfs: Add inode map, and the start of file extent items
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 25ce07908ee3..1849a99690c8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -28,15 +28,15 @@ static int free_some_buffers(struct btrfs_root *root)
 {
 	struct list_head *node, *next;
 	struct btrfs_buffer *b;
-	if (root->cache_size < cache_max)
+	if (root->fs_info->cache_size < cache_max)
 		return 0;
-	list_for_each_safe(node, next, &root->cache) {
+	list_for_each_safe(node, next, &root->fs_info->cache) {
 		b = list_entry(node, struct btrfs_buffer, cache);
 		if (b->count == 1) {
 			BUG_ON(!list_empty(&b->dirty));
 			list_del_init(&b->cache);
 			btrfs_block_release(root, b);
-			if (root->cache_size < cache_max)
+			if (root->fs_info->cache_size < cache_max)
 				break;
 		}
 	}
@@ -57,10 +57,10 @@ struct btrfs_buffer *alloc_tree_block(struct btrfs_root *root, u64 blocknr)
 	INIT_LIST_HEAD(&buf->dirty);
 	free_some_buffers(root);
 	radix_tree_preload(GFP_KERNEL);
-	ret = radix_tree_insert(&root->cache_radix, blocknr, buf);
+	ret = radix_tree_insert(&root->fs_info->cache_radix, blocknr, buf);
 	radix_tree_preload_end();
-	list_add_tail(&buf->cache, &root->cache);
-	root->cache_size++;
+	list_add_tail(&buf->cache, &root->fs_info->cache);
+	root->fs_info->cache_size++;
 	if (ret) {
 		free(buf);
 		return NULL;
@@ -71,7 +71,7 @@ struct btrfs_buffer *alloc_tree_block(struct btrfs_root *root, u64 blocknr)
 struct btrfs_buffer *find_tree_block(struct btrfs_root *root, u64 blocknr)
 {
 	struct btrfs_buffer *buf;
-	buf = radix_tree_lookup(&root->cache_radix, blocknr);
+	buf = radix_tree_lookup(&root->fs_info->cache_radix, blocknr);
 	if (buf) {
 		buf->count++;
 	} else {
@@ -90,14 +90,15 @@ struct btrfs_buffer *read_tree_block(struct btrfs_root *root, u64 blocknr)
 	struct btrfs_buffer *buf;
 	int ret;
 
-	buf = radix_tree_lookup(&root->cache_radix, blocknr);
+	buf = radix_tree_lookup(&root->fs_info->cache_radix, blocknr);
 	if (buf) {
 		buf->count++;
 	} else {
 		buf = alloc_tree_block(root, blocknr);
 		if (!buf)
 			return NULL;
-		ret = pread(root->fp, &buf->node, root->blocksize, offset);
+		ret = pread(root->fs_info->fp, &buf->node, root->blocksize,
+			    offset);
 		if (ret != root->blocksize) {
 			free(buf);
 			return NULL;
@@ -113,7 +114,7 @@ int dirty_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 {
 	if (!list_empty(&buf->dirty))
 		return 0;
-	list_add_tail(&buf->dirty, &root->trans);
+	list_add_tail(&buf->dirty, &root->fs_info->trans);
 	buf->count++;
 	return 0;
 }
@@ -137,7 +138,7 @@ int write_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
 
 	if (buf->blocknr != btrfs_header_blocknr(&buf->node.header))
 		BUG();
-	ret = pwrite(root->fp, &buf->node, root->blocksize, offset);
+	ret = pwrite(root->fs_info->fp, &buf->node, root->blocksize, offset);
 	if (ret != root->blocksize)
 		return ret;
 	return 0;
@@ -149,8 +150,9 @@ static int __commit_transaction(struct btrfs_trans_handle *trans, struct
 	struct btrfs_buffer *b;
 	int ret = 0;
 	int wret;
-	while(!list_empty(&root->trans)) {
-		b = list_entry(root->trans.next, struct btrfs_buffer, dirty);
+	while(!list_empty(&root->fs_info->trans)) {
+		b = list_entry(root->fs_info->trans.next, struct btrfs_buffer,
+			       dirty);
 		list_del_init(&b->dirty);
 		wret = write_tree_block(trans, root, b);
 		if (wret)
@@ -160,13 +162,21 @@ static int __commit_transaction(struct btrfs_trans_handle *trans, struct
 	return ret;
 }
 
-static int commit_extent_and_tree_roots(struct btrfs_trans_handle *trans,
-					struct btrfs_root *tree_root, struct
-					btrfs_root *extent_root)
+static int commit_tree_roots(struct btrfs_trans_handle *trans,
+			     struct btrfs_fs_info *fs_info)
 {
 	int ret;
 	u64 old_extent_block;
-
+	struct btrfs_root *tree_root = fs_info->tree_root;
+	struct btrfs_root *extent_root = fs_info->extent_root;
+	struct btrfs_root *inode_root = fs_info->inode_root;
+
+	btrfs_set_root_blocknr(&inode_root->root_item,
+			       inode_root->node->blocknr);
+	ret = btrfs_update_root(trans, tree_root,
+				&inode_root->root_key,
+				&inode_root->root_item);
+	BUG_ON(ret);
 	while(1) {
 		old_extent_block = btrfs_root_blocknr(&extent_root->root_item);
 		if (old_extent_block == extent_root->node->blocknr)
@@ -178,8 +188,6 @@ static int commit_extent_and_tree_roots(struct btrfs_trans_handle *trans,
 					&extent_root->root_item);
 		BUG_ON(ret);
 	}
-	__commit_transaction(trans, extent_root);
-	__commit_transaction(trans, tree_root);
 	return 0;
 }
 
@@ -190,9 +198,6 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans, struct
 	struct btrfs_buffer *snap = root->commit_root;
 	struct btrfs_key snap_key;
 
-	ret = __commit_transaction(trans, root);
-	BUG_ON(ret);
-
 	if (root->commit_root == root->node)
 		return 0;
 
@@ -200,54 +205,55 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans, struct
 	root->root_key.offset++;
 
 	btrfs_set_root_blocknr(&root->root_item, root->node->blocknr);
-	ret = btrfs_insert_root(trans, root->tree_root, &root->root_key,
-				&root->root_item);
+	ret = btrfs_insert_root(trans, root->fs_info->tree_root,
+				&root->root_key, &root->root_item);
+	BUG_ON(ret);
+
+	ret = commit_tree_roots(trans, root->fs_info);
 	BUG_ON(ret);
 
-	ret = commit_extent_and_tree_roots(trans, root->tree_root,
-					   root->extent_root);
+	ret = __commit_transaction(trans, root);
 	BUG_ON(ret);
 
 	write_ctree_super(trans, root, s);
-	btrfs_finish_extent_commit(trans, root->extent_root);
-	btrfs_finish_extent_commit(trans, root->tree_root);
+	btrfs_finish_extent_commit(trans, root->fs_info->extent_root);
+	btrfs_finish_extent_commit(trans, root->fs_info->tree_root);
 
 	root->commit_root = root->node;
 	root->node->count++;
 	ret = btrfs_drop_snapshot(trans, root, snap);
 	BUG_ON(ret);
 
-	ret = btrfs_del_root(trans, root->tree_root, &snap_key);
+	ret = btrfs_del_root(trans, root->fs_info->tree_root, &snap_key);
 	BUG_ON(ret);
 
 	return ret;
 }
 
 static int __setup_root(struct btrfs_super_block *super,
-			struct btrfs_root *root, u64 objectid, int fp)
+			struct btrfs_root *root,
+			struct btrfs_fs_info *fs_info,
+			u64 objectid, int fp)
 {
-	INIT_LIST_HEAD(&root->trans);
-	INIT_LIST_HEAD(&root->cache);
-	root->cache_size = 0;
-	root->fp = fp;
 	root->node = NULL;
 	root->commit_root = NULL;
 	root->blocksize = btrfs_super_blocksize(super);
 	root->ref_cows = 0;
-	memset(&root->current_insert, 0, sizeof(root->current_insert));
-	memset(&root->last_insert, 0, sizeof(root->last_insert));
+	root->fs_info = fs_info;
 	memset(&root->root_key, 0, sizeof(root->root_key));
 	memset(&root->root_item, 0, sizeof(root->root_item));
 	return 0;
 }
 
 static int find_and_setup_root(struct btrfs_super_block *super,
-			       struct btrfs_root *tree_root, u64 objectid,
+			       struct btrfs_root *tree_root,
+			       struct btrfs_fs_info *fs_info,
+			       u64 objectid,
 			       struct btrfs_root *root, int fp)
 {
 	int ret;
 
-	__setup_root(super, root, objectid, fp);
+	__setup_root(super, root, fs_info, objectid, fp);
 	ret = btrfs_find_last_root(tree_root, objectid,
 				   &root->root_item, &root->root_key);
 	BUG_ON(ret);
@@ -263,29 +269,31 @@ struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 	struct btrfs_root *root = malloc(sizeof(struct btrfs_root));
 	struct btrfs_root *extent_root = malloc(sizeof(struct btrfs_root));
 	struct btrfs_root *tree_root = malloc(sizeof(struct btrfs_root));
+	struct btrfs_root *inode_root = malloc(sizeof(struct btrfs_root));
+	struct btrfs_fs_info *fs_info = malloc(sizeof(*fs_info));
 	int fp;
 	int ret;
 
-	root->extent_root = extent_root;
-	root->tree_root = tree_root;
-
-	extent_root->extent_root = extent_root;
-	extent_root->tree_root = tree_root;
-
-	tree_root->extent_root = extent_root;
-	tree_root->tree_root = tree_root;
-
 	fp = open(filename, O_CREAT | O_RDWR, 0600);
 	if (fp < 0) {
 		free(root);
 		return NULL;
 	}
-	INIT_RADIX_TREE(&root->cache_radix, GFP_KERNEL);
-	INIT_RADIX_TREE(&root->pinned_radix, GFP_KERNEL);
-	INIT_RADIX_TREE(&extent_root->pinned_radix, GFP_KERNEL);
-	INIT_RADIX_TREE(&extent_root->cache_radix, GFP_KERNEL);
-	INIT_RADIX_TREE(&tree_root->pinned_radix, GFP_KERNEL);
-	INIT_RADIX_TREE(&tree_root->cache_radix, GFP_KERNEL);
+	INIT_RADIX_TREE(&fs_info->cache_radix, GFP_KERNEL);
+	INIT_RADIX_TREE(&fs_info->pinned_radix, GFP_KERNEL);
+	INIT_LIST_HEAD(&fs_info->trans);
+	INIT_LIST_HEAD(&fs_info->cache);
+	fs_info->cache_size = 0;
+	fs_info->fp = fp;
+	fs_info->running_transaction = NULL;
+	fs_info->fs_root = root;
+	fs_info->tree_root = tree_root;
+	fs_info->extent_root = extent_root;
+	fs_info->inode_root = inode_root;
+	fs_info->last_inode_alloc = 0;
+	fs_info->last_inode_alloc_dirid = 0;
+	memset(&fs_info->current_insert, 0, sizeof(fs_info->current_insert));
+	memset(&fs_info->last_insert, 0, sizeof(fs_info->last_insert));
 
 	ret = pread(fp, super, sizeof(struct btrfs_super_block),
 		     BTRFS_SUPER_INFO_OFFSET);
@@ -301,16 +309,20 @@ struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 	}
 	BUG_ON(ret < 0);
 
-	__setup_root(super, tree_root, BTRFS_ROOT_TREE_OBJECTID, fp);
+	__setup_root(super, tree_root, fs_info, BTRFS_ROOT_TREE_OBJECTID, fp);
 	tree_root->node = read_tree_block(tree_root, btrfs_super_root(super));
 	BUG_ON(!tree_root->node);
 
-	ret = find_and_setup_root(super, tree_root, BTRFS_EXTENT_TREE_OBJECTID,
-				  extent_root, fp);
+	ret = find_and_setup_root(super, tree_root, fs_info,
+				  BTRFS_EXTENT_TREE_OBJECTID, extent_root, fp);
 	BUG_ON(ret);
 
-	ret = find_and_setup_root(super, tree_root, BTRFS_FS_TREE_OBJECTID,
-				  root, fp);
+	ret = find_and_setup_root(super, tree_root, fs_info,
+				  BTRFS_INODE_MAP_OBJECTID, inode_root, fp);
+	BUG_ON(ret);
+
+	ret = find_and_setup_root(super, tree_root, fs_info,
+				  BTRFS_FS_TREE_OBJECTID, root, fp);
 	BUG_ON(ret);
 
 	root->commit_root = root->node;
@@ -323,8 +335,8 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 		      *root, struct btrfs_super_block *s)
 {
 	int ret;
-	btrfs_set_super_root(s, root->tree_root->node->blocknr);
-	ret = pwrite(root->fp, s, sizeof(*s),
+	btrfs_set_super_root(s, root->fs_info->tree_root->node->blocknr);
+	ret = pwrite(root->fs_info->fp, s, sizeof(*s),
 		     BTRFS_SUPER_INFO_OFFSET);
 	if (ret != sizeof(*s)) {
 		fprintf(stderr, "failed to write new super block err %d\n", ret);
@@ -335,9 +347,10 @@ int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
 
 static int drop_cache(struct btrfs_root *root)
 {
-	while(!list_empty(&root->cache)) {
-		struct btrfs_buffer *b = list_entry(root->cache.next,
-						   struct btrfs_buffer, cache);
+	while(!list_empty(&root->fs_info->cache)) {
+		struct btrfs_buffer *b = list_entry(root->fs_info->cache.next,
+						    struct btrfs_buffer,
+						    cache);
 		list_del_init(&b->cache);
 		btrfs_block_release(root, b);
 	}
@@ -348,26 +361,28 @@ int close_ctree(struct btrfs_root *root, struct btrfs_super_block *s)
 	int ret;
 	struct btrfs_trans_handle *trans;
 
-	trans = root->running_transaction;
+	trans = root->fs_info->running_transaction;
 	btrfs_commit_transaction(trans, root, s);
-	ret = commit_extent_and_tree_roots(trans, root->tree_root,
-					   root->extent_root);
+	ret = commit_tree_roots(trans, root->fs_info);
+	BUG_ON(ret);
+	ret = __commit_transaction(trans, root);
 	BUG_ON(ret);
 	write_ctree_super(trans, root, s);
-	drop_cache(root->extent_root);
-	drop_cache(root->tree_root);
 	drop_cache(root);
-	BUG_ON(!list_empty(&root->trans));
-	BUG_ON(!list_empty(&root->extent_root->trans));
-	BUG_ON(!list_empty(&root->tree_root->trans));
+	BUG_ON(!list_empty(&root->fs_info->trans));
 
-	close(root->fp);
+	close(root->fs_info->fp);
 	if (root->node)
 		btrfs_block_release(root, root->node);
-	if (root->extent_root->node)
-		btrfs_block_release(root->extent_root, root->extent_root->node);
-	if (root->tree_root->node)
-		btrfs_block_release(root->tree_root, root->tree_root->node);
+	if (root->fs_info->extent_root->node)
+		btrfs_block_release(root->fs_info->extent_root,
+				    root->fs_info->extent_root->node);
+	if (root->fs_info->inode_root->node)
+		btrfs_block_release(root->fs_info->inode_root,
+				    root->fs_info->inode_root->node);
+	if (root->fs_info->tree_root->node)
+		btrfs_block_release(root->fs_info->tree_root,
+				    root->fs_info->tree_root->node);
 	btrfs_block_release(root, root->commit_root);
 	free(root);
 	printf("on close %d blocks are allocated\n", allocated_blocks);
@@ -382,15 +397,16 @@ void btrfs_block_release(struct btrfs_root *root, struct btrfs_buffer *buf)
 	if (buf->count == 0) {
 		BUG_ON(!list_empty(&buf->cache));
 		BUG_ON(!list_empty(&buf->dirty));
-		if (!radix_tree_lookup(&root->cache_radix, buf->blocknr))
+		if (!radix_tree_lookup(&root->fs_info->cache_radix,
+				       buf->blocknr))
 			BUG();
-		radix_tree_delete(&root->cache_radix, buf->blocknr);
+		radix_tree_delete(&root->fs_info->cache_radix, buf->blocknr);
 		memset(buf, 0, sizeof(*buf));
 		free(buf);
 		BUG_ON(allocated_blocks == 0);
 		allocated_blocks--;
-		BUG_ON(root->cache_size == 0);
-		root->cache_size--;
+		BUG_ON(root->fs_info->cache_size == 0);
+		root->fs_info->cache_size--;
 	}
 }
 

commit e089f05c18ab36ed5fa7e2319052e03ab800d518
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 16 16:20:31 2007 -0400

    Btrfs: transaction handles everywhere
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8d9457b5aef5..25ce07908ee3 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -9,6 +9,7 @@
 #include "radix-tree.h"
 #include "ctree.h"
 #include "disk-io.h"
+#include "transaction.h"
 
 static int allocated_blocks = 0;
 int cache_max = 10000;
@@ -107,7 +108,8 @@ struct btrfs_buffer *read_tree_block(struct btrfs_root *root, u64 blocknr)
 	return buf;
 }
 
-int dirty_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
+int dirty_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		     struct btrfs_buffer *buf)
 {
 	if (!list_empty(&buf->dirty))
 		return 0;
@@ -116,7 +118,8 @@ int dirty_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
 	return 0;
 }
 
-int clean_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
+int clean_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		     struct btrfs_buffer *buf)
 {
 	if (!list_empty(&buf->dirty)) {
 		list_del_init(&buf->dirty);
@@ -125,7 +128,8 @@ int clean_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
 	return 0;
 }
 
-int write_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
+int write_tree_block(struct btrfs_trans_handle *trans, struct btrfs_root *root,
+		     struct btrfs_buffer *buf)
 {
 	u64 blocknr = buf->blocknr;
 	loff_t offset = blocknr * root->blocksize;
@@ -139,7 +143,8 @@ int write_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
 	return 0;
 }
 
-static int __commit_transaction(struct btrfs_root *root)
+static int __commit_transaction(struct btrfs_trans_handle *trans, struct
+				btrfs_root *root)
 {
 	struct btrfs_buffer *b;
 	int ret = 0;
@@ -147,7 +152,7 @@ static int __commit_transaction(struct btrfs_root *root)
 	while(!list_empty(&root->trans)) {
 		b = list_entry(root->trans.next, struct btrfs_buffer, dirty);
 		list_del_init(&b->dirty);
-		wret = write_tree_block(root, b);
+		wret = write_tree_block(trans, root, b);
 		if (wret)
 			ret = wret;
 		btrfs_block_release(root, b);
@@ -155,8 +160,9 @@ static int __commit_transaction(struct btrfs_root *root)
 	return ret;
 }
 
-static int commit_extent_and_tree_roots(struct btrfs_root *tree_root,
-					struct btrfs_root *extent_root)
+static int commit_extent_and_tree_roots(struct btrfs_trans_handle *trans,
+					struct btrfs_root *tree_root, struct
+					btrfs_root *extent_root)
 {
 	int ret;
 	u64 old_extent_block;
@@ -167,24 +173,24 @@ static int commit_extent_and_tree_roots(struct btrfs_root *tree_root,
 			break;
 		btrfs_set_root_blocknr(&extent_root->root_item,
 				       extent_root->node->blocknr);
-		ret = btrfs_update_root(tree_root,
+		ret = btrfs_update_root(trans, tree_root,
 					&extent_root->root_key,
 					&extent_root->root_item);
 		BUG_ON(ret);
 	}
-	__commit_transaction(extent_root);
-	__commit_transaction(tree_root);
+	__commit_transaction(trans, extent_root);
+	__commit_transaction(trans, tree_root);
 	return 0;
 }
 
-int btrfs_commit_transaction(struct btrfs_root *root,
-			     struct btrfs_super_block *s)
+int btrfs_commit_transaction(struct btrfs_trans_handle *trans, struct
+			     btrfs_root *root, struct btrfs_super_block *s)
 {
 	int ret = 0;
 	struct btrfs_buffer *snap = root->commit_root;
 	struct btrfs_key snap_key;
 
-	ret = __commit_transaction(root);
+	ret = __commit_transaction(trans, root);
 	BUG_ON(ret);
 
 	if (root->commit_root == root->node)
@@ -194,23 +200,24 @@ int btrfs_commit_transaction(struct btrfs_root *root,
 	root->root_key.offset++;
 
 	btrfs_set_root_blocknr(&root->root_item, root->node->blocknr);
-	ret = btrfs_insert_root(root->tree_root, &root->root_key,
+	ret = btrfs_insert_root(trans, root->tree_root, &root->root_key,
 				&root->root_item);
 	BUG_ON(ret);
 
-	ret = commit_extent_and_tree_roots(root->tree_root, root->extent_root);
+	ret = commit_extent_and_tree_roots(trans, root->tree_root,
+					   root->extent_root);
 	BUG_ON(ret);
 
-        write_ctree_super(root, s);
-	btrfs_finish_extent_commit(root->extent_root);
-	btrfs_finish_extent_commit(root->tree_root);
+	write_ctree_super(trans, root, s);
+	btrfs_finish_extent_commit(trans, root->extent_root);
+	btrfs_finish_extent_commit(trans, root->tree_root);
 
 	root->commit_root = root->node;
 	root->node->count++;
-	ret = btrfs_drop_snapshot(root, snap);
+	ret = btrfs_drop_snapshot(trans, root, snap);
 	BUG_ON(ret);
 
-	ret = btrfs_del_root(root->tree_root, &snap_key);
+	ret = btrfs_del_root(trans, root->tree_root, &snap_key);
 	BUG_ON(ret);
 
 	return ret;
@@ -312,7 +319,8 @@ struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 	return root;
 }
 
-int write_ctree_super(struct btrfs_root *root, struct btrfs_super_block *s)
+int write_ctree_super(struct btrfs_trans_handle *trans, struct btrfs_root
+		      *root, struct btrfs_super_block *s)
 {
 	int ret;
 	btrfs_set_super_root(s, root->tree_root->node->blocknr);
@@ -338,10 +346,14 @@ static int drop_cache(struct btrfs_root *root)
 int close_ctree(struct btrfs_root *root, struct btrfs_super_block *s)
 {
 	int ret;
-	btrfs_commit_transaction(root, s);
-	ret = commit_extent_and_tree_roots(root->tree_root, root->extent_root);
+	struct btrfs_trans_handle *trans;
+
+	trans = root->running_transaction;
+	btrfs_commit_transaction(trans, root, s);
+	ret = commit_extent_and_tree_roots(trans, root->tree_root,
+					   root->extent_root);
 	BUG_ON(ret);
-	write_ctree_super(root, s);
+	write_ctree_super(trans, root, s);
 	drop_cache(root->extent_root);
 	drop_cache(root->tree_root);
 	drop_cache(root);

commit 123abc88c9087b9c5605566ee3491aaef17fd837
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 14 14:14:43 2007 -0400

    Btrfs: variable block size support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 3d4bf6833f2a..8d9457b5aef5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -46,7 +46,8 @@ struct btrfs_buffer *alloc_tree_block(struct btrfs_root *root, u64 blocknr)
 {
 	struct btrfs_buffer *buf;
 	int ret;
-	buf = malloc(sizeof(struct btrfs_buffer));
+
+	buf = malloc(sizeof(struct btrfs_buffer) + root->blocksize);
 	if (!buf)
 		return buf;
 	allocated_blocks++;
@@ -84,7 +85,7 @@ struct btrfs_buffer *find_tree_block(struct btrfs_root *root, u64 blocknr)
 
 struct btrfs_buffer *read_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	loff_t offset = blocknr * BTRFS_BLOCKSIZE;
+	loff_t offset = blocknr * root->blocksize;
 	struct btrfs_buffer *buf;
 	int ret;
 
@@ -95,8 +96,8 @@ struct btrfs_buffer *read_tree_block(struct btrfs_root *root, u64 blocknr)
 		buf = alloc_tree_block(root, blocknr);
 		if (!buf)
 			return NULL;
-		ret = pread(root->fp, &buf->node, BTRFS_BLOCKSIZE, offset);
-		if (ret != BTRFS_BLOCKSIZE) {
+		ret = pread(root->fp, &buf->node, root->blocksize, offset);
+		if (ret != root->blocksize) {
 			free(buf);
 			return NULL;
 		}
@@ -127,13 +128,13 @@ int clean_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
 int write_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
 {
 	u64 blocknr = buf->blocknr;
-	loff_t offset = blocknr * BTRFS_BLOCKSIZE;
+	loff_t offset = blocknr * root->blocksize;
 	int ret;
 
 	if (buf->blocknr != btrfs_header_blocknr(&buf->node.header))
 		BUG();
-	ret = pwrite(root->fp, &buf->node, BTRFS_BLOCKSIZE, offset);
-	if (ret != BTRFS_BLOCKSIZE)
+	ret = pwrite(root->fp, &buf->node, root->blocksize, offset);
+	if (ret != root->blocksize)
 		return ret;
 	return 0;
 }
@@ -215,7 +216,8 @@ int btrfs_commit_transaction(struct btrfs_root *root,
 	return ret;
 }
 
-static int __setup_root(struct btrfs_root *root, u64 objectid, int fp)
+static int __setup_root(struct btrfs_super_block *super,
+			struct btrfs_root *root, u64 objectid, int fp)
 {
 	INIT_LIST_HEAD(&root->trans);
 	INIT_LIST_HEAD(&root->cache);
@@ -223,6 +225,8 @@ static int __setup_root(struct btrfs_root *root, u64 objectid, int fp)
 	root->fp = fp;
 	root->node = NULL;
 	root->commit_root = NULL;
+	root->blocksize = btrfs_super_blocksize(super);
+	root->ref_cows = 0;
 	memset(&root->current_insert, 0, sizeof(root->current_insert));
 	memset(&root->last_insert, 0, sizeof(root->last_insert));
 	memset(&root->root_key, 0, sizeof(root->root_key));
@@ -230,19 +234,19 @@ static int __setup_root(struct btrfs_root *root, u64 objectid, int fp)
 	return 0;
 }
 
-static int find_and_setup_root(struct btrfs_root *tree_root, u64 objectid,
-			struct btrfs_root *root, int fp)
+static int find_and_setup_root(struct btrfs_super_block *super,
+			       struct btrfs_root *tree_root, u64 objectid,
+			       struct btrfs_root *root, int fp)
 {
 	int ret;
 
-	__setup_root(root, objectid, fp);
+	__setup_root(super, root, objectid, fp);
 	ret = btrfs_find_last_root(tree_root, objectid,
 				   &root->root_item, &root->root_key);
 	BUG_ON(ret);
 
 	root->node = read_tree_block(root,
 				     btrfs_root_blocknr(&root->root_item));
-	root->ref_cows = 0;
 	BUG_ON(!root->node);
 	return 0;
 }
@@ -277,28 +281,28 @@ struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 	INIT_RADIX_TREE(&tree_root->cache_radix, GFP_KERNEL);
 
 	ret = pread(fp, super, sizeof(struct btrfs_super_block),
-		     BTRFS_SUPER_INFO_OFFSET(BTRFS_BLOCKSIZE));
+		     BTRFS_SUPER_INFO_OFFSET);
 	if (ret == 0 || btrfs_super_root(super) == 0) {
 		printf("making new FS!\n");
-		ret = mkfs(fp, 0, BTRFS_BLOCKSIZE);
+		ret = mkfs(fp, 0, 1024);
 		if (ret)
 			return NULL;
 		ret = pread(fp, super, sizeof(struct btrfs_super_block),
-			     BTRFS_SUPER_INFO_OFFSET(BTRFS_BLOCKSIZE));
+			     BTRFS_SUPER_INFO_OFFSET);
 		if (ret != sizeof(struct btrfs_super_block))
 			return NULL;
 	}
 	BUG_ON(ret < 0);
 
-	__setup_root(tree_root, BTRFS_ROOT_TREE_OBJECTID, fp);
+	__setup_root(super, tree_root, BTRFS_ROOT_TREE_OBJECTID, fp);
 	tree_root->node = read_tree_block(tree_root, btrfs_super_root(super));
 	BUG_ON(!tree_root->node);
 
-	ret = find_and_setup_root(tree_root, BTRFS_EXTENT_TREE_OBJECTID,
+	ret = find_and_setup_root(super, tree_root, BTRFS_EXTENT_TREE_OBJECTID,
 				  extent_root, fp);
 	BUG_ON(ret);
 
-	ret = find_and_setup_root(tree_root, BTRFS_FS_TREE_OBJECTID,
+	ret = find_and_setup_root(super, tree_root, BTRFS_FS_TREE_OBJECTID,
 				  root, fp);
 	BUG_ON(ret);
 
@@ -313,7 +317,7 @@ int write_ctree_super(struct btrfs_root *root, struct btrfs_super_block *s)
 	int ret;
 	btrfs_set_super_root(s, root->tree_root->node->blocknr);
 	ret = pwrite(root->fp, s, sizeof(*s),
-		     BTRFS_SUPER_INFO_OFFSET(BTRFS_BLOCKSIZE));
+		     BTRFS_SUPER_INFO_OFFSET);
 	if (ret != sizeof(*s)) {
 		fprintf(stderr, "failed to write new super block err %d\n", ret);
 		return ret;

commit 3768f3689fc76ecea17414936dff7a02746a4355
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 13 16:47:54 2007 -0400

    Btrfs: Change the super to point to a tree of trees to enable persistent snapshots
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c34c0c60935f..3d4bf6833f2a 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -154,41 +154,96 @@ static int __commit_transaction(struct btrfs_root *root)
 	return ret;
 }
 
+static int commit_extent_and_tree_roots(struct btrfs_root *tree_root,
+					struct btrfs_root *extent_root)
+{
+	int ret;
+	u64 old_extent_block;
+
+	while(1) {
+		old_extent_block = btrfs_root_blocknr(&extent_root->root_item);
+		if (old_extent_block == extent_root->node->blocknr)
+			break;
+		btrfs_set_root_blocknr(&extent_root->root_item,
+				       extent_root->node->blocknr);
+		ret = btrfs_update_root(tree_root,
+					&extent_root->root_key,
+					&extent_root->root_item);
+		BUG_ON(ret);
+	}
+	__commit_transaction(extent_root);
+	__commit_transaction(tree_root);
+	return 0;
+}
+
 int btrfs_commit_transaction(struct btrfs_root *root,
 			     struct btrfs_super_block *s)
 {
 	int ret = 0;
+	struct btrfs_buffer *snap = root->commit_root;
+	struct btrfs_key snap_key;
 
 	ret = __commit_transaction(root);
-	if (!ret && root != root->extent_root)
-		ret = __commit_transaction(root->extent_root);
 	BUG_ON(ret);
-	if (root->commit_root != root->node) {
-		struct btrfs_buffer *snap = root->commit_root;
-		root->commit_root = root->node;
-		root->node->count++;
-		ret = btrfs_drop_snapshot(root, snap);
-		BUG_ON(ret);
-		// btrfs_block_release(root, snap);
-	}
+
+	if (root->commit_root == root->node)
+		return 0;
+
+	memcpy(&snap_key, &root->root_key, sizeof(snap_key));
+	root->root_key.offset++;
+
+	btrfs_set_root_blocknr(&root->root_item, root->node->blocknr);
+	ret = btrfs_insert_root(root->tree_root, &root->root_key,
+				&root->root_item);
+	BUG_ON(ret);
+
+	ret = commit_extent_and_tree_roots(root->tree_root, root->extent_root);
+	BUG_ON(ret);
+
         write_ctree_super(root, s);
-	btrfs_finish_extent_commit(root);
+	btrfs_finish_extent_commit(root->extent_root);
+	btrfs_finish_extent_commit(root->tree_root);
+
+	root->commit_root = root->node;
+	root->node->count++;
+	ret = btrfs_drop_snapshot(root, snap);
+	BUG_ON(ret);
+
+	ret = btrfs_del_root(root->tree_root, &snap_key);
+	BUG_ON(ret);
+
 	return ret;
 }
 
-static int __setup_root(struct btrfs_root *root, struct btrfs_root *extent_root,
-			struct btrfs_root_info *info, int fp)
+static int __setup_root(struct btrfs_root *root, u64 objectid, int fp)
 {
 	INIT_LIST_HEAD(&root->trans);
 	INIT_LIST_HEAD(&root->cache);
 	root->cache_size = 0;
 	root->fp = fp;
 	root->node = NULL;
-	root->extent_root = extent_root;
 	root->commit_root = NULL;
-	root->node = read_tree_block(root, info->tree_root);
 	memset(&root->current_insert, 0, sizeof(root->current_insert));
 	memset(&root->last_insert, 0, sizeof(root->last_insert));
+	memset(&root->root_key, 0, sizeof(root->root_key));
+	memset(&root->root_item, 0, sizeof(root->root_item));
+	return 0;
+}
+
+static int find_and_setup_root(struct btrfs_root *tree_root, u64 objectid,
+			struct btrfs_root *root, int fp)
+{
+	int ret;
+
+	__setup_root(root, objectid, fp);
+	ret = btrfs_find_last_root(tree_root, objectid,
+				   &root->root_item, &root->root_key);
+	BUG_ON(ret);
+
+	root->node = read_tree_block(root,
+				     btrfs_root_blocknr(&root->root_item));
+	root->ref_cows = 0;
+	BUG_ON(!root->node);
 	return 0;
 }
 
@@ -196,9 +251,19 @@ struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 {
 	struct btrfs_root *root = malloc(sizeof(struct btrfs_root));
 	struct btrfs_root *extent_root = malloc(sizeof(struct btrfs_root));
+	struct btrfs_root *tree_root = malloc(sizeof(struct btrfs_root));
 	int fp;
 	int ret;
 
+	root->extent_root = extent_root;
+	root->tree_root = tree_root;
+
+	extent_root->extent_root = extent_root;
+	extent_root->tree_root = tree_root;
+
+	tree_root->extent_root = extent_root;
+	tree_root->tree_root = tree_root;
+
 	fp = open(filename, O_CREAT | O_RDWR, 0600);
 	if (fp < 0) {
 		free(root);
@@ -208,11 +273,14 @@ struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 	INIT_RADIX_TREE(&root->pinned_radix, GFP_KERNEL);
 	INIT_RADIX_TREE(&extent_root->pinned_radix, GFP_KERNEL);
 	INIT_RADIX_TREE(&extent_root->cache_radix, GFP_KERNEL);
+	INIT_RADIX_TREE(&tree_root->pinned_radix, GFP_KERNEL);
+	INIT_RADIX_TREE(&tree_root->cache_radix, GFP_KERNEL);
+
 	ret = pread(fp, super, sizeof(struct btrfs_super_block),
 		     BTRFS_SUPER_INFO_OFFSET(BTRFS_BLOCKSIZE));
-	if (ret == 0 || super->root_info.tree_root == 0) {
+	if (ret == 0 || btrfs_super_root(super) == 0) {
 		printf("making new FS!\n");
-		ret = mkfs(fp);
+		ret = mkfs(fp, 0, BTRFS_BLOCKSIZE);
 		if (ret)
 			return NULL;
 		ret = pread(fp, super, sizeof(struct btrfs_super_block),
@@ -221,24 +289,29 @@ struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 			return NULL;
 	}
 	BUG_ON(ret < 0);
-	__setup_root(root, extent_root, &super->root_info, fp);
-	__setup_root(extent_root, extent_root, &super->extent_info, fp);
+
+	__setup_root(tree_root, BTRFS_ROOT_TREE_OBJECTID, fp);
+	tree_root->node = read_tree_block(tree_root, btrfs_super_root(super));
+	BUG_ON(!tree_root->node);
+
+	ret = find_and_setup_root(tree_root, BTRFS_EXTENT_TREE_OBJECTID,
+				  extent_root, fp);
+	BUG_ON(ret);
+
+	ret = find_and_setup_root(tree_root, BTRFS_FS_TREE_OBJECTID,
+				  root, fp);
+	BUG_ON(ret);
+
 	root->commit_root = root->node;
 	root->node->count++;
+	root->ref_cows = 1;
 	return root;
 }
 
-static int __update_root(struct btrfs_root *root, struct btrfs_root_info *info)
-{
-	info->tree_root = root->node->blocknr;
-	return 0;
-}
-
 int write_ctree_super(struct btrfs_root *root, struct btrfs_super_block *s)
 {
 	int ret;
-	__update_root(root, &s->root_info);
-	__update_root(root->extent_root, &s->extent_info);
+	btrfs_set_super_root(s, root->tree_root->node->blocknr);
 	ret = pwrite(root->fp, s, sizeof(*s),
 		     BTRFS_SUPER_INFO_OFFSET(BTRFS_BLOCKSIZE));
 	if (ret != sizeof(*s)) {
@@ -260,19 +333,25 @@ static int drop_cache(struct btrfs_root *root)
 }
 int close_ctree(struct btrfs_root *root, struct btrfs_super_block *s)
 {
+	int ret;
 	btrfs_commit_transaction(root, s);
-	__commit_transaction(root->extent_root);
+	ret = commit_extent_and_tree_roots(root->tree_root, root->extent_root);
+	BUG_ON(ret);
 	write_ctree_super(root, s);
 	drop_cache(root->extent_root);
+	drop_cache(root->tree_root);
 	drop_cache(root);
 	BUG_ON(!list_empty(&root->trans));
 	BUG_ON(!list_empty(&root->extent_root->trans));
+	BUG_ON(!list_empty(&root->tree_root->trans));
 
 	close(root->fp);
 	if (root->node)
 		btrfs_block_release(root, root->node);
 	if (root->extent_root->node)
 		btrfs_block_release(root->extent_root, root->extent_root->node);
+	if (root->tree_root->node)
+		btrfs_block_release(root->tree_root, root->tree_root->node);
 	btrfs_block_release(root, root->commit_root);
 	free(root);
 	printf("on close %d blocks are allocated\n", allocated_blocks);

commit 234b63a091e1df6bd4261dd7b3a7490074830628
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 13 10:46:10 2007 -0400

    rename funcs and structs to btrfs
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 065e888d2c0b..c34c0c60935f 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -13,7 +13,7 @@
 static int allocated_blocks = 0;
 int cache_max = 10000;
 
-static int check_tree_block(struct ctree_root *root, struct tree_buffer *buf)
+static int check_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
 {
 	if (buf->blocknr != btrfs_header_blocknr(&buf->node.header))
 		BUG();
@@ -23,18 +23,18 @@ static int check_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 	return 0;
 }
 
-static int free_some_buffers(struct ctree_root *root)
+static int free_some_buffers(struct btrfs_root *root)
 {
 	struct list_head *node, *next;
-	struct tree_buffer *b;
+	struct btrfs_buffer *b;
 	if (root->cache_size < cache_max)
 		return 0;
 	list_for_each_safe(node, next, &root->cache) {
-		b = list_entry(node, struct tree_buffer, cache);
+		b = list_entry(node, struct btrfs_buffer, cache);
 		if (b->count == 1) {
 			BUG_ON(!list_empty(&b->dirty));
 			list_del_init(&b->cache);
-			tree_block_release(root, b);
+			btrfs_block_release(root, b);
 			if (root->cache_size < cache_max)
 				break;
 		}
@@ -42,11 +42,11 @@ static int free_some_buffers(struct ctree_root *root)
 	return 0;
 }
 
-struct tree_buffer *alloc_tree_block(struct ctree_root *root, u64 blocknr)
+struct btrfs_buffer *alloc_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	struct tree_buffer *buf;
+	struct btrfs_buffer *buf;
 	int ret;
-	buf = malloc(sizeof(struct tree_buffer));
+	buf = malloc(sizeof(struct btrfs_buffer));
 	if (!buf)
 		return buf;
 	allocated_blocks++;
@@ -66,9 +66,9 @@ struct tree_buffer *alloc_tree_block(struct ctree_root *root, u64 blocknr)
 	return buf;
 }
 
-struct tree_buffer *find_tree_block(struct ctree_root *root, u64 blocknr)
+struct btrfs_buffer *find_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	struct tree_buffer *buf;
+	struct btrfs_buffer *buf;
 	buf = radix_tree_lookup(&root->cache_radix, blocknr);
 	if (buf) {
 		buf->count++;
@@ -82,10 +82,10 @@ struct tree_buffer *find_tree_block(struct ctree_root *root, u64 blocknr)
 	return buf;
 }
 
-struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
+struct btrfs_buffer *read_tree_block(struct btrfs_root *root, u64 blocknr)
 {
-	loff_t offset = blocknr * CTREE_BLOCKSIZE;
-	struct tree_buffer *buf;
+	loff_t offset = blocknr * BTRFS_BLOCKSIZE;
+	struct btrfs_buffer *buf;
 	int ret;
 
 	buf = radix_tree_lookup(&root->cache_radix, blocknr);
@@ -95,8 +95,8 @@ struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 		buf = alloc_tree_block(root, blocknr);
 		if (!buf)
 			return NULL;
-		ret = pread(root->fp, &buf->node, CTREE_BLOCKSIZE, offset);
-		if (ret != CTREE_BLOCKSIZE) {
+		ret = pread(root->fp, &buf->node, BTRFS_BLOCKSIZE, offset);
+		if (ret != BTRFS_BLOCKSIZE) {
 			free(buf);
 			return NULL;
 		}
@@ -106,7 +106,7 @@ struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 	return buf;
 }
 
-int dirty_tree_block(struct ctree_root *root, struct tree_buffer *buf)
+int dirty_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
 {
 	if (!list_empty(&buf->dirty))
 		return 0;
@@ -115,46 +115,47 @@ int dirty_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 	return 0;
 }
 
-int clean_tree_block(struct ctree_root *root, struct tree_buffer *buf)
+int clean_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
 {
 	if (!list_empty(&buf->dirty)) {
 		list_del_init(&buf->dirty);
-		tree_block_release(root, buf);
+		btrfs_block_release(root, buf);
 	}
 	return 0;
 }
 
-int write_tree_block(struct ctree_root *root, struct tree_buffer *buf)
+int write_tree_block(struct btrfs_root *root, struct btrfs_buffer *buf)
 {
 	u64 blocknr = buf->blocknr;
-	loff_t offset = blocknr * CTREE_BLOCKSIZE;
+	loff_t offset = blocknr * BTRFS_BLOCKSIZE;
 	int ret;
 
 	if (buf->blocknr != btrfs_header_blocknr(&buf->node.header))
 		BUG();
-	ret = pwrite(root->fp, &buf->node, CTREE_BLOCKSIZE, offset);
-	if (ret != CTREE_BLOCKSIZE)
+	ret = pwrite(root->fp, &buf->node, BTRFS_BLOCKSIZE, offset);
+	if (ret != BTRFS_BLOCKSIZE)
 		return ret;
 	return 0;
 }
 
-static int __commit_transaction(struct ctree_root *root)
+static int __commit_transaction(struct btrfs_root *root)
 {
-	struct tree_buffer *b;
+	struct btrfs_buffer *b;
 	int ret = 0;
 	int wret;
 	while(!list_empty(&root->trans)) {
-		b = list_entry(root->trans.next, struct tree_buffer, dirty);
+		b = list_entry(root->trans.next, struct btrfs_buffer, dirty);
 		list_del_init(&b->dirty);
 		wret = write_tree_block(root, b);
 		if (wret)
 			ret = wret;
-		tree_block_release(root, b);
+		btrfs_block_release(root, b);
 	}
 	return ret;
 }
 
-int commit_transaction(struct ctree_root *root, struct ctree_super_block *s)
+int btrfs_commit_transaction(struct btrfs_root *root,
+			     struct btrfs_super_block *s)
 {
 	int ret = 0;
 
@@ -163,20 +164,20 @@ int commit_transaction(struct ctree_root *root, struct ctree_super_block *s)
 		ret = __commit_transaction(root->extent_root);
 	BUG_ON(ret);
 	if (root->commit_root != root->node) {
-		struct tree_buffer *snap = root->commit_root;
+		struct btrfs_buffer *snap = root->commit_root;
 		root->commit_root = root->node;
 		root->node->count++;
 		ret = btrfs_drop_snapshot(root, snap);
 		BUG_ON(ret);
-		// tree_block_release(root, snap);
+		// btrfs_block_release(root, snap);
 	}
         write_ctree_super(root, s);
 	btrfs_finish_extent_commit(root);
 	return ret;
 }
 
-static int __setup_root(struct ctree_root *root, struct ctree_root *extent_root,
-			struct ctree_root_info *info, int fp)
+static int __setup_root(struct btrfs_root *root, struct btrfs_root *extent_root,
+			struct btrfs_root_info *info, int fp)
 {
 	INIT_LIST_HEAD(&root->trans);
 	INIT_LIST_HEAD(&root->cache);
@@ -191,10 +192,10 @@ static int __setup_root(struct ctree_root *root, struct ctree_root *extent_root,
 	return 0;
 }
 
-struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
+struct btrfs_root *open_ctree(char *filename, struct btrfs_super_block *super)
 {
-	struct ctree_root *root = malloc(sizeof(struct ctree_root));
-	struct ctree_root *extent_root = malloc(sizeof(struct ctree_root));
+	struct btrfs_root *root = malloc(sizeof(struct btrfs_root));
+	struct btrfs_root *extent_root = malloc(sizeof(struct btrfs_root));
 	int fp;
 	int ret;
 
@@ -207,16 +208,16 @@ struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
 	INIT_RADIX_TREE(&root->pinned_radix, GFP_KERNEL);
 	INIT_RADIX_TREE(&extent_root->pinned_radix, GFP_KERNEL);
 	INIT_RADIX_TREE(&extent_root->cache_radix, GFP_KERNEL);
-	ret = pread(fp, super, sizeof(struct ctree_super_block),
-		     CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
+	ret = pread(fp, super, sizeof(struct btrfs_super_block),
+		     BTRFS_SUPER_INFO_OFFSET(BTRFS_BLOCKSIZE));
 	if (ret == 0 || super->root_info.tree_root == 0) {
 		printf("making new FS!\n");
 		ret = mkfs(fp);
 		if (ret)
 			return NULL;
-		ret = pread(fp, super, sizeof(struct ctree_super_block),
-			     CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
-		if (ret != sizeof(struct ctree_super_block))
+		ret = pread(fp, super, sizeof(struct btrfs_super_block),
+			     BTRFS_SUPER_INFO_OFFSET(BTRFS_BLOCKSIZE));
+		if (ret != sizeof(struct btrfs_super_block))
 			return NULL;
 	}
 	BUG_ON(ret < 0);
@@ -227,18 +228,19 @@ struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
 	return root;
 }
 
-static int __update_root(struct ctree_root *root, struct ctree_root_info *info)
+static int __update_root(struct btrfs_root *root, struct btrfs_root_info *info)
 {
 	info->tree_root = root->node->blocknr;
 	return 0;
 }
 
-int write_ctree_super(struct ctree_root *root, struct ctree_super_block *s)
+int write_ctree_super(struct btrfs_root *root, struct btrfs_super_block *s)
 {
 	int ret;
 	__update_root(root, &s->root_info);
 	__update_root(root->extent_root, &s->extent_info);
-	ret = pwrite(root->fp, s, sizeof(*s), CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
+	ret = pwrite(root->fp, s, sizeof(*s),
+		     BTRFS_SUPER_INFO_OFFSET(BTRFS_BLOCKSIZE));
 	if (ret != sizeof(*s)) {
 		fprintf(stderr, "failed to write new super block err %d\n", ret);
 		return ret;
@@ -246,19 +248,19 @@ int write_ctree_super(struct ctree_root *root, struct ctree_super_block *s)
 	return 0;
 }
 
-static int drop_cache(struct ctree_root *root)
+static int drop_cache(struct btrfs_root *root)
 {
 	while(!list_empty(&root->cache)) {
-		struct tree_buffer *b = list_entry(root->cache.next,
-						   struct tree_buffer, cache);
+		struct btrfs_buffer *b = list_entry(root->cache.next,
+						   struct btrfs_buffer, cache);
 		list_del_init(&b->cache);
-		tree_block_release(root, b);
+		btrfs_block_release(root, b);
 	}
 	return 0;
 }
-int close_ctree(struct ctree_root *root, struct ctree_super_block *s)
+int close_ctree(struct btrfs_root *root, struct btrfs_super_block *s)
 {
-	commit_transaction(root, s);
+	btrfs_commit_transaction(root, s);
 	__commit_transaction(root->extent_root);
 	write_ctree_super(root, s);
 	drop_cache(root->extent_root);
@@ -268,16 +270,16 @@ int close_ctree(struct ctree_root *root, struct ctree_super_block *s)
 
 	close(root->fp);
 	if (root->node)
-		tree_block_release(root, root->node);
+		btrfs_block_release(root, root->node);
 	if (root->extent_root->node)
-		tree_block_release(root->extent_root, root->extent_root->node);
-	tree_block_release(root, root->commit_root);
+		btrfs_block_release(root->extent_root, root->extent_root->node);
+	btrfs_block_release(root, root->commit_root);
 	free(root);
 	printf("on close %d blocks are allocated\n", allocated_blocks);
 	return 0;
 }
 
-void tree_block_release(struct ctree_root *root, struct tree_buffer *buf)
+void btrfs_block_release(struct btrfs_root *root, struct btrfs_buffer *buf)
 {
 	buf->count--;
 	if (buf->count < 0)

commit 7518a238ea0152dc849d1ed76d3cae8b44e12f46
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 12 12:01:18 2007 -0400

    Btrfs: get/set for struct header fields
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c9201ec81fef..065e888d2c0b 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -15,9 +15,10 @@ int cache_max = 10000;
 
 static int check_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 {
-	if (buf->blocknr != buf->node.header.blocknr)
+	if (buf->blocknr != btrfs_header_blocknr(&buf->node.header))
 		BUG();
-	if (root->node && buf->node.header.parentid != root->node->node.header.parentid)
+	if (root->node && btrfs_header_parentid(&buf->node.header) !=
+	    btrfs_header_parentid(&root->node->node.header))
 		BUG();
 	return 0;
 }
@@ -129,7 +130,7 @@ int write_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 	loff_t offset = blocknr * CTREE_BLOCKSIZE;
 	int ret;
 
-	if (buf->blocknr != buf->node.header.blocknr)
+	if (buf->blocknr != btrfs_header_blocknr(&buf->node.header))
 		BUG();
 	ret = pwrite(root->fp, &buf->node, CTREE_BLOCKSIZE, offset);
 	if (ret != CTREE_BLOCKSIZE)

commit 83e15a28e046dbb4534dd263d1d3dc867a8994a2
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Mar 12 09:03:27 2007 -0400

    fix leak in btrfs_drop_snapshot
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 997cc578a185..c9201ec81fef 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -167,7 +167,7 @@ int commit_transaction(struct ctree_root *root, struct ctree_super_block *s)
 		root->node->count++;
 		ret = btrfs_drop_snapshot(root, snap);
 		BUG_ON(ret);
-		tree_block_release(root, snap);
+		// tree_block_release(root, snap);
 	}
         write_ctree_super(root, s);
 	btrfs_finish_extent_commit(root);

commit 0579da4280812f34f382fb0f8004d7b0219e7a33
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Mar 7 16:15:30 2007 -0500

    Btrfs: Fixup last found extent caching
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2fe31c3508c1..997cc578a185 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -186,6 +186,7 @@ static int __setup_root(struct ctree_root *root, struct ctree_root *extent_root,
 	root->commit_root = NULL;
 	root->node = read_tree_block(root, info->tree_root);
 	memset(&root->current_insert, 0, sizeof(root->current_insert));
+	memset(&root->last_insert, 0, sizeof(root->last_insert));
 	return 0;
 }
 

commit a28ec19775d62d673b034082128aca95780d3737
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Mar 6 20:08:01 2007 -0500

    Btrfs: Fixup reference counting on cows
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 0e1c31e682fb..2fe31c3508c1 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -153,13 +153,24 @@ static int __commit_transaction(struct ctree_root *root)
 	return ret;
 }
 
-int commit_transaction(struct ctree_root *root)
+int commit_transaction(struct ctree_root *root, struct ctree_super_block *s)
 {
-	int ret;
+	int ret = 0;
+
 	ret = __commit_transaction(root);
 	if (!ret && root != root->extent_root)
 		ret = __commit_transaction(root->extent_root);
 	BUG_ON(ret);
+	if (root->commit_root != root->node) {
+		struct tree_buffer *snap = root->commit_root;
+		root->commit_root = root->node;
+		root->node->count++;
+		ret = btrfs_drop_snapshot(root, snap);
+		BUG_ON(ret);
+		tree_block_release(root, snap);
+	}
+        write_ctree_super(root, s);
+	btrfs_finish_extent_commit(root);
 	return ret;
 }
 
@@ -168,10 +179,13 @@ static int __setup_root(struct ctree_root *root, struct ctree_root *extent_root,
 {
 	INIT_LIST_HEAD(&root->trans);
 	INIT_LIST_HEAD(&root->cache);
+	root->cache_size = 0;
 	root->fp = fp;
 	root->node = NULL;
-	root->node = read_tree_block(root, info->tree_root);
 	root->extent_root = extent_root;
+	root->commit_root = NULL;
+	root->node = read_tree_block(root, info->tree_root);
+	memset(&root->current_insert, 0, sizeof(root->current_insert));
 	return 0;
 }
 
@@ -188,6 +202,8 @@ struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
 		return NULL;
 	}
 	INIT_RADIX_TREE(&root->cache_radix, GFP_KERNEL);
+	INIT_RADIX_TREE(&root->pinned_radix, GFP_KERNEL);
+	INIT_RADIX_TREE(&extent_root->pinned_radix, GFP_KERNEL);
 	INIT_RADIX_TREE(&extent_root->cache_radix, GFP_KERNEL);
 	ret = pread(fp, super, sizeof(struct ctree_super_block),
 		     CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
@@ -204,6 +220,8 @@ struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
 	BUG_ON(ret < 0);
 	__setup_root(root, extent_root, &super->root_info, fp);
 	__setup_root(extent_root, extent_root, &super->extent_info, fp);
+	root->commit_root = root->node;
+	root->node->count++;
 	return root;
 }
 
@@ -236,9 +254,11 @@ static int drop_cache(struct ctree_root *root)
 	}
 	return 0;
 }
-int close_ctree(struct ctree_root *root)
+int close_ctree(struct ctree_root *root, struct ctree_super_block *s)
 {
-	commit_transaction(root);
+	commit_transaction(root, s);
+	__commit_transaction(root->extent_root);
+	write_ctree_super(root, s);
 	drop_cache(root->extent_root);
 	drop_cache(root);
 	BUG_ON(!list_empty(&root->trans));
@@ -249,6 +269,7 @@ int close_ctree(struct ctree_root *root)
 		tree_block_release(root, root->node);
 	if (root->extent_root->node)
 		tree_block_release(root->extent_root, root->extent_root->node);
+	tree_block_release(root, root->commit_root);
 	free(root);
 	printf("on close %d blocks are allocated\n", allocated_blocks);
 	return 0;

commit 02217ed299c6340a35696e0610047eb96826de2d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 2 16:08:05 2007 -0500

    Btrfs: early reference counting
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index b1a8149bbc84..0e1c31e682fb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -260,6 +260,8 @@ void tree_block_release(struct ctree_root *root, struct tree_buffer *buf)
 	if (buf->count < 0)
 		BUG();
 	if (buf->count == 0) {
+		BUG_ON(!list_empty(&buf->cache));
+		BUG_ON(!list_empty(&buf->dirty));
 		if (!radix_tree_lookup(&root->cache_radix, buf->blocknr))
 			BUG();
 		radix_tree_delete(&root->cache_radix, buf->blocknr);

commit 77ce6846c40e83193df01295e5af437f8b6c7a2d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 2 10:06:43 2007 -0500

    Btrfs: period commit during initial fill in the random tester
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f7ca5362291e..b1a8149bbc84 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -11,7 +11,6 @@
 #include "disk-io.h"
 
 static int allocated_blocks = 0;
-int cache_size = 0;
 int cache_max = 10000;
 
 static int check_tree_block(struct ctree_root *root, struct tree_buffer *buf)
@@ -36,7 +35,7 @@ static int free_some_buffers(struct ctree_root *root)
 			list_del_init(&b->cache);
 			tree_block_release(root, b);
 			if (root->cache_size < cache_max)
-				return 0;
+				break;
 		}
 	}
 	return 0;

commit f0930a37f1c096c3a8f6a17b1e251c7fdf4d4457
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 2 09:47:58 2007 -0500

    Btrfs: Fix extent code to use merge during delete
    Remove implicit commit in del_item and insert_item
    Add implicit commit to close()
    Add commit op in random-test
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 656ace6147a8..f7ca5362291e 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -239,6 +239,7 @@ static int drop_cache(struct ctree_root *root)
 }
 int close_ctree(struct ctree_root *root)
 {
+	commit_transaction(root);
 	drop_cache(root->extent_root);
 	drop_cache(root);
 	BUG_ON(!list_empty(&root->trans));

commit ed2ff2cba766dfe7976a0113f667c9a0a50dff02
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 1 18:59:40 2007 -0500

    Btrfs: pretend page cache & commit code
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index c42dc72706bf..656ace6147a8 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -11,6 +11,8 @@
 #include "disk-io.h"
 
 static int allocated_blocks = 0;
+int cache_size = 0;
+int cache_max = 10000;
 
 static int check_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 {
@@ -21,6 +23,25 @@ static int check_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 	return 0;
 }
 
+static int free_some_buffers(struct ctree_root *root)
+{
+	struct list_head *node, *next;
+	struct tree_buffer *b;
+	if (root->cache_size < cache_max)
+		return 0;
+	list_for_each_safe(node, next, &root->cache) {
+		b = list_entry(node, struct tree_buffer, cache);
+		if (b->count == 1) {
+			BUG_ON(!list_empty(&b->dirty));
+			list_del_init(&b->cache);
+			tree_block_release(root, b);
+			if (root->cache_size < cache_max)
+				return 0;
+		}
+	}
+	return 0;
+}
+
 struct tree_buffer *alloc_tree_block(struct ctree_root *root, u64 blocknr)
 {
 	struct tree_buffer *buf;
@@ -30,10 +51,14 @@ struct tree_buffer *alloc_tree_block(struct ctree_root *root, u64 blocknr)
 		return buf;
 	allocated_blocks++;
 	buf->blocknr = blocknr;
-	buf->count = 1;
+	buf->count = 2;
+	INIT_LIST_HEAD(&buf->dirty);
+	free_some_buffers(root);
 	radix_tree_preload(GFP_KERNEL);
 	ret = radix_tree_insert(&root->cache_radix, blocknr, buf);
 	radix_tree_preload_end();
+	list_add_tail(&buf->cache, &root->cache);
+	root->cache_size++;
 	if (ret) {
 		free(buf);
 		return NULL;
@@ -57,7 +82,6 @@ struct tree_buffer *find_tree_block(struct ctree_root *root, u64 blocknr)
 	return buf;
 }
 
-
 struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 {
 	loff_t offset = blocknr * CTREE_BLOCKSIZE;
@@ -82,6 +106,24 @@ struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 	return buf;
 }
 
+int dirty_tree_block(struct ctree_root *root, struct tree_buffer *buf)
+{
+	if (!list_empty(&buf->dirty))
+		return 0;
+	list_add_tail(&buf->dirty, &root->trans);
+	buf->count++;
+	return 0;
+}
+
+int clean_tree_block(struct ctree_root *root, struct tree_buffer *buf)
+{
+	if (!list_empty(&buf->dirty)) {
+		list_del_init(&buf->dirty);
+		tree_block_release(root, buf);
+	}
+	return 0;
+}
+
 int write_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 {
 	u64 blocknr = buf->blocknr;
@@ -96,9 +138,37 @@ int write_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 	return 0;
 }
 
+static int __commit_transaction(struct ctree_root *root)
+{
+	struct tree_buffer *b;
+	int ret = 0;
+	int wret;
+	while(!list_empty(&root->trans)) {
+		b = list_entry(root->trans.next, struct tree_buffer, dirty);
+		list_del_init(&b->dirty);
+		wret = write_tree_block(root, b);
+		if (wret)
+			ret = wret;
+		tree_block_release(root, b);
+	}
+	return ret;
+}
+
+int commit_transaction(struct ctree_root *root)
+{
+	int ret;
+	ret = __commit_transaction(root);
+	if (!ret && root != root->extent_root)
+		ret = __commit_transaction(root->extent_root);
+	BUG_ON(ret);
+	return ret;
+}
+
 static int __setup_root(struct ctree_root *root, struct ctree_root *extent_root,
 			struct ctree_root_info *info, int fp)
 {
+	INIT_LIST_HEAD(&root->trans);
+	INIT_LIST_HEAD(&root->cache);
 	root->fp = fp;
 	root->node = NULL;
 	root->node = read_tree_block(root, info->tree_root);
@@ -157,8 +227,23 @@ int write_ctree_super(struct ctree_root *root, struct ctree_super_block *s)
 	return 0;
 }
 
+static int drop_cache(struct ctree_root *root)
+{
+	while(!list_empty(&root->cache)) {
+		struct tree_buffer *b = list_entry(root->cache.next,
+						   struct tree_buffer, cache);
+		list_del_init(&b->cache);
+		tree_block_release(root, b);
+	}
+	return 0;
+}
 int close_ctree(struct ctree_root *root)
 {
+	drop_cache(root->extent_root);
+	drop_cache(root);
+	BUG_ON(!list_empty(&root->trans));
+	BUG_ON(!list_empty(&root->extent_root->trans));
+
 	close(root->fp);
 	if (root->node)
 		tree_block_release(root, root->node);
@@ -182,6 +267,8 @@ void tree_block_release(struct ctree_root *root, struct tree_buffer *buf)
 		free(buf);
 		BUG_ON(allocated_blocks == 0);
 		allocated_blocks--;
+		BUG_ON(root->cache_size == 0);
+		root->cache_size--;
 	}
 }
 

commit c673024aba596e57c07196cb3400cdcc9d28f3aa
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Feb 26 10:46:55 2007 -0500

    Btrfs: fixup dbfile perms
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index f4c6ff202ba9..c42dc72706bf 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -113,7 +113,7 @@ struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
 	int fp;
 	int ret;
 
-	fp = open(filename, O_CREAT | O_RDWR);
+	fp = open(filename, O_CREAT | O_RDWR, 0600);
 	if (fp < 0) {
 		free(root);
 		return NULL;

commit 5de08d7d50ba535b968d97101ed2ab07c2b8eb7d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat Feb 24 06:24:44 2007 -0500

    Btrfs: Break up ctree.c a little
    Extent fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 14955e440773..f4c6ff202ba9 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -172,7 +172,6 @@ int close_ctree(struct ctree_root *root)
 void tree_block_release(struct ctree_root *root, struct tree_buffer *buf)
 {
 	buf->count--;
-	write_tree_block(root, buf);
 	if (buf->count < 0)
 		BUG();
 	if (buf->count == 0) {

commit 9a8dd1502de6aa683ae46cf0397e9b6e636416fb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Feb 23 08:38:36 2007 -0500

    Btrfs: Block sized tree extents and extent deletion
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index a696a4278ac5..14955e440773 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -12,33 +12,13 @@
 
 static int allocated_blocks = 0;
 
-static int get_free_block(struct ctree_root *root, u64 *block)
+static int check_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 {
-	struct stat st;
-	int ret = 0;
-
-	if (root->alloc_extent->num_used >= root->alloc_extent->num_blocks)
-		return -1;
-
-	*block = root->alloc_extent->blocknr + root->alloc_extent->num_used;
-	root->alloc_extent->num_used += 1;
-	if (root->alloc_extent->num_used >= root->alloc_extent->num_blocks) {
-		struct alloc_extent *ae = root->alloc_extent;
-		root->alloc_extent = root->reserve_extent;
-		root->reserve_extent = ae;
-		ae->num_blocks = 0;
-	}
-	st.st_size = 0;
-	ret = fstat(root->fp, &st);
-	if (st.st_size < (*block + 1) * CTREE_BLOCKSIZE) {
-		ret = ftruncate(root->fp,
-				(*block + 1) * CTREE_BLOCKSIZE);
-		if (ret) {
-			perror("ftruncate");
-			exit(1);
-		}
-	}
-	return ret;
+	if (buf->blocknr != buf->node.header.blocknr)
+		BUG();
+	if (root->node && buf->node.header.parentid != root->node->node.header.parentid)
+		BUG();
+	return 0;
 }
 
 struct tree_buffer *alloc_tree_block(struct ctree_root *root, u64 blocknr)
@@ -61,22 +41,23 @@ struct tree_buffer *alloc_tree_block(struct ctree_root *root, u64 blocknr)
 	return buf;
 }
 
-struct tree_buffer *alloc_free_block(struct ctree_root *root)
+struct tree_buffer *find_tree_block(struct ctree_root *root, u64 blocknr)
 {
-	u64 free_block;
-	int ret;
-	struct tree_buffer * buf;
-	ret = get_free_block(root, &free_block);
-	if (ret) {
-		BUG();
-		return NULL;
+	struct tree_buffer *buf;
+	buf = radix_tree_lookup(&root->cache_radix, blocknr);
+	if (buf) {
+		buf->count++;
+	} else {
+		buf = alloc_tree_block(root, blocknr);
+		if (!buf) {
+			BUG();
+			return NULL;
+		}
 	}
-	buf = alloc_tree_block(root, free_block);
-	if (!buf)
-		BUG();
 	return buf;
 }
 
+
 struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 {
 	loff_t offset = blocknr * CTREE_BLOCKSIZE;
@@ -86,20 +67,17 @@ struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 	buf = radix_tree_lookup(&root->cache_radix, blocknr);
 	if (buf) {
 		buf->count++;
-		goto test;
-	}
-	buf = alloc_tree_block(root, blocknr);
-	if (!buf)
-		return NULL;
-	ret = pread(root->fp, &buf->node, CTREE_BLOCKSIZE, offset);
-	if (ret != CTREE_BLOCKSIZE) {
-		free(buf);
-		return NULL;
+	} else {
+		buf = alloc_tree_block(root, blocknr);
+		if (!buf)
+			return NULL;
+		ret = pread(root->fp, &buf->node, CTREE_BLOCKSIZE, offset);
+		if (ret != CTREE_BLOCKSIZE) {
+			free(buf);
+			return NULL;
+		}
 	}
-test:
-	if (buf->blocknr != buf->node.header.blocknr)
-		BUG();
-	if (root->node && buf->node.header.parentid != root->node->node.header.parentid)
+	if (check_tree_block(root, buf))
 		BUG();
 	return buf;
 }
@@ -121,17 +99,10 @@ int write_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 static int __setup_root(struct ctree_root *root, struct ctree_root *extent_root,
 			struct ctree_root_info *info, int fp)
 {
-	INIT_RADIX_TREE(&root->cache_radix, GFP_KERNEL);
 	root->fp = fp;
 	root->node = NULL;
 	root->node = read_tree_block(root, info->tree_root);
 	root->extent_root = extent_root;
-	memcpy(&root->ai1, &info->alloc_extent, sizeof(info->alloc_extent));
-	memcpy(&root->ai2, &info->reserve_extent, sizeof(info->reserve_extent));
-	root->alloc_extent = &root->ai1;
-	root->reserve_extent = &root->ai2;
-	printf("setup done reading root %p, used %lu available %lu\n", root, root->alloc_extent->num_used, root->alloc_extent->num_blocks);
-	printf("setup done reading root %p, reserve used %lu available %lu\n", root, root->reserve_extent->num_used, root->reserve_extent->num_blocks);
 	return 0;
 }
 
@@ -147,6 +118,8 @@ struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
 		free(root);
 		return NULL;
 	}
+	INIT_RADIX_TREE(&root->cache_radix, GFP_KERNEL);
+	INIT_RADIX_TREE(&extent_root->cache_radix, GFP_KERNEL);
 	ret = pread(fp, super, sizeof(struct ctree_super_block),
 		     CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
 	if (ret == 0 || super->root_info.tree_root == 0) {
@@ -168,8 +141,6 @@ struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
 static int __update_root(struct ctree_root *root, struct ctree_root_info *info)
 {
 	info->tree_root = root->node->blocknr;
-	memcpy(&info->alloc_extent, root->alloc_extent, sizeof(struct alloc_extent));
-	memcpy(&info->reserve_extent, root->reserve_extent, sizeof(struct alloc_extent));
 	return 0;
 }
 
@@ -201,6 +172,7 @@ int close_ctree(struct ctree_root *root)
 void tree_block_release(struct ctree_root *root, struct tree_buffer *buf)
 {
 	buf->count--;
+	write_tree_block(root, buf);
 	if (buf->count < 0)
 		BUG();
 	if (buf->count == 0) {

commit 5c680ed620c2b69cf751aecf1a5e03ce2c89c7f3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Feb 22 11:39:13 2007 -0500

    Btrfs: switch to early splits
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 2f71ccf1c3cb..a696a4278ac5 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -149,7 +149,8 @@ struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
 	}
 	ret = pread(fp, super, sizeof(struct ctree_super_block),
 		     CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
-	if (ret == 0) {
+	if (ret == 0 || super->root_info.tree_root == 0) {
+		printf("making new FS!\n");
 		ret = mkfs(fp);
 		if (ret)
 			return NULL;

commit cfaa72952fa7b44aa5d967cbc266110900552aef
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Feb 21 17:04:57 2007 -0500

    Btrfs: extent fixes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 653f18aab330..2f71ccf1c3cb 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -15,7 +15,7 @@ static int allocated_blocks = 0;
 static int get_free_block(struct ctree_root *root, u64 *block)
 {
 	struct stat st;
-	int ret;
+	int ret = 0;
 
 	if (root->alloc_extent->num_used >= root->alloc_extent->num_blocks)
 		return -1;
@@ -30,9 +30,14 @@ static int get_free_block(struct ctree_root *root, u64 *block)
 	}
 	st.st_size = 0;
 	ret = fstat(root->fp, &st);
-	if (st.st_size < (*block + 1) * CTREE_BLOCKSIZE)
+	if (st.st_size < (*block + 1) * CTREE_BLOCKSIZE) {
 		ret = ftruncate(root->fp,
 				(*block + 1) * CTREE_BLOCKSIZE);
+		if (ret) {
+			perror("ftruncate");
+			exit(1);
+		}
+	}
 	return ret;
 }
 
@@ -81,11 +86,7 @@ struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 	buf = radix_tree_lookup(&root->cache_radix, blocknr);
 	if (buf) {
 		buf->count++;
-		if (buf->blocknr != blocknr)
-			BUG();
-		if (buf->blocknr != buf->node.header.blocknr)
-			BUG();
-		return buf;
+		goto test;
 	}
 	buf = alloc_tree_block(root, blocknr);
 	if (!buf)
@@ -95,8 +96,11 @@ struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 		free(buf);
 		return NULL;
 	}
+test:
 	if (buf->blocknr != buf->node.header.blocknr)
 		BUG();
+	if (root->node && buf->node.header.parentid != root->node->node.header.parentid)
+		BUG();
 	return buf;
 }
 
@@ -111,36 +115,30 @@ int write_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 	ret = pwrite(root->fp, &buf->node, CTREE_BLOCKSIZE, offset);
 	if (ret != CTREE_BLOCKSIZE)
 		return ret;
-	if (buf == root->node)
-		return update_root_block(root);
 	return 0;
 }
 
-struct ctree_super_block {
-	struct ctree_root_info root_info;
-	struct ctree_root_info extent_info;
-} __attribute__ ((__packed__));
-
 static int __setup_root(struct ctree_root *root, struct ctree_root *extent_root,
 			struct ctree_root_info *info, int fp)
 {
+	INIT_RADIX_TREE(&root->cache_radix, GFP_KERNEL);
 	root->fp = fp;
+	root->node = NULL;
 	root->node = read_tree_block(root, info->tree_root);
 	root->extent_root = extent_root;
 	memcpy(&root->ai1, &info->alloc_extent, sizeof(info->alloc_extent));
 	memcpy(&root->ai2, &info->reserve_extent, sizeof(info->reserve_extent));
 	root->alloc_extent = &root->ai1;
 	root->reserve_extent = &root->ai2;
-	INIT_RADIX_TREE(&root->cache_radix, GFP_KERNEL);
-	printf("setup done reading root %p, used %lu\n", root, root->alloc_extent->num_used);
+	printf("setup done reading root %p, used %lu available %lu\n", root, root->alloc_extent->num_used, root->alloc_extent->num_blocks);
+	printf("setup done reading root %p, reserve used %lu available %lu\n", root, root->reserve_extent->num_used, root->reserve_extent->num_blocks);
 	return 0;
 }
 
-struct ctree_root *open_ctree(char *filename)
+struct ctree_root *open_ctree(char *filename, struct ctree_super_block *super)
 {
 	struct ctree_root *root = malloc(sizeof(struct ctree_root));
 	struct ctree_root *extent_root = malloc(sizeof(struct ctree_root));
-	struct ctree_super_block super;
 	int fp;
 	int ret;
 
@@ -149,48 +147,61 @@ struct ctree_root *open_ctree(char *filename)
 		free(root);
 		return NULL;
 	}
-	ret = pread(fp, &super, sizeof(struct ctree_super_block),
+	ret = pread(fp, super, sizeof(struct ctree_super_block),
 		     CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
 	if (ret == 0) {
 		ret = mkfs(fp);
 		if (ret)
 			return NULL;
-		ret = pread(fp, &super, sizeof(struct ctree_super_block),
+		ret = pread(fp, super, sizeof(struct ctree_super_block),
 			     CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
 		if (ret != sizeof(struct ctree_super_block))
 			return NULL;
 	}
 	BUG_ON(ret < 0);
-	__setup_root(root, extent_root, &super.root_info, fp);
-	__setup_root(extent_root, extent_root, &super.extent_info, fp);
+	__setup_root(root, extent_root, &super->root_info, fp);
+	__setup_root(extent_root, extent_root, &super->extent_info, fp);
 	return root;
 }
 
-int close_ctree(struct ctree_root *root)
+static int __update_root(struct ctree_root *root, struct ctree_root_info *info)
 {
-	close(root->fp);
-	if (root->node)
-		tree_block_release(root, root->node);
-	free(root);
-	printf("on close %d blocks are allocated\n", allocated_blocks);
+	info->tree_root = root->node->blocknr;
+	memcpy(&info->alloc_extent, root->alloc_extent, sizeof(struct alloc_extent));
+	memcpy(&info->reserve_extent, root->reserve_extent, sizeof(struct alloc_extent));
 	return 0;
 }
 
-int update_root_block(struct ctree_root *root)
+int write_ctree_super(struct ctree_root *root, struct ctree_super_block *s)
 {
 	int ret;
-	u64 root_block = root->node->blocknr;
-
-	ret = pwrite(root->fp, &root_block, sizeof(u64), 0);
-	if (ret != sizeof(u64))
+	__update_root(root, &s->root_info);
+	__update_root(root->extent_root, &s->extent_info);
+	ret = pwrite(root->fp, s, sizeof(*s), CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
+	if (ret != sizeof(*s)) {
+		fprintf(stderr, "failed to write new super block err %d\n", ret);
 		return ret;
+	}
+	return 0;
+}
+
+int close_ctree(struct ctree_root *root)
+{
+	close(root->fp);
+	if (root->node)
+		tree_block_release(root, root->node);
+	if (root->extent_root->node)
+		tree_block_release(root->extent_root, root->extent_root->node);
+	free(root);
+	printf("on close %d blocks are allocated\n", allocated_blocks);
 	return 0;
 }
 
 void tree_block_release(struct ctree_root *root, struct tree_buffer *buf)
 {
-	return;
 	buf->count--;
+	if (buf->count < 0)
+		BUG();
 	if (buf->count == 0) {
 		if (!radix_tree_lookup(&root->cache_radix, buf->blocknr))
 			BUG();

commit d97e63b69ef21c02b67e20e41d9968b0e503572e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Feb 20 16:40:44 2007 -0500

    Btrfs: early extent mapping support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 8d51a07051d9..653f18aab330 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -12,25 +12,27 @@
 
 static int allocated_blocks = 0;
 
-struct ctree_header {
-	u64 root_block;
-} __attribute__ ((__packed__));
-
 static int get_free_block(struct ctree_root *root, u64 *block)
 {
 	struct stat st;
 	int ret;
 
+	if (root->alloc_extent->num_used >= root->alloc_extent->num_blocks)
+		return -1;
+
+	*block = root->alloc_extent->blocknr + root->alloc_extent->num_used;
+	root->alloc_extent->num_used += 1;
+	if (root->alloc_extent->num_used >= root->alloc_extent->num_blocks) {
+		struct alloc_extent *ae = root->alloc_extent;
+		root->alloc_extent = root->reserve_extent;
+		root->reserve_extent = ae;
+		ae->num_blocks = 0;
+	}
 	st.st_size = 0;
 	ret = fstat(root->fp, &st);
-	if (st.st_size > sizeof(struct ctree_header)) {
-		*block = (st.st_size -
-			sizeof(struct ctree_header)) / CTREE_BLOCKSIZE;
-	} else {
-		*block = 0;
-	}
-	ret = ftruncate(root->fp, sizeof(struct ctree_header) + (*block + 1) *
-			CTREE_BLOCKSIZE);
+	if (st.st_size < (*block + 1) * CTREE_BLOCKSIZE)
+		ret = ftruncate(root->fp,
+				(*block + 1) * CTREE_BLOCKSIZE);
 	return ret;
 }
 
@@ -72,7 +74,7 @@ struct tree_buffer *alloc_free_block(struct ctree_root *root)
 
 struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 {
-	loff_t offset = blocknr * CTREE_BLOCKSIZE + sizeof(struct ctree_header);
+	loff_t offset = blocknr * CTREE_BLOCKSIZE;
 	struct tree_buffer *buf;
 	int ret;
 
@@ -101,7 +103,7 @@ struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
 int write_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 {
 	u64 blocknr = buf->blocknr;
-	loff_t offset = blocknr * CTREE_BLOCKSIZE + sizeof(struct ctree_header);
+	loff_t offset = blocknr * CTREE_BLOCKSIZE;
 	int ret;
 
 	if (buf->blocknr != buf->node.header.blocknr)
@@ -114,11 +116,32 @@ int write_tree_block(struct ctree_root *root, struct tree_buffer *buf)
 	return 0;
 }
 
+struct ctree_super_block {
+	struct ctree_root_info root_info;
+	struct ctree_root_info extent_info;
+} __attribute__ ((__packed__));
+
+static int __setup_root(struct ctree_root *root, struct ctree_root *extent_root,
+			struct ctree_root_info *info, int fp)
+{
+	root->fp = fp;
+	root->node = read_tree_block(root, info->tree_root);
+	root->extent_root = extent_root;
+	memcpy(&root->ai1, &info->alloc_extent, sizeof(info->alloc_extent));
+	memcpy(&root->ai2, &info->reserve_extent, sizeof(info->reserve_extent));
+	root->alloc_extent = &root->ai1;
+	root->reserve_extent = &root->ai2;
+	INIT_RADIX_TREE(&root->cache_radix, GFP_KERNEL);
+	printf("setup done reading root %p, used %lu\n", root, root->alloc_extent->num_used);
+	return 0;
+}
+
 struct ctree_root *open_ctree(char *filename)
 {
 	struct ctree_root *root = malloc(sizeof(struct ctree_root));
+	struct ctree_root *extent_root = malloc(sizeof(struct ctree_root));
+	struct ctree_super_block super;
 	int fp;
-	u64 root_block;
 	int ret;
 
 	fp = open(filename, O_CREAT | O_RDWR);
@@ -126,14 +149,20 @@ struct ctree_root *open_ctree(char *filename)
 		free(root);
 		return NULL;
 	}
-	root->fp = fp;
-	INIT_RADIX_TREE(&root->cache_radix, GFP_KERNEL);
-	ret = pread(fp, &root_block, sizeof(u64), 0);
-	if (ret == sizeof(u64)) {
-		printf("reading root node at block %lu\n", root_block);
-		root->node = read_tree_block(root, root_block);
-	} else
-		root->node = NULL;
+	ret = pread(fp, &super, sizeof(struct ctree_super_block),
+		     CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
+	if (ret == 0) {
+		ret = mkfs(fp);
+		if (ret)
+			return NULL;
+		ret = pread(fp, &super, sizeof(struct ctree_super_block),
+			     CTREE_SUPER_INFO_OFFSET(CTREE_BLOCKSIZE));
+		if (ret != sizeof(struct ctree_super_block))
+			return NULL;
+	}
+	BUG_ON(ret < 0);
+	__setup_root(root, extent_root, &super.root_info, fp);
+	__setup_root(extent_root, extent_root, &super.extent_info, fp);
 	return root;
 }
 
@@ -160,6 +189,7 @@ int update_root_block(struct ctree_root *root)
 
 void tree_block_release(struct ctree_root *root, struct tree_buffer *buf)
 {
+	return;
 	buf->count--;
 	if (buf->count == 0) {
 		if (!radix_tree_lookup(&root->cache_radix, buf->blocknr))

commit eb60ceac0ebd11e9896ed1ca84fcad71a4b23601
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Feb 2 09:18:22 2007 -0500

    Btrfs: Add backing store, memory management
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
new file mode 100644
index 000000000000..8d51a07051d9
--- /dev/null
+++ b/fs/btrfs/disk-io.c
@@ -0,0 +1,174 @@
+#define _XOPEN_SOURCE 500
+#include <stdio.h>
+#include <stdlib.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <unistd.h>
+#include "kerncompat.h"
+#include "radix-tree.h"
+#include "ctree.h"
+#include "disk-io.h"
+
+static int allocated_blocks = 0;
+
+struct ctree_header {
+	u64 root_block;
+} __attribute__ ((__packed__));
+
+static int get_free_block(struct ctree_root *root, u64 *block)
+{
+	struct stat st;
+	int ret;
+
+	st.st_size = 0;
+	ret = fstat(root->fp, &st);
+	if (st.st_size > sizeof(struct ctree_header)) {
+		*block = (st.st_size -
+			sizeof(struct ctree_header)) / CTREE_BLOCKSIZE;
+	} else {
+		*block = 0;
+	}
+	ret = ftruncate(root->fp, sizeof(struct ctree_header) + (*block + 1) *
+			CTREE_BLOCKSIZE);
+	return ret;
+}
+
+struct tree_buffer *alloc_tree_block(struct ctree_root *root, u64 blocknr)
+{
+	struct tree_buffer *buf;
+	int ret;
+	buf = malloc(sizeof(struct tree_buffer));
+	if (!buf)
+		return buf;
+	allocated_blocks++;
+	buf->blocknr = blocknr;
+	buf->count = 1;
+	radix_tree_preload(GFP_KERNEL);
+	ret = radix_tree_insert(&root->cache_radix, blocknr, buf);
+	radix_tree_preload_end();
+	if (ret) {
+		free(buf);
+		return NULL;
+	}
+	return buf;
+}
+
+struct tree_buffer *alloc_free_block(struct ctree_root *root)
+{
+	u64 free_block;
+	int ret;
+	struct tree_buffer * buf;
+	ret = get_free_block(root, &free_block);
+	if (ret) {
+		BUG();
+		return NULL;
+	}
+	buf = alloc_tree_block(root, free_block);
+	if (!buf)
+		BUG();
+	return buf;
+}
+
+struct tree_buffer *read_tree_block(struct ctree_root *root, u64 blocknr)
+{
+	loff_t offset = blocknr * CTREE_BLOCKSIZE + sizeof(struct ctree_header);
+	struct tree_buffer *buf;
+	int ret;
+
+	buf = radix_tree_lookup(&root->cache_radix, blocknr);
+	if (buf) {
+		buf->count++;
+		if (buf->blocknr != blocknr)
+			BUG();
+		if (buf->blocknr != buf->node.header.blocknr)
+			BUG();
+		return buf;
+	}
+	buf = alloc_tree_block(root, blocknr);
+	if (!buf)
+		return NULL;
+	ret = pread(root->fp, &buf->node, CTREE_BLOCKSIZE, offset);
+	if (ret != CTREE_BLOCKSIZE) {
+		free(buf);
+		return NULL;
+	}
+	if (buf->blocknr != buf->node.header.blocknr)
+		BUG();
+	return buf;
+}
+
+int write_tree_block(struct ctree_root *root, struct tree_buffer *buf)
+{
+	u64 blocknr = buf->blocknr;
+	loff_t offset = blocknr * CTREE_BLOCKSIZE + sizeof(struct ctree_header);
+	int ret;
+
+	if (buf->blocknr != buf->node.header.blocknr)
+		BUG();
+	ret = pwrite(root->fp, &buf->node, CTREE_BLOCKSIZE, offset);
+	if (ret != CTREE_BLOCKSIZE)
+		return ret;
+	if (buf == root->node)
+		return update_root_block(root);
+	return 0;
+}
+
+struct ctree_root *open_ctree(char *filename)
+{
+	struct ctree_root *root = malloc(sizeof(struct ctree_root));
+	int fp;
+	u64 root_block;
+	int ret;
+
+	fp = open(filename, O_CREAT | O_RDWR);
+	if (fp < 0) {
+		free(root);
+		return NULL;
+	}
+	root->fp = fp;
+	INIT_RADIX_TREE(&root->cache_radix, GFP_KERNEL);
+	ret = pread(fp, &root_block, sizeof(u64), 0);
+	if (ret == sizeof(u64)) {
+		printf("reading root node at block %lu\n", root_block);
+		root->node = read_tree_block(root, root_block);
+	} else
+		root->node = NULL;
+	return root;
+}
+
+int close_ctree(struct ctree_root *root)
+{
+	close(root->fp);
+	if (root->node)
+		tree_block_release(root, root->node);
+	free(root);
+	printf("on close %d blocks are allocated\n", allocated_blocks);
+	return 0;
+}
+
+int update_root_block(struct ctree_root *root)
+{
+	int ret;
+	u64 root_block = root->node->blocknr;
+
+	ret = pwrite(root->fp, &root_block, sizeof(u64), 0);
+	if (ret != sizeof(u64))
+		return ret;
+	return 0;
+}
+
+void tree_block_release(struct ctree_root *root, struct tree_buffer *buf)
+{
+	buf->count--;
+	if (buf->count == 0) {
+		if (!radix_tree_lookup(&root->cache_radix, buf->blocknr))
+			BUG();
+		radix_tree_delete(&root->cache_radix, buf->blocknr);
+		memset(buf, 0, sizeof(*buf));
+		free(buf);
+		BUG_ON(allocated_blocks == 0);
+		allocated_blocks--;
+	}
+}
+
