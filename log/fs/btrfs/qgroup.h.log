commit 81f7eb00ff5bb8326e82503a32809421d14abb8a
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Feb 11 15:25:37 2020 +0800

    btrfs: destroy qgroup extent records on transaction abort
    
    We clean up the delayed references when we abort a transaction but we
    leave the pending qgroup extent records behind, leaking memory.
    
    This patch destroys the extent records when we destroy the delayed refs
    and makes sure ensure they're gone before releasing the transaction.
    
    Fixes: 3368d001ba5d ("btrfs: qgroup: Record possible quota-related extent for qgroup.")
    CC: stable@vger.kernel.org # 4.4+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    [ Rebased to latest upstream, remove to_qgroup() helper, use
      rbtree_postorder_for_each_entry_safe() wrapper ]
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 236f12224d52..1bc654459469 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -414,5 +414,6 @@ int btrfs_qgroup_add_swapped_blocks(struct btrfs_trans_handle *trans,
 		u64 last_snapshot);
 int btrfs_qgroup_trace_subtree_after_cow(struct btrfs_trans_handle *trans,
 		struct btrfs_root *root, struct extent_buffer *eb);
+void btrfs_qgroup_destroy_extent_records(struct btrfs_transaction *trans);
 
 #endif

commit 32da5386d9a4fd5c1155cecf703df104d918954c
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 29 19:20:18 2019 +0100

    btrfs: rename btrfs_block_group_cache
    
    The type name is misleading, a single entry is named 'cache' while this
    normally means a collection of objects. Rename that everywhere. Also the
    identifier was quite long, making function prototypes harder to format.
    
    Suggested-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 46ba7bd2961c..236f12224d52 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -408,7 +408,7 @@ void btrfs_qgroup_init_swapped_blocks(
 void btrfs_qgroup_clean_swapped_blocks(struct btrfs_root *root);
 int btrfs_qgroup_add_swapped_blocks(struct btrfs_trans_handle *trans,
 		struct btrfs_root *subvol_root,
-		struct btrfs_block_group_cache *bg,
+		struct btrfs_block_group *bg,
 		struct extent_buffer *subvol_parent, int subvol_slot,
 		struct extent_buffer *reloc_parent, int reloc_slot,
 		u64 last_snapshot);

commit 1418bae1c22951aad9883bc8f8f4dccb272cce1e
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jan 23 15:15:12 2019 +0800

    btrfs: qgroup: Move reserved data accounting from btrfs_delayed_ref_head to btrfs_qgroup_extent_record
    
    [BUG]
    Btrfs/139 will fail with a high probability if the testing machine (VM)
    has only 2G RAM.
    
    Resulting the final write success while it should fail due to EDQUOT,
    and the fs will have quota exceeding the limit by 16K.
    
    The simplified reproducer will be: (needs a 2G ram VM)
    
      $ mkfs.btrfs -f $dev
      $ mount $dev $mnt
    
      $ btrfs subv create $mnt/subv
      $ btrfs quota enable $mnt
      $ btrfs quota rescan -w $mnt
      $ btrfs qgroup limit -e 1G $mnt/subv
    
      $ for i in $(seq -w  1 8); do
            xfs_io -f -c "pwrite 0 128M" $mnt/subv/file_$i > /dev/null
            echo "file $i written" > /dev/kmsg
        done
      $ sync
      $ btrfs qgroup show -pcre --raw $mnt
    
    The last pwrite will not trigger EDQUOT and final 'qgroup show' will
    show something like:
    
      qgroupid         rfer         excl     max_rfer     max_excl parent  child
      --------         ----         ----     --------     -------- ------  -----
      0/5             16384        16384         none         none ---     ---
      0/256      1073758208   1073758208         none   1073741824 ---     ---
    
    And 1073758208 is larger than
      > 1073741824.
    
    [CAUSE]
    It's a bug in btrfs qgroup data reserved space management.
    
    For quota limit, we must ensure that:
      reserved (data + metadata) + rfer/excl <= limit
    
    Since rfer/excl is only updated at transaction commmit time, reserved
    space needs to be taken special care.
    
    One important part of reserved space is data, and for a new data extent
    written to disk, we still need to take the reserved space until
    rfer/excl numbers get updated.
    
    Originally when an ordered extent finishes, we migrate the reserved
    qgroup data space from extent_io tree to delayed ref head of the data
    extent, expecting delayed ref will only be cleaned up at commit
    transaction time.
    
    However for small RAM machine, due to memory pressure dirty pages can be
    flushed back to disk without committing a transaction.
    
    The related events will be something like:
    
      file 1 written
      btrfs_finish_ordered_io: ino=258 ordered offset=0 len=54947840
      btrfs_finish_ordered_io: ino=258 ordered offset=54947840 len=5636096
      btrfs_finish_ordered_io: ino=258 ordered offset=61153280 len=57344
      btrfs_finish_ordered_io: ino=258 ordered offset=61210624 len=8192
      btrfs_finish_ordered_io: ino=258 ordered offset=60583936 len=569344
      cleanup_ref_head: num_bytes=54947840
      cleanup_ref_head: num_bytes=5636096
      cleanup_ref_head: num_bytes=569344
      cleanup_ref_head: num_bytes=57344
      cleanup_ref_head: num_bytes=8192
      ^^^^^^^^^^^^^^^^ This will free qgroup data reserved space
      file 2 written
      ...
      file 8 written
      cleanup_ref_head: num_bytes=8192
      ...
      btrfs_commit_transaction  <<< the only transaction committed during
                                    the test
    
    When file 2 is written, we have already freed 128M reserved qgroup data
    space for ino 258. Thus later write won't trigger EDQUOT.
    
    This allows us to write more data beyond qgroup limit.
    
    In my 2G ram VM, it could reach about 1.2G before hitting EDQUOT.
    
    [FIX]
    By moving reserved qgroup data space from btrfs_delayed_ref_head to
    btrfs_qgroup_extent_record, we can ensure that reserved qgroup data
    space won't be freed half way before commit transaction, thus fix the
    problem.
    
    Fixes: f64d5ca86821 ("btrfs: delayed_ref: Add new function to record reserved space into delayed ref")
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 5e93733b78c8..46ba7bd2961c 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -107,6 +107,17 @@ struct btrfs_qgroup_extent_record {
 	struct rb_node node;
 	u64 bytenr;
 	u64 num_bytes;
+
+	/*
+	 * For qgroup reserved data space freeing.
+	 *
+	 * @data_rsv_refroot and @data_rsv will be recorded after
+	 * BTRFS_ADD_DELAYED_EXTENT is called.
+	 * And will be used to free reserved qgroup space at
+	 * transaction commit time.
+	 */
+	u32 data_rsv;		/* reserved data space needs to be freed */
+	u64 data_rsv_refroot;	/* which root the reserved data belongs to */
 	struct ulist *old_roots;
 };
 
@@ -326,15 +337,6 @@ int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans, u64 srcid,
 void btrfs_qgroup_free_refroot(struct btrfs_fs_info *fs_info,
 			       u64 ref_root, u64 num_bytes,
 			       enum btrfs_qgroup_rsv_type type);
-static inline void btrfs_qgroup_free_delayed_ref(struct btrfs_fs_info *fs_info,
-						 u64 ref_root, u64 num_bytes)
-{
-	if (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))
-		return;
-	trace_btrfs_qgroup_free_delayed_ref(fs_info, ref_root, num_bytes);
-	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes,
-				  BTRFS_QGROUP_RSV_DATA);
-}
 
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,

commit 9627736b75f612e05cef122b215a68113af9cd4d
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jan 23 15:15:18 2019 +0800

    btrfs: qgroup: Cleanup old subtree swap code
    
    Since it's replaced by new delayed subtree swap code, remove the
    original code.
    
    The cleanup is small since most of its core function is still used by
    delayed subtree swap trace.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 3f5e0b413312..5e93733b78c8 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -316,12 +316,6 @@ int btrfs_qgroup_trace_leaf_items(struct btrfs_trans_handle *trans,
 int btrfs_qgroup_trace_subtree(struct btrfs_trans_handle *trans,
 			       struct extent_buffer *root_eb,
 			       u64 root_gen, int root_level);
-
-int btrfs_qgroup_trace_subtree_swap(struct btrfs_trans_handle *trans,
-				struct btrfs_block_group_cache *bg_cache,
-				struct extent_buffer *src_parent, int src_slot,
-				struct extent_buffer *dst_parent, int dst_slot,
-				u64 last_snapshot);
 int btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans, u64 bytenr,
 				u64 num_bytes, struct ulist *old_roots,
 				struct ulist *new_roots);

commit f616f5cd9da7fceb7d884812da380b26040cd083
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jan 23 15:15:17 2019 +0800

    btrfs: qgroup: Use delayed subtree rescan for balance
    
    Before this patch, qgroup code traces the whole subtree of subvolume and
    reloc trees unconditionally.
    
    This makes qgroup numbers consistent, but it could cause tons of
    unnecessary extent tracing, which causes a lot of overhead.
    
    However for subtree swap of balance, just swap both subtrees because
    they contain the same contents and tree structure, so qgroup numbers
    won't change.
    
    It's the race window between subtree swap and transaction commit could
    cause qgroup number change.
    
    This patch will delay the qgroup subtree scan until COW happens for the
    subtree root.
    
    So if there is no other operations for the fs, balance won't cause extra
    qgroup overhead. (best case scenario)
    Depending on the workload, most of the subtree scan can still be
    avoided.
    
    Only for worst case scenario, it will fall back to old subtree swap
    overhead. (scan all swapped subtrees)
    
    [[Benchmark]]
    Hardware:
            VM 4G vRAM, 8 vCPUs,
            disk is using 'unsafe' cache mode,
            backing device is SAMSUNG 850 evo SSD.
            Host has 16G ram.
    
    Mkfs parameter:
            --nodesize 4K (To bump up tree size)
    
    Initial subvolume contents:
            4G data copied from /usr and /lib.
            (With enough regular small files)
    
    Snapshots:
            16 snapshots of the original subvolume.
            each snapshot has 3 random files modified.
    
    balance parameter:
            -m
    
    So the content should be pretty similar to a real world root fs layout.
    
    And after file system population, there is no other activity, so it
    should be the best case scenario.
    
                         | v4.20-rc1            | w/ patchset    | diff
    -----------------------------------------------------------------------
    relocated extents    | 22615                | 22457          | -0.1%
    qgroup dirty extents | 163457               | 121606         | -25.6%
    time (sys)           | 22.884s              | 18.842s        | -17.6%
    time (real)          | 27.724s              | 22.884s        | -17.5%
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 8dc17020e5be..3f5e0b413312 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -416,5 +416,7 @@ int btrfs_qgroup_add_swapped_blocks(struct btrfs_trans_handle *trans,
 		struct extent_buffer *subvol_parent, int subvol_slot,
 		struct extent_buffer *reloc_parent, int reloc_slot,
 		u64 last_snapshot);
+int btrfs_qgroup_trace_subtree_after_cow(struct btrfs_trans_handle *trans,
+		struct btrfs_root *root, struct extent_buffer *eb);
 
 #endif

commit 370a11b8114bcca3738fe6a5d7ed8babcc212f39
Author: Qu Wenruo <wqu@suse.com>
Date:   Wed Jan 23 15:15:16 2019 +0800

    btrfs: qgroup: Introduce per-root swapped blocks infrastructure
    
    To allow delayed subtree swap rescan, btrfs needs to record per-root
    information about which tree blocks get swapped.  This patch introduces
    the required infrastructure.
    
    The designed workflow will be:
    
    1) Record the subtree root block that gets swapped.
    
       During subtree swap:
       O = Old tree blocks
       N = New tree blocks
             reloc tree                         subvolume tree X
                Root                               Root
               /    \                             /    \
             NA     OB                          OA      OB
           /  |     |  \                      /  |      |  \
         NC  ND     OE  OF                   OC  OD     OE  OF
    
      In this case, NA and OA are going to be swapped, record (NA, OA) into
      subvolume tree X.
    
    2) After subtree swap.
             reloc tree                         subvolume tree X
                Root                               Root
               /    \                             /    \
             OA     OB                          NA      OB
           /  |     |  \                      /  |      |  \
         OC  OD     OE  OF                   NC  ND     OE  OF
    
    3a) COW happens for OB
        If we are going to COW tree block OB, we check OB's bytenr against
        tree X's swapped_blocks structure.
        If it doesn't fit any, nothing will happen.
    
    3b) COW happens for NA
        Check NA's bytenr against tree X's swapped_blocks, and get a hit.
        Then we do subtree scan on both subtrees OA and NA.
        Resulting 6 tree blocks to be scanned (OA, OC, OD, NA, NC, ND).
    
        Then no matter what we do to subvolume tree X, qgroup numbers will
        still be correct.
        Then NA's record gets removed from X's swapped_blocks.
    
    4)  Transaction commit
        Any record in X's swapped_blocks gets removed, since there is no
        modification to swapped subtrees, no need to trigger heavy qgroup
        subtree rescan for them.
    
    This will introduce 128 bytes overhead for each btrfs_root even qgroup
    is not enabled. This is to reduce memory allocations and potential
    failures.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 20c6bd5fa701..8dc17020e5be 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -6,6 +6,8 @@
 #ifndef BTRFS_QGROUP_H
 #define BTRFS_QGROUP_H
 
+#include <linux/spinlock.h>
+#include <linux/rbtree.h>
 #include "ulist.h"
 #include "delayed-ref.h"
 
@@ -37,6 +39,66 @@
  *    Normally at qgroup rescan and transaction commit time.
  */
 
+/*
+ * Special performance optimization for balance.
+ *
+ * For balance, we need to swap subtree of subvolume and reloc trees.
+ * In theory, we need to trace all subtree blocks of both subvolume and reloc
+ * trees, since their owner has changed during such swap.
+ *
+ * However since balance has ensured that both subtrees are containing the
+ * same contents and have the same tree structures, such swap won't cause
+ * qgroup number change.
+ *
+ * But there is a race window between subtree swap and transaction commit,
+ * during that window, if we increase/decrease tree level or merge/split tree
+ * blocks, we still need to trace the original subtrees.
+ *
+ * So for balance, we use a delayed subtree tracing, whose workflow is:
+ *
+ * 1) Record the subtree root block get swapped.
+ *
+ *    During subtree swap:
+ *    O = Old tree blocks
+ *    N = New tree blocks
+ *          reloc tree                     subvolume tree X
+ *             Root                               Root
+ *            /    \                             /    \
+ *          NA     OB                          OA      OB
+ *        /  |     |  \                      /  |      |  \
+ *      NC  ND     OE  OF                   OC  OD     OE  OF
+ *
+ *   In this case, NA and OA are going to be swapped, record (NA, OA) into
+ *   subvolume tree X.
+ *
+ * 2) After subtree swap.
+ *          reloc tree                     subvolume tree X
+ *             Root                               Root
+ *            /    \                             /    \
+ *          OA     OB                          NA      OB
+ *        /  |     |  \                      /  |      |  \
+ *      OC  OD     OE  OF                   NC  ND     OE  OF
+ *
+ * 3a) COW happens for OB
+ *     If we are going to COW tree block OB, we check OB's bytenr against
+ *     tree X's swapped_blocks structure.
+ *     If it doesn't fit any, nothing will happen.
+ *
+ * 3b) COW happens for NA
+ *     Check NA's bytenr against tree X's swapped_blocks, and get a hit.
+ *     Then we do subtree scan on both subtrees OA and NA.
+ *     Resulting 6 tree blocks to be scanned (OA, OC, OD, NA, NC, ND).
+ *
+ *     Then no matter what we do to subvolume tree X, qgroup numbers will
+ *     still be correct.
+ *     Then NA's record gets removed from X's swapped_blocks.
+ *
+ * 4)  Transaction commit
+ *     Any record in X's swapped_blocks gets removed, since there is no
+ *     modification to the swapped subtrees, no need to trigger heavy qgroup
+ *     subtree rescan for them.
+ */
+
 /*
  * Record a dirty extent, and info qgroup to update quota on it
  * TODO: Use kmem cache to alloc it.
@@ -48,6 +110,24 @@ struct btrfs_qgroup_extent_record {
 	struct ulist *old_roots;
 };
 
+struct btrfs_qgroup_swapped_block {
+	struct rb_node node;
+
+	int level;
+	bool trace_leaf;
+
+	/* bytenr/generation of the tree block in subvolume tree after swap */
+	u64 subvol_bytenr;
+	u64 subvol_generation;
+
+	/* bytenr/generation of the tree block in reloc tree after swap */
+	u64 reloc_bytenr;
+	u64 reloc_generation;
+
+	u64 last_snapshot;
+	struct btrfs_key first_key;
+};
+
 /*
  * Qgroup reservation types:
  *
@@ -325,4 +405,16 @@ void btrfs_qgroup_convert_reserved_meta(struct btrfs_root *root, int num_bytes);
 
 void btrfs_qgroup_check_reserved_leak(struct inode *inode);
 
+/* btrfs_qgroup_swapped_blocks related functions */
+void btrfs_qgroup_init_swapped_blocks(
+	struct btrfs_qgroup_swapped_blocks *swapped_blocks);
+
+void btrfs_qgroup_clean_swapped_blocks(struct btrfs_root *root);
+int btrfs_qgroup_add_swapped_blocks(struct btrfs_trans_handle *trans,
+		struct btrfs_root *subvol_root,
+		struct btrfs_block_group_cache *bg,
+		struct extent_buffer *subvol_parent, int subvol_slot,
+		struct extent_buffer *reloc_parent, int reloc_slot,
+		u64 last_snapshot);
+
 #endif

commit 52042d8e82ff50d40e76a275ac0b97aa663328b0
Author: Andrea Gelmini <andrea.gelmini@gelma.net>
Date:   Wed Nov 28 12:05:13 2018 +0100

    btrfs: Fix typos in comments and strings
    
    The typos accumulate over time so once in a while time they get fixed in
    a large patch.
    
    Signed-off-by: Andrea Gelmini <andrea.gelmini@gelma.net>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index e4e6ee44073a..20c6bd5fa701 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -81,10 +81,10 @@ enum btrfs_qgroup_rsv_type {
  *
  * Each type should have different reservation behavior.
  * E.g, data follows its io_tree flag modification, while
- * *currently* meta is just reserve-and-clear during transcation.
+ * *currently* meta is just reserve-and-clear during transaction.
  *
  * TODO: Add new type for reservation which can survive transaction commit.
- * Currect metadata reservation behavior is not suitable for such case.
+ * Current metadata reservation behavior is not suitable for such case.
  */
 struct btrfs_qgroup_rsv {
 	u64 values[BTRFS_QGROUP_RSV_LAST];

commit bbe339cc323ca9d2a57ac203d2d9d11a09655dcc
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 27 15:25:13 2018 +0100

    btrfs: drop extra enum initialization where using defaults
    
    The first auto-assigned value to enum is 0, we can use that and not
    initialize all members where the auto-increment does the same. This is
    used for values that are not part of on-disk format.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index d8f78f5ab854..e4e6ee44073a 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -70,7 +70,7 @@ struct btrfs_qgroup_extent_record {
  *	be converted into META_PERTRANS.
  */
 enum btrfs_qgroup_rsv_type {
-	BTRFS_QGROUP_RSV_DATA = 0,
+	BTRFS_QGROUP_RSV_DATA,
 	BTRFS_QGROUP_RSV_META_PERTRANS,
 	BTRFS_QGROUP_RSV_META_PREALLOC,
 	BTRFS_QGROUP_RSV_LAST,

commit 3628b4ca64f24a4ec55055597d0cb1c814729f8b
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Oct 9 14:36:45 2018 +0800

    btrfs: qgroup: Avoid calling qgroup functions if qgroup is not enabled
    
    Some qgroup trace events like btrfs_qgroup_release_data() and
    btrfs_qgroup_free_delayed_ref() can still be triggered even if qgroup is
    not enabled.
    
    This is caused by the lack of qgroup status check before calling some
    qgroup functions.  Thankfully the functions can handle quota disabled
    case well and just do nothing for qgroup disabled case.
    
    This patch will do earlier check before triggering related trace events.
    
    And for enabled <-> disabled race case:
    
    1) For enabled->disabled case
       Disable will wipe out all qgroups data including reservation and
       excl/rfer. Even if we leak some reservation or numbers, it will
       still be cleared, so nothing will go wrong.
    
    2) For disabled -> enabled case
       Current btrfs_qgroup_release_data() will use extent_io tree to ensure
       we won't underflow reservation. And for delayed_ref we use
       head->qgroup_reserved to record the reserved space, so in that case
       head->qgroup_reserved should be 0 and we won't underflow.
    
    CC: stable@vger.kernel.org # 4.14+
    Reported-by: Chris Murphy <lists@colorremedies.com>
    Link: https://lore.kernel.org/linux-btrfs/CAJCQCtQau7DtuUUeycCkZ36qjbKuxNzsgqJ7+sJ6W0dK_NLE3w@mail.gmail.com/
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 80ebeb3ab5ba..d8f78f5ab854 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -255,6 +255,8 @@ void btrfs_qgroup_free_refroot(struct btrfs_fs_info *fs_info,
 static inline void btrfs_qgroup_free_delayed_ref(struct btrfs_fs_info *fs_info,
 						 u64 ref_root, u64 num_bytes)
 {
+	if (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))
+		return;
 	trace_btrfs_qgroup_free_delayed_ref(fs_info, ref_root, num_bytes);
 	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes,
 				  BTRFS_QGROUP_RSV_DATA);

commit 3d0174f78e72301324a5b0ba7d67676474e36fff
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Sep 27 14:42:35 2018 +0800

    btrfs: qgroup: Only trace data extents in leaves if we're relocating data block group
    
    For qgroup_trace_extent_swap(), if we find one leaf that needs to be
    traced, we will also iterate all file extents and trace them.
    
    This is OK if we're relocating data block groups, but if we're
    relocating metadata block groups, balance code itself has ensured that
    both subtree of file tree and reloc tree contain the same contents.
    
    That's to say, if we're relocating metadata block groups, all file
    extents in reloc and file tree should match, thus no need to trace them.
    This should reduce the total number of dirty extents processed in metadata
    block group balance.
    
    [[Benchmark]] (with all previous enhancement)
    Hardware:
            VM 4G vRAM, 8 vCPUs,
            disk is using 'unsafe' cache mode,
            backing device is SAMSUNG 850 evo SSD.
            Host has 16G ram.
    
    Mkfs parameter:
            --nodesize 4K (To bump up tree size)
    
    Initial subvolume contents:
            4G data copied from /usr and /lib.
            (With enough regular small files)
    
    Snapshots:
            16 snapshots of the original subvolume.
            each snapshot has 3 random files modified.
    
    balance parameter:
            -m
    
    So the content should be pretty similar to a real world root fs layout.
    
                         | v4.19-rc1    | w/ patchset    | diff (*)
    ---------------------------------------------------------------
    relocated extents    | 22929        | 22851          | -0.3%
    qgroup dirty extents | 227757       | 140886         | -38.1%
    time (sys)           | 65.253s      | 37.464s        | -42.6%
    time (real)          | 74.032s      | 44.722s        | -39.6%
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 1aaf4c276900..80ebeb3ab5ba 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -238,6 +238,7 @@ int btrfs_qgroup_trace_subtree(struct btrfs_trans_handle *trans,
 			       u64 root_gen, int root_level);
 
 int btrfs_qgroup_trace_subtree_swap(struct btrfs_trans_handle *trans,
+				struct btrfs_block_group_cache *bg_cache,
 				struct extent_buffer *src_parent, int src_slot,
 				struct extent_buffer *dst_parent, int dst_slot,
 				u64 last_snapshot);

commit 5f527822be40104e9056c981ff06c7750153a10a
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Sep 27 14:42:32 2018 +0800

    btrfs: qgroup: Use generation-aware subtree swap to mark dirty extents
    
    Before this patch, with quota enabled during balance, we need to mark
    the whole subtree dirty for quota.
    
    E.g.
    OO = Old tree blocks (from file tree)
    NN = New tree blocks (from reloc tree)
    
            File tree (src)                   Reloc tree (dst)
                OO (a)                              NN (a)
               /  \                                /  \
         (b) OO    OO (c)                    (b) NN    NN (c)
            /  \  /  \                          /  \  /  \
           OO  OO OO OO (d)                    OO  OO OO NN (d)
    
    For old balance + quota case, quota will mark the whole src and dst tree
    dirty, including all the 3 old tree blocks in reloc tree.
    
    It's doable for small file tree or new tree blocks are all located at
    lower level.
    
    But for large file tree or new tree blocks are all located at higher
    level, this will lead to mark the whole tree dirty, and be unbelievably
    slow.
    
    This patch will change how we handle such balance with quota enabled
    case.
    
    Now we will search from (b) and (c) for any new tree blocks whose
    generation is equal to @last_snapshot, and only mark them dirty.
    
    In above case, we only need to trace tree blocks NN(b), NN(c) and NN(d).
    (NN(a) will be traced when COW happens for nodeptr modification).  And
    also for tree blocks OO(b), OO(c), OO(d). (OO(a) will be traced when COW
    happens for nodeptr modification.)
    
    For above case, we could skip 3 tree blocks, but for larger tree, we can
    skip tons of unmodified tree blocks, and hugely speed up balance.
    
    This patch will introduce a new function,
    btrfs_qgroup_trace_subtree_swap(), which will do the following main
    work:
    
    1) Read out real root eb
       And setup basic dst_path for later calls
    2) Call qgroup_trace_new_subtree_blocks()
       To trace all new tree blocks in reloc tree and their counter
       parts in the file tree.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 54b8bb282c0e..1aaf4c276900 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -236,6 +236,11 @@ int btrfs_qgroup_trace_leaf_items(struct btrfs_trans_handle *trans,
 int btrfs_qgroup_trace_subtree(struct btrfs_trans_handle *trans,
 			       struct extent_buffer *root_eb,
 			       u64 root_gen, int root_level);
+
+int btrfs_qgroup_trace_subtree_swap(struct btrfs_trans_handle *trans,
+				struct extent_buffer *src_parent, int src_slot,
+				struct extent_buffer *dst_parent, int dst_slot,
+				u64 last_snapshot);
 int btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans, u64 bytenr,
 				u64 num_bytes, struct ulist *old_roots,
 				struct ulist *new_roots);

commit a937742250199a37358a4da0a990744b92c8623c
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:41 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_qgroup_inherit
    
    It can be fetched from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 2c8960f9028c..54b8bb282c0e 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -241,9 +241,8 @@ int btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans, u64 bytenr,
 				struct ulist *new_roots);
 int btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans);
 int btrfs_run_qgroups(struct btrfs_trans_handle *trans);
-int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
-			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
-			 struct btrfs_qgroup_inherit *inherit);
+int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans, u64 srcid,
+			 u64 objectid, struct btrfs_qgroup_inherit *inherit);
 void btrfs_qgroup_free_refroot(struct btrfs_fs_info *fs_info,
 			       u64 ref_root, u64 num_bytes,
 			       enum btrfs_qgroup_rsv_type type);

commit 280f8bd2cbe0b4b578c217b8fa504294c30abde1
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:40 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_run_qgroups
    
    It can be fetched from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 61b723b1e4d8..2c8960f9028c 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -240,8 +240,7 @@ int btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans, u64 bytenr,
 				u64 num_bytes, struct ulist *old_roots,
 				struct ulist *new_roots);
 int btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans);
-int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
-		      struct btrfs_fs_info *fs_info);
+int btrfs_run_qgroups(struct btrfs_trans_handle *trans);
 int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
 			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
 			 struct btrfs_qgroup_inherit *inherit);

commit 8696d76045579c9611fe1cfc064e48ada32bb796
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:39 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_qgroup_account_extent
    
    It can be fetched from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index b8f15ce6c83d..61b723b1e4d8 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -236,11 +236,9 @@ int btrfs_qgroup_trace_leaf_items(struct btrfs_trans_handle *trans,
 int btrfs_qgroup_trace_subtree(struct btrfs_trans_handle *trans,
 			       struct extent_buffer *root_eb,
 			       u64 root_gen, int root_level);
-int
-btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans,
-			    struct btrfs_fs_info *fs_info,
-			    u64 bytenr, u64 num_bytes,
-			    struct ulist *old_roots, struct ulist *new_roots);
+int btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans, u64 bytenr,
+				u64 num_bytes, struct ulist *old_roots,
+				struct ulist *new_roots);
 int btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans);
 int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
 		      struct btrfs_fs_info *fs_info);

commit deb406274339f386836313af7eeb8001cca6c33f
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:38 2018 +0800

    btrfs: qgroup: Drop root parameter from btrfs_qgroup_trace_subtree
    
    The fs_info can be fetched from the transaction handle directly.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 9d434a01d467..b8f15ce6c83d 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -234,7 +234,6 @@ int btrfs_qgroup_trace_leaf_items(struct btrfs_trans_handle *trans,
  * Return <0 for error(ENOMEM or tree search error)
  */
 int btrfs_qgroup_trace_subtree(struct btrfs_trans_handle *trans,
-			       struct btrfs_root *root,
 			       struct extent_buffer *root_eb,
 			       u64 root_gen, int root_level);
 int

commit 8d38d7eb7bb60a7a441cec3ba92784d9f1e20d5f
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:37 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_qgroup_trace_leaf_items
    
    It can be fetched from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 0215dc0b1710..9d434a01d467 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -222,7 +222,6 @@ int btrfs_qgroup_trace_extent(struct btrfs_trans_handle *trans, u64 bytenr,
  * Return <0 for error(ENOMEM)
  */
 int btrfs_qgroup_trace_leaf_items(struct btrfs_trans_handle *trans,
-				  struct btrfs_fs_info *fs_info,
 				  struct extent_buffer *eb);
 /*
  * Inform qgroup to trace a whole subtree, including all its child tree

commit a95f3aafd6a2d0e8de834c95e91066825e3e7787
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 16:28:03 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_qgroup_trace_extent
    
    It can be fetched from the transaction handle. In addition, remove the
    WARN_ON(trans == NULL) because it's not possible to hit this condition.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 385367989ed6..0215dc0b1710 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -212,9 +212,8 @@ int btrfs_qgroup_trace_extent_post(struct btrfs_fs_info *fs_info,
  * Return <0 for error, like memory allocation failure or invalid parameter
  * (NULL trans)
  */
-int btrfs_qgroup_trace_extent(struct btrfs_trans_handle *trans,
-		struct btrfs_fs_info *fs_info, u64 bytenr, u64 num_bytes,
-		gfp_t gfp_flag);
+int btrfs_qgroup_trace_extent(struct btrfs_trans_handle *trans, u64 bytenr,
+			      u64 num_bytes, gfp_t gfp_flag);
 
 /*
  * Inform qgroup to trace all leaf items of data

commit f0042d5e92b66969a12166d1deb5a979250d6c25
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:35 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_limit_qgroup
    
    It can be fetched from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 41516dddf123..385367989ed6 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -153,8 +153,7 @@ int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,
 			      u64 dst);
 int btrfs_create_qgroup(struct btrfs_trans_handle *trans, u64 qgroupid);
 int btrfs_remove_qgroup(struct btrfs_trans_handle *trans, u64 qgroupid);
-int btrfs_limit_qgroup(struct btrfs_trans_handle *trans,
-		       struct btrfs_fs_info *fs_info, u64 qgroupid,
+int btrfs_limit_qgroup(struct btrfs_trans_handle *trans, u64 qgroupid,
 		       struct btrfs_qgroup_limit *limit);
 int btrfs_read_qgroup_config(struct btrfs_fs_info *fs_info);
 void btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info);

commit 3efbee1d006a97eaec5f070430c75010ef8746f1
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:34 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_remove_qgroup
    
    It can be fetched from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 03adfedd9d01..41516dddf123 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -152,8 +152,7 @@ int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,
 int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,
 			      u64 dst);
 int btrfs_create_qgroup(struct btrfs_trans_handle *trans, u64 qgroupid);
-int btrfs_remove_qgroup(struct btrfs_trans_handle *trans,
-			      struct btrfs_fs_info *fs_info, u64 qgroupid);
+int btrfs_remove_qgroup(struct btrfs_trans_handle *trans, u64 qgroupid);
 int btrfs_limit_qgroup(struct btrfs_trans_handle *trans,
 		       struct btrfs_fs_info *fs_info, u64 qgroupid,
 		       struct btrfs_qgroup_limit *limit);

commit 49a05ecde3f130ae9d69ab619e3ea125cf1f32c9
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:33 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_create_qgroup
    
    It can be fetched from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 539d4c449f26..03adfedd9d01 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -151,8 +151,7 @@ int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,
 			      u64 dst);
 int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,
 			      u64 dst);
-int btrfs_create_qgroup(struct btrfs_trans_handle *trans,
-			struct btrfs_fs_info *fs_info, u64 qgroupid);
+int btrfs_create_qgroup(struct btrfs_trans_handle *trans, u64 qgroupid);
 int btrfs_remove_qgroup(struct btrfs_trans_handle *trans,
 			      struct btrfs_fs_info *fs_info, u64 qgroupid);
 int btrfs_limit_qgroup(struct btrfs_trans_handle *trans,

commit 39616c2735ad04ecf4874519b64556decb73d968
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:32 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_del_qgroup_relation
    
    It can be fetched from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index cb4d0e58f486..539d4c449f26 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -149,8 +149,8 @@ int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info,
 				     bool interruptible);
 int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,
 			      u64 dst);
-int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,
-			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
+int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,
+			      u64 dst);
 int btrfs_create_qgroup(struct btrfs_trans_handle *trans,
 			struct btrfs_fs_info *fs_info, u64 qgroupid);
 int btrfs_remove_qgroup(struct btrfs_trans_handle *trans,

commit 9f8a6ce6ba8ebeb86de59b1adfdc64087049f76f
Author: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
Date:   Wed Jul 18 14:45:30 2018 +0800

    btrfs: qgroup: Drop fs_info parameter from btrfs_add_qgroup_relation
    
    It can be fetched from the transaction handle.
    
    Signed-off-by: Lu Fengqi <lufq.fnst@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index bec7c9b17a8e..cb4d0e58f486 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -147,8 +147,8 @@ int btrfs_qgroup_rescan(struct btrfs_fs_info *fs_info);
 void btrfs_qgroup_rescan_resume(struct btrfs_fs_info *fs_info);
 int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info,
 				     bool interruptible);
-int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,
-			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
+int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,
+			      u64 dst);
 int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,
 			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
 int btrfs_create_qgroup(struct btrfs_trans_handle *trans,

commit 340f1aa27f367e0c3d2662d44f356b05087fea05
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Jul 5 14:50:48 2018 +0300

    btrfs: qgroups: Move transaction management inside btrfs_quota_enable/disable
    
    Commit 5d23515be669 ("btrfs: Move qgroup rescan on quota enable to
    btrfs_quota_enable") not only resulted in an easier to follow code but
    it also introduced a subtle bug. It changed the timing when the initial
    transaction rescan was happening:
    
    - before the commit: it would happen after transaction commit had occured
    - after the commit: it might happen before the transaction was committed
    
    This results in failure to correctly rescan the quota since there could
    be data which is still not committed on disk.
    
    This patch aims to fix this by moving the transaction creation/commit
    inside btrfs_quota_enable, which allows to schedule the quota commit
    after the transaction has been committed.
    
    Fixes: 5d23515be669 ("btrfs: Move qgroup rescan on quota enable to btrfs_quota_enable")
    Reported-by: Misono Tomohiro <misono.tomohiro@jp.fujitsu.com>
    Link: https://marc.info/?l=linux-btrfs&m=152999289017582
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index d60dd06445ce..bec7c9b17a8e 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -141,10 +141,8 @@ struct btrfs_qgroup {
 #define QGROUP_RELEASE		(1<<1)
 #define QGROUP_FREE		(1<<2)
 
-int btrfs_quota_enable(struct btrfs_trans_handle *trans,
-		       struct btrfs_fs_info *fs_info);
-int btrfs_quota_disable(struct btrfs_trans_handle *trans,
-			struct btrfs_fs_info *fs_info);
+int btrfs_quota_enable(struct btrfs_fs_info *fs_info);
+int btrfs_quota_disable(struct btrfs_fs_info *fs_info);
 int btrfs_qgroup_rescan(struct btrfs_fs_info *fs_info);
 void btrfs_qgroup_rescan_resume(struct btrfs_fs_info *fs_info);
 int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info,

commit 9888c3402c8567a977de37f61e9dd87792723064
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:16:55 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- headers
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Unify the include protection macros to match the file names.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index e63e2d497a8e..d60dd06445ce 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -1,23 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Copyright (C) 2014 Facebook.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
-#ifndef __BTRFS_QGROUP__
-#define __BTRFS_QGROUP__
+#ifndef BTRFS_QGROUP_H
+#define BTRFS_QGROUP_H
 
 #include "ulist.h"
 #include "delayed-ref.h"
@@ -341,4 +328,5 @@ void btrfs_qgroup_free_meta_all_pertrans(struct btrfs_root *root);
 void btrfs_qgroup_convert_reserved_meta(struct btrfs_root *root, int num_bytes);
 
 void btrfs_qgroup_check_reserved_leak(struct inode *inode);
-#endif /* __BTRFS_QGROUP__ */
+
+#endif

commit 64cfaef6362fc756972f477372997fbe117d79cb
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Dec 12 15:34:31 2017 +0800

    btrfs: qgroup: Introduce function to convert META_PREALLOC into META_PERTRANS
    
    For meta_prealloc reservation users, after btrfs_join_transaction()
    caller will modify tree so part (or even all) meta_prealloc reservation
    should be converted to meta_pertrans until transaction commit time.
    
    This patch introduces a new function,
    btrfs_qgroup_convert_reserved_meta() to do this for META_PREALLOC
    reservation user.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 987a5a49deb8..e63e2d497a8e 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -332,5 +332,13 @@ static inline void btrfs_qgroup_free_meta_prealloc(struct btrfs_root *root,
  */
 void btrfs_qgroup_free_meta_all_pertrans(struct btrfs_root *root);
 
+/*
+ * Convert @num_bytes of META_PREALLOCATED reservation to META_PERTRANS.
+ *
+ * This is called when preallocated meta reservation needs to be used.
+ * Normally after btrfs_join_transaction() call.
+ */
+void btrfs_qgroup_convert_reserved_meta(struct btrfs_root *root, int num_bytes);
+
 void btrfs_qgroup_check_reserved_leak(struct inode *inode);
 #endif /* __BTRFS_QGROUP__ */

commit 733e03a0b26a463d75aa86083c9fab856571e7fc
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Dec 12 15:34:29 2017 +0800

    btrfs: qgroup: Split meta rsv type into meta_prealloc and meta_pertrans
    
    Btrfs uses 2 different methods to reseve metadata qgroup space.
    
    1) Reserve at btrfs_start_transaction() time
       This is quite straightforward, caller will use the trans handler
       allocated to modify b-trees.
    
       In this case, reserved metadata should be kept until qgroup numbers
       are updated.
    
    2) Reserve by using block_rsv first, and later btrfs_join_transaction()
       This is more complicated, caller will reserve space using block_rsv
       first, and then later call btrfs_join_transaction() to get a trans
       handle.
    
       In this case, before we modify trees, the reserved space can be
       modified on demand, and after btrfs_join_transaction(), such reserved
       space should also be kept until qgroup numbers are updated.
    
    Since these two types behave differently, split the original "META"
    reservation type into 2 sub-types:
    
      META_PERTRANS:
        For above case 1)
    
      META_PREALLOC:
        For reservations that happened before btrfs_join_transaction() of
        case 2)
    
    NOTE: This patch will only convert existing qgroup meta reservation
    callers according to its situation, not ensuring all callers are at
    correct timing.
    Such fix will be added in later patches.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    [ update comments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 279e71a21695..987a5a49deb8 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -61,9 +61,31 @@ struct btrfs_qgroup_extent_record {
 	struct ulist *old_roots;
 };
 
+/*
+ * Qgroup reservation types:
+ *
+ * DATA:
+ *	space reserved for data
+ *
+ * META_PERTRANS:
+ * 	Space reserved for metadata (per-transaction)
+ * 	Due to the fact that qgroup data is only updated at transaction commit
+ * 	time, reserved space for metadata must be kept until transaction
+ * 	commits.
+ * 	Any metadata reserved that are used in btrfs_start_transaction() should
+ * 	be of this type.
+ *
+ * META_PREALLOC:
+ *	There are cases where metadata space is reserved before starting
+ *	transaction, and then btrfs_join_transaction() to get a trans handle.
+ *	Any metadata reserved for such usage should be of this type.
+ *	And after join_transaction() part (or all) of such reservation should
+ *	be converted into META_PERTRANS.
+ */
 enum btrfs_qgroup_rsv_type {
 	BTRFS_QGROUP_RSV_DATA = 0,
-	BTRFS_QGROUP_RSV_META,
+	BTRFS_QGROUP_RSV_META_PERTRANS,
+	BTRFS_QGROUP_RSV_META_PREALLOC,
 	BTRFS_QGROUP_RSV_LAST,
 };
 
@@ -269,9 +291,46 @@ int btrfs_qgroup_release_data(struct inode *inode, u64 start, u64 len);
 int btrfs_qgroup_free_data(struct inode *inode,
 			struct extent_changeset *reserved, u64 start, u64 len);
 
-int btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes,
-			      bool enforce);
-void btrfs_qgroup_free_meta_all(struct btrfs_root *root);
-void btrfs_qgroup_free_meta(struct btrfs_root *root, int num_bytes);
+int __btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes,
+				enum btrfs_qgroup_rsv_type type, bool enforce);
+/* Reserve metadata space for pertrans and prealloc type */
+static inline int btrfs_qgroup_reserve_meta_pertrans(struct btrfs_root *root,
+				int num_bytes, bool enforce)
+{
+	return __btrfs_qgroup_reserve_meta(root, num_bytes,
+			BTRFS_QGROUP_RSV_META_PERTRANS, enforce);
+}
+static inline int btrfs_qgroup_reserve_meta_prealloc(struct btrfs_root *root,
+				int num_bytes, bool enforce)
+{
+	return __btrfs_qgroup_reserve_meta(root, num_bytes,
+			BTRFS_QGROUP_RSV_META_PREALLOC, enforce);
+}
+
+void __btrfs_qgroup_free_meta(struct btrfs_root *root, int num_bytes,
+			     enum btrfs_qgroup_rsv_type type);
+
+/* Free per-transaction meta reservation for error handling */
+static inline void btrfs_qgroup_free_meta_pertrans(struct btrfs_root *root,
+						   int num_bytes)
+{
+	__btrfs_qgroup_free_meta(root, num_bytes,
+			BTRFS_QGROUP_RSV_META_PERTRANS);
+}
+
+/* Pre-allocated meta reservation can be freed at need */
+static inline void btrfs_qgroup_free_meta_prealloc(struct btrfs_root *root,
+						   int num_bytes)
+{
+	__btrfs_qgroup_free_meta(root, num_bytes,
+			BTRFS_QGROUP_RSV_META_PREALLOC);
+}
+
+/*
+ * Per-transaction meta reservation should be all freed at transaction commit
+ * time
+ */
+void btrfs_qgroup_free_meta_all_pertrans(struct btrfs_root *root);
+
 void btrfs_qgroup_check_reserved_leak(struct inode *inode);
 #endif /* __BTRFS_QGROUP__ */

commit 5c40507ffb1bbbc8eeeaa6d8da181f431cb83d97
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Dec 12 15:34:28 2017 +0800

    btrfs: qgroup: Cleanup the remaining old reservation counters
    
    So qgroup is switched to new separate types reservation system.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index b5ee229b3ef1..279e71a21695 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -107,7 +107,6 @@ struct btrfs_qgroup {
 	/*
 	 * reservation tracking
 	 */
-	u64 reserved;
 	struct btrfs_qgroup_rsv rsv;
 
 	/*

commit d4e5c92055d8933e9a2030fcbe6d0dbbec538c58
Author: Qu Wenruo <wqu@suse.com>
Date:   Tue Dec 12 15:34:23 2017 +0800

    btrfs: qgroup: Skeleton to support separate qgroup reservation type
    
    Instead of single qgroup->reserved, use a new structure btrfs_qgroup_rsv
    to store different types of reservation.
    
    This patch only updates the header needed to compile.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index ad003483d20c..b5ee229b3ef1 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -61,6 +61,26 @@ struct btrfs_qgroup_extent_record {
 	struct ulist *old_roots;
 };
 
+enum btrfs_qgroup_rsv_type {
+	BTRFS_QGROUP_RSV_DATA = 0,
+	BTRFS_QGROUP_RSV_META,
+	BTRFS_QGROUP_RSV_LAST,
+};
+
+/*
+ * Represents how many bytes we have reserved for this qgroup.
+ *
+ * Each type should have different reservation behavior.
+ * E.g, data follows its io_tree flag modification, while
+ * *currently* meta is just reserve-and-clear during transcation.
+ *
+ * TODO: Add new type for reservation which can survive transaction commit.
+ * Currect metadata reservation behavior is not suitable for such case.
+ */
+struct btrfs_qgroup_rsv {
+	u64 values[BTRFS_QGROUP_RSV_LAST];
+};
+
 /*
  * one struct for each qgroup, organized in fs_info->qgroup_tree.
  */
@@ -88,6 +108,7 @@ struct btrfs_qgroup {
 	 * reservation tracking
 	 */
 	u64 reserved;
+	struct btrfs_qgroup_rsv rsv;
 
 	/*
 	 * lists
@@ -227,12 +248,14 @@ int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
 			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
 			 struct btrfs_qgroup_inherit *inherit);
 void btrfs_qgroup_free_refroot(struct btrfs_fs_info *fs_info,
-			       u64 ref_root, u64 num_bytes);
+			       u64 ref_root, u64 num_bytes,
+			       enum btrfs_qgroup_rsv_type type);
 static inline void btrfs_qgroup_free_delayed_ref(struct btrfs_fs_info *fs_info,
 						 u64 ref_root, u64 num_bytes)
 {
 	trace_btrfs_qgroup_free_delayed_ref(fs_info, ref_root, num_bytes);
-	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes);
+	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes,
+				  BTRFS_QGROUP_RSV_DATA);
 }
 
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS

commit 460fb20a4bba040d7a95629ef7a4e9b97bfdbb6e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Mar 15 16:00:25 2018 +0200

    btrfs: Drop fs_info parameter from btrfs_qgroup_account_extents
    
    It's provided by the transaction handle.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index d9984e87cddf..ad003483d20c 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -220,8 +220,7 @@ btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans,
 			    struct btrfs_fs_info *fs_info,
 			    u64 bytenr, u64 num_bytes,
 			    struct ulist *old_roots, struct ulist *new_roots);
-int btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans,
-				 struct btrfs_fs_info *fs_info);
+int btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans);
 int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
 		      struct btrfs_fs_info *fs_info);
 int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,

commit bc42bda22345efdb5d8b578d1b4df2c6eaa85c58
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Feb 27 15:10:39 2017 +0800

    btrfs: qgroup: Fix qgroup reserved space underflow by only freeing reserved ranges
    
    [BUG]
    For the following case, btrfs can underflow qgroup reserved space
    at an error path:
    (Page size 4K, function name without "btrfs_" prefix)
    
             Task A                  |             Task B
    ----------------------------------------------------------------------
    Buffered_write [0, 2K)           |
    |- check_data_free_space()       |
    |  |- qgroup_reserve_data()      |
    |     Range aligned to page      |
    |     range [0, 4K)          <<< |
    |     4K bytes reserved      <<< |
    |- copy pages to page cache      |
                                     | Buffered_write [2K, 4K)
                                     | |- check_data_free_space()
                                     | |  |- qgroup_reserved_data()
                                     | |     Range alinged to page
                                     | |     range [0, 4K)
                                     | |     Already reserved by A <<<
                                     | |     0 bytes reserved      <<<
                                     | |- delalloc_reserve_metadata()
                                     | |  And it *FAILED* (Maybe EQUOTA)
                                     | |- free_reserved_data_space()
                                          |- qgroup_free_data()
                                             Range aligned to page range
                                             [0, 4K)
                                             Freeing 4K
    (Special thanks to Chandan for the detailed report and analyse)
    
    [CAUSE]
    Above Task B is freeing reserved data range [0, 4K) which is actually
    reserved by Task A.
    
    And at writeback time, page dirty by Task A will go through writeback
    routine, which will free 4K reserved data space at file extent insert
    time, causing the qgroup underflow.
    
    [FIX]
    For btrfs_qgroup_free_data(), add @reserved parameter to only free
    data ranges reserved by previous btrfs_qgroup_reserve_data().
    So in above case, Task B will try to free 0 byte, so no underflow.
    
    Reported-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Tested-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 99408e93eb0d..d9984e87cddf 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -245,7 +245,8 @@ int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,
 int btrfs_qgroup_reserve_data(struct inode *inode,
 			struct extent_changeset **reserved, u64 start, u64 len);
 int btrfs_qgroup_release_data(struct inode *inode, u64 start, u64 len);
-int btrfs_qgroup_free_data(struct inode *inode, u64 start, u64 len);
+int btrfs_qgroup_free_data(struct inode *inode,
+			struct extent_changeset *reserved, u64 start, u64 len);
 
 int btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes,
 			      bool enforce);

commit 364ecf3651e0862152c8b340d7cb3021dc0122c7
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Feb 27 15:10:38 2017 +0800

    btrfs: qgroup: Introduce extent changeset for qgroup reserve functions
    
    Introduce a new parameter, struct extent_changeset for
    btrfs_qgroup_reserved_data() and its callers.
    
    Such extent_changeset was used in btrfs_qgroup_reserve_data() to record
    which range it reserved in current reserve, so it can free it in error
    paths.
    
    The reason we need to export it to callers is, at buffered write error
    path, without knowing what exactly which range we reserved in current
    allocation, we can free space which is not reserved by us.
    
    This will lead to qgroup reserved space underflow.
    
    Reviewed-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index d11125d6afb9..99408e93eb0d 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -242,7 +242,8 @@ int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,
 #endif
 
 /* New io_tree based accurate qgroup reserve API */
-int btrfs_qgroup_reserve_data(struct inode *inode, u64 start, u64 len);
+int btrfs_qgroup_reserve_data(struct inode *inode,
+			struct extent_changeset **reserved, u64 start, u64 len);
 int btrfs_qgroup_release_data(struct inode *inode, u64 start, u64 len);
 int btrfs_qgroup_free_data(struct inode *inode, u64 start, u64 len);
 

commit d1b8b94a2b4f416b416bdfde46315e9aef17f358
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Feb 27 15:10:35 2017 +0800

    btrfs: qgroup: Cleanup btrfs_qgroup_prepare_account_extents function
    
    Quite a lot of qgroup corruption happens due to wrong time of calling
    btrfs_qgroup_prepare_account_extents().
    
    Since the safest time is to call it just before
    btrfs_qgroup_account_extents(), there is no need to separate these 2
    functions.
    
    Merging them will make code cleaner and less bug prone.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    [ changelog and comment adjustments ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index fe04d3f295c6..d11125d6afb9 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -134,8 +134,7 @@ int btrfs_limit_qgroup(struct btrfs_trans_handle *trans,
 int btrfs_read_qgroup_config(struct btrfs_fs_info *fs_info);
 void btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info);
 struct btrfs_delayed_extent_op;
-int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
-					 struct btrfs_fs_info *fs_info);
+
 /*
  * Inform qgroup to trace one dirty extent, its info is recorded in @record.
  * So qgroup can account it at transaction committing time.

commit d51ea5dd222d13dc46c76b2446aa59c4183e3922
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Mar 13 15:52:09 2017 +0800

    btrfs: qgroup: Re-arrange tracepoint timing to co-operate with reserved space tracepoint
    
    Newly introduced qgroup reserved space trace points are normally nested
    into several common qgroup operations.
    
    While some other trace points are not well placed to co-operate with
    them, causing confusing output.
    
    This patch re-arrange trace_btrfs_qgroup_release_data() and
    trace_btrfs_qgroup_free_delayed_ref() trace points so they are triggered
    before reserved space ones.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 31e468b16175..fe04d3f295c6 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -230,15 +230,11 @@ int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
 			 struct btrfs_qgroup_inherit *inherit);
 void btrfs_qgroup_free_refroot(struct btrfs_fs_info *fs_info,
 			       u64 ref_root, u64 num_bytes);
-/*
- * TODO: Add proper trace point for it, as btrfs_qgroup_free() is
- * called by everywhere, can't provide good trace for delayed ref case.
- */
 static inline void btrfs_qgroup_free_delayed_ref(struct btrfs_fs_info *fs_info,
 						 u64 ref_root, u64 num_bytes)
 {
-	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes);
 	trace_btrfs_qgroup_free_delayed_ref(fs_info, ref_root, num_bytes);
+	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes);
 }
 
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS

commit 3159fe7baef3a50fc332455e252d8a01a18f1ff1
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Mar 13 15:52:08 2017 +0800

    btrfs: qgroup: Add trace point for qgroup reserved space
    
    Introduce the following trace points:
    qgroup_update_reserve
    qgroup_meta_reserve
    
    These trace points are handy to trace qgroup reserve space related
    problems.
    
    Also export btrfs_qgroup structure, as now we directly pass btrfs_qgroup
    structure to trace points, so that structure needs to be exported.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 96fc56ebf55a..31e468b16175 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -61,6 +61,50 @@ struct btrfs_qgroup_extent_record {
 	struct ulist *old_roots;
 };
 
+/*
+ * one struct for each qgroup, organized in fs_info->qgroup_tree.
+ */
+struct btrfs_qgroup {
+	u64 qgroupid;
+
+	/*
+	 * state
+	 */
+	u64 rfer;	/* referenced */
+	u64 rfer_cmpr;	/* referenced compressed */
+	u64 excl;	/* exclusive */
+	u64 excl_cmpr;	/* exclusive compressed */
+
+	/*
+	 * limits
+	 */
+	u64 lim_flags;	/* which limits are set */
+	u64 max_rfer;
+	u64 max_excl;
+	u64 rsv_rfer;
+	u64 rsv_excl;
+
+	/*
+	 * reservation tracking
+	 */
+	u64 reserved;
+
+	/*
+	 * lists
+	 */
+	struct list_head groups;  /* groups this group is member of */
+	struct list_head members; /* groups that are members of this group */
+	struct list_head dirty;   /* dirty groups */
+	struct rb_node node;	  /* tree of qgroups */
+
+	/*
+	 * temp variables for accounting operations
+	 * Refer to qgroup_shared_accounting() for details.
+	 */
+	u64 old_refcnt;
+	u64 new_refcnt;
+};
+
 /*
  * For qgroup event trace points only
  */

commit f486135ebab4fb91366a1e41fb15ed3036ad0cf9
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 15 16:17:03 2017 +0100

    btrfs: remove unused qgroup members from btrfs_trans_handle
    
    The members have been effectively unused since "Btrfs: rework qgroup
    accounting" (fcebe4562dec83b3), there's no substitute for
    assert_qgroups_uptodate so it's removed as well.
    
    Reviewed-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 26932a8a1993..96fc56ebf55a 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -196,7 +196,6 @@ static inline void btrfs_qgroup_free_delayed_ref(struct btrfs_fs_info *fs_info,
 	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes);
 	trace_btrfs_qgroup_free_delayed_ref(fs_info, ref_root, num_bytes);
 }
-void assert_qgroups_uptodate(struct btrfs_trans_handle *trans);
 
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,

commit fb235dc06fac9eaa4408ade9c8b20d45d63c89b7
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Wed Feb 15 10:43:03 2017 +0800

    btrfs: qgroup: Move half of the qgroup accounting time out of commit trans
    
    Just as Filipe pointed out, the most time consuming parts of qgroup are
    btrfs_qgroup_account_extents() and
    btrfs_qgroup_prepare_account_extents().
    Which both call btrfs_find_all_roots() to get old_roots and new_roots
    ulist.
    
    What makes things worse is, we're calling that expensive
    btrfs_find_all_roots() at transaction committing time with
    TRANS_STATE_COMMIT_DOING, which will blocks all incoming transaction.
    
    Such behavior is necessary for @new_roots search as current
    btrfs_find_all_roots() can't do it correctly so we do call it just
    before switch commit roots.
    
    However for @old_roots search, it's not necessary as such search is
    based on commit_root, so it will always be correct and we can move it
    out of transaction committing.
    
    This patch moves the @old_roots search part out of
    commit_transaction(), so in theory we can half the time qgroup time
    consumption at commit_transaction().
    
    But please note that, this won't speedup qgroup overall, the total time
    consumption is still the same, just reduce the performance stall.
    
    Cc: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index ee95f456a61f..26932a8a1993 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -94,9 +94,10 @@ int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
 /*
  * Inform qgroup to trace one dirty extent, its info is recorded in @record.
- * So qgroup can account it at commit trans time.
+ * So qgroup can account it at transaction committing time.
  *
- * No lock version, caller must acquire delayed ref lock and allocate memory.
+ * No lock version, caller must acquire delayed ref lock and allocated memory,
+ * then call btrfs_qgroup_trace_extent_post() after exiting lock context.
  *
  * Return 0 for success insert
  * Return >0 for existing record, caller can free @record safely.
@@ -107,12 +108,38 @@ int btrfs_qgroup_trace_extent_nolock(
 		struct btrfs_delayed_ref_root *delayed_refs,
 		struct btrfs_qgroup_extent_record *record);
 
+/*
+ * Post handler after qgroup_trace_extent_nolock().
+ *
+ * NOTE: Current qgroup does the expensive backref walk at transaction
+ * committing time with TRANS_STATE_COMMIT_DOING, this blocks incoming
+ * new transaction.
+ * This is designed to allow btrfs_find_all_roots() to get correct new_roots
+ * result.
+ *
+ * However for old_roots there is no need to do backref walk at that time,
+ * since we search commit roots to walk backref and result will always be
+ * correct.
+ *
+ * Due to the nature of no lock version, we can't do backref there.
+ * So we must call btrfs_qgroup_trace_extent_post() after exiting
+ * spinlock context.
+ *
+ * TODO: If we can fix and prove btrfs_find_all_roots() can get correct result
+ * using current root, then we can move all expensive backref walk out of
+ * transaction committing, but not now as qgroup accounting will be wrong again.
+ */
+int btrfs_qgroup_trace_extent_post(struct btrfs_fs_info *fs_info,
+				   struct btrfs_qgroup_extent_record *qrecord);
+
 /*
  * Inform qgroup to trace one dirty extent, specified by @bytenr and
  * @num_bytes.
  * So qgroup can account it at commit trans time.
  *
- * Better encapsulated version.
+ * Better encapsulated version, with memory allocation and backref walk for
+ * commit roots.
+ * So this can sleep.
  *
  * Return 0 if the operation is done.
  * Return <0 for error, like memory allocation failure or invalid parameter

commit 003d7c59e8afc9b2c6b0d163e8e115406c4faecc
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jan 25 09:50:33 2017 -0500

    btrfs: allow unlink to exceed subvolume quota
    
    Once a qgroup limit is exceeded, it's impossible to restore normal
    operation to the subvolume without modifying the limit or removing
    the subvolume.  This is a surprising situation for many users used
    to the typical workflow with quotas on other file systems where it's
    possible to remove files until the used space is back under the limit.
    
    When we go to unlink a file and start the transaction, we'll hit
    the qgroup limit while trying to reserve space for the items we'll
    modify while removing the file.  We discussed last month how best
    to handle this situation and agreed that there is no perfect solution.
    The best principle-of-least-surprise solution is to handle it similarly
    to how we already handle ENOSPC when unlinking, which is to allow
    the operation to succeed with the expectation that it will ultimately
    release space under most circumstances.
    
    This patch modifies the transaction start path to select whether to
    honor the qgroups limits.  btrfs_start_transaction_fallback_global_rsv
    is the only caller that skips enforcement.  The reservation and tracking
    still happens normally -- it just skips the enforcement step.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 416ae8e1d23c..ee95f456a61f 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -181,7 +181,8 @@ int btrfs_qgroup_reserve_data(struct inode *inode, u64 start, u64 len);
 int btrfs_qgroup_release_data(struct inode *inode, u64 start, u64 len);
 int btrfs_qgroup_free_data(struct inode *inode, u64 start, u64 len);
 
-int btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes);
+int btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes,
+			      bool enforce);
 void btrfs_qgroup_free_meta_all(struct btrfs_root *root);
 void btrfs_qgroup_free_meta(struct btrfs_root *root, int num_bytes);
 void btrfs_qgroup_check_reserved_leak(struct inode *inode);

commit 2ff7e61e0d30ff166a2ae94575526bffe11fd1a8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:24 2016 -0400

    btrfs: take an fs_info directly when the root is not used otherwise
    
    There are loads of functions in btrfs that accept a root parameter
    but only use it to obtain an fs_info pointer.  Let's convert those to
    just accept an fs_info pointer directly.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 99c879dbedc1..416ae8e1d23c 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -129,7 +129,7 @@ int btrfs_qgroup_trace_extent(struct btrfs_trans_handle *trans,
  * Return <0 for error(ENOMEM)
  */
 int btrfs_qgroup_trace_leaf_items(struct btrfs_trans_handle *trans,
-				  struct btrfs_root *root,
+				  struct btrfs_fs_info *fs_info,
 				  struct extent_buffer *eb);
 /*
  * Inform qgroup to trace a whole subtree, including all its child tree

commit 33d1f05ccb698aa92db3e64a639ce523cf18a408
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Oct 18 09:31:28 2016 +0800

    btrfs: Export and move leaf/subtree qgroup helpers to qgroup.c
    
    Move account_shared_subtree() to qgroup.c and rename it to
    btrfs_qgroup_trace_subtree().
    
    Do the same thing for account_leaf_items() and rename it to
    btrfs_qgroup_trace_leaf_items().
    
    Since all these functions are only for qgroup, move them to qgroup.c and
    export them is more appropriate.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-and-Tested-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 9303e09c71dc..99c879dbedc1 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -122,6 +122,29 @@ int btrfs_qgroup_trace_extent(struct btrfs_trans_handle *trans,
 		struct btrfs_fs_info *fs_info, u64 bytenr, u64 num_bytes,
 		gfp_t gfp_flag);
 
+/*
+ * Inform qgroup to trace all leaf items of data
+ *
+ * Return 0 for success
+ * Return <0 for error(ENOMEM)
+ */
+int btrfs_qgroup_trace_leaf_items(struct btrfs_trans_handle *trans,
+				  struct btrfs_root *root,
+				  struct extent_buffer *eb);
+/*
+ * Inform qgroup to trace a whole subtree, including all its child tree
+ * blocks and data.
+ * The root tree block is specified by @root_eb.
+ *
+ * Normally used by relocation(tree block swap) and subvolume deletion.
+ *
+ * Return 0 for success
+ * Return <0 for error(ENOMEM or tree search error)
+ */
+int btrfs_qgroup_trace_subtree(struct btrfs_trans_handle *trans,
+			       struct btrfs_root *root,
+			       struct extent_buffer *root_eb,
+			       u64 root_gen, int root_level);
 int
 btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans,
 			    struct btrfs_fs_info *fs_info,

commit 50b3e040b7c092c3c157f3febaaac77038e9f6fd
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Oct 18 09:31:27 2016 +0800

    btrfs: qgroup: Rename functions to make it follow reserve,trace,account steps
    
    Rename btrfs_qgroup_insert_dirty_extent(_nolock) to
    btrfs_qgroup_trace_extent(_nolock), according to the new
    reserve/trace/account naming schema.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-and-Tested-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index a72bf2192757..9303e09c71dc 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -93,8 +93,8 @@ struct btrfs_delayed_extent_op;
 int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
 /*
- * Insert one dirty extent record into @delayed_refs, informing qgroup to
- * account that extent at commit trans time.
+ * Inform qgroup to trace one dirty extent, its info is recorded in @record.
+ * So qgroup can account it at commit trans time.
  *
  * No lock version, caller must acquire delayed ref lock and allocate memory.
  *
@@ -102,14 +102,15 @@ int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
  * Return >0 for existing record, caller can free @record safely.
  * Error is not possible
  */
-int btrfs_qgroup_insert_dirty_extent_nolock(
+int btrfs_qgroup_trace_extent_nolock(
 		struct btrfs_fs_info *fs_info,
 		struct btrfs_delayed_ref_root *delayed_refs,
 		struct btrfs_qgroup_extent_record *record);
 
 /*
- * Insert one dirty extent record into @delayed_refs, informing qgroup to
- * account that extent at commit trans time.
+ * Inform qgroup to trace one dirty extent, specified by @bytenr and
+ * @num_bytes.
+ * So qgroup can account it at commit trans time.
  *
  * Better encapsulated version.
  *
@@ -117,7 +118,7 @@ int btrfs_qgroup_insert_dirty_extent_nolock(
  * Return <0 for error, like memory allocation failure or invalid parameter
  * (NULL trans)
  */
-int btrfs_qgroup_insert_dirty_extent(struct btrfs_trans_handle *trans,
+int btrfs_qgroup_trace_extent(struct btrfs_trans_handle *trans,
 		struct btrfs_fs_info *fs_info, u64 bytenr, u64 num_bytes,
 		gfp_t gfp_flag);
 

commit 1d2beaa95b307db5aacd527065d16ed48854d04e
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Oct 18 09:31:26 2016 +0800

    btrfs: qgroup: Add comments explaining how btrfs qgroup works
    
    Add explaination how btrfs qgroups work.
    
    Qgroup is split into 3 main phrases:
    1) Reserve
       To ensure qgroup doesn't exceed its limit
    
    2) Trace
       To info qgroup to trace which extent
    
    3) Account
       Calculate qgroup number change for each traced extent.
    
    This should save quite some time for new developers.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 1bc64c864b62..a72bf2192757 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -22,6 +22,34 @@
 #include "ulist.h"
 #include "delayed-ref.h"
 
+/*
+ * Btrfs qgroup overview
+ *
+ * Btrfs qgroup splits into 3 main part:
+ * 1) Reserve
+ *    Reserve metadata/data space for incoming operations
+ *    Affect how qgroup limit works
+ *
+ * 2) Trace
+ *    Tell btrfs qgroup to trace dirty extents.
+ *
+ *    Dirty extents including:
+ *    - Newly allocated extents
+ *    - Extents going to be deleted (in this trans)
+ *    - Extents whose owner is going to be modified
+ *
+ *    This is the main part affects whether qgroup numbers will stay
+ *    consistent.
+ *    Btrfs qgroup can trace clean extents and won't cause any problem,
+ *    but it will consume extra CPU time, it should be avoided if possible.
+ *
+ * 3) Account
+ *    Btrfs qgroup will updates its numbers, based on dirty extents traced
+ *    in previous step.
+ *
+ *    Normally at qgroup rescan and transaction commit time.
+ */
+
 /*
  * Record a dirty extent, and info qgroup to update quota on it
  * TODO: Use kmem cache to alloc it.

commit cb93b52cc005ba0e470845b519c662e661d5113c
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Aug 15 10:36:50 2016 +0800

    btrfs: qgroup: Refactor btrfs_qgroup_insert_dirty_extent()
    
    Refactor btrfs_qgroup_insert_dirty_extent() function, to two functions:
    1. btrfs_qgroup_insert_dirty_extent_nolock()
       Almost the same with original code.
       For delayed_ref usage, which has delayed refs locked.
    
       Change the return value type to int, since caller never needs the
       pointer, but only needs to know if they need to free the allocated
       memory.
    
    2. btrfs_qgroup_insert_dirty_extent()
       The more encapsulated version.
    
       Will do the delayed_refs lock, memory allocation, quota enabled check
       and other things.
    
    The original design is to keep exported functions to minimal, but since
    more btrfs hacks exposed, like replacing path in balance, we need to
    record dirty extents manually, so we have to add such functions.
    
    Also, add comment for both functions, to info developers how to keep
    qgroup correct when doing hacks.
    
    Cc: Mark Fasheh <mfasheh@suse.de>
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Reviewed-and-Tested-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index af3e5578cad7..1bc64c864b62 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -64,10 +64,35 @@ void btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info);
 struct btrfs_delayed_extent_op;
 int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
-struct btrfs_qgroup_extent_record *
-btrfs_qgroup_insert_dirty_extent(struct btrfs_fs_info *fs_info,
-				 struct btrfs_delayed_ref_root *delayed_refs,
-				 struct btrfs_qgroup_extent_record *record);
+/*
+ * Insert one dirty extent record into @delayed_refs, informing qgroup to
+ * account that extent at commit trans time.
+ *
+ * No lock version, caller must acquire delayed ref lock and allocate memory.
+ *
+ * Return 0 for success insert
+ * Return >0 for existing record, caller can free @record safely.
+ * Error is not possible
+ */
+int btrfs_qgroup_insert_dirty_extent_nolock(
+		struct btrfs_fs_info *fs_info,
+		struct btrfs_delayed_ref_root *delayed_refs,
+		struct btrfs_qgroup_extent_record *record);
+
+/*
+ * Insert one dirty extent record into @delayed_refs, informing qgroup to
+ * account that extent at commit trans time.
+ *
+ * Better encapsulated version.
+ *
+ * Return 0 if the operation is done.
+ * Return <0 for error, like memory allocation failure or invalid parameter
+ * (NULL trans)
+ */
+int btrfs_qgroup_insert_dirty_extent(struct btrfs_trans_handle *trans,
+		struct btrfs_fs_info *fs_info, u64 bytenr, u64 num_bytes,
+		gfp_t gfp_flag);
+
 int
 btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans,
 			    struct btrfs_fs_info *fs_info,

commit d06f23d6a947c9abae41dc46be69a56baf36f436
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Aug 8 22:08:06 2016 -0400

    btrfs: waiting on qgroup rescan should not always be interruptible
    
    We wait on qgroup rescan completion in three places: file system
    shutdown, the quota disable ioctl, and the rescan wait ioctl.  If the
    user sends a signal while we're waiting, we continue happily along.  This
    is expected behavior for the rescan wait ioctl.  It's racy in the shutdown
    path but mostly works due to other unrelated synchronization points.
    In the quota disable path, it Oopses the kernel pretty much immediately.
    
    Cc: <stable@vger.kernel.org> # v4.4+
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 710887c06aaf..af3e5578cad7 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -46,7 +46,8 @@ int btrfs_quota_disable(struct btrfs_trans_handle *trans,
 			struct btrfs_fs_info *fs_info);
 int btrfs_qgroup_rescan(struct btrfs_fs_info *fs_info);
 void btrfs_qgroup_rescan_resume(struct btrfs_fs_info *fs_info);
-int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info);
+int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info,
+				     bool interruptible);
 int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,
 			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
 int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,

commit bc074524e123ded281cde25ebc5661910f9679e3
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Jun 9 17:27:55 2016 -0400

    btrfs: prefix fsid to all trace events
    
    When using trace events to debug a problem, it's impossible to determine
    which file system generated a particular event.  This patch adds a
    macro to prefix standard information to the head of a trace event.
    
    The extent_state alloc/free events are all that's left without an
    fs_info available.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index ecb2c143ef75..710887c06aaf 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -63,9 +63,10 @@ void btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info);
 struct btrfs_delayed_extent_op;
 int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
-struct btrfs_qgroup_extent_record
-*btrfs_qgroup_insert_dirty_extent(struct btrfs_delayed_ref_root *delayed_refs,
-				  struct btrfs_qgroup_extent_record *record);
+struct btrfs_qgroup_extent_record *
+btrfs_qgroup_insert_dirty_extent(struct btrfs_fs_info *fs_info,
+				 struct btrfs_delayed_ref_root *delayed_refs,
+				 struct btrfs_qgroup_extent_record *record);
 int
 btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans,
 			    struct btrfs_fs_info *fs_info,
@@ -88,7 +89,7 @@ static inline void btrfs_qgroup_free_delayed_ref(struct btrfs_fs_info *fs_info,
 						 u64 ref_root, u64 num_bytes)
 {
 	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes);
-	trace_btrfs_qgroup_free_delayed_ref(ref_root, num_bytes);
+	trace_btrfs_qgroup_free_delayed_ref(fs_info, ref_root, num_bytes);
 }
 void assert_qgroups_uptodate(struct btrfs_trans_handle *trans);
 

commit 56fa9d0762ed17153c1bdff3c0aeeecbe522b504
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Oct 13 09:53:10 2015 +0800

    btrfs: qgroup: Check if qgroup reserved space leaked
    
    Add check at btrfs_destroy_inode() time to detect qgroup reserved space
    leak.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 686b60f60b61..ecb2c143ef75 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -105,4 +105,5 @@ int btrfs_qgroup_free_data(struct inode *inode, u64 start, u64 len);
 int btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes);
 void btrfs_qgroup_free_meta_all(struct btrfs_root *root);
 void btrfs_qgroup_free_meta(struct btrfs_root *root, int num_bytes);
+void btrfs_qgroup_check_reserved_leak(struct inode *inode);
 #endif /* __BTRFS_QGROUP__ */

commit 81fb6f77a02678ddb0755c24f83c4ed5207da046
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Sep 28 16:57:53 2015 +0800

    btrfs: qgroup: Add new trace point for qgroup data reserve
    
    Now each qgroup reserve for data will has its ftrace event for better
    debugging.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index adb03da3d298..686b60f60b61 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -33,6 +33,13 @@ struct btrfs_qgroup_extent_record {
 	struct ulist *old_roots;
 };
 
+/*
+ * For qgroup event trace points only
+ */
+#define QGROUP_RESERVE		(1<<0)
+#define QGROUP_RELEASE		(1<<1)
+#define QGROUP_FREE		(1<<2)
+
 int btrfs_quota_enable(struct btrfs_trans_handle *trans,
 		       struct btrfs_fs_info *fs_info);
 int btrfs_quota_disable(struct btrfs_trans_handle *trans,
@@ -81,6 +88,7 @@ static inline void btrfs_qgroup_free_delayed_ref(struct btrfs_fs_info *fs_info,
 						 u64 ref_root, u64 num_bytes)
 {
 	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes);
+	trace_btrfs_qgroup_free_delayed_ref(ref_root, num_bytes);
 }
 void assert_qgroups_uptodate(struct btrfs_trans_handle *trans);
 

commit 7cf5b97650f2ecefbd5afa2d58b61b289b6e3750
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 8 17:25:55 2015 +0800

    btrfs: qgroup: Cleanup old inaccurate facilities
    
    Cleanup the old facilities which use old btrfs_qgroup_reserve() function
    call, replace them with the newer version, and remove the "__" prefix in
    them.
    
    Also, make btrfs_qgroup_reserve/free() functions private, as they are
    now only used inside qgroup codes.
    
    Now, the whole btrfs qgroup is swithed to use the new reserve facilities.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 7d1c87cd3c78..adb03da3d298 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -71,15 +71,8 @@ int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
 int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
 			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
 			 struct btrfs_qgroup_inherit *inherit);
-int btrfs_qgroup_reserve(struct btrfs_root *root, u64 num_bytes);
 void btrfs_qgroup_free_refroot(struct btrfs_fs_info *fs_info,
 			       u64 ref_root, u64 num_bytes);
-static inline void btrfs_qgroup_free(struct btrfs_root *root, u64 num_bytes)
-{
-	return btrfs_qgroup_free_refroot(root->fs_info, root->objectid,
-					 num_bytes);
-}
-
 /*
  * TODO: Add proper trace point for it, as btrfs_qgroup_free() is
  * called by everywhere, can't provide good trace for delayed ref case.
@@ -89,7 +82,6 @@ static inline void btrfs_qgroup_free_delayed_ref(struct btrfs_fs_info *fs_info,
 {
 	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes);
 }
-
 void assert_qgroups_uptodate(struct btrfs_trans_handle *trans);
 
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS

commit 55eeaf0578038c40baaf3cf9408c23e42cd2a2b8
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 8 17:08:38 2015 +0800

    btrfs: qgroup: Introduce new functions to reserve/free metadata
    
    Introduce new functions btrfs_qgroup_reserve/free_meta() to reserve/free
    metadata reserved space.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 80924aeceb09..7d1c87cd3c78 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -101,4 +101,8 @@ int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,
 int btrfs_qgroup_reserve_data(struct inode *inode, u64 start, u64 len);
 int btrfs_qgroup_release_data(struct inode *inode, u64 start, u64 len);
 int btrfs_qgroup_free_data(struct inode *inode, u64 start, u64 len);
+
+int btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes);
+void btrfs_qgroup_free_meta_all(struct btrfs_root *root);
+void btrfs_qgroup_free_meta(struct btrfs_root *root, int num_bytes);
 #endif /* __BTRFS_QGROUP__ */

commit 297d750b9f8d7e6f2dbdf8abc5aa3b5c656affdc
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 8 17:08:37 2015 +0800

    btrfs: delayed_ref: release and free qgroup reserved at proper timing
    
    Qgroup reserved space needs to be released from inode dirty map and get
    freed at different timing:
    
    1) Release when the metadata is written into tree
    After corresponding metadata is written into tree, any newer write will
    be COWed(don't include NOCOW case yet).
    So we must release its range from inode dirty range map, or we will
    forget to reserve needed range, causing accounting exceeding the limit.
    
    2) Free reserved bytes when delayed ref is run
    When delayed refs are run, qgroup accounting will follow soon and turn
    the reserved bytes into rfer/excl numbers.
    As run_delayed_refs and qgroup accounting are all done at
    commit_transaction() time, we are safe to free reserved space in
    run_delayed_ref time().
    
    With these timing to release/free reserved space, we should be able to
    resolve the long existing qgroup reserve space leak problem.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 564eb2147740..80924aeceb09 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -72,7 +72,23 @@ int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
 			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
 			 struct btrfs_qgroup_inherit *inherit);
 int btrfs_qgroup_reserve(struct btrfs_root *root, u64 num_bytes);
-void btrfs_qgroup_free(struct btrfs_root *root, u64 num_bytes);
+void btrfs_qgroup_free_refroot(struct btrfs_fs_info *fs_info,
+			       u64 ref_root, u64 num_bytes);
+static inline void btrfs_qgroup_free(struct btrfs_root *root, u64 num_bytes)
+{
+	return btrfs_qgroup_free_refroot(root->fs_info, root->objectid,
+					 num_bytes);
+}
+
+/*
+ * TODO: Add proper trace point for it, as btrfs_qgroup_free() is
+ * called by everywhere, can't provide good trace for delayed ref case.
+ */
+static inline void btrfs_qgroup_free_delayed_ref(struct btrfs_fs_info *fs_info,
+						 u64 ref_root, u64 num_bytes)
+{
+	btrfs_qgroup_free_refroot(fs_info, ref_root, num_bytes);
+}
 
 void assert_qgroups_uptodate(struct btrfs_trans_handle *trans);
 

commit f695fdcef83ac6972e0eda1d6588a56348f521a2
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Oct 12 16:28:06 2015 +0800

    btrfs: qgroup: Introduce functions to release/free qgroup reserve data
    space
    
    Introduce functions btrfs_qgroup_release/free_data() to release/free
    reserved data range.
    
    Release means, just remove the data range from io_tree, but doesn't
    free the reserved space.
    This is for normal buffered write case, when data is written into disc
    and its metadata is added into tree, its reserved space should still be
    kept until commit_trans().
    So in that case, we only release dirty range, but keep the reserved
    space recorded some other place until commit_tran().
    
    Free means not only remove data range, but also free reserved space.
    This is used for case for cleanup and invalidate page.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index bd17cc24335c..564eb2147740 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -83,4 +83,6 @@ int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,
 
 /* New io_tree based accurate qgroup reserve API */
 int btrfs_qgroup_reserve_data(struct inode *inode, u64 start, u64 len);
+int btrfs_qgroup_release_data(struct inode *inode, u64 start, u64 len);
+int btrfs_qgroup_free_data(struct inode *inode, u64 start, u64 len);
 #endif /* __BTRFS_QGROUP__ */

commit 524725537023bb25a371722b1329446e5a2adcdb
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Oct 12 16:05:40 2015 +0800

    btrfs: qgroup: Introduce btrfs_qgroup_reserve_data function
    
    Introduce a new function, btrfs_qgroup_reserve_data(), which will use
    io_tree to accurate qgroup reserve, to avoid reserved space leaking.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 6387dcfa354c..bd17cc24335c 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -81,4 +81,6 @@ int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,
 			       u64 rfer, u64 excl);
 #endif
 
+/* New io_tree based accurate qgroup reserve API */
+int btrfs_qgroup_reserve_data(struct inode *inode, u64 start, u64 len);
 #endif /* __BTRFS_QGROUP__ */

commit e69bcee37692f5d8c557335ddd2444cb4afe0005
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Fri Apr 17 10:23:16 2015 +0800

    btrfs: qgroup: Cleanup the old ref_node-oriented mechanism.
    
    Goodbye, the old mechanisim.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 90998b5e1713..6387dcfa354c 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -22,45 +22,6 @@
 #include "ulist.h"
 #include "delayed-ref.h"
 
-/*
- * A description of the operations, all of these operations only happen when we
- * are adding the 1st reference for that subvolume in the case of adding space
- * or on the last reference delete in the case of subtraction.  The only
- * exception is the last one, which is added for confusion.
- *
- * BTRFS_QGROUP_OPER_ADD_EXCL: adding bytes where this subvolume is the only
- * one pointing at the bytes we are adding.  This is called on the first
- * allocation.
- *
- * BTRFS_QGROUP_OPER_ADD_SHARED: adding bytes where this bytenr is going to be
- * shared between subvols.  This is called on the creation of a ref that already
- * has refs from a different subvolume, so basically reflink.
- *
- * BTRFS_QGROUP_OPER_SUB_EXCL: removing bytes where this subvolume is the only
- * one referencing the range.
- *
- * BTRFS_QGROUP_OPER_SUB_SHARED: removing bytes where this subvolume shares with
- * refs with other subvolumes.
- */
-enum btrfs_qgroup_operation_type {
-	BTRFS_QGROUP_OPER_ADD_EXCL,
-	BTRFS_QGROUP_OPER_ADD_SHARED,
-	BTRFS_QGROUP_OPER_SUB_EXCL,
-	BTRFS_QGROUP_OPER_SUB_SHARED,
-	BTRFS_QGROUP_OPER_SUB_SUBTREE,
-};
-
-struct btrfs_qgroup_operation {
-	u64 ref_root;
-	u64 bytenr;
-	u64 num_bytes;
-	u64 seq;
-	enum btrfs_qgroup_operation_type type;
-	struct seq_list elem;
-	struct rb_node n;
-	struct list_head list;
-};
-
 /*
  * Record a dirty extent, and info qgroup to update quota on it
  * TODO: Use kmem cache to alloc it.
@@ -93,11 +54,6 @@ int btrfs_limit_qgroup(struct btrfs_trans_handle *trans,
 int btrfs_read_qgroup_config(struct btrfs_fs_info *fs_info);
 void btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info);
 struct btrfs_delayed_extent_op;
-int btrfs_qgroup_record_ref(struct btrfs_trans_handle *trans,
-			    struct btrfs_fs_info *fs_info, u64 ref_root,
-			    u64 bytenr, u64 num_bytes,
-			    enum btrfs_qgroup_operation_type type,
-			    int mod_seq);
 int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
 					 struct btrfs_fs_info *fs_info);
 struct btrfs_qgroup_extent_record
@@ -110,11 +66,6 @@ btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans,
 			    struct ulist *old_roots, struct ulist *new_roots);
 int btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans,
 				 struct btrfs_fs_info *fs_info);
-int btrfs_delayed_qgroup_accounting(struct btrfs_trans_handle *trans,
-				    struct btrfs_fs_info *fs_info);
-void btrfs_remove_qgroup_operation(struct btrfs_trans_handle *trans,
-				   struct btrfs_fs_info *fs_info,
-				   struct btrfs_qgroup_operation *oper);
 int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
 		      struct btrfs_fs_info *fs_info);
 int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,

commit 442244c9633292a147ab2b29e7007a7c8a3909b2
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Thu Apr 16 17:18:36 2015 +0800

    btrfs: qgroup: Switch self test to extent-oriented qgroup mechanism.
    
    Since the self test transaction don't have delayed_ref_roots, so use
    find_all_roots() and export btrfs_qgroup_account_extent() to simulate it
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index cb703f859af6..90998b5e1713 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -103,6 +103,11 @@ int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
 struct btrfs_qgroup_extent_record
 *btrfs_qgroup_insert_dirty_extent(struct btrfs_delayed_ref_root *delayed_refs,
 				  struct btrfs_qgroup_extent_record *record);
+int
+btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans,
+			    struct btrfs_fs_info *fs_info,
+			    u64 bytenr, u64 num_bytes,
+			    struct ulist *old_roots, struct ulist *new_roots);
 int btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans,
 				 struct btrfs_fs_info *fs_info);
 int btrfs_delayed_qgroup_accounting(struct btrfs_trans_handle *trans,

commit 550d7a2ed5db35756222ec17cff3376ff38d78e2
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Thu Apr 16 15:37:33 2015 +0800

    btrfs: qgroup: Add new qgroup calculation function
    btrfs_qgroup_account_extents().
    
    The new btrfs_qgroup_account_extents() function should be called in
    btrfs_commit_transaction() and it will update all the qgroup according
    to delayed_ref_root->dirty_extent_root.
    
    The new function can handle both normal operation during
    commit_transaction() or in rescan in a unified method with clearer
    logic.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 6fe249f078ac..cb703f859af6 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -103,6 +103,8 @@ int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
 struct btrfs_qgroup_extent_record
 *btrfs_qgroup_insert_dirty_extent(struct btrfs_delayed_ref_root *delayed_refs,
 				  struct btrfs_qgroup_extent_record *record);
+int btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans,
+				 struct btrfs_fs_info *fs_info);
 int btrfs_delayed_qgroup_accounting(struct btrfs_trans_handle *trans,
 				    struct btrfs_fs_info *fs_info);
 void btrfs_remove_qgroup_operation(struct btrfs_trans_handle *trans,

commit 3b7d00f99c60b31e1cff0efc6b9178eea3696e27
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Thu Apr 16 16:40:39 2015 +0800

    btrfs: qgroup: Add new function to record old_roots.
    
    Add function btrfs_qgroup_prepare_account_extents() to get old_roots
    which are needed for qgroup.
    
    We do it in commit_transaction() and before switch_roots(), and only
    search commit_root, so it gives a quite accurate view for previous
    transaction.
    
    With old_roots from previous transaction, we can use it to do accurate
    account with current transaction.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index e58155d0390c..6fe249f078ac 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -98,6 +98,8 @@ int btrfs_qgroup_record_ref(struct btrfs_trans_handle *trans,
 			    u64 bytenr, u64 num_bytes,
 			    enum btrfs_qgroup_operation_type type,
 			    int mod_seq);
+int btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,
+					 struct btrfs_fs_info *fs_info);
 struct btrfs_qgroup_extent_record
 *btrfs_qgroup_insert_dirty_extent(struct btrfs_delayed_ref_root *delayed_refs,
 				  struct btrfs_qgroup_extent_record *record);

commit 3368d001ba5df44930d986e82b1b497d4da285ba
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Thu Apr 16 14:34:17 2015 +0800

    btrfs: qgroup: Record possible quota-related extent for qgroup.
    
    Add hook in add_delayed_ref_head() to record quota-related extent record
    into delayed_ref_root->dirty_extent_record rb-tree for later qgroup
    accounting.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index c5242aa9a4b2..e58155d0390c 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -19,6 +19,9 @@
 #ifndef __BTRFS_QGROUP__
 #define __BTRFS_QGROUP__
 
+#include "ulist.h"
+#include "delayed-ref.h"
+
 /*
  * A description of the operations, all of these operations only happen when we
  * are adding the 1st reference for that subvolume in the case of adding space
@@ -58,6 +61,17 @@ struct btrfs_qgroup_operation {
 	struct list_head list;
 };
 
+/*
+ * Record a dirty extent, and info qgroup to update quota on it
+ * TODO: Use kmem cache to alloc it.
+ */
+struct btrfs_qgroup_extent_record {
+	struct rb_node node;
+	u64 bytenr;
+	u64 num_bytes;
+	struct ulist *old_roots;
+};
+
 int btrfs_quota_enable(struct btrfs_trans_handle *trans,
 		       struct btrfs_fs_info *fs_info);
 int btrfs_quota_disable(struct btrfs_trans_handle *trans,
@@ -84,6 +98,9 @@ int btrfs_qgroup_record_ref(struct btrfs_trans_handle *trans,
 			    u64 bytenr, u64 num_bytes,
 			    enum btrfs_qgroup_operation_type type,
 			    int mod_seq);
+struct btrfs_qgroup_extent_record
+*btrfs_qgroup_insert_dirty_extent(struct btrfs_delayed_ref_root *delayed_refs,
+				  struct btrfs_qgroup_extent_record *record);
 int btrfs_delayed_qgroup_accounting(struct btrfs_trans_handle *trans,
 				    struct btrfs_fs_info *fs_info);
 void btrfs_remove_qgroup_operation(struct btrfs_trans_handle *trans,

commit e2d1f92399afb6ec518b68867ed10db2585b283a
Author: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
Date:   Fri Feb 6 10:26:52 2015 -0500

    btrfs: qgroup: do a reservation in a higher level.
    
    There are two problems in qgroup:
    
    a). The PAGE_CACHE is 4K, even when we are writing a data of 1K,
    qgroup will reserve a 4K size. It will cause the last 3K in a qgroup
    is not available to user.
    
    b). When user is writing a inline data, qgroup will not reserve it,
    it means this is a window we can exceed the limit of a qgroup.
    
    The main idea of this patch is reserving the data size of write_bytes
    rather than the reserve_bytes. It means qgroup will not care about
    the data size btrfs will reserve for user, but only care about the
    data size user is going to write. Then reserve it when user want to
    write and release it in transaction committed.
    
    In this way, qgroup can be released from the complex procedure in
    btrfs and only do the reserve when user want to write and account
    when the data is written in commit_transaction().
    
    Signed-off-by: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 64d49b8482b3..c5242aa9a4b2 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -94,10 +94,6 @@ int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
 int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
 			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
 			 struct btrfs_qgroup_inherit *inherit);
-int btrfs_qgroup_update_reserved_bytes(struct btrfs_fs_info *fs_info,
-				       u64 ref_root,
-				       u64 num_bytes,
-				       int sign);
 int btrfs_qgroup_reserve(struct btrfs_root *root, u64 num_bytes);
 void btrfs_qgroup_free(struct btrfs_root *root, u64 num_bytes);
 

commit 31193213f1f9c13f6485007ef1e233b119e46910
Author: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
Date:   Fri Dec 12 16:44:35 2014 +0800

    Btrfs: qgroup: Introduce a may_use to account space_info->bytes_may_use.
    
    Currently, for pre_alloc or delay_alloc, the bytes will be accounted
    in space_info by the three guys.
    space_info->bytes_may_use --- space_info->reserved --- space_info->used.
    But on the other hand, in qgroup, there are only two counters to account the
    bytes, qgroup->reserved and qgroup->excl. And qg->reserved accounts
    bytes in space_info->bytes_may_use and qg->excl accounts bytes in
    space_info->used. So the bytes in space_info->reserved is not accounted
    in qgroup. If so, there is a window we can exceed the quota limit when
    bytes is in space_info->reserved.
    
    Example:
            # btrfs quota enable /mnt
            # btrfs qgroup limit -e 10M /mnt
            # for((i=0;i<20;i++));do fallocate -l 1M /mnt/data$i; done
            # sync
            # btrfs qgroup show -pcre /mnt
    qgroupid rfer     excl     max_rfer max_excl parent  child
    -------- ----     ----     -------- -------- ------  -----
    0/5      20987904 20987904 0        10485760 ---     ---
    
    qg->excl is 20987904 larger than max_excl 10485760.
    
    This patch introduce a new counter named may_use to qgroup, then
    there are three counters in qgroup to account bytes in space_info
    as below.
    space_info->bytes_may_use --- space_info->reserved --- space_info->used.
    qgroup->may_use           --- qgroup->reserved     --- qgroup->excl
    
    With this patch applied:
            # btrfs quota enable /mnt
            # btrfs qgroup limit -e 10M /mnt
            # for((i=0;i<20;i++));do fallocate -l 1M /mnt/data$i; done
    fallocate: /mnt/data9: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data10: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data11: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data12: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data13: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data14: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data15: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data16: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data17: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data18: fallocate failed: Disk quota exceeded
    fallocate: /mnt/data19: fallocate failed: Disk quota exceeded
            # sync
            # btrfs qgroup show -pcre /mnt
    qgroupid rfer    excl    max_rfer max_excl parent  child
    -------- ----    ----    -------- -------- ------  -----
    0/5      9453568 9453568 0        10485760 ---     ---
    
    Reported-by: Cyril SCETBON <cyril.scetbon@free.fr>
    Signed-off-by: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index c5242aa9a4b2..64d49b8482b3 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -94,6 +94,10 @@ int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
 int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
 			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
 			 struct btrfs_qgroup_inherit *inherit);
+int btrfs_qgroup_update_reserved_bytes(struct btrfs_fs_info *fs_info,
+				       u64 ref_root,
+				       u64 num_bytes,
+				       int sign);
 int btrfs_qgroup_reserve(struct btrfs_root *root, u64 num_bytes);
 void btrfs_qgroup_free(struct btrfs_root *root, u64 num_bytes);
 

commit 4087cf24ae2af17f7dd9fd34e22fde816952d421
Author: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
Date:   Sun Jan 18 10:59:23 2015 -0500

    Btrfs: qgroup: cleanup, remove an unsued parameter in btrfs_create_qgroup().
    
    Signed-off-by: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 18cc68ca3090..c5242aa9a4b2 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -70,8 +70,7 @@ int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,
 int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,
 			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
 int btrfs_create_qgroup(struct btrfs_trans_handle *trans,
-			struct btrfs_fs_info *fs_info, u64 qgroupid,
-			char *name);
+			struct btrfs_fs_info *fs_info, u64 qgroupid);
 int btrfs_remove_qgroup(struct btrfs_trans_handle *trans,
 			      struct btrfs_fs_info *fs_info, u64 qgroupid);
 int btrfs_limit_qgroup(struct btrfs_trans_handle *trans,

commit 1152651a081720ef6a8c76bb7da676e8c900ac30
Author: Mark Fasheh <mfasheh@suse.de>
Date:   Thu Jul 17 12:39:01 2014 -0700

    btrfs: qgroup: account shared subtrees during snapshot delete
    
    During its tree walk, btrfs_drop_snapshot() will skip any shared
    subtrees it encounters. This is incorrect when we have qgroups
    turned on as those subtrees need to have their contents
    accounted. In particular, the case we're concerned with is when
    removing our snapshot root leaves the subtree with only one root
    reference.
    
    In those cases we need to find the last remaining root and add
    each extent in the subtree to the corresponding qgroup exclusive
    counts.
    
    This patch implements the shared subtree walk and a new qgroup
    operation, BTRFS_QGROUP_OPER_SUB_SUBTREE. When an operation of
    this type is encountered during qgroup accounting, we search for
    any root references to that extent and in the case that we find
    only one reference left, we go ahead and do the math on it's
    exclusive counts.
    
    Signed-off-by: Mark Fasheh <mfasheh@suse.de>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
index 5952ff1fbd7a..18cc68ca3090 100644
--- a/fs/btrfs/qgroup.h
+++ b/fs/btrfs/qgroup.h
@@ -44,6 +44,7 @@ enum btrfs_qgroup_operation_type {
 	BTRFS_QGROUP_OPER_ADD_SHARED,
 	BTRFS_QGROUP_OPER_SUB_EXCL,
 	BTRFS_QGROUP_OPER_SUB_SHARED,
+	BTRFS_QGROUP_OPER_SUB_SUBTREE,
 };
 
 struct btrfs_qgroup_operation {

commit fcebe4562dec83b3f8d3088d77584727b09130b2
Author: Josef Bacik <jbacik@fb.com>
Date:   Tue May 13 17:30:47 2014 -0700

    Btrfs: rework qgroup accounting
    
    Currently qgroups account for space by intercepting delayed ref updates to fs
    trees.  It does this by adding sequence numbers to delayed ref updates so that
    it can figure out how the tree looked before the update so we can adjust the
    counters properly.  The problem with this is that it does not allow delayed refs
    to be merged, so if you say are defragging an extent with 5k snapshots pointing
    to it we will thrash the delayed ref lock because we need to go back and
    manually merge these things together.  Instead we want to process quota changes
    when we know they are going to happen, like when we first allocate an extent, we
    free a reference for an extent, we add new references etc.  This patch
    accomplishes this by only adding qgroup operations for real ref changes.  We
    only modify the sequence number when we need to lookup roots for bytenrs, this
    reduces the amount of churn on the sequence number and allows us to merge
    delayed refs as we add them most of the time.  This patch encompasses a bunch of
    architectural changes
    
    1) qgroup ref operations: instead of tracking qgroup operations through the
    delayed refs we simply add new ref operations whenever we notice that we need to
    when we've modified the refs themselves.
    
    2) tree mod seq:  we no longer have this separation of major/minor counters.
    this makes the sequence number stuff much more sane and we can remove some
    locking that was needed to protect the counter.
    
    3) delayed ref seq: we now read the tree mod seq number and use that as our
    sequence.  This means each new delayed ref doesn't have it's own unique sequence
    number, rather whenever we go to lookup backrefs we inc the sequence number so
    we can make sure to keep any new operations from screwing up our world view at
    that given point.  This allows us to merge delayed refs during runtime.
    
    With all of these changes the delayed ref stuff is a little saner and the qgroup
    accounting stuff no longer goes negative in some cases like it was before.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/qgroup.h b/fs/btrfs/qgroup.h
new file mode 100644
index 000000000000..5952ff1fbd7a
--- /dev/null
+++ b/fs/btrfs/qgroup.h
@@ -0,0 +1,107 @@
+/*
+ * Copyright (C) 2014 Facebook.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
+#ifndef __BTRFS_QGROUP__
+#define __BTRFS_QGROUP__
+
+/*
+ * A description of the operations, all of these operations only happen when we
+ * are adding the 1st reference for that subvolume in the case of adding space
+ * or on the last reference delete in the case of subtraction.  The only
+ * exception is the last one, which is added for confusion.
+ *
+ * BTRFS_QGROUP_OPER_ADD_EXCL: adding bytes where this subvolume is the only
+ * one pointing at the bytes we are adding.  This is called on the first
+ * allocation.
+ *
+ * BTRFS_QGROUP_OPER_ADD_SHARED: adding bytes where this bytenr is going to be
+ * shared between subvols.  This is called on the creation of a ref that already
+ * has refs from a different subvolume, so basically reflink.
+ *
+ * BTRFS_QGROUP_OPER_SUB_EXCL: removing bytes where this subvolume is the only
+ * one referencing the range.
+ *
+ * BTRFS_QGROUP_OPER_SUB_SHARED: removing bytes where this subvolume shares with
+ * refs with other subvolumes.
+ */
+enum btrfs_qgroup_operation_type {
+	BTRFS_QGROUP_OPER_ADD_EXCL,
+	BTRFS_QGROUP_OPER_ADD_SHARED,
+	BTRFS_QGROUP_OPER_SUB_EXCL,
+	BTRFS_QGROUP_OPER_SUB_SHARED,
+};
+
+struct btrfs_qgroup_operation {
+	u64 ref_root;
+	u64 bytenr;
+	u64 num_bytes;
+	u64 seq;
+	enum btrfs_qgroup_operation_type type;
+	struct seq_list elem;
+	struct rb_node n;
+	struct list_head list;
+};
+
+int btrfs_quota_enable(struct btrfs_trans_handle *trans,
+		       struct btrfs_fs_info *fs_info);
+int btrfs_quota_disable(struct btrfs_trans_handle *trans,
+			struct btrfs_fs_info *fs_info);
+int btrfs_qgroup_rescan(struct btrfs_fs_info *fs_info);
+void btrfs_qgroup_rescan_resume(struct btrfs_fs_info *fs_info);
+int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info);
+int btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,
+			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
+int btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,
+			      struct btrfs_fs_info *fs_info, u64 src, u64 dst);
+int btrfs_create_qgroup(struct btrfs_trans_handle *trans,
+			struct btrfs_fs_info *fs_info, u64 qgroupid,
+			char *name);
+int btrfs_remove_qgroup(struct btrfs_trans_handle *trans,
+			      struct btrfs_fs_info *fs_info, u64 qgroupid);
+int btrfs_limit_qgroup(struct btrfs_trans_handle *trans,
+		       struct btrfs_fs_info *fs_info, u64 qgroupid,
+		       struct btrfs_qgroup_limit *limit);
+int btrfs_read_qgroup_config(struct btrfs_fs_info *fs_info);
+void btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info);
+struct btrfs_delayed_extent_op;
+int btrfs_qgroup_record_ref(struct btrfs_trans_handle *trans,
+			    struct btrfs_fs_info *fs_info, u64 ref_root,
+			    u64 bytenr, u64 num_bytes,
+			    enum btrfs_qgroup_operation_type type,
+			    int mod_seq);
+int btrfs_delayed_qgroup_accounting(struct btrfs_trans_handle *trans,
+				    struct btrfs_fs_info *fs_info);
+void btrfs_remove_qgroup_operation(struct btrfs_trans_handle *trans,
+				   struct btrfs_fs_info *fs_info,
+				   struct btrfs_qgroup_operation *oper);
+int btrfs_run_qgroups(struct btrfs_trans_handle *trans,
+		      struct btrfs_fs_info *fs_info);
+int btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,
+			 struct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,
+			 struct btrfs_qgroup_inherit *inherit);
+int btrfs_qgroup_reserve(struct btrfs_root *root, u64 num_bytes);
+void btrfs_qgroup_free(struct btrfs_root *root, u64 num_bytes);
+
+void assert_qgroups_uptodate(struct btrfs_trans_handle *trans);
+
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+int btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,
+			       u64 rfer, u64 excl);
+#endif
+
+#endif /* __BTRFS_QGROUP__ */
