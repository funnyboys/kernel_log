commit 7fe6d45e4009d9502fef32ac6222862ac17f8674
Author: Dennis Zhou <dennis@kernel.org>
Date:   Thu Jan 2 16:26:39 2020 -0500

    btrfs: have multiple discard lists
    
    Non-block group destruction discarding currently only had a single list
    with no minimum discard length. This can lead to caravaning more
    meaningful discards behind a heavily fragmented block group.
    
    This adds support for multiple lists with minimum discard lengths to
    prevent the caravan effect. We promote block groups back up when we
    exceed the BTRFS_ASYNC_DISCARD_MAX_FILTER size, currently we support
    only 2 lists with filters of 1MB and 32KB respectively.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 5018190a49a3..2e0a8077aa74 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -146,7 +146,7 @@ int btrfs_trim_block_group_extents(struct btrfs_block_group *block_group,
 				   bool async);
 int btrfs_trim_block_group_bitmaps(struct btrfs_block_group *block_group,
 				   u64 *trimmed, u64 start, u64 end, u64 minlen,
-				   bool async);
+				   u64 maxlen, bool async);
 
 /* Support functions for running our sanity tests */
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS

commit 5dc7c10b87474c98116d3438739743cd77263e9f
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:21 2019 -0800

    btrfs: keep track of discardable_bytes for async discard
    
    Keep track of this metric so that we can understand how ahead or behind
    we are in discarding rate. This uses the same accounting method as
    discardable_extents, deltas between previous/current values and
    propagating them up.
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index bd1e7a542271..5018190a49a3 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -52,6 +52,7 @@ struct btrfs_free_space_ctl {
 	int unit;
 	u64 start;
 	s32 discardable_extents[BTRFS_STAT_NR_ENTRIES];
+	s64 discardable_bytes[BTRFS_STAT_NR_ENTRIES];
 	const struct btrfs_free_space_op *op;
 	void *private;
 	struct mutex cache_writeout_mutex;

commit dfb79ddb130e0a239e3e90aaf5f5b908555f52bb
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:20 2019 -0800

    btrfs: track discardable extents for async discard
    
    The number of discardable extents will serve as the rate limiting metric
    for how often we should discard. This keeps track of discardable extents
    in the free space caches by maintaining deltas and propagating them to
    the global count.
    
    The deltas are calculated from 2 values stored in PREV and CURR entries,
    then propagated up to the global discard ctl.  The current counter value
    becomes the previous counter value after update.
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 765c5cbd99a5..bd1e7a542271 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -28,6 +28,7 @@ struct btrfs_free_space {
 	unsigned long *bitmap;
 	struct list_head list;
 	enum btrfs_trim_state trim_state;
+	s32 bitmap_extents;
 };
 
 static inline bool btrfs_free_space_trimmed(struct btrfs_free_space *info)
@@ -50,6 +51,7 @@ struct btrfs_free_space_ctl {
 	int total_bitmaps;
 	int unit;
 	u64 start;
+	s32 discardable_extents[BTRFS_STAT_NR_ENTRIES];
 	const struct btrfs_free_space_op *op;
 	void *private;
 	struct mutex cache_writeout_mutex;

commit 2bee7eb8bb8185679ea282b8ccff6bfabcf52a63
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:16 2019 -0800

    btrfs: discard one region at a time in async discard
    
    The prior two patches added discarding via a background workqueue. This
    just piggybacked off of the fstrim code to trim the whole block at once.
    Well inevitably this is worse performance wise and will aggressively
    overtrim. But it was nice to plumb the other infrastructure to keep the
    patches easier to review.
    
    This adds the real goal of this series which is discarding slowly (ie. a
    slow long running fstrim). The discarding is split into two phases,
    extents and then bitmaps. The reason for this is two fold. First, the
    bitmap regions overlap the extent regions. Second, discarding the
    extents first will let the newly trimmed bitmaps have the highest chance
    of coalescing when being readded to the free space cache.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index f799eb491410..765c5cbd99a5 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -138,6 +138,12 @@ int btrfs_return_cluster_to_free_space(
 			       struct btrfs_free_cluster *cluster);
 int btrfs_trim_block_group(struct btrfs_block_group *block_group,
 			   u64 *trimmed, u64 start, u64 end, u64 minlen);
+int btrfs_trim_block_group_extents(struct btrfs_block_group *block_group,
+				   u64 *trimmed, u64 start, u64 end, u64 minlen,
+				   bool async);
+int btrfs_trim_block_group_bitmaps(struct btrfs_block_group *block_group,
+				   u64 *trimmed, u64 start, u64 end, u64 minlen,
+				   bool async);
 
 /* Support functions for running our sanity tests */
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS

commit 6e80d4f8c422d3b2b0c37324d3243f5ed9b558c8
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:15 2019 -0800

    btrfs: handle empty block_group removal for async discard
    
    block_group removal is a little tricky. It can race with the extent
    allocator, the cleaner thread, and balancing. The current path is for a
    block_group to be added to the unused_bgs list. Then, when the cleaner
    thread comes around, it starts a transaction and then proceeds with
    removing the block_group. Extents that are pinned are subsequently
    removed from the pinned trees and then eventually a discard is issued
    for the entire block_group.
    
    Async discard introduces another player into the game, the discard
    workqueue. While it has none of the racing issues, the new problem is
    ensuring we don't leave free space untrimmed prior to forgetting the
    block_group.  This is handled by placing fully free block_groups on a
    separate discard queue. This is necessary to maintain discarding order
    as in the future we will slowly trim even fully free block_groups. The
    ordering helps us make progress on the same block_group rather than say
    the last fully freed block_group or needing to search through the fully
    freed block groups at the beginning of a list and insert after.
    
    The new order of events is a fully freed block group gets placed on the
    unused discard queue first. Once it's processed, it will be placed on
    the unusued_bgs list and then the original sequence of events will
    happen, just without the final whole block_group discard.
    
    The mount flags can change when processing unused_bgs, so when flipping
    from DISCARD to DISCARD_ASYNC, the unused_bgs must be punted to the
    discard_list to be trimmed. If we flip off DISCARD_ASYNC, we punt
    free block groups on the discard_list to the unused_bg queue which will
    do the final discard for us.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 6a85a5d16343..f799eb491410 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -119,6 +119,7 @@ int btrfs_remove_free_space(struct btrfs_block_group *block_group,
 			    u64 bytenr, u64 size);
 void __btrfs_remove_free_space_cache(struct btrfs_free_space_ctl *ctl);
 void btrfs_remove_free_space_cache(struct btrfs_block_group *block_group);
+bool btrfs_is_free_space_trimmed(struct btrfs_block_group *block_group);
 u64 btrfs_find_space_for_alloc(struct btrfs_block_group *block_group,
 			       u64 offset, u64 bytes, u64 empty_size,
 			       u64 *max_extent_size);

commit b0643e59cfa609c4b5f246f2b2c33b078f87e9d9
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:14 2019 -0800

    btrfs: add the beginning of async discard, discard workqueue
    
    When discard is enabled, everytime a pinned extent is released back to
    the block_group's free space cache, a discard is issued for the extent.
    This is an overeager approach when it comes to discarding and helping
    the SSD maintain enough free space to prevent severe garbage collection
    situations.
    
    This adds the beginning of async discard. Instead of issuing a discard
    prior to returning it to the free space, it is just marked as untrimmed.
    The block_group is then added to a LRU which then feeds into a workqueue
    to issue discards at a much slower rate. Full discarding of unused block
    groups is still done and will be addressed in a future patch of the
    series.
    
    For now, we don't persist the discard state of extents and bitmaps.
    Therefore, our failure recovery mode will be to consider extents
    untrimmed. This lets us handle failure and unmounting as one in the
    same.
    
    On a number of Facebook webservers, I collected data every minute
    accounting the time we spent in btrfs_finish_extent_commit() (col. 1)
    and in btrfs_commit_transaction() (col. 2). btrfs_finish_extent_commit()
    is where we discard extents synchronously before returning them to the
    free space cache.
    
    discard=sync:
                     p99 total per minute       p99 total per minute
          Drive   |   extent_commit() (ms)  |    commit_trans() (ms)
        ---------------------------------------------------------------
         Drive A  |           434           |          1170
         Drive B  |           880           |          2330
         Drive C  |          2943           |          3920
         Drive D  |          4763           |          5701
    
    discard=async:
                     p99 total per minute       p99 total per minute
          Drive   |   extent_commit() (ms)  |    commit_trans() (ms)
        --------------------------------------------------------------
         Drive A  |           134           |           956
         Drive B  |            64           |          1972
         Drive C  |            59           |          1032
         Drive D  |            62           |          1200
    
    While it's not great that the stats are cumulative over 1m, all of these
    servers are running the same workload and and the delta between the two
    are substantial. We are spending significantly less time in
    btrfs_finish_extent_commit() which is responsible for discarding.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 5f25d94c9946..6a85a5d16343 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -113,6 +113,8 @@ int __btrfs_add_free_space(struct btrfs_fs_info *fs_info,
 			   enum btrfs_trim_state trim_state);
 int btrfs_add_free_space(struct btrfs_block_group *block_group,
 			 u64 bytenr, u64 size);
+int btrfs_add_free_space_async_trimmed(struct btrfs_block_group *block_group,
+				       u64 bytenr, u64 size);
 int btrfs_remove_free_space(struct btrfs_block_group *block_group,
 			    u64 bytenr, u64 size);
 void __btrfs_remove_free_space_cache(struct btrfs_free_space_ctl *ctl);

commit da080fe1bad4777b02f6a3db42823a8797aadbca
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:13 2019 -0800

    btrfs: keep track of free space bitmap trim status cleanliness
    
    There is a cap in btrfs in the amount of free extents that a block group
    can have. When it surpasses that threshold, future extents are placed
    into bitmaps. Instead of keeping track of if a certain bit is trimmed or
    not in a second bitmap, keep track of the relative state of the bitmap.
    
    With async discard, trimming bitmaps becomes a more frequent operation.
    As a trade off with simplicity, we keep track of if discarding a bitmap
    is in progress. If we fully scan a bitmap and trim as necessary, the
    bitmap is marked clean. This has some caveats as the min block size may
    skip over regions deemed too small. But this should be a reasonable
    trade off rather than keeping a second bitmap and making allocation
    paths more complex. The downside is we may overtrim, but ideally the min
    block size should prevent us from doing that too often and getting stuck
    trimming pathological cases.
    
    BTRFS_TRIM_STATE_TRIMMING is added to indicate a bitmap is in the
    process of being trimmed. If additional free space is added to that
    bitmap, the bit is cleared. A bitmap will be marked
    BTRFS_TRIM_STATE_TRIMMED if the trimming code was able to reach the end
    of it and the former is still set.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 66c073f854dc..5f25d94c9946 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -8,10 +8,16 @@
 
 /*
  * This is the trim state of an extent or bitmap.
+ *
+ * BTRFS_TRIM_STATE_TRIMMING is special and used to maintain the state of a
+ * bitmap as we may need several trims to fully trim a single bitmap entry.
+ * This is reset should any free space other than trimmed space be added to the
+ * bitmap.
  */
 enum btrfs_trim_state {
 	BTRFS_TRIM_STATE_UNTRIMMED,
 	BTRFS_TRIM_STATE_TRIMMED,
+	BTRFS_TRIM_STATE_TRIMMING,
 };
 
 struct btrfs_free_space {
@@ -29,6 +35,12 @@ static inline bool btrfs_free_space_trimmed(struct btrfs_free_space *info)
 	return (info->trim_state == BTRFS_TRIM_STATE_TRIMMED);
 }
 
+static inline bool btrfs_free_space_trimming_bitmap(
+					    struct btrfs_free_space *info)
+{
+	return (info->trim_state == BTRFS_TRIM_STATE_TRIMMING);
+}
+
 struct btrfs_free_space_ctl {
 	spinlock_t tree_lock;
 	struct rb_root free_space_offset;

commit a7ccb255852413dd59263e551fd0ef13f76fc9b9
Author: Dennis Zhou <dennis@kernel.org>
Date:   Fri Dec 13 16:22:12 2019 -0800

    btrfs: keep track of which extents have been discarded
    
    Async discard will use the free space cache as backing knowledge for
    which extents to discard. This patch plumbs knowledge about which
    extents need to be discarded into the free space cache from
    unpin_extent_range().
    
    An untrimmed extent can merge with everything as this is a new region.
    Absorbing trimmed extents is a tradeoff to for greater coalescing which
    makes life better for find_free_extent(). Additionally, it seems the
    size of a trim isn't as problematic as the trim io itself.
    
    When reading in the free space cache from disk, if sync is set, mark all
    extents as trimmed. The current code ensures at transaction commit that
    all free space is trimmed when sync is set, so this reflects that.
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index ba9a23241101..66c073f854dc 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -6,6 +6,14 @@
 #ifndef BTRFS_FREE_SPACE_CACHE_H
 #define BTRFS_FREE_SPACE_CACHE_H
 
+/*
+ * This is the trim state of an extent or bitmap.
+ */
+enum btrfs_trim_state {
+	BTRFS_TRIM_STATE_UNTRIMMED,
+	BTRFS_TRIM_STATE_TRIMMED,
+};
+
 struct btrfs_free_space {
 	struct rb_node offset_index;
 	u64 offset;
@@ -13,8 +21,14 @@ struct btrfs_free_space {
 	u64 max_extent_size;
 	unsigned long *bitmap;
 	struct list_head list;
+	enum btrfs_trim_state trim_state;
 };
 
+static inline bool btrfs_free_space_trimmed(struct btrfs_free_space *info)
+{
+	return (info->trim_state == BTRFS_TRIM_STATE_TRIMMED);
+}
+
 struct btrfs_free_space_ctl {
 	spinlock_t tree_lock;
 	struct rb_root free_space_offset;
@@ -83,7 +97,8 @@ int btrfs_write_out_ino_cache(struct btrfs_root *root,
 void btrfs_init_free_space_ctl(struct btrfs_block_group *block_group);
 int __btrfs_add_free_space(struct btrfs_fs_info *fs_info,
 			   struct btrfs_free_space_ctl *ctl,
-			   u64 bytenr, u64 size);
+			   u64 bytenr, u64 size,
+			   enum btrfs_trim_state trim_state);
 int btrfs_add_free_space(struct btrfs_block_group *block_group,
 			 u64 bytenr, u64 size);
 int btrfs_remove_free_space(struct btrfs_block_group *block_group,

commit 32da5386d9a4fd5c1155cecf703df104d918954c
Author: David Sterba <dsterba@suse.com>
Date:   Tue Oct 29 19:20:18 2019 +0100

    btrfs: rename btrfs_block_group_cache
    
    The type name is misleading, a single entry is named 'cache' while this
    normally means a collection of objects. Rename that everywhere. Also the
    identifier was quite long, making function prototypes harder to format.
    
    Suggested-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 39c32c8fc24f..ba9a23241101 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -50,24 +50,23 @@ struct btrfs_io_ctl {
 	unsigned check_crcs:1;
 };
 
-struct inode *lookup_free_space_inode(
-		struct btrfs_block_group_cache *block_group,
+struct inode *lookup_free_space_inode(struct btrfs_block_group *block_group,
 		struct btrfs_path *path);
 int create_free_space_inode(struct btrfs_trans_handle *trans,
-			    struct btrfs_block_group_cache *block_group,
+			    struct btrfs_block_group *block_group,
 			    struct btrfs_path *path);
 
 int btrfs_check_trunc_cache_free_space(struct btrfs_fs_info *fs_info,
 				       struct btrfs_block_rsv *rsv);
 int btrfs_truncate_free_space_cache(struct btrfs_trans_handle *trans,
-				    struct btrfs_block_group_cache *block_group,
+				    struct btrfs_block_group *block_group,
 				    struct inode *inode);
-int load_free_space_cache(struct btrfs_block_group_cache *block_group);
+int load_free_space_cache(struct btrfs_block_group *block_group);
 int btrfs_wait_cache_io(struct btrfs_trans_handle *trans,
-			struct btrfs_block_group_cache *block_group,
+			struct btrfs_block_group *block_group,
 			struct btrfs_path *path);
 int btrfs_write_out_cache(struct btrfs_trans_handle *trans,
-			  struct btrfs_block_group_cache *block_group,
+			  struct btrfs_block_group *block_group,
 			  struct btrfs_path *path);
 struct inode *lookup_free_ino_inode(struct btrfs_root *root,
 				    struct btrfs_path *path);
@@ -81,42 +80,40 @@ int btrfs_write_out_ino_cache(struct btrfs_root *root,
 			      struct btrfs_path *path,
 			      struct inode *inode);
 
-void btrfs_init_free_space_ctl(struct btrfs_block_group_cache *block_group);
+void btrfs_init_free_space_ctl(struct btrfs_block_group *block_group);
 int __btrfs_add_free_space(struct btrfs_fs_info *fs_info,
 			   struct btrfs_free_space_ctl *ctl,
 			   u64 bytenr, u64 size);
-int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
+int btrfs_add_free_space(struct btrfs_block_group *block_group,
 			 u64 bytenr, u64 size);
-int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,
+int btrfs_remove_free_space(struct btrfs_block_group *block_group,
 			    u64 bytenr, u64 size);
 void __btrfs_remove_free_space_cache(struct btrfs_free_space_ctl *ctl);
-void btrfs_remove_free_space_cache(struct btrfs_block_group_cache
-				     *block_group);
-u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
+void btrfs_remove_free_space_cache(struct btrfs_block_group *block_group);
+u64 btrfs_find_space_for_alloc(struct btrfs_block_group *block_group,
 			       u64 offset, u64 bytes, u64 empty_size,
 			       u64 *max_extent_size);
 u64 btrfs_find_ino_for_alloc(struct btrfs_root *fs_root);
-void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
+void btrfs_dump_free_space(struct btrfs_block_group *block_group,
 			   u64 bytes);
-int btrfs_find_space_cluster(struct btrfs_block_group_cache *block_group,
+int btrfs_find_space_cluster(struct btrfs_block_group *block_group,
 			     struct btrfs_free_cluster *cluster,
 			     u64 offset, u64 bytes, u64 empty_size);
 void btrfs_init_free_cluster(struct btrfs_free_cluster *cluster);
-u64 btrfs_alloc_from_cluster(struct btrfs_block_group_cache *block_group,
+u64 btrfs_alloc_from_cluster(struct btrfs_block_group *block_group,
 			     struct btrfs_free_cluster *cluster, u64 bytes,
 			     u64 min_start, u64 *max_extent_size);
 int btrfs_return_cluster_to_free_space(
-			       struct btrfs_block_group_cache *block_group,
+			       struct btrfs_block_group *block_group,
 			       struct btrfs_free_cluster *cluster);
-int btrfs_trim_block_group(struct btrfs_block_group_cache *block_group,
+int btrfs_trim_block_group(struct btrfs_block_group *block_group,
 			   u64 *trimmed, u64 start, u64 end, u64 minlen);
 
 /* Support functions for running our sanity tests */
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
-int test_add_free_space_entry(struct btrfs_block_group_cache *cache,
+int test_add_free_space_entry(struct btrfs_block_group *cache,
 			      u64 offset, u64 bytes, bool bitmap);
-int test_check_exists(struct btrfs_block_group_cache *cache,
-		      u64 offset, u64 bytes);
+int test_check_exists(struct btrfs_block_group *cache, u64 offset, u64 bytes);
 #endif
 
 #endif

commit 67b61aefcef3842a360e6c603860a785fd971c7a
Author: David Sterba <dsterba@suse.com>
Date:   Wed Aug 21 19:57:04 2019 +0200

    btrfs: move struct io_ctl to free-space-cache.h
    
    The io_ctl structure is used for free space management, and used only by
    the v1 space cache code, but unfortunatlly the full definition is
    required by block-group.h so it can't be moved to free-space-cache.c
    without additional changes.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 2205a4113ef3..39c32c8fc24f 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -36,7 +36,19 @@ struct btrfs_free_space_op {
 			   struct btrfs_free_space *info);
 };
 
-struct btrfs_io_ctl;
+struct btrfs_io_ctl {
+	void *cur, *orig;
+	struct page *page;
+	struct page **pages;
+	struct btrfs_fs_info *fs_info;
+	struct inode *inode;
+	unsigned long size;
+	int index;
+	int num_pages;
+	int entries;
+	int bitmaps;
+	unsigned check_crcs:1;
+};
 
 struct inode *lookup_free_space_inode(
 		struct btrfs_block_group_cache *block_group,

commit 478b4d9f0105e33cae34445d5ad2eb9798628231
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Thu Jun 20 15:37:43 2019 -0400

    btrfs: move btrfs_add_free_space out of a header file
    
    This is prep work for moving block_group_cache around.  Having this in
    the header file makes the header file include need to be in a certain
    order, which is awkward, so just move it into free-space-cache.c and
    then we can re-arrange later.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 8760acb55ffd..2205a4113ef3 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -73,14 +73,8 @@ void btrfs_init_free_space_ctl(struct btrfs_block_group_cache *block_group);
 int __btrfs_add_free_space(struct btrfs_fs_info *fs_info,
 			   struct btrfs_free_space_ctl *ctl,
 			   u64 bytenr, u64 size);
-static inline int
-btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
-		     u64 bytenr, u64 size)
-{
-	return __btrfs_add_free_space(block_group->fs_info,
-				      block_group->free_space_ctl,
-				      bytenr, size);
-}
+int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
+			 u64 bytenr, u64 size);
 int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,
 			    u64 bytenr, u64 size);
 void __btrfs_remove_free_space_cache(struct btrfs_free_space_ctl *ctl);

commit 2ceeae2e4c4c3be9d52e84909e3882302002bb9c
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:53:49 2019 +0100

    btrfs: get fs_info from block group in btrfs_find_space_cluster
    
    We can read fs_info from the block group cache structure and can drop it
    from the parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 9067841a8528..8760acb55ffd 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -92,8 +92,7 @@ u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
 u64 btrfs_find_ino_for_alloc(struct btrfs_root *fs_root);
 void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
 			   u64 bytes);
-int btrfs_find_space_cluster(struct btrfs_fs_info *fs_info,
-			     struct btrfs_block_group_cache *block_group,
+int btrfs_find_space_cluster(struct btrfs_block_group_cache *block_group,
 			     struct btrfs_free_cluster *cluster,
 			     u64 offset, u64 bytes, u64 empty_size);
 void btrfs_init_free_cluster(struct btrfs_free_cluster *cluster);

commit bb6cb1c5b92bc67082acf4dd0f037d8d3d0d0c61
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:47:15 2019 +0100

    btrfs: get fs_info from block group in load_free_space_cache
    
    We can read fs_info from the block group cache structure and can drop it
    from the parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index ab387c219bb0..9067841a8528 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -50,8 +50,7 @@ int btrfs_check_trunc_cache_free_space(struct btrfs_fs_info *fs_info,
 int btrfs_truncate_free_space_cache(struct btrfs_trans_handle *trans,
 				    struct btrfs_block_group_cache *block_group,
 				    struct inode *inode);
-int load_free_space_cache(struct btrfs_fs_info *fs_info,
-			  struct btrfs_block_group_cache *block_group);
+int load_free_space_cache(struct btrfs_block_group_cache *block_group);
 int btrfs_wait_cache_io(struct btrfs_trans_handle *trans,
 			struct btrfs_block_group_cache *block_group,
 			struct btrfs_path *path);

commit 7949f3392ed65d19f0f6726e9e32445aa8b707dc
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:40:19 2019 +0100

    btrfs: get fs_info from block group in lookup_free_space_inode
    
    We can read fs_info from the block group cache structure and can drop it
    from the parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index b3a4fce7946a..ab387c219bb0 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -38,9 +38,9 @@ struct btrfs_free_space_op {
 
 struct btrfs_io_ctl;
 
-struct inode *lookup_free_space_inode(struct btrfs_fs_info *fs_info,
-				      struct btrfs_block_group_cache
-				      *block_group, struct btrfs_path *path);
+struct inode *lookup_free_space_inode(
+		struct btrfs_block_group_cache *block_group,
+		struct btrfs_path *path);
 int create_free_space_inode(struct btrfs_trans_handle *trans,
 			    struct btrfs_block_group_cache *block_group,
 			    struct btrfs_path *path);

commit fe04153452a6305ddaab056f4fa412c142a6f955
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:51:56 2019 +0100

    btrfs: get fs_info from trans in btrfs_write_out_cache
    
    We can read fs_info from the transaction and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 4f0d26ccfde6..b3a4fce7946a 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -55,8 +55,7 @@ int load_free_space_cache(struct btrfs_fs_info *fs_info,
 int btrfs_wait_cache_io(struct btrfs_trans_handle *trans,
 			struct btrfs_block_group_cache *block_group,
 			struct btrfs_path *path);
-int btrfs_write_out_cache(struct btrfs_fs_info *fs_info,
-			  struct btrfs_trans_handle *trans,
+int btrfs_write_out_cache(struct btrfs_trans_handle *trans,
 			  struct btrfs_block_group_cache *block_group,
 			  struct btrfs_path *path);
 struct inode *lookup_free_ino_inode(struct btrfs_root *root,

commit 4ca75f1bd413ec0c550f925c009a7ba1b20e6003
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 20 13:42:57 2019 +0100

    btrfs: get fs_info from trans in create_free_space_inode
    
    We can read fs_info from the transaction and can drop it from the
    parameters.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 15e30b93db0d..4f0d26ccfde6 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -41,8 +41,7 @@ struct btrfs_io_ctl;
 struct inode *lookup_free_space_inode(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_group_cache
 				      *block_group, struct btrfs_path *path);
-int create_free_space_inode(struct btrfs_fs_info *fs_info,
-			    struct btrfs_trans_handle *trans,
+int create_free_space_inode(struct btrfs_trans_handle *trans,
 			    struct btrfs_block_group_cache *block_group,
 			    struct btrfs_path *path);
 

commit 9888c3402c8567a977de37f61e9dd87792723064
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:16:55 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- headers
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Unify the include protection macros to match the file names.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 79eca4cabb1c..15e30b93db0d 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -1,23 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Copyright (C) 2009 Oracle.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
-#ifndef __BTRFS_FREE_SPACE_CACHE
-#define __BTRFS_FREE_SPACE_CACHE
+#ifndef BTRFS_FREE_SPACE_CACHE_H
+#define BTRFS_FREE_SPACE_CACHE_H
 
 struct btrfs_free_space {
 	struct rb_node offset_index;

commit 77ab86bf1c64ab282f2230521c7d4d7f69ea3a3f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Feb 15 16:28:30 2017 -0500

    btrfs: free-space-cache, clean up unnecessary root arguments
    
    The free space cache APIs accept a root but always use the tree root.
    
    Also, btrfs_truncate_free_space_cache accepts a root AND an inode but
    the inode always points to the root anyway, so let's just pass the inode.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 6f3c025a2c6c..79eca4cabb1c 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -51,18 +51,17 @@ struct btrfs_free_space_op {
 
 struct btrfs_io_ctl;
 
-struct inode *lookup_free_space_inode(struct btrfs_root *root,
+struct inode *lookup_free_space_inode(struct btrfs_fs_info *fs_info,
 				      struct btrfs_block_group_cache
 				      *block_group, struct btrfs_path *path);
-int create_free_space_inode(struct btrfs_root *root,
+int create_free_space_inode(struct btrfs_fs_info *fs_info,
 			    struct btrfs_trans_handle *trans,
 			    struct btrfs_block_group_cache *block_group,
 			    struct btrfs_path *path);
 
 int btrfs_check_trunc_cache_free_space(struct btrfs_fs_info *fs_info,
 				       struct btrfs_block_rsv *rsv);
-int btrfs_truncate_free_space_cache(struct btrfs_root *root,
-				    struct btrfs_trans_handle *trans,
+int btrfs_truncate_free_space_cache(struct btrfs_trans_handle *trans,
 				    struct btrfs_block_group_cache *block_group,
 				    struct inode *inode);
 int load_free_space_cache(struct btrfs_fs_info *fs_info,

commit 2ff7e61e0d30ff166a2ae94575526bffe11fd1a8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:24 2016 -0400

    btrfs: take an fs_info directly when the root is not used otherwise
    
    There are loads of functions in btrfs that accept a root parameter
    but only use it to obtain an fs_info pointer.  Let's convert those to
    just accept an fs_info pointer directly.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index f39ba850b566..6f3c025a2c6c 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -59,7 +59,7 @@ int create_free_space_inode(struct btrfs_root *root,
 			    struct btrfs_block_group_cache *block_group,
 			    struct btrfs_path *path);
 
-int btrfs_check_trunc_cache_free_space(struct btrfs_root *root,
+int btrfs_check_trunc_cache_free_space(struct btrfs_fs_info *fs_info,
 				       struct btrfs_block_rsv *rsv);
 int btrfs_truncate_free_space_cache(struct btrfs_root *root,
 				    struct btrfs_trans_handle *trans,
@@ -109,7 +109,7 @@ u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
 u64 btrfs_find_ino_for_alloc(struct btrfs_root *fs_root);
 void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
 			   u64 bytes);
-int btrfs_find_space_cluster(struct btrfs_root *root,
+int btrfs_find_space_cluster(struct btrfs_fs_info *fs_info,
 			     struct btrfs_block_group_cache *block_group,
 			     struct btrfs_free_cluster *cluster,
 			     u64 offset, u64 bytes, u64 empty_size);

commit afdb571890615059ed4f0625209b379aff6cb08d
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Sep 9 12:09:35 2016 -0400

    btrfs: simplify btrfs_wait_cache_io prototype
    
    With the exception of the one case where btrfs_wait_cache_io is called
    without a block group, it's called with the same arguments.  The root
    argument is only used in the special case, so let's factor out the core
    and simplify the call in the normal case to require a trans, block group,
    and path.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 70e7a7cc15f3..f39ba850b566 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -67,11 +67,9 @@ int btrfs_truncate_free_space_cache(struct btrfs_root *root,
 				    struct inode *inode);
 int load_free_space_cache(struct btrfs_fs_info *fs_info,
 			  struct btrfs_block_group_cache *block_group);
-int btrfs_wait_cache_io(struct btrfs_root *root,
-			struct btrfs_trans_handle *trans,
+int btrfs_wait_cache_io(struct btrfs_trans_handle *trans,
 			struct btrfs_block_group_cache *block_group,
-			struct btrfs_io_ctl *io_ctl,
-			struct btrfs_path *path, u64 offset);
+			struct btrfs_path *path);
 int btrfs_write_out_cache(struct btrfs_fs_info *fs_info,
 			  struct btrfs_trans_handle *trans,
 			  struct btrfs_block_group_cache *block_group,

commit 5b4aacefb8fbfc996e68b9b083d30f8bc0972449
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Jun 21 10:40:19 2016 -0400

    btrfs: call functions that overwrite their root parameter with fs_info
    
    There are 11 functions that accept a root parameter and immediately
    overwrite it.  We can pass those an fs_info pointer instead.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 363fdd955e5d..70e7a7cc15f3 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -72,7 +72,7 @@ int btrfs_wait_cache_io(struct btrfs_root *root,
 			struct btrfs_block_group_cache *block_group,
 			struct btrfs_io_ctl *io_ctl,
 			struct btrfs_path *path, u64 offset);
-int btrfs_write_out_cache(struct btrfs_root *root,
+int btrfs_write_out_cache(struct btrfs_fs_info *fs_info,
 			  struct btrfs_trans_handle *trans,
 			  struct btrfs_block_group_cache *block_group,
 			  struct btrfs_path *path);

commit ab8d0fc48dba09e0a2b8b0dbfe144d4de9eb874f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:02 2016 -0400

    btrfs: convert pr_* to btrfs_* where possible
    
    For many printks, we want to know which file system issued the message.
    
    This patch converts most pr_* calls to use the btrfs_* versions instead.
    In some cases, this means adding plumbing to allow call sites access to
    an fs_info pointer.
    
    fs/btrfs/check-integrity.c is left alone for another day.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 3af651c2bbc7..363fdd955e5d 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -89,13 +89,15 @@ int btrfs_write_out_ino_cache(struct btrfs_root *root,
 			      struct inode *inode);
 
 void btrfs_init_free_space_ctl(struct btrfs_block_group_cache *block_group);
-int __btrfs_add_free_space(struct btrfs_free_space_ctl *ctl,
+int __btrfs_add_free_space(struct btrfs_fs_info *fs_info,
+			   struct btrfs_free_space_ctl *ctl,
 			   u64 bytenr, u64 size);
 static inline int
 btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
 		     u64 bytenr, u64 size)
 {
-	return __btrfs_add_free_space(block_group->free_space_ctl,
+	return __btrfs_add_free_space(block_group->fs_info,
+				      block_group->free_space_ctl,
 				      bytenr, size);
 }
 int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,

commit 0132761017e012ab4dc8584d679503f2ba26ca86
Author: Nicholas D Steeves <nsteeves@gmail.com>
Date:   Thu May 19 21:18:45 2016 -0400

    btrfs: fix string and comment grammatical issues and typos
    
    Signed-off-by: Nicholas D Steeves <nsteeves@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 33178c490ace..3af651c2bbc7 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -123,7 +123,7 @@ int btrfs_return_cluster_to_free_space(
 int btrfs_trim_block_group(struct btrfs_block_group_cache *block_group,
 			   u64 *trimmed, u64 start, u64 end, u64 minlen);
 
-/* Support functions for runnint our sanity tests */
+/* Support functions for running our sanity tests */
 #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 int test_add_free_space_entry(struct btrfs_block_group_cache *cache,
 			      u64 offset, u64 bytes, bool bitmap);

commit 20e5506baf3fd651e245bc970d8c11a734ee1b8a
Author: David Sterba <dsterba@suse.com>
Date:   Thu Nov 19 11:42:28 2015 +0100

    btrfs: constify remaining structs with function pointers
    
    * struct extent_io_ops
    * struct btrfs_free_space_op
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index f251865eb6f3..33178c490ace 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -37,7 +37,7 @@ struct btrfs_free_space_ctl {
 	int total_bitmaps;
 	int unit;
 	u64 start;
-	struct btrfs_free_space_op *op;
+	const struct btrfs_free_space_op *op;
 	void *private;
 	struct mutex cache_writeout_mutex;
 	struct list_head trimming_ranges;

commit cef404837002103584c7c82f1e3fc3ec5961f47b
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Oct 2 16:09:42 2015 -0400

    Btrfs: keep track of largest extent in bitmaps
    
    We can waste a lot of time searching through bitmaps when we are heavily
    fragmented trying to find large contiguous areas that don't exist in the bitmap.
    So keep track of the max extent size when we do a full search of a bitmap so
    that next time around we can just skip the expensive searching if our max size
    is less than what we are looking for.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index a16a029ad3b1..f251865eb6f3 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -23,6 +23,7 @@ struct btrfs_free_space {
 	struct rb_node offset_index;
 	u64 offset;
 	u64 bytes;
+	u64 max_extent_size;
 	unsigned long *bitmap;
 	struct list_head list;
 };

commit 1bbc621ef28462456131c035eaeb5567a1a2a2fe
Author: Chris Mason <clm@fb.com>
Date:   Mon Apr 6 12:46:08 2015 -0700

    Btrfs: allow block group cache writeout outside critical section in commit
    
    We loop through all of the dirty block groups during commit and write
    the free space cache.  In order to make sure the cache is currect, we do
    this while no other writers are allowed in the commit.
    
    If a large number of block groups are dirty, this can introduce long
    stalls during the final stages of the commit, which can block new procs
    trying to change the filesystem.
    
    This commit changes the block group cache writeout to take appropriate
    locks and allow it to run earlier in the commit.  We'll still have to
    redo some of the block groups, but it means we can get most of the work
    out of the way without blocking the entire FS.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index c4339863af05..a16a029ad3b1 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -62,6 +62,7 @@ int btrfs_check_trunc_cache_free_space(struct btrfs_root *root,
 				       struct btrfs_block_rsv *rsv);
 int btrfs_truncate_free_space_cache(struct btrfs_root *root,
 				    struct btrfs_trans_handle *trans,
+				    struct btrfs_block_group_cache *block_group,
 				    struct inode *inode);
 int load_free_space_cache(struct btrfs_fs_info *fs_info,
 			  struct btrfs_block_group_cache *block_group);

commit c9dc4c6578502c2085705347375b82089aad18d0
Author: Chris Mason <clm@fb.com>
Date:   Sat Apr 4 17:14:42 2015 -0700

    Btrfs: two stage dirty block group writeout
    
    Block group cache writeout is currently waiting on the pages for each
    block group cache before moving on to writing the next one.  This commit
    switches things around to send down all the caches and then wait on them
    in batches.
    
    The end result is much faster, since we're keeping the disk pipeline
    full.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 88b2238a0aed..c4339863af05 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -48,6 +48,8 @@ struct btrfs_free_space_op {
 			   struct btrfs_free_space *info);
 };
 
+struct btrfs_io_ctl;
+
 struct inode *lookup_free_space_inode(struct btrfs_root *root,
 				      struct btrfs_block_group_cache
 				      *block_group, struct btrfs_path *path);
@@ -63,11 +65,15 @@ int btrfs_truncate_free_space_cache(struct btrfs_root *root,
 				    struct inode *inode);
 int load_free_space_cache(struct btrfs_fs_info *fs_info,
 			  struct btrfs_block_group_cache *block_group);
+int btrfs_wait_cache_io(struct btrfs_root *root,
+			struct btrfs_trans_handle *trans,
+			struct btrfs_block_group_cache *block_group,
+			struct btrfs_io_ctl *io_ctl,
+			struct btrfs_path *path, u64 offset);
 int btrfs_write_out_cache(struct btrfs_root *root,
 			  struct btrfs_trans_handle *trans,
 			  struct btrfs_block_group_cache *block_group,
 			  struct btrfs_path *path);
-
 struct inode *lookup_free_ino_inode(struct btrfs_root *root,
 				    struct btrfs_path *path);
 int create_free_ino_inode(struct btrfs_root *root,

commit 55507ce3612365a5173dfb080a4baf45d1ef8cd1
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Dec 1 17:04:09 2014 +0000

    Btrfs: fix race between writing free space cache and trimming
    
    Trimming is completely transactionless, and the way it operates consists
    of hiding free space entries from a block group, perform the trim/discard
    and then make the free space entries visible again.
    Therefore while a free space entry is being trimmed, we can have free space
    cache writing running in parallel (as part of a transaction commit) which
    will miss the free space entry. This means that an unmount (or crash/reboot)
    after that transaction commit and mount again before another transaction
    starts/commits after the discard finishes, we will have some free space
    that won't be used again unless the free space cache is rebuilt. After the
    unmount, fsck (btrfsck, btrfs check) reports the issue like the following
    example:
    
            *** fsck.btrfs output ***
            checking extents
            checking free space cache
            There is no free space entry for 521764864-521781248
            There is no free space entry for 521764864-1103101952
            cache appears valid but isnt 29360128
            Checking filesystem on /dev/sdc
            UUID: b4789e27-4774-4626-98e9-ae8dfbfb0fb5
            found 1235681286 bytes used err is -22
            (...)
    
    Another issue caused by this race is a crash while writing bitmap entries
    to the cache, because while the cache writeout task accesses the bitmaps,
    the trim task can be concurrently modifying the bitmap or worse might
    be freeing the bitmap. The later case results in the following crash:
    
    [55650.804460] general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC
    [55650.804835] Modules linked in: btrfs dm_flakey dm_mod crc32c_generic xor raid6_pq nfsd auth_rpcgss oid_registry nfs_acl nfs lockd fscache sunrpc loop parport_pc parport i2c_piix4 psmouse evdev pcspkr microcode processor i2ccore serio_raw thermal_sys button ext4 crc16 jbd2 mbcache sg sd_mod crc_t10dif sr_mod cdrom crct10dif_generic crct10dif_common ata_generic virtio_scsi floppy ata_piix libata virtio_pci virtio_ring virtio scsi_mod e1000 [last unloaded: btrfs]
    [55650.806169] CPU: 1 PID: 31002 Comm: btrfs-transacti Tainted: G        W      3.17.0-rc5-btrfs-next-1+ #1
    [55650.806493] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    [55650.806867] task: ffff8800b12f6410 ti: ffff880071538000 task.ti: ffff880071538000
    [55650.807166] RIP: 0010:[<ffffffffa037cf45>]  [<ffffffffa037cf45>] write_bitmap_entries+0x65/0xbb [btrfs]
    [55650.807514] RSP: 0018:ffff88007153bc30  EFLAGS: 00010246
    [55650.807687] RAX: 000000005d1ec000 RBX: ffff8800a665df08 RCX: 0000000000000400
    [55650.807885] RDX: ffff88005d1ec000 RSI: 6b6b6b6b6b6b6b6b RDI: ffff88005d1ec000
    [55650.808017] RBP: ffff88007153bc58 R08: 00000000ddd51536 R09: 00000000000001e0
    [55650.808017] R10: 0000000000000000 R11: 0000000000000037 R12: 6b6b6b6b6b6b6b6b
    [55650.808017] R13: ffff88007153bca8 R14: 6b6b6b6b6b6b6b6b R15: ffff88007153bc98
    [55650.808017] FS:  0000000000000000(0000) GS:ffff88023ec80000(0000) knlGS:0000000000000000
    [55650.808017] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [55650.808017] CR2: 0000000002273b88 CR3: 00000000b18f6000 CR4: 00000000000006e0
    [55650.808017] Stack:
    [55650.808017]  ffff88020e834e00 ffff880172d68db0 0000000000000000 ffff88019257c800
    [55650.808017]  ffff8801d42ea720 ffff88007153bd10 ffffffffa037d2fa ffff880224e99180
    [55650.808017]  ffff8801469a6188 ffff880224e99140 ffff880172d68c50 00000003000000b7
    [55650.808017] Call Trace:
    [55650.808017]  [<ffffffffa037d2fa>] __btrfs_write_out_cache+0x1ea/0x37f [btrfs]
    [55650.808017]  [<ffffffffa037d959>] btrfs_write_out_cache+0xa1/0xd8 [btrfs]
    [55650.808017]  [<ffffffffa033936b>] btrfs_write_dirty_block_groups+0x4b5/0x505 [btrfs]
    [55650.808017]  [<ffffffffa03aa98e>] commit_cowonly_roots+0x15e/0x1f7 [btrfs]
    [55650.808017]  [<ffffffff813eb9c7>] ? _raw_spin_lock+0xe/0x10
    [55650.808017]  [<ffffffffa0346e46>] btrfs_commit_transaction+0x411/0x882 [btrfs]
    [55650.808017]  [<ffffffffa03432a4>] transaction_kthread+0xf2/0x1a4 [btrfs]
    [55650.808017]  [<ffffffffa03431b2>] ? btrfs_cleanup_transaction+0x3d8/0x3d8 [btrfs]
    [55650.808017]  [<ffffffff8105966b>] kthread+0xb7/0xbf
    [55650.808017]  [<ffffffff810595b4>] ? __kthread_parkme+0x67/0x67
    [55650.808017]  [<ffffffff813ebeac>] ret_from_fork+0x7c/0xb0
    [55650.808017]  [<ffffffff810595b4>] ? __kthread_parkme+0x67/0x67
    [55650.808017] Code: 4c 89 ef 8d 70 ff e8 d4 fc ff ff 41 8b 45 34 41 39 45 30 7d 5c 31 f6 4c 89 ef e8 80 f6 ff ff 49 8b 7d 00 4c 89 f6 b9 00 04 00 00 <f3> a5 4c 89 ef 41 8b 45 30 8d 70 ff e8 a3 fc ff ff 41 8b 45 34
    [55650.808017] RIP  [<ffffffffa037cf45>] write_bitmap_entries+0x65/0xbb [btrfs]
    [55650.808017]  RSP <ffff88007153bc30>
    [55650.815725] ---[ end trace 1c032e96b149ff86 ]---
    
    Fix this by serializing both tasks in such a way that cache writeout
    doesn't wait for the trim/discard of free space entries to finish and
    doesn't miss any free space entry.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 0cf4977ef70d..88b2238a0aed 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -38,6 +38,8 @@ struct btrfs_free_space_ctl {
 	u64 start;
 	struct btrfs_free_space_op *op;
 	void *private;
+	struct mutex cache_writeout_mutex;
+	struct list_head trimming_ranges;
 };
 
 struct btrfs_free_space_op {

commit 74514323947ef27347564bfd7a663fdb3429cb20
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Fri Sep 20 14:46:51 2013 +0100

    Btrfs: remove path arg from btrfs_truncate_free_space_cache
    
    Not used for anything, and removing it avoids caller's need to
    allocate a path structure.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index ba8d5a1b64b5..0cf4977ef70d 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -58,7 +58,6 @@ int btrfs_check_trunc_cache_free_space(struct btrfs_root *root,
 				       struct btrfs_block_rsv *rsv);
 int btrfs_truncate_free_space_cache(struct btrfs_root *root,
 				    struct btrfs_trans_handle *trans,
-				    struct btrfs_path *path,
 				    struct inode *inode);
 int load_free_space_cache(struct btrfs_fs_info *fs_info,
 			  struct btrfs_block_group_cache *block_group);

commit 53645a91f4baed059ec5dfb22340cf3e6b8fdd2c
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Fri Sep 20 14:43:28 2013 +0100

    Btrfs: remove duplicated ino cache's inode lookup
    
    We're doing a unnecessary extra lookup of the ino cache's
    inode when we already have it (and holding a reference)
    during the process of saving the ino cache contents to disk.
    Therefore remove this extra lookup.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index e737f92cf6d0..ba8d5a1b64b5 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -76,7 +76,8 @@ int load_free_ino_cache(struct btrfs_fs_info *fs_info,
 			struct btrfs_root *root);
 int btrfs_write_out_ino_cache(struct btrfs_root *root,
 			      struct btrfs_trans_handle *trans,
-			      struct btrfs_path *path);
+			      struct btrfs_path *path,
+			      struct inode *inode);
 
 void btrfs_init_free_space_ctl(struct btrfs_block_group_cache *block_group);
 int __btrfs_add_free_space(struct btrfs_free_space_ctl *ctl,

commit a482039889b85c45fc9616e65d560db7a35d4f54
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Mon Sep 9 13:19:42 2013 +0800

    Btrfs: allocate the free space by the existed max extent size when ENOSPC
    
    By the current code, if the requested size is very large, and all the extents
    in the free space cache are small, we will waste lots of the cpu time to cut
    the requested size in half and search the cache again and again until it gets
    down to the size the allocator can return. In fact, we can know the max extent
    size in the cache after the first search, so we needn't cut the size in half
    repeatedly, and just use the max extent size directly. This way can save
    lots of cpu time and make the performance grow up when there are only fragments
    in the free space cache.
    
    According to my test, if there are only 4KB free space extents in the fs,
    and the total size of those extents are 256MB, we can reduce the execute
    time of the following test from 5.4s to 1.4s.
      dd if=/dev/zero of=<testfile> bs=1MB count=1 oflag=sync
    
    Changelog v2 -> v3:
    - fix the problem that we skip the block group with the space which is
      less than we need.
    
    Changelog v1 -> v2:
    - address the problem that we return a wrong start position when searching
      the free space in a bitmap.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index c74904167476..e737f92cf6d0 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -94,7 +94,8 @@ void __btrfs_remove_free_space_cache(struct btrfs_free_space_ctl *ctl);
 void btrfs_remove_free_space_cache(struct btrfs_block_group_cache
 				     *block_group);
 u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
-			       u64 offset, u64 bytes, u64 empty_size);
+			       u64 offset, u64 bytes, u64 empty_size,
+			       u64 *max_extent_size);
 u64 btrfs_find_ino_for_alloc(struct btrfs_root *fs_root);
 void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
 			   u64 bytes);
@@ -105,7 +106,7 @@ int btrfs_find_space_cluster(struct btrfs_root *root,
 void btrfs_init_free_cluster(struct btrfs_free_cluster *cluster);
 u64 btrfs_alloc_from_cluster(struct btrfs_block_group_cache *block_group,
 			     struct btrfs_free_cluster *cluster, u64 bytes,
-			     u64 min_start);
+			     u64 min_start, u64 *max_extent_size);
 int btrfs_return_cluster_to_free_space(
 			       struct btrfs_block_group_cache *block_group,
 			       struct btrfs_free_cluster *cluster);

commit dc11dd5d707a4157882f281c96055d6894d10c8c
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Aug 14 15:05:12 2013 -0400

    Btrfs: separate out tests into their own directory
    
    The plan is to have a bunch of unit tests that run when btrfs is loaded when you
    build with the appropriate config option.  My ultimate goal is to have a test
    for every non-static function we have, but at first I'm going to focus on the
    things that cause us the most problems.  To start out with this just adds a
    tests/ directory and moves the existing free space cache tests into that
    directory and sets up all of the infrastructure.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 4acfb19ba4ee..c74904167476 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -112,6 +112,12 @@ int btrfs_return_cluster_to_free_space(
 int btrfs_trim_block_group(struct btrfs_block_group_cache *block_group,
 			   u64 *trimmed, u64 start, u64 end, u64 minlen);
 
-void btrfs_test_free_space_cache(void);
+/* Support functions for runnint our sanity tests */
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+int test_add_free_space_entry(struct btrfs_block_group_cache *cache,
+			      u64 offset, u64 bytes, bool bitmap);
+int test_check_exists(struct btrfs_block_group_cache *cache,
+		      u64 offset, u64 bytes);
+#endif
 
 #endif

commit 00361589d2eebd90fca022148c763e40d3e90871
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Aug 14 14:02:47 2013 -0400

    Btrfs: avoid starting a transaction in the write path
    
    I noticed while looking at a deadlock that we are always starting a transaction
    in cow_file_range().  This isn't really needed since we only need a transaction
    if we are doing an inline extent, or if the allocator needs to allocate a chunk.
    So push down all the transaction start stuff to be closer to where we actually
    need a transaction in all of these cases.  This will hopefully reduce our write
    latency when we are committing often.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 894116b71304..4acfb19ba4ee 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -98,8 +98,7 @@ u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
 u64 btrfs_find_ino_for_alloc(struct btrfs_root *fs_root);
 void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
 			   u64 bytes);
-int btrfs_find_space_cluster(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *root,
+int btrfs_find_space_cluster(struct btrfs_root *root,
 			     struct btrfs_block_group_cache *block_group,
 			     struct btrfs_free_cluster *cluster,
 			     u64 offset, u64 bytes, u64 empty_size);

commit e6d2960582f625ba6e676117019b62aa87425e8f
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Apr 30 16:51:58 2013 +0000

    btrfs: move ifdef around sanity checks out of init_btrfs_fs
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 8b7f19f44961..894116b71304 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -113,8 +113,6 @@ int btrfs_return_cluster_to_free_space(
 int btrfs_trim_block_group(struct btrfs_block_group_cache *block_group,
 			   u64 *trimmed, u64 start, u64 end, u64 minlen);
 
-#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
 void btrfs_test_free_space_cache(void);
-#endif
 
 #endif

commit 7b61cd92242542944fc27024900c495a6a7b3396
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Mon May 13 13:55:09 2013 +0000

    Btrfs: don't use global block reservation for inode cache truncation
    
    It is very likely that there are lots of subvolumes/snapshots in the filesystem,
    so if we use global block reservation to do inode cache truncation, we may hog
    all the free space that is reserved in global rsv. So it is better that we do
    the free space reservation for inode cache truncation by ourselves.
    
    Cc: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 4dc17d8809c7..8b7f19f44961 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -54,6 +54,8 @@ int create_free_space_inode(struct btrfs_root *root,
 			    struct btrfs_block_group_cache *block_group,
 			    struct btrfs_path *path);
 
+int btrfs_check_trunc_cache_free_space(struct btrfs_root *root,
+				       struct btrfs_block_rsv *rsv);
 int btrfs_truncate_free_space_cache(struct btrfs_root *root,
 				    struct btrfs_trans_handle *trans,
 				    struct btrfs_path *path,

commit 74255aa07d292385ca3a4a4e8f0bc492d9bdd116
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Mar 15 09:47:08 2013 -0400

    Btrfs: add some free space cache tests
    
    We keep hitting bugs in the tree log replay because btrfs_remove_free_space
    doesn't account for some corner case.  So add a bunch of tests to try and fully
    test btrfs_remove_free_space since the only time it is called is during tree log
    replay.  These tests all finish successfully, so as we find more of these bugs
    we need to add to these tests to make sure we don't regress in fixing things.
    I've hidden the tests behind a Kconfig option, but they take no time to run so
    all btrfs developers should have this turned on all the time.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 8f2613f779ed..4dc17d8809c7 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -110,4 +110,9 @@ int btrfs_return_cluster_to_free_space(
 			       struct btrfs_free_cluster *cluster);
 int btrfs_trim_block_group(struct btrfs_block_group_cache *block_group,
 			   u64 *trimmed, u64 start, u64 end, u64 minlen);
+
+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS
+void btrfs_test_free_space_cache(void);
+#endif
+
 #endif

commit 82d5902d9c681be37ffa9d70482907f9f0b7ec1f
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Apr 20 10:33:24 2011 +0800

    Btrfs: Support reading/writing on disk free ino cache
    
    This is similar to block group caching.
    
    We dedicate a special inode in fs tree to save free ino cache.
    
    At the very first time we create/delete a file after mount, the free ino
    cache will be loaded from disk into memory. When the fs tree is commited,
    the cache will be written back to disk.
    
    To keep compatibility, we check the root generation against the generation
    of the special inode when loading the cache, so the loading will fail
    if the btrfs filesystem was mounted in an older kernel before.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index af06e6b6ceaa..8f2613f779ed 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -65,6 +65,17 @@ int btrfs_write_out_cache(struct btrfs_root *root,
 			  struct btrfs_block_group_cache *block_group,
 			  struct btrfs_path *path);
 
+struct inode *lookup_free_ino_inode(struct btrfs_root *root,
+				    struct btrfs_path *path);
+int create_free_ino_inode(struct btrfs_root *root,
+			  struct btrfs_trans_handle *trans,
+			  struct btrfs_path *path);
+int load_free_ino_cache(struct btrfs_fs_info *fs_info,
+			struct btrfs_root *root);
+int btrfs_write_out_ino_cache(struct btrfs_root *root,
+			      struct btrfs_trans_handle *trans,
+			      struct btrfs_path *path);
+
 void btrfs_init_free_space_ctl(struct btrfs_block_group_cache *block_group);
 int __btrfs_add_free_space(struct btrfs_free_space_ctl *ctl,
 			   u64 bytenr, u64 size);

commit 581bb050941b4f220f84d3e5ed6dace3d42dd382
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Apr 20 10:06:11 2011 +0800

    Btrfs: Cache free inode numbers in memory
    
    Currently btrfs stores the highest objectid of the fs tree, and it always
    returns (highest+1) inode number when we create a file, so inode numbers
    won't be reclaimed when we delete files, so we'll run out of inode numbers
    as we keep create/delete files in 32bits machines.
    
    This fixes it, and it works similarly to how we cache free space in block
    cgroups.
    
    We start a kernel thread to read the file tree. By scanning inode items,
    we know which chunks of inode numbers are free, and we cache them in
    an rb-tree.
    
    Because we are searching the commit root, we have to carefully handle the
    cross-transaction case.
    
    The rb-tree is a hybrid extent+bitmap tree, so if we have too many small
    chunks of inode numbers, we'll use bitmaps. Initially we allow 16K ram
    of extents, and a bitmap will be used if we exceed this threshold. The
    extents threshold is adjusted in runtime.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index a64a23fae1eb..af06e6b6ceaa 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -64,15 +64,25 @@ int btrfs_write_out_cache(struct btrfs_root *root,
 			  struct btrfs_trans_handle *trans,
 			  struct btrfs_block_group_cache *block_group,
 			  struct btrfs_path *path);
+
 void btrfs_init_free_space_ctl(struct btrfs_block_group_cache *block_group);
-int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
-			 u64 bytenr, u64 size);
+int __btrfs_add_free_space(struct btrfs_free_space_ctl *ctl,
+			   u64 bytenr, u64 size);
+static inline int
+btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
+		     u64 bytenr, u64 size)
+{
+	return __btrfs_add_free_space(block_group->free_space_ctl,
+				      bytenr, size);
+}
 int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,
 			    u64 bytenr, u64 size);
+void __btrfs_remove_free_space_cache(struct btrfs_free_space_ctl *ctl);
 void btrfs_remove_free_space_cache(struct btrfs_block_group_cache
-				   *block_group);
+				     *block_group);
 u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
 			       u64 offset, u64 bytes, u64 empty_size);
+u64 btrfs_find_ino_for_alloc(struct btrfs_root *fs_root);
 void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
 			   u64 bytes);
 int btrfs_find_space_cluster(struct btrfs_trans_handle *trans,

commit 34d52cb6c50b5a43901709998f59fb1c5a43dc4a
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Mar 29 13:46:06 2011 +0800

    Btrfs: Make free space cache code generic
    
    So we can re-use the code to cache free inode numbers.
    
    The change is quite straightforward. Two new structures are introduced.
    
    - struct btrfs_free_space_ctl
    
      We move those variables that are used for caching free space from
      struct btrfs_block_group_cache to this new struct.
    
    - struct btrfs_free_space_op
    
      We do block group specific work (e.g. calculation of extents threshold)
      through functions registered in this struct.
    
    And then we can remove references to struct btrfs_block_group_cache.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 12b2b5165f8a..a64a23fae1eb 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -27,6 +27,25 @@ struct btrfs_free_space {
 	struct list_head list;
 };
 
+struct btrfs_free_space_ctl {
+	spinlock_t tree_lock;
+	struct rb_root free_space_offset;
+	u64 free_space;
+	int extents_thresh;
+	int free_extents;
+	int total_bitmaps;
+	int unit;
+	u64 start;
+	struct btrfs_free_space_op *op;
+	void *private;
+};
+
+struct btrfs_free_space_op {
+	void (*recalc_thresholds)(struct btrfs_free_space_ctl *ctl);
+	bool (*use_bitmap)(struct btrfs_free_space_ctl *ctl,
+			   struct btrfs_free_space *info);
+};
+
 struct inode *lookup_free_space_inode(struct btrfs_root *root,
 				      struct btrfs_block_group_cache
 				      *block_group, struct btrfs_path *path);
@@ -45,6 +64,7 @@ int btrfs_write_out_cache(struct btrfs_root *root,
 			  struct btrfs_trans_handle *trans,
 			  struct btrfs_block_group_cache *block_group,
 			  struct btrfs_path *path);
+void btrfs_init_free_space_ctl(struct btrfs_block_group_cache *block_group);
 int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
 			 u64 bytenr, u64 size);
 int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,

commit 92c423118105e1c8c1587367a26eeb3277bda89a
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Wed Mar 2 16:50:21 2011 +0800

    Btrfs: Remove unused btrfs_block_group_free_space()
    
    We've already recorded the value in block_group->frees_space.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 65c3b935289f..12b2b5165f8a 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -55,7 +55,6 @@ u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
 			       u64 offset, u64 bytes, u64 empty_size);
 void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
 			   u64 bytes);
-u64 btrfs_block_group_free_space(struct btrfs_block_group_cache *block_group);
 int btrfs_find_space_cluster(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root,
 			     struct btrfs_block_group_cache *block_group,

commit f7039b1d5c32241f87a513e33120db36bf30264d
Author: Li Dongyang <lidongyang@novell.com>
Date:   Thu Mar 24 10:24:28 2011 +0000

    Btrfs: add btrfs_trim_fs() to handle FITRIM
    
    We take an free extent out from allocator, trim it, then put it back,
    but before we trim the block group, we should make sure the block group is
    cached, so plus a little change to make cache_block_group() run without a
    transaction.
    
    Signed-off-by: Li Dongyang <lidongyang@novell.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index e49ca5c321b5..65c3b935289f 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -68,4 +68,6 @@ u64 btrfs_alloc_from_cluster(struct btrfs_block_group_cache *block_group,
 int btrfs_return_cluster_to_free_space(
 			       struct btrfs_block_group_cache *block_group,
 			       struct btrfs_free_cluster *cluster);
+int btrfs_trim_block_group(struct btrfs_block_group_cache *block_group,
+			   u64 *trimmed, u64 start, u64 end, u64 minlen);
 #endif

commit 9d66e233c7042da27ec699453770f41e567a0442
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Aug 25 16:54:15 2010 -0400

    Btrfs: load free space cache if it exists
    
    This patch actually loads the free space cache if it exists.  The only thing
    that really changes here is that we need to cache the block group if we're going
    to remove an extent from it.  Previously we did not do this since the caching
    kthread would pick it up.  With the on disk cache we don't have this luxury so
    we need to make sure we read the on disk cache in first, and then remove the
    extent, that way when the extent is unpinned the free space is added to the
    block group.  This has been tested with all sorts of things.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 189f740bd3c0..e49ca5c321b5 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -39,6 +39,8 @@ int btrfs_truncate_free_space_cache(struct btrfs_root *root,
 				    struct btrfs_trans_handle *trans,
 				    struct btrfs_path *path,
 				    struct inode *inode);
+int load_free_space_cache(struct btrfs_fs_info *fs_info,
+			  struct btrfs_block_group_cache *block_group);
 int btrfs_write_out_cache(struct btrfs_root *root,
 			  struct btrfs_trans_handle *trans,
 			  struct btrfs_block_group_cache *block_group,

commit 0cb59c9953171e9adf6da8142a5c85ceb77bb60d
Author: Josef Bacik <josef@redhat.com>
Date:   Fri Jul 2 12:14:14 2010 -0400

    Btrfs: write out free space cache
    
    This is a simple bit, just dump the free space cache out to our preallocated
    inode when we're writing out dirty block groups.  There are a bunch of changes
    in inode.c in order to account for special cases.  Mostly when we're doing the
    writeout we're holding trans_mutex, so we need to use the nolock transacation
    functions.  Also we can't do asynchronous completions since the async thread
    could be blocked on already completed IO waiting for the transaction lock.  This
    has been tested with xfstests and btrfs filesystem balance, as well as my ENOSPC
    tests.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 45be29e5f01e..189f740bd3c0 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -34,10 +34,15 @@ int create_free_space_inode(struct btrfs_root *root,
 			    struct btrfs_trans_handle *trans,
 			    struct btrfs_block_group_cache *block_group,
 			    struct btrfs_path *path);
+
 int btrfs_truncate_free_space_cache(struct btrfs_root *root,
 				    struct btrfs_trans_handle *trans,
 				    struct btrfs_path *path,
 				    struct inode *inode);
+int btrfs_write_out_cache(struct btrfs_root *root,
+			  struct btrfs_trans_handle *trans,
+			  struct btrfs_block_group_cache *block_group,
+			  struct btrfs_path *path);
 int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
 			 u64 bytenr, u64 size);
 int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,

commit 0af3d00bad38d3bb9912a60928ad0669f17bdb76
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jun 21 14:48:16 2010 -0400

    Btrfs: create special free space cache inode
    
    In order to save free space cache, we need an inode to hold the data, and we
    need a special item to point at the right inode for the right block group.  So
    first, create a special item that will point to the right inode, and the number
    of extent entries we will have and the number of bitmaps we will have.  We
    truncate and pre-allocate space everytime to make sure it's uptodate.
    
    This feature will be turned on as soon as you mount with -o space_cache, however
    it is safe to boot into old kernels, they will just generate the cache the old
    fashion way.  When you boot back into a newer kernel we will notice that we
    modified and not the cache and automatically discard the cache.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 890a8e79011b..45be29e5f01e 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -27,6 +27,17 @@ struct btrfs_free_space {
 	struct list_head list;
 };
 
+struct inode *lookup_free_space_inode(struct btrfs_root *root,
+				      struct btrfs_block_group_cache
+				      *block_group, struct btrfs_path *path);
+int create_free_space_inode(struct btrfs_root *root,
+			    struct btrfs_trans_handle *trans,
+			    struct btrfs_block_group_cache *block_group,
+			    struct btrfs_path *path);
+int btrfs_truncate_free_space_cache(struct btrfs_root *root,
+				    struct btrfs_trans_handle *trans,
+				    struct btrfs_path *path,
+				    struct inode *inode);
 int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
 			 u64 bytenr, u64 size);
 int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,

commit 963030817060e4f109be1993b9ae8f81dbf5e11a
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jul 13 21:29:25 2009 -0400

    Btrfs: use hybrid extents+bitmap rb tree for free space
    
    Currently btrfs has a problem where it can use a ridiculous amount of RAM simply
    tracking free space.  As free space gets fragmented, we end up with thousands of
    entries on an rb-tree per block group, which usually spans 1 gig of area.  Since
    we currently don't ever flush free space cache back to disk this gets to be a
    bit unweildly on large fs's with lots of fragmentation.
    
    This patch solves this problem by using PAGE_SIZE bitmaps for parts of the free
    space cache.  Initially we calculate a threshold of extent entries we can
    handle, which is however many extent entries we can cram into 16k of ram.  The
    maximum amount of RAM that should ever be used to track 1 gigabyte of diskspace
    will be 32k of RAM, which scales much better than we did before.
    
    Once we pass the extent threshold, we start adding bitmaps and using those
    instead for tracking the free space.  This patch also makes it so that any free
    space thats less than 4 * sectorsize we go ahead and put into a bitmap.  This is
    nice since we try and allocate out of the front of a block group, so if the
    front of a block group is heavily fragmented and then has a huge chunk of free
    space at the end, we go ahead and add the fragmented areas to bitmaps and use a
    normal extent entry to track the big chunk at the back of the block group.
    
    I've also taken the opportunity to revamp how we search for free space.
    Previously we indexed free space via an offset indexed rb tree and a bytes
    indexed rb tree.  I've dropped the bytes indexed rb tree and use only the offset
    indexed rb tree.  This cuts the number of tree operations we were doing
    previously down by half, and gives us a little bit of a better allocation
    pattern since we will always start from a specific offset and search forward
    from there, instead of searching for the size we need and try and get it as
    close as possible to the offset we want.
    
    I've given this a healthy amount of testing pre-new format stuff, as well as
    post-new format stuff.  I've booted up my fedora box which is installed on btrfs
    with this patch and ran with it for a few days without issues.  I've not seen
    any performance regressions in any of my tests.
    
    Since the last patch Yan Zheng fixed a problem where we could have overlapping
    entries, so updating their offset inline would cause problems.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@redhat.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index 266fb8764054..890a8e79011b 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -19,6 +19,14 @@
 #ifndef __BTRFS_FREE_SPACE_CACHE
 #define __BTRFS_FREE_SPACE_CACHE
 
+struct btrfs_free_space {
+	struct rb_node offset_index;
+	u64 offset;
+	u64 bytes;
+	unsigned long *bitmap;
+	struct list_head list;
+};
+
 int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
 			 u64 bytenr, u64 size);
 int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,

commit 451d7585a8bb1b9bec0d676ce3dece1923164e55
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 9 20:28:34 2009 -0400

    Btrfs: add mount -o ssd_spread to spread allocations out
    
    Some SSDs perform best when reusing block numbers often, while
    others perform much better when clustering strictly allocates
    big chunks of unused space.
    
    The default mount -o ssd will find rough groupings of blocks
    where there are a bunch of free blocks that might have some
    allocated blocks mixed in.
    
    mount -o ssd_spread will make sure there are no allocated blocks
    mixed in.  It should perform better on lower end SSDs.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
index ab0bdc0a63ce..266fb8764054 100644
--- a/fs/btrfs/free-space-cache.h
+++ b/fs/btrfs/free-space-cache.h
@@ -31,6 +31,7 @@ void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
 			   u64 bytes);
 u64 btrfs_block_group_free_space(struct btrfs_block_group_cache *block_group);
 int btrfs_find_space_cluster(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root,
 			     struct btrfs_block_group_cache *block_group,
 			     struct btrfs_free_cluster *cluster,
 			     u64 offset, u64 bytes, u64 empty_size);

commit fa9c0d795f7b57c76560b7fac703f5d341210e28
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Apr 3 09:47:43 2009 -0400

    Btrfs: rework allocation clustering
    
    Because btrfs is copy-on-write, we end up picking new locations for
    blocks very often.  This makes it fairly difficult to maintain perfect
    read patterns over time, but we can at least do some optimizations
    for writes.
    
    This is done today by remembering the last place we allocated and
    trying to find a free space hole big enough to hold more than just one
    allocation.  The end result is that we tend to write sequentially to
    the drive.
    
    This happens all the time for metadata and it happens for data
    when mounted -o ssd.  But, the way we record it is fairly racey
    and it tends to fragment the free space over time because we are trying
    to allocate fairly large areas at once.
    
    This commit gets rid of the races by adding a free space cluster object
    with dedicated locking to make sure that only one process at a time
    is out replacing the cluster.
    
    The free space fragmentation is somewhat solved by allowing a cluster
    to be comprised of smaller free space extents.  This part definitely
    adds some CPU time to the cluster allocations, but it allows the allocator
    to consume the small holes left behind by cow.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h
new file mode 100644
index 000000000000..ab0bdc0a63ce
--- /dev/null
+++ b/fs/btrfs/free-space-cache.h
@@ -0,0 +1,44 @@
+/*
+ * Copyright (C) 2009 Oracle.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
+#ifndef __BTRFS_FREE_SPACE_CACHE
+#define __BTRFS_FREE_SPACE_CACHE
+
+int btrfs_add_free_space(struct btrfs_block_group_cache *block_group,
+			 u64 bytenr, u64 size);
+int btrfs_remove_free_space(struct btrfs_block_group_cache *block_group,
+			    u64 bytenr, u64 size);
+void btrfs_remove_free_space_cache(struct btrfs_block_group_cache
+				   *block_group);
+u64 btrfs_find_space_for_alloc(struct btrfs_block_group_cache *block_group,
+			       u64 offset, u64 bytes, u64 empty_size);
+void btrfs_dump_free_space(struct btrfs_block_group_cache *block_group,
+			   u64 bytes);
+u64 btrfs_block_group_free_space(struct btrfs_block_group_cache *block_group);
+int btrfs_find_space_cluster(struct btrfs_trans_handle *trans,
+			     struct btrfs_block_group_cache *block_group,
+			     struct btrfs_free_cluster *cluster,
+			     u64 offset, u64 bytes, u64 empty_size);
+void btrfs_init_free_cluster(struct btrfs_free_cluster *cluster);
+u64 btrfs_alloc_from_cluster(struct btrfs_block_group_cache *block_group,
+			     struct btrfs_free_cluster *cluster, u64 bytes,
+			     u64 min_start);
+int btrfs_return_cluster_to_free_space(
+			       struct btrfs_block_group_cache *block_group,
+			       struct btrfs_free_cluster *cluster);
+#endif
