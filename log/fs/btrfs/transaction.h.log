commit 7f9fe614407692f670601a634621138233ac00d7
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Fri Mar 13 15:58:05 2020 -0400

    btrfs: improve global reserve stealing logic
    
    For unlink transactions and block group removal
    btrfs_start_transaction_fallback_global_rsv will first try to start an
    ordinary transaction and if it fails it will fall back to reserving the
    required amount by stealing from the global reserve. This is problematic
    because of all the same reasons we had with previous iterations of the
    ENOSPC handling, thundering herd.  We get a bunch of failures all at
    once, everybody tries to allocate from the global reserve, some win and
    some lose, we get an ENSOPC.
    
    Fix this behavior by introducing BTRFS_RESERVE_FLUSH_ALL_STEAL. It's
    used to mark unlink reservation. To fix this we need to integrate this
    logic into the normal ENOSPC infrastructure.  We still go through all of
    the normal flushing work, and at the moment we begin to fail all the
    tickets we try to satisfy any tickets that are allowed to steal by
    stealing from the global reserve.  If this works we start the flushing
    system over again just like we would with a normal ticket satisfaction.
    This serializes our global reserve stealing, so we don't have the
    thundering herd problem.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Tested-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 31ae8d273065..bf102e64bfb2 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -193,8 +193,7 @@ struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   unsigned int num_items);
 struct btrfs_trans_handle *btrfs_start_transaction_fallback_global_rsv(
 					struct btrfs_root *root,
-					unsigned int num_items,
-					int min_factor);
+					unsigned int num_items);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_spacecache(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nostart(struct btrfs_root *root);

commit fe119a6eeb670585e29dbe3932e00ad29ae8f5f9
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Jan 20 16:09:18 2020 +0200

    btrfs: switch to per-transaction pinned extents
    
    This commit flips the switch to start tracking/processing pinned extents
    on a per-transaction basis. It mostly replaces all references from
    btrfs_fs_info::(pinned_extents|freed_extents[]) to
    btrfs_transaction::pinned_extents.
    
    Two notable modifications that warrant explicit mention are changing
    clean_pinned_extents to get a reference to the previously running
    transaction. The other one is removal of call to
    btrfs_destroy_pinned_extent since transactions are going to be cleaned
    in btrfs_cleanup_one_transaction.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 453cea7c7a72..31ae8d273065 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -71,6 +71,7 @@ struct btrfs_transaction {
 	 */
 	struct list_head io_bgs;
 	struct list_head dropped_roots;
+	struct extent_io_tree pinned_extents;
 
 	/*
 	 * we need to make sure block group deletion doesn't race with

commit bf31f87f71cc7a89871ab0a451c047a0c0144bf1
Author: David Sterba <dsterba@suse.com>
Date:   Wed Feb 5 17:34:34 2020 +0100

    btrfs: add wrapper for transaction abort predicate
    
    The status of aborted transaction can change between calls and it needs
    to be accessed by READ_ONCE. Add a helper that also wraps the unlikely
    hint.
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 49f7196368f5..453cea7c7a72 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -115,6 +115,10 @@ struct btrfs_trans_handle {
 	struct btrfs_block_rsv *orig_rsv;
 	refcount_t use_count;
 	unsigned int type;
+	/*
+	 * Error code of transaction abort, set outside of locks and must use
+	 * the READ_ONCE/WRITE_ONCE access
+	 */
 	short aborted;
 	bool adding_csums;
 	bool allocating_chunk;
@@ -126,6 +130,14 @@ struct btrfs_trans_handle {
 	struct list_head new_bgs;
 };
 
+/*
+ * The abort status can be changed between calls and is not protected by locks.
+ * This accepts btrfs_transaction and btrfs_trans_handle as types. Once it's
+ * set to a non-zero value it does not change, so the macro should be in checks
+ * but is not necessary for further reads of the value.
+ */
+#define TRANS_ABORTED(trans)		(unlikely(READ_ONCE((trans)->aborted)))
+
 struct btrfs_pending_snapshot {
 	struct dentry *dentry;
 	struct inode *dir;

commit 8d510121bfbf87302e0594d2022c5e7d52b26f7f
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Tue Oct 8 20:43:06 2019 +0300

    btrfs: Rename btrfs_join_transaction_nolock
    
    This function is used only during the final phase of freespace cache
    writeout. This is necessary since using the plain btrfs_join_transaction
    api is deadlock prone. The deadlock looks like:
    
    T1:
    btrfs_commit_transaction
      commit_cowonly_roots
        btrfs_write_dirty_block_groups
          btrfs_wait_cache_io
            __btrfs_wait_cache_io
           btrfs_wait_ordered_range <-- Triggers ordered IO for freespace
                                        inode and blocks transaction commit
                                        until freespace cache writeout
    
    T2: <-- after T1 has triggered the writeout
    finish_ordered_fn
      btrfs_finish_ordered_io
        btrfs_join_transaction <--- this would block waiting for current
                                    transaction to commit, but since trans
                                    commit is waiting for this writeout to
                                    finish
    
    The special purpose functions prevents it by simply skipping the "wait
    for writeout" since it's guaranteed the transaction won't proceed until
    we are done.
    
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 2ac89fb0d709..49f7196368f5 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -183,7 +183,7 @@ struct btrfs_trans_handle *btrfs_start_transaction_fallback_global_rsv(
 					unsigned int num_items,
 					int min_factor);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
-struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);
+struct btrfs_trans_handle *btrfs_join_transaction_spacecache(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nostart(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_attach_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_attach_transaction_barrier(

commit 3296bf562443a8ca35aaad959a76a49e9b412760
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Aug 22 15:25:00 2019 +0800

    btrfs: transaction: Cleanup unused TRANS_STATE_BLOCKED
    
    The state was introduced in commit 4a9d8bdee368 ("Btrfs: make the state
    of the transaction more readable"), then in commit 302167c50b32
    ("btrfs: don't end the transaction for delayed refs in throttle") the
    state is completely removed.
    
    So we can just clean up the state since it's only compared but never
    set.
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index c51135d9b448..2ac89fb0d709 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -13,7 +13,6 @@
 
 enum btrfs_trans_state {
 	TRANS_STATE_RUNNING,
-	TRANS_STATE_BLOCKED,
 	TRANS_STATE_COMMIT_START,
 	TRANS_STATE_COMMIT_DOING,
 	TRANS_STATE_UNBLOCKED,

commit b9fae2ebee0cc3a16e1b61fa397099886886e906
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Sep 11 17:42:38 2019 +0100

    Btrfs: make btrfs_wait_extents() static
    
    It's not used ouside of transaction.c
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 2c5a6f6e5bb0..c51135d9b448 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -218,8 +218,6 @@ int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_write_marked_extents(struct btrfs_fs_info *fs_info,
 				struct extent_io_tree *dirty_pages, int mark);
-int btrfs_wait_extents(struct btrfs_fs_info *fs_info,
-		       struct extent_io_tree *dirty_pages);
 int btrfs_wait_tree_log_extents(struct btrfs_root *root, int mark);
 int btrfs_transaction_blocked(struct btrfs_fs_info *info);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);

commit a6d155d2e363f26290ffd50591169cb96c2a609e
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Jul 29 09:37:10 2019 +0100

    Btrfs: fix deadlock between fiemap and transaction commits
    
    The fiemap handler locks a file range that can have unflushed delalloc,
    and after locking the range, it tries to attach to a running transaction.
    If the running transaction started its commit, that is, it is in state
    TRANS_STATE_COMMIT_START, and either the filesystem was mounted with the
    flushoncommit option or the transaction is creating a snapshot for the
    subvolume that contains the file that fiemap is operating on, we end up
    deadlocking. This happens because fiemap is blocked on the transaction,
    waiting for it to complete, and the transaction is waiting for the flushed
    dealloc to complete, which requires locking the file range that the fiemap
    task already locked. The following stack traces serve as an example of
    when this deadlock happens:
    
      (...)
      [404571.515510] Workqueue: btrfs-endio-write btrfs_endio_write_helper [btrfs]
      [404571.515956] Call Trace:
      [404571.516360]  ? __schedule+0x3ae/0x7b0
      [404571.516730]  schedule+0x3a/0xb0
      [404571.517104]  lock_extent_bits+0x1ec/0x2a0 [btrfs]
      [404571.517465]  ? remove_wait_queue+0x60/0x60
      [404571.517832]  btrfs_finish_ordered_io+0x292/0x800 [btrfs]
      [404571.518202]  normal_work_helper+0xea/0x530 [btrfs]
      [404571.518566]  process_one_work+0x21e/0x5c0
      [404571.518990]  worker_thread+0x4f/0x3b0
      [404571.519413]  ? process_one_work+0x5c0/0x5c0
      [404571.519829]  kthread+0x103/0x140
      [404571.520191]  ? kthread_create_worker_on_cpu+0x70/0x70
      [404571.520565]  ret_from_fork+0x3a/0x50
      [404571.520915] kworker/u8:6    D    0 31651      2 0x80004000
      [404571.521290] Workqueue: btrfs-flush_delalloc btrfs_flush_delalloc_helper [btrfs]
      (...)
      [404571.537000] fsstress        D    0 13117  13115 0x00004000
      [404571.537263] Call Trace:
      [404571.537524]  ? __schedule+0x3ae/0x7b0
      [404571.537788]  schedule+0x3a/0xb0
      [404571.538066]  wait_current_trans+0xc8/0x100 [btrfs]
      [404571.538349]  ? remove_wait_queue+0x60/0x60
      [404571.538680]  start_transaction+0x33c/0x500 [btrfs]
      [404571.539076]  btrfs_check_shared+0xa3/0x1f0 [btrfs]
      [404571.539513]  ? extent_fiemap+0x2ce/0x650 [btrfs]
      [404571.539866]  extent_fiemap+0x2ce/0x650 [btrfs]
      [404571.540170]  do_vfs_ioctl+0x526/0x6f0
      [404571.540436]  ksys_ioctl+0x70/0x80
      [404571.540734]  __x64_sys_ioctl+0x16/0x20
      [404571.540997]  do_syscall_64+0x60/0x1d0
      [404571.541279]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      (...)
      [404571.543729] btrfs           D    0 14210  14208 0x00004000
      [404571.544023] Call Trace:
      [404571.544275]  ? __schedule+0x3ae/0x7b0
      [404571.544526]  ? wait_for_completion+0x112/0x1a0
      [404571.544795]  schedule+0x3a/0xb0
      [404571.545064]  schedule_timeout+0x1ff/0x390
      [404571.545351]  ? lock_acquire+0xa6/0x190
      [404571.545638]  ? wait_for_completion+0x49/0x1a0
      [404571.545890]  ? wait_for_completion+0x112/0x1a0
      [404571.546228]  wait_for_completion+0x131/0x1a0
      [404571.546503]  ? wake_up_q+0x70/0x70
      [404571.546775]  btrfs_wait_ordered_extents+0x27c/0x400 [btrfs]
      [404571.547159]  btrfs_commit_transaction+0x3b0/0xae0 [btrfs]
      [404571.547449]  ? btrfs_mksubvol+0x4a4/0x640 [btrfs]
      [404571.547703]  ? remove_wait_queue+0x60/0x60
      [404571.547969]  btrfs_mksubvol+0x605/0x640 [btrfs]
      [404571.548226]  ? __sb_start_write+0xd4/0x1c0
      [404571.548512]  ? mnt_want_write_file+0x24/0x50
      [404571.548789]  btrfs_ioctl_snap_create_transid+0x169/0x1a0 [btrfs]
      [404571.549048]  btrfs_ioctl_snap_create_v2+0x11d/0x170 [btrfs]
      [404571.549307]  btrfs_ioctl+0x133f/0x3150 [btrfs]
      [404571.549549]  ? mem_cgroup_charge_statistics+0x4c/0xd0
      [404571.549792]  ? mem_cgroup_commit_charge+0x84/0x4b0
      [404571.550064]  ? __handle_mm_fault+0xe3e/0x11f0
      [404571.550306]  ? do_raw_spin_unlock+0x49/0xc0
      [404571.550608]  ? _raw_spin_unlock+0x24/0x30
      [404571.550976]  ? __handle_mm_fault+0xedf/0x11f0
      [404571.551319]  ? do_vfs_ioctl+0xa2/0x6f0
      [404571.551659]  ? btrfs_ioctl_get_supported_features+0x30/0x30 [btrfs]
      [404571.552087]  do_vfs_ioctl+0xa2/0x6f0
      [404571.552355]  ksys_ioctl+0x70/0x80
      [404571.552621]  __x64_sys_ioctl+0x16/0x20
      [404571.552864]  do_syscall_64+0x60/0x1d0
      [404571.553104]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      (...)
    
    If we were joining the transaction instead of attaching to it, we would
    not risk a deadlock because a join only blocks if the transaction is in a
    state greater then or equals to TRANS_STATE_COMMIT_DOING, and the delalloc
    flush performed by a transaction is done before it reaches that state,
    when it is in the state TRANS_STATE_COMMIT_START. However a transaction
    join is intended for use cases where we do modify the filesystem, and
    fiemap only needs to peek at delayed references from the current
    transaction in order to determine if extents are shared, and, besides
    that, when there is no current transaction or when it blocks to wait for
    a current committing transaction to complete, it creates a new transaction
    without reserving any space. Such unnecessary transactions, besides doing
    unnecessary IO, can cause transaction aborts (-ENOSPC) and unnecessary
    rotation of the precious backup roots.
    
    So fix this by adding a new transaction join variant, named join_nostart,
    which behaves like the regular join, but it does not create a transaction
    when none currently exists or after waiting for a committing transaction
    to complete.
    
    Fixes: 03628cdbc64db6 ("Btrfs: do not start a transaction during fiemap")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 527ea94b57d9..2c5a6f6e5bb0 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -94,11 +94,13 @@ struct btrfs_transaction {
 #define __TRANS_JOIN		(1U << 11)
 #define __TRANS_JOIN_NOLOCK	(1U << 12)
 #define __TRANS_DUMMY		(1U << 13)
+#define __TRANS_JOIN_NOSTART	(1U << 14)
 
 #define TRANS_START		(__TRANS_START | __TRANS_FREEZABLE)
 #define TRANS_ATTACH		(__TRANS_ATTACH)
 #define TRANS_JOIN		(__TRANS_JOIN | __TRANS_FREEZABLE)
 #define TRANS_JOIN_NOLOCK	(__TRANS_JOIN_NOLOCK)
+#define TRANS_JOIN_NOSTART	(__TRANS_JOIN_NOSTART)
 
 #define TRANS_EXTWRITERS	(__TRANS_START | __TRANS_ATTACH)
 
@@ -183,6 +185,7 @@ struct btrfs_trans_handle *btrfs_start_transaction_fallback_global_rsv(
 					int min_factor);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);
+struct btrfs_trans_handle *btrfs_join_transaction_nostart(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_attach_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_attach_transaction_barrier(
 					struct btrfs_root *root);

commit fb6dea26601b60e41d70c310537dd1e2617b25b6
Author: Josef Bacik <josef@toxicpanda.com>
Date:   Wed Jun 19 15:11:59 2019 -0400

    btrfs: migrate btrfs_trans_release_chunk_metadata
    
    Move this into transaction.c with the rest of the transaction related
    code.
    
    Signed-off-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 78c446c222b7..527ea94b57d9 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -224,5 +224,6 @@ void btrfs_put_transaction(struct btrfs_transaction *transaction);
 void btrfs_apply_pending_changes(struct btrfs_fs_info *fs_info);
 void btrfs_add_dropped_root(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
+void btrfs_trans_release_chunk_metadata(struct btrfs_trans_handle *trans);
 
 #endif

commit 74f657d89c6734c260509338e88ad6d5f5a24e1d
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Apr 15 09:29:19 2019 +0100

    Btrfs: remove no longer used member num_dirty_bgs from transaction
    
    The member num_dirty_bgs of struct btrfs_transaction is not used anymore,
    it is set and incremented but nothing reads its value anymore. Its last
    read use was removed by commit 64403612b73a94 ("btrfs: rework
    btrfs_check_space_for_delayed_refs"). So just remove that member.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 4419a4a0294b..78c446c222b7 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -80,7 +80,6 @@ struct btrfs_transaction {
 	 */
 	struct mutex cache_write_mutex;
 	spinlock_t dirty_bgs_lock;
-	unsigned int num_dirty_bgs;
 	/* Protected by spin lock fs_info->unused_bgs_lock. */
 	struct list_head deleted_bgs;
 	spinlock_t dropped_roots_lock;

commit 1c11b63eff2a67906cb9137bc6b2ee27767f313b
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Mar 27 14:24:12 2019 +0200

    btrfs: replace pending/pinned chunks lists with io tree
    
    The pending chunks list contains chunks that are allocated in the
    current transaction but haven't been created yet. The pinned chunks
    list contains chunks that are being released in the current transaction.
    Both describe chunks that are not reflected on disk as in use but are
    unavailable just the same.
    
    The pending chunks list is anchored by the transaction handle, which
    means that we need to hold a reference to a transaction when working
    with the list.
    
    The way we use them is by iterating over both lists to perform
    comparisons on the stripes they describe for each device. This is
    backwards and requires that we keep a transaction handle open while
    we're trimming.
    
    This patchset adds an extent_io_tree to btrfs_device that maintains
    the allocation state of the device.  Extents are set dirty when
    chunks are first allocated -- when the extent maps are added to the
    mapping tree. They're cleared when last removed -- when the extent
    maps are removed from the mapping tree. This matches the lifespan
    of the pending and pinned chunks list and allows us to do trims
    on unallocated space safely without pinning the transaction for what
    may be a lengthy operation. We can also use this io tree to mark
    which chunks have already been trimmed so we don't repeat the operation.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 2bd76f681520..4419a4a0294b 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -51,7 +51,6 @@ struct btrfs_transaction {
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 	struct list_head pending_snapshots;
-	struct list_head pending_chunks;
 	struct list_head dev_update_list;
 	struct list_head switch_commits;
 	struct list_head dirty_bgs;

commit bbbf7243d62d8be73b7ef60721c127b36b2d523e
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Mar 25 14:31:22 2019 +0200

    btrfs: combine device update operations during transaction commit
    
    We currently overload the pending_chunks list to handle updating
    btrfs_device->commit_bytes used.  We don't actually care about the
    extent mapping or even the device mapping for the chunk - we just need
    the device, and we can end up processing it multiple times.  The
    fs_devices->resized_list does more or less the same thing, but with the
    disk size.  They are called consecutively during commit and have more or
    less the same purpose.
    
    We can combine the two lists into a single list that attaches to the
    transaction and contains a list of devices that need updating.  Since we
    always add the device to a list when we change bytes_used or
    disk_total_size, there's no harm in copying both values at once.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index b34678e7968e..2bd76f681520 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -52,6 +52,7 @@ struct btrfs_transaction {
 	wait_queue_head_t commit_wait;
 	struct list_head pending_snapshots;
 	struct list_head pending_chunks;
+	struct list_head dev_update_list;
 	struct list_head switch_commits;
 	struct list_head dirty_bgs;
 

commit 3b1da515c64e18bdd6a13348313f1168396b3722
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Mar 11 13:10:56 2019 +0000

    Btrfs: remove no longer used 'sync' member from transaction handle
    
    Commit db2462a6ad3d ("btrfs: don't run delayed refs in the end transaction
    logic") removed its last use, so now it does absolutely nothing, therefore
    remove it.
    
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index f1ba78949d1b..b34678e7968e 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -120,7 +120,6 @@ struct btrfs_trans_handle {
 	bool allocating_chunk;
 	bool can_flush_pending_bgs;
 	bool reloc_reserved;
-	bool sync;
 	bool dirty;
 	struct btrfs_root *root;
 	struct btrfs_fs_info *fs_info;

commit bbe339cc323ca9d2a57ac203d2d9d11a09655dcc
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 27 15:25:13 2018 +0100

    btrfs: drop extra enum initialization where using defaults
    
    The first auto-assigned value to enum is 0, we can use that and not
    initialize all members where the auto-increment does the same. This is
    used for values that are not part of on-disk format.
    
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Qu Wenruo <wqu@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 703d5116a2fc..f1ba78949d1b 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -12,13 +12,13 @@
 #include "ctree.h"
 
 enum btrfs_trans_state {
-	TRANS_STATE_RUNNING		= 0,
-	TRANS_STATE_BLOCKED		= 1,
-	TRANS_STATE_COMMIT_START	= 2,
-	TRANS_STATE_COMMIT_DOING	= 3,
-	TRANS_STATE_UNBLOCKED		= 4,
-	TRANS_STATE_COMPLETED		= 5,
-	TRANS_STATE_MAX			= 6,
+	TRANS_STATE_RUNNING,
+	TRANS_STATE_BLOCKED,
+	TRANS_STATE_COMMIT_START,
+	TRANS_STATE_COMMIT_DOING,
+	TRANS_STATE_UNBLOCKED,
+	TRANS_STATE_COMPLETED,
+	TRANS_STATE_MAX,
 };
 
 #define BTRFS_TRANS_HAVE_FREE_BGS	0

commit 85dd506c8e022a5c5555ad22decfa0abf93a5d64
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Oct 26 17:15:21 2018 +0100

    Btrfs: remove no longer used stuff for tracking pending ordered extents
    
    Tracking pending ordered extents per transaction was introduced in commit
    50d9aa99bd35 ("Btrfs: make sure logged extents complete in the current
    transaction V3") and later updated in commit 161c3549b45a ("Btrfs: change
    how we wait for pending ordered extents").
    
    However now that on fsync we always wait for ordered extents to complete
    before logging, done in commit 5636cf7d6dc8 ("btrfs: remove the logged
    extents infrastructure"), we no longer need the stuff to track for pending
    ordered extents, which was not completely removed in the mentioned commit.
    So remove the remaining of the pending ordered extents infrastructure.
    
    Reviewed-by: Liu Bo <bo.liu@linux.alibaba.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 4cbb1b55387d..703d5116a2fc 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -39,7 +39,6 @@ struct btrfs_transaction {
 	 */
 	atomic_t num_writers;
 	refcount_t use_count;
-	atomic_t pending_ordered;
 
 	unsigned long flags;
 
@@ -51,7 +50,6 @@ struct btrfs_transaction {
 	time64_t start_time;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
-	wait_queue_head_t pending_wait;
 	struct list_head pending_snapshots;
 	struct list_head pending_chunks;
 	struct list_head switch_commits;

commit a944442c2b8a420301e7830f976bab8cc86a2b4d
Author: Allen Pais <allen.lkml@gmail.com>
Date:   Tue Jun 12 17:18:25 2018 +0530

    btrfs: replace get_seconds with new 64bit time API
    
    The get_seconds() function is deprecated as it truncates the timestamp
    to 32 bits. Change it to or ktime_get_real_seconds().
    
    Signed-off-by: Allen Pais <allen.lkml@gmail.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    [ update changelog ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 94439482a0ec..4cbb1b55387d 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -48,7 +48,7 @@ struct btrfs_transaction {
 	int aborted;
 	struct list_head list;
 	struct extent_io_tree dirty_pages;
-	unsigned long start_time;
+	time64_t start_time;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 	wait_queue_head_t pending_wait;

commit 6b0cb1f90147908f7d85dd15e4dec56c8b6b632f
Author: Gu JinXiang <gujx@cn.fujitsu.com>
Date:   Wed May 30 11:00:39 2018 +0800

    btrfs: drop useless member qgroup_reserved of btrfs_pending_snapshot
    
    Since there is no more use of qgroup_reserved member in struct
    btrfs_pending_snapshot, remove it.
    
    Signed-off-by: Gu JinXiang <gujx@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index d8c0826bc2c7..94439482a0ec 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -139,7 +139,6 @@ struct btrfs_pending_snapshot {
 	struct btrfs_path *path;
 	/* block reservation for the operation */
 	struct btrfs_block_rsv block_rsv;
-	u64 qgroup_reserved;
 	/* extra metadata reservation for relocation */
 	int error;
 	bool readonly;

commit a514d63882c3d2063b21b865447266ebcb18b04c
Author: Qu Wenruo <wqu@suse.com>
Date:   Fri Dec 22 16:06:39 2017 +0800

    btrfs: qgroup: Commit transaction in advance to reduce early EDQUOT
    
    Unlike previous method that tries to commit transaction inside
    qgroup_reserve(), this time we will try to commit transaction using
    fs_info->transaction_kthread to avoid nested transaction and no need to
    worry about locking context.
    
    Since it's an asynchronous function call and we won't wait for
    transaction commit, unlike previous method, we must call it before we
    hit the qgroup limit.
    
    So this patch will use the ratio and size of qgroup meta_pertrans
    reservation as indicator to check if we should trigger a transaction
    commit.  (meta_prealloc won't be cleaned in transaction committ, it's
    useless anyway)
    
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index c88fccd80bc5..d8c0826bc2c7 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -199,6 +199,20 @@ int btrfs_clean_one_deleted_snapshot(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans);
 int btrfs_commit_transaction_async(struct btrfs_trans_handle *trans,
 				   int wait_for_unblock);
+
+/*
+ * Try to commit transaction asynchronously, so this is safe to call
+ * even holding a spinlock.
+ *
+ * It's done by informing transaction_kthread to commit transaction without
+ * waiting for commit interval.
+ */
+static inline void btrfs_commit_transaction_locksafe(
+		struct btrfs_fs_info *fs_info)
+{
+	set_bit(BTRFS_FS_NEED_ASYNC_COMMIT, &fs_info->flags);
+	wake_up_process(fs_info->transaction_kthread);
+}
 int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans);
 int btrfs_should_end_transaction(struct btrfs_trans_handle *trans);
 void btrfs_throttle(struct btrfs_fs_info *fs_info);

commit 9888c3402c8567a977de37f61e9dd87792723064
Author: David Sterba <dsterba@suse.com>
Date:   Tue Apr 3 19:16:55 2018 +0200

    btrfs: replace GPL boilerplate by SPDX -- headers
    
    Remove GPL boilerplate text (long, short, one-line) and keep the rest,
    ie. personal, company or original source copyright statements. Add the
    SPDX header.
    
    Unify the include protection macros to match the file names.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index b6c94ce33503..c88fccd80bc5 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -1,23 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Copyright (C) 2007 Oracle.  All rights reserved.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public
- * License v2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * You should have received a copy of the GNU General Public
- * License along with this program; if not, write to the
- * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
- * Boston, MA 021110-1307, USA.
  */
 
-#ifndef __BTRFS_TRANSACTION__
-#define __BTRFS_TRANSACTION__
+#ifndef BTRFS_TRANSACTION_H
+#define BTRFS_TRANSACTION_H
 
 #include <linux/refcount.h>
 #include "btrfs_inode.h"
@@ -228,4 +215,5 @@ void btrfs_put_transaction(struct btrfs_transaction *transaction);
 void btrfs_apply_pending_changes(struct btrfs_fs_info *fs_info);
 void btrfs_add_dropped_root(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
+
 #endif

commit bcf3a3e7fb55f9238bc848147316317d099c2048
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Mon Feb 5 10:41:15 2018 +0200

    btrfs: Remove code referencing unused TRANS_USERSPACE
    
    Now that the userspace transaction ioctls have been removed,
    TRANS_USERSPACE is no longer used hence we can remove it.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 2762c8d6191c..b6c94ce33503 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -105,21 +105,18 @@ struct btrfs_transaction {
 
 #define __TRANS_FREEZABLE	(1U << 0)
 
-#define __TRANS_USERSPACE	(1U << 8)
 #define __TRANS_START		(1U << 9)
 #define __TRANS_ATTACH		(1U << 10)
 #define __TRANS_JOIN		(1U << 11)
 #define __TRANS_JOIN_NOLOCK	(1U << 12)
 #define __TRANS_DUMMY		(1U << 13)
 
-#define TRANS_USERSPACE		(__TRANS_USERSPACE | __TRANS_FREEZABLE)
 #define TRANS_START		(__TRANS_START | __TRANS_FREEZABLE)
 #define TRANS_ATTACH		(__TRANS_ATTACH)
 #define TRANS_JOIN		(__TRANS_JOIN | __TRANS_FREEZABLE)
 #define TRANS_JOIN_NOLOCK	(__TRANS_JOIN_NOLOCK)
 
-#define TRANS_EXTWRITERS	(__TRANS_USERSPACE | __TRANS_START |	\
-				 __TRANS_ATTACH)
+#define TRANS_EXTWRITERS	(__TRANS_START | __TRANS_ATTACH)
 
 #define BTRFS_SEND_TRANS_STUB	((void *)1)
 
@@ -207,7 +204,6 @@ struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root
 struct btrfs_trans_handle *btrfs_attach_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_attach_transaction_barrier(
 					struct btrfs_root *root);
-struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *root);
 int btrfs_wait_for_commit(struct btrfs_fs_info *fs_info, u64 transid);
 
 void btrfs_add_dead_root(struct btrfs_root *root);

commit 45ae2c1841c31c90077cf427c09ea0e83e381026
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Thu Feb 8 18:25:18 2018 +0200

    btrfs: Document consistency of transaction->io_bgs list
    
    The reason why io_bgs can be modified without holding any lock is
    non-obvious. Document it and reference that documentation from the
    respective call sites.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 817fd7c9836b..2762c8d6191c 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -69,6 +69,22 @@ struct btrfs_transaction {
 	struct list_head pending_chunks;
 	struct list_head switch_commits;
 	struct list_head dirty_bgs;
+
+	/*
+	 * There is no explicit lock which protects io_bgs, rather its
+	 * consistency is implied by the fact that all the sites which modify
+	 * it do so under some form of transaction critical section, namely:
+	 *
+	 * - btrfs_start_dirty_block_groups - This function can only ever be
+	 *   run by one of the transaction committers. Refer to
+	 *   BTRFS_TRANS_DIRTY_BG_RUN usage in btrfs_commit_transaction
+	 *
+	 * - btrfs_write_dirty_blockgroups - this is called by
+	 *   commit_cowonly_roots from transaction critical section
+	 *   (TRANS_STATE_COMMIT_DOING)
+	 *
+	 * - btrfs_cleanup_dirty_bgs - called on transaction abort
+	 */
 	struct list_head io_bgs;
 	struct list_head dropped_roots;
 

commit 7806c6eb15f227a484c368bbaf07da9978f57869
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Fri Dec 15 12:06:18 2017 +0200

    btrfs: Remove unused btrfs_start_transaction_lflush function
    
    Commit 0e8c36a9fd81 ("Btrfs: fix lots of orphan inodes when the space
    is not enough") changed the way transaction reservation is made in
    btrfs_evict_node and as a result this function became unused. This has
    been the status quo for 5 years in which time no one noticed, so I'd
    say it's safe to assume it's unlikely it will ever be used again.
    
    Historical note: there were more attempts to remove the function, the
    reasoning was missing and only based on some static analysis tool
    reports. Other reason for rejection was that there seemed to be
    connection to BTRFS_RESERVE_FLUSH_LIMIT and that would need to be
    removeed to. This was not correct so removing the function is all we can
    do.
    
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    [ add the note ]
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 6beee072b1bd..817fd7c9836b 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -186,9 +186,6 @@ struct btrfs_trans_handle *btrfs_start_transaction_fallback_global_rsv(
 					struct btrfs_root *root,
 					unsigned int num_items,
 					int min_factor);
-struct btrfs_trans_handle *btrfs_start_transaction_lflush(
-					struct btrfs_root *root,
-					unsigned int num_items);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_attach_transaction(struct btrfs_root *root);

commit 5302e0896445ac3a9c707bd42c39c58a49959980
Author: David Sterba <dsterba@suse.com>
Date:   Wed Nov 8 01:54:33 2017 +0100

    btrfs: reorder btrfs_transaction members for better packing
    
    There are now 20 bytes of holes, we can reduce that to 4 by minor
    changes. Moving 'aborted' to the status and flags is also more logical,
    similar for num_dirty_bgs. The size goes from 432 to 416.
    
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 1805fd101767..6beee072b1bd 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -58,6 +58,7 @@ struct btrfs_transaction {
 
 	/* Be protected by fs_info->trans_lock when we want to change it. */
 	enum btrfs_trans_state state;
+	int aborted;
 	struct list_head list;
 	struct extent_io_tree dirty_pages;
 	unsigned long start_time;
@@ -70,7 +71,6 @@ struct btrfs_transaction {
 	struct list_head dirty_bgs;
 	struct list_head io_bgs;
 	struct list_head dropped_roots;
-	unsigned int num_dirty_bgs;
 
 	/*
 	 * we need to make sure block group deletion doesn't race with
@@ -79,11 +79,11 @@ struct btrfs_transaction {
 	 */
 	struct mutex cache_write_mutex;
 	spinlock_t dirty_bgs_lock;
+	unsigned int num_dirty_bgs;
 	/* Protected by spin lock fs_info->unused_bgs_lock. */
 	struct list_head deleted_bgs;
 	spinlock_t dropped_roots_lock;
 	struct btrfs_delayed_ref_root delayed_refs;
-	int aborted;
 	struct btrfs_fs_info *fs_info;
 };
 

commit 165c8b022c492f7eb33f7c936ac063a6fd4e90a3
Author: David Sterba <dsterba@suse.com>
Date:   Wed Nov 8 02:12:57 2017 +0100

    btrfs: use narrower type for btrfs_transaction::num_dirty_bgs
    
    The u64 is an overkill here, we could not possibly create that many
    blockgroups in one transaction.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index edf53112a6f2..1805fd101767 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -70,7 +70,7 @@ struct btrfs_transaction {
 	struct list_head dirty_bgs;
 	struct list_head io_bgs;
 	struct list_head dropped_roots;
-	u64 num_dirty_bgs;
+	unsigned int num_dirty_bgs;
 
 	/*
 	 * we need to make sure block group deletion doesn't race with

commit 1ca4bb63f6bcc0b4fa3cc6d5aea0a503186a3e20
Author: David Sterba <dsterba@suse.com>
Date:   Wed Nov 8 01:54:33 2017 +0100

    btrfs: reorder btrfs_trans_handle members for better packing
    
    Recent updates to the structure left some holes, reorder the types so
    the packing is tight. The size goes from 112 to 104 on 64bit.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index afa88f035654..edf53112a6f2 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -111,11 +111,12 @@ struct btrfs_trans_handle {
 	u64 transid;
 	u64 bytes_reserved;
 	u64 chunk_bytes_reserved;
-	refcount_t use_count;
 	unsigned long delayed_ref_updates;
 	struct btrfs_transaction *transaction;
 	struct btrfs_block_rsv *block_rsv;
 	struct btrfs_block_rsv *orig_rsv;
+	refcount_t use_count;
+	unsigned int type;
 	short aborted;
 	bool adding_csums;
 	bool allocating_chunk;
@@ -123,7 +124,6 @@ struct btrfs_trans_handle {
 	bool reloc_reserved;
 	bool sync;
 	bool dirty;
-	unsigned int type;
 	struct btrfs_root *root;
 	struct btrfs_fs_info *fs_info;
 	struct list_head new_bgs;

commit b50fff816cbd670ea545ce98ae374356f08f2d75
Author: David Sterba <dsterba@suse.com>
Date:   Wed Nov 8 01:39:58 2017 +0100

    btrfs: switch to refcount_t type for btrfs_trans_handle::use_count
    
    The use_count is a reference counter, we can use the refcount_t type,
    though we don't use the atomicity. This is not a performance critical
    code and we could catch the underflows. The type is changed from long,
    but the number of references will fit an int.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index c48a4a03f1b4..afa88f035654 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -111,7 +111,7 @@ struct btrfs_trans_handle {
 	u64 transid;
 	u64 bytes_reserved;
 	u64 chunk_bytes_reserved;
-	unsigned long use_count;
+	refcount_t use_count;
 	unsigned long delayed_ref_updates;
 	struct btrfs_transaction *transaction;
 	struct btrfs_block_rsv *block_rsv;

commit 2dbda74ed9e5497697b913c780c928e25e70d832
Author: David Sterba <dsterba@suse.com>
Date:   Wed Nov 8 01:32:48 2017 +0100

    btrfs: remove unused member of btrfs_trans_handle
    
    Last user was removed in a monster commit a22285a6a32390195235171
    ("Btrfs: Integrate metadata reservation with start_transaction") in
    2010.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index a673142c003e..c48a4a03f1b4 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -112,7 +112,6 @@ struct btrfs_trans_handle {
 	u64 bytes_reserved;
 	u64 chunk_bytes_reserved;
 	unsigned long use_count;
-	unsigned long blocks_reserved;
 	unsigned long delayed_ref_updates;
 	struct btrfs_transaction *transaction;
 	struct btrfs_block_rsv *block_rsv;

commit 7c2871a2f4695fadc35ea463552b23180c7a7e34
Author: David Sterba <dsterba@suse.com>
Date:   Wed Nov 8 01:07:43 2017 +0100

    btrfs: switch btrfs_trans_handle::adding_csums to bool
    
    The semantics of adding_csums matches bool, 'short' was most likely used
    to save space in a698d0755adb6f2 ("Btrfs: add a type field for the
    transaction handle").
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index c55e44560103..a673142c003e 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -118,7 +118,7 @@ struct btrfs_trans_handle {
 	struct btrfs_block_rsv *block_rsv;
 	struct btrfs_block_rsv *orig_rsv;
 	short aborted;
-	short adding_csums;
+	bool adding_csums;
 	bool allocating_chunk;
 	bool can_flush_pending_bgs;
 	bool reloc_reserved;

commit f486135ebab4fb91366a1e41fb15ed3036ad0cf9
Author: David Sterba <dsterba@suse.com>
Date:   Wed Mar 15 16:17:03 2017 +0100

    btrfs: remove unused qgroup members from btrfs_trans_handle
    
    The members have been effectively unused since "Btrfs: rework qgroup
    accounting" (fcebe4562dec83b3), there's no substitute for
    assert_qgroups_uptodate so it's removed as well.
    
    Reviewed-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 902619f83db6..c55e44560103 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -127,8 +127,6 @@ struct btrfs_trans_handle {
 	unsigned int type;
 	struct btrfs_root *root;
 	struct btrfs_fs_info *fs_info;
-	struct seq_list delayed_ref_elem;
-	struct list_head qgroup_ref_list;
 	struct list_head new_bgs;
 };
 

commit 9b64f57ddf8673d29fafb3405d4aa1e93f5a4cd7
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Mar 3 10:55:11 2017 +0200

    btrfs: convert btrfs_transaction.use_count from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 5dfb5590fff6..902619f83db6 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -18,6 +18,8 @@
 
 #ifndef __BTRFS_TRANSACTION__
 #define __BTRFS_TRANSACTION__
+
+#include <linux/refcount.h>
 #include "btrfs_inode.h"
 #include "delayed-ref.h"
 #include "ctree.h"
@@ -49,7 +51,7 @@ struct btrfs_transaction {
 	 * transaction can end
 	 */
 	atomic_t num_writers;
-	atomic_t use_count;
+	refcount_t use_count;
 	atomic_t pending_ordered;
 
 	unsigned long flags;

commit 3a45bb207ee2c5548ebf6f5fcc7d249e141f15e8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Sep 9 21:39:03 2016 -0400

    btrfs: remove root parameter from transaction commit/end routines
    
    Now we only use the root parameter to print the root objectid in
    a tracepoint.  We can use the root parameter from the transaction
    handle for that.  It's also used to join the transaction with
    async commits, so we remove the comment that it's just for checking.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 1c43ed3aa1ac..5dfb5590fff6 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -123,11 +123,6 @@ struct btrfs_trans_handle {
 	bool sync;
 	bool dirty;
 	unsigned int type;
-	/*
-	 * this root is only needed to validate that the root passed to
-	 * start_transaction is the same as the one passed to end_transaction.
-	 * Subvolume quota depends on this
-	 */
 	struct btrfs_root *root;
 	struct btrfs_fs_info *fs_info;
 	struct seq_list delayed_ref_elem;
@@ -185,8 +180,7 @@ static inline void btrfs_clear_skip_qgroup(struct btrfs_trans_handle *trans)
 	delayed_refs->qgroup_to_skip = 0;
 }
 
-int btrfs_end_transaction(struct btrfs_trans_handle *trans,
-			  struct btrfs_root *root);
+int btrfs_end_transaction(struct btrfs_trans_handle *trans);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   unsigned int num_items);
 struct btrfs_trans_handle *btrfs_start_transaction_fallback_global_rsv(
@@ -207,15 +201,11 @@ int btrfs_wait_for_commit(struct btrfs_fs_info *fs_info, u64 transid);
 void btrfs_add_dead_root(struct btrfs_root *root);
 int btrfs_defrag_root(struct btrfs_root *root);
 int btrfs_clean_one_deleted_snapshot(struct btrfs_root *root);
-int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
-			     struct btrfs_root *root);
+int btrfs_commit_transaction(struct btrfs_trans_handle *trans);
 int btrfs_commit_transaction_async(struct btrfs_trans_handle *trans,
-				   struct btrfs_root *root,
 				   int wait_for_unblock);
-int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
-				   struct btrfs_root *root);
-int btrfs_should_end_transaction(struct btrfs_trans_handle *trans,
-				 struct btrfs_root *root);
+int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans);
+int btrfs_should_end_transaction(struct btrfs_trans_handle *trans);
 void btrfs_throttle(struct btrfs_fs_info *fs_info);
 int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);

commit bf89d38febaadd5b1da60fed54929cbde65fedf9
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Sep 9 20:42:44 2016 -0400

    btrfs: split btrfs_wait_marked_extents into normal and tree log functions
    
    btrfs_write_and_wait_marked_extents and btrfs_sync_log both call
    btrfs_wait_marked_extents, which provides a core loop and then handles
    errors differently based on whether it's it's a log root or not.
    
    This means that btrfs_write_and_wait_marked_extents needs to take a root
    because btrfs_wait_marked_extents requires one, even though it's only
    used to determine whether the root is a log root.  The log root code
    won't ever call into the transaction commit code using a log root, so we
    can factor out the core loop and provide the error handling appropriate
    to each waiter in new routines.  This allows us to eventually remove
    the root argument from btrfs_commit_transaction, and as a result,
    btrfs_end_transaction.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index b005371a62db..1c43ed3aa1ac 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -221,8 +221,9 @@ int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_write_marked_extents(struct btrfs_fs_info *fs_info,
 				struct extent_io_tree *dirty_pages, int mark);
-int btrfs_wait_marked_extents(struct btrfs_root *root,
-				struct extent_io_tree *dirty_pages, int mark);
+int btrfs_wait_extents(struct btrfs_fs_info *fs_info,
+		       struct extent_io_tree *dirty_pages);
+int btrfs_wait_tree_log_extents(struct btrfs_root *root, int mark);
 int btrfs_transaction_blocked(struct btrfs_fs_info *info);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
 void btrfs_put_transaction(struct btrfs_transaction *transaction);

commit 2ff7e61e0d30ff166a2ae94575526bffe11fd1a8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 22 18:54:24 2016 -0400

    btrfs: take an fs_info directly when the root is not used otherwise
    
    There are loads of functions in btrfs that accept a root parameter
    but only use it to obtain an fs_info pointer.  Let's convert those to
    just accept an fs_info pointer directly.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 6cf0d37d4f76..b005371a62db 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -202,7 +202,7 @@ struct btrfs_trans_handle *btrfs_attach_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_attach_transaction_barrier(
 					struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *root);
-int btrfs_wait_for_commit(struct btrfs_root *root, u64 transid);
+int btrfs_wait_for_commit(struct btrfs_fs_info *fs_info, u64 transid);
 
 void btrfs_add_dead_root(struct btrfs_root *root);
 int btrfs_defrag_root(struct btrfs_root *root);
@@ -216,10 +216,10 @@ int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
 int btrfs_should_end_transaction(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root);
-void btrfs_throttle(struct btrfs_root *root);
+void btrfs_throttle(struct btrfs_fs_info *fs_info);
 int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
-int btrfs_write_marked_extents(struct btrfs_root *root,
+int btrfs_write_marked_extents(struct btrfs_fs_info *fs_info,
 				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_wait_marked_extents(struct btrfs_root *root,
 				struct extent_io_tree *dirty_pages, int mark);

commit ab8d0fc48dba09e0a2b8b0dbfe144d4de9eb874f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Sep 20 10:05:02 2016 -0400

    btrfs: convert pr_* to btrfs_* where possible
    
    For many printks, we want to know which file system issued the message.
    
    This patch converts most pr_* calls to use the btrfs_* versions instead.
    In some cases, this means adding plumbing to allow call sites access to
    an fs_info pointer.
    
    fs/btrfs/check-integrity.c is left alone for another day.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index efb122643380..6cf0d37d4f76 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -82,6 +82,7 @@ struct btrfs_transaction {
 	spinlock_t dropped_roots_lock;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
+	struct btrfs_fs_info *fs_info;
 };
 
 #define __TRANS_FREEZABLE	(1U << 0)

commit 64b63580728ef19137d35363a1c28794b70ad416
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Jun 20 17:23:41 2016 -0400

    btrfs: add btrfs_trans_handle->fs_info pointer
    
    btrfs_trans_handle->root is documented as for use for confirming
    that the root passed in to start the transaction is the same as the
    one ending it.  It's used in several places when an fs_info pointer
    is needed, so let's just add an fs_info pointer directly.  Eventually,
    the root pointer can be removed.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index c5abee4f01ad..efb122643380 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -128,6 +128,7 @@ struct btrfs_trans_handle {
 	 * Subvolume quota depends on this
 	 */
 	struct btrfs_root *root;
+	struct btrfs_fs_info *fs_info;
 	struct seq_list delayed_ref_elem;
 	struct list_head qgroup_ref_list;
 	struct list_head new_bgs;

commit 64c12921e11b3a0c10d088606e328c58e29274d8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Jun 8 00:36:38 2016 -0400

    btrfs: account for non-CoW'd blocks in btrfs_abort_transaction
    
    The test for !trans->blocks_used in btrfs_abort_transaction is
    insufficient to determine whether it's safe to drop the transaction
    handle on the floor.  btrfs_cow_block, informed by should_cow_block,
    can return blocks that have already been CoW'd in the current
    transaction.  trans->blocks_used is only incremented for new block
    allocations. If an operation overlaps the blocks in the current
    transaction entirely and must abort the transaction, we'll happily
    let it clean up the trans handle even though it may have modified
    the blocks and will commit an incomplete operation.
    
    In the long-term, I'd like to do closer tracking of when the fs
    is actually modified so we can still recover as gracefully as possible,
    but that approach will need some discussion.  In the short term,
    since this is the only code using trans->blocks_used, let's just
    switch it to a bool indicating whether any blocks were used and set
    it when should_cow_block returns false.
    
    Cc: stable@vger.kernel.org # 3.4+
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 9fe0ec2bf0fe..c5abee4f01ad 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -110,7 +110,6 @@ struct btrfs_trans_handle {
 	u64 chunk_bytes_reserved;
 	unsigned long use_count;
 	unsigned long blocks_reserved;
-	unsigned long blocks_used;
 	unsigned long delayed_ref_updates;
 	struct btrfs_transaction *transaction;
 	struct btrfs_block_rsv *block_rsv;
@@ -121,6 +120,7 @@ struct btrfs_trans_handle {
 	bool can_flush_pending_bgs;
 	bool reloc_reserved;
 	bool sync;
+	bool dirty;
 	unsigned int type;
 	/*
 	 * this root is only needed to validate that the root passed to

commit 0132761017e012ab4dc8584d679503f2ba26ca86
Author: Nicholas D Steeves <nsteeves@gmail.com>
Date:   Thu May 19 21:18:45 2016 -0400

    btrfs: fix string and comment grammatical issues and typos
    
    Signed-off-by: Nicholas D Steeves <nsteeves@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 72be51f7ca2f..9fe0ec2bf0fe 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -144,7 +144,7 @@ struct btrfs_pending_snapshot {
 	/* block reservation for the operation */
 	struct btrfs_block_rsv block_rsv;
 	u64 qgroup_reserved;
-	/* extra metadata reseration for relocation */
+	/* extra metadata reservation for relocation */
 	int error;
 	bool readonly;
 	struct list_head list;

commit 8546b570511f428838129c00e701eda481cd7c13
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 10 18:54:03 2015 +0100

    btrfs: preallocate path for snapshot creation at ioctl time
    
    We can also preallocate btrfs_path that's used during pending snapshot
    creation and avoid another late ENOMEM failure.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index b6f9a3c94468..72be51f7ca2f 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -140,6 +140,7 @@ struct btrfs_pending_snapshot {
 	struct btrfs_root_item *root_item;
 	struct btrfs_root *snap;
 	struct btrfs_qgroup_inherit *inherit;
+	struct btrfs_path *path;
 	/* block reservation for the operation */
 	struct btrfs_block_rsv block_rsv;
 	u64 qgroup_reserved;

commit b0c0ea6338d5018e02d27c5315084fb1a5d099f6
Author: David Sterba <dsterba@suse.com>
Date:   Tue Nov 10 18:54:00 2015 +0100

    btrfs: allocate root item at snapshot ioctl time
    
    The actual snapshot creation is delayed until transaction commit. If we
    cannot get enough memory for the root item there, we have to fail the
    whole transaction commit which is bad. So we'll allocate the memory at
    the ioctl call and pass it along with the pending_snapshot struct. The
    potential ENOMEM will be returned to the caller of snapshot ioctl.
    
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 64c8221b6165..b6f9a3c94468 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -137,6 +137,7 @@ struct btrfs_pending_snapshot {
 	struct dentry *dentry;
 	struct inode *dir;
 	struct btrfs_root *root;
+	struct btrfs_root_item *root_item;
 	struct btrfs_root *snap;
 	struct btrfs_qgroup_inherit *inherit;
 	/* block reservation for the operation */

commit 348a0013d54acec35c22958480af054b97b5e4fe
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Nov 27 12:16:16 2015 +0000

    Btrfs: fix unprotected list move from unused_bgs to deleted_bgs list
    
    As of my previous change titled "Btrfs: fix scrub preventing unused block
    groups from being deleted", the following warning at
    extent-tree.c:btrfs_delete_unused_bgs() can be hit when we mount the a
    filesysten with "-o discard":
    
     10263  void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info)
     10264  {
     (...)
     10405                  if (trimming) {
     10406                          WARN_ON(!list_empty(&block_group->bg_list));
     10407                          spin_lock(&trans->transaction->deleted_bgs_lock);
     10408                          list_move(&block_group->bg_list,
     10409                                    &trans->transaction->deleted_bgs);
     10410                          spin_unlock(&trans->transaction->deleted_bgs_lock);
     10411                          btrfs_get_block_group(block_group);
     10412                  }
     (...)
    
    This happens because scrub can now add back the block group to the list of
    unused block groups (fs_info->unused_bgs). This is dangerous because we
    are moving the block group from the unused block groups list to the list
    of deleted block groups without holding the lock that protects the source
    list (fs_info->unused_bgs_lock).
    
    The following diagram illustrates how this happens:
    
                CPU 1                                     CPU 2
    
     cleaner_kthread()
       btrfs_delete_unused_bgs()
    
         sees bg X in list
          fs_info->unused_bgs
    
         deletes bg X from list
          fs_info->unused_bgs
    
                                                scrub_enumerate_chunks()
    
                                                  searches device tree using
                                                  its commit root
    
                                                  finds device extent for
                                                  block group X
    
                                                  gets block group X from the tree
                                                  fs_info->block_group_cache_tree
                                                  (via btrfs_lookup_block_group())
    
                                                  sets bg X to RO (again)
    
                                                  scrub_chunk(bg X)
    
                                                  sets bg X back to RW mode
    
                                                  adds bg X to the list
                                                  fs_info->unused_bgs again,
                                                  since it's still unused and
                                                  currently not in that list
    
         sets bg X to RO mode
    
         btrfs_remove_chunk(bg X)
    
         --> discard is enabled and bg X
             is in the fs_info->unused_bgs
             list again so the warning is
             triggered
         --> we move it from that list into
             the transaction's delete_bgs
             list, but we can have another
             task currently manipulating
             the first list (fs_info->unused_bgs)
    
    Fix this by using the same lock (fs_info->unused_bgs_lock) to protect both
    the list of unused block groups and the list of deleted block groups. This
    makes it safe and there's not much worry for more lock contention, as this
    lock is seldom used and only the cleaner kthread adds elements to the list
    of deleted block groups. The warning goes away too, as this was previously
    an impossible case (and would have been better a BUG_ON/ASSERT) but it's
    not impossible anymore.
    Reproduced with fstest btrfs/073 (using MOUNT_OPTIONS="-o discard").
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 0da21ca9b3fb..64c8221b6165 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -77,8 +77,8 @@ struct btrfs_transaction {
 	 */
 	struct mutex cache_write_mutex;
 	spinlock_t dirty_bgs_lock;
+	/* Protected by spin lock fs_info->unused_bgs_lock. */
 	struct list_head deleted_bgs;
-	spinlock_t deleted_bgs_lock;
 	spinlock_t dropped_roots_lock;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;

commit 8eab77ff167b62760d878f1d19312eb9f7d4c176
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Nov 13 23:57:16 2015 +0000

    Btrfs: use global reserve when deleting unused block group after ENOSPC
    
    It's possible to reach a state where the cleaner kthread isn't able to
    start a transaction to delete an unused block group due to lack of enough
    free metadata space and due to lack of unallocated device space to allocate
    a new metadata block group as well. If this happens try to use space from
    the global block group reserve just like we do for unlink operations, so
    that we don't reach a permanent state where starting a transaction for
    filesystem operations (file creation, renames, etc) keeps failing with
    -ENOSPC. Such an unfortunate state was observed on a machine where over
    a dozen unused data block groups existed and the cleaner kthread was
    failing to delete them due to ENOSPC error when attempting to start a
    transaction, and even running balance with a -dusage=0 filter failed with
    ENOSPC as well. Also unmounting and mounting again the filesystem didn't
    help. Allowing the cleaner kthread to use the global block reserve to
    delete the unused data block groups fixed the problem.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index b05b2f64d913..0da21ca9b3fb 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -185,6 +185,10 @@ int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   unsigned int num_items);
+struct btrfs_trans_handle *btrfs_start_transaction_fallback_global_rsv(
+					struct btrfs_root *root,
+					unsigned int num_items,
+					int min_factor);
 struct btrfs_trans_handle *btrfs_start_transaction_lflush(
 					struct btrfs_root *root,
 					unsigned int num_items);

commit a9e6d153563d2ed69c6cd7fb4fa5ce4ca7c712eb
Merge: 56fa9d0762ed 0584f718ed1f
Author: Chris Mason <clm@fb.com>
Date:   Wed Oct 21 19:00:38 2015 -0700

    Merge branch 'allocator-fixes' into for-linus-4.4
    
    Signed-off-by: Chris Mason <clm@fb.com>

commit 2968b1f48bd7366dd7310acde1ee6d1bf7791142
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Oct 1 12:55:18 2015 -0400

    Btrfs: don't continue setting up space cache when enospc
    
    If we hit ENOSPC when setting up a space cache don't bother setting up any of
    the other space cache's in this transaction, it'll just induce unnecessary
    latency.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 109b8b7fb48e..30ae75074ca4 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -34,6 +34,7 @@ enum btrfs_trans_state {
 
 #define BTRFS_TRANS_HAVE_FREE_BGS	0
 #define BTRFS_TRANS_DIRTY_BG_RUN	1
+#define BTRFS_TRANS_CACHE_ENOSPC	2
 
 struct btrfs_transaction {
 	u64 transid;

commit 3204d33cda40d9bc97f257c441225d3713916661
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Sep 24 10:46:10 2015 -0400

    Btrfs: add a flags field to btrfs_transaction
    
    I want to set some per transaction flags, so instead of adding yet another int
    lets just convert the current two int indicators to flags and add a flags field
    for future use.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index bf7b1ddf5993..109b8b7fb48e 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -32,6 +32,9 @@ enum btrfs_trans_state {
 	TRANS_STATE_MAX			= 6,
 };
 
+#define BTRFS_TRANS_HAVE_FREE_BGS	0
+#define BTRFS_TRANS_DIRTY_BG_RUN	1
+
 struct btrfs_transaction {
 	u64 transid;
 	/*
@@ -48,10 +51,7 @@ struct btrfs_transaction {
 	atomic_t use_count;
 	atomic_t pending_ordered;
 
-	/*
-	 * true if there is free bgs operations in this transaction
-	 */
-	int have_free_bgs;
+	unsigned long flags;
 
 	/* Be protected by fs_info->trans_lock when we want to change it. */
 	enum btrfs_trans_state state;
@@ -81,7 +81,6 @@ struct btrfs_transaction {
 	spinlock_t dropped_roots_lock;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
-	int dirty_bg_run;
 };
 
 #define __TRANS_FREEZABLE	(1U << 0)

commit 161c3549b45aeef05451b6822d8aaaf39c7bedce
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Sep 24 16:17:39 2015 -0400

    Btrfs: change how we wait for pending ordered extents
    
    We have a mechanism to make sure we don't lose updates for ordered extents that
    were logged in the transaction that is currently running.  We add the ordered
    extent to a transaction list and then the transaction waits on all the ordered
    extents in that list.  However are substantially large file systems this list
    can be extremely large, and can give us soft lockups, since the ordered extents
    don't remove themselves from the list when they do complete.
    
    To fix this we simply add a counter to the transaction that is incremented any
    time we have a logged extent that needs to be completed in the current
    transaction.  Then when the ordered extent finally completes it decrements the
    per transaction counter and wakes up the transaction if we are the last ones.
    This will eliminate the softlockup.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index db6bfd92f0ea..bf7b1ddf5993 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -46,6 +46,7 @@ struct btrfs_transaction {
 	 */
 	atomic_t num_writers;
 	atomic_t use_count;
+	atomic_t pending_ordered;
 
 	/*
 	 * true if there is free bgs operations in this transaction
@@ -59,9 +60,9 @@ struct btrfs_transaction {
 	unsigned long start_time;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
+	wait_queue_head_t pending_wait;
 	struct list_head pending_snapshots;
 	struct list_head pending_chunks;
-	struct list_head pending_ordered;
 	struct list_head switch_commits;
 	struct list_head dirty_bgs;
 	struct list_head io_bgs;
@@ -129,7 +130,6 @@ struct btrfs_trans_handle {
 	 */
 	struct btrfs_root *root;
 	struct seq_list delayed_ref_elem;
-	struct list_head ordered;
 	struct list_head qgroup_ref_list;
 	struct list_head new_bgs;
 };

commit 7174109c6548c4db85a383b8ae9d01469cddd110
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Tue Sep 8 17:22:41 2015 +0800

    btrfs: qgroup: Use new metadata reservation.
    
    As we have the new metadata reservation functions, use them to replace
    the old btrfs_qgroup_reserve() call for metadata.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index db6bfd92f0ea..54b7dea74967 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -107,7 +107,6 @@ struct btrfs_trans_handle {
 	u64 transid;
 	u64 bytes_reserved;
 	u64 chunk_bytes_reserved;
-	u64 qgroup_reserved;
 	unsigned long use_count;
 	unsigned long blocks_reserved;
 	unsigned long blocks_used;

commit 5aed1dd8b458aa63aa9b7c1c5dd78f54de143c6f
Author: Alexandru Moise <00moses.alexander00@gmail.com>
Date:   Tue Sep 22 20:59:15 2015 +0000

    btrfs: change num_items type from u64 to unsigned int
    
    The value of num_items that start_transaction() ultimately
    always takes is a small one, so a 64 bit integer is overkill.
    
    Also change num_items for btrfs_start_transaction() and
    btrfs_start_transaction_lflush() as well.
    
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Alexandru Moise <00moses.alexander00@gmail.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index a994bb097ee5..db6bfd92f0ea 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -185,9 +185,10 @@ static inline void btrfs_clear_skip_qgroup(struct btrfs_trans_handle *trans)
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
-						   int num_items);
+						   unsigned int num_items);
 struct btrfs_trans_handle *btrfs_start_transaction_lflush(
-					struct btrfs_root *root, int num_items);
+					struct btrfs_root *root,
+					unsigned int num_items);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_attach_transaction(struct btrfs_root *root);

commit d9a0540a79f87456907f2ce031f058cf745c5bff
Author: Filipe Manana <fdmanana@suse.com>
Date:   Sat Oct 3 13:13:13 2015 +0100

    Btrfs: fix deadlock when finalizing block group creation
    
    Josef ran into a deadlock while a transaction handle was finalizing the
    creation of its block groups, which produced the following trace:
    
      [260445.593112] fio             D ffff88022a9df468     0  8924   4518 0x00000084
      [260445.593119]  ffff88022a9df468 ffffffff81c134c0 ffff880429693c00 ffff88022a9df488
      [260445.593126]  ffff88022a9e0000 ffff8803490d7b00 ffff8803490d7b18 ffff88022a9df4b0
      [260445.593132]  ffff8803490d7af8 ffff88022a9df488 ffffffff8175a437 ffff8803490d7b00
      [260445.593137] Call Trace:
      [260445.593145]  [<ffffffff8175a437>] schedule+0x37/0x80
      [260445.593189]  [<ffffffffa0850f37>] btrfs_tree_lock+0xa7/0x1f0 [btrfs]
      [260445.593197]  [<ffffffff810db7c0>] ? prepare_to_wait_event+0xf0/0xf0
      [260445.593225]  [<ffffffffa07eac44>] btrfs_lock_root_node+0x34/0x50 [btrfs]
      [260445.593253]  [<ffffffffa07eff6b>] btrfs_search_slot+0x88b/0xa00 [btrfs]
      [260445.593295]  [<ffffffffa08389df>] ? free_extent_buffer+0x4f/0x90 [btrfs]
      [260445.593324]  [<ffffffffa07f1a06>] btrfs_insert_empty_items+0x66/0xc0 [btrfs]
      [260445.593351]  [<ffffffffa07ea94a>] ? btrfs_alloc_path+0x1a/0x20 [btrfs]
      [260445.593394]  [<ffffffffa08403b9>] btrfs_finish_chunk_alloc+0x1c9/0x570 [btrfs]
      [260445.593427]  [<ffffffffa08002ab>] btrfs_create_pending_block_groups+0x11b/0x200 [btrfs]
      [260445.593459]  [<ffffffffa0800964>] do_chunk_alloc+0x2a4/0x2e0 [btrfs]
      [260445.593491]  [<ffffffffa0803815>] find_free_extent+0xa55/0xd90 [btrfs]
      [260445.593524]  [<ffffffffa0803c22>] btrfs_reserve_extent+0xd2/0x220 [btrfs]
      [260445.593532]  [<ffffffff8119fe5d>] ? account_page_dirtied+0xdd/0x170
      [260445.593564]  [<ffffffffa0803e78>] btrfs_alloc_tree_block+0x108/0x4a0 [btrfs]
      [260445.593597]  [<ffffffffa080c9de>] ? btree_set_page_dirty+0xe/0x10 [btrfs]
      [260445.593626]  [<ffffffffa07eb5cd>] __btrfs_cow_block+0x12d/0x5b0 [btrfs]
      [260445.593654]  [<ffffffffa07ebbff>] btrfs_cow_block+0x11f/0x1c0 [btrfs]
      [260445.593682]  [<ffffffffa07ef8c7>] btrfs_search_slot+0x1e7/0xa00 [btrfs]
      [260445.593724]  [<ffffffffa08389df>] ? free_extent_buffer+0x4f/0x90 [btrfs]
      [260445.593752]  [<ffffffffa07f1a06>] btrfs_insert_empty_items+0x66/0xc0 [btrfs]
      [260445.593830]  [<ffffffffa07ea94a>] ? btrfs_alloc_path+0x1a/0x20 [btrfs]
      [260445.593905]  [<ffffffffa08403b9>] btrfs_finish_chunk_alloc+0x1c9/0x570 [btrfs]
      [260445.593946]  [<ffffffffa08002ab>] btrfs_create_pending_block_groups+0x11b/0x200 [btrfs]
      [260445.593990]  [<ffffffffa0815798>] btrfs_commit_transaction+0xa8/0xb40 [btrfs]
      [260445.594042]  [<ffffffffa085abcd>] ? btrfs_log_dentry_safe+0x6d/0x80 [btrfs]
      [260445.594089]  [<ffffffffa082bc84>] btrfs_sync_file+0x294/0x350 [btrfs]
      [260445.594115]  [<ffffffff8123e29b>] vfs_fsync_range+0x3b/0xa0
      [260445.594133]  [<ffffffff81023891>] ? syscall_trace_enter_phase1+0x131/0x180
      [260445.594149]  [<ffffffff8123e35d>] do_fsync+0x3d/0x70
      [260445.594169]  [<ffffffff81023bb8>] ? syscall_trace_leave+0xb8/0x110
      [260445.594187]  [<ffffffff8123e600>] SyS_fsync+0x10/0x20
      [260445.594204]  [<ffffffff8175de6e>] entry_SYSCALL_64_fastpath+0x12/0x71
    
    This happened because the same transaction handle created a large number
    of block groups and while finalizing their creation (inserting new items
    and updating existing items in the chunk and device trees) a new metadata
    extent had to be allocated and no free space was found in the current
    metadata block groups, which made find_free_extent() attempt to allocate
    a new block group via do_chunk_alloc(). However at do_chunk_alloc() we
    ended up allocating a new system chunk too and exceeded the threshold
    of 2Mb of reserved chunk bytes, which makes do_chunk_alloc() enter the
    final part of block group creation again (at
    btrfs_create_pending_block_groups()) and attempt to lock again the root
    of the chunk tree when it's already write locked by the same task.
    
    Similarly we can deadlock on extent tree nodes/leafs if while we are
    running delayed references we end up creating a new metadata block group
    in order to allocate a new node/leaf for the extent tree (as part of
    a CoW operation or growing the tree), as btrfs_create_pending_block_groups
    inserts items into the extent tree as well. In this case we get the
    following trace:
    
      [14242.773581] fio             D ffff880428ca3418     0  3615   3100 0x00000084
      [14242.773588]  ffff880428ca3418 ffff88042d66b000 ffff88042a03c800 ffff880428ca3438
      [14242.773594]  ffff880428ca4000 ffff8803e4b20190 ffff8803e4b201a8 ffff880428ca3460
      [14242.773600]  ffff8803e4b20188 ffff880428ca3438 ffffffff8175a437 ffff8803e4b20190
      [14242.773606] Call Trace:
      [14242.773613]  [<ffffffff8175a437>] schedule+0x37/0x80
      [14242.773656]  [<ffffffffa057ff07>] btrfs_tree_lock+0xa7/0x1f0 [btrfs]
      [14242.773664]  [<ffffffff810db7c0>] ? prepare_to_wait_event+0xf0/0xf0
      [14242.773692]  [<ffffffffa0519c44>] btrfs_lock_root_node+0x34/0x50 [btrfs]
      [14242.773720]  [<ffffffffa051ef6b>] btrfs_search_slot+0x88b/0xa00 [btrfs]
      [14242.773750]  [<ffffffffa0520a06>] btrfs_insert_empty_items+0x66/0xc0 [btrfs]
      [14242.773758]  [<ffffffff811ef4a2>] ? kmem_cache_alloc+0x1d2/0x200
      [14242.773786]  [<ffffffffa0520ad1>] btrfs_insert_item+0x71/0xf0 [btrfs]
      [14242.773818]  [<ffffffffa052f292>] btrfs_create_pending_block_groups+0x102/0x200 [btrfs]
      [14242.773850]  [<ffffffffa052f96e>] do_chunk_alloc+0x2ae/0x2f0 [btrfs]
      [14242.773934]  [<ffffffffa0532825>] find_free_extent+0xa55/0xd90 [btrfs]
      [14242.773998]  [<ffffffffa0532c22>] btrfs_reserve_extent+0xc2/0x1d0 [btrfs]
      [14242.774041]  [<ffffffffa0532e38>] btrfs_alloc_tree_block+0x108/0x4a0 [btrfs]
      [14242.774078]  [<ffffffffa051a5cd>] __btrfs_cow_block+0x12d/0x5b0 [btrfs]
      [14242.774118]  [<ffffffffa051abff>] btrfs_cow_block+0x11f/0x1c0 [btrfs]
      [14242.774155]  [<ffffffffa051e8c7>] btrfs_search_slot+0x1e7/0xa00 [btrfs]
      [14242.774194]  [<ffffffffa0528021>] ? __btrfs_free_extent.isra.70+0x2e1/0xcb0 [btrfs]
      [14242.774235]  [<ffffffffa0520a06>] btrfs_insert_empty_items+0x66/0xc0 [btrfs]
      [14242.774274]  [<ffffffffa051994a>] ? btrfs_alloc_path+0x1a/0x20 [btrfs]
      [14242.774318]  [<ffffffffa052c433>] __btrfs_run_delayed_refs+0xbb3/0x1020 [btrfs]
      [14242.774358]  [<ffffffffa052f404>] btrfs_run_delayed_refs.part.78+0x74/0x280 [btrfs]
      [14242.774391]  [<ffffffffa052f627>] btrfs_run_delayed_refs+0x17/0x20 [btrfs]
      [14242.774432]  [<ffffffffa05be236>] commit_cowonly_roots+0x8d/0x2bd [btrfs]
      [14242.774474]  [<ffffffffa059d07f>] ? __btrfs_run_delayed_items+0x1cf/0x210 [btrfs]
      [14242.774516]  [<ffffffffa05adac3>] ? btrfs_qgroup_account_extents+0x83/0x130 [btrfs]
      [14242.774558]  [<ffffffffa0544c40>] btrfs_commit_transaction+0x590/0xb40 [btrfs]
      [14242.774599]  [<ffffffffa0589b9d>] ? btrfs_log_dentry_safe+0x6d/0x80 [btrfs]
      [14242.774642]  [<ffffffffa055ac54>] btrfs_sync_file+0x294/0x350 [btrfs]
      [14242.774650]  [<ffffffff8123e29b>] vfs_fsync_range+0x3b/0xa0
      [14242.774657]  [<ffffffff81023891>] ? syscall_trace_enter_phase1+0x131/0x180
      [14242.774663]  [<ffffffff8123e35d>] do_fsync+0x3d/0x70
      [14242.774669]  [<ffffffff81023bb8>] ? syscall_trace_leave+0xb8/0x110
      [14242.774675]  [<ffffffff8123e600>] SyS_fsync+0x10/0x20
      [14242.774681]  [<ffffffff8175de6e>] entry_SYSCALL_64_fastpath+0x12/0x71
    
    Fix this by never recursing into the finalization phase of block group
    creation and making sure we never trigger the finalization of block group
    creation while running delayed references.
    
    Reported-by: Josef Bacik <jbacik@fb.com>
    Fixes: 00d80e342c0f ("Btrfs: fix quick exhaustion of the system array in the superblock")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 87964bf8892d..a994bb097ee5 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -118,6 +118,7 @@ struct btrfs_trans_handle {
 	short aborted;
 	short adding_csums;
 	bool allocating_chunk;
+	bool can_flush_pending_bgs;
 	bool reloc_reserved;
 	bool sync;
 	unsigned int type;

commit 2b9dbef272b63c561aab0a5be34fd428f7b710f5
Author: Josef Bacik <jbacik@fb.com>
Date:   Tue Sep 15 10:07:04 2015 -0400

    Btrfs: keep dropped roots in cache until transaction commit
    
    When dropping a snapshot we need to account for the qgroup changes.  If we drop
    the snapshot in all one go then the backref code will fail to find blocks from
    the snapshot we dropped since it won't be able to find the root in the fs root
    cache.  This can lead to us failing to find refs from other roots that pointed
    at blocks in the now deleted root.  To handle this we need to not remove the fs
    roots from the cache until after we process the qgroup operations.  Do this by
    adding dropped roots to a list on the transaction, and letting the transaction
    remove the roots at the same time it drops the commit roots.  This will keep all
    of the backref searching code in sync properly, and fixes a problem Mark was
    seeing with snapshot delete and qgroups.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Tested-by: Holger Hoffstätte <holger.hoffstaette@googlemail.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index edc2fbc262d7..87964bf8892d 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -65,6 +65,7 @@ struct btrfs_transaction {
 	struct list_head switch_commits;
 	struct list_head dirty_bgs;
 	struct list_head io_bgs;
+	struct list_head dropped_roots;
 	u64 num_dirty_bgs;
 
 	/*
@@ -76,6 +77,7 @@ struct btrfs_transaction {
 	spinlock_t dirty_bgs_lock;
 	struct list_head deleted_bgs;
 	spinlock_t deleted_bgs_lock;
+	spinlock_t dropped_roots_lock;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
 	int dirty_bg_run;
@@ -216,5 +218,6 @@ int btrfs_transaction_blocked(struct btrfs_fs_info *info);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
 void btrfs_put_transaction(struct btrfs_transaction *transaction);
 void btrfs_apply_pending_changes(struct btrfs_fs_info *fs_info);
-
+void btrfs_add_dropped_root(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root);
 #endif

commit e33e17ee1098d8d751552ac11c111e1c1a3db014
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Jun 15 09:41:19 2015 -0400

    btrfs: add missing discards when unpinning extents with -o discard
    
    When we clear the dirty bits in btrfs_delete_unused_bgs for extents
    in the empty block group, it results in btrfs_finish_extent_commit being
    unable to discard the freed extents.
    
    The block group removal patch added an alternate path to forget extents
    other than btrfs_finish_extent_commit.  As a result, any extents that
    would be freed when the block group is removed aren't discarded.  In my
    test run, with a large copy of mixed sized files followed by removal, it
    left nearly 2/3 of extents undiscarded.
    
    To clean up the block groups, we add the removed block group onto a list
    that will be discarded after transaction commit.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Reviewed-by: Filipe Manana <fdmanana@suse.com>
    Tested-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index eb09c2067fa8..edc2fbc262d7 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -74,6 +74,8 @@ struct btrfs_transaction {
 	 */
 	struct mutex cache_write_mutex;
 	spinlock_t dirty_bgs_lock;
+	struct list_head deleted_bgs;
+	spinlock_t deleted_bgs_lock;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
 	int dirty_bg_run;

commit 9086db86e0b09c39abead4d747119695553e3978
Author: Qu Wenruo <quwenruo@cn.fujitsu.com>
Date:   Mon Apr 20 09:53:50 2015 +0800

    btrfs: qgroup: Add the ability to skip given qgroup for old/new_roots.
    
    This is used by later qgroup fix patches for snapshot.
    
    As current snapshot accounting is done by btrfs_qgroup_inherit(), but
    new extent oriented quota mechanism will account extent from
    btrfs_copy_root() and other snapshot things, causing wrong result.
    
    So add this ability to handle snapshot accounting.
    
    Signed-off-by: Qu Wenruo <quwenruo@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 036fa83d6ccb..eb09c2067fa8 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -154,6 +154,29 @@ static inline void btrfs_set_inode_last_trans(struct btrfs_trans_handle *trans,
 	spin_unlock(&BTRFS_I(inode)->lock);
 }
 
+/*
+ * Make qgroup codes to skip given qgroupid, means the old/new_roots for
+ * qgroup won't contain the qgroupid in it.
+ */
+static inline void btrfs_set_skip_qgroup(struct btrfs_trans_handle *trans,
+					 u64 qgroupid)
+{
+	struct btrfs_delayed_ref_root *delayed_refs;
+
+	delayed_refs = &trans->transaction->delayed_refs;
+	WARN_ON(delayed_refs->qgroup_to_skip);
+	delayed_refs->qgroup_to_skip = qgroupid;
+}
+
+static inline void btrfs_clear_skip_qgroup(struct btrfs_trans_handle *trans)
+{
+	struct btrfs_delayed_ref_root *delayed_refs;
+
+	delayed_refs = &trans->transaction->delayed_refs;
+	WARN_ON(!delayed_refs->qgroup_to_skip);
+	delayed_refs->qgroup_to_skip = 0;
+}
+
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,

commit 4fbcdf6694544fd9d2aedbc1e73e52b90a4fcc20
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed May 20 14:01:54 2015 +0100

    Btrfs: fix -ENOSPC when finishing block group creation
    
    While creating a block group, we often end up getting ENOSPC while updating
    the chunk tree, which leads to a transaction abortion that produces a trace
    like the following:
    
    [30670.116368] WARNING: CPU: 4 PID: 20735 at fs/btrfs/super.c:260 __btrfs_abort_transaction+0x52/0x106 [btrfs]()
    [30670.117777] BTRFS: Transaction aborted (error -28)
    (...)
    [30670.163567] Call Trace:
    [30670.163906]  [<ffffffff8142fa46>] dump_stack+0x4f/0x7b
    [30670.164522]  [<ffffffff8108b6a2>] ? console_unlock+0x361/0x3ad
    [30670.165171]  [<ffffffff81045ea5>] warn_slowpath_common+0xa1/0xbb
    [30670.166323]  [<ffffffffa035daa7>] ? __btrfs_abort_transaction+0x52/0x106 [btrfs]
    [30670.167213]  [<ffffffff81045f05>] warn_slowpath_fmt+0x46/0x48
    [30670.167862]  [<ffffffffa035daa7>] __btrfs_abort_transaction+0x52/0x106 [btrfs]
    [30670.169116]  [<ffffffffa03743d7>] btrfs_create_pending_block_groups+0x101/0x130 [btrfs]
    [30670.170593]  [<ffffffffa038426a>] __btrfs_end_transaction+0x84/0x366 [btrfs]
    [30670.171960]  [<ffffffffa038455c>] btrfs_end_transaction+0x10/0x12 [btrfs]
    [30670.174649]  [<ffffffffa036eb6b>] btrfs_check_data_free_space+0x11f/0x27c [btrfs]
    [30670.176092]  [<ffffffffa039450d>] btrfs_fallocate+0x7c8/0xb96 [btrfs]
    [30670.177218]  [<ffffffff812459f2>] ? __this_cpu_preempt_check+0x13/0x15
    [30670.178622]  [<ffffffff81152447>] vfs_fallocate+0x14c/0x1de
    [30670.179642]  [<ffffffff8116b915>] ? __fget_light+0x2d/0x4f
    [30670.180692]  [<ffffffff81152863>] SyS_fallocate+0x47/0x62
    [30670.186737]  [<ffffffff81435b32>] system_call_fastpath+0x12/0x17
    [30670.187792] ---[ end trace 0373e6b491c4a8cc ]---
    
    This is because we don't do proper space reservation for the chunk block
    reserve when we have multiple tasks allocating chunks in parallel.
    
    So block group creation has 2 phases, and the first phase essentially
    checks if there is enough space in the system space_info, allocating a
    new system chunk if there isn't, while the second phase updates the
    device, extent and chunk trees. However, because the updates to the
    chunk tree happen in the second phase, if we have N tasks, each with
    its own transaction handle, allocating new chunks in parallel and if
    there is only enough space in the system space_info to allocate M chunks,
    where M < N, none of the tasks ends up allocating a new system chunk in
    the first phase and N - M tasks will get -ENOSPC when attempting to
    update the chunk tree in phase 2 if they need to COW any nodes/leafs
    from the chunk tree.
    
    Fix this by doing proper reservation in the chunk block reserve.
    
    The issue could be reproduced by running fstests generic/038 in a loop,
    which eventually triggered the problem.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 0b24755596ba..036fa83d6ccb 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -102,6 +102,7 @@ struct btrfs_transaction {
 struct btrfs_trans_handle {
 	u64 transid;
 	u64 bytes_reserved;
+	u64 chunk_bytes_reserved;
 	u64 qgroup_reserved;
 	unsigned long use_count;
 	unsigned long blocks_reserved;

commit 1bbc621ef28462456131c035eaeb5567a1a2a2fe
Author: Chris Mason <clm@fb.com>
Date:   Mon Apr 6 12:46:08 2015 -0700

    Btrfs: allow block group cache writeout outside critical section in commit
    
    We loop through all of the dirty block groups during commit and write
    the free space cache.  In order to make sure the cache is currect, we do
    this while no other writers are allowed in the commit.
    
    If a large number of block groups are dirty, this can introduce long
    stalls during the final stages of the commit, which can block new procs
    trying to change the filesystem.
    
    This commit changes the block group cache writeout to take appropriate
    locks and allow it to run earlier in the commit.  We'll still have to
    redo some of the block groups, but it means we can get most of the work
    out of the way without blocking the entire FS.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 4cb0ae264534..0b24755596ba 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -64,10 +64,19 @@ struct btrfs_transaction {
 	struct list_head pending_ordered;
 	struct list_head switch_commits;
 	struct list_head dirty_bgs;
+	struct list_head io_bgs;
 	u64 num_dirty_bgs;
+
+	/*
+	 * we need to make sure block group deletion doesn't race with
+	 * free space cache writeout.  This mutex keeps them from stomping
+	 * on each other
+	 */
+	struct mutex cache_write_mutex;
 	spinlock_t dirty_bgs_lock;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
+	int dirty_bg_run;
 };
 
 #define __TRANS_FREEZABLE	(1U << 0)

commit cb723e491955ac11a1591ae25cada7c3b1470609
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed Feb 18 08:06:57 2015 -0800

    Btrfs: reserve space for block groups
    
    This changes our delayed refs calculations to include the space needed
    to write back dirty block groups.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 96b189b8898a..4cb0ae264534 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -64,6 +64,7 @@ struct btrfs_transaction {
 	struct list_head pending_ordered;
 	struct list_head switch_commits;
 	struct list_head dirty_bgs;
+	u64 num_dirty_bgs;
 	spinlock_t dirty_bgs_lock;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;

commit 2f2ff0ee5e4303e727cfd7abd4133d1a8ee68394
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Mar 20 17:19:46 2015 +0000

    Btrfs: fix metadata inconsistencies after directory fsync
    
    We can get into inconsistency between inodes and directory entries
    after fsyncing a directory. The issue is that while a directory gets
    the new dentries persisted in the fsync log and replayed at mount time,
    the link count of the inode that directory entries point to doesn't
    get updated, staying with an incorrect link count (smaller then the
    correct value). This later leads to stale file handle errors when
    accessing (including attempt to delete) some of the links if all the
    other ones are removed, which also implies impossibility to delete the
    parent directories, since the dentries can not be removed.
    
    Another issue is that (unlike ext3/4, xfs, f2fs, reiserfs, nilfs2),
    when fsyncing a directory, new files aren't logged (their metadata and
    dentries) nor any child directories. So this patch fixes this issue too,
    since it has the same resolution as the incorrect inode link count issue
    mentioned before.
    
    This is very easy to reproduce, and the following excerpt from my test
    case for xfstests shows how:
    
      _scratch_mkfs >> $seqres.full 2>&1
      _init_flakey
      _mount_flakey
    
      # Create our main test file and directory.
      $XFS_IO_PROG -f -c "pwrite -S 0xaa 0 8K" $SCRATCH_MNT/foo | _filter_xfs_io
      mkdir $SCRATCH_MNT/mydir
    
      # Make sure all metadata and data are durably persisted.
      sync
    
      # Add a hard link to 'foo' inside our test directory and fsync only the
      # directory. The btrfs fsync implementation had a bug that caused the new
      # directory entry to be visible after the fsync log replay but, the inode
      # of our file remained with a link count of 1.
      ln $SCRATCH_MNT/foo $SCRATCH_MNT/mydir/foo_2
    
      # Add a few more links and new files.
      # This is just to verify nothing breaks or gives incorrect results after the
      # fsync log is replayed.
      ln $SCRATCH_MNT/foo $SCRATCH_MNT/mydir/foo_3
      $XFS_IO_PROG -f -c "pwrite -S 0xff 0 64K" $SCRATCH_MNT/hello | _filter_xfs_io
      ln $SCRATCH_MNT/hello $SCRATCH_MNT/mydir/hello_2
    
      # Add some subdirectories and new files and links to them. This is to verify
      # that after fsyncing our top level directory 'mydir', all the subdirectories
      # and their files/links are registered in the fsync log and exist after the
      # fsync log is replayed.
      mkdir -p $SCRATCH_MNT/mydir/x/y/z
      ln $SCRATCH_MNT/foo $SCRATCH_MNT/mydir/x/y/foo_y_link
      ln $SCRATCH_MNT/foo $SCRATCH_MNT/mydir/x/y/z/foo_z_link
      touch $SCRATCH_MNT/mydir/x/y/z/qwerty
    
      # Now fsync only our top directory.
      $XFS_IO_PROG -c "fsync" $SCRATCH_MNT/mydir
    
      # And fsync now our new file named 'hello', just to verify later that it has
      # the expected content and that the previous fsync on the directory 'mydir' had
      # no bad influence on this fsync.
      $XFS_IO_PROG -c "fsync" $SCRATCH_MNT/hello
    
      # Simulate a crash/power loss.
      _load_flakey_table $FLAKEY_DROP_WRITES
      _unmount_flakey
    
      _load_flakey_table $FLAKEY_ALLOW_WRITES
      _mount_flakey
    
      # Verify the content of our file 'foo' remains the same as before, 8192 bytes,
      # all with the value 0xaa.
      echo "File 'foo' content after log replay:"
      od -t x1 $SCRATCH_MNT/foo
    
      # Remove the first name of our inode. Because of the directory fsync bug, the
      # inode's link count was 1 instead of 5, so removing the 'foo' name ended up
      # deleting the inode and the other names became stale directory entries (still
      # visible to applications). Attempting to remove or access the remaining
      # dentries pointing to that inode resulted in stale file handle errors and
      # made it impossible to remove the parent directories since it was impossible
      # for them to become empty.
      echo "file 'foo' link count after log replay: $(stat -c %h $SCRATCH_MNT/foo)"
      rm -f $SCRATCH_MNT/foo
    
      # Now verify that all files, links and directories created before fsyncing our
      # directory exist after the fsync log was replayed.
      [ -f $SCRATCH_MNT/mydir/foo_2 ] || echo "Link mydir/foo_2 is missing"
      [ -f $SCRATCH_MNT/mydir/foo_3 ] || echo "Link mydir/foo_3 is missing"
      [ -f $SCRATCH_MNT/hello ] || echo "File hello is missing"
      [ -f $SCRATCH_MNT/mydir/hello_2 ] || echo "Link mydir/hello_2 is missing"
      [ -f $SCRATCH_MNT/mydir/x/y/foo_y_link ] || \
          echo "Link mydir/x/y/foo_y_link is missing"
      [ -f $SCRATCH_MNT/mydir/x/y/z/foo_z_link ] || \
          echo "Link mydir/x/y/z/foo_z_link is missing"
      [ -f $SCRATCH_MNT/mydir/x/y/z/qwerty ] || \
          echo "File mydir/x/y/z/qwerty is missing"
    
      # We expect our file here to have a size of 64Kb and all the bytes having the
      # value 0xff.
      echo "file 'hello' content after log replay:"
      od -t x1 $SCRATCH_MNT/hello
    
      # Now remove all files/links, under our test directory 'mydir', and verify we
      # can remove all the directories.
      rm -f $SCRATCH_MNT/mydir/x/y/z/*
      rmdir $SCRATCH_MNT/mydir/x/y/z
      rm -f $SCRATCH_MNT/mydir/x/y/*
      rmdir $SCRATCH_MNT/mydir/x/y
      rmdir $SCRATCH_MNT/mydir/x
      rm -f $SCRATCH_MNT/mydir/*
      rmdir $SCRATCH_MNT/mydir
    
      # An fsck, run by the fstests framework everytime a test finishes, also detected
      # the inconsistency and printed the following error message:
      #
      # root 5 inode 257 errors 2001, no inode item, link count wrong
      #    unresolved ref dir 258 index 2 namelen 5 name foo_2 filetype 1 errors 4, no inode ref
      #    unresolved ref dir 258 index 3 namelen 5 name foo_3 filetype 1 errors 4, no inode ref
    
      status=0
      exit
    
    The expected golden output for the test is:
    
      wrote 8192/8192 bytes at offset 0
      XXX Bytes, X ops; XX:XX:XX.X (XXX YYY/sec and XXX ops/sec)
      wrote 65536/65536 bytes at offset 0
      XXX Bytes, X ops; XX:XX:XX.X (XXX YYY/sec and XXX ops/sec)
      File 'foo' content after log replay:
      0000000 aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa
      *
      0020000
      file 'foo' link count after log replay: 5
      file 'hello' content after log replay:
      0000000 ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
      *
      0200000
    
    Which is the output after this patch and when running the test against
    ext3/4, xfs, f2fs, reiserfs or nilfs2. Without this patch, the test's
    output is:
    
      wrote 8192/8192 bytes at offset 0
      XXX Bytes, X ops; XX:XX:XX.X (XXX YYY/sec and XXX ops/sec)
      wrote 65536/65536 bytes at offset 0
      XXX Bytes, X ops; XX:XX:XX.X (XXX YYY/sec and XXX ops/sec)
      File 'foo' content after log replay:
      0000000 aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa
      *
      0020000
      file 'foo' link count after log replay: 1
      Link mydir/foo_2 is missing
      Link mydir/foo_3 is missing
      Link mydir/x/y/foo_y_link is missing
      Link mydir/x/y/z/foo_z_link is missing
      File mydir/x/y/z/qwerty is missing
      file 'hello' content after log replay:
      0000000 ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
      *
      0200000
      rmdir: failed to remove '/home/fdmanana/btrfs-tests/scratch_1/mydir/x/y/z': No such file or directory
      rmdir: failed to remove '/home/fdmanana/btrfs-tests/scratch_1/mydir/x/y': No such file or directory
      rmdir: failed to remove '/home/fdmanana/btrfs-tests/scratch_1/mydir/x': No such file or directory
      rm: cannot remove '/home/fdmanana/btrfs-tests/scratch_1/mydir/foo_2': Stale file handle
      rm: cannot remove '/home/fdmanana/btrfs-tests/scratch_1/mydir/foo_3': Stale file handle
      rmdir: failed to remove '/home/fdmanana/btrfs-tests/scratch_1/mydir': Directory not empty
    
    Fsck, without this fix, also complains about the wrong link count:
    
      root 5 inode 257 errors 2001, no inode item, link count wrong
          unresolved ref dir 258 index 2 namelen 5 name foo_2 filetype 1 errors 4, no inode ref
          unresolved ref dir 258 index 3 namelen 5 name foo_3 filetype 1 errors 4, no inode ref
    
    So fix this by logging the inodes that the dentries point to when
    fsyncing a directory.
    
    A test case for xfstests follows.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 937050a2b68e..96b189b8898a 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -136,9 +136,11 @@ struct btrfs_pending_snapshot {
 static inline void btrfs_set_inode_last_trans(struct btrfs_trans_handle *trans,
 					      struct inode *inode)
 {
+	spin_lock(&BTRFS_I(inode)->lock);
 	BTRFS_I(inode)->last_trans = trans->transaction->transid;
 	BTRFS_I(inode)->last_sub_trans = BTRFS_I(inode)->root->log_transid;
 	BTRFS_I(inode)->last_log_commit = BTRFS_I(inode)->root->last_log_commit;
+	spin_unlock(&BTRFS_I(inode)->lock);
 }
 
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,

commit 13212b54d18d5235fb97fbdcba8ae453fd2a3a51
Author: Zhao Lei <zhaolei@cn.fujitsu.com>
Date:   Thu Feb 12 14:18:17 2015 +0800

    btrfs: Fix out-of-space bug
    
    Btrfs will report NO_SPACE when we create and remove files for several times,
    and we can't write to filesystem until mount it again.
    
    Steps to reproduce:
     1: Create a single-dev btrfs fs with default option
     2: Write a file into it to take up most fs space
     3: Delete above file
     4: Wait about 100s to let chunk removed
     5: goto 2
    
    Script is like following:
     #!/bin/bash
    
     # Recommend 1.2G space, too large disk will make test slow
     DEV="/dev/sda16"
     MNT="/mnt/tmp"
    
     dev_size="$(lsblk -bn -o SIZE "$DEV")" || exit 2
     file_size_m=$((dev_size * 75 / 100 / 1024 / 1024))
    
     echo "Loop write ${file_size_m}M file on $((dev_size / 1024 / 1024))M dev"
    
     for ((i = 0; i < 10; i++)); do umount "$MNT" 2>/dev/null; done
     echo "mkfs $DEV"
     mkfs.btrfs -f "$DEV" >/dev/null || exit 2
     echo "mount $DEV $MNT"
     mount "$DEV" "$MNT" || exit 2
    
     for ((loop_i = 0; loop_i < 20; loop_i++)); do
         echo
         echo "loop $loop_i"
    
         echo "dd file..."
         cmd=(dd if=/dev/zero of="$MNT"/file0 bs=1M count="$file_size_m")
         "${cmd[@]}" 2>/dev/null || {
             # NO_SPACE error triggered
             echo "dd failed: ${cmd[*]}"
             exit 1
         }
    
         echo "rm file..."
         rm -f "$MNT"/file0 || exit 2
    
         for ((i = 0; i < 10; i++)); do
             df "$MNT" | tail -1
             sleep 10
         done
     done
    
    Reason:
     It is triggered by commit: 47ab2a6c689913db23ccae38349714edf8365e0a
     which is used to remove empty block groups automatically, but the
     reason is not in that patch. Code before works well because btrfs
     don't need to create and delete chunks so many times with high
     complexity.
     Above bug is caused by many reason, any of them can trigger it.
    
    Reason1:
     When we remove some continuous chunks but leave other chunks after,
     these disk space should be used by chunk-recreating, but in current
     code, only first create will successed.
     Fixed by Forrest Liu <forrestl@synology.com> in:
     Btrfs: fix find_free_dev_extent() malfunction in case device tree has hole
    
    Reason2:
     contains_pending_extent() return wrong value in calculation.
     Fixed by Forrest Liu <forrestl@synology.com> in:
     Btrfs: fix find_free_dev_extent() malfunction in case device tree has hole
    
    Reason3:
     btrfs_check_data_free_space() try to commit transaction and retry
     allocating chunk when the first allocating failed, but space_info->full
     is set in first allocating, and prevent second allocating in retry.
     Fixed in this patch by clear space_info->full in commit transaction.
    
     Tested for severial times by above script.
    
    Changelog v3->v4:
     use light weight int instead of atomic_t to record have_remove_bgs in
     transaction, suggested by:
     Josef Bacik <jbacik@fb.com>
    
    Changelog v2->v3:
     v2 fixed the bug by adding more commit-transaction, but we
     only need to reclaim space when we are really have no space for
     new chunk, noticed by:
     Filipe David Manana <fdmanana@gmail.com>
    
     Actually, our code already have this type of commit-and-retry,
     we only need to make it working with removed-bgs.
     v3 fixed the bug with above way.
    
    Changelog v1->v2:
     v1 will introduce a new bug when delete and create chunk in same disk
     space in same transaction, noticed by:
     Filipe David Manana <fdmanana@gmail.com>
     V2 fix this bug by commit transaction after remove block grops.
    
    Reported-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Suggested-by: Filipe David Manana <fdmanana@gmail.com>
    Suggested-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Zhao Lei <zhaolei@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 3305451451ca..937050a2b68e 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -47,6 +47,11 @@ struct btrfs_transaction {
 	atomic_t num_writers;
 	atomic_t use_count;
 
+	/*
+	 * true if there is free bgs operations in this transaction
+	 */
+	int have_free_bgs;
+
 	/* Be protected by fs_info->trans_lock when we want to change it. */
 	enum btrfs_trans_state state;
 	struct list_head list;

commit ce93ec548cfa02f9cd6b70d546d5f36f4d160f57
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Nov 17 15:45:48 2014 -0500

    Btrfs: track dirty block groups on their own list
    
    Currently any time we try to update the block groups on disk we will walk _all_
    block groups and check for the ->dirty flag to see if it is set.  This function
    can get called several times during a commit.  So if you have several terabytes
    of data you will be a very sad panda as we will loop through _all_ of the block
    groups several times, which makes the commit take a while which slows down the
    rest of the file system operations.
    
    This patch introduces a dirty list for the block groups that we get added to
    when we dirty the block group for the first time.  Then we simply update any
    block groups that have been dirtied since the last time we called
    btrfs_write_dirty_block_groups.  This allows us to clean up how we write the
    free space cache out so it is much cleaner.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 00ed29c4b3f9..3305451451ca 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -58,6 +58,8 @@ struct btrfs_transaction {
 	struct list_head pending_chunks;
 	struct list_head pending_ordered;
 	struct list_head switch_commits;
+	struct list_head dirty_bgs;
+	spinlock_t dirty_bgs_lock;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
 };

commit ad27c0dab76a7abc8809ec41ae59cf67de5ea906
Merge: b38ef71cb102 a6f69dc8018d
Author: Chris Mason <clm@fb.com>
Date:   Tue Nov 25 05:45:30 2014 -0800

    Merge branch 'dev/pending-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux into for-linus

commit 50d9aa99bd35c77200e0e3dd7a72274f8304701f
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Nov 21 14:52:38 2014 -0500

    Btrfs: make sure logged extents complete in the current transaction V3
    
    Liu Bo pointed out that my previous fix would lose the generation update in the
    scenario I described.  It is actually much worse than that, we could lose the
    entire extent if we lose power right after the transaction commits.  Consider
    the following
    
    write extent 0-4k
    log extent in log tree
    commit transaction
            < power fail happens here
    ordered extent completes
    
    We would lose the 0-4k extent because it hasn't updated the actual fs tree, and
    the transaction commit will reset the log so it isn't replayed.  If we lose
    power before the transaction commit we are save, otherwise we are not.
    
    Fix this by keeping track of all extents we logged in this transaction.  Then
    when we go to commit the transaction make sure we wait for all of those ordered
    extents to complete before proceeding.  This will make sure that if we lose
    power after the transaction commit we still have our data.  This also fixes the
    problem of the improperly updated extent generation.  Thanks,
    
    cc: stable@vger.kernel.org
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index b3f5b40aab22..fd400a3668a8 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -56,6 +56,7 @@ struct btrfs_transaction {
 	wait_queue_head_t commit_wait;
 	struct list_head pending_snapshots;
 	struct list_head pending_chunks;
+	struct list_head pending_ordered;
 	struct list_head switch_commits;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
@@ -105,6 +106,7 @@ struct btrfs_trans_handle {
 	 */
 	struct btrfs_root *root;
 	struct seq_list delayed_ref_elem;
+	struct list_head ordered;
 	struct list_head qgroup_ref_list;
 	struct list_head new_bgs;
 };

commit 663dfbb07774e0fe1049e8db3054a08500122f18
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Oct 13 12:28:37 2014 +0100

    Btrfs: deal with convert_extent_bit errors to avoid fs corruption
    
    When committing a transaction or a log, we look for btree extents that
    need to be durably persisted by searching for ranges in a io tree that
    have some bits set (EXTENT_DIRTY or EXTENT_NEW). We then attempt to clear
    those bits and set the EXTENT_NEED_WAIT bit, with calls to the function
    convert_extent_bit, and then start writeback for the extents.
    
    That function however can return an error (at the moment only -ENOMEM
    is possible, specially when it does GFP_ATOMIC allocation requests
    through alloc_extent_state_atomic) - that means the ranges didn't got
    the EXTENT_NEED_WAIT bit set (or at least not for the whole range),
    which in turn means a call to btrfs_wait_marked_extents() won't find
    those ranges for which we started writeback, causing a transaction
    commit or a log commit to persist a new superblock without waiting
    for the writeback of extents in that range to finish first.
    
    Therefore if a crash happens after persisting the new superblock and
    before writeback finishes, we have a superblock pointing to roots that
    weren't fully persisted or roots that point to nodes or leafs that weren't
    fully persisted, causing all sorts of unexpected/bad behaviour as we endup
    reading garbage from disk or the content of some node/leaf from a past
    generation that got cowed or deleted and is no longer valid (for this later
    case we end up getting error messages like "parent transid verify failed on
    X wanted Y found Z" when reading btree nodes/leafs from disk).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index d8f40e1a5d2d..b3f5b40aab22 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -145,8 +145,6 @@ struct btrfs_trans_handle *btrfs_attach_transaction_barrier(
 					struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *root);
 int btrfs_wait_for_commit(struct btrfs_root *root, u64 transid);
-int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
-				     struct btrfs_root *root);
 
 void btrfs_add_dead_root(struct btrfs_root *root);
 int btrfs_defrag_root(struct btrfs_root *root);

commit 572d9ab7845ea0e043ec34cd733a75228130ad03
Author: David Sterba <dsterba@suse.cz>
Date:   Wed Feb 5 15:26:17 2014 +0100

    btrfs: add support for processing pending changes
    
    There are some actions that modify global filesystem state but cannot be
    performed at the time of request, but later at the transaction commit
    time when the filesystem is in a known state.
    
    For example enabling new incompat features on-the-fly or issuing
    transaction commit from unsafe contexts (sysfs handlers).
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index d8f40e1a5d2d..75ebcfce9d57 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -170,4 +170,6 @@ int btrfs_wait_marked_extents(struct btrfs_root *root,
 int btrfs_transaction_blocked(struct btrfs_fs_info *info);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
 void btrfs_put_transaction(struct btrfs_transaction *transaction);
+void btrfs_apply_pending_changes(struct btrfs_fs_info *fs_info);
+
 #endif

commit 2755a0de64693501741fb3603cd8ca928b0b7e81
Author: David Sterba <dsterba@suse.cz>
Date:   Thu Jul 31 00:43:18 2014 +0200

    btrfs: hide typecast to definition of BTRFS_SEND_TRANS_STUB
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 579be51b27e5..d8f40e1a5d2d 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -79,7 +79,7 @@ struct btrfs_transaction {
 #define TRANS_EXTWRITERS	(__TRANS_USERSPACE | __TRANS_START |	\
 				 __TRANS_ATTACH)
 
-#define BTRFS_SEND_TRANS_STUB	1
+#define BTRFS_SEND_TRANS_STUB	((void *)1)
 
 struct btrfs_trans_handle {
 	u64 transid;

commit 8d875f95da43c6a8f18f77869f2ef26e9594fecc
Author: Chris Mason <clm@fb.com>
Date:   Tue Aug 12 10:47:42 2014 -0700

    btrfs: disable strict file flushes for renames and truncates
    
    Truncates and renames are often used to replace old versions of a file
    with new versions.  Applications often expect this to be an atomic
    replacement, even if they haven't done anything to make sure the new
    version is fully on disk.
    
    Btrfs has strict flushing in place to make sure that renaming over an
    old file with a new file will fully flush out the new file before
    allowing the transaction commit with the rename to complete.
    
    This ordering means the commit code needs to be able to lock file pages,
    and there are a few paths in the filesystem where we will try to end a
    transaction with the page lock held.  It's rare, but these things can
    deadlock.
    
    This patch removes the ordered flushes and switches to a best effort
    filemap_flush like ext4 uses. It's not perfect, but it should fix the
    deadlocks.
    
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 7dd558ed0716..579be51b27e5 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -55,7 +55,6 @@ struct btrfs_transaction {
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 	struct list_head pending_snapshots;
-	struct list_head ordered_operations;
 	struct list_head pending_chunks;
 	struct list_head switch_commits;
 	struct btrfs_delayed_ref_root delayed_refs;

commit faa2dbf004e89e8f7ccd28fbe6f07c308417b8ae
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed May 7 17:06:09 2014 -0400

    Btrfs: add sanity tests for new qgroup accounting code
    
    This exercises the various parts of the new qgroup accounting code.  We do some
    basic stuff and do some things with the shared refs to make sure all that code
    works.  I had to add a bunch of infrastructure because I needed to be able to
    insert items into a fake tree without having to do all the hard work myself,
    hopefully this will be usefull in the future.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index b57b924e8e03..7dd558ed0716 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -69,6 +69,7 @@ struct btrfs_transaction {
 #define __TRANS_ATTACH		(1U << 10)
 #define __TRANS_JOIN		(1U << 11)
 #define __TRANS_JOIN_NOLOCK	(1U << 12)
+#define __TRANS_DUMMY		(1U << 13)
 
 #define TRANS_USERSPACE		(__TRANS_USERSPACE | __TRANS_FREEZABLE)
 #define TRANS_START		(__TRANS_START | __TRANS_FREEZABLE)

commit 9e351cc862b098d8ec8f8022d110932490794925
Author: Josef Bacik <jbacik@fb.com>
Date:   Thu Mar 13 15:42:13 2014 -0400

    Btrfs: remove transaction from send
    
    Lets try this again.  We can deadlock the box if we send on a box and try to
    write onto the same fs with the app that is trying to listen to the send pipe.
    This is because the writer could get stuck waiting for a transaction commit
    which is being blocked by the send.  So fix this by making sure looking at the
    commit roots is always going to be consistent.  We do this by keeping track of
    which roots need to have their commit roots swapped during commit, and then
    taking the commit_root_sem and swapping them all at once.  Then make sure we
    take a read lock on the commit_root_sem in cases where we search the commit root
    to make sure we're always looking at a consistent view of the commit roots.
    Previously we had problems with this because we would swap a fs tree commit root
    and then swap the extent tree commit root independently which would cause the
    backref walking code to screw up sometimes.  With this patch we no longer
    deadlock and pass all the weird send/receive corner cases.  Thanks,
    
    Reportedy-by: Hugo Mills <hugo@carfax.org.uk>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 2bcba89d952e..b57b924e8e03 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -57,6 +57,7 @@ struct btrfs_transaction {
 	struct list_head pending_snapshots;
 	struct list_head ordered_operations;
 	struct list_head pending_chunks;
+	struct list_head switch_commits;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
 };

commit a26e8c9f75b0bfd8cccc9e8f110737b136eb5994
Author: Josef Bacik <jbacik@fb.com>
Date:   Fri Mar 28 17:07:27 2014 -0400

    Btrfs: don't clear uptodate if the eb is under IO
    
    So I have an awful exercise script that will run snapshot, balance and
    send/receive in parallel.  This sometimes would crash spectacularly and when it
    came back up the fs would be completely hosed.  Turns out this is because of a
    bad interaction of balance and send/receive.  Send will hold onto its entire
    path for the whole send, but its blocks could get relocated out from underneath
    it, and because it doesn't old tree locks theres nothing to keep this from
    happening.  So it will go to read in a slot with an old transid, and we could
    have re-allocated this block for something else and it could have a completely
    different transid.  But because we think it is invalid we clear uptodate and
    re-read in the block.  If we do this before we actually write out the new block
    we could write back stale data to the fs, and boom we're screwed.
    
    Now we definitely need to fix this disconnect between send and balance, but we
    really really need to not allow ourselves to accidently read in stale data over
    new data.  So make sure we check if the extent buffer is not under io before
    clearing uptodate, this will kick back EIO to the caller instead of reading in
    stale data and keep us from corrupting the fs.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 6ac037e9f9f0..2bcba89d952e 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -78,6 +78,8 @@ struct btrfs_transaction {
 #define TRANS_EXTWRITERS	(__TRANS_USERSPACE | __TRANS_START |	\
 				 __TRANS_ATTACH)
 
+#define BTRFS_SEND_TRANS_STUB	1
+
 struct btrfs_trans_handle {
 	u64 transid;
 	u64 bytes_reserved;

commit 5039eddc19aee8c894191c24f2dde4e645ca1bbb
Author: Josef Bacik <jbacik@fb.com>
Date:   Wed Jan 15 13:34:13 2014 -0500

    Btrfs: make fsync latency less sucky
    
    Looking into some performance related issues with large amounts of metadata
    revealed that we can have some pretty huge swings in fsync() performance.  If we
    have a lot of delayed refs backed up (as you will tend to do with lots of
    metadata) fsync() will wander off and try to run some of those delayed refs
    which can result in reading from disk and such.  Since the actual act of fsync()
    doesn't create any delayed refs there is no need to make it throttle on delayed
    ref stuff, that will be handled by other people.  With this patch we get much
    smoother fsync performance with large amounts of metadata.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index d05b6013fea8..6ac037e9f9f0 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -93,6 +93,7 @@ struct btrfs_trans_handle {
 	short adding_csums;
 	bool allocating_chunk;
 	bool reloc_reserved;
+	bool sync;
 	unsigned int type;
 	/*
 	 * this root is only needed to validate that the root passed to

commit a56dbd89400dd2cb9c91d734435dbfe059495da1
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Dec 26 13:07:04 2013 +0800

    Btrfs: remove btrfs_end_transaction_dmeta()
    
    Two reasons:
    - btrfs_end_transaction_dmeta() is the same as btrfs_end_transaction_throttle()
      so it is unnecessary.
    - All the delayed items should be dealt in the current transaction, so the
      workers should not commit the transaction, instead, deal with the delayed
      items as many as possible.
    
    So we can remove btrfs_end_transaction_dmeta()
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <clm@fb.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 7657d115067d..d05b6013fea8 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -154,8 +154,6 @@ int btrfs_commit_transaction_async(struct btrfs_trans_handle *trans,
 				   int wait_for_unblock);
 int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
-int btrfs_end_transaction_dmeta(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root);
 int btrfs_should_end_transaction(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root);
 void btrfs_throttle(struct btrfs_root *root);

commit 20dd2cbf01888a91fdd921403040a710b275a1ff
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Sep 25 21:47:45 2013 +0800

    Btrfs: fix BUG_ON() casued by the reserved space migration
    
    When we did space balance and snapshot creation at the same time, we might
    meet the following oops:
     kernel BUG at fs/btrfs/inode.c:3038!
     [SNIP]
     Call Trace:
     [<ffffffffa0411ec7>] btrfs_orphan_cleanup+0x293/0x407 [btrfs]
     [<ffffffffa042dc45>] btrfs_mksubvol.isra.28+0x259/0x373 [btrfs]
     [<ffffffffa042de85>] btrfs_ioctl_snap_create_transid+0x126/0x156 [btrfs]
     [<ffffffffa042dff1>] btrfs_ioctl_snap_create_v2+0xd0/0x121 [btrfs]
     [<ffffffffa0430b2c>] btrfs_ioctl+0x414/0x1854 [btrfs]
     [<ffffffff813b60b7>] ? __do_page_fault+0x305/0x379
     [<ffffffff811215a9>] vfs_ioctl+0x1d/0x39
     [<ffffffff81121d7c>] do_vfs_ioctl+0x32d/0x3e2
     [<ffffffff81057fe7>] ? finish_task_switch+0x80/0xb8
     [<ffffffff81121e88>] SyS_ioctl+0x57/0x83
     [<ffffffff813b39ff>] ? do_device_not_available+0x12/0x14
     [<ffffffff813b99c2>] system_call_fastpath+0x16/0x1b
     [SNIP]
     RIP  [<ffffffffa040da40>] btrfs_orphan_add+0xc3/0x126 [btrfs]
    
    The reason of the problem is that the relocation root creation stole
    the reserved space, which was reserved for orphan item deletion.
    
    There are several ways to fix this problem, one is to increasing
    the reserved space size of the space balace, and then we can use
    that space to create the relocation tree for each fs/file trees.
    But it is hard to calculate the suitable size because we doesn't
    know how many fs/file trees we need relocate.
    
    We fixed this problem by reserving the space for relocation root creation
    actively since the space it need is very small (one tree block, used for
    root node copy), then we use that reserved space to create the
    relocation tree. If we don't reserve space for relocation tree creation,
    we will use the reserved space of the balance.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 306f88ae1de3..7657d115067d 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -92,6 +92,7 @@ struct btrfs_trans_handle {
 	short aborted;
 	short adding_csums;
 	bool allocating_chunk;
+	bool reloc_reserved;
 	unsigned int type;
 	/*
 	 * this root is only needed to validate that the root passed to

commit 724e2315db3d59a8201d4a87c7c7a873e60e1ce0
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Sep 30 11:36:38 2013 -0400

    Btrfs: fix two use-after-free bugs with transaction cleanup
    
    I was noticing the slab redzone stuff going off every once and a while during
    transaction aborts.  This was caused by two things
    
    1) We would walk the pending snapshots and set their error to -ECANCELED.  We
    don't need to do this, the snapshot stuff waits for a transaction commit and if
    there is a problem we just free our pending snapshot object and exit.  Doing
    this was causing us to touch the pending snapshot object after the thing had
    already been freed.
    
    2) We were freeing the transaction manually with wanton disregard for it's
    use_count reference counter.  To fix this I cleaned up the transaction freeing
    loop to either wait for the transaction commit to finish if it was in the middle
    of that (since it will be cleaned and freed up there) or to do the cleanup
    oursevles.
    
    I also moved the global "kill all things dirty everywhere" stuff outside of the
    transaction cleanup loop since that only needs to be done once.  With this patch
    I'm no longer seeing slab corruption because of use after frees.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 5c2af8491621..306f88ae1de3 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -166,4 +166,5 @@ int btrfs_wait_marked_extents(struct btrfs_root *root,
 				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_transaction_blocked(struct btrfs_fs_info *info);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
+void btrfs_put_transaction(struct btrfs_transaction *transaction);
 #endif

commit 171170c1c5625cab9687ecf6714e09e0c8a6ed3c
Author: Sergei Trofimovich <slyfox@gentoo.org>
Date:   Wed Aug 14 23:27:46 2013 +0300

    btrfs: mark some local function as 'static'
    
    Cc: Josef Bacik <jbacik@fusionio.com>
    Cc: Chris Mason <chris.mason@fusionio.com>
    Signed-off-by: Sergei Trofimovich <slyfox@gentoo.org>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index defbc4269897..5c2af8491621 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -160,8 +160,6 @@ int btrfs_should_end_transaction(struct btrfs_trans_handle *trans,
 void btrfs_throttle(struct btrfs_root *root);
 int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
-int btrfs_write_and_wait_marked_extents(struct btrfs_root *root,
-				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_write_marked_extents(struct btrfs_root *root,
 				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_wait_marked_extents(struct btrfs_root *root,

commit cfad392b22163eba71d882950e17d2c4d43b2bad
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Jul 25 15:11:47 2013 -0400

    Btrfs: check to see if root_list is empty before adding it to dead roots
    
    A user reported a panic when running with autodefrag and deleting snapshots.
    This is because we could end up trying to add the root to the dead roots list
    twice.  To fix this check to see if we are empty before adding ourselves to the
    dead roots list.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 005b0375d18c..defbc4269897 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -143,7 +143,7 @@ int btrfs_wait_for_commit(struct btrfs_root *root, u64 transid);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root);
 
-int btrfs_add_dead_root(struct btrfs_root *root);
+void btrfs_add_dead_root(struct btrfs_root *root);
 int btrfs_defrag_root(struct btrfs_root *root);
 int btrfs_clean_one_deleted_snapshot(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,

commit 6df9a95e63395f595d0d1eb5d561dd6c91c40270
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Thu Jun 27 13:22:46 2013 -0400

    Btrfs: make the chunk allocator completely tree lockless
    
    When adjusting the enospc rules for relocation I ran into a deadlock because we
    were relocating the only system chunk and that forced us to try and allocate a
    new system chunk while holding locks in the chunk tree, which caused us to
    deadlock.  To fix this I've moved all of the dev extent addition and chunk
    addition out to the delayed chunk completion stuff.  We still keep the in-memory
    stuff which makes sure everything is consistent.
    
    One change I had to make was to search the commit root of the device tree to
    find a free dev extent, and hold onto any chunk em's that we allocated in that
    transaction so we do not allocate the same dev extent twice.  This has the side
    effect of fixing a bug with balance that has been there ever since balance
    existed.  Basically you can free a block group and it's dev extent and then
    immediately allocate that dev extent for a new block group and write stuff to
    that dev extent, all within the same transaction.  So if you happen to crash
    during a balance you could come back to a completely broken file system.  This
    patch should keep these sort of things from happening in the future since we
    won't be able to allocate free'd dev extents until after the transaction
    commits.  This has passed all of the xfstests and my super annoying stress test
    followed by a balance.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 66d2a6ccbf05..005b0375d18c 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -56,6 +56,7 @@ struct btrfs_transaction {
 	wait_queue_head_t commit_wait;
 	struct list_head pending_snapshots;
 	struct list_head ordered_operations;
+	struct list_head pending_chunks;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
 };

commit 4a9d8bdee368de78ace8b36da4eb2186afea162d
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri May 17 03:53:43 2013 +0000

    Btrfs: make the state of the transaction more readable
    
    We used 3 variants to track the state of the transaction, it was complex
    and wasted the memory space. Besides that, it was hard to understand that
    which types of the transaction handles should be blocked in each transaction
    state, so the developers often made mistakes.
    
    This patch improved the above problem. In this patch, we define 6 states
    for the transaction,
      enum btrfs_trans_state {
            TRANS_STATE_RUNNING             = 0,
            TRANS_STATE_BLOCKED             = 1,
            TRANS_STATE_COMMIT_START        = 2,
            TRANS_STATE_COMMIT_DOING        = 3,
            TRANS_STATE_UNBLOCKED           = 4,
            TRANS_STATE_COMPLETED           = 5,
            TRANS_STATE_MAX                 = 6,
      }
    and just use 1 variant to track those state.
    
    In order to make the blocked handle types for each state more clear,
    we introduce a array:
      unsigned int btrfs_blocked_trans_types[TRANS_STATE_MAX] = {
            [TRANS_STATE_RUNNING]           = 0U,
            [TRANS_STATE_BLOCKED]           = (__TRANS_USERSPACE |
                                               __TRANS_START),
            [TRANS_STATE_COMMIT_START]      = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH),
            [TRANS_STATE_COMMIT_DOING]      = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH |
                                               __TRANS_JOIN),
            [TRANS_STATE_UNBLOCKED]         = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH |
                                               __TRANS_JOIN |
                                               __TRANS_JOIN_NOLOCK),
            [TRANS_STATE_COMPLETED]         = (__TRANS_USERSPACE |
                                               __TRANS_START |
                                               __TRANS_ATTACH |
                                               __TRANS_JOIN |
                                               __TRANS_JOIN_NOLOCK),
      }
    it is very intuitionistic.
    
    Besides that, because we remove ->in_commit in transaction structure, so
    the lock ->commit_lock which was used to protect it is unnecessary, remove
    ->commit_lock.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 0fc45e2a5139..66d2a6ccbf05 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -22,6 +22,16 @@
 #include "delayed-ref.h"
 #include "ctree.h"
 
+enum btrfs_trans_state {
+	TRANS_STATE_RUNNING		= 0,
+	TRANS_STATE_BLOCKED		= 1,
+	TRANS_STATE_COMMIT_START	= 2,
+	TRANS_STATE_COMMIT_DOING	= 3,
+	TRANS_STATE_UNBLOCKED		= 4,
+	TRANS_STATE_COMPLETED		= 5,
+	TRANS_STATE_MAX			= 6,
+};
+
 struct btrfs_transaction {
 	u64 transid;
 	/*
@@ -37,10 +47,8 @@ struct btrfs_transaction {
 	atomic_t num_writers;
 	atomic_t use_count;
 
-	spinlock_t commit_lock;
-	int in_commit;
-	int commit_done;
-	int blocked;
+	/* Be protected by fs_info->trans_lock when we want to change it. */
+	enum btrfs_trans_state state;
 	struct list_head list;
 	struct extent_io_tree dirty_pages;
 	unsigned long start_time;

commit 3f1e3fa65c44b8ecdf2d6f14956c2cfe3a462a03
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:29 2013 +0000

    Btrfs: remove unnecessary varient ->num_joined in btrfs_transaction structure
    
    We used ->num_joined track if there were some writers which join the current
    transaction when the committer was sleeping. If some writers joined the current
    transaction, we has to continue the while loop to do some necessary stuff, such
    as flush the ordered operations. But it is unnecessary because we will do it
    after the while loop.
    
    Besides that, tracking ->num_joined would make the committer drop into the while
    loop when there are lots of internal writers(TRANS_JOIN).
    
    So we remove ->num_joined and don't track if there are some writers which join
    the current transaction when the committer is sleeping.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 5cc77b085427..0fc45e2a5139 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -37,8 +37,6 @@ struct btrfs_transaction {
 	atomic_t num_writers;
 	atomic_t use_count;
 
-	unsigned long num_joined;
-
 	spinlock_t commit_lock;
 	int in_commit;
 	int commit_done;

commit 0860adfdb21c87c73afab4d143e7195603b3e883
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed May 15 07:48:27 2013 +0000

    Btrfs: don't wait for all the writers circularly during the transaction commit
    
    btrfs_commit_transaction has the following loop before we commit the
    transaction.
    
    do {
        // attempt to do some useful stuff and/or sleep
    } while (atomic_read(&cur_trans->num_writers) > 1 ||
             (should_grow && cur_trans->num_joined != joined));
    
    This is used to prevent from the TRANS_START to get in the way of a
    committing transaction. But it does not prevent from TRANS_JOIN, that
    is we would do this loop for a long time if some writers JOIN the
    current transaction endlessly.
    
    Because we need join the current transaction to do some useful stuff,
    we can not block TRANS_JOIN here. So we introduce a external writer
    counter, which is used to count the TRANS_USERSPACE/TRANS_START writers.
    If the external writer counter is zero, we can break the above loop.
    
    In order to make the code more clear, we don't use enum variant
    to define the type of the transaction handle, use bitmask instead.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 24c97335a59f..5cc77b085427 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -24,6 +24,12 @@
 
 struct btrfs_transaction {
 	u64 transid;
+	/*
+	 * total external writers(USERSPACE/START/ATTACH) in this
+	 * transaction, it must be zero before the transaction is
+	 * being committed
+	 */
+	atomic_t num_extwriters;
 	/*
 	 * total writers in this transaction, it must be zero before the
 	 * transaction can end
@@ -48,13 +54,22 @@ struct btrfs_transaction {
 	int aborted;
 };
 
-enum btrfs_trans_type {
-	TRANS_START,
-	TRANS_JOIN,
-	TRANS_USERSPACE,
-	TRANS_JOIN_NOLOCK,
-	TRANS_ATTACH,
-};
+#define __TRANS_FREEZABLE	(1U << 0)
+
+#define __TRANS_USERSPACE	(1U << 8)
+#define __TRANS_START		(1U << 9)
+#define __TRANS_ATTACH		(1U << 10)
+#define __TRANS_JOIN		(1U << 11)
+#define __TRANS_JOIN_NOLOCK	(1U << 12)
+
+#define TRANS_USERSPACE		(__TRANS_USERSPACE | __TRANS_FREEZABLE)
+#define TRANS_START		(__TRANS_START | __TRANS_FREEZABLE)
+#define TRANS_ATTACH		(__TRANS_ATTACH)
+#define TRANS_JOIN		(__TRANS_JOIN | __TRANS_FREEZABLE)
+#define TRANS_JOIN_NOLOCK	(__TRANS_JOIN_NOLOCK)
+
+#define TRANS_EXTWRITERS	(__TRANS_USERSPACE | __TRANS_START |	\
+				 __TRANS_ATTACH)
 
 struct btrfs_trans_handle {
 	u64 transid;
@@ -70,7 +85,7 @@ struct btrfs_trans_handle {
 	short aborted;
 	short adding_csums;
 	bool allocating_chunk;
-	enum btrfs_trans_type type;
+	unsigned int type;
 	/*
 	 * this root is only needed to validate that the root passed to
 	 * start_transaction is the same as the one passed to end_transaction.

commit 48a3b6366f6913683563d934eb16fea67dead9c1
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Apr 25 20:41:01 2013 +0000

    btrfs: make static code static & remove dead code
    
    Big patch, but all it does is add statics to functions which
    are in fact static, then remove the associated dead-code fallout.
    
    removed functions:
    
    btrfs_iref_to_path()
    __btrfs_lookup_delayed_deletion_item()
    __btrfs_search_delayed_insertion_item()
    __btrfs_search_delayed_deletion_item()
    find_eb_for_page()
    btrfs_find_block_group()
    range_straddles_pages()
    extent_range_uptodate()
    btrfs_file_extent_length()
    btrfs_scrub_cancel_devid()
    btrfs_start_transaction_lflush()
    
    btrfs_print_tree() is left because it is used for debugging.
    btrfs_start_transaction_lflush() and btrfs_reada_detach() are
    left for symmetry.
    
    ulist.c functions are left, another patch will take care of those.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index f6edd5e6baa3..24c97335a59f 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -146,5 +146,4 @@ int btrfs_wait_marked_extents(struct btrfs_root *root,
 				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_transaction_blocked(struct btrfs_fs_info *info);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
-void put_transaction(struct btrfs_transaction *transaction);
 #endif

commit 9d1a2a3ad59f7ae810bf04a5a05995bf2d79300c
Author: David Sterba <dsterba@suse.cz>
Date:   Tue Mar 12 15:13:28 2013 +0000

    btrfs: clean snapshots one by one
    
    Each time pick one dead root from the list and let the caller know if
    it's needed to continue. This should improve responsiveness during
    umount and balance which at some point waits for cleaning all currently
    queued dead roots.
    
    A new dead root is added to the end of the list, so the snapshots
    disappear in the order of deletion.
    
    The snapshot cleaning work is now done only from the cleaner thread and the
    others wake it if needed.
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 3c8e0d25c8e4..f6edd5e6baa3 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -123,7 +123,7 @@ int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 
 int btrfs_add_dead_root(struct btrfs_root *root);
 int btrfs_defrag_root(struct btrfs_root *root);
-int btrfs_clean_old_snapshots(struct btrfs_root *root);
+int btrfs_clean_one_deleted_snapshot(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
 int btrfs_commit_transaction_async(struct btrfs_trans_handle *trans,

commit d5c1207017cd8387b4d3224dd7ab6cf5cd7f1c9a
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Feb 28 10:04:33 2013 +0000

    Btrfs: fix wrong reserved space in qgroup during snap/subv creation
    
    There are two problems in the space reservation of the snapshot/
    subvolume creation.
    - don't reserve the space for the root item insertion
    - the space which is reserved in the qgroup is different with
      the free space reservation. we need reserve free space for
      7 items, but in qgroup reservation, we need reserve space only
      for 3 items.
    
    So we implement new metadata reservation functions for the
    snapshot/subvolume creation.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 5f67fba07ab4..3c8e0d25c8e4 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -90,6 +90,7 @@ struct btrfs_pending_snapshot {
 	struct btrfs_qgroup_inherit *inherit;
 	/* block reservation for the operation */
 	struct btrfs_block_rsv block_rsv;
+	u64 qgroup_reserved;
 	/* extra metadata reseration for relocation */
 	int error;
 	bool readonly;

commit e9662f701c85ebc99f532bf8bb53208c0648846a
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Feb 28 10:01:15 2013 +0000

    Btrfs: remove unnecessary dget_parent/dput when creating the pending snapshot
    
    Since we have grabbed the parent inode at the beginning of the
    snapshot creation, and both sync and async snapshot creation
    release it after the pending snapshots are actually created,
    it is safe to access the parent inode directly during the snapshot
    creation, we needn't use dget_parent/dput to fix the parent dentry
    and get the dir inode.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 5afd7b1dceac..5f67fba07ab4 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -84,6 +84,7 @@ struct btrfs_trans_handle {
 
 struct btrfs_pending_snapshot {
 	struct dentry *dentry;
+	struct inode *dir;
 	struct btrfs_root *root;
 	struct btrfs_root *snap;
 	struct btrfs_qgroup_inherit *inherit;

commit d4edf39bd5db443151efc993dac67ec9d6b5b8c1
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Feb 20 09:17:06 2013 +0000

    Btrfs: fix uncompleted transaction
    
    In some cases, we need commit the current transaction, but don't want
    to start a new one if there is no running transaction, so we introduce
    the function - btrfs_attach_transaction(), which can catch the current
    transaction, and return -ENOENT if there is no running transaction.
    
    But no running transaction doesn't mean the current transction completely,
    because we removed the running transaction before it completes. In some
    cases, it doesn't matter. But in some special cases, such as freeze fs, we
    hope the transaction is fully on disk, it will introduce some bugs, for
    example, we may feeze the fs and dump the data in the disk, if the transction
    doesn't complete, we would dump inconsistent data. So we need fix the above
    problem for those cases.
    
    We fixes this problem by introducing a function:
            btrfs_attach_transaction_barrier()
    if we hope all the transaction is fully on the disk, even they are not
    running, we can use this function.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 3f772fd0191a..5afd7b1dceac 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -112,6 +112,8 @@ struct btrfs_trans_handle *btrfs_start_transaction_lflush(
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_attach_transaction(struct btrfs_root *root);
+struct btrfs_trans_handle *btrfs_attach_transaction_barrier(
+					struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *root);
 int btrfs_wait_for_commit(struct btrfs_root *root, u64 transid);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,

commit 569e0f358c0c37f6733702d4a5d2c412860f7169
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Feb 13 11:09:14 2013 -0500

    Btrfs: place ordered operations on a per transaction list
    
    Miao made the ordered operations stuff run async, which introduced a
    deadlock where we could get somebody (sync) racing in and committing the
    transaction while a commit was already happening.  The new committer would
    try and flush ordered operations which would hang waiting for the commit to
    finish because it is done asynchronously and no longer inherits the callers
    trans handle.  To fix this we need to make the ordered operations list a per
    transaction list.  We can get new inodes added to the ordered operation list
    by truncating them and then having another process writing to them, so this
    makes it so that anybody trying to add an ordered operation _must_ start a
    transaction in order to add itself to the list, which will keep new inodes
    from getting added to the ordered operations list after we start committing.
    This should fix the deadlock and also keeps us from doing a lot more work
    than we need to during commit.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 46628210e5d8..3f772fd0191a 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -43,6 +43,7 @@ struct btrfs_transaction {
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 	struct list_head pending_snapshots;
+	struct list_head ordered_operations;
 	struct btrfs_delayed_ref_root delayed_refs;
 	int aborted;
 };

commit de78b51a2852bddccd6535e9e12de65f92787a1e
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Jan 31 18:21:12 2013 +0000

    btrfs: remove cache only arguments from defrag path
    
    The entry point at the defrag ioctl always sets "cache only" to 0;
    the codepaths haven't run for a long time as far as I can
    tell.  Chris says they're dead code, so remove them.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 69700f7b20ac..46628210e5d8 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -117,7 +117,7 @@ int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root);
 
 int btrfs_add_dead_root(struct btrfs_root *root);
-int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
+int btrfs_defrag_root(struct btrfs_root *root);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);

commit c6b305a89b1903d63652691ad5eb9f05aa0326b8
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Dec 18 09:16:16 2012 -0500

    Btrfs: don't re-enter when allocating a chunk
    
    If we start running low on metadata space we will try to allocate a chunk,
    which could then try to allocate a chunk to add the device entry.  The thing
    is we allocate a chunk before we try really hard to make the allocation, so
    we should be able to find space for the device entry.  Add a flag to the
    trans handle so we know we're currently allocating a chunk so we can just
    bail out if we try to allocate another chunk.  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 0e8aa1e6c287..69700f7b20ac 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -68,6 +68,7 @@ struct btrfs_trans_handle {
 	struct btrfs_block_rsv *orig_rsv;
 	short aborted;
 	short adding_csums;
+	bool allocating_chunk;
 	enum btrfs_trans_type type;
 	/*
 	 * this root is only needed to validate that the root passed to

commit 08e007d2e57744472a9424735a368ffe6d625597
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Tue Oct 16 11:33:38 2012 +0000

    Btrfs: improve the noflush reservation
    
    In some places(such as: evicting inode), we just can not flush the reserved
    space of delalloc, flushing the delayed directory index and delayed inode
    is OK, but we don't try to flush those things and just go back when there is
    no enough space to be reserved. This patch fixes this problem.
    
    We defined 3 types of the flush operations: NO_FLUSH, FLUSH_LIMIT and FLUSH_ALL.
    If we can in the transaction, we should not flush anything, or the deadlock
    would happen, so use NO_FLUSH. If we flushing the reserved space of delalloc
    would cause deadlock, use FLUSH_LIMIT. In the other cases, FLUSH_ALL is used,
    and we will flush all things.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 80961947a6b2..0e8aa1e6c287 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -105,7 +105,7 @@ int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   int num_items);
-struct btrfs_trans_handle *btrfs_start_transaction_noflush(
+struct btrfs_trans_handle *btrfs_start_transaction_lflush(
 					struct btrfs_root *root, int num_items);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);

commit 354aa0fb6d5b97b262e056f7ad7bfc88d7ce0004
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Sep 20 01:54:00 2012 -0600

    Btrfs: fix orphan transaction on the freezed filesystem
    
    With the following debug patch:
    
     static int btrfs_freeze(struct super_block *sb)
     {
    +       struct btrfs_fs_info *fs_info = btrfs_sb(sb);
    +       struct btrfs_transaction *trans;
    +
    +       spin_lock(&fs_info->trans_lock);
    +       trans = fs_info->running_transaction;
    +       if (trans) {
    +               printk("Transid %llu, use_count %d, num_writer %d\n",
    +                       trans->transid, atomic_read(&trans->use_count),
    +                       atomic_read(&trans->num_writers));
    +       }
    +       spin_unlock(&fs_info->trans_lock);
            return 0;
     }
    
    I found there was a orphan transaction after the freeze operation was done.
    
    It is because the transaction may not be committed when the transaction handle
    end even though it is the last handle of the current transaction. This design
    avoid committing the transaction frequently, but also introduce the above
    problem.
    
    So I add btrfs_attach_transaction() which can catch the current transaction
    and commit it. If there is no transaction, it will return ENOENT, and do not
    anything.
    
    This function also can be used to instead of btrfs_join_transaction_freeze()
    because it don't increase the writer counter and don't start a new transaction,
    so it also can fix the deadlock between sync and freeze.
    
    Besides that, it is used to instead of btrfs_join_transaction() in
    transaction_kthread(), because if there is no transaction, the transaction
    kthread needn't anything.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 0630bd19396a..80961947a6b2 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -52,7 +52,7 @@ enum btrfs_trans_type {
 	TRANS_JOIN,
 	TRANS_USERSPACE,
 	TRANS_JOIN_NOLOCK,
-	TRANS_JOIN_FREEZE,
+	TRANS_ATTACH,
 };
 
 struct btrfs_trans_handle {
@@ -109,7 +109,7 @@ struct btrfs_trans_handle *btrfs_start_transaction_noflush(
 					struct btrfs_root *root, int num_items);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);
-struct btrfs_trans_handle *btrfs_join_transaction_freeze(struct btrfs_root *root);
+struct btrfs_trans_handle *btrfs_attach_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *root);
 int btrfs_wait_for_commit(struct btrfs_root *root, u64 transid);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,

commit a698d0755adb6f27289d1e6610b2240595d27e8c
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Thu Sep 20 01:51:59 2012 -0600

    Btrfs: add a type field for the transaction handle
    
    This patch add a type field into the transaction handle structure,
    in this way, we needn't implement various end-transaction functions
    and can make the code more simple and readable.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index fbf8313b9d67..0630bd19396a 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -47,6 +47,14 @@ struct btrfs_transaction {
 	int aborted;
 };
 
+enum btrfs_trans_type {
+	TRANS_START,
+	TRANS_JOIN,
+	TRANS_USERSPACE,
+	TRANS_JOIN_NOLOCK,
+	TRANS_JOIN_FREEZE,
+};
+
 struct btrfs_trans_handle {
 	u64 transid;
 	u64 bytes_reserved;
@@ -58,8 +66,9 @@ struct btrfs_trans_handle {
 	struct btrfs_transaction *transaction;
 	struct btrfs_block_rsv *block_rsv;
 	struct btrfs_block_rsv *orig_rsv;
-	int aborted;
-	int adding_csums;
+	short aborted;
+	short adding_csums;
+	enum btrfs_trans_type type;
 	/*
 	 * this root is only needed to validate that the root passed to
 	 * start_transaction is the same as the one passed to end_transaction.
@@ -94,8 +103,6 @@ static inline void btrfs_set_inode_last_trans(struct btrfs_trans_handle *trans,
 
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
-int btrfs_end_transaction_nolock(struct btrfs_trans_handle *trans,
-				 struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   int num_items);
 struct btrfs_trans_handle *btrfs_start_transaction_noflush(

commit 60376ce4a8396bc5cd777be05b6a9bf044520f42
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Fri Sep 14 10:34:40 2012 -0400

    Btrfs: fix race in sync and freeze again
    
    I screwed this up, there is a race between checking if there is a running
    transaction and actually starting a transaction in sync where we could race
    with a freezer and get ourselves into trouble.  To fix this we need to make
    a new join type to only do the try lock on the freeze stuff.  If it fails
    we'll return EPERM and just return from sync.  This fixes a hang Liu Bo
    reported when running xfstest 68 in a loop.  Thanks,
    
    Reported-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index b6463e128048..fbf8313b9d67 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -102,6 +102,7 @@ struct btrfs_trans_handle *btrfs_start_transaction_noflush(
 					struct btrfs_root *root, int num_items);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);
+struct btrfs_trans_handle *btrfs_join_transaction_freeze(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *root);
 int btrfs_wait_for_commit(struct btrfs_root *root, u64 transid);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,

commit ea658badc47e614e38ab4d98510488474c7e6d4b
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Sep 11 16:57:25 2012 -0400

    Btrfs: delay block group item insertion
    
    So we have lots of places where we try to preallocate chunks in order to
    make sure we have enough space as we make our allocations.  This has
    historically meant that we're constantly tweaking when we should allocate a
    new chunk, and historically we have gotten this horribly wrong so we way
    over allocate either metadata or data.  To try and keep this from happening
    we are going to make it so that the block group item insertion is done out
    of band at the end of a transaction.  This will allow us to create chunks
    even if we are trying to make an allocation for the extent tree.  With this
    patch my enospc tests run faster (didn't expect this) and more efficiently
    use the disk space (this is what I wanted).  Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 1b054800eca3..b6463e128048 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -68,6 +68,7 @@ struct btrfs_trans_handle {
 	struct btrfs_root *root;
 	struct seq_list delayed_ref_elem;
 	struct list_head qgroup_ref_list;
+	struct list_head new_bgs;
 };
 
 struct btrfs_pending_snapshot {

commit 8407aa464331556e4f6784f974030b83fc7585ed
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Sep 7 01:43:32 2012 -0600

    Btrfs: fix corrupted metadata in the snapshot
    
    When we delete a inode, we will remove all the delayed items including delayed
    inode update, and then truncate all the relative metadata. If there is lots of
    metadata, we will end the current transaction, and start a new transaction to
    truncate the left metadata. In this way, we will leave a inode item that its
    link counter is > 0, and also may leave some directory index items in fs/file tree
    after the current transaction ends. In other words, the metadata in this fs/file tree
    is inconsistent. If we create a snapshot for this tree now, we will find a inode with
    corrupted metadata in the new snapshot, and we won't continue to drop the left metadata,
    because its link counter is not 0.
    
    We fix this problem by updating the inode item before the current transaction ends.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 1a138bfb8f13..1b054800eca3 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -97,6 +97,8 @@ int btrfs_end_transaction_nolock(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   int num_items);
+struct btrfs_trans_handle *btrfs_start_transaction_noflush(
+					struct btrfs_root *root, int num_items);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *root);

commit 46d8bc34248f3a94dea910137d1ddf5fb1e3a1cc
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Aug 29 01:07:55 2012 -0600

    Btrfs: fix a bug in checking whether a inode is already in log
    
    This is based on Josef's "Btrfs: turbo charge fsync".
    
    The current btrfs checks if an inode is in log by comparing
    root's last_log_commit to inode's last_sub_trans[2].
    
    But the problem is that this root->last_log_commit is shared among
    inodes.
    
    Say we have N inodes to be logged, after the first inode,
    root's last_log_commit is updated and the N-1 remained files will
    be skipped.
    
    This fixes the bug by keeping a local copy of root's last_log_commit
    inside each inode and this local copy will be maintained itself.
    
    [1]: we regard each log transaction as a subset of btrfs's transaction,
    i.e. sub_trans
    
    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index e8b8416c688b..1a138bfb8f13 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -88,6 +88,7 @@ static inline void btrfs_set_inode_last_trans(struct btrfs_trans_handle *trans,
 {
 	BTRFS_I(inode)->last_trans = trans->transaction->transid;
 	BTRFS_I(inode)->last_sub_trans = BTRFS_I(inode)->root->log_transid;
+	BTRFS_I(inode)->last_log_commit = BTRFS_I(inode)->root->last_log_commit;
 }
 
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,

commit b478b2baa37ac99fc04a30809c780dd5dfd43595
Merge: 67c9684f48ea 6f72c7e20dba
Author: Chris Mason <chris.mason@fusionio.com>
Date:   Wed Jul 25 16:11:38 2012 -0400

    Merge branch 'qgroup' of git://git.jan-o-sch.net/btrfs-unstable into for-linus
    
    Conflicts:
            fs/btrfs/ioctl.c
            fs/btrfs/ioctl.h
            fs/btrfs/transaction.c
            fs/btrfs/transaction.h
    
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

commit 0e721106923be82f651dd0ee504742a8a3eb089f
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Tue Jun 26 16:13:18 2012 -0400

    Btrfs: change how we indicate we're adding csums
    
    There is weird logic I had to put in place to make sure that when we were
    adding csums that we'd used the delalloc block rsv instead of the global
    block rsv.  Part of this meant that we had to free up our transaction
    reservation before we ran the delayed refs since csum deletion happens
    during the delayed ref work.  The problem with this is that when we release
    a reservation we will add it to the global reserve if it is not full in
    order to keep us going along longer before we have to force a transaction
    commit.  By releasing our reservation before we run delayed refs we don't
    get the opportunity to drain down the global reserve for the work we did, so
    we won't refill it as often.  This isn't a problem per-se, it just results
    in us possibly committing transactions more and more often, and in rare
    cases could cause those WARN_ON()'s to pop in use_block_rsv because we ran
    out of space in our block rsv.
    
    This also helps us by holding onto space while the delayed refs run so we
    don't end up with as many people trying to do things at the same time, which
    again will help us not force commits or hit the use_block_rsv warnings.
    Thanks,
    
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index fe27379e368b..d314a74b4968 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -57,6 +57,7 @@ struct btrfs_trans_handle {
 	struct btrfs_block_rsv *block_rsv;
 	struct btrfs_block_rsv *orig_rsv;
 	int aborted;
+	int adding_csums;
 };
 
 struct btrfs_pending_snapshot {

commit 6f72c7e20dbaea55f04546de69586c84a3654503
Author: Arne Jansen <sensille@gmx.net>
Date:   Wed Sep 14 15:58:21 2011 +0200

    Btrfs: add qgroup inheritance
    
    When creating a subvolume or snapshot, it is necessary
    to initialize the qgroup account with a copy of some
    other (tracking) qgroup. This patch adds parameters
    to the ioctls to pass the information from which qgroup
    to inherit.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 2759e0572c5c..cca315dcdfcd 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -73,6 +73,7 @@ struct btrfs_pending_snapshot {
 	struct dentry *dentry;
 	struct btrfs_root *root;
 	struct btrfs_root *snap;
+	struct btrfs_qgroup_inherit *inherit;
 	/* block reservation for the operation */
 	struct btrfs_block_rsv block_rsv;
 	/* extra metadata reseration for relocation */

commit c556723794b3487a79de1ecd6354975b1389f5ff
Author: Arne Jansen <sensille@gmx.net>
Date:   Wed Sep 14 15:44:05 2011 +0200

    Btrfs: hooks to reserve qgroup space
    
    Like block reserves, reserve a small piece of space on each
    transaction start and for delalloc. These are the hooks that
    can actually return EDQUOT to the user.
    The amount of space reserved is tracked in the transaction
    handle.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 16ba00842c38..2759e0572c5c 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -50,6 +50,7 @@ struct btrfs_transaction {
 struct btrfs_trans_handle {
 	u64 transid;
 	u64 bytes_reserved;
+	u64 qgroup_reserved;
 	unsigned long use_count;
 	unsigned long blocks_reserved;
 	unsigned long blocks_used;

commit bed92eae26ccf280d1a2168b7509447b56675a27
Author: Arne Jansen <sensille@gmx.net>
Date:   Thu Jun 28 18:03:02 2012 +0200

    Btrfs: qgroup implementation and prototypes
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>
    Signed-off-by: Jan Schmidt <list.btrfs@jan-o-sch.net>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 010729446e13..16ba00842c38 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -20,6 +20,7 @@
 #define __BTRFS_TRANSACTION__
 #include "btrfs_inode.h"
 #include "delayed-ref.h"
+#include "ctree.h"
 
 struct btrfs_transaction {
 	u64 transid;
@@ -63,6 +64,8 @@ struct btrfs_trans_handle {
 	 * Subvolume quota depends on this
 	 */
 	struct btrfs_root *root;
+	struct seq_list delayed_ref_elem;
+	struct list_head qgroup_ref_list;
 };
 
 struct btrfs_pending_snapshot {

commit d13603ef6e14a12cd65a6975e8117c0fea7c7ddf
Author: Arne Jansen <sensille@gmx.net>
Date:   Tue Sep 13 11:40:09 2011 +0200

    Btrfs: check the root passed to btrfs_end_transaction
    
    This patch only add a consistancy check to validate that the
    same root is passed to start_transaction and end_transaction.
    Subvolume quota depends on this.
    
    Signed-off-by: Arne Jansen <sensille@gmx.net>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index fe27379e368b..010729446e13 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -57,6 +57,12 @@ struct btrfs_trans_handle {
 	struct btrfs_block_rsv *block_rsv;
 	struct btrfs_block_rsv *orig_rsv;
 	int aborted;
+	/*
+	 * this root is only needed to validate that the root passed to
+	 * start_transaction is the same as the one passed to end_transaction.
+	 * Subvolume quota depends on this
+	 */
+	struct btrfs_root *root;
 };
 
 struct btrfs_pending_snapshot {

commit 49b25e0540904be0bf558b84475c69d72e4de66e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Mar 1 17:24:58 2012 +0100

    btrfs: enhance transaction abort infrastructure
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 02564e6230ac..fe27379e368b 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -43,6 +43,7 @@ struct btrfs_transaction {
 	wait_queue_head_t commit_wait;
 	struct list_head pending_snapshots;
 	struct btrfs_delayed_ref_root delayed_refs;
+	int aborted;
 };
 
 struct btrfs_trans_handle {
@@ -55,6 +56,7 @@ struct btrfs_trans_handle {
 	struct btrfs_transaction *transaction;
 	struct btrfs_block_rsv *block_rsv;
 	struct btrfs_block_rsv *orig_rsv;
+	int aborted;
 };
 
 struct btrfs_pending_snapshot {
@@ -114,4 +116,5 @@ int btrfs_wait_marked_extents(struct btrfs_root *root,
 				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_transaction_blocked(struct btrfs_fs_info *info);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
+void put_transaction(struct btrfs_transaction *transaction);
 #endif

commit ff5714cca971848963b87d6b477c16ca8abbaa54
Merge: 174ba50915b0 d90c732122a1
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat May 28 07:00:39 2011 -0400

    Merge branch 'for-chris' of
    git://git.kernel.org/pub/scm/linux/kernel/git/josef/btrfs-work into for-linus
    
    Conflicts:
            fs/btrfs/disk-io.c
            fs/btrfs/extent-tree.c
            fs/btrfs/free-space-cache.c
            fs/btrfs/inode.c
            fs/btrfs/transaction.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit d82a6f1d7e8b61ed5996334d0db66651bb43641d
Author: Josef Bacik <josef@redhat.com>
Date:   Wed May 11 15:26:06 2011 -0400

    Btrfs: kill BTRFS_I(inode)->block_group
    
    Originally this was going to be used as a way to give hints to the allocator,
    but frankly we can get much better hints elsewhere and it's not even used at all
    for anything usefull.  In addition to be completely useless, when we initialize
    an inode we try and find a freeish block group to set as the inodes block group,
    and with a completely full 40gb fs this takes _forever_, so I imagine with say
    1tb fs this is just unbearable.  So just axe the thing altoghether, we don't
    need it and it saves us 8 bytes in the inode and saves us 500 microseconds per
    inode lookup in my testcase.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 11c6efcd4ed2..da7289e06a82 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -47,7 +47,6 @@ struct btrfs_transaction {
 
 struct btrfs_trans_handle {
 	u64 transid;
-	u64 block_group;
 	u64 bytes_reserved;
 	unsigned long use_count;
 	unsigned long blocks_reserved;
@@ -70,19 +69,6 @@ struct btrfs_pending_snapshot {
 	struct list_head list;
 };
 
-static inline void btrfs_set_trans_block_group(struct btrfs_trans_handle *trans,
-					       struct inode *inode)
-{
-	trans->block_group = BTRFS_I(inode)->block_group;
-}
-
-static inline void btrfs_update_inode_block_group(
-					  struct btrfs_trans_handle *trans,
-					  struct inode *inode)
-{
-	BTRFS_I(inode)->block_group = trans->block_group;
-}
-
 static inline void btrfs_set_inode_last_trans(struct btrfs_trans_handle *trans,
 					      struct inode *inode)
 {

commit a4abeea41adfa3c143c289045f4625dfaeba2212
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Apr 11 17:25:13 2011 -0400

    Btrfs: kill trans_mutex
    
    We use trans_mutex for lots of things, here's a basic list
    
    1) To serialize trans_handles joining the currently running transaction
    2) To make sure that no new trans handles are started while we are committing
    3) To protect the dead_roots list and the transaction lists
    
    Really the serializing trans_handles joining is not too hard, and can really get
    bogged down in acquiring a reference to the transaction.  So replace the
    trans_mutex with a trans_lock spinlock and use it to do the following
    
    1) Protect fs_info->running_transaction.  All trans handles have to do is check
    this, and then take a reference of the transaction and keep on going.
    2) Protect the fs_info->trans_list.  This doesn't get used too much, basically
    it just holds the current transactions, which will usually just be the currently
    committing transaction and the currently running transaction at most.
    3) Protect the dead roots list.  This is only ever processed by splicing the
    list so this is relatively simple.
    4) Protect the fs_info->reloc_ctl stuff.  This is very lightweight and was using
    the trans_mutex before, so this is a pretty straightforward change.
    5) Protect fs_info->no_trans_join.  Because we don't hold the trans_lock over
    the entirety of the commit we need to have a way to block new people from
    creating a new transaction while we're doing our work.  So we set no_trans_join
    and in join_transaction we test to see if that is set, and if it is we do a
    wait_on_commit.
    6) Make the transaction use count atomic so we don't need to take locks to
    modify it when we're dropping references.
    7) Add a commit_lock to the transaction to make sure multiple people trying to
    commit the same transaction don't race and commit at the same time.
    8) Make open_ioctl_trans an atomic so we don't have to take any locks for ioctl
    trans.
    
    I have tested this with xfstests, but obviously it is a pretty hairy change so
    lots of testing is greatly appreciated.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 154314f80f8d..11c6efcd4ed2 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -28,10 +28,12 @@ struct btrfs_transaction {
 	 * transaction can end
 	 */
 	atomic_t num_writers;
+	atomic_t use_count;
 
 	unsigned long num_joined;
+
+	spinlock_t commit_lock;
 	int in_commit;
-	atomic_t use_count;
 	int commit_done;
 	int blocked;
 	struct list_head list;

commit 2a1eb4614d984d5cd4c928784e9afcf5c07f93be
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Apr 13 15:15:59 2011 -0400

    Btrfs: if we've already started a trans handle, use that one
    
    We currently track trans handles in current->journal_info, but we don't actually
    use it.  This patch fixes it.  This will cover the case where we have multiple
    people starting transactions down the call chain.  This keeps us from having to
    allocate a new handle and all of that, we just increase the use count of the
    current handle, save the old block_rsv, and return.  I tested this with xfstests
    and it worked out fine.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 1f573f09dba2..154314f80f8d 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -47,11 +47,13 @@ struct btrfs_trans_handle {
 	u64 transid;
 	u64 block_group;
 	u64 bytes_reserved;
+	unsigned long use_count;
 	unsigned long blocks_reserved;
 	unsigned long blocks_used;
 	unsigned long delayed_ref_updates;
 	struct btrfs_transaction *transaction;
 	struct btrfs_block_rsv *block_rsv;
+	struct btrfs_block_rsv *orig_rsv;
 };
 
 struct btrfs_pending_snapshot {

commit 7a7eaa40a39bde4eefc91aadeb1ce3dc4e6a1252
Author: Josef Bacik <josef@redhat.com>
Date:   Wed Apr 13 12:54:33 2011 -0400

    Btrfs: take away the num_items argument from btrfs_join_transaction
    
    I keep forgetting that btrfs_join_transaction() just ignores the num_items
    argument, which leads me to sending pointless patches and looking stupid :).  So
    just kill the num_items argument from btrfs_join_transaction and
    btrfs_start_ioctl_transaction, since neither of them use it.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index e441acc6c584..1f573f09dba2 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -92,12 +92,9 @@ int btrfs_end_transaction_nolock(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   int num_items);
-struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root,
-						  int num_blocks);
-struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root,
-							  int num_blocks);
-struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *r,
-							 int num_blocks);
+struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root);
+struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root);
+struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *root);
 int btrfs_wait_for_commit(struct btrfs_root *root, u64 transid);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root);

commit 945d8962ceee6bb273365d0bdf42f763225b290f
Merge: 0d0ca30f1809 4ea028859bbd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sun May 22 12:33:42 2011 -0400

    Merge branch 'cleanups' of git://repo.or.cz/linux-2.6/btrfs-unstable into inode_numbers
    
    Conflicts:
            fs/btrfs/extent-tree.c
            fs/btrfs/free-space-cache.c
            fs/btrfs/inode.c
            fs/btrfs/tree-log.c
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit 16cdcec736cd214350cdb591bf1091f8beedefa0
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Apr 22 18:12:22 2011 +0800

    btrfs: implement delayed inode items operation
    
    Changelog V5 -> V6:
    - Fix oom when the memory load is high, by storing the delayed nodes into the
      root's radix tree, and letting btrfs inodes go.
    
    Changelog V4 -> V5:
    - Fix the race on adding the delayed node to the inode, which is spotted by
      Chris Mason.
    - Merge Chris Mason's incremental patch into this patch.
    - Fix deadlock between readdir() and memory fault, which is reported by
      Itaru Kitayama.
    
    Changelog V3 -> V4:
    - Fix nested lock, which is reported by Itaru Kitayama, by updating space cache
      inode in time.
    
    Changelog V2 -> V3:
    - Fix the race between the delayed worker and the task which does delayed items
      balance, which is reported by Tsutomu Itoh.
    - Modify the patch address David Sterba's comment.
    - Fix the bug of the cpu recursion spinlock, reported by Chris Mason
    
    Changelog V1 -> V2:
    - break up the global rb-tree, use a list to manage the delayed nodes,
      which is created for every directory and file, and used to manage the
      delayed directory name index items and the delayed inode item.
    - introduce a worker to deal with the delayed nodes.
    
    Compare with Ext3/4, the performance of file creation and deletion on btrfs
    is very poor. the reason is that btrfs must do a lot of b+ tree insertions,
    such as inode item, directory name item, directory name index and so on.
    
    If we can do some delayed b+ tree insertion or deletion, we can improve the
    performance, so we made this patch which implemented delayed directory name
    index insertion/deletion and delayed inode update.
    
    Implementation:
    - introduce a delayed root object into the filesystem, that use two lists to
      manage the delayed nodes which are created for every file/directory.
      One is used to manage all the delayed nodes that have delayed items. And the
      other is used to manage the delayed nodes which is waiting to be dealt with
      by the work thread.
    - Every delayed node has two rb-tree, one is used to manage the directory name
      index which is going to be inserted into b+ tree, and the other is used to
      manage the directory name index which is going to be deleted from b+ tree.
    - introduce a worker to deal with the delayed operation. This worker is used
      to deal with the works of the delayed directory name index items insertion
      and deletion and the delayed inode update.
      When the delayed items is beyond the lower limit, we create works for some
      delayed nodes and insert them into the work queue of the worker, and then
      go back.
      When the delayed items is beyond the upper bound, we create works for all
      the delayed nodes that haven't been dealt with, and insert them into the work
      queue of the worker, and then wait for that the untreated items is below some
      threshold value.
    - When we want to insert a directory name index into b+ tree, we just add the
      information into the delayed inserting rb-tree.
      And then we check the number of the delayed items and do delayed items
      balance. (The balance policy is above.)
    - When we want to delete a directory name index from the b+ tree, we search it
      in the inserting rb-tree at first. If we look it up, just drop it. If not,
      add the key of it into the delayed deleting rb-tree.
      Similar to the delayed inserting rb-tree, we also check the number of the
      delayed items and do delayed items balance.
      (The same to inserting manipulation)
    - When we want to update the metadata of some inode, we cached the data of the
      inode into the delayed node. the worker will flush it into the b+ tree after
      dealing with the delayed insertion and deletion.
    - We will move the delayed node to the tail of the list after we access the
      delayed node, By this way, we can cache more delayed items and merge more
      inode updates.
    - If we want to commit transaction, we will deal with all the delayed node.
    - the delayed node will be freed when we free the btrfs inode.
    - Before we log the inode items, we commit all the directory name index items
      and the delayed inode update.
    
    I did a quick test by the benchmark tool[1] and found we can improve the
    performance of file creation by ~15%, and file deletion by ~20%.
    
    Before applying this patch:
    Create files:
            Total files: 50000
            Total time: 1.096108
            Average time: 0.000022
    Delete files:
            Total files: 50000
            Total time: 1.510403
            Average time: 0.000030
    
    After applying this patch:
    Create files:
            Total files: 50000
            Total time: 0.932899
            Average time: 0.000019
    Delete files:
            Total files: 50000
            Total time: 1.215732
            Average time: 0.000024
    
    [1] http://marc.info/?l=linux-btrfs&m=128212635122920&q=p3
    
    Many thanks for Kitayama-san's help!
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Reviewed-by: David Sterba <dave@jikos.cz>
    Tested-by: Tsutomu Itoh <t-itoh@jp.fujitsu.com>
    Tested-by: Itaru Kitayama <kitayama@cl.bb4u.ne.jp>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index e441acc6c584..cb928c6c42e6 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -115,6 +115,8 @@ int btrfs_commit_transaction_async(struct btrfs_trans_handle *trans,
 				   int wait_for_unblock);
 int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
+int btrfs_end_transaction_dmeta(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root);
 int btrfs_should_end_transaction(struct btrfs_trans_handle *trans,
 				 struct btrfs_root *root);
 void btrfs_throttle(struct btrfs_root *root);

commit 621496f4fd56195b7b273521f467c2945165481f
Author: David Sterba <dsterba@suse.cz>
Date:   Wed May 4 12:56:49 2011 +0200

    btrfs: remove unused function prototypes
    
    function prototypes without a body
    
    Signed-off-by: David Sterba <dsterba@suse.cz>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index e441acc6c584..000a41008c3b 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -101,11 +101,8 @@ struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *r,
 int btrfs_wait_for_commit(struct btrfs_root *root, u64 transid);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root);
-int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,
-			    struct btrfs_root *root);
 
 int btrfs_add_dead_root(struct btrfs_root *root);
-int btrfs_drop_dead_root(struct btrfs_root *root);
 int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,

commit 13c5a93e7005d7dae0b6d070d25203593e692d13
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Apr 11 15:45:29 2011 -0400

    Btrfs: avoid taking the trans_mutex in btrfs_end_transaction
    
    I've been working on making our O_DIRECT latency not suck and I noticed we were
    taking the trans_mutex in btrfs_end_transaction.  So to do this we convert
    num_writers and use_count to atomic_t's and just decrement them in
    btrfs_end_transaction.  Instead of deleting the transaction from the trans list
    in put_transaction we do that in btrfs_commit_transaction() since that's the
    only time it actually needs to be removed from the list.  Thanks,
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 229a594cacd5..e441acc6c584 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -27,11 +27,11 @@ struct btrfs_transaction {
 	 * total writers in this transaction, it must be zero before the
 	 * transaction can end
 	 */
-	unsigned long num_writers;
+	atomic_t num_writers;
 
 	unsigned long num_joined;
 	int in_commit;
-	int use_count;
+	atomic_t use_count;
 	int commit_done;
 	int blocked;
 	struct list_head list;

commit b83cc9693f39689490970c19f6c5b866f6719a70
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Mon Dec 20 16:04:08 2010 +0800

    Btrfs: Add readonly snapshots support
    
    Usage:
    
    Set BTRFS_SUBVOL_RDONLY of btrfs_ioctl_vol_arg_v2->flags, and call
    ioctl(BTRFS_I0CTL_SNAP_CREATE_V2).
    
    Implementation:
    
    - Set readonly bit of btrfs_root_item->flags.
    - Add readonly checks in btrfs_permission (inode_permission),
    btrfs_setattr, btrfs_set/remove_xattr and some ioctls.
    
    Changelog for v3:
    
    - Eliminate btrfs_root->readonly, but check btrfs_root->root_item.flags.
    - Rename BTRFS_ROOT_SNAP_RDONLY to BTRFS_ROOT_SUBVOL_RDONLY.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index f104b57ad4ef..229a594cacd5 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -62,6 +62,7 @@ struct btrfs_pending_snapshot {
 	struct btrfs_block_rsv block_rsv;
 	/* extra metadata reseration for relocation */
 	int error;
+	bool readonly;
 	struct list_head list;
 };
 

commit 462045928bda777c86919a396a42991fcf235378
Author: Sage Weil <sage@newdream.net>
Date:   Fri Oct 29 15:41:32 2010 -0400

    Btrfs: add START_SYNC, WAIT_SYNC ioctls
    
    START_SYNC will start a sync/commit, but not wait for it to
    complete.  Any modification started after the ioctl returns is
    guaranteed not to be included in the commit.  If a non-NULL
    pointer is passed, the transaction id will be returned to
    userspace.
    
    WAIT_SYNC will wait for any in-progress commit to complete.  If a
    transaction id is specified, the ioctl will block and then
    return (success) when the specified transaction has committed.
    If it has already committed when we call the ioctl, it returns
    immediately.  If the specified transaction doesn't exist, it
    returns EINVAL.
    
    If no transaction id is specified, WAIT_SYNC will wait for the
    currently committing transaction to finish it's commit to disk.
    If there is no currently committing transaction, it returns
    success.
    
    These ioctls are useful for applications which want to impose an
    ordering on when fs modifications reach disk, but do not want to
    wait for the full (slow) commit process to do so.
    
    Picky callers can take the transid returned by START_SYNC and
    feed it to WAIT_SYNC, and be certain to wait only as long as
    necessary for the transaction _they_ started to reach disk.
    
    Sloppy callers can START_SYNC and WAIT_SYNC without a transid,
    and provided they didn't wait too long between the calls, they
    will get the same result.  However, if a second commit starts
    before they call WAIT_SYNC, they may end up waiting longer for
    it to commit as well.  Even so, a START_SYNC+WAIT_SYNC still
    guarantees that any operation completed before the START_SYNC
    reaches disk.
    
    Signed-off-by: Sage Weil <sage@newdream.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index e1908e6872fe..f104b57ad4ef 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -97,6 +97,7 @@ struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root
 							  int num_blocks);
 struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *r,
 							 int num_blocks);
+int btrfs_wait_for_commit(struct btrfs_root *root, u64 transid);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root);
 int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,

commit bb9c12c945cbd1b0eaa1589546dde772ccabeeba
Author: Sage Weil <sage@newdream.net>
Date:   Fri Oct 29 15:37:34 2010 -0400

    Btrfs: async transaction commit
    
    Add support for an async transaction commit that is ordered such that any
    subsequent operations will join the following transaction, but does not
    wait until the current commit is fully on disk.  This avoids much of the
    latency associated with the btrfs_commit_transaction for callers concerned
    with serialization and not safety.
    
    The wait_for_unblock flag controls whether we wait for the 'middle' portion
    of commit_transaction to complete, which is necessary if the caller expects
    some of the modifications contained in the commit to be available (this is
    the case for subvol/snapshot creation).
    
    Signed-off-by: Sage Weil <sage@newdream.net>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 15f83e1c1ef7..e1908e6872fe 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -108,6 +108,9 @@ int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
+int btrfs_commit_transaction_async(struct btrfs_trans_handle *trans,
+				   struct btrfs_root *root,
+				   int wait_for_unblock);
 int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
 int btrfs_should_end_transaction(struct btrfs_trans_handle *trans,

commit 0af3d00bad38d3bb9912a60928ad0669f17bdb76
Author: Josef Bacik <josef@redhat.com>
Date:   Mon Jun 21 14:48:16 2010 -0400

    Btrfs: create special free space cache inode
    
    In order to save free space cache, we need an inode to hold the data, and we
    need a special item to point at the right inode for the right block group.  So
    first, create a special item that will point to the right inode, and the number
    of extent entries we will have and the number of bitmaps we will have.  We
    truncate and pre-allocate space everytime to make sure it's uptodate.
    
    This feature will be turned on as soon as you mount with -o space_cache, however
    it is safe to boot into old kernels, they will just generate the cache the old
    fashion way.  When you boot back into a newer kernel we will notice that we
    modified and not the cache and automatically discard the cache.
    
    Signed-off-by: Josef Bacik <josef@redhat.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index e104986d0bfd..15f83e1c1ef7 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -87,10 +87,14 @@ static inline void btrfs_set_inode_last_trans(struct btrfs_trans_handle *trans,
 
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
+int btrfs_end_transaction_nolock(struct btrfs_trans_handle *trans,
+				 struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   int num_items);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root,
 						  int num_blocks);
+struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root,
+							  int num_blocks);
 struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *r,
 							 int num_blocks);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,

commit 8929ecfa50f266163832eeacfbc3642ed5eb83b6
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:49:58 2010 -0400

    Btrfs: Introduce global metadata reservation
    
    Reserve metadata space for extent tree, checksum tree and root tree
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 14b3841b75d5..e104986d0bfd 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -106,6 +106,8 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
 int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
+int btrfs_should_end_transaction(struct btrfs_trans_handle *trans,
+				 struct btrfs_root *root);
 void btrfs_throttle(struct btrfs_root *root);
 int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
@@ -115,5 +117,6 @@ int btrfs_write_marked_extents(struct btrfs_root *root,
 				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_wait_marked_extents(struct btrfs_root *root,
 				struct extent_io_tree *dirty_pages, int mark);
+int btrfs_transaction_blocked(struct btrfs_fs_info *info);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
 #endif

commit a22285a6a32390195235171b89d157ed1a1fe932
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:48:46 2010 -0400

    Btrfs: Integrate metadata reservation with start_transaction
    
    Besides simplify the code, this change makes sure all metadata
    reservation for normal metadata operations are released after
    committing transaction.
    
    Changes since V1:
    
    Add code that check if unlink and rmdir will free space.
    
    Add ENOSPC handling for clone ioctl.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 56e728d70e39..14b3841b75d5 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -57,8 +57,11 @@ struct btrfs_trans_handle {
 struct btrfs_pending_snapshot {
 	struct dentry *dentry;
 	struct btrfs_root *root;
-	char *name;
-	struct btrfs_key root_key;
+	struct btrfs_root *snap;
+	/* block reservation for the operation */
+	struct btrfs_block_rsv block_rsv;
+	/* extra metadata reseration for relocation */
+	int error;
 	struct list_head list;
 };
 
@@ -85,11 +88,11 @@ static inline void btrfs_set_inode_last_trans(struct btrfs_trans_handle *trans,
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
-						   int num_blocks);
+						   int num_items);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root,
-						   int num_blocks);
+						  int num_blocks);
 struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *r,
-						   int num_blocks);
+							 int num_blocks);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root);
 int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,

commit f0486c68e4bd9a06a5904d3eeb3a0d73a83befb8
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Sun May 16 10:46:25 2010 -0400

    Btrfs: Introduce contexts for metadata reservation
    
    Introducing metadata reseravtion contexts has two major advantages.
    First, it makes metadata reseravtion more traceable. Second, it can
    reclaim freed space and re-add them to the itself after transaction
    committed.
    
    Besides add btrfs_block_rsv structure and related helper functions,
    This patch contains following changes:
    
    Move code that decides if freed tree block should be pinned into
    btrfs_free_tree_block().
    
    Make space accounting more accurate, mainly for handling read only
    block groups.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 93c7ccb33118..56e728d70e39 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -45,13 +45,13 @@ struct btrfs_transaction {
 
 struct btrfs_trans_handle {
 	u64 transid;
+	u64 block_group;
+	u64 bytes_reserved;
 	unsigned long blocks_reserved;
 	unsigned long blocks_used;
-	struct btrfs_transaction *transaction;
-	u64 block_group;
-	u64 alloc_exclude_start;
-	u64 alloc_exclude_nr;
 	unsigned long delayed_ref_updates;
+	struct btrfs_transaction *transaction;
+	struct btrfs_block_rsv *block_rsv;
 };
 
 struct btrfs_pending_snapshot {

commit 8cef4e160d74920ad1725f58c89fd75ec4c4ac38
Author: Yan, Zheng <zheng.yan@oracle.com>
Date:   Thu Nov 12 09:33:26 2009 +0000

    Btrfs: Avoid superfluous tree-log writeout
    
    We allow two log transactions at a time, but use same flag
    to mark dirty tree-log btree blocks. So we may flush dirty
    blocks belonging to newer log transaction when committing a
    log transaction. This patch fixes the issue by using two
    flags to mark dirty tree-log btree blocks.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index d4e3e7a6938c..93c7ccb33118 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -107,10 +107,10 @@ void btrfs_throttle(struct btrfs_root *root);
 int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_write_and_wait_marked_extents(struct btrfs_root *root,
-					struct extent_io_tree *dirty_pages);
+				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_write_marked_extents(struct btrfs_root *root,
-					struct extent_io_tree *dirty_pages);
+				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_wait_marked_extents(struct btrfs_root *root,
-					struct extent_io_tree *dirty_pages);
+				struct extent_io_tree *dirty_pages, int mark);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
 #endif

commit 690587d109ffe19d6743e4cc80c18b0906b7f9ff
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Oct 13 13:29:19 2009 -0400

    Btrfs: streamline tree-log btree block writeout
    
    Syncing the tree log is a 3 phase operation.
    
    1) write and wait for all the tree log blocks for a given root.
    
    2) write and wait for all the tree log blocks for the
    tree of tree log roots.
    
    3) write and wait for the super blocks (barriers here)
    
    This isn't as efficient as it could be because there is
    no requirement to wait for the blocks from step one to hit the disk
    before we start writing the blocks from step two.  This commit
    changes the sequence so that we don't start waiting until
    all the tree blocks from both steps one and two have been sent
    to disk.
    
    We do this by breaking up btrfs_write_wait_marked_extents into
    two functions, which is trivial because it was already broken
    up into two parts.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index f68cbbe61e56..d4e3e7a6938c 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -108,5 +108,9 @@ int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_write_and_wait_marked_extents(struct btrfs_root *root,
 					struct extent_io_tree *dirty_pages);
+int btrfs_write_marked_extents(struct btrfs_root *root,
+					struct extent_io_tree *dirty_pages);
+int btrfs_wait_marked_extents(struct btrfs_root *root,
+					struct extent_io_tree *dirty_pages);
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
 #endif

commit 257c62e1bce03e5b9f3f069fd52ad73a56de71fd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Oct 13 13:21:08 2009 -0400

    Btrfs: avoid tree log commit when there are no changes
    
    rpm has a habit of running fdatasync when the file hasn't
    changed.  We already detect if a file hasn't been changed
    in the current transaction but it might have been sent to
    the tree-log in this transaction and not changed since
    the last call to fsync.
    
    In this case, we want to avoid a tree log sync, which includes
    a number of synchronous writes and barriers.  This commit
    extends the existing tracking of the last transaction to change
    a file to also track the last sub-transaction.
    
    The end result is that rpm -ivh and -Uvh are roughly twice as fast,
    and on par with ext3.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 663c67404918..f68cbbe61e56 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -79,6 +79,7 @@ static inline void btrfs_set_inode_last_trans(struct btrfs_trans_handle *trans,
 					      struct inode *inode)
 {
 	BTRFS_I(inode)->last_trans = trans->transaction->transid;
+	BTRFS_I(inode)->last_sub_trans = BTRFS_I(inode)->root->log_transid;
 }
 
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,

commit f36f3042eae238bdaefe7c79310afe573bfc3622
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 30 10:04:48 2009 -0400

    Btrfs: be more polite in the async caching threads
    
    The semaphore used by the async caching threads can prevent a
    transaction commit, which can make the FS appear to stall.  This
    releases the semaphore more often when a transaction commit is
    in progress.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 961c3ee5a2e1..663c67404918 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -107,4 +107,5 @@ int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
 int btrfs_write_and_wait_marked_extents(struct btrfs_root *root,
 					struct extent_io_tree *dirty_pages);
+int btrfs_transaction_in_commit(struct btrfs_fs_info *info);
 #endif

commit 5d4f98a28c7d334091c1b7744f48a1acdd2a4ae0
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Jun 10 10:45:14 2009 -0400

    Btrfs: Mixed back reference  (FORWARD ROLLING FORMAT CHANGE)
    
    This commit introduces a new kind of back reference for btrfs metadata.
    Once a filesystem has been mounted with this commit, IT WILL NO LONGER
    BE MOUNTABLE BY OLDER KERNELS.
    
    When a tree block in subvolume tree is cow'd, the reference counts of all
    extents it points to are increased by one.  At transaction commit time,
    the old root of the subvolume is recorded in a "dead root" data structure,
    and the btree it points to is later walked, dropping reference counts
    and freeing any blocks where the reference count goes to 0.
    
    The increments done during cow and decrements done after commit cancel out,
    and the walk is a very expensive way to go about freeing the blocks that
    are no longer referenced by the new btree root.  This commit reduces the
    transaction overhead by avoiding the need for dead root records.
    
    When a non-shared tree block is cow'd, we free the old block at once, and the
    new block inherits old block's references. When a tree block with reference
    count > 1 is cow'd, we increase the reference counts of all extents
    the new block points to by one, and decrease the old block's reference count by
    one.
    
    This dead tree avoidance code removes the need to modify the reference
    counts of lower level extents when a non-shared tree block is cow'd.
    But we still need to update back ref for all pointers in the block.
    This is because the location of the block is recorded in the back ref
    item.
    
    We can solve this by introducing a new type of back ref. The new
    back ref provides information about pointer's key, level and in which
    tree the pointer lives. This information allow us to find the pointer
    by searching the tree. The shortcoming of the new back ref is that it
    only works for pointers in tree blocks referenced by their owner trees.
    
    This is mostly a problem for snapshots, where resolving one of these
    fuzzy back references would be O(number_of_snapshots) and quite slow.
    The solution used here is to use the fuzzy back references in the common
    case where a given tree block is only referenced by one root,
    and use the full back references when multiple roots have a reference
    on a given block.
    
    This commit adds per subvolume red-black tree to keep trace of cached
    inodes. The red-black tree helps the balancing code to find cached
    inodes whose inode numbers within a given range.
    
    This commit improves the balancing code by introducing several data
    structures to keep the state of balancing. The most important one
    is the back ref cache. It caches how the upper level tree blocks are
    referenced. This greatly reduce the overhead of checking back ref.
    
    The improved balancing code scales significantly better with a large
    number of snapshots.
    
    This is a very large commit and was written in a number of
    pieces.  But, they depend heavily on the disk format change and were
    squashed together to make sure git bisect didn't end up in a
    bad state wrt space balancing or the format change.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 94f5bde2b58d..961c3ee5a2e1 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -62,12 +62,6 @@ struct btrfs_pending_snapshot {
 	struct list_head list;
 };
 
-struct btrfs_dirty_root {
-	struct list_head list;
-	struct btrfs_root *root;
-	struct btrfs_root *latest_root;
-};
-
 static inline void btrfs_set_trans_block_group(struct btrfs_trans_handle *trans,
 					       struct inode *inode)
 {
@@ -100,7 +94,8 @@ int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
 
-int btrfs_add_dead_root(struct btrfs_root *root, struct btrfs_root *latest);
+int btrfs_add_dead_root(struct btrfs_root *root);
+int btrfs_drop_dead_root(struct btrfs_root *root);
 int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
@@ -108,7 +103,8 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
 void btrfs_throttle(struct btrfs_root *root);
-int btrfs_record_root_in_trans(struct btrfs_root *root);
+int btrfs_record_root_in_trans(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root);
 int btrfs_write_and_wait_marked_extents(struct btrfs_root *root,
 					struct extent_io_tree *dirty_pages);
 #endif

commit b7ec40d7845bffca8bb3af2ea3f192d6257bbe21
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 12 20:12:45 2009 -0400

    Btrfs: reduce stalls during transaction commit
    
    To avoid deadlocks and reduce latencies during some critical operations, some
    transaction writers are allowed to jump into the running transaction and make
    it run a little longer, while others sit around and wait for the commit to
    finish.
    
    This is a bit unfair, especially when the callers that jump in do a bunch
    of IO that makes all the others procs on the box wait.  This commit
    reduces the stalls this produces by pre-reading file extent pointers
    during btrfs_finish_ordered_io before the transaction is joined.
    
    It also tunes the drop_snapshot code to politely wait for transactions
    that have started writing out their delayed refs to finish.  This avoids
    new delayed refs being flooded into the queue while we're trying to
    close off the transaction.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 94876709217f..94f5bde2b58d 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -23,7 +23,12 @@
 
 struct btrfs_transaction {
 	u64 transid;
+	/*
+	 * total writers in this transaction, it must be zero before the
+	 * transaction can end
+	 */
 	unsigned long num_writers;
+
 	unsigned long num_joined;
 	int in_commit;
 	int use_count;

commit 56bec294dea971335d4466b30f2d959f28f6e36d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 13 10:10:06 2009 -0400

    Btrfs: do extent allocation and reference count updates in the background
    
    The extent allocation tree maintains a reference count and full
    back reference information for every extent allocated in the
    filesystem.  For subvolume and snapshot trees, every time
    a block goes through COW, the new copy of the block adds a reference
    on every block it points to.
    
    If a btree node points to 150 leaves, then the COW code needs to go
    and add backrefs on 150 different extents, which might be spread all
    over the extent allocation tree.
    
    These updates currently happen during btrfs_cow_block, and most COWs
    happen during btrfs_search_slot.  btrfs_search_slot has locks held
    on both the parent and the node we are COWing, and so we really want
    to avoid IO during the COW if we can.
    
    This commit adds an rbtree of pending reference count updates and extent
    allocations.  The tree is ordered by byte number of the extent and byte number
    of the parent for the back reference.  The tree allows us to:
    
    1) Modify back references in something close to disk order, reducing seeks
    2) Significantly reduce the number of modifications made as block pointers
    are balanced around
    3) Do all of the extent insertion and back reference modifications outside
    of the performance critical btrfs_search_slot code.
    
    #3 has the added benefit of greatly reducing the btrfs stack footprint.
    The extent allocation tree modifications are done without the deep
    (and somewhat recursive) call chains used in the past.
    
    These delayed back reference updates must be done before the transaction
    commits, and so the rbtree is tied to the transaction.  Throttling is
    implemented to help keep the queue of backrefs at a reasonable size.
    
    Since there was a similar mechanism in place for the extent tree
    extents, that is removed and replaced by the delayed reference tree.
    
    Yan Zheng <yan.zheng@oracle.com> helped review and fixup this code.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index ea292117f882..94876709217f 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -19,6 +19,7 @@
 #ifndef __BTRFS_TRANSACTION__
 #define __BTRFS_TRANSACTION__
 #include "btrfs_inode.h"
+#include "delayed-ref.h"
 
 struct btrfs_transaction {
 	u64 transid;
@@ -34,6 +35,7 @@ struct btrfs_transaction {
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 	struct list_head pending_snapshots;
+	struct btrfs_delayed_ref_root delayed_refs;
 };
 
 struct btrfs_trans_handle {
@@ -44,6 +46,7 @@ struct btrfs_trans_handle {
 	u64 block_group;
 	u64 alloc_exclude_start;
 	u64 alloc_exclude_nr;
+	unsigned long delayed_ref_updates;
 };
 
 struct btrfs_pending_snapshot {

commit d397712bcc6a759a560fd247e6053ecae091f958
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Jan 5 21:25:51 2009 -0500

    Btrfs: Fix checkpatch.pl warnings
    
    There were many, most are fixed now.  struct-funcs.c generates some warnings
    but these are bogus.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index ffe7f639732b..ea292117f882 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -66,9 +66,9 @@ static inline void btrfs_set_trans_block_group(struct btrfs_trans_handle *trans,
 	trans->block_group = BTRFS_I(inode)->block_group;
 }
 
-static inline void btrfs_update_inode_block_group(struct
-						  btrfs_trans_handle *trans,
-						  struct inode *inode)
+static inline void btrfs_update_inode_block_group(
+					  struct btrfs_trans_handle *trans,
+					  struct inode *inode)
 {
 	BTRFS_I(inode)->block_group = trans->block_group;
 }

commit d2fb3437e4d8d12c73c587615ad187d5288547ec
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Thu Dec 11 16:30:39 2008 -0500

    Btrfs: fix leaking block group on balance
    
    The block group structs are referenced in many different
    places, and it's not safe to free while balancing.  So, those block
    group structs were simply leaked instead.
    
    This patch replaces the block group pointer in the inode with the starting byte
    offset of the block group and adds reference counting to the block group
    struct.
    
    Signed-off-by: Yan Zheng <zheng.yan@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 202c8be6c05d..ffe7f639732b 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -41,7 +41,7 @@ struct btrfs_trans_handle {
 	unsigned long blocks_reserved;
 	unsigned long blocks_used;
 	struct btrfs_transaction *transaction;
-	struct btrfs_block_group_cache *block_group;
+	u64 block_group;
 	u64 alloc_exclude_start;
 	u64 alloc_exclude_nr;
 };

commit 3de4586c5278a28107030c336956381f69ff7a9d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Nov 17 21:02:50 2008 -0500

    Btrfs: Allow subvolumes and snapshots anywhere in the directory tree
    
    Before, all snapshots and subvolumes lived in a single flat directory.  This
    was awkward and confusing because the single flat directory was only writable
    with the ioctls.
    
    This commit changes the ioctls to create subvols and snapshots at any
    point in the directory tree.  This requires making separate ioctls for
    snapshot and subvol creation instead of a combining them into one.
    
    The subvol ioctl does:
    
    btrfsctl -S subvol_name parent_dir
    
    After the ioctl is done subvol_name lives inside parent_dir.
    
    The snapshot ioctl does:
    
    btrfsctl -s path_for_snapshot root_to_snapshot
    
    path_for_snapshot can be an absolute or relative path.  btrfsctl breaks it up
    into directory and basename components.
    
    root_to_snapshot can be any file or directory in the FS.  The snapshot
    is taken of the entire root where that file lives.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index eef2cb7d7e78..202c8be6c05d 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -47,8 +47,10 @@ struct btrfs_trans_handle {
 };
 
 struct btrfs_pending_snapshot {
+	struct dentry *dentry;
 	struct btrfs_root *root;
 	char *name;
+	struct btrfs_key root_key;
 	struct list_head list;
 };
 

commit d0c803c4049c5ca322d4795d8b74f28768603e0e
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Sep 11 16:17:57 2008 -0400

    Btrfs: Record dirty pages tree-log pages in an extent_io tree
    
    This is the same way the transaction code makes sure that all the
    other tree blocks are safely on disk.  There's an extent_io tree
    for each root, and any blocks allocated to the tree logs are
    recorded in that tree.
    
    At tree-log sync, the extent_io tree is walked to flush down the
    dirty pages and wait for them.
    
    The main benefit is less time spent walking the tree log and skipping
    clean pages, and getting sequential IO down to the drive.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index cc63650d60d6..eef2cb7d7e78 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -99,4 +99,6 @@ int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
 void btrfs_throttle(struct btrfs_root *root);
 int btrfs_record_root_in_trans(struct btrfs_root *root);
+int btrfs_write_and_wait_marked_extents(struct btrfs_root *root,
+					struct extent_io_tree *dirty_pages);
 #endif

commit e02119d5a7b4396c5a872582fddc8bd6d305a70a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Sep 5 16:13:11 2008 -0400

    Btrfs: Add a write ahead tree log to optimize synchronous operations
    
    File syncs and directory syncs are optimized by copying their
    items into a special (copy-on-write) log tree.  There is one log tree per
    subvolume and the btrfs super block points to a tree of log tree roots.
    
    After a crash, items are copied out of the log tree and back into the
    subvolume.  See tree-log.c for all the details.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 598baa312417..cc63650d60d6 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -98,4 +98,5 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
 void btrfs_throttle(struct btrfs_root *root);
+int btrfs_record_root_in_trans(struct btrfs_root *root);
 #endif

commit b48652c101cce7a54379a49cc0cf854cec2c94e2
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Mon Aug 4 23:23:47 2008 -0400

    Btrfs: Various small fixes.
    
    This trivial patch contains two locking fixes and a off by one fix.
    
    ---
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 2c73caeebb2c..598baa312417 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -90,8 +90,7 @@ int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
 
-int btrfs_add_dead_root(struct btrfs_root *root, struct btrfs_root *latest,
-			struct list_head *dead_list);
+int btrfs_add_dead_root(struct btrfs_root *root, struct btrfs_root *latest);
 int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,

commit 9ca9ee09c176a814189063c8b88f75c8f8e4ad19
Author: Sage Weil <sage@newdream.net>
Date:   Mon Aug 4 10:41:27 2008 -0400

    Btrfs: fix ioctl-initiated transactions vs wait_current_trans()
    
    Commit 597:466b27332893 (btrfs_start_transaction: wait for commits in
    progress) breaks the transaction start/stop ioctls by making
    btrfs_start_transaction conditionally wait for the next transaction to
    start.  If an application artificially is holding a transaction open,
    things deadlock.
    
    This workaround maintains a count of open ioctl-initiated transactions in
    fs_info, and avoids wait_current_trans() if any are currently open (in
    start_transaction() and btrfs_throttle()).  The start transaction ioctl
    uses a new btrfs_start_ioctl_transaction() that _does_ call
    wait_current_trans(), effectively pushing the join/wait decision to the
    outer ioctl-initiated transaction.
    
    This more or less neuters btrfs_throttle() when ioctl-initiated
    transactions are in use, but that seems like a pretty fundamental
    consequence of wrapping lots of write()'s in a transaction.  Btrfs has no
    way to tell if the application considers a given operation as part of it's
    transaction.
    
    Obviously, if the transaction start/stop ioctls aren't being used, there
    is no effect on current behavior.
    
    Signed-off-by: Sage Weil <sage@newdream.net>
    ---
     ctree.h       |    1 +
     ioctl.c       |   12 +++++++++++-
     transaction.c |   18 +++++++++++++-----
     transaction.h |    2 ++
     4 files changed, 27 insertions(+), 6 deletions(-)
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index f5adb23151fb..2c73caeebb2c 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -83,6 +83,8 @@ struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   int num_blocks);
 struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root,
 						   int num_blocks);
+struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *r,
+						   int num_blocks);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root);
 int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,

commit f321e4910398cf7922265d269fb17fd26f312571
Author: Yan Zheng <zheng.yan@oracle.com>
Date:   Wed Jul 30 09:26:11 2008 -0400

    Btrfs: Update and fix mount -o nodatacow
    
    To check whether a given file extent is referenced by multiple snapshots, the
    checker walks down the fs tree through dead root and checks all tree blocks in
    the path.
    
    We can easily detect whether a given tree block is directly referenced by other
    snapshot. We can also detect any indirect reference from other snapshot by
    checking reference's generation. The checker can always detect multiple
    references, but can't reliably detect cases of single reference. So btrfs may
    do file data cow even there is only one reference.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index df2ca2aad1c0..f5adb23151fb 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -52,6 +52,11 @@ struct btrfs_pending_snapshot {
 	struct list_head list;
 };
 
+struct btrfs_dirty_root {
+	struct list_head list;
+	struct btrfs_root *root;
+	struct btrfs_root *latest_root;
+};
 
 static inline void btrfs_set_trans_block_group(struct btrfs_trans_handle *trans,
 					       struct inode *inode)

commit ab78c84de1ce4db1b2a2cef361625ad80abbab3f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jul 29 16:15:18 2008 -0400

    Btrfs: Throttle operations if the reference cache gets too large
    
    A large reference cache is directly related to a lot of work pending
    for the cleaner thread.  This throttles back new operations based on
    the size of the reference cache so the cleaner thread will be able to keep
    up.
    
    Overall, this actually makes the FS faster because the cleaner thread will
    be more likely to find things in cache.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 11fbdeceb26c..df2ca2aad1c0 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -91,4 +91,5 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
 int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
+void btrfs_throttle(struct btrfs_root *root);
 #endif

commit f9295749388f82c8d2f485e99c72cd7c7876a99b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:54:14 2008 -0400

    btrfs_start_transaction: wait for commits in progress to finish
    
    btrfs_commit_transaction has to loop waiting for any writers in the
    transaction to finish before it can proceed.  btrfs_start_transaction
    should be polite and not join a transaction that is in the process
    of being finished off.
    
    There are a few places that can't wait, basically the ones doing IO that
    might be needed to finish the transaction.  For them, btrfs_join_transaction
    is added.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 910350cd4cf0..11fbdeceb26c 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -27,6 +27,7 @@ struct btrfs_transaction {
 	int in_commit;
 	int use_count;
 	int commit_done;
+	int blocked;
 	struct list_head list;
 	struct extent_io_tree dirty_pages;
 	unsigned long start_time;
@@ -75,6 +76,8 @@ int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
 						   int num_blocks);
+struct btrfs_trans_handle *btrfs_join_transaction(struct btrfs_root *root,
+						   int num_blocks);
 int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root);
 int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,

commit e6dcd2dc9c489108648e2ed543315dd134d50a9a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jul 17 12:53:50 2008 -0400

    Btrfs: New data=ordered implementation
    
    The old data=ordered code would force commit to wait until
    all the data extents from the transaction were fully on disk.  This
    introduced large latencies into the commit and stalled new writers
    in the transaction for a long time.
    
    The new code changes the way data allocations and extents work:
    
    * When delayed allocation is filled, data extents are reserved, and
      the extent bit EXTENT_ORDERED is set on the entire range of the extent.
      A struct btrfs_ordered_extent is allocated an inserted into a per-inode
      rbtree to track the pending extents.
    
    * As each page is written EXTENT_ORDERED is cleared on the bytes corresponding
      to that page.
    
    * When all of the bytes corresponding to a single struct btrfs_ordered_extent
      are written, The previously reserved extent is inserted into the FS
      btree and into the extent allocation trees.  The checksums for the file
      data are also updated.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 9ccd5a5b170f..910350cd4cf0 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -19,7 +19,6 @@
 #ifndef __BTRFS_TRANSACTION__
 #define __BTRFS_TRANSACTION__
 #include "btrfs_inode.h"
-#include "ordered-data.h"
 
 struct btrfs_transaction {
 	u64 transid;
@@ -31,7 +30,6 @@ struct btrfs_transaction {
 	struct list_head list;
 	struct extent_io_tree dirty_pages;
 	unsigned long start_time;
-	struct btrfs_ordered_inode_tree ordered_inode_tree;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 	struct list_head pending_snapshots;
@@ -88,8 +86,6 @@ int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
-int btrfs_write_ordered_inodes(struct btrfs_trans_handle *trans,
-				struct btrfs_root *root);
 int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
 				   struct btrfs_root *root);
 #endif

commit 3f157a2fd2ad731e1ed9964fecdc5f459f04a4a4
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Online btree defragmentation fixes
    
    The btree defragger wasn't making forward progress because the new key wasn't
    being saved by the btrfs_search_forward function.
    
    This also disables the automatic btree defrag, it wasn't scaling well to
    huge filesystems.  The auto-defrag needs to be done differently.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index e1e5a06b65f4..9ccd5a5b170f 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -84,7 +84,6 @@ int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,
 
 int btrfs_add_dead_root(struct btrfs_root *root, struct btrfs_root *latest,
 			struct list_head *dead_list);
-int btrfs_defrag_dirty_roots(struct btrfs_fs_info *info);
 int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,

commit a74a4b97b61beede185b4b3ad359d7d378b0d312
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Btrfs: Replace the transaction work queue with kthreads
    
    This creates one kthread for commits and one kthread for
    deleting old snapshots.  All the work queues are removed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 52559b51b181..e1e5a06b65f4 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -82,16 +82,6 @@ int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
 
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
-void btrfs_transaction_cleaner(void *p);
-#else
-void btrfs_transaction_cleaner(struct work_struct *work);
-#endif
-
-void btrfs_transaction_flush_work(struct btrfs_root *root);
-void btrfs_transaction_queue_work(struct btrfs_root *root, int delay);
-void btrfs_init_transaction_sys(void);
-void btrfs_exit_transaction_sys(void);
 int btrfs_add_dead_root(struct btrfs_root *root, struct btrfs_root *latest,
 			struct list_head *dead_list);
 int btrfs_defrag_dirty_roots(struct btrfs_fs_info *info);

commit 89ce8a63d0c761fbb02089850605360f389477d8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Jun 25 16:01:31 2008 -0400

    Add btrfs_end_transaction_throttle to force writers to wait for pending commits
    
    The existing throttle mechanism was often not sufficient to prevent
    new writers from coming in and making a given transaction run forever.
    This adds an explicit wait at the end of most operations so they will
    allow the current transaction to close.
    
    There is no wait inside file_write, inode updates, or cow filling, all which
    have different deadlock possibilities.
    
    This is a temporary measure until better asynchronous commit support is
    added.  This code leads to stalls as it waits for data=ordered
    writeback, and it really needs to be fixed.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index c3172ddb3321..52559b51b181 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -101,4 +101,6 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
 int btrfs_write_ordered_inodes(struct btrfs_trans_handle *trans,
 				struct btrfs_root *root);
+int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,
+				   struct btrfs_root *root);
 #endif

commit d1310b2e0cd98eb1348553e69b73827b436dca7b
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Jan 24 16:13:08 2008 -0500

    Btrfs: Split the extent_map code into two parts
    
    There is now extent_map for mapping offsets in the file to disk and
    extent_io for state tracking, IO submission and extent_bufers.
    
    The new extent_map code shifts from [start,end] pairs to [start,len], and
    pushes the locking out into the caller.  This allows a few performance
    optimizations and is easier to use.
    
    A number of extent_map usage bugs were fixed, mostly with failing
    to remove extent_map entries when changing the file.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index fd52e9b23922..c3172ddb3321 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -29,7 +29,7 @@ struct btrfs_transaction {
 	int use_count;
 	int commit_done;
 	struct list_head list;
-	struct extent_map_tree dirty_pages;
+	struct extent_io_tree dirty_pages;
 	unsigned long start_time;
 	struct btrfs_ordered_inode_tree ordered_inode_tree;
 	wait_queue_head_t writer_wait;

commit 3063d29f2a4d4a4e9fa1ec77c124514f287c6da7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 8 15:46:30 2008 -0500

    Btrfs: Move snapshot creation to commit time
    
    It is very difficult to create a consistent snapshot of the btree when
    other writers may update the btree before the commit is done.
    
    This changes the snapshot creation to happen during the commit, while
    no other updates are possible.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index c157ddbe9d1e..fd52e9b23922 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -34,6 +34,7 @@ struct btrfs_transaction {
 	struct btrfs_ordered_inode_tree ordered_inode_tree;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
+	struct list_head pending_snapshots;
 };
 
 struct btrfs_trans_handle {
@@ -46,6 +47,12 @@ struct btrfs_trans_handle {
 	u64 alloc_exclude_nr;
 };
 
+struct btrfs_pending_snapshot {
+	struct btrfs_root *root;
+	char *name;
+	struct list_head list;
+};
+
 
 static inline void btrfs_set_trans_block_group(struct btrfs_trans_handle *trans,
 					       struct inode *inode)

commit dc17ff8f11d129db9e83ab7244769e4eae05e14d
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jan 8 15:46:30 2008 -0500

    Btrfs: Add data=ordered support
    
    This forces file data extents down the disk along with the metadata that
    references them.  The current implementation is fairly simple, and just
    writes out all of the dirty pages in an inode before the commit.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index eef840bca91e..c157ddbe9d1e 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -16,9 +16,10 @@
  * Boston, MA 021110-1307, USA.
  */
 
-#ifndef __TRANSACTION__
-#define __TRANSACTION__
+#ifndef __BTRFS_TRANSACTION__
+#define __BTRFS_TRANSACTION__
 #include "btrfs_inode.h"
+#include "ordered-data.h"
 
 struct btrfs_transaction {
 	u64 transid;
@@ -30,6 +31,7 @@ struct btrfs_transaction {
 	struct list_head list;
 	struct extent_map_tree dirty_pages;
 	unsigned long start_time;
+	struct btrfs_ordered_inode_tree ordered_inode_tree;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 };
@@ -90,4 +92,6 @@ int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);
 int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 			     struct btrfs_root *root);
+int btrfs_write_ordered_inodes(struct btrfs_trans_handle *trans,
+				struct btrfs_root *root);
 #endif

commit 6da6abae027e2dbc59bca5f4168b0760f25068c7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Dec 18 16:15:09 2007 -0500

    Btrfs: Back port to 2.6.18-el kernels
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index ae39fcfc169a..eef840bca91e 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -73,7 +73,12 @@ int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+void btrfs_transaction_cleaner(void *p);
+#else
 void btrfs_transaction_cleaner(struct work_struct *work);
+#endif
+
 void btrfs_transaction_flush_work(struct btrfs_root *root);
 void btrfs_transaction_queue_work(struct btrfs_root *root, int delay);
 void btrfs_init_transaction_sys(void);

commit 5f39d397dfbe140a14edecd4e73c34ce23c4f9ee
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Oct 15 16:14:19 2007 -0400

    Btrfs: Create extent_buffer interface for large blocksizes
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 4bc328cbb24c..ae39fcfc169a 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -28,7 +28,7 @@ struct btrfs_transaction {
 	int use_count;
 	int commit_done;
 	struct list_head list;
-	struct radix_tree_root dirty_pages;
+	struct extent_map_tree dirty_pages;
 	unsigned long start_time;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
@@ -83,5 +83,6 @@ int btrfs_add_dead_root(struct btrfs_root *root, struct btrfs_root *latest,
 int btrfs_defrag_dirty_roots(struct btrfs_fs_info *info);
 int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);
-
+int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
+			     struct btrfs_root *root);
 #endif

commit 5ce14bbcdd1b5d9233d26a1e89faf3a26c820c58
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Sep 11 11:15:39 2007 -0400

    Btrfs: Find and remove dead roots the first time a root is loaded.
    
    Dead roots are trees left over after a crash, and they were either in the
    process of being removed or were waiting to be removed when the box crashed.
    Before, a search of the entire tree of root pointers was done on mount
    looking for dead roots.  Now, the search is done the first time we load
    a root.
    
    This makes mount faster when there are a large number of snapshots, and it
    enables the block accounting code to properly update the block counts on
    the latest root as old versions of the root are reaped after a crash.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index e451783a1a4d..4bc328cbb24c 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -78,7 +78,8 @@ void btrfs_transaction_flush_work(struct btrfs_root *root);
 void btrfs_transaction_queue_work(struct btrfs_root *root, int delay);
 void btrfs_init_transaction_sys(void);
 void btrfs_exit_transaction_sys(void);
-int btrfs_add_dead_root(struct btrfs_root *root, struct list_head *dead_list);
+int btrfs_add_dead_root(struct btrfs_root *root, struct btrfs_root *latest,
+			struct list_head *dead_list);
 int btrfs_defrag_dirty_roots(struct btrfs_fs_info *info);
 int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
 int btrfs_clean_old_snapshots(struct btrfs_root *root);

commit 15ee9bc7ed171248d1405df5854da5fa91bfdc39
Author: Josef Bacik <jwhiter@redhat.com>
Date:   Fri Aug 10 16:22:09 2007 -0400

    Btrfs: delay commits during fsync to allow more writers
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index d5f491d3757e..e451783a1a4d 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -23,6 +23,7 @@
 struct btrfs_transaction {
 	u64 transid;
 	unsigned long num_writers;
+	unsigned long num_joined;
 	int in_commit;
 	int use_count;
 	int commit_done;
@@ -57,6 +58,12 @@ static inline void btrfs_update_inode_block_group(struct
 	BTRFS_I(inode)->block_group = trans->block_group;
 }
 
+static inline void btrfs_set_inode_last_trans(struct btrfs_trans_handle *trans,
+					      struct inode *inode)
+{
+	BTRFS_I(inode)->last_trans = trans->transaction->transid;
+}
+
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,

commit e9d0b13b5bbb58c9b840e407a8d181442f799966
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Aug 10 14:06:19 2007 -0400

    Btrfs: Btree defrag on the extent-mapping tree as well
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 65a395eeca91..d5f491d3757e 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -73,5 +73,7 @@ void btrfs_init_transaction_sys(void);
 void btrfs_exit_transaction_sys(void);
 int btrfs_add_dead_root(struct btrfs_root *root, struct list_head *dead_list);
 int btrfs_defrag_dirty_roots(struct btrfs_fs_info *info);
+int btrfs_defrag_root(struct btrfs_root *root, int cacheonly);
+int btrfs_clean_old_snapshots(struct btrfs_root *root);
 
 #endif

commit 26b8003f10569a9155b7539ef5a7379ee0c6b050
Author: Chris Mason <chris.mason@oracle.com>
Date:   Wed Aug 8 20:17:12 2007 -0400

    Btrfs: Replace extent tree preallocation code with some bit radix magic.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 8b2714e65562..65a395eeca91 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -39,6 +39,8 @@ struct btrfs_trans_handle {
 	unsigned long blocks_used;
 	struct btrfs_transaction *transaction;
 	struct btrfs_block_group_cache *block_group;
+	u64 alloc_exclude_start;
+	u64 alloc_exclude_nr;
 };
 
 

commit 6702ed490ca0bb44e17131818a5a18b773957c5a
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Aug 7 16:15:09 2007 -0400

    Btrfs: Add run time btree defrag, and an ioctl to force btree defrag
    
    This adds two types of btree defrag, a run time form that tries to
    defrag recently allocated blocks in the btree when they are still in ram,
    and an ioctl that forces defrag of all btree blocks.
    
    File data blocks are not defragged yet, but this can make a huge difference
    in sequential btree reads.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index ebf44f3e1118..8b2714e65562 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -70,5 +70,6 @@ void btrfs_transaction_queue_work(struct btrfs_root *root, int delay);
 void btrfs_init_transaction_sys(void);
 void btrfs_exit_transaction_sys(void);
 int btrfs_add_dead_root(struct btrfs_root *root, struct list_head *dead_list);
+int btrfs_defrag_dirty_roots(struct btrfs_fs_info *info);
 
 #endif

commit 5eda7b5e9b0bed864dd18284c7df9b3c8207dad7
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 22 14:16:25 2007 -0400

    Btrfs: Add the ability to find and remove dead roots after a crash.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 5fb1d322aa10..ebf44f3e1118 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -69,5 +69,6 @@ void btrfs_transaction_flush_work(struct btrfs_root *root);
 void btrfs_transaction_queue_work(struct btrfs_root *root, int delay);
 void btrfs_init_transaction_sys(void);
 void btrfs_exit_transaction_sys(void);
+int btrfs_add_dead_root(struct btrfs_root *root, struct list_head *dead_list);
 
 #endif

commit 6cbd55707802b98843f953d1ae6d8f5bcd9a76c0
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Jun 12 09:07:21 2007 -0400

    Btrfs: add GPLv2
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index f25b4900db45..5fb1d322aa10 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -1,3 +1,21 @@
+/*
+ * Copyright (C) 2007 Oracle.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public
+ * License v2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public
+ * License along with this program; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 021110-1307, USA.
+ */
+
 #ifndef __TRANSACTION__
 #define __TRANSACTION__
 #include "btrfs_inode.h"

commit facda1e787d43191a3368c322f682054991c41b8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 8 18:11:48 2007 -0400

    Btrfs: get forced transaction commits via workqueue
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 0b08208be853..f25b4900db45 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -8,7 +8,6 @@ struct btrfs_transaction {
 	int in_commit;
 	int use_count;
 	int commit_done;
-	int magic;
 	struct list_head list;
 	struct radix_tree_root dirty_pages;
 	unsigned long start_time;
@@ -17,13 +16,11 @@ struct btrfs_transaction {
 };
 
 struct btrfs_trans_handle {
-	int magic;
 	u64 transid;
 	unsigned long blocks_reserved;
 	unsigned long blocks_used;
 	struct btrfs_transaction *transaction;
 	struct btrfs_block_group_cache *block_group;
-	int magic2;
 };
 
 

commit 08607c1b182b3b8b54d7141a0c012cda17d201e6
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Jun 8 15:33:54 2007 -0400

    Btrfs: add compat ioctl
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index b5378119e76c..0b08208be853 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -11,6 +11,7 @@ struct btrfs_transaction {
 	int magic;
 	struct list_head list;
 	struct radix_tree_root dirty_pages;
+	unsigned long start_time;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 };
@@ -47,4 +48,11 @@ int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
 				     struct btrfs_root *root);
 int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,
 			    struct btrfs_root *root);
+
+void btrfs_transaction_cleaner(struct work_struct *work);
+void btrfs_transaction_flush_work(struct btrfs_root *root);
+void btrfs_transaction_queue_work(struct btrfs_root *root, int delay);
+void btrfs_init_transaction_sys(void);
+void btrfs_exit_transaction_sys(void);
+
 #endif

commit 31f3c99b73483f7b738a886c552050cbd6128ff3
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 30 15:25:45 2007 -0400

    Btrfs: allocator improvements, inode block groups
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index afe42d167cee..b5378119e76c 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -1,5 +1,6 @@
 #ifndef __TRANSACTION__
 #define __TRANSACTION__
+#include "btrfs_inode.h"
 
 struct btrfs_transaction {
 	u64 transid;
@@ -20,10 +21,24 @@ struct btrfs_trans_handle {
 	unsigned long blocks_reserved;
 	unsigned long blocks_used;
 	struct btrfs_transaction *transaction;
+	struct btrfs_block_group_cache *block_group;
 	int magic2;
 };
 
 
+static inline void btrfs_set_trans_block_group(struct btrfs_trans_handle *trans,
+					       struct inode *inode)
+{
+	trans->block_group = BTRFS_I(inode)->block_group;
+}
+
+static inline void btrfs_update_inode_block_group(struct
+						  btrfs_trans_handle *trans,
+						  struct inode *inode)
+{
+	BTRFS_I(inode)->block_group = trans->block_group;
+}
+
 int btrfs_end_transaction(struct btrfs_trans_handle *trans,
 			  struct btrfs_root *root);
 struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,

commit 7c4452b9a6ca7aabe37ea2e43d443110bdc08cd8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Sat Apr 28 09:29:35 2007 -0400

    Btrfs: smarter transaction writeback
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 3cc29900a074..afe42d167cee 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -9,6 +9,7 @@ struct btrfs_transaction {
 	int commit_done;
 	int magic;
 	struct list_head list;
+	struct radix_tree_root dirty_pages;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 };

commit 8fd17795b2261ecb1bad2a6df09ef14c4957a3fb
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Apr 19 21:01:03 2007 -0400

    Btrfs: early fsync support
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 4f1496ae6f24..3cc29900a074 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -8,6 +8,7 @@ struct btrfs_transaction {
 	int use_count;
 	int commit_done;
 	int magic;
+	struct list_head list;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 };

commit 2c90e5d658424bc71b111eb5a972240d5d06fe86
Author: Chris Mason <chris.mason@oracle.com>
Date:   Mon Apr 2 10:50:19 2007 -0400

    Btrfs: still corruption hunting
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 7e6c08a0accd..4f1496ae6f24 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -7,15 +7,18 @@ struct btrfs_transaction {
 	int in_commit;
 	int use_count;
 	int commit_done;
+	int magic;
 	wait_queue_head_t writer_wait;
 	wait_queue_head_t commit_wait;
 };
 
 struct btrfs_trans_handle {
+	int magic;
 	u64 transid;
 	unsigned long blocks_reserved;
 	unsigned long blocks_used;
 	struct btrfs_transaction *transaction;
+	int magic2;
 };
 
 

commit 79154b1b5bcf87903db7ff16a30b360b78d6fe4f
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 22 15:59:16 2007 -0400

    Btrfs: transaction rework
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 9ab27b7491c5..7e6c08a0accd 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -1,27 +1,30 @@
 #ifndef __TRANSACTION__
 #define __TRANSACTION__
 
+struct btrfs_transaction {
+	u64 transid;
+	unsigned long num_writers;
+	int in_commit;
+	int use_count;
+	int commit_done;
+	wait_queue_head_t writer_wait;
+	wait_queue_head_t commit_wait;
+};
+
 struct btrfs_trans_handle {
 	u64 transid;
 	unsigned long blocks_reserved;
 	unsigned long blocks_used;
+	struct btrfs_transaction *transaction;
 };
 
-static inline struct btrfs_trans_handle *
-btrfs_start_transaction(struct btrfs_root *root, int num_blocks)
-{
-	struct btrfs_trans_handle *h = kmalloc(sizeof(*h), GFP_NOFS);
-	h->transid = root->root_key.offset;
-	h->blocks_reserved = num_blocks;
-	h->blocks_used = 0;
-	return h;
-}
-
-static inline void btrfs_free_transaction(struct btrfs_root *root,
-					  struct btrfs_trans_handle *handle)
-{
-	memset(handle, 0, sizeof(*handle));
-	kfree(handle);
-}
 
+int btrfs_end_transaction(struct btrfs_trans_handle *trans,
+			  struct btrfs_root *root);
+struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,
+						   int num_blocks);
+int btrfs_write_and_wait_transaction(struct btrfs_trans_handle *trans,
+				     struct btrfs_root *root);
+int btrfs_commit_tree_roots(struct btrfs_trans_handle *trans,
+			    struct btrfs_root *root);
 #endif

commit e20d96d64f9cf9288ffecc9ad4714e91c3b97ca8
Author: Chris Mason <chris.mason@oracle.com>
Date:   Thu Mar 22 12:13:20 2007 -0400

    Mountable btrfs, with readdir
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
index 3adb6e69fe43..9ab27b7491c5 100644
--- a/fs/btrfs/transaction.h
+++ b/fs/btrfs/transaction.h
@@ -10,7 +10,7 @@ struct btrfs_trans_handle {
 static inline struct btrfs_trans_handle *
 btrfs_start_transaction(struct btrfs_root *root, int num_blocks)
 {
-	struct btrfs_trans_handle *h = malloc(sizeof(*h));
+	struct btrfs_trans_handle *h = kmalloc(sizeof(*h), GFP_NOFS);
 	h->transid = root->root_key.offset;
 	h->blocks_reserved = num_blocks;
 	h->blocks_used = 0;
@@ -21,7 +21,7 @@ static inline void btrfs_free_transaction(struct btrfs_root *root,
 					  struct btrfs_trans_handle *handle)
 {
 	memset(handle, 0, sizeof(*handle));
-	free(handle);
+	kfree(handle);
 }
 
 #endif

commit e089f05c18ab36ed5fa7e2319052e03ab800d518
Author: Chris Mason <chris.mason@oracle.com>
Date:   Fri Mar 16 16:20:31 2007 -0400

    Btrfs: transaction handles everywhere
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h
new file mode 100644
index 000000000000..3adb6e69fe43
--- /dev/null
+++ b/fs/btrfs/transaction.h
@@ -0,0 +1,27 @@
+#ifndef __TRANSACTION__
+#define __TRANSACTION__
+
+struct btrfs_trans_handle {
+	u64 transid;
+	unsigned long blocks_reserved;
+	unsigned long blocks_used;
+};
+
+static inline struct btrfs_trans_handle *
+btrfs_start_transaction(struct btrfs_root *root, int num_blocks)
+{
+	struct btrfs_trans_handle *h = malloc(sizeof(*h));
+	h->transid = root->root_key.offset;
+	h->blocks_reserved = num_blocks;
+	h->blocks_used = 0;
+	return h;
+}
+
+static inline void btrfs_free_transaction(struct btrfs_root *root,
+					  struct btrfs_trans_handle *handle)
+{
+	memset(handle, 0, sizeof(*handle));
+	free(handle);
+}
+
+#endif
